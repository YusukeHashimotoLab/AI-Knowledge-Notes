<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ç¬¬2ç« ï¼šGraph Convolutional Networks (GCN) - AI Terakoya</title>

    <style>
        :root {
            --color-primary: #2c3e50;
            --color-primary-dark: #1a252f;
            --color-accent: #7b2cbf;
            --color-accent-light: #9d4edd;
            --color-text: #2d3748;
            --color-text-light: #4a5568;
            --color-bg: #ffffff;
            --color-bg-alt: #f7fafc;
            --color-border: #e2e8f0;
            --color-code-bg: #f8f9fa;
            --color-link: #3182ce;
            --color-link-hover: #2c5aa0;

            --spacing-xs: 0.5rem;
            --spacing-sm: 1rem;
            --spacing-md: 1.5rem;
            --spacing-lg: 2rem;
            --spacing-xl: 3rem;

            --font-body: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            --font-mono: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;

            --border-radius: 8px;
            --box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: var(--font-body);
            line-height: 1.7;
            color: var(--color-text);
            background-color: var(--color-bg);
            font-size: 16px;
        }

        header {
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            padding: var(--spacing-xl) var(--spacing-md);
            margin-bottom: var(--spacing-xl);
            box-shadow: var(--box-shadow);
        }

        .header-content {
            max-width: 900px;
            margin: 0 auto;
        }

        h1 {
            font-size: 2rem;
            font-weight: 700;
            margin-bottom: var(--spacing-sm);
            line-height: 1.2;
        }

        .subtitle {
            font-size: 1.1rem;
            opacity: 0.95;
            font-weight: 400;
            margin-bottom: var(--spacing-md);
        }

        .meta {
            display: flex;
            flex-wrap: wrap;
            gap: var(--spacing-md);
            font-size: 0.9rem;
            opacity: 0.9;
        }

        .meta-item {
            display: flex;
            align-items: center;
            gap: 0.3rem;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 0 var(--spacing-md) var(--spacing-xl);
        }

        h2 {
            font-size: 1.75rem;
            color: var(--color-primary);
            margin-top: var(--spacing-xl);
            margin-bottom: var(--spacing-md);
            padding-bottom: var(--spacing-xs);
            border-bottom: 3px solid var(--color-accent);
        }

        h3 {
            font-size: 1.4rem;
            color: var(--color-primary);
            margin-top: var(--spacing-lg);
            margin-bottom: var(--spacing-sm);
        }

        h4 {
            font-size: 1.1rem;
            color: var(--color-primary-dark);
            margin-top: var(--spacing-md);
            margin-bottom: var(--spacing-sm);
        }

        p {
            margin-bottom: var(--spacing-md);
            color: var(--color-text);
        }

        a {
            color: var(--color-link);
            text-decoration: none;
            transition: color 0.2s;
        }

        a:hover {
            color: var(--color-link-hover);
            text-decoration: underline;
        }

        ul, ol {
            margin-left: var(--spacing-lg);
            margin-bottom: var(--spacing-md);
        }

        li {
            margin-bottom: var(--spacing-xs);
            color: var(--color-text);
        }

        pre {
            background-color: var(--color-code-bg);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            overflow-x: auto;
            margin-bottom: var(--spacing-md);
            font-family: var(--font-mono);
            font-size: 0.9rem;
            line-height: 1.5;
        }

        code {
            font-family: var(--font-mono);
            font-size: 0.9em;
            background-color: var(--color-code-bg);
            padding: 0.2em 0.4em;
            border-radius: 3px;
        }

        pre code {
            background-color: transparent;
            padding: 0;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: var(--spacing-md);
            font-size: 0.95rem;
        }

        th, td {
            border: 1px solid var(--color-border);
            padding: var(--spacing-sm);
            text-align: left;
        }

        th {
            background-color: var(--color-bg-alt);
            font-weight: 600;
            color: var(--color-primary);
        }

        blockquote {
            border-left: 4px solid var(--color-accent);
            padding-left: var(--spacing-md);
            margin: var(--spacing-md) 0;
            color: var(--color-text-light);
            font-style: italic;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        .mermaid {
            text-align: center;
            margin: var(--spacing-lg) 0;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        details {
            background-color: var(--color-bg-alt);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            margin-bottom: var(--spacing-md);
        }

        summary {
            cursor: pointer;
            font-weight: 600;
            color: var(--color-primary);
            user-select: none;
            padding: var(--spacing-xs);
            margin: calc(-1 * var(--spacing-md));
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        summary:hover {
            background-color: rgba(123, 44, 191, 0.1);
        }

        details[open] summary {
            margin-bottom: var(--spacing-md);
            border-bottom: 1px solid var(--color-border);
        }

        .navigation {
            display: flex;
            justify-content: space-between;
            gap: var(--spacing-md);
            margin: var(--spacing-xl) 0;
            padding-top: var(--spacing-lg);
            border-top: 2px solid var(--color-border);
        }

        .nav-button {
            flex: 1;
            padding: var(--spacing-md);
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            border-radius: var(--border-radius);
            text-align: center;
            font-weight: 600;
            transition: transform 0.2s, box-shadow 0.2s;
            box-shadow: var(--box-shadow);
        }

        .nav-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
            text-decoration: none;
        }

        footer {
            margin-top: var(--spacing-xl);
            padding: var(--spacing-lg) var(--spacing-md);
            background-color: var(--color-bg-alt);
            border-top: 1px solid var(--color-border);
            text-align: center;
            font-size: 0.9rem;
            color: var(--color-text-light);
        }

        @media (max-width: 768px) {
            h1 {
                font-size: 1.5rem;
            }

            h2 {
                font-size: 1.4rem;
            }

            h3 {
                font-size: 1.2rem;
            }

            .meta {
                font-size: 0.85rem;
            }

            .navigation {
                flex-direction: column;
            }

            table {
                font-size: 0.85rem;
            }

            th, td {
                padding: var(--spacing-xs);
            }
        }
    </style>

    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
        mermaid.initialize({ startOnLoad: true, theme: 'default' });
    </script>

    <!-- MathJax for LaTeX equation rendering -->
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                displayMath: [['$$', '$$'], ['\\[', '\\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
                ignoreHtmlClass: 'mermaid'
            }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" async></script>
</head>
<body>
    <header>
        <div class="header-content">
            <h1>ç¬¬2ç« ï¼šGraph Convolutional Networks (GCN)</h1>
            <p class="subtitle">ã‚¹ãƒšã‚¯ãƒˆãƒ«ã‚°ãƒ©ãƒ•ç†è«–ã‹ã‚‰å®Ÿè£…ã¾ã§å®Œå…¨ç†è§£</p>
            <div class="meta">
                <span class="meta-item">ğŸ“– èª­äº†æ™‚é–“: 30-35åˆ†</span>
                <span class="meta-item">ğŸ“Š é›£æ˜“åº¦: ä¸­ç´šã€œä¸Šç´š</span>
                <span class="meta-item">ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹: 12å€‹</span>
                <span class="meta-item">ğŸ“ æ¼”ç¿’å•é¡Œ: 5å•</span>
            </div>
        </div>
    </header>

    <main class="container">

<h2>å­¦ç¿’ç›®æ¨™</h2>
<p>ã“ã®ç« ã‚’èª­ã‚€ã“ã¨ã§ã€ä»¥ä¸‹ã‚’ç¿’å¾—ã§ãã¾ã™ï¼š</p>
<ul>
<li>âœ… ã‚¹ãƒšã‚¯ãƒˆãƒ«ã‚°ãƒ©ãƒ•ç†è«–ã®åŸºç¤ï¼ˆã‚°ãƒ©ãƒ•ãƒ©ãƒ—ãƒ©ã‚·ã‚¢ãƒ³ã€å›ºæœ‰å€¤åˆ†è§£ï¼‰ã‚’ç†è§£ã™ã‚‹</li>
<li>âœ… CNNã‹ã‚‰GCNã¸ã®ç†è«–çš„ãªæ‹¡å¼µã®å‹•æ©Ÿã‚’èª¬æ˜ã§ãã‚‹</li>
<li>âœ… GCNå±¤ã®æ•°å­¦çš„å®šå¼åŒ–ã¨å¯¾ç§°æ­£è¦åŒ–ã®æ„å‘³ã‚’ç†è§£ã™ã‚‹</li>
<li>âœ… PyTorchã§GCNå±¤ã‚’ä¸€ã‹ã‚‰å®Ÿè£…ã§ãã‚‹</li>
<li>âœ… PyTorch Geometricãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§GCNãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã§ãã‚‹</li>
<li>âœ… Coraãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ãƒãƒ¼ãƒ‰åˆ†é¡ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã§ãã‚‹</li>
</ul>

<hr>

<h2>2.1 ã‚¹ãƒšã‚¯ãƒˆãƒ«ã‚°ãƒ©ãƒ•ç†è«–ã®åŸºç¤</h2>

<h3>ã‚°ãƒ©ãƒ•ãƒ©ãƒ—ãƒ©ã‚·ã‚¢ãƒ³ï¼ˆGraph Laplacianï¼‰</h3>

<p><strong>ã‚°ãƒ©ãƒ•ãƒ©ãƒ—ãƒ©ã‚·ã‚¢ãƒ³</strong>ã¯ã€ã‚°ãƒ©ãƒ•ã®æ§‹é€ ã‚’è¡Œåˆ—ã§è¡¨ç¾ã™ã‚‹åŸºæœ¬çš„ãªæ‰‹æ³•ã§ã™ã€‚ã‚°ãƒ©ãƒ• $G = (V, E)$ ã«å¯¾ã—ã¦ã€ä»¥ä¸‹ã®ã‚ˆã†ã«å®šç¾©ã•ã‚Œã¾ã™ï¼š</p>

$$
L = D - A
$$

<p>ã“ã“ã§ï¼š</p>
<ul>
<li>$A$ï¼šéš£æ¥è¡Œåˆ—ï¼ˆAdjacency matrixï¼‰</li>
<li>$D$ï¼šæ¬¡æ•°è¡Œåˆ—ï¼ˆDegree matrixï¼‰ã€å¯¾è§’è¦ç´ ãŒ $D_{ii} = \sum_j A_{ij}$</li>
<li>$L$ï¼šãƒ©ãƒ—ãƒ©ã‚·ã‚¢ãƒ³è¡Œåˆ—ï¼ˆLaplacian matrixï¼‰</li>
</ul>

<h3>æ­£è¦åŒ–ãƒ©ãƒ—ãƒ©ã‚·ã‚¢ãƒ³</h3>

<p>GCNã§ã¯ã€<strong>å¯¾ç§°æ­£è¦åŒ–ãƒ©ãƒ—ãƒ©ã‚·ã‚¢ãƒ³</strong>ãŒä½¿ç”¨ã•ã‚Œã¾ã™ï¼š</p>

$$
L_{\text{sym}} = D^{-1/2} L D^{-1/2} = I - D^{-1/2} A D^{-1/2}
$$

<p>ã¾ãŸã€ãƒ©ãƒ³ãƒ€ãƒ ã‚¦ã‚©ãƒ¼ã‚¯æ­£è¦åŒ–ãƒ©ãƒ—ãƒ©ã‚·ã‚¢ãƒ³ã‚‚ã‚ã‚Šã¾ã™ï¼š</p>

$$
L_{\text{rw}} = D^{-1} L = I - D^{-1} A
$$

<div class="mermaid">
graph LR
    A["éš£æ¥è¡Œåˆ— A"] --> L["ãƒ©ãƒ—ãƒ©ã‚·ã‚¢ãƒ³ L = D - A"]
    D["æ¬¡æ•°è¡Œåˆ— D"] --> L
    L --> Lsym["å¯¾ç§°æ­£è¦åŒ– L_sym"]
    L --> Lrw["ãƒ©ãƒ³ãƒ€ãƒ ã‚¦ã‚©ãƒ¼ã‚¯ L_rw"]

    style A fill:#b3e5fc
    style D fill:#c5e1a5
    style L fill:#fff9c4
    style Lsym fill:#ffab91
</div>

<h3>ã‚°ãƒ©ãƒ•ãƒ©ãƒ—ãƒ©ã‚·ã‚¢ãƒ³ã®å®Ÿè£…</h3>

<pre><code class="language-python">import numpy as np
import torch
import networkx as nx
import matplotlib.pyplot as plt

def compute_graph_laplacian(A):
    """
    ã‚°ãƒ©ãƒ•ãƒ©ãƒ—ãƒ©ã‚·ã‚¢ãƒ³ã‚’è¨ˆç®—

    Args:
        A: (N, N) éš£æ¥è¡Œåˆ—

    Returns:
        L: (N, N) ãƒ©ãƒ—ãƒ©ã‚·ã‚¢ãƒ³è¡Œåˆ—
        D: (N, N) æ¬¡æ•°è¡Œåˆ—
    """
    # æ¬¡æ•°è¡Œåˆ—ï¼ˆå¯¾è§’è¡Œåˆ—ï¼‰
    D = np.diag(A.sum(axis=1))

    # ãƒ©ãƒ—ãƒ©ã‚·ã‚¢ãƒ³ L = D - A
    L = D - A

    return L, D


def compute_normalized_laplacian(A, method='symmetric'):
    """
    æ­£è¦åŒ–ãƒ©ãƒ—ãƒ©ã‚·ã‚¢ãƒ³ã‚’è¨ˆç®—

    Args:
        A: (N, N) éš£æ¥è¡Œåˆ—
        method: 'symmetric' or 'random_walk'

    Returns:
        L_norm: (N, N) æ­£è¦åŒ–ãƒ©ãƒ—ãƒ©ã‚·ã‚¢ãƒ³
    """
    # æ¬¡æ•°è¡Œåˆ—
    D = np.diag(A.sum(axis=1))

    # D^{-1/2}ï¼ˆå¯¾ç§°æ­£è¦åŒ–ç”¨ï¼‰
    D_inv_sqrt = np.diag(1.0 / np.sqrt(np.diag(D) + 1e-10))

    if method == 'symmetric':
        # L_sym = I - D^{-1/2} A D^{-1/2}
        L_norm = np.eye(len(A)) - D_inv_sqrt @ A @ D_inv_sqrt
    elif method == 'random_walk':
        # L_rw = I - D^{-1} A
        D_inv = np.diag(1.0 / (np.diag(D) + 1e-10))
        L_norm = np.eye(len(A)) - D_inv @ A
    else:
        raise ValueError(f"Unknown method: {method}")

    return L_norm


# ç°¡å˜ãªã‚°ãƒ©ãƒ•ã®ä¾‹
print("=== ã‚°ãƒ©ãƒ•ãƒ©ãƒ—ãƒ©ã‚·ã‚¢ãƒ³ã®è¨ˆç®—ä¾‹ ===")

# 5ãƒãƒ¼ãƒ‰ã®ã‚°ãƒ©ãƒ•ã‚’ä½œæˆ
G = nx.Graph()
G.add_edges_from([(0, 1), (0, 2), (1, 2), (2, 3), (3, 4)])

# éš£æ¥è¡Œåˆ—
A = nx.adjacency_matrix(G).toarray()
print(f"éš£æ¥è¡Œåˆ— A:\n{A}\n")

# ãƒ©ãƒ—ãƒ©ã‚·ã‚¢ãƒ³è¡Œåˆ—
L, D = compute_graph_laplacian(A)
print(f"æ¬¡æ•°è¡Œåˆ— D:\n{D}\n")
print(f"ãƒ©ãƒ—ãƒ©ã‚·ã‚¢ãƒ³ L = D - A:\n{L}\n")

# æ­£è¦åŒ–ãƒ©ãƒ—ãƒ©ã‚·ã‚¢ãƒ³
L_sym = compute_normalized_laplacian(A, method='symmetric')
print(f"å¯¾ç§°æ­£è¦åŒ–ãƒ©ãƒ—ãƒ©ã‚·ã‚¢ãƒ³ L_sym:\n{L_sym}\n")

# ãƒ©ãƒ—ãƒ©ã‚·ã‚¢ãƒ³ã®æ€§è³ªã‚’ç¢ºèª
print("=== ãƒ©ãƒ—ãƒ©ã‚·ã‚¢ãƒ³ã®æ€§è³ª ===")
print(f"Lã®å„è¡Œã®å’Œ: {L.sum(axis=1)}")
print("â†’ ã™ã¹ã¦0ï¼ˆãƒ©ãƒ—ãƒ©ã‚·ã‚¢ãƒ³ã®é‡è¦ãªæ€§è³ªï¼‰")

# ã‚°ãƒ©ãƒ•ã®å¯è¦–åŒ–
plt.figure(figsize=(8, 6))
pos = nx.spring_layout(G)
nx.draw(G, pos, with_labels=True, node_color='lightblue',
        node_size=800, font_size=16, font_weight='bold')
plt.title("Sample Graph (5 nodes)")
plt.savefig('graph_example.png', dpi=150, bbox_inches='tight')
print("\nã‚°ãƒ©ãƒ•ã‚’ä¿å­˜: graph_example.png")
plt.close()
</code></pre>

<h3>å›ºæœ‰å€¤åˆ†è§£ã¨ã‚¹ãƒšã‚¯ãƒˆãƒ«</h3>

<p>ãƒ©ãƒ—ãƒ©ã‚·ã‚¢ãƒ³è¡Œåˆ—ã®<strong>å›ºæœ‰å€¤åˆ†è§£</strong>ã¯ã€ã‚°ãƒ©ãƒ•ã®å‘¨æ³¢æ•°æˆåˆ†ã‚’è¡¨ã—ã¾ã™ï¼š</p>

$$
L = U \Lambda U^T
$$

<p>ã“ã“ã§ï¼š</p>
<ul>
<li>$U$ï¼šå›ºæœ‰ãƒ™ã‚¯ãƒˆãƒ«è¡Œåˆ—ï¼ˆã‚°ãƒ©ãƒ•ãƒ•ãƒ¼ãƒªã‚¨åŸºåº•ï¼‰</li>
<li>$\Lambda$ï¼šå›ºæœ‰å€¤ã®å¯¾è§’è¡Œåˆ—ï¼ˆå‘¨æ³¢æ•°ã«å¯¾å¿œï¼‰</li>
</ul>

<pre><code class="language-python">import numpy as np
import matplotlib.pyplot as plt

def spectral_analysis(L):
    """
    ãƒ©ãƒ—ãƒ©ã‚·ã‚¢ãƒ³ã®ã‚¹ãƒšã‚¯ãƒˆãƒ«åˆ†æ

    Args:
        L: (N, N) ãƒ©ãƒ—ãƒ©ã‚·ã‚¢ãƒ³è¡Œåˆ—

    Returns:
        eigenvalues: (N,) å›ºæœ‰å€¤ï¼ˆæ˜‡é †ï¼‰
        eigenvectors: (N, N) å›ºæœ‰ãƒ™ã‚¯ãƒˆãƒ«
    """
    # å›ºæœ‰å€¤åˆ†è§£
    eigenvalues, eigenvectors = np.linalg.eigh(L)

    return eigenvalues, eigenvectors


print("\n=== ã‚¹ãƒšã‚¯ãƒˆãƒ«åˆ†æ ===")

# å›ºæœ‰å€¤åˆ†è§£
eigenvalues, eigenvectors = spectral_analysis(L)

print(f"å›ºæœ‰å€¤ï¼ˆæ˜‡é †ï¼‰:\n{eigenvalues}\n")
print(f"å›ºæœ‰ãƒ™ã‚¯ãƒˆãƒ«ï¼ˆæœ€åˆã®3ã¤ï¼‰:\n{eigenvectors[:, :3]}\n")

# å›ºæœ‰å€¤ã®å¯è¦–åŒ–
plt.figure(figsize=(10, 4))

plt.subplot(1, 2, 1)
plt.bar(range(len(eigenvalues)), eigenvalues, color='steelblue')
plt.xlabel('Index')
plt.ylabel('Eigenvalue')
plt.title('Laplacian Eigenvalues (Spectrum)')
plt.grid(True, alpha=0.3)

plt.subplot(1, 2, 2)
plt.plot(eigenvectors[:, 0], 'o-', label='1st eigenvector', markersize=8)
plt.plot(eigenvectors[:, 1], 's-', label='2nd eigenvector', markersize=8)
plt.plot(eigenvectors[:, 2], '^-', label='3rd eigenvector', markersize=8)
plt.xlabel('Node')
plt.ylabel('Value')
plt.title('First 3 Eigenvectors')
plt.legend()
plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('laplacian_spectrum.png', dpi=150, bbox_inches='tight')
print("ã‚¹ãƒšã‚¯ãƒˆãƒ«ã‚’ä¿å­˜: laplacian_spectrum.png")
plt.close()

# é‡è¦ãªæ€§è³ª
print("=== ãƒ©ãƒ—ãƒ©ã‚·ã‚¢ãƒ³ã®é‡è¦ãªæ€§è³ª ===")
print(f"æœ€å°å›ºæœ‰å€¤: {eigenvalues[0]:.6f}")
print("â†’ é€£çµã‚°ãƒ©ãƒ•ã§ã¯å¸¸ã«0")
print(f"æœ€å°å›ºæœ‰å€¤ã®å›ºæœ‰ãƒ™ã‚¯ãƒˆãƒ«: {eigenvectors[:, 0]}")
print("â†’ ã™ã¹ã¦åŒã˜å€¤ï¼ˆå®šæ•°ãƒ™ã‚¯ãƒˆãƒ«ï¼‰")
</code></pre>

<h3>ã‚¹ãƒšã‚¯ãƒˆãƒ«ç•³ã¿è¾¼ã¿</h3>

<p>ã‚°ãƒ©ãƒ•ä¸Šã®ç•³ã¿è¾¼ã¿ã¯ã€<strong>ãƒ•ãƒ¼ãƒªã‚¨é ˜åŸŸ</strong>ã§å®šç¾©ã•ã‚Œã¾ã™ï¼š</p>

$$
x \star_G g = U \left( (U^T g) \odot (U^T x) \right)
$$

<p>ã“ã“ã§ï¼š</p>
<ul>
<li>$x$ï¼šãƒãƒ¼ãƒ‰ç‰¹å¾´ãƒ™ã‚¯ãƒˆãƒ«</li>
<li>$g$ï¼šãƒ•ã‚£ãƒ«ã‚¿ï¼ˆå‘¨æ³¢æ•°é ˜åŸŸã§å®šç¾©ï¼‰</li>
<li>$\odot$ï¼šè¦ç´ ã”ã¨ã®ç©ï¼ˆHadamardç©ï¼‰</li>
</ul>

<blockquote>
<p>ã€Œã‚¹ãƒšã‚¯ãƒˆãƒ«ç•³ã¿è¾¼ã¿ã¯ã€ã‚°ãƒ©ãƒ•ãƒ•ãƒ¼ãƒªã‚¨å¤‰æ›ã‚’ç”¨ã„ã¦ã‚°ãƒ©ãƒ•ä¸Šã®ä¿¡å·ã‚’å‘¨æ³¢æ•°é ˜åŸŸã§å‡¦ç†ã—ã¾ã™ã€</p>
</blockquote>

<hr>

<h2>2.2 CNNã‹ã‚‰GCNã¸ã®æ‹¡å¼µ</h2>

<h3>CNNã®ç•³ã¿è¾¼ã¿æ¼”ç®—</h3>

<p>é€šå¸¸ã®CNNï¼ˆConvolutional Neural Networksï¼‰ã§ã¯ã€<strong>ç”»åƒã®ã‚°ãƒªãƒƒãƒ‰æ§‹é€ </strong>ä¸Šã§ç•³ã¿è¾¼ã¿ã‚’è¡Œã„ã¾ã™ï¼š</p>

$$
h_i^{(\ell+1)} = \sigma \left( W^{(\ell)} \sum_{j \in \mathcal{N}(i)} h_j^{(\ell)} + b^{(\ell)} \right)
$$

<p>ã“ã“ã§ã€$\mathcal{N}(i)$ ã¯ç”»ç´  $i$ ã®è¿‘å‚ï¼ˆé€šå¸¸ã¯3Ã—3ã‚«ãƒ¼ãƒãƒ«ï¼‰ã§ã™ã€‚</p>

<h3>ã‚°ãƒ©ãƒ•ã¸ã®ä¸€èˆ¬åŒ–ã®èª²é¡Œ</h3>

<table>
<thead>
<tr>
<th>èª²é¡Œ</th>
<th>ç”»åƒï¼ˆã‚°ãƒªãƒƒãƒ‰ï¼‰</th>
<th>ã‚°ãƒ©ãƒ•</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>è¿‘å‚ã®ã‚µã‚¤ã‚º</strong></td>
<td>å›ºå®šï¼ˆ3Ã—3ãªã©ï¼‰</td>
<td>ãƒãƒ¼ãƒ‰ã”ã¨ã«ç•°ãªã‚‹</td>
</tr>
<tr>
<td><strong>é †åº</strong></td>
<td>å›ºå®šï¼ˆä¸Šä¸‹å·¦å³ï¼‰</td>
<td>å®šç¾©ãªã—</td>
</tr>
<tr>
<td><strong>è·é›¢</strong></td>
<td>ãƒ¦ãƒ¼ã‚¯ãƒªãƒƒãƒ‰è·é›¢</td>
<td>ã‚°ãƒ©ãƒ•ä¸Šã®è·é›¢</td>
</tr>
<tr>
<td><strong>å¯¾ç§°æ€§</strong></td>
<td>ä¸¦é€²å¯¾ç§°æ€§</td>
<td>ç½®æ›å¯¾ç§°æ€§</td>
</tr>
</tbody>
</table>

<div class="mermaid">
graph TB
    CNN["CNN<br/>ã‚°ãƒªãƒƒãƒ‰æ§‹é€ "] --> Challenge["èª²é¡Œ<br/>ä¸è¦å‰‡ãªã‚°ãƒ©ãƒ•æ§‹é€ "]
    Challenge --> Spectral["ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ1<br/>ã‚¹ãƒšã‚¯ãƒˆãƒ«æ³•"]
    Challenge --> Spatial["ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ2<br/>ç©ºé–“æ³•"]
    Spectral --> GCN["GCN<br/>ä¸€æ¬¡è¿‘ä¼¼"]

    style CNN fill:#b3e5fc
    style Challenge fill:#fff9c4
    style Spectral fill:#c5e1a5
    style GCN fill:#ffab91
</div>

<h3>GCNã®åŸºæœ¬ã‚¢ã‚¤ãƒ‡ã‚¢</h3>

<p><strong>Graph Convolutional Networks (GCN)</strong>ã¯ã€ã‚¹ãƒšã‚¯ãƒˆãƒ«ç•³ã¿è¾¼ã¿ã‚’<strong>ä¸€æ¬¡è¿‘ä¼¼</strong>ã™ã‚‹ã“ã¨ã§ã€åŠ¹ç‡çš„ãªã‚°ãƒ©ãƒ•ç•³ã¿è¾¼ã¿ã‚’å®Ÿç¾ã—ã¾ã™ï¼š</p>

$$
H^{(\ell+1)} = \sigma \left( \tilde{D}^{-1/2} \tilde{A} \tilde{D}^{-1/2} H^{(\ell)} W^{(\ell)} \right)
$$

<p>ã“ã“ã§ï¼š</p>
<ul>
<li>$\tilde{A} = A + I$ï¼šè‡ªå·±ãƒ«ãƒ¼ãƒ—ã‚’è¿½åŠ ã—ãŸéš£æ¥è¡Œåˆ—</li>
<li>$\tilde{D}$ï¼š$\tilde{A}$ ã®æ¬¡æ•°è¡Œåˆ—</li>
<li>$H^{(\ell)}$ï¼š$\ell$ å±¤ç›®ã®ãƒãƒ¼ãƒ‰ç‰¹å¾´è¡Œåˆ—</li>
<li>$W^{(\ell)}$ï¼šå­¦ç¿’å¯èƒ½ãªé‡ã¿è¡Œåˆ—</li>
<li>$\sigma$ï¼šæ´»æ€§åŒ–é–¢æ•°</li>
</ul>

<h3>è‡ªå·±ãƒ«ãƒ¼ãƒ—ã®è¿½åŠ ã¨ãã®æ„ç¾©</h3>

<pre><code class="language-python">import numpy as np
import torch

def add_self_loops(A):
    """
    éš£æ¥è¡Œåˆ—ã«è‡ªå·±ãƒ«ãƒ¼ãƒ—ã‚’è¿½åŠ 

    Args:
        A: (N, N) éš£æ¥è¡Œåˆ—

    Returns:
        A_tilde: (N, N) è‡ªå·±ãƒ«ãƒ¼ãƒ—ä»˜ãéš£æ¥è¡Œåˆ—
    """
    # å˜ä½è¡Œåˆ—ã‚’è¿½åŠ 
    A_tilde = A + np.eye(len(A))
    return A_tilde


print("\n=== è‡ªå·±ãƒ«ãƒ¼ãƒ—ã®è¿½åŠ  ===")

# å…ƒã®éš£æ¥è¡Œåˆ—
print(f"å…ƒã®éš£æ¥è¡Œåˆ— A:\n{A}\n")

# è‡ªå·±ãƒ«ãƒ¼ãƒ—ã‚’è¿½åŠ 
A_tilde = add_self_loops(A)
print(f"è‡ªå·±ãƒ«ãƒ¼ãƒ—ä»˜ã Ãƒ = A + I:\n{A_tilde}\n")

print("=== è‡ªå·±ãƒ«ãƒ¼ãƒ—ã®æ„ç¾© ===")
print("1. ãƒãƒ¼ãƒ‰è‡ªèº«ã®ç‰¹å¾´ã‚’ä¿æŒ")
print("2. æ¬¡æ•°ãŒ0ã®ãƒãƒ¼ãƒ‰ã§ã‚‚æƒ…å ±ã‚’æŒã¦ã‚‹")
print("3. æ•°å€¤å®‰å®šæ€§ã®å‘ä¸Š")
</code></pre>

<h3>å¯¾ç§°æ­£è¦åŒ–ã®å°å‡º</h3>

<p>å¯¾ç§°æ­£è¦åŒ–ã¯ã€<strong>ãƒãƒ¼ãƒ‰ã®æ¬¡æ•°ã®å½±éŸ¿ã‚’æ­£è¦åŒ–</strong>ã—ã¾ã™ï¼š</p>

$$
\hat{A} = \tilde{D}^{-1/2} \tilde{A} \tilde{D}^{-1/2}
$$

<p>ã“ã‚Œã«ã‚ˆã‚Šï¼š</p>
<ol>
<li>æ¬¡æ•°ãŒå¤§ãã„ãƒãƒ¼ãƒ‰ã‹ã‚‰ã®å¯„ä¸ã‚’æ­£è¦åŒ–</li>
<li>å¯¾ç§°è¡Œåˆ—ã¨ãªã‚Šæ•°å€¤çš„ã«å®‰å®š</li>
<li>å›ºæœ‰å€¤ãŒ [-1, 1] ã®ç¯„å›²ã«åã¾ã‚‹</li>
</ol>

<pre><code class="language-python">import numpy as np

def symmetric_normalization(A):
    """
    å¯¾ç§°æ­£è¦åŒ–éš£æ¥è¡Œåˆ—ã‚’è¨ˆç®—

    Args:
        A: (N, N) éš£æ¥è¡Œåˆ—

    Returns:
        A_hat: (N, N) æ­£è¦åŒ–éš£æ¥è¡Œåˆ—
    """
    # è‡ªå·±ãƒ«ãƒ¼ãƒ—ã‚’è¿½åŠ 
    A_tilde = A + np.eye(len(A))

    # æ¬¡æ•°è¡Œåˆ—
    D_tilde = np.diag(A_tilde.sum(axis=1))

    # D^{-1/2}
    D_inv_sqrt = np.diag(1.0 / np.sqrt(np.diag(D_tilde)))

    # Ã‚ = D^{-1/2} Ãƒ D^{-1/2}
    A_hat = D_inv_sqrt @ A_tilde @ D_inv_sqrt

    return A_hat


print("\n=== å¯¾ç§°æ­£è¦åŒ– ===")

A_hat = symmetric_normalization(A)
print(f"æ­£è¦åŒ–éš£æ¥è¡Œåˆ— Ã‚:\n{A_hat}\n")

# å„è¡Œã®å’Œã‚’ç¢ºèª
print(f"Ã‚ã®å„è¡Œã®å’Œ:\n{A_hat.sum(axis=1)}\n")
print("â†’ å¿…ãšã—ã‚‚1ã§ã¯ãªã„ãŒã€ãƒãƒ©ãƒ³ã‚¹ãŒå–ã‚Œã¦ã„ã‚‹")

# å¯¾ç§°æ€§ã‚’ç¢ºèª
is_symmetric = np.allclose(A_hat, A_hat.T)
print(f"Ã‚ã¯å¯¾ç§°è¡Œåˆ—: {is_symmetric}")
</code></pre>

<hr>

<h2>2.3 GCNå±¤ã®æ•°å­¦çš„å®šå¼åŒ–</h2>

<h3>å˜ä¸€GCNå±¤ã®å®šç¾©</h3>

<p>1ã¤ã®GCNå±¤ã¯ã€ä»¥ä¸‹ã®æ¼”ç®—ã‚’å®Ÿè¡Œã—ã¾ã™ï¼š</p>

$$
H^{(\ell+1)} = \sigma \left( \hat{A} H^{(\ell)} W^{(\ell)} \right)
$$

<p>ã“ã“ã§ï¼š</p>
<ul>
<li>$H^{(\ell)} \in \mathbb{R}^{N \times d_\ell}$ï¼š$\ell$ å±¤ç›®ã®ãƒãƒ¼ãƒ‰ç‰¹å¾´ï¼ˆ$N$ ã¯ãƒãƒ¼ãƒ‰æ•°ã€$d_\ell$ ã¯ç‰¹å¾´æ¬¡å…ƒï¼‰</li>
<li>$W^{(\ell)} \in \mathbb{R}^{d_\ell \times d_{\ell+1}}$ï¼šå­¦ç¿’å¯èƒ½ãªé‡ã¿è¡Œåˆ—</li>
<li>$\hat{A} = \tilde{D}^{-1/2} \tilde{A} \tilde{D}^{-1/2}$ï¼šæ­£è¦åŒ–éš£æ¥è¡Œåˆ—</li>
<li>$\sigma$ï¼šæ´»æ€§åŒ–é–¢æ•°ï¼ˆReLUã€Tanhãªã©ï¼‰</li>
</ul>

<h3>è¨ˆç®—ã®æµã‚Œ</h3>

<div class="mermaid">
graph LR
    H0["H^(â„“)<br/>(N Ã— d_â„“)"] --> Mult1["H^(â„“) W^(â„“)"]
    W["W^(â„“)<br/>(d_â„“ Ã— d_â„“+1)"] --> Mult1
    Mult1 --> Aggregate["Ã‚ Ã— (H^(â„“) W^(â„“))"]
    Ahat["Ã‚<br/>(N Ã— N)"] --> Aggregate
    Aggregate --> Activation["Ïƒ(...)"]
    Activation --> H1["H^(â„“+1)<br/>(N Ã— d_â„“+1)"]

    style H0 fill:#b3e5fc
    style W fill:#c5e1a5
    style Aggregate fill:#fff59d
    style H1 fill:#ffab91
</div>

<h3>ãƒãƒ¼ãƒ‰ãƒ¬ãƒ™ãƒ«ã§ã®è§£é‡ˆ</h3>

<p>å„ãƒãƒ¼ãƒ‰ $i$ ã«å¯¾ã—ã¦ï¼š</p>

$$
h_i^{(\ell+1)} = \sigma \left( \sum_{j \in \mathcal{N}(i) \cup \{i\}} \frac{1}{\sqrt{\tilde{d}_i \tilde{d}_j}} h_j^{(\ell)} W^{(\ell)} \right)
$$

<p>ã“ã‚Œã¯ã€<strong>è¿‘å‚ãƒãƒ¼ãƒ‰ã®ç‰¹å¾´ã®é‡ã¿ä»˜ãå’Œ</strong>ã‚’è¨ˆç®—ã—ã¦ã„ã‚‹ã“ã¨ã‚’æ„å‘³ã—ã¾ã™ã€‚</p>

<h3>ãƒã‚¤ã‚¢ã‚¹é …ã®è¿½åŠ </h3>

<p>å®Ÿç”¨çš„ã«ã¯ã€ãƒã‚¤ã‚¢ã‚¹é …ã‚‚è¿½åŠ ã—ã¾ã™ï¼š</p>

$$
H^{(\ell+1)} = \sigma \left( \hat{A} H^{(\ell)} W^{(\ell)} + b^{(\ell)} \right)
$$

<h3>å¤šå±¤GCNã®å®šå¼åŒ–</h3>

<p>$L$ å±¤ã®GCNã¯ã€å†å¸°çš„ã«å®šç¾©ã•ã‚Œã¾ã™ï¼š</p>

$$
\begin{align}
H^{(0)} &= X \quad \text{ï¼ˆå…¥åŠ›ç‰¹å¾´ï¼‰} \\
H^{(\ell+1)} &= \sigma \left( \hat{A} H^{(\ell)} W^{(\ell)} \right), \quad \ell = 0, 1, \ldots, L-1 \\
Z &= H^{(L)} \quad \text{ï¼ˆå‡ºåŠ›ï¼‰}
\end{align}
$$

<pre><code class="language-python">import torch
import torch.nn as nn
import torch.nn.functional as F

def gcn_layer_forward(A_hat, H, W, bias=None, activation=None):
    """
    GCNå±¤ã®é †ä¼æ’­

    Args:
        A_hat: (N, N) æ­£è¦åŒ–éš£æ¥è¡Œåˆ—
        H: (N, d_in) ãƒãƒ¼ãƒ‰ç‰¹å¾´
        W: (d_in, d_out) é‡ã¿è¡Œåˆ—
        bias: (d_out,) ãƒã‚¤ã‚¢ã‚¹ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        activation: æ´»æ€§åŒ–é–¢æ•°ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰

    Returns:
        H_next: (N, d_out) æ¬¡ã®å±¤ã®ç‰¹å¾´
    """
    # 1. ç‰¹å¾´å¤‰æ›ï¼šH @ W
    H_transformed = H @ W

    # 2. è¿‘å‚é›†ç´„ï¼šÃ‚ @ (H @ W)
    H_aggregated = A_hat @ H_transformed

    # 3. ãƒã‚¤ã‚¢ã‚¹è¿½åŠ 
    if bias is not None:
        H_aggregated = H_aggregated + bias

    # 4. æ´»æ€§åŒ–
    if activation is not None:
        H_next = activation(H_aggregated)
    else:
        H_next = H_aggregated

    return H_next


# æ•°å€¤ä¾‹
print("\n=== GCNå±¤ã®é †ä¼æ’­ ===")

N = 5  # ãƒãƒ¼ãƒ‰æ•°
d_in = 4  # å…¥åŠ›ç‰¹å¾´æ¬¡å…ƒ
d_out = 8  # å‡ºåŠ›ç‰¹å¾´æ¬¡å…ƒ

# ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿
A_hat_torch = torch.FloatTensor(A_hat)
H = torch.randn(N, d_in)
W = torch.randn(d_in, d_out)
b = torch.randn(d_out)

print(f"å…¥åŠ›ç‰¹å¾´ H: {H.shape}")
print(f"é‡ã¿ W: {W.shape}")
print(f"æ­£è¦åŒ–éš£æ¥è¡Œåˆ— Ã‚: {A_hat_torch.shape}")

# GCNå±¤ã®è¨ˆç®—
H_next = gcn_layer_forward(A_hat_torch, H, W, bias=b, activation=torch.relu)

print(f"å‡ºåŠ›ç‰¹å¾´ H^(â„“+1): {H_next.shape}")
print(f"\nã‚µãƒ³ãƒ—ãƒ«å‡ºåŠ›ï¼ˆãƒãƒ¼ãƒ‰0ã®ç‰¹å¾´ï¼‰:\n{H_next[0]}")
</code></pre>

<hr>

<h2>2.4 PyTorchã§ã®GCNå±¤å®Ÿè£…</h2>

<h3>GCNLayerã‚¯ãƒ©ã‚¹ã®å®Ÿè£…</h3>

<pre><code class="language-python">import torch
import torch.nn as nn
import torch.nn.functional as F

class GCNLayer(nn.Module):
    """
    å˜ä¸€ã®GCNå±¤
    """
    def __init__(self, in_features, out_features, bias=True):
        """
        Args:
            in_features: å…¥åŠ›ç‰¹å¾´æ¬¡å…ƒ
            out_features: å‡ºåŠ›ç‰¹å¾´æ¬¡å…ƒ
            bias: ãƒã‚¤ã‚¢ã‚¹ã‚’ä½¿ç”¨ã™ã‚‹ã‹
        """
        super(GCNLayer, self).__init__()

        # é‡ã¿è¡Œåˆ—
        self.weight = nn.Parameter(torch.FloatTensor(in_features, out_features))

        # ãƒã‚¤ã‚¢ã‚¹
        if bias:
            self.bias = nn.Parameter(torch.FloatTensor(out_features))
        else:
            self.register_parameter('bias', None)

        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®åˆæœŸåŒ–
        self.reset_parameters()

    def reset_parameters(self):
        """Xavierã®åˆæœŸåŒ–"""
        nn.init.xavier_uniform_(self.weight)
        if self.bias is not None:
            nn.init.zeros_(self.bias)

    def forward(self, x, adj):
        """
        é †ä¼æ’­

        Args:
            x: (N, in_features) ãƒãƒ¼ãƒ‰ç‰¹å¾´
            adj: (N, N) æ­£è¦åŒ–éš£æ¥è¡Œåˆ—

        Returns:
            output: (N, out_features) å‡ºåŠ›ç‰¹å¾´
        """
        # ç‰¹å¾´å¤‰æ›ï¼šX @ W
        support = torch.mm(x, self.weight)

        # è¿‘å‚é›†ç´„ï¼šÃ‚ @ (X @ W)
        output = torch.spmm(adj, support) if adj.is_sparse else torch.mm(adj, support)

        # ãƒã‚¤ã‚¢ã‚¹è¿½åŠ 
        if self.bias is not None:
            output = output + self.bias

        return output


# å‹•ä½œç¢ºèª
print("\n=== GCNLayerã‚¯ãƒ©ã‚¹ã®å‹•ä½œç¢ºèª ===")

N = 10  # ãƒãƒ¼ãƒ‰æ•°
in_features = 16
out_features = 32

# GCNå±¤ã®ä½œæˆ
gcn_layer = GCNLayer(in_features, out_features)

# ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿
x = torch.randn(N, in_features)
adj = torch.randn(N, N)
# å¯¾ç§°æ­£è¦åŒ–ï¼ˆç°¡ç•¥ç‰ˆï¼‰
adj = (adj + adj.T) / 2
adj = adj / adj.sum(dim=1, keepdim=True)

# Forward
output = gcn_layer(x, adj)

print(f"å…¥åŠ›: {x.shape}")
print(f"éš£æ¥è¡Œåˆ—: {adj.shape}")
print(f"å‡ºåŠ›: {output.shape}")

# ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°
num_params = sum(p.numel() for p in gcn_layer.parameters())
print(f"ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {num_params:,}")
print(f"  é‡ã¿: {gcn_layer.weight.numel():,}")
print(f"  ãƒã‚¤ã‚¢ã‚¹: {gcn_layer.bias.numel() if gcn_layer.bias is not None else 0}")
</code></pre>

<h3>å®Œå…¨ãªGCNãƒ¢ãƒ‡ãƒ«ã®å®Ÿè£…</h3>

<pre><code class="language-python">import torch
import torch.nn as nn
import torch.nn.functional as F

class GCN(nn.Module):
    """
    å¤šå±¤Graph Convolutional Network
    """
    def __init__(self, input_dim, hidden_dim, output_dim, num_layers=2, dropout=0.5):
        """
        Args:
            input_dim: å…¥åŠ›ç‰¹å¾´æ¬¡å…ƒ
            hidden_dim: éš ã‚Œå±¤ã®æ¬¡å…ƒ
            output_dim: å‡ºåŠ›æ¬¡å…ƒï¼ˆã‚¯ãƒ©ã‚¹æ•°ï¼‰
            num_layers: GCNå±¤ã®æ•°
            dropout: ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆç‡
        """
        super(GCN, self).__init__()

        self.num_layers = num_layers
        self.dropout = dropout

        # GCNå±¤ã®ãƒªã‚¹ãƒˆ
        self.gcn_layers = nn.ModuleList()

        # æœ€åˆã®å±¤
        self.gcn_layers.append(GCNLayer(input_dim, hidden_dim))

        # ä¸­é–“å±¤
        for _ in range(num_layers - 2):
            self.gcn_layers.append(GCNLayer(hidden_dim, hidden_dim))

        # æœ€å¾Œã®å±¤
        if num_layers > 1:
            self.gcn_layers.append(GCNLayer(hidden_dim, output_dim))
        else:
            # 1å±¤ã®ã¿ã®å ´åˆ
            self.gcn_layers[0] = GCNLayer(input_dim, output_dim)

    def forward(self, x, adj):
        """
        é †ä¼æ’­

        Args:
            x: (N, input_dim) ãƒãƒ¼ãƒ‰ç‰¹å¾´
            adj: (N, N) æ­£è¦åŒ–éš£æ¥è¡Œåˆ—

        Returns:
            output: (N, output_dim) å‡ºåŠ›ï¼ˆãƒ­ã‚¸ãƒƒãƒˆï¼‰
        """
        h = x

        # ä¸­é–“å±¤
        for i in range(self.num_layers - 1):
            h = self.gcn_layers[i](h, adj)
            h = F.relu(h)
            h = F.dropout(h, p=self.dropout, training=self.training)

        # æœ€å¾Œã®å±¤ï¼ˆæ´»æ€§åŒ–ãªã—ï¼‰
        output = self.gcn_layers[-1](h, adj)

        return output


# ãƒ¢ãƒ‡ãƒ«ä½œæˆ
print("\n=== GCNãƒ¢ãƒ‡ãƒ«ã®ä½œæˆ ===")

input_dim = 1433  # Coraãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ç‰¹å¾´æ¬¡å…ƒ
hidden_dim = 16
output_dim = 7  # ã‚¯ãƒ©ã‚¹æ•°
num_layers = 2

model = GCN(input_dim, hidden_dim, output_dim, num_layers=num_layers, dropout=0.5)

# ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿
N = 100
x = torch.randn(N, input_dim)
adj = torch.randn(N, N)
adj = (adj + adj.T) / 2
adj = adj / adj.sum(dim=1, keepdim=True)

# Forward
output = model(x, adj)

print(f"å…¥åŠ›: {x.shape}")
print(f"å‡ºåŠ›: {output.shape}")

# ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°
total_params = sum(p.numel() for p in model.parameters())
print(f"\nç·ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {total_params:,}")

# å„å±¤ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°
for i, layer in enumerate(model.gcn_layers):
    layer_params = sum(p.numel() for p in layer.parameters())
    print(f"  GCNå±¤{i+1}: {layer_params:,}")
</code></pre>

<h3>æ­£è¦åŒ–éš£æ¥è¡Œåˆ—ã®å‰å‡¦ç†</h3>

<pre><code class="language-python">import torch
import scipy.sparse as sp
import numpy as np

def preprocess_adjacency(adj):
    """
    éš£æ¥è¡Œåˆ—ã‚’å¯¾ç§°æ­£è¦åŒ–

    Args:
        adj: (N, N) éš£æ¥è¡Œåˆ—ï¼ˆNumPyé…åˆ—ã¾ãŸã¯SciPy sparseï¼‰

    Returns:
        adj_normalized: (N, N) æ­£è¦åŒ–éš£æ¥è¡Œåˆ—ï¼ˆTensorï¼‰
    """
    # NumPyé…åˆ—ã«å¤‰æ›
    if sp.issparse(adj):
        adj = adj.toarray()

    # è‡ªå·±ãƒ«ãƒ¼ãƒ—ã‚’è¿½åŠ 
    adj_tilde = adj + np.eye(adj.shape[0])

    # æ¬¡æ•°è¡Œåˆ—
    degree = np.array(adj_tilde.sum(1))

    # D^{-1/2}
    degree_inv_sqrt = np.power(degree, -0.5).flatten()
    degree_inv_sqrt[np.isinf(degree_inv_sqrt)] = 0.
    D_inv_sqrt = sp.diags(degree_inv_sqrt)

    # Ã‚ = D^{-1/2} Ãƒ D^{-1/2}
    if sp.issparse(adj):
        adj_normalized = D_inv_sqrt @ sp.csr_matrix(adj_tilde) @ D_inv_sqrt
        adj_normalized = torch.FloatTensor(adj_normalized.toarray())
    else:
        adj_normalized = D_inv_sqrt @ adj_tilde @ D_inv_sqrt
        adj_normalized = torch.FloatTensor(adj_normalized)

    return adj_normalized


# ä½¿ç”¨ä¾‹
print("\n=== éš£æ¥è¡Œåˆ—ã®å‰å‡¦ç† ===")

# ã‚µãƒ³ãƒ—ãƒ«éš£æ¥è¡Œåˆ—
N = 5
adj_raw = np.array([
    [0, 1, 1, 0, 0],
    [1, 0, 1, 0, 0],
    [1, 1, 0, 1, 1],
    [0, 0, 1, 0, 1],
    [0, 0, 1, 1, 0]
], dtype=np.float32)

print(f"å…ƒã®éš£æ¥è¡Œåˆ—:\n{adj_raw}\n")

# æ­£è¦åŒ–
adj_norm = preprocess_adjacency(adj_raw)

print(f"æ­£è¦åŒ–éš£æ¥è¡Œåˆ—:\n{adj_norm}\n")

# æ€§è³ªã®ç¢ºèª
print("=== æ­£è¦åŒ–ã®åŠ¹æœ ===")
print(f"æœ€å¤§å€¤: {adj_norm.max().item():.4f}")
print(f"æœ€å°å€¤: {adj_norm.min().item():.4f}")
print(f"å¯¾è§’è¦ç´ ï¼ˆè‡ªå·±ãƒ«ãƒ¼ãƒ—ï¼‰: {adj_norm.diag()}")
</code></pre>

<hr>

<h2>2.5 PyTorch Geometricã®åˆ©ç”¨</h2>

<h3>PyTorch Geometricã¨ã¯</h3>

<p><strong>PyTorch Geometric (PyG)</strong>ã¯ã€ã‚°ãƒ©ãƒ•ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ç”¨ã®å¼·åŠ›ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§ã™ã€‚ä»¥ä¸‹ã®æ©Ÿèƒ½ã‚’æä¾›ã—ã¾ã™ï¼š</p>

<ul>
<li>åŠ¹ç‡çš„ãªã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿æ§‹é€ ï¼ˆCOOå½¢å¼ã®ã‚¨ãƒƒã‚¸ãƒªã‚¹ãƒˆï¼‰</li>
<li>è±Šå¯ŒãªGNNå±¤ï¼ˆGCNã€GATã€GraphSAGEãªã©ï¼‰</li>
<li>ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆCoraã€PubMedã€CiteSeerãªã©ï¼‰</li>
<li>ãƒŸãƒ‹ãƒãƒƒãƒå‡¦ç†ã®ã‚µãƒãƒ¼ãƒˆ</li>
</ul>

<h3>PyTorch Geometricã§ã®GCNå®Ÿè£…</h3>

<pre><code class="language-python">import torch
import torch.nn.functional as F
from torch_geometric.nn import GCNConv
from torch_geometric.data import Data

class PyGGCN(torch.nn.Module):
    """
    PyTorch Geometricã®GCNConvã‚’ä½¿ç”¨ã—ãŸãƒ¢ãƒ‡ãƒ«
    """
    def __init__(self, input_dim, hidden_dim, output_dim, dropout=0.5):
        super(PyGGCN, self).__init__()

        # GCNå±¤
        self.conv1 = GCNConv(input_dim, hidden_dim)
        self.conv2 = GCNConv(hidden_dim, output_dim)

        self.dropout = dropout

    def forward(self, x, edge_index):
        """
        Args:
            x: (N, input_dim) ãƒãƒ¼ãƒ‰ç‰¹å¾´
            edge_index: (2, E) ã‚¨ãƒƒã‚¸ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆCOOå½¢å¼ï¼‰

        Returns:
            output: (N, output_dim) å‡ºåŠ›
        """
        # ç¬¬1å±¤
        x = self.conv1(x, edge_index)
        x = F.relu(x)
        x = F.dropout(x, p=self.dropout, training=self.training)

        # ç¬¬2å±¤
        x = self.conv2(x, edge_index)

        return x


# ãƒ¢ãƒ‡ãƒ«ä½œæˆ
print("\n=== PyTorch Geometric GCN ===")

input_dim = 1433
hidden_dim = 16
output_dim = 7

pyg_model = PyGGCN(input_dim, hidden_dim, output_dim)

# ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ï¼ˆPyGå½¢å¼ï¼‰
N = 100
E = 200

x = torch.randn(N, input_dim)
edge_index = torch.randint(0, N, (2, E))  # (2, E)

# Forward
output = pyg_model(x, edge_index)

print(f"å…¥åŠ›: {x.shape}")
print(f"ã‚¨ãƒƒã‚¸ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹: {edge_index.shape}")
print(f"å‡ºåŠ›: {output.shape}")

# ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°
total_params = sum(p.numel() for p in pyg_model.parameters())
print(f"ç·ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {total_params:,}")
</code></pre>

<h3>ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ã®æ§‹ç¯‰</h3>

<pre><code class="language-python">import torch
from torch_geometric.data import Data
import networkx as nx

def networkx_to_pyg(G, node_features=None, labels=None):
    """
    NetworkXã‚°ãƒ©ãƒ•ã‚’PyTorch Geometricå½¢å¼ã«å¤‰æ›

    Args:
        G: NetworkXã‚°ãƒ©ãƒ•
        node_features: (N, d) ãƒãƒ¼ãƒ‰ç‰¹å¾´ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        labels: (N,) ãƒãƒ¼ãƒ‰ãƒ©ãƒ™ãƒ«ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰

    Returns:
        data: PyTorch Geometricã®Dataã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
    """
    # ã‚¨ãƒƒã‚¸ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆCOOå½¢å¼ï¼‰
    edge_list = list(G.edges())
    edge_index = torch.tensor(edge_list, dtype=torch.long).t().contiguous()

    # ç„¡å‘ã‚°ãƒ©ãƒ•ã®å ´åˆã€é€†æ–¹å‘ã®ã‚¨ãƒƒã‚¸ã‚‚è¿½åŠ 
    if not G.is_directed():
        edge_index = torch.cat([edge_index, edge_index.flip(0)], dim=1)

    # ãƒãƒ¼ãƒ‰ç‰¹å¾´
    if node_features is None:
        # ãƒ€ãƒŸãƒ¼ç‰¹å¾´ï¼ˆå˜ä½è¡Œåˆ—ï¼‰
        x = torch.eye(G.number_of_nodes())
    else:
        x = torch.FloatTensor(node_features)

    # ãƒ©ãƒ™ãƒ«
    y = torch.LongTensor(labels) if labels is not None else None

    # Dataã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆä½œæˆ
    data = Data(x=x, edge_index=edge_index, y=y)

    return data


# ä¾‹ï¼šç°¡å˜ãªã‚°ãƒ©ãƒ•
print("\n=== NetworkX â†’ PyTorch Geometric ===")

G = nx.karate_club_graph()
print(f"ã‚°ãƒ©ãƒ•: {G.number_of_nodes()} ãƒãƒ¼ãƒ‰, {G.number_of_edges()} ã‚¨ãƒƒã‚¸")

# PyGå½¢å¼ã«å¤‰æ›
data = networkx_to_pyg(G)

print(f"\nPyGãƒ‡ãƒ¼ã‚¿:")
print(f"  ãƒãƒ¼ãƒ‰ç‰¹å¾´: {data.x.shape}")
print(f"  ã‚¨ãƒƒã‚¸ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹: {data.edge_index.shape}")
print(f"  ã‚¨ãƒƒã‚¸æ•°: {data.num_edges}")
print(f"  ãƒãƒ¼ãƒ‰æ•°: {data.num_nodes}")
</code></pre>

<hr>

<h2>2.6 å®Ÿè·µï¼šCoraãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã®ãƒãƒ¼ãƒ‰åˆ†é¡</h2>

<h3>Coraãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æ¦‚è¦</h3>

<p><strong>Coraãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ</strong>ã¯ã€è«–æ–‡ã®å¼•ç”¨ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã§ã™ï¼š</p>

<ul>
<li><strong>ãƒãƒ¼ãƒ‰</strong>ï¼š2,708æœ¬ã®è«–æ–‡</li>
<li><strong>ã‚¨ãƒƒã‚¸</strong>ï¼š5,429ã®å¼•ç”¨é–¢ä¿‚</li>
<li><strong>ç‰¹å¾´</strong>ï¼š1,433æ¬¡å…ƒã®bag-of-wordsç‰¹å¾´ï¼ˆå˜èªã®æœ‰ç„¡ï¼‰</li>
<li><strong>ã‚¯ãƒ©ã‚¹</strong>ï¼š7ã¤ã®ç ”ç©¶åˆ†é‡ï¼ˆCase_Basedã€Genetic_Algorithmsã€Neural_Networksã€Probabilistic_Methodsã€Reinforcement_Learningã€Rule_Learningã€Theoryï¼‰</li>
</ul>

<h3>ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®èª­ã¿è¾¼ã¿ã¨å¯è¦–åŒ–</h3>

<pre><code class="language-python">import torch
from torch_geometric.datasets import Planetoid
import matplotlib.pyplot as plt
import networkx as nx

# Coraãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®èª­ã¿è¾¼ã¿
print("=== Coraãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®èª­ã¿è¾¼ã¿ ===")

dataset = Planetoid(root='./data', name='Cora')
data = dataset[0]

print(f"ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ: {dataset}")
print(f"ã‚°ãƒ©ãƒ•æ•°: {len(dataset)}")
print(f"\nã‚°ãƒ©ãƒ•æƒ…å ±:")
print(f"  ãƒãƒ¼ãƒ‰æ•°: {data.num_nodes}")
print(f"  ã‚¨ãƒƒã‚¸æ•°: {data.num_edges}")
print(f"  ãƒãƒ¼ãƒ‰ç‰¹å¾´æ¬¡å…ƒ: {data.num_node_features}")
print(f"  ã‚¯ãƒ©ã‚¹æ•°: {dataset.num_classes}")
print(f"\nãƒ‡ãƒ¼ã‚¿åˆ†å‰²:")
print(f"  è¨“ç·´ãƒãƒ¼ãƒ‰: {data.train_mask.sum().item()}")
print(f"  æ¤œè¨¼ãƒãƒ¼ãƒ‰: {data.val_mask.sum().item()}")
print(f"  ãƒ†ã‚¹ãƒˆãƒãƒ¼ãƒ‰: {data.test_mask.sum().item()}")

# ã‚¯ãƒ©ã‚¹åˆ†å¸ƒ
print(f"\nã‚¯ãƒ©ã‚¹åˆ†å¸ƒ:")
for i in range(dataset.num_classes):
    count = (data.y == i).sum().item()
    print(f"  ã‚¯ãƒ©ã‚¹ {i}: {count} ãƒãƒ¼ãƒ‰")

# ãƒ‡ãƒ¼ã‚¿ã®ä¸€éƒ¨ã‚’ç¢ºèª
print(f"\næœ€åˆã®5ãƒãƒ¼ãƒ‰ã®ç‰¹å¾´ï¼ˆéã‚¼ãƒ­è¦ç´ ã®ã¿ï¼‰:")
for i in range(5):
    nonzero = data.x[i].nonzero().squeeze()
    print(f"  ãƒãƒ¼ãƒ‰ {i}: {len(nonzero)} å€‹ã®å˜èª, ãƒ©ãƒ™ãƒ«={data.y[i].item()}")
</code></pre>

<h3>GCNãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´</h3>

<pre><code class="language-python">import torch
import torch.nn.functional as F
from torch_geometric.nn import GCNConv

class CoraGCN(torch.nn.Module):
    """Coraç”¨ã®GCNãƒ¢ãƒ‡ãƒ«"""
    def __init__(self, num_features, hidden_dim, num_classes, dropout=0.5):
        super(CoraGCN, self).__init__()
        self.conv1 = GCNConv(num_features, hidden_dim)
        self.conv2 = GCNConv(hidden_dim, num_classes)
        self.dropout = dropout

    def forward(self, x, edge_index):
        x = self.conv1(x, edge_index)
        x = F.relu(x)
        x = F.dropout(x, p=self.dropout, training=self.training)
        x = self.conv2(x, edge_index)
        return F.log_softmax(x, dim=1)


def train(model, data, optimizer):
    """1ã‚¨ãƒãƒƒã‚¯ã®è¨“ç·´"""
    model.train()
    optimizer.zero_grad()

    # Forward
    out = model(data.x, data.edge_index)

    # è¨“ç·´ãƒãƒ¼ãƒ‰ã®ã¿ã§æå¤±è¨ˆç®—
    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])

    # Backward
    loss.backward()
    optimizer.step()

    return loss.item()


def evaluate(model, data, mask):
    """è©•ä¾¡"""
    model.eval()

    with torch.no_grad():
        out = model(data.x, data.edge_index)
        pred = out.argmax(dim=1)

        # ç²¾åº¦è¨ˆç®—
        correct = (pred[mask] == data.y[mask]).sum().item()
        accuracy = correct / mask.sum().item()

    return accuracy


# ãƒ¢ãƒ‡ãƒ«ä½œæˆ
print("\n=== GCNãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ ===")

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"ãƒ‡ãƒã‚¤ã‚¹: {device}")

model = CoraGCN(
    num_features=dataset.num_node_features,
    hidden_dim=16,
    num_classes=dataset.num_classes,
    dropout=0.5
).to(device)

data = data.to(device)

optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)

# è¨“ç·´ãƒ«ãƒ¼ãƒ—
num_epochs = 200
best_val_acc = 0
best_test_acc = 0

print("\nã‚¨ãƒãƒƒã‚¯ | æå¤±   | è¨“ç·´ç²¾åº¦ | æ¤œè¨¼ç²¾åº¦ | ãƒ†ã‚¹ãƒˆç²¾åº¦")
print("-" * 60)

for epoch in range(1, num_epochs + 1):
    loss = train(model, data, optimizer)

    if epoch % 10 == 0:
        train_acc = evaluate(model, data, data.train_mask)
        val_acc = evaluate(model, data, data.val_mask)
        test_acc = evaluate(model, data, data.test_mask)

        if val_acc > best_val_acc:
            best_val_acc = val_acc
            best_test_acc = test_acc

        print(f"{epoch:7d} | {loss:.4f} | {train_acc:.4f}   | {val_acc:.4f}   | {test_acc:.4f}")

print(f"\næœ€è‰¯ã®æ¤œè¨¼ç²¾åº¦: {best_val_acc:.4f}")
print(f"å¯¾å¿œã™ã‚‹ãƒ†ã‚¹ãƒˆç²¾åº¦: {best_test_acc:.4f}")
</code></pre>

<h3>å­¦ç¿’æ›²ç·šã®å¯è¦–åŒ–</h3>

<pre><code class="language-python">import matplotlib.pyplot as plt
import numpy as np

def train_with_history(model, data, optimizer, num_epochs=200):
    """è¨“ç·´å±¥æ­´ã‚’è¨˜éŒ²"""
    history = {
        'train_loss': [],
        'train_acc': [],
        'val_acc': [],
        'test_acc': []
    }

    for epoch in range(1, num_epochs + 1):
        # è¨“ç·´
        loss = train(model, data, optimizer)

        # è©•ä¾¡
        train_acc = evaluate(model, data, data.train_mask)
        val_acc = evaluate(model, data, data.val_mask)
        test_acc = evaluate(model, data, data.test_mask)

        history['train_loss'].append(loss)
        history['train_acc'].append(train_acc)
        history['val_acc'].append(val_acc)
        history['test_acc'].append(test_acc)

    return history


# æ–°ã—ã„ãƒ¢ãƒ‡ãƒ«ã§è¨“ç·´
print("\n=== å­¦ç¿’æ›²ç·šã®è¨˜éŒ² ===")

model_new = CoraGCN(
    num_features=dataset.num_node_features,
    hidden_dim=16,
    num_classes=dataset.num_classes,
    dropout=0.5
).to(device)

optimizer_new = torch.optim.Adam(model_new.parameters(), lr=0.01, weight_decay=5e-4)

history = train_with_history(model_new, data, optimizer_new, num_epochs=200)

# å¯è¦–åŒ–
fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# æå¤±
axes[0].plot(history['train_loss'], label='Train Loss', linewidth=2)
axes[0].set_xlabel('Epoch')
axes[0].set_ylabel('Loss')
axes[0].set_title('Training Loss')
axes[0].legend()
axes[0].grid(True, alpha=0.3)

# ç²¾åº¦
axes[1].plot(history['train_acc'], label='Train Acc', linewidth=2)
axes[1].plot(history['val_acc'], label='Val Acc', linewidth=2)
axes[1].plot(history['test_acc'], label='Test Acc', linewidth=2)
axes[1].set_xlabel('Epoch')
axes[1].set_ylabel('Accuracy')
axes[1].set_title('Accuracy')
axes[1].legend()
axes[1].grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('cora_training_curves.png', dpi=150, bbox_inches='tight')
print("å­¦ç¿’æ›²ç·šã‚’ä¿å­˜: cora_training_curves.png")
plt.close()

print(f"\næœ€çµ‚ç²¾åº¦:")
print(f"  è¨“ç·´: {history['train_acc'][-1]:.4f}")
print(f"  æ¤œè¨¼: {history['val_acc'][-1]:.4f}")
print(f"  ãƒ†ã‚¹ãƒˆ: {history['test_acc'][-1]:.4f}")
</code></pre>

<h3>ãƒãƒ¼ãƒ‰åŸ‹ã‚è¾¼ã¿ã®å¯è¦–åŒ–</h3>

<pre><code class="language-python">import torch
import matplotlib.pyplot as plt
from sklearn.manifold import TSNE

def visualize_embeddings(model, data, layer='layer1'):
    """ãƒãƒ¼ãƒ‰åŸ‹ã‚è¾¼ã¿ã‚’t-SNEã§å¯è¦–åŒ–"""
    model.eval()

    with torch.no_grad():
        # ç¬¬1å±¤ã®å‡ºåŠ›ã‚’å–å¾—
        x = model.conv1(data.x, data.edge_index)
        x = F.relu(x)

        if layer == 'layer2':
            x = model.conv2(x, data.edge_index)

        embeddings = x.cpu().numpy()

    # t-SNE
    print(f"\n=== t-SNEåŸ‹ã‚è¾¼ã¿ï¼ˆ{embeddings.shape[1]}æ¬¡å…ƒ â†’ 2æ¬¡å…ƒï¼‰===")
    tsne = TSNE(n_components=2, random_state=42)
    embeddings_2d = tsne.fit_transform(embeddings)

    # å¯è¦–åŒ–
    plt.figure(figsize=(12, 10))

    # ã‚¯ãƒ©ã‚¹ã”ã¨ã«è‰²åˆ†ã‘
    labels = data.y.cpu().numpy()
    for i in range(dataset.num_classes):
        mask = labels == i
        plt.scatter(embeddings_2d[mask, 0], embeddings_2d[mask, 1],
                   label=f'Class {i}', alpha=0.6, s=30)

    plt.xlabel('t-SNE Dimension 1')
    plt.ylabel('t-SNE Dimension 2')
    plt.title(f'Node Embeddings Visualization ({layer})')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.tight_layout()

    filename = f'cora_embeddings_{layer}.png'
    plt.savefig(filename, dpi=150, bbox_inches='tight')
    print(f"åŸ‹ã‚è¾¼ã¿ã‚’ä¿å­˜: {filename}")
    plt.close()


# ç¬¬1å±¤ã¨ç¬¬2å±¤ã®åŸ‹ã‚è¾¼ã¿ã‚’å¯è¦–åŒ–
visualize_embeddings(model_new, data, layer='layer1')
visualize_embeddings(model_new, data, layer='layer2')

print("\nâ†’ åŒã˜ã‚¯ãƒ©ã‚¹ã®ãƒãƒ¼ãƒ‰ãŒè¿‘ãã«é…ç½®ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª")
</code></pre>

<hr>

<h2>æ¼”ç¿’å•é¡Œ</h2>

<details>
<summary><strong>æ¼”ç¿’1ï¼šGCNå±¤æ•°ã®å½±éŸ¿èª¿æŸ»</strong></summary>

<p>GCNã®å±¤æ•°ï¼ˆ1å±¤ã€2å±¤ã€3å±¤ã€4å±¤ï¼‰ã‚’å¤‰ãˆã¦ã€Coraãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã®æ€§èƒ½ã‚’æ¯”è¼ƒã—ã¦ãã ã•ã„ã€‚éå¹³æ»‘åŒ–ï¼ˆover-smoothingï¼‰ã®å•é¡Œã‚’è¦³å¯Ÿã§ãã¾ã™ã‹ï¼Ÿ</p>

<pre><code class="language-python">import torch

# TODO: ç•°ãªã‚‹å±¤æ•°ã®GCNãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´
# TODO: ãƒ†ã‚¹ãƒˆç²¾åº¦ã‚’ãƒ—ãƒ­ãƒƒãƒˆ
# TODO: å±¤æ•°ãŒå¢—ãˆã‚‹ã¨æ€§èƒ½ãŒä½ä¸‹ã™ã‚‹ç†ç”±ã‚’åˆ†æ
# ãƒ’ãƒ³ãƒˆ: å±¤ãŒæ·±ã™ãã‚‹ã¨ãƒãƒ¼ãƒ‰è¡¨ç¾ãŒä¼¼é€šã£ã¦ã—ã¾ã†ï¼ˆéå¹³æ»‘åŒ–ï¼‰
</code></pre>

</details>

<details>
<summary><strong>æ¼”ç¿’2ï¼šãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆç‡ã®æœ€é©åŒ–</strong></summary>

<p>ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆç‡ï¼ˆ0.0, 0.2, 0.5, 0.7, 0.9ï¼‰ã‚’å¤‰ãˆã¦ã€è¨“ç·´ç²¾åº¦ã¨æ¤œè¨¼ç²¾åº¦ã®å¤‰åŒ–ã‚’èª¿æŸ»ã—ã¦ãã ã•ã„ã€‚</p>

<pre><code class="language-python">import torch

# TODO: ç•°ãªã‚‹ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆç‡ã§ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´
# TODO: è¨“ç·´ç²¾åº¦ vs æ¤œè¨¼ç²¾åº¦ã®ã‚°ãƒ©ãƒ•ã‚’ä½œæˆ
# TODO: æœ€é©ãªãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆç‡ã‚’è¦‹ã¤ã‘ã‚‹
# æœŸå¾…: é©åº¦ãªãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆã§éå­¦ç¿’ã‚’é˜²ã
</code></pre>

</details>

<details>
<summary><strong>æ¼”ç¿’3ï¼šéš ã‚Œå±¤ã®æ¬¡å…ƒæ•°ã®å½±éŸ¿</strong></summary>

<p>éš ã‚Œå±¤ã®æ¬¡å…ƒæ•°ï¼ˆ4, 8, 16, 32, 64, 128ï¼‰ã‚’å¤‰ãˆã¦ã€æ€§èƒ½ã¨è¨ˆç®—æ™‚é–“ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’èª¿æŸ»ã—ã¦ãã ã•ã„ã€‚</p>

<pre><code class="language-python">import torch
import time

# TODO: ç•°ãªã‚‹éš ã‚Œå±¤æ¬¡å…ƒã§ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´
# TODO: ãƒ†ã‚¹ãƒˆç²¾åº¦ã¨ã‚¨ãƒãƒƒã‚¯ã‚ãŸã‚Šã®æ™‚é–“ã‚’è¨˜éŒ²
# TODO: æ€§èƒ½ vs è¨ˆç®—ã‚³ã‚¹ãƒˆã®ã‚°ãƒ©ãƒ•ã‚’ä½œæˆ
# åˆ†æ: æ¬¡å…ƒãŒå¤§ãã„ã»ã©è¡¨ç¾åŠ›ãŒé«˜ã„ãŒã€éå­¦ç¿’ã—ã‚„ã™ã„
</code></pre>

</details>

<details>
<summary><strong>æ¼”ç¿’4ï¼šæ­£è¦åŒ–æ‰‹æ³•ã®æ¯”è¼ƒ</strong></summary>

<p>å¯¾ç§°æ­£è¦åŒ–ã€ãƒ©ãƒ³ãƒ€ãƒ ã‚¦ã‚©ãƒ¼ã‚¯æ­£è¦åŒ–ã€æ­£è¦åŒ–ãªã—ã®3ã¤ã®æ‰‹æ³•ã§GCNã‚’è¨“ç·´ã—ã€æ€§èƒ½ã‚’æ¯”è¼ƒã—ã¦ãã ã•ã„ã€‚</p>

<pre><code class="language-python">import torch
import numpy as np

# TODO: 3ç¨®é¡ã®æ­£è¦åŒ–æ‰‹æ³•ã‚’å®Ÿè£…
# TODO: ãã‚Œãã‚Œã§GCNã‚’è¨“ç·´
# TODO: ãƒ†ã‚¹ãƒˆç²¾åº¦ã‚’æ¯”è¼ƒ
# æœŸå¾…: å¯¾ç§°æ­£è¦åŒ–ãŒæœ€ã‚‚å®‰å®šã—ã¦é«˜æ€§èƒ½
</code></pre>

</details>

<details>
<summary><strong>æ¼”ç¿’5ï¼šä»–ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã®å®Ÿé¨“</strong></summary>

<p>CiteSeerã¾ãŸã¯PubMedãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§GCNã‚’è¨“ç·´ã—ã€Coraã¨ã®é•ã„ã‚’åˆ†æã—ã¦ãã ã•ã„ã€‚</p>

<pre><code class="language-python">from torch_geometric.datasets import Planetoid

# TODO: CiteSeerã¾ãŸã¯PubMedãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’èª­ã¿è¾¼ã‚€
# TODO: åŒã˜GCNãƒ¢ãƒ‡ãƒ«ã§è¨“ç·´
# TODO: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆé–“ã®æ€§èƒ½å·®ã‚’åˆ†æ
# TODO: ã‚°ãƒ©ãƒ•æ§‹é€ ã®é•ã„ï¼ˆå¯†åº¦ã€æ¬¡æ•°åˆ†å¸ƒãªã©ï¼‰ã‚’èª¿æŸ»
</code></pre>

</details>

<hr>

<h2>ã¾ã¨ã‚</h2>

<p>ã“ã®ç« ã§ã¯ã€Graph Convolutional Networks (GCN)ã®ç†è«–ã¨å®Ÿè£…ã‚’å­¦ã³ã¾ã—ãŸã€‚</p>

<h3>é‡è¦ãƒã‚¤ãƒ³ãƒˆ</h3>

<ul>
<li><strong>ã‚°ãƒ©ãƒ•ãƒ©ãƒ—ãƒ©ã‚·ã‚¢ãƒ³</strong>ï¼šã‚°ãƒ©ãƒ•æ§‹é€ ã‚’è¡Œåˆ—ã§è¡¨ç¾ã—ã€å›ºæœ‰å€¤åˆ†è§£ã§ã‚¹ãƒšã‚¯ãƒˆãƒ«è§£æ</li>
<li><strong>ã‚¹ãƒšã‚¯ãƒˆãƒ«ç•³ã¿è¾¼ã¿</strong>ï¼šãƒ•ãƒ¼ãƒªã‚¨é ˜åŸŸã§ã®ã‚°ãƒ©ãƒ•ä¿¡å·å‡¦ç†</li>
<li><strong>GCNã®å‹•æ©Ÿ</strong>ï¼šCNNã®ç•³ã¿è¾¼ã¿ã‚’ã‚°ãƒ©ãƒ•æ§‹é€ ã«æ‹¡å¼µ</li>
<li><strong>å¯¾ç§°æ­£è¦åŒ–</strong>ï¼šæ¬¡æ•°ã®å½±éŸ¿ã‚’æ­£è¦åŒ–ã—ã€æ•°å€¤å®‰å®šæ€§ã‚’å‘ä¸Š</li>
<li><strong>GCNå±¤</strong>ï¼šè¿‘å‚ãƒãƒ¼ãƒ‰ã®ç‰¹å¾´ã‚’é›†ç´„ã—ã¦æ–°ã—ã„è¡¨ç¾ã‚’å­¦ç¿’</li>
<li><strong>å®Ÿè£…</strong>ï¼šPyTorchã§ã®ä¸€ã‹ã‚‰å®Ÿè£…ã¨PyTorch Geometricã®æ´»ç”¨</li>
<li><strong>ãƒãƒ¼ãƒ‰åˆ†é¡</strong>ï¼šCoraãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§é«˜ç²¾åº¦ãªè«–æ–‡åˆ†é¡ã‚’å®Ÿç¾</li>
<li><strong>éå¹³æ»‘åŒ–</strong>ï¼šå±¤ãŒæ·±ã™ãã‚‹ã¨ãƒãƒ¼ãƒ‰è¡¨ç¾ãŒä¼¼é€šã†å•é¡Œ</li>
</ul>

<h3>GCNã®åˆ©ç‚¹ã¨é™ç•Œ</h3>

<table>
<thead>
<tr>
<th>é …ç›®</th>
<th>åˆ©ç‚¹</th>
<th>é™ç•Œ</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>è¨ˆç®—åŠ¹ç‡</strong></td>
<td>ç·šå½¢è¨ˆç®—é‡ $O(|E|)$</td>
<td>å¤§è¦æ¨¡ã‚°ãƒ©ãƒ•ã§ãƒ¡ãƒ¢ãƒªåˆ¶ç´„</td>
</tr>
<tr>
<td><strong>è¡¨ç¾åŠ›</strong></td>
<td>ã‚°ãƒ©ãƒ•æ§‹é€ ã‚’æ´»ç”¨</td>
<td>éå¹³æ»‘åŒ–å•é¡Œ</td>
</tr>
<tr>
<td><strong>ä¸€èˆ¬åŒ–æ€§</strong></td>
<td>æ§˜ã€…ãªã‚°ãƒ©ãƒ•ã‚¿ã‚¹ã‚¯ã«é©ç”¨å¯èƒ½</td>
<td>å‹•çš„ã‚°ãƒ©ãƒ•ã«ã¯ä¸å‘ã</td>
</tr>
<tr>
<td><strong>è§£é‡ˆæ€§</strong></td>
<td>è¿‘å‚é›†ç´„ã®ç›´æ„Ÿçš„ãªç†è§£</td>
<td>ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³æ©Ÿæ§‹ãªã—</td>
</tr>
</tbody>
</table>

<h3>æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—</h3>

<p>æ¬¡ç« ã§ã¯ã€<strong>Graph Attention Networks (GAT)</strong>ã«ã¤ã„ã¦å­¦ã³ã¾ã™ã€‚ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³æ©Ÿæ§‹ã«ã‚ˆã‚‹ã‚ˆã‚ŠæŸ”è»Ÿãªè¿‘å‚é›†ç´„ã€ãƒãƒ«ãƒãƒ˜ãƒƒãƒ‰ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã€GCNã¨ã®æ¯”è¼ƒãªã©ã€GNNã®è¡¨ç¾åŠ›ã‚’ã•ã‚‰ã«å‘ä¸Šã•ã›ã‚‹æ‰‹æ³•ã‚’ç¿’å¾—ã—ã¾ã™ã€‚</p>

<div class="navigation">
    <a href="chapter1-graph-basics.html" class="nav-button">â† ç¬¬1ç« ï¼šã‚°ãƒ©ãƒ•ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å…¥é–€</a>
    <a href="chapter3-gat.html" class="nav-button">ç¬¬3ç« ï¼šGraph Attention Networks â†’</a>
</div>

</main>

<footer>
    <p>&copy; 2024 AI Terakoya. All rights reserved.</p>
</footer>

</body>
</html>
