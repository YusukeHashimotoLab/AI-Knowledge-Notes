<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ç¬¬1ç« ï¼šç•°å¸¸æ¤œçŸ¥åŸºç¤ - AI Terakoya</title>

    <style>
        :root {
            --color-primary: #2c3e50;
            --color-primary-dark: #1a252f;
            --color-accent: #7b2cbf;
            --color-accent-light: #9d4edd;
            --color-text: #2d3748;
            --color-text-light: #4a5568;
            --color-bg: #ffffff;
            --color-bg-alt: #f7fafc;
            --color-border: #e2e8f0;
            --color-code-bg: #f8f9fa;
            --color-link: #3182ce;
            --color-link-hover: #2c5aa0;

            --spacing-xs: 0.5rem;
            --spacing-sm: 1rem;
            --spacing-md: 1.5rem;
            --spacing-lg: 2rem;
            --spacing-xl: 3rem;

            --font-body: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            --font-mono: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;

            --border-radius: 8px;
            --box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: var(--font-body);
            line-height: 1.7;
            color: var(--color-text);
            background-color: var(--color-bg);
            font-size: 16px;
        }

        header {
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            padding: var(--spacing-xl) var(--spacing-md);
            margin-bottom: var(--spacing-xl);
            box-shadow: var(--box-shadow);
        }

        .header-content {
            max-width: 900px;
            margin: 0 auto;
        }

        h1 {
            font-size: 2rem;
            font-weight: 700;
            margin-bottom: var(--spacing-sm);
            line-height: 1.2;
        }

        .subtitle {
            font-size: 1.1rem;
            opacity: 0.95;
            font-weight: 400;
            margin-bottom: var(--spacing-md);
        }

        .meta {
            display: flex;
            flex-wrap: wrap;
            gap: var(--spacing-md);
            font-size: 0.9rem;
            opacity: 0.9;
        }

        .meta-item {
            display: flex;
            align-items: center;
            gap: 0.3rem;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 0 var(--spacing-md) var(--spacing-xl);
        }

        h2 {
            font-size: 1.75rem;
            color: var(--color-primary);
            margin-top: var(--spacing-xl);
            margin-bottom: var(--spacing-md);
            padding-bottom: var(--spacing-xs);
            border-bottom: 3px solid var(--color-accent);
        }

        h3 {
            font-size: 1.4rem;
            color: var(--color-primary);
            margin-top: var(--spacing-lg);
            margin-bottom: var(--spacing-sm);
        }

        h4 {
            font-size: 1.1rem;
            color: var(--color-primary-dark);
            margin-top: var(--spacing-md);
            margin-bottom: var(--spacing-sm);
        }

        p {
            margin-bottom: var(--spacing-md);
            color: var(--color-text);
        }

        a {
            color: var(--color-link);
            text-decoration: none;
            transition: color 0.2s;
        }

        a:hover {
            color: var(--color-link-hover);
            text-decoration: underline;
        }

        ul, ol {
            margin-left: var(--spacing-lg);
            margin-bottom: var(--spacing-md);
        }

        li {
            margin-bottom: var(--spacing-xs);
            color: var(--color-text);
        }

        pre {
            background-color: var(--color-code-bg);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            overflow-x: auto;
            margin-bottom: var(--spacing-md);
            font-family: var(--font-mono);
            font-size: 0.9rem;
            line-height: 1.5;
        }

        code {
            font-family: var(--font-mono);
            font-size: 0.9em;
            background-color: var(--color-code-bg);
            padding: 0.2em 0.4em;
            border-radius: 3px;
        }

        pre code {
            background-color: transparent;
            padding: 0;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: var(--spacing-md);
            font-size: 0.95rem;
        }

        th, td {
            border: 1px solid var(--color-border);
            padding: var(--spacing-sm);
            text-align: left;
        }

        th {
            background-color: var(--color-bg-alt);
            font-weight: 600;
            color: var(--color-primary);
        }

        blockquote {
            border-left: 4px solid var(--color-accent);
            padding-left: var(--spacing-md);
            margin: var(--spacing-md) 0;
            color: var(--color-text-light);
            font-style: italic;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        .mermaid {
            text-align: center;
            margin: var(--spacing-lg) 0;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        details {
            background-color: var(--color-bg-alt);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            margin-bottom: var(--spacing-md);
        }

        summary {
            cursor: pointer;
            font-weight: 600;
            color: var(--color-primary);
            user-select: none;
            padding: var(--spacing-xs);
            margin: calc(-1 * var(--spacing-md));
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        summary:hover {
            background-color: rgba(123, 44, 191, 0.1);
        }

        details[open] summary {
            margin-bottom: var(--spacing-md);
            border-bottom: 1px solid var(--color-border);
        }

        .navigation {
            display: flex;
            justify-content: space-between;
            gap: var(--spacing-md);
            margin: var(--spacing-xl) 0;
            padding-top: var(--spacing-lg);
            border-top: 2px solid var(--color-border);
        }

        .nav-button {
            flex: 1;
            padding: var(--spacing-md);
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            border-radius: var(--border-radius);
            text-align: center;
            font-weight: 600;
            transition: transform 0.2s, box-shadow 0.2s;
            box-shadow: var(--box-shadow);
        }

        .nav-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
            text-decoration: none;
        }

        footer {
            margin-top: var(--spacing-xl);
            padding: var(--spacing-lg) var(--spacing-md);
            background-color: var(--color-bg-alt);
            border-top: 1px solid var(--color-border);
            text-align: center;
            font-size: 0.9rem;
            color: var(--color-text-light);
        }

        @media (max-width: 768px) {
            h1 {
                font-size: 1.5rem;
            }

            h2 {
                font-size: 1.4rem;
            }

            h3 {
                font-size: 1.2rem;
            }

            .meta {
                font-size: 0.85rem;
            }

            .navigation {
                flex-direction: column;
            }

            table {
                font-size: 0.85rem;
            }

            th, td {
                padding: var(--spacing-xs);
            }
        }
    </style>

    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
        mermaid.initialize({ startOnLoad: true, theme: 'default' });
    </script>

    <!-- MathJax for LaTeX equation rendering -->
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                displayMath: [['$$', '$$'], ['\\[', '\\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
                ignoreHtmlClass: 'mermaid'
            }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" async></script>
</head>
<body>
    <header>
        <div class="header-content">
            <h1>ç¬¬1ç« ï¼šç•°å¸¸æ¤œçŸ¥åŸºç¤</h1>
            <p class="subtitle">ç•°å¸¸æ¤œçŸ¥ã®åŸºæœ¬æ¦‚å¿µã¨ã‚¿ã‚¹ã‚¯è¨­è¨ˆ</p>
            <div class="meta">
                <span class="meta-item">ğŸ“– èª­äº†æ™‚é–“: 25-30åˆ†</span>
                <span class="meta-item">ğŸ“Š é›£æ˜“åº¦: åˆç´š</span>
                <span class="meta-item">ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹: 8å€‹</span>
                <span class="meta-item">ğŸ“ æ¼”ç¿’å•é¡Œ: 5å•</span>
            </div>
        </div>
    </header>

    <main class="container">

<h2>å­¦ç¿’ç›®æ¨™</h2>
<p>ã“ã®ç« ã‚’èª­ã‚€ã“ã¨ã§ã€ä»¥ä¸‹ã‚’ç¿’å¾—ã§ãã¾ã™ï¼š</p>
<ul>
<li>âœ… ç•°å¸¸æ¤œçŸ¥ã®å®šç¾©ã¨ç¨®é¡ã‚’ç†è§£ã™ã‚‹</li>
<li>âœ… Point, Contextual, Collectiveç•°å¸¸ã‚’åŒºåˆ¥ã§ãã‚‹</li>
<li>âœ… ç•°å¸¸æ¤œçŸ¥ã®ã‚¿ã‚¹ã‚¯åˆ†é¡ã¨é¸æŠåŸºæº–ã‚’ç†è§£ã™ã‚‹</li>
<li>âœ… é©åˆ‡ãªè©•ä¾¡æŒ‡æ¨™ã‚’é¸æŠã§ãã‚‹</li>
<li>âœ… ä»£è¡¨çš„ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨å¯è¦–åŒ–æ‰‹æ³•ã‚’ä½¿ãˆã‚‹</li>
<li>âœ… ç•°å¸¸æ¤œçŸ¥ã®èª²é¡Œã¨å¯¾å‡¦æ³•ã‚’ç†è§£ã™ã‚‹</li>
</ul>

<hr>

<h2>1.1 ç•°å¸¸æ¤œçŸ¥ã¨ã¯</h2>

<h3>ç•°å¸¸ã®å®šç¾©</h3>
<p><strong>ç•°å¸¸æ¤œçŸ¥ï¼ˆAnomaly Detectionï¼‰</strong>ã¯ã€æ­£å¸¸ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ã‚‰å¤§ããé€¸è„±ã—ãŸãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆã‚’è­˜åˆ¥ã™ã‚‹ã‚¿ã‚¹ã‚¯ã§ã™ã€‚</p>

<blockquote>
<p>ã€Œç•°å¸¸ï¼ˆAnomalyï¼‰ã€ã¨ã¯ã€å¤šæ•°ã®æ­£å¸¸ãªãƒ‡ãƒ¼ã‚¿ã¨ã¯ç•°ãªã‚‹ã€ç¨€ã§äºˆæœŸã—ãªã„ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æŒã¤è¦³æ¸¬å€¤ã§ã™ã€‚</p>
</blockquote>

<h3>ç•°å¸¸ã®3ã¤ã®ã‚¿ã‚¤ãƒ—</h3>

<table>
<thead>
<tr>
<th>ã‚¿ã‚¤ãƒ—</th>
<th>èª¬æ˜</th>
<th>ä¾‹</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Point Anomaly</strong><br>ï¼ˆç‚¹ç•°å¸¸ï¼‰</td>
<td>å€‹åˆ¥ã®ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆãŒç•°å¸¸</td>
<td>ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆã‚«ãƒ¼ãƒ‰ã§çªç„¶ã®é«˜é¡æ±ºæ¸ˆ</td>
</tr>
<tr>
<td><strong>Contextual Anomaly</strong><br>ï¼ˆæ–‡è„ˆçš„ç•°å¸¸ï¼‰</td>
<td>ç‰¹å®šã®æ–‡è„ˆã§ã®ã¿ç•°å¸¸</td>
<td>å¤ã®æ°—æ¸©35â„ƒã¯æ­£å¸¸ã€å†¬ã¯ç•°å¸¸</td>
</tr>
<tr>
<td><strong>Collective Anomaly</strong><br>ï¼ˆé›†å›£ç•°å¸¸ï¼‰</td>
<td>ãƒ‡ãƒ¼ã‚¿ã®é›†åˆãŒç•°å¸¸ãƒ‘ã‚¿ãƒ¼ãƒ³</td>
<td>å¿ƒé›»å›³ã®ç•°å¸¸æ³¢å½¢ã®é€£ç¶š</td>
</tr>
</tbody>
</table>

<h3>ç•°å¸¸æ¤œçŸ¥ã®å¿œç”¨ä¾‹</h3>

<h4>1. ä¸æ­£æ¤œçŸ¥ï¼ˆFraud Detectionï¼‰</h4>
<ul>
<li>ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆã‚«ãƒ¼ãƒ‰è©æ¬ºã®æ¤œå‡º</li>
<li>ä¿é™ºé‡‘è«‹æ±‚ã®ä¸æ­£æ¤œçŸ¥</li>
<li>ãƒãƒãƒ¼ãƒ­ãƒ³ãƒ€ãƒªãƒ³ã‚°æ¤œçŸ¥</li>
</ul>

<h4>2. è£½é€ æ¥­ï¼ˆManufacturingï¼‰</h4>
<ul>
<li>è£½å“ã®ä¸è‰¯å“æ¤œå‡º</li>
<li>è¨­å‚™ã®æ•…éšœäºˆçŸ¥</li>
<li>å“è³ªç®¡ç†ã®ç•°å¸¸æ¤œçŸ¥</li>
</ul>

<h4>3. åŒ»ç™‚ï¼ˆHealthcareï¼‰</h4>
<ul>
<li>ç–¾ç—…ã®æ—©æœŸç™ºè¦‹</li>
<li>åŒ»ç™‚ç”»åƒã§ã®è…«ç˜æ¤œå‡º</li>
<li>ãƒã‚¤ã‚¿ãƒ«ã‚µã‚¤ãƒ³ã®ç•°å¸¸æ¤œçŸ¥</li>
</ul>

<h4>4. ITã‚·ã‚¹ãƒ†ãƒ ï¼ˆCybersecurity & Operationsï¼‰</h4>
<ul>
<li>ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ä¾µå…¥æ¤œçŸ¥</li>
<li>ã‚µãƒ¼ãƒãƒ¼éšœå®³ã®äºˆæ¸¬</li>
<li>ç•°å¸¸ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã®æ¤œå‡º</li>
</ul>

<h3>ç•°å¸¸æ¤œçŸ¥ã®ãƒ“ã‚¸ãƒã‚¹ä¾¡å€¤</h3>

<div class="mermaid">
graph LR
    A[ç•°å¸¸æ¤œçŸ¥] --> B[ã‚³ã‚¹ãƒˆå‰Šæ¸›]
    A --> C[ãƒªã‚¹ã‚¯ä½æ¸›]
    A --> D[åç›Šå‘ä¸Š]

    B --> B1[æ•…éšœå‰ã®äºˆé˜²ä¿å®ˆ]
    B --> B2[ä¸è‰¯å“ã®æ—©æœŸç™ºè¦‹]

    C --> C1[ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ä¾µå®³é˜²æ­¢]
    C --> C2[ä¸æ­£å–å¼•ã®é˜²æ­¢]

    D --> D1[ãƒ€ã‚¦ãƒ³ã‚¿ã‚¤ãƒ å‰Šæ¸›]
    D --> D2[é¡§å®¢æº€è¶³åº¦å‘ä¸Š]

    style A fill:#7b2cbf,color:#fff
    style B fill:#e8f5e9
    style C fill:#fff3e0
    style D fill:#e3f2fd
</div>

<h3>å®Ÿä¾‹ï¼šç•°å¸¸æ¤œçŸ¥ã®åŸºæœ¬</h3>

<pre><code class="language-python">import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import make_blobs

# æ­£å¸¸ãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆ
np.random.seed(42)
X_normal, _ = make_blobs(n_samples=300, centers=1,
                         cluster_std=1.0, center_box=(0, 0))

# ç•°å¸¸ãƒ‡ãƒ¼ã‚¿ã®è¿½åŠ ï¼ˆ3ç¨®é¡ï¼‰
# 1. Point Anomaly: é›¢ã‚ŒãŸç‚¹
point_anomalies = np.array([[8, 8], [-8, -8], [8, -8]])

# 2. Contextual Anomaly: æ­£å¸¸ç¯„å›²ã ãŒæ–‡è„ˆçš„ã«ç•°å¸¸
# ï¼ˆä¾‹ï¼šæ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã§ã®å­£ç¯€å¤–ã‚Œã®å€¤ï¼‰
contextual_anomalies = np.array([[2, 2], [-2, -2]])

# 3. Collective Anomaly: é›†å›£ã¨ã—ã¦ç•°å¸¸
collective_anomalies = np.random.normal(loc=[5, 5], scale=0.3, size=(10, 2))

# å…¨ãƒ‡ãƒ¼ã‚¿ã®çµåˆ
X_all = np.vstack([X_normal, point_anomalies,
                   contextual_anomalies, collective_anomalies])

# å¯è¦–åŒ–
plt.figure(figsize=(12, 8))

plt.scatter(X_normal[:, 0], X_normal[:, 1],
            c='blue', alpha=0.5, s=50, label='æ­£å¸¸ãƒ‡ãƒ¼ã‚¿', edgecolors='black')
plt.scatter(point_anomalies[:, 0], point_anomalies[:, 1],
            c='red', s=200, marker='X', label='Point Anomaly',
            edgecolors='black', linewidths=2)
plt.scatter(contextual_anomalies[:, 0], contextual_anomalies[:, 1],
            c='orange', s=200, marker='s', label='Contextual Anomaly',
            edgecolors='black', linewidths=2)
plt.scatter(collective_anomalies[:, 0], collective_anomalies[:, 1],
            c='purple', s=100, marker='^', label='Collective Anomaly',
            edgecolors='black', linewidths=2)

plt.xlabel('ç‰¹å¾´é‡ 1', fontsize=12)
plt.ylabel('ç‰¹å¾´é‡ 2', fontsize=12)
plt.title('ç•°å¸¸ã®3ã¤ã®ã‚¿ã‚¤ãƒ—', fontsize=14, fontweight='bold')
plt.legend(fontsize=10)
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()

print("=== ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆ ===")
print(f"æ­£å¸¸ãƒ‡ãƒ¼ã‚¿: {len(X_normal)}å€‹")
print(f"Point Anomaly: {len(point_anomalies)}å€‹")
print(f"Contextual Anomaly: {len(contextual_anomalies)}å€‹")
print(f"Collective Anomaly: {len(collective_anomalies)}å€‹")
print(f"ç•°å¸¸ç‡: {(len(point_anomalies) + len(contextual_anomalies) + len(collective_anomalies)) / len(X_all) * 100:.1f}%")
</code></pre>

<blockquote>
<p><strong>é‡è¦</strong>: ç•°å¸¸æ¤œçŸ¥ã§ã¯ã€æ­£å¸¸ãƒ‡ãƒ¼ã‚¿ãŒå¤§å¤šæ•°ã‚’å ã‚ã€ç•°å¸¸ãƒ‡ãƒ¼ã‚¿ã¯å°‘æ•°ï¼ˆé€šå¸¸1-5%ï¼‰ã§ã™ã€‚</p>
</blockquote>

<hr>

<h2>1.2 ç•°å¸¸æ¤œçŸ¥ã®ã‚¿ã‚¹ã‚¯åˆ†é¡</h2>

<h3>1. å­¦ç¿’æ–¹æ³•ã«ã‚ˆã‚‹åˆ†é¡</h3>

<table>
<thead>
<tr>
<th>ã‚¿ã‚¤ãƒ—</th>
<th>ãƒ©ãƒ™ãƒ«æƒ…å ±</th>
<th>ä½¿ç”¨å ´é¢</th>
<th>ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ä¾‹</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>æ•™å¸«ã‚ã‚Šå­¦ç¿’</strong><br>(Supervised)</td>
<td>æ­£å¸¸ãƒ»ç•°å¸¸ãƒ©ãƒ™ãƒ«ä¸¡æ–¹</td>
<td>ãƒ©ãƒ™ãƒ«ä»˜ããƒ‡ãƒ¼ã‚¿ãŒè±Šå¯Œ</td>
<td>Random Forest, SVM</td>
</tr>
<tr>
<td><strong>åŠæ•™å¸«ã‚ã‚Šå­¦ç¿’</strong><br>(Semi-supervised)</td>
<td>æ­£å¸¸ãƒ©ãƒ™ãƒ«ã®ã¿</td>
<td>æ­£å¸¸ãƒ‡ãƒ¼ã‚¿ã®ã¿ãƒ©ãƒ™ãƒ«åŒ–</td>
<td>One-Class SVM, Autoencoder</td>
</tr>
<tr>
<td><strong>æ•™å¸«ãªã—å­¦ç¿’</strong><br>(Unsupervised)</td>
<td>ãƒ©ãƒ™ãƒ«ãªã—</td>
<td>ãƒ©ãƒ™ãƒ«å–å¾—ãŒå›°é›£</td>
<td>Isolation Forest, LOF, DBSCAN</td>
</tr>
</tbody>
</table>

<h3>2. Novelty Detection vs Outlier Detection</h3>

<table>
<thead>
<tr>
<th>ã‚¿ã‚¤ãƒ—</th>
<th>è¨“ç·´ãƒ‡ãƒ¼ã‚¿</th>
<th>ç›®çš„</th>
<th>ä¾‹</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Novelty Detection</strong><br>ï¼ˆæ–°è¦æ€§æ¤œçŸ¥ï¼‰</td>
<td>æ­£å¸¸ãƒ‡ãƒ¼ã‚¿ã®ã¿</td>
<td>æ–°ã—ã„ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¤œå‡º</td>
<td>æ–°ç¨®ã®ãƒãƒ«ã‚¦ã‚§ã‚¢æ¤œå‡º</td>
</tr>
<tr>
<td><strong>Outlier Detection</strong><br>ï¼ˆå¤–ã‚Œå€¤æ¤œå‡ºï¼‰</td>
<td>æ­£å¸¸+ç•°å¸¸æ··åœ¨</td>
<td>æ—¢å­˜ãƒ‡ãƒ¼ã‚¿å†…ã®ç•°å¸¸æ¤œå‡º</td>
<td>ã‚»ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿ã®ãƒã‚¤ã‚ºé™¤å»</td>
</tr>
</tbody>
</table>

<h3>3. Online vs Offline Detection</h3>

<table>
<thead>
<tr>
<th>ã‚¿ã‚¤ãƒ—</th>
<th>å‡¦ç†ã‚¿ã‚¤ãƒŸãƒ³ã‚°</th>
<th>ç‰¹å¾´</th>
<th>å¿œç”¨ä¾‹</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Online Detection</strong><br>ï¼ˆãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ï¼‰</td>
<td>ãƒ‡ãƒ¼ã‚¿åˆ°ç€æ™‚</td>
<td>ä½é…å»¶ã€é€æ¬¡æ›´æ–°</td>
<td>ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ä¾µå…¥æ¤œçŸ¥</td>
</tr>
<tr>
<td><strong>Offline Detection</strong><br>ï¼ˆãƒãƒƒãƒå‡¦ç†ï¼‰</td>
<td>ä¸€æ‹¬å‡¦ç†</td>
<td>é«˜ç²¾åº¦ã€å…¨ä½“æœ€é©åŒ–</td>
<td>æœˆæ¬¡ãƒ¬ãƒãƒ¼ãƒˆã®ç•°å¸¸åˆ†æ</td>
</tr>
</tbody>
</table>

<h3>ã‚¿ã‚¹ã‚¯é¸æŠã®æ±ºå®šãƒ•ãƒ­ãƒ¼</h3>

<div class="mermaid">
graph TD
    A[ç•°å¸¸æ¤œçŸ¥ã‚¿ã‚¹ã‚¯è¨­è¨ˆ] --> B{ãƒ©ãƒ™ãƒ«ãƒ‡ãƒ¼ã‚¿ã¯ã‚ã‚‹?}
    B -->|ä¸¡æ–¹ã‚ã‚‹| C[æ•™å¸«ã‚ã‚Šå­¦ç¿’]
    B -->|æ­£å¸¸ã®ã¿| D[åŠæ•™å¸«ã‚ã‚Šå­¦ç¿’ / Novelty Detection]
    B -->|ãªã—| E[æ•™å¸«ãªã—å­¦ç¿’ / Outlier Detection]

    C --> F{ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ?}
    D --> F
    E --> F

    F -->|Yes| G[Online Detection]
    F -->|No| H[Offline Detection]

    G --> I[æ‰‹æ³•é¸æŠ]
    H --> I

    style A fill:#7b2cbf,color:#fff
    style C fill:#e8f5e9
    style D fill:#fff3e0
    style E fill:#ffebee
    style G fill:#e3f2fd
    style H fill:#f3e5f5
</div>

<h3>å®Ÿä¾‹ï¼š3ã¤ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã®æ¯”è¼ƒ</h3>

<pre><code class="language-python">import numpy as np
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import OneClassSVM
from sklearn.ensemble import IsolationForest
from sklearn.metrics import classification_report, accuracy_score

# ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆï¼ˆä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿ï¼‰
np.random.seed(42)
X, y = make_classification(n_samples=1000, n_features=10, n_informative=8,
                           n_redundant=2, n_classes=2, weights=[0.95, 0.05],
                           flip_y=0, random_state=42)

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42, stratify=y
)

print("=== ãƒ‡ãƒ¼ã‚¿åˆ†å¸ƒ ===")
print(f"è¨“ç·´ãƒ‡ãƒ¼ã‚¿: {len(y_train)}å€‹ (æ­£å¸¸: {(y_train==0).sum()}, ç•°å¸¸: {(y_train==1).sum()})")
print(f"ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {len(y_test)}å€‹ (æ­£å¸¸: {(y_test==0).sum()}, ç•°å¸¸: {(y_test==1).sum()})")

# 1. æ•™å¸«ã‚ã‚Šå­¦ç¿’ï¼ˆãƒ©ãƒ™ãƒ«ã‚ã‚Šï¼‰
print("\n=== 1. æ•™å¸«ã‚ã‚Šå­¦ç¿’ (Supervised) ===")
clf_supervised = RandomForestClassifier(n_estimators=100, random_state=42)
clf_supervised.fit(X_train, y_train)
y_pred_supervised = clf_supervised.predict(X_test)
acc_supervised = accuracy_score(y_test, y_pred_supervised)
print(f"ç²¾åº¦: {acc_supervised:.3f}")
print(classification_report(y_test, y_pred_supervised, target_names=['æ­£å¸¸', 'ç•°å¸¸']))

# 2. åŠæ•™å¸«ã‚ã‚Šå­¦ç¿’ï¼ˆæ­£å¸¸ãƒ‡ãƒ¼ã‚¿ã®ã¿ã§è¨“ç·´ï¼‰
print("\n=== 2. åŠæ•™å¸«ã‚ã‚Šå­¦ç¿’ (Semi-supervised / Novelty Detection) ===")
X_train_normal = X_train[y_train == 0]  # æ­£å¸¸ãƒ‡ãƒ¼ã‚¿ã®ã¿
clf_novelty = OneClassSVM(nu=0.05, kernel='rbf', gamma='auto')
clf_novelty.fit(X_train_normal)
y_pred_novelty = clf_novelty.predict(X_test)
# One-Class SVMã®å‡ºåŠ›: 1=æ­£å¸¸, -1=ç•°å¸¸ â†’ 0=æ­£å¸¸, 1=ç•°å¸¸ã«å¤‰æ›
y_pred_novelty = (y_pred_novelty == -1).astype(int)
acc_novelty = accuracy_score(y_test, y_pred_novelty)
print(f"ç²¾åº¦: {acc_novelty:.3f}")
print(classification_report(y_test, y_pred_novelty, target_names=['æ­£å¸¸', 'ç•°å¸¸']))

# 3. æ•™å¸«ãªã—å­¦ç¿’ï¼ˆãƒ©ãƒ™ãƒ«ãªã—ï¼‰
print("\n=== 3. æ•™å¸«ãªã—å­¦ç¿’ (Unsupervised / Outlier Detection) ===")
clf_unsupervised = IsolationForest(contamination=0.05, random_state=42)
clf_unsupervised.fit(X_train)
y_pred_unsupervised = clf_unsupervised.predict(X_test)
# Isolation Forestã®å‡ºåŠ›: 1=æ­£å¸¸, -1=ç•°å¸¸ â†’ 0=æ­£å¸¸, 1=ç•°å¸¸ã«å¤‰æ›
y_pred_unsupervised = (y_pred_unsupervised == -1).astype(int)
acc_unsupervised = accuracy_score(y_test, y_pred_unsupervised)
print(f"ç²¾åº¦: {acc_unsupervised:.3f}")
print(classification_report(y_test, y_pred_unsupervised, target_names=['æ­£å¸¸', 'ç•°å¸¸']))

# æ¯”è¼ƒã‚µãƒãƒª
print("\n=== ç²¾åº¦æ¯”è¼ƒ ===")
print(f"æ•™å¸«ã‚ã‚Šå­¦ç¿’:   {acc_supervised:.3f}")
print(f"åŠæ•™å¸«ã‚ã‚Šå­¦ç¿’: {acc_novelty:.3f}")
print(f"æ•™å¸«ãªã—å­¦ç¿’:   {acc_unsupervised:.3f}")
</code></pre>

<blockquote>
<p><strong>é‡è¦</strong>: æ•™å¸«ã‚ã‚Šå­¦ç¿’ãŒæœ€ã‚‚é«˜ç²¾åº¦ã§ã™ãŒã€ãƒ©ãƒ™ãƒ«ä»˜ããƒ‡ãƒ¼ã‚¿ãŒå¿…è¦ã§ã™ã€‚å®Ÿéš›ã®ãƒ“ã‚¸ãƒã‚¹ã§ã¯ã€ãƒ©ãƒ™ãƒ«å–å¾—ã‚³ã‚¹ãƒˆã‚’è€ƒæ…®ã—ã¦æ‰‹æ³•ã‚’é¸æŠã—ã¾ã™ã€‚</p>
</blockquote>

<hr>

<h2>1.3 è©•ä¾¡æŒ‡æ¨™</h2>

<h3>ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡å•é¡Œ</h3>

<p>ç•°å¸¸æ¤œçŸ¥ã§ã¯ã€æ­£å¸¸ãƒ‡ãƒ¼ã‚¿ãŒåœ§å€’çš„ã«å¤šã„ãŸã‚ã€ç²¾åº¦ï¼ˆAccuracyï¼‰ã ã‘ã§ã¯ä¸ååˆ†ã§ã™ã€‚</p>

<pre><code class="language-python">import numpy as np
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# ä¾‹ï¼šæ­£å¸¸95%, ç•°å¸¸5%ã®ãƒ‡ãƒ¼ã‚¿
y_true = np.array([0]*95 + [1]*5)

# ãƒ€ãƒ¡ãªäºˆæ¸¬å™¨ï¼šå…¨ã¦æ­£å¸¸ã¨äºˆæ¸¬
y_pred_bad = np.array([0]*100)

# è‰¯ã„äºˆæ¸¬å™¨ï¼šç•°å¸¸ã‚’æ­£ã—ãæ¤œå‡º
y_pred_good = np.concatenate([np.array([0]*95), np.array([1]*5)])

print("=== ãƒ€ãƒ¡ãªäºˆæ¸¬å™¨ï¼ˆå…¨ã¦æ­£å¸¸ã¨äºˆæ¸¬ï¼‰===")
print(f"ç²¾åº¦: {accuracy_score(y_true, y_pred_bad):.3f}")
print(f"Precision: {precision_score(y_true, y_pred_bad, zero_division=0):.3f}")
print(f"Recall: {recall_score(y_true, y_pred_bad, zero_division=0):.3f}")
print(f"F1: {f1_score(y_true, y_pred_bad, zero_division=0):.3f}")

print("\n=== è‰¯ã„äºˆæ¸¬å™¨ï¼ˆç•°å¸¸ã‚’æ­£ã—ãæ¤œå‡ºï¼‰===")
print(f"ç²¾åº¦: {accuracy_score(y_true, y_pred_good):.3f}")
print(f"Precision: {precision_score(y_true, y_pred_good):.3f}")
print(f"Recall: {recall_score(y_true, y_pred_good):.3f}")
print(f"F1: {f1_score(y_true, y_pred_good):.3f}")
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>=== ãƒ€ãƒ¡ãªäºˆæ¸¬å™¨ï¼ˆå…¨ã¦æ­£å¸¸ã¨äºˆæ¸¬ï¼‰===
ç²¾åº¦: 0.950
Precision: 0.000
Recall: 0.000
F1: 0.000

=== è‰¯ã„äºˆæ¸¬å™¨ï¼ˆç•°å¸¸ã‚’æ­£ã—ãæ¤œå‡ºï¼‰===
ç²¾åº¦: 1.000
Precision: 1.000
Recall: 1.000
F1: 1.000
</code></pre>

<blockquote>
<p><strong>æ•™è¨“</strong>: ç²¾åº¦95%ã§ã‚‚ã€ç•°å¸¸ã‚’1ã¤ã‚‚æ¤œå‡ºã§ãã¦ã„ãªã„å ´åˆãŒã‚ã‚Šã¾ã™ã€‚</p>
</blockquote>

<h3>æ··åŒè¡Œåˆ—ã¨ä¸»è¦æŒ‡æ¨™</h3>

<table>
<thead>
<tr>
<th>æŒ‡æ¨™</th>
<th>è¨ˆç®—å¼</th>
<th>æ„å‘³</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Precisionï¼ˆé©åˆç‡ï¼‰</strong></td>
<td>$\frac{TP}{TP + FP}$</td>
<td>ç•°å¸¸ã¨äºˆæ¸¬ã—ãŸã†ã¡å®Ÿéš›ã«ç•°å¸¸ã®å‰²åˆ</td>
</tr>
<tr>
<td><strong>Recallï¼ˆå†ç¾ç‡ï¼‰</strong></td>
<td>$\frac{TP}{TP + FN}$</td>
<td>å®Ÿéš›ã®ç•°å¸¸ã®ã†ã¡æ¤œå‡ºã§ããŸå‰²åˆ</td>
</tr>
<tr>
<td><strong>F1 Score</strong></td>
<td>$2 \cdot \frac{P \cdot R}{P + R}$</td>
<td>Precisionã¨Recallã®èª¿å’Œå¹³å‡</td>
</tr>
<tr>
<td><strong>ROC-AUC</strong></td>
<td>ROCæ›²ç·šä¸‹ã®é¢ç©</td>
<td>é–¾å€¤ã«ä¾å­˜ã—ãªã„ç·åˆæ€§èƒ½</td>
</tr>
<tr>
<td><strong>PR-AUC</strong></td>
<td>PRæ›²ç·šä¸‹ã®é¢ç©</td>
<td>ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿ã§ã®ROC-AUCã‚ˆã‚Šé©åˆ‡</td>
</tr>
</tbody>
</table>

<h3>ROC-AUC vs PR-AUC</h3>

<pre><code class="language-python">import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import make_classification
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score

# ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆ
X, y = make_classification(n_samples=1000, n_features=20, n_informative=15,
                           n_redundant=5, n_classes=2, weights=[0.95, 0.05],
                           random_state=42)

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42, stratify=y
)

# ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´
clf = RandomForestClassifier(n_estimators=100, random_state=42)
clf.fit(X_train, y_train)

# äºˆæ¸¬ç¢ºç‡ã®å–å¾—
y_scores = clf.predict_proba(X_test)[:, 1]

# ROCæ›²ç·š
fpr, tpr, _ = roc_curve(y_test, y_scores)
roc_auc = auc(fpr, tpr)

# PRæ›²ç·š
precision, recall, _ = precision_recall_curve(y_test, y_scores)
pr_auc = average_precision_score(y_test, y_scores)

# å¯è¦–åŒ–
fig, axes = plt.subplots(1, 2, figsize=(14, 6))

# ROCæ›²ç·š
axes[0].plot(fpr, tpr, color='blue', lw=2,
             label=f'ROCæ›²ç·š (AUC = {roc_auc:.3f})')
axes[0].plot([0, 1], [0, 1], color='gray', lw=1, linestyle='--',
             label='ãƒ©ãƒ³ãƒ€ãƒ äºˆæ¸¬')
axes[0].set_xlabel('False Positive Rate', fontsize=12)
axes[0].set_ylabel('True Positive Rate', fontsize=12)
axes[0].set_title('ROCæ›²ç·š', fontsize=14, fontweight='bold')
axes[0].legend(fontsize=10)
axes[0].grid(True, alpha=0.3)

# PRæ›²ç·š
axes[1].plot(recall, precision, color='green', lw=2,
             label=f'PRæ›²ç·š (AUC = {pr_auc:.3f})')
baseline = (y_test == 1).sum() / len(y_test)
axes[1].axhline(y=baseline, color='gray', lw=1, linestyle='--',
                label=f'ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ ({baseline:.3f})')
axes[1].set_xlabel('Recall', fontsize=12)
axes[1].set_ylabel('Precision', fontsize=12)
axes[1].set_title('Precision-Recallæ›²ç·š', fontsize=14, fontweight='bold')
axes[1].legend(fontsize=10)
axes[1].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

print("=== è©•ä¾¡æŒ‡æ¨™ ===")
print(f"ROC-AUC: {roc_auc:.3f}")
print(f"PR-AUC: {pr_auc:.3f}")
print(f"ç•°å¸¸ãƒ‡ãƒ¼ã‚¿ã®å‰²åˆ: {baseline:.3f}")
</code></pre>

<blockquote>
<p><strong>é‡è¦</strong>: ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿ã§ã¯ã€PR-AUCãŒROC-AUCã‚ˆã‚Šé©åˆ‡ãªæŒ‡æ¨™ã§ã™ã€‚ROC-AUCã¯æ­£å¸¸ãƒ‡ãƒ¼ã‚¿ãŒå¤šã„ãŸã‚æ¥½è¦³çš„ã«ãªã‚ŠãŒã¡ã§ã™ã€‚</p>
</blockquote>

<h3>ãƒ‰ãƒ¡ã‚¤ãƒ³ç‰¹åŒ–è©•ä¾¡æŒ‡æ¨™</h3>

<table>
<thead>
<tr>
<th>ãƒ‰ãƒ¡ã‚¤ãƒ³</th>
<th>é‡è¦–ã™ã‚‹æŒ‡æ¨™</th>
<th>ç†ç”±</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>åŒ»ç™‚è¨ºæ–­</strong></td>
<td>Recallï¼ˆé«˜ï¼‰</td>
<td>è¦‹é€ƒã—ã‚’æœ€å°åŒ–ï¼ˆFNå‰Šæ¸›ï¼‰</td>
</tr>
<tr>
<td><strong>ã‚¹ãƒ‘ãƒ ãƒ•ã‚£ãƒ«ã‚¿</strong></td>
<td>Precisionï¼ˆé«˜ï¼‰</td>
<td>èª¤æ¤œå‡ºã‚’æœ€å°åŒ–ï¼ˆFPå‰Šæ¸›ï¼‰</td>
</tr>
<tr>
<td><strong>ä¸æ­£æ¤œçŸ¥</strong></td>
<td>F1, PR-AUC</td>
<td>ãƒãƒ©ãƒ³ã‚¹é‡è¦–</td>
</tr>
<tr>
<td><strong>äºˆé˜²ä¿å®ˆ</strong></td>
<td>Recallï¼ˆé«˜ï¼‰</td>
<td>æ•…éšœã®è¦‹é€ƒã—é˜²æ­¢</td>
</tr>
</tbody>
</table>

<hr>

<h2>1.4 ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨å¯è¦–åŒ–</h2>

<h3>Synthetic Datasetsï¼ˆåˆæˆãƒ‡ãƒ¼ã‚¿ï¼‰</h3>

<pre><code class="language-python">import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import make_blobs, make_moons
from scipy.stats import multivariate_normal

np.random.seed(42)

# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ1: ã‚¬ã‚¦ã‚¹åˆ†å¸ƒ
X_gaussian, _ = make_blobs(n_samples=300, centers=1, cluster_std=1.0,
                           center_box=(0, 0), random_state=42)
outliers_gaussian = np.random.uniform(low=-8, high=8, size=(15, 2))
X1 = np.vstack([X_gaussian, outliers_gaussian])
y1 = np.array([0]*300 + [1]*15)

# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ2: ä¸‰æ—¥æœˆå‹
X_moons, _ = make_moons(n_samples=300, noise=0.05, random_state=42)
outliers_moons = np.random.uniform(low=-2, high=3, size=(15, 2))
X2 = np.vstack([X_moons, outliers_moons])
y2 = np.array([0]*300 + [1]*15)

# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ3: ãƒ‰ãƒ¼ãƒŠãƒ„å‹
theta = np.linspace(0, 2*np.pi, 300)
r = 3 + np.random.normal(0, 0.3, 300)
X_donut = np.column_stack([r * np.cos(theta), r * np.sin(theta)])
outliers_donut = np.random.normal(0, 1, size=(15, 2))
X3 = np.vstack([X_donut, outliers_donut])
y3 = np.array([0]*300 + [1]*15)

# å¯è¦–åŒ–
fig, axes = plt.subplots(1, 3, figsize=(16, 5))

datasets = [
    (X1, y1, 'ã‚¬ã‚¦ã‚¹åˆ†å¸ƒ'),
    (X2, y2, 'ä¸‰æ—¥æœˆå‹'),
    (X3, y3, 'ãƒ‰ãƒ¼ãƒŠãƒ„å‹')
]

for ax, (X, y, title) in zip(axes, datasets):
    ax.scatter(X[y==0, 0], X[y==0, 1], c='blue', alpha=0.6,
               s=50, label='æ­£å¸¸', edgecolors='black')
    ax.scatter(X[y==1, 0], X[y==1, 1], c='red', alpha=0.9,
               s=150, marker='X', label='ç•°å¸¸', edgecolors='black', linewidths=2)
    ax.set_xlabel('ç‰¹å¾´é‡ 1', fontsize=11)
    ax.set_ylabel('ç‰¹å¾´é‡ 2', fontsize=11)
    ax.set_title(title, fontsize=13, fontweight='bold')
    ax.legend(fontsize=10)
    ax.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

print("=== Synthetic Datasetsã®ç‰¹å¾´ ===")
print("1. ã‚¬ã‚¦ã‚¹åˆ†å¸ƒ: ç·šå½¢åˆ†é›¢å¯èƒ½ã€çµ±è¨ˆçš„æ‰‹æ³•ã«é©åˆ")
print("2. ä¸‰æ—¥æœˆå‹: éç·šå½¢ãƒ‘ã‚¿ãƒ¼ãƒ³ã€å¢ƒç•ŒãŒè¤‡é›‘")
print("3. ãƒ‰ãƒ¼ãƒŠãƒ„å‹: å¯†åº¦ãƒ™ãƒ¼ã‚¹ã®æ‰‹æ³•ãŒæœ‰åŠ¹")
</code></pre>

<h3>Real-world Datasets</h3>

<table>
<thead>
<tr>
<th>ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ</th>
<th>ãƒ‰ãƒ¡ã‚¤ãƒ³</th>
<th>ã‚µãƒ³ãƒ—ãƒ«æ•°</th>
<th>ç•°å¸¸ç‡</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Credit Card Fraud</strong></td>
<td>é‡‘è</td>
<td>284,807</td>
<td>0.17%</td>
</tr>
<tr>
<td><strong>KDD Cup 99</strong></td>
<td>ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯</td>
<td>4,898,431</td>
<td>19.7%</td>
</tr>
<tr>
<td><strong>MNIST (ç•°å¸¸æ¤œçŸ¥ç‰ˆ)</strong></td>
<td>ç”»åƒ</td>
<td>70,000</td>
<td>å¯å¤‰</td>
</tr>
<tr>
<td><strong>Thyroid Disease</strong></td>
<td>åŒ»ç™‚</td>
<td>3,772</td>
<td>2.5%</td>
</tr>
<tr>
<td><strong>NASA Bearing</strong></td>
<td>è£½é€ </td>
<td>æ™‚ç³»åˆ—</td>
<td>å¯å¤‰</td>
</tr>
</tbody>
</table>

<h3>å¯è¦–åŒ–æ‰‹æ³•</h3>

<h4>1. æ¬¡å…ƒå‰Šæ¸›ã«ã‚ˆã‚‹å¯è¦–åŒ–</h4>

<pre><code class="language-python">import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import make_classification
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE

# é«˜æ¬¡å…ƒãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆï¼ˆ20æ¬¡å…ƒï¼‰
X, y = make_classification(n_samples=500, n_features=20, n_informative=15,
                           n_redundant=5, n_classes=2, weights=[0.95, 0.05],
                           random_state=42)

# PCAã«ã‚ˆã‚‹æ¬¡å…ƒå‰Šæ¸›
pca = PCA(n_components=2, random_state=42)
X_pca = pca.fit_transform(X)

# t-SNEã«ã‚ˆã‚‹æ¬¡å…ƒå‰Šæ¸›
tsne = TSNE(n_components=2, random_state=42, perplexity=30)
X_tsne = tsne.fit_transform(X)

# å¯è¦–åŒ–
fig, axes = plt.subplots(1, 2, figsize=(14, 6))

# PCA
axes[0].scatter(X_pca[y==0, 0], X_pca[y==0, 1], c='blue', alpha=0.6,
                s=50, label='æ­£å¸¸', edgecolors='black')
axes[0].scatter(X_pca[y==1, 0], X_pca[y==1, 1], c='red', alpha=0.9,
                s=150, marker='X', label='ç•°å¸¸', edgecolors='black', linewidths=2)
axes[0].set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%})', fontsize=12)
axes[0].set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%})', fontsize=12)
axes[0].set_title('PCAå¯è¦–åŒ–', fontsize=14, fontweight='bold')
axes[0].legend(fontsize=10)
axes[0].grid(True, alpha=0.3)

# t-SNE
axes[1].scatter(X_tsne[y==0, 0], X_tsne[y==0, 1], c='blue', alpha=0.6,
                s=50, label='æ­£å¸¸', edgecolors='black')
axes[1].scatter(X_tsne[y==1, 0], X_tsne[y==1, 1], c='red', alpha=0.9,
                s=150, marker='X', label='ç•°å¸¸', edgecolors='black', linewidths=2)
axes[1].set_xlabel('t-SNE 1', fontsize=12)
axes[1].set_ylabel('t-SNE 2', fontsize=12)
axes[1].set_title('t-SNEå¯è¦–åŒ–', fontsize=14, fontweight='bold')
axes[1].legend(fontsize=10)
axes[1].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

print("=== æ¬¡å…ƒå‰Šæ¸›ã®æ¯”è¼ƒ ===")
print(f"PCAç´¯ç©å¯„ä¸ç‡ï¼ˆ2æˆåˆ†ï¼‰: {pca.explained_variance_ratio_.sum():.2%}")
print("t-SNE: éç·šå½¢æ§‹é€ ã®ä¿æŒã«å„ªã‚Œã‚‹ï¼ˆå±€æ‰€æ§‹é€ é‡è¦–ï¼‰")
</code></pre>

<h4>2. ç•°å¸¸ã‚¹ã‚³ã‚¢ã®å¯è¦–åŒ–</h4>

<pre><code class="language-python">import numpy as np
import matplotlib.pyplot as plt
from sklearn.ensemble import IsolationForest
from sklearn.datasets import make_blobs

# ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
np.random.seed(42)
X_normal, _ = make_blobs(n_samples=300, centers=1, cluster_std=1.0,
                         center_box=(0, 0), random_state=42)
X_outliers = np.random.uniform(low=-8, high=8, size=(15, 2))
X = np.vstack([X_normal, X_outliers])

# Isolation Forestã§ç•°å¸¸ã‚¹ã‚³ã‚¢è¨ˆç®—
clf = IsolationForest(contamination=0.05, random_state=42)
clf.fit(X)
anomaly_scores = -clf.score_samples(X)  # è² ã®å€¤ã‚’æ­£ã«å¤‰æ›

# ã‚°ãƒªãƒƒãƒ‰ä¸Šã§ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ï¼ˆãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ç”¨ï¼‰
xx, yy = np.meshgrid(np.linspace(-10, 10, 200), np.linspace(-10, 10, 200))
Z = -clf.score_samples(np.c_[xx.ravel(), yy.ravel()])
Z = Z.reshape(xx.shape)

# å¯è¦–åŒ–
fig, axes = plt.subplots(1, 2, figsize=(15, 6))

# ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—
contour = axes[0].contourf(xx, yy, Z, levels=20, cmap='RdYlBu_r', alpha=0.7)
axes[0].scatter(X[:, 0], X[:, 1], c=anomaly_scores, cmap='RdYlBu_r',
                s=50, edgecolors='black', linewidths=1)
plt.colorbar(contour, ax=axes[0], label='ç•°å¸¸ã‚¹ã‚³ã‚¢')
axes[0].set_xlabel('ç‰¹å¾´é‡ 1', fontsize=12)
axes[0].set_ylabel('ç‰¹å¾´é‡ 2', fontsize=12)
axes[0].set_title('ç•°å¸¸ã‚¹ã‚³ã‚¢ã®ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—', fontsize=14, fontweight='bold')
axes[0].grid(True, alpha=0.3)

# ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ 
axes[1].hist(anomaly_scores, bins=30, alpha=0.7, edgecolor='black', color='steelblue')
axes[1].axvline(x=np.percentile(anomaly_scores, 95), color='red',
                linestyle='--', linewidth=2, label='95%ç‚¹ï¼ˆé–¾å€¤ï¼‰')
axes[1].set_xlabel('ç•°å¸¸ã‚¹ã‚³ã‚¢', fontsize=12)
axes[1].set_ylabel('é »åº¦', fontsize=12)
axes[1].set_title('ç•°å¸¸ã‚¹ã‚³ã‚¢ã®åˆ†å¸ƒ', fontsize=14, fontweight='bold')
axes[1].legend(fontsize=10)
axes[1].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

print("=== ç•°å¸¸ã‚¹ã‚³ã‚¢çµ±è¨ˆ ===")
print(f"æœ€å°å€¤: {anomaly_scores.min():.3f}")
print(f"æœ€å¤§å€¤: {anomaly_scores.max():.3f}")
print(f"å¹³å‡: {anomaly_scores.mean():.3f}")
print(f"95%ç‚¹ï¼ˆé–¾å€¤å€™è£œï¼‰: {np.percentile(anomaly_scores, 95):.3f}")
</code></pre>

<hr>

<h2>1.5 ç•°å¸¸æ¤œçŸ¥ã®èª²é¡Œ</h2>

<h3>1. Label Scarcityï¼ˆãƒ©ãƒ™ãƒ«ä¸è¶³ï¼‰</h3>

<p><strong>å•é¡Œ</strong>: ç•°å¸¸ãƒ‡ãƒ¼ã‚¿ã®ãƒ©ãƒ™ãƒ«ä»˜ã‘ã¯é«˜ã‚³ã‚¹ãƒˆã§å›°é›£</p>

<p><strong>å¯¾å‡¦æ³•</strong>:</p>
<ul>
<li>æ•™å¸«ãªã—å­¦ç¿’ï¼ˆIsolation Forest, LOFï¼‰</li>
<li>åŠæ•™å¸«ã‚ã‚Šå­¦ç¿’ï¼ˆOne-Class SVM, Autoencoderï¼‰</li>
<li>Active Learningï¼ˆé‡è¦ã‚µãƒ³ãƒ—ãƒ«ã®ã¿ãƒ©ãƒ™ãƒ«ä»˜ã‘ï¼‰</li>
<li>Weak Supervisionï¼ˆãƒã‚¤ã‚ºãƒ©ãƒ™ãƒ«ã®æ´»ç”¨ï¼‰</li>
</ul>

<h3>2. High Dimensionalityï¼ˆé«˜æ¬¡å…ƒæ€§ï¼‰</h3>

<p><strong>å•é¡Œ</strong>: æ¬¡å…ƒã®å‘ªã„ï¼ˆè·é›¢ãŒæ„å‘³ã‚’å¤±ã†ï¼‰</p>

<p><strong>å¯¾å‡¦æ³•</strong>:</p>
<ul>
<li>æ¬¡å…ƒå‰Šæ¸›ï¼ˆPCA, Autoencoderï¼‰</li>
<li>ç‰¹å¾´é¸æŠï¼ˆé‡è¦ç‰¹å¾´é‡ã®ã¿ä½¿ç”¨ï¼‰</li>
<li>éƒ¨åˆ†ç©ºé–“æ³•ï¼ˆSubspace methodsï¼‰</li>
</ul>

<pre><code class="language-python">import numpy as np
import matplotlib.pyplot as plt
from scipy.spatial.distance import pdist

# æ¬¡å…ƒã®å‘ªã„ã®å®Ÿé¨“
dimensions = [2, 5, 10, 20, 50, 100, 200]
avg_distances = []

np.random.seed(42)
for d in dimensions:
    # ãƒ©ãƒ³ãƒ€ãƒ ãªç‚¹ã‚’ç”Ÿæˆ
    X = np.random.uniform(0, 1, size=(100, d))
    # å…¨ãƒšã‚¢é–“ã®è·é›¢ã‚’è¨ˆç®—
    distances = pdist(X, metric='euclidean')
    avg_distances.append(distances.mean())

# å¯è¦–åŒ–
plt.figure(figsize=(10, 6))
plt.plot(dimensions, avg_distances, marker='o', linewidth=2, markersize=8)
plt.xlabel('æ¬¡å…ƒæ•°', fontsize=12)
plt.ylabel('å¹³å‡ãƒ¦ãƒ¼ã‚¯ãƒªãƒƒãƒ‰è·é›¢', fontsize=12)
plt.title('æ¬¡å…ƒã®å‘ªã„ï¼šæ¬¡å…ƒæ•°ã¨è·é›¢ã®é–¢ä¿‚', fontsize=14, fontweight='bold')
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()

print("=== æ¬¡å…ƒã®å‘ªã„ ===")
for d, dist in zip(dimensions, avg_distances):
    print(f"æ¬¡å…ƒæ•° {d:3d}: å¹³å‡è·é›¢ = {dist:.3f}")
print("\nâ†’ é«˜æ¬¡å…ƒã§ã¯å…¨ã¦ã®ç‚¹ãŒç­‰è·é›¢ã«è¦‹ãˆã‚‹ï¼ˆè·é›¢ãŒæ„å‘³ã‚’å¤±ã†ï¼‰")
</code></pre>

<h3>3. Concept Driftï¼ˆæ¦‚å¿µãƒ‰ãƒªãƒ•ãƒˆï¼‰</h3>

<p><strong>å•é¡Œ</strong>: æ™‚é–“ã¨ã¨ã‚‚ã«æ­£å¸¸ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒå¤‰åŒ–</p>

<p><strong>å¯¾å‡¦æ³•</strong>:</p>
<ul>
<li>Online Learningï¼ˆé€æ¬¡æ›´æ–°ï¼‰</li>
<li>Sliding Windowï¼ˆç›´è¿‘ãƒ‡ãƒ¼ã‚¿ã§å†è¨“ç·´ï¼‰</li>
<li>Ensemble Methodsï¼ˆè¤‡æ•°æ™‚æœŸã®ãƒ¢ãƒ‡ãƒ«ï¼‰</li>
<li>Adaptive Thresholdsï¼ˆé–¾å€¤ã®å‹•çš„èª¿æ•´ï¼‰</li>
</ul>

<h3>4. Interpretabilityï¼ˆè§£é‡ˆå¯èƒ½æ€§ï¼‰</h3>

<p><strong>å•é¡Œ</strong>: ãªãœç•°å¸¸ã¨åˆ¤å®šã•ã‚ŒãŸã‹èª¬æ˜ãŒå›°é›£</p>

<p><strong>å¯¾å‡¦æ³•</strong>:</p>
<ul>
<li>Rule-based methodsï¼ˆãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹æ‰‹æ³•ï¼‰</li>
<li>Feature importanceï¼ˆç‰¹å¾´é‡é‡è¦åº¦ï¼‰</li>
<li>SHAP valuesï¼ˆShapleyå€¤ã«ã‚ˆã‚‹èª¬æ˜ï¼‰</li>
<li>Attention mechanismsï¼ˆæ³¨ç›®ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ï¼‰</li>
</ul>

<pre><code class="language-python">import numpy as np
import matplotlib.pyplot as plt
from sklearn.ensemble import IsolationForest
from sklearn.tree import DecisionTreeClassifier

# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿
np.random.seed(42)
X_normal = np.random.normal(0, 1, size=(100, 5))
X_anomaly = np.random.normal(5, 1, size=(5, 5))
X = np.vstack([X_normal, X_anomaly])
y = np.array([0]*100 + [1]*5)

# Isolation Forestã§ç•°å¸¸æ¤œçŸ¥
clf_if = IsolationForest(contamination=0.05, random_state=42)
clf_if.fit(X)
predictions = clf_if.predict(X)

# ç•°å¸¸ã‚µãƒ³ãƒ—ãƒ«ã®ç‰¹å¾´é‡é‡è¦åº¦ã‚’åˆ†æ
# ç°¡æ˜“çš„ã«å„ç‰¹å¾´é‡ã®åå·®ã‚’è¨ˆç®—
X_mean = X_normal.mean(axis=0)
X_std = X_normal.std(axis=0)

anomaly_idx = np.where(predictions == -1)[0][:3]  # æœ€åˆã®3ã¤ã®ç•°å¸¸ã‚µãƒ³ãƒ—ãƒ«

# å¯è¦–åŒ–
fig, axes = plt.subplots(1, 3, figsize=(15, 5))

for i, idx in enumerate(anomaly_idx):
    deviations = np.abs((X[idx] - X_mean) / X_std)
    axes[i].bar(range(5), deviations, color='steelblue', edgecolor='black')
    axes[i].axhline(y=2, color='red', linestyle='--', linewidth=2, label='2Ïƒ')
    axes[i].set_xlabel('ç‰¹å¾´é‡', fontsize=11)
    axes[i].set_ylabel('æ¨™æº–åå·®', fontsize=11)
    axes[i].set_title(f'ç•°å¸¸ã‚µãƒ³ãƒ—ãƒ« {idx}ã®åå·®', fontsize=12, fontweight='bold')
    axes[i].set_xticks(range(5))
    axes[i].set_xticklabels([f'F{j}' for j in range(5)])
    axes[i].legend(fontsize=9)
    axes[i].grid(True, alpha=0.3, axis='y')

plt.tight_layout()
plt.show()

print("=== è§£é‡ˆå¯èƒ½æ€§ã®ä¾‹ ===")
for i, idx in enumerate(anomaly_idx):
    deviations = np.abs((X[idx] - X_mean) / X_std)
    max_dev_feature = deviations.argmax()
    print(f"ç•°å¸¸ã‚µãƒ³ãƒ—ãƒ« {idx}: ç‰¹å¾´é‡ {max_dev_feature} ãŒæœ€ã‚‚ç•°å¸¸ ({deviations[max_dev_feature]:.2f}Ïƒ)")
</code></pre>

<h3>èª²é¡Œã®å„ªå…ˆé †ä½</h3>

<table>
<thead>
<tr>
<th>èª²é¡Œ</th>
<th>å½±éŸ¿åº¦</th>
<th>å¯¾å‡¦é›£æ˜“åº¦</th>
<th>å„ªå…ˆåº¦</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Label Scarcity</strong></td>
<td>é«˜</td>
<td>ä¸­</td>
<td>é«˜</td>
</tr>
<tr>
<td><strong>Concept Drift</strong></td>
<td>é«˜</td>
<td>é«˜</td>
<td>é«˜</td>
</tr>
<tr>
<td><strong>High Dimensionality</strong></td>
<td>ä¸­</td>
<td>ä¸­</td>
<td>ä¸­</td>
</tr>
<tr>
<td><strong>Interpretability</strong></td>
<td>ä¸­</td>
<td>é«˜</td>
<td>ä¸­</td>
</tr>
</tbody>
</table>

<hr>

<h2>1.6 æœ¬ç« ã®ã¾ã¨ã‚</h2>

<h3>å­¦ã‚“ã ã“ã¨</h3>

<ol>
<li><p><strong>ç•°å¸¸æ¤œçŸ¥ã®åŸºæœ¬</strong></p>
<ul>
<li>Point, Contextual, Collectiveç•°å¸¸ã®3ã‚¿ã‚¤ãƒ—</li>
<li>ä¸æ­£æ¤œçŸ¥ã€è£½é€ ã€åŒ»ç™‚ã€ITã‚·ã‚¹ãƒ†ãƒ ã¸ã®å¿œç”¨</li>
<li>ãƒ“ã‚¸ãƒã‚¹ä¾¡å€¤ã®ç†è§£</li>
</ul></li>

<li><p><strong>ã‚¿ã‚¹ã‚¯åˆ†é¡</strong></p>
<ul>
<li>æ•™å¸«ã‚ã‚Šãƒ»åŠæ•™å¸«ã‚ã‚Šãƒ»æ•™å¸«ãªã—å­¦ç¿’</li>
<li>Novelty Detection vs Outlier Detection</li>
<li>Online vs Offline Detection</li>
</ul></li>

<li><p><strong>è©•ä¾¡æŒ‡æ¨™</strong></p>
<ul>
<li>Precision, Recall, F1ã®ä½¿ã„åˆ†ã‘</li>
<li>ROC-AUC vs PR-AUC</li>
<li>ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡å•é¡Œã¸ã®å¯¾å‡¦</li>
</ul></li>

<li><p><strong>ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨å¯è¦–åŒ–</strong></p>
<ul>
<li>Syntheticãƒ‡ãƒ¼ã‚¿ã§ã®æ¤œè¨¼</li>
<li>Real-worldãƒ‡ãƒ¼ã‚¿ã®ç‰¹æ€§</li>
<li>PCA, t-SNE, ç•°å¸¸ã‚¹ã‚³ã‚¢ã®å¯è¦–åŒ–</li>
</ul></li>

<li><p><strong>èª²é¡Œã¨å¯¾å‡¦æ³•</strong></p>
<ul>
<li>Label Scarcity: æ•™å¸«ãªã—ãƒ»åŠæ•™å¸«ã‚ã‚Šå­¦ç¿’</li>
<li>High Dimensionality: æ¬¡å…ƒå‰Šæ¸›</li>
<li>Concept Drift: Online Learning</li>
<li>Interpretability: SHAP, Feature Importance</li>
</ul></li>
</ol>

<h3>ç•°å¸¸æ¤œçŸ¥ã®åŸå‰‡</h3>

<table>
<thead>
<tr>
<th>åŸå‰‡</th>
<th>èª¬æ˜</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>ãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜æ´»ç”¨</strong></td>
<td>æ¥­å‹™çŸ¥è­˜ã‚’æ‰‹æ³•é¸æŠã¨é–¾å€¤è¨­å®šã«åæ˜ </td>
</tr>
<tr>
<td><strong>é©åˆ‡ãªè©•ä¾¡æŒ‡æ¨™</strong></td>
<td>ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿ã§ã¯PR-AUC, F1ã‚’å„ªå…ˆ</td>
</tr>
<tr>
<td><strong>ç¶™ç¶šçš„ç›£è¦–</strong></td>
<td>Concept Driftã«å¯¾å¿œã™ã‚‹å†è¨“ç·´</td>
</tr>
<tr>
<td><strong>è§£é‡ˆå¯èƒ½æ€§é‡è¦–</strong></td>
<td>æœ¬ç•ªé‹ç”¨ã«ã¯èª¬æ˜å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ãŒå¿…è¦</td>
</tr>
<tr>
<td><strong>ã‚³ã‚¹ãƒˆæ„è­˜</strong></td>
<td>FP, FNã®ãƒ“ã‚¸ãƒã‚¹ã‚³ã‚¹ãƒˆã‚’è€ƒæ…®</td>
</tr>
</tbody>
</table>

<h3>æ¬¡ã®ç« ã¸</h3>

<p>ç¬¬2ç« ã§ã¯ã€<strong>çµ±è¨ˆçš„ç•°å¸¸æ¤œçŸ¥</strong>ã‚’å­¦ã³ã¾ã™ï¼š</p>
<ul>
<li>Z-score, Grubbs Test</li>
<li>Gaussian Mixture Models</li>
<li>Statistical Process Control</li>
<li>Bayesian Anomaly Detection</li>
<li>æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã¸ã®å¿œç”¨</li>
</ul>

<hr>

<h2>æ¼”ç¿’å•é¡Œ</h2>

<h3>å•é¡Œ1ï¼ˆé›£æ˜“åº¦ï¼šeasyï¼‰</h3>
<p>Point Anomaly, Contextual Anomaly, Collective Anomalyã®é•ã„ã‚’èª¬æ˜ã—ã€ãã‚Œãã‚Œã®å…·ä½“ä¾‹ã‚’æŒ™ã’ã¦ãã ã•ã„ã€‚</p>

<details>
<summary>è§£ç­”ä¾‹</summary>

<p><strong>è§£ç­”</strong>ï¼š</p>

<ol>
<li><p><strong>Point Anomalyï¼ˆç‚¹ç•°å¸¸ï¼‰</strong></p>
<ul>
<li>èª¬æ˜: å€‹åˆ¥ã®ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆãŒã€ä»–ã®å…¨ã¦ã®ãƒ‡ãƒ¼ã‚¿ã¨å¤§ããç•°ãªã‚‹</li>
<li>ä¾‹: ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆã‚«ãƒ¼ãƒ‰ã§çªç„¶10ä¸‡å††ã®é«˜é¡æ±ºæ¸ˆãŒç™ºç”Ÿ</li>
</ul></li>

<li><p><strong>Contextual Anomalyï¼ˆæ–‡è„ˆçš„ç•°å¸¸ï¼‰</strong></p>
<ul>
<li>èª¬æ˜: ç‰¹å®šã®æ–‡è„ˆï¼ˆæ™‚é–“ã€å ´æ‰€ãªã©ï¼‰ã«ãŠã„ã¦ã®ã¿ç•°å¸¸ã¨ã¿ãªã•ã‚Œã‚‹</li>
<li>ä¾‹: æ°—æ¸©35â„ƒã¯å¤ã¯æ­£å¸¸ã ãŒã€å†¬ã¯ç•°å¸¸ã€‚åˆå‰3æ™‚ã®ã‚ªãƒ•ã‚£ã‚¹ãƒ“ãƒ«ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ã¯ç•°å¸¸</li>
</ul></li>

<li><p><strong>Collective Anomalyï¼ˆé›†å›£ç•°å¸¸ï¼‰</strong></p>
<ul>
<li>èª¬æ˜: å€‹ã€…ã®ãƒ‡ãƒ¼ã‚¿ã¯æ­£å¸¸ã ãŒã€é›†åˆã¨ã—ã¦ç•°å¸¸ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å½¢æˆ</li>
<li>ä¾‹: å¿ƒé›»å›³ã®ä¸€æ™‚çš„ãªç•°å¸¸æ³¢å½¢ã®é€£ç¶šã€Webã‚µãƒ¼ãƒãƒ¼ã¸ã®åˆ†æ•£DoSæ”»æ’ƒ</li>
</ul></li>
</ol>

</details>

<h3>å•é¡Œ2ï¼ˆé›£æ˜“åº¦ï¼šmediumï¼‰</h3>
<p>ä»¥ä¸‹ã®ã‚·ãƒŠãƒªã‚ªã«å¯¾ã—ã¦ã€é©åˆ‡ãªç•°å¸¸æ¤œçŸ¥ã®ã‚¿ã‚¹ã‚¯è¨­å®šï¼ˆæ•™å¸«ã‚ã‚Š/åŠæ•™å¸«ã‚ã‚Š/æ•™å¸«ãªã—ï¼‰ã‚’é¸æŠã—ã€ç†ç”±ã‚’è¿°ã¹ã¦ãã ã•ã„ã€‚</p>

<p><strong>ã‚·ãƒŠãƒªã‚ª</strong>: è£½é€ ãƒ©ã‚¤ãƒ³ã§è£½å“ç”»åƒã‹ã‚‰ä¸è‰¯å“ã‚’æ¤œå‡ºã—ãŸã„ã€‚æ­£å¸¸å“ã®ç”»åƒã¯å¤§é‡ã«ã‚ã‚‹ãŒã€ä¸è‰¯å“ã®ç”»åƒã¯æ•°æšã—ã‹ãªã„ã€‚</p>

<details>
<summary>è§£ç­”ä¾‹</summary>

<p><strong>è§£ç­”</strong>ï¼š</p>

<p><strong>æ¨å¥¨ã‚¿ã‚¹ã‚¯</strong>: <strong>åŠæ•™å¸«ã‚ã‚Šå­¦ç¿’ï¼ˆNovelty Detectionï¼‰</strong></p>

<p><strong>ç†ç”±</strong>ï¼š</p>

<ol>
<li><p><strong>ãƒ©ãƒ™ãƒ«çŠ¶æ³</strong></p>
<ul>
<li>æ­£å¸¸å“ã®ç”»åƒã¯å¤§é‡ã«ã‚ã‚‹ï¼ˆãƒ©ãƒ™ãƒ«ä»˜ãï¼‰</li>
<li>ä¸è‰¯å“ã®ç”»åƒã¯æ•°æšï¼ˆæ•™å¸«ã‚ã‚Šå­¦ç¿’ã«ã¯ä¸ååˆ†ï¼‰</li>
</ul></li>

<li><p><strong>ã‚¿ã‚¹ã‚¯ã®æ€§è³ª</strong></p>
<ul>
<li>æ­£å¸¸å“ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å­¦ç¿’ã—ã€ãã‚Œã‹ã‚‰é€¸è„±ã™ã‚‹ã‚‚ã®ã‚’ç•°å¸¸ã¨ã™ã‚‹</li>
<li>Novelty Detectionï¼ˆæ–°è¦æ€§æ¤œçŸ¥ï¼‰ã®å…¸å‹çš„ãªãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹</li>
</ul></li>

<li><p><strong>å…·ä½“çš„æ‰‹æ³•</strong></p>
<ul>
<li>One-Class SVM: æ­£å¸¸ãƒ‡ãƒ¼ã‚¿ã®ã¿ã§å¢ƒç•Œã‚’å­¦ç¿’</li>
<li>Autoencoder: æ­£å¸¸ç”»åƒã®å†æ§‹æˆèª¤å·®ã§ç•°å¸¸åˆ¤å®š</li>
<li>Deep SVDD: æ·±å±¤å­¦ç¿’ã«ã‚ˆã‚‹æ­£å¸¸ãƒ‡ãƒ¼ã‚¿ã®è¶…çƒé¢è¡¨ç¾</li>
</ul></li>
</ol>

<p><strong>æ•™å¸«ã‚ã‚Šå­¦ç¿’ãŒä¸é©ãªç†ç”±</strong>:</p>
<ul>
<li>ä¸è‰¯å“ã®ã‚µãƒ³ãƒ—ãƒ«ãŒå°‘ãªã™ãã‚‹ï¼ˆæ•°æšã§ã¯æ±åŒ–å›°é›£ï¼‰</li>
<li>ä¸è‰¯å“ã®ç¨®é¡ãŒæœªçŸ¥ï¼ˆè¨“ç·´ãƒ‡ãƒ¼ã‚¿ã«å«ã¾ã‚Œãªã„ä¸è‰¯ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡ºã§ããªã„ï¼‰</li>
</ul>

<p><strong>æ•™å¸«ãªã—å­¦ç¿’ãŒä¸é©ãªç†ç”±</strong>:</p>
<ul>
<li>æ­£å¸¸å“ã®ãƒ©ãƒ™ãƒ«ãŒã‚ã‚‹ã®ã«æ´»ç”¨ã—ãªã„ã®ã¯éåŠ¹ç‡</li>
<li>åŠæ•™å¸«ã‚ã‚Šå­¦ç¿’ã®æ–¹ãŒé«˜ç²¾åº¦</li>
</ul>

</details>

<h3>å•é¡Œ3ï¼ˆé›£æ˜“åº¦ï¼šmediumï¼‰</h3>
<p>ç•°å¸¸æ¤œçŸ¥ã«ãŠã„ã¦ã€ãªãœAccuracyï¼ˆç²¾åº¦ï¼‰ã ã‘ã§ã¯è©•ä¾¡ãŒä¸ååˆ†ãªã®ã‹èª¬æ˜ã—ã€ä»£ã‚ã‚Šã«ä½¿ã†ã¹ãæŒ‡æ¨™ã‚’ææ¡ˆã—ã¦ãã ã•ã„ã€‚</p>

<details>
<summary>è§£ç­”ä¾‹</summary>

<p><strong>è§£ç­”</strong>ï¼š</p>

<p><strong>AccuracyãŒä¸ååˆ†ãªç†ç”±</strong>ï¼š</p>

<p>ç•°å¸¸æ¤œçŸ¥ã§ã¯ã€æ­£å¸¸ãƒ‡ãƒ¼ã‚¿ãŒåœ§å€’çš„å¤šæ•°ï¼ˆ95-99%ï¼‰ã‚’å ã‚ã‚‹ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡å•é¡ŒãŒã‚ã‚Šã¾ã™ã€‚</p>

<p><strong>å…·ä½“ä¾‹</strong>:</p>
<ul>
<li>ãƒ‡ãƒ¼ã‚¿: æ­£å¸¸95%, ç•°å¸¸5%</li>
<li>äºˆæ¸¬å™¨A: å…¨ã¦ã‚’æ­£å¸¸ã¨äºˆæ¸¬ â†’ Accuracy = 95%ï¼ˆç•°å¸¸ã‚’1ã¤ã‚‚æ¤œå‡ºã§ãã¦ã„ãªã„ï¼‰</li>
<li>äºˆæ¸¬å™¨B: ç•°å¸¸ã‚’å…¨ã¦æ­£ã—ãæ¤œå‡º â†’ Accuracy = 100%</li>
</ul>

<p>äºˆæ¸¬å™¨Aã¯å½¹ã«ç«‹ãŸãªã„ã®ã«ã€Accuracyã§ã¯95%ã®é«˜è©•ä¾¡ã‚’å¾—ã¦ã—ã¾ã„ã¾ã™ã€‚</p>

<p><strong>æ¨å¥¨ã™ã‚‹è©•ä¾¡æŒ‡æ¨™</strong>ï¼š</p>

<table>
<thead>
<tr>
<th>æŒ‡æ¨™</th>
<th>æ¨å¥¨ç†ç”±</th>
<th>ä½¿ç”¨å ´é¢</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>PR-AUC</strong></td>
<td>ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿ã«é©åˆ‡ã€é–¾å€¤éä¾å­˜</td>
<td>ç·åˆè©•ä¾¡</td>
</tr>
<tr>
<td><strong>F1 Score</strong></td>
<td>Precision/Recallã®ãƒãƒ©ãƒ³ã‚¹</td>
<td>å˜ä¸€é–¾å€¤ã§ã®è©•ä¾¡</td>
</tr>
<tr>
<td><strong>Recall</strong></td>
<td>ç•°å¸¸ã®è¦‹é€ƒã—æœ€å°åŒ–</td>
<td>åŒ»ç™‚ã€äºˆé˜²ä¿å®ˆ</td>
</tr>
<tr>
<td><strong>Precision</strong></td>
<td>èª¤æ¤œå‡ºæœ€å°åŒ–</td>
<td>ã‚¹ãƒ‘ãƒ ãƒ•ã‚£ãƒ«ã‚¿</td>
</tr>
</tbody>
</table>

<p><strong>è¨ˆç®—å¼</strong>:</p>
<ul>
<li>Precision = TP / (TP + FP): ç•°å¸¸ã¨äºˆæ¸¬ã—ãŸã†ã¡å®Ÿéš›ã«ç•°å¸¸ã®å‰²åˆ</li>
<li>Recall = TP / (TP + FN): å®Ÿéš›ã®ç•°å¸¸ã®ã†ã¡æ¤œå‡ºã§ããŸå‰²åˆ</li>
<li>F1 = 2 Ã— (Precision Ã— Recall) / (Precision + Recall)</li>
</ul>

</details>

<h3>å•é¡Œ4ï¼ˆé›£æ˜“åº¦ï¼šhardï¼‰</h3>
<p>æ¬¡å…ƒã®å‘ªã„ãŒç•°å¸¸æ¤œçŸ¥ã«ä¸ãˆã‚‹å½±éŸ¿ã‚’èª¬æ˜ã—ã€å¯¾å‡¦æ³•ã‚’3ã¤æŒ™ã’ã¦ãã ã•ã„ã€‚Pythonã‚³ãƒ¼ãƒ‰ã§æ¬¡å…ƒæ•°ã¨è·é›¢ã®é–¢ä¿‚ã‚’ç¤ºã—ã¦ãã ã•ã„ã€‚</p>

<details>
<summary>è§£ç­”ä¾‹</summary>

<p><strong>è§£ç­”</strong>ï¼š</p>

<p><strong>æ¬¡å…ƒã®å‘ªã„ã®å½±éŸ¿</strong>ï¼š</p>

<p>é«˜æ¬¡å…ƒç©ºé–“ã§ã¯ã€å…¨ã¦ã®ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆé–“ã®è·é›¢ãŒä¼¼é€šã£ã¦ãã‚‹ãŸã‚ã€è·é›¢ãƒ™ãƒ¼ã‚¹ã®ç•°å¸¸æ¤œçŸ¥æ‰‹æ³•ï¼ˆKNN, LOFãªã©ï¼‰ãŒæ©Ÿèƒ½ã—ãªããªã‚Šã¾ã™ã€‚</p>

<p><strong>å…·ä½“çš„ãªå•é¡Œ</strong>:</p>
<ol>
<li>æœ€è¿‘å‚ã¨æœ€é ç‚¹ã®è·é›¢ãŒåæŸã™ã‚‹</li>
<li>ç•°å¸¸ãƒ‡ãƒ¼ã‚¿ã¨æ­£å¸¸ãƒ‡ãƒ¼ã‚¿ã®è·é›¢å·®ãŒå°ã•ããªã‚‹</li>
<li>ãƒ¦ãƒ¼ã‚¯ãƒªãƒƒãƒ‰è·é›¢ãŒæ„å‘³ã‚’å¤±ã†</li>
</ol>

<p><strong>å¯¾å‡¦æ³•</strong>ï¼š</p>

<ol>
<li><p><strong>æ¬¡å…ƒå‰Šæ¸›</strong></p>
<ul>
<li>PCA: ä¸»æˆåˆ†åˆ†æã§é‡è¦ãªè»¸ã®ã¿æ®‹ã™</li>
<li>Autoencoder: éç·šå½¢ãªæ¬¡å…ƒå‰Šæ¸›</li>
<li>t-SNE/UMAP: å¯è¦–åŒ–ã¨æ§‹é€ ä¿æŒ</li>
</ul></li>

<li><p><strong>ç‰¹å¾´é¸æŠ</strong></p>
<ul>
<li>Mutual Information: ç•°å¸¸æ¤œçŸ¥ã«å¯„ä¸ã™ã‚‹ç‰¹å¾´é‡ã‚’é¸æŠ</li>
<li>L1æ­£å‰‡åŒ–: ä¸è¦ãªç‰¹å¾´é‡ã®é‡ã¿ã‚’0ã«ã™ã‚‹</li>
<li>ãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜: å°‚é–€å®¶ã«ã‚ˆã‚‹ç‰¹å¾´é‡é¸å®š</li>
</ul></li>

<li><p><strong>éƒ¨åˆ†ç©ºé–“æ³•</strong></p>
<ul>
<li>Subspace methods: è¤‡æ•°ã®ä½æ¬¡å…ƒéƒ¨åˆ†ç©ºé–“ã§ç•°å¸¸æ¤œçŸ¥</li>
<li>Random Projection: ãƒ©ãƒ³ãƒ€ãƒ ãªä½æ¬¡å…ƒå°„å½±ã‚’è¤‡æ•°ä½¿ç”¨</li>
</ul></li>
</ol>

<p><strong>Pythonã‚³ãƒ¼ãƒ‰</strong>ï¼š</p>

<pre><code class="language-python">import numpy as np
import matplotlib.pyplot as plt
from scipy.spatial.distance import pdist, squareform

# æ¬¡å…ƒã®å‘ªã„ã®å®Ÿé¨“
np.random.seed(42)
dimensions = [2, 5, 10, 20, 50, 100, 200, 500]
results = []

for d in dimensions:
    # å‡ä¸€åˆ†å¸ƒã‹ã‚‰ãƒ©ãƒ³ãƒ€ãƒ ãªç‚¹ã‚’ç”Ÿæˆ
    X = np.random.uniform(0, 1, size=(100, d))

    # å…¨ãƒšã‚¢é–“ã®è·é›¢ã‚’è¨ˆç®—
    distances = pdist(X, metric='euclidean')

    # çµ±è¨ˆã‚’è¨˜éŒ²
    results.append({
        'dim': d,
        'mean': distances.mean(),
        'std': distances.std(),
        'min': distances.min(),
        'max': distances.max()
    })

# å¯è¦–åŒ–
fig, axes = plt.subplots(1, 2, figsize=(14, 6))

# å¹³å‡è·é›¢ã¨æ¨™æº–åå·®
dims = [r['dim'] for r in results]
means = [r['mean'] for r in results]
stds = [r['std'] for r in results]

axes[0].plot(dims, means, marker='o', linewidth=2, markersize=8, label='å¹³å‡è·é›¢')
axes[0].fill_between(dims,
                      [m - s for m, s in zip(means, stds)],
                      [m + s for m, s in zip(means, stds)],
                      alpha=0.3, label='Â±1Ïƒ')
axes[0].set_xlabel('æ¬¡å…ƒæ•°', fontsize=12)
axes[0].set_ylabel('ãƒ¦ãƒ¼ã‚¯ãƒªãƒƒãƒ‰è·é›¢', fontsize=12)
axes[0].set_title('æ¬¡å…ƒæ•°ã¨è·é›¢ã®é–¢ä¿‚', fontsize=14, fontweight='bold')
axes[0].legend(fontsize=10)
axes[0].grid(True, alpha=0.3)

# æœ€å°è·é›¢ã¨æœ€å¤§è·é›¢ã®æ¯”ç‡
ratios = [r['min'] / r['max'] for r in results]
axes[1].plot(dims, ratios, marker='s', linewidth=2, markersize=8, color='red')
axes[1].axhline(y=1.0, color='gray', linestyle='--', label='å®Œå…¨ä¸€è‡´')
axes[1].set_xlabel('æ¬¡å…ƒæ•°', fontsize=12)
axes[1].set_ylabel('æœ€å°è·é›¢ / æœ€å¤§è·é›¢', fontsize=12)
axes[1].set_title('è·é›¢ã®ç›¸å¯¾å·®ã®æ¶ˆå¤±', fontsize=14, fontweight='bold')
axes[1].legend(fontsize=10)
axes[1].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

print("=== æ¬¡å…ƒã®å‘ªã„ï¼šè·é›¢ã®çµ±è¨ˆ ===")
for r in results:
    print(f"æ¬¡å…ƒæ•° {r['dim']:3d}: å¹³å‡={r['mean']:.3f}, "
          f"æ¨™æº–åå·®={r['std']:.3f}, æœ€å°/æœ€å¤§æ¯”={r['min']/r['max']:.3f}")

print("\nâ†’ æ¬¡å…ƒæ•°ãŒå¢—ãˆã‚‹ã¨:")
print("  1. å¹³å‡è·é›¢ãŒå¢—åŠ ï¼ˆã‚¹ã‚±ãƒ¼ãƒ«åŠ¹æœï¼‰")
print("  2. ç›¸å¯¾çš„ãªè·é›¢å·®ãŒç¸®å°ï¼ˆæœ€å°/æœ€å¤§æ¯”ãŒ1ã«è¿‘ã¥ãï¼‰")
print("  3. å…¨ã¦ã®ç‚¹ãŒç­‰è·é›¢ã«è¦‹ãˆã‚‹ï¼ˆç•°å¸¸æ¤œçŸ¥ãŒå›°é›£ï¼‰")
</code></pre>

<p><strong>çµè«–</strong>:</p>
<ul>
<li>é«˜æ¬¡å…ƒã§ã¯è·é›¢ã®å·®ç•°ãŒå°ã•ããªã‚Šã€ç•°å¸¸æ¤œçŸ¥ã®ç²¾åº¦ãŒä½ä¸‹</li>
<li>æ¬¡å…ƒå‰Šæ¸›ã¾ãŸã¯ç‰¹å¾´é¸æŠã«ã‚ˆã‚Šã€æ„å‘³ã®ã‚ã‚‹è·é›¢ã‚’ä¿æŒ</li>
<li>ãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜ã‚’æ´»ç”¨ã—ãŸç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ãŒé‡è¦</li>
</ul>

</details>

<h3>å•é¡Œ5ï¼ˆé›£æ˜“åº¦ï¼šhardï¼‰</h3>
<p>Concept Driftï¼ˆæ¦‚å¿µãƒ‰ãƒªãƒ•ãƒˆï¼‰ãŒç•°å¸¸æ¤œçŸ¥ã«ä¸ãˆã‚‹å½±éŸ¿ã‚’èª¬æ˜ã—ã€Online Learningã«ã‚ˆã‚‹å¯¾å‡¦æ³•ã‚’ç¤ºã—ã¦ãã ã•ã„ã€‚æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã§ã®ç°¡å˜ãªå®Ÿè£…ä¾‹ã‚‚å«ã‚ã¦ãã ã•ã„ã€‚</p>

<details>
<summary>è§£ç­”ä¾‹</summary>

<p><strong>è§£ç­”</strong>ï¼š</p>

<p><strong>Concept Driftã®å½±éŸ¿</strong>ï¼š</p>

<p>Concept Driftã¨ã¯ã€æ™‚é–“ã¨ã¨ã‚‚ã«æ­£å¸¸ãƒ‡ãƒ¼ã‚¿ã®åˆ†å¸ƒãŒå¤‰åŒ–ã™ã‚‹ç¾è±¡ã§ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€éå»ã®ãƒ‡ãƒ¼ã‚¿ã§è¨“ç·´ã—ãŸãƒ¢ãƒ‡ãƒ«ãŒç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿ã«é©åˆã—ãªããªã‚Šã¾ã™ã€‚</p>

<p><strong>å…·ä½“ä¾‹</strong>:</p>
<ul>
<li>Eã‚³ãƒãƒ¼ã‚¹: å­£ç¯€å¤‰å‹•ï¼ˆå¤ã¨å†¬ã§è³¼è²·ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒå¤‰åŒ–ï¼‰</li>
<li>è£½é€ æ¥­: è¨­å‚™ã®çµŒå¹´åŠ£åŒ–ã§æ­£å¸¸ãªæŒ¯å‹•ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒå¤‰åŒ–</li>
<li>ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯: ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ãƒ‘ã‚¿ãƒ¼ãƒ³ã®é€²åŒ–</li>
</ul>

<p><strong>å•é¡Œç‚¹</strong>:</p>
<ol>
<li>éå»ã®ãƒ¢ãƒ‡ãƒ«ãŒå¤ããªã‚Šã€èª¤æ¤œå‡ºï¼ˆFPï¼‰ãŒå¢—åŠ </li>
<li>æ–°ã—ã„æ­£å¸¸ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç•°å¸¸ã¨èª¤åˆ¤å®š</li>
<li>æ¤œçŸ¥æ€§èƒ½ã®çµŒæ™‚çš„ãªåŠ£åŒ–</li>
</ol>

<p><strong>Online Learningã«ã‚ˆã‚‹å¯¾å‡¦æ³•</strong>ï¼š</p>

<ol>
<li><p><strong>Sliding Window Approach</strong></p>
<ul>
<li>ç›´è¿‘Nã‚µãƒ³ãƒ—ãƒ«ã®ã¿ã§ãƒ¢ãƒ‡ãƒ«ã‚’å†è¨“ç·´</li>
<li>å¤ã„ãƒ‡ãƒ¼ã‚¿ã‚’ç ´æ£„ã—ã€æ–°ã—ã„ãƒ‘ã‚¿ãƒ¼ãƒ³ã«é©å¿œ</li>
</ul></li>

<li><p><strong>Incremental Learning</strong></p>
<ul>
<li>æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã§ãƒ¢ãƒ‡ãƒ«ã‚’é€æ¬¡æ›´æ–°</li>
<li>å…¨ãƒ‡ãƒ¼ã‚¿ã‚’å†è¨“ç·´ã›ãšåŠ¹ç‡çš„</li>
</ul></li>

<li><p><strong>Adaptive Thresholds</strong></p>
<ul>
<li>ç•°å¸¸åˆ¤å®šã®é–¾å€¤ã‚’å‹•çš„ã«èª¿æ•´</li>
<li>æœ€è¿‘ã®ãƒ‡ãƒ¼ã‚¿åˆ†å¸ƒã«åŸºã¥ãé–¾å€¤æ›´æ–°</li>
</ul></li>
</ol>

<p><strong>å®Ÿè£…ä¾‹ï¼ˆSliding Windowï¼‰</strong>ï¼š</p>

<pre><code class="language-python">import numpy as np
import matplotlib.pyplot as plt
from sklearn.ensemble import IsolationForest

# æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆï¼ˆæ¦‚å¿µãƒ‰ãƒªãƒ•ãƒˆã‚ã‚Šï¼‰
np.random.seed(42)
n_samples = 1000
time = np.arange(n_samples)

# æ­£å¸¸ãƒ‡ãƒ¼ã‚¿: å¹³å‡ãŒæ™‚é–“ã¨ã¨ã‚‚ã«å¤‰åŒ–ï¼ˆConcept Driftï¼‰
mean_shift = time / 200  # å¾ã€…ã«å¹³å‡ãŒå¢—åŠ 
X = np.random.normal(loc=mean_shift, scale=1.0, size=(n_samples, 5))

# ç•°å¸¸ãƒ‡ãƒ¼ã‚¿ã‚’ä¸€éƒ¨è¿½åŠ 
anomaly_indices = np.random.choice(n_samples, size=50, replace=False)
X[anomaly_indices] += np.random.uniform(5, 10, size=(50, 5))

# çœŸã®ãƒ©ãƒ™ãƒ«
y_true = np.zeros(n_samples)
y_true[anomaly_indices] = 1

# 1. é™çš„ãƒ¢ãƒ‡ãƒ«ï¼ˆåˆæœŸãƒ‡ãƒ¼ã‚¿ã®ã¿ã§è¨“ç·´ï¼‰
print("=== 1. é™çš„ãƒ¢ãƒ‡ãƒ«ï¼ˆConcept Driftæœªå¯¾å¿œï¼‰===")
static_model = IsolationForest(contamination=0.05, random_state=42)
static_model.fit(X[:200])  # åˆæœŸ200ã‚µãƒ³ãƒ—ãƒ«ã®ã¿

static_predictions = static_model.predict(X)
static_predictions = (static_predictions == -1).astype(int)

from sklearn.metrics import precision_score, recall_score, f1_score
static_precision = precision_score(y_true, static_predictions)
static_recall = recall_score(y_true, static_predictions)
static_f1 = f1_score(y_true, static_predictions)

print(f"Precision: {static_precision:.3f}")
print(f"Recall: {static_recall:.3f}")
print(f"F1 Score: {static_f1:.3f}")

# 2. Online Learningï¼ˆSliding Windowï¼‰
print("\n=== 2. Online Learningï¼ˆSliding Window, window=200ï¼‰===")
window_size = 200
online_predictions = np.zeros(n_samples)

for i in range(window_size, n_samples):
    # ç›´è¿‘window_sizeã‚µãƒ³ãƒ—ãƒ«ã§ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´
    window_data = X[i-window_size:i]
    online_model = IsolationForest(contamination=0.05, random_state=42)
    online_model.fit(window_data)

    # ç¾åœ¨ã®ã‚µãƒ³ãƒ—ãƒ«ã‚’äºˆæ¸¬
    pred = online_model.predict(X[i:i+1])
    online_predictions[i] = (pred == -1).astype(int)

online_precision = precision_score(y_true[window_size:], online_predictions[window_size:])
online_recall = recall_score(y_true[window_size:], online_predictions[window_size:])
online_f1 = f1_score(y_true[window_size:], online_predictions[window_size:])

print(f"Precision: {online_precision:.3f}")
print(f"Recall: {online_recall:.3f}")
print(f"F1 Score: {online_f1:.3f}")

# å¯è¦–åŒ–
fig, axes = plt.subplots(2, 1, figsize=(14, 10))

# ãƒ‡ãƒ¼ã‚¿ã®å¹³å‡ã®å¤‰åŒ–ï¼ˆConcept Driftï¼‰
axes[0].plot(time, X.mean(axis=1), alpha=0.7, label='ãƒ‡ãƒ¼ã‚¿å¹³å‡')
axes[0].scatter(anomaly_indices, X[anomaly_indices].mean(axis=1),
                c='red', s=50, marker='X', label='ç•°å¸¸ãƒ‡ãƒ¼ã‚¿', zorder=5)
axes[0].set_xlabel('æ™‚åˆ»', fontsize=12)
axes[0].set_ylabel('å¹³å‡å€¤', fontsize=12)
axes[0].set_title('Concept Drift: æ™‚é–“ã¨ã¨ã‚‚ã«æ­£å¸¸ãƒ‡ãƒ¼ã‚¿ã®åˆ†å¸ƒãŒå¤‰åŒ–',
                  fontsize=14, fontweight='bold')
axes[0].legend(fontsize=10)
axes[0].grid(True, alpha=0.3)

# äºˆæ¸¬ã®æ¯”è¼ƒ
axes[1].scatter(time, static_predictions, alpha=0.5, label='é™çš„ãƒ¢ãƒ‡ãƒ«', s=10)
axes[1].scatter(time, online_predictions, alpha=0.5, label='Online Learning', s=10)
axes[1].scatter(anomaly_indices, y_true[anomaly_indices],
                c='red', marker='X', s=100, label='çœŸã®ç•°å¸¸', zorder=5, edgecolors='black')
axes[1].set_xlabel('æ™‚åˆ»', fontsize=12)
axes[1].set_ylabel('ç•°å¸¸ãƒ•ãƒ©ã‚°', fontsize=12)
axes[1].set_title('é™çš„ãƒ¢ãƒ‡ãƒ« vs Online Learning', fontsize=14, fontweight='bold')
axes[1].legend(fontsize=10)
axes[1].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

print("\n=== æ€§èƒ½æ¯”è¼ƒ ===")
print(f"é™çš„ãƒ¢ãƒ‡ãƒ«:      F1={static_f1:.3f}")
print(f"Online Learning: F1={online_f1:.3f}")
print(f"æ”¹å–„: {(online_f1 - static_f1):.3f}")
</code></pre>

<p><strong>çµè«–</strong>:</p>
<ul>
<li>Concept DriftãŒã‚ã‚‹ç’°å¢ƒã§ã¯ã€é™çš„ãƒ¢ãƒ‡ãƒ«ã¯æ€§èƒ½ãŒåŠ£åŒ–</li>
<li>Sliding Windowã«ã‚ˆã‚‹ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å­¦ç¿’ã§ã€æ–°ã—ã„ãƒ‘ã‚¿ãƒ¼ãƒ³ã«é©å¿œ</li>
<li>ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºã¯ã€å®‰å®šæ€§ï¼ˆå¤§ï¼‰ã¨é©å¿œé€Ÿåº¦ï¼ˆå°ï¼‰ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•</li>
</ul>

</details>

<hr>

<h2>å‚è€ƒæ–‡çŒ®</h2>

<ol>
<li>Chandola, V., Banerjee, A., & Kumar, V. (2009). <em>Anomaly detection: A survey</em>. ACM computing surveys (CSUR), 41(3), 1-58.</li>
<li>Aggarwal, C. C. (2017). <em>Outlier analysis</em> (2nd ed.). Springer.</li>
<li>Goldstein, M., & Uchida, S. (2016). <em>A comparative evaluation of unsupervised anomaly detection algorithms for multivariate data</em>. PloS one, 11(4), e0152173.</li>
<li>Pang, G., Shen, C., Cao, L., & Hengel, A. V. D. (2021). <em>Deep learning for anomaly detection: A review</em>. ACM Computing Surveys (CSUR), 54(2), 1-38.</li>
<li>Rousseeuw, P. J., & Hubert, M. (2011). <em>Robust statistics for outlier detection</em>. Wiley interdisciplinary reviews: Data mining and knowledge discovery, 1(1), 73-79.</li>
</ol>

<div class="navigation">
    <a href="index.html" class="nav-button">â† ã‚·ãƒªãƒ¼ã‚ºç›®æ¬¡</a>
    <a href="chapter2-statistical-methods.html" class="nav-button">æ¬¡ã®ç« : çµ±è¨ˆçš„ç•°å¸¸æ¤œçŸ¥ â†’</a>
</div>

    </main>

    <footer>
        <p><strong>ä½œæˆè€…</strong>: AI Terakoya Content Team</p>
        <p><strong>ç›£ä¿®</strong>: Dr. Yusuke Hashimotoï¼ˆæ±åŒ—å¤§å­¦ï¼‰</p>
        <p><strong>ãƒãƒ¼ã‚¸ãƒ§ãƒ³</strong>: 1.0 | <strong>ä½œæˆæ—¥</strong>: 2025-10-21</p>
        <p><strong>ãƒ©ã‚¤ã‚»ãƒ³ã‚¹</strong>: Creative Commons BY 4.0</p>
        <p>Â© 2025 AI Terakoya. All rights reserved.</p>
    </footer>
</body>
</html>
