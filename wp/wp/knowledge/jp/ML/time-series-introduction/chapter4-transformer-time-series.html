<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ç¬¬4ç« ï¼šTransformerã«ã‚ˆã‚‹æ™‚ç³»åˆ—äºˆæ¸¬ - AI Terakoya</title>

    <style>
        :root {
            --color-primary: #2c3e50;
            --color-primary-dark: #1a252f;
            --color-accent: #7b2cbf;
            --color-accent-light: #9d4edd;
            --color-text: #2d3748;
            --color-text-light: #4a5568;
            --color-bg: #ffffff;
            --color-bg-alt: #f7fafc;
            --color-border: #e2e8f0;
            --color-code-bg: #f8f9fa;
            --color-link: #3182ce;
            --color-link-hover: #2c5aa0;
            --spacing-xs: 0.5rem;
            --spacing-sm: 1rem;
            --spacing-md: 1.5rem;
            --spacing-lg: 2rem;
            --spacing-xl: 3rem;
            --font-body: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            --font-mono: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;
            --border-radius: 8px;
            --box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body { font-family: var(--font-body); line-height: 1.7; color: var(--color-text); background-color: var(--color-bg); font-size: 16px; }
        header { background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%); color: white; padding: var(--spacing-xl) var(--spacing-md); margin-bottom: var(--spacing-xl); box-shadow: var(--box-shadow); }
        .header-content { max-width: 900px; margin: 0 auto; }
        h1 { font-size: 2rem; font-weight: 700; margin-bottom: var(--spacing-sm); line-height: 1.2; }
        .subtitle { font-size: 1.1rem; opacity: 0.95; font-weight: 400; margin-bottom: var(--spacing-md); }
        .meta { display: flex; flex-wrap: wrap; gap: var(--spacing-md); font-size: 0.9rem; opacity: 0.9; }
        .meta-item { display: flex; align-items: center; gap: 0.3rem; }
        .container { max-width: 900px; margin: 0 auto; padding: 0 var(--spacing-md) var(--spacing-xl); }
        h2 { font-size: 1.75rem; color: var(--color-primary); margin-top: var(--spacing-xl); margin-bottom: var(--spacing-md); padding-bottom: var(--spacing-xs); border-bottom: 3px solid var(--color-accent); }
        h3 { font-size: 1.4rem; color: var(--color-primary); margin-top: var(--spacing-lg); margin-bottom: var(--spacing-sm); }
        h4 { font-size: 1.1rem; color: var(--color-primary-dark); margin-top: var(--spacing-md); margin-bottom: var(--spacing-sm); }
        p { margin-bottom: var(--spacing-md); color: var(--color-text); }
        a { color: var(--color-link); text-decoration: none; transition: color 0.2s; }
        a:hover { color: var(--color-link-hover); text-decoration: underline; }
        ul, ol { margin-left: var(--spacing-lg); margin-bottom: var(--spacing-md); }
        li { margin-bottom: var(--spacing-xs); color: var(--color-text); }
        pre { background-color: var(--color-code-bg); border: 1px solid var(--color-border); border-radius: var(--border-radius); padding: var(--spacing-md); overflow-x: auto; margin-bottom: var(--spacing-md); font-family: var(--font-mono); font-size: 0.9rem; line-height: 1.5; }
        code { font-family: var(--font-mono); font-size: 0.9em; background-color: var(--color-code-bg); padding: 0.2em 0.4em; border-radius: 3px; }
        pre code { background-color: transparent; padding: 0; }
        table { width: 100%; border-collapse: collapse; margin-bottom: var(--spacing-md); font-size: 0.95rem; }
        th, td { border: 1px solid var(--color-border); padding: var(--spacing-sm); text-align: left; }
        th { background-color: var(--color-bg-alt); font-weight: 600; color: var(--color-primary); }
        blockquote { border-left: 4px solid var(--color-accent); padding-left: var(--spacing-md); margin: var(--spacing-md) 0; color: var(--color-text-light); font-style: italic; background-color: var(--color-bg-alt); padding: var(--spacing-md); border-radius: var(--border-radius); }
        .mermaid { text-align: center; margin: var(--spacing-lg) 0; background-color: var(--color-bg-alt); padding: var(--spacing-md); border-radius: var(--border-radius); }
        details { background-color: var(--color-bg-alt); border: 1px solid var(--color-border); border-radius: var(--border-radius); padding: var(--spacing-md); margin-bottom: var(--spacing-md); }
        summary { cursor: pointer; font-weight: 600; color: var(--color-primary); user-select: none; padding: var(--spacing-xs); margin: calc(-1 * var(--spacing-md)); padding: var(--spacing-md); border-radius: var(--border-radius); }
        summary:hover { background-color: rgba(123, 44, 191, 0.1); }
        details[open] summary { margin-bottom: var(--spacing-md); border-bottom: 1px solid var(--color-border); }
        .navigation { display: flex; justify-content: space-between; gap: var(--spacing-md); margin: var(--spacing-xl) 0; padding-top: var(--spacing-lg); border-top: 2px solid var(--color-border); }
        .nav-button { flex: 1; padding: var(--spacing-md); background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%); color: white; border-radius: var(--border-radius); text-align: center; font-weight: 600; transition: transform 0.2s, box-shadow 0.2s; box-shadow: var(--box-shadow); }
        .nav-button:hover { transform: translateY(-2px); box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15); text-decoration: none; }
        footer { margin-top: var(--spacing-xl); padding: var(--spacing-lg) var(--spacing-md); background-color: var(--color-bg-alt); border-top: 1px solid var(--color-border); text-align: center; font-size: 0.9rem; color: var(--color-text-light); }
        @media (max-width: 768px) { h1 { font-size: 1.5rem; } h2 { font-size: 1.4rem; } h3 { font-size: 1.2rem; } .meta { font-size: 0.85rem; } .navigation { flex-direction: column; } table { font-size: 0.85rem; } th, td { padding: var(--spacing-xs); } }
    </style>

    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
        mermaid.initialize({ startOnLoad: true, theme: 'default' });
    </script>
    <script>
        MathJax = {
            tex: { inlineMath: [['$', '$'], ['\\(', '\\)']], displayMath: [['$$', '$$'], ['\\[', '\\]']], processEscapes: true, processEnvironments: true },
            options: { skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'], ignoreHtmlClass: 'mermaid' }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" async></script>
</head>
<body>
    <header>
        <div class="header-content">
            <h1>ç¬¬4ç« ï¼šTransformerã«ã‚ˆã‚‹æ™‚ç³»åˆ—äºˆæ¸¬</h1>
            <p class="subtitle">Temporal Fusion Transformerã€Informerã€é•·æœŸäºˆæ¸¬ã¸ã®æœ€å…ˆç«¯ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ</p>
            <div class="meta">
                <span class="meta-item">ğŸ“– èª­äº†æ™‚é–“: 30-35åˆ†</span>
                <span class="meta-item">ğŸ“Š é›£æ˜“åº¦: ä¸Šç´š</span>
                <span class="meta-item">ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹: 8å€‹</span>
                <span class="meta-item">ğŸ“ æ¼”ç¿’å•é¡Œ: 5å•</span>
            </div>
        </div>
    </header>

    <main class="container">

<h2>å­¦ç¿’ç›®æ¨™</h2>
<p>ã“ã®ç« ã‚’èª­ã‚€ã“ã¨ã§ã€ä»¥ä¸‹ã‚’ç¿’å¾—ã§ãã¾ã™ï¼š</p>
<ul>
<li>âœ… æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã™ã‚‹Transformerã®Positional Encodingã‚’ç†è§£ã™ã‚‹</li>
<li>âœ… Temporal Attentionãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã®ä»•çµ„ã¿ã¨å®Ÿè£…æ–¹æ³•ã‚’ç¿’å¾—ã™ã‚‹</li>
<li>âœ… Multi-horizonäºˆæ¸¬ã®æ¦‚å¿µã¨å®Ÿè£…ã‚’ç†è§£ã™ã‚‹</li>
<li>âœ… Temporal Fusion Transformerï¼ˆTFTï¼‰ã®å®Œå…¨ãªã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’ç†è§£ã™ã‚‹</li>
<li>âœ… Variable Selection Networkã¨Interpretable Attentionã‚’å®Ÿè£…ã§ãã‚‹</li>
<li>âœ… Informerã®ProbSparse Attentionã¨é•·æœŸäºˆæ¸¬æ‰‹æ³•ã‚’ç¿’å¾—ã™ã‚‹</li>
<li>âœ… Autoformerã€FEDformerã€Patch TSTãªã©ã®æœ€æ–°ãƒ¢ãƒ‡ãƒ«ã‚’ç†è§£ã™ã‚‹</li>
<li>âœ… pytorch-forecastingã‚’ç”¨ã„ãŸæœ¬æ ¼çš„ãªäºˆæ¸¬ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’æ§‹ç¯‰ã§ãã‚‹</li>
</ul>

<hr>

<h2>4.1 Transformer for æ™‚ç³»åˆ—</h2>

<h3>æ™‚ç³»åˆ—ã«ãŠã‘ã‚‹Transformerã®é©ç”¨</h3>

<p><strong>Transformer</strong>ã¯ã€å…ƒã€…è‡ªç„¶è¨€èªå‡¦ç†ã®ãŸã‚ã«è¨­è¨ˆã•ã‚Œã¾ã—ãŸãŒã€æ™‚ç³»åˆ—äºˆæ¸¬ã«ãŠã„ã¦ã‚‚å¼·åŠ›ãªãƒ„ãƒ¼ãƒ«ã¨ãªã£ã¦ã„ã¾ã™ã€‚Attentionæ©Ÿæ§‹ã«ã‚ˆã‚Šã€é•·æœŸä¾å­˜é–¢ä¿‚ã‚’åŠ¹ç‡çš„ã«æ‰ãˆã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚</p>

<blockquote>
<p>ã€ŒTransformerã®Self-Attentionã¯ã€æ™‚ç³»åˆ—ã«ãŠã‘ã‚‹ä»»æ„ã®æ™‚ç‚¹é–“ã®ä¾å­˜é–¢ä¿‚ã‚’ç›´æ¥çš„ã«ãƒ¢ãƒ‡ãƒ«åŒ–ã§ãã‚‹ã€‚ã“ã‚Œã¯RNN/LSTMã®é€æ¬¡å‡¦ç†ã®åˆ¶ç´„ã‚’è¶…ãˆã‚‹ã€</p>
</blockquote>

<h3>Positional Encoding for Time</h3>

<p>æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã§ã¯ã€æ™‚é–“çš„ãªé †åºæƒ…å ±ãŒæ¥µã‚ã¦é‡è¦ã§ã™ã€‚Transformerã«ã¯å†å¸°æ§‹é€ ãŒãªã„ãŸã‚ã€<strong>Positional Encoding</strong>ã§æ™‚é–“æƒ…å ±ã‚’æ˜ç¤ºçš„ã«æ³¨å…¥ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚</p>

<h4>æ¨™æº–çš„ãªSinusoidal Encoding</h4>

<p>$$
\begin{align}
PE_{(pos, 2i)} &= \sin\left(\frac{pos}{10000^{2i/d_{model}}}\right) \\
PE_{(pos, 2i+1)} &= \cos\left(\frac{pos}{10000^{2i/d_{model}}}\right)
\end{align}
$$</p>

<p>ã“ã“ã§ï¼š</p>
<ul>
<li>$pos$ï¼šæ™‚é–“ã‚¹ãƒ†ãƒƒãƒ—ã®ä½ç½®</li>
<li>$i$ï¼šæ¬¡å…ƒã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹</li>
<li>$d_{model}$ï¼šãƒ¢ãƒ‡ãƒ«ã®æ¬¡å…ƒæ•°</li>
</ul>

<h4>æ™‚ç³»åˆ—ç‰¹æœ‰ã®Temporal Encoding</h4>

<p>æ™‚ç³»åˆ—ã§ã¯ã€ã•ã‚‰ã«ä»¥ä¸‹ã®æƒ…å ±ã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã™ã‚‹ã“ã¨ãŒæœ‰åŠ¹ã§ã™ï¼š</p>
<ul>
<li><strong>çµ¶å¯¾æ™‚åˆ»</strong>ï¼šæ™‚åˆ»ã€æ—¥ä»˜ã€æ›œæ—¥ã€æœˆãªã©</li>
<li><strong>ç›¸å¯¾ä½ç½®</strong>ï¼šç¾åœ¨ã‹ã‚‰ã®ç›¸å¯¾çš„ãªæ™‚é–“è·é›¢</li>
<li><strong>å‘¨æœŸæ€§</strong>ï¼šæ—¥æ¬¡ã€é€±æ¬¡ã€å¹´æ¬¡ãªã©ã®å‘¨æœŸãƒ‘ã‚¿ãƒ¼ãƒ³</li>
</ul>

<h3>Temporal Attention</h3>

<p>æ™‚ç³»åˆ—ç”¨ã®Attentionæ©Ÿæ§‹ã§ã¯ã€é€šå¸¸ã®Self-Attentionã«åŠ ãˆã¦ã€æ™‚é–“çš„ãªæ§‹é€ ã‚’è€ƒæ…®ã—ãŸå·¥å¤«ãŒæ–½ã•ã‚Œã¾ã™ã€‚</p>

<h4>Masked Temporal Attention</h4>

<p>äºˆæ¸¬ã‚¿ã‚¹ã‚¯ã§ã¯ã€æœªæ¥ã®æƒ…å ±ã‚’è¦‹ã¦ã¯ã„ã‘ãªã„ãŸã‚ã€<strong>Causal Masking</strong>ã‚’é©ç”¨ã—ã¾ã™ï¼š</p>

<p>$$
\text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}} + M\right)V
$$</p>

<p>ã“ã“ã§ã€ãƒã‚¹ã‚¯è¡Œåˆ—$M$ã¯ï¼š</p>
<p>$$
M_{ij} = \begin{cases}
0 & \text{if } i \geq j \\
-\infty & \text{if } i < j
\end{cases}
$$</p>

<h3>Multi-horizon Forecasting</h3>

<p><strong>Multi-horizon forecasting</strong>ã¯ã€è¤‡æ•°ã®å°†æ¥æ™‚ç‚¹ã‚’åŒæ™‚ã«äºˆæ¸¬ã™ã‚‹ã‚¿ã‚¹ã‚¯ã§ã™ã€‚Transformerã®decoderã‚’ä½¿ã„ã€autoregressiveæ–¹å¼ã¾ãŸã¯ç›´æ¥äºˆæ¸¬æ–¹å¼ã§å®Ÿè£…ã—ã¾ã™ã€‚</p>

<div class="mermaid">
graph LR
    A[Past Context<br/>t-n...t] --> B[Encoder<br/>Self-Attention]
    B --> C[Decoder<br/>Masked Attention]
    C --> D[Multi-step Output<br/>t+1...t+h]

    style A fill:#e3f2fd
    style B fill:#fff3e0
    style C fill:#e8f5e9
    style D fill:#f3e5f5
</div>

<h3>Vanilla Transformer Example</h3>

<pre><code class="language-python">import torch
import torch.nn as nn
import numpy as np
import matplotlib.pyplot as plt

class PositionalEncoding(nn.Module):
    """æ™‚ç³»åˆ—ç”¨ã®Positional Encoding"""

    def __init__(self, d_model, max_len=5000):
        super().__init__()

        # Positional encodingã®è¨ˆç®—
        position = torch.arange(max_len).unsqueeze(1)
        div_term = torch.exp(torch.arange(0, d_model, 2) *
                            (-np.log(10000.0) / d_model))

        pe = torch.zeros(max_len, 1, d_model)
        pe[:, 0, 0::2] = torch.sin(position * div_term)
        pe[:, 0, 1::2] = torch.cos(position * div_term)

        self.register_buffer('pe', pe)

    def forward(self, x):
        """
        Args:
            x: Tensor of shape (seq_len, batch_size, d_model)
        """
        x = x + self.pe[:x.size(0)]
        return x


class TimeSeriesTransformer(nn.Module):
    """æ™‚ç³»åˆ—äºˆæ¸¬ç”¨ã®Transformer"""

    def __init__(self, input_dim, d_model, nhead, num_encoder_layers,
                 num_decoder_layers, dim_feedforward, output_len, dropout=0.1):
        super().__init__()

        self.d_model = d_model
        self.output_len = output_len

        # Input embedding
        self.encoder_input_layer = nn.Linear(input_dim, d_model)
        self.decoder_input_layer = nn.Linear(input_dim, d_model)

        # Positional encoding
        self.pos_encoder = PositionalEncoding(d_model)

        # Transformer
        self.transformer = nn.Transformer(
            d_model=d_model,
            nhead=nhead,
            num_encoder_layers=num_encoder_layers,
            num_decoder_layers=num_decoder_layers,
            dim_feedforward=dim_feedforward,
            dropout=dropout,
            batch_first=False
        )

        # Output layer
        self.output_layer = nn.Linear(d_model, input_dim)

    def generate_square_subsequent_mask(self, sz):
        """Causal maskã®ç”Ÿæˆ"""
        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)
        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(
            mask == 1, float(0.0))
        return mask

    def forward(self, src, tgt):
        """
        Args:
            src: (seq_len, batch_size, input_dim) - éå»ãƒ‡ãƒ¼ã‚¿
            tgt: (output_len, batch_size, input_dim) - ãƒ‡ã‚³ãƒ¼ãƒ€å…¥åŠ›
        """
        # Embedding
        src = self.encoder_input_layer(src) * np.sqrt(self.d_model)
        tgt = self.decoder_input_layer(tgt) * np.sqrt(self.d_model)

        # Positional encoding
        src = self.pos_encoder(src)
        tgt = self.pos_encoder(tgt)

        # Causal mask
        tgt_mask = self.generate_square_subsequent_mask(tgt.size(0)).to(tgt.device)

        # Transformer
        output = self.transformer(src, tgt, tgt_mask=tgt_mask)

        # Output projection
        output = self.output_layer(output)

        return output


# ãƒ¢ãƒ‡ãƒ«ã®ä½¿ç”¨ä¾‹
def train_transformer_example():
    """Transformerã®è¨“ç·´ä¾‹"""

    # åˆæˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆï¼ˆã‚µã‚¤ãƒ³æ³¢ + ãƒã‚¤ã‚ºï¼‰
    def generate_data(n_samples=1000, seq_len=50, output_len=10):
        X, y = [], []
        t = np.linspace(0, 100, n_samples + seq_len + output_len)
        data = np.sin(t * 0.1) + np.random.normal(0, 0.1, len(t))

        for i in range(n_samples):
            X.append(data[i:i+seq_len])
            y.append(data[i+seq_len:i+seq_len+output_len])

        return np.array(X), np.array(y)

    # ãƒ‡ãƒ¼ã‚¿æº–å‚™
    X_train, y_train = generate_data(n_samples=800)
    X_test, y_test = generate_data(n_samples=200)

    X_train = torch.FloatTensor(X_train).unsqueeze(-1)  # (800, 50, 1)
    y_train = torch.FloatTensor(y_train).unsqueeze(-1)  # (800, 10, 1)
    X_test = torch.FloatTensor(X_test).unsqueeze(-1)
    y_test = torch.FloatTensor(y_test).unsqueeze(-1)

    # ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰
    model = TimeSeriesTransformer(
        input_dim=1,
        d_model=64,
        nhead=4,
        num_encoder_layers=2,
        num_decoder_layers=2,
        dim_feedforward=256,
        output_len=10,
        dropout=0.1
    )

    criterion = nn.MSELoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

    # è¨“ç·´
    n_epochs = 50
    batch_size = 32

    for epoch in range(n_epochs):
        model.train()
        total_loss = 0

        # ãƒŸãƒ‹ãƒãƒƒãƒè¨“ç·´
        for i in range(0, len(X_train), batch_size):
            batch_X = X_train[i:i+batch_size].transpose(0, 1)  # (seq_len, batch, 1)
            batch_y = y_train[i:i+batch_size].transpose(0, 1)  # (output_len, batch, 1)

            # ãƒ‡ã‚³ãƒ¼ãƒ€å…¥åŠ›ï¼ˆteacher forcingç”¨ï¼‰
            # æœ€åˆã®ã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ—ã¯ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã®æœ€å¾Œã®å€¤ã‚’ä½¿ç”¨
            decoder_input = torch.cat([
                batch_X[-1:],  # æœ€å¾Œã®å€¤
                batch_y[:-1]   # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®æœ€åˆã‹ã‚‰n-1å€‹
            ], dim=0)

            optimizer.zero_grad()
            output = model(batch_X, decoder_input)
            loss = criterion(output, batch_y)
            loss.backward()
            optimizer.step()

            total_loss += loss.item()

        if (epoch + 1) % 10 == 0:
            print(f'Epoch [{epoch+1}/{n_epochs}], Loss: {total_loss/len(X_train):.6f}')

    # è©•ä¾¡
    model.eval()
    with torch.no_grad():
        # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§äºˆæ¸¬ï¼ˆautoregressiveãƒ¢ãƒ¼ãƒ‰ï¼‰
        test_X = X_test[0:1].transpose(0, 1)  # (50, 1, 1)

        # åˆæœŸãƒ‡ã‚³ãƒ¼ãƒ€å…¥åŠ›
        decoder_input = test_X[-1:]  # (1, 1, 1)
        predictions = []

        for _ in range(10):
            output = model(test_X, decoder_input)
            next_pred = output[-1:]  # æœ€å¾Œã®äºˆæ¸¬
            predictions.append(next_pred.squeeze().item())
            decoder_input = torch.cat([decoder_input, next_pred], dim=0)

        # å¯è¦–åŒ–
        plt.figure(figsize=(12, 5))
        plt.plot(range(50), X_test[0].numpy(), label='Input', marker='o')
        plt.plot(range(50, 60), y_test[0].numpy(), label='True Future', marker='s')
        plt.plot(range(50, 60), predictions, label='Predicted', marker='^')
        plt.axvline(x=50, color='gray', linestyle='--', alpha=0.5)
        plt.xlabel('Time Step')
        plt.ylabel('Value')
        plt.title('Transformer Time Series Forecasting')
        plt.legend()
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        plt.savefig('transformer_forecast.png', dpi=150, bbox_inches='tight')
        plt.close()

        print(f"äºˆæ¸¬çµæœã‚’ä¿å­˜ã—ã¾ã—ãŸ: transformer_forecast.png")
        print(f"MSE: {np.mean((np.array(predictions) - y_test[0].numpy().flatten())**2):.6f}")

if __name__ == "__main__":
    train_transformer_example()
</code></pre>

<hr>

<h2>4.2 Temporal Fusion Transformer (TFT)</h2>

<h3>TFTã®æ¦‚è¦</h3>

<p><strong>Temporal Fusion Transformer (TFT)</strong>ã¯ã€Google ResearchãŒ2021å¹´ã«ç™ºè¡¨ã—ãŸæ™‚ç³»åˆ—äºˆæ¸¬ã«ç‰¹åŒ–ã—ãŸTransformerã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§ã™ã€‚è§£é‡ˆå¯èƒ½æ€§ã¨é«˜ç²¾åº¦ã‚’ä¸¡ç«‹ã—ãŸè¨­è¨ˆãŒç‰¹å¾´ã§ã™ã€‚</p>

<blockquote>
<p>ã€ŒTFTã¯ã€Variable Selection Networkã€LSTM-based Encoder-Decoderã€Interpretable Multi-head Attentionã‚’çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã§ã€äºˆæ¸¬ç²¾åº¦ã¨è§£é‡ˆå¯èƒ½æ€§ã‚’åŒæ™‚ã«å®Ÿç¾ã™ã‚‹ã€</p>
</blockquote>

<h3>TFT Architecture</h3>

<p>TFTã¯ä»¥ä¸‹ã®ä¸»è¦ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã§æ§‹æˆã•ã‚Œã¾ã™ï¼š</p>

<div class="mermaid">
graph TB
    A[Input Variables] --> B[Variable Selection Network]
    B --> C[Static Covariate Encoder]
    B --> D[Temporal Processing]

    D --> E[LSTM Encoder<br/>Past]
    D --> F[LSTM Decoder<br/>Future]

    C --> G[Context Vector]
    E --> G
    F --> G

    G --> H[Gated Residual Network]
    H --> I[Multi-head Attention]
    I --> J[Feed-Forward]
    J --> K[Quantile Output]

    style A fill:#e3f2fd
    style B fill:#fff3e0
    style I fill:#e8f5e9
    style K fill:#f3e5f5
</div>

<h3>Variable Selection Network</h3>

<p><strong>Variable Selection Network (VSN)</strong>ã¯ã€å…¥åŠ›å¤‰æ•°ã®é‡è¦åº¦ã‚’å­¦ç¿’ã—ã€è‡ªå‹•çš„ã«ç‰¹å¾´é¸æŠã‚’è¡Œã„ã¾ã™ã€‚</p>

<p>å„å¤‰æ•°$v_i$ã«å¯¾ã™ã‚‹é‡è¦åº¦é‡ã¿$w_i$ã‚’è¨ˆç®—ï¼š</p>

<p>$$
\mathbf{w} = \text{Softmax}(\text{GRN}(\mathbf{v}_1, \ldots, \mathbf{v}_n))
$$</p>

<p>é¸æŠã•ã‚ŒãŸå¤‰æ•°ï¼š</p>
<p>$$
\mathbf{\xi} = \sum_{i=1}^{n} w_i \cdot \text{GRN}(\mathbf{v}_i)
$$</p>

<p>ã“ã“ã§ã€<strong>GRN (Gated Residual Network)</strong>ã¯ã€ä»¥ä¸‹ã®æ§‹é€ ã‚’æŒã¤ãƒ–ãƒ­ãƒƒã‚¯ã§ã™ï¼š</p>

<p>$$
\text{GRN}(\mathbf{a}, \mathbf{c}) = \text{LayerNorm}(\mathbf{a} + \text{GLU}(\eta_1)) \\
\eta_1 = \mathbf{W}_1\eta_2 + \mathbf{b}_1 \\
\eta_2 = \text{ELU}(\mathbf{W}_2\mathbf{a} + \mathbf{W}_3\mathbf{c} + \mathbf{b}_2)
$$</p>

<h3>Interpretable Multi-head Attention</h3>

<p>TFTã®Attentionæ©Ÿæ§‹ã¯ã€å„æ™‚ç‚¹ã®é‡è¦åº¦ã‚’å¯è¦–åŒ–ã§ãã‚‹ã‚ˆã†ã«è¨­è¨ˆã•ã‚Œã¦ã„ã¾ã™ï¼š</p>

<p>$$
\text{Attention}(Q, K, V) = \text{Softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V
$$</p>

<p>Attention weightsã‚’å¹³å‡åŒ–ã™ã‚‹ã“ã¨ã§ã€å„æ™‚ç‚¹ã®é‡è¦åº¦ã‚’è§£é‡ˆï¼š</p>

<p>$$
\alpha_t = \frac{1}{H}\sum_{h=1}^{H} \text{Softmax}\left(\frac{Q_hK_h^T}{\sqrt{d_k}}\right)_{t,:}
$$</p>

<h3>pytorch-forecasting Library</h3>

<p><code>pytorch-forecasting</code>ã¯ã€TFTã‚’å«ã‚€æ™‚ç³»åˆ—äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã‚’ç°¡å˜ã«ä½¿ãˆã‚‹ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§ã™ã€‚</p>

<pre><code class="language-python">import pandas as pd
import numpy as np
import torch
from pytorch_forecasting import TimeSeriesDataSet, TemporalFusionTransformer
from pytorch_forecasting.data import GroupNormalizer
from pytorch_forecasting.metrics import QuantileLoss
from pytorch_lightning import Trainer
import matplotlib.pyplot as plt

def create_tft_example():
    """TFTã‚’ä½¿ã£ãŸäºˆæ¸¬ä¾‹"""

    # åˆæˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    np.random.seed(42)
    n_samples = 1000

    data = []
    for store_id in range(5):
        for day in range(n_samples):
            # ãƒˆãƒ¬ãƒ³ãƒ‰ + å­£ç¯€æ€§ + ãƒã‚¤ã‚º
            trend = day * 0.1
            seasonality = 10 * np.sin(2 * np.pi * day / 30)  # æœˆæ¬¡å‘¨æœŸ
            weekly = 5 * np.sin(2 * np.pi * day / 7)  # é€±æ¬¡å‘¨æœŸ
            noise = np.random.normal(0, 2)
            store_effect = store_id * 5

            value = 50 + trend + seasonality + weekly + noise + store_effect

            data.append({
                'time_idx': day,
                'store_id': str(store_id),
                'value': max(0, value),
                'day_of_week': day % 7,
                'day_of_month': (day % 30) + 1,
                'month': ((day // 30) % 12) + 1
            })

    df = pd.DataFrame(data)

    # TimeSeriesDataSetã®ä½œæˆ
    max_encoder_length = 60  # éå»60æ—¥ã‚’ä½¿ç”¨
    max_prediction_length = 20  # 20æ—¥å…ˆã‚’äºˆæ¸¬
    training_cutoff = df["time_idx"].max() - max_prediction_length

    training = TimeSeriesDataSet(
        df[lambda x: x.time_idx <= training_cutoff],
        time_idx="time_idx",
        target="value",
        group_ids=["store_id"],
        min_encoder_length=max_encoder_length // 2,
        max_encoder_length=max_encoder_length,
        min_prediction_length=1,
        max_prediction_length=max_prediction_length,
        static_categoricals=["store_id"],
        time_varying_known_reals=["time_idx", "day_of_week", "day_of_month", "month"],
        time_varying_unknown_reals=["value"],
        target_normalizer=GroupNormalizer(
            groups=["store_id"], transformation="softplus"
        ),
        add_relative_time_idx=True,
        add_target_scales=True,
        add_encoder_length=True,
    )

    # Validation dataset
    validation = TimeSeriesDataSet.from_dataset(
        training, df, predict=True, stop_randomization=True
    )

    # DataLoaders
    batch_size = 64
    train_dataloader = training.to_dataloader(
        train=True, batch_size=batch_size, num_workers=0
    )
    val_dataloader = validation.to_dataloader(
        train=False, batch_size=batch_size, num_workers=0
    )

    # TFTãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰
    tft = TemporalFusionTransformer.from_dataset(
        training,
        learning_rate=0.03,
        hidden_size=32,
        attention_head_size=1,
        dropout=0.1,
        hidden_continuous_size=16,
        output_size=7,  # quantile outputã®æ•°
        loss=QuantileLoss(),
        log_interval=10,
        reduce_on_plateau_patience=4,
    )

    print(f"TFTãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {tft.size()/1e3:.1f}k")

    # è¨“ç·´
    trainer = Trainer(
        max_epochs=30,
        accelerator="cpu",
        enable_model_summary=True,
        gradient_clip_val=0.1,
        limit_train_batches=30,
        enable_checkpointing=True,
    )

    trainer.fit(
        tft,
        train_dataloaders=train_dataloader,
        val_dataloaders=val_dataloader,
    )

    # äºˆæ¸¬
    best_model = tft.load_from_checkpoint(trainer.checkpoint_callback.best_model_path)

    # æœ€åˆã®ãƒãƒƒãƒã§äºˆæ¸¬
    predictions = best_model.predict(val_dataloader, return_x=True)

    # å¯è¦–åŒ–
    for idx in range(min(3, len(predictions.output))):
        best_model.plot_prediction(
            predictions.x, predictions.output, idx=idx, add_loss_to_title=True
        )
        plt.savefig(f'tft_prediction_{idx}.png', dpi=150, bbox_inches='tight')
        plt.close()

    print(f"äºˆæ¸¬çµæœã‚’ä¿å­˜ã—ã¾ã—ãŸ: tft_prediction_*.png")

    # Variable importanceã®å¯è¦–åŒ–
    interpretation = best_model.interpret_output(predictions.output, reduction="sum")

    # Attention weights
    fig, ax = plt.subplots(figsize=(10, 5))
    attention = interpretation["attention"].mean(0).cpu().numpy()

    im = ax.imshow(attention, cmap='YlOrRd', aspect='auto')
    ax.set_xlabel('Encoder Time Steps')
    ax.set_ylabel('Decoder Time Steps')
    ax.set_title('TFT Attention Weights (Interpretability)')
    plt.colorbar(im, ax=ax)
    plt.tight_layout()
    plt.savefig('tft_attention.png', dpi=150, bbox_inches='tight')
    plt.close()

    print(f"Attention weightsã‚’ä¿å­˜ã—ã¾ã—ãŸ: tft_attention.png")

    # Variable importance
    importance = best_model.interpret_output(
        predictions.output, reduction="sum"
    )

    return best_model, predictions, importance

if __name__ == "__main__":
    model, preds, importance = create_tft_example()
</code></pre>

<hr>

<h2>4.3 Informer</h2>

<h3>Informerã®å‹•æ©Ÿ</h3>

<p><strong>Informer</strong>ã¯ã€é•·æœŸæ™‚ç³»åˆ—äºˆæ¸¬ï¼ˆLSTF: Long Sequence Time-series Forecastingï¼‰ã®ãŸã‚ã«è¨­è¨ˆã•ã‚ŒãŸTransformerã§ã™ã€‚æ¨™æº–çš„ãªTransformerã®è¨ˆç®—é‡ã¨ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®å•é¡Œã‚’è§£æ±ºã—ã¾ã™ã€‚</p>

<blockquote>
<p>ã€Œæ¨™æº–çš„ãªTransformerã®Attentionã¯$O(L^2)$ã®è¨ˆç®—é‡ã‚’æŒã¤ãŸã‚ã€é•·ã„ç³»åˆ—ï¼ˆä¾‹ï¼š1000ã‚¹ãƒ†ãƒƒãƒ—ä»¥ä¸Šï¼‰ã§ã¯å®Ÿç”¨çš„ã§ãªã„ã€‚Informerã¯ProbSparse Attentionã«ã‚ˆã‚Š$O(L\log L)$ã«å‰Šæ¸›ã™ã‚‹ã€</p>
</blockquote>

<h3>ProbSparse Attention</h3>

<p><strong>ProbSparse Self-Attention</strong>ã¯ã€é‡è¦ãªã‚¯ã‚¨ãƒªã®ã¿ã‚’é¸æŠçš„ã«è¨ˆç®—ã™ã‚‹åŠ¹ç‡çš„ãªAttentionæ©Ÿæ§‹ã§ã™ã€‚</p>

<h4>Query Sparsity Measurement</h4>

<p>å„ã‚¯ã‚¨ãƒª$q_i$ã®ã€Œé‡è¦åº¦ã€ã‚’ã‚¹ãƒ‘ãƒ¼ã‚¹æ€§ã§æ¸¬å®šï¼š</p>

<p>$$
M(q_i, K) = \ln \sum_{j=1}^{L_k} e^{\frac{q_i k_j^T}{\sqrt{d}}} - \frac{1}{L_k}\sum_{j=1}^{L_k}\frac{q_i k_j^T}{\sqrt{d}}
$$</p>

<p>ã“ã®å€¤ãŒå¤§ãã„ã»ã©ã€ã‚¯ã‚¨ãƒªã¯ç‰¹å®šã®ã‚­ãƒ¼ã«é›†ä¸­ã—ã¦ãŠã‚Šï¼ˆã‚¹ãƒ‘ãƒ¼ã‚¹ï¼‰ã€é‡è¦ã§ã™ã€‚</p>

<h4>Top-u Selection</h4>

<p>ä¸Šä½$u$å€‹ã®ã‚¯ã‚¨ãƒªã®ã¿ã§Attentionã‚’è¨ˆç®—ï¼š</p>

<p>$$
\bar{Q} = \text{Top-}u(M(q_i, K))
$$</p>

<p>$$
\text{ProbSparseAttention}(\bar{Q}, K, V) = \text{Softmax}\left(\frac{\bar{Q}K^T}{\sqrt{d}}\right)V
$$</p>

<p>ä»–ã®ã‚¯ã‚¨ãƒªã¯å¹³å‡å€¤ã§åŸ‹ã‚ã‚‹ï¼š</p>
<p>$$
\text{Attention}(Q, K, V) = [\text{ProbSparseAttention}(\bar{Q}, K, V); \bar{V}]
$$</p>

<h3>Self-Attention Distilling</h3>

<p>Informerã¯ã€ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€å±¤ã”ã¨ã«ç³»åˆ—é•·ã‚’åŠåˆ†ã«ã™ã‚‹<strong>Distillingæ“ä½œ</strong>ã‚’é©ç”¨ã—ã¾ã™ï¼š</p>

<ol>
<li>Self-Attentionå±¤ã‚’é€šé</li>
<li>1D Convolution + Max Poolingã§ç³»åˆ—é•·ã‚’åŠåˆ†ã«</li>
<li>æ¬¡ã®å±¤ã¸</li>
</ol>

<p>ã“ã‚Œã«ã‚ˆã‚Šã€$L \to L/2 \to L/4 \to \ldots$ã¨ç³»åˆ—é•·ãŒæ¸›å°‘ã—ã€ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ãŒå‘ä¸Šã—ã¾ã™ã€‚</p>

<div class="mermaid">
graph LR
    A[Input L] --> B[ProbSparse Attn]
    B --> C[Distilling<br/>L/2]
    C --> D[ProbSparse Attn]
    D --> E[Distilling<br/>L/4]
    E --> F[...]

    style A fill:#e3f2fd
    style C fill:#fff3e0
    style E fill:#fff3e0
    style F fill:#e8f5e9
</div>

<h3>Informer Implementation</h3>

<pre><code class="language-python">import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import matplotlib.pyplot as plt

class ProbAttention(nn.Module):
    """ProbSparse Self-Attention"""

    def __init__(self, d_model, n_heads, factor=5):
        super().__init__()
        self.d_model = d_model
        self.n_heads = n_heads
        self.d_k = d_model // n_heads
        self.factor = factor

        self.W_q = nn.Linear(d_model, d_model)
        self.W_k = nn.Linear(d_model, d_model)
        self.W_v = nn.Linear(d_model, d_model)
        self.W_o = nn.Linear(d_model, d_model)

    def forward(self, queries, keys, values, attn_mask=None):
        B, L_q, _ = queries.shape
        _, L_k, _ = keys.shape

        # Linear projection
        Q = self.W_q(queries).view(B, L_q, self.n_heads, self.d_k)
        K = self.W_k(keys).view(B, L_k, self.n_heads, self.d_k)
        V = self.W_v(values).view(B, L_k, self.n_heads, self.d_k)

        # Transpose for multi-head attention
        Q = Q.transpose(1, 2)  # (B, n_heads, L_q, d_k)
        K = K.transpose(1, 2)
        V = V.transpose(1, 2)

        # ProbSparse Attention
        # ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ•°
        u = self.factor * int(np.ceil(np.log(L_q)))
        u = min(u, L_q)

        # ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆç°¡æ˜“ç‰ˆã€æœ¬æ¥ã¯ã‚¹ãƒ‘ãƒ¼ã‚¹æ€§ã§é¸æŠï¼‰
        Q_sample = Q[:, :, :u, :]

        # Attention scores
        scores = torch.matmul(Q_sample, K.transpose(-2, -1)) / np.sqrt(self.d_k)

        if attn_mask is not None:
            scores = scores.masked_fill(attn_mask[:, :, :u, :] == 0, -1e9)

        attn = F.softmax(scores, dim=-1)

        # Apply attention to values
        out_sample = torch.matmul(attn, V)  # (B, n_heads, u, d_k)

        # æ®‹ã‚Šã¯å¹³å‡å€¤ã§åŸ‹ã‚ã‚‹
        V_mean = V.mean(dim=2, keepdim=True).expand(-1, -1, L_q - u, -1)
        out = torch.cat([out_sample, V_mean], dim=2)

        # Reshape and project
        out = out.transpose(1, 2).contiguous().view(B, L_q, self.d_model)
        out = self.W_o(out)

        return out, attn


class Distilling(nn.Module):
    """Distillingæ“ä½œï¼ˆç³»åˆ—é•·ã‚’åŠåˆ†ã«ï¼‰"""

    def __init__(self, d_model):
        super().__init__()
        self.conv = nn.Conv1d(d_model, d_model, kernel_size=3, padding=1)
        self.norm = nn.LayerNorm(d_model)
        self.activation = nn.ELU()
        self.maxpool = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)

    def forward(self, x):
        # x: (B, L, d_model)
        x = x.transpose(1, 2)  # (B, d_model, L)
        x = self.conv(x)
        x = self.activation(x)
        x = self.maxpool(x)
        x = x.transpose(1, 2)  # (B, L/2, d_model)
        x = self.norm(x)
        return x


class InformerEncoder(nn.Module):
    """Informerã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€"""

    def __init__(self, d_model, n_heads, d_ff, n_layers, dropout=0.1):
        super().__init__()

        self.attn_layers = nn.ModuleList([
            ProbAttention(d_model, n_heads) for _ in range(n_layers)
        ])

        self.distilling_layers = nn.ModuleList([
            Distilling(d_model) for _ in range(n_layers - 1)
        ])

        self.ffn_layers = nn.ModuleList([
            nn.Sequential(
                nn.Linear(d_model, d_ff),
                nn.ReLU(),
                nn.Dropout(dropout),
                nn.Linear(d_ff, d_model),
                nn.Dropout(dropout)
            ) for _ in range(n_layers)
        ])

        self.norm_layers = nn.ModuleList([
            nn.LayerNorm(d_model) for _ in range(2 * n_layers)
        ])

    def forward(self, x):
        attns = []

        for i, (attn, ffn) in enumerate(zip(self.attn_layers, self.ffn_layers)):
            # Self-attention
            new_x, attn_weights = attn(x, x, x)
            x = self.norm_layers[2*i](x + new_x)
            attns.append(attn_weights)

            # FFN
            new_x = ffn(x)
            x = self.norm_layers[2*i+1](x + new_x)

            # Distillingï¼ˆæœ€å¾Œã®å±¤ä»¥å¤–ï¼‰
            if i < len(self.distilling_layers):
                x = self.distilling_layers[i](x)

        return x, attns


def test_informer():
    """Informerã®ãƒ†ã‚¹ãƒˆ"""

    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    batch_size = 4
    seq_len = 96  # é•·ã„ç³»åˆ—
    d_model = 64
    n_heads = 4
    d_ff = 256
    n_layers = 3

    # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€
    encoder = InformerEncoder(d_model, n_heads, d_ff, n_layers)

    # ãƒ€ãƒŸãƒ¼å…¥åŠ›
    x = torch.randn(batch_size, seq_len, d_model)

    # Forward
    output, attns = encoder(x)

    print(f"å…¥åŠ›ã‚µã‚¤ã‚º: {x.shape}")
    print(f"å‡ºåŠ›ã‚µã‚¤ã‚º: {output.shape}")
    print(f"Attention weightsæ•°: {len(attns)}")

    # ç³»åˆ—é•·ã®æ¸›å°‘ã‚’ç¢ºèª
    print("\nå±¤ã”ã¨ã®ç³»åˆ—é•·:")
    test_x = x
    for i, distill in enumerate(encoder.distilling_layers):
        test_x = distill(test_x)
        print(f"  Layer {i+1}: {test_x.shape[1]}")

    # Attention weightsã®å¯è¦–åŒ–
    fig, axes = plt.subplots(1, len(attns), figsize=(15, 3))
    for i, attn in enumerate(attns):
        # æœ€åˆã®ãƒãƒƒãƒã€æœ€åˆã®ãƒ˜ãƒƒãƒ‰ã®attentionã‚’è¡¨ç¤º
        attn_map = attn[0, 0].detach().numpy()
        axes[i].imshow(attn_map, cmap='viridis', aspect='auto')
        axes[i].set_title(f'Layer {i+1}')
        axes[i].set_xlabel('Key')
        axes[i].set_ylabel('Query (sampled)')

    plt.tight_layout()
    plt.savefig('informer_attention.png', dpi=150, bbox_inches='tight')
    plt.close()

    print(f"\nAttention weightsã‚’ä¿å­˜ã—ã¾ã—ãŸ: informer_attention.png")

if __name__ == "__main__":
    test_informer()
</code></pre>

<hr>

<h2>4.4 ãã®ä»–ã®Transformerãƒ¢ãƒ‡ãƒ«</h2>

<h3>Autoformer</h3>

<p><strong>Autoformer</strong>ï¼ˆ2021ï¼‰ã¯ã€æ™‚ç³»åˆ—ã®åˆ†è§£ã¨Auto-Correlationãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’å°å…¥ã—ãŸãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚</p>

<h4>ä¸»ãªç‰¹å¾´</h4>
<ul>
<li><strong>Series Decomposition Block</strong>ï¼šãƒˆãƒ¬ãƒ³ãƒ‰ã¨å­£ç¯€æˆåˆ†ã‚’åˆ†é›¢</li>
<li><strong>Auto-Correlation Mechanism</strong>ï¼šæ™‚ç³»åˆ—ã®å‘¨æœŸæ€§ã‚’ç›´æ¥æ‰ãˆã‚‹</li>
<li><strong>Progressive Decomposition</strong>ï¼šå„å±¤ã§åˆ†è§£ã‚’ç¹°ã‚Šè¿”ã™</li>
</ul>

<h4>Auto-Correlation</h4>

<p>å¾“æ¥ã®Attentionã®ä»£ã‚ã‚Šã«ã€æ™‚ç³»åˆ—ã®è‡ªå·±ç›¸é–¢ã‚’åˆ©ç”¨ï¼š</p>

<p>$$
\text{AutoCorr}(Q, K, V) = \text{Softmax}\left(\frac{\mathcal{R}_{Q,K}}{\tau}\right)V
$$</p>

<p>ã“ã“ã§ã€$\mathcal{R}_{Q,K}$ã¯è‡ªå·±ç›¸é–¢é–¢æ•°ã§ã™ã€‚</p>

<h3>FEDformer</h3>

<p><strong>FEDformer</strong>ï¼ˆFrequency Enhanced Decomposed Transformer, 2022ï¼‰ã¯ã€å‘¨æ³¢æ•°é ˜åŸŸã§ã®å‡¦ç†ã‚’å°å…¥ã—ãŸãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚</p>

<h4>ä¸»ãªç‰¹å¾´</h4>
<ul>
<li><strong>Frequency Enhanced Block (FEB)</strong>ï¼šFFTã‚’ç”¨ã„ãŸå‘¨æ³¢æ•°é ˜åŸŸã§ã®å‡¦ç†</li>
<li><strong>Seasonal-Trend Decomposition</strong>ï¼šå‘¨æ³¢æ•°é ˜åŸŸã§ã®åˆ†è§£</li>
<li><strong>Fourier Enhanced Attention</strong>ï¼šå‘¨æ³¢æ•°æˆåˆ†ã«åŸºã¥ãAttention</li>
</ul>

<h4>å‘¨æ³¢æ•°é ˜åŸŸå‡¦ç†</h4>

<p>$$
\hat{X} = \text{FFT}(X) \\
\hat{X}' = \text{FrequencyAttention}(\hat{X}) \\
X' = \text{IFFT}(\hat{X}')
$$</p>

<h3>Patch TST (PatchTST)</h3>

<p><strong>PatchTST</strong>ï¼ˆ2023ï¼‰ã¯ã€æ™‚ç³»åˆ—ã‚’ãƒ‘ãƒƒãƒã«åˆ†å‰²ã—ã¦Transformerã«å…¥åŠ›ã™ã‚‹æ–°ã—ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã™ã€‚</p>

<h4>ä¸»ãªç‰¹å¾´</h4>
<ul>
<li><strong>Patching</strong>ï¼šé€£ç¶šã™ã‚‹æ™‚é–“ã‚¹ãƒ†ãƒƒãƒ—ã‚’ãƒ‘ãƒƒãƒã¨ã—ã¦æ‰±ã†</li>
<li><strong>Channel Independence</strong>ï¼šå„å¤‰æ•°ã‚’ç‹¬ç«‹ã«å‡¦ç†</li>
<li><strong>Efficient Architecture</strong>ï¼šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã¨è¨ˆç®—é‡ã‚’å‰Šæ¸›</li>
</ul>

<h4>Patchingæ“ä½œ</h4>

<p>é•·ã•$L$ã®ç³»åˆ—ã‚’ã€ã‚µã‚¤ã‚º$P$ã®ãƒ‘ãƒƒãƒ$N = L/P$å€‹ã«åˆ†å‰²ï¼š</p>

<p>$$
X = [x_1, x_2, \ldots, x_L] \to [\mathbf{p}_1, \mathbf{p}_2, \ldots, \mathbf{p}_N]
$$</p>

<p>å„ãƒ‘ãƒƒãƒ$\mathbf{p}_i \in \mathbb{R}^P$ã‚’Transformerã®ãƒˆãƒ¼ã‚¯ãƒ³ã¨ã—ã¦æ‰±ã„ã¾ã™ã€‚</p>

<h3>Model Comparison</h3>

<table>
<thead>
<tr>
<th>ãƒ¢ãƒ‡ãƒ«</th>
<th>ä¸»ãªç‰¹å¾´</th>
<th>è¨ˆç®—é‡</th>
<th>é•·æœŸäºˆæ¸¬</th>
<th>è§£é‡ˆæ€§</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Vanilla Transformer</strong></td>
<td>æ¨™æº–çš„ãªAttention</td>
<td>$O(L^2)$</td>
<td>â–³</td>
<td>â–³</td>
</tr>
<tr>
<td><strong>TFT</strong></td>
<td>Variable Selectionã€è§£é‡ˆå¯èƒ½</td>
<td>$O(L^2)$</td>
<td>ã€‡</td>
<td>â—</td>
</tr>
<tr>
<td><strong>Informer</strong></td>
<td>ProbSparse Attention</td>
<td>$O(L\log L)$</td>
<td>â—</td>
<td>â–³</td>
</tr>
<tr>
<td><strong>Autoformer</strong></td>
<td>Auto-Correlationã€åˆ†è§£</td>
<td>$O(L\log L)$</td>
<td>â—</td>
<td>ã€‡</td>
</tr>
<tr>
<td><strong>FEDformer</strong></td>
<td>å‘¨æ³¢æ•°é ˜åŸŸå‡¦ç†</td>
<td>$O(L)$</td>
<td>â—</td>
<td>ã€‡</td>
</tr>
<tr>
<td><strong>PatchTST</strong></td>
<td>Patchingã€åŠ¹ç‡çš„</td>
<td>$O((L/P)^2)$</td>
<td>â—</td>
<td>â–³</td>
</tr>
</tbody>
</table>

<pre><code class="language-python">import numpy as np
import matplotlib.pyplot as plt
from matplotlib.patches import Rectangle

def visualize_model_comparison():
    """Transformerãƒ¢ãƒ‡ãƒ«ã®æ¯”è¼ƒå¯è¦–åŒ–"""

    models = ['Vanilla\nTransformer', 'TFT', 'Informer',
              'Autoformer', 'FEDformer', 'PatchTST']

    # æ€§èƒ½æŒ‡æ¨™ï¼ˆä»®æƒ³çš„ãªã‚¹ã‚³ã‚¢ 0-10ï¼‰
    accuracy = [7, 8.5, 8, 8.5, 9, 8.5]
    efficiency = [4, 5, 8, 8, 9, 9]
    interpretability = [5, 9, 5, 7, 7, 4]
    long_term = [5, 7, 9, 9, 9.5, 9]

    x = np.arange(len(models))
    width = 0.2

    fig, ax = plt.subplots(figsize=(14, 6))

    ax.bar(x - 1.5*width, accuracy, width, label='Accuracy', color='#7b2cbf')
    ax.bar(x - 0.5*width, efficiency, width, label='Efficiency', color='#9d4edd')
    ax.bar(x + 0.5*width, interpretability, width, label='Interpretability', color='#c77dff')
    ax.bar(x + 1.5*width, long_term, width, label='Long-term Forecasting', color='#e0aaff')

    ax.set_xlabel('Model', fontweight='bold')
    ax.set_ylabel('Score (0-10)', fontweight='bold')
    ax.set_title('Transformer Models Comparison', fontsize=14, fontweight='bold')
    ax.set_xticks(x)
    ax.set_xticklabels(models, fontsize=10)
    ax.legend(loc='upper left')
    ax.grid(True, alpha=0.3, axis='y')
    ax.set_ylim(0, 10)

    plt.tight_layout()
    plt.savefig('transformer_models_comparison.png', dpi=150, bbox_inches='tight')
    plt.close()

    print("ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒã‚°ãƒ©ãƒ•ã‚’ä¿å­˜ã—ã¾ã—ãŸ: transformer_models_comparison.png")

    # è¨ˆç®—é‡ã®æ¯”è¼ƒ
    fig, ax = plt.subplots(figsize=(10, 6))

    seq_lengths = np.arange(100, 2001, 100)

    # è¨ˆç®—é‡ï¼ˆæ­£è¦åŒ–ï¼‰
    vanilla = (seq_lengths ** 2) / 1000
    informer = (seq_lengths * np.log(seq_lengths)) / 100
    fedformer = seq_lengths / 10
    patch_size = 16
    patchtst = ((seq_lengths / patch_size) ** 2) / 1000

    ax.plot(seq_lengths, vanilla, label='Vanilla ($O(L^2)$)',
            linewidth=2, marker='o', markersize=3, color='#e63946')
    ax.plot(seq_lengths, informer, label='Informer ($O(L\\log L)$)',
            linewidth=2, marker='s', markersize=3, color='#f77f00')
    ax.plot(seq_lengths, fedformer, label='FEDformer ($O(L)$)',
            linewidth=2, marker='^', markersize=3, color='#06a77d')
    ax.plot(seq_lengths, patchtst, label='PatchTST ($O((L/P)^2)$, P=16)',
            linewidth=2, marker='d', markersize=3, color='#7b2cbf')

    ax.set_xlabel('Sequence Length', fontweight='bold')
    ax.set_ylabel('Computational Cost (normalized)', fontweight='bold')
    ax.set_title('Computational Complexity Comparison', fontsize=14, fontweight='bold')
    ax.legend(loc='upper left')
    ax.grid(True, alpha=0.3)
    ax.set_xlim(100, 2000)

    plt.tight_layout()
    plt.savefig('transformer_complexity.png', dpi=150, bbox_inches='tight')
    plt.close()

    print("è¨ˆç®—é‡æ¯”è¼ƒã‚°ãƒ©ãƒ•ã‚’ä¿å­˜ã—ã¾ã—ãŸ: transformer_complexity.png")

if __name__ == "__main__":
    visualize_model_comparison()
</code></pre>

<hr>

<h2>4.5 å®Ÿè·µãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ</h2>

<h3>Multi-variate Forecasting with Exogenous Variables</h3>

<p>å®Ÿéš›ã®ãƒ“ã‚¸ãƒã‚¹å•é¡Œã§ã¯ã€è¤‡æ•°ã®æ™‚ç³»åˆ—å¤‰æ•°ã¨å¤–ç”Ÿå¤‰æ•°ã‚’åŒæ™‚ã«æ‰±ã†å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ã“ã“ã§ã¯ã€TFTã‚’ä½¿ã£ãŸå®Œå…¨ãªäºˆæ¸¬ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’æ§‹ç¯‰ã—ã¾ã™ã€‚</p>

<h3>ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆè¨­å®š</h3>

<p><strong>ã‚¿ã‚¹ã‚¯</strong>ï¼šå°å£²åº—ã®å£²ä¸Šäºˆæ¸¬</p>

<p><strong>ãƒ‡ãƒ¼ã‚¿</strong>ï¼š</p>
<ul>
<li><strong>Target</strong>ï¼šæ—¥æ¬¡å£²ä¸Š</li>
<li><strong>Time-varying known</strong>ï¼šä¾¡æ ¼ã€ãƒ—ãƒ­ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³ã€æ›œæ—¥ã€ç¥æ—¥</li>
<li><strong>Time-varying unknown</strong>ï¼šç«¶åˆã®æ´»å‹•ã€å¤©å€™ï¼ˆäºˆæ¸¬å›°é›£ï¼‰</li>
<li><strong>Static</strong>ï¼šåº—èˆ—ã‚«ãƒ†ã‚´ãƒªã€åœ°åŸŸ</li>
</ul>

<h3>Complete TFT Pipeline</h3>

<pre><code class="language-python">import pandas as pd
import numpy as np
import torch
from pytorch_forecasting import TimeSeriesDataSet, TemporalFusionTransformer
from pytorch_forecasting.data import GroupNormalizer
from pytorch_forecasting.metrics import QuantileLoss, SMAPE
from pytorch_lightning import Trainer
from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')

def generate_retail_data():
    """å°å£²å£²ä¸Šãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆ"""

    np.random.seed(42)

    # åº—èˆ—æƒ…å ±
    stores = [
        {'store_id': 'A', 'category': 'urban', 'region': 'north'},
        {'store_id': 'B', 'category': 'urban', 'region': 'south'},
        {'store_id': 'C', 'category': 'suburban', 'region': 'north'},
        {'store_id': 'D', 'category': 'suburban', 'region': 'south'},
        {'store_id': 'E', 'category': 'rural', 'region': 'west'},
    ]

    data = []
    n_days = 730  # 2å¹´åˆ†

    for store in stores:
        store_id = store['store_id']
        base_sales = {'urban': 1000, 'suburban': 600, 'rural': 300}[store['category']]

        for day in range(n_days):
            # æ—¥ä»˜ç‰¹å¾´
            date = pd.Timestamp('2022-01-01') + pd.Timedelta(days=day)
            day_of_week = date.dayofweek
            month = date.month
            is_weekend = int(day_of_week >= 5)
            is_holiday = int(month == 12 and date.day >= 20)  # å¹´æœ«

            # ãƒˆãƒ¬ãƒ³ãƒ‰
            trend = day * 0.5

            # å­£ç¯€æ€§
            yearly_season = 200 * np.sin(2 * np.pi * day / 365)
            weekly_season = 150 * (1 if day_of_week in [5, 6] else 0)

            # å¤–ç”Ÿå¤‰æ•°
            price = 100 + np.random.normal(0, 5)
            promotion = int(np.random.random() < 0.15)  # 15%ã®ç¢ºç‡
            competitor_activity = np.random.normal(0.5, 0.2)

            # å£²ä¸Šè¨ˆç®—
            sales = base_sales + trend + yearly_season + weekly_season
            sales *= (1 + 0.3 * promotion)  # ãƒ—ãƒ­ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³åŠ¹æœ
            sales *= (1 - 0.2 * competitor_activity)  # ç«¶åˆã®å½±éŸ¿
            sales *= (0.9 if day_of_week == 0 else 1.0)  # æœˆæ›œã¯ä½ã„
            sales += np.random.normal(0, 50)
            sales = max(0, sales)

            data.append({
                'date': date,
                'time_idx': day,
                'store_id': store_id,
                'category': store['category'],
                'region': store['region'],
                'sales': sales,
                'price': price,
                'promotion': promotion,
                'day_of_week': day_of_week,
                'month': month,
                'is_weekend': is_weekend,
                'is_holiday': is_holiday,
                'competitor_activity': competitor_activity,
            })

    return pd.DataFrame(data)


def build_tft_forecaster():
    """TFTäºˆæ¸¬å™¨ã®æ§‹ç¯‰ã¨è¨“ç·´"""

    # ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    print("ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆä¸­...")
    df = generate_retail_data()

    print(f"ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {len(df)} rows")
    print(f"åº—èˆ—æ•°: {df['store_id'].nunique()}")
    print(f"æœŸé–“: {df['date'].min()} to {df['date'].max()}")

    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ
    max_encoder_length = 60
    max_prediction_length = 30
    training_cutoff = df["time_idx"].max() - max_prediction_length

    training = TimeSeriesDataSet(
        df[lambda x: x.time_idx <= training_cutoff],
        time_idx="time_idx",
        target="sales",
        group_ids=["store_id"],
        min_encoder_length=max_encoder_length // 2,
        max_encoder_length=max_encoder_length,
        min_prediction_length=1,
        max_prediction_length=max_prediction_length,

        # Static features
        static_categoricals=["store_id", "category", "region"],

        # Time-varying known (future values are known)
        time_varying_known_categoricals=["day_of_week", "month", "is_weekend", "is_holiday"],
        time_varying_known_reals=["time_idx", "price", "promotion"],

        # Time-varying unknown (future values are not known)
        time_varying_unknown_reals=["sales", "competitor_activity"],

        # Normalization
        target_normalizer=GroupNormalizer(
            groups=["store_id"], transformation="softplus"
        ),

        # Additional features
        add_relative_time_idx=True,
        add_target_scales=True,
        add_encoder_length=True,
    )

    validation = TimeSeriesDataSet.from_dataset(
        training, df, predict=True, stop_randomization=True
    )

    # DataLoaders
    batch_size = 32
    train_dataloader = training.to_dataloader(
        train=True, batch_size=batch_size, num_workers=0, shuffle=True
    )
    val_dataloader = validation.to_dataloader(
        train=False, batch_size=batch_size, num_workers=0
    )

    print(f"\nè¨“ç·´ãƒãƒƒãƒæ•°: {len(train_dataloader)}")
    print(f"æ¤œè¨¼ãƒãƒƒãƒæ•°: {len(val_dataloader)}")

    # TFTãƒ¢ãƒ‡ãƒ«
    tft = TemporalFusionTransformer.from_dataset(
        training,
        learning_rate=0.03,
        hidden_size=64,
        attention_head_size=4,
        dropout=0.1,
        hidden_continuous_size=32,
        output_size=7,  # 7 quantiles
        loss=QuantileLoss(),
        log_interval=10,
        reduce_on_plateau_patience=4,
    )

    print(f"\nTFTãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰å®Œäº†")
    print(f"ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {tft.size()/1e3:.1f}k")

    # Callbacks
    early_stop_callback = EarlyStopping(
        monitor="val_loss",
        patience=10,
        verbose=False,
        mode="min"
    )

    checkpoint_callback = ModelCheckpoint(
        monitor="val_loss",
        mode="min",
        save_top_k=1,
        verbose=False
    )

    # Trainer
    trainer = Trainer(
        max_epochs=100,
        accelerator="cpu",
        enable_model_summary=True,
        gradient_clip_val=0.1,
        callbacks=[early_stop_callback, checkpoint_callback],
        limit_train_batches=50,
        limit_val_batches=10,
        enable_checkpointing=True,
    )

    # è¨“ç·´
    print("\nè¨“ç·´é–‹å§‹...")
    trainer.fit(
        tft,
        train_dataloaders=train_dataloader,
        val_dataloaders=val_dataloader,
    )

    # ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰
    best_model = TemporalFusionTransformer.load_from_checkpoint(
        checkpoint_callback.best_model_path
    )

    # è©•ä¾¡
    print("\nè©•ä¾¡ä¸­...")
    predictions = best_model.predict(val_dataloader, return_x=True, return_y=True)

    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—
    actuals = predictions.y[0].cpu().numpy()
    preds = predictions.output['prediction'].cpu().numpy()

    mae = np.mean(np.abs(actuals - preds))
    rmse = np.sqrt(np.mean((actuals - preds) ** 2))
    mape = np.mean(np.abs((actuals - preds) / (actuals + 1e-8))) * 100

    print(f"\nè©•ä¾¡çµæœ:")
    print(f"  MAE: {mae:.2f}")
    print(f"  RMSE: {rmse:.2f}")
    print(f"  MAPE: {mape:.2f}%")

    # å¯è¦–åŒ–
    visualize_predictions(best_model, predictions, df)
    visualize_interpretation(best_model, predictions)

    return best_model, predictions, df


def visualize_predictions(model, predictions, df):
    """äºˆæ¸¬çµæœã®å¯è¦–åŒ–"""

    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    axes = axes.flatten()

    for idx in range(min(4, len(predictions.output))):
        ax = axes[idx]

        # ãƒ‡ãƒ¼ã‚¿å–å¾—
        x = predictions.x
        y_true = predictions.y[0][idx].cpu().numpy()
        y_pred = predictions.output['prediction'][idx].cpu().numpy()

        # äºˆæ¸¬åŒºé–“ï¼ˆquantilesï¼‰
        quantiles = predictions.output['quantiles'][idx].cpu().numpy()

        time_steps = np.arange(len(y_true))

        # ãƒ—ãƒ­ãƒƒãƒˆ
        ax.plot(time_steps, y_true, 'o-', label='Actual', color='#2d3748', linewidth=2)
        ax.plot(time_steps, y_pred, 's-', label='Predicted', color='#7b2cbf', linewidth=2)

        # äºˆæ¸¬åŒºé–“ï¼ˆ10%-90%ï¼‰
        ax.fill_between(
            time_steps,
            quantiles[:, 0],  # 10% quantile
            quantiles[:, -1],  # 90% quantile
            alpha=0.2,
            color='#9d4edd',
            label='10%-90% Prediction Interval'
        )

        ax.set_xlabel('Time Step', fontweight='bold')
        ax.set_ylabel('Sales', fontweight='bold')
        ax.set_title(f'Store {idx+1}: Sales Forecast', fontweight='bold')
        ax.legend()
        ax.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.savefig('tft_sales_predictions.png', dpi=150, bbox_inches='tight')
    plt.close()

    print(f"äºˆæ¸¬çµæœã‚’ä¿å­˜ã—ã¾ã—ãŸ: tft_sales_predictions.png")


def visualize_interpretation(model, predictions):
    """Variable Importanceã¨Attentionã®å¯è¦–åŒ–"""

    interpretation = model.interpret_output(
        predictions.output, reduction="sum"
    )

    fig, axes = plt.subplots(1, 2, figsize=(15, 5))

    # Variable importance
    ax = axes[0]

    # Encoder variable importance
    encoder_importance = interpretation["encoder_variables"].cpu().numpy()
    encoder_vars = list(interpretation["encoder_variables_names"])

    y_pos = np.arange(len(encoder_vars))
    ax.barh(y_pos, encoder_importance, color='#7b2cbf')
    ax.set_yticks(y_pos)
    ax.set_yticklabels(encoder_vars)
    ax.set_xlabel('Importance', fontweight='bold')
    ax.set_title('Encoder Variable Importance', fontweight='bold')
    ax.grid(True, alpha=0.3, axis='x')

    # Attention weights
    ax = axes[1]
    attention = interpretation["attention"].mean(0).cpu().numpy()

    im = ax.imshow(attention, cmap='YlOrRd', aspect='auto')
    ax.set_xlabel('Encoder Time Steps', fontweight='bold')
    ax.set_ylabel('Decoder Time Steps', fontweight='bold')
    ax.set_title('Average Attention Weights', fontweight='bold')
    plt.colorbar(im, ax=ax)

    plt.tight_layout()
    plt.savefig('tft_interpretation.png', dpi=150, bbox_inches='tight')
    plt.close()

    print(f"è§£é‡ˆå¯èƒ½æ€§ã®å¯è¦–åŒ–ã‚’ä¿å­˜ã—ã¾ã—ãŸ: tft_interpretation.png")


if __name__ == "__main__":
    model, predictions, df = build_tft_forecaster()

    print("\n" + "="*60)
    print("TFTäºˆæ¸¬ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Œäº†ï¼")
    print("="*60)
</code></pre>

<h3>Production Deployment Considerations</h3>

<p>æœ¬ç•ªç’°å¢ƒã¸ã®ãƒ‡ãƒ—ãƒ­ã‚¤æ™‚ã«ã¯ã€ä»¥ä¸‹ã®ç‚¹ã«æ³¨æ„ãŒå¿…è¦ã§ã™ï¼š</p>

<h4>1. ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜ã¨ãƒ­ãƒ¼ãƒ‰</h4>

<pre><code class="language-python"># ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜
model.save("tft_model.pt")

# ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰
from pytorch_forecasting import TemporalFusionTransformer
loaded_model = TemporalFusionTransformer.load_from_checkpoint("tft_model.pt")
</code></pre>

<h4>2. ãƒãƒƒãƒäºˆæ¸¬ã®æœ€é©åŒ–</h4>

<pre><code class="language-python"># å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã§ã®äºˆæ¸¬
predictions = model.predict(
    dataloader,
    mode="raw",  # ç”Ÿã®å‡ºåŠ›ã‚’å–å¾—
    return_index=True,  # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚‚è¿”ã™
    trainer_kwargs={"accelerator": "gpu"}  # GPUã‚’ä½¿ç”¨
)
</code></pre>

<h4>3. ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ äºˆæ¸¬API</h4>

<pre><code class="language-python">from fastapi import FastAPI
import torch

app = FastAPI()

# ãƒ¢ãƒ‡ãƒ«ã‚’ã‚°ãƒ­ãƒ¼ãƒãƒ«ã«ãƒ­ãƒ¼ãƒ‰
model = TemporalFusionTransformer.load_from_checkpoint("tft_model.pt")
model.eval()

@app.post("/predict")
async def predict(input_data: dict):
    # ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†
    dataset = prepare_dataset(input_data)
    dataloader = dataset.to_dataloader(train=False, batch_size=1)

    # äºˆæ¸¬
    with torch.no_grad():
        predictions = model.predict(dataloader)

    return {"predictions": predictions.tolist()}
</code></pre>

<h4>4. ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ã¨ãƒ‰ãƒªãƒ•ãƒˆæ¤œå‡º</h4>

<ul>
<li><strong>äºˆæ¸¬ç²¾åº¦ã®ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°</strong>ï¼šå®šæœŸçš„ã«MAE/RMSEã‚’è¨ˆç®—</li>
<li><strong>ãƒ‡ãƒ¼ã‚¿ãƒ‰ãƒªãƒ•ãƒˆæ¤œå‡º</strong>ï¼šå…¥åŠ›åˆ†å¸ƒã®å¤‰åŒ–ã‚’ç›£è¦–</li>
<li><strong>å†è¨“ç·´ãƒˆãƒªã‚¬ãƒ¼</strong>ï¼šç²¾åº¦ä½ä¸‹æ™‚ã«è‡ªå‹•å†è¨“ç·´</li>
</ul>

<hr>

<h2>ç·´ç¿’å•é¡Œ</h2>

<details>
<summary><strong>å•é¡Œ1ï¼šPositional Encoding</strong> - æ™‚ç³»åˆ—ç”¨ã®Positional Encodingã‚’å®Ÿè£…ã—ã€ãã®å½¹å‰²ã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚</summary>

<p><strong>è§£ç­”ä¾‹</strong>ï¼š</p>

<pre><code class="language-python">import torch
import torch.nn as nn
import numpy as np
import matplotlib.pyplot as plt

class TemporalPositionalEncoding(nn.Module):
    def __init__(self, d_model, max_len=5000):
        super().__init__()

        pe = torch.zeros(max_len, d_model)
        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)
        div_term = torch.exp(torch.arange(0, d_model, 2).float() *
                            (-np.log(10000.0) / d_model))

        pe[:, 0::2] = torch.sin(position * div_term)
        pe[:, 1::2] = torch.cos(position * div_term)

        self.register_buffer('pe', pe.unsqueeze(0))

    def forward(self, x):
        return x + self.pe[:, :x.size(1), :]

# å¯è¦–åŒ–
pe = TemporalPositionalEncoding(d_model=128, max_len=100)
encoding = pe.pe[0].numpy()

plt.figure(figsize=(12, 6))
plt.imshow(encoding.T, cmap='RdBu', aspect='auto')
plt.xlabel('Position')
plt.ylabel('Dimension')
plt.title('Positional Encoding Heatmap')
plt.colorbar()
plt.tight_layout()
plt.savefig('positional_encoding.png', dpi=150)
plt.close()

print("Positional Encodingã¯ã€ç³»åˆ—ã®ä½ç½®æƒ…å ±ã‚’æ³¨å…¥ã™ã‚‹å½¹å‰²ã‚’æŒã¤")
print("ç•°ãªã‚‹å‘¨æ³¢æ•°ã®sin/cosæ³¢ã«ã‚ˆã‚Šã€ç›¸å¯¾ä½ç½®ã‚‚æ‰ãˆã‚‰ã‚Œã‚‹")
</code></pre>

<p><strong>å½¹å‰²</strong>ï¼š</p>
<ul>
<li>Transformerã«ã¯å†å¸°æ§‹é€ ãŒãªã„ãŸã‚ã€ä½ç½®æƒ…å ±ã‚’æ˜ç¤ºçš„ã«è¿½åŠ </li>
<li>ç•°ãªã‚‹å‘¨æ³¢æ•°ã«ã‚ˆã‚Šã€è¿‘ã„ä½ç½®ã¨é ã„ä½ç½®ã®ä¸¡æ–¹ã‚’åŒºåˆ¥</li>
<li>æ™‚ç³»åˆ—ã§ã¯ã€çµ¶å¯¾æ™‚åˆ»ã‚„å‘¨æœŸæ€§ã‚‚è¿½åŠ ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰å¯èƒ½</li>
</ul>
</details>

<details>
<summary><strong>å•é¡Œ2ï¼šTFTã®Variable Selection</strong> - Variable Selection Networkã®å®Ÿè£…ã¨ã€ãã®åˆ©ç‚¹ã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚</summary>

<p><strong>è§£ç­”ä¾‹</strong>ï¼š</p>

<pre><code class="language-python">import torch
import torch.nn as nn

class GatedResidualNetwork(nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim, dropout=0.1):
        super().__init__()
        self.fc1 = nn.Linear(input_dim, hidden_dim)
        self.fc2 = nn.Linear(hidden_dim, output_dim)
        self.gate = nn.Linear(hidden_dim, output_dim)
        self.dropout = nn.Dropout(dropout)
        self.layer_norm = nn.LayerNorm(output_dim)

        if input_dim != output_dim:
            self.skip = nn.Linear(input_dim, output_dim)
        else:
            self.skip = None

    def forward(self, x):
        # GRNè¨ˆç®—
        eta2 = torch.relu(self.fc1(x))
        eta1 = self.fc2(eta2)
        gate = torch.sigmoid(self.gate(eta2))

        # Gated output
        output = gate * eta1
        output = self.dropout(output)

        # Skip connection
        if self.skip is not None:
            x = self.skip(x)

        return self.layer_norm(x + output)


class VariableSelectionNetwork(nn.Module):
    def __init__(self, input_dims, hidden_dim, output_dim, dropout=0.1):
        super().__init__()
        self.input_dims = input_dims

        # å„å¤‰æ•°ç”¨ã®GRN
        self.variable_grns = nn.ModuleList([
            GatedResidualNetwork(1, hidden_dim, output_dim, dropout)
            for _ in range(len(input_dims))
        ])

        # é‡ã¿è¨ˆç®—ç”¨ã®GRN
        self.weight_grn = GatedResidualNetwork(
            sum(input_dims), hidden_dim, len(input_dims), dropout
        )

    def forward(self, variables):
        # variables: list of tensors
        # å„å¤‰æ•°ã‚’å¤‰æ›
        transformed = [grn(v.unsqueeze(-1)) for grn, v in
                      zip(self.variable_grns, variables)]

        # é‡ã¿è¨ˆç®—
        concat_vars = torch.cat(variables, dim=-1)
        weights = torch.softmax(self.weight_grn(concat_vars), dim=-1)

        # åŠ é‡å’Œ
        output = sum(w.unsqueeze(-1) * t for w, t in
                    zip(weights.split(1, dim=-1), transformed))

        return output, weights

# ãƒ†ã‚¹ãƒˆ
n_vars = 5
batch_size = 32
seq_len = 50

vsn = VariableSelectionNetwork(
    input_dims=[1]*n_vars, hidden_dim=64, output_dim=32
)

variables = [torch.randn(batch_size, seq_len) for _ in range(n_vars)]
output, weights = vsn(variables)

print(f"Output shape: {output.shape}")
print(f"Weights shape: {weights.shape}")
print(f"Variable importance: {weights[0, 0]}")
</code></pre>

<p><strong>åˆ©ç‚¹</strong>ï¼š</p>
<ul>
<li>è‡ªå‹•çš„ã«é‡è¦ãªå¤‰æ•°ã‚’é¸æŠã—ã€ãƒã‚¤ã‚ºã‚’å‰Šæ¸›</li>
<li>è§£é‡ˆå¯èƒ½æ€§ï¼šã©ã®å¤‰æ•°ãŒé‡è¦ã‹ã‚’å¯è¦–åŒ–</li>
<li>éå­¦ç¿’ã®é˜²æ­¢ï¼šä¸è¦ãªå¤‰æ•°ã®å½±éŸ¿ã‚’æŠ‘åˆ¶</li>
</ul>
</details>

<details>
<summary><strong>å•é¡Œ3ï¼šProbSparse Attention</strong> - Informerã®ProbSparse Attentionã®åŠ¹ç‡æ€§ã‚’ã€æ¨™æº–çš„ãªAttentionã¨æ¯”è¼ƒã—ã¦ãã ã•ã„ã€‚</summary>

<p><strong>è§£ç­”ä¾‹</strong>ï¼š</p>

<pre><code class="language-python">import torch
import time
import matplotlib.pyplot as plt

def standard_attention(Q, K, V):
    """æ¨™æº–çš„ãªAttention O(L^2)"""
    d_k = Q.size(-1)
    scores = torch.matmul(Q, K.transpose(-2, -1)) / (d_k ** 0.5)
    attn = torch.softmax(scores, dim=-1)
    return torch.matmul(attn, V)

def probsparse_attention(Q, K, V, factor=5):
    """ProbSparse Attention O(L log L)"""
    L_q = Q.size(1)
    L_k = K.size(1)
    d_k = Q.size(-1)

    # Top-u selection
    u = factor * int(np.ceil(np.log(L_q)))
    u = min(u, L_q)

    # ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆç°¡æ˜“ç‰ˆï¼‰
    Q_sample = Q[:, :u, :]

    scores = torch.matmul(Q_sample, K.transpose(-2, -1)) / (d_k ** 0.5)
    attn = torch.softmax(scores, dim=-1)

    out_sample = torch.matmul(attn, V)

    # æ®‹ã‚Šã¯å¹³å‡
    V_mean = V.mean(dim=1, keepdim=True).expand(-1, L_q - u, -1)
    output = torch.cat([out_sample, V_mean], dim=1)

    return output

# ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
seq_lengths = [100, 200, 500, 1000, 1500, 2000]
standard_times = []
probsparse_times = []

batch_size = 8
d_model = 64

for seq_len in seq_lengths:
    Q = K = V = torch.randn(batch_size, seq_len, d_model)

    # Standard Attention
    start = time.time()
    _ = standard_attention(Q, K, V)
    standard_times.append(time.time() - start)

    # ProbSparse Attention
    start = time.time()
    _ = probsparse_attention(Q, K, V)
    probsparse_times.append(time.time() - start)

    print(f"Seq={seq_len}: Standard={standard_times[-1]:.4f}s, "
          f"ProbSparse={probsparse_times[-1]:.4f}s")

# å¯è¦–åŒ–
plt.figure(figsize=(10, 6))
plt.plot(seq_lengths, standard_times, 'o-', label='Standard Attention', linewidth=2)
plt.plot(seq_lengths, probsparse_times, 's-', label='ProbSparse Attention', linewidth=2)
plt.xlabel('Sequence Length')
plt.ylabel('Time (seconds)')
plt.title('Attention Mechanism Efficiency Comparison')
plt.legend()
plt.grid(True, alpha=0.3)
plt.savefig('attention_efficiency.png', dpi=150)
plt.close()

speedup = [s/p for s, p in zip(standard_times, probsparse_times)]
print(f"\nAverage speedup: {np.mean(speedup):.2f}x")
</code></pre>

<p><strong>æ¯”è¼ƒçµæœ</strong>ï¼š</p>
<ul>
<li>ç³»åˆ—é•·ãŒé•·ã„ã»ã©ã€ProbSparseã®å„ªä½æ€§ãŒé¡•è‘—</li>
<li>$L=2000$ã§ã¯ç´„5-10å€ã®é«˜é€ŸåŒ–</li>
<li>ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚‚å¤§å¹…ã«å‰Šæ¸›</li>
</ul>
</details>

<details>
<summary><strong>å•é¡Œ4ï¼šMulti-horizon Prediction</strong> - Autoregressiveãƒ¢ãƒ¼ãƒ‰ã¨ Direct ãƒ¢ãƒ¼ãƒ‰ã®é•ã„ã‚’å®Ÿè£…ã—ã€æ¯”è¼ƒã—ã¦ãã ã•ã„ã€‚</summary>

<p><strong>è§£ç­”ä¾‹</strong>ï¼š</p>

<pre><code class="language-python">import torch
import torch.nn as nn
import numpy as np
import matplotlib.pyplot as plt

class AutoregressivePredictor(nn.Module):
    """Autoregressive multi-step prediction"""
    def __init__(self, input_dim, hidden_dim):
        super().__init__()
        self.rnn = nn.LSTM(input_dim, hidden_dim, batch_first=True)
        self.fc = nn.Linear(hidden_dim, input_dim)

    def forward(self, x, n_steps):
        # x: (batch, seq_len, input_dim)
        predictions = []

        for _ in range(n_steps):
            out, _ = self.rnn(x)
            pred = self.fc(out[:, -1:, :])  # æœ€å¾Œã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’äºˆæ¸¬
            predictions.append(pred)
            x = torch.cat([x, pred], dim=1)  # äºˆæ¸¬ã‚’å…¥åŠ›ã«è¿½åŠ 

        return torch.cat(predictions, dim=1)


class DirectPredictor(nn.Module):
    """Direct multi-step prediction"""
    def __init__(self, input_dim, hidden_dim, n_steps):
        super().__init__()
        self.rnn = nn.LSTM(input_dim, hidden_dim, batch_first=True)
        self.fc = nn.Linear(hidden_dim, input_dim * n_steps)
        self.n_steps = n_steps
        self.input_dim = input_dim

    def forward(self, x):
        # x: (batch, seq_len, input_dim)
        out, _ = self.rnn(x)
        pred = self.fc(out[:, -1, :])  # å…¨ã‚¹ãƒ†ãƒƒãƒ—ã‚’ä¸€åº¦ã«äºˆæ¸¬
        return pred.view(-1, self.n_steps, self.input_dim)

# ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
def generate_test_data(n_samples=100):
    t = np.linspace(0, 10, n_samples)
    data = np.sin(t) + 0.1 * np.random.randn(n_samples)
    return torch.FloatTensor(data).unsqueeze(-1)

# è¨“ç·´
seq_len = 20
n_steps = 10
data = generate_test_data(200)

X_train = torch.stack([data[i:i+seq_len] for i in range(150)])
y_train = torch.stack([data[i+seq_len:i+seq_len+n_steps] for i in range(150)])

# ãƒ¢ãƒ‡ãƒ«
auto_model = AutoregressivePredictor(1, 32)
direct_model = DirectPredictor(1, 32, n_steps)

criterion = nn.MSELoss()

# Autoregressiveè¨“ç·´
optimizer = torch.optim.Adam(auto_model.parameters())
for epoch in range(100):
    pred = auto_model(X_train, n_steps)
    loss = criterion(pred, y_train)
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()

# Directè¨“ç·´
optimizer = torch.optim.Adam(direct_model.parameters())
for epoch in range(100):
    pred = direct_model(X_train)
    loss = criterion(pred, y_train)
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()

# è©•ä¾¡
X_test = X_train[0:1]
y_test = y_train[0:1]

auto_pred = auto_model(X_test, n_steps).detach().numpy()
direct_pred = direct_model(X_test).detach().numpy()

# å¯è¦–åŒ–
plt.figure(figsize=(12, 5))
plt.plot(range(seq_len), X_test[0].numpy(), 'o-', label='Input')
plt.plot(range(seq_len, seq_len+n_steps), y_test[0].numpy(), 's-', label='True')
plt.plot(range(seq_len, seq_len+n_steps), auto_pred[0], '^-', label='Autoregressive')
plt.plot(range(seq_len, seq_len+n_steps), direct_pred[0], 'd-', label='Direct')
plt.axvline(x=seq_len, color='gray', linestyle='--', alpha=0.5)
plt.legend()
plt.grid(True, alpha=0.3)
plt.savefig('multihorizon_comparison.png', dpi=150)
plt.close()

print("Autoregressive: é€æ¬¡äºˆæ¸¬ã€èª¤å·®ãŒè“„ç©")
print("Direct: ä¸€åº¦ã«äºˆæ¸¬ã€ä¸¦åˆ—è¨ˆç®—å¯èƒ½")
</code></pre>
</details>

<details>
<summary><strong>å•é¡Œ5ï¼šProduction Deployment</strong> - TFTãƒ¢ãƒ‡ãƒ«ã‚’æœ¬ç•ªç’°å¢ƒã«ãƒ‡ãƒ—ãƒ­ã‚¤ã™ã‚‹ãŸã‚ã®å®Œå…¨ãªãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’è¨­è¨ˆã—ã¦ãã ã•ã„ã€‚</summary>

<p><strong>è§£ç­”ä¾‹</strong>ï¼š</p>

<pre><code class="language-python">"""
æœ¬ç•ªç’°å¢ƒãƒ‡ãƒ—ãƒ­ã‚¤ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

1. ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜ã¨ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†
2. æ¨è«–APIã®æ§‹ç¯‰
3. ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ã¨ãƒ­ã‚®ãƒ³ã‚°
4. è‡ªå‹•å†è¨“ç·´ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
"""

# 1. ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜
class ModelManager:
    def __init__(self, model_dir="models"):
        self.model_dir = model_dir

    def save_model(self, model, version):
        import joblib
        path = f"{self.model_dir}/tft_v{version}.pkl"
        joblib.dump(model, path)
        print(f"Model saved: {path}")

    def load_latest_model(self):
        import glob, joblib
        models = glob.glob(f"{self.model_dir}/tft_v*.pkl")
        latest = max(models, key=lambda x: int(x.split('v')[-1].split('.')[0]))
        return joblib.load(latest)

# 2. FastAPIæ¨è«–ã‚µãƒ¼ãƒãƒ¼
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import pandas as pd

app = FastAPI()

class PredictionRequest(BaseModel):
    store_id: str
    historical_data: list
    future_covariates: dict

class PredictionResponse(BaseModel):
    predictions: list
    confidence_intervals: dict
    variable_importance: dict

@app.on_event("startup")
async def load_model():
    global model
    manager = ModelManager()
    model = manager.load_latest_model()

@app.post("/predict", response_model=PredictionResponse)
async def predict(request: PredictionRequest):
    try:
        # ãƒ‡ãƒ¼ã‚¿æº–å‚™
        df = pd.DataFrame(request.historical_data)
        dataset = prepare_dataset(df, request.future_covariates)

        # äºˆæ¸¬
        predictions = model.predict(dataset)
        interpretation = model.interpret_output(predictions)

        return PredictionResponse(
            predictions=predictions.tolist(),
            confidence_intervals={
                "lower": predictions.quantile(0.1).tolist(),
                "upper": predictions.quantile(0.9).tolist()
            },
            variable_importance=interpretation["encoder_variables"].tolist()
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# 3. ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°
import logging
from prometheus_client import Counter, Histogram

prediction_counter = Counter('predictions_total', 'Total predictions')
prediction_latency = Histogram('prediction_latency_seconds', 'Prediction latency')

@app.middleware("http")
async def monitor_requests(request, call_next):
    with prediction_latency.time():
        response = await call_next(request)
    prediction_counter.inc()
    return response

# 4. è‡ªå‹•å†è¨“ç·´
class AutoRetrainer:
    def __init__(self, threshold_mae=50.0):
        self.threshold_mae = threshold_mae

    def check_performance(self, predictions, actuals):
        mae = np.mean(np.abs(predictions - actuals))

        if mae > self.threshold_mae:
            print(f"Performance degraded: MAE={mae:.2f}")
            self.trigger_retraining()

    def trigger_retraining(self):
        # å†è¨“ç·´ã‚¸ãƒ§ãƒ–ã‚’ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«
        import subprocess
        subprocess.run(["python", "train_tft.py"])

# 5. ãƒ‡ãƒ—ãƒ­ã‚¤ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
def deploy_pipeline():
    # DockeråŒ–
    dockerfile = """
    FROM python:3.9
    WORKDIR /app
    COPY requirements.txt .
    RUN pip install -r requirements.txt
    COPY . .
    CMD ["uvicorn", "api:app", "--host", "0.0.0.0", "--port", "8000"]
    """

    # Kubernetes manifest
    k8s_deployment = """
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: tft-predictor
    spec:
      replicas: 3
      template:
        spec:
          containers:
          - name: tft
            image: tft-predictor:latest
            resources:
              limits:
                memory: "2Gi"
                cpu: "1000m"
    """

    print("Deployment configuration generated")

if __name__ == "__main__":
    deploy_pipeline()
</code></pre>

<p><strong>ãƒ‡ãƒ—ãƒ­ã‚¤è¦ç´ </strong>ï¼š</p>
<ul>
<li>ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ã¨ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½</li>
<li>é«˜é€Ÿãªæ¨è«–APIï¼ˆFastAPIï¼‰</li>
<li>ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ï¼ˆPrometheusï¼‰</li>
<li>è‡ªå‹•å†è¨“ç·´ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³</li>
<li>ã‚³ãƒ³ãƒ†ãƒŠåŒ–ã¨ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆDocker/K8sï¼‰</li>
</ul>
</details>

<hr>

<h2>å‚è€ƒæ–‡çŒ®</h2>

<h3>è«–æ–‡</h3>
<ul>
<li>Vaswani et al. (2017). <em>Attention Is All You Need</em>. NeurIPS.</li>
<li>Lim et al. (2021). <em>Temporal Fusion Transformers for Interpretable Multi-horizon Time Series Forecasting</em>. International Journal of Forecasting.</li>
<li>Zhou et al. (2021). <em>Informer: Beyond Efficient Transformer for Long Sequence Time-Series Forecasting</em>. AAAI.</li>
<li>Wu et al. (2021). <em>Autoformer: Decomposition Transformers with Auto-Correlation for Long-Term Series Forecasting</em>. NeurIPS.</li>
<li>Zhou et al. (2022). <em>FEDformer: Frequency Enhanced Decomposed Transformer for Long-term Series Forecasting</em>. ICML.</li>
<li>Nie et al. (2023). <em>A Time Series is Worth 64 Words: Long-term Forecasting with Transformers</em>. ICLR (PatchTST).</li>
</ul>

<h3>æ›¸ç±</h3>
<ul>
<li>Hyndman & Athanasopoulos. <em>Forecasting: Principles and Practice</em> (3rd edition).</li>
<li>Nielsen, A. <em>Practical Time Series Analysis</em>. O'Reilly Media.</li>
</ul>

<h3>ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã¨ãƒ„ãƒ¼ãƒ«</h3>
<ul>
<li><a href="https://pytorch-forecasting.readthedocs.io/">PyTorch Forecasting</a> - TFTã€N-BEATSç­‰ã®å®Ÿè£…</li>
<li><a href="https://github.com/thuml/Autoformer">Autoformer GitHub</a> - å…¬å¼å®Ÿè£…</li>
<li><a href="https://github.com/MAZiqing/FEDformer">FEDformer GitHub</a> - å…¬å¼å®Ÿè£…</li>
<li><a href="https://github.com/yuqinie98/PatchTST">PatchTST GitHub</a> - å…¬å¼å®Ÿè£…</li>
</ul>

<h3>ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ãƒªã‚½ãƒ¼ã‚¹</h3>
<ul>
<li><a href="https://huggingface.co/blog/time-series-transformers">HuggingFace Time Series Guide</a></li>
<li><a href="https://towardsdatascience.com/temporal-fusion-transformer-for-time-series-forecasting-9e9b8c47f0a5">Temporal Fusion Transformer Tutorial</a></li>
<li><a href="https://arxiv.org/abs/2310.06625">Time Series Transformers Survey</a> - æœ€æ–°ã‚µãƒ¼ãƒ™ã‚¤è«–æ–‡</li>
</ul>

<hr>

<div class="navigation">
    <a href="chapter3-deep-learning-time-series.html" class="nav-button">â† å‰ã®ç« ï¼šæ·±å±¤å­¦ç¿’ã«ã‚ˆã‚‹æ™‚ç³»åˆ—äºˆæ¸¬</a>
    <a href="chapter5-advanced-topics.html" class="nav-button">æ¬¡ã®ç« ï¼šç™ºå±•çš„ãƒˆãƒ”ãƒƒã‚¯ â†’</a>
</div>

    </main>

    <footer>
        <p>&copy; 2025 AI Terakoya. All rights reserved.</p>
    </footer>
</body>
</html>
