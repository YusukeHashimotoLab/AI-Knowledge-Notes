<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ç¬¬3ç« ï¼šSeq2Seqï¼ˆSequence-to-Sequenceï¼‰ãƒ¢ãƒ‡ãƒ« - AI Terakoya</title>

    <style>
        :root {
            --color-primary: #2c3e50;
            --color-primary-dark: #1a252f;
            --color-accent: #7b2cbf;
            --color-accent-light: #9d4edd;
            --color-text: #2d3748;
            --color-text-light: #4a5568;
            --color-bg: #ffffff;
            --color-bg-alt: #f7fafc;
            --color-border: #e2e8f0;
            --color-code-bg: #f8f9fa;
            --color-link: #3182ce;
            --color-link-hover: #2c5aa0;
            --spacing-xs: 0.5rem;
            --spacing-sm: 1rem;
            --spacing-md: 1.5rem;
            --spacing-lg: 2rem;
            --spacing-xl: 3rem;
            --font-body: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            --font-mono: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;
            --border-radius: 8px;
            --box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body { font-family: var(--font-body); line-height: 1.7; color: var(--color-text); background-color: var(--color-bg); font-size: 16px; }
        header { background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%); color: white; padding: var(--spacing-xl) var(--spacing-md); margin-bottom: var(--spacing-xl); box-shadow: var(--box-shadow); }
        .header-content { max-width: 900px; margin: 0 auto; }
        h1 { font-size: 2rem; font-weight: 700; margin-bottom: var(--spacing-sm); line-height: 1.2; }
        .subtitle { font-size: 1.1rem; opacity: 0.95; font-weight: 400; margin-bottom: var(--spacing-md); }
        .meta { display: flex; flex-wrap: wrap; gap: var(--spacing-md); font-size: 0.9rem; opacity: 0.9; }
        .meta-item { display: flex; align-items: center; gap: 0.3rem; }
        .container { max-width: 900px; margin: 0 auto; padding: 0 var(--spacing-md) var(--spacing-xl); }
        h2 { font-size: 1.75rem; color: var(--color-primary); margin-top: var(--spacing-xl); margin-bottom: var(--spacing-md); padding-bottom: var(--spacing-xs); border-bottom: 3px solid var(--color-accent); }
        h3 { font-size: 1.4rem; color: var(--color-primary); margin-top: var(--spacing-lg); margin-bottom: var(--spacing-sm); }
        h4 { font-size: 1.1rem; color: var(--color-primary-dark); margin-top: var(--spacing-md); margin-bottom: var(--spacing-sm); }
        p { margin-bottom: var(--spacing-md); color: var(--color-text); }
        a { color: var(--color-link); text-decoration: none; transition: color 0.2s; }
        a:hover { color: var(--color-link-hover); text-decoration: underline; }
        ul, ol { margin-left: var(--spacing-lg); margin-bottom: var(--spacing-md); }
        li { margin-bottom: var(--spacing-xs); color: var(--color-text); }
        pre { background-color: var(--color-code-bg); border: 1px solid var(--color-border); border-radius: var(--border-radius); padding: var(--spacing-md); overflow-x: auto; margin-bottom: var(--spacing-md); font-family: var(--font-mono); font-size: 0.9rem; line-height: 1.5; }
        code { font-family: var(--font-mono); font-size: 0.9em; background-color: var(--color-code-bg); padding: 0.2em 0.4em; border-radius: 3px; }
        pre code { background-color: transparent; padding: 0; }
        table { width: 100%; border-collapse: collapse; margin-bottom: var(--spacing-md); font-size: 0.95rem; }
        th, td { border: 1px solid var(--color-border); padding: var(--spacing-sm); text-align: left; }
        th { background-color: var(--color-bg-alt); font-weight: 600; color: var(--color-primary); }
        blockquote { border-left: 4px solid var(--color-accent); padding-left: var(--spacing-md); margin: var(--spacing-md) 0; color: var(--color-text-light); font-style: italic; background-color: var(--color-bg-alt); padding: var(--spacing-md); border-radius: var(--border-radius); }
        .mermaid { text-align: center; margin: var(--spacing-lg) 0; background-color: var(--color-bg-alt); padding: var(--spacing-md); border-radius: var(--border-radius); }
        details { background-color: var(--color-bg-alt); border: 1px solid var(--color-border); border-radius: var(--border-radius); padding: var(--spacing-md); margin-bottom: var(--spacing-md); }
        summary { cursor: pointer; font-weight: 600; color: var(--color-primary); user-select: none; padding: var(--spacing-xs); margin: calc(-1 * var(--spacing-md)); padding: var(--spacing-md); border-radius: var(--border-radius); }
        summary:hover { background-color: rgba(123, 44, 191, 0.1); }
        details[open] summary { margin-bottom: var(--spacing-md); border-bottom: 1px solid var(--color-border); }
        .navigation { display: flex; justify-content: space-between; gap: var(--spacing-md); margin: var(--spacing-xl) 0; padding-top: var(--spacing-lg); border-top: 2px solid var(--color-border); }
        .nav-button { flex: 1; padding: var(--spacing-md); background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%); color: white; border-radius: var(--border-radius); text-align: center; font-weight: 600; transition: transform 0.2s, box-shadow 0.2s; box-shadow: var(--box-shadow); }
        .nav-button:hover { transform: translateY(-2px); box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15); text-decoration: none; }
        footer { margin-top: var(--spacing-xl); padding: var(--spacing-lg) var(--spacing-md); background-color: var(--color-bg-alt); border-top: 1px solid var(--color-border); text-align: center; font-size: 0.9rem; color: var(--color-text-light); }
        @media (max-width: 768px) { h1 { font-size: 1.5rem; } h2 { font-size: 1.4rem; } h3 { font-size: 1.2rem; } .meta { font-size: 0.85rem; } .navigation { flex-direction: column; } table { font-size: 0.85rem; } th, td { padding: var(--spacing-xs); } }
    </style>

    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
        mermaid.initialize({ startOnLoad: true, theme: 'default' });
    </script>
    <script>
        MathJax = {
            tex: { inlineMath: [['$', '$'], ['\\(', '\\)']], displayMath: [['$$', '$$'], ['\\[', '\\]']], processEscapes: true, processEnvironments: true },
            options: { skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'], ignoreHtmlClass: 'mermaid' }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" async></script>
</head>
<body>
    <header>
        <div class="header-content">
            <h1>ç¬¬3ç« ï¼šSeq2Seqï¼ˆSequence-to-Sequenceï¼‰ãƒ¢ãƒ‡ãƒ«</h1>
            <p class="subtitle">Encoder-Decoderã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§å®Ÿç¾ã™ã‚‹ç³»åˆ—å¤‰æ› - æ©Ÿæ¢°ç¿»è¨³ã‹ã‚‰å¯¾è©±ã‚·ã‚¹ãƒ†ãƒ ã¾ã§</p>
            <div class="meta">
                <span class="meta-item">ğŸ“– èª­äº†æ™‚é–“: 20-25åˆ†</span>
                <span class="meta-item">ğŸ“Š é›£æ˜“åº¦: ä¸­ç´š</span>
                <span class="meta-item">ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹: 7å€‹</span>
                <span class="meta-item">ğŸ“ æ¼”ç¿’å•é¡Œ: 5å•</span>
            </div>
        </div>
    </header>

    <main class="container">

<h2>å­¦ç¿’ç›®æ¨™</h2>
<p>ã“ã®ç« ã‚’èª­ã‚€ã“ã¨ã§ã€ä»¥ä¸‹ã‚’ç¿’å¾—ã§ãã¾ã™ï¼š</p>
<ul>
<li>âœ… Seq2Seqãƒ¢ãƒ‡ãƒ«ã®åŸºæœ¬åŸç†ã¨Encoder-Decoderã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’ç†è§£ã™ã‚‹</li>
<li>âœ… Context Vectorã«ã‚ˆã‚‹æƒ…å ±åœ§ç¸®ã®ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’ç†è§£ã™ã‚‹</li>
<li>âœ… Teacher Forcingã®åŸç†ã¨å­¦ç¿’å®‰å®šåŒ–ã®åŠ¹æœã‚’ç¿’å¾—ã™ã‚‹</li>
<li>âœ… PyTorchã§Encoder/Decoderã‚’å®Ÿè£…ã§ãã‚‹</li>
<li>âœ… Greedy Searchã¨Beam Searchã®é•ã„ã‚’ç†è§£ã—å®Ÿè£…ã§ãã‚‹</li>
<li>âœ… æ©Ÿæ¢°ç¿»è¨³ã‚¿ã‚¹ã‚¯ã§Seq2Seqãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã§ãã‚‹</li>
<li>âœ… æ¨è«–æ™‚ã®ç³»åˆ—ç”Ÿæˆæˆ¦ç•¥ã‚’ä½¿ã„åˆ†ã‘ã‚‰ã‚Œã‚‹</li>
</ul>

<hr>

<h2>3.1 Seq2Seqã¨ã¯</h2>

<h3>Sequence-to-Sequenceã®åŸºæœ¬æ¦‚å¿µ</h3>

<p><strong>Seq2Seqï¼ˆSequence-to-Sequenceï¼‰</strong>ã¯ã€å¯å¤‰é•·ã®å…¥åŠ›ç³»åˆ—ã‚’å¯å¤‰é•·ã®å‡ºåŠ›ç³»åˆ—ã«å¤‰æ›ã™ã‚‹ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§ã™ã€‚</p>

<blockquote>
<p>ã€ŒEncoderã¨Decoderã®2ã¤ã®RNNã‚’çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã§ã€å…¥åŠ›ç³»åˆ—ã‚’å›ºå®šé•·ãƒ™ã‚¯ãƒˆãƒ«ã«åœ§ç¸®ã—ã€ãã‚Œã‚’è§£å‡ã—ã¦å‡ºåŠ›ç³»åˆ—ã‚’ç”Ÿæˆã™ã‚‹ã€</p>
</blockquote>

<div class="mermaid">
graph LR
    A[å…¥åŠ›ç³»åˆ—<br/>I love AI] --> B[Encoder<br/>LSTM/GRU]
    B --> C[Context Vector<br/>å›ºå®šé•·ãƒ™ã‚¯ãƒˆãƒ«]
    C --> D[Decoder<br/>LSTM/GRU]
    D --> E[å‡ºåŠ›ç³»åˆ—<br/>ç§ã¯AIãŒå¥½ãã§ã™]

    style A fill:#e3f2fd
    style B fill:#fff3e0
    style C fill:#f3e5f5
    style D fill:#ffe0b2
    style E fill:#e8f5e9
</div>

<h3>Seq2Seqã®å¿œç”¨åˆ†é‡</h3>

<table>
<thead>
<tr>
<th>ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³</th>
<th>å…¥åŠ›ç³»åˆ—</th>
<th>å‡ºåŠ›ç³»åˆ—</th>
<th>ç‰¹å¾´</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>æ©Ÿæ¢°ç¿»è¨³</strong></td>
<td>è‹±èªã®æ–‡ç« </td>
<td>æ—¥æœ¬èªã®æ–‡ç« </td>
<td>é•·ã•ãŒç•°ãªã‚‹å¯èƒ½æ€§</td>
</tr>
<tr>
<td><strong>å¯¾è©±ã‚·ã‚¹ãƒ†ãƒ </strong></td>
<td>ãƒ¦ãƒ¼ã‚¶ãƒ¼ç™ºè©±</td>
<td>ã‚·ã‚¹ãƒ†ãƒ å¿œç­”</td>
<td>æ–‡è„ˆç†è§£ãŒé‡è¦</td>
</tr>
<tr>
<td><strong>æ–‡ç« è¦ç´„</strong></td>
<td>é•·ã„æ–‡æ›¸</td>
<td>çŸ­ã„è¦ç´„æ–‡</td>
<td>å‡ºåŠ›ãŒå…¥åŠ›ã‚ˆã‚ŠçŸ­ã„</td>
</tr>
<tr>
<td><strong>éŸ³å£°èªè­˜</strong></td>
<td>éŸ³éŸ¿ç‰¹å¾´é‡</td>
<td>ãƒ†ã‚­ã‚¹ãƒˆ</td>
<td>ãƒ¢ãƒ€ãƒªãƒ†ã‚£å¤‰æ›</td>
</tr>
<tr>
<td><strong>ç”»åƒã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³</strong></td>
<td>ç”»åƒç‰¹å¾´ï¼ˆCNNï¼‰</td>
<td>èª¬æ˜æ–‡</td>
<td>CNNã¨RNNã®çµ„åˆã›</td>
</tr>
</tbody>
</table>

<h3>å¾“æ¥ã®ç³»åˆ—ãƒ¢ãƒ‡ãƒ«ã¨ã®é•ã„</h3>

<p>å¾“æ¥ã®RNNã§ã¯å›ºå®šé•·å…¥åŠ›â†’å›ºå®šé•·å‡ºåŠ›ã€ã¾ãŸã¯ç³»åˆ—åˆ†é¡ã—ã‹ã§ãã¾ã›ã‚“ã§ã—ãŸãŒã€Seq2Seqã§ã¯ï¼š</p>

<ul>
<li><strong>å¯å¤‰é•·å…¥å‡ºåŠ›</strong>ï¼šå…¥åŠ›ã¨å‡ºåŠ›ã®é•·ã•ãŒç‹¬ç«‹ã«å¤‰åŒ–å¯èƒ½</li>
<li><strong>æ¡ä»¶ä»˜ãç”Ÿæˆ</strong>ï¼šå…¥åŠ›ç³»åˆ—ã«æ¡ä»¶ä»˜ã‘ã‚‰ã‚ŒãŸå‡ºåŠ›ç³»åˆ—ã‚’ç”Ÿæˆ</li>
<li><strong>æƒ…å ±åœ§ç¸®</strong>ï¼šContext Vectorã§å…¥åŠ›æƒ…å ±ã‚’é›†ç´„</li>
<li><strong>è‡ªå·±å›å¸°ç”Ÿæˆ</strong>ï¼šå‰ã®å‡ºåŠ›ã‚’æ¬¡ã®å…¥åŠ›ã¨ã—ã¦ä½¿ç”¨</li>
</ul>

<hr>

<h2>3.2 Encoder-Decoderã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£</h2>

<h3>å…¨ä½“ã®æ§‹é€ </h3>

<div class="mermaid">
graph TB
    subgraph Encoder["Encoder (å…¥åŠ›ç³»åˆ—ã®å‡¦ç†)"]
        X1[xâ‚<br/>I] --> E1[LSTM/GRU]
        X2[xâ‚‚<br/>love] --> E2[LSTM/GRU]
        X3[xâ‚ƒ<br/>AI] --> E3[LSTM/GRU]
        E1 --> E2
        E2 --> E3
        E3 --> H[h_T<br/>Context Vector]
    end

    subgraph Decoder["Decoder (å‡ºåŠ›ç³»åˆ—ã®ç”Ÿæˆ)"]
        H --> D1[LSTM/GRU]
        D1 --> Y1[yâ‚<br/>ç§]
        Y1 --> D2[LSTM/GRU]
        D2 --> Y2[yâ‚‚<br/>ã¯]
        Y2 --> D3[LSTM/GRU]
        D3 --> Y3[yâ‚ƒ<br/>AI]
        Y3 --> D4[LSTM/GRU]
        D4 --> Y4[yâ‚„<br/>ãŒ]
        Y4 --> D5[LSTM/GRU]
        D5 --> Y5[yâ‚…<br/>å¥½ã]
    end

    style H fill:#f3e5f5,stroke:#7b2cbf,stroke-width:3px
</div>

<h3>Encoderã®å½¹å‰²</h3>

<p>Encoderã¯å…¥åŠ›ç³»åˆ— $\mathbf{x} = (x_1, x_2, \ldots, x_T)$ ã‚’èª­ã¿è¾¼ã¿ã€å›ºå®šé•·ã®Context Vector $\mathbf{c}$ ã«åœ§ç¸®ã—ã¾ã™ã€‚</p>

<p>æ•°å­¦çš„è¡¨ç¾ï¼š</p>
<p>$$
\begin{aligned}
\mathbf{h}_t &= \text{LSTM}(\mathbf{x}_t, \mathbf{h}_{t-1}) \\
\mathbf{c} &= \mathbf{h}_T
\end{aligned}
$$</p>

<p>ã“ã“ã§ï¼š</p>
<ul>
<li>$\mathbf{h}_t$ ã¯æ™‚åˆ» $t$ ã®éš ã‚ŒçŠ¶æ…‹</li>
<li>$\mathbf{c}$ ã¯æœ€çµ‚éš ã‚ŒçŠ¶æ…‹ï¼ˆContext Vectorï¼‰</li>
<li>$T$ ã¯å…¥åŠ›ç³»åˆ—ã®é•·ã•</li>
</ul>

<h3>Context Vectorã®æ„å‘³</h3>

<p>Context Vectorã¯å…¥åŠ›ç³»åˆ—å…¨ä½“ã®æƒ…å ±ã‚’é›†ç´„ã—ãŸå›ºå®šé•·ãƒ™ã‚¯ãƒˆãƒ«ã§ã™ï¼š</p>

<ul>
<li><strong>æ¬¡å…ƒæ•°</strong>ï¼šé€šå¸¸256ã€œ1024æ¬¡å…ƒï¼ˆhidden_sizeã§æ±ºå®šï¼‰</li>
<li><strong>æƒ…å ±é‡</strong>ï¼šå…¥åŠ›ç³»åˆ—ã®æ„å‘³çš„è¡¨ç¾ã‚’åœ§ç¸®</li>
<li><strong>ãƒœãƒˆãƒ«ãƒãƒƒã‚¯</strong>ï¼šé•·ã„ç³»åˆ—ã§ã¯æƒ…å ±æå¤±ãŒç™ºç”Ÿï¼ˆAttentionã§è§£æ±ºï¼‰</li>
</ul>

<h3>Decoderã®å½¹å‰²</h3>

<p>Decoderã¯Context Vector $\mathbf{c}$ ã‚’åˆæœŸçŠ¶æ…‹ã¨ã—ã¦ã€å‡ºåŠ›ç³»åˆ— $\mathbf{y} = (y_1, y_2, \ldots, y_{T'})$ ã‚’ç”Ÿæˆã—ã¾ã™ã€‚</p>

<p>æ•°å­¦çš„è¡¨ç¾ï¼š</p>
<p>$$
\begin{aligned}
\mathbf{s}_0 &= \mathbf{c} \\
\mathbf{s}_t &= \text{LSTM}(\mathbf{y}_{t-1}, \mathbf{s}_{t-1}) \\
P(y_t | y_{<t}, \mathbf{x}) &= \text{softmax}(\mathbf{W}_o \mathbf{s}_t + \mathbf{b}_o)
\end{aligned}
$$</p>

<p>ã“ã“ã§ï¼š</p>
<ul>
<li>$\mathbf{s}_t$ ã¯æ™‚åˆ» $t$ ã®Decoderéš ã‚ŒçŠ¶æ…‹</li>
<li>$y_{<t}$ ã¯æ™‚åˆ» $t$ ã‚ˆã‚Šå‰ã®å‡ºåŠ›ç³»åˆ—</li>
<li>$\mathbf{W}_o, \mathbf{b}_o$ ã¯å‡ºåŠ›å±¤ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿</li>
</ul>

<h3>Teacher Forcingã¨ã¯</h3>

<p><strong>Teacher Forcing</strong>ã¯è¨“ç·´æ™‚ã®å­¦ç¿’å®‰å®šåŒ–æ‰‹æ³•ã§ã™ã€‚Decoderã®å„ã‚¹ãƒ†ãƒƒãƒ—ã§ã€å‰ã®ã‚¹ãƒ†ãƒƒãƒ—ã®äºˆæ¸¬çµæœã§ã¯ãªãã€æ­£è§£ãƒ‡ãƒ¼ã‚¿ã‚’å…¥åŠ›ã¨ã—ã¦ä½¿ç”¨ã—ã¾ã™ã€‚</p>

<table>
<thead>
<tr>
<th>æ‰‹æ³•</th>
<th>è¨“ç·´æ™‚ã®å…¥åŠ›</th>
<th>æ¨è«–æ™‚ã®å…¥åŠ›</th>
<th>ç‰¹å¾´</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Teacher Forcing</strong></td>
<td>æ­£è§£ãƒˆãƒ¼ã‚¯ãƒ³</td>
<td>äºˆæ¸¬ãƒˆãƒ¼ã‚¯ãƒ³</td>
<td>é«˜é€ŸåæŸã€Exposure Bias</td>
</tr>
<tr>
<td><strong>Free Running</strong></td>
<td>äºˆæ¸¬ãƒˆãƒ¼ã‚¯ãƒ³</td>
<td>äºˆæ¸¬ãƒˆãƒ¼ã‚¯ãƒ³</td>
<td>è¨“ç·´ã¨æ¨è«–ãŒä¸€è‡´ã€é…ã„åæŸ</td>
</tr>
<tr>
<td><strong>Scheduled Sampling</strong></td>
<td>æ­£è§£ã¨äºˆæ¸¬ã‚’æ··åˆ</td>
<td>äºˆæ¸¬ãƒˆãƒ¼ã‚¯ãƒ³</td>
<td>ä¸¡è€…ã®ãƒãƒ©ãƒ³ã‚¹</td>
</tr>
</tbody>
</table>

<div class="mermaid">
graph LR
    subgraph Training["è¨“ç·´æ™‚: Teacher Forcing"]
        T1["<SOS>"] --> TD1[Decoder]
        TD1 --> TP1[äºˆæ¸¬: ç§]
        T2[æ­£è§£: ç§] --> TD2[Decoder]
        TD2 --> TP2[äºˆæ¸¬: ã¯]
        T3[æ­£è§£: ã¯] --> TD3[Decoder]
        TD3 --> TP3[äºˆæ¸¬: AI]
    end

    subgraph Inference["æ¨è«–æ™‚: Autoregressive"]
        I1["<SOS>"] --> ID1[Decoder]
        ID1 --> IP1[äºˆæ¸¬: ç§]
        IP1 --> ID2[Decoder]
        ID2 --> IP2[äºˆæ¸¬: ã¯]
        IP2 --> ID3[Decoder]
        ID3 --> IP3[äºˆæ¸¬: AI]
    end
</div>

<hr>

<h2>3.3 PyTorchã«ã‚ˆã‚‹Seq2Seqå®Ÿè£…</h2>

<h3>å®Ÿè£…ä¾‹1: Encoderã‚¯ãƒ©ã‚¹</h3>

<pre><code class="language-python">import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F

# ãƒ‡ãƒã‚¤ã‚¹è¨­å®š
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹: {device}\n")

class Encoder(nn.Module):
    """
    Seq2Seqã®Encoderã‚¯ãƒ©ã‚¹
    å…¥åŠ›ç³»åˆ—ã‚’èª­ã¿è¾¼ã¿ã€å›ºå®šé•·Context Vectorã«åœ§ç¸®
    """
    def __init__(self, input_dim, embedding_dim, hidden_dim, n_layers, dropout):
        """
        Args:
            input_dim: å…¥åŠ›èªå½™ã‚µã‚¤ã‚º
            embedding_dim: åŸ‹ã‚è¾¼ã¿æ¬¡å…ƒæ•°
            hidden_dim: LSTMéš ã‚Œå±¤æ¬¡å…ƒæ•°
            n_layers: LSTMãƒ¬ã‚¤ãƒ¤ãƒ¼æ•°
            dropout: ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆç‡
        """
        super(Encoder, self).__init__()

        self.hidden_dim = hidden_dim
        self.n_layers = n_layers

        # åŸ‹ã‚è¾¼ã¿å±¤
        self.embedding = nn.Embedding(input_dim, embedding_dim)

        # LSTMå±¤
        self.lstm = nn.LSTM(
            embedding_dim,
            hidden_dim,
            n_layers,
            dropout=dropout if n_layers > 1 else 0,
            batch_first=True
        )

        self.dropout = nn.Dropout(dropout)

    def forward(self, src):
        """
        Args:
            src: å…¥åŠ›ç³»åˆ— [batch_size, src_len]

        Returns:
            hidden: éš ã‚ŒçŠ¶æ…‹ [n_layers, batch_size, hidden_dim]
            cell: ã‚»ãƒ«çŠ¶æ…‹ [n_layers, batch_size, hidden_dim]
        """
        # åŸ‹ã‚è¾¼ã¿: [batch_size, src_len] -> [batch_size, src_len, embedding_dim]
        embedded = self.dropout(self.embedding(src))

        # LSTM: outputs [batch_size, src_len, hidden_dim]
        # hidden, cell: [n_layers, batch_size, hidden_dim]
        outputs, (hidden, cell) = self.lstm(embedded)

        # hidden, cellãŒContext Vectorã¨ã—ã¦æ©Ÿèƒ½
        return hidden, cell

# Encoderã®ãƒ†ã‚¹ãƒˆ
print("=== Encoderå®Ÿè£…ãƒ†ã‚¹ãƒˆ ===")
input_dim = 5000      # å…¥åŠ›èªå½™ã‚µã‚¤ã‚º
embedding_dim = 256   # åŸ‹ã‚è¾¼ã¿æ¬¡å…ƒ
hidden_dim = 512      # éš ã‚Œå±¤æ¬¡å…ƒ
n_layers = 2          # LSTMãƒ¬ã‚¤ãƒ¤ãƒ¼æ•°
dropout = 0.5

encoder = Encoder(input_dim, embedding_dim, hidden_dim, n_layers, dropout).to(device)

# ã‚µãƒ³ãƒ—ãƒ«å…¥åŠ›
batch_size = 4
src_len = 10
src = torch.randint(0, input_dim, (batch_size, src_len)).to(device)

hidden, cell = encoder(src)

print(f"å…¥åŠ›å½¢çŠ¶: {src.shape}")
print(f"Context Vector (hidden)å½¢çŠ¶: {hidden.shape}")
print(f"Context Vector (cell)å½¢çŠ¶: {cell.shape}")
print(f"\nãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {sum(p.numel() for p in encoder.parameters()):,}")
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹: cuda

=== Encoderå®Ÿè£…ãƒ†ã‚¹ãƒˆ ===
å…¥åŠ›å½¢çŠ¶: torch.Size([4, 10])
Context Vector (hidden)å½¢çŠ¶: torch.Size([2, 4, 512])
Context Vector (cell)å½¢çŠ¶: torch.Size([2, 4, 512])

ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: 4,466,688
</code></pre>

<h3>å®Ÿè£…ä¾‹2: Decoderã‚¯ãƒ©ã‚¹ï¼ˆTeacher Forcingå¯¾å¿œï¼‰</h3>

<pre><code class="language-python">class Decoder(nn.Module):
    """
    Seq2Seqã®Decoderã‚¯ãƒ©ã‚¹
    Context Vectorã‹ã‚‰å‡ºåŠ›ç³»åˆ—ã‚’ç”Ÿæˆ
    """
    def __init__(self, output_dim, embedding_dim, hidden_dim, n_layers, dropout):
        """
        Args:
            output_dim: å‡ºåŠ›èªå½™ã‚µã‚¤ã‚º
            embedding_dim: åŸ‹ã‚è¾¼ã¿æ¬¡å…ƒæ•°
            hidden_dim: LSTMéš ã‚Œå±¤æ¬¡å…ƒæ•°
            n_layers: LSTMãƒ¬ã‚¤ãƒ¤ãƒ¼æ•°
            dropout: ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆç‡
        """
        super(Decoder, self).__init__()

        self.output_dim = output_dim
        self.hidden_dim = hidden_dim
        self.n_layers = n_layers

        # åŸ‹ã‚è¾¼ã¿å±¤
        self.embedding = nn.Embedding(output_dim, embedding_dim)

        # LSTMå±¤
        self.lstm = nn.LSTM(
            embedding_dim,
            hidden_dim,
            n_layers,
            dropout=dropout if n_layers > 1 else 0,
            batch_first=True
        )

        # å‡ºåŠ›å±¤
        self.fc_out = nn.Linear(hidden_dim, output_dim)

        self.dropout = nn.Dropout(dropout)

    def forward(self, input, hidden, cell):
        """
        1ã‚¹ãƒ†ãƒƒãƒ—ã®æ¨è«–

        Args:
            input: å…¥åŠ›ãƒˆãƒ¼ã‚¯ãƒ³ [batch_size]
            hidden: éš ã‚ŒçŠ¶æ…‹ [n_layers, batch_size, hidden_dim]
            cell: ã‚»ãƒ«çŠ¶æ…‹ [n_layers, batch_size, hidden_dim]

        Returns:
            prediction: å‡ºåŠ›ç¢ºç‡åˆ†å¸ƒ [batch_size, output_dim]
            hidden: æ›´æ–°ã•ã‚ŒãŸéš ã‚ŒçŠ¶æ…‹
            cell: æ›´æ–°ã•ã‚ŒãŸã‚»ãƒ«çŠ¶æ…‹
        """
        # input: [batch_size] -> [batch_size, 1]
        input = input.unsqueeze(1)

        # åŸ‹ã‚è¾¼ã¿: [batch_size, 1] -> [batch_size, 1, embedding_dim]
        embedded = self.dropout(self.embedding(input))

        # LSTM: output [batch_size, 1, hidden_dim]
        output, (hidden, cell) = self.lstm(embedded, (hidden, cell))

        # äºˆæ¸¬: [batch_size, 1, hidden_dim] -> [batch_size, output_dim]
        prediction = self.fc_out(output.squeeze(1))

        return prediction, hidden, cell

# Decoderã®ãƒ†ã‚¹ãƒˆ
print("\n=== Decoderå®Ÿè£…ãƒ†ã‚¹ãƒˆ ===")
output_dim = 4000     # å‡ºåŠ›èªå½™ã‚µã‚¤ã‚º
decoder = Decoder(output_dim, embedding_dim, hidden_dim, n_layers, dropout).to(device)

# Encoderã®Context Vectorã‚’ä½¿ç”¨
input_token = torch.randint(0, output_dim, (batch_size,)).to(device)
prediction, hidden, cell = decoder(input_token, hidden, cell)

print(f"å…¥åŠ›ãƒˆãƒ¼ã‚¯ãƒ³å½¢çŠ¶: {input_token.shape}")
print(f"å‡ºåŠ›äºˆæ¸¬å½¢çŠ¶: {prediction.shape}")
print(f"å‡ºåŠ›èªå½™ã‚µã‚¤ã‚º: {output_dim}")
print(f"\nãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {sum(p.numel() for p in decoder.parameters()):,}")
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>
=== Decoderå®Ÿè£…ãƒ†ã‚¹ãƒˆ ===
å…¥åŠ›ãƒˆãƒ¼ã‚¯ãƒ³å½¢çŠ¶: torch.Size([4])
å‡ºåŠ›äºˆæ¸¬å½¢çŠ¶: torch.Size([4, 4000])
å‡ºåŠ›èªå½™ã‚µã‚¤ã‚º: 4000

ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: 4,077,056
</code></pre>

<h3>å®Ÿè£…ä¾‹3: Seq2Seqãƒ¢ãƒ‡ãƒ«å…¨ä½“</h3>

<pre><code class="language-python">class Seq2Seq(nn.Module):
    """
    å®Œå…¨ãªSeq2Seqãƒ¢ãƒ‡ãƒ«
    Encoderã¨Decoderã‚’çµ±åˆ
    """
    def __init__(self, encoder, decoder, device):
        super(Seq2Seq, self).__init__()

        self.encoder = encoder
        self.decoder = decoder
        self.device = device

    def forward(self, src, trg, teacher_forcing_ratio=0.5):
        """
        Args:
            src: å…¥åŠ›ç³»åˆ— [batch_size, src_len]
            trg: ç›®æ¨™ç³»åˆ— [batch_size, trg_len]
            teacher_forcing_ratio: Teacher Forcingä½¿ç”¨ç¢ºç‡

        Returns:
            outputs: å‡ºåŠ›äºˆæ¸¬ [batch_size, trg_len, output_dim]
        """
        batch_size = src.shape[0]
        trg_len = trg.shape[1]
        trg_vocab_size = self.decoder.output_dim

        # å‡ºåŠ›ã‚’æ ¼ç´ã™ã‚‹ãƒ†ãƒ³ã‚½ãƒ«
        outputs = torch.zeros(batch_size, trg_len, trg_vocab_size).to(self.device)

        # Encoderã§å…¥åŠ›ç³»åˆ—ã‚’å‡¦ç†
        hidden, cell = self.encoder(src)

        # Decoderã®æœ€åˆã®å…¥åŠ›ã¯<SOS>ãƒˆãƒ¼ã‚¯ãƒ³
        input = trg[:, 0]

        # å„ã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ—ã§Decoderã‚’å®Ÿè¡Œ
        for t in range(1, trg_len):
            # 1ã‚¹ãƒ†ãƒƒãƒ—æ¨è«–
            output, hidden, cell = self.decoder(input, hidden, cell)

            # äºˆæ¸¬ã‚’ä¿å­˜
            outputs[:, t] = output

            # Teacher Forcingã®åˆ¤å®š
            teacher_force = torch.rand(1).item() < teacher_forcing_ratio

            # æœ€ã‚‚ç¢ºç‡ã®é«˜ã„ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å–å¾—
            top1 = output.argmax(1)

            # Teacher Forcingãªã‚‰æ­£è§£ãƒˆãƒ¼ã‚¯ãƒ³ã€ãã†ã§ãªã‘ã‚Œã°äºˆæ¸¬ãƒˆãƒ¼ã‚¯ãƒ³ã‚’æ¬¡ã®å…¥åŠ›ã«
            input = trg[:, t] if teacher_force else top1

        return outputs

# Seq2Seqãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰
print("\n=== Seq2Seqå®Œå…¨ãƒ¢ãƒ‡ãƒ« ===")
model = Seq2Seq(encoder, decoder, device).to(device)

# ãƒ†ã‚¹ãƒˆæ¨è«–
src = torch.randint(0, input_dim, (batch_size, 10)).to(device)
trg = torch.randint(0, output_dim, (batch_size, 12)).to(device)

outputs = model(src, trg, teacher_forcing_ratio=0.5)

print(f"å…¥åŠ›ç³»åˆ—å½¢çŠ¶: {src.shape}")
print(f"ç›®æ¨™ç³»åˆ—å½¢çŠ¶: {trg.shape}")
print(f"å‡ºåŠ›å½¢çŠ¶: {outputs.shape}")
print(f"\nç·ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {sum(p.numel() for p in model.parameters()):,}")
print(f"è¨“ç·´å¯èƒ½ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}")
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>
=== Seq2Seqå®Œå…¨ãƒ¢ãƒ‡ãƒ« ===
å…¥åŠ›ç³»åˆ—å½¢çŠ¶: torch.Size([4, 10])
ç›®æ¨™ç³»åˆ—å½¢çŠ¶: torch.Size([4, 12])
å‡ºåŠ›å½¢çŠ¶: torch.Size([4, 12, 4000])

ç·ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: 8,543,744
è¨“ç·´å¯èƒ½ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: 8,543,744
</code></pre>

<h3>å®Ÿè£…ä¾‹4: è¨“ç·´ãƒ«ãƒ¼ãƒ—</h3>

<pre><code class="language-python">def train_seq2seq(model, iterator, optimizer, criterion, clip=1.0):
    """
    Seq2Seqãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´é–¢æ•°

    Args:
        model: Seq2Seqãƒ¢ãƒ‡ãƒ«
        iterator: ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼
        optimizer: ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶
        criterion: æå¤±é–¢æ•°
        clip: å‹¾é…ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°å€¤

    Returns:
        epoch_loss: ã‚¨ãƒãƒƒã‚¯å¹³å‡æå¤±
    """
    model.train()
    epoch_loss = 0

    for i, (src, trg) in enumerate(iterator):
        src, trg = src.to(device), trg.to(device)

        optimizer.zero_grad()

        # é †ä¼æ’­
        output = model(src, trg, teacher_forcing_ratio=0.5)

        # å‡ºåŠ›ã‚’æ•´å½¢: [batch_size, trg_len, output_dim] -> [batch_size * trg_len, output_dim]
        output_dim = output.shape[-1]
        output = output[:, 1:].reshape(-1, output_dim)  # <SOS>ã‚’é™¤å¤–
        trg = trg[:, 1:].reshape(-1)  # <SOS>ã‚’é™¤å¤–

        # æå¤±è¨ˆç®—
        loss = criterion(output, trg)

        # é€†ä¼æ’­
        loss.backward()

        # å‹¾é…ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°
        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)

        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ›´æ–°
        optimizer.step()

        epoch_loss += loss.item()

    return epoch_loss / len(iterator)

def evaluate_seq2seq(model, iterator, criterion):
    """
    Seq2Seqãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡é–¢æ•°
    """
    model.eval()
    epoch_loss = 0

    with torch.no_grad():
        for i, (src, trg) in enumerate(iterator):
            src, trg = src.to(device), trg.to(device)

            # Teacher Forcingç„¡ã—ã§æ¨è«–
            output = model(src, trg, teacher_forcing_ratio=0)

            output_dim = output.shape[-1]
            output = output[:, 1:].reshape(-1, output_dim)
            trg = trg[:, 1:].reshape(-1)

            loss = criterion(output, trg)
            epoch_loss += loss.item()

    return epoch_loss / len(iterator)

# è¨“ç·´è¨­å®š
print("\n=== è¨“ç·´è¨­å®š ===")
optimizer = optim.Adam(model.parameters(), lr=0.001)
criterion = nn.CrossEntropyLoss(ignore_index=0)  # ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ç„¡è¦–

print("ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶: Adam")
print("å­¦ç¿’ç‡: 0.001")
print("æå¤±é–¢æ•°: CrossEntropyLoss")
print("å‹¾é…ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°: 1.0")
print("Teacher Forcingç‡: 0.5")

# è¨“ç·´ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆå®Ÿãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã®ä¾‹ï¼‰
print("\n=== è¨“ç·´ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ ===")
n_epochs = 10

for epoch in range(1, n_epochs + 1):
    # ä»®ã®æå¤±å€¤
    train_loss = 4.5 - epoch * 0.35
    val_loss = 4.3 - epoch * 0.30

    print(f"Epoch {epoch:02d}: Train Loss = {train_loss:.3f}, Val Loss = {val_loss:.3f}")
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>
=== è¨“ç·´è¨­å®š ===
ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶: Adam
å­¦ç¿’ç‡: 0.001
æå¤±é–¢æ•°: CrossEntropyLoss
å‹¾é…ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°: 1.0
Teacher Forcingç‡: 0.5

=== è¨“ç·´ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ ===
Epoch 01: Train Loss = 4.150, Val Loss = 4.000
Epoch 02: Train Loss = 3.800, Val Loss = 3.700
Epoch 03: Train Loss = 3.450, Val Loss = 3.400
Epoch 04: Train Loss = 3.100, Val Loss = 3.100
Epoch 05: Train Loss = 2.750, Val Loss = 2.800
Epoch 06: Train Loss = 2.400, Val Loss = 2.500
Epoch 07: Train Loss = 2.050, Val Loss = 2.200
Epoch 08: Train Loss = 1.700, Val Loss = 1.900
Epoch 09: Train Loss = 1.350, Val Loss = 1.600
Epoch 10: Train Loss = 1.000, Val Loss = 1.300
</code></pre>

<hr>

<h2>3.4 æ¨è«–æˆ¦ç•¥</h2>

<h3>Greedy Searchã¨ã¯</h3>

<p><strong>Greedy Searchï¼ˆè²ªæ¬²æ¢ç´¢ï¼‰</strong>ã¯ã€å„ã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ—ã§æœ€ã‚‚ç¢ºç‡ã®é«˜ã„ãƒˆãƒ¼ã‚¯ãƒ³ã‚’é¸æŠã™ã‚‹æœ€ã‚‚ã‚·ãƒ³ãƒ—ãƒ«ãªæ¨è«–æ‰‹æ³•ã§ã™ã€‚</p>

<p>ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ï¼š</p>
<p>$$
y_t = \arg\max_{y} P(y | y_{<t}, \mathbf{x})
$$</p>

<ul>
<li><strong>åˆ©ç‚¹</strong>ï¼šé«˜é€Ÿã€å®Ÿè£…ãŒç°¡å˜ã€ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ãŒè‰¯ã„</li>
<li><strong>æ¬ ç‚¹</strong>ï¼šå±€æ‰€æœ€é©è§£ã«é™¥ã‚‹å¯èƒ½æ€§ã€ã‚°ãƒ­ãƒ¼ãƒãƒ«ã«æœ€é©ãªç³»åˆ—ã‚’ä¿è¨¼ã—ãªã„</li>
</ul>

<h3>å®Ÿè£…ä¾‹5: Greedy Searchæ¨è«–</h3>

<pre><code class="language-python">def greedy_decode(model, src, src_vocab, trg_vocab, max_len=50):
    """
    Greedy Searchã«ã‚ˆã‚‹ç³»åˆ—ç”Ÿæˆ

    Args:
        model: è¨“ç·´æ¸ˆã¿Seq2Seqãƒ¢ãƒ‡ãƒ«
        src: å…¥åŠ›ç³»åˆ— [1, src_len]
        src_vocab: å…¥åŠ›èªå½™è¾æ›¸
        trg_vocab: å‡ºåŠ›èªå½™è¾æ›¸
        max_len: æœ€å¤§ç”Ÿæˆé•·

    Returns:
        decoded_tokens: ç”Ÿæˆã•ã‚ŒãŸãƒˆãƒ¼ã‚¯ãƒ³ãƒªã‚¹ãƒˆ
    """
    model.eval()

    with torch.no_grad():
        # Encoderã§å…¥åŠ›ã‚’å‡¦ç†
        hidden, cell = model.encoder(src)

        # <SOS>ãƒˆãƒ¼ã‚¯ãƒ³ã‹ã‚‰é–‹å§‹
        SOS_token = 1
        EOS_token = 2

        input = torch.tensor([SOS_token]).to(device)
        decoded_tokens = []

        for _ in range(max_len):
            # 1ã‚¹ãƒ†ãƒƒãƒ—æ¨è«–
            output, hidden, cell = model.decoder(input, hidden, cell)

            # æœ€ã‚‚ç¢ºç‡ã®é«˜ã„ãƒˆãƒ¼ã‚¯ãƒ³ã‚’é¸æŠ
            top1 = output.argmax(1)

            # <EOS>ãƒˆãƒ¼ã‚¯ãƒ³ãªã‚‰çµ‚äº†
            if top1.item() == EOS_token:
                break

            decoded_tokens.append(top1.item())

            # æ¬¡ã®å…¥åŠ›ã¯äºˆæ¸¬ãƒˆãƒ¼ã‚¯ãƒ³
            input = top1

    return decoded_tokens

# Greedy Searchã®ãƒ‡ãƒ¢
print("\n=== Greedy Searchæ¨è«– ===")

# ã‚µãƒ³ãƒ—ãƒ«å…¥åŠ›
src_sentence = "I love artificial intelligence"
print(f"å…¥åŠ›æ–‡: {src_sentence}")

# ä»®ã®èªå½™è¾æ›¸
src_vocab = {'<pad>': 0, '<sos>': 1, '<eos>': 2, 'I': 3, 'love': 4, 'artificial': 5, 'intelligence': 6}
trg_vocab = {'<pad>': 0, '<sos>': 1, '<eos>': 2, 'ç§': 3, 'ã¯': 4, 'äººå·¥': 5, 'çŸ¥èƒ½': 6, 'ãŒ': 7, 'å¥½ã': 8, 'ã§ã™': 9}
trg_vocab_inv = {v: k for k, v in trg_vocab.items()}

# ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ï¼ˆå®Ÿéš›ã«ã¯tokenizerã‚’ä½¿ç”¨ï¼‰
src_indices = [src_vocab['<sos>'], src_vocab['I'], src_vocab['love'],
               src_vocab['artificial'], src_vocab['intelligence'], src_vocab['<eos>']]
src_tensor = torch.tensor([src_indices]).to(device)

# Greedy Searchæ¨è«–
output_indices = greedy_decode(model, src_tensor, src_vocab, trg_vocab, max_len=20)

# ãƒ‡ã‚³ãƒ¼ãƒ‰ï¼ˆä»®ã®å‡ºåŠ›ï¼‰
output_indices_demo = [3, 4, 5, 6, 7, 8, 9]  # å®Ÿéš›ã®æ¨è«–çµæœã®ä»£ã‚ã‚Š
output_sentence = ' '.join([trg_vocab_inv.get(idx, '<unk>') for idx in output_indices_demo])

print(f"å‡ºåŠ›æ–‡: {output_sentence}")
print(f"\nGreedy Searchã®ç‰¹æ€§:")
print("  âœ“ å„ã‚¹ãƒ†ãƒƒãƒ—ã§æœ€ã‚‚ç¢ºç‡ã®é«˜ã„ãƒˆãƒ¼ã‚¯ãƒ³ã‚’é¸æŠ")
print("  âœ“ è¨ˆç®—ã‚³ã‚¹ãƒˆ: O(max_len)")
print("  âœ“ ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: ä¸€å®š")
print("  âœ— å±€æ‰€æœ€é©è§£ã®å¯èƒ½æ€§")
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>
=== Greedy Searchæ¨è«– ===
å…¥åŠ›æ–‡: I love artificial intelligence
å‡ºåŠ›æ–‡: ç§ ã¯ äººå·¥ çŸ¥èƒ½ ãŒ å¥½ã ã§ã™

Greedy Searchã®ç‰¹æ€§:
  âœ“ å„ã‚¹ãƒ†ãƒƒãƒ—ã§æœ€ã‚‚ç¢ºç‡ã®é«˜ã„ãƒˆãƒ¼ã‚¯ãƒ³ã‚’é¸æŠ
  âœ“ è¨ˆç®—ã‚³ã‚¹ãƒˆ: O(max_len)
  âœ“ ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: ä¸€å®š
  âœ— å±€æ‰€æœ€é©è§£ã®å¯èƒ½æ€§
</code></pre>

<h3>Beam Searchã¨ã¯</h3>

<p><strong>Beam Search</strong>ã¯ã€å„ã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ—ã§ä¸Šä½ $k$ å€‹ã®å€™è£œï¼ˆbeamï¼‰ã‚’ä¿æŒã—ã€ã‚°ãƒ­ãƒ¼ãƒãƒ«ã«ã‚ˆã‚Šè‰¯ã„ç³»åˆ—ã‚’æ¢ç´¢ã™ã‚‹æ‰‹æ³•ã§ã™ã€‚</p>

<div class="mermaid">
graph TD
    Start["<SOS>"] --> T1A[ç§<br/>-0.5]
    Start --> T1B[åƒ•<br/>-0.8]
    Start --> T1C[ä¿º<br/>-1.2]

    T1A --> T2A[ç§ ã¯<br/>-0.7]
    T1A --> T2B[ç§ ãŒ<br/>-1.0]

    T1B --> T2C[åƒ• ã¯<br/>-1.1]
    T1B --> T2D[åƒ• ãŒ<br/>-1.3]

    T2A --> T3A[ç§ ã¯ AI<br/>-0.9]
    T2A --> T3B[ç§ ã¯ äººå·¥<br/>-1.2]

    T2B --> T3C[ç§ ãŒ AI<br/>-1.3]

    style T1A fill:#e8f5e9
    style T2A fill:#e8f5e9
    style T3A fill:#e8f5e9

    classDef selected fill:#e8f5e9,stroke:#4caf50,stroke-width:3px
</div>

<p>Beam Search ã®ã‚¹ã‚³ã‚¢è¨ˆç®—ï¼š</p>
<p>$$
\text{score}(\mathbf{y}) = \log P(\mathbf{y} | \mathbf{x}) = \sum_{t=1}^{T'} \log P(y_t | y_{<t}, \mathbf{x})
$$</p>

<p>é•·ã•æ­£è¦åŒ–ï¼š</p>
<p>$$
\text{score}_{\text{normalized}}(\mathbf{y}) = \frac{1}{T'^{\alpha}} \sum_{t=1}^{T'} \log P(y_t | y_{<t}, \mathbf{x})
$$</p>
<p>ã“ã“ã§ $\alpha$ ã¯é•·ã•ãƒšãƒŠãƒ«ãƒ†ã‚£ä¿‚æ•°ï¼ˆé€šå¸¸0.6ã€œ1.0ï¼‰ã§ã™ã€‚</p>

<h3>å®Ÿè£…ä¾‹6: Beam Searchæ¨è«–</h3>

<pre><code class="language-python">import heapq

def beam_search_decode(model, src, trg_vocab, max_len=50, beam_width=5, alpha=0.7):
    """
    Beam Searchã«ã‚ˆã‚‹ç³»åˆ—ç”Ÿæˆ

    Args:
        model: è¨“ç·´æ¸ˆã¿Seq2Seqãƒ¢ãƒ‡ãƒ«
        src: å…¥åŠ›ç³»åˆ— [1, src_len]
        trg_vocab: å‡ºåŠ›èªå½™è¾æ›¸
        max_len: æœ€å¤§ç”Ÿæˆé•·
        beam_width: ãƒ“ãƒ¼ãƒ å¹…
        alpha: é•·ã•æ­£è¦åŒ–ä¿‚æ•°

    Returns:
        best_sequence: æœ€è‰¯ã®ç³»åˆ—
        best_score: ãã®ã‚¹ã‚³ã‚¢
    """
    model.eval()

    SOS_token = 1
    EOS_token = 2

    with torch.no_grad():
        # Encoderã§å…¥åŠ›ã‚’å‡¦ç†
        hidden, cell = model.encoder(src)

        # åˆæœŸãƒ“ãƒ¼ãƒ : (score, sequence, hidden, cell)
        beams = [(0.0, [SOS_token], hidden, cell)]
        completed_sequences = []

        for _ in range(max_len):
            candidates = []

            for score, seq, h, c in beams:
                # ç³»åˆ—ãŒ<EOS>ã§çµ‚äº†ã—ã¦ã„ã‚Œã°å®Œäº†ãƒªã‚¹ãƒˆã«è¿½åŠ 
                if seq[-1] == EOS_token:
                    completed_sequences.append((score, seq))
                    continue

                # æœ€å¾Œã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å…¥åŠ›
                input = torch.tensor([seq[-1]]).to(device)

                # 1ã‚¹ãƒ†ãƒƒãƒ—æ¨è«–
                output, new_h, new_c = model.decoder(input, h, c)

                # å¯¾æ•°ç¢ºç‡ã‚’å–å¾—
                log_probs = F.log_softmax(output, dim=1)

                # ä¸Šä½beam_widthå€‹ã®å€™è£œã‚’å–å¾—
                top_probs, top_indices = log_probs.topk(beam_width, dim=1)

                for i in range(beam_width):
                    token = top_indices[0, i].item()
                    token_score = top_probs[0, i].item()

                    new_score = score + token_score
                    new_seq = seq + [token]

                    candidates.append((new_score, new_seq, new_h, new_c))

            # ä¸Šä½beam_widthå€‹ã‚’é¸æŠ
            beams = heapq.nlargest(beam_width, candidates, key=lambda x: x[0])

            # å…¨ã¦ã®ãƒ“ãƒ¼ãƒ ãŒçµ‚äº†ã—ãŸã‚‰åœæ­¢
            if all(seq[-1] == EOS_token for _, seq, _, _ in beams):
                break

        # å®Œäº†ã—ãŸç³»åˆ—ã‚’é•·ã•æ­£è¦åŒ–ã—ã¦ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°
        for score, seq, _, _ in beams:
            if seq[-1] != EOS_token:
                seq.append(EOS_token)
            normalized_score = score / (len(seq) ** alpha)
            completed_sequences.append((normalized_score, seq))

        # æœ€è‰¯ã®ç³»åˆ—ã‚’è¿”ã™
        best_score, best_sequence = max(completed_sequences, key=lambda x: x[0])

        return best_sequence, best_score

# Beam Searchã®ãƒ‡ãƒ¢
print("\n=== Beam Searchæ¨è«– ===")

src_sentence = "I love artificial intelligence"
print(f"å…¥åŠ›æ–‡: {src_sentence}")

# Beam Searchæ¨è«–
beam_width = 5
print(f"ãƒ“ãƒ¼ãƒ å¹…: {beam_width}")
print(f"é•·ã•æ­£è¦åŒ–ä¿‚æ•°: 0.7\n")

# ä»®ã®å‡ºåŠ›
output_sequence_demo = [1, 3, 4, 5, 6, 7, 8, 9, 2]  # <sos> ç§ ã¯ äººå·¥ çŸ¥èƒ½ ãŒ å¥½ã ã§ã™ <eos>
output_sentence = ' '.join([trg_vocab_inv.get(idx, '<unk>') for idx in output_sequence_demo[1:-1]])

print(f"æœ€è‰¯ç³»åˆ—: {output_sentence}")
print(f"æ­£è¦åŒ–ã‚¹ã‚³ã‚¢: -0.85ï¼ˆä»®å®šï¼‰\n")

# Beam Searchã®ç‰¹æ€§æ¯”è¼ƒ
print("=== Greedy Search vs Beam Search ===")
comparison = [
    ["ç‰¹æ€§", "Greedy Search", "Beam Search (k=5)"],
    ["æ¢ç´¢ç©ºé–“", "1å€™è£œã®ã¿", "5å€™è£œã‚’ä¿æŒ"],
    ["è¨ˆç®—é‡", "O(V Ã— T)", "O(k Ã— V Ã— T)"],
    ["ãƒ¡ãƒ¢ãƒª", "O(1)", "O(k)"],
    ["å“è³ª", "å±€æ‰€æœ€é©", "ã‚ˆã‚Šè‰¯ã„è§£"],
    ["é€Ÿåº¦", "æœ€é€Ÿ", "5å€é…ã„"],
]

for row in comparison:
    print(f"{row[0]:12} | {row[1]:20} | {row[2]:20}")
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>
=== Beam Searchæ¨è«– ===
å…¥åŠ›æ–‡: I love artificial intelligence
ãƒ“ãƒ¼ãƒ å¹…: 5
é•·ã•æ­£è¦åŒ–ä¿‚æ•°: 0.7

æœ€è‰¯ç³»åˆ—: ç§ ã¯ äººå·¥ çŸ¥èƒ½ ãŒ å¥½ã ã§ã™
æ­£è¦åŒ–ã‚¹ã‚³ã‚¢: -0.85ï¼ˆä»®å®šï¼‰

=== Greedy Search vs Beam Search ===
ç‰¹æ€§         | Greedy Search        | Beam Search (k=5)
æ¢ç´¢ç©ºé–“     | 1å€™è£œã®ã¿            | 5å€™è£œã‚’ä¿æŒ
è¨ˆç®—é‡       | O(V Ã— T)             | O(k Ã— V Ã— T)
ãƒ¡ãƒ¢ãƒª       | O(1)                 | O(k)
å“è³ª         | å±€æ‰€æœ€é©             | ã‚ˆã‚Šè‰¯ã„è§£
é€Ÿåº¦         | æœ€é€Ÿ                 | 5å€é…ã„
</code></pre>

<h3>æ¨è«–æˆ¦ç•¥ã®é¸æŠåŸºæº–</h3>

<table>
<thead>
<tr>
<th>ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³</th>
<th>æ¨å¥¨æ‰‹æ³•</th>
<th>ç†ç”±</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å¯¾è©±</strong></td>
<td>Greedy Search</td>
<td>é€Ÿåº¦é‡è¦–ã€ä½ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·</td>
</tr>
<tr>
<td><strong>æ©Ÿæ¢°ç¿»è¨³</strong></td>
<td>Beam Search (k=5-10)</td>
<td>å“è³ªé‡è¦–ã€BLEUå‘ä¸Š</td>
</tr>
<tr>
<td><strong>æ–‡ç« è¦ç´„</strong></td>
<td>Beam Search (k=3-5)</td>
<td>ãƒãƒ©ãƒ³ã‚¹é‡è¦–</td>
</tr>
<tr>
<td><strong>å‰µé€ çš„ç”Ÿæˆ</strong></td>
<td>Top-k/Nucleus Sampling</td>
<td>å¤šæ§˜æ€§é‡è¦–</td>
</tr>
<tr>
<td><strong>éŸ³å£°èªè­˜</strong></td>
<td>Beam Search + LM</td>
<td>è¨€èªãƒ¢ãƒ‡ãƒ«ã¨ã®çµ±åˆ</td>
</tr>
</tbody>
</table>

<hr>

<h2>3.5 å®Ÿè·µï¼šè‹±æ—¥æ©Ÿæ¢°ç¿»è¨³</h2>

<h3>å®Ÿè£…ä¾‹7: å®Œå…¨ãªç¿»è¨³ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³</h3>

<pre><code class="language-python">import random

class TranslationPipeline:
    """
    è‹±æ—¥æ©Ÿæ¢°ç¿»è¨³ã®å®Œå…¨ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
    """
    def __init__(self, model, src_vocab, trg_vocab, device):
        self.model = model
        self.src_vocab = src_vocab
        self.trg_vocab = trg_vocab
        self.trg_vocab_inv = {v: k for k, v in trg_vocab.items()}
        self.device = device

    def tokenize(self, sentence, vocab):
        """æ–‡ç« ã‚’ãƒˆãƒ¼ã‚¯ãƒ³åŒ–"""
        # å®Ÿéš›ã«ã¯spaCyã‚„MeCabã‚’ä½¿ç”¨
        tokens = sentence.lower().split()
        indices = [vocab.get(token, vocab['<unk>']) for token in tokens]
        return [vocab['<sos>']] + indices + [vocab['<eos>']]

    def detokenize(self, indices):
        """ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ–‡ç« ã«æˆ»ã™"""
        tokens = [self.trg_vocab_inv.get(idx, '<unk>') for idx in indices]
        # <sos>, <eos>, <pad>ã‚’é™¤å»
        tokens = [t for t in tokens if t not in ['<sos>', '<eos>', '<pad>']]
        return ''.join(tokens)  # æ—¥æœ¬èªã¯ç©ºç™½ãªã—

    def translate(self, sentence, method='beam', beam_width=5):
        """
        æ–‡ç« ã‚’ç¿»è¨³

        Args:
            sentence: å…¥åŠ›æ–‡ï¼ˆè‹±èªï¼‰
            method: 'greedy' or 'beam'
            beam_width: ãƒ“ãƒ¼ãƒ å¹…

        Returns:
            translation: ç¿»è¨³çµæœï¼ˆæ—¥æœ¬èªï¼‰
        """
        self.model.eval()

        # ãƒˆãƒ¼ã‚¯ãƒ³åŒ–
        src_indices = self.tokenize(sentence, self.src_vocab)
        src_tensor = torch.tensor([src_indices]).to(self.device)

        # æ¨è«–
        if method == 'greedy':
            output_indices = greedy_decode(
                self.model, src_tensor, self.src_vocab, self.trg_vocab
            )
        else:
            output_indices, score = beam_search_decode(
                self.model, src_tensor, self.trg_vocab, beam_width=beam_width
            )
            output_indices = output_indices[1:-1]  # <sos>, <eos>ã‚’é™¤å»

        # ãƒ‡ãƒˆãƒ¼ã‚¯ãƒ³åŒ–
        translation = self.detokenize(output_indices)

        return translation

# ç¿»è¨³ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®ãƒ‡ãƒ¢
print("\n=== è‹±æ—¥æ©Ÿæ¢°ç¿»è¨³ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ ===\n")

# æ‹¡å¼µã•ã‚ŒãŸèªå½™è¾æ›¸ï¼ˆãƒ‡ãƒ¢ç”¨ï¼‰
src_vocab_demo = {
    '<pad>': 0, '<sos>': 1, '<eos>': 2, '<unk>': 3,
    'i': 4, 'love': 5, 'artificial': 6, 'intelligence': 7,
    'machine': 8, 'learning': 9, 'is': 10, 'amazing': 11,
    'deep': 12, 'neural': 13, 'networks': 14, 'are': 15, 'powerful': 16
}

trg_vocab_demo = {
    '<pad>': 0, '<sos>': 1, '<eos>': 2, '<unk>': 3,
    'ç§': 4, 'ã¯': 5, 'äººå·¥': 6, 'çŸ¥èƒ½': 7, 'ãŒ': 8, 'å¥½ã': 9, 'ã§ã™': 10,
    'æ©Ÿæ¢°': 11, 'å­¦ç¿’': 12, 'ç´ æ™´ã‚‰ã—ã„': 13, 'ãƒ‡ã‚£ãƒ¼ãƒ—': 14,
    'ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«': 15, 'ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯': 16, 'å¼·åŠ›': 17
}

# ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ§‹ç¯‰
pipeline = TranslationPipeline(model, src_vocab_demo, trg_vocab_demo, device)

# ãƒ†ã‚¹ãƒˆæ–‡ç« 
test_sentences = [
    "I love artificial intelligence",
    "Machine learning is amazing",
    "Deep neural networks are powerful"
]

print("--- Greedy Searchç¿»è¨³ ---")
for sent in test_sentences:
    # ä»®ã®ç¿»è¨³çµæœï¼ˆå®Ÿéš›ã®æ¨è«–ã®ä»£ã‚ã‚Šï¼‰
    translations_demo = [
        "ç§ã¯äººå·¥çŸ¥èƒ½ãŒå¥½ãã§ã™",
        "æ©Ÿæ¢°å­¦ç¿’ã¯ç´ æ™´ã‚‰ã—ã„ã§ã™",
        "ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã¯å¼·åŠ›ã§ã™"
    ]
    translation = translations_demo[test_sentences.index(sent)]
    print(f"EN: {sent}")
    print(f"JA: {translation}\n")

print("--- Beam Searchç¿»è¨³ (k=5) ---")
for sent in test_sentences:
    # Beam Searchã§ã‚ˆã‚Šè‰¯ã„ç¿»è¨³ï¼ˆä»®å®šï¼‰
    translations_demo_beam = [
        "ç§ã¯äººå·¥çŸ¥èƒ½ãŒå¤§å¥½ãã§ã™",
        "æ©Ÿæ¢°å­¦ç¿’ã¯ã¨ã¦ã‚‚ç´ æ™´ã‚‰ã—ã„ã§ã™",
        "ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã¯éå¸¸ã«å¼·åŠ›ã§ã™"
    ]
    translation = translations_demo_beam[test_sentences.index(sent)]
    print(f"EN: {sent}")
    print(f"JA: {translation}\n")

# æ€§èƒ½è©•ä¾¡ï¼ˆä»®ã®æŒ‡æ¨™ï¼‰
print("=== ç¿»è¨³å“è³ªè©•ä¾¡ï¼ˆãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆï¼‰ ===")
print("BLEU Score:")
print("  Greedy Search: 18.5")
print("  Beam Search (k=5): 22.3")
print("  Beam Search (k=10): 23.1\n")

print("è¨“ç·´ãƒ‡ãƒ¼ã‚¿: 100,000æ–‡ãƒšã‚¢")
print("ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: 5,000æ–‡ãƒšã‚¢")
print("è¨“ç·´æ™‚é–“: ç´„8æ™‚é–“ (GPU)")
print("æ¨è«–é€Ÿåº¦: ~50æ–‡/ç§’ (Greedy), ~12æ–‡/ç§’ (Beam k=5)")
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>
=== è‹±æ—¥æ©Ÿæ¢°ç¿»è¨³ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ ===

--- Greedy Searchç¿»è¨³ ---
EN: I love artificial intelligence
JA: ç§ã¯äººå·¥çŸ¥èƒ½ãŒå¥½ãã§ã™

EN: Machine learning is amazing
JA: æ©Ÿæ¢°å­¦ç¿’ã¯ç´ æ™´ã‚‰ã—ã„ã§ã™

EN: Deep neural networks are powerful
JA: ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã¯å¼·åŠ›ã§ã™

--- Beam Searchç¿»è¨³ (k=5) ---
EN: I love artificial intelligence
JA: ç§ã¯äººå·¥çŸ¥èƒ½ãŒå¤§å¥½ãã§ã™

EN: Machine learning is amazing
JA: æ©Ÿæ¢°å­¦ç¿’ã¯ã¨ã¦ã‚‚ç´ æ™´ã‚‰ã—ã„ã§ã™

EN: Deep neural networks are powerful
JA: ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã¯éå¸¸ã«å¼·åŠ›ã§ã™

=== ç¿»è¨³å“è³ªè©•ä¾¡ï¼ˆãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆï¼‰ ===
BLEU Score:
  Greedy Search: 18.5
  Beam Search (k=5): 22.3
  Beam Search (k=10): 23.1

è¨“ç·´ãƒ‡ãƒ¼ã‚¿: 100,000æ–‡ãƒšã‚¢
ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: 5,000æ–‡ãƒšã‚¢
è¨“ç·´æ™‚é–“: ç´„8æ™‚é–“ (GPU)
æ¨è«–é€Ÿåº¦: ~50æ–‡/ç§’ (Greedy), ~12æ–‡/ç§’ (Beam k=5)
</code></pre>

<hr>

<h2>Seq2Seqã®èª²é¡Œã¨é™ç•Œ</h2>

<h3>Context Vectorã®ãƒœãƒˆãƒ«ãƒãƒƒã‚¯å•é¡Œ</h3>

<p>Seq2Seqã®æœ€å¤§ã®èª²é¡Œã¯ã€å…¥åŠ›ç³»åˆ—å…¨ä½“ã‚’å›ºå®šé•·ãƒ™ã‚¯ãƒˆãƒ«ã«åœ§ç¸®ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã“ã¨ã§ã™ã€‚</p>

<div class="mermaid">
graph LR
    A[é•·ã„å…¥åŠ›ç³»åˆ—<br/>50ãƒˆãƒ¼ã‚¯ãƒ³] --> B[Context Vector<br/>512æ¬¡å…ƒ]
    B --> C[æƒ…å ±æå¤±]
    C --> D[ç¿»è¨³å“è³ªä½ä¸‹]

    style B fill:#ffebee,stroke:#c62828
    style C fill:#ffebee,stroke:#c62828
</div>

<p>å•é¡Œç‚¹ï¼š</p>
<ul>
<li><strong>æƒ…å ±åœ§ç¸®ã®é™ç•Œ</strong>ï¼šé•·ã„æ–‡ç« ã§ã¯é‡è¦ãªæƒ…å ±ãŒå¤±ã‚ã‚Œã‚‹</li>
<li><strong>é•·è·é›¢ä¾å­˜ã®å›°é›£</strong>ï¼šæ–‡ç« ã®å…ˆé ­ã¨æœ«å°¾ã®é–¢é€£æ€§ãŒå¤±ã‚ã‚Œã‚‹</li>
<li><strong>å›ºå®šå®¹é‡</strong>ï¼šæ–‡ç« ã®é•·ã•ã«é–¢ã‚ã‚‰ãšãƒ™ã‚¯ãƒˆãƒ«æ¬¡å…ƒã¯å›ºå®š</li>
</ul>

<h3>è§£æ±ºç­–ï¼šAttentionãƒ¡ã‚«ãƒ‹ã‚ºãƒ </h3>

<p><strong>Attention</strong>ã¯ã€DecoderãŒå„ã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ—ã§Encoder ã®å…¨éš ã‚ŒçŠ¶æ…‹ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹æ©Ÿæ§‹ã§ã™ã€‚</p>

<table>
<thead>
<tr>
<th>æ‰‹æ³•</th>
<th>Context Vector</th>
<th>é•·æ–‡æ€§èƒ½</th>
<th>è¨ˆç®—é‡</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Vanilla Seq2Seq</strong></td>
<td>æœ€çµ‚éš ã‚ŒçŠ¶æ…‹ã®ã¿</td>
<td>ä½ã„</td>
<td>O(1)</td>
</tr>
<tr>
<td><strong>Seq2Seq + Attention</strong></td>
<td>å…¨éš ã‚ŒçŠ¶æ…‹ã®é‡ã¿ä»˜ãå’Œ</td>
<td>é«˜ã„</td>
<td>O(T Ã— T')</td>
</tr>
<tr>
<td><strong>Transformer</strong></td>
<td>Self-Attentionæ©Ÿæ§‹</td>
<td>éå¸¸ã«é«˜ã„</td>
<td>O(TÂ²)</td>
</tr>
</tbody>
</table>

<p>Attentionã«ã¤ã„ã¦ã¯æ¬¡ç« ã§è©³ã—ãå­¦ç¿’ã—ã¾ã™ã€‚</p>

<hr>

<h2>ã¾ã¨ã‚</h2>

<p>ã“ã®ç« ã§ã¯ã€Seq2Seqãƒ¢ãƒ‡ãƒ«ã®åŸºç¤ã‚’å­¦ã³ã¾ã—ãŸï¼š</p>

<h3>é‡è¦ãªãƒã‚¤ãƒ³ãƒˆ</h3>

<details>
<summary><strong>1. Encoder-Decoderã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£</strong></summary>
<ul>
<li>EncoderãŒå…¥åŠ›ç³»åˆ—ã‚’å›ºå®šé•·Context Vectorã«åœ§ç¸®</li>
<li>DecoderãŒContext Vectorã‹ã‚‰å‡ºåŠ›ç³»åˆ—ã‚’ç”Ÿæˆ</li>
<li>2ã¤ã®LSTM/GRUã‚’çµ„ã¿åˆã‚ã›ã¦æ§‹æˆ</li>
<li>å¯å¤‰é•·å…¥åŠ›â†’å¯å¤‰é•·å‡ºåŠ›ã‚’å®Ÿç¾</li>
</ul>
</details>

<details>
<summary><strong>2. Teacher Forcing</strong></summary>
<ul>
<li>è¨“ç·´æ™‚ã«æ­£è§£ãƒˆãƒ¼ã‚¯ãƒ³ã‚’Decoderã«å…¥åŠ›</li>
<li>å­¦ç¿’ã®é«˜é€ŸåŒ–ã¨å®‰å®šåŒ–ã«å¯„ä¸</li>
<li>æ¨è«–æ™‚ã¨ã®å·®ç•°ï¼ˆExposure Biasï¼‰ã«æ³¨æ„</li>
<li>Scheduled Samplingã§ç·©å’Œå¯èƒ½</li>
</ul>
</details>

<details>
<summary><strong>3. æ¨è«–æˆ¦ç•¥</strong></summary>
<ul>
<li><strong>Greedy Search</strong>ï¼šæœ€é€Ÿã ãŒå“è³ªã¯ä½ã‚</li>
<li><strong>Beam Search</strong>ï¼šå“è³ªå‘ä¸Šã€è¨ˆç®—ã‚³ã‚¹ãƒˆã¯ k å€</li>
<li>é•·ã•æ­£è¦åŒ–ã§ãƒã‚¤ã‚¢ã‚¹ã‚’è£œæ­£</li>
<li>ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã«å¿œã˜ã¦ä½¿ã„åˆ†ã‘</li>
</ul>
</details>

<details>
<summary><strong>4. å®Ÿè£…ã®ãƒã‚¤ãƒ³ãƒˆ</strong></summary>
<ul>
<li>Encoderã¯<code>requires_grad=False</code>ä¸è¦ï¼ˆå…¨ã¦å­¦ç¿’ï¼‰</li>
<li>å‹¾é…ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°ã§å‹¾é…çˆ†ç™ºã‚’é˜²æ­¢</li>
<li>CrossEntropyLossã§<code>ignore_index</code>ã‚’è¨­å®šï¼ˆãƒ‘ãƒ‡ã‚£ãƒ³ã‚°å¯¾å¿œï¼‰</li>
<li>ãƒãƒƒãƒå‡¦ç†ã§åŠ¹ç‡åŒ–</li>
</ul>
</details>

<h3>æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—</h3>

<p>æ¬¡ç« ã§ã¯ã€Seq2Seqã®æœ€å¤§ã®èª²é¡Œã§ã‚ã‚‹Context Vectorã®ãƒœãƒˆãƒ«ãƒãƒƒã‚¯å•é¡Œã‚’è§£æ±ºã™ã‚‹<strong>Attentionãƒ¡ã‚«ãƒ‹ã‚ºãƒ </strong>ã‚’å­¦ã³ã¾ã™ï¼š</p>

<ul>
<li>Bahdanau Attentionï¼ˆAdditive Attentionï¼‰</li>
<li>Luong Attentionï¼ˆMultiplicative Attentionï¼‰</li>
<li>Self-Attentionï¼ˆTransformerã¸ã®æ©‹æ¸¡ã—ï¼‰</li>
<li>Attentionå¯è¦–åŒ–ã«ã‚ˆã‚‹è§£é‡ˆæ€§å‘ä¸Š</li>
</ul>

<hr>

<h2>æ¼”ç¿’å•é¡Œ</h2>

<details>
<summary><strong>å•é¡Œ1: Context Vectorã®ç†è§£</strong></summary>
<p><strong>è³ªå•</strong>ï¼šSeq2Seqãƒ¢ãƒ‡ãƒ«ã§Context Vectorã®æ¬¡å…ƒæ•°ã‚’256ã‹ã‚‰1024ã«å¢—ã‚„ã—ãŸå ´åˆã€ç¿»è¨³å“è³ªã¨ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã¯ã©ã®ã‚ˆã†ã«å¤‰åŒ–ã—ã¾ã™ã‹ï¼Ÿãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚</p>

<p><strong>è§£ç­”ä¾‹</strong>ï¼š</p>
<ul>
<li><strong>å“è³ªå‘ä¸Š</strong>ï¼šContext Vectorã®è¡¨ç¾åŠ›ãŒå¢—ã—ã€ã‚ˆã‚Šå¤šãã®æƒ…å ±ã‚’ä¿æŒå¯èƒ½ã€‚ç‰¹ã«é•·æ–‡ã§åŠ¹æœçš„</li>
<li><strong>ãƒ¡ãƒ¢ãƒªå¢—åŠ </strong>ï¼šLSTMéš ã‚ŒçŠ¶æ…‹ã®ã‚µã‚¤ã‚ºãŒ4å€ã«ãªã‚Šã€ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚‚ç´„4å€å¢—åŠ </li>
<li><strong>è¨“ç·´æ™‚é–“å¢—åŠ </strong>ï¼šè¡Œåˆ—æ¼”ç®—ã®è¨ˆç®—é‡ãŒå¢—ãˆã€è¨“ç·´é€Ÿåº¦ãŒä½ä¸‹</li>
<li><strong>éå­¦ç¿’ãƒªã‚¹ã‚¯</strong>ï¼šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°å¢—åŠ ã«ã‚ˆã‚Šã€å°è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã¯éå­¦ç¿’ã®å¯èƒ½æ€§</li>
<li><strong>æœ€é©å€¤</strong>ï¼šã‚¿ã‚¹ã‚¯ã¨ãƒ‡ãƒ¼ã‚¿é‡ã«å¿œã˜ã¦512ãŒä¸€èˆ¬çš„ãªãƒãƒ©ãƒ³ã‚¹ç‚¹</li>
</ul>
</details>

<details>
<summary><strong>å•é¡Œ2: Teacher Forcingã®å½±éŸ¿</strong></summary>
<p><strong>è³ªå•</strong>ï¼šTeacher Forcingç‡ã‚’0.0ï¼ˆå¸¸ã«Free Runningï¼‰ã¨1.0ï¼ˆå¸¸ã«Teacher Forcingï¼‰ã§è¨“ç·´ã—ãŸå ´åˆã€ãã‚Œãã‚Œã©ã®ã‚ˆã†ãªå•é¡ŒãŒç™ºç”Ÿã—ã¾ã™ã‹ï¼Ÿ</p>

<p><strong>è§£ç­”ä¾‹</strong>ï¼š</p>

<p><strong>Teacher Forcingç‡ = 1.0ï¼ˆå¸¸ã«æ­£è§£ã‚’å…¥åŠ›ï¼‰</strong>ï¼š</p>
<ul>
<li>è¨“ç·´ã¯é«˜é€Ÿã§å®‰å®š</li>
<li>è¨“ç·´æå¤±ã¯ä½ä¸‹ã—ã‚„ã™ã„</li>
<li>ã—ã‹ã—æ¨è«–æ™‚ã«ã¯äºˆæ¸¬ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ä½¿ã†ãŸã‚ã€è¨“ç·´ã¨æ¨è«–ã®ã‚®ãƒ£ãƒƒãƒ—ï¼ˆExposure Biasï¼‰ãŒå¤§ãã„</li>
<li>ä¸€åº¦èª¤ã‚‹ã¨é€£é–çš„ã«ã‚¨ãƒ©ãƒ¼ãŒè“„ç©</li>
</ul>

<p><strong>Teacher Forcingç‡ = 0.0ï¼ˆå¸¸ã«äºˆæ¸¬ã‚’å…¥åŠ›ï¼‰</strong>ï¼š</p>
<ul>
<li>è¨“ç·´ã¨æ¨è«–ã®å‹•ä½œãŒä¸€è‡´</li>
<li>ã—ã‹ã—è¨“ç·´åˆæœŸã¯äºˆæ¸¬ç²¾åº¦ãŒä½ãã€å­¦ç¿’ãŒä¸å®‰å®š</li>
<li>åæŸãŒé…ã„ã€è¨“ç·´æ™‚é–“ãŒå¤§å¹…ã«å¢—åŠ </li>
<li>å‹¾é…ãŒæ¶ˆå¤±ã—ã‚„ã™ã„</li>
</ul>

<p><strong>æ¨å¥¨</strong>ï¼š0.5å‰å¾Œã€ã¾ãŸã¯Scheduled Samplingã§å¾ã€…ã«æ¸›å°‘ã•ã›ã‚‹</p>
</details>

<details>
<summary><strong>å•é¡Œ3: Beam Searchã®ãƒ“ãƒ¼ãƒ å¹…é¸æŠ</strong></summary>
<p><strong>è³ªå•</strong>ï¼šæ©Ÿæ¢°ç¿»è¨³ã‚·ã‚¹ãƒ†ãƒ ã§ã€ãƒ“ãƒ¼ãƒ å¹…ã‚’5ã‹ã‚‰20ã«å¢—ã‚„ã—ãŸå ´åˆã€BLEU ã‚¹ã‚³ã‚¢ã¨æ¨è«–æ™‚é–“ã¯ã©ã†å¤‰åŒ–ã™ã‚‹ã¨äºˆæƒ³ã•ã‚Œã¾ã™ã‹ï¼Ÿå®Ÿé¨“çµæœã®å‚¾å‘ã‚’äºˆæ¸¬ã—ã¦ãã ã•ã„ã€‚</p>

<p><strong>è§£ç­”ä¾‹</strong>ï¼š</p>

<p><strong>BLEU ã‚¹ã‚³ã‚¢ã®å¤‰åŒ–</strong>ï¼š</p>
<ul>
<li>k=5 â†’ k=10: +1ã€œ2ãƒã‚¤ãƒ³ãƒˆæ”¹å–„ï¼ˆå¤§ããªåŠ¹æœï¼‰</li>
<li>k=10 â†’ k=20: +0.5ãƒã‚¤ãƒ³ãƒˆç¨‹åº¦ï¼ˆåç©«é€“æ¸›ï¼‰</li>
<li>k=20ä»¥ä¸Š: ã»ã¼æ¨ªã°ã„ï¼ˆé£½å’Œï¼‰</li>
</ul>

<p><strong>æ¨è«–æ™‚é–“ã®å¤‰åŒ–</strong>ï¼š</p>
<ul>
<li>ãƒ“ãƒ¼ãƒ å¹…ã«ã»ã¼ç·šå½¢ã«æ¯”ä¾‹</li>
<li>k=5 â†’ k=20: ç´„4å€é…ããªã‚‹</li>
</ul>

<p><strong>å®Ÿç”¨çš„ãªé¸æŠ</strong>ï¼š</p>
<ul>
<li>ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ç¿»è¨³: k=10ã€œ20</li>
<li>ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç¿»è¨³: k=3ã€œ5</li>
<li>å“è³ªæœ€é‡è¦–: k=50ã§ã‚‚ä½¿ç”¨ã™ã‚‹å ´åˆã‚ã‚Š</li>
</ul>
</details>

<details>
<summary><strong>å•é¡Œ4: ç³»åˆ—é•·ã¨ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡</strong></summary>
<p><strong>è³ªå•</strong>ï¼šãƒãƒƒãƒã‚µã‚¤ã‚º32ã€æœ€å¤§ç³»åˆ—é•·50ã®Seq2Seqãƒ¢ãƒ‡ãƒ«ã§ã€æœ€å¤§ç³»åˆ—é•·ã‚’100ã«å¢—ã‚„ã—ãŸå ´åˆã€ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã¯ã©ã®ç¨‹åº¦å¢—åŠ ã—ã¾ã™ã‹ï¼Ÿè¨ˆç®—ã—ã¦ãã ã•ã„ã€‚</p>

<p><strong>è§£ç­”ä¾‹</strong>ï¼š</p>

<p>ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®ä¸»è¦å› ï¼š</p>
<ol>
<li><strong>éš ã‚ŒçŠ¶æ…‹</strong>: batch_size Ã— seq_len Ã— hidden_dim</li>
<li><strong>å‹¾é…</strong>: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã”ã¨ã«ä¿å­˜</li>
<li><strong>ä¸­é–“æ´»æ€§åŒ–</strong>: BPTTã§å„æ™‚åˆ»ã®å€¤ã‚’ä¿æŒ</li>
</ol>

<p>ç³»åˆ—é•·ãŒ50â†’100ã«ãªã‚‹ã¨ï¼š</p>
<ul>
<li>éš ã‚ŒçŠ¶æ…‹: 2å€</li>
<li>BPTTã®ä¸­é–“å€¤: 2å€</li>
<li>å…¨ä½“ã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: ç´„1.8ã€œ2å€ï¼ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯ä¸å¤‰ï¼‰</li>
</ul>

<p>å…·ä½“çš„ãªè¨ˆç®—ï¼ˆhidden_dim=512ã®å ´åˆï¼‰ï¼š</p>
<ul>
<li>éš ã‚ŒçŠ¶æ…‹: 32 Ã— 100 Ã— 512 Ã— 4 bytes = 6.4 MB</li>
<li>BPTTã®å…¨æ™‚åˆ»åˆ†: ç´„640 MB</li>
<li>ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: ä¸å¤‰</li>
</ul>

<p><strong>å¯¾ç­–</strong>ï¼šç³»åˆ—ã‚’åˆ†å‰²ã€Gradient Checkpointingã€ã‚ˆã‚Šå°ã•ã„ãƒãƒƒãƒã‚µã‚¤ã‚º</p>
</details>

<details>
<summary><strong>å•é¡Œ5: Seq2Seqã®å¿œç”¨è¨­è¨ˆ</strong></summary>
<p><strong>è³ªå•</strong>ï¼šãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã‚’Seq2Seqã§å®Ÿè£…ã™ã‚‹å ´åˆã€ã©ã®ã‚ˆã†ãªå·¥å¤«ãŒå¿…è¦ã§ã™ã‹ï¼Ÿå°‘ãªãã¨ã‚‚3ã¤ã®èª²é¡Œã¨è§£æ±ºç­–ã‚’ææ¡ˆã—ã¦ãã ã•ã„ã€‚</p>

<p><strong>è§£ç­”ä¾‹</strong>ï¼š</p>

<p><strong>èª²é¡Œ1: æ–‡è„ˆã®ä¿æŒ</strong></p>
<ul>
<li>å•é¡Œ: å˜ä¸€ã®ç™ºè©±ãƒšã‚¢ã ã‘ã§ã¯ä¼šè©±ã®æµã‚ŒãŒå¤±ã‚ã‚Œã‚‹</li>
<li>è§£æ±ºç­–: éå»Nç™ºè©±ã‚’é€£çµã—ã¦å…¥åŠ›ã€ã¾ãŸã¯éšå±¤çš„Seq2Seq</li>
</ul>

<p><strong>èª²é¡Œ2: æ±ç”¨çš„ã™ãã‚‹å¿œç­”</strong></p>
<ul>
<li>å•é¡Œ: "I don't know"ã€"OK"ãªã©ã®ç„¡é›£ãªå¿œç­”ã°ã‹ã‚Šç”Ÿæˆ</li>
<li>è§£æ±ºç­–: Maximum Mutual Informationç›®çš„é–¢æ•°ã€DiversityãƒšãƒŠãƒ«ãƒ†ã‚£ã€å¼·åŒ–å­¦ç¿’</li>
</ul>

<p><strong>èª²é¡Œ3: äº‹å®Ÿæ€§ã®æ¬ å¦‚</strong></p>
<ul>
<li>å•é¡Œ: çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã‚’å‚ç…§ã›ãšã€å¹»è¦šçš„ãªå¿œç­”ã‚’ç”Ÿæˆ</li>
<li>è§£æ±ºç­–: Knowledge-groundedå¯¾è©±ã€Retrieval-augmentedç”Ÿæˆ</li>
</ul>

<p><strong>èª²é¡Œ4: äººæ ¼ã®ä¸€è²«æ€§</strong></p>
<ul>
<li>å•é¡Œ: å¿œç­”ã”ã¨ã«ãƒˆãƒ¼ãƒ³ã‚„æ€§æ ¼ãŒå¤‰ã‚ã‚‹</li>
<li>è§£æ±ºç­–: Personaãƒ™ã‚¯ãƒˆãƒ«ã®å°å…¥ã€ã‚¹ã‚¿ã‚¤ãƒ«è»¢é€æŠ€è¡“</li>
</ul>

<p><strong>èª²é¡Œ5: è©•ä¾¡ã®å›°é›£</strong></p>
<ul>
<li>å•é¡Œ: BLEUãªã©ã®è‡ªå‹•è©•ä¾¡æŒ‡æ¨™ãŒå¯¾è©±å“è³ªã‚’åæ˜ ã—ãªã„</li>
<li>è§£æ±ºç­–: äººé–“è©•ä¾¡ã€Engagementã‚¹ã‚³ã‚¢ã€ã‚¿ã‚¹ã‚¯æˆåŠŸç‡</li>
</ul>
</details>

<hr>

<div class="navigation">
    <a href="chapter2-lstm-gru.html" class="nav-button">â† ç¬¬2ç« ï¼šLSTM & GRU</a>
    <a href="chapter4-attention.html" class="nav-button">ç¬¬4ç« ï¼šAttentionãƒ¡ã‚«ãƒ‹ã‚ºãƒ  â†’</a>
</div>

    </main>

    <footer>
        <p>&copy; 2025 AI Terakoya. All rights reserved.</p>
        <p>ML-A02: RNNå…¥é–€ - Seq2Seqã§å¯å¤‰é•·ç³»åˆ—å¤‰æ›ã‚’ãƒã‚¹ã‚¿ãƒ¼ã—ã‚ˆã†</p>
    </footer>

</body>
</html>
