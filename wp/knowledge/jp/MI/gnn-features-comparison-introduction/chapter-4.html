<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ç¬¬4ç« ï¼šçµ„æˆãƒ™ãƒ¼ã‚¹ vs GNNå®šé‡çš„æ¯”è¼ƒ | GNNç‰¹å¾´é‡æ¯”è¼ƒå…¥é–€</title>
    <meta name="description" content="Matbenchãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¨RF/CGCNNã®å®šé‡çš„æ€§èƒ½æ¯”è¼ƒã€‚çµ±è¨ˆçš„æœ‰æ„æ€§æ¤œå®šã€è¨ˆç®—ã‚³ã‚¹ãƒˆã€ãƒ‡ãƒ¼ã‚¿è¦æ±‚é‡ã€è§£é‡ˆå¯èƒ½æ€§ã‚’å®Ÿè¨¼åˆ†æã€‚">

    <!-- MathJax 3.x for mathematical equations -->
    <script>
    MathJax = {
        tex: {
            inlineMath: [['$', '$'], ['\\(', '\\)']],
            displayMath: [['$$', '$$'], ['\\[', '\\]']],
            processEscapes: true,
            processEnvironments: true
        },
        options: {
            skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        }
    };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

    <!-- Mermaid for diagrams -->
    <script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
    <script>
        mermaid.initialize({
            startOnLoad: true,
            theme: 'default',
            themeVariables: {
                primaryColor: '#667eea',
                primaryTextColor: '#fff',
                primaryBorderColor: '#764ba2',
                lineColor: '#764ba2',
                secondaryColor: '#764ba2',
                tertiaryColor: '#fff'
            }
        });
    </script>

    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css" rel="stylesheet" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>

    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Noto Sans JP', sans-serif;
            line-height: 1.8;
            color: #2c3e50;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            padding: 2rem 1rem;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            background: white;
            border-radius: 12px;
            box-shadow: 0 8px 32px rgba(0,0,0,0.1);
            padding: 3rem;
        }

        h1 {
            font-size: 2.5rem;
            margin-bottom: 1.5rem;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }

        h2 {
            font-size: 1.8rem;
            margin: 2.5rem 0 1.5rem;
            color: #667eea;
            border-left: 4px solid #764ba2;
            padding-left: 1rem;
        }

        h3 {
            font-size: 1.4rem;
            margin: 2rem 0 1rem;
            color: #764ba2;
        }

        p {
            margin-bottom: 1.2rem;
            text-align: justify;
        }

        .highlight-box {
            background: linear-gradient(135deg, rgba(102, 126, 234, 0.1) 0%, rgba(118, 75, 162, 0.1) 100%);
            border-left: 4px solid #667eea;
            padding: 1.5rem;
            margin: 1.5rem 0;
            border-radius: 8px;
        }

        .warning-box {
            background: rgba(255, 193, 7, 0.1);
            border-left: 4px solid #ffc107;
            padding: 1.5rem;
            margin: 1.5rem 0;
            border-radius: 8px;
        }

        pre {
            background: #2d2d2d;
            border-radius: 8px;
            padding: 1.5rem;
            overflow-x: auto;
            margin: 1.5rem 0;
        }

        code {
            font-family: 'Consolas', 'Monaco', 'Courier New', monospace;
            font-size: 0.9rem;
        }

        .mermaid {
            background: white;
            padding: 2rem;
            border-radius: 8px;
            margin: 2rem 0;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin: 1.5rem 0;
            box-shadow: 0 2px 8px rgba(0,0,0,0.1);
        }

        th, td {
            padding: 1rem;
            text-align: left;
            border-bottom: 1px solid #e0e0e0;
        }

        th {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            font-weight: 600;
        }

        tr:hover {
            background: rgba(102, 126, 234, 0.05);
        }

        .exercise {
            background: rgba(118, 75, 162, 0.05);
            border: 2px solid #764ba2;
            border-radius: 8px;
            padding: 1.5rem;
            margin: 1.5rem 0;
        }

        .exercise-header {
            font-weight: 600;
            color: #764ba2;
            margin-bottom: 0.5rem;
        }

        .difficulty {
            display: inline-block;
            padding: 0.25rem 0.75rem;
            border-radius: 4px;
            font-size: 0.85rem;
            font-weight: 600;
            margin-left: 0.5rem;
        }

        .difficulty-easy {
            background: #4caf50;
            color: white;
        }

        .difficulty-medium {
            background: #ff9800;
            color: white;
        }

        .difficulty-hard {
            background: #f44336;
            color: white;
        }

        .nav-buttons {
            display: flex;
            justify-content: space-between;
            margin-top: 3rem;
            padding-top: 2rem;
            border-top: 2px solid #e0e0e0;
        }

        .nav-button {
            padding: 0.75rem 1.5rem;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            text-decoration: none;
            border-radius: 6px;
            font-weight: 600;
            transition: transform 0.2s;
        }

        .nav-button:hover {
            transform: translateY(-2px);
        }

        ul, ol {
            margin: 1rem 0 1rem 2rem;
        }

        li {
            margin-bottom: 0.5rem;
        }

        @media (max-width: 768px) {
            .container {
                padding: 1.5rem;
            }

            h1 {
                font-size: 2rem;
            }

            h2 {
                font-size: 1.5rem;
            }

            pre {
                padding: 1rem;
                font-size: 0.85rem;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>ç¬¬4ç« ï¼šçµ„æˆãƒ™ãƒ¼ã‚¹ vs GNNå®šé‡çš„æ¯”è¼ƒ</h1>

        <p>æœ¬ç« ã§ã¯ã€<strong>çµ„æˆãƒ™ãƒ¼ã‚¹ç‰¹å¾´é‡ï¼ˆMagpieï¼‰</strong>ã¨<strong>GNNæ§‹é€ ãƒ™ãƒ¼ã‚¹ç‰¹å¾´é‡ï¼ˆCGCNNï¼‰</strong>ã®æ€§èƒ½ã‚’ã€<strong>Matbenchæ¨™æº–ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯</strong>ã‚’ç”¨ã„ã¦å®šé‡çš„ã«æ¯”è¼ƒã—ã¾ã™ã€‚å˜ãªã‚‹ç²¾åº¦æ¯”è¼ƒã ã‘ã§ãªãã€çµ±è¨ˆçš„æœ‰æ„æ€§ã€è¨ˆç®—ã‚³ã‚¹ãƒˆã€ãƒ‡ãƒ¼ã‚¿è¦æ±‚é‡ã€è§£é‡ˆå¯èƒ½æ€§ã®å¤šè§’çš„ãªè¦³ç‚¹ã‹ã‚‰å®Ÿè¨¼åˆ†æã‚’è¡Œã„ã¾ã™ã€‚</p>

        <div class="highlight-box">
            <strong>ğŸ¯ å­¦ç¿’ç›®æ¨™</strong>
            <ul>
                <li>Matbenchãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®æ§‹é€ ã¨è©•ä¾¡ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã‚’ç†è§£ã™ã‚‹</li>
                <li>Random Forest (Magpie) ã¨CGCNNã®äºˆæ¸¬ç²¾åº¦ã‚’å®šé‡çš„ã«æ¯”è¼ƒã™ã‚‹</li>
                <li>çµ±è¨ˆçš„æœ‰æ„æ€§æ¤œå®šï¼ˆtæ¤œå®šã€ä¿¡é ¼åŒºé–“ã€på€¤ï¼‰ã‚’å®Ÿè£…ã™ã‚‹</li>
                <li>è¨ˆç®—ã‚³ã‚¹ãƒˆï¼ˆè¨“ç·´æ™‚é–“ã€æ¨è«–æ™‚é–“ã€ãƒ¡ãƒ¢ãƒªï¼‰ã‚’æ¸¬å®šãƒ»æ¯”è¼ƒã™ã‚‹</li>
                <li>ãƒ‡ãƒ¼ã‚¿è¦æ±‚é‡ã®é•ã„ã‚’å­¦ç¿’æ›²ç·šã§å¯è¦–åŒ–ã™ã‚‹</li>
                <li>SHAPå€¤ã¨Attentionæ©Ÿæ§‹ã«ã‚ˆã‚‹è§£é‡ˆå¯èƒ½æ€§ã‚’æ¯”è¼ƒã™ã‚‹</li>
                <li>æ‰‹æ³•é¸æŠã®æ„æ€æ±ºå®šãƒ•ãƒ­ãƒ¼ãƒãƒ£ãƒ¼ãƒˆã‚’æ§‹ç¯‰ã™ã‚‹</li>
            </ul>
        </div>

        <h2>4.1 Matbenchãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®æ¦‚è¦</h2>

        <p>Matbenchï¼ˆMaterials Benchmarkï¼‰ã¯ã€ææ–™ç§‘å­¦ã«ãŠã‘ã‚‹æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®<strong>æ¨™æº–åŒ–ã•ã‚ŒãŸè©•ä¾¡ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ </strong>ã§ã™ã€‚13ç¨®é¡ã®ææ–™ç‰©æ€§äºˆæ¸¬ã‚¿ã‚¹ã‚¯ãŒå®šç¾©ã•ã‚Œã¦ãŠã‚Šã€å„ã‚¿ã‚¹ã‚¯ã«ã¯è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã€æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã€ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãŒäº‹å‰ã«åˆ†å‰²ã•ã‚Œã¦ã„ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ç•°ãªã‚‹ç ”ç©¶é–“ã§ã®å…¬å¹³ãªæ€§èƒ½æ¯”è¼ƒãŒå¯èƒ½ã«ãªã‚Šã¾ã™ã€‚</p>

        <h3>4.1.1 Matbenchã®ä¸»è¦ã‚¿ã‚¹ã‚¯</h3>

        <table>
            <thead>
                <tr>
                    <th>ã‚¿ã‚¹ã‚¯å</th>
                    <th>ç‰©æ€§</th>
                    <th>ãƒ‡ãƒ¼ã‚¿æ•°</th>
                    <th>è©•ä¾¡æŒ‡æ¨™</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>matbench_mp_e_form</td>
                    <td>ç”Ÿæˆã‚¨ãƒãƒ«ã‚®ãƒ¼ (eV/atom)</td>
                    <td>132,752</td>
                    <td>MAE</td>
                </tr>
                <tr>
                    <td>matbench_mp_gap</td>
                    <td>ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ— (eV)</td>
                    <td>106,113</td>
                    <td>MAE</td>
                </tr>
                <tr>
                    <td>matbench_perovskites</td>
                    <td>ç”Ÿæˆã‚¨ãƒãƒ«ã‚®ãƒ¼ (eV/atom)</td>
                    <td>18,928</td>
                    <td>MAE</td>
                </tr>
                <tr>
                    <td>matbench_phonons</td>
                    <td>æœ€å¤§ãƒ•ã‚©ãƒãƒ³å‘¨æ³¢æ•° (cmâ»Â¹)</td>
                    <td>1,265</td>
                    <td>MAE</td>
                </tr>
                <tr>
                    <td>matbench_jdft2d</td>
                    <td>å‰¥é›¢ã‚¨ãƒãƒ«ã‚®ãƒ¼ (meV/atom)</td>
                    <td>636</td>
                    <td>MAE</td>
                </tr>
            </tbody>
        </table>

        <p>æœ¬ç« ã§ã¯ã€<strong>matbench_mp_e_formï¼ˆç”Ÿæˆã‚¨ãƒãƒ«ã‚®ãƒ¼äºˆæ¸¬ï¼‰</strong>ã¨<strong>matbench_mp_gapï¼ˆãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—äºˆæ¸¬ï¼‰</strong>ã®2ã¤ã®ã‚¿ã‚¹ã‚¯ã‚’å¯¾è±¡ã«ã€Random Forestï¼ˆMagpieç‰¹å¾´é‡ï¼‰ã¨CGCNNã®æ€§èƒ½ã‚’æ¯”è¼ƒã—ã¾ã™ã€‚</p>

        <h3>4.1.2 è©•ä¾¡ãƒ—ãƒ­ãƒˆã‚³ãƒ«</h3>

        <p>Matbenchã§ã¯ã€<strong>5-foldäº¤å·®æ¤œè¨¼</strong>ã«ã‚ˆã‚‹è©•ä¾¡ãŒæ¨™æº–ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã§ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå…¨ä½“ãŒ5ã¤ã®foldã«åˆ†å‰²ã•ã‚Œã¦ãŠã‚Šã€å„foldã«ã¤ã„ã¦ä»¥ä¸‹ã®è©•ä¾¡ã‚’å®Ÿæ–½ã—ã¾ã™ï¼š</p>

        <ol>
            <li><strong>è¨“ç·´ï¼ˆTrainingï¼‰</strong>ï¼šæ®‹ã‚Šã®4 foldã§ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´</li>
            <li><strong>æ¤œè¨¼ï¼ˆValidationï¼‰</strong>ï¼šãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«ä½¿ç”¨ï¼ˆä»»æ„ï¼‰</li>
            <li><strong>ãƒ†ã‚¹ãƒˆï¼ˆTestingï¼‰</strong>ï¼šè©²å½“foldã§æ€§èƒ½è©•ä¾¡ï¼ˆMAEã€RMSEã€RÂ²ã‚’è¨ˆç®—ï¼‰</li>
        </ol>

        <p>5ã¤ã®foldã®è©•ä¾¡æŒ‡æ¨™ã‚’å¹³å‡ã™ã‚‹ã“ã¨ã§ã€<strong>æ±åŒ–æ€§èƒ½ã®ä¿¡é ¼æ€§ã®é«˜ã„æ¨å®š</strong>ãŒå¾—ã‚‰ã‚Œã¾ã™ã€‚</p>

        <h2>4.2 Matbenchãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè£…</h2>

        <p>æœ¬ç¯€ã§ã¯ã€Random Forestï¼ˆMagpieï¼‰ã¨CGCNN on Matbench mp_e_formã‚¿ã‚¹ã‚¯ã‚’å®Ÿè£…ã—ã€äºˆæ¸¬ç²¾åº¦ã‚’å®šé‡çš„ã«æ¯”è¼ƒã—ã¾ã™ã€‚</p>

        <h3>4.2.1 ç’°å¢ƒæ§‹ç¯‰ã¨ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰</h3>

        <div class="highlight-box">
            <strong>ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹1ï¼šMatbenchãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ­ãƒ¼ãƒ‰</strong>
        </div>

        <pre><code class="language-python"># Matbenchãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ­ãƒ¼ãƒ‰ã¨å‰å‡¦ç†
import numpy as np
import pandas as pd
from matbench.bench import MatbenchBenchmark
from pymatgen.core import Structure
from matminer.featurizers.composition import ElementProperty
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import warnings
warnings.filterwarnings('ignore')

# Matbenchãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®åˆæœŸåŒ–
mb = MatbenchBenchmark(autoload=False)

# mp_e_formã‚¿ã‚¹ã‚¯ã‚’ãƒ­ãƒ¼ãƒ‰ï¼ˆç”Ÿæˆã‚¨ãƒãƒ«ã‚®ãƒ¼äºˆæ¸¬ï¼‰
task = mb.matbench_mp_e_form
task.load()

print(f"ã‚¿ã‚¹ã‚¯å: {task.metadata['task_type']}")
print(f"ãƒ‡ãƒ¼ã‚¿æ•°: {len(task.df)}")
print(f"å…¥åŠ›: {task.metadata['input_type']}")
print(f"å‡ºåŠ›: {task.metadata['target']}")

# ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®ç¢ºèª
print("\nãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒ«:")
print(task.df.head(3))

# å‡ºåŠ›ä¾‹ï¼š
# ã‚¿ã‚¹ã‚¯å: regression
# ãƒ‡ãƒ¼ã‚¿æ•°: 132752
# å…¥åŠ›: structure
# å‡ºåŠ›: e_form (eV/atom)
#
# ãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒ«:
#                                           structure  e_form
# 0  Structure: Fe2 O3 ...                    -2.54
# 1  Structure: Mn2 O3 ...                    -2.89
# 2  Structure: Co2 O3 ...                    -2.31
</code></pre>

        <h3>4.2.2 Random Forestï¼ˆMagpieç‰¹å¾´é‡ï¼‰ã®å®Ÿè£…</h3>

        <div class="highlight-box">
            <strong>ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹2ï¼šMagpieç‰¹å¾´é‡æŠ½å‡ºã¨Random Forestè¨“ç·´</strong>
        </div>

        <pre><code class="language-python"># Random Forest + Magpieç‰¹å¾´é‡ã®å®Ÿè£…
from matminer.featurizers.composition import ElementProperty

def extract_magpie_features(structures):
    """
    Pymatgenã®Structureã‹ã‚‰Magpieç‰¹å¾´é‡ã‚’æŠ½å‡º

    Parameters:
    -----------
    structures : list of Structure
        çµæ™¶æ§‹é€ ã®ãƒªã‚¹ãƒˆ

    Returns:
    --------
    features : np.ndarray, shape (n_samples, 145)
        Magpieç‰¹å¾´é‡ï¼ˆ145æ¬¡å…ƒï¼‰
    """
    # Magpieç‰¹å¾´é‡æŠ½å‡ºå™¨ã®åˆæœŸåŒ–
    featurizer = ElementProperty.from_preset("magpie")

    features = []
    for struct in structures:
        # Structureã‹ã‚‰Compositionã‚’å–å¾—
        comp = struct.composition
        # Magpieç‰¹å¾´é‡ã‚’è¨ˆç®—ï¼ˆ145æ¬¡å…ƒï¼‰
        feat = featurizer.featurize(comp)
        features.append(feat)

    return np.array(features)

# 5-foldäº¤å·®æ¤œè¨¼ã®è©•ä¾¡
rf_results = []

for fold_idx, fold in enumerate(task.folds):
    print(f"\n=== Fold {fold_idx + 1}/5 ===")

    # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    train_inputs, train_outputs = task.get_train_and_val_data(fold)
    test_inputs, test_outputs = task.get_test_data(fold, include_target=True)

    # Magpieç‰¹å¾´é‡æŠ½å‡º
    print("Magpieç‰¹å¾´é‡ã‚’æŠ½å‡ºä¸­...")
    X_train = extract_magpie_features(train_inputs)
    X_test = extract_magpie_features(test_inputs)
    y_train = train_outputs.values
    y_test = test_outputs.values

    print(f"è¨“ç·´ãƒ‡ãƒ¼ã‚¿: {X_train.shape}, ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {X_test.shape}")

    # Random Forestãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´
    print("Random Forestã‚’è¨“ç·´ä¸­...")
    rf_model = RandomForestRegressor(
        n_estimators=100,
        max_depth=30,
        min_samples_split=5,
        random_state=42,
        n_jobs=-1
    )
    rf_model.fit(X_train, y_train)

    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§äºˆæ¸¬
    y_pred = rf_model.predict(X_test)

    # è©•ä¾¡æŒ‡æ¨™ã‚’è¨ˆç®—
    mae = mean_absolute_error(y_test, y_pred)
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    r2 = r2_score(y_test, y_pred)

    print(f"MAE:  {mae:.4f} eV/atom")
    print(f"RMSE: {rmse:.4f} eV/atom")
    print(f"RÂ²:   {r2:.4f}")

    rf_results.append({
        'fold': fold_idx + 1,
        'mae': mae,
        'rmse': rmse,
        'r2': r2
    })

# 5-foldå¹³å‡ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—
rf_df = pd.DataFrame(rf_results)
print("\n=== Random Forest (Magpie) ç·åˆçµæœ ===")
print(f"MAE:  {rf_df['mae'].mean():.4f} Â± {rf_df['mae'].std():.4f} eV/atom")
print(f"RMSE: {rf_df['rmse'].mean():.4f} Â± {rf_df['rmse'].std():.4f} eV/atom")
print(f"RÂ²:   {rf_df['r2'].mean():.4f} Â± {rf_df['r2'].std():.4f}")

# å‡ºåŠ›ä¾‹ï¼š
# === Random Forest (Magpie) ç·åˆçµæœ ===
# MAE:  0.0325 Â± 0.0012 eV/atom
# RMSE: 0.0678 Â± 0.0019 eV/atom
# RÂ²:   0.9321 Â± 0.0045
</code></pre>

        <h3>4.2.3 CGCNNã®å®Ÿè£…</h3>

        <div class="highlight-box">
            <strong>ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹3ï¼šCGCNN on Matbenchè¨“ç·´</strong>
        </div>

        <pre><code class="language-python"># CGCNN on Matbenchã®å®Ÿè£…
import torch
import torch.nn as nn
from torch_geometric.data import Data, DataLoader
from torch_geometric.nn import CGConv, global_mean_pool
import time

# CGCNN for Matbenchã®å®šç¾©ï¼ˆChapter 2ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ï¼‰
class CGCNNMatbench(nn.Module):
    def __init__(self, atom_fea_len=92, nbr_fea_len=41, hidden_dim=128, n_conv=3):
        super(CGCNNMatbench, self).__init__()

        # Atom embedding
        self.atom_embedding = nn.Linear(atom_fea_len, hidden_dim)

        # Convolution layers
        self.conv_layers = nn.ModuleList([
            CGConv(hidden_dim, nbr_fea_len) for _ in range(n_conv)
        ])
        self.bn_layers = nn.ModuleList([
            nn.BatchNorm1d(hidden_dim) for _ in range(n_conv)
        ])

        # Readout
        self.fc1 = nn.Linear(hidden_dim, 64)
        self.fc2 = nn.Linear(64, 1)
        self.activation = nn.Softplus()

    def forward(self, data):
        x, edge_index, edge_attr, batch = data.x, data.edge_index, data.edge_attr, data.batch

        # Atom embedding
        x = self.atom_embedding(x)

        # Graph convolutions
        for conv, bn in zip(self.conv_layers, self.bn_layers):
            x = conv(x, edge_index, edge_attr)
            x = bn(x)
            x = self.activation(x)

        # Global pooling
        x = global_mean_pool(x, batch)

        # Fully connected layers
        x = self.fc1(x)
        x = self.activation(x)
        x = self.fc2(x)

        return x.squeeze()

def structure_to_pyg_data(structure, target, cutoff=8.0):
    """
    Pymatgenã®Structureã‚’PyTorch Geometricã®ãƒ‡ãƒ¼ã‚¿ã«å¤‰æ›

    Parameters:
    -----------
    structure : Structure
        çµæ™¶æ§‹é€ 
    target : float
        ç›®æ¨™å€¤ï¼ˆç”Ÿæˆã‚¨ãƒãƒ«ã‚®ãƒ¼ï¼‰
    cutoff : float
        ã‚«ãƒƒãƒˆã‚ªãƒ•åŠå¾„ (Ã…)

    Returns:
    --------
    data : Data
        PyTorch Geometricã®ãƒ‡ãƒ¼ã‚¿ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
    """
    # ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡ï¼ˆå…ƒç´ ã®one-hot encodingã€92æ¬¡å…ƒï¼‰
    atom_types = [site.specie.Z for site in structure]
    x = torch.zeros(len(atom_types), 92)
    for i, z in enumerate(atom_types):
        x[i, z - 1] = 1.0

    # ã‚¨ãƒƒã‚¸æ§‹ç¯‰ï¼ˆcutoffåŠå¾„ä»¥å†…ã®åŸå­ãƒšã‚¢ï¼‰
    neighbors = structure.get_all_neighbors(cutoff)
    edge_index = []
    edge_attr = []

    for i, neighbors_i in enumerate(neighbors):
        for neighbor in neighbors_i:
            j = neighbor.index
            distance = neighbor.nn_distance

            # Gaussian distance expansion (41æ¬¡å…ƒ)
            distances = torch.linspace(0, cutoff, 41)
            sigma = 0.5
            edge_feature = torch.exp(-((distance - distances) ** 2) / (2 * sigma ** 2))

            edge_index.append([i, j])
            edge_attr.append(edge_feature)

    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()
    edge_attr = torch.stack(edge_attr)
    y = torch.tensor([target], dtype=torch.float)

    return Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)

# 5-foldäº¤å·®æ¤œè¨¼ã®è©•ä¾¡
cgcnn_results = []

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹: {device}")

for fold_idx, fold in enumerate(task.folds):
    print(f"\n=== Fold {fold_idx + 1}/5 ===")

    # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    train_inputs, train_outputs = task.get_train_and_val_data(fold)
    test_inputs, test_outputs = task.get_test_data(fold, include_target=True)

    # PyTorch Geometricãƒ‡ãƒ¼ã‚¿ã«å¤‰æ›
    print("ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ã‚’æ§‹ç¯‰ä¸­...")
    train_data = [structure_to_pyg_data(s, t) for s, t in zip(train_inputs, train_outputs.values)]
    test_data = [structure_to_pyg_data(s, t) for s, t in zip(test_inputs, test_outputs.values)]

    train_loader = DataLoader(train_data, batch_size=32, shuffle=True)
    test_loader = DataLoader(test_data, batch_size=32, shuffle=False)

    # CGCNNãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–
    model = CGCNNMatbench().to(device)
    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
    criterion = nn.L1Loss()  # MAEæå¤±

    # è¨“ç·´
    print("CGCNNã‚’è¨“ç·´ä¸­...")
    model.train()
    for epoch in range(50):  # å®Ÿéš›ã«ã¯early stoppingã‚’ä½¿ç”¨ã™ã¹ã
        total_loss = 0
        for batch in train_loader:
            batch = batch.to(device)
            optimizer.zero_grad()
            out = model(batch)
            loss = criterion(out, batch.y)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()

        if (epoch + 1) % 10 == 0:
            print(f"Epoch {epoch+1}/50, Loss: {total_loss/len(train_loader):.4f}")

    # ãƒ†ã‚¹ãƒˆ
    model.eval()
    y_true = []
    y_pred = []

    with torch.no_grad():
        for batch in test_loader:
            batch = batch.to(device)
            out = model(batch)
            y_true.extend(batch.y.cpu().numpy())
            y_pred.extend(out.cpu().numpy())

    y_true = np.array(y_true)
    y_pred = np.array(y_pred)

    # è©•ä¾¡æŒ‡æ¨™ã‚’è¨ˆç®—
    mae = mean_absolute_error(y_true, y_pred)
    rmse = np.sqrt(mean_squared_error(y_true, y_pred))
    r2 = r2_score(y_true, y_pred)

    print(f"MAE:  {mae:.4f} eV/atom")
    print(f"RMSE: {rmse:.4f} eV/atom")
    print(f"RÂ²:   {r2:.4f}")

    cgcnn_results.append({
        'fold': fold_idx + 1,
        'mae': mae,
        'rmse': rmse,
        'r2': r2
    })

# 5-foldå¹³å‡ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—
cgcnn_df = pd.DataFrame(cgcnn_results)
print("\n=== CGCNN ç·åˆçµæœ ===")
print(f"MAE:  {cgcnn_df['mae'].mean():.4f} Â± {cgcnn_df['mae'].std():.4f} eV/atom")
print(f"RMSE: {cgcnn_df['rmse'].mean():.4f} Â± {cgcnn_df['rmse'].std():.4f} eV/atom")
print(f"RÂ²:   {cgcnn_df['r2'].mean():.4f} Â± {cgcnn_df['r2'].std():.4f}")

# å‡ºåŠ›ä¾‹ï¼š
# === CGCNN ç·åˆçµæœ ===
# MAE:  0.0286 Â± 0.0009 eV/atom
# RMSE: 0.0592 Â± 0.0014 eV/atom
# RÂ²:   0.9524 Â± 0.0032
</code></pre>

        <h3>4.2.4 äºˆæ¸¬ç²¾åº¦ã®å®šé‡çš„æ¯”è¼ƒ</h3>

        <p>5-foldäº¤å·®æ¤œè¨¼ã®çµæœã‚’çµ±åˆã—ã€Random Forestï¼ˆMagpieï¼‰ã¨CGCNNã®äºˆæ¸¬ç²¾åº¦ã‚’æ¯”è¼ƒã—ã¾ã™ã€‚</p>

        <div class="highlight-box">
            <strong>ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹4ï¼šäºˆæ¸¬ç²¾åº¦æ¯”è¼ƒã®å¯è¦–åŒ–</strong>
        </div>

        <pre><code class="language-python"># äºˆæ¸¬ç²¾åº¦æ¯”è¼ƒã®å¯è¦–åŒ–
import matplotlib.pyplot as plt
import seaborn as sns

# çµæœã‚’çµ±åˆ
comparison_df = pd.DataFrame({
    'Model': ['RF (Magpie)'] * 5 + ['CGCNN'] * 5,
    'Fold': list(range(1, 6)) * 2,
    'MAE': list(rf_df['mae']) + list(cgcnn_df['mae']),
    'RMSE': list(rf_df['rmse']) + list(cgcnn_df['rmse']),
    'RÂ²': list(rf_df['r2']) + list(cgcnn_df['r2'])
})

# å¯è¦–åŒ–
fig, axes = plt.subplots(1, 3, figsize=(15, 5))

# MAEæ¯”è¼ƒ
sns.barplot(data=comparison_df, x='Model', y='MAE', ax=axes[0], palette=['#667eea', '#764ba2'])
axes[0].set_title('MAE Comparison (Lower is Better)', fontsize=14, fontweight='bold')
axes[0].set_ylabel('MAE (eV/atom)', fontsize=12)
axes[0].axhline(0.03, color='red', linestyle='--', linewidth=1, label='Target: 0.03')
axes[0].legend()

# RMSEæ¯”è¼ƒ
sns.barplot(data=comparison_df, x='Model', y='RMSE', ax=axes[1], palette=['#667eea', '#764ba2'])
axes[1].set_title('RMSE Comparison (Lower is Better)', fontsize=14, fontweight='bold')
axes[1].set_ylabel('RMSE (eV/atom)', fontsize=12)

# RÂ²æ¯”è¼ƒ
sns.barplot(data=comparison_df, x='Model', y='RÂ²', ax=axes[2], palette=['#667eea', '#764ba2'])
axes[2].set_title('RÂ² Comparison (Higher is Better)', fontsize=14, fontweight='bold')
axes[2].set_ylabel('RÂ²', fontsize=12)
axes[2].axhline(0.95, color='red', linestyle='--', linewidth=1, label='Target: 0.95')
axes[2].legend()

plt.tight_layout()
plt.savefig('accuracy_comparison.png', dpi=300, bbox_inches='tight')
plt.show()

# çµ±è¨ˆã‚µãƒãƒªãƒ¼
print("=== äºˆæ¸¬ç²¾åº¦ã®çµ±è¨ˆã‚µãƒãƒªãƒ¼ ===")
print(comparison_df.groupby('Model').agg({
    'MAE': ['mean', 'std'],
    'RMSE': ['mean', 'std'],
    'RÂ²': ['mean', 'std']
}).round(4))

# ç›¸å¯¾çš„ãªæ”¹å–„ç‡ã‚’è¨ˆç®—
mae_improvement = (rf_df['mae'].mean() - cgcnn_df['mae'].mean()) / rf_df['mae'].mean() * 100
rmse_improvement = (rf_df['rmse'].mean() - cgcnn_df['rmse'].mean()) / rf_df['rmse'].mean() * 100
r2_improvement = (cgcnn_df['r2'].mean() - rf_df['r2'].mean()) / rf_df['r2'].mean() * 100

print(f"\n=== CGCNNã®ç›¸å¯¾çš„æ”¹å–„ç‡ ===")
print(f"MAEæ”¹å–„:  {mae_improvement:.2f}%")
print(f"RMSEæ”¹å–„: {rmse_improvement:.2f}%")
print(f"RÂ²æ”¹å–„:   {r2_improvement:.2f}%")

# å‡ºåŠ›ä¾‹ï¼š
# === CGCNNã®ç›¸å¯¾çš„æ”¹å–„ç‡ ===
# MAEæ”¹å–„:  12.00%
# RMSEæ”¹å–„: 12.68%
# RÂ²æ”¹å–„:   2.18%
</code></pre>

        <p><strong>çµæœã®è§£é‡ˆï¼š</strong></p>
        <ul>
            <li><strong>MAEæ”¹å–„ï¼š12.00%</strong> - CGCNNã¯ç”Ÿæˆã‚¨ãƒãƒ«ã‚®ãƒ¼äºˆæ¸¬ã«ãŠã„ã¦ã€Magpie+RFã‚ˆã‚Šã‚‚ç´„12%ä½ã„èª¤å·®ã‚’é”æˆ</li>
            <li><strong>RÂ²æ”¹å–„ï¼š2.18%</strong> - æ—¢ã«RFãŒé«˜ã„RÂ²ï¼ˆ0.932ï¼‰ã‚’é”æˆã—ã¦ã„ã‚‹ãŸã‚ã€ç›¸å¯¾çš„æ”¹å–„ç‡ã¯å°ã•ã„ãŒã€CGCNNã¯0.952ã¨ã„ã†æ¥µã‚ã¦é«˜ã„æ±ºå®šä¿‚æ•°ã‚’å®Ÿç¾</li>
            <li><strong>çµ±è¨ˆçš„æœ‰æ„æ€§ã®æ¤œè¨¼ãŒå¿…è¦</strong> - æ¬¡ç¯€ã§ã€ã“ã®ç²¾åº¦å·®ãŒçµ±è¨ˆçš„ã«æœ‰æ„ã‹ã‚’æ¤œå®šã—ã¾ã™</li>
        </ul>

        <div class="warning-box">
            <strong>âš ï¸ é‡è¦ãªæ³¨æ„ç‚¹</strong>
            <p>æœ¬ã‚³ãƒ¼ãƒ‰ä¾‹ã§ã¯è¨ˆç®—æ™‚é–“ã®éƒ½åˆä¸Šã€CGCNNã®ã‚¨ãƒãƒƒã‚¯æ•°ã‚’50ã«åˆ¶é™ã—ã¦ã„ã¾ã™ãŒã€å®Ÿéš›ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã¯<strong>early stoppingã¨ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–</strong>ã‚’å®Ÿæ–½ã™ã¹ãã§ã™ã€‚ã¾ãŸã€GPUç’°å¢ƒã§ã®å®Ÿè¡Œã‚’å¼·ãæ¨å¥¨ã—ã¾ã™ï¼ˆè¨“ç·´æ™‚é–“ãŒ10-20å€é«˜é€ŸåŒ–ï¼‰ã€‚</p>
        </div>

        <h2>4.3 çµ±è¨ˆçš„æœ‰æ„æ€§æ¤œå®š</h2>

        <p>å‰ç¯€ã§ã¯ã€CGCNNãŒRandom Forestï¼ˆMagpieï¼‰ã‚ˆã‚Šã‚‚ç´„12%ä½ã„MAEã‚’é”æˆã™ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¾ã—ãŸã€‚ã—ã‹ã—ã€ã“ã®ç²¾åº¦å·®ãŒ<strong>çµ±è¨ˆçš„ã«æœ‰æ„</strong>ã‹ã©ã†ã‹ã‚’æ¤œè¨¼ã—ãªã‘ã‚Œã°ã€å˜ãªã‚‹å¶ç„¶ã®å¯èƒ½æ€§ã‚’æ’é™¤ã§ãã¾ã›ã‚“ã€‚æœ¬ç¯€ã§ã¯ã€<strong>å¯¾å¿œã®ã‚ã‚‹tæ¤œå®šï¼ˆpaired t-testï¼‰</strong>ã¨<strong>95%ä¿¡é ¼åŒºé–“</strong>ã‚’ç”¨ã„ã¦çµ±è¨ˆçš„æœ‰æ„æ€§ã‚’è©•ä¾¡ã—ã¾ã™ã€‚</p>

        <h3>4.3.1 å¯¾å¿œã®ã‚ã‚‹tæ¤œå®šã®åŸç†</h3>

        <p>5-foldäº¤å·®æ¤œè¨¼ã§ã¯ã€åŒã˜ãƒ‡ãƒ¼ã‚¿åˆ†å‰²ã«å¯¾ã—ã¦RFã¨CGCNNã®ä¸¡æ–¹ã‚’è©•ä¾¡ã—ã¦ã„ã¾ã™ã€‚ã—ãŸãŒã£ã¦ã€å„foldã®MAEå·®ã¯<strong>å¯¾å¿œã®ã‚ã‚‹ãƒ‡ãƒ¼ã‚¿ï¼ˆpaired dataï¼‰</strong>ã¨ã—ã¦æ‰±ã†ã“ã¨ãŒã§ãã¾ã™ã€‚å¯¾å¿œã®ã‚ã‚‹tæ¤œå®šã¯ã€ä»¥ä¸‹ã®å¸°ç„¡ä»®èª¬ã‚’æ¤œå®šã—ã¾ã™ï¼š</p>

        <p>$$H_0: \mu_{\text{diff}} = 0 \quad \text{ï¼ˆRFã¨CGCNNã®å¹³å‡MAEå·®ã¯ã‚¼ãƒ­ï¼‰}$$</p>

        <p>$$H_1: \mu_{\text{diff}} \neq 0 \quad \text{ï¼ˆå¹³å‡MAEå·®ã¯ã‚¼ãƒ­ã§ã¯ãªã„ï¼‰}$$</p>

        <p>æ¤œå®šçµ±è¨ˆé‡tã¯ä»¥ä¸‹ã®ã‚ˆã†ã«è¨ˆç®—ã•ã‚Œã¾ã™ï¼š</p>

        <p>$$t = \frac{\bar{d}}{s_d / \sqrt{n}}$$</p>

        <p>ã“ã“ã§ã€$\bar{d}$ã¯å·®ã®å¹³å‡ã€$s_d$ã¯å·®ã®æ¨™æº–åå·®ã€$n$ã¯ã‚µãƒ³ãƒ—ãƒ«æ•°ï¼ˆfoldæ•°=5ï¼‰ã§ã™ã€‚</p>

        <h3>4.3.2 tæ¤œå®šã®å®Ÿè£…</h3>

        <div class="highlight-box">
            <strong>ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹5ï¼šå¯¾å¿œã®ã‚ã‚‹tæ¤œå®šã®å®Ÿè£…</strong>
        </div>

        <pre><code class="language-python"># å¯¾å¿œã®ã‚ã‚‹tæ¤œå®šã®å®Ÿè£…
from scipy import stats
import numpy as np

# Random Forestã¨CGCNNã®MAEï¼ˆ5 foldã®çµæœï¼‰
rf_mae = np.array([0.0325, 0.0338, 0.0312, 0.0329, 0.0321])  # ä¾‹ç¤ºãƒ‡ãƒ¼ã‚¿
cgcnn_mae = np.array([0.0286, 0.0293, 0.0279, 0.0288, 0.0284])  # ä¾‹ç¤ºãƒ‡ãƒ¼ã‚¿

# MAEã®å·®ã‚’è¨ˆç®—
mae_diff = rf_mae - cgcnn_mae

print("=== å¯¾å¿œã®ã‚ã‚‹tæ¤œå®š ===")
print(f"RF MAE:     {rf_mae}")
print(f"CGCNN MAE:  {cgcnn_mae}")
print(f"MAEå·®:      {mae_diff}")
print(f"å¹³å‡å·®:     {mae_diff.mean():.4f} eV/atom")
print(f"æ¨™æº–åå·®:   {mae_diff.std(ddof=1):.4f} eV/atom")

# å¯¾å¿œã®ã‚ã‚‹tæ¤œå®šã‚’å®Ÿæ–½
t_statistic, p_value = stats.ttest_rel(rf_mae, cgcnn_mae)

print(f"\ntçµ±è¨ˆé‡:    {t_statistic:.4f}")
print(f"på€¤:        {p_value:.4f}")

# æœ‰æ„æ°´æº–Î±=0.05ã§åˆ¤å®š
alpha = 0.05
if p_value < alpha:
    print(f"\nåˆ¤å®š: på€¤ ({p_value:.4f}) < Î± ({alpha}) â†’ å¸°ç„¡ä»®èª¬ã‚’æ£„å´")
    print("çµè«–: CGCNNã¨RFã®ç²¾åº¦å·®ã¯çµ±è¨ˆçš„ã«æœ‰æ„ã§ã™ã€‚")
else:
    print(f"\nåˆ¤å®š: på€¤ ({p_value:.4f}) â‰¥ Î± ({alpha}) â†’ å¸°ç„¡ä»®èª¬ã‚’æ£„å´ã§ãã¾ã›ã‚“")
    print("çµè«–: CGCNNã¨RFã®ç²¾åº¦å·®ã¯çµ±è¨ˆçš„ã«æœ‰æ„ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")

# åŠ¹æœé‡ï¼ˆCohen's dï¼‰ã‚’è¨ˆç®—
cohens_d = mae_diff.mean() / mae_diff.std(ddof=1)
print(f"\nåŠ¹æœé‡ï¼ˆCohen's dï¼‰: {cohens_d:.4f}")
if abs(cohens_d) < 0.2:
    print("åŠ¹æœé‡ã®å¤§ãã•: å°ã•ã„")
elif abs(cohens_d) < 0.5:
    print("åŠ¹æœé‡ã®å¤§ãã•: ä¸­ç¨‹åº¦")
elif abs(cohens_d) < 0.8:
    print("åŠ¹æœé‡ã®å¤§ãã•: å¤§ãã„")
else:
    print("åŠ¹æœé‡ã®å¤§ãã•: éå¸¸ã«å¤§ãã„")

# å‡ºåŠ›ä¾‹ï¼š
# === å¯¾å¿œã®ã‚ã‚‹tæ¤œå®š ===
# RF MAE:     [0.0325 0.0338 0.0312 0.0329 0.0321]
# CGCNN MAE:  [0.0286 0.0293 0.0279 0.0288 0.0284]
# MAEå·®:      [0.0039 0.0045 0.0033 0.0041 0.0037]
# å¹³å‡å·®:     0.0039 eV/atom
# æ¨™æº–åå·®:   0.0004 eV/atom
#
# tçµ±è¨ˆé‡:    20.5891
# på€¤:        0.0001
#
# åˆ¤å®š: på€¤ (0.0001) < Î± (0.05) â†’ å¸°ç„¡ä»®èª¬ã‚’æ£„å´
# çµè«–: CGCNNã¨RFã®ç²¾åº¦å·®ã¯çµ±è¨ˆçš„ã«æœ‰æ„ã§ã™ã€‚
#
# åŠ¹æœé‡ï¼ˆCohen's dï¼‰: 9.1894
# åŠ¹æœé‡ã®å¤§ãã•: éå¸¸ã«å¤§ãã„
</code></pre>

        <h3>4.3.3 95%ä¿¡é ¼åŒºé–“ã®è¨ˆç®—</h3>

        <p>95%ä¿¡é ¼åŒºé–“ã¯ã€<strong>çœŸã®å¹³å‡å·®ãŒ95%ã®ç¢ºç‡ã§å«ã¾ã‚Œã‚‹ç¯„å›²</strong>ã‚’ç¤ºã—ã¾ã™ã€‚ä¿¡é ¼åŒºé–“ãŒ0ã‚’å«ã¾ãªã„å ´åˆã€çµ±è¨ˆçš„ã«æœ‰æ„ãªå·®ãŒã‚ã‚‹ã¨çµè«–ã§ãã¾ã™ã€‚</p>

        <div class="highlight-box">
            <strong>ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹6ï¼š95%ä¿¡é ¼åŒºé–“ã®è¨ˆç®—ã¨å¯è¦–åŒ–</strong>
        </div>

        <pre><code class="language-python"># 95%ä¿¡é ¼åŒºé–“ã®è¨ˆç®—ã¨å¯è¦–åŒ–
from scipy import stats
import matplotlib.pyplot as plt

# 95%ä¿¡é ¼åŒºé–“ã‚’è¨ˆç®—
confidence_level = 0.95
degrees_freedom = len(mae_diff) - 1
t_critical = stats.t.ppf((1 + confidence_level) / 2, degrees_freedom)

mean_diff = mae_diff.mean()
se_diff = mae_diff.std(ddof=1) / np.sqrt(len(mae_diff))
margin_error = t_critical * se_diff

ci_lower = mean_diff - margin_error
ci_upper = mean_diff + margin_error

print("=== 95%ä¿¡é ¼åŒºé–“ ===")
print(f"å¹³å‡å·®:          {mean_diff:.4f} eV/atom")
print(f"æ¨™æº–èª¤å·®:        {se_diff:.4f} eV/atom")
print(f"tè‡¨ç•Œå€¤ (df={degrees_freedom}): {t_critical:.4f}")
print(f"èª¤å·®ç¯„å›²:        Â±{margin_error:.4f} eV/atom")
print(f"95%ä¿¡é ¼åŒºé–“:     [{ci_lower:.4f}, {ci_upper:.4f}] eV/atom")

if ci_lower > 0:
    print("\nåˆ¤å®š: ä¿¡é ¼åŒºé–“ãŒ0ã‚’å«ã¾ãªã„ â†’ çµ±è¨ˆçš„ã«æœ‰æ„ãªå·®ã‚ã‚Š")
else:
    print("\nåˆ¤å®š: ä¿¡é ¼åŒºé–“ãŒ0ã‚’å«ã‚€ â†’ çµ±è¨ˆçš„ã«æœ‰æ„ãªå·®ãªã—")

# å¯è¦–åŒ–
fig, ax = plt.subplots(figsize=(10, 6))

# å„foldã®MAEå·®ã‚’ãƒ—ãƒ­ãƒƒãƒˆ
ax.scatter(range(1, 6), mae_diff, s=100, color='#764ba2', zorder=3, label='å„foldã®MAEå·®')

# å¹³å‡ç·š
ax.axhline(mean_diff, color='#667eea', linestyle='--', linewidth=2, label=f'å¹³å‡å·®: {mean_diff:.4f}')

# 95%ä¿¡é ¼åŒºé–“
ax.axhspan(ci_lower, ci_upper, alpha=0.2, color='#667eea', label=f'95%ä¿¡é ¼åŒºé–“: [{ci_lower:.4f}, {ci_upper:.4f}]')

# ã‚¼ãƒ­ãƒ©ã‚¤ãƒ³
ax.axhline(0, color='red', linestyle='-', linewidth=1, label='å·®ãªã—ï¼ˆHâ‚€ï¼‰')

ax.set_xlabel('Foldç•ªå·', fontsize=12)
ax.set_ylabel('MAEå·® (RF - CGCNN) [eV/atom]', fontsize=12)
ax.set_title('5-foldäº¤å·®æ¤œè¨¼ã«ãŠã‘ã‚‹MAEå·®ã¨95%ä¿¡é ¼åŒºé–“', fontsize=14, fontweight='bold')
ax.set_xticks(range(1, 6))
ax.legend(fontsize=10)
ax.grid(alpha=0.3)

plt.tight_layout()
plt.savefig('statistical_significance.png', dpi=300, bbox_inches='tight')
plt.show()

# å‡ºåŠ›ä¾‹ï¼š
# === 95%ä¿¡é ¼åŒºé–“ ===
# å¹³å‡å·®:          0.0039 eV/atom
# æ¨™æº–èª¤å·®:        0.0002 eV/atom
# tè‡¨ç•Œå€¤ (df=4): 2.7764
# èª¤å·®ç¯„å›²:        Â±0.0005 eV/atom
# 95%ä¿¡é ¼åŒºé–“:     [0.0034, 0.0044] eV/atom
#
# åˆ¤å®š: ä¿¡é ¼åŒºé–“ãŒ0ã‚’å«ã¾ãªã„ â†’ çµ±è¨ˆçš„ã«æœ‰æ„ãªå·®ã‚ã‚Š
</code></pre>

        <h3>4.3.4 çµ±è¨ˆçš„æ¤œå®šçµæœã®ã¾ã¨ã‚</h3>

        <table>
            <thead>
                <tr>
                    <th>æ¤œå®šæ‰‹æ³•</th>
                    <th>çµæœ</th>
                    <th>è§£é‡ˆ</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>å¯¾å¿œã®ã‚ã‚‹tæ¤œå®š</td>
                    <td>t=20.59, p=0.0001</td>
                    <td>p < 0.05 â†’ çµ±è¨ˆçš„ã«æœ‰æ„</td>
                </tr>
                <tr>
                    <td>95%ä¿¡é ¼åŒºé–“</td>
                    <td>[0.0034, 0.0044] eV/atom</td>
                    <td>0ã‚’å«ã¾ãªã„ â†’ çµ±è¨ˆçš„ã«æœ‰æ„</td>
                </tr>
                <tr>
                    <td>åŠ¹æœé‡ï¼ˆCohen's dï¼‰</td>
                    <td>9.19</td>
                    <td>éå¸¸ã«å¤§ãã„åŠ¹æœé‡</td>
                </tr>
                <tr>
                    <td>ç›¸å¯¾çš„æ”¹å–„ç‡</td>
                    <td>12.00%</td>
                    <td>å®Ÿç”¨ä¸Šã®æ„ç¾©ã‚ã‚Š</td>
                </tr>
            </tbody>
        </table>

        <p><strong>çµè«–ï¼š</strong></p>
        <ul>
            <li>CGCNNã¯Random Forestï¼ˆMagpieï¼‰ã«å¯¾ã—ã¦<strong>çµ±è¨ˆçš„ã«æœ‰æ„ãªç²¾åº¦å‘ä¸Š</strong>ã‚’ç¤ºã—ã¾ã—ãŸï¼ˆp=0.0001 << 0.05ï¼‰</li>
            <li>95%ä¿¡é ¼åŒºé–“ [0.0034, 0.0044] eV/atomã¯0ã‚’å«ã¾ãªã„ãŸã‚ã€ç²¾åº¦å·®ã®å­˜åœ¨ã¯çµ±è¨ˆçš„ã«æ”¯æŒã•ã‚Œã¾ã™</li>
            <li>Cohen's d = 9.19ã¨ã„ã†æ¥µã‚ã¦å¤§ãã„åŠ¹æœé‡ã¯ã€CGCNNã®å®Ÿç”¨ä¸Šã®å„ªä½æ€§ã‚’ç¤ºã—ã¦ã„ã¾ã™</li>
            <li>12%ã®ç›¸å¯¾çš„æ”¹å–„ç‡ã¯ã€ææ–™æ¢ç´¢ã®åŠ¹ç‡åŒ–ã«ç›´çµã™ã‚‹å®Ÿå‹™çš„ãªãƒ¡ãƒªãƒƒãƒˆãŒã‚ã‚Šã¾ã™</li>
        </ul>

        <div class="warning-box">
            <strong>âš ï¸ çµ±è¨ˆçš„æœ‰æ„æ€§ vs å®Ÿç”¨çš„æœ‰æ„æ€§</strong>
            <p>çµ±è¨ˆçš„ã«æœ‰æ„ãªå·®ãŒèªã‚ã‚‰ã‚Œã¦ã‚‚ã€ãã®å·®ãŒ<strong>å®Ÿç”¨ä¸Šæ„å‘³ãŒã‚ã‚‹ã‹</strong>ã¯åˆ¥é€”æ¤œè¨ãŒå¿…è¦ã§ã™ã€‚æœ¬ã‚±ãƒ¼ã‚¹ã§ã¯ã€MAEå·®0.0039 eV/atomã¯ææ–™æ¢ç´¢ã«ãŠã„ã¦ååˆ†å®Ÿç”¨çš„ãªæ”¹å–„ã¨åˆ¤æ–­ã§ãã¾ã™ï¼ˆç”Ÿæˆã‚¨ãƒãƒ«ã‚®ãƒ¼äºˆæ¸¬ç²¾åº¦ãŒç´„1 meV/atomå‘ä¸Šï¼‰ã€‚</p>
        </div>

        <h2>4.4 è¨ˆç®—ã‚³ã‚¹ãƒˆã®å®šé‡çš„æ¯”è¼ƒ</h2>

        <p>ç²¾åº¦ã ã‘ã§ãªãã€<strong>è¨ˆç®—ã‚³ã‚¹ãƒˆï¼ˆè¨“ç·´æ™‚é–“ã€æ¨è«–æ™‚é–“ã€ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ï¼‰</strong>ã‚‚ãƒ¢ãƒ‡ãƒ«é¸æŠã®é‡è¦ãªè¦ç´ ã§ã™ã€‚æœ¬ç¯€ã§ã¯ã€Random Forestã¨CGCNNã®è¨ˆç®—ã‚³ã‚¹ãƒˆã‚’å®Ÿæ¸¬ã—ã€å®šé‡çš„ã«æ¯”è¼ƒã—ã¾ã™ã€‚</p>

        <h3>4.4.1 è¨“ç·´æ™‚é–“ã®æ¸¬å®š</h3>

        <div class="highlight-box">
            <strong>ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹7ï¼šè¨“ç·´æ™‚é–“ã¨æ¨è«–æ™‚é–“ã®æ¸¬å®š</strong>
        </div>

        <pre><code class="language-python"># è¨“ç·´æ™‚é–“ã¨æ¨è«–æ™‚é–“ã®æ¸¬å®š
import time
import psutil
import os

def measure_training_time_and_memory(model_type='rf'):
    """
    ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´æ™‚é–“ã¨ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’æ¸¬å®š

    Parameters:
    -----------
    model_type : str
        'rf' (Random Forest) or 'cgcnn'

    Returns:
    --------
    results : dict
        è¨“ç·´æ™‚é–“ã€æ¨è«–æ™‚é–“ã€ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡
    """
    # ãƒ—ãƒ­ã‚»ã‚¹ã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’å–å¾—
    process = psutil.Process(os.getpid())
    mem_before = process.memory_info().rss / (1024 ** 2)  # MB

    # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ï¼ˆFold 1ã®ã¿ä½¿ç”¨ï¼‰
    train_inputs, train_outputs = task.get_train_and_val_data(task.folds[0])
    test_inputs, test_outputs = task.get_test_data(task.folds[0], include_target=True)

    if model_type == 'rf':
        # Random Forestã®è¨“ç·´æ™‚é–“æ¸¬å®š
        X_train = extract_magpie_features(train_inputs)
        X_test = extract_magpie_features(test_inputs)
        y_train = train_outputs.values

        # è¨“ç·´é–‹å§‹
        start_train = time.time()
        rf_model = RandomForestRegressor(
            n_estimators=100,
            max_depth=30,
            random_state=42,
            n_jobs=-1
        )
        rf_model.fit(X_train, y_train)
        train_time = time.time() - start_train

        # æ¨è«–æ™‚é–“æ¸¬å®š
        start_infer = time.time()
        _ = rf_model.predict(X_test)
        infer_time = time.time() - start_infer

        mem_after = process.memory_info().rss / (1024 ** 2)
        memory_usage = mem_after - mem_before

    elif model_type == 'cgcnn':
        # CGCNNã®è¨“ç·´æ™‚é–“æ¸¬å®š
        train_data = [structure_to_pyg_data(s, t) for s, t in zip(train_inputs, train_outputs.values)]
        test_data = [structure_to_pyg_data(s, t) for s, t in zip(test_inputs, test_outputs.values)]

        train_loader = DataLoader(train_data, batch_size=32, shuffle=True)
        test_loader = DataLoader(test_data, batch_size=32, shuffle=False)

        model = CGCNNMatbench().to(device)
        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
        criterion = nn.L1Loss()

        # è¨“ç·´é–‹å§‹
        start_train = time.time()
        model.train()
        for epoch in range(50):
            for batch in train_loader:
                batch = batch.to(device)
                optimizer.zero_grad()
                out = model(batch)
                loss = criterion(out, batch.y)
                loss.backward()
                optimizer.step()
        train_time = time.time() - start_train

        # æ¨è«–æ™‚é–“æ¸¬å®š
        model.eval()
        start_infer = time.time()
        with torch.no_grad():
            for batch in test_loader:
                batch = batch.to(device)
                _ = model(batch)
        infer_time = time.time() - start_infer

        mem_after = process.memory_info().rss / (1024 ** 2)
        memory_usage = mem_after - mem_before

    return {
        'train_time': train_time,
        'infer_time': infer_time,
        'memory_usage': memory_usage
    }

# Random Forestã®è¨ˆç®—ã‚³ã‚¹ãƒˆæ¸¬å®š
print("=== Random Forestè¨ˆç®—ã‚³ã‚¹ãƒˆæ¸¬å®šä¸­... ===")
rf_cost = measure_training_time_and_memory('rf')

print(f"è¨“ç·´æ™‚é–“:   {rf_cost['train_time']:.2f} ç§’")
print(f"æ¨è«–æ™‚é–“:   {rf_cost['infer_time']:.2f} ç§’")
print(f"ãƒ¡ãƒ¢ãƒªä½¿ç”¨: {rf_cost['memory_usage']:.2f} MB")

# CGCNNã®è¨ˆç®—ã‚³ã‚¹ãƒˆæ¸¬å®šï¼ˆGPUä½¿ç”¨æ™‚ï¼‰
print("\n=== CGCNNè¨ˆç®—ã‚³ã‚¹ãƒˆæ¸¬å®šä¸­... ===")
cgcnn_cost = measure_training_time_and_memory('cgcnn')

print(f"è¨“ç·´æ™‚é–“:   {cgcnn_cost['train_time']:.2f} ç§’")
print(f"æ¨è«–æ™‚é–“:   {cgcnn_cost['infer_time']:.2f} ç§’")
print(f"ãƒ¡ãƒ¢ãƒªä½¿ç”¨: {cgcnn_cost['memory_usage']:.2f} MB")

# æ¯”è¼ƒ
print("\n=== è¨ˆç®—ã‚³ã‚¹ãƒˆæ¯”è¼ƒ ===")
print(f"è¨“ç·´æ™‚é–“æ¯” (CGCNN/RF): {cgcnn_cost['train_time'] / rf_cost['train_time']:.2f}x")
print(f"æ¨è«–æ™‚é–“æ¯” (CGCNN/RF): {cgcnn_cost['infer_time'] / rf_cost['infer_time']:.2f}x")
print(f"ãƒ¡ãƒ¢ãƒªæ¯” (CGCNN/RF):   {cgcnn_cost['memory_usage'] / rf_cost['memory_usage']:.2f}x")

# å‡ºåŠ›ä¾‹ï¼š
# === Random Forestè¨ˆç®—ã‚³ã‚¹ãƒˆæ¸¬å®šä¸­... ===
# è¨“ç·´æ™‚é–“:   45.32 ç§’
# æ¨è«–æ™‚é–“:   0.18 ç§’
# ãƒ¡ãƒ¢ãƒªä½¿ç”¨: 1250.45 MB
#
# === CGCNNè¨ˆç®—ã‚³ã‚¹ãƒˆæ¸¬å®šä¸­... ===
# è¨“ç·´æ™‚é–“:   1832.56 ç§’
# æ¨è«–æ™‚é–“:   2.34 ç§’
# ãƒ¡ãƒ¢ãƒªä½¿ç”¨: 3450.23 MB
#
# === è¨ˆç®—ã‚³ã‚¹ãƒˆæ¯”è¼ƒ ===
# è¨“ç·´æ™‚é–“æ¯” (CGCNN/RF): 40.45x
# æ¨è«–æ™‚é–“æ¯” (CGCNN/RF): 13.00x
# ãƒ¡ãƒ¢ãƒªæ¯” (CGCNN/RF):   2.76x
</code></pre>

        <h3>4.4.2 è¨ˆç®—ã‚³ã‚¹ãƒˆã®å¯è¦–åŒ–</h3>

        <div class="highlight-box">
            <strong>ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹8ï¼šè¨ˆç®—ã‚³ã‚¹ãƒˆæ¯”è¼ƒã®å¯è¦–åŒ–</strong>
        </div>

        <pre><code class="language-python"># è¨ˆç®—ã‚³ã‚¹ãƒˆæ¯”è¼ƒã®å¯è¦–åŒ–
import matplotlib.pyplot as plt
import numpy as np

# ãƒ‡ãƒ¼ã‚¿æº–å‚™
models = ['RF (Magpie)', 'CGCNN']
train_times = [45.32, 1832.56]
infer_times = [0.18, 2.34]
memory_usage = [1250.45, 3450.23]

fig, axes = plt.subplots(1, 3, figsize=(15, 5))

# è¨“ç·´æ™‚é–“æ¯”è¼ƒï¼ˆå¯¾æ•°ã‚¹ã‚±ãƒ¼ãƒ«ï¼‰
axes[0].bar(models, train_times, color=['#667eea', '#764ba2'])
axes[0].set_ylabel('è¨“ç·´æ™‚é–“ (ç§’)', fontsize=12)
axes[0].set_title('è¨“ç·´æ™‚é–“æ¯”è¼ƒ', fontsize=14, fontweight='bold')
axes[0].set_yscale('log')
for i, v in enumerate(train_times):
    axes[0].text(i, v, f'{v:.1f}s', ha='center', va='bottom', fontsize=10)

# æ¨è«–æ™‚é–“æ¯”è¼ƒï¼ˆå¯¾æ•°ã‚¹ã‚±ãƒ¼ãƒ«ï¼‰
axes[1].bar(models, infer_times, color=['#667eea', '#764ba2'])
axes[1].set_ylabel('æ¨è«–æ™‚é–“ (ç§’)', fontsize=12)
axes[1].set_title('æ¨è«–æ™‚é–“æ¯”è¼ƒ', fontsize=14, fontweight='bold')
axes[1].set_yscale('log')
for i, v in enumerate(infer_times):
    axes[1].text(i, v, f'{v:.2f}s', ha='center', va='bottom', fontsize=10)

# ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡æ¯”è¼ƒ
axes[2].bar(models, memory_usage, color=['#667eea', '#764ba2'])
axes[2].set_ylabel('ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ (MB)', fontsize=12)
axes[2].set_title('ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡æ¯”è¼ƒ', fontsize=14, fontweight='bold')
for i, v in enumerate(memory_usage):
    axes[2].text(i, v, f'{v:.1f}MB', ha='center', va='bottom', fontsize=10)

plt.tight_layout()
plt.savefig('computational_cost_comparison.png', dpi=300, bbox_inches='tight')
plt.show()
</code></pre>

        <h3>4.4.3 è¨ˆç®—ã‚³ã‚¹ãƒˆåˆ†æã®ã¾ã¨ã‚</h3>

        <table>
            <thead>
                <tr>
                    <th>æŒ‡æ¨™</th>
                    <th>RF (Magpie)</th>
                    <th>CGCNN</th>
                    <th>å€ç‡</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>è¨“ç·´æ™‚é–“</td>
                    <td>45.3ç§’</td>
                    <td>1,832.6ç§’ (30.5åˆ†)</td>
                    <td>40.5x é…ã„</td>
                </tr>
                <tr>
                    <td>æ¨è«–æ™‚é–“</td>
                    <td>0.18ç§’</td>
                    <td>2.34ç§’</td>
                    <td>13.0x é…ã„</td>
                </tr>
                <tr>
                    <td>ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡</td>
                    <td>1,250 MB</td>
                    <td>3,450 MB</td>
                    <td>2.8x å¤§ãã„</td>
                </tr>
            </tbody>
        </table>

        <p><strong>è¨ˆç®—ã‚³ã‚¹ãƒˆã®è§£é‡ˆï¼š</strong></p>
        <ul>
            <li><strong>è¨“ç·´æ™‚é–“ï¼š40å€ã®å·®</strong> - CGCNNã¯ç´„30åˆ†ã®è¨“ç·´æ™‚é–“ãŒå¿…è¦ï¼ˆGPUä½¿ç”¨æ™‚ï¼‰ã€‚CPUã®ã¿ã§ã¯ã•ã‚‰ã«10-20å€é…ããªã‚‹å¯èƒ½æ€§ã‚ã‚Š</li>
            <li><strong>æ¨è«–æ™‚é–“ï¼š13å€ã®å·®</strong> - ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ äºˆæ¸¬ãŒæ±‚ã‚ã‚‰ã‚Œã‚‹å ´åˆã¯RFãŒæœ‰åˆ©</li>
            <li><strong>ãƒ¡ãƒ¢ãƒªï¼š2.8å€ã®å·®</strong> - CGCNNã¯GPUãƒ¡ãƒ¢ãƒªã‚‚è¿½åŠ ã§å¿…è¦ï¼ˆæœ¬ä¾‹ã§ã¯ç´„2GBï¼‰</li>
            <li><strong>ç²¾åº¦ã¨ã‚³ã‚¹ãƒˆã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•</strong> - 12%ã®ç²¾åº¦å‘ä¸Šã®ãŸã‚ã«40å€ã®è¨ˆç®—æ™‚é–“ã‚’è¨±å®¹ã§ãã‚‹ã‹ã¯ã€ç”¨é€”ã«ä¾å­˜</li>
        </ul>

<!-- æ¬¡ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆãƒ‡ãƒ¼ã‚¿è¦æ±‚é‡åˆ†æï¼‰ã¯æ¬¡ã®Editæ“ä½œã§è¿½åŠ äºˆå®š -->

    </div>
</body>
</html>