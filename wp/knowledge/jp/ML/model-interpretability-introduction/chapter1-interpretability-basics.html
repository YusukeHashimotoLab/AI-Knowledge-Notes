<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ç¬¬1ç« ï¼šãƒ¢ãƒ‡ãƒ«è§£é‡ˆæ€§åŸºç¤ - AI Terakoya</title>

    <style>
        :root {
            --color-primary: #2c3e50;
            --color-primary-dark: #1a252f;
            --color-accent: #7b2cbf;
            --color-accent-light: #9d4edd;
            --color-text: #2d3748;
            --color-text-light: #4a5568;
            --color-bg: #ffffff;
            --color-bg-alt: #f7fafc;
            --color-border: #e2e8f0;
            --color-code-bg: #f8f9fa;
            --color-link: #3182ce;
            --color-link-hover: #2c5aa0;

            --spacing-xs: 0.5rem;
            --spacing-sm: 1rem;
            --spacing-md: 1.5rem;
            --spacing-lg: 2rem;
            --spacing-xl: 3rem;

            --font-body: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            --font-mono: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;

            --border-radius: 8px;
            --box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: var(--font-body);
            line-height: 1.7;
            color: var(--color-text);
            background-color: var(--color-bg);
            font-size: 16px;
        }

        header {
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            padding: var(--spacing-xl) var(--spacing-md);
            margin-bottom: var(--spacing-xl);
            box-shadow: var(--box-shadow);
        }

        .header-content {
            max-width: 900px;
            margin: 0 auto;
        }

        h1 {
            font-size: 2rem;
            font-weight: 700;
            margin-bottom: var(--spacing-sm);
            line-height: 1.2;
        }

        .subtitle {
            font-size: 1.1rem;
            opacity: 0.95;
            font-weight: 400;
            margin-bottom: var(--spacing-md);
        }

        .meta {
            display: flex;
            flex-wrap: wrap;
            gap: var(--spacing-md);
            font-size: 0.9rem;
            opacity: 0.9;
        }

        .meta-item {
            display: flex;
            align-items: center;
            gap: 0.3rem;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 0 var(--spacing-md) var(--spacing-xl);
        }

        h2 {
            font-size: 1.75rem;
            color: var(--color-primary);
            margin-top: var(--spacing-xl);
            margin-bottom: var(--spacing-md);
            padding-bottom: var(--spacing-xs);
            border-bottom: 3px solid var(--color-accent);
        }

        h3 {
            font-size: 1.4rem;
            color: var(--color-primary);
            margin-top: var(--spacing-lg);
            margin-bottom: var(--spacing-sm);
        }

        h4 {
            font-size: 1.1rem;
            color: var(--color-primary-dark);
            margin-top: var(--spacing-md);
            margin-bottom: var(--spacing-sm);
        }

        p {
            margin-bottom: var(--spacing-md);
            color: var(--color-text);
        }

        a {
            color: var(--color-link);
            text-decoration: none;
            transition: color 0.2s;
        }

        a:hover {
            color: var(--color-link-hover);
            text-decoration: underline;
        }

        ul, ol {
            margin-left: var(--spacing-lg);
            margin-bottom: var(--spacing-md);
        }

        li {
            margin-bottom: var(--spacing-xs);
            color: var(--color-text);
        }

        pre {
            background-color: var(--color-code-bg);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            overflow-x: auto;
            margin-bottom: var(--spacing-md);
            font-family: var(--font-mono);
            font-size: 0.9rem;
            line-height: 1.5;
        }

        code {
            font-family: var(--font-mono);
            font-size: 0.9em;
            background-color: var(--color-code-bg);
            padding: 0.2em 0.4em;
            border-radius: 3px;
        }

        pre code {
            background-color: transparent;
            padding: 0;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: var(--spacing-md);
            font-size: 0.95rem;
        }

        th, td {
            border: 1px solid var(--color-border);
            padding: var(--spacing-sm);
            text-align: left;
        }

        th {
            background-color: var(--color-bg-alt);
            font-weight: 600;
            color: var(--color-primary);
        }

        blockquote {
            border-left: 4px solid var(--color-accent);
            padding-left: var(--spacing-md);
            margin: var(--spacing-md) 0;
            color: var(--color-text-light);
            font-style: italic;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        .mermaid {
            text-align: center;
            margin: var(--spacing-lg) 0;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        details {
            background-color: var(--color-bg-alt);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            margin-bottom: var(--spacing-md);
        }

        summary {
            cursor: pointer;
            font-weight: 600;
            color: var(--color-primary);
            user-select: none;
            padding: var(--spacing-xs);
            margin: calc(-1 * var(--spacing-md));
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        summary:hover {
            background-color: rgba(123, 44, 191, 0.1);
        }

        details[open] summary {
            margin-bottom: var(--spacing-md);
            border-bottom: 1px solid var(--color-border);
        }

        .navigation {
            display: flex;
            justify-content: space-between;
            gap: var(--spacing-md);
            margin: var(--spacing-xl) 0;
            padding-top: var(--spacing-lg);
            border-top: 2px solid var(--color-border);
        }

        .nav-button {
            flex: 1;
            padding: var(--spacing-md);
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            border-radius: var(--border-radius);
            text-align: center;
            font-weight: 600;
            transition: transform 0.2s, box-shadow 0.2s;
            box-shadow: var(--box-shadow);
        }

        .nav-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
            text-decoration: none;
        }

        footer {
            margin-top: var(--spacing-xl);
            padding: var(--spacing-lg) var(--spacing-md);
            background-color: var(--color-bg-alt);
            border-top: 1px solid var(--color-border);
            text-align: center;
            font-size: 0.9rem;
            color: var(--color-text-light);
        }
        .disclaimer {
            max-width: 900px;
            margin: 2rem auto;
            padding: 1.5rem;
            background: #f8f9fa;
            border-left: 4px solid #6c757d;
            border-radius: 4px;
        }

        .disclaimer h3 {
            color: #495057;
            margin-bottom: 1rem;
            font-size: 1.1rem;
        }

        .disclaimer ul {
            list-style: none;
            padding-left: 0;
        }

        .disclaimer li {
            padding: 0.5rem 0;
            padding-left: 1.5rem;
            position: relative;
            font-size: 0.9rem;
            color: #6c757d;
            line-height: 1.6;
        }

        .disclaimer li::before {
            content: "âš ï¸";
            position: absolute;
            left: 0;
        }


        @media (max-width: 768px) {
            h1 {
                font-size: 1.5rem;
            }

            h2 {
                font-size: 1.4rem;
            }

            h3 {
                font-size: 1.2rem;
            }

            .meta {
                font-size: 0.85rem;
            }

            .navigation {
                flex-direction: column;
            }

            table {
                font-size: 0.85rem;
            }

            th, td {
                padding: var(--spacing-xs);
            }
        }
    
        
    
        /* Breadcrumb styles */
        .breadcrumb {
            background: #f7fafc;
            padding: 0.75rem 1rem;
            border-bottom: 1px solid #e2e8f0;
            font-size: 0.9rem;
        }

        .breadcrumb-content {
            max-width: 900px;
            margin: 0 auto;
            display: flex;
            align-items: center;
            flex-wrap: wrap;
            gap: 0.5rem;
        }

        .breadcrumb a {
            color: #667eea;
            text-decoration: none;
            transition: color 0.2s;
        }

        .breadcrumb a:hover {
            color: #764ba2;
            text-decoration: underline;
        }

        .breadcrumb-separator {
            color: #a0aec0;
            margin: 0 0.25rem;
        }

        .breadcrumb-current {
            color: #4a5568;
            font-weight: 500;
        }
    </style>

    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
        mermaid.initialize({ startOnLoad: true, theme: 'default' });
    </script>

    <!-- MathJax for LaTeX equation rendering -->
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                displayMath: [['$$', '$$'], ['\\[', '\\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
                ignoreHtmlClass: 'mermaid'
            }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" async></script>
</head>
<body>
            <nav class="breadcrumb">
        <div class="breadcrumb-content">
            <a href="/AI-Knowledge-Notes/knowledge/jp/index.html">AIå¯ºå­å±‹ãƒˆãƒƒãƒ—</a><span class="breadcrumb-separator">â€º</span><a href="/AI-Knowledge-Notes/knowledge/jp/ML/index.html">æ©Ÿæ¢°å­¦ç¿’</a><span class="breadcrumb-separator">â€º</span><a href="/AI-Knowledge-Notes/knowledge/jp/ML/model-interpretability-introduction/index.html">Model Interpretability</a><span class="breadcrumb-separator">â€º</span><span class="breadcrumb-current">Chapter 1</span>
        </div>
    </nav>

        <header>
        <div class="header-content">
            <h1>ç¬¬1ç« ï¼šãƒ¢ãƒ‡ãƒ«è§£é‡ˆæ€§åŸºç¤</h1>
            <p class="subtitle">ä¿¡é ¼ã§ãã‚‹AIã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ã™ã‚‹ãŸã‚ã®è§£é‡ˆæ€§ã®ç†è§£</p>
            <div class="meta">
                <span class="meta-item">ğŸ“– èª­äº†æ™‚é–“: 30-35åˆ†</span>
                <span class="meta-item">ğŸ“Š é›£æ˜“åº¦: åˆç´š</span>
                <span class="meta-item">ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹: 8å€‹</span>
                <span class="meta-item">ğŸ“ æ¼”ç¿’å•é¡Œ: 6å•</span>
            </div>
        </div>
    </header>

    <main class="container">

<h2>å­¦ç¿’ç›®æ¨™</h2>
<p>ã“ã®ç« ã‚’èª­ã‚€ã“ã¨ã§ã€ä»¥ä¸‹ã‚’ç¿’å¾—ã§ãã¾ã™ï¼š</p>
<ul>
<li>âœ… ãƒ¢ãƒ‡ãƒ«è§£é‡ˆæ€§ãŒé‡è¦ãªç†ç”±ã‚’ç†è§£ã™ã‚‹</li>
<li>âœ… è§£é‡ˆæ€§ã®åˆ†é¡ä½“ç³»ã‚’æŠŠæ¡ã™ã‚‹</li>
<li>âœ… è§£é‡ˆå¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã®ç‰¹å¾´ã‚’çŸ¥ã‚‹</li>
<li>âœ… ä¸»è¦ãªè§£é‡ˆæ‰‹æ³•ã®æ¦‚è¦ã‚’ç†è§£ã™ã‚‹</li>
<li>âœ… è§£é‡ˆæ€§ã‚’è©•ä¾¡ã™ã‚‹åŸºæº–ã‚’å­¦ã¶</li>
<li>âœ… å®Ÿè·µçš„ãªè§£é‡ˆå¯èƒ½ãƒ¢ãƒ‡ãƒ«ã‚’å®Ÿè£…ã§ãã‚‹</li>
</ul>

<hr>

<h2>1.1 ãªãœãƒ¢ãƒ‡ãƒ«è§£é‡ˆæ€§ãŒé‡è¦ã‹</h2>

<h3>ä¿¡é ¼æ€§ã¨èª¬æ˜è²¬ä»»</h3>

<p>æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬ã‚’ä¿¡é ¼ã™ã‚‹ãŸã‚ã«ã¯ã€ã€Œãªãœãã®äºˆæ¸¬ã«è‡³ã£ãŸã®ã‹ã€ã‚’ç†è§£ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ç‰¹ã«é«˜ãƒªã‚¹ã‚¯ãªæ„æ€æ±ºå®šï¼ˆåŒ»ç™‚è¨ºæ–­ã€èè³‡å¯©æŸ»ã€åˆ‘äº‹å¸æ³•ãªã©ï¼‰ã§ã¯ã€èª¬æ˜è²¬ä»»ãŒä¸å¯æ¬ ã§ã™ã€‚</p>

<table>
<thead>
<tr>
<th>é©ç”¨é ˜åŸŸ</th>
<th>è§£é‡ˆæ€§ãŒå¿…è¦ãªç†ç”±</th>
<th>ãƒªã‚¹ã‚¯</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>åŒ»ç™‚è¨ºæ–­</strong></td>
<td>åŒ»å¸«ãŒè¨ºæ–­æ ¹æ‹ ã‚’ç†è§£ã—ã€æ‚£è€…ã«èª¬æ˜ã™ã‚‹å¿…è¦ãŒã‚ã‚‹</td>
<td>èª¤è¨ºã«ã‚ˆã‚‹ç”Ÿå‘½ã®å±é™º</td>
</tr>
<tr>
<td><strong>èè³‡å¯©æŸ»</strong></td>
<td>æ‹’å¦ç†ç”±ã®èª¬æ˜ç¾©å‹™ã€å…¬æ­£æ€§ã®ç¢ºä¿</td>
<td>å·®åˆ¥çš„ãªåˆ¤æ–­ã€æ³•çš„è¨´è¨Ÿ</td>
</tr>
<tr>
<td><strong>åˆ‘äº‹å¸æ³•</strong></td>
<td>å†çŠ¯ãƒªã‚¹ã‚¯è©•ä¾¡ã®æ ¹æ‹ ã‚’ç¤ºã™å¿…è¦ãŒã‚ã‚‹</td>
<td>ä¸å½“ãªåˆ¤æ±ºã€äººæ¨©ä¾µå®³</td>
</tr>
<tr>
<td><strong>è‡ªå‹•é‹è»¢</strong></td>
<td>äº‹æ•…æ™‚ã®è²¬ä»»è¿½åŠã€å®‰å…¨æ€§ã®æ¤œè¨¼</td>
<td>äººå‘½æå¤±ã€æ³•çš„è²¬ä»»</td>
</tr>
</tbody>
</table>

<blockquote>
<p><strong>é‡è¦</strong>: ã€Œäºˆæ¸¬ç²¾åº¦ãŒé«˜ã„ã€ã ã‘ã§ã¯ä¸ååˆ†ã§ã™ã€‚ã‚¹ãƒ†ãƒ¼ã‚¯ãƒ›ãƒ«ãƒ€ãƒ¼ãŒãƒ¢ãƒ‡ãƒ«ã‚’ä¿¡é ¼ã—ã€é©åˆ‡ã«åˆ©ç”¨ã™ã‚‹ã«ã¯ã€äºˆæ¸¬ã®æ ¹æ‹ ã‚’ç†è§£ã§ãã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚</p>
</blockquote>

<h3>è¦åˆ¶è¦ä»¶ï¼ˆGDPRã€AIè¦åˆ¶ï¼‰</h3>

<p>ä¸–ç•Œä¸­ã§æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®é€æ˜æ€§ã«é–¢ã™ã‚‹è¦åˆ¶ãŒå¼·åŒ–ã•ã‚Œã¦ã„ã¾ã™ï¼š</p>

<ul>
<li><strong>GDPRï¼ˆæ¬§å·ä¸€èˆ¬ãƒ‡ãƒ¼ã‚¿ä¿è­·è¦å‰‡ï¼‰</strong>: è‡ªå‹•åŒ–ã•ã‚ŒãŸæ„æ€æ±ºå®šã«é–¢ã™ã‚‹ã€Œèª¬æ˜ã‚’å—ã‘ã‚‹æ¨©åˆ©ã€ã‚’è¦å®šï¼ˆç¬¬22æ¡ï¼‰</li>
<li><strong>EU AI Act</strong>: é«˜ãƒªã‚¹ã‚¯AIã‚·ã‚¹ãƒ†ãƒ ã«å¯¾ã™ã‚‹é€æ˜æ€§ã¨èª¬æ˜å¯èƒ½æ€§ã®è¦ä»¶</li>
<li><strong>ç±³å›½å…¬æ­£ä¿¡ç”¨å ±å‘Šæ³•</strong>: ä¿¡ç”¨ã‚¹ã‚³ã‚¢ã«é–¢ã™ã‚‹ã€Œä¸åˆ©ãªæªç½®ã®é€šçŸ¥ã€ç¾©å‹™</li>
<li><strong>æ—¥æœ¬ã®å€‹äººæƒ…å ±ä¿è­·æ³•</strong>: è‡ªå‹•åŒ–ã•ã‚ŒãŸæ„æ€æ±ºå®šã«é–¢ã™ã‚‹æœ¬äººã¸ã®æƒ…å ±æä¾›</li>
</ul>

<h3>ãƒ‡ãƒãƒƒã‚°ã¨ãƒ¢ãƒ‡ãƒ«æ”¹å–„</h3>

<p>è§£é‡ˆæ€§ã¯ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½å‘ä¸Šã«ã‚‚ä¸å¯æ¬ ã§ã™ï¼š</p>

<pre><code class="language-python">"""
ä¾‹: ãƒ¢ãƒ‡ãƒ«ãŒäºˆæœŸã—ãªã„äºˆæ¸¬ã‚’ã™ã‚‹å ´åˆã®è¨ºæ–­

å•é¡Œ: é¡§å®¢ã®é›¢åäºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ãŒå®Ÿé‹ç”¨ã§æ€§èƒ½ãŒä½ã„
"""

import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split

# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
np.random.seed(42)
n_samples = 1000

data = pd.DataFrame({
    'age': np.random.randint(18, 80, n_samples),
    'tenure_months': np.random.randint(1, 120, n_samples),
    'monthly_charges': np.random.uniform(20, 150, n_samples),
    'total_charges': np.random.uniform(100, 10000, n_samples),
    'num_support_calls': np.random.poisson(2, n_samples),
    'contract_type': np.random.choice(['month', 'year', '2year'], n_samples),
    'customer_id': np.arange(n_samples)  # ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯ï¼
})

# ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤‰æ•°ï¼ˆé›¢åï¼‰
data['churn'] = ((data['num_support_calls'] > 3) |
                 (data['monthly_charges'] > 100)).astype(int)

# ãƒ¢ãƒ‡ãƒ«è¨“ç·´
X = data.drop('churn', axis=1)
X_encoded = pd.get_dummies(X, columns=['contract_type'])
y = data['churn']

X_train, X_test, y_train, y_test = train_test_split(
    X_encoded, y, test_size=0.2, random_state=42
)

model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# Feature Importanceã§è¨ºæ–­
feature_importance = pd.DataFrame({
    'feature': X_encoded.columns,
    'importance': model.feature_importances_
}).sort_values('importance', ascending=False)

print("Feature Importance:")
print(feature_importance.head(10))

# å•é¡Œç™ºè¦‹: customer_idãŒæœ€ã‚‚é‡è¦ãªç‰¹å¾´é‡ã«ãªã£ã¦ã„ã‚‹ï¼ˆãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯ï¼‰
print("\nâš ï¸ customer_idã®é‡è¦åº¦ãŒç•°å¸¸ã«é«˜ã„ â†’ ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯ã®å¯èƒ½æ€§")
</code></pre>

<h3>ãƒã‚¤ã‚¢ã‚¹æ¤œå‡º</h3>

<p>è§£é‡ˆæ€§ã«ã‚ˆã‚Šã€ãƒ¢ãƒ‡ãƒ«ãŒå­¦ç¿’ã—ãŸä¸å…¬å¹³ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç™ºè¦‹ã§ãã¾ã™ï¼š</p>

<pre><code class="language-python">"""
ä¾‹: æ¡ç”¨ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«ã®ãƒã‚¤ã‚¢ã‚¹æ¤œå‡º
"""

import numpy as np
import pandas as pd
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler

# ãƒã‚¤ã‚¢ã‚¹ã®ã‚ã‚‹ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿
np.random.seed(42)
n_samples = 1000

data = pd.DataFrame({
    'years_experience': np.random.randint(0, 20, n_samples),
    'education_level': np.random.randint(1, 5, n_samples),
    'skills_score': np.random.uniform(0, 100, n_samples),
    'gender': np.random.choice(['M', 'F'], n_samples),
    'age': np.random.randint(22, 65, n_samples)
})

# ãƒã‚¤ã‚¢ã‚¹ã®ã‚ã‚‹ã‚¿ãƒ¼ã‚²ãƒƒãƒˆï¼ˆæ€§åˆ¥ã«ã‚ˆã‚‹å·®åˆ¥ãŒå«ã¾ã‚Œã‚‹ï¼‰
data['hired'] = (
    (data['years_experience'] > 5) &
    (data['skills_score'] > 60) &
    (data['gender'] == 'M')  # æ€§åˆ¥ãƒã‚¤ã‚¢ã‚¹
).astype(int)

# ãƒ¢ãƒ‡ãƒ«è¨“ç·´
X = pd.get_dummies(data.drop('hired', axis=1), columns=['gender'])
y = data['hired']

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

model = LogisticRegression(random_state=42)
model.fit(X_scaled, y)

# ä¿‚æ•°ã‚’ç¢ºèªã—ã¦ãƒã‚¤ã‚¢ã‚¹ã‚’æ¤œå‡º
coefficients = pd.DataFrame({
    'feature': X.columns,
    'coefficient': model.coef_[0]
}).sort_values('coefficient', ascending=False)

print("Model Coefficients:")
print(coefficients)

# gender_Mã®ä¿‚æ•°ãŒç•°å¸¸ã«é«˜ã„ â†’ æ€§åˆ¥ãƒã‚¤ã‚¢ã‚¹ã‚’æ¤œå‡º
print("\nâš ï¸ gender_Mã®ä¿‚æ•°ãŒé«˜ã„ â†’ æ€§åˆ¥ã«ã‚ˆã‚‹å·®åˆ¥ã®å¯èƒ½æ€§")
print("ğŸ“Š å…¬æ­£æ€§ã®è©•ä¾¡ãŒå¿…è¦")
</code></pre>

<hr>

<h2>1.2 è§£é‡ˆæ€§ã®åˆ†é¡</h2>

<h3>ã‚°ãƒ­ãƒ¼ãƒãƒ«è§£é‡ˆ vs ãƒ­ãƒ¼ã‚«ãƒ«è§£é‡ˆ</h3>

<table>
<thead>
<tr>
<th>åˆ†é¡</th>
<th>èª¬æ˜</th>
<th>è³ªå•</th>
<th>æ‰‹æ³•ä¾‹</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>ã‚°ãƒ­ãƒ¼ãƒãƒ«è§£é‡ˆ</strong></td>
<td>ãƒ¢ãƒ‡ãƒ«å…¨ä½“ã®æŒ¯ã‚‹èˆã„ã‚’ç†è§£</td>
<td>ã€Œãƒ¢ãƒ‡ãƒ«ã¯ä¸€èˆ¬çš„ã«ã©ã†äºˆæ¸¬ã™ã‚‹ã‹ï¼Ÿã€</td>
<td>Feature Importance, Partial Dependence</td>
</tr>
<tr>
<td><strong>ãƒ­ãƒ¼ã‚«ãƒ«è§£é‡ˆ</strong></td>
<td>å€‹åˆ¥ã®äºˆæ¸¬ã‚’èª¬æ˜</td>
<td>ã€Œãªãœã“ã®é¡§å®¢ã¯é›¢åã™ã‚‹ã¨äºˆæ¸¬ã•ã‚ŒãŸã‹ï¼Ÿã€</td>
<td>LIME, SHAP, Counterfactual</td>
</tr>
</tbody>
</table>

<pre><code class="language-python">"""
ä¾‹: ã‚°ãƒ­ãƒ¼ãƒãƒ«è§£é‡ˆ vs ãƒ­ãƒ¼ã‚«ãƒ«è§£é‡ˆ
"""

import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
np.random.seed(42)
n_samples = 500

data = pd.DataFrame({
    'age': np.random.randint(18, 70, n_samples),
    'income': np.random.uniform(20000, 150000, n_samples),
    'debt_ratio': np.random.uniform(0, 1, n_samples),
    'credit_history_months': np.random.randint(0, 360, n_samples)
})

# ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ: ãƒ­ãƒ¼ãƒ³æ‰¿èª
data['approved'] = (
    (data['income'] > 50000) &
    (data['debt_ratio'] < 0.5) &
    (data['credit_history_months'] > 24)
).astype(int)

X = data.drop('approved', axis=1)
y = data['approved']

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

model = RandomForestClassifier(n_estimators=50, random_state=42)
model.fit(X_train, y_train)

# --- ã‚°ãƒ­ãƒ¼ãƒãƒ«è§£é‡ˆ: Feature Importance ---
print("=== ã‚°ãƒ­ãƒ¼ãƒãƒ«è§£é‡ˆ ===")
print("ãƒ¢ãƒ‡ãƒ«å…¨ä½“ã§æœ€ã‚‚é‡è¦ãªç‰¹å¾´é‡:")
feature_importance = pd.DataFrame({
    'feature': X.columns,
    'importance': model.feature_importances_
}).sort_values('importance', ascending=False)
print(feature_importance)

# --- ãƒ­ãƒ¼ã‚«ãƒ«è§£é‡ˆ: å€‹åˆ¥ã®äºˆæ¸¬èª¬æ˜ ---
print("\n=== ãƒ­ãƒ¼ã‚«ãƒ«è§£é‡ˆ ===")
# ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‹ã‚‰1ã‚µãƒ³ãƒ—ãƒ«é¸æŠ
sample_idx = 0
sample = X_test.iloc[sample_idx:sample_idx+1]
prediction = model.predict(sample)[0]
prediction_proba = model.predict_proba(sample)[0]

print(f"ã‚µãƒ³ãƒ—ãƒ« {sample_idx} ã®ç‰¹å¾´:")
print(sample.T)
print(f"\näºˆæ¸¬: {'æ‰¿èª' if prediction == 1 else 'å´ä¸‹'}")
print(f"ç¢ºç‡: {prediction_proba[1]:.2%}")

# ç°¡æ˜“çš„ãªãƒ­ãƒ¼ã‚«ãƒ«é‡è¦åº¦ï¼ˆãƒ„ãƒªãƒ¼ãƒ™ãƒ¼ã‚¹ï¼‰
# å®Ÿéš›ã«ã¯SHAPã‚„LIMEã‚’ä½¿ç”¨ã™ã‚‹ã®ãŒæœ›ã¾ã—ã„
print("\nã“ã®äºˆæ¸¬ã«å¯„ä¸ã—ãŸç‰¹å¾´ï¼ˆæ¦‚ç®—ï¼‰:")
for feature in X.columns:
    print(f"  {feature}: {sample[feature].values[0]:.2f}")
</code></pre>

<h3>ãƒ¢ãƒ‡ãƒ«å›ºæœ‰ vs ãƒ¢ãƒ‡ãƒ«éä¾å­˜</h3>

<table>
<thead>
<tr>
<th>åˆ†é¡</th>
<th>èª¬æ˜</th>
<th>åˆ©ç‚¹</th>
<th>æ¬ ç‚¹</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>ãƒ¢ãƒ‡ãƒ«å›ºæœ‰</strong></td>
<td>ç‰¹å®šã®ãƒ¢ãƒ‡ãƒ«ã«ç‰¹åŒ–ã—ãŸè§£é‡ˆ</td>
<td>æ­£ç¢ºã€åŠ¹ç‡çš„</td>
<td>ä»–ã®ãƒ¢ãƒ‡ãƒ«ã«é©ç”¨ã§ããªã„</td>
</tr>
<tr>
<td><strong>ãƒ¢ãƒ‡ãƒ«éä¾å­˜</strong></td>
<td>ã©ã®ãƒ¢ãƒ‡ãƒ«ã«ã‚‚é©ç”¨å¯èƒ½</td>
<td>æ±ç”¨æ€§ãŒé«˜ã„</td>
<td>è¨ˆç®—ã‚³ã‚¹ãƒˆãŒé«˜ã„å ´åˆãŒã‚ã‚‹</td>
</tr>
</tbody>
</table>

<h3>äº‹å‰è§£é‡ˆæ€§ vs äº‹å¾Œè§£é‡ˆæ€§</h3>

<ul>
<li><strong>äº‹å‰è§£é‡ˆæ€§ï¼ˆIntrinsic Interpretabilityï¼‰</strong>: ãƒ¢ãƒ‡ãƒ«è‡ªä½“ãŒè§£é‡ˆå¯èƒ½ï¼ˆç·šå½¢å›å¸°ã€æ±ºå®šæœ¨ï¼‰</li>
<li><strong>äº‹å¾Œè§£é‡ˆæ€§ï¼ˆPost-hoc Interpretabilityï¼‰</strong>: ãƒ–ãƒ©ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ãƒ¢ãƒ‡ãƒ«ã‚’å¾Œã‹ã‚‰è§£é‡ˆï¼ˆSHAPã€LIMEï¼‰</li>
</ul>

<h3>è§£é‡ˆæ€§ã®åˆ†é¡ä½“ç³»</h3>

<div class="mermaid">
graph TB
    A[ãƒ¢ãƒ‡ãƒ«è§£é‡ˆæ€§] --> B[ã‚¹ã‚³ãƒ¼ãƒ—]
    A --> C[ä¾å­˜æ€§]
    A --> D[ã‚¿ã‚¤ãƒŸãƒ³ã‚°]

    B --> B1[ã‚°ãƒ­ãƒ¼ãƒãƒ«è§£é‡ˆ<br/>ãƒ¢ãƒ‡ãƒ«å…¨ä½“ã®æŒ¯ã‚‹èˆã„]
    B --> B2[ãƒ­ãƒ¼ã‚«ãƒ«è§£é‡ˆ<br/>å€‹åˆ¥äºˆæ¸¬ã®èª¬æ˜]

    C --> C1[ãƒ¢ãƒ‡ãƒ«å›ºæœ‰<br/>ç‰¹å®šãƒ¢ãƒ‡ãƒ«ç”¨]
    C --> C2[ãƒ¢ãƒ‡ãƒ«éä¾å­˜<br/>æ±ç”¨çš„]

    D --> D1[äº‹å‰è§£é‡ˆæ€§<br/>æœ¬è³ªçš„ã«è§£é‡ˆå¯èƒ½]
    D --> D2[äº‹å¾Œè§£é‡ˆæ€§<br/>å¾Œä»˜ã‘èª¬æ˜]

    style A fill:#7b2cbf,color:#fff
    style B1 fill:#e3f2fd
    style B2 fill:#e3f2fd
    style C1 fill:#fff3e0
    style C2 fill:#fff3e0
    style D1 fill:#c8e6c9
    style D2 fill:#c8e6c9
</div>

<hr>

<h2>1.3 è§£é‡ˆå¯èƒ½ãªãƒ¢ãƒ‡ãƒ«</h2>

<h3>ç·šå½¢å›å¸°</h3>

<p>ç·šå½¢å›å¸°ã¯æœ€ã‚‚è§£é‡ˆã—ã‚„ã™ã„ãƒ¢ãƒ‡ãƒ«ã®ä¸€ã¤ã§ã™ã€‚å„ç‰¹å¾´é‡ã®ä¿‚æ•°ãŒç›´æ¥çš„ã«å½±éŸ¿ã‚’ç¤ºã—ã¾ã™ã€‚</p>

<p><strong>æ•°å¼</strong>:</p>
<p>$$y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \cdots + \beta_n x_n$$</p>

<p>$\beta_i$ ã¯ç‰¹å¾´é‡ $x_i$ ã®1å˜ä½å¤‰åŒ–ã«å¯¾ã™ã‚‹äºˆæ¸¬å€¤ã®å¤‰åŒ–é‡ã‚’ç¤ºã—ã¾ã™ã€‚</p>

<pre><code class="language-python">"""
ä¾‹: ç·šå½¢å›å¸°ã«ã‚ˆã‚‹ä½å®…ä¾¡æ ¼äºˆæ¸¬
"""

import numpy as np
import pandas as pd
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
np.random.seed(42)
n_samples = 200

data = pd.DataFrame({
    'square_feet': np.random.randint(500, 4000, n_samples),
    'bedrooms': np.random.randint(1, 6, n_samples),
    'age_years': np.random.randint(0, 50, n_samples),
    'distance_to_city': np.random.uniform(0, 50, n_samples)
})

# ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ: ä¾¡æ ¼ï¼ˆä¸‡å††ï¼‰
data['price'] = (
    data['square_feet'] * 0.5 +
    data['bedrooms'] * 50 -
    data['age_years'] * 5 -
    data['distance_to_city'] * 10 +
    np.random.normal(0, 100, n_samples)
)

X = data.drop('price', axis=1)
y = data['price']

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# æ¨™æº–åŒ–ï¼ˆä¿‚æ•°ã®æ¯”è¼ƒã®ãŸã‚ï¼‰
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# ãƒ¢ãƒ‡ãƒ«è¨“ç·´
model = LinearRegression()
model.fit(X_train_scaled, y_train)

# ä¿‚æ•°ã®è§£é‡ˆ
coefficients = pd.DataFrame({
    'feature': X.columns,
    'coefficient': model.coef_,
    'abs_coefficient': np.abs(model.coef_)
}).sort_values('abs_coefficient', ascending=False)

print("ç·šå½¢å›å¸°ãƒ¢ãƒ‡ãƒ«ã®ä¿‚æ•°:")
print(coefficients)
print(f"\nåˆ‡ç‰‡: {model.intercept_:.2f}")

print("\nè§£é‡ˆ:")
print("- square_feet ã®ä¿‚æ•°ãŒæœ€ã‚‚å¤§ãã„ â†’ é¢ç©ãŒä¾¡æ ¼ã«æœ€ã‚‚å½±éŸ¿")
print("- age_years ã®ä¿‚æ•°ãŒè²  â†’ ç¯‰å¹´æ•°ãŒå¤ã„ã»ã©ä¾¡æ ¼ãŒä½ã„")
print("- ä¿‚æ•°ãŒæ¨™æº–åŒ–ã•ã‚Œã¦ã„ã‚‹ãŸã‚ã€ç›´æ¥æ¯”è¼ƒå¯èƒ½")

# äºˆæ¸¬ä¾‹
sample = X_test_scaled[0:1]
prediction = model.predict(sample)[0]
print(f"\nã‚µãƒ³ãƒ—ãƒ«äºˆæ¸¬ä¾¡æ ¼: {prediction:.2f}ä¸‡å††")
</code></pre>

<h3>æ±ºå®šæœ¨</h3>

<p>æ±ºå®šæœ¨ã¯äººé–“ãŒç†è§£ã—ã‚„ã™ã„ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã®åˆ†å²æ§‹é€ ã‚’æŒã¡ã¾ã™ã€‚</p>

<pre><code class="language-python">"""
ä¾‹: æ±ºå®šæœ¨ã«ã‚ˆã‚‹ã‚¢ã‚¤ãƒªã‚¹åˆ†é¡
"""

import numpy as np
import pandas as pd
from sklearn.datasets import load_iris
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
iris = load_iris()
X = pd.DataFrame(iris.data, columns=iris.feature_names)
y = iris.target

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# æ±ºå®šæœ¨ãƒ¢ãƒ‡ãƒ«ï¼ˆæ·±ã•ã‚’åˆ¶é™ã—ã¦è§£é‡ˆã—ã‚„ã™ãï¼‰
model = DecisionTreeClassifier(max_depth=3, random_state=42)
model.fit(X_train, y_train)

# ç²¾åº¦
accuracy = model.score(X_test, y_test)
print(f"ç²¾åº¦: {accuracy:.2%}")

# ãƒ«ãƒ¼ãƒ«ã®æŠ½å‡ºï¼ˆãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ï¼‰
from sklearn.tree import export_text
tree_rules = export_text(model, feature_names=list(iris.feature_names))
print("\næ±ºå®šæœ¨ã®ãƒ«ãƒ¼ãƒ«:")
print(tree_rules[:500] + "...")  # æœ€åˆã®500æ–‡å­—ã®ã¿è¡¨ç¤º

# è§£é‡ˆä¾‹
print("\nè§£é‡ˆ:")
print("- petal width (cm) <= 0.8 ã§ setosa ã¨åˆ¤å®š")
print("- ãã‚Œä»¥å¤–ã¯ petal width ã‚„ petal length ã§ versicolor/virginica ã‚’åˆ¤å®š")
print("- æ±ºå®šå¢ƒç•ŒãŒæ˜ç¢ºã§ã€å°‚é–€å®¶ã§ãªãã¦ã‚‚ç†è§£å¯èƒ½")
</code></pre>

<h3>ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«</h3>

<p>IF-THENãƒ«ãƒ¼ãƒ«ã§æ§‹æˆã•ã‚Œã‚‹ãƒ¢ãƒ‡ãƒ«ã¯ã€ãƒ“ã‚¸ãƒã‚¹ãƒ«ãƒ¼ãƒ«ã¨ã—ã¦ç›´æ¥åˆ©ç”¨å¯èƒ½ã§ã™ã€‚</p>

<pre><code class="language-python">"""
ä¾‹: ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹åˆ†é¡å™¨
"""

import numpy as np
import pandas as pd

class SimpleRuleClassifier:
    """è§£é‡ˆå¯èƒ½ãªãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹åˆ†é¡å™¨"""

    def __init__(self):
        self.rules = []

    def add_rule(self, condition, prediction, description=""):
        """ãƒ«ãƒ¼ãƒ«ã‚’è¿½åŠ """
        self.rules.append({
            'condition': condition,
            'prediction': prediction,
            'description': description
        })

    def predict(self, X):
        """äºˆæ¸¬"""
        predictions = []
        for _, row in X.iterrows():
            prediction = None
            for rule in self.rules:
                if rule['condition'](row):
                    prediction = rule['prediction']
                    break
            predictions.append(prediction if prediction is not None else 0)
        return np.array(predictions)

    def explain(self):
        """ãƒ«ãƒ¼ãƒ«ã‚’èª¬æ˜"""
        print("åˆ†é¡ãƒ«ãƒ¼ãƒ«:")
        for i, rule in enumerate(self.rules, 1):
            print(f"  Rule {i}: {rule['description']} â†’ {rule['prediction']}")

# ä½¿ç”¨ä¾‹: ãƒ­ãƒ¼ãƒ³æ‰¿èªãƒ«ãƒ¼ãƒ«
classifier = SimpleRuleClassifier()

# ãƒ«ãƒ¼ãƒ«1: é«˜åå…¥ã§ä½è² å‚µ
classifier.add_rule(
    condition=lambda row: row['income'] > 100000 and row['debt_ratio'] < 0.3,
    prediction=1,
    description="é«˜åå…¥ï¼ˆ>100Kï¼‰ã‹ã¤ä½è² å‚µç‡ï¼ˆ<30%ï¼‰"
)

# ãƒ«ãƒ¼ãƒ«2: ä¸­åå…¥ã§è‰¯å¥½ãªä¿¡ç”¨å±¥æ­´
classifier.add_rule(
    condition=lambda row: row['income'] > 50000 and row['credit_history_months'] > 36,
    prediction=1,
    description="ä¸­åå…¥ï¼ˆ>50Kï¼‰ã‹ã¤ä¿¡ç”¨å±¥æ­´3å¹´ä»¥ä¸Š"
)

# ãƒ«ãƒ¼ãƒ«3: ãã‚Œä»¥å¤–ã¯å´ä¸‹
classifier.add_rule(
    condition=lambda row: True,
    prediction=0,
    description="ãã®ä»–ã®ã‚±ãƒ¼ã‚¹"
)

# ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
test_data = pd.DataFrame({
    'income': [120000, 60000, 30000],
    'debt_ratio': [0.2, 0.4, 0.6],
    'credit_history_months': [48, 40, 12]
})

predictions = classifier.predict(test_data)
classifier.explain()

print("\näºˆæ¸¬çµæœ:")
for i, (pred, income) in enumerate(zip(predictions, test_data['income'])):
    print(f"  ç”³è«‹è€… {i+1} (åå…¥: ${income:,.0f}): {'æ‰¿èª' if pred == 1 else 'å´ä¸‹'}")
</code></pre>

<h3>GAM (Generalized Additive Models)</h3>

<p>GAMã¯ã€å„ç‰¹å¾´é‡ã®éç·šå½¢åŠ¹æœã‚’å¯è¦–åŒ–ã§ãã‚‹è§£é‡ˆå¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚</p>

<p><strong>æ•°å¼</strong>:</p>
<p>$$g(\mathbb{E}[y]) = \beta_0 + f_1(x_1) + f_2(x_2) + \cdots + f_n(x_n)$$</p>

<p>$f_i$ ã¯ç‰¹å¾´é‡ $x_i$ ã®éç·šå½¢é–¢æ•°ã§ã™ã€‚</p>

<pre><code class="language-python">"""
ä¾‹: GAMã«ã‚ˆã‚‹éç·šå½¢é–¢ä¿‚ã®ãƒ¢ãƒ‡ãƒªãƒ³ã‚°
"""

import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import Ridge
from sklearn.model_selection import train_test_split

# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆï¼ˆéç·šå½¢é–¢ä¿‚ï¼‰
np.random.seed(42)
n_samples = 300

x1 = np.random.uniform(-3, 3, n_samples)
x2 = np.random.uniform(-3, 3, n_samples)

# éç·šå½¢é–¢ä¿‚: siné–¢æ•°ã¨2æ¬¡é–¢æ•°
y = np.sin(x1) + x2**2 + np.random.normal(0, 0.2, n_samples)

data = pd.DataFrame({'x1': x1, 'x2': x2, 'y': y})

# ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°: å¤šé …å¼ç‰¹å¾´ã‚’è¿½åŠ ï¼ˆGAMã®è¿‘ä¼¼ï¼‰
from sklearn.preprocessing import PolynomialFeatures

X = data[['x1', 'x2']]
poly = PolynomialFeatures(degree=3, include_bias=False, interaction_features=False)
X_poly = poly.fit_transform(X)

feature_names = poly.get_feature_names_out(['x1', 'x2'])

X_train, X_test, y_train, y_test = train_test_split(
    X_poly, data['y'], test_size=0.2, random_state=42
)

# ãƒªãƒƒã‚¸å›å¸°ã§è¨“ç·´
model = Ridge(alpha=1.0)
model.fit(X_train, y_train)

print(f"ãƒ†ã‚¹ãƒˆRÂ²ã‚¹ã‚³ã‚¢: {model.score(X_test, y_test):.3f}")

# å„ç‰¹å¾´é‡ã®åŠ¹æœã‚’å¯è¦–åŒ–
print("\nå„ç‰¹å¾´é‡ã®å¤šé …å¼ä¿‚æ•°:")
coef_df = pd.DataFrame({
    'feature': feature_names,
    'coefficient': model.coef_
})
print(coef_df)

print("\nè§£é‡ˆ:")
print("- x1ã®å¥‡æ•°æ¬¡ã®é …ãŒé‡è¦ â†’ siné–¢æ•°çš„ãªéç·šå½¢æ€§")
print("- x2ã®2æ¬¡ã®é …ãŒé‡è¦ â†’ 2æ¬¡é–¢æ•°çš„ãªé–¢ä¿‚")
print("- å„å¤‰æ•°ã®åŠ¹æœã‚’å€‹åˆ¥ã«è§£é‡ˆå¯èƒ½")
</code></pre>

<hr>

<h2>1.4 è§£é‡ˆæ‰‹æ³•ã®æ¦‚è¦</h2>

<h3>Feature Importance</h3>

<p>ç‰¹å¾´é‡ã®é‡è¦åº¦ã‚’å®šé‡åŒ–ã™ã‚‹æ‰‹æ³•ã€‚ãƒ„ãƒªãƒ¼ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã§é »ç¹ã«ä½¿ç”¨ã•ã‚Œã¾ã™ã€‚</p>

<ul>
<li><strong>Mean Decrease Impurity</strong>: ä¸ç´”åº¦ã®æ¸›å°‘é‡ã§é‡è¦åº¦ã‚’æ¸¬å®š</li>
<li><strong>Permutation Importance</strong>: ç‰¹å¾´é‡ã‚’ã‚·ãƒ£ãƒƒãƒ•ãƒ«ã—ãŸéš›ã®æ€§èƒ½ä½ä¸‹ã§æ¸¬å®š</li>
</ul>

<h3>Partial Dependence Plot (PDP)</h3>

<p>ç‰¹å®šã®ç‰¹å¾´é‡ã¨ãƒ¢ãƒ‡ãƒ«äºˆæ¸¬ã®é–¢ä¿‚ã‚’å¯è¦–åŒ–ã—ã¾ã™ã€‚</p>

<p><strong>æ•°å¼</strong>:</p>
<p>$$\text{PDP}(x_s) = \mathbb{E}_{x_c}[f(x_s, x_c)]$$</p>

<p>$x_s$ ã¯å¯¾è±¡ç‰¹å¾´é‡ã€$x_c$ ã¯ãã®ä»–ã®ç‰¹å¾´é‡ã§ã™ã€‚</p>

<h3>SHAP (SHapley Additive exPlanations)</h3>

<p>ã‚²ãƒ¼ãƒ ç†è«–ã®Shapleyå€¤ã‚’ç”¨ã„ã¦ã€å„ç‰¹å¾´é‡ã®è²¢çŒ®åº¦ã‚’è¨ˆç®—ã—ã¾ã™ã€‚</p>

<p><strong>ç‰¹å¾´</strong>:</p>
<ul>
<li>ä¸€è²«æ€§ã®ã‚ã‚‹èª¬æ˜</li>
<li>å±€æ‰€çš„ãŠã‚ˆã³å¤§åŸŸçš„è§£é‡ˆãŒå¯èƒ½</li>
<li>ãƒ¢ãƒ‡ãƒ«éä¾å­˜</li>
</ul>

<h3>LIME (Local Interpretable Model-agnostic Explanations)</h3>

<p>å€‹åˆ¥ã®äºˆæ¸¬ã‚’ã€å±€æ‰€çš„ã«ç·šå½¢ãƒ¢ãƒ‡ãƒ«ã§è¿‘ä¼¼ã—ã¦èª¬æ˜ã—ã¾ã™ã€‚</p>

<p><strong>æ‰‹é †</strong>:</p>
<ol>
<li>äºˆæ¸¬ã—ãŸã„ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®è¿‘å‚ã«ã‚µãƒ³ãƒ—ãƒ«ã‚’ç”Ÿæˆ</li>
<li>ãƒ–ãƒ©ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ãƒ¢ãƒ‡ãƒ«ã§äºˆæ¸¬ã‚’å–å¾—</li>
<li>è§£é‡ˆå¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ï¼ˆç·šå½¢å›å¸°ãªã©ï¼‰ã§ãƒ­ãƒ¼ã‚«ãƒ«ã«è¿‘ä¼¼</li>
<li>è¿‘ä¼¼ãƒ¢ãƒ‡ãƒ«ã®ä¿‚æ•°ã‚’è§£é‡ˆ</li>
</ol>

<h3>Saliency Mapsï¼ˆé¡•è‘—æ€§ãƒãƒƒãƒ—ï¼‰</h3>

<p>ç”»åƒåˆ†é¡ã«ãŠã„ã¦ã€ã©ã®ãƒ”ã‚¯ã‚»ãƒ«ãŒäºˆæ¸¬ã«é‡è¦ã‹ã‚’å¯è¦–åŒ–ã—ã¾ã™ã€‚</p>

<p><strong>è¨ˆç®—æ–¹æ³•</strong>:</p>
<p>$$S(x) = \left| \frac{\partial f(x)}{\partial x} \right|$$</p>

<p>å…¥åŠ›ç”»åƒã«å¯¾ã™ã‚‹å‹¾é…ã‚’è¨ˆç®—ã—ã€é‡è¦ãªé ˜åŸŸã‚’å¼·èª¿è¡¨ç¤ºã—ã¾ã™ã€‚</p>

<hr>

<h2>1.5 è§£é‡ˆæ€§ã®è©•ä¾¡</h2>

<h3>Fidelityï¼ˆå¿ å®Ÿåº¦ï¼‰</h3>

<p>è§£é‡ˆæ‰‹æ³•ãŒå…ƒã®ãƒ¢ãƒ‡ãƒ«ã®æŒ¯ã‚‹èˆã„ã‚’ã©ã‚Œã ã‘æ­£ç¢ºã«èª¬æ˜ã—ã¦ã„ã‚‹ã‹ã‚’æ¸¬å®šã—ã¾ã™ã€‚</p>

<table>
<thead>
<tr>
<th>è©•ä¾¡æŒ‡æ¨™</th>
<th>èª¬æ˜</th>
<th>è¨ˆç®—æ–¹æ³•</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>RÂ²ã‚¹ã‚³ã‚¢</strong></td>
<td>èª¬æ˜ãƒ¢ãƒ‡ãƒ«ã¨å…ƒãƒ¢ãƒ‡ãƒ«ã®ä¸€è‡´åº¦</td>
<td>$R^2 = 1 - \frac{\sum(y_{\text{true}} - y_{\text{approx}})^2}{\sum(y_{\text{true}} - \bar{y})^2}$</td>
</tr>
<tr>
<td><strong>Local Fidelity</strong></td>
<td>å±€æ‰€çš„ãªäºˆæ¸¬ã®ä¸€è‡´åº¦</td>
<td>è¿‘å‚ã‚µãƒ³ãƒ—ãƒ«ã§ã®äºˆæ¸¬èª¤å·®</td>
</tr>
</tbody>
</table>

<h3>Consistencyï¼ˆä¸€è²«æ€§ï¼‰</h3>

<p>é¡ä¼¼ã—ãŸã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã«å¯¾ã—ã¦é¡ä¼¼ã—ãŸèª¬æ˜ãŒå¾—ã‚‰ã‚Œã‚‹ã‹ã‚’è©•ä¾¡ã—ã¾ã™ã€‚</p>

<pre><code class="language-python">"""
ä¾‹: è§£é‡ˆã®ä¸€è²«æ€§è©•ä¾¡
"""

import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split

# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿
np.random.seed(42)
n_samples = 500

data = pd.DataFrame({
    'feature1': np.random.normal(0, 1, n_samples),
    'feature2': np.random.normal(0, 1, n_samples),
    'feature3': np.random.normal(0, 1, n_samples)
})
data['target'] = (data['feature1'] + data['feature2'] > 0).astype(int)

X = data.drop('target', axis=1)
y = data['target']

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

model = RandomForestClassifier(n_estimators=50, random_state=42)
model.fit(X_train, y_train)

# é¡ä¼¼ã‚µãƒ³ãƒ—ãƒ«ã®Feature Importanceæ¯”è¼ƒ
sample1 = X_test.iloc[0:1]
sample2 = X_test.iloc[1:2]  # é¡ä¼¼ã‚µãƒ³ãƒ—ãƒ«

# ãƒ„ãƒªãƒ¼ãƒ‘ã‚¹ã‚’ä½¿ã£ãŸç°¡æ˜“çš„ãªãƒ­ãƒ¼ã‚«ãƒ«é‡è¦åº¦
# ï¼ˆå®Ÿéš›ã«ã¯SHAPã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã‚’æ¨å¥¨ï¼‰

print("ã‚µãƒ³ãƒ—ãƒ«1ã®ç‰¹å¾´:")
print(sample1.values)
print(f"äºˆæ¸¬: {model.predict(sample1)[0]}")

print("\nã‚µãƒ³ãƒ—ãƒ«2ã®ç‰¹å¾´:")
print(sample2.values)
print(f"äºˆæ¸¬: {model.predict(sample2)[0]}")

# è·é›¢è¨ˆç®—
distance = np.linalg.norm(sample1.values - sample2.values)
print(f"\nã‚µãƒ³ãƒ—ãƒ«é–“ã®è·é›¢: {distance:.3f}")
print("ä¸€è²«æ€§è©•ä¾¡: é¡ä¼¼ã‚µãƒ³ãƒ—ãƒ«ã«å¯¾ã™ã‚‹èª¬æ˜ãŒé¡ä¼¼ã—ã¦ã„ã‚‹ã‹ç¢ºèªãŒå¿…è¦")
</code></pre>

<h3>Stabilityï¼ˆå®‰å®šæ€§ï¼‰</h3>

<p>å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã®ã‚ãšã‹ãªå¤‰åŒ–ã«å¯¾ã—ã¦ã€è§£é‡ˆãŒå¤§ããå¤‰ã‚ã‚‰ãªã„ã‹ã‚’è©•ä¾¡ã—ã¾ã™ã€‚</p>

<h3>Comprehensibilityï¼ˆç†è§£å®¹æ˜“æ€§ï¼‰</h3>

<p>äººé–“ãŒèª¬æ˜ã‚’ç†è§£ã—ã‚„ã™ã„ã‹ã‚’è©•ä¾¡ã—ã¾ã™ã€‚å®šé‡åŒ–ãŒé›£ã—ã„ãŸã‚ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼èª¿æŸ»ãŒä¸€èˆ¬çš„ã§ã™ã€‚</p>

<table>
<thead>
<tr>
<th>è©•ä¾¡æ–¹æ³•</th>
<th>èª¬æ˜</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>ãƒ«ãƒ¼ãƒ«æ•°</strong></td>
<td>æ±ºå®šæœ¨ã‚„ãƒ«ãƒ¼ãƒ«ã‚»ãƒƒãƒˆã®ãƒ«ãƒ¼ãƒ«æ•°ï¼ˆå°‘ãªã„ã»ã©ç†è§£ã—ã‚„ã™ã„ï¼‰</td>
</tr>
<tr>
<td><strong>ç‰¹å¾´é‡æ•°</strong></td>
<td>èª¬æ˜ã«ä½¿ç”¨ã•ã‚Œã‚‹ç‰¹å¾´é‡ã®æ•°ï¼ˆå°‘ãªã„ã»ã©è‰¯ã„ï¼‰</td>
</tr>
<tr>
<td><strong>ãƒ¦ãƒ¼ã‚¶ãƒ¼èª¿æŸ»</strong></td>
<td>å®Ÿéš›ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã‚‹ç†è§£åº¦ãƒ†ã‚¹ãƒˆ</td>
</tr>
</tbody>
</table>

<hr>

<h2>ç·´ç¿’å•é¡Œ</h2>

<details>
<summary>å•é¡Œ1: ãƒ¢ãƒ‡ãƒ«è§£é‡ˆæ€§ã®å¿…è¦æ€§</summary>
<p><strong>å•é¡Œ</strong>: ä»¥ä¸‹ã®ã‚·ãƒŠãƒªã‚ªã§ã€ãƒ¢ãƒ‡ãƒ«è§£é‡ˆæ€§ãŒç‰¹ã«é‡è¦ã§ã‚ã‚‹ç†ç”±ã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚</p>
<ol>
<li>éŠ€è¡Œã®èè³‡å¯©æŸ»ã‚·ã‚¹ãƒ†ãƒ </li>
<li>åŒ»ç™‚ç”»åƒè¨ºæ–­æ”¯æ´ã‚·ã‚¹ãƒ†ãƒ </li>
<li>ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚·ã‚¹ãƒ†ãƒ </li>
</ol>
<p><strong>è§£ç­”ä¾‹</strong>:</p>
<ol>
<li><strong>èè³‡å¯©æŸ»</strong>: æ‹’å¦ç†ç”±ã®èª¬æ˜ç¾©å‹™ï¼ˆæ³•çš„è¦ä»¶ï¼‰ã€å…¬æ­£æ€§ã®ç¢ºä¿ã€å·®åˆ¥çš„ãªåˆ¤æ–­ã®é˜²æ­¢</li>
<li><strong>åŒ»ç™‚è¨ºæ–­</strong>: åŒ»å¸«ã«ã‚ˆã‚‹è¨ºæ–­æ ¹æ‹ ã®ç†è§£ã€æ‚£è€…ã¸ã®èª¬æ˜ã€èª¤è¨ºã®ãƒªã‚¹ã‚¯è»½æ¸›ã€åŒ»ç™‚éèª¤è¨´è¨Ÿã¸ã®å¯¾å¿œ</li>
<li><strong>ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³</strong>: ãƒ¦ãƒ¼ã‚¶ãƒ¼ä¿¡é ¼ã®å‘ä¸Šã€æ¨è–¦ç†ç”±ã®é€æ˜æ€§ã€ãƒã‚¤ã‚¢ã‚¹ã®æ¤œå‡ºï¼ˆãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ãƒãƒ–ãƒ«ã®å›é¿ï¼‰</li>
</ol>
</details>

<details>
<summary>å•é¡Œ2: ã‚°ãƒ­ãƒ¼ãƒãƒ«è§£é‡ˆã¨ãƒ­ãƒ¼ã‚«ãƒ«è§£é‡ˆ</summary>
<p><strong>å•é¡Œ</strong>: ã€Œé¡§å®¢é›¢åäºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã€ã«ãŠã„ã¦ã€ã‚°ãƒ­ãƒ¼ãƒãƒ«è§£é‡ˆã¨ãƒ­ãƒ¼ã‚«ãƒ«è§£é‡ˆãã‚Œãã‚Œã§çŸ¥ã‚ŠãŸã„æƒ…å ±ã®ä¾‹ã‚’æŒ™ã’ã¦ãã ã•ã„ã€‚</p>
<p><strong>è§£ç­”ä¾‹</strong>:</p>
<ul>
<li><strong>ã‚°ãƒ­ãƒ¼ãƒãƒ«è§£é‡ˆ</strong>:
  <ul>
    <li>ã€Œã‚µãƒãƒ¼ãƒˆå•ã„åˆã‚ã›å›æ•°ã€ãŒé›¢åã«æœ€ã‚‚å½±éŸ¿ã™ã‚‹ç‰¹å¾´é‡ã§ã‚ã‚‹</li>
    <li>ã€Œå¥‘ç´„æœŸé–“ã€ã¨é›¢åç¢ºç‡ã®é–¢ä¿‚ï¼ˆé•·ã„ã»ã©é›¢åç‡ãŒä½ã„å‚¾å‘ï¼‰</li>
    <li>ãƒ¢ãƒ‡ãƒ«å…¨ä½“ã§é‡è¦ãªä¸Šä½5ã¤ã®ç‰¹å¾´é‡</li>
  </ul>
</li>
<li><strong>ãƒ­ãƒ¼ã‚«ãƒ«è§£é‡ˆ</strong>:
  <ul>
    <li>é¡§å®¢Aï¼ˆID=12345ï¼‰ãŒé›¢åã™ã‚‹ã¨äºˆæ¸¬ã•ã‚ŒãŸç†ç”±ï¼ˆã‚µãƒãƒ¼ãƒˆå•ã„åˆã‚ã›ãŒ10å›ä»¥ä¸Šã€å¥‘ç´„æœŸé–“ãŒ3ãƒ¶æœˆæœªæº€ãªã©ï¼‰</li>
    <li>ã“ã®é¡§å®¢ã®é›¢åç¢ºç‡ã‚’ä¸‹ã’ã‚‹ãŸã‚ã«æ”¹å–„ã™ã¹ãè¦å› </li>
  </ul>
</li>
</ul>
</details>

<details>
<summary>å•é¡Œ3: è§£é‡ˆå¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã®é¸æŠ</summary>
<p><strong>å•é¡Œ</strong>: ä»¥ä¸‹ã®ã‚·ãƒŠãƒªã‚ªã§ã€ã©ã®è§£é‡ˆå¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ãŒé©åˆ‡ã‹é¸æŠã—ã€ç†ç”±ã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚</p>
<ol>
<li>ä½å®…ä¾¡æ ¼äºˆæ¸¬ï¼ˆç‰¹å¾´é‡: é¢ç©ã€éƒ¨å±‹æ•°ã€ç¯‰å¹´æ•°ãªã©ï¼‰</li>
<li>ã‚¹ãƒ‘ãƒ ãƒ¡ãƒ¼ãƒ«åˆ†é¡ï¼ˆç‰¹å¾´é‡: å˜èªã®å‡ºç¾é »åº¦ï¼‰</li>
<li>æ‚£è€…ã®å†å…¥é™¢ãƒªã‚¹ã‚¯äºˆæ¸¬ï¼ˆç‰¹å¾´é‡: å¹´é½¢ã€è¨ºæ–­å±¥æ­´ã€æ¤œæŸ»å€¤ãªã©ï¼‰</li>
</ol>
<p><strong>è§£ç­”ä¾‹</strong>:</p>
<ol>
<li><strong>ç·šå½¢å›å¸°</strong>: å„ç‰¹å¾´é‡ã®ä¿‚æ•°ãŒä¾¡æ ¼ã¸ã®å½±éŸ¿ã‚’ç›´æ¥ç¤ºã™ãŸã‚ã€ä¸å‹•ç”£æ¥­è€…ã‚„é¡§å®¢ãŒç†è§£ã—ã‚„ã™ã„</li>
<li><strong>æ±ºå®šæœ¨ã¾ãŸã¯ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹</strong>: ã€Œ"ç„¡æ–™"ã¨ã„ã†å˜èªãŒ5å›ä»¥ä¸Š â†’ ã‚¹ãƒ‘ãƒ ã€ã®ã‚ˆã†ãªãƒ«ãƒ¼ãƒ«ãŒç›´æ„Ÿçš„</li>
<li><strong>GAMã¾ãŸã¯æ±ºå®šæœ¨</strong>: éç·šå½¢ãªé–¢ä¿‚ï¼ˆä¾‹: å¹´é½¢ã¨å†å…¥é™¢ãƒªã‚¹ã‚¯ã®Uå­—å‹é–¢ä¿‚ï¼‰ã‚’å¯è¦–åŒ–ã§ãã‚‹ã€‚åŒ»å¸«ãŒè¨ºæ–­ãƒ­ã‚¸ãƒƒã‚¯ã‚’ç†è§£ã—ã‚„ã™ã„</li>
</ol>
</details>

<details>
<summary>å•é¡Œ4: ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯ã®æ¤œå‡º</summary>
<p><strong>å•é¡Œ</strong>: Feature Importanceã‚’ä½¿ã£ã¦ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯ã‚’æ¤œå‡ºã™ã‚‹æ–¹æ³•ã‚’èª¬æ˜ã—ã€ã‚³ãƒ¼ãƒ‰ä¾‹ã‚’ç¤ºã—ã¦ãã ã•ã„ã€‚</p>
<p><strong>è§£ç­”ä¾‹</strong>:</p>
<pre><code class="language-python">"""
ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯ã®æ¤œå‡ºæ–¹æ³•
"""
import pandas as pd
from sklearn.ensemble import RandomForestClassifier

# ç–‘ã‚ã—ã„ç‰¹å¾´é‡ã®ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ
suspicious_features = [
    'id', 'timestamp', 'created_at', 'updated_at',
    'target', 'label', 'outcome'  # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤‰æ•°ãã®ã‚‚ã®ã‚„ãã®ãƒªãƒ¼ã‚¯
]

# Feature Importanceã‚’è¨ˆç®—
model = RandomForestClassifier()
# model.fit(X_train, y_train)

feature_importance = pd.DataFrame({
    'feature': X.columns,
    'importance': model.feature_importances_
}).sort_values('importance', ascending=False)

# ä¸Šä½ã®ç‰¹å¾´é‡ã‚’ãƒã‚§ãƒƒã‚¯
top_features = feature_importance.head(5)
for _, row in top_features.iterrows():
    feature = row['feature']
    importance = row['importance']

    # ç–‘ã‚ã—ã„ç‰¹å¾´é‡ãŒä¸Šä½ã«ã‚ã‚‹ã‹
    if any(suspect in feature.lower() for suspect in suspicious_features):
        print(f"âš ï¸ ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯ã®å¯èƒ½æ€§: {feature} (é‡è¦åº¦: {importance:.3f})")

    # é‡è¦åº¦ãŒç•°å¸¸ã«é«˜ã„ã‹ï¼ˆ>0.9ï¼‰
    if importance > 0.9:
        print(f"âš ï¸ ç•°å¸¸ã«é«˜ã„é‡è¦åº¦: {feature} (é‡è¦åº¦: {importance:.3f})")
</code></pre>
</details>

<details>
<summary>å•é¡Œ5: è§£é‡ˆæ€§ã®è©•ä¾¡</summary>
<p><strong>å•é¡Œ</strong>: è§£é‡ˆæ‰‹æ³•ã®ã€ŒFidelityï¼ˆå¿ å®Ÿåº¦ï¼‰ã€ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã«ã€ã©ã®ã‚ˆã†ãªæŒ‡æ¨™ã‚„æ–¹æ³•ã‚’ä½¿ç”¨ã§ãã¾ã™ã‹ï¼Ÿ</p>
<p><strong>è§£ç­”ä¾‹</strong>:</p>
<ul>
<li><strong>RÂ²ã‚¹ã‚³ã‚¢</strong>: èª¬æ˜ãƒ¢ãƒ‡ãƒ«ï¼ˆLIMEã®ç·šå½¢è¿‘ä¼¼ãªã©ï¼‰ã¨å…ƒã®ãƒ–ãƒ©ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬ã®ä¸€è‡´åº¦</li>
<li><strong>äºˆæ¸¬èª¤å·®</strong>: èª¬æ˜ãƒ¢ãƒ‡ãƒ«ã¨å…ƒãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬ã®å¹³å‡çµ¶å¯¾èª¤å·®ï¼ˆMAEï¼‰</li>
<li><strong>åˆ†é¡ç²¾åº¦ã®æ¯”è¼ƒ</strong>: èª¬æ˜ãƒ¢ãƒ‡ãƒ«ãŒå…ƒãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬ã‚’ã©ã‚Œã ã‘æ­£ç¢ºã«å†ç¾ã§ãã‚‹ã‹</li>
<li><strong>ãƒ­ãƒ¼ã‚«ãƒ«å¿ å®Ÿåº¦</strong>: ç‰¹å®šã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®è¿‘å‚ã«ãŠã„ã¦ã€èª¬æ˜ãƒ¢ãƒ‡ãƒ«ãŒã©ã‚Œã ã‘æ­£ç¢ºã‹</li>
</ul>
</details>

<details>
<summary>å•é¡Œ6: å®Ÿè£…èª²é¡Œ</summary>
<p><strong>å•é¡Œ</strong>: scikit-learnã®ã‚¿ã‚¤ã‚¿ãƒ‹ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆã¾ãŸã¯ä»»æ„ã®ãƒ‡ãƒ¼ã‚¿ï¼‰ã‚’ä½¿ç”¨ã—ã¦ã€ä»¥ä¸‹ã‚’å®Ÿè£…ã—ã¦ãã ã•ã„ã€‚</p>
<ol>
<li>ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã—ã€ä¿‚æ•°ã‚’è§£é‡ˆã™ã‚‹</li>
<li>æ±ºå®šæœ¨ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã—ã€ãƒ«ãƒ¼ãƒ«ã‚’æŠ½å‡ºã™ã‚‹</li>
<li>ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã—ã€Feature Importanceã‚’å¯è¦–åŒ–ã™ã‚‹</li>
<li>3ã¤ã®ãƒ¢ãƒ‡ãƒ«ã®è§£é‡ˆå®¹æ˜“æ€§ã‚’æ¯”è¼ƒã™ã‚‹</li>
</ol>
<p><strong>ãƒ’ãƒ³ãƒˆ</strong>:</p>
<pre><code class="language-python">from sklearn.datasets import fetch_openml
import pandas as pd

# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
titanic = fetch_openml('titanic', version=1, as_frame=True, parser='auto')
df = titanic.frame

# å‰å‡¦ç†ï¼ˆæ¬ æå€¤å‡¦ç†ã€ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãªã©ï¼‰
# ...

# ãƒ¢ãƒ‡ãƒ«è¨“ç·´ã¨è§£é‡ˆ
# ...
</code></pre>
</details>

<hr>

<h2>ã¾ã¨ã‚</h2>

<p>ã“ã®ç« ã§ã¯ã€ãƒ¢ãƒ‡ãƒ«è§£é‡ˆæ€§ã®åŸºç¤ã«ã¤ã„ã¦å­¦ã³ã¾ã—ãŸï¼š</p>

<ul>
<li>âœ… <strong>é‡è¦æ€§</strong>: ä¿¡é ¼æ€§ã€è¦åˆ¶å¯¾å¿œã€ãƒ‡ãƒãƒƒã‚°ã€ãƒã‚¤ã‚¢ã‚¹æ¤œå‡ºã«ä¸å¯æ¬ </li>
<li>âœ… <strong>åˆ†é¡</strong>: ã‚°ãƒ­ãƒ¼ãƒãƒ«/ãƒ­ãƒ¼ã‚«ãƒ«ã€ãƒ¢ãƒ‡ãƒ«å›ºæœ‰/éä¾å­˜ã€äº‹å‰/äº‹å¾Œè§£é‡ˆæ€§</li>
<li>âœ… <strong>è§£é‡ˆå¯èƒ½ãƒ¢ãƒ‡ãƒ«</strong>: ç·šå½¢å›å¸°ã€æ±ºå®šæœ¨ã€ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã€GAM</li>
<li>âœ… <strong>è§£é‡ˆæ‰‹æ³•</strong>: Feature Importance, PDP, SHAP, LIME, Saliency Maps</li>
<li>âœ… <strong>è©•ä¾¡åŸºæº–</strong>: Fidelity, Consistency, Stability, Comprehensibility</li>
</ul>

<p>æ¬¡ç« ã§ã¯ã€Feature Importanceã¨Permutation Importanceã«ã¤ã„ã¦è©³ã—ãå­¦ã³ã¾ã™ã€‚</p>

<hr>

<h2>å‚è€ƒæ–‡çŒ®</h2>

<ul>
<li>Molnar, C. (2022). <em>Interpretable Machine Learning: A Guide for Making Black Box Models Explainable</em>. <a href="https://christophm.github.io/interpretable-ml-book/">https://christophm.github.io/interpretable-ml-book/</a></li>
<li>Lundberg, S. M., & Lee, S. I. (2017). "A Unified Approach to Interpreting Model Predictions." <em>NIPS 2017</em>.</li>
<li>Ribeiro, M. T., Singh, S., & Guestrin, C. (2016). "Why Should I Trust You?: Explaining the Predictions of Any Classifier." <em>KDD 2016</em>.</li>
<li>Rudin, C. (2019). "Stop Explaining Black Box Machine Learning Models for High Stakes Decisions and Use Interpretable Models Instead." <em>Nature Machine Intelligence</em>.</li>
<li>European Union. (2016). <em>General Data Protection Regulation (GDPR)</em>. Article 22.</li>
<li>Doshi-Velez, F., & Kim, B. (2017). "Towards A Rigorous Science of Interpretable Machine Learning." <em>arXiv:1702.08608</em>.</li>
</ul>

        <div class="navigation">
            <a href="index.html" class="nav-button">ğŸ“š ç›®æ¬¡ã«æˆ»ã‚‹</a>
            <a href="chapter2-feature-importance.html" class="nav-button">æ¬¡ã®ç« ã¸ â†’</a>
        </div>
    </main>

    
    <section class="disclaimer">
        <h3>å…è²¬äº‹é …</h3>
        <ul>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯æ•™è‚²ãƒ»ç ”ç©¶ãƒ»æƒ…å ±æä¾›ã®ã¿ã‚’ç›®çš„ã¨ã—ã¦ãŠã‚Šã€å°‚é–€çš„ãªåŠ©è¨€(æ³•å¾‹ãƒ»ä¼šè¨ˆãƒ»æŠ€è¡“çš„ä¿è¨¼ãªã©)ã‚’æä¾›ã™ã‚‹ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŠã‚ˆã³ä»˜éšã™ã‚‹ã‚³ãƒ¼ãƒ‰ä¾‹ã¯ã€Œç¾çŠ¶æœ‰å§¿(AS IS)ã€ã§æä¾›ã•ã‚Œã€æ˜ç¤ºã¾ãŸã¯é»™ç¤ºã‚’å•ã‚ãšã€å•†å“æ€§ã€ç‰¹å®šç›®çš„é©åˆæ€§ã€æ¨©åˆ©éä¾µå®³ã€æ­£ç¢ºæ€§ãƒ»å®Œå…¨æ€§ã€å‹•ä½œãƒ»å®‰å…¨æ€§ç­‰ã„ã‹ãªã‚‹ä¿è¨¼ã‚‚ã—ã¾ã›ã‚“ã€‚</li>
            <li>å¤–éƒ¨ãƒªãƒ³ã‚¯ã€ç¬¬ä¸‰è€…ãŒæä¾›ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ»ãƒ„ãƒ¼ãƒ«ãƒ»ãƒ©ã‚¤ãƒ–ãƒ©ãƒªç­‰ã®å†…å®¹ãƒ»å¯ç”¨æ€§ãƒ»å®‰å…¨æ€§ã«ã¤ã„ã¦ã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯ä¸€åˆ‡ã®è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®åˆ©ç”¨ãƒ»å®Ÿè¡Œãƒ»è§£é‡ˆã«ã‚ˆã‚Šç›´æ¥çš„ãƒ»é–“æ¥çš„ãƒ»ä»˜éšçš„ãƒ»ç‰¹åˆ¥ãƒ»çµæœçš„ãƒ»æ‡²ç½°çš„æå®³ãŒç”Ÿã˜ãŸå ´åˆã§ã‚‚ã€é©ç”¨æ³•ã§è¨±å®¹ã•ã‚Œã‚‹æœ€å¤§é™ã®ç¯„å›²ã§ã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å†…å®¹ã¯ã€äºˆå‘Šãªãå¤‰æ›´ãƒ»æ›´æ–°ãƒ»æä¾›åœæ­¢ã•ã‚Œã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®è‘—ä½œæ¨©ãƒ»ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯æ˜è¨˜ã•ã‚ŒãŸæ¡ä»¶(ä¾‹: CC BY 4.0)ã«å¾“ã„ã¾ã™ã€‚å½“è©²ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯é€šå¸¸ã€ç„¡ä¿è¨¼æ¡é …ã‚’å«ã¿ã¾ã™ã€‚</li>
        </ul>
    </section>

<footer>
        <p>&copy; 2025 AI Terakoya. All rights reserved.</p>
    </footer>
</body>
</html>
