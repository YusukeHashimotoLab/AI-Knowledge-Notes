<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>第3章：高度なチューニング手法 - AI Terakoya</title>

    <style>
        :root {
            --color-primary: #2c3e50;
            --color-primary-dark: #1a252f;
            --color-accent: #7b2cbf;
            --color-accent-light: #9d4edd;
            --color-text: #2d3748;
            --color-text-light: #4a5568;
            --color-bg: #ffffff;
            --color-bg-alt: #f7fafc;
            --color-border: #e2e8f0;
            --color-code-bg: #f8f9fa;
            --color-link: #3182ce;
            --color-link-hover: #2c5aa0;

            --spacing-xs: 0.5rem;
            --spacing-sm: 1rem;
            --spacing-md: 1.5rem;
            --spacing-lg: 2rem;
            --spacing-xl: 3rem;

            --font-body: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            --font-mono: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;

            --border-radius: 8px;
            --box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: var(--font-body);
            line-height: 1.7;
            color: var(--color-text);
            background-color: var(--color-bg);
            font-size: 16px;
        }

        header {
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            padding: var(--spacing-xl) var(--spacing-md);
            margin-bottom: var(--spacing-xl);
            box-shadow: var(--box-shadow);
        }

        .header-content {
            max-width: 900px;
            margin: 0 auto;
        }

        h1 {
            font-size: 2rem;
            font-weight: 700;
            margin-bottom: var(--spacing-sm);
            line-height: 1.2;
        }

        .subtitle {
            font-size: 1.1rem;
            opacity: 0.95;
            font-weight: 400;
            margin-bottom: var(--spacing-md);
        }

        .meta {
            display: flex;
            flex-wrap: wrap;
            gap: var(--spacing-md);
            font-size: 0.9rem;
            opacity: 0.9;
        }

        .meta-item {
            display: flex;
            align-items: center;
            gap: 0.3rem;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 0 var(--spacing-md) var(--spacing-xl);
        }

        h2 {
            font-size: 1.75rem;
            color: var(--color-primary);
            margin-top: var(--spacing-xl);
            margin-bottom: var(--spacing-md);
            padding-bottom: var(--spacing-xs);
            border-bottom: 3px solid var(--color-accent);
        }

        h3 {
            font-size: 1.4rem;
            color: var(--color-primary);
            margin-top: var(--spacing-lg);
            margin-bottom: var(--spacing-sm);
        }

        h4 {
            font-size: 1.1rem;
            color: var(--color-primary-dark);
            margin-top: var(--spacing-md);
            margin-bottom: var(--spacing-sm);
        }

        p {
            margin-bottom: var(--spacing-md);
            color: var(--color-text);
        }

        a {
            color: var(--color-link);
            text-decoration: none;
            transition: color 0.2s;
        }

        a:hover {
            color: var(--color-link-hover);
            text-decoration: underline;
        }

        ul, ol {
            margin-left: var(--spacing-lg);
            margin-bottom: var(--spacing-md);
        }

        li {
            margin-bottom: var(--spacing-xs);
            color: var(--color-text);
        }

        pre {
            background-color: var(--color-code-bg);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            overflow-x: auto;
            margin-bottom: var(--spacing-md);
            font-family: var(--font-mono);
            font-size: 0.9rem;
            line-height: 1.5;
        }

        code {
            font-family: var(--font-mono);
            font-size: 0.9em;
            background-color: var(--color-code-bg);
            padding: 0.2em 0.4em;
            border-radius: 3px;
        }

        pre code {
            background-color: transparent;
            padding: 0;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: var(--spacing-md);
            font-size: 0.95rem;
        }

        th, td {
            border: 1px solid var(--color-border);
            padding: var(--spacing-sm);
            text-align: left;
        }

        th {
            background-color: var(--color-bg-alt);
            font-weight: 600;
            color: var(--color-primary);
        }

        blockquote {
            border-left: 4px solid var(--color-accent);
            padding-left: var(--spacing-md);
            margin: var(--spacing-md) 0;
            color: var(--color-text-light);
            font-style: italic;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        .mermaid {
            text-align: center;
            margin: var(--spacing-lg) 0;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        details {
            background-color: var(--color-bg-alt);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            margin-bottom: var(--spacing-md);
        }

        summary {
            cursor: pointer;
            font-weight: 600;
            color: var(--color-primary);
            user-select: none;
            padding: var(--spacing-xs);
            margin: calc(-1 * var(--spacing-md));
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        summary:hover {
            background-color: rgba(123, 44, 191, 0.1);
        }

        details[open] summary {
            margin-bottom: var(--spacing-md);
            border-bottom: 1px solid var(--color-border);
        }

        .navigation {
            display: flex;
            justify-content: space-between;
            gap: var(--spacing-md);
            margin: var(--spacing-xl) 0;
            padding-top: var(--spacing-lg);
            border-top: 2px solid var(--color-border);
        }

        .nav-button {
            flex: 1;
            padding: var(--spacing-md);
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            border-radius: var(--border-radius);
            text-align: center;
            font-weight: 600;
            transition: transform 0.2s, box-shadow 0.2s;
            box-shadow: var(--box-shadow);
        }

        .nav-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
            text-decoration: none;
        }

        footer {
            margin-top: var(--spacing-xl);
            padding: var(--spacing-lg) var(--spacing-md);
            background-color: var(--color-bg-alt);
            border-top: 1px solid var(--color-border);
            text-align: center;
            font-size: 0.9rem;
            color: var(--color-text-light);
        }

        @media (max-width: 768px) {
            h1 {
                font-size: 1.5rem;
            }

            h2 {
                font-size: 1.4rem;
            }

            h3 {
                font-size: 1.2rem;
            }

            .meta {
                font-size: 0.85rem;
            }

            .navigation {
                flex-direction: column;
            }

            table {
                font-size: 0.85rem;
            }

            th, td {
                padding: var(--spacing-xs);
            }
        }
    </style>

    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
        mermaid.initialize({ startOnLoad: true, theme: 'default' });
    </script>

    <!-- MathJax for LaTeX equation rendering -->
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                displayMath: [['$$', '$$'], ['\\[', '\\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
                ignoreHtmlClass: 'mermaid'
            }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" async></script>
</head>
<body>
    <header>
        <div class="header-content">
            <h1>第3章：高度なチューニング手法</h1>
            <p class="subtitle">Hyperband、BOHB、Population-based Trainingによる効率的な探索</p>
            <div class="meta">
                <span class="meta-item">📖 読了時間: 25-30分</span>
                <span class="meta-item">📊 難易度: 中級-上級</span>
                <span class="meta-item">💻 コード例: 6個</span>
                <span class="meta-item">🚀 実践的手法</span>
            </div>
        </div>
    </header>

    <main class="container">

<h2>学習目標</h2>
<p>この章を読むことで、以下を習得できます：</p>
<ul>
<li>✅ Successive HalvingとHyperbandの原理を理解する</li>
<li>✅ BOHBによるベイズ最適化とHyperbandの融合を活用できる</li>
<li>✅ Population-based Training (PBT)で並列学習を最適化できる</li>
<li>✅ Hyperopt、SMAC、Ax/BoTorchなど主要ライブラリの特徴を理解する</li>
<li>✅ Ray Tuneで大規模分散チューニングを実装できる</li>
</ul>

<hr>

<h2>3.1 Hyperband</h2>

<h3>Successive Halvingの原理</h3>

<p><strong>Successive Halving</strong>は、限られた計算リソースを効率的に配分する手法です。基本アイデアは以下の通り：</p>

<ol>
<li>多数の設定でトレーニングを少量のリソースで開始</li>
<li>性能の悪い設定を段階的に除外（半分ずつ）</li>
<li>残った有望な設定により多くのリソースを割り当て</li>
</ol>

<blockquote>
<p><strong>重要</strong>: 早期に性能が悪い設定を除外することで、計算コストを大幅に削減できます。</p>
</blockquote>

<h3>アルゴリズムの流れ</h3>

<div class="mermaid">
graph TD
    A[n個の設定をランダム生成] --> B[各設定をrリソースで評価]
    B --> C{性能の上位n/2を選択}
    C --> D[リソースを2倍に増やす]
    D --> E{さらに上位n/4を選択}
    E --> F[リソースを2倍に増やす]
    F --> G[最終的に最良の設定が残る]

    style A fill:#ffebee
    style B fill:#fff3e0
    style C fill:#e3f2fd
    style D fill:#f3e5f5
    style E fill:#e3f2fd
    style F fill:#f3e5f5
    style G fill:#c8e6c9
</div>

<h3>Hyperbandアルゴリズム</h3>

<p><strong>Hyperband</strong>は、Successive Halvingを複数の異なる設定で実行し、リソース配分戦略を最適化します。</p>

<p>パラメータ：</p>
<ul>
<li><strong>R</strong>: 1つの設定に割り当てる最大リソース（エポック数など）</li>
<li><strong>η</strong>: 各ラウンドでの削減率（通常3または4）</li>
</ul>

<p>$$
s_{\max} = \lfloor \log_\eta(R) \rfloor
$$</p>

<h3>Optunaでの実装（HyperbandPruner）</h3>

<pre><code class="language-python">import optuna
from optuna.pruners import HyperbandPruner
from sklearn.datasets import load_iris
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_val_score
import numpy as np

# Hyperbandの設定
pruner = HyperbandPruner(
    min_resource=1,      # 最小リソース（エポック）
    max_resource=100,    # 最大リソース
    reduction_factor=3   # 削減率η
)

def objective(trial):
    # ハイパーパラメータの提案
    n_estimators = trial.suggest_int('n_estimators', 10, 200)
    max_depth = trial.suggest_int('max_depth', 2, 32)
    min_samples_split = trial.suggest_int('min_samples_split', 2, 20)
    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)

    # データの準備
    X, y = load_iris(return_X_y=True)

    # 段階的にn_estimatorsを増やして評価（Hyperband対応）
    for step in range(1, 6):
        # 現在のステップに応じた木の数
        current_n_estimators = int(n_estimators * step / 5)

        model = RandomForestClassifier(
            n_estimators=current_n_estimators,
            max_depth=max_depth,
            min_samples_split=min_samples_split,
            min_samples_leaf=min_samples_leaf,
            random_state=42
        )

        # 交差検証スコア
        score = cross_val_score(model, X, y, cv=3, n_jobs=-1).mean()

        # Optunaに中間値を報告
        trial.report(score, step)

        # 枝刈り判定
        if trial.should_prune():
            raise optuna.TrialPruned()

    return score

# スタディの実行
study = optuna.create_study(
    direction='maximize',
    pruner=pruner,
    study_name='hyperband_example'
)

study.optimize(objective, n_trials=100, timeout=300)

print("\n=== Hyperband 最適化結果 ===")
print(f"最良スコア: {study.best_value:.4f}")
print(f"最良パラメータ: {study.best_params}")
print(f"\n完了試行: {len([t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE])}")
print(f"枝刈りされた試行: {len([t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED])}")
</code></pre>

<p><strong>出力例</strong>：</p>
<pre><code>=== Hyperband 最適化結果 ===
最良スコア: 0.9733
最良パラメータ: {'n_estimators': 142, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 1}

完了試行: 28
枝刈りされた試行: 72
</code></pre>

<blockquote>
<p><strong>効果</strong>: 100試行のうち72試行が早期に枝刈りされ、計算時間を大幅に削減。</p>
</blockquote>

<hr>

<h2>3.2 BOHB (Bayesian Optimization and HyperBand)</h2>

<h3>HyperbandとベイズOPの融合</h3>

<p><strong>BOHB</strong>は、Hyperbandの効率的なリソース配分とベイズ最適化の賢い探索を組み合わせた手法です。</p>

<table>
<thead>
<tr>
<th>手法</th>
<th>長所</th>
<th>短所</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Hyperband</strong></td>
<td>効率的なリソース配分</td>
<td>ランダムサンプリング</td>
</tr>
<tr>
<td><strong>ベイズ最適化</strong></td>
<td>賢い探索</td>
<td>全てのリソースを割り当て</td>
</tr>
<tr>
<td><strong>BOHB</strong></td>
<td>効率的 + 賢い探索</td>
<td>実装が複雑</td>
</tr>
</tbody>
</table>

<h3>BOHBの動作原理</h3>

<ol>
<li><strong>Hyperbandフレームワーク</strong>でリソース配分を管理</li>
<li>各ラウンドで、<strong>TPE（Tree-structured Parzen Estimator）</strong>を使用してハイパーパラメータを提案</li>
<li>過去の試行結果から学習し、有望な領域を優先的に探索</li>
</ol>

<div class="mermaid">
graph LR
    A[過去の試行データ] --> B[TPEモデル構築]
    B --> C[有望な設定を提案]
    C --> D[Successive Halvingで評価]
    D --> E[結果をフィードバック]
    E --> A

    style A fill:#e3f2fd
    style B fill:#f3e5f5
    style C fill:#fff3e0
    style D fill:#ffebee
    style E fill:#e8f5e9
</div>

<h3>実装と活用シーン</h3>

<pre><code class="language-python">import optuna
from optuna.samplers import TPESampler
from optuna.pruners import HyperbandPruner
from sklearn.datasets import load_digits
from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import cross_val_score

# BOHB設定（TPE + Hyperband）
sampler = TPESampler(seed=42, n_startup_trials=10)
pruner = HyperbandPruner(
    min_resource=5,
    max_resource=100,
    reduction_factor=3
)

def objective_bohb(trial):
    # ハイパーパラメータ提案（TPEが賢く選択）
    hidden_layer_size = trial.suggest_int('hidden_layer_size', 50, 200)
    alpha = trial.suggest_float('alpha', 1e-5, 1e-1, log=True)
    learning_rate_init = trial.suggest_float('learning_rate_init', 1e-4, 1e-1, log=True)

    X, y = load_digits(return_X_y=True)

    # Hyperband: 段階的にmax_iterを増やす
    for step in range(1, 6):
        max_iter = int(100 * step / 5)

        model = MLPClassifier(
            hidden_layer_sizes=(hidden_layer_size,),
            alpha=alpha,
            learning_rate_init=learning_rate_init,
            max_iter=max_iter,
            random_state=42
        )

        score = cross_val_score(model, X, y, cv=3, n_jobs=-1).mean()

        trial.report(score, step)
        if trial.should_prune():
            raise optuna.TrialPruned()

    return score

# BOHBスタディ
study_bohb = optuna.create_study(
    direction='maximize',
    sampler=sampler,
    pruner=pruner,
    study_name='bohb_example'
)

study_bohb.optimize(objective_bohb, n_trials=50, timeout=180)

print("\n=== BOHB 最適化結果 ===")
print(f"最良スコア: {study_bohb.best_value:.4f}")
print(f"最良パラメータ:")
for key, value in study_bohb.best_params.items():
    print(f"  {key}: {value}")
print(f"\n完了/枝刈り: {len([t for t in study_bohb.trials if t.state == optuna.trial.TrialState.COMPLETE])}/{len([t for t in study_bohb.trials if t.state == optuna.trial.TrialState.PRUNED])}")
</code></pre>

<h3>活用シーン</h3>

<ul>
<li><strong>ニューラルネットワーク</strong>: エポック数を段階的に増やす</li>
<li><strong>アンサンブル学習</strong>: 弱学習器の数を段階的に増やす</li>
<li><strong>大規模データ</strong>: データサンプル数を段階的に増やす</li>
</ul>

<hr>

<h2>3.3 Population-based Training (PBT)</h2>

<h3>PBTの原理</h3>

<p><strong>Population-based Training</strong>は、複数のモデルを並列に学習させ、定期的に以下を実行します：</p>

<ol>
<li><strong>Exploit（活用）</strong>: 性能の悪いモデルを性能の良いモデルに置き換え</li>
<li><strong>Explore（探索）</strong>: ハイパーパラメータを摂動させて新しい設定を試す</li>
</ol>

<blockquote>
<p><strong>特徴</strong>: 学習中にハイパーパラメータを動的に調整できる点が、従来手法との大きな違い。</p>
</blockquote>

<h3>PBTのワークフロー</h3>

<div class="mermaid">
graph TD
    A[Population初期化<br/>n個のモデル] --> B[各モデルを並列学習]
    B --> C{定期的な評価ポイント}
    C --> D[性能の悪いモデルを特定]
    D --> E[良いモデルの重みをコピー<br/>Exploit]
    E --> F[ハイパーパラメータを摂動<br/>Explore]
    F --> G{学習終了?}
    G -->|No| B
    G -->|Yes| H[最良モデルを選択]

    style A fill:#ffebee
    style B fill:#fff3e0
    style C fill:#f3e5f5
    style E fill:#e3f2fd
    style F fill:#e8f5e9
    style H fill:#c8e6c9
</div>

<h3>Ray Tuneでの実装</h3>

<pre><code class="language-python">from ray import tune
from ray.tune.schedulers import PopulationBasedTraining
import numpy as np

def train_function(config):
    """トレーニング関数（シミュレーション）"""
    # 初期設定
    learning_rate = config["lr"]
    momentum = config["momentum"]

    # 学習のシミュレーション
    for step in range(100):
        # ダミーの性能指標（実際にはモデル訓練）
        # 学習率とモーメンタムが適切な範囲で良い性能
        optimal_lr = 0.01
        optimal_momentum = 0.9

        score = 1.0 - (
            abs(learning_rate - optimal_lr) / optimal_lr +
            abs(momentum - optimal_momentum) / optimal_momentum
        ) / 2

        # ノイズを追加してリアルな学習を模倣
        score += np.random.normal(0, 0.05)

        # Ray Tuneに結果を報告
        tune.report(score=score, lr=learning_rate, momentum=momentum)

# PBTスケジューラの設定
pbt_scheduler = PopulationBasedTraining(
    time_attr="training_iteration",
    metric="score",
    mode="max",
    perturbation_interval=10,  # 10イテレーションごとに摂動
    hyperparam_mutations={
        "lr": lambda: np.random.uniform(0.001, 0.1),
        "momentum": lambda: np.random.uniform(0.8, 0.99)
    }
)

# Ray Tuneの実行
analysis = tune.run(
    train_function,
    name="pbt_example",
    scheduler=pbt_scheduler,
    num_samples=8,  # 8個のモデルを並列実行
    config={
        "lr": tune.uniform(0.001, 0.1),
        "momentum": tune.uniform(0.8, 0.99)
    },
    stop={"training_iteration": 100},
    verbose=1
)

print("\n=== PBT 最適化結果 ===")
best_config = analysis.get_best_config(metric="score", mode="max")
print(f"最良設定:")
print(f"  Learning Rate: {best_config['lr']:.4f}")
print(f"  Momentum: {best_config['momentum']:.4f}")
print(f"\n最良スコア: {analysis.best_result['score']:.4f}")
</code></pre>

<h3>並列学習との組み合わせ</h3>

<p>PBTの最大の利点は、並列計算リソースを最大限活用できる点です：</p>

<table>
<thead>
<tr>
<th>シナリオ</th>
<th>従来手法</th>
<th>PBT</th>
</tr>
</thead>
<tbody>
<tr>
<td>8 GPUで100エポック</td>
<td>逐次に8設定を試す<br/>800エポック分の時間</td>
<td>8設定を同時学習<br/>100エポック分の時間</td>
</tr>
<tr>
<td>動的調整</td>
<td>不可</td>
<td>学習中に最適化</td>
</tr>
<tr>
<td>リソース効率</td>
<td>性能悪い設定も最後まで</td>
<td>早期に良い設定に収束</td>
</tr>
</tbody>
</table>

<hr>

<h2>3.4 その他の高度な手法</h2>

<h3>Hyperopt (TPE実装)</h3>

<p><strong>Hyperopt</strong>は、Tree-structured Parzen Estimator (TPE)を実装した人気のライブラリです。</p>

<pre><code class="language-python">from hyperopt import fmin, tpe, hp, STATUS_OK, Trials
from sklearn.datasets import load_breast_cancer
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.model_selection import cross_val_score
import numpy as np

# 探索空間の定義
space = {
    'n_estimators': hp.quniform('n_estimators', 50, 300, 1),
    'max_depth': hp.quniform('max_depth', 3, 15, 1),
    'learning_rate': hp.loguniform('learning_rate', np.log(0.001), np.log(0.3)),
    'subsample': hp.uniform('subsample', 0.5, 1.0),
    'min_samples_split': hp.quniform('min_samples_split', 2, 20, 1)
}

# データ準備
X, y = load_breast_cancer(return_X_y=True)

def objective_hyperopt(params):
    """Hyperopt用の目的関数"""
    # 整数型に変換
    params['n_estimators'] = int(params['n_estimators'])
    params['max_depth'] = int(params['max_depth'])
    params['min_samples_split'] = int(params['min_samples_split'])

    model = GradientBoostingClassifier(**params, random_state=42)
    score = cross_val_score(model, X, y, cv=5, n_jobs=-1).mean()

    # Hyperoptは最小化なので、負の値を返す
    return {'loss': -score, 'status': STATUS_OK}

# 最適化実行
trials = Trials()
best = fmin(
    fn=objective_hyperopt,
    space=space,
    algo=tpe.suggest,  # TPEアルゴリズム
    max_evals=50,
    trials=trials,
    rstate=np.random.default_rng(42)
)

print("\n=== Hyperopt (TPE) 最適化結果 ===")
print("最良パラメータ:")
for key, value in best.items():
    print(f"  {key}: {value}")
print(f"\n最良スコア: {-min(trials.losses()):.4f}")
</code></pre>

<h3>SMAC (Random Forest based)</h3>

<p><strong>SMAC (Sequential Model-based Algorithm Configuration)</strong>は、ランダムフォレストをサロゲートモデルとして使用します。</p>

<p>特徴：</p>
<ul>
<li>カテゴリカル変数と条件付きパラメータに強い</li>
<li>不確実性推定が優れている</li>
<li>ノイズの多い目的関数にロバスト</li>
</ul>

<h3>Ax/BoTorch (Facebook Research)</h3>

<p><strong>Ax</strong>と<strong>BoTorch</strong>は、Facebook Researchが開発した次世代ベイズ最適化フレームワークです。</p>

<pre><code class="language-python">from ax.service.ax_client import AxClient
from sklearn.datasets import load_wine
from sklearn.svm import SVC
from sklearn.model_selection import cross_val_score

# Axクライアントの作成
ax_client = AxClient()

# 探索空間の定義
ax_client.create_experiment(
    name="svm_optimization",
    parameters=[
        {"name": "C", "type": "range", "bounds": [0.1, 100.0], "log_scale": True},
        {"name": "gamma", "type": "range", "bounds": [0.0001, 1.0], "log_scale": True},
        {"name": "kernel", "type": "choice", "values": ["rbf", "poly", "sigmoid"]}
    ],
    objective_name="accuracy",
    minimize=False
)

# データ準備
X, y = load_wine(return_X_y=True)

# 最適化ループ
for i in range(30):
    # 次の設定を提案
    parameters, trial_index = ax_client.get_next_trial()

    # モデル評価
    model = SVC(**parameters, random_state=42)
    score = cross_val_score(model, X, y, cv=5, n_jobs=-1).mean()

    # 結果を報告
    ax_client.complete_trial(trial_index=trial_index, raw_data=score)

# 最良設定の取得
best_parameters, metrics = ax_client.get_best_parameters()

print("\n=== Ax/BoTorch 最適化結果 ===")
print("最良パラメータ:")
for key, value in best_parameters.items():
    print(f"  {key}: {value}")
print(f"\n最良精度: {metrics[0]['accuracy']:.4f}")
print(f"信頼区間: [{metrics[0]['accuracy'] - metrics[1]['accuracy']['accuracy']:.4f}, "
      f"{metrics[0]['accuracy'] + metrics[1]['accuracy']['accuracy']:.4f}]")
</code></pre>

<h3>手法比較表</h3>

<table>
<thead>
<tr>
<th>手法</th>
<th>サロゲートモデル</th>
<th>強み</th>
<th>適用場面</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Hyperopt (TPE)</strong></td>
<td>カーネル密度推定</td>
<td>シンプル、高速</td>
<td>一般的な最適化</td>
</tr>
<tr>
<td><strong>SMAC</strong></td>
<td>ランダムフォレスト</td>
<td>条件付きパラメータ</td>
<td>複雑な探索空間</td>
</tr>
<tr>
<td><strong>Ax/BoTorch</strong></td>
<td>ガウス過程</td>
<td>不確実性推定、マルチタスク</td>
<td>研究・実験</td>
</tr>
<tr>
<td><strong>Optuna</strong></td>
<td>TPE/GP/CMA-ES</td>
<td>柔軟、枝刈り</td>
<td>実用的な最適化</td>
</tr>
</tbody>
</table>

<hr>

<h2>3.5 実践: Ray Tuneによる大規模チューニング</h2>

<h3>Ray Tuneセットアップ</h3>

<p><strong>Ray Tune</strong>は、分散ハイパーパラメータチューニングのための統一フレームワークです。</p>

<pre><code class="language-python">import ray
from ray import tune
from ray.tune.schedulers import ASHAScheduler
from ray.tune.search.bayesopt import BayesOptSearch
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
import numpy as np

# Rayの初期化
ray.init(ignore_reinit_error=True)

# データ準備
X, y = make_classification(
    n_samples=10000, n_features=20, n_informative=15,
    n_redundant=5, random_state=42
)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# PyTorchデータセット
train_dataset = TensorDataset(
    torch.FloatTensor(X_train),
    torch.LongTensor(y_train)
)
test_dataset = TensorDataset(
    torch.FloatTensor(X_test),
    torch.LongTensor(y_test)
)

def train_model(config):
    """Ray Tune用のトレーニング関数"""
    # モデル定義
    model = nn.Sequential(
        nn.Linear(20, config["hidden_size_1"]),
        nn.ReLU(),
        nn.Dropout(config["dropout"]),
        nn.Linear(config["hidden_size_1"], config["hidden_size_2"]),
        nn.ReLU(),
        nn.Dropout(config["dropout"]),
        nn.Linear(config["hidden_size_2"], 2)
    )

    # 最適化器
    optimizer = optim.Adam(model.parameters(), lr=config["lr"])
    criterion = nn.CrossEntropyLoss()

    # データローダー
    train_loader = DataLoader(
        train_dataset,
        batch_size=config["batch_size"],
        shuffle=True
    )
    test_loader = DataLoader(test_dataset, batch_size=256)

    # トレーニングループ
    for epoch in range(50):
        model.train()
        for batch_X, batch_y in train_loader:
            optimizer.zero_grad()
            outputs = model(batch_X)
            loss = criterion(outputs, batch_y)
            loss.backward()
            optimizer.step()

        # 検証
        model.eval()
        correct = 0
        total = 0
        with torch.no_grad():
            for batch_X, batch_y in test_loader:
                outputs = model(batch_X)
                _, predicted = torch.max(outputs.data, 1)
                total += batch_y.size(0)
                correct += (predicted == batch_y).sum().item()

        accuracy = correct / total

        # Ray Tuneに報告
        tune.report(accuracy=accuracy, epoch=epoch)

# 探索空間
search_space = {
    "hidden_size_1": tune.choice([32, 64, 128, 256]),
    "hidden_size_2": tune.choice([16, 32, 64, 128]),
    "lr": tune.loguniform(1e-4, 1e-1),
    "batch_size": tune.choice([32, 64, 128]),
    "dropout": tune.uniform(0.1, 0.5)
}

print("=== Ray Tune セットアップ完了 ===")
print(f"探索空間: {len(search_space)}次元")
</code></pre>

<h3>PBTスケジューラの活用</h3>

<pre><code class="language-python">from ray.tune.schedulers import PopulationBasedTraining

# PBTスケジューラ
pbt = PopulationBasedTraining(
    time_attr="epoch",
    metric="accuracy",
    mode="max",
    perturbation_interval=5,
    hyperparam_mutations={
        "lr": lambda: 10 ** np.random.uniform(-4, -1),
        "dropout": lambda: np.random.uniform(0.1, 0.5)
    }
)

# Ray Tune実行（PBT）
analysis_pbt = tune.run(
    train_model,
    name="pbt_neural_net",
    scheduler=pbt,
    num_samples=8,  # 8つのモデルを並列実行
    config=search_space,
    resources_per_trial={"cpu": 2, "gpu": 0},  # GPU利用時は変更
    verbose=1
)

print("\n=== PBT実行結果 ===")
best_trial_pbt = analysis_pbt.get_best_trial("accuracy", "max", "last")
print(f"最良精度: {best_trial_pbt.last_result['accuracy']:.4f}")
print(f"最良設定:")
for key, value in best_trial_pbt.config.items():
    print(f"  {key}: {value}")
</code></pre>

<h3>分散環境での実行</h3>

<p>Ray Tuneは、複数マシンでの分散実行をサポートします：</p>

<pre><code class="language-python"># ASHAスケジューラ + ベイズ最適化
from ray.tune.schedulers import ASHAScheduler
from ray.tune.search.bayesopt import BayesOptSearch

# ASHAスケジューラ（Hyperbandの改良版）
asha_scheduler = ASHAScheduler(
    max_t=50,              # 最大エポック
    grace_period=5,        # 最小エポック
    reduction_factor=3     # 削減率
)

# ベイズ最適化サーチャー
bayesopt = BayesOptSearch(
    metric="accuracy",
    mode="max"
)

# 分散実行
analysis_distributed = tune.run(
    train_model,
    name="distributed_tuning",
    scheduler=asha_scheduler,
    search_alg=bayesopt,
    num_samples=100,  # 100試行
    config=search_space,
    resources_per_trial={"cpu": 2},
    verbose=1
)

print("\n=== 分散チューニング結果 ===")
best_trial = analysis_distributed.get_best_trial("accuracy", "max", "last")
print(f"最良精度: {best_trial.last_result['accuracy']:.4f}")
print(f"\n試行統計:")
print(f"  完了試行: {len(analysis_distributed.trials)}")
print(f"  平均精度: {np.mean([t.last_result['accuracy'] for t in analysis_distributed.trials if 'accuracy' in t.last_result]):.4f}")

# 結果の可視化
import pandas as pd

df = analysis_distributed.results_df
print(f"\n=== トップ5設定 ===")
top5 = df.nlargest(5, 'accuracy')[['accuracy', 'config/hidden_size_1', 'config/lr', 'config/dropout']]
print(top5)

# Rayのシャットダウン
ray.shutdown()
</code></pre>

<h3>Ray Tuneの利点</h3>

<table>
<thead>
<tr>
<th>機能</th>
<th>説明</th>
<th>利点</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>統一API</strong></td>
<td>複数スケジューラ/サーチャーを統一インターフェース</td>
<td>簡単に手法を切り替え</td>
</tr>
<tr>
<td><strong>分散実行</strong></td>
<td>複数マシンで自動スケーリング</td>
<td>大規模探索が可能</td>
</tr>
<tr>
<td><strong>早期停止</strong></td>
<td>ASHA、Hyperband、Medianなど</td>
<td>計算資源の節約</td>
</tr>
<tr>
<td><strong>チェックポイント</strong></td>
<td>中断・再開サポート</td>
<td>長時間実行の安全性</td>
</tr>
<tr>
<td><strong>可視化</strong></td>
<td>TensorBoard統合</td>
<td>リアルタイム監視</td>
</tr>
</tbody>
</table>

<hr>

<h2>3.6 本章のまとめ</h2>

<h3>学んだこと</h3>

<ol>
<li><p><strong>Hyperband</strong></p>
<ul>
<li>Successive Halvingで効率的なリソース配分</li>
<li>早期に性能の悪い設定を除外</li>
<li>Optunaで簡単に実装可能</li>
</ul></li>

<li><p><strong>BOHB</strong></p>
<ul>
<li>HyperbandとTPEの融合</li>
<li>効率的なリソース配分と賢い探索の両立</li>
<li>ニューラルネットワークなどで特に有効</li>
</ul></li>

<li><p><strong>Population-based Training</strong></p>
<ul>
<li>並列学習中に動的にハイパーパラメータを調整</li>
<li>Exploit（活用）とExplore（探索）のバランス</li>
<li>大規模並列環境で真価を発揮</li>
</ul></li>

<li><p><strong>その他の手法</strong></p>
<ul>
<li>Hyperopt: シンプルで高速なTPE実装</li>
<li>SMAC: 条件付きパラメータに強い</li>
<li>Ax/BoTorch: 最先端のベイズ最適化</li>
</ul></li>

<li><p><strong>Ray Tune</strong></p>
<ul>
<li>統一フレームワークで複数手法を活用</li>
<li>分散環境での大規模チューニング</li>
<li>実用的なツールとの統合</li>
</ul></li>
</ol>

<h3>手法選択ガイドライン</h3>

<table>
<thead>
<tr>
<th>シナリオ</th>
<th>推奨手法</th>
<th>理由</th>
</tr>
</thead>
<tbody>
<tr>
<td>限られた計算資源</td>
<td>Hyperband</td>
<td>効率的なリソース配分</td>
</tr>
<tr>
<td>ニューラルネット</td>
<td>BOHB、PBT</td>
<td>段階的学習と動的調整</td>
</tr>
<tr>
<td>大規模並列環境</td>
<td>PBT、Ray Tune</td>
<td>並列リソースを最大活用</td>
</tr>
<tr>
<td>条件付きパラメータ</td>
<td>SMAC</td>
<td>複雑な探索空間に対応</td>
</tr>
<tr>
<td>研究・実験</td>
<td>Ax/BoTorch</td>
<td>最先端手法とカスタマイズ性</td>
</tr>
<tr>
<td>実用的プロジェクト</td>
<td>Optuna、Ray Tune</td>
<td>使いやすさと実績</td>
</tr>
</tbody>
</table>

<h3>次の章へ</h3>

<p>第4章では、<strong>実践的な最適化戦略</strong>を学びます：</p>
<ul>
<li>探索空間の設計ベストプラクティス</li>
<li>並列化と分散実行の最適化</li>
<li>結果の分析と可視化</li>
<li>本番環境へのデプロイ</li>
</ul>

<hr>

<h2>参考文献</h2>

<ol>
<li>Li, L., et al. (2018). "Hyperband: A Novel Bandit-Based Approach to Hyperparameter Optimization". <em>Journal of Machine Learning Research</em>, 18(185), 1-52.</li>
<li>Falkner, S., Klein, A., & Hutter, F. (2018). "BOHB: Robust and Efficient Hyperparameter Optimization at Scale". <em>ICML 2018</em>.</li>
<li>Jaderberg, M., et al. (2017). "Population Based Training of Neural Networks". <em>arXiv:1711.09846</em>.</li>
<li>Liaw, R., et al. (2018). "Tune: A Research Platform for Distributed Model Selection and Training". <em>arXiv:1807.05118</em>.</li>
<li>Bergstra, J., et al. (2013). "Making a Science of Model Search: Hyperparameter Optimization in Hundreds of Dimensions for Vision Architectures". <em>ICML 2013</em>.</li>
</ol>

<div class="navigation">
    <a href="chapter2-bayesian-optimization.html" class="nav-button">← 前の章: ベイズ最適化</a>
    <a href="chapter4-practical-strategies.html" class="nav-button">次の章: 実践的最適化戦略 →</a>
</div>

    </main>

    <footer>
        <p><strong>作成者</strong>: AI Terakoya Content Team</p>
        <p><strong>監修</strong>: Dr. Yusuke Hashimoto（東北大学）</p>
        <p><strong>バージョン</strong>: 1.0 | <strong>作成日</strong>: 2025-10-21</p>
        <p><strong>ライセンス</strong>: Creative Commons BY 4.0</p>
        <p>© 2025 AI Terakoya. All rights reserved.</p>
    </footer>
</body>
</html>
