<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>第2章：機械学習の基礎知識 - 概念・手法・エコシステム - AI Terakoya</title>

    <style>
        :root {
            --color-primary: #2c3e50;
            --color-primary-dark: #1a252f;
            --color-accent: #667eea;
            --color-accent-light: #764ba2;
            --color-text: #2d3748;
            --color-text-light: #4a5568;
            --color-bg: #ffffff;
            --color-bg-alt: #f7fafc;
            --color-border: #e2e8f0;
            --color-code-bg: #f8f9fa;
            --color-link: #3182ce;
            --color-link-hover: #2c5aa0;

            --spacing-xs: 0.5rem;
            --spacing-sm: 1rem;
            --spacing-md: 1.5rem;
            --spacing-lg: 2rem;
            --spacing-xl: 3rem;

            --font-body: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            --font-mono: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;

            --border-radius: 8px;
            --box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: var(--font-body);
            line-height: 1.7;
            color: var(--color-text);
            background-color: var(--color-bg);
            font-size: 16px;
        }

        header {
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            padding: var(--spacing-xl) var(--spacing-md);
            margin-bottom: var(--spacing-xl);
            box-shadow: var(--box-shadow);
        }

        .header-content {
            max-width: 900px;
            margin: 0 auto;
        }

        h1 {
            font-size: 2rem;
            font-weight: 700;
            margin-bottom: var(--spacing-sm);
            line-height: 1.2;
        }

        .subtitle {
            font-size: 1.1rem;
            opacity: 0.95;
            font-weight: 400;
            margin-bottom: var(--spacing-md);
        }

        .meta {
            display: flex;
            flex-wrap: wrap;
            gap: var(--spacing-md);
            font-size: 0.9rem;
            opacity: 0.9;
        }

        .meta-item {
            display: flex;
            align-items: center;
            gap: 0.3rem;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 0 var(--spacing-md) var(--spacing-xl);
        }

        h2 {
            font-size: 1.75rem;
            color: var(--color-primary);
            margin-top: var(--spacing-xl);
            margin-bottom: var(--spacing-md);
            padding-bottom: var(--spacing-xs);
            border-bottom: 3px solid var(--color-accent);
        }

        h3 {
            font-size: 1.4rem;
            color: var(--color-primary);
            margin-top: var(--spacing-lg);
            margin-bottom: var(--spacing-sm);
        }

        h4 {
            font-size: 1.1rem;
            color: var(--color-primary-dark);
            margin-top: var(--spacing-md);
            margin-bottom: var(--spacing-sm);
        }

        p {
            margin-bottom: var(--spacing-md);
            color: var(--color-text);
        }

        a {
            color: var(--color-link);
            text-decoration: none;
            transition: color 0.2s;
        }

        a:hover {
            color: var(--color-link-hover);
            text-decoration: underline;
        }

        ul, ol {
            margin-left: var(--spacing-lg);
            margin-bottom: var(--spacing-md);
        }

        li {
            margin-bottom: var(--spacing-xs);
            color: var(--color-text);
        }

        pre {
            background-color: var(--color-code-bg);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            overflow-x: auto;
            margin-bottom: var(--spacing-md);
            font-family: var(--font-mono);
            font-size: 0.9rem;
            line-height: 1.5;
        }

        code {
            font-family: var(--font-mono);
            font-size: 0.9em;
            background-color: var(--color-code-bg);
            padding: 0.2em 0.4em;
            border-radius: 3px;
        }

        pre code {
            background-color: transparent;
            padding: 0;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: var(--spacing-md);
            font-size: 0.95rem;
        }

        th, td {
            border: 1px solid var(--color-border);
            padding: var(--spacing-sm);
            text-align: left;
        }

        th {
            background-color: var(--color-bg-alt);
            font-weight: 600;
            color: var(--color-primary);
        }

        blockquote {
            border-left: 4px solid var(--color-accent);
            padding-left: var(--spacing-md);
            margin: var(--spacing-md) 0;
            color: var(--color-text-light);
            font-style: italic;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        .mermaid {
            text-align: center;
            margin: var(--spacing-lg) 0;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        details {
            background-color: var(--color-bg-alt);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            margin-bottom: var(--spacing-md);
        }

        summary {
            cursor: pointer;
            font-weight: 600;
            color: var(--color-primary);
            user-select: none;
            padding: var(--spacing-xs);
            margin: calc(-1 * var(--spacing-md));
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        summary:hover {
            background-color: rgba(102, 126, 234, 0.1);
        }

        details[open] summary {
            margin-bottom: var(--spacing-md);
            border-bottom: 1px solid var(--color-border);
        }

        .learning-objectives {
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
            padding: var(--spacing-lg);
            border-radius: var(--border-radius);
            border-left: 4px solid var(--color-accent);
            margin-bottom: var(--spacing-xl);
        }

        .learning-objectives h2 {
            margin-top: 0;
            border-bottom: none;
        }

        .navigation {
            display: flex;
            justify-content: space-between;
            gap: var(--spacing-md);
            margin: var(--spacing-xl) 0;
            padding-top: var(--spacing-lg);
            border-top: 2px solid var(--color-border);
        }

        .nav-button {
            flex: 1;
            padding: var(--spacing-md);
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            border-radius: var(--border-radius);
            text-align: center;
            font-weight: 600;
            transition: transform 0.2s, box-shadow 0.2s;
            box-shadow: var(--box-shadow);
        }

        .nav-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
            text-decoration: none;
        }

        footer {
            margin-top: var(--spacing-xl);
            padding: var(--spacing-lg) var(--spacing-md);
            background-color: var(--color-bg-alt);
            border-top: 1px solid var(--color-border);
            text-align: center;
            font-size: 0.9rem;
            color: var(--color-text-light);
        }

        .highlight-box {
            background: linear-gradient(135deg, #e3f2fd 0%, #bbdefb 100%);
            border-left: 4px solid #2196f3;
            padding: var(--spacing-md);
            margin: var(--spacing-md) 0;
            border-radius: var(--border-radius);
        }

        @media (max-width: 768px) {
            h1 {
                font-size: 1.5rem;
            }

            h2 {
                font-size: 1.4rem;
            }

            h3 {
                font-size: 1.2rem;
            }

            .meta {
                font-size: 0.85rem;
            }

            .navigation {
                flex-direction: column;
            }

            table {
                font-size: 0.85rem;
            }

            th, td {
                padding: var(--spacing-xs);
            }
        }
    </style>

    <script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
    <script>
        mermaid.initialize({ startOnLoad: true, theme: 'default', securityLevel: 'strict' });
    </script>

    <!-- MathJax for LaTeX equation rendering -->
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                displayMath: [['$$', '$$'], ['\\[', '\\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
                ignoreHtmlClass: 'mermaid'
            }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" async></script>
</head>
<body>
    <header>
        <div class="header-content">
            <h1>第2章：機械学習の基礎知識</h1>
            <p class="subtitle">概念・手法・エコシステム</p>
            <div class="meta">
                <span class="meta-item">📖 読了時間: 20-25分</span>
                <span class="meta-item">📊 難易度: 入門〜中級</span>
                <span class="meta-item">💻 コード例: 5個</span>
                <span class="meta-item">📝 演習問題: 4問</span>
            </div>
        </div>
    </header>

    <main class="container">
        <p class="chapter-description" style="margin: 1.5rem 0; padding: 1rem; background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%); border-left: 4px solid #667eea; border-radius: 8px; font-size: 1.05rem; line-height: 1.8; color: #2d3748;">
            この章では、機械学習の基本概念、3つの学習タイプ、主要なアルゴリズム、そして実践的なワークフローを学びます。専門用語を理解し、実装への準備を整えます。
        </p>

        <div class="learning-objectives">
            <h2>学習目標</h2>
            <p>この章を完了すると、以下のスキルを習得できます：</p>
            <ul>
                <li>機械学習の定義と3つの学習タイプ（教師あり・教師なし・強化学習）を説明できる</li>
                <li>20の重要なML用語を適切に使用できる</li>
                <li>4つの主要フレームワーク（scikit-learn、PyTorch、TensorFlow、XGBoost）の特徴と使い分けを理解している</li>
                <li>機械学習ワークフロー全7ステップを詳細に説明できる</li>
                <li>特徴量の種類と変換方法を理解し、実装できる</li>
            </ul>
        </div>

        <h2>2.1 機械学習の定義と分類</h2>

        <h3>2.1.1 機械学習とは</h3>

        <p><strong>機械学習（Machine Learning: ML）</strong>は、データから自動的にパターンを学習し、予測や判断を行うコンピュータプログラムの総称です。</p>

        <p><strong>古典的定義</strong>（Arthur Samuel, 1959）：</p>
        <blockquote>
            "明示的にプログラムすることなく、コンピュータに学習する能力を与える研究分野"
        </blockquote>

        <p><strong>形式的定義</strong>（Tom Mitchell, 1997）：</p>
        <blockquote>
            "タスクTにおいて、経験Eから学習し、性能指標Pで測定した性能が向上するプログラム"
        </blockquote>

        <p><strong>具体例で理解する：</strong></p>
        <ul>
            <li><strong>タスクT</strong>：スパムメールの判定</li>
            <li><strong>経験E</strong>：過去のメール（スパム/非スパムのラベル付き）</li>
            <li><strong>性能P</strong>：判定精度（正答率）</li>
        </ul>

        <p>システムが過去のメールデータから学習し、新しいメールをスパムか否か判定する精度が向上すれば、それは「機械学習している」と言えます。</p>

        <h4>AI、ML、DLの関係</h4>

        <div class="mermaid">
graph TD
    A[人工知能 AI<br/>Artificial Intelligence] --> B[機械学習 ML<br/>Machine Learning]
    B --> C[深層学習 DL<br/>Deep Learning]

    A1[知的な振る舞いを<br/>示すシステム全般] -.-> A
    B1[データから<br/>パターンを学習] -.-> B
    C1[ニューラルネットワーク<br/>を使った学習] -.-> C

    style A fill:#e3f2fd
    style B fill:#fff3e0
    style C fill:#f3e5f5
        </div>

        <p><strong>包含関係：</strong></p>
        <ul>
            <li><strong>AI（人工知能）</strong>：最も広い概念。チェスプログラム、チャットボット、自動運転など、知的な振る舞いを示すシステム全般</li>
            <li><strong>ML（機械学習）</strong>：AIの一手法。データから自動的に学習する技術</li>
            <li><strong>DL（深層学習）</strong>：MLの一種。多層ニューラルネットワークを使った学習手法</li>
        </ul>

        <h3>2.1.2 機械学習の3つの学習タイプ</h3>

        <p>機械学習は、データの種類と学習方法によって3つに大別されます。</p>

        <h4>1. 教師あり学習（Supervised Learning）</h4>

        <p><strong>定義：</strong> ラベル付きデータ（入力と正解のペア）から学習する手法</p>

        <p><strong>仕組み：</strong></p>
        <pre><code>入力データ（特徴量） + 正解ラベル → モデル訓練 → 予測</code></pre>

        <p><strong>具体例：</strong></p>
        <ul>
            <li><strong>スパム判定</strong>：メール本文（入力）→ スパム/非スパム（正解）</li>
            <li><strong>価格予測</strong>：住宅の特徴（広さ、築年数、立地）→ 価格</li>
            <li><strong>画像分類</strong>：猫の画像 → "猫"というラベル</li>
            <li><strong>音声認識</strong>：音声データ → テキスト</li>
        </ul>

        <p><strong>主要アルゴリズム：</strong></p>
        <ul>
            <li><strong>線形回帰</strong>（Linear Regression）：連続値の予測</li>
            <li><strong>ロジスティック回帰</strong>（Logistic Regression）：2値分類</li>
            <li><strong>決定木</strong>（Decision Tree）：条件分岐による分類</li>
            <li><strong>サポートベクターマシン</strong>（SVM）：最適な境界線を学習</li>
            <li><strong>ニューラルネットワーク</strong>（Neural Network）：複雑なパターン学習</li>
        </ul>

        <h4>2. 教師なし学習（Unsupervised Learning）</h4>

        <p><strong>定義：</strong> ラベルなしデータから、隠れたパターンや構造を発見する手法</p>

        <p><strong>仕組み：</strong></p>
        <pre><code>入力データのみ（正解なし） → モデル → パターン発見</code></pre>

        <p><strong>具体例：</strong></p>
        <ul>
            <li><strong>顧客セグメンテーション</strong>：購買履歴から顧客をグループ分け</li>
            <li><strong>異常検知</strong>：通常と異なるパターンを検出（不正取引、機器故障）</li>
            <li><strong>次元削減</strong>：高次元データを2-3次元に圧縮して可視化</li>
            <li><strong>推薦システム</strong>：類似商品の発見</li>
        </ul>

        <p><strong>主要アルゴリズム：</strong></p>
        <ul>
            <li><strong>K-means</strong>：データをK個のクラスタに分割</li>
            <li><strong>階層クラスタリング</strong>：樹形図でグループ構造を表現</li>
            <li><strong>主成分分析（PCA）</strong>：データの主要な方向を抽出</li>
            <li><strong>自己組織化マップ（SOM）</strong>：データの分布を可視化</li>
        </ul>

        <h4>3. 強化学習（Reinforcement Learning）</h4>

        <p><strong>定義：</strong> 試行錯誤を通じて、報酬を最大化する行動を学習する手法</p>

        <p><strong>仕組み：</strong></p>
        <pre><code>エージェント → 行動 → 環境 → 報酬・状態フィードバック → 学習</code></pre>

        <p><strong>主要概念：</strong></p>
        <ul>
            <li><strong>エージェント</strong>：学習する主体（例：ゲームAI、ロボット）</li>
            <li><strong>環境</strong>：エージェントが行動する場（例：ゲーム盤面、実世界）</li>
            <li><strong>行動</strong>：エージェントが選択する操作</li>
            <li><strong>報酬</strong>：行動の良し悪しを示す数値（+で良い、-で悪い）</li>
            <li><strong>方策</strong>：状態から行動への写像（「この状況ではこう行動する」）</li>
        </ul>

        <p><strong>具体例：</strong></p>
        <ul>
            <li><strong>ゲームAI</strong>：AlphaGo（囲碁）、Dota 2、Atariゲーム</li>
            <li><strong>ロボット制御</strong>：二足歩行、物体把持、ドローン飛行</li>
            <li><strong>自動運転</strong>：車線維持、障害物回避</li>
            <li><strong>推薦システム</strong>：ユーザー反応から最適な推薦を学習</li>
        </ul>

        <h4>3つの学習タイプの比較</h4>

        <table>
            <thead>
                <tr>
                    <th>学習タイプ</th>
                    <th>データ</th>
                    <th>目的</th>
                    <th>適用例</th>
                    <th>難易度</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td><strong>教師あり学習</strong></td>
                    <td>ラベル付き</td>
                    <td>予測・分類</td>
                    <td>スパム判定、価格予測、画像認識</td>
                    <td>中</td>
                </tr>
                <tr>
                    <td><strong>教師なし学習</strong></td>
                    <td>ラベルなし</td>
                    <td>パターン発見</td>
                    <td>顧客分析、異常検知、データ圧縮</td>
                    <td>高</td>
                </tr>
                <tr>
                    <td><strong>強化学習</strong></td>
                    <td>報酬シグナル</td>
                    <td>行動最適化</td>
                    <td>ゲームAI、ロボット、自動運転</td>
                    <td>最高</td>
                </tr>
            </tbody>
        </table>

        <h4>学習タイプの選択フローチャート</h4>

        <div class="mermaid">
graph TD
    A[解きたい問題] --> B{正解データは<br/>ある？}
    B -->|Yes| C{出力は何？}
    B -->|No| D{目的は？}

    C -->|連続値<br/>例:価格| E[回帰<br/>Linear Regression]
    C -->|カテゴリ<br/>例:スパム/非スパム| F[分類<br/>Logistic Regression<br/>Decision Tree]

    D -->|グループ分け| G[クラスタリング<br/>K-means]
    D -->|次元削減| H[次元削減<br/>PCA]
    D -->|異常検知| I[異常検知<br/>Isolation Forest]

    J{試行錯誤で<br/>最適化？} -->|Yes| K[強化学習<br/>Q-learning<br/>DQN]

    style E fill:#e8f5e9
    style F fill:#e8f5e9
    style G fill:#fff3e0
    style H fill:#fff3e0
    style I fill:#fff3e0
    style K fill:#f3e5f5
        </div>

        <h2>2.2 機械学習の重要用語集（20語）</h2>

        <p>機械学習を学ぶ上で必須となる専門用語を、カテゴリ別に整理しました。各用語は日本語・英語・定義・具体例の4点セットで理解しましょう。</p>

        <h3>基礎用語（8語）</h3>

        <table>
            <thead>
                <tr>
                    <th>用語（日本語）</th>
                    <th>用語（英語）</th>
                    <th>定義と具体例</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td><strong>1. 特徴量</strong></td>
                    <td>Feature</td>
                    <td>モデルへの入力となるデータの属性や性質。住宅価格予測なら「広さ、築年数、駅距離」など。特徴量の質がモデル性能を大きく左右します。適切な特徴量を設計することを「特徴量エンジニアリング」と呼びます。</td>
                </tr>
                <tr>
                    <td><strong>2. ラベル</strong></td>
                    <td>Label</td>
                    <td>教師あり学習における正解データ。スパム判定なら「スパム」「非スパム」のラベル、住宅価格予測なら「価格」の数値。ラベル付きデータの収集はコストがかかるため、データ数が限られることが多いです。</td>
                </tr>
                <tr>
                    <td><strong>3. 訓練データ</strong></td>
                    <td>Training Data</td>
                    <td>モデルの学習に使うデータセット。全データの70-80%を訓練に使うのが一般的。訓練データが多いほど、モデルは複雑なパターンを学習できますが、過学習のリスクも増えます。</td>
                </tr>
                <tr>
                    <td><strong>4. テストデータ</strong></td>
                    <td>Test Data</td>
                    <td>学習済みモデルの性能を評価するための未学習データ。全データの20-30%を使用。重要：テストデータは学習に一切使わず、最終評価のみに使います。テストデータで高性能なら汎化性能が高いと判断できます。</td>
                </tr>
                <tr>
                    <td><strong>5. モデル</strong></td>
                    <td>Model</td>
                    <td>入力から出力への写像を表現する数式やプログラム。線形回帰なら $y = wx + b$ という数式、ニューラルネットワークなら多層の計算グラフ。訓練により、モデルのパラメータ（重みw、バイアスb）が最適化されます。</td>
                </tr>
                <tr>
                    <td><strong>6. 予測</strong></td>
                    <td>Prediction</td>
                    <td>学習済みモデルが新しい入力データに対して出力する値。回帰なら連続値（例：価格3,500万円）、分類ならクラス（例：スパム）。予測精度を向上させることが機械学習の主目的です。</td>
                </tr>
                <tr>
                    <td><strong>7. 損失関数</strong></td>
                    <td>Loss Function</td>
                    <td>予測値と正解との差（誤差）を数値化する関数。回帰では平均二乗誤差（MSE）、分類では交差エントロピーがよく使われます。学習の目的は損失関数を最小化することです。損失が小さいほど予測精度が高いことを意味します。</td>
                </tr>
                <tr>
                    <td><strong>8. 過学習</strong></td>
                    <td>Overfitting</td>
                    <td>訓練データに過度に適合し、未知データへの予測性能が低下する現象。訓練精度は高いがテスト精度が低い場合に発生。対策：データ数を増やす、モデルを単純化、正則化、交差検証など。機械学習で最も注意すべき問題の一つです。</td>
                </tr>
            </tbody>
        </table>

        <h3>手法用語（7語）</h3>

        <table>
            <thead>
                <tr>
                    <th>用語（日本語）</th>
                    <th>用語（英語）</th>
                    <th>定義と具体例</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td><strong>9. 回帰</strong></td>
                    <td>Regression</td>
                    <td>連続値を予測するタスク。住宅価格、株価、気温などの数値予測。代表的手法：線形回帰、リッジ回帰、ランダムフォレスト。出力が「3,500万円」「25.3℃」のように具体的な数値になります。</td>
                </tr>
                <tr>
                    <td><strong>10. 分類</strong></td>
                    <td>Classification</td>
                    <td>カテゴリ（クラス）を予測するタスク。スパム判定、病気診断、画像認識など。2値分類（Yes/No）と多クラス分類（猫/犬/鳥）があります。出力は「スパム」「良性」「猫」などのラベルです。</td>
                </tr>
                <tr>
                    <td><strong>11. クラスタリング</strong></td>
                    <td>Clustering</td>
                    <td>正解ラベルなしでデータをグループ分けする教師なし学習。顧客セグメンテーション、文書分類、画像圧縮などに使用。K-meansでは事前にグループ数Kを指定し、データを自動的にK個に分割します。</td>
                </tr>
                <tr>
                    <td><strong>12. 交差検証</strong></td>
                    <td>Cross-Validation</td>
                    <td>データをK個に分割し、1つをテスト、残りを訓練に使う操作をK回繰り返す手法。K-fold交差検証（K=5や10が一般的）により、モデルの汎化性能を正確に評価できます。データが少ない場合に特に有効です。</td>
                </tr>
                <tr>
                    <td><strong>13. ハイパーパラメータ</strong></td>
                    <td>Hyperparameter</td>
                    <td>学習前に人間が設定する調整項目。学習率、木の深さ、ニューロン数など。モデルのパラメータ（重みw、バイアスb）とは異なり、訓練では更新されません。Grid SearchやRandom Searchで最適値を探索します。</td>
                </tr>
                <tr>
                    <td><strong>14. 正則化</strong></td>
                    <td>Regularization</td>
                    <td>過学習を防ぐためにモデルの複雑さにペナルティを課す手法。L1正則化（Lasso）はパラメータをゼロに近づけ、L2正則化（Ridge）は小さな値に抑制します。正則化により汎化性能が向上します。</td>
                </tr>
                <tr>
                    <td><strong>15. アンサンブル</strong></td>
                    <td>Ensemble</td>
                    <td>複数のモデルの予測を組み合わせて精度を向上させる手法。バギング（Random Forest）、ブースティング（XGBoost）、スタッキングなど。「三人寄れば文殊の知恵」の原理で、単一モデルより高精度になることが多いです。</td>
                </tr>
            </tbody>
        </table>

        <h3>評価用語（5語）</h3>

        <table>
            <thead>
                <tr>
                    <th>用語（日本語）</th>
                    <th>用語（英語）</th>
                    <th>定義と具体例</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td><strong>16. 精度</strong></td>
                    <td>Accuracy</td>
                    <td>全予測のうち正解した割合。計算式：$\text{Accuracy} = \frac{\text{正解数}}{\text{全データ数}}$。100個中85個正解なら精度85%。シンプルだが、データが偏っている場合（スパム1% vs 非スパム99%）は誤解を招く指標です。</td>
                </tr>
                <tr>
                    <td><strong>17. 再現率</strong></td>
                    <td>Recall</td>
                    <td>実際の正例のうち、正しく検出できた割合。計算式：$\text{Recall} = \frac{\text{真陽性}}{\text{真陽性 + 偽陰性}}$。病気診断で「病気の人を見逃さない」ことが重要な場合に重視。再現率が高いほど見逃しが少ないです。</td>
                </tr>
                <tr>
                    <td><strong>18. 適合率</strong></td>
                    <td>Precision</td>
                    <td>モデルが正と予測したもののうち、実際に正だった割合。計算式：$\text{Precision} = \frac{\text{真陽性}}{\text{真陽性 + 偽陽性}}$。スパム判定で「非スパムをスパムと誤判定しない」ことが重要な場合に重視。適合率が高いほど誤検知が少ないです。</td>
                </tr>
                <tr>
                    <td><strong>19. F1スコア</strong></td>
                    <td>F1 Score</td>
                    <td>適合率と再現率の調和平均。計算式：$\text{F1} = 2 \times \frac{\text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}$。両方のバランスを取る指標で、どちらか一方だけが高くても良いスコアになりません。データが不均衡な場合に精度より有用です。</td>
                </tr>
                <tr>
                    <td><strong>20. AUC-ROC</strong></td>
                    <td>AUC-ROC</td>
                    <td>ROC曲線（横軸：偽陽性率、縦軸：真陽性率）の下側面積。0.5は完全ランダム、1.0は完全分類を意味します。閾値に依存しない評価指標で、分類器の総合的な性能を示します。AUC=0.9以上なら優秀なモデルと評価されます。</td>
                </tr>
            </tbody>
        </table>

        <h2>2.3 主要フレームワーク比較</h2>

        <p>機械学習の実装には、目的に応じたフレームワークの選択が重要です。ここでは4つの主要フレームワークを詳しく比較します。</p>

        <h3>2.3.1 scikit-learn（サイキットラーン）</h3>

        <p><strong>特徴：</strong> Pythonで最も広く使われる汎用機械学習ライブラリ</p>

        <p><strong>強み：</strong></p>
        <ul>
            <li><strong>初学者向け</strong>：統一されたAPIで使いやすい（fit、predict、scoreの3メソッドが基本）</li>
            <li><strong>古典的ML手法が充実</strong>：回帰、分類、クラスタリング、次元削減など</li>
            <li><strong>ドキュメント充実</strong>：公式ドキュメントが詳細でサンプルコード豊富</li>
            <li><strong>前処理機能</strong>：スケーリング、エンコーディング、特徴選択など</li>
        </ul>

        <p><strong>弱み：</strong></p>
        <ul>
            <li>深層学習には非対応（ニューラルネットワークは浅いもののみ）</li>
            <li>大規模データ（数百GB以上）では遅い</li>
            <li>GPU利用不可</li>
        </ul>

        <p><strong>適用場面：</strong></p>
        <ul>
            <li>表形式データ（CSV、Excelなど）の分析</li>
            <li>小〜中規模データ（数万〜数百万サンプル）</li>
            <li>プロトタイピング、ベースライン作成</li>
            <li>教育・学習目的</li>
        </ul>

        <h3>2.3.2 PyTorch（パイトーチ）</h3>

        <p><strong>特徴：</strong> Meta（旧Facebook）開発の深層学習フレームワーク</p>

        <p><strong>強み：</strong></p>
        <ul>
            <li><strong>研究向け</strong>：柔軟性が高く、新しいアーキテクチャを実装しやすい</li>
            <li><strong>Pythonic</strong>：Pythonらしい書き方ができ、デバッグが容易</li>
            <li><strong>動的計算グラフ</strong>：実行時にグラフを構築するため直感的</li>
            <li><strong>研究コミュニティ</strong>：最新論文の実装が豊富（GitHub）</li>
        </ul>

        <p><strong>弱み：</strong></p>
        <ul>
            <li>本番環境へのデプロイがやや複雑</li>
            <li>モデルの最適化・圧縮はTensorFlowより少ない</li>
        </ul>

        <p><strong>適用場面：</strong></p>
        <ul>
            <li>深層学習の研究開発</li>
            <li>カスタムモデルの実装（新しいアーキテクチャ）</li>
            <li>画像認識、自然言語処理、音声認識</li>
            <li>学術論文の再現実装</li>
        </ul>

        <h3>2.3.3 TensorFlow / Keras（テンソルフロー / ケラス）</h3>

        <p><strong>特徴：</strong> Google開発の本番環境向け深層学習フレームワーク（Kerasは高水準API）</p>

        <p><strong>強み：</strong></p>
        <ul>
            <li><strong>本番環境向け</strong>：TensorFlow Servingで簡単にデプロイ</li>
            <li><strong>スケーラビリティ</strong>：分散学習、マルチGPU対応が充実</li>
            <li><strong>Keras統合</strong>：高水準APIで簡潔にモデル構築可能</li>
            <li><strong>エコシステム</strong>：TensorFlow Lite（モバイル）、TensorFlow.js（Web）など</li>
        </ul>

        <p><strong>弱み：</strong></p>
        <ul>
            <li>学習曲線がやや急（初学者には難しい部分も）</li>
            <li>デバッグがPyTorchより難しい（静的計算グラフ）</li>
        </ul>

        <p><strong>適用場面：</strong></p>
        <ul>
            <li>本番環境へのデプロイが前提のプロジェクト</li>
            <li>大規模システム（クラウド、分散学習）</li>
            <li>モバイルアプリへのML組み込み</li>
            <li>企業での実用化</li>
        </ul>

        <h3>2.3.4 XGBoost / LightGBM（エックスジーブースト / ライトジービーエム）</h3>

        <p><strong>特徴：</strong> 勾配ブースティングに特化した高速ライブラリ</p>

        <p><strong>強み：</strong></p>
        <ul>
            <li><strong>表形式データで最高性能</strong>：Kaggleコンペで圧倒的シェア</li>
            <li><strong>高速</strong>：大規模データでも短時間で学習</li>
            <li><strong>特徴量重要度</strong>：どの特徴量が重要か自動評価</li>
            <li><strong>欠損値対応</strong>：欠損値を自動で扱える</li>
        </ul>

        <p><strong>弱み：</strong></p>
        <ul>
            <li>画像・テキストデータには不向き（CNNやRNNが必要）</li>
            <li>ハイパーパラメータ調整が複雑</li>
        </ul>

        <p><strong>適用場面：</strong></p>
        <ul>
            <li>表形式データ（CSV、データベース）の分類・回帰</li>
            <li>Kaggleなどのデータ分析コンペ</li>
            <li>ビジネスデータ分析（売上予測、顧客離反予測）</li>
            <li>構造化データで高精度が求められる場面</li>
        </ul>

        <h3>フレームワーク比較表</h3>

        <table>
            <thead>
                <tr>
                    <th>フレームワーク</th>
                    <th>得意分野</th>
                    <th>学習難易度</th>
                    <th>速度</th>
                    <th>本番環境</th>
                    <th>GPU対応</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td><strong>scikit-learn</strong></td>
                    <td>古典的ML、表形式データ</td>
                    <td>易</td>
                    <td>中</td>
                    <td>△</td>
                    <td>×</td>
                </tr>
                <tr>
                    <td><strong>PyTorch</strong></td>
                    <td>深層学習、研究開発</td>
                    <td>中</td>
                    <td>高（GPU）</td>
                    <td>○</td>
                    <td>◎</td>
                </tr>
                <tr>
                    <td><strong>TensorFlow/Keras</strong></td>
                    <td>本番環境、大規模システム</td>
                    <td>中〜高</td>
                    <td>高（GPU）</td>
                    <td>◎</td>
                    <td>◎</td>
                </tr>
                <tr>
                    <td><strong>XGBoost/LightGBM</strong></td>
                    <td>表形式データ、コンペ</td>
                    <td>中</td>
                    <td>高（CPU）</td>
                    <td>○</td>
                    <td>△</td>
                </tr>
            </tbody>
        </table>

        <h3>フレームワーク選択フローチャート</h3>

        <div class="mermaid">
graph TD
    A[扱うデータの種類は？] --> B{表形式データ<br/>CSV/Excel}
    A --> C{画像・テキスト・音声}

    B --> D{データサイズ}
    D -->|小〜中<br/>10万行以下| E[scikit-learn<br/>初学者向け]
    D -->|大<br/>10万行以上| F[XGBoost/LightGBM<br/>高精度・高速]

    C --> G{目的は？}
    G -->|研究・実験| H[PyTorch<br/>柔軟性重視]
    G -->|本番デプロイ| I[TensorFlow/Keras<br/>スケーラビリティ重視]

    style E fill:#e8f5e9
    style F fill:#e8f5e9
    style H fill:#f3e5f5
    style I fill:#fff3e0
        </div>

        <h2>2.4 機械学習エコシステム</h2>

        <p>機械学習プロジェクトは、データ収集から本番運用まで複数のステップで構成されます。全体像を理解することが重要です。</p>

        <div class="mermaid">
graph LR
    A[データソース<br/>DB/API/ファイル] --> B[データ収集<br/>Scraping/ETL]
    B --> C[データストレージ<br/>Data Lake/DWH]
    C --> D[前処理<br/>クリーニング/正規化]
    D --> E[特徴量エンジニアリング<br/>変換/選択/生成]
    E --> F[モデル訓練<br/>学習/調整]
    F --> G[評価<br/>精度検証]
    G --> H{性能OK?}
    H -->|No| I[ハイパーパラメータ調整<br/>特徴量追加]
    I --> F
    H -->|Yes| J[デプロイ<br/>本番環境]
    J --> K[モニタリング<br/>性能監視]
    K --> L[フィードバック<br/>データ追加]
    L --> B

    style A fill:#e3f2fd
    style F fill:#fff3e0
    style J fill:#e8f5e9
    style K fill:#ffebee
        </div>

        <p><strong>各コンポーネントの役割：</strong></p>

        <ul>
            <li><strong>データソース</strong>：データベース、API、センサー、ファイル、Webスクレイピングなど</li>
            <li><strong>データストレージ</strong>：Data Lake（生データ保存）、Data Warehouse（整形済みデータ）</li>
            <li><strong>前処理</strong>：欠損値処理、外れ値除去、データクリーニング</li>
            <li><strong>特徴量エンジニアリング</strong>：MLモデルに適した形式への変換</li>
            <li><strong>モデル訓練</strong>：アルゴリズム選択、学習、ハイパーパラメータ調整</li>
            <li><strong>評価</strong>：交差検証、テストデータでの精度確認</li>
            <li><strong>デプロイ</strong>：本番環境へのモデル配置（API化、組み込み）</li>
            <li><strong>モニタリング</strong>：予測精度の監視、モデルの劣化検知</li>
            <li><strong>フィードバック</strong>：新データの収集、モデルの再訓練</li>
        </ul>

        <h2>2.5 機械学習ワークフロー詳細（7ステップ）</h2>

        <p>実際の機械学習プロジェクトは、以下の7ステップで進行します。各ステップの詳細、時間見積もり、注意点を理解しましょう。</p>

        <h3>Step 0：問題定式化（最も重要、見落とされがち）</h3>

        <p><strong>目的：</strong> 解くべき問題をML的に定義する</p>

        <p><strong>実施内容：</strong></p>
        <ul>
            <li><strong>問題タイプの特定</strong>：回帰？分類？クラスタリング？</li>
            <li><strong>成功指標（KPI）の定義</strong>：精度80%以上、F1スコア0.9など</li>
            <li><strong>データ可用性の確認</strong>：必要なデータは入手可能か？</li>
            <li><strong>制約条件の整理</strong>：予算、期限、計算リソース</li>
        </ul>

        <p><strong>時間見積もり：</strong> 1-2週間（ステークホルダーとの議論含む）</p>

        <p><strong>よくある失敗：</strong></p>
        <ul>
            <li>問題定式化をスキップして、いきなりコーディング開始</li>
            <li>ビジネス目標とML目標の不一致</li>
            <li>達成不可能な精度目標の設定</li>
        </ul>

        <p><strong>具体例：</strong></p>
        <blockquote>
            <p><strong>ビジネス課題：</strong> 顧客離反を減らしたい</p>
            <p><strong>ML問題定式化：</strong></p>
            <ul>
                <li>タスク：2値分類（離反する/しない）</li>
                <li>入力：顧客属性（年齢、契約期間、購買履歴）</li>
                <li>出力：離反確率</li>
                <li>成功指標：再現率（Recall）80%以上（離反者を見逃さない）</li>
                <li>データ：過去2年間の顧客データ10万件</li>
            </ul>
        </blockquote>

        <h3>Step 1：データ収集</h3>

        <p><strong>目的：</strong> 学習に必要なデータを集める</p>

        <p><strong>データソース：</strong></p>
        <ul>
            <li><strong>社内データ</strong>：データベース、ログ、CRM</li>
            <li><strong>公開データ</strong>：Kaggle、UCI ML Repository、政府統計</li>
            <li><strong>API</strong>：Twitter API、Google Maps API</li>
            <li><strong>Webスクレイピング</strong>：BeautifulSoup、Scrapy</li>
            <li><strong>アノテーション</strong>：人手によるラベル付け</li>
        </ul>

        <p><strong>必要データ量の目安：</strong></p>
        <ul>
            <li><strong>最低限</strong>：100サンプル（プロトタイプ）</li>
            <li><strong>推奨</strong>：1,000〜10,000サンプル（古典的ML）</li>
            <li><strong>理想</strong>：10,000〜1,000,000サンプル（深層学習）</li>
        </ul>

        <p><strong>時間見積もり：</strong> 1-4週間</p>

        <p><strong>注意点：</strong></p>
        <ul>
            <li>データの品質（ノイズ、欠損値）を確認</li>
            <li>クラスの偏り（スパム1% vs 非スパム99%など）に注意</li>
            <li>プライバシー、ライセンスの確認</li>
        </ul>

        <h3>Step 2：探索的データ分析（EDA: Exploratory Data Analysis）</h3>

        <p><strong>目的：</strong> データの特性を理解し、問題点を発見する</p>

        <p><strong>実施内容：</strong></p>
        <ul>
            <li><strong>統計量の確認</strong>：平均、中央値、分散、最大・最小値</li>
            <li><strong>分布の可視化</strong>：ヒストグラム、箱ひげ図</li>
            <li><strong>相関分析</strong>：変数間の関係性（相関係数、散布図）</li>
            <li><strong>欠損値の確認</strong>：どの列にどれだけ欠損があるか</li>
            <li><strong>外れ値の検出</strong>：異常に大きい/小さい値</li>
        </ul>

        <p><strong>時間見積もり：</strong> 数日-1週間</p>

        <p><strong>ツール：</strong> pandas、matplotlib、seaborn、pandas-profiling</p>

        <h3>Step 3：前処理・データクリーニング</h3>

        <p><strong>目的：</strong> データをMLモデルが扱える形式に変換する</p>

        <p><strong>実施内容：</strong></p>

        <h4>1. 欠損値処理</h4>
        <ul>
            <li><strong>削除</strong>：欠損が少ない場合（5%未満）</li>
            <li><strong>補完</strong>：平均値、中央値、最頻値で埋める</li>
            <li><strong>予測</strong>：他の特徴量から欠損値を予測</li>
        </ul>

        <h4>2. 外れ値処理</h4>
        <ul>
            <li><strong>除去</strong>：明らかなエラーデータ</li>
            <li><strong>キャッピング</strong>：上限・下限を設定</li>
            <li><strong>変換</strong>：対数変換で影響を軽減</li>
        </ul>

        <h4>3. スケーリング（正規化・標準化）</h4>
        <ul>
            <li><strong>標準化（Standardization）</strong>：平均0、標準偏差1に変換<br>
                $z = \frac{x - \mu}{\sigma}$</li>
            <li><strong>正規化（Normalization）</strong>：0-1の範囲に変換<br>
                $x' = \frac{x - x_{\min}}{x_{\max} - x_{\min}}$</li>
        </ul>

        <h4>4. カテゴリ変数のエンコーディング</h4>
        <ul>
            <li><strong>Label Encoding</strong>：カテゴリを数値に変換（赤→0、青→1、緑→2）</li>
            <li><strong>One-Hot Encoding</strong>：カテゴリをバイナリベクトルに変換</li>
        </ul>

        <p><strong>時間見積もり：</strong> 数日-1週間</p>

        <p><strong>注意点：</strong></p>
        <ul>
            <li>訓練データとテストデータで同じ前処理を適用</li>
            <li>スケーリングの統計量（平均、標準偏差）は訓練データから計算</li>
        </ul>

        <h3>Step 4：特徴量エンジニアリング</h3>

        <p><strong>目的：</strong> モデルの予測精度を向上させる特徴量を作成する</p>

        <p><strong>手法：</strong></p>
        <ul>
            <li><strong>既存特徴量の変換</strong>：対数変換、平方根、多項式</li>
            <li><strong>交互作用項</strong>：特徴量の積（広さ × 駅距離）</li>
            <li><strong>集約統計量</strong>：グループごとの平均、合計、カウント</li>
            <li><strong>時系列特徴量</strong>：ラグ特徴量、移動平均、季節性</li>
            <li><strong>ドメイン知識の活用</strong>：業界特有の指標</li>
        </ul>

        <p><strong>時間見積もり：</strong> 数日-2週間</p>

        <p><strong>具体例：</strong></p>
        <blockquote>
            <p>住宅価格予測で、「広さ」と「築年数」から新しい特徴量を作成：</p>
            <ul>
                <li><code>広さ_per_築年数 = 広さ / (築年数 + 1)</code></li>
                <li><code>駅近フラグ = 1 if 駅距離 < 500m else 0</code></li>
            </ul>
        </blockquote>

        <h3>Step 5：モデル選択と訓練</h3>

        <p><strong>目的：</strong> 適切なアルゴリズムを選び、学習させる</p>

        <p><strong>戦略：</strong></p>
        <ol>
            <li><strong>ベースラインモデル</strong>：最もシンプルなモデル（線形回帰、ロジスティック回帰）</li>
            <li><strong>複数モデルの比較</strong>：決定木、ランダムフォレスト、XGBoost、SVM</li>
            <li><strong>最良モデルの選択</strong>：交差検証で性能評価</li>
        </ol>

        <p><strong>時間見積もり：</strong> 数時間-数日</p>

        <p><strong>ツール：</strong> scikit-learn、XGBoost、LightGBM</p>

        <h3>Step 6：評価とハイパーパラメータチューニング</h3>

        <p><strong>目的：</strong> モデルの性能を最大化する</p>

        <p><strong>評価手法：</strong></p>
        <ul>
            <li><strong>ホールドアウト法</strong>：訓練80%、テスト20%に分割</li>
            <li><strong>K-fold交差検証</strong>：データをK個に分割し、K回評価</li>
        </ul>

        <p><strong>チューニング手法：</strong></p>
        <ul>
            <li><strong>Grid Search</strong>：すべての組み合わせを試す（時間かかる）</li>
            <li><strong>Random Search</strong>：ランダムにサンプリング（効率的）</li>
            <li><strong>ベイズ最適化</strong>：効率的に最適値を探索</li>
        </ul>

        <p><strong>時間見積もり：</strong> 数日-1週間</p>

        <h3>Step 7：モデル解釈と検証</h3>

        <p><strong>目的：</strong> モデルが正しく動作しているか確認する</p>

        <p><strong>実施内容：</strong></p>
        <ul>
            <li><strong>特徴量重要度</strong>：どの特徴量が重要か</li>
            <li><strong>予測誤差の分析</strong>：どのデータで間違えているか</li>
            <li><strong>SHAP値</strong>：個別予測の説明</li>
            <li><strong>ビジネス検証</strong>：実際に使えるか確認</li>
        </ul>

        <p><strong>時間見積もり：</strong> 数日-1週間</p>

        <h3>ワークフロー全体の時間見積もり</h3>

        <div class="mermaid">
gantt
    title 機械学習プロジェクトのタイムライン
    dateFormat  YYYY-MM-DD
    section 準備
    問題定式化           :a1, 2024-01-01, 14d
    section データ
    データ収集          :a2, 2024-01-15, 21d
    EDA                :a3, 2024-02-05, 7d
    前処理              :a4, 2024-02-12, 7d
    section モデル
    特徴量エンジニアリング :a5, 2024-02-19, 14d
    モデル訓練          :a6, 2024-03-04, 3d
    評価・チューニング   :a7, 2024-03-07, 7d
    検証               :a8, 2024-03-14, 7d
        </div>

        <p><strong>プロジェクト全体：</strong> 2-3ヶ月（小〜中規模）、6-12ヶ月（大規模）</p>

        <h2>2.6 特徴量の深掘り</h2>

        <p>特徴量（Feature）は、機械学習モデルへの入力となるデータの属性です。適切な特徴量を設計することで、モデルの精度が劇的に向上します。</p>

        <h3>2.6.1 特徴量の種類</h3>

        <h4>1. 数値特徴量（Numerical Features）</h4>

        <p><strong>連続値：</strong> 無限に細かく分割できる数値</p>
        <ul>
            <li>年齢：25.5歳、30.2歳</li>
            <li>価格：1,234,567円</li>
            <li>温度：23.7℃</li>
            <li>距離：5.3km</li>
        </ul>

        <p><strong>離散値：</strong> 整数値</p>
        <ul>
            <li>購入回数：0, 1, 2, 3回</li>
            <li>部屋数：1LDK, 2LDK, 3LDK</li>
            <li>在庫数：0, 5, 10個</li>
        </ul>

        <h4>2. カテゴリ特徴量（Categorical Features）</h4>

        <p><strong>名義（Nominal）：</strong> 順序関係がない</p>
        <ul>
            <li>色：赤、青、緑</li>
            <li>性別：男性、女性</li>
            <li>地域：東京、大阪、福岡</li>
            <li>商品カテゴリ：家電、衣料、食品</li>
        </ul>

        <p><strong>順序（Ordinal）：</strong> 順序関係がある</p>
        <ul>
            <li>教育レベル：小卒 < 中卒 < 高卒 < 大卒</li>
            <li>評価：低 < 中 < 高</li>
            <li>サイズ：S < M < L < XL</li>
        </ul>

        <h4>3. テキスト特徴量（Text Features）</h4>

        <p><strong>変換手法：</strong></p>
        <ul>
            <li><strong>Bag of Words（BoW）</strong>：単語の出現回数</li>
            <li><strong>TF-IDF</strong>：単語の重要度を数値化</li>
            <li><strong>Word Embeddings</strong>：単語をベクトル化（Word2Vec、GloVe）</li>
        </ul>

        <h4>4. 時系列特徴量（Time Series Features）</h4>

        <p><strong>派生特徴量：</strong></p>
        <ul>
            <li><strong>ラグ特徴量</strong>：過去の値（1日前、7日前）</li>
            <li><strong>移動平均</strong>：過去N日間の平均</li>
            <li><strong>季節性</strong>：月、曜日、祝日フラグ</li>
            <li><strong>トレンド</strong>：増加・減少傾向</li>
        </ul>

        <h4>5. 画像特徴量（Image Features）</h4>

        <p><strong>変換手法：</strong></p>
        <ul>
            <li><strong>ピクセル値</strong>：RGB値を直接使用</li>
            <li><strong>エッジ検出</strong>：輪郭の抽出</li>
            <li><strong>CNN特徴量</strong>：深層学習で自動抽出</li>
        </ul>

        <h3>2.6.2 カテゴリ変数の数値化（コード例）</h3>

        <pre><code>"""
カテゴリ変数を数値に変換する2つの手法

目的: 機械学習モデルはカテゴリを直接扱えないため、数値化が必要
対象: 初学者
実行時間: 約3秒
"""

import pandas as pd
from sklearn.preprocessing import LabelEncoder

# 1. サンプルデータの準備
df = pd.DataFrame({
    'color': ['red', 'blue', 'green', 'red', 'blue'],
    'size': ['S', 'M', 'L', 'M', 'S'],
    'price': [100, 150, 200, 120, 90]
})

print("元のデータ:")
print(df)
print("\n" + "="*50 + "\n")

# 2. Label Encoding（ラベルエンコーディング）
# 各カテゴリを整数に変換（赤→0, 青→1, 緑→2）
le = LabelEncoder()
df['color_label'] = le.fit_transform(df['color'])

print("Label Encoding後:")
print(df[['color', 'color_label']])
print("\n注意: 数値に順序関係が生まれる（blue=1 > red=0）が、実際には順序はない")
print("\n" + "="*50 + "\n")

# 3. One-Hot Encoding（ワンホットエンコーディング）
# 各カテゴリを独立したバイナリ列に変換
df_onehot = pd.get_dummies(df, columns=['size'], prefix='size')

print("One-Hot Encoding後:")
print(df_onehot)
print("\nsize_S, size_M, size_Lの3列が作成され、該当する列だけ1、他は0")

# 期待される出力:
# 元のデータ:
#   color size  price
# 0   red    S    100
# 1  blue    M    150
# 2 green    L    200
# 3   red    M    120
# 4  blue    S     90
#
# Label Encoding後:
#   color  color_label
# 0   red            2
# 1  blue            0
# 2 green            1
# 3   red            2
# 4  blue            0
#
# One-Hot Encoding後:
#   color  price  color_label  size_L  size_M  size_S
# 0   red    100            2       0       0       1
# 1  blue    150            0       0       1       0
# 2 green    200            1       1       0       0
# 3   red    120            2       0       1       0
# 4  blue     90            0       0       0       1
</code></pre>

        <h3>2.6.3 数値特徴量のスケーリング（コード例）</h3>

        <pre><code>"""
数値特徴量のスケーリング（標準化・正規化）

目的: 異なるスケールの特徴量を統一し、モデル学習を安定化
対象: 初学者
実行時間: 約3秒
"""

import numpy as np
from sklearn.preprocessing import StandardScaler, MinMaxScaler

# 1. サンプルデータ（住宅データ）
data = np.array([
    [50, 10, 500],   # 広さ(m²), 築年数, 駅距離(m)
    [60, 15, 300],
    [70, 5, 800],
    [80, 20, 200],
    [90, 8, 600]
])

print("元のデータ:")
print("  広さ(m²)  築年数  駅距離(m)")
print(data)
print("\n注意: スケールが全く異なる（広さ:50-90, 築年数:5-20, 距離:200-800）")
print("\n" + "="*50 + "\n")

# 2. 標準化（Standardization）
# 平均0、標準偏差1に変換
scaler_std = StandardScaler()
data_std = scaler_std.fit_transform(data)

print("標準化後（平均0、標準偏差1）:")
print(data_std)
print("\n各列の平均:", data_std.mean(axis=0))
print("各列の標準偏差:", data_std.std(axis=0))
print("\n" + "="*50 + "\n")

# 3. 正規化（Normalization）
# 0-1の範囲に変換
scaler_norm = MinMaxScaler()
data_norm = scaler_norm.fit_transform(data)

print("正規化後（0-1の範囲）:")
print(data_norm)
print("\n各列の最小値:", data_norm.min(axis=0))
print("各列の最大値:", data_norm.max(axis=0))

# 期待される出力:
# 元のデータ:
#   広さ(m²)  築年数  駅距離(m)
# [[ 50  10 500]
#  [ 60  15 300]
#  [ 70   5 800]
#  [ 80  20 200]
#  [ 90   8 600]]
#
# 標準化後（平均0、標準偏差1）:
# [[-1.41 -0.39  0.00]
#  [-0.71  0.78 -1.00]
#  [ 0.00 -1.17  1.50]
#  [ 0.71  1.56 -1.50]
#  [ 1.41 -0.78  0.50]]
#
# 正規化後（0-1の範囲）:
# [[0.00 0.33 0.50]
#  [0.25 0.67 0.17]
#  [0.50 0.00 1.00]
#  [0.75 1.00 0.00]
#  [1.00 0.20 0.67]]
</code></pre>

        <h3>2.6.4 特徴量の選択と重要度（コード例）</h3>

        <pre><code>"""
特徴量の選択と重要度の評価

目的: どの特徴量が予測に重要かを判断し、不要な特徴量を削除
対象: 初〜中級者
実行時間: 約5秒
"""

import pandas as pd
from sklearn.datasets import load_diabetes
from sklearn.ensemble import RandomForestRegressor
import matplotlib.pyplot as plt

# 1. サンプルデータの読み込み（糖尿病データセット）
diabetes = load_diabetes()
X = pd.DataFrame(diabetes.data, columns=diabetes.feature_names)
y = diabetes.target

print("データセット情報:")
print(f"サンプル数: {X.shape[0]}, 特徴量数: {X.shape[1]}")
print(f"特徴量: {list(X.columns)}")
print("\n" + "="*50 + "\n")

# 2. ランダムフォレストで特徴量重要度を計算
model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(X, y)

# 3. 特徴量重要度の取得
importances = pd.DataFrame({
    'feature': X.columns,
    'importance': model.feature_importances_
}).sort_values('importance', ascending=False)

print("特徴量重要度ランキング:")
print(importances)
print("\n" + "="*50 + "\n")

# 4. 相関係数の計算
correlations = X.corrwith(pd.Series(y)).abs().sort_values(ascending=False)

print("目的変数との相関係数（絶対値）:")
print(correlations)

# 期待される出力:
# データセット情報:
# サンプル数: 442, 特徴量数: 10
# 特徴量: ['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6']
#
# 特徴量重要度ランキング:
#    feature  importance
# 2      bmi    0.289345
# 8       s5    0.201928
# 4       s1    0.127654
# ...
#
# 目的変数との相関係数（絶対値）:
# bmi    0.586450
# s5     0.565883
# bp     0.441484
# ...
</code></pre>

        <h3>2.6.5 特徴量エンジニアリングの実例（コード例）</h3>

        <pre><code>"""
特徴量エンジニアリング: 新しい特徴量の作成

目的: 既存の特徴量から、より予測力の高い派生特徴量を作成
対象: 中級者
実行時間: 約3秒
"""

import pandas as pd
import numpy as np

# 1. サンプルデータ（住宅価格予測）
df = pd.DataFrame({
    '広さ': [50, 60, 70, 80, 90],
    '築年数': [10, 15, 5, 20, 8],
    '駅距離': [500, 300, 800, 200, 600],
    '部屋数': [2, 3, 3, 4, 2],
    '価格': [3000, 3500, 4200, 4500, 3800]  # 万円
})

print("元の特徴量:")
print(df)
print("\n" + "="*50 + "\n")

# 2. 派生特徴量の作成

# (1) 交互作用項: 広さと築年数の積
df['広さ×築年数'] = df['広さ'] * df['築年数']

# (2) 比率: 広さあたりの価格
df['価格per広さ'] = df['価格'] / df['広さ']

# (3) 多項式: 築年数の二乗（経年劣化は非線形）
df['築年数²'] = df['築年数'] ** 2

# (4) カテゴリ化: 駅距離を「近い/遠い」に変換
df['駅近フラグ'] = (df['駅距離'] < 400).astype(int)

# (5) ドメイン知識: 部屋数あたりの広さ
df['広さper部屋'] = df['広さ'] / df['部屋数']

# (6) 対数変換: 駅距離の対数（遠距離の影響を軽減）
df['log_駅距離'] = np.log1p(df['駅距離'])

print("特徴量エンジニアリング後:")
print(df)
print("\n" + "="*50 + "\n")

print("新しい特徴量の統計:")
print(df[['広さ×築年数', '価格per広さ', '駅近フラグ', '広さper部屋']].describe())

# 期待される出力:
# 元の特徴量:
#    広さ  築年数  駅距離  部屋数   価格
# 0   50     10    500      2  3000
# 1   60     15    300      3  3500
# 2   70      5    800      3  4200
# 3   80     20    200      4  4500
# 4   90      8    600      2  3800
#
# 特徴量エンジニアリング後:
#    広さ  築年数  駅距離  部屋数   価格  広さ×築年数  価格per広さ  築年数²  駅近フラグ  広さper部屋  log_駅距離
# 0   50     10    500      2  3000         500        60.0      100          0       25.0    6.215
# 1   60     15    300      3  3500         900        58.3      225          1       20.0    5.704
# 2   70      5    800      3  4200         350        60.0       25          0       23.3    6.685
# 3   80     20    200      4  4500        1600        56.2      400          1       20.0    5.298
# 4   90      8    600      2  3800         720        42.2       64          0       45.0    6.397
</code></pre>

        <h2>本章のまとめ</h2>

        <p>この章では、機械学習の基礎知識を体系的に学びました。以下の内容を習得しました：</p>

        <div class="highlight-box">
            <h3>習得した知識とスキル</h3>
            <ul>
                <li><strong>機械学習の定義</strong>：データから自動的にパターンを学習する技術</li>
                <li><strong>3つの学習タイプ</strong>：教師あり学習、教師なし学習、強化学習の違いと適用場面</li>
                <li><strong>20の重要用語</strong>：特徴量、ラベル、モデル、損失関数、過学習など</li>
                <li><strong>4つの主要フレームワーク</strong>：scikit-learn、PyTorch、TensorFlow、XGBoostの使い分け</li>
                <li><strong>機械学習エコシステム</strong>：データ収集から本番運用までの全体像</li>
                <li><strong>7ステップワークフロー</strong>：問題定式化、データ収集、EDA、前処理、特徴量エンジニアリング、訓練、評価</li>
                <li><strong>特徴量の種類と変換</strong>：数値、カテゴリ、テキスト、時系列、画像特徴量</li>
            </ul>
        </div>

        <h3>次章への橋渡し</h3>

        <p>第2章では、機械学習の理論と概念を学びました。次の第3章では、実際にPythonコードを書いて、6つの機械学習モデルを実装します。環境構築から始まり、データ前処理、モデル訓練、評価まで、手を動かして体験します。</p>

        <p><strong>第3章で学ぶこと：</strong></p>
        <ul>
            <li>Python環境の構築（Anaconda / venv / Google Colab）</li>
            <li>6つのモデルの完全実装（線形回帰、ロジスティック回帰、決定木、ランダムフォレスト、SVM、KNN）</li>
            <li>ハイパーパラメータチューニング（Grid Search、Random Search）</li>
            <li>Titanicデータセットで実践プロジェクト</li>
        </ul>

        <h2>演習問題</h2>

        <h3>問題1（難易度：easy）</h3>
        <p><strong>教師あり学習と教師なし学習の違いを、具体例とともに説明してください。</strong></p>

        <details>
            <summary>ヒント</summary>
            <p>「正解ラベル」の有無に注目してください。教師あり学習では入力と正解のペアが必要ですが、教師なし学習では正解なしでパターンを発見します。</p>
        </details>

        <details>
            <summary>解答例</summary>
            <h4>教師あり学習（Supervised Learning）</h4>
            <p><strong>定義：</strong> ラベル付きデータ（入力と正解のペア）から学習する手法</p>
            <p><strong>具体例：</strong></p>
            <ul>
                <li><strong>スパム判定</strong>：メール本文（入力）→ スパム/非スパム（正解ラベル）</li>
                <li><strong>住宅価格予測</strong>：広さ、築年数（入力）→ 価格（正解ラベル）</li>
                <li><strong>画像認識</strong>：猫の画像（入力）→ "猫"というラベル（正解）</li>
            </ul>

            <h4>教師なし学習（Unsupervised Learning）</h4>
            <p><strong>定義：</strong> ラベルなしデータから、隠れたパターンや構造を発見する手法</p>
            <p><strong>具体例：</strong></p>
            <ul>
                <li><strong>顧客セグメンテーション</strong>：購買履歴から顧客を自動的にグループ分け（正解なし）</li>
                <li><strong>異常検知</strong>：通常と異なるパターンを検出（正常/異常のラベルなし）</li>
                <li><strong>推薦システム</strong>：類似商品の発見（正解なし、類似性のみ）</li>
            </ul>

            <h4>主な違い</h4>
            <table>
                <tr>
                    <th>項目</th>
                    <th>教師あり学習</th>
                    <th>教師なし学習</th>
                </tr>
                <tr>
                    <td>データ</td>
                    <td>ラベル付き</td>
                    <td>ラベルなし</td>
                </tr>
                <tr>
                    <td>目的</td>
                    <td>予測・分類</td>
                    <td>パターン発見</td>
                </tr>
                <tr>
                    <td>評価</td>
                    <td>精度、F1スコアなど</td>
                    <td>シルエット係数など</td>
                </tr>
            </table>
        </details>

        <h3>問題2（難易度：easy）</h3>
        <p><strong>過学習とは何か、なぜ問題なのか説明してください。また、過学習を防ぐ方法を3つ挙げてください。</strong></p>

        <details>
            <summary>ヒント</summary>
            <p>訓練データとテストデータでの性能差に注目してください。訓練精度は高いのに、テスト精度が低い場合は過学習の可能性があります。</p>
        </details>

        <details>
            <summary>解答例</summary>
            <h4>過学習（Overfitting）とは</h4>
            <p><strong>定義：</strong> モデルが訓練データに過度に適合し、未知のデータへの予測性能が低下する現象</p>

            <p><strong>症状：</strong></p>
            <ul>
                <li>訓練データでの精度：95%（高い）</li>
                <li>テストデータでの精度：70%（低い）</li>
            </ul>

            <p><strong>原因：</strong></p>
            <ul>
                <li>モデルが複雑すぎる（パラメータ数が多い）</li>
                <li>訓練データが少ない</li>
                <li>ノイズや外れ値まで学習してしまう</li>
            </ul>

            <p><strong>なぜ問題なのか：</strong></p>
            <ul>
                <li>実世界での予測精度が低い（本番環境で使えない）</li>
                <li>訓練データのパターンを「暗記」しているだけで、一般化できていない</li>
                <li>新しいデータに対応できない</li>
            </ul>

            <h4>過学習を防ぐ方法</h4>
            <ol>
                <li><strong>データ数を増やす</strong>：訓練データを増やすことで、モデルが一般的なパターンを学習</li>
                <li><strong>正則化（Regularization）</strong>：L1正則化（Lasso）、L2正則化（Ridge）でパラメータに制約</li>
                <li><strong>交差検証（Cross-Validation）</strong>：K-fold交差検証で汎化性能を正確に評価</li>
                <li><strong>モデルを単純化</strong>：決定木の深さを制限、ニューラルネットワークの層数を減らす</li>
                <li><strong>ドロップアウト</strong>：ニューラルネットワークで一部のノードをランダムに無効化</li>
                <li><strong>Early Stopping</strong>：検証誤差が増加し始めたら学習を停止</li>
            </ol>
        </details>

        <h3>問題3（難易度：medium）</h3>
        <p><strong>あるECサイトで顧客の購買予測をしたい。以下の2つの問題設定について、それぞれ回帰問題か分類問題かを判断し、理由とともに答えてください。</strong></p>
        <ul>
            <li>(A) 顧客が次月に購入する金額を予測したい</li>
            <li>(B) 顧客が1ヶ月以内に購入するか否かを予測したい</li>
        </ul>

        <details>
            <summary>ヒント</summary>
            <p>出力が連続値（数値）なら回帰、カテゴリ（Yes/No、高/中/低など）なら分類です。</p>
        </details>

        <details>
            <summary>解答例</summary>
            <h4>(A) 顧客が次月に購入する金額を予測したい</h4>
            <p><strong>答え：回帰問題（Regression）</strong></p>

            <p><strong>理由：</strong></p>
            <ul>
                <li>出力が<strong>連続値</strong>（0円、3,500円、15,000円など）</li>
                <li>具体的な数値を予測する</li>
                <li>評価指標：MAE（平均絶対誤差）、RMSE（二乗平均平方根誤差）</li>
            </ul>

            <p><strong>適用モデル：</strong></p>
            <ul>
                <li>線形回帰（Linear Regression）</li>
                <li>ランダムフォレスト回帰（Random Forest Regressor）</li>
                <li>XGBoost回帰</li>
            </ul>

            <h4>(B) 顧客が1ヶ月以内に購入するか否かを予測したい</h4>
            <p><strong>答え：分類問題（Classification）</strong></p>

            <p><strong>理由：</strong></p>
            <ul>
                <li>出力が<strong>カテゴリ</strong>（購入する/しない、Yes/No）</li>
                <li>2値分類（Binary Classification）</li>
                <li>評価指標：精度（Accuracy）、F1スコア、AUC-ROC</li>
            </ul>

            <p><strong>適用モデル：</strong></p>
            <ul>
                <li>ロジスティック回帰（Logistic Regression）</li>
                <li>ランダムフォレスト分類（Random Forest Classifier）</li>
                <li>XGBoost分類</li>
            </ul>

            <h4>ビジネス的観点</h4>
            <ul>
                <li><strong>(A)の回帰</strong>：マーケティング予算の配分、在庫計画に有用</li>
                <li><strong>(B)の分類</strong>：ターゲット顧客の絞り込み、クーポン配布に有用</li>
            </ul>
        </details>

        <h3>問題4（難易度：medium）</h3>
        <p><strong>特徴量エンジニアリングで、カテゴリ変数「都道府県」をどのように数値化すべきか、2つの方法を説明してください。それぞれの長所・短所も述べてください。</strong></p>

        <details>
            <summary>ヒント</summary>
            <p>カテゴリ変数を数値化する代表的な手法は、Label EncodingとOne-Hot Encodingです。順序関係の有無に注目してください。</p>
        </details>

        <details>
            <summary>解答例</summary>
            <h4>方法1：Label Encoding（ラベルエンコーディング）</h4>

            <p><strong>手法：</strong> 各都道府県に一意の整数を割り当てる</p>

            <pre><code>東京 → 0
大阪 → 1
福岡 → 2
北海道 → 3
...</code></pre>

            <p><strong>長所：</strong></p>
            <ul>
                <li>メモリ効率が良い（1列で済む）</li>
                <li>実装が簡単</li>
                <li>データサイズが増えない</li>
            </ul>

            <p><strong>短所：</strong></p>
            <ul>
                <li><strong>誤った順序関係が生まれる</strong>：大阪(1) > 東京(0)のような意味のない大小関係</li>
                <li>線形モデルでは不適切（都道府県に順序はない）</li>
                <li>決定木系モデル（ランダムフォレスト、XGBoost）では使用可能</li>
            </ul>

            <h4>方法2：One-Hot Encoding（ワンホットエンコーディング）</h4>

            <p><strong>手法：</strong> 各都道府県を独立したバイナリ列に変換</p>

            <pre><code>東京    → [1, 0, 0, 0, ...]（東京列が1、他は0）
大阪    → [0, 1, 0, 0, ...]（大阪列が1、他は0）
福岡    → [0, 0, 1, 0, ...]（福岡列が1、他は0）
北海道  → [0, 0, 0, 1, ...]（北海道列が1、他は0）</code></pre>

            <p><strong>長所：</strong></p>
            <ul>
                <li><strong>順序関係を作らない</strong>：各都道府県が独立した特徴量として扱われる</li>
                <li>線形モデルでも正しく学習できる</li>
                <li>解釈性が高い（「東京の効果」が明確）</li>
            </ul>

            <p><strong>短所：</strong></p>
            <ul>
                <li>特徴量数が増加（47都道府県なら47列）</li>
                <li>メモリ消費が大きい</li>
                <li>カテゴリ数が多い場合（数千以上）は次元の呪い</li>
            </ul>

            <h4>使い分けガイド</h4>
            <table>
                <tr>
                    <th>条件</th>
                    <th>推奨手法</th>
                </tr>
                <tr>
                    <td>カテゴリ数が少ない（<100）</td>
                    <td>One-Hot Encoding</td>
                </tr>
                <tr>
                    <td>カテゴリ数が多い（>100）</td>
                    <td>Label Encoding + 決定木系モデル</td>
                </tr>
                <tr>
                    <td>線形モデル使用</td>
                    <td>One-Hot Encoding必須</td>
                </tr>
                <tr>
                    <td>決定木系モデル使用</td>
                    <td>どちらでも可（Label Encodingが効率的）</td>
                </tr>
            </table>

            <h4>都道府県の場合の推奨</h4>
            <p><strong>推奨：One-Hot Encoding</strong></p>
            <ul>
                <li>カテゴリ数が47個で適度</li>
                <li>順序関係がない（東京 > 大阪は意味不明）</li>
                <li>解釈性が高い（地域別の効果を分析可能）</li>
            </ul>
        </details>

        <h2>参考文献</h2>

        <ol>
            <li>Mitchell, T. M. (1997). <em>Machine Learning</em>. McGraw-Hill. ISBN: 0070428077</li>
            <li>Bishop, C. M. (2006). <em>Pattern Recognition and Machine Learning</em>. Springer. ISBN: 0387310738</li>
            <li>Goodfellow, I., Bengio, Y., & Courville, A. (2016). <em>Deep Learning</em>. MIT Press. <a href="https://www.deeplearningbook.org/">https://www.deeplearningbook.org/</a></li>
            <li>scikit-learn Documentation. (2024). <a href="https://scikit-learn.org/stable/">https://scikit-learn.org/stable/</a></li>
            <li>加藤公一 (2018). 『仕事ではじめる機械学習』オライリー・ジャパン. ISBN: 4873118255</li>
            <li>Sebastian Raschka (2019). <em>Python Machine Learning</em> (3rd ed.). Packt Publishing. ISBN: 1789955750</li>
            <li>Aurélien Géron (2019). <em>Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow</em> (2nd ed.). O'Reilly Media. ISBN: 1492032646</li>
        </ol>

        <div class="navigation">
            <a href="chapter1-introduction.html" class="nav-button">← 第1章：なぜ今機械学習なのか</a>
            <a href="index.html" class="nav-button">シリーズ目次</a>
            <a href="chapter3-hands-on.html" class="nav-button">第3章：Pythonハンズオン →</a>
        </div>
    </main>

    <footer>
        <div class="container">
            <p>&copy; 2025 ML Knowledge Hub - Dr. Yusuke Hashimoto, Tohoku University</p>
            <p>Licensed under CC BY 4.0 | <a href="https://creativecommons.org/licenses/by/4.0/deed.ja">詳細</a></p>
        </div>
    </footer>
</body>
</html>
