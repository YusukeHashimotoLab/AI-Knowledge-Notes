<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ç¬¬4ç« ï¼šPyTorchã¨TensorFlowå®Ÿè·µ - AI Terakoya</title>

    <style>
        :root {
            --color-primary: #2c3e50;
            --color-primary-dark: #1a252f;
            --color-accent: #7b2cbf;
            --color-accent-light: #9d4edd;
            --color-text: #2d3748;
            --color-text-light: #4a5568;
            --color-bg: #ffffff;
            --color-bg-alt: #f7fafc;
            --color-border: #e2e8f0;
            --color-code-bg: #f8f9fa;
            --color-link: #3182ce;
            --color-link-hover: #2c5aa0;

            --spacing-xs: 0.5rem;
            --spacing-sm: 1rem;
            --spacing-md: 1.5rem;
            --spacing-lg: 2rem;
            --spacing-xl: 3rem;

            --font-body: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            --font-mono: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;

            --border-radius: 8px;
            --box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: var(--font-body);
            line-height: 1.7;
            color: var(--color-text);
            background-color: var(--color-bg);
            font-size: 16px;
        }

        header {
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            padding: var(--spacing-xl) var(--spacing-md);
            margin-bottom: var(--spacing-xl);
            box-shadow: var(--box-shadow);
        }

        .header-content {
            max-width: 900px;
            margin: 0 auto;
        }

        h1 {
            font-size: 2rem;
            font-weight: 700;
            margin-bottom: var(--spacing-sm);
            line-height: 1.2;
        }

        .subtitle {
            font-size: 1.1rem;
            opacity: 0.95;
            font-weight: 400;
            margin-bottom: var(--spacing-md);
        }

        .meta {
            display: flex;
            flex-wrap: wrap;
            gap: var(--spacing-md);
            font-size: 0.9rem;
            opacity: 0.9;
        }

        .meta-item {
            display: flex;
            align-items: center;
            gap: 0.3rem;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 0 var(--spacing-md) var(--spacing-xl);
        }

        h2 {
            font-size: 1.75rem;
            color: var(--color-primary);
            margin-top: var(--spacing-xl);
            margin-bottom: var(--spacing-md);
            padding-bottom: var(--spacing-xs);
            border-bottom: 3px solid var(--color-accent);
        }

        h3 {
            font-size: 1.4rem;
            color: var(--color-primary);
            margin-top: var(--spacing-lg);
            margin-bottom: var(--spacing-sm);
        }

        h4 {
            font-size: 1.1rem;
            color: var(--color-primary-dark);
            margin-top: var(--spacing-md);
            margin-bottom: var(--spacing-sm);
        }

        p {
            margin-bottom: var(--spacing-md);
            color: var(--color-text);
        }

        a {
            color: var(--color-link);
            text-decoration: none;
            transition: color 0.2s;
        }

        a:hover {
            color: var(--color-link-hover);
            text-decoration: underline;
        }

        ul, ol {
            margin-left: var(--spacing-lg);
            margin-bottom: var(--spacing-md);
        }

        li {
            margin-bottom: var(--spacing-xs);
            color: var(--color-text);
        }

        pre {
            background-color: var(--color-code-bg);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            overflow-x: auto;
            margin-bottom: var(--spacing-md);
            font-family: var(--font-mono);
            font-size: 0.9rem;
            line-height: 1.5;
        }

        code {
            font-family: var(--font-mono);
            font-size: 0.9em;
            background-color: var(--color-code-bg);
            padding: 0.2em 0.4em;
            border-radius: 3px;
        }

        pre code {
            background-color: transparent;
            padding: 0;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: var(--spacing-md);
            font-size: 0.95rem;
        }

        th, td {
            border: 1px solid var(--color-border);
            padding: var(--spacing-sm);
            text-align: left;
        }

        th {
            background-color: var(--color-bg-alt);
            font-weight: 600;
            color: var(--color-primary);
        }

        blockquote {
            border-left: 4px solid var(--color-accent);
            padding-left: var(--spacing-md);
            margin: var(--spacing-md) 0;
            color: var(--color-text-light);
            font-style: italic;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        .mermaid {
            text-align: center;
            margin: var(--spacing-lg) 0;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        details {
            background-color: var(--color-bg-alt);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            margin-bottom: var(--spacing-md);
        }

        summary {
            cursor: pointer;
            font-weight: 600;
            color: var(--color-primary);
            user-select: none;
            padding: var(--spacing-xs);
            margin: calc(-1 * var(--spacing-md));
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        summary:hover {
            background-color: rgba(123, 44, 191, 0.1);
        }

        details[open] summary {
            margin-bottom: var(--spacing-md);
            border-bottom: 1px solid var(--color-border);
        }

        .navigation {
            display: flex;
            justify-content: space-between;
            gap: var(--spacing-md);
            margin: var(--spacing-xl) 0;
            padding-top: var(--spacing-lg);
            border-top: 2px solid var(--color-border);
        }

        .nav-button {
            flex: 1;
            padding: var(--spacing-md);
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            border-radius: var(--border-radius);
            text-align: center;
            font-weight: 600;
            transition: transform 0.2s, box-shadow 0.2s;
            box-shadow: var(--box-shadow);
        }

        .nav-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
            text-decoration: none;
        }

        footer {
            margin-top: var(--spacing-xl);
            padding: var(--spacing-lg) var(--spacing-md);
            background-color: var(--color-bg-alt);
            border-top: 1px solid var(--color-border);
            text-align: center;
            font-size: 0.9rem;
            color: var(--color-text-light);
        }

        @media (max-width: 768px) {
            h1 {
                font-size: 1.5rem;
            }

            h2 {
                font-size: 1.4rem;
            }

            h3 {
                font-size: 1.2rem;
            }

            .meta {
                font-size: 0.85rem;
            }

            .navigation {
                flex-direction: column;
            }

            table {
                font-size: 0.85rem;
            }

            th, td {
                padding: var(--spacing-xs);
            }
        }
    </style>

    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
        mermaid.initialize({ startOnLoad: true, theme: 'default' });
    </script>

    <!-- MathJax for LaTeX equation rendering -->
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                displayMath: [['$$', '$$'], ['\\[', '\\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
                ignoreHtmlClass: 'mermaid'
            }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" async></script>
</head>
<body>
    <header>
        <div class="header-content">
            <h1>ç¬¬4ç« ï¼šPyTorchã¨TensorFlowå®Ÿè·µ</h1>
            <p class="subtitle">ç¾ä»£çš„ãªãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã®å®Ÿè£…ã¨ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹</p>
            <div class="meta">
                <span class="meta-item">ğŸ“– èª­äº†æ™‚é–“: 25-30åˆ†</span>
                <span class="meta-item">ğŸ“Š é›£æ˜“åº¦: ä¸­ç´š</span>
                <span class="meta-item">ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹: 12å€‹</span>
                <span class="meta-item">ğŸ“ æ¼”ç¿’å•é¡Œ: 5å•</span>
            </div>
        </div>
    </header>

    <main class="container">

<h2>å­¦ç¿’ç›®æ¨™</h2>
<p>ã“ã®ç« ã‚’èª­ã‚€ã“ã¨ã§ã€ä»¥ä¸‹ã‚’ç¿’å¾—ã§ãã¾ã™ï¼š</p>
<ul>
<li>âœ… PyTorchã®ãƒ†ãƒ³ã‚½ãƒ«æ“ä½œã¨è‡ªå‹•å¾®åˆ†ã®ä»•çµ„ã¿ã‚’ç†è§£ã™ã‚‹</li>
<li>âœ… nn.Moduleã‚’ä½¿ã£ãŸæœ¬æ ¼çš„ãªãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ§‹ç¯‰</li>
<li>âœ… DataLoaderã‚’æ´»ç”¨ã—ãŸåŠ¹ç‡çš„ãªãƒãƒƒãƒå‡¦ç†</li>
<li>âœ… TensorFlow/Kerasã®å®Ÿè£…ãƒ‘ã‚¿ãƒ¼ãƒ³ã¨PyTorchã¨ã®æ¯”è¼ƒ</li>
<li>âœ… ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜ãƒ»èª­ã¿è¾¼ã¿ã€GPUæ´»ç”¨ãªã©ã®å®Ÿç”¨ãƒ†ã‚¯ãƒ‹ãƒƒã‚¯</li>
</ul>

<hr>

<h2>4.1 PyTorchå…¥é–€</h2>

<h3>PyTorchã¨ã¯</h3>
<p><strong>PyTorch</strong>ã¯ã€Metaï¼ˆæ—§Facebookï¼‰ãŒé–‹ç™ºã—ãŸã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®æ©Ÿæ¢°å­¦ç¿’ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã™ã€‚ç ”ç©¶è€…ã‚„å®Ÿå‹™å®¶ã«åºƒãä½¿ã‚ã‚Œã¦ãŠã‚Šã€ä»¥ä¸‹ã®ç‰¹å¾´ãŒã‚ã‚Šã¾ã™ï¼š</p>

<ul>
<li><strong>Define-by-Run</strong>: å‹•çš„ãªè¨ˆç®—ã‚°ãƒ©ãƒ•ï¼ˆå®Ÿè¡Œã—ãªãŒã‚‰ã‚°ãƒ©ãƒ•ã‚’æ§‹ç¯‰ï¼‰</li>
<li><strong>Pythonic</strong>: NumPyãƒ©ã‚¤ã‚¯ãªç›´æ„Ÿçš„ãªAPI</li>
<li><strong>è‡ªå‹•å¾®åˆ†</strong>: Autogradã«ã‚ˆã‚‹è‡ªå‹•çš„ãªå‹¾é…è¨ˆç®—</li>
<li><strong>GPUå¯¾å¿œ</strong>: CUDAã«ã‚ˆã‚‹é«˜é€ŸåŒ–ãŒå®¹æ˜“</li>
</ul>

<blockquote>
<p>ã€ŒPyTorchã¯ç ”ç©¶ã‹ã‚‰æœ¬ç•ªç’°å¢ƒã¾ã§ã€ã‚·ãƒ¼ãƒ ãƒ¬ã‚¹ã«ä½¿ãˆã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã™ã€‚æŸ”è»Ÿæ€§ã¨é«˜é€Ÿæ€§ã‚’ä¸¡ç«‹ã—ã¦ã„ã¾ã™ã€‚ã€</p>
</blockquote>

<h3>ãƒ†ãƒ³ã‚½ãƒ«æ“ä½œã®åŸºç¤</h3>

<p>PyTorchã®åŸºæœ¬ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã¯<strong>ãƒ†ãƒ³ã‚½ãƒ«ï¼ˆTensorï¼‰</strong>ã§ã™ã€‚NumPyã®ndarrayã«ä¼¼ã¦ã„ã¾ã™ãŒã€GPUä¸Šã§è¨ˆç®—ã§ãã¾ã™ã€‚</p>

<pre><code class="language-python">import torch
import numpy as np

# ãƒ†ãƒ³ã‚½ãƒ«ã®ä½œæˆ
print("=== ãƒ†ãƒ³ã‚½ãƒ«ã®ä½œæˆ ===")

# ãƒªã‚¹ãƒˆã‹ã‚‰ä½œæˆ
x = torch.tensor([1.0, 2.0, 3.0])
print(f"x = {x}")
print(f"x.shape = {x.shape}")  # torch.Size([3])

# ã‚¼ãƒ­ã§åˆæœŸåŒ–
zeros = torch.zeros(2, 3)
print(f"\nzeros:\n{zeros}")

# æ­£è¦åˆ†å¸ƒã‹ã‚‰ãƒ©ãƒ³ãƒ€ãƒ ã«åˆæœŸåŒ–
randn = torch.randn(2, 3)
print(f"\nrandn:\n{randn}")

# NumPyé…åˆ—ã‹ã‚‰å¤‰æ›
np_array = np.array([[1, 2], [3, 4]])
torch_tensor = torch.from_numpy(np_array)
print(f"\nNumPyã‹ã‚‰å¤‰æ›:\n{torch_tensor}")

# ãƒ†ãƒ³ã‚½ãƒ«ã®æ¼”ç®—
a = torch.tensor([[1.0, 2.0], [3.0, 4.0]])
b = torch.tensor([[5.0, 6.0], [7.0, 8.0]])

print(f"\n=== ãƒ†ãƒ³ã‚½ãƒ«æ¼”ç®— ===")
print(f"a + b:\n{a + b}")
print(f"a * bï¼ˆè¦ç´ ã”ã¨ï¼‰:\n{a * b}")
print(f"a @ bï¼ˆè¡Œåˆ—ç©ï¼‰:\n{a @ b}")
print(f"a.Tï¼ˆè»¢ç½®ï¼‰:\n{a.T}")
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>=== ãƒ†ãƒ³ã‚½ãƒ«ã®ä½œæˆ ===
x = tensor([1., 2., 3.])
x.shape = torch.Size([3])

zeros:
tensor([[0., 0., 0.],
        [0., 0., 0.]])

randn:
tensor([[ 0.3367, -1.2312,  0.5414],
        [-0.8485,  1.1234, -0.3421]])

NumPyã‹ã‚‰å¤‰æ›:
tensor([[1, 2],
        [3, 4]])

=== ãƒ†ãƒ³ã‚½ãƒ«æ¼”ç®— ===
a + b:
tensor([[ 6.,  8.],
        [10., 12.]])
a * bï¼ˆè¦ç´ ã”ã¨ï¼‰:
tensor([[ 5., 12.],
        [21., 32.]])
a @ bï¼ˆè¡Œåˆ—ç©ï¼‰:
tensor([[19., 22.],
        [43., 50.]])
a.Tï¼ˆè»¢ç½®ï¼‰:
tensor([[1., 3.],
        [2., 4.]])
</code></pre>

<h3>GPUå¯¾å¿œã‚³ãƒ¼ãƒ‰</h3>

<pre><code class="language-python">import torch

# GPUãŒåˆ©ç”¨å¯èƒ½ã‹ãƒã‚§ãƒƒã‚¯
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹: {device}")

# ãƒ†ãƒ³ã‚½ãƒ«ã‚’GPUã«è»¢é€
x = torch.randn(1000, 1000)
x_gpu = x.to(device)  # GPUã«è»¢é€
print(f"x_gpu.device: {x_gpu.device}")

# GPUã§è¨ˆç®—
y_gpu = x_gpu @ x_gpu.T
print(f"GPUè¨ˆç®—çµæœã®shape: {y_gpu.shape}")

# CPUã«æˆ»ã™
y_cpu = y_gpu.cpu()
print(f"CPUã«è»¢é€: {y_cpu.device}")

# ãƒ‡ãƒã‚¤ã‚¹ã‚’æ˜ç¤ºçš„ã«æŒ‡å®šã—ã¦ä½œæˆ
z = torch.randn(10, 10, device=device)
print(f"ãƒ‡ãƒã‚¤ã‚¹æŒ‡å®šã§ä½œæˆ: {z.device}")
</code></pre>

<h3>Autogradï¼ˆè‡ªå‹•å¾®åˆ†ï¼‰</h3>

<p>PyTorchã®<strong>Autograd</strong>ã¯ã€ãƒ†ãƒ³ã‚½ãƒ«æ¼”ç®—ã‚’è¿½è·¡ã—ã¦è‡ªå‹•çš„ã«å‹¾é…ã‚’è¨ˆç®—ã—ã¾ã™ã€‚</p>

<pre><code class="language-python">import torch

# å‹¾é…ã‚’è¨ˆç®—ã—ãŸã„ãƒ†ãƒ³ã‚½ãƒ«ã¯ requires_grad=True ã‚’è¨­å®š
x = torch.tensor([2.0], requires_grad=True)
print(f"x = {x}")

# é †ä¼æ’­: y = x^2 + 3x + 1
y = x**2 + 3*x + 1
print(f"y = {y}")

# é€†ä¼æ’­: dy/dx ã‚’è¨ˆç®—
y.backward()  # è‡ªå‹•å¾®åˆ†å®Ÿè¡Œ

# å‹¾é…ã‚’å–å¾—
print(f"dy/dx = {x.grad}")  # dy/dx = 2x + 3 = 2*2 + 3 = 7

# ã‚ˆã‚Šè¤‡é›‘ãªä¾‹
print("\n=== è¤‡é›‘ãªè¨ˆç®—ã‚°ãƒ©ãƒ• ===")
x = torch.randn(3, requires_grad=True)
print(f"x = {x}")

# è¤‡æ•°ã®æ¼”ç®—ã‚’çµ„ã¿åˆã‚ã›
y = x * 2
z = y ** 2
out = z.mean()  # ã‚¹ã‚«ãƒ©ãƒ¼å€¤

print(f"out = {out}")

# å‹¾é…è¨ˆç®—
out.backward()
print(f"x.grad = {x.grad}")

# å‹¾é…ã®æ¤œè¨¼: d(mean((x*2)^2))/dx = d(mean(4x^2))/dx = 8x/3
print(f"æœŸå¾…å€¤ï¼ˆ8x/3ï¼‰: {8 * x.data / 3}")
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>x = tensor([2.], requires_grad=True)
y = tensor([11.], grad_fn=&lt;AddBackward0&gt;)
dy/dx = tensor([7.])

=== è¤‡é›‘ãªè¨ˆç®—ã‚°ãƒ©ãƒ• ===
x = tensor([-0.5234,  1.2156, -0.8945], requires_grad=True)
out = tensor(2.0394, grad_fn=&lt;MeanBackward0&gt;)
x.grad = tensor([-1.3957,  3.2416, -2.3853])
æœŸå¾…å€¤ï¼ˆ8x/3ï¼‰: tensor([-1.3957,  3.2416, -2.3853])
</code></pre>

<div class="mermaid">
graph TD
    x[x: requires_grad=True] --> mul[y = x * 2]
    mul --> pow[z = y ** 2]
    pow --> mean[out = z.mean]
    mean --> backward[backward]
    backward --> grad[x.grad ã«å‹¾é…ãŒä¿å­˜]

    style x fill:#e3f2fd
    style mul fill:#fff3e0
    style pow fill:#fff3e0
    style mean fill:#fff3e0
    style backward fill:#f3e5f5
    style grad fill:#e8f5e9
</div>

<h3>nn.Moduleã§ãƒ¢ãƒ‡ãƒ«å®šç¾©</h3>

<p><strong>nn.Module</strong>ã¯PyTorchã®ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ§‹ç¯‰ã®åŸºæœ¬ã‚¯ãƒ©ã‚¹ã§ã™ã€‚</p>

<pre><code class="language-python">import torch
import torch.nn as nn
import torch.nn.functional as F

class SimpleNet(nn.Module):
    """ã‚·ãƒ³ãƒ—ãƒ«ãª3å±¤ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯"""

    def __init__(self, input_size, hidden_size, output_size):
        """
        Args:
            input_size: å…¥åŠ›å±¤ã®ã‚µã‚¤ã‚º
            hidden_size: éš ã‚Œå±¤ã®ã‚µã‚¤ã‚º
            output_size: å‡ºåŠ›å±¤ã®ã‚µã‚¤ã‚º
        """
        super(SimpleNet, self).__init__()

        # ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®å®šç¾©
        self.fc1 = nn.Linear(input_size, hidden_size)
        self.fc2 = nn.Linear(hidden_size, hidden_size)
        self.fc3 = nn.Linear(hidden_size, output_size)

    def forward(self, x):
        """é †ä¼æ’­"""
        x = F.relu(self.fc1(x))  # 1å±¤ç›® + ReLU
        x = F.relu(self.fc2(x))  # 2å±¤ç›® + ReLU
        x = self.fc3(x)           # å‡ºåŠ›å±¤ï¼ˆæ´»æ€§åŒ–ãªã—ï¼‰
        return x

# ãƒ¢ãƒ‡ãƒ«ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–
model = SimpleNet(input_size=784, hidden_size=128, output_size=10)
print(model)

# ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ç¢ºèª
print(f"\nç·ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {sum(p.numel() for p in model.parameters()):,}")

# æ¨è«–ã®å®Ÿè¡Œ
x = torch.randn(32, 784)  # ãƒãƒƒãƒã‚µã‚¤ã‚º32
output = model(x)
print(f"\nå…¥åŠ›shape: {x.shape}")
print(f"å‡ºåŠ›shape: {output.shape}")  # (32, 10)
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>SimpleNet(
  (fc1): Linear(in_features=784, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=128, bias=True)
  (fc3): Linear(in_features=128, out_features=10, bias=True)
)

ç·ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: 118,026

å…¥åŠ›shape: torch.Size([32, 784])
å‡ºåŠ›shape: torch.Size([32, 10])
</code></pre>

<h3>å­¦ç¿’ãƒ«ãƒ¼ãƒ—ã®å®Ÿè£…</h3>

<pre><code class="language-python">import torch
import torch.nn as nn
import torch.optim as optim

# ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã®ä½œæˆ
X_train = torch.randn(1000, 784)
y_train = torch.randint(0, 10, (1000,))  # 0-9ã®ãƒ©ãƒ™ãƒ«

# ãƒ¢ãƒ‡ãƒ«ã€æå¤±é–¢æ•°ã€ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ã®æº–å‚™
model = SimpleNet(784, 128, 10)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# å­¦ç¿’ãƒ«ãƒ¼ãƒ—
num_epochs = 10
batch_size = 32

print("=== å­¦ç¿’é–‹å§‹ ===")
for epoch in range(num_epochs):
    # ã‚¨ãƒãƒƒã‚¯ã”ã¨ã®æå¤±
    epoch_loss = 0.0
    num_batches = 0

    # ãƒŸãƒ‹ãƒãƒƒãƒã«åˆ†å‰²
    for i in range(0, len(X_train), batch_size):
        # ãƒãƒƒãƒãƒ‡ãƒ¼ã‚¿ã®å–å¾—
        batch_X = X_train[i:i+batch_size]
        batch_y = y_train[i:i+batch_size]

        # å‹¾é…ã‚’ã‚¼ãƒ­ã«ãƒªã‚»ãƒƒãƒˆï¼ˆé‡è¦ï¼ï¼‰
        optimizer.zero_grad()

        # é †ä¼æ’­
        outputs = model(batch_X)

        # æå¤±è¨ˆç®—
        loss = criterion(outputs, batch_y)

        # é€†ä¼æ’­
        loss.backward()

        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ›´æ–°
        optimizer.step()

        epoch_loss += loss.item()
        num_batches += 1

    # ã‚¨ãƒãƒƒã‚¯ã”ã¨ã®å¹³å‡æå¤±
    avg_loss = epoch_loss / num_batches
    print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}")

print("\nå­¦ç¿’å®Œäº†ï¼")
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>=== å­¦ç¿’é–‹å§‹ ===
Epoch [1/10], Loss: 2.3124
Epoch [2/10], Loss: 2.2845
Epoch [3/10], Loss: 2.2567
Epoch [4/10], Loss: 2.2301
Epoch [5/10], Loss: 2.2048
Epoch [6/10], Loss: 2.1807
Epoch [7/10], Loss: 2.1577
Epoch [8/10], Loss: 2.1357
Epoch [9/10], Loss: 2.1146
Epoch [10/10], Loss: 2.0944

å­¦ç¿’å®Œäº†ï¼
</code></pre>

<hr>

<h2>4.2 å®Ÿè·µçš„ãªãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰</h2>

<h3>ã‚«ã‚¹ã‚¿ãƒ ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®ä½œæˆ</h3>

<p>ç‹¬è‡ªã®å‡¦ç†ã‚’è¡Œã†ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚’nn.Moduleã‚’ç¶™æ‰¿ã—ã¦ä½œæˆã§ãã¾ã™ã€‚</p>

<pre><code class="language-python">import torch
import torch.nn as nn
import math

class GaussianNoise(nn.Module):
    """å­¦ç¿’æ™‚ã«ã‚¬ã‚¦ã‚·ã‚¢ãƒ³ãƒã‚¤ã‚ºã‚’è¿½åŠ ã™ã‚‹ãƒ¬ã‚¤ãƒ¤ãƒ¼"""

    def __init__(self, sigma=0.1):
        """
        Args:
            sigma: ãƒã‚¤ã‚ºã®æ¨™æº–åå·®
        """
        super(GaussianNoise, self).__init__()
        self.sigma = sigma

    def forward(self, x):
        """
        å­¦ç¿’æ™‚ã®ã¿ãƒã‚¤ã‚ºã‚’è¿½åŠ 
        """
        if self.training:  # å­¦ç¿’ãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã®ã¿
            noise = torch.randn_like(x) * self.sigma
            return x + noise
        return x

class ResidualBlock(nn.Module):
    """æ®‹å·®æ¥ç¶šï¼ˆResidual Connectionï¼‰ã‚’æŒã¤ãƒ–ãƒ­ãƒƒã‚¯"""

    def __init__(self, size):
        super(ResidualBlock, self).__init__()
        self.fc1 = nn.Linear(size, size)
        self.fc2 = nn.Linear(size, size)
        self.bn1 = nn.BatchNorm1d(size)
        self.bn2 = nn.BatchNorm1d(size)

    def forward(self, x):
        """
        y = F(x) + x  ï¼ˆæ®‹å·®æ¥ç¶šï¼‰
        """
        residual = x  # ã‚·ãƒ§ãƒ¼ãƒˆã‚«ãƒƒãƒˆæ¥ç¶š

        out = F.relu(self.bn1(self.fc1(x)))
        out = self.bn2(self.fc2(out))

        out = out + residual  # æ®‹å·®ã‚’è¿½åŠ 
        out = F.relu(out)

        return out

# ã‚«ã‚¹ã‚¿ãƒ ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚’çµ„ã¿è¾¼ã‚“ã ãƒ¢ãƒ‡ãƒ«
class CustomNet(nn.Module):
    def __init__(self):
        super(CustomNet, self).__init__()
        self.fc1 = nn.Linear(784, 256)
        self.noise = GaussianNoise(sigma=0.05)
        self.res1 = ResidualBlock(256)
        self.res2 = ResidualBlock(256)
        self.fc_out = nn.Linear(256, 10)

    def forward(self, x):
        x = F.relu(self.fc1(x))
        x = self.noise(x)  # ãƒã‚¤ã‚ºè¿½åŠ ï¼ˆæ­£å‰‡åŒ–ï¼‰
        x = self.res1(x)   # æ®‹å·®ãƒ–ãƒ­ãƒƒã‚¯1
        x = self.res2(x)   # æ®‹å·®ãƒ–ãƒ­ãƒƒã‚¯2
        x = self.fc_out(x)
        return x

# ãƒ†ã‚¹ãƒˆ
model = CustomNet()
x = torch.randn(16, 784)

# å­¦ç¿’ãƒ¢ãƒ¼ãƒ‰
model.train()
out_train = model(x)
print(f"å­¦ç¿’ãƒ¢ãƒ¼ãƒ‰å‡ºåŠ›: {out_train.shape}")

# è©•ä¾¡ãƒ¢ãƒ¼ãƒ‰
model.eval()
out_eval = model(x)
print(f"è©•ä¾¡ãƒ¢ãƒ¼ãƒ‰å‡ºåŠ›: {out_eval.shape}")
</code></pre>

<div class="mermaid">
graph LR
    input[å…¥åŠ› x] --> fc1[å…¨çµåˆå±¤]
    fc1 --> noise[ã‚¬ã‚¦ã‚·ã‚¢ãƒ³ãƒã‚¤ã‚º]
    noise --> res1[æ®‹å·®ãƒ–ãƒ­ãƒƒã‚¯1]
    res1 --> res2[æ®‹å·®ãƒ–ãƒ­ãƒƒã‚¯2]
    res2 --> fc_out[å‡ºåŠ›å±¤]
    fc_out --> output[å‡ºåŠ›]

    input -.ã‚·ãƒ§ãƒ¼ãƒˆã‚«ãƒƒãƒˆ.-> res1
    res1 -.ã‚·ãƒ§ãƒ¼ãƒˆã‚«ãƒƒãƒˆ.-> res2

    style input fill:#e3f2fd
    style noise fill:#fff9c4
    style res1 fill:#f3e5f5
    style res2 fill:#f3e5f5
    style output fill:#e8f5e9
</div>

<h3>æå¤±é–¢æ•°ã¨ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶</h3>

<p>PyTorchã¯å¤šæ§˜ãªæå¤±é–¢æ•°ã¨ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ã‚’æä¾›ã—ã¦ã„ã¾ã™ã€‚</p>

<pre><code class="language-python">import torch
import torch.nn as nn
import torch.optim as optim

# ãƒ¢ãƒ‡ãƒ«ã®æº–å‚™
model = SimpleNet(784, 128, 10)

print("=== æå¤±é–¢æ•°ã®é¸æŠ ===")

# åˆ†é¡å•é¡Œã®æå¤±é–¢æ•°
criterion_ce = nn.CrossEntropyLoss()  # å¤šã‚¯ãƒ©ã‚¹åˆ†é¡
criterion_bce = nn.BCEWithLogitsLoss()  # äºŒå€¤åˆ†é¡
criterion_nll = nn.NLLLoss()  # è² ã®å¯¾æ•°å°¤åº¦

# å›å¸°å•é¡Œã®æå¤±é–¢æ•°
criterion_mse = nn.MSELoss()  # å¹³å‡äºŒä¹—èª¤å·®
criterion_mae = nn.L1Loss()   # å¹³å‡çµ¶å¯¾èª¤å·®
criterion_huber = nn.SmoothL1Loss()  # Huberæå¤±

print("åˆ†é¡: CrossEntropyLoss, BCEWithLogitsLoss, NLLLoss")
print("å›å¸°: MSELoss, L1Loss, SmoothL1Loss")

print("\n=== ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ã®é¸æŠ ===")

# SGDï¼ˆç¢ºç‡çš„å‹¾é…é™ä¸‹æ³•ï¼‰
optimizer_sgd = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)

# Adamï¼ˆé©å¿œçš„å­¦ç¿’ç‡ï¼‰
optimizer_adam = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999))

# AdamWï¼ˆWeight Decayã‚’æ”¹å–„ã—ãŸAdamï¼‰
optimizer_adamw = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)

# RMSprop
optimizer_rmsprop = optim.RMSprop(model.parameters(), lr=0.01, alpha=0.99)

print("SGD: å¤å…¸çš„ã€ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ ã§å®‰å®šåŒ–")
print("Adam: é©å¿œçš„å­¦ç¿’ç‡ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§è‰¯å¥½")
print("AdamW: Adamã®æ”¹è‰¯ç‰ˆã€æ­£å‰‡åŒ–ãŒæ”¹å–„")
print("RMSprop: RNNã§åŠ¹æœçš„")

# ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ã®ä½¿ç”¨ä¾‹
print("\n=== å­¦ç¿’ã‚¹ãƒ†ãƒƒãƒ—ã®ä¾‹ ===")
optimizer = optim.Adam(model.parameters(), lr=0.001)
criterion = nn.CrossEntropyLoss()

# ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿
x = torch.randn(32, 784)
y = torch.randint(0, 10, (32,))

# 1ã‚¹ãƒ†ãƒƒãƒ—ã®å­¦ç¿’
optimizer.zero_grad()      # å‹¾é…ãƒªã‚»ãƒƒãƒˆ
output = model(x)          # é †ä¼æ’­
loss = criterion(output, y)  # æå¤±è¨ˆç®—
loss.backward()            # é€†ä¼æ’­
optimizer.step()           # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ›´æ–°

print(f"æå¤±: {loss.item():.4f}")
</code></pre>

<h3>DataLoaderã¨ãƒãƒƒãƒå‡¦ç†</h3>

<p><strong>DataLoader</strong>ã¯ã€ãƒ‡ãƒ¼ã‚¿ã®è‡ªå‹•ãƒãƒƒãƒåŒ–ã€ã‚·ãƒ£ãƒƒãƒ•ãƒ«ã€ä¸¦åˆ—èª­ã¿è¾¼ã¿ã‚’æä¾›ã—ã¾ã™ã€‚</p>

<pre><code class="language-python">import torch
from torch.utils.data import Dataset, DataLoader
import numpy as np

# ã‚«ã‚¹ã‚¿ãƒ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚¯ãƒ©ã‚¹
class CustomDataset(Dataset):
    """ã‚«ã‚¹ã‚¿ãƒ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®å®Ÿè£…ä¾‹"""

    def __init__(self, data, labels, transform=None):
        """
        Args:
            data: å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ï¼ˆNumPyé…åˆ—ã¾ãŸã¯ãƒ†ãƒ³ã‚½ãƒ«ï¼‰
            labels: ãƒ©ãƒ™ãƒ«ãƒ‡ãƒ¼ã‚¿
            transform: ãƒ‡ãƒ¼ã‚¿å¤‰æ›é–¢æ•°ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        """
        self.data = data
        self.labels = labels
        self.transform = transform

    def __len__(self):
        """ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã‚µã‚¤ã‚ºã‚’è¿”ã™"""
        return len(self.data)

    def __getitem__(self, idx):
        """ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«å¯¾å¿œã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã™"""
        x = self.data[idx]
        y = self.labels[idx]

        # å¤‰æ›ã‚’é©ç”¨
        if self.transform:
            x = self.transform(x)

        return x, y

# ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã®ä½œæˆ
np.random.seed(42)
data = np.random.randn(1000, 784).astype(np.float32)
labels = np.random.randint(0, 10, size=1000)

# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ä½œæˆ
dataset = CustomDataset(data, labels)

# DataLoaderã®ä½œæˆ
train_loader = DataLoader(
    dataset,
    batch_size=32,      # ãƒãƒƒãƒã‚µã‚¤ã‚º
    shuffle=True,       # ã‚¨ãƒãƒƒã‚¯ã”ã¨ã«ã‚·ãƒ£ãƒƒãƒ•ãƒ«
    num_workers=0,      # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã®ä¸¦åˆ—æ•°ï¼ˆ0=ãƒ¡ã‚¤ãƒ³ãƒ—ãƒ­ã‚»ã‚¹ã®ã¿ï¼‰
    drop_last=True      # æœ€å¾Œã®ä¸å®Œå…¨ãªãƒãƒƒãƒã‚’ç ´æ£„
)

print(f"ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚µã‚¤ã‚º: {len(dataset)}")
print(f"ãƒãƒƒãƒæ•°: {len(train_loader)}")

# DataLoaderã®ä½¿ç”¨ä¾‹
print("\n=== DataLoaderã«ã‚ˆã‚‹ãƒãƒƒãƒå‡¦ç† ===")
for batch_idx, (data_batch, labels_batch) in enumerate(train_loader):
    if batch_idx >= 3:  # æœ€åˆã®3ãƒãƒƒãƒã®ã¿è¡¨ç¤º
        break
    print(f"ãƒãƒƒãƒ {batch_idx+1}: data shape={data_batch.shape}, labels shape={labels_batch.shape}")

# å­¦ç¿’ãƒ«ãƒ¼ãƒ—ã§ã®ä½¿ç”¨ä¾‹
print("\n=== å­¦ç¿’ãƒ«ãƒ¼ãƒ—ä¾‹ ===")
model = SimpleNet(784, 128, 10)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

for epoch in range(3):
    model.train()
    total_loss = 0

    for batch_idx, (data, target) in enumerate(train_loader):
        optimizer.zero_grad()
        output = model(data)
        loss = criterion(output, target)
        loss.backward()
        optimizer.step()

        total_loss += loss.item()

    avg_loss = total_loss / len(train_loader)
    print(f"Epoch {epoch+1}: å¹³å‡æå¤± = {avg_loss:.4f}")
</code></pre>

<h3>å­¦ç¿’ã®å¯è¦–åŒ–</h3>

<pre><code class="language-python">import matplotlib.pyplot as plt
from IPython.display import clear_output

class TrainingMonitor:
    """å­¦ç¿’éç¨‹ã‚’å¯è¦–åŒ–ã™ã‚‹ã‚¯ãƒ©ã‚¹"""

    def __init__(self):
        self.train_losses = []
        self.val_losses = []
        self.train_accs = []
        self.val_accs = []

    def update(self, train_loss, val_loss, train_acc, val_acc):
        """ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è¿½åŠ """
        self.train_losses.append(train_loss)
        self.val_losses.append(val_loss)
        self.train_accs.append(train_acc)
        self.val_accs.append(val_acc)

    def plot(self):
        """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ—ãƒ­ãƒƒãƒˆ"""
        clear_output(wait=True)

        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))

        # æå¤±ã®ãƒ—ãƒ­ãƒƒãƒˆ
        ax1.plot(self.train_losses, label='Train Loss', marker='o')
        ax1.plot(self.val_losses, label='Val Loss', marker='s')
        ax1.set_xlabel('Epoch')
        ax1.set_ylabel('Loss')
        ax1.set_title('Training and Validation Loss')
        ax1.legend()
        ax1.grid(True, alpha=0.3)

        # ç²¾åº¦ã®ãƒ—ãƒ­ãƒƒãƒˆ
        ax2.plot(self.train_accs, label='Train Acc', marker='o')
        ax2.plot(self.val_accs, label='Val Acc', marker='s')
        ax2.set_xlabel('Epoch')
        ax2.set_ylabel('Accuracy (%)')
        ax2.set_title('Training and Validation Accuracy')
        ax2.legend()
        ax2.grid(True, alpha=0.3)

        plt.tight_layout()
        plt.show()

# ä½¿ç”¨ä¾‹
monitor = TrainingMonitor()

# ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
for epoch in range(10):
    # æå¤±ã¯å¾ã€…ã«æ¸›å°‘
    train_loss = 2.0 - epoch * 0.15 + np.random.randn() * 0.05
    val_loss = 2.1 - epoch * 0.13 + np.random.randn() * 0.05

    # ç²¾åº¦ã¯å¾ã€…ã«å‘ä¸Š
    train_acc = 20 + epoch * 7 + np.random.randn() * 2
    val_acc = 18 + epoch * 6.5 + np.random.randn() * 2

    monitor.update(train_loss, val_loss, train_acc, val_acc)
    monitor.plot()

print("å­¦ç¿’æ›²ç·šã®å¯è¦–åŒ–å®Œäº†")
</code></pre>

<hr>

<h2>4.3 TensorFlow/Keraså…¥é–€</h2>

<h3>TensorFlowã¨Kerasã®æ¦‚è¦</h3>

<p><strong>TensorFlow</strong>ã¯GoogleãŒé–‹ç™ºã—ãŸãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã€<strong>Keras</strong>ã¯é«˜ãƒ¬ãƒ™ãƒ«APIã¨ã—ã¦çµ±åˆã•ã‚Œã¦ã„ã¾ã™ã€‚</p>

<ul>
<li><strong>Define-and-Run</strong>: é™çš„ãªè¨ˆç®—ã‚°ãƒ©ãƒ•ï¼ˆé«˜é€ŸåŒ–ã«æœ‰åˆ©ï¼‰</li>
<li><strong>Eager Execution</strong>: TensorFlow 2.xä»¥é™ã¯å‹•çš„å®Ÿè¡Œã‚‚ã‚µãƒãƒ¼ãƒˆ</li>
<li><strong>Production Ready</strong>: TensorFlow Servingã€TF Liteã€TF.jsã§æœ¬ç•ªå±•é–‹ãŒå®¹æ˜“</li>
<li><strong>Keras API</strong>: ã‚·ãƒ³ãƒ—ãƒ«ã§ç›´æ„Ÿçš„ãªAPI</li>
</ul>

<h3>Sequential APIã¨Functional API</h3>

<pre><code class="language-python">import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np

print(f"TensorFlow version: {tf.__version__}")

# ===== Sequential API =====
print("\n=== Sequential API ===")
# å±¤ã‚’é †ç•ªã«ç©ã¿é‡ã­ã‚‹ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ¢ãƒ‡ãƒ«

model_seq = keras.Sequential([
    layers.Dense(128, activation='relu', input_shape=(784,)),
    layers.Dropout(0.2),
    layers.Dense(128, activation='relu'),
    layers.Dropout(0.2),
    layers.Dense(10, activation='softmax')
])

model_seq.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

print(model_seq.summary())

# ===== Functional API =====
print("\n=== Functional API ===")
# ã‚ˆã‚Šè¤‡é›‘ãªæ§‹é€ ï¼ˆåˆ†å²ã€ãƒãƒ«ãƒå…¥å‡ºåŠ›ï¼‰ãŒå¯èƒ½

# å…¥åŠ›ã®å®šç¾©
inputs = keras.Input(shape=(784,))

# éš ã‚Œå±¤ã®å®šç¾©
x = layers.Dense(128, activation='relu')(inputs)
x = layers.Dropout(0.2)(x)
x = layers.Dense(128, activation='relu')(x)
x = layers.Dropout(0.2)(x)

# å‡ºåŠ›å±¤
outputs = layers.Dense(10, activation='softmax')(x)

# ãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰
model_func = keras.Model(inputs=inputs, outputs=outputs)

model_func.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

print(model_func.summary())

# ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’
X_train = np.random.randn(1000, 784).astype(np.float32)
y_train = np.random.randint(0, 10, size=1000)

print("\n=== å­¦ç¿’å®Ÿè¡Œ ===")
history = model_seq.fit(
    X_train, y_train,
    batch_size=32,
    epochs=5,
    validation_split=0.2,
    verbose=1
)
</code></pre>

<h3>ã‚«ã‚¹ã‚¿ãƒ ãƒ¢ãƒ‡ãƒ«ã®ä½œæˆ</h3>

<pre><code class="language-python">import tensorflow as tf
from tensorflow import keras

class CustomModel(keras.Model):
    """ã‚«ã‚¹ã‚¿ãƒ ãƒ¢ãƒ‡ãƒ«ã‚¯ãƒ©ã‚¹ï¼ˆPyTorchã®nn.Moduleã«ç›¸å½“ï¼‰"""

    def __init__(self, num_classes=10):
        super(CustomModel, self).__init__()
        self.dense1 = layers.Dense(128, activation='relu')
        self.dropout1 = layers.Dropout(0.2)
        self.dense2 = layers.Dense(128, activation='relu')
        self.dropout2 = layers.Dropout(0.2)
        self.dense3 = layers.Dense(num_classes, activation='softmax')

    def call(self, inputs, training=False):
        """é †ä¼æ’­ï¼ˆPyTorchã®forwardã«ç›¸å½“ï¼‰"""
        x = self.dense1(inputs)
        x = self.dropout1(x, training=training)  # å­¦ç¿’æ™‚ã®ã¿Dropout
        x = self.dense2(x)
        x = self.dropout2(x, training=training)
        return self.dense3(x)

# ã‚«ã‚¹ã‚¿ãƒ ãƒ¢ãƒ‡ãƒ«ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–
custom_model = CustomModel(num_classes=10)

# ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«
custom_model.compile(
    optimizer=keras.optimizers.Adam(learning_rate=0.001),
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

# ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’
X_train = np.random.randn(1000, 784).astype(np.float32)
y_train = np.random.randint(0, 10, size=1000)

history = custom_model.fit(
    X_train, y_train,
    batch_size=32,
    epochs=5,
    validation_split=0.2,
    verbose=1
)

print("\nã‚«ã‚¹ã‚¿ãƒ ãƒ¢ãƒ‡ãƒ«å­¦ç¿’å®Œäº†")
</code></pre>

<h3>ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã®æ´»ç”¨</h3>

<p><strong>ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯</strong>ã¯ã€å­¦ç¿’ä¸­ã®ç‰¹å®šã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã§å®Ÿè¡Œã•ã‚Œã‚‹å‡¦ç†ã§ã™ã€‚</p>

<pre><code class="language-python">from tensorflow.keras.callbacks import (
    EarlyStopping,
    ModelCheckpoint,
    ReduceLROnPlateau,
    TensorBoard
)
import datetime

# Early Stopping: æ¤œè¨¼æå¤±ãŒæ”¹å–„ã—ãªããªã£ãŸã‚‰å­¦ç¿’ã‚’åœæ­¢
early_stop = EarlyStopping(
    monitor='val_loss',     # ç›£è¦–ã™ã‚‹æŒ‡æ¨™
    patience=5,              # æ”¹å–„ã—ãªã„ã‚¨ãƒãƒƒã‚¯æ•°
    restore_best_weights=True  # æœ€è‰¯ã®é‡ã¿ã‚’å¾©å…ƒ
)

# Model Checkpoint: ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜
checkpoint = ModelCheckpoint(
    filepath='best_model.h5',
    monitor='val_accuracy',
    save_best_only=True,
    verbose=1
)

# Learning Rate Scheduler: å­¦ç¿’ç‡ã‚’å‹•çš„ã«èª¿æ•´
reduce_lr = ReduceLROnPlateau(
    monitor='val_loss',
    factor=0.5,              # å­¦ç¿’ç‡ã‚’åŠåˆ†ã«
    patience=3,
    min_lr=1e-6,
    verbose=1
)

# TensorBoard: å­¦ç¿’éç¨‹ã®å¯è¦–åŒ–
log_dir = "logs/fit/" + datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
tensorboard = TensorBoard(log_dir=log_dir, histogram_freq=1)

# ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’ä½¿ã£ãŸå­¦ç¿’
model = keras.Sequential([
    layers.Dense(128, activation='relu', input_shape=(784,)),
    layers.Dropout(0.2),
    layers.Dense(64, activation='relu'),
    layers.Dense(10, activation='softmax')
])

model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

# ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿
X_train = np.random.randn(1000, 784).astype(np.float32)
y_train = np.random.randint(0, 10, size=1000)
X_val = np.random.randn(200, 784).astype(np.float32)
y_val = np.random.randint(0, 10, size=200)

# ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’æŒ‡å®šã—ã¦å­¦ç¿’
history = model.fit(
    X_train, y_train,
    batch_size=32,
    epochs=20,
    validation_data=(X_val, y_val),
    callbacks=[early_stop, checkpoint, reduce_lr],
    verbose=1
)

print("\nã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’æ´»ç”¨ã—ãŸå­¦ç¿’å®Œäº†")
print(f"å­¦ç¿’çµ‚äº†ã‚¨ãƒãƒƒã‚¯: {len(history.history['loss'])}")
</code></pre>

<h3>PyTorchã¨ã®æ¯”è¼ƒ</h3>

<table>
<thead>
<tr>
<th>æ©Ÿèƒ½</th>
<th>PyTorch</th>
<th>TensorFlow/Keras</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>è¨ˆç®—ã‚°ãƒ©ãƒ•</strong></td>
<td>å‹•çš„ï¼ˆDefine-by-Runï¼‰</td>
<td>é™çš„+å‹•çš„ï¼ˆEager Executionï¼‰</td>
</tr>
<tr>
<td><strong>ãƒ¢ãƒ‡ãƒ«å®šç¾©</strong></td>
<td>nn.Moduleç¶™æ‰¿</td>
<td>Sequential/Functional/Model</td>
</tr>
<tr>
<td><strong>å­¦ç¿’ãƒ«ãƒ¼ãƒ—</strong></td>
<td>æ‰‹å‹•ã§è¨˜è¿°</td>
<td>model.fit()ã§è‡ªå‹•åŒ–</td>
</tr>
<tr>
<td><strong>ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿</strong></td>
<td>DataLoader</td>
<td>tf.data.Dataset</td>
</tr>
<tr>
<td><strong>ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶</strong></td>
<td>torch.optim</td>
<td>keras.optimizers</td>
</tr>
<tr>
<td><strong>ãƒ‡ãƒã‚¤ã‚¹ç®¡ç†</strong></td>
<td>.to(device)æ˜ç¤ºçš„</td>
<td>è‡ªå‹•ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§GPUä½¿ç”¨ï¼‰</td>
</tr>
<tr>
<td><strong>ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£</strong></td>
<td>ç ”ç©¶è€…ã«äººæ°—</td>
<td>ç”£æ¥­ç•Œã«äººæ°—</td>
</tr>
<tr>
<td><strong>æœ¬ç•ªå±•é–‹</strong></td>
<td>TorchServe</td>
<td>TF Servingï¼ˆæˆç†Ÿï¼‰</td>
</tr>
</tbody>
</table>

<blockquote>
<p><strong>é¸æŠã®ãƒã‚¤ãƒ³ãƒˆ</strong>:<br>
- <strong>PyTorch</strong>: ç ”ç©¶ã€æŸ”è»Ÿæ€§é‡è¦–ã€ç´°ã‹ã„åˆ¶å¾¡ãŒå¿…è¦<br>
- <strong>TensorFlow/Keras</strong>: æœ¬ç•ªå±•é–‹ã€é«˜é€ŸåŒ–é‡è¦–ã€ã‚·ãƒ³ãƒ—ãƒ«ãªAPI</p>
</blockquote>

<div class="mermaid">
graph TB
    subgraph PyTorch
        A1[nn.Module] --> A2[forward]
        A2 --> A3[æ‰‹å‹•å­¦ç¿’ãƒ«ãƒ¼ãƒ—]
        A3 --> A4[optimizer.step]
    end

    subgraph TensorFlow
        B1[Sequential/Model] --> B2[call/forward]
        B2 --> B3[model.fit]
        B3 --> B4[è‡ªå‹•å­¦ç¿’]
    end

    style A1 fill:#ffe0b2
    style A2 fill:#fff9c4
    style A3 fill:#f0f4c3
    style A4 fill:#c8e6c9

    style B1 fill:#e1bee7
    style B2 fill:#f3e5f5
    style B3 fill:#e8eaf6
    style B4 fill:#c5cae9
</div>

<hr>

<h2>4.4 å®Ÿç”¨çš„ãªãƒ†ã‚¯ãƒ‹ãƒƒã‚¯</h2>

<h3>GPUä½¿ç”¨ã¨ãƒ¡ãƒ¢ãƒªç®¡ç†</h3>

<pre><code class="language-python">import torch
import torch.nn as nn

# === GPUä½¿ç”¨ã®åŸºæœ¬ ===
print("=== GPUæƒ…å ± ===")
print(f"CUDAåˆ©ç”¨å¯èƒ½: {torch.cuda.is_available()}")
if torch.cuda.is_available():
    print(f"GPUæ•°: {torch.cuda.device_count()}")
    print(f"GPUå: {torch.cuda.get_device_name(0)}")
    print(f"ãƒ¡ãƒ¢ãƒªå‰²ã‚Šå½“ã¦: {torch.cuda.memory_allocated(0) / 1024**2:.2f} MB")
    print(f"ãƒ¡ãƒ¢ãƒªã‚­ãƒ£ãƒƒã‚·ãƒ¥: {torch.cuda.memory_reserved(0) / 1024**2:.2f} MB")

# ãƒ‡ãƒã‚¤ã‚¹ã®é¸æŠ
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"\nä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹: {device}")

# ãƒ¢ãƒ‡ãƒ«ã¨ãƒ‡ãƒ¼ã‚¿ã‚’GPUã«è»¢é€
model = SimpleNet(784, 128, 10).to(device)
x = torch.randn(32, 784, device=device)  # ç›´æ¥GPUã«ä½œæˆ

# æ¨è«–
with torch.no_grad():  # å‹¾é…è¨ˆç®—ã‚’ç„¡åŠ¹åŒ–ï¼ˆãƒ¡ãƒ¢ãƒªç¯€ç´„ï¼‰
    output = model(x)
print(f"å‡ºåŠ›ãƒ‡ãƒã‚¤ã‚¹: {output.device}")

# === ãƒ¡ãƒ¢ãƒªç®¡ç†ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ ===
print("\n=== ãƒ¡ãƒ¢ãƒªç®¡ç† ===")

# 1. ä¸è¦ãªãƒ†ãƒ³ã‚½ãƒ«ã¯å‰Šé™¤
x = torch.randn(1000, 1000, device=device)
del x
torch.cuda.empty_cache()  # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢

# 2. Gradient Checkpointingï¼ˆãƒ¡ãƒ¢ãƒªã¨è¨ˆç®—ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ï¼‰
from torch.utils.checkpoint import checkpoint

class MemoryEfficientNet(nn.Module):
    def __init__(self):
        super().__init__()
        self.layer1 = nn.Linear(784, 1024)
        self.layer2 = nn.Linear(1024, 1024)
        self.layer3 = nn.Linear(1024, 10)

    def forward(self, x):
        # checkpointã‚’ä½¿ã†ã¨ã€ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãŒæ¸›ã‚‹ï¼ˆè¨ˆç®—ã¯é…ããªã‚‹ï¼‰
        x = checkpoint(lambda x: F.relu(self.layer1(x)), x)
        x = checkpoint(lambda x: F.relu(self.layer2(x)), x)
        x = self.layer3(x)
        return x

# 3. Mixed Precision Trainingï¼ˆãƒ¡ãƒ¢ãƒªå‰Šæ¸›ï¼‹é«˜é€ŸåŒ–ï¼‰
from torch.cuda.amp import autocast, GradScaler

model = SimpleNet(784, 128, 10).to(device)
optimizer = torch.optim.Adam(model.parameters())
scaler = GradScaler()  # è‡ªå‹•ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°

for epoch in range(3):
    for data, target in [(torch.randn(32, 784, device=device),
                          torch.randint(0, 10, (32,), device=device))]:
        optimizer.zero_grad()

        # Mixed Precision
        with autocast():
            output = model(data)
            loss = F.cross_entropy(output, target)

        # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ä»˜ãé€†ä¼æ’­
        scaler.scale(loss).backward()
        scaler.step(optimizer)
        scaler.update()

    print(f"Epoch {epoch+1} å®Œäº†")

print("\nGPUæœ€é©åŒ–å­¦ç¿’å®Œäº†")
</code></pre>

<h3>ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜ã¨èª­ã¿è¾¼ã¿</h3>

<pre><code class="language-python">import torch
import torch.nn as nn

# ãƒ¢ãƒ‡ãƒ«ã®æº–å‚™
model = SimpleNet(784, 128, 10)
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

# ===== PyTorchã§ã®ä¿å­˜ãƒ»èª­ã¿è¾¼ã¿ =====
print("=== PyTorch: ãƒ¢ãƒ‡ãƒ«ä¿å­˜ ===")

# æ–¹æ³•1: state_dictã®ã¿ä¿å­˜ï¼ˆæ¨å¥¨ï¼‰
torch.save(model.state_dict(), 'model_weights.pth')
print("é‡ã¿ã‚’ä¿å­˜: model_weights.pth")

# æ–¹æ³•2: ãƒ¢ãƒ‡ãƒ«å…¨ä½“ã‚’ä¿å­˜
torch.save(model, 'model_full.pth')
print("ãƒ¢ãƒ‡ãƒ«å…¨ä½“ã‚’ä¿å­˜: model_full.pth")

# æ–¹æ³•3: ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆï¼ˆå­¦ç¿’é€”ä¸­ã®çŠ¶æ…‹ï¼‰
checkpoint = {
    'epoch': 10,
    'model_state_dict': model.state_dict(),
    'optimizer_state_dict': optimizer.state_dict(),
    'loss': 0.5,
}
torch.save(checkpoint, 'checkpoint.pth')
print("ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜: checkpoint.pth")

print("\n=== PyTorch: ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ ===")

# æ–¹æ³•1: state_dictã®èª­ã¿è¾¼ã¿
model_new = SimpleNet(784, 128, 10)
model_new.load_state_dict(torch.load('model_weights.pth'))
model_new.eval()  # è©•ä¾¡ãƒ¢ãƒ¼ãƒ‰ã«è¨­å®š
print("é‡ã¿ã‚’èª­ã¿è¾¼ã¿å®Œäº†")

# æ–¹æ³•2: ãƒ¢ãƒ‡ãƒ«å…¨ä½“ã®èª­ã¿è¾¼ã¿
model_loaded = torch.load('model_full.pth')
model_loaded.eval()
print("ãƒ¢ãƒ‡ãƒ«å…¨ä½“èª­ã¿è¾¼ã¿å®Œäº†")

# æ–¹æ³•3: ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰å†é–‹
checkpoint = torch.load('checkpoint.pth')
model_new.load_state_dict(checkpoint['model_state_dict'])
optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
epoch = checkpoint['epoch']
loss = checkpoint['loss']
print(f"ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆèª­ã¿è¾¼ã¿: Epoch={epoch}, Loss={loss}")

# ===== TensorFlow/Kerasã§ã®ä¿å­˜ãƒ»èª­ã¿è¾¼ã¿ =====
print("\n=== TensorFlow/Keras: ãƒ¢ãƒ‡ãƒ«ä¿å­˜ ===")

# Kerasãƒ¢ãƒ‡ãƒ«ã®æº–å‚™
keras_model = keras.Sequential([
    layers.Dense(128, activation='relu', input_shape=(784,)),
    layers.Dense(10, activation='softmax')
])
keras_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')

# æ–¹æ³•1: SavedFormatï¼ˆæ¨å¥¨ï¼‰
keras_model.save('saved_model/')
print("SavedFormatä¿å­˜: saved_model/")

# æ–¹æ³•2: HDF5å½¢å¼
keras_model.save('model.h5')
print("HDF5ä¿å­˜: model.h5")

# æ–¹æ³•3: é‡ã¿ã®ã¿
keras_model.save_weights('weights.h5')
print("é‡ã¿ã®ã¿ä¿å­˜: weights.h5")

print("\n=== TensorFlow/Keras: ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ ===")

# SavedFormatã‹ã‚‰èª­ã¿è¾¼ã¿
loaded_model = keras.models.load_model('saved_model/')
print("SavedFormatèª­ã¿è¾¼ã¿å®Œäº†")

# HDF5ã‹ã‚‰èª­ã¿è¾¼ã¿
loaded_model_h5 = keras.models.load_model('model.h5')
print("HDF5èª­ã¿è¾¼ã¿å®Œäº†")

# é‡ã¿ã®ã¿èª­ã¿è¾¼ã¿
new_model = keras.Sequential([
    layers.Dense(128, activation='relu', input_shape=(784,)),
    layers.Dense(10, activation='softmax')
])
new_model.load_weights('weights.h5')
print("é‡ã¿ã®ã¿èª­ã¿è¾¼ã¿å®Œäº†")
</code></pre>

<h3>Early Stoppingã¨Checkpointing</h3>

<pre><code class="language-python">import torch
import numpy as np

class EarlyStopping:
    """Early Stoppingã‚’å®Ÿè£…ã™ã‚‹ã‚¯ãƒ©ã‚¹ï¼ˆPyTorchç”¨ï¼‰"""

    def __init__(self, patience=7, min_delta=0, restore_best_weights=True):
        """
        Args:
            patience: æ”¹å–„ã—ãªã„ã‚¨ãƒãƒƒã‚¯æ•°
            min_delta: æ”¹å–„ã¨åˆ¤å®šã™ã‚‹æœ€å°å¤‰åŒ–é‡
            restore_best_weights: æœ€è‰¯ã®é‡ã¿ã‚’å¾©å…ƒã™ã‚‹ã‹
        """
        self.patience = patience
        self.min_delta = min_delta
        self.restore_best_weights = restore_best_weights

        self.counter = 0
        self.best_loss = None
        self.early_stop = False
        self.best_weights = None

    def __call__(self, val_loss, model):
        """
        Args:
            val_loss: æ¤œè¨¼æå¤±
            model: ãƒ¢ãƒ‡ãƒ«

        Returns:
            æ—©æœŸåœæ­¢ã™ã¹ãã‹ã©ã†ã‹
        """
        if self.best_loss is None:
            self.best_loss = val_loss
            self.save_checkpoint(model)
        elif val_loss > self.best_loss - self.min_delta:
            self.counter += 1
            print(f'EarlyStopping counter: {self.counter}/{self.patience}')
            if self.counter >= self.patience:
                self.early_stop = True
                if self.restore_best_weights:
                    print('æœ€è‰¯ã®é‡ã¿ã‚’å¾©å…ƒã—ã¾ã™')
                    model.load_state_dict(self.best_weights)
        else:
            self.best_loss = val_loss
            self.save_checkpoint(model)
            self.counter = 0

        return self.early_stop

    def save_checkpoint(self, model):
        """ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜"""
        if self.restore_best_weights:
            self.best_weights = model.state_dict().copy()

# ä½¿ç”¨ä¾‹
print("=== Early Stopping å®Ÿè£…ä¾‹ ===")
model = SimpleNet(784, 128, 10)
optimizer = torch.optim.Adam(model.parameters())
criterion = nn.CrossEntropyLoss()
early_stopping = EarlyStopping(patience=5, restore_best_weights=True)

# ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿
X_train = torch.randn(800, 784)
y_train = torch.randint(0, 10, (800,))
X_val = torch.randn(200, 784)
y_val = torch.randint(0, 10, (200,))

for epoch in range(50):
    # å­¦ç¿’
    model.train()
    optimizer.zero_grad()
    output = model(X_train)
    loss = criterion(output, y_train)
    loss.backward()
    optimizer.step()

    # æ¤œè¨¼
    model.eval()
    with torch.no_grad():
        val_output = model(X_val)
        val_loss = criterion(val_output, y_val)

    print(f'Epoch {epoch+1}: Train Loss={loss.item():.4f}, Val Loss={val_loss.item():.4f}')

    # Early Stoppingåˆ¤å®š
    if early_stopping(val_loss.item(), model):
        print(f'Early stopping at epoch {epoch+1}')
        break

print("\nå­¦ç¿’å®Œäº†")
</code></pre>

<h3>å­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°</h3>

<pre><code class="language-python">import torch
import torch.optim as optim
from torch.optim.lr_scheduler import (
    StepLR,
    ExponentialLR,
    CosineAnnealingLR,
    ReduceLROnPlateau
)
import matplotlib.pyplot as plt

# ãƒ¢ãƒ‡ãƒ«ã¨ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶
model = SimpleNet(784, 128, 10)
optimizer = optim.Adam(model.parameters(), lr=0.1)

print("=== å­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ã®ç¨®é¡ ===\n")

# 1. StepLR: ä¸€å®šã‚¨ãƒãƒƒã‚¯ã”ã¨ã«å­¦ç¿’ç‡ã‚’æ¸›è¡°
scheduler1 = StepLR(optimizer, step_size=10, gamma=0.5)
print("StepLR: 10ã‚¨ãƒãƒƒã‚¯ã”ã¨ã«å­¦ç¿’ç‡ã‚’åŠæ¸›")

# 2. ExponentialLR: æŒ‡æ•°é–¢æ•°çš„ã«æ¸›è¡°
scheduler2 = ExponentialLR(optimizer, gamma=0.95)
print("ExponentialLR: æ¯ã‚¨ãƒãƒƒã‚¯5%æ¸›è¡°")

# 3. CosineAnnealingLR: ã‚³ã‚µã‚¤ãƒ³é–¢æ•°ã§æ¸›è¡°
scheduler3 = CosineAnnealingLR(optimizer, T_max=50, eta_min=1e-6)
print("CosineAnnealingLR: ã‚³ã‚µã‚¤ãƒ³é–¢æ•°ã§æ»‘ã‚‰ã‹ã«æ¸›è¡°")

# 4. ReduceLROnPlateau: æå¤±ãŒæ”¹å–„ã—ãªã„å ´åˆã«æ¸›è¡°
scheduler4 = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)
print("ReduceLROnPlateau: æå¤±ãŒæ”¹å–„ã—ãªã„å ´åˆã«æ¸›è¡°")

# å­¦ç¿’ç‡ã®æ¨ç§»ã‚’å¯è¦–åŒ–
print("\n=== å­¦ç¿’ç‡ã®æ¨ç§» ===")

schedulers = {
    'StepLR': StepLR(optim.Adam(model.parameters(), lr=0.1), step_size=10, gamma=0.5),
    'ExponentialLR': ExponentialLR(optim.Adam(model.parameters(), lr=0.1), gamma=0.95),
    'CosineAnnealingLR': CosineAnnealingLR(optim.Adam(model.parameters(), lr=0.1), T_max=50)
}

fig, ax = plt.subplots(figsize=(10, 6))

for name, scheduler in schedulers.items():
    lrs = []
    optimizer = scheduler.optimizer

    for epoch in range(50):
        lrs.append(optimizer.param_groups[0]['lr'])
        scheduler.step()

    ax.plot(lrs, label=name, linewidth=2)

ax.set_xlabel('Epoch', fontsize=12)
ax.set_ylabel('Learning Rate', fontsize=12)
ax.set_title('å­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ã®æ¯”è¼ƒ', fontsize=14, fontweight='bold')
ax.legend(fontsize=11)
ax.grid(True, alpha=0.3)
ax.set_yscale('log')
plt.tight_layout()
plt.show()

# å®Ÿéš›ã®ä½¿ç”¨ä¾‹
print("\n=== ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ä½¿ç”¨ä¾‹ ===")
model = SimpleNet(784, 128, 10)
optimizer = optim.Adam(model.parameters(), lr=0.01)
scheduler = CosineAnnealingLR(optimizer, T_max=10)

for epoch in range(10):
    # å­¦ç¿’å‡¦ç†ï¼ˆçœç•¥ï¼‰
    current_lr = optimizer.param_groups[0]['lr']
    print(f"Epoch {epoch+1}: Learning Rate = {current_lr:.6f}")

    # ã‚¨ãƒãƒƒã‚¯çµ‚äº†æ™‚ã«ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ã‚’æ›´æ–°
    scheduler.step()

print("\nå­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°å®Œäº†")
</code></pre>

<div class="mermaid">
graph TB
    A[å­¦ç¿’é–‹å§‹] --> B{æ¤œè¨¼æå¤±æ”¹å–„?}
    B -->|Yes| C[å­¦ç¿’ç¶™ç¶š]
    B -->|No| D[ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼+1]
    D --> E{patienceè¶…é?}
    E -->|No| C
    E -->|Yes| F[Early Stopping]
    F --> G[ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«å¾©å…ƒ]

    C --> H{æœ€å¤§ã‚¨ãƒãƒƒã‚¯?}
    H -->|No| I[å­¦ç¿’ç‡æ›´æ–°]
    I --> B
    H -->|Yes| J[å­¦ç¿’å®Œäº†]

    style A fill:#e3f2fd
    style F fill:#ffebee
    style G fill:#fff9c4
    style J fill:#e8f5e9
</div>

<hr>

<h2>4.5 æœ¬ç« ã®ã¾ã¨ã‚</h2>

<h3>å­¦ã‚“ã ã“ã¨</h3>

<ol>
<li><p><strong>PyTorchåŸºç¤</strong></p>
<ul>
<li>ãƒ†ãƒ³ã‚½ãƒ«æ“ä½œã¨GPUæ´»ç”¨</li>
<li>Autogradã«ã‚ˆã‚‹è‡ªå‹•å¾®åˆ†</li>
<li>nn.Moduleã§ã®ãƒ¢ãƒ‡ãƒ«å®šç¾©</li>
<li>å­¦ç¿’ãƒ«ãƒ¼ãƒ—ã®å®Ÿè£…ãƒ‘ã‚¿ãƒ¼ãƒ³</li>
</ul></li>
<li><p><strong>å®Ÿè·µçš„ãªãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰</strong></p>
<ul>
<li>ã‚«ã‚¹ã‚¿ãƒ ãƒ¬ã‚¤ãƒ¤ãƒ¼ï¼ˆæ®‹å·®æ¥ç¶šã€ãƒã‚¤ã‚ºå±¤ï¼‰</li>
<li>æå¤±é–¢æ•°ã¨ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ã®é¸æŠ</li>
<li>DataLoaderã«ã‚ˆã‚‹åŠ¹ç‡çš„ãªãƒãƒƒãƒå‡¦ç†</li>
<li>å­¦ç¿’éç¨‹ã®å¯è¦–åŒ–</li>
</ul></li>
<li><p><strong>TensorFlow/Keras</strong></p>
<ul>
<li>Sequential/Functional/Custom Modelã®3ã¤ã®API</li>
<li>ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã«ã‚ˆã‚‹å­¦ç¿’åˆ¶å¾¡</li>
<li>PyTorchã¨ã®é•ã„ã¨ä½¿ã„åˆ†ã‘</li>
</ul></li>
<li><p><strong>å®Ÿç”¨ãƒ†ã‚¯ãƒ‹ãƒƒã‚¯</strong></p>
<ul>
<li>GPUãƒ¡ãƒ¢ãƒªç®¡ç†ã¨Mixed Precision</li>
<li>ãƒ¢ãƒ‡ãƒ«ä¿å­˜ãƒ»èª­ã¿è¾¼ã¿ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹</li>
<li>Early Stoppingã¨Checkpointing</li>
<li>å­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°</li>
</ul></li>
</ol>

<h3>ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯é¸æŠã‚¬ã‚¤ãƒ‰</h3>

<table>
<thead>
<tr>
<th>ç”¨é€”</th>
<th>æ¨å¥¨ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯</th>
<th>ç†ç”±</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>ç ”ç©¶ãƒ»è«–æ–‡å®Ÿè£…</strong></td>
<td>PyTorch</td>
<td>æŸ”è»Ÿæ€§ã€ãƒ‡ãƒãƒƒã‚°ã—ã‚„ã™ã•</td>
</tr>
<tr>
<td><strong>ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ”ãƒ³ã‚°</strong></td>
<td>Keras</td>
<td>ã‚·ãƒ³ãƒ—ãƒ«ã€é«˜é€Ÿé–‹ç™º</td>
</tr>
<tr>
<td><strong>æœ¬ç•ªå±•é–‹</strong></td>
<td>TensorFlow</td>
<td>TF Servingã€æˆç†Ÿã—ãŸã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ </td>
</tr>
<tr>
<td><strong>ã‚«ã‚¹ã‚¿ãƒ å®Ÿè£…</strong></td>
<td>PyTorch</td>
<td>ç´°ã‹ã„åˆ¶å¾¡ãŒå¯èƒ½</td>
</tr>
<tr>
<td><strong>ãƒ¢ãƒã‚¤ãƒ«/çµ„ã¿è¾¼ã¿</strong></td>
<td>TensorFlow</td>
<td>TF Liteã€æœ€é©åŒ–ãƒ„ãƒ¼ãƒ«</td>
</tr>
</tbody>
</table>

<h3>ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹</h3>

<ol>
<li><strong>ãƒ‡ãƒã‚¤ã‚¹ç®¡ç†</strong>: GPUã®æœ‰ç„¡ã«é–¢ã‚ã‚‰ãšå‹•ä½œã™ã‚‹ã‚³ãƒ¼ãƒ‰ã‚’æ›¸ã</li>
<li><strong>å†ç¾æ€§</strong>: ä¹±æ•°ã‚·ãƒ¼ãƒ‰ã‚’å›ºå®šï¼ˆ<code>torch.manual_seed(42)</code>ï¼‰</li>
<li><strong>ãƒ¡ãƒ¢ãƒªåŠ¹ç‡</strong>: <code>torch.no_grad()</code>ã§æ¨è«–æ™‚ã®ãƒ¡ãƒ¢ãƒªã‚’ç¯€ç´„</li>
<li><strong>å­¦ç¿’ç›£è¦–</strong>: TensorBoardã‚„WandBã§å¯è¦–åŒ–</li>
<li><strong>ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ</strong>: å®šæœŸçš„ã«ä¿å­˜ã—ã¦å­¦ç¿’ã®ä¸­æ–­ã«å‚™ãˆã‚‹</li>
</ol>

<h3>æ¬¡ã®ç« ã¸</h3>

<p>ç¬¬5ç« ã§ã¯ã€<strong>ç•³ã¿è¾¼ã¿ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼ˆCNNï¼‰</strong>ã‚’å­¦ã³ã¾ã™ï¼š</p>
<ul>
<li>ç”»åƒèªè­˜ã®ãŸã‚ã®ç•³ã¿è¾¼ã¿å±¤</li>
<li>ãƒ—ãƒ¼ãƒªãƒ³ã‚°å±¤ã¨ç‰¹å¾´æŠ½å‡º</li>
<li>ä»£è¡¨çš„ãªCNNã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ï¼ˆLeNetã€VGGã€ResNetï¼‰</li>
<li>å®Ÿãƒ‡ãƒ¼ã‚¿ï¼ˆCIFAR-10ã€ImageNetï¼‰ã§ã®å®Ÿè£…</li>
</ul>

<hr>

<h2>æ¼”ç¿’å•é¡Œ</h2>

<h3>å•é¡Œ1ï¼ˆé›£æ˜“åº¦ï¼šeasyï¼‰</h3>
<p>ä»¥ä¸‹ã®æ–‡ç« ã®æ­£èª¤ã‚’åˆ¤å®šã—ã¦ãã ã•ã„ã€‚</p>
<ol>
<li>PyTorchã¯Define-by-Runæ–¹å¼ã‚’æ¡ç”¨ã—ã¦ã„ã‚‹</li>
<li>TensorFlow 2.xã§ã¯Eager ExecutionãŒãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§æœ‰åŠ¹</li>
<li>nn.Moduleã®forwardãƒ¡ã‚½ãƒƒãƒ‰ã¯æ‰‹å‹•ã§å‘¼ã³å‡ºã™å¿…è¦ãŒã‚ã‚‹</li>
<li>DataLoaderã®shuffle=Trueã¯æ¯ã‚¨ãƒãƒƒã‚¯ã§ãƒ‡ãƒ¼ã‚¿é †ã‚’ã‚·ãƒ£ãƒƒãƒ•ãƒ«ã™ã‚‹</li>
</ol>

<details>
<summary>è§£ç­”ä¾‹</summary>

<p><strong>è§£ç­”</strong>ï¼š</p>
<ol>
<li><strong>æ­£</strong> - PyTorchã¯å‹•çš„ãªè¨ˆç®—ã‚°ãƒ©ãƒ•ã‚’æ§‹ç¯‰</li>
<li><strong>æ­£</strong> - TF 2.xã§ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§å‹•çš„å®Ÿè¡Œ</li>
<li><strong>èª¤</strong> - <code>model(x)</code>ã§è‡ªå‹•çš„ã«å‘¼ã°ã‚Œã‚‹</li>
<li><strong>æ­£</strong> - ã‚¨ãƒãƒƒã‚¯ã”ã¨ã«ã‚·ãƒ£ãƒƒãƒ•ãƒ«ã•ã‚Œã‚‹</li>
</ol>

</details>

<h3>å•é¡Œ2ï¼ˆé›£æ˜“åº¦ï¼šmediumï¼‰</h3>
<p>ä»¥ä¸‹ã®PyTorchã‚³ãƒ¼ãƒ‰ã®ãƒã‚°ã‚’ä¿®æ­£ã—ã¦ãã ã•ã„ã€‚</p>

<pre><code class="language-python">import torch
import torch.nn as nn

model = nn.Linear(10, 5)
optimizer = torch.optim.SGD(model.parameters(), lr=0.01)

for epoch in range(10):
    x = torch.randn(32, 10)
    y = torch.randn(32, 5)

    output = model(x)
    loss = nn.MSELoss(output, y)
    loss.backward()
    optimizer.step()
</code></pre>

<details>
<summary>ãƒ’ãƒ³ãƒˆ</summary>

<ul>
<li>æå¤±é–¢æ•°ã®ä½¿ã„æ–¹ã‚’ç¢ºèª</li>
<li>å‹¾é…ã®ãƒªã‚»ãƒƒãƒˆãŒå¿…è¦</li>
</ul>

</details>

<details>
<summary>è§£ç­”ä¾‹</summary>

<pre><code class="language-python">import torch
import torch.nn as nn

model = nn.Linear(10, 5)
optimizer = torch.optim.SGD(model.parameters(), lr=0.01)
criterion = nn.MSELoss()  # æå¤±é–¢æ•°ã‚’ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–

for epoch in range(10):
    x = torch.randn(32, 10)
    y = torch.randn(32, 5)

    optimizer.zero_grad()  # å‹¾é…ã‚’ã‚¼ãƒ­ã«ãƒªã‚»ãƒƒãƒˆï¼ˆè¿½åŠ ï¼‰
    output = model(x)
    loss = criterion(output, y)  # ä¿®æ­£
    loss.backward()
    optimizer.step()
</code></pre>

<p><strong>ä¿®æ­£ç‚¹</strong>ï¼š</p>
<ol>
<li><code>nn.MSELoss()</code>ã§ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–</li>
<li><code>optimizer.zero_grad()</code>ã§å‹¾é…ãƒªã‚»ãƒƒãƒˆ</li>
</ol>

</details>

<h3>å•é¡Œ3ï¼ˆé›£æ˜“åº¦ï¼šmediumï¼‰</h3>
<p>ä»¥ä¸‹ã®è¦ä»¶ã‚’æº€ãŸã™ã‚«ã‚¹ã‚¿ãƒ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚¯ãƒ©ã‚¹ã‚’å®Ÿè£…ã—ã¦ãã ã•ã„ï¼š</p>
<ul>
<li>NumPyé…åˆ—ã®ãƒ‡ãƒ¼ã‚¿ã¨ãƒ©ãƒ™ãƒ«ã‚’å—ã‘å–ã‚‹</li>
<li>ãƒ‡ãƒ¼ã‚¿ã‚’æ­£è¦åŒ–ï¼ˆå¹³å‡0ã€æ¨™æº–åå·®1ï¼‰</li>
<li>DataLoaderã§ä½¿ç”¨å¯èƒ½</li>
</ul>

<details>
<summary>è§£ç­”ä¾‹</summary>

<pre><code class="language-python">import torch
from torch.utils.data import Dataset, DataLoader
import numpy as np

class NormalizedDataset(Dataset):
    """æ­£è¦åŒ–ã‚’é©ç”¨ã™ã‚‹ã‚«ã‚¹ã‚¿ãƒ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ"""

    def __init__(self, data, labels):
        """
        Args:
            data: NumPyé…åˆ— (N, features)
            labels: NumPyé…åˆ— (N,)
        """
        # ãƒ‡ãƒ¼ã‚¿ã‚’æ­£è¦åŒ–
        self.mean = data.mean(axis=0)
        self.std = data.std(axis=0) + 1e-8  # ã‚¼ãƒ­é™¤ç®—å›é¿
        self.data = (data - self.mean) / self.std
        self.labels = labels

        # PyTorchãƒ†ãƒ³ã‚½ãƒ«ã«å¤‰æ›
        self.data = torch.FloatTensor(self.data)
        self.labels = torch.LongTensor(self.labels)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return self.data[idx], self.labels[idx]

# ãƒ†ã‚¹ãƒˆ
np.random.seed(42)
data = np.random.randn(100, 10) * 5 + 10  # å¹³å‡10ã€æ¨™æº–åå·®5
labels = np.random.randint(0, 3, size=100)

dataset = NormalizedDataset(data, labels)
loader = DataLoader(dataset, batch_size=16, shuffle=True)

# ç¢ºèª
sample_data, sample_label = dataset[0]
print(f"æ­£è¦åŒ–å¾Œã®ãƒ‡ãƒ¼ã‚¿ï¼ˆæœ€åˆã®ã‚µãƒ³ãƒ—ãƒ«ï¼‰: {sample_data}")
print(f"ãƒ‡ãƒ¼ã‚¿ã®å¹³å‡ï¼ˆæ­£è¦åŒ–å¾Œï¼‰: {dataset.data.mean():.4f}")
print(f"ãƒ‡ãƒ¼ã‚¿ã®æ¨™æº–åå·®ï¼ˆæ­£è¦åŒ–å¾Œï¼‰: {dataset.data.std():.4f}")
</code></pre>

</details>

<h3>å•é¡Œ4ï¼ˆé›£æ˜“åº¦ï¼šhardï¼‰</h3>
<p>PyTorchã¨TensorFlow/Kerasã®ä¸¡æ–¹ã§ã€åŒã˜ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®ãƒ¢ãƒ‡ãƒ«ã‚’å®Ÿè£…ã—ã¦ãã ã•ã„ï¼š</p>
<ul>
<li>å…¥åŠ›: 28x28ã®ç”»åƒï¼ˆ784æ¬¡å…ƒï¼‰</li>
<li>éš ã‚Œå±¤1: 256ãƒ¦ãƒ‹ãƒƒãƒˆã€ReLUã€Dropout(0.3)</li>
<li>éš ã‚Œå±¤2: 128ãƒ¦ãƒ‹ãƒƒãƒˆã€ReLUã€Dropout(0.3)</li>
<li>å‡ºåŠ›å±¤: 10ã‚¯ãƒ©ã‚¹åˆ†é¡</li>
</ul>

<details>
<summary>è§£ç­”ä¾‹</summary>

<p><strong>PyTorchå®Ÿè£…</strong>ï¼š</p>
<pre><code class="language-python">import torch
import torch.nn as nn
import torch.nn.functional as F

class PyTorchModel(nn.Module):
    def __init__(self):
        super(PyTorchModel, self).__init__()
        self.fc1 = nn.Linear(784, 256)
        self.dropout1 = nn.Dropout(0.3)
        self.fc2 = nn.Linear(256, 128)
        self.dropout2 = nn.Dropout(0.3)
        self.fc3 = nn.Linear(128, 10)

    def forward(self, x):
        x = F.relu(self.fc1(x))
        x = self.dropout1(x)
        x = F.relu(self.fc2(x))
        x = self.dropout2(x)
        x = self.fc3(x)
        return x

# ä½¿ç”¨ä¾‹
pytorch_model = PyTorchModel()
x = torch.randn(32, 784)
output = pytorch_model(x)
print(f"PyTorch output shape: {output.shape}")
</code></pre>

<p><strong>TensorFlow/Keraså®Ÿè£…</strong>ï¼š</p>
<pre><code class="language-python">import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

# Sequential API
keras_model = keras.Sequential([
    layers.Dense(256, activation='relu', input_shape=(784,)),
    layers.Dropout(0.3),
    layers.Dense(128, activation='relu'),
    layers.Dropout(0.3),
    layers.Dense(10)
])

# ä½¿ç”¨ä¾‹
x = tf.random.normal((32, 784))
output = keras_model(x)
print(f"Keras output shape: {output.shape}")
</code></pre>

<p><strong>ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã®ç¢ºèª</strong>ï¼š</p>
<pre><code class="language-python"># PyTorch
pytorch_params = sum(p.numel() for p in pytorch_model.parameters())
print(f"PyTorch parameters: {pytorch_params:,}")

# Keras
keras_model.summary()
</code></pre>

</details>

<h3>å•é¡Œ5ï¼ˆé›£æ˜“åº¦ï¼šhardï¼‰</h3>
<p>Early Stoppingã¨Model Checkpointingã‚’çµ„ã¿åˆã‚ã›ãŸå­¦ç¿’ã‚³ãƒ¼ãƒ‰ã‚’å®Ÿè£…ã—ã¦ãã ã•ã„ã€‚ä»¥ä¸‹ã®æ¡ä»¶ã‚’æº€ãŸã™ã“ã¨ï¼š</p>
<ul>
<li>æ¤œè¨¼æå¤±ãŒ5ã‚¨ãƒãƒƒã‚¯æ”¹å–„ã—ãªã„å ´åˆã«åœæ­¢</li>
<li>ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã‚’è‡ªå‹•ä¿å­˜</li>
<li>å­¦ç¿’çµ‚äº†æ™‚ã«ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã‚’å¾©å…ƒ</li>
</ul>

<details>
<summary>è§£ç­”ä¾‹</summary>

<pre><code class="language-python">import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np

class EarlyStoppingWithCheckpoint:
    """Early Stoppingã¨Checkpointingã‚’çµ±åˆã—ãŸã‚¯ãƒ©ã‚¹"""

    def __init__(self, patience=5, checkpoint_path='best_model.pth', verbose=True):
        self.patience = patience
        self.checkpoint_path = checkpoint_path
        self.verbose = verbose

        self.counter = 0
        self.best_loss = None
        self.early_stop = False

    def __call__(self, val_loss, model):
        if self.best_loss is None or val_loss < self.best_loss:
            # æ”¹å–„ã—ãŸå ´åˆ
            if self.verbose:
                if self.best_loss is not None:
                    improvement = self.best_loss - val_loss
                    print(f'æ¤œè¨¼æå¤±ãŒæ”¹å–„: {self.best_loss:.4f} â†’ {val_loss:.4f} ({improvement:.4f})')
                else:
                    print(f'åˆæœŸãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«: {val_loss:.4f}')

            self.best_loss = val_loss
            self.counter = 0

            # ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜
            torch.save(model.state_dict(), self.checkpoint_path)
            if self.verbose:
                print(f'ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜: {self.checkpoint_path}')
        else:
            # æ”¹å–„ã—ãªã‹ã£ãŸå ´åˆ
            self.counter += 1
            if self.verbose:
                print(f'EarlyStopping counter: {self.counter}/{self.patience}')

            if self.counter >= self.patience:
                self.early_stop = True
                if self.verbose:
                    print('Early Stoppingç™ºå‹•ï¼')

        return self.early_stop

    def load_best_model(self, model):
        """ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚€"""
        model.load_state_dict(torch.load(self.checkpoint_path))
        if self.verbose:
            print(f'ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã‚’å¾©å…ƒ: {self.checkpoint_path} (loss={self.best_loss:.4f})')

# ä½¿ç”¨ä¾‹
print("=== Early Stopping + Checkpoint å®Ÿè£…ä¾‹ ===\n")

# ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿
X_train = torch.randn(800, 784)
y_train = torch.randint(0, 10, (800,))
X_val = torch.randn(200, 784)
y_val = torch.randint(0, 10, (200,))

# ãƒ¢ãƒ‡ãƒ«ã€æå¤±é–¢æ•°ã€ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶
model = SimpleNet(784, 128, 10)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# Early Stoppingã®åˆæœŸåŒ–
early_stopping = EarlyStoppingWithCheckpoint(
    patience=5,
    checkpoint_path='best_model.pth',
    verbose=True
)

# å­¦ç¿’ãƒ«ãƒ¼ãƒ—
for epoch in range(50):
    # å­¦ç¿’
    model.train()
    optimizer.zero_grad()
    output = model(X_train)
    train_loss = criterion(output, y_train)
    train_loss.backward()
    optimizer.step()

    # æ¤œè¨¼
    model.eval()
    with torch.no_grad():
        val_output = model(X_val)
        val_loss = criterion(val_output, y_val)

    print(f'\nEpoch {epoch+1}: Train Loss={train_loss.item():.4f}, Val Loss={val_loss.item():.4f}')

    # Early Stoppingåˆ¤å®š
    if early_stopping(val_loss.item(), model):
        print(f'\nå­¦ç¿’ã‚’{epoch+1}ã‚¨ãƒãƒƒã‚¯ã§çµ‚äº†')
        break

# ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã‚’å¾©å…ƒ
print("\n" + "="*50)
early_stopping.load_best_model(model)
print("="*50)
</code></pre>

</details>

<hr>

<h2>å‚è€ƒæ–‡çŒ®</h2>

<ol>
<li>Paszke, A., et al. (2019). "PyTorch: An Imperative Style, High-Performance Deep Learning Library." <em>NeurIPS</em>.</li>
<li>Abadi, M., et al. (2016). "TensorFlow: A System for Large-Scale Machine Learning." <em>OSDI</em>.</li>
<li>Chollet, F. (2017). <em>Deep Learning with Python</em>. Manning Publications.</li>
<li>Stevens, E., Antiga, L., & Viehmann, T. (2020). <em>Deep Learning with PyTorch</em>. Manning Publications.</li>
</ol>

<div class="navigation">
    <a href="chapter3-activation.html" class="nav-button">â† å‰ã®ç« : æ´»æ€§åŒ–é–¢æ•°</a>
    <a href="index.html" class="nav-button">ã‚·ãƒªãƒ¼ã‚ºç›®æ¬¡</a>
    <a href="chapter5-cnn.html" class="nav-button">æ¬¡ã®ç« : CNN â†’</a>
</div>

    </main>

    <footer>
        <p><strong>ä½œæˆè€…</strong>: AI Terakoya Content Team</p>
        <p><strong>ç›£ä¿®</strong>: Dr. Yusuke Hashimotoï¼ˆæ±åŒ—å¤§å­¦ï¼‰</p>
        <p><strong>ãƒãƒ¼ã‚¸ãƒ§ãƒ³</strong>: 1.0 | <strong>ä½œæˆæ—¥</strong>: 2025-10-20</p>
        <p><strong>ãƒ©ã‚¤ã‚»ãƒ³ã‚¹</strong>: Creative Commons BY 4.0</p>
        <p>Â© 2025 AI Terakoya. All rights reserved.</p>
    </footer>
</body>
</html>
