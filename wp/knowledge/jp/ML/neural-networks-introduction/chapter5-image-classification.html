<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ç¬¬5ç« ï¼šç”»åƒåˆ†é¡ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ - AI Terakoya</title>

    <style>
        :root {
            --color-primary: #2c3e50;
            --color-primary-dark: #1a252f;
            --color-accent: #7b2cbf;
            --color-accent-light: #9d4edd;
            --color-text: #2d3748;
            --color-text-light: #4a5568;
            --color-bg: #ffffff;
            --color-bg-alt: #f7fafc;
            --color-border: #e2e8f0;
            --color-code-bg: #f8f9fa;
            --color-link: #3182ce;
            --color-link-hover: #2c5aa0;

            --spacing-xs: 0.5rem;
            --spacing-sm: 1rem;
            --spacing-md: 1.5rem;
            --spacing-lg: 2rem;
            --spacing-xl: 3rem;

            --font-body: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            --font-mono: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;

            --border-radius: 8px;
            --box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: var(--font-body);
            line-height: 1.7;
            color: var(--color-text);
            background-color: var(--color-bg);
            font-size: 16px;
        }

        header {
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            padding: var(--spacing-xl) var(--spacing-md);
            margin-bottom: var(--spacing-xl);
            box-shadow: var(--box-shadow);
        }

        .header-content {
            max-width: 900px;
            margin: 0 auto;
        }

        h1 {
            font-size: 2rem;
            font-weight: 700;
            margin-bottom: var(--spacing-sm);
            line-height: 1.2;
        }

        .subtitle {
            font-size: 1.1rem;
            opacity: 0.95;
            font-weight: 400;
            margin-bottom: var(--spacing-md);
        }

        .meta {
            display: flex;
            flex-wrap: wrap;
            gap: var(--spacing-md);
            font-size: 0.9rem;
            opacity: 0.9;
        }

        .meta-item {
            display: flex;
            align-items: center;
            gap: 0.3rem;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 0 var(--spacing-md) var(--spacing-xl);
        }

        h2 {
            font-size: 1.75rem;
            color: var(--color-primary);
            margin-top: var(--spacing-xl);
            margin-bottom: var(--spacing-md);
            padding-bottom: var(--spacing-xs);
            border-bottom: 3px solid var(--color-accent);
        }

        h3 {
            font-size: 1.4rem;
            color: var(--color-primary);
            margin-top: var(--spacing-lg);
            margin-bottom: var(--spacing-sm);
        }

        h4 {
            font-size: 1.1rem;
            color: var(--color-primary-dark);
            margin-top: var(--spacing-md);
            margin-bottom: var(--spacing-sm);
        }

        p {
            margin-bottom: var(--spacing-md);
            color: var(--color-text);
        }

        a {
            color: var(--color-link);
            text-decoration: none;
            transition: color 0.2s;
        }

        a:hover {
            color: var(--color-link-hover);
            text-decoration: underline;
        }

        ul, ol {
            margin-left: var(--spacing-lg);
            margin-bottom: var(--spacing-md);
        }

        li {
            margin-bottom: var(--spacing-xs);
            color: var(--color-text);
        }

        pre {
            background-color: var(--color-code-bg);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            overflow-x: auto;
            margin-bottom: var(--spacing-md);
            font-family: var(--font-mono);
            font-size: 0.9rem;
            line-height: 1.5;
        }

        code {
            font-family: var(--font-mono);
            font-size: 0.9em;
            background-color: var(--color-code-bg);
            padding: 0.2em 0.4em;
            border-radius: 3px;
        }

        pre code {
            background-color: transparent;
            padding: 0;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: var(--spacing-md);
            font-size: 0.95rem;
        }

        th, td {
            border: 1px solid var(--color-border);
            padding: var(--spacing-sm);
            text-align: left;
        }

        th {
            background-color: var(--color-bg-alt);
            font-weight: 600;
            color: var(--color-primary);
        }

        blockquote {
            border-left: 4px solid var(--color-accent);
            padding-left: var(--spacing-md);
            margin: var(--spacing-md) 0;
            color: var(--color-text-light);
            font-style: italic;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        .mermaid {
            text-align: center;
            margin: var(--spacing-lg) 0;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        details {
            background-color: var(--color-bg-alt);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            margin-bottom: var(--spacing-md);
        }

        summary {
            cursor: pointer;
            font-weight: 600;
            color: var(--color-primary);
            user-select: none;
            padding: var(--spacing-xs);
            margin: calc(-1 * var(--spacing-md));
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        summary:hover {
            background-color: rgba(123, 44, 191, 0.1);
        }

        details[open] summary {
            margin-bottom: var(--spacing-md);
            border-bottom: 1px solid var(--color-border);
        }

        .navigation {
            display: flex;
            justify-content: space-between;
            gap: var(--spacing-md);
            margin: var(--spacing-xl) 0;
            padding-top: var(--spacing-lg);
            border-top: 2px solid var(--color-border);
        }

        .nav-button {
            flex: 1;
            padding: var(--spacing-md);
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            border-radius: var(--border-radius);
            text-align: center;
            font-weight: 600;
            transition: transform 0.2s, box-shadow 0.2s;
            box-shadow: var(--box-shadow);
        }

        .nav-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
            text-decoration: none;
        }

        footer {
            margin-top: var(--spacing-xl);
            padding: var(--spacing-lg) var(--spacing-md);
            background-color: var(--color-bg-alt);
            border-top: 1px solid var(--color-border);
            text-align: center;
            font-size: 0.9rem;
            color: var(--color-text-light);
        }
        .disclaimer {
            max-width: 900px;
            margin: 2rem auto;
            padding: 1.5rem;
            background: #f8f9fa;
            border-left: 4px solid #6c757d;
            border-radius: 4px;
        }

        .disclaimer h3 {
            color: #495057;
            margin-bottom: 1rem;
            font-size: 1.1rem;
        }

        .disclaimer ul {
            list-style: none;
            padding-left: 0;
        }

        .disclaimer li {
            padding: 0.5rem 0;
            padding-left: 1.5rem;
            position: relative;
            font-size: 0.9rem;
            color: #6c757d;
            line-height: 1.6;
        }

        .disclaimer li::before {
            content: "âš ï¸";
            position: absolute;
            left: 0;
        }


        @media (max-width: 768px) {
            h1 {
                font-size: 1.5rem;
            }

            h2 {
                font-size: 1.4rem;
            }

            h3 {
                font-size: 1.2rem;
            }

            .meta {
                font-size: 0.85rem;
            }

            .navigation {
                flex-direction: column;
            }

            table {
                font-size: 0.85rem;
            }

            th, td {
                padding: var(--spacing-xs);
            }
        }
    
        
    
        /* Breadcrumb styles */
        .breadcrumb {
            background: #f7fafc;
            padding: 0.75rem 1rem;
            border-bottom: 1px solid #e2e8f0;
            font-size: 0.9rem;
        }

        .breadcrumb-content {
            max-width: 900px;
            margin: 0 auto;
            display: flex;
            align-items: center;
            flex-wrap: wrap;
            gap: 0.5rem;
        }

        .breadcrumb a {
            color: #667eea;
            text-decoration: none;
            transition: color 0.2s;
        }

        .breadcrumb a:hover {
            color: #764ba2;
            text-decoration: underline;
        }

        .breadcrumb-separator {
            color: #a0aec0;
            margin: 0 0.25rem;
        }

        .breadcrumb-current {
            color: #4a5568;
            font-weight: 500;
        }
    </style>

    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
        mermaid.initialize({ startOnLoad: true, theme: 'default' });
    </script>

    <!-- MathJax for LaTeX equation rendering -->
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                displayMath: [['$$', '$$'], ['\\[', '\\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
                ignoreHtmlClass: 'mermaid'
            }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" async></script>
</head>
<body>
            <nav class="breadcrumb">
        <div class="breadcrumb-content">
            <a href="/AI-Knowledge-Notes/knowledge/jp/index.html">AIå¯ºå­å±‹ãƒˆãƒƒãƒ—</a><span class="breadcrumb-separator">â€º</span><a href="/AI-Knowledge-Notes/knowledge/jp/ML/index.html">æ©Ÿæ¢°å­¦ç¿’</a><span class="breadcrumb-separator">â€º</span><a href="/AI-Knowledge-Notes/knowledge/jp/ML/neural-networks-introduction/index.html">Neural Networks</a><span class="breadcrumb-separator">â€º</span><span class="breadcrumb-current">Chapter 5</span>
        </div>
    </nav>

        <header>
        <div class="header-content">
            <h1>ç¬¬5ç« ï¼šç”»åƒåˆ†é¡ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ</h1>
            <p class="subtitle">å®Ÿè·µçš„ãªCNNãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ - MNIST ã‹ã‚‰ CIFAR-10 ã¾ã§</p>
            <div class="meta">
                <span class="meta-item">ğŸ“– èª­äº†æ™‚é–“: 30-35åˆ†</span>
                <span class="meta-item">ğŸ“Š é›£æ˜“åº¦: ä¸­ç´šã€œä¸Šç´š</span>
                <span class="meta-item">ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹: 17å€‹</span>
                <span class="meta-item">ğŸ“ æ¼”ç¿’å•é¡Œ: 5å•</span>
            </div>
        </div>
    </header>

    <main class="container">

<h2>å­¦ç¿’ç›®æ¨™</h2>
<p>ã“ã®ç« ã‚’èª­ã‚€ã“ã¨ã§ã€ä»¥ä¸‹ã‚’ç¿’å¾—ã§ãã¾ã™ï¼š</p>
<ul>
<li>âœ… MNISTæ‰‹æ›¸ãæ•°å­—èªè­˜ã®å®Œå…¨ãªå®Ÿè£…ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³</li>
<li>âœ… CNNè¨­è¨ˆã®å®Ÿè·µçš„ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¨ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹</li>
<li>âœ… CIFAR-10ã‚«ãƒ©ãƒ¼ç”»åƒåˆ†é¡ã®é«˜åº¦ãªãƒ†ã‚¯ãƒ‹ãƒƒã‚¯</li>
<li>âœ… ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã¨æ­£å‰‡åŒ–ã®åŠ¹æœçš„ãªæ´»ç”¨</li>
<li>âœ… è»¢ç§»å­¦ç¿’ã¨ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã®å®Ÿè£…</li>
<li>âœ… æœ¬ç•ªç’°å¢ƒã¸ã®ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆæˆ¦ç•¥</li>
</ul>

<hr>

<h2>5.1 ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ1: MNISTæ‰‹æ›¸ãæ•°å­—èªè­˜</h2>

<h3>ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æº–å‚™ã¨å‰å‡¦ç†</h3>

<p><strong>MNISTï¼ˆModified National Institute of Standards and Technologyï¼‰</strong>ã¯ã€æ‰‹æ›¸ãæ•°å­—ï¼ˆ0-9ï¼‰ã®ç”»åƒåˆ†é¡ã‚¿ã‚¹ã‚¯ã§ã€æ©Ÿæ¢°å­¦ç¿’ã®"Hello World"ã¨ã‚‚å‘¼ã°ã‚Œã¾ã™ã€‚</p>

<table>
<thead>
<tr>
<th>ç‰¹å¾´</th>
<th>è©³ç´°</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>ç”»åƒã‚µã‚¤ã‚º</strong></td>
<td>28Ã—28 ãƒ”ã‚¯ã‚»ãƒ«ï¼ˆã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«ï¼‰</td>
</tr>
<tr>
<td><strong>ã‚¯ãƒ©ã‚¹æ•°</strong></td>
<td>10ã‚¯ãƒ©ã‚¹ï¼ˆæ•°å­— 0-9ï¼‰</td>
</tr>
<tr>
<td><strong>è¨“ç·´ãƒ‡ãƒ¼ã‚¿</strong></td>
<td>60,000æš</td>
</tr>
<tr>
<td><strong>ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿</strong></td>
<td>10,000æš</td>
</tr>
<tr>
<td><strong>é›£æ˜“åº¦</strong></td>
<td>å…¥é–€ãƒ¬ãƒ™ãƒ«ï¼ˆæœ€é«˜ç²¾åº¦: 99.8%+ï¼‰</td>
</tr>
</tbody>
</table>

<h4>ãƒ‡ãƒ¼ã‚¿ã®ãƒ­ãƒ¼ãƒ‰ã¨å¯è¦–åŒ–</h4>

<pre><code class="language-python">import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
import matplotlib.pyplot as plt
import numpy as np

# ãƒ‡ãƒã‚¤ã‚¹ã®è¨­å®š
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f'Using device: {device}')

# ãƒ‡ãƒ¼ã‚¿å¤‰æ›ã®å®šç¾©
transform = transforms.Compose([
    transforms.ToTensor(),  # [0, 255] â†’ [0.0, 1.0]
    transforms.Normalize((0.1307,), (0.3081,))  # MNISTå¹³å‡ã¨æ¨™æº–åå·®
])

# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ­ãƒ¼ãƒ‰
train_dataset = datasets.MNIST(
    root='./data',
    train=True,
    download=True,
    transform=transform
)

test_dataset = datasets.MNIST(
    root='./data',
    train=False,
    download=True,
    transform=transform
)

# ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã®ä½œæˆ
train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)

print(f'è¨“ç·´ãƒ‡ãƒ¼ã‚¿: {len(train_dataset)}æš')
print(f'ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {len(test_dataset)}æš')

# ã‚µãƒ³ãƒ—ãƒ«ç”»åƒã®å¯è¦–åŒ–
def visualize_mnist_samples(dataset, n_samples=10):
    """MNISTã‚µãƒ³ãƒ—ãƒ«ç”»åƒã®è¡¨ç¤º"""
    fig, axes = plt.subplots(2, 5, figsize=(12, 5))
    axes = axes.ravel()

    for i in range(n_samples):
        image, label = dataset[i]
        # æ­£è¦åŒ–ã‚’æˆ»ã™
        image = image.squeeze() * 0.3081 + 0.1307

        axes[i].imshow(image, cmap='gray')
        axes[i].set_title(f'Label: {label}')
        axes[i].axis('off')

    plt.tight_layout()
    plt.show()

visualize_mnist_samples(train_dataset)
</code></pre>

<h3>CNNãƒ¢ãƒ‡ãƒ«ã®è¨­è¨ˆ</h3>

<p>MNISTç”¨ã®åŠ¹ç‡çš„ãªCNNã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’è¨­è¨ˆã—ã¾ã™ã€‚</p>

<div class="mermaid">
graph LR
    A[å…¥åŠ›<br/>28Ã—28Ã—1] --> B[Conv1<br/>24Ã—24Ã—32]
    B --> C[Pool1<br/>12Ã—12Ã—32]
    C --> D[Conv2<br/>8Ã—8Ã—64]
    D --> E[Pool2<br/>4Ã—4Ã—64]
    E --> F[Flatten<br/>1024]
    F --> G[FC1<br/>128]
    G --> H[Dropout<br/>0.5]
    H --> I[FC2<br/>10]

    style A fill:#e3f2fd
    style I fill:#e8f5e9
</div>

<pre><code class="language-python">class MNISTNet(nn.Module):
    """MNISTç”¨CNNãƒ¢ãƒ‡ãƒ«"""

    def __init__(self):
        super(MNISTNet, self).__init__()

        # ç•³ã¿è¾¼ã¿å±¤
        self.conv1 = nn.Conv2d(1, 32, kernel_size=5)  # 28Ã—28Ã—1 â†’ 24Ã—24Ã—32
        self.conv2 = nn.Conv2d(32, 64, kernel_size=5)  # 12Ã—12Ã—32 â†’ 8Ã—8Ã—64

        # ãƒ—ãƒ¼ãƒªãƒ³ã‚°å±¤
        self.pool = nn.MaxPool2d(2, 2)

        # å…¨çµåˆå±¤
        self.fc1 = nn.Linear(64 * 4 * 4, 128)
        self.fc2 = nn.Linear(128, 10)

        # ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆ
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        # ç¬¬1ãƒ–ãƒ­ãƒƒã‚¯: Conv â†’ ReLU â†’ Pool
        x = self.pool(F.relu(self.conv1(x)))  # â†’ 12Ã—12Ã—32

        # ç¬¬2ãƒ–ãƒ­ãƒƒã‚¯: Conv â†’ ReLU â†’ Pool
        x = self.pool(F.relu(self.conv2(x)))  # â†’ 4Ã—4Ã—64

        # å¹³å¦åŒ–
        x = x.view(-1, 64 * 4 * 4)  # â†’ 1024

        # å…¨çµåˆå±¤
        x = F.relu(self.fc1(x))  # â†’ 128
        x = self.dropout(x)
        x = self.fc2(x)  # â†’ 10

        return x

# ãƒ¢ãƒ‡ãƒ«ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–
model = MNISTNet().to(device)

# ãƒ¢ãƒ‡ãƒ«æ§‹é€ ã®è¡¨ç¤º
print(model)

# ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã®è¨ˆç®—
total_params = sum(p.numel() for p in model.parameters())
trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
print(f'\nç·ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {total_params:,}')
print(f'è¨“ç·´å¯èƒ½ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {trainable_params:,}')
</code></pre>

<p><strong>å‡ºåŠ›ä¾‹</strong>ï¼š</p>
<pre><code>MNISTNet(
  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))
  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (fc1): Linear(in_features=1024, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=10, bias=True)
  (dropout): Dropout(p=0.5, inplace=False)
)

ç·ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: 163,978
è¨“ç·´å¯èƒ½ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: 163,978
</code></pre>

<h3>å­¦ç¿’ã¨è©•ä¾¡</h3>

<pre><code class="language-python">def train_epoch(model, device, train_loader, optimizer, criterion, epoch):
    """1ã‚¨ãƒãƒƒã‚¯ã®è¨“ç·´"""
    model.train()
    running_loss = 0.0
    correct = 0
    total = 0

    for batch_idx, (data, target) in enumerate(train_loader):
        data, target = data.to(device), target.to(device)

        # å‹¾é…ã‚’ã‚¼ãƒ­ã‚¯ãƒªã‚¢
        optimizer.zero_grad()

        # é †ä¼æ’­
        output = model(data)
        loss = criterion(output, target)

        # é€†ä¼æ’­
        loss.backward()
        optimizer.step()

        # çµ±è¨ˆæƒ…å ±
        running_loss += loss.item()
        _, predicted = output.max(1)
        total += target.size(0)
        correct += predicted.eq(target).sum().item()

        # é€²æ—è¡¨ç¤º
        if batch_idx % 100 == 0:
            print(f'Epoch {epoch}, Batch {batch_idx}/{len(train_loader)}, '
                  f'Loss: {loss.item():.4f}, Acc: {100.*correct/total:.2f}%')

    epoch_loss = running_loss / len(train_loader)
    epoch_acc = 100. * correct / total

    return epoch_loss, epoch_acc

def evaluate(model, device, test_loader, criterion):
    """ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§è©•ä¾¡"""
    model.eval()
    test_loss = 0
    correct = 0

    with torch.no_grad():
        for data, target in test_loader:
            data, target = data.to(device), target.to(device)
            output = model(data)
            test_loss += criterion(output, target).item()
            pred = output.argmax(dim=1, keepdim=True)
            correct += pred.eq(target.view_as(pred)).sum().item()

    test_loss /= len(test_loader)
    test_acc = 100. * correct / len(test_loader.dataset)

    print(f'\nTest set: Average loss: {test_loss:.4f}, '
          f'Accuracy: {correct}/{len(test_loader.dataset)} ({test_acc:.2f}%)\n')

    return test_loss, test_acc

# è¨“ç·´è¨­å®š
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# è¨“ç·´ãƒ«ãƒ¼ãƒ—
num_epochs = 10
train_losses, train_accs = [], []
test_losses, test_accs = [], []

for epoch in range(1, num_epochs + 1):
    train_loss, train_acc = train_epoch(model, device, train_loader, optimizer, criterion, epoch)
    test_loss, test_acc = evaluate(model, device, test_loader, criterion)

    train_losses.append(train_loss)
    train_accs.append(train_acc)
    test_losses.append(test_loss)
    test_accs.append(test_acc)

# ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜
torch.save(model.state_dict(), 'mnist_cnn.pth')
print('ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸ: mnist_cnn.pth')
</code></pre>

<h3>ã‚¨ãƒ©ãƒ¼åˆ†æã¨å¯è¦–åŒ–</h3>

<pre><code class="language-python">from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns

def plot_confusion_matrix(model, device, test_loader):
    """æ··åŒè¡Œåˆ—ã®å¯è¦–åŒ–"""
    model.eval()
    all_preds = []
    all_targets = []

    with torch.no_grad():
        for data, target in test_loader:
            data, target = data.to(device), target.to(device)
            output = model(data)
            pred = output.argmax(dim=1)
            all_preds.extend(pred.cpu().numpy())
            all_targets.extend(target.cpu().numpy())

    # æ··åŒè¡Œåˆ—ã®è¨ˆç®—
    cm = confusion_matrix(all_targets, all_preds)

    # å¯è¦–åŒ–
    plt.figure(figsize=(10, 8))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=range(10), yticklabels=range(10))
    plt.xlabel('Predicted Label')
    plt.ylabel('True Label')
    plt.title('Confusion Matrix - MNIST')
    plt.show()

    # åˆ†é¡ãƒ¬ãƒãƒ¼ãƒˆ
    print('\nClassification Report:')
    print(classification_report(all_targets, all_preds,
                                target_names=[str(i) for i in range(10)]))

plot_confusion_matrix(model, device, test_loader)

def visualize_misclassified(model, device, test_loader, n_samples=10):
    """èª¤åˆ†é¡ã•ã‚ŒãŸã‚µãƒ³ãƒ—ãƒ«ã®è¡¨ç¤º"""
    model.eval()
    misclassified = []

    with torch.no_grad():
        for data, target in test_loader:
            data, target = data.to(device), target.to(device)
            output = model(data)
            pred = output.argmax(dim=1)

            # èª¤åˆ†é¡ã‚’è¦‹ã¤ã‘ã‚‹
            mask = pred != target
            if mask.sum() > 0:
                for i in range(len(mask)):
                    if mask[i]:
                        misclassified.append({
                            'image': data[i].cpu(),
                            'true': target[i].item(),
                            'pred': pred[i].item(),
                            'confidence': F.softmax(output[i], dim=0)[pred[i]].item()
                        })

                        if len(misclassified) >= n_samples:
                            break

            if len(misclassified) >= n_samples:
                break

    # å¯è¦–åŒ–
    fig, axes = plt.subplots(2, 5, figsize=(12, 5))
    axes = axes.ravel()

    for i, item in enumerate(misclassified[:n_samples]):
        image = item['image'].squeeze() * 0.3081 + 0.1307
        axes[i].imshow(image, cmap='gray')
        axes[i].set_title(f"True: {item['true']}, Pred: {item['pred']}\n"
                         f"Conf: {item['confidence']:.2%}")
        axes[i].axis('off')

    plt.tight_layout()
    plt.show()

visualize_misclassified(model, device, test_loader)

def plot_training_history(train_losses, train_accs, test_losses, test_accs):
    """å­¦ç¿’æ›²ç·šã®å¯è¦–åŒ–"""
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))

    epochs = range(1, len(train_losses) + 1)

    # Lossæ›²ç·š
    ax1.plot(epochs, train_losses, 'b-', label='Training Loss', linewidth=2)
    ax1.plot(epochs, test_losses, 'r-', label='Test Loss', linewidth=2)
    ax1.set_xlabel('Epoch')
    ax1.set_ylabel('Loss')
    ax1.set_title('Training and Test Loss')
    ax1.legend()
    ax1.grid(True, alpha=0.3)

    # Accuracyæ›²ç·š
    ax2.plot(epochs, train_accs, 'b-', label='Training Accuracy', linewidth=2)
    ax2.plot(epochs, test_accs, 'r-', label='Test Accuracy', linewidth=2)
    ax2.set_xlabel('Epoch')
    ax2.set_ylabel('Accuracy (%)')
    ax2.set_title('Training and Test Accuracy')
    ax2.legend()
    ax2.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.show()

plot_training_history(train_losses, train_accs, test_losses, test_accs)
</code></pre>

<hr>

<h2>5.2 ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ2: CIFAR-10ã‚«ãƒ©ãƒ¼ç”»åƒåˆ†é¡</h2>

<h3>ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æ¦‚è¦</h3>

<p><strong>CIFAR-10ï¼ˆCanadian Institute for Advanced Researchï¼‰</strong>ã¯ã€MNISTã‚ˆã‚Šé›£æ˜“åº¦ã®é«˜ã„å®Ÿä¸–ç•Œç”»åƒã®åˆ†é¡ã‚¿ã‚¹ã‚¯ã§ã™ã€‚</p>

<table>
<thead>
<tr>
<th>ç‰¹å¾´</th>
<th>è©³ç´°</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>ç”»åƒã‚µã‚¤ã‚º</strong></td>
<td>32Ã—32 ãƒ”ã‚¯ã‚»ãƒ«ï¼ˆRGB ã‚«ãƒ©ãƒ¼ï¼‰</td>
</tr>
<tr>
<td><strong>ã‚¯ãƒ©ã‚¹æ•°</strong></td>
<td>10ã‚¯ãƒ©ã‚¹ï¼ˆé£›è¡Œæ©Ÿã€è»Šã€é³¥ã€çŒ«ã€é¹¿ã€çŠ¬ã€è›™ã€é¦¬ã€èˆ¹ã€ãƒˆãƒ©ãƒƒã‚¯ï¼‰</td>
</tr>
<tr>
<td><strong>è¨“ç·´ãƒ‡ãƒ¼ã‚¿</strong></td>
<td>50,000æšï¼ˆå„ã‚¯ãƒ©ã‚¹5,000æšï¼‰</td>
</tr>
<tr>
<td><strong>ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿</strong></td>
<td>10,000æšï¼ˆå„ã‚¯ãƒ©ã‚¹1,000æšï¼‰</td>
</tr>
<tr>
<td><strong>é›£æ˜“åº¦</strong></td>
<td>ä¸­ç´šï¼ˆæœ€é«˜ç²¾åº¦: 99%+ã€æ¨™æº–çš„ã«ã¯ 90-95%ï¼‰</td>
</tr>
</tbody>
</table>

<h3>ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã®é‡è¦æ€§</h3>

<p>CIFAR-10ã§ã¯<strong>ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µï¼ˆData Augmentationï¼‰</strong>ãŒç²¾åº¦å‘ä¸Šã®éµã¨ãªã‚Šã¾ã™ã€‚</p>

<div class="mermaid">
graph LR
    A[å…ƒç”»åƒ] --> B[æ°´å¹³åè»¢]
    A --> C[ãƒ©ãƒ³ãƒ€ãƒ ã‚¯ãƒ­ãƒƒãƒ—]
    A --> D[è‰²èª¿å¤‰æ›]
    A --> E[å›è»¢]
    B --> F[è¨“ç·´ãƒ‡ãƒ¼ã‚¿]
    C --> F
    D --> F
    E --> F

    style A fill:#e3f2fd
    style F fill:#e8f5e9
</div>

<pre><code class="language-python">from torchvision import datasets, transforms

# CIFAR-10ã®ã‚¯ãƒ©ã‚¹å
classes = ('airplane', 'automobile', 'bird', 'cat', 'deer',
           'dog', 'frog', 'horse', 'ship', 'truck')

# ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã‚’å«ã‚€è¨“ç·´ç”¨å¤‰æ›
train_transform = transforms.Compose([
    transforms.RandomCrop(32, padding=4),  # ãƒ©ãƒ³ãƒ€ãƒ ã‚¯ãƒ­ãƒƒãƒ—
    transforms.RandomHorizontalFlip(),  # æ°´å¹³åè»¢ï¼ˆç¢ºç‡50%ï¼‰
    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),  # è‰²èª¿å¤‰æ›
    transforms.ToTensor(),
    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))
])

# ãƒ†ã‚¹ãƒˆç”¨å¤‰æ›ï¼ˆæ‹¡å¼µãªã—ï¼‰
test_transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))
])

# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ­ãƒ¼ãƒ‰
train_dataset = datasets.CIFAR10(
    root='./data',
    train=True,
    download=True,
    transform=train_transform
)

test_dataset = datasets.CIFAR10(
    root='./data',
    train=False,
    download=True,
    transform=test_transform
)

# ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼
train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2)
test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=2)

def visualize_augmentation(dataset, idx=0, n_augments=8):
    """ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã®åŠ¹æœã‚’å¯è¦–åŒ–"""
    fig, axes = plt.subplots(2, 4, figsize=(12, 6))
    axes = axes.ravel()

    # å…ƒç”»åƒ
    original_img, label = dataset[idx]

    for i in range(n_augments):
        # æ‹¡å¼µå¾Œã®ç”»åƒã‚’å–å¾—
        img, _ = dataset[idx]

        # æ­£è¦åŒ–ã‚’æˆ»ã™
        img = img.numpy().transpose((1, 2, 0))
        mean = np.array([0.4914, 0.4822, 0.4465])
        std = np.array([0.2470, 0.2435, 0.2616])
        img = std * img + mean
        img = np.clip(img, 0, 1)

        axes[i].imshow(img)
        axes[i].set_title(f'Augmentation {i+1}')
        axes[i].axis('off')

    plt.suptitle(f'Class: {classes[label]}', fontsize=16)
    plt.tight_layout()
    plt.show()

visualize_augmentation(train_dataset)
</code></pre>

<h3>ã‚ˆã‚Šæ·±ã„ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è¨­è¨ˆ</h3>

<p>CIFAR-10ã«ã¯VGGã‚¹ã‚¿ã‚¤ãƒ«ã®ã‚ˆã‚Šæ·±ã„CNNãŒåŠ¹æœçš„ã§ã™ã€‚</p>

<pre><code class="language-python">class CIFAR10Net(nn.Module):
    """CIFAR-10ç”¨ã®æ·±ã„CNN (VGG-style)"""

    def __init__(self, num_classes=10):
        super(CIFAR10Net, self).__init__()

        # ãƒ–ãƒ­ãƒƒã‚¯1: 32Ã—32 â†’ 16Ã—16
        self.conv1_1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)
        self.bn1_1 = nn.BatchNorm2d(64)
        self.conv1_2 = nn.Conv2d(64, 64, kernel_size=3, padding=1)
        self.bn1_2 = nn.BatchNorm2d(64)

        # ãƒ–ãƒ­ãƒƒã‚¯2: 16Ã—16 â†’ 8Ã—8
        self.conv2_1 = nn.Conv2d(64, 128, kernel_size=3, padding=1)
        self.bn2_1 = nn.BatchNorm2d(128)
        self.conv2_2 = nn.Conv2d(128, 128, kernel_size=3, padding=1)
        self.bn2_2 = nn.BatchNorm2d(128)

        # ãƒ–ãƒ­ãƒƒã‚¯3: 8Ã—8 â†’ 4Ã—4
        self.conv3_1 = nn.Conv2d(128, 256, kernel_size=3, padding=1)
        self.bn3_1 = nn.BatchNorm2d(256)
        self.conv3_2 = nn.Conv2d(256, 256, kernel_size=3, padding=1)
        self.bn3_2 = nn.BatchNorm2d(256)
        self.conv3_3 = nn.Conv2d(256, 256, kernel_size=3, padding=1)
        self.bn3_3 = nn.BatchNorm2d(256)

        # ãƒ—ãƒ¼ãƒªãƒ³ã‚°
        self.pool = nn.MaxPool2d(2, 2)

        # å…¨çµåˆå±¤
        self.fc1 = nn.Linear(256 * 4 * 4, 512)
        self.bn_fc1 = nn.BatchNorm1d(512)
        self.fc2 = nn.Linear(512, num_classes)

        # ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆ
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        # ãƒ–ãƒ­ãƒƒã‚¯1
        x = F.relu(self.bn1_1(self.conv1_1(x)))
        x = F.relu(self.bn1_2(self.conv1_2(x)))
        x = self.pool(x)

        # ãƒ–ãƒ­ãƒƒã‚¯2
        x = F.relu(self.bn2_1(self.conv2_1(x)))
        x = F.relu(self.bn2_2(self.conv2_2(x)))
        x = self.pool(x)

        # ãƒ–ãƒ­ãƒƒã‚¯3
        x = F.relu(self.bn3_1(self.conv3_1(x)))
        x = F.relu(self.bn3_2(self.conv3_2(x)))
        x = F.relu(self.bn3_3(self.conv3_3(x)))
        x = self.pool(x)

        # å¹³å¦åŒ–
        x = x.view(-1, 256 * 4 * 4)

        # å…¨çµåˆå±¤
        x = F.relu(self.bn_fc1(self.fc1(x)))
        x = self.dropout(x)
        x = self.fc2(x)

        return x

# ãƒ¢ãƒ‡ãƒ«ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–
model = CIFAR10Net().to(device)

# ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°
total_params = sum(p.numel() for p in model.parameters())
print(f'ç·ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {total_params:,}')
</code></pre>

<h3>æ­£å‰‡åŒ–ãƒ†ã‚¯ãƒ‹ãƒƒã‚¯ï¼ˆDropoutã€Batch Normalizationï¼‰</h3>

<blockquote>
<p><strong>Batch Normalization</strong>: å„å±¤ã®å‡ºåŠ›ã‚’æ­£è¦åŒ–ã—ã€å­¦ç¿’ã‚’å®‰å®šåŒ–ãƒ»é«˜é€ŸåŒ–ã—ã¾ã™ã€‚</p>
<p><strong>Dropout</strong>: è¨“ç·´ä¸­ã«ãƒ©ãƒ³ãƒ€ãƒ ã«ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã‚’ç„¡åŠ¹åŒ–ã—ã€éå­¦ç¿’ã‚’é˜²ãã¾ã™ã€‚</p>
</blockquote>

<pre><code class="language-python">def train_with_scheduler(model, device, train_loader, test_loader, num_epochs=50):
    """Learning Rate Schedulerã‚’ä½¿ã£ãŸè¨“ç·´"""

    criterion = nn.CrossEntropyLoss()
    optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)

    # Learning Rate Scheduler
    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[25, 40], gamma=0.1)

    train_losses, train_accs = [], []
    test_losses, test_accs = [], []

    best_acc = 0.0

    for epoch in range(1, num_epochs + 1):
        # è¨“ç·´
        model.train()
        running_loss = 0.0
        correct = 0
        total = 0

        for batch_idx, (data, target) in enumerate(train_loader):
            data, target = data.to(device), target.to(device)

            optimizer.zero_grad()
            output = model(data)
            loss = criterion(output, target)
            loss.backward()
            optimizer.step()

            running_loss += loss.item()
            _, predicted = output.max(1)
            total += target.size(0)
            correct += predicted.eq(target).sum().item()

        train_loss = running_loss / len(train_loader)
        train_acc = 100. * correct / total

        # è©•ä¾¡
        model.eval()
        test_loss = 0
        correct = 0

        with torch.no_grad():
            for data, target in test_loader:
                data, target = data.to(device), target.to(device)
                output = model(data)
                test_loss += criterion(output, target).item()
                pred = output.argmax(dim=1)
                correct += pred.eq(target).sum().item()

        test_loss /= len(test_loader)
        test_acc = 100. * correct / len(test_loader.dataset)

        # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ã®ã‚¹ãƒ†ãƒƒãƒ—
        scheduler.step()

        # è¨˜éŒ²
        train_losses.append(train_loss)
        train_accs.append(train_acc)
        test_losses.append(test_loss)
        test_accs.append(test_acc)

        print(f'Epoch {epoch}/{num_epochs} - '
              f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}% - '
              f'Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.2f}% - '
              f'LR: {scheduler.get_last_lr()[0]:.6f}')

        # ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜
        if test_acc > best_acc:
            best_acc = test_acc
            torch.save(model.state_dict(), 'cifar10_best.pth')
            print(f'  â†’ Best model saved! (Acc: {best_acc:.2f}%)')

    return train_losses, train_accs, test_losses, test_accs

# è¨“ç·´å®Ÿè¡Œ
train_losses, train_accs, test_losses, test_accs = train_with_scheduler(
    model, device, train_loader, test_loader, num_epochs=50
)
</code></pre>

<h3>Early Stoppingå®Ÿè£…</h3>

<pre><code class="language-python">class EarlyStopping:
    """Early Stoppingã®å®Ÿè£…"""

    def __init__(self, patience=7, min_delta=0, path='checkpoint.pth'):
        """
        Args:
            patience: æ”¹å–„ãŒè¦‹ã‚‰ã‚Œãªã„æœ€å¤§ã‚¨ãƒãƒƒã‚¯æ•°
            min_delta: æ”¹å–„ã¨è¦‹ãªã™æœ€å°å¤‰åŒ–é‡
            path: ãƒ¢ãƒ‡ãƒ«ä¿å­˜å…ˆã®ãƒ‘ã‚¹
        """
        self.patience = patience
        self.min_delta = min_delta
        self.path = path
        self.counter = 0
        self.best_score = None
        self.early_stop = False
        self.best_loss = np.Inf

    def __call__(self, val_loss, model):
        score = -val_loss

        if self.best_score is None:
            self.best_score = score
            self.save_checkpoint(val_loss, model)
        elif score < self.best_score + self.min_delta:
            self.counter += 1
            print(f'EarlyStopping counter: {self.counter}/{self.patience}')
            if self.counter >= self.patience:
                self.early_stop = True
        else:
            self.best_score = score
            self.save_checkpoint(val_loss, model)
            self.counter = 0

    def save_checkpoint(self, val_loss, model):
        """ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜"""
        torch.save(model.state_dict(), self.path)
        self.best_loss = val_loss

# ä½¿ç”¨ä¾‹
def train_with_early_stopping(model, device, train_loader, test_loader,
                              num_epochs=100, patience=10):
    """Early Stoppingã‚’ä½¿ã£ãŸè¨“ç·´"""

    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=0.001)
    early_stopping = EarlyStopping(patience=patience, path='cifar10_checkpoint.pth')

    for epoch in range(1, num_epochs + 1):
        # è¨“ç·´ãƒ«ãƒ¼ãƒ—ï¼ˆçœç•¥ï¼‰
        train_loss = 0.0  # å®Ÿéš›ã«ã¯è¨“ç·´ã‚’å®Ÿè¡Œ

        # æ¤œè¨¼
        model.eval()
        val_loss = 0
        with torch.no_grad():
            for data, target in test_loader:
                data, target = data.to(device), target.to(device)
                output = model(data)
                val_loss += criterion(output, target).item()

        val_loss /= len(test_loader)

        # Early Stoppingãƒã‚§ãƒƒã‚¯
        early_stopping(val_loss, model)

        if early_stopping.early_stop:
            print(f'Early stopping triggered at epoch {epoch}')
            break

    # ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰
    model.load_state_dict(torch.load('cifar10_checkpoint.pth'))
    return model
</code></pre>

<hr>

<h2>5.3 é«˜åº¦ãªãƒ†ã‚¯ãƒ‹ãƒƒã‚¯</h2>

<h3>Transfer Learningï¼ˆè»¢ç§»å­¦ç¿’ï¼‰</h3>

<p>äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã†ã“ã¨ã§ã€å°‘ãªã„ãƒ‡ãƒ¼ã‚¿ã§ã‚‚é«˜ç²¾åº¦ã‚’å®Ÿç¾ã§ãã¾ã™ã€‚</p>

<div class="mermaid">
graph LR
    A[ImageNet<br/>äº‹å‰å­¦ç¿’] --> B[ç‰¹å¾´æŠ½å‡ºå™¨<br/>å›ºå®š]
    B --> C[åˆ†é¡å™¨<br/>è¨“ç·´]
    C --> D[CIFAR-10<br/>åˆ†é¡]

    style A fill:#e3f2fd
    style B fill:#fff3e0
    style C fill:#f3e5f5
    style D fill:#e8f5e9
</div>

<pre><code class="language-python">import torchvision.models as models

def create_transfer_model(num_classes=10, freeze_features=True):
    """ResNet18ã‚’ãƒ™ãƒ¼ã‚¹ã«ã—ãŸè»¢ç§»å­¦ç¿’ãƒ¢ãƒ‡ãƒ«"""

    # ImageNetã§äº‹å‰å­¦ç¿’æ¸ˆã¿ã®ResNet18ã‚’ãƒ­ãƒ¼ãƒ‰
    model = models.resnet18(pretrained=True)

    # ç‰¹å¾´æŠ½å‡ºå™¨ã‚’å›ºå®š
    if freeze_features:
        for param in model.parameters():
            param.requires_grad = False

    # æœ€çµ‚å±¤ã‚’ç½®ãæ›ãˆï¼ˆCIFAR-10ç”¨ã«10ã‚¯ãƒ©ã‚¹åˆ†é¡ï¼‰
    num_features = model.fc.in_features
    model.fc = nn.Linear(num_features, num_classes)

    return model

# ãƒ¢ãƒ‡ãƒ«ã®ä½œæˆ
transfer_model = create_transfer_model(num_classes=10, freeze_features=True).to(device)

# è¨“ç·´å¯èƒ½ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ã¿ã‚’æœ€é©åŒ–
optimizer = optim.Adam(filter(lambda p: p.requires_grad, transfer_model.parameters()),
                       lr=0.001)

print("è»¢ç§»å­¦ç¿’ãƒ¢ãƒ‡ãƒ«:")
print(f"å…¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {sum(p.numel() for p in transfer_model.parameters()):,}")
print(f"è¨“ç·´å¯èƒ½ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {sum(p.numel() for p in transfer_model.parameters() if p.requires_grad):,}")

def finetune_transfer_model(model, device, train_loader, test_loader, num_epochs=20):
    """è»¢ç§»å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°"""

    criterion = nn.CrossEntropyLoss()

    # Phase 1: åˆ†é¡å™¨ã®ã¿è¨“ç·´ï¼ˆ5ã‚¨ãƒãƒƒã‚¯ï¼‰
    print("\nPhase 1: Training classifier only...")
    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)

    for epoch in range(1, 6):
        model.train()
        running_loss = 0.0

        for data, target in train_loader:
            data, target = data.to(device), target.to(device)
            optimizer.zero_grad()
            output = model(data)
            loss = criterion(output, target)
            loss.backward()
            optimizer.step()
            running_loss += loss.item()

        print(f"Epoch {epoch}/5 - Loss: {running_loss/len(train_loader):.4f}")

    # Phase 2: å…¨å±¤ã‚’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆ15ã‚¨ãƒãƒƒã‚¯ï¼‰
    print("\nPhase 2: Fine-tuning all layers...")
    for param in model.parameters():
        param.requires_grad = True

    optimizer = optim.Adam(model.parameters(), lr=0.0001)  # ã‚ˆã‚Šå°ã•ã„å­¦ç¿’ç‡

    for epoch in range(1, 16):
        model.train()
        running_loss = 0.0

        for data, target in train_loader:
            data, target = data.to(device), target.to(device)
            optimizer.zero_grad()
            output = model(data)
            loss = criterion(output, target)
            loss.backward()
            optimizer.step()
            running_loss += loss.item()

        # è©•ä¾¡
        model.eval()
        correct = 0
        with torch.no_grad():
            for data, target in test_loader:
                data, target = data.to(device), target.to(device)
                output = model(data)
                pred = output.argmax(dim=1)
                correct += pred.eq(target).sum().item()

        test_acc = 100. * correct / len(test_loader.dataset)
        print(f"Epoch {epoch}/15 - Loss: {running_loss/len(train_loader):.4f}, "
              f"Test Acc: {test_acc:.2f}%")

    return model

# ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å®Ÿè¡Œ
transfer_model = finetune_transfer_model(transfer_model, device, train_loader, test_loader)
</code></pre>

<h3>Learning Rate Finder</h3>

<p>æœ€é©ãªå­¦ç¿’ç‡ã‚’è‡ªå‹•çš„ã«è¦‹ã¤ã‘ã‚‹ãƒ†ã‚¯ãƒ‹ãƒƒã‚¯ï¼ˆFast.aiã§æœ‰åï¼‰ã€‚</p>

<pre><code class="language-python">import matplotlib.pyplot as plt

class LRFinder:
    """Learning Rate Finderã®å®Ÿè£…"""

    def __init__(self, model, optimizer, criterion, device):
        self.model = model
        self.optimizer = optimizer
        self.criterion = criterion
        self.device = device
        self.history = {'lr': [], 'loss': []}
        self.best_loss = 1e9

    def range_test(self, train_loader, start_lr=1e-7, end_lr=10, num_iter=100):
        """å­¦ç¿’ç‡ã®ç¯„å›²ã‚’ãƒ†ã‚¹ãƒˆ"""

        # å­¦ç¿’ç‡ã®ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«
        lr_schedule = np.logspace(np.log10(start_lr), np.log10(end_lr), num_iter)

        # ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸçŠ¶æ…‹ã‚’ä¿å­˜
        model_state = self.model.state_dict()
        optimizer_state = self.optimizer.state_dict()

        self.model.train()
        iter_count = 0

        for batch_idx, (data, target) in enumerate(train_loader):
            if iter_count >= num_iter:
                break

            data, target = data.to(self.device), target.to(self.device)

            # å­¦ç¿’ç‡ã‚’æ›´æ–°
            lr = lr_schedule[iter_count]
            for param_group in self.optimizer.param_groups:
                param_group['lr'] = lr

            # é †ä¼æ’­ã¨é€†ä¼æ’­
            self.optimizer.zero_grad()
            output = self.model(data)
            loss = self.criterion(output, target)
            loss.backward()
            self.optimizer.step()

            # è¨˜éŒ²
            self.history['lr'].append(lr)
            self.history['loss'].append(loss.item())

            # ç™ºæ•£ãƒã‚§ãƒƒã‚¯
            if loss.item() > 4 * self.best_loss:
                break

            if loss.item() < self.best_loss:
                self.best_loss = loss.item()

            iter_count += 1

        # ãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸçŠ¶æ…‹ã«æˆ»ã™
        self.model.load_state_dict(model_state)
        self.optimizer.load_state_dict(optimizer_state)

    def plot(self):
        """çµæœã®ãƒ—ãƒ­ãƒƒãƒˆ"""
        plt.figure(figsize=(10, 6))
        plt.plot(self.history['lr'], self.history['loss'])
        plt.xscale('log')
        plt.xlabel('Learning Rate')
        plt.ylabel('Loss')
        plt.title('Learning Rate Finder')
        plt.grid(True, alpha=0.3)
        plt.show()

        # æ¨å¥¨å­¦ç¿’ç‡
        min_loss_idx = np.argmin(self.history['loss'])
        suggested_lr = self.history['lr'][min_loss_idx] / 10
        print(f"æ¨å¥¨å­¦ç¿’ç‡: {suggested_lr:.2e}")

# ä½¿ç”¨ä¾‹
model = CIFAR10Net().to(device)
optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9)
criterion = nn.CrossEntropyLoss()

lr_finder = LRFinder(model, optimizer, criterion, device)
lr_finder.range_test(train_loader, start_lr=1e-6, end_lr=1, num_iter=100)
lr_finder.plot()
</code></pre>

<h3>ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«</h3>

<p>è¤‡æ•°ã®ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬ã‚’çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã§ã€ç²¾åº¦ã‚’å‘ä¸Šã•ã›ã¾ã™ã€‚</p>

<pre><code class="language-python">class ModelEnsemble:
    """ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã®å®Ÿè£…"""

    def __init__(self, models, device):
        """
        Args:
            models: ãƒ¢ãƒ‡ãƒ«ã®ãƒªã‚¹ãƒˆ
            device: å®Ÿè¡Œãƒ‡ãƒã‚¤ã‚¹
        """
        self.models = models
        self.device = device

        # å…¨ãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡ãƒ¢ãƒ¼ãƒ‰ã«
        for model in self.models:
            model.eval()

    def predict(self, data):
        """ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬ï¼ˆå¹³å‡ï¼‰"""
        predictions = []

        with torch.no_grad():
            for model in self.models:
                output = model(data)
                predictions.append(F.softmax(output, dim=1))

        # å¹³å‡ã‚’å–ã‚‹
        ensemble_pred = torch.stack(predictions).mean(dim=0)
        return ensemble_pred

    def evaluate(self, test_loader):
        """ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§è©•ä¾¡"""
        correct = 0
        total = 0

        with torch.no_grad():
            for data, target in test_loader:
                data, target = data.to(self.device), target.to(self.device)

                # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬
                ensemble_pred = self.predict(data)
                pred = ensemble_pred.argmax(dim=1)

                correct += pred.eq(target).sum().item()
                total += target.size(0)

        accuracy = 100. * correct / total
        print(f'Ensemble Accuracy: {correct}/{total} ({accuracy:.2f}%)')
        return accuracy

# è¤‡æ•°ã®ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ï¼ˆç•°ãªã‚‹åˆæœŸåŒ–ã‚„è¨­å®šã§ï¼‰
def train_multiple_models(n_models=5):
    """è¤‡æ•°ã®ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´"""
    models = []

    for i in range(n_models):
        print(f"\nTraining model {i+1}/{n_models}...")

        # ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–
        model = CIFAR10Net().to(device)

        # è¨“ç·´ï¼ˆç°¡ç•¥ç‰ˆï¼‰
        criterion = nn.CrossEntropyLoss()
        optimizer = optim.Adam(model.parameters(), lr=0.001)

        # è¨“ç·´ãƒ«ãƒ¼ãƒ—ï¼ˆçœç•¥ï¼‰
        # ... train_epoch(model, device, train_loader, optimizer, criterion)

        models.append(model)

    return models

# ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã®ä½¿ç”¨ä¾‹
# models = train_multiple_models(n_models=5)
# ensemble = ModelEnsemble(models, device)
# ensemble_acc = ensemble.evaluate(test_loader)
</code></pre>

<h3>Grad-CAMå¯è¦–åŒ–</h3>

<p>ãƒ¢ãƒ‡ãƒ«ãŒç”»åƒã®ã©ã“ã«æ³¨ç›®ã—ã¦ã„ã‚‹ã‹ã‚’å¯è¦–åŒ–ã—ã¾ã™ã€‚</p>

<pre><code class="language-python">class GradCAM:
    """Gradient-weighted Class Activation Mappingã®å®Ÿè£…"""

    def __init__(self, model, target_layer):
        self.model = model
        self.target_layer = target_layer
        self.gradients = None
        self.activations = None

        # ãƒ•ãƒƒã‚¯ã‚’ç™»éŒ²
        target_layer.register_forward_hook(self.save_activation)
        target_layer.register_backward_hook(self.save_gradient)

    def save_activation(self, module, input, output):
        """é †ä¼æ’­æ™‚ã®æ´»æ€§åŒ–ã‚’ä¿å­˜"""
        self.activations = output.detach()

    def save_gradient(self, module, grad_input, grad_output):
        """é€†ä¼æ’­æ™‚ã®å‹¾é…ã‚’ä¿å­˜"""
        self.gradients = grad_output[0].detach()

    def generate_cam(self, input_image, target_class):
        """CAMã‚’ç”Ÿæˆ"""

        # é †ä¼æ’­
        output = self.model(input_image)

        # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚¯ãƒ©ã‚¹ã®ã‚¹ã‚³ã‚¢ã«å¯¾ã™ã‚‹å‹¾é…
        self.model.zero_grad()
        class_loss = output[0, target_class]
        class_loss.backward()

        # å‹¾é…ã¨æ´»æ€§åŒ–ã‚’å–å¾—
        gradients = self.gradients[0]  # [C, H, W]
        activations = self.activations[0]  # [C, H, W]

        # å‹¾é…ã®å¹³å‡ï¼ˆé‡ã¿ï¼‰
        weights = gradients.mean(dim=(1, 2))  # [C]

        # é‡ã¿ä»˜ãå’Œ
        cam = torch.zeros(activations.shape[1:], dtype=torch.float32)
        for i, w in enumerate(weights):
            cam += w * activations[i]

        # ReLUé©ç”¨
        cam = F.relu(cam)

        # æ­£è¦åŒ–
        cam = cam - cam.min()
        cam = cam / cam.max()

        return cam.cpu().numpy()

def visualize_gradcam(model, image, label, device):
    """Grad-CAMã®å¯è¦–åŒ–"""

    # Grad-CAMã®æº–å‚™ï¼ˆæœ€å¾Œã®ç•³ã¿è¾¼ã¿å±¤ã‚’ã‚¿ãƒ¼ã‚²ãƒƒãƒˆï¼‰
    target_layer = model.conv3_3  # CIFAR10Netã®å ´åˆ
    gradcam = GradCAM(model, target_layer)

    # CAMã®ç”Ÿæˆ
    model.eval()
    image_input = image.unsqueeze(0).to(device)
    cam = gradcam.generate_cam(image_input, label)

    # å…ƒç”»åƒã®æº–å‚™
    img = image.cpu().numpy().transpose((1, 2, 0))
    mean = np.array([0.4914, 0.4822, 0.4465])
    std = np.array([0.2470, 0.2435, 0.2616])
    img = std * img + mean
    img = np.clip(img, 0, 1)

    # CAMã‚’ãƒªã‚µã‚¤ã‚º
    from scipy.ndimage import zoom
    cam_resized = zoom(cam, (img.shape[0]/cam.shape[0], img.shape[1]/cam.shape[1]))

    # å¯è¦–åŒ–
    fig, axes = plt.subplots(1, 3, figsize=(12, 4))

    axes[0].imshow(img)
    axes[0].set_title('Original Image')
    axes[0].axis('off')

    axes[1].imshow(cam_resized, cmap='jet')
    axes[1].set_title('Grad-CAM')
    axes[1].axis('off')

    axes[2].imshow(img)
    axes[2].imshow(cam_resized, cmap='jet', alpha=0.5)
    axes[2].set_title('Overlay')
    axes[2].axis('off')

    plt.tight_layout()
    plt.show()

# ä½¿ç”¨ä¾‹
# image, label = test_dataset[0]
# visualize_gradcam(model, image, label, device)
</code></pre>

<hr>

<h2>5.4 å®Ÿè·µçš„ãªãƒ’ãƒ³ãƒˆã¨ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹</h2>

<h3>ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°</h3>

<div class="mermaid">
graph TD
    A[åˆæœŸè¨­å®š] --> B{æ¤œè¨¼ç²¾åº¦}
    B -->|ä½ã„| C[å­¦ç¿’ç‡èª¿æ•´]
    B -->|éå­¦ç¿’| D[æ­£å‰‡åŒ–å¼·åŒ–]
    B -->|å­¦ç¿’ä¸è¶³| E[ã‚¨ãƒãƒƒã‚¯æ•°å¢—åŠ ]
    C --> F[å†è¨“ç·´]
    D --> F
    E --> F
    F --> B
    B -->|æº€è¶³| G[æœ€çµ‚è©•ä¾¡]

    style A fill:#e3f2fd
    style G fill:#e8f5e9
</div>

<table>
<thead>
<tr>
<th>ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿</th>
<th>æ¨å¥¨ç¯„å›²</th>
<th>èª¿æ•´ã®ãƒ’ãƒ³ãƒˆ</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Learning Rate</strong></td>
<td>1e-4 ~ 1e-1</td>
<td>LR Finderã‚’ä½¿ç”¨ã€å¤§ãã™ãã‚‹ã¨ç™ºæ•£</td>
</tr>
<tr>
<td><strong>Batch Size</strong></td>
<td>32 ~ 256</td>
<td>GPU ãƒ¡ãƒ¢ãƒªã«ä¾å­˜ã€å¤§ãã„ã»ã©å®‰å®š</td>
</tr>
<tr>
<td><strong>Weight Decay</strong></td>
<td>1e-5 ~ 1e-3</td>
<td>éå­¦ç¿’å¯¾ç­–ã€L2æ­£å‰‡åŒ–</td>
</tr>
<tr>
<td><strong>Dropout Rate</strong></td>
<td>0.3 ~ 0.5</td>
<td>éå­¦ç¿’ãŒå¼·ã„å ´åˆã¯å¢—ã‚„ã™</td>
</tr>
<tr>
<td><strong>Optimizer</strong></td>
<td>Adam, SGD+Momentum</td>
<td>Adamã¯æ±ç”¨çš„ã€SGDã¯åæŸãŒè‰¯ã„</td>
</tr>
</tbody>
</table>

<h3>ãƒ‡ãƒãƒƒã‚°ãƒ†ã‚¯ãƒ‹ãƒƒã‚¯</h3>

<pre><code class="language-python">class ModelDebugger:
    """ãƒ¢ãƒ‡ãƒ«ã®ãƒ‡ãƒãƒƒã‚°ãƒ„ãƒ¼ãƒ«"""

    @staticmethod
    def check_gradients(model):
        """å‹¾é…ã®ç¢ºèª"""
        print("\n=== Gradient Check ===")
        for name, param in model.named_parameters():
            if param.requires_grad and param.grad is not None:
                grad_mean = param.grad.mean().item()
                grad_std = param.grad.std().item()
                grad_max = param.grad.abs().max().item()
                print(f"{name:30s} - Mean: {grad_mean:8.6f}, "
                      f"Std: {grad_std:8.6f}, Max: {grad_max:8.6f}")

                # å‹¾é…æ¶ˆå¤±ãƒ»çˆ†ç™ºã®è­¦å‘Š
                if grad_max < 1e-6:
                    print(f"  âš ï¸  WARNING: Vanishing gradient!")
                if grad_max > 100:
                    print(f"  âš ï¸  WARNING: Exploding gradient!")

    @staticmethod
    def check_weights(model):
        """é‡ã¿ã®çµ±è¨ˆã‚’ç¢ºèª"""
        print("\n=== Weight Statistics ===")
        for name, param in model.named_parameters():
            if 'weight' in name:
                weight_mean = param.data.mean().item()
                weight_std = param.data.std().item()
                print(f"{name:30s} - Mean: {weight_mean:8.6f}, Std: {weight_std:8.6f}")

    @staticmethod
    def check_nan_inf(model):
        """NaN/Infã®æ¤œå‡º"""
        print("\n=== NaN/Inf Check ===")
        has_issue = False
        for name, param in model.named_parameters():
            if torch.isnan(param.data).any():
                print(f"  âŒ NaN detected in {name}")
                has_issue = True
            if torch.isinf(param.data).any():
                print(f"  âŒ Inf detected in {name}")
                has_issue = True

        if not has_issue:
            print("  âœ… No NaN/Inf detected")

    @staticmethod
    def visualize_activation_distribution(model, data, device):
        """æ´»æ€§åŒ–ã®åˆ†å¸ƒã‚’å¯è¦–åŒ–"""
        activations = {}

        def hook_fn(name):
            def hook(module, input, output):
                activations[name] = output.detach().cpu()
            return hook

        # ãƒ•ãƒƒã‚¯ã‚’ç™»éŒ²
        hooks = []
        for name, module in model.named_modules():
            if isinstance(module, (nn.Conv2d, nn.Linear)):
                hooks.append(module.register_forward_hook(hook_fn(name)))

        # é †ä¼æ’­
        model.eval()
        with torch.no_grad():
            _ = model(data.to(device))

        # ãƒ•ãƒƒã‚¯ã‚’å‰Šé™¤
        for hook in hooks:
            hook.remove()

        # å¯è¦–åŒ–
        fig, axes = plt.subplots(len(activations), 1, figsize=(10, 3*len(activations)))
        if len(activations) == 1:
            axes = [axes]

        for ax, (name, activation) in zip(axes, activations.items()):
            activation_flat = activation.flatten().numpy()
            ax.hist(activation_flat, bins=50, alpha=0.7)
            ax.set_title(f'Activation Distribution: {name}')
            ax.set_xlabel('Activation Value')
            ax.set_ylabel('Frequency')
            ax.grid(True, alpha=0.3)

        plt.tight_layout()
        plt.show()

# ä½¿ç”¨ä¾‹
debugger = ModelDebugger()

# è¨“ç·´ãƒ«ãƒ¼ãƒ—å†…ã§ä½¿ç”¨
for epoch in range(num_epochs):
    # è¨“ç·´
    # ...

    # ãƒ‡ãƒãƒƒã‚°ãƒã‚§ãƒƒã‚¯
    debugger.check_gradients(model)
    debugger.check_nan_inf(model)
</code></pre>

<h3>GPUæ´»ç”¨ã¨ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–</h3>

<pre><code class="language-python">import torch.cuda as cuda

class GPUOptimizer:
    """GPUæœ€é©åŒ–ã®ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£"""

    @staticmethod
    def get_gpu_info():
        """GPUæƒ…å ±ã®å–å¾—"""
        if not torch.cuda.is_available():
            print("CUDA is not available")
            return

        print(f"GPU Device: {torch.cuda.get_device_name(0)}")
        print(f"CUDA Version: {torch.version.cuda}")
        print(f"Total Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB")
        print(f"Allocated Memory: {torch.cuda.memory_allocated(0) / 1e9:.4f} GB")
        print(f"Cached Memory: {torch.cuda.memory_reserved(0) / 1e9:.4f} GB")

    @staticmethod
    def clear_cache():
        """GPUã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®ã‚¯ãƒªã‚¢"""
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            print("GPU cache cleared")

    @staticmethod
    def mixed_precision_training_example(model, train_loader, device):
        """Mixed Precision Trainingï¼ˆFP16ï¼‰ã®ä¾‹"""
        from torch.cuda.amp import autocast, GradScaler

        criterion = nn.CrossEntropyLoss()
        optimizer = optim.Adam(model.parameters(), lr=0.001)
        scaler = GradScaler()

        model.train()

        for data, target in train_loader:
            data, target = data.to(device), target.to(device)

            optimizer.zero_grad()

            # Mixed Precision
            with autocast():
                output = model(data)
                loss = criterion(output, target)

            # Scalerã‚’ä½¿ç”¨ã—ãŸé€†ä¼æ’­
            scaler.scale(loss).backward()
            scaler.step(optimizer)
            scaler.update()

        print("Mixed precision training completed")

# GPUæƒ…å ±ã®è¡¨ç¤º
GPUOptimizer.get_gpu_info()

# ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ã®Tips
def optimize_memory_usage():
    """ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®æœ€é©åŒ–"""

    tips = [
        "1. ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’å°ã•ãã™ã‚‹ï¼ˆ64 â†’ 32 â†’ 16ï¼‰",
        "2. Gradient Accumulation ã‚’ä½¿ç”¨ï¼ˆè¤‡æ•°ã‚¹ãƒ†ãƒƒãƒ—ã§å‹¾é…ã‚’ç´¯ç©ï¼‰",
        "3. Mixed Precision Trainingï¼ˆFP16ï¼‰ã‚’ä½¿ç”¨",
        "4. ä¸è¦ãªä¸­é–“çµæœã¯ torch.no_grad() ã§åŒ…ã‚€",
        "5. del æ–‡ã§ä¸è¦ãªå¤‰æ•°ã‚’æ˜ç¤ºçš„ã«å‰Šé™¤",
        "6. torch.cuda.empty_cache() ã§ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢",
        "7. DataLoader ã® num_workers ã‚’èª¿æ•´ï¼ˆCPU/GPU ãƒãƒ©ãƒ³ã‚¹ï¼‰",
        "8. Inplace æ“ä½œã‚’æ´»ç”¨ï¼ˆx = x + 1 â†’ x += 1ï¼‰"
    ]

    print("\n=== ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ã®Tips ===")
    for tip in tips:
        print(tip)

optimize_memory_usage()
</code></pre>

<h3>æœ¬ç•ªç’°å¢ƒã¸ã®ãƒ‡ãƒ—ãƒ­ã‚¤</h3>

<pre><code class="language-python">import torch.jit

class ModelDeployment:
    """ãƒ¢ãƒ‡ãƒ«ã®ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆ"""

    @staticmethod
    def export_to_torchscript(model, example_input, save_path='model_scripted.pt'):
        """TorchScriptã¸ã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
        model.eval()

        # Scriptãƒ¢ãƒ¼ãƒ‰
        scripted_model = torch.jit.script(model)
        scripted_model.save(save_path)
        print(f"Model exported to TorchScript: {save_path}")

        return scripted_model

    @staticmethod
    def export_to_onnx(model, example_input, save_path='model.onnx'):
        """ONNXãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã¸ã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
        model.eval()

        torch.onnx.export(
            model,
            example_input,
            save_path,
            export_params=True,
            opset_version=11,
            do_constant_folding=True,
            input_names=['input'],
            output_names=['output'],
            dynamic_axes={
                'input': {0: 'batch_size'},
                'output': {0: 'batch_size'}
            }
        )
        print(f"Model exported to ONNX: {save_path}")

    @staticmethod
    def optimize_for_inference(model):
        """æ¨è«–ç”¨ã®æœ€é©åŒ–"""
        model.eval()

        # æ¨è«–ãƒ¢ãƒ¼ãƒ‰ã«è¨­å®š
        for param in model.parameters():
            param.requires_grad = False

        # Batchnorm ã¨ Dropout ã‚’å›ºå®š
        for module in model.modules():
            if isinstance(module, nn.BatchNorm2d):
                module.track_running_stats = False
            if isinstance(module, nn.Dropout):
                module.p = 0

        return model

    @staticmethod
    def benchmark_inference(model, example_input, device, num_runs=100):
        """æ¨è«–é€Ÿåº¦ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯"""
        import time

        model.eval()
        model = model.to(device)
        example_input = example_input.to(device)

        # ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—
        with torch.no_grad():
            for _ in range(10):
                _ = model(example_input)

        # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
        torch.cuda.synchronize() if device.type == 'cuda' else None
        start_time = time.time()

        with torch.no_grad():
            for _ in range(num_runs):
                _ = model(example_input)

        torch.cuda.synchronize() if device.type == 'cuda' else None
        end_time = time.time()

        avg_time = (end_time - start_time) / num_runs
        fps = 1 / avg_time

        print(f"\n=== Inference Benchmark ===")
        print(f"Average inference time: {avg_time*1000:.2f} ms")
        print(f"Throughput: {fps:.2f} FPS")
        print(f"Total runs: {num_runs}")

# ä½¿ç”¨ä¾‹
deployment = ModelDeployment()

# ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰
model = CIFAR10Net().to(device)
model.load_state_dict(torch.load('cifar10_best.pth'))

# æ¨è«–ç”¨ã«æœ€é©åŒ–
model = deployment.optimize_for_inference(model)

# ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
example_input = torch.randn(1, 3, 32, 32).to(device)
# deployment.export_to_torchscript(model, example_input)
# deployment.export_to_onnx(model, example_input)

# ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
deployment.benchmark_inference(model, example_input, device)
</code></pre>

<hr>

<h2>æœ¬ç« ã®ã¾ã¨ã‚</h2>

<h3>å­¦ã‚“ã ã“ã¨</h3>

<ol>
<li><p><strong>MNISTæ‰‹æ›¸ãæ•°å­—èªè­˜</strong></p>
<ul>
<li>å®Œå…¨ãªãƒ‡ãƒ¼ã‚¿æº–å‚™ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³</li>
<li>åŠ¹ç‡çš„ãªCNNã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è¨­è¨ˆ</li>
<li>æ··åŒè¡Œåˆ—ã¨ã‚¨ãƒ©ãƒ¼åˆ†æ</li>
</ul></li>
<li><p><strong>CIFAR-10ã‚«ãƒ©ãƒ¼ç”»åƒåˆ†é¡</strong></p>
<ul>
<li>ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã®å®Ÿè·µçš„ãªæ´»ç”¨</li>
<li>VGGã‚¹ã‚¿ã‚¤ãƒ«ã®æ·±ã„ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯</li>
<li>Batch Normalizationã¨Dropout</li>
</ul></li>
<li><p><strong>é«˜åº¦ãªãƒ†ã‚¯ãƒ‹ãƒƒã‚¯</strong></p>
<ul>
<li>è»¢ç§»å­¦ç¿’ã¨ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°</li>
<li>Learning Rate Finder</li>
<li>ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«</li>
<li>Grad-CAMå¯è¦–åŒ–</li>
</ul></li>
<li><p><strong>å®Ÿè·µçš„ãªã‚¹ã‚­ãƒ«</strong></p>
<ul>
<li>ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°</li>
<li>ãƒ‡ãƒãƒƒã‚°ãƒ†ã‚¯ãƒ‹ãƒƒã‚¯</li>
<li>GPUæœ€é©åŒ–</li>
<li>æœ¬ç•ªãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆ</li>
</ul></li>
</ol>

<h3>ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ</h3>

<table>
<thead>
<tr>
<th>é …ç›®</th>
<th>é‡è¦åº¦</th>
<th>èª¬æ˜</th>
</tr>
</thead>
<tbody>
<tr>
<td>âœ… ãƒ‡ãƒ¼ã‚¿æ­£è¦åŒ–</td>
<td>å¿…é ˆ</td>
<td>å¹³å‡0ã€æ¨™æº–åå·®1ã«æ­£è¦åŒ–</td>
</tr>
<tr>
<td>âœ… ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µ</td>
<td>é«˜</td>
<td>è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®å¤šæ§˜æ€§ã‚’å¢—ã‚„ã™</td>
</tr>
<tr>
<td>âœ… Batch Normalization</td>
<td>é«˜</td>
<td>å­¦ç¿’ã®å®‰å®šåŒ–ã¨é«˜é€ŸåŒ–</td>
</tr>
<tr>
<td>âœ… Dropout</td>
<td>é«˜</td>
<td>éå­¦ç¿’ã®é˜²æ­¢</td>
</tr>
<tr>
<td>âœ… Learning Rate Scheduling</td>
<td>ä¸­</td>
<td>å­¦ç¿’ç‡ã®å‹•çš„èª¿æ•´</td>
</tr>
<tr>
<td>âœ… Early Stopping</td>
<td>ä¸­</td>
<td>éå­¦ç¿’ã®æ—©æœŸæ¤œå‡º</td>
</tr>
<tr>
<td>âœ… ãƒ¢ãƒ‡ãƒ«ä¿å­˜</td>
<td>å¿…é ˆ</td>
<td>ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ</td>
</tr>
<tr>
<td>âœ… è©•ä¾¡æŒ‡æ¨™ã®è¨˜éŒ²</td>
<td>å¿…é ˆ</td>
<td>è¨“ç·´éç¨‹ã®å¯è¦–åŒ–</td>
</tr>
</tbody>
</table>

<hr>

<h2>æ¼”ç¿’å•é¡Œ</h2>

<h3>å•é¡Œ1ï¼ˆé›£æ˜“åº¦ï¼šmediumï¼‰</h3>
<p>MNISTãƒ¢ãƒ‡ãƒ«ã«ä»¥ä¸‹ã®æ”¹å–„ã‚’åŠ ãˆã¦ã€ç²¾åº¦ã‚’99%ä»¥ä¸Šã«ã—ã¦ãã ã•ã„ï¼š</p>
<ul>
<li>Batch Normalizationã‚’è¿½åŠ </li>
<li>ã‚ˆã‚Šæ·±ã„ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼ˆ3å±¤ä»¥ä¸Šã®ç•³ã¿è¾¼ã¿å±¤ï¼‰</li>
<li>ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µï¼ˆå›è»¢ã€å¹³è¡Œç§»å‹•ï¼‰</li>
</ul>

<details>
<summary>ãƒ’ãƒ³ãƒˆ</summary>

<ul>
<li>å„ç•³ã¿è¾¼ã¿å±¤ã®å¾Œã«Batch Normalizationã‚’è¿½åŠ </li>
<li>RandomRotation ã¨ RandomAffine ã‚’ä½¿ç”¨</li>
<li>å­¦ç¿’ç‡ã‚’é©åˆ‡ã«èª¿æ•´ï¼ˆ0.001å‰å¾Œï¼‰</li>
</ul>

</details>

<details>
<summary>è§£ç­”ä¾‹</summary>

<pre><code class="language-python">class ImprovedMNISTNet(nn.Module):
    """æ”¹å–„ç‰ˆMNISTãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯"""

    def __init__(self):
        super(ImprovedMNISTNet, self).__init__()

        # ç•³ã¿è¾¼ã¿å±¤ï¼ˆ3ãƒ–ãƒ­ãƒƒã‚¯ï¼‰
        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)
        self.bn1 = nn.BatchNorm2d(32)

        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)
        self.bn2 = nn.BatchNorm2d(64)

        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)
        self.bn3 = nn.BatchNorm2d(128)

        self.pool = nn.MaxPool2d(2, 2)

        # å…¨çµåˆå±¤
        self.fc1 = nn.Linear(128 * 3 * 3, 256)
        self.bn_fc = nn.BatchNorm1d(256)
        self.fc2 = nn.Linear(256, 10)

        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        # ãƒ–ãƒ­ãƒƒã‚¯1: 28Ã—28 â†’ 14Ã—14
        x = self.pool(F.relu(self.bn1(self.conv1(x))))

        # ãƒ–ãƒ­ãƒƒã‚¯2: 14Ã—14 â†’ 7Ã—7
        x = self.pool(F.relu(self.bn2(self.conv2(x))))

        # ãƒ–ãƒ­ãƒƒã‚¯3: 7Ã—7 â†’ 3Ã—3
        x = self.pool(F.relu(self.bn3(self.conv3(x))))

        # å¹³å¦åŒ–ã¨å…¨çµåˆå±¤
        x = x.view(-1, 128 * 3 * 3)
        x = F.relu(self.bn_fc(self.fc1(x)))
        x = self.dropout(x)
        x = self.fc2(x)

        return x

# ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µ
train_transform = transforms.Compose([
    transforms.RandomRotation(10),
    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),
    transforms.ToTensor(),
    transforms.Normalize((0.1307,), (0.3081,))
])

# è¨“ç·´
# model = ImprovedMNISTNet().to(device)
# æœŸå¾…ã•ã‚Œã‚‹ç²¾åº¦: 99.2%ä»¥ä¸Š
</code></pre>

</details>

<h3>å•é¡Œ2ï¼ˆé›£æ˜“åº¦ï¼šhardï¼‰</h3>
<p>CIFAR-10ã§è»¢ç§»å­¦ç¿’ã‚’ä½¿ã£ã¦ã€20ã‚¨ãƒãƒƒã‚¯ä»¥å†…ã«90%ä»¥ä¸Šã®ç²¾åº¦ã‚’é”æˆã—ã¦ãã ã•ã„ã€‚ResNet50ã‚’ä½¿ç”¨ã—ã€é©åˆ‡ãªãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æˆ¦ç•¥ã‚’å®Ÿè£…ã—ã¦ãã ã•ã„ã€‚</p>

<details>
<summary>ãƒ’ãƒ³ãƒˆ</summary>

<ul>
<li>Phase 1: åˆ†é¡å™¨ã®ã¿è¨“ç·´ï¼ˆ5ã‚¨ãƒãƒƒã‚¯ã€lr=0.001ï¼‰</li>
<li>Phase 2: æœ€å¾Œã®æ®‹å·®ãƒ–ãƒ­ãƒƒã‚¯ã‚’è§£å‡ï¼ˆ10ã‚¨ãƒãƒƒã‚¯ã€lr=0.0001ï¼‰</li>
<li>Phase 3: å…¨å±¤ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆ5ã‚¨ãƒãƒƒã‚¯ã€lr=0.00001ï¼‰</li>
</ul>

</details>

<h3>å•é¡Œ3ï¼ˆé›£æ˜“åº¦ï¼šmediumï¼‰</h3>
<p>Learning Rate Finderã‚’å®Ÿè£…ã—ã€æœ€é©ãªå­¦ç¿’ç‡ã‚’è¦‹ã¤ã‘ã¦ãã ã•ã„ã€‚ãã®å­¦ç¿’ç‡ã‚’ä½¿ã£ã¦ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã—ã€çµæœã‚’æ¯”è¼ƒã—ã¦ãã ã•ã„ã€‚</p>

<details>
<summary>è§£ç­”ä¾‹</summary>

<pre><code class="language-python"># LRFinderã‚’ä½¿ç”¨
model = CIFAR10Net().to(device)
optimizer = optim.SGD(model.parameters(), lr=0.001)
criterion = nn.CrossEntropyLoss()

lr_finder = LRFinder(model, optimizer, criterion, device)
lr_finder.range_test(train_loader, start_lr=1e-6, end_lr=1, num_iter=200)
lr_finder.plot()

# æ¨å¥¨å­¦ç¿’ç‡ã‚’ä½¿ç”¨
# å‡ºåŠ›ä¾‹: "æ¨å¥¨å­¦ç¿’ç‡: 1.2e-02"
suggested_lr = 0.012

# æ–°ã—ã„ãƒ¢ãƒ‡ãƒ«ã§è¨“ç·´
model = CIFAR10Net().to(device)
optimizer = optim.SGD(model.parameters(), lr=suggested_lr, momentum=0.9)
# è¨“ç·´å®Ÿè¡Œ...
</code></pre>

</details>

<h3>å•é¡Œ4ï¼ˆé›£æ˜“åº¦ï¼šhardï¼‰</h3>
<p>3ã¤ã®ç•°ãªã‚‹ãƒ¢ãƒ‡ãƒ«ï¼ˆç•°ãªã‚‹ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¾ãŸã¯ç•°ãªã‚‹åˆæœŸåŒ–ï¼‰ã‚’è¨“ç·´ã—ã€ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã§ç²¾åº¦ã‚’å‘ä¸Šã•ã›ã¦ãã ã•ã„ã€‚å€‹ã€…ã®ãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Š2%ä»¥ä¸Šã®æ”¹å–„ã‚’ç›®æŒ‡ã—ã¦ãã ã•ã„ã€‚</p>

<details>
<summary>ãƒ’ãƒ³ãƒˆ</summary>

<ul>
<li>ãƒ¢ãƒ‡ãƒ«1: CIFAR10Netï¼ˆVGGã‚¹ã‚¿ã‚¤ãƒ«ï¼‰</li>
<li>ãƒ¢ãƒ‡ãƒ«2: ResNet18ï¼ˆè»¢ç§»å­¦ç¿’ï¼‰</li>
<li>ãƒ¢ãƒ‡ãƒ«3: DenseNetï¼ˆè»¢ç§»å­¦ç¿’ï¼‰</li>
<li>ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æ–¹æ³•: äºˆæ¸¬ç¢ºç‡ã®å¹³å‡ã€ã¾ãŸã¯å¤šæ•°æ±º</li>
</ul>

</details>

<h3>å•é¡Œ5ï¼ˆé›£æ˜“åº¦ï¼šhardï¼‰</h3>
<p>Mixed Precision Trainingï¼ˆFP16ï¼‰ã‚’å®Ÿè£…ã—ã€é€šå¸¸ã®è¨“ç·´ã¨æ¯”è¼ƒã—ã¦ãã ã•ã„ã€‚é€Ÿåº¦ã¨ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã€ç²¾åº¦ã®å·®ã‚’æ¸¬å®šã—ã¦ãã ã•ã„ã€‚</p>

<details>
<summary>è§£ç­”ä¾‹</summary>

<pre><code class="language-python">from torch.cuda.amp import autocast, GradScaler
import time

def train_with_mixed_precision(model, train_loader, num_epochs=10):
    """Mixed Precision Trainingã®å®Ÿè£…"""

    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=0.001)
    scaler = GradScaler()

    start_time = time.time()

    for epoch in range(1, num_epochs + 1):
        model.train()
        running_loss = 0.0

        for data, target in train_loader:
            data, target = data.to(device), target.to(device)

            optimizer.zero_grad()

            # Mixed Precision
            with autocast():
                output = model(data)
                loss = criterion(output, target)

            # Scaled backpropagation
            scaler.scale(loss).backward()
            scaler.step(optimizer)
            scaler.update()

            running_loss += loss.item()

        epoch_loss = running_loss / len(train_loader)
        print(f"Epoch {epoch}/{num_epochs} - Loss: {epoch_loss:.4f}")

    total_time = time.time() - start_time
    print(f"\nTotal training time: {total_time:.2f} seconds")

    # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡
    if torch.cuda.is_available():
        print(f"Max memory allocated: {torch.cuda.max_memory_allocated()/1e9:.2f} GB")

# é€šå¸¸è¨“ç·´ã¨æ¯”è¼ƒ
model_fp32 = CIFAR10Net().to(device)
model_fp16 = CIFAR10Net().to(device)

print("=== FP32 Training ===")
# é€šå¸¸è¨“ç·´...

print("\n=== FP16 Training ===")
train_with_mixed_precision(model_fp16, train_loader)

# æœŸå¾…ã•ã‚Œã‚‹çµæœ:
# - FP16ã¯1.5-2å€é«˜é€Ÿ
# - ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã¯30-40%å‰Šæ¸›
# - ç²¾åº¦ã¯ã»ã¼åŒç­‰ï¼ˆÂ±0.5%ä»¥å†…ï¼‰
</code></pre>

</details>

<hr>

<h2>å‚è€ƒæ–‡çŒ®</h2>

<ol>
<li>LeCun, Y., Bottou, L., Bengio, Y., & Haffner, P. (1998). "Gradient-based learning applied to document recognition." <em>Proceedings of the IEEE</em>, 86(11), 2278-2324.</li>
<li>Krizhevsky, A., & Hinton, G. (2009). "Learning multiple layers of features from tiny images." <em>Technical Report</em>, University of Toronto.</li>
<li>He, K., Zhang, X., Ren, S., & Sun, J. (2016). "Deep residual learning for image recognition." <em>CVPR</em>.</li>
<li>Smith, L. N. (2017). "Cyclical learning rates for training neural networks." <em>WACV</em>.</li>
<li>Selvaraju, R. R., et al. (2017). "Grad-CAM: Visual explanations from deep networks via gradient-based localization." <em>ICCV</em>.</li>
<li>Ioffe, S., & Szegedy, C. (2015). "Batch normalization: Accelerating deep network training by reducing internal covariate shift." <em>ICML</em>.</li>
</ol>

<div class="navigation">
    <a href="chapter4-cnn.html" class="nav-button">â† å‰ã®ç« : CNN</a>
    <a href="index.html" class="nav-button">ã‚·ãƒªãƒ¼ã‚ºç›®æ¬¡</a>
    <a href="../index.html" class="nav-button">æ©Ÿæ¢°å­¦ç¿’ãƒˆãƒƒãƒ— â†’</a>
</div>

    </main>

    
    <section class="disclaimer">
        <h3>å…è²¬äº‹é …</h3>
        <ul>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯æ•™è‚²ãƒ»ç ”ç©¶ãƒ»æƒ…å ±æä¾›ã®ã¿ã‚’ç›®çš„ã¨ã—ã¦ãŠã‚Šã€å°‚é–€çš„ãªåŠ©è¨€(æ³•å¾‹ãƒ»ä¼šè¨ˆãƒ»æŠ€è¡“çš„ä¿è¨¼ãªã©)ã‚’æä¾›ã™ã‚‹ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŠã‚ˆã³ä»˜éšã™ã‚‹ã‚³ãƒ¼ãƒ‰ä¾‹ã¯ã€Œç¾çŠ¶æœ‰å§¿(AS IS)ã€ã§æä¾›ã•ã‚Œã€æ˜ç¤ºã¾ãŸã¯é»™ç¤ºã‚’å•ã‚ãšã€å•†å“æ€§ã€ç‰¹å®šç›®çš„é©åˆæ€§ã€æ¨©åˆ©éä¾µå®³ã€æ­£ç¢ºæ€§ãƒ»å®Œå…¨æ€§ã€å‹•ä½œãƒ»å®‰å…¨æ€§ç­‰ã„ã‹ãªã‚‹ä¿è¨¼ã‚‚ã—ã¾ã›ã‚“ã€‚</li>
            <li>å¤–éƒ¨ãƒªãƒ³ã‚¯ã€ç¬¬ä¸‰è€…ãŒæä¾›ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ»ãƒ„ãƒ¼ãƒ«ãƒ»ãƒ©ã‚¤ãƒ–ãƒ©ãƒªç­‰ã®å†…å®¹ãƒ»å¯ç”¨æ€§ãƒ»å®‰å…¨æ€§ã«ã¤ã„ã¦ã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯ä¸€åˆ‡ã®è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®åˆ©ç”¨ãƒ»å®Ÿè¡Œãƒ»è§£é‡ˆã«ã‚ˆã‚Šç›´æ¥çš„ãƒ»é–“æ¥çš„ãƒ»ä»˜éšçš„ãƒ»ç‰¹åˆ¥ãƒ»çµæœçš„ãƒ»æ‡²ç½°çš„æå®³ãŒç”Ÿã˜ãŸå ´åˆã§ã‚‚ã€é©ç”¨æ³•ã§è¨±å®¹ã•ã‚Œã‚‹æœ€å¤§é™ã®ç¯„å›²ã§ã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å†…å®¹ã¯ã€äºˆå‘Šãªãå¤‰æ›´ãƒ»æ›´æ–°ãƒ»æä¾›åœæ­¢ã•ã‚Œã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®è‘—ä½œæ¨©ãƒ»ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯æ˜è¨˜ã•ã‚ŒãŸæ¡ä»¶(ä¾‹: CC BY 4.0)ã«å¾“ã„ã¾ã™ã€‚å½“è©²ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯é€šå¸¸ã€ç„¡ä¿è¨¼æ¡é …ã‚’å«ã¿ã¾ã™ã€‚</li>
        </ul>
    </section>

<footer>
        <p><strong>ä½œæˆè€…</strong>: AI Terakoya Content Team</p>
        <p><strong>ãƒãƒ¼ã‚¸ãƒ§ãƒ³</strong>: 1.0 | <strong>ä½œæˆæ—¥</strong>: 2025-10-20</p>
        <p><strong>ãƒ©ã‚¤ã‚»ãƒ³ã‚¹</strong>: Creative Commons BY 4.0</p>
        <p>Â© 2025 AI Terakoya. All rights reserved.</p>
    </footer>
</body>
</html>
