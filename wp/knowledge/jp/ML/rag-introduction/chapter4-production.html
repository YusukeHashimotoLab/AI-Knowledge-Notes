<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="ãƒ—ãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³ç’°å¢ƒã¸ã®å±•é–‹ - ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã€æœ€é©åŒ–ã€ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°">
    <title>ç¬¬4ç« ï¼šãƒ—ãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³ç’°å¢ƒã¸ã®å±•é–‹ - RAGå…¥é–€ã‚·ãƒªãƒ¼ã‚º</title>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js"></script>
    <style>
        :root {
            --primary-color: #2c3e50;
            --secondary-color: #3498db;
            --accent-color: #e74c3c;
            --bg-color: #ffffff;
            --text-color: #333333;
            --border-color: #e0e0e0;
            --code-bg: #f5f5f5;
            --link-color: #3498db;
            --link-hover: #2980b9;
        }
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", "Hiragino Sans", "Hiragino Kaku Gothic ProN", Meiryo, sans-serif;
            line-height: 1.8;
            color: var(--text-color);
            background: var(--bg-color);
            padding: 0;
            margin: 0;
        }
        .container { max-width: 900px; margin: 0 auto; padding: 2rem 1.5rem; }
        header {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 2rem 0;
            margin-bottom: 2rem;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        header .container { padding: 0 1.5rem; }
        h1 { font-size: 2rem; margin-bottom: 0.5rem; font-weight: 700; }
        .meta {
            display: flex;
            gap: 1.5rem;
            flex-wrap: wrap;
            font-size: 0.9rem;
            opacity: 0.95;
            margin-top: 1rem;
        }
        .meta span { display: inline-flex; align-items: center; gap: 0.3rem; }
        h2 {
            font-size: 1.75rem;
            margin-top: 2.5rem;
            margin-bottom: 1rem;
            padding-bottom: 0.5rem;
            border-bottom: 3px solid var(--secondary-color);
            color: var(--primary-color);
        }
        h3 { font-size: 1.4rem; margin-top: 2rem; margin-bottom: 0.8rem; color: var(--primary-color); }
        h4 { font-size: 1.2rem; margin-top: 1.5rem; margin-bottom: 0.6rem; color: var(--primary-color); }
        p { margin-bottom: 1.2rem; }
        a { color: var(--link-color); text-decoration: none; transition: color 0.2s; }
        a:hover { color: var(--link-hover); text-decoration: underline; }
        ul, ol { margin-left: 2rem; margin-bottom: 1.2rem; }
        li { margin-bottom: 0.5rem; }
        pre {
            background: var(--code-bg);
            padding: 1.2rem;
            border-radius: 6px;
            overflow-x: auto;
            margin-bottom: 1.5rem;
            border-left: 4px solid var(--secondary-color);
        }
        code {
            background: var(--code-bg);
            padding: 0.2rem 0.4rem;
            border-radius: 3px;
            font-family: 'Menlo', 'Monaco', 'Courier New', monospace;
            font-size: 0.9em;
        }
        pre code { background: none; padding: 0; }
        .nav-buttons {
            display: flex;
            justify-content: space-between;
            margin: 3rem 0;
            gap: 1rem;
            flex-wrap: wrap;
        }
        .nav-button {
            display: inline-block;
            padding: 0.8rem 1.5rem;
            background: var(--secondary-color);
            color: white;
            border-radius: 6px;
            text-decoration: none;
            transition: all 0.3s;
            font-weight: 600;
        }
        .nav-button:hover {
            background: var(--link-hover);
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(52, 152, 219, 0.3);
        }
        .example-box {
            background: #f8f9fa;
            border-left: 4px solid var(--accent-color);
            padding: 1.2rem;
            margin: 1.5rem 0;
            border-radius: 4px;
        }
        .note-box {
            background: #fff3cd;
            border-left: 4px solid #ffc107;
            padding: 1rem;
            margin: 1.5rem 0;
            border-radius: 4px;
        }
        footer {
            margin-top: 4rem;
            padding: 2rem 0;
            border-top: 2px solid var(--border-color);
            text-align: center;
            color: #666;
            font-size: 0.9rem;
        }
        @media (max-width: 768px) {
            .container { padding: 1rem; }
            h1 { font-size: 1.6rem; }
            h2 { font-size: 1.4rem; }
            .meta { font-size: 0.85rem; }
        }
    
        .feedback-notice {
            background: #fff3cd;
            border: 2px solid #ffc107;
            border-radius: 8px;
            padding: 2rem;
            margin: 3rem auto;
            max-width: 900px;
        }

        .feedback-notice h3 {
            color: #856404;
            font-size: 1.3rem;
            margin-bottom: 1rem;
            text-align: center;
        }

        .feedback-notice p {
            color: #856404;
            font-size: 1rem;
            margin-bottom: 1.5rem;
            text-align: center;
        }

        .feedback-options {
            display: flex;
            justify-content: center;
            gap: 1rem;
            flex-wrap: wrap;
        }

        .feedback-button {
            display: inline-block;
            padding: 0.8rem 1.5rem;
            background: #3498db;
            color: white;
            text-decoration: none;
            border-radius: 6px;
            font-weight: 600;
            transition: all 0.3s;
        }

        .feedback-button:hover {
            background: #2980b9;
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(52, 152, 219, 0.3);
        }

    
        
    
        /* Breadcrumb styles */
        .breadcrumb {
            background: #f7fafc;
            padding: 0.75rem 1rem;
            border-bottom: 1px solid #e2e8f0;
            font-size: 0.9rem;
        }

        .breadcrumb-content {
            max-width: 900px;
            margin: 0 auto;
            display: flex;
            align-items: center;
            flex-wrap: wrap;
            gap: 0.5rem;
        }

        .breadcrumb a {
            color: #667eea;
            text-decoration: none;
            transition: color 0.2s;
        }

        .breadcrumb a:hover {
            color: #764ba2;
            text-decoration: underline;
        }

        .breadcrumb-separator {
            color: #a0aec0;
            margin: 0 0.25rem;
        }

        .breadcrumb-current {
            color: #4a5568;
            font-weight: 500;
        }
    </style>
</head>
<body>
            <nav class="breadcrumb">
        <div class="breadcrumb-content">
            <a href="/AI-Knowledge-Notes/knowledge/jp/index.html">AIå¯ºå­å±‹ãƒˆãƒƒãƒ—</a><span class="breadcrumb-separator">â€º</span><a href="/AI-Knowledge-Notes/knowledge/jp/ML/index.html">æ©Ÿæ¢°å­¦ç¿’</a><span class="breadcrumb-separator">â€º</span><a href="/AI-Knowledge-Notes/knowledge/jp/ML/rag-introduction/index.html">Rag</a><span class="breadcrumb-separator">â€º</span><span class="breadcrumb-current">Chapter 4</span>
        </div>
    </nav>

        <header>
        <div class="container">
            <h1>ç¬¬4ç« ï¼šãƒ—ãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³ç’°å¢ƒã¸ã®å±•é–‹</h1>
            <p style="font-size: 1.1rem; margin-top: 0.5rem; opacity: 0.95;">ã‚·ã‚¹ãƒ†ãƒ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¨é‹ç”¨</p>
            <div class="meta">
                <span>ğŸ“– å­¦ç¿’æ™‚é–“: 30-40åˆ†</span>
                <span>ğŸ“Š é›£æ˜“åº¦: ä¸Šç´š</span>
                <span>ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹: 6å€‹</span>
            </div>
        </div>
    </header>

    <main class="container">
        <h2>1. ã‚·ã‚¹ãƒ†ãƒ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£</h2>

        <h3>1.1 ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹è¨­è¨ˆ</h3>
        <p>æœ¬ç•ªç’°å¢ƒã®RAGã‚·ã‚¹ãƒ†ãƒ ã¯ã€è¤‡æ•°ã®ã‚µãƒ¼ãƒ“ã‚¹ã«åˆ†é›¢ã—ã¦æ§‹ç¯‰ã—ã¾ã™ã€‚</p>

        <div class="example-box">
            <strong>RAGã‚·ã‚¹ãƒ†ãƒ ã®ä¸»è¦ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ:</strong>
            <ul>
                <li><strong>ã‚¤ãƒ³ã‚¸ã‚§ã‚¹ãƒˆã‚µãƒ¼ãƒ“ã‚¹</strong>: ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå–ã‚Šè¾¼ã¿ã¨å‰å‡¦ç†</li>
                <li><strong>ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ã‚µãƒ¼ãƒ“ã‚¹</strong>: ãƒ™ã‚¯ãƒˆãƒ«åŒ–å‡¦ç†</li>
                <li><strong>æ¤œç´¢ã‚µãƒ¼ãƒ“ã‚¹</strong>: ãƒ™ã‚¯ãƒˆãƒ«DBæ¤œç´¢ã¨ãƒªãƒ©ãƒ³ã‚­ãƒ³ã‚°</li>
                <li><strong>ç”Ÿæˆã‚µãƒ¼ãƒ“ã‚¹</strong>: LLMå‘¼ã³å‡ºã—ã¨å›ç­”ç”Ÿæˆ</li>
                <li><strong>APIã‚²ãƒ¼ãƒˆã‚¦ã‚§ã‚¤</strong>: ãƒªã‚¯ã‚¨ã‚¹ãƒˆç®¡ç†ã¨èªè¨¼</li>
            </ul>
        </div>

        <h4>å®Ÿè£…ä¾‹1: FastAPIãƒ™ãƒ¼ã‚¹RAGã‚·ã‚¹ãƒ†ãƒ </h4>
        <pre><code>from fastapi import FastAPI, HTTPException, Depends
from pydantic import BaseModel
from typing import List, Optional
import asyncio
from functools import lru_cache

app = FastAPI(title="RAG API", version="1.0.0")

# ãƒªã‚¯ã‚¨ã‚¹ãƒˆ/ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ¢ãƒ‡ãƒ«
class QueryRequest(BaseModel):
    query: str
    top_k: int = 5
    filters: Optional[dict] = None

class SearchResult(BaseModel):
    content: str
    score: float
    metadata: dict

class QueryResponse(BaseModel):
    answer: str
    sources: List[SearchResult]
    processing_time: float

# ä¾å­˜æ€§æ³¨å…¥
@lru_cache()
def get_rag_service():
    """RAGã‚µãƒ¼ãƒ“ã‚¹ã®ã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³å–å¾—"""
    from services.rag_service import RAGService
    return RAGService()

@app.post("/query", response_model=QueryResponse)
async def query_endpoint(
    request: QueryRequest,
    rag_service = Depends(get_rag_service)
):
    """RAGã‚¯ã‚¨ãƒªã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    try:
        import time
        start = time.time()

        # æ¤œç´¢ã¨ç”Ÿæˆã‚’ä¸¦è¡Œå®Ÿè¡Œ
        answer, sources = await rag_service.query(
            query=request.query,
            top_k=request.top_k,
            filters=request.filters
        )

        processing_time = time.time() - start

        return QueryResponse(
            answer=answer,
            sources=sources,
            processing_time=processing_time
        )

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

class IndexRequest(BaseModel):
    documents: List[dict]
    collection_name: str

@app.post("/index")
async def index_endpoint(
    request: IndexRequest,
    rag_service = Depends(get_rag_service)
):
    """ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ"""
    try:
        result = await rag_service.index_documents(
            documents=request.documents,
            collection_name=request.collection_name
        )
        return {"status": "success", "indexed": result}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/health")
async def health_check():
    """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"""
    return {"status": "healthy"}

# RAGã‚µãƒ¼ãƒ“ã‚¹å®Ÿè£…ï¼ˆservices/rag_service.pyï¼‰
class RAGService:
    """RAGãƒ“ã‚¸ãƒã‚¹ãƒ­ã‚¸ãƒƒã‚¯"""

    def __init__(self):
        self.vectorstore = self._init_vectorstore()
        self.llm = self._init_llm()
        self.embeddings = self._init_embeddings()

    def _init_vectorstore(self):
        # ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢åˆæœŸåŒ–
        pass

    def _init_llm(self):
        # LLMåˆæœŸåŒ–
        pass

    def _init_embeddings(self):
        # ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–
        pass

    async def query(self, query: str, top_k: int = 5, filters: dict = None):
        """éåŒæœŸã‚¯ã‚¨ãƒªå‡¦ç†"""
        # æ¤œç´¢
        search_results = await self._search(query, top_k, filters)

        # ç”Ÿæˆ
        answer = await self._generate(query, search_results)

        return answer, search_results

    async def _search(self, query: str, top_k: int, filters: dict):
        """éåŒæœŸæ¤œç´¢"""
        # å®Ÿè£…
        pass

    async def _generate(self, query: str, context: list):
        """éåŒæœŸç”Ÿæˆ"""
        # å®Ÿè£…
        pass

    async def index_documents(self, documents: list, collection_name: str):
        """éåŒæœŸã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ"""
        # å®Ÿè£…
        pass

# å®Ÿè¡Œ
if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)</code></pre>

        <h2>2. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–</h2>

        <h3>2.1 ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°æˆ¦ç•¥</h3>
        <p>é »ç¹ãªã‚¯ã‚¨ãƒªã«å¯¾ã—ã¦ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’æ´»ç”¨ã—ã€ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“ã‚’çŸ­ç¸®ã—ã¾ã™ã€‚</p>

        <h4>å®Ÿè£…ä¾‹2: ãƒãƒ«ãƒãƒ¬ãƒ™ãƒ«ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°</h4>
        <pre><code>import redis
from functools import lru_cache
import hashlib
import json
import time

class MultiLevelCache:
    """ãƒãƒ«ãƒãƒ¬ãƒ™ãƒ«ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ """

    def __init__(self, redis_url: str = "redis://localhost:6379"):
        # L1: ãƒ¡ãƒ¢ãƒªã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼ˆLRUï¼‰
        self.memory_cache_size = 100

        # L2: Redis
        self.redis_client = redis.from_url(redis_url)

        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥çµ±è¨ˆ
        self.stats = {
            'hits': 0,
            'misses': 0,
            'l1_hits': 0,
            'l2_hits': 0
        }

    def _generate_key(self, query: str, params: dict) -> str:
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼ç”Ÿæˆ"""
        cache_input = f"{query}:{json.dumps(params, sort_keys=True)}"
        return hashlib.md5(cache_input.encode()).hexdigest()

    @lru_cache(maxsize=100)
    def _l1_get(self, key: str):
        """L1ã‚­ãƒ£ãƒƒã‚·ãƒ¥å–å¾—ï¼ˆãƒ¡ãƒ¢ãƒªï¼‰"""
        # LRUãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ã§è‡ªå‹•ç®¡ç†
        return None

    def get(self, query: str, params: dict):
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥å–å¾—ï¼ˆL1 â†’ L2ï¼‰"""
        key = self._generate_key(query, params)

        # L1ãƒã‚§ãƒƒã‚¯
        try:
            result = self._l1_get(key)
            if result:
                self.stats['hits'] += 1
                self.stats['l1_hits'] += 1
                return result
        except:
            pass

        # L2ãƒã‚§ãƒƒã‚¯ï¼ˆRedisï¼‰
        try:
            cached = self.redis_client.get(key)
            if cached:
                result = json.loads(cached)

                # L1ã«ãƒ—ãƒ­ãƒ¢ãƒ¼ãƒˆ
                self._l1_set(key, result)

                self.stats['hits'] += 1
                self.stats['l2_hits'] += 1
                return result
        except Exception as e:
            print(f"Redis error: {e}")

        self.stats['misses'] += 1
        return None

    def _l1_set(self, key: str, value):
        """L1ã‚­ãƒ£ãƒƒã‚·ãƒ¥è¨­å®š"""
        # LRUã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«è¨­å®š
        self._l1_get.__wrapped__(self, key)  # ãƒˆãƒªã‚¬ãƒ¼
        self._l1_get.cache_info()

    def set(self, query: str, params: dict, value, ttl: int = 3600):
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥è¨­å®šï¼ˆL1 & L2ï¼‰"""
        key = self._generate_key(query, params)

        # L1è¨­å®š
        self._l1_set(key, value)

        # L2è¨­å®šï¼ˆRedisï¼‰
        try:
            self.redis_client.setex(
                key,
                ttl,
                json.dumps(value)
            )
        except Exception as e:
            print(f"Redis set error: {e}")

    def invalidate(self, pattern: str = "*"):
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç„¡åŠ¹åŒ–"""
        # L1ã‚¯ãƒªã‚¢
        self._l1_get.cache_clear()

        # L2ã‚¯ãƒªã‚¢ï¼ˆãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒï¼‰
        try:
            keys = self.redis_client.keys(pattern)
            if keys:
                self.redis_client.delete(*keys)
        except Exception as e:
            print(f"Redis invalidate error: {e}")

    def get_stats(self):
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥çµ±è¨ˆ"""
        total = self.stats['hits'] + self.stats['misses']
        hit_rate = self.stats['hits'] / total if total > 0 else 0

        return {
            **self.stats,
            'hit_rate': hit_rate,
            'total_requests': total
        }

# RAGã‚·ã‚¹ãƒ†ãƒ ã¨ã®çµ±åˆ
class CachedRAGService:
    """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä»˜ãRAGã‚µãƒ¼ãƒ“ã‚¹"""

    def __init__(self):
        self.cache = MultiLevelCache()
        self.rag_service = RAGService()

    async def query(self, query: str, top_k: int = 5):
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥è€ƒæ…®ã‚¯ã‚¨ãƒª"""
        params = {'top_k': top_k}

        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯
        cached_result = self.cache.get(query, params)
        if cached_result:
            print("Cache hit!")
            return cached_result

        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒŸã‚¹: å®Ÿè¡Œ
        print("Cache miss, executing query...")
        result = await self.rag_service.query(query, top_k)

        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜ï¼ˆ1æ™‚é–“TTLï¼‰
        self.cache.set(query, params, result, ttl=3600)

        return result

    def get_cache_stats(self):
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥çµ±è¨ˆå–å¾—"""
        return self.cache.get_stats()

# ä½¿ç”¨ä¾‹
cached_rag = CachedRAGService()

# åˆå›ã‚¯ã‚¨ãƒªï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒŸã‚¹ï¼‰
result1 = await cached_rag.query("æ©Ÿæ¢°å­¦ç¿’ã¨ã¯")

# åŒã˜ã‚¯ã‚¨ãƒªï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆï¼‰
result2 = await cached_rag.query("æ©Ÿæ¢°å­¦ç¿’ã¨ã¯")

# çµ±è¨ˆè¡¨ç¤º
stats = cached_rag.get_cache_stats()
print(f"ãƒ’ãƒƒãƒˆç‡: {stats['hit_rate']:.2%}")</code></pre>

        <h3>2.2 ãƒãƒƒãƒå‡¦ç†æœ€é©åŒ–</h3>
        <p>è¤‡æ•°ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå‡¦ç†ã‚’åŠ¹ç‡åŒ–ã™ã‚‹ãƒãƒƒãƒå‡¦ç†ã‚’å®Ÿè£…ã—ã¾ã™ã€‚</p>

        <h4>å®Ÿè£…ä¾‹3: ãƒãƒƒãƒã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ</h4>
        <pre><code>import asyncio
from typing import List
from concurrent.futures import ThreadPoolExecutor
import numpy as np

class BatchIndexer:
    """ãƒãƒƒãƒã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆã‚·ã‚¹ãƒ†ãƒ """

    def __init__(self, embeddings, vectorstore, batch_size=50, max_workers=4):
        self.embeddings = embeddings
        self.vectorstore = vectorstore
        self.batch_size = batch_size
        self.max_workers = max_workers

    def create_batches(self, documents: List, batch_size: int):
        """ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ãƒãƒƒãƒã«åˆ†å‰²"""
        for i in range(0, len(documents), batch_size):
            yield documents[i:i + batch_size]

    async def process_batch_async(self, batch: List):
        """ãƒãƒƒãƒéåŒæœŸå‡¦ç†"""
        # ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ç”Ÿæˆï¼ˆä¸¦è¡Œï¼‰
        texts = [doc.page_content for doc in batch]

        # ãƒãƒƒãƒã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°å–å¾—
        embeddings = await asyncio.to_thread(
            self.embeddings.embed_documents,
            texts
        )

        # ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã«è¿½åŠ 
        await asyncio.to_thread(
            self.vectorstore.add_documents,
            batch
        )

        return len(batch)

    async def index_documents_parallel(self, documents: List):
        """ä¸¦åˆ—ãƒãƒƒãƒã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ"""
        batches = list(self.create_batches(documents, self.batch_size))

        print(f"å‡¦ç†é–‹å§‹: {len(documents)}ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ, {len(batches)}ãƒãƒƒãƒ")

        # ä¸¦åˆ—å‡¦ç†
        tasks = [
            self.process_batch_async(batch)
            for batch in batches
        ]

        # ã‚»ãƒãƒ•ã‚©ã§åŒæ™‚å®Ÿè¡Œæ•°åˆ¶é™
        semaphore = asyncio.Semaphore(self.max_workers)

        async def limited_task(task):
            async with semaphore:
                return await task

        results = await asyncio.gather(
            *[limited_task(task) for task in tasks]
        )

        total_indexed = sum(results)
        print(f"ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å®Œäº†: {total_indexed}ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ")

        return total_indexed

    def index_with_progress(self, documents: List):
        """ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ä»˜ãã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ"""
        from tqdm import tqdm

        batches = list(self.create_batches(documents, self.batch_size))

        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            futures = []

            for batch in batches:
                future = executor.submit(self._process_batch_sync, batch)
                futures.append(future)

            # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹è¡¨ç¤º
            with tqdm(total=len(documents), desc="ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ") as pbar:
                for future in futures:
                    count = future.result()
                    pbar.update(count)

        print("ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆå®Œäº†")

    def _process_batch_sync(self, batch: List):
        """åŒæœŸãƒãƒƒãƒå‡¦ç†"""
        texts = [doc.page_content for doc in batch]
        self.embeddings.embed_documents(texts)
        self.vectorstore.add_documents(batch)
        return len(batch)

# ä½¿ç”¨ä¾‹
batch_indexer = BatchIndexer(
    embeddings=embeddings,
    vectorstore=vectorstore,
    batch_size=50,
    max_workers=4
)

# å¤§é‡ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
large_documents = [...]  # 10000ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ

# éåŒæœŸä¸¦åˆ—å‡¦ç†
await batch_indexer.index_documents_parallel(large_documents)

# ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ä»˜ãå‡¦ç†
batch_indexer.index_with_progress(large_documents)</code></pre>

        <h2>3. ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ã¨è©•ä¾¡</h2>

        <h3>3.1 ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨­è¨ˆ</h3>
        <p>RAGã‚·ã‚¹ãƒ†ãƒ ã®å“è³ªã¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’æ¸¬å®šã™ã‚‹ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’å®šç¾©ã—ã¾ã™ã€‚</p>

        <div class="example-box">
            <strong>ä¸»è¦ãƒ¡ãƒˆãƒªã‚¯ã‚¹:</strong>
            <ul>
                <li><strong>ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·</strong>: æ¤œç´¢æ™‚é–“ã€ç”Ÿæˆæ™‚é–“ã€ç·å‡¦ç†æ™‚é–“</li>
                <li><strong>ç²¾åº¦</strong>: æ¤œç´¢ç²¾åº¦ã€å›ç­”ã®æ­£ç¢ºæ€§</li>
                <li><strong>é–¢é€£æ€§</strong>: æ¤œç´¢çµæœã¨ã‚¯ã‚¨ãƒªã®é–¢é€£åº¦</li>
                <li><strong>ã‚³ã‚¹ãƒˆ</strong>: APIã‚³ãƒ¼ãƒ«æ•°ã€ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡</li>
            </ul>
        </div>

        <h4>å®Ÿè£…ä¾‹4: ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†ã‚·ã‚¹ãƒ†ãƒ </h4>
        <pre><code>from prometheus_client import Counter, Histogram, Gauge
import time
from functools import wraps

# Prometheusãƒ¡ãƒˆãƒªã‚¯ã‚¹å®šç¾©
query_counter = Counter(
    'rag_queries_total',
    'Total number of RAG queries',
    ['status']
)

query_latency = Histogram(
    'rag_query_duration_seconds',
    'RAG query duration',
    ['component']
)

search_results_count = Gauge(
    'rag_search_results',
    'Number of search results returned'
)

llm_tokens = Counter(
    'rag_llm_tokens_total',
    'Total LLM tokens used',
    ['type']  # prompt or completion
)

class RAGMetrics:
    """RAGãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†"""

    def __init__(self):
        self.metrics_data = []

    def track_query(self, func):
        """ã‚¯ã‚¨ãƒªå‡¦ç†ãƒ¡ãƒˆãƒªã‚¯ã‚¹"""
        @wraps(func)
        async def wrapper(*args, **kwargs):
            start = time.time()

            try:
                result = await func(*args, **kwargs)
                query_counter.labels(status='success').inc()

                # ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·è¨˜éŒ²
                duration = time.time() - start
                query_latency.labels(component='total').observe(duration)

                # çµæœæ•°è¨˜éŒ²
                if hasattr(result, 'sources'):
                    search_results_count.set(len(result.sources))

                return result

            except Exception as e:
                query_counter.labels(status='error').inc()
                raise

        return wrapper

    def track_search(self, func):
        """æ¤œç´¢ãƒ¡ãƒˆãƒªã‚¯ã‚¹"""
        @wraps(func)
        async def wrapper(*args, **kwargs):
            start = time.time()

            result = await func(*args, **kwargs)

            duration = time.time() - start
            query_latency.labels(component='search').observe(duration)

            return result

        return wrapper

    def track_generation(self, func):
        """ç”Ÿæˆãƒ¡ãƒˆãƒªã‚¯ã‚¹"""
        @wraps(func)
        async def wrapper(*args, **kwargs):
            start = time.time()

            result = await func(*args, **kwargs)

            duration = time.time() - start
            query_latency.labels(component='generation').observe(duration)

            # ãƒˆãƒ¼ã‚¯ãƒ³æ•°è¨˜éŒ²
            if hasattr(result, 'usage'):
                llm_tokens.labels(type='prompt').inc(result.usage.prompt_tokens)
                llm_tokens.labels(type='completion').inc(result.usage.completion_tokens)

            return result

        return wrapper

class RAGEvaluator:
    """RAGå“è³ªè©•ä¾¡"""

    def __init__(self, llm):
        self.llm = llm

    def evaluate_retrieval(self, query: str, retrieved_docs: list, relevant_docs: list):
        """æ¤œç´¢ç²¾åº¦è©•ä¾¡"""
        # Precision@K
        retrieved_ids = {doc.metadata.get('id') for doc in retrieved_docs}
        relevant_ids = {doc.metadata.get('id') for doc in relevant_docs}

        hits = retrieved_ids.intersection(relevant_ids)

        precision = len(hits) / len(retrieved_ids) if retrieved_ids else 0
        recall = len(hits) / len(relevant_ids) if relevant_ids else 0

        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0

        return {
            'precision': precision,
            'recall': recall,
            'f1_score': f1
        }

    async def evaluate_answer_quality(self, query: str, answer: str, ground_truth: str):
        """å›ç­”å“è³ªè©•ä¾¡ï¼ˆLLMãƒ™ãƒ¼ã‚¹ï¼‰"""
        prompt = f"""ä»¥ä¸‹ã®è³ªå•ã€å›ç­”ã€æ­£è§£ã‚’è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚
        1-5ã®ã‚¹ã‚³ã‚¢ã§è©•ä¾¡ï¼ˆ5ãŒæœ€é«˜ï¼‰ã—ã€ç†ç”±ã‚‚è¿°ã¹ã¦ãã ã•ã„ã€‚

        è³ªå•: {query}
        å›ç­”: {answer}
        æ­£è§£: {ground_truth}

        è©•ä¾¡ï¼ˆJSONå½¢å¼ï¼‰:
        {{
            "accuracy_score": <1-5>,
            "relevance_score": <1-5>,
            "completeness_score": <1-5>,
            "reasoning": "<ç†ç”±>"
        }}
        """

        response = await self.llm(prompt)

        # JSONãƒ‘ãƒ¼ã‚¹
        import json
        evaluation = json.loads(response.content)

        return evaluation

    def calculate_mrr(self, queries: list, results: list):
        """MRRï¼ˆMean Reciprocal Rankï¼‰è¨ˆç®—"""
        reciprocal_ranks = []

        for query_results in results:
            for rank, doc in enumerate(query_results, 1):
                if doc.metadata.get('is_relevant'):
                    reciprocal_ranks.append(1 / rank)
                    break
            else:
                reciprocal_ranks.append(0)

        mrr = sum(reciprocal_ranks) / len(reciprocal_ranks) if reciprocal_ranks else 0

        return mrr

# ä½¿ç”¨ä¾‹
metrics = RAGMetrics()
evaluator = RAGEvaluator(llm)

# ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿é©ç”¨
class MonitoredRAGService:
    def __init__(self):
        self.metrics = RAGMetrics()

    @metrics.track_query
    async def query(self, query: str):
        # ã‚¯ã‚¨ãƒªå‡¦ç†
        search_results = await self.search(query)
        answer = await self.generate(query, search_results)
        return answer

    @metrics.track_search
    async def search(self, query: str):
        # æ¤œç´¢å‡¦ç†
        pass

    @metrics.track_generation
    async def generate(self, query: str, context: list):
        # ç”Ÿæˆå‡¦ç†
        pass

# è©•ä¾¡å®Ÿè¡Œ
evaluation = await evaluator.evaluate_answer_quality(
    query="æ©Ÿæ¢°å­¦ç¿’ã¨ã¯",
    answer="ç”Ÿæˆã•ã‚ŒãŸå›ç­”",
    ground_truth="æ­£è§£ã®å›ç­”"
)

print(f"ç²¾åº¦ã‚¹ã‚³ã‚¢: {evaluation['accuracy_score']}/5")</code></pre>

        <h3>3.2 A/Bãƒ†ã‚¹ãƒˆå®Ÿè£…</h3>
        <p>ç•°ãªã‚‹RAGè¨­å®šã®åŠ¹æœã‚’æ¯”è¼ƒã™ã‚‹A/Bãƒ†ã‚¹ãƒˆã‚’å®Ÿæ–½ã—ã¾ã™ã€‚</p>

        <h4>å®Ÿè£…ä¾‹5: A/Bãƒ†ã‚¹ãƒˆãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯</h4>
        <pre><code>import random
from typing import Dict, Any
from dataclasses import dataclass
from collections import defaultdict

@dataclass
class ExperimentVariant:
    """å®Ÿé¨“ãƒãƒªã‚¢ãƒ³ãƒˆ"""
    name: str
    config: Dict[str, Any]
    traffic_ratio: float  # 0.0-1.0

class ABTestManager:
    """A/Bãƒ†ã‚¹ãƒˆç®¡ç†"""

    def __init__(self):
        self.experiments = {}
        self.results = defaultdict(lambda: defaultdict(list))

    def create_experiment(self, experiment_name: str, variants: list):
        """å®Ÿé¨“ä½œæˆ"""
        # ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯æ¯”ç‡ã®åˆè¨ˆãƒã‚§ãƒƒã‚¯
        total_ratio = sum(v.traffic_ratio for v in variants)
        if abs(total_ratio - 1.0) > 0.001:
            raise ValueError("ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯æ¯”ç‡ã®åˆè¨ˆã¯1.0ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™")

        self.experiments[experiment_name] = variants
        print(f"å®Ÿé¨“ä½œæˆ: {experiment_name}")

    def assign_variant(self, experiment_name: str, user_id: str):
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ãƒãƒªã‚¢ãƒ³ãƒˆå‰²ã‚Šå½“ã¦"""
        if experiment_name not in self.experiments:
            raise ValueError(f"å®Ÿé¨“ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {experiment_name}")

        # æ±ºå®šçš„å‰²ã‚Šå½“ã¦ï¼ˆåŒã˜ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã¯åŒã˜ãƒãƒªã‚¢ãƒ³ãƒˆï¼‰
        hash_val = hash(f"{experiment_name}:{user_id}") % 1000 / 1000

        cumulative_ratio = 0
        for variant in self.experiments[experiment_name]:
            cumulative_ratio += variant.traffic_ratio
            if hash_val < cumulative_ratio:
                return variant

        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        return self.experiments[experiment_name][0]

    def record_result(self, experiment_name: str, variant_name: str,
                     metric_name: str, value: float):
        """çµæœè¨˜éŒ²"""
        self.results[experiment_name][variant_name].append({
            'metric': metric_name,
            'value': value
        })

    def analyze_results(self, experiment_name: str, metric_name: str):
        """çµæœåˆ†æ"""
        if experiment_name not in self.results:
            return None

        analysis = {}

        for variant_name, results in self.results[experiment_name].items():
            metric_values = [
                r['value'] for r in results
                if r['metric'] == metric_name
            ]

            if metric_values:
                analysis[variant_name] = {
                    'mean': np.mean(metric_values),
                    'std': np.std(metric_values),
                    'count': len(metric_values),
                    'min': min(metric_values),
                    'max': max(metric_values)
                }

        return analysis

# RAGã‚·ã‚¹ãƒ†ãƒ ã§ã®ä½¿ç”¨
class ABTestedRAGService:
    """A/Bãƒ†ã‚¹ãƒˆå¯¾å¿œRAGã‚µãƒ¼ãƒ“ã‚¹"""

    def __init__(self):
        self.ab_test = ABTestManager()
        self._setup_experiments()

    def _setup_experiments(self):
        """å®Ÿé¨“ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
        # ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°æˆ¦ç•¥ãƒ†ã‚¹ãƒˆ
        chunking_variants = [
            ExperimentVariant(
                name="fixed_500",
                config={"chunk_size": 500, "overlap": 50},
                traffic_ratio=0.5
            ),
            ExperimentVariant(
                name="fixed_1000",
                config={"chunk_size": 1000, "overlap": 100},
                traffic_ratio=0.5
            )
        ]
        self.ab_test.create_experiment("chunking_strategy", chunking_variants)

        # ãƒªãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒ†ã‚¹ãƒˆ
        rerank_variants = [
            ExperimentVariant(
                name="no_rerank",
                config={"use_reranking": False},
                traffic_ratio=0.33
            ),
            ExperimentVariant(
                name="cross_encoder",
                config={"use_reranking": True, "method": "cross_encoder"},
                traffic_ratio=0.33
            ),
            ExperimentVariant(
                name="mmr",
                config={"use_reranking": True, "method": "mmr"},
                traffic_ratio=0.34
            )
        ]
        self.ab_test.create_experiment("reranking_method", rerank_variants)

    async def query(self, query: str, user_id: str):
        """ãƒãƒªã‚¢ãƒ³ãƒˆé©ç”¨ã‚¯ã‚¨ãƒª"""
        # ãƒãƒªã‚¢ãƒ³ãƒˆå‰²ã‚Šå½“ã¦
        chunking_variant = self.ab_test.assign_variant("chunking_strategy", user_id)
        rerank_variant = self.ab_test.assign_variant("reranking_method", user_id)

        print(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼{user_id}:")
        print(f"  ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°: {chunking_variant.name}")
        print(f"  ãƒªãƒ©ãƒ³ã‚­ãƒ³ã‚°: {rerank_variant.name}")

        # è¨­å®šé©ç”¨
        start = time.time()

        # ã‚¯ã‚¨ãƒªå®Ÿè¡Œï¼ˆè¨­å®šã«åŸºã¥ãï¼‰
        result = await self._execute_query(
            query,
            chunking_variant.config,
            rerank_variant.config
        )

        latency = time.time() - start

        # çµæœè¨˜éŒ²
        self.ab_test.record_result(
            "chunking_strategy",
            chunking_variant.name,
            "latency",
            latency
        )

        self.ab_test.record_result(
            "reranking_method",
            rerank_variant.name,
            "latency",
            latency
        )

        return result

    async def _execute_query(self, query: str, chunking_config: dict,
                           rerank_config: dict):
        """è¨­å®šã‚’é©ç”¨ã—ãŸã‚¯ã‚¨ãƒªå®Ÿè¡Œ"""
        # å®Ÿè£…
        pass

    def get_experiment_results(self):
        """å®Ÿé¨“çµæœå–å¾—"""
        chunking_results = self.ab_test.analyze_results(
            "chunking_strategy", "latency"
        )

        rerank_results = self.ab_test.analyze_results(
            "reranking_method", "latency"
        )

        return {
            'chunking': chunking_results,
            'reranking': rerank_results
        }

# ä½¿ç”¨ä¾‹
ab_rag = ABTestedRAGService()

# ãƒ†ã‚¹ãƒˆã‚¯ã‚¨ãƒªå®Ÿè¡Œ
for user_id in range(100):
    await ab_rag.query("æ©Ÿæ¢°å­¦ç¿’ã®è©•ä¾¡æŒ‡æ¨™", f"user_{user_id}")

# çµæœåˆ†æ
results = ab_rag.get_experiment_results()
print("\nãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°æˆ¦ç•¥æ¯”è¼ƒ:")
for variant, stats in results['chunking'].items():
    print(f"{variant}: å¹³å‡ {stats['mean']:.3f}ç§’ (n={stats['count']})")</code></pre>

        <h2>4. ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã¨ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£</h2>

        <h3>4.1 åˆ†æ•£å‡¦ç†ã¨ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚·ãƒ³ã‚°</h3>
        <p>å¤§è¦æ¨¡ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã«å¯¾å¿œã™ã‚‹åˆ†æ•£ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’æ§‹ç¯‰ã—ã¾ã™ã€‚</p>

        <h4>å®Ÿè£…ä¾‹6: Celeryãƒ™ãƒ¼ã‚¹éåŒæœŸå‡¦ç†</h4>
        <pre><code>from celery import Celery
from kombu import Queue
import os

# Celeryè¨­å®š
celery_app = Celery(
    'rag_tasks',
    broker=os.getenv('REDIS_URL', 'redis://localhost:6379/0'),
    backend=os.getenv('REDIS_URL', 'redis://localhost:6379/0')
)

celery_app.conf.update(
    task_serializer='json',
    accept_content=['json'],
    result_serializer='json',
    timezone='Asia/Tokyo',
    enable_utc=True,
    task_routes={
        'rag_tasks.index_document': {'queue': 'indexing'},
        'rag_tasks.generate_embedding': {'queue': 'embedding'},
        'rag_tasks.query_rag': {'queue': 'query'}
    }
)

# ã‚¿ã‚¹ã‚¯å®šç¾©
@celery_app.task(name='rag_tasks.index_document')
def index_document_task(document_data: dict):
    """ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆã‚¿ã‚¹ã‚¯"""
    from services.indexer import DocumentIndexer

    indexer = DocumentIndexer()
    result = indexer.index(document_data)

    return {
        'status': 'completed',
        'document_id': document_data.get('id'),
        'indexed_chunks': result['chunks']
    }

@celery_app.task(name='rag_tasks.generate_embedding')
def generate_embedding_task(text: str):
    """ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ç”Ÿæˆã‚¿ã‚¹ã‚¯"""
    from services.embeddings import EmbeddingService

    embedding_service = EmbeddingService()
    embedding = embedding_service.generate(text)

    return embedding.tolist()

@celery_app.task(name='rag_tasks.query_rag', bind=True)
def query_rag_task(self, query: str, user_id: str):
    """RAGã‚¯ã‚¨ãƒªã‚¿ã‚¹ã‚¯ï¼ˆãƒªãƒˆãƒ©ã‚¤ä»˜ãï¼‰"""
    try:
        from services.rag_service import RAGService

        rag = RAGService()
        result = rag.query_sync(query)

        return {
            'status': 'success',
            'answer': result['answer'],
            'sources': result['sources']
        }

    except Exception as e:
        # ãƒªãƒˆãƒ©ã‚¤ï¼ˆæœ€å¤§3å›ã€æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•ï¼‰
        raise self.retry(exc=e, countdown=2 ** self.request.retries, max_retries=3)

# FastAPIçµ±åˆ
from fastapi import BackgroundTasks

@app.post("/query_async")
async def query_async(request: QueryRequest, background_tasks: BackgroundTasks):
    """éåŒæœŸã‚¯ã‚¨ãƒª"""
    # Celeryã‚¿ã‚¹ã‚¯å®Ÿè¡Œ
    task = query_rag_task.delay(request.query, "user_123")

    return {
        'task_id': task.id,
        'status': 'processing'
    }

@app.get("/task_status/{task_id}")
async def get_task_status(task_id: str):
    """ã‚¿ã‚¹ã‚¯çŠ¶æ…‹ç¢ºèª"""
    task = celery_app.AsyncResult(task_id)

    if task.ready():
        return {
            'status': 'completed',
            'result': task.result
        }
    else:
        return {
            'status': 'processing'
        }

# ãƒãƒƒãƒã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ
@app.post("/batch_index")
async def batch_index(documents: List[dict]):
    """ãƒãƒƒãƒã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ"""
    # ä¸¦åˆ—ã‚¿ã‚¹ã‚¯å®Ÿè¡Œ
    tasks = [
        index_document_task.delay(doc)
        for doc in documents
    ]

    return {
        'status': 'processing',
        'task_count': len(tasks),
        'task_ids': [task.id for task in tasks]
    }

# Celeryãƒ¯ãƒ¼ã‚«ãƒ¼èµ·å‹•ã‚³ãƒãƒ³ãƒ‰
# celery -A tasks.celery_app worker --loglevel=info --queues=indexing,embedding,query</code></pre>

        <div class="note-box">
            <strong>ãƒ—ãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³é‹ç”¨ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹:</strong>
            <ul>
                <li><strong>ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°</strong>: Prometheus + Grafanaã§å¯è¦–åŒ–</li>
                <li><strong>ãƒ­ã‚°ç®¡ç†</strong>: æ§‹é€ åŒ–ãƒ­ã‚°ï¼ˆJSONï¼‰ã¨Elasticsearchçµ±åˆ</li>
                <li><strong>ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£</strong>: APIã‚­ãƒ¼èªè¨¼ã€ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã€å…¥åŠ›æ¤œè¨¼</li>
                <li><strong>CI/CD</strong>: è‡ªå‹•ãƒ†ã‚¹ãƒˆã€æ®µéšçš„ãƒ‡ãƒ—ãƒ­ã‚¤</li>
                <li><strong>ç½å®³å¾©æ—§</strong>: ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã€ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³</li>
            </ul>
        </div>

        <h2>ã¾ã¨ã‚</h2>
        <ul>
            <li>ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§å„ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’åˆ†é›¢</li>
            <li>å¤šå±¤ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ã¨ãƒãƒƒãƒå‡¦ç†ã§ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–</li>
            <li>åŒ…æ‹¬çš„ãªãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†ã¨A/Bãƒ†ã‚¹ãƒˆã§ç¶™ç¶šçš„æ”¹å–„</li>
            <li>Celeryã«ã‚ˆã‚‹éåŒæœŸå‡¦ç†ã§å¤§è¦æ¨¡ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã«å¯¾å¿œ</li>
            <li>ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã¨ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã‚’è€ƒæ…®ã—ãŸæœ¬ç•ªé‹ç”¨è¨­è¨ˆ</li>
        </ul>

        <div class="nav-buttons">
            <a href="./chapter3-advanced-rag.html" class="nav-button">â† ç¬¬3ç« </a>
            <a href="./index.html" class="nav-button">ã‚·ãƒªãƒ¼ã‚ºç›®æ¬¡ã¸</a>
        </div>
    </main>


        <div class="feedback-notice">
            <h3>âš ï¸ ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å“è³ªå‘ä¸Šã«ã”å”åŠ›ãã ã•ã„</h3>
            <p>ã“ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯AIã‚’æ´»ç”¨ã—ã¦ä½œæˆã•ã‚Œã¦ã„ã¾ã™ã€‚èª¤ã‚Šã‚„æ”¹å–„ç‚¹ã‚’è¦‹ã¤ã‘ã‚‰ã‚ŒãŸå ´åˆã¯ã€ä»¥ä¸‹ã®æ–¹æ³•ã§ã”å ±å‘Šãã ã•ã„ï¼š</p>
            <div class="feedback-options">
                <a href="https://forms.gle/9GfVBa2Qa7Uy9taQA" target="_blank" class="feedback-button">
                    ğŸ“ ä¿®æ­£ä¾é ¼ãƒ•ã‚©ãƒ¼ãƒ 
                </a>
                <a href="mailto:yusuke.hashimoto.d8@tohoku.ac.jp" class="feedback-button">
                    âœ‰ï¸ ãƒ¡ãƒ¼ãƒ«ã§é€£çµ¡
                </a>
            </div>
        </div>

    <footer>
        <div class="container">
            <p>&copy; 2025 AI Terakoya - Dr. Yusuke Hashimoto, Tohoku University</p>
            <p>Licensed under CC BY 4.0</p>
        </div>
    </footer>
</body>
</html>
