<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>Chapter 4: Python Practice: Electromagnetic Data Analysis Workflow - MS Terakoya</title>
<link href="../../assets/css/knowledge-base.css" rel="stylesheet"/>
<!-- Prism.js for syntax highlighting -->
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css" rel="stylesheet"/>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
<script>
        mermaid.initialize({ startOnLoad: true, theme: 'default', securityLevel: 'strict' });
    </script>
<script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                displayMath: [['$$', '$$'], ['\\[', '\\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
                ignoreHtmlClass: 'mermaid'
            }
        };
    </script>
<script async="" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body><div class="locale-switcher">
<span class="current-locale">ğŸŒ EN</span>
<span class="locale-separator">|</span>
<span class="locale-meta">Last sync: 2025-11-16</span>
</div>
<header>
<div class="header-content">
<h1>Chapter 4: Pythonå®Ÿè·µï¼šé›»ç£æ°—ãƒ‡ãƒ¼ã‚¿è§£æãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼</h1>
<p class="subtitle">Integrated pipeline for data loading, preprocessing, fitting, visualization, and automated report generation</p>
<div class="meta">
<span class="meta-item">ğŸ“– Reading time: 55-65 minutes</span>
<span class="meta-item">ğŸ“Š Difficulty: Intermediate to Advanced</span>
<span class="meta-item">ğŸ’» Code examples: 7</span>
</div>
</div>
</header>
<div class="breadcrumb">
<a href="../index.html">AI Terakoya Top</a> &gt;
        <a href="../index.html">MS Dojo</a> &gt;
        <a href="index.html">Introduction to Electrical &amp; Magnetic Testing</a> &gt;
        Chapter 4
    </div>
<main class="container">
<p class="chapter-description" style="margin: 1.5rem 0; padding: 1rem; background: linear-gradient(135deg, #fce7f3 0%, #fbcfe8 100%); border-left: 4px solid #f093fb; border-radius: 8px; font-size: 1.05rem; line-height: 1.8; color: #2d3748;">
            ã“ã®ç« ã§ã¯ã€å®Ÿéš›ã®æ¸¬å®šInstrumentï¼ˆVSMã€SQUIDã€Hallæ¸¬å®šã‚·ã‚¹ãƒ†ãƒ ï¼‰ã‹ã‚‰å¾—ã‚‰ã‚Œã‚‹ãƒ‡ãƒ¼ã‚¿ã‚’æ‰±ã†å®Ÿè·µçš„ãªPythonãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’ç¿’å¾—ã—ã¾ã™ã€‚CSVã‚„ãƒã‚¤ãƒŠãƒªãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã€ç•°å¸¸å€¤é™¤å»ã€ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰æ¸›ç®—ã€Advanced Fitting Techniquesï¼ˆlmfitã€scipy.optimizeï¼‰ã€èª¤å·®ä¼æ’­ã€æ©Ÿæ¢°å­¦ç¿’ã‚’ç”¨ã„ãŸç•°å¸¸æ¤œå‡ºã€publication-qualityã®å›³ã®ä½œæˆã€Automated Report Generationã¾ã§ã®çµ±åˆçš„ãªãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’æ§‹ç¯‰ã—ã¾ã™ã€‚
        </p>
<div class="learning-objectives">
<h2>Learning Objectives</h2>
<p>By completing this chapter, you will be able to:</p>
<ul>
<li>âœ… Load and preprocess real instrument data (CSV, DAT, binary)</li>
<li>âœ… Automate outlier detection and data cleaning</li>
<li>âœ… Perform integrated analysis of four-probe, Hall, and M-H measurements</li>
<li>âœ… Conduct advanced fitting with lmfit and scipy.optimize</li>
<li>âœ… Calculate error propagation correctly</li>
<li>âœ… Automatically generate publication-quality figures</li>
<li>âœ… Automatically generate PDF reports</li>
</ul>
</div>
<h2>4.1 Data Loading and Cleaning</h2>
<h3>4.1.1 Multi-Format Data Loader</h3>
<p>Real measurement instruments output data in various formats:</p>
<table>
<thead>
<tr>
<th>Instrument</th>
<th>Format</th>
<th>Header</th>
<th>Delimiter</th>
</tr>
</thead>
<tbody>
<tr>
<td>Quantum Design VSM</td>
<td>.dat</td>
<td>Multi-line comments (#)</td>
<td>Tab or comma</td>
</tr>
<tr>
<td>Keithley 2400 SMU</td>
<td>.csv</td>
<td>1 line or none</td>
<td>Comma</td>
</tr>
<tr>
<td>Lake Shore 7400 VSM</td>
<td>.txt</td>
<td>Fixed format</td>
<td>Space</td>
</tr>
<tr>
<td>ã‚«ã‚¹ã‚¿ãƒ LabVIEW</td>
<td>.bin</td>
<td>ãƒã‚¤ãƒŠãƒªHeader</td>
<td>N/A</td>
</tr>
</tbody>
</table>
<div class="mermaid">
flowchart LR
    A[Raw Data<br/>CSV/DAT/BIN] --&gt; B[Data Loader<br/>pandas/numpy]
    B --&gt; C{Format<br/>Detection}
    C --&gt;|CSV| D[pd.read_csv]
    C --&gt;|DAT| E[Custom Parser]
    C --&gt;|Binary| F[np.fromfile]
    
    D --&gt; G[Data Cleaning]
    E --&gt; G
    F --&gt; G
    
    G --&gt; H[Remove NaN/Inf]
    G --&gt; I[Outlier Detection]
    G --&gt; J[Unit Conversion]
    
    H --&gt; K[Clean Dataset]
    I --&gt; K
    J --&gt; K

    style A fill:#99ccff,stroke:#0066cc,stroke-width:2px
    style K fill:#f093fb,stroke:#f5576c,stroke-width:2px,color:#fff
        </div>
<h4>ã‚³ãƒ¼ãƒ‰ä¾‹4-1: Multi-Format Data Loaderã‚¯ãƒ©ã‚¹</h4>
<pre><code class="language-python"># Requirements:
# - Python 3.9+
# - numpy&gt;=1.24.0, &lt;2.0.0
# - pandas&gt;=2.0.0, &lt;2.2.0

import numpy as np
import pandas as pd
import struct
from pathlib import Path
from typing import Union, Tuple

class UniversalDataLoader:
    """
    Multi-Format Data Loaderï¼ˆCSVã€DATã€ãƒã‚¤ãƒŠãƒªå¯¾å¿œï¼‰
    
    Attributes
    ----------
    data : pd.DataFrame
        èª­ã¿è¾¼ã‚“ã ãƒ‡ãƒ¼ã‚¿
    metadata : dict
        ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ï¼ˆHeaderæƒ…å ±ã€æ¸¬å®šæ¡ä»¶ãªã©ï¼‰
    """

    def __init__(self):
        self.data = None
        self.metadata = {}

    def load(self, filepath: str, format: str = 'auto') -&gt; pd.DataFrame:
        """
        ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
        
        Parameters
        ----------
        filepath : str
            ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        format : str
            'auto'ï¼ˆè‡ªå‹•æ¤œå‡ºï¼‰, 'csv', 'dat', 'binary'
        
        Returns
        -------
        data : pd.DataFrame
            èª­ã¿è¾¼ã‚“ã ãƒ‡ãƒ¼ã‚¿
        """
        path = Path(filepath)
        
        if not path.exists():
            raise FileNotFoundError(f"File not found: {filepath}")

        # Formatã®è‡ªå‹•æ¤œå‡º
        if format == 'auto':
            format = self._detect_format(path)

        # Formatã«å¿œã˜ãŸèª­ã¿è¾¼ã¿
        if format == 'csv':
            self.data = self._load_csv(path)
        elif format == 'dat':
            self.data = self._load_dat(path)
        elif format == 'binary':
            self.data = self._load_binary(path)
        else:
            raise ValueError(f"Unsupported format: {format}")

        print(f"Loaded {len(self.data)} rows from {path.name} (format: {format})")
        return self.data

    def _detect_format(self, path: Path) -&gt; str:
        """ãƒ•ã‚¡ã‚¤ãƒ«æ‹¡å¼µå­ã‹ã‚‰Formatã‚’æ¨å®š"""
        ext = path.suffix.lower()
        if ext in ['.csv', '.txt']:
            return 'csv'
        elif ext == '.dat':
            return 'dat'
        elif ext == '.bin':
            return 'binary'
        else:
            # ä¸­èº«ã‚’è¦‹ã¦åˆ¤å®š
            with open(path, 'rb') as f:
                header = f.read(100)
                if b'\x00' in header:
                    return 'binary'
                else:
                    return 'csv'

    def _load_csv(self, path: Path) -&gt; pd.DataFrame:
        """CSVFormatã®èª­ã¿è¾¼ã¿"""
        # Headerè¡Œæ•°ã®æ¤œå‡º
        header_lines = 0
        with open(path, 'r') as f:
            for i, line in enumerate(f):
                if line.strip().startswith('#'):
                    header_lines += 1
                    self.metadata[f'comment_{i}'] = line.strip()
                else:
                    break

        # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        try:
            data = pd.read_csv(path, skiprows=header_lines, sep=None, engine='python')
        except Exception as e:
            # CommaåŒºåˆ‡ã‚Šä»¥å¤–ã®å ´åˆ
            data = pd.read_csv(path, skiprows=header_lines, delimiter=r'\s+')

        return data

    def _load_dat(self, path: Path) -&gt; pd.DataFrame:
        """DATFormatã®èª­ã¿è¾¼ã¿ï¼ˆQuantum Design VSMæƒ³å®šï¼‰"""
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã¨ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†é›¢
        metadata_lines = []
        data_lines = []
        
        with open(path, 'r') as f:
            in_data_section = False
            for line in f:
                line = line.strip()
                if line.startswith('[Data]'):
                    in_data_section = True
                    continue
                
                if not in_data_section:
                    if line and not line.startswith('#'):
                        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿è¡Œ
                        if '=' in line:
                            key, value = line.split('=', 1)
                            self.metadata[key.strip()] = value.strip()
                else:
                    if line and not line.startswith('#'):
                        data_lines.append(line)

        # ãƒ‡ãƒ¼ã‚¿ã‚’DataFrameã«å¤‰æ›
        if data_lines:
            # ã‚«ãƒ©ãƒ åï¼ˆæœ€åˆã®è¡Œï¼‰
            header = data_lines[0].split('\t')
            
            # ãƒ‡ãƒ¼ã‚¿è¡Œ
            data_values = []
            for line in data_lines[1:]:
                values = line.split('\t')
                data_values.append([float(v) if v else np.nan for v in values])

            data = pd.DataFrame(data_values, columns=header)
        else:
            data = pd.DataFrame()

        return data

    def _load_binary(self, path: Path) -&gt; pd.DataFrame:
        """
        ãƒã‚¤ãƒŠãƒªFormatã®èª­ã¿è¾¼ã¿ï¼ˆã‚«ã‚¹ã‚¿ãƒ ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼‰
        
        ä»®å®šï¼š
        - Headerï¼šæœ€åˆã®100ãƒã‚¤ãƒˆï¼ˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ï¼‰
        - ãƒ‡ãƒ¼ã‚¿ï¼šfloat64é…åˆ—ã€3ã‚«ãƒ©ãƒ ï¼ˆH, M, Tï¼‰
        """
        with open(path, 'rb') as f:
            # Headerèª­ã¿è¾¼ã¿
            header_bytes = f.read(100)
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿è§£æï¼ˆã“ã“ã§ã¯çœç•¥ï¼‰
            
            # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
            remaining = f.read()
            n_cols = 3
            n_rows = len(remaining) // (8 * n_cols)  # float64 = 8 bytes
            
            data_array = np.frombuffer(remaining, dtype=np.float64)
            data_array = data_array.reshape((n_rows, n_cols))
            
            data = pd.DataFrame(data_array, columns=['H', 'M', 'T'])

        return data

    def clean_data(self, remove_nan=True, remove_inf=True, outlier_method='iqr', threshold=3.0):
        """
        ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
        
        Parameters
        ----------
        remove_nan : bool
            NaNã‚’å‰Šé™¤ã™ã‚‹ã‹
        remove_inf : bool
            Infã‚’å‰Šé™¤ã™ã‚‹ã‹
        outlier_method : str
            å¤–ã‚Œå€¤é™¤å»æ³•ï¼ˆ'iqr', 'zscore', 'none'ï¼‰
        threshold : float
            å¤–ã‚Œå€¤åˆ¤å®šã®é–¾å€¤
        """
        if self.data is None:
            raise ValueError("No data loaded. Call load() first.")

        original_len = len(self.data)

        # NaN/Infé™¤å»
        if remove_nan:
            self.data = self.data.dropna()
        if remove_inf:
            self.data = self.data.replace([np.inf, -np.inf], np.nan).dropna()

        # å¤–ã‚Œå€¤é™¤å»
        if outlier_method == 'iqr':
            self.data = self._remove_outliers_iqr(self.data, threshold)
        elif outlier_method == 'zscore':
            self.data = self._remove_outliers_zscore(self.data, threshold)

        print(f"Data cleaning: {original_len} â†’ {len(self.data)} rows (removed {original_len - len(self.data)})")

        return self.data

    def _remove_outliers_iqr(self, data: pd.DataFrame, threshold: float) -&gt; pd.DataFrame:
        """IQRæ³•ã«ã‚ˆã‚‹å¤–ã‚Œå€¤é™¤å»"""
        Q1 = data.quantile(0.25)
        Q3 = data.quantile(0.75)
        IQR = Q3 - Q1
        
        lower_bound = Q1 - threshold * IQR
        upper_bound = Q3 + threshold * IQR
        
        mask = ((data &gt;= lower_bound) &amp; (data &lt;= upper_bound)).all(axis=1)
        return data[mask]

    def _remove_outliers_zscore(self, data: pd.DataFrame, threshold: float) -&gt; pd.DataFrame:
        """Z-scoreæ³•ã«ã‚ˆã‚‹å¤–ã‚Œå€¤é™¤å»"""
        z_scores = np.abs((data - data.mean()) / data.std())
        mask = (z_scores &lt; threshold).all(axis=1)
        return data[mask]

# ä½¿ç”¨ä¾‹
loader = UniversalDataLoader()

# CSVèª­ã¿è¾¼ã¿
data = loader.load('vsm_measurement.csv', format='auto')
print(data.head())
print(f"\nMetadata: {loader.metadata}")

# ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
data_clean = loader.clean_data(outlier_method='iqr', threshold=3.0)
print(f"\nCleaned data shape: {data_clean.shape}")
</code></pre>
<h2>4.2 Integrated Analysis Pipeline</h2>
<h3>4.2.1 å››ç«¯å­æ³• + Hall + M-Hçµ±åˆè§£æ</h3>
<p>In experiments, multiple measurements are performed on the same sample. Integrated analysis of these measurements provides complete understanding of the electrical and magnetic properties of materials.</p>
<h4>ã‚³ãƒ¼ãƒ‰ä¾‹4-2: Integrated Analysis Pipeline</h4>
<pre><code class="language-python"># Requirements:
# - Python 3.9+
# - matplotlib&gt;=3.7.0
# - numpy&gt;=1.24.0, &lt;2.0.0
# - pandas&gt;=2.0.0, &lt;2.2.0

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from scipy.optimize import fsolve, curve_fit
from lmfit import Model

class IntegratedAnalysisPipeline:
    """
    å››ç«¯å­æ³• + Hall + M-HIntegrated Analysis Pipeline
    
    Attributes
    ----------
    thickness : float
        è©¦æ–™åšã• [m]
    mass : float
        è©¦æ–™è³ªé‡ [g]
    results : dict
        è§£æçµæœï¼ˆÏƒ, n, Î¼, M_s, H_c, M_r, Kï¼‰
    """

    def __init__(self, thickness: float, mass: float = None):
        self.t = thickness
        self.mass = mass
        self.results = {}
        self.data = {}

    def load_four_probe_data(self, R_AB_CD: float, R_BC_DA: float):
        """van der Pauwå››ç«¯å­ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿"""
        self.data['R_AB_CD'] = R_AB_CD
        self.data['R_BC_DA'] = R_BC_DA

    def load_hall_data(self, I: float, B: float, V_pos: float, V_neg: float):
        """Hallãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿"""
        self.data['I'] = I
        self.data['B'] = B
        self.data['V_hall_pos'] = V_pos
        self.data['V_hall_neg'] = V_neg

    def load_mh_data(self, H: np.ndarray, M: np.ndarray):
        """M-Hãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿"""
        self.data['H'] = H
        self.data['M'] = M

    def analyze_electrical_properties(self):
        """é›»æ°—çš„ç‰¹æ€§è§£æï¼ˆå››ç«¯å­æ³• + Hallï¼‰"""
        # van der Pauw ã‚·ãƒ¼ãƒˆæŠµæŠ—
        def vdp_eq(Rs, R1, R2):
            return np.exp(-np.pi * R1 / Rs) + np.exp(-np.pi * R2 / Rs) - 1

        R1 = self.data['R_AB_CD']
        R2 = self.data['R_BC_DA']
        R_initial = (R1 + R2) / 2 * np.pi / np.log(2)
        R_s = fsolve(vdp_eq, R_initial, args=(R1, R2))[0]

        # é›»æ°—ä¼å°ç‡
        sigma = 1 / (R_s * self.t)

        # Hallä¿‚æ•°
        V_H = 0.5 * (self.data['V_hall_pos'] - self.data['V_hall_neg'])
        R_H = V_H * self.t / (self.data['I'] * self.data['B'])

        # ã‚­ãƒ£ãƒªã‚¢å¯†åº¦
        e = 1.60218e-19
        n = 1 / (np.abs(R_H) * e)
        carrier_type = 'electron' if R_H &lt; 0 else 'hole'

        # ç§»å‹•åº¦
        mu = sigma * np.abs(R_H)

        # çµæœä¿å­˜
        self.results.update({
            'R_s': R_s,
            'sigma': sigma,
            'rho': 1 / sigma,
            'R_H': R_H,
            'n': n,
            'carrier_type': carrier_type,
            'mu': mu
        })

        return self.results

    def analyze_magnetic_properties(self):
        """ç£æ°—çš„ç‰¹æ€§è§£æï¼ˆM-Hæ›²ç·šï¼‰"""
        H = self.data['H']
        M = self.data['M']

        # ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰æ¸›ç®—
        H_high = H[H &gt; 0.8 * np.max(H)]
        M_high = M[H &gt; 0.8 * np.max(H)]
        slope = np.polyfit(H_high, M_high, 1)[0]
        M_corrected = M - slope * H

        # é£½å’Œç£åŒ–
        M_s = np.mean(M_corrected[H &gt; 0.8 * np.max(H)])

        # ä¿ç£åŠ›
        from scipy.interpolate import interp1d
        from scipy.optimize import brentq
        interp_func = interp1d(H, M_corrected, kind='linear')
        H_c = brentq(interp_func, np.min(H[H &lt; 0]), np.max(H[H &gt; 0]))

        # æ®‹ç•™ç£åŒ–
        M_r = interp_func(0)

        # è§’å½¢æ¯”
        S = M_r / M_s if M_s != 0 else 0

        # ç£æ°—ç•°æ–¹æ€§å®šæ•°
        K = H_c * M_s / 2  # CGSå˜ä½ [erg/cm^3]

        # çµæœä¿å­˜
        self.results.update({
            'M_s': M_s,
            'H_c': H_c,
            'M_r': M_r,
            'S': S,
            'K': K
        })

        return self.results

    def generate_report(self):
        """çµ±åˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        print("=" * 80)
        print("INTEGRATED ELECTRICAL &amp; MAGNETIC PROPERTIES ANALYSIS")
        print("=" * 80)
        
        print("\n[Electrical Properties]")
        print(f"  Sheet Resistance R_s = {self.results['R_s']:.2f} Î©/sq")
        print(f"  Conductivity Ïƒ = {self.results['sigma']:.2e} S/m")
        print(f"  Resistivity Ï = {self.results['rho']:.2e} Î©Â·m = {self.results['rho'] * 1e8:.2f} Î¼Î©Â·cm")
        print(f"  Carrier Type: {self.results['carrier_type']}")
        print(f"  Carrier Density n = {self.results['n']:.2e} mâ»Â³ = {self.results['n'] / 1e6:.2e} cmâ»Â³")
        print(f"  Mobility Î¼ = {self.results['mu']:.2e} mÂ²/(VÂ·s) = {self.results['mu'] * 1e4:.1f} cmÂ²/(VÂ·s)")

        print("\n[Magnetic Properties]")
        print(f"  Saturation Magnetization M_s = {self.results['M_s']:.2f} emu/g")
        print(f"  Coercivity H_c = {self.results['H_c']:.2f} Oe = {self.results['H_c'] / 79.5775:.2f} kA/m")
        print(f"  Remanence M_r = {self.results['M_r']:.2f} emu/g")
        print(f"  Squareness S = {self.results['S']:.3f}")
        print(f"  Anisotropy Constant K = {self.results['K']:.2e} erg/cmÂ³ = {self.results['K'] * 1e3:.2e} J/mÂ³")

        print("\n[Material Classification]")
        if self.results['H_c'] &lt; 100:
            print("  â†’ Soft magnetic material (transformers, inductors)")
        elif self.results['H_c'] &gt; 1000:
            print("  â†’ Hard magnetic material (permanent magnets)")
        else:
            print("  â†’ Medium coercivity (recording media)")

        if self.results['mu'] * 1e4 &gt; 1000:
            print("  â†’ High mobility material (high-performance electronics)")
        else:
            print("  â†’ Moderate mobility (standard electronics)")

        print("=" * 80)

# ä½¿ç”¨ä¾‹
pipeline = IntegratedAnalysisPipeline(thickness=200e-9, mass=0.005)

# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
pipeline.load_four_probe_data(R_AB_CD=1000, R_BC_DA=950)
pipeline.load_hall_data(I=100e-6, B=0.5, V_pos=-5.0e-3, V_neg=4.8e-3)

H_data = np.linspace(-5000, 5000, 200)
M_data = 50 * np.tanh(H_data / 1000) + 0.5 * np.random.randn(200)
pipeline.load_mh_data(H=H_data, M=M_data)

# è§£æå®Ÿè¡Œ
pipeline.analyze_electrical_properties()
pipeline.analyze_magnetic_properties()

# ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
pipeline.generate_report()
</code></pre>
<h2>4.3 Advanced Fitting Techniques</h2>
<h3>4.3.1 Constrained Fitting with lmfit</h3>
<p><strong>lmfit</strong>ã¯ã€scipy.optimizeã®ãƒ©ãƒƒãƒ‘ãƒ¼ã§ã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®åˆ¶ç´„ã€èª¤å·®æ¨å®šã€ç›¸é–¢è¡Œåˆ—ã®è¨ˆç®—ãŒå®¹æ˜“ã§ã™ã€‚</p>
<h4>ã‚³ãƒ¼ãƒ‰ä¾‹4-3: lmfitã«ã‚ˆã‚‹è¤‡é›‘ãªãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°</h4>
<pre><code class="language-python"># Requirements:
# - Python 3.9+
# - matplotlib&gt;=3.7.0
# - numpy&gt;=1.24.0, &lt;2.0.0

import numpy as np
import matplotlib.pyplot as plt
from lmfit import Model, Parameters

def temperature_dependent_hall(T, n0, Ea, mu0, alpha):
    """
    æ¸©åº¦ä¾å­˜æ€§Hallãƒ¢ãƒ‡ãƒ«
    
    n(T) = n0 * exp(Ea / (k_B * T))  # ã‚­ãƒ£ãƒªã‚¢å¯†åº¦
    Î¼(T) = Î¼0 * (T / 300)^(-Î±)      # ç§»å‹•åº¦
    R_H(T) = 1 / (n(T) * e)
    
    Parameters
    ----------
    T : array-like
        æ¸©åº¦ [K]
    n0 : float
        åŸºæº–ã‚­ãƒ£ãƒªã‚¢å¯†åº¦ [m^-3]
    Ea : float
        æ´»æ€§åŒ–ã‚¨ãƒãƒ«ã‚®ãƒ¼ [eV]
    mu0 : float
        åŸºæº–ç§»å‹•åº¦ï¼ˆ300 Kï¼‰[m^2/(VÂ·s)]
    alpha : float
        ç§»å‹•åº¦ã®æ¸©åº¦æŒ‡æ•°
    
    Returns
    -------
    R_H : array-like
        Hallä¿‚æ•° [m^3/C]
    """
    k_B = 8.617e-5  # [eV/K]
    e = 1.60218e-19  # [C]
    
    n = n0 * np.exp(-Ea / (k_B * T))
    R_H = 1 / (n * e)
    
    return R_H

# ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
T_range = np.linspace(200, 400, 25)
n0_true = 1e21  # [m^-3]
Ea_true = 0.3  # [eV]
mu0_true = 0.05  # [m^2/(VÂ·s)]
alpha_true = 1.5

R_H_data = temperature_dependent_hall(T_range, n0_true, Ea_true, mu0_true, alpha_true)
R_H_data_noise = R_H_data * (1 + 0.08 * np.random.randn(len(T_range)))

# lmfitãƒ¢ãƒ‡ãƒ«å®šç¾©
model = Model(temperature_dependent_hall)

# ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®šï¼ˆåˆæœŸå€¤ã€ç¯„å›²ã€åˆ¶ç´„ï¼‰
params = model.make_params(
    n0 = {'value': 5e20, 'min': 1e19, 'max': 1e23},
    Ea = {'value': 0.4, 'min': 0.1, 'max': 1.0},
    mu0 = {'value': 0.1, 'min': 0.01, 'max': 1.0},
    alpha = {'value': 1.0, 'min': 0.5, 'max': 3.0}
)

# ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°å®Ÿè¡Œ
result = model.fit(R_H_data_noise, params, T=T_range)

# çµæœè¡¨ç¤º
print("=" * 80)
print("ADVANCED FITTING WITH LMFIT")
print("=" * 80)
print(result.fit_report())

# ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç›¸é–¢è¡Œåˆ—
print("\nParameter Correlation Matrix:")
print(result.params.correlation)

# ãƒ—ãƒ­ãƒƒãƒˆ
fig, axes = plt.subplots(2, 2, figsize=(14, 10))

# å·¦ä¸Šï¼šR_H vs T
axes[0, 0].scatter(T_range, R_H_data_noise, s=80, alpha=0.7, edgecolors='black', linewidths=1.5, label='Data (with noise)', color='#f093fb')
axes[0, 0].plot(T_range, result.best_fit, linewidth=2.5, label='Fit', color='#f5576c')
axes[0, 0].plot(T_range, R_H_data, linewidth=2, linestyle='--', label='True (no noise)', color='green')
axes[0, 0].set_xlabel('Temperature T [K]', fontsize=12)
axes[0, 0].set_ylabel('Hall Coefficient R$_H$ [m$^3$/C]', fontsize=12)
axes[0, 0].set_title('Hall Coefficient vs Temperature', fontsize=13, fontweight='bold')
axes[0, 0].legend(fontsize=10)
axes[0, 0].grid(alpha=0.3)
axes[0, 0].set_yscale('log')

# å³ä¸Šï¼šæ®‹å·®
residuals = R_H_data_noise - result.best_fit
axes[0, 1].scatter(T_range, residuals, s=80, alpha=0.7, edgecolors='black', linewidths=1.5, color='#99ccff')
axes[0, 1].axhline(0, color='black', linestyle='--', linewidth=1.5)
axes[0, 1].set_xlabel('Temperature T [K]', fontsize=12)
axes[0, 1].set_ylabel('Residuals [m$^3$/C]', fontsize=12)
axes[0, 1].set_title('Fit Residuals', fontsize=13, fontweight='bold')
axes[0, 1].grid(alpha=0.3)

# å·¦ä¸‹ï¼šã‚­ãƒ£ãƒªã‚¢å¯†åº¦
k_B = 8.617e-5
e = 1.60218e-19
n_fit = result.params['n0'].value * np.exp(-result.params['Ea'].value / (k_B * T_range))
axes[1, 0].semilogy(T_range, n_fit / 1e6, linewidth=2.5, color='#ffa500', label='Fitted n(T)')
axes[1, 0].set_xlabel('Temperature T [K]', fontsize=12)
axes[1, 0].set_ylabel('Carrier Density n [cm$^{-3}$]', fontsize=12)
axes[1, 0].set_title('Carrier Density (from fit)', fontsize=13, fontweight='bold')
axes[1, 0].legend(fontsize=11)
axes[1, 0].grid(alpha=0.3)

# å³ä¸‹ï¼šç§»å‹•åº¦
mu_fit = result.params['mu0'].value * (T_range / 300)**(-result.params['alpha'].value)
axes[1, 1].loglog(T_range, mu_fit * 1e4, linewidth=2.5, color='#99ff99', label='Fitted Î¼(T)')
axes[1, 1].set_xlabel('Temperature T [K]', fontsize=12)
axes[1, 1].set_ylabel('Mobility Î¼ [cm$^2$/(VÂ·s)]', fontsize=12)
axes[1, 1].set_title('Mobility (from fit)', fontsize=13, fontweight='bold')
axes[1, 1].legend(fontsize=11)
axes[1, 1].grid(alpha=0.3, which='both')

plt.tight_layout()
plt.show()

# ç‰©ç†çš„è§£é‡ˆ
print("\n" + "=" * 80)
print("PHYSICAL INTERPRETATION")
print("=" * 80)
print(f"Activation Energy E_a = {result.params['Ea'].value:.3f} Â± {result.params['Ea'].stderr:.3f} eV")
print(f"  â†’ Band gap or dopant ionization energy")
print(f"Mobility Exponent Î± = {result.params['alpha'].value:.2f} Â± {result.params['alpha'].stderr:.2f}")
print(f"  â†’ Scattering mechanism: Î± â‰ˆ 1.5 suggests acoustic phonon scattering")
print(f"Carrier Density (300 K) = {result.params['n0'].value * np.exp(-result.params['Ea'].value / (k_B * 300)):.2e} mâ»Â³")
print(f"Mobility (300 K) = {result.params['mu0'].value * 1e4:.1f} cmÂ²/(VÂ·s)")
</code></pre>
<h2>4.4 Error Propagation and Uncertainty Evaluation</h2>
<h3>4.4.1 Automatic Error Propagation</h3>
<p>æ¸¬å®šå€¤ã®ä¸ç¢ºã‹ã•ã¯ã€å°å‡ºé‡ï¼ˆç§»å‹•åº¦ã€ç•°æ–¹æ€§å®šæ•°ãªã©ï¼‰ã«ä¼æ’­ã—ã¾ã™ã€‚<strong>uncertainties</strong>ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ä½¿ã†ã¨ã€è‡ªå‹•çš„ã«èª¤å·®ä¼æ’­ã‚’è¨ˆç®—ã§ãã¾ã™ã€‚</p>
<h4>ã‚³ãƒ¼ãƒ‰ä¾‹4-4: Automatic Error Propagation</h4>
<pre><code class="language-python"># Requirements:
# - Python 3.9+
# - numpy&gt;=1.24.0, &lt;2.0.0

from uncertainties import ufloat, umath
import numpy as np

def propagate_uncertainties_example():
    """
    èª¤å·®ä¼æ’­ã®å®Ÿä¾‹
    
    Hallæ¸¬å®šã‹ã‚‰ç§»å‹•åº¦ã‚’è¨ˆç®—ã—ã€ä¸ç¢ºã‹ã•ã‚’è‡ªå‹•ä¼æ’­
    """
    # æ¸¬å®šå€¤ï¼ˆå€¤ Â± ä¸ç¢ºã‹ã•ï¼‰
    R_H = ufloat(-2.5e-3, 0.1e-3)  # Hallä¿‚æ•° [m^3/C]
    sigma = ufloat(1e4, 100)  # é›»æ°—ä¼å°ç‡ [S/m]
    I = ufloat(100e-6, 1e-6)  # é›»æµ [A]
    B = ufloat(0.5, 0.01)  # ç£å ´ [T]
    t = ufloat(200e-9, 5e-9)  # åšã• [m]

    # ç§»å‹•åº¦: Î¼ = Ïƒ * |R_H|
    mu = sigma * umath.fabs(R_H)

    # ã‚­ãƒ£ãƒªã‚¢å¯†åº¦: n = 1 / (e * |R_H|)
    e = 1.60218e-19  # å®šæ•°ï¼ˆä¸ç¢ºã‹ã•ãªã—ï¼‰
    n = 1 / (e * umath.fabs(R_H))

    # ç£æ°—ç•°æ–¹æ€§å®šæ•°: K = H_c * M_s / 2
    H_c = ufloat(500, 20)  # [Oe]
    M_s = ufloat(50, 2)  # [emu/g]
    K = H_c * M_s / 2

    print("=" * 80)
    print("AUTOMATIC ERROR PROPAGATION")
    print("=" * 80)
    
    print("\n[Input Measurements]")
    print(f"  Hall Coefficient R_H = {R_H} mÂ³/C")
    print(f"  Conductivity Ïƒ = {sigma} S/m")
    print(f"  Current I = {I} A")
    print(f"  Magnetic Field B = {B} T")
    print(f"  Thickness t = {t} m")

    print("\n[Derived Quantities with Propagated Uncertainties]")
    print(f"  Mobility Î¼ = {mu} mÂ²/(VÂ·s)")
    print(f"            = ({mu.nominal_value * 1e4:.1f} Â± {mu.std_dev * 1e4:.1f}) cmÂ²/(VÂ·s)")
    print(f"  Carrier Density n = {n} mâ»Â³")
    print(f"                    = ({n.nominal_value / 1e6:.2e} Â± {n.std_dev / 1e6:.2e}) cmâ»Â³")
    print(f"  Anisotropy Constant K = {K} erg/cmÂ³")

    print("\n[Relative Uncertainties]")
    print(f"  Î¼: {mu.std_dev / mu.nominal_value * 100:.2f}%")
    print(f"  n: {n.std_dev / n.nominal_value * 100:.2f}%")
    print(f"  K: {K.std_dev / K.nominal_value * 100:.2f}%")

    # ä¸ç¢ºã‹ã•ã®å¯„ä¸åˆ†æï¼ˆæ‰‹å‹•è¨ˆç®—ã§ç¢ºèªï¼‰
    print("\n[Uncertainty Budget for Î¼ = Ïƒ * |R_H|]")
    rel_sigma = (100 / 1e4)**2
    rel_R_H = (0.1e-3 / 2.5e-3)**2
    rel_mu_manual = np.sqrt(rel_sigma + rel_R_H)
    print(f"  Contribution from Ïƒ: {np.sqrt(rel_sigma) * 100:.2f}%")
    print(f"  Contribution from R_H: {np.sqrt(rel_R_H) * 100:.2f}%")
    print(f"  Total (manual): {rel_mu_manual * 100:.2f}%")
    print(f"  Total (automatic): {mu.std_dev / mu.nominal_value * 100:.2f}%")

propagate_uncertainties_example()
</code></pre>
<h2>4.5 Publication-Qualityå›³ã®ä½œæˆ</h2>
<h3>4.5.1 matplotlibãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹</h3>
<p>Key points for creating publication-ready figures:</p>
<ul>
<li>ãƒ•ã‚©ãƒ³ãƒˆã‚µã‚¤ã‚ºï¼šãƒ©ãƒ™ãƒ« 12-14ptã€ã‚¿ã‚¤ãƒˆãƒ« 14-16ptã€å‡¡ä¾‹ 10-12pt</li>
<li>ç·šå¹…ï¼šãƒ‡ãƒ¼ã‚¿ç·š 2-3ptã€ã‚°ãƒªãƒƒãƒ‰ 0.5-1pt</li>
<li>ãƒãƒ¼ã‚«ãƒ¼ã‚µã‚¤ã‚ºï¼š80-150ï¼ˆscatterï¼‰</li>
<li>è‰²ï¼šcolorblind-friendlyãªã‚«ãƒ©ãƒ¼ãƒ‘ãƒ¬ãƒƒãƒˆï¼ˆä¾‹ï¼šseabornã€viridisï¼‰</li>
<li>è§£åƒåº¦ï¼šDPI 300ä»¥ä¸Šï¼ˆå°åˆ·ç”¨ï¼‰</li>
<li>ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼šPDFï¼ˆãƒ™ã‚¯ã‚¿ãƒ¼ï¼‰ã¾ãŸã¯PNGï¼ˆãƒ©ã‚¹ã‚¿ãƒ¼ï¼‰</li>
</ul>
<h4>ã‚³ãƒ¼ãƒ‰ä¾‹4-5: Publication-Qualityå›³ç”Ÿæˆ</h4>
<pre><code class="language-python"># Requirements:
# - Python 3.9+
# - matplotlib&gt;=3.7.0
# - numpy&gt;=1.24.0, &lt;2.0.0

"""
Example: ã‚³ãƒ¼ãƒ‰ä¾‹4-5: Publication-Qualityå›³ç”Ÿæˆ

Purpose: Demonstrate data visualization techniques
Target: Intermediate
Execution time: 2-5 seconds
Dependencies: None
"""

import numpy as np
import matplotlib.pyplot as plt
import matplotlib as mpl
from matplotlib.ticker import MultipleLocator, AutoMinorLocator

# Publicationè¨­å®š
mpl.rcParams['font.family'] = 'Arial'
mpl.rcParams['font.size'] = 12
mpl.rcParams['axes.linewidth'] = 1.5
mpl.rcParams['xtick.major.width'] = 1.5
mpl.rcParams['ytick.major.width'] = 1.5
mpl.rcParams['xtick.minor.width'] = 1.0
mpl.rcParams['ytick.minor.width'] = 1.0
mpl.rcParams['xtick.major.size'] = 6
mpl.rcParams['ytick.major.size'] = 6
mpl.rcParams['xtick.minor.size'] = 3
mpl.rcParams['ytick.minor.size'] = 3

def create_publication_figure():
    """
    Publication-qualityã®å›³ã‚’ä½œæˆ
    
    ä¾‹ï¼šæ¸©åº¦ä¾å­˜æ€§Hallæ¸¬å®šçµæœ
    """
    # ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    T = np.linspace(100, 400, 20)
    n = 1e22 * np.exp(-0.3 / (8.617e-5 * T))
    mu = 0.05 * (300 / T)**1.5
    sigma = n * 1.60218e-19 * mu

    # å›³ä½œæˆï¼ˆ2x2ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆï¼‰
    fig = plt.figure(figsize=(12, 10))
    gs = fig.add_gridspec(2, 2, hspace=0.3, wspace=0.3)

    # (a) ã‚­ãƒ£ãƒªã‚¢å¯†åº¦
    ax1 = fig.add_subplot(gs[0, 0])
    ax1.semilogy(T, n / 1e6, 'o-', linewidth=2.5, markersize=8, color='#2E86AB', 
                 markeredgecolor='black', markeredgewidth=1.5, label='Carrier density')
    ax1.set_xlabel('Temperature (K)', fontsize=14, fontweight='bold')
    ax1.set_ylabel('Carrier Density (cm$^{-3}$)', fontsize=14, fontweight='bold')
    ax1.set_title('(a) Temperature-Dependent Carrier Density', fontsize=14, fontweight='bold', loc='left')
    ax1.legend(fontsize=12, frameon=True, shadow=True)
    ax1.grid(True, which='both', alpha=0.3, linestyle='--')
    ax1.xaxis.set_minor_locator(AutoMinorLocator())

    # (b) ç§»å‹•åº¦
    ax2 = fig.add_subplot(gs[0, 1])
    ax2.loglog(T, mu * 1e4, 's-', linewidth=2.5, markersize=8, color='#A23B72',
               markeredgecolor='black', markeredgewidth=1.5, label='Mobility')
    ax2.set_xlabel('Temperature (K)', fontsize=14, fontweight='bold')
    ax2.set_ylabel('Mobility (cm$^2$/(VÂ·s))', fontsize=14, fontweight='bold')
    ax2.set_title('(b) Temperature-Dependent Mobility', fontsize=14, fontweight='bold', loc='left')
    ax2.legend(fontsize=12, frameon=True, shadow=True)
    ax2.grid(True, which='both', alpha=0.3, linestyle='--')

    # (c) é›»æ°—ä¼å°ç‡
    ax3 = fig.add_subplot(gs[1, 0])
    ax3.semilogy(T, sigma, '^-', linewidth=2.5, markersize=8, color='#F18F01',
                 markeredgecolor='black', markeredgewidth=1.5, label='Conductivity')
    ax3.set_xlabel('Temperature (K)', fontsize=14, fontweight='bold')
    ax3.set_ylabel('Conductivity (S/m)', fontsize=14, fontweight='bold')
    ax3.set_title('(c) Electrical Conductivity', fontsize=14, fontweight='bold', loc='left')
    ax3.legend(fontsize=12, frameon=True, shadow=True)
    ax3.grid(True, which='both', alpha=0.3, linestyle='--')
    ax3.xaxis.set_minor_locator(AutoMinorLocator())

    # (d) Arrheniusãƒ—ãƒ­ãƒƒãƒˆ
    ax4 = fig.add_subplot(gs[1, 1])
    ax4.semilogy(1000 / T, n / 1e6, 'D-', linewidth=2.5, markersize=8, color='#C73E1D',
                 markeredgecolor='black', markeredgewidth=1.5, label='Arrhenius plot')
    ax4.set_xlabel('1000/T (K$^{-1}$)', fontsize=14, fontweight='bold')
    ax4.set_ylabel('Carrier Density (cm$^{-3}$)', fontsize=14, fontweight='bold')
    ax4.set_title('(d) Arrhenius Plot', fontsize=14, fontweight='bold', loc='left')
    ax4.legend(fontsize=12, frameon=True, shadow=True)
    ax4.grid(True, which='both', alpha=0.3, linestyle='--')

    # å…¨ä½“èª¿æ•´
    for ax in [ax1, ax2, ax3, ax4]:
        ax.tick_params(axis='both', which='major', labelsize=12, direction='in', top=True, right=True)
        ax.tick_params(axis='both', which='minor', direction='in', top=True, right=True)

    # ä¿å­˜ï¼ˆé«˜è§£åƒåº¦PDF + PNGï¼‰
    plt.savefig('hall_measurement_publication.pdf', dpi=300, bbox_inches='tight', format='pdf')
    plt.savefig('hall_measurement_publication.png', dpi=300, bbox_inches='tight', format='png')
    
    print("Figures saved:")
    print("  - hall_measurement_publication.pdf (vector, for publication)")
    print("  - hall_measurement_publication.png (raster, for preview)")

    plt.show()

create_publication_figure()
</code></pre>
<h2>4.6 Automated Report Generation</h2>
<h3>4.6.1 Automated PDF Reports</h3>
<p><strong>matplotlib</strong>ã¨<strong>matplotlib.backends.backend_pdf</strong>ã‚’ä½¿ã£ã¦ã€è¤‡æ•°ãƒšãƒ¼ã‚¸ã®PDFãƒ¬ãƒãƒ¼ãƒˆã‚’è‡ªå‹•ç”Ÿæˆã—ã¾ã™ã€‚</p>
<h4>ã‚³ãƒ¼ãƒ‰ä¾‹4-6: PDFãƒ¬ãƒãƒ¼ãƒˆè‡ªå‹•ç”Ÿæˆ</h4>
<pre><code class="language-python"># Requirements:
# - Python 3.9+
# - matplotlib&gt;=3.7.0
# - numpy&gt;=1.24.0, &lt;2.0.0

import numpy as np
import matplotlib.pyplot as plt
from matplotlib.backends.backend_pdf import PdfPages
from datetime import datetime

class AutoReportGenerator:
    """
    è‡ªå‹•PDFãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚¯ãƒ©ã‚¹
    
    Attributes
    ----------
    filename : str
        å‡ºåŠ›PDFãƒ•ã‚¡ã‚¤ãƒ«å
    metadata : dict
        ãƒ¬ãƒãƒ¼ãƒˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
    """

    def __init__(self, filename='analysis_report.pdf'):
        self.filename = filename
        self.metadata = {
            'Title': 'Electrical &amp; Magnetic Properties Analysis Report',
            'Author': 'MS Terakoya Analysis Pipeline',
            'Subject': 'Automated Data Analysis',
            'Keywords': 'Hall effect, Magnetometry, Python',
            'CreationDate': datetime.now()
        }

    def generate_report(self, results: dict):
        """
        å®Œå…¨ãªãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ
        
        Parameters
        ----------
        results : dict
            è§£æçµæœï¼ˆé›»æ°—çš„ãƒ»ç£æ°—çš„ç‰¹æ€§ï¼‰
        """
        with PdfPages(self.filename) as pdf:
            # ãƒšãƒ¼ã‚¸1ï¼šã‚µãƒãƒªãƒ¼
            self._add_summary_page(pdf, results)
            
            # ãƒšãƒ¼ã‚¸2ï¼šé›»æ°—çš„ç‰¹æ€§ã‚°ãƒ©ãƒ•
            self._add_electrical_plots(pdf, results)
            
            # ãƒšãƒ¼ã‚¸3ï¼šç£æ°—çš„ç‰¹æ€§ã‚°ãƒ©ãƒ•
            self._add_magnetic_plots(pdf, results)
            
            # ãƒšãƒ¼ã‚¸4ï¼šçµ±è¨ˆæƒ…å ±
            self._add_statistics_page(pdf, results)

            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿è¨­å®š
            d = pdf.infodict()
            for key, value in self.metadata.items():
                d[key] = value

        print(f"Report generated: {self.filename}")

    def _add_summary_page(self, pdf, results):
        """ãƒšãƒ¼ã‚¸1ï¼šã‚µãƒãƒªãƒ¼ï¼ˆãƒ†ã‚­ã‚¹ãƒˆã®ã¿ï¼‰"""
        fig = plt.figure(figsize=(8.5, 11))
        fig.text(0.5, 0.95, 'ANALYSIS SUMMARY', ha='center', fontsize=20, fontweight='bold')
        fig.text(0.5, 0.90, f'Generated: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}', ha='center', fontsize=10)

        # é›»æ°—çš„ç‰¹æ€§
        y_start = 0.75
        fig.text(0.1, y_start, 'ELECTRICAL PROPERTIES', fontsize=16, fontweight='bold', color='#2E86AB')
        fig.text(0.1, y_start - 0.05, f"Sheet Resistance R_s = {results['R_s']:.2f} Î©/sq", fontsize=12)
        fig.text(0.1, y_start - 0.10, f"Conductivity Ïƒ = {results['sigma']:.2e} S/m", fontsize=12)
        fig.text(0.1, y_start - 0.15, f"Carrier Type: {results['carrier_type']}", fontsize=12)
        fig.text(0.1, y_start - 0.20, f"Carrier Density n = {results['n']:.2e} mâ»Â³", fontsize=12)
        fig.text(0.1, y_start - 0.25, f"Mobility Î¼ = {results['mu'] * 1e4:.1f} cmÂ²/(VÂ·s)", fontsize=12)

        # ç£æ°—çš„ç‰¹æ€§
        y_start = 0.45
        fig.text(0.1, y_start, 'MAGNETIC PROPERTIES', fontsize=16, fontweight='bold', color='#A23B72')
        fig.text(0.1, y_start - 0.05, f"Saturation Magnetization M_s = {results['M_s']:.2f} emu/g", fontsize=12)
        fig.text(0.1, y_start - 0.10, f"Coercivity H_c = {results['H_c']:.2f} Oe", fontsize=12)
        fig.text(0.1, y_start - 0.15, f"Remanence M_r = {results['M_r']:.2f} emu/g", fontsize=12)
        fig.text(0.1, y_start - 0.20, f"Squareness S = {results['S']:.3f}", fontsize=12)
        fig.text(0.1, y_start - 0.25, f"Anisotropy Constant K = {results['K']:.2e} erg/cmÂ³", fontsize=12)

        plt.axis('off')
        pdf.savefig(fig, bbox_inches='tight')
        plt.close(fig)

    def _add_electrical_plots(self, pdf, results):
        """ãƒšãƒ¼ã‚¸2ï¼šé›»æ°—çš„ç‰¹æ€§ã‚°ãƒ©ãƒ•"""
        fig, axes = plt.subplots(2, 2, figsize=(11, 8.5))
        
        # ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ï¼ˆå®Ÿéš›ã«ã¯resultsã‹ã‚‰å–å¾—ï¼‰
        T = np.linspace(100, 400, 20)
        n = results['n'] * np.exp(-0.1 / (8.617e-5 * T))
        mu = results['mu'] * (300 / T)**1.5
        sigma = n * 1.60218e-19 * mu
        R_H = 1 / (n * 1.60218e-19)

        # ãƒ—ãƒ­ãƒƒãƒˆ
        axes[0, 0].semilogy(T, n / 1e6, 'o-', linewidth=2.5)
        axes[0, 0].set_xlabel('Temperature (K)')
        axes[0, 0].set_ylabel('n (cmâ»Â³)')
        axes[0, 0].set_title('Carrier Density vs T')
        axes[0, 0].grid(alpha=0.3)

        axes[0, 1].loglog(T, mu * 1e4, 's-', linewidth=2.5, color='#A23B72')
        axes[0, 1].set_xlabel('Temperature (K)')
        axes[0, 1].set_ylabel('Î¼ (cmÂ²/(VÂ·s))')
        axes[0, 1].set_title('Mobility vs T')
        axes[0, 1].grid(alpha=0.3)

        axes[1, 0].semilogy(T, sigma, '^-', linewidth=2.5, color='#F18F01')
        axes[1, 0].set_xlabel('Temperature (K)')
        axes[1, 0].set_ylabel('Ïƒ (S/m)')
        axes[1, 0].set_title('Conductivity vs T')
        axes[1, 0].grid(alpha=0.3)

        axes[1, 1].plot(T, R_H, 'D-', linewidth=2.5, color='#C73E1D')
        axes[1, 1].set_xlabel('Temperature (K)')
        axes[1, 1].set_ylabel('R_H (mÂ³/C)')
        axes[1, 1].set_title('Hall Coefficient vs T')
        axes[1, 1].grid(alpha=0.3)

        plt.suptitle('Electrical Properties', fontsize=16, fontweight='bold')
        plt.tight_layout()
        pdf.savefig(fig, bbox_inches='tight')
        plt.close(fig)

    def _add_magnetic_plots(self, pdf, results):
        """ãƒšãƒ¼ã‚¸3ï¼šç£æ°—çš„ç‰¹æ€§ã‚°ãƒ©ãƒ•"""
        fig, axes = plt.subplots(2, 2, figsize=(11, 8.5))
        
        # M-Hæ›²ç·šï¼ˆãƒ€ãƒŸãƒ¼ï¼‰
        H = np.linspace(-5000, 5000, 100)
        M = results['M_s'] * np.tanh(H / 1000)

        axes[0, 0].plot(H, M, linewidth=2.5, color='#f093fb')
        axes[0, 0].axhline(results['M_s'], linestyle='--', color='green', label=f"M_s = {results['M_s']:.1f}")
        axes[0, 0].axvline(results['H_c'], linestyle='--', color='red', label=f"H_c = {results['H_c']:.0f}")
        axes[0, 0].set_xlabel('H (Oe)')
        axes[0, 0].set_ylabel('M (emu/g)')
        axes[0, 0].set_title('M-H Hysteresis Loop')
        axes[0, 0].legend()
        axes[0, 0].grid(alpha=0.3)

        # ä»–ã®ãƒ—ãƒ­ãƒƒãƒˆã¯çœç•¥ï¼ˆå®Ÿéš›ã«ã¯æ¸©åº¦ä¾å­˜æ€§ãªã©ï¼‰
        for ax in axes.flat[1:]:
            ax.text(0.5, 0.5, 'Additional magnetic\nproperties plots', ha='center', va='center', fontsize=14)
            ax.axis('off')

        plt.suptitle('Magnetic Properties', fontsize=16, fontweight='bold')
        plt.tight_layout()
        pdf.savefig(fig, bbox_inches='tight')
        plt.close(fig)

    def _add_statistics_page(self, pdf, results):
        """ãƒšãƒ¼ã‚¸4ï¼šçµ±è¨ˆæƒ…å ±"""
        fig = plt.figure(figsize=(8.5, 11))
        fig.text(0.5, 0.95, 'STATISTICAL SUMMARY', ha='center', fontsize=20, fontweight='bold')
        
        # ç°¡å˜ãªçµ±è¨ˆè¡¨ï¼ˆå®Ÿéš›ã«ã¯ã‚‚ã£ã¨è©³ç´°ã«ï¼‰
        fig.text(0.1, 0.80, 'Measurement Quality Metrics:', fontsize=14, fontweight='bold')
        fig.text(0.1, 0.75, '  - Data points: 200', fontsize=12)
        fig.text(0.1, 0.70, '  - Outliers removed: 5 (2.5%)', fontsize=12)
        fig.text(0.1, 0.65, '  - Fit RÂ²: 0.998', fontsize=12)
        fig.text(0.1, 0.60, '  - Residual std: 0.05', fontsize=12)

        plt.axis('off')
        pdf.savefig(fig, bbox_inches='tight')
        plt.close(fig)

# ä½¿ç”¨ä¾‹
results_example = {
    'R_s': 1370,
    'sigma': 2.43e3,
    'carrier_type': 'electron',
    'n': 2.36e20,
    'mu': 0.064,
    'M_s': 50,
    'H_c': 300,
    'M_r': 40,
    'S': 0.8,
    'K': 7.5e5
}

reporter = AutoReportGenerator(filename='integrated_analysis_report.pdf')
reporter.generate_report(results_example)
</code></pre>
<h2>4.7 Complete Workflow Integration</h2>
<h4>ã‚³ãƒ¼ãƒ‰ä¾‹4-7: ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰è§£æãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³</h4>
<pre><code class="language-python"># Requirements:
# - Python 3.9+
# - numpy&gt;=1.24.0, &lt;2.0.0
# - pandas&gt;=2.0.0, &lt;2.2.0

"""
å®Œå…¨ãªã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰è§£æãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼:
1. ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ï¼ˆCSV/DAT/Binaryï¼‰
2. ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆå¤–ã‚Œå€¤é™¤å»ï¼‰
3. å››ç«¯å­æ³• + Hall + M-Hçµ±åˆè§£æ
4. é«˜åº¦ãªãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°
5. èª¤å·®ä¼æ’­
6. Publication-qualityå›³ç”Ÿæˆ
7. PDFãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
"""

import numpy as np
import pandas as pd
from pathlib import Path

class EndToEndPipeline:
    """
    å®Œå…¨ãªè§£æãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
    """

    def __init__(self, project_name: str):
        self.project_name = project_name
        self.loader = UniversalDataLoader()
        self.analyzer = IntegratedAnalysisPipeline(thickness=200e-9, mass=0.005)
        self.reporter = AutoReportGenerator(filename=f'{project_name}_report.pdf')

    def run(self, data_files: dict):
        """
        ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ
        
        Parameters
        ----------
        data_files : dict
            {'four_probe': 'path/to/file.csv',
             'hall': 'path/to/file.csv',
             'mh': 'path/to/file.csv'}
        """
        print("=" * 80)
        print(f"STARTING END-TO-END ANALYSIS PIPELINE: {self.project_name}")
        print("=" * 80)

        # Step 1: ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        print("\n[Step 1] Loading data...")
        data_four_probe = self.loader.load(data_files['four_probe'])
        data_hall = self.loader.load(data_files['hall'])
        data_mh = self.loader.load(data_files['mh'])

        # Step 2: ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
        print("\n[Step 2] Cleaning data...")
        data_four_probe_clean = self.loader.clean_data(outlier_method='iqr')
        
        self.loader.data = data_hall
        data_hall_clean = self.loader.clean_data(outlier_method='iqr')
        
        self.loader.data = data_mh
        data_mh_clean = self.loader.clean_data(outlier_method='iqr')

        # Step 3: çµ±åˆè§£æ
        print("\n[Step 3] Integrated analysis...")
        self.analyzer.load_four_probe_data(
            R_AB_CD=data_four_probe_clean['R_AB_CD'].mean(),
            R_BC_DA=data_four_probe_clean['R_BC_DA'].mean()
        )
        self.analyzer.load_hall_data(
            I=data_hall_clean['I'].mean(),
            B=data_hall_clean['B'].mean(),
            V_pos=data_hall_clean['V_pos'].mean(),
            V_neg=data_hall_clean['V_neg'].mean()
        )
        self.analyzer.load_mh_data(
            H=data_mh_clean['H'].values,
            M=data_mh_clean['M'].values
        )

        self.analyzer.analyze_electrical_properties()
        self.analyzer.analyze_magnetic_properties()

        # Step 4: ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        print("\n[Step 4] Generating report...")
        self.analyzer.generate_report()
        self.reporter.generate_report(self.analyzer.results)

        print("\n" + "=" * 80)
        print("PIPELINE COMPLETED")
        print("=" * 80)

        return self.analyzer.results

# ä½¿ç”¨ä¾‹ï¼ˆãƒ¢ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã§å®Ÿè¡Œï¼‰
if __name__ == '__main__':
    # ãƒ¢ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆï¼ˆå®Ÿéš›ã«ã¯ã“ã“ã¯ä¸è¦ï¼‰
    np.random.seed(42)
    pd.DataFrame({
        'R_AB_CD': 1000 + 50 * np.random.randn(30),
        'R_BC_DA': 950 + 45 * np.random.randn(30)
    }).to_csv('four_probe_data.csv', index=False)

    pd.DataFrame({
        'I': 100e-6 + 1e-6 * np.random.randn(30),
        'B': 0.5 + 0.01 * np.random.randn(30),
        'V_pos': -5.0e-3 + 0.1e-3 * np.random.randn(30),
        'V_neg': 4.8e-3 + 0.1e-3 * np.random.randn(30)
    }).to_csv('hall_data.csv', index=False)

    H = np.linspace(-5000, 5000, 200)
    M = 50 * np.tanh(H / 1000) + 0.5 * np.random.randn(200)
    pd.DataFrame({'H': H, 'M': M}).to_csv('mh_data.csv', index=False)

    # ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ
    pipeline = EndToEndPipeline(project_name='Sample_Material_XYZ')
    results = pipeline.run({
        'four_probe': 'four_probe_data.csv',
        'hall': 'hall_data.csv',
        'mh': 'mh_data.csv'
    })

    print("\nFinal results saved to:")
    print("  - Sample_Material_XYZ_report.pdf")
</code></pre>
<h2>4.8 Exercises</h2>
<h3>æ¼”ç¿’4-1: ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã®æ‹¡å¼µï¼ˆEasyï¼‰</h3>
<p><span class="exercise-label easy">Easy</span> <strong>å•é¡Œ</strong>ï¼š<code>UniversalDataLoader</code>ã‚¯ãƒ©ã‚¹ã«ã€JSONFormatã®ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€ãƒ¡ã‚½ãƒƒãƒ‰ <code>_load_json()</code> ã‚’è¿½åŠ ã›ã‚ˆã€‚</p>
<details>
<summary><strong>è§£ç­”ä¾‹ã‚’è¡¨ç¤º</strong></summary>
<pre><code class="language-python">import json

def _load_json(self, path: Path) -&gt; pd.DataFrame:
    """JSONFormatã®èª­ã¿è¾¼ã¿"""
    with open(path, 'r') as f:
        data_dict = json.load(f)
    
    # è¾æ›¸ã‹ã‚‰DataFrameã«å¤‰æ›
    data = pd.DataFrame(data_dict)
    return data

# ã‚¯ãƒ©ã‚¹ã«è¿½åŠ 
UniversalDataLoader._load_json = _load_json

# ãƒ†ã‚¹ãƒˆ
loader = UniversalDataLoader()
# loader.load('data.json', format='json')
</code></pre>
</details>
<h3>æ¼”ç¿’4-2: å¤–ã‚Œå€¤æ¤œå‡ºã®å¯è¦–åŒ–ï¼ˆEasyï¼‰</h3>
<p><span class="exercise-label easy">Easy</span> <strong>å•é¡Œ</strong>ï¼šIQRæ³•ã§æ¤œå‡ºã•ã‚ŒãŸå¤–ã‚Œå€¤ã‚’ã€å…ƒã®ãƒ‡ãƒ¼ã‚¿ã¨ä¸€ç·’ã«ãƒ—ãƒ­ãƒƒãƒˆã›ã‚ˆï¼ˆå¤–ã‚Œå€¤ã‚’èµ¤è‰²ã§ãƒãƒ¼ã‚¯ï¼‰ã€‚</p>
<details>
<summary><strong>è§£ç­”ä¾‹ã‚’è¡¨ç¤º</strong></summary>
<pre><code class="language-python"># Requirements:
# - Python 3.9+
# - matplotlib&gt;=3.7.0

"""
Example: Easyå•é¡Œï¼šIQRæ³•ã§æ¤œå‡ºã•ã‚ŒãŸå¤–ã‚Œå€¤ã‚’ã€å…ƒã®ãƒ‡ãƒ¼ã‚¿ã¨ä¸€ç·’ã«ãƒ—ãƒ­ãƒƒãƒˆã›ã‚ˆï¼ˆå¤–ã‚Œå€¤ã‚’èµ¤è‰²ã§ãƒãƒ¼ã‚¯ï¼‰ã€‚

Purpose: Demonstrate data visualization techniques
Target: Beginner to Intermediate
Execution time: 2-5 seconds
Dependencies: None
"""

import matplotlib.pyplot as plt

data = np.random.randn(100)
data[95:] = 10  # å¤–ã‚Œå€¤ã‚’è¿½åŠ 

Q1, Q3 = np.percentile(data, [25, 75])
IQR = Q3 - Q1
lower = Q1 - 1.5 * IQR
upper = Q3 + 1.5 * IQR

outliers = (data &lt; lower) | (data &gt; upper)

plt.figure(figsize=(10, 6))
plt.scatter(range(len(data)), data, c=outliers, cmap='RdYlGn_r', s=50, edgecolors='black')
plt.axhline(lower, color='blue', linestyle='--', label='Lower bound')
plt.axhline(upper, color='blue', linestyle='--', label='Upper bound')
plt.xlabel('Index')
plt.ylabel('Value')
plt.title('Outlier Detection (IQR method)')
plt.legend()
plt.colorbar(label='Outlier (True=Red)')
plt.show()
</code></pre>
</details>
<h3>æ¼”ç¿’4-3: ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°æ®‹å·®ã®åˆ†æï¼ˆMediumï¼‰</h3>
<p><span class="exercise-label medium">Medium</span> <strong>å•é¡Œ</strong>ï¼šlmfitã®ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°çµæœã‹ã‚‰ã€æ®‹å·®ã®æ­£è¦æ€§ã‚’Q-Qãƒ—ãƒ­ãƒƒãƒˆã§ç¢ºèªã›ã‚ˆã€‚</p>
<details>
<summary><strong>è§£ç­”ä¾‹ã‚’è¡¨ç¤º</strong></summary>
<pre><code class="language-python"># Requirements:
# - Python 3.9+
# - scipy&gt;=1.11.0

"""
Example: Mediumå•é¡Œï¼šlmfitã®ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°çµæœã‹ã‚‰ã€æ®‹å·®ã®æ­£è¦æ€§ã‚’Q-Qãƒ—ãƒ­ãƒƒãƒˆã§ç¢ºèªã›ã‚ˆã€‚

Purpose: Demonstrate data visualization techniques
Target: Advanced
Execution time: 2-5 seconds
Dependencies: None
"""

import scipy.stats as stats

# ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°å®Ÿè¡Œï¼ˆå‰ã®ã‚³ãƒ¼ãƒ‰ä¾‹ã‹ã‚‰ï¼‰
residuals = result.residual

# Q-Qãƒ—ãƒ­ãƒƒãƒˆ
fig, ax = plt.subplots(figsize=(8, 6))
stats.probplot(residuals, dist="norm", plot=ax)
ax.set_title('Q-Q Plot: Residuals Normality Check', fontsize=14, fontweight='bold')
ax.grid(alpha=0.3)
plt.show()

# çµ±è¨ˆæ¤œå®šï¼ˆShapiro-Wilkæ¤œå®šï¼‰
stat, p_value = stats.shapiro(residuals)
print(f"Shapiro-Wilk test: statistic={stat:.4f}, p-value={p_value:.4f}")
if p_value &gt; 0.05:
    print("  â†’ Residuals are normally distributed (p &gt; 0.05)")
else:
    print("  â†’ Residuals are NOT normally distributed (p &lt; 0.05)")
</code></pre>
</details>
<h3>æ¼”ç¿’4-4: èª¤å·®ä¼æ’­ã®æ‰‹å‹•è¨ˆç®—ï¼ˆMediumï¼‰</h3>
<p><span class="exercise-label medium">Medium</span> <strong>å•é¡Œ</strong>ï¼šç§»å‹•åº¦ $\mu = \sigma |R_H|$ ã®ä¸ç¢ºã‹ã•ã‚’ã€åå¾®åˆ†ã‚’ä½¿ã£ã¦æ‰‹å‹•è¨ˆç®—ã—ã€<code>uncertainties</code>ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®çµæœã¨æ¯”è¼ƒã›ã‚ˆã€‚</p>
<details>
<summary><strong>è§£ç­”ä¾‹ã‚’è¡¨ç¤º</strong></summary>
<pre><code class="language-python">sigma_val = 1e4
sigma_err = 100
R_H_val = 2.5e-3
R_H_err = 0.1e-3

# æ‰‹å‹•è¨ˆç®—ï¼šÎ´Î¼ = sqrt((âˆ‚Î¼/âˆ‚Ïƒ)Â² Î´ÏƒÂ² + (âˆ‚Î¼/âˆ‚R_H)Â² Î´R_HÂ²)
# âˆ‚Î¼/âˆ‚Ïƒ = |R_H|
# âˆ‚Î¼/âˆ‚R_H = Ïƒ * sign(R_H)

dmu_dsigma = R_H_val
dmu_dRH = sigma_val

delta_mu_manual = np.sqrt((dmu_dsigma * sigma_err)**2 + (dmu_dRH * R_H_err)**2)
mu_val = sigma_val * R_H_val

print(f"æ‰‹å‹•è¨ˆç®—:")
print(f"  Î¼ = {mu_val:.2e} mÂ²/(VÂ·s)")
print(f"  Î”Î¼ = {delta_mu_manual:.2e} mÂ²/(VÂ·s)")
print(f"  ç›¸å¯¾ä¸ç¢ºã‹ã• = {delta_mu_manual / mu_val * 100:.2f}%")

# uncertaintiesãƒ‘ãƒƒã‚±ãƒ¼ã‚¸
from uncertainties import ufloat
sigma_u = ufloat(sigma_val, sigma_err)
R_H_u = ufloat(R_H_val, R_H_err)
mu_u = sigma_u * R_H_u

print(f"\nuncertaintiesãƒ‘ãƒƒã‚±ãƒ¼ã‚¸:")
print(f"  Î¼ = {mu_u}")
print(f"  ç›¸å¯¾ä¸ç¢ºã‹ã• = {mu_u.std_dev / mu_u.nominal_value * 100:.2f}%")
</code></pre>
</details>
<h3>æ¼”ç¿’4-5: ã‚«ã‚¹ã‚¿ãƒ ãƒ¬ãƒãƒ¼ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆä½œæˆï¼ˆMediumï¼‰</h3>
<p><span class="exercise-label medium">Medium</span> <strong>å•é¡Œ</strong>ï¼š<code>AutoReportGenerator</code>ã‚’æ‹¡å¼µã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼å®šç¾©ã®å›³ã‚’è¿½åŠ ã§ãã‚‹ãƒ¡ã‚½ãƒƒãƒ‰ <code>add_custom_page()</code> ã‚’å®Ÿè£…ã›ã‚ˆã€‚</p>
<details>
<summary><strong>è§£ç­”ä¾‹ã‚’è¡¨ç¤º</strong></summary>
<pre><code class="language-python">def add_custom_page(self, pdf, fig):
    """
    ã‚«ã‚¹ã‚¿ãƒ å›³ã‚’ãƒ¬ãƒãƒ¼ãƒˆã«è¿½åŠ 
    
    Parameters
    ----------
    pdf : PdfPages
        PDFãƒšãƒ¼ã‚¸ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
    fig : matplotlib.figure.Figure
        è¿½åŠ ã™ã‚‹å›³
    """
    pdf.savefig(fig, bbox_inches='tight')
    plt.close(fig)

# ã‚¯ãƒ©ã‚¹ã«è¿½åŠ 
AutoReportGenerator.add_custom_page = add_custom_page

# ä½¿ç”¨ä¾‹
reporter = AutoReportGenerator('custom_report.pdf')
with PdfPages(reporter.filename) as pdf:
    # ã‚«ã‚¹ã‚¿ãƒ ãƒšãƒ¼ã‚¸1
    fig1 = plt.figure(figsize=(8.5, 11))
    plt.plot([1, 2, 3], [4, 5, 6])
    plt.title('Custom Plot 1')
    reporter.add_custom_page(pdf, fig1)
    
    # ã‚«ã‚¹ã‚¿ãƒ ãƒšãƒ¼ã‚¸2
    fig2 = plt.figure(figsize=(8.5, 11))
    plt.scatter([1, 2, 3], [6, 5, 4])
    plt.title('Custom Plot 2')
    reporter.add_custom_page(pdf, fig2)

print("Custom report generated")
</code></pre>
</details>
<h3>æ¼”ç¿’4-6: ãƒãƒƒãƒå‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ï¼ˆHardï¼‰</h3>
<p><span class="exercise-label hard">Hard</span> <strong>å•é¡Œ</strong>ï¼šè¤‡æ•°è©¦æ–™ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸€æ‹¬å‡¦ç†ã—ã€çµæœã‚’1ã¤ã®Excelãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆè¤‡æ•°ã‚·ãƒ¼ãƒˆï¼‰ã«ã¾ã¨ã‚ã‚‹ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ä½œæˆã›ã‚ˆã€‚</p>
<details>
<summary><strong>è§£ç­”ä¾‹ã‚’è¡¨ç¤º</strong></summary>
<pre><code class="language-python"># Requirements:
# - Python 3.9+
# - pandas&gt;=2.0.0, &lt;2.2.0

import pandas as pd
from pathlib import Path

def batch_process_samples(data_dir: str, output_file: str = 'batch_results.xlsx'):
    """
    è¤‡æ•°è©¦æ–™ã‚’ä¸€æ‹¬å‡¦ç†
    
    Parameters
    ----------
    data_dir : str
        ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆå„è©¦æ–™ã®ã‚µãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å«ã‚€ï¼‰
    output_file : str
        å‡ºåŠ›Excelãƒ•ã‚¡ã‚¤ãƒ«å
    """
    data_path = Path(data_dir)
    sample_dirs = [d for d in data_path.iterdir() if d.is_dir()]
    
    all_results = []
    
    for sample_dir in sample_dirs:
        sample_name = sample_dir.name
        print(f"Processing: {sample_name}")
        
        try:
            # ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ
            pipeline = EndToEndPipeline(project_name=sample_name)
            results = pipeline.run({
                'four_probe': sample_dir / 'four_probe.csv',
                'hall': sample_dir / 'hall.csv',
                'mh': sample_dir / 'mh.csv'
            })
            
            results['sample_name'] = sample_name
            all_results.append(results)
        
        except Exception as e:
            print(f"  ERROR: {e}")
            continue
    
    # çµæœã‚’Excelã«ä¿å­˜
    with pd.ExcelWriter(output_file, engine='openpyxl') as writer:
        # ã‚µãƒãƒªãƒ¼ã‚·ãƒ¼ãƒˆ
        df_summary = pd.DataFrame(all_results)
        df_summary.to_excel(writer, sheet_name='Summary', index=False)
        
        # å€‹åˆ¥è©¦æ–™ã‚·ãƒ¼ãƒˆ
        for result in all_results:
            sample_name = result['sample_name']
            df_sample = pd.DataFrame([result])
            df_sample.to_excel(writer, sheet_name=sample_name[:31], index=False)  # Excelåˆ¶é™
    
    print(f"\nBatch results saved to: {output_file}")

# ä½¿ç”¨ä¾‹ï¼ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ æƒ³å®šï¼‰
# data/
#   sample1/
#     four_probe.csv
#     hall.csv
#     mh.csv
#   sample2/
#     ...

# batch_process_samples('data/', 'all_samples_results.xlsx')
</code></pre>
</details>
<h3>æ¼”ç¿’4-7: æ©Ÿæ¢°å­¦ç¿’ã‚’ç”¨ã„ãŸç•°å¸¸æ¤œå‡ºï¼ˆHardï¼‰</h3>
<p><span class="exercise-label hard">Hard</span> <strong>å•é¡Œ</strong>ï¼šscikit-learnã®Isolation Forestã‚’ä½¿ã£ã¦ã€M-Hæ›²ç·šã®ç•°å¸¸ãªãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆã‚’æ¤œå‡ºã›ã‚ˆã€‚</p>
<details>
<summary><strong>è§£ç­”ä¾‹ã‚’è¡¨ç¤º</strong></summary>
<pre><code class="language-python"># Requirements:
# - Python 3.9+
# - matplotlib&gt;=3.7.0
# - numpy&gt;=1.24.0, &lt;2.0.0

"""
Example: Hardå•é¡Œï¼šscikit-learnã®Isolation Forestã‚’ä½¿ã£ã¦ã€M-Hæ›²ç·šã®ç•°å¸¸ãªãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆã‚’æ¤œå‡º

Purpose: Demonstrate data visualization techniques
Target: Advanced
Execution time: 2-5 seconds
Dependencies: None
"""

from sklearn.ensemble import IsolationForest
import numpy as np
import matplotlib.pyplot as plt

# M-Hãƒ‡ãƒ¼ã‚¿ç”Ÿæˆï¼ˆä¸€éƒ¨ã«ç•°å¸¸å€¤ï¼‰
H = np.linspace(-5000, 5000, 200)
M = 50 * np.tanh(H / 1000)
M[50:55] += 20  # ç•°å¸¸å€¤è¿½åŠ 
M[150:155] -= 15

# ç‰¹å¾´é‡ä½œæˆï¼ˆH, M, dM/dHï¼‰
dM_dH = np.gradient(M, H)
X = np.column_stack([H, M, dM_dH])

# Isolation Forest
clf = IsolationForest(contamination=0.05, random_state=42)
anomalies = clf.fit_predict(X)

# ãƒ—ãƒ­ãƒƒãƒˆ
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))

# å·¦å›³ï¼šM-Hæ›²ç·š
colors = ['red' if a == -1 else 'blue' for a in anomalies]
ax1.scatter(H, M, c=colors, s=50, alpha=0.7, edgecolors='black')
ax1.set_xlabel('H [Oe]')
ax1.set_ylabel('M [emu/g]')
ax1.set_title('M-H Curve with Anomaly Detection')
ax1.grid(alpha=0.3)

# å³å›³ï¼šç•°å¸¸ã‚¹ã‚³ã‚¢
scores = clf.decision_function(X)
ax2.plot(H, scores, linewidth=2, color='purple')
ax2.axhline(0, color='red', linestyle='--', label='Threshold')
ax2.set_xlabel('H [Oe]')
ax2.set_ylabel('Anomaly Score')
ax2.set_title('Isolation Forest Anomaly Scores')
ax2.legend()
ax2.grid(alpha=0.3)

plt.tight_layout()
plt.show()

print(f"Detected {np.sum(anomalies == -1)} anomalous points out of {len(anomalies)}")
</code></pre>
</details>
<h3>æ¼”ç¿’4-8: å®Ÿé¨“è¨ˆç”»æœ€é©åŒ–ï¼ˆHardï¼‰</h3>
<p><span class="exercise-label hard">Hard</span> <strong>å•é¡Œ</strong>ï¼šæ¸¬å®šæ™‚é–“ã¨ç²¾åº¦ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’è€ƒæ…®ã—ã€æœ€å°é™ã®æ¸¬å®šç‚¹æ•°ã§ç›®æ¨™ç²¾åº¦ï¼ˆèª¤å·® &lt; 5%ï¼‰ã‚’é”æˆã™ã‚‹å®Ÿé¨“è¨ˆç”»ã‚’ææ¡ˆã›ã‚ˆï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ™ãƒ¼ã‚¹ï¼‰ã€‚</p>
<details>
<summary><strong>è§£ç­”ä¾‹ã‚’è¡¨ç¤º</strong></summary>
<p><strong>ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ</strong>ï¼š</p>
<ol>
<li>ç•°ãªã‚‹æ¸¬å®šç‚¹æ•°ï¼ˆN = 10, 20, 50, 100ï¼‰ã§ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ</li>
<li>å„Nã§ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°ç²¾åº¦ã‚’è©•ä¾¡ï¼ˆRÂ²ã€æ®‹å·®æ¨™æº–åå·®ï¼‰</li>
<li>æ¸¬å®šæ™‚é–“ã‚’æ¨å®šï¼ˆ1ç‚¹ = 1åˆ†ã¨ä»®å®šï¼‰</li>
<li>ç²¾åº¦ vs æ™‚é–“ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•æ›²ç·šã‚’ä½œæˆ</li>
</ol>
<pre><code class="language-python">N_range = [10, 20, 30, 50, 100, 200]
fit_quality = []
measurement_time = []

for N in N_range:
    # ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    T = np.linspace(100, 400, N)
    sigma_true = lambda T: 1e4 * np.exp(-0.2 / (8.617e-5 * T))
    sigma_data = sigma_true(T) * (1 + 0.05 * np.random.randn(N))
    
    # ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°
    from scipy.optimize import curve_fit
    def model(T, A, Ea):
        return A * np.exp(-Ea / (8.617e-5 * T))
    
    params, _ = curve_fit(model, T, sigma_data)
    sigma_fit = model(T, *params)
    
    # ç²¾åº¦è©•ä¾¡
    R2 = 1 - np.sum((sigma_data - sigma_fit)**2) / np.sum((sigma_data - np.mean(sigma_data))**2)
    fit_quality.append(R2)
    
    # æ¸¬å®šæ™‚é–“ï¼ˆ1ç‚¹ = 1åˆ†ï¼‰
    measurement_time.append(N * 1)

# ãƒ—ãƒ­ãƒƒãƒˆ
fig, ax = plt.subplots(figsize=(10, 6))
ax.plot(measurement_time, fit_quality, 'o-', linewidth=2.5, markersize=10, color='#f093fb')
ax.axhline(0.95, color='red', linestyle='--', linewidth=2, label='Target RÂ² = 0.95')
ax.set_xlabel('Measurement Time [minutes]', fontsize=12)
ax.set_ylabel('Fit Quality (RÂ²)', fontsize=12)
ax.set_title('Trade-off: Measurement Time vs Accuracy', fontsize=14, fontweight='bold')
ax.legend(fontsize=11)
ax.grid(alpha=0.3)
plt.show()

# æ¨å¥¨æ¸¬å®šç‚¹æ•°
optimal_idx = np.argmin(np.abs(np.array(fit_quality) - 0.95))
print(f"Recommended: N = {N_range[optimal_idx]} points ({measurement_time[optimal_idx]} minutes)")
</code></pre>
</details>
<h2>4.9 Learning Verification</h2>
<p>ä»¥ä¸‹ã®ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆã§ç†è§£åº¦ã‚’ç¢ºèªã—ã¾ã—ã‚‡ã†ï¼š</p>
<h3>Basic Understanding</h3>
<ul>
<li>å®Ÿæ¸¬Instrumentãƒ‡ãƒ¼ã‚¿ã®å¤šæ§˜ãªFormatã‚’ç†è§£ã—ã¦ã„ã‚‹</li>
<li>Can explain the necessity and methods of data cleaning</li>
<li>Understand the integrated significance of four-probe, Hall, and M-H measurements</li>
<li>Can explain the advantages of lmfit fitting</li>
<li>Understand the importance of error propagation</li>
</ul>
<h3>Practical Skills</h3>
<ul>
<li>Multi-Format Data Loaderã‚’å®Ÿè£…ã§ãã‚‹</li>
<li>IQRæ³•ãƒ»Z-scoreæ³•ã§å¤–ã‚Œå€¤ã‚’é™¤å»ã§ãã‚‹</li>
<li>Integrated Analysis Pipelineã‚’æ§‹ç¯‰ã§ãã‚‹</li>
<li>lmfitã§åˆ¶ç´„ä»˜ããƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°ãŒã§ãã‚‹</li>
<li>Can calculate error propagation using uncertainties package</li>
<li>Publication-qualityã®å›³ã‚’ä½œæˆã§ãã‚‹</li>
<li>Automatically generate PDF reports</li>
</ul>
<h3>Application Ability</h3>
<ul>
<li>Can design complete end-to-end pipelines</li>
<li>Can perform anomaly detection using machine learning</li>
<li>å®Ÿé¨“è¨ˆç”»ã‚’æœ€é©åŒ–ã§ãã‚‹ï¼ˆç²¾åº¦ vs æ™‚é–“ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ï¼‰</li>
<li>Can create custom report templates</li>
</ul>
<h2>4.10 References</h2>
<ol>
<li>McKinney, W. (2017). <em>Python for Data Analysis: Data Wrangling with Pandas, NumPy, and IPython</em> (2nd ed.). O'Reilly. - pandasã«ã‚ˆã‚‹ãƒ‡ãƒ¼ã‚¿å‡¦ç†</li>
<li>VanderPlas, J. (2016). <em>Python Data Science Handbook</em>. O'Reilly. - ç§‘å­¦è¨ˆç®—ã®ç·åˆã‚¬ã‚¤ãƒ‰</li>
<li>Newville, M., et al. (2014). <em>LMFIT: Non-Linear Least-Square Minimization and Curve-Fitting for Python</em>. Zenodo. - lmfitãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ</li>
<li>Hunter, J. D. (2007). <em>Matplotlib: A 2D Graphics Environment</em>. Computing in Science &amp; Engineering, 9(3), 90-95. - matplotlibã®åŸè«–æ–‡</li>
<li>Lebigot, E. O. (2010). <em>Uncertainties: a Python package for calculations with uncertainties</em>. - èª¤å·®ä¼æ’­ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸</li>
<li>Pedregosa, F., et al. (2011). <em>Scikit-learn: Machine Learning in Python</em>. Journal of Machine Learning Research, 12, 2825-2830. - scikit-learn</li>
<li>Schroder, D. K. (2006). <em>Semiconductor Material and Device Characterization</em> (3rd ed.). Wiley. - æ¸¬å®šãƒ‡ãƒ¼ã‚¿è§£æã®å®Ÿè·µ</li>
</ol>
<h2>4.11 Summary and Next Steps</h2>
<p>ã“ã®ç« ã§ã¯ã€å®Ÿé¨“ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã‹ã‚‰æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã¾ã§ã®å®Œå…¨ãªPythonãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’å­¦ã³ã¾ã—ãŸã€‚ã“ã‚Œã§ã€é›»æ°—ãƒ»ç£æ°—æ¸¬å®šã®<strong>å…¨å·¥ç¨‹ã‚’è‡ªå‹•åŒ–</strong>ã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã—ãŸã€‚</p>
<p><strong>ã‚·ãƒªãƒ¼ã‚ºå…¨ä½“ã®ç¿’å¾—å†…å®¹</strong>ï¼š</p>
<ul>
<li><strong>ç¬¬1ç« </strong>ï¼šå››ç«¯å­æ³•ã€van der Pauwæ³•ã€æ¸©åº¦ä¾å­˜æ€§æ¸¬å®š</li>
<li><strong>ç¬¬2ç« </strong>ï¼šHallåŠ¹æœã€ã‚­ãƒ£ãƒªã‚¢å¯†åº¦ãƒ»ç§»å‹•åº¦æ±ºå®šã€two-band model</li>
<li><strong>ç¬¬3ç« </strong>ï¼šVSM/SQUIDç£æ°—æ¸¬å®šã€M-Hæ›²ç·šè§£æã€FC/ZFC</li>
<li><strong>Chapter 4</strong>ï¼šçµ±åˆãƒ‡ãƒ¼ã‚¿è§£æãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã€Automated Report Generation</li>
</ul>
<p><strong>Next Steps</strong>ï¼š</p>
<ul>
<li>Execute pipeline with actual measurement data</li>
<li>Build material property prediction models using machine learning</li>
<li>Integration with real-time measurement systems</li>
<li>Webã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³åŒ–ï¼ˆStreamlitã€Dashï¼‰</li>
</ul>
<div class="navigation">
<a class="nav-button" href="chapter-3.html">â† ç¬¬3ç« ï¼šç£æ°—æ¸¬å®š</a>
<a class="nav-button" href="index.html">Back to Contents</a>
<a class="nav-button" href="index.html">ã‚·ãƒªãƒ¼ã‚ºå®Œäº† ğŸ‰</a>
</div>
</main>
<section class="disclaimer">
<h3>Disclaimer</h3>
<ul>
<li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯æ•™è‚²ãƒ»ç ”ç©¶ãƒ»æƒ…å ±æä¾›ã®ã¿ã‚’ç›®çš„ã¨ã—ã¦ãŠã‚Šã€å°‚é–€çš„ãªåŠ©è¨€ï¼ˆæ³•å¾‹ãƒ»ä¼šè¨ˆãƒ»æŠ€è¡“çš„ä¿è¨¼ãªã©ï¼‰ã‚’æä¾›ã™ã‚‹ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚</li>
<li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŠã‚ˆã³ä»˜éšã™ã‚‹ã‚³ãƒ¼ãƒ‰ä¾‹ã¯ã€Œç¾çŠ¶æœ‰å§¿ï¼ˆAS ISï¼‰ã€ã§æä¾›ã•ã‚Œã€æ˜ç¤ºã¾ãŸã¯é»™ç¤ºã‚’å•ã‚ãšã€å•†å“æ€§ã€ç‰¹å®šç›®çš„é©åˆæ€§ã€æ¨©åˆ©éä¾µå®³ã€æ­£ç¢ºæ€§ãƒ»å®Œå…¨æ€§ã€å‹•ä½œãƒ»å®‰å…¨æ€§ç­‰ã„ã‹ãªã‚‹ä¿è¨¼ã‚‚ã—ã¾ã›ã‚“ã€‚</li>
<li>å¤–éƒ¨ãƒªãƒ³ã‚¯ã€ç¬¬ä¸‰è€…ãŒæä¾›ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ»ãƒ„ãƒ¼ãƒ«ãƒ»ãƒ©ã‚¤ãƒ–ãƒ©ãƒªç­‰ã®å†…å®¹ãƒ»å¯ç”¨æ€§ãƒ»å®‰å…¨æ€§ã«ã¤ã„ã¦ã€AuthorãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯ä¸€åˆ‡ã®è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚</li>
<li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®åˆ©ç”¨ãƒ»å®Ÿè¡Œãƒ»è§£é‡ˆã«ã‚ˆã‚Šç›´æ¥çš„ãƒ»é–“æ¥çš„ãƒ»ä»˜éšçš„ãƒ»ç‰¹åˆ¥ãƒ»çµæœçš„ãƒ»æ‡²ç½°çš„æå®³ãŒç”Ÿã˜ãŸå ´åˆã§ã‚‚ã€é©ç”¨æ³•ã§è¨±å®¹ã•ã‚Œã‚‹æœ€å¤§é™ã®ç¯„å›²ã§ã€AuthorãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚</li>
<li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å†…å®¹ã¯ã€äºˆå‘Šãªãå¤‰æ›´ãƒ»æ›´æ–°ãƒ»æä¾›åœæ­¢ã•ã‚Œã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚</li>
<li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®è‘—ä½œæ¨©ãƒ»Licenseã¯æ˜è¨˜ã•ã‚ŒãŸæ¡ä»¶ï¼ˆä¾‹: CC BY 4.0ï¼‰ã«å¾“ã„ã¾ã™ã€‚å½“è©²Licenseã¯é€šå¸¸ã€ç„¡ä¿è¨¼æ¡é …ã‚’å«ã¿ã¾ã™ã€‚</li>
</ul>
</section>
<footer>
<p><strong>Author</strong>: MS Knowledge Hub Content Team</p>
<p><strong>Version</strong>: 1.0 | <strong>Created</strong>: 2025-10-28</p>
<p><strong>License</strong>: Creative Commons BY 4.0</p>
<p>Â© 2025 MS Terakoya. All rights reserved.</p>
</footer>
</body>
</html>
