<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>Chapter 1: Fundamentals of Vectors and Matrices | Linear Algebra and Tensor Analysis</title>
<meta content="Learn vector operations, dot and cross products, basic matrix operations, inverse matrices, and NumPy implementation." name="description"/>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\(', '\)']],
                displayMath: [['$$', '$$'], ['\[', '\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
                ignoreHtmlClass: 'mermaid'
            }
        };
    </script>
<script async="" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<link href="../../assets/css/knowledge-base.css" rel="stylesheet"/>
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css" rel="stylesheet"/>
</head>
<body><div class="locale-switcher">
<span class="current-locale">üåê EN</span>
<span class="locale-separator">|</span>
<a href="../../../jp/FM/linear-algebra-tensor/chapter-1.html" class="locale-link">üáØüáµ JP</a>
<span class="locale-separator">|</span>
<span class="locale-meta">Last sync: 2025-11-16</span>
</div>
<header>
<h1>Chapter 1: Fundamentals of Vectors and Matrices</h1>
<p class="subtitle">Vectors and Matrices Fundamentals</p>
</header>
<div class="container">
<div class="breadcrumb">
<a href="../index.html">Fundamentals of Mathematics Dojo</a> &gt;
            <a href="index.html">Linear Algebra and Tensor Analysis</a> &gt;
            Chapter 1
        </div>
<div class="content">
<h2>1.1 Vector Fundamentals</h2>
<div class="definition">
<strong>Definition: Vector</strong><br/>
                An n-dimensional vector is a set of n numbers:
                \[\mathbf{v} = \begin{pmatrix} v_1 \\ v_2 \\ \vdots \\ v_n \end{pmatrix}\]
                Represents quantities with magnitude and direction (position, velocity, force, etc.).
            </div>
<h3>Code Example 1: Vector Operations with NumPy</h3>
<div class="code-title">Python Implementation: Vector Operations with NumPy</div>
<div class="code-example"><pre><code class="language-python"># Requirements:
# - Python 3.9+
# - matplotlib&gt;=3.7.0
# - numpy&gt;=1.24.0, &lt;2.0.0

"""
Example: Code Example 1: Vector Operations with NumPy

Purpose: Demonstrate data visualization techniques
Target: Beginner to Intermediate
Execution time: 2-5 seconds
Dependencies: None
"""

import numpy as np
import matplotlib.pyplot as plt

# Define vectors
v1 = np.array([3, 2])
v2 = np.array([1, 4])

# Vector operations
v_sum = v1 + v2      # Sum
v_diff = v1 - v2     # Difference
v_scalar = 2 * v1    # Scalar multiplication

print("Vector Operations:")
print(f"v1 = {v1}")
print(f"v2 = {v2}")
print(f"v1 + v2 = {v_sum}")
print(f"v1 - v2 = {v_diff}")
print(f"2 * v1 = {v_scalar}")

# Visualization
fig, ax = plt.subplots(figsize=(8, 8))
origin = [0, 0]

# Draw vectors as arrows
ax.quiver(*origin, *v1, angles='xy', scale_units='xy', scale=1, color='blue', width=0.01, label='v1')
ax.quiver(*origin, *v2, angles='xy', scale_units='xy', scale=1, color='red', width=0.01, label='v2')
ax.quiver(*origin, *v_sum, angles='xy', scale_units='xy', scale=1, color='green', width=0.01, label='v1+v2')

# Display parallelogram law
ax.plot([v1[0], v_sum[0]], [v1[1], v_sum[1]], 'k--', alpha=0.3)
ax.plot([v2[0], v_sum[0]], [v2[1], v_sum[1]], 'k--', alpha=0.3)

ax.set_xlim(-1, 6)
ax.set_ylim(-1, 7)
ax.set_xlabel('x')
ax.set_ylabel('y')
ax.set_title('Vector Addition')
ax.legend()
ax.grid(True, alpha=0.3)
ax.axhline(y=0, color='k', linewidth=0.5)
ax.axvline(x=0, color='k', linewidth=0.5)
plt.axis('equal')
plt.show()</code></pre></div>
<h2>1.2 Dot Product and Norm</h2>
<div class="definition">
<strong>Definition: Dot Product and Norm</strong><br/>
                Dot product of vectors v, w:
                \[\mathbf{v} \cdot \mathbf{w} = \sum_{i=1}^n v_i w_i = v_1 w_1 + v_2 w_2 + \cdots + v_n w_n\]
                Norm (length):
                \[\|\mathbf{v}\| = \sqrt{\mathbf{v} \cdot \mathbf{v}} = \sqrt{v_1^2 + v_2^2 + \cdots + v_n^2}\]
            </div>
<h3>Code Example 2: Calculating Dot Product and Norm</h3>
<div class="code-block"># Calculate dot product
dot_product = np.dot(v1, v2)
# or v1 @ v2

# Calculate norm
norm_v1 = np.linalg.norm(v1)
norm_v2 = np.linalg.norm(v2)

# Calculate angle: cos Œ∏ = (v¬∑w) / (||v|| ||w||)
cos_theta = dot_product / (norm_v1 * norm_v2)
theta_rad = np.arccos(cos_theta)
theta_deg = np.degrees(theta_rad)

print(f"\nDot Product and Angle:")
print(f"v1 ¬∑ v2 = {dot_product}")
print(f"||v1|| = {norm_v1:.4f}")
print(f"||v2|| = {norm_v2:.4f}")
print(f"Angle between v1 and v2: {theta_deg:.2f}¬∞")

# Unit vector (normalization)
v1_unit = v1 / norm_v1
v2_unit = v2 / norm_v2
print(f"\nUnit vector of v1: {v1_unit}")
print(f"Norm of unit vector: {np.linalg.norm(v1_unit):.10f}")</div>
<h2>1.3 Cross Product (3D)</h2>
<div class="definition">
<strong>Definition: Cross Product</strong><br/>
                Cross product of 3D vectors v, w:
                \[\mathbf{v} \times \mathbf{w} = \begin{pmatrix} v_2 w_3 - v_3 w_2 \\ v_3 w_1 - v_1 w_3 \\ v_1 w_2 - v_2 w_1 \end{pmatrix}\]
                Result is a vector perpendicular to both v and w.
            </div>
<h3>Code Example 3: Calculating and Visualizing Cross Product</h3>
<div class="code-block">from mpl_toolkits.mplot3d import Axes3D

# 3D vectors
v_3d = np.array([1, 0, 0])
w_3d = np.array([0, 1, 0])

# Calculate cross product
cross_product = np.cross(v_3d, w_3d)

print("Cross Product Calculation:")
print(f"v = {v_3d}")
print(f"w = {w_3d}")
print(f"v √ó w = {cross_product}")
print(f"||v √ó w|| = {np.linalg.norm(cross_product):.4f}")

# Verify v √ó w is perpendicular to v and w
print(f"\nPerpendicularity Check:")
print(f"(v √ó w) ¬∑ v = {np.dot(cross_product, v_3d):.10f}")
print(f"(v √ó w) ¬∑ w = {np.dot(cross_product, w_3d):.10f}")

# 3D visualization
fig = plt.figure(figsize=(10, 8))
ax = fig.add_subplot(111, projection='3d')

origin = [0, 0, 0]
ax.quiver(*origin, *v_3d, color='blue', arrow_length_ratio=0.1, linewidth=2, label='v')
ax.quiver(*origin, *w_3d, color='red', arrow_length_ratio=0.1, linewidth=2, label='w')
ax.quiver(*origin, *cross_product, color='green', arrow_length_ratio=0.1, linewidth=2, label='v√ów')

ax.set_xlim([-0.5, 1.5])
ax.set_ylim([-0.5, 1.5])
ax.set_zlim([-0.5, 1.5])
ax.set_xlabel('X')
ax.set_ylabel('Y')
ax.set_zlabel('Z')
ax.set_title('Cross Product: v √ó w')
ax.legend()
plt.show()</div>
<h2>1.4 Basic Matrix Operations</h2>
<div class="definition">
<strong>Definition: Matrix</strong><br/>
                An m √ó n matrix is an array of numbers with m rows and n columns:
                \[A = \begin{pmatrix} a_{11} &amp; a_{12} &amp; \cdots &amp; a_{1n} \\ a_{21} &amp; a_{22} &amp; \cdots &amp; a_{2n} \\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ a_{m1} &amp; a_{m2} &amp; \cdots &amp; a_{mn} \end{pmatrix}\]
            </div>
<h3>Code Example 4: Basic Matrix Operations</h3>
<div class="code-block"># Define matrices
A = np.array([[1, 2, 3],
              [4, 5, 6]])

B = np.array([[7, 8],
              [9, 10],
              [11, 12]])

print("Matrix Operations:")
print(f"A (2√ó3) =\n{A}\n")
print(f"B (3√ó2) =\n{B}\n")

# Transpose matrix
A_T = A.T
print(f"A^T (transpose) =\n{A_T}\n")

# Matrix product (2√ó3) √ó (3√ó2) = (2√ó2)
C = A @ B  # or np.dot(A, B)
print(f"A √ó B (2√ó2) =\n{C}\n")

# Element-wise operations
D = A + A  # Addition if same shape
E = 2 * A  # Scalar multiplication
print(f"A + A =\n{D}\n")
print(f"2 * A =\n{E}")</div>
<h2>1.5 Special Matrices</h2>
<h3>Code Example 5: Identity Matrix, Zero Matrix, Diagonal Matrix</h3>
<div class="code-block"># Identity matrix (diagonal elements are 1)
I = np.eye(3)
print("Identity Matrix I (3√ó3):")
print(I)

# Zero matrix
Z = np.zeros((2, 3))
print(f"\nZero Matrix O (2√ó3):\n{Z}")

# Diagonal matrix
diag_values = [1, 2, 3]
D_diag = np.diag(diag_values)
print(f"\nDiagonal Matrix D:\n{D_diag}")

# Extract diagonal elements of matrix
A_square = np.array([[1, 2, 3],
                     [4, 5, 6],
                     [7, 8, 9]])
diag_A = np.diag(A_square)
print(f"\nDiagonal elements of A: {diag_A}")

# Trace (sum of diagonal elements)
trace_A = np.trace(A_square)
print(f"tr(A) = {trace_A}")</div>
<h2>1.6 Inverse Matrix</h2>
<div class="definition">
<strong>Definition: Inverse Matrix</strong><br/>
                For square matrix A, A‚Åª¬π satisfying AA‚Åª¬π = A‚Åª¬πA = I is called the inverse matrix.
                Inverse exists ‚áî det(A) ‚â† 0 (non-singular matrix)
            </div>
<h3>Code Example 6: Calculating Inverse Matrix</h3>
<div class="code-block"># Non-singular matrix
A_inv = np.array([[1, 2],
                  [3, 4]])

# Calculate inverse
A_inverse = np.linalg.inv(A_inv)

print("Inverse Matrix Calculation:")
print(f"A =\n{A_inv}\n")
print(f"A^(-1) =\n{A_inverse}\n")

# Verification: A √ó A^(-1) = I
product = A_inv @ A_inverse
print(f"A √ó A^(-1) =\n{product}\n")
print(f"Close to identity matrix: {np.allclose(product, np.eye(2))}")

# Determinant
det_A = np.linalg.det(A_inv)
print(f"\ndet(A) = {det_A:.4f}")
print(f"det(A) ‚â† 0 so inverse exists ‚úì")</div>
<h2>1.7 Geometric Meaning of Linear Transformations</h2>
<h3>Code Example 7: Rotation Matrix</h3>
<div class="code-block"># Rotation matrix: rotate counterclockwise by Œ∏
def rotation_matrix(theta):
    """2D rotation matrix"""
    cos_t = np.cos(theta)
    sin_t = np.sin(theta)
    return np.array([[cos_t, -sin_t],
                     [sin_t,  cos_t]])

# 45 degree rotation
theta = np.pi / 4  # 45 degrees
R = rotation_matrix(theta)

print(f"45 Degree Rotation Matrix:")
print(R)

# Original vectors
points = np.array([[1, 0], [0, 1], [1, 1], [0, 0]])

# Rotated vectors
rotated_points = points @ R.T

# Visualization
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))

# Original shape
ax1.plot([0, 1], [0, 0], 'b-', linewidth=2, marker='o')
ax1.plot([0, 0], [0, 1], 'r-', linewidth=2, marker='o')
ax1.set_xlim(-1.5, 1.5)
ax1.set_ylim(-1.5, 1.5)
ax1.set_xlabel('x')
ax1.set_ylabel('y')
ax1.set_title('Original Shape')
ax1.grid(True, alpha=0.3)
ax1.axhline(y=0, color='k', linewidth=0.5)
ax1.axvline(x=0, color='k', linewidth=0.5)
ax1.axis('equal')

# Rotated shape
ax2.plot([0, rotated_points[0,0]], [0, rotated_points[0,1]], 'b-', linewidth=2, marker='o')
ax2.plot([0, rotated_points[1,0]], [0, rotated_points[1,1]], 'r-', linewidth=2, marker='o')
ax2.set_xlim(-1.5, 1.5)
ax2.set_ylim(-1.5, 1.5)
ax2.set_xlabel('x')
ax2.set_ylabel('y')
ax2.set_title('After 45¬∞ Rotation')
ax2.grid(True, alpha=0.3)
ax2.axhline(y=0, color='k', linewidth=0.5)
ax2.axvline(x=0, color='k', linewidth=0.5)
ax2.axis('equal')

plt.tight_layout()
plt.show()</div>
<h3>Code Example 8: Scaling and Shear</h3>
<div class="code-block"># Scaling matrix (expansion/contraction)
S = np.array([[2, 0],
              [0, 0.5]])

# Shear matrix
Sh = np.array([[1, 0.5],
               [0, 1]])

# Square vertices
square = np.array([[0, 0], [1, 0], [1, 1], [0, 1], [0, 0]])

# After transformation
scaled = square @ S.T
sheared = square @ Sh.T

fig, axes = plt.subplots(1, 3, figsize=(15, 5))

# Original shape
axes[0].plot(square[:,0], square[:,1], 'b-', linewidth=2)
axes[0].fill(square[:,0], square[:,1], alpha=0.3)
axes[0].set_title('Original Square')
axes[0].set_xlim(-0.5, 2.5)
axes[0].set_ylim(-0.5, 2.5)
axes[0].grid(True, alpha=0.3)
axes[0].axis('equal')

# Scaling
axes[1].plot(scaled[:,0], scaled[:,1], 'r-', linewidth=2)
axes[1].fill(scaled[:,0], scaled[:,1], alpha=0.3, color='red')
axes[1].set_title('Scaling (2x, 0.5x)')
axes[1].set_xlim(-0.5, 2.5)
axes[1].set_ylim(-0.5, 2.5)
axes[1].grid(True, alpha=0.3)
axes[1].axis('equal')

# Shear
axes[2].plot(sheared[:,0], sheared[:,1], 'g-', linewidth=2)
axes[2].fill(sheared[:,0], sheared[:,1], alpha=0.3, color='green')
axes[2].set_title('Shear')
axes[2].set_xlim(-0.5, 2.5)
axes[2].set_ylim(-0.5, 2.5)
axes[2].grid(True, alpha=0.3)
axes[2].axis('equal')

plt.tight_layout()
plt.show()

print("Linear Transformations:")
print(f"Scaling Matrix:\n{S}")
print(f"\nShear Matrix:\n{Sh}")</div>
<h2>Summary</h2>
<ul>
<li>Vectors are quantities with magnitude and direction, efficiently handled as NumPy arrays</li>
<li>Dot product is used for angle calculations, cross product generates perpendicular vectors</li>
<li>Matrices represent linear transformations, unifying rotation, scaling, and shear operations</li>
<li>Inverse matrices are essential for solving linear equations and inverse operations</li>
<li>NumPy linear algebra functions enable concise implementation of complex operations</li>
</ul>
<div class="nav-buttons">
<a class="nav-button" href="index.html">‚Üê Series Top</a>
<a class="nav-button" href="chapter-2.html">Chapter 2: Determinants and Linear Systems ‚Üí</a>
</div>
</div>
</div>
<section class="disclaimer">
<h3>Disclaimer</h3>
<ul>
<li>This content is provided solely for educational, research, and informational purposes and does not constitute professional advice (legal, accounting, technical warranty, etc.).</li>
<li>This content and accompanying code examples are provided "AS IS" without any warranty, express or implied, including but not limited to merchantability, fitness for a particular purpose, non-infringement, accuracy, completeness, operation, or safety.</li>
<li>The author and Tohoku University assume no responsibility for the content, availability, or safety of external links, third-party data, tools, libraries, etc.</li>
<li>To the maximum extent permitted by applicable law, the author and Tohoku University shall not be liable for any direct, indirect, incidental, special, consequential, or punitive damages arising from the use, execution, or interpretation of this content.</li>
<li>The content may be changed, updated, or discontinued without notice.</li>
<li>The copyright and license of this content are subject to the stated conditions (e.g., CC BY 4.0). Such licenses typically include no-warranty clauses.</li>
</ul>
</section>

<footer>
<p>¬© 2025 AI Terakoya - Fundamentals of Mathematics Dojo</p>
</footer>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
</body>
</html>
