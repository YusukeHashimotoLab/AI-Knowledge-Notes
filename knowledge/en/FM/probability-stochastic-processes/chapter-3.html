<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Chapter 3: Markov Processes and Poisson Processes | Probability Theory and Stochastic Processes</title>
    <meta name="description" content="Markov chainã€transition probability matrixã€stationary distributionã€Poisson processã€Applications to Process Engineeringã‚’å­¦ã³.">
            <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif; line-height: 1.8; color: #333; background: #f5f5f5; }
        header { background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 1.5rem; text-align: center; }
        h1 { font-size: 1.8rem; margin-bottom: 0.5rem; }
        .subtitle { opacity: 0.9; }
        .container { max-width: 900px; margin: 2rem auto; padding: 0 1rem; }
        .breadcrumb { margin-bottom: 1.5rem; font-size: 0.9rem; }
        .breadcrumb a { color: #667eea; text-decoration: none; }
        .content { background: white; padding: 2.5rem; border-radius: 12px; box-shadow: 0 2px 8px rgba(0,0,0,0.1); margin-bottom: 2rem; }
        h2 { color: #667eea; margin: 2rem 0 1rem 0; padding-bottom: 0.5rem; border-bottom: 2px solid #e0e0e0; }
        h3 { color: #764ba2; margin: 1.5rem 0 0.8rem 0; }
        .definition { background: #e7f3ff; border-left: 4px solid #667eea; padding: 1rem 1.5rem; margin: 1.5rem 0; border-radius: 4px; }
        .theorem { background: #f3e5f5; border-left: 4px solid #764ba2; padding: 1rem 1.5rem; margin: 1.5rem 0; border-radius: 4px; }
        .example { background: #fff3e0; border-left: 4px solid #ff9800; padding: 1rem 1.5rem; margin: 1.5rem 0; border-radius: 4px; }
        .code-title {
            background: #667eea;
            color: white;
            padding: 0.5rem 1rem;
            border-radius: 6px 6px 0 0;
            font-weight: 600;
            margin-top: 1.5rem;
        }
        .code-example {
            background: #1e1e1e;
            color: #d4d4d4;
            padding: 1.5rem;
            border-radius: 0 0 8px 8px;
            overflow-x: auto;
            margin: 0 0 1rem 0;
            font-family: 'Courier New', monospace;
            font-size: 0.9rem;
            line-height: 1.6;
            white-space: pre-wrap;
        }
        .code-block {
            background: #1e1e1e;
            color: #d4d4d4;
            padding: 1.5rem;
            border-radius: 8px;
            overflow-x: auto;
            margin: 1rem 0;
            font-family: 'Courier New', monospace;
            font-size: 0.9rem;
            line-height: 1.6;
            white-space: pre-wrap;
        }
        .code-block code {
            font-family: 'Courier New', monospace;
            font-size: 0.9rem;
            line-height: 1.6;
            white-space: pre-wrap;
        }
        .output { background: #f8f9fa; border: 1px solid #dee2e6; padding: 1rem; border-radius: 6px; margin: 1rem 0; font-family: monospace; font-size: 0.9rem; }
        table { width: 100%; border-collapse: collapse; margin: 1.5rem 0; }
        th, td { padding: 0.8rem; text-align: left; border: 1px solid #ddd; }
        th { background: #667eea; color: white; }
        .note { background: #fff3cd; border-left: 4px solid #ffc107; padding: 1rem 1.5rem; margin: 1.5rem 0; border-radius: 4px; }
        .exercise { background: #d4edda; border-left: 4px solid #28a745; padding: 1rem 1.5rem; margin: 1.5rem 0; border-radius: 4px; }
        .nav-buttons { display: flex; justify-content: space-between; margin: 2rem 0; }
        .nav-button { padding: 0.8rem 1.5rem; background: #667eea; color: white; text-decoration: none; border-radius: 6px; font-weight: 600; }
        .nav-button:hover { background: #764ba2; }
        footer { background: #2c3e50; color: white; text-align: center; padding: 2rem 1rem; margin-top: 3rem; }
        @media (max-width: 768px) { .content { padding: 1.5rem; } h1 { font-size: 1.5rem; } }
    </style>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>
    <header>
        <h1>Chapter 3: Markov Processes and Poisson Processes</h1>
        <p class="subtitle">Markov Processes and Poisson Processes</p>
    </header>

    <div class="container">
                <div class="breadcrumb">
            <a href="../index.html">Fundamentals of Mathematics</a> &gt;
            <a href="index.html">ç¢ºç‡è«–ã¨ç¢ºç‡éç¨‹</a> &gt;
            Chapter 3
        </div>

        <div class="content">
            <h2>3.1 Fundamentals of Markov Chains</h2>

            <div class="definition">
                <strong>ğŸ“ Definition: Markov chainï¼ˆMarkov Chainï¼‰</strong><br>
                ç¢ºç‡éç¨‹ \(\{X_n\}_{n=0,1,2,\ldots}\) ãŒ<strong>Markov chain</strong>ã§ã‚ã‚‹ã¨ is æ¬¡ã®æ€§è³ªã‚’æº€ãŸã™ã“ã¨ã§ã™ï¼š

                \[P(X_{n+1} = j \mid X_n = i, X_{n-1} = i_{n-1}, \ldots, X_0 = i_0) = P(X_{n+1} = j \mid X_n = i)\]

                ã“ã‚Œã‚’<strong>ãƒãƒ«ã‚³ãƒ•æ€§</strong>ï¼ˆmemoryless propertyï¼‰ã¨ã„ã„ã¾ã™ï¼šæœªæ¥ã¯ç¾åœ¨ã®çŠ¶æ…‹ã®ã¿ã«ä¾å­˜ã—ã€éå»ã®å±¥æ­´ã«ã¯ä¾å­˜ã—ã¾ã›ã‚“ã€‚

                <strong>transition probability:</strong>
                \[p_{ij} = P(X_{n+1} = j \mid X_n = i)\]

                <strong>transition probability matrix:</strong>
                \[P = (p_{ij}), \quad \sum_{j} p_{ij} = 1 \text{ for all } i\]
            </div>

            <h3>ğŸ’» Code Example1: é›¢æ•£Simulation of Markov Chains</h3>
            <div class="code-block">import numpy as np
import matplotlib.pyplot as plt
from scipy.linalg import eig

# 3çŠ¶æ…‹Markov chainã®ä¾‹ï¼šå¤©æ°—ãƒ¢ãƒ‡ãƒ«ï¼ˆæ™´ã‚Œã€æ›‡ã‚Šã€é›¨ï¼‰
states = ['æ™´ã‚Œ', 'æ›‡ã‚Š', 'é›¨']
n_states = len(states)

# transition probability matrix
# P[i,j] = P(æ˜æ—¥ã®å¤©æ°—=j | ä»Šæ—¥ã®å¤©æ°—=i)
P = np.array([
    [0.7, 0.2, 0.1],  # æ™´ã‚Œ â†’ æ™´ã‚Œ/æ›‡ã‚Š/é›¨
    [0.3, 0.4, 0.3],  # æ›‡ã‚Š â†’ æ™´ã‚Œ/æ›‡ã‚Š/é›¨
    [0.2, 0.3, 0.5]   # é›¨ â†’ æ™´ã‚Œ/æ›‡ã‚Š/é›¨
])

print("transition probability matrix P:")
print(P)
print(f"\nå„è¡Œã®å’Œï¼ˆç¢ºç‡ã®å’Œ=1ï¼‰: {P.sum(axis=1)}")

# Simulation of Markov Chains
def simulate_markov_chain(P, initial_state, n_steps):
    """Simulation of Markov Chains"""
    n_states = P.shape[0]
    states_sequence = [initial_state]
    current_state = initial_state

    for _ in range(n_steps):
        # ç¾åœ¨ã®çŠ¶æ…‹ã‹ã‚‰æ¬¡ã®çŠ¶æ…‹ã‚’ç¢ºç‡çš„ã«é¸æŠ
        next_state = np.random.choice(n_states, p=P[current_state])
        states_sequence.append(next_state)
        current_state = next_state

    return states_sequence

# simulationå®Ÿè¡Œ
np.random.seed(42)
n_days = 100
initial_state = 0  # æœ€åˆã¯æ™´ã‚Œ

trajectory = simulate_markov_chain(P, initial_state, n_days)

# visualization
fig, axes = plt.subplots(2, 1, figsize=(14, 8))

# (1) çŠ¶æ…‹ã®time series
time = np.arange(len(trajectory))
axes[0].step(time, trajectory, where='post', color='#667eea', linewidth=2)
axes[0].set_yticks([0, 1, 2])
axes[0].set_yticklabels(states)
axes[0].set_xlabel('æ—¥æ•°', fontsize=11)
axes[0].set_ylabel('å¤©æ°—', fontsize=11)
axes[0].set_title('Markov chainã«ã‚ˆã‚‹å¤©æ°—ã®æ¨ç§»', fontsize=12, fontweight='bold')
axes[0].grid(alpha=0.3)
axes[0].set_xlim([0, n_days])

# (2) å„çŠ¶æ…‹ã®å‡ºç¾é »åº¦
state_counts = [trajectory.count(i) for i in range(n_states)]
state_freqs = np.array(state_counts) / len(trajectory)

x_pos = np.arange(n_states)
axes[1].bar(x_pos, state_freqs, color='#667eea', alpha=0.7, edgecolor='black')
axes[1].set_xticks(x_pos)
axes[1].set_xticklabels(states)
axes[1].set_ylabel('ç›¸å¯¾é »åº¦', fontsize=11)
axes[1].set_title('å„çŠ¶æ…‹ã®å‡ºç¾é »åº¦', fontsize=12, fontweight='bold')
axes[1].grid(axis='y', alpha=0.3)

plt.tight_layout()
plt.show()

print(f"\nå„çŠ¶æ…‹ã®å‡ºç¾é »åº¦:")
for i, state in enumerate(states):
    print(f"  {state}: {state_freqs[i]:.4f} ({state_counts[i]}/{len(trajectory)}æ—¥)")</div>

            <div class="output">transition probability matrix P:
[[0.7 0.2 0.1]
 [0.3 0.4 0.3]
 [0.2 0.3 0.5]]

å„è¡Œã®å’Œï¼ˆç¢ºç‡ã®å’Œ=1ï¼‰: [1. 1. 1.]

å„çŠ¶æ…‹ã®å‡ºç¾é »åº¦:
  æ™´ã‚Œ: 0.4653 (47/101æ—¥)
  æ›‡ã‚Š: 0.2970 (30/101æ—¥)
  é›¨: 0.2376 (24/101æ—¥)</div>

            <h2>3.2 Transition Probability Matrix and Stationary Distribution</h2>

            <div class="theorem">
                <strong>ğŸ“Š Theorem: stationary distribution</strong><br>
                ç¢ºç‡ãƒ™ã‚¯ãƒˆãƒ« \(\pi = (\pi_1, \pi_2, \ldots, \pi_n)\) ãŒ<strong>stationary distribution</strong>ã§ã‚ã‚‹ã¨ã¯ï¼š

                \[\pi P = \pi, \quad \sum_i \pi_i = 1, \quad \pi_i \geq 0\]

                ã‚’æº€ãŸã™ã“ã¨.stationary distributionã¯transition probability matrix \(P\) ã®å›ºæœ‰å€¤1ã«å¯¾å¿œã™ã‚‹å·¦å›ºæœ‰ãƒ™ã‚¯ãƒˆãƒ«.

                <strong>ã‚¨ãƒ«ã‚´ãƒ¼ãƒ‰å®šç†:</strong> æ—¢ç´„ã‹ã¤éå‘¨æœŸçš„ãªMarkov chain is å”¯ä¸€ã®stationary distribution \(\pi\) ã«åæŸã—ã¾ã™ï¼š
                \[\lim_{n \to \infty} P^n = \begin{pmatrix} \pi \\ \pi \\ \vdots \\ \pi \end{pmatrix}\]
            </div>

            <h3>ğŸ’» Code Example2: Transition Probability Matrix and Stationary Distributionã®è¨ˆç®—</h3>
            <div class="code-block"># stationary distributionã®è¨ˆç®—ï¼ˆå›ºæœ‰å€¤å•é¡Œã¨ã—ã¦è§£ãï¼‰
def compute_stationary_distribution(P):
    """transition probability matrixPã®stationary distributionã‚’è¨ˆç®—"""
    # P^T ã®å›ºæœ‰å€¤ãƒ»å›ºæœ‰ãƒ™ã‚¯ãƒˆãƒ«ã‚’è¨ˆç®—
    eigenvalues, eigenvectors = eig(P.T)

    # å›ºæœ‰å€¤1ã«å¯¾å¿œã™ã‚‹å›ºæœ‰ãƒ™ã‚¯ãƒˆãƒ«ã‚’æ¢ã™
    idx = np.argmin(np.abs(eigenvalues - 1))
    stationary = np.real(eigenvectors[:, idx])

    # æ­£è¦åŒ–ï¼ˆå’Œ=1ï¼‰
    stationary = stationary / stationary.sum()

    return stationary

# å¤©æ°—ãƒ¢ãƒ‡ãƒ«ã®stationary distribution
pi_stationary = compute_stationary_distribution(P)

print("stationary distributionã®è¨ˆç®—:")
print("="*60)
for i, state in enumerate(states):
    print(f"  Ï€({state}) = {pi_stationary[i]:.6f}")

# verification: Ï€ * P = Ï€
pi_P = pi_stationary @ P
print(f"\nverification: Ï€ * P = Ï€")
print(f"  Ï€ * P = {pi_P}")
print(f"  Ï€     = {pi_stationary}")
print(f"  error  = {np.linalg.norm(pi_P - pi_stationary):.10f}")

# é•·æœŸçš„ãªæŒ™å‹•: P^n ã®è¨ˆç®—
n_steps = [1, 5, 10, 20, 50, 100]

fig, axes = plt.subplots(2, 3, figsize=(15, 10))
axes = axes.flatten()

for idx, n in enumerate(n_steps):
    P_n = np.linalg.matrix_power(P, n)

    # ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—
    im = axes[idx].imshow(P_n, cmap='Blues', vmin=0, vmax=1)
    axes[idx].set_xticks(range(n_states))
    axes[idx].set_yticks(range(n_states))
    axes[idx].set_xticklabels(states, rotation=45)
    axes[idx].set_yticklabels(states)
    axes[idx].set_title(f'P^{n}', fontsize=12, fontweight='bold')

    # æ•°å€¤ã‚’è¡¨ç¤º
    for i in range(n_states):
        for j in range(n_states):
            text = axes[idx].text(j, i, f'{P_n[i, j]:.3f}',
                                   ha="center", va="center", color="black", fontsize=9)

    axes[idx].set_xlabel('æ¬¡ã®çŠ¶æ…‹', fontsize=10)
    axes[idx].set_ylabel('ç¾åœ¨ã®çŠ¶æ…‹', fontsize=10)

plt.colorbar(im, ax=axes, fraction=0.046, pad=0.04)
plt.suptitle('transition probability matrixã®ç´¯ä¹— P^nï¼ˆstationary distributionã¸ã®åæŸï¼‰',
             fontsize=14, fontweight='bold')
plt.tight_layout()
plt.show()

# ç•°ãªã‚‹åˆæœŸåˆ†å¸ƒã‹ã‚‰ã®åæŸ
initial_distributions = [
    np.array([1, 0, 0]),  # æ™´ã‚Œã‚¹ã‚¿ãƒ¼ãƒˆ
    np.array([0, 1, 0]),  # æ›‡ã‚Šã‚¹ã‚¿ãƒ¼ãƒˆ
    np.array([0, 0, 1]),  # é›¨ã‚¹ã‚¿ãƒ¼ãƒˆ
    np.array([1/3, 1/3, 1/3])  # uniform distribution
]

fig, ax = plt.subplots(figsize=(12, 6))

for i, pi_0 in enumerate(initial_distributions):
    distributions = [pi_0]
    for n in range(50):
        pi_n = distributions[-1] @ P
        distributions.append(pi_n)

    distributions = np.array(distributions)

    for j, state in enumerate(states):
        ax.plot(distributions[:, j], linewidth=2, alpha=0.7,
                label=f'{states[i]}ã‚¹ã‚¿ãƒ¼ãƒˆ â†’ {state}' if i == 0 else None,
                linestyle=['-', '--', ':'][j])

ax.axhline(y=pi_stationary[0], color='red', linestyle='--', alpha=0.5, linewidth=2)
ax.axhline(y=pi_stationary[1], color='green', linestyle='--', alpha=0.5, linewidth=2)
ax.axhline(y=pi_stationary[2], color='blue', linestyle='--', alpha=0.5, linewidth=2)

ax.set_xlabel('ã‚¹ãƒ†ãƒƒãƒ—æ•° n', fontsize=11)
ax.set_ylabel('ç¢ºç‡', fontsize=11)
ax.set_title('ç•°ãªã‚‹åˆæœŸåˆ†å¸ƒã‹ã‚‰ã®stationary distributionã¸ã®åæŸ', fontsize=12, fontweight='bold')
ax.legend(fontsize=9, ncol=2)
ax.grid(alpha=0.3)

plt.tight_layout()
plt.show()</div>

            <h2>3.3 ãƒ©ãƒ³ãƒ€ãƒ ã‚¦ã‚©ãƒ¼ã‚¯</h2>

            <div class="definition">
                <strong>ğŸ“ Definition: ãƒ©ãƒ³ãƒ€ãƒ ã‚¦ã‚©ãƒ¼ã‚¯</strong><br>
                1æ¬¡å…ƒãƒ©ãƒ³ãƒ€ãƒ ã‚¦ã‚©ãƒ¼ã‚¯ is ç¢ºç‡ \(p\) ã§å³ã«1ç§»å‹•ã€ç¢ºç‡ \(1-p\) ã§å·¦ã«1ç§»å‹•ã™ã‚‹Markov chainã§ã™ï¼š
                \[X_{n+1} = X_n + \epsilon_{n+1}, \quad \epsilon_{n+1} = \begin{cases} +1 & \text{w.p. } p \\ -1 & \text{w.p. } 1-p \end{cases}\]

                å¯¾ç§°ãƒ©ãƒ³ãƒ€ãƒ ã‚¦ã‚©ãƒ¼ã‚¯ï¼ˆ\(p = 1/2\)ï¼‰ is materials scienceã«ãŠã‘ã‚‹diffusionç¾è±¡ã®é›¢æ•£ãƒ¢ãƒ‡ãƒ«.
            </div>

            <h3>ğŸ’» Code Example3: ãƒ©ãƒ³ãƒ€ãƒ ã‚¦ã‚©ãƒ¼ã‚¯</h3>
            <div class="code-block"># 1æ¬¡å…ƒãƒ©ãƒ³ãƒ€ãƒ ã‚¦ã‚©ãƒ¼ã‚¯ã®simulation
np.random.seed(42)

def random_walk_1d(n_steps, p=0.5, initial_pos=0):
    """1æ¬¡å…ƒãƒ©ãƒ³ãƒ€ãƒ ã‚¦ã‚©ãƒ¼ã‚¯"""
    positions = [initial_pos]
    current_pos = initial_pos

    for _ in range(n_steps):
        step = 1 if np.random.rand() < p else -1
        current_pos += step
        positions.append(current_pos)

    return np.array(positions)

# è¤‡æ•°ã®çµŒè·¯ã‚’simulation
n_steps = 1000
n_paths = 100
p = 0.5  # å¯¾ç§°ãƒ©ãƒ³ãƒ€ãƒ ã‚¦ã‚©ãƒ¼ã‚¯

fig, axes = plt.subplots(2, 2, figsize=(14, 10))

# (1) è¤‡æ•°çµŒè·¯ã®visualization
for _ in range(50):
    path = random_walk_1d(n_steps, p)
    axes[0, 0].plot(path, alpha=0.2, linewidth=0.8, color='#667eea')

axes[0, 0].axhline(y=0, color='red', linestyle='--', linewidth=2, label='é–‹å§‹ä½ç½®')
axes[0, 0].set_xlabel('ã‚¹ãƒ†ãƒƒãƒ—æ•°', fontsize=11)
axes[0, 0].set_ylabel('ä½ç½®', fontsize=11)
axes[0, 0].set_title('å¯¾ç§°ãƒ©ãƒ³ãƒ€ãƒ ã‚¦ã‚©ãƒ¼ã‚¯ï¼ˆp=0.5ï¼‰', fontsize=12, fontweight='bold')
axes[0, 0].legend()
axes[0, 0].grid(alpha=0.3)

# (2) æœ€çµ‚ä½ç½®ã®åˆ†å¸ƒ
final_positions = [random_walk_1d(n_steps, p)[-1] for _ in range(n_paths)]

axes[0, 1].hist(final_positions, bins=30, density=True, alpha=0.6,
                 color='#667eea', edgecolor='black')

# ç†è«–åˆ†å¸ƒï¼ˆCentral Limit Theoremã«ã‚ˆã‚Šnormal distributionã«è¿‘ã¥ãï¼‰
# E[Xn] = 0 (å¯¾ç§°), Var(Xn) = n (å„ã‚¹ãƒ†ãƒƒãƒ—ã®variance=1)
x = np.linspace(min(final_positions), max(final_positions), 1000)
theoretical_pdf = stats.norm.pdf(x, 0, np.sqrt(n_steps))
axes[0, 1].plot(x, theoretical_pdf, 'r-', linewidth=2.5, label='N(0, n)')

axes[0, 1].set_xlabel('æœ€çµ‚ä½ç½®', fontsize=11)
axes[0, 1].set_ylabel('å¯†åº¦', fontsize=11)
axes[0, 1].set_title(f'æœ€çµ‚ä½ç½®ã®åˆ†å¸ƒï¼ˆn={n_steps}ï¼‰', fontsize=12, fontweight='bold')
axes[0, 1].legend()
axes[0, 1].grid(alpha=0.3)

# (3) éå¯¾ç§°ãƒ©ãƒ³ãƒ€ãƒ ã‚¦ã‚©ãƒ¼ã‚¯
p_biased = 0.6
paths_biased = [random_walk_1d(n_steps, p_biased) for _ in range(50)]

for path in paths_biased:
    axes[1, 0].plot(path, alpha=0.2, linewidth=0.8, color='#764ba2')

axes[1, 0].axhline(y=0, color='red', linestyle='--', linewidth=2)
axes[1, 0].set_xlabel('ã‚¹ãƒ†ãƒƒãƒ—æ•°', fontsize=11)
axes[1, 0].set_ylabel('ä½ç½®', fontsize=11)
axes[1, 0].set_title(f'éå¯¾ç§°ãƒ©ãƒ³ãƒ€ãƒ ã‚¦ã‚©ãƒ¼ã‚¯ï¼ˆp={p_biased}ï¼‰', fontsize=12, fontweight='bold')
axes[1, 0].grid(alpha=0.3)

# (4) å¹³å‡å¤‰ä½ã¨ç†è«–å€¤ã®æ¯”è¼ƒ
n_checkpoints = np.arange(0, n_steps+1, 10)
mean_positions = []
std_positions = []

for n in n_checkpoints:
    if n == 0:
        mean_positions.append(0)
        std_positions.append(0)
    else:
        paths = [random_walk_1d(n, p_biased) for _ in range(n_paths)]
        final_pos = [path[-1] for path in paths]
        mean_positions.append(np.mean(final_pos))
        std_positions.append(np.std(final_pos))

mean_positions = np.array(mean_positions)
std_positions = np.array(std_positions)

# ç†è«–å€¤
theoretical_mean = n_checkpoints * (2*p_biased - 1)  # E[Xn] = n(2p-1)
theoretical_std = np.sqrt(n_checkpoints * 4*p_biased*(1-p_biased))  # Var(Xn) = 4np(1-p)

axes[1, 1].plot(n_checkpoints, mean_positions, 'o-', color='#667eea',
                 linewidth=2, markersize=4, label='å®Ÿæ¸¬å¹³å‡')
axes[1, 1].plot(n_checkpoints, theoretical_mean, '--', color='red',
                 linewidth=2, label='ç†è«–å¹³å‡')
axes[1, 1].fill_between(n_checkpoints,
                          theoretical_mean - theoretical_std,
                          theoretical_mean + theoretical_std,
                          alpha=0.2, color='red', label='ç†è«–Â±1Ïƒ')
axes[1, 1].set_xlabel('ã‚¹ãƒ†ãƒƒãƒ—æ•°', fontsize=11)
axes[1, 1].set_ylabel('å¹³å‡ä½ç½®', fontsize=11)
axes[1, 1].set_title('éå¯¾ç§°ãƒ©ãƒ³ãƒ€ãƒ ã‚¦ã‚©ãƒ¼ã‚¯ã®å¹³å‡å¤‰ä½', fontsize=12, fontweight='bold')
axes[1, 1].legend()
axes[1, 1].grid(alpha=0.3)

plt.tight_layout()
plt.show()

print(f"å¯¾ç§°ãƒ©ãƒ³ãƒ€ãƒ ã‚¦ã‚©ãƒ¼ã‚¯ï¼ˆp=0.5ï¼‰:")
print(f"  ç†è«–: E[X{n_steps}] = 0, Var(X{n_steps}) = {n_steps}")
print(f"  å®Ÿæ¸¬: å¹³å‡={np.mean(final_positions):.2f}, variance={np.var(final_positions):.2f}")

print(f"\néå¯¾ç§°ãƒ©ãƒ³ãƒ€ãƒ ã‚¦ã‚©ãƒ¼ã‚¯ï¼ˆp={p_biased}ï¼‰:")
print(f"  ç†è«–: E[X{n_steps}] = {theoretical_mean[-1]:.2f}, Var(X{n_steps}) = {theoretical_std[-1]**2:.2f}")
print(f"  å®Ÿæ¸¬: å¹³å‡={mean_positions[-1]:.2f}, standard deviation={std_positions[-1]:.2f}")</div>

            <h2>3.4 Continuous-Time Markov Processes</h2>

            <div class="definition">
                <strong>ğŸ“ Definition: Continuous-Time Markov Processes</strong><br>
                Continuous-Time Markov Processes is é€£ç¶šæ™‚é–“ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ \(t \geq 0\) ã‚’æŒã¤Markov process \(\{X(t)\}_{t \geq 0}\) .

                <strong>æ¨ç§»ç‡è¡Œåˆ— \(Q\)ï¼ˆgenerator matrixï¼‰:</strong>
                \[q_{ij} = \lim_{h \to 0} \frac{P(X(t+h) = j \mid X(t) = i)}{h} \quad (i \neq j)\]
                \[q_{ii} = -\sum_{j \neq i} q_{ij}\]

                <strong>ãƒãƒ£ãƒƒãƒ—ãƒãƒ³-ã‚³ãƒ«ãƒ¢ã‚´ãƒ­ãƒ•æ–¹ç¨‹å¼:</strong>
                \[\frac{dP(t)}{dt} = Q P(t)\]
                è§£ã¯ \(P(t) = e^{Qt}\)
            </div>

            <h3>ğŸ’» Code Example4: Continuous-Time Markov Processes</h3>
            <div class="code-block">from scipy.linalg import expm

# Continuous-Time Markov Processesã®ä¾‹ï¼šSIRæ„ŸæŸ“ãƒ¢ãƒ‡ãƒ«ã®ç°¡ç•¥ç‰ˆ
# çŠ¶æ…‹: å¥åº·(H), æ„ŸæŸ“(I), å›å¾©(R)
states_sir = ['å¥åº·', 'æ„ŸæŸ“', 'å›å¾©']

# æ¨ç§»ç‡è¡Œåˆ— Q
# Q[i,j] = çŠ¶æ…‹iã‹ã‚‰çŠ¶æ…‹jã¸ã®æ¨ç§»ç‡ï¼ˆiâ‰ jã®ã¨ãï¼‰
lambda_infection = 0.3  # æ„ŸæŸ“ç‡
mu_recovery = 0.2       # å›å¾©ç‡

Q = np.array([
    [-lambda_infection, lambda_infection, 0],
    [0, -mu_recovery, mu_recovery],
    [0, 0, 0]  # å›å¾©ã¯å¸åçŠ¶æ…‹
])

print("æ¨ç§»ç‡è¡Œåˆ— Q:")
print(Q)
print(f"\nå„è¡Œã®å’Œï¼ˆ=0ï¼‰: {Q.sum(axis=1)}")

# æ™‚é–“ç™ºå±• P(t) = exp(Qt)
times = np.linspace(0, 30, 100)
initial_state = np.array([1, 0, 0])  # æœ€åˆã¯å¥åº·

probabilities = []
for t in times:
    P_t = expm(Q * t)
    prob_t = initial_state @ P_t
    probabilities.append(prob_t)

probabilities = np.array(probabilities)

# visualization
fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# (1) ç¢ºç‡ã®æ™‚é–“ç™ºå±•
for i, state in enumerate(states_sir):
    axes[0].plot(times, probabilities[:, i], linewidth=2.5, label=state)

axes[0].set_xlabel('æ™‚é–“', fontsize=11)
axes[0].set_ylabel('ç¢ºç‡', fontsize=11)
axes[0].set_title('Continuous-Time Markov Processesï¼ˆSIRãƒ¢ãƒ‡ãƒ«ï¼‰', fontsize=12, fontweight='bold')
axes[0].legend(fontsize=10)
axes[0].grid(alpha=0.3)
axes[0].set_ylim([0, 1])

# (2) simulationï¼ˆã‚¸ãƒ£ãƒ³ãƒ—éç¨‹ã¨ã—ã¦ï¼‰
def simulate_ctmc(Q, initial_state, T_max):
    """é€£ç¶šæ™‚é–“Simulation of Markov Chainsï¼ˆGillespieã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ï¼‰"""
    n_states = Q.shape[0]
    current_state = initial_state
    current_time = 0

    times = [current_time]
    states = [current_state]

    while current_time < T_max:
        # ç¾åœ¨ã®çŠ¶æ…‹ã§ã®æ»åœ¨æ™‚é–“ï¼ˆexponential distributionï¼‰
        rate = -Q[current_state, current_state]
        if rate == 0:  # å¸åçŠ¶æ…‹
            break

        waiting_time = np.random.exponential(1/rate)
        current_time += waiting_time

        if current_time > T_max:
            break

        # æ¬¡ã®çŠ¶æ…‹ã‚’é¸æŠ
        transition_probs = Q[current_state].copy()
        transition_probs[current_state] = 0
        transition_probs /= transition_probs.sum()

        next_state = np.random.choice(n_states, p=transition_probs)

        times.append(current_time)
        states.append(next_state)
        current_state = next_state

    return times, states

# è¤‡æ•°çµŒè·¯ã®simulation
np.random.seed(42)
n_simulations = 20
T_max = 30

for _ in range(n_simulations):
    sim_times, sim_states = simulate_ctmc(Q, 0, T_max)
    axes[1].step(sim_times, sim_states, where='post',
                  alpha=0.4, linewidth=1.5, color='#667eea')

axes[1].set_yticks([0, 1, 2])
axes[1].set_yticklabels(states_sir)
axes[1].set_xlabel('æ™‚é–“', fontsize=11)
axes[1].set_ylabel('çŠ¶æ…‹', fontsize=11)
axes[1].set_title('CTMC simulationï¼ˆã‚µãƒ³ãƒ—ãƒ«çµŒè·¯ï¼‰', fontsize=12, fontweight='bold')
axes[1].grid(alpha=0.3)
axes[1].set_xlim([0, T_max])

plt.tight_layout()
plt.show()</div>

            <h2>3.5 Properties of Poisson Processes</h2>

            <div class="definition">
                <strong>ğŸ“ Definition: Poisson process</strong><br>
                è¨ˆæ•°éç¨‹ \(\{N(t)\}_{t \geq 0}\) ãŒ<strong>Poisson process</strong>ï¼ˆå¼·åº¦ \(\lambda\)ï¼‰ã§ã‚ã‚‹ã¨ã¯ï¼š

                <ol>
                    <li>\(N(0) = 0\)</li>
                    <li>ç‹¬ç«‹å¢—åˆ†æ€§: äº’ã„ã«é‡ãªã‚‰ãªã„æ™‚é–“åŒºé–“ã§ã®å¢—åˆ†ã¯ç‹¬ç«‹</li>
                    <li>å®šå¸¸å¢—åˆ†æ€§: \(N(t+s) - N(s)\) ã®åˆ†å¸ƒã¯ \(t\) ã®ã¿ã«ä¾å­˜</li>
                    <li>\(N(t) \sim Pois(\lambda t)\)ã€ã™ãªã‚ã¡ \(P(N(t) = k) = \frac{(\lambda t)^k e^{-\lambda t}}{k!}\)</li>
                </ol>

                <strong>åˆ°ç€é–“éš”æ™‚é–“:</strong> Poisson processã«ãŠã‘ã‚‹äº‹è±¡é–“ã®waiting timeã¯ \(Exp(\lambda)\) ã«å¾“ã„.
            </div>

            <h3>ğŸ’» Code Example5: Poisson processã®ç”Ÿæˆ</h3>
            <div class="code-block"># Poisson processã®simulation
np.random.seed(42)
lambda_rate = 2.0  # å¼·åº¦ï¼ˆå˜ä½æ™‚é–“ã‚ãŸã‚Šã®å¹³å‡åˆ°ç€æ•°ï¼‰
T_max = 10

def simulate_poisson_process(lambda_rate, T_max):
    """Poisson processã®simulation"""
    arrival_times = []
    current_time = 0

    while current_time < T_max:
        # æ¬¡ã®åˆ°ç€ã¾ã§ã®æ™‚é–“ï¼ˆexponential distributionï¼‰
        inter_arrival_time = np.random.exponential(1/lambda_rate)
        current_time += inter_arrival_time

        if current_time < T_max:
            arrival_times.append(current_time)

    return np.array(arrival_times)

# è¤‡æ•°çµŒè·¯ã®simulation
n_paths = 10

fig, axes = plt.subplots(2, 2, figsize=(14, 10))

# (1) ã‚µãƒ³ãƒ—ãƒ«çµŒè·¯
for i in range(n_paths):
    arrivals = simulate_poisson_process(lambda_rate, T_max)
    counts = np.arange(1, len(arrivals) + 1)

    axes[0, 0].step(arrivals, counts, where='post', alpha=0.6, linewidth=2)

# ç†è«–çš„expectation E[N(t)] = Î»t
t_theory = np.linspace(0, T_max, 1000)
axes[0, 0].plot(t_theory, lambda_rate * t_theory, 'r--', linewidth=2.5,
                 label=f'E[N(t)] = Î»t = {lambda_rate}t')

axes[0, 0].set_xlabel('æ™‚é–“ t', fontsize=11)
axes[0, 0].set_ylabel('ç´¯ç©åˆ°ç€æ•° N(t)', fontsize=11)
axes[0, 0].set_title(f'Poisson processï¼ˆÎ»={lambda_rate}ï¼‰', fontsize=12, fontweight='bold')
axes[0, 0].legend()
axes[0, 0].grid(alpha=0.3)

# (2) åˆ°ç€é–“éš”æ™‚é–“ã®åˆ†å¸ƒ
all_inter_arrivals = []
for _ in range(1000):
    arrivals = simulate_poisson_process(lambda_rate, T_max)
    if len(arrivals) > 1:
        inter_arrivals = np.diff(np.concatenate([[0], arrivals]))
        all_inter_arrivals.extend(inter_arrivals)

all_inter_arrivals = np.array(all_inter_arrivals)

axes[0, 1].hist(all_inter_arrivals, bins=50, density=True, alpha=0.6,
                 color='#667eea', edgecolor='black', label='simulation')

# ç†è«–åˆ†å¸ƒ Exp(Î»)
x = np.linspace(0, max(all_inter_arrivals), 1000)
theoretical_pdf = lambda_rate * np.exp(-lambda_rate * x)
axes[0, 1].plot(x, theoretical_pdf, 'r-', linewidth=2.5, label=f'Exp({lambda_rate})')

axes[0, 1].set_xlabel('åˆ°ç€é–“éš”æ™‚é–“', fontsize=11)
axes[0, 1].set_ylabel('å¯†åº¦', fontsize=11)
axes[0, 1].set_title('åˆ°ç€é–“éš”æ™‚é–“ã®åˆ†å¸ƒ', fontsize=12, fontweight='bold')
axes[0, 1].legend()
axes[0, 1].grid(alpha=0.3)

# (3) æ™‚åˆ»tã§ã®åˆ°ç€æ•°ã®åˆ†å¸ƒ
t_fixed = 5
counts_at_t = []
for _ in range(5000):
    arrivals = simulate_poisson_process(lambda_rate, t_fixed)
    counts_at_t.append(len(arrivals))

counts_at_t = np.array(counts_at_t)

# ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ 
unique, counts = np.unique(counts_at_t, return_counts=True)
axes[1, 0].bar(unique, counts/len(counts_at_t), alpha=0.6,
                color='#667eea', edgecolor='black', label='simulation')

# ç†è«–åˆ†å¸ƒ Pois(Î»t)
k = np.arange(0, max(counts_at_t) + 1)
theoretical_pmf = stats.poisson.pmf(k, lambda_rate * t_fixed)
axes[1, 0].plot(k, theoretical_pmf, 'ro-', linewidth=2, markersize=6,
                 label=f'Pois({lambda_rate * t_fixed})')

axes[1, 0].set_xlabel(f't={t_fixed}ã§ã®åˆ°ç€æ•°', fontsize=11)
axes[1, 0].set_ylabel('ç¢ºç‡', fontsize=11)
axes[1, 0].set_title(f'æ™‚åˆ»t={t_fixed}ã§ã®åˆ°ç€æ•°ã®åˆ†å¸ƒ', fontsize=12, fontweight='bold')
axes[1, 0].legend()
axes[1, 0].grid(alpha=0.3)

# (4) ç•°ãªã‚‹å¼·åº¦ã§ã®æ¯”è¼ƒ
lambdas = [0.5, 1.0, 2.0, 4.0]
colors = ['blue', 'green', 'orange', 'red']

for lam, color in zip(lambdas, colors):
    arrivals = simulate_poisson_process(lam, T_max)
    counts = np.arange(1, len(arrivals) + 1)
    axes[1, 1].step(arrivals, counts, where='post', linewidth=2,
                     alpha=0.7, color=color, label=f'Î»={lam}')

axes[1, 1].set_xlabel('æ™‚é–“ t', fontsize=11)
axes[1, 1].set_ylabel('ç´¯ç©åˆ°ç€æ•° N(t)', fontsize=11)
axes[1, 1].set_title('ç•°ãªã‚‹å¼·åº¦ã§ã®Poisson process', fontsize=12, fontweight='bold')
axes[1, 1].legend()
axes[1, 1].grid(alpha=0.3)

plt.tight_layout()
plt.show()

print("Poisson processã®verification:")
print(f"ç†è«–: E[åˆ°ç€é–“éš”] = 1/Î» = {1/lambda_rate:.4f}")
print(f"å®Ÿæ¸¬: E[åˆ°ç€é–“éš”] = {np.mean(all_inter_arrivals):.4f}")
print(f"\nç†è«–: E[N({t_fixed})] = Î»t = {lambda_rate * t_fixed:.4f}")
print(f"å®Ÿæ¸¬: E[N({t_fixed})] = {np.mean(counts_at_t):.4f}")</div>

            <h2>3.6 åˆ°ç€é–“éš”æ™‚é–“ã®åˆ†å¸ƒ</h2>

            <h3>ğŸ’» Code Example6: åˆ°ç€é–“éš”æ™‚é–“ã®åˆ†å¸ƒ</h3>
            <div class="code-block"># kç•ªç›®ã®åˆ°ç€æ™‚åˆ»ã®åˆ†å¸ƒï¼ˆã‚¢ãƒ¼ãƒ©ãƒ³åˆ†å¸ƒï¼‰
np.random.seed(42)
lambda_rate = 1.5
n_simulations = 5000

# k=1, 2, 3, 4ç•ªç›®ã®åˆ°ç€æ™‚åˆ»
k_values = [1, 2, 3, 4]

fig, axes = plt.subplots(2, 2, figsize=(14, 10))
axes = axes.flatten()

for idx, k in enumerate(k_values):
    # simulation
    arrival_times_k = []
    for _ in range(n_simulations):
        arrivals = simulate_poisson_process(lambda_rate, 20)
        if len(arrivals) >= k:
            arrival_times_k.append(arrivals[k-1])

    arrival_times_k = np.array(arrival_times_k)

    # ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ 
    axes[idx].hist(arrival_times_k, bins=50, density=True, alpha=0.6,
                    color='#667eea', edgecolor='black', label='simulation')

    # ç†è«–åˆ†å¸ƒï¼ˆgamma distribution = ã‚¢ãƒ¼ãƒ©ãƒ³åˆ†å¸ƒï¼‰
    # T_k ~ Gamma(k, Î»)
    x = np.linspace(0, max(arrival_times_k), 1000)
    theoretical_pdf = stats.gamma.pdf(x, a=k, scale=1/lambda_rate)
    axes[idx].plot(x, theoretical_pdf, 'r-', linewidth=2.5,
                    label=f'Gamma({k}, {lambda_rate})')

    axes[idx].set_xlabel(f'{k}ç•ªç›®ã®åˆ°ç€æ™‚åˆ»', fontsize=11)
    axes[idx].set_ylabel('å¯†åº¦', fontsize=11)
    axes[idx].set_title(f'{k}ç•ªç›®ã®åˆ°ç€æ™‚åˆ»ã®åˆ†å¸ƒ', fontsize=12, fontweight='bold')
    axes[idx].legend()
    axes[idx].grid(alpha=0.3)

    # çµ±è¨ˆé‡
    theoretical_mean = k / lambda_rate
    theoretical_var = k / lambda_rate**2
    print(f"k={k}ç•ªç›®ã®åˆ°ç€æ™‚åˆ»:")
    print(f"  ç†è«–: E[T{k}] = {theoretical_mean:.4f}, Var(T{k}) = {theoretical_var:.4f}")
    print(f"  å®Ÿæ¸¬: E[T{k}] = {np.mean(arrival_times_k):.4f}, Var(T{k}) = {np.var(arrival_times_k):.4f}\n")

plt.tight_layout()
plt.show()</div>

            <h2>3.7 Applications to Process Engineeringï¼ˆfailureãƒ¢ãƒ‡ãƒªãƒ³ã‚°ï¼‰</h2>

            <h3>ğŸ’» Code Example7: Applications to Process Engineeringï¼ˆfailureãƒ¢ãƒ‡ãƒªãƒ³ã‚°ï¼‰</h3>
            <div class="code-block"># è£½é€ ãƒ—ãƒ­ã‚»ã‚¹ã®failureãƒ¢ãƒ‡ãƒªãƒ³ã‚°ï¼ˆPoisson processã®å¿œç”¨ï¼‰
np.random.seed(42)

# ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
lambda_failure = 0.05  # failureç‡ï¼ˆ1æ™‚é–“ã‚ãŸã‚Š0.05å› = 20æ™‚é–“ã«1å›ï¼‰
T_operation = 1000  # é‹è»¢æ™‚é–“ï¼ˆæ™‚é–“ï¼‰
repair_time_mean = 2  # å¹³å‡ä¿®ç†æ™‚é–“ï¼ˆæ™‚é–“ï¼‰

# failureæ™‚åˆ»ã®simulation
failure_times = simulate_poisson_process(lambda_failure, T_operation)
n_failures = len(failure_times)

# ä¿®ç†æ™‚é–“ï¼ˆlognormal distributionã¨ä»®å®šï¼‰
repair_times = np.random.lognormal(mean=np.log(repair_time_mean), sigma=0.3, size=n_failures)

# ç¨¼åƒç‡ã®è¨ˆç®—
total_repair_time = repair_times.sum()
uptime = T_operation - total_repair_time
availability = uptime / T_operation

fig, axes = plt.subplots(2, 2, figsize=(14, 10))

# (1) failureæ™‚åˆ»ã¨ãƒ€ã‚¦ãƒ³ã‚¿ã‚¤ãƒ 
time_grid = np.linspace(0, T_operation, 10000)
operational_status = np.ones_like(time_grid)

for i, (failure_time, repair_time) in enumerate(zip(failure_times, repair_times)):
    end_repair = failure_time + repair_time
    mask = (time_grid >= failure_time) & (time_grid < end_repair)
    operational_status[mask] = 0

axes[0, 0].fill_between(time_grid, 0, operational_status,
                          color='green', alpha=0.6, label='ç¨¼åƒä¸­')
axes[0, 0].fill_between(time_grid, 0, 1-operational_status,
                          color='red', alpha=0.6, label='ãƒ€ã‚¦ãƒ³ã‚¿ã‚¤ãƒ ')

for failure_time in failure_times[:10]:  # æœ€åˆã®10å€‹ã®ã¿è¡¨ç¤º
    axes[0, 0].axvline(failure_time, color='red', linestyle='--', alpha=0.5, linewidth=1)

axes[0, 0].set_xlabel('æ™‚é–“ï¼ˆæ™‚é–“ï¼‰', fontsize=11)
axes[0, 0].set_ylabel('çŠ¶æ…‹', fontsize=11)
axes[0, 0].set_title('è£½é€ ãƒ—ãƒ­ã‚»ã‚¹ã®ç¨¼åƒçŠ¶æ³', fontsize=12, fontweight='bold')
axes[0, 0].legend()
axes[0, 0].set_ylim([0, 1.2])
axes[0, 0].grid(alpha=0.3)

# (2) failureé–“éš”æ™‚é–“ã®åˆ†å¸ƒ
if len(failure_times) > 1:
    inter_failure_times = np.diff(failure_times)

    axes[0, 1].hist(inter_failure_times, bins=20, density=True, alpha=0.6,
                     color='#667eea', edgecolor='black', label='å®Ÿæ¸¬')

    # ç†è«–åˆ†å¸ƒ Exp(Î»)
    x = np.linspace(0, max(inter_failure_times), 1000)
    theoretical_pdf = lambda_failure * np.exp(-lambda_failure * x)
    axes[0, 1].plot(x, theoretical_pdf, 'r-', linewidth=2.5,
                     label=f'Exp({lambda_failure})')

    axes[0, 1].set_xlabel('failureé–“éš”æ™‚é–“ï¼ˆæ™‚é–“ï¼‰', fontsize=11)
    axes[0, 1].set_ylabel('å¯†åº¦', fontsize=11)
    axes[0, 1].set_title('failureé–“éš”æ™‚é–“ã®åˆ†å¸ƒï¼ˆMTBFè§£æï¼‰', fontsize=12, fontweight='bold')
    axes[0, 1].legend()
    axes[0, 1].grid(alpha=0.3)

# (3) ç´¯ç©failureæ•°
counts = np.arange(1, len(failure_times) + 1)
axes[1, 0].step(failure_times, counts, where='post', linewidth=2.5,
                 color='#667eea', label='å®Ÿæ¸¬')
axes[1, 0].plot(time_grid, lambda_failure * time_grid, 'r--', linewidth=2,
                 label=f'E[N(t)] = {lambda_failure}t')

axes[1, 0].set_xlabel('æ™‚é–“ï¼ˆæ™‚é–“ï¼‰', fontsize=11)
axes[1, 0].set_ylabel('ç´¯ç©failureæ•°', fontsize=11)
axes[1, 0].set_title('ç´¯ç©failureæ•°ã®æ¨ç§»', fontsize=12, fontweight='bold')
axes[1, 0].legend()
axes[1, 0].grid(alpha=0.3)

# (4) ç¨¼åƒç‡ã®æ™‚é–“æ¨ç§»
window_size = 100  # ç§»å‹•çª“ã®ã‚µã‚¤ã‚ºï¼ˆæ™‚é–“ï¼‰
time_points = np.arange(window_size, T_operation, 10)
availabilities = []

for t in time_points:
    # [t-window_size, t] ã®åŒºé–“ã§ã®ç¨¼åƒç‡
    start_time = t - window_size
    failures_in_window = failure_times[(failure_times >= start_time) & (failure_times < t)]
    repairs_in_window = repair_times[:(len(failures_in_window))]

    total_downtime = repairs_in_window.sum()
    avail = 1 - total_downtime / window_size
    availabilities.append(avail)

axes[1, 1].plot(time_points, availabilities, linewidth=2, color='#667eea',
                 label='ç§»å‹•çª“ç¨¼åƒç‡')
axes[1, 1].axhline(y=availability, color='red', linestyle='--', linewidth=2,
                    label=f'å…¨ä½“ç¨¼åƒç‡ = {availability:.4f}')

axes[1, 1].set_xlabel('æ™‚é–“ï¼ˆæ™‚é–“ï¼‰', fontsize=11)
axes[1, 1].set_ylabel('ç¨¼åƒç‡', fontsize=11)
axes[1, 1].set_title(f'ç¨¼åƒç‡ã®æ™‚é–“æ¨ç§»ï¼ˆçª“ã‚µã‚¤ã‚º={window_size}hï¼‰', fontsize=12, fontweight='bold')
axes[1, 1].legend()
axes[1, 1].grid(alpha=0.3)
axes[1, 1].set_ylim([0, 1])

plt.tight_layout()
plt.show()

# çµ±è¨ˆã‚µãƒãƒªãƒ¼
print("failureãƒ¢ãƒ‡ãƒªãƒ³ã‚°çµ±è¨ˆ:")
print("="*60)
print(f"é‹è»¢æ™‚é–“: {T_operation} æ™‚é–“")
print(f"failureå›æ•°: {n_failures} å›")
print(f"å¹³å‡failureé–“éš”ï¼ˆMTBFï¼‰: {T_operation / n_failures:.2f} æ™‚é–“")
print(f"ç†è«–MTBF: {1 / lambda_failure:.2f} æ™‚é–“")
print(f"\nç·ä¿®ç†æ™‚é–“: {total_repair_time:.2f} æ™‚é–“")
print(f"å¹³å‡ä¿®ç†æ™‚é–“ï¼ˆMTTRï¼‰: {repair_times.mean():.2f} æ™‚é–“")
print(f"\nç¨¼åƒç‡: {availability:.4f} ({availability*100:.2f}%)")
print(f"ç†è«–ç¨¼åƒç‡: {1 / (1 + lambda_failure * repair_time_mean):.4f}")</div>

            <div class="note">
                <strong>ğŸ’¡ Note:</strong> Poisson process is è£½é€ ãƒ—ãƒ­ã‚»ã‚¹ã«ãŠã‘ã‚‹failureãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã€quality controlã€ä¿å®ˆè¨ˆç”»ã«åºƒãå¿œç”¨ã•ã‚Œ.MTBFï¼ˆå¹³å‡failureé–“éš”ï¼‰= 1/Î»ã€ç¨¼åƒç‡ = MTBF / (MTBF + MTTR) ãªã©ã®æŒ‡æ¨™ãŒã€ãƒ—ãƒ­ã‚»ã‚¹æœ€é©åŒ–ã®æ„æ€æ±ºå®šã«ä½¿ã‚ã‚Œ.
            </div>

            <h2>Exercises</h2>

            <div class="exercise">
                <strong>ğŸ“ Exercise1: Markov chainã®stationary distribution</strong><br>
                æ¬¡ã®transition probability matrixã‚’æŒã¤Markov chainã‚’è€ƒãˆã‚‹ï¼š
                \[P = \begin{pmatrix} 0.8 & 0.2 & 0 \\ 0.1 & 0.7 & 0.2 \\ 0 & 0.3 & 0.7 \end{pmatrix}\]
                <ol>
                    <li>stationary distribution Ï€ ã‚’å›ºæœ‰å€¤å•é¡Œã¨ã—ã¦è¨ˆç®—ã›ã‚ˆ</li>
                    <li>ç•°ãªã‚‹åˆæœŸåˆ†å¸ƒã‹ã‚‰100ã‚¹ãƒ†ãƒƒãƒ—simulationã—ã€stationary distributionã¸ã®åæŸã‚’ç¢ºèªã›ã‚ˆ</li>
                    <li>\(P^{50}\) ã‚’è¨ˆç®—ã—ã€å„è¡ŒãŒstationary distributionã«åæŸã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã›ã‚ˆ</li>
                </ol>
            </div>

            <div class="exercise">
                <strong>ğŸ“ Exercise2: ãƒ©ãƒ³ãƒ€ãƒ ã‚¦ã‚©ãƒ¼ã‚¯ã®è§£æ</strong><br>
                1æ¬¡å…ƒãƒ©ãƒ³ãƒ€ãƒ ã‚¦ã‚©ãƒ¼ã‚¯ï¼ˆp=0.6ï¼‰ã‚’1000ã‚¹ãƒ†ãƒƒãƒ—ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆã—ï¼š
                <ol>
                    <li>æœ€çµ‚ä½ç½®ã®åˆ†å¸ƒã‚’ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ã§visualizationã›ã‚ˆ</li>
                    <li>ç†è«–çš„ãªexpectation E[X_n] = n(2p-1) ã¨å®Ÿæ¸¬å€¤ã‚’æ¯”è¼ƒã›ã‚ˆ</li>
                    <li>Central Limit Theoremã«ã‚ˆã‚Šã€standardizationã—ãŸæœ€çµ‚ä½ç½®ãŒnormal distributionã«å¾“ã†ã“ã¨ã‚’ç¢ºèªã›ã‚ˆ</li>
                </ol>
            </div>

            <div class="exercise">
                <strong>ğŸ“ Exercise3: Poisson processã®å¿œç”¨</strong><br>
                ã‚³ãƒ¼ãƒ«ã‚»ãƒ³ã‚¿ãƒ¼ã¸ã®å•ã„åˆã‚ã›ãŒPoisson processï¼ˆÎ»=5 [ä»¶/æ™‚]ï¼‰ã«å¾“ã†ã¨ã™ã‚‹ï¼š
                <ol>
                    <li>1æ™‚é–“ã§10ä»¶ä»¥ä¸Šã®å•ã„åˆã‚ã›ãŒæ¥ã‚‹ç¢ºç‡ã‚’è¨ˆç®—ã›ã‚ˆ</li>
                    <li>æ¬¡ã®å•ã„åˆã‚ã›ã¾ã§ã®waiting timeãŒ15åˆ†ä»¥ä¸Šã«ãªã‚‹ç¢ºç‡ã‚’è¨ˆç®—ã›ã‚ˆ</li>
                    <li>8æ™‚é–“ç¨¼åƒã§ã€å•ã„åˆã‚ã›æ•°ã®åˆ†å¸ƒã‚’simulationã—ã€Poisson distributionã¨æ¯”è¼ƒã›ã‚ˆ</li>
                </ol>
            </div>

            <div class="nav-buttons">
                <a href="chapter-2.html" class="nav-button">â† Chapter 2</a>
                <a href="chapter-4.html" class="nav-button">To Chapter 4 â†’</a>
            </div>
        </div>
    </div>

    <footer>
        <p>&copy; 2025 AI Terakoya - Fundamentals of Mathematics & Physics Dojo</p>
    </footer>
</body>
</html>
