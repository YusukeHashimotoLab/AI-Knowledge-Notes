<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Chapter 3: Multivariable Calculus | Introduction to Calculus and Vector Analysis</title>
    <meta name="description" content="Learn partial derivatives, total differentials, Jacobian matrices, multiple integrals, and Lagrange multipliers.">
        <link rel="stylesheet" href="../../assets/css/knowledge-base.css">
</head>
<body>
    <header>
        <h1>Chapter 3: Multivariable Calculus</h1>
        <p class="subtitle">Multivariable Calculus</p>
    </header>

    <div class="container">
        <div class="breadcrumb">
            <a href="../../index.html">AI Terakoya Top</a> &gt; <a href="../index.html">FM Dojo</a> &gt;
            <a href="index.html">Introduction to Calculus and Vector Analysis</a> &gt;
            Chapter 3
        </div>

        <div class="content">
            <h2>3.1 Partial Derivatives and Total Differentials</h2>

            <div class="definition">
                <strong>ğŸ“ Definition: Partial Derivative</strong><br>
                The partial derivative of multivariable function f(x, y) with respect to x is:
                $$\frac{\partial f}{\partial x} = \lim_{h \to 0} \frac{f(x+h, y) - f(x, y)}{h}$$
                Differentiate with respect to one variable while keeping other variables fixed.
            </div>

            <h3>ğŸ’» Code Example 1: Numerical Calculation of Partial Derivatives</h3>
            <div class="code-block">import numpy as np
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D

def f(x, y):
    """Two-variable function: f(x,y) = xÂ² + xy + yÂ²"""
    return x**2 + x*y + y**2

def partial_x(f, x, y, h=1e-5):
    """Numerical calculation of âˆ‚f/âˆ‚x"""
    return (f(x+h, y) - f(x-h, y)) / (2*h)

def partial_y(f, x, y, h=1e-5):
    """Numerical calculation of âˆ‚f/âˆ‚y"""
    return (f(x, y+h) - f(x, y-h)) / (2*h)

# Partial derivatives at point (1, 2)
x0, y0 = 1, 2
df_dx = partial_x(f, x0, y0)
df_dy = partial_y(f, x0, y0)

print(f"Partial derivatives at point ({x0}, {y0}):")
print(f"âˆ‚f/âˆ‚x = {df_dx:.6f} (analytical solution: {2*x0 + y0})")
print(f"âˆ‚f/âˆ‚y = {df_dy:.6f} (analytical solution: {x0 + 2*y0})")

# 3D visualization
x = np.linspace(-3, 3, 50)
y = np.linspace(-3, 3, 50)
X, Y = np.meshgrid(x, y)
Z = f(X, Y)

fig = plt.figure(figsize=(10, 8))
ax = fig.add_subplot(111, projection='3d')
ax.plot_surface(X, Y, Z, alpha=0.7, cmap='viridis')
ax.scatter([x0], [y0], [f(x0, y0)], color='red', s=100)
ax.set_xlabel('x')
ax.set_ylabel('y')
ax.set_zlabel('f(x,y)')
ax.set_title('f(x,y) = xÂ² + xy + yÂ²')
plt.show()</div>

            <h3>ğŸ’» Code Example 2: Partial Derivatives Using SymPy</h3>
            <div class="code-block">import sympy as sp

x, y, z = sp.symbols('x y z')

# Partial derivatives of various multivariable functions
f1 = x**2 + y**2
f2 = x*sp.exp(y)
f3 = sp.sin(x*y)
f4 = x**2 * y + y**2 * z + z**2 * x

functions = [f1, f2, f3, f4]

print("Examples of partial derivatives:")
for f in functions:
    print(f"\nf = {f}")
    vars = list(f.free_symbols)
    for var in vars:
        print(f"  âˆ‚f/âˆ‚{var} = {sp.diff(f, var)}")</div>

            <h2>3.2 Gradient and Jacobian Matrix</h2>

            <div class="definition">
                <strong>ğŸ“ Definition: Gradient</strong><br>
                The gradient of scalar field f(x, y, z) is a vector with partial derivatives as components:
                $$\nabla f = \left( \frac{\partial f}{\partial x}, \frac{\partial f}{\partial y}, \frac{\partial f}{\partial z} \right)$$
                The gradient vector points in the direction of steepest increase of the function.
            </div>

            <h3>ğŸ’» Code Example 3: Implementation of Gradient Descent Method</h3>
            <div class="code-block">def gradient(f, x, y, h=1e-5):
    """Numerical calculation of gradient vector"""
    grad_x = (f(x+h, y) - f(x-h, y)) / (2*h)
    grad_y = (f(x, y+h) - f(x, y-h)) / (2*h)
    return np.array([grad_x, grad_y])

def gradient_descent(f, x0, y0, learning_rate=0.1, n_iter=50):
    """Minimum search using gradient descent"""
    path = [(x0, y0)]
    x, y = x0, y0

    for i in range(n_iter):
        grad = gradient(f, x, y)
        x -= learning_rate * grad[0]
        y -= learning_rate * grad[1]
        path.append((x, y))

    return np.array(path)

# Search for minimum of f(x,y) = xÂ² + yÂ²
f_simple = lambda x, y: x**2 + y**2
path = gradient_descent(f_simple, x0=3, y0=2, learning_rate=0.2, n_iter=20)

print("Minimum search using gradient descent:")
print(f"Starting point: ({path[0,0]:.2f}, {path[0,1]:.2f})")
print(f"Ending point: ({path[-1,0]:.6f}, {path[-1,1]:.6f})")
print(f"Minimum value: f = {f_simple(path[-1,0], path[-1,1]):.6f}")

# Visualization
x = np.linspace(-3, 3, 100)
y = np.linspace(-3, 3, 100)
X, Y = np.meshgrid(x, y)
Z = f_simple(X, Y)

plt.figure(figsize=(10, 8))
plt.contour(X, Y, Z, levels=20, cmap='viridis', alpha=0.6)
plt.colorbar(label='f(x,y)')
plt.plot(path[:,0], path[:,1], 'ro-', linewidth=2, markersize=6)
plt.scatter([path[0,0]], [path[0,1]], color='green', s=150, marker='*', label='Starting point')
plt.scatter([path[-1,0]], [path[-1,1]], color='red', s=150, marker='*', label='Ending point')
plt.xlabel('x')
plt.ylabel('y')
plt.title('Optimization Using Gradient Descent')
plt.legend()
plt.grid(True, alpha=0.3)
plt.axis('equal')
plt.show()</div>

            <h2>3.3 Lagrange Multiplier Method</h2>

            <div class="theorem">
                <strong>ğŸ“ Theorem: Lagrange Multiplier Method</strong><br>
                The problem of optimizing f(x, y) under constraint g(x, y) = 0 is
                reduced to finding stationary points of the Lagrange function L(x, y, Î») = f(x, y) - Î»g(x, y).
            </div>

            <h3>ğŸ’» Code Example 4: Constrained Optimization Problem</h3>
            <div class="code-block">from scipy.optimize import minimize

# Problem: Minimize xÂ² + yÂ², constraint x + y = 1
def objective(X):
    x, y = X
    return x**2 + y**2

def constraint(X):
    x, y = X
    return x + y - 1  # x + y = 1

# Specify constraint in dictionary format
cons = {'type': 'eq', 'fun': constraint}

# Execute optimization
x0 = [0, 0]  # Initial value
result = minimize(objective, x0, method='SLSQP', constraints=cons)

print("Results of constrained optimization:")
print(f"Optimal solution: x = {result.x[0]:.6f}, y = {result.x[1]:.6f}")
print(f"Minimum value: f = {result.fun:.6f}")
print(f"Constraint verification: x + y = {result.x[0] + result.x[1]:.6f}")

# Comparison with analytical solution (analytical solution for this problem is x = y = 0.5)
print(f"\nAnalytical solution: x = y = 0.5, f = 0.5")
print(f"Error: {abs(result.x[0] - 0.5):.2e}")</div>

            <h2>3.4 Multiple Integrals (Double Integrals, Triple Integrals)</h2>

            <h3>ğŸ’» Code Example 5: Numerical Calculation of Double Integrals</h3>
            <div class="code-block">from scipy import integrate

# âˆ«âˆ«_D xy dxdy, D: 0 â‰¤ x â‰¤ 1, 0 â‰¤ y â‰¤ 2
def integrand(y, x):
    """Integrand f(x,y) = xy"""
    return x * y

# dblquad: double integral
result, error = integrate.dblquad(integrand,
                                   0, 1,      # x range
                                   0, 2)      # y range

print("Double integral calculation:")
print(f"âˆ«â‚€Â¹ âˆ«â‚€Â² xy dy dx = {result:.6f}")
print(f"Analytical solution: [xÂ²/2]â‚€Â¹ Â· [yÂ²/2]â‚€Â² = 0.5 Â· 2 = 1.0")
print(f"Estimated error: {error:.2e}")</div>

            <h3>ğŸ’» Code Example 6: Double Integral Using Polar Coordinate Transformation</h3>
            <div class="code-block"># âˆ«âˆ« (xÂ² + yÂ²) dxdy over disk xÂ² + yÂ² â‰¤ 1
# Polar coordinate transformation: x = r cos Î¸, y = r sin Î¸, dxdy = r dr dÎ¸

def integrand_polar(theta, r):
    """Integrand in polar coordinates: rÂ² Â· r = rÂ³"""
    return r**3

# Integration range: 0 â‰¤ r â‰¤ 1, 0 â‰¤ Î¸ â‰¤ 2Ï€
result, error = integrate.dblquad(integrand_polar,
                                   0, 1,           # r range
                                   0, 2*np.pi)     # Î¸ range

print("\nDouble integral using polar coordinate transformation:")
print(f"âˆ«âˆ«_D (xÂ² + yÂ²) dxdy = {result:.6f}")
print(f"Analytical solution: âˆ«â‚€^2Ï€ dÎ¸ âˆ«â‚€Â¹ rÂ³ dr = 2Ï€ Â· [râ´/4]â‚€Â¹ = Ï€/2 â‰ˆ {np.pi/2:.6f}")
print(f"Error: {abs(result - np.pi/2):.2e}")</div>

            <h3>ğŸ’» Code Example 7: Application to Materials Science (Concentration Distribution Integration)</h3>
            <div class="code-block"># Impurity concentration distribution on circular wafer
def concentration(r, theta):
    """
    Concentration distribution C(r,Î¸) [atoms/cmÂ³]
    Concentration decreases with distance from center
    """
    r_max = 5.0  # Wafer radius [cm]
    C0 = 1e15    # Center concentration [atoms/cmÂ³]
    return C0 * np.exp(-r**2 / r_max**2)

# Calculate total impurity atoms in entire wafer
R = 5.0  # Wafer radius [cm]

def integrand_concentration(theta, r):
    return concentration(r, theta) * r  # Multiply by Jacobian r

total_atoms, error = integrate.dblquad(integrand_concentration,
                                        0, R,
                                        0, 2*np.pi)

print("\nApplication to materials science:")
print(f"Wafer radius: {R} cm")
print(f"Center concentration: {1e15:.2e} atoms/cmÂ³")
print(f"Total impurity atoms: {total_atoms:.4e} atoms")
print(f"Average concentration: {total_atoms / (np.pi * R**2):.4e} atoms/cmÂ³")

# Visualization of concentration distribution
r_plot = np.linspace(0, R, 100)
theta_plot = np.linspace(0, 2*np.pi, 100)
R_grid, Theta_grid = np.meshgrid(r_plot, theta_plot)
C_grid = concentration(R_grid, Theta_grid)

# Convert polar to Cartesian coordinates
X_grid = R_grid * np.cos(Theta_grid)
Y_grid = R_grid * np.sin(Theta_grid)

plt.figure(figsize=(10, 8))
plt.contourf(X_grid, Y_grid, C_grid, levels=20, cmap='hot')
plt.colorbar(label='Concentration (atoms/cmÂ³)')
plt.xlabel('x (cm)')
plt.ylabel('y (cm)')
plt.title('Impurity Concentration Distribution on Wafer')
plt.axis('equal')
plt.grid(True, alpha=0.3)
plt.show()</div>

            <h2>Summary</h2>
            <ul>
                <li>Partial derivatives represent the rate of change of multivariable functions with respect to each variable</li>
                <li>The gradient vector indicates the direction of steepest increase and is utilized in optimization</li>
                <li>Constrained optimization problems can be solved using Lagrange multipliers</li>
                <li>Multiple integrals calculate accumulated quantities of multivariable functions, often simplified using polar coordinate transformations</li>
                <li>In materials science, they are applied to integration calculations of concentration distributions, temperature distributions, etc.</li>
            </ul>

            <div class="nav-buttons">
                <a href="chapter-2.html" class="nav-button">â† Chapter 2: Fundamentals of Integration</a>
                <a href="chapter-4.html" class="nav-button">Chapter 4: Vector Fields â†’</a>
            </div>
        </div>
    </div>

    <footer>
        <p>&copy; 2025 AI Terakoya - Fundamentals of Mathematics</p>
    </footer>

    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
        <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\(', '\)']],
                displayMath: [['$$', '$$'], ['\[', '\]']],
                processEscapes: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
            }
        };
    </script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</body>
</html>
