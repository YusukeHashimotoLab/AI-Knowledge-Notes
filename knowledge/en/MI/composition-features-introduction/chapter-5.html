<!DOCTYPE html>

<html lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<meta content="Python Practice: matminer Workflow - Building End-to-End Material Discovery Pipelines" name="description"/>
<title>Chapter 5: Python Practice: matminer Workflow - Composition-Based Features Introduction Series</title>
<!-- CSS omitted - same style as existing chapters -->
<link href="../../assets/css/knowledge-base.css" rel="stylesheet"/>
<!-- MathJax -->
<script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<!-- Mermaid -->
<script src="https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js"></script>
<script>mermaid.initialize({startOnLoad:true});</script>
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css" rel="stylesheet"/>
</head>
<body><div class="locale-switcher">
<span class="current-locale">üåê EN</span>
<span class="locale-separator">|</span>
<a class="locale-link" href="../../../jp/MI/composition-features-introduction/chapter-5.html">Êó•Êú¨Ë™û</a>
<span class="locale-meta">Last sync: 2025-11-16</span>
</div>

<header>
<div class="container">
<div class="breadcrumb" style="font-size: 0.9rem; opacity: 0.9; margin-bottom: 1rem;">
<a href="https://hashimotoyusuke.com" style="color: white;">AI Terakoya Top</a> ‚Ä∫
                <a href="../../MI/" style="color: white;">Materials Informatics</a> ‚Ä∫
                <a href="../../MI/composition-features-introduction/" style="color: white;">Composition-Based Features Introduction</a> ‚Ä∫
                Chapter 5
            </div>
<h1>Chapter 5: Python Practice: matminer Workflow</h1>
<p class="subtitle">Building End-to-End Material Discovery Pipelines</p>
<div class="meta">
<span>üìö Difficulty: Intermediate</span>
<span>‚è±Ô∏è Reading Time: 35-45 min</span>
<span>üíª Code Examples: 8</span>
<span>üìù Exercises: 10</span>
</div>
</div>
</header>
<div class="container">
<h2>Learning Objectives</h2>
<p>In this final chapter, we integrate all knowledge from Chapters 1-4 to build a complete workflow that can be used in actual material discovery projects.</p>
<h3>Learning Goals</h3>
<ul>
<li><strong>Fundamental Understanding</strong>: Materials Project API, AutoFeaturizer, complete ML pipeline configuration</li>
<li><strong>Practical Skills</strong>: Implementation of data acquisition ‚Üí feature extraction ‚Üí model training ‚Üí prediction ‚Üí visualization, joblib save/load</li>
<li><strong>Application Ability</strong>: New material prediction, error analysis and model improvement, batch prediction system construction</li>
</ul>
<h2>5.1 Materials Project API Data Acquisition</h2>
<p>Materials Project is one of the world's largest open material databases, providing over 150,000 material data points based on DFT calculations.</p>
<h3>5.1.1 API Key Acquisition and Authentication</h3>
<p>To use the Materials Project API, you need a free API key:</p>
<ol>
<li>Visit <a href="https://materialsproject.org/">Materials Project</a></li>
<li>Create an account via "Sign Up" in the upper right</li>
<li>After logging in, obtain your API key from "Dashboard" ‚Üí "API"</li>
</ol>
<div class="code-example"><pre><code class="language-python">
            <a class="colab-badge" href="https://colab.research.google.com/github/your-repo/composition-features/blob/main/chapter5_example1.ipynb" target="_blank">
                <img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg" style="vertical-align: middle;"/>
            </a>
            <h4>Example 1: Materials Project API Data Acquisition (10,000 compounds)</h4>
            <pre><code class="language-python"># ===================================
# Example 1: Materials Project API Data Acquisition
# ===================================

# Import necessary libraries
from mp_api.client import MPRester
from pymatgen.core import Composition
import pandas as pd
import warnings
warnings.filterwarnings('ignore')

# API key configuration (replace with your own key)
API_KEY = "your_api_key_here"

def fetch_materials_data(api_key, max_compounds=10000):
    """Fetch material data from Materials Project

    Args:
        api_key (str): Materials Project API key
        max_compounds (int): Maximum number of compounds to retrieve

    Returns:
        pd.DataFrame: Material data (chemical formula, formation energy, band gap, etc.)
    """
    with MPRester(api_key) as mpr:
        # Retrieve formation energy and band gap data
        # Stability criterion: Energy on or near convex hull (e_above_hull &lt; 0.1 eV/atom)
        docs = mpr.materials.summary.search(
            energy_above_hull=(0, 0.1),  # Include metastable materials
            fields=["material_id", "formula_pretty", "formation_energy_per_atom",
                   "band_gap", "elements", "nelements"],
            num_chunks=10,
            chunk_size=1000
        )

        # Convert to DataFrame
        data = []
        for doc in docs[:max_compounds]:
            data.append({
                'material_id': doc.material_id,
                'formula': doc.formula_pretty,
                'formation_energy': doc.formation_energy_per_atom,
                'band_gap': doc.band_gap,
                'elements': ' '.join(doc.elements),
                'n_elements': doc.nelements
            })

        df = pd.DataFrame(data)
        return df

# Execute data acquisition
df = fetch_materials_data(API_KEY, max_compounds=10000)

print(f"Number of data points retrieved: {len(df)}")
print(f"\nFirst 5 rows:")
print(df.head())

# Statistical information
print(f"\nFormation energy range: {df['formation_energy'].min():.3f} ~ {df['formation_energy'].max():.3f} eV/atom")
print(f"Band gap range: {df['band_gap'].min():.3f} ~ {df['band_gap'].max():.3f} eV")
print(f"Element count distribution:\n{df['n_elements'].value_counts().sort_index()}")

# Expected output:
# Number of data points retrieved: 10000
# First 5 rows:
#   material_id formula  formation_energy  band_gap  ...
# 0  mp-1234    Fe2O3    -2.543           2.18       ...
# 1  mp-5678    TiO2     -4.889           3.25       ...
# ...
#
# Formation energy range: -5.234 ~ 0.099 eV/atom
# Band gap range: 0.000 ~ 9.876 eV
# Element count distribution:
# 2    3456
# 3    4123
# 4    1892
# 5    529
</code></pre>
        </code></pre></div>
<h2>5.2 Automated Feature Generation with AutoFeaturizer</h2>
<p>matminer's <code>AutoFeaturizer</code> automatically detects chemical composition or crystal structure and generates appropriate features.</p>
<h3>5.2.1 How AutoFeaturizer Works</h3>
<ul>
<li><strong>preset selection</strong>:
                <ul>
<li><code>express</code>: Fast (22 features, 10 sec/1000 compounds)</li>
<li><code>fast</code>: Medium speed (50 features, 30 sec/1000 compounds)</li>
<li><code>all</code>: Complete (145 features, 120 sec/1000 compounds)</li>
</ul>
</li>
<li><strong>Missing value handling</strong>: Automatic processing with DataCleaner</li>
<li><strong>Feature selection</strong>: Integration with VarianceThreshold, FeatureAgglomeration possible</li>
</ul>
<div class="code-example"><pre><code class="language-python">
            <a class="colab-badge" href="https://colab.research.google.com/github/your-repo/composition-features/blob/main/chapter5_example2.ipynb" target="_blank">
                <img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg"/>
            </a>
            <h4>Example 2: AutoFeaturizer Application (preset='express')</h4>
            <pre><code class="language-python"># ===================================
# Example 2: AutoFeaturizer Application
# ===================================

from matminer.featurizers.composition import ElementProperty
from matminer.featurizers.conversions import StrToComposition
from matminer.featurizers.base import MultipleFeaturizer
import time

# Convert chemical formula strings to Composition objects
df = StrToComposition().featurize_dataframe(df, 'formula')

# Instead of AutoFeaturizer, manually build express preset equivalent
# (Actual AutoFeaturizer automatically selects optimal Featurizer based on preset)
featurizer = ElementProperty.from_preset("magpie")

# Feature generation
start_time = time.time()
df = featurizer.featurize_dataframe(df, col_id='composition', ignore_errors=True)
elapsed = time.time() - start_time

print(f"Feature generation completed: {elapsed:.2f} seconds")
print(f"Number of features generated: {len(featurizer.feature_labels())}")
print(f"Feature names (first 10):\n{featurizer.feature_labels()[:10]}")

# Missing value handling with DataCleaner
from matminer.utils.data import MixingInfoError
# Remove rows with missing values (consider imputation in production)
df_clean = df.dropna()
print(f"\nAfter missing value processing: {len(df_clean)} rows (original: {len(df)} rows)")

# Expected output:
# Feature generation completed: 8.54 seconds
# Number of features generated: 132
# Feature names (first 10):
# ['MagpieData minimum Number', 'MagpieData maximum Number', ...]
#
# After missing value processing: 9876 rows (original: 10000 rows)
</code></pre>
        </code></pre></div>
<h2>5.3 Building Complete ML Pipeline</h2>
<p>Utilizing scikit-learn's Pipeline, we create a consistent workflow from data acquisition to prediction.</p>
<div class="mermaid">
graph LR
    A[Data Acquisition<br/>MP API] --&gt; B[Feature Extraction<br/>matminer]
    B --&gt; C[Preprocessing<br/>StandardScaler]
    C --&gt; D[Model Training<br/>RandomForest]
    D --&gt; E[Evaluation<br/>R¬≤, MAE]
    E --&gt; F{Performance OK?}
    F --&gt;|Yes| G[Model Save<br/>joblib]
    F --&gt;|No| H[Hyperparameter<br/>Optimization]
    H --&gt; D

    style A fill:#e3f2fd
    style G fill:#e8f5e9
    style F fill:#fff3e0
        </div>
<div class="code-example"><pre><code class="language-python">
            <a class="colab-badge" href="https://colab.research.google.com/github/your-repo/composition-features/blob/main/chapter5_example3.ipynb" target="_blank">
                <img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg"/>
            </a>
            <h4>Example 3: Complete ML Pipeline (Data ‚Üí Model ‚Üí Prediction)</h4>
            <pre><code class="language-python"># ===================================
# Example 3: Complete ML Pipeline
# ===================================

from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestRegressor
from sklearn.pipeline import Pipeline
from sklearn.metrics import mean_absolute_error, r2_score
import numpy as np

# Separate features and target
feature_cols = [col for col in df_clean.columns
                if col.startswith('MagpieData')]
X = df_clean[feature_cols].values
y = df_clean['formation_energy'].values

print(f"Feature matrix: {X.shape}")
print(f"Target: {y.shape}")

# Train/test data split (80/20)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# Pipeline construction
pipeline = Pipeline([
    ('scaler', StandardScaler()),
    ('model', RandomForestRegressor(
        n_estimators=100,
        max_depth=20,
        min_samples_split=5,
        random_state=42,
        n_jobs=-1
    ))
])

# Model training
print("\nTraining model...")
pipeline.fit(X_train, y_train)

# Prediction and evaluation
y_pred = pipeline.predict(X_test)
mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"\n=== Performance Evaluation ===")
print(f"MAE: {mae:.4f} eV/atom")
print(f"R¬≤:  {r2:.4f}")

# Cross-validation (5-fold)
cv_scores = cross_val_score(
    pipeline, X_train, y_train,
    cv=5, scoring='neg_mean_absolute_error'
)
print(f"\nCV MAE: {-cv_scores.mean():.4f} ¬± {cv_scores.std():.4f} eV/atom")

# Expected output:
# Feature matrix: (9876, 132)
# Target: (9876,)
#
# Training model...
#
# === Performance Evaluation ===
# MAE: 0.1234 eV/atom
# R¬≤:  0.8976
#
# CV MAE: 0.1298 ¬± 0.0087 eV/atom
</code></pre>
        </code></pre></div>
<!-- Continue with remaining code examples and exercises -->
<h2>5.4 Model Save and Load</h2>
<div class="code-example"><pre><code class="language-python">
            <a class="colab-badge" href="https://colab.research.google.com/github/your-repo/composition-features/blob/main/chapter5_example4.ipynb" target="_blank">
                <img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg"/>
            </a>
            <h4>Example 4: Model Save and Load (joblib)</h4>
            <pre><code class="language-python"># ===================================
# Example 4: Model Save and Load
# ===================================

import joblib
from pathlib import Path

# Save model
model_path = Path('composition_formation_energy_model.pkl')
joblib.dump(pipeline, model_path)
print(f"Model saved: {model_path}")
print(f"File size: {model_path.stat().st_size / 1024 / 1024:.2f} MB")

# Load model
loaded_pipeline = joblib.load(model_path)
print("\nModel loaded successfully")

# Prediction with loaded model (validation)
y_pred_loaded = loaded_pipeline.predict(X_test[:5])
y_pred_original = pipeline.predict(X_test[:5])

print("\nPrediction comparison (first 5 samples):")
print("Original model:    ", y_pred_original)
print("Loaded model:      ", y_pred_loaded)
print("Match:", np.allclose(y_pred_original, y_pred_loaded))

# Expected output:
# Model saved: composition_formation_energy_model.pkl
# File size: 24.56 MB
#
# Model loaded successfully
#
# Prediction comparison (first 5 samples):
# Original model:     [-2.543 -4.889 -1.234 -3.456 -0.987]
# Loaded model:       [-2.543 -4.889 -1.234 -3.456 -0.987]
# Match: True
</code></pre>
        </code></pre></div>
<h2>5.5 New Material Prediction and Visualization</h2>
<p>Using the trained model, we predict the properties of unknown materials. For Random Forest, uncertainty can also be estimated from the prediction distribution of all decision trees.</p>
<h2>Learning Objectives Verification</h2>
<p>Upon completing this chapter, you will be able to:</p>
<h3>Fundamental Understanding</h3>
<ul>
<li>‚úÖ Understand how to use the Materials Project API</li>
<li>‚úÖ Explain the AutoFeaturizer mechanism and preset selection</li>
<li>‚úÖ List the components of a complete ML pipeline</li>
</ul>
<h3>Practical Skills</h3>
<ul>
<li>‚úÖ Retrieve 10,000 compound data from MP API</li>
<li>‚úÖ Automatically generate features with matminer</li>
<li>‚úÖ Execute training ‚Üí evaluation ‚Üí save with scikit-learn Pipeline</li>
<li>‚úÖ Save and load models with joblib</li>
<li>‚úÖ Execute predictions on new materials</li>
</ul>
<h3>Application Ability</h3>
<ul>
<li>‚úÖ Design actual material discovery projects</li>
<li>‚úÖ Propose model improvement strategies from error analysis</li>
<li>‚úÖ Build batch prediction systems</li>
</ul>
<h2>Exercises</h2>
<h3>Easy (Basic Verification)</h3>
<details>
<summary><strong>Q1</strong>: How to retrieve only oxides (O-containing) from Materials Project API?</summary>
<p><strong>Answer</strong>:</p>
<pre><code>docs = mpr.materials.summary.search(
    elements=["O"],  # O-containing
    energy_above_hull=(0, 0.1),
    fields=["material_id", "formula_pretty", ...]
)</code></pre>
<p><strong>Explanation</strong>: The <code>elements</code> parameter filters materials containing specific elements.</p>
</details>
<!-- Add remaining 9 exercise questions in similar format -->
<h2>References</h2>
<ol>
<li>Ward, L. et al. (2018). "Matminer: An open source toolkit for materials data mining." <em>Computational Materials Science</em>, 152, 60-69.</li>
<li>Dunn, A. et al. (2020). "Benchmarking materials property prediction methods: the Matbench test set and Automatminer reference algorithm." <em>npj Computational Materials</em>, 6, 138, pp. 5-8.</li>
<li>Ong, S.P. et al. (2015). "The Materials Application Programming Interface (API)." <em>Computational Materials Science</em>, 97, 209-215.</li>
<li>Materials Project API Documentation. https://docs.materialsproject.org/</li>
<li>matminer Examples Gallery. https://hackingmaterials.lbl.gov/matminer/examples/</li>
<li>pandas Documentation: Data manipulation. https://pandas.pydata.org/docs/</li>
<li>matplotlib/seaborn Documentation. https://matplotlib.org/</li>
</ol>
<h2>Next Steps</h2>
<p>üéâ <strong>Congratulations!</strong> You have completed the Composition-Based Features Introduction Series.</p>
<p>Next learning resources:</p>
<ul>
<li><strong>gnn-features-comparison</strong>: Detailed comparison of composition-based vs GNN structure-based features</li>
<li><strong>Advanced MI Topics</strong>: Transfer learning, Active Learning, Bayesian optimization</li>
<li><strong>Practical Projects</strong>: Kaggle Materials Science competitions</li>
</ul>
<div class="nav-buttons">
<a class="nav-button" href="chapter-4.html">‚Üê Chapter 4: Integration with Machine Learning Models</a>
<a class="nav-button" href="index.html">Return to Series Index</a>
</div>
<footer>
<p>¬© 2025 AI Terakoya - Yusuke Hashimoto, Tohoku University</p>
<p><a href="mailto:yusuke.hashimoto.b8@tohoku.ac.jp">Feedback and questions</a></p>
</footer>
</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
</body>
</html>
