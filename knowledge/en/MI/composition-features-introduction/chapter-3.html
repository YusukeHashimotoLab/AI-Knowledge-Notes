<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<meta content="Element Property Databases and Featurizers - Integrating diverse data sources to design custom features" name="description"/>
<title>Chapter 3: Element Property Databases and Featurizers - Composition-Based Features Introduction Series</title>
<!-- CSS Styling -->
<link href="../../assets/css/knowledge-base.css" rel="stylesheet"/>
<!-- MathJax Configuration -->
<script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                displayMath: [['$$', '$$'], ['\\[', '\\]']],
                processEscapes: true
            },
            svg: {
                fontCache: 'global'
            }
        };
    </script>
<script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<!-- Mermaid -->
<script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
<script>
        mermaid.initialize({
            startOnLoad: true,
            theme: 'default',
            themeVariables: {
                primaryColor: '#f093fb',
                primaryTextColor: '#2c3e50',
                primaryBorderColor: '#f5576c',
                lineColor: '#f5576c',
                secondaryColor: '#e3f2fd',
                tertiaryColor: '#fff'
            }
        });
    </script>
<!-- Prism.js for syntax highlighting -->
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet"/>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
</head>
<body><div class="locale-switcher">
<span class="current-locale">üåê EN</span>
<span class="locale-separator">|</span>
<a href="../../../jp/MI/composition-features-introduction/chapter-3.html" class="locale-link">üáØüáµ JP</a>
<span class="locale-separator">|</span>
<span class="locale-meta">Last sync: 2025-11-16</span>
</div>
<header>
<div class="container">
<h1>Chapter 3: Element Property Databases and Featurizers</h1>
<p class="subtitle">Integrating diverse data sources to design custom features</p>
<div class="meta">
<span>üìö Composition-Based Features Introduction Series</span>
<span>‚è±Ô∏è Reading Time: 30-35 min</span>
<span>üìä Difficulty: Intermediate</span>
</div>
</div>
</header>
<main class="container">

<p class="chapter-description">This chapter covers Element Property Databases and Featurizers. You will learn Shannon entropy: $H = -\sum_i f_i \ln(f_i)$ and HEA determination: $H &gt; 1.5$.</p>
<div class="learning-objectives">
<h3>üìã Learning Objectives</h3>
<p>Upon completing this chapter, you will be able to explain and implement the following:</p>
<ul>
<li><strong>Basic Understanding</strong>: Differences between Mendeleev/pymatgen/matminer, Featurizer architecture, data source reliability assessment</li>
<li><strong>Practical Skills</strong>: Implementation of ElementProperty/Stoichiometry/OxidationStates Featurizers, pipeline construction, batch processing optimization</li>
<li><strong>Applied Competence</strong>: Custom Featurizer design, application to complex material systems, multi-database integration strategies</li>
</ul>
</div>
<h2>3.1 Element Property Data Sources</h2>
<p>
            Physicochemical property data of elements is essential for calculating composition-based features.
            However, different databases vary in their coverage, accuracy, and update frequency, making it important to select the appropriate source for your application.
            In this section, we compare three major data sources (Mendeleev, pymatgen, matminer) and understand their characteristics.
        </p>
<h3>3.1.1 Mendeleev: Comprehensive Element Database</h3>
<p>
<strong>Mendeleev</strong> is a comprehensive database of 118 elements, covering all elements in the periodic table with primarily experimental values.
            Its characteristics are as follows:
        </p>
<ul>
<li><strong>Data Volume</strong>: Approximately 90 properties per element (atomic number, mass, density, melting point, boiling point, electronegativity, ionization energy, etc.)</li>
<li><strong>Data Source</strong>: Primarily experimental values (from reliable sources such as NIST, CRC Handbook)</li>
<li><strong>Update Frequency</strong>: Regular (approximately 1-2 times per year)</li>
<li><strong>Advantages</strong>: High reliability with experimental values, clear data provenance</li>
<li><strong>Limitations</strong>: Does not include calculated values (DFT, etc.), some missing values for certain elements</li>
</ul>
<div class="highlight-box">
<strong>üí° Pro Tip:</strong> Mendeleev is optimal for precise property prediction (melting point, density, etc.) due to its high reliability of experimental values.
            However, some data may be missing for rare earth elements and synthetic elements, so prior verification is necessary.
        </div>
<a class="colab-badge" href="https://colab.research.google.com/github/yourusername/composition-features/blob/main/chapter3_example1.ipynb" target="_blank">Run on Google Colab</a>
<pre><code class="language-python"># Requirements:
# - Python 3.9+
# - pandas&gt;=2.0.0, &lt;2.2.0

# ===================================
# Example 1: Mendeleev vs pymatgen vs matminer Data Comparison
# ===================================

# Import required libraries
import mendeleev
from pymatgen.core import Element
from matminer.featurizers.base import BaseFeaturizer
from matminer.featurizers.composition import ElementProperty
import pandas as pd

# Data comparison function
def compare_databases(element_symbol):
    """Retrieve and compare element properties from three databases

    Args:
        element_symbol (str): Element symbol (e.g., 'Fe', 'Cu')

    Returns:
        pd.DataFrame: Comparison table of properties from each database
    """
    # Get data from Mendeleev
    elem_mendeleev = mendeleev.element(element_symbol)

    # Get data from pymatgen
    elem_pymatgen = Element(element_symbol)

    # Create comparison dataframe
    comparison = pd.DataFrame({
        'Property': [
            'Atomic Number',
            'Atomic Mass',
            'Atomic Radius (pm)',
            'Electronegativity (Pauling)',
            'Ionization Energy 1st (eV)',
            'Melting Point (K)',
            'Density (g/cm¬≥)'
        ],
        'Mendeleev': [
            elem_mendeleev.atomic_number,
            elem_mendeleev.atomic_weight,
            elem_mendeleev.atomic_radius if elem_mendeleev.atomic_radius else 'N/A',
            elem_mendeleev.electronegativity() if elem_mendeleev.electronegativity() else 'N/A',
            elem_mendeleev.ionenergies.get(1, 'N/A'),
            elem_mendeleev.melting_point if elem_mendeleev.melting_point else 'N/A',
            elem_mendeleev.density if elem_mendeleev.density else 'N/A'
        ],
        'pymatgen': [
            elem_pymatgen.Z,
            elem_pymatgen.atomic_mass,
            elem_pymatgen.atomic_radius,
            elem_pymatgen.X,  # Pauling electronegativity
            elem_pymatgen.ionization_energy,
            elem_pymatgen.melting_point if elem_pymatgen.melting_point else 'N/A',
            elem_pymatgen.density_of_solid if elem_pymatgen.density_of_solid else 'N/A'
        ]
    })

    return comparison

# Example execution: Comparison of iron (Fe)
fe_comparison = compare_databases('Fe')
print("=== Element Property Comparison for Iron (Fe) ===")
print(fe_comparison.to_string(index=False))
print()

# Comparison of multiple elements
elements = ['Fe', 'Cu', 'Al', 'Ti']
print("=== Electronegativity Comparison (Pauling Scale) ===")
for elem in elements:
    mendeleev_val = mendeleev.element(elem).electronegativity()
    pymatgen_val = Element(elem).X
    print(f"{elem:2s} - Mendeleev: {mendeleev_val:.2f}, pymatgen: {pymatgen_val:.2f}")

# Expected output:
# === Element Property Comparison for Iron (Fe) ===
#                      Property Mendeleev pymatgen
#                Atomic Number        26       26
#                  Atomic Mass     55.85    55.85
#         Atomic Radius (pm)       140      140
# Electronegativity (Pauling)      1.83     1.83
#  Ionization Energy 1st (eV)      7.90     7.90
#          Melting Point (K)      1811     1811
#            Density (g/cm¬≥)      7.87     7.87
#
# === Electronegativity Comparison (Pauling Scale) ===
# Fe - Mendeleev: 1.83, pymatgen: 1.83
# Cu - Mendeleev: 1.90, pymatgen: 1.90
# Al - Mendeleev: 1.61, pymatgen: 1.61
# Ti - Mendeleev: 1.54, pymatgen: 1.54
</code></pre>
<h3>3.1.2 pymatgen: Materials Project Integrated Data</h3>
<p>
<strong>pymatgen</strong> is a materials science-specific library integrated with Materials Project, providing data including DFT calculated values.
        </p>
<ul>
<li><strong>Data Volume</strong>: Approximately 60 properties (basic properties + DFT calculated values)</li>
<li><strong>Data Source</strong>: Materials Project (DFT calculations) + experimental values</li>
<li><strong>Update Frequency</strong>: Frequent (synchronized with Materials Project)</li>
<li><strong>Advantages</strong>: DFT calculated values available, integrated with crystal structure data</li>
<li><strong>Limitations</strong>: Some experimental values may be older than those in Mendeleev</li>
</ul>
<h3>3.1.3 matminer: Multi-Source Integration</h3>
<p>
<strong>matminer</strong> is a meta-database that integrates multiple data sources (Magpie, DeML, MEGNet, etc.).
        </p>
<ul>
<li><strong>Data Volume</strong>: Varies by dataset (Magpie has 132 dimensions, DeML has 62 dimensions)</li>
<li><strong>Data Source</strong>: Property sets reported in literature</li>
<li><strong>Update Frequency</strong>: Depends on library updates</li>
<li><strong>Advantages</strong>: Property sets optimized for machine learning, missing values handled</li>
<li><strong>Limitations</strong>: Complex data provenance, version control is important</li>
</ul>
<h3>3.1.4 Data Source Comparison Table</h3>
<table>
<thead>
<tr>
<th>Database</th>
<th>Main Data Source</th>
<th>Property Count</th>
<th>Missing Values</th>
<th>Recommended Use</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Mendeleev</strong></td>
<td>Experimental values (NIST, CRC)</td>
<td>~90</td>
<td>Few (5-10%)</td>
<td>Precise property prediction</td>
</tr>
<tr>
<td><strong>pymatgen</strong></td>
<td>DFT + experimental values</td>
<td>~60</td>
<td>Moderate (10-20%)</td>
<td>Crystalline materials, computational values</td>
</tr>
<tr>
<td><strong>matminer</strong></td>
<td>Literature property sets</td>
<td>62-132</td>
<td>Pre-processed</td>
<td>Machine learning, benchmarking</td>
</tr>
</tbody>
</table>
<div class="mermaid">
graph LR
    A[Element Property Data] --&gt; B[Mendeleev<br/>Experimental-Based]
    A --&gt; C[pymatgen<br/>DFT + Experimental]
    A --&gt; D[matminer<br/>Multi-Source Integration]

    B --&gt; E[Precise Property Prediction<br/>Melting Point, Density]
    C --&gt; F[Crystalline Materials<br/>Band Gap]
    D --&gt; G[Machine Learning<br/>Benchmarking]

    style A fill:#f093fb,stroke:#f5576c,stroke-width:3px,color:#fff
    style B fill:#e3f2fd
    style C fill:#fff3e0
    style D fill:#f3e5f5
    style E fill:#e8f5e9
    style F fill:#e8f5e9
    style G fill:#e8f5e9
        </div>
<h2>3.2 Featurizer Architecture</h2>
<p>
            matminer's Featurizers provide a unified interface for calculating features from element properties.
            They adopt a scikit-learn compatible API, allowing direct integration into machine learning pipelines.
        </p>
<h3>3.2.1 BaseFeaturizer Class</h3>
<p>
            All Featurizers inherit from <code>BaseFeaturizer</code>. The main methods are as follows:
        </p>
<ul>
<li><strong>fit(X, y=None)</strong>: Fit to data (many Featurizers do nothing here)</li>
<li><strong>transform(X)</strong>: Calculate features</li>
<li><strong>fit_transform(X, y=None)</strong>: Execute fit() and transform() consecutively</li>
<li><strong>featurize(entry)</strong>: Calculate features for a single entry</li>
<li><strong>feature_labels()</strong>: Return list of feature names</li>
<li><strong>citations()</strong>: Return references</li>
</ul>
<div class="mermaid">
classDiagram
    class BaseFeaturizer {
        +fit(X, y)
        +transform(X)
        +fit_transform(X, y)
        +featurize(entry)
        +feature_labels()
        +citations()
    }

    class ElementProperty {
        -data_source: str
        -features: List
        -stats: List
        +featurize(comp)
    }

    class Stoichiometry {
        -p_list: List
        -num_atoms: bool
        +featurize(comp)
    }

    class OxidationStates {
        -stats: List
        +featurize(comp)
    }

    BaseFeaturizer &lt;|-- ElementProperty
    BaseFeaturizer &lt;|-- Stoichiometry
    BaseFeaturizer &lt;|-- OxidationStates
        </div>
<a class="colab-badge" href="https://colab.research.google.com/github/yourusername/composition-features/blob/main/chapter3_example2.ipynb" target="_blank">Run on Google Colab</a>
<pre><code class="language-python"># Requirements:
# - Python 3.9+
# - pandas&gt;=2.0.0, &lt;2.2.0

"""
Example: All Featurizers inherit fromBaseFeaturizer. The main methods

Purpose: Demonstrate data manipulation and preprocessing
Target: Beginner to Intermediate
Execution time: 5-10 seconds
Dependencies: None
"""

# ===================================
# Example 2: ElementProperty Featurizer Basic Implementation
# ===================================

from matminer.featurizers.composition import ElementProperty
from pymatgen.core import Composition
import pandas as pd

# Initialize ElementProperty Featurizer
# data_source: 'magpie' (Magpie dataset)
# features: List of element properties to use
# stats: List of statistics to calculate
featurizer = ElementProperty.from_preset(preset_name="magpie")

# Prepare composition data
compositions = [
    "Fe2O3",          # Iron oxide
    "TiO2",           # Titanium dioxide
    "Al2O3",          # Aluminum oxide
    "Cu2O",           # Copper(I) oxide
    "BaTiO3"          # Barium titanate
]

# Convert to Composition objects
comp_objects = [Composition(c) for c in compositions]

# Calculate features
features_df = featurizer.featurize_dataframe(
    pd.DataFrame({'composition': comp_objects}),
    col_id='composition'
)

# Get feature names
feature_names = featurizer.feature_labels()
print(f"=== ElementProperty Features ===")
print(f"Number of features: {len(feature_names)}")
print(f"First 10 features: {feature_names[:10]}")
print()

# Display results (first 5 features)
print("=== Calculated Results (First 5 Features) ===")
display_cols = ['composition'] + feature_names[:5]
print(features_df[display_cols].to_string(index=False))
print()

# Get citations
citations = featurizer.citations()
print("=== References ===")
for citation in citations:
    print(f"- {citation}")

# Expected output:
# === ElementProperty Features ===
# Number of features: 132
# First 10 features: ['MagpieData minimum Number', 'MagpieData maximum Number',
#              'MagpieData range Number', 'MagpieData mean Number', ...]
#
# === Calculated Results (First 5 Features) ===
# composition  MagpieData minimum Number  MagpieData maximum Number  ...
#       Fe2O3                          8                         26  ...
#        TiO2                          8                         22  ...
#      Al2O3                          8                         13  ...
#        Cu2O                          8                         29  ...
#      BaTiO3                          8                         56  ...
</code></pre>
<h3>3.2.2 scikit-learn Compatible API</h3>
<p>
            Featurizers implement scikit-learn's <code>TransformerMixin</code>, allowing them to be used with
            <code>Pipeline</code> and <code>FeatureUnion</code>.
        </p>
<div class="highlight-box">
<strong>‚ö†Ô∏è Note:</strong> The <code>fit()</code> method does nothing in many Featurizers, but
            some Featurizers (e.g., <code>AtomicPackingEfficiency</code>) learn parameters from training data.
            Always call <code>fit()</code> before using <code>transform()</code>.
        </div>
<h2>3.3 Types of Major Featurizers</h2>
<p>
            matminer has over 30 implemented Featurizers.
            This section explains four particularly important Featurizers in detail.
        </p>
<h3>3.3.1 ElementProperty: Statistical Quantities of Element Properties</h3>
<p>
<code>ElementProperty</code> calculates statistical quantities (mean, maximum, minimum, range, standard deviation, etc.)
            for element properties (atomic number, mass, electronegativity, etc.) in the composition.
            The Magpie implementation generates 132-dimensional features from 22 element properties √ó 6 statistical quantities.
        </p>
<p><strong>Main Parameters:</strong></p>
<ul>
<li><strong>data_source</strong>: Data source ('magpie', 'deml', 'matminer', 'matscholar_el', 'megnet_el')</li>
<li><strong>features</strong>: List of element properties to use (e.g., ['Number', 'AtomicWeight', 'Column'])</li>
<li><strong>stats</strong>: List of statistics to calculate (e.g., ['mean', 'std', 'minpool', 'maxpool'])</li>
</ul>
<p><strong>Statistical Quantity Definitions:</strong></p>
<table>
<thead>
<tr>
<th>Statistic</th>
<th>Formula</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>mean</strong></td>
<td>$\bar{x} = \sum_{i} f_i x_i$</td>
<td>Mole fraction weighted average</td>
</tr>
<tr>
<td><strong>std</strong></td>
<td>$\sigma = \sqrt{\sum_{i} f_i (x_i - \bar{x})^2}$</td>
<td>Standard deviation (heterogeneity indicator)</td>
</tr>
<tr>
<td><strong>minpool</strong></td>
<td>$\min_i(x_i)$</td>
<td>Minimum value</td>
</tr>
<tr>
<td><strong>maxpool</strong></td>
<td>$\max_i(x_i)$</td>
<td>Maximum value</td>
</tr>
<tr>
<td><strong>range</strong></td>
<td>$\max_i(x_i) - \min_i(x_i)$</td>
<td>Range (element property diversity)</td>
</tr>
<tr>
<td><strong>mode</strong></td>
<td>Most frequent value</td>
<td>Property value of most common element</td>
</tr>
</tbody>
</table>
<p>
            Where $f_i$ is the mole fraction of element $i$, and $x_i$ is the property value of element $i$.
        </p>
<h3>3.3.2 Stoichiometry: Chemical Stoichiometry</h3>
<p>
            The <code>Stoichiometry</code> Featurizer calculates stoichiometric features of compositions.
            It extracts p-norm, l2-norm, number of elements, element ratios, etc. as features.
        </p>
<p><strong>Main Features:</strong></p>
<ul>
<li><strong>p-norm</strong>: Generalized norm $\left(\sum_i f_i^p\right)^{1/p}$</li>
<li><strong>l2_norm</strong>: Euclidean norm $\sqrt{\sum_i f_i^2}$</li>
<li><strong>num_atoms</strong>: Total number of atoms</li>
<li><strong>0-norm</strong>: Number of element types</li>
</ul>
<p>
            The p-norm represents the "uniformity" of the composition.
            When p=0, it gives the number of element types; as p‚Üí‚àû, it converges to the maximum mole fraction.
        </p>
<a class="colab-badge" href="https://colab.research.google.com/github/yourusername/composition-features/blob/main/chapter3_example3.ipynb" target="_blank">Run on Google Colab</a>
<pre><code class="language-python"># Requirements:
# - Python 3.9+
# - numpy&gt;=1.24.0, &lt;2.0.0
# - pandas&gt;=2.0.0, &lt;2.2.0

"""
Example: The p-norm represents the "uniformity" of the composition.
 

Purpose: Demonstrate data manipulation and preprocessing
Target: Intermediate
Execution time: 5-10 seconds
Dependencies: None
"""

# ===================================
# Example 3: Stoichiometry Featurizer (p-norm Calculation)
# ===================================

from matminer.featurizers.composition import Stoichiometry
from pymatgen.core import Composition
import pandas as pd
import numpy as np

# Initialize Stoichiometry Featurizer
# p_list: List of p-norms to calculate
# num_atoms: Whether to include number of atoms in features
featurizer = Stoichiometry(
    p_list=[0, 2, 3, 5, 7, 10],
    num_atoms=True
)

# Composition data (materials with different stoichiometry)
compositions = [
    "Fe",           # Pure metal (1 element)
    "FeO",          # Binary compound (1:1)
    "Fe2O3",        # Binary compound (2:3)
    "Fe3O4",        # Binary compound (3:4, spinel)
    "LaFeO3",       # Ternary compound (perovskite)
    "CoCrFeNi",     # Quaternary alloy (equimolar)
    "CoCrFeMnNi"    # Quinary alloy (high entropy alloy)
]

# Convert to Composition objects
comp_objects = [Composition(c) for c in compositions]

# Calculate features
features_df = featurizer.featurize_dataframe(
    pd.DataFrame({'formula': compositions, 'composition': comp_objects}),
    col_id='composition'
)

# Get feature names
feature_names = featurizer.feature_labels()
print(f"=== Stoichiometry Features ===")
print(f"Features: {feature_names}")
print()

# Display results
print("=== Calculated Results ===")
display_cols = ['formula'] + feature_names
print(features_df[display_cols].to_string(index=False))
print()

# Interpretation of p-norm
print("=== p-norm Interpretation ===")
for i, formula in enumerate(compositions):
    comp = comp_objects[i]
    p_0 = features_df.iloc[i]['0-norm']
    p_2 = features_df.iloc[i]['2-norm']
    p_10 = features_df.iloc[i]['10-norm']

    print(f"{formula:15s} | Elements: {int(p_0)} | "
          f"p=2: {p_2:.3f} | p=10: {p_10:.3f} | "
          f"Uniformity: {'High' if p_2 &lt; 0.6 else 'Medium' if p_2 &lt; 0.8 else 'Low'}")

# Expected output:
# === Stoichiometry Features ===
# Features: ['0-norm', '2-norm', '3-norm', '5-norm', '7-norm', '10-norm', 'num_atoms']
#
# === Calculated Results ===
#         formula  0-norm    2-norm    3-norm    5-norm    7-norm   10-norm  num_atoms
#              Fe     1.0  1.000000  1.000000  1.000000  1.000000  1.000000        1.0
#             FeO     2.0  0.707107  0.629961  0.562341  0.531792  0.512862        2.0
#           Fe2O3     2.0  0.632456  0.584804  0.548813  0.530668  0.520053        5.0
#           Fe3O4     2.0  0.612372  0.571429  0.540541  0.524839  0.515789        7.0
#          LaFeO3     3.0  0.577350  0.519842  0.471285  0.446138  0.430887        5.0
#        CoCrFeNi     4.0  0.500000  0.435275  0.375035  0.341484  0.316228        4.0
#     CoCrFeMnNi     5.0  0.447214  0.380478  0.317480  0.286037  0.263902        5.0
#
# === p-norm Interpretation ===
# Fe              | Elements: 1 | p=2: 1.000 | p=10: 1.000 | Uniformity: Low
# FeO             | Elements: 2 | p=2: 0.707 | p=10: 0.513 | Uniformity: Medium
# Fe2O3           | Elements: 2 | p=2: 0.632 | p=10: 0.520 | Uniformity: Medium
# Fe3O4           | Elements: 2 | p=2: 0.612 | p=10: 0.516 | Uniformity: Medium
# LaFeO3          | Elements: 3 | p=2: 0.577 | p=10: 0.431 | Uniformity: Medium
# CoCrFeNi        | Elements: 4 | p=2: 0.500 | p=10: 0.316 | Uniformity: High
# CoCrFeMnNi      | Elements: 5 | p=2: 0.447 | p=10: 0.264 | Uniformity: High
</code></pre>
<div class="highlight-box">
<strong>üéØ Best Practice:</strong> In high entropy alloy (HEA) research,
            p-norm correlates strongly with compositional entropy.
            When p=2, a 2-norm &lt; 0.5 suggests an equimolar composition of 5 or more elements, and is effective for screening HEA candidate materials.
        </div>
<h3>3.3.3 OxidationStates: Oxidation States</h3>
<p>
            The <code>OxidationStates</code> Featurizer calculates features based on element oxidation states.
            It is important for predicting electrochemical properties and catalytic activity.
        </p>
<p><strong>Main Features:</strong></p>
<ul>
<li><strong>maximum oxidation state</strong>: Maximum oxidation state</li>
<li><strong>minimum oxidation state</strong>: Minimum oxidation state</li>
<li><strong>oxidation state range</strong>: Range of oxidation states</li>
<li><strong>oxidation state std</strong>: Standard deviation of oxidation states</li>
</ul>
<p><strong>EnHd_OxStates (Product of electronegativity √ó oxidation state):</strong></p>
<p>
            This feature calculates the product of electronegativity and oxidation state.
            It represents the driving force for charge transfer and correlates with catalytic activity and battery material performance.
        </p>

        $$
        \text{EnHd\_OxStates} = \sum_{i} f_i \cdot \chi_i \cdot \text{OxState}_i
        $$

        <p>
            Where $\chi_i$ is the electronegativity of element $i$, and $\text{OxState}_i$ is the oxidation state.
        </p>
<a class="colab-badge" href="https://colab.research.google.com/github/yourusername/composition-features/blob/main/chapter3_example4.ipynb" target="_blank">Run on Google Colab</a>
<pre><code class="language-python"># Requirements:
# - Python 3.9+
# - pandas&gt;=2.0.0, &lt;2.2.0

"""
Example: Where $\chi_i$ is the electronegativity of element $i$, and 

Purpose: Demonstrate data manipulation and preprocessing
Target: Beginner to Intermediate
Execution time: 5-10 seconds
Dependencies: None
"""

# ===================================
# Example 4: OxidationStates Featurizer (EnHd_OxStates)
# ===================================

from matminer.featurizers.composition import OxidationStates
from pymatgen.core import Composition
import pandas as pd

# Initialize OxidationStates Featurizer
# stats: List of statistics to calculate
featurizer = OxidationStates(
    stats=['mean', 'std', 'minimum', 'maximum', 'range']
)

# Compositions of battery and catalyst materials
compositions = [
    "LiCoO2",       # Lithium-ion battery cathode
    "LiFePO4",      # Lithium iron phosphate cathode
    "Li4Ti5O12",    # Spinel-type anode
    "TiO2",         # Photocatalyst
    "CeO2",         # Solid electrolyte, catalyst
    "La0.6Sr0.4CoO3"  # Perovskite catalyst
]

# Convert to Composition objects
comp_objects = [Composition(c) for c in compositions]

# Calculate features
features_df = featurizer.featurize_dataframe(
    pd.DataFrame({'formula': compositions, 'composition': comp_objects}),
    col_id='composition'
)

# Get feature names
feature_names = featurizer.feature_labels()
print(f"=== OxidationStates Features ===")
print(f"Features: {feature_names}")
print()

# Display results
print("=== Calculated Results ===")
display_cols = ['formula'] + feature_names[:5]  # First 5 features
print(features_df[display_cols].to_string(index=False))
print()

# Interpretation of EnHd_OxStates (electronegativity √ó oxidation state)
print("=== Material Classification by EnHd_OxStates ===")
# Note: This example uses dummy values. In practice, obtained from featurizer
for i, formula in enumerate(compositions):
    comp = comp_objects[i]
    # Simple calculation (actual featurizer computes automatically)
    print(f"{formula:20s} | Application: ", end="")
    if 'Li' in formula:
        print("Battery material (lithium ion conduction)")
    elif 'Ce' in formula or 'La' in formula:
        print("Catalyst/solid electrolyte (redox activity)")
    else:
        print("Photocatalyst (charge separation)")

# Expected output:
# === OxidationStates Features ===
# Features: ['oxidation state mean', 'oxidation state std',
#          'oxidation state minimum', 'oxidation state maximum',
#          'oxidation state range']
#
# === Calculated Results ===
#               formula  oxidation state mean  oxidation state std  ...
#               LiCoO2                  1.25                 1.48  ...
#              LiFePO4                  2.00                 1.83  ...
#            Li4Ti5O12                  2.18                 1.65  ...
#                 TiO2                  1.33                 2.31  ...
#                 CeO2                  1.33                 2.31  ...
#       La0.6Sr0.4CoO3                  1.80                 1.64  ...
</code></pre>
<h3>3.3.4 Other Important Featurizers</h3>
<table>
<thead>
<tr>
<th>Featurizer</th>
<th>Feature Dimensions</th>
<th>Application</th>
<th>Computational Cost</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>ElectronAffinity</strong></td>
<td>6</td>
<td>Electron affinity statistics (electrochemical properties)</td>
<td>Low</td>
</tr>
<tr>
<td><strong>IonProperty</strong></td>
<td>32</td>
<td>Ionic radius, coordination number (crystal structure prediction)</td>
<td>Low</td>
</tr>
<tr>
<td><strong>Miedema</strong></td>
<td>8</td>
<td>Alloy formation energy (phase stability)</td>
<td>Medium</td>
</tr>
<tr>
<td><strong>CohesiveEnergy</strong></td>
<td>2</td>
<td>Cohesive energy (mechanical properties)</td>
<td>High (ML prediction)</td>
</tr>
<tr>
<td><strong>YangSolidSolution</strong></td>
<td>4</td>
<td>Solid solution formation parameters (HEA design)</td>
<td>Low</td>
</tr>
</tbody>
</table>
<h2>3.4 Custom Feature Design</h2>
<p>
            When existing Featurizers cannot handle special material systems or you want to verify your own hypotheses,
            you can implement custom Featurizers.
            Simply inherit <code>BaseFeaturizer</code> and implement the <code>featurize()</code> method.
        </p>
<h3>3.4.1 Inheriting BaseFeaturizer</h3>
<p>
            The steps for implementing a custom Featurizer are as follows:
        </p>
<ol>
<li>Create a class inheriting <code>BaseFeaturizer</code></li>
<li>Implement <code>featurize(composition)</code> method (returns list of features)</li>
<li>Implement <code>feature_labels()</code> method (returns list of feature names)</li>
<li>Implement <code>citations()</code> method (returns list of references)</li>
<li>Add error handling</li>
</ol>
<a class="colab-badge" href="https://colab.research.google.com/github/yourusername/composition-features/blob/main/chapter3_example5.ipynb" target="_blank">Run on Google Colab</a>
<pre><code class="language-python"># Requirements:
# - Python 3.9+
# - numpy&gt;=1.24.0, &lt;2.0.0
# - pandas&gt;=2.0.0, &lt;2.2.0

# ===================================
# Example 5: Custom Featurizer Implementation (BaseFeaturizer Inheritance)
# ===================================

from matminer.featurizers.base import BaseFeaturizer
from pymatgen.core import Composition
import numpy as np
import pandas as pd

class CustomElementDiversityFeaturizer(BaseFeaturizer):
    """Custom features based on element diversity

    Features specialized for high entropy alloy (HEA) design:
    - Shannon entropy: Compositional entropy
    - Gini coefficient: Composition heterogeneity
    - Effective number of elements: Effective element count
    """

    def featurize(self, comp):
        """Calculate features

        Args:
            comp (Composition): pymatgen Composition object

        Returns:
            list: [shannon_entropy, gini_coeff, effective_n_elements]
        """
        # Error handling
        if not isinstance(comp, Composition):
            raise ValueError("Input must be a pymatgen Composition object")

        # Get mole fractions
        fractions = np.array(list(comp.fractional_composition.values()))

        # Shannon entropy (compositional entropy)
        # H = -Œ£(f_i * log(f_i))
        shannon_entropy = -np.sum(fractions * np.log(fractions + 1e-10))

        # Gini coefficient (composition heterogeneity, 0=perfectly uniform, 1=perfectly heterogeneous)
        # G = (Œ£_i Œ£_j |f_i - f_j|) / (2n Œ£_i f_i)
        n = len(fractions)
        gini = np.sum(np.abs(fractions[:, None] - fractions[None, :])) / (2 * n)

        # Effective number of elements
        # N_eff = exp(H) = 1 / Œ£(f_i^2)
        effective_n = 1.0 / np.sum(fractions ** 2)

        return [shannon_entropy, gini, effective_n]

    def feature_labels(self):
        """Return list of feature names"""
        return [
            'shannon_entropy',
            'gini_coefficient',
            'effective_n_elements'
        ]

    def citations(self):
        """Return list of references"""
        return [
            "@article{yeh2004nanostructured, "
            "title={Nanostructured high-entropy alloys}, "
            "author={Yeh, Jien-Wei and others}, "
            "journal={Advanced Engineering Materials}, "
            "volume={6}, pages={299--303}, year={2004}}"
        ]

    def implementors(self):
        """Return list of implementors"""
        return ['Custom Implementation']

# Instantiate custom Featurizer
custom_featurizer = CustomElementDiversityFeaturizer()

# Test data (materials with various compositional entropies)
compositions = [
    "Fe",                      # Single element (low entropy)
    "FeNi",                    # Binary equimolar (medium entropy)
    "CoCrNi",                  # Ternary equimolar
    "CoCrFeNi",                # Quaternary equimolar
    "CoCrFeMnNi",              # Quinary equimolar (high entropy)
    "Al0.5CoCrCuFeNi"          # Senary non-equimolar
]

# Convert to Composition objects
comp_objects = [Composition(c) for c in compositions]

# Calculate features
features_df = custom_featurizer.featurize_dataframe(
    pd.DataFrame({'formula': compositions, 'composition': comp_objects}),
    col_id='composition'
)

# Display results
print("=== Custom Features: Element Diversity ===")
display_cols = ['formula'] + custom_featurizer.feature_labels()
print(features_df[display_cols].to_string(index=False))
print()

# HEA determination (Shannon entropy &gt; 1.5 and Effective N &gt; 4)
print("=== High Entropy Alloy (HEA) Determination ===")
for i, formula in enumerate(compositions):
    entropy = features_df.iloc[i]['shannon_entropy']
    eff_n = features_df.iloc[i]['effective_n_elements']
    is_hea = entropy &gt; 1.5 and eff_n &gt; 4.0

    print(f"{formula:20s} | H={entropy:.3f} | N_eff={eff_n:.2f} | "
          f"{'‚úÖ HEA' if is_hea else '‚ùå Non-HEA'}")

# Expected output:
# === Custom Features: Element Diversity ===
#               formula  shannon_entropy  gini_coefficient  effective_n_elements
#                    Fe            0.000             0.000                  1.00
#                 FeNi            0.693             0.250                  2.00
#              CoCrNi            1.099             0.333                  3.00
#            CoCrFeNi            1.386             0.375                  4.00
#         CoCrFeMnNi            1.609             0.400                  5.00
#   Al0.5CoCrCuFeNi            1.705             0.429                  5.45
#
# === High Entropy Alloy (HEA) Determination ===
# Fe                   | H=0.000 | N_eff=1.00 | ‚ùå Non-HEA
# FeNi                 | H=0.693 | N_eff=2.00 | ‚ùå Non-HEA
# CoCrNi               | H=1.099 | N_eff=3.00 | ‚ùå Non-HEA
# CoCrFeNi             | H=1.386 | N_eff=4.00 | ‚ùå Non-HEA
# CoCrFeMnNi           | H=1.609 | N_eff=5.00 | ‚úÖ HEA
# Al0.5CoCrCuFeNi      | H=1.705 | N_eff=5.45 | ‚úÖ HEA
</code></pre>
<h3>3.4.2 Integrating Multiple Featurizers</h3>
<p>
            By combining multiple Featurizers, you can build a richer feature set.
            Using <code>MultipleFeaturizer</code> allows you to apply multiple Featurizers at once.
        </p>
<a class="colab-badge" href="https://colab.research.google.com/github/yourusername/composition-features/blob/main/chapter3_example6.ipynb" target="_blank">Run on Google Colab</a>
<pre><code class="language-python"># Requirements:
# - Python 3.9+
# - pandas&gt;=2.0.0, &lt;2.2.0

"""
Example: By combining multiple Featurizers, you can build a richer fe

Purpose: Demonstrate data manipulation and preprocessing
Target: Beginner to Intermediate
Execution time: 5-10 seconds
Dependencies: None
"""

# ===================================
# Example 6: MultipleFeaturizer Integration (Multiple Featurizer Pipeline)
# ===================================

from matminer.featurizers.composition import (
    ElementProperty, Stoichiometry, OxidationStates
)
from matminer.featurizers.conversions import StrToComposition
from matminer.featurizers.base import MultipleFeaturizer
import pandas as pd

# Integrate multiple Featurizers
featurizer = MultipleFeaturizer([
    ElementProperty.from_preset(preset_name="magpie"),
    Stoichiometry(p_list=[2, 3, 5, 7, 10]),
    OxidationStates(stats=['mean', 'std'])
])

# Composition data (SMILES string format)
data = pd.DataFrame({
    'formula': [
        'Fe2O3',
        'TiO2',
        'Al2O3',
        'CeO2',
        'BaTiO3',
        'LiCoO2',
        'CoCrFeMnNi'
    ],
    'target_property': [
        5.24,   # Band gap (eV) - dummy values
        3.20,
        8.80,
        3.19,
        3.38,
        2.70,
        0.00    # Metal (no band gap)
    ]
})

# Convert strings to Composition objects
str_to_comp = StrToComposition()
data = str_to_comp.featurize_dataframe(data, 'formula')

# Calculate features
features_df = featurizer.featurize_dataframe(
    data,
    col_id='composition',
    ignore_errors=True  # Continue while ignoring errors
)

# Get feature names
feature_names = featurizer.feature_labels()
print(f"=== Integrated Feature Set ===")
print(f"Total feature count: {len(feature_names)}")
print(f"- ElementProperty (Magpie): 132 dimensions")
print(f"- Stoichiometry: 5 dimensions")
print(f"- OxidationStates: 2 dimensions")
print(f"- Total: 139 dimensions")
print()

# Display first 10 features
print("=== First 10 Features ===")
display_cols = ['formula', 'target_property'] + feature_names[:10]
print(features_df[display_cols].head().to_string(index=False))
print()

# Feature statistics
print("=== Feature Statistics (Partial) ===")
stats_cols = ['MagpieData mean Number', '2-norm', 'oxidation state mean']
print(features_df[stats_cols].describe().round(3))

# Expected output:
# === Integrated Feature Set ===
# Total feature count: 139
# - ElementProperty (Magpie): 132 dimensions
# - Stoichiometry: 5 dimensions
# - OxidationStates: 2 dimensions
# - Total: 139 dimensions
#
# === First 10 Features ===
#        formula  target_property  MagpieData minimum Number  ...
#          Fe2O3             5.24                          8  ...
#           TiO2             3.20                          8  ...
#         Al2O3             8.80                          8  ...
#           CeO2             3.19                          8  ...
#        BaTiO3             3.38                          8  ...
</code></pre>
<h3>3.4.3 Batch Processing Optimization</h3>
<p>
            When handling large datasets (10,000+ compositions), batch processing optimization is important.
            <code>featurize_dataframe()</code> is faster than pandas <code>apply()</code>.
        </p>
<a class="colab-badge" href="https://colab.research.google.com/github/yourusername/composition-features/blob/main/chapter3_example7.ipynb" target="_blank">Run on Google Colab</a>
<pre><code class="language-python"># Requirements:
# - Python 3.9+
# - numpy&gt;=1.24.0, &lt;2.0.0
# - pandas&gt;=2.0.0, &lt;2.2.0

"""
Example: When handling large datasets (10,000+ compositions), batch p

Purpose: Demonstrate data manipulation and preprocessing
Target: Advanced
Execution time: 5-10 seconds
Dependencies: None
"""

# ===================================
# Example 7: Batch Processing Optimization (pandas Integration)
# ===================================

from matminer.featurizers.composition import ElementProperty
from matminer.featurizers.conversions import StrToComposition
from pymatgen.core import Composition
import pandas as pd
import time
import numpy as np

# Generate large dataset (1000 compositions)
np.random.seed(42)
elements = ['Fe', 'Co', 'Ni', 'Cu', 'Al', 'Ti', 'Cr', 'Mn']
formulas = []

for _ in range(1000):
    # Randomly select 2-5 elements
    n_elements = np.random.randint(2, 6)
    selected_elements = np.random.choice(elements, n_elements, replace=False)

    # Generate random composition ratios
    ratios = np.random.randint(1, 5, n_elements)

    # Build chemical formula
    formula = ''.join([f"{elem}{ratio}" for elem, ratio in zip(selected_elements, ratios)])
    formulas.append(formula)

# Create dataframe
data = pd.DataFrame({'formula': formulas})

# Prepare Featurizer
str_to_comp = StrToComposition()
featurizer = ElementProperty.from_preset(preset_name="magpie")

print("=== Batch Processing Performance Comparison ===")
print(f"Number of data: {len(data)} compositions")
print()

# Method 1: Sequential processing using apply() (slow)
start_time = time.time()
data_method1 = data.copy()
data_method1['composition'] = data_method1['formula'].apply(lambda x: Composition(x))
data_method1 = data_method1.apply(
    lambda row: pd.Series(featurizer.featurize(row['composition'])),
    axis=1
)
time_method1 = time.time() - start_time
print(f"Method 1 (apply)         : {time_method1:.2f} seconds")

# Method 2: Batch processing using featurize_dataframe() (fast)
start_time = time.time()
data_method2 = data.copy()
data_method2 = str_to_comp.featurize_dataframe(data_method2, 'formula')
data_method2 = featurizer.featurize_dataframe(
    data_method2,
    col_id='composition',
    multiindex=False,
    ignore_errors=True
)
time_method2 = time.time() - start_time
print(f"Method 2 (featurize_df)  : {time_method2:.2f} seconds")
print(f"Speedup factor: {time_method1/time_method2:.1f}x")
print()

# Method 3: Parallel processing (fastest)
start_time = time.time()
data_method3 = data.copy()
data_method3 = str_to_comp.featurize_dataframe(data_method3, 'formula')
data_method3 = featurizer.featurize_dataframe(
    data_method3,
    col_id='composition',
    multiindex=False,
    ignore_errors=True,
    n_jobs=-1  # Use all CPU cores
)
time_method3 = time.time() - start_time
print(f"Method 3 (parallel)      : {time_method3:.2f} seconds")
print(f"Speedup factor: {time_method1/time_method3:.1f}x")

# Expected output:
# === Batch Processing Performance Comparison ===
# Number of data: 1000 compositions
#
# Method 1 (apply)         : 12.34 seconds
# Method 2 (featurize_df)  : 3.21 seconds
# Speedup factor: 3.8x
#
# Method 3 (parallel)      : 0.87 seconds
# Speedup factor: 14.2x
</code></pre>
<h3>3.4.4 Multi-Database Integration Strategy</h3>
<p>
            For production-level applications, it's important to integrate data from multiple databases (Mendeleev, pymatgen, matminer)
            to maximize data coverage and reliability.
            The key is establishing a priority order and confidence scoring system.
        </p>
<p><strong>Data Source Priority Strategy:</strong></p>
<ol>
<li><strong>First Priority</strong>: Mendeleev experimental values (confidence: 0.95)</li>
<li><strong>Second Priority</strong>: pymatgen values (DFT or experimental, confidence: 0.80)</li>
<li><strong>Third Priority</strong>: matminer/literature values (confidence: 0.70)</li>
<li><strong>Fallback</strong>: Default values or interpolation (confidence: 0.50)</li>
</ol>
<a class="colab-badge" href="https://colab.research.google.com/github/yourusername/composition-features/blob/main/chapter3_example8.ipynb" target="_blank">Run on Google Colab</a>
<pre><code class="language-python"># Requirements:
# - Python 3.9+
# - numpy&gt;=1.24.0, &lt;2.0.0
# - pandas&gt;=2.0.0, &lt;2.2.0

# ===================================
# Example 8: Multi-Database Integration (Fallback Strategy)
# ===================================

import mendeleev
from pymatgen.core import Element, Composition
import pandas as pd
import numpy as np

class MultiSourceElementDataFetcher:
    """Element property data fetcher from multiple sources with confidence scoring

    Priority order:
    1. Mendeleev (experimental values, confidence: 0.95)
    2. pymatgen (DFT/experimental, confidence: 0.80)
    3. Default values (confidence: 0.50)
    """

    def __init__(self):
        self.confidence_scores = {
            'mendeleev': 0.95,
            'pymatgen': 0.80,
            'default': 0.50
        }

    def get_property(self, element_symbol, property_name):
        """Get element property from multiple sources with fallback

        Args:
            element_symbol (str): Element symbol (e.g., 'Fe')
            property_name (str): Property name ('electronegativity', 'atomic_radius', 'ionization_energy')

        Returns:
            dict: {'value': float, 'source': str, 'confidence': float}
        """
        # Try Mendeleev first (highest confidence)
        try:
            elem_mendeleev = mendeleev.element(element_symbol)
            if property_name == 'electronegativity':
                value = elem_mendeleev.electronegativity()
            elif property_name == 'atomic_radius':
                value = elem_mendeleev.atomic_radius
            elif property_name == 'ionization_energy':
                value = elem_mendeleev.ionenergies.get(1, None)
            else:
                value = None

            if value is not None:
                return {
                    'value': value,
                    'source': 'mendeleev',
                    'confidence': self.confidence_scores['mendeleev']
                }
        except Exception:
            pass

        # Fallback to pymatgen (medium confidence)
        try:
            elem_pymatgen = Element(element_symbol)
            if property_name == 'electronegativity':
                value = elem_pymatgen.X
            elif property_name == 'atomic_radius':
                value = elem_pymatgen.atomic_radius
            elif property_name == 'ionization_energy':
                value = elem_pymatgen.ionization_energy
            else:
                value = None

            if value is not None:
                return {
                    'value': value,
                    'source': 'pymatgen',
                    'confidence': self.confidence_scores['pymatgen']
                }
        except Exception:
            pass

        # Default value (low confidence)
        default_values = {
            'electronegativity': 1.5,
            'atomic_radius': 150.0,
            'ionization_energy': 7.0
        }

        return {
            'value': default_values.get(property_name, 0.0),
            'source': 'default',
            'confidence': self.confidence_scores['default']
        }

    def get_composition_features(self, composition):
        """Get features for a composition with confidence tracking

        Args:
            composition (str or Composition): Composition formula

        Returns:
            pd.DataFrame: Features with source and confidence information
        """
        comp = Composition(composition) if isinstance(composition, str) else composition

        results = []
        for element, fraction in comp.items():
            for prop_name in ['electronegativity', 'atomic_radius', 'ionization_energy']:
                prop_data = self.get_property(str(element), prop_name)
                results.append({
                    'element': str(element),
                    'property': prop_name,
                    'value': prop_data['value'],
                    'source': prop_data['source'],
                    'confidence': prop_data['confidence']
                })

        return pd.DataFrame(results)

# Usage example
fetcher = MultiSourceElementDataFetcher()

# Test compositions
test_compositions = [
    "Fe2O3",       # Iron oxide
    "TiO2",        # Titanium dioxide
    "CoCrFeMnNi"   # High entropy alloy
]

print("=== Data Retrieval from Multiple Sources ===")
print()

for comp_str in test_compositions:
    comp = Composition(comp_str)
    feature_df = fetcher.get_composition_features(comp)

    print(f"Composition: {comp_str}")
    print(f"  Data sources: {feature_df['source'].value_counts().to_dict()}")
    print(f"  Average confidence: {feature_df['confidence'].mean():.2f}")
    print()

# Detailed display for Fe2O3
print("=== Detailed Data for Fe2O3 ===")
fe2o3_features = fetcher.get_composition_features("Fe2O3")
print(fe2o3_features.to_string(index=False))

# Best practices
print()
print("=== Database Integration Best Practices ===")
print("‚úÖ Priority: Mendeleev (experimental) &gt; pymatgen (calculated) &gt; default values")
print("‚úÖ Record confidence scores to track data quality")
print("‚úÖ Output warnings when using default values")
print("‚úÖ Record data source and version (ensure reproducibility)")

# Expected output:
# === Data Retrieval from Multiple Sources ===
#
# Composition: Fe2O3
#   Data sources: {'mendeleev': 6}
#   Average confidence: 0.95
#
# Composition: TiO2
#   Data sources: {'mendeleev': 6}
#   Average confidence: 0.95
#
# Composition: CoCrFeMnNi
#   Data sources: {'mendeleev': 15}
#   Average confidence: 0.95
#
# === Detailed Data for Fe2O3 ===
# element           property  value      source  confidence
#      Fe  electronegativity   1.83  mendeleev        0.95
#      Fe      atomic_radius 140.00  mendeleev        0.95
#      Fe  ionization_energy   7.90  mendeleev        0.95
#       O  electronegativity   3.44  mendeleev        0.95
#       O      atomic_radius  60.00  mendeleev        0.95
#       O  ionization_energy  13.62  mendeleev        0.95
</code></pre>
<h2>Learning Objectives Review</h2>
<div class="learning-objectives">
<p>Having completed this chapter, you can now explain and implement the following:</p>
<h3>Basic Understanding</h3>
<ul>
<li>‚úÖ Explain the differences between the three data sources: Mendeleev, pymatgen, and matminer</li>
<li>‚úÖ Identify the main data sources for each database (experimental vs DFT calculated values)</li>
<li>‚úÖ Understand Featurizer architecture (BaseFeaturizer, fit/transform API)</li>
<li>‚úÖ Explain the benefits of scikit-learn compatibility</li>
</ul>
<h3>Practical Skills</h3>
<ul>
<li>‚úÖ Calculate 132-dimensional Magpie features using ElementProperty Featurizer</li>
<li>‚úÖ Calculate p-norm and compositional entropy using Stoichiometry Featurizer</li>
<li>‚úÖ Calculate oxidation state statistics using OxidationStates Featurizer</li>
<li>‚úÖ Pipeline multiple Featurizers using MultipleFeaturizer</li>
<li>‚úÖ Optimize batch processing with featurize_dataframe() and n_jobs=-1</li>
</ul>
<h3>Applied Competence</h3>
<ul>
<li>‚úÖ Design custom Featurizers by inheriting BaseFeaturizer</li>
<li>‚úÖ Implement high entropy alloy (HEA) features (Shannon entropy, Gini coefficient)</li>
<li>‚úÖ Build integration strategies to select optimal values from multiple databases</li>
<li>‚úÖ Evaluate data source reliability and select appropriate databases</li>
</ul>
</div>
<h2>Exercises</h2>
<h3>Easy (Fundamentals Review)</h3>
<p><strong>Q1</strong>: What is the main data source of the Mendeleev database?</p>
<ol type="a">
<li>DFT calculated values</li>
<li>Experimental values (NIST, CRC Handbook, etc.)</li>
<li>Machine learning predicted values</li>
<li>Literature average values</li>
</ol>
<details>
<summary>View Answer</summary>
<p><strong>Answer</strong>: b) Experimental values (NIST, CRC Handbook, etc.)</p>
<p><strong>Explanation</strong>:</p>
<p>Mendeleev is a comprehensive database centered on experimental values.
            Main sources include reliable references such as NIST (National Institute of Standards and Technology) and CRC Handbook of Chemistry and Physics. This makes it suitable for precise property prediction (melting point, density, etc.).</p>
<p>In contrast, pymatgen includes DFT calculated values from Materials Project,
            and matminer integrates property sets reported in multiple papers.</p>
</details>
<p><strong>Q2</strong>: What does the <code>feature_labels()</code> method of <code>BaseFeaturizer</code> return?</p>
<ol type="a">
<li>Feature values (list of numbers)</li>
<li>Feature names (list of strings)</li>
<li>List of references</li>
<li>Composition object</li>
</ol>
<details>
<summary>View Answer</summary>
<p><strong>Answer</strong>: b) Feature names (list of strings)</p>
<p><strong>Explanation</strong>:</p>
<p><code>feature_labels()</code> returns a list of names (labels) for the features generated by the Featurizer.
            For example, in the case of ElementProperty, it returns 132 feature names such as <code>['MagpieData minimum Number', 'MagpieData maximum Number', ...]</code>.</p>
<p>This allows you to verify what each dimension of the calculated features represents,
            improving the interpretability of machine learning models.</p>
</details>
<p><strong>Q3</strong>: In the following code, what is the type of the return value of <code>featurizer.featurize(Composition("Fe2O3"))</code>?</p>
<pre><code class="language-python">from matminer.featurizers.composition import Stoichiometry
featurizer = Stoichiometry()
result = featurizer.featurize(Composition("Fe2O3"))</code></pre>
<ol type="a">
<li>pandas DataFrame</li>
<li>numpy array</li>
<li>list</li>
<li>dict (dictionary)</li>
</ol>
<details>
<summary>View Answer</summary>
<p><strong>Answer</strong>: c) list</p>
<p><strong>Explanation</strong>:</p>
<p>The <code>featurize()</code> method calculates features for a single composition and
            returns them in <strong>Python list format</strong>.
            Example: <code>[2.0, 0.632456, 0.584804, ...]</code></p>
<p>On the other hand, the <code>featurize_dataframe()</code> method takes a pandas DataFrame as input and returns a DataFrame with added features.
            For handling large datasets, using <code>featurize_dataframe()</code> is recommended.</p>
</details>
<h3>Medium (Application)</h3>
<p><strong>Q4</strong>: As the p value of p-norm increases, what value does it converge to?
        Also, explain its physical meaning.</p>
<details>
<summary>View Answer</summary>
<p><strong>Answer</strong>: As p‚Üí‚àû, p-norm converges to the maximum mole fraction.</p>
<p><strong>Explanation</strong>:</p>
<p>The p-norm is defined by the following formula:</p>
<p>$$\text{p-norm} = \left(\sum_{i} f_i^p\right)^{1/p}$$</p>
<p>In the limit as p‚Üí‚àû, the maximum mole fraction $f_{\max}$ dominates, and p-norm ‚Üí $f_{\max}$.</p>
<p><strong>Physical Meaning</strong>:</p>
<ul>
<li>p=0: Number of element types (count of non-zero mole fractions)</li>
<li>p=2: Euclidean norm (composition "magnitude")</li>
<li>p‚Üí‚àû: Mole fraction of most abundant element (dominance of main component)</li>
</ul>
<p><strong>Application Example</strong>:</p>
<p>In high entropy alloy (HEA) research, when p=2, a 2-norm &lt; 0.5 suggests equimolar composition of 5 or more elements,
            and is used for screening HEA candidate materials.</p>
</details>
<p><strong>Q5</strong>: In the following code, how many features (dimensions) will there be?</p>
<pre><code class="language-python">from matminer.featurizers.base import MultipleFeaturizer
from matminer.featurizers.composition import (
    ElementProperty, Stoichiometry, OxidationStates
)

featurizer = MultipleFeaturizer([
    ElementProperty.from_preset("magpie"),  # 132 dimensions
    Stoichiometry(p_list=[2, 3, 5]),        # ? dimensions
    OxidationStates(stats=['mean', 'std'])  # ? dimensions
])</code></pre>
<details>
<summary>View Answer</summary>
<p><strong>Answer</strong>: 137 dimensions</p>
<p><strong>Calculation Process</strong>:</p>
<ul>
<li><strong>ElementProperty (magpie)</strong>: 132 dimensions</li>
<li><strong>Stoichiometry</strong>: 3 dimensions with p_list=[2, 3, 5]</li>
<li><strong>OxidationStates</strong>: 2 dimensions with stats=['mean', 'std']</li>
<li><strong>Total</strong>: 132 + 3 + 2 = 137 dimensions</li>
</ul>
<p><strong>Note</strong>:</p>
<p>The default for Stoichiometry is p_list=[0, 2, 3, 5, 7, 10] which gives 6 dimensions, but
            in this case p_list is explicitly specified as [2, 3, 5], resulting in 3 dimensions.</p>
<p>To verify the feature count, run <code>len(featurizer.feature_labels())</code>.</p>
</details>
<p><strong>Q6</strong>: What is the optimal method for batch applying ElementProperty Featurizer to a dataset of 1000 compositions?</p>
<ol type="a">
<li><code>df.apply(lambda x: featurizer.featurize(x['composition']), axis=1)</code></li>
<li><code>featurizer.featurize_dataframe(df, col_id='composition')</code></li>
<li><code>featurizer.featurize_dataframe(df, col_id='composition', n_jobs=-1)</code></li>
<li><code>for i in range(len(df)): featurizer.featurize(df.iloc[i]['composition'])</code></li>
</ol>
<details>
<summary>View Answer</summary>
<p><strong>Answer</strong>: c) <code>featurizer.featurize_dataframe(df, col_id='composition', n_jobs=-1)</code></p>
<p><strong>Explanation</strong>:</p>
<p>Performance comparison (for 1000 compositions):</p>
<table>
<thead>
<tr>
<th>Method</th>
<th>Execution Time</th>
<th>Speedup Factor</th>
</tr>
</thead>
<tbody>
<tr>
<td>d) for loop</td>
<td>15.2 seconds</td>
<td>1.0x (baseline)</td>
</tr>
<tr>
<td>a) apply()</td>
<td>12.3 seconds</td>
<td>1.2x</td>
</tr>
<tr>
<td>b) featurize_dataframe()</td>
<td>3.2 seconds</td>
<td>4.8x</td>
</tr>
<tr>
<td>c) featurize_dataframe(n_jobs=-1)</td>
<td>0.9 seconds</td>
<td>16.9x</td>
</tr>
</tbody>
</table>
<p><strong>Best Practices</strong>:</p>
<ul>
<li>‚úÖ Use <code>n_jobs=-1</code> to utilize all CPU cores</li>
<li>‚úÖ Use <code>ignore_errors=True</code> to skip error rows</li>
<li>‚úÖ Consider chunk-based processing for large data (&gt;10K)</li>
</ul>
</details>
<p><strong>Q7</strong>: When implementing a custom Featurizer, which methods must be implemented? (Multiple choices possible)</p>
<ol type="a">
<li><code>featurize(entry)</code></li>
<li><code>feature_labels()</code></li>
<li><code>citations()</code></li>
<li><code>fit(X, y)</code></li>
</ol>
<details>
<summary>View Answer</summary>
<p><strong>Answer</strong>: a) <code>featurize(entry)</code> and b) <code>feature_labels()</code></p>
<p><strong>Explanation</strong>:</p>
<p><strong>Required Methods</strong>:</p>
<ul>
<li><strong><code>featurize(entry)</code></strong>: Calculate features for a single entry (returns list)</li>
<li><strong><code>feature_labels()</code></strong>: Return list of feature names</li>
</ul>
<p><strong>Optional Methods</strong>:</p>
<ul>
<li><strong><code>citations()</code></strong>: Return list of references (recommended)</li>
<li><strong><code>implementors()</code></strong>: Return list of implementors (recommended)</li>
<li><strong><code>fit(X, y)</code></strong>: Learn from training data (only when necessary)</li>
</ul>
<p><strong>Implementation Example</strong>:</p>
<pre><code class="language-python">class CustomFeaturizer(BaseFeaturizer):
    def featurize(self, comp):
        # Calculate features
        return [value1, value2, ...]

    def feature_labels(self):
        # Return feature names
        return ['feature1', 'feature2', ...]

    def citations(self):
        # Return references (recommended)
        return ['@article{...}']

    def implementors(self):
        # Return implementors (recommended)
        return ['Your Name']</code></pre>
</details>
<h3>Hard (Advanced)</h3>
<p><strong>Q8</strong>: Design a custom Featurizer to identify high entropy alloys (HEA).
        Show an implementation that calculates the following features:</p>
<ul>
<li>Shannon entropy: $H = -\sum_i f_i \ln(f_i)$</li>
<li>Effective number of elements: $N_{\text{eff}} = \exp(H)$</li>
<li>HEA determination: $H &gt; 1.5$ and $N_{\text{eff}} &gt; 4.0$</li>
</ul>
<details>
<summary>View Answer</summary>
<p><strong>Implementation Example</strong>:</p>
<pre><code class="language-python"># Requirements:
# - Python 3.9+
# - numpy&gt;=1.24.0, &lt;2.0.0
# - pandas&gt;=2.0.0, &lt;2.2.0

from matminer.featurizers.base import BaseFeaturizer
from pymatgen.core import Composition
import numpy as np

class HEAFeaturizer(BaseFeaturizer):
    """High Entropy Alloy (HEA) Features

    Features:
    - shannon_entropy: Compositional entropy
    - effective_n_elements: Effective number of elements
    - is_hea: HEA determination (True/False ‚Üí 1/0)
    """

    def featurize(self, comp):
        """Calculate features

        Args:
            comp (Composition): pymatgen Composition object

        Returns:
            list: [shannon_entropy, effective_n_elements, is_hea]
        """
        # Get mole fractions
        fractions = np.array(list(comp.fractional_composition.values()))

        # Shannon entropy
        # H = -Œ£(f_i * log(f_i))
        # Add small value to avoid log(0)
        shannon_entropy = -np.sum(fractions * np.log(fractions + 1e-10))

        # Effective number of elements
        # N_eff = exp(H)
        effective_n = np.exp(shannon_entropy)

        # HEA determination
        is_hea = 1.0 if (shannon_entropy &gt; 1.5 and effective_n &gt; 4.0) else 0.0

        return [shannon_entropy, effective_n, is_hea]

    def feature_labels(self):
        """Return list of feature names"""
        return [
            'shannon_entropy',
            'effective_n_elements',
            'is_hea'
        ]

    def citations(self):
        """Return list of references"""
        return [
            "@article{yeh2004nanostructured, "
            "title={Nanostructured high-entropy alloys with multiple principal elements}, "
            "author={Yeh, Jien-Wei and Chen, Swe-Kai and Lin, Su-Jien and others}, "
            "journal={Advanced Engineering Materials}, "
            "volume={6}, number={5}, pages={299--303}, year={2004}}"
        ]

    def implementors(self):
        """Return list of implementors"""
        return ['Custom HEA Featurizer']

# Usage example
featurizer = HEAFeaturizer()

# Test data
test_compositions = [
    "Fe",              # H=0.00, N_eff=1.00 ‚Üí Non-HEA
    "FeNi",            # H=0.69, N_eff=2.00 ‚Üí Non-HEA
    "CoCrFeNi",        # H=1.39, N_eff=4.00 ‚Üí Non-HEA (borderline)
    "CoCrFeMnNi",      # H=1.61, N_eff=5.00 ‚Üí HEA
    "AlCoCrFeNi"       # H=1.61, N_eff=5.00 ‚Üí HEA
]

import pandas as pd
comp_objects = [Composition(c) for c in test_compositions]
df = featurizer.featurize_dataframe(
    pd.DataFrame({'formula': test_compositions, 'composition': comp_objects}),
    col_id='composition'
)

print(df[['formula', 'shannon_entropy', 'effective_n_elements', 'is_hea']])

# Expected output:
#         formula  shannon_entropy  effective_n_elements  is_hea
# 0            Fe             0.00                  1.00     0.0
# 1          FeNi             0.69                  2.00     0.0
# 2      CoCrFeNi             1.39                  4.00     0.0
# 3   CoCrFeMnNi             1.61                  5.00     1.0
# 4    AlCoCrFeNi             1.61                  5.00     1.0</code></pre>
<p><strong>Key Points</strong>:</p>
<ul>
<li>‚úÖ Use <code>np.log(fractions + 1e-10)</code> to avoid <code>log(0)</code> error</li>
<li>‚úÖ Return HEA determination as 1.0/0.0 floating point instead of Boolean (compatibility with ML models)</li>
<li>‚úÖ Shannon entropy threshold (1.5) is based on literature values</li>
</ul>
</details>
<p><strong>Q9</strong>: Implement a function that retrieves electronegativity from multiple databases (Mendeleev, pymatgen, matminer)
        and calculates confidence scores. Define confidence as follows:</p>
<ul>
<li>Mendeleev (experimental values): 0.95</li>
<li>pymatgen (calculated values): 0.80</li>
<li>Default values: 0.50</li>
</ul>
<details>
<summary>View Answer</summary>
<p><strong>Implementation Example</strong>:</p>
<pre><code class="language-python"># Requirements:
# - Python 3.9+
# - pandas&gt;=2.0.0, &lt;2.2.0

import mendeleev
from pymatgen.core import Element
import pandas as pd

def get_electronegativity_with_confidence(element_symbol):
    """Retrieve electronegativity from multiple sources with confidence

    Args:
        element_symbol (str): Element symbol (e.g., 'Fe')

    Returns:
        dict: {'value': float, 'source': str, 'confidence': float}
    """
    # Try Mendeleev first (highest confidence)
    try:
        elem = mendeleev.element(element_symbol)
        en = elem.electronegativity()
        if en is not None:
            return {
                'value': en,
                'source': 'mendeleev',
                'confidence': 0.95
            }
    except Exception:
        pass

    # Fallback to pymatgen (medium confidence)
    try:
        elem = Element(element_symbol)
        en = elem.X
        if en is not None:
            return {
                'value': en,
                'source': 'pymatgen',
                'confidence': 0.80
            }
    except Exception:
        pass

    # Default value (low confidence)
    return {
        'value': 1.5,  # Typical electronegativity
        'source': 'default',
        'confidence': 0.50
    }

# Usage example
elements = ['Fe', 'Cu', 'Al', 'Ti', 'Uuo']  # Uuo is synthetic element

print("=== Electronegativity with Confidence Scores ===")
results = []
for elem in elements:
    data = get_electronegativity_with_confidence(elem)
    results.append({
        'Element': elem,
        'Electronegativity': data['value'],
        'Source': data['source'],
        'Confidence': data['confidence']
    })

df = pd.DataFrame(results)
print(df.to_string(index=False))

# Expected output:
# === Electronegativity with Confidence Scores ===
# Element  Electronegativity      Source  Confidence
#      Fe               1.83  mendeleev        0.95
#      Cu               1.90  mendeleev        0.95
#      Al               1.61  mendeleev        0.95
#      Ti               1.54  mendeleev        0.95
#     Uuo               1.50     default        0.50  # Synthetic element, no data</code></pre>
<p><strong>Application to Production Systems</strong>:</p>
<ul>
<li>‚úÖ Record confidence scores in metadata for traceability</li>
<li>‚úÖ Issue warnings when confidence &lt; 0.70</li>
<li>‚úÖ Use weighted averaging based on confidence for ensemble predictions</li>
<li>‚úÖ Track data source versions for reproducibility</li>
</ul>
</details>
<p><strong>Q10</strong>: Implement an efficient feature calculation pipeline for a large dataset (100,000 compositions).
        Include the following optimizations:</p>
<ul>
<li>Chunk-based processing (chunk size: 1,000)</li>
<li>Parallel processing (n_jobs=-1)</li>
<li>Progress monitoring (tqdm)</li>
<li>Error handling (ignore_errors=True)</li>
</ul>
<details>
<summary>View Answer</summary>
<p><strong>Implementation Example</strong>:</p>
<pre><code class="language-python"># Requirements:
# - Python 3.9+
# - numpy&gt;=1.24.0, &lt;2.0.0
# - pandas&gt;=2.0.0, &lt;2.2.0
# - tqdm&gt;=4.65.0

from matminer.featurizers.composition import ElementProperty
from matminer.featurizers.conversions import StrToComposition
import pandas as pd
import numpy as np
from tqdm import tqdm
import time

def featurize_large_dataset(formulas, chunk_size=1000):
    """Efficiently featurize large dataset with chunking and parallel processing

    Args:
        formulas (list): List of chemical formulas
        chunk_size (int): Number of compositions per chunk

    Returns:
        pd.DataFrame: Featurized dataset
    """
    # Initialize featurizers
    str_to_comp = StrToComposition()
    featurizer = ElementProperty.from_preset("magpie")

    # Split into chunks
    n_chunks = (len(formulas) + chunk_size - 1) // chunk_size
    chunks = np.array_split(formulas, n_chunks)

    results = []

    print(f"=== Large Dataset Feature Calculation ===")
    print(f"Number of data: {len(formulas):,} compositions")
    print(f"Chunk size: {chunk_size:,} compositions")
    print()

    # Process chunks with progress bar
    for i, chunk in enumerate(tqdm(chunks, desc="Processing chunks")):
        # Create dataframe for chunk
        chunk_df = pd.DataFrame({'formula': chunk})

        # Convert to Composition
        chunk_df = str_to_comp.featurize_dataframe(
            chunk_df,
            'formula',
            ignore_errors=True
        )

        # Calculate features with parallel processing
        chunk_df = featurizer.featurize_dataframe(
            chunk_df,
            col_id='composition',
            multiindex=False,
            ignore_errors=True,
            n_jobs=-1  # Use all CPU cores
        )

        results.append(chunk_df)

    # Concatenate all chunks
    final_df = pd.concat(results, ignore_index=True)
    return final_df

# Generate test dataset (100,000 compositions)
np.random.seed(42)
elements = ['Fe', 'Co', 'Ni', 'Cu', 'Al', 'Ti', 'Cr', 'Mn']
formulas = []

for _ in range(100000):
    n_elem = np.random.randint(2, 6)
    selected = np.random.choice(elements, n_elem, replace=False)
    ratios = np.random.randint(1, 5, n_elem)
    formula = ''.join([f"{e}{r}" for e, r in zip(selected, ratios)])
    formulas.append(formula)

# Execute featurization
start_time = time.time()
result_df = featurize_large_dataset(formulas, chunk_size=1000)
elapsed_time = time.time() - start_time

print(f"\nProcessing completed: {elapsed_time:.1f} seconds")
print(f"Processing speed: {len(formulas) / elapsed_time:.0f} compositions/second")
print(f"Number of features: {len(result_df.columns)} dimensions")

# Display partial results
print("\n=== Results (First 5 rows) ===")
print(result_df.head())

# Expected output:
# === Large Dataset Feature Calculation ===
# Number of data: 100,000 compositions
# Chunk size: 1,000 compositions
#
# Processing chunks: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [02:34&lt;00:00,  1.55s/it]
#
# Processing completed: 154.3 seconds
# Processing speed: 648 compositions/second
# Number of features: 135 dimensions</code></pre>
<p><strong>Optimization Points</strong>:</p>
<ul>
<li>‚úÖ Chunk size: 1,000-10,000 is optimal (memory vs speed tradeoff)</li>
<li>‚úÖ Enable parallel processing with <code>n_jobs=-1</code></li>
<li>‚úÖ Skip error rows with <code>ignore_errors=True</code></li>
<li>‚úÖ Display progress bar with <code>tqdm</code> (user-friendly)</li>
<li>‚úÖ Monitor memory usage (use <code>psutil</code>)</li>
</ul>
<p><strong>Further Optimizations</strong>:</p>
<ul>
<li>Distributed processing using Dask (&gt;1M compositions)</li>
<li>Save intermediate results in HDF5/Parquet format</li>
<li>GPU acceleration (CuPy, RAPIDS)</li>
</ul>
</details>
<h2>Next Steps</h2>
<p>
            In this chapter, we learned about the differences between element property databases (Mendeleev, pymatgen, matminer) and
            the Featurizer architecture.
            In the next chapter, we will learn how to build actual machine learning models using these features,
            and techniques for feature selection and dimensionality reduction.
        </p>
<div class="nav-buttons">
<a class="nav-button" href="chapter-2.html">‚Üê Chapter 2: Magpie and Statistical Descriptors</a>
<a class="nav-button" href="chapter-4.html">Chapter 4: Integration with Machine Learning ‚Üí</a>
</div>
<h2>References</h2>
<ol>
<li>
                Ward, L., Dunn, A., Faghaninia, A., Zimmermann, N. E., Bajaj, S., Wang, Q., ... &amp; Jain, A. (2018).
                "Matminer: An open source toolkit for materials data mining."
                <em>Computational Materials Science</em>, 152, 60-69.
                DOI: <a href="https://doi.org/10.1016/j.commatsci.2018.05.018" target="_blank">10.1016/j.commatsci.2018.05.018</a>
<br/><em>Original matminer paper. Details of Featurizer architecture and main features (pp. 62-66)</em>
</li>
<li>
                Ong, S. P., Richards, W. D., Jain, A., Hautier, G., Kocher, M., Cholia, S., ... &amp; Ceder, G. (2013).
                "Python Materials Genomics (pymatgen): A robust, open-source python library for materials analysis."
                <em>Computational Materials Science</em>, 68, 314-319.
                DOI: <a href="https://doi.org/10.1016/j.commatsci.2012.10.028" target="_blank">10.1016/j.commatsci.2012.10.028</a>
<br/><em>Original pymatgen library paper. Details of Element and Composition classes (pp. 315-317)</em>
</li>
<li>
                Himanen, L., J√§ger, M. O., Morooka, E. V., Federici Canova, F., Ranawat, Y. S., Gao, D. Z., ... &amp; Foster, A. S. (2019).
                "DScribe: Library of descriptors for machine learning in materials science."
                <em>Computer Physics Communications</em>, 247, 106949, pp. 1-15.
                DOI: <a href="https://doi.org/10.1016/j.cpc.2019.106949" target="_blank">10.1016/j.cpc.2019.106949</a>
<br/><em>Comprehensive review of material descriptors. Theoretical background of composition-based features (pp. 3-7)</em>
</li>
<li>
                matminer API Documentation: Featurizer classes.
                <a href="https://hackingmaterials.lbl.gov/matminer/" target="_blank">https://hackingmaterials.lbl.gov/matminer/</a>
<br/><em>Official matminer documentation. Detailed usage examples and parameter descriptions for each Featurizer</em>
</li>
<li>
                pymatgen.core.periodic_table Documentation.
                <a href="https://pymatgen.org/pymatgen.core.periodic_table.html" target="_blank">https://pymatgen.org/</a>
<br/><em>Detailed API specifications for pymatgen's Element and Composition classes</em>
</li>
<li>
                Mendeleev package documentation.
                <a href="https://mendeleev.readthedocs.io/" target="_blank">https://mendeleev.readthedocs.io/</a>
<br/><em>Official Mendeleev package documentation. Element property data sources and accuracy information</em>
</li>
<li>
                Materials Project Database documentation.
                <a href="https://docs.materialsproject.org/" target="_blank">https://docs.materialsproject.org/</a>
<br/><em>Official Materials Project documentation. Details of DFT calculation methods and database structure</em>
</li>
</ol>
<hr style="margin: 3rem 0; border: none; border-top: 1px solid var(--border-color);"/>
<div class="nav-buttons">
<a class="nav-button" href="index.html">Back to Series Index</a>
<a class="nav-button" href="chapter-4.html">Proceed to Chapter 4 ‚Üí</a>
</div>
<p style="text-align: center; color: #666; font-size: 0.9rem; margin-top: 2rem;">
            ¬© 2025 AI Terakoya - Materials Informatics Knowledge Hub
        </p>
</main>
</body>
</html>
