<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Chapter 2: Fundamentals of GNN Theory - AI Terakoya</title>

    <style>
        :root {
            --color-primary: #2c3e50;
            --color-primary-dark: #1a252f;
            --color-accent: #7b2cbf;
            --color-accent-light: #9d4edd;
            --color-text: #2d3748;
            --color-text-light: #4a5568;
            --color-bg: #ffffff;
            --color-bg-alt: #f7fafc;
            --color-border: #e2e8f0;
            --color-code-bg: #f8f9fa;
            --color-link: #3182ce;
            --color-link-hover: #2c5aa0;

            --spacing-xs: 0.5rem;
            --spacing-sm: 1rem;
            --spacing-md: 1.5rem;
            --spacing-lg: 2rem;
            --spacing-xl: 3rem;

            --font-body: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            --font-mono: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;

            --border-radius: 8px;
            --box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: var(--font-body);
            line-height: 1.7;
            color: var(--color-text);
            background-color: var(--color-bg);
            font-size: 16px;
        }

        header {
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            padding: var(--spacing-xl) var(--spacing-md);
            margin-bottom: var(--spacing-xl);
            box-shadow: var(--box-shadow);
        }

        .header-content {
            max-width: 900px;
            margin: 0 auto;
        }

        h1 {
            font-size: 2rem;
            font-weight: 700;
            margin-bottom: var(--spacing-sm);
            line-height: 1.2;
        }

        .subtitle {
            font-size: 1.1rem;
            opacity: 0.95;
            font-weight: 400;
            margin-bottom: var(--spacing-md);
        }

        .meta {
            display: flex;
            flex-wrap: wrap;
            gap: var(--spacing-md);
            font-size: 0.9rem;
            opacity: 0.9;
        }

        .meta-item {
            display: flex;
            align-items: center;
            gap: 0.3rem;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 0 var(--spacing-md) var(--spacing-xl);
        }

        h2 {
            font-size: 1.75rem;
            color: var(--color-primary);
            margin-top: var(--spacing-xl);
            margin-bottom: var(--spacing-md);
            padding-bottom: var(--spacing-xs);
            border-bottom: 3px solid var(--color-accent);
        }

        h3 {
            font-size: 1.4rem;
            color: var(--color-primary);
            margin-top: var(--spacing-lg);
            margin-bottom: var(--spacing-sm);
        }

        h4 {
            font-size: 1.1rem;
            color: var(--color-primary-dark);
            margin-top: var(--spacing-md);
            margin-bottom: var(--spacing-sm);
        }

        p {
            margin-bottom: var(--spacing-md);
            color: var(--color-text);
        }

        a {
            color: var(--color-link);
            text-decoration: none;
            transition: color 0.2s;
        }

        a:hover {
            color: var(--color-link-hover);
            text-decoration: underline;
        }

        ul, ol {
            margin-left: var(--spacing-lg);
            margin-bottom: var(--spacing-md);
        }

        li {
            margin-bottom: var(--spacing-xs);
            color: var(--color-text);
        }

        pre {
            background-color: var(--color-code-bg);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            overflow-x: auto;
            margin-bottom: var(--spacing-md);
            font-family: var(--font-mono);
            font-size: 0.9rem;
            line-height: 1.5;
        }

        code {
            font-family: var(--font-mono);
            font-size: 0.9em;
            background-color: var(--color-code-bg);
            padding: 0.2em 0.4em;
            border-radius: 3px;
        }

        pre code {
            background-color: transparent;
            padding: 0;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: var(--spacing-md);
            font-size: 0.95rem;
        }

        th, td {
            border: 1px solid var(--color-border);
            padding: var(--spacing-sm);
            text-align: left;
        }

        th {
            background-color: var(--color-bg-alt);
            font-weight: 600;
            color: var(--color-primary);
        }

        blockquote {
            border-left: 4px solid var(--color-accent);
            padding-left: var(--spacing-md);
            margin: var(--spacing-md) 0;
            color: var(--color-text-light);
            font-style: italic;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        .mermaid {
            text-align: center;
            margin: var(--spacing-lg) 0;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        details {
            background-color: var(--color-bg-alt);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            margin-bottom: var(--spacing-md);
        }

        summary {
            cursor: pointer;
            font-weight: 600;
            color: var(--color-primary);
            user-select: none;
            padding: var(--spacing-xs);
            margin: calc(-1 * var(--spacing-md));
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        summary:hover {
            background-color: rgba(123, 44, 191, 0.1);
        }

        details[open] summary {
            margin-bottom: var(--spacing-md);
            border-bottom: 1px solid var(--color-border);
        }

        .learning-objectives {
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
            padding: var(--spacing-lg);
            border-radius: var(--border-radius);
            border-left: 4px solid var(--color-accent);
            margin-bottom: var(--spacing-xl);
        }

        .learning-objectives h2 {
            margin-top: 0;
            border-bottom: none;
        }

        .navigation {
            display: flex;
            justify-content: space-between;
            gap: var(--spacing-md);
            margin: var(--spacing-xl) 0;
            padding-top: var(--spacing-lg);
            border-top: 2px solid var(--color-border);
        }

        .nav-button {
            flex: 1;
            padding: var(--spacing-md);
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            border-radius: var(--border-radius);
            text-align: center;
            font-weight: 600;
            transition: transform 0.2s, box-shadow 0.2s;
            box-shadow: var(--box-shadow);
        }

        .nav-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
            text-decoration: none;
        }

        footer {
            margin-top: var(--spacing-xl);
            padding: var(--spacing-lg) var(--spacing-md);
            background-color: var(--color-bg-alt);
            border-top: 1px solid var(--color-border);
            text-align: center;
            font-size: 0.9rem;
            color: var(--color-text-light);
        }
        .disclaimer {
            max-width: 900px;
            margin: 2rem auto;
            padding: 1.5rem;
            background: #f8f9fa;
            border-left: 4px solid #6c757d;
            border-radius: 4px;
        }

        .disclaimer h3 {
            color: #495057;
            margin-bottom: 1rem;
            font-size: 1.1rem;
        }

        .disclaimer ul {
            list-style: none;
            padding-left: 0;
        }

        .disclaimer li {
            padding: 0.5rem 0;
            padding-left: 1.5rem;
            position: relative;
            font-size: 0.9rem;
            color: #6c757d;
            line-height: 1.6;
        }

        .disclaimer li::before {
            content: "‚ö†Ô∏è";
            position: absolute;
            left: 0;
        }


        @media (max-width: 768px) {
            h1 {
                font-size: 1.5rem;
            }

            h2 {
                font-size: 1.4rem;
            }

            h3 {
                font-size: 1.2rem;
            }

            .meta {
                font-size: 0.85rem;
            }

            .navigation {
                flex-direction: column;
            }

            table {
                font-size: 0.85rem;
            }

            th, td {
                padding: var(--spacing-xs);
            }
        }



        /* Breadcrumb styles */
        .breadcrumb {
            background: #f7fafc;
            padding: 0.75rem 1rem;
            border-bottom: 1px solid #e2e8f0;
            font-size: 0.9rem;
        }

        .breadcrumb-content {
            max-width: 900px;
            margin: 0 auto;
            display: flex;
            align-items: center;
            flex-wrap: wrap;
            gap: 0.5rem;
        }

        .breadcrumb a {
            color: #667eea;
            text-decoration: none;
            transition: color 0.2s;
        }

        .breadcrumb a:hover {
            color: #764ba2;
            text-decoration: underline;
        }

        .breadcrumb-separator {
            color: #a0aec0;
            margin: 0 0.25rem;
        }

        .breadcrumb-current {
            color: #4a5568;
            font-weight: 500;
        }
    </style>

    <script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
    <script>
        mermaid.initialize({ startOnLoad: true, theme: 'default', securityLevel: 'strict' });
    </script>

    <!-- MathJax for LaTeX equation rendering -->
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\(', '\)']],
                displayMath: [['$$', '$$'], ['\[', '\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
                ignoreHtmlClass: 'mermaid'
            }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" async></script>
</head>
<body>
            <nav class="breadcrumb">
        <div class="breadcrumb-content">
            <a href="/AI-Knowledge-Notes/knowledge/en/index.html">AI Terakoya Home</a><span class="breadcrumb-separator">‚Ä∫</span><a href="/AI-Knowledge-Notes/knowledge/en/MI/index.html">Materials Informatics</a><span class="breadcrumb-separator">‚Ä∫</span><a href="/AI-Knowledge-Notes/knowledge/en/MI/gnn-introduction/index.html">Gnn</a><span class="breadcrumb-separator">‚Ä∫</span><span class="breadcrumb-current">Chapter 2</span>
        </div>
    </nav>

        <header>
        <div class="header-content">
            <h1>Chapter 2: Fundamentals of GNN Theory</h1>
            <p class="subtitle">From Message Passing to Materials Science-Specialized GNNs</p>
            <div class="meta">
                <span class="meta-item">üìñ Reading Time: 25-30 min</span>
                <span class="meta-item">üìä Level: Intermediate</span>
                <span class="meta-item">üíª Code Examples: 10</span>
                <span class="meta-item">üìù Exercises: 3</span>
            </div>
        </div>
    </header>

    <main class="container">
<h1>Chapter 2: Fundamentals of GNN Theory</h1>
<p class="chapter-description" style="margin: 1.5rem 0; padding: 1rem; background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%); border-left: 4px solid #7b2cbf; border-radius: 8px; font-size: 1.05rem; line-height: 1.8; color: #2d3748;">We organize the basic mechanisms of message passing so you can grasp them intuitively even without formulas. We cover the differences between representative models and when to use each.</p>
<p class="chapter-supplement" style="margin: 0.75rem 0 1.5rem 0; padding: 0.75rem 1rem; background: linear-gradient(135deg, #fff8e1 0%, #fff3cd 100%); border-left: 3px solid #f59e0b; border-radius: 6px; font-size: 0.95rem; line-height: 1.7; color: #4a5568;"><strong>üí° Note:</strong> Understanding is faster when you think separately about three points: the amount transmitted (weights), the number of times (layers), and how it's received (aggregation).</p>




<p><strong>From Message Passing to Materials Science-Specialized GNNs</strong></p>
<h2>Learning Objectives</h2>
<p>By reading this chapter, you will master:</p>
<ul>
<li>‚úÖ Understand mathematical definitions and representations of graphs</li>
<li>‚úÖ Explain the 3 steps of message passing (aggregation ‚Üí update ‚Üí output)</li>
<li>‚úÖ Understand the principles and differences of GCN, GAT, and GraphSAGE</li>
<li>‚úÖ Learn the features of materials science-specialized GNNs (SchNet, DimeNet)</li>
<li>‚úÖ Implement simple GNNs in PyTorch</li>
<li>‚úÖ Understand the importance of equivariant GNNs</li>
</ul>
<p><strong>Reading Time</strong>: 25-30 min
<strong>Code Examples</strong>: 10
<strong>Exercises</strong>: 3</p>
<hr />
<h2>2.1 Mathematical Definition of Graphs</h2>
<h3>Basic Elements of Graphs</h3>
<p><strong>Definition</strong>:</p>
<blockquote>
<p>A graph $G = (V, E)$ consists of a vertex set $V$ and an edge set $E \subseteq V \times V$.</p>
</blockquote>
<p><strong>Notation</strong>:
- $n = |V|$: Number of vertices
- $m = |E|$: Number of edges
- $\mathcal{N}(v)$: Neighbor set of vertex $v$</p>
<hr />
<h3>Adjacency Matrix</h3>
<p><strong>Definition</strong>:
$$
A \in {0, 1}^{n \times n}, \quad A_{ij} = \begin{cases}
1 &amp; \text{if } (v_i, v_j) \in E \
0 &amp; \text{otherwise}
\end{cases}
$$</p>
<p><strong>Python Implementation</strong>:</p>
<pre><code class="language-python">import numpy as np

# Example: Triangle graph (3 vertices, 3 edges)
n = 3
A = np.array([
    [0, 1, 1],  # Vertex 0: connected to 1, 2
    [1, 0, 1],  # Vertex 1: connected to 0, 2
    [1, 1, 0]   # Vertex 2: connected to 0, 1
])

print(&quot;Adjacency Matrix:&quot;)
print(A)
print(f&quot;\nNumber of vertices: {n}&quot;)
print(f&quot;Number of edges: {A.sum() // 2}&quot;)  # Divide by 2 for undirected graphs
</code></pre>
<p><strong>Output</strong>:</p>
<pre><code>Adjacency Matrix:
[[0 1 1]
 [1 0 1]
 [1 1 0]]

Number of vertices: 3
Number of edges: 3
</code></pre>
<hr />
<h3>Degree Matrix</h3>
<p><strong>Definition</strong>:
$$
D \in \mathbb{R}^{n \times n}, \quad D_{ii} = \sum_{j=1}^{n} A_{ij}
$$</p>
<p><strong>Physical Meaning</strong>: Number of connections per vertex (number of bonds in chemistry)</p>
<pre><code class="language-python"># Degree matrix
D = np.diag(A.sum(axis=1))
print(&quot;Degree Matrix:&quot;)
print(D)
print(f&quot;\nDegree of each vertex: {np.diag(D)}&quot;)
</code></pre>
<p><strong>Output</strong>:</p>
<pre><code>Degree Matrix:
[[2 0 0]
 [0 2 0]
 [0 0 2]]

Degree of each vertex: [2 2 2]
</code></pre>
<hr />
<h3>Laplacian Matrix</h3>
<p><strong>Definition</strong>:
$$
L = D - A
$$</p>
<p><strong>Normalized Laplacian</strong> (commonly used in GNNs):
$$
\tilde{L} = D^{-1/2} L D^{-1/2} = I - D^{-1/2} A D^{-1/2}
$$</p>
<pre><code class="language-python"># Laplacian matrix
L = D - A
print(&quot;Laplacian Matrix:&quot;)
print(L)

# Normalized Laplacian
D_inv_sqrt = np.diag(1 / np.sqrt(np.diag(D)))
L_norm = np.eye(n) - D_inv_sqrt @ A @ D_inv_sqrt
print(&quot;\nNormalized Laplacian:&quot;)
print(L_norm)
</code></pre>
<p><strong>Output</strong>:</p>
<pre><code>Laplacian Matrix:
[[ 2 -1 -1]
 [-1  2 -1]
 [-1 -1  2]]

Normalized Laplacian:
[[ 1.  -0.5 -0.5]
 [-0.5  1.  -0.5]
 [-0.5 -0.5  1. ]]
</code></pre>
<p><strong>Applications</strong>:
- Spectral graph theory
- Graph Fourier transform
- Graph signal processing</p>
<hr />
<h3>Vertex Features and Edge Features</h3>
<p><strong>Vertex Feature Matrix</strong> $X \in \mathbb{R}^{n \times d}$:
- Each row $x_i \in \mathbb{R}^d$: Feature vector of vertex $i$
- Materials science: atomic number, electronegativity, valence electrons, etc.</p>
<p><strong>Edge Feature Matrix</strong> $E \in \mathbb{R}^{m \times d_e}$:
- Each row $e_{ij} \in \mathbb{R}^{d_e}$: Features of edge $(i, j)$
- Materials science: bond length, bond order, bond angle, etc.</p>
<pre><code class="language-python"># Example: Features of water molecule (H‚ÇÇO)
X = np.array([
    [8, 2.55, 6],   # O: atomic number 8, electronegativity 2.55, valence electrons 6
    [1, 2.20, 1],   # H1
    [1, 2.20, 1]    # H2
])

print(&quot;Vertex Feature Matrix (3√ó3):&quot;)
print(X)
print(f&quot;Shape: {X.shape}&quot;)
</code></pre>
<hr />
<h2>2.2 Message Passing Mechanism</h2>
<h3>Message Passing Neural Network (MPNN)</h3>
<p>This is the <strong>unified framework</strong> for GNNs (Gilmer et al., 2017).</p>
<p><strong>Algorithm</strong>:</p>
<div class="mermaid">
flowchart LR
    A[Input: Vertex features X] --> B[Step 1: Message Generation]
    B --> C[Step 2: Aggregation]
    C --> D[Step 3: Update]
    D --> E{Repeat?}
    E -->|Yes| B
    E -->|No| F[Output: New features]

    style A fill:#e3f2fd
    style B fill:#fff3e0
    style C fill:#f3e5f5
    style D fill:#e8f5e9
    style F fill:#ffebee
</div>

<hr />
<h3>Step 1: Message Generation</h3>
<p><strong>Definition</strong>:
$$
m_{ij}^{(t)} = \text{Message}(h_i^{(t)}, h_j^{(t)}, e_{ij})
$$</p>
<ul>
<li>$h_i^{(t)}$: Hidden state of vertex $i$ at layer $t$</li>
<li>$h_j^{(t)}$: Hidden state of neighbor vertex $j$</li>
<li>$e_{ij}$: Features of edge $(i, j)$</li>
</ul>
<p><strong>Simplest Form</strong>:
$$
m_{ij}^{(t)} = W \cdot h_j^{(t)}
$$</p>
<pre><code class="language-python">import torch
import torch.nn as nn

class MessageFunction(nn.Module):
    def __init__(self, in_dim, out_dim):
        super().__init__()
        self.W = nn.Linear(in_dim, out_dim)

    def forward(self, h_j):
        &quot;&quot;&quot;
        Generate messages from neighbor vertices

        Parameters:
        -----------
        h_j : Tensor (num_neighbors, in_dim)
            Features of neighbor vertices

        Returns:
        --------
        messages : Tensor (num_neighbors, out_dim)
            Generated messages
        &quot;&quot;&quot;
        return self.W(h_j)

# Example
in_dim, out_dim = 16, 32
msg_fn = MessageFunction(in_dim, out_dim)

# Features of neighbor vertices (3 neighbors)
h_neighbors = torch.randn(3, in_dim)
messages = msg_fn(h_neighbors)
print(f&quot;Message shape: {messages.shape}&quot;)
# Output: torch.Size([3, 32])
</code></pre>
<hr />
<h3>Step 2: Aggregation</h3>
<p><strong>Definition</strong>:
$$
m_i^{(t)} = \text{Aggregate}\left( {m_{ij}^{(t)} : j \in \mathcal{N}(i)} \right)
$$</p>
<p><strong>Representative Aggregation Functions</strong>:</p>
<table>
<thead>
<tr>
<th>Aggregation Method</th>
<th>Formula</th>
<th>Characteristics</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Sum</strong></td>
<td>$\sum_{j \in \mathcal{N}(i)} m_{ij}^{(t)}$</td>
<td>Order invariant, sensitive to degree</td>
</tr>
<tr>
<td><strong>Mean</strong></td>
<td>$\frac{1}{|\mathcal{N}(i)|} \sum_{j \in \mathcal{N}(i)} m_{ij}^{(t)}$</td>
<td>Normalized by degree</td>
</tr>
<tr>
<td><strong>Max</strong></td>
<td>$\max_{j \in \mathcal{N}(i)} m_{ij}^{(t)}$</td>
<td>Preserves strongest feature</td>
</tr>
<tr>
<td><strong>Attention</strong></td>
<td>$\sum_{j \in \mathcal{N}(i)} \alpha_{ij} m_{ij}^{(t)}$</td>
<td>Weighted by importance</td>
</tr>
</tbody>
</table>
<pre><code class="language-python">class AggregationFunction:
    @staticmethod
    def sum_agg(messages):
        &quot;&quot;&quot;Sum aggregation&quot;&quot;&quot;
        return torch.sum(messages, dim=0)

    @staticmethod
    def mean_agg(messages):
        &quot;&quot;&quot;Mean aggregation&quot;&quot;&quot;
        return torch.mean(messages, dim=0)

    @staticmethod
    def max_agg(messages):
        &quot;&quot;&quot;Max aggregation&quot;&quot;&quot;
        return torch.max(messages, dim=0)[0]

# Example
messages = torch.tensor([
    [1.0, 2.0, 3.0],
    [4.0, 5.0, 6.0],
    [7.0, 8.0, 9.0]
])

print(&quot;Sum:&quot;, AggregationFunction.sum_agg(messages))
# Output: tensor([12., 15., 18.])

print(&quot;Mean:&quot;, AggregationFunction.mean_agg(messages))
# Output: tensor([4., 5., 6.])

print(&quot;Max:&quot;, AggregationFunction.max_agg(messages))
# Output: tensor([7., 8., 9.])
</code></pre>
<hr />
<h3>Step 3: Update</h3>
<p><strong>Definition</strong>:
$$
h_i^{(t+1)} = \text{Update}\left( h_i^{(t)}, m_i^{(t)} \right)
$$</p>
<p><strong>Typical Update Formula</strong>:
$$
h_i^{(t+1)} = \sigma\left( W_1 h_i^{(t)} + W_2 m_i^{(t)} \right)
$$</p>
<pre><code class="language-python">class UpdateFunction(nn.Module):
    def __init__(self, hidden_dim):
        super().__init__()
        self.W1 = nn.Linear(hidden_dim, hidden_dim)
        self.W2 = nn.Linear(hidden_dim, hidden_dim)
        self.activation = nn.ReLU()

    def forward(self, h_i, m_i):
        &quot;&quot;&quot;
        Update vertex features

        Parameters:
        -----------
        h_i : Tensor (hidden_dim,)
            Current vertex features
        m_i : Tensor (hidden_dim,)
            Aggregated messages

        Returns:
        --------
        h_new : Tensor (hidden_dim,)
            Updated vertex features
        &quot;&quot;&quot;
        return self.activation(self.W1(h_i) + self.W2(m_i))

# Example
hidden_dim = 32
update_fn = UpdateFunction(hidden_dim)

h_current = torch.randn(hidden_dim)
m_aggregated = torch.randn(hidden_dim)
h_new = update_fn(h_current, m_aggregated)

print(f&quot;Before update: {h_current[:5]}&quot;)
print(f&quot;After update: {h_new[:5]}&quot;)
</code></pre>
<hr />
<h3>Complete Message Passing Picture</h3>
<pre><code class="language-python">class SimpleGNN(nn.Module):
    def __init__(self, in_dim, hidden_dim, num_layers):
        super().__init__()
        self.num_layers = num_layers

        # Parameters for each layer
        self.message_fns = nn.ModuleList([
            MessageFunction(hidden_dim, hidden_dim)
            for _ in range(num_layers)
        ])
        self.update_fns = nn.ModuleList([
            UpdateFunction(hidden_dim)
            for _ in range(num_layers)
        ])

        # Input projection
        self.input_proj = nn.Linear(in_dim, hidden_dim)

    def forward(self, x, edge_index):
        &quot;&quot;&quot;
        Parameters:
        -----------
        x : Tensor (num_nodes, in_dim)
            Vertex feature matrix
        edge_index : Tensor (2, num_edges)
            Edge list [[src], [dst]]

        Returns:
        --------
        h : Tensor (num_nodes, hidden_dim)
            Updated vertex features
        &quot;&quot;&quot;
        # Input projection
        h = self.input_proj(x)

        # Message passing layers
        for layer in range(self.num_layers):
            h_new = []

            # Update each vertex
            for i in range(x.size(0)):
                # Get neighbors
                neighbors = edge_index[1][edge_index[0] == i]

                if len(neighbors) &gt; 0:
                    # Step 1: Message generation
                    messages = self.message_fns[layer](h[neighbors])

                    # Step 2: Aggregation
                    m_i = torch.mean(messages, dim=0)

                    # Step 3: Update
                    h_i_new = self.update_fns[layer](h[i], m_i)
                else:
                    # No neighbors
                    h_i_new = h[i]

                h_new.append(h_i_new)

            h = torch.stack(h_new)

        return h

# Usage example
model = SimpleGNN(in_dim=16, hidden_dim=32, num_layers=3)

# Graph data (triangle)
x = torch.randn(3, 16)  # 3 vertices, 16-dim features
edge_index = torch.tensor([
    [0, 0, 1, 1, 2, 2],  # Source
    [1, 2, 0, 2, 0, 1]   # Destination
])

# Forward pass
h_out = model(x, edge_index)
print(f&quot;Output shape: {h_out.shape}&quot;)
# Output: torch.Size([3, 32])
</code></pre>
<hr />
<h2>2.3 Representative GNN Architectures</h2>
<h3>Graph Convolutional Network (GCN)</h3>
<p><strong>Paper</strong>: Kipf &amp; Welling (2017), <em>ICLR</em></p>
<p><strong>Core Idea</strong>: Spectral convolution on graphs</p>
<p><strong>Update Formula</strong>:
$$
H^{(l+1)} = \sigma\left( \tilde{D}^{-1/2} \tilde{A} \tilde{D}^{-1/2} H^{(l)} W^{(l)} \right)
$$</p>
<ul>
<li>$\tilde{A} = A + I$: Adjacency matrix with self-loops</li>
<li>$\tilde{D}_{ii} = \sum_j \tilde{A}_{ij}$: Degree matrix</li>
<li>$H^{(l)} \in \mathbb{R}^{n \times d}$: Features at layer $l$</li>
<li>$W^{(l)} \in \mathbb{R}^{d \times d'}$: Learnable weights</li>
</ul>
<p><strong>Python Implementation</strong>:</p>
<pre><code class="language-python">import torch
import torch.nn as nn
import torch.nn.functional as F

class GCNLayer(nn.Module):
    def __init__(self, in_features, out_features):
        super().__init__()
        self.linear = nn.Linear(in_features, out_features)

    def forward(self, X, A):
        &quot;&quot;&quot;
        Parameters:
        -----------
        X : Tensor (num_nodes, in_features)
            Vertex feature matrix
        A : Tensor (num_nodes, num_nodes)
            Adjacency matrix

        Returns:
        --------
        H : Tensor (num_nodes, out_features)
            Updated features
        &quot;&quot;&quot;
        # Add self-loops
        A_tilde = A + torch.eye(A.size(0), device=A.device)

        # Degree matrix
        D_tilde = torch.diag(A_tilde.sum(dim=1))

        # Normalization: D^(-1/2) * A * D^(-1/2)
        D_inv_sqrt = torch.diag(1.0 / torch.sqrt(D_tilde.diagonal()))
        A_norm = D_inv_sqrt @ A_tilde @ D_inv_sqrt

        # Graph convolution
        H = A_norm @ X
        H = self.linear(H)
        return F.relu(H)

# Usage example
gcn = GCNLayer(in_features=16, out_features=32)

# Graph data
X = torch.randn(5, 16)  # 5 vertices, 16-dim
A = torch.tensor([
    [0, 1, 1, 0, 0],
    [1, 0, 1, 1, 0],
    [1, 1, 0, 1, 1],
    [0, 1, 1, 0, 1],
    [0, 0, 1, 1, 0]
], dtype=torch.float32)

H = gcn(X, A)
print(f&quot;GCN output shape: {H.shape}&quot;)
# Output: torch.Size([5, 32])
</code></pre>
<p><strong>Characteristics</strong>:
- ‚úÖ Simple and fast
- ‚úÖ Watch for over-smoothing
- ‚úÖ Fixed weights (all neighbors treated equally)</p>
<hr />
<h3>Graph Attention Network (GAT)</h3>
<p><strong>Paper</strong>: Veliƒçkoviƒá et al. (2018), <em>ICLR</em></p>
<p><strong>Core Idea</strong>: Use attention to emphasize important neighbors</p>
<p><strong>Attention Coefficients</strong>:
$$
\alpha_{ij} = \frac{\exp\left( \text{LeakyReLU}(a^T [W h_i | W h_j]) \right)}
{\sum_{k \in \mathcal{N}(i)} \exp\left( \text{LeakyReLU}(a^T [W h_i | W h_k]) \right)}
$$</p>
<p><strong>Update Formula</strong>:
$$
h_i^{(l+1)} = \sigma\left( \sum_{j \in \mathcal{N}(i)} \alpha_{ij} W^{(l)} h_j^{(l)} \right)
$$</p>
<pre><code class="language-python">class GATLayer(nn.Module):
    def __init__(self, in_features, out_features, dropout=0.6,
                 alpha=0.2):
        super().__init__()
        self.W = nn.Linear(in_features, out_features, bias=False)
        self.a = nn.Parameter(torch.zeros(2 * out_features, 1))
        self.leakyrelu = nn.LeakyReLU(alpha)
        self.dropout = nn.Dropout(dropout)

        nn.init.xavier_uniform_(self.a.data, gain=1.414)

    def forward(self, X, A):
        &quot;&quot;&quot;
        Parameters:
        -----------
        X : Tensor (num_nodes, in_features)
        A : Tensor (num_nodes, num_nodes)

        Returns:
        --------
        H : Tensor (num_nodes, out_features)
        &quot;&quot;&quot;
        # Linear transformation
        Wh = self.W(X)  # (N, out_features)
        N = Wh.size(0)

        # Attention computation
        # [Wh_i || Wh_j] for all edges
        Wh_repeat_interleave = Wh.repeat_interleave(N, dim=0)
        Wh_repeat = Wh.repeat(N, 1)
        concat = torch.cat([Wh_repeat_interleave, Wh_repeat], dim=1)
        concat = concat.view(N, N, -1)

        # Attention score
        e = self.leakyrelu(concat @ self.a).squeeze(2)

        # Mask (set -inf where no edge)
        zero_vec = -9e15 * torch.ones_like(e)
        attention = torch.where(A &gt; 0, e, zero_vec)

        # Softmax
        attention = F.softmax(attention, dim=1)
        attention = self.dropout(attention)

        # Weighted sum
        H = torch.matmul(attention, Wh)
        return F.elu(H)

# Usage example
gat = GATLayer(in_features=16, out_features=32)
H_gat = gat(X, A)
print(f&quot;GAT output shape: {H_gat.shape}&quot;)
# Output: torch.Size([5, 32])
</code></pre>
<p><strong>Characteristics</strong>:
- ‚úÖ Dynamic weights (automatically learns important neighbors)
- ‚úÖ Interpretable (attention coefficient visualization)
- ‚ùå Higher computational cost (about 2√ó GCN)</p>
<hr />
<h3>GraphSAGE (SAmple and aggreGatE)</h3>
<p><strong>Paper</strong>: Hamilton et al. (2017), <em>NeurIPS</em></p>
<p><strong>Core Idea</strong>: Sampling for mini-batch training</p>
<p><strong>Update Formula</strong>:
$$
h_i^{(l+1)} = \sigma\left( W \cdot \text{Concat}\left( h_i^{(l)}, \text{Aggregate}({h_j^{(l)} : j \in \mathcal{S}(i)}) \right) \right)
$$</p>
<ul>
<li>$\mathcal{S}(i)$: Sampled neighbors (not all)</li>
</ul>
<pre><code class="language-python">class GraphSAGELayer(nn.Module):
    def __init__(self, in_features, out_features, num_samples=10):
        super().__init__()
        self.num_samples = num_samples
        # Concat version: input is in_features * 2
        self.linear = nn.Linear(in_features * 2, out_features)

    def forward(self, X, A):
        &quot;&quot;&quot;
        Parameters:
        -----------
        X : Tensor (num_nodes, in_features)
        A : Tensor (num_nodes, num_nodes)

        Returns:
        --------
        H : Tensor (num_nodes, out_features)
        &quot;&quot;&quot;
        N = X.size(0)
        H_new = []

        for i in range(N):
            # Sample neighbors
            neighbors = torch.nonzero(A[i]).squeeze()
            if neighbors.numel() &gt; self.num_samples:
                # Random sampling
                perm = torch.randperm(neighbors.numel())
                sampled = neighbors[perm[:self.num_samples]]
            else:
                sampled = neighbors

            # Aggregation (Mean)
            if sampled.numel() &gt; 0:
                h_neighbors = X[sampled]
                h_agg = torch.mean(h_neighbors, dim=0)
            else:
                h_agg = torch.zeros_like(X[i])

            # Concat
            h_concat = torch.cat([X[i], h_agg], dim=0)

            # Linear transformation
            h_new = self.linear(h_concat)
            H_new.append(h_new)

        H = torch.stack(H_new)
        return F.relu(H)

# Usage example
sage = GraphSAGELayer(in_features=16, out_features=32,
                      num_samples=3)
H_sage = sage(X, A)
print(f&quot;GraphSAGE output shape: {H_sage.shape}&quot;)
# Output: torch.Size([5, 32])
</code></pre>
<p><strong>Characteristics</strong>:
- ‚úÖ Scalable (works with large graphs)
- ‚úÖ Mini-batch training possible
- ‚úÖ Inductive learning (generalizes to new vertices)</p>
<hr />
<h3>Comparison of Three GNNs</h3>
<div class="mermaid">
flowchart TD
    A[GNN Selection] --> B{Data Size}
    B -->|Small\n10k vertices| C[GCN]
    B -->|Medium\n10k-100k| D[GAT]
    B -->|Large\n100k+| E[GraphSAGE]

    C --> F[Simple, fast]
    D --> G[High accuracy, interpretability]
    E --> H[Scalable]

    style A fill:#e3f2fd
    style C fill:#fff3e0
    style D fill:#f3e5f5
    style E fill:#e8f5e9
</div>

<table>
<thead>
<tr>
<th>Method</th>
<th>Complexity</th>
<th>Accuracy</th>
<th>Scalability</th>
<th>Interpretability</th>
<th>Recommended Use</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>GCN</strong></td>
<td>$O(m \cdot d^2)$</td>
<td>Medium</td>
<td>Low</td>
<td>Medium</td>
<td>Small-scale, prototyping</td>
</tr>
<tr>
<td><strong>GAT</strong></td>
<td>$O(m \cdot d^2 + n \cdot d)$</td>
<td>High</td>
<td>Medium</td>
<td>High</td>
<td>Medium-scale, high accuracy requirements</td>
</tr>
<tr>
<td><strong>GraphSAGE</strong></td>
<td>$O(k \cdot s \cdot d^2)$</td>
<td>Medium-High</td>
<td>High</td>
<td>Medium</td>
<td>Large-scale, real-time prediction</td>
</tr>
</tbody>
</table>
<ul>
<li>$m$: Number of edges</li>
<li>$n$: Number of vertices</li>
<li>$d$: Feature dimension</li>
<li>$k$: Number of layers</li>
<li>$s$: Number of samples</li>
</ul>
<hr />
<h2>2.4 Materials Science-Specialized GNNs</h2>
<h3>SchNet (Continuous-filter Convolutional NN)</h3>
<p><strong>Paper</strong>: Sch√ºtt et al. (2017), <em>NeurIPS</em></p>
<p><strong>Target</strong>: Predicting <strong>quantum chemical properties</strong> of molecules and materials</p>
<p><strong>Core Ideas</strong>:
1. <strong>Continuous filters</strong>: Convolution in 3D space rather than discrete graphs
2. <strong>Distance-dependent</strong>: Explicitly models interatomic distances</p>
<p><strong>Architecture</strong>:</p>
<div class="mermaid">
flowchart LR
    A[Atom features] --> B[Embedding layer]
    B --> C[Interaction block 1]
    C --> D[Interaction block 2]
    D --> E[Interaction block 3]
    E --> F[Output layer]

    G[Interatomic distances] --> C
    G --> D
    G --> E

    style A fill:#e3f2fd
    style B fill:#fff3e0
    style C fill:#f3e5f5
    style D fill:#e8f5e9
    style E fill:#ffebee
    style F fill:#fff9c4
    style G fill:#e1bee7
</div>

<p><strong>Formula</strong>:
$$
h_i^{(l+1)} = h_i^{(l)} + \sum_{j \in \mathcal{N}(i)} h_j^{(l)} \odot \phi\left( |r_i - r_j| \right)
$$</p>
<ul>
<li>$\phi(d)$: <strong>Continuous filter function</strong> (depends on distance $d$)</li>
<li>$r_i, r_j$: 3D coordinates of atoms</li>
</ul>
<p><strong>Filter Function</strong>:
$$
\phi(d) = \sum_{k=1}^{K} w_k \exp\left( -\gamma (d - \mu_k)^2 \right)
$$</p>
<ul>
<li>Gaussian basis expansion (RBF: Radial Basis Function)</li>
</ul>
<pre><code class="language-python">import torch
import torch.nn as nn

class GaussianBasis(nn.Module):
    def __init__(self, start=0.0, stop=5.0, num_gaussians=50):
        super().__init__()
        self.mu = nn.Parameter(
            torch.linspace(start, stop, num_gaussians),
            requires_grad=False
        )
        self.gamma = nn.Parameter(
            torch.tensor(10.0),
            requires_grad=True
        )

    def forward(self, distances):
        &quot;&quot;&quot;
        Parameters:
        -----------
        distances : Tensor (num_edges,)
            Interatomic distances

        Returns:
        --------
        rbf : Tensor (num_edges, num_gaussians)
            Gaussian basis expansion
        &quot;&quot;&quot;
        # (num_edges, 1) - (1, num_gaussians)
        diff = distances.unsqueeze(-1) - self.mu.unsqueeze(0)
        rbf = torch.exp(-self.gamma * diff ** 2)
        return rbf

class SchNetInteraction(nn.Module):
    def __init__(self, hidden_dim, num_gaussians):
        super().__init__()
        self.rbf_layer = GaussianBasis(num_gaussians=num_gaussians)
        self.filter_net = nn.Sequential(
            nn.Linear(num_gaussians, hidden_dim),
            nn.Softplus(),
            nn.Linear(hidden_dim, hidden_dim)
        )
        self.linear = nn.Linear(hidden_dim, hidden_dim)

    def forward(self, h, edge_index, distances):
        &quot;&quot;&quot;
        Parameters:
        -----------
        h : Tensor (num_atoms, hidden_dim)
            Atom features
        edge_index : Tensor (2, num_edges)
            Edge list
        distances : Tensor (num_edges,)
            Interatomic distances

        Returns:
        --------
        h_new : Tensor (num_atoms, hidden_dim)
            Updated features
        &quot;&quot;&quot;
        # RBF expansion
        rbf = self.rbf_layer(distances)

        # Filter generation
        W = self.filter_net(rbf)

        # Message passing
        src, dst = edge_index
        messages = h[dst] * W  # Element-wise product

        # Aggregation
        h_agg = torch.zeros_like(h)
        h_agg.index_add_(0, src, messages)

        # Update
        h_new = h + self.linear(h_agg)
        return h_new

# Usage example
schnet_layer = SchNetInteraction(hidden_dim=128,
                                 num_gaussians=50)

# Data
num_atoms = 5
h = torch.randn(num_atoms, 128)
edge_index = torch.tensor([[0, 1, 2, 3], [1, 2, 3, 4]])
distances = torch.tensor([1.5, 1.8, 2.0, 1.6])

h_new = schnet_layer(h, edge_index, distances)
print(f&quot;SchNet output shape: {h_new.shape}&quot;)
# Output: torch.Size([5, 128])
</code></pre>
<p><strong>Application Examples</strong>:
- QM9 dataset (molecular property prediction)
- MD17 (molecular dynamics)
- OC20 (catalytic adsorption energy)</p>
<p><strong>Performance</strong>:</p>
<pre><code>QM9 HOMO-LUMO gap:
- DFT calculation: 24 hours/molecule
- SchNet: 0.01 seconds/molecule (MAE=0.04 eV)
</code></pre>
<hr />
<h3>DimeNet (Directional Message Passing NN)</h3>
<p><strong>Paper</strong>: Klicpera et al. (2020), <em>ICLR</em></p>
<p><strong>Extension</strong>: Also considers <strong>bond angles</strong></p>
<p><strong>Core Ideas</strong>:
- Uses not only distance but also <strong>angle information</strong>
- Three-body interactions (triplet interaction)</p>
<p><strong>Update Formula</strong>:
$$
m_{ij} = \sum_{k \in \mathcal{N}(j) \setminus {i}} W\left( d_{ij}, d_{jk}, \theta_{ijk} \right) h_k
$$</p>
<ul>
<li>$\theta_{ijk}$: Angle $\angle i-j-k$</li>
</ul>
<div class="mermaid">
flowchart TD
    A[Atom i] --|d_ij| B[Atom j]
    B --|d_jk| C[Atom k]
    A - Angle Œ∏_ijk .-> C

    style A fill:#e3f2fd
    style B fill:#fff3e0
    style C fill:#f3e5f5
</div>

<p><strong>Angle Calculation</strong>:</p>
<pre><code class="language-python">import torch

def compute_angle(pos_i, pos_j, pos_k):
    &quot;&quot;&quot;
    Calculate angle between three atoms

    Parameters:
    -----------
    pos_i, pos_j, pos_k : Tensor (3,)
        3D coordinates of atoms

    Returns:
    --------
    angle : Tensor (1,)
        Angle (radians)
    &quot;&quot;&quot;
    # Vectors
    v_ij = pos_j - pos_i
    v_jk = pos_k - pos_j

    # Dot product
    cos_angle = torch.dot(v_ij, v_jk) / (
        torch.norm(v_ij) * torch.norm(v_jk) + 1e-8
    )

    # Angle
    angle = torch.acos(torch.clamp(cos_angle, -1.0, 1.0))
    return angle

# Example: H-O-H bond angle in water molecule
pos_O = torch.tensor([0.0, 0.0, 0.0])
pos_H1 = torch.tensor([0.96, 0.0, 0.0])
pos_H2 = torch.tensor([0.24, 0.93, 0.0])

angle = compute_angle(pos_H1, pos_O, pos_H2)
print(f&quot;H-O-H angle: {torch.rad2deg(angle):.1f}¬∞&quot;)
# Output: 104.5¬∞ (closely matches experimental value)
</code></pre>
<p><strong>Performance</strong>:</p>
<pre><code>QM9 dataset:
- SchNet: MAE=0.041 eV
- DimeNet: MAE=0.033 eV (20% improvement)

Computation time:
- SchNet: 0.01 seconds/molecule
- DimeNet: 0.05 seconds/molecule (5√ó slower)
</code></pre>
<hr />
<h3>GemNet (Geometric Message Passing NN)</h3>
<p><strong>Paper</strong>: Gasteiger et al. (2021), <em>NeurIPS</em></p>
<p><strong>Further Extension</strong>: <strong>Four-body interactions</strong> (dihedral angles)</p>
<p><strong>Target</strong>: Crystal structures, complex molecules</p>
<p><strong>Core Ideas</strong>:
- Consideration of torsion angles (dihedral angles)
- Higher-order geometric information</p>
<div class="mermaid">
flowchart LR
    A[Atom i] --- B[Atom j]
    B --- C[Atom k]
    C --- D[Atom l]

    A - Torsion angle œÜ .-> D

    style A fill:#e3f2fd
    style B fill:#fff3e0
    style C fill:#f3e5f5
    style D fill:#e8f5e9
</div>

<p><strong>Performance</strong>:</p>
<pre><code>OC20 dataset (catalysis):
- SchNet: MAE=0.61 eV
- DimeNet++: MAE=0.49 eV
- GemNet: MAE=0.43 eV (best accuracy)
</code></pre>
<hr />
<h3>Comparison of Materials Science GNNs</h3>
<table>
<thead>
<tr>
<th>Method</th>
<th>Information Considered</th>
<th>Accuracy</th>
<th>Speed</th>
<th>Recommended Use</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>SchNet</strong></td>
<td>Distance</td>
<td>Medium</td>
<td>Fast</td>
<td>Molecular property prediction</td>
</tr>
<tr>
<td><strong>DimeNet</strong></td>
<td>Distance + Angle</td>
<td>High</td>
<td>Medium</td>
<td>Catalysis, complex molecules</td>
</tr>
<tr>
<td><strong>GemNet</strong></td>
<td>Distance + Angle + Torsion</td>
<td>Highest</td>
<td>Slow</td>
<td>Crystals, high accuracy requirements</td>
</tr>
</tbody>
</table>
<hr />
<h2>2.5 Importance of Equivariance</h2>
<h3>What is Equivariance?</h3>
<p><strong>Definition</strong>:</p>
<blockquote>
<p>A function $f$ is <strong>equivariant</strong> with respect to a transformation $T$ if:
$$f(T(x)) = T(f(x))$$</p>
</blockquote>
<p><strong>Meaning in Materials Science</strong>:
- Even if you rotate or translate a molecule, predictions remain the same (or undergo corresponding transformations)</p>
<hr />
<h3>E(3) Equivariance</h3>
<p><strong>E(3) Group</strong>: Isometric transformations in 3D Euclidean space
- Rotation
- Translation
- Inversion</p>
<p><strong>Importance</strong>:
- Physical laws are independent of coordinate systems
- GNNs should be as well</p>
<hr />
<h3>Examples of Equivariant GNNs: NequIP, MACE</h3>
<p><strong>NequIP</strong> (Batzner et al., 2022):
- <strong>E(3)-equivariant message passing</strong>
- Uses spherical harmonics</p>
<p><strong>Update Formula</strong>:
$$
m_{ij} = \phi\left( |r_i - r_j| \right) \otimes Y_l(r_{ij})
$$</p>
<ul>
<li>$Y_l$: Spherical harmonics (preserve angular information)</li>
<li>$\otimes$: Tensor product</li>
</ul>
<p><strong>MACE</strong> (Batatia et al., 2022):
- <strong>Higher-order equivariance</strong>
- More accurate force field prediction</p>
<p><strong>Performance</strong>:</p>
<pre><code>MD17 dataset (molecular dynamics):
- SchNet: MAE(force) = 0.21 kcal/mol/√Ö
- NequIP: MAE(force) = 0.05 kcal/mol/√Ö (76% improvement)
</code></pre>
<hr />
<h3>Testing Equivariance</h3>
<pre><code class="language-python">import torch
import torch.nn as nn

def test_equivariance(model, pos, edge_index):
    &quot;&quot;&quot;
    Test model equivariance
    &quot;&quot;&quot;
    # Original prediction
    pred_original = model(pos, edge_index)

    # Rotation matrix (90-degree rotation)
    angle = torch.tensor(torch.pi / 2)
    rotation = torch.tensor([
        [torch.cos(angle), -torch.sin(angle), 0],
        [torch.sin(angle), torch.cos(angle), 0],
        [0, 0, 1]
    ])

    # Rotate coordinates
    pos_rotated = pos @ rotation.T

    # Prediction after rotation
    pred_rotated = model(pos_rotated, edge_index)

    # Rotate prediction
    pred_original_rotated = pred_original @ rotation.T

    # Calculate error
    error = torch.abs(pred_rotated - pred_original_rotated).mean()
    print(f&quot;Equivariance error: {error.item():.6f}&quot;)

    if error &lt; 1e-5:
        print(&quot;‚úÖ Model is equivariant&quot;)
    else:
        print(&quot;‚ùå Model is not equivariant&quot;)

# Usage example (simplified)
class SimpleEquivariantModel(nn.Module):
    def forward(self, pos, edge_index):
        # Simplified: compute coordinate differences (equivariant)
        src, dst = edge_index
        diff = pos[dst] - pos[src]
        return diff

model = SimpleEquivariantModel()
pos = torch.randn(5, 3)
edge_index = torch.tensor([[0, 1, 2], [1, 2, 3]])

test_equivariance(model, pos, edge_index)
</code></pre>
<hr />
<h2>2.6 Column: Why Are Deep GNNs Difficult?</h2>
<h3>Over-smoothing</h3>
<p><strong>Problem</strong>: As layers get deeper, <strong>all vertices become identical</strong></p>
<p><strong>Cause</strong>: Information diffuses through repeated message passing</p>
<pre><code class="language-python"># Demonstration of over-smoothing
import torch
import torch.nn.functional as F

def demonstrate_oversmoothing(X, A, num_layers=10):
    &quot;&quot;&quot;
    Visualize over-smoothing
    &quot;&quot;&quot;
    H = X
    smoothness = []

    for layer in range(num_layers):
        # Simple GCN layer
        D = torch.diag(A.sum(dim=1))
        D_inv_sqrt = torch.diag(1.0 / torch.sqrt(D.diagonal()))
        A_norm = D_inv_sqrt @ A @ D_inv_sqrt

        H = A_norm @ H
        H = F.relu(H)

        # Smoothness (similarity between vertices)
        similarity = F.cosine_similarity(
            H.unsqueeze(1), H.unsqueeze(0), dim=2
        )
        avg_similarity = similarity[torch.triu_indices(
            H.size(0), H.size(0), offset=1
        )[0], torch.triu_indices(
            H.size(0), H.size(0), offset=1
        )[1]].mean()

        smoothness.append(avg_similarity.item())
        print(f&quot;Layer {layer+1}: Average similarity = {avg_similarity:.4f}&quot;)

    return smoothness

# Execute
X = torch.randn(5, 16)
A = torch.eye(5) + torch.rand(5, 5) &gt; 0.7
smoothness = demonstrate_oversmoothing(X, A.float(), num_layers=10)
</code></pre>
<p><strong>Example Output</strong>:</p>
<pre><code>Layer 1: Average similarity = 0.2341
Layer 2: Average similarity = 0.4523
Layer 3: Average similarity = 0.6789
...
Layer 10: Average similarity = 0.9876
</code></pre>
<p>‚Üí All vertices become similar as layers deepen</p>
<hr />
<h3>Countermeasures</h3>
<ol>
<li>
<p><strong>Residual Connections</strong>:
   $$h_i^{(l+1)} = h_i^{(l)} + \text{GNN}(h_i^{(l)})$$</p>
</li>
<li>
<p><strong>Jumping Knowledge Network</strong>:
   - Combine outputs from all layers</p>
</li>
<li>
<p><strong>PairNorm</strong>:
   - Feature normalization</p>
</li>
</ol>
<pre><code class="language-python">class GNNWithResidual(nn.Module):
    def __init__(self, hidden_dim):
        super().__init__()
        self.conv = GCNLayer(hidden_dim, hidden_dim)

    def forward(self, X, A):
        # Residual connection
        H = self.conv(X, A)
        return X + H  # Shortcut
</code></pre>
<hr />
<h2>2.7 Chapter Summary</h2>
<h3>What We Learned</h3>
<ol>
<li>
<p><strong>Mathematical Definition of Graphs</strong>
   - Adjacency matrix, degree matrix, Laplacian matrix
   - Vertex features and edge features</p>
</li>
<li>
<p><strong>Message Passing</strong>
   - 3 steps: Message generation ‚Üí Aggregation ‚Üí Update
   - Aggregation functions: Sum, Mean, Max, Attention</p>
</li>
<li>
<p><strong>Representative GNN Architectures</strong>
   - GCN: Simple, fast
   - GAT: Attention, high accuracy
   - GraphSAGE: Scalable, mini-batch</p>
</li>
<li>
<p><strong>Materials Science-Specialized GNNs</strong>
   - SchNet: Distance-dependent, continuous filters
   - DimeNet: Also considers angles
   - GemNet: Also considers torsion angles</p>
</li>
<li>
<p><strong>Equivariance</strong>
   - Importance of E(3) equivariance
   - State-of-the-art methods: NequIP, MACE</p>
</li>
</ol>
<h3>Key Points</h3>
<ul>
<li>‚úÖ Message passing is a <strong>unified framework</strong> for GNNs</li>
<li>‚úÖ Choice of aggregation function significantly impacts performance</li>
<li>‚úÖ <strong>Geometric information</strong> (distance, angles) is crucial in materials science</li>
<li>‚úÖ Equivariance <strong>guarantees physical laws</strong></li>
<li>‚úÖ Watch for over-smoothing (use residual connections as countermeasure)</li>
</ul>
<h3>To the Next Chapter</h3>
<p>In Chapter 3, we learn <strong>PyTorch Geometric in Practice</strong>:
- Environment setup (PyG, RDKit, ASE)
- Molecular property prediction with QM9 dataset
- Crystal property prediction with Materials Project data
- Model evaluation and hyperparameter tuning
- Practical projects</p>
<p><strong><a href="./chapter-3.html">Chapter 3: PyTorch Geometric in Practice ‚Üí</a></strong></p>
<hr />
<h2>Exercises</h2>
<h3>Problem 1 (Difficulty: easy)</h3>
<p>Judge whether the following statements are true or false.</p>
<ol>
<li>Message passing is performed in the order: Aggregation ‚Üí Update ‚Üí Message Generation</li>
<li>GAT uses Attention, so it treats all neighbors with the same weight</li>
<li>SchNet explicitly considers interatomic distances</li>
</ol>
<details>
<summary>Hint</summary>

- Recall the 3 steps of message passing
- The core idea of GAT is "emphasize important neighbors"
- SchNet's feature is "continuous filters"

</details>

<details>
<summary>Solution</summary>

**Answer**:
1. **False** - Correct order is: Message generation ‚Üí Aggregation ‚Üí Update
2. **False** - GAT assigns **different weights** with Attention
3. **True** - SchNet encodes distance with RBF (Gaussian basis)

**Explanation**:

For 1:

```python
# Correct order
for layer in range(num_layers):
    # Step 1: Message generation
    messages = message_function(h_neighbors)

    # Step 2: Aggregation
    m_i = aggregate(messages)

    # Step 3: Update
    h_i = update_function(h_i, m_i)
```


For 2:
- GAT's attention coefficient $\alpha_{ij}$ differs for each neighbor
- Large weights for important neighbors, small weights for others

For 3:
- SchNet's filter function: $\phi(d) = \sum_k w_k \exp(-\gamma (d - \mu_k)^2)$
- Different distances $d$ produce different filter values

</details>

<hr />
<h3>Problem 2 (Difficulty: medium)</h3>
<p>For the following graph, calculate the forward pass of one GCN layer by hand.</p>
<p><strong>Graph</strong>:</p>
<pre><code>Vertices: 3 (v0, v1, v2)
Edges: v0-v1, v1-v2 (linear graph)

Vertex features:
X = [[1, 0],
     [0, 1],
     [1, 1]]

Adjacency matrix:
A = [[0, 1, 0],
     [1, 0, 1],
     [0, 1, 0]]

Weight matrix (simplified):
W = [[1, 0],
     [0, 1]]  (identity matrix)
</code></pre>
<p><strong>Requirements</strong>:
1. Calculate $\tilde{A} = A + I$
2. Calculate normalized adjacency matrix $\hat{A} = \tilde{D}^{-1/2} \tilde{A} \tilde{D}^{-1/2}$
3. Calculate GCN output $H = \hat{A} X W$ (no activation function)</p>
<details>
<summary>Hint</summary>

**Steps**:
1. Add self-loops: $\tilde{A}_{ii} = 1$
2. Degree matrix: $\tilde{D}_{ii} = \sum_j \tilde{A}_{ij}$
3. Calculate $\tilde{D}^{-1/2}$ (reciprocal of square root of diagonal elements)
4. Calculate matrix product

</details>

<details>
<summary>Solution</summary>

**Step 1: Adjacency matrix with self-loops**
$$
\tilde{A} = A + I = \begin{bmatrix}
0 & 1 & 0 \\
1 & 0 & 1 \\
0 & 1 & 0
\end{bmatrix} + \begin{bmatrix}
1 & 0 & 0 \\
0 & 1 & 0 \\
0 & 0 & 1
\end{bmatrix} = \begin{bmatrix}
1 & 1 & 0 \\
1 & 1 & 1 \\
0 & 1 & 1
\end{bmatrix}
$$

**Step 2: Degree matrix**
$$
\tilde{D} = \begin{bmatrix}
2 & 0 & 0 \\
0 & 3 & 0 \\
0 & 0 & 2
\end{bmatrix}
$$

(Sum of each row)

**Step 3: $\tilde{D}^{-1/2}$**
$$
\tilde{D}^{-1/2} = \begin{bmatrix}
1/\sqrt{2} & 0 & 0 \\
0 & 1/\sqrt{3} & 0 \\
0 & 0 & 1/\sqrt{2}
\end{bmatrix} \approx \begin{bmatrix}
0.707 & 0 & 0 \\
0 & 0.577 & 0 \\
0 & 0 & 0.707
\end{bmatrix}
$$

**Step 4: Normalized adjacency matrix**
$$
\hat{A} = \tilde{D}^{-1/2} \tilde{A} \tilde{D}^{-1/2}
$$

Calculation process:

```python
import numpy as np

A_tilde = np.array([
    [1, 1, 0],
    [1, 1, 1],
    [0, 1, 1]
], dtype=float)

D_tilde = np.diag([2, 3, 2])
D_inv_sqrt = np.diag([1/np.sqrt(2), 1/np.sqrt(3), 1/np.sqrt(2)])

A_hat = D_inv_sqrt @ A_tilde @ D_inv_sqrt
print("Normalized adjacency matrix:")
print(A_hat)
```


$$
\hat{A} \approx \begin{bmatrix}
0.500 & 0.408 & 0 \\
0.408 & 0.333 & 0.408 \\
0 & 0.408 & 0.500
\end{bmatrix}
$$

**Step 5: GCN output**
$$
H = \hat{A} X W
$$

($W = I$ so $H = \hat{A} X$)


```python
X = np.array([
    [1, 0],
    [0, 1],
    [1, 1]
], dtype=float)

H = A_hat @ X
print("GCN output:")
print(H)
```


$$
H \approx \begin{bmatrix}
0.500 & 0.408 \\
0.816 & 0.741 \\
0.408 & 0.908
\end{bmatrix}
$$

**Interpretation**:
- Vertex 1 (center): Aggregates information from both neighbors
- Vertices 0, 2 (endpoints): Mainly incorporate information from neighbor 1

**Python Verification**:

```python
# Complete code
A = np.array([[0, 1, 0], [1, 0, 1], [0, 1, 0]], dtype=float)
X = np.array([[1, 0], [0, 1], [1, 1]], dtype=float)

# GCN
A_tilde = A + np.eye(3)
D_tilde = np.diag(A_tilde.sum(axis=1))
D_inv_sqrt = np.diag(1.0 / np.sqrt(D_tilde.diagonal()))
A_hat = D_inv_sqrt @ A_tilde @ D_inv_sqrt

H = A_hat @ X
print("Final output:")
print(H)
```


</details>

<hr />
<h3>Problem 3 (Difficulty: hard)</h3>
<p>Implement SchNet's continuous filter function and visualize the filter response to different interatomic distances.</p>
<p><strong>Requirements</strong>:
1. Implement Gaussian basis (RBF) functions
2. Calculate RBF response for distances 0.5√Ö~5.0√Ö
3. Visualize with heatmap
4. Consider the physical meaning of filters</p>
<details>
<summary>Hint</summary>

**RBF Formula**:
$$\phi_k(d) = \exp\left( -\gamma (d - \mu_k)^2 \right)$$

- $\mu_k$: Centers of Gaussian functions (uniformly distributed from 0~5√Ö)
- $\gamma$: Width parameter (around 10)

**Visualization Points**:
- X-axis: Distance (0.5~5.0√Ö)
- Y-axis: RBF index (0~49)
- Color: RBF response value (0~1)

</details>

<details>
<summary>Solution</summary>


```python
import torch
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# ===== Implementation =====
class GaussianBasisFunction:
    def __init__(self, start=0.0, stop=5.0, num_gaussians=50,
                 gamma=10.0):
        """
        Gaussian Basis Function (RBF)

        Parameters:
        -----------
        start, stop : float
            Distance range
        num_gaussians : int
            Number of Gaussian functions
        gamma : float
            Width parameter
        """
        self.mu = torch.linspace(start, stop, num_gaussians)
        self.gamma = gamma

    def __call__(self, distances):
        """
        Calculate RBF response

        Parameters:
        -----------
        distances : Tensor (num_distances,)

        Returns:
        --------
        rbf : Tensor (num_distances, num_gaussians)
        """
        # (num_distances, 1) - (1, num_gaussians)
        diff = distances.unsqueeze(-1) - self.mu.unsqueeze(0)
        rbf = torch.exp(-self.gamma * diff ** 2)
        return rbf

# ===== Visualization =====
# Generate RBF
rbf_layer = GaussianBasisFunction(
    start=0.0, stop=5.0,
    num_gaussians=50, gamma=10.0
)

# Distance samples (0.5~5.0√Ö)
distances = torch.linspace(0.5, 5.0, 100)

# RBF response
rbf_response = rbf_layer(distances)  # (100, 50)

# Heatmap
plt.figure(figsize=(12, 6))
sns.heatmap(
    rbf_response.T.numpy(),  # Transpose (RBF x distance)
    cmap='viridis',
    xticklabels=10,
    yticklabels=10,
    cbar_kws={'label': 'RBF Response'}
)
plt.xlabel('Distance (√Ö)')
plt.ylabel('RBF Index')
plt.title('SchNet Continuous Filter: RBF Response')

# X-axis labels to actual distances
xticks = np.linspace(0, len(distances)-1, 10).astype(int)
xticklabels = [f'{distances[i]:.1f}' for i in xticks]
plt.xticks(xticks, xticklabels)

plt.tight_layout()
plt.savefig('schnet_rbf_heatmap.png', dpi=150)
plt.show()

# ===== RBF response at specific distances =====
fig, axes = plt.subplots(2, 2, figsize=(12, 10))
example_distances = [1.0, 1.5, 2.0, 3.0]  # √Ö

for ax, d in zip(axes.flatten(), example_distances):
    d_tensor = torch.tensor([d])
    rbf = rbf_layer(d_tensor).squeeze()

    ax.plot(rbf_layer.mu.numpy(), rbf.numpy(),
            marker='o', linewidth=2)
    ax.axvline(d, color='red', linestyle='--',
               label=f'Distance = {d}√Ö')
    ax.set_xlabel('RBF Center Œº (√Ö)')
    ax.set_ylabel('RBF Response')
    ax.set_title(f'RBF Response at d = {d}√Ö')
    ax.legend()
    ax.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('schnet_rbf_profiles.png', dpi=150)
plt.show()

# ===== Physical meaning considerations =====
print("\n===== Physical Meaning =====")
print("1. Short range (0.5-2.0√Ö): Covalent bonding region")
print("   - C-C: 1.54√Ö, C=C: 1.34√Ö, C-H: 1.09√Ö")
print("   - RBF responds sharply (identifies bond presence)")

print("\n2. Medium range (2.0-3.5√Ö): Non-covalent interactions")
print("   - Hydrogen bonds: 2.8√Ö, van der Waals forces")
print("   - RBF responds smoothly")

print("\n3. Long range (3.5-5.0√Ö): Weak interactions")
print("   - Electrostatic interactions, dispersion forces")
print("   - Small RBF response")

print("\n4. Role of Gaussian basis:")
print("   - Continuous distance representation (no discretization)")
print("   - Differentiable for any distance")
print("   - Optimizable by machine learning (Œ≥ parameter)")
```


**Output Interpretation**:

1. **Heatmap**:
   - Diagonal pattern (each RBF has maximum response at specific distance)
   - Smooth transitions (overlapping Gaussian functions)

2. **RBF Profiles**:
   - Distance 1.0√Ö: Strong response around RBF #10
   - Distance 2.0√Ö: Strong response around RBF #20
   - Gaussian shape means neighboring RBFs also respond weakly

3. **Physical Meaning**:
   - **SchNet represents distance as "distribution"**
   - Not discrete binning, but continuous overlap
   - Neural network learns distance dependence

**Extension Challenges**:
1. Change $\gamma$ parameter to adjust RBF width
2. Asymmetric Gaussian basis (dense for short range, sparse for long range)
3. Visualize RBF filters for actual molecules

</details>

<hr />
<h2>References</h2>
<ol>
<li>
<p>Kipf, T. N. &amp; Welling, M. (2017). "Semi-Supervised Classification with Graph Convolutional Networks." <em>ICLR</em>.
   DOI: <a href="https://arxiv.org/abs/1609.02907">https://arxiv.org/abs/1609.02907</a></p>
</li>
<li>
<p>Veliƒçkoviƒá, P. et al. (2018). "Graph Attention Networks." <em>ICLR</em>.
   DOI: <a href="https://arxiv.org/abs/1710.10903">https://arxiv.org/abs/1710.10903</a></p>
</li>
<li>
<p>Hamilton, W. L. et al. (2017). "Inductive Representation Learning on Large Graphs." <em>NeurIPS</em>.
   DOI: <a href="https://arxiv.org/abs/1706.02216">https://arxiv.org/abs/1706.02216</a></p>
</li>
<li>
<p>Sch√ºtt, K. T. et al. (2017). "SchNet: A continuous-filter convolutional neural network for modeling quantum interactions." <em>NeurIPS</em>.
   DOI: <a href="https://arxiv.org/abs/1706.08566">https://arxiv.org/abs/1706.08566</a></p>
</li>
<li>
<p>Klicpera, J. et al. (2020). "Directional Message Passing for Molecular Graphs." <em>ICLR</em>.
   DOI: <a href="https://arxiv.org/abs/2003.03123">https://arxiv.org/abs/2003.03123</a></p>
</li>
<li>
<p>Gasteiger, J. et al. (2021). "GemNet: Universal Directional Graph Neural Networks for Molecules." <em>NeurIPS</em>.
   DOI: <a href="https://arxiv.org/abs/2106.08903">https://arxiv.org/abs/2106.08903</a></p>
</li>
<li>
<p>Batzner, S. et al. (2022). "E(3)-equivariant graph neural networks for data-efficient and accurate interatomic potentials." <em>Nature Communications</em>, 13, 2453.
   DOI: <a href="https://doi.org/10.1038/s41467-022-29939-5">https://doi.org/10.1038/s41467-022-29939-5</a></p>
</li>
</ol>
<hr />
<h2>Navigation</h2>
<h3>Previous Chapter</h3>
<p><strong><a href="./chapter-1.html">Chapter 1: Why Materials Science Needs GNNs ‚Üê</a></strong></p>
<h3>Next Chapter</h3>
<p><strong><a href="./chapter-3.html">Chapter 3: PyTorch Geometric in Practice ‚Üí</a></strong></p>
<h3>Series Contents</h3>
<p><strong><a href="./index.html">‚Üê Back to Series Contents</a></strong></p>
<hr />
<h2>Author Information</h2>
<p><strong>Author</strong>: AI Terakoya Content Team
<strong>Date</strong>: 2025-10-17
<strong>Version</strong>: 1.0</p>
<p><strong>Update History</strong>:
- 2025-10-17: v1.0 Initial release</p>
<p><strong>Feedback</strong>:
- GitHub Issues: [Repository URL]/issues
- Email: yusuke.hashimoto.b8@tohoku.ac.jp</p>
<p><strong>License</strong>: Creative Commons BY 4.0</p>
<hr />
<p><strong>Let's actually run GNNs in Chapter 3!</strong></p><div class="navigation">
    <a href="chapter-1.html" class="nav-button">‚Üê Previous Chapter</a>
    <a href="index.html" class="nav-button">Back to Series Contents</a>
    <a href="chapter-3.html" class="nav-button">Next Chapter ‚Üí</a>
</div>
    </main>


    <section class="disclaimer">
        <h3>Disclaimer</h3>
        <ul>
            <li>This content is for educational, research, and informational purposes only and does not provide professional advice (legal, accounting, technical guarantees, etc.).</li>
            <li>This content and accompanying code examples are provided "AS IS" without any warranties, express or implied, including merchantability, fitness for a particular purpose, non-infringement, accuracy, completeness, operation, or safety.</li>
            <li>The author and Tohoku University assume no responsibility for the content, availability, or safety of external links, third-party data, tools, or libraries.</li>
            <li>To the maximum extent permitted by applicable law, the author and Tohoku University shall not be liable for any direct, indirect, incidental, special, consequential, or punitive damages arising from the use, execution, or interpretation of this content.</li>
            <li>The content of this material may be changed, updated, or discontinued without notice.</li>
            <li>Copyright and licensing of this content are subject to the specified conditions (e.g., CC BY 4.0). Such licenses typically include warranty disclaimers.</li>
        </ul>
    </section>

<footer>
        <p><strong>Author</strong>: AI Terakoya Content Team</p>
        <p><strong>Version</strong>: 1.0 | <strong>Date</strong>: 2025-10-17</p>
        <p><strong>License</strong>: Creative Commons BY 4.0</p>
        <p>¬© 2025 AI Terakoya. All rights reserved.</p>
    </footer>
</body>
</html>