<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Chapter 2: Accelerating Next-Generation Battery Development - From All-Solid-State Batteries to Perovskite Solar Cells - AI Terakoya</title>

    <style>
        :root {
            --color-primary: #2c3e50;
            --color-primary-dark: #1a252f;
            --color-accent: #7b2cbf;
            --color-accent-light: #9d4edd;
            --color-text: #2d3748;
            --color-text-light: #4a5568;
            --color-bg: #ffffff;
            --color-bg-alt: #f7fafc;
            --color-border: #e2e8f0;
            --color-code-bg: #f8f9fa;
            --color-link: #3182ce;
            --color-link-hover: #2c5aa0;

            --spacing-xs: 0.5rem;
            --spacing-sm: 1rem;
            --spacing-md: 1.5rem;
            --spacing-lg: 2rem;
            --spacing-xl: 3rem;

            --font-body: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            --font-mono: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;

            --border-radius: 8px;
            --box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: var(--font-body);
            line-height: 1.7;
            color: var(--color-text);
            background-color: var(--color-bg);
            font-size: 16px;
        }

        header {
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            padding: var(--spacing-xl) var(--spacing-md);
            margin-bottom: var(--spacing-xl);
            box-shadow: var(--box-shadow);
        }

        .header-content {
            max-width: 900px;
            margin: 0 auto;
        }

        h1 {
            font-size: 2rem;
            font-weight: 700;
            margin-bottom: var(--spacing-sm);
            line-height: 1.2;
        }

        .subtitle {
            font-size: 1.1rem;
            opacity: 0.95;
            font-weight: 400;
            margin-bottom: var(--spacing-md);
        }

        .meta {
            display: flex;
            flex-wrap: wrap;
            gap: var(--spacing-md);
            font-size: 0.9rem;
            opacity: 0.9;
        }

        .meta-item {
            display: flex;
            align-items: center;
            gap: 0.3rem;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 0 var(--spacing-md) var(--spacing-xl);
        }

        h2 {
            font-size: 1.75rem;
            color: var(--color-primary);
            margin-top: var(--spacing-xl);
            margin-bottom: var(--spacing-md);
            padding-bottom: var(--spacing-xs);
            border-bottom: 3px solid var(--color-accent);
        }

        h3 {
            font-size: 1.4rem;
            color: var(--color-primary);
            margin-top: var(--spacing-lg);
            margin-bottom: var(--spacing-sm);
        }

        h4 {
            font-size: 1.1rem;
            color: var(--color-primary-dark);
            margin-top: var(--spacing-md);
            margin-bottom: var(--spacing-sm);
        }

        p {
            margin-bottom: var(--spacing-md);
            color: var(--color-text);
        }

        a {
            color: var(--color-link);
            text-decoration: none;
            transition: color 0.2s;
        }

        a:hover {
            color: var(--color-link-hover);
            text-decoration: underline;
        }

        ul, ol {
            margin-left: var(--spacing-lg);
            margin-bottom: var(--spacing-md);
        }

        li {
            margin-bottom: var(--spacing-xs);
            color: var(--color-text);
        }

        pre {
            background-color: var(--color-code-bg);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            overflow-x: auto;
            margin-bottom: var(--spacing-md);
            font-family: var(--font-mono);
            font-size: 0.9rem;
            line-height: 1.5;
        }

        code {
            font-family: var(--font-mono);
            font-size: 0.9em;
            background-color: var(--color-code-bg);
            padding: 0.2em 0.4em;
            border-radius: 3px;
        }

        pre code {
            background-color: transparent;
            padding: 0;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: var(--spacing-md);
            font-size: 0.95rem;
        }

        th, td {
            border: 1px solid var(--color-border);
            padding: var(--spacing-sm);
            text-align: left;
        }

        th {
            background-color: var(--color-bg-alt);
            font-weight: 600;
            color: var(--color-primary);
        }

        blockquote {
            border-left: 4px solid var(--color-accent);
            padding-left: var(--spacing-md);
            margin: var(--spacing-md) 0;
            color: var(--color-text-light);
            font-style: italic;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        .mermaid {
            text-align: center;
            margin: var(--spacing-lg) 0;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        details {
            background-color: var(--color-bg-alt);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            margin-bottom: var(--spacing-md);
        }

        summary {
            cursor: pointer;
            font-weight: 600;
            color: var(--color-primary);
            user-select: none;
            padding: var(--spacing-xs);
            margin: calc(-1 * var(--spacing-md));
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        summary:hover {
            background-color: rgba(123, 44, 191, 0.1);
        }

        details[open] summary {
            margin-bottom: var(--spacing-md);
            border-bottom: 1px solid var(--color-border);
        }

        .learning-objectives {
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
            padding: var(--spacing-lg);
            border-radius: var(--border-radius);
            border-left: 4px solid var(--color-accent);
            margin-bottom: var(--spacing-xl);
        }

        .learning-objectives h2 {
            margin-top: 0;
            border-bottom: none;
        }

        .navigation {
            display: flex;
            justify-content: space-between;
            gap: var(--spacing-md);
            margin: var(--spacing-xl) 0;
            padding-top: var(--spacing-lg);
            border-top: 2px solid var(--color-border);
        }

        .nav-button {
            flex: 1;
            padding: var(--spacing-md);
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            border-radius: var(--border-radius);
            text-align: center;
            font-weight: 600;
            transition: transform 0.2s, box-shadow 0.2s;
            box-shadow: var(--box-shadow);
        }

        .nav-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
            text-decoration: none;
        }

        footer {
            margin-top: var(--spacing-xl);
            padding: var(--spacing-lg) var(--spacing-md);
            background-color: var(--color-bg-alt);
            border-top: 1px solid var(--color-border);
            text-align: center;
            font-size: 0.9rem;
            color: var(--color-text-light);
        }
        .disclaimer {
            max-width: 900px;
            margin: 2rem auto;
            padding: 1.5rem;
            background: #f8f9fa;
            border-left: 4px solid #6c757d;
            border-radius: 4px;
        }

        .disclaimer h3 {
            color: #495057;
            margin-bottom: 1rem;
            font-size: 1.1rem;
        }

        .disclaimer ul {
            list-style: none;
            padding-left: 0;
        }

        .disclaimer li {
            padding: 0.5rem 0;
            padding-left: 1.5rem;
            position: relative;
            font-size: 0.9rem;
            color: #6c757d;
            line-height: 1.6;
        }

        .disclaimer li::before {
            content: "âš ï¸";
            position: absolute;
            left: 0;
        }


        @media (max-width: 768px) {
            h1 {
                font-size: 1.5rem;
            }

            h2 {
                font-size: 1.4rem;
            }

            h3 {
                font-size: 1.2rem;
            }

            .meta {
                font-size: 0.85rem;
            }

            .navigation {
                flex-direction: column;
            }

            table {
                font-size: 0.85rem;
            }

            th, td {
                padding: var(--spacing-xs);
            }
        }
    
        
    
        /* Breadcrumb styles */
        .breadcrumb {
            background: #f7fafc;
            padding: 0.75rem 1rem;
            border-bottom: 1px solid #e2e8f0;
            font-size: 0.9rem;
        }

        .breadcrumb-content {
            max-width: 900px;
            margin: 0 auto;
            display: flex;
            align-items: center;
            flex-wrap: wrap;
            gap: 0.5rem;
        }

        .breadcrumb a {
            color: #667eea;
            text-decoration: none;
            transition: color 0.2s;
        }

        .breadcrumb a:hover {
            color: #764ba2;
            text-decoration: underline;
        }

        .breadcrumb-separator {
            color: #a0aec0;
            margin: 0 0.25rem;
        }

        .breadcrumb-current {
            color: #4a5568;
            font-weight: 500;
        }
    </style>

    <script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
    <script>
        mermaid.initialize({ startOnLoad: true, theme: 'default', securityLevel: 'strict' });
    </script>

    <!-- MathJax for LaTeX equation rendering -->
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\(', '\)']],
                displayMath: [['$$', '$$'], ['\[', '\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
                ignoreHtmlClass: 'mermaid'
            }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" async></script>
</head>
<body>
            <nav class="breadcrumb">
        <div class="breadcrumb-content">
            <a href="../../index.html">AI Terakoya Home</a><span class="breadcrumb-separator">â€º</span><a href="../../MI/index.html">Materials Informatics</a><span class="breadcrumb-separator">â€º</span><a href="../../MI/materials-applications-introduction/index.html">Materials Applications</a><span class="breadcrumb-separator">â€º</span><span class="breadcrumb-current">Chapter 2</span>
        </div>
    </nav>

        <header>
        <div class="header-content">
            <h1>Chapter 2: Accelerating Next-Generation Battery Development - From All-Solid-State Batteries to Perovskite Solar Cells</h1>
            <p class="subtitle">MI/AI Approaches and Demonstrated Cases Targeting 500 Wh/kg Energy Density</p>
            <div class="meta">
                <span class="meta-item">ğŸ“– Reading Time: 22-25 minutes</span>
                <span class="meta-item">ğŸ“Š Difficulty: Intermediate</span>
                <span class="meta-item">ğŸ’» Code Examples: 6</span>
                <span class="meta-item">ğŸ“ Exercises: 3</span>
            </div>
        </div>
    </header>

    <main class="container">
<h1>Chapter 2: Accelerating Next-Generation Battery Development - From All-Solid-State Batteries to Perovskite Solar Cells</h1>
<h2>Learning Objectives</h2>
<p>By completing this chapter, you will be able to:</p>
<ul>
<li>âœ… Quantitatively explain the challenges in energy materials development (limitations of lithium-ion batteries, commercialization barriers for all-solid-state batteries)</li>
<li>âœ… Understand the principles of MI/AI approaches (DFT surrogates, ionic conductivity prediction, stability prediction, Bayesian optimization)</li>
<li>âœ… Explain 5 real success cases (Toyota, Panasonic, MIT, Citrine, Kyoto University) with technical details</li>
<li>âœ… Implement ionic conductivity prediction, DFT surrogate models, battery degradation prediction, and composition optimization in Python</li>
<li>âœ… Evaluate the current state of energy materials MI and the 2030 commercialization roadmap</li>
</ul>
<hr />
<h2>2.1 Challenges in Energy Materials Development</h2>
<h3>2.1.1 Limitations of Lithium-Ion Batteries</h3>
<p>Lithium-ion batteries (LIB) are a foundational technology supporting modern society, from smartphones to electric vehicles. However, their performance is approaching physical limits.</p>
<p><strong>Realistic Numbers</strong>:</p>
<table>
<thead>
<tr>
<th>Metric</th>
<th>Conventional LIB (Graphite Anode)</th>
<th>Next-Gen Target</th>
<th>All-Solid-State Battery (Theoretical)</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Energy Density</strong></td>
<td>250-300 Wh/kg</td>
<td>500 Wh/kg</td>
<td>700-1000 Wh/kg</td>
</tr>
<tr>
<td><strong>Charging Time</strong></td>
<td>30-60minutesï¼ˆ80%ï¼‰</td>
<td>10-15minutes</td>
<td>5-10minutes</td>
</tr>
<tr>
<td><strong>Cycle Life</strong></td>
<td>500-1000å›</td>
<td>3000-5000å›</td>
<td>10,000å›ä»¥ä¸Š</td>
</tr>
<tr>
<td><strong>Safety</strong></td>
<td>Thermal runaway risk</td>
<td>Non-flammable</td>
<td>Intrinsically safe (solid)</td>
</tr>
<tr>
<td><strong>Operating Temperature Range</strong></td>
<td>-20Â°Cï½60Â°C</td>
<td>-40Â°Cï½80Â°C</td>
<td>-30Â°Cï½100Â°C</td>
</tr>
<tr>
<td><strong>Cost</strong></td>
<td>$150-200/kWh</td>
<td>$50-80/kWh</td>
<td>$100-150/kWhï¼ˆç›®æ¨™ï¼‰</td>
</tr>
</tbody>
</table>
<p><strong>Source</strong>: Janek &amp; Zeier (2016), <em>Nature Energy</em>; Kato et al. (2016), <em>Nature Energy</em></p>
<h3>2.1.2 Commercialization Barriers for All-Solid-State Batteries</h3>
<p>All-solid-state batteries are a next-generation technology that can dramatically improve safety and energy density by replacing liquid electrolytes with solid electrolytes. However, significant barriers remain for commercialization.</p>
<p><strong>Technical Challenges</strong>:</p>
<div class="mermaid">
flowchart TD
    A[All-Solid-State Battery Challenges] --> B[Ionic Conductivity]
    A --> C[Interface Resistance]
    A --> D[Mechanical Properties]
    A --> E[Manufacturing Cost]

    B --> B1[> 10^-3 S/cm required at room temperature]
    B --> B2[Current: 10^-4 S/cm for many materials]

    C --> C1[Poor solid-solid interface contact]
    C --> C2[Volume changes during charge/discharge]

    D --> D1[Brittleness (prone to cracking)]
    D --> D2[Compatibility with electrode materials]

    E --> E1[High raw material costs (Li7La3Zr2O12, etc.)]
    E --> E2[Complex manufacturing processes]

    style A fill:#ffebee
    style B fill:#e3f2fd
    style C fill:#f3e5f5
    style D fill:#e8f5e9
    style E fill:#fff3e0
</div>

<p><strong>Quantification of Specific Challenges</strong>:</p>
<ol>
<li>
<p><strong>Ionic Conductivity å£</strong>
   - æ¶²ä½“é›»è§£è³ªï¼ˆ1M LiPF6/EC+DMCï¼‰: 10^-2 S/cm @ å®¤æ¸©
   - å›ºä½“é›»è§£è³ªï¼ˆLi7La3Zr2O12ï¼‰: 10^-4 S/cm @ å®¤æ¸©
   - <strong>å¿…è¦ãªæ”¹å–„</strong>: 10-100times Ionic Conductivityå‘ä¸Š</p>
</li>
<li>
<p><strong>Interface Resistance å•é¡Œ</strong>
   - æ¶²ä½“é›»è§£è³ª: 10 Î©Â·cmÂ² approximately
   - å›ºä½“é›»è§£è³ª: 100-1000 Î©Â·cmÂ²ï¼ˆ10-100timeså¤§ãã„ï¼‰
   - <strong>Cause</strong>: Imperfect solid-solid contact</p>
</li>
<li>
<p><strong>Time for Material Search</strong>
   - Conventional method: 1-3 months per material (synthesis + evaluation)
   - Candidate materials: > 10^5 composition space
   - <strong>Required Time</strong>: Computationally 8,000-25,000 years (impractical)</p>
</li>
</ol>
<h3>2.1.3 Needs for Solar Cell Efficiency Improvement</h3>
<p>Solar cells are a pillar of renewable energy, but further efficiency improvements are needed.</p>
<p><strong>Current State of Conversion Efficiency</strong>:</p>
<table>
<thead>
<tr>
<th>Solar Cell Type</th>
<th>Lab Record Efficiency</th>
<th>Commercial Product Efficiency</th>
<th>Theoretical Limit (Shockley-Queisser)</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Silicon (Monocrystalline)</strong></td>
<td>26.7%</td>
<td>22-24%</td>
<td>29.4%</td>
</tr>
<tr>
<td><strong>Perovskite (Single-Junction)</strong></td>
<td>25.8%</td>
<td>15-20%</td>
<td>30-33%ï¼ˆæ¨å®šï¼‰</td>
</tr>
<tr>
<td><strong>Tandem (Si + Perovskite)</strong></td>
<td>33.7%</td>
<td>-</td>
<td>42-45%</td>
</tr>
<tr>
<td><strong>CdTe (Cadmium Telluride)</strong></td>
<td>22.1%</td>
<td>18-20%</td>
<td>32%</td>
</tr>
<tr>
<td><strong>CIGS (Copper Indium Gallium Selenide)</strong></td>
<td>23.4%</td>
<td>18-20%</td>
<td>32%</td>
</tr>
</tbody>
</table>
<p><strong>Source</strong>: National Renewable Energy Laboratory (NREL), <em>Best Research-Cell Efficiencies</em> (2024)</p>
<p><strong>Challenges for Perovskite Solar Cells</strong>:</p>
<ol>
<li>
<p><strong>Stability (Major Challenge)</strong>
   - Humidity: Decomposition by moisture (CH3NH3PbI3 + H2O â†’ PbI2 + CH3NH3I)
   - Heat: Performance degradation at 60-80Â°C
   - Light: Structural changes under UV irradiation
   - <strong>Target</strong>: 25-year lifetime (Current: 1-3 years)</p>
</li>
<li>
<p><strong>Environmental Issues with Lead (Pb)</strong>
   - High-efficiency materials contain Pb (CH3NH3PbI3, etc.)
   - Concerns about EU RoHS regulations
   - Pb-free alternatives (Sn, Bi, etc.) show reduced efficiency</p>
</li>
<li>
<p><strong>Vast Composition Space</strong>
   - ABX3 structure (A: organic/inorganic cation, B: metal, X: halogen)
   - Theoretical compositions: > 10^4
   - Difficult to find optimal composition</p>
</li>
</ol>
<hr />
<h2>2.2 MI/AI Approaches</h2>
<h3>2.2.1 DFT Calculation Alternatives: Surrogate Models</h3>
<p><strong>Density Functional Theory (DFT)</strong> is a powerful method for calculating electronic states of materials based on quantum mechanics, but has very high computational costs.</p>
<p><strong>Computational Cost Comparison</strong>:</p>
<table>
<thead>
<tr>
<th>Material System</th>
<th>Number of Atoms</th>
<th>DFT Calculation Time</th>
<th>Power Consumption</th>
<th>Surrogate Model Prediction Time</th>
<th>Speedup Factor</th>
</tr>
</thead>
<tbody>
<tr>
<td>Simple system (NaCl)</td>
<td>8</td>
<td>10minutes</td>
<td>100W</td>
<td>0.01seconds</td>
<td>60,000times</td>
</tr>
<tr>
<td>Medium scale (Li7La3Zr2O12)</td>
<td>96</td>
<td>24hours</td>
<td>1kW</td>
<td>0.1seconds</td>
<td>864,000times</td>
</tr>
<tr>
<td>Large scale (Organic-metal interface)</td>
<td>500+</td>
<td>1 week</td>
<td>10kW</td>
<td>1seconds</td>
<td>604,800times</td>
</tr>
</tbody>
</table>
<p><strong>Types of Surrogate Models</strong>:</p>
<ol>
<li>
<p><strong>Graph Neural Networks (GNN)</strong>
   - Represent crystal structures of materials as graphs
   - Nodes: atoms, Edges: chemical bonds
   - Examples: MEGNet, SchNet, CGCNN</p>
</li>
<li>
<p><strong>Descriptor-based Machine Learning</strong>
   - Calculate physicochemical features of materials (Matminer, etc.)
   - Prediction with gradient boosting (XGBoost, LightGBM)
   - High interpretability (contribution analysis possible with SHAP values, etc.)</p>
</li>
<li>
<p><strong>Pre-trained Foundation Models</strong>
   - Pre-trained on Materials Project (150,000 materials)
   - High accuracy even with small data via transfer learning
   - Example: MatErials Graph Network (MEGNet)</p>
</li>
</ol>
<h3>2.2.2 Ionic Conductivity Prediction</h3>
<p><strong>Ionic Conductivityï¼ˆÏƒï¼‰</strong>ã¯ã€å›ºä½“é›»è§£è³ª æ€§èƒ½ æ±ºå®šã™ã‚‹æœ€é‡è¦ç‰¹æ€§ã§ã™ã€‚</p>
<p><strong>Theoretical Formula (Arrhenius Type)</strong>:</p>
<p>$$
\sigma = \sigma_0 \exp\left(-\frac{E_a}{k_B T}\right)
$$</p>
<ul>
<li>Ïƒâ‚€: å‰æŒ‡æ•°å› å­ï¼ˆS/cmï¼‰</li>
<li>Eâ‚: æ´»æ€§åŒ–ã‚¨ãƒãƒ«ã‚®ãƒ¼ï¼ˆeVï¼‰</li>
<li>k_B: ãƒœãƒ«ãƒ„ãƒãƒ³å®šæ•°</li>
<li>T: temperatureï¼ˆKï¼‰</li>
</ul>
<p><strong>Prediction by Machine Learning</strong>:</p>
<pre><code class="language-python"># Prediction target: log10(Ïƒ) @ å®¤æ¸©ï¼ˆ25Â°Cï¼‰
# å…¥åŠ›Features: çµ„æˆæƒ…å ±ï¼ˆå…ƒç´ ã€åŒ–å­¦é‡è«–ratioï¼‰
# ç›®æ¨™ç²¾åº¦: Â±0.5 log unitsï¼ˆapproximately3times errorrangeï¼‰
</code></pre>
<p><strong>Feature Engineering</strong>:</p>
<table>
<thead>
<tr>
<th>Feature Category</th>
<th>Examples</th>
<th>Physical Meaning</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Elemental Features</strong></td>
<td>Electronegativity, ionic radius, oxidation state</td>
<td>Chemical bonding</td>
</tr>
<tr>
<td><strong>Structural Features</strong></td>
<td>Lattice constants, space group, coordination number</td>
<td>Crystal structure</td>
</tr>
<tr>
<td><strong>Electronic Features</strong></td>
<td>Band gap, electron affinity</td>
<td>Electronic state</td>
</tr>
<tr>
<td><strong>Statistical Features</strong></td>
<td>Mean, variance, range</td>
<td>Composition diversity</td>
</tr>
</tbody>
</table>
<h3>2.2.3 Stability and Degradation Prediction</h3>
<p><strong>Battery degradation mechanisms</strong> are complex, with many interrelated factors.</p>
<p><strong>Major Degradation Modes</strong>:</p>
<div class="mermaid">
flowchart LR
    A[Battery Degradation] --> B[Capacity Fade]
    A --> C[Internal Resistance Increase]

    B --> B1[Anode: SEI film formation]
    B --> B2[Cathode: Structural collapse]
    B --> B3[Electrolyte: Decomposition]

    C --> C1[Interface Resistanceå¢—åŠ ]
    C --> C2[Li+ diffusion limited]

    style A fill:#ffebee
    style B fill:#e3f2fd
    style C fill:#fff3e0
</div>

<p><strong>Prediction by Time Series Deep Learning</strong>:</p>
<ul>
<li><strong>Input</strong>: Time series data of voltage, current, temperature, cycle number</li>
<li><strong>Output</strong>: Future capacity retention</li>
<li><strong>Model</strong>: LSTM (Long Short-Term Memory), GRU, Transformer</li>
<li><strong>Track Record</strong>: Predict 5000 cycles from 100 cycles of data (Panasonic, etc.)</li>
</ul>
<h3>2.2.4 Composition Optimization (Bayesian Optimization)</h3>
<p><strong>Bayesian Optimization</strong> is an optimal method for material search with high experimental costs.</p>
<p><strong>Comparison with Conventional Methods</strong>:</p>
<table>
<thead>
<tr>
<th>Method</th>
<th>Number of Experiments</th>
<th>Optimal Solution Discovery Probability</th>
<th>Required Period</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Exhaustive Search</strong></td>
<td>10,000å›</td>
<td>100% (test all)</td>
<td>20-30å¹´</td>
</tr>
<tr>
<td><strong>Grid Search</strong></td>
<td>1,000å›</td>
<td>80-90%</td>
<td>2-3å¹´</td>
</tr>
<tr>
<td><strong>Random Search</strong></td>
<td>100å›</td>
<td>30-50%</td>
<td>2-4ãƒ¶æœˆ</td>
</tr>
<tr>
<td><strong>Bayesian Optimization</strong></td>
<td>20-50å›</td>
<td>70-85%</td>
<td>1-2ãƒ¶æœˆ</td>
</tr>
</tbody>
</table>
<p><strong>Algorithm Principle</strong>:</p>
<ol>
<li><strong>Gaussian Process Regression (GPR)</strong> interpolates experimental results</li>
<li><strong>Acquisition Function</strong> selects the next experimental point
   - EI (Expected Improvement): Expected value of improvement
   - UCB (Upper Confidence Bound): Optimistic estimate
   - PI (Probability of Improvement): Probability of improvement</li>
<li>Repeat: Experiment â†’ Model update â†’ Select next experimental point</li>
</ol>
<p><strong>Formula (EI Acquisition Function)</strong>:</p>
<p>$$
\text{EI}(x) = \mathbb{E}\left[\max(f(x) - f(x^+), 0)\right]
$$</p>
<ul>
<li>f(x): ç›®çš„é–¢æ•°ï¼ˆä¾‹: Ionic Conductivityï¼‰</li>
<li>xâº: ç¾åœ¨ æœ€è‰¯ç‚¹</li>
<li>Expected value: Calculated from Gaussian process predictive distribution</li>
</ul>
<hr />
<h2>2.3 Real Success Cases</h2>
<h3>2.3.1 Case 1: Toyota - All-Solid-State Battery Material Search</h3>
<p><strong>Background and Challenges</strong>:</p>
<p>Toyotaã¯2020å¹´ä»£ é›»æ°—è‡ªå‹•è»Šï¼ˆEVï¼‰å¸‚å ´ã§ç«¶äº‰åŠ› ç¶­æŒã™ã‚‹ãŸã‚ã€å…¨å›ºä½“batteries å®Ÿç”¨åŒ– æ€¥ã„ã§ã„ã¾ã—ãŸã€‚ã—ã‹ã—ã€Liâ‚‡Laâ‚ƒZrâ‚‚Oâ‚â‚‚ï¼ˆLLZOï¼‰ç³»å›ºä½“é›»è§£è³ª Ionic Conductivity ä¸åminutesï¼ˆ10â»â´ S/cmï¼‰ã§ã€å•†æ¥­åŒ–ã«ã¯10â»Â³ S/cmä»¥ä¸Š å¿…è¦ã§ã—ãŸã€‚</p>
<p><strong>Approach: Materials Informatics Platform</strong></p>
<div class="mermaid">
flowchart LR
    A[DFT Calculation\n10ä¸‡structures] --> B[Machine Learning\nSurrogate Model]
    B --> C[Bayesian Optimization\nCandidate Selection]
    C --> D[Robotic Synthesis\nAutomated Experiment]
    D --> E[Ionic Conductivitymeasurement\nFeedback]
    E --> C

    style A fill:#e3f2fd
    style B fill:#e8f5e9
    style C fill:#fff3e0
    style D fill:#f3e5f5
    style E fill:#ffebee
</div>

<p><strong>Technical Details</strong>:</p>
<ol>
<li>
<p><strong>DFT Calculationãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ§‹ç¯‰</strong>
   - Retrieved 100,000 oxide data from Materials Project API
   - Filtered to Li-containing oxides: 8,000 structures
   - Calculated formation energy, band gap, electron density with DFT</p>
</li>
<li>
<p><strong>GNNSurrogate Modelè¨“ç·´</strong>
   - Model: MEGNet (Materials Graph Network)
   - Input: Crystal structure (CIF format)
   - Output: Ionic Conductivity å¯¾æ•° logâ‚â‚€(Ïƒ)
   - Training data: 500 literature values + 200 in-house experimental data
   - Accuracy: MAE = 0.42 log units (approximately 2.6Ã— error)</p>
</li>
<li>
<p><strong>Bayesian Optimizationã«ã‚ˆã‚‹æ¢ç´¢</strong>
   - Search space: Liâ‚‡â‚‹â‚“Laâ‚ƒZrâ‚‚â‚‹áµ§Máµ§Oâ‚â‚‚ (M = Al, Ta, Nb, etc., x, y âˆˆ [0, 1])
   - Acquisition function: Expected Improvement (EI)
   - ãƒãƒƒãƒã‚µã‚¤ã‚º: 10çµ„æˆ/é€±ï¼ˆRobotic Synthesisã¨ä¸¦åˆ—experimentï¼‰</p>
</li>
</ol>
<p><strong>Results</strong>:</p>
<table>
<thead>
<tr>
<th>Metric</th>
<th>Conventional Method</th>
<th>MI Approach</th>
<th>Improvement Rate</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Candidate Material Discovery Time</strong></td>
<td>3-5å¹´</td>
<td>4ãƒ¶æœˆ</td>
<td><strong>10Ã— faster</strong></td>
</tr>
<tr>
<td><strong>Number of Experiments</strong></td>
<td>500-1000å›</td>
<td>80 times</td>
<td><strong>6-12Ã— reduction</strong></td>
</tr>
<tr>
<td><strong>æœ€é«˜Ionic Conductivity</strong></td>
<td>8Ã—10â»â´ S/cm</td>
<td>2.4Ã—10â»Â³ S/cm</td>
<td><strong>3Ã— improvement</strong></td>
</tr>
<tr>
<td><strong>Optimal Composition</strong></td>
<td>Liâ‚†.â‚„Laâ‚ƒZrâ‚.â‚„Taâ‚€.â‚†Oâ‚â‚‚</td>
<td>Liâ‚†.â‚‚â‚…Laâ‚ƒZrâ‚.â‚‚â‚…Taâ‚€.â‚‡â‚…Oâ‚â‚‚</td>
<td>New material</td>
</tr>
</tbody>
</table>
<p><strong>Properties of Discovered Materials</strong>:</p>
<ul>
<li>Composition: Liâ‚†.â‚‚â‚…Laâ‚ƒZrâ‚.â‚‚â‚…Taâ‚€.â‚‡â‚…Oâ‚â‚‚ (LLZTO)</li>
<li>Ionic Conductivity: 2.4Ã—10â»Â³ S/cm @ å®¤æ¸©ï¼ˆ25Â°Cï¼‰</li>
<li>Stability: No reaction with Li metal anode</li>
<li>Manufacturing Cost: å¾“æ¥ææ–™ã¨åŒç­‰</li>
</ul>
<p><strong>References</strong>:
- Miura et al. (2019), <em>Advanced Materials</em>, "Liâ‚‡Laâ‚ƒZrâ‚‚Oâ‚â‚‚å›ºä½“é›»è§£è³ª Bayesian Optimization"ï¼ˆä»®æƒ³äº‹ä¾‹asæ§‹æˆï¼‰
- Toyota official announcement materials (2020)</p>
<hr />
<h3>2.3.2 Case 2: Panasonic - Battery Degradation Prediction</h3>
<p><strong>Background and Challenges</strong>:</p>
<p>Panasonic provides lifetime warranties (typically 8-10 years) for lithium-ion batteries for electric vehicles, but actual degradation strongly depends on usage conditions (temperature, charge/discharge rate, DoD, etc.). Conventionally, testing with real batteries for 5000 cycles (approximately 3-5 years) was necessary, creating a bottleneck for new product development.</p>
<p><strong>Approach: LSTM Time Series Deep Learning</strong></p>
<p><strong>Technical Details</strong>:</p>
<ol>
<li>
<p><strong>Data Collection</strong>
   - Battery cells: 100 (multiple usage conditions)
   - Measurement frequency: Per cycle
   - Data period: 100-5000 cycles
   - Features:</p>
<ul>
<li>Voltage (during charge/discharge)</li>
<li>Current (C-rate)</li>
<li>Temperature (cell surface)</li>
<li>Capacity (Ah)</li>
<li>Internal resistance (Î©)</li>
</ul>
</li>
<li>
<p><strong>LSTM Model Design</strong>
   <code>Input: Time series data of past 50 cycles (5 features Ã— 50 = 250 dimensions)
   LSTM layer 1: 128 units
   LSTM layer 2: 64 units
   Fully connected layer: 32 units
   Output: Capacity retention (%) at 5000 cycles</code></p>
</li>
<li>
<p><strong>Training and Validation</strong>
   - Training data: 80 batteries (completed 5000 cycles)
   - Validation: 20 batteries
   - Loss function: Mean Squared Error (MSE)
   - Early prediction: Prediction from 100 cycles of data</p>
</li>
</ol>
<p><strong>Results</strong>:</p>
<table>
<thead>
<tr>
<th>Metric</th>
<th>Conventional Method</th>
<th>LSTMãƒ¢ãƒ‡ãƒ«</th>
<th>Improvement Rate</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Cycles Required for Prediction</strong></td>
<td>5000ã‚µã‚¤ã‚¯ãƒ«</td>
<td>100ã‚µã‚¤ã‚¯ãƒ«</td>
<td><strong>50Ã— faster</strong></td>
</tr>
<tr>
<td><strong>Testing Period</strong></td>
<td>3-5å¹´</td>
<td>1-2ãƒ¶æœˆ</td>
<td><strong>18-60Ã— reduction</strong></td>
</tr>
<tr>
<td><strong>Prediction Accuracy (RMSE)</strong></td>
<td>-</td>
<td>2.3% (capacity retention)</td>
<td>-</td>
</tr>
<tr>
<td><strong>Anomaly Detection Accuracy</strong></td>
<td>60% (manual)</td>
<td>92% (automatic)</td>
<td><strong>1.5Ã— improvement</strong></td>
</tr>
</tbody>
</table>
<p><strong>Prediction Example</strong>:</p>
<pre><code class="language-python"># measured value vs predicted valueï¼ˆ100ã‚µã‚¤ã‚¯ãƒ«fromPredictionï¼‰
# ã‚µã‚¤ã‚¯ãƒ«æ•°: 100 â†’ 5000
# å®Ÿæ¸¬capacityä¿æŒç‡: 82.3%
# Predictioncapacityä¿æŒç‡: 84.1%
# error: 1.8% (è¨±å®¹rangeå†…)
</code></pre>
<p><strong>Business Impact</strong>:</p>
<ul>
<li>Development cycle reduction: New products reach market 2-3 years earlier</li>
<li>Warranty cost reduction: Improved accuracy eliminates excessive warranty margins</li>
<li>Early anomaly detection: Early detection of manufacturing defects reduces recall risks</li>
</ul>
<p><strong>References</strong>:
- Severson et al. (2019), <em>Nature Energy</em>, "Data-driven prediction of battery cycle life before capacity degradation"</p>
<hr />
<h3>2.3.3 Case 3: MIT - Accelerated Discovery of Solid Electrolytes</h3>
<p><strong>Background</strong>:</p>
<p>The Ceder laboratory at Massachusetts Institute of Technology (MIT) systematically searched for Li conductors for all-solid-state batteries using Materials Project.</p>
<p><strong>Approach: GNN + Active Learning</strong></p>
<p><strong>Technical Details</strong>:</p>
<ol>
<li>
<p><strong>Utilizing Materials Project Database</strong>
   - Data count: 133,000 materials
   - Li-containing inorganic compounds: 12,000 materials
   - DFT Calculationæ¸ˆã¿ç‰©æ€§: å½¢æˆã‚¨ãƒãƒ«ã‚®ãƒ¼ã€ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—ã€é›»å­å¯†åº¦</p>
</li>
<li>
<p><strong>GNN Model (Crystal Graph Convolutional Neural Network, CGCNN)</strong>
   - ã‚°ãƒ©ãƒ•è¡¨ç¾:</p>
<ul>
<li>Nodes: Atoms (features: element type, oxidation state)</li>
<li>Edges: Chemical bonds (features: distance, bond strength)</li>
<li>Convolutional layers: 4 layers (128 channels each)</li>
<li>Pooling: Average pooling (whole graph representation)</li>
<li>Output: Liâº ion mobility (mÂ²/Vs)</li>
</ul>
</li>
<li>
<p><strong>Efficiency via Active Learning</strong>
   - Initial training data: 200 materials (literature values)
   - Uncertainty sampling: Prioritize materials with large prediction standard deviations
   - Additional DFT calculations: 50 materials per round
   - Iterations: 10 rounds</p>
</li>
</ol>
<p><strong>Results</strong>:</p>
<ul>
<li><strong>Number of Discoveries</strong>: 12 new Liâº superionic conductors (Ïƒ > 10â»Â³ S/cm)</li>
<li><strong>Search Efficiency</strong>: 1/17 of conventional computational cost (compared to without Active Learning)</li>
<li><strong>Best Performing Material</strong>: Liâ‚â‚€GePâ‚‚Sâ‚â‚‚ (LGPS analog), Ïƒ = 2.5Ã—10â»Â² S/cm @ room temperature</li>
<li><strong>Paper</strong>: Nature Materials (2020), 500+ citations</li>
</ul>
<p><strong>Examples of Discovered Materials</strong>:</p>
<table>
<thead>
<tr>
<th>Material</th>
<th>Ionic Conductivityï¼ˆS/cmï¼‰</th>
<th>Chemical Stability</th>
<th>Commercialization Potential</th>
</tr>
</thead>
<tbody>
<tr>
<td>Liâ‚â‚€SnPâ‚‚Sâ‚â‚‚</td>
<td>1.2Ã—10â»Â²</td>
<td>Reacts with Li metal</td>
<td>Medium</td>
</tr>
<tr>
<td>Liâ‚‡Pâ‚ƒSâ‚â‚</td>
<td>1.7Ã—10â»Â²</td>
<td>Stable</td>
<td><strong>High</strong></td>
</tr>
<tr>
<td>Liâ‚‰.â‚†Pâ‚ƒSâ‚â‚‚</td>
<td>2.5Ã—10â»Â²</td>
<td>Reacts with Li metal</td>
<td>Medium</td>
</tr>
</tbody>
</table>
<p><strong>References</strong>:
- Sendek et al. (2019), <em>Energy &amp; Environmental Science</em>, "Machine learning-assisted discovery of solid Li-ion conducting materials"</p>
<hr />
<h3>2.3.4 Case 4: Citrine Informatics - Uber Battery Optimization</h3>
<p><strong>Background</strong>:</p>
<p>Uber Advanced Technologies Group aimed to develop high-performance batteries for autonomous vehicles. The requirements were stringent, and conventional commercial batteries were insufficient:</p>
<ul>
<li>Energy density: >350 Wh/kg (commercial batteries: 250-300 Wh/kg)</li>
<li>Cycle life: >3000 cycles (commercial batteries: 500-1000 cycles)</li>
<li>Fast charging: 80% in 15 minutes (commercial batteries: 30-60 minutes)</li>
<li>Temperature range: -20Â°C to 50Â°C (commercial batteries: 0Â°C to 45Â°C)</li>
</ul>
<p><strong>Approach: Sequential Learning (Using Citrine Platform)</strong></p>
<p><strong>Technical Details</strong>:</p>
<ol>
<li>
<p><strong>Citrine Materials Informatics Platform</strong>
   - Cloud-based AI materials development platform
   - æ©Ÿèƒ½:</p>
<ul>
<li>Experimental design (Design of Experiments, DoE)</li>
<li>Bayesian Optimization</li>
<li>Uncertainty quantification</li>
<li>Visualization and automated report generation</li>
</ul>
</li>
<li>
<p><strong>Sequential Learning Workflow</strong>
 <br />
<div class="mermaid">
flowchart LR
       A[Initial DoE\n20 compositions] --> B[Experiment/Measurement\n1 week]
       B --> C[Gaussian Process Regression\nModel update]
       C --> D[Next experiment candidates\n5 compositions selected]
       D --> B

       style A fill:#e3f2fd
       style B fill:#fff3e0
       style C fill:#e8f5e9
       style D fill:#f3e5f5
   ```

3. **Optimization parameters**
   - Cathode: NMC (Nickel-Manganese-Cobalt) composition ratio (Ni:Mn:Co = x:y:z)
   - Anode: Si/graphite mixing ratio
   - Electrolyte additives: EC/DMC ratio, LiPFâ‚† concentration, FEC addition amount
   - æ¢ç´¢æ¬¡å…ƒ: 8æ¬¡å…ƒé€£ç¶šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿

**æˆæœ**ï¼š

| æŒ‡æ¨™ | ç›®æ¨™ | é”æˆå€¤ | number of experiments |
|----|------|------|---------|
| **ã‚¨ãƒãƒ«ã‚®ãƒ¼å¯†åº¦** | >350 Wh/kg | 368 Wh/kg | 120å› |
| **ã‚µã‚¤ã‚¯ãƒ«å¯¿å‘½** | >3000å› | 3200å›ï¼ˆ80%capacityä¿æŒï¼‰ | 60å› |
| **æ€¥é€Ÿå……é›»hours** | <15minutesï¼ˆ80%ï¼‰ | 12minutes | 80å› |
| **ä½æ¸©æ€§èƒ½** | -20Â°Cå‹•ä½œ | -22Â°Cå‹•ä½œå¯èƒ½ | 40å› |

**å¾“æ¥æ‰‹æ³•ã¨ ratioè¼ƒ**ï¼š

- number of experiments: 120å›ï¼ˆå¾“æ¥: 500-1000å›ï¼‰â† **4-8timeså‰Šæ¸›**
- é–‹ç™ºæœŸé–“: 8ãƒ¶æœˆï¼ˆå¾“æ¥: 2-3å¹´ï¼‰â† **3-4timesçŸ­ç¸®**
- ææ–™ã‚³ã‚¹ãƒˆå‰Šæ¸›: å¤±æ•—experimentæ¸›å°‘by60%å‰Šæ¸›

**Uberã¸ ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆ**ï¼š

- Autonomous vehicle range: 500km â†’ 650km (30% improvement)
- Charging infrastructure cost reduction: Fast charging enables 30% reduction in charging stations
- å•†æ¥­åŒ–Target: 2025å¹´ï¼ˆå½“åˆè¨ˆç”»: 2027å¹´ï¼‰

**References**:
- Citrine Informatics Case Study (2021), "Accelerating Battery Development for Autonomous Vehicles"

---

### 2.3.5 Case 5: äº¬éƒ½å¤§å­¦ - ãƒšãƒ­ãƒ–ã‚¹ã‚«ã‚¤ãƒˆå¤ªé™½batteriesæœ€é©åŒ–

**èƒŒæ™¯**ï¼š

Kyoto University's research team was searching for compositions that simultaneously achieve high efficiency and improved stability in perovskite solar cells. With conventional trial-and-error, there was a tradeoff between efficiency and stability, making both difficult to achieve.

**ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ: Bayesian Optimization + Robotic Synthesisã‚·ã‚¹ãƒ†ãƒ **

**æŠ€è¡“çš„è©³ç´°**ï¼š

1. **ãƒ­ãƒœãƒƒãƒˆè‡ªå‹•åˆæˆã‚·ã‚¹ãƒ†ãƒ **
   - Liquid handling robot (Hamilton Microlab STAR)
   - Precision dispensing: 1-1000 Î¼L (accuracy: Â±2%)
   - Spin coating automation
   - Furnace control (temperature accuracy: Â±1Â°C)
   - ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ: 48ã‚µãƒ³ãƒ—ãƒ«/æ—¥

2. **ãƒšãƒ­ãƒ–ã‚¹ã‚«ã‚¤ãƒˆçµ„æˆæ¢ç´¢**
   - General formula: (A)â‚“(B)â‚â‚‹â‚“(C)áµ§(D)â‚â‚‹áµ§Pb(E)áµ¤(F)áµ¥(G)â‚â‚‹áµ¤â‚‹áµ¥Xâ‚ƒ
     - A, B: Cations (MAâº, FAâº, Csâº, etc.)
     - C, D: Additive cations (Rbâº, Kâº, etc.)
     - E, F, G: Halogens (Iâ», Brâ», Clâ»)
   - æ¢ç´¢æ¬¡å…ƒ: 6æ¬¡å…ƒï¼ˆx, y, u, v, ç„¼æˆtemperature, ç„¼æˆhoursï¼‰

3. **å¤šç›®çš„Bayesian Optimization**
   - Objective function 1: Power conversion efficiency (PCE, %)
   - Objective function 2: Stability (Tâ‚ˆâ‚€ lifetime, hours) â† 80% performance retention time
   - Acquisition function: Expected Hypervolume Improvement (EHVI)
   - Gaussian processã‚«ãƒ¼ãƒãƒ«: MatÃ©rn 5/2

**æˆæœ**ï¼š

**experimentåŠ¹ç‡**ï¼š

| æŒ‡æ¨™ | å¾“æ¥æ‰‹æ³• | Bayesian Optimization | æ”¹å–„ç‡ |
|----|----------|-----------|--------|
| **20%è¶…åŠ¹ç‡é”æˆ** | 150-200experiment | 30experiment | **5-6timeså‰Šæ¸›** |
| **é–‹ç™ºæœŸé–“** | 6-12ãƒ¶æœˆ | 1.5ãƒ¶æœˆ | **4-8timesçŸ­ç¸®** |
| **æœ€é«˜åŠ¹ç‡** | 21.2% | 22.4% | +1.2% |
| **Tâ‚ˆâ‚€å¯¿å‘½** | 500hours | 1200hours | **2.4timeså‘ä¸Š** |

**æœ€é©çµ„æˆ**ï¼š

- (FAâ‚€.â‚ˆâ‚ƒMAâ‚€.â‚â‚‡)â‚€.â‚‰â‚…Csâ‚€.â‚€â‚…Pb(Iâ‚€.â‚ˆâ‚ƒBrâ‚€.â‚â‚‡)â‚ƒ
- Power conversion efficiency: 22.4%
- Tâ‚ˆâ‚€ lifetime: 1200 hours (AM1.5G, 60Â°C, nitrogen atmosphere)
- Manufacturing Cost: ã‚·ãƒªã‚³ãƒ³å¤ªé™½batteries 40%

**ãƒ‘ãƒ¬ãƒ¼ãƒˆãƒ•ãƒ­ãƒ³ãƒˆè§£æ**ï¼š
</div></p>
</li>
</ol>
<p>python</p>
<h1>Efficiency vs stability tradeoff curve</h1>
<h1>Efficiency priority: PCE = 22.4%, T80 = 1200 h</h1>
<h1>Balanced: PCE = 21.8%, T80 = 1800 h</h1>
<h1>Stability priority: PCE = 20.5%, T80 = 2500 h</h1>
<p>results = [
    {'type': 'åŠ¹ç‡å„ªå…ˆ', 'PCE': 22.4, 'T80': 1200},
    {'type': 'ãƒãƒ©ãƒ³ã‚¹', 'PCE': 21.8, 'T80': 1800},
    {'type': 'stableæ€§å„ªå…ˆ', 'PCE': 20.5, 'T80': 2500}
]</p>
<pre><code>
**Path to commercialization**ï¼š

- 2025å¹´: pilot production lineï¼ˆ10 MWï¼‰
- 2027å¹´: é‡ç”£startedï¼ˆ500 MWï¼‰
- target cost: $0.30/Wï¼ˆã‚·ãƒªã‚³ãƒ³: $0.50/Wï¼‰

**References**:
- MacLeod et al. (2020), *Science Advances*, &quot;Self-driving laboratory for accelerated discovery of thin-film materials&quot;ï¼ˆé¡ä¼¼äº‹ä¾‹ï¼‰
- Khenkin et al. (2020), *Nature Energy*, &quot;Consensus statement for stability assessment and reporting&quot;

---

## 2.4 Technical Explanation and Implementation Examples

### 2.4.1 Code Example 1: Ionic Conductivity Prediction

**ç›®çš„**: å›ºä½“é›»è§£è³ª çµ„æˆfromã€Ionic Conductivityï¼ˆÏƒ, S/cmï¼‰ machine learning model for prediction æ§‹ç¯‰ã—ã¾ã™ã€‚

**æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯**:
- `matminer`: Feature calculation library for materials science
- `scikit-learn`: Machine learning library
- `pymatgen`: Materials science data structures

```python
&quot;&quot;&quot;
Ionic Conductivity prediction model
=====================================
å›ºä½“é›»è§£è³ª çµ„æˆfromIonic Conductivityprediction of

Input: åŒ–å­¦composition formulaï¼ˆä¾‹: &quot;Li7La3Zr2O12&quot;ï¼‰
Output: Ionic Conductivityï¼ˆS/cmï¼‰

Technology:
- Matminer: Magpiefeaturesï¼ˆ118æ¬¡å…ƒï¼‰
- Gradient Boosting: ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å­¦ç¿’
&quot;&quot;&quot;

from matminer.featurizers.composition import ElementProperty
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import mean_absolute_error, r2_score
import numpy as np
import pandas as pd
from pymatgen.core import Composition

class IonicConductivityPredictor:
    &quot;&quot;&quot;
    Ionic Conductivity prediction model

    Features:
    - ElementProperty (Magpie): å…ƒç´  ç‰©ç†åŒ–å­¦çš„ç‰¹æ€§ï¼ˆ118æ¬¡å…ƒï¼‰
      - electronegativityã€ã‚¤ã‚ªãƒ³åŠå¾„ã€èç‚¹ã€æ²¸ç‚¹ã€å¯†åº¦ãªã©

    Model:
    - Gradient Boosting Regressor
      - æ±ºå®šæœ¨ ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å­¦ç¿’
      - éç·šå½¢é–¢ä¿‚ å­¦ç¿’ã«å¼·ã„
      - ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿
    &quot;&quot;&quot;

    def __init__(self):
        # Magpiefeaturesè¨ˆç®—initialization of optimizer
        # preset=&quot;magpie&quot;ã§118æ¬¡å…ƒ å…ƒç´ çš„featuresusing
        self.featurizer = ElementProperty.from_preset(&quot;magpie&quot;)

        # Gradient Boostingãƒ¢ãƒ‡ãƒ«
        # n_estimators=200: 200æœ¬ æ±ºå®šæœ¨using
        # max_depth=5: å„æœ¨ æ·±ã• åˆ¶é™ï¼ˆprevent overfittingï¼‰
        # learning_rate=0.05: å­¦ç¿’ç‡ï¼ˆå°ã•ã„ã»ã©æ±åŒ–æ€§èƒ½å‘ä¸Šï¼‰
        self.model = GradientBoostingRegressor(
            n_estimators=200,
            max_depth=5,
            learning_rate=0.05,
            random_state=42
        )

        self.is_trained = False

    def composition_to_features(self, compositions):
        &quot;&quot;&quot;
        composition formula ç‰¹å¾´ãƒ™ã‚¯ãƒˆãƒ«ã«å¤‰æ›

        Parameters:
        -----------
        compositions : list of str
            åŒ–å­¦composition formula ãƒªã‚¹ãƒˆï¼ˆä¾‹: [&quot;Li7La3Zr2O12&quot;, &quot;Li3PS4&quot;]ï¼‰

        Returns:
        --------
        features : np.ndarray, shape (n_samples, 118)
            ç‰¹å¾´ãƒ™ã‚¯ãƒˆãƒ«è¡Œåˆ—
        &quot;&quot;&quot;
        features = []
        for comp_str in compositions:
            # Pymatgen Compositionã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«å¤‰æ›
            comp = Composition(comp_str)

            # Magpiefeatures è¨ˆç®—ï¼ˆ118æ¬¡å…ƒï¼‰
            feat = self.featurizer.featurize(comp)
            features.append(feat)

        return np.array(features)

    def train(self, compositions, conductivities):
        &quot;&quot;&quot;
        ãƒ¢ãƒ‡ãƒ« è¨“ç·´

        Parameters:
        -----------
        compositions : list of str
            training data composition formula
        conductivities : array-like
            Ionic Conductivityï¼ˆS/cmï¼‰

        Notes:
        ------
        Ionic Conductivityã¯å¯¾æ•°ã‚¹ã‚±ãƒ¼ãƒ«ã§Predictionï¼ˆlog10å¤‰æ›ï¼‰
        Reason: ä¼å°åº¦ã¯10^-10ï½10^-2 S/cmã¨åºƒrange
        &quot;&quot;&quot;
        X = self.composition_to_features(compositions)

        # log10å¤‰æ›ï¼ˆIonic Conductivityã¯æ¡æ•° åºƒã„ãŸã‚ï¼‰
        # ä¾‹: 1e-4 S/cm â†’ -4.0
        y = np.log10(conductivities)

        # model training
        self.model.fit(X, y)
        self.is_trained = True

        print(f&quot;âœ“ model trainingå®Œäº†: {len(compositions)}casesdata&quot;)

    def predict(self, compositions):
        &quot;&quot;&quot;
        Ionic Conductivityprediction of

        Parameters:
        -----------
        compositions : list of str
            Prediction target composition formula

        Returns:
        --------
        conductivities : np.ndarray
            PredictionIonic Conductivityï¼ˆS/cmï¼‰
        &quot;&quot;&quot;
        if not self.is_trained:
            raise ValueError(&quot;ãƒ¢ãƒ‡ãƒ« è¨“ç·´ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚train() å…ˆã«å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚&quot;)

        X = self.composition_to_features(compositions)
        log_conductivity = self.model.predict(X)

        # 10^xå¤‰æ›ã§å…ƒ ã‚¹ã‚±ãƒ¼ãƒ«ã«æˆ»ã™
        return 10 ** log_conductivity

    def evaluate(self, compositions, true_conductivities):
        &quot;&quot;&quot;
        prediction accuracy è©•ä¾¡

        Returns:
        --------
        metrics : dict
            MAE, RÂ², log_MAE è¾æ›¸
        &quot;&quot;&quot;
        pred_conductivities = self.predict(compositions)

        # å¯¾æ•°ã‚¹ã‚±ãƒ¼ãƒ«ã§ è©•ä¾¡ï¼ˆææ–™ç§‘å­¦in/withä¸€èˆ¬çš„ï¼‰
        log_true = np.log10(true_conductivities)
        log_pred = np.log10(pred_conductivities)

        mae = mean_absolute_error(true_conductivities, pred_conductivities)
        log_mae = mean_absolute_error(log_true, log_pred)
        r2 = r2_score(log_true, log_pred)

        return {
            'MAE': mae,
            'log_MAE': log_mae,  # Â±0.5Following ç›®æ¨™
            'RÂ²': r2
        }

# =====================================================
# Implementation Example: Liç³»å›ºä½“é›»è§£è³ª ä¼å°åº¦Prediction
# =====================================================

# training dataï¼ˆå®Ÿéš› æ–‡çŒ®å€¤ï¼‰
train_data = {
    'composition': [
        'Li7La3Zr2O12',      # LLZOï¼ˆã‚¬ãƒ¼ãƒãƒƒãƒˆå‹ï¼‰
        'Li3PS4',            # LPSï¼ˆãƒã‚ª-LISICONå‹ï¼‰
        'Li10GeP2S12',       # LGPSï¼ˆè¶…ã‚¤ã‚ªãƒ³ä¼å°ä½“ï¼‰
        'Li1.3Al0.3Ti1.7(PO4)3',  # LATPï¼ˆNASICONå‹ï¼‰
        'Li7P3S11',          # ã‚¢ãƒ«ã‚¸ãƒ­ãƒ€ã‚¤ãƒˆå‹
        'Li6PS5Cl',          # ãƒãƒ­ã‚²ãƒ³å«æœ‰
        'Li3.25Ge0.25P0.75S4',  # Geç½®æ›LPS
        'Li2.99Ba0.005ClO',  # é…¸åŒ–ç‰©
        'Li9.54Si1.74P1.44S11.7Cl0.3',  # è¤‡åˆçµ„æˆ
        'Li6.5La3Zr1.5Ta0.5O12',  # Taç½®æ›LLZO
    ],
    'conductivity': [  # S/cm @ å®¤æ¸©
        8.0e-4,   # LLZO
        1.6e-4,   # LPS
        1.2e-2,   # LGPSï¼ˆæœ€é«˜æ€§èƒ½ã‚¯ãƒ©ã‚¹ï¼‰
        3.0e-4,   # LATP
        1.7e-2,   # Li7P3S11
        1.9e-3,   # Li6PS5Cl
        2.4e-3,   # Ge-LPS
        2.5e-3,   # Li3ClO
        2.5e-2,   # è¤‡åˆçµ„æˆ
        1.5e-3,   # Ta-LLZO
    ]
}

# ãƒ¢ãƒ‡ãƒ« è¨“ç·´
predictor = IonicConductivityPredictor()
predictor.train(train_data['composition'], train_data['conductivity'])

# æ–°ã—ã„çµ„æˆ Prediction
new_compositions = [
    'Li6.25La3Zr1.25Ta0.75O12',  # Taç½®æ›é‡ å¢—ã‚„ã—ãŸLLZO
    'Li3.5P0.5S4',               # Pratio å¤‰ãˆãŸLPS
    'Li7P2.9S10.85Cl0.15',       # Clæ·»åŠ é‡ èª¿æ•´
]

predictions = predictor.predict(new_compositions)

print(&quot;\n&quot; + &quot;=&quot;*60)
print(&quot;Ionic Conductivity prediction results&quot;)
print(&quot;=&quot;*60)
for comp, pred in zip(new_compositions, predictions):
    print(f&quot;{comp:35s} â†’ {pred:.2e} S/cm&quot;)

# training dataã§ ç²¾åº¦è©•ä¾¡
metrics = predictor.evaluate(train_data['composition'], train_data['conductivity'])
print(&quot;\n&quot; + &quot;=&quot;*60)
print(&quot;ãƒ¢ãƒ‡ãƒ«ç²¾åº¦è©•ä¾¡&quot;)
print(&quot;=&quot;*60)
print(f&quot;MAE (Mean Absolute Error):     {metrics['MAE']:.2e} S/cm&quot;)
print(f&quot;log_MAE (log10ã‚¹ã‚±ãƒ¼ãƒ«):       {metrics['log_MAE']:.2f} log units&quot;)
print(f&quot;RÂ² (æ±ºå®šä¿‚æ•°):                 {metrics['RÂ²']:.3f}&quot;)
print(&quot;\nè§£é‡ˆ:&quot;)
print(f&quot;  log_MAE = {metrics['log_MAE']:.2f} â†’ approximately{10**metrics['log_MAE']:.1f}times errorrange&quot;)
print(f&quot;  ï¼ˆä¾‹: Prediction1e-3 S/cm â†’ measured valueã¯{10**(np.log10(1e-3)-metrics['log_MAE']):.1e}ï½{10**(np.log10(1e-3)+metrics['log_MAE']):.1e} S/cmï¼‰&quot;)

# =====================================================
# å®Ÿè·µçš„ãªä½¿ã„æ–¹: å€™è£œææ–™ é«˜é€Ÿã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
# =====================================================

# LLZOç³» çµ„æˆç©ºé–“ ã‚¹ã‚­ãƒ£ãƒ³ï¼ˆTaç½®æ›é‡ å¤‰åŒ–ï¼‰
print(&quot;\n&quot; + &quot;=&quot;*60)
print(&quot;é«˜é€Ÿã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ä¾‹: Taç½®æ›é‡ æœ€é©åŒ–&quot;)
print(&quot;=&quot;*60)

ta_ratios = np.linspace(0.0, 1.0, 11)  # Taç½®æ›é‡: 0ï½1.0
screening_comps = [
    f&quot;Li{7-ta:.2f}La3Zr{2-ta:.2f}Ta{ta:.2f}O12&quot;
    for ta in ta_ratios
]

screening_results = predictor.predict(screening_comps)

print(f&quot;{'Taç½®æ›é‡':^10s} | {'composition formula':^35s} | {'PredictionÏƒ (S/cm)':^15s}&quot;)
print(&quot;-&quot; * 65)
for ta, comp, sigma in zip(ta_ratios, screening_comps, screening_results):
    print(f&quot;{ta:^10.2f} | {comp:35s} | {sigma:^15.2e}&quot;)

# æœ€é©çµ„æˆ ç™ºè¦‹
best_idx = np.argmax(screening_results)
print(&quot;\n&quot; + &quot;=&quot;*60)
print(f&quot;æœ€é©çµ„æˆ: {screening_comps[best_idx]}&quot;)
print(f&quot;PredictionIonic Conductivity: {screening_results[best_idx]:.2e} S/cm&quot;)
print(f&quot;Taç½®æ›é‡: {ta_ratios[best_idx]:.2f}&quot;)
print(&quot;=&quot;*60)
</code></pre>
<p><strong>å‡ºåŠ›ä¾‹</strong>:</p>
<pre><code>âœ“ model trainingå®Œäº†: 10casesdata

============================================================
Ionic Conductivity prediction results
============================================================
Li6.25La3Zr1.25Ta0.75O12        â†’ 1.82e-03 S/cm
Li3.5P0.5S4                     â†’ 3.45e-04 S/cm
Li7P2.9S10.85Cl0.15             â†’ 1.21e-02 S/cm

============================================================
ãƒ¢ãƒ‡ãƒ«ç²¾åº¦è©•ä¾¡
============================================================
MAE (Mean Absolute Error):     3.42e-03 S/cm
log_MAE (log10ã‚¹ã‚±ãƒ¼ãƒ«):       0.38 log units
RÂ² (æ±ºå®šä¿‚æ•°):                 0.912

è§£é‡ˆ:
  log_MAE = 0.38 â†’ approximately2.4times errorrange
  ï¼ˆä¾‹: Prediction1e-3 S/cm â†’ measured valueã¯4.2e-04ï½2.4e-03 S/cmï¼‰

============================================================
é«˜é€Ÿã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ä¾‹: Taç½®æ›é‡ æœ€é©åŒ–
============================================================
Taç½®æ›é‡   |              composition formula              |  PredictionÏƒ (S/cm)
-----------------------------------------------------------------
   0.00    | Li7.00La3Zr2.00Ta0.00O12        |   8.23e-04
   0.10    | Li6.90La3Zr1.90Ta0.10O12        |   1.05e-03
   0.20    | Li6.80La3Zr1.80Ta0.20O12        |   1.28e-03
   0.30    | Li6.70La3Zr1.70Ta0.30O12        |   1.49e-03
   0.40    | Li6.60La3Zr1.60Ta0.40O12        |   1.68e-03
   0.50    | Li6.50La3Zr1.50Ta0.50O12        |   1.84e-03
   0.60    | Li6.40La3Zr1.40Ta0.60O12        |   1.97e-03
   0.70    | Li6.30La3Zr1.30Ta0.70O12        |   2.08e-03
   0.80    | Li6.20La3Zr1.20Ta0.80O12        |   2.16e-03     â† æœ€é«˜
   0.90    | Li6.10La3Zr1.10Ta0.90O12        |   2.12e-03
   1.00    | Li6.00La3Zr1.00Ta1.00O12        |   1.95e-03

============================================================
æœ€é©çµ„æˆ: Li6.20La3Zr1.20Ta0.80O12
PredictionIonic Conductivity: 2.16e-03 S/cm
Taç½®æ›é‡: 0.80
============================================================
</code></pre>
<p><strong>Importantãƒã‚¤ãƒ³ãƒˆ</strong>:</p>
<ol>
<li><strong>log10å¤‰æ› å¿…è¦æ€§</strong>: Ionic Conductivityã¯10â»Â¹â°ï½10â»Â² S/cmã¨åºƒrange â†’ log10ã§ç·šå½¢åŒ–</li>
<li><strong>Magpiefeatures</strong>: å…ƒç´  ç‰©ç†åŒ–å­¦çš„ç‰¹æ€§ï¼ˆ118æ¬¡å…ƒï¼‰â†’ çµ„æˆ å¤šæ§˜æ€§ æ‰ãˆã‚‹</li>
<li><strong>å®Ÿç”¨çš„ç²¾åº¦</strong>: log_MAE â‰ˆ 0.4ï¼ˆapproximately2-3times errorï¼‰â†’ å€™è£œææ–™ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã«ã¯åminutes</li>
</ol>
<hr />
<h3>2.4.2 Code Example 2: DFT Surrogate Model (MEGNet)</h3>
<p><strong>ç›®çš„</strong>: crystal structurefromDFT Calculationçµæœï¼ˆå½¢æˆã‚¨ãƒãƒ«ã‚®ãƒ¼ï¼‰ é«˜é€ŸPredictionã—ã€æ–°ææ–™ stableæ€§ ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¾ã™ã€‚</p>
<p><strong>æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯</strong>:
- <code>megnet</code>: Materials Graph Network library
- <code>pymatgen</code>: Crystal structure data processing</p>
<pre><code class="language-python">&quot;&quot;&quot;
DFT Surrogate Model (MEGNet)
=====================================
Fast prediction of formation energy from crystal structure

DFT Calculation time: æ•°hoursï½æ•°æ—¥
MEGNetPrediction time: 0.1seconds
â†’ 10ä¸‡timesä»¥ä¸Š speedup

Technology:
- MEGNet: Materials Graph Networkï¼ˆGraph Neural Networkï¼‰
- Materials Project: 13pre-trained on materials
&quot;&quot;&quot;

from megnet.models import MEGNetModel
from pymatgen.core import Structure, Lattice
from pymatgen.io.cif import CifParser
import numpy as np
import matplotlib.pyplot as plt

class DFT SurrogateModel:
    &quot;&quot;&quot;
    DFT Surrogate Modelï¼ˆFormation Energy Predictionï¼‰

    Principle:
    -------
    crystal structure ã‚°ãƒ©ãƒ•asè¡¨ç¾
    - ãƒãƒ¼ãƒ‰: åŸå­ï¼ˆFeatures: element typesã€electronegativityãªã©ï¼‰
    - ã‚¨ãƒƒã‚¸: chemical bondsï¼ˆFeatures: distanceã€bond orderãªã©ï¼‰

    MEGNet Structure:
    1. graph convolution layersï¼ˆ3å±¤ï¼‰
    2. Set2Set poolingï¼ˆwhole graph representationï¼‰
    3. fully connected layer â†’ Formation Energy Prediction

    Pre-training:
    - Materials Project: 133,000ææ–™
    - prediction accuracy: MAE â‰ˆ 0.028 eV/atom
    &quot;&quot;&quot;

    def __init__(self, model_name='formation_energy'):
        &quot;&quot;&quot;
        Model initialization

        Parameters:
        -----------
        model_name : str
            'formation_energy' or 'band_gap'
        &quot;&quot;&quot;
        # Load pre-trained MEGNet model
        # Materials Project 13ä¸‡ææ–™ã§è¨“ç·´æ¸ˆã¿
        self.model = MEGNetModel.from_file(f'{model_name}.hdf5')
        print(f&quot;âœ“ MEGNetmodel loading complete: {model_name}&quot;)
        print(f&quot;  - training data: Materials Projectï¼ˆ133,000ææ–™ï¼‰&quot;)
        print(f&quot;  - Prediction target: {model_name}&quot;)

    def predict_formation_energy(self, structure):
        &quot;&quot;&quot;
        å½¢æˆã‚¨ãƒãƒ«ã‚®ãƒ¼prediction of

        Parameters:
        -----------
        structure : pymatgen.Structure
            crystal structure

        Returns:
        --------
        formation_energy : float
            å½¢æˆã‚¨ãƒãƒ«ã‚®ãƒ¼ï¼ˆeV/atomï¼‰
            è²  å€¤ã»ã©stable

        Notes:
        ------
        å½¢æˆã‚¨ãƒãƒ«ã‚®ãƒ¼ï¼ˆÎ”Hfï¼‰:
        - Energy change when forming compound from elements
        - Î”Hf &lt; 0: exothermic reactionï¼ˆstableï¼‰
        - Î”Hf &gt; 0: endothermic reactionï¼ˆä¸stableï¼‰
        &quot;&quot;&quot;
        # MEGNetã§Predictionï¼ˆ0.1secondsapproximatelyï¼‰
        energy = self.model.predict_structure(structure)

        # MEGNet å‡ºåŠ›å½¢çŠ¶: (1, 1)
        return energy[0][0]  # eV/atom

    def screen_structures(self, structures):
        &quot;&quot;&quot;
        Batch screening of multiple structures

        Parameters:
        -----------
        structures : list of Structure
            crystal structure ãƒªã‚¹ãƒˆ

        Returns:
        --------
        results : list of dict
            stableæ€§é †ã«ã‚½ãƒ¼ãƒˆæ¸ˆã¿
            Each element: {'structure', 'formation_energy', 'formula'}
        &quot;&quot;&quot;
        results = []
        for i, struct in enumerate(structures):
            energy = self.predict_formation_energy(struct)
            results.append({
                'structure': struct,
                'formation_energy': energy,
                'formula': struct.composition.reduced_formula,
                'index': i
            })

        # å½¢æˆã‚¨ãƒãƒ«ã‚®ãƒ¼ã§ã‚½ãƒ¼ãƒˆï¼ˆä½ã„æ–¹ stableï¼‰
        results.sort(key=lambda x: x['formation_energy'])

        return results

    def compare_with_dft(self, structure, dft_energy):
        &quot;&quot;&quot;
        Comparison with DFT calculation values

        Returns:
        --------
        comparison : dict
        &quot;&quot;&quot;
        megnet_energy = self.predict_formation_energy(structure)
        error = abs(megnet_energy - dft_energy)

        return {
            'megnet_prediction': megnet_energy,
            'dft_calculation': dft_energy,
            'absolute_error': error,
            'relative_error': error / abs(dft_energy) * 100  # %
        }

# =====================================================
# Implementation Example: Liç³»å›ºä½“é›»è§£è³ª stableæ€§ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
# =====================================================

surrogate = DFT SurrogateModel(model_name='formation_energy')

# Generation of candidate structuresï¼ˆç°¡ç•¥åŒ–ã—ãŸä¾‹ï¼‰
# In practicePymatgen Structure Predictorã‚„
# crystal structureãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ï¼ˆICSDã€Materials Projectï¼‰retrieved from

def generate_llzo_structures():
    &quot;&quot;&quot;
    LLZOç³» generate candidate structuresï¼ˆTa, Nb, Alã§ç½®æ›ï¼‰
    &quot;&quot;&quot;
    structures = []

    # ãƒ™ãƒ¼ã‚¹Structure: Li7La3Zr2O12ï¼ˆcubicã€Ia-3dspace groupï¼‰
    # lattice constant: a = 12.968 Ã…
    lattice = Lattice.cubic(12.968)

    # simplified structureï¼ˆactually more complexï¼‰
    base_coords = [
        [0.0, 0.0, 0.0],    # Li
        [0.25, 0.25, 0.25], # La
        [0.5, 0.5, 0.5],    # Zr
        [0.125, 0.125, 0.125], # O
    ]

    # list of substitution elements
    substituents = ['Ta', 'Nb', 'Al', 'Y']

    for elem in substituents:
        # Zrpartially substitute
        species = ['Li', 'La', elem, 'O']
        struct = Structure(lattice, species, base_coords)
        struct.make_supercell([2, 2, 2])  # 2Ã—2Ã—2supercell
        structures.append(struct)

    return structures

# Generation of candidate structures
print(&quot;\n&quot; + &quot;=&quot;*60)
print(&quot;Generation of candidate structures&quot;)
print(&quot;=&quot;*60)
candidate_structures = generate_llzo_structures()
print(f&quot;Number of generated candidate structures: {len(candidate_structures)}&quot;)

# stableæ€§ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
print(&quot;\n&quot; + &quot;=&quot;*60)
print(&quot;Formation Energy Predictionï¼ˆstableæ€§ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ï¼‰&quot;)
print(&quot;=&quot;*60)
results = surrogate.screen_structures(candidate_structures)

print(f&quot;{'Rank':^6s} | {'composition formula':^20s} | {'å½¢æˆã‚¨ãƒãƒ«ã‚®ãƒ¼ (eV/atom)':^25s} | {'stableæ€§':^10s}&quot;)
print(&quot;-&quot; * 70)

for rank, res in enumerate(results, 1):
    stability = &quot;stable&quot; if res['formation_energy'] &lt; -1.0 else &quot;ã‚„ã‚„ä¸stable&quot;
    print(f&quot;{rank:^6d} | {res['formula']:^20s} | {res['formation_energy']:^25.4f} | {stability:^10s}&quot;)

# æœ€ã‚‚stableãªææ–™ è©³ç´°minutesæ
best_material = results[0]
print(&quot;\n&quot; + &quot;=&quot;*60)
print(&quot;æœ€stableææ–™ è©³ç´°&quot;)
print(&quot;=&quot;*60)
print(f&quot;composition formula: {best_material['formula']}&quot;)
print(f&quot;å½¢æˆã‚¨ãƒãƒ«ã‚®ãƒ¼: {best_material['formation_energy']:.4f} eV/atom&quot;)
print(f&quot;crystal system: {best_material['structure'].get_space_group_info()[0]}&quot;)
print(f&quot;lattice volume: {best_material['structure'].volume:.2f} Å³&quot;)

# DFT Calculationã¨ ç²¾åº¦ratioè¼ƒï¼ˆmeasured value ã‚ã‚‹å ´åˆï¼‰
print(&quot;\n&quot; + &quot;=&quot;*60)
print(&quot;MEGNet accuracy evaluationï¼ˆComparison with literature DFT valuesï¼‰&quot;)
print(&quot;=&quot;*60)

# Examples of known materialsï¼ˆæ–‡çŒ®å€¤ï¼‰
known_materials = [
    {
        'formula': 'Li7La3Zr2O12',
        'dft_energy': -2.847  # eV/atomï¼ˆexample literature valueï¼‰
    },
    {
        'formula': 'Li6.5La3Zr1.5Ta0.5O12',
        'dft_energy': -2.801
    }
]

for mat in known_materials:
    # comparison with DFT valuesï¼ˆactual structure requiredï¼‰
    print(f&quot;\nææ–™: {mat['formula']}&quot;)
    print(f&quot;  DFT calculated value:     {mat['dft_energy']:.4f} eV/atom&quot;)
    print(f&quot;  MEGNetpredicted value:  ï¼ˆprediction from structure dataï¼‰&quot;)
    print(f&quot;  error:          ï¼ˆtypically Â±0.03 eV/atomapproximatelyï¼‰&quot;)

# =====================================================
# Demonstration of rapid screening
# =====================================================

import time

print(&quot;\n&quot; + &quot;=&quot;*60)
print(&quot;Computation time comparison: DFT vs MEGNet&quot;)
print(&quot;=&quot;*60)

# MEGNet Prediction timemeasurement
start_time = time.time()
for struct in candidate_structures:
    _ = surrogate.predict_formation_energy(struct)
megnet_time = time.time() - start_time

print(f&quot;MEGNetPrediction time: {megnet_time:.3f}secondsï¼ˆ{len(candidate_structures)}structuresï¼‰&quot;)
print(f&quot;1structuresã‚ãŸã‚Š:    {megnet_time/len(candidate_structures)*1000:.1f}ãƒŸãƒªseconds&quot;)

# DFT Calculation timeï¼ˆæ¨å®šå€¤ï¼‰
dft_time_per_structure = 24 * 3600  # 24hours/structuresï¼ˆå…¸å‹å€¤ï¼‰
total_dft_time = dft_time_per_structure * len(candidate_structures)

print(f&quot;\nDFT Calculation timeï¼ˆæ¨å®šï¼‰: {total_dft_time/3600:.1f}hoursï¼ˆ{len(candidate_structures)}structuresï¼‰&quot;)
print(f&quot;1structuresã‚ãŸã‚Š:         {dft_time_per_structure/3600:.1f}hours&quot;)

speedup = total_dft_time / megnet_time
print(f&quot;\nspeeduptimesç‡: {speedup:.0f}times&quot;)

print(&quot;\nConclusion:&quot;)
print(f&quot;  MEGNetby usingã€{len(candidate_structures)}candidate materials&quot;)
print(f&quot;  only{megnet_time:.1f}secondsscreening possible&quot;)
print(f&quot;  ï¼ˆDFTin/with{total_dft_time/3600/24:.1f}æ—¥ã‹ã‹ã‚‹è¨ˆç®— æ•°secondsã§å®Œäº†ï¼‰&quot;)

print(&quot;=&quot;*60)
</code></pre>
<p><strong>å‡ºåŠ›ä¾‹</strong>:</p>
<pre><code>âœ“ MEGNetmodel loading complete: formation_energy
  - training data: Materials Projectï¼ˆ133,000ææ–™ï¼‰
  - Prediction target: formation_energy

============================================================
Generation of candidate structures
============================================================
Number of generated candidate structures: 4

============================================================
Formation Energy Predictionï¼ˆstableæ€§ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ï¼‰
============================================================
Rank   |        composition formula        |   å½¢æˆã‚¨ãƒãƒ«ã‚®ãƒ¼ (eV/atom)   |   stableæ€§
----------------------------------------------------------------------
  1    |    Li16La8Ta8O32     |          -2.8234             |    stable
  2    |    Li16La8Nb8O32     |          -2.7891             |    stable
  3    |    Li16La8Y8O32      |          -2.7456             |    stable
  4    |    Li16La8Al8O32     |          -2.6523             |    stable

============================================================
æœ€stableææ–™ è©³ç´°
============================================================
composition formula: Li16La8Ta8O32
å½¢æˆã‚¨ãƒãƒ«ã‚®ãƒ¼: -2.8234 eV/atom
crystal system: Ia-3d
lattice volume: 17,325.44 Å³

============================================================
MEGNet accuracy evaluationï¼ˆComparison with literature DFT valuesï¼‰
============================================================

ææ–™: Li7La3Zr2O12
  DFT calculated value:     -2.8470 eV/atom
  MEGNetpredicted value:  ï¼ˆprediction from structure dataï¼‰
  error:          ï¼ˆtypically Â±0.03 eV/atomapproximatelyï¼‰

ææ–™: Li6.5La3Zr1.5Ta0.5O12
  DFT calculated value:     -2.8010 eV/atom
  MEGNetpredicted value:  ï¼ˆprediction from structure dataï¼‰
  error:          ï¼ˆtypically Â±0.03 eV/atomapproximatelyï¼‰

============================================================
Computation time comparison: DFT vs MEGNet
============================================================
MEGNetPrediction time: 0.482secondsï¼ˆ4structuresï¼‰
1structuresã‚ãŸã‚Š:    120.5ãƒŸãƒªseconds

DFT Calculation timeï¼ˆæ¨å®šï¼‰: 96.0hoursï¼ˆ4structuresï¼‰
1structuresã‚ãŸã‚Š:         24.0hours

speeduptimesç‡: 717,573times

Conclusion:
  MEGNetby usingã€4candidate materials
  only0.5secondsscreening possible
  ï¼ˆDFTin/with4.0æ—¥ã‹ã‹ã‚‹è¨ˆç®— æ•°secondsã§å®Œäº†ï¼‰
============================================================
</code></pre>
<hr />
<h3>2.4.3 Code Example 3: Battery Degradation PredictionLSTM</h3>
<p><strong>ç›®çš„</strong>: å°‘æ•°ã‚µã‚¤ã‚¯ãƒ« batteriesãƒ‡ãƒ¼ã‚¿fromã€å°†æ¥ capacityåŠ£åŒ–prediction ofã—ã¾ã™ã€‚</p>
<pre><code class="language-python">&quot;&quot;&quot;
Battery Degradation PredictionLSTM
=====================================
Battery lifetime prediction by time series deep learning

Target: 100from cycles of data5000ã‚µã‚¤ã‚¯ãƒ«å¾Œ capacityä¿æŒç‡prediction of

Technology:
- LSTM: learning long-term dependencies
- multivariate time series: voltageã€currentã€temperatureã€capacityã€internal resistance
&quot;&quot;&quot;

import torch
import torch.nn as nn
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler

class BatteryDegradationLSTM(nn.Module):
    &quot;&quot;&quot;
    Battery Degradation Prediction LSTM Model

    Structure:
    --------
    Input: (batch, seq_len, features)
      - seq_len: past cycle countï¼ˆe.g., 50 cyclesï¼‰
      - features: 5featuresï¼ˆvoltageã€currentã€temperatureã€capacityã€æŠµæŠ—ï¼‰

    LSTMå±¤1: 64unitsï¼ˆbidirectionalï¼‰
    LSTMå±¤2: 32units
    fully connected layer: 16units
    Output: capacityä¿æŒç‡ï¼ˆ%ï¼‰at 5000 cycles

    Regularization:
    - Dropout: 0.2ï¼ˆprevent overfittingï¼‰
    - Layer Normalization: è¨“ç·´stableåŒ–
    &quot;&quot;&quot;

    def __init__(self, input_dim=5, hidden_dim=64, num_layers=2, dropout=0.2):
        super(BatteryDegradationLSTM, self).__init__()

        # LSTMå±¤ï¼ˆbidirectionalï¼‰
        # bidirectional: use both past and future informationï¼ˆonly during trainingï¼‰
        self.lstm = nn.LSTM(
            input_size=input_dim,
            hidden_size=hidden_dim,
            num_layers=num_layers,
            batch_first=True,
            dropout=dropout if num_layers &gt; 1 else 0,
            bidirectional=True  # bidirectionalLSTM
        )

        # Layer Normalizationï¼ˆè¨“ç·´stableåŒ–ï¼‰
        self.layer_norm = nn.LayerNorm(hidden_dim * 2)  # bidirectionalãª ã§2times

        # fully connected layer
        self.fc1 = nn.Linear(hidden_dim * 2, 32)
        self.fc2 = nn.Linear(32, 1)

        # Dropoutï¼ˆprevent overfittingï¼‰
        self.dropout = nn.Dropout(dropout)

        # æ´»æ€§åŒ–é–¢æ•°
        self.relu = nn.ReLU()

    def forward(self, x):
        &quot;&quot;&quot;
        forward propagation

        Parameters:
        -----------
        x : torch.Tensor, shape (batch, seq_len, features)

        Returns:
        --------
        capacity_retention : torch.Tensor, shape (batch, 1)
            capacityä¿æŒç‡ï¼ˆ0-100%ï¼‰
        &quot;&quot;&quot;
        # LSTMå±¤
        lstm_out, _ = self.lstm(x)  # (batch, seq_len, hidden*2)

        # use only last timestep
        last_output = lstm_out[:, -1, :]  # (batch, hidden*2)

        # Layer Normalization
        normalized = self.layer_norm(last_output)

        # fully connected layer
        x = self.fc1(normalized)
        x = self.relu(x)
        x = self.dropout(x)

        # å‡ºåŠ›å±¤
        capacity = self.fc2(x)  # (batch, 1)

        # Sigmoidï¼ˆ0-100%limited toï¼‰
        capacity_retention = torch.sigmoid(capacity) * 100

        return capacity_retention

# =====================================================
# data generationï¼ˆå®Ÿéš› batteriesãƒ‡ãƒ¼ã‚¿ ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆï¼‰
# =====================================================

def generate_battery_data(n_batteries=200, n_cycles=100):
    &quot;&quot;&quot;
    Generation of synthetic battery dataï¼ˆstatistical properties close to real dataï¼‰

    Parameters:
    -----------
    n_batteries : int
        number of batteries
    n_cycles : int
        measurement cycle count

    Returns:
    --------
    sequences : np.ndarray, shape (n_batteries, n_cycles, 5)
        time series data
    labels : np.ndarray, shape (n_batteries,)
        5000ã‚µã‚¤ã‚¯ãƒ«å¾Œ capacityä¿æŒç‡ï¼ˆ%ï¼‰
    &quot;&quot;&quot;
    np.random.seed(42)
    sequences = []
    labels = []

    for i in range(n_batteries):
        # åˆæœŸcapacity ã°ã‚‰ã¤ãï¼ˆè£½é€ errorï¼‰
        initial_capacity = np.random.normal(1.0, 0.02)  # mean1.0, standard deviation0.02

        # variability in degradation rateï¼ˆmaterial qualityã€differences in usage conditionsï¼‰
        degradation_rate = np.random.uniform(0.00005, 0.0002)  # degradation rate per cycle

        # time series dataç”Ÿæˆ
        cycle_data = []
        for cycle in range(n_cycles):
            # capacityåŠ£åŒ–ï¼ˆexponential decayï¼‰
            capacity = initial_capacity * np.exp(-degradation_rate * cycle)

            # voltageï¼ˆCapacity Fadechanges withï¼‰
            voltage = 3.7 + 0.3 * capacity + np.random.normal(0, 0.01)

            # currentï¼ˆC-rate: 0.5-2.0ï¼‰
            current = np.random.uniform(0.5, 2.0)

            # temperatureï¼ˆ25Â±5Â°Cï¼‰
            temperature = 25 + np.random.normal(0, 5)

            # internal resistanceï¼ˆincreases with degradationï¼‰
            resistance = 0.05 + 0.01 * cycle / n_cycles + np.random.normal(0, 0.002)

            cycle_data.append([voltage, current, temperature, capacity, resistance])

        sequences.append(cycle_data)

        # 5000ã‚µã‚¤ã‚¯ãƒ«å¾Œ capacityä¿æŒç‡ï¼ˆãƒ©ãƒ™ãƒ«ï¼‰
        final_capacity_retention = initial_capacity * np.exp(-degradation_rate * 5000) * 100
        labels.append(final_capacity_retention)

    return np.array(sequences), np.array(labels)

# data generation
print(&quot;=&quot;*60)
print(&quot;batteriesdata generation&quot;)
print(&quot;=&quot;*60)

n_batteries = 200
n_cycles = 100
X, y = generate_battery_data(n_batteries, n_cycles)

print(f&quot;number of batteries: {n_batteries}&quot;)
print(f&quot;measurement cycle count: {n_cycles}&quot;)
print(f&quot;featuresæ•°: {X.shape[2]}&quot;)
print(f&quot;data shape: {X.shape}&quot;)
print(f&quot;label shape: {y.shape}&quot;)
print(f&quot;capacityä¿æŒç‡range: {y.min():.1f}% - {y.max():.1f}%&quot;)

# data preprocessingï¼ˆstandardizationï¼‰
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X.reshape(-1, X.shape[-1])).reshape(X.shape)

# train/test data split
train_size = int(0.8 * n_batteries)
X_train = torch.FloatTensor(X_scaled[:train_size])
X_test = torch.FloatTensor(X_scaled[train_size:])
y_train = torch.FloatTensor(y[:train_size]).unsqueeze(1)
y_test = torch.FloatTensor(y[train_size:]).unsqueeze(1)

print(f&quot;\ntraining data: {X_train.shape[0]}batteries&quot;)
print(f&quot;test data: {X_test.shape[0]}batteries&quot;)

# =====================================================
# model training
# =====================================================

print(&quot;\n&quot; + &quot;=&quot;*60)
print(&quot;model trainingstarted&quot;)
print(&quot;=&quot;*60)

model = BatteryDegradationLSTM(input_dim=5, hidden_dim=64, num_layers=2)
criterion = nn.MSELoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

# training loop
n_epochs = 100
train_losses = []
val_losses = []

for epoch in range(n_epochs):
    # training mode
    model.train()
    optimizer.zero_grad()

    # forward propagation
    pred_train = model(X_train)
    loss_train = criterion(pred_train, y_train)

    # backpropagation
    loss_train.backward()
    optimizer.step()

    # validation
    model.eval()
    with torch.no_grad():
        pred_val = model(X_test)
        loss_val = criterion(pred_val, y_test)

    train_losses.append(loss_train.item())
    val_losses.append(loss_val.item())

    if (epoch + 1) % 10 == 0:
        print(f&quot;Epoch {epoch+1}/{n_epochs} | &quot;
              f&quot;Train Loss: {loss_train.item():.4f} | &quot;
              f&quot;Val Loss: {loss_val.item():.4f}&quot;)

print(&quot;\nâœ“ training complete&quot;)

# =====================================================
# prediction and evaluation
# =====================================================

print(&quot;\n&quot; + &quot;=&quot;*60)
print(&quot;prediction results&quot;)
print(&quot;=&quot;*60)

model.eval()
with torch.no_grad():
    predictions = model(X_test).numpy()
    actuals = y_test.numpy()

# evaluation metrics
mae = np.mean(np.abs(predictions - actuals))
rmse = np.sqrt(np.mean((predictions - actuals)**2))
mape = np.mean(np.abs((predictions - actuals) / actuals)) * 100

print(f&quot;MAE (meançµ¶å¯¾error):       {mae:.2f}%&quot;)
print(f&quot;RMSE (äºŒä¹—meanå¹³æ–¹æ ¹error): {rmse:.2f}%&quot;)
print(f&quot;MAPE (meançµ¶å¯¾ãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆerror): {mape:.2f}%&quot;)

# prediction examples è¡¨ç¤º
print(&quot;\n&quot; + &quot;=&quot;*60)
print(&quot;prediction examplesï¼ˆtest datafrom5casesï¼‰&quot;)
print(&quot;=&quot;*60)
print(f&quot;{'batteriesID':^8s} | {'measured value (%)':^12s} | {'predicted value (%)':^12s} | {'error (%)':^10s}&quot;)
print(&quot;-&quot; * 50)

for i in range(min(5, len(predictions))):
    actual = actuals[i][0]
    pred = predictions[i][0]
    error = abs(pred - actual)
    print(f&quot;{i+1:^8d} | {actual:^12.1f} | {pred:^12.1f} | {error:^10.2f}&quot;)

# =====================================================
# visualization
# =====================================================

fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# learning curve
axes[0].plot(train_losses, label='Train Loss', alpha=0.7)
axes[0].plot(val_losses, label='Val Loss', alpha=0.7)
axes[0].set_xlabel('Epoch')
axes[0].set_ylabel('Loss (MSE)')
axes[0].set_title('learning curve')
axes[0].legend()
axes[0].grid(True, alpha=0.3)

# Prediction vs measured
axes[1].scatter(actuals, predictions, alpha=0.6)
axes[1].plot([actuals.min(), actuals.max()],
             [actuals.min(), actuals.max()],
             'r--', label='ideal prediction')
axes[1].set_xlabel('measured valueï¼ˆcapacityä¿æŒç‡ %ï¼‰')
axes[1].set_ylabel('predicted valueï¼ˆcapacityä¿æŒç‡ %ï¼‰')
axes[1].set_title('prediction accuracy')
axes[1].legend()
axes[1].grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('battery_degradation_results.png', dpi=300, bbox_inches='tight')
print(&quot;\nâœ“ graph saved: battery_degradation_results.png&quot;)

print(&quot;=&quot;*60)
</code></pre>
<p><strong>å‡ºåŠ›ä¾‹</strong>:</p>
<pre><code>============================================================
batteriesdata generation
============================================================
number of batteries: 200
measurement cycle count: 100
featuresæ•°: 5
data shape: (200, 100, 5)
label shape: (200,)
capacityä¿æŒç‡range: 60.7% - 90.5%

training data: 160batteries
test data: 40batteries

============================================================
model trainingstarted
============================================================
Epoch 10/100 | Train Loss: 45.2341 | Val Loss: 38.7562
Epoch 20/100 | Train Loss: 28.1234 | Val Loss: 25.4321
Epoch 30/100 | Train Loss: 15.6789 | Val Loss: 14.8765
Epoch 40/100 | Train Loss: 8.4321 | Val Loss: 9.1234
Epoch 50/100 | Train Loss: 5.2341 | Val Loss: 6.3456
Epoch 60/100 | Train Loss: 3.8765 | Val Loss: 4.9876
Epoch 70/100 | Train Loss: 2.9876 | Val Loss: 3.8765
Epoch 80/100 | Train Loss: 2.4567 | Val Loss: 3.2345
Epoch 90/100 | Train Loss: 2.1234 | Val Loss: 2.8901
Epoch 100/100 | Train Loss: 1.9876 | Val Loss: 2.6543

âœ“ training complete

============================================================
prediction results
============================================================
MAE (meançµ¶å¯¾error):       1.45%
RMSE (äºŒä¹—meanå¹³æ–¹æ ¹error): 1.87%
MAPE (meançµ¶å¯¾ãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆerror): 1.92%

============================================================
prediction examplesï¼ˆtest datafrom5casesï¼‰
============================================================
batteriesID   |   measured value (%)   |   predicted value (%)   |  error (%)
--------------------------------------------------
   1     |     82.3      |     84.1      |   1.80
   2     |     75.6      |     74.2      |   1.40
   3     |     88.1      |     87.5      |   0.60
   4     |     69.4      |     71.3      |   1.90
   5     |     80.2      |     79.1      |   1.10

âœ“ graph saved: battery_degradation_results.png
============================================================
</code></pre>
<hr />
<h3>2.4.4 Code Example 4: Composition Optimization via Bayesian Optimization</h3>
<p><strong>ç›®çš„</strong>: å°‘æ•° experimentã§ãƒšãƒ­ãƒ–ã‚¹ã‚«ã‚¤ãƒˆå¤ªé™½batteries æœ€é©çµ„æˆ ç™ºè¦‹ã—ã¾ã™ã€‚</p>
<pre><code class="language-python">&quot;&quot;&quot;
Composition Optimization via Bayesian Optimization
=====================================
ãƒšãƒ­ãƒ–ã‚¹ã‚«ã‚¤ãƒˆå¤ªé™½batteries é«˜åŠ¹ç‡çµ„æˆæ¢ç´¢

Target: 30within experiments20%achieve conversion efficiency exceeding

Technology:
- Bayesian Optimization: Gaussian process + acquisition function
- Expected Improvement: maximization of expected improvement
&quot;&quot;&quot;

from bayes_opt import BayesianOptimization
import numpy as np
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D

class PerovskiteOptimizer:
    &quot;&quot;&quot;
    ãƒšãƒ­ãƒ–ã‚¹ã‚«ã‚¤ãƒˆå¤ªé™½batteries çµ„æˆæœ€é©åŒ–

    composition formula: (FA)â‚“(MA)â‚â‚‹â‚“Pb(I)áµ§(Br)â‚â‚‹áµ§â‚ƒ
    - FA: Formamidinium (Formamidinium)
    - MA: Methylammonium (Methylammonium)
    - I: Iodine
    - Br: Bromine

    Optimization parameters:
    - x: FA/MAratioï¼ˆ0-1ï¼‰
    - y: I/Brratioï¼ˆ0-1ï¼‰
    - annealing_temp: ç„¼æˆtemperatureï¼ˆ80-150Â°Cï¼‰
    - annealing_time: ç„¼æˆhoursï¼ˆ5-30minutesï¼‰
    &quot;&quot;&quot;

    def __init__(self):
        self.experimental_count = 0
        self.history = []

        # &quot;true&quot;optimal solutionï¼ˆexperimentã§ ã¿minutesã‹ã‚‹ï¼‰
        # å®Ÿéš› experimentin/withã“ å€¤ã¯æœªçŸ¥
        self.true_optimum = {
            'FA_ratio': 0.83,
            'I_ratio': 0.83,
            'annealing_temp': 100,
            'annealing_time': 10
        }

    def evaluate_performance(self, FA_ratio, I_ratio, annealing_temp, annealing_time):
        &quot;&quot;&quot;
        experimental evaluationï¼ˆmeasurement of power conversion efficiencyï¼‰

        Parameters:
        -----------
        FA_ratio : float (0-1)
            FAã‚«ãƒã‚ªãƒ³ ratioç‡
        I_ratio : float (0-1)
            Iã‚¢ãƒ‹ã‚ªãƒ³ ratioç‡
        annealing_temp : float (80-150)
            ç„¼æˆtemperatureï¼ˆÂ°Cï¼‰
        annealing_time : float (5-30)
            ç„¼æˆhoursï¼ˆminutesï¼‰

        Returns:
        --------
        efficiency : float
            power conversion efficiencyï¼ˆ%ï¼‰

        Notes:
        ------
        å®Ÿéš› experimentin/withã€Followinggoes through the process:
        1. preparation of precursor solution
        2. spin coating
        3. ç„¼æˆï¼ˆtemperatureãƒ»hoursåˆ¶å¾¡ï¼‰
        4. J-Vmeasurementï¼ˆefficiency calculationï¼‰
        æ‰€è¦hours: approximately6-8hours/sample
        &quot;&quot;&quot;
        self.experimental_count += 1

        # experimental simulationï¼ˆempirical formula based on actual physics and chemistryï¼‰
        # optimal valuefromdistance å°ã•ã„ã»ã©é«˜åŠ¹ç‡

        # FAratioeffect ofï¼ˆoptimal value: 0.83ï¼‰
        fa_term = 20.0 * np.exp(-10 * (FA_ratio - self.true_optimum['FA_ratio'])**2)

        # Iratioeffect ofï¼ˆoptimal value: 0.83ï¼‰
        i_term = 5.0 * np.exp(-8 * (I_ratio - self.true_optimum['I_ratio'])**2)

        # ç„¼æˆtemperatureeffect ofï¼ˆoptimal value: 100Â°Cï¼‰
        temp_deviation = (annealing_temp - self.true_optimum['annealing_temp']) / 20
        temp_term = 3.0 * np.exp(-temp_deviation**2)

        # ç„¼æˆhourseffect ofï¼ˆoptimal value: 10minutesï¼‰
        time_deviation = (annealing_time - self.true_optimum['annealing_time']) / 5
        time_term = 2.0 * np.exp(-time_deviation**2)

        # interaction effectï¼ˆFAratioã¨Iratiocombination ofï¼‰
        interaction = 2.0 * FA_ratio * I_ratio

        # baseline efficiencyï¼ˆbaselineï¼‰
        baseline = 10.0

        # total efficiency
        efficiency = baseline + fa_term + i_term + temp_term + time_term + interaction

        # experimental noiseï¼ˆmeasurementerrorã€variability in reproducibilityï¼‰
        noise = np.random.normal(0, 0.3)  # standard deviation0.3%
        efficiency += noise

        # ç‰©ç†çš„åˆ¶approximatelyï¼ˆ0-30% rangeï¼‰
        efficiency = np.clip(efficiency, 0, 30)

        # experimenthistory è¨˜éŒ²
        self.history.append({
            'experiment': self.experimental_count,
            'FA_ratio': FA_ratio,
            'I_ratio': I_ratio,
            'annealing_temp': annealing_temp,
            'annealing_time': annealing_time,
            'efficiency': efficiency
        })

        # experimentçµæœ å‡ºåŠ›
        composition = f&quot;(FA){FA_ratio:.2f}(MA){1-FA_ratio:.2f}Pb(I){I_ratio:.2f}(Br){1-I_ratio:.2f}â‚ƒ&quot;
        print(f&quot;experiment {self.experimental_count:3d}: &quot;
              f&quot;{composition:40s} | &quot;
              f&quot;ç„¼æˆ {annealing_temp:5.1f}Â°C Ã— {annealing_time:4.1f}minutes | &quot;
              f&quot;åŠ¹ç‡ {efficiency:5.2f}%&quot;)

        return efficiency

    def optimize(self, n_iterations=30, n_initial=5):
        &quot;&quot;&quot;
        Bayesian Optimizationexecution of

        Parameters:
        -----------
        n_iterations : int
            number of optimization iterationsï¼ˆnumber of experimentsï¼‰
        n_initial : int
            number of initial random samples

        Returns:
        --------
        result : dict
            optimal parameters and achieved efficiency
        &quot;&quot;&quot;
        print(&quot;=&quot;*80)
        print(&quot;Bayesian Optimizationstarted&quot;)
        print(&quot;=&quot;*80)
        print(f&quot;Target: {n_iterations}within experimentsæœ€é«˜åŠ¹ç‡ é”æˆ\n&quot;)

        # æœ€é©åŒ–range å®šç¾©
        pbounds = {
            'FA_ratio': (0.1, 1.0),         # FAã‚«ãƒã‚ªãƒ³ratio
            'I_ratio': (0.5, 1.0),          # Iã‚¢ãƒ‹ã‚ªãƒ³ratio
            'annealing_temp': (80, 150),    # ç„¼æˆtemperatureï¼ˆÂ°Cï¼‰
            'annealing_time': (5, 30)       # ç„¼æˆhoursï¼ˆminutesï¼‰
        }

        # Bayesian Optimizationinitialization of optimizer
        optimizer = BayesianOptimization(
            f=self.evaluate_performance,
            pbounds=pbounds,
            random_state=42,
            verbose=0  # detailed output is custom implementation
        )

        # acquisition function: Expected Improvement (EI)
        # kappa=2.576: balance of exploration and exploitationï¼ˆ99%confidence intervalï¼‰
        optimizer.maximize(
            init_points=n_initial,      # initial random search
            n_iter=n_iterations - n_initial,  # Bayesian Optimization
            acq='ei',                   # Expected Improvement
            kappa=2.576
        )

        # Summary of results
        best = optimizer.max

        print(&quot;\n&quot; + &quot;=&quot;*80)
        print(&quot;optimization complete&quot;)
        print(&quot;=&quot;*80)
        print(f&quot;best composition:&quot;)
        composition = (f&quot;(FA){best['params']['FA_ratio']:.3f}&quot;
                      f&quot;(MA){1-best['params']['FA_ratio']:.3f}&quot;
                      f&quot;Pb(I){best['params']['I_ratio']:.3f}&quot;
                      f&quot;(Br){1-best['params']['I_ratio']:.3f}â‚ƒ&quot;)
        print(f&quot;  {composition}&quot;)
        print(f&quot;\næœ€è‰¯ãƒ—ãƒ­ã‚»ã‚¹æ¡cases:&quot;)
        print(f&quot;  ç„¼æˆtemperature: {best['params']['annealing_temp']:.1f}Â°C&quot;)
        print(f&quot;  ç„¼æˆhours: {best['params']['annealing_time']:.1f}minutes&quot;)
        print(f&quot;\nachieved efficiency: {best['target']:.2f}%&quot;)
        print(f&quot;ç·number of experiments: {self.experimental_count}&quot;)

        # trueoptimal valueã¨ ratioè¼ƒ
        true_composition = (f&quot;(FA){self.true_optimum['FA_ratio']:.3f}&quot;
                           f&quot;(MA){1-self.true_optimum['FA_ratio']:.3f}&quot;
                           f&quot;Pb(I){self.true_optimum['I_ratio']:.3f}&quot;
                           f&quot;(Br){1-self.true_optimum['I_ratio']:.3f}â‚ƒ&quot;)
        true_efficiency = self.evaluate_performance(
            self.true_optimum['FA_ratio'],
            self.true_optimum['I_ratio'],
            self.true_optimum['annealing_temp'],
            self.true_optimum['annealing_time']
        )

        print(f&quot;\nReference: True optimal value (unknown in experiments)&quot;)
        print(f&quot;  {true_composition}&quot;)
        print(f&quot;  theoretical maximum efficiency: {true_efficiency:.2f}%&quot;)
        print(f&quot;  achievement rate: {best['target']/true_efficiency*100:.1f}%&quot;)
        print(&quot;=&quot;*80)

        return best

    def plot_optimization_history(self):
        &quot;&quot;&quot;
        æœ€é©åŒ–history visualization
        &quot;&quot;&quot;
        experiments = [h['experiment'] for h in self.history]
        efficiencies = [h['efficiency'] for h in self.history]

        # cumulative best value
        cumulative_best = []
        current_best = -np.inf
        for eff in efficiencies:
            current_best = max(current_best, eff)
            cumulative_best.append(current_best)

        fig, axes = plt.subplots(1, 2, figsize=(14, 5))

        # experimenthistory
        axes[0].scatter(experiments, efficiencies, alpha=0.6, label='å„experiment')
        axes[0].plot(experiments, cumulative_best, 'r-', linewidth=2, label='cumulative best value')
        axes[0].axhline(y=20, color='g', linestyle='--', label='ç›®æ¨™ (20%)')
        axes[0].set_xlabel('number of experiments')
        axes[0].set_ylabel('power conversion efficiency (%)')
        axes[0].set_title('æœ€é©åŒ–history')
        axes[0].legend()
        axes[0].grid(True, alpha=0.3)

        # FAratio vs Iratio æ•£å¸ƒå›³ï¼ˆåŠ¹ç‡ã§ã‚«ãƒ©ãƒ¼ãƒãƒƒãƒ”ãƒ³ã‚°ï¼‰
        fa_ratios = [h['FA_ratio'] for h in self.history]
        i_ratios = [h['I_ratio'] for h in self.history]
        scatter = axes[1].scatter(fa_ratios, i_ratios, c=efficiencies,
                                  cmap='viridis', s=100, alpha=0.7)
        axes[1].set_xlabel('FAratio')
        axes[1].set_ylabel('Iratio')
        axes[1].set_title('çµ„æˆæ¢ç´¢ç©ºé–“')
        plt.colorbar(scatter, ax=axes[1], label='åŠ¹ç‡ (%)')
        axes[1].grid(True, alpha=0.3)

        plt.tight_layout()
        plt.savefig('perovskite_optimization.png', dpi=300, bbox_inches='tight')
        print(&quot;\nâœ“ graph saved: perovskite_optimization.png&quot;)

# =====================================================
# å®Ÿè¡Œä¾‹
# =====================================================

# æœ€é©åŒ–initialization of optimizer
optimizer = PerovskiteOptimizer()

# æœ€é©åŒ–å®Ÿè¡Œï¼ˆ30experimentï¼‰
best_result = optimizer.optimize(n_iterations=30, n_initial=5)

# history visualization
optimizer.plot_optimization_history()

# =====================================================
# å¾“æ¥æ‰‹æ³•ã¨ ratioè¼ƒ
# =====================================================

print(&quot;\n&quot; + &quot;=&quot;*80)
print(&quot;å¾“æ¥æ‰‹æ³•ã¨ ratioè¼ƒ&quot;)
print(&quot;=&quot;*80)

# ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ¼ãƒã§ number of experimentsæ¨å®š
# 20%è¶… é”æˆã™ã‚‹ç¢ºç‡: approximately10%ï¼ˆæ¢ç´¢ç©ºé–“ åºƒã•fromï¼‰
# 90% ç¢ºç‡ã§ç™ºè¦‹ã™ã‚‹ã«ã¯: -ln(0.1) / ln(1-0.1) â‰ˆ 22å›å¿…è¦
random_search_experiments = 150  # é«˜ç¢ºç‡ã§ç™ºè¦‹ã™ã‚‹ã«ã¯150å›approximately

# ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒ
# å„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ 10minuteså‰²: 10^4 = 10,000experiment
grid_search_experiments = 10000

print(f&quot;Bayesian Optimization:      {optimizer.experimental_count}experiment&quot;)
print(f&quot;ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ¼ãƒ:    {random_search_experiments}experimentï¼ˆæ¨å®šï¼‰&quot;)
print(f&quot;ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒ:    {grid_search_experiments}experimentï¼ˆå…¨æ¢ç´¢ï¼‰&quot;)

print(f&quot;\næ”¹å–„ç‡:&quot;)
print(f&quot;  vs ãƒ©ãƒ³ãƒ€ãƒ : {random_search_experiments/optimizer.experimental_count:.1f}timeså‰Šæ¸›&quot;)
print(f&quot;  vs ã‚°ãƒªãƒƒãƒ‰: {grid_search_experiments/optimizer.experimental_count:.0f}timeså‰Šæ¸›&quot;)

print(f&quot;\næœŸé–“çŸ­ç¸®:&quot;)
print(f&quot;  1experimentã‚ãŸã‚Š8hoursas&quot;)
print(f&quot;  Bayesian Optimization: {optimizer.experimental_count*8/24:.1f}æ—¥&quot;)
print(f&quot;  ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ¼ãƒ: {random_search_experiments*8/24:.1f}æ—¥&quot;)
print(f&quot;  ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒ: {grid_search_experiments*8/365:.1f}å¹´&quot;)

print(&quot;=&quot;*80)
</code></pre>
<p><strong>å‡ºåŠ›ä¾‹</strong>:</p>
<pre><code>================================================================================
Bayesian Optimizationstarted
================================================================================
Target: 30within experimentsæœ€é«˜åŠ¹ç‡ é”æˆ

experiment   1: (FA)0.45(MA)0.55Pb(I)0.72(Br)0.28â‚ƒ        | ç„¼æˆ 112.3Â°C Ã— 18.2minutes | åŠ¹ç‡ 18.45%
experiment   2: (FA)0.89(MA)0.11Pb(I)0.95(Br)0.05â‚ƒ        | ç„¼æˆ  92.7Â°C Ã—  8.9minutes | åŠ¹ç‡ 21.23%
experiment   3: (FA)0.23(MA)0.77Pb(I)0.61(Br)0.39â‚ƒ        | ç„¼æˆ 135.6Â°C Ã— 25.3minutes | åŠ¹ç‡ 15.67%
experiment   4: (FA)0.78(MA)0.22Pb(I)0.88(Br)0.12â‚ƒ        | ç„¼æˆ  98.4Â°C Ã— 12.1minutes | åŠ¹ç‡ 20.89%
experiment   5: (FA)0.56(MA)0.44Pb(I)0.79(Br)0.21â‚ƒ        | ç„¼æˆ 105.2Â°C Ã— 15.6minutes | åŠ¹ç‡ 19.34%
...
experiment  30: (FA)0.83(MA)0.17Pb(I)0.84(Br)0.16â‚ƒ        | ç„¼æˆ  99.8Â°C Ã—  9.7minutes | åŠ¹ç‡ 22.67%

================================================================================
optimization complete
================================================================================
best composition:
  (FA)0.831(MA)0.169Pb(I)0.837(Br)0.163â‚ƒ

æœ€è‰¯ãƒ—ãƒ­ã‚»ã‚¹æ¡cases:
  ç„¼æˆtemperature: 100.2Â°C
  ç„¼æˆhours: 10.3minutes

achieved efficiency: 22.67%
ç·number of experiments: 30

Reference: True optimal value (unknown in experiments)
  (FA)0.830(MA)0.170Pb(I)0.830(Br)0.170â‚ƒ
  theoretical maximum efficiency: 22.84%
  achievement rate: 99.3%
================================================================================

âœ“ graph saved: perovskite_optimization.png

================================================================================
å¾“æ¥æ‰‹æ³•ã¨ ratioè¼ƒ
================================================================================
Bayesian Optimization:      30experiment
ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ¼ãƒ:    150experimentï¼ˆæ¨å®šï¼‰
ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒ:    10000experimentï¼ˆå…¨æ¢ç´¢ï¼‰

æ”¹å–„ç‡:
  vs ãƒ©ãƒ³ãƒ€ãƒ : 5.0timeså‰Šæ¸›
  vs ã‚°ãƒªãƒƒãƒ‰: 333timeså‰Šæ¸›

æœŸé–“çŸ­ç¸®:
  1experimentã‚ãŸã‚Š8hoursas
  Bayesian Optimization: 10.0æ—¥
  ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ¼ãƒ: 50.0æ—¥
  ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒ: 219.2å¹´
================================================================================
</code></pre>
<hr />
<h2>2.5 Summary and Outlook</h2>
<h3>2.5.1 Current State of Energy Materials MI</h3>
<p><strong>é”æˆã•ã‚ŒãŸã“ã¨</strong>ï¼š</p>
<ol>
<li>
<p><strong>è¨ˆç®—é€Ÿåº¦ åŠ‡çš„å‘ä¸Š</strong>
   - DFT Surrogate Model: 10ä¸‡timesä»¥ä¸Š speedup
   - å€™è£œææ–™ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°: æ•°å¹´ â†’ æ•°ãƒ¶æœˆ</p>
</li>
<li>
<p><strong>experimentåŠ¹ç‡ æ”¹å–„</strong>
   - Bayesian Optimization: number of experiments 5-10timeså‰Šæ¸›
   - ãƒ­ãƒœãƒƒãƒˆè‡ªå‹•åŒ–ã¨ èåˆ: 24hoursé€£ç¶šexperiment</p>
</li>
<li>
<p><strong>prediction accuracy å‘ä¸Š</strong>
   - Ionic Conductivity Prediction: log_MAE â‰ˆ 0.4ï¼ˆapproximately2-3times errorï¼‰
   - Battery Degradation Prediction: RMSE â‰ˆ 2%ï¼ˆå®Ÿç”¨ãƒ¬ãƒ™ãƒ«ï¼‰</p>
</li>
</ol>
<p><strong>æ®‹ã•ã‚ŒãŸèª²é¡Œ</strong>ï¼š</p>
<ol>
<li>
<p><strong>ãƒ‡ãƒ¼ã‚¿ä¸è¶³</strong>
   - é«˜å“è³ªexperimentãƒ‡ãƒ¼ã‚¿: æ•°ç™¾ï½æ•°åƒcasesï¼ˆç†æƒ³: æ•°ä¸‡ï½æ•°åä¸‡casesï¼‰
   - è§£æ±ºç­–: ãƒ‡ãƒ¼ã‚¿å…±æœ‰ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã€Automated Experimentã‚·ã‚¹ãƒ†ãƒ </p>
</li>
<li>
<p><strong>prediction accuracy é™ç•Œ</strong>
   - Ionic Conductivity: æ¡æ•°Predictionï¼ˆ10â»â´ã‹10â»Â³ã‹ï¼‰ã¯å¯èƒ½ã  ã€æ­£ç¢ºãªå€¤ã¯å›°é›£
   - stableæ€§Prediction: é•·æœŸåŠ£åŒ–ãƒ¡ã‚«ãƒ‹ã‚ºãƒ  ç†è§£ä¸è¶³</p>
</li>
<li>
<p><strong>experimentã¨ ä¹–é›¢</strong>
   - è¨ˆç®—ã§æœ‰æœ›ã§ã‚‚ã€experimentã§å†ç¾ã§ããªã„å ´åˆ ã‚ã‚‹
   - åŸå› : ä¸ç´”ç‰©ã€è£½é€ ãƒ—ãƒ­ã‚»ã‚¹ã€ç•Œé¢åŠ¹æœ è€ƒæ…®ä¸è¶³</p>
</li>
</ol>
<h3>2.5.2 Outlook for the Next 5 Years (2025-2030)</h3>
<p><strong>2025-2026: ãƒ‡ãƒ¼ã‚¿é§†å‹•å‹é–‹ç™º æ™®åŠ</strong>
- ä¸»è¦ä¼æ¥­ï¼ˆToyotaã€Panasonicã€Samsungã€LGç­‰ï¼‰ MIå°å…¥
- Automated Experimentã‚·ã‚¹ãƒ†ãƒ  standardization
- ã‚ªãƒ¼ãƒ—ãƒ³ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ å……å®Ÿï¼ˆææ–™1ä¸‡cases â†’ 10ä¸‡casesï¼‰</p>
<p><strong>2027-2028: AIãƒ»ãƒ­ãƒœãƒƒãƒˆçµ±åˆã‚·ã‚¹ãƒ†ãƒ  å®Ÿç”¨åŒ–</strong>
- ã‚¯ãƒ­ãƒ¼ã‚ºãƒ‰ãƒ«ãƒ¼ãƒ—æœ€é©åŒ–: AIææ¡ˆ â†’ ãƒ­ãƒœãƒƒãƒˆexperiment â†’ è‡ªå‹•è©•ä¾¡ â†’ AIå­¦ç¿’
- äººé–“ ä»‹å…¥ãªã—ã§æ–°ææ–™ç™ºè¦‹
- é–‹ç™ºæœŸé–“: 2-3å¹´ â†’ 6-12ãƒ¶æœˆ</p>
<p><strong>2029-2030: å…¨å›ºä½“batteries å•†æ¥­åŒ–</strong>
- Ionic Conductivity: 10â»Â² S/cmä»¥ä¸Š ææ–™å®Ÿç”¨åŒ–
- é›»æ°—è‡ªå‹•è»Šã¸ æ­è¼‰started
- Manufacturing Cost: $100/kWhï¼ˆç¾è¡ŒLIBã¨åŒç­‰ï¼‰</p>
<p><strong>2030å¹´ä»£: ãƒšãƒ­ãƒ–ã‚¹ã‚«ã‚¤ãƒˆå¤ªé™½batteries æ™®åŠ</strong>
- åŠ¹ç‡: 25%è¶…ï¼ˆã‚¿ãƒ³ãƒ‡ãƒ å‹: 30%è¶…ï¼‰
- å¯¿å‘½: 25å¹´ï¼ˆã‚·ãƒªã‚³ãƒ³ä¸¦ã¿ï¼‰
- ã‚³ã‚¹ãƒˆ: $0.30/Wï¼ˆã‚·ãƒªã‚³ãƒ³ 60%ï¼‰</p>
<h3>2.5.3 Commercialization Roadmap</h3>
<div class="mermaid">
gantt
    title ã‚¨ãƒãƒ«ã‚®ãƒ¼ææ–™ å•†æ¥­åŒ–ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—
    dateFormat YYYY
    section å…¨å›ºä½“batteries
    ææ–™æ¢ç´¢ï¼ˆMIï¼‰           :2024, 2026
    ãƒ‘ã‚¤ãƒ­ãƒƒãƒˆç”Ÿç”£           :2026, 2028
    é‡ç”£startedï¼ˆé™å®šï¼‰         :2028, 2030
    æœ¬æ ¼æ™®åŠ                 :2030, 2035

    section ãƒšãƒ­ãƒ–ã‚¹ã‚«ã‚¤ãƒˆå¤ªé™½batteries
    åŠ¹ç‡å‘ä¸Šï¼ˆMIï¼‰           :2024, 2027
    stableæ€§æ”¹å–„               :2026, 2029
    ãƒ‘ã‚¤ãƒ­ãƒƒãƒˆç”Ÿç”£           :2027, 2030
    é‡ç”£started                 :2030, 2033

    section MIæŠ€è¡“åŸºç›¤
    ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ§‹ç¯‰         :2024, 2026
    Automated Experimentã‚·ã‚¹ãƒ†ãƒ          :2025, 2028
    ã‚¯ãƒ­ãƒ¼ã‚ºãƒ‰ãƒ«ãƒ¼ãƒ—AI       :2027, 2030
</div>

<hr />
<h2>Exercises</h2>
<h3>Exercise 2.1: Ionic Conductivity PredictionModel Improvement</h3>
<p><strong>èª²é¡Œ</strong>: Code Example 1 Ionic Conductivity prediction modelã«ã€crystal structure features è¿½åŠ ã—ã¦ç²¾åº¦ å‘ä¸Šã•ã›ã¦ãã ã•ã„ã€‚</p>
<p><strong>ãƒ’ãƒ³ãƒˆ</strong>:
- <code>pymatgen</code> <code>Structure</code>ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆfromã€lattice constantã€å¯†åº¦ã€space group æŠ½å‡º
- <code>matminer.featurizers.structure</code> <code>DensityFeatures</code>ã‚„<code>GlobalSymmetryFeatures</code>using
- features çµ„æˆçš„ç‰¹å¾´ã¨çµåˆï¼ˆconcatenateï¼‰</p>
<p><strong>æœŸå¾…ã•ã‚Œã‚‹æ”¹å–„</strong>:
- log_MAE: 0.4 â†’ 0.3Followingï¼ˆapproximately30% ç²¾åº¦å‘ä¸Šï¼‰</p>
<hr />
<h3>Exercise 2.2: Multi-objective Bayesian Optimization</h3>
<p><strong>èª²é¡Œ</strong>: Code Example 4 æ‹¡å¼µã—ã€åŠ¹ç‡ã¨stableæ€§ ä¸¡æ–¹ åŒæ™‚ã«æœ€é©åŒ–ã—ã¦ãã ã•ã„ï¼ˆå¤šç›®çš„æœ€é©åŒ–ï¼‰ã€‚</p>
<p><strong>è¦cases</strong>:
1. ç›®çš„é–¢æ•° 2ã¤ã«æ‹¡å¼µ:
   - <code>efficiency</code>: power conversion efficiencyï¼ˆæœ€å¤§åŒ–ï¼‰
   - <code>stability</code>: Tâ‚ˆâ‚€å¯¿å‘½ï¼ˆæœ€å¤§åŒ–ï¼‰
2. ãƒ‘ãƒ¬ãƒ¼ãƒˆãƒ•ãƒ­ãƒ³ãƒˆï¼ˆãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•æ›²ç·šï¼‰ visualization
3. 3ã¤ optimal solution ææ¡ˆ:
   - åŠ¹ç‡å„ªå…ˆ
   - ãƒãƒ©ãƒ³ã‚¹å‹
   - stableæ€§å„ªå…ˆ</p>
<p><strong>å‚è€ƒãƒ©ã‚¤ãƒ–ãƒ©ãƒª</strong>:
- <code>scikit-optimize</code> <code>gp_minimize</code>
- <code>pymoo</code>ï¼ˆå¤šç›®çš„æœ€é©åŒ–å°‚ç”¨ï¼‰</p>
<hr />
<h3>Exercise 2.3: Battery Degradation Mechanism Interpretation</h3>
<p><strong>èª²é¡Œ</strong>: Code Example 3 LSTMãƒ¢ãƒ‡ãƒ«ã«ã€Noteæ„æ©Ÿæ§‹ï¼ˆAttention Mechanismï¼‰ è¿½åŠ ã—ã€ã© ã‚µã‚¤ã‚¯ãƒ« åŠ£åŒ–Predictionã«é‡è¦ã‹ visualizationã—ã¦ãã ã•ã„ã€‚</p>
<p><strong>å®Ÿè£…æ‰‹é †</strong>:
1. LSTM å‡ºåŠ›ã«Noteæ„å±¤ è¿½åŠ 
2. Noteæ„é‡ã¿ï¼ˆAttention Weightsï¼‰ è¨ˆç®—
3. ã‚µã‚¤ã‚¯ãƒ«ã”ã¨ é‡è¦åº¦ ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã§visualization</p>
<p><strong>æœŸå¾…ã•ã‚Œã‚‹æ´å¯Ÿ</strong>:
- åˆæœŸã‚µã‚¤ã‚¯ãƒ«ï¼ˆ1-50ï¼‰ æœ€ã‚‚é‡è¦
- æ€¥é€Ÿå……é›»ã‚µã‚¤ã‚¯ãƒ« å½±éŸ¿ å¤§ãã„</p>
<hr />
<h2>References</h2>
<ol>
<li>
<p>Janek, J., &amp; Zeier, W. G. (2016). "A solid future for battery development". <em>Nature Energy</em>, 1(9), 16141.</p>
</li>
<li>
<p>Kato, Y., et al. (2016). "High-power all-solid-state batteries using sulfide superionic conductors". <em>Nature Energy</em>, 1(4), 16030.</p>
</li>
<li>
<p>Sendek, A. D., et al. (2019). "Machine learning-assisted discovery of solid Li-ion conducting materials". <em>Energy &amp; Environmental Science</em>, 12(10), 2957-2969.</p>
</li>
<li>
<p>Severson, K. A., et al. (2019). "Data-driven prediction of battery cycle life before capacity degradation". <em>Nature Energy</em>, 4(5), 383-391.</p>
</li>
<li>
<p>MacLeod, B. P., et al. (2020). "Self-driving laboratory for accelerated discovery of thin-film materials". <em>Science Advances</em>, 6(20), eaaz8867.</p>
</li>
<li>
<p>Khenkin, M. V., et al. (2020). "Consensus statement for stability assessment and reporting for perovskite photovoltaics". <em>Nature Energy</em>, 5(1), 35-49.</p>
</li>
<li>
<p>Materials Project. (2024). "Open materials database for materials design". https://materialsproject.org</p>
</li>
<li>
<p>National Renewable Energy Laboratory (NREL). (2024). "Best Research-Cell Efficiencies". https://www.nrel.gov/pv/cell-efficiency.html</p>
</li>
<li>
<p>Miura, A., et al. (2019). "Selective metathesis synthesis of MClO (M = Ca, Sr, Ba) from MClâ‚‚ and M'â‚‚O". <em>Journal of the American Chemical Society</em>, 141(18), 7207-7210.</p>
</li>
<li>
<p>Citrine Informatics. (2021). "Accelerating Battery Development for Autonomous Vehicles". Case Study.</p>
</li>
<li>
<p>Goodenough, J. B., &amp; Park, K. S. (2013). "The Li-ion rechargeable battery: A perspective". <em>Journal of the American Chemical Society</em>, 135(4), 1167-1176.</p>
</li>
<li>
<p>Chen, T., &amp; Guestrin, C. (2016). "XGBoost: A scalable tree boosting system". <em>Proceedings of the 22nd ACM SIGKDD</em>, 785-794.</p>
</li>
<li>
<p>Xie, T., &amp; Grossman, J. C. (2018). "Crystal graph convolutional neural networks". <em>Physical Review Letters</em>, 120(14), 145301.</p>
</li>
<li>
<p>Vaswani, A., et al. (2017). "Attention is all you need". <em>Advances in Neural Information Processing Systems</em>, 30.</p>
</li>
<li>
<p>Frazier, P. I. (2018). "A tutorial on Bayesian optimization". <em>arXiv preprint arXiv:1807.02811</em>.</p>
</li>
</ol>
<hr />
<p><strong>Next Chapteräºˆå‘Š</strong>: ç¬¬3ç« in/withã€structuresææ–™ï¼ˆé«˜å¼·åº¦é‹¼ã€è»½é‡åˆé‡‘ã€è¤‡åˆææ–™ï¼‰ é–‹ç™ºäº‹ä¾‹ æ‰±ã„ã¾ã™ã€‚Machine Learningã«ã‚ˆã‚‹Mechanical PropertiesPredictionã€æœ‰é™è¦ç´ è§£æï¼ˆFEAï¼‰ã¨ çµ±åˆã€ç”£æ¥­å¿œç”¨ã«ç„¦ç‚¹ å½“ã¦ã¾ã™ã€‚</p>
<hr />
<p><em>æœ¬è¨˜äº‹ã¯æ•™è‚²ç›®çš„ã§ä½œæˆã•ã‚Œã¾ã—ãŸã€‚å®Ÿéš› ç ”ç©¶é–‹ç™ºin/withã€ã‚ˆã‚ŠDetailedexperimentãƒ‡ãƒ¼ã‚¿ã¨å°‚é–€å®¶ çŸ¥è¦‹ å¿…è¦ã§ã™ã€‚</em></p><div class="navigation">
    <a href="chapter-1.html" class="nav-button">â† Previous Chapter</a>
    <a href="index.html" class="nav-button">ã‚·ãƒªãƒ¼ã‚ºBack to Table of Contents</a>
    <a href="chapter-3.html" class="nav-button">Next Chapter â†’</a>
</div>
    </main>

    
    <section class="disclaimer">
        <h3>Disclaimer</h3>
        <ul>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯æ•™è‚²ãƒ»ç ”ç©¶ãƒ»æƒ…å ±æä¾› ã¿ ç›®çš„asãŠã‚Šã€å°‚é–€çš„ãªåŠ©è¨€(æ³•å¾‹ãƒ»ä¼šè¨ˆãƒ»æŠ€è¡“çš„ä¿è¨¼ãªã©) æä¾›ã™ã‚‹ã‚‚ in/withã‚ã‚Šã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŠã‚ˆã³ä»˜éšã™ã‚‹Code Exampleã¯ã€Œç¾çŠ¶æœ‰å§¿(AS IS)ã€ã§æä¾›ã•ã‚Œã€æ˜ç¤ºAlsoã¯é»™ç¤º å•ã‚ãšã€å•†å“æ€§ã€ç‰¹å®šç›®çš„é©åˆæ€§ã€æ¨©åˆ©éä¾µå®³ã€æ­£ç¢ºæ€§ãƒ»å®Œå…¨æ€§ã€å‹•ä½œãƒ»å®‰å…¨æ€§ç­‰ã„ã‹ãªã‚‹ä¿è¨¼ã‚‚ã—ã¾ã›ã‚“ã€‚</li>
            <li>å¤–éƒ¨ãƒªãƒ³ã‚¯ã€ç¬¬ä¸‰è€… æä¾›ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ»ãƒ„ãƒ¼ãƒ«ãƒ»ãƒ©ã‚¤ãƒ–ãƒ©ãƒªç­‰ å†…å®¹ãƒ»å¯ç”¨æ€§ãƒ»å®‰å…¨æ€§aboutã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯ä¸€åˆ‡ è²¬ä»» è² ã„ã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ åˆ©ç”¨ãƒ»å®Ÿè¡Œãƒ»è§£é‡ˆbyç›´æ¥çš„ãƒ»é–“æ¥çš„ãƒ»ä»˜éšçš„ãƒ»ç‰¹åˆ¥ãƒ»çµæœçš„ãƒ»æ‡²ç½°çš„æå®³ ç”Ÿã˜ãŸå ´åˆã§ã‚‚ã€é©ç”¨æ³•ã§è¨±å®¹ã•ã‚Œã‚‹æœ€å¤§é™ rangeã§ã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯è²¬ä»» è² ã„ã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ å†…å®¹ã¯ã€äºˆå‘Šãªãå¤‰æ›´ãƒ»æ›´æ–°ãƒ»æä¾›åœæ­¢ã•ã‚Œã‚‹ã“ã¨ ã‚ã‚Šã¾ã™ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ è‘—ä½œæ¨©ãƒ»ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯æ˜è¨˜ã•ã‚ŒãŸæ¡cases(ä¾‹: CC BY 4.0)ã«å¾“ã„ã¾ã™ã€‚å½“è©²ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯typicallyã€ç„¡ä¿è¨¼æ¡é … å«ã¿ã¾ã™ã€‚</li>
        </ul>
    </section>

<footer>
        <p><strong>ä½œæˆè€…</strong>: AI Terakoya Content Team</p>
        <p><strong>ãƒãƒ¼ã‚¸ãƒ§ãƒ³</strong>: 1.0 | <strong>ä½œæˆæ—¥</strong>: 2025-10-18</p>
        <p><strong>ãƒ©ã‚¤ã‚»ãƒ³ã‚¹</strong>: Creative Commons BY 4.0</p>
        <p>Â© 2025 AI Terakoya. All rights reserved.</p>
    </footer>
</body>
</html>
