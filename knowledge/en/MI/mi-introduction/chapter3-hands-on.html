<!DOCTYPE html>

<html lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>Chapter 3: Hands-on MI with Python - Practical Material Property Prediction - AI Terakoya</title>
<link href="../../assets/css/knowledge-base.css" rel="stylesheet"/>
<script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
<script>
        mermaid.initialize({ startOnLoad: true, theme: 'default', securityLevel: 'strict' });
    </script>
<!-- MathJax for LaTeX equation rendering -->
<script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\(', '\)']],
                displayMath: [['$$', '$$'], ['\[', '\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
                ignoreHtmlClass: 'mermaid'
            }
        };
    </script>
<script async="" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>
<nav class="breadcrumb">
<div class="breadcrumb-content">
<a href="../index.html">AI Terakoya Top</a><span class="breadcrumb-separator">‚Ä∫</span><a href="../../MI/index.html">Materials Informatics</a><span class="breadcrumb-separator">‚Ä∫</span><a href="../../MI/mi-introduction/index.html">MI Introduction</a><span class="breadcrumb-separator">‚Ä∫</span><span class="breadcrumb-current">Chapter 3</span>
</div>
</nav><div class="locale-switcher">
<span class="current-locale">üåê EN</span>
<span class="locale-separator">|</span>
<a class="locale-link" href="../../../jp/MI/mi-introduction/chapter3-hands-on.html">Êó•Êú¨Ë™û</a>
<span class="locale-meta">Last sync: 2025-11-16</span>
</div>

<header>
<div class="header-content">
<h1>Chapter 3: Hands-on MI with Python - Practical Material Property Prediction</h1>
<p class="subtitle">Implementation and Best Practices for Machine Learning in Materials Development</p>
<div class="meta">
<span class="meta-item">üìñ Reading time: 20-25 min</span>
<span class="meta-item">üìä Level: Intermediate</span>
<span class="meta-item">üíª Code examples: 0</span>
<span class="meta-item">üìù Exercises: 0</span>
</div>
</div>
</header>
<main class="container">
<h1>Chapter 3: Hands-on MI with Python - Practical Material Property Prediction</h1>
<p class="chapter-description" style="margin: 1.5rem 0; padding: 1rem; background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%); border-left: 4px solid #7b2cbf; border-radius: 8px; font-size: 1.05rem; line-height: 1.8; color: #2d3748;">We implement and compare six regression models on the same dataset, gaining practical insights into evaluation and tuning. We use SHAP to interpret "why predictions work."</p>
<p class="chapter-supplement" style="margin: 0.75rem 0 1.5rem 0; padding: 0.75rem 1rem; background: linear-gradient(135deg, #fff8e1 0%, #fff3cd 100%); border-left: 3px solid #f59e0b; border-radius: 6px; font-size: 0.95rem; line-height: 1.7; color: #4a5568;"><strong>üí° Note:</strong> We compare models from "simple to complex" to experience the balance between overfitting and generalization. Use multiple metrics (MAE and R¬≤) rather than relying on a single indicator.</p>
<h2>Learning Objectives</h2>
<p>By completing this chapter, you will be able to:
- Set up a Python environment and install MI libraries
- Implement and compare the performance of 5+ machine learning models
- Execute hyperparameter tuning
- Complete a practical material property prediction project
- Troubleshoot errors independently</p>
<hr/>
<h2>1. Environment Setup: Three Options</h2>
<p>There are three approaches to set up a Python environment for material property prediction, depending on your situation.</p>
<h3>1.1 Option 1: Anaconda (Recommended for Beginners)</h3>
<p><strong>Features:</strong>
- Scientific computing libraries included by default
- Easy environment management (GUI available)
- Windows/Mac/Linux compatible</p>
<p><strong>Installation Steps:</strong></p>
<pre><code class="language-bash"># 1. Download Anaconda
# Official site: https://www.anaconda.com/download
# Select Python 3.11 or higher

# 2. After installation, launch Anaconda Prompt

# 3. Create virtual environment (MI-specific environment)
conda create -n mi-env python=3.11 numpy pandas matplotlib scikit-learn jupyter

# 4. Activate environment
conda activate mi-env

# 5. Verify installation
python --version
# Output: Python 3.11.x
</code></pre>
<p><strong>Screen Output Example:</strong></p>
<pre><code>(base) $ conda create -n mi-env python=3.11
Collecting package metadata: done
Solving environment: done
...
Proceed ([y]/n)? y

# Upon success, the following will be displayed
# To activate this environment, use
#   $ conda activate mi-env
</code></pre>
<p><strong>Advantages of Anaconda:</strong>
- ‚úÖ NumPy, SciPy, etc. included by default
- ‚úÖ Fewer dependency issues
- ‚úÖ Visual management with Anaconda Navigator
- ‚ùå Large file size (3GB+)</p>
<h3>1.2 Option 2: venv (Python Standard)</h3>
<p><strong>Features:</strong>
- Python standard tool (no additional installation needed)
- Lightweight (install only what's needed)
- Isolates environments per project</p>
<p><strong>Installation Steps:</strong></p>
<pre><code class="language-bash"># 1. Verify Python 3.11 or higher is installed
python3 --version
# Output: Python 3.11.x or higher required

# 2. Create virtual environment
python3 -m venv mi-env

# 3. Activate environment
# macOS/Linux:
source mi-env/bin/activate

# Windows (PowerShell):
mi-env\Scripts\Activate.ps1

# Windows (Command Prompt):
mi-env\Scripts\activate.bat

# 4. Upgrade pip
pip install --upgrade pip

# 5. Install required libraries
pip install numpy pandas matplotlib scikit-learn jupyter

# 6. Verify installation
pip list
</code></pre>
<p><strong>Advantages of venv:</strong>
- ‚úÖ Lightweight (tens of MB)
- ‚úÖ Python standard tool (no additional installation)
- ‚úÖ Independent per project
- ‚ùå Requires manual dependency resolution</p>
<h3>1.3 Option 3: Google Colab (No Installation Required)</h3>
<p><strong>Features:</strong>
- Browser-only execution
- No installation needed (cloud execution)
- Free GPU/TPU access</p>
<p><strong>Usage:</strong></p>
<pre><code>1. Access Google Colab: https://colab.research.google.com
2. Create new notebook
3. Run the following code (required libraries are pre-installed)
</code></pre>
<pre><code class="language-python"># Google Colab has these pre-installed
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor

print("Library import successful!")
print(f"NumPy version: {np.__version__}")
print(f"Pandas version: {pd.__version__}")
</code></pre>
<p><strong>Advantages of Google Colab:</strong>
- ‚úÖ No installation needed (start immediately)
- ‚úÖ Free GPU access
- ‚úÖ Google Drive integration (easy data storage)
- ‚ùå Internet connection required
- ‚ùå Session resets after 12 hours</p>
<h3>1.4 Environment Selection Guide</h3>
<table>
<thead>
<tr>
<th>Situation</th>
<th>Recommended Option</th>
<th>Reason</th>
</tr>
</thead>
<tbody>
<tr>
<td>First Python environment</td>
<td>Anaconda</td>
<td>Easy setup, fewer issues</td>
</tr>
<tr>
<td>Already have Python</td>
<td>venv</td>
<td>Lightweight, project-independent</td>
</tr>
<tr>
<td>Want to try immediately</td>
<td>Google Colab</td>
<td>No installation, instant start</td>
</tr>
<tr>
<td>Need GPU computation</td>
<td>Google Colab or Anaconda</td>
<td>Free GPU (Colab) or Local GPU (Anaconda)</td>
</tr>
<tr>
<td>Offline environment</td>
<td>Anaconda or venv</td>
<td>Local execution, no internet needed</td>
</tr>
</tbody>
</table>
<h3>1.5 Installation Verification and Troubleshooting</h3>
<p><strong>Verification Commands:</strong></p>
<pre><code class="language-python"># Can run in all environments
import sys
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import sklearn

print("===== Environment Check =====")
print(f"Python version: {sys.version}")
print(f"NumPy version: {np.__version__}")
print(f"Pandas version: {pd.__version__}")
print(f"Matplotlib version: {plt.matplotlib.__version__}")
print(f"scikit-learn version: {sklearn.__version__}")
print("\n‚úÖ All libraries installed successfully!")
</code></pre>
<p><strong>Expected Output:</strong></p>
<pre><code>===== Environment Check =====
Python version: 3.11.x
NumPy version: 1.24.x
Pandas version: 2.0.x
Matplotlib version: 3.7.x
scikit-learn version: 1.3.x

‚úÖ All libraries installed successfully!
</code></pre>
<p><strong>Common Errors and Solutions:</strong></p>
<table>
<thead>
<tr>
<th>Error Message</th>
<th>Cause</th>
<th>Solution</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>ModuleNotFoundError: No module named 'numpy'</code></td>
<td>Library not installed</td>
<td>Run <code>pip install numpy</code></td>
</tr>
<tr>
<td><code>pip is not recognized</code></td>
<td>pip PATH not set</td>
<td>Reinstall Python or configure PATH</td>
</tr>
<tr>
<td><code>SSL: CERTIFICATE_VERIFY_FAILED</code></td>
<td>SSL certificate error</td>
<td><code>pip install --trusted-host pypi.org --trusted-host files.pythonhosted.org &lt;package&gt;</code></td>
</tr>
<tr>
<td><code>MemoryError</code></td>
<td>Insufficient memory</td>
<td>Reduce data size or use Google Colab</td>
</tr>
<tr>
<td><code>ImportError: DLL load failed</code> (Windows)</td>
<td>Missing C++ redistributable</td>
<td>Install Microsoft Visual C++ Redistributable</td>
</tr>
</tbody>
</table>
<hr/>
<h2>2. Code Example Series: Six Machine Learning Models</h2>
<p>We implement six different machine learning models and compare their performance.</p>
<h3>2.1 Example 1: Linear Regression (Baseline)</h3>
<p><strong>Overview:</strong>
The simplest machine learning model. Learns linear relationships between features and target variables.</p>
<pre><code class="language-python">import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error, r2_score
import time

# Create sample data (alloy composition and melting point)
# Note: Use real data from Materials Project in actual research
np.random.seed(42)
n_samples = 100

# Element A, B ratios (sum to 1.0)
element_A = np.random.uniform(0.1, 0.9, n_samples)
element_B = 1.0 - element_A

# Melting point model (linear relationship + noise)
# Melting point = 1000 + 400 * element_A + noise
melting_point = 1000 + 400 * element_A + np.random.normal(0, 20, n_samples)

# Store in DataFrame
data = pd.DataFrame({
    'element_A': element_A,
    'element_B': element_B,
    'melting_point': melting_point
})

print("===== Data Check =====")
print(data.head())
print(f"\nNumber of samples: {len(data)}")
print(f"Melting point range: {melting_point.min():.1f} - {melting_point.max():.1f} K")

# Split features and target
X = data[['element_A', 'element_B']]  # Input: composition
y = data['melting_point']  # Output: melting point

# Split into training and test data (80% vs 20%)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# Build and train model
start_time = time.time()
model_lr = LinearRegression()
model_lr.fit(X_train, y_train)
training_time = time.time() - start_time

# Prediction
y_pred = model_lr.predict(X_test)

# Evaluation
mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print("\n===== Linear Regression Model Performance =====")
print(f"Training time: {training_time:.4f} seconds")
print(f"Mean Absolute Error (MAE): {mae:.2f} K")
print(f"R¬≤ score: {r2:.4f}")

# Display learned coefficients
print("\n===== Learned Coefficients =====")
print(f"Intercept: {model_lr.intercept_:.2f}")
print(f"element_A coefficient: {model_lr.coef_[0]:.2f}")
print(f"element_B coefficient: {model_lr.coef_[1]:.2f}")

# Visualization
plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_pred, alpha=0.6, s=100, c='blue')
plt.plot([y_test.min(), y_test.max()],
         [y_test.min(), y_test.max()],
         'r--', lw=2, label='Perfect prediction')
plt.xlabel('Actual value (K)', fontsize=12)
plt.ylabel('Predicted value (K)', fontsize=12)
plt.title('Linear Regression: Melting Point Prediction Results', fontsize=14)
plt.legend()
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()
</code></pre>
<p><strong>Code Explanation:</strong>
1. <strong>Data Generation</strong>: Calculate melting point from element_A ratio (linear relationship + noise)
2. <strong>Data Splitting</strong>: 80% training, 20% testing
3. <strong>Model Training</strong>: Using LinearRegression()
4. <strong>Evaluation</strong>: Calculate MAE (average error) and R¬≤ (explanatory power)
5. <strong>Coefficient Display</strong>: Check learned linear relationship</p>
<p><strong>Expected Results:</strong>
- MAE: 15-25 K
- R¬≤: 0.95+ (high accuracy due to linear data)
- Training time: Under 0.01 seconds</p>
<hr/>
<h3>2.2 Example 2: Random Forest (Enhanced Version)</h3>
<p><strong>Overview:</strong>
Powerful model combining multiple decision trees. Can learn non-linear relationships.</p>
<pre><code class="language-python">from sklearn.ensemble import RandomForestRegressor

# Generate more complex non-linear data
np.random.seed(42)
n_samples = 200

element_A = np.random.uniform(0.1, 0.9, n_samples)
element_B = 1.0 - element_A

# Non-linear melting point model (quadratic + interaction terms)
melting_point = (
    1000
    + 400 * element_A
    - 300 * element_A**2  # Quadratic term
    + 200 * element_A * element_B  # Interaction term
    + np.random.normal(0, 15, n_samples)
)

data_rf = pd.DataFrame({
    'element_A': element_A,
    'element_B': element_B,
    'melting_point': melting_point
})

X_rf = data_rf[['element_A', 'element_B']]
y_rf = data_rf['melting_point']

X_train_rf, X_test_rf, y_train_rf, y_test_rf = train_test_split(
    X_rf, y_rf, test_size=0.2, random_state=42
)

# Build Random Forest model
start_time = time.time()
model_rf = RandomForestRegressor(
    n_estimators=100,      # Number of trees (more = better accuracy, longer time)
    max_depth=10,          # Maximum tree depth (deeper = learns complex relationships)
    min_samples_split=5,   # Minimum samples required to split
    min_samples_leaf=2,    # Minimum samples in leaf node
    random_state=42,       # For reproducibility
    n_jobs=-1              # Use all CPU cores
)
model_rf.fit(X_train_rf, y_train_rf)
training_time_rf = time.time() - start_time

# Prediction and evaluation
y_pred_rf = model_rf.predict(X_test_rf)
mae_rf = mean_absolute_error(y_test_rf, y_pred_rf)
r2_rf = r2_score(y_test_rf, y_pred_rf)

print("\n===== Random Forest Model Performance =====")
print(f"Training time: {training_time_rf:.4f} seconds")
print(f"Mean Absolute Error (MAE): {mae_rf:.2f} K")
print(f"R¬≤ score: {r2_rf:.4f}")

# Feature importance
feature_importance = pd.DataFrame({
    'Feature': ['element_A', 'element_B'],
    'Importance': model_rf.feature_importances_
}).sort_values('Importance', ascending=False)

print("\n===== Feature Importance =====")
print(feature_importance)

# Out-of-Bag (OOB) score (uses part of training data for validation)
model_rf_oob = RandomForestRegressor(
    n_estimators=100,
    max_depth=10,
    random_state=42,
    oob_score=True  # Enable OOB score
)
model_rf_oob.fit(X_train_rf, y_train_rf)
print(f"\nOOB Score (R¬≤): {model_rf_oob.oob_score_:.4f}")

# Visualization: Prediction results
fig, axes = plt.subplots(1, 2, figsize=(15, 6))

# Left: Predicted vs Actual
axes[0].scatter(y_test_rf, y_pred_rf, alpha=0.6, s=100, c='green')
axes[0].plot([y_test_rf.min(), y_test_rf.max()],
             [y_test_rf.min(), y_test_rf.max()],
             'r--', lw=2, label='Perfect prediction')
axes[0].set_xlabel('Actual value (K)', fontsize=12)
axes[0].set_ylabel('Predicted value (K)', fontsize=12)
axes[0].set_title('Random Forest: Prediction Results', fontsize=14)
axes[0].legend()
axes[0].grid(True, alpha=0.3)

# Right: Feature importance
axes[1].barh(feature_importance['Feature'], feature_importance['Importance'])
axes[1].set_xlabel('Importance', fontsize=12)
axes[1].set_title('Feature Importance', fontsize=14)
axes[1].grid(True, alpha=0.3, axis='x')

plt.tight_layout()
plt.show()
</code></pre>
<p><strong>Code Explanation:</strong>
1. <strong>Non-linear Data</strong>: Complex relationship with quadratic and interaction terms
2. <strong>Hyperparameters</strong>:
   - <code>n_estimators</code>: Number of trees (100)
   - <code>max_depth</code>: Tree depth (10 levels)
   - <code>min_samples_split</code>: Minimum samples for splitting (5)
3. <strong>Feature Importance</strong>: Shows which features contribute to prediction
4. <strong>OOB Score</strong>: Validates on part of training data (overfitting check)</p>
<p><strong>Expected Results:</strong>
- MAE: 10-20 K (improvement over linear regression)
- R¬≤: 0.90-0.98 (high accuracy)
- Training time: 0.1-0.5 seconds</p>
<hr/>
<h3>2.3 Example 3: Gradient Boosting (XGBoost/LightGBM)</h3>
<p><strong>Overview:</strong>
Sequentially learns decision trees to reduce error. Powerful model that frequently wins Kaggle competitions.</p>
<pre><code class="language-python"># Install LightGBM (first time only)
# pip install lightgbm

import lightgbm as lgb

# Build LightGBM model
start_time = time.time()
model_lgb = lgb.LGBMRegressor(
    n_estimators=100,       # Number of boosting rounds
    learning_rate=0.1,      # Learning rate (smaller = cautious, larger = faster)
    max_depth=5,            # Tree depth
    num_leaves=31,          # Number of leaves (LightGBM-specific)
    subsample=0.8,          # Sampling ratio (prevents overfitting)
    colsample_bytree=0.8,   # Feature sampling ratio
    random_state=42,
    verbose=-1              # Hide training logs
)
model_lgb.fit(
    X_train_rf, y_train_rf,
    eval_set=[(X_test_rf, y_test_rf)],  # Validation data
    eval_metric='mae',       # Evaluation metric
    callbacks=[lgb.early_stopping(stopping_rounds=10, verbose=False)]  # Early stopping
)
training_time_lgb = time.time() - start_time

# Prediction and evaluation
y_pred_lgb = model_lgb.predict(X_test_rf)
mae_lgb = mean_absolute_error(y_test_rf, y_pred_lgb)
r2_lgb = r2_score(y_test_rf, y_pred_lgb)

print("\n===== LightGBM Model Performance =====")
print(f"Training time: {training_time_lgb:.4f} seconds")
print(f"Mean Absolute Error (MAE): {mae_lgb:.2f} K")
print(f"R¬≤ score: {r2_lgb:.4f}")

# Display learning curve (training progress)
fig, ax = plt.subplots(figsize=(10, 6))
lgb.plot_metric(model_lgb, metric='mae', ax=ax)
ax.set_title('LightGBM Learning Curve (MAE Changes)', fontsize=14)
ax.set_xlabel('Boosting Round', fontsize=12)
ax.set_ylabel('MAE (K)', fontsize=12)
ax.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()
</code></pre>
<p><strong>Code Explanation:</strong>
1. <strong>Gradient Boosting</strong>: Next tree corrects errors from previous tree
2. <strong>Early Stopping</strong>: Stops training when validation error stops improving (prevents overfitting)
3. <strong>Learning Rate</strong>: 0.1 (typical value, range 0.01-0.3)
4. <strong>Subsampling</strong>: Randomly selects 80% of data each round</p>
<p><strong>Expected Results:</strong>
- MAE: 8-15 K (equal or better than Random Forest)
- R¬≤: 0.92-0.99
- Training time: 0.2-0.8 seconds</p>
<hr/>
<h3>2.4 Example 4: Support Vector Regression (SVR)</h3>
<p><strong>Overview:</strong>
Regression version of Support Vector Machine. Learns non-linear relationships through kernel trick.</p>
<pre><code class="language-python">from sklearn.svm import SVR
from sklearn.preprocessing import StandardScaler

# SVR is sensitive to feature scale, so standardization is essential
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train_rf)
X_test_scaled = scaler.transform(X_test_rf)

# Build SVR model
start_time = time.time()
model_svr = SVR(
    kernel='rbf',      # Gaussian kernel (handles non-linearity)
    C=100,             # Regularization parameter (larger = fits training data more closely)
    gamma='scale',     # Kernel coefficient ('scale' = auto-set)
    epsilon=0.1        # Epsilon-tube width (errors within this range ignored)
)
model_svr.fit(X_train_scaled, y_train_rf)
training_time_svr = time.time() - start_time

# Prediction and evaluation
y_pred_svr = model_svr.predict(X_test_scaled)
mae_svr = mean_absolute_error(y_test_rf, y_pred_svr)
r2_svr = r2_score(y_test_rf, y_pred_svr)

print("\n===== SVR Model Performance =====")
print(f"Training time: {training_time_svr:.4f} seconds")
print(f"Mean Absolute Error (MAE): {mae_svr:.2f} K")
print(f"R¬≤ score: {r2_svr:.4f}")
print(f"Support vectors: {len(model_svr.support_)}/{len(X_train_rf)}")

# Visualization
plt.figure(figsize=(10, 6))
plt.scatter(y_test_rf, y_pred_svr, alpha=0.6, s=100, c='purple')
plt.plot([y_test_rf.min(), y_test_rf.max()],
         [y_test_rf.min(), y_test_rf.max()],
         'r--', lw=2, label='Perfect prediction')
plt.xlabel('Actual value (K)', fontsize=12)
plt.ylabel('Predicted value (K)', fontsize=12)
plt.title('SVR: Melting Point Prediction Results', fontsize=14)
plt.legend()
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()
</code></pre>
<p><strong>Code Explanation:</strong>
1. <strong>Standardization</strong>: Transform to mean 0, standard deviation 1 (essential for SVR)
2. <strong>RBF Kernel</strong>: Non-linear transformation using Gaussian function
3. <strong>C Parameter</strong>: Larger values fit training data more strictly (higher overfitting risk)
4. <strong>Support Vectors</strong>: Important data points used for prediction</p>
<p><strong>Expected Results:</strong>
- MAE: 12-25 K
- R¬≤: 0.85-0.95
- Training time: 0.5-2 seconds (slower than other models)</p>
<hr/>
<h3>2.5 Example 5: Neural Network (MLP)</h3>
<p><strong>Overview:</strong>
Multilayer Perceptron. Foundation of deep learning models.</p>
<pre><code class="language-python">from sklearn.neural_network import MLPRegressor

# Build MLP model
start_time = time.time()
model_mlp = MLPRegressor(
    hidden_layer_sizes=(64, 32, 16),  # 3 layers: 64‚Üí32‚Üí16 neurons
    activation='relu',         # Activation function (ReLU: most common)
    solver='adam',             # Optimization algorithm (Adam: adaptive learning rate)
    alpha=0.001,               # L2 regularization parameter (prevents overfitting)
    learning_rate_init=0.01,   # Initial learning rate
    max_iter=500,              # Maximum epochs
    random_state=42,
    early_stopping=True,       # Stop if validation error stops improving
    validation_fraction=0.2,   # Use 20% of training data for validation
    verbose=False
)
model_mlp.fit(X_train_scaled, y_train_rf)
training_time_mlp = time.time() - start_time

# Prediction and evaluation
y_pred_mlp = model_mlp.predict(X_test_scaled)
mae_mlp = mean_absolute_error(y_test_rf, y_pred_mlp)
r2_mlp = r2_score(y_test_rf, y_pred_mlp)

print("\n===== MLP Model Performance =====")
print(f"Training time: {training_time_mlp:.4f} seconds")
print(f"Mean Absolute Error (MAE): {mae_mlp:.2f} K")
print(f"R¬≤ score: {r2_mlp:.4f}")
print(f"Number of iterations: {model_mlp.n_iter_}")
print(f"Loss: {model_mlp.loss_:.4f}")

# Visualize learning curve
plt.figure(figsize=(10, 6))
plt.plot(model_mlp.loss_curve_, label='Training Loss', lw=2)
plt.xlabel('Epoch', fontsize=12)
plt.ylabel('Loss', fontsize=12)
plt.title('MLP Learning Curve', fontsize=14)
plt.legend()
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()
</code></pre>
<p><strong>Code Explanation:</strong>
1. <strong>Hidden Layers</strong>: (64, 32, 16) = 3-layer neural network
2. <strong>ReLU Activation Function</strong>: Introduces non-linearity
3. <strong>Adam Optimization</strong>: Efficient learning with adaptive learning rate
4. <strong>Early Stopping</strong>: Prevents overfitting</p>
<p><strong>Expected Results:</strong>
- MAE: 10-20 K
- R¬≤: 0.90-0.98
- Training time: 1-3 seconds (slower than other models)</p>
<hr/>
<h3>2.6 Example 6: Materials Project API Real Data Integration</h3>
<p><strong>Overview:</strong>
Retrieve data from actual materials database and build prediction model with Machine Learning.</p>
<pre><code class="language-python"># Using Materials Project API (requires free API key)
# Register: https://materialsproject.org

# Note: Run the following code after obtaining API key
# Using mock data here to demonstrate functionality

try:
    from pymatgen.ext.matproj import MPRester

    # Set API key (replace 'YOUR_API_KEY' with actual key)
    API_KEY = "YOUR_API_KEY"

    with MPRester(API_KEY) as mpr:
        # Retrieve band gap data for lithium compounds
        entries = mpr.query(
            criteria={
                "elements": {"$all": ["Li"]},
                "nelements": {"$lte": 2}
            },
            properties=[
                "material_id",
                "pretty_formula",
                "band_gap",
                "formation_energy_per_atom"
            ]
        )

        # Convert to DataFrame
        df_mp = pd.DataFrame(entries)
        print(f"Retrieved data count: {len(df_mp)}")
        print(df_mp.head())

except ImportError:
    print("pymatgen is not installed.")
    print("Install with: pip install pymatgen")
except Exception as e:
    print(f"API connection error: {e}")
    print("Continuing with mock data.")

    # Mock data (typical Materials Project data format)
    df_mp = pd.DataFrame({
        'material_id': ['mp-1', 'mp-2', 'mp-3', 'mp-4', 'mp-5'],
        'pretty_formula': ['Li', 'Li2O', 'LiH', 'Li3N', 'LiF'],
        'band_gap': [0.0, 7.5, 3.9, 1.2, 13.8],
        'formation_energy_per_atom': [0.0, -2.9, -0.5, -0.8, -3.5]
    })
    print("Using mock data:")
    print(df_mp)

# Predict band gap from formation energy using machine learning
if len(df_mp) &gt; 5:
    X_mp = df_mp[['formation_energy_per_atom']].values
    y_mp = df_mp['band_gap'].values

    X_train_mp, X_test_mp, y_train_mp, y_test_mp = train_test_split(
        X_mp, y_mp, test_size=0.2, random_state=42
    )

    # Predict with Random Forest
    model_mp = RandomForestRegressor(n_estimators=100, random_state=42)
    model_mp.fit(X_train_mp, y_train_mp)

    y_pred_mp = model_mp.predict(X_test_mp)
    mae_mp = mean_absolute_error(y_test_mp, y_pred_mp)
    r2_mp = r2_score(y_test_mp, y_pred_mp)

    print(f"\n===== Prediction Performance with Materials Project Data =====")
    print(f"MAE: {mae_mp:.2f} eV")
    print(f"R¬≤: {r2_mp:.4f}")
else:
    print("Insufficient data count, skipping machine learning.")
</code></pre>
<p><strong>Code Explanation:</strong>
1. <strong>MPRester</strong>: Materials Project API client
2. <strong>query()</strong>: Search materials (filter by elements and properties)
3. <strong>Real Data Advantage</strong>: Reliable data from DFT calculations</p>
<p><strong>Expected Results:</strong>
- Real data retrieval count: 10-100 entries (depends on search criteria)
- Prediction performance depends on data count (R¬≤: 0.6-0.9)</p>
<hr/>
<h2>3. Model Performance Comparison</h2>
<p>We evaluate all models on the same data and compare performance.</p>
<h3>3.1 Comprehensive Comparison Table</h3>
<table>
<thead>
<tr>
<th>Model</th>
<th>MAE (K)</th>
<th>R¬≤</th>
<th style="text-align: right;">Training Time (sec)</th>
<th>Memory</th>
<th>Interpretability</th>
</tr>
</thead>
<tbody>
<tr>
<td>Linear Regression</td>
<td>18.5</td>
<td>0.952</td>
<td style="text-align: right;">0.005</td>
<td>Small</td>
<td>‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê</td>
</tr>
<tr>
<td>Random Forest</td>
<td>12.3</td>
<td>0.982</td>
<td style="text-align: right;">0.32</td>
<td>Medium</td>
<td>‚≠ê‚≠ê‚≠ê‚≠ê</td>
</tr>
<tr>
<td>LightGBM</td>
<td>10.8</td>
<td>0.987</td>
<td style="text-align: right;">0.45</td>
<td>Medium</td>
<td>‚≠ê‚≠ê‚≠ê</td>
</tr>
<tr>
<td>SVR</td>
<td>15.2</td>
<td>0.965</td>
<td style="text-align: right;">1.85</td>
<td>Large</td>
<td>‚≠ê‚≠ê</td>
</tr>
<tr>
<td>MLP</td>
<td>13.1</td>
<td>0.978</td>
<td style="text-align: right;">2.10</td>
<td>Large</td>
<td>‚≠ê</td>
</tr>
</tbody>
</table>
<p><strong>Legend:</strong>
- <strong>MAE</strong>: Smaller is better (average error)
- <strong>R¬≤</strong>: Closer to 1 is better (explanatory power)
- <strong>Training Time</strong>: Shorter is better
- <strong>Memory</strong>: Small &lt; Medium &lt; Large
- <strong>Interpretability</strong>: More ‚≠ê = easier to interpret</p>
<h3>3.2 Visualization: Performance Comparison</h3>
<pre><code class="language-python">import matplotlib.pyplot as plt

# Model performance data
models = ['Linear Regression', 'Random Forest', 'LightGBM', 'SVR', 'MLP']
mae_scores = [18.5, 12.3, 10.8, 15.2, 13.1]
r2_scores = [0.952, 0.982, 0.987, 0.965, 0.978]
training_times = [0.005, 0.32, 0.45, 1.85, 2.10]

fig, axes = plt.subplots(1, 3, figsize=(18, 5))

# MAE comparison
axes[0].bar(models, mae_scores, color=['blue', 'green', 'orange', 'purple', 'red'])
axes[0].set_ylabel('MAE (K)', fontsize=12)
axes[0].set_title('Mean Absolute Error (smaller is better)', fontsize=14)
axes[0].tick_params(axis='x', rotation=45)
axes[0].grid(True, alpha=0.3, axis='y')

# R¬≤ comparison
axes[1].bar(models, r2_scores, color=['blue', 'green', 'orange', 'purple', 'red'])
axes[1].set_ylabel('R¬≤', fontsize=12)
axes[1].set_title('R¬≤ Score (closer to 1 is better)', fontsize=14)
axes[1].tick_params(axis='x', rotation=45)
axes[1].grid(True, alpha=0.3, axis='y')
axes[1].set_ylim(0.9, 1.0)

# Training time comparison
axes[2].bar(models, training_times, color=['blue', 'green', 'orange', 'purple', 'red'])
axes[2].set_ylabel('Training time (sec)', fontsize=12)
axes[2].set_title('Training Time (shorter is better)', fontsize=14)
axes[2].tick_params(axis='x', rotation=45)
axes[2].grid(True, alpha=0.3, axis='y')

plt.tight_layout()
plt.show()
</code></pre>
<h3>3.3 Model Selection Flowchart</h3>
<div class="mermaid">
flowchart TD
    A[Material Property Prediction Task] --&gt; B{Data count?}
    B --&gt;|&lt; 100| C[Linear Regression or SVR]
    B --&gt;|100-1000| D[Random Forest]
    B --&gt;|&gt; 1000| E{Time constraints?}

    E --&gt;|Strict| F[Random Forest]
    E --&gt;|Relaxed| G[LightGBM or MLP]

    C --&gt; H{Interpretability important?}
    H --&gt;|Yes| I[Linear Regression]
    H --&gt;|No| J[SVR]

    D --&gt; K[Random Forest Recommended]
    F --&gt; K
    G --&gt; L{Strong non-linearity?}
    L --&gt;|Yes| M[MLP]
    L --&gt;|No| N[LightGBM]

    style A fill:#e3f2fd
    style K fill:#c8e6c9
    style M fill:#fff9c4
    style N fill:#fff9c4
    style I fill:#c8e6c9
    style J fill:#c8e6c9
</div>
<h3>3.4 Model Selection Guidelines</h3>
<p><strong>Recommended Model by Situation:</strong></p>
<table>
<thead>
<tr>
<th>Situation</th>
<th>Recommended Model</th>
<th>Reason</th>
</tr>
</thead>
<tbody>
<tr>
<td>Data count &lt; 100</td>
<td>Linear Regression or SVR</td>
<td>Prevents overfitting, simple models are safer</td>
</tr>
<tr>
<td>Data count 100-1000</td>
<td>Random Forest</td>
<td>Well-balanced, easy hyperparameter tuning</td>
</tr>
<tr>
<td>Data count &gt; 1000</td>
<td>LightGBM or MLP</td>
<td>High accuracy with large-scale data</td>
</tr>
<tr>
<td>Interpretability is important</td>
<td>Linear Regression or Random Forest</td>
<td>Clear coefficients and feature importance</td>
</tr>
<tr>
<td>Strict time constraints</td>
<td>Linear Regression or Random Forest</td>
<td>Fast training</td>
</tr>
<tr>
<td>Maximum accuracy needed</td>
<td>LightGBM (with ensemble)</td>
<td>Many Kaggle competition wins</td>
</tr>
<tr>
<td>Strong non-linearity</td>
<td>MLP or SVR</td>
<td>Can learn complex relationships</td>
</tr>
</tbody>
</table>
<hr/>
<h2>4. Hyperparameter Tuning</h2>
<p>To maximize model performance, we optimize hyperparameters.</p>
<h3>4.1 What are Hyperparameters</h3>
<p><strong>Definition:</strong>
Machine learning model settings (must be decided before training).</p>
<p><strong>Example (Random Forest):</strong>
- <code>n_estimators</code>: Number of trees (10, 50, 100, 200...)
- <code>max_depth</code>: Tree depth (3, 5, 10, 20...)
- <code>min_samples_split</code>: Minimum samples for splitting (2, 5, 10...)</p>
<p><strong>Importance:</strong>
Proper hyperparameters can improve performance by 10-30%.</p>
<h3>4.2 Grid Search</h3>
<p><strong>Overview:</strong>
Try all combinations and select the best.</p>
<pre><code class="language-python">from sklearn.model_selection import GridSearchCV

# Random Forest hyperparameter candidates
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [5, 10, 15, None],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}

# Grid Search configuration
grid_search = GridSearchCV(
    estimator=RandomForestRegressor(random_state=42),
    param_grid=param_grid,
    cv=5,              # 5-fold cross-validation
    scoring='neg_mean_absolute_error',  # Evaluate with MAE (smaller is better)
    n_jobs=-1,         # Parallel execution
    verbose=1          # Show progress
)

# Execute Grid Search
print("===== Grid Search Started =====")
print(f"Number of combinations to search: {len(param_grid['n_estimators']) * len(param_grid['max_depth']) * len(param_grid['min_samples_split']) * len(param_grid['min_samples_leaf'])}")
start_time = time.time()
grid_search.fit(X_train_rf, y_train_rf)
grid_search_time = time.time() - start_time

# Best hyperparameters
print(f"\n===== Grid Search Completed ({grid_search_time:.2f} seconds) =====")
print("Best hyperparameters:")
for param, value in grid_search.best_params_.items():
    print(f"  {param}: {value}")

print(f"\nCross-validation MAE: {-grid_search.best_score_:.2f} K")

# Evaluate test data with best model
best_model = grid_search.best_estimator_
y_pred_best = best_model.predict(X_test_rf)
mae_best = mean_absolute_error(y_test_rf, y_pred_best)
r2_best = r2_score(y_test_rf, y_pred_best)

print(f"\nTest data performance:")
print(f"  MAE: {mae_best:.2f} K")
print(f"  R¬≤: {r2_best:.4f}")
</code></pre>
<p><strong>Code Explanation:</strong>
1. <strong>param_grid</strong>: Range of hyperparameters to search
2. <strong>GridSearchCV</strong>: Try all combinations (3√ó4√ó3√ó3=108 patterns)
3. <strong>cv=5</strong>: Evaluate with 5-fold cross-validation (split data into 5 parts)
4. <strong>best_params_</strong>: Best combination</p>
<p><strong>Expected Results:</strong>
- Grid Search time: 10-60 seconds (depends on data count and parameters)
- Best MAE: 10-15 K (improvement over default)</p>
<h3>4.3 Random Search</h3>
<p><strong>Overview:</strong>
Try random combinations (faster, for large-scale search).</p>
<pre><code class="language-python">from sklearn.model_selection import RandomizedSearchCV
from scipy.stats import randint, uniform

# Specify hyperparameter distributions
param_distributions = {
    'n_estimators': randint(50, 300),        # Random integer from 50-300
    'max_depth': randint(5, 30),             # Integer from 5-30
    'min_samples_split': randint(2, 20),     # Integer from 2-20
    'min_samples_leaf': randint(1, 10),      # Integer from 1-10
    'max_features': uniform(0.5, 0.5)        # Float from 0.5-1.0
}

# Random Search configuration
random_search = RandomizedSearchCV(
    estimator=RandomForestRegressor(random_state=42),
    param_distributions=param_distributions,
    n_iter=50,         # 50 random samples
    cv=5,
    scoring='neg_mean_absolute_error',
    n_jobs=-1,
    random_state=42,
    verbose=1
)

# Execute Random Search
print("===== Random Search Started =====")
start_time = time.time()
random_search.fit(X_train_rf, y_train_rf)
random_search_time = time.time() - start_time

print(f"\n===== Random Search Completed ({random_search_time:.2f} seconds) =====")
print("Best hyperparameters:")
for param, value in random_search.best_params_.items():
    print(f"  {param}: {value}")

print(f"\nCross-validation MAE: {-random_search.best_score_:.2f} K")
</code></pre>
<p><strong>Grid Search vs Random Search:</strong></p>
<table>
<thead>
<tr>
<th>Item</th>
<th>Grid Search</th>
<th>Random Search</th>
</tr>
</thead>
<tbody>
<tr>
<td>Search method</td>
<td>All combinations</td>
<td>Random sampling</td>
</tr>
<tr>
<td>Execution time</td>
<td>Long (exhaustive search)</td>
<td>Short (specified iterations only)</td>
</tr>
<tr>
<td>Best solution guarantee</td>
<td>Yes (exhaustive)</td>
<td>No (probabilistic)</td>
</tr>
<tr>
<td>Application scenario</td>
<td>Small-scale search</td>
<td>Large-scale search</td>
</tr>
</tbody>
</table>
<h3>4.4 Hyperparameter Effect Visualization</h3>
<pre><code class="language-python"># Get all Grid Search results
results = pd.DataFrame(grid_search.cv_results_)

# Visualize n_estimators impact
fig, axes = plt.subplots(1, 2, figsize=(15, 5))

# n_estimators vs MAE
for depth in [5, 10, 15, None]:
    mask = results['param_max_depth'] == depth
    axes[0].plot(
        results[mask]['param_n_estimators'],
        -results[mask]['mean_test_score'],
        marker='o',
        label=f'max_depth={depth}'
    )

axes[0].set_xlabel('n_estimators', fontsize=12)
axes[0].set_ylabel('Cross-validation MAE (K)', fontsize=12)
axes[0].set_title('Impact of n_estimators', fontsize=14)
axes[0].legend()
axes[0].grid(True, alpha=0.3)

# max_depth vs MAE
for n_est in [50, 100, 200]:
    mask = results['param_n_estimators'] == n_est
    axes[1].plot(
        results[mask]['param_max_depth'].apply(lambda x: 20 if x is None else x),
        -results[mask]['mean_test_score'],
        marker='o',
        label=f'n_estimators={n_est}'
    )

axes[1].set_xlabel('max_depth', fontsize=12)
axes[1].set_ylabel('Cross-validation MAE (K)', fontsize=12)
axes[1].set_title('Impact of max_depth', fontsize=14)
axes[1].legend()
axes[1].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
</code></pre>
<hr/>
<h2>5. Feature Engineering (Materials-specific)</h2>
<p>We create features specific to materials data to improve prediction performance.</p>
<h3>5.1 What is Feature Engineering</h3>
<p><strong>Definition:</strong>
Process of creating and selecting effective features for prediction from raw data.</p>
<p><strong>Importance:</strong>
"Good features &gt; Advanced models"
- Simple models can achieve high accuracy with proper features
- No model can perform well with inappropriate features</p>
<h3>5.2 Automatic Feature Extraction with Matminer</h3>
<p><strong>Matminer:</strong>
Feature extraction library for materials science.</p>
<pre><code class="language-bash"># Install (first time only)
pip install matminer
</code></pre>
<pre><code class="language-python">from matminer.featurizers.composition import ElementProperty
from pymatgen.core import Composition

# Composition data (example: Li2O)
compositions = ['Li2O', 'LiCoO2', 'LiFePO4', 'Li4Ti5O12']

# Convert to Composition objects
comp_objects = [Composition(c) for c in compositions]

# Extract features with ElementProperty
featurizer = ElementProperty.from_preset('magpie')

# Calculate features
features = []
for comp in comp_objects:
    feat = featurizer.featurize(comp)
    features.append(feat)

# Convert to DataFrame
feature_names = featurizer.feature_labels()
df_features = pd.DataFrame(features, columns=feature_names)

print("===== Features Extracted with Matminer =====")
print(f"Number of features: {len(feature_names)}")
print(f"\nFirst 5 features:")
print(df_features.head())
print(f"\nFeature examples:")
for i in range(min(5, len(feature_names))):
    print(f"  {feature_names[i]}")
</code></pre>
<p><strong>Examples of Matminer-extracted features:</strong>
- <code>MagpieData avg_dev MeltingT</code>: Melting point deviation
- <code>MagpieData mean Electronegativity</code>: Mean electronegativity
- <code>MagpieData mean AtomicWeight</code>: Mean atomic weight
- <code>MagpieData range Number</code>: Atomic number range
- Total 130+ features</p>
<h3>5.3 Manual Feature Engineering</h3>
<pre><code class="language-python"># Base data
data_advanced = pd.DataFrame({
    'element_A': [0.5, 0.6, 0.7, 0.8],
    'element_B': [0.5, 0.4, 0.3, 0.2],
    'melting_point': [1200, 1250, 1300, 1350]
})

# Create new features
data_advanced['sum_AB'] = data_advanced['element_A'] + data_advanced['element_B']  # Sum (always 1.0)
data_advanced['diff_AB'] = abs(data_advanced['element_A'] - data_advanced['element_B'])  # Absolute difference
data_advanced['product_AB'] = data_advanced['element_A'] * data_advanced['element_B']  # Product (interaction)
data_advanced['ratio_AB'] = data_advanced['element_A'] / (data_advanced['element_B'] + 1e-10)  # Ratio
data_advanced['A_squared'] = data_advanced['element_A'] ** 2  # Squared term (non-linearity)
data_advanced['B_squared'] = data_advanced['element_B'] ** 2

print("===== Data After Feature Engineering =====")
print(data_advanced)
</code></pre>
<h3>5.4 Feature Importance Analysis</h3>
<pre><code class="language-python"># Train model using extended features
X_advanced = data_advanced.drop('melting_point', axis=1)
y_advanced = data_advanced['melting_point']

# Train with Random Forest
model_advanced = RandomForestRegressor(n_estimators=100, random_state=42)
model_advanced.fit(X_advanced, y_advanced)

# Get feature importance
importances = pd.DataFrame({
    'Feature': X_advanced.columns,
    'Importance': model_advanced.feature_importances_
}).sort_values('Importance', ascending=False)

print("===== Feature Importance =====")
print(importances)

# Visualization
plt.figure(figsize=(10, 6))
plt.barh(importances['Feature'], importances['Importance'])
plt.xlabel('Importance', fontsize=12)
plt.title('Feature Importance (Random Forest)', fontsize=14)
plt.grid(True, alpha=0.3, axis='x')
plt.tight_layout()
plt.show()
</code></pre>
<h3>5.5 Feature Selection</h3>
<p><strong>Purpose:</strong>
Remove features that don't contribute to prediction (prevents overfitting, reduces computation time).</p>
<pre><code class="language-python">from sklearn.feature_selection import SelectKBest, f_regression

# SelectKBest: Select top K features
selector = SelectKBest(score_func=f_regression, k=3)  # Top 3
X_selected = selector.fit_transform(X_advanced, y_advanced)

# Selected features
selected_features = X_advanced.columns[selector.get_support()]
print(f"Selected features: {list(selected_features)}")

# Train model with selected features
model_selected = RandomForestRegressor(n_estimators=100, random_state=42)
model_selected.fit(X_selected, y_advanced)

print(f"Before feature selection: {X_advanced.shape[1]} features")
print(f"After feature selection: {X_selected.shape[1]} features")
</code></pre>
<hr/>
<h2>6. Troubleshooting Guide</h2>
<p>Common errors encountered in practice and their solutions.</p>
<h3>6.1 Common Errors List</h3>
<table>
<thead>
<tr>
<th>Error Message</th>
<th>Cause</th>
<th>Solution</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>ModuleNotFoundError: No module named 'sklearn'</code></td>
<td>scikit-learn not installed</td>
<td><code>pip install scikit-learn</code></td>
</tr>
<tr>
<td><code>MemoryError</code></td>
<td>Insufficient memory</td>
<td>Reduce data size, batch processing, use Google Colab</td>
</tr>
<tr>
<td><code>ConvergenceWarning: lbfgs failed to converge</code></td>
<td>MLP training didn't converge</td>
<td>Increase <code>max_iter</code> (e.g., 1000), adjust learning rate</td>
</tr>
<tr>
<td><code>ValueError: Input contains NaN</code></td>
<td>Missing values in data</td>
<td>Remove with <code>df.dropna()</code> or fill with <code>df.fillna()</code></td>
</tr>
<tr>
<td><code>ValueError: could not convert string to float</code></td>
<td>String data present</td>
<td>Convert to dummy variables with <code>pd.get_dummies()</code></td>
</tr>
<tr>
<td><code>R¬≤ is negative</code></td>
<td>Model worse than random prediction</td>
<td>Review features, change model</td>
</tr>
<tr>
<td><code>ZeroDivisionError</code></td>
<td>Division by zero</td>
<td>Add small value to denominator (e.g., <code>x / (y + 1e-10)</code>)</td>
</tr>
</tbody>
</table>
<h3>6.2 Debugging Checklist</h3>
<p><strong>Step 1: Data Verification</strong></p>
<pre><code class="language-python"># Basic statistics
print(df.describe())

# Check missing values
print(df.isnull().sum())

# Check data types
print(df.dtypes)

# Check for infinity/NaN
print(df.isin([np.inf, -np.inf]).sum())
</code></pre>
<p><strong>Step 2: Data Visualization</strong></p>
<pre><code class="language-python"># Check distribution
df.hist(figsize=(12, 8), bins=30)
plt.tight_layout()
plt.show()

# Correlation matrix
import seaborn as sns
plt.figure(figsize=(10, 8))
sns.heatmap(df.corr(), annot=True, cmap='coolwarm')
plt.title('Correlation Matrix')
plt.show()
</code></pre>
<p><strong>Step 3: Test with Small Data</strong></p>
<pre><code class="language-python"># Test with first 10 samples only
X_small = X[:10]
y_small = y[:10]

model_test = RandomForestRegressor(n_estimators=10)
model_test.fit(X_small, y_small)
print("Small data training successful")
</code></pre>
<p><strong>Step 4: Model Simplification</strong></p>
<pre><code class="language-python"># If complex model fails, try linear regression first
model_simple = LinearRegression()
model_simple.fit(X_train, y_train)
print(f"Linear regression R¬≤: {model_simple.score(X_test, y_test):.4f}")
</code></pre>
<p><strong>Step 5: Read Error Messages</strong></p>
<pre><code class="language-python">try:
    model.fit(X_train, y_train)
except Exception as e:
    print(f"Error details: {type(e).__name__}")
    print(f"Message: {str(e)}")
    import traceback
    traceback.print_exc()
</code></pre>
<h3>6.3 Solutions for Poor Performance</h3>
<table>
<thead>
<tr>
<th>Symptom</th>
<th>Possible Cause</th>
<th>Solution</th>
</tr>
</thead>
<tbody>
<tr>
<td>R¬≤ &lt; 0.5</td>
<td>Inappropriate features</td>
<td>Feature engineering, use Matminer</td>
</tr>
<tr>
<td>Small training error, large test error</td>
<td>Overfitting</td>
<td>Strengthen regularization, add data, simplify model</td>
</tr>
<tr>
<td>Both training and test errors large</td>
<td>Underfitting</td>
<td>Increase model complexity, add features, adjust learning rate</td>
</tr>
<tr>
<td>All predictions same</td>
<td>Model not learning</td>
<td>Review hyperparameters, feature scaling</td>
</tr>
<tr>
<td>Training slow</td>
<td>Large data or model</td>
<td>Data sampling, simplify model, parallelize</td>
</tr>
</tbody>
</table>
<hr/>
<h2>7. Project Challenge: Band Gap Prediction</h2>
<p>Apply what you've learned to a practical project.</p>
<h3>7.1 Project Overview</h3>
<p><strong>Goal:</strong>
Build MI model to predict band gap from composition</p>
<p><strong>Target Performance:</strong>
- R¬≤ &gt; 0.7 (70%+ explanatory power)
- MAE &lt; 0.5 eV (error under 0.5 eV)</p>
<p><strong>Data Source:</strong>
Materials Project API (or mock data)</p>
<h3>7.2 Step-by-Step Guide</h3>
<p><strong>Step 1: Data Collection</strong></p>
<pre><code class="language-python"># Retrieve data from Materials Project API (can use mock data as alternative)
# Target: 100+ oxide data entries

data_project = pd.DataFrame({
    'formula': ['Li2O', 'Na2O', 'MgO', 'Al2O3', 'SiO2'] * 20,
    'Li_ratio': [0.67, 0.0, 0.0, 0.0, 0.0] * 20,
    'O_ratio': [0.33, 0.67, 0.5, 0.6, 0.67] * 20,
    'band_gap': [7.5, 5.2, 7.8, 8.8, 9.0] * 20
})

# Add noise (more realistic)
np.random.seed(42)
data_project['band_gap'] += np.random.normal(0, 0.3, len(data_project))

print(f"Data count: {len(data_project)}")
</code></pre>
<p><strong>Step 2: Feature Engineering</strong></p>
<pre><code class="language-python"># Create additional features from element ratios
# (In practice, recommend using Matminer for atomic properties)

data_project['sum_elements'] = data_project['Li_ratio'] + data_project['O_ratio']
data_project['product_LiO'] = data_project['Li_ratio'] * data_project['O_ratio']
</code></pre>
<p><strong>Step 3: Data Splitting</strong></p>
<pre><code class="language-python">X_project = data_project[['Li_ratio', 'O_ratio', 'sum_elements', 'product_LiO']]
y_project = data_project['band_gap']

X_train_proj, X_test_proj, y_train_proj, y_test_proj = train_test_split(
    X_project, y_project, test_size=0.2, random_state=42
)
</code></pre>
<p><strong>Step 4: Model Selection and Training</strong></p>
<pre><code class="language-python"># Using Random Forest
model_project = RandomForestRegressor(
    n_estimators=200,
    max_depth=15,
    random_state=42
)
model_project.fit(X_train_proj, y_train_proj)
</code></pre>
<p><strong>Step 5: Evaluation</strong></p>
<pre><code class="language-python">y_pred_proj = model_project.predict(X_test_proj)
mae_proj = mean_absolute_error(y_test_proj, y_pred_proj)
r2_proj = r2_score(y_test_proj, y_pred_proj)

print(f"===== Project Results =====")
print(f"MAE: {mae_proj:.2f} eV")
print(f"R¬≤: {r2_proj:.4f}")

if r2_proj &gt; 0.7 and mae_proj &lt; 0.5:
    print("üéâ Goal achieved!")
else:
    print("‚ùå Goal not achieved. Add more features.")
</code></pre>
<p><strong>Step 6: Visualization</strong></p>
<pre><code class="language-python">plt.figure(figsize=(10, 6))
plt.scatter(y_test_proj, y_pred_proj, alpha=0.6, s=100)
plt.plot([y_test_proj.min(), y_test_proj.max()],
         [y_test_proj.min(), y_test_proj.max()],
         'r--', lw=2, label='Perfect prediction')
plt.xlabel('Actual Band Gap (eV)', fontsize=12)
plt.ylabel('Predicted Band Gap (eV)', fontsize=12)
plt.title('Band Gap Prediction Project', fontsize=14)
plt.legend()
plt.grid(True, alpha=0.3)
plt.text(0.05, 0.95, f'R¬≤ = {r2_proj:.3f}\nMAE = {mae_proj:.3f} eV',
         transform=plt.gca().transAxes, fontsize=12, verticalalignment='top',
         bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))
plt.tight_layout()
plt.show()
</code></pre>
<h3>7.3 Advanced Challenges</h3>
<p><strong>Beginner:</strong>
- Build prediction model for different material properties (melting point, formation energy)</p>
<p><strong>Intermediate:</strong>
- Extract 130+ features with Matminer to improve performance
- Evaluate model reliability with cross-validation</p>
<p><strong>Advanced:</strong>
- Retrieve real data from Materials Project API
- Ensemble learning (combining multiple models)
- Predict with Neural Network (MLP)</p>
<hr/>
<h2>8. Summary</h2>
<h3>What You Learned in This Chapter</h3>
<ol>
<li>
<p><strong>Environment Setup</strong>
   - Three options: Anaconda, venv, Google Colab
   - How to choose optimal environment based on situation</p>
</li>
<li>
<p><strong>Six Machine Learning Models</strong>
   - Linear Regression (Baseline)
   - Random Forest (Balanced)
   - LightGBM (High accuracy)
   - SVR (Non-linear capable)
   - MLP (Deep Learning)
   - Materials Project real data integration</p>
</li>
<li>
<p><strong>Model Selection Guidelines</strong>
   - Optimal models based on data count, computation time, interpretability
   - Performance comparison table and flowchart</p>
</li>
<li>
<p><strong>Hyperparameter Tuning</strong>
   - Grid Search and Random Search
   - Hyperparameter effect visualization</p>
</li>
<li>
<p><strong>Feature Engineering</strong>
   - Automatic extraction with Matminer
   - Manual feature creation (interaction terms, quadratic terms)
   - Feature importance and selection</p>
</li>
<li>
<p><strong>Troubleshooting</strong>
   - Common errors and solutions
   - 5-step debugging process</p>
</li>
<li>
<p><strong>Practical Project</strong>
   - Complete implementation of band gap prediction
   - Steps to achieve goals</p>
</li>
</ol>
<h3>Next Steps</h3>
<p><strong>After completing this tutorial, you can:</strong>
- ‚úÖ Implement material property prediction
- ‚úÖ Use and compare 5+ models
- ‚úÖ Perform hyperparameter tuning
- ‚úÖ Solve errors independently</p>
<p><strong>Topics to learn next:</strong>
1. <strong>Deep Learning Applications</strong>
   - Graph Neural Networks (GNN)
   - Crystal Graph Convolutional Networks (CGCNN)</p>
<ol start="2">
<li>
<p><strong>Bayesian Optimization</strong>
   - Methods to minimize experiments
   - Gaussian Process Regression</p>
</li>
<li>
<p><strong>Transfer Learning</strong>
   - Achieve high accuracy with less data
   - Utilize pre-trained models</p>
</li>
</ol>
<hr/>
<h2>Exercises</h2>
<h3>Exercise 1 (Difficulty: Easy)</h3>
<p>From the six models implemented in this tutorial, select the most suitable model when data count is low (&lt; 100 entries) and explain why.</p>
<details>
<summary>Hint</summary>

Consider overfitting risk and model complexity.

</details>
<details>
<summary>Sample Answer</summary>

**Answer: Linear Regression**

**Reasons:**
1. **Low overfitting risk**: Fewer parameters means stability with limited data
2. **High interpretability**: Coefficients show feature influence clearly
3. **Fast training**: Low computational cost

**Other candidate: SVR**
- SVR is also effective for strong non-linearity
- However, requires hyperparameter tuning

With limited data, complex models (Random Forest, MLP) memorize training data, resulting in significantly lower performance on new data (overfitting).

</details>
<hr/>
<h3>Exercise 2 (Difficulty: Medium)</h3>
<p>Compare Grid Search and Random Search, and explain which method should be used in which situations.</p>
<details>
<summary>Hint</summary>

Consider search space size and time constraints.

</details>
<details>
<summary>Sample Answer</summary>

**When to use Grid Search:**
1. **Few hyperparameters to search** (2-3)
2. **Few candidates per parameter** (3-5 each)
3. **Sufficient computation time**
4. **Need guaranteed best solution**

**Example:** n_estimators=[50, 100, 200] √ó max_depth=[5, 10, 15] = 9 patterns

**When to use Random Search:**
1. **Many hyperparameters** (4+)
2. **Many candidates/continuous values**
3. **Limited computation time**
4. **Good enough solution sufficient**

**Example:** 5 parameters, 10 candidates each = 100,000 patterns ‚Üí Random Search with 100 samples

**General strategy:**
1. First use Random Search to narrow range (100-200 iterations)
2. Detailed search with Grid Search on promising range

</details>
<hr/>
<h3>Exercise 3 (Difficulty: Medium)</h3>
<p>The following error occurred. Explain the cause and solution.</p>
<pre><code>ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.
</code></pre>
<details>
<summary>Hint</summary>

This error occurs during MLPRegressor training.

</details>
<details>
<summary>Sample Answer</summary>

**Cause:**
MLPRegressor (Neural Network) training did not converge within specified iterations (max_iter).

**Possible factors:**
1. max_iter too small (default 200)
2. Learning rate too small (slow learning)
3. Improper data scaling (not standardized)
4. Model too complex (many layers, many neurons)

**Solutions:**

**Method 1: Increase max_iter**

<pre><code class="language-python">model_mlp = MLPRegressor(max_iter=1000)  # Default 200‚Üí1000
</code></pre>


**Method 2: Standardize data**

<pre><code class="language-python">from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)
</code></pre>


**Method 3: Adjust learning rate**

<pre><code class="language-python">model_mlp = MLPRegressor(
    learning_rate_init=0.01,  # Increase learning rate
    max_iter=500
)
</code></pre>


**Method 4: Enable Early Stopping**

<pre><code class="language-python">model_mlp = MLPRegressor(
    early_stopping=True,  # Stop if validation error doesn't improve
    validation_fraction=0.2,
    max_iter=1000
)
</code></pre>


**Recommended approach:**
First try Method 2 (data standardization), if still doesn't converge, combine Methods 1 and 4.

</details>
<hr/>
<h3>Exercise 4 (Difficulty: Hard)</h3>
<p>Write code to extract 5+ features from composition <code>"Li2O"</code> using Matminer.</p>
<details>
<summary>Hint</summary>

Use `ElementProperty` featurizer with `from_preset('magpie')`.

</details>
<details>
<summary>Sample Answer</summary>
<pre><code class="language-python">from matminer.featurizers.composition import ElementProperty
from pymatgen.core import Composition
import pandas as pd

# Create composition object
comp = Composition("Li2O")

# Initialize feature extractor with Magpie preset
featurizer = ElementProperty.from_preset('magpie')

# Calculate features
features = featurizer.featurize(comp)

# Get feature names
feature_names = featurizer.feature_labels()

# Convert to DataFrame (for readability)
df = pd.DataFrame([features], columns=feature_names)

print(f"===== Li2O Features (First 5) =====")
for i in range(5):
    print(f"{feature_names[i]}: {features[i]:.4f}")

print(f"\nTotal feature count: {len(features)}")
</code></pre>


**Expected output:**

<pre><code>===== Li2O Features (First 5) =====
MagpieData minimum Number: 3.0000
MagpieData maximum Number: 8.0000
MagpieData range Number: 5.0000
MagpieData mean Number: 5.3333
MagpieData avg_dev Number: 1.5556

Total feature count: 132
</code></pre>


**Explanation:**
- `MagpieData minimum Number`: Minimum atomic number (Li: 3)
- `MagpieData maximum Number`: Maximum atomic number (O: 8)
- `MagpieData range Number`: Atomic number range (8-3=5)
- `MagpieData mean Number`: Mean atomic number ((3+3+8)/3=5.33)
- `MagpieData avg_dev Number`: Average deviation of atomic numbers

Matminer automatically extracts 132 features (electronegativity, atomic radius, melting point, etc.).

</details>
<hr/>
<h3>Exercise 5 (Difficulty: Hard)</h3>
<p>Your band gap project achieved only R¬≤=0.5. Propose three concrete approaches to improve performance and explain implementation methods.</p>
<details>
<summary>Hint</summary>

Consider from three perspectives: features, model, and hyperparameters.

</details>
<details>
<summary>Sample Answer</summary>

**Approach 1: Feature Engineering (Most effective)**

**Implementation:**

<pre><code class="language-python">from matminer.featurizers.composition import ElementProperty
from pymatgen.core import Composition

# Extract atomic properties from composition
def extract_features(formula):
    comp = Composition(formula)
    featurizer = ElementProperty.from_preset('magpie')
    features = featurizer.featurize(comp)
    return features

# Add features to existing data
data_project['features'] = data_project['formula'].apply(extract_features)
# Expand to DataFrame (132-dimensional features)
features_df = pd.DataFrame(data_project['features'].tolist())
X_enhanced = features_df  # From 2 dimensions ‚Üí expanded to 132
</code></pre>


**Expected improvement:**
R¬≤ 0.5 ‚Üí 0.75-0.85 (significant feature increase)

---

**Approach 2: Ensemble Learning (combining multiple models)**

**Implementation:**

<pre><code class="language-python">from sklearn.ensemble import VotingRegressor

# Combine 3 models
model_rf = RandomForestRegressor(n_estimators=200, random_state=42)
model_lgb = lgb.LGBMRegressor(n_estimators=200, random_state=42)
model_svr = SVR(kernel='rbf', C=100)

# Ensemble model (average prediction)
ensemble = VotingRegressor([
    ('rf', model_rf),
    ('lgb', model_lgb),
    ('svr', model_svr)
])

ensemble.fit(X_train, y_train)
y_pred_ensemble = ensemble.predict(X_test)
</code></pre>


**Expected improvement:**
R¬≤ 0.5 ‚Üí 0.6-0.7 (more stable than single model)

---

**Approach 3: Hyperparameter Tuning**

**Implementation:**

<pre><code class="language-python">from sklearn.model_selection import RandomizedSearchCV
from scipy.stats import randint

param_dist = {
    'n_estimators': randint(100, 500),
    'max_depth': randint(10, 50),
    'min_samples_split': randint(2, 20),
    'min_samples_leaf': randint(1, 10)
}

random_search = RandomizedSearchCV(
    RandomForestRegressor(random_state=42),
    param_distributions=param_dist,
    n_iter=100,  # Try 100 patterns
    cv=5,
    scoring='neg_mean_absolute_error',
    n_jobs=-1,
    random_state=42
)

random_search.fit(X_train, y_train)
best_model = random_search.best_estimator_
</code></pre>


**Expected improvement:**
R¬≤ 0.5 ‚Üí 0.55-0.65 (optimization over default)

---

**Optimal strategy:**
1. First **Approach 1** (feature engineering) ‚Üí Maximum effect
2. Next **Approach 3** (hyperparameter tuning) for fine-tuning
3. Finally **Approach 2** (ensemble) for final performance boost

This sequence can target R¬≤ 0.5 ‚Üí 0.8+.

</details>
<hr/>
<h2>9. End-of-Chapter Checklist: Implementation Skills Quality Assurance</h2>
<p>Comprehensively check skills required to complete practical material property prediction projects.</p>
<h3>9.1 Environment Setup Skills</h3>
<h4>Basic Level</h4>
<ul>
<li>[ ] Python 3.9+ is installed</li>
<li>[ ] Can explain differences between three environment options (Anaconda/venv/Colab)</li>
<li>[ ] Can select optimal environment for your situation</li>
<li>[ ] Can create, activate, and deactivate virtual environments</li>
<li>[ ] Can install libraries with pip/conda</li>
<li>[ ] Can run environment verification code without errors</li>
</ul>
<h4>Advanced Level</h4>
<ul>
<li>[ ] Can create and use requirements.txt (<code>pip freeze &gt; requirements.txt</code>)</li>
<li>[ ] Can set environment variables (.env) and manage API keys securely</li>
<li>[ ] Can mount Google Drive in Google Colab to read data</li>
<li>[ ] Can use multiple virtual environments for different purposes</li>
<li>[ ] Can troubleshoot installation errors independently</li>
</ul>
<hr/>
<h3>9.2 Model Implementation Skills</h3>
<h4>Basic Level (6 Model Implementation)</h4>
<ul>
<li>[ ] Can implement linear regression and explain coefficient meaning</li>
<li>[ ] Can implement Random Forest and explain role of <code>n_estimators</code></li>
<li>[ ] Can install and implement LightGBM</li>
<li>[ ] Understand necessity of standardization (StandardScaler) for SVR</li>
<li>[ ] Can implement MLPRegressor (Neural Network)</li>
<li>[ ] Can retrieve data from Materials Project API (or create mock data)</li>
</ul>
<h4>Advanced Level (Model Selection and Evaluation)</h4>
<ul>
<li>[ ] Can select optimal model based on data count, time, interpretability constraints</li>
<li>[ ] Can compare models on three axes: MAE, R¬≤, training time</li>
<li>[ ] Can determine need for non-linear models when linear regression R¬≤ &lt; 0.5</li>
<li>[ ] Can detect overfitting with OOB score (Random Forest)</li>
<li>[ ] Can visualize learning curves and check training convergence</li>
</ul>
<h4>Expert Level (Ensemble and Applications)</h4>
<ul>
<li>[ ] Can combine multiple models with VotingRegressor</li>
<li>[ ] Can implement Stacking ensemble</li>
<li>[ ] Can evaluate generalization performance with cross-validation (5-fold CV)</li>
<li>[ ] Can calculate confidence intervals for predictions</li>
</ul>
<hr/>
<h3>9.3 Hyperparameter Tuning Skills</h3>
<h4>Basic Level</h4>
<ul>
<li>[ ] Can explain difference between hyperparameters and parameters</li>
<li>[ ] Can implement GridSearchCV to find best hyperparameters</li>
<li>[ ] Can implement RandomizedSearchCV and explain difference from Grid Search</li>
<li>[ ] Understand meaning of <code>cv=5</code> (5-fold cross-validation)</li>
<li>[ ] Can get best combination with <code>best_params_</code></li>
<li>[ ] Can check cross-validation score with <code>best_score_</code></li>
</ul>
<h4>Advanced Level</h4>
<ul>
<li>[ ] Can explain 4+ main Random Forest hyperparameters</li>
<li><code>n_estimators</code>: Number of trees</li>
<li><code>max_depth</code>: Tree depth</li>
<li><code>min_samples_split</code>: Minimum samples for split</li>
<li><code>min_samples_leaf</code>: Minimum samples in leaf</li>
<li>[ ] Understand trade-off between LightGBM's <code>learning_rate</code> and <code>n_estimators</code></li>
<li>[ ] Can implement Early Stopping to prevent overfitting</li>
<li>[ ] Can visualize hyperparameter impact</li>
</ul>
<h4>Expert Level</h4>
<ul>
<li>[ ] Can implement Bayesian Optimization (e.g., Optuna)</li>
<li>[ ] Can theoretically determine hyperparameter search ranges</li>
<li>[ ] Can implement Nested Cross-Validation</li>
</ul>
<hr/>
<h3>9.4 Feature Engineering Skills</h3>
<h4>Basic Level</h4>
<ul>
<li>[ ] Can create new features from element ratios (sum, difference, product, ratio)</li>
<li>[ ] Can get and visualize feature importance (feature_importances_)</li>
<li>[ ] Can remove low-importance features</li>
<li>[ ] Can select top K features with SelectKBest</li>
</ul>
<h4>Advanced Level (Matminer Utilization)</h4>
<ul>
<li>[ ] Can install and import Matminer</li>
<li>[ ] Can extract features from composition with ElementProperty featurizer</li>
<li>[ ] Can auto-generate 132-dimensional features with <code>from_preset('magpie')</code></li>
<li>[ ] Can integrate extracted features into DataFrame for machine learning</li>
<li>[ ] Understand meaning of Matminer features (electronegativity, atomic radius, melting point, etc.)</li>
</ul>
<h4>Expert Level</h4>
<ul>
<li>[ ] Can combine multiple featurizers (ElementProperty, Stoichiometry, OxidationStates)</li>
<li>[ ] Can design material-specific features using domain knowledge</li>
<li>[ ] Can detect and handle multicollinearity (VIF: Variance Inflation Factor)</li>
<li>[ ] Can implement dimensionality reduction (PCA, t-SNE) and visualize features</li>
</ul>
<hr/>
<h3>9.5 Data Processing Skills</h3>
<h4>Basic Level</h4>
<ul>
<li>[ ] Can split data with train_test_split (80% vs 20%)</li>
<li>[ ] Ensure reproducibility with <code>random_state=42</code></li>
<li>[ ] Can check basic statistics (mean, std, min, max)</li>
<li>[ ] Can detect missing values (NaN) with <code>df.isnull().sum()</code></li>
<li>[ ] Can remove or fill missing values (<code>dropna()</code> or <code>fillna()</code>)</li>
</ul>
<h4>Advanced Level</h4>
<ul>
<li>[ ] Can standardize data with StandardScaler (mean 0, std 1)</li>
<li>[ ] Can normalize to 0-1 with MinMaxScaler</li>
<li>[ ] Can convert categorical variables to dummy variables (<code>pd.get_dummies()</code>)</li>
<li>[ ] Can detect and handle outliers (IQR method, Z-score method)</li>
<li>[ ] Understand correct preprocessing order to prevent data leakage</li>
<li>‚ùå Wrong: Standardize all data ‚Üí split</li>
<li>‚úÖ Correct: Split ‚Üí standardize on training data ‚Üí apply to test data</li>
</ul>
<h4>Expert Level</h4>
<ul>
<li>[ ] Can handle imbalanced data with SMOTE (oversampling)</li>
<li>[ ] Can implement time-ordered splitting for time series (TimeSeriesSplit)</li>
<li>[ ] Can integrate data processing and model training with Pipeline (sklearn.pipeline)</li>
</ul>
<hr/>
<h3>9.6 Evaluation &amp; Visualization Skills</h3>
<h4>Basic Level</h4>
<ul>
<li>[ ] Can calculate and interpret MAE (Mean Absolute Error)</li>
<li>[ ] Can calculate and interpret R¬≤ (closer to 1 is better)</li>
<li>[ ] Can measure training time (<code>time.time()</code>)</li>
<li>[ ] Can create predicted vs actual scatter plots</li>
<li>[ ] Can create model performance comparison tables</li>
</ul>
<h4>Advanced Level</h4>
<ul>
<li>[ ] Can visualize learning curves (Loss curve)</li>
<li>[ ] Can create residual plots and detect model bias</li>
<li>[ ] Can create and interpret confusion matrix (for classification)</li>
<li>[ ] Can graph feature importance</li>
<li>[ ] Can visualize hyperparameter impact in 2D plots</li>
</ul>
<h4>Expert Level</h4>
<ul>
<li>[ ] Can explain prediction reasons with SHAP values</li>
<li>[ ] Can visualize feature impact with Partial Dependence Plot (PDP)</li>
<li>[ ] Can analyze training data amount impact with Learning Curve</li>
</ul>
<hr/>
<h3>9.7 Troubleshooting Skills</h3>
<h4>Basic Level (Error Handling)</h4>
<ul>
<li>[ ] Can resolve <code>ModuleNotFoundError</code> (<code>pip install</code>)</li>
<li>[ ] Can resolve <code>ValueError: Input contains NaN</code> (handle missing values)</li>
<li>[ ] Can resolve <code>ConvergenceWarning</code> (MLP convergence error)</li>
<li>Increase <code>max_iter</code></li>
<li>Standardize data</li>
<li>Enable Early Stopping</li>
<li>[ ] Can read error messages, search, and find solutions</li>
</ul>
<h4>Advanced Level (Performance Improvement)</h4>
<ul>
<li>[ ] Can implement 3+ improvement strategies when R¬≤ &lt; 0.5</li>
<li>Feature engineering</li>
<li>Model change (linear‚Üínon-linear)</li>
<li>Hyperparameter tuning</li>
<li>[ ] Can detect overfitting (training error ‚â™ test error)</li>
<li>[ ] Can detect underfitting (both training and test errors large)</li>
<li>[ ] Can execute 5-step debugging
  1. Data verification
  2. Data visualization
  3. Test with small data
  4. Model simplification
  5. Read error messages</li>
</ul>
<h4>Expert Level (Systematic Debugging)</h4>
<ul>
<li>[ ] Can identify execution time bottlenecks with profiling (cProfile)</li>
<li>[ ] Can monitor memory usage and prevent MemoryError</li>
<li>[ ] Can set up logging to record training process</li>
<li>[ ] Can track experiments with version control (Git)</li>
</ul>
<hr/>
<h3>9.8 Project Completion Skills</h3>
<h4>Essential Skills (Band Gap Prediction Project)</h4>
<ul>
<li>[ ] Understand project goals (R¬≤ &gt; 0.7, MAE &lt; 0.5 eV)</li>
<li>[ ] Completed data collection (Materials Project API or mock data)</li>
<li>[ ] Performed feature engineering</li>
<li>[ ] Split data into training/testing (80% vs 20%)</li>
<li>[ ] Built prediction model with Random Forest or LightGBM</li>
<li>[ ] Evaluated performance with MAE and R¬≤</li>
<li>[ ] Visualized prediction results (scatter plot)</li>
<li>[ ] Determined goal achievement/non-achievement</li>
</ul>
<h4>Advanced Skills</h4>
<ul>
<li>[ ] Beginner challenge: Build prediction model for different properties (melting point, formation energy)</li>
<li>[ ] Intermediate challenge: Extract 130+ features with Matminer to improve performance</li>
<li>[ ] Advanced challenge: Improve performance with ensemble learning</li>
<li>[ ] Advanced challenge: Predict with Neural Network (MLP)</li>
</ul>
<hr/>
<h3>9.9 Code Quality Skills</h3>
<h4>Basic Level</h4>
<ul>
<li>[ ] All code includes dependency library versions in comments
  <code>python
  # Dependencies: Python 3.9+, scikit-learn 1.3+, numpy 1.24+</code></li>
<li>[ ] Random seed fixed for reproducibility (<code>random_state=42</code>)</li>
<li>[ ] Performed data validation (shape, dtype, NaN, range)</li>
<li>[ ] Clear variable names (<code>X_train</code>, <code>y_test</code>, <code>model_rf</code>)</li>
<li>[ ] Comments explain processing purpose</li>
</ul>
<h4>Advanced Level</h4>
<ul>
<li>[ ] Functionalized code for reusability
  <code>python
  def train_and_evaluate(model, X_train, X_test, y_train, y_test):
      model.fit(X_train, y_train)
      y_pred = model.predict(X_test)
      mae = mean_absolute_error(y_test, y_pred)
      r2 = r2_score(y_test, y_pred)
      return mae, r2</code></li>
<li>[ ] Implemented error handling with try-except</li>
<li>[ ] Record training process with logging</li>
<li>[ ] Can convert Jupyter Notebook to script (.py)</li>
<li>[ ] Environment reproducible with requirements.txt</li>
</ul>
<hr/>
<h3>9.10 Overall Assessment: Project Completion Level</h3>
<p>Check your achievement level with the following assessments.</p>
<h4>Level 1: Beginner</h4>
<ul>
<li>Environment setup skills: 100% basic level achieved</li>
<li>Model implementation skills: 3+ out of 6 basic level implemented</li>
<li>Troubleshooting: Solve basic level errors independently</li>
</ul>
<p><strong>Achievement goal:</strong> Can implement linear regression and Random Forest, calculate MAE and R¬≤</p>
<hr/>
<h4>Level 2: Intermediate</h4>
<ul>
<li>Environment setup skills: 80%+ advanced level achieved</li>
<li>Model implementation skills: 100% basic + 50%+ advanced achieved</li>
<li>Hyperparameter tuning: 100% basic level achieved</li>
<li>Feature engineering: 100% basic level achieved</li>
<li>Project completion skills: 100% essential skills achieved</li>
</ul>
<p><strong>Achievement goal:</strong> Achieve R¬≤ &gt; 0.7, MAE &lt; 0.5 eV in band gap prediction project</p>
<hr/>
<h4>Level 3: Advanced</h4>
<ul>
<li>All categories: 100% advanced level achieved</li>
<li>Hyperparameter tuning: 50%+ expert level</li>
<li>Feature engineering: 100% expert level (Matminer utilization) achieved</li>
<li>Project completion skills: 2+ advanced skills achieved</li>
</ul>
<p><strong>Achievement goal:</strong> Extract 130 features with Matminer, achieve R¬≤ &gt; 0.85 with ensemble learning</p>
<hr/>
<h4>Level 4: Expert</h4>
<ul>
<li>All categories: 80%+ expert level achieved</li>
<li>Code quality: 100% advanced level achieved</li>
<li>Project completion skills: All advanced skills achieved</li>
<li>Can propose and implement 3+ original improvements</li>
</ul>
<p><strong>Achievement goal:</strong>
- Retrieve real data from Materials Project API
- Hyperparameter optimization with Bayesian optimization
- Achieve model explainability with SHAP values
- R¬≤ &gt; 0.90, practical-level prediction accuracy</p>
<hr/>
<h3>9.11 Readiness Check for Next Steps</h3>
<p>Check if you're ready for the next learning stage with the following checklist.</p>
<h4>Preparation for Deep Learning (GNN, CGCNN)</h4>
<ul>
<li>[ ] Implemented Neural Network (MLP) and understand ReLU, Adam, Early Stopping</li>
<li>[ ] Can visualize learning curves and detect overfitting</li>
<li>[ ] Understand importance of data standardization</li>
<li>[ ] Can explain loss functions (MSE, MAE) and backpropagation concepts</li>
</ul>
<h4>Preparation for Bayesian Optimization</h4>
<ul>
<li>[ ] Can implement hyperparameter tuning (Grid Search, Random Search)</li>
<li>[ ] Can evaluate generalization performance with cross-validation</li>
<li>[ ] Can set hyperparameter search space</li>
</ul>
<h4>Preparation for Transfer Learning</h4>
<ul>
<li>[ ] Understand pre-trained model concepts</li>
<li>[ ] Can explain necessity of fine-tuning</li>
<li>[ ] Know Domain Adaptation concepts</li>
</ul>
<h4>Preparation for Practical Projects</h4>
<ul>
<li>[ ] Can version control code with Git</li>
<li>[ ] Can convert Jupyter Notebook to Python script</li>
<li>[ ] Environment reproducible with requirements.txt</li>
<li>[ ] Can compile experimental results into Markdown/PDF reports</li>
<li>[ ] Can save and load prediction models with pickle/joblib</li>
<li>[ ] Can manage API keys securely in .env file</li>
</ul>
<hr/>
<p><strong>Checklist Usage Tips:</strong>
1. <strong>Review regularly</strong>: Re-check after learning, 1 week, 1 month later
2. <strong>Prioritize unachieved items</strong>: Focus learning on unchecked items
3. <strong>Record level assessment</strong>: Visualize growth to maintain motivation
4. <strong>Use in practice</strong>: Confirm essential skills before project start</p>
<hr/>
<h2>References</h2>
<ol>
<li>
<p>Pedregosa, F., et al. (2011). "Scikit-learn: Machine Learning in Python." <em>Journal of Machine Learning Research</em>, 12, 2825-2830.
   URL: https://scikit-learn.org
   <em>Official scikit-learn documentation. Detailed explanations and tutorials for all algorithms.</em></p>
</li>
<li>
<p>Ward, L., et al. (2018). "Matminer: An open source toolkit for materials data mining." <em>Computational Materials Science</em>, 152, 60-69.
   DOI: <a href="https://doi.org/10.1016/j.commatsci.2018.05.018">10.1016/j.commatsci.2018.05.018</a>
   GitHub: https://github.com/hackingmaterials/matminer
   <em>Feature extraction library for materials science. Auto-generates 132 types of materials descriptors.</em></p>
</li>
<li>
<p>Jain, A., et al. (2013). "Commentary: The Materials Project: A materials genome approach to accelerating materials innovation." <em>APL Materials</em>, 1(1), 011002.
   DOI: <a href="https://doi.org/10.1063/1.4812323">10.1063/1.4812323</a>
   URL: https://materialsproject.org
   <em>Official Materials Project paper. Database of 140,000+ materials.</em></p>
</li>
<li>
<p>Ke, G., et al. (2017). "LightGBM: A Highly Efficient Gradient Boosting Decision Tree." <em>Advances in Neural Information Processing Systems</em>, 30, 3146-3154.
   GitHub: https://github.com/microsoft/LightGBM
   <em>Official LightGBM paper. High-speed gradient boosting implementation.</em></p>
</li>
<li>
<p>Bergstra, J., &amp; Bengio, Y. (2012). "Random Search for Hyper-Parameter Optimization." <em>Journal of Machine Learning Research</em>, 13, 281-305.
   URL: https://www.jmlr.org/papers/v13/bergstra12a.html
   <em>Theoretical background of Random Search. More efficient search method than Grid Search.</em></p>
</li>
<li>
<p>Raschka, S., &amp; Mirjalili, V. (2019). <em>Python Machine Learning, 3rd Edition</em>. Packt Publishing.
   <em>Comprehensive machine learning textbook in Python. Detailed practical scikit-learn usage.</em></p>
</li>
<li>
<p>scikit-learn User Guide. (2024). "Hyperparameter tuning."
   URL: https://scikit-learn.org/stable/modules/grid_search.html
   <em>Official hyperparameter tuning guide. Details on Grid Search and Random Search.</em></p>
</li>
</ol>
<hr/>
<p><strong>Created</strong>: 2025-10-16
<strong>Version</strong>: 3.0
<strong>Template</strong>: content_agent_prompts.py v1.0
<strong>Author</strong>: MI Knowledge Hub Project</p><div class="navigation">
<a class="nav-button" href="chapter2-fundamentals.html">‚Üê Previous Chapter</a>
<a class="nav-button" href="index.html">Back to Series Index</a>
<a class="nav-button" href="chapter4-real-world.html">Next Chapter ‚Üí</a>
</div>
</main>
<section class="disclaimer">
<h3>Disclaimer</h3>
<ul>
<li>This content is for educational, research, and informational purposes only and does not provide professional advice (legal, accounting, technical guarantees, etc.).</li>
<li>This content and accompanying code examples are provided "AS IS" without warranty of any kind, express or implied, including but not limited to warranties of merchantability, fitness for a particular purpose, non-infringement, accuracy, completeness, operation, or safety.</li>
<li>The creator and Tohoku University assume no responsibility for the content, availability, or safety of external links, third-party data, tools, libraries, etc.</li>
<li>To the maximum extent permitted by applicable law, the creator and Tohoku University are not liable for any direct, indirect, incidental, special, consequential, or punitive damages arising from the use, execution, or interpretation of this content.</li>
<li>The content of this material is subject to change, update, or discontinuation without notice.</li>
<li>Copyright and license of this content follows specified terms (e.g., CC BY 4.0). Such licenses typically include no-warranty clauses.</li>
</ul>
</section>
<footer>
<p><strong>Creator</strong>: AI Terakoya Content Team</p>
<p><strong>Version</strong>: 3.0 | <strong>Created</strong>: 2025-10-16</p>
<p><strong>License</strong>: Creative Commons BY 4.0</p>
<p>¬© 2025 AI Terakoya. All rights reserved.</p>
</footer>
</body>
</html>
