<!DOCTYPE html>

<html lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>Chapter 4: Active Learning Strategies - AI Terakoya</title>
<link href="../../assets/css/knowledge-base.css" rel="stylesheet"/>
<script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
<script>
        mermaid.initialize({ startOnLoad: true, theme: 'default', securityLevel: 'strict' });
    </script>
<!-- MathJax for LaTeX equation rendering -->
<script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\(', '\)']],
                displayMath: [['$$', '$$'], ['\[', '\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
                ignoreHtmlClass: 'mermaid'
            }
        };
    </script>
<script async="" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>
<nav class="breadcrumb">
<div class="breadcrumb-content">
<a href="/AI-Knowledge-Notes/knowledge/en/index.html">AI Terakoya Home</a><span class="breadcrumb-separator">‚Ä∫</span><a href="/AI-Knowledge-Notes/knowledge/en/MI/index.html">Materials Informatics</a><span class="breadcrumb-separator">‚Ä∫</span><a href="/AI-Knowledge-Notes/knowledge/en/MI/bayesian-optimization-introduction/index.html">Bayesian Optimization</a><span class="breadcrumb-separator">‚Ä∫</span><span class="breadcrumb-current">Chapter 4</span>
</div>
</nav><div class="locale-switcher">
<span class="current-locale">üåê EN</span>
<span class="locale-separator">|</span>
<a class="locale-link" href="../../../jp/MI/bayesian-optimization-introduction/chapter-4.html">Êó•Êú¨Ë™û</a>
<span class="locale-meta">Last sync: 2025-11-16</span>
</div>

<header>
<div class="header-content">
<h1>Chapter 4: Active Learning Strategies</h1>
<p class="subtitle">Next-Generation Materials Development through Autonomous Experimental Systems</p>
<div class="meta">
<span class="meta-item">üìñ Reading Time: 20-25 min</span>
<span class="meta-item">üìä Difficulty: Intermediate</span>
<span class="meta-item">üíª Code Examples: 8</span>
<span class="meta-item">üìù Exercises: 3</span>
</div>
</div>
</header>
<main class="container">
<h1>Chapter 4: Active Learning Strategies</h1>
<p><strong>Next-Generation Materials Development through Autonomous Experimental Systems</strong></p>
<h2>Learning Objectives</h2>
<p>By reading this chapter, you will be able to:</p>
<ul>
<li>‚úÖ Explain the differences between Active Learning and Bayesian Optimization</li>
<li>‚úÖ Implement three major strategies (uncertainty, diversity, model change)</li>
<li>‚úÖ Design closed-loop optimization systems</li>
<li>‚úÖ Gain practical knowledge from real-world success cases (Berkeley A-Lab, RoboRXN, etc.)</li>
<li>‚úÖ Understand career paths and next learning steps</li>
</ul>
<p><strong>Reading Time</strong>: 20-25 min
<strong>Code Examples</strong>: 8
<strong>Exercises</strong>: 3</p>
<hr/>
<h2>4.1 What is Active Learning?</h2>
<h3>Differences and Similarities with Bayesian Optimization</h3>
<p>The <strong>Bayesian Optimization</strong> we learned in previous chapters focused on maximizing (or minimizing) an objective function. On the other hand, <strong>Active Learning</strong> is a broader concept.</p>
<p><strong>Definition</strong>:</p>
<blockquote>
<p>Active Learning is a technique that efficiently improves the performance of machine learning models by <strong>actively selecting the most informative data points</strong>.</p>
</blockquote>
<p><strong>Relationship between Bayesian Optimization and Active Learning</strong>:</p>
<div class="mermaid">
flowchart TB
    A[Active Learning\nBroad Concept] --&gt; B[Goal: Model Improvement]
    A --&gt; C[Goal: Exploration Efficiency]
    A --&gt; D[Goal: Classification Accuracy]

    C --&gt; E[Bayesian Optimization\nSpecial Case]
    E --&gt; F[Specialized in Objective Function Maximization]

    B --&gt; G[Uncertainty Reduction]
    D --&gt; H[Decision Boundary Refinement]

    style A fill:#e3f2fd
    style E fill:#fff3e0
    style F fill:#f3e5f5
</div>
<p><strong>Similarities</strong>:
- Learning from past data
- Exploiting uncertainty
- Sequential sampling
- Efficient exploration</p>
<p><strong>Differences</strong>:
- <strong>Bayesian Optimization</strong>: Clear goal of maximizing/minimizing objective function
- <strong>Active Learning</strong>: Diverse goals such as improving model generalization performance, refining classification boundaries</p>
<h3>Importance in Materials Science</h3>
<p>In materials science, Active Learning demonstrates its power in the following situations:</p>
<ol>
<li>
<p><strong>Understanding the Search Space</strong>
   - When the objective function is unknown or complex
   - When we first want to understand the structure of the search space</p>
</li>
<li>
<p><strong>Discovery of Diverse Materials</strong>
   - When we need diverse candidates, not just the optimal solution
   - Example: Materials that can support multiple applications</p>
</li>
<li>
<p><strong>Model Improvement</strong>
   - When improving prediction model accuracy is the top priority
   - Optimization of experimental design</p>
</li>
</ol>
<hr/>
<h2>4.2 Three Major Active Learning Strategies</h2>
<h3>Strategy 1: Uncertainty Sampling</h3>
<p><strong>Basic Idea</strong>:
Select points with the <strong>highest prediction uncertainty</strong>.</p>
<p><strong>Mathematical Definition</strong>:
$$
x_{\text{next}} = \arg\max_{x} \sigma(x)
$$</p>
<p>where $\sigma(x)$ is the prediction standard deviation of the Gaussian Process.</p>
<p><strong>Characteristics</strong>:
- Most simple and intuitive
- Directly reduces prediction model uncertainty
- Efficiently covers the entire search space</p>
<p><strong>Code Example 1: Implementation of Uncertainty Sampling</strong></p>
<pre><code class="language-python"># Uncertainty Sampling
import numpy as np
import matplotlib.pyplot as plt
from sklearn.gaussian_process import GaussianProcessRegressor
from sklearn.gaussian_process.kernels import RBF, ConstantKernel

# Objective function (assumed unknown)
def true_function(x):
    """Material property (e.g., catalyst activity)"""
    return (
        np.sin(3 * x) * np.exp(-x) +
        0.7 * np.exp(-((x - 0.5) / 0.2)**2)
    )

# Uncertainty Sampling
def uncertainty_sampling(gp, X_candidate):
    """
    Select the point with maximum uncertainty

    Parameters:
    -----------
    gp : GaussianProcessRegressor
        Trained Gaussian Process model
    X_candidate : array
        Candidate points

    Returns:
    --------
    next_x : float
        Next experimental point
    """
    # Calculate prediction standard deviation
    _, std = gp.predict(X_candidate.reshape(-1, 1), return_std=True)

    # Select the point with maximum uncertainty
    next_idx = np.argmax(std)
    next_x = X_candidate[next_idx]

    return next_x, std

# Demonstration
np.random.seed(42)

# Initial sampling (few experiments)
X_train = np.array([0.1, 0.5, 0.9]).reshape(-1, 1)
y_train = true_function(X_train).ravel()

# Train Gaussian Process model
kernel = ConstantKernel(1.0) * RBF(length_scale=0.15)
gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10)
gp.fit(X_train, y_train)

# Candidate points
X_candidate = np.linspace(0, 1, 500)

# Uncertainty sampling
next_x, std = uncertainty_sampling(gp, X_candidate)

# Prediction
X_test = np.linspace(0, 1, 200).reshape(-1, 1)
y_pred, y_std = gp.predict(X_test, return_std=True)

# Visualization
plt.figure(figsize=(12, 6))

# True function
plt.plot(X_test, true_function(X_test), 'k--', linewidth=2,
         label='True Function')

# Observed data
plt.scatter(X_train, y_train, c='red', s=150, zorder=10,
            edgecolors='black', label='Observed Data')

# Prediction mean
plt.plot(X_test, y_pred, 'b-', linewidth=2, label='Predicted Mean')

# Uncertainty (95% confidence interval)
plt.fill_between(X_test.ravel(), y_pred - 1.96 * y_std,
                 y_pred + 1.96 * y_std, alpha=0.3,
                 color='blue', label='95% Confidence Interval')

# Proposed point
plt.axvline(next_x, color='orange', linestyle='--', linewidth=3,
            label=f'Proposed Point x={next_x:.3f}')
plt.scatter([next_x], [true_function(np.array([[next_x]]))[0]],
            c='orange', s=200, marker='*', zorder=10,
            edgecolors='black', label='Next Experiment Point')

plt.xlabel('Parameter x', fontsize=12)
plt.ylabel('Property Value y (Catalyst Activity)', fontsize=12)
plt.title('Uncertainty Sampling Strategy', fontsize=14)
plt.legend(loc='best')
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.savefig('uncertainty_sampling_demo.png', dpi=150,
            bbox_inches='tight')
plt.show()

print("Uncertainty Sampling Results:")
print(f"  Proposed point: x = {next_x:.3f}")
print(f"  Maximum uncertainty: œÉ = {np.max(std):.4f}")
print(f"  Predicted value: y = {gp.predict([[next_x]])[0]:.3f}")
print("\nStrategy:")
print("  - Prioritize regions farthest from observed data")
print("  - Efficiently reduce model uncertainty")
print("  - Cover the entire search space in a balanced manner")
</code></pre>
<p><strong>Output</strong>:</p>
<pre><code>Uncertainty Sampling Results:
  Proposed point: x = 0.247
  Maximum uncertainty: œÉ = 0.4521
  Predicted value: y = 0.482

Strategy:
  - Prioritize regions farthest from observed data
  - Efficiently reduce model uncertainty
  - Cover the entire search space in a balanced manner
</code></pre>
<hr/>
<h3>Strategy 2: Diversity Sampling</h3>
<p><strong>Basic Idea</strong>:
Select <strong>different regions</strong> from existing data points to ensure diversity in the search space.</p>
<p><strong>Implementation Methods</strong>:
- <strong>K-means Clustering</strong>: Partition the search space and select representative points from each cluster
- <strong>MaxMin Distance</strong>: Select the point farthest from existing points
- <strong>Determinantal Point Process (DPP)</strong>: Probabilistically generate diverse point sets</p>
<p><strong>Code Example 2: Implementation of Diversity Sampling</strong></p>
<pre><code class="language-python"># Diversity Sampling (MaxMin Strategy)
from scipy.spatial.distance import cdist

def diversity_sampling(X_sampled, X_candidate):
    """
    Select the point farthest from existing data

    Parameters:
    -----------
    X_sampled : array (n_sampled, n_features)
        Already sampled points
    X_candidate : array (n_candidates, n_features)
        Candidate points

    Returns:
    --------
    next_x : array
        Next experimental point
    """
    # Calculate minimum distance from each candidate to existing points
    distances = cdist(X_candidate, X_sampled, metric='euclidean')
    min_distances = np.min(distances, axis=1)

    # Select the point with maximum minimum distance (MaxMin strategy)
    next_idx = np.argmax(min_distances)
    next_x = X_candidate[next_idx]

    return next_x, min_distances

# Demonstration (2D)
np.random.seed(42)

# 2D search space
n_candidates = 1000
X_candidate_2d = np.random.uniform(0, 1, (n_candidates, 2))

# Initial sampling
X_sampled_2d = np.array([[0.2, 0.3], [0.7, 0.8], [0.5, 0.5]])

# 5 iterations of diversity sampling
fig, axes = plt.subplots(1, 3, figsize=(15, 5))

for i, ax in enumerate(axes):
    # Diversity sampling
    next_x, min_dists = diversity_sampling(X_sampled_2d,
                                            X_candidate_2d)

    # Plot
    scatter = ax.scatter(X_candidate_2d[:, 0], X_candidate_2d[:, 1],
                         c=min_dists, cmap='viridis', s=10, alpha=0.5,
                         vmin=0, vmax=0.5)
    ax.scatter(X_sampled_2d[:, 0], X_sampled_2d[:, 1],
               c='red', s=150, marker='o', edgecolors='black',
               label='Existing Data', zorder=10)
    ax.scatter(next_x[0], next_x[1], c='orange', s=300,
               marker='*', edgecolors='black',
               label='Next Experiment Point', zorder=10)

    ax.set_xlabel('Parameter x1', fontsize=12)
    ax.set_ylabel('Parameter x2', fontsize=12)
    ax.set_title(f'Iteration {i+1}', fontsize=14)
    ax.legend(loc='best')
    ax.set_xlim([0, 1])
    ax.set_ylim([0, 1])

    # Add for next iteration
    if i &lt; 2:
        X_sampled_2d = np.vstack([X_sampled_2d, next_x])

plt.colorbar(scatter, ax=axes[-1], label='Minimum Distance from Existing Points')
plt.tight_layout()
plt.savefig('diversity_sampling_demo.png', dpi=150,
            bbox_inches='tight')
plt.show()

print("Characteristics of Diversity Sampling:")
print("  - Uniformly covers the search space")
print("  - Corrects bias in existing data")
print("  - Effective for discovering diverse material candidates")
</code></pre>
<p><strong>Important Observations</strong>:
- Proposed points are always in locations away from existing data
- The search space is gradually covered uniformly
- Less likely to fall into local optima</p>
<hr/>
<h3>Strategy 3: Expected Model Change</h3>
<p><strong>Basic Idea</strong>:
When adding a new data point, select the point where the <strong>model change is maximized</strong>.</p>
<p><strong>Mathematical Definition</strong>:
$$
x_{\text{next}} = \arg\max_{x} ||\theta_{\text{new}} - \theta_{\text{old}}||
$$</p>
<p>where $\theta$ represents the model parameters.</p>
<p><strong>Implementation Considerations</strong>:
- Use Fisher information
- Prioritize high-impact data points
- Computationally expensive (use approximation methods)</p>
<p><strong>Code Example 3: Integrated Comparison of Three Strategies</strong></p>
<pre><code class="language-python"># Integrated comparison of three strategies
def compare_strategies(n_iterations=10):
    """
    Compare three Active Learning strategies

    Parameters:
    -----------
    n_iterations : int
        Number of sampling iterations

    Returns:
    --------
    results : dict
        Results for each strategy
    """
    # Initial data
    np.random.seed(42)
    X_init = np.array([0.15, 0.45, 0.75]).reshape(-1, 1)
    y_init = true_function(X_init).ravel()

    # Candidate points
    X_candidate = np.linspace(0, 1, 500)

    # Store results
    results = {
        'uncertainty': {'X': X_init.copy(), 'y': y_init.copy()},
        'diversity': {'X': X_init.copy(), 'y': y_init.copy()},
        'random': {'X': X_init.copy(), 'y': y_init.copy()}
    }

    for i in range(n_iterations):
        # Strategy 1: Uncertainty sampling
        kernel = ConstantKernel(1.0) * RBF(length_scale=0.15)
        gp = GaussianProcessRegressor(kernel=kernel,
                                        n_restarts_optimizer=10)
        gp.fit(results['uncertainty']['X'], results['uncertainty']['y'])
        next_x_unc, _ = uncertainty_sampling(gp, X_candidate)
        next_y_unc = true_function(np.array([[next_x_unc]]))[0]
        results['uncertainty']['X'] = np.vstack(
            [results['uncertainty']['X'], [[next_x_unc]]]
        )
        results['uncertainty']['y'] = np.append(
            results['uncertainty']['y'], next_y_unc
        )

        # Strategy 2: Diversity sampling
        next_x_div, _ = diversity_sampling(
            results['diversity']['X'],
            X_candidate.reshape(-1, 1)
        )
        next_y_div = true_function(next_x_div.reshape(-1, 1))[0]
        results['diversity']['X'] = np.vstack(
            [results['diversity']['X'], next_x_div.reshape(1, -1)]
        )
        results['diversity']['y'] = np.append(
            results['diversity']['y'], next_y_div
        )

        # Random (for comparison)
        next_x_rand = np.random.choice(X_candidate)
        next_y_rand = true_function(np.array([[next_x_rand]]))[0]
        results['random']['X'] = np.vstack(
            [results['random']['X'], [[next_x_rand]]]
        )
        results['random']['y'] = np.append(
            results['random']['y'], next_y_rand
        )

    return results

# Execute
results = compare_strategies(n_iterations=7)

# Visualization
fig, axes = plt.subplots(1, 3, figsize=(15, 5))
strategies = ['uncertainty', 'diversity', 'random']
titles = ['Uncertainty Sampling', 'Diversity Sampling', 'Random (Reference)']
colors = ['blue', 'green', 'gray']

X_test = np.linspace(0, 1, 200)
y_true = true_function(X_test)

for ax, strategy, title, color in zip(axes, strategies, titles, colors):
    # True function
    ax.plot(X_test, y_true, 'k--', linewidth=2, label='True Function')

    # Sampling points
    X = results[strategy]['X']
    y = results[strategy]['y']

    # Initial points (red) and added points (strategy-specific color)
    ax.scatter(X[:3], y[:3], c='red', s=150, marker='o',
               edgecolors='black', label='Initial Points', zorder=10)
    ax.scatter(X[3:], y[3:], c=color, s=100, marker='^',
               edgecolors='black', label='Added Points', zorder=10, alpha=0.7)

    # Gaussian Process prediction
    kernel = ConstantKernel(1.0) * RBF(length_scale=0.15)
    gp = GaussianProcessRegressor(kernel=kernel,
                                    n_restarts_optimizer=10)
    gp.fit(X, y)
    y_pred, y_std = gp.predict(X_test.reshape(-1, 1), return_std=True)

    ax.plot(X_test, y_pred, '-', color=color, linewidth=2,
            label='Predicted Mean')
    ax.fill_between(X_test, y_pred - 1.96 * y_std,
                     y_pred + 1.96 * y_std, alpha=0.2, color=color)

    ax.set_xlabel('Parameter x', fontsize=12)
    ax.set_ylabel('Property Value y', fontsize=12)
    ax.set_title(title, fontsize=14)
    ax.legend(loc='best')
    ax.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('strategies_comparison.png', dpi=150, bbox_inches='tight')
plt.show()

# Performance evaluation
print("Performance Comparison by Strategy:")
print("=" * 60)
for strategy, title in zip(strategies, titles):
    X = results[strategy]['X']
    y = results[strategy]['y']

    # True optimal value
    true_optimal = np.max(y_true)

    # Best value found
    best_found = np.max(y)

    # Achievement rate
    achievement = (best_found / true_optimal) * 100

    # RMSE (prediction accuracy)
    kernel = ConstantKernel(1.0) * RBF(length_scale=0.15)
    gp = GaussianProcessRegressor(kernel=kernel,
                                    n_restarts_optimizer=10)
    gp.fit(X, y)
    y_pred = gp.predict(X_test.reshape(-1, 1))
    rmse = np.sqrt(np.mean((y_pred - y_true)**2))

    print(f"\n{title}:")
    print(f"  Sample count: {len(X)}")
    print(f"  Best value: {best_found:.4f}")
    print(f"  Achievement rate: {achievement:.1f}%")
    print(f"  Prediction RMSE: {rmse:.4f}")
</code></pre>
<p><strong>Expected Output</strong>:</p>
<pre><code>Performance Comparison by Strategy:
============================================================

Uncertainty Sampling:
  Sample count: 10
  Best value: 0.7234
  Achievement rate: 97.8%
  Prediction RMSE: 0.0421

Diversity Sampling:
  Sample count: 10
  Best value: 0.6912
  Achievement rate: 93.5%
  Prediction RMSE: 0.0389

Random (Reference):
  Sample count: 10
  Best value: 0.6523
  Achievement rate: 88.2%
  Prediction RMSE: 0.0512
</code></pre>
<p><strong>Key Insights</strong>:
- <strong>Uncertainty Sampling</strong>: Excellent for finding the best value
- <strong>Diversity Sampling</strong>: Excellent for understanding the search space
- <strong>Practice</strong>: Select or combine strategies depending on the objective</p>
<hr/>
<h2>4.3 Closed-Loop Optimization</h2>
<h3>Integration with Autonomous Experimental Systems</h3>
<p>Closed-loop optimization <strong>directly connects experimental equipment with AI</strong> to build autonomous systems that operate 24/7.</p>
<h3>System Architecture</h3>
<div class="mermaid">
flowchart TB
    subgraph "AI Engine"
    A[Machine Learning Model\nGaussian Process] --&gt; B[Acquisition Function\nNext Experiment Proposal]
    end

    subgraph "Experimental Equipment"
    C[Robotic Arm\nMaterial Synthesis] --&gt; D[Measurement Device\nProperty Evaluation]
    end

    subgraph "Data Management"
    E[Database\nExperiment History] --&gt; F[Visualization\nProgress Monitoring]
    end

    B --&gt; C
    D --&gt; E
    E --&gt; A

    G[Human Researcher\nGoal Setting &amp; Monitoring] -.-&gt; B
    F -.-&gt; G

    style A fill:#e3f2fd
    style C fill:#fff3e0
    style E fill:#f3e5f5
    style G fill:#e8f5e9
</div>
<p><strong>Components</strong>:
1. <strong>AI Engine</strong>: Bayesian Optimization &amp; Active Learning
2. <strong>Experimental Equipment</strong>: Robotics, automated measurement
3. <strong>Data Management</strong>: Real-time database, visualization
4. <strong>Human</strong>: Goal setting, anomaly monitoring, final decisions</p>
<h3>Closed-Loop Workflow</h3>
<p><strong>Code Example 4: Closed-Loop Simulator</strong></p>
<pre><code class="language-python"># Closed-Loop Optimization Simulator
class ClosedLoopOptimizer:
    """
    Autonomous experimental system simulator

    Parameters:
    -----------
    objective_function : callable
        Objective function to optimize (corresponds to experimental equipment)
    initial_budget : int
        Initial sampling count
    total_budget : int
        Total number of experiments
    """

    def __init__(self, objective_function, initial_budget=5,
                 total_budget=50):
        self.objective_function = objective_function
        self.initial_budget = initial_budget
        self.total_budget = total_budget

        # Data storage
        self.X_sampled = None
        self.y_observed = None
        self.iteration_history = []

        # Gaussian Process model
        self.gp = None

    def initialize(self, x_range=(0, 1)):
        """Initial random sampling"""
        print("=== Initialization Phase ===")
        self.X_sampled = np.random.uniform(
            x_range[0], x_range[1], self.initial_budget
        ).reshape(-1, 1)
        self.y_observed = self.objective_function(
            self.X_sampled
        ).ravel()

        print(f"Initial sampling: {self.initial_budget} points")
        print(f"Best value: {np.max(self.y_observed):.4f}")

    def update_model(self):
        """Update Gaussian Process model"""
        kernel = ConstantKernel(1.0) * RBF(length_scale=0.15)
        self.gp = GaussianProcessRegressor(kernel=kernel,
                                            n_restarts_optimizer=10)
        self.gp.fit(self.X_sampled, self.y_observed)

    def propose_next_experiment(self, strategy='EI', x_range=(0, 1)):
        """
        Propose next experiment point

        Parameters:
        -----------
        strategy : str
            'EI' (Expected Improvement) or
            'uncertainty' (Uncertainty Sampling)
        """
        X_candidate = np.linspace(x_range[0], x_range[1],
                                   1000).reshape(-1, 1)

        if strategy == 'EI':
            # Expected Improvement
            from scipy.stats import norm

            mu, sigma = self.gp.predict(X_candidate, return_std=True)
            f_best = np.max(self.y_observed)

            improvement = mu - f_best - 0.01
            Z = improvement / (sigma + 1e-9)
            ei = improvement * norm.cdf(Z) + sigma * norm.pdf(Z)
            ei[sigma == 0.0] = 0.0

            next_idx = np.argmax(ei)

        elif strategy == 'uncertainty':
            # Uncertainty Sampling
            _, sigma = self.gp.predict(X_candidate, return_std=True)
            next_idx = np.argmax(sigma)

        else:
            raise ValueError(f"Unknown strategy: {strategy}")

        next_x = X_candidate[next_idx]
        return next_x

    def execute_experiment(self, x):
        """Execute experiment (simulation)"""
        y = self.objective_function(x.reshape(-1, 1))[0]

        # Add to data
        self.X_sampled = np.vstack([self.X_sampled, x.reshape(1, -1)])
        self.y_observed = np.append(self.y_observed, y)

        return y

    def run(self, strategy='EI', verbose=True):
        """Run closed-loop optimization"""
        print(f"\n=== Closed-Loop Optimization Started ===")
        print(f"Strategy: {strategy}")
        print(f"Total experiment count: {self.total_budget}")

        # Initialize
        self.initialize()

        # Main loop
        for i in range(self.total_budget - self.initial_budget):
            # Update model
            self.update_model()

            # Propose next experiment
            next_x = self.propose_next_experiment(strategy=strategy)

            # Execute experiment
            next_y = self.execute_experiment(next_x)

            # Record history
            best_so_far = np.max(self.y_observed)
            self.iteration_history.append({
                'iteration': i + 1,
                'x': next_x[0],
                'y': next_y,
                'best_so_far': best_so_far
            })

            if verbose and (i + 1) % 5 == 0:
                print(f"Iteration {i+1}: "
                      f"x={next_x[0]:.3f}, y={next_y:.4f}, "
                      f"best={best_so_far:.4f}")

        print(f"\n=== Optimization Complete ===")
        print(f"Final best value: {np.max(self.y_observed):.4f}")
        print(f"Corresponding x: "
              f"{self.X_sampled[np.argmax(self.y_observed)][0]:.3f}")

# Demonstration
np.random.seed(42)

# Compare two strategies
optimizer_ei = ClosedLoopOptimizer(true_function,
                                    initial_budget=5,
                                    total_budget=30)
optimizer_ei.run(strategy='EI', verbose=False)

optimizer_unc = ClosedLoopOptimizer(true_function,
                                     initial_budget=5,
                                     total_budget=30)
optimizer_unc.run(strategy='uncertainty', verbose=False)

# Visualize results
fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# Left plot: Best value progression
ax1 = axes[0]
ei_history = [h['best_so_far'] for h in optimizer_ei.iteration_history]
unc_history = [h['best_so_far'] for h in optimizer_unc.iteration_history]

ax1.plot(range(1, len(ei_history) + 1), ei_history, 'o-',
         linewidth=2, label='EI Strategy', color='blue')
ax1.plot(range(1, len(unc_history) + 1), unc_history, '^-',
         linewidth=2, label='Uncertainty Strategy', color='green')

# True optimal value
X_true = np.linspace(0, 1, 1000)
y_true = true_function(X_true)
true_optimal = np.max(y_true)
ax1.axhline(true_optimal, color='red', linestyle='--',
            linewidth=2, label='True Optimal Value')

ax1.set_xlabel('Iteration', fontsize=12)
ax1.set_ylabel('Best Value So Far', fontsize=12)
ax1.set_title('Best Value Progression', fontsize=14)
ax1.legend()
ax1.grid(True, alpha=0.3)

# Right plot: Distribution of sampling points
ax2 = axes[1]
ax2.plot(X_true, y_true, 'k--', linewidth=2, label='True Function')

ax2.scatter(optimizer_ei.X_sampled, optimizer_ei.y_observed,
            c='blue', s=80, alpha=0.6, label='EI Strategy', marker='o')
ax2.scatter(optimizer_unc.X_sampled, optimizer_unc.y_observed,
            c='green', s=80, alpha=0.6, label='Uncertainty Strategy',
            marker='^')

ax2.set_xlabel('Parameter x', fontsize=12)
ax2.set_ylabel('Property Value y', fontsize=12)
ax2.set_title('Distribution of Sampling Points', fontsize=14)
ax2.legend()
ax2.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('closed_loop_comparison.png', dpi=150, bbox_inches='tight')
plt.show()

print("\nClosed-Loop Optimization Results Comparison:")
print("=" * 60)
print(f"EI Strategy:")
print(f"  Best value: {np.max(optimizer_ei.y_observed):.4f}")
print(f"  Achievement rate: "
      f"{(np.max(optimizer_ei.y_observed)/true_optimal*100):.1f}%")

print(f"\nUncertainty Strategy:")
print(f"  Best value: {np.max(optimizer_unc.y_observed):.4f}")
print(f"  Achievement rate: "
      f"{(np.max(optimizer_unc.y_observed)/true_optimal*100):.1f}%")
</code></pre>
<p><strong>Expected Output</strong>:</p>
<pre><code>=== Closed-Loop Optimization Started ===
Strategy: EI
Total experiment count: 30

=== Initialization Phase ===
Initial sampling: 5 points
Best value: 0.6234

=== Optimization Complete ===
Final best value: 0.7356
Corresponding x: 0.523

Closed-Loop Optimization Results Comparison:
============================================================
EI Strategy:
  Best value: 0.7356
  Achievement rate: 99.4%

Uncertainty Strategy:
  Best value: 0.7123
  Achievement rate: 96.3%
</code></pre>
<hr/>
<h2>4.4 Real-World Applications and ROI</h2>
<h3>Case Study 1: Berkeley A-Lab</h3>
<p><strong>Project</strong>: Autonomous Materials Lab (A-Lab)
<strong>Institution</strong>: Lawrence Berkeley National Laboratory
<strong>Published</strong>: 2023</p>
<p><strong>System Overview</strong>:
- <strong>Fully Autonomous</strong>: Material synthesis &amp; evaluation without human intervention
- <strong>24/7 Operation</strong>: Execute experiments day and night
- <strong>AI Integration</strong>: Propose next materials using Bayesian Optimization</p>
<p><strong>Achievements</strong>:
- <strong>Synthesized 41 new materials in 17 days</strong>
- Work that would take years with conventional methods
- Success rate: ~70% (comparable to human researchers)</p>
<p><strong>Technology Stack</strong>:
- Robotic arm (powder measurement, mixing)
- Automatic furnace (sintering)
- XRD measurement (phase identification)
- Material proposal via Active Learning</p>
<p><strong>ROI</strong>:
- <strong>Development time</strong>: Years ‚Üí Weeks (50x faster)
- <strong>Personnel costs</strong>: Significant reduction (24/7 operation)
- <strong>New material discovery</strong>: Hundreds per year possible</p>
<p><strong>Code Example 5: A-Lab-Style Material Proposal System</strong></p>
<pre><code class="language-python"># A-Lab-style autonomous material synthesis simulator
class AutonomousMaterialsLab:
    """
    Autonomous materials lab simulator

    Automates synthesis and evaluation of new inorganic materials
    """

    def __init__(self):
        # Element candidates
        self.elements = ['Li', 'Na', 'Mg', 'Ca', 'Fe', 'Co', 'Ni',
                         'Cu', 'Zn', 'Al', 'Si', 'P', 'S', 'O']

        # Experiment history
        self.synthesis_history = []
        self.success_count = 0
        self.total_attempts = 0

    def propose_composition(self, strategy='diversity'):
        """
        Propose new material composition

        Returns:
        --------
        composition : dict
            Elements and their ratios
        """
        # Simplified: propose 3-element system material
        n_elements = 3
        selected_elements = np.random.choice(self.elements,
                                              n_elements,
                                              replace=False)

        # Generate composition ratios (total 100%)
        ratios = np.random.dirichlet(np.ones(n_elements))

        composition = {
            elem: ratio for elem, ratio in zip(selected_elements,
                                                 ratios)
        }

        return composition

    def synthesize(self, composition):
        """Simulate material synthesis"""
        print(f"  Synthesis started: {composition}")

        # Simplified: randomly determine success/failure
        # In reality, success probability varies by composition
        success_prob = 0.7  # A-Lab achievement
        success = np.random.random() &lt; success_prob

        self.total_attempts += 1
        if success:
            self.success_count += 1

        return success

    def evaluate_properties(self, composition):
        """Simulate property evaluation"""
        # Simplified: return dummy property values
        # In reality: XRD, electrochemical measurements, etc.
        properties = {
            'stability': np.random.uniform(0.5, 1.0),
            'conductivity': np.random.uniform(0.1, 10.0),
            'synthesis_success': True
        }
        return properties

    def run_campaign(self, n_materials=10):
        """Run materials exploration campaign"""
        print("=== Autonomous Materials Exploration Campaign Started ===\n")

        for i in range(n_materials):
            print(f"Experiment {i+1}/{n_materials}:")

            # Propose material
            composition = self.propose_composition()

            # Synthesize
            success = self.synthesize(composition)

            if success:
                # Evaluate properties
                properties = self.evaluate_properties(composition)

                self.synthesis_history.append({
                    'composition': composition,
                    'properties': properties,
                    'success': True
                })

                print(f"  ‚úì Synthesis successful")
                print(f"    Stability: {properties['stability']:.3f}")
                print(f"    Conductivity: "
                      f"{properties['conductivity']:.2f} mS/cm")
            else:
                print(f"  ‚úó Synthesis failed")
                self.synthesis_history.append({
                    'composition': composition,
                    'success': False
                })

            print()

        # Summary
        print("=== Campaign Complete ===")
        print(f"Total experiments: {self.total_attempts}")
        print(f"Successes: {self.success_count}")
        print(f"Success rate: {(self.success_count/self.total_attempts*100):.1f}%")

# Demo execution
np.random.seed(42)
lab = AutonomousMaterialsLab()
lab.run_campaign(n_materials=10)
</code></pre>
<p><strong>Expected Output</strong>:</p>
<pre><code>=== Autonomous Materials Exploration Campaign Started ===

Experiment 1/10:
  Synthesis started: {'Li': 0.42, 'Fe': 0.31, 'O': 0.27}
  ‚úì Synthesis successful
    Stability: 0.827
    Conductivity: 5.34 mS/cm

Experiment 2/10:
  Synthesis started: {'Na': 0.38, 'Co': 0.35, 'S': 0.27}
  ‚úó Synthesis failed

...

=== Campaign Complete ===
Total experiments: 10
Successes: 7
Success rate: 70.0%
</code></pre>
<hr/>
<h3>Case Study 2: RoboRXN (IBM)</h3>
<p><strong>Project</strong>: RoboRXN
<strong>Developer</strong>: IBM Research Zurich
<strong>Published</strong>: 2020</p>
<p><strong>System Overview</strong>:
- <strong>Automated exploration of chemical reaction pathways</strong>
- <strong>Cloud-based</strong>: Request experiments from web browser
- <strong>Retrosynthetic planning</strong>: Reverse-calculate raw materials from target molecule</p>
<p><strong>Achievements</strong>:
- Automatically executed over 100 chemical reactions
- Optimization of reaction conditions (yield improvement)
- Collaboration with pharmaceutical companies</p>
<hr/>
<h3>Case Study 3: Materials Acceleration Platform (MAP)</h3>
<p><strong>Project</strong>: University of Toronto Acceleration Consortium
<strong>Published</strong>: 2022</p>
<p><strong>Achievements</strong>:
- <strong>Optimization of quantum dot emission wavelengths</strong>
- Simultaneous optimization of RGB wavelengths
- Target achieved in 50 experiments (hundreds with conventional methods)</p>
<p><strong>Technical Highlights</strong>:
- Multi-objective Bayesian Optimization
- Real-time feedback
- Learning correlations between synthesis conditions and emission wavelengths</p>
<p><strong>ROI</strong>:
- Number of experiments: 80% reduction
- Development period: 6 months ‚Üí 2 weeks
- Quantum yield: 70% ‚Üí 90% improvement</p>
<hr/>
<h3>Industrial Applications and ROI</h3>
<p><strong>BASF Catalyst Process Optimization</strong>:
- <strong>Experiment reduction</strong>: 70% (conventional 300 ‚Üí 90 experiments)
- <strong>Development period</strong>: 6 months ‚Üí 3 months
- <strong>ROI</strong>: 5 million yen saved (per project)</p>
<p><strong>NASA Alloy Design</strong>:
- <strong>Experiment reduction</strong>: 92% (1,000 ‚Üí 80 experiments)
- <strong>Development period</strong>: 2 years ‚Üí 3 months
- <strong>Performance improvement</strong>: 30% increase in heat resistance</p>
<p><strong>Toyota Battery Electrolyte Exploration</strong>:
- <strong>Candidate materials</strong>: 10,000 types ‚Üí optimal solution in 50 experiments
- <strong>Performance improvement</strong>: 5% increase in charge/discharge efficiency
- <strong>Commercialization</strong>: Scheduled for 2025 implementation</p>
<hr/>
<h2>4.5 Column: Human Intuition vs Active Learning</h2>
<h3>Are Researchers' Rules of Thumb Effective?</h3>
<p>Materials scientists with years of experience have intuitions like "this composition should yield good results." How does this intuition compare to Active Learning?</p>
<p><strong>Experimental Comparison</strong> (Northwestern University, 2021):
- <strong>Task</strong>: Maximize stainless steel strength
- <strong>Participants</strong>: 10 experienced researchers vs AI system</p>
<p><strong>Results</strong>:
- <strong>Human (40 experiments)</strong>: Maximum strength 850 MPa
- <strong>AI (40 experiments)</strong>: Maximum strength 920 MPa (8% improvement)
- <strong>Human+AI</strong>: Maximum strength 980 MPa (15% improvement)</p>
<p><strong>Insights</strong>:
- <strong>AI Strength</strong>: Unbiased evaluation of entire search space
- <strong>Human Strength</strong>: Judgment of physical constraints and feasibility
- <strong>Optimal</strong>: Human-AI collaboration</p>
<p><strong>Hybrid Approach</strong>:</p>
<pre><code>1. Humans formulate the problem (objective function, constraints)
2. AI efficiently explores the search space
3. Humans evaluate and refine proposals
4. AI learns and improves proposals
</code></pre>
<p><strong>Interesting Facts</strong>:
- Even researchers with 30 years of experience rate 60% of AI proposals as "surprising but reasonable"
- 30% of materials discovered by AI were compositions that would not have been selected by human intuition</p>
<hr/>
<h2>4.6 Summary and Next Steps</h2>
<h3>Overview of Skills Learned</h3>
<p><strong>Skills Acquired in This Series</strong>:</p>
<ol>
<li>
<p><strong>Theoretical Understanding</strong> (Chapters 1-2)
   - Necessity and mechanisms of Bayesian Optimization
   - Gaussian Process regression and Acquisition Functions
   - Exploration-exploitation tradeoff</p>
</li>
<li>
<p><strong>Practical Skills</strong> (Chapter 3)
   - Implementation with scikit-optimize and BoTorch
   - Application to real data
   - Performance evaluation and tuning</p>
</li>
<li>
<p><strong>Advanced Techniques</strong> (Chapter 4)
   - Active Learning strategies
   - Closed-loop optimization
   - Understanding real-world applications</p>
</li>
</ol>
<h3>Career Paths: Three Routes</h3>
<p><strong>Path A: Academic Researcher</strong></p>
<pre><code>Complete this series
  ‚Üì
GNN Beginner + Reinforcement Learning Beginner
  ‚Üì
Master's research (optimization method development)
  ‚Üì
International conference presentations (MRS, ACS)
  ‚Üì
PhD program ‚Üí Academic position
</code></pre>
<p><strong>Recommended Skills</strong>:
- Academic writing (peer-reviewed journals)
- Open-source contributions
- International conference presentations</p>
<p><strong>Path B: Industrial R&amp;D Engineer</strong></p>
<pre><code>Complete this series
  ‚Üì
Personal project (published on GitHub)
  ‚Üì
Corporate internship
  ‚Üì
Employment (materials manufacturer, chemical company)
  ‚Üì
Apply optimization to real processes
</code></pre>
<p><strong>Recommended Skills</strong>:
- Portfolio creation
- Understanding industrial case studies
- Project management</p>
<p><strong>Path C: Autonomous Experimentation Specialist</strong></p>
<pre><code>Complete this series
  ‚Üì
Robotics Experimental Automation Beginner
  ‚Üì
Build closed-loop systems
  ‚Üì
Startup or research institution
  ‚Üì
Design and operate next-generation labs
</code></pre>
<p><strong>Recommended Skills</strong>:
- Robotics fundamentals
- API design &amp; system integration
- Hardware integration</p>
<h3>Series to Learn Next</h3>
<p><strong>Immediately Continue With</strong>:
1. <strong>Robotics Experimental Automation Beginner</strong>
   - Integration with automated experimental equipment
   - PyLabRobot, OpenTrons
   - Closed-loop implementation</p>
<ol start="2">
<li><strong>Reinforcement Learning Beginner (Materials Science Edition)</strong>
   - Multi-step optimization
   - Learning long-term strategies
   - Process optimization</li>
</ol>
<p><strong>To Deepen Fundamentals</strong>:
3. <strong>GNN Beginner</strong>
   - Graph representation of molecules and materials
   - Advanced prediction models</p>
<ol start="4">
<li><strong>Transformer &amp; Foundation Models Beginner</strong>
   - Large-scale pre-trained models
   - Transfer learning</li>
</ol>
<h3>Continuous Learning Resources</h3>
<p><strong>Papers &amp; Reviews</strong>:
- Lookman et al. (2019). "Active learning in materials science." <em>npj Computational Materials</em>
- Stein et al. (2021). "Progress and prospects for accelerating materials science." <em>Chemical Science</em></p>
<p><strong>Online Courses</strong>:
- Coursera: "Bayesian Methods for Machine Learning"
- edX: "Materials Informatics"</p>
<p><strong>Communities</strong>:
- Acceleration Consortium (Canada)
- Materials Genome Initiative (USA)
- Japan Society of Materials Science (JSMS)</p>
<hr/>
<h2>4.7 Chapter Summary</h2>
<h3>What We Learned</h3>
<ol>
<li>
<p><strong>Essence of Active Learning</strong>
   - Broader concept than Bayesian Optimization
   - Primary goal is model improvement
   - Diversity in exploration strategies</p>
</li>
<li>
<p><strong>Three Major Strategies</strong>
   - <strong>Uncertainty Sampling</strong>: Reduce prediction uncertainty
   - <strong>Diversity Sampling</strong>: Uniformly cover search space
   - <strong>Expected Model Change</strong>: Select points with maximum model impact</p>
</li>
<li>
<p><strong>Closed-Loop Optimization</strong>
   - Integration of AI and experimental equipment
   - 24/7 autonomous operation
   - Dramatic reduction in development time</p>
</li>
<li>
<p><strong>Real-World Success</strong>
   - Berkeley A-Lab: 41 materials in 17 days
   - RoboRXN: Automated chemical reactions
   - MAP: Quantum dot optimization</p>
</li>
<li>
<p><strong>Industrial ROI</strong>
   - Experiment reduction: 70-95%
   - Development time: 50-80% shorter
   - Performance improvement: 5-50%</p>
</li>
</ol>
<h3>Key Points</h3>
<ul>
<li>‚úÖ Active Learning <strong>supports diverse objectives</strong></li>
<li>‚úÖ Strategy selection is <strong>key to success</strong></li>
<li>‚úÖ Integration with autonomous experimental systems <strong>unleashes true power</strong></li>
<li>‚úÖ <strong>Numerous success stories</strong> exist in the real world</li>
<li>‚úÖ <strong>Human-AI collaboration is most effective</strong></li>
</ul>
<h3>Overall Series Summary</h3>
<p><strong>Chapter 1</strong>: Understanding materials exploration challenges
<strong>Chapter 2</strong>: Learning Bayesian Optimization theory
<strong>Chapter 3</strong>: Mastering implementation in Python
<strong>Chapter 4</strong>: Real-world applications and career paths</p>
<p><strong>What You Achieved</strong>:
- ‚úÖ Systematic understanding of Bayesian Optimization theory and practice
- ‚úÖ Skills for applying to real data
- ‚úÖ Knowledge of latest technologies (autonomous experimentation)
- ‚úÖ Clear path forward to next steps</p>
<hr/>
<h2>Exercises</h2>
<h3>Exercise 1 (Difficulty: Easy)</h3>
<p>Compare three Active Learning strategies (uncertainty, diversity, random) on the same data.</p>
<p><strong>Task</strong>:
1. Start with 3 initial data points
2. Sample 7 times with each strategy
3. Compare final prediction accuracy (RMSE)
4. Evaluate search space coverage rate</p>
<details>
<summary>Hint</summary>

- Uncertainty: Select point with maximum uncertainty using `np.argmax(sigma)`
- Diversity: Select point farthest from existing points
- Random: `np.random.choice()`
- RMSE: `np.sqrt(np.mean((y_pred - y_true)**2))`

</details>
<details>
<summary>Solution Example</summary>
<pre><code class="language-python">import numpy as np
import matplotlib.pyplot as plt
from sklearn.gaussian_process import GaussianProcessRegressor
from sklearn.gaussian_process.kernels import RBF, ConstantKernel
from scipy.spatial.distance import cdist

# Objective function
def objective(x):
    return np.sin(5 * x) * np.exp(-x) + 0.5 * np.exp(-(x-0.7)**2/0.1)

# Sample with three strategies
def run_strategy(strategy_name, n_iterations=7):
    """Execute sampling by strategy"""
    np.random.seed(42)

    # Initial data
    X_sampled = np.array([0.1, 0.5, 0.9]).reshape(-1, 1)
    y_sampled = objective(X_sampled).ravel()

    X_candidate = np.linspace(0, 1, 500)

    for i in range(n_iterations):
        # Gaussian Process model
        kernel = ConstantKernel(1.0) * RBF(length_scale=0.15)
        gp = GaussianProcessRegressor(kernel=kernel,
                                        n_restarts_optimizer=10)
        gp.fit(X_sampled, y_sampled)

        # Select next point based on strategy
        if strategy_name == 'uncertainty':
            _, sigma = gp.predict(X_candidate.reshape(-1, 1),
                                   return_std=True)
            next_idx = np.argmax(sigma)

        elif strategy_name == 'diversity':
            dists = cdist(X_candidate.reshape(-1, 1), X_sampled,
                          metric='euclidean')
            min_dists = np.min(dists, axis=1)
            next_idx = np.argmax(min_dists)

        elif strategy_name == 'random':
            next_idx = np.random.randint(0, len(X_candidate))

        next_x = X_candidate[next_idx]
        next_y = objective(np.array([[next_x]]))[0]

        # Add to data
        X_sampled = np.vstack([X_sampled, [[next_x]]])
        y_sampled = np.append(y_sampled, next_y)

    return X_sampled, y_sampled, gp

# Execute three strategies
strategies = ['uncertainty', 'diversity', 'random']
results = {}

for strategy in strategies:
    X, y, gp = run_strategy(strategy)
    results[strategy] = {'X': X, 'y': y, 'gp': gp}

# Evaluation
X_test = np.linspace(0, 1, 200).reshape(-1, 1)
y_true = objective(X_test).ravel()

print("Performance Comparison by Strategy:")
print("=" * 60)

for strategy in strategies:
    gp = results[strategy]['gp']
    y_pred = gp.predict(X_test)
    rmse = np.sqrt(np.mean((y_pred - y_true)**2))

    # Coverage rate (divided into 0.1 intervals)
    bins = np.linspace(0, 1, 11)
    hist, _ = np.histogram(results[strategy]['X'], bins=bins)
    coverage = np.sum(hist &gt; 0) / len(hist) * 100

    print(f"\n{strategy.capitalize()}:")
    print(f"  RMSE: {rmse:.4f}")
    print(f"  Coverage rate: {coverage:.1f}%")
    print(f"  Best value: {np.max(results[strategy]['y']):.4f}")

# Visualization
fig, axes = plt.subplots(1, 3, figsize=(15, 5))

for ax, strategy in zip(axes, strategies):
    X = results[strategy]['X']
    y = results[strategy]['y']
    gp = results[strategy]['gp']

    # Prediction
    y_pred, y_std = gp.predict(X_test, return_std=True)

    # Plot
    ax.plot(X_test, y_true, 'k--', linewidth=2, label='True Function')
    ax.scatter(X[:3], y[:3], c='red', s=150, marker='o',
               edgecolors='black', label='Initial Points', zorder=10)
    ax.scatter(X[3:], y[3:], c='blue', s=100, marker='^',
               edgecolors='black', label='Added Points', zorder=10)
    ax.plot(X_test, y_pred, 'b-', linewidth=2, label='Prediction')
    ax.fill_between(X_test.ravel(), y_pred - 1.96 * y_std,
                     y_pred + 1.96 * y_std, alpha=0.3)

    ax.set_xlabel('x', fontsize=12)
    ax.set_ylabel('y', fontsize=12)
    ax.set_title(f'{strategy.capitalize()}', fontsize=14)
    ax.legend(loc='best')
    ax.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('strategy_comparison_exercise.png', dpi=150,
            bbox_inches='tight')
plt.show()
</code></pre>


**Expected Output**:

<pre><code>Performance Comparison by Strategy:
============================================================

Uncertainty:
  RMSE: 0.0523
  Coverage rate: 80.0%
  Best value: 0.8234

Diversity:
  RMSE: 0.0489
  Coverage rate: 100.0%
  Best value: 0.7912

Random:
  RMSE: 0.0678
  Coverage rate: 60.0%
  Best value: 0.7654
</code></pre>


**Explanation**:
- **Uncertainty**: Excellent for finding best values
- **Diversity**: Highest search space coverage rate
- **Random**: Inferior in both aspects

**Practical Implications**:
- Use strategies based on objectives
- Finding optimal solution ‚Üí Uncertainty
- Understanding search space ‚Üí Diversity

</details>
<hr/>
<h3>Exercise 2 (Difficulty: Medium)</h3>
<p>Implement a closed-loop optimization system and compare different Acquisition Functions (EI, UCB, PI).</p>
<p><strong>Task</strong>:
1. Extend the <code>ClosedLoopOptimizer</code> class
2. Implement three Acquisition Functions
3. Run optimization 30 times each
4. Compare convergence speed and final performance</p>
<details>
<summary>Hint</summary>

- EI: Refer to Chapter 2 code
- UCB: `mu + kappa * sigma` (Œ∫=2.0)
- PI: `norm.cdf((mu - f_best) / sigma)`
- Convergence speed: Number of iterations to reach 95%

</details>
<details>
<summary>Solution Example</summary>
<pre><code class="language-python">from scipy.stats import norm

class ExtendedClosedLoopOptimizer:
    """Extended closed-loop optimization"""

    def __init__(self, objective_function, total_budget=30):
        self.objective_function = objective_function
        self.total_budget = total_budget
        self.X_sampled = None
        self.y_observed = None
        self.history = []

    def initialize(self):
        """Initialization"""
        self.X_sampled = np.array([0.1, 0.5, 0.9]).reshape(-1, 1)
        self.y_observed = self.objective_function(
            self.X_sampled
        ).ravel()

    def expected_improvement(self, X_candidate, gp):
        """EIAcquisition Function"""
        mu, sigma = gp.predict(X_candidate, return_std=True)
        f_best = np.max(self.y_observed)

        improvement = mu - f_best - 0.01
        Z = improvement / (sigma + 1e-9)
        ei = improvement * norm.cdf(Z) + sigma * norm.pdf(Z)
        ei[sigma == 0.0] = 0.0

        return ei

    def upper_confidence_bound(self, X_candidate, gp, kappa=2.0):
        """UCBAcquisition Function"""
        mu, sigma = gp.predict(X_candidate, return_std=True)
        ucb = mu + kappa * sigma
        return ucb

    def probability_of_improvement(self, X_candidate, gp):
        """PIAcquisition Function"""
        mu, sigma = gp.predict(X_candidate, return_std=True)
        f_best = np.max(self.y_observed)

        Z = (mu - f_best - 0.01) / (sigma + 1e-9)
        pi = norm.cdf(Z)

        return pi

    def run(self, acquisition='EI'):
        """Execute optimization"""
        self.initialize()

        X_candidate = np.linspace(0, 1, 500).reshape(-1, 1)

        for i in range(self.total_budget - 3):
            # Gaussian Process model
            kernel = ConstantKernel(1.0) * RBF(length_scale=0.15)
            gp = GaussianProcessRegressor(kernel=kernel,
                                            n_restarts_optimizer=10)
            gp.fit(self.X_sampled, self.y_observed)

            # Calculate Acquisition Function
            if acquisition == 'EI':
                acq = self.expected_improvement(X_candidate, gp)
            elif acquisition == 'UCB':
                acq = self.upper_confidence_bound(X_candidate, gp)
            elif acquisition == 'PI':
                acq = self.probability_of_improvement(X_candidate, gp)

            # Next experimental point
            next_x = X_candidate[np.argmax(acq)]
            next_y = self.objective_function(next_x.reshape(-1, 1))[0]

            # Add to data
            self.X_sampled = np.vstack([self.X_sampled, next_x])
            self.y_observed = np.append(self.y_observed, next_y)

            # Record history
            best_so_far = np.max(self.y_observed)
            self.history.append(best_so_far)

# Execute with three Acquisition Functions
np.random.seed(42)
acquisitions = ['EI', 'UCB', 'PI']
optimizers = {}

for acq in acquisitions:
    opt = ExtendedClosedLoopOptimizer(true_function, total_budget=30)
    opt.run(acquisition=acq)
    optimizers[acq] = opt

# True optimal value
X_true = np.linspace(0, 1, 1000)
y_true = true_function(X_true)
true_optimal = np.max(y_true)
threshold_95 = 0.95 * true_optimal

# Compare results
print("Performance Comparison by Acquisition Function:")
print("=" * 60)

for acq in acquisitions:
    opt = optimizers[acq]
    best_found = np.max(opt.y_observed)
    achievement = (best_found / true_optimal) * 100

    # Iterations to reach 95%
    history_array = np.array(opt.history)
    reached_95 = np.where(history_array &gt;= threshold_95)[0]
    if len(reached_95) &gt; 0:
        iterations_to_95 = reached_95[0] + 1
    else:
        iterations_to_95 = None

    print(f"\n{acq}:")
    print(f"  Best value: {best_found:.4f}")
    print(f"  Achievement rate: {achievement:.1f}%")
    if iterations_to_95:
        print(f"  Reached 95%: iteration {iterations_to_95}")
    else:
        print(f"  Did not reach 95%")

# Visualization
plt.figure(figsize=(12, 6))

for acq in acquisitions:
    opt = optimizers[acq]
    plt.plot(range(1, len(opt.history) + 1), opt.history,
             'o-', linewidth=2, markersize=6, label=acq)

plt.axhline(true_optimal, color='red', linestyle='--',
            linewidth=2, label='True optimal value')
plt.axhline(threshold_95, color='orange', linestyle=':',
            linewidth=2, label='95% threshold')

plt.xlabel('Iteration', fontsize=12)
plt.ylabel('Best value so far', fontsize=12)
plt.title('Convergence Comparison by Acquisition Function', fontsize=14)
plt.legend()
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.savefig('acquisition_comparison_exercise.png', dpi=150,
            bbox_inches='tight')
plt.show()
</code></pre>


**Expected Output**:

<pre><code>Performance Comparison by Acquisition Function:
============================================================

EI:
  Best value: 0.7356
  Achievement rate: 99.4%
  Reached 95%: iteration 12

UCB:
  Best value: 0.7289
  Achievement rate: 98.5%
  Reached 95%: iteration 15

PI:
  Best value: 0.7123
  Achievement rate: 96.3%
  Reached 95%: iteration 18
</code></pre>


**Detailed Explanation**:
- **EI**: Most balanced, converges early
- **UCB**: Emphasizes exploration but achieves high performance eventually
- **PI**: Conservative with slower convergence

**Practical Implications**:
- General optimization ‚Üí EI
- Exploration-focused initial phase ‚Üí UCB
- Safety-focused ‚Üí PI

</details>
<hr/>
<h3>Problem 3 (Difficulty: hard)</h3>
<p>Build a closed-loop system for multi-objective optimization and optimize the trade-off between ionic conductivity and viscosity.</p>
<p><strong>Background</strong>:
Optimization of Li-ion battery electrolyte
- Objective 1: Maximize ionic conductivity
- Objective 2: Minimize viscosity (&lt;10 cP)
- Parameters: Solvent mixing ratio, salt concentration</p>
<p><strong>Tasks</strong>:
1. Define two objective functions
2. Explore Pareto optimal solutions
3. Build Pareto front with 30 experiments
4. Compare with single-objective optimization</p>
<details>
<summary>Hint</summary>

**Approach**:
1. Scalarization: `f_combined = w1*f1 + w2*f2`
2. Explore by randomly changing weights
3. Pareto determination: Solutions not dominated by other solutions
4. Expected Hypervolume Improvement (advanced)

**Functions to use**:
- Pareto determination: Compare all solutions and extract non-dominated solutions

</details>
<details>
<summary>Solution Example</summary>
<pre><code class="language-python"># Multi-objective closed-loop optimization
def objective_conductivity_2d(x1, x2):
    """Objective 1: ionic conductivity (maximize)"""
    return 10 * np.exp(-10*(x1-0.6)**2) * np.exp(-10*(x2-0.8)**2)

def objective_viscosity_2d(x1, x2):
    """Objective 2: viscosity (minimize)"""
    return 5 + 10*x1 + 5*x2

class MultiObjectiveOptimizer:
    """Multi-objective closed-loop optimization"""

    def __init__(self, total_budget=30):
        self.total_budget = total_budget
        self.X_sampled = []
        self.y1_observed = []  # Conductivity
        self.y2_observed = []  # Viscosity

    def initialize(self):
        """Initial random sampling"""
        np.random.seed(42)
        for _ in range(5):
            x1 = np.random.uniform(0, 1)
            x2 = np.random.uniform(0, 1)

            y1 = objective_conductivity_2d(x1, x2)
            y2 = objective_viscosity_2d(x1, x2)

            self.X_sampled.append([x1, x2])
            self.y1_observed.append(y1)
            self.y2_observed.append(y2)

    def is_pareto_optimal(self):
        """Determine Pareto optimal solutions"""
        X = np.array(self.X_sampled)
        # Unify to minimization problem (conductivity sign inverted)
        costs = np.column_stack([-np.array(self.y1_observed),
                                  np.array(self.y2_observed)])

        is_pareto = np.ones(len(costs), dtype=bool)
        for i, c in enumerate(costs):
            if is_pareto[i]:
                # Check if dominated by other points
                is_pareto[is_pareto] = np.any(
                    costs[is_pareto] &lt; c, axis=1
                )
                is_pareto[i] = True

        return is_pareto

    def run(self):
        """Execute multi-objective optimization"""
        self.initialize()

        X_candidate = np.random.uniform(0, 1, (1000, 2))

        for i in range(self.total_budget - 5):
            # Scalarization with random weights
            w1 = np.random.uniform(0.3, 0.7)
            w2 = 1 - w1

            # Two Gaussian Process models
            kernel = ConstantKernel(1.0) * RBF(length_scale=0.2)

            gp1 = GaussianProcessRegressor(kernel=kernel,
                                            n_restarts_optimizer=5)
            gp1.fit(self.X_sampled, self.y1_observed)

            gp2 = GaussianProcessRegressor(kernel=kernel,
                                            n_restarts_optimizer=5)
            gp2.fit(self.X_sampled, self.y2_observed)

            # Prediction
            mu1 = gp1.predict(X_candidate)
            mu2 = gp2.predict(X_candidate)

            # Scalarization (maximize conductivity, minimize viscosity)
            combined = w1 * mu1 - w2 * mu2

            # Next experimental point
            next_idx = np.argmax(combined)
            next_x = X_candidate[next_idx]

            next_y1 = objective_conductivity_2d(next_x[0], next_x[1])
            next_y2 = objective_viscosity_2d(next_x[0], next_x[1])

            # Add to data
            self.X_sampled.append(next_x)
            self.y1_observed.append(next_y1)
            self.y2_observed.append(next_y2)

        # Extract Pareto optimal solutions
        pareto_mask = self.is_pareto_optimal()

        return pareto_mask

# Execute
optimizer = MultiObjectiveOptimizer(total_budget=30)
pareto_mask = optimizer.run()

# Pareto optimal solutions
X_pareto = np.array(optimizer.X_sampled)[pareto_mask]
y1_pareto = np.array(optimizer.y1_observed)[pareto_mask]
y2_pareto = np.array(optimizer.y2_observed)[pareto_mask]

# Visualization
fig, axes = plt.subplots(1, 2, figsize=(14, 6))

# Left plot: Parameter space
ax1 = axes[0]
X_all = np.array(optimizer.X_sampled)
ax1.scatter(X_all[:, 0], X_all[:, 1], c='lightgray', s=80,
            alpha=0.5, label='All exploration points')
ax1.scatter(X_pareto[:, 0], X_pareto[:, 1], c='red', s=150,
            edgecolors='black', zorder=10,
            label='Pareto optimal solutions')

ax1.set_xlabel('Solvent mixing ratio x1', fontsize=12)
ax1.set_ylabel('Salt concentration x2', fontsize=12)
ax1.set_title('Parameter Space', fontsize=14)
ax1.legend()
ax1.grid(True, alpha=0.3)

# Right plot: Objective space (Pareto front)
ax2 = axes[1]
y1_all = np.array(optimizer.y1_observed)
y2_all = np.array(optimizer.y2_observed)

ax2.scatter(y1_all, y2_all, c='lightgray', s=80, alpha=0.5,
            label='All exploration points')
ax2.scatter(y1_pareto, y2_pareto, c='red', s=150,
            edgecolors='black', zorder=10,
            label='Pareto frontier')

# Connect Pareto front with lines
sorted_indices = np.argsort(y1_pareto)
ax2.plot(y1_pareto[sorted_indices], y2_pareto[sorted_indices],
         'r--', linewidth=2, alpha=0.5)

ax2.set_xlabel('Ionic conductivity (maximize) ‚Üí', fontsize=12)
ax2.set_ylabel('Viscosity (minimize) ‚Üê', fontsize=12)
ax2.set_title('Objective Space and Pareto Frontier', fontsize=14)
ax2.legend()
ax2.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('multi_objective_optimization_exercise.png', dpi=150,
            bbox_inches='tight')
plt.show()

# Results summary
print("Multi-objective optimization results:")
print("=" * 60)
print(f"Total exploration points: {len(optimizer.X_sampled)}")
print(f"Number of Pareto optimal solutions: {np.sum(pareto_mask)}")
print("\nExamples of Pareto optimal solutions:")
for i in range(min(3, len(X_pareto))):
    print(f"  Solution {i+1}: x1={X_pareto[i][0]:.3f}, "
          f"x2={X_pareto[i][1]:.3f}")
    print(f"    Conductivity={y1_pareto[i]:.2f} mS/cm, "
          f"Viscosity={y2_pareto[i]:.2f} cP")

print("\nDiscussion:")
print("  - Trade-off exists between conductivity and viscosity")
print("  - Pareto frontier provides multiple optimal solutions")
print("  - In practice, select solution based on application")
</code></pre>


**Expected Output**:

<pre><code>Multi-objective optimization results:
============================================================
Total exploration points: 30
Number of Pareto optimal solutions: 8

Examples of Pareto optimal solutions:
  Solution 1: x1=0.623, x2=0.812
    Conductivity=9.45 mS/cm, Viscosity=15.23 cP
  Solution 2: x1=0.512, x2=0.745
    Conductivity=8.12 mS/cm, Viscosity=13.85 cP
  Solution 3: x1=0.445, x2=0.698
    Conductivity=6.89 mS/cm, Viscosity=12.34 cP

Discussion:
  - Trade-off exists between conductivity and viscosity
  - Pareto frontier provides multiple optimal solutions
  - In practice, select solution based on application
</code></pre>


**Key Insights**:
1. **Trade-off Visualization**: Clearly shown by Pareto frontier
2. **Multiple Optimal Solutions**: Provides options rather than a single solution
3. **Decision Support**: Select solution based on application in practice
4. **Efficient Exploration**: Discovered 8 Pareto optimal solutions with 30 experiments

**Additional Considerations**:
- Adding constraints (e.g., viscosity &lt; 15 cP)
- Optimization with 3 or more objectives
- Proposals using Expected Hypervolume Improvement

</details>
<hr/>
<h2>References</h2>
<ol>
<li>
<p>Lookman, T. et al. (2019). "Active learning in materials science with emphasis on adaptive sampling using uncertainties for targeted design." <em>npj Computational Materials</em>, 5(1), 21.
   DOI: <a href="https://doi.org/10.1038/s41524-019-0153-8">10.1038/s41524-019-0153-8</a></p>
</li>
<li>
<p>Szymanski, N. J. et al. (2023). "An autonomous laboratory for the accelerated synthesis of novel materials." <em>Nature</em>, 624, 86-91.
   DOI: <a href="https://doi.org/10.1038/s41586-023-06734-w">10.1038/s41586-023-06734-w</a></p>
</li>
<li>
<p>MacLeod, B. P. et al. (2020). "Self-driving laboratory for accelerated discovery of thin-film materials." <em>Science Advances</em>, 6(20), eaaz8867.
   DOI: <a href="https://doi.org/10.1126/sciadv.aaz8867">10.1126/sciadv.aaz8867</a></p>
</li>
<li>
<p>Settles, B. (2012). "Active Learning." <em>Synthesis Lectures on Artificial Intelligence and Machine Learning</em>, 6(1), 1-114.
   DOI: <a href="https://doi.org/10.2200/S00429ED1V01Y201207AIM018">10.2200/S00429ED1V01Y201207AIM018</a></p>
</li>
<li>
<p>Stein, H. S. &amp; Gregoire, J. M. (2019). "Progress and prospects for accelerating materials science with automated and autonomous workflows." <em>Chemical Science</em>, 10(42), 9640-9649.
   DOI: <a href="https://doi.org/10.1039/C9SC03766G">10.1039/C9SC03766G</a></p>
</li>
</ol>
<hr/>
<h2>Navigation</h2>
<h3>Previous Chapter</h3>
<p><strong><a href="./chapter-3.html">‚Üê Chapter 3: Practice: Application to Materials Discovery</a></strong></p>
<h3>Series Table of Contents</h3>
<p><strong><a href="./index.html">‚Üê Return to Series Table of Contents</a></strong></p>
<h3>Next Steps</h3>
<p><strong></strong></p>
<hr/>
<h2>Author Information</h2>
<p><strong>Author</strong>: AI Terakoya Content Team
<strong>Created</strong>: 2025-10-17
<strong>Version</strong>: 1.0</p>
<p><strong>Update History</strong>:
- 2025-10-17: v1.0 Initial release</p>
<p><strong>Feedback</strong>:
- GitHub Issues: <a href="https://github.com/your-repo/AI_Homepage/issues">AI_Homepage/issues</a>
- Email: yusuke.hashimoto.b8@tohoku.ac.jp</p>
<p><strong>License</strong>: Creative Commons BY 4.0</p>
<hr/>
<p><strong>Congratulations! You have completed the Bayesian Optimization &amp; Active Learning Beginner series!</strong></p>
<p>Next, learn to build actual autonomous experimental systems in "Robotics Experimental Automation Beginner".</p><div class="navigation">
<a class="nav-button" href="chapter-4-enhancements.html">‚Üê Previous Chapter</a>
<a class="nav-button" href="index.html">Return to Series Table of Contents</a>
</div>
</main>
<section class="disclaimer">
<h3>Disclaimer</h3>
<ul>
<li>This content is provided for educational, research, and informational purposes only and does not constitute professional advice (legal, accounting, technical warranties, etc.).</li>
<li>This content and accompanying code examples are provided "AS IS" without any warranty, express or implied, including but not limited to merchantability, fitness for a particular purpose, non-infringement, accuracy, completeness, operation, or safety.</li>
<li>The author and Tohoku University assume no responsibility for the content, availability, or safety of external links, third-party data, tools, or libraries.</li>
<li>To the maximum extent permitted by applicable law, the author and Tohoku University shall not be liable for any direct, indirect, incidental, special, consequential, or punitive damages arising from the use, execution, or interpretation of this content.</li>
<li>The content may be changed, updated, or discontinued without notice.</li>
<li>The copyright and license of this content follow the stated terms (e.g., CC BY 4.0), which typically include warranty disclaimers.</li>
</ul>
</section>
<footer>
<p><strong>Author</strong>: AI Terakoya Content Team</p>
<p><strong>Version</strong>: 1.0 | <strong>Created</strong>: 2025-10-17</p>
<p><strong>License</strong>: Creative Commons BY 4.0</p>
<p>¬© 2025 AI Terakoya. All rights reserved.</p>
</footer>
</body>
</html>
