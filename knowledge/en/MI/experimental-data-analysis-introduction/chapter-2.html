<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Chapter 2: Spectral Data Analysis - AI Terakoya</title>

    <style>
        :root {
            --color-primary: #2c3e50;
            --color-primary-dark: #1a252f;
            --color-accent: #7b2cbf;
            --color-accent-light: #9d4edd;
            --color-text: #2d3748;
            --color-text-light: #4a5568;
            --color-bg: #ffffff;
            --color-bg-alt: #f7fafc;
            --color-border: #e2e8f0;
            --color-code-bg: #f8f9fa;
            --color-link: #3182ce;
            --color-link-hover: #2c5aa0;

            --spacing-xs: 0.5rem;
            --spacing-sm: 1rem;
            --spacing-md: 1.5rem;
            --spacing-lg: 2rem;
            --spacing-xl: 3rem;

            --font-body: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            --font-mono: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;

            --border-radius: 8px;
            --box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: var(--font-body);
            line-height: 1.7;
            color: var(--color-text);
            background-color: var(--color-bg);
            font-size: 16px;
        }

        header {
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            padding: var(--spacing-xl) var(--spacing-md);
            margin-bottom: var(--spacing-xl);
            box-shadow: var(--box-shadow);
        }

        .header-content {
            max-width: 900px;
            margin: 0 auto;
        }

        h1 {
            font-size: 2rem;
            font-weight: 700;
            margin-bottom: var(--spacing-sm);
            line-height: 1.2;
        }

        .subtitle {
            font-size: 1.1rem;
            opacity: 0.95;
            font-weight: 400;
            margin-bottom: var(--spacing-md);
        }

        .meta {
            display: flex;
            flex-wrap: wrap;
            gap: var(--spacing-md);
            font-size: 0.9rem;
            opacity: 0.9;
        }

        .meta-item {
            display: flex;
            align-items: center;
            gap: 0.3rem;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 0 var(--spacing-md) var(--spacing-xl);
        }

        h2 {
            font-size: 1.75rem;
            color: var(--color-primary);
            margin-top: var(--spacing-xl);
            margin-bottom: var(--spacing-md);
            padding-bottom: var(--spacing-xs);
            border-bottom: 3px solid var(--color-accent);
        }

        h3 {
            font-size: 1.4rem;
            color: var(--color-primary);
            margin-top: var(--spacing-lg);
            margin-bottom: var(--spacing-sm);
        }

        h4 {
            font-size: 1.1rem;
            color: var(--color-primary-dark);
            margin-top: var(--spacing-md);
            margin-bottom: var(--spacing-sm);
        }

        p {
            margin-bottom: var(--spacing-md);
            color: var(--color-text);
        }

        a {
            color: var(--color-link);
            text-decoration: none;
            transition: color 0.2s;
        }

        a:hover {
            color: var(--color-link-hover);
            text-decoration: underline;
        }

        ul, ol {
            margin-left: var(--spacing-lg);
            margin-bottom: var(--spacing-md);
        }

        li {
            margin-bottom: var(--spacing-xs);
            color: var(--color-text);
        }

        pre {
            background-color: var(--color-code-bg);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            overflow-x: auto;
            margin-bottom: var(--spacing-md);
            font-family: var(--font-mono);
            font-size: 0.9rem;
            line-height: 1.5;
        }

        code {
            font-family: var(--font-mono);
            font-size: 0.9em;
            background-color: var(--color-code-bg);
            padding: 0.2em 0.4em;
            border-radius: 3px;
        }

        pre code {
            background-color: transparent;
            padding: 0;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: var(--spacing-md);
            font-size: 0.95rem;
        }

        th, td {
            border: 1px solid var(--color-border);
            padding: var(--spacing-sm);
            text-align: left;
        }

        th {
            background-color: var(--color-bg-alt);
            font-weight: 600;
            color: var(--color-primary);
        }

        blockquote {
            border-left: 4px solid var(--color-accent);
            padding-left: var(--spacing-md);
            margin: var(--spacing-md) 0;
            color: var(--color-text-light);
            font-style: italic;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        .mermaid {
            text-align: center;
            margin: var(--spacing-lg) 0;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        details {
            background-color: var(--color-bg-alt);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            margin-bottom: var(--spacing-md);
        }

        summary {
            cursor: pointer;
            font-weight: 600;
            color: var(--color-primary);
            user-select: none;
            padding: var(--spacing-xs);
            margin: calc(-1 * var(--spacing-md));
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        summary:hover {
            background-color: rgba(123, 44, 191, 0.1);
        }

        details[open] summary {
            margin-bottom: var(--spacing-md);
            border-bottom: 1px solid var(--color-border);
        }

        .learning-objectives {
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
            padding: var(--spacing-lg);
            border-radius: var(--border-radius);
            border-left: 4px solid var(--color-accent);
            margin-bottom: var(--spacing-xl);
        }

        .learning-objectives h2 {
            margin-top: 0;
            border-bottom: none;
        }

        .navigation {
            display: flex;
            justify-content: space-between;
            gap: var(--spacing-md);
            margin: var(--spacing-xl) 0;
            padding-top: var(--spacing-lg);
            border-top: 2px solid var(--color-border);
        }

        .nav-button {
            flex: 1;
            padding: var(--spacing-md);
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            border-radius: var(--border-radius);
            text-align: center;
            font-weight: 600;
            transition: transform 0.2s, box-shadow 0.2s;
            box-shadow: var(--box-shadow);
        }

        .nav-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
            text-decoration: none;
        }

        footer {
            margin-top: var(--spacing-xl);
            padding: var(--spacing-lg) var(--spacing-md);
            background-color: var(--color-bg-alt);
            border-top: 1px solid var(--color-border);
            text-align: center;
            font-size: 0.9rem;
            color: var(--color-text-light);
        }
        .disclaimer {
            max-width: 900px;
            margin: 2rem auto;
            padding: 1.5rem;
            background: #f8f9fa;
            border-left: 4px solid #6c757d;
            border-radius: 4px;
        }

        .disclaimer h3 {
            color: #495057;
            margin-bottom: 1rem;
            font-size: 1.1rem;
        }

        .disclaimer ul {
            list-style: none;
            padding-left: 0;
        }

        .disclaimer li {
            padding: 0.5rem 0;
            padding-left: 1.5rem;
            position: relative;
            font-size: 0.9rem;
            color: #6c757d;
            line-height: 1.6;
        }

        .disclaimer li::before {
            content: "âš ï¸";
            position: absolute;
            left: 0;
        }


        @media (max-width: 768px) {
            h1 {
                font-size: 1.5rem;
            }

            h2 {
                font-size: 1.4rem;
            }

            h3 {
                font-size: 1.2rem;
            }

            .meta {
                font-size: 0.85rem;
            }

            .navigation {
                flex-direction: column;
            }

            table {
                font-size: 0.85rem;
            }

            th, td {
                padding: var(--spacing-xs);
            }
        }
    
        
    
        /* Breadcrumb styles */
        .breadcrumb {
            background: #f7fafc;
            padding: 0.75rem 1rem;
            border-bottom: 1px solid #e2e8f0;
            font-size: 0.9rem;
        }

        .breadcrumb-content {
            max-width: 900px;
            margin: 0 auto;
            display: flex;
            align-items: center;
            flex-wrap: wrap;
            gap: 0.5rem;
        }

        .breadcrumb a {
            color: #667eea;
            text-decoration: none;
            transition: color 0.2s;
        }

        .breadcrumb a:hover {
            color: #764ba2;
            text-decoration: underline;
        }

        .breadcrumb-separator {
            color: #a0aec0;
            margin: 0 0.25rem;
        }

        .breadcrumb-current {
            color: #4a5568;
            font-weight: 500;
        }
    </style>

    <script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
    <script>
        mermaid.initialize({ startOnLoad: true, theme: 'default', securityLevel: 'strict' });
    </script>

    <!-- MathJax for LaTeX equation rendering -->
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\(', '\)']],
                displayMath: [['$$', '$$'], ['\[', '\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
                ignoreHtmlClass: 'mermaid'
            }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" async></script>
</head>
<body>
            <nav class="breadcrumb">
        <div class="breadcrumb-content">
            <a href="/AI-Knowledge-Notes/knowledge/en/index.html">AI Terakoya Top</a><span class="breadcrumb-separator">â€º</span><a href="/AI-Knowledge-Notes/knowledge/en/MI/index.html">Materials Informatics</a><span class="breadcrumb-separator">â€º</span><a href="/AI-Knowledge-Notes/knowledge/en/MI/experimental-data-analysis-introduction/index.html">Experimental Data Analysis</a><span class="breadcrumb-separator">â€º</span><span class="breadcrumb-current">Chapter 2</span>
        </div>
    </nav>

        <header>
        <div class="header-content">
            <h1>Chapter 2: Spectral Data Analysis</h1>
            <p class="subtitle">Automated Analysis of XRD, XPS, IR, and Raman - Extraction of Structural and Compositional Information</p>
            <div class="meta">
                <span class="meta-item">ğŸ“– Reading Time: 25-30 min</span>
                <span class="meta-item">ğŸ“Š Difficulty: Intermediate</span>
                <span class="meta-item">ğŸ’» Code Examples: 11</span>
                <span class="meta-item">ğŸ“ Exercises: 3 problems</span>
            </div>
        </div>
    </header>

    <main class="container">
<h1>Chapter 2: Spectral Data Analysis</h1>
<p class="chapter-description" style="margin: 1.5rem 0; padding: 1rem; background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%); border-left: 4px solid #7b2cbf; border-radius: 8px; font-size: 1.05rem; line-height: 1.8; color: #2d3748;">Experience the key points of XRD analysis from peak identification to refinement using Python. Learn the perspective of reducing human error through automation.</p>
<p class="chapter-supplement" style="margin: 0.75rem 0 1.5rem 0; padding: 0.75rem 1rem; background: linear-gradient(135deg, #fff8e1 0%, #fff3cd 100%); border-left: 3px solid #f59e0b; border-radius: 6px; font-size: 0.95rem; line-height: 1.7; color: #4a5568;"><strong>ğŸ’¡ Supplement:</strong> Selection of reference patterns and initial values are key to convergence. Keep logs to accelerate the improvement cycle.</p>





<p><strong>Automated Analysis of XRD, XPS, IR, and Raman - Extraction of Structural and Compositional Information</strong></p>
<h2>Learning Objectives</h2>
<p>By reading this chapter, you will master the following:</p>
<ul>
<li>âœ… Understand the characteristics of XRD, XPS, IR, and Raman spectra and select appropriate preprocessing methods</li>
<li>âœ… Implement peak detection algorithms and quantify peak positions and intensities</li>
<li>âœ… Utilize background removal methods (polynomial fitting, SNIP) appropriately</li>
<li>âœ… Perform quantitative phase analysis (RIR method) from XRD patterns</li>
<li>âœ… Automate spectral analysis pipelines</li>
</ul>
<p><strong>Reading Time</strong>: 25-30 min
<strong>Code Examples</strong>: 11
<strong>Exercises</strong>: 3 problems</p>
<hr />
<h2>2.1 Characteristics of Spectral Data and Preprocessing Strategies</h2>
<h3>Characteristics of Each Measurement Technique</h3>
<p>Understanding the characteristics of the four spectral measurement techniques frequently used in materials science is important for selecting appropriate analysis methods.</p>
<table>
<thead>
<tr>
<th>Measurement Technique</th>
<th>Information Obtained</th>
<th>Peak Characteristics</th>
<th>Typical Background</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>XRD</strong></td>
<td>Crystal structure, phase identification</td>
<td>Sharp (diffraction peaks)</td>
<td>Low intensity, gradual rise (amorphous)</td>
</tr>
<tr>
<td><strong>XPS</strong></td>
<td>Elemental composition, chemical state</td>
<td>Asymmetric (spin-orbit splitting)</td>
<td>Shirley-type (inelastic scattering)</td>
</tr>
<tr>
<td><strong>IR</strong></td>
<td>Molecular vibrations, functional groups</td>
<td>Sharp to broad</td>
<td>Nearly flat (transmission method)</td>
</tr>
<tr>
<td><strong>Raman</strong></td>
<td>Crystallinity, molecular vibrations</td>
<td>Sharp (high crystallinity)</td>
<td>Fluorescence background (organic matter)</td>
</tr>
</tbody>
</table>
<h3>Typical Workflow for Spectral Analysis</h3>
<div class="mermaid">
flowchart TD
    A[Spectral Measurement] --> B[Data Loading]
    B --> C[Noise Removal]
    C --> D[Background Removal]
    D --> E[Peak Detection]
    E --> F[Peak Fitting]
    F --> G[Quantitative Analysis]
    G --> H[Result Visualization]

    style A fill:#e3f2fd
    style D fill:#fff3e0
    style E fill:#f3e5f5
    style G fill:#e8f5e9
    style H fill:#fce4ec
</div>

<p><strong>Purpose of Each Step</strong>:
1. <strong>Noise Removal</strong>: S/N ratio improvement (studied in Chapter 1)
2. <strong>Background Removal</strong>: Baseline correction
3. <strong>Peak Detection</strong>: Automatic identification of peak positions
4. <strong>Peak Fitting</strong>: Modeling of peak shapes
5. <strong>Quantitative Analysis</strong>: Calculation of composition and phase fractions</p>
<hr />
<h2>2.2 Data Licensing and Reproducibility</h2>
<h3>Spectral Data Repositories and Licenses</h3>
<p>In spectral analysis, utilizing standard databases and public data is important.</p>
<h4>Major Spectral Databases</h4>
<table>
<thead>
<tr>
<th>Database</th>
<th>Content</th>
<th>License</th>
<th>Access</th>
<th>Citation Requirements</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>ICDD PDF-4+</strong></td>
<td>XRD Standard Patterns</td>
<td>Commercial License</td>
<td>Paid Subscription</td>
<td>Required</td>
</tr>
<tr>
<td><strong>COD (Crystallography Open Database)</strong></td>
<td>Crystal structure, XRD</td>
<td>CC0 / Public Domain</td>
<td>Free</td>
<td>Recommended</td>
</tr>
<tr>
<td><strong>NIST XPS Database</strong></td>
<td>XPS Standard Spectra</td>
<td>Public Domain</td>
<td>Free</td>
<td>Required</td>
</tr>
<tr>
<td><strong>RRUFF Project</strong></td>
<td>Raman/IRMineral Spectra</td>
<td>CC BY-NC-SA 3.0</td>
<td>Free</td>
<td>Required</td>
</tr>
<tr>
<td><strong>SDBS (Spectral Database)</strong></td>
<td>IR/RamanOrganic Compounds</td>
<td>Free</td>
<td>Free</td>
<td>Recommended</td>
</tr>
</tbody>
</table>
<h4>Precautions When Using Data</h4>
<p><strong>When Using Commercial Databases</strong>:</p>
<pre><code class="language-python"># ICDD PDF-4+Example comment when using data
&quot;&quot;&quot;
XRD peak matching using ICDD PDF-4+ database.
Reference: ICDD PDF-4+ 2024 (Entry 01-089-0599)
License: International Centre for Diffraction Data
Note: Commercial license required for publication use
&quot;&quot;&quot;
</code></pre>
<p><strong>When Using Open Data</strong>:</p>
<pre><code class="language-python"># COD (Crystallography Open Database)Usage example
&quot;&quot;&quot;
Crystal structure data from COD.
Reference: COD Entry 1234567
Citation: GraÅ¾ulis, S. et al. (2012) Nucleic Acids Research, 40, D420-D427
License: CC0 1.0 Universal (Public Domain)
URL: http://www.crystallography.net/cod/1234567.html
&quot;&quot;&quot;
</code></pre>
<h3>Best Practices for Code Reproducibility</h3>
<h4>Recording Environment Information</h4>
<pre><code class="language-python">import sys
import numpy as np
import scipy
from scipy import signal
import matplotlib

print(&quot;=== Spectral Analysis Environment ===&quot;)
print(f&quot;Python: {sys.version}&quot;)
print(f&quot;NumPy: {np.__version__}&quot;)
print(f&quot;SciPy: {scipy.__version__}&quot;)
print(f&quot;Matplotlib: {matplotlib.__version__}&quot;)

# Recommended versions(as of October 2025):
# - Python: 3.10or later
# - NumPy: 1.24or later
# - SciPy: 1.10or later
# - Matplotlib: 3.7or later
</code></pre>
<h4>Parameter Documentation</h4>
<p><strong>Bad Example</strong>ï¼ˆNot reproducibleï¼‰:</p>
<pre><code class="language-python">bg = snip_background(spectrum, 50)  # Why 50?
</code></pre>
<p><strong>Good Example</strong>ï¼ˆReproducibleï¼‰:</p>
<pre><code class="language-python"># SNIP method parameter settings
SNIP_ITERATIONS = 50  # Estimated background widthï¼ˆapproximately5%ï¼‰
SNIP_DESCRIPTION = &quot;&quot;&quot;
The number of iterations corresponds to the characteristic width of the background.
XRD data(700 points, 2Î¸=10-80Â°), corresponding to a width of approximately 10Â°â‰ˆ100 points, therefore
iterations=50ï¼ˆabout half the widthï¼‰is appropriate.
&quot;&quot;&quot;
bg = snip_background(spectrum, iterations=SNIP_ITERATIONS)
</code></pre>
<h4>Recording Analysis Parameters</h4>
<pre><code class="language-python"># Peak detection parametersï¼ˆInformation to be recorded in experiment notebookï¼‰
PEAK_DETECTION_PARAMS = {
    'method': 'find_peaks',
    'prominence': 100,  # countsï¼ˆapproximately5å€ï¼‰
    'distance': 10,     # pointsï¼ˆç´„0.1Â° in 2Î¸ï¼‰
    'height': 50,       # countsï¼ˆMinimum physically meaningfulwith physical meaningï¼‰
    'width': 3,         # pointsï¼ˆMinimum peak widthï¼‰
    'noise_level': 20   # countsï¼ˆstandard deviation of baseline regionï¼‰
}

# Save parameters to JSONï¼ˆensuring reproducibilityï¼‰
import json
with open('peak_detection_params.json', 'w') as f:
    json.dump(PEAK_DETECTION_PARAMS, f, indent=2)
</code></pre>
<hr />
<h2>2.3 Background Removal Methods</h2>
<h3>Polynomial Fitting Method</h3>
<p>The simplest method approximates the background with a polynomial and subtracts it from the original data.</p>
<p><strong>Code Example1: å¤šé …å¼Background Removal</strong></p>
<pre><code class="language-python"># Background Removal for XRD Patterns
import numpy as np
import matplotlib.pyplot as plt
from scipy.signal import savgol_filter

# Generate sample XRD data
np.random.seed(42)
two_theta = np.linspace(10, 80, 700)

# Peak components
peaks = (
    1000 * np.exp(-((two_theta - 28) ** 2) / 10) +
    1500 * np.exp(-((two_theta - 32) ** 2) / 8) +
    800 * np.exp(-((two_theta - 47) ** 2) / 12)
)

# Background (amorphous halo)
background = (
    100 +
    50 * np.sin(two_theta / 10) +
    30 * (two_theta / 80) ** 2
)

# Noise
noise = np.random.normal(0, 20, len(two_theta))

# Overall signal
intensity = peaks + background + noise

# Background estimation by polynomial fitting
poly_degree = 5
coeffs = np.polyfit(two_theta, intensity, poly_degree)
background_fit = np.polyval(coeffs, two_theta)

# Background subtraction
intensity_corrected = intensity - background_fit

# Visualization
fig, axes = plt.subplots(2, 2, figsize=(14, 10))

# Raw data
axes[0, 0].plot(two_theta, intensity, linewidth=1)
axes[0, 0].set_xlabel('2Î¸ (degree)')
axes[0, 0].set_ylabel('Intensity')
axes[0, 0].set_title('Raw XRD Pattern')
axes[0, 0].grid(True, alpha=0.3)

# Fitting Results
axes[0, 1].plot(two_theta, intensity, label='Raw data', alpha=0.5)
axes[0, 1].plot(two_theta, background_fit,
                label=f'Polynomial fit (deg={poly_degree})',
                linewidth=2, color='red')
axes[0, 1].set_xlabel('2Î¸ (degree)')
axes[0, 1].set_ylabel('Intensity')
axes[0, 1].set_title('Background Estimation')
axes[0, 1].legend()
axes[0, 1].grid(True, alpha=0.3)

# After correction
axes[1, 0].plot(two_theta, intensity_corrected, linewidth=1,
                color='green')
axes[1, 0].axhline(y=0, color='r', linestyle='--', alpha=0.5)
axes[1, 0].set_xlabel('2Î¸ (degree)')
axes[1, 0].set_ylabel('Intensity')
axes[1, 0].set_title('After Background Subtraction')
axes[1, 0].grid(True, alpha=0.3)

# Comparison with true peaks
axes[1, 1].plot(two_theta, peaks, label='True peaks',
                linewidth=2, alpha=0.7)
axes[1, 1].plot(two_theta, intensity_corrected,
                label='Corrected data', linewidth=1.5, alpha=0.7)
axes[1, 1].set_xlabel('2Î¸ (degree)')
axes[1, 1].set_ylabel('Intensity')
axes[1, 1].set_title('Comparison with True Peaks')
axes[1, 1].legend()
axes[1, 1].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

print(f&quot;Polynomial degree: {poly_degree}&quot;)
print(f&quot;Background average: {background_fit.mean():.1f}&quot;)
print(f&quot;After correctionofå¹³å‡å€¤: {intensity_corrected.mean():.1f}&quot;)
</code></pre>
<p><strong>Output</strong>:</p>
<pre><code>Polynomial degree: 5
Background average: 150.3
After correctionofå¹³å‡å€¤: 0.5
</code></pre>
<p><strong>ä½¿ã„åˆ†ã‘ã‚¬ã‚¤ãƒ‰</strong>:
- <strong>ä½æ¬¡ï¼ˆ2-3æ¬¡ï¼‰</strong>: ç·©ã‚„ã‹ãªãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ï¼ˆIRã€XPSï¼‰
- <strong>ä¸­æ¬¡ï¼ˆ4-6æ¬¡ï¼‰</strong>: ã‚„ã‚„è¤‡é›‘ãªå½¢çŠ¶ï¼ˆXRDéæ™¶è³ªãƒãƒ­ãƒ¼ï¼‰
- <strong>é«˜æ¬¡ï¼ˆ&gt;7æ¬¡ï¼‰</strong>: è¤‡é›‘ãªå½¢çŠ¶ï¼ˆNote:ã‚ªãƒ¼ãƒãƒ¼ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°ofãƒªã‚¹ã‚¯ï¼‰</p>
<h3>SNIP methodï¼ˆStatistics-sensitive Non-linear Iterative Peak-clippingï¼‰</h3>
<p>An advanced method that estimates the background while preserving peak information.</p>
<p><strong>Code Example2: SNIP methodbyBackground Removal</strong></p>
<pre><code class="language-python">def snip_background(spectrum, iterations=30):
    &quot;&quot;&quot;
    Background estimation by SNIP method

    Parameters:
    -----------
    spectrum : array-like
        Input spectrum
    iterations : int
        Iterationå›æ•°ï¼ˆãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ofå¹…ã«å¯¾å¿œï¼‰

    Returns:
    --------
    background : array-like
        Estimated background
    &quot;&quot;&quot;
    spectrum = np.array(spectrum, dtype=float)
    background = np.copy(spectrum)

    for i in range(1, iterations + 1):
        # Comparison with left and right values
        for j in range(i, len(background) - i):
            v1 = (background[j - i] + background[j + i]) / 2
            v2 = background[j]
            background[j] = min(v1, v2)

    return background

# Application of SNIP method
snip_bg = snip_background(intensity, iterations=50)
intensity_snip = intensity - snip_bg

# Visualization
fig, axes = plt.subplots(1, 3, figsize=(16, 5))

# Raw dataã¨SNIPãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰
axes[0].plot(two_theta, intensity, label='Raw data', alpha=0.6)
axes[0].plot(two_theta, snip_bg, label='SNIP background',
             linewidth=2, color='orange')
axes[0].set_xlabel('2Î¸ (degree)')
axes[0].set_ylabel('Intensity')
axes[0].set_title('SNIP Background Estimation')
axes[0].legend()
axes[0].grid(True, alpha=0.3)

# SNIPAfter correction
axes[1].plot(two_theta, intensity_snip, linewidth=1.5,
             color='purple')
axes[1].axhline(y=0, color='r', linestyle='--', alpha=0.5)
axes[1].set_xlabel('2Î¸ (degree)')
axes[1].set_ylabel('Intensity')
axes[1].set_title('After SNIP Subtraction')
axes[1].grid(True, alpha=0.3)

# Polynomial vs SNIP comparison
axes[2].plot(two_theta, intensity_corrected,
             label='Polynomial', alpha=0.7, linewidth=1.5)
axes[2].plot(two_theta, intensity_snip,
             label='SNIP', alpha=0.7, linewidth=1.5)
axes[2].set_xlabel('2Î¸ (degree)')
axes[2].set_ylabel('Intensity')
axes[2].set_title('Polynomial vs SNIP')
axes[2].legend()
axes[2].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

print(f&quot;SNIP Iterationå›æ•°: 50&quot;)
print(f&quot;Polynomial method residual: {np.std(intensity_corrected - peaks):.2f}&quot;)
print(f&quot;SNIP method residual: {np.std(intensity_snip - peaks):.2f}&quot;)
</code></pre>
<p><strong>Advantages of the SNIP Method</strong>:
- Less affected by peaks
- Handles complex background shapes
- Intuitive parameter adjustment (iterations = background width)</p>
<hr />
<h2>2.3 Peak Detectionã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ </h2>
<h3>scipy.signal.find_peaks byåŸºæœ¬çš„ãªPeak Detection</h3>
<p><strong>Code Example3: Peak DetectionofåŸºæœ¬</strong></p>
<pre><code class="language-python">from scipy.signal import find_peaks

# Background Removalæ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã§Peak Detection
peaks_idx, properties = find_peaks(
    intensity_snip,
    height=100,        # Minimum peak height
    prominence=80,     # Prominence (height difference from surroundings)
    distance=10,       # Minimum peak distance (data points)
    width=3           # Minimum peak width
)

peak_positions = two_theta[peaks_idx]
peak_heights = intensity_snip[peaks_idx]

# Visualization
plt.figure(figsize=(14, 6))

plt.plot(two_theta, intensity_snip, linewidth=1.5,
         label='Background-corrected')
plt.plot(peak_positions, peak_heights, 'rx',
         markersize=12, markeredgewidth=2, label='Detected peaks')

# Label peak positions
for pos, height in zip(peak_positions, peak_heights):
    plt.annotate(f'{pos:.1f}Â°',
                xy=(pos, height),
                xytext=(pos, height + 100),
                ha='center',
                fontsize=9,
                bbox=dict(boxstyle='round,pad=0.3',
                         facecolor='yellow', alpha=0.5))

plt.xlabel('2Î¸ (degree)')
plt.ylabel('Intensity')
plt.title('Peak Detection Results')
plt.legend()
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()

print(&quot;=== Detected Peaks ===&quot;)
for i, (pos, height) in enumerate(zip(peak_positions,
                                       peak_heights), 1):
    print(f&quot;Peak {i}: 2Î¸ = {pos:.2f}Â°, Intensity = {height:.1f}&quot;)
</code></pre>
<p><strong>Output</strong>:</p>
<pre><code>=== Detected Peaks ===
Peak 1: 2Î¸ = 28.04Â°, Intensity = 1021.3
Peak 2: 2Î¸ = 32.05Â°, Intensity = 1512.7
Peak 3: 2Î¸ = 47.07Â°, Intensity = 798.5
</code></pre>
<h3>Optimization of Peak Detection Parameters</h3>
<p><strong>Code Example4: Parameter sensitivity analysis</strong></p>
<pre><code class="language-python"># ç•°ãªã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§Peak Detection
prominence_values = [30, 50, 80, 100]

fig, axes = plt.subplots(2, 2, figsize=(14, 10))
axes = axes.ravel()

for i, prom in enumerate(prominence_values):
    peaks_idx, _ = find_peaks(
        intensity_snip,
        prominence=prom,
        distance=5
    )

    axes[i].plot(two_theta, intensity_snip, linewidth=1.5)
    axes[i].plot(two_theta[peaks_idx], intensity_snip[peaks_idx],
                'rx', markersize=10, markeredgewidth=2)
    axes[i].set_xlabel('2Î¸ (degree)')
    axes[i].set_ylabel('Intensity')
    axes[i].set_title(f'Prominence = {prom} ({len(peaks_idx)} peaks)')
    axes[i].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

print(&quot;=== Parameter Sensitivity ===&quot;)
for prom in prominence_values:
    peaks_idx, _ = find_peaks(intensity_snip, prominence=prom)
    print(f&quot;Prominence = {prom:3d}: {len(peaks_idx)} peaks detected&quot;)
</code></pre>
<h3>Peak Fitting (Gaussian and Lorentzian)</h3>
<p><strong>Code Example5: Gaussian fitting</strong></p>
<pre><code class="language-python">from scipy.optimize import curve_fit

def gaussian(x, amplitude, center, sigma):
    &quot;&quot;&quot;Gaussian function&quot;&quot;&quot;
    return amplitude * np.exp(-((x - center) ** 2) / (2 * sigma ** 2))

def lorentzian(x, amplitude, center, gamma):
    &quot;&quot;&quot;Lorentzian function&quot;&quot;&quot;
    return amplitude * gamma**2 / ((x - center)**2 + gamma**2)

# Extract region around first peak
peak_region_mask = (two_theta &gt; 26) &amp; (two_theta &lt; 30)
x_data = two_theta[peak_region_mask]
y_data = intensity_snip[peak_region_mask]

# Gaussian fitting
initial_guess = [1000, 28, 1]  # [amplitude, center, sigma]
params_gauss, _ = curve_fit(gaussian, x_data, y_data,
                             p0=initial_guess)

# Lorentzian fitting
initial_guess_lor = [1000, 28, 0.5]  # [amplitude, center, gamma]
params_lor, _ = curve_fit(lorentzian, x_data, y_data,
                          p0=initial_guess_lor)

# Fitting result
x_fit = np.linspace(x_data.min(), x_data.max(), 200)
y_gauss = gaussian(x_fit, *params_gauss)
y_lor = lorentzian(x_fit, *params_lor)

# Visualization
plt.figure(figsize=(12, 6))

plt.plot(x_data, y_data, 'o', label='Data', markersize=6)
plt.plot(x_fit, y_gauss, '-', linewidth=2,
         label=f'Gaussian (Ïƒ={params_gauss[2]:.2f})')
plt.plot(x_fit, y_lor, '--', linewidth=2,
         label=f'Lorentzian (Î³={params_lor[2]:.2f})')

plt.xlabel('2Î¸ (degree)')
plt.ylabel('Intensity')
plt.title('Peak Fitting: Gaussian vs Lorentzian')
plt.legend()
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()

print(&quot;=== Fitting Results ===&quot;)
print(f&quot;ã‚¬ã‚¦ã‚·ã‚¢ãƒ³:&quot;)
print(f&quot;  Center position: {params_gauss[1]:.3f}Â°&quot;)
print(f&quot;  Amplitude: {params_gauss[0]:.1f}&quot;)
print(f&quot;  Ïƒ: {params_gauss[2]:.3f}Â°&quot;)
print(f&quot;\nãƒ­ãƒ¼ãƒ¬ãƒ³ãƒ„:&quot;)
print(f&quot;  Center position: {params_lor[1]:.3f}Â°&quot;)
print(f&quot;  Amplitude: {params_lor[0]:.1f}&quot;)
print(f&quot;  Î³: {params_lor[2]:.3f}Â°&quot;)
</code></pre>
<hr />
<h2>2.4 XPS Spectral Analysis</h2>
<h3>Shirley-type Background Removal</h3>
<p>XPS spectra have characteristic backgrounds due to inelastic scattering.</p>
<p><strong>Code Example6: Shirley background</strong></p>
<pre><code class="language-python">def shirley_background(x, y, tol=1e-5, max_iter=50):
    &quot;&quot;&quot;
    Shirley-type background estimation

    Parameters:
    -----------
    x : array-like
        ã‚¨ãƒãƒ«ã‚®ãƒ¼è»¸ï¼ˆDescending orderRecommendedï¼‰
    y : array-like
        Intensity
    tol : float
        Convergence checké–¾å€¤
    max_iter : int
        æœ€å¤§Iterationå›æ•°

    Returns:
    --------
    background : array-like
        Shirley background
    &quot;&quot;&quot;
    # Data preparation
    y = np.array(y, dtype=float)
    background = np.zeros_like(y)

    # Values at both ends
    y_min = min(y[0], y[-1])
    y_max = max(y[0], y[-1])

    # Initial background (linear)
    background = np.linspace(y[0], y[-1], len(y))

    # Iteration
    for iteration in range(max_iter):
        background_old = background.copy()

        # Using cumulative sum
        cumsum = np.cumsum(y - background)
        total = cumsum[-1]

        if total == 0:
            break

        # New background
        background = y[-1] + (y[0] - y[-1]) * cumsum / total

        # Convergence check
        if np.max(np.abs(background - background_old)) &lt; tol:
            break

    return background

# Generate XPS sample data (C 1s spectrum)
binding_energy = np.linspace(280, 295, 300)[::-1]  # Descending order
xps_peak = 5000 * np.exp(-((binding_energy - 285) ** 2) / 2)
shirley_bg = np.linspace(500, 200, len(binding_energy))
xps_spectrum = xps_peak + shirley_bg + \
               np.random.normal(0, 50, len(binding_energy))

# Shirley backgroundæ¨å®š
shirley_bg_calc = shirley_background(binding_energy, xps_spectrum)

# Background subtraction
xps_corrected = xps_spectrum - shirley_bg_calc

# Visualization
fig, axes = plt.subplots(1, 3, figsize=(16, 5))

# XPSRaw data
axes[0].plot(binding_energy, xps_spectrum, linewidth=1.5)
axes[0].set_xlabel('Binding Energy (eV)')
axes[0].set_ylabel('Intensity (CPS)')
axes[0].set_title('Raw XPS Spectrum (C 1s)')
axes[0].invert_xaxis()
axes[0].grid(True, alpha=0.3)

# ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰æ¨å®š
axes[1].plot(binding_energy, xps_spectrum,
             label='Raw data', alpha=0.6)
axes[1].plot(binding_energy, shirley_bg_calc,
             label='Shirley background',
             linewidth=2, color='red')
axes[1].set_xlabel('Binding Energy (eV)')
axes[1].set_ylabel('Intensity (CPS)')
axes[1].set_title('Shirley Background Estimation')
axes[1].invert_xaxis()
axes[1].legend()
axes[1].grid(True, alpha=0.3)

# After correction
axes[2].plot(binding_energy, xps_corrected,
             linewidth=1.5, color='green')
axes[2].set_xlabel('Binding Energy (eV)')
axes[2].set_ylabel('Intensity (CPS)')
axes[2].set_title('After Shirley Subtraction')
axes[2].invert_xaxis()
axes[2].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

print(&quot;=== ã‚·ãƒ£ãƒ¼ãƒªãƒ¼Background Removal ===&quot;)
print(f&quot;Energy range: {binding_energy.max():.1f} - &quot;
      f&quot;{binding_energy.min():.1f} eV&quot;)
print(f&quot;Background height (high BE side): {shirley_bg_calc[0]:.1f}&quot;)
print(f&quot;Background height (low BE side): {shirley_bg_calc[-1]:.1f}&quot;)
</code></pre>
<hr />
<h2>2.5 IR and Raman Spectral Analysis</h2>
<h3>Baseline Correction (Asymmetric Least Squares Method)</h3>
<p>IRãƒ»Ramanã‚¹ãƒšã‚¯ãƒˆãƒ«ofè›å…‰Background Removalã«æœ‰åŠ¹ã§ã™ã€‚</p>
<p><strong>Code Example7: ALS methodbyBaseline correction</strong></p>
<pre><code class="language-python">from scipy import sparse
from scipy.sparse.linalg import spsolve

def als_baseline(y, lam=1e5, p=0.01, niter=10):
    &quot;&quot;&quot;
    Baseline estimation by Asymmetric Least Squares method

    Parameters:
    -----------
    y : array-like
        Spectral data
    lam : float
        Smoothing parameter (larger is smoother)
    p : float
        Asymmetry parameter (0-1, smaller avoids peaks more)
    niter : int
        Iterationå›æ•°

    Returns:
    --------
    baseline : array-like
        Estimated baseline
    &quot;&quot;&quot;
    L = len(y)
    D = sparse.diags([1, -2, 1], [0, -1, -2], shape=(L, L-2))
    w = np.ones(L)

    for i in range(niter):
        W = sparse.spdiags(w, 0, L, L)
        Z = W + lam * D.dot(D.transpose())
        z = spsolve(Z, w * y)
        w = p * (y &gt; z) + (1 - p) * (y &lt; z)

    return z

# Generate Raman sample data
raman_shift = np.linspace(200, 2000, 900)
raman_peaks = (
    3000 * np.exp(-((raman_shift - 520) ** 2) / 100) +
    2000 * np.exp(-((raman_shift - 950) ** 2) / 200) +
    1500 * np.exp(-((raman_shift - 1350) ** 2) / 150)
)
fluorescence_bg = 500 + 0.5 * raman_shift + \
                  0.0005 * (raman_shift - 1000) ** 2
raman_spectrum = raman_peaks + fluorescence_bg + \
                 np.random.normal(0, 50, len(raman_shift))

# Application of ALS method
als_bg = als_baseline(raman_spectrum, lam=1e6, p=0.01)
raman_corrected = raman_spectrum - als_bg

# Visualization
fig, axes = plt.subplots(1, 3, figsize=(16, 5))

# Raw data
axes[0].plot(raman_shift, raman_spectrum, linewidth=1.5)
axes[0].set_xlabel('Raman Shift (cmâ»Â¹)')
axes[0].set_ylabel('Intensity (a.u.)')
axes[0].set_title('Raw Raman Spectrum')
axes[0].grid(True, alpha=0.3)

# Baseline estimation
axes[1].plot(raman_shift, raman_spectrum,
             label='Raw data', alpha=0.6)
axes[1].plot(raman_shift, als_bg,
             label='ALS baseline', linewidth=2, color='red')
axes[1].set_xlabel('Raman Shift (cmâ»Â¹)')
axes[1].set_ylabel('Intensity (a.u.)')
axes[1].set_title('ALS Baseline Estimation')
axes[1].legend()
axes[1].grid(True, alpha=0.3)

# After correction
axes[2].plot(raman_shift, raman_corrected,
             linewidth=1.5, color='purple')
axes[2].set_xlabel('Raman Shift (cmâ»Â¹)')
axes[2].set_ylabel('Intensity (a.u.)')
axes[2].set_title('After ALS Subtraction')
axes[2].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

print(&quot;=== ALS Baseline correction ===&quot;)
print(f&quot;Smoothing parameter (Î»): 1e6&quot;)
print(f&quot;Asymmetry parameter (p): 0.01&quot;)
</code></pre>
<hr />
<h2>2.6 Quantitative Phase Analysis (XRD-RIR Method)</h2>
<h3>Reference Intensity Ratio (RIR) Method</h3>
<p>Calculate the weight fraction of each phase from XRD patterns containing multiple phases.</p>
<p><strong>Code Example8: Quantitative Phase Analysis by RIR Method</strong></p>
<pre><code class="language-python"># Generate XRD pattern for two-phase system
two_theta = np.linspace(10, 80, 700)

# Phase Aï¼ˆExample:Î±-Fe2O3ã€ä¸»Peak: 33.2Â°ï¼‰
phase_A = (
    2000 * np.exp(-((two_theta - 33.2) ** 2) / 15) +
    1200 * np.exp(-((two_theta - 35.6) ** 2) / 10) +
    800 * np.exp(-((two_theta - 54.1) ** 2) / 12)
)

# Phase Bï¼ˆExample:Fe3O4ã€ä¸»Peak: 35.5Â°ï¼‰
phase_B = (
    1500 * np.exp(-((two_theta - 35.5) ** 2) / 18) +
    1000 * np.exp(-((two_theta - 30.1) ** 2) / 12) +
    600 * np.exp(-((two_theta - 62.7) ** 2) / 14)
)

# Mixed pattern (Phase A:Phase B = 70:30 wt%)
ratio_A = 0.7
ratio_B = 0.3
mixed_pattern = ratio_A * phase_A + ratio_B * phase_B + \
                np.random.normal(0, 30, len(two_theta))

# RIR values (literature values, relative to corundum)
RIR_A = 3.5  # Î±-Fe2O3 of RIR
RIR_B = 2.8  # Fe3O4 of RIR

# Measurement of main peak intensity
# Phase Aofä¸»Peakï¼ˆ33.2Â°ä»˜è¿‘ï¼‰
peak_A_idx = np.argmax(mixed_pattern[(two_theta &gt; 32) &amp;
                                     (two_theta &lt; 34)])
I_A = mixed_pattern[(two_theta &gt; 32) &amp; (two_theta &lt; 34)][peak_A_idx]

# Phase Bofä¸»Peakï¼ˆ35.5Â°ä»˜è¿‘ï¼‰
peak_B_idx = np.argmax(mixed_pattern[(two_theta &gt; 34.5) &amp;
                                     (two_theta &lt; 36)])
I_B = mixed_pattern[(two_theta &gt; 34.5) &amp; (two_theta &lt; 36)][peak_B_idx]

# Weight fraction calculation by RIR method
# W_A / W_B = (I_A / I_B) * (RIR_B / RIR_A)
ratio_calc = (I_A / I_B) * (RIR_B / RIR_A)

# Normalization
W_A_calc = ratio_calc / (1 + ratio_calc)
W_B_calc = 1 - W_A_calc

# Visualization
fig, axes = plt.subplots(2, 2, figsize=(14, 10))

# Mixed pattern
axes[0, 0].plot(two_theta, mixed_pattern, linewidth=1.5)
axes[0, 0].set_xlabel('2Î¸ (degree)')
axes[0, 0].set_ylabel('Intensity')
axes[0, 0].set_title('Mixed XRD Pattern (Phase A + B)')
axes[0, 0].grid(True, alpha=0.3)

# Individual Phase Contributions
axes[0, 1].plot(two_theta, ratio_A * phase_A,
                label='Phase A (70%)', linewidth=1.5)
axes[0, 1].plot(two_theta, ratio_B * phase_B,
                label='Phase B (30%)', linewidth=1.5)
axes[0, 1].set_xlabel('2Î¸ (degree)')
axes[0, 1].set_ylabel('Intensity')
axes[0, 1].set_title('Individual Phase Contributions')
axes[0, 1].legend()
axes[0, 1].grid(True, alpha=0.3)

# Main Peak Positions
axes[1, 0].plot(two_theta, mixed_pattern, linewidth=1.5)
axes[1, 0].axvline(x=33.2, color='blue',
                   linestyle='--', label='Phase A peak')
axes[1, 0].axvline(x=35.5, color='orange',
                   linestyle='--', label='Phase B peak')
axes[1, 0].set_xlabel('2Î¸ (degree)')
axes[1, 0].set_ylabel('Intensity')
axes[1, 0].set_title('Main Peak Positions')
axes[1, 0].legend()
axes[1, 0].grid(True, alpha=0.3)

# Quantitative Results
categories = ['Phase A', 'Phase B']
true_values = [ratio_A * 100, ratio_B * 100]
calc_values = [W_A_calc * 100, W_B_calc * 100]

x = np.arange(len(categories))
width = 0.35

axes[1, 1].bar(x - width/2, true_values, width,
               label='True', alpha=0.7)
axes[1, 1].bar(x + width/2, calc_values, width,
               label='Calculated (RIR)', alpha=0.7)
axes[1, 1].set_ylabel('Weight Fraction (%)')
axes[1, 1].set_title('Quantitative Phase Analysis')
axes[1, 1].set_xticks(x)
axes[1, 1].set_xticklabels(categories)
axes[1, 1].legend()
axes[1, 1].grid(True, alpha=0.3, axis='y')

plt.tight_layout()
plt.show()

print(&quot;=== Quantitative Phase Analysis by RIR Method ===&quot;)
print(f&quot;ä¸»PeakIntensity:&quot;)
print(f&quot;  Phase A (33.2Â°): {I_A:.1f}&quot;)
print(f&quot;  Phase B (35.5Â°): {I_B:.1f}&quot;)
print(f&quot;\nRIR values:&quot;)
print(f&quot;  Phase A: {RIR_A}&quot;)
print(f&quot;  Phase B: {RIR_B}&quot;)
print(f&quot;\nWeight fraction:&quot;)
print(f&quot;  True value - Phase A: {ratio_A*100:.1f}%, Phase B: {ratio_B*100:.1f}%&quot;)
print(f&quot;  Calculated - Phase A: {W_A_calc*100:.1f}%, Phase B: {W_B_calc*100:.1f}%&quot;)
print(f&quot;  Error: Phase A {abs(ratio_A - W_A_calc)*100:.1f}%&quot;)
</code></pre>
<hr />
<h2>2.7 Automated Spectral Analysis Pipeline</h2>
<h3>Integrated Analysis Pipeline</h3>
<p><strong>Code Example9: Automated spectral analysis pipeline</strong></p>
<pre><code class="language-python">from dataclasses import dataclass
from typing import Tuple, List

@dataclass
class PeakInfo:
    &quot;&quot;&quot;Data class to store peak information&quot;&quot;&quot;
    position: float
    intensity: float
    width: float
    area: float

class SpectrumAnalyzer:
    &quot;&quot;&quot;ã‚¹ãƒšã‚¯ãƒˆãƒ«è‡ªå‹•è§£æã‚¯ãƒ©ã‚¹&quot;&quot;&quot;

    def __init__(self, spectrum_type='XRD'):
        &quot;&quot;&quot;
        Parameters:
        -----------
        spectrum_type : str
            'XRD', 'XPS', 'IR', 'Raman'
        &quot;&quot;&quot;
        self.spectrum_type = spectrum_type
        self.x = None
        self.y = None
        self.y_corrected = None
        self.peaks = []

    def load_data(self, x: np.ndarray, y: np.ndarray):
        &quot;&quot;&quot;Data Loading&quot;&quot;&quot;
        self.x = np.array(x)
        self.y = np.array(y)

    def remove_background(self, method='snip', **kwargs):
        &quot;&quot;&quot;Background Removal&quot;&quot;&quot;
        if method == 'snip':
            iterations = kwargs.get('iterations', 30)
            bg = snip_background(self.y, iterations)
        elif method == 'polynomial':
            degree = kwargs.get('degree', 5)
            coeffs = np.polyfit(self.x, self.y, degree)
            bg = np.polyval(coeffs, self.x)
        elif method == 'als':
            lam = kwargs.get('lam', 1e5)
            p = kwargs.get('p', 0.01)
            bg = als_baseline(self.y, lam, p)
        else:
            raise ValueError(f&quot;Unknown method: {method}&quot;)

        self.y_corrected = self.y - bg
        return self.y_corrected

    def detect_peaks(self, **kwargs):
        &quot;&quot;&quot;Peak Detection&quot;&quot;&quot;
        if self.y_corrected is None:
            raise ValueError(&quot;Run remove_background first&quot;)

        prominence = kwargs.get('prominence', 50)
        distance = kwargs.get('distance', 10)

        peaks_idx, properties = find_peaks(
            self.y_corrected,
            prominence=prominence,
            distance=distance
        )

        self.peaks = []
        for idx in peaks_idx:
            peak = PeakInfo(
                position=self.x[idx],
                intensity=self.y_corrected[idx],
                width=properties['widths'][0] if 'widths' in properties else 0,
                area=0  # å¾Œã§Calculated
            )
            self.peaks.append(peak)

        return self.peaks

    def report(self):
        &quot;&quot;&quot;çµæœãƒ¬ãƒãƒ¼ãƒˆ&quot;&quot;&quot;
        print(f&quot;\n=== {self.spectrum_type} Spectrum Analysis Report ===&quot;)
        print(f&quot;ãƒ‡ãƒ¼ã‚¿ç‚¹æ•°: {len(self.x)}&quot;)
        print(f&quot;Detected Peaksæ•°: {len(self.peaks)}&quot;)
        print(f&quot;\nPeakæƒ…å ±:&quot;)
        for i, peak in enumerate(self.peaks, 1):
            if self.spectrum_type == 'XRD':
                print(f&quot;  Peak {i}: 2Î¸ = {peak.position:.2f}Â°, &quot;
                      f&quot;Intensity = {peak.intensity:.1f}&quot;)
            elif self.spectrum_type == 'XPS':
                print(f&quot;  Peak {i}: BE = {peak.position:.2f} eV, &quot;
                      f&quot;Intensity = {peak.intensity:.1f}&quot;)
            elif self.spectrum_type in ['IR', 'Raman']:
                print(f&quot;  Peak {i}: {peak.position:.1f} cmâ»Â¹, &quot;
                      f&quot;Intensity = {peak.intensity:.1f}&quot;)

# Usage example
analyzer = SpectrumAnalyzer(spectrum_type='XRD')
analyzer.load_data(two_theta, intensity)
analyzer.remove_background(method='snip', iterations=50)
peaks = analyzer.detect_peaks(prominence=80, distance=10)
analyzer.report()

# Visualization
plt.figure(figsize=(14, 6))

plt.subplot(1, 2, 1)
plt.plot(analyzer.x, analyzer.y, label='Raw', alpha=0.5)
plt.plot(analyzer.x, analyzer.y_corrected,
         label='Background-corrected', linewidth=1.5)
plt.xlabel('2Î¸ (degree)')
plt.ylabel('Intensity')
plt.title('Spectrum Processing')
plt.legend()
plt.grid(True, alpha=0.3)

plt.subplot(1, 2, 2)
plt.plot(analyzer.x, analyzer.y_corrected, linewidth=1.5)
peak_positions = [p.position for p in peaks]
peak_intensities = [p.intensity for p in peaks]
plt.plot(peak_positions, peak_intensities, 'rx',
         markersize=12, markeredgewidth=2)
plt.xlabel('2Î¸ (degree)')
plt.ylabel('Intensity')
plt.title('Peak Detection')
plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
</code></pre>
<hr />
<h2>2.8 å®Ÿè·µçš„ãªè½ã¨ã—ç©´ã¨å¯¾ç­–</h2>
<h3>ã‚ˆãã‚ã‚‹å¤±æ•—ä¾‹ã¨ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹</h3>
<h4>å¤±æ•—1: Background Removaloféå‰°é©ç”¨</h4>
<p><strong>ç—‡çŠ¶</strong>: Background Removalå¾Œã€PeakIntensityãŒè² ã«ãªã‚‹ã€ã¾ãŸã¯å°ã•ãªPeakãŒæ¶ˆå¤±</p>
<p><strong>åŸå› </strong>: Polynomial degreeãŒé«˜ã™ãã‚‹ã€ã¾ãŸã¯SNIPofiterationså€¤ãŒå¤§ãã™ãã‚‹</p>
<p><strong>å¯¾ç­–</strong>:</p>
<pre><code class="language-python"># âŒ Bad Exampleï¼šéåº¦ãªBackground Removal
poly_degree = 15  # é«˜ã™ãã‚‹æ¬¡æ•°
bg = np.polyval(np.polyfit(two_theta, intensity, poly_degree), two_theta)
corrected = intensity - bg
# çµæœ: PeakãŒæ­ªã¿ã€è² ofå€¤ãŒç™ºç”Ÿ

# âœ… Good Exampleï¼šé©åˆ‡ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨æ¤œè¨¼
poly_degree = 5  # é©åº¦ãªæ¬¡æ•°
bg = np.polyval(np.polyfit(two_theta, intensity, poly_degree), two_theta)
corrected = intensity - bg

# æ¤œè¨¼: è² ofå€¤ofå‰²åˆãƒã‚§ãƒƒã‚¯
negative_ratio = (corrected &lt; 0).sum() / len(corrected)
if negative_ratio &gt; 0.05:  # 5%or laterãŒè² ãªã‚‰è­¦å‘Š
    print(f&quot;è­¦å‘Š: Background RemovalãŒéå‰°ã§ã™ï¼ˆè² ofå€¤ãŒ{negative_ratio*100:.1f}%ï¼‰&quot;)
    print(&quot;Polynomial degreeä¸‹ã’ã‚‹ã‹ã€SNIPofiterationsæ¸›ã‚‰ã—ã¦ãã ã•ã„&quot;)
</code></pre>
<h4>å¤±æ•—2: Peak detection parametersofä¸é©åˆ‡ãªè¨­å®š</h4>
<p><strong>ç—‡çŠ¶</strong>: Noiseèª¤ã£ã¦Peakã¨ã—ã¦æ¤œå‡ºã€ã¾ãŸã¯çœŸ of Peakè¦‹é€ƒã™</p>
<p><strong>åŸå› </strong>: prominenceã‚„heightofé–¾å€¤ãŒé©åˆ‡ã§ãªã„</p>
<p><strong>å¯¾ç­–</strong>:</p>
<pre><code class="language-python"># âŒ Bad Exampleï¼šå›ºå®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
peaks, _ = find_peaks(spectrum, prominence=50, height=100)
# ç•°ãªã‚‹S/Næ¯”ofãƒ‡ãƒ¼ã‚¿ã«å¯¾å¿œã§ããªã„

# âœ… Good Exampleï¼šé©å¿œçš„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š
# Noiseãƒ¬ãƒ™ãƒ«ofå®šé‡è©•ä¾¡
baseline_region = spectrum[(two_theta &gt; 70) &amp; (two_theta &lt; 80)]  # ä¿¡å·ãªã—é ˜åŸŸ
noise_std = np.std(baseline_region)
snr = spectrum.max() / noise_std

# S/Næ¯”ã«å¿œã˜ãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´
if snr &gt; 50:  # é«˜å“è³ªãƒ‡ãƒ¼ã‚¿
    prominence = 3 * noise_std
    height = 2 * noise_std
elif snr &gt; 20:  # ä¸­å“è³ªãƒ‡ãƒ¼ã‚¿
    prominence = 5 * noise_std
    height = 3 * noise_std
else:  # ä½å“è³ªãƒ‡ãƒ¼ã‚¿
    prominence = 10 * noise_std
    height = 5 * noise_std
    print(f&quot;è­¦å‘Š: S/Næ¯”ãŒä½ã„ï¼ˆ{snr:.1f}ï¼‰ã€‚æ¸¬å®šå†å®Ÿè¡Œã—ã¦ãã ã•ã„&quot;)

peaks, properties = find_peaks(spectrum, prominence=prominence, height=height)
print(f&quot;Noiseãƒ¬ãƒ™ãƒ«: {noise_std:.2f}, S/Næ¯”: {snr:.1f}&quot;)
print(f&quot;Detected Peaksæ•°: {len(peaks)}&quot;)
</code></pre>
<h4>å¤±æ•—3: XPSã‚¹ãƒšã‚¯ãƒˆãƒ«ofèª¤ã£ãŸå®šé‡</h4>
<p><strong>ç—‡çŠ¶</strong>: å…ƒç´ çµ„æˆãŒç‰©ç†çš„ã«ã‚ã‚Šãˆãªã„å€¤ï¼ˆåˆè¨ˆãŒ100%å¤§ããè¶…ãˆã‚‹ã€ã¾ãŸã¯è² ï¼‰</p>
<p><strong>åŸå› </strong>: ã‚·ãƒ£ãƒ¼ãƒªãƒ¼Background Removalofå¤±æ•—ã€ã¾ãŸã¯æ„Ÿåº¦ä¿‚æ•°ofèª¤ç”¨</p>
<p><strong>å¯¾ç­–</strong>:</p>
<pre><code class="language-python"># âŒ Bad Exampleï¼šBackground Removalãªã—ã§å®šé‡
peak_area_C = np.trapz(xps_C_spectrum, binding_energy_C)
peak_area_O = np.trapz(xps_O_spectrum, binding_energy_O)
# çµæœ: ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚‚å«ã‚ãŸç©åˆ†å€¤

# âœ… Good Exampleï¼šã‚·ãƒ£ãƒ¼ãƒªãƒ¼After correction of Peaké¢ç©
bg_C = shirley_background(binding_energy_C, xps_C_spectrum)
corrected_C = xps_C_spectrum - bg_C
peak_area_C = np.trapz(corrected_C[corrected_C &gt; 0],
                       binding_energy_C[corrected_C &gt; 0])

bg_O = shirley_background(binding_energy_O, xps_O_spectrum)
corrected_O = xps_O_spectrum - bg_O
peak_area_O = np.trapz(corrected_O[corrected_O &gt; 0],
                       binding_energy_O[corrected_O &gt; 0])

# æ„Ÿåº¦ä¿‚æ•°ã§è£œæ­£ï¼ˆæ–‡çŒ®å€¤ä½¿ç”¨ï¼‰
SENSITIVITY_FACTORS = {'C': 0.296, 'O': 0.711, 'Fe': 2.957}  # Scofield
atomic_ratio_C = peak_area_C / SENSITIVITY_FACTORS['C']
atomic_ratio_O = peak_area_O / SENSITIVITY_FACTORS['O']

# Normalization
total = atomic_ratio_C + atomic_ratio_O
at_percent_C = (atomic_ratio_C / total) * 100
at_percent_O = (atomic_ratio_O / total) * 100

# æ¤œè¨¼
assert abs(at_percent_C + at_percent_O - 100) &lt; 1, &quot;çµ„æˆofåˆè¨ˆãŒ100%ã§ã‚ã‚Šã¾ã›ã‚“&quot;
print(f&quot;C: {at_percent_C:.1f} at%, O: {at_percent_O:.1f} at%&quot;)
</code></pre>
<h4>å¤±æ•—4: RIRæ³•ofèª¤ç”¨</h4>
<p><strong>ç—‡çŠ¶</strong>: å®šé‡ç›¸åˆ†æofçµæœãŒé‡é‡æ¯”ofåˆè¨ˆ100%å¤§ããé€¸è„±</p>
<p><strong>åŸå› </strong>: RIR valuesofä¸ä¸€è‡´ï¼ˆç•°ãªã‚‹å‚ç…§ç‰©è³ªï¼‰ã€ã¾ãŸã¯Peaké‡ãªã‚Šofç„¡è¦–</p>
<p><strong>å¯¾ç­–</strong>:</p>
<pre><code class="language-python"># âŒ Bad Exampleï¼šPeaké‡ãªã‚Šç„¡è¦–ã—ãŸå®šé‡
I_A = intensity[peak_A_index]  # å˜ä¸€ç‚¹ of Intensity
I_B = intensity[peak_B_index]
# çµæœ: è¿‘æ¥Peakofå½±éŸ¿ã§ErrorãŒå¤§ãã„

# âœ… Good Exampleï¼šPeakåˆ†é›¢ã¨RIRæ³•ofæ­£ã—ã„é©ç”¨
# Peaké ˜åŸŸExtraction
peak_A_region = (two_theta &gt; 32) &amp; (two_theta &lt; 34)
peak_B_region = (two_theta &gt; 34.5) &amp; (two_theta &lt; 36.5)

# Gaussian fitting Peakåˆ†é›¢
from scipy.optimize import curve_fit

def gaussian(x, amp, cen, wid):
    return amp * np.exp(-(x - cen)**2 / (2 * wid**2))

# Phase A of Peakãƒ•ã‚£ãƒƒãƒˆ
popt_A, _ = curve_fit(gaussian, two_theta[peak_A_region],
                      intensity[peak_A_region],
                      p0=[1000, 33.2, 0.5])
I_A_corrected = popt_A[0]  # Peaké«˜ã•

# Phase B of Peakãƒ•ã‚£ãƒƒãƒˆï¼ˆåŒæ§˜ï¼‰
popt_B, _ = curve_fit(gaussian, two_theta[peak_B_region],
                      intensity[peak_B_region],
                      p0=[1500, 35.5, 0.5])
I_B_corrected = popt_B[0]

# RIR valuesofç¢ºèªï¼ˆåŒã˜å‚ç…§ç‰©è³ªã«å¯¾ã™ã‚‹å€¤ä½¿ç”¨ï¼‰
RIR_A = 3.5  # vs Corundum (Î±-Al2O3)
RIR_B = 2.8  # vs Corundum (Î±-Al2O3)

# Weight fractionCalculated
ratio = (I_A_corrected / I_B_corrected) * (RIR_B / RIR_A)
W_A = ratio / (1 + ratio)
W_B = 1 - W_A

# æ¤œè¨¼
assert abs(W_A + W_B - 1.0) &lt; 0.01, &quot;Weight fractionofåˆè¨ˆãŒ1ã§ã‚ã‚Šã¾ã›ã‚“&quot;
print(f&quot;Phase A: {W_A*100:.1f} wt%, Phase B: {W_B*100:.1f} wt%&quot;)
</code></pre>
<h4>å¤±æ•—5: ã‚¹ãƒšã‚¯ãƒˆãƒ«è§£æofæ¸¬å®šErrorç„¡è¦–</h4>
<p><strong>ç—‡çŠ¶</strong>: è§£æçµæœã«Errorç¯„å›²ãŒç¤ºã•ã‚Œãšã€å†ç¾æ€§ãŒè©•ä¾¡ã§ããªã„</p>
<p><strong>åŸå› </strong>: æ¸¬å®šofç¹°ã‚Šè¿”ã—ã‚„Noiseofå½±éŸ¿å®šé‡ã—ã¦ã„ãªã„</p>
<p><strong>å¯¾ç­–</strong>:</p>
<pre><code class="language-python"># âŒ Bad Exampleï¼š1å›æ¸¬å®šofã¿ã€Errorãªã—
peak_position = two_theta[peak_index]
print(f&quot;Peakä½ç½®: {peak_position:.2f}Â°&quot;)

# âœ… Good Exampleï¼šè¤‡æ•°æ¸¬å®šã¨Errorè©•ä¾¡
# åŒä¸€ã‚µãƒ³ãƒ—ãƒ«of3å›æ¸¬å®š
measurements = []
for i in range(3):
    spectrum_i = measure_xrd()  # æ¸¬å®šé–¢æ•°
    bg_i = snip_background(spectrum_i, iterations=50)
    corrected_i = spectrum_i - bg_i
    peaks_i, _ = find_peaks(corrected_i, prominence=80)

    # ä¸»Peakï¼ˆæœ€å¤§IntensityPeakï¼‰ofä½ç½®
    main_peak_i = two_theta[peaks_i[np.argmax(corrected_i[peaks_i])]]
    measurements.append(main_peak_i)

# çµ±è¨ˆå‡¦ç†
peak_mean = np.mean(measurements)
peak_std = np.std(measurements, ddof=1)  # ä¸åæ¨™æº–åå·®
peak_sem = peak_std / np.sqrt(len(measurements))  # æ¨™æº–Error

print(f&quot;Peakä½ç½®: {peak_mean:.3f} Â± {peak_sem:.3f}Â°ï¼ˆå¹³å‡Â±æ¨™æº–Errorã€n=3ï¼‰&quot;)

# æ¸¬å®šErrorãŒå¤§ãã„å ´åˆofè­¦å‘Š
if peak_std &gt; 0.1:  # 0.1Â°or laterofã°ã‚‰ã¤ã
    print(f&quot;è­¦å‘Š: æ¸¬å®šofã°ã‚‰ã¤ããŒå¤§ãã„ï¼ˆÏƒ={peak_std:.3f}Â°ï¼‰&quot;)
    print(&quot;è©¦æ–™ofã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆã‚„è£…ç½®ofå®‰å®šæ€§ç¢ºèªã—ã¦ãã ã•ã„&quot;)
</code></pre>
<hr />
<h2>2.9 ã‚¹ãƒšã‚¯ãƒˆãƒ«è§£æãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ</h2>
<h3>Data Loadingã¨æ¤œè¨¼</h3>
<ul>
<li>[ ] ãƒ‡ãƒ¼ã‚¿å½¢å¼ãŒæ­£ã—ã„ã‹ç¢ºèªï¼ˆ2Î¸, ã‚¨ãƒãƒ«ã‚®ãƒ¼, æ³¢æ•°ofå˜ä½ï¼‰</li>
<li>[ ] ãƒ‡ãƒ¼ã‚¿ç¯„å›²ãŒå¦¥å½“ã‹ç¢ºèªï¼ˆXRD: 10-80Â°, XPS: 0-1200 eV, Raman: 200-2000 cmâ»Â¹ï¼‰</li>
<li>[ ] æ¬ æå€¤ofå‰²åˆç¢ºèªï¼ˆ10%or laterã¯è¦æ³¨æ„ï¼‰</li>
<li>[ ] ãƒ‡ãƒ¼ã‚¿ç‚¹æ•°ãŒååˆ†ã‹ç¢ºèªï¼ˆæœ€ä½100ç‚¹or laterRecommendedï¼‰</li>
<li>[ ] ã‚¹ãƒšã‚¯ãƒˆãƒ« of Visualizationï¼ˆå…¨ä½“åƒofæŠŠæ¡ï¼‰</li>
</ul>
<h3>ç’°å¢ƒã¨å†ç¾æ€§</h3>
<ul>
<li>[ ] Python, NumPy, SciPy, Matplotlibofãƒãƒ¼ã‚¸ãƒ§ãƒ³è¨˜éŒ²</li>
<li>[ ] è§£æãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿JSON/YAMLãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜</li>
<li>[ ] Databaseä½¿ç”¨æ™‚ã¯Licenseã¨å¼•ç”¨æƒ…å ±è¨˜éŒ²</li>
<li>[ ] å•†ç”¨Databaseï¼ˆICDDï¼‰ä½¿ç”¨æ™‚ã¯åˆ©ç”¨è¦ç´„éµå®ˆ</li>
<li>[ ] ä¹±æ•°ã‚·ãƒ¼ãƒ‰å›ºå®šï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰</li>
</ul>
<h3>Noiseãƒ¬ãƒ™ãƒ«è©•ä¾¡</h3>
<ul>
<li>[ ] ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³é ˜åŸŸã§Noiseofæ¨™æº–åå·®Calculated</li>
<li>[ ] S/Næ¯”Calculatedï¼ˆPeaké«˜ã• / Noiseæ¨™æº–åå·®ï¼‰</li>
<li>[ ] S/Næ¯”ãŒ3or laterã§ã‚ã‚‹ã“ã¨ç¢ºèª</li>
<li>[ ] å¿…è¦ã«å¿œã˜ã¦ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°é©ç”¨ï¼ˆNoise Removalï¼‰</li>
</ul>
<h3>Background Removal</h3>
<ul>
<li>[ ] Measurement Techniqueã«å¿œã˜ãŸæ‰‹æ³•é¸æŠ</li>
<li>XRD/Raman: SNIP methodã¾ãŸã¯Polynomial fitting</li>
<li>XPS: ã‚·ãƒ£ãƒ¼ãƒªãƒ¼å‹ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰</li>
<li>IR/Ramanï¼ˆè›å…‰ã‚ã‚Šï¼‰: ALS method</li>
<li>[ ] ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨˜éŒ²ï¼ˆPolynomial degreeã€SNIPIterationæ•°ï¼‰</li>
<li>[ ] Background subtractionå¾Œã€è² ofå€¤ofå‰²åˆç¢ºèªï¼ˆ5%ä»¥ä¸‹ãŒæœ›ã¾ã—ã„ï¼‰</li>
<li>[ ] <strong>è£œæ­£å‰å¾Œofã‚¹ãƒšã‚¯ãƒˆãƒ«å¿…ãšVisualization</strong></li>
</ul>
<h3>Peak Detection</h3>
<ul>
<li>[ ] Noiseãƒ¬ãƒ™ãƒ«ã«åŸºã¥ã„ã¦prominence/heightè¨­å®š</li>
<li>[ ] ç‰©ç†çš„ã«å¦¥å½“ãªPeakå¹…ï¼ˆwidthï¼‰è¨­å®š</li>
<li>[ ] æœ€å°Peaké–“éš”ï¼ˆdistanceï¼‰è¨­å®š</li>
<li>[ ] <strong>Detected Peakså…ƒã‚¹ãƒšã‚¯ãƒˆãƒ«ã«é‡ã­ã¦Visualization</strong></li>
<li>[ ] Peakæ•°ãŒæœŸå¾…å€¤ã¨ä¸€è‡´ã™ã‚‹ã‹ç¢ºèª</li>
</ul>
<h3>Peak Fitting</h3>
<ul>
<li>[ ] Peakå½¢çŠ¶é–¢æ•°é¸æŠï¼ˆã‚¬ã‚¦ã‚·ã‚¢ãƒ³ã€ãƒ­ãƒ¼ãƒ¬ãƒ³ãƒ„ã€Pseudo-Voigtï¼‰</li>
<li>[ ] åˆæœŸå€¤é©åˆ‡ã«è¨­å®šï¼ˆãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°ofåæŸæ€§ï¼‰</li>
<li>[ ] Fitting Results of RÂ²å€¤ç¢ºèªï¼ˆ0.95or laterãŒæœ›ã¾ã—ã„ï¼‰</li>
<li>[ ] ãƒ•ã‚£ãƒƒãƒˆæ›²ç·šã¨å®Ÿæ¸¬å€¤Visualization</li>
<li>[ ] æ®‹å·®ãƒ—ãƒ­ãƒƒãƒˆã§ç³»çµ±Errorç¢ºèª</li>
</ul>
<h3>Quantitative Analysisï¼ˆXRD-RIRæ³•ï¼‰</h3>
<ul>
<li>[ ] RIR valuesofå‚ç…§ç‰©è³ªãŒçµ±ä¸€ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª</li>
<li>[ ] Peaké‡ãªã‚ŠãŒã‚ã‚‹å ´åˆã¯Peakåˆ†é›¢å®Ÿæ–½</li>
<li>[ ] Weight fractionofåˆè¨ˆãŒ100%ã«è¿‘ã„ã‹ç¢ºèªï¼ˆÂ±5%ä»¥å†…ï¼‰</li>
<li>[ ] è¤‡æ•°æ¸¬å®šofå¹³å‡ã¨æ¨™æº–åå·®å ±å‘Š</li>
</ul>
<h3>Quantitative Analysisï¼ˆXPSï¼‰</h3>
<ul>
<li>[ ] ã‚·ãƒ£ãƒ¼ãƒªãƒ¼Background Removalå®Ÿæ–½</li>
<li>[ ] Peaké¢ç©ç©åˆ†ï¼ˆè² ofå€¤é™¤å¤–ï¼‰</li>
<li>[ ] æ„Ÿåº¦ä¿‚æ•°ã§è£œæ­£ï¼ˆScofieldä¿‚æ•°ãªã©ï¼‰</li>
<li>[ ] åŸå­%ofåˆè¨ˆãŒ100%ã§ã‚ã‚‹ã“ã¨ç¢ºèª</li>
<li>[ ] ã‚¹ãƒ”ãƒ³è»Œé“åˆ†è£‚è€ƒæ…®ï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰</li>
</ul>
<h3>çµæœofå¦¥å½“æ€§æ¤œè¨¼</h3>
<ul>
<li>[ ] æ—¢çŸ¥ã‚µãƒ³ãƒ—ãƒ«ã§æ‰‹æ³•æ¤œè¨¼</li>
<li>[ ] æ–‡çŒ®å€¤ã¨æ¯”è¼ƒï¼ˆPeakä½ç½®ã€Intensityæ¯”ï¼‰</li>
<li>[ ] è¤‡æ•°æ¸¬å®šofå†ç¾æ€§ç¢ºèªï¼ˆæ¨™æº–åå·®ã€æ¨™æº–Errorï¼‰</li>
<li>[ ] ç‰©ç†çš„ãƒ»åŒ–å­¦çš„å¦¥å½“æ€§è©•ä¾¡</li>
<li>[ ] æ¸¬å®šErrorã¨è§£æErroråˆ†é›¢</li>
</ul>
<h3>Automationãƒ»Batch processing</h3>
<ul>
<li>[ ] ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å®Ÿè£…ï¼ˆtry-exceptï¼‰</li>
<li>[ ] å‡¦ç†å¤±æ•—æ™‚ofãƒ­ã‚°è¨˜éŒ²</li>
<li>[ ] å‡¦ç†æ™‚é–“æ¸¬å®šãƒ»è¨˜éŒ²</li>
<li>[ ] æˆåŠŸç‡Calculatedãƒ»å ±å‘Šï¼ˆä¾‹: 95/100 files succeededï¼‰</li>
<li>[ ] çµæœJSON/CSVå½¢å¼ã§ä¿å­˜</li>
</ul>
<h3>æ–‡æ›¸åŒ–</h3>
<ul>
<li>[ ] è§£ææ‰‹é †Reproducibleãªå½¢ã§è¨˜éŒ²</li>
<li>[ ] ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®šofæ ¹æ‹ è¨˜è¼‰</li>
<li>[ ] ä½¿ç”¨ã—ãŸDatabaseãƒ»æ–‡çŒ®å¼•ç”¨</li>
<li>[ ] æœ€çµ‚çµæœofä¸ç¢ºã‹ã•æ˜ç¤º</li>
<li>[ ] ã‚³ãƒ¼ãƒ‰ã«ã‚³ãƒ¡ãƒ³ãƒˆè¿½åŠ ï¼ˆå°†æ¥ofè‡ªåˆ†ofãŸã‚ï¼‰</li>
</ul>
<hr />
<h2>2.10 æœ¬ç«  of Summary</h2>
<h3>å­¦ã‚“ã ã“ã¨</h3>
<ol>
<li>
<p><strong>ãƒ‡ãƒ¼ã‚¿Licenseã¨å†ç¾æ€§</strong>
   - ã‚¹ãƒšã‚¯ãƒˆãƒ«Databaseofæ´»ç”¨ã¨Licenseéµå®ˆ
   - ç’°å¢ƒæƒ…å ±ã¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ofæ–‡æ›¸åŒ–
   - ã‚³ãƒ¼ãƒ‰å†ç¾æ€§ofãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹</p>
</li>
<li>
<p><strong>Background Removalæ‰‹æ³•</strong>
   - Polynomial fittingï¼ˆæ±ç”¨ï¼‰
   - SNIP methodï¼ˆXRDã€Ramanï¼‰
   - ã‚·ãƒ£ãƒ¼ãƒªãƒ¼å‹ï¼ˆXPSï¼‰
   - ALS methodï¼ˆIRã€Ramanï¼‰</p>
</li>
<li>
<p><strong>Peak Detection</strong>
   - <code>scipy.signal.find_peaks</code>ofæ´»ç”¨
   - ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–ï¼ˆprominenceã€distanceã€widthï¼‰
   - ã‚¬ã‚¦ã‚·ã‚¢ãƒ³ãƒ»Lorentzian fitting</p>
</li>
<li>
<p><strong>Quantitative Analysis</strong>
   - RIRæ³•byç›¸åˆ†ç‡Calculated
   - XPSå®šé‡ï¼ˆæ„Ÿåº¦ä¿‚æ•°è£œæ­£ï¼‰
   - Peaké¢ç©ofå®šé‡è©•ä¾¡</p>
</li>
<li>
<p><strong>å®Ÿè·µçš„ãªè½ã¨ã—ç©´</strong>
   - Background Removaloféå‰°é©ç”¨å›é¿
   - é©å¿œçš„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š
   - æ¸¬å®šErrorofå®šé‡è©•ä¾¡</p>
</li>
<li>
<p><strong>Automation</strong>
   - ã‚¯ãƒ©ã‚¹ãƒ™ãƒ¼ã‚¹ofè§£æãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
   - è¤‡æ•°Measurement Techniqueã¸ofå¯¾å¿œ</p>
</li>
</ol>
<h3>é‡è¦ãªãƒã‚¤ãƒ³ãƒˆ</h3>
<ul>
<li>âœ… Databaseä½¿ç”¨æ™‚ã¯Licenseã¨å¼•ç”¨å¿…ãšç¢ºèª</li>
<li>âœ… è§£æãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ–‡æ›¸åŒ–ã—å†ç¾æ€§ç¢ºä¿</li>
<li>âœ… Background Removal Measurement Techniqueã”ã¨ã«é©åˆ‡ãªæ‰‹æ³•é¸æŠ</li>
<li>âœ… Peak Detectioninã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´ã¨Visualizationç¢ºèªãŒRequired</li>
<li>âœ… Quantitative Analysisã«ã¯æ¨™æº–è©¦æ–™ã‚„RIR valuesãªã©ofå‚ç…§æƒ…å ±ãŒå¿…è¦</li>
<li>âœ… æ¸¬å®šErrorå®šé‡è©•ä¾¡ã—ã€çµæœã«ä¸ç¢ºã‹ã•æ˜ç¤º</li>
<li>âœ… Automationã«fromå†ç¾æ€§ã¨å‡¦ç†é€Ÿåº¦ãŒå¤§å¹…ã«å‘ä¸Š</li>
</ul>
<h3>Next Chapterã¸</h3>
<p>ç¬¬3ç« inã€ç”»åƒãƒ‡ãƒ¼ã‚¿ï¼ˆSEMã€TEMï¼‰ofè§£ææ‰‹æ³•å­¦ã³ã¾ã™ï¼š
- ç”»åƒå‰å‡¦ç†ï¼ˆNoise Removalã€ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆèª¿æ•´ï¼‰
- ç²’å­æ¤œå‡ºï¼ˆWatershedæ³•ï¼‰
- ç²’å¾„åˆ†å¸ƒè§£æ
- CNNbyç”»åƒåˆ†é¡</p>
<p><strong><a href="./chapter-3.html">ç¬¬3ç« ï¼šç”»åƒãƒ‡ãƒ¼ã‚¿è§£æ â†’</a></strong></p>
<hr />
<h2>æ¼”ç¿’Problem</h2>
<h3>Problem1ï¼ˆDifficulty: Easyï¼‰</h3>
<p>æ¬¡ofæ–‡ç« ofæ­£èª¤åˆ¤å®šã—ã¦ãã ã•ã„ã€‚</p>
<ol>
<li>SNIP method Polynomial fittingfromã‚‚Less affected by peaks</li>
<li>XPSã‚¹ãƒšã‚¯ãƒˆãƒ«ã«ã¯ç·šå½¢ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ãŒé©ã—ã¦ã„ã‚‹</li>
<li>Peak Detectionofprominenceãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯ã€Peaké–“ofæœ€å°è·é›¢æŒ‡å®šã™ã‚‹</li>
</ol>
<details>
<summary>Hint</summary>

1. SNIP methodofå‹•ä½œåŸç†ï¼ˆPeakã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°ï¼‰è€ƒãˆã‚‹
2. XPSofãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã¯éå¼¾æ€§æ•£ä¹±ã«èµ·å› ã™ã‚‹
3. prominenceã€distanceã€widthãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ofæ„å‘³ç¢ºèª

</details>

<details>
<summary>Solution Example</summary>

**è§£ç­”**:
1. **æ­£** - SNIP method Peaké¿ã‘ã¦ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰æ¨å®šã™ã‚‹ãŸã‚ã€å¤šé …å¼fromãƒ­ãƒã‚¹ãƒˆ
2. **èª¤** - XPSã¯ã‚·ãƒ£ãƒ¼ãƒªãƒ¼å‹ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ãŒé©åˆ‡ï¼ˆéå¼¾æ€§æ•£ä¹±byéå¯¾ç§°å½¢çŠ¶ï¼‰
3. **èª¤** - prominence Prominence (height difference from surroundings)ã€Peaké–“è·é›¢ã¯distanceãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿

**Explanation**:
Background Removalæ‰‹æ³•ofé¸æŠã¯æ¸¬å®šåŸç†ã«åŸºã¥ãã“ã¨ãŒé‡è¦ã§ã™ã€‚XPSoféå¼¾æ€§æ•£ä¹±ã€Ramanofè›å…‰ã€XRDoféæ™¶è³ªãƒãƒ­ãƒ¼ãªã©ã€ãã‚Œãã‚Œç•°ãªã‚‹ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å½¢çŠ¶æŒã¡ã¾ã™ã€‚

</details>

<hr />
<h3>Problem2ï¼ˆDifficulty: Mediumï¼‰</h3>
<p>ä»¥ä¸‹ of XRD dataã«å¯¾ã—ã¦ã€SNIP method Background Removalè¡Œã„ã€Peakæ¤œå‡ºã—ã¦ãã ã•ã„ã€‚</p>
<pre><code class="language-python">import numpy as np

# ã‚µãƒ³ãƒ—ãƒ«XRD data
np.random.seed(123)
two_theta = np.linspace(15, 75, 600)
intensity = (
    1200 * np.exp(-((two_theta - 26.6) ** 2) / 12) +
    1800 * np.exp(-((two_theta - 33.8) ** 2) / 10) +
    1000 * np.exp(-((two_theta - 54.8) ** 2) / 15) +
    150 + 50 * np.sin(two_theta / 8) +
    np.random.normal(0, 40, len(two_theta))
)
</code></pre>
<p><strong>è¦æ±‚äº‹é …</strong>:
1. SNIP method Background Removalï¼ˆiterations=40ï¼‰
2. Peak Detectionï¼ˆprominence=100ï¼‰
3. Detected Peaksä½ç½®ã¨IntensityOutput
4. å‡¦ç†å‰å¾Œofã‚¹ãƒšã‚¯ãƒˆãƒ«Visualization</p>
<details>
<summary>Hint</summary>

**å‡¦ç†ãƒ•ãƒ­ãƒ¼**:
1. SNIPé–¢æ•°å®šç¾©ã¾ãŸã¯å†åˆ©ç”¨
2. Background subtraction
3. `find_peaks`ã§Peak Detection
4. çµæœæ•´ç†ã—ã¦Output
5. `matplotlib`ã§3æ®µéšï¼ˆRaw dataã€ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã€After correctionï¼‰Visualization

</details>

<details>
<summary>Solution Example</summary>


<pre><code class="language-python">import numpy as np
import matplotlib.pyplot as plt
from scipy.signal import find_peaks

# SNIPé–¢æ•°ï¼ˆCode Example2fromï¼‰
def snip_background(spectrum, iterations=30):
    spectrum = np.array(spectrum, dtype=float)
    background = np.copy(spectrum)

    for i in range(1, iterations + 1):
        for j in range(i, len(background) - i):
            v1 = (background[j - i] + background[j + i]) / 2
            v2 = background[j]
            background[j] = min(v1, v2)

    return background

# Sample data
np.random.seed(123)
two_theta = np.linspace(15, 75, 600)
intensity = (
    1200 * np.exp(-((two_theta - 26.6) ** 2) / 12) +
    1800 * np.exp(-((two_theta - 33.8) ** 2) / 10) +
    1000 * np.exp(-((two_theta - 54.8) ** 2) / 15) +
    150 + 50 * np.sin(two_theta / 8) +
    np.random.normal(0, 40, len(two_theta))
)

# SNIP methodé©ç”¨
bg = snip_background(intensity, iterations=40)
intensity_corrected = intensity - bg

# Peak Detection
peaks_idx, _ = find_peaks(intensity_corrected, prominence=100)
peak_positions = two_theta[peaks_idx]
peak_intensities = intensity_corrected[peaks_idx]

# çµæœOutput
print(&quot;=== Peak Detectionçµæœ ===&quot;)
for i, (pos, intens) in enumerate(zip(peak_positions,
                                       peak_intensities), 1):
    print(f&quot;Peak {i}: 2Î¸ = {pos:.2f}Â°, Intensity = {intens:.1f}&quot;)

# Visualization
fig, axes = plt.subplots(1, 3, figsize=(16, 5))

axes[0].plot(two_theta, intensity, linewidth=1.5)
axes[0].set_xlabel('2Î¸ (degree)')
axes[0].set_ylabel('Intensity')
axes[0].set_title('Raw XRD Pattern')
axes[0].grid(True, alpha=0.3)

axes[1].plot(two_theta, intensity, label='Raw', alpha=0.6)
axes[1].plot(two_theta, bg, label='SNIP background',
             linewidth=2, color='red')
axes[1].set_xlabel('2Î¸ (degree)')
axes[1].set_ylabel('Intensity')
axes[1].set_title('Background Estimation')
axes[1].legend()
axes[1].grid(True, alpha=0.3)

axes[2].plot(two_theta, intensity_corrected, linewidth=1.5)
axes[2].plot(peak_positions, peak_intensities, 'rx',
             markersize=12, markeredgewidth=2)
axes[2].set_xlabel('2Î¸ (degree)')
axes[2].set_ylabel('Intensity')
axes[2].set_title('After Background Subtraction + Peak Detection')
axes[2].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
</code></pre>


**Output**:

<pre><code>=== Peak Detectionçµæœ ===
Peak 1: 2Î¸ = 26.59Â°, Intensity = 1205.3
Peak 2: 2Î¸ = 33.81Â°, Intensity = 1813.7
Peak 3: 2Î¸ = 54.76Â°, Intensity = 1008.2
</code></pre>


**Explanation**:
SNIP methodofiterations=40ã¯ã€ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰characteristicsçš„ãªå¹…ï¼ˆãƒ‡ãƒ¼ã‚¿ç‚¹æ•°ï¼‰ã«å¯¾å¿œã—ã¾ã™ã€‚ã“ofä¾‹inç·©ã‚„ã‹ãªãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ofãŸã‚ã€40Iterationã§ååˆ†ã§ã™ã€‚prominence=100ã«fromã€NoisePeaké™¤å¤–ã—ã€ä¸»è¦ãª3Peakofã¿æ¤œå‡ºã§ãã¾ã—ãŸã€‚

</details>

<hr />
<h3>Problem3ï¼ˆDifficulty: Hardï¼‰</h3>
<p>è¤‡æ•° of Measurement Techniqueï¼ˆXRDã€XPSã€Ramanï¼‰ of Spectral dataè‡ªå‹•å‡¦ç†ã™ã‚‹ãƒãƒƒãƒã‚·ã‚¹ãƒ†ãƒ æ§‹ç¯‰ã—ã¦ãã ã•ã„ã€‚</p>
<p><strong>Background</strong>:
ææ–™ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãƒ¼from100ã‚µãƒ³ãƒ—ãƒ«ofè¤‡åˆæ¸¬å®šãƒ‡ãƒ¼ã‚¿ï¼ˆXRDã€XPSã€Ramanï¼‰ãŒå¾—ã‚‰ã‚Œã¾ã—ãŸã€‚å„æ¸¬å®šabouté©åˆ‡ãªå‰å‡¦ç†è‡ªå‹•é¸æŠã—ã€Peakæƒ…å ±æŠ½å‡ºã™ã‚‹çµ±åˆã‚·ã‚¹ãƒ†ãƒ ãŒå¿…è¦ã§ã™ã€‚</p>
<p><strong>Tasks</strong>:
1. Measurement Techniqueã«å¿œã˜ãŸæœ€é©ãªBackground Removalæ‰‹æ³•ofè‡ªå‹•é¸æŠ
2. Peak detection parametersofè‡ªå‹•èª¿æ•´
3. Save results in JSON format
4. ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã¨ãƒ­ã‚°Output</p>
<p><strong>Constraints</strong>:
- å„Measurement Techniqueã§ç•°ãªã‚‹ãƒ‡ãƒ¼ã‚¿å½¢å¼ï¼ˆåˆ—åã€å˜ä½ï¼‰
- æ¸¬å®šå“è³ªofã°ã‚‰ã¤ãï¼ˆNoiseãƒ¬ãƒ™ãƒ«ï¼‰
- Processing time: Within 10 seconds/sample</p>
<details>
<summary>Hint</summary>

**Design Guidelines**:
1. `SpectrumAnalyzer`Extend class
2. Measurement Techniqueofè‡ªå‹•åˆ¤å®šï¼ˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã¾ãŸã¯ãƒ•ã‚¡ã‚¤ãƒ«åfromï¼‰
3. é©å¿œçš„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´ï¼ˆNoiseãƒ¬ãƒ™ãƒ«ã«å¿œã˜ã¦prominenceèª¿æ•´ï¼‰
4. JSONOutputã«ã¯Peakä½ç½®ã€Intensityã€æ¨å®šç›¸æƒ…å ±å«ã‚ã‚‹

**Class Design Example**:

<pre><code class="language-python">class AutoSpectrumProcessor:
    def __init__(self):
        self.analyzers = {}  # Measurement Techniqueã”ã¨ofanalyzer

    def detect_spectrum_type(self, data):
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿fromMeasurement Techniqueåˆ¤å®š
        pass

    def adaptive_parameters(self, spectrum):
        # Noiseãƒ¬ãƒ™ãƒ«ã«å¿œã˜ã¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´
        pass

    def batch_process(self, file_list):
        # Process multiple files
        pass
</code></pre>


</details>

<details>
<summary>Solution Example</summary>

**Solution Overview**:
Measurement Techniqueofè‡ªå‹•åˆ¤å®šã€é©å¿œçš„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´ã€çµæœ of Save JSONå«ã‚€çµ±åˆå‡¦ç†ã‚·ã‚¹ãƒ†ãƒ æ§‹ç¯‰ã—ã¾ã™ã€‚

**Implementation Code**:


<pre><code class="language-python">import json
import logging
from pathlib import Path
from typing import Dict, List
from dataclasses import dataclass, asdict

logging.basicConfig(level=logging.INFO)

@dataclass
class SpectrumResult:
    &quot;&quot;&quot;Store analysis results&quot;&quot;&quot;
    spectrum_type: str
    num_peaks: int
    peaks: List[Dict]
    processing_time: float
    background_method: str

class AutoSpectrumProcessor:
    &quot;&quot;&quot;Automated spectral analysis system&quot;&quot;&quot;

    def __init__(self):
        self.bg_methods = {
            'XRD': 'snip',
            'XPS': 'shirley',
            'Raman': 'als',
            'IR': 'als'
        }

    def detect_spectrum_type(self, x: np.ndarray) -&gt; str:
        &quot;&quot;&quot;
        ãƒ‡ãƒ¼ã‚¿ç¯„å›²fromMeasurement Techniqueæ¨å®š
        &quot;&quot;&quot;
        x_range = x.max() - x.min()
        x_min = x.min()

        if x_min &gt; 5 and x_range &lt; 100:  # 2Î¸ç¯„å›²
            return 'XRD'
        elif x_min &gt; 200 and x_range &gt; 500:  # BEç¯„å›²
            return 'XPS'
        elif x_min &gt; 100 and x_range &gt; 1000:  # cm-1ç¯„å›²
            return 'Raman' if x.max() &lt; 4000 else 'IR'
        else:
            return 'Unknown'

    def adaptive_prominence(self, spectrum: np.ndarray) -&gt; float:
        &quot;&quot;&quot;
        Noiseãƒ¬ãƒ™ãƒ«ã«å¿œã˜ã¦prominenceèª¿æ•´
        &quot;&quot;&quot;
        noise_std = np.std(np.diff(spectrum))
        snr = np.max(spectrum) / (noise_std + 1e-10)

        if snr &gt; 50:
            return 0.05 * np.max(spectrum)  # é«˜S/N
        elif snr &gt; 20:
            return 0.08 * np.max(spectrum)  # ä¸­S/N
        else:
            return 0.12 * np.max(spectrum)  # ä½S/N

    def process_spectrum(self, x: np.ndarray, y: np.ndarray,
                        metadata: Dict = None) -&gt; SpectrumResult:
        &quot;&quot;&quot;
        Process single spectrum
        &quot;&quot;&quot;
        import time
        start_time = time.time()

        # Measurement Techniqueofåˆ¤å®š
        if metadata and 'type' in metadata:
            spec_type = metadata['type']
        else:
            spec_type = self.detect_spectrum_type(x)

        logging.info(f&quot;Detected spectrum type: {spec_type}&quot;)

        # Background Removal
        bg_method = self.bg_methods.get(spec_type, 'snip')

        if bg_method == 'snip':
            bg = snip_background(y, iterations=40)
        elif bg_method == 'als':
            bg = als_baseline(y, lam=1e6, p=0.01)
        else:
            # Simple linear (if Shirley not implemented)
            bg = np.linspace(y[0], y[-1], len(y))

        y_corrected = y - bg

        # é©å¿œçš„Peak Detection
        prominence = self.adaptive_prominence(y_corrected)
        peaks_idx, _ = find_peaks(y_corrected, prominence=prominence)

        # Peakæƒ…å ±æ§‹é€ åŒ–
        peaks_info = []
        for idx in peaks_idx:
            peaks_info.append({
                'position': float(x[idx]),
                'intensity': float(y_corrected[idx]),
                'unit': '2Î¸(deg)' if spec_type == 'XRD' else 'cm-1'
            })

        processing_time = time.time() - start_time

        result = SpectrumResult(
            spectrum_type=spec_type,
            num_peaks=len(peaks_idx),
            peaks=peaks_info,
            processing_time=processing_time,
            background_method=bg_method
        )

        return result

    def batch_process(self, data_list: List[Dict],
                     output_file: str = 'results.json'):
        &quot;&quot;&quot;
        Batch processing

        Parameters:
        -----------
        data_list : list of dict
            Each element is {'x': array, 'y': array, 'metadata': dict}
        &quot;&quot;&quot;
        results = []

        for i, data in enumerate(data_list, 1):
            try:
                logging.info(f&quot;Processing spectrum {i}/{len(data_list)}&quot;)
                result = self.process_spectrum(
                    data['x'],
                    data['y'],
                    data.get('metadata')
                )
                results.append(asdict(result))

            except Exception as e:
                logging.error(f&quot;Failed to process spectrum {i}: {e}&quot;)
                continue

        # Save JSON
        with open(output_file, 'w') as f:
            json.dump(results, f, indent=2)

        logging.info(f&quot;Results saved to {output_file}&quot;)
        return results

# Demo execution
if __name__ == &quot;__main__&quot;:
    processor = AutoSpectrumProcessor()

    # Generate sample data (3 types of measurements)
    data_list = []

    # XRD data
    two_theta = np.linspace(20, 60, 400)
    xrd_y = (
        1000 * np.exp(-((two_theta - 28) ** 2) / 10) +
        1500 * np.exp(-((two_theta - 35) ** 2) / 8) +
        100 + np.random.normal(0, 30, len(two_theta))
    )
    data_list.append({
        'x': two_theta,
        'y': xrd_y,
        'metadata': {'type': 'XRD', 'sample': 'Fe2O3'}
    })

    # Ramanãƒ‡ãƒ¼ã‚¿
    raman_shift = np.linspace(200, 2000, 900)
    raman_y = (
        2000 * np.exp(-((raman_shift - 520) ** 2) / 100) +
        1500 * np.exp(-((raman_shift - 950) ** 2) / 150) +
        500 + np.random.normal(0, 50, len(raman_shift))
    )
    data_list.append({
        'x': raman_shift,
        'y': raman_y,
        'metadata': {'type': 'Raman', 'sample': 'Si'}
    })

    # Batch processingå®Ÿè¡Œ
    results = processor.batch_process(data_list,
                                      output_file='spectrum_results.json')

    print(&quot;\n=== Processing Summary ===&quot;)
    for i, result in enumerate(results, 1):
        print(f&quot;Spectrum {i}:&quot;)
        print(f&quot;  Type: {result['spectrum_type']}&quot;)
        print(f&quot;  Peaks detected: {result['num_peaks']}&quot;)
        print(f&quot;  Processing time: {result['processing_time']:.3f}s&quot;)
</code></pre>


**çµæœï¼ˆJSONOutputä¾‹ï¼‰**:

<pre><code class="language-json">[
  {
    &quot;spectrum_type&quot;: &quot;XRD&quot;,
    &quot;num_peaks&quot;: 2,
    &quot;peaks&quot;: [
      {&quot;position&quot;: 28.05, &quot;intensity&quot;: 1023.4, &quot;unit&quot;: &quot;2Î¸(deg)&quot;},
      {&quot;position&quot;: 35.01, &quot;intensity&quot;: 1518.7, &quot;unit&quot;: &quot;2Î¸(deg)&quot;}
    ],
    &quot;processing_time&quot;: 0.045,
    &quot;background_method&quot;: &quot;snip&quot;
  },
  {
    &quot;spectrum_type&quot;: &quot;Raman&quot;,
    &quot;num_peaks&quot;: 2,
    &quot;peaks&quot;: [
      {&quot;position&quot;: 520.3, &quot;intensity&quot;: 2015.6, &quot;unit&quot;: &quot;cm-1&quot;},
      {&quot;position&quot;: 949.8, &quot;intensity&quot;: 1507.2, &quot;unit&quot;: &quot;cm-1&quot;}
    ],
    &quot;processing_time&quot;: 0.052,
    &quot;background_method&quot;: &quot;als&quot;
  }
]
</code></pre>


**è©³ç´°ãªExplanation**:
1. **è‡ªå‹•åˆ¤å®š**: ãƒ‡ãƒ¼ã‚¿ç¯„å›²fromMeasurement Techniqueæ¨å®šï¼ˆXRD: 10-80Â°ã€Raman: 200-2000 cmâ»Â¹ï¼‰
2. **é©å¿œçš„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**: S/Næ¯”fromprominenceè‡ªå‹•èª¿æ•´
3. **æ§‹é€ åŒ–Output**: JSONå½¢å¼ã§å¾Œç¶šè§£æã‚„Databaseç™»éŒ²ã«å¯¾å¿œ
4. **ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°**: å€‹åˆ¥ã‚¹ãƒšã‚¯ãƒˆãƒ«ofå¤±æ•—ãŒãƒãƒƒãƒå…¨ä½“åœæ­¢ã•ã›ãªã„

**è¿½åŠ ofæ¤œè¨äº‹é …**:
- Measurement Techniqueofåˆ¤å®šç²¾åº¦å‘ä¸Šï¼ˆæ©Ÿæ¢°å­¦ç¿’åˆ†é¡å™¨ofå°å…¥ï¼‰
- ã‚¯ãƒ©ã‚¦ãƒ‰ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ï¼ˆS3ã€GCSï¼‰from of Data Loading
- Webãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã§ofãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ Visualization
- Databaseï¼ˆMongoDBï¼‰ã¸ofçµæœä¿å­˜

</details>

<hr />
<h2>References</h2>
<ol>
<li>
<p>Pecharsky, V. K., &amp; Zavalij, P. Y. (2009). "Fundamentals of Powder Diffraction and Structural Characterization of Materials." Springer. ISBN: 978-0387095783</p>
</li>
<li>
<p>Briggs, D., &amp; Seah, M. P. (1990). "Practical Surface Analysis by Auger and X-ray Photoelectron Spectroscopy." Wiley. ISBN: 978-0471920816</p>
</li>
<li>
<p>Ryan, C. G. et al. (1988). "SNIP, a statistics-sensitive background treatment for the quantitative analysis of PIXE spectra in geoscience applications." <em>Nuclear Instruments and Methods in Physics Research B</em>, 34(3), 396-402. DOI: <a href="https://doi.org/10.1016/0168-583X(88)90063-8">10.1016/0168-583X(88)90063-8</a></p>
</li>
<li>
<p>Eilers, P. H. C., &amp; Boelens, H. F. M. (2005). "Baseline Correction with Asymmetric Least Squares Smoothing." <em>Leiden University Medical Centre Report</em>.</p>
</li>
<li>
<p>SciPy Documentation: Signal Processing. URL: <a href="https://docs.scipy.org/doc/scipy/reference/signal.html">https://docs.scipy.org/doc/scipy/reference/signal.html</a></p>
</li>
</ol>
<hr />
<h2>ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³</h2>
<h3>Previous Chapter</h3>
<p><strong><a href="./chapter-1.html">ç¬¬1ç« ï¼šå®Ÿé¨“ãƒ‡ãƒ¼ã‚¿è§£æofåŸºç¤ â†</a></strong></p>
<h3>Next Chapter</h3>
<p><strong><a href="./chapter-3.html">ç¬¬3ç« ï¼šç”»åƒãƒ‡ãƒ¼ã‚¿è§£æ â†’</a></strong></p>
<h3>Series Index</h3>
<p><strong><a href="./index.html">â† Series Indexã«æˆ»ã‚‹</a></strong></p>
<hr />
<h2>è‘—è€…æƒ…å ±</h2>
<p><strong>ä½œæˆè€…</strong>: AI Terakoya Content Team
<strong>ä½œæˆæ—¥</strong>: 2025-10-17
<strong>ãƒãƒ¼ã‚¸ãƒ§ãƒ³</strong>: 1.0</p>
<p><strong>æ›´æ–°å±¥æ­´</strong>:
- 2025-10-17: v1.0 åˆç‰ˆå…¬é–‹</p>
<p><strong>ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯</strong>:
- GitHub Issues: [ãƒªãƒã‚¸ãƒˆãƒªURL]/issues
- Email: yusuke.hashimoto.b8@tohoku.ac.jp</p>
<p><strong>License</strong>: Creative Commons BY 4.0</p>
<hr />
<p><strong>Next Chapterã§å­¦ç¿’ç¶šã‘ã¾ã—ã‚‡ã†ï¼</strong></p><div class="navigation">
    <a href="chapter-1.html" class="nav-button">â† Previous Chapter</a>
    <a href="index.html" class="nav-button">Series Indexã«æˆ»ã‚‹</a>
    <a href="chapter-3.html" class="nav-button">Next Chapter â†’</a>
</div>
    </main>

    
    <section class="disclaimer">
        <h3>Disclaimer</h3>
        <ul>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯æ•™è‚²ãƒ»ç ”ç©¶ãƒ»æƒ…å ±æä¾›ofã¿ç›®çš„ã¨ã—ã¦ãŠã‚Šã€å°‚é–€çš„ãªåŠ©è¨€(æ³•å¾‹ãƒ»ä¼šè¨ˆãƒ»æŠ€è¡“çš„ä¿è¨¼ãªã©)æä¾›ã™ã‚‹ã‚‚ofinã‚ã‚Šã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŠã‚ˆã³ä»˜éšã™ã‚‹Code Exampleã¯ã€Œç¾çŠ¶æœ‰å§¿(AS IS)ã€ã§æä¾›ã•ã‚Œã€æ˜ç¤ºã¾ãŸã¯é»™ç¤ºå•ã‚ãšã€å•†å“æ€§ã€ç‰¹å®šç›®çš„é©åˆæ€§ã€æ¨©åˆ©éä¾µå®³ã€æ­£ç¢ºæ€§ãƒ»å®Œå…¨æ€§ã€å‹•ä½œãƒ»å®‰å…¨æ€§ç­‰ã„ã‹ãªã‚‹ä¿è¨¼ã‚‚ã—ã¾ã›ã‚“ã€‚</li>
            <li>å¤–éƒ¨ãƒªãƒ³ã‚¯ã€ç¬¬ä¸‰è€…ãŒæä¾›ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ»ãƒ„ãƒ¼ãƒ«ãƒ»ãƒ©ã‚¤ãƒ–ãƒ©ãƒªç­‰ of Contentãƒ»å¯ç”¨æ€§ãƒ»å®‰å…¨æ€§aboutã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯ä¸€åˆ‡ofè²¬ä»»è² ã„ã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ofåˆ©ç”¨ãƒ»å®Ÿè¡Œãƒ»è§£é‡ˆã«fromç›´æ¥çš„ãƒ»é–“æ¥çš„ãƒ»ä»˜éšçš„ãƒ»ç‰¹åˆ¥ãƒ»çµæœçš„ãƒ»æ‡²ç½°çš„æå®³ãŒç”Ÿã˜ãŸå ´åˆã§ã‚‚ã€é©ç”¨æ³•ã§è¨±å®¹ã•ã‚Œã‚‹æœ€å¤§é™ofç¯„å›²ã§ã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯è²¬ä»»è² ã„ã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ of Contentã¯ã€äºˆå‘Šãªãå¤‰æ›´ãƒ»æ›´æ–°ãƒ»æä¾›åœæ­¢ã•ã‚Œã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ofè‘—ä½œæ¨©ãƒ»Licenseã¯æ˜è¨˜ã•ã‚ŒãŸæ¡ä»¶(ä¾‹: CC BY 4.0)ã«å¾“ã„ã¾ã™ã€‚å½“è©²Licenseã¯é€šå¸¸ã€ç„¡ä¿è¨¼æ¡é …å«ã¿ã¾ã™ã€‚</li>
        </ul>
    </section>

<footer>
        <p><strong>ä½œæˆè€…</strong>: AI Terakoya Content Team</p>
        <p><strong>ãƒãƒ¼ã‚¸ãƒ§ãƒ³</strong>: 1.0 | <strong>ä½œæˆæ—¥</strong>: 2025-10-17</p>
        <p><strong>License</strong>: Creative Commons BY 4.0</p>
        <p>Â© 2025 AI Terakoya. All rights reserved.</p>
    </footer>
</body>
</html>
