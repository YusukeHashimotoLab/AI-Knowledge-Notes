<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Chapter 3ï¼šç•°å¸¸æ¤œçŸ¥ã¨æ•…éšœè¨ºæ–­ - ProcessData Analysiså®Ÿè·µ Series">
    <title>Chapter 3ï¼šç•°å¸¸æ¤œçŸ¥ã¨æ•…éšœè¨ºæ–­ - ProcessData Analysiså®Ÿè·µ | PI Knowledge Hub</title>

        <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif;
            line-height: 1.8; color: #333; background: #f5f5f5;
        }
        header {
            background: linear-gradient(135deg, #11998e 0%, #38ef7d 100%);
            color: white; padding: 2rem 1rem; text-align: center;
        }
        h1 { font-size: 2rem; margin-bottom: 0.5rem; }
        .subtitle { opacity: 0.9; font-size: 1.1rem; }
        .container { max-width: 1200px; margin: 2rem auto; padding: 0 1rem; }
        .back-link {
            display: inline-block; margin-bottom: 2rem; padding: 0.5rem 1rem;
            background: white; color: #11998e; text-decoration: none;
            border-radius: 6px; font-weight: 600;
        }
        .content-box {
            background: white; padding: 2rem; border-radius: 12px;
            margin-bottom: 2rem; box-shadow: 0 2px 8px rgba(0,0,0,0.1);
        }
        h2 {
            color: #11998e; margin: 2rem 0 1rem 0;
            padding-bottom: 0.5rem; border-bottom: 3px solid #11998e;
        }
        h3 { color: #2c3e50; margin: 1.5rem 0 1rem 0; }
        h4 { color: #2c3e50; margin: 1rem 0 0.5rem 0; }
        p { margin-bottom: 1rem; }
        ul, ol { margin-left: 2rem; margin-bottom: 1rem; }
        li { margin-bottom: 0.5rem; }
        pre {
            background: #1e1e1e; color: #d4d4d4; padding: 1.5rem;
            border-radius: 8px; overflow-x: auto; margin: 1rem 0;
            border-left: 4px solid #11998e;
        }
        code {
            font-family: 'Courier New', monospace; font-size: 0.9rem;
        }
        .key-point {
            background: #e8f5e9; padding: 1rem; border-radius: 6px;
            border-left: 4px solid #4caf50; margin: 1rem 0;
        }
        .tech-note {
            background: #e3f2fd; padding: 1rem; border-radius: 6px;
            border-left: 4px solid #2196f3; margin: 1rem 0;
        }
        .formula {
            background: #f0f7ff; padding: 1rem; border-radius: 6px;
            margin: 1rem 0; overflow-x: auto;
        }
        table {
            width: 100%; border-collapse: collapse; margin: 1rem 0;
        }
        th, td {
            border: 1px solid #ddd; padding: 0.75rem; text-align: left;
        }
        th {
            background: #11998e; color: white; font-weight: 600;
        }
        tr:nth-child(even) { background: #f9f9f9; }
        .nav-buttons {
            display: flex; justify-content: space-between; margin-top: 3rem;
        }
        .nav-buttons a {
            padding: 0.75rem 1.5rem;
            background: linear-gradient(135deg, #11998e 0%, #38ef7d 100%);
            color: white; text-decoration: none; border-radius: 6px;
            font-weight: 600;
        }
        footer {
            background: #2c3e50; color: white; text-align: center;
            padding: 2rem 1rem; margin-top: 4rem;
        }
        @media (max-width: 768px) {
            h1 { font-size: 1.6rem; }
            .container { padding: 0 0.5rem; }
            pre { padding: 1rem; }
        }
    
        
    
        /* Breadcrumb styles */
        .breadcrumb {
            background: #f7fafc;
            padding: 0.75rem 1rem;
            border-bottom: 1px solid #e2e8f0;
            font-size: 0.9rem;
        }

        .breadcrumb-content {
            max-width: 900px;
            margin: 0 auto;
            display: flex;
            align-items: center;
            flex-wrap: wrap;
            gap: 0.5rem;
        }

        .breadcrumb a {
            color: #667eea;
            text-decoration: none;
            transition: color 0.2s;
        }

        .breadcrumb a:hover {
            color: #764ba2;
            text-decoration: underline;
        }

        .breadcrumb-separator {
            color: #a0aec0;
            margin: 0 0.25rem;
        }

        .breadcrumb-current {
            color: #4a5568;
            font-weight: 500;
        }
    </style>
</head>
<body>
            <nav class="breadcrumb">
        <div class="breadcrumb-content">
            <a href="../../index.html">AI Terakoya Top</a><span class="breadcrumb-separator">â€º</span><a href="../../PI/index.html">Process Informatics</a><span class="breadcrumb-separator">â€º</span><a href="../../PI/process-data-analysis/index.html">Process Data Analysis</a><span class="breadcrumb-separator">â€º</span><span class="breadcrumb-current">Chapter 3</span>
        </div>
    </nav>

        <header>
        <div class="container">
            <h1>Chapter 3ï¼šç•°å¸¸æ¤œçŸ¥ã¨æ•…éšœè¨ºæ–­</h1>
            <p class="subtitle">Anomaly Detection and Fault Diagnosis for Process Systems</p>
            <div class="meta">
                <span class="meta">ğŸ“š ProcessData Analysiså®Ÿè·µ Series</span>
                <span class="meta">â±ï¸ Reading Time: 35-40 minutes</span>
                <span class="meta">ğŸ’» Code Examples: 8</span>
                <span class="meta">ğŸ“ Difficulty: Intermediateï½Advanced</span>
            </div>
        </div>
    </header>

    <div class="container">
        <section>
            <h2>3.1 ã‚¤ãƒ³ãƒˆãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³</h2>
            <p>
                Chemical Plantã®Safetyæ€§ã¨ç”Ÿç”£æ€§ã‚’ç¶­æŒã™ã‚‹ãŸã‚ã«ã¯ã€ç•°å¸¸ã®æ—©æœŸæ¤œçŸ¥ã¨æ•…éšœåŸå› ã®è¿…é€Ÿãªè¨ºæ–­ãŒä¸å¯æ¬ ã§ã™ã€‚
                ã‚»ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ç•°å¸¸ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è‡ªå‹•çš„ã«æ¤œå‡ºã—ã€æ•…éšœç®‡æ‰€ã‚’ç‰¹å®šã™ã‚‹æŠ€è¡“ã¯ã€ãƒ—ãƒ©ãƒ³ãƒˆé‹è»¢ã®é«˜åº¦åŒ–ã«ãŠã„ã¦é‡è¦ãªå½¹å‰²ã‚’æœãŸã—ã¾ã™ã€‚
            </p>

            <p>
                æœ¬ Chapterã§ã¯ã€çµ±è¨ˆçš„æ‰‹æ³•ã‹ã‚‰Machine Learningã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã€Deep Learningã¾ã§ã€8ã¤ã®å®Ÿè·µçš„ãªç•°å¸¸æ¤œçŸ¥ãƒ»æ•…éšœè¨ºæ–­æŠ€è¡“ã‚’å®Ÿè£…ã—ã¾ã™ã€‚
                å„æ‰‹æ³•ã®ç‰¹æ€§ã‚’ç†è§£ã—ã€Processç‰¹æ€§ã«å¿œã˜ãŸé©åˆ‡ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’é¸æŠã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚
            </p>

            <div class="callout callout-info">
                <h4>ğŸ“Š æœ¬ Chapterã§å­¦ã¶ã“ã¨</h4>
                <ul style="margin-bottom: 0;">
                    <li>çµ±è¨ˆçš„ç•°å¸¸æ¤œçŸ¥ï¼ˆZ-score, Modified Z-scoreï¼‰</li>
                    <li>Machine Learningã«ã‚ˆã‚‹ç•°å¸¸æ¤œçŸ¥ï¼ˆIsolation Forest, One-Class SVMï¼‰</li>
                    <li>Deep Learningã«ã‚ˆã‚‹ç•°å¸¸æ¤œçŸ¥ï¼ˆAutoencoder, LSTMï¼‰</li>
                    <li>æ•…éšœ minutesé¡ã¨ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æ‰‹æ³•</li>
                    <li>æ ¹æœ¬åŸå›  minutesæï¼ˆGrangerå› æœæ€§æ¤œå®šï¼‰</li>
                </ul>
            </div>
        </section>

        <section>
            <h2>3.2 çµ±è¨ˆçš„ç•°å¸¸æ¤œçŸ¥</h2>
            <p>
                çµ±è¨ˆçš„æ‰‹æ³•ã¯è§£é‡ˆæ€§ãŒé«˜ãã€è¨ˆç®—ã‚³ã‚¹ãƒˆãŒä½ã„ãŸã‚ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ Monitoringã«é©ã—ã¦ã„ã¾ã™ã€‚
                æ­£è¦ minuteså¸ƒã‚’ä»®å®šã—ãŸZ-scoreãƒ™ãƒ¼ã‚¹ã®æ‰‹æ³•ã¨ã€å¤–ã‚Œå€¤ã«é ‘å¥ãªModified Z-scoreã‚’çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã§ã€é«˜ç²¾åº¦ãªæ¤œçŸ¥ã‚’å®Ÿç¾ã—ã¾ã™ã€‚
            </p>

            <div class="example-box">
                <h4>Example 1: çµ±è¨ˆçš„ç•°å¸¸æ¤œçŸ¥ï¼ˆZ-score & Modified Z-scoreï¼‰</h4>
                <p>æ¨™æº–çš„ãªZ-scoreã¨å¤–ã‚Œå€¤ã«é ‘å¥ãªModified Z-scoreã‚’çµ„ã¿åˆã‚ã›ãŸç•°å¸¸æ¤œçŸ¥ã‚’å®Ÿè£…ã—ã¾ã™ã€‚</p>
                <pre><code># ===================================
# Example 1: çµ±è¨ˆçš„ç•°å¸¸æ¤œçŸ¥
# ===================================
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from scipy import stats

# Processãƒ‡ãƒ¼ã‚¿ç”Ÿæˆï¼ˆåå¿œå™¨æ¸©åº¦ã€ç•°å¸¸ã‚’å«ã‚€ï¼‰
np.random.seed(42)
n_samples = 500
normal_data = np.random.normal(350, 2, n_samples)

# ç•°å¸¸ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ ï¼ˆ3ç¨®é¡ï¼‰
anomaly_indices = [50, 150, 250, 350, 450]
normal_data[anomaly_indices] = [360, 340, 365, 335, 362]  # ç•°å¸¸å€¤

df = pd.DataFrame({'temperature': normal_data})

def detect_anomalies_zscore(data, threshold=3.0):
    """æ¨™æº–Z-scoreæ³•ã«ã‚ˆã‚‹ç•°å¸¸æ¤œçŸ¥"""
    mean = data.mean()
    std = data.std()
    z_scores = np.abs((data - mean) / std)
    return z_scores > threshold, z_scores

def detect_anomalies_modified_zscore(data, threshold=3.5):
    """Modified Z-scoreæ³•ï¼ˆä¸­å¤®å€¤ãƒ™ãƒ¼ã‚¹ã€å¤–ã‚Œå€¤ã«é ‘å¥ï¼‰"""
    median = data.median()
    mad = np.median(np.abs(data - median))
    modified_z_scores = 0.6745 * (data - median) / mad
    return np.abs(modified_z_scores) > threshold, modified_z_scores

# ä¸¡æ‰‹æ³•ã‚’é©ç”¨
is_anomaly_z, z_scores = detect_anomalies_zscore(df['temperature'])
is_anomaly_mod, mod_z_scores = detect_anomalies_modified_zscore(df['temperature'])

# çµæœæ¯”è¼ƒ
print("ç•°å¸¸æ¤œçŸ¥çµæœ:")
print(f"Z-scoreæ³•: {is_anomaly_z.sum()}ã®ç•°å¸¸ã‚’æ¤œå‡º")
print(f"Modified Z-scoreæ³•: {is_anomaly_mod.sum()}ã®ç•°å¸¸ã‚’æ¤œå‡º")

# æ¤œå‡ºç²¾åº¦ã®è©•ä¾¡
true_anomalies = np.zeros(n_samples, dtype=bool)
true_anomalies[anomaly_indices] = True

tp_z = np.sum(is_anomaly_z & true_anomalies)
fp_z = np.sum(is_anomaly_z & ~true_anomalies)
precision_z = tp_z / is_anomaly_z.sum() if is_anomaly_z.sum() > 0 else 0
recall_z = tp_z / true_anomalies.sum()

tp_mod = np.sum(is_anomaly_mod & true_anomalies)
fp_mod = np.sum(is_anomaly_mod & ~true_anomalies)
precision_mod = tp_mod / is_anomaly_mod.sum() if is_anomaly_mod.sum() > 0 else 0
recall_mod = tp_mod / true_anomalies.sum()

print(f"\nZ-scoreæ³•: Precision={precision_z:.2f}, Recall={recall_z:.2f}")
print(f"Modified Z-scoreæ³•: Precision={precision_mod:.2f}, Recall={recall_mod:.2f}")

# å¯è¦–åŒ–
fig, axes = plt.subplots(2, 1, figsize=(14, 8))

axes[0].plot(df['temperature'], 'b-', alpha=0.6, label='ãƒ‡ãƒ¼ã‚¿')
axes[0].scatter(np.where(is_anomaly_z)[0], df.loc[is_anomaly_z, 'temperature'],
                color='red', s=100, zorder=5, label=f'ç•°å¸¸ (Z-score)')
axes[0].axhline(df['temperature'].mean() + 3*df['temperature'].std(),
                color='r', linestyle='--', alpha=0.5, label='Â±3Ïƒé–¾å€¤')
axes[0].axhline(df['temperature'].mean() - 3*df['temperature'].std(),
                color='r', linestyle='--', alpha=0.5)
axes[0].set_ylabel('æ¸©åº¦ (Â°C)')
axes[0].set_title('Z-scoreæ³•')
axes[0].legend()
axes[0].grid(True, alpha=0.3)

axes[1].plot(df['temperature'], 'b-', alpha=0.6, label='ãƒ‡ãƒ¼ã‚¿')
axes[1].scatter(np.where(is_anomaly_mod)[0], df.loc[is_anomaly_mod, 'temperature'],
                color='red', s=100, zorder=5, label='ç•°å¸¸ (Modified Z-score)')
axes[1].set_xlabel('ã‚µãƒ³ãƒ—ãƒ«')
axes[1].set_ylabel('æ¸©åº¦ (Â°C)')
axes[1].set_title('Modified Z-scoreæ³•ï¼ˆå¤–ã‚Œå€¤ã«é ‘å¥ï¼‰')
axes[1].legend()
axes[1].grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('statistical_anomaly_detection.png', dpi=300)
print("\nçµæœ: Modified Z-scoreãŒå¤–ã‚Œå€¤ã®å½±éŸ¿ã‚’å—ã‘ã«ããã€ã‚ˆã‚Šæ­£ç¢º")
</code></pre>
            </div>
        </section>

        <section>
            <h2>3.3 Machine Learningã«ã‚ˆã‚‹ç•°å¸¸æ¤œçŸ¥</h2>
            <p>
                Machine Learningã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã¯ã€é«˜æ¬¡å…ƒãƒ‡ãƒ¼ã‚¿ã‚„è¤‡é›‘ãªéç·šå½¢ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¤œçŸ¥ã«å„ªã‚Œã¦ã„ã¾ã™ã€‚
                æ•™å¸«ãªã—å­¦ç¿’ã«ã‚ˆã‚Šã€æ­£å¸¸ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‹ã‚‰ç•°å¸¸ã‚’è­˜åˆ¥ã§ãã‚‹ç‚¹ãŒå®Ÿç”¨ä¸Šã®å¤§ããªåˆ©ç‚¹ã§ã™ã€‚
            </p>

            <div class="example-box">
                <h4>Example 2: Isolation Forestã«ã‚ˆã‚‹ç•°å¸¸æ¤œçŸ¥</h4>
                <p>ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆãƒ™ãƒ¼ã‚¹ã®åŠ¹ç‡çš„ãªç•°å¸¸æ¤œçŸ¥ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’å®Ÿè£…ã—ã¾ã™ã€‚</p>
                <pre><code># ===================================
# Example 2: Isolation Forest
# ===================================
from sklearn.ensemble import IsolationForest

# å¤šå¤‰é‡Processãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
np.random.seed(42)
n_normal = 450
n_anomaly = 50

# æ­£å¸¸ãƒ‡ãƒ¼ã‚¿ï¼ˆæ¸©åº¦ã€åœ§åŠ›ã€æµé‡ã®ç›¸é–¢ã‚ã‚Šï¼‰
normal_temp = np.random.normal(350, 3, n_normal)
normal_pressure = 5 + 0.01 * normal_temp + np.random.normal(0, 0.2, n_normal)
normal_flow = 100 + 0.5 * normal_temp + np.random.normal(0, 5, n_normal)

# ç•°å¸¸ãƒ‡ãƒ¼ã‚¿ï¼ˆç›¸é–¢ãŒå´©ã‚Œã‚‹ï¼‰
anomaly_temp = np.random.uniform(340, 370, n_anomaly)
anomaly_pressure = np.random.uniform(4, 7, n_anomaly)
anomaly_flow = np.random.uniform(80, 150, n_anomaly)

# ãƒ‡ãƒ¼ã‚¿çµåˆ
X = np.column_stack([
    np.concatenate([normal_temp, anomaly_temp]),
    np.concatenate([normal_pressure, anomaly_pressure]),
    np.concatenate([normal_flow, anomaly_flow])
])
y_true = np.concatenate([np.zeros(n_normal), np.ones(n_anomaly)])

df_process = pd.DataFrame(X, columns=['temperature', 'pressure', 'flow'])
df_process['is_anomaly_true'] = y_true

# Isolation Forestè¨“ç·´
iso_forest = IsolationForest(
    contamination=0.1,  # æœŸå¾…ã•ã‚Œã‚‹ç•°å¸¸å‰²åˆ
    random_state=42,
    n_estimators=100
)
predictions = iso_forest.fit_predict(X)
anomaly_scores = iso_forest.score_samples(X)

df_process['anomaly_score'] = anomaly_scores
df_process['is_anomaly_pred'] = predictions == -1

# è©•ä¾¡
from sklearn.metrics import classification_report, confusion_matrix

print("Isolation Forestçµæœ:")
print(classification_report(y_true, predictions == -1, target_names=['æ­£å¸¸', 'ç•°å¸¸']))
print("\næ··åŒè¡Œåˆ—:")
print(confusion_matrix(y_true, predictions == -1))

# å¯è¦–åŒ–ï¼ˆ3Dæ•£å¸ƒå›³ï¼‰
from mpl_toolkits.mplot3d import Axes3D

fig = plt.figure(figsize=(14, 6))
ax1 = fig.add_subplot(121, projection='3d')
ax2 = fig.add_subplot(122, projection='3d')

# çœŸã®ç•°å¸¸
scatter1 = ax1.scatter(df_process['temperature'], df_process['pressure'],
                       df_process['flow'], c=df_process['is_anomaly_true'],
                       cmap='RdYlGn_r', s=30, alpha=0.6)
ax1.set_xlabel('æ¸©åº¦ (Â°C)')
ax1.set_ylabel('åœ§åŠ› (MPa)')
ax1.set_zlabel('æµé‡ (mÂ³/h)')
ax1.set_title('çœŸã®ç•°å¸¸ãƒ©ãƒ™ãƒ«')
plt.colorbar(scatter1, ax=ax1)

# æ¤œå‡ºçµæœ
scatter2 = ax2.scatter(df_process['temperature'], df_process['pressure'],
                       df_process['flow'], c=df_process['anomaly_score'],
                       cmap='RdYlGn', s=30, alpha=0.6)
ax2.set_xlabel('æ¸©åº¦ (Â°C)')
ax2.set_ylabel('åœ§åŠ› (MPa)')
ax2.set_zlabel('æµé‡ (mÂ³/h)')
ax2.set_title('Isolation Forestç•°å¸¸ã‚¹ã‚³ã‚¢')
plt.colorbar(scatter2, ax=ax2)

plt.tight_layout()
plt.savefig('isolation_forest.png', dpi=300)
print("\nçµæœ: é«˜æ¬¡å…ƒç©ºé–“ã§ã®ç•°å¸¸ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åŠ¹ç‡çš„ã«æ¤œå‡º")
</code></pre>
            </div>

            <div class="example-box">
                <h4>Example 3: One-Class SVMã«ã‚ˆã‚‹æ–°è¦æ€§æ¤œçŸ¥</h4>
                <p>æ­£å¸¸ãƒ‡ãƒ¼ã‚¿ã®å¢ƒç•Œã‚’å­¦ç¿’ã—ã€æœªçŸ¥ã®ç•°å¸¸ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡ºã—ã¾ã™ã€‚</p>
                <pre><code># ===================================
# Example 3: One-Class SVM
# ===================================
from sklearn.svm import OneClassSVM
from sklearn.preprocessing import StandardScaler

# ãƒ‡ãƒ¼ã‚¿ã®æ¨™æº–åŒ–ï¼ˆSVMã«ã¯é‡è¦ï¼‰
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# One-Class SVMè¨“ç·´
oc_svm = OneClassSVM(
    kernel='rbf',
    gamma='auto',
    nu=0.1  # ç•°å¸¸ã®ä¸Šé™å‰²åˆ
)
predictions_svm = oc_svm.fit_predict(X_scaled)
decision_scores = oc_svm.decision_function(X_scaled)

df_process['decision_score'] = decision_scores
df_process['is_anomaly_svm'] = predictions_svm == -1

# è©•ä¾¡
print("\nOne-Class SVMçµæœ:")
print(classification_report(y_true, predictions_svm == -1, target_names=['æ­£å¸¸', 'ç•°å¸¸']))

# æ±ºå®šå¢ƒç•Œã®å¯è¦–åŒ–ï¼ˆ2DæŠ•å½±ï¼‰
fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# æ¸©åº¦-åœ§åŠ›å¹³é¢
xx, yy = np.meshgrid(np.linspace(X_scaled[:, 0].min()-1, X_scaled[:, 0].max()+1, 100),
                     np.linspace(X_scaled[:, 1].min()-1, X_scaled[:, 1].max()+1, 100))
Z = oc_svm.decision_function(np.c_[xx.ravel(), yy.ravel(), np.zeros(xx.ravel().shape[0])])
Z = Z.reshape(xx.shape)

axes[0].contourf(xx, yy, Z, levels=np.linspace(Z.min(), 0, 7), cmap='RdYlGn', alpha=0.3)
axes[0].contour(xx, yy, Z, levels=[0], linewidths=2, colors='red')
axes[0].scatter(X_scaled[y_true==0, 0], X_scaled[y_true==0, 1],
                c='green', s=20, alpha=0.6, label='æ­£å¸¸')
axes[0].scatter(X_scaled[y_true==1, 0], X_scaled[y_true==1, 1],
                c='red', s=50, alpha=0.8, marker='x', label='ç•°å¸¸')
axes[0].set_xlabel('æ¸©åº¦ï¼ˆæ¨™æº–åŒ–ï¼‰')
axes[0].set_ylabel('åœ§åŠ›ï¼ˆæ¨™æº–åŒ–ï¼‰')
axes[0].set_title('One-Class SVMæ±ºå®šå¢ƒç•Œ')
axes[0].legend()

# æ±ºå®šã‚¹ã‚³ã‚¢ã® minuteså¸ƒ
axes[1].hist(decision_scores[y_true==0], bins=30, alpha=0.6, label='æ­£å¸¸', color='green')
axes[1].hist(decision_scores[y_true==1], bins=30, alpha=0.6, label='ç•°å¸¸', color='red')
axes[1].axvline(0, color='black', linestyle='--', label='æ±ºå®šé–¾å€¤')
axes[1].set_xlabel('æ±ºå®šã‚¹ã‚³ã‚¢')
axes[1].set_ylabel('é »åº¦')
axes[1].set_title('æ±ºå®šã‚¹ã‚³ã‚¢ minuteså¸ƒ')
axes[1].legend()

plt.tight_layout()
plt.savefig('one_class_svm.png', dpi=300)
print("\nçµæœ: æ­£å¸¸ãƒ‡ãƒ¼ã‚¿ã®å¢ƒç•Œã‚’å³å¯†ã«ãƒ¢ãƒ‡ãƒ«åŒ–ã€æ–°è¦ç•°å¸¸ã«å¯¾å¿œå¯èƒ½")
</code></pre>
            </div>
        </section>

        <section>
            <h2>3.4 Deep Learningã«ã‚ˆã‚‹ç•°å¸¸æ¤œçŸ¥</h2>
            <p>
                Deep Learningã¯ã€è¤‡é›‘ãªæ™‚ç©ºé–“ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚„é«˜æ¬¡å…ƒãƒ‡ãƒ¼ã‚¿ã®ç•°å¸¸æ¤œçŸ¥ã«å¨åŠ›ã‚’ç™ºæ®ã—ã¾ã™ã€‚
                Autoencoderã¨LSTMã‚’ç”¨ã„ãŸ2ã¤ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’å®Ÿè£…ã—ã¾ã™ã€‚
            </p>

            <div class="example-box">
                <h4>Example 4: Autoencoderã«ã‚ˆã‚‹å†æ§‹æˆèª¤å·®ãƒ™ãƒ¼ã‚¹ç•°å¸¸æ¤œçŸ¥</h4>
                <p>æ­£å¸¸ãƒ‡ãƒ¼ã‚¿ã‚’åœ§ç¸®ãƒ»å¾©å…ƒã—ã€å†æ§‹æˆèª¤å·®ã‹ã‚‰ç•°å¸¸ã‚’æ¤œå‡ºã—ã¾ã™ã€‚</p>
                <pre><code># ===================================
# Example 4: Autoencoderç•°å¸¸æ¤œçŸ¥
# ===================================
import tensorflow as tf
from tensorflow import keras
from sklearn.model_selection import train_test_split

# æ­£å¸¸ãƒ‡ãƒ¼ã‚¿ã®ã¿ã§è¨“ç·´ï¼ˆæ•™å¸«ãªã—å­¦ç¿’ï¼‰
X_train = X[y_true == 0]
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X)

# Autoencoderãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰
input_dim = X_train_scaled.shape[1]
encoding_dim = 2  # åœ§ç¸®æ¬¡å…ƒ

autoencoder = keras.Sequential([
    keras.layers.Dense(8, activation='relu', input_shape=(input_dim,)),
    keras.layers.Dense(encoding_dim, activation='relu', name='encoder'),
    keras.layers.Dense(8, activation='relu'),
    keras.layers.Dense(input_dim, activation='linear', name='decoder')
])

autoencoder.compile(optimizer='adam', loss='mse')

# è¨“ç·´
history = autoencoder.fit(
    X_train_scaled, X_train_scaled,
    epochs=50,
    batch_size=32,
    validation_split=0.2,
    verbose=0
)

# å†æ§‹æˆèª¤å·®è¨ˆç®—
X_reconstructed = autoencoder.predict(X_test_scaled)
reconstruction_errors = np.mean(np.square(X_test_scaled - X_reconstructed), axis=1)

# ç•°å¸¸æ¤œçŸ¥é–¾å€¤ï¼ˆæ­£å¸¸ãƒ‡ãƒ¼ã‚¿ã®95ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«ï¼‰
threshold = np.percentile(reconstruction_errors[y_true==0], 95)
predictions_ae = reconstruction_errors > threshold

# è©•ä¾¡
print("\nAutoencoderçµæœ:")
print(f"é–¾å€¤: {threshold:.4f}")
print(classification_report(y_true, predictions_ae, target_names=['æ­£å¸¸', 'ç•°å¸¸']))

# å¯è¦–åŒ–
fig, axes = plt.subplots(2, 2, figsize=(14, 10))

# å­¦ç¿’æ›²ç·š
axes[0, 0].plot(history.history['loss'], label='è¨“ç·´æå¤±')
axes[0, 0].plot(history.history['val_loss'], label='æ¤œè¨¼æå¤±')
axes[0, 0].set_xlabel('ã‚¨ãƒãƒƒã‚¯')
axes[0, 0].set_ylabel('MSE')
axes[0, 0].set_title('Autoencoderå­¦ç¿’æ›²ç·š')
axes[0, 0].legend()
axes[0, 0].grid(True, alpha=0.3)

# å†æ§‹æˆèª¤å·® minuteså¸ƒ
axes[0, 1].hist(reconstruction_errors[y_true==0], bins=30, alpha=0.6,
                label='æ­£å¸¸', color='green')
axes[0, 1].hist(reconstruction_errors[y_true==1], bins=30, alpha=0.6,
                label='ç•°å¸¸', color='red')
axes[0, 1].axvline(threshold, color='black', linestyle='--', label='é–¾å€¤')
axes[0, 1].set_xlabel('å†æ§‹æˆèª¤å·®')
axes[0, 1].set_ylabel('é »åº¦')
axes[0, 1].set_title('å†æ§‹æˆèª¤å·® minuteså¸ƒ')
axes[0, 1].legend()

# æ½œåœ¨ç©ºé–“ï¼ˆ2æ¬¡å…ƒã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ï¼‰
encoder_model = keras.Model(autoencoder.input,
                            autoencoder.get_layer('encoder').output)
encoded = encoder_model.predict(X_test_scaled)

axes[1, 0].scatter(encoded[y_true==0, 0], encoded[y_true==0, 1],
                   c='green', s=20, alpha=0.6, label='æ­£å¸¸')
axes[1, 0].scatter(encoded[y_true==1, 0], encoded[y_true==1, 1],
                   c='red', s=50, alpha=0.8, marker='x', label='ç•°å¸¸')
axes[1, 0].set_xlabel('æ½œåœ¨æ¬¡å…ƒ1')
axes[1, 0].set_ylabel('æ½œåœ¨æ¬¡å…ƒ2')
axes[1, 0].set_title('æ½œåœ¨ç©ºé–“è¡¨ç¾')
axes[1, 0].legend()
axes[1, 0].grid(True, alpha=0.3)

# ROCæ›²ç·š
from sklearn.metrics import roc_curve, auc
fpr, tpr, _ = roc_curve(y_true, reconstruction_errors)
roc_auc = auc(fpr, tpr)

axes[1, 1].plot(fpr, tpr, label=f'ROC (AUC = {roc_auc:.2f})')
axes[1, 1].plot([0, 1], [0, 1], 'k--', label='ãƒ©ãƒ³ãƒ€ãƒ ')
axes[1, 1].set_xlabel('å½é™½æ€§ç‡')
axes[1, 1].set_ylabel('çœŸé™½æ€§ç‡')
axes[1, 1].set_title('ROCæ›²ç·š')
axes[1, 1].legend()
axes[1, 1].grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('autoencoder_anomaly.png', dpi=300)
print(f"\nçµæœ: AUC={roc_auc:.3f}ã€é«˜æ¬¡å…ƒãƒ‡ãƒ¼ã‚¿ã®éç·šå½¢ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å­¦ç¿’")
</code></pre>
            </div>

            <div class="example-box">
                <h4>Example 5: LSTMã«ã‚ˆã‚‹æ™‚ç³»åˆ—ç•°å¸¸æ¤œçŸ¥</h4>
                <p>æ™‚ç³»åˆ—ã® hoursçš„ä¾å­˜æ€§ã‚’å­¦ç¿’ã—ã€Predictionèª¤å·®ã‹ã‚‰ç•°å¸¸ã‚’æ¤œå‡ºã—ã¾ã™ã€‚</p>
                <pre><code># ===================================
# Example 5: LSTMæ™‚ç³»åˆ—ç•°å¸¸æ¤œçŸ¥
# ===================================

# æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆï¼ˆå­£ç¯€æ€§+ãƒˆãƒ¬ãƒ³ãƒ‰+ç•°å¸¸ï¼‰
np.random.seed(42)
n_timesteps = 1000
t = np.arange(n_timesteps)

# æ­£å¸¸ãƒ‘ã‚¿ãƒ¼ãƒ³
normal_series = 100 + 0.01*t + 10*np.sin(2*np.pi*t/50) + np.random.normal(0, 1, n_timesteps)

# ç•°å¸¸ã‚’æ³¨å…¥
anomaly_ranges = [(200, 220), (500, 530), (800, 815)]
for start, end in anomaly_ranges:
    normal_series[start:end] += np.random.uniform(15, 25, end-start)

# ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿ä½œæˆ
def create_sequences(data, seq_length=50):
    X, y = [], []
    for i in range(len(data) - seq_length):
        X.append(data[i:i+seq_length])
        y.append(data[i+seq_length])
    return np.array(X), np.array(y)

seq_length = 50
X_seq, y_seq = create_sequences(normal_series, seq_length)
X_seq = X_seq.reshape((X_seq.shape[0], X_seq.shape[1], 1))

# è¨“ç·´/ãƒ†ã‚¹ãƒˆ minuteså‰²ï¼ˆç•°å¸¸ã‚’å«ã¾ãªã„éƒ¨ minutesã§è¨“ç·´ï¼‰
split_idx = 150 - seq_length
X_train_lstm = X_seq[:split_idx]
y_train_lstm = y_seq[:split_idx]
X_test_lstm = X_seq
y_test_lstm = y_seq

# LSTMãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰
lstm_model = keras.Sequential([
    keras.layers.LSTM(32, activation='relu', input_shape=(seq_length, 1)),
    keras.layers.Dense(16, activation='relu'),
    keras.layers.Dense(1)
])

lstm_model.compile(optimizer='adam', loss='mse')

# è¨“ç·´
history_lstm = lstm_model.fit(
    X_train_lstm, y_train_lstm,
    epochs=30,
    batch_size=32,
    validation_split=0.2,
    verbose=0
)

# Predictionã¨èª¤å·®è¨ˆç®—
predictions_lstm = lstm_model.predict(X_test_lstm).flatten()
prediction_errors = np.abs(y_test_lstm - predictions_lstm)

# ç•°å¸¸é–¾å€¤ï¼ˆè¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®95ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«ï¼‰
train_errors = prediction_errors[:split_idx]
threshold_lstm = np.percentile(train_errors, 95)
anomalies_lstm = prediction_errors > threshold_lstm

# å¯è¦–åŒ–
fig, axes = plt.subplots(3, 1, figsize=(14, 10))

# å…ƒãƒ‡ãƒ¼ã‚¿
axes[0].plot(normal_series, 'b-', alpha=0.7, label='å®Ÿæ¸¬å€¤')
for start, end in anomaly_ranges:
    axes[0].axvspan(start, end, color='red', alpha=0.2)
axes[0].set_ylabel('Processå€¤')
axes[0].set_title('æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ï¼ˆç•°å¸¸æœŸé–“ã‚’èµ¤ã§è¡¨ç¤ºï¼‰')
axes[0].legend()
axes[0].grid(True, alpha=0.3)

# Prediction vs å®Ÿæ¸¬
axes[1].plot(y_test_lstm, 'b-', alpha=0.5, label='å®Ÿæ¸¬å€¤')
axes[1].plot(predictions_lstm, 'g--', alpha=0.7, label='Predictionå€¤')
axes[1].set_ylabel('Processå€¤')
axes[1].set_title('LSTMPredictionçµæœ')
axes[1].legend()
axes[1].grid(True, alpha=0.3)

# Predictionèª¤å·®ã¨ç•°å¸¸æ¤œçŸ¥
axes[2].plot(prediction_errors, 'k-', alpha=0.6, label='Predictionèª¤å·®')
axes[2].axhline(threshold_lstm, color='red', linestyle='--', label=f'é–¾å€¤={threshold_lstm:.2f}')
axes[2].fill_between(range(len(anomalies_lstm)), 0, prediction_errors,
                     where=anomalies_lstm, color='red', alpha=0.3, label='æ¤œå‡ºç•°å¸¸')
axes[2].set_xlabel('æ™‚åˆ»')
axes[2].set_ylabel('Predictionèª¤å·®')
axes[2].set_title('LSTMç•°å¸¸æ¤œçŸ¥çµæœ')
axes[2].legend()
axes[2].grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('lstm_anomaly.png', dpi=300)
print("\nçµæœ: æ™‚ç³»åˆ—ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å­¦ç¿’ã€ç•°å¸¸æœŸé–“ã‚’é«˜ç²¾åº¦ã§æ¤œå‡º")
</code></pre>
            </div>
        </section>

        <section>
            <h2>3.5 æ•…éšœ minutesé¡ã¨ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æ‰‹æ³•</h2>
            <p>
                ç•°å¸¸ã‚’æ¤œå‡ºã™ã‚‹ã ã‘ã§ãªãã€æ•…éšœã®ç¨®é¡ã‚’ minutesé¡ã™ã‚‹ã“ã¨ã§ã€é©åˆ‡ãªå¯¾å‡¦æ³•ã‚’è¿…é€Ÿã«æ±ºå®šã§ãã¾ã™ã€‚
                Random Forestã¨ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æŠ•ç¥¨ã«ã‚ˆã‚‹é ‘å¥ãª minutesé¡ã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ã—ã¾ã™ã€‚
            </p>

            <div class="example-box">
                <h4>Example 6: Random Forestã«ã‚ˆã‚‹æ•…éšœ minutesé¡</h4>
                <p>è¤‡æ•°ã®æ•…éšœã‚¿ã‚¤ãƒ—ã‚’Machine Learningã§ minutesé¡ã—ã¾ã™ã€‚</p>
                <pre><code># ===================================
# Example 6: æ•…éšœ minutesé¡ï¼ˆRandom Forestï¼‰
# ===================================
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns

# æ•…éšœãƒ‡ãƒ¼ã‚¿ç”Ÿæˆï¼ˆ4ã‚¯ãƒ©ã‚¹ï¼šæ­£å¸¸ã€ã‚»ãƒ³ã‚µãƒ¼æ•…éšœã€Processç•°å¸¸ã€Controlç³»ç•°å¸¸ï¼‰
np.random.seed(42)
n_per_class = 200

# ã‚¯ãƒ©ã‚¹0: æ­£å¸¸
normal = np.random.multivariate_normal([350, 5, 100], [[4, 0.1, 5], [0.1, 0.04, 0.5], [5, 0.5, 25]], n_per_class)

# ã‚¯ãƒ©ã‚¹1: ã‚»ãƒ³ã‚µãƒ¼æ•…éšœï¼ˆãƒã‚¤ã‚ºå¢—å¤§ï¼‰
sensor_fault = np.random.multivariate_normal([350, 5, 100], [[16, 0.1, 5], [0.1, 0.16, 0.5], [5, 0.5, 100]], n_per_class)

# ã‚¯ãƒ©ã‚¹2: Processç•°å¸¸ï¼ˆæ¸©åº¦ä¸Šæ˜‡ï¼‰
process_fault = np.random.multivariate_normal([365, 5.5, 120], [[4, 0.2, 8], [0.2, 0.04, 0.6], [8, 0.6, 25]], n_per_class)

# ã‚¯ãƒ©ã‚¹3: Controlç³»ç•°å¸¸ï¼ˆå¤‰å‹•ãƒ‘ã‚¿ãƒ¼ãƒ³å¤‰åŒ–ï¼‰
control_fault = np.random.multivariate_normal([350, 4.5, 90], [[9, -0.3, -10], [-0.3, 0.09, 2], [-10, 2, 64]], n_per_class)

# ãƒ‡ãƒ¼ã‚¿çµ±åˆ
X_fault = np.vstack([normal, sensor_fault, process_fault, control_fault])
y_fault = np.array([0]*n_per_class + [1]*n_per_class + [2]*n_per_class + [3]*n_per_class)

# è¨“ç·´/ãƒ†ã‚¹ãƒˆ minuteså‰²
X_train_fault, X_test_fault, y_train_fault, y_test_fault = train_test_split(
    X_fault, y_fault, test_size=0.3, random_state=42, stratify=y_fault
)

# Random Forestè¨“ç·´
rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)
rf_classifier.fit(X_train_fault, y_train_fault)

# Prediction
y_pred_rf = rf_classifier.predict(X_test_fault)
y_pred_proba = rf_classifier.predict_proba(X_test_fault)

# è©•ä¾¡
fault_names = ['æ­£å¸¸', 'ã‚»ãƒ³ã‚µãƒ¼æ•…éšœ', 'Processç•°å¸¸', 'Controlç³»ç•°å¸¸']
print("\nRandom Forestæ•…éšœ minutesé¡çµæœ:")
print(classification_report(y_test_fault, y_pred_rf, target_names=fault_names))

# æ··åŒè¡Œåˆ—
cm = confusion_matrix(y_test_fault, y_pred_rf)
fig, axes = plt.subplots(1, 2, figsize=(14, 5))

sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=fault_names,
            yticklabels=fault_names, ax=axes[0])
axes[0].set_xlabel('Prediction')
axes[0].set_ylabel('çœŸå€¤')
axes[0].set_title('æ··åŒè¡Œåˆ—')

# ç‰¹å¾´é‡è¦åº¦
importances = rf_classifier.feature_importances_
feature_names = ['æ¸©åº¦', 'åœ§åŠ›', 'æµé‡']
axes[1].barh(feature_names, importances, color='teal')
axes[1].set_xlabel('é‡è¦åº¦')
axes[1].set_title('ç‰¹å¾´é‡è¦åº¦')

plt.tight_layout()
plt.savefig('fault_classification.png', dpi=300)
print("\nçµæœ: è¤‡æ•°ã®æ•…éšœã‚¿ã‚¤ãƒ—ã‚’é«˜ç²¾åº¦ã§ minutesé¡ã€ç‰¹å¾´é‡è¦åº¦ã‹ã‚‰è¨ºæ–­æ ¹æ‹ ã‚’æç¤º")
</code></pre>
            </div>

            <div class="example-box">
                <h4>Example 7: ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ç•°å¸¸æ¤œçŸ¥ï¼ˆæŠ•ç¥¨æ–¹å¼ï¼‰</h4>
                <p>è¤‡æ•°ã®ç•°å¸¸æ¤œçŸ¥æ‰‹æ³•ã‚’çµ„ã¿åˆã‚ã›ã€é ‘å¥æ€§ã‚’å‘ä¸Šã•ã›ã¾ã™ã€‚</p>
                <pre><code># ===================================
# Example 7: ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ç•°å¸¸æ¤œçŸ¥
# ===================================

# è¤‡æ•°ã®æ¤œçŸ¥å™¨ã‚’è¨“ç·´ï¼ˆå‰è¿°ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ï¼‰
# 1. Isolation Forest
iso_pred = (iso_forest.predict(X) == -1).astype(int)

# 2. One-Class SVM
svm_pred = (oc_svm.predict(X_scaled) == -1).astype(int)

# 3. Autoencoderï¼ˆå†æ§‹æˆèª¤å·®ï¼‰
ae_pred = (reconstruction_errors > threshold).astype(int)

# ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æŠ•ç¥¨
ensemble_votes = np.column_stack([iso_pred, svm_pred, ae_pred])
ensemble_pred = (ensemble_votes.sum(axis=1) >= 2).astype(int)  # å¤šæ•°æ±º

# è©•ä¾¡
from sklearn.metrics import accuracy_score, f1_score

methods = {
    'Isolation Forest': iso_pred,
    'One-Class SVM': svm_pred,
    'Autoencoder': ae_pred,
    'ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ï¼ˆæŠ•ç¥¨ï¼‰': ensemble_pred
}

print("\nã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ç•°å¸¸æ¤œçŸ¥çµæœ:")
print(f"{'æ‰‹æ³•':<25} {'Accuracy':<10} {'F1-score':<10}")
print("-" * 45)
for name, pred in methods.items():
    acc = accuracy_score(y_true, pred)
    f1 = f1_score(y_true, pred)
    print(f"{name:<25} {acc:.4f}     {f1:.4f}")

# åˆ¥æ‰‹æ³•ã®ä¸€è‡´åº¦ minutesæ
fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# æŠ•ç¥¨æ•°ã® minuteså¸ƒ
vote_counts = ensemble_votes.sum(axis=1)
axes[0].hist([vote_counts[y_true==0], vote_counts[y_true==1]],
             bins=4, label=['æ­£å¸¸', 'ç•°å¸¸'], color=['green', 'red'], alpha=0.6)
axes[0].set_xlabel('æ¤œçŸ¥å™¨ã®æŠ•ç¥¨æ•°')
axes[0].set_ylabel('é »åº¦')
axes[0].set_title('ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æŠ•ç¥¨ minuteså¸ƒ')
axes[0].legend()
axes[0].grid(True, alpha=0.3)

# æ‰‹æ³•é–“ã®ç›¸é–¢
method_matrix = np.column_stack([iso_pred, svm_pred, ae_pred, ensemble_pred])
correlation = np.corrcoef(method_matrix.T)
sns.heatmap(correlation, annot=True, fmt='.2f', cmap='coolwarm',
            xticklabels=['Iso Forest', 'SVM', 'AE', 'Ensemble'],
            yticklabels=['Iso Forest', 'SVM', 'AE', 'Ensemble'],
            ax=axes[1], vmin=-1, vmax=1)
axes[1].set_title('æ¤œçŸ¥æ‰‹æ³•é–“ã®ç›¸é–¢')

plt.tight_layout()
plt.savefig('ensemble_anomaly.png', dpi=300)
print("\nçµæœ: ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã«ã‚ˆã‚Šã€åˆ¥æ‰‹æ³•ã®å¼±ç‚¹ã‚’è£œå®Œã—ç²¾åº¦å‘ä¸Š")
</code></pre>
            </div>
        </section>

        <section>
            <h2>3.6 æ ¹æœ¬åŸå›  minutesæ</h2>
            <p>
                ç•°å¸¸ãŒæ¤œå‡ºã•ã‚ŒãŸéš›ã€ãã®åŸå› ã‚’ç‰¹å®šã™ã‚‹ã“ã¨ãŒé‡è¦ã§ã™ã€‚
                Grangerå› æœæ€§æ¤œå®šã«ã‚ˆã‚Šã€æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å¤‰æ•°é–“ã®å› æœé–¢ä¿‚ã‚’æ¨å®šã—ã€æ ¹æœ¬åŸå› ã‚’çµã‚Šè¾¼ã¿ã¾ã™ã€‚
            </p>

            <div class="example-box">
                <h4>Example 8: Grangerå› æœæ€§æ¤œå®šã«ã‚ˆã‚‹æ ¹æœ¬åŸå›  minutesæ</h4>
                <p>è¤‡æ•°ã®Processå¤‰æ•°é–“ã®å› æœé–¢ä¿‚ã‚’ minutesæã—ã€æ•…éšœã®åŸå› ã‚’ç‰¹å®šã—ã¾ã™ã€‚</p>
                <pre><code># ===================================
# Example 8: Grangerå› æœæ€§ minutesæ
# ===================================
from statsmodels.tsa.stattools import grangercausalitytests

# å› æœé–¢ä¿‚ã‚’æŒã¤Processãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
np.random.seed(42)
n = 500

# åŸå› å¤‰æ•°ï¼ˆè§¦åª’æ¸©åº¦ï¼‰
catalyst_temp = np.zeros(n)
catalyst_temp[0] = 300
for i in range(1, n):
    catalyst_temp[i] = 0.95 * catalyst_temp[i-1] + 300 * 0.05 + np.random.normal(0, 1)

# è§¦åª’æ¸©åº¦ãŒåå¿œé€Ÿåº¦ã«å½±éŸ¿ï¼ˆé…å»¶ã‚ã‚Šï¼‰
reaction_rate = np.zeros(n)
for i in range(3, n):
    reaction_rate[i] = 50 + 0.3 * catalyst_temp[i-2] + np.random.normal(0, 2)

# åå¿œé€Ÿåº¦ãŒè£½å“åç‡ã«å½±éŸ¿
product_yield = np.zeros(n)
for i in range(2, n):
    product_yield[i] = 70 + 0.5 * reaction_rate[i-1] + np.random.normal(0, 1.5)

# ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ä½œæˆ
df_causal = pd.DataFrame({
    'catalyst_temp': catalyst_temp,
    'reaction_rate': reaction_rate,
    'product_yield': product_yield
})

# Grangerå› æœæ€§æ¤œå®šé–¢æ•°
def granger_causality_matrix(data, variables, max_lag=5):
    """å¤‰æ•°é–“ã®Grangerå› æœæ€§ã‚’ãƒ†ã‚¹ãƒˆã—ã€è¡Œåˆ—ã§è¡¨ç¤º"""
    df_results = pd.DataFrame(np.zeros((len(variables), len(variables))),
                              columns=variables, index=variables)

    for c in variables:
        for r in variables:
            if c != r:
                test_result = grangercausalitytests(
                    data[[r, c]], max_lag, verbose=False
                )
                # å„ãƒ©ã‚°ã§ã®æœ€å°på€¤ã‚’ä½¿ç”¨
                p_values = [test_result[lag][0]['ssr_ftest'][1] for lag in range(1, max_lag+1)]
                min_p = np.min(p_values)
                df_results.loc[r, c] = min_p

    return df_results

# å› æœæ€§æ¤œå®šå®Ÿæ–½
variables = ['catalyst_temp', 'reaction_rate', 'product_yield']
causality_matrix = granger_causality_matrix(df_causal[50:], variables, max_lag=5)

print("\nGrangerå› æœæ€§æ¤œå®šçµæœï¼ˆpå€¤ï¼‰:")
print("åˆ— â†’ è¡Œã¸ã®å› æœé–¢ä¿‚ã‚’ç¤ºã™ï¼ˆp < 0.05ã§æœ‰æ„ï¼‰")
print(causality_matrix.round(4))

# æœ‰æ„ãªå› æœé–¢ä¿‚ã®æŠ½å‡º
print("\næœ‰æ„ãªå› æœé–¢ä¿‚ï¼ˆp < 0.05ï¼‰:")
for cause in variables:
    for effect in variables:
        p_value = causality_matrix.loc[effect, cause]
        if p_value < 0.05 and cause != effect:
            print(f"  {cause} â†’ {effect} (p={p_value:.4f})")

# å¯è¦–åŒ–
fig, axes = plt.subplots(2, 2, figsize=(14, 10))

# æ™‚ç³»åˆ—ãƒ—ãƒ­ãƒƒãƒˆ
axes[0, 0].plot(df_causal['catalyst_temp'], label='è§¦åª’æ¸©åº¦')
axes[0, 0].set_ylabel('æ¸©åº¦ (Â°C)')
axes[0, 0].set_title('è§¦åª’æ¸©åº¦ï¼ˆåŸå› å¤‰æ•°ï¼‰')
axes[0, 0].legend()
axes[0, 0].grid(True, alpha=0.3)

axes[0, 1].plot(df_causal['reaction_rate'], label='åå¿œé€Ÿåº¦', color='orange')
axes[0, 1].set_ylabel('é€Ÿåº¦ (mol/s)')
axes[0, 1].set_title('åå¿œé€Ÿåº¦ï¼ˆä¸­é–“å¤‰æ•°ï¼‰')
axes[0, 1].legend()
axes[0, 1].grid(True, alpha=0.3)

axes[1, 0].plot(df_causal['product_yield'], label='è£½å“åç‡', color='green')
axes[1, 0].set_xlabel('æ™‚åˆ»')
axes[1, 0].set_ylabel('åç‡ (%)')
axes[1, 0].set_title('è£½å“åç‡ï¼ˆçµæœå¤‰æ•°ï¼‰')
axes[1, 0].legend()
axes[1, 0].grid(True, alpha=0.3)

# å› æœæ€§è¡Œåˆ—ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—
significance_matrix = (causality_matrix < 0.05).astype(int)
sns.heatmap(significance_matrix, annot=causality_matrix.round(3), fmt='',
            cmap='RdYlGn_r', cbar_kws={'label': 'æœ‰æ„æ€§'},
            xticklabels=variables, yticklabels=variables,
            ax=axes[1, 1], vmin=0, vmax=1)
axes[1, 1].set_title('å› æœé–¢ä¿‚ãƒãƒƒãƒ—ï¼ˆç·‘=æœ‰æ„ï¼‰')
axes[1, 1].set_xlabel('åŸå›  â†’')
axes[1, 1].set_ylabel('â† çµæœ')

plt.tight_layout()
plt.savefig('granger_causality.png', dpi=300)

print("\nçµæœ: è§¦åª’æ¸©åº¦ â†’ åå¿œé€Ÿåº¦ â†’ è£½å“åç‡ã®å› æœãƒã‚§ãƒ¼ãƒ³ã‚’ç‰¹å®š")
print("æ•…éšœè¨ºæ–­: è£½å“åç‡ä½ä¸‹ã®æ ¹æœ¬åŸå› ã¯è§¦åª’æ¸©åº¦ç•°å¸¸ã®å¯èƒ½æ€§ãŒé«˜ã„")
</code></pre>
            </div>
        </section>

        <section>
            <h2>3.7 å®ŸProcessã¸ã®é©ç”¨æˆ¦ç•¥</h2>
            <div class="callout callout-success">
                <h4>ğŸ’¡ å®Ÿè£…ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹</h4>
                <ul style="margin-bottom: 0;">
                    <li><strong>æ®µéšçš„å°å…¥</strong>: çµ±è¨ˆæ‰‹æ³• â†’ Machine Learning â†’ Deep Learningã®é †ã§è©¦ã™</li>
                    <li><strong>é–¾å€¤èª¿æ•´</strong>: False Alarmã‚’æ¸›ã‚‰ã™ãŸã‚ã€é‹è»¢ãƒ‡ãƒ¼ã‚¿ã§é–¾å€¤ã‚’Optimization</li>
                    <li><strong>ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æ´»ç”¨</strong>: è¤‡æ•°æ‰‹æ³•ã®çµ„ã¿åˆã‚ã›ã§é ‘å¥æ€§ã‚’å‘ä¸Š</li>
                    <li><strong>å¯è¦–åŒ–é‡è¦–</strong>: ã‚ªãƒšãƒ¬ãƒ¼ã‚¿ãƒ¼ãŒåˆ¤æ–­ã§ãã‚‹ã‚ˆã†ã€æ¤œçŸ¥ç†ç”±ã‚’å¯è¦–åŒ–</li>
                    <li><strong>ç¶™ç¶šå­¦ç¿’</strong>: Processå¤‰æ›´ã«å¿œã˜ã¦ãƒ¢ãƒ‡ãƒ«ã‚’å®šæœŸçš„ã«å†è¨“ç·´</li>
                </ul>
            </div>

            <h3>æ‰‹æ³•é¸æŠã‚¬ã‚¤ãƒ‰</h3>
            <table>
                <tr>
                    <th style="width: 25%;">çŠ¶æ³</th>
                    <th style="width: 35%;">æ¨å¥¨æ‰‹æ³•</th>
                    <th style="width: 40%;">ç†ç”±</th>
                </tr>
                <tr>
                    <td>å˜å¤‰é‡ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ </td>
                    <td>Z-score / Modified Z-score</td>
                    <td>è¨ˆç®—ã‚³ã‚¹ãƒˆä½ã€è§£é‡ˆå®¹æ˜“</td>
                </tr>
                <tr>
                    <td>å¤šå¤‰é‡ã€éç·šå½¢</td>
                    <td>Isolation Forest</td>
                    <td>é«˜æ¬¡å…ƒã«å¼·ãã€è¨“ç·´é«˜é€Ÿ</td>
                </tr>
                <tr>
                    <td>æ–°è¦ç•°å¸¸ãƒ‘ã‚¿ãƒ¼ãƒ³</td>
                    <td>One-Class SVM</td>
                    <td>å¢ƒç•Œå­¦ç¿’ã«ã‚ˆã‚ŠæœªçŸ¥ç•°å¸¸ã‚’æ¤œçŸ¥</td>
                </tr>
                <tr>
                    <td>è¤‡é›‘ãªæ™‚ç©ºé–“ãƒ‘ã‚¿ãƒ¼ãƒ³</td>
                    <td>Autoencoder / LSTM</td>
                    <td>é«˜æ¬¡å…ƒã®æ½œåœ¨æ§‹é€ ã‚’å­¦ç¿’</td>
                </tr>
                <tr>
                    <td>æ•…éšœã‚¿ã‚¤ãƒ— minutesé¡</td>
                    <td>Random Forest</td>
                    <td> minutesé¡ç²¾åº¦é«˜ã€è§£é‡ˆå¯èƒ½</td>
                </tr>
                <tr>
                    <td>æ ¹æœ¬åŸå›  minutesæ</td>
                    <td>Grangerå› æœæ€§</td>
                    <td>å¤‰æ•°é–“ã®å› æœé–¢ä¿‚ã‚’æ¨å®š</td>
                </tr>
            </table>
        </section>

        <section>
            <h2>3.8 Summary</h2>
            <p>
                æœ¬ Chapterã§ã¯ã€çµ±è¨ˆæ‰‹æ³•ã‹ã‚‰Deep Learningã¾ã§8ã¤ã®ç•°å¸¸æ¤œçŸ¥ãƒ»æ•…éšœè¨ºæ–­æŠ€è¡“ã‚’å®Ÿè£…ã—ã¾ã—ãŸã€‚
                å„æ‰‹æ³•ã®ç‰¹æ€§ã‚’ç†è§£ã—ã€Processç‰¹æ€§ã‚„é‹ç”¨æ¡ä»¶ã«å¿œã˜ã¦é©åˆ‡ã«é¸æŠãƒ»çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã§ã€
                é«˜ç²¾åº¦ãªç•°å¸¸æ¤œçŸ¥ã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ã§ãã¾ã™ã€‚
            </p>

            <h3>ç¿’å¾—ã—ãŸã‚¹ã‚­ãƒ«</h3>
            <ul>
                <li>âœ… çµ±è¨ˆçš„æ‰‹æ³•ï¼ˆZ-score, Modified Z-scoreï¼‰ã«ã‚ˆã‚‹åŸºæœ¬çš„ãªç•°å¸¸æ¤œçŸ¥</li>
                <li>âœ… Isolation Forestã«ã‚ˆã‚‹é«˜æ¬¡å…ƒãƒ‡ãƒ¼ã‚¿ã®åŠ¹ç‡çš„ãªç•°å¸¸æ¤œçŸ¥</li>
                <li>âœ… One-Class SVMã«ã‚ˆã‚‹æ–°è¦æ€§æ¤œçŸ¥ã¨æ±ºå®šå¢ƒç•Œã®å¯è¦–åŒ–</li>
                <li>âœ… Autoencoderã«ã‚ˆã‚‹å†æ§‹æˆèª¤å·®ãƒ™ãƒ¼ã‚¹ã®ç•°å¸¸æ¤œçŸ¥</li>
                <li>âœ… LSTMã«ã‚ˆã‚‹æ™‚ç³»åˆ—ãƒ‘ã‚¿ãƒ¼ãƒ³å­¦ç¿’ã¨Predictionèª¤å·®ãƒ™ãƒ¼ã‚¹æ¤œçŸ¥</li>
                <li>âœ… Random Forestã«ã‚ˆã‚‹æ•…éšœã‚¿ã‚¤ãƒ—ã®å¤šã‚¯ãƒ©ã‚¹ minutesé¡</li>
                <li>âœ… ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æŠ•ç¥¨ã«ã‚ˆã‚‹é ‘å¥ãªç•°å¸¸æ¤œçŸ¥ã‚·ã‚¹ãƒ†ãƒ </li>
                <li>âœ… Grangerå› æœæ€§æ¤œå®šã«ã‚ˆã‚‹æ ¹æœ¬åŸå›  minutesæ</li>
            </ul>

            <div class="callout callout-info">
                <h4>ğŸ“š Next Steps</h4>
                <p>
                    Chapter 4ã§ã¯ã€ProcessOptimizationã¨ã‚½ãƒ•ãƒˆã‚»ãƒ³ã‚µãƒ¼æŠ€è¡“ã‚’å­¦ç¿’ã—ã¾ã™ã€‚
                    Machine Learningãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ãŸå“è³ªPredictionã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ Optimizationã€ä»®æƒ³ã‚»ãƒ³ã‚µãƒ¼ã®æ§‹ç¯‰ãªã©ã‚’å®Ÿè£…ã—ã¾ã™ã€‚
                </p>
            </div>
        </section>

        <section>
            <h2>3.9 Exercises</h2>

            <h4>æ¼”ç¿’1ï¼ˆåŸºç¤ï¼‰: çµ±è¨ˆçš„ç•°å¸¸æ¤œçŸ¥ã®æ¯”è¼ƒ</h4>
            <p>
                Example 1ã®ã‚³ãƒ¼ãƒ‰ã‚’ä¿®æ­£ã—ã€æ­£è¦ minuteså¸ƒã«å¾“ã‚ãªã„ãƒ‡ãƒ¼ã‚¿ï¼ˆå¯¾æ•°æ­£è¦ minuteså¸ƒãªã©ï¼‰ã«å¯¾ã™ã‚‹
                Z-scoreã¨Modified Z-scoreã®æ€§èƒ½ã‚’æ¯”è¼ƒã—ã¦ãã ã•ã„ã€‚ã©ã¡ã‚‰ãŒé ‘å¥ã‹èª¬æ˜ã—ã¦ãã ã•ã„ã€‚
            </p>

            <h4>æ¼”ç¿’2ï¼ˆIntermediateï¼‰: Autoencoderã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£Optimization</h4>
            <p>
                Example 4ã®Autoencoderã«ã¤ã„ã¦ã€ä»¥ä¸‹ã®å®Ÿé¨“ã‚’è¡Œã„ã€æœ€é©ãªã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’æ±ºå®šã—ã¦ãã ã•ã„ï¼š
            </p>
            <ul>
                <li>ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ¬¡å…ƒã‚’1, 2, 4, 8ã§æ¯”è¼ƒ</li>
                <li>éš ã‚Œå±¤ã®å±¤æ•°ã‚’1, 2, 3ã§æ¯”è¼ƒ</li>
                <li>æ´»æ€§åŒ–é–¢æ•°ï¼ˆReLU, tanh, ELUï¼‰ã‚’æ¯”è¼ƒ</li>
            </ul>

            <h4>æ¼”ç¿’3ï¼ˆAdvancedï¼‰: ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ç•°å¸¸æ¤œçŸ¥ã‚·ã‚¹ãƒ†ãƒ </h4>
            <p>
                ä»¥ä¸‹ã®è¦ä»¶ã‚’æº€ãŸã™å®Ÿç”¨çš„ãªç•°å¸¸æ¤œçŸ¥ã‚·ã‚¹ãƒ†ãƒ ã‚’è¨­è¨ˆãƒ»å®Ÿè£…ã—ã¦ãã ã•ã„ï¼š
            </p>
            <ol>
                <li>çµ±è¨ˆæ‰‹æ³•ã§1æ¬¡ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆè¨ˆç®—ã‚³ã‚¹ãƒˆå‰Šæ¸›ï¼‰</li>
                <li>ç–‘ã‚ã—ã„ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦Machine Learningã§ç²¾å¯†æ¤œæŸ»</li>
                <li>ç•°å¸¸æ¤œå‡ºæ™‚ã«Grangerå› æœæ€§ã§åŸå› ã‚’æ¨å®š</li>
                <li>False Alarmç‡ã‚’5%ä»¥ä¸‹ã«æŠ‘ãˆã‚‹é–¾å€¤è¨­å®š</li>
            </ol>

            <div class="callout callout-tip">
                <h4>ğŸ’¡ ãƒ’ãƒ³ãƒˆ</h4>
                <p>
                    æ¼”ç¿’3ã§ã¯ã€ã‚«ã‚¹ã‚±ãƒ¼ãƒ‰å‹ã®æ¤œçŸ¥ã‚·ã‚¹ãƒ†ãƒ ãŒåŠ¹æœçš„ã§ã™ã€‚çµ±è¨ˆæ‰‹æ³•ã§é«˜é€Ÿã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°å¾Œã€
                    ç–‘ã‚ã—ã„ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’Deep Learningã§æ¤œè¨¼ã™ã‚‹ã“ã¨ã§ã€è¨ˆç®—ã‚³ã‚¹ãƒˆã¨ç²¾åº¦ã®ãƒãƒ©ãƒ³ã‚¹ãŒå–ã‚Œã¾ã™ã€‚
                    ROCæ›²ç·šã‚’æã„ã¦æœ€é©ãªé–¾å€¤ã‚’æ±ºå®šã—ã¾ã—ã‚‡ã†ã€‚
                </p>
            </div>
        </section>

        <div class="nav-buttons">
            <a href="#" class="btn">â† Chapter 2ã¸æˆ»ã‚‹</a>
            <a href="#" class="btn" style="background: #ccc; cursor: not-allowed;">Chapter 4ã¸é€²ã‚€ â†’</a>
        </div>

        <footer>
            <p>&copy; 2025 Yusuke Hashimoto, Tohoku University. All rights reserved.</p>
            <p style="margin-top: 0.5rem;">
                <a href="./index.html">Series Contents</a> |
                <a href="../index.html">PIãƒŠãƒ¬ãƒƒã‚¸ãƒãƒ–TOP</a>
            </p>
        </footer>
    </div>
</body>
</html>
