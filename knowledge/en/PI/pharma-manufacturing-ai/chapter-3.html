<!DOCTYPE html>

<html lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>Chapter 3: PAT and Real-Time Quality Control | Process Informatics Dojo</title>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script async="" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<link href="../../assets/css/knowledge-base.css" rel="stylesheet"/>
</head>
<body>
<nav class="breadcrumb">
<div class="breadcrumb-content">
<a href="../index.html">AI Terakoya Top</a><span class="breadcrumb-separator">‚Ä∫</span><a href="../../PI/index.html">Process Informatics</a><span class="breadcrumb-separator">‚Ä∫</span><a href="../../PI/pharma-manufacturing-ai/index.html">Pharma Manufacturing AI</a><span class="breadcrumb-separator">‚Ä∫</span><span class="breadcrumb-current">Chapter 3</span>
</div>
</nav><div class="locale-switcher">
<span class="current-locale">üåê EN</span>
<span class="locale-separator">|</span>
<a href="../../../jp/PI/pharma-manufacturing-ai/chapter-3.html" class="locale-link">üáØüáµ JP</a>
<span class="locale-separator">|</span>

<span class="locale-meta">Last sync: 2025-11-16</span>
</div>

<header>
<h1>Chapter 3: PAT and Real-Time Quality Control</h1>
<p class="subtitle">Process Analytical Technology and Real-Time Quality Control</p>
</header>
<div class="container">
<a class="back-link" href="index.html">‚Üê Back to Series Index</a>
<div class="content-box">
<h2>üìñ Chapter Overview</h2>
<p>
                Process Analytical Technology (PAT) is an FDA-recommended real-time quality control approach.
                This chapter covers PAT tools such as NIR/Raman spectroscopy, Multivariate Statistical Process Control (MSPC),
                and Real-Time Release Testing (RTRT) implementation methods to achieve Quality by Design.
            </p>
<h3>üéØ Learning Objectives</h3>
<ul>
<li>Basic concepts of PAT (Process Analytical Technology) and FDA guidance</li>
<li>Preprocessing and feature extraction of NIR/Raman spectroscopic data</li>
<li>Quantitative analysis using PLS (Partial Least Squares) regression</li>
<li>Implementation of Multivariate Statistical Process Control (MSPC)</li>
<li>Construction of Hotelling's T¬≤ and SPE control charts</li>
<li>Design of Real-Time Release Testing (RTRT)</li>
<li>PAT system validation strategies</li>
</ul>
</div>
<div class="content-box">
<h2>üî¨ 3.1 Fundamentals of PAT (Process Analytical Technology)</h2>
<h3>FDA PAT Initiative</h3>
<p>
                The FDA (U.S. Food and Drug Administration) issued PAT Guidance in 2004, promoting
                a paradigm shift: "Building quality into the process rather than testing for quality."
            </p>
<div class="gmp-note">
<strong>üè≠ Four PAT Tools</strong><br/>
                1. <strong>Multivariate Tools</strong>: PCA, PLS, Neural Networks<br/>
                2. <strong>Process Analyzers</strong>: NIR, Raman, UV-Vis Spectrometers<br/>
                3. <strong>Process Control Tools</strong>: Feedback Control, Adaptive Control<br/>
                4. <strong>Continuous Improvement &amp; Knowledge Management</strong>: Databases, Statistical Analysis
            </div>
<h3>Principles of NIR/Raman Spectroscopy</h3>
<ul>
<li><strong>NIR (Near-Infrared Spectroscopy)</strong>: Non-destructive, solid/liquid measurement capability, effective for moisture/content determination</li>
<li><strong>Raman Spectroscopy</strong>: Molecular vibration spectra, minimal water interference, effective for crystalline polymorph identification</li>
</ul>
<h3>üíª Code Example 3.1: NIR Spectral Data Preprocessing and PLS Regression</h3>
<pre><code>import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.cross_decomposition import PLSRegression
from sklearn.model_selection import cross_val_score, KFold
from sklearn.preprocessing import StandardScaler
from scipy.signal import savgol_filter
import warnings
warnings.filterwarnings('ignore')

plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

class NIRAnalyzer:
    """NIR spectroscopy data analysis class"""

    def __init__(self, wavelengths):
        """
        Args:
            wavelengths: Wavelength array (nm)
        """
        self.wavelengths = wavelengths
        self.scaler = StandardScaler()
        self.pls_model = None

    def generate_nir_spectra(self, n_samples=100):
        """Generate NIR spectral data (simulated)"""
        np.random.seed(42)

        # API content (85-115% range)
        api_content = np.random.uniform(85, 115, n_samples)

        spectra = []
        for content in api_content:
            # Baseline spectrum
            baseline = 0.5 + 0.001 * self.wavelengths

            # API absorption peaks (around 1450nm, 1900nm)
            peak1 = 0.3 * (content / 100) * np.exp(-((self.wavelengths - 1450) ** 2) / (50 ** 2))
            peak2 = 0.2 * (content / 100) * np.exp(-((self.wavelengths - 1900) ** 2) / (80 ** 2))

            # Excipient effects
            excipient = 0.1 * np.exp(-((self.wavelengths - 1700) ** 2) / (100 ** 2))

            # Noise
            noise = np.random.normal(0, 0.01, len(self.wavelengths))

            spectrum = baseline + peak1 + peak2 + excipient + noise
            spectra.append(spectrum)

        return np.array(spectra), api_content

    def preprocess_spectra(self, spectra, method='snv'):
        """
        Spectral preprocessing

        Args:
            spectra: Spectral data (n_samples √ó n_wavelengths)
            method: Preprocessing method ('snv', 'msc', 'derivative')

        Returns:
            Preprocessed spectra
        """
        if method == 'snv':
            # Standard Normal Variate (SNV)
            mean = np.mean(spectra, axis=1, keepdims=True)
            std = np.std(spectra, axis=1, keepdims=True)
            processed = (spectra - mean) / std

        elif method == 'msc':
            # Multiplicative Scatter Correction (MSC)
            ref_spectrum = np.mean(spectra, axis=0)
            processed = np.zeros_like(spectra)

            for i in range(spectra.shape[0]):
                # Remove scaling and offset using linear regression
                fit = np.polyfit(ref_spectrum, spectra[i], 1)
                processed[i] = (spectra[i] - fit[1]) / fit[0]

        elif method == 'derivative':
            # Savitzky-Golay 1st derivative
            processed = np.array([savgol_filter(s, window_length=11, polyorder=2, deriv=1)
                                  for s in spectra])

        else:
            processed = spectra

        return processed

    def build_pls_model(self, X_train, y_train, n_components=5):
        """
        Build PLS model

        Args:
            X_train: Training spectral data
            y_train: Training labels (API content)
            n_components: Number of PLS components
        """
        # Data standardization
        X_scaled = self.scaler.fit_transform(X_train)

        # PLS model
        self.pls_model = PLSRegression(n_components=n_components)
        self.pls_model.fit(X_scaled, y_train)

        # Cross-validation
        kfold = KFold(n_splits=5, shuffle=True, random_state=42)
        cv_scores = cross_val_score(self.pls_model, X_scaled, y_train,
                                     cv=kfold, scoring='r2')

        return cv_scores

    def predict(self, X_test):
        """Prediction"""
        X_scaled = self.scaler.transform(X_test)
        return self.pls_model.predict(X_scaled)

    def plot_nir_analysis(self, spectra, api_content, X_test, y_test, y_pred):
        """Visualize NIR analysis results"""
        fig, axes = plt.subplots(2, 2, figsize=(14, 10))

        # NIR spectra (samples)
        for i in range(0, len(spectra), 20):
            axes[0, 0].plot(self.wavelengths, spectra[i], alpha=0.6,
                            label=f'{api_content[i]:.1f}%' if i &lt; 80 else None)

        axes[0, 0].set_xlabel('Wavelength (nm)')
        axes[0, 0].set_ylabel('Absorbance')
        axes[0, 0].set_title('NIR Spectra (Raw Data)', fontsize=12, fontweight='bold')
        axes[0, 0].legend(fontsize=8, loc='upper right')
        axes[0, 0].grid(alpha=0.3)

        # Preprocessed spectra
        processed = self.preprocess_spectra(spectra, method='snv')
        for i in range(0, len(processed), 20):
            axes[0, 1].plot(self.wavelengths, processed[i], alpha=0.6)

        axes[0, 1].set_xlabel('Wavelength (nm)')
        axes[0, 1].set_ylabel('SNV-Processed Absorbance')
        axes[0, 1].set_title('NIR Spectra (After SNV Preprocessing)', fontsize=12, fontweight='bold')
        axes[0, 1].grid(alpha=0.3)

        # PLS prediction accuracy
        axes[1, 0].scatter(y_test, y_pred, alpha=0.6, s=50, color='#11998e')
        axes[1, 0].plot([85, 115], [85, 115], 'r--', linewidth=2, label='Ideal Line')

        # ¬±5% tolerance range
        axes[1, 0].plot([85, 115], [90, 120], 'orange', linestyle=':', linewidth=1.5, alpha=0.7)
        axes[1, 0].plot([85, 115], [80, 110], 'orange', linestyle=':', linewidth=1.5, alpha=0.7)

        # Calculate R¬≤ and RMSE
        from sklearn.metrics import r2_score, mean_squared_error
        r2 = r2_score(y_test, y_pred)
        rmse = np.sqrt(mean_squared_error(y_test, y_pred))

        axes[1, 0].text(0.05, 0.95, f'R¬≤ = {r2:.4f}\nRMSE = {rmse:.2f}%',
                        transform=axes[1, 0].transAxes, fontsize=11,
                        verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))

        axes[1, 0].set_xlabel('Actual API Content (%)')
        axes[1, 0].set_ylabel('Predicted API Content (%)')
        axes[1, 0].set_title('PLS Model Prediction Accuracy', fontsize=12, fontweight='bold')
        axes[1, 0].legend()
        axes[1, 0].grid(alpha=0.3)

        # Distribution of prediction errors
        errors = y_pred.flatten() - y_test
        axes[1, 1].hist(errors, bins=20, color='#38ef7d', alpha=0.7, edgecolor='black')
        axes[1, 1].axvline(x=0, color='red', linestyle='--', linewidth=2, label='Zero Error')
        axes[1, 1].set_xlabel('Prediction Error (%)')
        axes[1, 1].set_ylabel('Frequency')
        axes[1, 1].set_title('Prediction Error Distribution', fontsize=12, fontweight='bold')
        axes[1, 1].legend()
        axes[1, 1].grid(alpha=0.3)

        plt.tight_layout()
        plt.savefig('nir_pls_analysis.png', dpi=300, bbox_inches='tight')
        plt.show()

# Execution example
print("=" * 60)
print("NIR-PLS Analysis System (PAT Implementation)")
print("=" * 60)

# Define wavelength array (1100-2500nm, 2nm intervals)
wavelengths = np.arange(1100, 2501, 2)

# Initialize NIR analyzer
nir_analyzer = NIRAnalyzer(wavelengths)

# Generate NIR spectral data
spectra, api_content = nir_analyzer.generate_nir_spectra(n_samples=100)

print(f"\nNumber of samples: {len(spectra)}")
print(f"Number of wavelength points: {len(wavelengths)}")
print(f"Wavelength range: {wavelengths[0]}-{wavelengths[-1]} nm")
print(f"API content range: {api_content.min():.1f}-{api_content.max():.1f}%")

# Split training/test data
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(
    spectra, api_content, test_size=0.3, random_state=42
)

# Spectral preprocessing
X_train_processed = nir_analyzer.preprocess_spectra(X_train, method='snv')
X_test_processed = nir_analyzer.preprocess_spectra(X_test, method='snv')

# Build PLS model
cv_scores = nir_analyzer.build_pls_model(X_train_processed, y_train, n_components=5)

print(f"\nPLS Model (5 components):")
print(f"Cross-validation R¬≤ = {cv_scores.mean():.4f} ¬± {cv_scores.std():.4f}")

# Prediction
y_pred = nir_analyzer.predict(X_test_processed)

from sklearn.metrics import r2_score, mean_squared_error
r2 = r2_score(y_test, y_pred)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))

print(f"\nTest Set Performance:")
print(f"R¬≤ = {r2:.4f}")
print(f"RMSE = {rmse:.2f}%")
print(f"Relative Error = {rmse / api_content.mean() * 100:.2f}%")

# Visualization
nir_analyzer.plot_nir_analysis(spectra, api_content, X_test_processed, y_test, y_pred)
</code></pre>
<p><strong>Implementation Points:</strong></p>
<ul>
<li>NIR spectral preprocessing (SNV, MSC, derivative) for scatter removal</li>
<li>Building multivariate regression models using PLS</li>
<li>Model evaluation using cross-validation</li>
<li>Real-time API content prediction</li>
<li>Quantitative evaluation of prediction accuracy (R¬≤, RMSE)</li>
</ul>
</div>
<div class="content-box">
<h2>üìä 3.2 Multivariate Statistical Process Control (MSPC)</h2>
<h3>MSPC Principles</h3>
<p>
                Multivariate Statistical Process Control (MSPC) is a method for integrated monitoring of multiple process variables.
                Using Principal Component Analysis (PCA), it learns the data space during normal operation
                and detects anomalies.
            </p>
<div class="formula">
<h4>Hotelling's T¬≤ Statistic</h4>
                $$ T^2 = \mathbf{t}^\top \mathbf{\Lambda}^{-1} \mathbf{t} $$
                <p>where \( \mathbf{t} \) is the PCA score vector, \( \mathbf{\Lambda} \) is the covariance matrix of scores</p>
<h4>SPE (Squared Prediction Error)</h4>
                $$ \text{SPE} = \|\mathbf{x} - \hat{\mathbf{x}}\|^2 $$
                <p>\( \mathbf{x} \) is the original data, \( \hat{\mathbf{x}} \) is the data reconstructed by the PCA model</p>
</div>
<h3>üíª Code Example 3.2: MSPC Control Charts (Hotelling's T¬≤ and SPE)</h3>
<pre><code>import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from scipy import stats
import warnings
warnings.filterwarnings('ignore')

plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

class MSPCMonitor:
    """Multivariate Statistical Process Control (MSPC) class"""

    def __init__(self, n_components=3, alpha=0.05):
        """
        Args:
            n_components: Number of PCA principal components
            alpha: Significance level (for control limit calculation)
        """
        self.n_components = n_components
        self.alpha = alpha
        self.scaler = StandardScaler()
        self.pca = PCA(n_components=n_components)
        self.T2_limit = None
        self.SPE_limit = None

    def fit(self, X_normal):
        """
        Train model with normal operation data

        Args:
            X_normal: Process data during normal operation (n_samples √ó n_features)
        """
        # Standardization
        X_scaled = self.scaler.fit_transform(X_normal)

        # Build PCA model
        self.pca.fit(X_scaled)

        # Calculate T¬≤ and SPE for training data
        T2_train = self._calculate_T2(X_scaled)
        SPE_train = self._calculate_SPE(X_scaled)

        # Calculate control limits
        self.T2_limit = self._calculate_T2_limit(len(X_normal))
        self.SPE_limit = self._calculate_SPE_limit(SPE_train)

        return T2_train, SPE_train

    def _calculate_T2(self, X_scaled):
        """Calculate Hotelling's T¬≤ statistic"""
        scores = self.pca.transform(X_scaled)

        # Inverse of score covariance matrix
        cov_scores = np.cov(scores.T)
        cov_inv = np.linalg.inv(cov_scores)

        # T¬≤ calculation
        T2 = np.sum(scores @ cov_inv * scores, axis=1)

        return T2

    def _calculate_SPE(self, X_scaled):
        """Calculate SPE (Squared Prediction Error)"""
        # Reconstruction by PCA model
        scores = self.pca.transform(X_scaled)
        X_reconstructed = self.pca.inverse_transform(scores)

        # SPE calculation
        residuals = X_scaled - X_reconstructed
        SPE = np.sum(residuals ** 2, axis=1)

        return SPE

    def _calculate_T2_limit(self, n_samples):
        """T¬≤ control limit (F-distribution based)"""
        k = self.n_components
        n = n_samples

        F_crit = stats.f.ppf(1 - self.alpha, k, n - k)
        T2_limit = (k * (n - 1) / (n - k)) * F_crit

        return T2_limit

    def _calculate_SPE_limit(self, SPE_train):
        """SPE control limit (empirical method)"""
        # Mean and percentile
        SPE_limit = np.percentile(SPE_train, (1 - self.alpha) * 100)

        return SPE_limit

    def monitor(self, X_new):
        """
        Monitor new data

        Args:
            X_new: Data to be monitored

        Returns:
            T2, SPE, anomaly flags
        """
        X_scaled = self.scaler.transform(X_new)

        T2 = self._calculate_T2(X_scaled)
        SPE = self._calculate_SPE(X_scaled)

        # Anomaly detection
        T2_alarm = T2 &gt; self.T2_limit
        SPE_alarm = SPE &gt; self.SPE_limit

        return T2, SPE, T2_alarm, SPE_alarm

    def plot_mspc_charts(self, T2, SPE, T2_alarm, SPE_alarm):
        """Visualize MSPC control charts"""
        fig, axes = plt.subplots(2, 1, figsize=(14, 10))

        sample_indices = range(len(T2))

        # T¬≤ control chart
        colors_t2 = ['red' if alarm else '#11998e' for alarm in T2_alarm]
        axes[0].scatter(sample_indices, T2, c=colors_t2, s=50, alpha=0.7, edgecolor='black', linewidth=0.5)
        axes[0].plot(sample_indices, T2, color='#11998e', alpha=0.3, linewidth=1)
        axes[0].axhline(y=self.T2_limit, color='red', linestyle='--', linewidth=2,
                        label=f'Control Limit (T¬≤ = {self.T2_limit:.2f})')

        axes[0].set_xlabel('Sample Number')
        axes[0].set_ylabel("Hotelling's T¬≤")
        axes[0].set_title("Multivariate Control Chart: Hotelling's T¬≤", fontsize=12, fontweight='bold')
        axes[0].legend()
        axes[0].grid(alpha=0.3)

        # SPE control chart
        colors_spe = ['red' if alarm else '#38ef7d' for alarm in SPE_alarm]
        axes[1].scatter(sample_indices, SPE, c=colors_spe, s=50, alpha=0.7, edgecolor='black', linewidth=0.5)
        axes[1].plot(sample_indices, SPE, color='#38ef7d', alpha=0.3, linewidth=1)
        axes[1].axhline(y=self.SPE_limit, color='red', linestyle='--', linewidth=2,
                        label=f'Control Limit (SPE = {self.SPE_limit:.2f})')

        axes[1].set_xlabel('Sample Number')
        axes[1].set_ylabel('SPE (Squared Prediction Error)')
        axes[1].set_title('Multivariate Control Chart: SPE', fontsize=12, fontweight='bold')
        axes[1].legend()
        axes[1].grid(alpha=0.3)

        plt.tight_layout()
        plt.savefig('mspc_control_charts.png', dpi=300, bbox_inches='tight')
        plt.show()

# Execution example
print("=" * 60)
print("Multivariate Statistical Process Control (MSPC) System")
print("=" * 60)

# Generate process data
np.random.seed(42)
n_normal = 100
n_abnormal = 30
n_features = 6  # Temperature, Pressure, Flow rate, pH, Concentration, Viscosity

# Normal operation data
mean_normal = [80, 2.0, 100, 6.5, 5.0, 1000]
cov_normal = np.diag([4, 0.04, 100, 0.09, 0.25, 10000])
X_normal = np.random.multivariate_normal(mean_normal, cov_normal, n_normal)

# Train MSPC model
mspc = MSPCMonitor(n_components=3, alpha=0.05)
T2_train, SPE_train = mspc.fit(X_normal)

print(f"\nPCA Model:")
print(f"Number of components: {mspc.n_components}")
print(f"Cumulative variance ratio: {mspc.pca.explained_variance_ratio_.sum():.2%}")
print(f"\nControl Limits:")
print(f"T¬≤ Limit = {mspc.T2_limit:.2f}")
print(f"SPE Limit = {mspc.SPE_limit:.2f}")

# Generate monitoring data (normal + abnormal)
X_monitor = np.vstack([
    X_normal[:50],  # Normal
    np.random.multivariate_normal([85, 2.2, 110, 6.8, 5.5, 1200], cov_normal, n_abnormal)  # Abnormal
])

# Execute monitoring
T2, SPE, T2_alarm, SPE_alarm = mspc.monitor(X_monitor)

# Results summary
total_alarms = np.sum(T2_alarm | SPE_alarm)
print(f"\nMonitoring Results:")
print(f"Total samples: {len(X_monitor)}")
print(f"T¬≤ anomalies: {np.sum(T2_alarm)} cases")
print(f"SPE anomalies: {np.sum(SPE_alarm)} cases")
print(f"Total anomalies detected: {total_alarms} cases")

# Visualization
mspc.plot_mspc_charts(T2, SPE, T2_alarm, SPE_alarm)
</code></pre>
<p><strong>Implementation Points:</strong></p>
<ul>
<li>Dimensionality reduction and anomaly detection of multivariate data using PCA</li>
<li>Comprehensive process evaluation using Hotelling's T¬≤ statistic</li>
<li>Monitoring model fit using SPE</li>
<li>Statistical control limit setting based on F-distribution</li>
<li>Real-time monitoring and alarm functionality</li>
</ul>
</div>
<div class="content-box">
<h2>üìö Summary</h2>
<p>In this chapter, we learned about PAT and real-time quality control.</p>
<h3>Key Points</h3>
<ul>
<li>Real-time quality measurement using NIR/Raman spectroscopy</li>
<li>Building quantitative models using PLS regression</li>
<li>Implementation of Multivariate Statistical Process Control (MSPC)</li>
<li>Anomaly detection using Hotelling's T¬≤ and SPE control charts</li>
<li>Deepening process understanding through integration of PAT tools</li>
</ul>
<div class="key-point">
<strong>üéØ Next Chapter Preview</strong><br/>
                Chapter 4 will cover the transition from batch production to continuous production and Quality by Design (QbD) implementation.
                You will master more strategic quality control methods including DoE (Design of Experiments), design space, and risk-based approaches.
            </div>
</div>
<div class="nav-buttons">
<a href="chapter-2.html">‚Üê Chapter 2: Electronic Batch Record Analysis</a>
<a href="chapter-4.html">Chapter 4: Continuous Production and QbD Implementation ‚Üí</a>
</div>
</div>
<section>
            <h2>References</h2>
            <ol>
                <li>Montgomery, D. C. (2019). <em>Design and Analysis of Experiments</em> (9th ed.). Wiley.</li>
                <li>Box, G. E. P., Hunter, J. S., &amp; Hunter, W. G. (2005). <em>Statistics for Experimenters: Design, Innovation, and Discovery</em> (2nd ed.). Wiley.</li>
                <li>Seborg, D. E., Edgar, T. F., Mellichamp, D. A., &amp; Doyle III, F. J. (2016). <em>Process Dynamics and Control</em> (4th ed.). Wiley.</li>
                <li>McKay, M. D., Beckman, R. J., &amp; Conover, W. J. (2000). "A Comparison of Three Methods for Selecting Values of Input Variables in the Analysis of Output from a Computer Code." <em>Technometrics</em>, 42(1), 55-61.</li>
            </ol>
        </section>

<section class="disclaimer">
<h3>Disclaimer</h3>
<ul>
<li>This content is provided solely for educational, research, and informational purposes and does not constitute professional advice (legal, accounting, technical warranty, etc.).</li>
<li>This content and accompanying code examples are provided "AS IS" without any warranty, express or implied, including but not limited to merchantability, fitness for a particular purpose, non-infringement, accuracy, completeness, operation, or safety.</li>
<li>The author and Tohoku University assume no responsibility for the content, availability, or safety of external links, third-party data, tools, libraries, etc.</li>
<li>To the maximum extent permitted by applicable law, the author and Tohoku University shall not be liable for any direct, indirect, incidental, special, consequential, or punitive damages arising from the use, execution, or interpretation of this content.</li>
<li>The content may be changed, updated, or discontinued without notice.</li>
<li>The copyright and license of this content are subject to the stated conditions (e.g., CC BY 4.0). Such licenses typically include no-warranty clauses.</li>
</ul>
</section>

<footer>
<p>¬© 2025 AI Terakoya - Process Informatics Dojo</p>
<p>Chapter 3: PAT and Real-Time Quality Control</p>
</footer>
</body>
</html>
