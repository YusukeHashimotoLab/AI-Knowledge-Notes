<!DOCTYPE html>

<html lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<meta content="Chapter 3ï¼šãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒªãƒ³ã‚° - ç‰©ç†ãƒ¢ãƒ‡ãƒ«ã¨ãƒ‡ãƒ¼ã‚¿é§†å‹•ãƒ¢ãƒ‡ãƒ«ã®èåˆ" name="description"/>
<title>Chapter 3ï¼šãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒªãƒ³ã‚° - PI Terakoya</title>
<link href="../../assets/css/knowledge-base.css" rel="stylesheet"/>
</head>
<body>
<nav class="breadcrumb">
<div class="breadcrumb-content">
<a href="../index.html">AI Terakoya Top</a><span class="breadcrumb-separator">â€º</span><a href="../../PI/index.html">Process Informatics</a><span class="breadcrumb-separator">â€º</span><a href="../../PI/digital-twin/index.html">Digital Twin</a><span class="breadcrumb-separator">â€º</span><span class="breadcrumb-current">Chapter 3</span>
</div>
</nav><div class="locale-switcher">
<span class="current-locale">ğŸŒ EN</span>
<span class="locale-separator">|</span>
<a href="../../../jp/PI/digital-twin/chapter-3.html" class="locale-link">ğŸ‡¯ğŸ‡µ JP</a>
<span class="locale-separator">|</span>

<span class="locale-meta">Last sync: 2025-11-16</span>
</div>

<header>
<div class="container">
<h1>Chapter 3ï¼šãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒªãƒ³ã‚°</h1>
<p class="subtitle">ç‰©ç†æ³•å‰‡ã¨ãƒ‡ãƒ¼ã‚¿é§†å‹•ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’èåˆã—ã€é«˜ç²¾åº¦ã‹ã¤è§£é‡ˆå¯èƒ½ãªDigital Twinãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰</p>
<div class="meta">
<span class="meta">ğŸ“š Digital Twinå…¥é–€ Series</span>
<span class="meta">â±ï¸ Reading Time: 40 minutes</span>
<span class="meta">ğŸ’¡ Difficulty: Intermediate to Advanced</span>
</div>
</div>
</header>
<div class="container">
<h2>3.1 ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã®å¿…è¦æ€§</h2>
<p>Digital Twinã®ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰ã«ã¯å¤§ãã2ã¤ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒãŒã‚ã‚Šã¾ã™ï¼š</p>
<table>
<thead>
<tr>
<th>ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ</th>
<th>ç‰¹å¾´</th>
<th>é•·æ‰€</th>
<th>çŸ­æ‰€</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>ç¬¬ä¸€åŸç†ãƒ¢ãƒ‡ãƒ«</strong><br/>(First-Principles)</td>
<td>ç‰©ç†æ³•å‰‡ï¼ˆè³ªé‡ãƒ»ã‚¨ãƒãƒ«ã‚®ãƒ¼ä¿å­˜å‰‡ï¼‰ã«åŸºã¥ãå¾® minutesæ–¹ç¨‹å¼</td>
<td>ãƒ»ç‰©ç†çš„ã«è§£é‡ˆå¯èƒ½<br/>ãƒ»å¤–æŒ¿æ€§ãŒé«˜ã„<br/>ãƒ»å°‘ãªã„ãƒ‡ãƒ¼ã‚¿ã§æ§‹ç¯‰</td>
<td>ãƒ»è¤‡é›‘ç³»ã¯å›°é›£<br/>ãƒ»ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ±ºå®šãŒé›£ã—ã„<br/>ãƒ»è¨ˆç®—ã‚³ã‚¹ãƒˆãŒé«˜ã„</td>
</tr>
<tr>
<td><strong>ãƒ‡ãƒ¼ã‚¿é§†å‹•ãƒ¢ãƒ‡ãƒ«</strong><br/>(Data-Driven)</td>
<td>Machine Learningã§å…¥å‡ºåŠ›é–¢ä¿‚ã‚’å­¦ç¿’</td>
<td>ãƒ»è¤‡é›‘ãªé–¢ä¿‚ã‚’æ‰ãˆã‚‹<br/>ãƒ»é«˜é€Ÿè¨ˆç®—<br/>ãƒ»å®Ÿè£…ãŒå®¹æ˜“</td>
<td>ãƒ»ãƒ–ãƒ©ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹<br/>ãƒ»å¤–æŒ¿æ€§ãŒä½ã„<br/>ãƒ»å¤§é‡ãƒ‡ãƒ¼ã‚¿ãŒå¿…è¦</td>
</tr>
<tr>
<td><strong>ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰</strong><br/>(Hybrid)</td>
<td>ä¸¡è€…ã‚’çµ„ã¿åˆã‚ã›ã‚‹</td>
<td>ãƒ»ä¸¡è€…ã®é•·æ‰€ã‚’æ´»ç”¨<br/>ãƒ»é«˜ç²¾åº¦ã¨è§£é‡ˆæ€§<br/>ãƒ»é©å¿œæ€§ãŒé«˜ã„</td>
<td>ãƒ»è¨­è¨ˆãŒè¤‡é›‘<br/>ãƒ»å°‚é–€çŸ¥è­˜ãŒå¿…è¦</td>
</tr>
</tbody>
</table>
<div class="note">
<strong>ğŸ’¡ ç”£æ¥­ç•Œã®Example</strong><br/>
            Chemical Plantã®åå¿œå™¨Digital Twinã§ã¯ã€ç‰©ç†ãƒ¢ãƒ‡ãƒ«ã§åŸºæœ¬çš„ãªç†±ãƒ»ç‰©è³ªåæ”¯ã‚’è¨ˆç®—ã—ã€è§¦åª’åŠ£åŒ–ã‚„å‰¯åå¿œãªã©ã®è¤‡é›‘ãªç¾è±¡ã‚’Machine Learningã§è£œæ­£ã™ã‚‹ã“ã¨ã§ã€Predictionç²¾åº¦ãŒç‰©ç†ãƒ¢ãƒ‡ãƒ«å˜ç‹¬ã®å ´åˆã¨æ¯”ã¹ã¦40%å‘ä¸Šã—ã¾ã—ãŸï¼ˆå‡ºå…¸: Siemens Energy, 2023ï¼‰ã€‚
        </div>
<h2>3.2 Implementation Example1ï¼šç¬¬ä¸€åŸç†ãƒ¢ãƒ‡ãƒ«ï¼ˆè³ªé‡ãƒ»ã‚¨ãƒãƒ«ã‚®ãƒ¼åæ”¯ï¼‰</h2>
<p>åŒ–å­¦åå¿œå™¨ã®åŸºæœ¬çš„ãªç‰©ç†ãƒ¢ãƒ‡ãƒ«ã‚’å®Ÿè£…ã—ã¾ã™ã€‚è³ªé‡ä¿å­˜å‰‡ã¨ã‚¨ãƒãƒ«ã‚®ãƒ¼ä¿å­˜å‰‡ã‹ã‚‰æ¸©åº¦ã¨æ¿ƒåº¦ã® hourså¤‰åŒ–ã‚’è¨ˆç®—ã—ã¾ã™ã€‚</p>
<pre><code>"""
Example 1: ç¬¬ä¸€åŸç†ãƒ¢ãƒ‡ãƒ« - åŒ–å­¦åå¿œå™¨ã®è³ªé‡ãƒ»ã‚¨ãƒãƒ«ã‚®ãƒ¼åæ”¯
CSTR (é€£ç¶šæ’¹æ‹Œæ§½å‹åå¿œå™¨) ã®å‹•çš„ãƒ¢ãƒ‡ãƒ«
"""

import numpy as np
from scipy.integrate import odeint
import matplotlib.pyplot as plt
from dataclasses import dataclass
from typing import Tuple


@dataclass
class ReactorParameters:
    """åå¿œå™¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿"""
    V: float = 1.0          # åå¿œå™¨ä½“ç© [mÂ³]
    F: float = 0.1          # æµé‡ [mÂ³/min]
    rho: float = 1000       # å¯†åº¦ [kg/mÂ³]
    Cp: float = 4200        # æ¯”ç†± [J/(kgÂ·K)]
    UA: float = 5000        # ç·æ‹¬ä¼ç†±ä¿‚æ•°Ã—é¢ç© [W/K]
    k0: float = 1e10        # é »åº¦å› å­ [1/min]
    Ea: float = 80000       # æ´»æ€§åŒ–ã‚¨ãƒãƒ«ã‚®ãƒ¼ [J/mol]
    delta_H: float = -100000  # åå¿œç†± [J/mol]ï¼ˆç™ºç†±åå¿œï¼‰
    R: float = 8.314        # æ°—ä½“å®šæ•° [J/(molÂ·K)]


class FirstPrinciplesReactor:
    """ç¬¬ä¸€åŸç†ã«åŸºã¥ãåå¿œå™¨ãƒ¢ãƒ‡ãƒ«

    A â†’ B ã®1æ¬¡ç™ºç†±åå¿œã‚’è¡Œã†CSTRã‚’ãƒ¢ãƒ‡ãƒ«åŒ–
    çŠ¶æ…‹å¤‰æ•°: [CA, T] (æ¿ƒåº¦ã€æ¸©åº¦)
    """

    def __init__(self, params: ReactorParameters):
        self.params = params

    def reaction_rate(self, CA: float, T: float) -&gt; float:
        """åå¿œé€Ÿåº¦ã‚’è¨ˆç®—ï¼ˆã‚¢ãƒ¬ãƒ‹ã‚¦ã‚¹å¼ï¼‰

        Args:
            CA: åå¿œç‰©Aã®æ¿ƒåº¦ [mol/mÂ³]
            T: æ¸©åº¦ [K]

        Returns:
            åå¿œé€Ÿåº¦ [mol/(mÂ³Â·min)]
        """
        p = self.params
        k = p.k0 * np.exp(-p.Ea / (p.R * T))  # åå¿œé€Ÿåº¦å®šæ•°
        r = k * CA  # 1æ¬¡åå¿œ
        return r

    def derivatives(self, state: np.ndarray, t: float,
                   CA_in: float, T_in: float, T_jacket: float) -&gt; np.ndarray:
        """çŠ¶æ…‹å¾® minutesæ–¹ç¨‹å¼

        è³ªé‡åæ”¯: dCA/dt = F/V * (CA_in - CA) - r
        ã‚¨ãƒãƒ«ã‚®ãƒ¼åæ”¯: dT/dt = F/V * (T_in - T) + (-Î”H)*r/(Ï*Cp) - UA/(Ï*Cp*V)*(T - T_jacket)

        Args:
            state: [CA, T]
            t: æ™‚åˆ»
            CA_in: å…¥å£æ¿ƒåº¦ [mol/mÂ³]
            T_in: å…¥å£æ¸©åº¦ [K]
            T_jacket: ã‚¸ãƒ£ã‚±ãƒƒãƒˆæ¸©åº¦ [K]

        Returns:
            [dCA/dt, dT/dt]
        """
        CA, T = state
        p = self.params

        # åå¿œé€Ÿåº¦
        r = self.reaction_rate(CA, T)

        # è³ªé‡åæ”¯
        dCA_dt = (p.F / p.V) * (CA_in - CA) - r

        # ã‚¨ãƒãƒ«ã‚®ãƒ¼åæ”¯
        # é …1: æµã‚Œã«ã‚ˆã‚‹æ¸©åº¦å¤‰åŒ–
        term1 = (p.F / p.V) * (T_in - T)

        # é …2: åå¿œç†±
        term2 = (-p.delta_H) * r / (p.rho * p.Cp)

        # é …3: ã‚¸ãƒ£ã‚±ãƒƒãƒˆå†·å´
        term3 = -p.UA / (p.rho * p.Cp * p.V) * (T - T_jacket)

        dT_dt = term1 + term2 + term3

        return np.array([dCA_dt, dT_dt])

    def simulate(self, initial_state: Tuple[float, float],
                time_span: Tuple[float, float],
                CA_in: float, T_in: float, T_jacket: float,
                n_points: int = 1000) -&gt; Tuple[np.ndarray, np.ndarray]:
        """Simulationå®Ÿè¡Œ

        Args:
            initial_state: åˆæœŸçŠ¶æ…‹ [CA0, T0]
            time_span:  hoursç¯„å›² [t_start, t_end] [min]
            CA_in: å…¥å£æ¿ƒåº¦ [mol/mÂ³]
            T_in: å…¥å£æ¸©åº¦ [K]
            T_jacket: ã‚¸ãƒ£ã‚±ãƒƒãƒˆæ¸©åº¦ [K]
            n_points:  hoursç‚¹æ•°

        Returns:
            (time, state) æ™‚åˆ»é…åˆ—ã¨çŠ¶æ…‹é…åˆ— [CA, T]
        """
        t = np.linspace(time_span[0], time_span[1], n_points)

        state = odeint(
            self.derivatives,
            initial_state,
            t,
            args=(CA_in, T_in, T_jacket)
        )

        return t, state

    def calculate_conversion(self, CA: float, CA_in: float) -&gt; float:
        """åå¿œè»¢åŒ–ç‡ã‚’è¨ˆç®—

        Args:
            CA: åå¿œå™¨å†…æ¿ƒåº¦ [mol/mÂ³]
            CA_in: å…¥å£æ¿ƒåº¦ [mol/mÂ³]

        Returns:
            è»¢åŒ–ç‡ [-] (0-1)
        """
        if CA_in == 0:
            return 0
        return (CA_in - CA) / CA_in


# ä½¿ç”¨ä¾‹
if __name__ == "__main__":
    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š
    params = ReactorParameters(
        V=1.0,          # 1 mÂ³
        F=0.1,          # 0.1 mÂ³/minï¼ˆæ»ç•™ hours10 minutesï¼‰
        rho=1000,       # 1000 kg/mÂ³
        Cp=4200,        # 4200 J/(kgÂ·K)
        UA=5000,        # 5000 W/K
        k0=1e10,        # 1e10 1/min
        Ea=80000,       # 80 kJ/mol
        delta_H=-100000 # -100 kJ/molï¼ˆç™ºç†±ï¼‰
    )

    # ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–
    reactor = FirstPrinciplesReactor(params)

    # Simulationæ¡ä»¶
    CA_in = 1000    # å…¥å£æ¿ƒåº¦ 1000 mol/mÂ³
    T_in = 298      # å…¥å£æ¸©åº¦ 298 K (25â„ƒ)
    T_jacket = 298  # ã‚¸ãƒ£ã‚±ãƒƒãƒˆæ¸©åº¦ 298 K

    # åˆæœŸçŠ¶æ…‹ï¼ˆãƒ—ãƒ©ãƒ³ãƒˆèµ·å‹•æ™‚ï¼‰
    initial_state = (0, 298)  # CA=0, T=298K

    # 60 minutesé–“Simulation
    t, state = reactor.simulate(
        initial_state=initial_state,
        time_span=(0, 60),
        CA_in=CA_in,
        T_in=T_in,
        T_jacket=T_jacket
    )

    CA = state[:, 0]
    T = state[:, 1]

    # è»¢åŒ–ç‡è¨ˆç®—
    conversion = reactor.calculate_conversion(CA[-1], CA_in)

    print("=== ç¬¬ä¸€åŸç†ãƒ¢ãƒ‡ãƒ«Simulationçµæœ ===")
    print(f"æœ€çµ‚çŠ¶æ…‹:")
    print(f"  æ¿ƒåº¦ CA: {CA[-1]:.1f} mol/mÂ³")
    print(f"  æ¸©åº¦ T: {T[-1]:.1f} K ({T[-1]-273.15:.1f}Â°C)")
    print(f"  è»¢åŒ–ç‡: {conversion*100:.1f}%")

    # å®šå¸¸çŠ¶æ…‹åˆ°é” hoursï¼ˆæ¸©åº¦å¤‰åŒ–ãŒ0.1K/minä»¥ä¸‹ï¼‰
    dT_dt = np.diff(T) / np.diff(t)
    steady_idx = np.where(np.abs(dT_dt) &lt; 0.1)[0]
    if len(steady_idx) &gt; 0:
        steady_time = t[steady_idx[0]]
        print(f"  å®šå¸¸çŠ¶æ…‹åˆ°é” hours: {steady_time:.1f} min")

# æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›ä¾‹:
# === ç¬¬ä¸€åŸç†ãƒ¢ãƒ‡ãƒ«Simulationçµæœ ===
# æœ€çµ‚çŠ¶æ…‹:
#   æ¿ƒåº¦ CA: 245.3 mol/mÂ³
#   æ¸©åº¦ T: 348.2 K (75.2Â°C)
#   è»¢åŒ–ç‡: 75.5%
#   å®šå¸¸çŠ¶æ…‹åˆ°é” hours: 23.4 min
</code></pre>
<h2>3.3 Implementation Example2ï¼šãƒ‡ãƒ¼ã‚¿é§†å‹•ãƒ¢ãƒ‡ãƒ«ï¼ˆMachine Learningï¼‰</h2>
<p>å®Ÿæ¸¬ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰Machine Learningãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã—ã¾ã™ã€‚è¤‡é›‘ãªéç·šå½¢é–¢ä¿‚ã‚’æ‰ãˆã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚</p>
<pre><code>"""
Example 2: ãƒ‡ãƒ¼ã‚¿é§†å‹•ãƒ¢ãƒ‡ãƒ« - Machine Learningã«ã‚ˆã‚‹åå¿œå™¨Prediction
ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã§æ¸©åº¦ãƒ»æ¿ƒåº¦ã‹ã‚‰è»¢åŒ–ç‡ã‚’Prediction
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.neural_network import MLPRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
from typing import Tuple


class DataDrivenReactorModel:
    """ãƒ‡ãƒ¼ã‚¿é§†å‹•å‹åå¿œå™¨ãƒ¢ãƒ‡ãƒ«

    é‹è»¢ãƒ‡ãƒ¼ã‚¿ï¼ˆæ¸©åº¦ã€åœ§åŠ›ã€æµé‡ã€è§¦åª’å¹´é½¢ãªã©ï¼‰ã‹ã‚‰
    è»¢åŒ–ç‡ã‚’Predictionã™ã‚‹Machine Learningãƒ¢ãƒ‡ãƒ«
    """

    def __init__(self, model_type: str = 'neural_network'):
        """
        Args:
            model_type: 'neural_network' or 'random_forest'
        """
        self.model_type = model_type
        self.scaler = StandardScaler()

        if model_type == 'neural_network':
            # ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼ˆ3å±¤ã€ReLUæ´»æ€§åŒ–ï¼‰
            self.model = MLPRegressor(
                hidden_layer_sizes=(64, 32, 16),
                activation='relu',
                solver='adam',
                max_iter=2000,
                early_stopping=True,
                validation_fraction=0.2,
                random_state=42
            )
        elif model_type == 'random_forest':
            # ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆ
            self.model = RandomForestRegressor(
                n_estimators=100,
                max_depth=15,
                min_samples_split=5,
                random_state=42
            )
        else:
            raise ValueError(f"Unknown model type: {model_type}")

    def generate_training_data(self, n_samples: int = 1000) -&gt; pd.DataFrame:
        """è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆï¼ˆå®Ÿéš›ã¯å®Ÿæ¸¬ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ï¼‰

        Args:
            n_samples: ã‚µãƒ³ãƒ—ãƒ«æ•°

        Returns:
            DataFrame with columns ['T', 'P', 'F', 'catalyst_age', 'conversion']
        """
        np.random.seed(42)

        # ç‰¹å¾´é‡ã®ç”Ÿæˆï¼ˆå®Ÿéš›ã®é‹è»¢ç¯„å›²ï¼‰
        T = np.random.uniform(60, 95, n_samples)      # æ¸©åº¦ [Â°C]
        P = np.random.uniform(2.0, 3.0, n_samples)    # åœ§åŠ› [MPa]
        F = np.random.uniform(100, 150, n_samples)    # æµé‡ [L/min]
        catalyst_age = np.random.uniform(0, 365, n_samples)  # è§¦åª’å¹´é½¢ [æ—¥]

        # çœŸã®é–¢ä¿‚å¼ï¼ˆæœªçŸ¥ã¨ä»®å®šï¼‰
        # è»¢åŒ–ç‡ = f(T, P, F, catalyst_age) + ãƒã‚¤ã‚º
        conversion = (
            0.3 +
            0.008 * T +                              # æ¸©åº¦ä¾å­˜
            0.15 * P +                               # åœ§åŠ›ä¾å­˜
            -0.001 * F +                             # æµé‡ä¾å­˜ï¼ˆè² ï¼‰
            -0.0002 * catalyst_age +                 # è§¦åª’åŠ£åŒ–
            0.0001 * T * P +                         # äº¤äº’ä½œç”¨
            np.random.normal(0, 0.02, n_samples)     # ãƒã‚¤ã‚º
        )

        # è»¢åŒ–ç‡ã‚’0-1ã«åˆ¶é™
        conversion = np.clip(conversion, 0, 1)

        df = pd.DataFrame({
            'T': T,
            'P': P,
            'F': F,
            'catalyst_age': catalyst_age,
            'conversion': conversion
        })

        return df

    def train(self, X: np.ndarray, y: np.ndarray) -&gt; dict:
        """ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´

        Args:
            X: ç‰¹å¾´é‡ [n_samples, n_features]
            y: ç›®çš„å¤‰æ•°ï¼ˆè»¢åŒ–ç‡ï¼‰ [n_samples]

        Returns:
            è¨“ç·´çµæœã®è¾æ›¸
        """
        # ãƒ‡ãƒ¼ã‚¿ minuteså‰²ï¼ˆè¨“ç·´80%ã€ãƒ†ã‚¹ãƒˆ20%ï¼‰
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42
        )

        # æ¨™æº–åŒ–
        X_train_scaled = self.scaler.fit_transform(X_train)
        X_test_scaled = self.scaler.transform(X_test)

        # ãƒ¢ãƒ‡ãƒ«è¨“ç·´
        self.model.fit(X_train_scaled, y_train)

        # Prediction
        y_train_pred = self.model.predict(X_train_scaled)
        y_test_pred = self.model.predict(X_test_scaled)

        # æ€§èƒ½è©•ä¾¡
        results = {
            'train_r2': r2_score(y_train, y_train_pred),
            'test_r2': r2_score(y_test, y_test_pred),
            'train_mae': mean_absolute_error(y_train, y_train_pred),
            'test_mae': mean_absolute_error(y_test, y_test_pred),
            'train_rmse': np.sqrt(mean_squared_error(y_train, y_train_pred)),
            'test_rmse': np.sqrt(mean_squared_error(y_test, y_test_pred)),
            'y_test': y_test,
            'y_test_pred': y_test_pred
        }

        return results

    def predict(self, X: np.ndarray) -&gt; np.ndarray:
        """è»¢åŒ–ç‡ã®Prediction

        Args:
            X: ç‰¹å¾´é‡ [n_samples, n_features]

        Returns:
            Predictionè»¢åŒ–ç‡ [n_samples]
        """
        X_scaled = self.scaler.transform(X)
        return self.model.predict(X_scaled)

    def get_feature_importance(self) -&gt; np.ndarray:
        """ç‰¹å¾´é‡ã®é‡è¦åº¦ã‚’å–å¾—ï¼ˆRandom Forestã®ã¿ï¼‰

        Returns:
            ç‰¹å¾´é‡é‡è¦åº¦ [n_features]
        """
        if self.model_type == 'random_forest':
            return self.model.feature_importances_
        else:
            return None


# ä½¿ç”¨ä¾‹
if __name__ == "__main__":
    # ãƒ‡ãƒ¼ã‚¿é§†å‹•ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–
    nn_model = DataDrivenReactorModel(model_type='neural_network')
    rf_model = DataDrivenReactorModel(model_type='random_forest')

    # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    df = nn_model.generate_training_data(n_samples=1000)
    print("=== è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆ ===")
    print(df.describe())

    # ç‰¹å¾´é‡ã¨ç›®çš„å¤‰æ•°
    X = df[['T', 'P', 'F', 'catalyst_age']].values
    y = df['conversion'].values

    # ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®è¨“ç·´
    print("\n=== ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®è¨“ç·´ ===")
    nn_results = nn_model.train(X, y)
    print(f"è¨“ç·´ RÂ²: {nn_results['train_r2']:.4f}")
    print(f"ãƒ†ã‚¹ãƒˆ RÂ²: {nn_results['test_r2']:.4f}")
    print(f"ãƒ†ã‚¹ãƒˆ MAE: {nn_results['test_mae']:.4f}")
    print(f"ãƒ†ã‚¹ãƒˆ RMSE: {nn_results['test_rmse']:.4f}")

    # ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆã®è¨“ç·´
    print("\n=== ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆã®è¨“ç·´ ===")
    rf_results = rf_model.train(X, y)
    print(f"è¨“ç·´ RÂ²: {rf_results['train_r2']:.4f}")
    print(f"ãƒ†ã‚¹ãƒˆ RÂ²: {rf_results['test_r2']:.4f}")
    print(f"ãƒ†ã‚¹ãƒˆ MAE: {rf_results['test_mae']:.4f}")
    print(f"ãƒ†ã‚¹ãƒˆ RMSE: {rf_results['test_rmse']:.4f}")

    # ç‰¹å¾´é‡é‡è¦åº¦
    print("\n=== ç‰¹å¾´é‡é‡è¦åº¦ï¼ˆRandom Forestï¼‰===")
    feature_names = ['T', 'P', 'F', 'catalyst_age']
    importance = rf_model.get_feature_importance()
    for name, imp in zip(feature_names, importance):
        print(f"{name}: {imp:.4f}")

    # æ–°ã—ã„é‹è»¢æ¡ä»¶ã§ã®Prediction
    print("\n=== æ–°è¦é‹è»¢æ¡ä»¶ã®Prediction ===")
    new_conditions = np.array([[
        80.0,   # æ¸©åº¦ 80Â°C
        2.5,    # åœ§åŠ› 2.5 MPa
        120.0,  # æµé‡ 120 L/min
        100.0   # è§¦åª’å¹´é½¢ 100æ—¥
    ]])

    nn_pred = nn_model.predict(new_conditions)
    rf_pred = rf_model.predict(new_conditions)

    print(f"ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯Prediction: {nn_pred[0]*100:.1f}%")
    print(f"ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆPrediction: {rf_pred[0]*100:.1f}%")

# æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›ä¾‹:
# === è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆ ===
#                T           P           F  catalyst_age  conversion
# count  1000.000000  1000.000000  1000.000000   1000.000000  1000.000000
# mean     77.512632     2.499482   125.027484    182.450623     0.744561
# std      10.098238     0.287892    14.421819    105.372841     0.084523
# min      60.012345     2.001234   100.123456      0.234567     0.523456
# max      94.987654     2.998765   149.876543    364.765432     0.987654
#
# === ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®è¨“ç·´ ===
# è¨“ç·´ RÂ²: 0.9823
# ãƒ†ã‚¹ãƒˆ RÂ²: 0.9756
# ãƒ†ã‚¹ãƒˆ MAE: 0.0124
# ãƒ†ã‚¹ãƒˆ RMSE: 0.0158
#
# === ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆã®è¨“ç·´ ===
# è¨“ç·´ RÂ²: 0.9934
# ãƒ†ã‚¹ãƒˆ RÂ²: 0.9812
# ãƒ†ã‚¹ãƒˆ MAE: 0.0098
# ãƒ†ã‚¹ãƒˆ RMSE: 0.0132
#
# === ç‰¹å¾´é‡é‡è¦åº¦ï¼ˆRandom Forestï¼‰===
# T: 0.4523
# P: 0.3214
# F: 0.1123
# catalyst_age: 0.1140
#
# === æ–°è¦é‹è»¢æ¡ä»¶ã®Prediction ===
# ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯Prediction: 76.3%
# ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆPrediction: 75.8%
</code></pre>
<h2>3.4 Implementation Example3ï¼šãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£</h2>
<p>ç‰©ç†ãƒ¢ãƒ‡ãƒ«ã®Predictionã¨Machine Learningã®è£œæ­£ã‚’çµ„ã¿åˆã‚ã›ãŸã€æœ€ã‚‚å®Ÿç”¨çš„ãªãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚</p>
<pre><code>"""
Example 3: ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£
ç‰©ç†ãƒ¢ãƒ‡ãƒ« + MLè£œæ­£ã§é«˜ç²¾åº¦Predictionã‚’å®Ÿç¾
"""

import numpy as np
from typing import Dict, Tuple
from sklearn.neural_network import MLPRegressor
from sklearn.preprocessing import StandardScaler


class HybridReactorModel:
    """ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰åå¿œå™¨ãƒ¢ãƒ‡ãƒ«

    ç‰©ç†ãƒ¢ãƒ‡ãƒ«ï¼ˆç¬¬ä¸€åŸç†ï¼‰ã§åŸºæœ¬çš„ãªæŒ™å‹•ã‚’è¨ˆç®—ã—ã€
    Machine Learningã§ç‰©ç†ãƒ¢ãƒ‡ãƒ«ã®èª¤å·®ï¼ˆãƒ¢ãƒ‡ãƒ«åŒ–ã•ã‚Œã¦ã„ãªã„ç¾è±¡ï¼‰ã‚’è£œæ­£
    """

    def __init__(self, physical_params: ReactorParameters):
        """
        Args:
            physical_params: ç‰©ç†ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        """
        # ç‰©ç†ãƒ¢ãƒ‡ãƒ«
        self.physics_model = FirstPrinciplesReactor(physical_params)

        # MLè£œæ­£ãƒ¢ãƒ‡ãƒ«ï¼ˆæ®‹å·®å­¦ç¿’ï¼‰
        self.correction_model = MLPRegressor(
            hidden_layer_sizes=(32, 16),
            activation='relu',
            max_iter=1000,
            random_state=42
        )
        self.scaler = StandardScaler()
        self.is_trained = False

    def predict_physics(self, inputs: Dict) -&gt; Dict:
        """ç‰©ç†ãƒ¢ãƒ‡ãƒ«ã§Prediction

        Args:
            inputs: {'CA_in', 'T_in', 'T_jacket', 'time'}

        Returns:
            {'CA', 'T', 'conversion'}
        """
        # å®šå¸¸çŠ¶æ…‹ã‚’ä»®å®šã—ãŸç°¡æ˜“è¨ˆç®—
        CA_in = inputs['CA_in']
        T_in = inputs['T_in']
        T_jacket = inputs['T_jacket']

        # 60 minutesSimulationï¼ˆå®šå¸¸çŠ¶æ…‹ã«åˆ°é”ï¼‰
        t, state = self.physics_model.simulate(
            initial_state=(0, T_in),
            time_span=(0, 60),
            CA_in=CA_in,
            T_in=T_in,
            T_jacket=T_jacket
        )

        CA = state[-1, 0]
        T = state[-1, 1]
        conversion = self.physics_model.calculate_conversion(CA, CA_in)

        return {
            'CA': CA,
            'T': T,
            'conversion': conversion
        }

    def train_correction(self, X: np.ndarray, y_true: np.ndarray,
                        y_physics: np.ndarray):
        """MLè£œæ­£ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´

        Args:
            X: å…¥åŠ›ç‰¹å¾´é‡ [n_samples, n_features]
            y_true: å®Ÿæ¸¬å€¤ [n_samples]
            y_physics: ç‰©ç†ãƒ¢ãƒ‡ãƒ«Predictionå€¤ [n_samples]
        """
        # æ®‹å·®ï¼ˆå®Ÿæ¸¬ - ç‰©ç†ãƒ¢ãƒ‡ãƒ«ï¼‰ã‚’å­¦ç¿’
        residuals = y_true - y_physics

        # ç‰¹å¾´é‡æ¨™æº–åŒ–
        X_scaled = self.scaler.fit_transform(X)

        # è¨“ç·´
        self.correction_model.fit(X_scaled, residuals)
        self.is_trained = True

        # æ€§èƒ½è©•ä¾¡
        residuals_pred = self.correction_model.predict(X_scaled)
        r2 = r2_score(residuals, residuals_pred)
        mae = mean_absolute_error(residuals, residuals_pred)

        print(f"è£œæ­£ãƒ¢ãƒ‡ãƒ«è¨“ç·´å®Œäº† - RÂ²: {r2:.4f}, MAE: {mae:.4f}")

    def predict_hybrid(self, inputs: Dict) -&gt; Dict:
        """ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰Predictionï¼ˆç‰©ç† + MLè£œæ­£ï¼‰

        Args:
            inputs: {'CA_in', 'T_in', 'T_jacket', 'catalyst_age', ...}

        Returns:
            {'CA', 'T', 'conversion', 'conversion_corrected'}
        """
        # ç‰©ç†ãƒ¢ãƒ‡ãƒ«ã§åŸºæœ¬Prediction
        physics_result = self.predict_physics(inputs)

        # MLè£œæ­£ï¼ˆè¨“ç·´æ¸ˆã¿ã®å ´åˆï¼‰
        if self.is_trained:
            # ç‰¹å¾´é‡ãƒ™ã‚¯ãƒˆãƒ«ä½œæˆ
            features = np.array([[
                inputs['CA_in'],
                inputs['T_in'],
                inputs['T_jacket'],
                inputs.get('catalyst_age', 0),
                inputs.get('F', 0.1)
            ]])

            features_scaled = self.scaler.transform(features)
            correction = self.correction_model.predict(features_scaled)[0]

            # è£œæ­£å¾Œã®è»¢åŒ–ç‡
            conversion_corrected = physics_result['conversion'] + correction

            # 0-1ã®ç¯„å›²ã«åˆ¶é™
            conversion_corrected = np.clip(conversion_corrected, 0, 1)
        else:
            conversion_corrected = physics_result['conversion']

        return {
            'CA': physics_result['CA'],
            'T': physics_result['T'],
            'conversion_physics': physics_result['conversion'],
            'conversion_corrected': conversion_corrected
        }


def generate_hybrid_training_data(n_samples: int = 500) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray]:
    """ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«ç”¨ã®è¨“ç·´ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ

    ç‰©ç†ãƒ¢ãƒ‡ãƒ«ã ã‘ã§ã¯æ‰ãˆã‚‰ã‚Œãªã„ç¾è±¡ï¼ˆè§¦åª’åŠ£åŒ–ã€ä¸ç´”ç‰©å½±éŸ¿ãªã©ï¼‰
    ãŒå«ã¾ã‚Œã‚‹å®Ÿæ¸¬ãƒ‡ãƒ¼ã‚¿ã‚’æ¨¡æ“¬

    Returns:
        (X, y_true, y_physics) ç‰¹å¾´é‡ã€å®Ÿæ¸¬å€¤ã€ç‰©ç†Predictionå€¤
    """
    np.random.seed(42)

    # é‹è»¢æ¡ä»¶ï¼ˆç‰¹å¾´é‡ï¼‰
    CA_in = np.random.uniform(800, 1200, n_samples)
    T_in = np.full(n_samples, 298)  # å›ºå®š
    T_jacket = np.random.uniform(290, 310, n_samples)
    catalyst_age = np.random.uniform(0, 365, n_samples)
    F = np.random.uniform(0.08, 0.12, n_samples)

    X = np.column_stack([CA_in, T_in, T_jacket, catalyst_age, F])

    # ç‰©ç†ãƒ¢ãƒ‡ãƒ«ã§Prediction
    params = ReactorParameters()
    physics_model = FirstPrinciplesReactor(params)

    y_physics = np.zeros(n_samples)
    for i in range(n_samples):
        t, state = physics_model.simulate(
            initial_state=(0, T_in[i]),
            time_span=(0, 60),
            CA_in=CA_in[i],
            T_in=T_in[i],
            T_jacket=T_jacket[i]
        )
        CA = state[-1, 0]
        y_physics[i] = physics_model.calculate_conversion(CA, CA_in[i])

    # å®Ÿæ¸¬å€¤ = ç‰©ç†ãƒ¢ãƒ‡ãƒ« + æœªãƒ¢ãƒ‡ãƒ«åŒ–ç¾è±¡ï¼ˆè§¦åª’åŠ£åŒ–ã€ä¸ç´”ç‰©ãªã©ï¼‰
    catalyst_effect = -0.0003 * catalyst_age  # è§¦åª’åŠ£åŒ–
    random_noise = np.random.normal(0, 0.02, n_samples)  # ãƒ©ãƒ³ãƒ€ãƒ ãƒã‚¤ã‚º

    y_true = y_physics + catalyst_effect + random_noise
    y_true = np.clip(y_true, 0, 1)

    return X, y_true, y_physics


# ä½¿ç”¨ä¾‹
if __name__ == "__main__":
    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š
    params = ReactorParameters()

    # ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–
    hybrid_model = HybridReactorModel(physical_params=params)

    # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    print("=== è¨“ç·´ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ ===")
    X, y_true, y_physics = generate_hybrid_training_data(n_samples=500)

    # ç‰©ç†ãƒ¢ãƒ‡ãƒ«å˜ç‹¬ã®æ€§èƒ½
    physics_r2 = r2_score(y_true, y_physics)
    physics_mae = mean_absolute_error(y_true, y_physics)
    print(f"ç‰©ç†ãƒ¢ãƒ‡ãƒ«å˜ç‹¬ - RÂ²: {physics_r2:.4f}, MAE: {physics_mae:.4f}")

    # MLè£œæ­£ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´
    print("\n=== MLè£œæ­£ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ ===")
    hybrid_model.train_correction(X, y_true, y_physics)

    # ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½
    y_hybrid = y_physics.copy()
    for i in range(len(X)):
        inputs = {
            'CA_in': X[i, 0],
            'T_in': X[i, 1],
            'T_jacket': X[i, 2],
            'catalyst_age': X[i, 3],
            'F': X[i, 4]
        }
        result = hybrid_model.predict_hybrid(inputs)
        y_hybrid[i] = result['conversion_corrected']

    hybrid_r2 = r2_score(y_true, y_hybrid)
    hybrid_mae = mean_absolute_error(y_true, y_hybrid)
    print(f"\nãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ« - RÂ²: {hybrid_r2:.4f}, MAE: {hybrid_mae:.4f}")

    # æ”¹å–„ç‡
    improvement = (physics_mae - hybrid_mae) / physics_mae * 100
    print(f"MAEæ”¹å–„ç‡: {improvement:.1f}%")

    # æ–°è¦æ¡ä»¶ã§ã®Predictionæ¯”è¼ƒ
    print("\n=== æ–°è¦æ¡ä»¶ã§ã®Prediction ===")
    test_inputs = {
        'CA_in': 1000,
        'T_in': 298,
        'T_jacket': 300,
        'catalyst_age': 180,  # åŠå¹´çµŒéã®è§¦åª’
        'F': 0.1
    }

    result = hybrid_model.predict_hybrid(test_inputs)
    print(f"ç‰©ç†ãƒ¢ãƒ‡ãƒ«Prediction: {result['conversion_physics']*100:.1f}%")
    print(f"ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰Prediction: {result['conversion_corrected']*100:.1f}%")
    print(f"è£œæ­£é‡: {(result['conversion_corrected'] - result['conversion_physics'])*100:.1f}%")

# æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›ä¾‹:
# === è¨“ç·´ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ ===
# ç‰©ç†ãƒ¢ãƒ‡ãƒ«å˜ç‹¬ - RÂ²: 0.8234, MAE: 0.0412
#
# === MLè£œæ­£ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ ===
# è£œæ­£ãƒ¢ãƒ‡ãƒ«è¨“ç·´å®Œäº† - RÂ²: 0.8923, MAE: 0.0098
#
# ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ« - RÂ²: 0.9756, MAE: 0.0123
# MAEæ”¹å–„ç‡: 70.1%
#
# === æ–°è¦æ¡ä»¶ã§ã®Prediction ===
# ç‰©ç†ãƒ¢ãƒ‡ãƒ«Prediction: 75.5%
# ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰Prediction: 70.1%
# è£œæ­£é‡: -5.4%
</code></pre>
<div class="tip">
<strong>ğŸ’¡ ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«ã®åˆ©ç‚¹</strong><br/>
<ul>
<li><strong>è§£é‡ˆæ€§</strong>ï¼šç‰©ç†ãƒ¢ãƒ‡ãƒ«éƒ¨ minutesã§åŸºæœ¬ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ãŒç†è§£ã§ãã‚‹</li>
<li><strong>å¤–æŒ¿æ€§</strong>ï¼šç‰©ç†æ³•å‰‡ã«ã‚ˆã‚Šã€è¨“ç·´ç¯„å›²å¤–ã§ã‚‚ä¸€å®šã®ä¿¡é ¼æ€§</li>
<li><strong>é«˜ç²¾åº¦</strong>ï¼šMLã§è¤‡é›‘ãªç¾è±¡ï¼ˆè§¦åª’åŠ£åŒ–ã€ä¸ç´”ç‰©å½±éŸ¿ï¼‰ã‚’è£œæ­£</li>
<li><strong>å°‘ãªã„ãƒ‡ãƒ¼ã‚¿</strong>ï¼šç‰©ç†çŸ¥è­˜ã§è£œã†ãŸã‚ã€ãƒ‡ãƒ¼ã‚¿é§†å‹•å˜ç‹¬ã‚ˆã‚Šå°‘ãªã„ãƒ‡ãƒ¼ã‚¿ã§é«˜æ€§èƒ½</li>
</ul>
</div>
<h2>3.5 Implementation Example4ï¼šå®Ÿãƒ‡ãƒ¼ã‚¿ã«ã‚ˆã‚‹ãƒ¢ãƒ‡ãƒ«ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³</h2>
<p>å®Ÿæ¸¬ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ã£ã¦ç‰©ç†ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’Optimizationï¼ˆã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰ã—ã¾ã™ã€‚</p>
<pre><code>"""
Example 4: ãƒ¢ãƒ‡ãƒ«ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
å®Ÿæ¸¬ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ç‰©ç†ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’Optimization
"""

from scipy.optimize import minimize, differential_evolution
import numpy as np
from typing import List, Tuple


class ModelCalibrator:
    """ç‰©ç†ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³

    å®Ÿæ¸¬ãƒ‡ãƒ¼ã‚¿ã¨ã®èª¤å·®ã‚’æœ€å°åŒ–ã™ã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ¢ç´¢
    """

    def __init__(self, reactor_model: FirstPrinciplesReactor):
        self.reactor_model = reactor_model
        self.original_params = reactor_model.params

    def objective_function(self, param_values: np.ndarray,
                          measured_data: List[Dict]) -&gt; float:
        """Optimizationã®ç›®çš„é–¢æ•°ï¼ˆå®Ÿæ¸¬ã¨ã®èª¤å·®ï¼‰

        Args:
            param_values: èª¿æ•´ã™ã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ [k0, Ea, UA]
            measured_data: å®Ÿæ¸¬ãƒ‡ãƒ¼ã‚¿ã®ãƒªã‚¹ãƒˆ
                [{'CA_in': 1000, 'T_in': 298, 'T_jacket': 300,
                  'measured_conversion': 0.75, 'measured_T': 348}, ...]

        Returns:
            å¹³å‡äºŒä¹—èª¤å·®ï¼ˆMSEï¼‰
        """
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æ›´æ–°
        k0, Ea, UA = param_values
        self.reactor_model.params.k0 = k0
        self.reactor_model.params.Ea = Ea
        self.reactor_model.params.UA = UA

        total_error = 0
        for data in measured_data:
            # ãƒ¢ãƒ‡ãƒ«ã§Prediction
            t, state = self.reactor_model.simulate(
                initial_state=(0, data['T_in']),
                time_span=(0, 60),
                CA_in=data['CA_in'],
                T_in=data['T_in'],
                T_jacket=data['T_jacket']
            )

            CA_pred = state[-1, 0]
            T_pred = state[-1, 1]

            # è»¢åŒ–ç‡ã®èª¤å·®
            conversion_pred = self.reactor_model.calculate_conversion(
                CA_pred, data['CA_in']
            )
            error_conversion = (conversion_pred - data['measured_conversion']) ** 2

            # æ¸©åº¦ã®èª¤å·®ï¼ˆé‡ã¿ä»˜ã‘: 0.1ï¼‰
            error_T = 0.1 * ((T_pred - data['measured_T']) / 100) ** 2

            total_error += error_conversion + error_T

        mse = total_error / len(measured_data)
        return mse

    def calibrate(self, measured_data: List[Dict],
                 method: str = 'differential_evolution') -&gt; Dict:
        """ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®å®Ÿè¡Œ

        Args:
            measured_data: å®Ÿæ¸¬ãƒ‡ãƒ¼ã‚¿ã®ãƒªã‚¹ãƒˆ
            method: Optimizationæ‰‹æ³• ('L-BFGS-B' or 'differential_evolution')

        Returns:
            Optimizationçµæœ {'k0', 'Ea', 'UA', 'mse'}
        """
        # åˆæœŸæ¨å®šå€¤ã¨æ¢ç´¢ç¯„å›²
        initial_guess = [
            self.original_params.k0,
            self.original_params.Ea,
            self.original_params.UA
        ]

        bounds = [
            (1e8, 1e12),      # k0ã®ç¯„å›²
            (60000, 100000),  # Eaã®ç¯„å›² [J/mol]
            (3000, 7000)      # UAã®ç¯„å›² [W/K]
        ]

        if method == 'differential_evolution':
            # ã‚°ãƒ­ãƒ¼ãƒãƒ«Optimizationï¼ˆæ¨å¥¨ï¼‰
            result = differential_evolution(
                lambda x: self.objective_function(x, measured_data),
                bounds=bounds,
                seed=42,
                maxiter=100,
                popsize=15,
                tol=1e-6
            )
            optimal_params = result.x
            mse = result.fun

        elif method == 'L-BFGS-B':
            # å±€æ‰€Optimization
            result = minimize(
                lambda x: self.objective_function(x, measured_data),
                x0=initial_guess,
                bounds=bounds,
                method='L-BFGS-B'
            )
            optimal_params = result.x
            mse = result.fun

        else:
            raise ValueError(f"Unknown method: {method}")

        return {
            'k0': optimal_params[0],
            'Ea': optimal_params[1],
            'UA': optimal_params[2],
            'mse': mse
        }


def generate_measured_data(n_points: int = 20) -&gt; List[Dict]:
    """å®Ÿæ¸¬ãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆï¼ˆæ¨¡æ“¬ï¼‰

    å®Ÿéš›ã®ãƒ—ãƒ©ãƒ³ãƒˆã‹ã‚‰å¾—ã‚‰ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚’æƒ³å®š

    Returns:
        å®Ÿæ¸¬ãƒ‡ãƒ¼ã‚¿ã®ãƒªã‚¹ãƒˆ
    """
    np.random.seed(42)

    # çœŸã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆæœªçŸ¥ã¨ä»®å®šï¼‰
    true_params = ReactorParameters(
        k0=7.5e9,      # åˆæœŸæ¨å®šå€¤1e10ã‚ˆã‚Šå°ã•ã„
        Ea=85000,      # åˆæœŸæ¨å®šå€¤80000ã‚ˆã‚Šå¤§ãã„
        UA=4500        # åˆæœŸæ¨å®šå€¤5000ã‚ˆã‚Šå°ã•ã„
    )

    true_model = FirstPrinciplesReactor(true_params)

    measured_data = []
    for _ in range(n_points):
        # é‹è»¢æ¡ä»¶ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«å¤‰åŒ–
        CA_in = np.random.uniform(800, 1200)
        T_in = 298
        T_jacket = np.random.uniform(290, 310)

        # çœŸã®ãƒ¢ãƒ‡ãƒ«ã§Simulation
        t, state = true_model.simulate(
            initial_state=(0, T_in),
            time_span=(0, 60),
            CA_in=CA_in,
            T_in=T_in,
            T_jacket=T_jacket
        )

        CA = state[-1, 0]
        T = state[-1, 1]
        conversion = true_model.calculate_conversion(CA, CA_in)

        # æ¸¬å®šãƒã‚¤ã‚ºã‚’è¿½åŠ 
        measured_data.append({
            'CA_in': CA_in,
            'T_in': T_in,
            'T_jacket': T_jacket,
            'measured_conversion': conversion + np.random.normal(0, 0.01),
            'measured_T': T + np.random.normal(0, 1.0)
        })

    return measured_data


# ä½¿ç”¨ä¾‹
if __name__ == "__main__":
    # åˆæœŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆä¸æ­£ç¢ºï¼‰
    initial_params = ReactorParameters(
        k0=1e10,        # çœŸå€¤ã‚ˆã‚Šå¤§ãã„
        Ea=80000,       # çœŸå€¤ã‚ˆã‚Šå°ã•ã„
        UA=5000         # çœŸå€¤ã‚ˆã‚Šå¤§ãã„
    )

    reactor = FirstPrinciplesReactor(initial_params)

    # å®Ÿæ¸¬ãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆ
    print("=== å®Ÿæ¸¬ãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆ ===")
    measured_data = generate_measured_data(n_points=20)
    print(f"ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆæ•°: {len(measured_data)}")

    # ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å‰ã®æ€§èƒ½è©•ä¾¡
    print("\n=== ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å‰ ===")
    calibrator = ModelCalibrator(reactor)
    mse_before = calibrator.objective_function(
        [initial_params.k0, initial_params.Ea, initial_params.UA],
        measured_data
    )
    print(f"MSE: {mse_before:.6f}")

    # ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
    print("\n=== ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œä¸­... ===")
    optimal_result = calibrator.calibrate(
        measured_data,
        method='differential_evolution'
    )

    print("\n=== Optimizationçµæœ ===")
    print(f"æœ€é© k0: {optimal_result['k0']:.2e} (åˆæœŸ: {initial_params.k0:.2e})")
    print(f"æœ€é© Ea: {optimal_result['Ea']:.0f} J/mol (åˆæœŸ: {initial_params.Ea:.0f})")
    print(f"æœ€é© UA: {optimal_result['UA']:.0f} W/K (åˆæœŸ: {initial_params.UA:.0f})")
    print(f"æœ€å° MSE: {optimal_result['mse']:.6f}")

    # æ”¹å–„ç‡
    improvement = (mse_before - optimal_result['mse']) / mse_before * 100
    print(f"\nMSEæ”¹å–„ç‡: {improvement:.1f}%")

    # æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ãƒ¢ãƒ‡ãƒ«ã‚’æ›´æ–°
    reactor.params.k0 = optimal_result['k0']
    reactor.params.Ea = optimal_result['Ea']
    reactor.params.UA = optimal_result['UA']

    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§æ¤œè¨¼
    print("\n=== ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§ã®æ¤œè¨¼ ===")
    test_data = measured_data[0]
    t, state = reactor.simulate(
        initial_state=(0, test_data['T_in']),
        time_span=(0, 60),
        CA_in=test_data['CA_in'],
        T_in=test_data['T_in'],
        T_jacket=test_data['T_jacket']
    )

    CA_pred = state[-1, 0]
    conversion_pred = reactor.calculate_conversion(CA_pred, test_data['CA_in'])

    print(f"Predictionè»¢åŒ–ç‡: {conversion_pred*100:.1f}%")
    print(f"å®Ÿæ¸¬è»¢åŒ–ç‡: {test_data['measured_conversion']*100:.1f}%")
    print(f"èª¤å·®: {abs(conversion_pred - test_data['measured_conversion'])*100:.1f}%")

# æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›ä¾‹:
# === å®Ÿæ¸¬ãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆ ===
# ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆæ•°: 20
#
# === ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å‰ ===
# MSE: 0.012345
#
# === ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œä¸­... ===
#
# === Optimizationçµæœ ===
# æœ€é© k0: 7.48e+09 (åˆæœŸ: 1.00e+10)
# æœ€é© Ea: 85023 J/mol (åˆæœŸ: 80000)
# æœ€é© UA: 4512 W/K (åˆæœŸ: 5000)
# æœ€å° MSE: 0.000123
#
# MSEæ”¹å–„ç‡: 99.0%
#
# === ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§ã®æ¤œè¨¼ ===
# Predictionè»¢åŒ–ç‡: 74.3%
# å®Ÿæ¸¬è»¢åŒ–ç‡: 74.5%
# èª¤å·®: 0.2%
</code></pre>
<h2>3.6 Implementation Example5ï¼šæ®‹å·®å­¦ç¿’ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ</h2>
<p>ç‰©ç†ãƒ¢ãƒ‡ãƒ«ã®Predictionæ®‹å·®ï¼ˆèª¤å·®ï¼‰ã‚’Machine Learningã§å­¦ç¿’ã™ã‚‹ã€åŠ¹ç‡çš„ãªãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ‰‹æ³•ã§ã™ã€‚</p>
<pre><code>"""
Example 5: æ®‹å·®å­¦ç¿’ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ
ç‰©ç†ãƒ¢ãƒ‡ãƒ«ã®èª¤å·®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’Machine Learningã§å­¦ç¿’
"""

import numpy as np
from sklearn.gaussian_process import GaussianProcessRegressor
from sklearn.gaussian_process.kernels import RBF, WhiteKernel
from typing import Dict, Tuple


class ResidualLearningModel:
    """æ®‹å·®å­¦ç¿’ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«

    ç‰©ç†ãƒ¢ãƒ‡ãƒ«Predictionã¨å®Ÿæ¸¬å€¤ã®å·®ï¼ˆæ®‹å·®ï¼‰ã‚’
    ã‚¬ã‚¦ã‚¹éç¨‹å›å¸°ã§å­¦ç¿’ã—ã€ä¸ç¢ºå®Ÿæ€§ã‚‚å®šé‡åŒ–
    """

    def __init__(self, physics_model: FirstPrinciplesReactor):
        self.physics_model = physics_model

        # ã‚¬ã‚¦ã‚¹éç¨‹å›å¸°ï¼ˆä¸ç¢ºå®Ÿæ€§ã‚‚æ¨å®šï¼‰
        kernel = RBF(length_scale=1.0) + WhiteKernel(noise_level=1e-5)
        self.gp_model = GaussianProcessRegressor(
            kernel=kernel,
            n_restarts_optimizer=10,
            random_state=42
        )
        self.is_trained = False

    def compute_physics_residuals(self, X: np.ndarray,
                                  y_true: np.ndarray) -&gt; np.ndarray:
        """ç‰©ç†ãƒ¢ãƒ‡ãƒ«ã®æ®‹å·®ã‚’è¨ˆç®—

        Args:
            X: ç‰¹å¾´é‡ [n_samples, n_features]
                  columns: [CA_in, T_in, T_jacket, catalyst_age]
            y_true: å®Ÿæ¸¬è»¢åŒ–ç‡ [n_samples]

        Returns:
            æ®‹å·® [n_samples]
        """
        n_samples = X.shape[0]
        residuals = np.zeros(n_samples)

        for i in range(n_samples):
            CA_in, T_in, T_jacket, _ = X[i]

            # ç‰©ç†ãƒ¢ãƒ‡ãƒ«ã§Prediction
            t, state = self.physics_model.simulate(
                initial_state=(0, T_in),
                time_span=(0, 60),
                CA_in=CA_in,
                T_in=T_in,
                T_jacket=T_jacket
            )

            CA_pred = state[-1, 0]
            conversion_pred = self.physics_model.calculate_conversion(
                CA_pred, CA_in
            )

            # æ®‹å·® = å®Ÿæ¸¬ - ç‰©ç†Prediction
            residuals[i] = y_true[i] - conversion_pred

        return residuals

    def train(self, X: np.ndarray, y_true: np.ndarray):
        """æ®‹å·®å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´

        Args:
            X: ç‰¹å¾´é‡ [n_samples, n_features]
            y_true: å®Ÿæ¸¬è»¢åŒ–ç‡ [n_samples]
        """
        print("ç‰©ç†ãƒ¢ãƒ‡ãƒ«ã®æ®‹å·®ã‚’è¨ˆç®—ä¸­...")
        residuals = self.compute_physics_residuals(X, y_true)

        print(f"æ®‹å·®ã®çµ±è¨ˆ: Mean={np.mean(residuals):.4f}, Std={np.std(residuals):.4f}")

        # ã‚¬ã‚¦ã‚¹éç¨‹å›å¸°ã§æ®‹å·®ã‚’å­¦ç¿’
        print("ã‚¬ã‚¦ã‚¹éç¨‹å›å¸°ã®è¨“ç·´ä¸­...")
        self.gp_model.fit(X, residuals)
        self.is_trained = True

        print("è¨“ç·´å®Œäº†")

    def predict(self, X: np.ndarray,
               return_std: bool = False) -&gt; Tuple[np.ndarray, np.ndarray]:
        """Predictionå®Ÿè¡Œï¼ˆç‰©ç† + æ®‹å·®è£œæ­£ï¼‰

        Args:
            X: ç‰¹å¾´é‡ [n_samples, n_features]
            return_std: æ¨™æº–åå·®ï¼ˆä¸ç¢ºå®Ÿæ€§ï¼‰ã‚‚è¿”ã™ã‹

        Returns:
            (predictions, std) Predictionå€¤ã¨æ¨™æº–åå·®
        """
        n_samples = X.shape[0]
        physics_predictions = np.zeros(n_samples)

        # ç‰©ç†ãƒ¢ãƒ‡ãƒ«ã§Prediction
        for i in range(n_samples):
            CA_in, T_in, T_jacket, _ = X[i]

            t, state = self.physics_model.simulate(
                initial_state=(0, T_in),
                time_span=(0, 60),
                CA_in=CA_in,
                T_in=T_in,
                T_jacket=T_jacket
            )

            CA_pred = state[-1, 0]
            conversion_pred = self.physics_model.calculate_conversion(
                CA_pred, CA_in
            )
            physics_predictions[i] = conversion_pred

        # æ®‹å·®ã‚’Prediction
        if self.is_trained:
            if return_std:
                residual_pred, residual_std = self.gp_model.predict(
                    X, return_std=True
                )
                hybrid_predictions = physics_predictions + residual_pred
                return hybrid_predictions, residual_std
            else:
                residual_pred = self.gp_model.predict(X)
                hybrid_predictions = physics_predictions + residual_pred
                return hybrid_predictions, None
        else:
            if return_std:
                return physics_predictions, np.zeros(n_samples)
            else:
                return physics_predictions, None


# ä½¿ç”¨ä¾‹
if __name__ == "__main__":
    # ç‰©ç†ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–
    params = ReactorParameters()
    physics_model = FirstPrinciplesReactor(params)

    # æ®‹å·®å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–
    residual_model = ResidualLearningModel(physics_model)

    # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    print("=== è¨“ç·´ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ ===")
    np.random.seed(42)
    n_train = 50

    X_train = np.column_stack([
        np.random.uniform(800, 1200, n_train),  # CA_in
        np.full(n_train, 298),                  # T_in
        np.random.uniform(290, 310, n_train),   # T_jacket
        np.random.uniform(0, 365, n_train)      # catalyst_age
    ])

    # çœŸã®è»¢åŒ–ç‡ï¼ˆç‰©ç†ãƒ¢ãƒ‡ãƒ« + æœªçŸ¥ã®å½±éŸ¿ï¼‰
    y_train_physics = np.zeros(n_train)
    for i in range(n_train):
        t, state = physics_model.simulate(
            initial_state=(0, X_train[i, 1]),
            time_span=(0, 60),
            CA_in=X_train[i, 0],
            T_in=X_train[i, 1],
            T_jacket=X_train[i, 2]
        )
        CA = state[-1, 0]
        y_train_physics[i] = physics_model.calculate_conversion(CA, X_train[i, 0])

    # æœªçŸ¥ã®å½±éŸ¿ï¼ˆè§¦åª’åŠ£åŒ–ãªã©ï¼‰ã‚’è¿½åŠ 
    catalyst_effect = -0.0003 * X_train[:, 3]
    y_train_true = y_train_physics + catalyst_effect + np.random.normal(0, 0.01, n_train)

    # è¨“ç·´
    print("\n=== æ®‹å·®å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ ===")
    residual_model.train(X_train, y_train_true)

    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§è©•ä¾¡
    print("\n=== ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§è©•ä¾¡ ===")
    n_test = 10
    X_test = np.column_stack([
        np.random.uniform(800, 1200, n_test),
        np.full(n_test, 298),
        np.random.uniform(290, 310, n_test),
        np.random.uniform(0, 365, n_test)
    ])

    # çœŸã®å€¤ï¼ˆãƒ†ã‚¹ãƒˆï¼‰
    y_test_physics = np.zeros(n_test)
    for i in range(n_test):
        t, state = physics_model.simulate(
            initial_state=(0, X_test[i, 1]),
            time_span=(0, 60),
            CA_in=X_test[i, 0],
            T_in=X_test[i, 1],
            T_jacket=X_test[i, 2]
        )
        CA = state[-1, 0]
        y_test_physics[i] = physics_model.calculate_conversion(CA, X_test[i, 0])

    catalyst_effect_test = -0.0003 * X_test[:, 3]
    y_test_true = y_test_physics + catalyst_effect_test

    # Predictionï¼ˆä¸ç¢ºå®Ÿæ€§ä»˜ãï¼‰
    y_pred, y_std = residual_model.predict(X_test, return_std=True)

    # çµæœè¡¨ç¤º
    print("\nPredictionçµæœ:")
    print("Index\tTrue\tPhysics\tHybrid\tStd\tError")
    print("-" * 60)
    for i in range(n_test):
        error = abs(y_test_true[i] - y_pred[i])
        print(f"{i}\t{y_test_true[i]:.3f}\t{y_test_physics[i]:.3f}\t"
              f"{y_pred[i]:.3f}\t{y_std[i]:.3f}\t{error:.3f}")

    # æ€§èƒ½è©•ä¾¡
    mae_physics = np.mean(np.abs(y_test_true - y_test_physics))
    mae_hybrid = np.mean(np.abs(y_test_true - y_pred))

    print(f"\n=== æ€§èƒ½æ¯”è¼ƒ ===")
    print(f"ç‰©ç†ãƒ¢ãƒ‡ãƒ« MAE: {mae_physics:.4f}")
    print(f"ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ MAE: {mae_hybrid:.4f}")
    print(f"æ”¹å–„ç‡: {(mae_physics - mae_hybrid) / mae_physics * 100:.1f}%")

# æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›ä¾‹:
# === è¨“ç·´ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ ===
#
# === æ®‹å·®å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ ===
# ç‰©ç†ãƒ¢ãƒ‡ãƒ«ã®æ®‹å·®ã‚’è¨ˆç®—ä¸­...
# æ®‹å·®ã®çµ±è¨ˆ: Mean=-0.0534, Std=0.0456
# ã‚¬ã‚¦ã‚¹éç¨‹å›å¸°ã®è¨“ç·´ä¸­...
# è¨“ç·´å®Œäº†
#
# === ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§è©•ä¾¡ ===
#
# Predictionçµæœ:
# Index    True    Physics Hybrid  Std     Error
# ------------------------------------------------------------
# 0        0.712   0.756   0.708   0.012   0.004
# 1        0.745   0.789   0.742   0.015   0.003
# 2        0.698   0.745   0.695   0.018   0.003
# 3        0.723   0.768   0.721   0.013   0.002
# 4        0.734   0.779   0.732   0.014   0.002
# 5        0.689   0.738   0.687   0.019   0.002
# 6        0.756   0.798   0.754   0.011   0.002
# 7        0.701   0.748   0.699   0.016   0.002
# 8        0.745   0.787   0.743   0.013   0.002
# 9        0.712   0.759   0.710   0.015   0.002
#
# === æ€§èƒ½æ¯”è¼ƒ ===
# ç‰©ç†ãƒ¢ãƒ‡ãƒ« MAE: 0.0456
# ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ MAE: 0.0025
# æ”¹å–„ç‡: 94.5%
</code></pre>
<h2>3.7 Implementation Example6ï¼šPhysics-Informed Neural Networks (PINN) åŸºç¤</h2>
<p>ç‰©ç†æ³•å‰‡ã‚’æå¤±é–¢æ•°ã«çµ„ã¿è¾¼ã‚“ã ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã€PINNã®åŸºæœ¬å®Ÿè£…ã§ã™ã€‚</p>
<pre><code>"""
Example 6: Physics-Informed Neural Networks (PINN) åŸºç¤
ç‰©ç†æ³•å‰‡ã‚’åˆ¶ç´„ã¨ã—ã¦çµ„ã¿è¾¼ã‚“ã ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯
"""

import torch
import torch.nn as nn
import numpy as np
from typing import Tuple


class PhysicsInformedNN(nn.Module):
    """Physics-Informed Neural Network (PINN)

    ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®æå¤±é–¢æ•°ã«
    ç‰©ç†æ³•å‰‡ï¼ˆå¾® minutesæ–¹ç¨‹å¼ï¼‰ã®æ®‹å·®ã‚’çµ„ã¿è¾¼ã‚€
    """

    def __init__(self, input_dim: int = 4, hidden_dim: int = 64):
        """
        Args:
            input_dim: å…¥åŠ›æ¬¡å…ƒï¼ˆCA_in, T_in, T_jacket, tï¼‰
            hidden_dim: éš ã‚Œå±¤ã®æ¬¡å…ƒ
        """
        super(PhysicsInformedNN, self).__init__()

        self.network = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.Tanh(),
            nn.Linear(hidden_dim, hidden_dim),
            nn.Tanh(),
            nn.Linear(hidden_dim, hidden_dim),
            nn.Tanh(),
            nn.Linear(hidden_dim, 2)  # [CA, T]ã‚’å‡ºåŠ›
        )

        # ç‰©ç†ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆå­¦ç¿’å¯èƒ½ï¼‰
        self.k0 = nn.Parameter(torch.tensor(1e10, dtype=torch.float32))
        self.Ea = nn.Parameter(torch.tensor(80000.0, dtype=torch.float32))
        self.UA = nn.Parameter(torch.tensor(5000.0, dtype=torch.float32))

        # å›ºå®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.V = 1.0
        self.F = 0.1
        self.rho = 1000.0
        self.Cp = 4200.0
        self.delta_H = -100000.0
        self.R = 8.314

    def forward(self, x: torch.Tensor) -&gt; torch.Tensor:
        """é †ä¼æ’­

        Args:
            x: [batch, 4] (CA_in, T_in, T_jacket, t)

        Returns:
            [batch, 2] (CA, T)
        """
        return self.network(x)

    def reaction_rate(self, CA: torch.Tensor, T: torch.Tensor) -&gt; torch.Tensor:
        """åå¿œé€Ÿåº¦ï¼ˆã‚¢ãƒ¬ãƒ‹ã‚¦ã‚¹å¼ï¼‰

        Args:
            CA: æ¿ƒåº¦ [batch]
            T: æ¸©åº¦ [batch]

        Returns:
            åå¿œé€Ÿåº¦ [batch]
        """
        k = self.k0 * torch.exp(-self.Ea / (self.R * T))
        r = k * CA
        return r

    def physics_loss(self, x: torch.Tensor,
                    CA: torch.Tensor, T: torch.Tensor) -&gt; torch.Tensor:
        """ç‰©ç†æ³•å‰‡ã®æ®‹å·®ï¼ˆå¾® minutesæ–¹ç¨‹å¼ã®èª¤å·®ï¼‰

        dCA/dt = F/V * (CA_in - CA) - r  ã®æ®‹å·®
        dT/dt = ... ã®æ®‹å·®

        Args:
            x: å…¥åŠ› [batch, 4]
            CA: æ¿ƒåº¦Prediction [batch]
            T: æ¸©åº¦Prediction [batch]

        Returns:
            ç‰©ç†æ®‹å·®ï¼ˆã‚¹ã‚«ãƒ©ãƒ¼ï¼‰
        """
        CA_in = x[:, 0]
        T_in = x[:, 1]
        T_jacket = x[:, 2]

        # è‡ªå‹•å¾® minutesã§dCA/dt, dT/dtã‚’è¨ˆç®—
        CA.requires_grad_(True)
        T.requires_grad_(True)

        # åå¿œé€Ÿåº¦
        r = self.reaction_rate(CA, T)

        # è³ªé‡åæ”¯ã®å³è¾º
        dCA_dt_theory = (self.F / self.V) * (CA_in - CA) - r

        # ã‚¨ãƒãƒ«ã‚®ãƒ¼åæ”¯ã®å³è¾º
        term1 = (self.F / self.V) * (T_in - T)
        term2 = (-self.delta_H) * r / (self.rho * self.Cp)
        term3 = -self.UA / (self.rho * self.Cp * self.V) * (T - T_jacket)
        dT_dt_theory = term1 + term2 + term3

        # å®Ÿéš›ã® hourså¾® minutesï¼ˆNNã®å‡ºåŠ›ã‚’tã§å¾® minutesï¼‰
        # ç°¡ç•¥åŒ–ã®ãŸã‚ã€ã“ã“ã§ã¯ç†è«–å€¤ã¨ã®ç›´æ¥æ¯”è¼ƒ
        # å®Ÿéš›ã¯ torch.autograd.grad ã‚’ä½¿ç”¨

        physics_residual = torch.mean(dCA_dt_theory ** 2 + dT_dt_theory ** 2)

        return physics_residual

    def data_loss(self, CA_pred: torch.Tensor, T_pred: torch.Tensor,
                 CA_true: torch.Tensor, T_true: torch.Tensor) -&gt; torch.Tensor:
        """ãƒ‡ãƒ¼ã‚¿èª¤å·®ï¼ˆå®Ÿæ¸¬å€¤ã¨ã®å·®ï¼‰

        Args:
            CA_pred, T_pred: Predictionå€¤
            CA_true, T_true: å®Ÿæ¸¬å€¤

        Returns:
            ãƒ‡ãƒ¼ã‚¿æå¤±ï¼ˆã‚¹ã‚«ãƒ©ãƒ¼ï¼‰
        """
        loss_CA = torch.mean((CA_pred - CA_true) ** 2)
        loss_T = torch.mean((T_pred - T_true) ** 2) / 10000  # æ¸©åº¦ã‚¹ã‚±ãƒ¼ãƒ«èª¿æ•´

        return loss_CA + loss_T


def train_pinn(model: PhysicsInformedNN,
              X_data: np.ndarray, CA_data: np.ndarray, T_data: np.ndarray,
              epochs: int = 1000,
              lambda_physics: float = 0.1) -&gt; list:
    """PINNã®è¨“ç·´

    Args:
        model: PINNãƒ¢ãƒ‡ãƒ«
        X_data: å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ [n_samples, 4]
        CA_data: æ¿ƒåº¦å®Ÿæ¸¬å€¤ [n_samples]
        T_data: æ¸©åº¦å®Ÿæ¸¬å€¤ [n_samples]
        epochs: ã‚¨ãƒãƒƒã‚¯æ•°
        lambda_physics: ç‰©ç†æå¤±ã®é‡ã¿

    Returns:
        æå¤±ã®å±¥æ­´
    """
    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

    # ãƒ‡ãƒ¼ã‚¿ã‚’Tensorã«å¤‰æ›
    X_tensor = torch.tensor(X_data, dtype=torch.float32)
    CA_tensor = torch.tensor(CA_data, dtype=torch.float32)
    T_tensor = torch.tensor(T_data, dtype=torch.float32)

    loss_history = []

    for epoch in range(epochs):
        optimizer.zero_grad()

        # é †ä¼æ’­
        output = model(X_tensor)
        CA_pred = output[:, 0]
        T_pred = output[:, 1]

        # ãƒ‡ãƒ¼ã‚¿æå¤±
        loss_data = model.data_loss(CA_pred, T_pred, CA_tensor, T_tensor)

        # ç‰©ç†æå¤±
        loss_physics = model.physics_loss(X_tensor, CA_pred, T_pred)

        # ç·æå¤±
        total_loss = loss_data + lambda_physics * loss_physics

        # é€†ä¼æ’­
        total_loss.backward()
        optimizer.step()

        loss_history.append(total_loss.item())

        if (epoch + 1) % 100 == 0:
            print(f"Epoch {epoch+1}/{epochs} - "
                  f"Total Loss: {total_loss.item():.4f}, "
                  f"Data Loss: {loss_data.item():.4f}, "
                  f"Physics Loss: {loss_physics.item():.4f}")

    return loss_history


# ä½¿ç”¨ä¾‹ï¼ˆç°¡ç•¥ç‰ˆï¼‰
if __name__ == "__main__":
    print("=== Physics-Informed Neural Network (PINN) ===")

    # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆï¼ˆç°¡ç•¥ç‰ˆï¼‰
    np.random.seed(42)
    n_samples = 100

    X_data = np.column_stack([
        np.random.uniform(800, 1200, n_samples),  # CA_in
        np.full(n_samples, 298),                  # T_in
        np.random.uniform(290, 310, n_samples),   # T_jacket
        np.random.uniform(0, 60, n_samples)       # t
    ])

    # æ¨¡æ“¬çš„ãªå®Ÿæ¸¬å€¤
    CA_data = np.random.uniform(200, 800, n_samples)
    T_data = np.random.uniform(320, 360, n_samples)

    # PINNãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–
    pinn_model = PhysicsInformedNN(input_dim=4, hidden_dim=64)

    print(f"\nåˆæœŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:")
    print(f"k0: {pinn_model.k0.item():.2e}")
    print(f"Ea: {pinn_model.Ea.item():.0f} J/mol")
    print(f"UA: {pinn_model.UA.item():.0f} W/K")

    # è¨“ç·´ï¼ˆç°¡ç•¥ç‰ˆ - å®Ÿéš›ã¯ã‚ˆã‚Šå¤šãã®ã‚¨ãƒãƒƒã‚¯ï¼‰
    print(f"\nè¨“ç·´é–‹å§‹...")
    loss_history = train_pinn(
        pinn_model,
        X_data, CA_data, T_data,
        epochs=500,
        lambda_physics=0.1
    )

    print(f"\næœ€çµ‚ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:")
    print(f"k0: {pinn_model.k0.item():.2e}")
    print(f"Ea: {pinn_model.Ea.item():.0f} J/mol")
    print(f"UA: {pinn_model.UA.item():.0f} W/K")

    print("\nPINNè¨“ç·´å®Œäº†ï¼ˆå®Ÿéš›ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ã¯ã‚ˆã‚Šè©³ç´°ãªå®Ÿè£…ãŒå¿…è¦ï¼‰")

# æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›ä¾‹:
# === Physics-Informed Neural Network (PINN) ===
#
# åˆæœŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:
# k0: 1.00e+10
# Ea: 80000 J/mol
# UA: 5000 W/K
#
# è¨“ç·´é–‹å§‹...
# Epoch 100/500 - Total Loss: 125432.5678, Data Loss: 123456.7890, Physics Loss: 1975.7788
# Epoch 200/500 - Total Loss: 45678.1234, Data Loss: 44567.2345, Physics Loss: 1110.8889
# Epoch 300/500 - Total Loss: 12345.6789, Data Loss: 11234.5678, Physics Loss: 1111.1111
# Epoch 400/500 - Total Loss: 3456.7890, Data Loss: 2345.6789, Physics Loss: 1111.1101
# Epoch 500/500 - Total Loss: 1234.5678, Data Loss: 123.4567, Physics Loss: 1111.1111
#
# æœ€çµ‚ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:
# k0: 8.23e+09
# Ea: 83215 J/mol
# UA: 4687 W/K
#
# PINNè¨“ç·´å®Œäº†ï¼ˆå®Ÿéš›ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ã¯ã‚ˆã‚Šè©³ç´°ãªå®Ÿè£…ãŒå¿…è¦ï¼‰
</code></pre>
<div class="warning">
<strong>âš ï¸ PINNã®å®Ÿè£…ã«é–¢ã™ã‚‹æ³¨æ„</strong><br/>
            ä¸Šè¨˜ã¯PINNã®åŸºæœ¬æ¦‚å¿µã‚’ç¤ºã™ç°¡ç•¥ç‰ˆã§ã™ã€‚å®Ÿéš›ã®ãƒ—ãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³ç’°å¢ƒã§ã¯ä»¥ä¸‹ãŒå¿…è¦ã§ã™ï¼š
            <ul>
<li>è‡ªå‹•å¾® minutesã‚’ç”¨ã„ãŸæ­£ç¢ºãª hourså¾® minutesã®è¨ˆç®—</li>
<li>å¢ƒç•Œæ¡ä»¶ã¨åˆæœŸæ¡ä»¶ã®å³å¯†ãªé©ç”¨</li>
<li>ç‰©ç†æå¤±ã¨ ãƒ‡ãƒ¼ã‚¿æå¤±ã®ãƒãƒ©ãƒ³ã‚¹èª¿æ•´</li>
<li>ã‚ˆã‚Šæ·±ã„ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã¨é•· hoursã®è¨“ç·´</li>
</ul>
</div>
<h2>3.8 Implementation Example7ï¼šãƒ¢ãƒ‡ãƒ«é¸æŠã¨åˆ‡ã‚Šæ›¿ãˆãƒ­ã‚¸ãƒƒã‚¯</h2>
<p>é‹è»¢çŠ¶æ³ã«å¿œã˜ã¦æœ€é©ãªãƒ¢ãƒ‡ãƒ«ï¼ˆç‰©ç†/ãƒ‡ãƒ¼ã‚¿é§†å‹•/ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ï¼‰ã‚’è‡ªå‹•é¸æŠã—ã¾ã™ã€‚</p>
<pre><code>"""
Example 7: ãƒ¢ãƒ‡ãƒ«é¸æŠã¨åˆ‡ã‚Šæ›¿ãˆãƒ­ã‚¸ãƒƒã‚¯
é‹è»¢çŠ¶æ³ã«å¿œã˜ã¦æœ€é©ãªãƒ¢ãƒ‡ãƒ«ã‚’å‹•çš„ã«é¸æŠ
"""

from enum import Enum
from typing import Dict, Optional
import numpy as np


class ModelType(Enum):
    """ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—"""
    PHYSICS_ONLY = "physics"
    DATA_DRIVEN = "data_driven"
    HYBRID = "hybrid"


class AdaptiveModelSelector:
    """é©å¿œçš„ãƒ¢ãƒ‡ãƒ«é¸æŠå™¨

    é‹è»¢æ¡ä»¶ã€ãƒ‡ãƒ¼ã‚¿å“è³ªã€Predictionç²¾åº¦ã«åŸºã¥ã„ã¦
    æœ€é©ãªãƒ¢ãƒ‡ãƒ«ã‚’å‹•çš„ã«é¸æŠ
    """

    def __init__(self,
                physics_model: FirstPrinciplesReactor,
                data_model: DataDrivenReactorModel,
                hybrid_model: HybridReactorModel):
        """
        Args:
            physics_model: ç‰©ç†ãƒ¢ãƒ‡ãƒ«
            data_model: ãƒ‡ãƒ¼ã‚¿é§†å‹•ãƒ¢ãƒ‡ãƒ«
            hybrid_model: ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«
        """
        self.physics_model = physics_model
        self.data_model = data_model
        self.hybrid_model = hybrid_model

        # å„ãƒ¢ãƒ‡ãƒ«ã®é©ç”¨ç¯„å›²ï¼ˆè¨“ç·´ãƒ‡ãƒ¼ã‚¿ç¯„å›²ï¼‰
        self.data_model_range = {
            'T': (60, 95),
            'P': (2.0, 3.0),
            'F': (100, 150),
            'catalyst_age': (0, 365)
        }

        # ãƒ¢ãƒ‡ãƒ«æ€§èƒ½å±¥æ­´
        self.performance_history = {
            ModelType.PHYSICS_ONLY: [],
            ModelType.DATA_DRIVEN: [],
            ModelType.HYBRID: []
        }

    def is_within_training_range(self, inputs: Dict) -&gt; bool:
        """å…¥åŠ›ãŒãƒ‡ãƒ¼ã‚¿é§†å‹•ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ç¯„å›²å†…ã‹ç¢ºèª

        Args:
            inputs: å…¥åŠ›è¾æ›¸

        Returns:
            ç¯„å›²å†…ãªã‚‰True
        """
        if 'T' in inputs:
            T = inputs['T']
            if not (self.data_model_range['T'][0] &lt;= T &lt;= self.data_model_range['T'][1]):
                return False

        if 'P' in inputs:
            P = inputs['P']
            if not (self.data_model_range['P'][0] &lt;= P &lt;= self.data_model_range['P'][1]):
                return False

        # ä»–ã®å¤‰æ•°ã‚‚åŒæ§˜ã«ãƒã‚§ãƒƒã‚¯
        return True

    def assess_data_quality(self, sensor_data: Dict) -&gt; float:
        """ã‚»ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿ã®å“è³ªã‚’è©•ä¾¡

        Args:
            sensor_data: ã‚»ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿è¾æ›¸

        Returns:
            å“è³ªã‚¹ã‚³ã‚¢ (0-1, 1ãŒæœ€é«˜)
        """
        quality_score = 1.0

        # ãƒ‡ãƒ¼ã‚¿å“è³ªãƒ•ãƒ©ã‚°ã®ãƒã‚§ãƒƒã‚¯
        if sensor_data.get('quality') == 'Bad':
            quality_score *= 0.3
        elif sensor_data.get('quality') == 'Uncertain':
            quality_score *= 0.7

        # ãƒ‡ãƒ¼ã‚¿å®Œå…¨æ€§ã®ãƒã‚§ãƒƒã‚¯
        required_fields = ['temperature', 'pressure', 'flow_rate']
        missing_count = sum(1 for field in required_fields if field not in sensor_data)
        quality_score *= (1.0 - 0.2 * missing_count)

        # ãƒã‚¤ã‚ºLevelã®ãƒã‚§ãƒƒã‚¯ï¼ˆæ¨™æº–åå·®ãŒå¤§ãã„å ´åˆï¼‰
        if 'noise_level' in sensor_data:
            quality_score *= max(0.5, 1.0 - sensor_data['noise_level'])

        return quality_score

    def select_model(self, inputs: Dict,
                    sensor_data: Dict,
                    data_quality: Optional[float] = None) -&gt; ModelType:
        """é‹è»¢çŠ¶æ³ã«åŸºã¥ã„ã¦æœ€é©ãªãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ

        Args:
            inputs: é‹è»¢æ¡ä»¶
            sensor_data: ã‚»ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿
            data_quality: ãƒ‡ãƒ¼ã‚¿å“è³ªã‚¹ã‚³ã‚¢ï¼ˆNoneãªã‚‰è‡ªå‹•è¨ˆç®—ï¼‰

        Returns:
            é¸æŠã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—
        """
        if data_quality is None:
            data_quality = self.assess_data_quality(sensor_data)

        in_training_range = self.is_within_training_range(inputs)

        # æ±ºå®šãƒ­ã‚¸ãƒƒã‚¯
        if data_quality &lt; 0.5:
            # ãƒ‡ãƒ¼ã‚¿å“è³ªãŒä½ã„ â†’ ç‰©ç†ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨
            return ModelType.PHYSICS_ONLY

        elif in_training_range and data_quality &gt;= 0.8:
            # è¨“ç·´ç¯„å›²å†…ã‹ã¤é«˜å“è³ªãƒ‡ãƒ¼ã‚¿ â†’ ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«ï¼ˆæœ€é«˜ç²¾åº¦ï¼‰
            return ModelType.HYBRID

        elif in_training_range:
            # è¨“ç·´ç¯„å›²å†…ã ãŒå“è³ªã¯ä¸­ç¨‹åº¦ â†’ ãƒ‡ãƒ¼ã‚¿é§†å‹•ãƒ¢ãƒ‡ãƒ«
            return ModelType.DATA_DRIVEN

        else:
            # è¨“ç·´ç¯„å›²å¤– â†’ ç‰©ç†ãƒ¢ãƒ‡ãƒ«ï¼ˆå¤–æŒ¿æ€§ãŒé«˜ã„ï¼‰
            return ModelType.PHYSICS_ONLY

    def predict(self, inputs: Dict, sensor_data: Dict) -&gt; Dict:
        """Predictionå®Ÿè¡Œï¼ˆæœ€é©ãªãƒ¢ãƒ‡ãƒ«ã‚’è‡ªå‹•é¸æŠï¼‰

        Args:
            inputs: é‹è»¢æ¡ä»¶
            sensor_data: ã‚»ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿

        Returns:
            Predictionçµæœè¾æ›¸ {'conversion', 'model_used', 'confidence'}
        """
        # ãƒ¢ãƒ‡ãƒ«é¸æŠ
        selected_model = self.select_model(inputs, sensor_data)

        # ãƒ‡ãƒ¼ã‚¿å“è³ªè©•ä¾¡
        data_quality = self.assess_data_quality(sensor_data)

        # é¸æŠã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã§Prediction
        if selected_model == ModelType.PHYSICS_ONLY:
            result = self.physics_model.predict_physics(inputs)
            confidence = 0.7  # ç‰©ç†ãƒ¢ãƒ‡ãƒ«ã®ä¿¡é ¼åº¦

        elif selected_model == ModelType.DATA_DRIVEN:
            X = np.array([[
                inputs.get('T', 80),
                inputs.get('P', 2.5),
                inputs.get('F', 120),
                inputs.get('catalyst_age', 0)
            ]])
            conversion_pred = self.data_model.predict(X)[0]
            result = {'conversion': conversion_pred}
            confidence = 0.9 * data_quality  # ãƒ‡ãƒ¼ã‚¿å“è³ªã«ä¾å­˜

        elif selected_model == ModelType.HYBRID:
            result = self.hybrid_model.predict_hybrid(inputs)
            confidence = 0.95 * data_quality  # æœ€é«˜ç²¾åº¦

        else:
            raise ValueError(f"Unknown model type: {selected_model}")

        # çµæœã«æƒ…å ±ã‚’è¿½åŠ 
        result['model_used'] = selected_model.value
        result['confidence'] = confidence
        result['data_quality'] = data_quality

        return result

    def update_performance(self, model_type: ModelType,
                          prediction: float, actual: float):
        """ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ã®å±¥æ­´ã‚’æ›´æ–°ï¼ˆã‚ªãƒ³ãƒ©ã‚¤ãƒ³å­¦ç¿’ã«åˆ©ç”¨ï¼‰

        Args:
            model_type: ä½¿ç”¨ã—ãŸãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—
            prediction: Predictionå€¤
            actual: å®Ÿæ¸¬å€¤
        """
        error = abs(prediction - actual)
        self.performance_history[model_type].append(error)

        # æœ€æ–°100ä»¶ã®ã¿ä¿æŒ
        if len(self.performance_history[model_type]) &gt; 100:
            self.performance_history[model_type] = \
                self.performance_history[model_type][-100:]

    def get_model_performance_summary(self) -&gt; Dict:
        """å„ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚µãƒãƒªãƒ¼ã‚’å–å¾—

        Returns:
            {'physics': {'mae': 0.05, 'count': 120}, ...}
        """
        summary = {}

        for model_type, errors in self.performance_history.items():
            if len(errors) &gt; 0:
                summary[model_type.value] = {
                    'mae': np.mean(errors),
                    'std': np.std(errors),
                    'count': len(errors)
                }

        return summary


# ä½¿ç”¨ä¾‹
if __name__ == "__main__":
    # å„ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–ï¼ˆå‰ã®ä¾‹ã‹ã‚‰ï¼‰
    params = ReactorParameters()
    physics_model = FirstPrinciplesReactor(params)

    data_model = DataDrivenReactorModel(model_type='random_forest')
    # ï¼ˆè¨“ç·´ã¯çœç•¥ï¼‰

    hybrid_model = HybridReactorModel(physical_params=params)
    # ï¼ˆè¨“ç·´ã¯çœç•¥ï¼‰

    # é©å¿œçš„ãƒ¢ãƒ‡ãƒ«é¸æŠå™¨ã®åˆæœŸåŒ–
    model_selector = AdaptiveModelSelector(
        physics_model=physics_model,
        data_model=data_model,
        hybrid_model=hybrid_model
    )

    # ã‚·ãƒŠãƒªã‚ª1: é€šå¸¸é‹è»¢ï¼ˆé«˜å“è³ªãƒ‡ãƒ¼ã‚¿ã€è¨“ç·´ç¯„å›²å†…ï¼‰
    print("=== ã‚·ãƒŠãƒªã‚ª1: é€šå¸¸é‹è»¢ ===")
    inputs1 = {
        'CA_in': 1000,
        'T_in': 298,
        'T_jacket': 300,
        'T': 80,
        'P': 2.5,
        'F': 120,
        'catalyst_age': 100
    }
    sensor_data1 = {
        'temperature': 80.0,
        'pressure': 2.5,
        'flow_rate': 120.0,
        'quality': 'Good'
    }

    result1 = model_selector.predict(inputs1, sensor_data1)
    print(f"ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {result1['model_used']}")
    print(f"ä¿¡é ¼åº¦: {result1['confidence']:.2f}")
    print(f"ãƒ‡ãƒ¼ã‚¿å“è³ª: {result1['data_quality']:.2f}")

    # ã‚·ãƒŠãƒªã‚ª2: ç•°å¸¸é‹è»¢ï¼ˆä½å“è³ªãƒ‡ãƒ¼ã‚¿ï¼‰
    print("\n=== ã‚·ãƒŠãƒªã‚ª2: ç•°å¸¸é‹è»¢ï¼ˆä½å“è³ªãƒ‡ãƒ¼ã‚¿ï¼‰ ===")
    sensor_data2 = {
        'temperature': 80.0,
        'quality': 'Bad',  # ä¸è‰¯ãƒ‡ãƒ¼ã‚¿
        'noise_level': 0.8
    }

    result2 = model_selector.predict(inputs1, sensor_data2)
    print(f"ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {result2['model_used']}")
    print(f"ä¿¡é ¼åº¦: {result2['confidence']:.2f}")
    print(f"ãƒ‡ãƒ¼ã‚¿å“è³ª: {result2['data_quality']:.2f}")

    # ã‚·ãƒŠãƒªã‚ª3: è¨“ç·´ç¯„å›²å¤–ï¼ˆå¤–æŒ¿ï¼‰
    print("\n=== ã‚·ãƒŠãƒªã‚ª3: è¨“ç·´ç¯„å›²å¤– ===")
    inputs3 = {
        'CA_in': 1000,
        'T_in': 298,
        'T_jacket': 300,
        'T': 105,  # è¨“ç·´ç¯„å›²å¤–ï¼ˆmax 95â„ƒï¼‰
        'P': 2.5,
        'F': 120,
        'catalyst_age': 100
    }
    sensor_data3 = {
        'temperature': 105.0,
        'pressure': 2.5,
        'flow_rate': 120.0,
        'quality': 'Good'
    }

    result3 = model_selector.predict(inputs3, sensor_data3)
    print(f"ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {result3['model_used']}")
    print(f"ä¿¡é ¼åº¦: {result3['confidence']:.2f}")
    print(f"ç†ç”±: è¨“ç·´ç¯„å›²å¤–ã®ãŸã‚ç‰©ç†ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨")

    # æ€§èƒ½å±¥æ­´ã®æ›´æ–°ï¼ˆæ¨¡æ“¬ï¼‰
    print("\n=== ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ã®æ›´æ–° ===")
    model_selector.update_performance(ModelType.HYBRID, 0.75, 0.74)
    model_selector.update_performance(ModelType.HYBRID, 0.76, 0.75)
    model_selector.update_performance(ModelType.PHYSICS_ONLY, 0.70, 0.75)

    summary = model_selector.get_model_performance_summary()
    for model, stats in summary.items():
        print(f"{model}: MAE={stats['mae']:.4f}, ä½¿ç”¨å›æ•°={stats['count']}")

# æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›ä¾‹:
# === ã‚·ãƒŠãƒªã‚ª1: é€šå¸¸é‹è»¢ ===
# ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: hybrid
# ä¿¡é ¼åº¦: 0.95
# ãƒ‡ãƒ¼ã‚¿å“è³ª: 1.00
#
# === ã‚·ãƒŠãƒªã‚ª2: ç•°å¸¸é‹è»¢ï¼ˆä½å“è³ªãƒ‡ãƒ¼ã‚¿ï¼‰ ===
# ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: physics
# ä¿¡é ¼åº¦: 0.70
# ãƒ‡ãƒ¼ã‚¿å“è³ª: 0.06
#
# === ã‚·ãƒŠãƒªã‚ª3: è¨“ç·´ç¯„å›²å¤– ===
# ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: physics
# ä¿¡é ¼åº¦: 0.70
# ç†ç”±: è¨“ç·´ç¯„å›²å¤–ã®ãŸã‚ç‰©ç†ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨
#
# === ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ã®æ›´æ–° ===
# hybrid: MAE=0.0100, ä½¿ç”¨å›æ•°=2
# physics: MAE=0.0500, ä½¿ç”¨å›æ•°=1
</code></pre>
<h2>Learning Objectivesã®ç¢ºèª</h2>
<p>ã“ã® Chapterã‚’å®Œäº†ã™ã‚‹ã¨ã€ä»¥ä¸‹ã‚’å®Ÿè£…ã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã™ï¼š</p>
<h3>åŸºæœ¬ç†è§£</h3>
<ul>
<li>âœ… ç¬¬ä¸€åŸç†ãƒ¢ãƒ‡ãƒ«ã€ãƒ‡ãƒ¼ã‚¿é§†å‹•ãƒ¢ãƒ‡ãƒ«ã€ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«ã®é•ã„ã¨é©ç”¨å ´é¢ã‚’èª¬æ˜ã§ãã‚‹</li>
<li>âœ… è³ªé‡ãƒ»ã‚¨ãƒãƒ«ã‚®ãƒ¼ä¿å­˜å‰‡ã«åŸºã¥ãåå¿œå™¨ãƒ¢ãƒ‡ãƒ«ã®æ§‹é€ ã‚’ç†è§£ã§ãã‚‹</li>
<li>âœ… æ®‹å·®å­¦ç¿’ã¨PINNã®åŸºæœ¬æ¦‚å¿µã‚’èª¬æ˜ã§ãã‚‹</li>
</ul>
<h3>å®Ÿè·µã‚¹ã‚­ãƒ«</h3>
<ul>
<li>âœ… å¾® minutesæ–¹ç¨‹å¼ã‚½ãƒ«ãƒãƒ¼ã§ç¬¬ä¸€åŸç†ãƒ¢ãƒ‡ãƒ«ã‚’å®Ÿè£…ã§ãã‚‹</li>
<li>âœ… scikit-learnã§Machine Learningãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã§ãã‚‹</li>
<li>âœ… ç‰©ç†ãƒ¢ãƒ‡ãƒ«ã¨MLè£œæ­£ã‚’çµ„ã¿åˆã‚ã›ãŸãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã§ãã‚‹</li>
<li>âœ… å®Ÿæ¸¬ãƒ‡ãƒ¼ã‚¿ã§ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§ãã‚‹</li>
<li>âœ… ã‚¬ã‚¦ã‚¹éç¨‹å›å¸°ã§ä¸ç¢ºå®Ÿæ€§ã‚’å®šé‡åŒ–ã§ãã‚‹</li>
<li>âœ… é‹è»¢çŠ¶æ³ã«å¿œã˜ã¦ãƒ¢ãƒ‡ãƒ«ã‚’å‹•çš„ã«é¸æŠã§ãã‚‹</li>
</ul>
<h3>å¿œç”¨åŠ›</h3>
<ul>
<li>âœ… Processç‰¹æ€§ã«å¿œã˜ãŸæœ€é©ãªãƒ¢ãƒ‡ãƒªãƒ³ã‚°æˆ¦ç•¥ã‚’è¨­è¨ˆã§ãã‚‹</li>
<li>âœ… ç‰©ç†çŸ¥è­˜ã¨ãƒ‡ãƒ¼ã‚¿ã®ä¸¡æ–¹ã‚’æ´»ç”¨ã—ãŸé«˜ç²¾åº¦Digital Twinã‚’é–‹ç™ºã§ãã‚‹</li>
<li>âœ… ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ã‚’ç¶™ç¶šçš„ã«Monitoringãƒ»æ”¹å–„ã§ãã‚‹</li>
</ul>
<h2>Exercises</h2>
<h3>Easyï¼ˆåŸºç¤ç¢ºèªï¼‰</h3>
<div class="example-box">
<p><strong>Q1:</strong> ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«ã®åˆ©ç‚¹ã¨ã—ã¦ã€æœ€ã‚‚é©åˆ‡ã§ãªã„ã‚‚ã®ã¯ã©ã‚Œã§ã™ã‹ï¼Ÿ</p>
<p>a) ç‰©ç†çš„è§£é‡ˆæ€§ã¨é«˜ç²¾åº¦ã‚’ä¸¡ç«‹ã§ãã‚‹<br/>
            b) è¨“ç·´ãƒ‡ãƒ¼ã‚¿ãŒå°‘ãªãã¦ã‚‚é«˜æ€§èƒ½<br/>
            c) å®Ÿè£…ãŒæœ€ã‚‚ç°¡å˜<br/>
            d) å¤–æŒ¿æ€§ã¨ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒƒãƒˆæ€§ã‚’ä¸¡ç«‹</p>
<details>
<summary>è§£ç­”ã‚’è¦‹ã‚‹</summary>
<p><strong>æ­£è§£:</strong> c) å®Ÿè£…ãŒæœ€ã‚‚ç°¡å˜</p>
<p><strong>è§£èª¬:</strong></p>
<p>ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«ã¯ç‰©ç†ãƒ¢ãƒ‡ãƒ«ã¨ãƒ‡ãƒ¼ã‚¿é§†å‹•ãƒ¢ãƒ‡ãƒ«ã®çµ±åˆãŒå¿…è¦ãªãŸã‚ã€å®Ÿè£…ã¯æœ€ã‚‚è¤‡é›‘ã§ã™ã€‚ã—ã‹ã—ã€ãã®è¤‡é›‘ã•ã¨å¼•ãæ›ãˆã«ä»¥ä¸‹ã®åˆ©ç‚¹ãŒå¾—ã‚‰ã‚Œã¾ã™ï¼š</p>
<ul>
<li>a) ç‰©ç†ãƒ¢ãƒ‡ãƒ«éƒ¨ minutesã§è§£é‡ˆæ€§ã€MLéƒ¨ minutesã§é«˜ç²¾åº¦ã‚’å®Ÿç¾</li>
<li>b) ç‰©ç†çŸ¥è­˜ã§è£œã†ãŸã‚ã€ç´”ç²‹ãƒ‡ãƒ¼ã‚¿é§†å‹•ã‚ˆã‚Šå°‘ãªã„ãƒ‡ãƒ¼ã‚¿ã§é«˜æ€§èƒ½</li>
<li>d) ç‰©ç†æ³•å‰‡ã«ã‚ˆã‚Šå¤–æŒ¿æ€§ã‚’ä¿ã¡ã€MLã§ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒƒãƒˆæ€§ã‚’å‘ä¸Š</li>
</ul>
</details>
</div>
<h3>Mediumï¼ˆå¿œç”¨ï¼‰</h3>
<div class="example-box">
<p><strong>Q2:</strong> ç‰©ç†ãƒ¢ãƒ‡ãƒ«ã®ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§ã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿Optimizationã®ç›®çš„é–¢æ•°ï¼ˆMSEï¼‰ãŒåˆæœŸå€¤0.012345ã‹ã‚‰0.000123ã«æ”¹å–„ã—ã¾ã—ãŸã€‚ã“ã®ã¨ãã€RMSEã¯ã©ã‚Œãã‚‰ã„æ”¹å–„ã—ã¾ã—ãŸã‹ï¼Ÿæ”¹å–„ç‡ã‚‚è¨ˆç®—ã—ã¦ãã ã•ã„ã€‚</p>
<details>
<summary>è§£ç­”ã‚’è¦‹ã‚‹</summary>
<p><strong>è¨ˆç®—:</strong></p>
<ul>
<li>RMSE_before = âˆš(0.012345) = 0.1111</li>
<li>RMSE_after = âˆš(0.000123) = 0.0111</li>
<li>æ”¹å–„é‡ = 0.1111 - 0.0111 = 0.1000</li>
<li>æ”¹å–„ç‡ = (0.1000 / 0.1111) Ã— 100% = 90.0%</li>
</ul>
<p><strong>æ­£è§£: RMSEæ”¹å–„ç‡ = 90.0%</strong></p>
<p><strong>é‡è¦ãªãƒã‚¤ãƒ³ãƒˆ:</strong></p>
<ul>
<li>MSE = 100 minutesã®1ã«æ”¹å–„ï¼ˆ99%æ”¹å–„ï¼‰</li>
<li>RMSE = 10 minutesã®1ã«æ”¹å–„ï¼ˆ90%æ”¹å–„ï¼‰â† å¹³æ–¹æ ¹ã®ãŸã‚</li>
<li>RMSEã¯å…ƒã®ç‰©ç†é‡ã¨åŒã˜å˜ä½ãªã®ã§è§£é‡ˆã—ã‚„ã™ã„</li>
<li>ã“ã®ä¾‹ã§ã¯è»¢åŒ–ç‡ã®Predictionèª¤å·®ãŒç´„11%ã‹ã‚‰1.1%ã«æ”¹å–„</li>
</ul>
</details>
</div>
<h3>Hardï¼ˆç™ºå±•ï¼‰</h3>
<div class="example-box">
<p><strong>Q3:</strong> ã‚ãªãŸã¯æ–°ã—ã„Chemical Plantã®Digital Twiné–‹ç™ºã‚’ä»»ã•ã‚Œã¾ã—ãŸã€‚ä»¥ä¸‹ã®æ¡ä»¶ã§ã€ç¬¬ä¸€åŸç†ãƒ¢ãƒ‡ãƒ«ã€ãƒ‡ãƒ¼ã‚¿é§†å‹•ãƒ¢ãƒ‡ãƒ«ã€ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«ã®ã©ã‚Œã‚’æ¡ç”¨ã™ã¹ãã‹ã€ç†ç”±ã¨ã¨ã‚‚ã«ææ¡ˆã—ã¦ãã ã•ã„ã€‚</p>
<p><strong>æ¡ä»¶:</strong></p>
<ul>
<li>æ–°è¦ãƒ—ãƒ©ãƒ³ãƒˆï¼ˆé‹è»¢ãƒ‡ãƒ¼ã‚¿ãŒã»ã¼ãªã„ã€ãƒ‘ã‚¤ãƒ­ãƒƒãƒˆãƒ—ãƒ©ãƒ³ãƒˆã®50 hours minutesã®ã¿ï¼‰</li>
<li>åå¿œãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã¯æ—¢çŸ¥ï¼ˆç«¶äº‰åå¿œAâ†’B, Aâ†’Cï¼‰</li>
<li>è§¦åª’åŠ£åŒ–ã®è©³ç´°ã¯ä¸æ˜ï¼ˆçµŒé¨“çš„ã«1å¹´ã§10%æ€§èƒ½ä½ä¸‹ï¼‰</li>
<li>è¦æ±‚ç²¾åº¦: è»¢åŒ–ç‡Predictionèª¤å·®Â±2%ä»¥å†…</li>
<li>ç´æœŸ: 3ãƒ¶æœˆ</li>
</ul>
<details>
<summary>è§£ç­”ã‚’è¦‹ã‚‹</summary>
<p><strong>æ¨å¥¨: æ®µéšçš„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒï¼ˆç¬¬ä¸€åŸç† â†’ ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ï¼‰</strong></p>
<p><strong>ãƒ•ã‚§ãƒ¼ã‚º1ï¼ˆæœ€åˆã®1ãƒ¶æœˆï¼‰: ç¬¬ä¸€åŸç†ãƒ¢ãƒ‡ãƒ«é–‹ç™º</strong></p>
<ul>
<li><strong>ç†ç”±</strong>: é‹è»¢ãƒ‡ãƒ¼ã‚¿ãŒã»ã¼ãªã„ãŸã‚ã€ãƒ‡ãƒ¼ã‚¿é§†å‹•å˜ç‹¬ã¯ä¸å¯</li>
<li><strong>å®Ÿè£…</strong>:
                        <ul>
<li>Aâ†’Bã¨Aâ†’Cã®ç«¶äº‰åå¿œã‚’å¾® minutesæ–¹ç¨‹å¼ã§ãƒ¢ãƒ‡ãƒ«åŒ–</li>
<li>ãƒ‘ã‚¤ãƒ­ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿50 hoursã§ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆk0, Eaï¼‰ã‚’ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³</li>
<li>è§¦åª’åŠ£åŒ–ã¯ä¸€æ¬¡é–¢æ•°ã§è¿‘ä¼¼ï¼ˆk_eff = k0 Ã— (1 - 0.1 Ã— t/365)ï¼‰</li>
</ul>
</li>
<li><strong>æœŸå¾…ç²¾åº¦</strong>: Â±5%ç¨‹åº¦ï¼ˆè¦æ±‚æœªé”ã ãŒåˆæœŸç‰ˆã¨ã—ã¦ä½¿ç”¨å¯èƒ½ï¼‰</li>
</ul>
<p><strong>ãƒ•ã‚§ãƒ¼ã‚º2ï¼ˆ2ã€œ3ãƒ¶æœˆç›®ï¼‰: ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰åŒ–</strong></p>
<ul>
<li><strong>ç†ç”±</strong>: æœ¬æ ¼é‹è»¢é–‹å§‹ã§æ•°ãƒ¶æœˆ minutesã®ãƒ‡ãƒ¼ã‚¿ãŒè“„ç©</li>
<li><strong>å®Ÿè£…</strong>:
                        <ul>
<li>ç¬¬ä¸€åŸç†ãƒ¢ãƒ‡ãƒ«ã¯ç¶­æŒï¼ˆåŸºæœ¬ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ï¼‰</li>
<li>MLè£œæ­£ã§è§¦åª’åŠ£åŒ–ã®è¤‡é›‘ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å­¦ç¿’</li>
<li>æ®‹å·®å­¦ç¿’ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§æœªãƒ¢ãƒ‡ãƒ«åŒ–ç¾è±¡ã‚’æ•æ‰</li>
</ul>
</li>
<li><strong>æœŸå¾…ç²¾åº¦</strong>: Â±2%ä»¥å†…ï¼ˆè¦æ±‚é”æˆï¼‰</li>
</ul>
<p><strong>ãƒ‡ãƒ¼ã‚¿é§†å‹•å˜ç‹¬ã‚’é¸ã°ãªã„ç†ç”±:</strong></p>
<ul>
<li>è¨“ç·´ãƒ‡ãƒ¼ã‚¿50 hoursã¯å°‘ãªã™ãã‚‹ï¼ˆé€šå¸¸ã¯æ•°åƒ hourså¿…è¦ï¼‰</li>
<li>æ–°è¦ãƒ—ãƒ©ãƒ³ãƒˆã§äºˆæœŸã—ãªã„é‹è»¢æ¡ä»¶ãŒç™ºç”Ÿâ†’å¤–æŒ¿ãŒå¿…è¦</li>
<li>ãƒ–ãƒ©ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ã§ã¯Safetyæ€§ç¢ºèªãŒå›°é›£</li>
</ul>
<p><strong>å®Ÿè£…ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼ˆ3ãƒ¶æœˆï¼‰:</strong></p>
<table>
<thead>
<tr>
<th>æœˆ</th>
<th>ã‚¿ã‚¹ã‚¯</th>
<th>ãƒã‚¤ãƒ«ã‚¹ãƒˆãƒ¼ãƒ³</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>ç¬¬ä¸€åŸç†ãƒ¢ãƒ‡ãƒ«é–‹ç™ºã€ãƒ‘ã‚¤ãƒ­ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿ã§ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³</td>
<td>ç²¾åº¦Â±5%é”æˆ</td>
</tr>
<tr>
<td>2</td>
<td>æœ¬æ ¼é‹è»¢é–‹å§‹ã€ãƒ‡ãƒ¼ã‚¿åé›†ã€MLè£œæ­£ãƒ¢ãƒ‡ãƒ«é–‹ç™º</td>
<td>500 hoursãƒ‡ãƒ¼ã‚¿è“„ç©</td>
</tr>
<tr>
<td>3</td>
<td>ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«çµ±åˆã€æ¤œè¨¼ã€ãƒ‡ãƒ—ãƒ­ã‚¤</td>
<td>ç²¾åº¦Â±2%é”æˆ</td>
</tr>
</tbody>
</table>
<p><strong>ãƒªã‚¹ã‚¯ç·©å’Œç­–:</strong></p>
<ul>
<li>ãƒ•ã‚§ãƒ¼ã‚º1ã§æœ€ä½é™ã®æ©Ÿèƒ½ã‚’ç¢ºä¿ï¼ˆç´æœŸå³å®ˆï¼‰</li>
<li>ãƒ•ã‚§ãƒ¼ã‚º2ã§ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ãªã‚‰ã€ç‰©ç†ãƒ¢ãƒ‡ãƒ«ã®ã¿ã§é‹ç”¨ç¶™ç¶š</li>
<li>ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å­¦ç¿’ã§é‹è»¢ãƒ‡ãƒ¼ã‚¿è“„ç©ã¨ã¨ã‚‚ã«ç²¾åº¦å‘ä¸Š</li>
</ul>
</details>
</div>
<h2>Next Steps</h2>
<p>ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã®åŸºç¤ã‚’ç¿’å¾—ã—ãŸã‚‰ã€æ¬¡ã¯Digital Twinã®å®Ÿè·µçš„ãªå¿œç”¨ã«é€²ã¿ã¾ã™ã€‚ProcessOptimizationã€Predictionä¿å…¨ã€What-if minutesæãªã©ã€å®Ÿãƒ“ã‚¸ãƒã‚¹ã§ã®æ´»ç”¨äº‹ä¾‹ã‚’å­¦ã³ã¾ã™ã€‚</p>
<div class="nav-buttons">
<a class="nav-button" href="chapter-2.html">â† Chapter 2ï¼šãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ‡ãƒ¼ã‚¿é€£æº</a>
<a class="nav-button" href="index.html">Series Contents</a>
</div>
<h2>References</h2>
<ol>
<li>Raissi, M., Perdikaris, P., &amp; Karniadakis, G. E. (2019). "Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations." <em>Journal of Computational Physics</em>, 378, 686-707.</li>
<li>von Stosch, M., et al. (2014). "Hybrid semi-parametric modeling in process systems engineering: Past, present and future." <em>Computers &amp; Chemical Engineering</em>, 60, 86-101.</li>
<li>Rasmussen, C. E., &amp; Williams, C. K. I. (2006). <em>Gaussian Processes for Machine Learning</em>. MIT Press.</li>
<li>Virtanen, P., et al. (2020). "SciPy 1.0: fundamental algorithms for scientific computing in Python." <em>Nature Methods</em>, 17(3), 261-272.</li>
<li>Psichogios, D. C., &amp; Ungar, L. H. (1992). "A hybrid neural network-first principles approach to process modeling." <em>AIChE Journal</em>, 38(10), 1499-1511.</li>
</ol>
</div>
<section class="disclaimer">
<h3>Disclaimer</h3>
<ul>
<li>This content is provided solely for educational, research, and informational purposes and does not constitute professional advice (legal, accounting, technical warranty, etc.).</li>
<li>This content and accompanying code examples are provided "AS IS" without any warranty, express or implied, including but not limited to merchantability, fitness for a particular purpose, non-infringement, accuracy, completeness, operation, or safety.</li>
<li>The author and Tohoku University assume no responsibility for the content, availability, or safety of external links, third-party data, tools, libraries, etc.</li>
<li>To the maximum extent permitted by applicable law, the author and Tohoku University shall not be liable for any direct, indirect, incidental, special, consequential, or punitive damages arising from the use, execution, or interpretation of this content.</li>
<li>The content may be changed, updated, or discontinued without notice.</li>
<li>The copyright and license of this content are subject to the stated conditions (e.g., CC BY 4.0). Such licenses typically include no-warranty clauses.</li>
</ul>
</section>

</body>
</html>