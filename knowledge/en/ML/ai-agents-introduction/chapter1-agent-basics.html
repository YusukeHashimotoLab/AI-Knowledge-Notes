<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="AI Agent Fundamentals - AI Agents Introduction Series Chapter 1">
    <title>Chapter 1: AI Agent Fundamentals - AI Agents Introduction Series</title>

    <!-- MathJax for formulas -->
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js"></script>

    <!-- CSS Styling -->
    <style>
        :root {
            --primary-color: #2c3e50;
            --secondary-color: #667eea;
            --accent-color: #764ba2;
            --bg-color: #ffffff;
            --text-color: #333333;
            --border-color: #e0e0e0;
            --code-bg: #f5f5f5;
            --link-color: #667eea;
            --link-hover: #764ba2;
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", "Helvetica Neue", Arial, sans-serif;
            line-height: 1.8;
            color: var(--text-color);
            background: var(--bg-color);
            padding: 0;
            margin: 0;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 2rem 1.5rem;
        }

        /* Header */
        header {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 2rem 0;
            margin-bottom: 2rem;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }

        header .container {
            padding: 0 1.5rem;
        }

        h1 {
            font-size: 2rem;
            margin-bottom: 0.5rem;
            font-weight: 700;
        }

        .meta {
            display: flex;
            gap: 1.5rem;
            flex-wrap: wrap;
            font-size: 0.9rem;
            opacity: 0.95;
            margin-top: 1rem;
        }

        .meta span {
            display: inline-flex;
            align-items: center;
            gap: 0.3rem;
        }

        /* Typography */
        h2 {
            font-size: 1.75rem;
            margin-top: 2.5rem;
            margin-bottom: 1rem;
            padding-bottom: 0.5rem;
            border-bottom: 3px solid var(--secondary-color);
            color: var(--primary-color);
        }

        h3 {
            font-size: 1.4rem;
            margin-top: 2rem;
            margin-bottom: 0.8rem;
            color: var(--primary-color);
        }

        h4 {
            font-size: 1.2rem;
            margin-top: 1.5rem;
            margin-bottom: 0.6rem;
            color: var(--primary-color);
        }

        p {
            margin-bottom: 1.2rem;
        }

        a {
            color: var(--link-color);
            text-decoration: none;
            transition: color 0.2s;
        }

        a:hover {
            color: var(--link-hover);
            text-decoration: underline;
        }

        /* Lists */
        ul, ol {
            margin-left: 2rem;
            margin-bottom: 1.2rem;
        }

        li {
            margin-bottom: 0.5rem;
        }

        /* Code blocks */
        code {
            background: var(--code-bg);
            padding: 0.2rem 0.4rem;
            border-radius: 3px;
            font-family: 'Menlo', 'Monaco', 'Courier New', monospace;
            font-size: 0.9em;
        }

        pre {
            background: var(--code-bg);
            padding: 1.5rem;
            border-radius: 8px;
            overflow-x: auto;
            margin-bottom: 1.5rem;
            border: 1px solid var(--border-color);
        }

        pre code {
            background: none;
            padding: 0;
            font-size: 0.9rem;
        }

        /* Tables */
        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: 1.5rem;
            overflow-x: auto;
            display: block;
        }

        thead {
            display: table;
            width: 100%;
            table-layout: fixed;
        }

        tbody {
            display: table;
            width: 100%;
            table-layout: fixed;
        }

        th, td {
            padding: 0.8rem;
            text-align: left;
            border: 1px solid var(--border-color);
        }

        th {
            background: var(--primary-color);
            color: white;
            font-weight: 600;
        }

        tr:nth-child(even) {
            background: #f9f9f9;
        }

        /* Blockquotes */
        blockquote {
            border-left: 4px solid var(--secondary-color);
            padding-left: 1.5rem;
            margin: 1.5rem 0;
            font-style: italic;
            color: #666;
        }

        /* Images */
        img {
            max-width: 100%;
            height: auto;
            border-radius: 8px;
            margin: 1rem 0;
        }

        /* Mermaid diagrams */
        .mermaid {
            text-align: center;
            margin: 2rem 0;
            background: white;
            padding: 1rem;
            border-radius: 8px;
            border: 1px solid var(--border-color);
        }

        /* Details/Summary */
        details {
            margin: 1rem 0;
            padding: 1rem;
            background: #f8f9fa;
            border-radius: 8px;
            border: 1px solid var(--border-color);
        }

        summary {
            cursor: pointer;
            font-weight: 600;
            color: var(--primary-color);
            padding: 0.5rem;
        }

        summary:hover {
            color: var(--secondary-color);
        }

        /* Footer */
        footer {
            margin-top: 4rem;
            padding: 2rem 0;
            border-top: 2px solid var(--border-color);
            text-align: center;
            color: #666;
            font-size: 0.9rem;
        }

        /* Navigation buttons */
        .nav-buttons {
            display: flex;
            justify-content: space-between;
            margin: 3rem 0;
            gap: 1rem;
            flex-wrap: wrap;
        }

        .nav-button {
            display: inline-block;
            padding: 0.8rem 1.5rem;
            background: var(--secondary-color);
            color: white;
            border-radius: 6px;
            text-decoration: none;
            transition: all 0.3s;
            font-weight: 600;
        }

        .nav-button:hover {
            background: var(--link-hover);
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(102, 126, 234, 0.3);
            text-decoration: none;
        }

        /* Responsive */
        @media (max-width: 768px) {
            .container {
                padding: 1rem;
            }

            h1 {
                font-size: 1.6rem;
            }

            h2 {
                font-size: 1.4rem;
            }

            .meta {
                font-size: 0.85rem;
            }

            pre {
                padding: 1rem;
                font-size: 0.85rem;
            }

            table {
                font-size: 0.9rem;
            }
        }

        .feedback-notice {
            background: #fff3cd;
            border: 2px solid #ffc107;
            border-radius: 8px;
            padding: 2rem;
            margin: 3rem auto;
            max-width: 900px;
        }

        .feedback-notice h3 {
            color: #856404;
            font-size: 1.3rem;
            margin-bottom: 1rem;
            text-align: center;
        }

        .feedback-notice p {
            color: #856404;
            font-size: 1rem;
            margin-bottom: 1.5rem;
            text-align: center;
        }

        .feedback-options {
            display: flex;
            justify-content: center;
            gap: 1rem;
            flex-wrap: wrap;
        }

        .feedback-button {
            display: inline-block;
            padding: 0.8rem 1.5rem;
            background: #3498db;
            color: white;
            text-decoration: none;
            border-radius: 6px;
            font-weight: 600;
            transition: all 0.3s;
        }

        .feedback-button:hover {
            background: #2980b9;
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(52, 152, 219, 0.3);
        }




        /* Breadcrumb styles */
        .breadcrumb {
            background: #f7fafc;
            padding: 0.75rem 1rem;
            border-bottom: 1px solid #e2e8f0;
            font-size: 0.9rem;
        }

        .breadcrumb-content {
            max-width: 900px;
            margin: 0 auto;
            display: flex;
            align-items: center;
            flex-wrap: wrap;
            gap: 0.5rem;
        }

        .breadcrumb a {
            color: #667eea;
            text-decoration: none;
            transition: color 0.2s;
        }

        .breadcrumb a:hover {
            color: #764ba2;
            text-decoration: underline;
        }

        .breadcrumb-separator {
            color: #a0aec0;
            margin: 0 0.25rem;
        }

        .breadcrumb-current {
            color: #4a5568;
            font-weight: 500;
        }
    </style>

    <!-- Mermaid for diagrams -->
    <script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
    <script>
        document.addEventListener('DOMContentLoaded', function() {
            const mermaidCodeBlocks = document.querySelectorAll('pre.codehilite code.language-mermaid, pre code.language-mermaid');

            mermaidCodeBlocks.forEach(function(codeBlock) {
                const pre = codeBlock.parentElement;
                const mermaidCode = codeBlock.textContent;

                const mermaidDiv = document.createElement('div');
                mermaidDiv.className = 'mermaid';
                mermaidDiv.textContent = mermaidCode.trim();

                pre.parentNode.replaceChild(mermaidDiv, pre);
            });

            if (typeof mermaid !== 'undefined') {
                mermaid.initialize({ startOnLoad: true, theme: 'default' });
                mermaid.init(undefined, document.querySelectorAll('.mermaid'));
            }
        });
    </script>
</head>
<body>
            <nav class="breadcrumb">
        <div class="breadcrumb-content">
            <a href="../../index.html">AI Terakoya Top</a><span class="breadcrumb-separator">‚Ä∫</span><a href="../../ML/index.html">Machine Learning</a><span class="breadcrumb-separator">‚Ä∫</span><a href="../../ML/ai-agents-introduction/index.html">AI Agents</a><span class="breadcrumb-separator">‚Ä∫</span><span class="breadcrumb-current">Chapter 1</span>
        </div>
    </nav>

        <header>
        <div class="container">
            <h1>Chapter 1: AI Agent Fundamentals</h1>
            <p style="font-size: 1.1rem; margin-top: 0.5rem; opacity: 0.95;">Concepts and Design of Autonomous AI Systems</p>
            <div class="meta">
                <span>üìñ Reading Time: 30-35 minutes</span>
                <span>üìä Difficulty: Intermediate</span>
                <span>üíª Code Examples: 6</span>
            </div>
        </div>
    </header>

    <main class="container">
        <h2 id="intro">What is an AI Agent?</h2>

        <h3>Definition and Characteristics</h3>
        <p>An <strong>AI Agent</strong> is an AI system that perceives its environment, makes autonomous decisions, and takes actions to achieve goals. Unlike traditional static AI models, agents dynamically assess situations and complete complex tasks through multiple steps.</p>

        <p><strong>Key Characteristics of AI Agents</strong>:</p>
        <ul>
            <li><strong>Autonomy</strong>: Acts independently without human instructions</li>
            <li><strong>Reactivity</strong>: Recognizes environmental changes and responds appropriately</li>
            <li><strong>Goal-oriented</strong>: Plans actions toward clear objectives</li>
            <li><strong>Learning</strong>: Learns and improves from experience</li>
            <li><strong>Tool Use</strong>: Leverages external tools and APIs</li>
        </ul>

        <h3>Differences from Traditional AI</h3>

        <table>
            <thead>
                <tr>
                    <th>Aspect</th>
                    <th>Traditional AI</th>
                    <th>AI Agent</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>Input/Output</td>
                    <td>Single input ‚Üí Single output</td>
                    <td>Multi-step dialogue and actions</td>
                </tr>
                <tr>
                    <td>Decision Making</td>
                    <td>Immediate response generation</td>
                    <td>Reasoning ‚Üí Action ‚Üí Observation loop</td>
                </tr>
                <tr>
                    <td>External Integration</td>
                    <td>Limited or impossible</td>
                    <td>Utilizes tools, APIs, and search</td>
                </tr>
                <tr>
                    <td>Task Complexity</td>
                    <td>Simple question answering</td>
                    <td>Multi-stage complex tasks</td>
                </tr>
                <tr>
                    <td>Adaptability</td>
                    <td>Fixed behavior</td>
                    <td>Changes strategy based on situation</td>
                </tr>
            </tbody>
        </table>

        <h2 id="architecture">Agent Architecture</h2>

        <h3>Basic Loop: Perception, Reasoning, Action</h3>
        <p>AI agents achieve goals by repeating the following cycle:</p>

        <div class="mermaid">
graph LR
    A[Perception] --> B[Reasoning]
    B --> C[Action]
    C --> D[Environment]
    D --> A

    style A fill:#e3f2fd
    style B fill:#fff3e0
    style C fill:#f3e5f5
    style D fill:#e8f5e9
</div>

        <ol>
            <li><strong>Perception</strong>: Observe environmental state, user input, and previous action results</li>
            <li><strong>Reasoning</strong>: Plan next action based on observed information</li>
            <li><strong>Action</strong>: Execute tools, generate responses, perform tasks</li>
            <li><strong>Environment</strong>: Action results reflected in environment, leading to next perception</li>
        </ol>

        <h3>Key Agent Components</h3>

        <pre><code class="language-python"># Basic agent structure
class Agent:
    def __init__(self, llm, tools, memory):
        self.llm = llm              # Large language model (reasoning engine)
        self.tools = tools          # Available tool set
        self.memory = memory        # Conversation history and state
        self.max_iterations = 10    # Maximum execution count

    def run(self, task):
        """Agent execution loop"""
        self.memory.add_message("user", task)

        for i in range(self.max_iterations):
            # 1. Reasoning: Determine next action
            thought = self.think()

            # 2. Action: Execute tool or provide answer
            if thought.action:
                observation = self.act(thought.action)
                self.memory.add_observation(observation)
            else:
                return thought.answer

        return "Could not complete task"

    def think(self):
        """Reason about next action using LLM"""
        prompt = self.build_prompt()
        response = self.llm.generate(prompt)
        return self.parse_response(response)

    def act(self, action):
        """Execute tool and get result"""
        tool = self.tools[action.tool_name]
        result = tool.execute(action.parameters)
        return result
</code></pre>

        <h2 id="react">ReAct Pattern</h2>

        <h3>Integration of Reasoning and Acting</h3>
        <p><strong>ReAct</strong> (Reasoning and Acting) is an agent pattern proposed by Yao et al. (2022) that determines actions while verbalizing the reasoning process.</p>

        <p><strong>ReAct Steps</strong>:</p>
        <ol>
            <li><strong>Thought</strong>: Analyze current situation and consider next action</li>
            <li><strong>Action</strong>: Select tool and determine parameters</li>
            <li><strong>Observation</strong>: Confirm tool execution results</li>
            <li>Repeat ‚Üí Eventually provide Answer</li>
        </ol>

        <h3>Example ReAct Prompt</h3>

        <pre><code class="language-python">REACT_PROMPT = """You are an assistant that answers questions. Please repeat thinking and acting in the following format.

Available tools:
- search: Execute web search (input: search query)
- calculator: Calculate mathematical expressions (input: expression)
- finish: Return final answer (input: answer text)

Format:
Question: User's question
Thought: What you are thinking
Action: tool_name[input]
Observation: Tool execution result
... (repeat as needed)
Thought: Final conclusion
Action: finish[final answer]

Question: {question}
Thought:"""

# Execution example
question = "Who won the 2024 Nobel Prize in Physics?"
response = """
Thought: I need to search the web for the latest Nobel Prize information
Action: search[2024 Nobel Prize in Physics winner]
Observation: The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton. Their foundational research in machine learning was recognized.
Thought: The winner has been identified from the search results
Action: finish[The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton. They were recognized for their contributions to the theoretical foundation of machine learning, particularly neural networks.]
"""
</code></pre>

        <h3>ReAct Agent Implementation</h3>

        <pre><code class="language-python">import re
from openai import OpenAI

class ReActAgent:
    def __init__(self, api_key):
        self.client = OpenAI(api_key=api_key)
        self.tools = {
            "search": self.mock_search,
            "calculator": self.calculator
        }

    def mock_search(self, query):
        """Mock search (use SerpAPI etc. in practice)"""
        # In actual implementation, call web search API
        return f"Search results: Information about {query}"

    def calculator(self, expression):
        """Calculator tool"""
        try:
            result = eval(expression)
            return f"Calculation result: {result}"
        except Exception as e:
            return f"Error: {str(e)}"

    def run(self, question, max_steps=5):
        """Execute ReAct loop"""
        prompt = REACT_PROMPT.format(question=question)

        for step in range(max_steps):
            # Generate next action with LLM
            response = self.client.chat.completions.create(
                model="gpt-4",
                messages=[{"role": "user", "content": prompt}],
                temperature=0
            )

            text = response.choices[0].message.content
            prompt += text

            # Extract Action
            action_match = re.search(r'Action: (\w+)\[(.*?)\]', text)
            if not action_match:
                continue

            tool_name = action_match.group(1)
            tool_input = action_match.group(2)

            # Check for termination
            if tool_name == "finish":
                return tool_input

            # Execute tool
            if tool_name in self.tools:
                observation = self.tools[tool_name](tool_input)
                prompt += f"\nObservation: {observation}\nThought:"
            else:
                prompt += f"\nObservation: Error - tool {tool_name} does not exist\nThought:"

        return "Reached maximum steps"

# Usage example
agent = ReActAgent(api_key="your-api-key")
answer = agent.run("Please calculate 123 + 456")
print(answer)  # Output: 579
</code></pre>

        <h2 id="cot">Chain-of-Thought</h2>

        <h3>Step-by-Step Reasoning Process</h3>
        <p><strong>Chain-of-Thought (CoT)</strong> is a technique that breaks down complex problems into steps for reasoning. Proposed by Wei et al. (2022), it is especially effective for tasks requiring mathematical reasoning and logical thinking.</p>

        <p><strong>Benefits of CoT</strong>:</p>
        <ul>
            <li>‚úÖ <strong>Improved Accuracy</strong>: Higher correct answer rate for complex problems</li>
            <li>‚úÖ <strong>Interpretability</strong>: Reasoning process is visualized</li>
            <li>‚úÖ <strong>Error Detection</strong>: Thinking process can be reviewed</li>
            <li>‚úÖ <strong>Easy Debugging</strong>: Can identify where mistakes occurred</li>
        </ul>

        <h3>Few-shot CoT Prompt</h3>

        <pre><code class="language-python">COT_PROMPT = """Please solve problems step by step as in the examples below.

Q: At a cafe, coffee is 300 yen per cup and cake is 450 yen per piece. How much does it cost to buy 2 cups of coffee and 3 pieces of cake?
A: First, calculate the total for coffee: 300 yen √ó 2 cups = 600 yen
Next, calculate the total for cake: 450 yen √ó 3 pieces = 1,350 yen
Finally, add them together: 600 yen + 1,350 yen = 1,950 yen
Answer: 1,950 yen

Q: {question}
A: Let's think step by step."""

# Implementation example
from openai import OpenAI

def chain_of_thought(question, api_key):
    """Reasoning using CoT"""
    client = OpenAI(api_key=api_key)

    prompt = COT_PROMPT.format(question=question)

    response = client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}],
        temperature=0
    )

    return response.choices[0].message.content

# Usage example
question = "There are 12 apples. You gave 3 to a friend and bought 8 more. How many apples are there now?"
answer = chain_of_thought(question, "your-api-key")
print(answer)
# Output:
# First, calculate apples after giving some away: 12 - 3 = 9
# Next, add the newly bought apples: 9 + 8 = 17
# Answer: 17
</code></pre>

        <h3>Zero-shot CoT ("Let's think step by step")</h3>
        <p>Kojima et al. (2022) discovered that the magic phrase "Let's think step by step" can elicit step-by-step reasoning without providing examples.</p>

        <pre><code class="language-python">def zero_shot_cot(question, api_key):
    """Zero-shot CoT: Step-by-step reasoning without examples"""
    client = OpenAI(api_key=api_key)

    # Step 1: Generate reasoning process
    prompt1 = f"{question}\n\nLet's think step by step."

    response1 = client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt1}],
        temperature=0
    )

    reasoning = response1.choices[0].message.content

    # Step 2: Extract final answer from reasoning
    prompt2 = f"{question}\n\n{reasoning}\n\nTherefore, the answer is:"

    response2 = client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt2}],
        temperature=0
    )

    answer = response2.choices[0].message.content

    return {
        "reasoning": reasoning,
        "answer": answer
    }

# Usage example
result = zero_shot_cot(
    "When 5 is added to 3 times a certain number, the result is 23. What is the number?",
    "your-api-key"
)
print(f"Reasoning: {result['reasoning']}")
print(f"Answer: {result['answer']}")
</code></pre>

        <h2 id="basic-implementation">Basic Agent Implementation</h2>

        <h3>Simple Agent Loop</h3>

        <pre><code class="language-python">import json
from openai import OpenAI
from typing import List, Dict, Any

class SimpleAgent:
    """Simple AI agent implementation"""

    def __init__(self, api_key: str, tools: Dict[str, callable]):
        self.client = OpenAI(api_key=api_key)
        self.tools = tools
        self.conversation_history = []
        self.system_prompt = """You are a capable AI assistant.
Use tools as needed to answer user questions.

Available tools:
{tool_descriptions}

Thinking process:
1. Understand the question
2. Select necessary tools
3. Execute tools
4. Integrate results and respond"""

    def get_tool_descriptions(self) -> str:
        """Generate tool descriptions"""
        descriptions = []
        for name, func in self.tools.items():
            desc = func.__doc__ or "No description"
            descriptions.append(f"- {name}: {desc}")
        return "\n".join(descriptions)

    def run(self, user_input: str, max_iterations: int = 5) -> str:
        """Execute agent"""
        self.conversation_history.append({
            "role": "user",
            "content": user_input
        })

        for iteration in range(max_iterations):
            # Query LLM
            response = self.client.chat.completions.create(
                model="gpt-4",
                messages=[
                    {
                        "role": "system",
                        "content": self.system_prompt.format(
                            tool_descriptions=self.get_tool_descriptions()
                        )
                    }
                ] + self.conversation_history,
                temperature=0
            )

            assistant_message = response.choices[0].message.content

            # Parse tool call
            tool_call = self.parse_tool_call(assistant_message)

            if tool_call:
                # Execute tool
                tool_name = tool_call["name"]
                tool_args = tool_call["args"]

                if tool_name in self.tools:
                    result = self.tools[tool_name](**tool_args)

                    # Add result to conversation history
                    self.conversation_history.append({
                        "role": "assistant",
                        "content": f"Executed tool {tool_name}"
                    })
                    self.conversation_history.append({
                        "role": "user",
                        "content": f"Result: {result}"
                    })
                else:
                    # Unknown tool
                    self.conversation_history.append({
                        "role": "user",
                        "content": f"Error: Tool {tool_name} does not exist"
                    })
            else:
                # No tool call = final answer
                return assistant_message

        return "Reached maximum iterations"

    def parse_tool_call(self, message: str) -> Dict[str, Any]:
        """Extract tool call from message (simplified version)"""
        # In practice, a more robust parser is needed
        import re
        match = re.search(r'TOOL: (\w+)\((.*?)\)', message)
        if match:
            tool_name = match.group(1)
            args_str = match.group(2)
            # Simple argument parsing
            args = {}
            if args_str:
                for arg in args_str.split(','):
                    key, value = arg.split('=')
                    args[key.strip()] = value.strip().strip('"\'')
            return {"name": tool_name, "args": args}
        return None

# Tool definitions
def get_weather(location: str) -> str:
    """Get weather for specified location"""
    # In practice, call API
    weather_data = {
        "Tokyo": "Sunny, 22¬∞C",
        "Osaka": "Cloudy, 20¬∞C",
        "Sapporo": "Rainy, 15¬∞C"
    }
    return weather_data.get(location, "No data")

def calculate(expression: str) -> float:
    """Calculate mathematical expression"""
    try:
        result = eval(expression)
        return result
    except Exception as e:
        return f"Calculation error: {str(e)}"

# Execute agent
agent = SimpleAgent(
    api_key="your-api-key",
    tools={
        "get_weather": get_weather,
        "calculate": calculate
    }
)

response = agent.run("Tell me the weather in Tokyo")
print(response)
</code></pre>

        <h2 id="prompt-engineering">Prompt Engineering for Agents</h2>

        <h3>Designing Effective System Prompts</h3>
        <p>Agent behavior is greatly influenced by the system prompt. Here are best practices for effective prompt design.</p>

        <h4>1. Clear Role Definition</h4>
        <pre><code class="language-python">SYSTEM_PROMPT = """You are a customer support agent.

Role:
- Accurately understand user problems
- Collect information using appropriate tools
- Provide friendly and professional responses

Important constraints:
- Do not speculate on uncertain information
- Handle personal information carefully
- Escalate appropriately when errors occur
"""
</code></pre>

        <h4>2. Tool Usage Guidelines</h4>
        <pre><code class="language-python">TOOL_USAGE_GUIDE = """
Available tools:

1. search_database(query: str) -> List[Dict]
   - Search database for relevant information
   - Use cases: Product information, order history search

2. send_email(to: str, subject: str, body: str) -> bool
   - Send email
   - Use cases: Confirmation emails, notifications

3. escalate_to_human(reason: str) -> None
   - Escalate to human operator
   - Use cases: Complex issues, complaint handling

Tool selection principles:
- First collect necessary information with search_database
- Generate response if automatic handling is possible
- Use escalate_to_human for complex or important cases
"""
</code></pre>

        <h4>3. Few-shot Examples</h4>
        <pre><code class="language-python">FEW_SHOT_EXAMPLES = """
Example 1:
User: Please tell me the delivery status of order number 12345
Thought: Need to search order information from database
Action: search_database(query="order_number:12345")
Observation: {order_id: 12345, status: "in_transit", tracking: "ABC123"}
Response: Your order 12345 is currently in transit. The tracking number is ABC123.

Example 2:
User: I would like a refund
Thought: Refunds involve important financial processing, should hand over to human
Action: escalate_to_human(reason="refund request")
Response: I understand you'd like a refund. Let me connect you with a representative.
"""
</code></pre>

        <h2 id="summary">Summary</h2>

        <h3>What We Learned in This Chapter</h3>
        <ul>
            <li>‚úÖ <strong>AI Agent Definition</strong>: Autonomy, reactivity, goal-orientation, tool use</li>
            <li>‚úÖ <strong>Agent Architecture</strong>: Perception ‚Üí Reasoning ‚Üí Action loop</li>
            <li>‚úÖ <strong>ReAct Pattern</strong>: Agent design integrating reasoning and action</li>
            <li>‚úÖ <strong>Chain-of-Thought</strong>: Improved accuracy through step-by-step reasoning</li>
            <li>‚úÖ <strong>Basic Implementation</strong>: Building simple agent loops</li>
            <li>‚úÖ <strong>Prompt Design</strong>: Effective prompts for agents</li>
        </ul>

        <h3>Key Concepts</h3>
        <blockquote>
            <p><strong>Agent = LLM + Tools + Reasoning Loop</strong></p>
            <p>AI agents autonomously solve complex tasks by combining the reasoning capabilities of large language models with external tools, repeating multi-step thinking and action.</p>
        </blockquote>

        <h3>Next Steps</h3>
        <p>In Chapter 2, we will learn in detail about Function Calling and Tool Use:</p>
        <ul>
            <li>OpenAI/Anthropic Function Calling API</li>
            <li>Tool schema definition</li>
            <li>External API integration and error handling</li>
            <li>Practical tool implementation patterns</li>
        </ul>

        <div class="nav-buttons">
            <a href="./index.html" class="nav-button">‚Üê Series Overview</a>
            <a href="./chapter2-tool-use.html" class="nav-button">Chapter 2: Tool Use ‚Üí</a>
        </div>
    </main>


        <div class="feedback-notice">
            <h3>‚ö†Ô∏è Help Us Improve Content Quality</h3>
            <p>This content was created with AI assistance. If you find errors or areas for improvement, please report them using one of the following methods:</p>
            <div class="feedback-options">
                <a href="https://forms.gle/9GfVBa2Qa7Uy9taQA" target="_blank" class="feedback-button">
                    üìù Correction Request Form
                </a>
                <a href="mailto:yusuke.hashimoto.d8@tohoku.ac.jp" class="feedback-button">
                    ‚úâÔ∏è Contact by Email
                </a>
            </div>
        </div>

    <footer>
        <div class="container">
            <p>&copy; 2025 AI Terakoya - Dr. Yusuke Hashimoto, Tohoku University</p>
            <p>Licensed under CC BY 4.0</p>
        </div>
    </footer>
</body>
</html>
