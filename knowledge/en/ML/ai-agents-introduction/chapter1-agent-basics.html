<!DOCTYPE html>

<html lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<meta content="AI Agent Fundamentals - AI Agents Introduction Series Chapter 1" name="description"/>
<title>Chapter 1: AI Agent Fundamentals - AI Agents Introduction Series</title>
<!-- MathJax for formulas -->
<script src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js"></script>
<!-- CSS Styling -->
<link href="../../assets/css/knowledge-base.css" rel="stylesheet"/>
<!-- Mermaid for diagrams -->
<script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
<script>
        document.addEventListener('DOMContentLoaded', function() {
            const mermaidCodeBlocks = document.querySelectorAll('pre.codehilite code.language-mermaid, pre code.language-mermaid');

            mermaidCodeBlocks.forEach(function(codeBlock) {
                const pre = codeBlock.parentElement;
                const mermaidCode = codeBlock.textContent;

                const mermaidDiv = document.createElement('div');
                mermaidDiv.className = 'mermaid';
                mermaidDiv.textContent = mermaidCode.trim();

                pre.parentNode.replaceChild(mermaidDiv, pre);
            });

            if (typeof mermaid !== 'undefined') {
                mermaid.initialize({ startOnLoad: true, theme: 'default' });
                mermaid.init(undefined, document.querySelectorAll('.mermaid'));
            }
        });
    </script>
</head>
<body>
<nav class="breadcrumb">
<div class="breadcrumb-content">
<a href="../index.html">AI Terakoya Top</a><span class="breadcrumb-separator">‚Ä∫</span><a href="../../ML/index.html">Machine Learning</a><span class="breadcrumb-separator">‚Ä∫</span><a href="../../ML/ai-agents-introduction/index.html">AI Agents</a><span class="breadcrumb-separator">‚Ä∫</span><span class="breadcrumb-current">Chapter 1</span>
</div>
</nav><div class="locale-switcher">
<span class="current-locale">üåê EN</span>
<span class="locale-separator">|</span>

<span class="locale-meta">Last sync: 2025-11-16</span>
</div>

<header>
<div class="container">
<h1>Chapter 1: AI Agent Fundamentals</h1>
<p style="font-size: 1.1rem; margin-top: 0.5rem; opacity: 0.95;">Concepts and Design of Autonomous AI Systems</p>
<div class="meta">
<span>üìñ Reading Time: 30-35 minutes</span>
<span>üìä Difficulty: Intermediate</span>
<span>üíª Code Examples: 6</span>
</div>
</div>
</header>
<main class="container">
<h2 id="intro">What is an AI Agent?</h2>
<h3>Definition and Characteristics</h3>
<p>An <strong>AI Agent</strong> is an AI system that perceives its environment, makes autonomous decisions, and takes actions to achieve goals. Unlike traditional static AI models, agents dynamically assess situations and complete complex tasks through multiple steps.</p>
<p><strong>Key Characteristics of AI Agents</strong>:</p>
<ul>
<li><strong>Autonomy</strong>: Acts independently without human instructions</li>
<li><strong>Reactivity</strong>: Recognizes environmental changes and responds appropriately</li>
<li><strong>Goal-oriented</strong>: Plans actions toward clear objectives</li>
<li><strong>Learning</strong>: Learns and improves from experience</li>
<li><strong>Tool Use</strong>: Leverages external tools and APIs</li>
</ul>
<h3>Differences from Traditional AI</h3>
<table>
<thead>
<tr>
<th>Aspect</th>
<th>Traditional AI</th>
<th>AI Agent</th>
</tr>
</thead>
<tbody>
<tr>
<td>Input/Output</td>
<td>Single input ‚Üí Single output</td>
<td>Multi-step dialogue and actions</td>
</tr>
<tr>
<td>Decision Making</td>
<td>Immediate response generation</td>
<td>Reasoning ‚Üí Action ‚Üí Observation loop</td>
</tr>
<tr>
<td>External Integration</td>
<td>Limited or impossible</td>
<td>Utilizes tools, APIs, and search</td>
</tr>
<tr>
<td>Task Complexity</td>
<td>Simple question answering</td>
<td>Multi-stage complex tasks</td>
</tr>
<tr>
<td>Adaptability</td>
<td>Fixed behavior</td>
<td>Changes strategy based on situation</td>
</tr>
</tbody>
</table>
<h2 id="architecture">Agent Architecture</h2>
<h3>Basic Loop: Perception, Reasoning, Action</h3>
<p>AI agents achieve goals by repeating the following cycle:</p>
<div class="mermaid">
graph LR
    A[Perception] --&gt; B[Reasoning]
    B --&gt; C[Action]
    C --&gt; D[Environment]
    D --&gt; A

    style A fill:#e3f2fd
    style B fill:#fff3e0
    style C fill:#f3e5f5
    style D fill:#e8f5e9
</div>
<ol>
<li><strong>Perception</strong>: Observe environmental state, user input, and previous action results</li>
<li><strong>Reasoning</strong>: Plan next action based on observed information</li>
<li><strong>Action</strong>: Execute tools, generate responses, perform tasks</li>
<li><strong>Environment</strong>: Action results reflected in environment, leading to next perception</li>
</ol>
<h3>Key Agent Components</h3>
<pre><code class="language-python"># Basic agent structure
class Agent:
    def __init__(self, llm, tools, memory):
        self.llm = llm              # Large language model (reasoning engine)
        self.tools = tools          # Available tool set
        self.memory = memory        # Conversation history and state
        self.max_iterations = 10    # Maximum execution count

    def run(self, task):
        """Agent execution loop"""
        self.memory.add_message("user", task)

        for i in range(self.max_iterations):
            # 1. Reasoning: Determine next action
            thought = self.think()

            # 2. Action: Execute tool or provide answer
            if thought.action:
                observation = self.act(thought.action)
                self.memory.add_observation(observation)
            else:
                return thought.answer

        return "Could not complete task"

    def think(self):
        """Reason about next action using LLM"""
        prompt = self.build_prompt()
        response = self.llm.generate(prompt)
        return self.parse_response(response)

    def act(self, action):
        """Execute tool and get result"""
        tool = self.tools[action.tool_name]
        result = tool.execute(action.parameters)
        return result
</code></pre>
<h2 id="react">ReAct Pattern</h2>
<h3>Integration of Reasoning and Acting</h3>
<p><strong>ReAct</strong> (Reasoning and Acting) is an agent pattern proposed by Yao et al. (2022) that determines actions while verbalizing the reasoning process.</p>
<p><strong>ReAct Steps</strong>:</p>
<ol>
<li><strong>Thought</strong>: Analyze current situation and consider next action</li>
<li><strong>Action</strong>: Select tool and determine parameters</li>
<li><strong>Observation</strong>: Confirm tool execution results</li>
<li>Repeat ‚Üí Eventually provide Answer</li>
</ol>
<h3>Example ReAct Prompt</h3>
<pre><code class="language-python">REACT_PROMPT = """You are an assistant that answers questions. Please repeat thinking and acting in the following format.

Available tools:
- search: Execute web search (input: search query)
- calculator: Calculate mathematical expressions (input: expression)
- finish: Return final answer (input: answer text)

Format:
Question: User's question
Thought: What you are thinking
Action: tool_name[input]
Observation: Tool execution result
... (repeat as needed)
Thought: Final conclusion
Action: finish[final answer]

Question: {question}
Thought:"""

# Execution example
question = "Who won the 2024 Nobel Prize in Physics?"
response = """
Thought: I need to search the web for the latest Nobel Prize information
Action: search[2024 Nobel Prize in Physics winner]
Observation: The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton. Their foundational research in machine learning was recognized.
Thought: The winner has been identified from the search results
Action: finish[The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton. They were recognized for their contributions to the theoretical foundation of machine learning, particularly neural networks.]
"""
</code></pre>
<h3>ReAct Agent Implementation</h3>
<pre><code class="language-python">import re
from openai import OpenAI

class ReActAgent:
    def __init__(self, api_key):
        self.client = OpenAI(api_key=api_key)
        self.tools = {
            "search": self.mock_search,
            "calculator": self.calculator
        }

    def mock_search(self, query):
        """Mock search (use SerpAPI etc. in practice)"""
        # In actual implementation, call web search API
        return f"Search results: Information about {query}"

    def calculator(self, expression):
        """Calculator tool"""
        try:
            result = eval(expression)
            return f"Calculation result: {result}"
        except Exception as e:
            return f"Error: {str(e)}"

    def run(self, question, max_steps=5):
        """Execute ReAct loop"""
        prompt = REACT_PROMPT.format(question=question)

        for step in range(max_steps):
            # Generate next action with LLM
            response = self.client.chat.completions.create(
                model="gpt-4",
                messages=[{"role": "user", "content": prompt}],
                temperature=0
            )

            text = response.choices[0].message.content
            prompt += text

            # Extract Action
            action_match = re.search(r'Action: (\w+)\[(.*?)\]', text)
            if not action_match:
                continue

            tool_name = action_match.group(1)
            tool_input = action_match.group(2)

            # Check for termination
            if tool_name == "finish":
                return tool_input

            # Execute tool
            if tool_name in self.tools:
                observation = self.tools[tool_name](tool_input)
                prompt += f"\nObservation: {observation}\nThought:"
            else:
                prompt += f"\nObservation: Error - tool {tool_name} does not exist\nThought:"

        return "Reached maximum steps"

# Usage example
agent = ReActAgent(api_key="your-api-key")
answer = agent.run("Please calculate 123 + 456")
print(answer)  # Output: 579
</code></pre>
<h2 id="cot">Chain-of-Thought</h2>
<h3>Step-by-Step Reasoning Process</h3>
<p><strong>Chain-of-Thought (CoT)</strong> is a technique that breaks down complex problems into steps for reasoning. Proposed by Wei et al. (2022), it is especially effective for tasks requiring mathematical reasoning and logical thinking.</p>
<p><strong>Benefits of CoT</strong>:</p>
<ul>
<li>‚úÖ <strong>Improved Accuracy</strong>: Higher correct answer rate for complex problems</li>
<li>‚úÖ <strong>Interpretability</strong>: Reasoning process is visualized</li>
<li>‚úÖ <strong>Error Detection</strong>: Thinking process can be reviewed</li>
<li>‚úÖ <strong>Easy Debugging</strong>: Can identify where mistakes occurred</li>
</ul>
<h3>Few-shot CoT Prompt</h3>
<pre><code class="language-python">COT_PROMPT = """Please solve problems step by step as in the examples below.

Q: At a cafe, coffee is 300 yen per cup and cake is 450 yen per piece. How much does it cost to buy 2 cups of coffee and 3 pieces of cake?
A: First, calculate the total for coffee: 300 yen √ó 2 cups = 600 yen
Next, calculate the total for cake: 450 yen √ó 3 pieces = 1,350 yen
Finally, add them together: 600 yen + 1,350 yen = 1,950 yen
Answer: 1,950 yen

Q: {question}
A: Let's think step by step."""

# Implementation example
from openai import OpenAI

def chain_of_thought(question, api_key):
    """Reasoning using CoT"""
    client = OpenAI(api_key=api_key)

    prompt = COT_PROMPT.format(question=question)

    response = client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}],
        temperature=0
    )

    return response.choices[0].message.content

# Usage example
question = "There are 12 apples. You gave 3 to a friend and bought 8 more. How many apples are there now?"
answer = chain_of_thought(question, "your-api-key")
print(answer)
# Output:
# First, calculate apples after giving some away: 12 - 3 = 9
# Next, add the newly bought apples: 9 + 8 = 17
# Answer: 17
</code></pre>
<h3>Zero-shot CoT ("Let's think step by step")</h3>
<p>Kojima et al. (2022) discovered that the magic phrase "Let's think step by step" can elicit step-by-step reasoning without providing examples.</p>
<pre><code class="language-python">def zero_shot_cot(question, api_key):
    """Zero-shot CoT: Step-by-step reasoning without examples"""
    client = OpenAI(api_key=api_key)

    # Step 1: Generate reasoning process
    prompt1 = f"{question}\n\nLet's think step by step."

    response1 = client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt1}],
        temperature=0
    )

    reasoning = response1.choices[0].message.content

    # Step 2: Extract final answer from reasoning
    prompt2 = f"{question}\n\n{reasoning}\n\nTherefore, the answer is:"

    response2 = client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt2}],
        temperature=0
    )

    answer = response2.choices[0].message.content

    return {
        "reasoning": reasoning,
        "answer": answer
    }

# Usage example
result = zero_shot_cot(
    "When 5 is added to 3 times a certain number, the result is 23. What is the number?",
    "your-api-key"
)
print(f"Reasoning: {result['reasoning']}")
print(f"Answer: {result['answer']}")
</code></pre>
<h2 id="basic-implementation">Basic Agent Implementation</h2>
<h3>Simple Agent Loop</h3>
<pre><code class="language-python">import json
from openai import OpenAI
from typing import List, Dict, Any

class SimpleAgent:
    """Simple AI agent implementation"""

    def __init__(self, api_key: str, tools: Dict[str, callable]):
        self.client = OpenAI(api_key=api_key)
        self.tools = tools
        self.conversation_history = []
        self.system_prompt = """You are a capable AI assistant.
Use tools as needed to answer user questions.

Available tools:
{tool_descriptions}

Thinking process:
1. Understand the question
2. Select necessary tools
3. Execute tools
4. Integrate results and respond"""

    def get_tool_descriptions(self) -&gt; str:
        """Generate tool descriptions"""
        descriptions = []
        for name, func in self.tools.items():
            desc = func.__doc__ or "No description"
            descriptions.append(f"- {name}: {desc}")
        return "\n".join(descriptions)

    def run(self, user_input: str, max_iterations: int = 5) -&gt; str:
        """Execute agent"""
        self.conversation_history.append({
            "role": "user",
            "content": user_input
        })

        for iteration in range(max_iterations):
            # Query LLM
            response = self.client.chat.completions.create(
                model="gpt-4",
                messages=[
                    {
                        "role": "system",
                        "content": self.system_prompt.format(
                            tool_descriptions=self.get_tool_descriptions()
                        )
                    }
                ] + self.conversation_history,
                temperature=0
            )

            assistant_message = response.choices[0].message.content

            # Parse tool call
            tool_call = self.parse_tool_call(assistant_message)

            if tool_call:
                # Execute tool
                tool_name = tool_call["name"]
                tool_args = tool_call["args"]

                if tool_name in self.tools:
                    result = self.tools[tool_name](**tool_args)

                    # Add result to conversation history
                    self.conversation_history.append({
                        "role": "assistant",
                        "content": f"Executed tool {tool_name}"
                    })
                    self.conversation_history.append({
                        "role": "user",
                        "content": f"Result: {result}"
                    })
                else:
                    # Unknown tool
                    self.conversation_history.append({
                        "role": "user",
                        "content": f"Error: Tool {tool_name} does not exist"
                    })
            else:
                # No tool call = final answer
                return assistant_message

        return "Reached maximum iterations"

    def parse_tool_call(self, message: str) -&gt; Dict[str, Any]:
        """Extract tool call from message (simplified version)"""
        # In practice, a more robust parser is needed
        import re
        match = re.search(r'TOOL: (\w+)\((.*?)\)', message)
        if match:
            tool_name = match.group(1)
            args_str = match.group(2)
            # Simple argument parsing
            args = {}
            if args_str:
                for arg in args_str.split(','):
                    key, value = arg.split('=')
                    args[key.strip()] = value.strip().strip('"\'')
            return {"name": tool_name, "args": args}
        return None

# Tool definitions
def get_weather(location: str) -&gt; str:
    """Get weather for specified location"""
    # In practice, call API
    weather_data = {
        "Tokyo": "Sunny, 22¬∞C",
        "Osaka": "Cloudy, 20¬∞C",
        "Sapporo": "Rainy, 15¬∞C"
    }
    return weather_data.get(location, "No data")

def calculate(expression: str) -&gt; float:
    """Calculate mathematical expression"""
    try:
        result = eval(expression)
        return result
    except Exception as e:
        return f"Calculation error: {str(e)}"

# Execute agent
agent = SimpleAgent(
    api_key="your-api-key",
    tools={
        "get_weather": get_weather,
        "calculate": calculate
    }
)

response = agent.run("Tell me the weather in Tokyo")
print(response)
</code></pre>
<h2 id="prompt-engineering">Prompt Engineering for Agents</h2>
<h3>Designing Effective System Prompts</h3>
<p>Agent behavior is greatly influenced by the system prompt. Here are best practices for effective prompt design.</p>
<h4>1. Clear Role Definition</h4>
<pre><code class="language-python">SYSTEM_PROMPT = """You are a customer support agent.

Role:
- Accurately understand user problems
- Collect information using appropriate tools
- Provide friendly and professional responses

Important constraints:
- Do not speculate on uncertain information
- Handle personal information carefully
- Escalate appropriately when errors occur
"""
</code></pre>
<h4>2. Tool Usage Guidelines</h4>
<pre><code class="language-python">TOOL_USAGE_GUIDE = """
Available tools:

1. search_database(query: str) -&gt; List[Dict]
   - Search database for relevant information
   - Use cases: Product information, order history search

2. send_email(to: str, subject: str, body: str) -&gt; bool
   - Send email
   - Use cases: Confirmation emails, notifications

3. escalate_to_human(reason: str) -&gt; None
   - Escalate to human operator
   - Use cases: Complex issues, complaint handling

Tool selection principles:
- First collect necessary information with search_database
- Generate response if automatic handling is possible
- Use escalate_to_human for complex or important cases
"""
</code></pre>
<h4>3. Few-shot Examples</h4>
<pre><code class="language-python">FEW_SHOT_EXAMPLES = """
Example 1:
User: Please tell me the delivery status of order number 12345
Thought: Need to search order information from database
Action: search_database(query="order_number:12345")
Observation: {order_id: 12345, status: "in_transit", tracking: "ABC123"}
Response: Your order 12345 is currently in transit. The tracking number is ABC123.

Example 2:
User: I would like a refund
Thought: Refunds involve important financial processing, should hand over to human
Action: escalate_to_human(reason="refund request")
Response: I understand you'd like a refund. Let me connect you with a representative.
"""
</code></pre>
<h2 id="summary">Summary</h2>
<h3>What We Learned in This Chapter</h3>
<ul>
<li>‚úÖ <strong>AI Agent Definition</strong>: Autonomy, reactivity, goal-orientation, tool use</li>
<li>‚úÖ <strong>Agent Architecture</strong>: Perception ‚Üí Reasoning ‚Üí Action loop</li>
<li>‚úÖ <strong>ReAct Pattern</strong>: Agent design integrating reasoning and action</li>
<li>‚úÖ <strong>Chain-of-Thought</strong>: Improved accuracy through step-by-step reasoning</li>
<li>‚úÖ <strong>Basic Implementation</strong>: Building simple agent loops</li>
<li>‚úÖ <strong>Prompt Design</strong>: Effective prompts for agents</li>
</ul>
<h3>Key Concepts</h3>
<blockquote>
<p><strong>Agent = LLM + Tools + Reasoning Loop</strong></p>
<p>AI agents autonomously solve complex tasks by combining the reasoning capabilities of large language models with external tools, repeating multi-step thinking and action.</p>
</blockquote>
<h3>Next Steps</h3>
<p>In Chapter 2, we will learn in detail about Function Calling and Tool Use:</p>
<ul>
<li>OpenAI/Anthropic Function Calling API</li>
<li>Tool schema definition</li>
<li>External API integration and error handling</li>
<li>Practical tool implementation patterns</li>
</ul>
<div class="nav-buttons">
<a class="nav-button" href="./index.html">‚Üê Series Overview</a>
<a class="nav-button" href="./chapter2-tool-use.html">Chapter 2: Tool Use ‚Üí</a>
</div>
</main>
<div class="feedback-notice">
<h3>‚ö†Ô∏è Help Us Improve Content Quality</h3>
<p>This content was created with AI assistance. If you find errors or areas for improvement, please report them using one of the following methods:</p>
<div class="feedback-options">
<a class="feedback-button" href="https://forms.gle/9GfVBa2Qa7Uy9taQA" target="_blank">
                    üìù Correction Request Form
                </a>
<a class="feedback-button" href="mailto:yusuke.hashimoto.d8@tohoku.ac.jp">
                    ‚úâÔ∏è Contact by Email
                </a>
</div>
</div>
<footer>
<div class="container">
<p>¬© 2025 AI Terakoya - Dr. Yusuke Hashimoto, Tohoku University</p>
<p>Licensed under CC BY 4.0</p>
</div>
</footer>
</body>
</html>
