<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8"/>
<meta content="Chapter 2: Image Classification and Deep Learning - AI Terakoya" name="description"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>Chapter 2: Image Classification and Deep Learning - AI Terakoya</title>
<link href="../../assets/css/knowledge-base.css" rel="stylesheet"/>
<script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
        mermaid.initialize({ startOnLoad: true, theme: 'default' });
    </script>
<!-- MathJax for LaTeX equation rendering -->
<script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                displayMath: [['$$', '$$'], ['\\[', '\\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
                ignoreHtmlClass: 'mermaid'
            }
        };
    </script>
<script async="" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>
<nav class="breadcrumb">
<div class="breadcrumb-content">
<a href="../index.html">AI Terakoya Top</a><span class="breadcrumb-separator">‚Ä∫</span><a href="../../ML/index.html">Machine Learning</a><span class="breadcrumb-separator">‚Ä∫</span><a href="../../ML/computer-vision-introduction/index.html">Computer Vision</a><span class="breadcrumb-separator">‚Ä∫</span><span class="breadcrumb-current">Chapter 2</span>
</div>
</nav><div class="locale-switcher">
<span class="current-locale">üåê EN</span>
<span class="locale-separator">|</span>
<a href="../../../jp/ML/computer-vision-introduction/chapter2-image-classification.html" class="locale-link">üáØüáµ JP</a>
<span class="locale-separator">|</span>
<span class="locale-meta">Last sync: 2025-11-16</span>
</div>
<header>
<div class="header-content">
<h1>Chapter 2: Image Classification and Deep Learning</h1>
<p class="subtitle">Building High-Accuracy Image Classification Systems with CNN Architectures and Transfer Learning</p>
<div class="meta">
<span class="meta-item">üìñ Reading Time: 30-35 minutes</span>
<span class="meta-item">üìä Difficulty: Intermediate</span>
<span class="meta-item">üíª Code Examples: 10</span>
<span class="meta-item">üìù Exercises: 5</span>
</div>
</div>
</header>
<main class="container">

<p class="chapter-description">This chapter covers Image Classification and Deep Learning. You will learn efficient design principles of Inception and EfficientNet's Compound Scaling.</p>
<h2>Learning Objectives</h2>
<p>By reading this chapter, you will master the following:</p>
<ul>
<li>‚úÖ Understand the characteristics of major CNN architectures such as LeNet, AlexNet, VGG, and ResNet</li>
<li>‚úÖ Explain the efficient design principles of Inception and MobileNet</li>
<li>‚úÖ Understand EfficientNet's Compound Scaling</li>
<li>‚úÖ Master the differences and applications of Transfer Learning and Fine-tuning</li>
<li>‚úÖ Learn how to utilize pre-trained models using torchvision.models</li>
<li>‚úÖ Implement techniques to improve generalization performance through Data Augmentation</li>
<li>‚úÖ Utilize training techniques such as Learning Rate Scheduling, TTA, and Model Ensemble</li>
<li>‚úÖ Complete practical image classification projects</li>
</ul>
<hr/>
<h2>2.1 Evolution of CNN Architectures</h2>
<h3>Historical Development of Image Classification</h3>
<p>Image classification is one of the most fundamental and important tasks in computer vision. With the advent of deep learning, the accuracy of image classification has dramatically improved.</p>
<div class="mermaid">
graph LR
    A[LeNet-5<br/>1998<br/>MNIST] --&gt; B[AlexNet<br/>2012<br/>ImageNet]
    B --&gt; C[VGG<br/>2014<br/>19 layers deep]
    C --&gt; D[GoogLeNet<br/>2014<br/>Inception]
    D --&gt; E[ResNet<br/>2015<br/>Residual connections]
    E --&gt; F[Inception-v4<br/>2016<br/>Hybrid]
    F --&gt; G[MobileNet<br/>2017<br/>Lightweight]
    G --&gt; H[EfficientNet<br/>2019<br/>Optimization]
    H --&gt; I[Vision Transformer<br/>2020+<br/>Attention]

    style A fill:#e1f5ff
    style B fill:#b3e5fc
    style C fill:#81d4fa
    style D fill:#4fc3f7
    style E fill:#29b6f6
    style F fill:#03a9f4
    style G fill:#039be5
    style H fill:#0288d1
    style I fill:#0277bd
</div>
<h3>LeNet-5 (1998): The Origin of CNNs</h3>
<p><strong>LeNet-5</strong> was developed by Yann LeCun for handwritten digit recognition and became the foundation of modern CNNs.</p>
<pre><code class="language-python"># Requirements:
# - Python 3.9+
# - torch&gt;=2.0.0, &lt;2.3.0

import torch
import torch.nn as nn
import torch.nn.functional as F

class LeNet5(nn.Module):
    """LeNet-5: Classical CNN for handwritten digit recognition"""
    def __init__(self, num_classes=10):
        super(LeNet5, self).__init__()

        # Feature extraction layers
        self.conv1 = nn.Conv2d(1, 6, kernel_size=5)    # 28√ó28 ‚Üí 24√ó24
        self.pool1 = nn.AvgPool2d(kernel_size=2)       # 24√ó24 ‚Üí 12√ó12
        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)   # 12√ó12 ‚Üí 8√ó8
        self.pool2 = nn.AvgPool2d(kernel_size=2)       # 8√ó8 ‚Üí 4√ó4

        # Classification layers
        self.fc1 = nn.Linear(16 * 4 * 4, 120)
        self.fc2 = nn.Linear(120, 84)
        self.fc3 = nn.Linear(84, num_classes)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        x = self.pool1(x)
        x = F.relu(self.conv2(x))
        x = self.pool2(x)

        x = x.view(x.size(0), -1)  # Flatten

        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)

        return x

# Model instantiation and testing
model = LeNet5(num_classes=10)
x = torch.randn(1, 1, 28, 28)
output = model(x)

print(f"LeNet-5")
print(f"Input: {x.shape} ‚Üí Output: {output.shape}")
print(f"Parameters: {sum(p.numel() for p in model.parameters()):,}")
</code></pre>
<h3>AlexNet (2012): The Deep Learning Revolution</h3>
<p><strong>AlexNet</strong> won the 2012 ImageNet Large Scale Visual Recognition Challenge (ILSVRC) and sparked the deep learning boom.</p>
<p>Main innovations:</p>
<ul>
<li><strong>ReLU activation function</strong>: Faster learning than Sigmoid</li>
<li><strong>Dropout</strong>: Preventing overfitting</li>
<li><strong>Data Augmentation</strong>: Improving generalization performance</li>
<li><strong>GPU parallel processing</strong>: Enabling training of large-scale models</li>
</ul>
<pre><code class="language-python"># Requirements:
# - Python 3.9+
# - torch&gt;=2.0.0, &lt;2.3.0

import torch
import torch.nn as nn

class AlexNet(nn.Module):
    """AlexNet: ImageNet 2012 winning model"""
    def __init__(self, num_classes=1000):
        super(AlexNet, self).__init__()

        # Feature extraction layers
        self.features = nn.Sequential(
            # Conv1: 96 filters, 11√ó11, stride=4
            nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=2),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=3, stride=2),

            # Conv2: 256 filters, 5√ó5
            nn.Conv2d(96, 256, kernel_size=5, padding=2),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=3, stride=2),

            # Conv3: 384 filters, 3√ó3
            nn.Conv2d(256, 384, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),

            # Conv4: 384 filters, 3√ó3
            nn.Conv2d(384, 384, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),

            # Conv5: 256 filters, 3√ó3
            nn.Conv2d(384, 256, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=3, stride=2),
        )

        # Classification layers
        self.classifier = nn.Sequential(
            nn.Dropout(p=0.5),
            nn.Linear(256 * 6 * 6, 4096),
            nn.ReLU(inplace=True),
            nn.Dropout(p=0.5),
            nn.Linear(4096, 4096),
            nn.ReLU(inplace=True),
            nn.Linear(4096, num_classes),
        )

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.classifier(x)
        return x

# Check model size
model = AlexNet(num_classes=1000)
total_params = sum(p.numel() for p in model.parameters())
print(f"\nAlexNet Total Parameters: {total_params:,}")
print(f"Memory Usage: approx {total_params * 4 / (1024**2):.1f} MB")
</code></pre>
<section class="disclaimer">
<h3>Disclaimer</h3>
<ul>
<li>This content is provided solely for educational, research, and informational purposes and does not constitute professional advice (legal, accounting, technical warranty, etc.).</li>
<li>This content and accompanying code examples are provided "AS IS" without any warranty, express or implied, including but not limited to merchantability, fitness for a particular purpose, non-infringement, accuracy, completeness, operation, or safety.</li>
<li>The author and Tohoku University assume no responsibility for the content, availability, or safety of external links, third-party data, tools, libraries, etc.</li>
<li>To the maximum extent permitted by applicable law, the author and Tohoku University shall not be liable for any direct, indirect, incidental, special, consequential, or punitive damages arising from the use, execution, or interpretation of this content.</li>
<li>The content may be changed, updated, or discontinued without notice.</li>
<li>The copyright and license of this content are subject to the stated conditions (e.g., CC BY 4.0). Such licenses typically include no-warranty clauses.</li>
</ul>
</section>

</main></body></html>