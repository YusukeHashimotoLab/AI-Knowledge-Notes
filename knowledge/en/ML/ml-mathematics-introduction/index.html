<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Introduction to Mathematics for Machine Learning Series - Complete Guide to Probability and Statistics, Linear Algebra, and Optimization Theory">
    <title>Introduction to Mathematics for Machine Learning Series v1.0 - AI Terakoya</title>
        <link rel="stylesheet" href="../../assets/css/knowledge-base.css">
</head>
<body>
            <nav class="breadcrumb">
        <div class="breadcrumb-content">
            <a href="../../index.html">AI Terakoya Home</a><span class="breadcrumb-separator">‚Ä∫</span><a href="../index.html">Machine Learning</a><span class="breadcrumb-separator">‚Ä∫</span><span class="breadcrumb-current">ML Mathematics</span>
        </div>
    </nav>

        <header>
        <div class="container">
            <h1>üìê Introduction to Mathematics for Machine Learning Series v1.0</h1>
            <p style="font-size: 1.1rem; margin-top: 0.5rem; opacity: 0.95;">Probability and Statistics, Linear Algebra, and Optimization Theory</p>
            <div class="meta">
                <span>üìñ Total Learning Time: 150-180 minutes</span>
                <span>üìä Level: Advanced</span>
                <span>üéØ Course ID: ML-P05</span>
            </div>
        </div>
    </header>

    <main class="container">
        <p><strong>Gain a deep mathematical understanding of machine learning and develop theory-based implementation skills</strong></p>

        <h2>Series Overview</h2>
        <p>This series is an advanced educational content consisting of 5 chapters that teaches the mathematical foundations of machine learning from both theoretical and implementation perspectives.</p>

        <p><strong>Features:</strong></p>
        <ul>
            <li>‚úÖ <strong>Integration of Theory and Implementation</strong>: Progressive learning from mathematical definitions to implementation</li>
            <li>‚úÖ <strong>Over 30 Implementation Examples</strong>: Implementations using NumPy/SciPy/PyTorch</li>
            <li>‚úÖ <strong>Systematic Coverage</strong>: Probability and statistics, linear algebra, optimization, information theory, and learning theory</li>
            <li>‚úÖ <strong>Practical Applications</strong>: Concrete applications of each theory to machine learning</li>
        </ul>

        <h2>Chapter Details</h2>

        <h3><a href="./chapter1-probability-statistics.html">Chapter 1: Fundamentals of Probability and Statistics</a></h3>
        <p><strong>Difficulty</strong>: Advanced | <strong>Learning Time</strong>: 30-35 minutes | <strong>Code Examples</strong>: 6</p>
        <h4>Learning Content</h4>
        <ol>
            <li>Probability Foundations - Bayes' theorem, conditional probability</li>
            <li>Probability Distributions - Normal distribution, multivariate normal distribution</li>
            <li>Expected Value and Variance - Covariance, correlation coefficient</li>
            <li>Maximum Likelihood Estimation and Bayesian Estimation - MAP estimation</li>
            <li>Practical Applications: Naive Bayes, GMM, Bayesian linear regression</li>
        </ol>
        <p><strong><a href="./chapter1-probability-statistics.html">Read Chapter 1 ‚Üí</a></strong></p>

        <hr>

        <h3><a href="./chapter2-linear-algebra.html">Chapter 2: Fundamentals of Linear Algebra</a></h3>
        <p><strong>Difficulty</strong>: Advanced | <strong>Learning Time</strong>: 30-35 minutes | <strong>Code Examples</strong>: 6</p>
        <h4>Learning Content</h4>
        <ol>
            <li>Vectors and Matrices - Inner product, norm, matrix operations</li>
            <li>Matrix Decomposition - Eigenvalue decomposition, SVD, QR decomposition</li>
            <li>Principal Component Analysis (PCA) - Mathematics of dimensionality reduction</li>
            <li>Linear Transformations and Projections - Geometry of least squares</li>
            <li>Practical Applications: Linear regression, Ridge regression, image PCA</li>
        </ol>
        <p><strong><a href="./chapter2-linear-algebra.html">Read Chapter 2 ‚Üí</a></strong></p>

        <hr>

        <h3><a href="./chapter3-optimization.html">Chapter 3: Optimization Theory</a></h3>
        <p><strong>Difficulty</strong>: Advanced | <strong>Learning Time</strong>: 30-40 minutes | <strong>Code Examples</strong>: 6</p>
        <h4>Learning Content</h4>
        <ol>
            <li>Optimization Foundations - Convex functions, gradients, Hessian</li>
            <li>Gradient Descent - Momentum, Adam, convergence</li>
            <li>Constrained Optimization - Lagrange multipliers, KKT conditions</li>
            <li>Convex Optimization - Linear programming, quadratic programming</li>
            <li>Practical Applications: Logistic regression, NN training, regularization</li>
        </ol>
        <p><strong><a href="./chapter3-optimization.html">Read Chapter 3 ‚Üí</a></strong></p>

        <hr>

        <h3><a href="./chapter4-information-theory.html">Chapter 4: Information Theory</a></h3>
        <p><strong>Difficulty</strong>: Advanced | <strong>Learning Time</strong>: 25-30 minutes | <strong>Code Examples</strong>: 6</p>
        <h4>Learning Content</h4>
        <ol>
            <li>Entropy - Information content, conditional entropy</li>
            <li>KL Divergence and Cross Entropy</li>
            <li>Mutual Information - Applications to feature selection</li>
            <li>Information Theory and Machine Learning - VAE, information bottleneck</li>
            <li>Practical Applications: Cross entropy loss, KL loss, ELBO</li>
        </ol>
        <p><strong><a href="./chapter4-information-theory.html">Read Chapter 4 ‚Üí</a></strong></p>

        <hr>

        <h3><a href="./chapter5-learning-theory.html">Chapter 5: Learning Theory in Machine Learning</a></h3>
        <p><strong>Difficulty</strong>: Advanced | <strong>Learning Time</strong>: 35-40 minutes | <strong>Code Examples</strong>: 6</p>
        <h4>Learning Content</h4>
        <ol>
            <li>PAC Learning - Learnability, sample complexity</li>
            <li>VC Dimension - Shattering, generalization error</li>
            <li>Bias-Variance Decomposition - Trade-offs</li>
            <li>Regularization Theory - L1/L2 regularization, Elastic Net</li>
            <li>Practical Applications: Early stopping, dropout, data augmentation</li>
        </ol>
        <p><strong><a href="./chapter5-learning-theory.html">Read Chapter 5 ‚Üí</a></strong></p>

        <hr>

        <h2>Prerequisites</h2>
        <h3>Required (Must Have)</h3>
        <ul>
            <li>‚úÖ Calculus Basics - Partial derivatives, multivariable functions</li>
            <li>‚úÖ Linear Algebra Introduction - Matrix operations, vector spaces</li>
            <li>‚úÖ Probability Theory Introduction - Random variables, expected value</li>
            <li>‚úÖ Intermediate Python - NumPy, basic numerical computing</li>
        </ul>

        <h2>Technologies Used</h2>
        <ul>
            <li><strong>NumPy 1.24+</strong> - Numerical computing</li>
            <li><strong>SciPy 1.10+</strong> - Scientific computing</li>
            <li><strong>PyTorch 2.0+</strong> - Deep learning</li>
            <li><strong>Matplotlib 3.7+</strong> - Visualization</li>
            <li><strong>scikit-learn 1.3+</strong> - Machine learning</li>
        </ul>

        <div class="nav-buttons">
            <a href="../index.html" class="nav-button">‚Üê Return to ML Series List</a>
            <a href="./chapter1-probability-statistics.html" class="nav-button">Start Chapter 1 ‚Üí</a>
        </div>

        <hr>
        <p><strong>Update History</strong></p>
        <ul>
            <li><strong>2025-10-23</strong>: v1.0 Initial release</li>
        </ul>
    </main>


        <div class="feedback-notice">
            <h3>‚ö†Ô∏è Please Help Us Improve Content Quality</h3>
            <p>This content was created with AI assistance. If you find any errors or areas for improvement, please report them using one of the following methods:</p>
            <div class="feedback-options">
                <a href="https://forms.gle/9GfVBa2Qa7Uy9taQA" target="_blank" class="feedback-button">
                    üìù Correction Request Form
                </a>
                <a href="mailto:yusuke.hashimoto.d8@tohoku.ac.jp" class="feedback-button">
                    ‚úâÔ∏è Contact by Email
                </a>
            </div>
        </div>

    <footer>
        <div class="container">
            <p>&copy; 2025 AI Terakoya - Dr. Yusuke Hashimoto, Tohoku University</p>
            <p>Licensed under CC BY 4.0</p>
        </div>
    </footer>
</body>
</html>
