<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Supervised Learning Introduction Series - Complete Guide to Regression, Classification, and Ensemble Methods">
    <title>Supervised Learning Introduction Series v1.0 - AI Terakoya</title>

    <!-- CSS Styling -->
        <link rel="stylesheet" href="../../assets/css/knowledge-base.css">

    <!-- Mermaid for diagrams -->
    <script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
    <script>
        // Mermaid.js initialization
        document.addEventListener('DOMContentLoaded', function() {
            if (typeof mermaid !== 'undefined') {
                mermaid.initialize({ startOnLoad: true, theme: 'default' });
            }
        });
    </script>
</head>
<body>
            <nav class="breadcrumb">
        <div class="breadcrumb-content">
            <a href="../../index.html">AI Terakoya Top</a><span class="breadcrumb-separator">‚Ä∫</span><a href="../index.html">Machine Learning</a><span class="breadcrumb-separator">‚Ä∫</span><span class="breadcrumb-current">Supervised Learning</span>
        </div>
    </nav>

        <header>
        <div class="container">
            <h1>üìä Supervised Learning Introduction Series v1.0</h1>
            <p class="subtitle">Complete Guide to Regression, Classification, and Ensemble Methods</p>
            <div class="meta">
                <span>üìñ Total Learning Time: 80-100 minutes</span>
                <span>üìä Level: Beginner to Intermediate</span>
                <span>üíª Code Examples: 40+</span>
                <span>üìù Chapters: 4</span>
            </div>
        </div>
    </header>

    <main class="container">
        <p><strong>From ML Fundamentals to Practice - Building Predictive Models that Learn from Data</strong></p>

        <h2 id="overview">Series Overview</h2>
        <p>This series is a practical educational content with 4 chapters that teaches <strong>Supervised Learning</strong> progressively from the basics.</p>

        <p><strong>Supervised Learning</strong> is a fundamental machine learning technique that learns from labeled data and makes predictions on unseen data. From the two main tasks of regression (numerical prediction) and classification (category prediction) to state-of-the-art ensemble methods, you'll master practical skills used in real-world applications.</p>

        <p><strong>Features:</strong></p>
        <ul>
            <li>‚úÖ <strong>Balance of Theory and Practice</strong>: Learn both mathematical background and implementation code</li>
            <li>‚úÖ <strong>Implementation Focused</strong>: Over 40 executable Python code examples</li>
            <li>‚úÖ <strong>Latest Techniques</strong>: XGBoost, LightGBM, CatBoost and other techniques used in practice</li>
            <li>‚úÖ <strong>Practical Projects</strong>: Complete implementation of housing price prediction and customer churn prediction</li>
            <li>‚úÖ <strong>Kaggle Preparation</strong>: Master techniques usable in competitions</li>
        </ul>

        <p><strong>Total Learning Time</strong>: 80-100 minutes (including code execution and exercises)</p>

        <h2 id="learning">How to Learn</h2>

        <h3>Recommended Learning Path</h3>

        <div class="mermaid">
graph TD
    A[Chapter 1: Regression Fundamentals] --> B[Chapter 2: Classification Fundamentals]
    B --> C[Chapter 3: Ensemble Methods]
    C --> D[Chapter 4: Practical Projects]

    style A fill:#e3f2fd
    style B fill:#fff3e0
    style C fill:#f3e5f5
    style D fill:#e8f5e9
        </div>

        <div class="learning-path">
            <h4>üéØ Complete Mastery Course (All Chapters Recommended)</h4>
            <p><strong>Target</strong>: ML beginners, those wanting systematic learning</p>
            <p><strong>Path</strong>: Chapter 1 ‚Üí Chapter 2 ‚Üí Chapter 3 ‚Üí Chapter 4</p>
            <p><strong>Duration</strong>: 80-100 minutes</p>
            <p><strong>Outcomes</strong>: Master from regression/classification basics to latest ensemble methods, complete 2 practical projects</p>
        </div>

        <div class="learning-path">
            <h4>‚ö° Fast Track Course (Practice Focused)</h4>
            <p><strong>Target</strong>: Those with basic knowledge, wanting to strengthen practical skills</p>
            <p><strong>Path</strong>: Chapter 3 (Ensemble Methods) ‚Üí Chapter 4 (Practical Projects)</p>
            <p><strong>Duration</strong>: 50-60 minutes</p>
            <p><strong>Outcomes</strong>: Master XGBoost/LightGBM/CatBoost, ready for Kaggle</p>
        </div>

        <div class="learning-path">
            <h4>üîç Focused Learning</h4>
            <p><strong>Target</strong>: Those wanting to learn specific topics</p>
            <ul>
                <li><strong>Regression Only</strong>: Chapter 1 (20-25 minutes)</li>
                <li><strong>Classification Only</strong>: Chapter 2 (25-30 minutes)</li>
                <li><strong>Ensemble Only</strong>: Chapter 3 (25-30 minutes)</li>
                <li><strong>Practice Only</strong>: Chapter 4 (30 minutes)</li>
            </ul>
        </div>

        <h2 id="chapters">Chapter Details</h2>

        <div class="chapter-grid">
            <div class="chapter-card ch1">
                <h3><a href="./chapter1-regression.html">Chapter 1: Regression Fundamentals</a></h3>
                <div class="chapter-meta">
                    üìñ Reading Time: 20-25 min | üíª Code Examples: 12 | üìù Exercises: 5
                </div>
                <h4>Learning Content</h4>
                <ul>
                    <li>Linear Regression Theory and Implementation</li>
                    <li>Mathematical Understanding of Least Squares</li>
                    <li>Gradient Descent Implementation</li>
                    <li>Polynomial Regression</li>
                    <li>Regularization (Ridge, Lasso, Elastic Net)</li>
                    <li>Evaluation on Real Data (R¬≤, RMSE, MAE)</li>
                </ul>
                <p><strong><a href="./chapter1-regression.html">Read Chapter 1 ‚Üí</a></strong></p>
            </div>

            <div class="chapter-card ch2">
                <h3><a href="./chapter2-classification.html">Chapter 2: Classification Fundamentals</a></h3>
                <div class="chapter-meta">
                    üìñ Reading Time: 25-30 min | üíª Code Examples: 12 | üìù Exercises: 5
                </div>
                <h4>Learning Content</h4>
                <ul>
                    <li>Logistic Regression Theory</li>
                    <li>Sigmoid Function and Probability Interpretation</li>
                    <li>Decision Tree Mechanisms</li>
                    <li>k-NN (k-Nearest Neighbors)</li>
                    <li>Support Vector Machines (SVM)</li>
                    <li>Evaluation Metrics (Accuracy, Recall, F1 Score, Confusion Matrix)</li>
                    <li>ROC Curve and AUC</li>
                </ul>
                <p><strong><a href="./chapter2-classification.html">Read Chapter 2 ‚Üí</a></strong></p>
            </div>

            <div class="chapter-card ch3">
                <h3><a href="./chapter3-ensemble.html">Chapter 3: Ensemble Methods</a></h3>
                <div class="chapter-meta">
                    üìñ Reading Time: 25-30 min | üíª Code Examples: 13 | üìù Exercises: 5
                </div>
                <h4>Learning Content</h4>
                <ul>
                    <li>Bagging Principles</li>
                    <li>Random Forest Implementation and Feature Importance</li>
                    <li>Boosting Principles</li>
                    <li>Gradient Boosting Implementation</li>
                    <li>XGBoost Practice</li>
                    <li>LightGBM Practice</li>
                    <li>CatBoost Practice</li>
                    <li>Ensemble Method Comparison</li>
                    <li>Kaggle Usage</li>
                </ul>
                <p><strong><a href="./chapter3-ensemble.html">Read Chapter 3 ‚Üí</a></strong></p>
            </div>

            <div class="chapter-card ch4">
                <h3><a href="./chapter4-projects.html">Chapter 4: Practical Projects</a></h3>
                <div class="chapter-meta">
                    üìñ Reading Time: 30 min | üíª Code Examples: 20 | üìù Exercises: 5
                </div>
                <h4>Learning Content</h4>
                <p><strong>Project 1: Housing Price Prediction (Regression)</strong></p>
                <ul>
                    <li>Data Loading and Exploratory Analysis</li>
                    <li>Feature Engineering</li>
                    <li>Model Selection and Evaluation</li>
                    <li>Hyperparameter Tuning</li>
                </ul>
                <p><strong>Project 2: Customer Churn Prediction (Classification)</strong></p>
                <ul>
                    <li>Data Preprocessing</li>
                    <li>Imbalanced Data Handling</li>
                    <li>Model Comparison</li>
                    <li>Business Impact Analysis</li>
                </ul>
                <p><strong><a href="./chapter4-projects.html">Read Chapter 4 ‚Üí</a></strong></p>
            </div>
        </div>

        <h2 id="outcomes">Overall Learning Outcomes</h2>

        <p>Upon completing this series, you will acquire the following skills and knowledge:</p>

        <h3>Knowledge Level (Understanding)</h3>
        <ul>
            <li>‚úÖ Can explain the difference between regression and classification</li>
            <li>‚úÖ Understand the mathematical background of linear and logistic regression</li>
            <li>‚úÖ Understand the mechanisms of decision trees, SVM, and k-NN</li>
            <li>‚úÖ Can explain the difference between Bagging and Boosting</li>
            <li>‚úÖ Understand the characteristics of XGBoost, LightGBM, and CatBoost</li>
            <li>‚úÖ Can explain the necessity and methods of regularization</li>
            <li>‚úÖ Can select appropriate evaluation metrics</li>
        </ul>

        <h3>Practical Skills (Doing)</h3>
        <ul>
            <li>‚úÖ Can implement linear regression from scratch with NumPy</li>
            <li>‚úÖ Can build regression/classification models with scikit-learn</li>
            <li>‚úÖ Can master XGBoost/LightGBM/CatBoost</li>
            <li>‚úÖ Can perform data preprocessing and feature engineering</li>
            <li>‚úÖ Can execute hyperparameter tuning</li>
            <li>‚úÖ Can evaluate model performance from multiple perspectives</li>
            <li>‚úÖ Can handle imbalanced data</li>
        </ul>

        <h3>Application Ability (Applying)</h3>
        <ul>
            <li>‚úÖ Can select appropriate algorithms for new problems</li>
            <li>‚úÖ Can detect and address overfitting</li>
            <li>‚úÖ Can formulate business problems as ML problems</li>
            <li>‚úÖ Can participate in Kaggle competitions</li>
            <li>‚úÖ Can build practical predictive models for real-world use</li>
        </ul>

        <h2 id="faq">Frequently Asked Questions (FAQ)</h2>

        <div class="faq">
            <h4>Q1: Can I learn without ML experience?</h4>
            <p><strong>A:</strong> Yes. By learning from Chapter 1 sequentially, you can understand progressively from the basics. Knowing Python basics (variables, functions, lists) is sufficient.</p>
        </div>

        <div class="faq">
            <h4>Q2: I'm not good at math - is that okay?</h4>
            <p><strong>A:</strong> High school-level math (calculus, linear algebra basics) is helpful. We supplement with intuitive explanations and code implementations beyond just formulas.</p>
        </div>

        <div class="faq">
            <h4>Q3: Which chapter should I start from?</h4>
            <p><strong>A:</strong> Beginners from Chapter 1, those with ML experience from Chapter 3 (Ensemble Methods), and those strengthening practical skills from Chapter 4.</p>
        </div>

        <div class="faq">
            <h4>Q4: What environment is needed?</h4>
            <p><strong>A:</strong> Python 3.7+, NumPy, pandas, scikit-learn, XGBoost, LightGBM, CatBoost, matplotlib. Using Google Colab eliminates environment setup.</p>
        </div>

        <div class="faq">
            <h4>Q5: Can I learn Kaggle-applicable techniques?</h4>
            <p><strong>A:</strong> Yes. Chapter 3 covers XGBoost/LightGBM/CatBoost, and Chapter 4 teaches feature engineering and hyperparameter tuning.</p>
        </div>

        <div class="faq">
            <h4>Q6: Will I reach a practical skill level?</h4>
            <p><strong>A:</strong> You'll master basic-level practical tasks (building, evaluating, and tuning predictive models). For more advanced techniques (deep learning, time series analysis, etc.), please refer to other series.</p>
        </div>

        <hr>

        <h2 id="start">Let's Get Started!</h2>
        <p>Are you ready? Start with Chapter 1 and begin your journey into the world of supervised learning!</p>

        <div class="nav-buttons">
            <a href="../index.html" class="nav-button">‚Üê Machine Learning Top</a>
            <a href="./chapter1-regression.html" class="nav-button">Chapter 1: Regression Fundamentals ‚Üí</a>
        </div>

        <hr>

        <p><strong>Update History</strong></p>
        <ul>
            <li><strong>2025-10-20</strong>: v1.0 Initial Release</li>
        </ul>

        <hr>

        <p><strong>Your supervised learning journey starts here!</strong></p>

    </main>


    <section class="disclaimer">
        <h3>Disclaimer</h3>
        <ul>
            <li>This content is provided for educational, research, and informational purposes only and does not constitute professional advice (legal, accounting, technical guarantees, etc.).</li>
            <li>This content and accompanying code examples are provided "AS IS" without any warranties, express or implied, including but not limited to merchantability, fitness for a particular purpose, non-infringement, accuracy, completeness, operation, or safety.</li>
            <li>The author and Tohoku University assume no responsibility for the content, availability, or safety of external links, data, tools, or libraries provided by third parties.</li>
            <li>To the maximum extent permitted by applicable law, the author and Tohoku University shall not be liable for any direct, indirect, incidental, special, consequential, or punitive damages arising from the use, execution, or interpretation of this content.</li>
            <li>The content of this material may be changed, updated, or discontinued without notice.</li>
            <li>The copyright and license of this content follow the specified conditions (e.g., CC BY 4.0), which typically include a no-warranty clause.</li>
        </ul>
    </section>

<footer>
        <div class="container">
            <p>&copy; 2025 AI Terakoya - Dr. Yusuke Hashimoto, Tohoku University</p>
            <p>Licensed under CC BY 4.0</p>
        </div>
    </footer>
</body>
</html>
