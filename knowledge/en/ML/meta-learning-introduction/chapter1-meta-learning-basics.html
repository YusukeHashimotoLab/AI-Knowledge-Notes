<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>Chapter 1: Fundamentals of Meta-Learning - AI Terakoya</title>
<link href="../../assets/css/knowledge-base.css" rel="stylesheet"/>
<script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
        mermaid.initialize({ startOnLoad: true, theme: 'default' });
    </script>
<!-- MathJax for LaTeX equation rendering -->
<script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                displayMath: [['$$', '$$'], ['\\[', '\\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
                ignoreHtmlClass: 'mermaid'
            }
        };
    </script>
<script async="" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>
<nav class="breadcrumb">
<div class="breadcrumb-content">
<a href="../index.html">AI Terakoya Top</a><span class="breadcrumb-separator">‚Ä∫</span><a href="../../ML/index.html">Machine Learning</a><span class="breadcrumb-separator">‚Ä∫</span><a href="../../ML/meta-learning-introduction/index.html">Meta Learning</a><span class="breadcrumb-separator">‚Ä∫</span><span class="breadcrumb-current">Chapter 1</span>
</div>
</nav><div class="locale-switcher">
<span class="current-locale">üåê EN</span>
<span class="locale-separator">|</span>
<a href="../../../jp/ML/meta-learning-introduction/chapter1-meta-learning-basics.html" class="locale-link">üáØüáµ JP</a>
<span class="locale-separator">|</span>
<span class="locale-meta">Last sync: 2025-11-16</span>
</div>
<header>
<div class="header-content">
<h1>Chapter 1: Fundamentals of Meta-Learning</h1>
<p class="subtitle">Learning to Learn - A New Paradigm for Learning from Few Examples</p>
<div class="meta">
<span class="meta-item">üìñ Reading Time: 25-30 min</span>
<span class="meta-item">üìä Difficulty: Beginner to Intermediate</span>
<span class="meta-item">üíª Code Examples: 7</span>
<span class="meta-item">üìù Exercises: 5</span>
</div>
</div>
</header>
<main class="container">

<p class="chapter-description">This chapter covers the fundamentals of Fundamentals of Meta, which learning. You will learn concept of meta-learning (Learning to Learn), problem setting of Few-Shot Learning, and roles of Support Set.</p>
<h2>Learning Objectives</h2>
<p>By reading this chapter, you will master the following:</p>
<ul>
<li>‚úÖ Understand the concept of meta-learning (Learning to Learn) and how it differs from conventional learning</li>
<li>‚úÖ Explain the problem setting of Few-Shot Learning and N-way K-shot classification</li>
<li>‚úÖ Understand the roles of Support Set and Query Set</li>
<li>‚úÖ Classify the three main approaches of meta-learning</li>
<li>‚úÖ Understand the structure of the Omniglot dataset and episode generation methods</li>
<li>‚úÖ Implement a simple Few-Shot classification baseline</li>
</ul>
<hr/>
<h2>1.1 What is Meta-Learning</h2>
<h3>Concept of Learning to Learn</h3>
<p><strong>Meta-Learning</strong> is a paradigm of "learning how to learn." While conventional machine learning solves specific tasks, meta-learning learns "the ability to quickly adapt to new tasks" itself.</p>
<blockquote>
<p>"Humans can learn new concepts from just a few examples. Machines should be able to do the same."</p>
</blockquote>
<h3>Differences from Conventional Learning</h3>
<table>
<thead>
<tr>
<th>Perspective</th>
<th>Conventional Machine Learning</th>
<th>Meta-Learning</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Goal</strong></td>
<td>Maximize performance on a single task</td>
<td>Acquire ability to adapt to new tasks</td>
</tr>
<tr>
<td><strong>Training Data</strong></td>
<td>Large amount of labeled data</td>
<td>Few samples from diverse tasks</td>
</tr>
<tr>
<td><strong>Learning Unit</strong></td>
<td>Individual samples</td>
<td>Tasks (episodes)</td>
</tr>
<tr>
<td><strong>Evaluation</strong></td>
<td>Test set from same distribution</td>
<td>Adaptation speed on unknown tasks</td>
</tr>
<tr>
<td><strong>Use Case</strong></td>
<td>Fixed tasks (e.g., cat vs dog classification)</td>
<td>Dynamic tasks (e.g., recognizing new animal species)</td>
</tr>
</tbody>
</table>
<h3>Learning Process of Meta-Learning</h3>
<div class="mermaid">
graph TD
    A[Multiple Tasks] --&gt; B[Task 1: Learn from 5 samples]
    A --&gt; C[Task 2: Learn from 5 samples]
    A --&gt; D[Task 3: Learn from 5 samples]
    B --&gt; E[Accumulation of Meta-Knowledge]
    C --&gt; E
    D --&gt; E
    E --&gt; F[New Task N]
    F --&gt; G[High accuracy with 5 samples]

    style A fill:#e3f2fd
    style E fill:#fff3e0
    style G fill:#c8e6c9
</div>
<h3>Scenarios Where Meta-Learning is Effective</h3>
<ul>
<li><strong>Medical Image Diagnosis</strong>: Few examples of rare diseases</li>
<li><strong>Personalized Recommendations</strong>: Limited history for new users</li>
<li><strong>Robotics</strong>: Quick adaptation to new environments</li>
<li><strong>Drug Discovery</strong>: Limited data on novel compounds</li>
<li><strong>Multilingual Processing</strong>: Learning with low-resource languages</li>
</ul>
<h3>Real Example: Comparison with Human Learning</h3>
<pre><code class="language-python"># Requirements:
# - Python 3.9+
# - matplotlib&gt;=3.7.0
# - numpy&gt;=1.24.0, &lt;2.0.0

import numpy as np
import matplotlib.pyplot as plt

# Comparison: Standard Learning vs Meta-Learning Learning Curve Simulation

def standard_learning_curve(n_samples):
    """Standard learning: Linear improvement"""
    return 0.5 + 0.45 * (1 - np.exp(-n_samples / 500))

def meta_learning_curve(n_samples):
    """Meta-learning: Rapid learning with few samples"""
    return 0.5 + 0.45 * (1 - np.exp(-n_samples / 20))

# Data points
samples = np.arange(1, 101, 1)
standard_acc = standard_learning_curve(samples)
meta_acc = meta_learning_curve(samples)

# Visualization
plt.figure(figsize=(12, 6))
plt.plot(samples, standard_acc, 'b-', linewidth=2, label='Standard Machine Learning')
plt.plot(samples, meta_acc, 'r-', linewidth=2, label='Meta-Learning')
plt.axhline(y=0.9, color='gray', linestyle='--', alpha=0.5, label='Target Accuracy 90%')
plt.axvline(x=10, color='green', linestyle=':', alpha=0.5, label='Few-Shot Region (10 samples)')

plt.xlabel('Number of Training Samples', fontsize=12)
plt.ylabel('Accuracy', fontsize=12)
plt.title('Comparison of Learning Paradigms: Standard Learning vs Meta-Learning', fontsize=14)
plt.legend(fontsize=11)
plt.grid(True, alpha=0.3)
plt.xlim(0, 100)
plt.ylim(0.4, 1.0)

# Annotate key points
plt.annotate('Meta-Learning: 85% with 10 samples',
             xy=(10, meta_learning_curve(10)),
             xytext=(30, 0.75),
             arrowprops=dict(arrowstyle='-&gt;', color='red', lw=1.5),
             fontsize=10, color='red')

plt.annotate('Standard Learning: ~60% with 10 samples',
             xy=(10, standard_learning_curve(10)),
             xytext=(30, 0.55),
             arrowprops=dict(arrowstyle='-&gt;', color='blue', lw=1.5),
             fontsize=10, color='blue')

plt.tight_layout()
plt.show()

print("=== Comparison of Learning Efficiency ===")
print(f"Accuracy with 10 samples:")
print(f"  Standard Learning: {standard_learning_curve(10):.3f}")
print(f"  Meta-Learning: {meta_learning_curve(10):.3f}")
print(f"  Difference: {(meta_learning_curve(10) - standard_learning_curve(10)):.3f}")
</code></pre>
<p><strong>Output</strong>:</p>
<pre><code>=== Comparison of Learning Efficiency ===
Accuracy with 10 samples:
  Standard Learning: 0.591
  Meta-Learning: 0.873
  Difference: 0.282
</code></pre>
<blockquote>
<p><strong>Important</strong>: The biggest advantage of meta-learning is its ability to achieve high accuracy with few samples.</p>
</blockquote>
<hr/>
<h2>1.2 Few-Shot Learning Problem Setting</h2>
<h3>N-way K-shot Classification</h3>
<p>The standard problem setting in Few-Shot Learning is <strong>N-way K-shot classification</strong>:</p>
<ul>
<li><strong>N-way</strong>: Classify N classes</li>
<li><strong>K-shot</strong>: K labeled samples per class</li>
</ul>
<p>Example: <strong>5-way 1-shot</strong> classification = Learning to classify 5 classes from 1 sample per class</p>
<h3>Support Set and Query Set</h3>
<p>Each episode (task) consists of two sets:</p>
<table>
<thead>
<tr>
<th>Set</th>
<th>Role</th>
<th>Size</th>
<th>Purpose</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Support Set</strong></td>
<td>Training samples</td>
<td>N √ó K samples</td>
<td>Model adaptation/update</td>
</tr>
<tr>
<td><strong>Query Set</strong></td>
<td>Evaluation samples</td>
<td>N √ó Q samples</td>
<td>Performance evaluation on task</td>
</tr>
</tbody>
</table>
<h3>Structure of an Episode</h3>
<div class="mermaid">
graph LR
    A[One Episode] --&gt; B[Support Set<br/>N√óK samples]
    A --&gt; C[Query Set<br/>N√óQ samples]
    B --&gt; D[Adapt Model]
    C --&gt; E[Evaluate Performance]

    style A fill:#e3f2fd
    style B fill:#fff3e0
    style C fill:#f3e5f5
    style D fill:#e8f5e9
    style E fill:#ffebee
</div>
<h3>Concrete Example: 5-way 1-shot Classification</h3>
<pre><code class="language-python"># Requirements:
# - Python 3.9+
# - numpy&gt;=1.24.0, &lt;2.0.0

import numpy as np

# Visualize the structure of a 5-way 1-shot episode

def create_episode_structure(n_way=5, k_shot=1, n_query=5):
    """
    Generate the structure of an N-way K-shot episode

    Args:
        n_way: Number of classes
        k_shot: Number of support samples per class
        n_query: Number of query samples per class

    Returns:
        Size information of support_set and query_set
    """
    support_size = n_way * k_shot
    query_size = n_way * n_query

    print(f"=== {n_way}-way {k_shot}-shot Episode Structure ===\n")
    print(f"„ÄêSupport Set„Äë")
    print(f"  Purpose: Model adaptation/learning")
    print(f"  Composition: {n_way} classes √ó {k_shot} samples/class = {support_size} samples")

    for i in range(n_way):
        samples = [f"S_{i}_{j}" for j in range(k_shot)]
        print(f"    Class {i}: {samples}")

    print(f"\n„ÄêQuery Set„Äë")
    print(f"  Purpose: Performance evaluation")
    print(f"  Composition: {n_way} classes √ó {n_query} samples/class = {query_size} samples")

    for i in range(n_way):
        samples = [f"Q_{i}_{j}" for j in range(min(n_query, 3))]
        if n_query &gt; 3:
            samples.append("...")
        print(f"    Class {i}: {samples}")

    return support_size, query_size

# Example of 5-way 1-shot
support_size, query_size = create_episode_structure(n_way=5, k_shot=1, n_query=5)

print(f"\nTotal Samples: {support_size + query_size}")
print(f"  Support: {support_size}")
print(f"  Query: {query_size}")
</code></pre>
<p><strong>Output</strong>:</p>
<pre><code>=== 5-way 1-shot Episode Structure ===

„ÄêSupport Set„Äë
  Purpose: Model adaptation/learning
  Composition: 5 classes √ó 1 samples/class = 5 samples
    Class 0: ['S_0_0']
    Class 1: ['S_1_0']
    Class 2: ['S_2_0']
    Class 3: ['S_3_0']
    Class 4: ['S_4_0']

„ÄêQuery Set„Äë
  Purpose: Performance evaluation
  Composition: 5 classes √ó 5 samples/class = 25 samples
    Class 0: ['Q_0_0', 'Q_0_1', 'Q_0_2', '...']
    Class 1: ['Q_1_0', 'Q_1_1', 'Q_1_2', '...']
    Class 2: ['Q_2_0', 'Q_2_1', 'Q_2_2', '...']
    Class 3: ['Q_3_0', 'Q_3_1', 'Q_3_2', '...']
    Class 4: ['Q_4_0', 'Q_4_1', 'Q_4_2', '...']

Total Samples: 30
  Support: 5
  Query: 25
</code></pre>
<h3>Episode-based Learning</h3>
<p>In meta-learning, we learn through multiple episodes:</p>
<ol>
<li>Randomly select N classes</li>
<li>Sample K support samples and Q query samples from each class</li>
<li>Adapt model with support set</li>
<li>Evaluate on query set and update meta-knowledge</li>
<li>Repeat steps 1-4</li>
</ol>
<pre><code class="language-python"># Requirements:
# - Python 3.9+
# - matplotlib&gt;=3.7.0
# - numpy&gt;=1.24.0, &lt;2.0.0

import numpy as np

def meta_training_simulation(n_episodes=1000, n_way=5, k_shot=1):
    """
    Simulate the meta-learning training process

    Args:
        n_episodes: Number of episodes
        n_way: Number of classes
        k_shot: Number of support samples
    """
    episode_accuracies = []

    for episode in range(n_episodes):
        # Generate random task for each episode
        # (In practice, sampled from dataset)

        # Simulation: Accuracy improves as episodes progress
        base_acc = 0.2  # Random guess (5-way: 20%)
        improvement = 0.7 * (1 - np.exp(-episode / 200))
        noise = np.random.normal(0, 0.05)  # Random noise

        acc = min(max(base_acc + improvement + noise, 0), 1)
        episode_accuracies.append(acc)

    # Visualization
    import matplotlib.pyplot as plt

    plt.figure(figsize=(12, 6))

    # Accuracy per episode
    plt.subplot(1, 2, 1)
    plt.plot(episode_accuracies, alpha=0.3, color='blue')

    # Moving average
    window = 50
    moving_avg = np.convolve(episode_accuracies,
                             np.ones(window)/window, mode='valid')
    plt.plot(range(window-1, n_episodes), moving_avg,
             'r-', linewidth=2, label=f'{window}-Episode Moving Average')

    plt.axhline(y=0.2, color='gray', linestyle='--',
                alpha=0.5, label='Random Guess (20%)')
    plt.xlabel('Episode', fontsize=12)
    plt.ylabel('Query Set Accuracy', fontsize=12)
    plt.title(f'{n_way}-way {k_shot}-shot Meta-Training Progress', fontsize=14)
    plt.legend()
    plt.grid(True, alpha=0.3)

    # Change in accuracy distribution
    plt.subplot(1, 2, 2)
    early = episode_accuracies[:200]
    late = episode_accuracies[-200:]

    plt.hist(early, bins=20, alpha=0.5, label='Early (0-200)', color='blue')
    plt.hist(late, bins=20, alpha=0.5, label='Late (800-1000)', color='red')
    plt.xlabel('Accuracy', fontsize=12)
    plt.ylabel('Frequency', fontsize=12)
    plt.title('Change in Accuracy Distribution', fontsize=14)
    plt.legend()
    plt.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.show()

    print(f"=== Meta-Training Statistics ({n_episodes} Episodes) ===")
    print(f"Average accuracy of first 100 episodes: {np.mean(episode_accuracies[:100]):.3f}")
    print(f"Average accuracy of last 100 episodes: {np.mean(episode_accuracies[-100:]):.3f}")
    print(f"Improvement: {(np.mean(episode_accuracies[-100:]) - np.mean(episode_accuracies[:100])):.3f}")

# Run simulation
meta_training_simulation(n_episodes=1000, n_way=5, k_shot=1)
</code></pre>
<blockquote>
<p><strong>Important</strong>: Through episode-based learning, the model acquires "the ability to learn from few samples" itself.</p>
</blockquote>
<hr/>
<h2>1.3 Classification of Meta-Learning Approaches</h2>
<p>Meta-learning methods can be broadly classified into three categories:</p>
<h3>1. Metric-based (Distance-based)</h3>
<p><strong>Basic Idea</strong>: Learn a good distance space and classify based on neighborhood</p>
<table>
<thead>
<tr>
<th>Method</th>
<th>Feature</th>
<th>Distance Calculation</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Siamese Networks</strong></td>
<td>Pairwise comparison</td>
<td>Euclidean distance, cosine similarity</td>
</tr>
<tr>
<td><strong>Matching Networks</strong></td>
<td>Weighted average with attention</td>
<td>Cosine similarity + attention</td>
</tr>
<tr>
<td><strong>Prototypical Networks</strong></td>
<td>Prototype per class</td>
<td>Distance to prototype</td>
</tr>
<tr>
<td><strong>Relation Networks</strong></td>
<td>Learnable distance function</td>
<td>Distance learning with neural network</td>
</tr>
</tbody>
</table>
<h4>Concept of Prototypical Networks</h4>
<pre><code class="language-python"># Requirements:
# - Python 3.9+
# - matplotlib&gt;=3.7.0
# - numpy&gt;=1.24.0, &lt;2.0.0

"""
Example: Concept of Prototypical Networks

Purpose: Demonstrate data visualization techniques
Target: Advanced
Execution time: 5-15 seconds
Dependencies: None
"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import make_blobs

# Visualize the concept of Prototypical Networks

# Simulation: Embedding space for 3 classes
np.random.seed(42)

# Generate data for each class
n_samples_per_class = 20
centers = np.array([[0, 0], [3, 3], [0, 3]])
X, y = make_blobs(n_samples=n_samples_per_class * 3,
                  centers=centers,
                  cluster_std=0.5,
                  random_state=42)

# Support Set (3 samples per class)
support_indices = []
for cls in range(3):
    cls_indices = np.where(y == cls)[0]
    support_indices.extend(cls_indices[:3])

support_X = X[support_indices]
support_y = y[support_indices]

# Query Set (remaining samples)
query_indices = [i for i in range(len(X)) if i not in support_indices]
query_X = X[query_indices]
query_y = y[query_indices]

# Compute prototypes (mean of support samples for each class)
prototypes = []
for cls in range(3):
    cls_support = support_X[support_y == cls]
    prototype = cls_support.mean(axis=0)
    prototypes.append(prototype)

prototypes = np.array(prototypes)

# Visualization
plt.figure(figsize=(12, 5))

# Left: Support Set and Prototypes
plt.subplot(1, 2, 1)
colors = ['red', 'blue', 'green']
for cls in range(3):
    cls_support = support_X[support_y == cls]
    plt.scatter(cls_support[:, 0], cls_support[:, 1],
                c=colors[cls], s=100, alpha=0.6,
                label=f'Class {cls} Support', marker='o')

plt.scatter(prototypes[:, 0], prototypes[:, 1],
            c=colors, s=300, marker='*',
            edgecolors='black', linewidth=2,
            label='Prototypes')

plt.xlabel('Embedding Dimension 1', fontsize=12)
plt.ylabel('Embedding Dimension 2', fontsize=12)
plt.title('Support Set and Prototypes', fontsize=14)
plt.legend()
plt.grid(True, alpha=0.3)

# Right: Query Set Classification
plt.subplot(1, 2, 2)

# All data points
for cls in range(3):
    cls_query = query_X[query_y == cls]
    plt.scatter(cls_query[:, 0], cls_query[:, 1],
                c=colors[cls], s=50, alpha=0.3,
                label=f'Class {cls} Query')

# Prototypes
plt.scatter(prototypes[:, 0], prototypes[:, 1],
            c=colors, s=300, marker='*',
            edgecolors='black', linewidth=2,
            label='Prototypes')

# Show classification of one query sample
query_sample = query_X[0]
plt.scatter(query_sample[0], query_sample[1],
            c='orange', s=200, marker='X',
            edgecolors='black', linewidth=2,
            label='Query Sample', zorder=5)

# Show distance to prototypes with lines
for i, proto in enumerate(prototypes):
    dist = np.linalg.norm(query_sample - proto)
    plt.plot([query_sample[0], proto[0]],
             [query_sample[1], proto[1]],
             'k--', alpha=0.3, linewidth=1)
    mid = (query_sample + proto) / 2
    plt.text(mid[0], mid[1], f'd={dist:.2f}', fontsize=9)

plt.xlabel('Embedding Dimension 1', fontsize=12)
plt.ylabel('Embedding Dimension 2', fontsize=12)
plt.title('Prototypical Networks: Distance-based Classification', fontsize=14)
plt.legend()
plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

print("=== Prototypical Networks ===")
print(f"Prototype coordinates:")
for i, proto in enumerate(prototypes):
    print(f"  Class {i}: [{proto[0]:.2f}, {proto[1]:.2f}]")
</code></pre>
<h3>2. Model-based</h3>
<p><strong>Basic Idea</strong>: Fast adaptation with models that have memory or recurrent structures</p>
<ul>
<li><strong>Memory-Augmented Neural Networks (MANN)</strong>: Store past experiences in external memory</li>
<li><strong>Meta Networks</strong>: Learn fast parameter generators</li>
<li><strong>SNAIL</strong>: Process past samples as time series</li>
</ul>
<h3>3. Optimization-based</h3>
<p><strong>Basic Idea</strong>: Learn good initial parameters and adapt in few steps</p>
<table>
<thead>
<tr>
<th>Method</th>
<th>Feature</th>
<th>Adaptation Method</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>MAML</strong></td>
<td>Model-agnostic, gradient-based</td>
<td>Few steps of gradient descent</td>
</tr>
<tr>
<td><strong>Reptile</strong></td>
<td>Simplified version of MAML</td>
<td>First-order derivatives only</td>
</tr>
<tr>
<td><strong>Meta-SGD</strong></td>
<td>Also learns learning rates</td>
<td>Adaptive learning rate + gradient descent</td>
</tr>
</tbody>
</table>
<h3>Comparison of Approaches</h3>
<table>
<thead>
<tr>
<th>Approach</th>
<th>Advantages</th>
<th>Disadvantages</th>
<th>Applications</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Metric-based</strong></td>
<td>Simple, fast, interpretable</td>
<td>Limited for complex tasks</td>
<td>Image classification, few-shot recognition</td>
</tr>
<tr>
<td><strong>Model-based</strong></td>
<td>Flexible, high expressiveness</td>
<td>Complex training</td>
<td>Sequential tasks</td>
</tr>
<tr>
<td><strong>Optimization-based</strong></td>
<td>Versatile, powerful</td>
<td>High computational cost</td>
<td>Reinforcement learning, complex tasks</td>
</tr>
</tbody>
</table>
<hr/>
<h2>1.4 Omniglot Dataset</h2>
<h3>Dataset Structure</h3>
<p><strong>Omniglot</strong> is a benchmark dataset called "the MNIST of meta-learning":</p>
<ul>
<li><strong>1,623 character classes</strong> (from 50 different alphabets)</li>
<li><strong>20 samples per class</strong> (handwritten by 20 different people)</li>
<li><strong>Image size</strong>: 105√ó105 pixels, grayscale</li>
<li><strong>Total samples</strong>: 32,460 images</li>
</ul>
<h3>Downloading and Preparing the Dataset</h3>
<pre><code class="language-python"># Requirements:
# - Python 3.9+
# - matplotlib&gt;=3.7.0
# - numpy&gt;=1.24.0, &lt;2.0.0
# - torch&gt;=2.0.0, &lt;2.3.0
# - torchvision&gt;=0.15.0

"""
Example: Downloading and Preparing the Dataset

Purpose: Demonstrate data visualization techniques
Target: Advanced
Execution time: 1-5 minutes
Dependencies: None
"""

import torch
import torchvision.transforms as transforms
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt
import numpy as np

# Prepare Omniglot dataset
# Note: Using torchvision.datasets.Omniglot

from torchvision.datasets import Omniglot

# Data transformation
transform = transforms.Compose([
    transforms.Resize((28, 28)),  # Resize to MNIST size
    transforms.ToTensor(),
])

# Load dataset
try:
    # Background set (for training)
    omniglot_train = Omniglot(
        root='./data',
        background=True,
        download=True,
        transform=transform
    )

    # Evaluation set (for testing)
    omniglot_test = Omniglot(
        root='./data',
        background=False,
        download=True,
        transform=transform
    )

    print("=== Omniglot Dataset ===")
    print(f"Training set: {len(omniglot_train)} samples")
    print(f"Test set: {len(omniglot_test)} samples")

    # Check data structure
    print(f"\nDataset structure:")
    print(f"  Training classes: {len(omniglot_train._alphabets)} alphabets")
    print(f"  Test classes: {len(omniglot_test._alphabets)} alphabets")

    # Sample visualization
    fig, axes = plt.subplots(2, 10, figsize=(15, 3))

    for i in range(10):
        # From training set
        img, label = omniglot_train[i * 100]
        axes[0, i].imshow(img.squeeze(), cmap='gray')
        axes[0, i].axis('off')
        axes[0, i].set_title(f'Train {i}', fontsize=9)

        # From test set
        img, label = omniglot_test[i * 50]
        axes[1, i].imshow(img.squeeze(), cmap='gray')
        axes[1, i].axis('off')
        axes[1, i].set_title(f'Test {i}', fontsize=9)

    plt.suptitle('Omniglot Samples (Top: Training Set, Bottom: Test Set)', fontsize=14)
    plt.tight_layout()
    plt.show()

except Exception as e:
    print(f"Dataset loading error: {e}")
    print("Note: Requires torchvision and internet connection")
</code></pre>
<h3>Episode Generation</h3>
<pre><code class="language-python">import random

class OmniglotEpisodeSampler:
    """
    Episode sampler for Omniglot
    Generates N-way K-shot episodes
    """
    def __init__(self, dataset, n_way=5, k_shot=1, n_query=5):
        self.dataset = dataset
        self.n_way = n_way
        self.k_shot = k_shot
        self.n_query = n_query

        # Group samples by class
        self.class_to_indices = {}
        for idx, (_, label) in enumerate(dataset):
            if label not in self.class_to_indices:
                self.class_to_indices[label] = []
            self.class_to_indices[label].append(idx)

        self.classes = list(self.class_to_indices.keys())
        print(f"Sampler initialized: {len(self.classes)} classes")

    def sample_episode(self):
        """
        Sample one episode

        Returns:
            support_set: (n_way * k_shot, C, H, W) tensor
            query_set: (n_way * n_query, C, H, W) tensor
            support_labels: (n_way * k_shot,) tensor
            query_labels: (n_way * n_query,) tensor
        """
        # Randomly select N classes
        episode_classes = random.sample(self.classes, self.n_way)

        support_set = []
        query_set = []
        support_labels = []
        query_labels = []

        for class_idx, cls in enumerate(episode_classes):
            # Sample indices for this class
            cls_indices = self.class_to_indices[cls]

            # Sample K+Q samples (without replacement)
            sampled_indices = random.sample(cls_indices,
                                           self.k_shot + self.n_query)

            # Support Set
            for i in range(self.k_shot):
                img, _ = self.dataset[sampled_indices[i]]
                support_set.append(img)
                support_labels.append(class_idx)

            # Query Set
            for i in range(self.k_shot, self.k_shot + self.n_query):
                img, _ = self.dataset[sampled_indices[i]]
                query_set.append(img)
                query_labels.append(class_idx)

        # Convert to tensors
        support_set = torch.stack(support_set)
        query_set = torch.stack(query_set)
        support_labels = torch.tensor(support_labels)
        query_labels = torch.tensor(query_labels)

        return support_set, query_set, support_labels, query_labels

# Example usage of episode sampler
try:
    sampler = OmniglotEpisodeSampler(
        omniglot_train,
        n_way=5,
        k_shot=1,
        n_query=5
    )

    # Sample one episode
    support, query, support_labels, query_labels = sampler.sample_episode()

    print(f"\n=== Episode Structure ===")
    print(f"Support Set: {support.shape}")
    print(f"Query Set: {query.shape}")
    print(f"Support Labels: {support_labels}")
    print(f"Query Labels: {query_labels}")

    # Visualization
    fig, axes = plt.subplots(2, 5, figsize=(12, 5))

    # Support Set
    for i in range(5):
        axes[0, i].imshow(support[i].squeeze(), cmap='gray')
        axes[0, i].axis('off')
        axes[0, i].set_title(f'Support\nClass {support_labels[i].item()}',
                            fontsize=10)

    # Query Set (one from each class)
    for i in range(5):
        axes[1, i].imshow(query[i].squeeze(), cmap='gray')
        axes[1, i].axis('off')
        axes[1, i].set_title(f'Query\nClass {query_labels[i].item()}',
                            fontsize=10)

    plt.suptitle('Example of 5-way 1-shot Episode', fontsize=14)
    plt.tight_layout()
    plt.show()

except NameError:
    print("Note: Omniglot dataset needs to be loaded")
</code></pre>
<hr/>
<h2>1.5 Practice: Simple Few-Shot Classification</h2>
<h3>Basic N-way K-shot Task</h3>
<p>The simplest Few-Shot classification approach is to calculate distances between the support set and query samples.</p>
<h3>Nearest Neighbor Baseline</h3>
<pre><code class="language-python"># Requirements:
# - Python 3.9+
# - matplotlib&gt;=3.7.0
# - numpy&gt;=1.24.0, &lt;2.0.0
# - torch&gt;=2.0.0, &lt;2.3.0

import torch
import torch.nn.functional as F
import numpy as np

class NearestNeighborClassifier:
    """
    Few-Shot classification baseline using nearest neighbor
    """
    def __init__(self, distance_metric='euclidean'):
        self.distance_metric = distance_metric

    def fit(self, support_set, support_labels):
        """
        Store Support Set

        Args:
            support_set: (N*K, feature_dim) tensor
            support_labels: (N*K,) tensor
        """
        self.support_set = support_set
        self.support_labels = support_labels

    def predict(self, query_set):
        """
        Classify Query Set

        Args:
            query_set: (N*Q, feature_dim) tensor

        Returns:
            predictions: (N*Q,) tensor
        """
        n_queries = query_set.size(0)
        predictions = []

        for i in range(n_queries):
            query = query_set[i]

            # Calculate distances to all support samples
            if self.distance_metric == 'euclidean':
                distances = torch.norm(self.support_set - query, dim=1)
            elif self.distance_metric == 'cosine':
                # Cosine similarity (converted to distance)
                similarities = F.cosine_similarity(
                    self.support_set,
                    query.unsqueeze(0),
                    dim=1
                )
                distances = 1 - similarities

            # Predict label of nearest neighbor
            nearest_idx = torch.argmin(distances)
            pred_label = self.support_labels[nearest_idx]
            predictions.append(pred_label)

        return torch.tensor(predictions)

    def evaluate(self, query_set, query_labels):
        """
        Calculate accuracy
        """
        predictions = self.predict(query_set)
        accuracy = (predictions == query_labels).float().mean()
        return accuracy.item()

# Experiment: Verify operation with simple 2D data
def test_nearest_neighbor():
    """Test Nearest Neighbor operation"""

    # Simulate 5-way 1-shot task
    n_way = 5
    k_shot = 1
    n_query = 10

    # Generate Support Set (place each class in different regions)
    support_set = []
    support_labels = []

    for cls in range(n_way):
        # Set center for each class
        center = torch.tensor([cls * 2.0, cls * 2.0])
        sample = center + torch.randn(2) * 0.5  # Add noise
        support_set.append(sample)
        support_labels.append(cls)

    support_set = torch.stack(support_set)
    support_labels = torch.tensor(support_labels)

    # Generate Query Set (multiple samples from each class)
    query_set = []
    query_labels = []

    for cls in range(n_way):
        center = torch.tensor([cls * 2.0, cls * 2.0])
        for _ in range(n_query // n_way):
            sample = center + torch.randn(2) * 0.5
            query_set.append(sample)
            query_labels.append(cls)

    query_set = torch.stack(query_set)
    query_labels = torch.tensor(query_labels)

    # Nearest Neighbor classification
    nn_classifier = NearestNeighborClassifier(distance_metric='euclidean')
    nn_classifier.fit(support_set, support_labels)
    accuracy = nn_classifier.evaluate(query_set, query_labels)

    print(f"=== Nearest Neighbor Baseline ===")
    print(f"Task: {n_way}-way {k_shot}-shot")
    print(f"Accuracy: {accuracy:.3f}")

    # Visualization
    import matplotlib.pyplot as plt

    plt.figure(figsize=(10, 8))

    colors = ['red', 'blue', 'green', 'orange', 'purple']

    # Support Set
    for cls in range(n_way):
        cls_support = support_set[support_labels == cls]
        plt.scatter(cls_support[:, 0], cls_support[:, 1],
                   c=colors[cls], s=300, marker='*',
                   edgecolors='black', linewidth=2,
                   label=f'Support Class {cls}', zorder=5)

    # Query Set
    for cls in range(n_way):
        cls_query = query_set[query_labels == cls]
        plt.scatter(cls_query[:, 0], cls_query[:, 1],
                   c=colors[cls], s=100, alpha=0.5,
                   marker='o', edgecolors='black')

    # Prediction results
    predictions = nn_classifier.predict(query_set)
    correct = (predictions == query_labels)
    incorrect = ~correct

    # Mark misclassifications with √ó
    if incorrect.any():
        plt.scatter(query_set[incorrect, 0], query_set[incorrect, 1],
                   s=200, marker='x', c='black', linewidth=3,
                   label='Misclassified', zorder=6)

    plt.xlabel('Feature Dimension 1', fontsize=12)
    plt.ylabel('Feature Dimension 2', fontsize=12)
    plt.title(f'Nearest Neighbor: {n_way}-way {k_shot}-shot\nAccuracy: {accuracy:.1%}',
             fontsize=14)
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.show()

# Run experiment
test_nearest_neighbor()
</code></pre>
<h3>Evaluation Protocol</h3>
<p>Standard evaluation method for Few-Shot learning:</p>
<ol>
<li><strong>Generate many episodes</strong> (e.g., 600 episodes)</li>
<li>Calculate accuracy for each episode</li>
<li>Report mean accuracy and standard deviation</li>
</ol>
<pre><code class="language-python"># Requirements:
# - Python 3.9+
# - matplotlib&gt;=3.7.0

def evaluate_fewshot_model(model, dataset_sampler, n_episodes=600):
    """
    Standard evaluation protocol for Few-Shot models

    Args:
        model: Few-Shot classification model
        dataset_sampler: Episode sampler
        n_episodes: Number of evaluation episodes

    Returns:
        mean_accuracy: Mean accuracy
        std_accuracy: Standard deviation
    """
    accuracies = []

    for episode in range(n_episodes):
        # Sample episode
        support, query, support_labels, query_labels = \
            dataset_sampler.sample_episode()

        # Flatten (treat as features)
        support_flat = support.view(support.size(0), -1)
        query_flat = query.view(query.size(0), -1)

        # Evaluate with model
        model.fit(support_flat, support_labels)
        accuracy = model.evaluate(query_flat, query_labels)
        accuracies.append(accuracy)

        if (episode + 1) % 100 == 0:
            print(f"Episode {episode + 1}/{n_episodes} completed")

    mean_acc = np.mean(accuracies)
    std_acc = np.std(accuracies)

    # 95% confidence interval
    conf_interval = 1.96 * std_acc / np.sqrt(n_episodes)

    print(f"\n=== Evaluation Results ({n_episodes} Episodes) ===")
    print(f"Mean accuracy: {mean_acc:.3f} ¬± {conf_interval:.3f}")
    print(f"Standard deviation: {std_acc:.3f}")
    print(f"Minimum accuracy: {min(accuracies):.3f}")
    print(f"Maximum accuracy: {max(accuracies):.3f}")

    # Visualize accuracy distribution
    import matplotlib.pyplot as plt

    plt.figure(figsize=(10, 6))
    plt.hist(accuracies, bins=30, alpha=0.7, edgecolor='black', color='skyblue')
    plt.axvline(mean_acc, color='red', linestyle='--', linewidth=2,
               label=f'Mean: {mean_acc:.3f}')
    plt.axvline(mean_acc - conf_interval, color='orange', linestyle=':',
               linewidth=2, label=f'95% CI')
    plt.axvline(mean_acc + conf_interval, color='orange', linestyle=':',
               linewidth=2)
    plt.xlabel('Accuracy', fontsize=12)
    plt.ylabel('Frequency', fontsize=12)
    plt.title(f'Few-Shot Accuracy Distribution ({n_episodes} Episodes)', fontsize=14)
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.show()

    return mean_acc, std_acc

# Run evaluation (if Omniglot dataset is available)
try:
    nn_model = NearestNeighborClassifier(distance_metric='euclidean')
    mean_acc, std_acc = evaluate_fewshot_model(
        nn_model,
        sampler,
        n_episodes=100  # Reduced for demo
    )
except NameError:
    print("Note: Requires Omniglot dataset and sampler")
</code></pre>
<blockquote>
<p><strong>Important</strong>: The Nearest Neighbor baseline, while simple, shows competitive performance on many Few-Shot tasks.</p>
</blockquote>
<hr/>
<h2>1.6 Chapter Summary</h2>
<h3>What We Learned</h3>
<ol>
<li><p><strong>Essence of Meta-Learning</strong></p>
<ul>
<li>Learning to Learn: Learning the learning method itself</li>
<li>Goal is fast adaptation with few samples</li>
<li>Episode-based training process</li>
</ul></li>
<li><p><strong>Few-Shot Learning Problem Setting</strong></p>
<ul>
<li>Definition of N-way K-shot classification</li>
<li>Roles of Support Set and Query Set</li>
<li>Standardized evaluation protocol</li>
</ul></li>
<li><p><strong>Three Approaches to Meta-Learning</strong></p>
<ul>
<li>Metric-based: Distance learning</li>
<li>Model-based: Memory and recurrence</li>
<li>Optimization-based: Good initialization</li>
</ul></li>
<li><p><strong>Omniglot Dataset</strong></p>
<ul>
<li>1,623 classes, 20 samples each</li>
<li>Implementation of episode generation</li>
<li>Standard benchmark for Few-Shot learning</li>
</ul></li>
<li><p><strong>Baseline Implementation</strong></p>
<ul>
<li>Nearest Neighbor classifier</li>
<li>Standard evaluation protocol</li>
<li>Reporting accuracy and confidence intervals</li>
</ul></li>
</ol>
<h3>Key Concepts in Meta-Learning</h3>
<table>
<thead>
<tr>
<th>Concept</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Episode</strong></td>
<td>One learning task (Support + Query)</td>
</tr>
<tr>
<td><strong>Meta-Training</strong></td>
<td>Learn adaptation ability from multiple episodes</td>
</tr>
<tr>
<td><strong>Meta-Testing</strong></td>
<td>Evaluate adaptation performance on unknown tasks</td>
</tr>
<tr>
<td><strong>Few-Shot</strong></td>
<td>Learning from few samples (typically 1-5)</td>
</tr>
<tr>
<td><strong>Zero-Shot</strong></td>
<td>Inference without training samples</td>
</tr>
</tbody>
</table>
<h3>To the Next Chapter</h3>
<p>In Chapter 2, we will learn about <strong>Prototypical Networks</strong> in detail:</p>
<ul>
<li>Prototype-based classification</li>
<li>Design of embedding networks</li>
<li>Implementation of episode training</li>
<li>Performance evaluation on Omniglot</li>
<li>Hyperparameter tuning</li>
</ul>
<hr/>
<h2>Exercises</h2>
<h3>Problem 1 (Difficulty: easy)</h3>
<p>Explain the differences between meta-learning and conventional machine learning from three perspectives: "learning unit," "training data," and "evaluation method."</p>
<details>
<summary>Sample Answer</summary>
<p><strong>Answer</strong>:</p>
<table>
<thead>
<tr>
<th>Perspective</th>
<th>Conventional Machine Learning</th>
<th>Meta-Learning</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Learning Unit</strong></td>
<td>Individual samples (images, text, etc.)</td>
<td>Entire tasks (episode-based)</td>
</tr>
<tr>
<td><strong>Training Data</strong></td>
<td>Large amount of labeled data for one task</td>
<td>Few samples from diverse tasks</td>
</tr>
<tr>
<td><strong>Evaluation Method</strong></td>
<td>Accuracy on test set from same distribution</td>
<td>Adaptation speed and accuracy on unknown tasks</td>
</tr>
</tbody>
</table>
<p><strong>Concrete Example</strong>:</p>
<ul>
<li><strong>Conventional Learning</strong>: Train classifier on 100,000 cat vs dog images ‚Üí Evaluate on test images from same distribution</li>
<li><strong>Meta-Learning</strong>: Learn from 1,000 animal species (5 images each) ‚Üí Classify new species from just 5 images</li>
</ul>
</details>
<h3>Problem 2 (Difficulty: medium)</h3>
<p>For a 5-way 3-shot classification task, calculate the sizes of Support Set and Query Set (5 samples per class), respectively. Also calculate the total number of samples per episode.</p>
<details>
<summary>Sample Answer</summary>
<p><strong>Answer</strong>:</p>
<p><strong>Conditions</strong>:</p>
<ul>
<li>N-way = 5 classes</li>
<li>K-shot = 3 samples/class (Support)</li>
<li>Q = 5 samples/class (Query)</li>
</ul>
<p><strong>Calculation</strong>:</p>
<ol>
<li><strong>Support Set Size</strong>:
   $$\text{Support} = N \times K = 5 \times 3 = 15 \text{ samples}$$</li>
<li><strong>Query Set Size</strong>:
   $$\text{Query} = N \times Q = 5 \times 5 = 25 \text{ samples}$$</li>
<li><strong>Total Samples</strong>:
   $$\text{Total} = \text{Support} + \text{Query} = 15 + 25 = 40 \text{ samples}$$</li>
</ol>
<p><strong>Structure</strong>:</p>
<pre><code>Support Set (15 samples):
  Class 0: [S_0_0, S_0_1, S_0_2]
  Class 1: [S_1_0, S_1_1, S_1_2]
  Class 2: [S_2_0, S_2_1, S_2_2]
  Class 3: [S_3_0, S_3_1, S_3_2]
  Class 4: [S_4_0, S_4_1, S_4_2]

Query Set (25 samples):
  Class 0: [Q_0_0, Q_0_1, Q_0_2, Q_0_3, Q_0_4]
  Class 1: [Q_1_0, Q_1_1, Q_1_2, Q_1_3, Q_1_4]
  Class 2: [Q_2_0, Q_2_1, Q_2_2, Q_2_3, Q_2_4]
  Class 3: [Q_3_0, Q_3_1, Q_3_2, Q_3_3, Q_3_4]
  Class 4: [Q_4_0, Q_4_1, Q_4_2, Q_4_3, Q_4_4]
</code></pre>
</details>
<h3>Problem 3 (Difficulty: medium)</h3>
<p>For the three meta-learning approaches (Metric-based, Model-based, Optimization-based), state the basic idea and one representative method for each.</p>
<details>
<summary>Sample Answer</summary>
<p><strong>Answer</strong>:</p>
<table>
<thead>
<tr>
<th>Approach</th>
<th>Basic Idea</th>
<th>Representative Method</th>
<th>Features</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Metric-based</strong></td>
<td>Learn a good distance space<br/>and classify based on neighborhood</td>
<td>Prototypical<br/>Networks</td>
<td>Compute prototype for each class,<br/>classify to nearest class</td>
</tr>
<tr>
<td><strong>Model-based</strong></td>
<td>Fast adaptation with<br/>memory or recurrent structures</td>
<td>Memory-Augmented<br/>Neural Networks</td>
<td>Store past experiences in external memory,<br/>reference for new tasks</td>
</tr>
<tr>
<td><strong>Optimization-based</strong></td>
<td>Learn good initial parameters,<br/>adapt in few steps</td>
<td>MAML<br/>(Model-Agnostic Meta-Learning)</td>
<td>Learn initialization that reaches<br/>high accuracy in few gradient steps</td>
</tr>
</tbody>
</table>
<p><strong>Usage Guidelines</strong>:</p>
<ul>
<li><strong>Metric-based</strong>: Simple and fast, optimal for image classification</li>
<li><strong>Model-based</strong>: Suited for complex sequential tasks</li>
<li><strong>Optimization-based</strong>: Highly versatile, applicable to reinforcement learning</li>
</ul>
</details>
<h3>Problem 4 (Difficulty: hard)</h3>
<p>For 5-way 1-shot classification on the Omniglot dataset, estimate the random guess accuracy and the expected accuracy of an ideal Nearest Neighbor classifier. Also discuss the target accuracy range that practical meta-learning methods should aim for.</p>
<details>
<summary>Sample Answer</summary>
<p><strong>Answer</strong>:</p>
<p><strong>1. Random Guess Accuracy</strong>:</p>
<ul>
<li>Randomly select one of 5 classes</li>
<li>Accuracy = 1/5 = <strong>20%</strong></li>
</ul>
<p><strong>2. Expected Accuracy of Ideal Nearest Neighbor Classifier</strong>:</p>
<p>Considering Omniglot characteristics:</p>
<ul>
<li>Each class is visually distinguishable (different characters)</li>
<li>Variation within same class exists (20 people's handwriting)</li>
<li>Pixel-based distance is imperfect</li>
</ul>
<p>Expected accuracy: <strong>60-75%</strong> approximately</p>
<p>Reasons:</p>
<ul>
<li>Support Set has only 1 sample ‚Üí Cannot capture within-class variation</li>
<li>Pixel-level distance is sensitive to rotation and deformation</li>
<li>Still much better than random</li>
</ul>
<p><strong>3. Target Accuracy Range for Meta-Learning Methods</strong>:</p>
<table>
<thead>
<tr>
<th>Method Type</th>
<th>Expected Accuracy</th>
<th>Reason</th>
</tr>
</thead>
<tbody>
<tr>
<td>Baseline (NN)</td>
<td>60-75%</td>
<td>Pixel distance only</td>
</tr>
<tr>
<td>Metric-based</td>
<td>85-95%</td>
<td>Learned embedding space</td>
</tr>
<tr>
<td>Optimization-based</td>
<td>95-98%</td>
<td>Task-specific adaptation</td>
</tr>
<tr>
<td>State-of-the-art</td>
<td>98%+</td>
<td>Data augmentation + ensembles</td>
</tr>
</tbody>
</table>
<p><strong>Real Examples (Paper Results)</strong>:</p>
<ul>
<li>Siamese Networks: ~92%</li>
<li>Matching Networks: ~93%</li>
<li>Prototypical Networks: ~95%</li>
<li>MAML: ~95-98%</li>
</ul>
</details>
<h3>Problem 5 (Difficulty: hard)</h3>
<p>Complete the following code to implement a simple Prototype classifier. Create a function that computes the prototype (mean) of support samples for each class and classifies query samples to the class with the nearest prototype.</p>
<pre><code class="language-python"># Requirements:
# - Python 3.9+
# - torch&gt;=2.0.0, &lt;2.3.0

import torch

def prototype_classify(support_set, support_labels, query_set, n_way):
    """
    Prototype-based classification

    Args:
        support_set: (N*K, feature_dim) tensor
        support_labels: (N*K,) tensor
        query_set: (N*Q, feature_dim) tensor
        n_way: Number of classes

    Returns:
        predictions: (N*Q,) tensor
    """
    prototypes = None  # Implement here

    predictions = None  # Implement here

    return predictions
</code></pre>
<details>
<summary>Sample Answer</summary>
<pre><code class="language-python"># Requirements:
# - Python 3.9+
# - torch&gt;=2.0.0, &lt;2.3.0

import torch

def prototype_classify(support_set, support_labels, query_set, n_way):
    """
    Prototype-based classification

    Args:
        support_set: (N*K, feature_dim) tensor
        support_labels: (N*K,) tensor
        query_set: (N*Q, feature_dim) tensor
        n_way: Number of classes

    Returns:
        predictions: (N*Q,) tensor
    """
    # 1. Compute prototype for each class
    prototypes = []
    for c in range(n_way):
        # Extract support samples for class c
        class_support = support_set[support_labels == c]
        # Compute mean as prototype
        prototype = class_support.mean(dim=0)
        prototypes.append(prototype)

    prototypes = torch.stack(prototypes)  # (n_way, feature_dim)

    # 2. Classify each query sample to the class with nearest prototype
    n_queries = query_set.size(0)
    predictions = []

    for i in range(n_queries):
        query = query_set[i]  # (feature_dim,)

        # Compute distances to all prototypes
        distances = torch.norm(prototypes - query, dim=1)  # (n_way,)

        # Predict class with minimum distance
        pred_class = torch.argmin(distances)
        predictions.append(pred_class)

    predictions = torch.stack(predictions)

    return predictions


# Test code
def test_prototype_classifier():
    """Test Prototype classifier"""

    # Simulate 5-way 2-shot task
    n_way = 5
    k_shot = 2
    n_query = 10
    feature_dim = 128

    # Generate dummy data
    support_set = torch.randn(n_way * k_shot, feature_dim)
    support_labels = torch.tensor([i for i in range(n_way) for _ in range(k_shot)])

    # Query Set: 2 samples from each class
    query_set = torch.randn(n_query, feature_dim)
    query_labels = torch.tensor([i % n_way for i in range(n_query)])

    # Execute classification
    predictions = prototype_classify(support_set, support_labels, query_set, n_way)

    # Calculate accuracy
    accuracy = (predictions == query_labels).float().mean()

    print("=== Prototype Classifier Test ===")
    print(f"Task: {n_way}-way {k_shot}-shot")
    print(f"Support Set: {support_set.shape}")
    print(f"Query Set: {query_set.shape}")
    print(f"Predictions: {predictions}")
    print(f"Ground Truth: {query_labels}")
    print(f"Accuracy: {accuracy:.3f}")

    # More realistic test: spatially separated classes
    print("\n=== Test with Separated Classes ===")

    support_set = []
    support_labels = []
    query_set = []
    query_labels = []

    for c in range(n_way):
        # Set center for each class
        center = torch.randn(feature_dim) * 5  # Large separation

        # Support samples
        for _ in range(k_shot):
            sample = center + torch.randn(feature_dim) * 0.5  # Small noise
            support_set.append(sample)
            support_labels.append(c)

        # Query samples
        for _ in range(2):
            sample = center + torch.randn(feature_dim) * 0.5
            query_set.append(sample)
            query_labels.append(c)

    support_set = torch.stack(support_set)
    support_labels = torch.tensor(support_labels)
    query_set = torch.stack(query_set)
    query_labels = torch.tensor(query_labels)

    # Execute classification
    predictions = prototype_classify(support_set, support_labels, query_set, n_way)
    accuracy = (predictions == query_labels).float().mean()

    print(f"Accuracy with separated data: {accuracy:.3f}")
    print("(When classes are clearly separated, accuracy becomes high)")

# Run test
test_prototype_classifier()
</code></pre>
<p><strong>Example Output</strong>:</p>
<pre><code>=== Prototype Classifier Test ===
Task: 5-way 2-shot
Support Set: torch.Size([10, 128])
Query Set: torch.Size([10, 128])
Predictions: tensor([1, 3, 0, 2, 4, 0, 1, 2, 3, 4])
Ground Truth: tensor([0, 1, 2, 3, 4, 0, 1, 2, 3, 4])
Accuracy: 0.300

=== Test with Separated Classes ===
Accuracy with separated data: 1.000
(When classes are clearly separated, accuracy becomes high)
</code></pre>
<p><strong>Explanation</strong>:</p>
<ol>
<li><strong>Prototype Computation</strong>: Take mean of support samples for each class</li>
<li><strong>Distance Calculation</strong>: Euclidean distance between query sample and all prototypes</li>
<li><strong>Classification</strong>: Predict the class of the prototype with minimum distance</li>
<li><strong>Performance</strong>: Achieves high accuracy when classes are spatially separated</li>
</ol>
</details>
<hr/>
<h2>References</h2>
<ol>
<li>Vinyals, O., et al. (2016). "Matching Networks for One Shot Learning." <em>NeurIPS</em>.</li>
<li>Snell, J., Swersky, K., &amp; Zemel, R. (2017). "Prototypical Networks for Few-shot Learning." <em>NeurIPS</em>.</li>
<li>Finn, C., Abbeel, P., &amp; Levine, S. (2017). "Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks." <em>ICML</em>.</li>
<li>Lake, B. M., et al. (2015). "Human-level concept learning through probabilistic program induction." <em>Science</em>.</li>
<li>Hospedales, T., et al. (2020). "Meta-Learning in Neural Networks: A Survey." <em>arXiv:2004.05439</em>.</li>
</ol>
<div class="navigation">
<a class="nav-button" href="index.html">‚Üê Series Contents</a>
<a class="nav-button" href="chapter2-maml.html">Next Chapter: Prototypical Networks ‚Üí</a>
</div>
</main>
<section class="disclaimer">
<h3>Disclaimer</h3>
<ul>
<li>This content is provided for educational, research, and informational purposes only and does not constitute professional advice (legal, accounting, technical guarantees, etc.).</li>
<li>This content and accompanying code examples are provided "AS IS" without warranty of any kind, express or implied, including but not limited to merchantability, fitness for a particular purpose, non-infringement, accuracy, completeness, operation, or safety.</li>
<li>The creator and Tohoku University assume no responsibility for the content, availability, or safety of external links, third-party data, tools, libraries, etc.</li>
<li>To the maximum extent permitted by applicable law, the creator and Tohoku University shall not be liable for any direct, indirect, incidental, special, consequential, or punitive damages arising from the use, execution, or interpretation of this content.</li>
<li>The content of this material is subject to change, update, or discontinuation without notice.</li>
<li>The copyright and license of this content are subject to the specified conditions (e.g., CC BY 4.0). Such licenses typically include no-warranty clauses.</li>
</ul>
</section>
<footer>
<p><strong>Author</strong>: AI Terakoya Content Team</p>
<p><strong>Version</strong>: 1.0 | <strong>Created</strong>: 2025-10-23</p>
<p><strong>License</strong>: Creative Commons BY 4.0</p>
<p>¬© 2025 AI Terakoya. All rights reserved.</p>
</footer>
</body>
</html>
