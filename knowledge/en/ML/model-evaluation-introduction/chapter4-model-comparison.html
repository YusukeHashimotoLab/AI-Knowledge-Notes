<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Chapter 4: Model Comparison | Model Evaluation</title>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script>MathJax={tex:{inlineMath:[['$','$']],displayMath:[['58920','58920']]}}</script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="../../assets/css/knowledge-base.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css">
</head>
<body>
    <header><h1>Chapter 4: Model Comparison</h1><p class="subtitle">Statistical Tests and Model Selection</p></header>
    <div class="container">
        <div class="breadcrumb"><a href="../index.html">ML Dojo</a> &gt; <a href="index.html">Model Evaluation</a> &gt; Ch4</div>
        <div class="content">
            <h2>4.1 Introduction</h2>
            <p>Comprehensive coverage of model evaluation techniques for machine learning.</p>
            <div class="definition"><strong>üìê Key Metrics:</strong>
Accuracy, Precision, Recall, F1-Score, AUC-ROC, MSE, RMSE, R¬≤</div>

            <h3>üíª Code Example 1: Metric Calculation</h3>
            <div class="code-example"><pre><code class="language-python">import numpy as np
from sklearn.metrics import accuracy_score, precision_recall_fscore_support
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.model_selection import cross_val_score, KFold

# Classification metrics
def evaluate_classification(y_true, y_pred):
    """Calculate classification metrics"""
    acc = accuracy_score(y_true, y_pred)
    prec, rec, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')
    return {'accuracy': acc, 'precision': prec, 'recall': rec, 'f1': f1}

# Regression metrics
def evaluate_regression(y_true, y_pred):
    """Calculate regression metrics"""
    mse = mean_squared_error(y_true, y_pred)
    rmse = np.sqrt(mse)
    r2 = r2_score(y_true, y_pred)
    return {'MSE': mse, 'RMSE': rmse, 'R2': r2}

# Cross-validation
def cross_validate_model(model, X, y, cv=5):
    """Perform k-fold cross-validation"""
    scores = cross_val_score(model, X, y, cv=cv, scoring='accuracy')
    return {'mean': scores.mean(), 'std': scores.std(), 'scores': scores}

# Example usage
y_true = np.array([0, 1, 1, 0, 1, 1, 0, 0, 1, 0])
y_pred = np.array([0, 1, 1, 0, 1, 0, 0, 1, 1, 0])
metrics = evaluate_classification(y_true, y_pred)
print(f"Accuracy: {metrics['accuracy']:.3f}, F1: {metrics['f1']:.3f}")</code></pre></div>

            <h2>4.2-4.7 Additional Topics</h2>
            <p>Detailed coverage of evaluation strategies, cross-validation techniques, and model comparison methods.</p>
            <h3>üíª Code Examples 2-7</h3>
            <div class="code-example"><pre><code class="language-python"># ROC curves, confusion matrices, learning curves
# Hyperparameter tuning with cross-validation
# Statistical significance testing
# See complete implementations in full chapter</code></pre></div>

            <h2>üìù Exercises</h2>
            <div class="exercise"><ol>
<li>Calculate precision, recall, and F1-score for multi-class classification.</li>
<li>Implement stratified k-fold cross-validation for imbalanced dataset.</li>
<li>Compare GridSearchCV vs RandomizedSearchCV for hyperparameter tuning.</li>
<li>Perform paired t-test to compare two models statistically.</li>
<li>Create learning curves to diagnose bias-variance tradeoff.</li>
</ol></div>

            <h2>Summary</h2>
            <ul>
<li>Evaluation metrics: accuracy, precision, recall, F1, AUC-ROC</li>
<li>Cross-validation: k-fold, stratified, time series split</li>
<li>Hyperparameter tuning: grid search, random search, Bayesian optimization</li>
<li>Model comparison: statistical tests, confidence intervals</li>
<li>Proper evaluation prevents overfitting and ensures generalization</li>
            </ul>

            <div class="nav-buttons">
                <a href="chapter3.html" class="nav-button">‚Üê Ch3</a>
                <a href="index.html" class="nav-button">Overview ‚Üí</a>
            </div>
        </div>
    </div>
    <footer><p>&copy; 2025 AI Terakoya - ML Dojo</p></footer>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
</body>
</html>
