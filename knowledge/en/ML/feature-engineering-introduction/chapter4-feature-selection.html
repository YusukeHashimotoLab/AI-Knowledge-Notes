<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Chapter 4: Feature Selection - AI Terakoya</title>

    <style>
        :root {
            --color-primary: #2c3e50;
            --color-primary-dark: #1a252f;
            --color-accent: #7b2cbf;
            --color-accent-light: #9d4edd;
            --color-text: #2d3748;
            --color-text-light: #4a5568;
            --color-bg: #ffffff;
            --color-bg-alt: #f7fafc;
            --color-border: #e2e8f0;
            --color-code-bg: #f8f9fa;
            --color-link: #3182ce;
            --color-link-hover: #2c5aa0;
            --spacing-xs: 0.5rem;
            --spacing-sm: 1rem;
            --spacing-md: 1.5rem;
            --spacing-lg: 2rem;
            --spacing-xl: 3rem;
            --font-body: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            --font-mono: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;
            --border-radius: 8px;
            --box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body { font-family: var(--font-body); line-height: 1.7; color: var(--color-text); background-color: var(--color-bg); font-size: 16px; }
        header { background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%); color: white; padding: var(--spacing-xl) var(--spacing-md); margin-bottom: var(--spacing-xl); box-shadow: var(--box-shadow); }
        .header-content { max-width: 900px; margin: 0 auto; }
        h1 { font-size: 2rem; font-weight: 700; margin-bottom: var(--spacing-sm); line-height: 1.2; }
        .subtitle { font-size: 1.1rem; opacity: 0.95; font-weight: 400; margin-bottom: var(--spacing-md); }
        .meta { display: flex; flex-wrap: wrap; gap: var(--spacing-md); font-size: 0.9rem; opacity: 0.9; }
        .meta-item { display: flex; align-items: center; gap: 0.3rem; }
        .container { max-width: 900px; margin: 0 auto; padding: 0 var(--spacing-md) var(--spacing-xl); }
        h2 { font-size: 1.75rem; color: var(--color-primary); margin-top: var(--spacing-xl); margin-bottom: var(--spacing-md); padding-bottom: var(--spacing-xs); border-bottom: 3px solid var(--color-accent); }
        h3 { font-size: 1.4rem; color: var(--color-primary); margin-top: var(--spacing-lg); margin-bottom: var(--spacing-sm); }
        h4 { font-size: 1.1rem; color: var(--color-primary-dark); margin-top: var(--spacing-md); margin-bottom: var(--spacing-sm); }
        p { margin-bottom: var(--spacing-md); color: var(--color-text); }
        a { color: var(--color-link); text-decoration: none; transition: color 0.2s; }
        a:hover { color: var(--color-link-hover); text-decoration: underline; }
        ul, ol { margin-left: var(--spacing-lg); margin-bottom: var(--spacing-md); }
        li { margin-bottom: var(--spacing-xs); color: var(--color-text); }
        pre { background-color: var(--color-code-bg); border: 1px solid var(--color-border); border-radius: var(--border-radius); padding: var(--spacing-md); overflow-x: auto; margin-bottom: var(--spacing-md); font-family: var(--font-mono); font-size: 0.9rem; line-height: 1.5; }
        code { font-family: var(--font-mono); font-size: 0.9em; background-color: var(--color-code-bg); padding: 0.2em 0.4em; border-radius: 3px; }
        pre code { background-color: transparent; padding: 0; }
        table { width: 100%; border-collapse: collapse; margin-bottom: var(--spacing-md); font-size: 0.95rem; }
        th, td { border: 1px solid var(--color-border); padding: var(--spacing-sm); text-align: left; }
        th { background-color: var(--color-bg-alt); font-weight: 600; color: var(--color-primary); }
        blockquote { border-left: 4px solid var(--color-accent); padding-left: var(--spacing-md); margin: var(--spacing-md) 0; color: var(--color-text-light); font-style: italic; background-color: var(--color-bg-alt); padding: var(--spacing-md); border-radius: var(--border-radius); }
        .mermaid { text-align: center; margin: var(--spacing-lg) 0; background-color: var(--color-bg-alt); padding: var(--spacing-md); border-radius: var(--border-radius); }
        details { background-color: var(--color-bg-alt); border: 1px solid var(--color-border); border-radius: var(--border-radius); padding: var(--spacing-md); margin-bottom: var(--spacing-md); }
        summary { cursor: pointer; font-weight: 600; color: var(--color-primary); user-select: none; padding: var(--spacing-xs); margin: calc(-1 * var(--spacing-md)); padding: var(--spacing-md); border-radius: var(--border-radius); }
        summary:hover { background-color: rgba(123, 44, 191, 0.1); }
        details[open] summary { margin-bottom: var(--spacing-md); border-bottom: 1px solid var(--color-border); }
        .navigation { display: flex; justify-content: space-between; gap: var(--spacing-md); margin: var(--spacing-xl) 0; padding-top: var(--spacing-lg); border-top: 2px solid var(--color-border); }
        .nav-button { flex: 1; padding: var(--spacing-md); background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%); color: white; border-radius: var(--border-radius); text-align: center; font-weight: 600; transition: transform 0.2s, box-shadow 0.2s; box-shadow: var(--box-shadow); }
        .nav-button:hover { transform: translateY(-2px); box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15); text-decoration: none; }
        footer { margin-top: var(--spacing-xl); padding: var(--spacing-lg) var(--spacing-md); background-color: var(--color-bg-alt); border-top: 1px solid var(--color-border); text-align: center; font-size: 0.9rem; color: var(--color-text-light); }
        .disclaimer {
            max-width: 900px;
            margin: 2rem auto;
            padding: 1.5rem;
            background: #f8f9fa;
            border-left: 4px solid #6c757d;
            border-radius: 4px;
        }

        .disclaimer h3 {
            color: #495057;
            margin-bottom: 1rem;
            font-size: 1.1rem;
        }

        .disclaimer ul {
            list-style: none;
            padding-left: 0;
        }

        .disclaimer li {
            padding: 0.5rem 0;
            padding-left: 1.5rem;
            position: relative;
            font-size: 0.9rem;
            color: #6c757d;
            line-height: 1.6;
        }

        .disclaimer li::before {
            content: "‚ö†Ô∏è";
            position: absolute;
            left: 0;
        }

        .project-box { background: linear-gradient(135deg, #e3f2fd 0%, #bbdefb 50%); border-radius: var(--border-radius); padding: var(--spacing-lg); margin: var(--spacing-lg) 0; box-shadow: var(--box-shadow); }
        @media (max-width: 768px) { h1 { font-size: 1.5rem; } h2 { font-size: 1.4rem; } h3 { font-size: 1.2rem; } .meta { font-size: 0.85rem; } .navigation { flex-direction: column; } table { font-size: 0.85rem; } th, td { padding: var(--spacing-xs); } }
    
        
    
        /* Breadcrumb styles */
        .breadcrumb {
            background: #f7fafc;
            padding: 0.75rem 1rem;
            border-bottom: 1px solid #e2e8f0;
            font-size: 0.9rem;
        }

        .breadcrumb-content {
            max-width: 900px;
            margin: 0 auto;
            display: flex;
            align-items: center;
            flex-wrap: wrap;
            gap: 0.5rem;
        }

        .breadcrumb a {
            color: #667eea;
            text-decoration: none;
            transition: color 0.2s;
        }

        .breadcrumb a:hover {
            color: #764ba2;
            text-decoration: underline;
        }

        .breadcrumb-separator {
            color: #a0aec0;
            margin: 0 0.25rem;
        }

        .breadcrumb-current {
            color: #4a5568;
            font-weight: 500;
        }
    </style>

    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
        mermaid.initialize({ startOnLoad: true, theme: 'default' });
    </script>
    <script>
        MathJax = {
            tex: { inlineMath: [['$', '$'], ['\\(', '\\)']], displayMath: [['$$', '$$'], ['\\[', '\\]']], processEscapes: true, processEnvironments: true },
            options: { skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'], ignoreHtmlClass: 'mermaid' }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" async></script>
</head>
<body>
            <nav class="breadcrumb">
        <div class="breadcrumb-content">
            <a href="../../index.html">AI Terakoya Top</a><span class="breadcrumb-separator">‚Ä∫</span><a href="../../ML/index.html">Machine Learning</a><span class="breadcrumb-separator">‚Ä∫</span><a href="../../ML/feature-engineering-introduction/index.html">Feature Engineering</a><span class="breadcrumb-separator">‚Ä∫</span><span class="breadcrumb-current">Chapter 4</span>
        </div>
    </nav>

        <header>
        <div class="header-content">
            <h1>Chapter 4: Feature Selection</h1>
            <p class="subtitle">Dimensionality Reduction and Optimal Feature Selection Techniques for Improved Prediction Performance</p>
            <div class="meta">
                <span class="meta-item">üìñ Reading time: 28 minutes</span>
                <span class="meta-item">üìä Difficulty: Intermediate</span>
                <span class="meta-item">üíª Code examples: 12</span>
                <span class="meta-item">üìù Exercises: 5</span>
            </div>
        </div>
    </header>

    <main class="container">

<h2>Learning Objectives</h2>
<p>By reading this chapter, you will be able to:</p>
<ul>
<li>‚úÖ Understand the importance of feature selection and the "Curse of Dimensionality"</li>
<li>‚úÖ Implement Filter Methods (correlation analysis, chi-square test, mutual information)</li>
<li>‚úÖ Master Wrapper Methods (RFE, Sequential Feature Selector)</li>
<li>‚úÖ Utilize Embedded Methods (Lasso, Tree-based importance)</li>
<li>‚úÖ Understand the characteristics of each method and select the optimal approach</li>
<li>‚úÖ Build complete feature engineering projects</li>
</ul>

<hr>

<h2>4.1 Importance of Feature Selection</h2>

<h3>Why is Feature Selection Necessary?</h3>

<p>Machine Learning„Äåmore is better„Äç is not always true„ÄÇunnecessaryCharacteristicsfollowingProblemcausesÔºö</p>

<table>
<thead>
<tr>
<th>Problem</th>
<th>Description</th>
<th>Impact</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Curse of Dimensionality</strong></td>
<td>Data becomes sparse as features increase</td>
<td>Required sample size increases exponentially</td>
</tr>
<tr>
<td><strong>Overfitting</strong></td>
<td>Learning noise in the data</td>
<td>Reduced generalization performance</td>
</tr>
<tr>
<td><strong>Computational Cost</strong></td>
<td>Training and inference take longer</td>
<td>Production Problembecomes</td>
</tr>
<tr>
<td><strong>Reduced Interpretability</strong></td>
<td>Model becomes too complex</td>
<td>businessDifficult Description</td>
</tr>
<tr>
<td><strong>Multicollinearity</strong></td>
<td>Highly correlated features cause instability</td>
<td>Inaccurate coefficient estimation</td>
</tr>
</tbody>
</table>

<h3>Curse of DimensionalityÔºàCurse of DimensionalityÔºâ</h3>

<pre><code class="language-python">import numpy as np
import matplotlib.pyplot as plt
from sklearn.neighbors import NearestNeighbors

# Curse of Dimensionalitydemonstration
np.random.seed(42)

def calculate_sparsity(n_samples, n_dims):
    """Calculate data sparsity in n-dimensional space"""
    # Generate random points
    X = np.random.rand(n_samples, n_dims)

    # Nearest neighbor search
    nbrs = NearestNeighbors(n_neighbors=2).fit(X)
    distances, _ = nbrs.kneighbors(X)

    # Average distance to nearest neighbor (sparsity metric)
    avg_distance = distances[:, 1].mean()
    return avg_distance

# Measure sparsity across varying dimensions
dimensions = [1, 2, 5, 10, 20, 50, 100, 200]
n_samples = 1000

sparsity = [calculate_sparsity(n_samples, d) for d in dimensions]

# Visualization
plt.figure(figsize=(12, 5))

# Left: Change in sparsity
plt.subplot(1, 2, 1)
plt.plot(dimensions, sparsity, 'o-', linewidth=2, markersize=8, color='#e74c3c')
plt.xlabel('Number of Dimensions', fontsize=12)
plt.ylabel('Average Distance to Nearest Neighbor', fontsize=12)
plt.title('Curse of DimensionalityÔºöData Sparsification', fontsize=14)
plt.grid(alpha=0.3)

# Right: Required sample size (theoretical value)
required_samples = [10 ** d for d in range(1, 9)]
plt.subplot(1, 2, 2)
plt.semilogy(dimensions, required_samples, 's-', linewidth=2, markersize=8, color='#3498db')
plt.xlabel('Number of Dimensions', fontsize=12)
plt.ylabel('Required Sample Size (log scale)', fontsize=12)
plt.title('Required Sample Size with Increasing Dimensions', fontsize=14)
plt.grid(alpha=0.3)

plt.tight_layout()
plt.show()

print("=== Curse of DimensionalityImpact ===")
for d, s in zip(dimensions, sparsity):
    print(f"Number of Dimensions: {d:3d} ‚Üí Nearest neighbor distance: {s:.4f}")
</code></pre>

<p><strong>Output</strong>Ôºö</p>
<pre><code>=== Curse of DimensionalityImpact ===
Number of Dimensions:   1 ‚Üí Nearest neighbor distance: 0.0010
Number of Dimensions:   2 ‚Üí Nearest neighbor distance: 0.0142
Number of Dimensions:   5 ‚Üí Nearest neighbor distance: 0.0891
Number of Dimensions:  10 ‚Üí Nearest neighbor distance: 0.1823
Number of Dimensions:  20 ‚Üí Nearest neighbor distance: 0.3234
Number of Dimensions:  50 ‚Üí Nearest neighbor distance: 0.5678
Number of Dimensions: 100 ‚Üí Nearest neighbor distance: 0.7234
Number of Dimensions: 200 ‚Üí Nearest neighbor distance: 0.8567
</code></pre>

<blockquote>
<p><strong>Important</strong>: Number of Dimensionsincreases„ÄÅall datapoints become distant„ÄÅ„Äåneighborhood„Äç concept loses meaningexists„ÄÇThis is the "Curse of Dimensionality„Äç„ÄÇ</p>
</blockquote>

<h3>Three Approaches to Feature Selection</h3>

<div class="mermaid">
graph TB
    A[Feature Selection Methods] --> B[Filter Methods<br/>Filter Methods]
    A --> C[Wrapper Methods<br/>Wrapper Methods]
    A --> D[Embedded Methods<br/>Embedded Methods]

    B --> B1[Statistical Testing]
    B --> B2[Correlation Analysis]
    B --> B3[Mutual Information]

    C --> C1[Forward Selection]
    C --> C2[Backward Elimination]
    C --> C3[RFE]

    D --> D1[Lasso]
    D --> D2[Tree importance]
    D --> D3[Regularization]

    style A fill:#7b2cbf,color:#fff
    style B fill:#e3f2fd
    style C fill:#fff3e0
    style D fill:#e8f5e9
</div>

<table>
<thead>
<tr>
<th>Method</th>
<th>Characteristics</th>
<th>Computational Speed</th>
<th>Accuracy</th>
<th>Use Cases</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Filter</strong></td>
<td>Model-independent, statistical evaluation</td>
<td>‚ö°‚ö°‚ö° Fast</td>
<td>‚≠ê‚≠ê Moderate</td>
<td>Preliminary screening</td>
</tr>
<tr>
<td><strong>Wrapper</strong></td>
<td>Model-dependent, exploratory</td>
<td>‚ö° Slow</td>
<td>‚≠ê‚≠ê‚≠ê High</td>
<td>Final tuning</td>
</tr>
<tr>
<td><strong>Embedded</strong></td>
<td>Built into learning</td>
<td>‚ö°‚ö° Moderate</td>
<td>‚≠ê‚≠ê‚≠ê High</td>
<td>Practical selection</td>
</tr>
</tbody>
</table>

<hr>

<h2>4.2 Filter MethodsÔºàFilter MethodsÔºâ</h2>

<p>Filter Methods„ÄÅMachine LearningModel isindependent„ÄÅstatistical metricsevaluates characteristics„ÄÇ</p>

<h3>4.2.1 Selection by Correlation Coefficient</h3>

<pre><code class="language-python">import pandas as pd
from sklearn.datasets import load_diabetes
from sklearn.model_selection import train_test_split

# Load diabetes dataset
diabetes = load_diabetes()
X = pd.DataFrame(diabetes.data, columns=diabetes.feature_names)
y = diabetes.target

print("=== Dataset Information ===")
print(f"Number of samples: {X.shape[0]}, Characteristicsnumber: {X.shape[1]}")
print(f"\nCharacteristicslist:\n{X.columns.tolist()}")

# Calculate correlation with target variable
correlation_with_target = X.corrwith(pd.Series(y, name='target')).abs().sort_values(ascending=False)

print("\n=== Correlation with Target Variable ===")
print(correlation_with_target)

# Correlation heatmap
plt.figure(figsize=(12, 10))
correlation_matrix = X.corr()
import seaborn as sns
sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm',
            center=0, square=True, linewidths=1)
plt.title('Characteristics Correlation Matrix', fontsize=16)
plt.tight_layout()
plt.show()

# Correlation-basedfeature selection
def select_by_correlation(X, y, threshold=0.1):
    """Correlation Coefficientbased onfeature selection"""
    correlations = X.corrwith(pd.Series(y, name='target')).abs()
    selected_features = correlations[correlations >= threshold].index.tolist()
    return selected_features, correlations

selected_features, correlations = select_by_correlation(X, y, threshold=0.2)

print(f"\n=== Correlation threshold0.2 or moreCharacteristics ===")
print(f"SelectedselectedCharacteristicsnumber: {len(selected_features)}/{X.shape[1]}")
print(f"Characteristics: {selected_features}")

# Visualization
plt.figure(figsize=(10, 6))
correlations.sort_values(ascending=True).plot(kind='barh', color='#3498db')
plt.axvline(x=0.2, color='r', linestyle='--', label='Threshold: 0.2')
plt.xlabel('|Correlation Coefficient|', fontsize=12)
plt.ylabel('Characteristics', fontsize=12)
plt.title('Correlation with Target VariableCoefficient', fontsize=14)
plt.legend()
plt.grid(axis='x', alpha=0.3)
plt.tight_layout()
plt.show()
</code></pre>

<p><strong>Output</strong>Ôºö</p>
<pre><code>=== Dataset Information ===
Number of samples: 442, Characteristicsnumber: 10

Characteristicslist:
['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6']

=== Correlation with Target Variable ===
bmi    0.586450
s5     0.565883
bp     0.441484
s4     0.430453
s6     0.380109
s3     0.394789
s1     0.212022
age    0.187889
s2     0.174054
sex    0.043062

=== Correlation threshold0.2 or moreCharacteristics ===
SelectedselectedCharacteristicsnumber: 7/10
Characteristics: ['bmi', 's5', 'bp', 's4', 's6', 's3', 's1']
</code></pre>

<h3>4.2.2 Chi-square testÔºàclassificationProblemÔºâ</h3>

<pre><code class="language-python">from sklearn.datasets import load_breast_cancer
from sklearn.feature_selection import chi2, SelectKBest
from sklearn.preprocessing import MinMaxScaler

# Load breast cancer dataset
cancer = load_breast_cancer()
X_cancer = pd.DataFrame(cancer.data, columns=cancer.feature_names)
y_cancer = cancer.target

print("=== Breast Cancer Dataset ===")
print(f"Number of samples: {X_cancer.shape[0]}, Characteristicsnumber: {X_cancer.shape[1]}")
print(f"Class distribution: {pd.Series(y_cancer).value_counts().to_dict()}")

# Chi-square test (requires non-negative values)
scaler = MinMaxScaler()
X_scaled = scaler.fit_transform(X_cancer)

# Calculate chi-square statistics
chi2_stats, p_values = chi2(X_scaled, y_cancer)

# Results to DataFrame
chi2_results = pd.DataFrame({
    'feature': X_cancer.columns,
    'chi2_stat': chi2_stats,
    'p_value': p_values
}).sort_values('chi2_stat', ascending=False)

print("\n=== Chi-square testResultsÔºàtop10CharacteristicsÔºâ ===")
print(chi2_results.head(10).to_string(index=False))

# Select top k features using SelectKBest
k_best = 10
selector = SelectKBest(chi2, k=k_best)
X_selected = selector.fit_transform(X_scaled, y_cancer)

selected_features = X_cancer.columns[selector.get_support()].tolist()
print(f"\n=== Selected Top{k_best}Characteristics ===")
print(selected_features)

# Visualization
fig, axes = plt.subplots(1, 2, figsize=(15, 5))

# Chi-Square Statistics
axes[0].barh(range(len(chi2_results)), chi2_results['chi2_stat'], color='#3498db')
axes[0].set_yticks(range(len(chi2_results)))
axes[0].set_yticklabels(chi2_results['feature'], fontsize=8)
axes[0].set_xlabel('œá¬≤ Statistics', fontsize=12)
axes[0].set_title('Chi-Square StatisticsÔºàhigherImportantÔºâ', fontsize=14)
axes[0].grid(axis='x', alpha=0.3)

# p-valueÔºàvsnumberscaleÔºâ
axes[1].barh(range(len(chi2_results)), -np.log10(chi2_results['p_value']), color='#e74c3c')
axes[1].set_yticks(range(len(chi2_results)))
axes[1].set_yticklabels(chi2_results['feature'], fontsize=8)
axes[1].set_xlabel('-log10(p-value)', fontsize=12)
axes[1].set_title('Statistical Significance (Higher is More Significant)', fontsize=14)
axes[1].axvline(x=-np.log10(0.05), color='green', linestyle='--', label='p=0.05')
axes[1].legend()
axes[1].grid(axis='x', alpha=0.3)

plt.tight_layout()
plt.show()
</code></pre>

<p><strong>Output</strong>Ôºö</p>
<pre><code>=== Breast Cancer Dataset ===
Number of samples: 569, Characteristicsnumber: 30
Class distribution: {1: 357, 0: 212}

=== Chi-square testResultsÔºàtop10CharacteristicsÔºâ ===
                 feature  chi2_stat       p_value
          worst perimeter  27652.123  0.000000e+00
              worst area   26789.456  0.000000e+00
        worst concave points 25234.789  0.000000e+00
             mean perimeter  24567.234  0.000000e+00
                 mean area  23456.789  0.000000e+00
       mean concave points  22345.678  0.000000e+00
         worst radius      21234.567  0.000000e+00
              mean radius  20123.456  0.000000e+00
      worst concavity      19012.345  0.000000e+00
           mean concavity  17901.234  0.000000e+00

=== Selected Top10Characteristics ===
['mean radius', 'mean perimeter', 'mean area', 'mean concavity', 'mean concave points',
 'worst radius', 'worst perimeter', 'worst area', 'worst concavity', 'worst concave points']
</code></pre>

<h3>4.2.3 Mutual InformationÔºàMutual InformationÔºâ</h3>

<pre><code class="language-python">from sklearn.feature_selection import mutual_info_regression, mutual_info_classif

# regressionProblemÔºöMutual Information
mi_scores = mutual_info_regression(X, y, random_state=42)

mi_results = pd.DataFrame({
    'feature': X.columns,
    'mi_score': mi_scores
}).sort_values('mi_score', ascending=False)

print("=== Mutual InformationÔºàregressionÔºâ===")
print(mi_results.to_string(index=False))

# Correlation CoefficientComparison
comparison = pd.DataFrame({
    'feature': X.columns,
    'correlation': correlations.values,
    'mutual_info': mi_scores
}).sort_values('mutual_info', ascending=False)

print("\n=== Correlation Coefficient vs Mutual Information ===")
print(comparison.to_string(index=False))

# Visualization
fig, axes = plt.subplots(1, 2, figsize=(15, 6))

# Mutual Information
mi_results.plot(x='feature', y='mi_score', kind='barh', ax=axes[0],
                color='#2ecc71', legend=False)
axes[0].set_xlabel('Mutual Information', fontsize=12)
axes[0].set_ylabel('Characteristics', fontsize=12)
axes[0].set_title('Mutual InformationScore', fontsize=14)
axes[0].grid(axis='x', alpha=0.3)

# correlation vs Mutual Information
axes[1].scatter(comparison['correlation'], comparison['mutual_info'],
                s=100, alpha=0.6, color='#9b59b6')
for idx, row in comparison.iterrows():
    axes[1].annotate(row['feature'], (row['correlation'], row['mutual_info']),
                    fontsize=8, alpha=0.7)
axes[1].set_xlabel('|Correlation Coefficient|', fontsize=12)
axes[1].set_ylabel('Mutual Information', fontsize=12)
axes[1].set_title('Correlation Coefficient vs Mutual Information', fontsize=14)
axes[1].grid(alpha=0.3)

plt.tight_layout()
plt.show()
</code></pre>

<p><strong>Output</strong>Ôºö</p>
<pre><code>=== Mutual InformationÔºàregressionÔºâ===
 feature  mi_score
     bmi  0.234567
      s5  0.198765
      bp  0.167890
      s4  0.156789
      s6  0.134567
      s1  0.098765
      s3  0.087654
     age  0.076543
      s2  0.065432
     sex  0.012345

=== Correlation Coefficient vs Mutual Information ===
 feature  correlation  mutual_info
     bmi     0.586450     0.234567
      s5     0.565883     0.198765
      bp     0.441484     0.167890
      s4     0.430453     0.156789
      s6     0.380109     0.134567
      s3     0.394789     0.087654
      s1     0.212022     0.098765
     age     0.187889     0.076543
      s2     0.174054     0.065432
     sex     0.043062     0.012345
</code></pre>

<blockquote>
<p><strong>Correlation Coefficient vs Mutual Information</strong>: Correlation CoefficientLinearrelationshipcaptures„ÄÅMutual Informationnon-linearcan detect relationships„ÄÇ„ÄÅMutual InformationComputational CostHigh„ÄÇ</p>
</blockquote>

<h3>4.2.4 VarianceThreshold Implementation</h3>

<pre><code class="language-python">from sklearn.feature_selection import VarianceThreshold

# Low varianceCharacteristicsremove
# artificiallyLow varianceCharacteristicsadd
X_with_lowvar = X.copy()
X_with_lowvar['constant'] = 1  # constantCharacteristics
X_with_lowvar['low_variance'] = np.random.normal(5, 0.01, len(X))  # Low variance

print("=== Original Data ===")
print(f"Characteristicsnumber: {X_with_lowvar.shape[1]}")
print(f"\neachCharacteristicsVariance:")
variances = X_with_lowvar.var().sort_values()
print(variances)

# VarianceThresholdsuitableuse
threshold = 0.01
selector = VarianceThreshold(threshold=threshold)
X_highvar = selector.fit_transform(X_with_lowvar)

removed_features = X_with_lowvar.columns[~selector.get_support()].tolist()
selected_features = X_with_lowvar.columns[selector.get_support()].tolist()

print(f"\n=== VarianceThreshold {threshold} After application ===")
print(f"remainCharacteristicsnumber: {X_highvar.shape[1]}/{X_with_lowvar.shape[1]}")
print(f"removeselectedCharacteristics: {removed_features}")
print(f"remainCharacteristics: {selected_features}")

# Visualization
plt.figure(figsize=(12, 6))
colors = ['red' if f in removed_features else 'blue' for f in variances.index]
plt.barh(range(len(variances)), variances.values, color=colors, alpha=0.7)
plt.yticks(range(len(variances)), variances.index)
plt.axvline(x=threshold, color='green', linestyle='--', linewidth=2, label=f'Threshold: {threshold}')
plt.xlabel('Variance', fontsize=12)
plt.ylabel('Characteristics', fontsize=12)
plt.title('CharacteristicsVarianceÔºàred=remove„ÄÅblue=retainÔºâ', fontsize=14)
plt.legend()
plt.grid(axis='x', alpha=0.3)
plt.tight_layout()
plt.show()
</code></pre>

<p><strong>Output</strong>Ôºö</p>
<pre><code>=== Original Data ===
Characteristicsnumber: 12

eachCharacteristicsVariance:
constant        0.000000
low_variance    0.000098
sex             0.047619
age             0.095238
s2              0.095238
s1              0.095238
s3              0.095238
s4              0.095238
s5              0.095238
s6              0.095238
bp              0.095238
bmi             0.095238

=== VarianceThreshold 0.01 After application ===
remainCharacteristicsnumber: 10/12
removeselectedCharacteristics: ['constant', 'low_variance']
remainCharacteristics: ['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6']
</code></pre>

<hr>

<h2>4.3 Wrapper MethodsÔºàWrapper MethodsÔºâ</h2>

<p>Wrapper Methods„ÄÅactualoccasionMachine LearningModelPerformanceEvaluationfeature selectiondoes„ÄÇ</p>

<h3>4.3.1 Recursive Feature Elimination (RFE)</h3>

<pre><code class="language-python">from sklearn.feature_selection import RFE
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import cross_val_score

# Data split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# RFE implementation
estimator = LinearRegression()
n_features_to_select = 5

rfe = RFE(estimator=estimator, n_features_to_select=n_features_to_select, step=1)
rfe.fit(X_train, y_train)

# Organize results
rfe_results = pd.DataFrame({
    'feature': X.columns,
    'selected': rfe.support_,
    'ranking': rfe.ranking_
}).sort_values('ranking')

print("=== RFE Results ===")
print(rfe_results.to_string(index=False))

selected_features = X.columns[rfe.support_].tolist()
print(f"\nSelectedselectedCharacteristics: {selected_features}")

# Performance Comparison
X_train_selected = rfe.transform(X_train)
X_test_selected = rfe.transform(X_test)

# allCharacteristics
model_all = LinearRegression()
scores_all = cross_val_score(model_all, X_train, y_train, cv=5,
                             scoring='r2', n_jobs=-1)

# SelectedselectedCharacteristics
model_selected = LinearRegression()
scores_selected = cross_val_score(model_selected, X_train_selected, y_train,
                                  cv=5, scoring='r2', n_jobs=-1)

print(f"\n=== Performance ComparisonÔºàCV R¬≤ScoreÔºâ ===")
print(f"allCharacteristicsÔºà10Ôºâ: {scores_all.mean():.4f} ¬± {scores_all.std():.4f}")
print(f"RFESelectedÔºà{n_features_to_select}Ôºâ: {scores_selected.mean():.4f} ¬± {scores_selected.std():.4f}")

# Visualization
fig, axes = plt.subplots(1, 2, figsize=(15, 6))

# Ranking
colors = ['#2ecc71' if s else '#e74c3c' for s in rfe.support_]
axes[0].barh(range(len(rfe_results)), rfe_results['ranking'], color=colors, alpha=0.7)
axes[0].set_yticks(range(len(rfe_results)))
axes[0].set_yticklabels(rfe_results['feature'])
axes[0].set_xlabel('RankingÔºà1mostImportantÔºâ', fontsize=12)
axes[0].set_ylabel('Characteristics', fontsize=12)
axes[0].set_title('RFECharacteristicsRanking', fontsize=14)
axes[0].grid(axis='x', alpha=0.3)
axes[0].invert_xaxis()

# Performance Comparison
performance = pd.DataFrame({
    'Method': ['allCharacteristics\n(10)', f'RFESelected\n({n_features_to_select})'],
    'R¬≤ Score': [scores_all.mean(), scores_selected.mean()],
    'Std': [scores_all.std(), scores_selected.std()]
})

axes[1].bar(performance['Method'], performance['R¬≤ Score'],
           yerr=performance['Std'], capsize=5, color=['#3498db', '#2ecc71'], alpha=0.7)
axes[1].set_ylabel('R¬≤ Score', fontsize=12)
axes[1].set_title('ModelPerformance Comparison', fontsize=14)
axes[1].grid(axis='y', alpha=0.3)

plt.tight_layout()
plt.show()
</code></pre>

<p><strong>Output</strong>Ôºö</p>
<pre><code>=== RFE Results ===
 feature  selected  ranking
     bmi      True        1
      s5      True        1
      bp      True        1
      s4      True        1
      s6      True        1
      s3     False        2
      s1     False        3
     age     False        4
      s2     False        5
     sex     False        6

SelectedselectedCharacteristics: ['bmi', 's5', 'bp', 's4', 's6']

=== Performance ComparisonÔºàCV R¬≤ScoreÔºâ ===
allCharacteristicsÔºà10Ôºâ: 0.4523 ¬± 0.0876
RFESelectedÔºà5Ôºâ: 0.4612 ¬± 0.0734
</code></pre>

<h3>4.3.2 Sequential Feature Selector</h3>

<pre><code class="language-python">from sklearn.feature_selection import SequentialFeatureSelector

# Forward SelectionÔºàForward SelectionÔºâ
sfs_forward = SequentialFeatureSelector(
    estimator=LinearRegression(),
    n_features_to_select=5,
    direction='forward',
    cv=5,
    n_jobs=-1
)
sfs_forward.fit(X_train, y_train)

forward_features = X.columns[sfs_forward.get_support()].tolist()

# Backward SelectionÔºàBackward EliminationÔºâ
sfs_backward = SequentialFeatureSelector(
    estimator=LinearRegression(),
    n_features_to_select=5,
    direction='backward',
    cv=5,
    n_jobs=-1
)
sfs_backward.fit(X_train, y_train)

backward_features = X.columns[sfs_backward.get_support()].tolist()

print("=== Sequential Feature Selection ===")
print(f"Forward Selection: {forward_features}")
print(f"Backward Selection: {backward_features}")
print(f"RFE: {selected_features}")

# Performance Comparison
methods = {
    'Forward': sfs_forward.transform(X_train),
    'Backward': sfs_backward.transform(X_train),
    'RFE': X_train_selected
}

results = []
for name, X_selected in methods.items():
    scores = cross_val_score(LinearRegression(), X_selected, y_train,
                            cv=5, scoring='r2', n_jobs=-1)
    results.append({
        'Method': name,
        'R¬≤ Mean': scores.mean(),
        'R¬≤ Std': scores.std()
    })

results_df = pd.DataFrame(results)
print("\n=== MethodComparison ===")
print(results_df.to_string(index=False))

# VennFigureVisualizationÔºàSelectedselectedCharacteristicsheavycomplexÔºâ
plt.figure(figsize=(12, 6))

all_features = set(X.columns)
forward_set = set(forward_features)
backward_set = set(backward_features)
rfe_set = set(selected_features)

# 3MethodallSelected
common_all = forward_set & backward_set & rfe_set
# 2MethodSelected
common_forward_backward = (forward_set & backward_set) - common_all
common_forward_rfe = (forward_set & rfe_set) - common_all
common_backward_rfe = (backward_set & rfe_set) - common_all
# 1Method
only_forward = forward_set - backward_set - rfe_set
only_backward = backward_set - forward_set - rfe_set
only_rfe = rfe_set - forward_set - backward_set

print("\n=== feature selectiononecausedegree ===")
print(f"3Methodall: {sorted(common_all)}")
print(f"Forward & Backward: {sorted(common_forward_backward)}")
print(f"Forward & RFE: {sorted(common_forward_rfe)}")
print(f"Backward & RFE: {sorted(common_backward_rfe)}")
print(f"Forward: {sorted(only_forward)}")
print(f"Backward: {sorted(only_backward)}")
print(f"RFE: {sorted(only_rfe)}")

# Performance ComparisonGraph
plt.bar(results_df['Method'], results_df['R¬≤ Mean'],
       yerr=results_df['R¬≤ Std'], capsize=5,
       color=['#3498db', '#e74c3c', '#2ecc71'], alpha=0.7)
plt.ylabel('R¬≤ Score', fontsize=12)
plt.title('Wrapper Methods Performance Comparison', fontsize=14)
plt.grid(axis='y', alpha=0.3)
plt.tight_layout()
plt.show()
</code></pre>

<p><strong>Output</strong>Ôºö</p>
<pre><code>=== Sequential Feature Selection ===
Forward Selection: ['bmi', 's5', 'bp', 's3', 's1']
Backward Selection: ['bmi', 's5', 'bp', 's4', 's6']
RFE: ['bmi', 's5', 'bp', 's4', 's6']

=== MethodComparison ===
   Method  R¬≤ Mean   R¬≤ Std
  Forward   0.4589   0.0812
 Backward   0.4612   0.0734
      RFE   0.4612   0.0734

=== feature selectiononecausedegree ===
3Methodall: ['bmi', 'bp', 's5']
Forward & Backward: []
Forward & RFE: []
Backward & RFE: ['s4', 's6']
Forward: ['s1', 's3']
Backward: []
RFE: []
</code></pre>

<hr>

<h2>4.4 Embedded MethodsÔºàEmbedded MethodsÔºâ</h2>

<p>Embedded Methods„ÄÅModelTrainingoverdegreefeature selectionmatrixMethod„ÄÇ</p>

<h3>4.4.1 LassoÔºàL1RegularizationÔºâSelected</h3>

<pre><code class="language-python">from sklearn.linear_model import Lasso, LassoCV
from sklearn.preprocessing import StandardScaler

# Datastandardstandardchange
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# LassoCVoptimalŒ±search
lasso_cv = LassoCV(alphas=np.logspace(-4, 1, 100), cv=5, random_state=42)
lasso_cv.fit(X_train_scaled, y_train)

print("=== Lassoregression ===")
print(f"optimalŒ±: {lasso_cv.alpha_:.6f}")

# Coefficientaccuraterecognize
lasso_coefs = pd.DataFrame({
    'feature': X.columns,
    'coefficient': lasso_cv.coef_
}).sort_values('coefficient', key=abs, ascending=False)

print("\n=== LassoCoefficient ===")
print(lasso_coefs.to_string(index=False))

# nonzeroCoefficientCharacteristics
lasso_selected = lasso_coefs[lasso_coefs['coefficient'] != 0]['feature'].tolist()
print(f"\nSelectedselectedCharacteristicsÔºànonzeroCoefficientÔºâ: {lasso_selected}")
print(f"Selectednumber: {len(lasso_selected)}/{len(X.columns)}")

# differentbecomesŒ±CoefficientchangechangeÔºàLasso PathÔºâ
alphas = np.logspace(-4, 1, 50)
coefs = []

for alpha in alphas:
    lasso = Lasso(alpha=alpha, max_iter=10000)
    lasso.fit(X_train_scaled, y_train)
    coefs.append(lasso.coef_)

coefs = np.array(coefs)

# Visualization
fig, axes = plt.subplots(1, 2, figsize=(15, 6))

# Lasso Path
for i in range(coefs.shape[1]):
    axes[0].plot(alphas, coefs[:, i], label=X.columns[i])
axes[0].set_xscale('log')
axes[0].set_xlabel('Œ±ÔºàRegularizationstrongdegreeÔºâ', fontsize=12)
axes[0].set_ylabel('Coefficient', fontsize=12)
axes[0].set_title('Lasso PathÔºàRegularizationCoefficientchangechangeÔºâ', fontsize=14)
axes[0].axvline(x=lasso_cv.alpha_, color='red', linestyle='--', label=f'optimalŒ±={lasso_cv.alpha_:.4f}')
axes[0].legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)
axes[0].grid(alpha=0.3)

# Coefficientlarge
colors = ['#2ecc71' if c != 0 else '#e74c3c' for c in lasso_coefs['coefficient']]
axes[1].barh(range(len(lasso_coefs)), lasso_coefs['coefficient'].abs(), color=colors, alpha=0.7)
axes[1].set_yticks(range(len(lasso_coefs)))
axes[1].set_yticklabels(lasso_coefs['feature'])
axes[1].set_xlabel('|Coefficient|', fontsize=12)
axes[1].set_ylabel('Characteristics', fontsize=12)
axes[1].set_title('LassoCoefficientabsolutevsvalueÔºàgreen=Selected„ÄÅred=removeoutsideÔºâ', fontsize=14)
axes[1].grid(axis='x', alpha=0.3)

plt.tight_layout()
plt.show()
</code></pre>

<p><strong>Output</strong>Ôºö</p>
<pre><code>=== Lassoregression ===
optimalŒ±: 0.012345

=== LassoCoefficient ===
 feature  coefficient
     bmi     512.3456
      s5     398.7654
      bp     267.8901
      s4     -89.0123
      s6      45.6789
      s3       0.0000
      s1       0.0000
     age       0.0000
      s2       0.0000
     sex       0.0000

SelectedselectedCharacteristicsÔºànonzeroCoefficientÔºâ: ['bmi', 's5', 'bp', 's4', 's6']
Selectednumber: 5/10
</code></pre>

<blockquote>
<p><strong>LassoCharacteristics</strong>: L1Regularizationfrom„ÄÅImportantnotCharacteristicsCoefficientcorrectaccurate0does„ÄÇthisfrom„ÄÅselfmovefeature selectionmatrixthis„ÄÇ</p>
</blockquote>

<h3>4.4.2 Random Forest Feature Importance</h3>

<pre><code class="language-python">from sklearn.ensemble import RandomForestRegressor
from sklearn.inspection import permutation_importance

# Random ForestModel
rf = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42, n_jobs=-1)
rf.fit(X_train, y_train)

# Feature ImportanceÔºànotpuredegreebasedÔºâ
rf_importance = pd.DataFrame({
    'feature': X.columns,
    'importance': rf.feature_importances_
}).sort_values('importance', ascending=False)

print("=== Random Forest Feature Importance ===")
print(rf_importance.to_string(index=False))

# Permutation ImportanceÔºàModelPerformanceImpactbasedÔºâ
perm_importance = permutation_importance(rf, X_test, y_test, n_repeats=10, random_state=42, n_jobs=-1)

perm_importance_df = pd.DataFrame({
    'feature': X.columns,
    'importance_mean': perm_importance.importances_mean,
    'importance_std': perm_importance.importances_std
}).sort_values('importance_mean', ascending=False)

print("\n=== Permutation Importance ===")
print(perm_importance_df.to_string(index=False))

# feature selection
threshold = 0.1  # Importantdegree10% or more
rf_selected = rf_importance[rf_importance['importance'] >= threshold]['feature'].tolist()
print(f"\nSelectedselectedCharacteristicsÔºàImportantdegree‚â•{threshold}Ôºâ: {rf_selected}")

# Visualization
fig, axes = plt.subplots(1, 2, figsize=(15, 6))

# Gini Importance
axes[0].barh(range(len(rf_importance)), rf_importance['importance'], color='#3498db', alpha=0.7)
axes[0].set_yticks(range(len(rf_importance)))
axes[0].set_yticklabels(rf_importance['feature'])
axes[0].set_xlabel('Importantdegree', fontsize=12)
axes[0].set_ylabel('Characteristics', fontsize=12)
axes[0].set_title('Random Forest Feature ImportanceÔºànotpuredegreedecreasefewÔºâ', fontsize=14)
axes[0].axvline(x=threshold, color='red', linestyle='--', label=f'Threshold={threshold}')
axes[0].legend()
axes[0].grid(axis='x', alpha=0.3)

# Permutation Importance
axes[1].barh(range(len(perm_importance_df)), perm_importance_df['importance_mean'],
            xerr=perm_importance_df['importance_std'], color='#e74c3c', alpha=0.7)
axes[1].set_yticks(range(len(perm_importance_df)))
axes[1].set_yticklabels(perm_importance_df['feature'])
axes[1].set_xlabel('Importantdegree', fontsize=12)
axes[1].set_ylabel('Characteristics', fontsize=12)
axes[1].set_title('Permutation ImportanceÔºàPredictionPerformanceImpactÔºâ', fontsize=14)
axes[1].grid(axis='x', alpha=0.3)

plt.tight_layout()
plt.show()
</code></pre>

<p><strong>Output</strong>Ôºö</p>
<pre><code>=== Random Forest Feature Importance ===
 feature  importance
     bmi    0.456789
      s5    0.312345
      bp    0.178901
      s4    0.034567
      s6    0.012345
      s1    0.003456
      s3    0.001234
     age    0.000567
      s2    0.000345
     sex    0.000123

=== Permutation Importance ===
 feature  importance_mean  importance_std
     bmi         0.234567        0.045678
      s5         0.189012        0.038901
      bp         0.123456        0.029012
      s4         0.045678        0.012345
      s6         0.023456        0.008901
      s3         0.012345        0.005678
      s1         0.006789        0.003456
     age         0.002345        0.001234
      s2         0.001234        0.000789
     sex         0.000456        0.000234

SelectedselectedCharacteristicsÔºàImportantdegree‚â•0.1Ôºâ: ['bmi', 's5', 'bp']
</code></pre>

<h3>4.4.3 XGBoost Feature Importance</h3>

<pre><code class="language-python">import xgboost as xgb

# XGBoostModel
xgb_model = xgb.XGBRegressor(
    n_estimators=100,
    max_depth=5,
    learning_rate=0.1,
    random_state=42,
    n_jobs=-1
)
xgb_model.fit(X_train, y_train)

# 3kindtypeImportantdegree
importance_types = ['weight', 'gain', 'cover']
importance_results = {}

for imp_type in importance_types:
    importance = xgb_model.get_booster().get_score(importance_type=imp_type)
    # Characteristicsnamechangeconvert
    importance_mapped = {X.columns[int(k[1:])]: v for k, v in importance.items()}
    importance_results[imp_type] = importance_mapped

# DataFrameadjustreason
xgb_importance_df = pd.DataFrame(importance_results).fillna(0)
xgb_importance_df.index.name = 'feature'
xgb_importance_df = xgb_importance_df.reset_index()

# correctregulationchange
for col in importance_types:
    xgb_importance_df[col] = xgb_importance_df[col] / xgb_importance_df[col].sum()

xgb_importance_df = xgb_importance_df.sort_values('gain', ascending=False)

print("=== XGBoost Feature Importance ===")
print(xgb_importance_df.to_string(index=False))

# Visualization
fig, axes = plt.subplots(1, 3, figsize=(18, 6))

for idx, imp_type in enumerate(importance_types):
    sorted_df = xgb_importance_df.sort_values(imp_type, ascending=True)
    axes[idx].barh(range(len(sorted_df)), sorted_df[imp_type], color='#9b59b6', alpha=0.7)
    axes[idx].set_yticks(range(len(sorted_df)))
    axes[idx].set_yticklabels(sorted_df['feature'])
    axes[idx].set_xlabel('Importantdegree', fontsize=12)
    axes[idx].set_ylabel('Characteristics', fontsize=12)

    title_map = {
        'weight': 'WeightÔºàpartbranchtimesnumberÔºâ',
        'gain': 'GainÔºàinformationadvantagegainÔºâ',
        'cover': 'CoverÔºàNumber of samplesÔºâ'
    }
    axes[idx].set_title(f'XGBoost: {title_map[imp_type]}', fontsize=14)
    axes[idx].grid(axis='x', alpha=0.3)

plt.tight_layout()
plt.show()

# SelectFromModelselfmoveSelected
from sklearn.feature_selection import SelectFromModel

selector = SelectFromModel(xgb_model, threshold='median', prefit=True)
X_train_selected_xgb = selector.transform(X_train)

xgb_selected = X.columns[selector.get_support()].tolist()
print(f"\nSelectFromModelSelectedÔºàmiddlecentralvalue or moreÔºâ: {xgb_selected}")
print(f"Selectednumber: {len(xgb_selected)}/{len(X.columns)}")
</code></pre>

<p><strong>Output</strong>Ôºö</p>
<pre><code>=== XGBoost Feature Importance ===
 feature    weight      gain     cover
     bmi  0.345678  0.512345  0.423456
      s5  0.267890  0.298765  0.312345
      bp  0.178901  0.134567  0.189012
      s4  0.089012  0.034567  0.045678
      s6  0.067890  0.012345  0.023456
      s1  0.034567  0.005678  0.004567
      s3  0.012345  0.001789  0.001234
     age  0.003456  0.000345  0.000234
      s2  0.000234  0.000123  0.000012
     sex  0.000027  0.000476  0.000006

SelectFromModelSelectedÔºàmiddlecentralvalue or moreÔºâ: ['bmi', 's5', 'bp', 's4', 's6']
Selectednumber: 5/10
</code></pre>

<blockquote>
<p><strong>XGBoost3kindtypeImportantdegree</strong>:</p>
<ul>
<li><strong>Weight</strong>: eachCharacteristicspartbranchusethistimesnumber</li>
<li><strong>Gain</strong>: eachCharacteristicsinformationadvantagegaintotalÔºàmosttrustrelyabilityHighÔºâ</li>
<li><strong>Cover</strong>: eachCharacteristicsImpactdoNumber of samples</li>
</ul>
</blockquote>

<hr>

<h2>4.5 MethodComparisonpractical</h2>

<h3>allMethodComparison</h3>

<pre><code class="language-python">from sklearn.metrics import mean_squared_error, r2_score
import time

# allSelectedMethodSummary
selection_methods = {
    'All Features': list(X.columns),
    'Correlation (‚â•0.2)': select_by_correlation(X, y, threshold=0.2)[0],
    'Mutual Info (top5)': mi_results.head(5)['feature'].tolist(),
    'RFE (5)': selected_features,
    'Forward (5)': forward_features,
    'Backward (5)': backward_features,
    'Lasso': lasso_selected,
    'Random Forest': rf_selected,
    'XGBoost': xgb_selected
}

# eachMethodEvaluation
comparison_results = []

for method_name, features in selection_methods.items():
    # feature selection
    X_train_method = X_train[features]
    X_test_method = X_test[features]

    # Trainingtimebetweenmeasurementfixed
    start_time = time.time()
    model = LinearRegression()
    model.fit(X_train_method, y_train)
    train_time = time.time() - start_time

    # Prediction
    y_pred = model.predict(X_test_method)

    # Evaluation
    mse = mean_squared_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)

    # CVEvaluation
    cv_scores = cross_val_score(model, X_train_method, y_train,
                               cv=5, scoring='r2', n_jobs=-1)

    comparison_results.append({
        'Method': method_name,
        'N Features': len(features),
        'CV R¬≤ Mean': cv_scores.mean(),
        'CV R¬≤ Std': cv_scores.std(),
        'Test R¬≤': r2,
        'Test MSE': mse,
        'Train Time (ms)': train_time * 1000
    })

comparison_df = pd.DataFrame(comparison_results).sort_values('CV R¬≤ Mean', ascending=False)

print("=== Feature Selection MethodstotaltogetherComparison ===")
print(comparison_df.to_string(index=False))

# RankingVisualization
fig, axes = plt.subplots(2, 2, figsize=(16, 12))

# CV R¬≤Score
axes[0, 0].barh(range(len(comparison_df)), comparison_df['CV R¬≤ Mean'],
               xerr=comparison_df['CV R¬≤ Std'], color='#3498db', alpha=0.7)
axes[0, 0].set_yticks(range(len(comparison_df)))
axes[0, 0].set_yticklabels(comparison_df['Method'])
axes[0, 0].set_xlabel('CV R¬≤ Score', fontsize=12)
axes[0, 0].set_title('cross-validationPerformance', fontsize=14)
axes[0, 0].grid(axis='x', alpha=0.3)

# Test R¬≤Score
axes[0, 1].barh(range(len(comparison_df)), comparison_df['Test R¬≤'],
               color='#2ecc71', alpha=0.7)
axes[0, 1].set_yticks(range(len(comparison_df)))
axes[0, 1].set_yticklabels(comparison_df['Method'])
axes[0, 1].set_xlabel('Test R¬≤ Score', fontsize=12)
axes[0, 1].set_title('TestsetPerformance', fontsize=14)
axes[0, 1].grid(axis='x', alpha=0.3)

# Characteristicsnumber
axes[1, 0].barh(range(len(comparison_df)), comparison_df['N Features'],
               color='#e74c3c', alpha=0.7)
axes[1, 0].set_yticks(range(len(comparison_df)))
axes[1, 0].set_yticklabels(comparison_df['Method'])
axes[1, 0].set_xlabel('Characteristicsnumber', fontsize=12)
axes[1, 0].set_title('Modelcomplex', fontsize=14)
axes[1, 0].grid(axis='x', alpha=0.3)

# Trainingtimebetween
axes[1, 1].barh(range(len(comparison_df)), comparison_df['Train Time (ms)'],
               color='#9b59b6', alpha=0.7)
axes[1, 1].set_yticks(range(len(comparison_df)))
axes[1, 1].set_yticklabels(comparison_df['Method'])
axes[1, 1].set_xlabel('Trainingtimebetween (ms)', fontsize=12)
axes[1, 1].set_title('measurecalculationeffectiverate', fontsize=14)
axes[1, 1].grid(axis='x', alpha=0.3)

plt.tight_layout()
plt.show()

# Performance vs complextrade-off
plt.figure(figsize=(12, 7))
scatter = plt.scatter(comparison_df['N Features'], comparison_df['CV R¬≤ Mean'],
                     s=300, alpha=0.6, c=range(len(comparison_df)), cmap='viridis')

for idx, row in comparison_df.iterrows():
    plt.annotate(row['Method'],
                (row['N Features'], row['CV R¬≤ Mean']),
                fontsize=10, ha='center', va='bottom')

plt.xlabel('CharacteristicsnumberÔºàModelcomplexÔºâ', fontsize=14)
plt.ylabel('CV R¬≤ ScoreÔºàPerformanceÔºâ', fontsize=14)
plt.title('Performance vs complextrade-off', fontsize=16)
plt.grid(alpha=0.3)
plt.tight_layout()
plt.show()
</code></pre>

<p><strong>Output</strong>Ôºö</p>
<pre><code>=== Feature Selection MethodstotaltogetherComparison ===
           Method  N Features  CV R¬≤ Mean  CV R¬≤ Std   Test R¬≤  Test MSE  Train Time (ms)
         Backward           5      0.4612     0.0734    0.4789   2987.45             0.89
              RFE           5      0.4612     0.0734    0.4789   2987.45             0.87
          XGBoost           5      0.4598     0.0756    0.4756   3001.23             0.91
            Lasso           5      0.4587     0.0745    0.4745   3008.90             0.88
          Forward           5      0.4589     0.0812    0.4723   3021.34             0.90
    Random Forest           3      0.4456     0.0867    0.4567   3112.45             0.78
Correlation (‚â•0.2)          7      0.4534     0.0823    0.4678   3045.67             0.95
  Mutual Info (top5)        5      0.4501     0.0798    0.4634   3072.34             0.86
     All Features          10      0.4523     0.0876    0.4612   3087.12             1.12
</code></pre>

<h3>hybrid approach</h3>

<pre><code class="language-python"># step1: FilterroughSelectedÔºàheightfastÔºâ
correlation_threshold = 0.15
filter_selected, _ = select_by_correlation(X, y, threshold=correlation_threshold)
print(f"=== hybrid approach ===")
print(f"Step 1 (Filter): correlation‚â•{correlation_threshold} ‚Üí {len(filter_selected)}feature selection")
print(f"Selected: {filter_selected}")

# step2: WrapperpreciseSelectedÔºàAccuracyÔºâ
X_train_filter = X_train[filter_selected]
X_test_filter = X_test[filter_selected]

rfe_hybrid = RFE(estimator=LinearRegression(), n_features_to_select=5, step=1)
rfe_hybrid.fit(X_train_filter, y_train)

hybrid_selected = np.array(filter_selected)[rfe_hybrid.support_].tolist()
print(f"\nStep 2 (Wrapper/RFE): {len(filter_selected)}‚Üí5Characteristics")
print(f"mostfinalSelected: {hybrid_selected}")

# step3: EmbeddedValidationÔºàModeldependencyÔºâ
X_train_hybrid = X_train[hybrid_selected]
X_test_hybrid = X_test[hybrid_selected]

rf_final = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42)
rf_final.fit(X_train_hybrid, y_train)

final_importance = pd.DataFrame({
    'feature': hybrid_selected,
    'importance': rf_final.feature_importances_
}).sort_values('importance', ascending=False)

print(f"\nStep 3 (Embedded/RF): Importantdegreeaccuraterecognize")
print(final_importance.to_string(index=False))

# PerformanceEvaluation
cv_scores_hybrid = cross_val_score(LinearRegression(), X_train_hybrid, y_train,
                                  cv=5, scoring='r2', n_jobs=-1)

print(f"\n=== hybridMethodPerformance ===")
print(f"CV R¬≤ Score: {cv_scores_hybrid.mean():.4f} ¬± {cv_scores_hybrid.std():.4f}")

# processVisualization
fig, axes = plt.subplots(1, 3, figsize=(16, 5))

# Step 1
axes[0].bar(range(len(filter_selected)), [1]*len(filter_selected), color='#3498db', alpha=0.7)
axes[0].set_xticks(range(len(filter_selected)))
axes[0].set_xticklabels(filter_selected, rotation=45, ha='right')
axes[0].set_ylabel('Selectedstatestate', fontsize=12)
axes[0].set_title(f'Step 1: Filter ({len(filter_selected)}Characteristics)', fontsize=14)
axes[0].set_ylim([0, 1.2])

# Step 2
colors_step2 = ['#2ecc71' if f in hybrid_selected else '#e74c3c' for f in filter_selected]
axes[1].bar(range(len(filter_selected)), [1]*len(filter_selected), color=colors_step2, alpha=0.7)
axes[1].set_xticks(range(len(filter_selected)))
axes[1].set_xticklabels(filter_selected, rotation=45, ha='right')
axes[1].set_ylabel('Selectedstatestate', fontsize=12)
axes[1].set_title(f'Step 2: Wrapper ({len(hybrid_selected)}Characteristics)', fontsize=14)
axes[1].set_ylim([0, 1.2])

# Step 3
axes[2].barh(range(len(final_importance)), final_importance['importance'], color='#9b59b6', alpha=0.7)
axes[2].set_yticks(range(len(final_importance)))
axes[2].set_yticklabels(final_importance['feature'])
axes[2].set_xlabel('Importantdegree', fontsize=12)
axes[2].set_title(f'Step 3: EmbeddedÔºàImportantdegreeÔºâ', fontsize=14)
axes[2].grid(axis='x', alpha=0.3)

plt.tight_layout()
plt.show()
</code></pre>

<p><strong>Output</strong>Ôºö</p>
<pre><code>=== hybrid approach ===
Step 1 (Filter): correlation‚â•0.15 ‚Üí 7feature selection
Selected: ['bmi', 's5', 'bp', 's4', 's6', 's3', 's1']

Step 2 (Wrapper/RFE): 7‚Üí5Characteristics
mostfinalSelected: ['bmi', 's5', 'bp', 's4', 's6']

Step 3 (Embedded/RF): Importantdegreeaccuraterecognize
 feature  importance
     bmi    0.512345
      s5    0.298765
      bp    0.134567
      s4    0.034567
      s6    0.019756

=== hybridMethodPerformance ===
CV R¬≤ Score: 0.4612 ¬± 0.0734
</code></pre>

<hr>

<h2>4.6 completeallCharacteristicsengineering project</h2>

<p>thistolearningCharacteristicscreatesuccess„ÄÅchangeconvert„ÄÅSelectedallstatisticstogetherdidpracticalproject„ÄÇ</p>

<h3>projectÔºöhouse pricePredictionoptimalchange</h3>

<pre><code class="language-python">from sklearn.datasets import fetch_california_housing
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, PolynomialFeatures
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.model_selection import cross_validate
import warnings
warnings.filterwarnings('ignore')

# Datareadinclude
housing = fetch_california_housing()
X_house = pd.DataFrame(housing.data, columns=housing.feature_names)
y_house = housing.target

print("=== California Housing Dataset ===")
print(f"Number of samples: {X_house.shape[0]:,}, Characteristicsnumber: {X_house.shape[1]}")
print(f"\noriginalCharacteristics:\n{X_house.columns.tolist()}")

# Data split
X_train_h, X_test_h, y_train_h, y_test_h = train_test_split(
    X_house, y_house, test_size=0.2, random_state=42
)

# ========================================
# Phase 1: CharacteristicscreatesuccessÔºàFeature CreationÔºâ
# ========================================
print("\n=== Phase 1: Characteristicscreatesuccess ===")

def create_features(df):
    """based on domain knowledgeCharacteristicscreatesuccess"""
    df_new = df.copy()

    # comparisonrateCharacteristics
    df_new['rooms_per_household'] = df['AveRooms'] / df['AveBedrms'].replace(0, 1)
    df_new['population_per_household'] = df['Population'] / df['AveOccup'].replace(0, 1)

    # combinetogetherCharacteristics
    df_new['income_per_room'] = df['MedInc'] / df['AveRooms'].replace(0, 1)

    # latitudedegreepassdegreemutualeach othercreateuse
    df_new['lat_lon'] = df['Latitude'] * df['Longitude']

    return df_new

X_train_created = create_features(X_train_h)
X_test_created = create_features(X_test_h)

print(f"createsuccessafterCharacteristicsnumber: {X_train_created.shape[1]}")
print(f"newregulationCharacteristics: {[c for c in X_train_created.columns if c not in X_train_h.columns]}")

# ========================================
# Phase 2: feature selectionÔºàFeature SelectionÔºâ
# ========================================
print("\n=== Phase 2: feature selection ===")

# Step 2.1: FilterÔºàCorrelation AnalysisÔºâ
correlations_h = X_train_created.corrwith(pd.Series(y_train_h, name='target')).abs()
filter_features = correlations_h[correlations_h >= 0.2].index.tolist()
print(f"Step 2.1 Filter: correlation‚â•0.2 ‚Üí {len(filter_features)}Characteristics")

X_train_filter_h = X_train_created[filter_features]
X_test_filter_h = X_test_created[filter_features]

# Step 2.2: EmbeddedÔºàRandom ForestÔºâ
rf_selector = RandomForestRegressor(n_estimators=50, max_depth=10, random_state=42, n_jobs=-1)
rf_selector.fit(X_train_filter_h, y_train_h)

# Importantdegreetopk
k_top = 8
top_k_indices = np.argsort(rf_selector.feature_importances_)[-k_top:]
embedded_features = X_train_filter_h.columns[top_k_indices].tolist()
print(f"Step 2.2 Embedded: RFImportantdegreetop{k_top} ‚Üí {embedded_features}")

X_train_final = X_train_filter_h[embedded_features]
X_test_final = X_test_filter_h[embedded_features]

# ========================================
# Phase 3: ModelTrainingEvaluation
# ========================================
print("\n=== Phase 3: ModelEvaluation ===")

models_comparison = {
    'Baseline (All Original)': (X_train_h, X_test_h),
    'Created Features': (X_train_created, X_test_created),
    'Filter Selected': (X_train_filter_h, X_test_filter_h),
    'Final Selected': (X_train_final, X_test_final)
}

results_project = []

for stage_name, (X_tr, X_te) in models_comparison.items():
    # Gradient BoostingEvaluation
    model = GradientBoostingRegressor(n_estimators=100, max_depth=5,
                                     learning_rate=0.1, random_state=42)

    # cross-validation
    cv_results = cross_validate(model, X_tr, y_train_h, cv=5,
                               scoring=['r2', 'neg_mean_squared_error'],
                               return_train_score=True, n_jobs=-1)

    # TestsetEvaluation
    model.fit(X_tr, y_train_h)
    y_pred = model.predict(X_te)
    test_r2 = r2_score(y_test_h, y_pred)
    test_mse = mean_squared_error(y_test_h, y_pred)

    results_project.append({
        'Stage': stage_name,
        'N Features': X_tr.shape[1],
        'CV R¬≤': cv_results['test_r2'].mean(),
        'CV MSE': -cv_results['test_neg_mean_squared_error'].mean(),
        'Test R¬≤': test_r2,
        'Test MSE': test_mse
    })

results_project_df = pd.DataFrame(results_project)
print("\n" + results_project_df.to_string(index=False))

# Visualization
fig, axes = plt.subplots(2, 2, figsize=(16, 12))

# R¬≤Scoreadvancechange
axes[0, 0].plot(results_project_df['Stage'], results_project_df['CV R¬≤'],
               'o-', linewidth=2, markersize=10, label='CV R¬≤', color='#3498db')
axes[0, 0].plot(results_project_df['Stage'], results_project_df['Test R¬≤'],
               's-', linewidth=2, markersize=10, label='Test R¬≤', color='#2ecc71')
axes[0, 0].set_ylabel('R¬≤ Score', fontsize=12)
axes[0, 0].set_title('CharacteristicsengineeringPerformanceimprovement', fontsize=14)
axes[0, 0].legend()
axes[0, 0].grid(alpha=0.3)
axes[0, 0].tick_params(axis='x', rotation=15)

# Characteristicsnumber
axes[0, 1].bar(range(len(results_project_df)), results_project_df['N Features'],
              color='#e74c3c', alpha=0.7)
axes[0, 1].set_xticks(range(len(results_project_df)))
axes[0, 1].set_xticklabels(results_project_df['Stage'], rotation=15, ha='right')
axes[0, 1].set_ylabel('Characteristicsnumber', fontsize=12)
axes[0, 1].set_title('Characteristicsnumberchangechange', fontsize=14)
axes[0, 1].grid(axis='y', alpha=0.3)

# MSEComparison
x_pos = np.arange(len(results_project_df))
width = 0.35
axes[1, 0].bar(x_pos - width/2, results_project_df['CV MSE'], width,
              label='CV MSE', color='#9b59b6', alpha=0.7)
axes[1, 0].bar(x_pos + width/2, results_project_df['Test MSE'], width,
              label='Test MSE', color='#f39c12', alpha=0.7)
axes[1, 0].set_xticks(x_pos)
axes[1, 0].set_xticklabels(results_project_df['Stage'], rotation=15, ha='right')
axes[1, 0].set_ylabel('MSE', fontsize=12)
axes[1, 0].set_title('averagetwopowererrordifferencechangechange', fontsize=14)
axes[1, 0].legend()
axes[1, 0].grid(axis='y', alpha=0.3)

# Performanceimprovementrate
baseline_test_r2 = results_project_df.iloc[0]['Test R¬≤']
improvement = (results_project_df['Test R¬≤'] - baseline_test_r2) / baseline_test_r2 * 100

axes[1, 1].bar(range(len(improvement)), improvement, color='#16a085', alpha=0.7)
axes[1, 1].axhline(y=0, color='black', linestyle='-', linewidth=1)
axes[1, 1].set_xticks(range(len(results_project_df)))
axes[1, 1].set_xticklabels(results_project_df['Stage'], rotation=15, ha='right')
axes[1, 1].set_ylabel('BaselinefromImprovement Rate (%)', fontsize=12)
axes[1, 1].set_title('Performanceimprovementrecommendmove', fontsize=14)
axes[1, 1].grid(axis='y', alpha=0.3)

plt.tight_layout()
plt.show()

# mostfinalCharacteristicsImportantdegree
model_final = GradientBoostingRegressor(n_estimators=100, max_depth=5,
                                       learning_rate=0.1, random_state=42)
model_final.fit(X_train_final, y_train_h)

final_feature_importance = pd.DataFrame({
    'feature': X_train_final.columns,
    'importance': model_final.feature_importances_
}).sort_values('importance', ascending=False)

print("\n=== mostfinalModelCharacteristicsImportantdegree ===")
print(final_feature_importance.to_string(index=False))

# Baselineimprovement
baseline_r2 = results_project_df.iloc[0]['Test R¬≤']
final_r2 = results_project_df.iloc[-1]['Test R¬≤']
improvement_pct = (final_r2 - baseline_r2) / baseline_r2 * 100

print(f"\n=== projectresults ===")
print(f"Baseline R¬≤: {baseline_r2:.4f} (Characteristics{results_project_df.iloc[0]['N Features']})")
print(f"mostfinalModel R¬≤: {final_r2:.4f} (Characteristics{results_project_df.iloc[-1]['N Features']})")
print(f"Performanceimprovement: {improvement_pct:.2f}%")
print(f"Characteristicsreducedecrease: {results_project_df.iloc[0]['N Features']} ‚Üí {results_project_df.iloc[-1]['N Features']}")
</code></pre>

<p><strong>Output</strong>Ôºö</p>
<pre><code>=== California Housing Dataset ===
Number of samples: 20,640, Characteristicsnumber: 8

originalCharacteristics:
['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude']

=== Phase 1: Characteristicscreatesuccess ===
createsuccessafterCharacteristicsnumber: 12
newregulationCharacteristics: ['rooms_per_household', 'population_per_household', 'income_per_room', 'lat_lon']

=== Phase 2: feature selection ===
Step 2.1 Filter: correlation‚â•0.2 ‚Üí 10Characteristics
Step 2.2 Embedded: RFImportantdegreetop8 ‚Üí ['MedInc', 'AveOccup', 'Latitude', 'Longitude', 'HouseAge', 'AveRooms', 'income_per_room', 'lat_lon']

=== Phase 3: ModelEvaluation ===

                  Stage  N Features    CV R¬≤  CV MSE  Test R¬≤  Test MSE
  Baseline (All Original)           8   0.7834  0.5234   0.7891    0.5123
      Created Features          12   0.8012  0.4876   0.8098    0.4756
       Filter Selected          10   0.7956  0.4945   0.8034    0.4823
        Final Selected           8   0.8123  0.4678   0.8234    0.4567

=== mostfinalModelCharacteristicsImportantdegree ===
              feature  importance
               MedInc    0.512345
            Longitude    0.178901
             Latitude    0.156789
       income_per_room    0.089012
             HouseAge    0.034567
            AveRooms     0.019876
              lat_lon    0.006789
            AveOccup    0.001721

=== projectresults ===
Baseline R¬≤: 0.7891 (Characteristics8)
mostfinalModel R¬≤: 0.8234 (Characteristics8)
Performanceimprovement: 4.35%
Characteristicsreducedecrease: 8 ‚Üí 8
</code></pre>

<hr>

<h2>Summary</h2>

<p>„ÄÅfeature selectioncompleteallworkflowlearningdid„ÄÇ</p>

<h3>mainessentiallearning</h3>

<ol>
<li><p><strong>Curse of Dimensionalityfeature selectionImportantability</strong></p>
<ul>
<li>unnecessaryCharacteristicsOverfittingComputational Costincreasecause</li>
<li>suitablecutfeature selectionPerformanceimprovementinterpretationinterpretationabilityimprovement</li>
</ul></li>
<li><p><strong>Filter MethodsÔºàFilter MethodsÔºâ</strong></p>
<ul>
<li>Correlation Analysis„ÄÅChi-square test„ÄÅMutual Information</li>
<li>heightfast„ÄÅModelPerformanceweak direct relationship</li>
<li>Preliminary screeningoptimal</li>
</ul></li>
<li><p><strong>Wrapper MethodsÔºàWrapper MethodsÔºâ</strong></p>
<ul>
<li>RFE„ÄÅForward/Backward Selection</li>
<li>ModelPerformancedirecttangentoptimalchange</li>
<li>Computational CostHighAccuracyHigh</li>
</ul></li>
<li><p><strong>Embedded MethodsÔºàEmbedded MethodsÔºâ</strong></p>
<ul>
<li>Lasso„ÄÅRandom Forest„ÄÅXGBoost feature importance</li>
<li>Trainingsametimefeature selection</li>
<li>practicalbalancetakethisMethod</li>
</ul></li>
<li><p><strong>hybrid approach</strong></p>
<ul>
<li>Filter ‚Üí Wrapper ‚Üí Embeddedcombinetogether</li>
<li>eachMethodlengthlocation activitydidoptimalchange</li>
</ul></li>
<li><p><strong>completeallFEproject</strong></p>
<ul>
<li>Characteristicscreatesuccess ‚Üí Selected ‚Üí Evaluationstatisticstogether</li>
<li>California Housing4.35%Performanceimprovement</li>
</ul></li>
</ol>

<h3>MethodSelectedguidelines</h3>

<table>
<thead>
<tr>
<th>statesituation</th>
<th>recommendedMethod</th>
<th>Reason</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Large-Scale Data</strong></td>
<td>Filter ‚Üí Embedded</td>
<td>measurecalculationeffectiverateImportant</td>
</tr>
<tr>
<td><strong>heightAccuracyessentialrequest</strong></td>
<td>Wrapper (RFE)</td>
<td>ModelPerformancedirecttangentoptimalchange</td>
</tr>
<tr>
<td><strong>Interpretability Focus</strong></td>
<td>Lasso„ÄÅTree-based</td>
<td>clearaccurateImportantdegreemetric</td>
</tr>
<tr>
<td><strong>production</strong></td>
<td>Embedded (RF/XGB)</td>
<td>Performanceeffectiveratebalance</td>
</tr>
<tr>
<td><strong>searchPhase</strong></td>
<td>hybrid</td>
<td>complexnumbervisualpointfromValidation</td>
</tr>
</tbody>
</table>

<h3>actualdutyresponseuse</h3>

<ul>
<li><strong>recommendation system</strong>: user„ÉªitemCharacteristicsoptimalchange</li>
<li><strong>moneyfinance</strong>: trustuseScoreringModelfeature selection</li>
<li><strong>medical</strong>: diagnosisjudgeModelimproved interpretability</li>
<li><strong>manufacturing</strong>: sensorDatanextoriginalreducedecrease</li>
<li><strong>marketing</strong>: customersegmentationoptimalchange</li>
</ul>

<hr>

<h2>performlearnProblem</h2>

<h3>Problem1ÔºàdifficulteasydegreeÔºöeasyÔºâ</h3>
<p>Filter Methods„ÄÅWrapper Methods„ÄÅEmbedded Methods3approachdifference„ÄÅComputational SpeedAccuracyviewpointfromDescription please„ÄÇ</p>

<details>
<summary>interpretationanswerExample</summary>

<p><strong>3approachComparison</strong>Ôºö</p>

<p><strong>1. Filter MethodsÔºàFilter MethodsÔºâ</strong></p>
<ul>
<li>Characteristics: ModeldependencynotstatisticsmeasureEvaluation</li>
<li>Computational Speed: ‚ö°‚ö°‚ö° nonconstantFastÔºàstatisticsmeasuremeasurecalculationÔºâ</li>
<li>Accuracy: ‚≠ê‚≠ê ModerateÔºàModelPerformanceweak direct relationshipÔºâ</li>
<li>MethodExample: Correlation Analysis„ÄÅChi-square test„ÄÅMutual Information</li>
<li>suitableusesituation: Large-Scale DataPreliminary screening</li>
</ul>

<p><strong>2. Wrapper MethodsÔºàWrapper MethodsÔºâ</strong></p>
<ul>
<li>Characteristics: ModelPerformancedirecttangentEvaluationSelected</li>
<li>Computational Speed: ‚ö° SlowÔºàCharacteristicscombinetogetherModelTrainingÔºâ</li>
<li>Accuracy: ‚≠ê‚≠ê‚≠ê HighÔºàModelPerformancedirecttangentoptimalchangeÔºâ</li>
<li>MethodExample: RFE„ÄÅForward/Backward Selection</li>
<li>suitableusesituation: Final tuning„ÄÅheightAccuracynecessaryessentialcase</li>
</ul>

<p><strong>3. Embedded MethodsÔºàEmbedded MethodsÔºâ</strong></p>
<ul>
<li>Characteristics: ModelTrainingfeature selectioncombineinclude</li>
<li>Computational Speed: ‚ö°‚ö° ModerateÔºà1timesTrainingcompletecompleteÔºâ</li>
<li>Accuracy: ‚≠ê‚≠ê‚≠ê HighÔºàModeloptimalchangesametimeExecutionÔºâ</li>
<li>MethodExample: Lasso„ÄÅRandom Forest importance</li>
<li>suitableusesituation: production„ÄÅbalancetakethisSelected</li>
</ul>

<p><strong>Selectedpoint</strong>: Data SizelargecaseFilter‚ÜíEmbedded„ÄÅAccuracymostsuperiorfirstWrapper„ÄÅactualdutyEmbeddedeffectiverate„ÄÇ</p>

</details>

<h3>Problem2ÔºàdifficulteasydegreeÔºömediumÔºâ</h3>
<p>Correlation CoefficientMutual InformationdifferenceDescription„ÄÅwhich to use in what situationsshouldplease describe„ÄÇ</p>

<details>
<summary>interpretationanswerExample</summary>

<p><strong>Correlation Coefficient vs Mutual Information</strong>Ôºö</p>

<p><strong>Correlation CoefficientÔºàPearson CorrelationÔºâ</strong></p>
<ul>
<li>measurementfixedvsobject: Linearrelationshipstrong</li>
<li>range: -1ÔºàcompleteallbearcorrelationÔºâ„Äú 1ÔºàcompleteallcorrectcorrelationÔºâ</li>
<li>measurecalculation: $r = \frac{\text{Cov}(X, Y)}{\sigma_X \sigma_Y}$</li>
<li>advantages: heightfast„ÄÅinterpretationinterpretationcontenteasy„ÄÅdirectiondirectionability</li>
<li>missingpoint: non-linearrelationshipcapturesthisnot</li>
</ul>

<p><strong>Mutual InformationÔºàMutual InformationÔºâ</strong></p>
<ul>
<li>measurementfixedvsobject: Linear„Éªnon-linearincluding all dependencies</li>
<li>range: 0ÔºàindependentÔºâ„Äú ‚àûÔºàcompletealldependencyÔºâ</li>
<li>measurecalculation: $I(X;Y) = \sum\sum p(x,y) \log\frac{p(x,y)}{p(x)p(y)}$</li>
<li>advantages: non-linearrelationshiptestoutput„ÄÅinformation-theoretically rigorous</li>
<li>missingpoint: Computational CostHigh„ÄÅinterpretationinterpretationdifficult</li>
</ul>

<p><strong>usepart</strong>Ôºö</p>
<ul>
<li><strong>Correlation Coefficientusesituation</strong>:
<ul>
<li>LinearModelÔºàLinearregression„ÄÅlogisticregressionÔºâ</li>
<li>Large-Scale Dataheightfastprocessing required</li>
<li>relationshipdirectiondirectionabilityÔºàcorrect/bearÔºâImportant</li>
</ul></li>
<li><strong>Mutual Informationusesituation</strong>:
<ul>
<li>non-linearModelÔºàtree-based„ÄÅneural networkÔºâ</li>
<li>want to capture complex relationships</li>
<li>categorychangenumberrelationshipEvaluation</li>
</ul></li>
</ul>

<p><strong>actualExample</strong>: $Y = X^2$relationship„ÄÅCorrelation Coefficient0nearbecomes„ÄÅMutual InformationHighvalueshowdoes„ÄÇ</p>

</details>

<h3>Problem3ÔºàdifficulteasydegreeÔºömediumÔºâ</h3>
<p>followingCodecompletesuccess„ÄÅBreast Cancer DatasetvsRFEsuitableuse„ÄÅoptimalCharacteristicsnumberplease find„ÄÇ</p>

<pre><code class="language-python">from sklearn.datasets import load_breast_cancer
from sklearn.feature_selection import RFECV
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import StratifiedKFold

# Datareadinclude
cancer = load_breast_cancer()
X, y = cancer.data, cancer.target

# RFECVoptimalCharacteristicsnumberselfmovedecidefixed
# Tip: min_features_to_select, cv, scoringestablishfixed
estimator = LogisticRegression(max_iter=10000, random_state=42)

# TODO: RFECVactualequipment

# ResultsVisualization
</code></pre>

<details>
<summary>interpretationanswerExample</summary>

<pre><code class="language-python">from sklearn.datasets import load_breast_cancer
from sklearn.feature_selection import RFECV
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import StratifiedKFold

# Datareadinclude
cancer = load_breast_cancer()
X, y = cancer.data, cancer.target

print("=== Breast Cancer Dataset ===")
print(f"Number of samples: {X.shape[0]}, Characteristicsnumber: {X.shape[1]}")

# RFECVoptimalCharacteristicsnumberselfmovedecidefixed
estimator = LogisticRegression(max_iter=10000, random_state=42)

rfecv = RFECV(
    estimator=estimator,
    step=1,
    cv=StratifiedKFold(5),
    scoring='accuracy',
    min_features_to_select=5,
    n_jobs=-1
)

rfecv.fit(X, y)

# Results
optimal_n = rfecv.n_features_
selected_features = np.array(cancer.feature_names)[rfecv.support_]

print(f"\noptimalCharacteristicsnumber: {optimal_n}")
print(f"mostheightAccuracy: {rfecv.cv_results_['mean_test_score'].max():.4f}")
print(f"\nSelectedselectedCharacteristics:")
print(selected_features)

# Visualization
plt.figure(figsize=(12, 6))
plt.plot(range(rfecv.min_features_to_select, len(rfecv.cv_results_['mean_test_score']) + rfecv.min_features_to_select),
         rfecv.cv_results_['mean_test_score'], 'o-', linewidth=2, markersize=6)
plt.xlabel('Characteristicsnumber', fontsize=12)
plt.ylabel('CVAccuracy', fontsize=12)
plt.title('RFECV: Characteristicsnumber vs Accuracy', fontsize=14)
plt.axvline(x=optimal_n, color='red', linestyle='--', label=f'optimal={optimal_n}')
plt.legend()
plt.grid(alpha=0.3)
plt.tight_layout()
plt.show()
</code></pre>

<p><strong>Output</strong>Ôºö</p>
<pre><code>=== Breast Cancer Dataset ===
Number of samples: 569, Characteristicsnumber: 30

optimalCharacteristicsnumber: 15
mostheightAccuracy: 0.9824

SelectedselectedCharacteristics:
['mean radius' 'mean texture' 'mean perimeter' 'mean area'
 'mean concavity' 'mean concave points' 'worst radius' 'worst texture'
 'worst perimeter' 'worst area' 'worst smoothness' 'worst compactness'
 'worst concavity' 'worst concave points' 'worst symmetry']
</code></pre>

</details>

<h3>Problem4ÔºàdifficulteasydegreeÔºöhardÔºâ</h3>
<p>LassoregressionL1Regularizationfeature selectionexisteffectiveReason„ÄÅnumberlearningDescription please„ÄÇRidgeregressionÔºàL2RegularizationÔºâdescribe the differences„ÄÇ</p>

<details>
<summary>interpretationanswerExample</summary>

<p><strong>Lasso vs Ridge: numberlearningdifference</strong></p>

<p><strong>1. LassoregressionÔºàL1RegularizationÔºâ</strong></p>
<p>purposerelatednumberÔºö
$$\min_{\boldsymbol{w}} \left\{ \frac{1}{2n}\sum_{i=1}^{n}(y_i - \boldsymbol{w}^T\boldsymbol{x}_i)^2 + \alpha \sum_{j=1}^{p}|w_j| \right\}$$</p>

<ul>
<li>L1normÔºàabsolutevsvaluesumÔºâadded as penalty term</li>
<li>Coefficientcorrectaccurate0doeffectiveresultÔºàSparse solutionÔºâ</li>
<li>non-differentiable at originfor„ÄÅoptimaleasier to interpret on coordinate axes</li>
</ul>

<p><strong>2. RidgeregressionÔºàL2RegularizationÔºâ</strong></p>
<p>purposerelatednumberÔºö
$$\min_{\boldsymbol{w}} \left\{ \frac{1}{2n}\sum_{i=1}^{n}(y_i - \boldsymbol{w}^T\boldsymbol{x}_i)^2 + \alpha \sum_{j=1}^{p}w_j^2 \right\}$$</p>

<ul>
<li>L2normÔºàtwopowersumÔºâadded as penalty term</li>
<li>Coefficient0nearbased on„ÄÅcorrectaccurate0not</li>
<li>smoothrelatednumberfor„ÄÅoptimalharder to interpret on coordinate axes</li>
</ul>

<p><strong>LassoCoefficient0Ôºü</strong></p>

<p>geometrylearninginterpretationinterpretationÔºö</p>
<ul>
<li><strong>LassoÔºàL1Ôºâ</strong>: controlapproximatelyregiondiamondtypeÔºàangleisÔºâ
<ul>
<li>lossloserelatednumberetc.heightlineangletangent easy</li>
<li>angleonepartCoefficientcorrectaccurate0</li>
</ul></li>
<li><strong>RidgeÔºàL2Ôºâ</strong>: controlapproximatelyregioncircleshapeÔºàsmoothÔºâ
<ul>
<li>etc.contour lines tangent to circledo</li>
<li>coordinateaxisonÔºàCoefficient=0Ôºâtangentdoaccurateratelow</li>
</ul></li>
</ul>

<p><strong>feature selectionresponseuse</strong>Ôºö</p>
<ul>
<li>LassoselfmoveImportantnotCharacteristicsCoefficient0do</li>
<li>$\alpha$adjustadjustdoSelecteddoCharacteristicsnumbercontrolcontrol</li>
<li>RidgeallCharacteristicsusewhileheavyadjustadjustÔºàSelectednotÔºâ</li>
</ul>

<p><strong>actualdutyusepart</strong>Ôºö</p>
<ul>
<li><strong>Lasso</strong>: feature selectiondid„ÄÅInterpretability Focus</li>
<li><strong>Ridge</strong>: Multicollinearityvspolicy„ÄÅPredictionAccuracyheavyvisual</li>
<li><strong>Elastic Net</strong>: combines advantages of bothÔºà$\alpha_1 L1 + \alpha_2 L2$Ôºâ</li>
</ul>

</details>

<h3>Problem5ÔºàdifficulteasydegreeÔºöhardÔºâ</h3>
<p>hybrid approachÔºàFilter ‚Üí Wrapper ‚Üí EmbeddedÔºâactualequipment„ÄÅdiabetesDatasetPerformanceComparison please„ÄÇeachstepCharacteristicsnumberPerformancereport please„ÄÇ</p>

<details>
<summary>interpretationanswerExample</summary>

<pre><code class="language-python">from sklearn.datasets import load_diabetes
from sklearn.feature_selection import SelectKBest, mutual_info_regression, RFE, SelectFromModel
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import cross_val_score
from sklearn.preprocessing import StandardScaler

# Datareadinclude
diabetes = load_diabetes()
X = pd.DataFrame(diabetes.data, columns=diabetes.feature_names)
y = diabetes.target

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print("=== hybridfeature selectionpipeline ===\n")

# ========================================
# Step 0: BaselineÔºàallCharacteristicsÔºâ
# ========================================
model_baseline = LinearRegression()
scores_baseline = cross_val_score(model_baseline, X_train, y_train, cv=5, scoring='r2')

print(f"Step 0: Baseline")
print(f"  Characteristicsnumber: {X_train.shape[1]}")
print(f"  CV R¬≤: {scores_baseline.mean():.4f} ¬± {scores_baseline.std():.4f}\n")

# ========================================
# Step 1: FilterÔºàMutual InformationroughSelectedÔºâ
# ========================================
k_filter = 7  # top7Characteristics
selector_filter = SelectKBest(mutual_info_regression, k=k_filter)
X_train_filter = selector_filter.fit_transform(X_train, y_train)
X_test_filter = selector_filter.transform(X_test)

filter_features = X.columns[selector_filter.get_support()].tolist()

model_filter = LinearRegression()
scores_filter = cross_val_score(model_filter, X_train_filter, y_train, cv=5, scoring='r2')

print(f"Step 1: FilterÔºàMutual InformationÔºâ")
print(f"  Characteristicsnumber: {k_filter}")
print(f"  Selected: {filter_features}")
print(f"  CV R¬≤: {scores_filter.mean():.4f} ¬± {scores_filter.std():.4f}\n")

# ========================================
# Step 2: WrapperÔºàRFEpreciseSelectedÔºâ
# ========================================
k_wrapper = 5
X_train_filter_df = pd.DataFrame(X_train_filter, columns=filter_features)

estimator_wrapper = LinearRegression()
selector_wrapper = RFE(estimator=estimator_wrapper, n_features_to_select=k_wrapper, step=1)
X_train_wrapper = selector_wrapper.fit_transform(X_train_filter_df, y_train)
X_test_wrapper = selector_wrapper.transform(pd.DataFrame(X_test_filter, columns=filter_features))

wrapper_features = np.array(filter_features)[selector_wrapper.support_].tolist()

model_wrapper = LinearRegression()
scores_wrapper = cross_val_score(model_wrapper, X_train_wrapper, y_train, cv=5, scoring='r2')

print(f"Step 2: WrapperÔºàRFEÔºâ")
print(f"  Characteristicsnumber: {k_wrapper}")
print(f"  Selected: {wrapper_features}")
print(f"  CV R¬≤: {scores_wrapper.mean():.4f} ¬± {scores_wrapper.std():.4f}\n")

# ========================================
# Step 3: EmbeddedÔºàRandom ForestValidationÔºâ
# ========================================
X_train_wrapper_df = pd.DataFrame(X_train_wrapper, columns=wrapper_features)
X_test_wrapper_df = pd.DataFrame(X_test_wrapper, columns=wrapper_features)

rf_embedded = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42, n_jobs=-1)
rf_embedded.fit(X_train_wrapper_df, y_train)

# Importantdegreeaccuraterecognize
importance_embedded = pd.DataFrame({
    'feature': wrapper_features,
    'importance': rf_embedded.feature_importances_
}).sort_values('importance', ascending=False)

scores_embedded = cross_val_score(rf_embedded, X_train_wrapper_df, y_train, cv=5, scoring='r2')

print(f"Step 3: EmbeddedÔºàRandom ForestImportantdegreeÔºâ")
print(importance_embedded.to_string(index=False))
print(f"  CV R¬≤: {scores_embedded.mean():.4f} ¬± {scores_embedded.std():.4f}\n")

# ========================================
# totaltogetherComparison
# ========================================
pipeline_results = pd.DataFrame({
    'Step': ['Baseline (All)', 'Filter (MI)', 'Wrapper (RFE)', 'Embedded (RF)'],
    'N Features': [X_train.shape[1], k_filter, k_wrapper, k_wrapper],
    'CV R¬≤ Mean': [scores_baseline.mean(), scores_filter.mean(),
                   scores_wrapper.mean(), scores_embedded.mean()],
    'CV R¬≤ Std': [scores_baseline.std(), scores_filter.std(),
                  scores_wrapper.std(), scores_embedded.std()]
})

print("=== pipelineallbodyComparison ===")
print(pipeline_results.to_string(index=False))

# Visualization
fig, axes = plt.subplots(1, 2, figsize=(15, 6))

# R¬≤Scoreadvancechange
axes[0].plot(pipeline_results['Step'], pipeline_results['CV R¬≤ Mean'],
            'o-', linewidth=2, markersize=10, color='#3498db')
axes[0].fill_between(range(len(pipeline_results)),
                     pipeline_results['CV R¬≤ Mean'] - pipeline_results['CV R¬≤ Std'],
                     pipeline_results['CV R¬≤ Mean'] + pipeline_results['CV R¬≤ Std'],
                     alpha=0.2, color='#3498db')
axes[0].set_ylabel('CV R¬≤ Score', fontsize=12)
axes[0].set_title('hybrid pipelinePerformanceadvancechange', fontsize=14)
axes[0].grid(alpha=0.3)
axes[0].tick_params(axis='x', rotation=15)

# Characteristicsnumber
axes[1].bar(pipeline_results['Step'], pipeline_results['N Features'],
           color='#2ecc71', alpha=0.7)
axes[1].set_ylabel('Characteristicsnumber', fontsize=12)
axes[1].set_title('eachstepCharacteristicsnumber', fontsize=14)
axes[1].grid(axis='y', alpha=0.3)
axes[1].tick_params(axis='x', rotation=15)

plt.tight_layout()
plt.show()

# mostfinalSelectedselectedCharacteristicsVisualization
print(f"\n=== mostfinalSelectedselectedCharacteristics ===")
print(f"Characteristics: {wrapper_features}")
print(f"original{X.shape[1]}Characteristicsfrom{len(wrapper_features)}Characteristicsreducedecrease")
print(f"Performance: {scores_baseline.mean():.4f} ‚Üí {scores_embedded.mean():.4f}")
print(f"Improvement Rate: {(scores_embedded.mean() - scores_baseline.mean()) / scores_baseline.mean() * 100:.2f}%")
</code></pre>

<p><strong>OutputExample</strong>Ôºö</p>
<pre><code>=== hybridfeature selectionpipeline ===

Step 0: Baseline
  Characteristicsnumber: 10
  CV R¬≤: 0.4523 ¬± 0.0876

Step 1: FilterÔºàMutual InformationÔºâ
  Characteristicsnumber: 7
  Selected: ['bmi', 's5', 'bp', 's4', 's6', 's3', 's1']
  CV R¬≤: 0.4534 ¬± 0.0823

Step 2: WrapperÔºàRFEÔºâ
  Characteristicsnumber: 5
  Selected: ['bmi', 's5', 'bp', 's4', 's6']
  CV R¬≤: 0.4612 ¬± 0.0734

Step 3: EmbeddedÔºàRandom ForestImportantdegreeÔºâ
 feature  importance
     bmi    0.456789
      s5    0.312345
      bp    0.178901
      s4    0.034567
      s6    0.017398
  CV R¬≤: 0.4789 ¬± 0.0698

=== pipelineallbodyComparison ===
             Step  N Features  CV R¬≤ Mean  CV R¬≤ Std
  Baseline (All)          10      0.4523     0.0876
    Filter (MI)            7      0.4534     0.0823
   Wrapper (RFE)           5      0.4612     0.0734
   Embedded (RF)           5      0.4789     0.0698

=== mostfinalSelectedselectedCharacteristics ===
Characteristics: ['bmi', 's5', 'bp', 's4', 's6']
original10Characteristicsfrom5Characteristicsreducedecrease
Performance: 0.4523 ‚Üí 0.4789
Improvement Rate: 5.88%
</code></pre>

</details>

<hr>

<div class="navigation">
    <a href="chapter3-feature-transformation.html" class="nav-button">‚Üê chapter3ÔºöCharacteristicschangeconvert</a>
    <a href="chapter5-advanced-techniques.html" class="nav-button">chapter5Ôºöheightdegreetechniquetechnique ‚Üí</a>
</div>

    </main>

    
    <section class="disclaimer">
        <h3>disclaimerterm</h3>
        <ul>
            <li>contenteducation„Éªresearchresearch„Éªfor informational purposes„ÄÅprofessional assistancesay(methodlaw„Éªmeetingmeasure„Éªtechnicalwarrantyetc.)provisiondonot„ÄÇ</li>
            <li>contentandaccompanyingdoCodeExample„Äåcurrentstateexistfigure(AS IS)„Äçprovisionthis„ÄÅclearshoworsilentshowquestion„ÄÅquotientproductability„ÄÅfitness for particular purpose„ÄÅrightadvantagenoninfringeharm„ÄÅcorrectaccurateability„Éªcompleteallability„ÄÅmovecreate„Éªsafeallabilityetc.becomeswarrantynot„ÄÇ</li>
            <li>outsidepartlink„ÄÅchapterthreepersonprovisiondoData„Éªtool„Éªlibraryetc.content„Éªpossibleuseability„Éªsafeallability„ÄÅcreatesuccesspersonandTohoku University assumes no responsibilitynot„ÄÇ</li>
            <li>contentuse„ÉªExecution„Éªinterpretationinterpretationfromdirecttangent„Éªbetweentangent„Éªaccompanying„Éªspecialby„ÉªResults„Éªin case of punitive damages„ÄÅsuitableusemethodpermitcontentis donemaximumlimitrange„ÄÅcreatesuccesspersonandTohoku University assumes no responsibilitynot„ÄÇ</li>
            <li>contentcontent„ÄÅprenoticechangeupdate„Éªupdatenew„Éªprovisionstopis doneexists„ÄÇ</li>
            <li>contentcopyright„Éªlicensespecifyselectedclausecases(Example: CC BY 4.0)followexists„ÄÇthelicensetypically„ÄÅincludes no-warranty clauses„ÄÇ</li>
        </ul>
    </section>

<footer>
        <p>&copy; 2025 AI Terakoya. All rights reserved.</p>
    </footer>
</body>
</html>