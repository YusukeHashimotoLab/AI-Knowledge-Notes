<!DOCTYPE html>

<html lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>Chapter 4: Practical AutoML Tools - AI Terakoya</title>
<link href="../../assets/css/knowledge-base.css" rel="stylesheet"/>
<script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
<script>
        mermaid.initialize({ startOnLoad: true, theme: 'default', securityLevel: 'strict' });
    </script>
<!-- MathJax for LaTeX equation rendering -->
<script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\(', '\)']],
                displayMath: [['$$', '$$'], ['\[', '\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
                ignoreHtmlClass: 'mermaid'
            }
        };
    </script>
<script async="" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>
<nav class="breadcrumb">
<div class="breadcrumb-content">
<a href="../index.html">AI Terakoya Top</a><span class="breadcrumb-separator">‚Ä∫</span><a href="../../ML/index.html">Machine Learning</a><span class="breadcrumb-separator">‚Ä∫</span><a href="../../ML/automl-introduction/index.html">AutoML</a><span class="breadcrumb-separator">‚Ä∫</span><span class="breadcrumb-current">Chapter 4</span>
</div>
</nav><div class="locale-switcher">
<span class="current-locale">üåê EN</span>
<span class="locale-separator">|</span>

<span class="locale-meta">Last sync: 2025-11-16</span>
</div>

<header>
<div class="header-content">
<h1>Chapter 4: Practical AutoML Tools</h1>
<p class="subtitle">Automated Machine Learning with TPOT, Auto-sklearn, and H2O AutoML</p>
<div class="meta">
<span class="meta-item">üìñ Reading Time: 40-45 minutes</span>
<span class="meta-item">üìä Difficulty: Intermediate</span>
<span class="meta-item">üíª Code Examples: 10</span>
<span class="meta-item">üìù Exercises: 5</span>
</div>
</div>
</header>
<main class="container">
<h1>Chapter 4: Practical AutoML Tools</h1>
<p><strong>Learning Objectives:</strong></p>
<ul>
<li>Understand TPOT's genetic programming approach</li>
<li>Master Auto-sklearn's Bayesian optimization and meta-learning</li>
<li>Build stacked ensembles with H2O AutoML</li>
<li>Understand characteristics and use cases of each AutoML tool</li>
<li>Learn deployment strategies for production environments</li>
</ul>
<p><strong>Reading Time</strong>: 40-45 minutes</p>
<hr/>
<h2>4.1 TPOT (Tree-based Pipeline Optimization Tool)</h2>
<h3>4.1.1 Overview of TPOT</h3>
<p><strong>What is TPOT:</strong><br/>
An AutoML tool that automatically optimizes entire scikit-learn pipelines using genetic programming.</p>
<p><strong>Developer:</strong> University of Pennsylvania (Moore Lab)</p>
<p><strong>Features:</strong></p>
<ul>
<li>Exploration using genetic algorithms</li>
<li>Full automation from preprocessing to model selection</li>
<li>Fully compatible with scikit-learn</li>
<li>Generated pipeline code can be exported as Python code</li>
</ul>
<h3>4.1.2 Genetic Programming Approach</h3>
<p><strong>Genetic Algorithm Flow:</strong></p>
<pre><code>1. Initial population generation (create random pipelines)
2. Evaluation (cross-validation score)
3. Selection (choose top individuals)
4. Crossover (combine pipelines)
5. Mutation (random changes)
6. Next generation
7. Repeat steps 2-6 for specified number of generations
</code></pre>
<p><strong>Pipeline Representation:</strong></p>
<pre><code># Genotype (tree structure)
Pipeline(
    SelectKBest(k=10),
    StandardScaler(),
    RandomForestClassifier(n_estimators=100)
)
</code></pre>
<h3>4.1.3 Basic Usage of TPOT</h3>
<p><strong>Example 1: Basic Classification Example</strong></p>
<pre><code class="language-python">from tpot import TPOTClassifier
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
import numpy as np

# Prepare dataset
iris = load_iris()
X_train, X_test, y_train, y_test = train_test_split(
    iris.data, iris.target, test_size=0.2, random_state=42
)

# Create TPOTClassifier
tpot = TPOTClassifier(
    generations=5,        # Number of evolutionary generations
    population_size=20,   # Number of individuals per generation
    cv=5,                 # Number of cross-validation folds
    random_state=42,
    verbosity=2,          # Progress display level
    n_jobs=-1             # Parallel processing
)

# Training (takes a few minutes)
tpot.fit(X_train, y_train)

# Evaluation
print(f'Test Accuracy: {tpot.score(X_test, y_test):.4f}')

# Save optimal pipeline as Python code
tpot.export('tpot_iris_pipeline.py')
</code></pre>
<p><strong>Output Example:</strong></p>
<pre><code>Generation 1 - Current best internal CV score: 0.9666666666666667
Generation 2 - Current best internal CV score: 0.975
Generation 3 - Current best internal CV score: 0.975
Generation 4 - Current best internal CV score: 0.9833333333333333
Generation 5 - Current best internal CV score: 0.9833333333333333

Best pipeline: RandomForestClassifier(SelectKBest(input_matrix, k=2),
                                      bootstrap=True, n_estimators=100)
Test Accuracy: 1.0000
</code></pre>
<h3>4.1.4 Customizing TPOT Configuration</h3>
<p><strong>Example 2: Custom TPOT Configuration</strong></p>
<pre><code class="language-python">from tpot import TPOTClassifier

# Create TPOT with custom configuration
tpot_config = {
    'sklearn.ensemble.RandomForestClassifier': {
        'n_estimators': [50, 100, 200],
        'max_features': ['sqrt', 'log2', None],
        'min_samples_split': [2, 5, 10]
    },
    'sklearn.svm.SVC': {
        'C': [0.1, 1.0, 10.0],
        'kernel': ['linear', 'rbf'],
        'gamma': ['scale', 'auto']
    },
    'sklearn.preprocessing.StandardScaler': {},
    'sklearn.feature_selection.SelectKBest': {
        'k': range(1, 11)
    }
}

tpot = TPOTClassifier(
    config_dict=tpot_config,
    generations=10,
    population_size=50,
    cv=5,
    scoring='f1_weighted',  # Change evaluation metric to F1 score
    max_time_mins=30,       # Maximum execution time 30 minutes
    random_state=42,
    verbosity=2
)

tpot.fit(X_train, y_train)
</code></pre>
<h3>4.1.5 Regression Example</h3>
<p><strong>Example 3: Using TPOT for Regression</strong></p>
<pre><code class="language-python">from tpot import TPOTRegressor
from sklearn.datasets import make_regression
from sklearn.model_selection import train_test_split

# Generate regression dataset
X, y = make_regression(n_samples=1000, n_features=20,
                       n_informative=15, noise=10, random_state=42)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# TPOTRegressor
tpot_reg = TPOTRegressor(
    generations=5,
    population_size=20,
    cv=5,
    scoring='neg_mean_squared_error',  # Minimize MSE
    random_state=42,
    verbosity=2
)

tpot_reg.fit(X_train, y_train)

# Evaluation
from sklearn.metrics import mean_squared_error, r2_score
y_pred = tpot_reg.predict(X_test)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f'Test MSE: {mse:.4f}')
print(f'Test R¬≤: {r2:.4f}')

# Save pipeline
tpot_reg.export('tpot_regression_pipeline.py')
</code></pre>
<p><strong>Example of Exported Code:</strong></p>
<pre><code class="language-python"># tpot_regression_pipeline.py
import numpy as np
import pandas as pd
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.model_selection import train_test_split
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import StandardScaler

# Generated pipeline
exported_pipeline = make_pipeline(
    StandardScaler(),
    GradientBoostingRegressor(
        alpha=0.9, learning_rate=0.1, loss="squared_error",
        max_depth=3, n_estimators=100
    )
)

# Usage example
exported_pipeline.fit(training_features, training_target)
results = exported_pipeline.predict(testing_features)
</code></pre>
<hr/>
<h2>4.2 Auto-sklearn</h2>
<h3>4.2.1 Overview of Auto-sklearn</h3>
<p><strong>What is Auto-sklearn:</strong><br/>
An automated machine learning tool that combines Bayesian optimization, meta-learning, and ensemble construction.</p>
<p><strong>Developer:</strong> University of Freiburg (Germany)</p>
<p><strong>Key Technologies:</strong></p>
<ol>
<li><strong>Bayesian Optimization:</strong> SMAC (Sequential Model-based Algorithm Configuration)</li>
<li><strong>Meta-learning:</strong> Learn initial configurations from past tasks</li>
<li><strong>Ensemble Construction:</strong> Automatically combine multiple models</li>
</ol>
<h3>4.2.2 Bayesian Optimization and Meta-learning</h3>
<p><strong>Bayesian Optimization Flow:</strong></p>
<pre><code>1. Evaluate model with initial configuration
2. Predict performance using Gaussian process
3. Determine next search point using acquisition function
4. Evaluate and update Gaussian process
5. Repeat steps 2-4
</code></pre>
<p><strong>Meta-learning:</strong><br/>
Infer good initial configurations for similar tasks from optimal settings on 140+ past datasets</p>
<pre><code>Meta-knowledge base (140+ tasks)
    ‚Üì
Similarity calculation (dataset features)
    ‚Üì
Warm start with top 25 configurations
    ‚Üì
Fine-tune with Bayesian optimization
</code></pre>
<h3>4.2.3 Basic Usage of Auto-sklearn</h3>
<p><strong>Example 4: Auto-sklearn Classification</strong></p>
<pre><code class="language-python">import autosklearn.classification
from sklearn.datasets import load_digits
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
import numpy as np

# Prepare dataset
digits = load_digits()
X_train, X_test, y_train, y_test = train_test_split(
    digits.data, digits.target, test_size=0.2, random_state=42
)

# Auto-sklearn classifier
automl = autosklearn.classification.AutoSklearnClassifier(
    time_left_for_this_task=300,  # Total execution time 5 minutes
    per_run_time_limit=30,         # 30 seconds per model
    ensemble_size=50,              # Ensemble size
    ensemble_nbest=200,            # Number of ensemble candidates
    initial_configurations_via_metalearning=25,  # Number of meta-learning initial configurations
    seed=42
)

# Training
automl.fit(X_train, y_train)

# Prediction and evaluation
y_pred = automl.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f'Test Accuracy: {accuracy:.4f}')

# Statistics of trained models
print(automl.sprint_statistics())

# Ensemble details
print(automl.show_models())
</code></pre>
<p><strong>Output Example:</strong></p>
<pre><code>auto-sklearn results:
  Dataset name: digits
  Metric: accuracy
  Best validation score: 0.9832
  Number of target algorithm runs: 127
  Number of successful target algorithm runs: 115
  Number of crashed target algorithm runs: 8
  Number of target algorithms that exceeded the time limit: 4
  Number of target algorithms that exceeded the memory limit: 0

Test Accuracy: 0.9806
</code></pre>
<h3>4.2.4 New Features in Auto-sklearn 2.0</h3>
<p><strong>Improvements in Auto-sklearn 2.0:</strong></p>
<ul>
<li>Reduced execution time (50% reduction compared to previous version)</li>
<li>Improved default settings</li>
<li>Faster portfolio construction</li>
<li>More efficient ensemble selection</li>
</ul>
<p><strong>Example 5: Using Auto-sklearn 2.0</strong></p>
<pre><code class="language-python">from autosklearn.experimental.askl2 import AutoSklearn2Classifier
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split

# Prepare data
cancer = load_breast_cancer()
X_train, X_test, y_train, y_test = train_test_split(
    cancer.data, cancer.target, test_size=0.2, random_state=42
)

# Auto-sklearn 2.0 (faster)
automl2 = AutoSklearn2Classifier(
    time_left_for_this_task=120,  # 2 minutes
    seed=42
)

automl2.fit(X_train, y_train)

# Evaluation
from sklearn.metrics import classification_report
y_pred = automl2.predict(X_test)
print(classification_report(y_test, y_pred))

# Get CV results
cv_results = automl2.cv_results_
print(f"Best model config: {automl2.get_models_with_weights()}")
</code></pre>
<h3>4.2.5 Custom Settings and Constraints</h3>
<p><strong>Example 6: Restricting Model Candidates</strong></p>
<pre><code class="language-python">import autosklearn.classification

# Restrict algorithms to use
automl_custom = autosklearn.classification.AutoSklearnClassifier(
    time_left_for_this_task=300,
    include={
        'classifier': ['random_forest', 'gradient_boosting', 'extra_trees'],
        'feature_preprocessor': ['no_preprocessing', 'pca', 'select_percentile']
    },
    exclude={
        'classifier': ['k_nearest_neighbors'],  # Exclude KNN
    },
    seed=42
)

automl_custom.fit(X_train, y_train)
</code></pre>
<hr/>
<h2>4.3 H2O AutoML</h2>
<h3>4.3.1 Overview of H2O AutoML</h3>
<p><strong>What is H2O.ai:</strong><br/>
An open-source distributed machine learning platform. Strong in large-scale data processing.</p>
<p><strong>H2O AutoML Features:</strong></p>
<ul>
<li>Automatic stacked ensemble construction</li>
<li>Leaderboard-style result display</li>
<li>Support for large-scale data (distributed processing)</li>
<li>Model explainability features (SHAP, PDP)</li>
</ul>
<h3>4.3.2 Basic Usage of H2O AutoML</h3>
<p><strong>Example 7: H2O AutoML Classification</strong></p>
<pre><code class="language-python">import h2o
from h2o.automl import H2OAutoML
import pandas as pd

# Initialize H2O
h2o.init()

# Prepare dataset (convert from Pandas)
from sklearn.datasets import load_wine
wine = load_wine()
df = pd.DataFrame(wine.data, columns=wine.feature_names)
df['target'] = wine.target

# Convert to H2O DataFrame
hf = h2o.H2OFrame(df)
hf['target'] = hf['target'].asfactor()  # For classification task

# Train/test split
train, test = hf.split_frame(ratios=[0.8], seed=42)

# Run AutoML
aml = H2OAutoML(
    max_runtime_secs=300,      # Maximum execution time 5 minutes
    max_models=20,              # Maximum number of models
    seed=42,
    sort_metric='AUC',          # Evaluation metric
    exclude_algos=['DeepLearning']  # Exclude deep learning
)

# Training (target is response variable, rest are predictor variables)
x = hf.columns
x.remove('target')
y = 'target'

aml.fit(x=x, y=y, training_frame=train)

# Display leaderboard
lb = aml.leaderboard
print(lb.head(rows=10))

# Prediction with best model
best_model = aml.leader
preds = best_model.predict(test)
print(preds.head())

# Model performance
perf = best_model.model_performance(test)
print(perf)
</code></pre>
<p><strong>Leaderboard Output Example:</strong></p>
<pre><code>                                              model_id       auc   logloss
0  StackedEnsemble_AllModels_1_AutoML_1_20241021  0.998876  0.067234
1  StackedEnsemble_BestOfFamily_1_AutoML_1_20241021  0.997543  0.072156
2               GBM_1_AutoML_1_20241021_163045  0.996321  0.078432
3                XRT_1_AutoML_1_20241021_163012  0.995234  0.081245
4                DRF_1_AutoML_1_20241021_163001  0.993456  0.089321
</code></pre>
<h3>4.3.3 Stacked Ensemble</h3>
<p><strong>H2O's Stacking Strategy:</strong></p>
<pre><code>Base Model Layer:
- GBM (multiple configurations)
- Random Forest
- XGBoost
- GLM
- DeepLearning

    ‚Üì Meta-features

Meta-model Layer:
- GLM (regularized)
- GBM

    ‚Üì

Final Prediction
</code></pre>
<p><strong>Example 8: Custom Stacked Ensemble</strong></p>
<pre><code class="language-python">from h2o.estimators import H2OGradientBoostingEstimator, H2ORandomForestEstimator
from h2o.estimators.stackedensemble import H2OStackedEnsembleEstimator

# Base model 1: GBM
gbm = H2OGradientBoostingEstimator(
    ntrees=50,
    max_depth=5,
    learn_rate=0.1,
    seed=42,
    model_id='gbm_base'
)
gbm.train(x=x, y=y, training_frame=train)

# Base model 2: Random Forest
rf = H2ORandomForestEstimator(
    ntrees=50,
    max_depth=10,
    seed=42,
    model_id='rf_base'
)
rf.train(x=x, y=y, training_frame=train)

# Build stacked ensemble
ensemble = H2OStackedEnsembleEstimator(
    base_models=[gbm, rf],
    metalearner_algorithm='gbm',
    seed=42
)
ensemble.train(x=x, y=y, training_frame=train)

# Evaluation
ensemble_perf = ensemble.model_performance(test)
print(f"Ensemble AUC: {ensemble_perf.auc()}")
</code></pre>
<h3>4.3.4 Model Explainability</h3>
<p><strong>Example 9: SHAP Values and PDP Visualization</strong></p>
<pre><code class="language-python"># SHAP values for best model
shap_values = best_model.shap_summary_plot(test)

# Partial Dependence Plot
best_model.partial_plot(
    data=test,
    cols=['alcohol', 'flavanoids'],  # Feature names
    plot=True
)

# Variable importance
varimp = best_model.varimp(use_pandas=True)
print(varimp.head(10))

# Feature Interaction
best_model.feature_interaction(max_depth=2)
</code></pre>
<hr/>
<h2>4.4 Other AutoML Tools</h2>
<h3>4.4.1 Google AutoML</h3>
<p><strong>Features:</strong></p>
<ul>
<li>Managed service on Google Cloud Platform</li>
<li>Uses Neural Architecture Search (NAS)</li>
<li>Supports image, text, and tabular data</li>
<li>Enterprise-grade scalability</li>
</ul>
<p><strong>Main Products:</strong></p>
<ul>
<li>AutoML Tables (tabular data)</li>
<li>AutoML Vision (image classification)</li>
<li>AutoML Natural Language (text classification)</li>
<li>Vertex AI (unified platform)</li>
</ul>
<h3>4.4.2 Azure AutoML</h3>
<p><strong>Features:</strong></p>
<ul>
<li>Integrated into Azure Machine Learning Studio</li>
<li>Codeless UI + Python library</li>
<li>Rich model explainability features</li>
<li>MLOps pipeline integration</li>
</ul>
<h3>4.4.3 PyCaret</h3>
<p><strong>What is PyCaret:</strong><br/>
A low-code machine learning library in Python. Can execute AutoML with just a few lines.</p>
<p><strong>Example 10: PyCaret Usage Example</strong></p>
<pre><code class="language-python">from pycaret.classification import *
import pandas as pd
from sklearn.datasets import load_iris

# Prepare dataset
iris = load_iris()
df = pd.DataFrame(iris.data, columns=iris.feature_names)
df['target'] = iris.target

# PyCaret environment setup
clf_setup = setup(
    data=df,
    target='target',
    train_size=0.8,
    session_id=42,
    verbose=False
)

# Compare all models (automatic)
best_models = compare_models(n_select=3)  # Top 3 models

# Detailed evaluation of best model
best = best_models[0]
evaluate_model(best)

# Hyperparameter tuning
tuned_best = tune_model(best, n_iter=50)

# Ensemble
bagged = ensemble_model(tuned_best, method='Bagging')
boosted = ensemble_model(tuned_best, method='Boosting')

# Stacking
stacked = stack_models(estimator_list=best_models[:3])

# Save model
save_model(stacked, 'pycaret_final_model')

# Predict on new data
predictions = predict_model(stacked, data=df)
print(predictions.head())
</code></pre>
<h3>4.4.4 Ludwig</h3>
<p><strong>What is Ludwig:</strong><br/>
A codeless deep learning toolbox developed by Uber. Build models with YAML configuration files.</p>
<p><strong>Features:</strong></p>
<ul>
<li>Declarative model definition (YAML-based)</li>
<li>Support for diverse data types (mixed image, text, and tabular data)</li>
<li>Built-in AutoML mode</li>
<li>Transfer learning support</li>
</ul>
<h3>4.4.5 AutoML Tool Comparison Table</h3>
<table>
<thead>
<tr>
<th>Tool</th>
<th>Optimization Method</th>
<th>Execution Speed</th>
<th>Scalability</th>
<th>Explainability</th>
<th>Learning Curve</th>
<th>Best Use Case</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>TPOT</strong></td>
<td>Genetic Programming</td>
<td>Medium</td>
<td>Medium</td>
<td>High (code export)</td>
<td>Low</td>
<td>Medium-scale data, pipeline automation</td>
</tr>
<tr>
<td><strong>Auto-sklearn</strong></td>
<td>Bayesian Optimization + Meta-learning</td>
<td>Medium-High</td>
<td>Medium</td>
<td>Medium</td>
<td>Low</td>
<td>Academic research, benchmarking</td>
</tr>
<tr>
<td><strong>H2O AutoML</strong></td>
<td>Grid Search + Stacking</td>
<td>High</td>
<td>High</td>
<td>High (SHAP integration)</td>
<td>Medium</td>
<td>Large-scale data, production</td>
</tr>
<tr>
<td><strong>PyCaret</strong></td>
<td>Combination of multiple methods</td>
<td>High</td>
<td>Medium</td>
<td>High</td>
<td>Very Low</td>
<td>Rapid prototyping</td>
</tr>
<tr>
<td><strong>Google AutoML</strong></td>
<td>NAS (Neural Architecture Search)</td>
<td>High</td>
<td>Very High</td>
<td>Medium</td>
<td>Low</td>
<td>Cloud-based large-scale tasks</td>
</tr>
<tr>
<td><strong>Azure AutoML</strong></td>
<td>Hybrid of multiple methods</td>
<td>High</td>
<td>High</td>
<td>Very High</td>
<td>Low</td>
<td>Enterprise MLOps</td>
</tr>
<tr>
<td><strong>Ludwig</strong></td>
<td>Hyperparameter search</td>
<td>Medium</td>
<td>Medium</td>
<td>Medium</td>
<td>Medium</td>
<td>Multimodal deep learning</td>
</tr>
</tbody>
</table>
<hr/>
<h2>4.5 AutoML Best Practices</h2>
<h3>4.5.1 Tool Selection Criteria</h3>
<p><strong>Selection by Data Size:</strong></p>
<ul>
<li><strong>Small scale (&lt;10,000 samples):</strong> TPOT, Auto-sklearn</li>
<li><strong>Medium scale (10,000-1,000,000):</strong> H2O AutoML, PyCaret</li>
<li><strong>Large scale (&gt;1,000,000):</strong> H2O AutoML (distributed mode), Google/Azure AutoML</li>
</ul>
<p><strong>Selection by Task Type:</strong></p>
<ul>
<li><strong>Tabular data:</strong> TPOT, Auto-sklearn, H2O, PyCaret</li>
<li><strong>Image/Text:</strong> Google AutoML, Ludwig</li>
<li><strong>Time series:</strong> Auto-sklearn, H2O, PyCaret</li>
<li><strong>Multimodal:</strong> Ludwig</li>
</ul>
<p><strong>Execution Time Constraints:</strong></p>
<ul>
<li><strong>Short time (&lt;10 minutes):</strong> PyCaret, Auto-sklearn 2.0</li>
<li><strong>Medium time (10 minutes to 1 hour):</strong> TPOT, H2O AutoML</li>
<li><strong>Long time OK (&gt;1 hour):</strong> All possible (deeper exploration)</li>
</ul>
<h3>4.5.2 Customization vs Full Automation</h3>
<p><strong>When Full Automation is Suitable:</strong></p>
<ul>
<li>Creating initial baseline</li>
<li>Limited domain knowledge</li>
<li>Rapid prototyping</li>
<li>Batch processing of multiple datasets</li>
</ul>
<p><strong>When Customization is Necessary:</strong></p>
<ul>
<li>Domain-specific preprocessing needed</li>
<li>Want to restrict to specific model families</li>
<li>Using custom evaluation metrics</li>
<li>Interpretability is top priority</li>
</ul>
<p><strong>Hybrid Approach:</strong></p>
<pre><code class="language-python"># 1. Create baseline with AutoML
tpot.fit(X_train, y_train)
baseline_score = tpot.score(X_test, y_test)

# 2. Manually improve exported pipeline
from tpot_exported_pipeline import exported_pipeline
pipeline = exported_pipeline

# 3. Add domain knowledge
from sklearn.preprocessing import FunctionTransformer

def domain_specific_transform(X):
    # Custom transformation
    return X

pipeline.steps.insert(
    0, ('domain_transform', FunctionTransformer(domain_specific_transform))
)

# 4. Re-evaluate
pipeline.fit(X_train, y_train)
improved_score = pipeline.score(X_test, y_test)
print(f'Baseline: {baseline_score:.4f}, Improved: {improved_score:.4f}')
</code></pre>
<h3>4.5.3 Deployment to Production Environment</h3>
<p><strong>Considerations for Deployment:</strong></p>
<ol>
<li>
<p><strong>Model Size and Inference Speed</strong></p>
<ul>
<li>Ensemble models are high accuracy but heavy</li>
<li>Select model based on inference speed requirements</li>
</ul>
</li>
<li>
<p><strong>Dependency Management</strong></p>
<ul>
<li>Include AutoML tool dependency libraries in production environment</li>
<li>Docker containerization recommended</li>
</ul>
</li>
<li>
<p><strong>Version Control</strong></p>
<ul>
<li>Model and pipeline versioning</li>
<li>Use MLOps tools like MLflow, DVC</li>
</ul>
</li>
<li>
<p><strong>Monitoring</strong></p>
<ul>
<li>Data drift detection</li>
<li>Model performance tracking</li>
<li>Set retraining triggers</li>
</ul>
</li>
</ol>
<p><strong>Deployment Example (Flask API):</strong></p>
<pre><code class="language-python"># app.py
from flask import Flask, request, jsonify
import joblib
import numpy as np

app = Flask(__name__)

# Load model
model = joblib.load('tpot_model.pkl')

@app.route('/predict', methods=['POST'])
def predict():
    data = request.get_json()
    features = np.array(data['features']).reshape(1, -1)
    prediction = model.predict(features)
    probability = model.predict_proba(features)

    return jsonify({
        'prediction': int(prediction[0]),
        'probability': probability[0].tolist()
    })

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000)
</code></pre>
<h3>4.5.4 Cost and Time Management</h3>
<p><strong>Computational Cost Reduction Strategies:</strong></p>
<ol>
<li>
<p><strong>Early Stopping:</strong></p>
<ul>
<li>Terminate early when no improvement is seen</li>
<li>Set <code>max_time_mins</code>, <code>max_models</code> parameters</li>
</ul>
</li>
<li>
<p><strong>Parallel Processing:</strong></p>
<ul>
<li>Use all CPU cores with <code>n_jobs=-1</code></li>
<li>For cloud, select appropriate instance type</li>
</ul>
</li>
<li>
<p><strong>Data Sampling:</strong></p>
<ul>
<li>Initial exploration with small sample</li>
<li>Retrain with full data once promising configuration is found</li>
</ul>
</li>
<li>
<p><strong>Staged Approach:</strong></p>
</li>
</ol>
<pre><code class="language-python"># Stage 1: Fast exploration (10 minutes)
quick_automl = TPOTClassifier(
    generations=3,
    population_size=10,
    max_time_mins=10
)
quick_automl.fit(X_train_sample, y_train_sample)

# Stage 2: Detailed exploration (1 hour)
if quick_automl.score(X_val, y_val) &gt; 0.85:  # Only if threshold exceeded
    deep_automl = TPOTClassifier(
        generations=20,
        population_size=50,
        max_time_mins=60
    )
    deep_automl.fit(X_train, y_train)
</code></pre>
<p><strong>Cloud Cost Management:</strong></p>
<ul>
<li><strong>Spot/Preemptible Instances:</strong> Can reduce costs by 70%</li>
<li><strong>Auto Scaling:</strong> Use resources only when needed</li>
<li><strong>Budget Alerts:</strong> Avoid unexpected costs by setting limits</li>
</ul>
<hr/>
<h2>4.6 Summary</h2>
<h3>What We Learned</h3>
<ol>
<li>
<p><strong>TPOT:</strong></p>
<ul>
<li>Optimizes entire pipeline with genetic programming</li>
<li>High transparency with Python code export</li>
<li>Suitable for exploration on medium-scale data</li>
</ul>
</li>
<li>
<p><strong>Auto-sklearn:</strong></p>
<ul>
<li>Efficient exploration with Bayesian optimization and meta-learning</li>
<li>Automatic ensemble construction</li>
<li>Widely used academically</li>
</ul>
</li>
<li>
<p><strong>H2O AutoML:</strong></p>
<ul>
<li>Strong with large-scale data</li>
<li>Easy result comparison with leaderboard</li>
<li>Rich model explainability features</li>
</ul>
</li>
<li>
<p><strong>Tool Selection Criteria:</strong></p>
<ul>
<li>Consider data size, task type, time constraints</li>
<li>Balance full automation and customization</li>
<li>Production requirements (speed, size, dependencies)</li>
</ul>
</li>
<li>
<p><strong>Best Practices:</strong></p>
<ul>
<li>Reduce costs with staged approach</li>
<li>Design monitoring for deployment</li>
<li>Integration with MLOps tools</li>
</ul>
</li>
</ol>
<h3>Next Steps</h3>
<p>In Chapter 5, we will learn automated feature engineering and using Feature Tools:</p>
<ul>
<li>Theory of automatic feature generation</li>
<li>Deep feature synthesis with Feature Tools</li>
<li>Automatic feature extraction for time series data</li>
<li>Automation of feature selection</li>
</ul>
<hr/>
<h2>Exercises</h2>
<p><strong>Question 1:</strong> Explain the roles of "crossover" and "mutation" in TPOT's genetic programming approach, and describe how each contributes to pipeline optimization.</p>
<p><strong>Question 2:</strong> Explain how Auto-sklearn's meta-learning solves the cold start problem. Also discuss situations where meta-learning might not be effective.</p>
<p><strong>Question 3:</strong> Design an experiment to compare the performance of H2O AutoML's stacked ensemble versus single models. Describe what types of datasets would maximize the effectiveness of stacking.</p>
<p><strong>Question 4:</strong> Select the optimal AutoML tool for the following scenarios and explain your reasoning:<br/>
(a) 10,000 samples of medical diagnostic data, high interpretability required<br/>
(b) 1 billion samples of click log data, inference speed is important<br/>
(c) Mixed image and text data, rapid prototyping</p>
<p><strong>Question 5:</strong> List five major considerations when deploying AutoML models to production environments, and describe specific countermeasures for each (within 600 characters).</p>
<hr/>
<h2>References</h2>
<ol>
<li>Olson, R. S. et al. "TPOT: A Tree-based Pipeline Optimization Tool for Automating Machine Learning." <em>AutoML Workshop at ICML</em> (2016).</li>
<li>Feurer, M. et al. "Efficient and Robust Automated Machine Learning." <em>NIPS</em> (2015).</li>
<li>LeDell, E. &amp; Poirier, S. "H2O AutoML: Scalable Automatic Machine Learning." <em>AutoML Workshop at ICML</em> (2020).</li>
<li>Hutter, F. et al. "Sequential Model-Based Optimization for General Algorithm Configuration." <em>LION</em> (2011).</li>
<li>Molnar, C. <em>Interpretable Machine Learning: A Guide for Making Black Box Models Explainable.</em> (2022).</li>
<li>Lundberg, S. M. &amp; Lee, S.-I. "A Unified Approach to Interpreting Model Predictions." <em>NIPS</em> (2017).</li>
<li>He, X. et al. "AutoML: A Survey of the State-of-the-Art." <em>Knowledge-Based Systems</em> (2021).</li>
</ol>
<hr/>
<p><strong>Next Chapter</strong>: <a href="chapter5-feature-engineering.html">Chapter 5: Automated Feature Engineering</a></p>
<p><strong>License</strong>: This content is provided under CC BY 4.0 license.</p>
<div class="navigation">
<a class="nav-button" href="chapter3-model-selection.html">‚Üê Previous Chapter</a>
<a class="nav-button" href="index.html">Return to Series Index</a>
<a class="nav-button" href="chapter5-feature-engineering.html">Next Chapter ‚Üí</a>
</div>
</main>
<section class="disclaimer">
<h3>Disclaimer</h3>
<ul>
<li>This content is provided solely for educational, research, and informational purposes and does not constitute professional advice (legal, accounting, technical guarantees, etc.).</li>
<li>This content and accompanying code examples are provided "AS IS" without any warranties, express or implied, including but not limited to merchantability, fitness for a particular purpose, non-infringement, accuracy, completeness, operation, or safety.</li>
<li>The authors and Tohoku University assume no responsibility for the content, availability, or safety of external links or third-party data, tools, or libraries.</li>
<li>To the maximum extent permitted by applicable law, the authors and Tohoku University shall not be liable for any direct, indirect, incidental, special, consequential, or punitive damages arising from the use, execution, or interpretation of this content.</li>
<li>The content of this material may be changed, updated, or discontinued without notice.</li>
<li>The copyright and license of this content follow the specified conditions (e.g., CC BY 4.0). Such licenses typically include no-warranty clauses.</li>
</ul>
</section>
<footer>
<p><strong>Created by</strong>: AI Terakoya Content Team</p>
<p><strong>Version</strong>: 1.0 | <strong>Created</strong>: 2025-10-21</p>
<p><strong>License</strong>: Creative Commons BY 4.0</p>
<p>¬© 2025 AI Terakoya. All rights reserved.</p>
</footer>
</body>
</html>
