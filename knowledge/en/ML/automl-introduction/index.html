<!DOCTYPE html>

<html lang="en">
<head>
<meta charset="utf-8"/>
<meta content="AutoML Introduction Series v1.0 - AI Terakoya" name="description"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<meta content="AutoML Introduction Series - A Complete Practical Guide to Efficient Model Building with Automated Machine Learning" name="description"/>
<title>AutoML Introduction Series v1.0 - AI Terakoya</title>
<!-- CSS Styling -->
<link href="../../assets/css/knowledge-base.css" rel="stylesheet"/>
<!-- Mermaid for diagrams -->
<script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
<script>
        // Mermaid.js Converter - Converts markdown-style mermaid code blocks to renderable divs
        document.addEventListener('DOMContentLoaded', function() {
            // Find all code blocks with class="language-mermaid"
            const mermaidCodeBlocks = document.querySelectorAll('pre.codehilite code.language-mermaid, pre code.language-mermaid');

            mermaidCodeBlocks.forEach(function(codeBlock) {
                const pre = codeBlock.parentElement;
                const mermaidCode = codeBlock.textContent;

                // Create a new div with mermaid class
                const mermaidDiv = document.createElement('div');
                mermaidDiv.className = 'mermaid';
                mermaidDiv.textContent = mermaidCode.trim();

                // Replace the pre element with the new div
                pre.parentNode.replaceChild(mermaidDiv, pre);
            });

            // Re-initialize mermaid after conversion
            if (typeof mermaid !== 'undefined') {
                mermaid.initialize({ startOnLoad: true, theme: 'default' });
                mermaid.init(undefined, document.querySelectorAll('.mermaid'));
            }
        });
    </script>
</head>
<body>
<nav class="breadcrumb">
<div class="breadcrumb-content">
<a href="../index.html">AI Terakoya Top</a><span class="breadcrumb-separator">‚Ä∫</span><a href="../index.html">Machine Learning</a><span class="breadcrumb-separator">‚Ä∫</span><span class="breadcrumb-current">AutoML</span>
</div>
</nav><div class="locale-switcher">
<span class="current-locale">üåê EN</span>
<span class="locale-separator">|</span>
<a href="../../../jp/ML/automl-introduction/index.html" class="locale-link">üáØüáµ JP</a>
<span class="locale-separator">|</span>

<span class="locale-meta">Last sync: 2025-11-16</span>
</div>

<header>
<div class="container">
<h1>AutoML Introduction Series v1.0</h1>
<p style="font-size: 1.1rem; margin-top: 0.5rem; opacity: 0.95;">Efficient Model Building with Automated Machine Learning</p>
<div class="meta">
<span>üìñ Total Learning Time: 4.5-5.5 hours</span>
<span>üìä Level: Intermediate</span>
</div>
</div>
</header>
<main class="container">
<p><strong>Learn AutoML fundamentals through practical experience with tools like AutoKeras, TPOT, and Optuna for automated model selection and hyperparameter optimization</strong></p>
<h2 id="overview">Series Overview</h2>
<p>This series is a practical educational content consisting of 4 chapters that teaches AutoML (Automated Machine Learning) theory and implementation from fundamentals to advanced concepts.</p>
<p><strong>AutoML (Automated Machine Learning)</strong> is a technology that automates machine learning model design, selection, and optimization processes to enable efficient model building. Through hyperparameter optimization (HPO) for model performance improvement, Neural Architecture Search (NAS) for automatic optimal network structure exploration, and meta-learning to leverage past knowledge, high-performance models can be built even with limited domain expertise. Tech giants like Google, Microsoft, and Amazon provide AutoML services contributing to data scientist productivity. This series provides practical knowledge using major tools like Optuna, AutoKeras, TPOT, Auto-sklearn, and H2O AutoML, enabling understanding and implementation of the latest AutoML technologies.</p>
<p><strong>Features:</strong></p>
<ul>
<li>‚úÖ <strong>Theory to Practice</strong>: Systematic learning from AutoML concepts to implementation and application</li>
<li>‚úÖ <strong>Implementation-Focused</strong>: Over 30 executable Python/Optuna/AutoKeras code examples</li>
<li>‚úÖ <strong>Practical-Oriented</strong>: Workflows designed for real machine learning projects</li>
<li>‚úÖ <strong>Latest Technology</strong>: Implementation using Optuna, AutoKeras, TPOT, and Auto-sklearn</li>
<li>‚úÖ <strong>Practical Applications</strong>: Practice in hyperparameter optimization, NAS, and AutoML tools</li>
</ul>
<p><strong>Total Learning Time</strong>: 4.5-5.5 hours (including code execution and exercises)</p>
<h2 id="learning">How to Study</h2>
<h3>Recommended Study Order</h3>
<div class="mermaid">
graph TD
    A[Chapter 1: AutoML Basics] --&gt; B[Chapter 2: Hyperparameter Optimization]
    B --&gt; C[Chapter 3: Neural Architecture Search]
    C --&gt; D[Chapter 4: AutoML Tools in Practice]

    style A fill:#e3f2fd
    style B fill:#fff3e0
    style C fill:#f3e5f5
    style D fill:#e8f5e9
</div>
<p><strong>For Beginners (no AutoML experience):</strong><br/>
        - Chapter 1 ‚Üí Chapter 2 ‚Üí Chapter 3 ‚Üí Chapter 4 (all chapters recommended)<br/>
        - Time required: 4.5-5.5 hours</p>
<p><strong>For Intermediate learners (with ML development experience):</strong><br/>
        - Chapter 2 ‚Üí Chapter 3 ‚Üí Chapter 4<br/>
        - Time required: 3.5-4.5 hours</p>
<p><strong>For Specific Topic Enhancement:</strong><br/>
        - AutoML Basics, NAS, Meta-learning: Chapter 1 (intensive study)<br/>
        - Hyperparameter Optimization, Optuna: Chapter 2 (intensive study)<br/>
        - Neural Architecture Search, AutoKeras: Chapter 3 (intensive study)<br/>
        - AutoML Tools, TPOT, H2O: Chapter 4 (intensive study)<br/>
        - Time required: 60-80 minutes/chapter</p>
<h2 id="chapters">Chapter Details</h2>
<h3><a href="./chapter1-automl-basics.html">Chapter 1: AutoML Basics</a></h3>
<p><strong>Difficulty</strong>: Intermediate<br/>
<strong>Reading Time</strong>: 60-70 minutes<br/>
<strong>Code Examples</strong>: 6</p>
<h4>Learning Content</h4>
<ol>
<li><strong>What is AutoML</strong> - Definition, purpose, advantages and disadvantages</li>
<li><strong>AutoML Components</strong> - Data preprocessing, feature engineering, model selection, HPO</li>
<li><strong>Neural Architecture Search (NAS)</strong> - Search space, search strategies, performance evaluation</li>
<li><strong>Meta-learning</strong> - Transfer learning, Few-shot learning, warm start</li>
<li><strong>AutoML Application Areas</strong> - Image classification, time series forecasting, natural language processing</li>
</ol>
<h4>Learning Objectives</h4>
<ul>
<li>‚úÖ Understand basic AutoML concepts</li>
<li>‚úÖ Explain AutoML components</li>
<li>‚úÖ Understand basic NAS principles</li>
<li>‚úÖ Explain meta-learning concepts</li>
<li>‚úÖ Understand AutoML application areas</li>
</ul>
<p><strong><a href="./chapter1-automl-basics.html">Read Chapter 1 ‚Üí</a></strong></p>
<hr/>
<h3><a href="./chapter2-hyperparameter-optimization.html">Chapter 2: Hyperparameter Optimization</a></h3>
<p><strong>Difficulty</strong>: Intermediate<br/>
<strong>Reading Time</strong>: 70-80 minutes<br/>
<strong>Code Examples</strong>: 10</p>
<h4>Learning Content</h4>
<ol>
<li><strong>HPO Fundamentals</strong> - Grid search, random search, Bayesian optimization</li>
<li><strong>Optuna</strong> - TPE, CMA-ES, Pruning, distributed optimization</li>
<li><strong>Hyperopt</strong> - Tree-structured Parzen Estimator, parallel optimization</li>
<li><strong>Ray Tune</strong> - Scalable HPO, Population Based Training</li>
<li><strong>Practical HPO</strong> - Search space design, Early Stopping, multi-objective optimization</li>
</ol>
<h4>Learning Objectives</h4>
<ul>
<li>‚úÖ Understand basic HPO methods</li>
<li>‚úÖ Execute efficient HPO with Optuna</li>
<li>‚úÖ Design appropriate search spaces</li>
<li>‚úÖ Reduce computational costs with Pruning</li>
<li>‚úÖ Implement multi-objective optimization</li>
</ul>
<p><strong><a href="./chapter2-hyperparameter-optimization.html">Read Chapter 2 ‚Üí</a></strong></p>
<hr/>
<h3><a href="./chapter3-neural-architecture-search.html">Chapter 3: Neural Architecture Search</a></h3>
<p><strong>Difficulty</strong>: Intermediate<br/>
<strong>Reading Time</strong>: 70-80 minutes<br/>
<strong>Code Examples</strong>: 8</p>
<h4>Learning Content</h4>
<ol>
<li><strong>NAS Basics</strong> - Search space, search strategies, performance estimation</li>
<li><strong>AutoKeras</strong> - AutoModel, ImageClassifier, TextClassifier</li>
<li><strong>NAS-Bench</strong> - Benchmark datasets, performance prediction</li>
<li><strong>DARTS</strong> - Differentiable NAS, continuous relaxation, gradient-based search</li>
<li><strong>Efficient NAS</strong> - One-shot NAS, Weight Sharing, SuperNet</li>
</ol>
<h4>Learning Objectives</h4>
<ul>
<li>‚úÖ Understand basic NAS principles</li>
<li>‚úÖ Build automatic models with AutoKeras</li>
<li>‚úÖ Evaluate performance using NAS-Bench</li>
<li>‚úÖ Understand DARTS principles</li>
<li>‚úÖ Explain efficient NAS methods</li>
</ul>
<p><strong><a href="./chapter3-neural-architecture-search.html">Read Chapter 3 ‚Üí</a></strong></p>
<hr/>
<h3><a href="./chapter4-automl-tools.html">Chapter 4: AutoML Tools in Practice</a></h3>
<p><strong>Difficulty</strong>: Intermediate<br/>
<strong>Reading Time</strong>: 60-70 minutes<br/>
<strong>Code Examples</strong>: 9</p>
<h4>Learning Content</h4>
<ol>
<li><strong>TPOT</strong> - Genetic Programming, pipeline optimization, feature selection</li>
<li><strong>Auto-sklearn</strong> - Meta-learning, ensemble, Bayesian optimization</li>
<li><strong>H2O AutoML</strong> - Leaderboard, Stacked Ensemble, explainability</li>
<li><strong>AutoML Tool Comparison</strong> - Performance, speed, ease of use, customizability</li>
<li><strong>Practical AutoML Workflows</strong> - Data preparation, model selection, deployment</li>
</ol>
<h4>Learning Objectives</h4>
<ul>
<li>‚úÖ Optimize pipelines with TPOT</li>
<li>‚úÖ Leverage meta-learning with Auto-sklearn</li>
<li>‚úÖ Build ensembles with H2O AutoML</li>
<li>‚úÖ Select appropriate AutoML tools</li>
<li>‚úÖ Implement end-to-end AutoML workflows</li>
</ul>
<p><strong><a href="./chapter4-automl-tools.html">Read Chapter 4 ‚Üí</a></strong></p>
<hr/>
<h2 id="outcomes">Overall Learning Outcomes</h2>
<p>Upon completing this series, you will have acquired the following skills and knowledge:</p>
<h3>Knowledge Level (Understanding)</h3>
<ul>
<li>‚úÖ Explain basic AutoML concepts and components</li>
<li>‚úÖ Understand principles of hyperparameter optimization and NAS</li>
<li>‚úÖ Explain roles of Optuna, AutoKeras, TPOT, and Auto-sklearn</li>
<li>‚úÖ Understand meta-learning and Bayesian optimization</li>
<li>‚úÖ Explain AutoML application areas and limitations</li>
</ul>
<h3>Practical Skills (Doing)</h3>
<ul>
<li>‚úÖ Optimize hyperparameters with Optuna</li>
<li>‚úÖ Automatically build image classification models with AutoKeras</li>
<li>‚úÖ Optimize ML pipelines with TPOT</li>
<li>‚úÖ Build ensemble models with H2O AutoML</li>
<li>‚úÖ Design appropriate search spaces and leverage Pruning</li>
</ul>
<h3>Application Ability (Applying)</h3>
<ul>
<li>‚úÖ Select suitable AutoML tools for projects</li>
<li>‚úÖ Design efficient HPO strategies</li>
<li>‚úÖ Explore optimal model structures using NAS</li>
<li>‚úÖ Implement end-to-end AutoML workflows</li>
<li>‚úÖ Interpret and improve AutoML results</li>
</ul>
<hr/>
<h2 id="prerequisites">Prerequisites</h2>
<p>To effectively study this series, the following knowledge is recommended:</p>
<h3>Required (Must Have)</h3>
<ul>
<li>‚úÖ <strong>Python Basics</strong>: Variables, functions, classes, modules</li>
<li>‚úÖ <strong>Machine Learning Basics</strong>: Training, validation, testing, cross-validation</li>
<li>‚úÖ <strong>scikit-learn</strong>: Pipeline, GridSearchCV, model training</li>
<li>‚úÖ <strong>NumPy/pandas</strong>: Data manipulation, array processing</li>
<li>‚úÖ <strong>Deep Learning Basics</strong>: Neural networks, CNN (recommended)</li>
</ul>
<h3>Recommended (Nice to Have)</h3>
<ul>
<li>üí° <strong>TensorFlow/Keras</strong>: Model building, training (for NAS)</li>
<li>üí° <strong>Bayesian Statistics</strong>: Understanding Bayesian optimization</li>
<li>üí° <strong>Optimization Algorithms</strong>: Gradient descent, evolutionary algorithms</li>
<li>üí° <strong>Distributed Computing</strong>: Parallel processing, Ray (for scaling)</li>
<li>üí° <strong>MLOps Basics</strong>: Experiment management, model management</li>
</ul>
<p><strong>Recommended Prerequisite Learning</strong>:</p>
<ul>
<li>üìö  - ML fundamentals</li>
<!-- Content in preparation <li>üìö <a href="../deep-learning-basics/">Deep Learning Introduction Series</a> - Neural networks</li>
            <!-- Content in preparation <li>üìö <a href="../python-for-ml/">Python for Machine Learning</a> - scikit-learn, pandas</li>
            <li>üìö <a href="../mlops-introduction/">MLOps Introduction</a> - Experiment management, model management</li>
        </ul>

        <hr>

        <h2 id="tech">Technologies and Tools Used</h2>

        <h3>Main Libraries</h3>
        <ul>
            <li><strong>Optuna 3.4+</strong> - Hyperparameter optimization</li>
            <li><strong>AutoKeras 1.1+</strong> - Neural Architecture Search</li>
            <li><strong>TPOT 0.12+</strong> - Genetic Programming AutoML</li>
            <li><strong>Auto-sklearn 0.15+</strong> - Meta-learning AutoML</li>
            <li><strong>H2O AutoML 3.42+</strong> - Ensemble AutoML</li>
            <li><strong>Hyperopt 0.2+</strong> - Bayesian optimization</li>
            <li><strong>Ray Tune 2.7+</strong> - Scalable HPO</li>
        </ul>

        <h3>Development Environment</h3>
        <ul>
            <li><strong>Python 3.8+</strong> - Programming language</li>
            <li><strong>scikit-learn 1.3+</strong> - Machine learning</li>
            <li><strong>TensorFlow 2.13+</strong> - Deep learning framework</li>
            <li><strong>Keras 2.13+</strong> - High-level API</li>
            <li><strong>pandas 2.0+</strong> - Data processing</li>
            <li><strong>NumPy 1.24+</strong> - Numerical computation</li>
        </ul>

        <h3>Cloud Services (Recommended)</h3>
        <ul>
            <li><strong>Google Cloud Vertex AI</strong> - AutoML Tables, AutoML Vision</li>
            <li><strong>AWS SageMaker Autopilot</strong> - AutoML functionality</li>
            <li><strong>Azure AutoML</strong> - Enterprise AutoML</li>
            <li><strong>Databricks AutoML</strong> - Integrated AutoML platform</li>
        </ul>

        <hr>

        <h2 id="start">Let's Get Started!</h2>
        <p>Ready to begin? Start with Chapter 1 and master AutoML technology!</p>

        <p><strong><a href="./chapter1-automl-basics.html">Chapter 1: AutoML Basics ‚Üí</a></strong></p>

        <hr>

        <h2 id="next">Next Steps</h2>

        <p>After completing this series, we recommend continuing with the following topics:</p>

        <h3>Advanced Learning</h3>
        <ul>
            <li>üìö <strong>Advanced NAS</strong>: Efficient NAS, One-shot NAS, Differentiable NAS</li>
            <li>üìö <strong>Meta-learning</strong>: MAML, Reptile, Few-shot Learning</li>
            <li>üìö <strong>AutoML for NLP</strong>: Transformer search, Prompt Tuning</li>
            <li>üìö <strong>Explainable AutoML</strong>: SHAP, LIME, feature importance</li>
        </ul>

        <h3>Related Series</h3>
        <ul>
            <li>üéØ <a href="../mlops-introduction/">MLOps Introduction</a> - Experiment management, model management, CI/CD</li>
            <li>üéØ  - Transformers, GANs, reinforcement learning</li>
            <li>üéØ <a href="../model-optimization/">Model Optimization</a> - Quantization, distillation, pruning</li>
        </ul>

        <h3>Practical Projects</h3>
        <ul>
            <li>üöÄ Image Classification AutoML Pipeline - Automatic model building with AutoKeras</li>
            <li>üöÄ Time Series Forecasting AutoML - Demand forecasting with TPOT</li>
            <li>üöÄ Custom NAS Implementation - Search space design based on DARTS</li>
            <li>üöÄ Multi-objective AutoML - Optimizing accuracy vs. inference speed tradeoffs</li>
        </ul>

        <hr>

        <p><strong>Update History</strong></p>
        <ul>
            <li><strong>2025-10-21</strong>: v1.0 first edition published</li>
        </ul>

        <hr>

        <p><strong>Your AutoML journey starts here!</strong></p>

    </main>


    <section class="disclaimer">
        <h3>Disclaimer</h3>
        <ul>
            <li>This content is provided solely for educational, research, and informational purposes and does not constitute professional advice (legal, accounting, technical guarantees, etc.).</li>
            <li>This content and accompanying code examples are provided "AS IS" without any warranties, express or implied, including but not limited to merchantability, fitness for a particular purpose, non-infringement, accuracy, completeness, operation, or safety.</li>
            <li>The authors and Tohoku University assume no responsibility for the content, availability, or safety of external links or third-party data, tools, or libraries.</li>
            <li>To the maximum extent permitted by applicable law, the authors and Tohoku University shall not be liable for any direct, indirect, incidental, special, consequential, or punitive damages arising from the use, execution, or interpretation of this content.</li>
            <li>The content of this material may be changed, updated, or discontinued without notice.</li>
            <li>The copyright and license of this content follow the specified conditions (e.g., CC BY 4.0). Such licenses typically include no-warranty clauses.</li>
        </ul>
    </section>

<footer>
        <div class="container">
            <p>&copy; 2025 AI Terakoya - Dr. Yusuke Hashimoto, Tohoku University</p>
            <p>Licensed under CC BY 4.0</p>
        </div>
    </footer>
</body>
</html>
--></ul></main></body></html>