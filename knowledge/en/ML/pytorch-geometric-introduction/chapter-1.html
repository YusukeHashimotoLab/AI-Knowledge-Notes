<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Chapter 1: PyTorch Geometric Introduction and Graph Data Fundamentals - PyTorch Geometric Introduction - AI Terakoya</title>
  <meta name="description" content="Learn the fundamentals of PyTorch Geometric and how to work with graph data. Understand graph structures, Data objects, built-in datasets, and basic GNN implementation through practical code examples.">

  <style>
    :root {
      --color-primary: #2c3e50;
      --color-primary-dark: #1a252f;
      --color-accent: #7b2cbf;
      --color-accent-light: #9d4edd;
      --color-text: #2d3748;
      --color-text-light: #4a5568;
      --color-bg: #ffffff;
      --color-bg-alt: #f7fafc;
      --color-border: #e2e8f0;
      --color-code-bg: #f8f9fa;
      --color-link: #3182ce;
      --color-link-hover: #2c5aa0;

      --spacing-xs: 0.5rem;
      --spacing-sm: 1rem;
      --spacing-md: 1.5rem;
      --spacing-lg: 2rem;
      --spacing-xl: 3rem;

      --font-body: -apple-system, BlinkMacSystemFont, "Segoe UI", "Hiragino Sans", "Hiragino Kaku Gothic ProN", Meiryo, sans-serif;
      --font-mono: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;

      --border-radius: 8px;
      --box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
    }

    * {
      margin: 0;
      padding: 0;
      box-sizing: border-box;
    }

    body {
      font-family: var(--font-body);
      line-height: 1.7;
      color: var(--color-text);
      background-color: var(--color-bg);
      font-size: 16px;
    }

    header {
      background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
      color: white;
      padding: var(--spacing-xl) var(--spacing-md);
      margin-bottom: var(--spacing-xl);
      box-shadow: var(--box-shadow);
    }

    .header-content {
      max-width: 900px;
      margin: 0 auto;
    }

    h1 {
      font-size: 2rem;
      font-weight: 700;
      margin-bottom: var(--spacing-sm);
      line-height: 1.2;
    }

    .subtitle {
      font-size: 1.1rem;
      opacity: 0.95;
      font-weight: 400;
      margin-bottom: var(--spacing-md);
    }

    .meta {
      display: flex;
      flex-wrap: wrap;
      gap: var(--spacing-md);
      font-size: 0.9rem;
      opacity: 0.9;
    }

    .meta-item {
      display: flex;
      align-items: center;
      gap: 0.3rem;
    }

    .container {
      max-width: 900px;
      margin: 0 auto;
      padding: 0 var(--spacing-md) var(--spacing-xl);
    }

    h2 {
      font-size: 1.75rem;
      color: var(--color-primary);
      margin-top: var(--spacing-xl);
      margin-bottom: var(--spacing-md);
      padding-bottom: var(--spacing-xs);
      border-bottom: 3px solid var(--color-accent);
    }

    h3 {
      font-size: 1.4rem;
      color: var(--color-primary);
      margin-top: var(--spacing-lg);
      margin-bottom: var(--spacing-sm);
    }

    h4 {
      font-size: 1.1rem;
      color: var(--color-primary-dark);
      margin-top: var(--spacing-md);
      margin-bottom: var(--spacing-sm);
    }

    p {
      margin-bottom: var(--spacing-md);
      color: var(--color-text);
    }

    a {
      color: var(--color-link);
      text-decoration: none;
      transition: color 0.2s;
    }

    a:hover {
      color: var(--color-link-hover);
      text-decoration: underline;
    }

    ul, ol {
      margin-left: var(--spacing-lg);
      margin-bottom: var(--spacing-md);
    }

    li {
      margin-bottom: var(--spacing-xs);
      color: var(--color-text);
    }

    pre {
      background-color: var(--color-code-bg);
      border: 1px solid var(--color-border);
      border-radius: var(--border-radius);
      padding: var(--spacing-md);
      overflow-x: auto;
      margin-bottom: var(--spacing-md);
      font-family: var(--font-mono);
      font-size: 0.9rem;
      line-height: 1.5;
    }

    code {
      font-family: var(--font-mono);
      font-size: 0.9em;
      background-color: var(--color-code-bg);
      padding: 0.2em 0.4em;
      border-radius: 3px;
    }

    pre code {
      background-color: transparent;
      padding: 0;
    }

    table {
      width: 100%;
      border-collapse: collapse;
      margin-bottom: var(--spacing-md);
      font-size: 0.95rem;
    }

    th, td {
      border: 1px solid var(--color-border);
      padding: var(--spacing-sm);
      text-align: left;
    }

    th {
      background-color: var(--color-bg-alt);
      font-weight: 600;
      color: var(--color-primary);
    }

    blockquote {
      border-left: 4px solid var(--color-accent);
      padding-left: var(--spacing-md);
      margin: var(--spacing-md) 0;
      color: var(--color-text-light);
      font-style: italic;
      background-color: var(--color-bg-alt);
      padding: var(--spacing-md);
      border-radius: var(--border-radius);
    }

    .mermaid {
      text-align: center;
      margin: var(--spacing-lg) 0;
      background-color: var(--color-bg-alt);
      padding: var(--spacing-md);
      border-radius: var(--border-radius);
    }

    details {
      background-color: var(--color-bg-alt);
      border: 1px solid var(--color-border);
      border-radius: var(--border-radius);
      padding: var(--spacing-md);
      margin-bottom: var(--spacing-md);
    }

    summary {
      cursor: pointer;
      font-weight: 600;
      color: var(--color-primary);
      user-select: none;
      padding: var(--spacing-xs);
      margin: calc(-1 * var(--spacing-md));
      padding: var(--spacing-md);
      border-radius: var(--border-radius);
    }

    summary:hover {
      background-color: rgba(123, 44, 191, 0.1);
    }

    details[open] summary {
      margin-bottom: var(--spacing-md);
      border-bottom: 1px solid var(--color-border);
    }

    .chapter-description {
      margin: 1.5rem 0;
      padding: 1rem;
      background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
      border-left: 4px solid #7b2cbf;
      border-radius: 8px;
      font-size: 1.05rem;
      line-height: 1.8;
      color: #2d3748;
    }

    .learning-objectives {
      background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
      padding: var(--spacing-lg);
      border-radius: var(--border-radius);
      border-left: 4px solid var(--color-accent);
      margin-bottom: var(--spacing-xl);
    }

    .learning-objectives h2 {
      margin-top: 0;
      border-bottom: none;
    }

    .navigation {
      display: flex;
      justify-content: space-between;
      gap: var(--spacing-md);
      margin: var(--spacing-xl) 0;
      padding-top: var(--spacing-lg);
      border-top: 2px solid var(--color-border);
    }

    .nav-button {
      flex: 1;
      padding: var(--spacing-md);
      background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
      color: white;
      border-radius: var(--border-radius);
      text-align: center;
      font-weight: 600;
      transition: transform 0.2s, box-shadow 0.2s;
      box-shadow: var(--box-shadow);
    }

    .nav-button:hover {
      transform: translateY(-2px);
      box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
      text-decoration: none;
    }

    .nav-button.disabled {
      opacity: 0.5;
      cursor: not-allowed;
      background: #6c757d;
    }

    .nav-button.disabled:hover {
      transform: none;
      box-shadow: var(--box-shadow);
    }

    footer {
      margin-top: var(--spacing-xl);
      padding: var(--spacing-lg) var(--spacing-md);
      background-color: var(--color-bg-alt);
      border-top: 1px solid var(--color-border);
      text-align: center;
      font-size: 0.9rem;
      color: var(--color-text-light);
    }

    .disclaimer {
      max-width: 900px;
      margin: 2rem auto;
      padding: 1.5rem;
      background: #f8f9fa;
      border-left: 4px solid #6c757d;
      border-radius: 4px;
    }

    .disclaimer h3 {
      color: #495057;
      margin-bottom: 1rem;
      font-size: 1.1rem;
    }

    .disclaimer ul {
      list-style: none;
      padding-left: 0;
    }

    .disclaimer li {
      padding: 0.5rem 0;
      padding-left: 1.5rem;
      position: relative;
      font-size: 0.9rem;
      color: #6c757d;
      line-height: 1.6;
    }

    .disclaimer li::before {
      content: "‚ö†Ô∏è";
      position: absolute;
      left: 0;
    }

    /* Breadcrumb styles */
    .breadcrumb {
      background: #f7fafc;
      padding: 0.75rem 1rem;
      border-bottom: 1px solid #e2e8f0;
      font-size: 0.9rem;
    }

    .breadcrumb-content {
      max-width: 900px;
      margin: 0 auto;
      display: flex;
      align-items: center;
      flex-wrap: wrap;
      gap: 0.5rem;
    }

    .breadcrumb a {
      color: #667eea;
      text-decoration: none;
      transition: color 0.2s;
    }

    .breadcrumb a:hover {
      color: #764ba2;
      text-decoration: underline;
    }

    .breadcrumb-separator {
      color: #a0aec0;
      margin: 0 0.25rem;
    }

    .breadcrumb-current {
      color: #4a5568;
      font-weight: 500;
    }

    .info-box {
      background: #e3f2fd;
      border-left: 4px solid #2196f3;
      padding: var(--spacing-md);
      margin: var(--spacing-md) 0;
      border-radius: var(--border-radius);
    }

    .warning-box {
      background: #fff3e0;
      border-left: 4px solid #ff9800;
      padding: var(--spacing-md);
      margin: var(--spacing-md) 0;
      border-radius: var(--border-radius);
    }

    .success-box {
      background: #e8f5e9;
      border-left: 4px solid #4caf50;
      padding: var(--spacing-md);
      margin: var(--spacing-md) 0;
      border-radius: var(--border-radius);
    }

    /* Responsive */
    @media (max-width: 768px) {
      .container {
        padding: 0 1rem 2rem;
      }

      h1 {
        font-size: 1.6rem;
      }

      h2 {
        font-size: 1.4rem;
      }

      .navigation {
        flex-direction: column;
      }
    }
  </style>

  <!-- Mermaid for diagrams -->
  <script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
  <!-- Prism.js for syntax highlighting -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
  <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
  <!-- MathJax for equations -->
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

  <script>
    // Mermaid.js initialization
    document.addEventListener('DOMContentLoaded', function() {
      if (typeof mermaid !== 'undefined') {
        mermaid.initialize({ startOnLoad: true, theme: 'default' });
      }
    });
  </script>
</head>
<body>
  <nav class="breadcrumb">
    <div class="breadcrumb-content">
      <a href="../../index.html">AI Terakoya Home</a><span class="breadcrumb-separator">‚Ä∫</span><a href="../index.html">Machine Learning</a><span class="breadcrumb-separator">‚Ä∫</span><a href="./index.html">PyTorch Geometric Introduction</a><span class="breadcrumb-separator">‚Ä∫</span><span class="breadcrumb-current">Chapter 1</span>
    </div>
  </nav>

  <header>
    <div class="header-content">
      <h1>Chapter 1: PyTorch Geometric Introduction and Graph Data Fundamentals</h1>
      <p class="subtitle">First Steps with Graph-Structured Data and GNN</p>
      <div class="meta">
        <span class="meta-item">üìñ Reading Time: 30-35 min</span>
        <span class="meta-item">üìä Difficulty: Intermediate</span>
        <span class="meta-item">üíª Code Examples: 12</span>
        <span class="meta-item">üìù Exercises: 5</span>
      </div>
    </div>
  </header>

  <main class="container">
    <div class="chapter-description">
      <p>In this chapter, you'll learn the fundamental concepts of graph data that underpin Graph Neural Networks (GNN) and how to use the PyTorch Geometric (PyG) library. Through the basic graph structure, PyG installation, working with Data objects, built-in datasets, and implementing a simple GCN layer, you'll build a solid foundation for GNN development.</p>
    </div>

    <div class="learning-objectives">
      <h2>Learning Objectives</h2>
      <ul>
        <li>‚úÖ Understand basic graph data concepts (nodes, edges, adjacency matrices)</li>
        <li>‚úÖ Install PyTorch Geometric and verify it works</li>
        <li>‚úÖ Create and manipulate PyG Data objects</li>
        <li>‚úÖ Load and explore built-in datasets</li>
        <li>‚úÖ Implement node classification with a simple GCN layer</li>
      </ul>
    </div>

    <h2 id="graph-basics">1. Graph Data Fundamentals</h2>

    <p>A <strong>Graph</strong> is a data structure composed of nodes (vertices) and edges (links). Many complex relationships in the real world can be represented as graphs.</p>

    <h3>Basic Graph Elements</h3>

    <ul>
      <li><strong>Node (Node/Vertex)</strong>: Points representing elements in a graph. Examples: people, molecular atoms, papers</li>
      <li><strong>Edge (Edge/Link)</strong>: Lines representing relationships between nodes. Examples: friendships, chemical bonds, citation relationships</li>
      <li><strong>Features</strong>: Attribute information associated with nodes or edges</li>
    </ul>

    <div class="mermaid">
graph LR
  A[Node A] -->|Edge| B[Node B]
  B --> C[Node C]
  A --> C
  C --> D[Node D]
  B --> D
    </div>

    <h3>Types of Graphs</h3>

    <table>
      <thead>
        <tr>
          <th>Category</th>
          <th>Type</th>
          <th>Description</th>
          <th>Examples</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>Directionality</td>
          <td>Directed Graph</td>
          <td>Edges have direction</td>
          <td>Twitter follow relationships, citation networks</td>
        </tr>
        <tr>
          <td></td>
          <td>Undirected Graph</td>
          <td>Edges have no direction</td>
          <td>Facebook friendships, molecular structures</td>
        </tr>
        <tr>
          <td>Node Types</td>
          <td>Homogeneous Graph</td>
          <td>Single type of node</td>
          <td>Social networks (people only)</td>
        </tr>
        <tr>
          <td></td>
          <td>Heterogeneous Graph</td>
          <td>Multiple types of nodes</td>
          <td>Recommendation graphs with users and products</td>
        </tr>
        <tr>
          <td>Weight</td>
          <td>Weighted Graph</td>
          <td>Edges have weights (strength)</td>
          <td>Road networks (distance), similarity graphs</td>
        </tr>
      </tbody>
    </table>

    <h3>Graph Representation Methods</h3>

    <p>Main methods for representing graphs in computers:</p>

    <h4>1. Adjacency Matrix</h4>

    <p>With \(N\) nodes, represented as an \(N \times N\) matrix \(A\):</p>
    <p>$$A_{ij} = \begin{cases} 1 & \text{if there is an edge from node } i \text{ to } j \\ 0 & \text{otherwise} \end{cases}$$</p>

    <pre><code class="language-python">import numpy as np

# Adjacency matrix for a 4-node graph
# Edges: 0‚Üí1, 1‚Üí2, 0‚Üí2, 2‚Üí3, 1‚Üí3
adjacency_matrix = np.array([
    [0, 1, 1, 0],  # Connections from node 0
    [0, 0, 1, 1],  # Connections from node 1
    [0, 0, 0, 1],  # Connections from node 2
    [0, 0, 0, 0]   # Connections from node 3
])

print("Adjacency Matrix:\n", adjacency_matrix)
</code></pre>

    <h4>2. Edge Index</h4>

    <p>An efficient representation method used in PyTorch Geometric. Suitable for sparse graphs.</p>

    <pre><code class="language-python">import torch

# Same graph represented as edge index
# Shape: [2, num_edges]
# Row 0: source nodes, Row 1: target nodes
edge_index = torch.tensor([
    [0, 1, 0, 2, 1],  # Source nodes
    [1, 2, 2, 3, 3]   # Target nodes
], dtype=torch.long)

print("Edge Index:\n", edge_index)
</code></pre>

    <div class="info-box">
      <p><strong>üí° Why Edge Index?</strong></p>
      <p>The adjacency matrix requires \(O(N^2)\) memory, but real-world graphs are often sparse, so edge index only requires \(O(E)\) (where \(E\) is the number of edges). For example, for a graph with 10,000 nodes and average degree 10, the adjacency matrix requires 100MB, but edge index only needs about 800KB.</p>
    </div>

    <h2 id="installation">2. PyTorch Geometric Installation and Environment Setup</h2>

    <p><strong>PyTorch Geometric</strong> is a graph neural network library built on PyTorch.</p>

    <h3>Installation Methods</h3>

    <p>PyTorch Geometric depends on the PyTorch and CUDA versions. First, check your environment.</p>

    <pre><code class="language-python">import torch
print(f"PyTorch version: {torch.__version__}")
print(f"CUDA available: {torch.cuda.is_available()}")
if torch.cuda.is_available():
    print(f"CUDA version: {torch.version.cuda}")
</code></pre>

    <h4>Method 1: Installation via pip (Recommended)</h4>

    <pre><code class="language-bash"># For PyTorch 2.0+ (CPU version)
pip install torch-geometric

# Additional dependencies
pip install pyg-lib torch-scatter torch-sparse torch-cluster torch-spline-conv -f https://data.pyg.org/whl/torch-2.1.0+cpu.html

# GPU version (for CUDA 11.8)
pip install torch-geometric
pip install pyg-lib torch-scatter torch-sparse torch-cluster torch-spline-conv -f https://data.pyg.org/whl/torch-2.1.0+cu118.html
</code></pre>

    <h4>Method 2: Installation via conda</h4>

    <pre><code class="language-bash"># For conda
conda install pyg -c pyg
</code></pre>

    <h4>Method 3: Google Colab (No Environment Setup Required)</h4>

    <p>In Google Colab, you can easily install with the following commands:</p>

    <pre><code class="language-python">!pip install torch-geometric
!pip install pyg-lib torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-2.1.0+cu118.html
</code></pre>

    <h3>Installation Verification</h3>

    <pre><code class="language-python">import torch
import torch_geometric

print(f"PyTorch version: {torch.__version__}")
print(f"PyTorch Geometric version: {torch_geometric.__version__}")

# Verify with sample data
from torch_geometric.data import Data

edge_index = torch.tensor([[0, 1, 1, 2],
                           [1, 0, 2, 1]], dtype=torch.long)
x = torch.tensor([[-1], [0], [1]], dtype=torch.float)
data = Data(x=x, edge_index=edge_index)

print(f"\nSample Data object created successfully!")
print(f"Number of nodes: {data.num_nodes}")
print(f"Number of edges: {data.num_edges}")
</code></pre>

    <p><strong>Sample Output:</strong></p>

    <pre><code>PyTorch version: 2.1.0
PyTorch Geometric version: 2.4.0

Sample Data object created successfully!
Number of nodes: 3
Number of edges: 4
</code></pre>

    <h2 id="data-object">3. PyG Data Object</h2>

    <p>The central data structure in PyTorch Geometric is the <strong>Data object</strong>. It efficiently stores graph structure and features.</p>

    <h3>Data Object Structure</h3>

    <table>
      <thead>
        <tr>
          <th>Attribute</th>
          <th>Shape</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td><code>x</code></td>
          <td>[num_nodes, num_features]</td>
          <td>Node feature matrix</td>
        </tr>
        <tr>
          <td><code>edge_index</code></td>
          <td>[2, num_edges]</td>
          <td>Edge connectivity information (COO format)</td>
        </tr>
        <tr>
          <td><code>edge_attr</code></td>
          <td>[num_edges, num_edge_features]</td>
          <td>Edge feature matrix (optional)</td>
        </tr>
        <tr>
          <td><code>y</code></td>
          <td>Arbitrary</td>
          <td>Target labels (node or graph)</td>
        </tr>
        <tr>
          <td><code>pos</code></td>
          <td>[num_nodes, num_dimensions]</td>
          <td>Node position coordinates (optional)</td>
        </tr>
      </tbody>
    </table>

    <h3>Creating Data Objects</h3>

    <pre><code class="language-python">import torch
from torch_geometric.data import Data

# Node features (3 nodes, each with 2-dimensional features)
x = torch.tensor([[1.0, 2.0],
                  [3.0, 4.0],
                  [5.0, 6.0]], dtype=torch.float)

# Edge index (4 edges)
# 0‚Üí1, 1‚Üí0, 1‚Üí2, 2‚Üí1
edge_index = torch.tensor([[0, 1, 1, 2],
                           [1, 0, 2, 1]], dtype=torch.long)

# Edge features (each edge has 1-dimensional features)
edge_attr = torch.tensor([[1.0], [1.0], [2.0], [2.0]], dtype=torch.float)

# Node labels (for node classification tasks)
y = torch.tensor([0, 1, 0], dtype=torch.long)

# Create Data object
data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)

print(data)
print(f"\nNumber of nodes: {data.num_nodes}")
print(f"Number of edges: {data.num_edges}")
print(f"Number of features: {data.num_node_features}")
print(f"Has isolated nodes: {data.has_isolated_nodes()}")
print(f"Has self-loops: {data.has_self_loops()}")
print(f"Is undirected: {data.is_undirected()}")
</code></pre>

    <p><strong>Output:</strong></p>

    <pre><code>Data(x=[3, 2], edge_index=[2, 4], edge_attr=[4, 1], y=[3])

Number of nodes: 3
Number of edges: 4
Number of features: 2
Has isolated nodes: False
Has self-loops: False
Is undirected: True
</code></pre>

    <h3>Data Object Operations</h3>

    <pre><code class="language-python">import torch
from torch_geometric.data import Data

data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)

# Get features of a specific node
print("Node 0 features:", data.x[0])

# Get information of a specific edge
print("Edge 0:", data.edge_index[:, 0])
print("Edge 0 attribute:", data.edge_attr[0])

# Transfer data to GPU
if torch.cuda.is_available():
    data = data.to('cuda')
    print(f"Data moved to: {data.x.device}")

# Move back to CPU
data = data.to('cpu')

# Validate data
print(f"\nIs valid: {data.validate()}")
</code></pre>

    <h2 id="datasets">4. Basic Data Operations and Built-in Datasets</h2>

    <p>PyTorch Geometric provides many built-in datasets for research and learning.</p>

    <h3>Major Built-in Datasets</h3>

    <table>
      <thead>
        <tr>
          <th>Dataset</th>
          <th>Type</th>
          <th>Nodes</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>Cora</td>
          <td>Citation Network</td>
          <td>2,708</td>
          <td>Paper citation relationships, 7-class classification</td>
        </tr>
        <tr>
          <td>Citeseer</td>
          <td>Citation Network</td>
          <td>3,327</td>
          <td>Paper citation relationships, 6-class classification</td>
        </tr>
        <tr>
          <td>PubMed</td>
          <td>Citation Network</td>
          <td>19,717</td>
          <td>Medical paper citations, 3-class classification</td>
        </tr>
        <tr>
          <td>PPI</td>
          <td>Biological Network</td>
          <td>14,755</td>
          <td>Protein interactions, multi-label classification</td>
        </tr>
        <tr>
          <td>QM9</td>
          <td>Molecular Graph</td>
          <td>~130k molecules</td>
          <td>Molecular property prediction, regression tasks</td>
        </tr>
      </tbody>
    </table>

    <h3>Loading the Cora Dataset</h3>

    <pre><code class="language-python">from torch_geometric.datasets import Planetoid

# Download and load Cora dataset
dataset = Planetoid(root='/tmp/Cora', name='Cora')

print(f"Dataset: {dataset}")
print(f"Number of graphs: {len(dataset)}")
print(f"Number of features: {dataset.num_features}")
print(f"Number of classes: {dataset.num_classes}")

# First graph (Cora is a single graph)
data = dataset[0]

print(f"\nGraph structure:")
print(f"Number of nodes: {data.num_nodes}")
print(f"Number of edges: {data.num_edges}")
print(f"Average node degree: {data.num_edges / data.num_nodes:.2f}")
print(f"Training nodes: {data.train_mask.sum().item()}")
print(f"Validation nodes: {data.val_mask.sum().item()}")
print(f"Test nodes: {data.test_mask.sum().item()}")

# Check node features and labels
print(f"\nNode features shape: {data.x.shape}")
print(f"Node labels shape: {data.y.shape}")
print(f"First node features: {data.x[0][:10]}...")
print(f"First node label: {data.y[0].item()}")
</code></pre>

    <p><strong>Sample Output:</strong></p>

    <pre><code>Dataset: Cora()
Number of graphs: 1
Number of features: 1433
Number of classes: 7

Graph structure:
Number of nodes: 2708
Number of edges: 10556
Average node degree: 3.90
Training nodes: 140
Validation nodes: 500
Test nodes: 1000

Node features shape: torch.Size([2708, 1433])
Node labels shape: torch.Size([2708])
First node features: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])...
First node label: 3
</code></pre>

    <h3>Using DataLoader</h3>

    <p>For datasets with multiple graphs, use DataLoader for batch processing.</p>

    <pre><code class="language-python">from torch_geometric.datasets import TUDataset
from torch_geometric.loader import DataLoader

# ENZYMES dataset (protein graph classification)
dataset = TUDataset(root='/tmp/ENZYMES', name='ENZYMES')

print(f"Dataset: {dataset}")
print(f"Number of graphs: {len(dataset)}")
print(f"Number of classes: {dataset.num_classes}")
print(f"Number of features: {dataset.num_features}")

# Create DataLoader
loader = DataLoader(dataset, batch_size=32, shuffle=True)

# Check batch
for batch in loader:
    print(f"\nBatch:")
    print(f"Number of graphs in batch: {batch.num_graphs}")
    print(f"Total nodes in batch: {batch.num_nodes}")
    print(f"Total edges in batch: {batch.num_edges}")
    print(f"Batch shape: {batch.batch.shape}")
    break  # Display first batch only
</code></pre>

    <div class="info-box">
      <p><strong>üí° Batch Processing Mechanism</strong></p>
      <p>PyG's DataLoader combines multiple graphs into one large graph. Which graph each node belongs to is managed by the <code>batch</code> attribute. This allows efficient batch processing of graphs of different sizes.</p>
    </div>

    <h2 id="first-gnn">5. Simple GNN Implementation Example</h2>

    <p>Let's implement a node classification model using the most basic graph neural network layer, <strong>GCNConv (Graph Convolutional Network)</strong>.</p>

    <h3>Basic Principles of GCN</h3>

    <p>GCN updates each node's features by aggregating features from neighboring nodes:</p>
    <p>$$\mathbf{x}_i^{(k+1)} = \sigma\left(\sum_{j \in \mathcal{N}(i) \cup \{i\}} \frac{1}{\sqrt{d_i d_j}} \mathbf{W}^{(k)} \mathbf{x}_j^{(k)}\right)$$</p>

    <p>Where:</p>
    <ul>
      <li>\(\mathbf{x}_i^{(k)}\): Features of node \(i\) at layer \(k\)</li>
      <li>\(\mathcal{N}(i)\): Set of neighbors of node \(i\)</li>
      <li>\(d_i\): Degree of node \(i\)</li>
      <li>\(\mathbf{W}^{(k)}\): Learnable weight matrix</li>
      <li>\(\sigma\): Activation function (ReLU, etc.)</li>
    </ul>

    <div class="mermaid">
graph LR
  A[Node A<br/>Features] --> AGG[Aggregate]
  B[Neighbor B<br/>Features] --> AGG
  C[Neighbor C<br/>Features] --> AGG
  AGG --> UPDATE[Update]
  UPDATE --> A2[New Features]
    </div>

    <h3>GCN Model Implementation</h3>

    <pre><code class="language-python">import torch
import torch.nn.functional as F
from torch_geometric.nn import GCNConv

class GCN(torch.nn.Module):
    def __init__(self, num_features, num_classes):
        super(GCN, self).__init__()
        # 2-layer GCN
        self.conv1 = GCNConv(num_features, 16)
        self.conv2 = GCNConv(16, num_classes)

    def forward(self, data):
        x, edge_index = data.x, data.edge_index

        # Layer 1: input ‚Üí 16 dimensions
        x = self.conv1(x, edge_index)
        x = F.relu(x)
        x = F.dropout(x, p=0.5, training=self.training)

        # Layer 2: 16 dimensions ‚Üí number of classes
        x = self.conv2(x, edge_index)

        return F.log_softmax(x, dim=1)

# Create model
from torch_geometric.datasets import Planetoid

dataset = Planetoid(root='/tmp/Cora', name='Cora')
data = dataset[0]

model = GCN(num_features=dataset.num_features,
            num_classes=dataset.num_classes)

print(model)
print(f"\nTotal parameters: {sum(p.numel() for p in model.parameters())}")
</code></pre>

    <h3>Training Loop Implementation</h3>

    <pre><code class="language-python">import torch
import torch.nn.functional as F
from torch_geometric.datasets import Planetoid

# Prepare data and model
dataset = Planetoid(root='/tmp/Cora', name='Cora')
data = dataset[0]

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = GCN(num_features=dataset.num_features,
            num_classes=dataset.num_classes).to(device)
data = data.to(device)

# Optimizer
optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)

# Training loop
model.train()
for epoch in range(200):
    optimizer.zero_grad()

    # Forward pass
    out = model(data)

    # Compute loss (training data only)
    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])

    # Backward pass
    loss.backward()
    optimizer.step()

    # Display results every 10 epochs
    if (epoch + 1) % 10 == 0:
        model.eval()
        _, pred = model(data).max(dim=1)
        correct = pred[data.train_mask].eq(data.y[data.train_mask]).sum().item()
        accuracy = correct / data.train_mask.sum().item()
        print(f'Epoch {epoch+1:03d}, Loss: {loss:.4f}, Train Acc: {accuracy:.4f}')
        model.train()
</code></pre>

    <h3>Model Evaluation</h3>

    <pre><code class="language-python">def test(model, data):
    model.eval()
    with torch.no_grad():
        out = model(data)
        _, pred = out.max(dim=1)

        # Training data accuracy
        correct = pred[data.train_mask].eq(data.y[data.train_mask]).sum().item()
        train_acc = correct / data.train_mask.sum().item()

        # Validation data accuracy
        correct = pred[data.val_mask].eq(data.y[data.val_mask]).sum().item()
        val_acc = correct / data.val_mask.sum().item()

        # Test data accuracy
        correct = pred[data.test_mask].eq(data.y[data.test_mask]).sum().item()
        test_acc = correct / data.test_mask.sum().item()

    return train_acc, val_acc, test_acc

train_acc, val_acc, test_acc = test(model, data)
print(f'\nFinal Results:')
print(f'Train Accuracy: {train_acc:.4f}')
print(f'Validation Accuracy: {val_acc:.4f}')
print(f'Test Accuracy: {test_acc:.4f}')
</code></pre>

    <p><strong>Sample Output:</strong></p>

    <pre><code>Epoch 010, Loss: 1.9234, Train Acc: 0.3143
Epoch 020, Loss: 1.7845, Train Acc: 0.4357
Epoch 030, Loss: 1.5234, Train Acc: 0.6000
...
Epoch 200, Loss: 0.5123, Train Acc: 0.9714

Final Results:
Train Accuracy: 0.9714
Validation Accuracy: 0.7540
Test Accuracy: 0.8130
</code></pre>

    <div class="success-box">
      <p><strong>üéâ First GNN Implementation Complete!</strong></p>
      <p>We achieved 81% test accuracy on the Cora dataset. This is a significant improvement over MLP models that don't consider graph structure (around 60%). GNNs achieve higher accuracy by learning relationships between nodes.</p>
    </div>

    <h2 id="exercises">Exercises</h2>

    <details>
      <summary><strong>Exercise 1: Creating Custom Graphs</strong></summary>
      <p>Create a graph with the following conditions:</p>
      <ol>
        <li>5 nodes (each node with 3-dimensional features)</li>
        <li>Undirected graph (bidirectional edges)</li>
        <li>Edges: 0-1, 1-2, 2-3, 3-4, 4-0</li>
        <li>Assign random labels (0, 1, or 2) to each node</li>
      </ol>
      <pre><code class="language-python"># Write your code here
</code></pre>
    </details>

    <details>
      <summary><strong>Exercise 2: Dataset Exploration</strong></summary>
      <p>Load the Citeseer dataset and output the following information:</p>
      <ul>
        <li>Number of nodes, number of edges</li>
        <li>Average node degree</li>
        <li>Number of feature dimensions</li>
        <li>Number of classes</li>
        <li>Number of training/validation/test nodes</li>
      </ul>
    </details>

    <details>
      <summary><strong>Exercise 3: 3-Layer GCN Implementation</strong></summary>
      <p>Extend the 2-layer GCN to implement a 3-layer GCN model. Set the intermediate layer dimensions to 32 and 16. Train on the Cora dataset and compare accuracy.</p>
      <p>Hint: Adding more layers can make overfitting easier, so you may need to adjust Dropout.</p>
    </details>

    <details>
      <summary><strong>Exercise 4: Using Edge Features</strong></summary>
      <p>Create a graph with weighted edges (features) and set the <code>edge_attr</code> attribute. Use random values (range 0.1-1.0) for edge weights.</p>
    </details>

    <details>
      <summary><strong>Exercise 5: Graph Visualization</strong></summary>
      <p>Use NetworkX and Matplotlib to visualize the created graph. Display nodes with different colors based on labels.</p>
      <pre><code class="language-python">import networkx as nx
import matplotlib.pyplot as plt
from torch_geometric.utils import to_networkx

# Convert PyG Data object to NetworkX graph
# Write your code here
</code></pre>
    </details>

    <h2 id="summary">Summary</h2>

    <p>In this chapter, we learned the fundamentals of graph neural networks:</p>

    <ul>
      <li>‚úÖ Basic graph data concepts (nodes, edges, adjacency matrices, edge indices)</li>
      <li>‚úÖ PyTorch Geometric installation and environment setup</li>
      <li>‚úÖ Data object structure and operation methods</li>
      <li>‚úÖ How to use built-in datasets (Cora, ENZYMES, etc.)</li>
      <li>‚úÖ Node classification implementation with GCNConv layers</li>
    </ul>

    <div class="success-box">
      <p><strong>üéâ Next Steps</strong></p>
      <p>In the next chapter, you'll learn in detail about the message passing mechanism of Graph Convolutional Networks (GCN) and fully understand node classification tasks. You'll also learn practical overfitting prevention and hyperparameter tuning techniques.</p>
    </div>

    <div class="navigation">
      <a href="./index.html" class="nav-button">‚Üê Series Overview</a>
      <span class="nav-button disabled">Chapter 2: Graph Convolutional Networks (Coming Soon) ‚Üí</span>
    </div>

    <hr style="margin: 2rem 0;">

    <p><strong>Reference Resources</strong></p>
    <ul>
      <li><a href="https://pytorch-geometric.readthedocs.io/" target="_blank">PyTorch Geometric Official Documentation</a></li>
      <li><a href="https://github.com/pyg-team/pytorch_geometric" target="_blank">PyTorch Geometric GitHub</a></li>
      <li><a href="https://arxiv.org/abs/1609.02907" target="_blank">GCN Paper: Semi-Supervised Classification with Graph Convolutional Networks</a></li>
    </ul>

  </main>

  <section class="disclaimer">
    <h3>Disclaimer</h3>
    <ul>
      <li>This content is provided for educational, research, and informational purposes only, and does not constitute professional advice (legal, accounting, technical guarantees, etc.).</li>
      <li>This content and accompanying code examples are provided "AS IS" without any warranties, express or implied, including but not limited to merchantability, fitness for a particular purpose, non-infringement, accuracy, completeness, operation, or safety.</li>
      <li>The creator and Tohoku University assume no responsibility for the content, availability, or safety of external links, third-party data, tools, libraries, etc.</li>
      <li>To the maximum extent permitted by applicable law, the creator and Tohoku University shall not be liable for any direct, indirect, incidental, special, consequential, or punitive damages arising from the use, execution, or interpretation of this content.</li>
      <li>The content of this material is subject to change, update, or discontinuation without notice.</li>
      <li>The copyright and license of this content follow the specified conditions (e.g., CC BY 4.0). Such licenses typically include warranty disclaimers.</li>
    </ul>
  </section>

  <footer>
    <div class="container">
      <p>&copy; 2025 AI Terakoya - Dr. Yusuke Hashimoto, Tohoku University</p>
      <p>Licensed under CC BY 4.0</p>
    </div>
  </footer>
</body>
</html>
