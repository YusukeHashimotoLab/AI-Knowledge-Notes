<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Chapter 3: GAN (Generative Adversarial Networks) - AI Terakoya</title>

    <style>
        :root {
            --color-primary: #2c3e50;
            --color-primary-dark: #1a252f;
            --color-accent: #7b2cbf;
            --color-accent-light: #9d4edd;
            --color-text: #2d3748;
            --color-text-light: #4a5568;
            --color-bg: #ffffff;
            --color-bg-alt: #f7fafc;
            --color-border: #e2e8f0;
            --color-code-bg: #f8f9fa;
            --color-link: #3182ce;
            --color-link-hover: #2c5aa0;
            --spacing-xs: 0.5rem;
            --spacing-sm: 1rem;
            --spacing-md: 1.5rem;
            --spacing-lg: 2rem;
            --spacing-xl: 3rem;
            --font-body: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            --font-mono: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;
            --border-radius: 8px;
            --box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body { font-family: var(--font-body); line-height: 1.7; color: var(--color-text); background-color: var(--color-bg); font-size: 16px; }
        header { background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%); color: white; padding: var(--spacing-xl) var(--spacing-md); margin-bottom: var(--spacing-xl); box-shadow: var(--box-shadow); }
        .header-content { max-width: 900px; margin: 0 auto; }
        h1 { font-size: 2rem; font-weight: 700; margin-bottom: var(--spacing-sm); line-height: 1.2; }
        .subtitle { font-size: 1.1rem; opacity: 0.95; font-weight: 400; margin-bottom: var(--spacing-md); }
        .meta { display: flex; flex-wrap: wrap; gap: var(--spacing-md); font-size: 0.9rem; opacity: 0.9; }
        .meta-item { display: flex; align-items: center; gap: 0.3rem; }
        .container { max-width: 900px; margin: 0 auto; padding: 0 var(--spacing-md) var(--spacing-xl); }
        h2 { font-size: 1.75rem; color: var(--color-primary); margin-top: var(--spacing-xl); margin-bottom: var(--spacing-md); padding-bottom: var(--spacing-xs); border-bottom: 3px solid var(--color-accent); }
        h3 { font-size: 1.4rem; color: var(--color-primary); margin-top: var(--spacing-lg); margin-bottom: var(--spacing-sm); }
        h4 { font-size: 1.1rem; color: var(--color-primary-dark); margin-top: var(--spacing-md); margin-bottom: var(--spacing-sm); }
        p { margin-bottom: var(--spacing-md); color: var(--color-text); }
        a { color: var(--color-link); text-decoration: none; transition: color 0.2s; }
        a:hover { color: var(--color-link-hover); text-decoration: underline; }
        ul, ol { margin-left: var(--spacing-lg); margin-bottom: var(--spacing-md); }
        li { margin-bottom: var(--spacing-xs); color: var(--color-text); }
        pre { background-color: var(--color-code-bg); border: 1px solid var(--color-border); border-radius: var(--border-radius); padding: var(--spacing-md); overflow-x: auto; margin-bottom: var(--spacing-md); font-family: var(--font-mono); font-size: 0.9rem; line-height: 1.5; }
        code { font-family: var(--font-mono); font-size: 0.9em; background-color: var(--color-code-bg); padding: 0.2em 0.4em; border-radius: 3px; }
        pre code { background-color: transparent; padding: 0; }
        table { width: 100%; border-collapse: collapse; margin-bottom: var(--spacing-md); font-size: 0.95rem; }
        th, td { border: 1px solid var(--color-border); padding: var(--spacing-sm); text-align: left; }
        th { background-color: var(--color-bg-alt); font-weight: 600; color: var(--color-primary); }
        blockquote { border-left: 4px solid var(--color-accent); padding-left: var(--spacing-md); margin: var(--spacing-md) 0; color: var(--color-text-light); font-style: italic; background-color: var(--color-bg-alt); padding: var(--spacing-md); border-radius: var(--border-radius); }
        .mermaid { text-align: center; margin: var(--spacing-lg) 0; background-color: var(--color-bg-alt); padding: var(--spacing-md); border-radius: var(--border-radius); }
        details { background-color: var(--color-bg-alt); border: 1px solid var(--color-border); border-radius: var(--border-radius); padding: var(--spacing-md); margin-bottom: var(--spacing-md); }
        summary { cursor: pointer; font-weight: 600; color: var(--color-primary); user-select: none; padding: var(--spacing-xs); margin: calc(-1 * var(--spacing-md)); padding: var(--spacing-md); border-radius: var(--border-radius); }
        summary:hover { background-color: rgba(123, 44, 191, 0.1); }
        details[open] summary { margin-bottom: var(--spacing-md); border-bottom: 1px solid var(--color-border); }
        .navigation { display: flex; justify-content: space-between; gap: var(--spacing-md); margin: var(--spacing-xl) 0; padding-top: var(--spacing-lg); border-top: 2px solid var(--color-border); }
        .nav-button { flex: 1; padding: var(--spacing-md); background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%); color: white; border-radius: var(--border-radius); text-align: center; font-weight: 600; transition: transform 0.2s, box-shadow 0.2s; box-shadow: var(--box-shadow); }
        .nav-button:hover { transform: translateY(-2px); box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15); text-decoration: none; }
        footer { margin-top: var(--spacing-xl); padding: var(--spacing-lg) var(--spacing-md); background-color: var(--color-bg-alt); border-top: 1px solid var(--color-border); text-align: center; font-size: 0.9rem; color: var(--color-text-light); }
        .disclaimer {
            max-width: 900px;
            margin: 2rem auto;
            padding: 1.5rem;
            background: #f8f9fa;
            border-left: 4px solid #6c757d;
            border-radius: 4px;
        }

        .disclaimer h3 {
            color: #495057;
            margin-bottom: 1rem;
            font-size: 1.1rem;
        }

        .disclaimer ul {
            list-style: none;
            padding-left: 0;
        }

        .disclaimer li {
            padding: 0.5rem 0;
            padding-left: 1.5rem;
            position: relative;
            font-size: 0.9rem;
            color: #6c757d;
            line-height: 1.6;
        }

        .disclaimer li::before {
            content: "âš ï¸";
            position: absolute;
            left: 0;
        }

        @media (max-width: 768px) { h1 { font-size: 1.5rem; } h2 { font-size: 1.4rem; } h3 { font-size: 1.2rem; } .meta { font-size: 0.85rem; } .navigation { flex-direction: column; } table { font-size: 0.85rem; } th, td { padding: var(--spacing-xs); } }
    
        
    
        /* Breadcrumb styles */
        .breadcrumb {
            background: #f7fafc;
            padding: 0.75rem 1rem;
            border-bottom: 1px solid #e2e8f0;
            font-size: 0.9rem;
        }

        .breadcrumb-content {
            max-width: 900px;
            margin: 0 auto;
            display: flex;
            align-items: center;
            flex-wrap: wrap;
            gap: 0.5rem;
        }

        .breadcrumb a {
            color: #667eea;
            text-decoration: none;
            transition: color 0.2s;
        }

        .breadcrumb a:hover {
            color: #764ba2;
            text-decoration: underline;
        }

        .breadcrumb-separator {
            color: #a0aec0;
            margin: 0 0.25rem;
        }

        .breadcrumb-current {
            color: #4a5568;
            font-weight: 500;
        }
    </style>

    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
        mermaid.initialize({ startOnLoad: true, theme: 'default' });
    </script>
    <script>
        MathJax = {
            tex: { inlineMath: [['$', '$'], ['\\(', '\\)']], displayMath: [['$$', '$$'], ['\\[', '\\]']], processEscapes: true, processEnvironments: true },
            options: { skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'], ignoreHtmlClass: 'mermaid' }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" async></script>
</head>
<body>
            <nav class="breadcrumb">
        <div class="breadcrumb-content">
            <a href="../../index.html">AI Terakoya Top</a><span class="breadcrumb-separator">â€º</span><a href="../../ML/index.html">Machine Learning</a><span class="breadcrumb-separator">â€º</span><a href="../../ML/generative-models-introduction/index.html">Generative Models</a><span class="breadcrumb-separator">â€º</span><span class="breadcrumb-current">Chapter 3</span>
        </div>
    </nav>

        <header>
        <div class="header-content">
            <h1>Chapter 3: GAN (Generative Adversarial Networks)</h1>
            <p class="subtitle">æ•µå¯¾çš„å­¦ç¿’ã§ç¾å®Ÿçš„ãªç”»åƒã‚’ç”Ÿæˆ - Vanilla GANã‹ã‚‰StyleGANã¾ã§</p>
            <div class="meta">
                <span class="meta-item">ğŸ“– Reading Time: 30-35 minutes</span>
                <span class="meta-item">ğŸ“Š Difficulty: Intermediate to Advanced</span>
                <span class="meta-item">ğŸ’» Code Examples: 8</span>
                <span class="meta-item">ğŸ“ Exercises: 5å•</span>
            </div>
        </div>
    </header>

    <main class="container">

<h2>Learning Objectives</h2>
<p>ã“ã® ChapterReadã“ã¨ã§ã€ä»¥ä¸‹ã‚’ç¿’å¾—ã§ãã¾ã™ï¼š</p>
<ul>
<li>âœ… GANã®åŸºæœ¬æ¦‚å¿µã¨Generatorã¨Discriminatorã®å½¹å‰²ã‚’ç†è§£ã™ã‚‹</li>
<li>âœ… Minimax gameã®ç†è«–çš„èƒŒæ™¯ã¨Nashå‡è¡¡ã‚’ç†è§£ã™ã‚‹</li>
<li>âœ… Mode collapseå•é¡Œã¨ãã®å¯¾ç­–ã‚’ç¿’å¾—ã™ã‚‹</li>
<li>âœ… DCGANï¼ˆDeep Convolutional GANï¼‰ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’å®Ÿè£…ã§ãã‚‹</li>
<li>âœ… WGAN-GPï¼ˆWasserstein GAN with Gradient Penaltyï¼‰ã‚’ç†è§£ã™ã‚‹</li>
<li>âœ… Spectral Normalizationã¨Label Smoothingã®è¨“ç·´ãƒ†ã‚¯ãƒ‹ãƒƒã‚¯ã‚’ç¿’å¾—ã™ã‚‹</li>
<li>âœ… StyleGANã®åŸºæœ¬æ¦‚å¿µã¨ç‰¹å¾´ã‚’ç†è§£ã™ã‚‹</li>
<li>âœ… å®Ÿéš›ã®ç”»åƒç”Ÿæˆãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’å®Ÿè£…ã§ãã‚‹</li>
</ul>

<hr>

<h2>3.1 GANã®åŸºæœ¬æ¦‚å¿µ</h2>

<h3>Generatorã¨ã¯</h3>

<p><strong>Generatorï¼ˆç”Ÿæˆå™¨ï¼‰</strong>ã¯ã€ãƒ©ãƒ³ãƒ€ãƒ ãƒã‚¤ã‚ºï¼ˆæ½œåœ¨å¤‰æ•°ï¼‰ã‹ã‚‰ç¾å®Ÿçš„ãªãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã™ã‚‹ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã§ã™ã€‚</p>

<blockquote>
<p>ã€ŒGeneratorã¯ã€ãƒ©ãƒ³ãƒ€ãƒ ãªæ½œåœ¨ãƒ™ã‚¯ãƒˆãƒ« $\mathbf{z} \sim p_z(\mathbf{z})$ ã‚’å…¥åŠ›ã¨ã—ã¦å—ã‘å–ã‚Šã€è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨è¦‹ minutesã‘ãŒã¤ã‹ãªã„å½ãƒ‡ãƒ¼ã‚¿ $G(\mathbf{z})$ ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ã‚’å­¦ç¿’ã™ã‚‹ã€</p>
</blockquote>

<div class="mermaid">
graph LR
    A[æ½œåœ¨ãƒ™ã‚¯ãƒˆãƒ« z<br/>100æ¬¡å…ƒãƒã‚¤ã‚º] --> B[Generator G]
    B --> C[ç”Ÿæˆç”»åƒ<br/>28Ã—28Ã—1]

    D[ãƒ©ãƒ³ãƒ€ãƒ <br/>ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°] --> A

    style A fill:#e3f2fd
    style B fill:#fff3e0
    style C fill:#e8f5e9
</div>

<h3>Discriminatorã¨ã¯</h3>

<p><strong>Discriminatorï¼ˆè­˜åˆ¥å™¨ï¼‰</strong>ã¯ã€å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ãŒæœ¬ç‰©ï¼ˆè¨“ç·´ãƒ‡ãƒ¼ã‚¿ï¼‰ã‹å½ç‰©ï¼ˆGeneratorã®å‡ºåŠ›ï¼‰ã‹ã‚’åˆ¤å®šã™ã‚‹äºŒå€¤ classificationå™¨ã§ã™ã€‚</p>

<div class="mermaid">
graph TB
    A1[æœ¬ç‰©ç”»åƒ] --> D[Discriminator D]
    A2[ç”Ÿæˆç”»åƒ] --> D

    D --> O1[æœ¬ç‰©: 1.0<br/>ã‚¹ã‚³ã‚¢]
    D --> O2[å½ç‰©: 0.0<br/>ã‚¹ã‚³ã‚¢]

    style A1 fill:#e8f5e9
    style A2 fill:#ffebee
    style D fill:#fff3e0
    style O1 fill:#e8f5e9
    style O2 fill:#ffebee
</div>

<h3>æ•µå¯¾çš„å­¦ç¿’ã®ãƒ¡ã‚«ãƒ‹ã‚ºãƒ </h3>

<p>GANã¯ã€Generatorã¨Discriminatorã®<strong>æ•µå¯¾çš„ãªç«¶äº‰</strong>ã‚’é€šã˜ã¦å­¦ç¿’ã—ã¾ã™ï¼š</p>

<div class="mermaid">
sequenceDiagram
    participant G as Generator
    participant D as Discriminator
    participant R as æœ¬ç‰©ãƒ‡ãƒ¼ã‚¿

    G->>G: ãƒã‚¤ã‚ºã‹ã‚‰ç”»åƒç”Ÿæˆ
    G->>D: ç”Ÿæˆç”»åƒã‚’æç¤º
    R->>D: æœ¬ç‰©ç”»åƒã‚’æç¤º
    D->>D: æœ¬ç‰©/å½ç‰©ã‚’è­˜åˆ¥
    D->>G: ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ï¼ˆå‹¾é…ï¼‰
    G->>G: ã‚ˆã‚Šé¨™ã—ã‚„ã™ã„ç”»åƒã¸æ”¹å–„
    D->>D: ã‚ˆã‚Šè¦‹ç ´ã‚Šã‚„ã™ãæ”¹å–„

    Note over G,D: ã“ã®ãƒ—ãƒ­ã‚»ã‚¹ã‚’ç¹°ã‚Šè¿”ã™
</div>

<h3>Minimax Gameç†è«–</h3>

<p>GANã®ç›®çš„é–¢æ•°ã¯<strong>Minimaxæœ€é©åŒ–</strong>ã¨ã—ã¦å®šå¼åŒ–ã•ã‚Œã¾ã™ï¼š</p>

<p>$$
\min_G \max_D V(D, G) = \mathbb{E}_{\mathbf{x} \sim p_{\text{data}}}[\log D(\mathbf{x})] + \mathbb{E}_{\mathbf{z} \sim p_z}[\log(1 - D(G(\mathbf{z})))]
$$</p>

<p>å„é …ã®æ„å‘³ï¼š</p>
<ul>
<li><strong>Chapter 1é …</strong> $\mathbb{E}_{\mathbf{x} \sim p_{\text{data}}}[\log D(\mathbf{x})]$ï¼šDiscriminatorãŒæœ¬ç‰©ã‚’æ­£ã—ãè­˜åˆ¥ã™ã‚‹èƒ½åŠ›</li>
<li><strong>Chapter 2é …</strong> $\mathbb{E}_{\mathbf{z} \sim p_z}[\log(1 - D(G(\mathbf{z})))]$ï¼šDiscriminatorãŒå½ç‰©ã‚’è¦‹ç ´ã‚‹èƒ½åŠ›</li>
</ul>

<table>
<thead>
<tr>
<th>ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯</th>
<th>ç›®æ¨™</th>
<th>æœ€é©åŒ–æ–¹å‘</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Discriminator (D)</strong></td>
<td>$V(D, G)$ ã‚’æœ€å¤§åŒ–</td>
<td>æœ¬ç‰©ã¨å½ç‰©ã‚’æ­£ç¢ºã«è­˜åˆ¥</td>
</tr>
<tr>
<td><strong>Generator (G)</strong></td>
<td>$V(D, G)$ ã‚’æœ€å°åŒ–</td>
<td>Discriminatorã‚’é¨™ã™ç”»åƒã‚’ç”Ÿæˆ</td>
</tr>
</tbody>
</table>

<h3>Nashå‡è¡¡ã¨ã¯</h3>

<p><strong>Nashå‡è¡¡</strong>ã¯ã€Generatorã¨DiscriminatorãŒäº’ã„ã«æœ€é©ãªæˆ¦ç•¥ã‚’å–ã‚Šã€ã©ã¡ã‚‰ã‚‚æˆ¦ç•¥ã‚’å¤‰æ›´ã™ã‚‹å‹•æ©ŸãŒãªã„çŠ¶æ…‹ã§ã™ã€‚</p>

<p>ç†è«–çš„ã«ã¯ã€Nashå‡è¡¡ã§ä»¥ä¸‹ãŒæˆç«‹ã—ã¾ã™ï¼š</p>
<ul>
<li>$D^*(\mathbf{x}) = \frac{p_{\text{data}}(\mathbf{x})}{p_{\text{data}}(\mathbf{x}) + p_g(\mathbf{x})} = 0.5$ï¼ˆè­˜åˆ¥å™¨ãŒåˆ¤æ–­ã§ããªã„ï¼‰</li>
<li>$p_g(\mathbf{x}) = p_{\text{data}}(\mathbf{x})$ï¼ˆç”Ÿæˆ minuteså¸ƒãŒçœŸã® minuteså¸ƒã¨ä¸€è‡´ï¼‰</li>
</ul>

<div class="mermaid">
graph LR
    subgraph åˆæœŸçŠ¶æ…‹
        I1[Generator<br/>ãƒ©ãƒ³ãƒ€ãƒ ç”»åƒ] --> I2[Discriminator<br/>ç°¡å˜ã«è­˜åˆ¥]
    end

    subgraph è¨“ç·´ä¸­
        M1[Generator<br/>æ”¹å–„ä¸­] --> M2[Discriminator<br/>ç²¾åº¦å‘ä¸Š]
    end

    subgraph Nashå‡è¡¡
        N1[Generator<br/>å®Œç’§ãªæ¨¡å€£] --> N2[Discriminator<br/>50%ã®ç²¾åº¦]
    end

    I2 --> M1
    M2 --> N1

    style I1 fill:#ffebee
    style M1 fill:#fff3e0
    style N1 fill:#e8f5e9
    style N2 fill:#e8f5e9
</div>

<hr>

<h2>3.2 GANã®å­¦ç¿’ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ </h2>

<h3>å®Ÿè£…ä¾‹1: Vanilla GANåŸºæœ¬æ§‹é€ </h3>

<pre><code class="language-python">import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np

# ãƒ‡ãƒã‚¤ã‚¹è¨­å®š
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹: {device}\n")

print("=== Vanilla GAN åŸºæœ¬æ§‹é€  ===\n")

# Generatorå®šç¾©
class Generator(nn.Module):
    def __init__(self, latent_dim=100, img_shape=(1, 28, 28)):
        super(Generator, self).__init__()
        self.img_shape = img_shape
        img_size = int(np.prod(img_shape))

        self.model = nn.Sequential(
            nn.Linear(latent_dim, 128),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Linear(128, 256),
            nn.BatchNorm1d(256),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Linear(256, 512),
            nn.BatchNorm1d(512),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Linear(512, img_size),
            nn.Tanh()  # [-1, 1]ã®ç¯„å›²ã«æ­£è¦åŒ–
        )

    def forward(self, z):
        img = self.model(z)
        img = img.view(img.size(0), *self.img_shape)
        return img

# Discriminatorå®šç¾©
class Discriminator(nn.Module):
    def __init__(self, img_shape=(1, 28, 28)):
        super(Discriminator, self).__init__()
        img_size = int(np.prod(img_shape))

        self.model = nn.Sequential(
            nn.Linear(img_size, 512),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Linear(512, 256),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Linear(256, 1),
            nn.Sigmoid()  # [0, 1]ã®ç¢ºç‡å‡ºåŠ›
        )

    def forward(self, img):
        img_flat = img.view(img.size(0), -1)
        validity = self.model(img_flat)
        return validity

# ãƒ¢ãƒ‡ãƒ«ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–
latent_dim = 100
img_shape = (1, 28, 28)

generator = Generator(latent_dim, img_shape).to(device)
discriminator = Discriminator(img_shape).to(device)

print("--- Generator ---")
print(generator)
print(f"\nGenerator ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {sum(p.numel() for p in generator.parameters()):,}")

print("\n--- Discriminator ---")
print(discriminator)
print(f"\nDiscriminator ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {sum(p.numel() for p in discriminator.parameters()):,}")

# ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
z = torch.randn(8, latent_dim).to(device)
fake_imgs = generator(z)
print(f"\nç”Ÿæˆç”»åƒå½¢çŠ¶: {fake_imgs.shape}")

validity = discriminator(fake_imgs)
print(f"Discriminatorå‡ºåŠ›å½¢çŠ¶: {validity.shape}")
print(f"Discriminatorã‚¹ã‚³ã‚¢ä¾‹: {validity[:3].detach().cpu().numpy().flatten()}")
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹: cuda

=== Vanilla GAN åŸºæœ¬æ§‹é€  ===

--- Generator ---
Generator(
  (model): Sequential(
    (0): Linear(in_features=100, out_features=128, bias=True)
    (1): LeakyReLU(negative_slope=0.2, inplace=True)
    (2): Linear(in_features=128, out_features=256, bias=True)
    (3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): LeakyReLU(negative_slope=0.2, inplace=True)
    (5): Linear(in_features=256, out_features=512, bias=True)
    (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): LeakyReLU(negative_slope=0.2, inplace=True)
    (8): Linear(in_features=512, out_features=784, bias=True)
    (9): Tanh()
  )
)

Generator ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: 533,136

--- Discriminator ---
Discriminator(
  (model): Sequential(
    (0): Linear(in_features=784, out_features=512, bias=True)
    (1): LeakyReLU(negative_slope=0.2, inplace=True)
    (2): Linear(in_features=512, out_features=256, bias=True)
    (3): LeakyReLU(negative_slope=0.2, inplace=True)
    (4): Linear(in_features=256, out_features=1, bias=True)
    (5): Sigmoid()
  )
)

Discriminator ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: 533,505

ç”Ÿæˆç”»åƒå½¢çŠ¶: torch.Size([8, 1, 28, 28])
Discriminatorå‡ºåŠ›å½¢çŠ¶: torch.Size([8, 1])
Discriminatorã‚¹ã‚³ã‚¢ä¾‹: [0.4987 0.5023 0.4956]
</code></pre>

<h3>å®Ÿè£…ä¾‹2: GANè¨“ç·´ãƒ«ãƒ¼ãƒ—</h3>

<pre><code class="language-python">from torchvision import datasets, transforms
from torch.utils.data import DataLoader

print("\n=== GAN è¨“ç·´ãƒ«ãƒ¼ãƒ— ===\n")

# ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ï¼ˆMNISTä½¿ç”¨ï¼‰
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize([0.5], [0.5])  # [-1, 1]ã«æ­£è¦åŒ–
])

# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ï¼ˆå®Ÿéš›ã«ã¯MNISTãªã©ã‚’ä½¿ç”¨ï¼‰
batch_size = 64
# dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)
# dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

# ãƒ‡ãƒ¢ç”¨ã®ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿
dataloader = [(torch.randn(batch_size, 1, 28, 28).to(device), None) for _ in range(10)]

# æå¤±é–¢æ•°ã¨ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãƒ¼
adversarial_loss = nn.BCELoss()
optimizer_G = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))
optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))

print("--- è¨“ç·´è¨­å®š ---")
print(f"ãƒãƒƒãƒã‚µã‚¤ã‚º: {batch_size}")
print(f"å­¦ç¿’ç‡: 0.0002")
print(f"Beta1: 0.5, Beta2: 0.999")
print(f"æå¤±é–¢æ•°: Binary Cross Entropy\n")

# è¨“ç·´ãƒ«ãƒ¼ãƒ—ï¼ˆç°¡ç•¥ç‰ˆï¼‰
num_epochs = 3
print("--- è¨“ç·´é–‹å§‹ ---")

for epoch in range(num_epochs):
    for i, (real_imgs, _) in enumerate(dataloader):
        batch_size_actual = real_imgs.size(0)

        # æ­£è§£ãƒ©ãƒ™ãƒ«ï¼ˆæœ¬ç‰©=1, å½ç‰©=0ï¼‰
        valid = torch.ones(batch_size_actual, 1).to(device)
        fake = torch.zeros(batch_size_actual, 1).to(device)

        # ---------------------
        #  Discriminatorã®è¨“ç·´
        # ---------------------
        optimizer_D.zero_grad()

        # æœ¬ç‰©ç”»åƒã®æå¤±
        real_loss = adversarial_loss(discriminator(real_imgs), valid)

        # å½ç‰©ç”»åƒã®æå¤±
        z = torch.randn(batch_size_actual, latent_dim).to(device)
        fake_imgs = generator(z)
        fake_loss = adversarial_loss(discriminator(fake_imgs.detach()), fake)

        # Discriminatorã®ç·æå¤±
        d_loss = (real_loss + fake_loss) / 2
        d_loss.backward()
        optimizer_D.step()

        # -----------------
        #  Generatorã®è¨“ç·´
        # -----------------
        optimizer_G.zero_grad()

        # Generatorã®æå¤±ï¼ˆDiscriminatorã‚’ã ã¾ã™ã“ã¨ãŒGã®ç›®æ¨™ï¼‰
        gen_imgs = generator(z)
        g_loss = adversarial_loss(discriminator(gen_imgs), valid)

        g_loss.backward()
        optimizer_G.step()

        # é€²æ—è¡¨ç¤º
        if i % 5 == 0:
            print(f"[Epoch {epoch+1}/{num_epochs}] [Batch {i}/{len(dataloader)}] "
                  f"[D loss: {d_loss.item():.4f}] [G loss: {g_loss.item():.4f}]")

    print(f"\nEpoch {epoch+1} å®Œäº†\n")

print("è¨“ç·´å®Œäº†!")

# ç”Ÿæˆã‚µãƒ³ãƒ—ãƒ«ã®ç¢ºèª
generator.eval()
with torch.no_grad():
    z_sample = torch.randn(16, latent_dim).to(device)
    generated_samples = generator(z_sample)
    print(f"\nç”Ÿæˆã‚µãƒ³ãƒ—ãƒ«å½¢çŠ¶: {generated_samples.shape}")
    print(f"ç”Ÿæˆã‚µãƒ³ãƒ—ãƒ«å€¤ã®ç¯„å›²: [{generated_samples.min():.2f}, {generated_samples.max():.2f}]")
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>
=== GAN è¨“ç·´ãƒ«ãƒ¼ãƒ— ===

--- è¨“ç·´è¨­å®š ---
ãƒãƒƒãƒã‚µã‚¤ã‚º: 64
å­¦ç¿’ç‡: 0.0002
Beta1: 0.5, Beta2: 0.999
æå¤±é–¢æ•°: Binary Cross Entropy

--- è¨“ç·´é–‹å§‹ ---
[Epoch 1/3] [Batch 0/10] [D loss: 0.6923] [G loss: 0.6934]
[Epoch 1/3] [Batch 5/10] [D loss: 0.5234] [G loss: 0.8123]

Epoch 1 å®Œäº†

[Epoch 2/3] [Batch 0/10] [D loss: 0.4567] [G loss: 0.9234]
[Epoch 2/3] [Batch 5/10] [D loss: 0.3892] [G loss: 1.0456]

Epoch 2 å®Œäº†

[Epoch 3/3] [Batch 0/10] [D loss: 0.3234] [G loss: 1.1234]
[Epoch 3/3] [Batch 5/10] [D loss: 0.2876] [G loss: 1.2123]

Epoch 3 å®Œäº†

è¨“ç·´å®Œäº†!

ç”Ÿæˆã‚µãƒ³ãƒ—ãƒ«å½¢çŠ¶: torch.Size([16, 1, 28, 28])
ç”Ÿæˆã‚µãƒ³ãƒ—ãƒ«å€¤ã®ç¯„å›²: [-0.98, 0.97]
</code></pre>

<h3>Mode Collapseå•é¡Œ</h3>

<p><strong>Mode Collapse</strong>ã¯ã€GeneratorãŒè¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®ä¸€éƒ¨ã®ãƒ¢ãƒ¼ãƒ‰ï¼ˆãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰ã ã‘ã‚’ç”Ÿæˆã—ã€å¤šæ§˜æ€§ãŒå¤±ã‚ã‚Œã‚‹ç¾è±¡ã§ã™ã€‚</p>

<div class="mermaid">
graph TB
    subgraph æ­£å¸¸ãªå­¦ç¿’
        N1[è¨“ç·´ãƒ‡ãƒ¼ã‚¿<br/>10ã‚¯ãƒ©ã‚¹] --> N2[Generator<br/>10ã‚¯ãƒ©ã‚¹ç”Ÿæˆ]
    end

    subgraph Mode Collapse
        M1[è¨“ç·´ãƒ‡ãƒ¼ã‚¿<br/>10ã‚¯ãƒ©ã‚¹] --> M2[Generator<br/>2-3ã‚¯ãƒ©ã‚¹ã®ã¿]
    end

    style N2 fill:#e8f5e9
    style M2 fill:#ffebee
</div>

<h3>Mode Collapseã®åŸå› ã¨å¯¾ç­–</h3>

<table>
<thead>
<tr>
<th>åŸå› </th>
<th>ç—‡çŠ¶</th>
<th>å¯¾ç­–</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>å‹¾é…ã®ä¸å®‰å®šæ€§</strong></td>
<td>GãŒä¸€éƒ¨ã®ã‚µãƒ³ãƒ—ãƒ«ã«å›ºåŸ·</td>
<td>Spectral Normalizationã€WGAN</td>
</tr>
<tr>
<td><strong>ç›®çš„é–¢æ•°ã®å•é¡Œ</strong></td>
<td>DãŒå®Œç’§ã«ãªã‚Šã™ãã‚‹</td>
<td>Label Smoothingã€One-sided Label</td>
</tr>
<tr>
<td><strong>æƒ…å ±ã®ä¸è¶³</strong></td>
<td>å¤šæ§˜æ€§ã®æ¬ å¦‚</td>
<td>Minibatch Discrimination</td>
</tr>
<tr>
<td><strong>æœ€é©åŒ–ã®å•é¡Œ</strong></td>
<td>Nashå‡è¡¡ã«åˆ°é”ã—ãªã„</td>
<td>Two Timescale Update Rule</td>
</tr>
</tbody>
</table>

<h3>å®Ÿè£…ä¾‹3: Mode Collapseå¯è¦–åŒ–</h3>

<pre><code class="language-python">import matplotlib.pyplot as plt

print("\n=== Mode Collapse å¯è¦–åŒ– ===\n")

def visualize_mode_collapse_simulation():
    """
    Mode Collapseã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆ2D Gaussianãƒ‡ãƒ¼ã‚¿ï¼‰
    """
    # 8ã®Gaussianæ··åˆ minuteså¸ƒï¼ˆçœŸã®ãƒ‡ãƒ¼ã‚¿ï¼‰
    def sample_real_data(n_samples):
        centers = [
            (1, 1), (1, -1), (-1, 1), (-1, -1),
            (2, 0), (-2, 0), (0, 2), (0, -2)
        ]
        samples = []
        for _ in range(n_samples):
            center = centers[np.random.randint(0, len(centers))]
            sample = np.random.randn(2) * 0.1 + center
            samples.append(sample)
        return np.array(samples)

    # æ­£å¸¸ãªGeneratorï¼ˆå…¨ãƒ¢ãƒ¼ãƒ‰ã‚’ã‚«ãƒãƒ¼ï¼‰
    real_data = sample_real_data(1000)

    # Mode Collapseã—ãŸãƒ‡ãƒ¼ã‚¿ï¼ˆ2ã¤ã®ãƒ¢ãƒ¼ãƒ‰ã®ã¿ï¼‰
    collapsed_centers = [(1, 1), (-1, -1)]
    collapsed_data = []
    for _ in range(1000):
        center = collapsed_centers[np.random.randint(0, len(collapsed_centers))]
        sample = np.random.randn(2) * 0.1 + center
        collapsed_data.append(sample)
    collapsed_data = np.array(collapsed_data)

    print("æ­£å¸¸ãªç”Ÿæˆãƒ‡ãƒ¼ã‚¿:")
    print(f"  ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªã‚¯ãƒ©ã‚¹ã‚¿æ•°: 8")
    print(f"  ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(real_data)}")

    print("\nMode Collapseãƒ‡ãƒ¼ã‚¿:")
    print(f"  ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªã‚¯ãƒ©ã‚¹ã‚¿æ•°: 2")
    print(f"  ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(collapsed_data)}")
    print(f"  å¤šæ§˜æ€§æå¤±: 75%")

visualize_mode_collapse_simulation()

# å®Ÿéš›ã®GANã§ã®Mode Collapseæ¤œå‡º
print("\n--- Mode Collapseæ¤œå‡ºæŒ‡æ¨™ ---")
print("1. Inception Score (IS):")
print("   - é«˜ã„å€¤ = é«˜å“è³ªãƒ»å¤šæ§˜æ€§")
print("   - Mode Collapseæ™‚ã¯ä½ä¸‹")
print("\n2. Frechet Inception Distance (FID):")
print("   - ä½ã„å€¤ = çœŸã®ãƒ‡ãƒ¼ã‚¿ã«è¿‘ã„")
print("   - Mode Collapseæ™‚ã¯ä¸Šæ˜‡")
print("\n3. Number of Modes Captured:")
print("   - ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã§æ¸¬å®š")
print("   - ç†æƒ³: å…¨ãƒ¢ãƒ¼ãƒ‰ã‚’ã‚«ãƒãƒ¼")
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>
=== Mode Collapse å¯è¦–åŒ– ===

æ­£å¸¸ãªç”Ÿæˆãƒ‡ãƒ¼ã‚¿:
  ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªã‚¯ãƒ©ã‚¹ã‚¿æ•°: 8
  ã‚µãƒ³ãƒ—ãƒ«æ•°: 1000

Mode Collapseãƒ‡ãƒ¼ã‚¿:
  ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªã‚¯ãƒ©ã‚¹ã‚¿æ•°: 2
  ã‚µãƒ³ãƒ—ãƒ«æ•°: 1000
  å¤šæ§˜æ€§æå¤±: 75%

--- Mode Collapseæ¤œå‡ºæŒ‡æ¨™ ---
1. Inception Score (IS):
   - é«˜ã„å€¤ = é«˜å“è³ªãƒ»å¤šæ§˜æ€§
   - Mode Collapseæ™‚ã¯ä½ä¸‹

2. Frechet Inception Distance (FID):
   - ä½ã„å€¤ = çœŸã®ãƒ‡ãƒ¼ã‚¿ã«è¿‘ã„
   - Mode Collapseæ™‚ã¯ä¸Šæ˜‡

3. Number of Modes Captured:
   - ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã§æ¸¬å®š
   - ç†æƒ³: å…¨ãƒ¢ãƒ¼ãƒ‰ã‚’ã‚«ãƒãƒ¼
</code></pre>

<hr>

<h2>3.3 DCGAN (Deep Convolutional GAN)</h2>

<h3>DCGANã®è¨­è¨ˆåŸå‰‡</h3>

<p><strong>DCGAN</strong>ã¯ã€ç•³ã¿è¾¼ã¿å±¤ã‚’ä½¿ç”¨ã—ãŸå®‰å®šçš„ãªGANã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§ã€ä»¥ä¸‹ã®ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã«å¾“ã„ã¾ã™ï¼š</p>

<ul>
<li><strong>Poolingå±¤ã‚’å‰Šé™¤</strong>ï¼šStrided Convolutionã¨Transposed Convolutionã‚’ä½¿ç”¨</li>
<li><strong>Batch Normalization</strong>ï¼šGeneratorã¨Discriminatorã®å…¨å±¤ã«é©ç”¨ï¼ˆå‡ºåŠ›å±¤ã‚’é™¤ãï¼‰</li>
<li><strong>å…¨çµåˆå±¤ã‚’å‰Šé™¤</strong>ï¼šå®Œå…¨ç•³ã¿è¾¼ã¿ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£</li>
<li><strong>ReLUæ´»æ€§åŒ–</strong>ï¼šGeneratorã®å…¨å±¤ã§ä½¿ç”¨ï¼ˆå‡ºåŠ›å±¤ã¯Tanhï¼‰</li>
<li><strong>LeakyReLUæ´»æ€§åŒ–</strong>ï¼šDiscriminatorã®å…¨å±¤ã§ä½¿ç”¨</li>
</ul>

<div class="mermaid">
graph LR
    subgraph DCGAN Generator
        G1[æ½œåœ¨ãƒ™ã‚¯ãƒˆãƒ«<br/>100] --> G2[Dense<br/>4Ã—4Ã—1024]
        G2 --> G3[ConvTranspose<br/>8Ã—8Ã—512]
        G3 --> G4[ConvTranspose<br/>16Ã—16Ã—256]
        G4 --> G5[ConvTranspose<br/>32Ã—32Ã—128]
        G5 --> G6[ConvTranspose<br/>64Ã—64Ã—3]
    end

    style G1 fill:#e3f2fd
    style G6 fill:#e8f5e9
</div>

<h3>å®Ÿè£…ä¾‹4: DCGAN Generator</h3>

<pre><code class="language-python">print("\n=== DCGAN ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ ===\n")

class DCGANGenerator(nn.Module):
    def __init__(self, latent_dim=100, img_channels=1):
        super(DCGANGenerator, self).__init__()

        self.init_size = 7  # MNISTç”¨ï¼ˆ7Ã—7 â†’ 28Ã—28ï¼‰
        self.l1 = nn.Sequential(
            nn.Linear(latent_dim, 128 * self.init_size ** 2)
        )

        self.conv_blocks = nn.Sequential(
            nn.BatchNorm2d(128),

            # Upsample 1: 7Ã—7 â†’ 14Ã—14
            nn.Upsample(scale_factor=2),
            nn.Conv2d(128, 128, 3, stride=1, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),

            # Upsample 2: 14Ã—14 â†’ 28Ã—28
            nn.Upsample(scale_factor=2),
            nn.Conv2d(128, 64, 3, stride=1, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),

            # Output layer
            nn.Conv2d(64, img_channels, 3, stride=1, padding=1),
            nn.Tanh()
        )

    def forward(self, z):
        out = self.l1(z)
        out = out.view(out.size(0), 128, self.init_size, self.init_size)
        img = self.conv_blocks(out)
        return img

class DCGANDiscriminator(nn.Module):
    def __init__(self, img_channels=1):
        super(DCGANDiscriminator, self).__init__()

        def discriminator_block(in_filters, out_filters, bn=True):
            block = [
                nn.Conv2d(in_filters, out_filters, 3, 2, 1),
                nn.LeakyReLU(0.2, inplace=True),
                nn.Dropout2d(0.25)
            ]
            if bn:
                block.append(nn.BatchNorm2d(out_filters))
            return block

        self.model = nn.Sequential(
            *discriminator_block(img_channels, 16, bn=False),  # 28Ã—28 â†’ 14Ã—14
            *discriminator_block(16, 32),                       # 14Ã—14 â†’ 7Ã—7
            *discriminator_block(32, 64),                       # 7Ã—7 â†’ 3Ã—3
            *discriminator_block(64, 128),                      # 3Ã—3 â†’ 1Ã—1
        )

        # Output layer
        ds_size = 1
        self.adv_layer = nn.Sequential(
            nn.Linear(128 * ds_size ** 2, 1),
            nn.Sigmoid()
        )

    def forward(self, img):
        out = self.model(img)
        out = out.view(out.size(0), -1)
        validity = self.adv_layer(out)
        return validity

# ãƒ¢ãƒ‡ãƒ«ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–
dcgan_generator = DCGANGenerator(latent_dim=100, img_channels=1).to(device)
dcgan_discriminator = DCGANDiscriminator(img_channels=1).to(device)

print("--- DCGAN Generator ---")
print(dcgan_generator)
print(f"\nãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {sum(p.numel() for p in dcgan_generator.parameters()):,}")

print("\n--- DCGAN Discriminator ---")
print(dcgan_discriminator)
print(f"\nãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {sum(p.numel() for p in dcgan_discriminator.parameters()):,}")

# ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
z_dcgan = torch.randn(4, 100).to(device)
fake_imgs_dcgan = dcgan_generator(z_dcgan)
print(f"\nç”Ÿæˆç”»åƒå½¢çŠ¶: {fake_imgs_dcgan.shape}")

validity_dcgan = dcgan_discriminator(fake_imgs_dcgan)
print(f"Discriminatorå‡ºåŠ›å½¢çŠ¶: {validity_dcgan.shape}")
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>
=== DCGAN ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ ===

--- DCGAN Generator ---
DCGANGenerator(
  (l1): Sequential(
    (0): Linear(in_features=100, out_features=6272, bias=True)
  )
  (conv_blocks): Sequential(
    (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): Upsample(scale_factor=2.0, mode=nearest)
    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): ReLU(inplace=True)
    (5): Upsample(scale_factor=2.0, mode=nearest)
    (6): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): Tanh()
  )
)

ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: 781,761

--- DCGAN Discriminator ---
DCGANDiscriminator(
  (model): Sequential(...)
  (adv_layer): Sequential(
    (0): Linear(in_features=128, out_features=1, bias=True)
    (1): Sigmoid()
  )
)

ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: 89,473

ç”Ÿæˆç”»åƒå½¢çŠ¶: torch.Size([4, 1, 28, 28])
Discriminatorå‡ºåŠ›å½¢çŠ¶: torch.Size([4, 1])
</code></pre>

<hr>

<h2>3.4 è¨“ç·´ãƒ†ã‚¯ãƒ‹ãƒƒã‚¯</h2>

<h3>WGAN-GP (Wasserstein GAN with Gradient Penalty)</h3>

<p><strong>WGAN</strong>ã¯ã€Wassersteinè·é›¢ã‚’ä½¿ç”¨ã—ã¦GANã®è¨“ç·´ã‚’å®‰å®šåŒ–ã—ã¾ã™ã€‚<strong>Gradient Penalty (GP)</strong>ã¯ã€Lipschitzåˆ¶ç´„ã‚’å¼·åˆ¶ã™ã‚‹æ‰‹æ³•ã§ã™ã€‚</p>

<p>WGAN-GPã®æå¤±é–¢æ•°ï¼š</p>
<p>$$
\mathcal{L}_D = \mathbb{E}_{\tilde{\mathbf{x}} \sim p_g}[D(\tilde{\mathbf{x}})] - \mathbb{E}_{\mathbf{x} \sim p_{\text{data}}}[D(\mathbf{x})] + \lambda \mathbb{E}_{\hat{\mathbf{x}} \sim p_{\hat{\mathbf{x}}}}[(\|\nabla_{\hat{\mathbf{x}}} D(\hat{\mathbf{x}})\|_2 - 1)^2]
$$</p>

<p>$$
\mathcal{L}_G = -\mathbb{E}_{\tilde{\mathbf{x}} \sim p_g}[D(\tilde{\mathbf{x}})]
$$</p>

<p>ã“ã“ã§ $\hat{\mathbf{x}} = \epsilon \mathbf{x} + (1 - \epsilon)\tilde{\mathbf{x}}$ ã¯æœ¬ç‰©ã¨å½ç‰©ã®é–“ã®è£œé–“ç‚¹ã§ã™ã€‚</p>

<h3>å®Ÿè£…ä¾‹5: WGAN-GPå®Ÿè£…</h3>

<pre><code class="language-python">print("\n=== WGAN-GP å®Ÿè£… ===\n")

def compute_gradient_penalty(D, real_samples, fake_samples, device):
    """
    Gradient Penaltyã®è¨ˆç®—
    """
    batch_size = real_samples.size(0)

    # ãƒ©ãƒ³ãƒ€ãƒ ãªé‡ã¿ï¼ˆè£œé–“ç”¨ï¼‰
    alpha = torch.rand(batch_size, 1, 1, 1).to(device)

    # æœ¬ç‰©ã¨å½ç‰©ã®è£œé–“
    interpolates = (alpha * real_samples + (1 - alpha) * fake_samples).requires_grad_(True)

    # Discriminatorã§è©•ä¾¡
    d_interpolates = D(interpolates)

    # å‹¾é…è¨ˆç®—
    gradients = torch.autograd.grad(
        outputs=d_interpolates,
        inputs=interpolates,
        grad_outputs=torch.ones_like(d_interpolates),
        create_graph=True,
        retain_graph=True,
        only_inputs=True
    )[0]

    # å‹¾é…ã®L2ãƒãƒ«ãƒ 
    gradients = gradients.view(batch_size, -1)
    gradient_norm = gradients.norm(2, dim=1)

    # Gradient Penalty
    gradient_penalty = ((gradient_norm - 1) ** 2).mean()

    return gradient_penalty

# WGAN-GPç”¨ã®Discriminatorï¼ˆSigmoidãªã—ï¼‰
class WGANDiscriminator(nn.Module):
    def __init__(self, img_channels=1):
        super(WGANDiscriminator, self).__init__()

        self.model = nn.Sequential(
            nn.Conv2d(img_channels, 16, 3, 2, 1),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Dropout2d(0.25),

            nn.Conv2d(16, 32, 3, 2, 1),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Dropout2d(0.25),
            nn.BatchNorm2d(32),

            nn.Conv2d(32, 64, 3, 2, 1),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Dropout2d(0.25),
            nn.BatchNorm2d(64),

            nn.Conv2d(64, 128, 3, 2, 1),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Dropout2d(0.25),
            nn.BatchNorm2d(128),
        )

        self.adv_layer = nn.Linear(128, 1)  # Sigmoidãªã—

    def forward(self, img):
        out = self.model(img)
        out = out.view(out.size(0), -1)
        validity = self.adv_layer(out)
        return validity

# WGAN-GPè¨“ç·´ãƒ«ãƒ¼ãƒ—ï¼ˆç°¡ç•¥ç‰ˆï¼‰
wgan_discriminator = WGANDiscriminator(img_channels=1).to(device)
optimizer_D_wgan = optim.Adam(wgan_discriminator.parameters(), lr=0.0001, betas=(0.5, 0.999))
optimizer_G_wgan = optim.Adam(dcgan_generator.parameters(), lr=0.0001, betas=(0.5, 0.999))

lambda_gp = 10  # Gradient Penaltyã®ä¿‚æ•°
n_critic = 5    # Discriminatorã‚’Generatorã®5å€è¨“ç·´

print("--- WGAN-GP è¨“ç·´è¨­å®š ---")
print(f"Gradient Penaltyä¿‚æ•° (Î»): {lambda_gp}")
print(f"Criticåå¾©å›æ•°: {n_critic}")
print(f"å­¦ç¿’ç‡: 0.0001")
print(f"æå¤±: Wassersteinè·é›¢ + GP\n")

# ã‚µãƒ³ãƒ—ãƒ«è¨“ç·´ã‚¹ãƒ†ãƒƒãƒ—
real_imgs_sample = torch.randn(32, 1, 28, 28).to(device)
z_sample = torch.randn(32, 100).to(device)

for step in range(3):
    # ---------------------
    #  Discriminatorã®è¨“ç·´
    # ---------------------
    for _ in range(n_critic):
        optimizer_D_wgan.zero_grad()

        fake_imgs_wgan = dcgan_generator(z_sample).detach()

        # Wassersteinæå¤±
        real_validity = wgan_discriminator(real_imgs_sample)
        fake_validity = wgan_discriminator(fake_imgs_wgan)

        # Gradient Penalty
        gp = compute_gradient_penalty(wgan_discriminator, real_imgs_sample, fake_imgs_wgan, device)

        # Discriminatoræå¤±
        d_loss_wgan = -torch.mean(real_validity) + torch.mean(fake_validity) + lambda_gp * gp

        d_loss_wgan.backward()
        optimizer_D_wgan.step()

    # -----------------
    #  Generatorã®è¨“ç·´
    # -----------------
    optimizer_G_wgan.zero_grad()

    gen_imgs_wgan = dcgan_generator(z_sample)
    fake_validity_g = wgan_discriminator(gen_imgs_wgan)

    # Generatoræå¤±
    g_loss_wgan = -torch.mean(fake_validity_g)

    g_loss_wgan.backward()
    optimizer_G_wgan.step()

    print(f"Step {step+1}: [D loss: {d_loss_wgan.item():.4f}] [G loss: {g_loss_wgan.item():.4f}] [GP: {gp.item():.4f}]")

print("\nWGAN-GPã®åˆ©ç‚¹:")
print("  âœ“ è¨“ç·´ã®å®‰å®šæ€§å‘ä¸Š")
print("  âœ“ Mode Collapseè»½æ¸›")
print("  âœ“ æ„å‘³ã®ã‚ã‚‹æå¤±ãƒ¡ãƒˆãƒªã‚¯ã‚¹ï¼ˆWassersteinè·é›¢ï¼‰")
print("  âœ“ Hyperparameterã¸ã®é ‘å¥æ€§")
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>
=== WGAN-GP å®Ÿè£… ===

--- WGAN-GP è¨“ç·´è¨­å®š ---
Gradient Penaltyä¿‚æ•° (Î»): 10
Criticåå¾©å›æ•°: 5
å­¦ç¿’ç‡: 0.0001
æå¤±: Wassersteinè·é›¢ + GP

Step 1: [D loss: 12.3456] [G loss: -8.2345] [GP: 0.2345]
Step 2: [D loss: 9.8765] [G loss: -10.5432] [GP: 0.1876]
Step 3: [D loss: 7.6543] [G loss: -12.3456] [GP: 0.1543]

WGAN-GPã®åˆ©ç‚¹:
  âœ“ è¨“ç·´ã®å®‰å®šæ€§å‘ä¸Š
  âœ“ Mode Collapseè»½æ¸›
  âœ“ æ„å‘³ã®ã‚ã‚‹æå¤±ãƒ¡ãƒˆãƒªã‚¯ã‚¹ï¼ˆWassersteinè·é›¢ï¼‰
  âœ“ Hyperparameterã¸ã®é ‘å¥æ€§
</code></pre>

<h3>Spectral Normalization</h3>

<p><strong>Spectral Normalization</strong>ã¯ã€Discriminatorã®å„å±¤ã®é‡ã¿è¡Œåˆ—ã®ã‚¹ãƒšã‚¯ãƒˆãƒ«ãƒãƒ«ãƒ ï¼ˆæœ€å¤§ç‰¹ç•°å€¤ï¼‰ã‚’1ã«æ­£è¦åŒ–ã™ã‚‹æ‰‹æ³•ã§ã™ã€‚</p>

<p>ã‚¹ãƒšã‚¯ãƒˆãƒ«ãƒãƒ«ãƒ ï¼š</p>
<p>$$
\|W\|_2 = \max_{\mathbf{h}} \frac{\|W\mathbf{h}\|_2}{\|\mathbf{h}\|_2}
$$</p>

<p>æ­£è¦åŒ–ã•ã‚ŒãŸé‡ã¿ï¼š</p>
<p>$$
\bar{W} = \frac{W}{\|W\|_2}
$$</p>

<h3>å®Ÿè£…ä¾‹6: Spectral Normalizationé©ç”¨</h3>

<pre><code class="language-python">from torch.nn.utils import spectral_norm

print("\n=== Spectral Normalization ===\n")

class SpectralNormDiscriminator(nn.Module):
    def __init__(self, img_channels=1):
        super(SpectralNormDiscriminator, self).__init__()

        self.model = nn.Sequential(
            spectral_norm(nn.Conv2d(img_channels, 64, 4, 2, 1)),
            nn.LeakyReLU(0.2, inplace=True),

            spectral_norm(nn.Conv2d(64, 128, 4, 2, 1)),
            nn.LeakyReLU(0.2, inplace=True),

            spectral_norm(nn.Conv2d(128, 256, 4, 2, 1)),
            nn.LeakyReLU(0.2, inplace=True),

            spectral_norm(nn.Conv2d(256, 512, 4, 2, 1)),
            nn.LeakyReLU(0.2, inplace=True),
        )

        self.adv_layer = spectral_norm(nn.Linear(512, 1))

    def forward(self, img):
        out = self.model(img)
        out = out.view(out.size(0), -1)
        validity = self.adv_layer(out)
        return validity

sn_discriminator = SpectralNormDiscriminator(img_channels=1).to(device)

print("--- Spectral Normalizationé©ç”¨æ¸ˆã¿ Discriminator ---")
print(sn_discriminator)
print(f"\nãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {sum(p.numel() for p in sn_discriminator.parameters()):,}")

# ã‚¹ãƒšã‚¯ãƒˆãƒ«ãƒãƒ«ãƒ ã®ç¢ºèª
print("\n--- ã‚¹ãƒšã‚¯ãƒˆãƒ«ãƒãƒ«ãƒ ç¢ºèª ---")
for name, module in sn_discriminator.named_modules():
    if isinstance(module, nn.Conv2d) or isinstance(module, nn.Linear):
        if hasattr(module, 'weight_orig'):  # Spectral Normé©ç”¨æ¸ˆã¿
            weight = module.weight
            spectral_norm_value = torch.norm(weight, p=2).item()
            print(f"{name}: ã‚¹ãƒšã‚¯ãƒˆãƒ«ãƒãƒ«ãƒ  â‰ˆ {spectral_norm_value:.4f}")

print("\nSpectral Normalizationã®åŠ¹æœ:")
print("  âœ“ Lipschitzåˆ¶ç´„ã‚’è‡ªå‹•çš„ã«æº€ãŸã™")
print("  âœ“ WGAN-GPã‚ˆã‚Šã‚·ãƒ³ãƒ—ãƒ«ï¼ˆGPãªã—ï¼‰")
print("  âœ“ è¨“ç·´ã®å®‰å®šæ€§å‘ä¸Š")
print("  âœ“ è¨ˆç®—åŠ¹ç‡ãŒè‰¯ã„")
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>
=== Spectral Normalization ===

--- Spectral Normalizationé©ç”¨æ¸ˆã¿ Discriminator ---
SpectralNormDiscriminator(
  (model): Sequential(
    (0): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
    (1): LeakyReLU(negative_slope=0.2, inplace=True)
    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
    (3): LeakyReLU(negative_slope=0.2, inplace=True)
    (4): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
    (5): LeakyReLU(negative_slope=0.2, inplace=True)
    (6): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
    (7): LeakyReLU(negative_slope=0.2, inplace=True)
  )
  (adv_layer): Linear(in_features=512, out_features=1, bias=True)
)

ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: 2,943,041

--- ã‚¹ãƒšã‚¯ãƒˆãƒ«ãƒãƒ«ãƒ ç¢ºèª ---
model.0: ã‚¹ãƒšã‚¯ãƒˆãƒ«ãƒãƒ«ãƒ  â‰ˆ 1.0023
model.2: ã‚¹ãƒšã‚¯ãƒˆãƒ«ãƒãƒ«ãƒ  â‰ˆ 0.9987
model.4: ã‚¹ãƒšã‚¯ãƒˆãƒ«ãƒãƒ«ãƒ  â‰ˆ 1.0012
model.6: ã‚¹ãƒšã‚¯ãƒˆãƒ«ãƒãƒ«ãƒ  â‰ˆ 0.9995
adv_layer: ã‚¹ãƒšã‚¯ãƒˆãƒ«ãƒãƒ«ãƒ  â‰ˆ 1.0008

Spectral Normalizationã®åŠ¹æœ:
  âœ“ Lipschitzåˆ¶ç´„ã‚’è‡ªå‹•çš„ã«æº€ãŸã™
  âœ“ WGAN-GPã‚ˆã‚Šã‚·ãƒ³ãƒ—ãƒ«ï¼ˆGPãªã—ï¼‰
  âœ“ è¨“ç·´ã®å®‰å®šæ€§å‘ä¸Š
  âœ“ è¨ˆç®—åŠ¹ç‡ãŒè‰¯ã„
</code></pre>

<h3>Label Smoothing</h3>

<p><strong>Label Smoothing</strong>ã¯ã€æ­£è§£ãƒ©ãƒ™ãƒ«ã‚’0/1ã§ã¯ãªãã€0.9/0.1ãªã©ã«ç·©å’Œã™ã‚‹ã“ã¨ã§ã€Discriminatorã®éä¿¡ã‚’é˜²ãã¾ã™ã€‚</p>

<table>
<thead>
<tr>
<th>æ‰‹æ³•</th>
<th>æœ¬ç‰©ãƒ©ãƒ™ãƒ«</th>
<th>å½ç‰©ãƒ©ãƒ™ãƒ«</th>
<th>åŠ¹æœ</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>é€šå¸¸</strong></td>
<td>1.0</td>
<td>0.0</td>
<td>DãŒéä¿¡â†’Gã®å‹¾é…æ¶ˆå¤±</td>
</tr>
<tr>
<td><strong>Label Smoothing</strong></td>
<td>0.9</td>
<td>0.1</td>
<td>Dã®éä¿¡ã‚’é˜²ã</td>
</tr>
<tr>
<td><strong>One-sided</strong></td>
<td>0.9</td>
<td>0.0</td>
<td>å½ç‰©å´ã®ã¿å³æ ¼</td>
</tr>
</tbody>
</table>

<pre><code class="language-python">print("\n=== Label Smoothing å®Ÿè£… ===\n")

# Label Smoothingé©ç”¨
real_label_smooth = 0.9
fake_label_smooth = 0.1

# é€šå¸¸ã®ãƒ©ãƒ™ãƒ«
valid_normal = torch.ones(batch_size, 1).to(device)
fake_normal = torch.zeros(batch_size, 1).to(device)

# Label Smoothingé©ç”¨
valid_smooth = torch.ones(batch_size, 1).to(device) * real_label_smooth
fake_smooth = torch.ones(batch_size, 1).to(device) * fake_label_smooth

print("é€šå¸¸ã®ãƒ©ãƒ™ãƒ«:")
print(f"  æœ¬ç‰©: {valid_normal[0].item()}")
print(f"  å½ç‰©: {fake_normal[0].item()}")

print("\nLabel Smoothingé©ç”¨:")
print(f"  æœ¬ç‰©: {valid_smooth[0].item()}")
print(f"  å½ç‰©: {fake_smooth[0].item()}")

print("\nLabel Smoothingã®åŠ¹æœ:")
print("  âœ“ Discriminatorã®éä¿¡ã‚’é˜²æ­¢")
print("  âœ“ Generatorã¸ã®å‹¾é…ã‚’å®‰å®šåŒ–")
print("  âœ“ è¨“ç·´ã®åæŸã‚’æ”¹å–„")
print("  âœ“ å®Ÿè£…ãŒéå¸¸ã«ã‚·ãƒ³ãƒ—ãƒ«")
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>
=== Label Smoothing å®Ÿè£… ===

é€šå¸¸ã®ãƒ©ãƒ™ãƒ«:
  æœ¬ç‰©: 1.0
  å½ç‰©: 0.0

Label Smoothingé©ç”¨:
  æœ¬ç‰©: 0.9
  å½ç‰©: 0.1

Label Smoothingã®åŠ¹æœ:
  âœ“ Discriminatorã®éä¿¡ã‚’é˜²æ­¢
  âœ“ Generatorã¸ã®å‹¾é…ã‚’å®‰å®šåŒ–
  âœ“ è¨“ç·´ã®åæŸã‚’æ”¹å–„
  âœ“ å®Ÿè£…ãŒéå¸¸ã«ã‚·ãƒ³ãƒ—ãƒ«
</code></pre>

<hr>

<h2>3.5 StyleGANæ¦‚è¦</h2>

<h3>StyleGANã®é©æ–°</h3>

<p><strong>StyleGAN</strong>ã¯ã€NVIDIAãŒé–‹ç™ºã—ãŸé«˜å“è³ªç”»åƒç”ŸæˆGANã§ã€ã‚¹ã‚¿ã‚¤ãƒ«ã®åˆ¶å¾¡å¯èƒ½æ€§ã‚’å¤§å¹…ã«å‘ä¸Šã•ã›ã¾ã—ãŸã€‚</p>

<div class="mermaid">
graph LR
    subgraph StyleGAN Architecture
        Z[æ½œåœ¨ãƒ™ã‚¯ãƒˆãƒ« z] --> M[Mapping Network<br/>8å±¤MLP]
        M --> W[ä¸­é–“æ½œåœ¨ç©ºé–“ w]
        W --> S1[Style 1<br/>4Ã—4è§£åƒåº¦]
        W --> S2[Style 2<br/>8Ã—8è§£åƒåº¦]
        W --> S3[Style 3<br/>16Ã—16è§£åƒåº¦]
        W --> S4[Style 4<br/>32Ã—32è§£åƒåº¦]

        N[ãƒã‚¤ã‚º] --> S1
        N --> S2
        N --> S3
        N --> S4

        S1 --> G[ç”Ÿæˆç”»åƒ<br/>1024Ã—1024]
        S2 --> G
        S3 --> G
        S4 --> G
    end

    style Z fill:#e3f2fd
    style W fill:#fff3e0
    style G fill:#e8f5e9
</div>

<h3>StyleGANã®ä¸»è¦æŠ€è¡“</h3>

<table>
<thead>
<tr>
<th>æŠ€è¡“</th>
<th>èª¬æ˜</th>
<th>åŠ¹æœ</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Mapping Network</strong></td>
<td>æ½œåœ¨ç©ºé–“zã‚’ä¸­é–“ç©ºé–“wã«å¤‰æ›</td>
<td>ã‚ˆã‚Šè§£ãã‚„ã™ã„æ½œåœ¨ç©ºé–“</td>
</tr>
<tr>
<td><strong>Adaptive Instance Norm</strong></td>
<td>å„å±¤ã§ã‚¹ã‚¿ã‚¤ãƒ«ã‚’æ³¨å…¥</td>
<td>éšå±¤çš„ãªã‚¹ã‚¿ã‚¤ãƒ«åˆ¶å¾¡</td>
</tr>
<tr>
<td><strong>Noise Injection</strong></td>
<td>å„å±¤ã«ãƒ©ãƒ³ãƒ€ãƒ ãƒã‚¤ã‚ºã‚’è¿½åŠ </td>
<td>ç´°éƒ¨ã®ãƒ©ãƒ³ãƒ€ãƒ æ€§ï¼ˆé«ªã®æ¯›ãªã©ï¼‰</td>
</tr>
<tr>
<td><strong>Progressive Growing</strong></td>
<td>ä½è§£åƒåº¦ã‹ã‚‰é«˜è§£åƒåº¦ã¸æ®µéšçš„è¨“ç·´</td>
<td>è¨“ç·´ã®å®‰å®šæ€§ã¨é«˜å“è³ªåŒ–</td>
</tr>
</tbody>
</table>

<h3>StyleGANã®ã‚¹ã‚¿ã‚¤ãƒ«æ··åˆ</h3>

<p>StyleGANã¯ã€ç•°ãªã‚‹æ½œåœ¨ãƒ™ã‚¯ãƒˆãƒ«ã®ã‚¹ã‚¿ã‚¤ãƒ«ã‚’çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ãŒã§ãã¾ã™ï¼š</p>

<ul>
<li><strong>ç²—ã„ã‚¹ã‚¿ã‚¤ãƒ«ï¼ˆ4Ã—4ã€œ8Ã—8ï¼‰</strong>ï¼šé¡”ã®å‘ãã€é«ªå‹ã€é¡”ã®å½¢</li>
<li><strong>ä¸­é–“ã‚¹ã‚¿ã‚¤ãƒ«ï¼ˆ16Ã—16ã€œ32Ã—32ï¼‰</strong>ï¼šè¡¨æƒ…ã€ç›®ã®é–‹ãå…·åˆã€é«ªã®æ¯›ã®ã‚¹ã‚¿ã‚¤ãƒ«</li>
<li><strong>ç´°ã‹ã„ã‚¹ã‚¿ã‚¤ãƒ«ï¼ˆ64Ã—64ã€œ1024Ã—1024ï¼‰</strong>ï¼šè‚Œã®è³ªæ„Ÿã€é«ªã®ç´°éƒ¨ã€èƒŒæ™¯</li>
</ul>

<h3>å®Ÿè£…ä¾‹7: StyleGANç°¡æ˜“ç‰ˆï¼ˆæ¦‚å¿µå®Ÿè£…ï¼‰</h3>

<pre><code class="language-python">print("\n=== StyleGAN æ¦‚å¿µå®Ÿè£… ===\n")

class MappingNetwork(nn.Module):
    """æ½œåœ¨ç©ºé–“zã‚’ä¸­é–“æ½œåœ¨ç©ºé–“wã«ãƒãƒƒãƒ”ãƒ³ã‚°"""
    def __init__(self, latent_dim=512, num_layers=8):
        super(MappingNetwork, self).__init__()

        layers = []
        for i in range(num_layers):
            layers.extend([
                nn.Linear(latent_dim, latent_dim),
                nn.LeakyReLU(0.2, inplace=True)
            ])

        self.mapping = nn.Sequential(*layers)

    def forward(self, z):
        w = self.mapping(z)
        return w

class AdaptiveInstanceNorm(nn.Module):
    """ã‚¹ã‚¿ã‚¤ãƒ«ã‚’æ³¨å…¥ã™ã‚‹AdaINå±¤"""
    def __init__(self, num_features, w_dim):
        super(AdaptiveInstanceNorm, self).__init__()

        self.norm = nn.InstanceNorm2d(num_features, affine=False)

        # ã‚¹ã‚¿ã‚¤ãƒ«ã‹ã‚‰ã‚¹ã‚±ãƒ¼ãƒ«ã¨ãƒã‚¤ã‚¢ã‚¹ã‚’ç”Ÿæˆ
        self.style_scale = nn.Linear(w_dim, num_features)
        self.style_bias = nn.Linear(w_dim, num_features)

    def forward(self, x, w):
        # Instance Normalization
        normalized = self.norm(x)

        # ã‚¹ã‚¿ã‚¤ãƒ«ã®é©ç”¨
        scale = self.style_scale(w).unsqueeze(2).unsqueeze(3)
        bias = self.style_bias(w).unsqueeze(2).unsqueeze(3)

        out = scale * normalized + bias
        return out

class StyleGANGeneratorBlock(nn.Module):
    """StyleGAN Generatorã®1ãƒ–ãƒ­ãƒƒã‚¯"""
    def __init__(self, in_channels, out_channels, w_dim=512):
        super(StyleGANGeneratorBlock, self).__init__()

        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, padding=1)
        self.adain1 = AdaptiveInstanceNorm(out_channels, w_dim)
        self.noise1 = nn.Parameter(torch.zeros(1))

        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, padding=1)
        self.adain2 = AdaptiveInstanceNorm(out_channels, w_dim)
        self.noise2 = nn.Parameter(torch.zeros(1))

        self.activation = nn.LeakyReLU(0.2, inplace=True)

    def forward(self, x, w, noise=None):
        # Conv1 + AdaIN1 + Noise
        out = self.conv1(x)
        if noise is not None:
            out = out + noise * self.noise1
        out = self.adain1(out, w)
        out = self.activation(out)

        # Conv2 + AdaIN2 + Noise
        out = self.conv2(out)
        if noise is not None:
            out = out + noise * self.noise2
        out = self.adain2(out, w)
        out = self.activation(out)

        return out

# Mapping Networkã®ãƒ†ã‚¹ãƒˆ
mapping_net = MappingNetwork(latent_dim=512, num_layers=8).to(device)
z_style = torch.randn(4, 512).to(device)
w = mapping_net(z_style)

print("--- Mapping Network ---")
print(f"å…¥åŠ› z å½¢çŠ¶: {z_style.shape}")
print(f"å‡ºåŠ› w å½¢çŠ¶: {w.shape}")
print(f"ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {sum(p.numel() for p in mapping_net.parameters()):,}")

# StyleGAN Blockã®ãƒ†ã‚¹ãƒˆ
style_block = StyleGANGeneratorBlock(128, 64, w_dim=512).to(device)
x_input = torch.randn(4, 128, 8, 8).to(device)
x_output = style_block(x_input, w)

print("\n--- StyleGAN Generator Block ---")
print(f"å…¥åŠ› x å½¢çŠ¶: {x_input.shape}")
print(f"å‡ºåŠ› x å½¢çŠ¶: {x_output.shape}")
print(f"ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {sum(p.numel() for p in style_block.parameters()):,}")

print("\nStyleGANã®ç‰¹å¾´:")
print("  âœ“ é«˜å“è³ªãªç”»åƒç”Ÿæˆï¼ˆ1024Ã—1024ä»¥ä¸Šï¼‰")
print("  âœ“ ã‚¹ã‚¿ã‚¤ãƒ«ã®ç´°ã‹ã„åˆ¶å¾¡ãŒå¯èƒ½")
print("  âœ“ ã‚¹ã‚¿ã‚¤ãƒ«æ··åˆã§å¤šæ§˜ãªç”»åƒç”Ÿæˆ")
print("  âœ“ è§£ãã‚„ã™ã„æ½œåœ¨ç©ºé–“ï¼ˆwç©ºé–“ï¼‰")
print("  âœ“ é¡”ç”»åƒç”Ÿæˆã§ç‰¹ã«å„ªã‚ŒãŸæ€§èƒ½")
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>
=== StyleGAN æ¦‚å¿µå®Ÿè£… ===

--- Mapping Network ---
å…¥åŠ› z å½¢çŠ¶: torch.Size([4, 512])
å‡ºåŠ› w å½¢çŠ¶: torch.Size([4, 512])
ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: 2,101,248

--- StyleGAN Generator Block ---
å…¥åŠ› x å½¢çŠ¶: torch.Size([4, 128, 8, 8])
å‡ºåŠ› x å½¢çŠ¶: torch.Size([4, 64, 8, 8])
ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: 222,976

StyleGANã®ç‰¹å¾´:
  âœ“ é«˜å“è³ªãªç”»åƒç”Ÿæˆï¼ˆ1024Ã—1024ä»¥ä¸Šï¼‰
  âœ“ ã‚¹ã‚¿ã‚¤ãƒ«ã®ç´°ã‹ã„åˆ¶å¾¡ãŒå¯èƒ½
  âœ“ ã‚¹ã‚¿ã‚¤ãƒ«æ··åˆã§å¤šæ§˜ãªç”»åƒç”Ÿæˆ
  âœ“ è§£ãã‚„ã™ã„æ½œåœ¨ç©ºé–“ï¼ˆwç©ºé–“ï¼‰
  âœ“ é¡”ç”»åƒç”Ÿæˆã§ç‰¹ã«å„ªã‚ŒãŸæ€§èƒ½
</code></pre>

<hr>

<h2>3.6 å®Ÿè·µï¼šç”»åƒç”Ÿæˆãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ</h2>

<h3>å®Ÿè£…ä¾‹8: å®Œå…¨ãªç”»åƒç”Ÿæˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³</h3>

<pre><code class="language-python">import torchvision.utils as vutils
from torchvision.utils import save_image

print("\n=== å®Œå…¨ãªç”»åƒç”Ÿæˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ ===\n")

class ImageGenerationPipeline:
    """ç”»åƒç”Ÿæˆã®å®Œå…¨ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³"""

    def __init__(self, generator, latent_dim=100, device='cuda'):
        self.generator = generator
        self.latent_dim = latent_dim
        self.device = device
        self.generator.eval()

    def generate_images(self, num_images=16, seed=None):
        """æŒ‡å®šæ•°ã®ç”»åƒã‚’ç”Ÿæˆ"""
        if seed is not None:
            torch.manual_seed(seed)

        with torch.no_grad():
            z = torch.randn(num_images, self.latent_dim).to(self.device)
            generated_imgs = self.generator(z)

        return generated_imgs

    def interpolate_latent(self, z1, z2, num_steps=10):
        """2ã¤ã®æ½œåœ¨ãƒ™ã‚¯ãƒˆãƒ«é–“ã‚’è£œé–“"""
        alphas = torch.linspace(0, 1, num_steps)
        interpolated_imgs = []

        with torch.no_grad():
            for alpha in alphas:
                z_interp = (1 - alpha) * z1 + alpha * z2
                img = self.generator(z_interp)
                interpolated_imgs.append(img)

        return torch.cat(interpolated_imgs, dim=0)

    def explore_latent_space(self, base_z, dimension, range_scale=3.0, num_steps=10):
        """æ½œåœ¨ç©ºé–“ã®ç‰¹å®šã®æ¬¡å…ƒã‚’æ¢ç´¢"""
        variations = []

        with torch.no_grad():
            for scale in torch.linspace(-range_scale, range_scale, num_steps):
                z_var = base_z.clone()
                z_var[0, dimension] += scale
                img = self.generator(z_var)
                variations.append(img)

        return torch.cat(variations, dim=0)

    def save_generated_images(self, images, filename, nrow=8):
        """ç”Ÿæˆç”»åƒã‚’ä¿å­˜"""
        # [-1, 1] â†’ [0, 1]ã«æ­£è¦åŒ–
        images = (images + 1) / 2.0
        images = torch.clamp(images, 0, 1)

        # ã‚°ãƒªãƒƒãƒ‰å½¢å¼ã§ä¿å­˜
        grid = vutils.make_grid(images, nrow=nrow, padding=2, normalize=False)

        print(f"ç”»åƒã‚’ä¿å­˜: {filename}")
        print(f"  ã‚°ãƒªãƒƒãƒ‰ã‚µã‚¤ã‚º: {grid.shape}")
        # save_image(grid, filename)  # å®Ÿéš›ã®ä¿å­˜

        return grid

# ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®åˆæœŸåŒ–
pipeline = ImageGenerationPipeline(
    generator=dcgan_generator,
    latent_dim=100,
    device=device
)

print("--- ç”»åƒç”Ÿæˆ ---")
generated_imgs = pipeline.generate_images(num_images=16, seed=42)
print(f"ç”Ÿæˆç”»åƒæ•°: {generated_imgs.size(0)}")
print(f"ç”»åƒå½¢çŠ¶: {generated_imgs.shape}")

# ã‚°ãƒªãƒƒãƒ‰ä¿å­˜
grid = pipeline.save_generated_images(generated_imgs, "generated_samples.png", nrow=4)
print(f"ã‚°ãƒªãƒƒãƒ‰å½¢çŠ¶: {grid.shape}\n")

# æ½œåœ¨ç©ºé–“ã®è£œé–“
print("--- æ½œåœ¨ç©ºé–“è£œé–“ ---")
z1 = torch.randn(1, 100).to(device)
z2 = torch.randn(1, 100).to(device)
interpolated_imgs = pipeline.interpolate_latent(z1, z2, num_steps=8)
print(f"è£œé–“ç”»åƒæ•°: {interpolated_imgs.size(0)}")
print(f"è£œé–“ã‚¹ãƒ†ãƒƒãƒ—: 8\n")

# æ½œåœ¨ç©ºé–“æ¢ç´¢
print("--- æ½œåœ¨ç©ºé–“æ¢ç´¢ ---")
base_z = torch.randn(1, 100).to(device)
dimension_to_explore = 5
variations = pipeline.explore_latent_space(base_z, dimension_to_explore, num_steps=10)
print(f"æ¢ç´¢æ¬¡å…ƒ: {dimension_to_explore}")
print(f"ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³æ•°: {variations.size(0)}")
print(f"ç¯„å›²: [-3.0, 3.0]\n")

# å“è³ªè©•ä¾¡æŒ‡æ¨™ï¼ˆæ¦‚å¿µï¼‰
print("--- ç”Ÿæˆå“è³ªè©•ä¾¡æŒ‡æ¨™ ---")
print("1. Inception Score (IS):")
print("   - ç”»åƒã®å“è³ªã¨å¤šæ§˜æ€§ã‚’è©•ä¾¡")
print("   - ç¯„å›²: 1.0ã€œï¼ˆé«˜ã„ã»ã©è‰¯ã„ï¼‰")
print("   - MNIST: ~2-3, ImageNet: ~10-15")

print("\n2. Frechet Inception Distance (FID):")
print("   - ç”Ÿæˆ minuteså¸ƒã¨çœŸã® minuteså¸ƒã®è·é›¢")
print("   - ç¯„å›²: 0ã€œï¼ˆä½ã„ã»ã©è‰¯ã„ï¼‰")
print("   - FID < 50: è‰¯å¥½ã€FID < 10: éå¸¸ã«è‰¯å¥½")

print("\n3. Precision & Recall:")
print("   - Precision: ç”Ÿæˆç”»åƒã®å“è³ª")
print("   - Recall: ç”Ÿæˆç”»åƒã®å¤šæ§˜æ€§")
print("   - ä¸¡æ–¹é«˜ã„ã®ãŒç†æƒ³")

print("\n--- å®Ÿç”¨çš„ãªå¿œç”¨ä¾‹ ---")
print("âœ“ é¡”ç”»åƒç”Ÿæˆï¼ˆStyleGANï¼‰")
print("âœ“ ã‚¢ãƒ¼ãƒˆä½œå“ç”Ÿæˆ")
print("âœ“ ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µï¼ˆå°‘é‡ãƒ‡ãƒ¼ã‚¿ã®è£œå®Œï¼‰")
print("âœ“ ç”»åƒã®è¶…è§£åƒï¼ˆSuper-Resolution GANï¼‰")
print("âœ“ ç”»åƒå¤‰æ›ï¼ˆpix2pixã€CycleGANï¼‰")
print("âœ“ 3Dãƒ¢ãƒ‡ãƒ«ç”Ÿæˆ")
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>
=== å®Œå…¨ãªç”»åƒç”Ÿæˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ ===

--- ç”»åƒç”Ÿæˆ ---
ç”Ÿæˆç”»åƒæ•°: 16
ç”»åƒå½¢çŠ¶: torch.Size([16, 1, 28, 28])
ç”»åƒã‚’ä¿å­˜: generated_samples.png
  ã‚°ãƒªãƒƒãƒ‰ã‚µã‚¤ã‚º: torch.Size([3, 62, 62])
ã‚°ãƒªãƒƒãƒ‰å½¢çŠ¶: torch.Size([3, 62, 62])

--- æ½œåœ¨ç©ºé–“è£œé–“ ---
è£œé–“ç”»åƒæ•°: 8
è£œé–“ã‚¹ãƒ†ãƒƒãƒ—: 8

--- æ½œåœ¨ç©ºé–“æ¢ç´¢ ---
æ¢ç´¢æ¬¡å…ƒ: 5
ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³æ•°: 10
ç¯„å›²: [-3.0, 3.0]

--- ç”Ÿæˆå“è³ªè©•ä¾¡æŒ‡æ¨™ ---
1. Inception Score (IS):
   - ç”»åƒã®å“è³ªã¨å¤šæ§˜æ€§ã‚’è©•ä¾¡
   - ç¯„å›²: 1.0ã€œï¼ˆé«˜ã„ã»ã©è‰¯ã„ï¼‰
   - MNIST: ~2-3, ImageNet: ~10-15

2. Frechet Inception Distance (FID):
   - ç”Ÿæˆ minuteså¸ƒã¨çœŸã® minuteså¸ƒã®è·é›¢
   - ç¯„å›²: 0ã€œï¼ˆä½ã„ã»ã©è‰¯ã„ï¼‰
   - FID < 50: è‰¯å¥½ã€FID < 10: éå¸¸ã«è‰¯å¥½

3. Precision & Recall:
   - Precision: ç”Ÿæˆç”»åƒã®å“è³ª
   - Recall: ç”Ÿæˆç”»åƒã®å¤šæ§˜æ€§
   - ä¸¡æ–¹é«˜ã„ã®ãŒç†æƒ³

--- å®Ÿç”¨çš„ãªå¿œç”¨ä¾‹ ---
âœ“ é¡”ç”»åƒç”Ÿæˆï¼ˆStyleGANï¼‰
âœ“ ã‚¢ãƒ¼ãƒˆä½œå“ç”Ÿæˆ
âœ“ ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µï¼ˆå°‘é‡ãƒ‡ãƒ¼ã‚¿ã®è£œå®Œï¼‰
âœ“ ç”»åƒã®è¶…è§£åƒï¼ˆSuper-Resolution GANï¼‰
âœ“ ç”»åƒå¤‰æ›ï¼ˆpix2pixã€CycleGANï¼‰
âœ“ 3Dãƒ¢ãƒ‡ãƒ«ç”Ÿæˆ
</code></pre>

<hr>

<h2>GANã®è¨“ç·´ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹</h2>

<h3>ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®é¸æŠ</h3>

<table>
<thead>
<tr>
<th>ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿</th>
<th>Recommendedå€¤</th>
<th>ç†ç”±</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>å­¦ç¿’ç‡</strong></td>
<td>0.0001ã€œ0.0002</td>
<td>å®‰å®šã—ãŸè¨“ç·´ã®ãŸã‚ä½ã‚ã«è¨­å®š</td>
</tr>
<tr>
<td><strong>Beta1 (Adam)</strong></td>
<td>0.5</td>
<td>é€šå¸¸ã®0.9ã‚ˆã‚Šä½ãï¼ˆGANã®ç‰¹æ€§ï¼‰</td>
</tr>
<tr>
<td><strong>Beta2 (Adam)</strong></td>
<td>0.999</td>
<td>æ¨™æº–å€¤ã‚’ç¶­æŒ</td>
</tr>
<tr>
<td><strong>ãƒãƒƒãƒã‚µã‚¤ã‚º</strong></td>
<td>64ã€œ128</td>
<td>å®‰å®šæ€§ã¨è¨ˆç®—åŠ¹ç‡ã®ãƒãƒ©ãƒ³ã‚¹</td>
</tr>
<tr>
<td><strong>æ½œåœ¨æ¬¡å…ƒ</strong></td>
<td>100ã€œ512</td>
<td>è¤‡é›‘ã•ã«å¿œã˜ã¦èª¿æ•´</td>
</tr>
</tbody>
</table>

<h3>è¨“ç·´ã®å®‰å®šåŒ–ãƒ†ã‚¯ãƒ‹ãƒƒã‚¯</h3>

<div class="mermaid">
graph TB
    A[è¨“ç·´ã®ä¸å®‰å®šæ€§] --> B1[å‹¾é…å•é¡Œ]
    A --> B2[Mode Collapse]
    A --> B3[åæŸå¤±æ•—]

    B1 --> C1[Spectral Norm]
    B1 --> C2[Gradient Clipping]
    B1 --> C3[WGAN-GP]

    B2 --> D1[Minibatch Discrimination]
    B2 --> D2[Feature Matching]
    B2 --> D3[Two Timescale]

    B3 --> E1[Label Smoothing]
    B3 --> E2[Noise Injection]
    B3 --> E3[Learning Rate Decay]

    style B1 fill:#ffebee
    style B2 fill:#ffebee
    style B3 fill:#ffebee
    style C1 fill:#e8f5e9
    style C2 fill:#e8f5e9
    style C3 fill:#e8f5e9
    style D1 fill:#e8f5e9
    style D2 fill:#e8f5e9
    style D3 fill:#e8f5e9
    style E1 fill:#e8f5e9
    style E2 fill:#e8f5e9
    style E3 fill:#e8f5e9
</div>

<h3>ãƒ‡ãƒãƒƒã‚°ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ</h3>

<ul>
<li><strong>DiscriminatorãŒå¼·ã™ãã‚‹</strong>ï¼šå­¦ç¿’ç‡ã‚’ä¸‹ã’ã‚‹ã€Label Smoothingé©ç”¨</li>
<li><strong>GeneratorãŒå¼·ã™ãã‚‹</strong>ï¼šDiscriminatorã®è¨“ç·´å›æ•°ã‚’å¢—ã‚„ã™</li>
<li><strong>Mode Collapseç™ºç”Ÿ</strong>ï¼šWGAN-GPã€Spectral Normã€Minibatch Discriminationã‚’è©¦ã™</li>
<li><strong>å‹¾é…æ¶ˆå¤±</strong>ï¼šLeakyReLUä½¿ç”¨ã€Batch Normalizationè¿½åŠ </li>
<li><strong>è¨“ç·´ã®æŒ¯å‹•</strong>ï¼šå­¦ç¿’ç‡ã‚’ä¸‹ã’ã‚‹ã€Two Timescale Update Rule</li>
</ul>

<hr>

<h2>Summary</h2>

<p>ã“ã® Chapterã§ã¯ã€GANã®åŸºç¤ã‹ã‚‰å¿œç”¨ã¾ã§ã‚’å­¦ã³ã¾ã—ãŸï¼š</p>

<h3>é‡è¦ãªãƒã‚¤ãƒ³ãƒˆ</h3>

<details>
<summary><strong>1. GANã®åŸºæœ¬åŸç†</strong></summary>
<ul>
<li>Generatorã¨Discriminatorã®æ•µå¯¾çš„ç«¶äº‰</li>
<li>Minimax gameã¨Nashå‡è¡¡</li>
<li>æ½œåœ¨ç©ºé–“ã‹ã‚‰ã®ç”»åƒç”Ÿæˆ</li>
<li>è¨“ç·´ã®ä¸å®‰å®šæ€§ã¨ãã®å¯¾ç­–</li>
</ul>
</details>

<details>
<summary><strong>2. Mode Collapseå•é¡Œ</strong></summary>
<ul>
<li>ç”Ÿæˆã®å¤šæ§˜æ€§ãŒå¤±ã‚ã‚Œã‚‹ç¾è±¡</li>
<li>åŸå› ï¼šå‹¾é…ã®ä¸å®‰å®šæ€§ã€ç›®çš„é–¢æ•°ã®å•é¡Œ</li>
<li>å¯¾ç­–ï¼šWGAN-GPã€Spectral Normã€Minibatch Discrimination</li>
<li>è©•ä¾¡æŒ‡æ¨™ï¼šISã€FIDã€Precision/Recall</li>
</ul>
</details>

<details>
<summary><strong>3. DCGAN</strong></summary>
<ul>
<li>ç•³ã¿è¾¼ã¿å±¤ã«ã‚ˆã‚‹å®‰å®šçš„ãªGAN</li>
<li>è¨­è¨ˆã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ï¼šPoolingå‰Šé™¤ã€BNé©ç”¨ã€å…¨çµåˆå±¤å‰Šé™¤</li>
<li>ç”»åƒç”Ÿæˆã§å„ªã‚ŒãŸæ€§èƒ½</li>
<li>å®Ÿè£…ãŒã‚·ãƒ³ãƒ—ãƒ«ã§ç†è§£ã—ã‚„ã™ã„</li>
</ul>
</details>

<details>
<summary><strong>4. è¨“ç·´ãƒ†ã‚¯ãƒ‹ãƒƒã‚¯</strong></summary>
<ul>
<li><strong>WGAN-GP</strong>ï¼šWassersteinè·é›¢ + Gradient Penalty</li>
<li><strong>Spectral Normalization</strong>ï¼šLipschitzåˆ¶ç´„ã®è‡ªå‹•æº€è¶³</li>
<li><strong>Label Smoothing</strong>ï¼šDiscriminatorã®éä¿¡é˜²æ­¢</li>
<li>ã“ã‚Œã‚‰ã‚’çµ„ã¿åˆã‚ã›ã¦å®‰å®šã—ãŸè¨“ç·´ã‚’å®Ÿç¾</li>
</ul>
</details>

<details>
<summary><strong>5. StyleGAN</strong></summary>
<ul>
<li>é«˜å“è³ªç”»åƒç”Ÿæˆï¼ˆ1024Ã—1024ä»¥ä¸Šï¼‰</li>
<li>Mapping Networkã§è§£ãã‚„ã™ã„æ½œåœ¨ç©ºé–“</li>
<li>AdaINã«ã‚ˆã‚‹éšå±¤çš„ã‚¹ã‚¿ã‚¤ãƒ«åˆ¶å¾¡</li>
<li>ã‚¹ã‚¿ã‚¤ãƒ«æ··åˆã§å¤šæ§˜ãªç”»åƒç”Ÿæˆ</li>
</ul>
</details>

<h3>Next Steps</h3>

<p>æ¬¡ Chapterã§ã¯ã€ã‚ˆã‚Šé«˜åº¦ãªGenerative Modelsã«é€²ã¿ã¾ã™ï¼š</p>

<ul>
<li>Conditional GANï¼ˆæ¡ä»¶ä»˜ãç”Ÿæˆï¼‰</li>
<li>pix2pixã€CycleGANï¼ˆç”»åƒå¤‰æ›ï¼‰</li>
<li>BigGANã€Progressive GANï¼ˆå¤§è¦æ¨¡ãƒ»é«˜è§£åƒåº¦ï¼‰</li>
<li>GANä»¥å¤–ã®Generative Modelsï¼ˆVAEã€Diffusion Modelsï¼‰ã¨ã®æ¯”è¼ƒ</li>
</ul>

<hr>

<h2>Exercises</h2>

<details>
<summary><strong>å•é¡Œ1: Nashå‡è¡¡ã®ç†è§£</strong></summary>
<p><strong>è³ªå•</strong>ï¼šGANãŒNashå‡è¡¡ã«åˆ°é”ã—ãŸå ´åˆã€ä»¥ä¸‹ã®æ¡ä»¶ãŒã©ã†ãªã‚‹ã‹èª¬æ˜ã—ã¦ãã ã•ã„ã€‚</p>
<ol>
<li>Discriminatorã®å‡ºåŠ› $D(\mathbf{x})$ ã®å€¤</li>
<li>ç”Ÿæˆ minuteså¸ƒ $p_g(\mathbf{x})$ ã¨çœŸã® minuteså¸ƒ $p_{\text{data}}(\mathbf{x})$ ã®é–¢ä¿‚</li>
<li>Generatorã®æå¤±ã®çŠ¶æ…‹</li>
<li>è¨“ç·´ãŒç¶™ç¶šã§ãã‚‹ã‹</li>
</ol>

<p><strong>è§£ç­”ä¾‹</strong>ï¼š</p>

<p><strong>1. Discriminatorã®å‡ºåŠ›</strong></p>
<ul>
<li>$D(\mathbf{x}) = 0.5$ ï¼ˆã™ã¹ã¦ã®å…¥åŠ›ã«å¯¾ã—ã¦ï¼‰</li>
<li>ç†ç”±ï¼šæœ¬ç‰©ã¨å½ç‰©ãŒåŒºåˆ¥ã§ããªã„çŠ¶æ…‹</li>
<li>ç†è«–çš„å°å‡ºï¼š$D^*(\mathbf{x}) = \frac{p_{\text{data}}(\mathbf{x})}{p_{\text{data}}(\mathbf{x}) + p_g(\mathbf{x})} = 0.5$</li>
</ul>

<p><strong>2.  minuteså¸ƒã®é–¢ä¿‚</strong></p>
<ul>
<li>$p_g(\mathbf{x}) = p_{\text{data}}(\mathbf{x})$ ï¼ˆå®Œå…¨ã«ä¸€è‡´ï¼‰</li>
<li>GeneratorãŒçœŸã®ãƒ‡ãƒ¼ã‚¿ minuteså¸ƒã‚’å®Œç’§ã«æ¨¡å€£</li>
<li>KL divergence: $D_{KL}(p_{\text{data}} \| p_g) = 0$</li>
</ul>

<p><strong>3. Generatorã®æå¤±</strong></p>
<ul>
<li>æœ€å°å€¤ã«åˆ°é”ï¼ˆç†è«–çš„ã«ã¯ï¼‰</li>
<li>$\mathcal{L}_G = -\log(0.5) = \log(2) \approx 0.693$</li>
<li>ã“ã‚Œä»¥ä¸Šæ”¹å–„ã™ã‚‹ä½™åœ°ãŒãªã„</li>
</ul>

<p><strong>4. è¨“ç·´ã®ç¶™ç¶š</strong></p>
<ul>
<li>ç†è«–ä¸Šã¯è¨“ç·´çµ‚äº†ï¼ˆåæŸï¼‰</li>
<li>å®Ÿéš›ã«ã¯å®Œå…¨ãªNashå‡è¡¡ã«ã¯åˆ°é”ã—ãªã„</li>
<li>æŒ¯å‹•ã‚„å¾®å°ãªæ”¹å–„ãŒç¶šãå¯èƒ½æ€§</li>
</ul>
</details>

<details>
<summary><strong>å•é¡Œ2: Mode Collapseã®æ¤œå‡ºã¨å¯¾ç­–</strong></summary>
<p><strong>è³ªå•</strong>ï¼šMNISTãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆ10ã‚¯ãƒ©ã‚¹ã®æ‰‹æ›¸ãæ•°å­—ï¼‰ã§GANã‚’è¨“ç·´ã—ãŸã¨ã“ã‚ã€ç”Ÿæˆç”»åƒãŒæ•°å­—ã®ã€Œ1ã€ã¨ã€Œ7ã€ã°ã‹ã‚Šã«ãªã‚Šã¾ã—ãŸã€‚ä»¥ä¸‹ã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚</p>
<ol>
<li>ã“ã®ç¾è±¡ã®åå‰ã¨åŸå› </li>
<li>ã©ã®ã‚ˆã†ã«æ¤œå‡ºã§ãã‚‹ã‹ï¼ˆ3ã¤ã®æ–¹æ³•ï¼‰</li>
<li>å¯¾ç­–ã‚’3ã¤ææ¡ˆã—ã€ãã‚Œãã‚Œã®åŠ¹æœã‚’èª¬æ˜</li>
</ol>

<p><strong>è§£ç­”ä¾‹</strong>ï¼š</p>

<p><strong>1. ç¾è±¡ã¨åŸå› </strong></p>
<ul>
<li><strong>ç¾è±¡</strong>ï¼šMode Collapseï¼ˆãƒ¢ãƒ¼ãƒ‰å´©å£Šï¼‰</li>
<li><strong>åŸå› </strong>ï¼š
<ul>
<li>GeneratorãŒã€Œ1ã€ã¨ã€Œ7ã€ã§Discriminatorã‚’é¨™ã›ã‚‹ã“ã¨ã‚’ç™ºè¦‹</li>
<li>ä»–ã®æ•°å­—ã‚ˆã‚Šå­¦ç¿’ãŒç°¡å˜ï¼ˆã‚·ãƒ³ãƒ—ãƒ«ãªå½¢çŠ¶ï¼‰</li>
<li>å‹¾é…ã®ä¸å®‰å®šæ€§ã«ã‚ˆã‚Šå±€æ‰€æœ€é©è§£ã«é™¥ã‚‹</li>
</ul>
</li>
</ul>

<p><strong>2. æ¤œå‡ºæ–¹æ³•</strong></p>
<ul>
<li><strong>è¦–è¦šçš„æ¤œæŸ»</strong>ï¼šç”Ÿæˆç”»åƒã‚’ç¢ºèªã—ã€å¤šæ§˜æ€§ã®æ¬ å¦‚ã‚’è¦³å¯Ÿ</li>
<li><strong>ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°</strong>ï¼šç”Ÿæˆç”»åƒã‚’k-meansã§ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã€ã‚¯ãƒ©ã‚¹ã‚¿æ•°ãŒå°‘ãªã„ï¼ˆ2ï¼‰</li>
<li><strong>Inception Score</strong>ï¼šå¤šæ§˜æ€§ãŒä½ã„ãŸã‚ã€ISã‚¹ã‚³ã‚¢ãŒä½ä¸‹</li>
</ul>

<p><strong>3. å¯¾ç­–</strong></p>

<p><strong>å¯¾ç­–A: WGAN-GPé©ç”¨</strong></p>
<ul>
<li>Wassersteinè·é›¢ + Gradient Penaltyã§è¨“ç·´ã‚’å®‰å®šåŒ–</li>
<li>åŠ¹æœï¼šå‹¾é…ã®çˆ†ç™ºãƒ»æ¶ˆå¤±ã‚’é˜²ãã€å…¨ãƒ¢ãƒ¼ãƒ‰ã‚’å­¦ç¿’ã—ã‚„ã™ããªã‚‹</li>
<li>å®Ÿè£…ï¼šDiscriminatorã®å‡ºåŠ›å±¤ã‹ã‚‰Sigmoidã‚’å‰Šé™¤ã€GPé …ã‚’è¿½åŠ </li>
</ul>

<p><strong>å¯¾ç­–B: Minibatch Discrimination</strong></p>
<ul>
<li>ãƒãƒƒãƒå†…ã®ã‚µãƒ³ãƒ—ãƒ«é–“ã®é¡ä¼¼åº¦ã‚’Discriminatorã«è¿½åŠ æƒ…å ±ã¨ã—ã¦æä¾›</li>
<li>åŠ¹æœï¼šGeneratorãŒåŒã˜ã‚µãƒ³ãƒ—ãƒ«ã°ã‹ã‚Šç”Ÿæˆã™ã‚‹ã¨ã€DiscriminatorãŒè¦‹ç ´ã‚Šã‚„ã™ããªã‚‹</li>
<li>å®Ÿè£…ï¼šãƒãƒƒãƒçµ±è¨ˆé‡ã‚’è¨ˆç®—ã—ã¦Discriminatorã®å…¥åŠ›ã«é€£çµ</li>
</ul>

<p><strong>å¯¾ç­–C: Two Timescale Update Rule</strong></p>
<ul>
<li>Discriminatorã‚’Generatorã‚ˆã‚Šå¤šãè¨“ç·´ï¼ˆä¾‹ï¼š5å›å¯¾1å›ï¼‰</li>
<li>åŠ¹æœï¼šDiscriminatorãŒå¸¸ã«å¼·ã„çŠ¶æ…‹ã‚’ä¿ã¡ã€GeneratorãŒå…¨ãƒ¢ãƒ¼ãƒ‰ã‚’æ¢ç´¢</li>
<li>å®Ÿè£…ï¼šè¨“ç·´ãƒ«ãƒ¼ãƒ—ã§D_stepsãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¨­å®š</li>
</ul>
</details>

<details>
<summary><strong>å•é¡Œ3: WGAN-GPã¨Spectral Normalizationã®æ¯”è¼ƒ</strong></summary>
<p><strong>è³ªå•</strong>ï¼šä»¥ä¸‹ã®è¦³ç‚¹ã‹ã‚‰ã€WGAN-GPã¨Spectral Normalizationã‚’æ¯”è¼ƒã—ã¦ãã ã•ã„ã€‚</p>
<ol>
<li>Lipschitzåˆ¶ç´„ã®å®Ÿç¾æ–¹æ³•</li>
<li>è¨ˆç®—ã‚³ã‚¹ãƒˆ</li>
<li>å®Ÿè£…ã®è¤‡é›‘ã•</li>
<li>è¨“ç·´ã®å®‰å®šæ€§</li>
<li>ã©ã¡ã‚‰ã‚’é¸ã¶ã¹ãã‹ï¼ˆçŠ¶æ³åˆ¥ï¼‰</li>
</ol>

<p><strong>è§£ç­”ä¾‹</strong>ï¼š</p>

<p><strong>1. Lipschitzåˆ¶ç´„ã®å®Ÿç¾æ–¹æ³•</strong></p>
<ul>
<li><strong>WGAN-GP</strong>ï¼š
<ul>
<li>Gradient Penaltyã§å‹¾é…ãƒãƒ«ãƒ ã‚’1ã«åˆ¶ç´„</li>
<li>è¨“ç·´æ™‚ã«è£œé–“ç‚¹ã§å‹¾é…ã‚’è¨ˆç®—</li>
<li>ã‚½ãƒ•ãƒˆåˆ¶ç´„ï¼ˆãƒšãƒŠãƒ«ãƒ†ã‚£é …ã¨ã—ã¦è¿½åŠ ï¼‰</li>
</ul>
</li>
<li><strong>Spectral Norm</strong>ï¼š
<ul>
<li>å„å±¤ã®é‡ã¿è¡Œåˆ—ã®ã‚¹ãƒšã‚¯ãƒˆãƒ«ãƒãƒ«ãƒ ã‚’1ã«æ­£è¦åŒ–</li>
<li>é‡ã¿ãã®ã‚‚ã®ã‚’åˆ¶ç´„</li>
<li>ãƒãƒ¼ãƒ‰åˆ¶ç´„ï¼ˆç›´æ¥çš„ãªæ­£è¦åŒ–ï¼‰</li>
</ul>
</li>
</ul>

<p><strong>2. è¨ˆç®—ã‚³ã‚¹ãƒˆ</strong></p>
<ul>
<li><strong>WGAN-GP</strong>ï¼š
<ul>
<li>å„ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§GPè¨ˆç®—ãŒå¿…è¦ï¼ˆè£œé–“+é€†ä¼æ’­ï¼‰</li>
<li>è¨“ç·´æ™‚ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ï¼šç´„30-50%å¢—</li>
</ul>
</li>
<li><strong>Spectral Norm</strong>ï¼š
<ul>
<li>Power Iterationã§æœ€å¤§ç‰¹ç•°å€¤ã‚’æ¨å®š</li>
<li>è¨“ç·´æ™‚ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ï¼šç´„5-10%å¢—</li>
<li>æ¨è«–æ™‚ã¯ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ãªã—</li>
</ul>
</li>
</ul>

<p><strong>3. å®Ÿè£…ã®è¤‡é›‘ã•</strong></p>
<ul>
<li><strong>WGAN-GP</strong>ï¼š
<ul>
<li>è£œé–“ç‚¹ã®ç”Ÿæˆã€å‹¾é…è¨ˆç®—ã€GPé …ã®è¿½åŠ ãŒå¿…è¦</li>
<li>å®Ÿè£…ãŒã‚„ã‚„è¤‡é›‘ï¼ˆç´„50è¡Œã®ã‚³ãƒ¼ãƒ‰ï¼‰</li>
</ul>
</li>
<li><strong>Spectral Norm</strong>ï¼š
<ul>
<li>PyTorchã®<code>spectral_norm()</code>ã‚’å±¤ã«é©ç”¨ã™ã‚‹ã ã‘</li>
<li>å®Ÿè£…ãŒéå¸¸ã«ã‚·ãƒ³ãƒ—ãƒ«ï¼ˆ1è¡Œã§å®Œäº†ï¼‰</li>
</ul>
</li>
</ul>

<p><strong>4. è¨“ç·´ã®å®‰å®šæ€§</strong></p>
<ul>
<li><strong>WGAN-GP</strong>ï¼š
<ul>
<li>Wassersteinè·é›¢ã«ã‚ˆã‚‹æ„å‘³ã®ã‚ã‚‹æå¤±</li>
<li>Mode Collapseè»½æ¸›ã«åŠ¹æœçš„</li>
<li>Î»ï¼ˆGPä¿‚æ•°ï¼‰ã®èª¿æ•´ãŒå¿…è¦</li>
</ul>
</li>
<li><strong>Spectral Norm</strong>ï¼š
<ul>
<li>å…¨å±¤ã§ä¸€è²«ã—ãŸLipschitzåˆ¶ç´„</li>
<li>HyperparameterãŒå°‘ãªã„ï¼ˆèª¿æ•´ä¸è¦ï¼‰</li>
<li>å®‰å®šæ€§ãŒé«˜ã„</li>
</ul>
</li>
</ul>

<p><strong>5. é¸æŠåŸºæº–</strong></p>
<ul>
<li><strong>WGAN-GPã‚’é¸ã¶å ´åˆ</strong>ï¼š
<ul>
<li>ç†è«–çš„ãªä¿è¨¼ãŒé‡è¦</li>
<li>Wassersteinè·é›¢ã‚’æå¤±ã¨ã—ã¦ä½¿ã„ãŸã„</li>
<li>è¨ˆç®—ãƒªã‚½ãƒ¼ã‚¹ã«ä½™è£•ãŒã‚ã‚‹</li>
</ul>
</li>
<li><strong>Spectral Normã‚’é¸ã¶å ´åˆ</strong>ï¼š
<ul>
<li>ã‚·ãƒ³ãƒ—ãƒ«ãªå®Ÿè£…ã‚’å„ªå…ˆ</li>
<li>è¨ˆç®—åŠ¹ç‡ãŒé‡è¦</li>
<li>ç´ æ—©ããƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ã‚’ä½œã‚ŠãŸã„</li>
<li>ç¾ä»£çš„ãªé¸æŠï¼ˆæœ€è¿‘ã®è«–æ–‡ã§å¤šç”¨ï¼‰</li>
</ul>
</li>
</ul>
</details>

<details>
<summary><strong>å•é¡Œ4: StyleGANã®ã‚¹ã‚¿ã‚¤ãƒ«æ··åˆ</strong></summary>
<p><strong>è³ªå•</strong>ï¼šStyleGANã§2ã¤ã®æ½œåœ¨ãƒ™ã‚¯ãƒˆãƒ« $\mathbf{z}_A$ ã¨ $\mathbf{z}_B$ ã‹ã‚‰ã€ã€ŒAã®é¡”ã®å½¢ + Bã®è¡¨æƒ…ã¨é«ªå‹ã€ã‚’æŒã¤ç”»åƒã‚’ç”Ÿæˆã—ãŸã„å ´åˆã€ã©ã®ã‚ˆã†ã«å®Ÿè£…ã—ã¾ã™ã‹ï¼Ÿ</p>
<ol>
<li>æ½œåœ¨ãƒ™ã‚¯ãƒˆãƒ«ã®ãƒãƒƒãƒ”ãƒ³ã‚°æ‰‹é †</li>
<li>ã©ã®è§£åƒåº¦å±¤ã§ã‚¹ã‚¿ã‚¤ãƒ«ã‚’åˆ‡ã‚Šæ›¿ãˆã‚‹ã‹</li>
<li>å®Ÿè£…ã‚³ãƒ¼ãƒ‰ã®æ¦‚è¦</li>
</ol>

<p><strong>è§£ç­”ä¾‹</strong>ï¼š</p>

<p><strong>1. ãƒãƒƒãƒ”ãƒ³ã‚°æ‰‹é †</strong></p>
<ul>
<li>$\mathbf{z}_A \rightarrow$ Mapping Network $\rightarrow \mathbf{w}_A$</li>
<li>$\mathbf{z}_B \rightarrow$ Mapping Network $\rightarrow \mathbf{w}_B$</li>
<li>å„è§£åƒåº¦å±¤ã§ç•°ãªã‚‹ $\mathbf{w}$ ã‚’ä½¿ç”¨</li>
</ul>

<p><strong>2. ã‚¹ã‚¿ã‚¤ãƒ«åˆ‡ã‚Šæ›¿ãˆãƒã‚¤ãƒ³ãƒˆ</strong></p>
<ul>
<li><strong>ç²—ã„ã‚¹ã‚¿ã‚¤ãƒ«ï¼ˆ4Ã—4ã€œ8Ã—8ï¼‰</strong>ï¼š$\mathbf{w}_A$ ã‚’ä½¿ç”¨
<ul>
<li>é¡”ã®å‘ãã€å…¨ä½“çš„ãªå½¢çŠ¶</li>
<li>Aã®ã€Œé¡”ã®å½¢ã€ã‚’ä¿æŒ</li>
</ul>
</li>
<li><strong>ä¸­é–“ã€œç´°ã‹ã„ã‚¹ã‚¿ã‚¤ãƒ«ï¼ˆ16Ã—16ã€œ1024Ã—1024ï¼‰</strong>ï¼š$\mathbf{w}_B$ ã‚’ä½¿ç”¨
<ul>
<li>è¡¨æƒ…ã€ç›®ã®é–‹ãã€é«ªå‹ã€è‚Œã®è³ªæ„Ÿ</li>
<li>Bã®ã€Œè¡¨æƒ…ã¨é«ªå‹ã€ã‚’é©ç”¨</li>
</ul>
</li>
</ul>

<p><strong>3. å®Ÿè£…ã‚³ãƒ¼ãƒ‰æ¦‚è¦</strong></p>
<pre><code class="language-python"># Mapping Network
w_A = mapping_network(z_A)
w_B = mapping_network(z_B)

# åˆæœŸã®å®šæ•°å…¥åŠ›
x = constant_input  # 4Ã—4

# ç²—ã„ã‚¹ã‚¿ã‚¤ãƒ«ï¼ˆAã®é¡”ã®å½¢ï¼‰
x = synthesis_block_4x4(x, w_A)  # 4Ã—4
x = synthesis_block_8x8(x, w_A)  # 8Ã—8

# ä¸­é–“ã€œç´°ã‹ã„ã‚¹ã‚¿ã‚¤ãƒ«ï¼ˆBã®è¡¨æƒ…ãƒ»é«ªå‹ï¼‰
x = synthesis_block_16x16(x, w_B)  # 16Ã—16
x = synthesis_block_32x32(x, w_B)  # 32Ã—32
x = synthesis_block_64x64(x, w_B)  # 64Ã—64
# ...ä»¥é™ã‚‚ w_B ã‚’ä½¿ç”¨

generated_image = x
</code></pre>

<p><strong>åŠ¹æœ</strong>ï¼š</p>
<ul>
<li>Aã®é¡”ã®åŸºæœ¬æ§‹é€ ã‚’ç¶­æŒã—ãªãŒã‚‰ã€Bã®è¡¨æƒ…ã¨é«ªå‹ãŒåæ˜ ã•ã‚Œã‚‹</li>
<li>ã‚¹ã‚¿ã‚¤ãƒ«æ··åˆã«ã‚ˆã‚Šç„¡é™ã®ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ãŒå¯èƒ½</li>
<li>åˆ‡ã‚Šæ›¿ãˆè§£åƒåº¦ã‚’å¤‰ãˆã‚‹ã“ã¨ã§ç•°ãªã‚‹åŠ¹æœã‚’å®Ÿç¾</li>
</ul>
</details>

<details>
<summary><strong>å•é¡Œ5: GANã®è©•ä¾¡æŒ‡æ¨™</strong></summary>
<p><strong>è³ªå•</strong>ï¼šä»¥ä¸‹ã®3ã¤ã®GANãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ã©ã®æŒ‡æ¨™ã‚’ã©ã®ã‚ˆã†ã«ä½¿ã†ã¹ãã‹èª¬æ˜ã—ã¦ãã ã•ã„ã€‚</p>

<ul>
<li><strong>ãƒ¢ãƒ‡ãƒ«A</strong>ï¼šIS = 8.5, FID = 25, Precision = 0.85, Recall = 0.60</li>
<li><strong>ãƒ¢ãƒ‡ãƒ«B</strong>ï¼šIS = 6.2, FID = 18, Precision = 0.75, Recall = 0.82</li>
<li><strong>ãƒ¢ãƒ‡ãƒ«C</strong>ï¼šIS = 7.8, FID = 15, Precision = 0.80, Recall = 0.78</li>
</ul>

<ol>
<li>å„æŒ‡æ¨™ã®æ„å‘³</li>
<li>ã©ã®ãƒ¢ãƒ‡ãƒ«ãŒæœ€é©ã‹ï¼ˆç”¨é€”åˆ¥ï¼‰</li>
<li>ç·åˆçš„ãªRecommendedãƒ¢ãƒ‡ãƒ«</li>
</ol>

<p><strong>è§£ç­”ä¾‹</strong>ï¼š</p>

<p><strong>1. å„æŒ‡æ¨™ã®æ„å‘³</strong></p>
<ul>
<li><strong>Inception Score (IS)</strong>ï¼š
<ul>
<li>ç”»åƒã®å“è³ªã¨å¤šæ§˜æ€§ã®çµ„ã¿åˆã‚ã›</li>
<li>é«˜ã„å€¤ = é«˜å“è³ªã§å¤šæ§˜</li>
<li>é™ç•Œï¼šçœŸã®ãƒ‡ãƒ¼ã‚¿ minuteså¸ƒã‚’è€ƒæ…®ã—ãªã„</li>
</ul>
</li>
<li><strong>Frechet Inception Distance (FID)</strong>ï¼š
<ul>
<li>ç”Ÿæˆ minuteså¸ƒã¨çœŸã® minuteså¸ƒã®è·é›¢</li>
<li>ä½ã„å€¤ = çœŸã®ãƒ‡ãƒ¼ã‚¿ã«è¿‘ã„</li>
<li>æœ€ã‚‚ä¿¡é ¼æ€§ãŒé«˜ã„æŒ‡æ¨™</li>
</ul>
</li>
<li><strong>Precision</strong>ï¼š
<ul>
<li>ç”Ÿæˆç”»åƒã®å“è³ªï¼ˆæœ¬ç‰©ã‚‰ã—ã•ï¼‰</li>
<li>é«˜ã„ = é«˜å“è³ªã ãŒã€å¤šæ§˜æ€§ã¯ä¿è¨¼ã•ã‚Œãªã„</li>
</ul>
</li>
<li><strong>Recall</strong>ï¼š
<ul>
<li>ç”Ÿæˆç”»åƒã®å¤šæ§˜æ€§ï¼ˆã‚«ãƒãƒ¬ãƒƒã‚¸ï¼‰</li>
<li>é«˜ã„ = å¤šæ§˜ã ãŒã€å“è³ªã¯ä¿è¨¼ã•ã‚Œãªã„</li>
</ul>
</li>
</ul>

<p><strong>2. ç”¨é€”åˆ¥ã®æœ€é©ãƒ¢ãƒ‡ãƒ«</strong></p>
<ul>
<li><strong>é«˜å“è³ªç”»åƒç”ŸæˆãŒæœ€å„ªå…ˆï¼ˆä¾‹ï¼šåºƒå‘Šç´ æï¼‰</strong>ï¼š
<ul>
<li>ãƒ¢ãƒ‡ãƒ«Aï¼ˆPrecision = 0.85ãŒæœ€é«˜ï¼‰</li>
<li>ç†ç”±ï¼šã€…ã®ç”»åƒå“è³ªãŒé‡è¦ã€å¤šæ§˜æ€§ã¯äºŒã®æ¬¡</li>
</ul>
</li>
<li><strong>ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µï¼ˆä¾‹ï¼šè¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®è£œå®Œï¼‰</strong>ï¼š
<ul>
<li>ãƒ¢ãƒ‡ãƒ«Bï¼ˆRecall = 0.82ãŒæœ€é«˜ï¼‰</li>
<li>ç†ç”±ï¼šå¤šæ§˜ãªã‚µãƒ³ãƒ—ãƒ«ãŒå¿…è¦ã€å¤šå°‘ã®å“è³ªä½ä¸‹ã¯è¨±å®¹</li>
</ul>
</li>
<li><strong>æ±ç”¨çš„ãªç”»åƒç”Ÿæˆ</strong>ï¼š
<ul>
<li>ãƒ¢ãƒ‡ãƒ«Cï¼ˆFID = 15ãŒæœ€ä½ã€ãƒãƒ©ãƒ³ã‚¹ãŒè‰¯ã„ï¼‰</li>
<li>ç†ç”±ï¼šå“è³ªã¨å¤šæ§˜æ€§ã®ãƒãƒ©ãƒ³ã‚¹ãŒå–ã‚Œã¦ã„ã‚‹</li>
</ul>
</li>
</ul>

<p><strong>3. ç·åˆçš„ãªRecommended</strong></p>
<ul>
<li><strong>Recommendedãƒ¢ãƒ‡ãƒ«ï¼šãƒ¢ãƒ‡ãƒ«C</strong></li>
<li>ç†ç”±ï¼š
<ul>
<li>FIDãŒæœ€ã‚‚ä½ã„ï¼ˆ15ï¼‰= çœŸã®ãƒ‡ãƒ¼ã‚¿ã«æœ€ã‚‚è¿‘ã„</li>
<li>Precision (0.80) ã¨ Recall (0.78) ãŒãƒãƒ©ãƒ³ã‚¹è‰¯ã„</li>
<li>ç‰¹å®šã®ç”¨é€”ã«åã‚‰ãªã„æ±ç”¨æ€§</li>
</ul>
</li>
<li><strong>ç·åˆè©•ä¾¡ã®è€ƒãˆæ–¹</strong>ï¼š
<ul>
<li>FIDã‚’æœ€å„ªå…ˆï¼ˆæœ€ã‚‚ä¿¡é ¼æ€§ãŒé«˜ã„ï¼‰</li>
<li>Precision/Recallã§å“è³ªã¨å¤šæ§˜æ€§ã®ãƒãƒ©ãƒ³ã‚¹ã‚’ç¢ºèª</li>
<li>ISã¯å‚è€ƒç¨‹åº¦ï¼ˆå˜ç‹¬ã§ã¯ä¸å minutesï¼‰</li>
</ul>
</li>
</ul>
</details>

<hr>

<div class="navigation">
    <a href="chapter2-vae.html" class="nav-button">â† Chapter 2: VAE (å¤‰ minutesã‚ªãƒ¼ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€)</a>
    <a href="chapter4-advanced-gans.html" class="nav-button">Chapter 4 Chapterï¼šé«˜åº¦ãªGANã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ â†’</a>
</div>

    </main>

    
    <section class="disclaimer">
        <h3>Disclaimer</h3>
        <ul>
            <li>This content is provided solely for educational, research, and informational purposes and does not constitute professional advice (legal, accounting, technical guarantees, etc.).</li>
            <li>This content and accompanying code examples are provided "AS IS" without warranty of any kind, either express or implied, including but not limited to merchantability, fitness for a particular purpose, non-infringement, accuracy, completeness, operation, or safety.</li>
            <li>The creators and Tohoku University assume no responsibility for the content, availability, or safety of external links, third-party data, tools, libraries, etc.</li>
            <li>To the maximum extent permitted by applicable law, the creators and Tohoku University shall not be liable for any direct, indirect, incidental, special, consequential, or punitive damages arising from the use, execution, or interpretation of this content.</li>
            <li>The content of this material may be changed, updated, or discontinued without notice.</li>
            <li>The copyright and license of this content are subject to the specified terms (e.g., CC BY 4.0). Such licenses typically include warranty disclaimers.</li>
        </ul>
    </section>

<footer>
        <p>&copy; 2025 AI Terakoya. All rights reserved.</p>
        <p>ML-A04: Generative Modelså…¥é–€ - GANã§ç¾å®Ÿçš„ãªç”»åƒã‚’ç”Ÿæˆã—ã‚ˆã†</p>
    </footer>

</body>
</html>
