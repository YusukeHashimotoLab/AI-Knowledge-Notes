<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Introduction to Unsupervised Learning Series - Complete Guide">
    <title>Introduction to Unsupervised Learning Series v1.0 - AI Terakoya</title>

    <!-- CSS Styling -->
        <link rel="stylesheet" href="../../assets/css/knowledge-base.css">

    <!-- Mermaid for diagrams -->
    <script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
    <script>
        // Mermaid.js Converter - Converts markdown-style mermaid code blocks to renderable divs
        document.addEventListener('DOMContentLoaded', function() {
            // Find all code blocks with class="language-mermaid"
            const mermaidCodeBlocks = document.querySelectorAll('pre.codehilite code.language-mermaid, pre code.language-mermaid');

            mermaidCodeBlocks.forEach(function(codeBlock) {
                const pre = codeBlock.parentElement;
                const mermaidCode = codeBlock.textContent;

                // Create a new div with mermaid class
                const mermaidDiv = document.createElement('div');
                mermaidDiv.className = 'mermaid';
                mermaidDiv.textContent = mermaidCode.trim();

                // Replace the pre element with the new div
                pre.parentNode.replaceChild(mermaidDiv, pre);
            });

            // Re-initialize mermaid after conversion
            if (typeof mermaid !== 'undefined') {
                mermaid.initialize({ startOnLoad: true, theme: 'default' });
                mermaid.init(undefined, document.querySelectorAll('.mermaid'));
            }
        });
    </script>
</head>
<body>
            <nav class="breadcrumb">
        <div class="breadcrumb-content">
            <a href="../../index.html">AI Terakoya Top</a><span class="breadcrumb-separator">‚Ä∫</span><a href="../index.html">Machine Learning</a><span class="breadcrumb-separator">‚Ä∫</span><span class="breadcrumb-current">Unsupervised Learning</span>
        </div>
    </nav>

        <header>
        <div class="container">
            <h1>üîç Introduction to Unsupervised Learning Series v1.0</h1>
            <p style="font-size: 1.1rem; margin-top: 0.5rem; opacity: 0.95;">From Clustering, Dimensionality Reduction, and Anomaly Detection Fundamentals to Practice</p>
            <div class="meta">
                <span>üìñ Total Learning Time: 70-90 minutes</span>
                <span>üìä Level: Beginner to Intermediate</span>
            </div>
        </div>
    </header>

    <main class="container">
        <p><strong>Techniques for extracting valuable insights from unlabeled data</strong></p>

        <h2 id="overview">Series Overview</h2>
        <p>This series is a practical educational content consisting of 4 chapters that allows you to learn unsupervised learning step by step from the basics.</p>

        <p><strong>Unsupervised Learning</strong> is a machine learning technique that discovers hidden patterns and structures from data without correct labels. Through techniques such as clustering, dimensionality reduction, and anomaly detection, it enables data understanding, visualization, compression, and anomaly detection, and is widely used in data analysis, marketing, security, and many other fields.</p>

        <p><strong>Features:</strong></p>
        <ul>
            <li>‚úÖ <strong>From basics to practice</strong>: Systematic learning from clustering fundamentals to customer segmentation</li>
            <li>‚úÖ <strong>Implementation-focused</strong>: 35+ executable Python code examples, practical projects</li>
            <li>‚úÖ <strong>Intuitive understanding</strong>: Understanding algorithm behavior through visualization</li>
            <li>‚úÖ <strong>scikit-learn utilization</strong>: Latest implementation methods using industry-standard libraries</li>
            <li>‚úÖ <strong>Practical project</strong>: Real-world problem solving through customer segmentation</li>
        </ul>

        <p><strong>Total Learning Time</strong>: 70-90 minutes (including code execution and exercises)</p>

        <h2 id="learning">How to Study</h2>

        <h3>Recommended Learning Order</h3>

        <div class="mermaid">
graph TD
    A[Chapter 1: Clustering Fundamentals] --> B[Chapter 2: Introduction to Dimensionality Reduction]
    B --> C[Chapter 3: Anomaly Detection]
    C --> D[Chapter 4: Practical Project]

    style A fill:#e3f2fd
    style B fill:#fff3e0
    style C fill:#f3e5f5
    style D fill:#e8f5e9
</div>

        <p><strong>For Beginners (completely new to unsupervised learning):</strong><br>
        - Chapter 1 ‚Üí Chapter 2 ‚Üí Chapter 3 ‚Üí Chapter 4 (all chapters recommended)<br>
        - Duration: 70-90 minutes</p>

        <p><strong>For Intermediate learners (with machine learning experience):</strong><br>
        - Chapter 2 ‚Üí Chapter 3 ‚Üí Chapter 4<br>
        - Duration: 50-60 minutes</p>

        <p><strong>Practical skill enhancement (implementation-focused rather than theory):</strong><br>
        - Chapter 4 (intensive learning)<br>
        - Duration: 25-30 minutes</p>

        <h2 id="chapters">Chapter Details</h2>

        <h3><a href="./chapter1-clustering.html">Chapter 1: Clustering Fundamentals</a></h3>
        <p><strong>Difficulty</strong>: Beginner<br>
        <strong>Reading Time</strong>: 20-25 minutes<br>
        <strong>Code Examples</strong>: 10</p>

        <h4>Learning Content</h4>
        <ol>
            <li><strong>What is Clustering</strong> - Techniques for grouping data</li>
            <li><strong>K-means Algorithm</strong> - The most basic clustering method</li>
            <li><strong>Hierarchical Clustering</strong> - Dendrograms and hierarchical cluster structure</li>
            <li><strong>DBSCAN Algorithm</strong> - Density-based clustering</li>
            <li><strong>Cluster Evaluation</strong> - Silhouette coefficient, elbow method</li>
        </ol>

        <h4>Learning Objectives</h4>
        <ul>
            <li>‚úÖ Understand the concept and application examples of clustering</li>
            <li>‚úÖ Implement K-means in Python</li>
            <li>‚úÖ Create dendrograms with hierarchical clustering</li>
            <li>‚úÖ Detect arbitrarily shaped clusters with DBSCAN</li>
            <li>‚úÖ Determine the appropriate number of clusters</li>
        </ul>

        <p><strong><a href="./chapter1-clustering.html">Read Chapter 1 ‚Üí</a></strong></p>

        <hr>

        <h3><a href="./chapter2-dimensionality-reduction.html">Chapter 2: Introduction to Dimensionality Reduction</a></h3>
        <p><strong>Difficulty</strong>: Beginner to Intermediate<br>
        <strong>Reading Time</strong>: 20-25 minutes<br>
        <strong>Code Examples</strong>: 9</p>

        <h4>Learning Content</h4>
        <ol>
            <li><strong>What is Dimensionality Reduction</strong> - Visualization and compression of high-dimensional data</li>
            <li><strong>Principal Component Analysis (PCA)</strong> - Linear transformation that maximizes variance</li>
            <li><strong>t-SNE</strong> - Nonlinear dimensionality reduction and visualization</li>
            <li><strong>UMAP</strong> - Fast and flexible dimensionality reduction</li>
            <li><strong>Application Examples</strong> - Visualization of image data and text data</li>
        </ol>

        <h4>Learning Objectives</h4>
        <ul>
            <li>‚úÖ Explain the purpose and benefits of dimensionality reduction</li>
            <li>‚úÖ Extract principal components with PCA</li>
            <li>‚úÖ Visualize high-dimensional data in 2D with t-SNE</li>
            <li>‚úÖ Understand the features of UMAP and differences from t-SNE</li>
            <li>‚úÖ Select appropriate dimensionality reduction methods</li>
        </ul>

        <p><strong><a href="./chapter2-dimensionality-reduction.html">Read Chapter 2 ‚Üí</a></strong></p>

        <hr>

        <h3><a href="./chapter3-anomaly-detection.html">Chapter 3: Anomaly Detection</a></h3>
        <p><strong>Difficulty</strong>: Intermediate<br>
        <strong>Reading Time</strong>: 15-20 minutes<br>
        <strong>Code Examples</strong>: 8</p>

        <h4>Learning Content</h4>
        <ol>
            <li><strong>What is Anomaly Detection</strong> - Detecting deviations from normal patterns</li>
            <li><strong>Statistical Methods</strong> - Z-score, Interquartile Range (IQR)</li>
            <li><strong>Isolation Forest</strong> - Utilizing the isolation of anomalous data</li>
            <li><strong>One-Class SVM</strong> - Learning the boundary of normal data</li>
            <li><strong>Application Examples</strong> - Fraud detection, system monitoring, quality control</li>
        </ol>

        <h4>Learning Objectives</h4>
        <ul>
            <li>‚úÖ Understand types of anomaly detection and application areas</li>
            <li>‚úÖ Detect outliers with statistical methods</li>
            <li>‚úÖ Implement Isolation Forest</li>
            <li>‚úÖ Define normal regions with One-Class SVM</li>
            <li>‚úÖ Select appropriate anomaly detection methods</li>
        </ul>

        <p><strong><a href="./chapter3-anomaly-detection.html">Read Chapter 3 ‚Üí</a></strong></p>

        <hr>

        <h3><a href="./chapter4-customer-segmentation.html">Chapter 4: Practical Project - Customer Segmentation</a></h3>
        <p><strong>Difficulty</strong>: Intermediate<br>
        <strong>Reading Time</strong>: 25-30 minutes<br>
        <strong>Code Examples</strong>: 10</p>

        <h4>Learning Content</h4>
        <ol>
            <li><strong>Project Overview</strong> - Analysis and grouping of customer data</li>
            <li><strong>Data Preprocessing</strong> - Missing value handling, normalization, feature engineering</li>
            <li><strong>Exploratory Data Analysis (EDA)</strong> - Understanding data distribution and correlation</li>
            <li><strong>Clustering Implementation</strong> - Comparison of K-means and hierarchical clustering</li>
            <li><strong>Visualization through Dimensionality Reduction</strong> - Visualizing clusters with PCA and t-SNE</li>
            <li><strong>Segment Interpretation</strong> - Deriving business value</li>
        </ol>

        <h4>Learning Objectives</h4>
        <ul>
            <li>‚úÖ Appropriately preprocess customer data</li>
            <li>‚úÖ Compare and evaluate multiple clustering methods</li>
            <li>‚úÖ Visualize and interpret clusters</li>
            <li>‚úÖ Analyze characteristics of each segment</li>
            <li>‚úÖ Obtain insights that can be utilized in business strategies</li>
        </ul>

        <p><strong><a href="./chapter4-customer-segmentation.html">Read Chapter 4 ‚Üí</a></strong></p>

        <hr>

        <h2 id="outcomes">Overall Learning Outcomes</h2>

        <p>Upon completing this series, you will acquire the following skills and knowledge:</p>

        <h3>Knowledge Level (Understanding)</h3>
        <ul>
            <li>‚úÖ Explain basic concepts and application areas of unsupervised learning</li>
            <li>‚úÖ Understand the mechanisms of clustering, dimensionality reduction, and anomaly detection</li>
            <li>‚úÖ Explain the characteristics and use cases of each method</li>
            <li>‚úÖ Intuitively understand the operating principles of algorithms</li>
            <li>‚úÖ Understand scikit-learn's API and design philosophy</li>
        </ul>

        <h3>Practical Skills (Doing)</h3>
        <ul>
            <li>‚úÖ Implement K-means, DBSCAN, and hierarchical clustering</li>
            <li>‚úÖ Visualize high-dimensional data with PCA, t-SNE, and UMAP</li>
            <li>‚úÖ Detect anomalies with Isolation Forest and One-Class SVM</li>
            <li>‚úÖ Calculate and interpret cluster evaluation metrics</li>
            <li>‚úÖ Build a complete pipeline for customer segmentation</li>
        </ul>

        <h3>Application Ability (Applying)</h3>
        <ul>
            <li>‚úÖ Select appropriate unsupervised learning methods for new problems</li>
            <li>‚úÖ Customize methods according to data characteristics</li>
            <li>‚úÖ Visualize results and derive business value</li>
            <li>‚úÖ Design hybrid methods combining supervised and unsupervised learning</li>
        </ul>

        <hr>

        <h2 id="prerequisites">Prerequisites</h2>

        <p>To effectively learn this series, it is desirable to have the following knowledge:</p>

        <h3>Required (Must Have)</h3>
        <ul>
            <li>‚úÖ <strong>Python Basics</strong>: Variables, functions, loops, conditionals</li>
            <li>‚úÖ <strong>NumPy Basics</strong>: Array manipulation, basic mathematical functions</li>
            <li>‚úÖ <strong>Machine Learning Overview</strong>: Differences between supervised and unsupervised learning</li>
        </ul>

        <h3>Recommended (Nice to Have)</h3>
        <ul>
            <li>üí° <strong>Pandas Basics</strong>: DataFrame manipulation, data preprocessing</li>
            <li>üí° <strong>Matplotlib/Seaborn</strong>: Basic graph creation</li>
            <li>üí° <strong>Linear Algebra Basics</strong>: Vectors, matrices, dot products (useful for understanding PCA)</li>
            <li>üí° <strong>Statistics Basics</strong>: Mean, variance, standard deviation</li>
        </ul>

        <p><strong>Recommended prior learning</strong>:</p>
        <ul>
            <li>üìö <a href="../supervised-learning-basics/">Supervised Learning Basics Series</a> - Basic concepts of machine learning</li>
            <li>üìö <a href="../data-preprocessing/">Data Preprocessing Series</a> - Data cleaning and feature engineering</li>
        </ul>

        <hr>

        <h2 id="tech">Technologies and Tools Used</h2>

        <h3>Main Libraries</h3>
        <ul>
            <li><strong>scikit-learn 1.3+</strong> - Clustering, dimensionality reduction, anomaly detection</li>
            <li><strong>NumPy 1.24+</strong> - Numerical computation</li>
            <li><strong>Pandas 2.0+</strong> - Data manipulation</li>
            <li><strong>Matplotlib 3.7+</strong> - Visualization</li>
            <li><strong>seaborn 0.12+</strong> - Statistical visualization</li>
            <li><strong>umap-learn</strong> - UMAP dimensionality reduction (optional)</li>
        </ul>

        <h3>Development Environment</h3>
        <ul>
            <li><strong>Python 3.8+</strong> - Programming language</li>
            <li><strong>Jupyter Notebook / Lab</strong> - Interactive development environment</li>
            <li><strong>Google Colab</strong> - Cloud environment (free GPU available)</li>
        </ul>

        <hr>

        <h2 id="start">Let's Get Started!</h2>
        <p>Are you ready? Start with Chapter 1 and begin your journey into the world of unsupervised learning!</p>

        <p><strong><a href="./chapter1-clustering.html">Chapter 1: Clustering Fundamentals ‚Üí</a></strong></p>

        <hr>

        <h2 id="next">Next Steps</h2>

        <p>After completing this series, we recommend proceeding to the following topics:</p>

        <h3>Deep Dive Learning</h3>
        <ul>
            <li>üìö <strong>Deep Learning for Unsupervised Learning</strong>: Autoencoder, VAE, GAN</li>
            <li>üìö <strong>Time Series Unsupervised Learning</strong>: Dynamic Time Warping (DTW), time series clustering</li>
            <li>üìö <strong>Text Analysis</strong>: Topic modeling (LDA), Word2Vec</li>
            <li>üìö <strong>Graph Clustering</strong>: Community detection, network analysis</li>
        </ul>

        <h3>Related Series</h3>
        <ul>
            <li>üéØ <a href="../neural-networks-introduction/">Introduction to Neural Networks</a> - Bridge to Autoencoders</li>
            <li>üéØ <a href="../deep-learning-advanced/">Advanced Deep Learning Applications</a> - Generative models (VAE, GAN)</li>
            <li>üéØ <a href="../ml-deployment/">Machine Learning Model Deployment</a> - Deployment to production</li>
        </ul>

        <h3>Practical Projects</h3>
        <ul>
            <li>üöÄ Image Segmentation - Clustering of image data</li>
            <li>üöÄ Recommendation System - Collaborative filtering</li>
            <li>üöÄ Fraud Detection System - Implementation of anomaly detection</li>
            <li>üöÄ Document Classification - Text clustering</li>
        </ul>

        <hr>

        <p><strong>Update History</strong></p>
        <ul>
            <li><strong>2025-10-20</strong>: v1.0 Initial release</li>
        </ul>

        <hr>

        <p><strong>Your journey into unsupervised learning starts here!</strong></p>

    </main>


    <section class="disclaimer">
        <h3>Disclaimer</h3>
        <ul>
            <li>This content is provided for educational, research, and informational purposes only, and does not constitute professional advice (legal, accounting, technical guarantees, etc.).</li>
            <li>This content and accompanying code examples are provided "AS IS" without any warranty, express or implied, including but not limited to merchantability, fitness for a particular purpose, non-infringement, accuracy, completeness, operation, and safety.</li>
            <li>The creators and Tohoku University assume no responsibility for the content, availability, or safety of external links, third-party data, tools, libraries, etc.</li>
            <li>To the maximum extent permitted by applicable law, the creators and Tohoku University shall not be liable for any direct, indirect, incidental, special, consequential, or punitive damages arising from the use, execution, or interpretation of this content.</li>
            <li>The content of this material may be changed, updated, or discontinued without notice.</li>
            <li>The copyright and license of this content are subject to the specified conditions (e.g., CC BY 4.0). Such licenses typically include no-warranty clauses.</li>
        </ul>
    </section>

<footer>
        <div class="container">
            <p>&copy; 2025 AI Terakoya - Dr. Yusuke Hashimoto, Tohoku University</p>
            <p>Licensed under CC BY 4.0</p>
        </div>
    </footer>
</body>
</html>
