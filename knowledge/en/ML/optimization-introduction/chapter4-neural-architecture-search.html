<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>Chapter 3: Neural Architecture Search - AI Terakoya</title>
<link href="../../assets/css/knowledge-base.css" rel="stylesheet"/>
<script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
        mermaid.initialize({ startOnLoad: true, theme: 'default' });
    </script>
<!-- MathJax for LaTeX equation rendering -->
<script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                displayMath: [['$$', '$$'], ['\\[', '\\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
                ignoreHtmlClass: 'mermaid'
            }
        };
    </script>
<script async="" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>
<nav class="breadcrumb">
<div class="breadcrumb-content">
<a href="../index.html">AI Terakoya Top</a><span class="breadcrumb-separator">‚Ä∫</span><a href="../../ML/index.html">Machine Learning</a><span class="breadcrumb-separator">‚Ä∫</span><a href="../../ML/automl-introduction/index.html">AutoML</a><span class="breadcrumb-separator">‚Ä∫</span><span class="breadcrumb-current">Chapter 3</span>
</div>
</nav><div class="locale-switcher">
<span class="current-locale">üåê EN</span>
<span class="locale-separator">|</span>
<span class="locale-link disabled">Êó•Êú¨Ë™û (Ê∫ñÂÇô‰∏≠)</span>
<span class="locale-meta">Last sync: 2025-11-16</span>
</div>
<header>
<div class="header-content">
<h1>Chapter 3: Neural Architecture Search</h1>
<p class="subtitle">Automated Neural Network Design - Exploring Optimal Architectures with DARTS and AutoKeras</p>
<div class="meta">
<span class="meta-item">üìñ Reading Time: 35-40 minutes</span>
<span class="meta-item">üìä Difficulty: Intermediate-Advanced</span>
<span class="meta-item">üíª Code Examples: 8</span>
<span class="meta-item">üìù Exercises: 5</span>
</div>
</div>
</header>
<main class="container">
<h2>Learning Objectives</h2>
<p>By completing this chapter, you will master the following:</p>
<ul>
<li>‚úÖ Understand the design of Neural Architecture Search (NAS) search spaces</li>
<li>‚úÖ Understand key NAS search strategies (reinforcement learning, evolutionary algorithms, gradient-based)</li>
<li>‚úÖ Implement automated model search using AutoKeras</li>
<li>‚úÖ Understand the principles and implementation of DARTS (Differentiable Architecture Search)</li>
<li>‚úÖ Understand NAS efficiency techniques (Weight Sharing, Proxy Tasks)</li>
<li>‚úÖ Apply AutoKeras and DARTS to real datasets</li>
</ul>
<hr/>
<h2>3.1 NAS Search Space</h2>
<h3>What is Neural Architecture Search?</h3>
<p><strong>Neural Architecture Search (NAS)</strong> is a technology that automatically designs neural network architectures.</p>
<blockquote>
<p>"Manual Design vs Automated Design" - NAS can discover architectures that surpass human expertise.</p>
</blockquote>
<h3>The Three Components of NAS</h3>
<table>
<thead>
<tr>
<th>Component</th>
<th>Description</th>
<th>Examples</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Search Space</strong></td>
<td>Set of explorable architectures</td>
<td>Cell-based, Macro, Micro</td>
</tr>
<tr>
<td><strong>Search Strategy</strong></td>
<td>Method for exploring architectures</td>
<td>Reinforcement learning, Evolution, Gradient-based</td>
</tr>
<tr>
<td><strong>Performance Estimation</strong></td>
<td>Evaluation of architecture quality</td>
<td>Accuracy, FLOPs, Latency</td>
</tr>
</tbody>
</table>
<h3>Cell-based Search Space</h3>
<p>In a <strong>Cell-based search space</strong>, we search for "Cells" that are used repeatedly.</p>
<div class="mermaid">
graph TD
    A[Input Image] --&gt; B[Stem Convolution]
    B --&gt; C[Normal Cell 1]
    C --&gt; D[Normal Cell 2]
    D --&gt; E[Reduction Cell]
    E --&gt; F[Normal Cell 3]
    F --&gt; G[Normal Cell 4]
    G --&gt; H[Reduction Cell]
    H --&gt; I[Normal Cell 5]
    I --&gt; J[Global Pool]
    J --&gt; K[Softmax]

    style C fill:#e3f2fd
    style D fill:#e3f2fd
    style E fill:#ffebee
    style F fill:#e3f2fd
    style G fill:#e3f2fd
    style H fill:#ffebee
    style I fill:#e3f2fd
</div>
<h4>Types of Cells</h4>
<table>
<thead>
<tr>
<th>Cell Type</th>
<th>Role</th>
<th>Spatial Resolution</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Normal Cell</strong></td>
<td>Feature extraction</td>
<td>Maintained</td>
</tr>
<tr>
<td><strong>Reduction Cell</strong></td>
<td>Downsampling</td>
<td>Reduced by half</td>
</tr>
</tbody>
</table>
<h3>Macro vs Micro Architecture</h3>
<table>
<thead>
<tr>
<th>Architecture</th>
<th>Search Target</th>
<th>Advantages</th>
<th>Disadvantages</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Macro</strong></td>
<td>Overall structure (layers, connections)</td>
<td>High flexibility</td>
<td>Huge search space</td>
</tr>
<tr>
<td><strong>Micro</strong></td>
<td>Internal cell structure</td>
<td>Efficient, transferable</td>
<td>Many constraints</td>
</tr>
</tbody>
</table>
<h3>Size of Search Space</h3>
<p>The size of a Cell-based search space is enormous:</p>
<p>$$
\text{Search Space Size} \approx O^{E}
$$</p>
<ul>
<li>$O$: Number of operation types (e.g., 8 types)</li>
<li>$E$: Number of edges (e.g., 14)</li>
<li>Example: $8^{14} \approx 4.4 \times 10^{12}$ possibilities</li>
</ul>
<h3>Practical Example of Search Space Design</h3>
<pre><code class="language-python"># Requirements:
# - Python 3.9+
# - numpy&gt;=1.24.0, &lt;2.0.0

"""
Example: Practical Example of Search Space Design

Purpose: Demonstrate core concepts and implementation patterns
Target: Intermediate
Execution time: 10-30 seconds
Dependencies: None
"""

import numpy as np

# NAS search space definition
class SearchSpace:
    def __init__(self):
        # Available operations
        self.operations = [
            'conv_3x3',
            'conv_5x5',
            'sep_conv_3x3',
            'sep_conv_5x5',
            'max_pool_3x3',
            'avg_pool_3x3',
            'identity',
            'zero'
        ]

        # Cell structure parameters
        self.num_nodes = 4  # Number of nodes in cell
        self.num_edges_per_node = 2  # Number of input edges per node

    def calculate_space_size(self):
        """Calculate size of search space"""
        num_ops = len(self.operations)

        # Calculate choices for each node
        total_choices = 1
        for node_id in range(2, self.num_nodes + 2):
            # Choice of edge source (select from previous nodes)
            edge_choices = node_id
            # Choice of operation
            op_choices = num_ops
            # Choices for this node
            node_choices = (edge_choices * op_choices) ** self.num_edges_per_node
            total_choices *= node_choices

        return total_choices

    def sample_architecture(self):
        """Randomly sample an architecture"""
        architecture = []

        for node_id in range(2, self.num_nodes + 2):
            # Select inputs to this node
            node_config = []
            for _ in range(self.num_edges_per_node):
                # Input source node
                input_node = np.random.randint(0, node_id)
                # Operation
                operation = np.random.choice(self.operations)
                node_config.append((input_node, operation))

            architecture.append(node_config)

        return architecture

# Calculate search space size
search_space = SearchSpace()
space_size = search_space.calculate_space_size()

print("=== NAS Search Space Analysis ===")
print(f"Number of operation types: {len(search_space.operations)}")
print(f"Number of nodes in cell: {search_space.num_nodes}")
print(f"Search space size: {space_size:,}")
print(f"Scientific notation: {space_size:.2e}")

# Sample architecture
sample = search_space.sample_architecture()
print(f"\n=== Sample Architecture ===")
for i, node in enumerate(sample, start=2):
    print(f"Node {i}:")
    for j, (input_node, op) in enumerate(node):
        print(f"  Input{j}: Node{input_node} ‚Üí {op}")
</code></pre>
<p><strong>Output</strong>:</p>
<pre><code>=== NAS Search Space Analysis ===
Number of operation types: 8
Number of nodes in cell: 4
Search space size: 17,179,869,184
Scientific notation: 1.72e+10

=== Sample Architecture ===
Node 2:
  Input0: Node0 ‚Üí sep_conv_3x3
  Input1: Node1 ‚Üí max_pool_3x3
Node 3:
  Input0: Node2 ‚Üí conv_5x5
  Input1: Node0 ‚Üí identity
Node 4:
  Input0: Node3 ‚Üí avg_pool_3x3
  Input1: Node1 ‚Üí sep_conv_5x5
Node 5:
  Input0: Node2 ‚Üí conv_3x3
  Input1: Node4 ‚Üí zero
</code></pre>
<hr/>
<h2>3.2 NAS Search Strategies</h2>
<h3>Comparison of Major Search Strategies</h3>
<table>
<thead>
<tr>
<th>Search Strategy</th>
<th>Principle</th>
<th>Computational Cost</th>
<th>Representative Method</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Reinforcement Learning</strong></td>
<td>Controller generates architectures</td>
<td>Very high</td>
<td>NASNet</td>
</tr>
<tr>
<td><strong>Evolutionary Algorithm</strong></td>
<td>Iterates mutation and selection</td>
<td>High</td>
<td>AmoebaNet</td>
</tr>
<tr>
<td><strong>Gradient-based</strong></td>
<td>Differentiable via continuous relaxation</td>
<td>Low</td>
<td>DARTS</td>
</tr>
<tr>
<td><strong>One-shot</strong></td>
<td>Train super-network once</td>
<td>Medium</td>
<td>ENAS</td>
</tr>
</tbody>
</table>
<h3>1. Reinforcement Learning-based (NASNet)</h3>
<p>In NASNet, an RNN controller generates architectures and learns using accuracy as a reward.</p>
<div class="mermaid">
graph LR
    A[RNN Controller] --&gt;|Generate Architecture| B[Child Network]
    B --&gt;|Train &amp; Evaluate| C[Validation Accuracy]
    C --&gt;|Reward| A

    style A fill:#e3f2fd
    style B fill:#fff3e0
    style C fill:#e8f5e9
</div>
<h4>Pseudocode for Reinforcement Learning NAS</h4>
<pre><code class="language-python"># Requirements:
# - Python 3.9+
# - numpy&gt;=1.24.0, &lt;2.0.0

# NASNet-style reinforcement learning search (conceptual implementation)
import numpy as np

class RLController:
    """Reinforcement learning-based NAS controller"""

    def __init__(self, search_space):
        self.search_space = search_space
        self.history = []

    def sample_architecture(self, epsilon=0.1):
        """Sample architecture using Œµ-greedy strategy"""
        if np.random.random() &lt; epsilon:
            # Explore: random sampling
            return self.search_space.sample_architecture()
        else:
            # Exploit: mutate from good past architectures
            if self.history:
                best_arch = max(self.history, key=lambda x: x['reward'])
                return self.mutate_architecture(best_arch['architecture'])
            else:
                return self.search_space.sample_architecture()

    def mutate_architecture(self, architecture):
        """Add small mutation to architecture"""
        mutated = [node[:] for node in architecture]

        # Randomly mutate one node
        node_idx = np.random.randint(len(mutated))
        edge_idx = np.random.randint(len(mutated[node_idx]))

        input_node, _ = mutated[node_idx][edge_idx]
        new_op = np.random.choice(self.search_space.operations)
        mutated[node_idx][edge_idx] = (input_node, new_op)

        return mutated

    def update(self, architecture, reward):
        """Receive reward and update history"""
        self.history.append({
            'architecture': architecture,
            'reward': reward
        })

# Simulation
search_space = SearchSpace()
controller = RLController(search_space)

print("=== Reinforcement Learning NAS Simulation ===")
for iteration in range(10):
    # Sample architecture
    arch = controller.sample_architecture(epsilon=0.3)

    # Simulate reward (in practice, train and get accuracy)
    # Here using diversity of operations as dummy reward
    ops_used = set()
    for node in arch:
        for _, op in node:
            ops_used.add(op)
    reward = len(ops_used) / len(search_space.operations) + np.random.normal(0, 0.1)

    # Update controller
    controller.update(arch, reward)

    print(f"Iteration {iteration + 1}: Reward = {reward:.3f}")

# Display best architecture
best = max(controller.history, key=lambda x: x['reward'])
print(f"\n=== Best Architecture (Reward: {best['reward']:.3f}) ===")
for i, node in enumerate(best['architecture'], start=2):
    print(f"Node {i}:")
    for j, (input_node, op) in enumerate(node):
        print(f"  Input{j}: Node{input_node} ‚Üí {op}")
</code></pre>
<h3>2. Evolutionary Algorithm</h3>
<p>Evolutionary algorithms optimize architectures by mimicking biological evolution.</p>
<pre><code class="language-python"># Evolutionary algorithm-based NAS (simplified version)
import random
import copy

class EvolutionaryNAS:
    """Evolutionary algorithm-based NAS"""

    def __init__(self, search_space, population_size=20, num_generations=10):
        self.search_space = search_space
        self.population_size = population_size
        self.num_generations = num_generations

    def initialize_population(self):
        """Generate initial population"""
        return [self.search_space.sample_architecture()
                for _ in range(self.population_size)]

    def evaluate_fitness(self, architecture):
        """Evaluate fitness (dummy implementation)"""
        # In practice, train network and measure accuracy
        # Here using operation diversity as score
        ops_used = set()
        for node in architecture:
            for _, op in node:
                ops_used.add(op)
        return len(ops_used) + random.gauss(0, 1)

    def select_parents(self, population, fitness_scores, k=2):
        """Tournament selection"""
        selected = []
        for _ in range(2):
            candidates_idx = random.sample(range(len(population)), k)
            best_idx = max(candidates_idx, key=lambda i: fitness_scores[i])
            selected.append(copy.deepcopy(population[best_idx]))
        return selected

    def crossover(self, parent1, parent2):
        """Crossover (single-point crossover)"""
        crossover_point = random.randint(1, len(parent1) - 1)
        child1 = parent1[:crossover_point] + parent2[crossover_point:]
        child2 = parent2[:crossover_point] + parent1[crossover_point:]
        return child1, child2

    def mutate(self, architecture, mutation_rate=0.1):
        """Mutation"""
        mutated = copy.deepcopy(architecture)

        for node_idx in range(len(mutated)):
            for edge_idx in range(len(mutated[node_idx])):
                if random.random() &lt; mutation_rate:
                    input_node, _ = mutated[node_idx][edge_idx]
                    new_op = random.choice(self.search_space.operations)
                    mutated[node_idx][edge_idx] = (input_node, new_op)

        return mutated

    def run(self):
        """Execute evolutionary algorithm"""
        # Initial population
        population = self.initialize_population()

        best_history = []

        for generation in range(self.num_generations):
            # Fitness evaluation
            fitness_scores = [self.evaluate_fitness(arch) for arch in population]

            # Statistics
            best_fitness = max(fitness_scores)
            avg_fitness = sum(fitness_scores) / len(fitness_scores)
            best_history.append(best_fitness)

            print(f"Generation {generation + 1}: Best={best_fitness:.3f}, Average={avg_fitness:.3f}")

            # Generate new generation
            new_population = []

            # Elitism
            elite_idx = fitness_scores.index(max(fitness_scores))
            new_population.append(copy.deepcopy(population[elite_idx]))

            # Selection, crossover, mutation
            while len(new_population) &lt; self.population_size:
                parents = self.select_parents(population, fitness_scores)
                offspring1, offspring2 = self.crossover(parents[0], parents[1])
                offspring1 = self.mutate(offspring1)
                offspring2 = self.mutate(offspring2)

                new_population.extend([offspring1, offspring2])

            population = new_population[:self.population_size]

        # Return best individual
        fitness_scores = [self.evaluate_fitness(arch) for arch in population]
        best_idx = fitness_scores.index(max(fitness_scores))

        return population[best_idx], best_history

# Execute
search_space = SearchSpace()
evo_nas = EvolutionaryNAS(search_space, population_size=20, num_generations=10)

print("=== Evolutionary Algorithm-based NAS ===")
best_arch, history = evo_nas.run()

print(f"\n=== Best Architecture ===")
for i, node in enumerate(best_arch, start=2):
    print(f"Node {i}:")
    for j, (input_node, op) in enumerate(node):
        print(f"  Input{j}: Node{input_node} ‚Üí {op}")
</code></pre>
<h3>3. Gradient-based (DARTS Overview)</h3>
<p>DARTS applies continuous relaxation to the search space and optimizes using gradient descent (details in Section 3.4).</p>
<blockquote>
<p><strong>Important</strong>: Gradient-based methods are over 1000 times faster than reinforcement learning and evolutionary algorithms.</p>
</blockquote>
<hr/>
<h2>3.3 AutoKeras</h2>
<h3>What is AutoKeras?</h3>
<p><strong>AutoKeras</strong> is a Keras-based AutoML library that makes NAS easily accessible.</p>
<h3>Installing AutoKeras</h3>
<pre><code class="language-bash">pip install autokeras
</code></pre>
<h3>Basic Usage of AutoKeras</h3>
<pre><code class="language-python"># Requirements:
# - Python 3.9+
# - numpy&gt;=1.24.0, &lt;2.0.0

"""
Example: Basic Usage of AutoKeras

Purpose: Demonstrate machine learning model training and evaluation
Target: Advanced
Execution time: 1-5 minutes
Dependencies: None
"""

# Basic AutoKeras example: image classification
import numpy as np
import autokeras as ak
from tensorflow.keras.datasets import mnist

# Prepare data
(x_train, y_train), (x_test, y_test) = mnist.load_data()

# Normalization
x_train = x_train.astype('float32') / 255.0
x_test = x_test.astype('float32') / 255.0

# Reduce training data (for demo)
x_train = x_train[:5000]
y_train = y_train[:5000]
x_test = x_test[:1000]
y_test = y_test[:1000]

print("=== Image Classification with AutoKeras ===")
print(f"Training data: {x_train.shape}")
print(f"Test data: {x_test.shape}")

# AutoKeras ImageClassifier
clf = ak.ImageClassifier(
    max_trials=5,  # Number of models to try
    overwrite=True,
    directory='autokeras_results',
    project_name='mnist_classification'
)

# Model search and training
print("\nStarting search...")
clf.fit(
    x_train, y_train,
    validation_split=0.2,
    epochs=3,
    verbose=1
)

# Evaluation
print("\n=== Model Evaluation ===")
test_loss, test_acc = clf.evaluate(x_test, y_test, verbose=0)
print(f"Test accuracy: {test_acc:.4f}")
print(f"Test loss: {test_loss:.4f}")

# Get best model
best_model = clf.export_model()
print("\n=== Best Model Structure ===")
best_model.summary()
</code></pre>
<h3>Various Tasks with AutoKeras</h3>
<h4>1. Structured Data Classification</h4>
<pre><code class="language-python"># Requirements:
# - Python 3.9+
# - numpy&gt;=1.24.0, &lt;2.0.0
# - pandas&gt;=2.0.0, &lt;2.2.0

"""
Example: 1. Structured Data Classification

Purpose: Demonstrate machine learning model training and evaluation
Target: Advanced
Execution time: 1-5 minutes
Dependencies: None
"""

# Handling structured data with AutoKeras
import numpy as np
import pandas as pd
import autokeras as ak
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split

# Prepare data
data = load_breast_cancer()
X = pd.DataFrame(data.data, columns=data.feature_names)
y = data.target

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

print("=== Structured Data Classification ===")
print(f"Features: {X.shape[1]} columns")
print(f"Training samples: {len(X_train)}")

# AutoKeras StructuredDataClassifier
clf = ak.StructuredDataClassifier(
    max_trials=3,
    overwrite=True,
    directory='autokeras_structured',
    project_name='breast_cancer'
)

# Search and training
clf.fit(
    X_train, y_train,
    validation_split=0.2,
    epochs=10,
    verbose=0
)

# Evaluation
test_loss, test_acc = clf.evaluate(X_test, y_test, verbose=0)
print(f"\n=== Evaluation Results ===")
print(f"Test accuracy: {test_acc:.4f}")

# Prediction
predictions = clf.predict(X_test[:5])
print(f"\n=== Sample Predictions ===")
for i, pred in enumerate(predictions[:5]):
    true_label = y_test.iloc[i] if isinstance(y_test, pd.Series) else y_test[i]
    print(f"Sample {i+1}: Prediction={pred[0][0]:.3f}, True={true_label}")
</code></pre>
<h4>2. Text Classification</h4>
<pre><code class="language-python"># Requirements:
# - Python 3.9+
# - numpy&gt;=1.24.0, &lt;2.0.0

"""
Example: 2. Text Classification

Purpose: Demonstrate core concepts and implementation patterns
Target: Advanced
Execution time: 1-5 minutes
Dependencies: None
"""

# Text classification with AutoKeras
import numpy as np
import autokeras as ak
from tensorflow.keras.datasets import imdb

# IMDB dataset (movie review sentiment analysis)
max_features = 10000
maxlen = 200

print("=== Text Classification (IMDB) ===")
(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)

# Reduce data (for demo)
x_train = x_train[:1000]
y_train = y_train[:1000]
x_test = x_test[:200]
y_test = y_test[:200]

# Padding
from tensorflow.keras.preprocessing.sequence import pad_sequences
x_train = pad_sequences(x_train, maxlen=maxlen)
x_test = pad_sequences(x_test, maxlen=maxlen)

print(f"Training data: {x_train.shape}")
print(f"Test data: {x_test.shape}")

# AutoKeras TextClassifier
clf = ak.TextClassifier(
    max_trials=3,
    overwrite=True,
    directory='autokeras_text',
    project_name='imdb_sentiment'
)

# Search and training
clf.fit(
    x_train, y_train,
    validation_split=0.2,
    epochs=3,
    verbose=0
)

# Evaluation
test_loss, test_acc = clf.evaluate(x_test, y_test, verbose=0)
print(f"\n=== Evaluation Results ===")
print(f"Test accuracy: {test_acc:.4f}")
</code></pre>
<h3>Custom Search Space in AutoKeras</h3>
<pre><code class="language-python"># Customizing search space with AutoKeras
import autokeras as ak
from tensorflow.keras.datasets import mnist

# Data preparation
(x_train, y_train), (x_test, y_test) = mnist.load_data()
x_train = x_train[:5000].astype('float32') / 255.0
y_train = y_train[:5000]
x_test = x_test[:1000].astype('float32') / 255.0
y_test = y_test[:1000]

print("=== Custom Search Space ===")

# Input node
input_node = ak.ImageInput()

# Normalization block
output = ak.Normalization()(input_node)

# Customize ConvBlock search space
output = ak.ConvBlock(
    num_blocks=2,  # Number of convolutional blocks
    num_layers=2,  # Number of layers per block
    max_pooling=True,
    dropout=0.25
)(output)

# Classification head
output = ak.ClassificationHead(
    num_classes=10,
    dropout=0.5
)(output)

# Build model
clf = ak.AutoModel(
    inputs=input_node,
    outputs=output,
    max_trials=3,
    overwrite=True,
    directory='autokeras_custom',
    project_name='mnist_custom'
)

# Training
clf.fit(
    x_train, y_train,
    validation_split=0.2,
    epochs=3,
    verbose=0
)

# Evaluation
test_loss, test_acc = clf.evaluate(x_test, y_test, verbose=0)
print(f"\nTest accuracy: {test_acc:.4f}")

# Get best model
best_model = clf.export_model()
print("\n=== Discovered Architecture ===")
best_model.summary()
</code></pre>
<hr/>
<h2>3.4 DARTS (Differentiable Architecture Search)</h2>
<h3>Principles of DARTS</h3>
<p><strong>DARTS</strong> makes gradient descent applicable by applying continuous relaxation to discrete search spaces.</p>
<h3>Continuous Relaxation</h3>
<p>Operations on each edge are represented as weighted sums of all operations:</p>
<p>$$
\bar{o}^{(i,j)}(x) = \sum_{o \in \mathcal{O}} \frac{\exp(\alpha_o^{(i,j)})}{\sum_{o' \in \mathcal{O}} \exp(\alpha_{o'}^{(i,j)})} \cdot o(x)
$$</p>
<ul>
<li>$\mathcal{O}$: Set of operations</li>
<li>$\alpha_o^{(i,j)}$: Weight of operation $o$ on edge $(i,j)$ (architecture parameter)</li>
<li>Normalized by softmax, making it differentiable</li>
</ul>
<h3>Bi-level Optimization</h3>
<p>DARTS alternately optimizes two types of parameters:</p>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>Description</th>
<th>Optimization</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Weights $w$</strong></td>
<td>Network weights</td>
<td>Minimize on training data</td>
</tr>
<tr>
<td><strong>Architecture $\alpha$</strong></td>
<td>Operation weights</td>
<td>Minimize on validation data</td>
</tr>
</tbody>
</table>
<p>Optimization problem:</p>
<p>$$
\begin{aligned}
\min_{\alpha} \quad &amp; \mathcal{L}_{\text{val}}(w^*(\alpha), \alpha) \\
\text{s.t.} \quad &amp; w^*(\alpha) = \arg\min_{w} \mathcal{L}_{\text{train}}(w, \alpha)
\end{aligned}
$$</p>
<h3>DARTS Implementation (Simplified Version)</h3>
<pre><code class="language-python"># Requirements:
# - Python 3.9+
# - torch&gt;=2.0.0, &lt;2.3.0

# Conceptual implementation of DARTS (simplified version)
import torch
import torch.nn as nn
import torch.nn.functional as F

class MixedOp(nn.Module):
    """Weighted sum of multiple operations"""

    def __init__(self, C, stride):
        super(MixedOp, self).__init__()
        self._ops = nn.ModuleList()

        # Available operations
        self.operations = [
            ('sep_conv_3x3', lambda C, stride: SepConv(C, C, 3, stride, 1)),
            ('sep_conv_5x5', lambda C, stride: SepConv(C, C, 5, stride, 2)),
            ('avg_pool_3x3', lambda C, stride: nn.AvgPool2d(3, stride=stride, padding=1)),
            ('max_pool_3x3', lambda C, stride: nn.MaxPool2d(3, stride=stride, padding=1)),
            ('skip_connect', lambda C, stride: nn.Identity() if stride == 1 else FactorizedReduce(C, C)),
        ]

        for name, op in self.operations:
            self._ops.append(op(C, stride))

    def forward(self, x, weights):
        """Compute weighted sum"""
        return sum(w * op(x) for w, op in zip(weights, self._ops))

class Cell(nn.Module):
    """DARTS Cell"""

    def __init__(self, num_nodes, C_prev, C, reduction):
        super(Cell, self).__init__()
        self.num_nodes = num_nodes

        # Operations for each edge
        self._ops = nn.ModuleList()
        for i in range(num_nodes):
            for j in range(2 + i):
                stride = 2 if reduction and j &lt; 2 else 1
                op = MixedOp(C, stride)
                self._ops.append(op)

    def forward(self, s0, s1, weights):
        """Forward pass"""
        states = [s0, s1]
        offset = 0

        for i in range(self.num_nodes):
            s = sum(self._ops[offset + j](h, weights[offset + j])
                   for j, h in enumerate(states))
            offset += len(states)
            states.append(s)

        return torch.cat(states[-self.num_nodes:], dim=1)

class DARTSNetwork(nn.Module):
    """DARTS search network"""

    def __init__(self, C=16, num_cells=8, num_nodes=4, num_classes=10):
        super(DARTSNetwork, self).__init__()
        self.num_cells = num_cells
        self.num_nodes = num_nodes

        # Architecture parameters (Œ±)
        num_ops = 5  # Number of operation types
        num_edges = sum(2 + i for i in range(num_nodes))
        self.alphas_normal = nn.Parameter(torch.randn(num_edges, num_ops))
        self.alphas_reduce = nn.Parameter(torch.randn(num_edges, num_ops))

        # Network weights (w)
        self.stem = nn.Sequential(
            nn.Conv2d(3, C, 3, padding=1, bias=False),
            nn.BatchNorm2d(C)
        )

        # Cell construction is simplified
        self.cells = nn.ModuleList()
        # ... (in actual implementation, add multiple Cells)

        self.classifier = nn.Linear(C, num_classes)

    def arch_parameters(self):
        """Return architecture parameters"""
        return [self.alphas_normal, self.alphas_reduce]

    def weights_parameters(self):
        """Return network weights"""
        return [p for n, p in self.named_parameters()
                if 'alpha' not in n]

# Usage example of DARTS
print("=== DARTS Conceptual Model ===")
model = DARTSNetwork(C=16, num_cells=8, num_nodes=4, num_classes=10)

print(f"Number of architecture parameters: {sum(p.numel() for p in model.arch_parameters())}")
print(f"Number of network weight parameters: {sum(p.numel() for p in model.weights_parameters())}")

# Shape of architecture parameters
print(f"\nNormal cell Œ±: {model.alphas_normal.shape}")
print(f"Reduction cell Œ±: {model.alphas_reduce.shape}")

# Normalize with softmax
weights_normal = F.softmax(model.alphas_normal, dim=-1)
print(f"\nNormalized weights (Normal cell, first edge):")
print(weights_normal[0].detach().numpy())
</code></pre>
<h3>DARTS Training Algorithm</h3>
<pre><code class="language-python"># Requirements:
# - Python 3.9+
# - torch&gt;=2.0.0, &lt;2.3.0

# DARTS training procedure (pseudocode)
import torch
import torch.optim as optim

class DARTSTrainer:
    """DARTS training class"""

    def __init__(self, model, train_loader, val_loader):
        self.model = model
        self.train_loader = train_loader
        self.val_loader = val_loader

        # Two optimizers
        self.optimizer_w = optim.SGD(
            model.weights_parameters(),
            lr=0.025,
            momentum=0.9,
            weight_decay=3e-4
        )

        self.optimizer_alpha = optim.Adam(
            model.arch_parameters(),
            lr=3e-4,
            betas=(0.5, 0.999),
            weight_decay=1e-3
        )

        self.criterion = nn.CrossEntropyLoss()

    def train_step(self, train_data, val_data):
        """One training step"""
        # 1. Update architecture parameters (Œ±)
        self.model.train()
        x_val, y_val = val_data

        self.optimizer_alpha.zero_grad()
        logits = self.model(x_val)
        loss_alpha = self.criterion(logits, y_val)
        loss_alpha.backward()
        self.optimizer_alpha.step()

        # 2. Update network weights (w)
        x_train, y_train = train_data

        self.optimizer_w.zero_grad()
        logits = self.model(x_train)
        loss_w = self.criterion(logits, y_train)
        loss_w.backward()
        self.optimizer_w.step()

        return loss_w.item(), loss_alpha.item()

    def derive_architecture(self):
        """Derive final architecture"""
        # Select operation with highest weight for each edge
        def parse_alpha(alpha):
            gene = []
            n = 2
            start = 0
            for i in range(self.model.num_nodes):
                end = start + n
                W = alpha[start:end].copy()

                # Select 2 best operations for each edge
                edges = sorted(range(W.shape[0]),
                              key=lambda x: -max(W[x]))[:2]

                for j in edges:
                    k_best = W[j].argmax()
                    gene.append((j, k_best))

                start = end
                n += 1

            return gene

        # Normalize with softmax
        weights_normal = F.softmax(self.model.alphas_normal, dim=-1)
        weights_reduce = F.softmax(self.model.alphas_reduce, dim=-1)

        gene_normal = parse_alpha(weights_normal.data.cpu().numpy())
        gene_reduce = parse_alpha(weights_reduce.data.cpu().numpy())

        return gene_normal, gene_reduce

# Simulation example
print("=== DARTS Training Procedure ===")
print("1. Initialize model")
print("2. For each epoch:")
print("   a. Update Œ± on validation data (architecture optimization)")
print("   b. Update w on training data (weight optimization)")
print("3. After training, select operation with highest weight for each edge")
print("4. Reconstruct network with selected operations and perform final training")
</code></pre>
<h3>Practical DARTS Example (PyTorch)</h3>
<pre><code class="language-python"># Requirements:
# - Python 3.9+
# - torch&gt;=2.0.0, &lt;2.3.0

# Example using actual DARTS implementation (using pt-darts library)
# Note: pt-darts is an external library (pip install pt-darts)

# Conceptual code example below
"""
import torch
from darts import DARTS
from darts.api import spaces
from darts.trainer import DARTSTrainer

# Define search space
search_space = spaces.get_search_space('darts', 'cifar10')

# Build DARTS model
model = DARTS(
    C=16,
    num_classes=10,
    layers=8,
    criterion=nn.CrossEntropyLoss(),
    steps=4,
    multiplier=4,
    stem_multiplier=3
)

# Initialize trainer
trainer = DARTSTrainer(
    model,
    optimizer_config={
        'w_lr': 0.025,
        'w_momentum': 0.9,
        'w_weight_decay': 3e-4,
        'alpha_lr': 3e-4,
        'alpha_weight_decay': 1e-3
    }
)

# Execute search
trainer.search(
    train_loader,
    val_loader,
    epochs=50
)

# Get best architecture
best_architecture = model.genotype()
print(f"Discovered architecture: {best_architecture}")
"""

print("=== Practical DARTS Usage ===")
print("1. Install libraries like pt-darts")
print("2. Define search space and model")
print("3. Search with bi-level optimization")
print("4. Retrain with discovered architecture")
print("\nAdvantages of DARTS:")
print("- Search time: 4 GPU days (NASNet requires 1800 GPU days)")
print("- High accuracy: Over 97% on CIFAR-10")
print("- Transferable: Applicable to ImageNet and others")
</code></pre>
<hr/>
<h2>3.5 NAS Efficiency Techniques</h2>
<h3>Comparison of Efficiency Techniques</h3>
<table>
<thead>
<tr>
<th>Technique</th>
<th>Principle</th>
<th>Speedup Factor</th>
<th>Impact on Accuracy</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Weight Sharing</strong></td>
<td>Share weights among candidate architectures</td>
<td>1000x</td>
<td>Small</td>
</tr>
<tr>
<td><strong>Proxy Tasks</strong></td>
<td>Evaluate on simplified tasks</td>
<td>10-100x</td>
<td>Medium</td>
</tr>
<tr>
<td><strong>Early Stopping</strong></td>
<td>Terminate low-performance models early</td>
<td>2-5x</td>
<td>Small</td>
</tr>
<tr>
<td><strong>Transfer Learning</strong></td>
<td>Transfer knowledge from similar tasks</td>
<td>5-10x</td>
<td>Small</td>
</tr>
</tbody>
</table>
<h3>1. Weight Sharing (ENAS)</h3>
<p><strong>Weight Sharing</strong> constructs a super-network where all candidate architectures share weights.</p>
<pre><code class="language-python"># Requirements:
# - Python 3.9+
# - torch&gt;=2.0.0, &lt;2.3.0

# Weight Sharing concept (ENAS-style)
import torch
import torch.nn as nn

class SharedWeightSuperNet(nn.Module):
    """Weight-sharing super-network"""

    def __init__(self, num_nodes=4, C=16):
        super(SharedWeightSuperNet, self).__init__()
        self.num_nodes = num_nodes

        # Build all possible operations in advance (share weights)
        self.ops = nn.ModuleDict({
            'conv_3x3': nn.Conv2d(C, C, 3, padding=1),
            'conv_5x5': nn.Conv2d(C, C, 5, padding=2),
            'max_pool': nn.MaxPool2d(3, stride=1, padding=1),
            'avg_pool': nn.AvgPool2d(3, stride=1, padding=1),
            'identity': nn.Identity()
        })

    def forward(self, x, architecture):
        """
        architecture: Specifies operation for each node
        Example: [('conv_3x3', 0), ('max_pool', 1), ...]
        """
        states = [x, x]  # Initial state

        for node_id, (op_name, input_id) in enumerate(architecture):
            # Compute with specified operation and input
            s = self.ops[op_name](states[input_id])
            states.append(s)

        # Return output of last node
        return states[-1]

# Build super-network
supernet = SharedWeightSuperNet(num_nodes=4, C=16)

print("=== Weight Sharing (ENAS-style) ===")
print(f"Number of super-network parameters: {sum(p.numel() for p in supernet.parameters()):,}")

# Use same weights for different architectures
arch1 = [('conv_3x3', 0), ('max_pool', 1), ('identity', 2), ('avg_pool', 1)]
arch2 = [('conv_5x5', 1), ('identity', 0), ('max_pool', 2), ('conv_3x3', 3)]

# Dummy input
x = torch.randn(1, 16, 32, 32)

output1 = supernet(x, arch1)
output2 = supernet(x, arch2)

print(f"\nArchitecture 1 output shape: {output1.shape}")
print(f"Architecture 2 output shape: {output2.shape}")
print("\n‚Üí Different architectures can be evaluated while sharing the same weights")
</code></pre>
<h3>2. Speedup with Proxy Tasks</h3>
<p>Proxy Tasks reduce cost through simplifications like:</p>
<table>
<thead>
<tr>
<th>Simplification</th>
<th>Example</th>
<th>Speedup</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Data Size Reduction</strong></td>
<td>Use only part of CIFAR-10</td>
<td>2-5x</td>
</tr>
<tr>
<td><strong>Epoch Reduction</strong></td>
<td>Evaluate with 10 epochs</td>
<td>5-10x</td>
</tr>
<tr>
<td><strong>Model Size Reduction</strong></td>
<td>Reduce channels to 1/4</td>
<td>4-8x</td>
</tr>
<tr>
<td><strong>Resolution Reduction</strong></td>
<td>16x16 instead of 32x32</td>
<td>4x</td>
</tr>
</tbody>
</table>
<h3>3. NAS-Bench Dataset</h3>
<p><strong>NAS-Bench</strong> is a database of pre-computed architecture performance.</p>
<pre><code class="language-python"># Conceptual usage of NAS-Bench
# Note: Actually use nasbench library (pip install nasbench)

class NASBenchSimulator:
    """NAS-Bench simulator"""

    def __init__(self):
        # Pre-computed performance data (dummy)
        self.benchmark_data = {}
        self._populate_dummy_data()

    def _populate_dummy_data(self):
        """Generate dummy benchmark data"""
        import random
        random.seed(42)

        # Pre-compute performance for 100 architectures
        for i in range(100):
            arch_hash = f"arch_{i:03d}"
            self.benchmark_data[arch_hash] = {
                'val_accuracy': random.uniform(0.88, 0.95),
                'test_accuracy': random.uniform(0.87, 0.94),
                'training_time': random.uniform(100, 500),
                'params': random.randint(1_000_000, 10_000_000),
                'flops': random.randint(50_000_000, 500_000_000)
            }

    def query(self, architecture):
        """Query architecture performance (returns immediately)"""
        # Hash architecture
        arch_hash = self._hash_architecture(architecture)

        if arch_hash in self.benchmark_data:
            return self.benchmark_data[arch_hash]
        else:
            # Estimate unknown architecture
            return {
                'val_accuracy': 0.90,
                'test_accuracy': 0.89,
                'training_time': 300,
                'params': 5_000_000,
                'flops': 250_000_000
            }

    def _hash_architecture(self, architecture):
        """Hash architecture"""
        # Simple hash (actual implementation is more complex)
        arch_str = str(architecture)
        hash_val = sum(ord(c) for c in arch_str) % 100
        return f"arch_{hash_val:03d}"

# Using NAS-Bench
bench = NASBenchSimulator()

print("=== Fast Evaluation with NAS-Bench ===")

# Architecture search
import time

architectures = [
    [('conv_3x3', 0), ('max_pool', 1)],
    [('conv_5x5', 0), ('identity', 1)],
    [('avg_pool', 0), ('conv_3x3', 1)]
]

start_time = time.time()
results = []

for arch in architectures:
    result = bench.query(arch)
    results.append((arch, result))

end_time = time.time()

print(f"Search time: {end_time - start_time:.4f} seconds")
print(f"\n=== Search Results ===")
for arch, result in results:
    print(f"Architecture: {arch}")
    print(f"  Validation accuracy: {result['val_accuracy']:.3f}")
    print(f"  Test accuracy: {result['test_accuracy']:.3f}")
    print(f"  Training time: {result['training_time']:.1f} seconds")
    print(f"  Parameters: {result['params']:,}")
    print()

print("‚Üí Performance can be obtained instantly without actual training")
</code></pre>
<h3>Combining Efficiency Techniques</h3>
<pre><code class="language-python"># Requirements:
# - Python 3.9+
# - numpy&gt;=1.24.0, &lt;2.0.0

# Search combining multiple efficiency techniques
import numpy as np

class EfficientNAS:
    """Efficient NAS"""

    def __init__(self, use_weight_sharing=True, use_proxy=True,
                 use_early_stopping=True):
        self.use_weight_sharing = use_weight_sharing
        self.use_proxy = use_proxy
        self.use_early_stopping = use_early_stopping

        if use_weight_sharing:
            self.supernet = SharedWeightSuperNet()

        if use_proxy:
            self.proxy_epochs = 10  # 10 epochs instead of full training
            self.proxy_data_fraction = 0.2  # Use only 20% of data

    def evaluate_architecture(self, architecture, full_evaluation=False):
        """Evaluate architecture"""
        if full_evaluation:
            # Full evaluation (only for final candidates)
            epochs = 50
            data_fraction = 1.0
        else:
            # Proxy evaluation
            epochs = self.proxy_epochs if self.use_proxy else 50
            data_fraction = self.proxy_data_fraction if self.use_proxy else 1.0

        # Early stopping simulation
        if self.use_early_stopping:
            # Terminate if performance is poor in first few epochs
            early_acc = np.random.random()
            if early_acc &lt; 0.5:  # Threshold
                return {'accuracy': early_acc, 'stopped_early': True}

        # Evaluation (dummy)
        accuracy = np.random.uniform(0.85, 0.95)

        return {
            'accuracy': accuracy,
            'epochs': epochs,
            'data_fraction': data_fraction,
            'stopped_early': False
        }

    def search(self, num_candidates=100, top_k=5):
        """Execute NAS search"""
        print("=== Efficient NAS Search ===")
        print(f"Weight Sharing: {self.use_weight_sharing}")
        print(f"Proxy Tasks: {self.use_proxy}")
        print(f"Early Stopping: {self.use_early_stopping}")
        print()

        candidates = []

        # 1. Large-scale proxy evaluation
        for i in range(num_candidates):
            arch = [('conv_3x3', 0), ('max_pool', 1)]  # Dummy
            result = self.evaluate_architecture(arch, full_evaluation=False)
            candidates.append((arch, result))

        # Candidates not terminated by early stopping
        valid_candidates = [c for c in candidates if not c[1]['stopped_early']]

        print(f"Initial candidates: {num_candidates}")
        print(f"Reduced by early stopping: {num_candidates - len(valid_candidates)}")

        # 2. Full evaluation of top K
        top_candidates = sorted(valid_candidates,
                               key=lambda x: x[1]['accuracy'],
                               reverse=True)[:top_k]

        print(f"Candidates for full evaluation: {top_k}")
        print()

        final_results = []
        for arch, proxy_result in top_candidates:
            full_result = self.evaluate_architecture(arch, full_evaluation=True)
            final_results.append((arch, full_result))

        # Return best candidate
        best = max(final_results, key=lambda x: x[1]['accuracy'])

        return best, final_results

# Execute
nas = EfficientNAS(
    use_weight_sharing=True,
    use_proxy=True,
    use_early_stopping=True
)

best_arch, all_results = nas.search(num_candidates=100, top_k=5)

print("=== Search Results ===")
print(f"Best architecture: {best_arch[0]}")
print(f"Best accuracy: {best_arch[1]['accuracy']:.3f}")
print(f"\nTop 5 accuracies:")
for i, (arch, result) in enumerate(all_results, 1):
    print(f"{i}. Accuracy={result['accuracy']:.3f}")
</code></pre>
<hr/>
<h2>3.6 Chapter Summary</h2>
<h3>What We Learned</h3>
<ol>
<li><p><strong>NAS Search Space</strong></p>
<ul>
<li>Design of Cell-based search spaces</li>
<li>Macro vs Micro architecture</li>
<li>Size and complexity of search spaces</li>
</ul></li>
<li><p><strong>NAS Search Strategies</strong></p>
<ul>
<li>Reinforcement Learning (NASNet): Generation with RNN controller</li>
<li>Evolutionary Algorithm: Mutation and selection</li>
<li>Gradient-based (DARTS): Speedup with continuous relaxation</li>
<li>One-shot (ENAS): Efficiency with Weight Sharing</li>
</ul></li>
<li><p><strong>AutoKeras</strong></p>
<ul>
<li>Automated learning for images, text, and structured data</li>
<li>Defining custom search spaces</li>
<li>Using advanced NAS with simple API</li>
</ul></li>
<li><p><strong>DARTS</strong></p>
<ul>
<li>Differentiable NAS through continuous relaxation</li>
<li>Bi-level optimization (w and Œ±)</li>
<li>Achieved over 1000x speedup</li>
</ul></li>
<li><p><strong>NAS Efficiency Techniques</strong></p>
<ul>
<li>Weight Sharing: Share weights in super-network</li>
<li>Proxy Tasks: Evaluate on simplified tasks</li>
<li>Early Stopping: Terminate low performance early</li>
<li>NAS-Bench: Pre-computed database</li>
</ul></li>
</ol>
<h3>Guidelines for Selecting Search Strategies</h3>
<table>
<thead>
<tr>
<th>Situation</th>
<th>Recommended Method</th>
<th>Reason</th>
</tr>
</thead>
<tbody>
<tr>
<td>Abundant computational resources</td>
<td>Reinforcement learning, Evolution</td>
<td>High accuracy expected</td>
</tr>
<tr>
<td>Limited computational resources</td>
<td>DARTS, ENAS</td>
<td>Fast and practical</td>
</tr>
<tr>
<td>First-time NAS</td>
<td>AutoKeras</td>
<td>Simple and easy to use</td>
</tr>
<tr>
<td>Customization needed</td>
<td>DARTS implementation</td>
<td>High flexibility</td>
</tr>
<tr>
<td>Benchmark research</td>
<td>NAS-Bench</td>
<td>Reproducibility and fairness</td>
</tr>
</tbody>
</table>
<h3>Next Chapter</h3>
<p>In Chapter 4, you will learn about <strong>Feature Engineering Automation</strong>:</p>
<ul>
<li>Automated feature generation</li>
<li>Automating feature selection</li>
<li>Visualizing feature importance</li>
<li>Integrating AutoML pipelines</li>
<li>Practical Feature Engineering</li>
</ul>
<hr/>
<h2>Exercises</h2>
<h3>Problem 1 (Difficulty: easy)</h3>
<p>Explain the three components of NAS (search space, search strategy, performance estimation).</p>
<details>
<summary>Sample Answer</summary>
<p><strong>Answer</strong>:</p>
<ol>
<li><p><strong>Search Space</strong></p>
<ul>
<li>Description: Set of explorable architectures</li>
<li>Examples: Cell-based (Normal Cell and Reduction Cell), layer types (Conv, Pooling), connection patterns</li>
<li>Importance: Too large search space has high computational cost, too small may miss optimal solution</li>
</ul></li>
<li><p><strong>Search Strategy</strong></p>
<ul>
<li>Description: How to explore architectures</li>
<li>Examples: Reinforcement learning (NASNet), evolutionary algorithm (AmoebaNet), gradient-based (DARTS)</li>
<li>Trade-off: Accuracy vs computational cost</li>
</ul></li>
<li><p><strong>Performance Estimation</strong></p>
<ul>
<li>Description: Method to evaluate architecture quality</li>
<li>Metrics: Accuracy, FLOPs, number of parameters, latency, memory usage</li>
<li>Efficiency: Proxy tasks, Weight sharing, Early stopping</li>
</ul></li>
</ol>
</details>
<h3>Problem 2 (Difficulty: medium)</h3>
<p>Explain why DARTS is faster than reinforcement learning-based NAS from the perspective of continuous relaxation.</p>
<details>
<summary>Sample Answer</summary>
<p><strong>Answer</strong>:</p>
<p><strong>Reinforcement Learning-based NAS (e.g., NASNet)</strong>:</p>
<ul>
<li>Discrete search: Iterates sampling architecture ‚Üí training ‚Üí evaluation</li>
<li>Each candidate must be trained individually</li>
<li>Computational cost: Thousands of architectures √ó full training = very high (1800 GPU days)</li>
</ul>
<p><strong>DARTS (Gradient-based)</strong>:</p>
<ul>
<li>Continuous relaxation: Converts discrete choice (which operation to use) to continuous weighted sum</li>
<li>Formula: $\bar{o}(x) = \sum_o \frac{\exp(\alpha_o)}{\sum_{o'} \exp(\alpha_{o'})} \cdot o(x)$</li>
<li>Enables gradient descent: Œ± can be optimized with gradients</li>
<li>Weight sharing: All candidates share the same super-network</li>
<li>Computational cost: 1 super-network training = significant reduction (4 GPU days)</li>
</ul>
<p><strong>Reasons for Speedup</strong>:</p>
<ol>
<li>Discrete‚ÜíContinuous: Becomes differentiable, enabling efficient gradient optimization</li>
<li>Weight sharing: Avoids individual training by sharing weights among candidates</li>
<li>Bi-level optimization: Efficiently searches by alternately updating w and Œ±</li>
</ol>
<p><strong>Results</strong>:</p>
<ul>
<li>NASNet: 1800 GPU days</li>
<li>DARTS: 4 GPU days</li>
<li>Speedup factor: Approximately 450x</li>
</ul>
</details>
<h3>Problem 3 (Difficulty: medium)</h3>
<p>Complete the following code to search for an image classification model using AutoKeras.</p>
<pre><code class="language-python">import autokeras as ak
from tensorflow.keras.datasets import fashion_mnist

# Prepare data
(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()

# x_train = ...
# x_test = ...

# clf = ak.ImageClassifier(...)

# Exercise: Train model
# clf.fit(...)

# Exercise: Evaluate
# test_acc = ...
# print(f"Test accuracy: {test_acc:.4f}")
</code></pre>
<details>
<summary>Sample Answer</summary>
<pre><code class="language-python"># Requirements:
# - Python 3.9+
# - numpy&gt;=1.24.0, &lt;2.0.0

"""
Example: Complete the following code to search for an image classific

Purpose: Demonstrate machine learning model training and evaluation
Target: Advanced
Execution time: 1-5 minutes
Dependencies: None
"""

import autokeras as ak
from tensorflow.keras.datasets import fashion_mnist

# Prepare data
(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()

# Normalize data
x_train = x_train.astype('float32') / 255.0
x_test = x_test.astype('float32') / 255.0

# Reduce data size (for demo)
x_train = x_train[:5000]
y_train = y_train[:5000]
x_test = x_test[:1000]
y_test = y_test[:1000]

print("=== Fashion-MNIST Classification ===")
print(f"Training data: {x_train.shape}")
print(f"Test data: {x_test.shape}")

# AutoKeras ImageClassifier
clf = ak.ImageClassifier(
    max_trials=5,  # Number of candidates to search
    epochs=10,     # Training epochs per candidate
    overwrite=True,
    directory='autokeras_fashion',
    project_name='fashion_mnist'
)

# Train model
print("\nStarting search...")
clf.fit(
    x_train, y_train,
    validation_split=0.2,
    verbose=1
)

# Evaluate
print("\n=== Evaluation ===")
test_loss, test_acc = clf.evaluate(x_test, y_test, verbose=0)
print(f"Test accuracy: {test_acc:.4f}")
print(f"Test loss: {test_loss:.4f}")

# Get best model
best_model = clf.export_model()
print("\n=== Discovered Model ===")
best_model.summary()

# Prediction example
import numpy as np
predictions = clf.predict(x_test[:5])
print("\n=== Prediction Examples ===")
for i in range(5):
    print(f"Sample {i+1}: Prediction={np.argmax(predictions[i])}, True={y_test[i]}")
</code></pre>
</details>
<h3>Problem 4 (Difficulty: hard)</h3>
<p>Implement a super-network using Weight Sharing and verify that weights are shared across two different architectures.</p>
<details>
<summary>Sample Answer</summary>
<pre><code class="language-python"># Requirements:
# - Python 3.9+
# - torch&gt;=2.0.0, &lt;2.3.0

import torch
import torch.nn as nn
import torch.nn.functional as F

class SharedOperations(nn.Module):
    """Pool of operations sharing weights"""

    def __init__(self, C):
        super(SharedOperations, self).__init__()

        # All possible operations (weights defined only once)
        self.ops = nn.ModuleDict({
            'conv_3x3': nn.Conv2d(C, C, 3, padding=1, bias=False),
            'conv_5x5': nn.Conv2d(C, C, 5, padding=2, bias=False),
            'sep_conv_3x3': nn.Sequential(
                nn.Conv2d(C, C, 3, padding=1, groups=C, bias=False),
                nn.Conv2d(C, C, 1, bias=False)
            ),
            'max_pool_3x3': nn.MaxPool2d(3, stride=1, padding=1),
            'avg_pool_3x3': nn.AvgPool2d(3, stride=1, padding=1),
            'identity': nn.Identity()
        })

    def forward(self, x, op_name):
        """Apply specified operation"""
        return self.ops[op_name](x)

class SuperNet(nn.Module):
    """Super-network"""

    def __init__(self, C=16):
        super(SuperNet, self).__init__()
        self.shared_ops = SharedOperations(C)

    def forward(self, x, architecture):
        """
        architecture: Format [(op_name, input_id), ...]
        """
        # Initial state
        states = [x]

        for op_name, input_id in architecture:
            s = self.shared_ops(states[input_id], op_name)
            states.append(s)

        # Return last state
        return states[-1]

# Build super-network
supernet = SuperNet(C=16)

print("=== Weight Sharing Verification ===")
print(f"Number of super-network parameters: {sum(p.numel() for p in supernet.parameters()):,}")

# Parameters per operation
print("\nNumber of parameters per operation:")
for name, op in supernet.shared_ops.ops.items():
    num_params = sum(p.numel() for p in op.parameters())
    print(f"  {name}: {num_params:,}")

# Two different architectures
arch1 = [('conv_3x3', 0), ('max_pool_3x3', 0), ('identity', 1)]
arch2 = [('conv_5x5', 0), ('avg_pool_3x3', 0), ('conv_3x3', 1)]

# Same input
x = torch.randn(2, 16, 32, 32)

# Forward pass with architecture 1
output1 = supernet(x, arch1)

# Forward pass with architecture 2
output2 = supernet(x, arch2)

print(f"\n=== Forward Pass Verification ===")
print(f"Architecture 1 output shape: {output1.shape}")
print(f"Architecture 2 output shape: {output2.shape}")

# Verify weights are shared
print("\n=== Weight Sharing Confirmation ===")
conv_3x3_params_before = list(supernet.shared_ops.ops['conv_3x3'].parameters())[0].clone()

# Backward pass with architecture 1 (uses conv_3x3)
loss1 = output1.sum()
loss1.backward()

conv_3x3_params_after = list(supernet.shared_ops.ops['conv_3x3'].parameters())[0]

# Check if gradients are accumulated
has_gradient = conv_3x3_params_after.grad is not None
print(f"Gradients accumulated in conv_3x3: {has_gradient}")

# Visually confirm weight sharing
print("\n=== Benefits of Weight Sharing ===")
print("1. Memory efficiency: Same weights used for all architectures")
print("2. Training efficiency: Evaluate all candidates with one super-network")
print("3. Speedup: Shared training instead of individual training")

# Try different architectures
print("\n=== Evaluating Multiple Architectures ===")
architectures = [
    [('conv_3x3', 0), ('max_pool_3x3', 0)],
    [('conv_5x5', 0), ('identity', 0)],
    [('sep_conv_3x3', 0), ('avg_pool_3x3', 0)],
]

for i, arch in enumerate(architectures, 1):
    output = supernet(x, arch)
    print(f"Architecture {i}: Output shape = {output.shape}, Mean = {output.mean():.4f}")

print("\n‚Üí All architectures were evaluated while sharing the same weights")
</code></pre>
</details>
<h3>Problem 5 (Difficulty: hard)</h3>
<p>In DARTS bi-level optimization, explain why training and validation data need to be separated for optimization. Also, predict what would happen if the same data were used for optimization.</p>
<details>
<summary>Sample Answer</summary>
<p><strong>Answer</strong>:</p>
<p><strong>Purpose of Bi-level Optimization</strong>:</p>
<p>DARTS optimizes two types of parameters:</p>
<ol>
<li><strong>Network weights (w)</strong>: Minimize on training data</li>
<li><strong>Architecture parameters (Œ±)</strong>: Minimize on validation data</li>
</ol>
<p>Optimization problem:</p>
<p>$$
\begin{aligned}
\min_{\alpha} \quad &amp; \mathcal{L}_{\text{val}}(w^*(\alpha), \alpha) \\
\text{s.t.} \quad &amp; w^*(\alpha) = \arg\min_{w} \mathcal{L}_{\text{train}}(w, \alpha)
\end{aligned}
$$</p>
<p><strong>Reasons for Separating Training/Validation Data</strong>:</p>
<ol>
<li><p><strong>Preventing Overfitting</strong></p>
<ul>
<li>Optimizing Œ± on training data would select architectures overfitted to training data</li>
<li>Optimizing on validation data selects architectures with high generalization performance</li>
</ul></li>
<li><p><strong>Role Separation</strong></p>
<ul>
<li>w: Learn best weights for given architecture (training data)</li>
<li>Œ±: Select architecture with highest validation performance (validation data)</li>
</ul></li>
<li><p><strong>Fair Evaluation</strong></p>
<ul>
<li>Evaluate w trained on training data on independent validation data</li>
<li>Architecture selection reflecting true generalization performance</li>
</ul></li>
</ol>
<p><strong>Problems When Optimizing with Same Data</strong>:</p>
<pre><code class="language-python"># Incorrect method (optimize w and Œ± with same data)
# ‚ùå Problematic code example
for epoch in range(num_epochs):
    # Update w on training data
    loss_w = train_loss(w, alpha, train_data)
    w.update(-lr * grad(loss_w, w))

    # Update Œ± on same training data ‚Üê Problem!
    loss_alpha = train_loss(w, alpha, train_data)
    alpha.update(-lr * grad(loss_alpha, alpha))
</code></pre>
<p><strong>Resulting Problems</strong>:</p>
<ol>
<li><strong>Overfitting</strong>: Selects architectures specialized to training data</li>
<li><strong>Identity Operation Preference</strong>: Preferentially selects skip connections since they reduce training loss without computational cost</li>
<li><strong>Degraded Generalization</strong>: Poor performance on test data</li>
<li><strong>Failure of Meaningful Search</strong>: Cannot discover truly useful architectures</li>
</ol>
<p><strong>Correct Method</strong>:</p>
<pre><code class="language-python"># ‚úÖ Correct method
for epoch in range(num_epochs):
    # Update w on training data
    loss_w = train_loss(w, alpha, train_data)
    w.update(-lr * grad(loss_w, w))

    # Update Œ± on validation data ‚Üê Correct!
    loss_alpha = val_loss(w, alpha, val_data)
    alpha.update(-lr * grad(loss_alpha, alpha))
</code></pre>
<p><strong>Summary</strong>:</p>
<table>
<thead>
<tr>
<th>Aspect</th>
<th>Train/Val Separation</th>
<th>Same Data</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Overfitting</strong></td>
<td>Prevented</td>
<td>Prone to overfitting</td>
</tr>
<tr>
<td><strong>Generalization</strong></td>
<td>High</td>
<td>Low</td>
</tr>
<tr>
<td><strong>Architecture</strong></td>
<td>Useful</td>
<td>Trivial (identity-biased)</td>
</tr>
<tr>
<td><strong>Practicality</strong></td>
<td>High</td>
<td>Low</td>
</tr>
</tbody>
</table>
</details>
<hr/>
<h2>References</h2>
<ol>
<li>Zoph, B., &amp; Le, Q. V. (2017). <em>Neural Architecture Search with Reinforcement Learning</em>. ICLR 2017.</li>
<li>Liu, H., Simonyan, K., &amp; Yang, Y. (2019). <em>DARTS: Differentiable Architecture Search</em>. ICLR 2019.</li>
<li>Pham, H., Guan, M., Zoph, B., Le, Q., &amp; Dean, J. (2018). <em>Efficient Neural Architecture Search via Parameter Sharing</em>. ICML 2018.</li>
<li>Real, E., et al. (2019). <em>Regularized Evolution for Image Classifier Architecture Search</em>. AAAI 2019.</li>
<li>Jin, H., Song, Q., &amp; Hu, X. (2019). <em>Auto-Keras: An Efficient Neural Architecture Search System</em>. KDD 2019.</li>
<li>Elsken, T., Metzen, J. H., &amp; Hutter, F. (2019). <em>Neural Architecture Search: A Survey</em>. JMLR 2019.</li>
</ol>
<div class="navigation">
<a class="nav-button" href="chapter2-hyperparameter-optimization.html">‚Üê Previous Chapter: Hyperparameter Optimization</a>
<a class="nav-button" href="chapter4-feature-engineering.html">Next Chapter: Feature Engineering Automation ‚Üí</a>
</div>
</main>
<section class="disclaimer">
<h3>Disclaimer</h3>
<ul>
<li>This content is provided for educational, research, and informational purposes only and does not constitute professional advice (legal, accounting, technical guarantees, etc.).</li>
<li>This content and accompanying code examples are provided "AS IS" without any express or implied warranties, including but not limited to merchantability, fitness for a particular purpose, non-infringement, accuracy, completeness, operation, and safety.</li>
<li>The content creators and Tohoku University assume no responsibility for the content, availability, or safety of external links, third-party data, tools, or libraries.</li>
<li>The content creators and Tohoku University shall not be liable for any direct, indirect, incidental, special, consequential, or punitive damages arising from the use, execution, or interpretation of this content, to the maximum extent permitted by applicable law.</li>
<li>The content of this material is subject to change, update, or discontinuation without notice.</li>
<li>The copyright and license of this content are subject to the specified terms (e.g., CC BY 4.0). Such licenses typically include no-warranty clauses.</li>
</ul>
</section>
<footer>
<p><strong>Author</strong>: AI Terakoya Content Team</p>
<p><strong>Version</strong>: 1.0 | <strong>Created</strong>: 2025-10-21</p>
<p><strong>License</strong>: Creative Commons BY 4.0</p>
<p>¬© 2025 AI Terakoya. All rights reserved.</p>
</footer>
</body>
</html>
