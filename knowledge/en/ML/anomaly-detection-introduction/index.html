<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Anomaly Detection Introduction Series - From Statistical Methods to Deep Learning-Based Anomaly Detection">
    <title>Anomaly Detection Introduction Series v1.0 - AI Terakoya</title>

    <!-- CSS Styling -->
        <link rel="stylesheet" href="../../assets/css/knowledge-base.css">

    <!-- Mermaid for diagrams -->
    <script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
    <script>
        // Mermaid.js Converter - Converts markdown-style mermaid code blocks to renderable divs
        document.addEventListener('DOMContentLoaded', function() {
            // Find all code blocks with class="language-mermaid"
            const mermaidCodeBlocks = document.querySelectorAll('pre.codehilite code.language-mermaid, pre code.language-mermaid');

            mermaidCodeBlocks.forEach(function(codeBlock) {
                const pre = codeBlock.parentElement;
                const mermaidCode = codeBlock.textContent;

                // Create a new div with mermaid class
                const mermaidDiv = document.createElement('div');
                mermaidDiv.className = 'mermaid';
                mermaidDiv.textContent = mermaidCode.trim();

                // Replace the pre element with the new div
                pre.parentNode.replaceChild(mermaidDiv, pre);
            });

            // Re-initialize mermaid after conversion
            if (typeof mermaid !== 'undefined') {
                mermaid.initialize({ startOnLoad: true, theme: 'default' });
                mermaid.init(undefined, document.querySelectorAll('.mermaid'));
            }
        });
    </script>
</head>
<body>
            <nav class="breadcrumb">
        <div class="breadcrumb-content">
            <a href="../../index.html">AI Terakoya Top</a><span class="breadcrumb-separator">‚Ä∫</span><a href="../index.html">Machine Learning</a><span class="breadcrumb-separator">‚Ä∫</span><span class="breadcrumb-current">Anomaly Detection</span>
        </div>
    </nav>

        <header>
        <div class="container">
            <h1>üîç Anomaly Detection Introduction Series v1.0</h1>
            <p style="font-size: 1.1rem; margin-top: 0.5rem; opacity: 0.95;">From Statistical Methods to Deep Learning-Based Anomaly Detection</p>
            <div class="meta">
                <span>üìñ Total Learning Time: 4.5-5.5 hours</span>
                <span>üìä Level: Intermediate</span>
            </div>
        </div>
    </header>

    <main class="container">
        <p><strong>Learn implementation methods for anomaly detection in real-world data, from fundamentals of anomaly detection to statistical methods, machine learning, and deep learning-based anomaly detection techniques</strong></p>

        <h2 id="overview">Series Overview</h2>
        <p>This series is a practical educational content consisting of four chapters that allows you to systematically learn the theory and implementation of Anomaly Detection from fundamentals to advanced levels.</p>

        <p><strong>Anomaly Detection</strong> is a machine learning technology that identifies data points that deviate from normal patterns, playing a crucial role in various fields such as defect detection in manufacturing, fraud detection in finance, intrusion detection in cybersecurity, and early disease detection in healthcare. Starting with statistical approaches using the 3-sigma rule and outlier detection, we will systematically study diverse methods including machine learning-based Isolation Forest, One-Class SVM, deep learning-based Autoencoders, VAE, GAN, and even time series anomaly detection. Understanding the differences between unsupervised learning that trains only on normal data, semi-supervised learning that uses a small amount of abnormal data, and supervised learning that uses both labels, you will be able to select and implement appropriate methods according to actual business challenges. Through practical implementation using major libraries such as scikit-learn, PyTorch, and TensorFlow, you will acquire skills in building anomaly detection systems.</p>

        <p><strong>Features:</strong></p>
        <ul>
            <li>‚úÖ <strong>From Theory to Practice</strong>: Systematic learning from fundamental concepts of anomaly detection to implementation and evaluation</li>
            <li>‚úÖ <strong>Implementation-Focused</strong>: Over 35 executable Python/scikit-learn/PyTorch code examples</li>
            <li>‚úÖ <strong>Diverse Methods</strong>: Wide range of approaches including statistical methods, machine learning, and deep learning</li>
            <li>‚úÖ <strong>Latest Technology Compliance</strong>: Comprehensive coverage of Autoencoders, VAE, GAN, and time series anomaly detection</li>
            <li>‚úÖ <strong>Practical Applications</strong>: Real-world application examples in manufacturing, finance, security, and healthcare</li>
        </ul>

        <p><strong>Total Learning Time</strong>: 4.5-5.5 hours (including code execution and exercises)</p>

        <h2 id="learning">How to Learn</h2>

        <h3>Recommended Learning Sequence</h3>

        <div class="mermaid">
graph TD
    A[Chapter 1: Fundamentals of Anomaly Detection] --> B[Chapter 2: Statistical Methods]
    B --> C[Chapter 3: Machine Learning-Based Anomaly Detection]
    C --> D[Chapter 4: Deep Learning-Based Anomaly Detection]

    style A fill:#e3f2fd
    style B fill:#fff3e0
    style C fill:#f3e5f5
    style D fill:#e8f5e9
</div>

        <p><strong>For Beginners (completely new to anomaly detection):</strong><br>
        - Chapter 1 ‚Üí Chapter 2 ‚Üí Chapter 3 ‚Üí Chapter 4 (all chapters recommended)<br>
        - Time required: 4.5-5.5 hours</p>

        <p><strong>For Intermediate Learners (with machine learning experience):</strong><br>
        - Chapter 2 ‚Üí Chapter 3 ‚Üí Chapter 4<br>
        - Time required: 3.5-4.5 hours</p>

        <p><strong>For Focused Topic Study:</strong><br>
        - Anomaly detection fundamentals and evaluation metrics: Chapter 1 (focused study)<br>
        - Statistical methods and outlier detection: Chapter 2 (focused study)<br>
        - Machine learning-based methods: Chapter 3 (focused study)<br>
        - Deep learning and time series anomaly detection: Chapter 4 (focused study)<br>
        - Time required: 60-80 minutes/chapter</p>

        <h2 id="chapters">Chapter Details</h2>

        <h3><a href="./chapter1-anomaly-basics.html">Chapter 1: Fundamentals of Anomaly Detection</a></h3>
        <p><strong>Difficulty</strong>: Intermediate<br>
        <strong>Reading Time</strong>: 60-70 minutes<br>
        <strong>Code Examples</strong>: 8</p>

        <h4>Learning Content</h4>
        <ol>
            <li><strong>What is Anomaly Detection</strong> - Definition of anomalies, deviation from normal patterns</li>
            <li><strong>Types of Tasks</strong> - Unsupervised learning, semi-supervised learning, supervised learning</li>
            <li><strong>Application Areas</strong> - Manufacturing, finance, security, healthcare, IoT</li>
            <li><strong>Evaluation Metrics</strong> - Precision, recall, F1 score, ROC-AUC, PR-AUC</li>
            <li><strong>Challenges and Constraints</strong> - Class imbalance, lack of labels, real-time requirements</li>
        </ol>

        <h4>Learning Objectives</h4>
        <ul>
            <li>‚úÖ Understand fundamental concepts of anomaly detection</li>
            <li>‚úÖ Explain types of anomaly detection tasks</li>
            <li>‚úÖ Select appropriate evaluation metrics</li>
            <li>‚úÖ Understand challenges of class imbalance</li>
            <li>‚úÖ Explain real-world applications of anomaly detection</li>
        </ul>

        <p><strong><a href="./chapter1-anomaly-basics.html">Read Chapter 1 ‚Üí</a></strong></p>

        <hr>

        <h3><a href="./chapter2-statistical-methods.html">Chapter 2: Statistical Methods</a></h3>
        <p><strong>Difficulty</strong>: Intermediate<br>
        <strong>Reading Time</strong>: 60-70 minutes<br>
        <strong>Code Examples</strong>: 9</p>

        <h4>Learning Content</h4>
        <ol>
            <li><strong>3-Sigma Rule</strong> - Normal distribution-based anomaly detection, mean and standard deviation</li>
            <li><strong>Interquartile Range (IQR)</strong> - Box plots, outlier detection</li>
            <li><strong>Mahalanobis Distance</strong> - Multivariate data anomaly detection, accounting for correlations</li>
            <li><strong>Statistical Hypothesis Testing</strong> - Grubbs test, Dixon test, outlier significance</li>
            <li><strong>Moving Average and Moving Standard Deviation</strong> - Time series data anomaly detection</li>
        </ol>

        <h4>Learning Objectives</h4>
        <ul>
            <li>‚úÖ Detect anomalies using the 3-sigma rule</li>
            <li>‚úÖ Implement outlier detection using IQR</li>
            <li>‚úÖ Calculate Mahalanobis distance</li>
            <li>‚úÖ Apply statistical hypothesis testing</li>
            <li>‚úÖ Detect anomalies in time series data</li>
        </ul>

        <p><strong><a href="./chapter2-statistical-methods.html">Read Chapter 2 ‚Üí</a></strong></p>

        <hr>

        <h3><a href="./chapter3-ml-based-anomaly.html">Chapter 3: Machine Learning-Based Anomaly Detection</a></h3>
        <p><strong>Difficulty</strong>: Intermediate<br>
        <strong>Reading Time</strong>: 70-80 minutes<br>
        <strong>Code Examples</strong>: 10</p>

        <h4>Learning Content</h4>
        <ol>
            <li><strong>Isolation Forest</strong> - Anomaly detection through random isolation, handling high-dimensional data</li>
            <li><strong>LOF (Local Outlier Factor)</strong> - Local density-based anomaly scoring, neighborhood-based method</li>
            <li><strong>One-Class SVM</strong> - Learning normal data boundaries, kernel methods</li>
            <li><strong>DBSCAN</strong> - Density-based clustering, noise detection</li>
            <li><strong>K-Nearest Neighbors (KNN)</strong> - Distance-based anomaly detection, simple and effective</li>
        </ol>

        <h4>Learning Objectives</h4>
        <ul>
            <li>‚úÖ Detect anomalies using Isolation Forest</li>
            <li>‚úÖ Detect local anomalies using LOF</li>
            <li>‚úÖ Implement One-Class SVM</li>
            <li>‚úÖ Identify noise using DBSCAN</li>
            <li>‚úÖ Understand characteristics and usage of each method</li>
        </ul>

        <p><strong><a href="./chapter3-ml-based-anomaly.html">Read Chapter 3 ‚Üí</a></strong></p>

        <hr>

        <h3><a href="./chapter4-deep-learning-anomaly.html">Chapter 4: Deep Learning-Based Anomaly Detection</a></h3>
        <p><strong>Difficulty</strong>: Intermediate to Advanced<br>
        <strong>Reading Time</strong>: 80-90 minutes<br>
        <strong>Code Examples</strong>: 11</p>

        <h4>Learning Content</h4>
        <ol>
            <li><strong>Autoencoder</strong> - Reconstruction error-based anomaly detection, dimensionality reduction</li>
            <li><strong>VAE (Variational Autoencoder)</strong> - Probabilistic latent representations, generative models</li>
            <li><strong>GAN (Generative Adversarial Network)</strong> - AnoGAN, normal data generation</li>
            <li><strong>LSTM Autoencoder</strong> - Time series anomaly detection, sequential pattern learning</li>
            <li><strong>Transformer</strong> - Attention mechanism, capturing long-term dependencies</li>
        </ol>

        <h4>Learning Objectives</h4>
        <ul>
            <li>‚úÖ Detect anomalies using Autoencoders</li>
            <li>‚úÖ Implement probabilistic anomaly detection using VAE</li>
            <li>‚úÖ Understand GAN-based anomaly detection</li>
            <li>‚úÖ Detect time series anomalies using LSTM Autoencoder</li>
            <li>‚úÖ Apply Transformers to anomaly detection</li>
        </ul>

        <p><strong><a href="./chapter4-deep-learning-anomaly.html">Read Chapter 4 ‚Üí</a></strong></p>

        <hr>

        <h2 id="outcomes">Overall Learning Outcomes</h2>

        <p>Upon completing this series, you will acquire the following skills and knowledge:</p>

        <h3>Knowledge Level (Understanding)</h3>
        <ul>
            <li>‚úÖ Explain fundamental concepts and types of anomaly detection tasks</li>
            <li>‚úÖ Understand characteristics of statistical methods, machine learning, and deep learning</li>
            <li>‚úÖ Explain advantages, disadvantages, and usage scenarios for each method</li>
            <li>‚úÖ Understand meaning and selection criteria for evaluation metrics</li>
            <li>‚úÖ Explain approaches to handling class imbalance problems</li>
        </ul>

        <h3>Practical Skills (Doing)</h3>
        <ul>
            <li>‚úÖ Detect outliers using 3-sigma rule and IQR</li>
            <li>‚úÖ Implement Isolation Forest and LOF</li>
            <li>‚úÖ Learn normal patterns using One-Class SVM</li>
            <li>‚úÖ Detect anomalies using Autoencoders</li>
            <li>‚úÖ Implement time series anomaly detection</li>
        </ul>

        <h3>Application Ability (Applying)</h3>
        <ul>
            <li>‚úÖ Select methods based on data characteristics</li>
            <li>‚úÖ Measure performance with appropriate evaluation metrics</li>
            <li>‚úÖ Handle class imbalance</li>
            <li>‚úÖ Design real-time anomaly detection systems</li>
            <li>‚úÖ Solve anomaly detection challenges in practical business contexts</li>
        </ul>

        <hr>

        <h2 id="prerequisites">Prerequisites</h2>

        <p>To effectively learn this series, it is desirable to have the following knowledge:</p>

        <h3>Required (Must Have)</h3>
        <ul>
            <li>‚úÖ <strong>Python Fundamentals</strong>: Variables, functions, classes, NumPy, pandas</li>
            <li>‚úÖ <strong>Machine Learning Fundamentals</strong>: Concepts of training, validation, and testing</li>
            <li>‚úÖ <strong>Statistics Fundamentals</strong>: Mean, standard deviation, normal distribution</li>
            <li>‚úÖ <strong>scikit-learn Fundamentals</strong>: Model training and evaluation</li>
            <li>‚úÖ <strong>Data Visualization</strong>: matplotlib, seaborn</li>
        </ul>

        <h3>Recommended (Nice to Have)</h3>
        <ul>
            <li>üí° <strong>Deep Learning Fundamentals</strong>: Neural networks, gradient descent (for Chapter 4)</li>
            <li>üí° <strong>PyTorch/TensorFlow</strong>: Deep learning frameworks (for Chapter 4)</li>
            <li>üí° <strong>Time Series Analysis</strong>: ARIMA, moving averages (for time series anomaly detection)</li>
            <li>üí° <strong>Dimensionality Reduction</strong>: PCA, t-SNE (for visualization)</li>
            <li>üí° <strong>Clustering</strong>: K-means, DBSCAN (for Chapter 3)</li>
        </ul>

        <p><strong>Recommended Prior Learning</strong>:</p>
        <ul>
            <li>üìö <a href="../machine-learning-basics/">Machine Learning Introduction Series</a> - ML fundamentals</li>
            <!-- Content in preparation <li>üìö <a href="../python-for-ml/">Python Machine Learning Practice</a> - scikit-learn, pandas</li>
            <!-- Content in preparation <li>üìö <a href="../deep-learning-basics/">Deep Learning Introduction</a> - Neural network fundamentals</li>
            <li>üìö <a href="../statistics-for-ml/">Statistics for Machine Learning</a> - Statistics fundamentals</li>
        </ul>

        <hr>

        <h2 id="tech">Technologies and Tools Used</h2>

        <h3>Main Libraries</h3>
        <ul>
            <li><strong>scikit-learn 1.3+</strong> - Isolation Forest, LOF, One-Class SVM</li>
            <li><strong>PyTorch 2.0+</strong> - Autoencoder, VAE, LSTM</li>
            <li><strong>TensorFlow 2.13+</strong> - Keras, deep learning models</li>
            <li><strong>NumPy 1.24+</strong> - Numerical computation, statistical processing</li>
            <li><strong>pandas 2.0+</strong> - Data processing, time series analysis</li>
            <li><strong>matplotlib 3.7+</strong> - Data visualization</li>
            <li><strong>seaborn 0.12+</strong> - Statistical visualization</li>
        </ul>

        <h3>Development Environment</h3>
        <ul>
            <li><strong>Python 3.8+</strong> - Programming language</li>
            <li><strong>Jupyter Notebook/Lab</strong> - Interactive development environment</li>
            <li><strong>Google Colab</strong> - Cloud GPU environment (recommended)</li>
            <li><strong>VSCode</strong> - Code editor (recommended)</li>
        </ul>

        <h3>Datasets</h3>
        <ul>
            <li><strong>KDD Cup 99</strong> - Network intrusion detection</li>
            <li><strong>Credit Card Fraud Detection</strong> - Credit card fraud detection</li>
            <li><strong>MNIST Anomaly</strong> - Image anomaly detection</li>
            <li><strong>NAB (Numenta Anomaly Benchmark)</strong> - Time series anomaly detection</li>
        </ul>

        <hr>

        <h2 id="start">Let's Get Started!</h2>
        <p>Are you ready? Start with Chapter 1 and master anomaly detection techniques!</p>

        <p><strong><a href="./chapter1-anomaly-basics.html">Chapter 1: Fundamentals of Anomaly Detection ‚Üí</a></strong></p>

        <hr>

        <h2 id="next">Next Steps</h2>

        <p>After completing this series, we recommend advancing to the following topics:</p>

        <h3>Advanced Study</h3>
        <ul>
            <li>üìö <strong>Real-Time Anomaly Detection</strong>: Streaming data, online learning</li>
            <li>üìö <strong>Explainable Anomaly Detection</strong>: SHAP, LIME, why was it classified as anomalous</li>
            <li>üìö <strong>Graph Anomaly Detection</strong>: Social networks, fraud ring detection</li>
            <li>üìö <strong>Multimodal Anomaly Detection</strong>: Integration of image, audio, and sensor data</li>
        </ul>

        <h3>Related Series</h3>
        <ul>
            <li>üéØ <a href="../time-series-forecasting/">Time Series Forecasting Introduction</a> - Time series analysis, LSTM, Transformer</li>
            <li>üéØ <a href="../autoencoder-deep-dive/">Autoencoder In-Depth</a> - VAE, Denoising AE, Sparse AE</li>
            <li>üéØ <a href="../imbalanced-learning/">Imbalanced Data Learning</a> - SMOTE, cost-sensitive learning</li>
        </ul>

        <h3>Practical Projects</h3>
        <ul>
            <li>üöÄ Defect Detection System in Manufacturing - Image-based anomaly detection</li>
            <li>üöÄ Credit Card Fraud Detection - Real-time anomaly scoring</li>
            <li>üöÄ Server Monitoring System - Time series anomaly detection and alerting</li>
            <li>üöÄ Medical Image Anomaly Detection - Lesion detection using VAE</li>
        </ul>

        <hr>

        <p><strong>Update History</strong></p>
        <ul>
            <li><strong>2025-10-21</strong>: v1.0 first edition released</li>
        </ul>

        <hr>

        <p><strong>Your journey into anomaly detection starts here!</strong></p>

    </main>


    <section class="disclaimer">
        <h3>Disclaimer</h3>
        <ul>
            <li>This content is provided solely for educational, research, and informational purposes and does not constitute professional advice (legal, accounting, technical guarantees, etc.).</li>
            <li>This content and accompanying code examples are provided "AS IS" without any warranties, express or implied, including but not limited to merchantability, fitness for a particular purpose, non-infringement, accuracy, completeness, operation, or safety.</li>
            <li>The authors and Tohoku University assume no responsibility for the content, availability, or safety of external links or third-party data, tools, or libraries.</li>
            <li>To the maximum extent permitted by applicable law, the authors and Tohoku University shall not be liable for any direct, indirect, incidental, special, consequential, or punitive damages arising from the use, execution, or interpretation of this content.</li>
            <li>The content of this material may be changed, updated, or discontinued without notice.</li>
            <li>The copyright and license of this content follow the specified conditions (e.g., CC BY 4.0). Such licenses typically include no-warranty clauses.</li>
        </ul>
    </section>

<footer>
        <div class="container">
            <p>&copy; 2025 AI Terakoya - Dr. Yusuke Hashimoto, Tohoku University</p>
            <p>Licensed under CC BY 4.0</p>
        </div>
    </footer>
</body>
</html>
