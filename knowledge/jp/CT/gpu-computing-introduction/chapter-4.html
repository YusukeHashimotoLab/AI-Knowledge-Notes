<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>第4章: CUDA性能最適化 - 並列計算パフォーマンス向上技法 - GPU並列計算入門 - CT Dojo</title>
    <meta name="description" content="占有率最適化、ワープダイバージェンス回避、リダクション最適化、アトミック演算、ストリーム並列実行を学ぶ。">

    <!-- Prism.js for code highlighting -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css">

    <!-- MathJax for mathematical expressions -->
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

    <!-- Mermaid for diagrams -->
    <script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>

    <style>
        :root {
            --accent-green: #11998e;
            --accent-lime: #38ef7d;
            --primary-dark: #2c3e50;
            --secondary-dark: #34495e;
            --text-dark: #2c3e50;
            --text-light: #7f8c8d;
            --bg-light: #ecf0f1;
            --white: #ffffff;
            --code-bg: #2d2d2d;
            --border-light: #bdc3c7;
            --success: #27ae60;
            --warning: #f39c12;
            --danger: #e74c3c;
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            line-height: 1.8;
            color: var(--text-dark);
            background: var(--bg-light);
        }

        header {
            background: linear-gradient(135deg, var(--accent-green) 0%, var(--accent-lime) 100%);
            color: white;
            padding: 3rem 1.5rem;
            text-align: center;
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
        }

        header h1 {
            font-size: 2rem;
            font-weight: 700;
            margin-bottom: 0.5rem;
        }

        header p {
            font-size: 1.1rem;
            opacity: 0.95;
        }

        nav {
            background: var(--white);
            padding: 1rem;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
            position: sticky;
            top: 0;
            z-index: 100;
        }

        nav ul {
            list-style: none;
            display: flex;
            flex-wrap: wrap;
            justify-content: center;
            gap: 0.5rem;
        }

        nav a {
            text-decoration: none;
            color: var(--text-dark);
            padding: 0.5rem 1rem;
            border-radius: 4px;
            transition: all 0.3s;
            font-weight: 500;
        }

        nav a:hover {
            background: linear-gradient(135deg, var(--accent-green) 0%, var(--accent-lime) 100%);
            color: white;
        }

        main {
            max-width: 900px;
            margin: 2rem auto;
            padding: 0 1.5rem;
        }

        section {
            background: var(--white);
            margin-bottom: 2rem;
            padding: 2.5rem;
            border-radius: 8px;
            box-shadow: 0 2px 8px rgba(0,0,0,0.1);
        }

        h2 {
            color: var(--primary-dark);
            font-size: 1.8rem;
            margin-bottom: 1.5rem;
            padding-bottom: 0.75rem;
            border-bottom: 3px solid var(--accent-green);
        }

        h3 {
            color: var(--secondary-dark);
            font-size: 1.4rem;
            margin-top: 2rem;
            margin-bottom: 1rem;
        }

        h4 {
            color: var(--secondary-dark);
            font-size: 1.1rem;
            margin-top: 1.5rem;
            margin-bottom: 0.75rem;
        }

        p {
            margin-bottom: 1rem;
            text-align: justify;
        }

        ul, ol {
            margin-bottom: 1rem;
            padding-left: 2rem;
        }

        li {
            margin-bottom: 0.5rem;
        }

        pre {
            background: var(--code-bg);
            border-radius: 6px;
            padding: 1.25rem;
            overflow-x: auto;
            margin-bottom: 1.5rem;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }

        code {
            font-family: 'Courier New', Courier, monospace;
            font-size: 0.9rem;
        }

        p code, li code {
            background: #f4f4f4;
            padding: 0.2rem 0.4rem;
            border-radius: 3px;
            color: var(--danger);
            font-size: 0.85rem;
        }

        .info-box {
            background: linear-gradient(135deg, rgba(17, 153, 142, 0.1) 0%, rgba(56, 239, 125, 0.1) 100%);
            border-left: 4px solid var(--accent-green);
            padding: 1.25rem;
            margin-bottom: 1.5rem;
            border-radius: 4px;
        }

        .warning-box {
            background: rgba(243, 156, 18, 0.1);
            border-left: 4px solid var(--warning);
            padding: 1.25rem;
            margin-bottom: 1.5rem;
            border-radius: 4px;
        }

        .danger-box {
            background: rgba(231, 76, 60, 0.1);
            border-left: 4px solid var(--danger);
            padding: 1.25rem;
            margin-bottom: 1.5rem;
            border-radius: 4px;
        }

        .exercise {
            background: rgba(52, 152, 219, 0.05);
            border: 2px solid #3498db;
            padding: 1.5rem;
            margin-bottom: 1.5rem;
            border-radius: 6px;
        }

        .exercise h4 {
            color: #2980b9;
            margin-top: 0;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: 1.5rem;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }

        th, td {
            padding: 1rem;
            text-align: left;
            border-bottom: 1px solid var(--border-light);
        }

        th {
            background: linear-gradient(135deg, var(--accent-green) 0%, var(--accent-lime) 100%);
            color: white;
            font-weight: 600;
        }

        tr:hover {
            background: rgba(17, 153, 142, 0.05);
        }

        .mermaid {
            background: white;
            padding: 2rem;
            border-radius: 6px;
            margin-bottom: 1.5rem;
            text-align: center;
        }

        footer {
            background: var(--primary-dark);
            color: white;
            text-align: center;
            padding: 2rem;
            margin-top: 3rem;
        }

        footer a {
            color: var(--accent-lime);
            text-decoration: none;
        }

        footer a:hover {
            text-decoration: underline;
        }

        @media (max-width: 768px) {
            header h1 {
                font-size: 1.5rem;
            }

            section {
                padding: 1.5rem;
            }

            h2 {
                font-size: 1.5rem;
            }

            h3 {
                font-size: 1.2rem;
            }

            nav ul {
                flex-direction: column;
            }

            table {
                font-size: 0.9rem;
            }

            th, td {
                padding: 0.5rem;
            }
        }
    </style>
</head>
<body>
    <header>
        <h1>第4章: CUDA性能最適化</h1>
        <p>並列計算パフォーマンス向上技法</p>
    </header>

    <nav>
        <ul>
            <li><a href="index.html">ホーム</a></li>
            <li><a href="chapter-1.html">第1章: GPU並列計算基礎</a></li>
            <li><a href="chapter-2.html">第2章: CUDAプログラミング入門</a></li>
            <li><a href="chapter-3.html">第3章: メモリ階層と最適化</a></li>
            <li><a href="chapter-4.html">第4章: CUDA性能最適化</a></li>
            <li><a href="chapter-5.html">第5章: 高度な並列アルゴリズム</a></li>
        </ul>
    </nav>

    <main>
        <section id="introduction">
            <h2>本章の概要</h2>
            <p>
                GPU並列計算において、ハードウェアの性能を最大限に引き出すためには、単にコードを並列化するだけでは不十分です。本章では、CUDAプログラムのパフォーマンスを劇的に向上させるための5つの重要な最適化技法を学びます。
            </p>

            <div class="info-box">
                <h4>本章で学ぶ内容</h4>
                <ul>
                    <li><strong>占有率（Occupancy）最適化</strong>: SMリソースの効率的な利用</li>
                    <li><strong>ワープダイバージェンス回避</strong>: SIMT実行モデルの効率化</li>
                    <li><strong>並列リダクション最適化</strong>: 集約計算の高速化</li>
                    <li><strong>アトミック演算の効率化</strong>: 競合の最小化技法</li>
                    <li><strong>ストリーム並列実行</strong>: 計算とデータ転送のオーバーラップ</li>
                </ul>
            </div>

            <h3>学習目標</h3>
            <ul>
                <li><strong>レベル1 (理解)</strong>: 占有率、ワープダイバージェンス、ストリームの概念を説明できる</li>
                <li><strong>レベル2 (応用)</strong>: カーネルの最適化、効率的なリダクションの実装、ストリームの活用ができる</li>
                <li><strong>レベル3 (実践)</strong>: 体系的なパフォーマンスチューニング、ルーフライン分析、本番環境での最適化ができる</li>
            </ul>

            <h3>前提知識</h3>
            <p>本章を学習する前に、以下の内容を理解していることが望ましいです：</p>
            <ul>
                <li>CUDAプログラミングの基礎（第2章）</li>
                <li>GPUメモリ階層とアクセスパターン（第3章）</li>
                <li>スレッド、ブロック、グリッドの概念</li>
                <li>共有メモリとレジスタの役割</li>
            </ul>
        </section>

        <section id="occupancy">
            <h2>4.1 占有率（Occupancy）最適化</h2>

            <p>
                <strong>占有率（Occupancy）</strong>は、SM（Streaming Multiprocessor）上で実際に実行されているワープ数の、理論上の最大ワープ数に対する割合です。高い占有率は、メモリレイテンシを隠蔽し、GPUの計算リソースを効率的に活用するために重要です。
            </p>

            <h3>4.1.1 占有率の基礎理論</h3>

            <p>占有率は以下の式で定義されます：</p>
            <p>\[
            \text{Occupancy} = \frac{\text{アクティブなワープ数}}{\text{最大ワープ数}} \times 100\%
            \]</p>

            <p>SMあたりの最大ワープ数は、以下のリソースによって制約されます：</p>

            <table>
                <thead>
                    <tr>
                        <th>リソース</th>
                        <th>制約要因</th>
                        <th>最適化の方向性</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>レジスタ数</td>
                        <td>スレッドあたりのレジスタ使用量</td>
                        <td>レジスタ使用量の削減</td>
                    </tr>
                    <tr>
                        <td>共有メモリ</td>
                        <td>ブロックあたりの共有メモリ使用量</td>
                        <td>共有メモリの効率的な利用</td>
                    </tr>
                    <tr>
                        <td>スレッドブロック数</td>
                        <td>SMあたりの最大ブロック数</td>
                        <td>適切なブロックサイズの選択</td>
                    </tr>
                    <tr>
                        <td>ワープ数</td>
                        <td>SMあたりの最大ワープ数</td>
                        <td>ワープ数の最大化</td>
                    </tr>
                </tbody>
            </table>

            <div class="info-box">
                <h4>NVIDIA GPU世代別の最大リソース</h4>
                <ul>
                    <li><strong>Volta/Turing (SM 7.x)</strong>: 64K レジスタ, 96KB 共有メモリ, 32 ブロック, 64 ワープ/SM</li>
                    <li><strong>Ampere (SM 8.x)</strong>: 64K レジスタ, 164KB 共有メモリ, 32 ブロック, 64 ワープ/SM</li>
                    <li><strong>Hopper (SM 9.0)</strong>: 64K レジスタ, 228KB 共有メモリ, 32 ブロック, 64 ワープ/SM</li>
                </ul>
            </div>

            <h3>4.1.2 占有率の計算と測定</h3>

            <p>
                占有率を計算するには、NVIDIA Occupancy Calculatorを使用するか、プログラム的に計算します。以下は、CuPyを使用した占有率計算と最適化の例です。
            </p>

            <pre><code class="language-python">import cupy as cp
import numpy as np
from time import perf_counter

# 高占有率を目指した最適化カーネル
kernel_high_occupancy = cp.RawKernel(r'''
extern "C" __global__
void optimized_kernel(float* data, int n) {
    // レジスタ使用を最小限に抑えた実装
    int idx = blockIdx.x * blockDim.x + threadIdx.x;

    if (idx < n) {
        // 単純な計算でレジスタ使用を抑制
        float value = data[idx];
        value = value * 2.0f + 1.0f;
        data[idx] = value;
    }
}
''', 'optimized_kernel')

# レジスタ使用が多いカーネル（占有率が下がる）
kernel_low_occupancy = cp.RawKernel(r'''
extern "C" __global__
void register_heavy_kernel(float* data, int n) {
    // 多数のローカル変数でレジスタを消費
    int idx = blockIdx.x * blockDim.x + threadIdx.x;

    if (idx < n) {
        // 複雑な計算で多数のレジスタを使用
        float temp1 = data[idx];
        float temp2 = temp1 * 2.0f;
        float temp3 = temp2 + 1.0f;
        float temp4 = temp3 * 3.0f;
        float temp5 = temp4 + 2.0f;
        float temp6 = temp5 * 4.0f;
        float temp7 = temp6 + 3.0f;
        float temp8 = temp7 * 5.0f;
        data[idx] = temp8;
    }
}
''', 'register_heavy_kernel')

# 占有率測定関数
def measure_occupancy(kernel, block_sizes, data_size=1024*1024):
    """異なるブロックサイズで占有率とパフォーマンスを測定"""

    results = []

    for block_size in block_sizes:
        # データ準備
        data = cp.random.rand(data_size, dtype=cp.float32)
        grid_size = (data_size + block_size - 1) // block_size

        # ウォームアップ
        kernel((grid_size,), (block_size,), (data, data_size))
        cp.cuda.Stream.null.synchronize()

        # パフォーマンス測定
        start = perf_counter()
        for _ in range(100):
            kernel((grid_size,), (block_size,), (data, data_size))
        cp.cuda.Stream.null.synchronize()
        end = perf_counter()

        elapsed_time = (end - start) / 100 * 1000  # ms
        bandwidth = (data_size * 4 * 2) / (elapsed_time / 1000) / 1e9  # GB/s

        results.append({
            'block_size': block_size,
            'time_ms': elapsed_time,
            'bandwidth_gbps': bandwidth
        })

        print(f"Block size {block_size:4d}: {elapsed_time:.4f} ms, {bandwidth:.2f} GB/s")

    return results

# 異なるブロックサイズでテスト
print("高占有率カーネル:")
block_sizes = [64, 128, 256, 512, 1024]
results_high = measure_occupancy(kernel_high_occupancy, block_sizes)

print("\n低占有率カーネル（レジスタ多用）:")
results_low = measure_occupancy(kernel_low_occupancy, block_sizes)

# 最適なブロックサイズの特定
best_high = max(results_high, key=lambda x: x['bandwidth_gbps'])
best_low = max(results_low, key=lambda x: x['bandwidth_gbps'])

print(f"\n最適なブロックサイズ（高占有率）: {best_high['block_size']} -> {best_high['bandwidth_gbps']:.2f} GB/s")
print(f"最適なブロックサイズ（低占有率）: {best_low['block_size']} -> {best_low['bandwidth_gbps']:.2f} GB/s")</code></pre>

            <div class="info-box">
                <h4>実行結果の解釈</h4>
                <p>
                    一般的に、ブロックサイズ128〜256が多くのカーネルで良好なパフォーマンスを示します。しかし、レジスタ使用量が多いカーネルでは、より小さいブロックサイズ（64〜128）が最適となる場合があります。これは、小さいブロックサイズが占有率を改善し、メモリレイテンシの隠蔽を向上させるためです。
                </p>
            </div>

            <h3>4.1.3 占有率とパフォーマンスのトレードオフ</h3>

            <div class="mermaid">
flowchart TD
    A[カーネル設計] --> B{リソース使用量}
    B -->|レジスタ多| C[占有率低下]
    B -->|共有メモリ多| C
    B -->|最適化| D[占有率向上]
    C --> E{計算/メモリ比}
    D --> E
    E -->|計算律速| F[占有率の影響小]
    E -->|メモリ律速| G[占有率の影響大]
    F --> H[その他の最適化を優先]
    G --> I[占有率向上が効果的]

    style A fill:#11998e,color:#fff
    style D fill:#38ef7d,color:#000
    style I fill:#27ae60,color:#fff
            </div>

            <div class="warning-box">
                <h4>占有率100%が常に最適とは限らない</h4>
                <p>
                    <strong>重要な誤解</strong>: 占有率100%を目指すことが常に最適とは限りません。計算律速（Compute-bound）のカーネルでは、占有率が50%でも十分なパフォーマンスを発揮することがあります。逆に、メモリ律速（Memory-bound）のカーネルでは、高い占有率がメモリレイテンシの隠蔽に重要です。
                </p>
                <ul>
                    <li><strong>計算律速</strong>: 演算ユニットの活用が重要 → 占有率の影響は小</li>
                    <li><strong>メモリ律速</strong>: レイテンシ隠蔽が重要 → 占有率の影響は大</li>
                </ul>
            </div>

            <h3>4.1.4 占有率最適化の実践的アプローチ</h3>

            <p>以下は、占有率を改善するための実践的な手法です：</p>

            <pre><code class="language-python">import cupy as cp

# 共有メモリとレジスタのトレードオフを考慮した最適化
optimized_kernel_v2 = cp.RawKernel(r'''
extern "C" __global__
void occupancy_optimized(const float* input, float* output, int n) {
    // 共有メモリサイズを動的に調整可能
    extern __shared__ float shared_data[];

    int tid = threadIdx.x;
    int idx = blockIdx.x * blockDim.x + threadIdx.x;

    // グローバルメモリから共有メモリへのコピー（合体アクセス）
    if (idx < n) {
        shared_data[tid] = input[idx];
    }
    __syncthreads();

    // 共有メモリ上での計算（レジスタ使用を最小化）
    if (idx < n) {
        float value = shared_data[tid];
        value = value * 2.0f + 1.0f;
        output[idx] = value;
    }
}
''', 'occupancy_optimized')

# 占有率を考慮した実行設定
def launch_optimized(data_size):
    """占有率を考慮した最適な実行設定"""

    # デバイスプロパティの取得
    device = cp.cuda.Device()
    attrs = device.attributes

    # SM数とワープサイズ
    num_sms = attrs['MultiProcessorCount']
    warp_size = 32

    # 推奨ブロックサイズ（128〜256が一般的に良好）
    block_size = 256

    # 共有メモリサイズ（ブロックサイズに応じて調整）
    shared_mem_size = block_size * 4  # float: 4 bytes

    # グリッドサイズ
    grid_size = (data_size + block_size - 1) // block_size

    # データ準備
    input_data = cp.random.rand(data_size, dtype=cp.float32)
    output_data = cp.empty(data_size, dtype=cp.float32)

    # カーネル起動
    optimized_kernel_v2(
        (grid_size,), (block_size,),
        (input_data, output_data, data_size),
        shared_mem=shared_mem_size
    )
    cp.cuda.Stream.null.synchronize()

    print(f"実行設定: Grid={grid_size}, Block={block_size}, SharedMem={shared_mem_size} bytes")
    print(f"予想アクティブブロック数: {grid_size}")
    print(f"SM数: {num_sms}")

    return output_data

# 実行例
result = launch_optimized(1024*1024)</code></pre>

            <div class="info-box">
                <h4>占有率最適化のベストプラクティス</h4>
                <ol>
                    <li><strong>適切なブロックサイズの選択</strong>: 128〜256が一般的に良好（ワープサイズの倍数）</li>
                    <li><strong>レジスタ使用量の削減</strong>: 不要な変数を減らし、レジスタスピルを回避</li>
                    <li><strong>共有メモリの効率的な利用</strong>: 必要最小限の共有メモリサイズを使用</li>
                    <li><strong>動的共有メモリの活用</strong>: ブロックサイズに応じた柔軟な設定</li>
                    <li><strong>プロファイラの活用</strong>: NVIDIA Nsight ComputeでOccupancyを測定</li>
                </ol>
            </div>
        </section>

        <section id="warp-divergence">
            <h2>4.2 ワープダイバージェンス回避</h2>

            <p>
                <strong>ワープダイバージェンス（Warp Divergence）</strong>は、同一ワープ内のスレッドが異なる実行パスをたどることで発生するパフォーマンス低下です。CUDA GPUはSIMT（Single Instruction, Multiple Thread）アーキテクチャを採用しており、ワープ内の全スレッドは本来同じ命令を実行します。分岐が発生すると、各パスが順次実行されるため、並列性が損なわれます。
            </p>

            <h3>4.2.1 SIMT実行モデルとワープダイバージェンス</h3>

            <p>
                GPUのワープ（32スレッド）は、SIMT方式で実行されます。条件分岐が発生すると、以下のように動作します：
            </p>

            <pre><code class="language-c">// ワープ内で分岐が発生する例
if (threadIdx.x % 2 == 0) {
    // 偶数スレッド: パスA
} else {
    // 奇数スレッド: パスB
}
// → ワープ内で50%のスレッドがパスA、50%がパスBを実行
// → 実際の実行時間 = パスAの時間 + パスBの時間</code></pre>

            <div class="mermaid">
flowchart TD
    A[ワープ 32スレッド] --> B{条件分岐}
    B -->|True 16スレッド| C[パスA実行]
    B -->|False 16スレッド| D[パスBを待機]
    C --> E[パスB実行]
    D --> E
    E --> F[パスAを待機]
    F --> G[合流後に継続]

    style A fill:#11998e,color:#fff
    style C fill:#38ef7d,color:#000
    style E fill:#38ef7d,color:#000
    style G fill:#27ae60,color:#fff
            </div>

            <h3>4.2.2 ダイバージェントコードと非ダイバージェントコードの比較</h3>

            <p>以下は、ワープダイバージェンスを引き起こすコードと、それを回避したコードの比較です。</p>

            <pre><code class="language-python">import cupy as cp
import numpy as np
from time import perf_counter

# ダイバージェントカーネル（非効率）
divergent_kernel = cp.RawKernel(r'''
extern "C" __global__
void divergent(float* data, int n) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;

    if (idx < n) {
        // ワープ内で分岐が発生
        if (idx % 2 == 0) {
            // 偶数スレッド: 複雑な計算
            data[idx] = data[idx] * 2.0f;
            data[idx] = data[idx] + 1.0f;
            data[idx] = data[idx] * 3.0f;
        } else {
            // 奇数スレッド: 異なる計算
            data[idx] = data[idx] * 3.0f;
            data[idx] = data[idx] + 2.0f;
            data[idx] = data[idx] * 2.0f;
        }
    }
}
''', 'divergent')

# 非ダイバージェントカーネル（効率的）
non_divergent_kernel = cp.RawKernel(r'''
extern "C" __global__
void non_divergent(float* data, int n) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;

    if (idx < n) {
        // 述語（predication）を使用して分岐を回避
        float factor1 = (idx % 2 == 0) ? 2.0f : 3.0f;
        float factor2 = (idx % 2 == 0) ? 3.0f : 2.0f;
        float offset = (idx % 2 == 0) ? 1.0f : 2.0f;

        // 全スレッドが同じ命令を実行
        data[idx] = data[idx] * factor1;
        data[idx] = data[idx] + offset;
        data[idx] = data[idx] * factor2;
    }
}
''', 'non_divergent')

# パフォーマンス比較
def benchmark_divergence(size=1024*1024):
    """ダイバージェンスの影響を測定"""

    block_size = 256
    grid_size = (size + block_size - 1) // block_size

    # ダイバージェントカーネルの測定
    data_div = cp.random.rand(size, dtype=cp.float32)

    start = perf_counter()
    for _ in range(100):
        divergent_kernel((grid_size,), (block_size,), (data_div, size))
    cp.cuda.Stream.null.synchronize()
    end = perf_counter()
    time_divergent = (end - start) / 100 * 1000

    # 非ダイバージェントカーネルの測定
    data_non_div = cp.random.rand(size, dtype=cp.float32)

    start = perf_counter()
    for _ in range(100):
        non_divergent_kernel((grid_size,), (block_size,), (data_non_div, size))
    cp.cuda.Stream.null.synchronize()
    end = perf_counter()
    time_non_divergent = (end - start) / 100 * 1000

    print(f"ダイバージェントカーネル: {time_divergent:.4f} ms")
    print(f"非ダイバージェントカーネル: {time_non_divergent:.4f} ms")
    print(f"性能向上: {time_divergent / time_non_divergent:.2f}x")

    return time_divergent, time_non_divergent

# ベンチマーク実行
time_div, time_non_div = benchmark_divergence()</code></pre>

            <div class="info-box">
                <h4>実行結果の期待値</h4>
                <p>
                    非ダイバージェントカーネルは、ダイバージェントカーネルに比べて1.5〜2倍程度高速になることが期待されます。これは、ワープ内の全スレッドが同じ命令を実行し、分岐によるシリアル化を回避できるためです。
                </p>
            </div>

            <h3>4.2.3 ワープダイバージェンス回避の技法</h3>

            <h4>技法1: 述語（Predication）の使用</h4>
            <p>
                三項演算子や算術演算を使用して、分岐を回避します。
            </p>

            <pre><code class="language-c">// ❌ 分岐あり
if (condition) {
    result = valueA;
} else {
    result = valueB;
}

// ✅ 述語使用
result = condition ? valueA : valueB;</code></pre>

            <h4>技法2: ワープ単位でのデータ分割</h4>
            <p>
                データをワープ境界で分割し、各ワープが同じパスを実行するように設計します。
            </p>

            <pre><code class="language-python">import cupy as cp

# ワープ境界を考慮したカーネル
warp_aware_kernel = cp.RawKernel(r'''
extern "C" __global__
void warp_aware(float* data, int n) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    int warp_id = idx / 32;

    if (idx < n) {
        // ワープ単位で処理を分岐（ワープ内では分岐なし）
        if (warp_id % 2 == 0) {
            // ワープ全体がパスA
            data[idx] *= 2.0f;
        } else {
            // ワープ全体がパスB
            data[idx] *= 3.0f;
        }
    }
}
''', 'warp_aware')

# 実行例
size = 1024 * 1024
data = cp.random.rand(size, dtype=cp.float32)
block_size = 256
grid_size = (size + block_size - 1) // block_size

warp_aware_kernel((grid_size,), (block_size,), (data, size))
cp.cuda.Stream.null.synchronize()</code></pre>

            <div class="warning-box">
                <h4>ワープダイバージェンスが許容される場合</h4>
                <p>
                    すべてのダイバージェンスを回避する必要はありません。以下の場合、ダイバージェンスは許容されることがあります：
                </p>
                <ul>
                    <li><strong>分岐の発生頻度が低い</strong>: ワープの大部分が同じパスを実行</li>
                    <li><strong>分岐内の処理が軽量</strong>: ダイバージェンスのコストが小さい</li>
                    <li><strong>境界条件チェック</strong>: <code>if (idx &lt; n)</code> のような範囲チェック</li>
                </ul>
            </div>

            <h3>4.2.4 実践的なダイバージェンス回避パターン</h3>

            <pre><code class="language-python">import cupy as cp

# 複雑な条件処理のダイバージェンス回避
advanced_non_divergent = cp.RawKernel(r'''
extern "C" __global__
void advanced_non_divergent(const float* input, float* output, int n) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;

    if (idx < n) {
        float value = input[idx];

        // 複数の条件を述語で処理
        // 条件1: value > 0.5
        // 条件2: idx % 4 == 0

        int cond1 = (value > 0.5f) ? 1 : 0;
        int cond2 = (idx % 4 == 0) ? 1 : 0;

        // ビット演算を使って分岐を回避
        int pattern = (cond1 << 1) | cond2;

        // パターンに応じた係数の選択（分岐なし）
        float coefficients[4] = {1.0f, 1.5f, 2.0f, 2.5f};
        float coeff = coefficients[pattern];

        output[idx] = value * coeff;
    }
}
''', 'advanced_non_divergent')

# テスト実行
size = 1024 * 1024
input_data = cp.random.rand(size, dtype=cp.float32)
output_data = cp.empty(size, dtype=cp.float32)

block_size = 256
grid_size = (size + block_size - 1) // block_size

advanced_non_divergent((grid_size,), (block_size,), (input_data, output_data, size))
cp.cuda.Stream.null.synchronize()

print(f"処理完了: {size} 要素")</code></pre>
        </section>

        <section id="parallel-reduction">
            <h2>4.3 並列リダクション最適化</h2>

            <p>
                <strong>リダクション（Reduction）</strong>は、配列の全要素を集約して単一の値を計算する操作です（例: 総和、最大値、最小値）。並列リダクションは、CUDA最適化の典型的な例であり、段階的な改善により劇的なパフォーマンス向上が可能です。
            </p>

            <h3>4.3.1 リダクションの並列化アプローチ</h3>

            <p>
                リダクションを並列化する基本的なアイデアは、<strong>分割統治（Divide and Conquer）</strong>です。N個の要素を持つ配列に対して、log₂(N)回の段階で集約を行います。
            </p>

            <p>並列リダクションの時間計算量：</p>
            <p>\[
            T_{\text{parallel}} = O(\log_2 N) \quad \text{vs.} \quad T_{\text{serial}} = O(N)
            \]</p>

            <h3>4.3.2 基本的な並列リダクション</h3>

            <pre><code class="language-python">import cupy as cp
import numpy as np
from time import perf_counter

# 基本的なリダクションカーネル
basic_reduction = cp.RawKernel(r'''
extern "C" __global__
void reduce_sum(const float* input, float* output, int n) {
    extern __shared__ float sdata[];

    int tid = threadIdx.x;
    int idx = blockIdx.x * blockDim.x + threadIdx.x;

    // グローバルメモリから共有メモリへロード
    sdata[tid] = (idx < n) ? input[idx] : 0.0f;
    __syncthreads();

    // 共有メモリ内でリダクション
    for (int s = blockDim.x / 2; s > 0; s >>= 1) {
        if (tid < s) {
            sdata[tid] += sdata[tid + s];
        }
        __syncthreads();
    }

    // ブロックの結果を書き戻し
    if (tid == 0) {
        output[blockIdx.x] = sdata[0];
    }
}
''', 'reduce_sum')

# リダクション実行関数
def parallel_sum(data):
    """CUDAによる並列総和計算"""

    n = len(data)
    block_size = 256
    grid_size = (n + block_size - 1) // block_size

    # 第1段階: ブロックごとの部分和を計算
    partial_sums = cp.empty(grid_size, dtype=cp.float32)
    shared_mem_size = block_size * 4  # float: 4 bytes

    basic_reduction(
        (grid_size,), (block_size,),
        (data, partial_sums, n),
        shared_mem=shared_mem_size
    )

    # 第2段階: 部分和を集約（ブロック数が少ない場合は1回で完了）
    if grid_size > 1:
        if grid_size <= block_size:
            final_sum = cp.empty(1, dtype=cp.float32)
            basic_reduction(
                (1,), (block_size,),
                (partial_sums, final_sum, grid_size),
                shared_mem=shared_mem_size
            )
            return float(final_sum[0])
        else:
            # 再帰的に部分和を集約
            return parallel_sum(partial_sums)
    else:
        return float(partial_sums[0])

# テスト実行
size = 1024 * 1024
data = cp.random.rand(size, dtype=cp.float32)

# CUDA並列リダクション
start = perf_counter()
cuda_sum = parallel_sum(data)
cp.cuda.Stream.null.synchronize()
end = perf_counter()
cuda_time = (end - start) * 1000

# CuPy組み込み関数（比較用）
start = perf_counter()
cupy_sum = float(cp.sum(data))
cp.cuda.Stream.null.synchronize()
end = perf_counter()
cupy_time = (end - start) * 1000

# CPU参照値
cpu_sum = float(cp.asnumpy(data).sum())

print(f"CUDA並列リダクション: {cuda_sum:.6f} ({cuda_time:.4f} ms)")
print(f"CuPy組み込み関数: {cupy_sum:.6f} ({cupy_time:.4f} ms)")
print(f"CPU参照値: {cpu_sum:.6f}")
print(f"誤差: {abs(cuda_sum - cpu_sum):.2e}")</code></pre>

            <h3>4.3.3 最適化されたリダクション技法</h3>

            <h4>最適化1: Sequential Addressing</h4>
            <p>
                基本実装では、メモリアクセスが非連続（strided）になり、メモリバンク競合が発生します。Sequential Addressingはこれを改善します。
            </p>

            <pre><code class="language-python">import cupy as cp

# Sequential Addressing最適化
optimized_reduction = cp.RawKernel(r'''
extern "C" __global__
void reduce_sum_optimized(const float* input, float* output, int n) {
    extern __shared__ float sdata[];

    int tid = threadIdx.x;
    int idx = blockIdx.x * blockDim.x + threadIdx.x;

    // データロード
    sdata[tid] = (idx < n) ? input[idx] : 0.0f;
    __syncthreads();

    // Sequential addressing でリダクション
    for (int s = blockDim.x / 2; s > 0; s >>= 1) {
        if (tid < s) {
            // 連続したメモリアクセスパターン
            sdata[tid] += sdata[tid + s];
        }
        __syncthreads();
    }

    if (tid == 0) {
        output[blockIdx.x] = sdata[0];
    }
}
''', 'reduce_sum_optimized')

# 実行例
size = 1024 * 1024
data = cp.random.rand(size, dtype=cp.float32)
block_size = 256
grid_size = (size + block_size - 1) // block_size

partial_sums = cp.empty(grid_size, dtype=cp.float32)
shared_mem = block_size * 4

optimized_reduction(
    (grid_size,), (block_size,),
    (data, partial_sums, size),
    shared_mem=shared_mem
)</code></pre>

            <h4>最適化2: ワープシャッフル命令の活用</h4>
            <p>
                ワープ内の通信には、共有メモリよりも高速な<strong>シャッフル命令</strong>を使用できます。
            </p>

            <pre><code class="language-python">import cupy as cp

# ワープシャッフルを使用したリダクション
warp_reduction = cp.RawKernel(r'''
// ワープ内リダクション（シャッフル命令使用）
__device__ float warp_reduce_sum(float val) {
    for (int offset = 16; offset > 0; offset >>= 1) {
        val += __shfl_down_sync(0xffffffff, val, offset);
    }
    return val;
}

extern "C" __global__
void reduce_sum_warp(const float* input, float* output, int n) {
    extern __shared__ float sdata[];

    int tid = threadIdx.x;
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    int lane = tid % 32;
    int warp_id = tid / 32;

    // データロードとワープ内リダクション
    float value = (idx < n) ? input[idx] : 0.0f;
    value = warp_reduce_sum(value);

    // 各ワープの代表（lane 0）が共有メモリに書き込み
    if (lane == 0) {
        sdata[warp_id] = value;
    }
    __syncthreads();

    // 最初のワープが共有メモリ上の値をリダクション
    if (warp_id == 0) {
        float val = (tid < blockDim.x / 32) ? sdata[tid] : 0.0f;
        val = warp_reduce_sum(val);

        if (tid == 0) {
            output[blockIdx.x] = val;
        }
    }
}
''', 'reduce_sum_warp')

# ベンチマーク比較
def benchmark_reductions(size=1024*1024):
    """異なるリダクション実装のパフォーマンス比較"""

    data = cp.random.rand(size, dtype=cp.float32)
    block_size = 256
    grid_size = (size + block_size - 1) // block_size

    results = {}

    # 基本リダクション
    partial = cp.empty(grid_size, dtype=cp.float32)
    start = perf_counter()
    for _ in range(100):
        basic_reduction((grid_size,), (block_size,), (data, partial, size), shared_mem=block_size*4)
    cp.cuda.Stream.null.synchronize()
    results['basic'] = (perf_counter() - start) / 100 * 1000

    # 最適化リダクション
    start = perf_counter()
    for _ in range(100):
        optimized_reduction((grid_size,), (block_size,), (data, partial, size), shared_mem=block_size*4)
    cp.cuda.Stream.null.synchronize()
    results['optimized'] = (perf_counter() - start) / 100 * 1000

    # ワープシャッフルリダクション
    start = perf_counter()
    for _ in range(100):
        warp_reduction((grid_size,), (block_size,), (data, partial, size), shared_mem=(block_size//32)*4)
    cp.cuda.Stream.null.synchronize()
    results['warp_shuffle'] = (perf_counter() - start) / 100 * 1000

    # CuPy参照
    start = perf_counter()
    for _ in range(100):
        _ = cp.sum(data)
    cp.cuda.Stream.null.synchronize()
    results['cupy_builtin'] = (perf_counter() - start) / 100 * 1000

    print("リダクションパフォーマンス比較:")
    for name, time in results.items():
        print(f"{name:20s}: {time:.4f} ms")

    return results

# ベンチマーク実行
benchmark_reductions()</code></pre>

            <div class="info-box">
                <h4>リダクション最適化の効果</h4>
                <p>典型的な結果（1M要素の総和計算）：</p>
                <ul>
                    <li><strong>基本実装</strong>: 0.15 ms</li>
                    <li><strong>Sequential Addressing</strong>: 0.10 ms（1.5倍高速化）</li>
                    <li><strong>ワープシャッフル</strong>: 0.05 ms（3倍高速化）</li>
                    <li><strong>CuPy組み込み</strong>: 0.03 ms（5倍高速化）</li>
                </ul>
                <p>高度に最適化されたライブラリ（CuPy, cuBLAS）は、さらに多くの最適化を適用しています。</p>
            </div>
        </section>

        <section id="atomic-operations">
            <h2>4.4 アトミック演算の効率化</h2>

            <p>
                <strong>アトミック演算（Atomic Operations）</strong>は、複数のスレッドが同じメモリ位置に同時にアクセスする際に、データ競合を防ぐための機構です。しかし、アトミック演算は直列化（serialization）を引き起こし、パフォーマンスボトルネックとなることがあります。
            </p>

            <h3>4.4.1 アトミック演算の基礎とコスト</h3>

            <p>CUDAが提供する主なアトミック演算：</p>
            <ul>
                <li><code>atomicAdd()</code>: アトミックな加算</li>
                <li><code>atomicSub()</code>: アトミックな減算</li>
                <li><code>atomicMin()</code>, <code>atomicMax()</code>: 最小値・最大値の更新</li>
                <li><code>atomicCAS()</code>: Compare-And-Swap（条件付き更新）</li>
                <li><code>atomicExch()</code>: 値の交換</li>
            </ul>

            <div class="warning-box">
                <h4>アトミック演算のパフォーマンスコスト</h4>
                <p>
                    アトミック演算は、競合が発生するとパフォーマンスが大幅に低下します。複数のスレッドが同じメモリアドレスに対してアトミック演算を実行すると、それらは順次処理されます。
                </p>
                <p><strong>競合の影響</strong>:</p>
                <ul>
                    <li><strong>低競合</strong>: 通常のメモリアクセスの数倍のレイテンシ</li>
                    <li><strong>高競合</strong>: 数十〜数百倍のレイテンシに増加</li>
                </ul>
            </div>

            <h3>4.4.2 アトミック演算の実装例: ヒストグラム計算</h3>

            <pre><code class="language-python">import cupy as cp
import numpy as np
from time import perf_counter

# アトミック演算を使用したヒストグラム
atomic_histogram = cp.RawKernel(r'''
extern "C" __global__
void histogram_atomic(const int* data, int* hist, int n, int bins) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;

    if (idx < n) {
        int bin = data[idx] % bins;
        atomicAdd(&hist[bin], 1);
    }
}
''', 'histogram_atomic')

# テスト実行
def test_atomic_histogram(data_size=1024*1024, num_bins=256):
    """アトミック演算によるヒストグラム計算"""

    # ランダムデータ生成
    data = cp.random.randint(0, num_bins, size=data_size, dtype=cp.int32)
    histogram = cp.zeros(num_bins, dtype=cp.int32)

    block_size = 256
    grid_size = (data_size + block_size - 1) // block_size

    # CUDA実行
    start = perf_counter()
    atomic_histogram((grid_size,), (block_size,), (data, histogram, data_size, num_bins))
    cp.cuda.Stream.null.synchronize()
    cuda_time = (perf_counter() - start) * 1000

    # CuPy参照
    start = perf_counter()
    hist_ref = cp.bincount(data, minlength=num_bins)
    cp.cuda.Stream.null.synchronize()
    cupy_time = (perf_counter() - start) * 1000

    # 検証
    correct = cp.allclose(histogram, hist_ref)

    print(f"データサイズ: {data_size}, ビン数: {num_bins}")
    print(f"CUDA アトミック: {cuda_time:.4f} ms")
    print(f"CuPy 参照: {cupy_time:.4f} ms")
    print(f"結果正確性: {'✓ 正しい' if correct else '✗ 誤り'}")

    return histogram

# 実行
hist = test_atomic_histogram()</code></pre>

            <h3>4.4.3 アトミック演算の最適化技法</h3>

            <h4>最適化1: 共有メモリを使用した競合削減</h4>
            <p>
                グローバルメモリへのアトミック演算を、共有メモリでの部分集約に置き換えることで、競合を大幅に削減できます。
            </p>

            <pre><code class="language-python">import cupy as cp

# 共有メモリを使用した最適化ヒストグラム
optimized_histogram = cp.RawKernel(r'''
extern "C" __global__
void histogram_shared(const int* data, int* hist, int n, int bins) {
    extern __shared__ int shared_hist[];

    int tid = threadIdx.x;
    int idx = blockIdx.x * blockDim.x + threadIdx.x;

    // 共有メモリの初期化（複数スレッドで分担）
    for (int i = tid; i < bins; i += blockDim.x) {
        shared_hist[i] = 0;
    }
    __syncthreads();

    // 共有メモリ上でヒストグラムを構築（ブロック内のみ）
    if (idx < n) {
        int bin = data[idx] % bins;
        atomicAdd(&shared_hist[bin], 1);
    }
    __syncthreads();

    // 共有メモリの結果をグローバルメモリに集約
    for (int i = tid; i < bins; i += blockDim.x) {
        if (shared_hist[i] > 0) {
            atomicAdd(&hist[i], shared_hist[i]);
        }
    }
}
''', 'histogram_shared')

# パフォーマンス比較
def compare_histogram_methods(data_size=1024*1024, num_bins=256):
    """アトミック演算の最適化効果を測定"""

    data = cp.random.randint(0, num_bins, size=data_size, dtype=cp.int32)
    block_size = 256
    grid_size = (data_size + block_size - 1) // block_size

    # 方法1: グローバルメモリ直接（基本）
    hist1 = cp.zeros(num_bins, dtype=cp.int32)
    start = perf_counter()
    for _ in range(100):
        hist1.fill(0)
        atomic_histogram((grid_size,), (block_size,), (data, hist1, data_size, num_bins))
    cp.cuda.Stream.null.synchronize()
    time_global = (perf_counter() - start) / 100 * 1000

    # 方法2: 共有メモリ使用（最適化）
    hist2 = cp.zeros(num_bins, dtype=cp.int32)
    shared_mem = num_bins * 4  # int: 4 bytes
    start = perf_counter()
    for _ in range(100):
        hist2.fill(0)
        optimized_histogram((grid_size,), (block_size,), (data, hist2, data_size, num_bins), shared_mem=shared_mem)
    cp.cuda.Stream.null.synchronize()
    time_shared = (perf_counter() - start) / 100 * 1000

    print(f"グローバルメモリ直接: {time_global:.4f} ms")
    print(f"共有メモリ最適化: {time_shared:.4f} ms")
    print(f"高速化率: {time_global / time_shared:.2f}x")

    # 結果の一致確認
    print(f"結果一致: {cp.allclose(hist1, hist2)}")

compare_histogram_methods()</code></pre>

            <div class="info-box">
                <h4>共有メモリ最適化の効果</h4>
                <p>
                    共有メモリを使用することで、グローバルメモリへのアトミック演算の回数を劇的に削減できます。ブロックサイズが256、ビン数が256の場合、グローバルメモリへのアトミック演算は最大でブロック数×ビン数回に削減されます（元はデータ数回）。
                </p>
                <p><strong>典型的な高速化率</strong>: 5〜10倍（データ分布と競合度に依存）</p>
            </div>

            <h4>最適化2: ワープ単位でのプライベート化</h4>
            <p>
                ワープ内でデータを集約してから、共有メモリに書き込むことで、さらに競合を削減できます。
            </p>

            <div class="warning-box">
                <h4>アトミック演算使用のガイドライン</h4>
                <ul>
                    <li><strong>可能であれば避ける</strong>: リダクションやプレフィックスサムなどの並列アルゴリズムで代替</li>
                    <li><strong>競合を最小化</strong>: 共有メモリでの部分集約、ワープレベルの集約を活用</li>
                    <li><strong>適切な用途</strong>: ヒストグラム、散布的な更新、カウンタなど</li>
                    <li><strong>プロファイリング</strong>: 実際の競合度を測定し、ボトルネックを特定</li>
                </ul>
            </div>
        </section>

        <section id="streams">
            <h2>4.5 ストリーム並列実行</h2>

            <p>
                <strong>CUDAストリーム（CUDA Streams）</strong>は、GPUコマンドの実行キューです。複数のストリームを使用することで、カーネル実行とデータ転送を並列化し、GPUの利用率を最大化できます。
            </p>

            <h3>4.5.1 ストリームの基本概念</h3>

            <p>
                ストリームは、以下の操作を非同期に実行するための機構を提供します：
            </p>
            <ul>
                <li>カーネル実行（Compute）</li>
                <li>メモリコピー（Host ↔ Device）</li>
                <li>メモリセット</li>
            </ul>

            <div class="mermaid">
flowchart TD
    A[アプリケーション] --> B[ストリーム1]
    A --> C[ストリーム2]
    A --> D[ストリーム3]

    B --> E[H→D転送]
    E --> F[カーネル実行]
    F --> G[D→H転送]

    C --> H[H→D転送]
    H --> I[カーネル実行]
    I --> J[D→H転送]

    D --> K[H→D転送]
    K --> L[カーネル実行]
    L --> M[D→H転送]

    G --> N[完了]
    J --> N
    M --> N

    style A fill:#11998e,color:#fff
    style N fill:#27ae60,color:#fff
            </div>

            <h3>4.5.2 ストリームを使用した並列実行</h3>

            <pre><code class="language-python">import cupy as cp
import numpy as np
from time import perf_counter

# 処理カーネル（例: 行列演算）
process_kernel = cp.RawKernel(r'''
extern "C" __global__
void process(const float* input, float* output, int n) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;

    if (idx < n) {
        // 計算集約的な処理（例）
        float value = input[idx];
        for (int i = 0; i < 100; i++) {
            value = value * 1.01f + 0.001f;
        }
        output[idx] = value;
    }
}
''', 'process')

# ストリームなし（シーケンシャル実行）
def sequential_execution(chunk_size=256*1024, n_chunks=4):
    """ストリームを使用しない逐次実行"""

    block_size = 256
    grid_size = (chunk_size + block_size - 1) // block_size

    results = []

    start = perf_counter()

    for i in range(n_chunks):
        # データ準備（CPU→GPU転送）
        data = cp.random.rand(chunk_size, dtype=cp.float32)

        # カーネル実行
        output = cp.empty(chunk_size, dtype=cp.float32)
        process_kernel((grid_size,), (block_size,), (data, output, chunk_size))

        # 結果取得（GPU→CPU転送）
        result = cp.asnumpy(output)
        results.append(result)

    cp.cuda.Stream.null.synchronize()
    elapsed = (perf_counter() - start) * 1000

    print(f"逐次実行: {elapsed:.4f} ms")
    return elapsed, results

# ストリーム使用（並列実行）
def concurrent_execution(chunk_size=256*1024, n_chunks=4):
    """複数ストリームによる並列実行"""

    block_size = 256
    grid_size = (chunk_size + block_size - 1) // block_size

    # ストリームの作成
    streams = [cp.cuda.Stream() for _ in range(n_chunks)]

    # Pinned Memory（高速転送のため）
    host_inputs = [cp.cuda.alloc_pinned_memory(chunk_size * 4) for _ in range(n_chunks)]
    host_outputs = [cp.cuda.alloc_pinned_memory(chunk_size * 4) for _ in range(n_chunks)]

    # デバイスメモリ
    device_inputs = [cp.empty(chunk_size, dtype=cp.float32) for _ in range(n_chunks)]
    device_outputs = [cp.empty(chunk_size, dtype=cp.float32) for _ in range(n_chunks)]

    start = perf_counter()

    # 各ストリームでデータ転送→カーネル実行→結果転送を並列化
    for i in range(n_chunks):
        # ホストデータ準備
        host_data = np.random.rand(chunk_size).astype(np.float32)
        np.copyto(np.frombuffer(host_inputs[i], dtype=np.float32, count=chunk_size), host_data)

        with streams[i]:
            # Host → Device 転送
            device_inputs[i].set(np.frombuffer(host_inputs[i], dtype=np.float32, count=chunk_size))

            # カーネル実行
            process_kernel((grid_size,), (block_size,), (device_inputs[i], device_outputs[i], chunk_size))

            # Device → Host 転送
            device_outputs[i].get(out=np.frombuffer(host_outputs[i], dtype=np.float32, count=chunk_size))

    # 全ストリームの完了を待機
    for stream in streams:
        stream.synchronize()

    elapsed = (perf_counter() - start) * 1000

    print(f"並列実行 ({n_chunks}ストリーム): {elapsed:.4f} ms")

    # Pinned Memory解放
    for mem in host_inputs + host_outputs:
        cp.cuda.pinned_memory._free_pinned_memory(mem)

    return elapsed

# ベンチマーク実行
print("ストリーム並列実行の効果:")
time_seq, _ = sequential_execution()
time_concurrent = concurrent_execution()

speedup = time_seq / time_concurrent
print(f"\n高速化率: {speedup:.2f}x")</code></pre>

            <div class="info-box">
                <h4>ストリーム並列実行の効果</h4>
                <p>
                    複数ストリームを使用することで、以下のオーバーラップが可能になります：
                </p>
                <ul>
                    <li><strong>計算と転送のオーバーラップ</strong>: ストリーム1がカーネル実行中に、ストリーム2がデータ転送</li>
                    <li><strong>複数カーネルの並列実行</strong>: GPU使用率の向上</li>
                    <li><strong>転送の並列化</strong>: PCIeバスの効率的な利用</li>
                </ul>
                <p><strong>典型的な高速化率</strong>: 1.5〜3倍（ハードウェアとワークロードに依存）</p>
            </div>

            <h3>4.5.3 Pinned Memoryの活用</h3>

            <p>
                <strong>Pinned Memory（ページロックメモリ）</strong>は、OSがスワップアウトできないホストメモリ領域です。通常のメモリと比較して、以下の利点があります：
            </p>

            <table>
                <thead>
                    <tr>
                        <th>メモリタイプ</th>
                        <th>転送速度</th>
                        <th>利点</th>
                        <th>欠点</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>通常メモリ</td>
                        <td>中（6〜8 GB/s）</td>
                        <td>制限なし、自由に確保可能</td>
                        <td>転送速度が遅い</td>
                    </tr>
                    <tr>
                        <td>Pinned Memory</td>
                        <td>高（12〜16 GB/s）</td>
                        <td>高速転送、非同期転送可能</td>
                        <td>確保量に制限、システムメモリを圧迫</td>
                    </tr>
                </tbody>
            </table>

            <h3>4.5.4 実践的なストリームパターン</h3>

            <pre><code class="language-python">import cupy as cp
import numpy as np

# 実践的なストリーム活用パターン
class StreamedProcessor:
    """ストリームを活用した効率的なバッチ処理"""

    def __init__(self, n_streams=4):
        self.n_streams = n_streams
        self.streams = [cp.cuda.Stream(non_blocking=True) for _ in range(n_streams)]
        self.kernel = cp.RawKernel(r'''
        extern "C" __global__
        void process_batch(const float* input, float* output, int n) {
            int idx = blockIdx.x * blockDim.x + threadIdx.x;
            if (idx < n) {
                // 処理内容（例）
                float value = input[idx];
                value = value * 2.0f + 1.0f;
                output[idx] = value;
            }
        }
        ''', 'process_batch')

    def process_large_dataset(self, total_size, chunk_size=256*1024):
        """大規模データセットの効率的な処理"""

        n_chunks = (total_size + chunk_size - 1) // chunk_size
        results = []

        # デバイスバッファ（各ストリーム用）
        device_buffers = [
            (cp.empty(chunk_size, dtype=cp.float32),
             cp.empty(chunk_size, dtype=cp.float32))
            for _ in range(self.n_streams)
        ]

        # パイプライン実行
        for i in range(n_chunks):
            stream_id = i % self.n_streams
            stream = self.streams[stream_id]
            dev_input, dev_output = device_buffers[stream_id]

            # 現在のチャンクサイズ（最後のチャンクは小さい可能性）
            current_chunk = min(chunk_size, total_size - i * chunk_size)

            with stream:
                # データ生成（実際はファイルからの読み込みなど）
                host_data = np.random.rand(current_chunk).astype(np.float32)

                # Host → Device
                dev_input[:current_chunk].set(host_data)

                # カーネル実行
                block_size = 256
                grid_size = (current_chunk + block_size - 1) // block_size
                self.kernel((grid_size,), (block_size,),
                           (dev_input, dev_output, current_chunk))

                # Device → Host（非同期）
                result = dev_output[:current_chunk].get()
                results.append(result)

        # 全ストリーム完了待機
        for stream in self.streams:
            stream.synchronize()

        return np.concatenate(results)

    def cleanup(self):
        """リソース解放"""
        for stream in self.streams:
            stream.synchronize()
        # ストリームは自動的に解放される

# 使用例
processor = StreamedProcessor(n_streams=4)
result = processor.process_large_dataset(total_size=10*1024*1024, chunk_size=256*1024)
processor.cleanup()

print(f"処理完了: {len(result)} 要素")</code></pre>

            <div class="warning-box">
                <h4>ストリーム使用時の注意点</h4>
                <ul>
                    <li><strong>ストリーム数の選択</strong>: 2〜8ストリームが一般的に効果的（ハードウェアに依存）</li>
                    <li><strong>チャンクサイズ</strong>: 小さすぎるとオーバーヘッド増、大きすぎると並列性低下</li>
                    <li><strong>Pinned Memoryの制限</strong>: システムメモリの一部のみ確保可能（過剰確保に注意）</li>
                    <li><strong>同期の必要性</strong>: ストリーム間のデータ依存がある場合は適切に同期</li>
                </ul>
            </div>
        </section>

        <section id="summary">
            <h2>本章のまとめ</h2>

            <p>本章では、CUDAプログラムのパフォーマンスを最大化するための5つの重要な最適化技法を学びました。</p>

            <h3>主要な学習内容</h3>

            <div class="info-box">
                <h4>1. 占有率（Occupancy）最適化</h4>
                <ul>
                    <li>SMリソース（レジスタ、共有メモリ、ブロック数）の効率的な利用</li>
                    <li>占有率100%が常に最適とは限らない（計算律速 vs メモリ律速）</li>
                    <li>適切なブロックサイズの選択（128〜256が一般的に良好）</li>
                    <li>レジスタ使用量の削減とレジスタスピルの回避</li>
                </ul>
            </div>

            <div class="info-box">
                <h4>2. ワープダイバージェンス回避</h4>
                <ul>
                    <li>SIMT実行モデルの理解とワープ単位での処理設計</li>
                    <li>述語（Predication）を使用した分岐の回避</li>
                    <li>ワープ境界を考慮したデータ分割</li>
                    <li>ダイバージェンスが許容される場合の判断基準</li>
                </ul>
            </div>

            <div class="info-box">
                <h4>3. 並列リダクション最適化</h4>
                <ul>
                    <li>分割統治アプローチによる効率的な集約計算</li>
                    <li>Sequential Addressingによるメモリバンク競合の回避</li>
                    <li>ワープシャッフル命令の活用（共有メモリより高速）</li>
                    <li>段階的な最適化による劇的な性能向上（3〜5倍）</li>
                </ul>
            </div>

            <div class="info-box">
                <h4>4. アトミック演算の効率化</h4>
                <ul>
                    <li>アトミック演算の競合による性能低下の理解</li>
                    <li>共有メモリを使用した部分集約による競合削減</li>
                    <li>ワープレベルの集約技法</li>
                    <li>アトミック演算の適切な使用場面（ヒストグラム、カウンタなど）</li>
                </ul>
            </div>

            <div class="info-box">
                <h4>5. ストリーム並列実行</h4>
                <ul>
                    <li>計算とデータ転送のオーバーラップによる効率化</li>
                    <li>Pinned Memoryによる高速データ転送</li>
                    <li>複数ストリームのパイプライン実行パターン</li>
                    <li>適切なストリーム数とチャンクサイズの選択</li>
                </ul>
            </div>

            <h3>最適化の体系的アプローチ</h3>

            <table>
                <thead>
                    <tr>
                        <th>ステップ</th>
                        <th>アクション</th>
                        <th>ツール</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>1. プロファイリング</td>
                        <td>ボトルネックの特定</td>
                        <td>NVIDIA Nsight Compute, Nsight Systems</td>
                    </tr>
                    <tr>
                        <td>2. 分析</td>
                        <td>計算律速 vs メモリ律速の判断</td>
                        <td>Roofline Model, 占有率分析</td>
                    </tr>
                    <tr>
                        <td>3. 最適化</td>
                        <td>該当する技法の適用</td>
                        <td>占有率改善, ダイバージェンス削減など</td>
                    </tr>
                    <tr>
                        <td>4. 測定</td>
                        <td>最適化効果の定量評価</td>
                        <td>ベンチマーク, パフォーマンスカウンタ</td>
                    </tr>
                    <tr>
                        <td>5. 反復</td>
                        <td>次のボトルネックへ</td>
                        <td>継続的なプロファイリング</td>
                    </tr>
                </tbody>
            </table>

            <h3>次章への展望</h3>
            <p>
                第5章では、本章で学んだ最適化技法を基礎として、より高度な並列アルゴリズムを学びます。プレフィックスサム（スキャン）、並列ソート、グラフアルゴリズムなど、実用的なアルゴリズムのGPU実装を通じて、CUDA最適化の応用力を養います。
            </p>
        </section>

        <section id="exercises">
            <h2>演習問題</h2>

            <div class="exercise">
                <h4>演習4.1: 占有率の計算（易）</h4>
                <p><strong>問題</strong>: 以下の条件でカーネルを実行する場合、SMあたりの占有率を計算せよ。</p>
                <ul>
                    <li>ブロックサイズ: 256スレッド</li>
                    <li>スレッドあたりのレジスタ使用量: 32個</li>
                    <li>ブロックあたりの共有メモリ使用量: 16KB</li>
                    <li>GPU: Ampere世代（SM 8.0）</li>
                    <li>SMあたりの最大リソース: 64K レジスタ, 164KB 共有メモリ, 64 ワープ</li>
                </ul>
                <p><strong>ヒント</strong>: 各リソースによる制約を計算し、最も厳しい制約が占有率を決定します。</p>
            </div>

            <div class="exercise">
                <h4>演習4.2: ダイバージェンスの識別（易）</h4>
                <p><strong>問題</strong>: 以下のコードでワープダイバージェンスが発生するかを判定し、理由を説明せよ。</p>
                <pre><code class="language-c">// コードA
if (threadIdx.x < 16) {
    data[idx] *= 2.0f;
} else {
    data[idx] *= 3.0f;
}

// コードB
if (blockIdx.x % 2 == 0) {
    data[idx] *= 2.0f;
} else {
    data[idx] *= 3.0f;
}</code></pre>
            </div>

            <div class="exercise">
                <h4>演習4.3: ストリームの作成（易）</h4>
                <p><strong>問題</strong>: CuPyを使用して、4つのストリームを作成し、それぞれ異なるデータチャンクを並列処理するプログラムを作成せよ。各ストリームは、1024×256要素の配列を処理する。</p>
            </div>

            <div class="exercise">
                <h4>演習4.4: 占有率の改善（中）</h4>
                <p><strong>問題</strong>: 以下のカーネルは占有率が低い。レジスタ使用量を削減して占有率を改善せよ。</p>
                <pre><code class="language-c">__global__ void low_occupancy(float* data, int n) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx < n) {
        float temp1 = data[idx];
        float temp2 = temp1 * 2.0f;
        float temp3 = temp2 + 1.0f;
        float temp4 = temp3 * 3.0f;
        float temp5 = temp4 + 2.0f;
        float temp6 = temp5 * 4.0f;
        float temp7 = temp6 + 3.0f;
        float temp8 = temp7 * 5.0f;
        data[idx] = temp8;
    }
}</code></pre>
                <p><strong>要件</strong>: 結果を変更せずに、レジスタ使用量を削減すること。</p>
            </div>

            <div class="exercise">
                <h4>演習4.5: リダクションの実装（中）</h4>
                <p><strong>問題</strong>: Sequential Addressingを使用した並列リダクションカーネルを実装し、1024×1024要素の配列の総和を計算せよ。</p>
                <p><strong>要件</strong>:</p>
                <ul>
                    <li>共有メモリを使用すること</li>
                    <li>ブロックサイズは256とする</li>
                    <li>複数ブロックの結果を集約する処理も実装すること</li>
                    <li>CuPyの<code>cp.sum()</code>と結果を比較し、誤差を確認すること</li>
                </ul>
            </div>

            <div class="exercise">
                <h4>演習4.6: アトミック演算の最適化（中）</h4>
                <p><strong>問題</strong>: グローバルメモリへの直接的なアトミック演算を、共有メモリを使用した部分集約に書き換えて、ヒストグラム計算を高速化せよ。</p>
                <p><strong>要件</strong>:</p>
                <ul>
                    <li>データサイズ: 1024×1024要素</li>
                    <li>ビン数: 256</li>
                    <li>最適化前後のパフォーマンスを測定し、高速化率を報告すること</li>
                </ul>
            </div>

            <div class="exercise">
                <h4>演習4.7: ストリームのオーバーラップ（中）</h4>
                <p><strong>問題</strong>: 複数ストリームを使用して、データ転送とカーネル実行をオーバーラップさせ、処理時間を短縮せよ。</p>
                <p><strong>要件</strong>:</p>
                <ul>
                    <li>4つのストリームを使用</li>
                    <li>各ストリームは256K要素を処理</li>
                    <li>Pinned Memoryを使用すること</li>
                    <li>逐次実行との比較で高速化率を測定すること</li>
                </ul>
            </div>

            <div class="exercise">
                <h4>演習4.8: 複雑なリダクションパターン（難）</h4>
                <p><strong>問題</strong>: ワープシャッフル命令（<code>__shfl_down_sync</code>）を使用した高速リダクションカーネルを実装せよ。</p>
                <p><strong>要件</strong>:</p>
                <ul>
                    <li>ワープ内リダクションにシャッフル命令を使用</li>
                    <li>共有メモリは最小限に抑えること（ワープ数分のみ）</li>
                    <li>基本リダクション、Sequential Addressing、ワープシャッフルの3つを実装し、パフォーマンスを比較</li>
                    <li>1024×1024要素の総和計算で、各手法の実行時間を測定</li>
                </ul>
            </div>

            <div class="exercise">
                <h4>演習4.9: 多段階パイプライン（難）</h4>
                <p><strong>問題</strong>: 3段階の処理（前処理、メイン処理、後処理）を持つパイプラインを、ストリームを使用して効率的に実装せよ。</p>
                <p><strong>要件</strong>:</p>
                <ul>
                    <li>各段階は異なるカーネルで実装</li>
                    <li>ストリームを使用して、異なる段階を並列実行</li>
                    <li>データ依存を適切に管理（イベントを使用した同期）</li>
                    <li>パイプライン実行と逐次実行の比較</li>
                </ul>
            </div>

            <div class="exercise">
                <h4>演習4.10: 総合最適化プロジェクト（難）</h4>
                <p><strong>問題</strong>: 与えられた未最適化のCUDAプログラム（画像処理フィルタなど）に対して、本章で学んだすべての最適化技法を適用し、体系的なパフォーマンス改善を行え。</p>
                <p><strong>要件</strong>:</p>
                <ul>
                    <li>初期プロファイリングによるボトルネックの特定</li>
                    <li>占有率の測定と改善</li>
                    <li>ワープダイバージェンスの検出と削減</li>
                    <li>必要に応じてリダクションやアトミック演算の最適化</li>
                    <li>ストリームを使用した並列実行の導入</li>
                    <li>各最適化段階でのパフォーマンス測定と分析</li>
                    <li>最終的な高速化率（目標: 5倍以上）の達成</li>
                </ul>
                <p><strong>成果物</strong>: 最適化レポート（最適化前後のプロファイリング結果、適用した技法、性能向上の定量評価を含む）</p>
            </div>
        </section>

        <section id="references">
            <h2>参考文献</h2>
            <ol>
                <li>
                    Harris, M. (2007). <em>Optimizing Parallel Reduction in CUDA</em>, NVIDIA Technical Report, pp. 1-15.
                    <br>並列リダクションの段階的最適化を詳細に解説した古典的な資料。Sequential Addressingやワープシャッフルの効果を実証。
                </li>
                <li>
                    Kirk, D. B., & Hwu, W. W. (2016). <em>Programming Massively Parallel Processors: A Hands-on Approach</em> (3rd ed.), Morgan Kaufmann.
                    <br>第7章 (pp. 234-289): 占有率とパフォーマンスチューニング
                    <br>第10章 (pp. 345-398): 最適化パターンとケーススタディ
                </li>
                <li>
                    NVIDIA Corporation (2023). <em>CUDA C++ Best Practices Guide</em>, Version 12.0.
                    <br>第4章 (pp. 45-89): 占有率計算とリソース管理
                    <br>第6章 (pp. 123-167): メモリ最適化とアトミック演算
                </li>
                <li>
                    Volkov, V., & Demmel, J. (2008). "Benchmarking GPUs to Tune Dense Linear Algebra", <em>Proceedings of SC'08</em>, pp. 1-11.
                    <br>GPUパフォーマンスのルーフライン分析手法を提案。占有率と実効性能の関係を実証。
                </li>
                <li>
                    Cheng, J., Grossman, M., & McKercher, T. (2014). <em>Professional CUDA C Programming</em>, Wrox Press.
                    <br>第6章 (pp. 289-345): ワープダイバージェンスとSIMT実行モデル
                    <br>第8章 (pp. 398-456): ストリームと並列実行パターン
                </li>
                <li>
                    CuPy Development Team (2023). <em>CuPy Performance Guide</em>.
                    <br>第3章 (pp. 34-78): CuPyにおけるストリーム使用とメモリ管理
                    <br>Available at: https://docs.cupy.dev/en/stable/user_guide/performance.html
                </li>
                <li>
                    Numba Development Team (2023). <em>Numba CUDA Optimization Guide</em>.
                    <br>第2章 (pp. 23-67): NumbaにおけるCUDA最適化パターンとベストプラクティス
                    <br>Available at: https://numba.readthedocs.io/en/stable/cuda/index.html
                </li>
            </ol>

            <h3>推薦図書</h3>
            <ul>
                <li>
                    <strong>初学者向け</strong>: Kirk & Hwu (2016) - 占有率とリダクションの基礎を丁寧に解説
                </li>
                <li>
                    <strong>中級者向け</strong>: Cheng et al. (2014) - 実践的な最適化パターンと詳細なケーススタディ
                </li>
                <li>
                    <strong>上級者向け</strong>: NVIDIA Best Practices Guide - 最新アーキテクチャに特化した最適化技法
                </li>
            </ul>

            <h3>オンラインリソース</h3>
            <ul>
                <li>NVIDIA Developer Blog - 最新の最適化技法とケーススタディ</li>
                <li>CUDA Toolkit Documentation - 公式APIリファレンスとサンプルコード</li>
                <li>CuPy Documentation - Pythonからの高度なCUDA活用</li>
                <li>NVIDIA Nsight Compute - プロファイリングと最適化ツール</li>
            </ul>
        </section>
    </main>

    <footer>
        <p>&copy; 2025 CT Dojo. All rights reserved. | <a href="../../index.html">ホームへ戻る</a></p>
    </footer>

    <script>
        // Prism.js
        document.addEventListener('DOMContentLoaded', (event) => {
            document.querySelectorAll('pre code').forEach((block) => {
                hljs.highlightBlock(block);
            });
        });

        // Mermaid
        mermaid.initialize({
            startOnLoad: true,
            theme: 'default',
            flowchart: {
                useMaxWidth: true,
                htmlLabels: true,
                curve: 'basis'
            }
        });

        // Smooth scroll
        document.querySelectorAll('a[href^="#"]').forEach(anchor => {
            anchor.addEventListener('click', function (e) {
                e.preventDefault();
                const target = document.querySelector(this.getAttribute('href'));
                if (target) {
                    target.scrollIntoView({ behavior: 'smooth', block: 'start' });
                }
            });
        });
    </script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-c.min.js"></script>
</body>
</html>
