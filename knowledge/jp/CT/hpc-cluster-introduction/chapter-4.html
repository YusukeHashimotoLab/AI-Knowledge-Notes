<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ç¬¬4ç« : ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã¨ãƒ‡ãƒ¼ã‚¿ç®¡ç† - HPCã‚¯ãƒ©ã‚¹ã‚¿å…¥é–€ - CT Dojo</title>
    <meta name="description" content="HPCã‚¯ãƒ©ã‚¹ã‚¿ã®ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã€ä¸¦åˆ—ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ï¼ˆLustreã€BeeGFSï¼‰ã€I/Oæ€§èƒ½æœ€é©åŒ–ã€Pythonãƒ‡ãƒ¼ã‚¿ç®¡ç†ï¼ˆHDF5ã€Zarrï¼‰ã‚’å­¦ã¶å®Ÿè·µã‚¬ã‚¤ãƒ‰ã€‚">

    <!-- Prism.js for code highlighting -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css">

    <!-- MathJax for mathematical expressions -->
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

    <!-- Mermaid for diagrams -->
    <script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>

    <style>
        :root {
            --accent-green: #11998e;
            --accent-lime: #38ef7d;
            --primary-dark: #2c3e50;
            --secondary-dark: #34495e;
            --text-dark: #2c3e50;
            --text-light: #7f8c8d;
            --bg-light: #ecf0f1;
            --white: #ffffff;
            --code-bg: #2d2d2d;
            --border-light: #bdc3c7;
            --success: #27ae60;
            --warning: #f39c12;
            --danger: #e74c3c;
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            line-height: 1.8;
            color: var(--text-dark);
            background: var(--bg-light);
        }

        header {
            background: linear-gradient(135deg, var(--accent-green) 0%, var(--accent-lime) 100%);
            color: white;
            padding: 3rem 1.5rem;
            text-align: center;
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
        }

        header h1 {
            font-size: 2rem;
            font-weight: 700;
            margin-bottom: 0.5rem;
        }

        header p {
            font-size: 1.1rem;
            opacity: 0.95;
        }

        nav {
            background: var(--white);
            padding: 1rem;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
            position: sticky;
            top: 0;
            z-index: 100;
        }

        nav ul {
            list-style: none;
            display: flex;
            flex-wrap: wrap;
            justify-content: center;
            gap: 0.5rem;
        }

        nav a {
            text-decoration: none;
            color: var(--text-dark);
            padding: 0.5rem 1rem;
            border-radius: 4px;
            transition: all 0.3s;
            font-weight: 500;
        }

        nav a:hover {
            background: linear-gradient(135deg, var(--accent-green) 0%, var(--accent-lime) 100%);
            color: white;
        }

        main {
            max-width: 900px;
            margin: 2rem auto;
            padding: 0 1.5rem;
        }

        section {
            background: var(--white);
            padding: 2rem;
            margin-bottom: 2rem;
            border-radius: 8px;
            box-shadow: 0 2px 8px rgba(0,0,0,0.1);
        }

        h2 {
            color: var(--primary-dark);
            font-size: 1.8rem;
            margin-bottom: 1.5rem;
            padding-bottom: 0.5rem;
            border-bottom: 3px solid;
            border-image: linear-gradient(90deg, var(--accent-green), var(--accent-lime)) 1;
        }

        h3 {
            color: var(--secondary-dark);
            font-size: 1.4rem;
            margin: 2rem 0 1rem;
        }

        h4 {
            color: var(--secondary-dark);
            font-size: 1.2rem;
            margin: 1.5rem 0 1rem;
        }

        p {
            margin-bottom: 1rem;
            line-height: 1.8;
        }

        ul, ol {
            margin-left: 2rem;
            margin-bottom: 1rem;
        }

        li {
            margin-bottom: 0.5rem;
        }

        code {
            background: #f8f9fa;
            padding: 0.2rem 0.4rem;
            border-radius: 3px;
            font-family: "Consolas", "Monaco", monospace;
            font-size: 0.9em;
            color: #e74c3c;
        }

        pre {
            background: var(--code-bg);
            padding: 1.5rem;
            border-radius: 8px;
            overflow-x: auto;
            margin: 1.5rem 0;
            box-shadow: 0 2px 8px rgba(0,0,0,0.15);
        }

        pre code {
            background: none;
            color: #f8f8f2;
            padding: 0;
        }

        .info-box {
            background: linear-gradient(135deg, rgba(17, 153, 142, 0.1) 0%, rgba(56, 239, 125, 0.1) 100%);
            border-left: 4px solid var(--accent-green);
            padding: 1.5rem;
            margin: 1.5rem 0;
            border-radius: 4px;
        }

        .info-box strong {
            color: var(--accent-green);
            display: block;
            margin-bottom: 0.5rem;
            font-size: 1.1rem;
        }

        .warning-box {
            background: rgba(243, 156, 18, 0.1);
            border-left: 4px solid var(--warning);
            padding: 1.5rem;
            margin: 1.5rem 0;
            border-radius: 4px;
        }

        .warning-box strong {
            color: var(--warning);
            display: block;
            margin-bottom: 0.5rem;
            font-size: 1.1rem;
        }

        .exercise-box {
            background: rgba(39, 174, 96, 0.05);
            border: 2px solid var(--success);
            padding: 1.5rem;
            margin: 1.5rem 0;
            border-radius: 8px;
        }

        .exercise-box h4 {
            color: var(--success);
            margin-top: 0;
        }

        .difficulty {
            display: inline-block;
            padding: 0.25rem 0.75rem;
            border-radius: 12px;
            font-size: 0.85rem;
            font-weight: 600;
            margin-left: 0.5rem;
        }

        .difficulty.easy {
            background: #d4edda;
            color: #155724;
        }

        .difficulty.medium {
            background: #fff3cd;
            color: #856404;
        }

        .difficulty.hard {
            background: #f8d7da;
            color: #721c24;
        }

        .mermaid {
            background: white;
            padding: 2rem;
            border-radius: 8px;
            margin: 2rem 0;
            text-align: center;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin: 1.5rem 0;
            background: white;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }

        th, td {
            padding: 1rem;
            text-align: left;
            border-bottom: 1px solid var(--border-light);
        }

        th {
            background: linear-gradient(135deg, var(--accent-green) 0%, var(--accent-lime) 100%);
            color: white;
            font-weight: 600;
        }

        tr:hover {
            background: rgba(17, 153, 142, 0.05);
        }

        footer {
            background: var(--primary-dark);
            color: white;
            text-align: center;
            padding: 2rem;
            margin-top: 4rem;
        }

        footer a {
            color: var(--accent-green);
            text-decoration: none;
        }

        footer a:hover {
            color: var(--accent-lime);
        }

        @media (max-width: 768px) {
            header h1 {
                font-size: 1.5rem;
            }

            nav ul {
                flex-direction: column;
                align-items: center;
            }

            section {
                padding: 1.5rem;
            }

            pre {
                padding: 1rem;
                font-size: 0.85rem;
            }
        }

        .breadcrumb {
            background: #f7fafc;
            padding: 0.75rem 1rem;
            border-bottom: 1px solid #e2e8f0;
            font-size: 0.9rem;
        }

        .breadcrumb-content {
            max-width: 900px;
            margin: 0 auto;
            display: flex;
            align-items: center;
            flex-wrap: wrap;
            gap: 0.5rem;
        }

        .breadcrumb a {
            color: #11998e;
            text-decoration: none;
            transition: color 0.2s;
        }

        .breadcrumb a:hover {
            color: #0e7c74;
            text-decoration: underline;
        }

        .breadcrumb-separator {
            color: #a0aec0;
            margin: 0 0.25rem;
        }

        .breadcrumb-current {
            color: #4a5568;
            font-weight: 500;
        }

        details {
            margin: 1rem 0;
            padding: 1rem;
            background: #f8f9fa;
            border-radius: 4px;
            border-left: 3px solid var(--accent-green);
        }

        summary {
            cursor: pointer;
            font-weight: 600;
            color: var(--accent-green);
            user-select: none;
        }

        summary:hover {
            color: var(--accent-lime);
        }

        details[open] summary {
            margin-bottom: 1rem;
        }
    </style>
</head>
<body>
    <nav class="breadcrumb">
        <div class="breadcrumb-content">
            <a href="/AI-Knowledge-Notes/knowledge/jp/index.html">AIå¯ºå­å±‹ãƒˆãƒƒãƒ—</a><span class="breadcrumb-separator">â€º</span><a href="/AI-Knowledge-Notes/knowledge/jp/CT/index.html">è¨ˆç®—å·¥å­¦</a><span class="breadcrumb-separator">â€º</span><a href="/AI-Knowledge-Notes/knowledge/jp/CT/hpc-cluster-introduction/index.html">HPC Cluster</a><span class="breadcrumb-separator">â€º</span><span class="breadcrumb-current">Chapter 4</span>
        </div>
    </nav>

    <header>
        <h1>ç¬¬4ç« : ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã¨ãƒ‡ãƒ¼ã‚¿ç®¡ç†</h1>
        <p>ä¸¦åˆ—ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ãƒ»I/Oæ€§èƒ½æœ€é©åŒ–ãƒ»Pythonãƒ‡ãƒ¼ã‚¿ç®¡ç†ãƒ»ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸éšå±¤</p>
    </header>

    <nav>
        <ul>
            <li><a href="index.html">ãƒˆãƒƒãƒ—</a></li>
            <li><a href="#intro">æœ¬ç« ã®æ¦‚è¦</a></li>
            <li><a href="#storage-architecture">ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£</a></li>
            <li><a href="#parallel-filesystems">ä¸¦åˆ—ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ </a></li>
            <li><a href="#data-transfer">ãƒ‡ãƒ¼ã‚¿è»¢é€ã¨ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—</a></li>
            <li><a href="#io-optimization">I/Oæ€§èƒ½æœ€é©åŒ–</a></li>
            <li><a href="#python-data">Pythonãƒ‡ãƒ¼ã‚¿ç®¡ç†</a></li>
            <li><a href="#learning-objectives">å­¦ç¿’ç›®æ¨™</a></li>
            <li><a href="#exercises">æ¼”ç¿’å•é¡Œ</a></li>
            <li><a href="#references">å‚è€ƒæ–‡çŒ®</a></li>
            <li><a href="chapter-5.html">æ¬¡ã®ç« ã¸ â†’</a></li>
        </ul>
    </nav>

    <main>
        <section id="intro">
            <h2>4.1 æœ¬ç« ã®æ¦‚è¦</h2>

            <p>
                HPCã‚¯ãƒ©ã‚¹ã‚¿ã«ãŠã‘ã‚‹ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã¨I/Oæ€§èƒ½ã¯ã€è¨ˆç®—æ€§èƒ½ã¨åŒæ§˜ã«é‡è¦ã§ã™ã€‚ä¸¦åˆ—ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ï¼ˆLustreã€BeeGFSç­‰ï¼‰ã¯ã€è¤‡æ•°ãƒãƒ¼ãƒ‰ã‹ã‚‰åŒæ™‚ã«ãƒ‡ãƒ¼ã‚¿ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹éš›ã®é«˜é€ŸåŒ–ã‚’å®Ÿç¾ã—ã¾ã™ã€‚æœ¬ç« ã§ã¯ã€ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã€I/Oæœ€é©åŒ–æ‰‹æ³•ã€Pythonã«ã‚ˆã‚‹åŠ¹ç‡çš„ãªãƒ‡ãƒ¼ã‚¿ç®¡ç†ã‚’å­¦ã³ã¾ã™ã€‚
            </p>

            <div class="info-box">
                <strong>æœ¬ç« ã®å­¦ç¿’ç›®æ¨™</strong>
                <ul>
                    <li><strong>ãƒ¬ãƒ™ãƒ«1ï¼ˆåŸºæœ¬ç†è§£ï¼‰</strong>: ä¸¦åˆ—ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ã®ä»•çµ„ã¿ï¼ˆLustreã€BeeGFSï¼‰ã‚’èª¬æ˜ã§ãã€ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸éšå±¤ï¼ˆSSDã€HDDã€ãƒ†ãƒ¼ãƒ—ï¼‰ã®ç‰¹æ€§ã‚’ç†è§£ã§ãã‚‹</li>
                    <li><strong>ãƒ¬ãƒ™ãƒ«2ï¼ˆå®Ÿè·µã‚¹ã‚­ãƒ«ï¼‰</strong>: Lustreã®ã‚¹ãƒˆãƒ©ã‚¤ãƒ”ãƒ³ã‚°è¨­å®šã€HDF5ä¸¦åˆ—I/Oã€ãƒ‡ãƒ¼ã‚¿è»¢é€ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å®Ÿè£…ã§ãã€I/Oãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã§ãã‚‹</li>
                    <li><strong>ãƒ¬ãƒ™ãƒ«3ï¼ˆå¿œç”¨åŠ›ï¼‰</strong>: ãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰ç‰¹æ€§ã«å¿œã˜ã¦I/Oæˆ¦ç•¥ã‚’æœ€é©åŒ–ã§ãã€ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸éšå±¤ç®¡ç†ã‚’è‡ªå‹•åŒ–ã§ãã€å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’è¨­è¨ˆã§ãã‚‹</li>
                </ul>
            </div>

            <div class="warning-box">
                <strong>å‰æçŸ¥è­˜</strong>
                <p>æœ¬ç« ã§ã¯ã€LinuxåŸºæœ¬æ“ä½œã€Pythonãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã€ç¬¬1ç« ã®ã‚¸ãƒ§ãƒ–ç®¡ç†ã®ç†è§£ã‚’å‰æã¨ã—ã¾ã™ã€‚</p>
            </div>
        </section>

        <section id="storage-architecture">
            <h2>4.2 HPCã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£</h2>

            <h3>ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸éšå±¤ã¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç‰¹æ€§</h3>
            <p>
                HPCã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã¯ã€æ€§èƒ½ã€å®¹é‡ã€ã‚³ã‚¹ãƒˆã®ç•°ãªã‚‹è¤‡æ•°ã®éšå±¤ã§æ§‹æˆã•ã‚Œã¾ã™ã€‚å„éšå±¤ã¯ç‰¹å®šã®ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã«æœ€é©åŒ–ã•ã‚Œã¦ã„ã¾ã™ã€‚
            </p>

            <table>
                <thead>
                    <tr>
                        <th>éšå±¤</th>
                        <th>ãƒ¡ãƒ‡ã‚£ã‚¢</th>
                        <th>å¸¯åŸŸå¹…</th>
                        <th>ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·</th>
                        <th>å®¹é‡å˜ä¾¡</th>
                        <th>ç”¨é€”</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><strong>Hot Tier</strong></td>
                        <td>NVMe SSD</td>
                        <td>3-7 GB/s</td>
                        <td>100 Î¼s</td>
                        <td>$$$</td>
                        <td>ã‚¢ã‚¯ãƒ†ã‚£ãƒ–è¨ˆç®—ãƒ‡ãƒ¼ã‚¿</td>
                    </tr>
                    <tr>
                        <td><strong>Warm Tier</strong></td>
                        <td>SATA SSD/HDD</td>
                        <td>500 MB/s</td>
                        <td>5-10 ms</td>
                        <td>$$</td>
                        <td>é »ç¹ã«ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ãƒ‡ãƒ¼ã‚¿</td>
                    </tr>
                    <tr>
                        <td><strong>Cold Tier</strong></td>
                        <td>Tape (LTO-9)</td>
                        <td>400 MB/s</td>
                        <td>60-120 s</td>
                        <td>$</td>
                        <td>é•·æœŸã‚¢ãƒ¼ã‚«ã‚¤ãƒ–</td>
                    </tr>
                </tbody>
            </table>

            <h3>Lustreã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£</h3>
            <p>
                <strong>Lustre</strong>ã¯ã€ä¸–ç•Œã®ã‚¹ãƒ¼ãƒ‘ãƒ¼ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿Top 500ã®60%ä»¥ä¸Šã§æ¡ç”¨ã•ã‚Œã‚‹ä¸¦åˆ—åˆ†æ•£ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ã§ã™ã€‚ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã€ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚µãƒ¼ãƒãƒ¼ï¼ˆMDSï¼‰ã€ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚µãƒ¼ãƒãƒ¼ï¼ˆOSSï¼‰ã‹ã‚‰æ§‹æˆã•ã‚Œã¾ã™ã€‚
            </p>

            <div class="mermaid">
flowchart TB
    subgraph Clients["è¨ˆç®—ãƒãƒ¼ãƒ‰ï¼ˆLustreã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆï¼‰"]
        C1[node001]
        C2[node002]
        C3[node003]
        C4[node004-128]
    end

    subgraph MGS["ç®¡ç†ã‚µãƒ¼ãƒãƒ¼"]
        MG[MGS<br/>Management Server]
    end

    subgraph MDS["ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚µãƒ¼ãƒãƒ¼"]
        MD1[MDS1<br/>Metadata Server]
        MD2[MDS2<br/>Failover]
        MDT[(MDT<br/>Metadata Target)]
    end

    subgraph OSS["ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚µãƒ¼ãƒãƒ¼ç¾¤"]
        OSS1[OSS1]
        OSS2[OSS2]
        OSS3[OSS3]
        OSS4[OSS4-16]
        OST1[(OST1<br/>Object Storage<br/>Target)]
        OST2[(OST2)]
        OST3[(OST3)]
        OST4[(OST4-64)]
    end

    Clients -->|ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿è¦æ±‚| MDS
    Clients -->|ãƒ‡ãƒ¼ã‚¿I/O| OSS
    MDS --> MDT
    OSS1 --> OST1
    OSS2 --> OST2
    OSS3 --> OST3
    OSS4 --> OST4
    MGS --> MDS
    MGS --> OSS

    style Clients fill:#e3f2fd
    style MGS fill:#fff3e0
    style MDS fill:#f3e5f5
    style OSS fill:#e8f5e9
            </div>

            <h3>RAIDæ§‹æˆã¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹</h3>
            <p>
                ä¸¦åˆ—ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ã®OSTã¯ã€é€šå¸¸RAIDï¼ˆRedundant Array of Independent Disksï¼‰ã§æ§‹æˆã•ã‚Œã¾ã™ã€‚RAID 6ãŒä¸€èˆ¬çš„ã§ã™ã€‚
            </p>

            <p style="text-align: center; font-size: 1.1rem; margin: 1.5rem 0;">
                \[
                \text{RAID 6å®¹é‡} = (N - 2) \times D
                \]
            </p>

            <p>
                ã“ã“ã§ã€\(N\)ã¯ãƒ‡ã‚£ã‚¹ã‚¯æ•°ã€\(D\)ã¯å„ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡ã§ã™ã€‚RAID 6ã¯2å°ã®ãƒ‡ã‚£ã‚¹ã‚¯æ•…éšœã«è€ãˆã‚‰ã‚Œã¾ã™ã€‚
            </p>

            <p style="text-align: center; font-size: 1.1rem; margin: 1.5rem 0;">
                \[
                \text{ç†è«–å¸¯åŸŸå¹…} = (N - 2) \times B_{\text{disk}}
                \]
            </p>

            <p>
                \(B_{\text{disk}}\)ã¯å˜ä¸€ãƒ‡ã‚£ã‚¹ã‚¯ã®å¸¯åŸŸå¹…ã§ã™ã€‚ä¾‹: 12å°ã®HDDï¼ˆå„200 MB/sï¼‰â†’ RAID 6å¸¯åŸŸå¹… = 10 Ã— 200 = 2 GB/sã€‚
            </p>

            <div class="info-box">
                <strong>ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚·ã‚¹ãƒ†ãƒ ã®é¸æŠåŸºæº–</strong>
                <ul>
                    <li><strong>é«˜å¸¯åŸŸå¹…é‡è¦–</strong>: å¤§è¦æ¨¡ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆæ›¸ãè¾¼ã¿ â†’ Lustre + NVMe SSD</li>
                    <li><strong>é«˜IOPSé‡è¦–</strong>: å°ãƒ•ã‚¡ã‚¤ãƒ«å¤šæ•°ã®ãƒ¡ã‚¿ã‚²ãƒãƒ è§£æ â†’ BeeGFS + SSD</li>
                    <li><strong>å®¹é‡é‡è¦–</strong>: é•·æœŸä¿å­˜ã®è¦³æ¸¬ãƒ‡ãƒ¼ã‚¿ â†’ GPFS + HDDã‚¢ãƒ¬ã‚¤</li>
                </ul>
            </div>
        </section>

        <section id="parallel-filesystems">
            <h2>4.3 ä¸¦åˆ—ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ã®å®Ÿè·µ</h2>

            <h3>ã‚³ãƒ¼ãƒ‰ä¾‹1: Lustreã‚¹ãƒˆãƒ©ã‚¤ãƒ”ãƒ³ã‚°è¨­å®š</h3>
            <pre><code class="language-bash">#!/bin/bash
# ===================================
# Lustreã‚¹ãƒˆãƒ©ã‚¤ãƒ”ãƒ³ã‚°è¨­å®šã‚¹ã‚¯ãƒªãƒ—ãƒˆ
# ===================================

# ç¾åœ¨ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ã‚¹ãƒˆãƒ©ã‚¤ãƒ”ãƒ³ã‚°æƒ…å ±ã‚’ç¢ºèª
lfs getstripe /scratch/$USER

# ã‚¹ãƒˆãƒ©ã‚¤ãƒ—æ•°: è¤‡æ•°OSTã«åˆ†æ•£ã—ã¦æ›¸ãè¾¼ã‚€OSTæ•°
# ã‚¹ãƒˆãƒ©ã‚¤ãƒ—ã‚µã‚¤ã‚º: å„OSTã«æ›¸ãè¾¼ã‚€ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚º

# ã‚±ãƒ¼ã‚¹1: å¤§è¦æ¨¡ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ>10GBï¼‰ã®é«˜é€Ÿæ›¸ãè¾¼ã¿
# ã‚¹ãƒˆãƒ©ã‚¤ãƒ—æ•°ã‚’å¤šãã€ã‚¹ãƒˆãƒ©ã‚¤ãƒ—ã‚µã‚¤ã‚ºã‚’å¤§ãã
mkdir -p /scratch/$USER/large_files
lfs setstripe -c 16 -S 4M /scratch/$USER/large_files
# -c 16: 16å€‹ã®OSTã«åˆ†æ•£ï¼ˆä¸¦åˆ—åº¦16ï¼‰
# -S 4M: 4MBãšã¤ãƒãƒ£ãƒ³ã‚¯ï¼ˆå¤§è¦æ¨¡I/Oã«æœ€é©ï¼‰

# ã‚±ãƒ¼ã‚¹2: å°ãƒ•ã‚¡ã‚¤ãƒ«å¤šæ•°ï¼ˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿é›†ç´„å‹ï¼‰
# ã‚¹ãƒˆãƒ©ã‚¤ãƒ—æ•°ã‚’å°‘ãªãã€ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚µãƒ¼ãƒãƒ¼è² è·ã‚’è»½æ¸›
mkdir -p /scratch/$USER/small_files
lfs setstripe -c 1 -S 1M /scratch/$USER/small_files
# -c 1: å˜ä¸€OSTã«é›†ç´„ï¼ˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿è² è·ä½æ¸›ï¼‰

# ã‚±ãƒ¼ã‚¹3: ä¸­è¦æ¨¡ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ1-10GBï¼‰ã®ãƒãƒ©ãƒ³ã‚¹è¨­å®š
mkdir -p /scratch/$USER/medium_files
lfs setstripe -c 4 -S 2M /scratch/$USER/medium_files
# -c 4: 4OSTã§ä¸¦åˆ—ï¼ˆãƒãƒ©ãƒ³ã‚¹ï¼‰
# -S 2M: 2MBãƒãƒ£ãƒ³ã‚¯

# ç‰¹å®šã®ãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚¹ãƒˆãƒ©ã‚¤ãƒ”ãƒ³ã‚°ã‚’é©ç”¨
dd if=/dev/zero of=/scratch/$USER/large_files/testfile.dat bs=1M count=10240
# 10GBã®ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ

# ã‚¹ãƒˆãƒ©ã‚¤ãƒ”ãƒ³ã‚°ã®æ¤œè¨¼
lfs getstripe /scratch/$USER/large_files/testfile.dat
# å‡ºåŠ›ä¾‹:
# lmm_stripe_count:  16
# lmm_stripe_size:   4194304
# lmm_pattern:       raid0
# lmm_layout_gen:    0
# lmm_stripe_offset: 5
#         obdidx           objid           objid           group
#              5          123456       0x1e240               0
#              7          123457       0x1e241               0
#              ...ï¼ˆ16å€‹ã®OSTï¼‰

# å¸¯åŸŸå¹…æ¸¬å®šï¼ˆä¸¦åˆ—æ›¸ãè¾¼ã¿ï¼‰
time dd if=/dev/zero of=/scratch/$USER/large_files/benchmark.dat bs=4M count=2560
# æœŸå¾…: 16ã‚¹ãƒˆãƒ©ã‚¤ãƒ—ã§å¸¯åŸŸå¹…ãŒå˜ä¸€OSTã®ç´„10-12å€ï¼ˆã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰è€ƒæ…®ï¼‰
</code></pre>

            <h3>ã‚¹ãƒˆãƒ©ã‚¤ãƒ”ãƒ³ã‚°æˆ¦ç•¥ã®æœ€é©åŒ–</h3>
            <p>
                ç†è«–çš„ãªæœ€é©ã‚¹ãƒˆãƒ©ã‚¤ãƒ—æ•°\(S\)ã¯ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º\(F\)ã€ã‚¹ãƒˆãƒ©ã‚¤ãƒ—ã‚µã‚¤ã‚º\(C\)ã€OSTæ•°\(N\)ã‹ã‚‰è¨ˆç®—ã§ãã¾ã™ï¼š
            </p>

            <p style="text-align: center; font-size: 1.1rem; margin: 1.5rem 0;">
                \[
                S_{\text{optimal}} = \min\left(\left\lceil \frac{F}{C} \right\rceil, N\right)
                \]
            </p>

            <p>
                ä¾‹: ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º50GBã€ã‚¹ãƒˆãƒ©ã‚¤ãƒ—ã‚µã‚¤ã‚º4MBã€OSTæ•°64ã®å ´åˆï¼š
                \(S = \min(\lceil 50000/4 \rceil, 64) = \min(12500, 64) = 64\)ã€‚
                ãŸã ã—ã€å®Ÿéš›ã«ã¯16-32ã‚¹ãƒˆãƒ©ã‚¤ãƒ—ã§ååˆ†ãªå¸¯åŸŸå¹…ãŒå¾—ã‚‰ã‚Œã‚‹ã“ã¨ãŒå¤šã„ã§ã™ã€‚
            </p>

            <h3>ã‚³ãƒ¼ãƒ‰ä¾‹2: HDF5ä¸¦åˆ—I/Oï¼ˆh5py parallel modeï¼‰</h3>
            <pre><code class="language-python">#!/usr/bin/env python3
# ===================================
# HDF5ä¸¦åˆ—æ›¸ãè¾¼ã¿ãƒ»èª­ã¿è¾¼ã¿ï¼ˆMPIãƒ™ãƒ¼ã‚¹ï¼‰
# ===================================

from mpi4py import MPI
import h5py
import numpy as np

# MPIåˆæœŸåŒ–
comm = MPI.COMM_WORLD
rank = comm.Get_rank()  # ãƒ—ãƒ­ã‚»ã‚¹IDï¼ˆ0ã‹ã‚‰é–‹å§‹ï¼‰
size = comm.Get_size()  # ç·ãƒ—ãƒ­ã‚»ã‚¹æ•°

# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚µã‚¤ã‚ºï¼ˆå…¨ä½“ï¼‰
N_total = 1000000  # 100ä¸‡è¦ç´ 
N_local = N_total // size  # å„ãƒ—ãƒ­ã‚»ã‚¹ãŒæ‹…å½“ã™ã‚‹è¦ç´ æ•°

# å„ãƒ—ãƒ­ã‚»ã‚¹ãŒå‡¦ç†ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ç¯„å›²
start_idx = rank * N_local
end_idx = (rank + 1) * N_local

# ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆï¼ˆä¾‹: ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµæœï¼‰
local_data = np.random.randn(N_local, 3)  # 3æ¬¡å…ƒãƒ™ã‚¯ãƒˆãƒ«

# ===================================
# ä¸¦åˆ—æ›¸ãè¾¼ã¿
# ===================================

# HDF5ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸¦åˆ—ãƒ¢ãƒ¼ãƒ‰ã§ä½œæˆ
# driver='mpio'ã‚’æŒ‡å®šã—ã¦MPI-IOä½¿ç”¨
with h5py.File('parallel_output.h5', 'w', driver='mpio', comm=comm) as f:
    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆï¼ˆå…¨ãƒ—ãƒ­ã‚»ã‚¹ãŒåŒã˜å½¢çŠ¶ã‚’çŸ¥ã£ã¦ã„ã‚‹å¿…è¦ãŒã‚ã‚‹ï¼‰
    dset = f.create_dataset('simulation_data',
                             shape=(N_total, 3),
                             dtype='float64')

    # å„ãƒ—ãƒ­ã‚»ã‚¹ãŒè‡ªåˆ†ã®æ‹…å½“ç¯„å›²ã«æ›¸ãè¾¼ã¿
    dset[start_idx:end_idx, :] = local_data

    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ï¼ˆå±æ€§ï¼‰ã®è¿½åŠ ï¼ˆrank 0ã®ã¿ï¼‰
    if rank == 0:
        dset.attrs['description'] = 'Parallel simulation output'
        dset.attrs['num_processes'] = size
        dset.attrs['total_elements'] = N_total

if rank == 0:
    print(f"Parallel write completed by {size} processes")

# ===================================
# ä¸¦åˆ—èª­ã¿è¾¼ã¿
# ===================================

comm.Barrier()  # å…¨ãƒ—ãƒ­ã‚»ã‚¹ãŒæ›¸ãè¾¼ã¿å®Œäº†ã‚’å¾…ã¤

with h5py.File('parallel_output.h5', 'r', driver='mpio', comm=comm) as f:
    dset = f['simulation_data']

    # å„ãƒ—ãƒ­ã‚»ã‚¹ãŒè‡ªåˆ†ã®æ‹…å½“ç¯„å›²ã‚’èª­ã¿è¾¼ã¿
    local_read_data = dset[start_idx:end_idx, :]

    # èª­ã¿è¾¼ã‚“ã ãƒ‡ãƒ¼ã‚¿ã®æ¤œè¨¼
    assert local_read_data.shape == (N_local, 3)

    if rank == 0:
        print(f"Dataset shape: {dset.shape}")
        print(f"Attributes: {dict(dset.attrs)}")

# ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‡ãƒ¼ã‚¿ã®å‡¦ç†ï¼ˆä¾‹: å¹³å‡è¨ˆç®—ï¼‰
local_mean = np.mean(local_read_data, axis=0)

# MPI Reduceã§å…¨ãƒ—ãƒ­ã‚»ã‚¹ã®å¹³å‡ã‚’è¨ˆç®—
global_mean = np.zeros(3)
comm.Reduce(local_mean * N_local, global_mean, op=MPI.SUM, root=0)

if rank == 0:
    global_mean /= N_total
    print(f"Global mean: {global_mean}")

# å®Ÿè¡Œæ–¹æ³•ï¼ˆSLURMã‚¸ãƒ§ãƒ–ã‚¹ã‚¯ãƒªãƒ—ãƒˆå†…ï¼‰:
# mpirun -np 16 python hdf5_parallel_io.py
# 16ãƒ—ãƒ­ã‚»ã‚¹ã§ä¸¦åˆ—I/Oå®Ÿè¡Œ
</code></pre>

            <div class="info-box">
                <strong>HDF5ä¸¦åˆ—I/Oã®æ€§èƒ½å‘ä¸Š</strong>
                <p>
                    MPI-IOã‚’ä½¿ã£ãŸä¸¦åˆ—æ›¸ãè¾¼ã¿ã¯ã€é€æ¬¡æ›¸ãè¾¼ã¿ã®10-50å€é«˜é€Ÿã§ã™ï¼ˆãƒ—ãƒ­ã‚»ã‚¹æ•°ã¨ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸æ€§èƒ½ã«ä¾å­˜ï¼‰ã€‚
                    ç‰¹ã«ã€Lustreã®ã‚¹ãƒˆãƒ©ã‚¤ãƒ”ãƒ³ã‚°ã¨çµ„ã¿åˆã‚ã›ã‚‹ã¨ã€å„MPIãƒ—ãƒ­ã‚»ã‚¹ãŒç•°ãªã‚‹OSTã«æ›¸ãè¾¼ã‚€ãŸã‚ã€å¸¯åŸŸå¹…ãŒå¤§å¹…ã«å‘ä¸Šã—ã¾ã™ã€‚
                </p>
            </div>
        </section>

        <section id="data-transfer">
            <h2>4.4 ãƒ‡ãƒ¼ã‚¿è»¢é€ã¨ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—</h2>

            <h3>ã‚³ãƒ¼ãƒ‰ä¾‹3: GridFTP/Globusãƒ‡ãƒ¼ã‚¿è»¢é€è‡ªå‹•åŒ–</h3>
            <pre><code class="language-bash">#!/bin/bash
# ===================================
# Globusã«ã‚ˆã‚‹é«˜é€Ÿãƒ‡ãƒ¼ã‚¿è»¢é€ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
# ===================================

# Globus CLIã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼ˆåˆå›ã®ã¿ï¼‰
# pip install globus-cli

# Globusèªè¨¼ï¼ˆåˆå›ã®ã¿ï¼‰
# globus login

# ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆæƒ…å ±
SOURCE_ENDPOINT="abc12345-1234-1234-1234-123456789abc"  # ãƒ­ãƒ¼ã‚«ãƒ«HPC
DEST_ENDPOINT="def67890-5678-5678-5678-567890abcdef"    # ãƒªãƒ¢ãƒ¼ãƒˆHPC

SOURCE_PATH="/scratch/$USER/simulation_results/"
DEST_PATH="/archive/project123/results/"

# è»¢é€ã‚¸ãƒ§ãƒ–ã‚’æŠ•å…¥
TASK_ID=$(globus transfer $SOURCE_ENDPOINT:$SOURCE_PATH \
                          $DEST_ENDPOINT:$DEST_PATH \
                          --recursive \
                          --label "Simulation results transfer" \
                          --sync-level checksum \
                          --jmespath 'task_id' --format=UNIX)

echo "Transfer task submitted: $TASK_ID"

# è»¢é€çŠ¶æ…‹ã‚’ç›£è¦–
while true; do
    STATUS=$(globus task show $TASK_ID --jmespath 'status' --format=UNIX)
    echo "Transfer status: $STATUS"

    if [ "$STATUS" == "SUCCEEDED" ]; then
        echo "Transfer completed successfully"
        break
    elif [ "$STATUS" == "FAILED" ]; then
        echo "Transfer failed"
        globus task show $TASK_ID
        exit 1
    fi

    sleep 30  # 30ç§’ã”ã¨ã«çŠ¶æ…‹ç¢ºèª
done

# è»¢é€çµ±è¨ˆã‚’è¡¨ç¤º
globus task show $TASK_ID
# å‡ºåŠ›ä¾‹:
# Task ID: abc-def-ghi
# Status: SUCCEEDED
# Files: 1,234
# Directories: 56
# Bytes Transferred: 523,456,789,012
# Effective Bandwidth: 1.2 GB/s
</code></pre>

            <h3>ã‚³ãƒ¼ãƒ‰ä¾‹4: rsyncå¢—åˆ†ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚¹ã‚¯ãƒªãƒ—ãƒˆ</h3>
            <pre><code class="language-bash">#!/bin/bash
# ===================================
# rsyncå¢—åˆ†ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆãƒ­ã‚°ä»˜ãï¼‰
# ===================================

# è¨­å®š
SOURCE_DIR="/scratch/$USER/active_project"
BACKUP_DIR="/work/$USER/backups"
LOG_DIR="$HOME/backup_logs"
DATE=$(date +%Y%m%d_%H%M%S)
LOG_FILE="$LOG_DIR/backup_$DATE.log"

# ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
mkdir -p $LOG_DIR
mkdir -p $BACKUP_DIR

# ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—é–‹å§‹
echo "==================================" | tee -a $LOG_FILE
echo "Backup started: $(date)" | tee -a $LOG_FILE
echo "Source: $SOURCE_DIR" | tee -a $LOG_FILE
echo "Destination: $BACKUP_DIR" | tee -a $LOG_FILE
echo "==================================" | tee -a $LOG_FILE

# rsyncã§å¢—åˆ†ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
# --archive: ãƒ‘ãƒ¼ãƒŸãƒƒã‚·ãƒ§ãƒ³ã€ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã€ã‚·ãƒ³ãƒœãƒªãƒƒã‚¯ãƒªãƒ³ã‚¯ä¿æŒ
# --verbose: è©³ç´°è¡¨ç¤º
# --compress: è»¢é€æ™‚åœ§ç¸®
# --delete: ã‚½ãƒ¼ã‚¹ã§å‰Šé™¤ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‹ã‚‰ã‚‚å‰Šé™¤
# --stats: çµ±è¨ˆæƒ…å ±è¡¨ç¤º
# --human-readable: äººé–“ãŒèª­ã¿ã‚„ã™ã„å½¢å¼
# --itemize-changes: å¤‰æ›´ã®è©³ç´°ã‚’è¡¨ç¤º

rsync -avz \
      --delete \
      --stats \
      --human-readable \
      --itemize-changes \
      --log-file=$LOG_FILE \
      --exclude '*.tmp' \
      --exclude '.git/' \
      $SOURCE_DIR/ \
      $BACKUP_DIR/ 2>&1 | tee -a $LOG_FILE

# rsyncã®çµ‚äº†ã‚³ãƒ¼ãƒ‰ç¢ºèª
if [ $? -eq 0 ]; then
    echo "Backup completed successfully: $(date)" | tee -a $LOG_FILE
else
    echo "Backup failed: $(date)" | tee -a $LOG_FILE
    exit 1
fi

# ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚µã‚¤ã‚ºã‚’è¨˜éŒ²
BACKUP_SIZE=$(du -sh $BACKUP_DIR | awk '{print $1}')
echo "Total backup size: $BACKUP_SIZE" | tee -a $LOG_FILE

# å¤ã„ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ï¼ˆ30æ—¥ä»¥ä¸Šå‰ï¼‰
find $LOG_DIR -name "backup_*.log" -mtime +30 -delete

echo "==================================" | tee -a $LOG_FILE
echo "Backup log saved to: $LOG_FILE" | tee -a $LOG_FILE

# cronã§å®šæœŸå®Ÿè¡Œã™ã‚‹å ´åˆ:
# crontab -e ã§ä»¥ä¸‹ã‚’è¿½åŠ 
# 0 2 * * * /home/$USER/scripts/backup.sh
# æ¯æ—¥åˆå‰2æ™‚ã«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Ÿè¡Œ
</code></pre>

            <div class="warning-box">
                <strong>ãƒ‡ãƒ¼ã‚¿è»¢é€ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹</strong>
                <ul>
                    <li><strong>å¸¯åŸŸåˆ¶é™</strong>: å…±æœ‰ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã§ã¯<code>rsync --bwlimit</code>ã§å¸¯åŸŸåˆ¶é™</li>
                    <li><strong>ãƒã‚§ãƒƒã‚¯ã‚µãƒ æ¤œè¨¼</strong>: <code>rsync -c</code>ã¾ãŸã¯<code>globus --sync-level checksum</code>ã§æ•´åˆæ€§ç¢ºèª</li>
                    <li><strong>åœ§ç¸®</strong>: ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å¸¯åŸŸãŒãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã®å ´åˆã€<code>-z</code>ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§åœ§ç¸®è»¢é€</li>
                    <li><strong>ä¸¦åˆ—è»¢é€</strong>: å°ãƒ•ã‚¡ã‚¤ãƒ«å¤šæ•°ã®å ´åˆã€GNU parallelã§rsyncã‚’ä¸¦åˆ—å®Ÿè¡Œ</li>
                </ul>
            </div>
        </section>

        <section id="io-optimization">
            <h2>4.5 I/Oæ€§èƒ½æœ€é©åŒ–</h2>

            <h3>I/Oãƒ‘ã‚¿ãƒ¼ãƒ³ã¨æœ€é©åŒ–æˆ¦ç•¥</h3>
            <table>
                <thead>
                    <tr>
                        <th>I/Oãƒ‘ã‚¿ãƒ¼ãƒ³</th>
                        <th>ç‰¹å¾´</th>
                        <th>æœ€é©åŒ–æ‰‹æ³•</th>
                        <th>é©ç”¨ä¾‹</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><strong>é€æ¬¡èª­ã¿è¾¼ã¿</strong></td>
                        <td>å¤§è¦æ¨¡ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é †ç•ªã«èª­ã‚€</td>
                        <td>å…ˆèª­ã¿ï¼ˆprefetchï¼‰ã€å¤§ããªãƒãƒƒãƒ•ã‚¡ã‚µã‚¤ã‚º</td>
                        <td>å‹•ç”»å‡¦ç†ã€ã‚²ãƒãƒ é…åˆ—è§£æ</td>
                    </tr>
                    <tr>
                        <td><strong>ãƒ©ãƒ³ãƒ€ãƒ ã‚¢ã‚¯ã‚»ã‚¹</strong></td>
                        <td>ãƒ•ã‚¡ã‚¤ãƒ«å†…ã®ä»»æ„ä½ç½®ã‚’èª­ã‚€</td>
                        <td>SSDä½¿ç”¨ã€ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ§‹ç¯‰</td>
                        <td>ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¯ã‚¨ãƒªã€åˆ†å­å‹•åŠ›å­¦</td>
                    </tr>
                    <tr>
                        <td><strong>ãƒãƒ¼ã‚¹ãƒˆæ›¸ãè¾¼ã¿</strong></td>
                        <td>çŸ­æ™‚é–“ã«å¤§é‡ãƒ‡ãƒ¼ã‚¿ã‚’æ›¸ã</td>
                        <td>ãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°ã€éåŒæœŸI/O</td>
                        <td>ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã€å¯è¦–åŒ–å‡ºåŠ›</td>
                    </tr>
                    <tr>
                        <td><strong>å°ãƒ•ã‚¡ã‚¤ãƒ«å¤šæ•°</strong></td>
                        <td>å¤šæ•°ã®å°ãƒ•ã‚¡ã‚¤ãƒ«æ“ä½œ</td>
                        <td>ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–åŒ–ï¼ˆtarï¼‰ã€ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æœ€é©åŒ–</td>
                        <td>ãƒ¡ã‚¿ã‚²ãƒãƒ è§£æã€ç”»åƒå‡¦ç†</td>
                    </tr>
                </tbody>
            </table>

            <h3>ã‚³ãƒ¼ãƒ‰ä¾‹5: Zarrä¸¦åˆ—æ›¸ãè¾¼ã¿ï¼ˆåˆ†æ•£é…åˆ—ï¼‰</h3>
            <pre><code class="language-python">#!/usr/bin/env python3
# ===================================
# Zarrä¸¦åˆ—æ›¸ãè¾¼ã¿ï¼ˆDaskåˆ†æ•£å‡¦ç†ï¼‰
# ===================================

import zarr
import numpy as np
import dask.array as da
from dask.distributed import Client, LocalCluster

# Daskåˆ†æ•£ã‚¯ãƒ©ã‚¹ã‚¿èµ·å‹•ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ï¼‰
# HPCã§ã¯SLURMçµ±åˆ: dask-jobqueueä½¿ç”¨
cluster = LocalCluster(n_workers=8, threads_per_worker=2)
client = Client(cluster)

print(f"Dask dashboard: {client.dashboard_link}")

# å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç”Ÿæˆï¼ˆãƒ¡ãƒ¢ãƒªã«è¼‰ã‚‰ãªã„ã‚µã‚¤ã‚ºï¼‰
# 10,000 x 10,000 x 100ã®3æ¬¡å…ƒé…åˆ—ï¼ˆ80GBï¼‰
shape = (10000, 10000, 100)
chunks = (1000, 1000, 10)  # ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºï¼ˆ8MB/chunkï¼‰

# Daské…åˆ—ï¼ˆé…å»¶è©•ä¾¡ï¼‰
data = da.random.random(shape, chunks=chunks)

# Zarrã‚¹ãƒˆã‚¢ã®ä½œæˆï¼ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ™ãƒ¼ã‚¹ã‚¹ãƒˆã‚¢ï¼‰
store_path = '/scratch/$USER/zarr_output.zarr'
zarr_array = zarr.open(store_path,
                        mode='w',
                        shape=shape,
                        chunks=chunks,
                        dtype='float64',
                        compressor=zarr.Blosc(cname='zstd', clevel=3, shuffle=2))

# ä¸¦åˆ—æ›¸ãè¾¼ã¿ï¼ˆDaskãŒè‡ªå‹•çš„ã«ãƒãƒ£ãƒ³ã‚¯ã‚’åˆ†æ•£å‡¦ç†ï¼‰
da.to_zarr(data, store_path, overwrite=True)

print(f"Data written to {store_path}")
print(f"Total size: {data.nbytes / 1e9:.2f} GB")
print(f"Chunks: {data.nchunks}")

# ===================================
# ä¸¦åˆ—èª­ã¿è¾¼ã¿ã¨å‡¦ç†
# ===================================

# Zarrã‹ã‚‰èª­ã¿è¾¼ã¿ï¼ˆé…å»¶è©•ä¾¡ï¼‰
loaded_data = da.from_zarr(store_path)

# çµ±è¨ˆè¨ˆç®—ï¼ˆä¸¦åˆ—å®Ÿè¡Œï¼‰
mean_val = loaded_data.mean().compute()
std_val = loaded_data.std().compute()

print(f"Mean: {mean_val:.6f}")
print(f"Std: {std_val:.6f}")

# éƒ¨åˆ†çš„ãªèª­ã¿è¾¼ã¿ï¼ˆç‰¹å®šã®ã‚¹ãƒ©ã‚¤ã‚¹ï¼‰
subset = loaded_data[0:1000, 0:1000, :].compute()
print(f"Subset shape: {subset.shape}")

client.close()
cluster.close()

# å®Ÿè¡Œçµæœä¾‹:
# Data written to /scratch/$USER/zarr_output.zarr
# Total size: 80.00 GB
# Chunks: 1000
# Mean: 0.499987
# Std: 0.288675
# Subset shape: (1000, 1000, 100)

# Zarrã®åˆ©ç‚¹:
# 1. ã‚¯ãƒ©ã‚¦ãƒ‰æœ€é©åŒ–ï¼ˆS3ã€GCSå¯¾å¿œï¼‰
# 2. åœ§ç¸®ç‡ãŒé«˜ã„ï¼ˆBlosc compressorï¼‰
# 3. ãƒãƒ£ãƒ³ã‚¯ä¸¦åˆ—ã‚¢ã‚¯ã‚»ã‚¹
# 4. NumPyäº’æ›API
</code></pre>

            <h3>ã‚³ãƒ¼ãƒ‰ä¾‹6: Darshan I/Oãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°è§£æ</h3>
            <pre><code class="language-bash">#!/bin/bash
# ===================================
# Darshan I/Oãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
# ===================================

# Darshanã¯HPCã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®I/Oå‹•ä½œã‚’è‡ªå‹•è¨˜éŒ²ã™ã‚‹ãƒ„ãƒ¼ãƒ«
# ã‚¸ãƒ§ãƒ–å®Ÿè¡Œæ™‚ã«LD_PRELOADã§è‡ªå‹•çš„ã«ãƒ­ã‚°åé›†

# ã‚¸ãƒ§ãƒ–å®Ÿè¡Œå¾Œã€Darshanãƒ­ã‚°ã‚’è§£æ

# Darshanãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆã‚·ã‚¹ãƒ†ãƒ ç®¡ç†è€…ãŒè¨­å®šï¼‰
DARSHAN_LOGS="/var/logs/darshan/$USER"

# æœ€æ–°ã®ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
LATEST_LOG=$(ls -t $DARSHAN_LOGS/*.darshan | head -1)

echo "Analyzing Darshan log: $LATEST_LOG"

# ===================================
# åŸºæœ¬ã‚µãƒãƒªãƒ¼ç”Ÿæˆ
# ===================================
darshan-parser $LATEST_LOG > darshan_summary.txt

# ä¸»è¦ãªI/Oçµ±è¨ˆã‚’æŠ½å‡º
echo "==================================" > io_report.txt
echo "I/O Performance Report" >> io_report.txt
echo "==================================" >> io_report.txt

# ç·I/Oæ™‚é–“
grep "total_POSIX_" $LATEST_LOG | head -5 >> io_report.txt

# èª­ã¿æ›¸ããƒã‚¤ãƒˆæ•°
echo "" >> io_report.txt
echo "Data Transfer:" >> io_report.txt
grep "total_bytes" $LATEST_LOG >> io_report.txt

# I/Oå¸¯åŸŸå¹…è¨ˆç®—
echo "" >> io_report.txt
echo "Bandwidth:" >> io_report.txt
grep "agg_perf" $LATEST_LOG >> io_report.txt

# ===================================
# ã‚°ãƒ©ãƒ•ã‚£ã‚«ãƒ«ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆï¼ˆPDFã¨HTMLï¼‰
# ===================================
darshan-job-summary.pl $LATEST_LOG

# å‡ºåŠ›: ã‚¸ãƒ§ãƒ–ID_summary.pdf

# PDFãƒ¬ãƒãƒ¼ãƒˆã«ã¯ä»¥ä¸‹ãŒå«ã¾ã‚Œã‚‹:
# - I/Oã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³
# - ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ã‚¯ã‚»ã‚¹ãƒ‘ã‚¿ãƒ¼ãƒ³
# - I/Oæ“ä½œã‚µã‚¤ã‚ºåˆ†å¸ƒ
# - ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ“ä½œçµ±è¨ˆ

echo "Reports generated:"
echo "  - darshan_summary.txt (text)"
echo "  - io_report.txt (custom summary)"
echo "  - *_summary.pdf (graphical)"

# ===================================
# I/Oãƒœãƒˆãƒ«ãƒãƒƒã‚¯ç‰¹å®š
# ===================================

# ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ“ä½œãŒå¤šã„å ´åˆã®è­¦å‘Š
METADATA_OPS=$(grep -c "stat\|open\|close" darshan_summary.txt)
if [ $METADATA_OPS -gt 10000 ]; then
    echo "WARNING: High metadata operations detected ($METADATA_OPS)"
    echo "Consider using file aggregation (HDF5, Zarr)"
fi

# å°è¦æ¨¡I/Oæ“ä½œã®æ¤œå‡º
SMALL_IO=$(grep "POSIX_SIZE_READ_0_100" darshan_summary.txt | awk '{print $2}')
if [ ! -z "$SMALL_IO" ] && [ $SMALL_IO -gt 1000 ]; then
    echo "WARNING: Many small I/O operations detected"
    echo "Consider buffering or increasing I/O size"
fi

# Lustreæœ€é©åŒ–ææ¡ˆ
STRIPE_COUNT=$(lfs getstripe $OUTPUT_DIR 2>/dev/null | grep stripe_count | awk '{print $2}')
if [ ! -z "$STRIPE_COUNT" ] && [ $STRIPE_COUNT -lt 4 ]; then
    echo "SUGGESTION: Increase Lustre stripe count for better parallelism"
    echo "Current: $STRIPE_COUNT, Recommended: 8-16"
fi
</code></pre>

            <div class="info-box">
                <strong>I/Oæœ€é©åŒ–ã®ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ</strong>
                <ul>
                    <li>âœ… ãƒãƒƒãƒ•ã‚¡ã‚µã‚¤ã‚ºã‚’é©åˆ‡ã«è¨­å®šï¼ˆé€šå¸¸4-16MBï¼‰</li>
                    <li>âœ… Lustreã‚¹ãƒˆãƒ©ã‚¤ãƒ”ãƒ³ã‚°ã‚’ãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰ã«åˆã‚ã›ã‚‹</li>
                    <li>âœ… HDF5/Zarrã§å°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é›†ç´„</li>
                    <li>âœ… éåŒæœŸI/Oï¼ˆasyncioã€MPI-IOï¼‰ã‚’æ´»ç”¨</li>
                    <li>âœ… Darshanã§ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ã—ã€ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã‚’ç‰¹å®š</li>
                </ul>
            </div>
        </section>

        <section id="python-data">
            <h2>4.6 Pythonãƒ‡ãƒ¼ã‚¿ç®¡ç†</h2>

            <h3>ã‚³ãƒ¼ãƒ‰ä¾‹7: PyTablesã«ã‚ˆã‚‹éšå±¤ãƒ‡ãƒ¼ã‚¿ç®¡ç†</h3>
            <pre><code class="language-python">#!/usr/bin/env python3
# ===================================
# PyTables: HDF5ã®é«˜ãƒ¬ãƒ™ãƒ«Pythonã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
# ===================================

import tables
import numpy as np

# PyTablesãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆï¼ˆåœ§ç¸®ã‚ã‚Šï¼‰
h5file = tables.open_file('experiment_data.h5', mode='w',
                           title='Material Science Experiments')

# ===================================
# éšå±¤æ§‹é€ ã®ä½œæˆ
# ===================================

# ã‚°ãƒ«ãƒ¼ãƒ—ï¼ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ã‚ˆã†ãªéšå±¤ï¼‰
experiments = h5file.create_group('/', 'experiments', 'All experiments')
exp1 = h5file.create_group(experiments, 'exp001', 'Temperature sweep')
exp2 = h5file.create_group(experiments, 'exp002', 'Pressure sweep')

# ===================================
# Tableã®å®šç¾©ï¼ˆæ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ï¼‰
# ===================================

class Measurement(tables.IsDescription):
    """æ¸¬å®šãƒ‡ãƒ¼ã‚¿ã®ã‚¹ã‚­ãƒ¼ãƒå®šç¾©"""
    timestamp = tables.Float64Col()     # UNIXã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—
    temperature = tables.Float32Col()   # æ¸©åº¦ [K]
    pressure = tables.Float32Col()      # åœ§åŠ› [Pa]
    conductivity = tables.Float32Col()  # é›»æ°—ä¼å°ç‡ [S/m]
    sample_id = tables.StringCol(16)    # ã‚µãƒ³ãƒ—ãƒ«ID

# Tableã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆä½œæˆï¼ˆexp1ã‚°ãƒ«ãƒ¼ãƒ—å†…ï¼‰
table = h5file.create_table(exp1, 'measurements', Measurement,
                             'Temperature sweep measurements',
                             filters=tables.Filters(complevel=5, complib='blosc'))

# ===================================
# ãƒ‡ãƒ¼ã‚¿ã®æ›¸ãè¾¼ã¿
# ===================================

measurement = table.row
for i in range(1000):
    measurement['timestamp'] = 1609459200.0 + i * 60  # 1åˆ†é–“éš”
    measurement['temperature'] = 300 + i * 0.1  # 300Kã‹ã‚‰æ˜‡æ¸©
    measurement['pressure'] = 101325  # 1 atm
    measurement['conductivity'] = 1e6 * np.exp(-0.01 * i)  # æŒ‡æ•°æ¸›è¡°
    measurement['sample_id'] = f'SAMPLE_{i:04d}'
    measurement.append()

table.flush()  # ãƒ‡ã‚£ã‚¹ã‚¯ã«æ›¸ãè¾¼ã¿

print(f"Table shape: {table.shape}")
print(f"Table columns: {table.colnames}")

# ===================================
# é…åˆ—ãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜ï¼ˆå¤§è¦æ¨¡æ•°å€¤ãƒ‡ãƒ¼ã‚¿ï¼‰
# ===================================

# EArrayï¼ˆæ‹¡å¼µå¯èƒ½é…åˆ—ï¼‰: å‹•çš„ã«ã‚µã‚¤ã‚ºãŒå¢—ãˆã‚‹
earray = h5file.create_earray(exp1, 'timeseries',
                               atom=tables.Float64Atom(),
                               shape=(0, 100),  # åˆæœŸ0è¡Œã€100åˆ—
                               title='Time series data',
                               filters=tables.Filters(complevel=5))

# ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ ï¼ˆè¡Œã‚’å¢—ã‚„ã™ï¼‰
for _ in range(50):
    new_data = np.random.randn(1, 100)  # 1è¡Œ100åˆ—
    earray.append(new_data)

print(f"EArray shape: {earray.shape}")  # (50, 100)

# ===================================
# ã‚¯ã‚¨ãƒªã¨ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
# ===================================

# WHEREå¥ã§ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºï¼ˆSQLé¢¨ï¼‰
high_temp = [row['conductivity'] for row in table.where('temperature > 340')]
print(f"High temperature conductivity samples: {len(high_temp)}")

# ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆã—ã¦é«˜é€Ÿæ¤œç´¢
table.cols.temperature.create_index()
table.cols.sample_id.create_csindex()  # å®Œå…¨ä¸€è‡´æ¤œç´¢ç”¨

# ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½¿ã£ãŸæ¤œç´¢
results = table.read_where('(temperature >= 350) & (temperature <= 360)')
print(f"Temperature 350-360K: {len(results)} measurements")

# ===================================
# åœ§ç¸®ç‡ã¨æ€§èƒ½
# ===================================

h5file.close()

# ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºç¢ºèª
import os
file_size = os.path.getsize('experiment_data.h5') / 1024  # KB
print(f"File size: {file_size:.2f} KB")

# éåœ§ç¸®ã¨ã®æ¯”è¼ƒ
uncompressed_size = (1000 * 32 + 50 * 100 * 8) / 1024  # ç†è«–ã‚µã‚¤ã‚º
compression_ratio = uncompressed_size / file_size
print(f"Compression ratio: {compression_ratio:.2f}x")

# å†åº¦é–‹ã„ã¦ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç¢ºèª
h5file = tables.open_file('experiment_data.h5', mode='r')
print(h5file)
# å‡ºåŠ›ä¾‹:
# experiment_data.h5 (File) 'Material Science Experiments'
# Last modif.: 'Fri Nov  1 10:30:00 2025'
# Object Tree:
# / (RootGroup) 'Material Science Experiments'
# /experiments (Group) 'All experiments'
# /experiments/exp001 (Group) 'Temperature sweep'
# /experiments/exp001/measurements (Table(1000,)) 'Temperature sweep measurements'
# /experiments/exp001/timeseries (EArray(50, 100)) 'Time series data'

h5file.close()
</code></pre>

            <h3>ã‚³ãƒ¼ãƒ‰ä¾‹8: ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ä½¿ç”¨é‡ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ã¨ã‚¢ãƒ©ãƒ¼ãƒˆ</h3>
            <pre><code class="language-python">#!/usr/bin/env python3
# ===================================
# ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ä½¿ç”¨é‡ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ãƒ»ã‚¯ã‚©ãƒ¼ã‚¿ã‚¢ãƒ©ãƒ¼ãƒˆ
# ===================================

import subprocess
import json
import smtplib
from email.mime.text import MIMEText
from datetime import datetime

def get_lustre_quota(filesystem='/scratch'):
    """Lustreã‚¯ã‚©ãƒ¼ã‚¿æƒ…å ±ã‚’å–å¾—"""
    try:
        result = subprocess.run(['lfs', 'quota', '-u', filesystem],
                                capture_output=True, text=True, check=True)

        # lfs quotaã®å‡ºåŠ›ã‚’ãƒ‘ãƒ¼ã‚¹
        lines = result.stdout.strip().split('\n')
        quota_line = lines[-1]  # æœ€çµ‚è¡Œã«ã‚¯ã‚©ãƒ¼ã‚¿æƒ…å ±

        # å‡ºåŠ›ä¾‹:
        # Filesystem  kbytes   quota   limit   grace   files   quota   limit   grace
        # /scratch    123456M  200000M 250000M   -       1234   10000   15000    -

        parts = quota_line.split()
        used_kb = int(parts[1].replace('M', '')) * 1024 if 'M' in parts[1] else int(parts[1])
        quota_kb = int(parts[2].replace('M', '')) * 1024 if 'M' in parts[2] else int(parts[2])
        limit_kb = int(parts[3].replace('M', '')) * 1024 if 'M' in parts[3] else int(parts[3])

        return {
            'used_gb': used_kb / (1024**2),
            'quota_gb': quota_kb / (1024**2),
            'limit_gb': limit_kb / (1024**2),
            'usage_percent': (used_kb / quota_kb) * 100 if quota_kb > 0 else 0
        }
    except subprocess.CalledProcessError as e:
        print(f"Error getting quota: {e}")
        return None

def get_directory_usage(path):
    """ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½¿ç”¨é‡ã‚’å–å¾—ï¼ˆduï¼‰"""
    try:
        result = subprocess.run(['du', '-sb', path],
                                capture_output=True, text=True, check=True)
        bytes_used = int(result.stdout.split()[0])
        return bytes_used / (1024**3)  # GB
    except subprocess.CalledProcessError as e:
        print(f"Error getting directory usage: {e}")
        return None

def send_alert_email(subject, message, recipient):
    """ã‚¢ãƒ©ãƒ¼ãƒˆãƒ¡ãƒ¼ãƒ«ã‚’é€ä¿¡"""
    msg = MIMEText(message)
    msg['Subject'] = subject
    msg['From'] = 'hpc-monitor@example.com'
    msg['To'] = recipient

    try:
        with smtplib.SMTP('localhost') as server:
            server.send_message(msg)
        print(f"Alert email sent to {recipient}")
    except Exception as e:
        print(f"Failed to send email: {e}")

def main():
    # è¨­å®š
    QUOTA_THRESHOLD = 80  # ã‚¯ã‚©ãƒ¼ã‚¿ä½¿ç”¨ç‡ã®è­¦å‘Šé–¾å€¤ï¼ˆ%ï¼‰
    EMAIL_RECIPIENT = 'user@example.com'

    # Lustreã‚¯ã‚©ãƒ¼ã‚¿ãƒã‚§ãƒƒã‚¯
    print("=" * 50)
    print(f"Storage Usage Report - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 50)

    quota_info = get_lustre_quota('/scratch')
    if quota_info:
        print(f"\nLustre Filesystem: /scratch")
        print(f"  Used: {quota_info['used_gb']:.2f} GB")
        print(f"  Quota: {quota_info['quota_gb']:.2f} GB")
        print(f"  Limit: {quota_info['limit_gb']:.2f} GB")
        print(f"  Usage: {quota_info['usage_percent']:.1f}%")

        # é–¾å€¤ãƒã‚§ãƒƒã‚¯
        if quota_info['usage_percent'] > QUOTA_THRESHOLD:
            alert_msg = f"""
WARNING: Storage quota threshold exceeded!

Filesystem: /scratch
Current usage: {quota_info['usage_percent']:.1f}%
Used: {quota_info['used_gb']:.2f} GB / {quota_info['quota_gb']:.2f} GB

Please clean up old files or request quota increase.
            """
            print("\nâš ï¸  WARNING: Quota threshold exceeded!")
            send_alert_email("Storage Quota Alert", alert_msg, EMAIL_RECIPIENT)

    # ä¸»è¦ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½¿ç”¨é‡
    important_dirs = [
        '/scratch/$USER/active_projects',
        '/scratch/$USER/results',
        '/scratch/$USER/temp'
    ]

    print("\n" + "=" * 50)
    print("Directory Usage Breakdown")
    print("=" * 50)

    dir_usage = []
    for directory in important_dirs:
        usage_gb = get_directory_usage(directory)
        if usage_gb is not None:
            dir_usage.append((directory, usage_gb))
            print(f"{directory}: {usage_gb:.2f} GB")

    # ä½¿ç”¨é‡é †ã«ã‚½ãƒ¼ãƒˆ
    dir_usage.sort(key=lambda x: x[1], reverse=True)

    # å¤§ãã„ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’è­¦å‘Š
    if dir_usage and dir_usage[0][1] > 100:  # 100GBè¶…ãˆ
        print(f"\nğŸ’¡ Suggestion: {dir_usage[0][0]} is using {dir_usage[0][1]:.2f} GB")
        print("   Consider archiving or cleaning up this directory.")

    # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã«è¨˜éŒ²
    log_entry = {
        'timestamp': datetime.now().isoformat(),
        'quota': quota_info,
        'directories': dict(dir_usage)
    }

    with open('storage_usage_log.json', 'a') as f:
        f.write(json.dumps(log_entry) + '\n')

    print("\n" + "=" * 50)
    print("Report saved to storage_usage_log.json")
    print("=" * 50)

if __name__ == '__main__':
    main()

# cronã§å®šæœŸå®Ÿè¡Œ:
# 0 9 * * * /home/$USER/scripts/storage_monitor.py
# æ¯æ—¥åˆå‰9æ™‚ã«ãƒã‚§ãƒƒã‚¯
</code></pre>

            <div class="info-box">
                <strong>Pythonãƒ‡ãƒ¼ã‚¿ç®¡ç†ãƒ„ãƒ¼ãƒ«ã®é¸æŠ</strong>
                <table>
                    <thead>
                        <tr>
                            <th>ãƒ„ãƒ¼ãƒ«</th>
                            <th>ç”¨é€”</th>
                            <th>é•·æ‰€</th>
                            <th>çŸ­æ‰€</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>HDF5 (h5py)</strong></td>
                            <td>ç§‘å­¦è¨ˆç®—å…¨èˆ¬</td>
                            <td>MPIä¸¦åˆ—I/Oã€åœ§ç¸®ã€éšå±¤æ§‹é€ </td>
                            <td>ã‚¹ã‚­ãƒ¼ãƒå¤‰æ›´ãŒå›°é›£</td>
                        </tr>
                        <tr>
                            <td><strong>Zarr</strong></td>
                            <td>ã‚¯ãƒ©ã‚¦ãƒ‰ã€é…åˆ—ãƒ‡ãƒ¼ã‚¿</td>
                            <td>ãƒãƒ£ãƒ³ã‚¯ä¸¦åˆ—ã€S3å¯¾å¿œã€æŸ”è»Ÿ</td>
                            <td>è¡¨å½¢å¼ãƒ‡ãƒ¼ã‚¿ã«ä¸å‘ã</td>
                        </tr>
                        <tr>
                            <td><strong>PyTables</strong></td>
                            <td>ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹é¢¨æ“ä½œ</td>
                            <td>ã‚¯ã‚¨ãƒªã€ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã€åœ§ç¸®</td>
                            <td>å­¦ç¿’æ›²ç·šãŒã‚„ã‚„æ€¥</td>
                        </tr>
                        <tr>
                            <td><strong>Parquet</strong></td>
                            <td>ãƒ“ãƒƒã‚°ãƒ‡ãƒ¼ã‚¿ã€åˆ†æ</td>
                            <td>åˆ—æŒ‡å‘ã€Sparké€£æºã€é«˜åœ§ç¸®</td>
                            <td>ä¸¦åˆ—æ›¸ãè¾¼ã¿ã«åˆ¶é™</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </section>

        <section id="learning-objectives">
            <h2>å­¦ç¿’ç›®æ¨™ã®ç¢ºèª</h2>

            <p>ã“ã®ç« ã‚’å®Œäº†ã™ã‚‹ã¨ã€ä»¥ä¸‹ã‚’èª¬æ˜ãƒ»å®Ÿè¡Œã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã™ï¼š</p>

            <h3>åŸºæœ¬ç†è§£</h3>
            <ul>
                <li>âœ… Lustreã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ï¼ˆOSTã€MDTã€MGTï¼‰ã®å½¹å‰²ã‚’èª¬æ˜ã§ãã‚‹</li>
                <li>âœ… ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸éšå±¤ï¼ˆHotã€Warmã€Coldï¼‰ã®ç‰¹æ€§ã¨ç”¨é€”ã‚’ç†è§£ã§ãã‚‹</li>
                <li>âœ… RAID 6ã®å®¹é‡è¨ˆç®—ã¨å†—é•·æ€§ã‚’èª¬æ˜ã§ãã‚‹</li>
                <li>âœ… I/Oãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆé€æ¬¡ã€ãƒ©ãƒ³ãƒ€ãƒ ã€ãƒãƒ¼ã‚¹ãƒˆï¼‰ã®é•ã„ã‚’ç†è§£ã§ãã‚‹</li>
            </ul>

            <h3>å®Ÿè·µã‚¹ã‚­ãƒ«</h3>
            <ul>
                <li>âœ… Lustreã‚¹ãƒˆãƒ©ã‚¤ãƒ”ãƒ³ã‚°è¨­å®šï¼ˆ<code>lfs setstripe</code>ï¼‰ã‚’å®Ÿè¡Œã§ãã‚‹</li>
                <li>âœ… HDF5ä¸¦åˆ—I/Oï¼ˆh5py + MPIï¼‰ã‚’å®Ÿè£…ã§ãã‚‹</li>
                <li>âœ… rsyncã§å¢—åˆ†ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ä½œæˆã§ãã‚‹</li>
                <li>âœ… Zarrã§å¤§è¦æ¨¡é…åˆ—ãƒ‡ãƒ¼ã‚¿ã‚’ç®¡ç†ã§ãã‚‹</li>
                <li>âœ… Darshanã§ã‚¸ãƒ§ãƒ–ã®I/Oãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è§£æã§ãã‚‹</li>
            </ul>

            <h3>å¿œç”¨åŠ›</h3>
            <ul>
                <li>âœ… ãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰ã«æœ€é©ãªã‚¹ãƒˆãƒ©ã‚¤ãƒ”ãƒ³ã‚°æˆ¦ç•¥ã‚’è¨­è¨ˆã§ãã‚‹</li>
                <li>âœ… I/Oãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã‚’ç‰¹å®šã—ã€æœ€é©åŒ–ææ¡ˆãŒã§ãã‚‹</li>
                <li>âœ… ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸éšå±¤ç®¡ç†ã®è‡ªå‹•åŒ–ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’æ§‹ç¯‰ã§ãã‚‹</li>
                <li>âœ… é©åˆ‡ãªãƒ‡ãƒ¼ã‚¿ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆHDF5ã€Zarrã€Parquetï¼‰ã‚’é¸æŠã§ãã‚‹</li>
            </ul>
        </section>

        <section id="exercises">
            <h2>æ¼”ç¿’å•é¡Œ</h2>

            <h3>Easyï¼ˆåŸºç¤ç¢ºèªï¼‰<span class="difficulty easy">åˆç´š</span></h3>

            <div class="exercise-box">
                <h4>Q1: Lustreã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®å½¹å‰²</h4>
                <p>Lustreã®3ã¤ã®ä¸»è¦ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆï¼ˆMGSã€MDSã€OSSï¼‰ã®å½¹å‰²ã‚’ãã‚Œãã‚Œèª¬æ˜ã—ã¦ãã ã•ã„ã€‚</p>

                <details>
                    <summary>è§£ç­”ã‚’è¦‹ã‚‹</summary>
                    <p><strong>æ­£è§£</strong>:</p>
                    <ol>
                        <li><strong>MGS (Management Server)</strong>: ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ã®è¨­å®šæƒ…å ±ã‚’ç®¡ç†ã€‚ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¨ã‚µãƒ¼ãƒãƒ¼é–“ã®æ¥ç¶šæƒ…å ±ã‚’æä¾›</li>
                        <li><strong>MDS (Metadata Server)</strong>: ãƒ•ã‚¡ã‚¤ãƒ«åã€ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ã€ãƒ‘ãƒ¼ãƒŸãƒƒã‚·ãƒ§ãƒ³ç­‰ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ç®¡ç†ã€‚MDTï¼ˆMetadata Targetï¼‰ã«ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜</li>
                        <li><strong>OSS (Object Storage Server)</strong>: å®Ÿéš›ã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã€‚è¤‡æ•°ã®OSTï¼ˆObject Storage Targetï¼‰ã‚’ç®¡ç†ã—ã€ä¸¦åˆ—I/Oã‚’å®Ÿç¾</li>
                    </ol>
                    <p><strong>è£œè¶³</strong>: ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¯MDSã‹ã‚‰ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã€OSSã‹ã‚‰ç›´æ¥ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿æ›¸ãã™ã‚‹ãŸã‚ã€ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã¨ãƒ‡ãƒ¼ã‚¿ã®ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ãŒåˆ†é›¢ã•ã‚Œé«˜æ€§èƒ½ã‚’å®Ÿç¾ã—ã¾ã™ã€‚</p>
                </details>
            </div>

            <div class="exercise-box">
                <h4>Q2: ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸éšå±¤ã®é¸æŠ</h4>
                <p>ä»¥ä¸‹ã®ãƒ‡ãƒ¼ã‚¿ã«æœ€é©ãªã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸éšå±¤ï¼ˆHotã€Warmã€Coldï¼‰ã‚’é¸ã³ã€ç†ç”±ã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚</p>
                <ul>
                    <li>(a) å®Ÿè¡Œä¸­ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®ä¸­é–“çµæœï¼ˆ1TBã€æ¯åˆ†ã‚¢ã‚¯ã‚»ã‚¹ï¼‰</li>
                    <li>(b) 3ãƒ¶æœˆå‰ã«å®Œäº†ã—ãŸãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ‡ãƒ¼ã‚¿ï¼ˆ5TBã€æœˆ1å›ã‚¢ã‚¯ã‚»ã‚¹ï¼‰</li>
                    <li>(c) 10å¹´å‰ã®è¦³æ¸¬ãƒ‡ãƒ¼ã‚¿ï¼ˆ50TBã€å¹´1å›ã‚¢ã‚¯ã‚»ã‚¹ï¼‰</li>
                </ul>

                <details>
                    <summary>è§£ç­”ã‚’è¦‹ã‚‹</summary>
                    <p><strong>æ­£è§£</strong>:</p>
                    <ul>
                        <li>(a) <strong>Hot Tierï¼ˆNVMe SSDï¼‰</strong>: é »ç¹ãªã‚¢ã‚¯ã‚»ã‚¹ã¨é«˜é€ŸI/OãŒå¿…è¦ã€‚ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãŒä½ãå¸¯åŸŸå¹…ãŒé«˜ã„SSDãŒæœ€é©</li>
                        <li>(b) <strong>Warm Tierï¼ˆSATA SSD/HDDï¼‰</strong>: ã‚¢ã‚¯ã‚»ã‚¹é »åº¦ã¯ä½ã„ãŒã€å¿…è¦æ™‚ã«ã¯æ•°åˆ†ä»¥å†…ã«ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½ãªé€Ÿåº¦ãŒæ±‚ã‚ã‚‰ã‚Œã‚‹</li>
                        <li>(c) <strong>Cold Tierï¼ˆTapeï¼‰</strong>: ã‚¢ã‚¯ã‚»ã‚¹é »åº¦ãŒæ¥µã‚ã¦ä½ãã€å®¹é‡å˜ä¾¡ãŒæœ€ã‚‚é‡è¦ã€‚ãƒ†ãƒ¼ãƒ—ã¯å¤§å®¹é‡ãƒ»ä½ã‚³ã‚¹ãƒˆã§é•·æœŸä¿å­˜ã«æœ€é©</li>
                    </ul>
                    <p><strong>ã‚³ã‚¹ãƒˆè©¦ç®—</strong>: 50TBã‚’10å¹´ä¿å­˜ã—ãŸå ´åˆã€NVMe SSDã¯ç´„$50,000ã€Tapeã¯ç´„$500ï¼ˆ100å€ã®å·®ï¼‰ã€‚</p>
                </details>
            </div>

            <div class="exercise-box">
                <h4>Q3: RAID 6å®¹é‡è¨ˆç®—</h4>
                <p>12å°ã®4TB HDDã§RAID 6ã‚’æ§‹æˆã—ãŸå ´åˆã®ä½¿ç”¨å¯èƒ½å®¹é‡ã‚’è¨ˆç®—ã—ã¦ãã ã•ã„ã€‚</p>

                <details>
                    <summary>è§£ç­”ã‚’è¦‹ã‚‹</summary>
                    <p><strong>æ­£è§£</strong>: 40TB</p>
                    <p><strong>è¨ˆç®—éç¨‹</strong>:</p>
                    <p>RAID 6ã®å®¹é‡å…¬å¼: \(\text{å®¹é‡} = (N - 2) \times D\)</p>
                    <ul>
                        <li>\(N = 12\)ï¼ˆãƒ‡ã‚£ã‚¹ã‚¯æ•°ï¼‰</li>
                        <li>\(D = 4\text{TB}\)ï¼ˆå„ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡ï¼‰</li>
                    </ul>
                    <p>\[
                    \text{å®¹é‡} = (12 - 2) \times 4 = 10 \times 4 = 40\text{TB}
                    \]</p>
                    <p><strong>è£œè¶³</strong>: RAID 6ã¯2å°ã®ãƒ‡ã‚£ã‚¹ã‚¯ãŒãƒ‘ãƒªãƒ†ã‚£æƒ…å ±ã«ä½¿ã‚ã‚Œã‚‹ãŸã‚ã€12å°ä¸­10å°åˆ†ãŒãƒ‡ãƒ¼ã‚¿å®¹é‡ã«ãªã‚Šã¾ã™ã€‚2å°åŒæ™‚æ•…éšœã¾ã§è€ãˆã‚‰ã‚Œã¾ã™ã€‚</p>
                </details>
            </div>

            <h3>Mediumï¼ˆå¿œç”¨ï¼‰<span class="difficulty medium">ä¸­ç´š</span></h3>

            <div class="exercise-box">
                <h4>Q4: Lustreã‚¹ãƒˆãƒ©ã‚¤ãƒ”ãƒ³ã‚°æœ€é©åŒ–</h4>
                <p>100GBã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’Lustreã«æ›¸ãè¾¼ã‚€å ´åˆã€ä»¥ä¸‹ã®æ¡ä»¶ã§æœ€é©ãªã‚¹ãƒˆãƒ©ã‚¤ãƒ—æ•°ã¨ã‚¹ãƒˆãƒ©ã‚¤ãƒ—ã‚µã‚¤ã‚ºã‚’æ±ºå®šã—ã¦ãã ã•ã„ã€‚</p>
                <ul>
                    <li>åˆ©ç”¨å¯èƒ½OSTæ•°: 64å€‹</li>
                    <li>å„OSTã®å¸¯åŸŸå¹…: 500 MB/s</li>
                    <li>ç›®æ¨™æ›¸ãè¾¼ã¿æ™‚é–“: 10ç§’ä»¥å†…</li>
                </ul>

                <details>
                    <summary>è§£ç­”ã‚’è¦‹ã‚‹</summary>
                    <p><strong>æ¨å¥¨è¨­å®š</strong>: ã‚¹ãƒˆãƒ©ã‚¤ãƒ—æ•° = 16-32ã€ã‚¹ãƒˆãƒ©ã‚¤ãƒ—ã‚µã‚¤ã‚º = 4MB</p>

                    <p><strong>è¨ˆç®—æ ¹æ‹ </strong>:</p>
                    <ol>
                        <li><strong>å¿…è¦å¸¯åŸŸå¹…</strong>:
                            <p>\[
                            B_{\text{required}} = \frac{100\text{GB}}{10\text{s}} = 10\text{GB/s}
                            \]</p>
                        </li>
                        <li><strong>ç†è«–çš„ã‚¹ãƒˆãƒ©ã‚¤ãƒ—æ•°</strong>:
                            <p>\[
                            S = \frac{10\text{GB/s}}{0.5\text{GB/s}} = 20
                            \]</p>
                        </li>
                        <li><strong>å®Ÿéš›ã®è¨­å®š</strong>: ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ã‚’è€ƒæ…®ã—ã€16-32ã‚¹ãƒˆãƒ©ã‚¤ãƒ—ã‚’æ¨å¥¨ï¼ˆç†è«–å€¤ã®80-160%ï¼‰</li>
                    </ol>

                    <p><strong>ã‚¹ãƒˆãƒ©ã‚¤ãƒ—ã‚µã‚¤ã‚ºã®é¸æŠ</strong>:</p>
                    <p>å¤§è¦æ¨¡ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ>10GBï¼‰ã«ã¯4MBãŒæœ€é©:</p>
                    <ul>
                        <li>å°ã•ã™ãã‚‹ï¼ˆ1MBï¼‰: ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ“ä½œãŒå¢—åŠ </li>
                        <li>å¤§ãã™ãã‚‹ï¼ˆ16MBï¼‰: å°è¦æ¨¡ã‚¢ã‚¯ã‚»ã‚¹æ™‚ã«éåŠ¹ç‡</li>
                        <li>4MB: ãƒãƒ©ãƒ³ã‚¹ãŒè‰¯ãã€å¤šãã®ãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰ã§é«˜æ€§èƒ½</li>
                    </ul>

                    <p><strong>å®Ÿè£…ã‚³ãƒãƒ³ãƒ‰</strong>:</p>
                    <pre><code class="language-bash">lfs setstripe -c 20 -S 4M /scratch/$USER/large_file.dat</code></pre>
                </details>
            </div>

            <div class="exercise-box">
                <h4>Q5: HDF5ä¸¦åˆ—I/Oå®Ÿè£…</h4>
                <p>16ãƒ—ãƒ­ã‚»ã‚¹ã®MPIãƒ—ãƒ­ã‚°ãƒ©ãƒ ã§ã€å„ãƒ—ãƒ­ã‚»ã‚¹ãŒ1GBã®ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã¾ã™ã€‚ã“ã‚Œã‚’å˜ä¸€ã®HDF5ãƒ•ã‚¡ã‚¤ãƒ«ã«åŠ¹ç‡çš„ã«æ›¸ãè¾¼ã‚€Pythonã‚³ãƒ¼ãƒ‰ã‚’æ›¸ã„ã¦ãã ã•ã„ã€‚</p>

                <details>
                    <summary>è§£ç­”ã‚’è¦‹ã‚‹</summary>
                    <p><strong>è§£ç­”ä¾‹</strong>:</p>
                    <pre><code class="language-python">#!/usr/bin/env python3
from mpi4py import MPI
import h5py
import numpy as np

# MPIè¨­å®š
comm = MPI.COMM_WORLD
rank = comm.Get_rank()
size = comm.Get_size()

# ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆï¼ˆå„ãƒ—ãƒ­ã‚»ã‚¹1GB = 125Mè¦ç´ ã®float64ï¼‰
local_size = 125_000_000  # 125M Ã— 8 bytes = 1GB
local_data = np.random.randn(local_size)

# HDF5ä¸¦åˆ—æ›¸ãè¾¼ã¿
filename = 'parallel_data.h5'
with h5py.File(filename, 'w', driver='mpio', comm=comm) as f:
    # å…¨ä½“ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆ16GBï¼‰
    total_size = size * local_size
    dset = f.create_dataset('data', shape=(total_size,), dtype='float64')

    # å„ãƒ—ãƒ­ã‚»ã‚¹ãŒè‡ªåˆ†ã®æ‹…å½“ç¯„å›²ã«æ›¸ãè¾¼ã¿
    start = rank * local_size
    end = (rank + 1) * local_size
    dset[start:end] = local_data

    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ï¼ˆrank 0ã®ã¿ï¼‰
    if rank == 0:
        dset.attrs['num_processes'] = size
        dset.attrs['total_size_gb'] = total_size * 8 / 1e9

if rank == 0:
    print(f"Parallel write completed: {filename}")
    print(f"Total size: {total_size * 8 / 1e9:.2f} GB")

# SLURMã‚¸ãƒ§ãƒ–ã‚¹ã‚¯ãƒªãƒ—ãƒˆ:
# #!/bin/bash
# #SBATCH -N 4
# #SBATCH --ntasks-per-node=4
# #SBATCH --time=00:10:00
# module load openmpi python/3.9
# mpirun -np 16 python hdf5_parallel.py
</code></pre>

                    <p><strong>æ€§èƒ½è©•ä¾¡</strong>:</p>
                    <ul>
                        <li><strong>é€æ¬¡æ›¸ãè¾¼ã¿</strong>: 16ãƒ—ãƒ­ã‚»ã‚¹ãŒé †ç•ªã«æ›¸ãè¾¼ã¿ â†’ ç´„160ç§’ï¼ˆå„10ç§’ï¼‰</li>
                        <li><strong>ä¸¦åˆ—æ›¸ãè¾¼ã¿</strong>: 16ãƒ—ãƒ­ã‚»ã‚¹ãŒåŒæ™‚ã«æ›¸ãè¾¼ã¿ â†’ ç´„10-15ç§’ï¼ˆ10-15å€é«˜é€Ÿï¼‰</li>
                    </ul>

                    <p><strong>é‡è¦ãƒã‚¤ãƒ³ãƒˆ</strong>:</p>
                    <ol>
                        <li><code>driver='mpio'</code>ã§MPI-IOæœ‰åŠ¹åŒ–</li>
                        <li>å…¨ãƒ—ãƒ­ã‚»ã‚¹ãŒåŒã˜<code>create_dataset</code>ã‚’å‘¼ã¶ï¼ˆé›†å›£æ“ä½œï¼‰</li>
                        <li>å„ãƒ—ãƒ­ã‚»ã‚¹ã¯è‡ªåˆ†ã®ç¯„å›²ã®ã¿æ›¸ãè¾¼ã‚€ï¼ˆä¸¦åˆ—ï¼‰</li>
                    </ol>
                </details>
            </div>

            <div class="exercise-box">
                <h4>Q6: I/Oãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«è§£æ</h4>
                <p>Darshanãƒ¬ãƒãƒ¼ãƒˆã§ä»¥ä¸‹ã®æƒ…å ±ãŒå¾—ã‚‰ã‚Œã¾ã—ãŸã€‚I/Oãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã‚’ç‰¹å®šã—ã€æ”¹å–„ç­–ã‚’ææ¡ˆã—ã¦ãã ã•ã„ã€‚</p>
                <pre><code>Total I/O time: 3600 seconds
Read operations: 1,234,567
Write operations: 123,456
Average read size: 4 KB
Average write size: 128 KB
Metadata operations: 567,890
Lustre stripe count: 1
</code></pre>

                <details>
                    <summary>è§£ç­”ã‚’è¦‹ã‚‹</summary>
                    <p><strong>ãƒœãƒˆãƒ«ãƒãƒƒã‚¯åˆ†æ</strong>:</p>
                    <ol>
                        <li><strong>å°è¦æ¨¡èª­ã¿è¾¼ã¿ãŒå¤šã„</strong>: å¹³å‡4KBã®èª­ã¿è¾¼ã¿ãŒ120ä¸‡å›ä»¥ä¸Š
                            <ul>
                                <li>å•é¡Œ: å°è¦æ¨¡I/Oã¯ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·æ”¯é…ã§éåŠ¹ç‡</li>
                                <li>å½±éŸ¿: I/Oæ™‚é–“ã®å¤§éƒ¨åˆ†ã‚’å ã‚ã‚‹å¯èƒ½æ€§</li>
                            </ul>
                        </li>
                        <li><strong>ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ“ä½œãŒå¤šã„</strong>: 56ä¸‡å›ä»¥ä¸Šã®open/close/stat
                            <ul>
                                <li>å•é¡Œ: ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚µãƒ¼ãƒãƒ¼ï¼ˆMDSï¼‰ãŒãƒœãƒˆãƒ«ãƒãƒƒã‚¯</li>
                                <li>å½±éŸ¿: MDSè² è·ã«ã‚ˆã‚Šå…¨ä½“ãŒé…å»¶</li>
                            </ul>
                        </li>
                        <li><strong>ã‚¹ãƒˆãƒ©ã‚¤ãƒ—æ•°ãŒä¸è¶³</strong>: stripe count = 1ï¼ˆå˜ä¸€OSTï¼‰
                            <ul>
                                <li>å•é¡Œ: ä¸¦åˆ—I/Oã®æ©æµã‚’å—ã‘ã‚‰ã‚Œãªã„</li>
                                <li>å½±éŸ¿: å¸¯åŸŸå¹…ãŒ500 MB/sï¼ˆå˜ä¸€OSTã®ä¸Šé™ï¼‰ã«åˆ¶é™</li>
                            </ul>
                        </li>
                    </ol>

                    <p><strong>æ”¹å–„ç­–</strong>:</p>

                    <p><strong>1. ãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°ã§å°è¦æ¨¡I/Oã‚’é›†ç´„</strong></p>
                    <pre><code class="language-python"># Before: å°è¦æ¨¡èª­ã¿è¾¼ã¿ï¼ˆéåŠ¹ç‡ï¼‰
with open('data.bin', 'rb') as f:
    for i in range(1000000):
        data = f.read(4)  # 4KB Ã— 100ä¸‡å› = 100ä¸‡å›ã®I/O

# After: ãƒãƒƒãƒ•ã‚¡ä»˜ãèª­ã¿è¾¼ã¿ï¼ˆåŠ¹ç‡çš„ï¼‰
with open('data.bin', 'rb', buffering=1024*1024) as f:  # 1MBãƒãƒƒãƒ•ã‚¡
    for i in range(1000000):
        data = f.read(4)  # ãƒãƒƒãƒ•ã‚¡ã‹ã‚‰èª­ã‚€ï¼ˆå®ŸI/Oã¯256å›ï¼‰
</code></pre>

                    <p><strong>2. HDF5/Zarrã§ãƒ•ã‚¡ã‚¤ãƒ«é›†ç´„</strong></p>
                    <pre><code class="language-python"># Before: 56ä¸‡å€‹ã®å°ãƒ•ã‚¡ã‚¤ãƒ«
for i in range(567890):
    with open(f'file_{i}.dat', 'w') as f:
        f.write(data[i])

# After: å˜ä¸€HDF5ãƒ•ã‚¡ã‚¤ãƒ«
with h5py.File('data.h5', 'w') as f:
    f.create_dataset('data', data=data)  # 1å›ã®open/closeã§æ¸ˆã‚€
</code></pre>

                    <p><strong>3. Lustreã‚¹ãƒˆãƒ©ã‚¤ãƒ”ãƒ³ã‚°å¢—åŠ </strong></p>
                    <pre><code class="language-bash">lfs setstripe -c 16 -S 4M /scratch/$USER/output_dir
# ã‚¹ãƒˆãƒ©ã‚¤ãƒ—æ•°ã‚’1 â†’ 16ã«å¢—ã‚„ã—ã€å¸¯åŸŸå¹…ã‚’ç†è«–ä¸Š16å€ã«
</code></pre>

                    <p><strong>æœŸå¾…åŠ¹æœ</strong>:</p>
                    <ul>
                        <li>I/Oæ™‚é–“: 3600ç§’ â†’ ç´„600ç§’ï¼ˆ6å€é«˜é€ŸåŒ–ï¼‰</li>
                        <li>I/Oæ“ä½œæ•°: 123ä¸‡å› â†’ ç´„5000å›ï¼ˆ250å€å‰Šæ¸›ï¼‰</li>
                        <li>å¸¯åŸŸå¹…: 500 MB/s â†’ ç´„4 GB/sï¼ˆ8å€å‘ä¸Šï¼‰</li>
                    </ul>
                </details>
            </div>

            <h3>Hardï¼ˆç™ºå±•ï¼‰<span class="difficulty hard">ä¸Šç´š</span></h3>

            <div class="exercise-box">
                <h4>Q7: é©å¿œçš„ã‚¹ãƒˆãƒ©ã‚¤ãƒ”ãƒ³ã‚°æœ€é©åŒ–</h4>
                <p>ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ã‚¯ã‚»ã‚¹ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å‹•çš„ã«åˆ†æã—ã€æœ€é©ãªLustreã‚¹ãƒˆãƒ©ã‚¤ãƒ”ãƒ³ã‚°è¨­å®šã‚’ææ¡ˆã™ã‚‹Pythonã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’è¨­è¨ˆã—ã¦ãã ã•ã„ã€‚è€ƒæ…®ã™ã¹ãè¦ç´ : ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã€ã‚¢ã‚¯ã‚»ã‚¹é »åº¦ã€èª­ã¿æ›¸ãæ¯”ç‡ã€ä¸¦åˆ—åº¦ã€‚</p>

                <details>
                    <summary>è§£ç­”ã‚’è¦‹ã‚‹</summary>
                    <p><strong>è§£ç­”ä¾‹</strong>:</p>
                    <pre><code class="language-python">#!/usr/bin/env python3
# ===================================
# é©å¿œçš„Lustreã‚¹ãƒˆãƒ©ã‚¤ãƒ”ãƒ³ã‚°æœ€é©åŒ–
# ===================================

import os
import subprocess
import json
from datetime import datetime, timedelta

class LustreOptimizer:
    def __init__(self, path):
        self.path = path
        self.access_log = f"{path}/.access_log.json"
        self.load_access_history()

    def load_access_history(self):
        """éå»ã®ã‚¢ã‚¯ã‚»ã‚¹ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’èª­ã¿è¾¼ã¿"""
        if os.path.exists(self.access_log):
            with open(self.access_log, 'r') as f:
                self.history = json.load(f)
        else:
            self.history = {'reads': 0, 'writes': 0, 'total_bytes': 0}

    def analyze_file(self, filename):
        """ãƒ•ã‚¡ã‚¤ãƒ«ç‰¹æ€§ã‚’åˆ†æ"""
        filepath = os.path.join(self.path, filename)

        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºå–å¾—
        size_bytes = os.path.getsize(filepath)
        size_gb = size_bytes / (1024**3)

        # ç¾åœ¨ã®ã‚¹ãƒˆãƒ©ã‚¤ãƒ”ãƒ³ã‚°æƒ…å ±
        current_stripe = self.get_current_stripe(filepath)

        # ã‚¢ã‚¯ã‚»ã‚¹ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æï¼ˆéå»7æ—¥é–“ï¼‰
        access_pattern = self.analyze_access_pattern(filename, days=7)

        return {
            'size_gb': size_gb,
            'current_stripe': current_stripe,
            'access_pattern': access_pattern
        }

    def get_current_stripe(self, filepath):
        """ç¾åœ¨ã®ã‚¹ãƒˆãƒ©ã‚¤ãƒ—è¨­å®šã‚’å–å¾—"""
        try:
            result = subprocess.run(['lfs', 'getstripe', filepath],
                                    capture_output=True, text=True, check=True)
            lines = result.stdout.split('\n')

            stripe_count = None
            stripe_size = None
            for line in lines:
                if 'stripe_count' in line:
                    stripe_count = int(line.split(':')[1].strip())
                if 'stripe_size' in line:
                    stripe_size = int(line.split(':')[1].strip())

            return {'count': stripe_count, 'size': stripe_size}
        except:
            return {'count': 1, 'size': 1048576}  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 1 stripe, 1MB

    def analyze_access_pattern(self, filename, days=7):
        """ã‚¢ã‚¯ã‚»ã‚¹ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ"""
        # ç°¡æ˜“å®Ÿè£…: å®Ÿéš›ã«ã¯Darshanãƒ­ã‚°ã‚„ã‚·ã‚¹ãƒ†ãƒ ãƒ­ã‚°ã‚’è§£æ
        cutoff_time = datetime.now() - timedelta(days=days)

        # çµ±è¨ˆæƒ…å ±ï¼ˆå®Ÿéš›ã¯ãƒ­ã‚°ã‹ã‚‰å–å¾—ï¼‰
        stats = {
            'read_count': 100,      # èª­ã¿è¾¼ã¿å›æ•°
            'write_count': 10,      # æ›¸ãè¾¼ã¿å›æ•°
            'avg_io_size': 4096,    # å¹³å‡I/Oã‚µã‚¤ã‚ºï¼ˆãƒã‚¤ãƒˆï¼‰
            'parallel_degree': 1,   # ä¸¦åˆ—ã‚¢ã‚¯ã‚»ã‚¹åº¦
            'read_write_ratio': 10  # èª­ã¿æ›¸ãæ¯”ç‡
        }

        return stats

    def recommend_stripe_config(self, file_info):
        """æœ€é©ã‚¹ãƒˆãƒ©ã‚¤ãƒ”ãƒ³ã‚°è¨­å®šã‚’æ¨å¥¨"""
        size_gb = file_info['size_gb']
        pattern = file_info['access_pattern']

        # ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹æœ€é©åŒ–
        recommendations = []

        # ãƒ«ãƒ¼ãƒ«1: ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã«åŸºã¥ã
        if size_gb < 1:
            stripe_count = 1
            stripe_size = 1  # MB
            recommendations.append("Small file: single stripe")
        elif size_gb < 10:
            stripe_count = 4
            stripe_size = 2  # MB
            recommendations.append("Medium file: moderate striping")
        else:
            stripe_count = min(16, int(size_gb / 2))  # 2GB/stripe
            stripe_size = 4  # MB
            recommendations.append("Large file: high striping")

        # ãƒ«ãƒ¼ãƒ«2: ã‚¢ã‚¯ã‚»ã‚¹ãƒ‘ã‚¿ãƒ¼ãƒ³ã«åŸºã¥ãèª¿æ•´
        if pattern['parallel_degree'] > 8:
            stripe_count = max(stripe_count, pattern['parallel_degree'])
            recommendations.append(f"High parallelism: increase to {stripe_count}")

        # ãƒ«ãƒ¼ãƒ«3: I/Oã‚µã‚¤ã‚ºã«åŸºã¥ãèª¿æ•´
        if pattern['avg_io_size'] > 1024*1024:  # > 1MB
            stripe_size = 4  # å¤§è¦æ¨¡I/Oå‘ã‘
            recommendations.append("Large I/O size: 4MB stripe size")
        else:
            stripe_size = 1  # å°è¦æ¨¡I/Oå‘ã‘
            recommendations.append("Small I/O size: 1MB stripe size")

        # ãƒ«ãƒ¼ãƒ«4: èª­ã¿æ›¸ãæ¯”ç‡
        if pattern['read_write_ratio'] > 5:  # èª­ã¿è¾¼ã¿ä¸»ä½“
            # èª­ã¿è¾¼ã¿æœ€é©åŒ–: ã‚¹ãƒˆãƒ©ã‚¤ãƒ—æ•°ã‚’å¢—ã‚„ã™
            stripe_count = min(stripe_count + 4, 32)
            recommendations.append("Read-heavy: optimize for bandwidth")

        return {
            'stripe_count': stripe_count,
            'stripe_size_mb': stripe_size,
            'recommendations': recommendations
        }

    def apply_striping(self, filename, config):
        """ã‚¹ãƒˆãƒ©ã‚¤ãƒ”ãƒ³ã‚°è¨­å®šã‚’é©ç”¨"""
        filepath = os.path.join(self.path, filename)

        # æ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆä¸€æ™‚ï¼‰
        temp_path = f"{filepath}.restripe"

        # æ–°ã—ã„ã‚¹ãƒˆãƒ©ã‚¤ãƒ”ãƒ³ã‚°è¨­å®šã§ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        temp_dir = os.path.dirname(temp_path)
        subprocess.run(['lfs', 'setstripe',
                        '-c', str(config['stripe_count']),
                        '-S', f"{config['stripe_size_mb']}M",
                        temp_dir], check=True)

        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚³ãƒ”ãƒ¼ï¼ˆæ–°ã—ã„ã‚¹ãƒˆãƒ©ã‚¤ãƒ”ãƒ³ã‚°ã§ï¼‰
        subprocess.run(['cp', filepath, temp_path], check=True)

        # å…ƒã®ãƒ•ã‚¡ã‚¤ãƒ«ã¨ç½®ãæ›ãˆ
        subprocess.run(['mv', temp_path, filepath], check=True)

        print(f"Applied striping: count={config['stripe_count']}, size={config['stripe_size_mb']}MB")

    def optimize_directory(self, auto_apply=False):
        """ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå…¨ä½“ã‚’æœ€é©åŒ–"""
        print(f"Analyzing directory: {self.path}")
        print("=" * 60)

        for filename in os.listdir(self.path):
            filepath = os.path.join(self.path, filename)
            if not os.path.isfile(filepath):
                continue

            # ãƒ•ã‚¡ã‚¤ãƒ«åˆ†æ
            file_info = self.analyze_file(filename)

            # æ¨å¥¨è¨­å®šç”Ÿæˆ
            config = self.recommend_stripe_config(file_info)

            # çµæœè¡¨ç¤º
            print(f"\nFile: {filename}")
            print(f"  Size: {file_info['size_gb']:.2f} GB")
            print(f"  Current: count={file_info['current_stripe']['count']}, "
                  f"size={file_info['current_stripe']['size']/1024/1024:.0f}MB")
            print(f"  Recommended: count={config['stripe_count']}, "
                  f"size={config['stripe_size_mb']}MB")
            print(f"  Rationale:")
            for rec in config['recommendations']:
                print(f"    - {rec}")

            # è‡ªå‹•é©ç”¨
            if auto_apply:
                current = file_info['current_stripe']
                if (current['count'] != config['stripe_count'] or
                    current['size'] != config['stripe_size_mb'] * 1024 * 1024):
                    print(f"  Applying new striping...")
                    self.apply_striping(filename, config)

# ä½¿ç”¨ä¾‹
optimizer = LustreOptimizer('/scratch/$USER/active_project')
optimizer.optimize_directory(auto_apply=False)  # ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³ï¼ˆæ¨å¥¨ã®ã¿ï¼‰
# optimizer.optimize_directory(auto_apply=True)  # å®Ÿéš›ã«é©ç”¨
</code></pre>

                    <p><strong>æœ€é©åŒ–æˆ¦ç•¥ã®è©³ç´°</strong>:</p>
                    <ol>
                        <li><strong>ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãƒ™ãƒ¼ã‚¹</strong>: å°(<1GB) â†’ å˜ä¸€stripeã€å¤§(>10GB) â†’ é«˜ä¸¦åˆ—</li>
                        <li><strong>ä¸¦åˆ—åº¦ãƒ™ãƒ¼ã‚¹</strong>: å¤šæ•°ãƒ—ãƒ­ã‚»ã‚¹ãŒåŒæ™‚ã‚¢ã‚¯ã‚»ã‚¹ â†’ stripeæ•°å¢—åŠ </li>
                        <li><strong>I/Oã‚µã‚¤ã‚ºãƒ™ãƒ¼ã‚¹</strong>: å¤§è¦æ¨¡I/O â†’ 4MB stripeã€å°è¦æ¨¡ â†’ 1MB stripe</li>
                        <li><strong>ã‚¢ã‚¯ã‚»ã‚¹ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ™ãƒ¼ã‚¹</strong>: èª­ã¿è¾¼ã¿ä¸»ä½“ â†’ å¸¯åŸŸå¹…é‡è¦–ã§ stripeå¢—åŠ </li>
                    </ol>
                </details>
            </div>

            <div class="exercise-box">
                <h4>Q8: ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸éšå±¤è‡ªå‹•ç®¡ç†</h4>
                <p>ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ã‚¯ã‚»ã‚¹é »åº¦ã¨çµŒéæ™‚é–“ã«åŸºã¥ã„ã¦ã€Hot â†’ Warm â†’ Coldã®ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸éšå±¤é–“ã§ãƒ‡ãƒ¼ã‚¿ã‚’è‡ªå‹•ç§»è¡Œã™ã‚‹ãƒãƒªã‚·ãƒ¼ã‚¨ãƒ³ã‚¸ãƒ³ã‚’è¨­è¨ˆã—ã¦ãã ã•ã„ã€‚</p>

                <details>
                    <summary>è§£ç­”ã‚’è¦‹ã‚‹</summary>
                    <p><strong>è§£ç­”ä¾‹</strong>:</p>
                    <pre><code class="language-python">#!/usr/bin/env python3
# ===================================
# ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸éšå±¤è‡ªå‹•ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ 
# ===================================

import os
import shutil
import subprocess
import json
from datetime import datetime, timedelta

class TierManager:
    def __init__(self, config_file='tier_config.json'):
        self.load_config(config_file)
        self.access_db = 'access_history.json'
        self.load_access_history()

    def load_config(self, config_file):
        """ãƒãƒªã‚·ãƒ¼è¨­å®šã‚’èª­ã¿è¾¼ã¿"""
        with open(config_file, 'r') as f:
            self.config = json.load(f)

        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šä¾‹
        if not self.config:
            self.config = {
                'tiers': {
                    'hot': {
                        'path': '/scratch/hot',
                        'max_age_days': 7,
                        'min_access_count': 10
                    },
                    'warm': {
                        'path': '/work/warm',
                        'max_age_days': 90,
                        'min_access_count': 1
                    },
                    'cold': {
                        'path': '/archive/cold',
                        'max_age_days': None,  # ç„¡æœŸé™
                        'min_access_count': 0
                    }
                },
                'migration_rules': [
                    {
                        'from': 'hot',
                        'to': 'warm',
                        'condition': 'age > 7 days OR access_count < 10'
                    },
                    {
                        'from': 'warm',
                        'to': 'cold',
                        'condition': 'age > 90 days AND access_count == 0'
                    }
                ]
            }

    def load_access_history(self):
        """ã‚¢ã‚¯ã‚»ã‚¹å±¥æ­´ã‚’ãƒ­ãƒ¼ãƒ‰"""
        if os.path.exists(self.access_db):
            with open(self.access_db, 'r') as f:
                self.access_history = json.load(f)
        else:
            self.access_history = {}

    def save_access_history(self):
        """ã‚¢ã‚¯ã‚»ã‚¹å±¥æ­´ã‚’ä¿å­˜"""
        with open(self.access_db, 'w') as f:
            json.dump(self.access_history, f, indent=2)

    def track_access(self, filepath, access_type='read'):
        """ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ã‚¯ã‚»ã‚¹ã‚’è¨˜éŒ²"""
        if filepath not in self.access_history:
            self.access_history[filepath] = {
                'created': datetime.now().isoformat(),
                'last_access': datetime.now().isoformat(),
                'access_count': 0,
                'current_tier': self.get_tier_from_path(filepath)
            }

        self.access_history[filepath]['last_access'] = datetime.now().isoformat()
        self.access_history[filepath]['access_count'] += 1
        self.save_access_history()

    def get_tier_from_path(self, filepath):
        """ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‹ã‚‰ç¾åœ¨ã®éšå±¤ã‚’åˆ¤å®š"""
        for tier, tier_config in self.config['tiers'].items():
            if filepath.startswith(tier_config['path']):
                return tier
        return 'unknown'

    def should_migrate(self, filepath):
        """ç§»è¡ŒãŒå¿…è¦ã‹ãƒã‚§ãƒƒã‚¯"""
        if filepath not in self.access_history:
            return None

        info = self.access_history[filepath]
        current_tier = info['current_tier']

        # ä½œæˆã‹ã‚‰ã®çµŒéæ—¥æ•°
        created = datetime.fromisoformat(info['created'])
        age_days = (datetime.now() - created).days

        # æœ€çµ‚ã‚¢ã‚¯ã‚»ã‚¹ã‹ã‚‰ã®çµŒéæ—¥æ•°
        last_access = datetime.fromisoformat(info['last_access'])
        idle_days = (datetime.now() - last_access).days

        # ç§»è¡Œãƒ«ãƒ¼ãƒ«è©•ä¾¡
        for rule in self.config['migration_rules']:
            if rule['from'] != current_tier:
                continue

            # ãƒ«ãƒ¼ãƒ«æ¡ä»¶ã‚’è©•ä¾¡
            migrate = False

            if current_tier == 'hot':
                # Hot â†’ Warm: 7æ—¥çµŒé OR ã‚¢ã‚¯ã‚»ã‚¹å°‘ãªã„
                if age_days > 7 or info['access_count'] < 10:
                    migrate = True

            elif current_tier == 'warm':
                # Warm â†’ Cold: 90æ—¥çµŒé AND æœ€è¿‘ã‚¢ã‚¯ã‚»ã‚¹ãªã—
                if age_days > 90 and idle_days > 30:
                    migrate = True

            if migrate:
                return rule['to']

        return None

    def migrate_file(self, filepath, target_tier):
        """ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æŒ‡å®šéšå±¤ã«ç§»è¡Œ"""
        source_path = filepath
        target_base = self.config['tiers'][target_tier]['path']

        # ç›¸å¯¾ãƒ‘ã‚¹ä¿æŒ
        current_tier = self.get_tier_from_path(filepath)
        current_base = self.config['tiers'][current_tier]['path']
        relative_path = os.path.relpath(filepath, current_base)

        target_path = os.path.join(target_base, relative_path)
        target_dir = os.path.dirname(target_path)

        # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        os.makedirs(target_dir, exist_ok=True)

        # ãƒ•ã‚¡ã‚¤ãƒ«ç§»è¡Œï¼ˆrsyncã§å®‰å…¨ã«ã‚³ãƒ”ãƒ¼ï¼‰
        print(f"Migrating: {source_path} â†’ {target_path}")
        subprocess.run(['rsync', '-av', '--remove-source-files',
                        source_path, target_path], check=True)

        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ›´æ–°
        self.access_history[filepath]['current_tier'] = target_tier
        self.access_history[filepath]['migrated'] = datetime.now().isoformat()

        # ã‚·ãƒ³ãƒœãƒªãƒƒã‚¯ãƒªãƒ³ã‚¯ä½œæˆï¼ˆé€éçš„ã‚¢ã‚¯ã‚»ã‚¹ï¼‰
        if os.path.exists(source_path):
            os.remove(source_path)
        os.symlink(target_path, source_path)

        print(f"Migration completed. Symlink created at {source_path}")
        self.save_access_history()

    def run_policy_engine(self, dry_run=True):
        """ãƒãƒªã‚·ãƒ¼ã‚¨ãƒ³ã‚¸ãƒ³å®Ÿè¡Œ"""
        print("=" * 60)
        print(f"Storage Tier Management - {datetime.now()}")
        print(f"Mode: {'Dry Run' if dry_run else 'Live Migration'}")
        print("=" * 60)

        migration_plan = []

        # å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¹ã‚­ãƒ£ãƒ³
        for tier, tier_config in self.config['tiers'].items():
            tier_path = tier_config['path']
            if not os.path.exists(tier_path):
                continue

            for root, dirs, files in os.walk(tier_path):
                for filename in files:
                    filepath = os.path.join(root, filename)

                    # ç§»è¡Œåˆ¤å®š
                    target_tier = self.should_migrate(filepath)
                    if target_tier:
                        file_size = os.path.getsize(filepath) / (1024**3)  # GB
                        migration_plan.append({
                            'source': filepath,
                            'target_tier': target_tier,
                            'size_gb': file_size,
                            'reason': f"Policy: {tier} â†’ {target_tier}"
                        })

        # ç§»è¡Œè¨ˆç”»ã‚µãƒãƒªãƒ¼
        print(f"\nMigration Plan: {len(migration_plan)} files")
        total_size = sum(item['size_gb'] for item in migration_plan)
        print(f"Total size: {total_size:.2f} GB\n")

        for item in migration_plan[:10]:  # æœ€åˆã®10ä»¶è¡¨ç¤º
            print(f"  {item['source']}")
            print(f"    â†’ {item['target_tier']} ({item['size_gb']:.2f} GB)")
            print(f"    Reason: {item['reason']}\n")

        if len(migration_plan) > 10:
            print(f"  ... and {len(migration_plan) - 10} more files\n")

        # å®Ÿéš›ã®ç§»è¡Œå®Ÿè¡Œ
        if not dry_run:
            for item in migration_plan:
                self.migrate_file(item['source'], item['target_tier'])
        else:
            print("Dry run completed. Use run_policy_engine(dry_run=False) to apply.")

# è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä¾‹ï¼ˆtier_config.jsonï¼‰
config_example = {
    "tiers": {
        "hot": {"path": "/scratch/hot", "max_age_days": 7, "min_access_count": 10},
        "warm": {"path": "/work/warm", "max_age_days": 90, "min_access_count": 1},
        "cold": {"path": "/archive/cold", "max_age_days": None, "min_access_count": 0}
    },
    "migration_rules": [
        {"from": "hot", "to": "warm", "condition": "age > 7 OR access < 10"},
        {"from": "warm", "to": "cold", "condition": "age > 90 AND idle > 30"}
    ]
}

# ä½¿ç”¨ä¾‹
manager = TierManager('tier_config.json')
manager.run_policy_engine(dry_run=True)  # ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³

# cronã§å®šæœŸå®Ÿè¡Œï¼ˆæ¯é€±æ—¥æ›œåˆå‰2æ™‚ï¼‰
# 0 2 * * 0 python3 /path/to/tier_manager.py
</code></pre>

                    <p><strong>ãƒãƒªã‚·ãƒ¼ã®è©³ç´°</strong>:</p>
                    <table>
                        <thead>
                            <tr>
                                <th>ç§»è¡Œãƒ‘ã‚¹</th>
                                <th>æ¡ä»¶</th>
                                <th>ç†ç”±</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>Hot â†’ Warm</td>
                                <td>ä½œæˆã‹ã‚‰7æ—¥çµŒé OR ã‚¢ã‚¯ã‚»ã‚¹<10å›</td>
                                <td>ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã§ãªã„ãƒ‡ãƒ¼ã‚¿ã‚’ã‚³ã‚¹ãƒˆä½ã„ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã¸</td>
                            </tr>
                            <tr>
                                <td>Warm â†’ Cold</td>
                                <td>ä½œæˆã‹ã‚‰90æ—¥çµŒé AND 30æ—¥é–“ã‚¢ã‚¯ã‚»ã‚¹ãªã—</td>
                                <td>é•·æœŸä¿å­˜ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ†ãƒ¼ãƒ—ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã¸</td>
                            </tr>
                            <tr>
                                <td>Cold â†’ Warm</td>
                                <td>ã‚¢ã‚¯ã‚»ã‚¹è¦æ±‚ç™ºç”Ÿ</td>
                                <td>å¿…è¦æ™‚ã«è‡ªå‹•çš„ã«ãƒªã‚¹ãƒˆã‚¢ï¼ˆã‚ªãƒ³ãƒ‡ãƒãƒ³ãƒ‰ï¼‰</td>
                            </tr>
                        </tbody>
                    </table>

                    <p><strong>æœŸå¾…åŠ¹æœ</strong>:</p>
                    <ul>
                        <li>Hotã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ä½¿ç”¨é‡: 80% â†’ 40%å‰Šæ¸›</li>
                        <li>ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚³ã‚¹ãƒˆ: å¹´é–“$100K â†’ $40Kï¼ˆ60%å‰Šæ¸›ï¼‰</li>
                        <li>è‡ªå‹•åŒ–ã«ã‚ˆã‚Šç®¡ç†è€…ã®æ‰‹é–“ãŒ90%å‰Šæ¸›</li>
                    </ul>
                </details>
            </div>
        </section>

        <section id="references">
            <h2>å‚è€ƒæ–‡çŒ®</h2>

            <ol>
                <li>
                    <strong>Lustre Project</strong>. (2023). <em>Lustre Operations Manual</em>. OpenSFS.
                    <a href="https://doc.lustre.org/" target="_blank">https://doc.lustre.org/</a>
                    (ç‰¹ã«ã‚¹ãƒˆãƒ©ã‚¤ãƒ”ãƒ³ã‚°è¨­å®š pp. 50-120ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚° pp. 200-280)
                </li>
                <li>
                    The HDF Group. (2023). <em>HDF5 User's Guide</em>.
                    <a href="https://docs.hdfgroup.org/hdf5/latest/" target="_blank">https://docs.hdfgroup.org/</a>
                    (ä¸¦åˆ—I/O pp. 100-180ã€ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°ã¨ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ pp. 250-320)
                </li>
                <li>
                    Collette, A. (2013). <em>Python and HDF5</em>. O'Reilly Media.
                    (h5pyåŸºç¤ pp. 80-145ã€ä¸¦åˆ—I/O pp. 180-230)
                </li>
                <li>
                    Ross, R., Thakur, R., et al. (2009). "Parallel I/O in Practice."
                    <em>Proceedings of SC09</em>, pp. 1-12.
                    DOI: 10.1145/1654059.1654070
                </li>
                <li>
                    Brandt, S., et al. (2020). <em>BeeGFS: The Parallel File System</em>. BeeGFS Whitepaper.
                    <a href="https://www.beegfs.io/docs/" target="_blank">https://www.beegfs.io/docs/</a>
                    (ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ pp. 5-45)
                </li>
                <li>
                    Lockwood, G., et al. (2017). "Understanding Darshan: Characterizing I/O Behavior of HPC Applications."
                    <em>Proceedings of Cray User Group</em>, pp. 1-15.
                    <a href="https://www.mcs.anl.gov/research/projects/darshan/" target="_blank">https://www.mcs.anl.gov/research/projects/darshan/</a>
                </li>
                <li>
                    Liu, Y., et al. (2016). <em>Best Practices for HPC I/O</em>. NERSC Documentation.
                    <a href="https://docs.nersc.gov/performance/io/" target="_blank">https://docs.nersc.gov/performance/io/</a>
                    (I/Oæœ€é©åŒ–æˆ¦ç•¥ pp. 20-75)
                </li>
            </ol>
        </section>

        <section id="next-steps">
            <h2>æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—</h2>

            <p>
                æœ¬ç« ã§ã¯ã€HPCã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã€ä¸¦åˆ—ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ã€I/Oæœ€é©åŒ–æ‰‹æ³•ã‚’å­¦ã³ã¾ã—ãŸã€‚æ¬¡ç« ã§ã¯ã€<strong>æ€§èƒ½ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ã¨ãƒ‡ãƒãƒƒã‚°æŠ€æ³•</strong>ã‚’å­¦ã³ã€ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã®ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã‚’ç‰¹å®šãƒ»è§£æ±ºã™ã‚‹æ–¹æ³•ã‚’ç¿’å¾—ã—ã¾ã™ã€‚
            </p>

            <div class="info-box">
                <strong>ç¬¬5ç« ã®äºˆç¿’</strong>
                <p>æ¬¡ç« ã§ã¯ã€æ€§èƒ½ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ãƒ„ãƒ¼ãƒ«ï¼ˆgprofã€Valgrindã€Intel VTuneï¼‰ã¨ãƒ‡ãƒãƒƒã‚°æŠ€è¡“ã‚’å®Ÿè·µã—ã¾ã™ã€‚ä»¥ä¸‹ã‚’äº‹å‰ã«æº–å‚™ã—ã¦ãŠãã¨ã‚¹ãƒ ãƒ¼ã‚ºã§ã™ï¼š</p>
                <ul>
                    <li>C/Pythonãƒ—ãƒ­ã‚°ãƒ©ãƒ ã®ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã¨ãƒ‡ãƒãƒƒã‚°çµŒé¨“</li>
                    <li>ç¬¬2ç« ã®ä¸¦åˆ—è¨ˆç®—æŠ€è¡“ã®å¾©ç¿’</li>
                    <li>HPCã‚¯ãƒ©ã‚¹ã‚¿ä¸Šã§ã®ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ãƒ„ãƒ¼ãƒ«ã®ç¢ºèªï¼ˆ<code>module avail</code>ï¼‰</li>
                </ul>
            </div>

            <div style="text-align: center; margin: 2rem 0;">
                <a href="index.html" style="margin-right: 1rem; padding: 0.75rem 1.5rem; background: #34495e; color: white; border-radius: 4px; text-decoration: none;">â† ã‚·ãƒªãƒ¼ã‚ºãƒˆãƒƒãƒ—</a>
                <a href="chapter-5.html" style="padding: 0.75rem 1.5rem; background: linear-gradient(135deg, #11998e 0%, #38ef7d 100%); color: white; border-radius: 4px; text-decoration: none;">ç¬¬5ç« ã¸é€²ã‚€ â†’</a>
            </div>
        </section>
    </main>

    <footer>
        <p><strong>CT Dojo - è¨ˆç®—å·¥å­¦é“å ´</strong></p>
        <p>HPCã‚¯ãƒ©ã‚¹ã‚¿å…¥é–€ã‚·ãƒªãƒ¼ã‚º ç¬¬4ç« </p>
        <p><a href="https://github.com/your-repo" target="_blank">GitHub</a> | <a href="mailto:contact@example.com">ãŠå•ã„åˆã‚ã›</a></p>
        <p>&copy; 2025 CT Knowledge Hub. Licensed under CC BY 4.0.</p>
    </footer>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-bash.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
    <script>
        mermaid.initialize({ startOnLoad: true, theme: 'default', securityLevel: 'strict' });
    </script>
</body>
</html>
