<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ç¬¬1ç« ï¼šãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°åŸºç¤ - AI Terakoya</title>

    <style>
        :root {
            --color-primary: #2c3e50;
            --color-primary-dark: #1a252f;
            --color-accent: #7b2cbf;
            --color-accent-light: #9d4edd;
            --color-text: #2d3748;
            --color-text-light: #4a5568;
            --color-bg: #ffffff;
            --color-bg-alt: #f7fafc;
            --color-border: #e2e8f0;
            --color-code-bg: #f8f9fa;
            --color-link: #3182ce;
            --color-link-hover: #2c5aa0;

            --spacing-xs: 0.5rem;
            --spacing-sm: 1rem;
            --spacing-md: 1.5rem;
            --spacing-lg: 2rem;
            --spacing-xl: 3rem;

            --font-body: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            --font-mono: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;

            --border-radius: 8px;
            --box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: var(--font-body);
            line-height: 1.7;
            color: var(--color-text);
            background-color: var(--color-bg);
            font-size: 16px;
        }

        header {
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            padding: var(--spacing-xl) var(--spacing-md);
            margin-bottom: var(--spacing-xl);
            box-shadow: var(--box-shadow);
        }

        .header-content {
            max-width: 900px;
            margin: 0 auto;
        }

        h1 {
            font-size: 2rem;
            font-weight: 700;
            margin-bottom: var(--spacing-sm);
            line-height: 1.2;
        }

        .subtitle {
            font-size: 1.1rem;
            opacity: 0.95;
            font-weight: 400;
            margin-bottom: var(--spacing-md);
        }

        .meta {
            display: flex;
            flex-wrap: wrap;
            gap: var(--spacing-md);
            font-size: 0.9rem;
            opacity: 0.9;
        }

        .meta-item {
            display: flex;
            align-items: center;
            gap: 0.3rem;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 0 var(--spacing-md) var(--spacing-xl);
        }

        h2 {
            font-size: 1.75rem;
            color: var(--color-primary);
            margin-top: var(--spacing-xl);
            margin-bottom: var(--spacing-md);
            padding-bottom: var(--spacing-xs);
            border-bottom: 3px solid var(--color-accent);
        }

        h3 {
            font-size: 1.4rem;
            color: var(--color-primary);
            margin-top: var(--spacing-lg);
            margin-bottom: var(--spacing-sm);
        }

        h4 {
            font-size: 1.1rem;
            color: var(--color-primary-dark);
            margin-top: var(--spacing-md);
            margin-bottom: var(--spacing-sm);
        }

        p {
            margin-bottom: var(--spacing-md);
            color: var(--color-text);
        }

        a {
            color: var(--color-link);
            text-decoration: none;
            transition: color 0.2s;
        }

        a:hover {
            color: var(--color-link-hover);
            text-decoration: underline;
        }

        ul, ol {
            margin-left: var(--spacing-lg);
            margin-bottom: var(--spacing-md);
        }

        li {
            margin-bottom: var(--spacing-xs);
            color: var(--color-text);
        }

        pre {
            background-color: var(--color-code-bg);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            overflow-x: auto;
            margin-bottom: var(--spacing-md);
            font-family: var(--font-mono);
            font-size: 0.9rem;
            line-height: 1.5;
        }

        code {
            font-family: var(--font-mono);
            font-size: 0.9em;
            background-color: var(--color-code-bg);
            padding: 0.2em 0.4em;
            border-radius: 3px;
        }

        pre code {
            background-color: transparent;
            padding: 0;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: var(--spacing-md);
            font-size: 0.95rem;
        }

        th, td {
            border: 1px solid var(--color-border);
            padding: var(--spacing-sm);
            text-align: left;
        }

        th {
            background-color: var(--color-bg-alt);
            font-weight: 600;
            color: var(--color-primary);
        }

        blockquote {
            border-left: 4px solid var(--color-accent);
            padding-left: var(--spacing-md);
            margin: var(--spacing-md) 0;
            color: var(--color-text-light);
            font-style: italic;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        .mermaid {
            text-align: center;
            margin: var(--spacing-lg) 0;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        details {
            background-color: var(--color-bg-alt);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            margin-bottom: var(--spacing-md);
        }

        summary {
            cursor: pointer;
            font-weight: 600;
            color: var(--color-primary);
            user-select: none;
            padding: var(--spacing-xs);
            margin: calc(-1 * var(--spacing-md));
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        summary:hover {
            background-color: rgba(123, 44, 191, 0.1);
        }

        details[open] summary {
            margin-bottom: var(--spacing-md);
            border-bottom: 1px solid var(--color-border);
        }

        .navigation {
            display: flex;
            justify-content: space-between;
            gap: var(--spacing-md);
            margin: var(--spacing-xl) 0;
            padding-top: var(--spacing-lg);
            border-top: 2px solid var(--color-border);
        }

        .nav-button {
            flex: 1;
            padding: var(--spacing-md);
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            border-radius: var(--border-radius);
            text-align: center;
            font-weight: 600;
            transition: transform 0.2s, box-shadow 0.2s;
            box-shadow: var(--box-shadow);
        }

        .nav-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
            text-decoration: none;
        }

        footer {
            margin-top: var(--spacing-xl);
            padding: var(--spacing-lg) var(--spacing-md);
            background-color: var(--color-bg-alt);
            border-top: 1px solid var(--color-border);
            text-align: center;
            font-size: 0.9rem;
            color: var(--color-text-light);
        }
        .disclaimer {
            max-width: 900px;
            margin: 2rem auto;
            padding: 1.5rem;
            background: #f8f9fa;
            border-left: 4px solid #6c757d;
            border-radius: 4px;
        }

        .disclaimer h3 {
            color: #495057;
            margin-bottom: 1rem;
            font-size: 1.1rem;
        }

        .disclaimer ul {
            list-style: none;
            padding-left: 0;
        }

        .disclaimer li {
            padding: 0.5rem 0;
            padding-left: 1.5rem;
            position: relative;
            font-size: 0.9rem;
            color: #6c757d;
            line-height: 1.6;
        }

        .disclaimer li::before {
            content: "âš ï¸";
            position: absolute;
            left: 0;
        }


        @media (max-width: 768px) {
            h1 {
                font-size: 1.5rem;
            }

            h2 {
                font-size: 1.4rem;
            }

            h3 {
                font-size: 1.2rem;
            }

            .meta {
                font-size: 0.85rem;
            }

            .navigation {
                flex-direction: column;
            }

            table {
                font-size: 0.85rem;
            }

            th, td {
                padding: var(--spacing-xs);
            }
        }
    
        /* Breadcrumb styles */
        .breadcrumb {
            background: #f7fafc;
            padding: 0.75rem 1rem;
            border-bottom: 1px solid #e2e8f0;
            font-size: 0.9rem;
        }

        .breadcrumb-content {
            max-width: 900px;
            margin: 0 auto;
            display: flex;
            align-items: center;
            flex-wrap: wrap;
            gap: 0.5rem;
        }

        .breadcrumb a {
            color: #667eea;
            text-decoration: none;
            transition: color 0.2s;
        }

        .breadcrumb a:hover {
            color: #764ba2;
            text-decoration: underline;
        }

        .breadcrumb-separator {
            color: #a0aec0;
            margin: 0 0.25rem;
        }

        .breadcrumb-current {
            color: #4a5568;
            font-weight: 500;
        }
    </style>

    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
        mermaid.initialize({ startOnLoad: true, theme: 'default' });
    </script>

    <!-- MathJax for LaTeX equation rendering -->
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                displayMath: [['$$', '$$'], ['\\[', '\\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
                ignoreHtmlClass: 'mermaid'
            }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" async></script>
</head>
<body>
        <nav class="breadcrumb">
        <div class="breadcrumb-content">
            <a href="/wp/knowledge/jp/index.html">AIå¯ºå­å±‹ãƒˆãƒƒãƒ—</a><span class="breadcrumb-separator">â€º</span><a href="/wp/knowledge/jp/ML/index.html">æ©Ÿæ¢°å­¦ç¿’</a><span class="breadcrumb-separator">â€º</span><a href="/wp/knowledge/jp/ML/hyperparameter-tuning-introduction/index.html">Hyperparameter Tuning</a><span class="breadcrumb-separator">â€º</span><span class="breadcrumb-current">Chapter 1</span>
        </div>
    </nav>

    <header>
        <div class="header-content">
            <h1>ç¬¬1ç« ï¼šãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°åŸºç¤</h1>
            <p class="subtitle">ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ã‚’æœ€å¤§åŒ–ã™ã‚‹æ¢ç´¢æ‰‹æ³•ã®åŸºæœ¬</p>
            <div class="meta">
                <span class="meta-item">ğŸ“– èª­äº†æ™‚é–“: 25-30åˆ†</span>
                <span class="meta-item">ğŸ“Š é›£æ˜“åº¦: åˆç´š</span>
                <span class="meta-item">ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹: 8å€‹</span>
                <span class="meta-item">ğŸ“ æ¼”ç¿’å•é¡Œ: 5å•</span>
            </div>
        </div>
    </header>

    <main class="container">

<h2>å­¦ç¿’ç›®æ¨™</h2>
<p>ã“ã®ç« ã‚’èª­ã‚€ã“ã¨ã§ã€ä»¥ä¸‹ã‚’ç¿’å¾—ã§ãã¾ã™ï¼š</p>
<ul>
<li>âœ… ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®é•ã„ã‚’ç†è§£ã™ã‚‹</li>
<li>âœ… ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã®é‡è¦æ€§ã¨æ¢ç´¢ç©ºé–“ã®è¨­è¨ˆã‚’å­¦ã¶</li>
<li>âœ… ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒã®ä»•çµ„ã¿ã¨å®Ÿè£…æ–¹æ³•ã‚’ç¿’å¾—ã™ã‚‹</li>
<li>âœ… ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ¼ãƒã®åˆ©ç‚¹ã¨ä½¿ã„æ–¹ã‚’ç†è§£ã™ã‚‹</li>
<li>âœ… äº¤å·®æ¤œè¨¼ã¨ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¢ç´¢ã‚’çµ„ã¿åˆã‚ã›ã‚‹</li>
<li>âœ… scikit-learnã§å®Ÿè·µçš„ãªãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å®Ÿè¡Œã§ãã‚‹</li>
</ul>

<hr>

<h2>1.1 ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨ã¯</h2>

<h3>ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨ã®é•ã„</h3>
<p><strong>ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆHyperparameterï¼‰</strong>ã¯ã€å­¦ç¿’å‰ã«äººé–“ãŒè¨­å®šã™ã‚‹å€¤ã§ã€ãƒ¢ãƒ‡ãƒ«ã®æ§‹é€ ã‚„å­¦ç¿’ãƒ—ãƒ­ã‚»ã‚¹ã‚’åˆ¶å¾¡ã—ã¾ã™ã€‚</p>

<table>
<thead>
<tr>
<th>ç¨®é¡</th>
<th>å®šç¾©</th>
<th>ä¾‹</th>
<th>æ±ºå®šæ–¹æ³•</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿</strong></td>
<td>å­¦ç¿’ã«ã‚ˆã‚Šè‡ªå‹•çš„ã«æœ€é©åŒ–</td>
<td>ç·šå½¢å›å¸°ã®ä¿‚æ•°ã€ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆã®é‡ã¿</td>
<td>è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å­¦ç¿’</td>
</tr>
<tr>
<td><strong>ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿</strong></td>
<td>å­¦ç¿’å‰ã«äººé–“ãŒè¨­å®š</td>
<td>å­¦ç¿’ç‡ã€æœ¨ã®æ·±ã•ã€æ­£å‰‡åŒ–ä¿‚æ•°</td>
<td>è©¦è¡ŒéŒ¯èª¤ã€æ¢ç´¢ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ </td>
</tr>
</tbody>
</table>

<h3>ä¸»è¦ãªãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿</h3>

<table>
<thead>
<tr>
<th>ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ </th>
<th>ä¸»è¦ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿</th>
<th>å½¹å‰²</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Random Forest</strong></td>
<td>n_estimators, max_depth, min_samples_split</td>
<td>æœ¨ã®æ•°ã€æ·±ã•ã€åˆ†å‰²æ¡ä»¶</td>
</tr>
<tr>
<td><strong>XGBoost</strong></td>
<td>learning_rate, max_depth, n_estimators, subsample</td>
<td>å­¦ç¿’é€Ÿåº¦ã€è¤‡é›‘åº¦ã€ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°</td>
</tr>
<tr>
<td><strong>SVM</strong></td>
<td>C, kernel, gamma</td>
<td>æ­£å‰‡åŒ–ã€ã‚«ãƒ¼ãƒãƒ«ã€å½±éŸ¿ç¯„å›²</td>
</tr>
<tr>
<td><strong>ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆ</strong></td>
<td>learning_rate, batch_size, hidden_layers</td>
<td>å­¦ç¿’é€Ÿåº¦ã€ãƒãƒƒãƒã€æ§‹é€ </td>
</tr>
</tbody>
</table>

<h3>ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã®é‡è¦æ€§</h3>

<blockquote>
<p>é©åˆ‡ãªãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®šã«ã‚ˆã‚Šã€ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã¯10-30%ä»¥ä¸Šæ”¹å–„ã™ã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚</p>
</blockquote>

<div class="mermaid">
graph LR
    A[ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š] --> B[ç²¾åº¦: 75%]
    C[ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å¾Œ] --> D[ç²¾åº¦: 88%]

    style A fill:#ffebee
    style B fill:#ffcdd2
    style C fill:#e8f5e9
    style D fill:#a5d6a7
</div>

<h3>æ¢ç´¢ç©ºé–“ã®è¨­è¨ˆ</h3>

<p>æ¢ç´¢ç©ºé–“ã¯ã€å„ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å€™è£œå€¤ã®ç¯„å›²ã§ã™ã€‚é©åˆ‡ãªè¨­è¨ˆãŒé‡è¦ã§ã™ã€‚</p>

<pre><code class="language-python">import numpy as np
from sklearn.ensemble import RandomForestClassifier

# æ¢ç´¢ç©ºé–“ã®å®šç¾©ä¾‹
param_space = {
    'n_estimators': [50, 100, 200, 300],           # æœ¨ã®æ•°
    'max_depth': [5, 10, 15, 20, None],            # æœ€å¤§æ·±ã•
    'min_samples_split': [2, 5, 10],               # åˆ†å‰²ã«å¿…è¦ãªæœ€å°ã‚µãƒ³ãƒ—ãƒ«æ•°
    'min_samples_leaf': [1, 2, 4],                 # è‘‰ã«å¿…è¦ãªæœ€å°ã‚µãƒ³ãƒ—ãƒ«æ•°
    'max_features': ['sqrt', 'log2', None]         # åˆ†å‰²æ™‚ã®ç‰¹å¾´é‡æ•°
}

print("=== æ¢ç´¢ç©ºé–“ã®æ¦‚è¦ ===")
print(f"n_estimators: {len(param_space['n_estimators'])}é€šã‚Š")
print(f"max_depth: {len(param_space['max_depth'])}é€šã‚Š")
print(f"min_samples_split: {len(param_space['min_samples_split'])}é€šã‚Š")
print(f"min_samples_leaf: {len(param_space['min_samples_leaf'])}é€šã‚Š")
print(f"max_features: {len(param_space['max_features'])}é€šã‚Š")

total_combinations = np.prod([len(v) for v in param_space.values()])
print(f"\nç·çµ„ã¿åˆã‚ã›æ•°: {total_combinations:,}")
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>=== æ¢ç´¢ç©ºé–“ã®æ¦‚è¦ ===
n_estimators: 4é€šã‚Š
max_depth: 5é€šã‚Š
min_samples_split: 3é€šã‚Š
min_samples_leaf: 3é€šã‚Š
max_features: 3é€šã‚Š

ç·çµ„ã¿åˆã‚ã›æ•°: 540
</code></pre>

<blockquote>
<p><strong>é‡è¦</strong>: æ¢ç´¢ç©ºé–“ãŒåºƒã™ãã‚‹ã¨è¨ˆç®—ã‚³ã‚¹ãƒˆãŒè†¨å¤§ã«ãªã‚Šã¾ã™ã€‚ãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜ã¨çµŒé¨“çš„ãªç¯„å›²ã‚’æ´»ç”¨ã—ã¾ã—ã‚‡ã†ã€‚</p>
</blockquote>

<hr>

<h2>1.2 ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒ</h2>

<h3>ä»•çµ„ã¿ã¨å®Ÿè£…</h3>

<p><strong>ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒï¼ˆGrid Searchï¼‰</strong>ã¯ã€æŒ‡å®šã—ãŸã™ã¹ã¦ã®ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®çµ„ã¿åˆã‚ã›ã‚’ç¶²ç¾…çš„ã«æ¢ç´¢ã—ã¾ã™ã€‚</p>

<div class="mermaid">
graph TD
    A[æ¢ç´¢ç©ºé–“å®šç¾©] --> B[ã™ã¹ã¦ã®çµ„ã¿åˆã‚ã›ç”Ÿæˆ]
    B --> C[å„çµ„ã¿åˆã‚ã›ã§å­¦ç¿’]
    C --> D[äº¤å·®æ¤œè¨¼ã§è©•ä¾¡]
    D --> E[æœ€è‰¯ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿é¸æŠ]

    style A fill:#e3f2fd
    style B fill:#bbdefb
    style C fill:#90caf9
    style D fill:#64b5f6
    style E fill:#42a5f5
</div>

<h3>scikit-learn GridSearchCV</h3>

<pre><code class="language-python">from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report
import time

# ãƒ‡ãƒ¼ã‚¿æº–å‚™
data = load_breast_cancer()
X_train, X_test, y_train, y_test = train_test_split(
    data.data, data.target, test_size=0.2, random_state=42
)

# ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒç”¨ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚°ãƒªãƒƒãƒ‰
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [5, 10, 15, None],
    'min_samples_split': [2, 5, 10]
}

# GridSearchCVã®è¨­å®š
grid_search = GridSearchCV(
    estimator=RandomForestClassifier(random_state=42),
    param_grid=param_grid,
    cv=5,                      # 5-foldäº¤å·®æ¤œè¨¼
    scoring='accuracy',        # è©•ä¾¡æŒ‡æ¨™
    n_jobs=-1,                 # å…¨CPUã‚³ã‚¢ä½¿ç”¨
    verbose=2                  # è©³ç´°å‡ºåŠ›
)

# ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒå®Ÿè¡Œ
print("=== ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒé–‹å§‹ ===")
start_time = time.time()
grid_search.fit(X_train, y_train)
elapsed_time = time.time() - start_time

# çµæœè¡¨ç¤º
print(f"\nå®Ÿè¡Œæ™‚é–“: {elapsed_time:.2f}ç§’")
print(f"\næœ€è‰¯ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:")
print(grid_search.best_params_)
print(f"\næœ€è‰¯ã‚¹ã‚³ã‚¢ï¼ˆäº¤å·®æ¤œè¨¼ï¼‰: {grid_search.best_score_:.4f}")

# ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§è©•ä¾¡
y_pred = grid_search.predict(X_test)
test_accuracy = accuracy_score(y_test, y_pred)
print(f"ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ç²¾åº¦: {test_accuracy:.4f}")
</code></pre>

<p><strong>å‡ºåŠ›ä¾‹</strong>ï¼š</p>
<pre><code>=== ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒé–‹å§‹ ===
Fitting 5 folds for each of 36 candidates, totalling 180 fits

å®Ÿè¡Œæ™‚é–“: 12.34ç§’

æœ€è‰¯ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:
{'max_depth': 15, 'min_samples_split': 2, 'n_estimators': 200}

æœ€è‰¯ã‚¹ã‚³ã‚¢ï¼ˆäº¤å·®æ¤œè¨¼ï¼‰: 0.9648
ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ç²¾åº¦: 0.9737
</code></pre>

<h3>æ¢ç´¢çµæœã®è©³ç´°åˆ†æ</h3>

<pre><code class="language-python">import pandas as pd
import matplotlib.pyplot as plt

# çµæœã‚’DataFrameã«å¤‰æ›
results_df = pd.DataFrame(grid_search.cv_results_)

# é‡è¦ãªåˆ—ã®ã¿æŠ½å‡º
results_summary = results_df[[
    'param_n_estimators',
    'param_max_depth',
    'param_min_samples_split',
    'mean_test_score',
    'std_test_score',
    'rank_test_score'
]].sort_values('rank_test_score')

print("\n=== ãƒˆãƒƒãƒ—5ã®çµ„ã¿åˆã‚ã› ===")
print(results_summary.head(10))

# å¯è¦–åŒ–ï¼šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å½±éŸ¿åˆ†æ
fig, axes = plt.subplots(1, 3, figsize=(15, 5))

# n_estimatorsã®å½±éŸ¿
results_df.groupby('param_n_estimators')['mean_test_score'].mean().plot(
    kind='bar', ax=axes[0], color='steelblue'
)
axes[0].set_title('n_estimators ã®å½±éŸ¿', fontsize=12)
axes[0].set_ylabel('å¹³å‡ã‚¹ã‚³ã‚¢')
axes[0].grid(True, alpha=0.3)

# max_depthã®å½±éŸ¿
results_df.groupby('param_max_depth')['mean_test_score'].mean().plot(
    kind='bar', ax=axes[1], color='forestgreen'
)
axes[1].set_title('max_depth ã®å½±éŸ¿', fontsize=12)
axes[1].set_ylabel('å¹³å‡ã‚¹ã‚³ã‚¢')
axes[1].grid(True, alpha=0.3)

# min_samples_splitã®å½±éŸ¿
results_df.groupby('param_min_samples_split')['mean_test_score'].mean().plot(
    kind='bar', ax=axes[2], color='coral'
)
axes[2].set_title('min_samples_split ã®å½±éŸ¿', fontsize=12)
axes[2].set_ylabel('å¹³å‡ã‚¹ã‚³ã‚¢')
axes[2].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
</code></pre>

<h3>é•·æ‰€ã¨çŸ­æ‰€</h3>

<table>
<thead>
<tr>
<th>é …ç›®</th>
<th>è©³ç´°</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>é•·æ‰€</strong></td>
<td>âœ… ç¶²ç¾…çš„æ¢ç´¢ã§æœ€é©è§£ã‚’è¦‹é€ƒã•ãªã„<br>âœ… å®Ÿè£…ãŒã‚·ãƒ³ãƒ—ãƒ«ã§ç†è§£ã—ã‚„ã™ã„<br>âœ… ä¸¦åˆ—åŒ–ãŒå®¹æ˜“</td>
</tr>
<tr>
<td><strong>çŸ­æ‰€</strong></td>
<td>âŒ è¨ˆç®—ã‚³ã‚¹ãƒˆãŒæŒ‡æ•°çš„ã«å¢—åŠ <br>âŒ é«˜æ¬¡å…ƒæ¢ç´¢ã«ã¯ä¸å‘ã<br>âŒ é€£ç¶šå€¤ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æ¢ç´¢ã«åˆ¶é™</td>
</tr>
<tr>
<td><strong>é©ç”¨å ´é¢</strong></td>
<td>ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ãŒå°‘ãªã„ï¼ˆ2-4å€‹ç¨‹åº¦ï¼‰<br>å„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å€™è£œãŒå°‘ãªã„<br>è¨ˆç®—ãƒªã‚½ãƒ¼ã‚¹ãŒååˆ†ã«ã‚ã‚‹</td>
</tr>
</tbody>
</table>

<hr>

<h2>1.3 ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ¼ãƒ</h2>

<h3>ç¢ºç‡çš„æ¢ç´¢ã®åˆ©ç‚¹</h3>

<p><strong>ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ¼ãƒï¼ˆRandom Searchï¼‰</strong>ã¯ã€æ¢ç´¢ç©ºé–“ã‹ã‚‰ãƒ©ãƒ³ãƒ€ãƒ ã«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®çµ„ã¿åˆã‚ã›ã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ã¾ã™ã€‚</p>

<blockquote>
<p>Bergstra & Bengio (2012)ã®ç ”ç©¶ã«ã‚ˆã‚Šã€ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ¼ãƒã¯ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒã‚ˆã‚Šã‚‚åŠ¹ç‡çš„ã§ã‚ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã¾ã™ã€‚</p>
</blockquote>

<div class="mermaid">
graph LR
    A[ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒ] --> B[ã™ã¹ã¦æ¢ç´¢<br/>è¨ˆç®—ã‚³ã‚¹ãƒˆ: é«˜]
    C[ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ¼ãƒ] --> D[ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°<br/>è¨ˆç®—ã‚³ã‚¹ãƒˆ: ä½]

    style A fill:#ffcdd2
    style B fill:#ef9a9a
    style C fill:#c8e6c9
    style D fill:#81c784
</div>

<h3>RandomizedSearchCV</h3>

<pre><code class="language-python">from sklearn.model_selection import RandomizedSearchCV
from scipy.stats import randint, uniform
import numpy as np

# ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ¼ãƒç”¨ã®åˆ†å¸ƒå®šç¾©
param_distributions = {
    'n_estimators': randint(50, 500),              # 50-500ã®æ•´æ•°
    'max_depth': randint(5, 30),                   # 5-30ã®æ•´æ•°
    'min_samples_split': randint(2, 20),           # 2-20ã®æ•´æ•°
    'min_samples_leaf': randint(1, 10),            # 1-10ã®æ•´æ•°
    'max_features': uniform(0.1, 0.9)              # 0.1-1.0ã®å®Ÿæ•°
}

# RandomizedSearchCVã®è¨­å®š
random_search = RandomizedSearchCV(
    estimator=RandomForestClassifier(random_state=42),
    param_distributions=param_distributions,
    n_iter=100,                # 100å›ã®ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
    cv=5,
    scoring='accuracy',
    n_jobs=-1,
    verbose=2,
    random_state=42
)

# ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ¼ãƒå®Ÿè¡Œ
print("=== ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ¼ãƒé–‹å§‹ ===")
start_time = time.time()
random_search.fit(X_train, y_train)
elapsed_time = time.time() - start_time

print(f"\nå®Ÿè¡Œæ™‚é–“: {elapsed_time:.2f}ç§’")
print(f"\næœ€è‰¯ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:")
print(random_search.best_params_)
print(f"\næœ€è‰¯ã‚¹ã‚³ã‚¢ï¼ˆäº¤å·®æ¤œè¨¼ï¼‰: {random_search.best_score_:.4f}")

# ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§è©•ä¾¡
y_pred_random = random_search.predict(X_test)
test_accuracy_random = accuracy_score(y_test, y_pred_random)
print(f"ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ç²¾åº¦: {test_accuracy_random:.4f}")
</code></pre>

<p><strong>å‡ºåŠ›ä¾‹</strong>ï¼š</p>
<pre><code>=== ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ¼ãƒé–‹å§‹ ===
Fitting 5 folds for each of 100 candidates, totalling 500 fits

å®Ÿè¡Œæ™‚é–“: 18.56ç§’

æœ€è‰¯ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:
{'max_depth': 18, 'max_features': 0.7234, 'min_samples_leaf': 1,
 'min_samples_split': 2, 'n_estimators': 387}

æœ€è‰¯ã‚¹ã‚³ã‚¢ï¼ˆäº¤å·®æ¤œè¨¼ï¼‰: 0.9692
ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ç²¾åº¦: 0.9825
</code></pre>

<h3>ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒã¨ã®æ¯”è¼ƒ</h3>

<pre><code class="language-python">import matplotlib.pyplot as plt

# æ¯”è¼ƒçµæœã®å¯è¦–åŒ–
comparison_data = {
    'ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒ': {
        'æ¢ç´¢å›æ•°': len(grid_search.cv_results_['params']),
        'å®Ÿè¡Œæ™‚é–“': 12.34,
        'CVç²¾åº¦': grid_search.best_score_,
        'ãƒ†ã‚¹ãƒˆç²¾åº¦': test_accuracy
    },
    'ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ¼ãƒ': {
        'æ¢ç´¢å›æ•°': len(random_search.cv_results_['params']),
        'å®Ÿè¡Œæ™‚é–“': 18.56,
        'CVç²¾åº¦': random_search.best_score_,
        'ãƒ†ã‚¹ãƒˆç²¾åº¦': test_accuracy_random
    }
}

# DataFrameåŒ–
comparison_df = pd.DataFrame(comparison_data).T
print("\n=== ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒ vs ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ¼ãƒ ===")
print(comparison_df)

# å¯è¦–åŒ–
fig, axes = plt.subplots(1, 3, figsize=(15, 5))

# æ¢ç´¢å›æ•°
comparison_df['æ¢ç´¢å›æ•°'].plot(kind='bar', ax=axes[0], color=['steelblue', 'coral'])
axes[0].set_title('æ¢ç´¢å›æ•°ã®æ¯”è¼ƒ', fontsize=12)
axes[0].set_ylabel('å›æ•°')
axes[0].grid(True, alpha=0.3)

# å®Ÿè¡Œæ™‚é–“
comparison_df['å®Ÿè¡Œæ™‚é–“'].plot(kind='bar', ax=axes[1], color=['steelblue', 'coral'])
axes[1].set_title('å®Ÿè¡Œæ™‚é–“ã®æ¯”è¼ƒ', fontsize=12)
axes[1].set_ylabel('ç§’')
axes[1].grid(True, alpha=0.3)

# ç²¾åº¦
comparison_df[['CVç²¾åº¦', 'ãƒ†ã‚¹ãƒˆç²¾åº¦']].plot(kind='bar', ax=axes[2])
axes[2].set_title('ç²¾åº¦ã®æ¯”è¼ƒ', fontsize=12)
axes[2].set_ylabel('ç²¾åº¦')
axes[2].set_ylim([0.95, 1.0])
axes[2].legend(['CVç²¾åº¦', 'ãƒ†ã‚¹ãƒˆç²¾åº¦'])
axes[2].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
</code></pre>

<h3>ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ¼ãƒã®åˆ©ç‚¹</h3>

<table>
<thead>
<tr>
<th>å´é¢</th>
<th>ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒ</th>
<th>ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ¼ãƒ</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>è¨ˆç®—åŠ¹ç‡</strong></td>
<td>æ¢ç´¢å›æ•° = å…¨çµ„ã¿åˆã‚ã›</td>
<td>æ¢ç´¢å›æ•°ã‚’æŒ‡å®šå¯èƒ½</td>
</tr>
<tr>
<td><strong>é€£ç¶šå€¤å¯¾å¿œ</strong></td>
<td>é›¢æ•£å€¤ã®ã¿</td>
<td>é€£ç¶šåˆ†å¸ƒã‹ã‚‰ç›´æ¥ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°</td>
</tr>
<tr>
<td><strong>é‡è¦æ€§ã¸ã®å¯¾å¿œ</strong></td>
<td>ã™ã¹ã¦å‡ç­‰ã«æ¢ç´¢</td>
<td>é‡è¦ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç¯„å›²ã‚’åºƒãæ¢ç´¢å¯èƒ½</td>
</tr>
<tr>
<td><strong>é«˜æ¬¡å…ƒæ¢ç´¢</strong></td>
<td>æ¬¡å…ƒå¢—åŠ ã§æŒ‡æ•°çš„ã«å¢—å¤§</td>
<td>æ¬¡å…ƒã«å¯¾ã—ã¦ç·šå½¢çš„</td>
</tr>
</tbody>
</table>

<hr>

<h2>1.4 äº¤å·®æ¤œè¨¼ã¨ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¢ç´¢</h2>

<h3>CVæˆ¦ç•¥ã®é¸æŠ</h3>

<p>äº¤å·®æ¤œè¨¼ã¯ã€ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æ±åŒ–æ€§èƒ½ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã«ä¸å¯æ¬ ã§ã™ã€‚</p>

<table>
<thead>
<tr>
<th>CVæ‰‹æ³•</th>
<th>èª¬æ˜</th>
<th>ä½¿ç”¨å ´é¢</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>K-Fold CV</strong></td>
<td>ãƒ‡ãƒ¼ã‚¿ã‚’Kåˆ†å‰²ã—ã€Kå›è©•ä¾¡</td>
<td>æ¨™æº–çš„ãªå ´é¢ï¼ˆK=5ã¾ãŸã¯10ï¼‰</td>
</tr>
<tr>
<td><strong>Stratified K-Fold</strong></td>
<td>ã‚¯ãƒ©ã‚¹æ¯”ç‡ã‚’ä¿æŒã—ã¦åˆ†å‰²</td>
<td>åˆ†é¡å•é¡Œã€ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿</td>
</tr>
<tr>
<td><strong>Time Series Split</strong></td>
<td>æ™‚ç³»åˆ—é †åºã‚’ä¿æŒ</td>
<td>æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿</td>
</tr>
<tr>
<td><strong>Leave-One-Out</strong></td>
<td>1ã‚µãƒ³ãƒ—ãƒ«ãšã¤ãƒ†ã‚¹ãƒˆ</td>
<td>å°è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ï¼ˆè¨ˆç®—ã‚³ã‚¹ãƒˆå¤§ï¼‰</td>
</tr>
</tbody>
</table>

<h3>è©•ä¾¡æŒ‡æ¨™ã®è¨­å®š</h3>

<pre><code class="language-python">from sklearn.model_selection import cross_val_score, StratifiedKFold
from sklearn.metrics import make_scorer, f1_score, precision_score, recall_score

# è¤‡æ•°ã®è©•ä¾¡æŒ‡æ¨™ã§æ¯”è¼ƒ
scoring_metrics = {
    'accuracy': 'accuracy',
    'precision': make_scorer(precision_score, average='weighted'),
    'recall': make_scorer(recall_score, average='weighted'),
    'f1': make_scorer(f1_score, average='weighted')
}

# Stratified K-Foldã§äº¤å·®æ¤œè¨¼
cv_strategy = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

# RandomizedSearchCVã«è¤‡æ•°è©•ä¾¡æŒ‡æ¨™ã‚’é©ç”¨
random_search_multi = RandomizedSearchCV(
    estimator=RandomForestClassifier(random_state=42),
    param_distributions=param_distributions,
    n_iter=50,
    cv=cv_strategy,
    scoring=scoring_metrics,
    refit='f1',                 # F1ã‚¹ã‚³ã‚¢ã§æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ
    n_jobs=-1,
    verbose=1,
    random_state=42
)

random_search_multi.fit(X_train, y_train)

print("=== è¤‡æ•°è©•ä¾¡æŒ‡æ¨™ã§ã®çµæœ ===")
print(f"æœ€è‰¯ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆF1åŸºæº–ï¼‰:")
print(random_search_multi.best_params_)

# å„æŒ‡æ¨™ã§ã®ã‚¹ã‚³ã‚¢
results = random_search_multi.cv_results_
best_index = random_search_multi.best_index_

print(f"\næœ€è‰¯ãƒ¢ãƒ‡ãƒ«ã®ã‚¹ã‚³ã‚¢:")
for metric in scoring_metrics.keys():
    score = results[f'mean_test_{metric}'][best_index]
    std = results[f'std_test_{metric}'][best_index]
    print(f"  {metric}: {score:.4f} (Â±{std:.4f})")
</code></pre>

<p><strong>å‡ºåŠ›ä¾‹</strong>ï¼š</p>
<pre><code>=== è¤‡æ•°è©•ä¾¡æŒ‡æ¨™ã§ã®çµæœ ===
æœ€è‰¯ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆF1åŸºæº–ï¼‰:
{'max_depth': 22, 'max_features': 0.6543, 'min_samples_leaf': 1,
 'min_samples_split': 3, 'n_estimators': 298}

æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ã®ã‚¹ã‚³ã‚¢:
  accuracy: 0.9670 (Â±0.0123)
  precision: 0.9678 (Â±0.0118)
  recall: 0.9670 (Â±0.0123)
  f1: 0.9672 (Â±0.0121)
</code></pre>

<h3>ã‚ªãƒ¼ãƒãƒ¼ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°é˜²æ­¢</h3>

<pre><code class="language-python">import matplotlib.pyplot as plt

# è¨“ç·´ã‚¹ã‚³ã‚¢ã¨ãƒ†ã‚¹ãƒˆã‚¹ã‚³ã‚¢ã®æ¯”è¼ƒ
results = random_search.cv_results_

train_scores = results['mean_train_score']
test_scores = results['mean_test_score']

# éå­¦ç¿’ã®æ¤œå‡º
overfit_gap = train_scores - test_scores

# å¯è¦–åŒ–
fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# ã‚¹ã‚³ã‚¢åˆ†å¸ƒ
axes[0].scatter(train_scores, test_scores, alpha=0.6, s=50)
axes[0].plot([0.9, 1.0], [0.9, 1.0], 'r--', label='ç†æƒ³çš„ãªç·š')
axes[0].set_xlabel('è¨“ç·´ã‚¹ã‚³ã‚¢')
axes[0].set_ylabel('ãƒ†ã‚¹ãƒˆã‚¹ã‚³ã‚¢ï¼ˆCVï¼‰')
axes[0].set_title('è¨“ç·´ vs ãƒ†ã‚¹ãƒˆã‚¹ã‚³ã‚¢', fontsize=12)
axes[0].legend()
axes[0].grid(True, alpha=0.3)

# éå­¦ç¿’ã‚®ãƒ£ãƒƒãƒ—
axes[1].hist(overfit_gap, bins=30, alpha=0.7, edgecolor='black')
axes[1].axvline(x=overfit_gap.mean(), color='r', linestyle='--',
                label=f'å¹³å‡ã‚®ãƒ£ãƒƒãƒ—: {overfit_gap.mean():.4f}')
axes[1].set_xlabel('éå­¦ç¿’ã‚®ãƒ£ãƒƒãƒ—ï¼ˆè¨“ç·´ - ãƒ†ã‚¹ãƒˆï¼‰')
axes[1].set_ylabel('é »åº¦')
axes[1].set_title('éå­¦ç¿’ã®ç¨‹åº¦', fontsize=12)
axes[1].legend()
axes[1].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

# éå­¦ç¿’ãŒå°‘ãªã„ä¸Šä½5ãƒ¢ãƒ‡ãƒ«
results_df = pd.DataFrame({
    'rank': results['rank_test_score'],
    'train_score': train_scores,
    'test_score': test_scores,
    'overfit_gap': overfit_gap
})

print("\n=== éå­¦ç¿’ãŒå°‘ãªã„ãƒˆãƒƒãƒ—5ãƒ¢ãƒ‡ãƒ« ===")
print(results_df.nsmallest(5, 'overfit_gap'))
</code></pre>

<hr>

<h2>1.5 å®Ÿè·µ: scikit-learnã§ã®åŸºæœ¬ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°</h2>

<h3>Random Forest ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ä¾‹</h3>

<pre><code class="language-python">from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report
import time

# ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
X, y = make_classification(
    n_samples=1000,
    n_features=20,
    n_informative=15,
    n_redundant=5,
    random_state=42
)

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã§ã®æ€§èƒ½
print("=== Random Forest ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚° ===\n")
rf_default = RandomForestClassifier(random_state=42)
rf_default.fit(X_train, y_train)
default_score = accuracy_score(y_test, rf_default.predict(X_test))
print(f"ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã®ç²¾åº¦: {default_score:.4f}")

# ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒ
param_grid_rf = {
    'n_estimators': [100, 200, 300],
    'max_depth': [10, 20, 30, None],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}

grid_rf = GridSearchCV(
    RandomForestClassifier(random_state=42),
    param_grid_rf,
    cv=5,
    scoring='accuracy',
    n_jobs=-1
)

start = time.time()
grid_rf.fit(X_train, y_train)
elapsed = time.time() - start

# ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å¾Œã®æ€§èƒ½
tuned_score = accuracy_score(y_test, grid_rf.predict(X_test))

print(f"\næœ€è‰¯ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: {grid_rf.best_params_}")
print(f"ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å¾Œã®ç²¾åº¦: {tuned_score:.4f}")
print(f"æ”¹å–„: {(tuned_score - default_score) * 100:.2f}%")
print(f"å®Ÿè¡Œæ™‚é–“: {elapsed:.2f}ç§’")
</code></pre>

<p><strong>å‡ºåŠ›ä¾‹</strong>ï¼š</p>
<pre><code>=== Random Forest ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚° ===

ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã®ç²¾åº¦: 0.8700

æœ€è‰¯ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}
ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å¾Œã®ç²¾åº¦: 0.9250
æ”¹å–„: 5.50%
å®Ÿè¡Œæ™‚é–“: 24.56ç§’
</code></pre>

<h3>XGBoost ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ä¾‹</h3>

<pre><code class="language-python">import xgboost as xgb
from sklearn.model_selection import RandomizedSearchCV
from scipy.stats import uniform, randint

# XGBoostã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åˆ†å¸ƒ
param_dist_xgb = {
    'n_estimators': randint(100, 500),
    'max_depth': randint(3, 10),
    'learning_rate': uniform(0.01, 0.3),
    'subsample': uniform(0.6, 0.4),
    'colsample_bytree': uniform(0.6, 0.4),
    'gamma': uniform(0, 0.5)
}

# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š
print("\n=== XGBoost ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚° ===\n")
xgb_default = xgb.XGBClassifier(random_state=42, eval_metric='logloss')
xgb_default.fit(X_train, y_train)
default_score_xgb = accuracy_score(y_test, xgb_default.predict(X_test))
print(f"ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã®ç²¾åº¦: {default_score_xgb:.4f}")

# ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ¼ãƒ
random_xgb = RandomizedSearchCV(
    xgb.XGBClassifier(random_state=42, eval_metric='logloss'),
    param_dist_xgb,
    n_iter=100,
    cv=5,
    scoring='accuracy',
    n_jobs=-1,
    random_state=42
)

start = time.time()
random_xgb.fit(X_train, y_train)
elapsed = time.time() - start

# ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å¾Œã®æ€§èƒ½
tuned_score_xgb = accuracy_score(y_test, random_xgb.predict(X_test))

print(f"\næœ€è‰¯ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:")
for param, value in random_xgb.best_params_.items():
    print(f"  {param}: {value:.4f}" if isinstance(value, float) else f"  {param}: {value}")

print(f"\nãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å¾Œã®ç²¾åº¦: {tuned_score_xgb:.4f}")
print(f"æ”¹å–„: {(tuned_score_xgb - default_score_xgb) * 100:.2f}%")
print(f"å®Ÿè¡Œæ™‚é–“: {elapsed:.2f}ç§’")
</code></pre>

<p><strong>å‡ºåŠ›ä¾‹</strong>ï¼š</p>
<pre><code>=== XGBoost ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚° ===

ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã®ç²¾åº¦: 0.9000

æœ€è‰¯ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:
  colsample_bytree: 0.8234
  gamma: 0.1234
  learning_rate: 0.0876
  max_depth: 7
  n_estimators: 387
  subsample: 0.8567

ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å¾Œã®ç²¾åº¦: 0.9400
æ”¹å–„: 4.00%
å®Ÿè¡Œæ™‚é–“: 42.18ç§’
</code></pre>

<h3>çµæœã®å¯è¦–åŒ–</h3>

<pre><code class="language-python">import matplotlib.pyplot as plt
import numpy as np

# ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ
models_comparison = {
    'RF (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ)': default_score,
    'RF (ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°)': tuned_score,
    'XGB (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ)': default_score_xgb,
    'XGB (ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°)': tuned_score_xgb
}

# å¯è¦–åŒ–
fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# ç²¾åº¦æ¯”è¼ƒ
models = list(models_comparison.keys())
scores = list(models_comparison.values())
colors = ['lightcoral', 'lightgreen', 'lightcoral', 'lightgreen']

axes[0].bar(models, scores, color=colors, edgecolor='black', alpha=0.7)
axes[0].set_ylabel('ç²¾åº¦')
axes[0].set_title('ãƒ¢ãƒ‡ãƒ«æ€§èƒ½æ¯”è¼ƒ', fontsize=14)
axes[0].set_ylim([0.8, 1.0])
axes[0].grid(True, alpha=0.3, axis='y')
for i, score in enumerate(scores):
    axes[0].text(i, score + 0.01, f'{score:.4f}', ha='center', fontsize=10)

# æ”¹å–„ç‡
improvements = [
    0,
    (tuned_score - default_score) * 100,
    0,
    (tuned_score_xgb - default_score_xgb) * 100
]

axes[1].bar(models, improvements, color=colors, edgecolor='black', alpha=0.7)
axes[1].set_ylabel('æ”¹å–„ç‡ï¼ˆ%ï¼‰')
axes[1].set_title('ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«ã‚ˆã‚‹æ”¹å–„', fontsize=14)
axes[1].grid(True, alpha=0.3, axis='y')
for i, imp in enumerate(improvements):
    if imp > 0:
        axes[1].text(i, imp + 0.2, f'{imp:.2f}%', ha='center', fontsize=10)

plt.tight_layout()
plt.show()
</code></pre>

<hr>

<h2>1.6 æœ¬ç« ã®ã¾ã¨ã‚</h2>

<h3>å­¦ã‚“ã ã“ã¨</h3>

<ol>
<li><p><strong>ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ç†è§£</strong></p>
<ul>
<li>ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨ã®é•ã„</li>
<li>ä¸»è¦ãªãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨å½¹å‰²</li>
<li>æ¢ç´¢ç©ºé–“ã®é©åˆ‡ãªè¨­è¨ˆ</li>
</ul></li>

<li><p><strong>ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒ</strong></p>
<ul>
<li>ç¶²ç¾…çš„æ¢ç´¢ã«ã‚ˆã‚‹æœ€é©åŒ–</li>
<li>scikit-learn GridSearchCVã®ä½¿ç”¨æ³•</li>
<li>è¨ˆç®—ã‚³ã‚¹ãƒˆã¨æ¢ç´¢åŠ¹ç‡ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•</li>
</ul></li>

<li><p><strong>ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ¼ãƒ</strong></p>
<ul>
<li>ç¢ºç‡çš„ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã®åŠ¹ç‡æ€§</li>
<li>é€£ç¶šåˆ†å¸ƒã‹ã‚‰ã®ç›´æ¥æ¢ç´¢</li>
<li>ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒã«å¯¾ã™ã‚‹å„ªä½æ€§</li>
</ul></li>

<li><p><strong>äº¤å·®æ¤œè¨¼ã®é‡è¦æ€§</strong></p>
<ul>
<li>é©åˆ‡ãªCVæˆ¦ç•¥ã®é¸æŠ</li>
<li>è¤‡æ•°è©•ä¾¡æŒ‡æ¨™ã§ã®ç·åˆè©•ä¾¡</li>
<li>éå­¦ç¿’ã®æ¤œå‡ºã¨é˜²æ­¢</li>
</ul></li>

<li><p><strong>å®Ÿè·µçš„ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°</strong></p>
<ul>
<li>Random Forestã¨XGBoostã®æœ€é©åŒ–</li>
<li>ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã‹ã‚‰ã®æ”¹å–„</li>
<li>çµæœã®å¯è¦–åŒ–ã¨è§£é‡ˆ</li>
</ul></li>
</ol>

<h3>æ‰‹æ³•é¸æŠã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³</h3>

<table>
<thead>
<tr>
<th>çŠ¶æ³</th>
<th>æ¨å¥¨æ‰‹æ³•</th>
<th>ç†ç”±</th>
</tr>
</thead>
<tbody>
<tr>
<td>ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ãŒå°‘ãªã„ï¼ˆ2-3å€‹ï¼‰</td>
<td>ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒ</td>
<td>ç¶²ç¾…çš„æ¢ç´¢ãŒç¾å®Ÿçš„</td>
</tr>
<tr>
<td>ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ãŒå¤šã„ï¼ˆ4å€‹ä»¥ä¸Šï¼‰</td>
<td>ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ¼ãƒ</td>
<td>è¨ˆç®—åŠ¹ç‡ãŒè‰¯ã„</td>
</tr>
<tr>
<td>é€£ç¶šå€¤ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿</td>
<td>ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ¼ãƒ</td>
<td>åˆ†å¸ƒã‹ã‚‰ç›´æ¥ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°</td>
</tr>
<tr>
<td>è¨ˆç®—ãƒªã‚½ãƒ¼ã‚¹ãŒé™å®šçš„</td>
<td>ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ¼ãƒ</td>
<td>æ¢ç´¢å›æ•°ã‚’åˆ¶å¾¡å¯èƒ½</td>
</tr>
<tr>
<td>æœ€é«˜ç²¾åº¦ãŒå¿…è¦</td>
<td>ä¸¡æ–¹ã‚’çµ„ã¿åˆã‚ã›</td>
<td>ç²—æ¢ç´¢â†’ç´°æ¢ç´¢ã®2æ®µéš</td>
</tr>
</tbody>
</table>

<h3>æ¬¡ã®ç« ã¸</h3>

<p>ç¬¬2ç« ã§ã¯ã€<strong>ãƒ™ã‚¤ã‚ºæœ€é©åŒ–</strong>ã‚’å­¦ã³ã¾ã™ï¼š</p>
<ul>
<li>ã‚¬ã‚¦ã‚¹éç¨‹ã«ã‚ˆã‚‹ä»£ç†ãƒ¢ãƒ‡ãƒ«</li>
<li>ç²å¾—é–¢æ•°ã®è¨­è¨ˆ</li>
<li>Optimaã‚’ä½¿ã£ãŸå®Ÿè£…</li>
<li>å¾“æ¥æ‰‹æ³•ã¨ã®æ€§èƒ½æ¯”è¼ƒ</li>
<li>å®Ÿè·µçš„ãªå¿œç”¨ä¾‹</li>
</ul>

<hr>

<h2>æ¼”ç¿’å•é¡Œ</h2>

<h3>å•é¡Œ1ï¼ˆé›£æ˜“åº¦: easyï¼‰</h3>
<p>ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®é•ã„ã‚’3ã¤ã®è¦³ç‚¹ï¼ˆå®šç¾©ã€æ±ºå®šæ–¹æ³•ã€ä¾‹ï¼‰ã‹ã‚‰èª¬æ˜ã—ã¦ãã ã•ã„ã€‚</p>

<details>
<summary>è§£ç­”ä¾‹</summary>

<p><strong>è§£ç­”</strong>ï¼š</p>

<table>
<thead>
<tr>
<th>è¦³ç‚¹</th>
<th>ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿</th>
<th>ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>å®šç¾©</strong></td>
<td>å­¦ç¿’å‰ã«äººé–“ãŒè¨­å®šã™ã‚‹å€¤</td>
<td>å­¦ç¿’ã«ã‚ˆã‚Šè‡ªå‹•çš„ã«æœ€é©åŒ–ã•ã‚Œã‚‹å€¤</td>
</tr>
<tr>
<td><strong>æ±ºå®šæ–¹æ³•</strong></td>
<td>è©¦è¡ŒéŒ¯èª¤ã€æ¢ç´¢ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã€çµŒé¨“</td>
<td>è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å‹¾é…é™ä¸‹æ³•ç­‰ã§å­¦ç¿’</td>
</tr>
<tr>
<td><strong>ä¾‹</strong></td>
<td>å­¦ç¿’ç‡ã€æœ¨ã®æ·±ã•ã€æ­£å‰‡åŒ–ä¿‚æ•°</td>
<td>ç·šå½¢å›å¸°ã®ä¿‚æ•°ã€ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆã®é‡ã¿</td>
</tr>
</tbody>
</table>

<p><strong>è£œè¶³èª¬æ˜</strong>ï¼š</p>
<ul>
<li>ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯ãƒ¢ãƒ‡ãƒ«ã®æ§‹é€ ã‚„å­¦ç¿’ãƒ—ãƒ­ã‚»ã‚¹ã‚’åˆ¶å¾¡</li>
<li>ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯ãƒ‡ãƒ¼ã‚¿ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è¡¨ç¾</li>
<li>é©åˆ‡ãªãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿é¸æŠã«ã‚ˆã‚Šã€ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å­¦ç¿’ãŒåŠ¹ç‡åŒ–</li>
</ul>

</details>

<h3>å•é¡Œ2ï¼ˆé›£æ˜“åº¦: mediumï¼‰</h3>
<p>ä»¥ä¸‹ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚°ãƒªãƒƒãƒ‰ã®ç·çµ„ã¿åˆã‚ã›æ•°ã‚’è¨ˆç®—ã—ã€ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒã®è¨ˆç®—ã‚³ã‚¹ãƒˆã«ã¤ã„ã¦è€ƒå¯Ÿã—ã¦ãã ã•ã„ã€‚</p>

<pre><code class="language-python">param_grid = {
    'n_estimators': [100, 200, 300, 400, 500],
    'max_depth': [5, 10, 15, 20, 25, 30],
    'min_samples_split': [2, 5, 10, 15],
    'learning_rate': [0.01, 0.05, 0.1, 0.2]
}
# 5-foldäº¤å·®æ¤œè¨¼ã‚’ä½¿ç”¨
</code></pre>

<details>
<summary>è§£ç­”ä¾‹</summary>

<pre><code class="language-python">import numpy as np

param_grid = {
    'n_estimators': [100, 200, 300, 400, 500],
    'max_depth': [5, 10, 15, 20, 25, 30],
    'min_samples_split': [2, 5, 10, 15],
    'learning_rate': [0.01, 0.05, 0.1, 0.2]
}

# å„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å€™è£œæ•°
param_counts = [len(v) for v in param_grid.values()]
print("å„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å€™è£œæ•°:")
for param, count in zip(param_grid.keys(), param_counts):
    print(f"  {param}: {count}")

# ç·çµ„ã¿åˆã‚ã›æ•°
total_combinations = np.prod(param_counts)
print(f"\nç·çµ„ã¿åˆã‚ã›æ•°: {total_combinations:,}")

# 5-foldäº¤å·®æ¤œè¨¼ã§ã®ç·å­¦ç¿’å›æ•°
cv_folds = 5
total_fits = total_combinations * cv_folds
print(f"5-fold CVã§ã®ç·å­¦ç¿’å›æ•°: {total_fits:,}")

# 1å›ã®å­¦ç¿’ã«1åˆ†ã‹ã‹ã‚‹ã¨ä»®å®š
time_per_fit = 1  # åˆ†
total_time_minutes = total_fits * time_per_fit
total_time_hours = total_time_minutes / 60

print(f"\nè¨ˆç®—æ™‚é–“ï¼ˆ1å›ã®å­¦ç¿’=1åˆ†ã¨ä»®å®šï¼‰:")
print(f"  {total_time_minutes:,}åˆ†")
print(f"  {total_time_hours:.1f}æ™‚é–“")
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>å„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å€™è£œæ•°:
  n_estimators: 5
  max_depth: 6
  min_samples_split: 4
  learning_rate: 4

ç·çµ„ã¿åˆã‚ã›æ•°: 480
5-fold CVã§ã®ç·å­¦ç¿’å›æ•°: 2,400

è¨ˆç®—æ™‚é–“ï¼ˆ1å›ã®å­¦ç¿’=1åˆ†ã¨ä»®å®šï¼‰:
  2,400åˆ†
  40.0æ™‚é–“
</code></pre>

<p><strong>è€ƒå¯Ÿ</strong>ï¼š</p>
<ul>
<li>ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ãŒå¢—ãˆã‚‹ã¨çµ„ã¿åˆã‚ã›ãŒæŒ‡æ•°çš„ã«å¢—åŠ </li>
<li>äº¤å·®æ¤œè¨¼ã«ã‚ˆã‚Šè¨ˆç®—ã‚³ã‚¹ãƒˆãŒã•ã‚‰ã«å¢—å¤§</li>
<li>ã“ã®ä¾‹ã§ã¯ç´„40æ™‚é–“ã®è¨ˆç®—æ™‚é–“ãŒå¿…è¦</li>
<li>ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ¼ãƒã§æ¢ç´¢å›æ•°ã‚’100ã«åˆ¶é™ã™ã‚Œã°ç´„8.3æ™‚é–“ï¼ˆ500å›ã®å­¦ç¿’ï¼‰</li>
</ul>

</details>

<h3>å•é¡Œ3ï¼ˆé›£æ˜“åº¦: mediumï¼‰</h3>
<p>ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒã¨ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ¼ãƒã®é•·æ‰€ãƒ»çŸ­æ‰€ã‚’æ¯”è¼ƒã—ã€ã©ã®ã‚ˆã†ãªå ´é¢ã§ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ¼ãƒãŒæœ‰åˆ©ã‹èª¬æ˜ã—ã¦ãã ã•ã„ã€‚</p>

<details>
<summary>è§£ç­”ä¾‹</summary>

<p><strong>è§£ç­”</strong>ï¼š</p>

<table>
<thead>
<tr>
<th>é …ç›®</th>
<th>ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒ</th>
<th>ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ¼ãƒ</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>æ¢ç´¢æ–¹æ³•</strong></td>
<td>ã™ã¹ã¦ã®çµ„ã¿åˆã‚ã›ã‚’ç¶²ç¾…</td>
<td>ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°</td>
</tr>
<tr>
<td><strong>è¨ˆç®—ã‚³ã‚¹ãƒˆ</strong></td>
<td>æŒ‡æ•°çš„ã«å¢—åŠ </td>
<td>æ¢ç´¢å›æ•°ã‚’åˆ¶å¾¡å¯èƒ½</td>
</tr>
<tr>
<td><strong>æœ€é©è§£ã®ä¿è¨¼</strong></td>
<td>æ¢ç´¢ç©ºé–“å†…ã§ä¿è¨¼</td>
<td>ç¢ºç‡çš„ï¼ˆä¿è¨¼ãªã—ï¼‰</td>
</tr>
<tr>
<td><strong>é€£ç¶šå€¤å¯¾å¿œ</strong></td>
<td>é›¢æ•£åŒ–ãŒå¿…è¦</td>
<td>é€£ç¶šåˆ†å¸ƒã‹ã‚‰ç›´æ¥ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°</td>
</tr>
<tr>
<td><strong>é«˜æ¬¡å…ƒæ¢ç´¢</strong></td>
<td>å›°é›£ï¼ˆçµ„ã¿åˆã‚ã›çˆ†ç™ºï¼‰</td>
<td>æ¬¡å…ƒã«å¯¾ã—ã¦ç·šå½¢çš„</td>
</tr>
</tbody>
</table>

<p><strong>ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ¼ãƒãŒæœ‰åˆ©ãªå ´é¢</strong>ï¼š</p>

<ol>
<li><strong>ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ãŒå¤šã„ï¼ˆ4å€‹ä»¥ä¸Šï¼‰</strong>
<ul>
<li>ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒã§ã¯çµ„ã¿åˆã‚ã›ãŒçˆ†ç™ºçš„ã«å¢—åŠ </li>
<li>ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ¼ãƒã¯æ¢ç´¢å›æ•°ã‚’å›ºå®šã§ãã‚‹</li>
</ul></li>

<li><strong>é€£ç¶šå€¤ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æœ€é©åŒ–</strong>
<ul>
<li>å­¦ç¿’ç‡ã€æ­£å‰‡åŒ–ä¿‚æ•°ãªã©ã®é€£ç¶šå€¤</li>
<li>åˆ†å¸ƒã‹ã‚‰ç›´æ¥ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã§ãã‚‹</li>
</ul></li>

<li><strong>ä¸€éƒ¨ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒé‡è¦ãªå ´åˆ</strong>
<ul>
<li>Bergstra & Bengio (2012)ãŒç¤ºã—ãŸé€šã‚Šã€é‡è¦ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ç¯„å›²ã‚’åºƒãæ¢ç´¢</li>
<li>ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒã¯ç­‰é–“éš”ã«åˆ¶é™ã•ã‚Œã‚‹</li>
</ul></li>

<li><strong>è¨ˆç®—ãƒªã‚½ãƒ¼ã‚¹ãŒé™å®šçš„</strong>
<ul>
<li>æ™‚é–“åˆ¶ç´„ãŒã‚ã‚‹å ´åˆ</li>
<li>æ¢ç´¢å›æ•°ã‚’äºˆç®—å†…ã«åˆ¶å¾¡</li>
</ul></li>
</ol>

</details>

<h3>å•é¡Œ4ï¼ˆé›£æ˜“åº¦: hardï¼‰</h3>
<p>ä»¥ä¸‹ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«å¯¾ã—ã¦ã€RandomForestClassifierã®ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å®Ÿè£…ã—ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã‹ã‚‰ã®æ”¹å–„ç‡ã‚’å ±å‘Šã—ã¦ãã ã•ã„ã€‚</p>

<pre><code class="language-python">from sklearn.datasets import load_wine
from sklearn.model_selection import train_test_split

data = load_wine()
X_train, X_test, y_train, y_test = train_test_split(
    data.data, data.target, test_size=0.2, random_state=42
)
</code></pre>

<details>
<summary>è§£ç­”ä¾‹</summary>

<pre><code class="language-python">from sklearn.datasets import load_wine
from sklearn.model_selection import train_test_split, RandomizedSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report
from scipy.stats import randint, uniform
import time

# ãƒ‡ãƒ¼ã‚¿æº–å‚™
data = load_wine()
X_train, X_test, y_train, y_test = train_test_split(
    data.data, data.target, test_size=0.2, random_state=42
)

print("=== Wine ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã®ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚° ===\n")
print(f"è¨“ç·´ãƒ‡ãƒ¼ã‚¿: {X_train.shape}")
print(f"ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {X_test.shape}")
print(f"ã‚¯ãƒ©ã‚¹æ•°: {len(data.target_names)}")

# 1. ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã§ã®æ€§èƒ½
print("\n1. ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã§ã®è©•ä¾¡")
rf_default = RandomForestClassifier(random_state=42)
rf_default.fit(X_train, y_train)
y_pred_default = rf_default.predict(X_test)
default_accuracy = accuracy_score(y_test, y_pred_default)

print(f"ç²¾åº¦: {default_accuracy:.4f}")

# 2. ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ¼ãƒã§ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°
print("\n2. ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ¼ãƒã§ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°")

param_distributions = {
    'n_estimators': randint(50, 500),
    'max_depth': randint(3, 30),
    'min_samples_split': randint(2, 20),
    'min_samples_leaf': randint(1, 10),
    'max_features': uniform(0.1, 0.9)
}

random_search = RandomizedSearchCV(
    RandomForestClassifier(random_state=42),
    param_distributions=param_distributions,
    n_iter=100,
    cv=5,
    scoring='accuracy',
    n_jobs=-1,
    random_state=42,
    verbose=1
)

start_time = time.time()
random_search.fit(X_train, y_train)
elapsed_time = time.time() - start_time

# æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ã§è©•ä¾¡
y_pred_tuned = random_search.predict(X_test)
tuned_accuracy = accuracy_score(y_test, y_pred_tuned)

print(f"\næœ€è‰¯ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:")
for param, value in random_search.best_params_.items():
    if isinstance(value, float):
        print(f"  {param}: {value:.4f}")
    else:
        print(f"  {param}: {value}")

print(f"\nCVç²¾åº¦: {random_search.best_score_:.4f}")
print(f"ãƒ†ã‚¹ãƒˆç²¾åº¦: {tuned_accuracy:.4f}")
print(f"å®Ÿè¡Œæ™‚é–“: {elapsed_time:.2f}ç§’")

# 3. æ”¹å–„ç‡ã®è¨ˆç®—
improvement = (tuned_accuracy - default_accuracy) * 100
improvement_pct = (tuned_accuracy / default_accuracy - 1) * 100

print(f"\n=== çµæœã®ã¾ã¨ã‚ ===")
print(f"ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š: {default_accuracy:.4f}")
print(f"ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å¾Œ: {tuned_accuracy:.4f}")
print(f"çµ¶å¯¾æ”¹å–„: {improvement:.2f}ãƒã‚¤ãƒ³ãƒˆ")
print(f"ç›¸å¯¾æ”¹å–„: {improvement_pct:.2f}%")

# 4. è©³ç´°ãªåˆ†é¡ãƒ¬ãƒãƒ¼ãƒˆ
print(f"\n=== åˆ†é¡ãƒ¬ãƒãƒ¼ãƒˆï¼ˆãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å¾Œï¼‰===")
print(classification_report(y_test, y_pred_tuned,
                          target_names=data.target_names))

# 5. å¯è¦–åŒ–
import matplotlib.pyplot as plt
import pandas as pd

results_df = pd.DataFrame(random_search.cv_results_)

fig, axes = plt.subplots(2, 2, figsize=(14, 10))

# ã‚¹ã‚³ã‚¢åˆ†å¸ƒ
axes[0, 0].hist(results_df['mean_test_score'], bins=20,
                alpha=0.7, edgecolor='black')
axes[0, 0].axvline(x=random_search.best_score_, color='r',
                   linestyle='--', label='æœ€è‰¯ã‚¹ã‚³ã‚¢')
axes[0, 0].set_xlabel('CVç²¾åº¦')
axes[0, 0].set_ylabel('é »åº¦')
axes[0, 0].set_title('ã‚¹ã‚³ã‚¢åˆ†å¸ƒ')
axes[0, 0].legend()
axes[0, 0].grid(True, alpha=0.3)

# ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å½±éŸ¿: n_estimators
axes[0, 1].scatter(results_df['param_n_estimators'],
                   results_df['mean_test_score'], alpha=0.5)
axes[0, 1].set_xlabel('n_estimators')
axes[0, 1].set_ylabel('CVç²¾åº¦')
axes[0, 1].set_title('n_estimatorsã®å½±éŸ¿')
axes[0, 1].grid(True, alpha=0.3)

# ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å½±éŸ¿: max_depth
axes[1, 0].scatter(results_df['param_max_depth'],
                   results_df['mean_test_score'], alpha=0.5)
axes[1, 0].set_xlabel('max_depth')
axes[1, 0].set_ylabel('CVç²¾åº¦')
axes[1, 0].set_title('max_depthã®å½±éŸ¿')
axes[1, 0].grid(True, alpha=0.3)

# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ vs ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°
comparison = ['ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ', 'ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°']
scores = [default_accuracy, tuned_accuracy]
colors = ['lightcoral', 'lightgreen']

axes[1, 1].bar(comparison, scores, color=colors,
               edgecolor='black', alpha=0.7)
axes[1, 1].set_ylabel('ç²¾åº¦')
axes[1, 1].set_title('æ€§èƒ½æ¯”è¼ƒ')
axes[1, 1].set_ylim([0.9, 1.0])
axes[1, 1].grid(True, alpha=0.3, axis='y')
for i, score in enumerate(scores):
    axes[1, 1].text(i, score + 0.005, f'{score:.4f}',
                    ha='center', fontsize=12)

plt.tight_layout()
plt.show()
</code></pre>

<p><strong>å‡ºåŠ›ä¾‹</strong>ï¼š</p>
<pre><code>=== Wine ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã®ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚° ===

è¨“ç·´ãƒ‡ãƒ¼ã‚¿: (142, 13)
ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: (36, 13)
ã‚¯ãƒ©ã‚¹æ•°: 3

1. ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã§ã®è©•ä¾¡
ç²¾åº¦: 0.9722

2. ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ¼ãƒã§ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°
Fitting 5 folds for each of 100 candidates, totalling 500 fits

æœ€è‰¯ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:
  max_depth: 18
  max_features: 0.3456
  min_samples_leaf: 1
  min_samples_split: 2
  n_estimators: 287

CVç²¾åº¦: 0.9859
ãƒ†ã‚¹ãƒˆç²¾åº¦: 1.0000
å®Ÿè¡Œæ™‚é–“: 15.23ç§’

=== çµæœã®ã¾ã¨ã‚ ===
ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š: 0.9722
ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å¾Œ: 1.0000
çµ¶å¯¾æ”¹å–„: 2.78ãƒã‚¤ãƒ³ãƒˆ
ç›¸å¯¾æ”¹å–„: 2.86%

=== åˆ†é¡ãƒ¬ãƒãƒ¼ãƒˆï¼ˆãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å¾Œï¼‰===
              precision    recall  f1-score   support

     class_0       1.00      1.00      1.00        14
     class_1       1.00      1.00      1.00        15
     class_2       1.00      1.00      1.00         7

    accuracy                           1.00        36
   macro avg       1.00      1.00      1.00        36
weighted avg       1.00      1.00      1.00        36
</code></pre>

</details>

<h3>å•é¡Œ5ï¼ˆé›£æ˜“åº¦: hardï¼‰</h3>
<p>äº¤å·®æ¤œè¨¼ã«ãŠã‘ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯ã®å±é™ºæ€§ã«ã¤ã„ã¦èª¬æ˜ã—ã€æ­£ã—ã„å®Ÿè£…æ–¹æ³•ã‚’ç¤ºã—ã¦ãã ã•ã„ã€‚ç‰¹ã«ã€ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã‚„ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¢ç´¢ã®æ–‡è„ˆã§è€ƒå¯Ÿã—ã¦ãã ã•ã„ã€‚</p>

<details>
<summary>è§£ç­”ä¾‹</summary>

<p><strong>è§£ç­”</strong>ï¼š</p>

<p><strong>ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯ã¨ã¯</strong>ï¼š</p>
<p>è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®å¢ƒç•Œã‚’è¶Šãˆã¦æƒ…å ±ãŒæ¼ã‚Œã‚‹ã“ã¨ã§ã€ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ãŒéå¤§è©•ä¾¡ã•ã‚Œã‚‹å•é¡Œã§ã™ã€‚</p>

<p><strong>å…·ä½“çš„ãªå±é™ºæ€§</strong>ï¼š</p>

<ol>
<li><strong>ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã§ã®ãƒªãƒ¼ã‚¯</strong>
<ul>
<li>å…¨ãƒ‡ãƒ¼ã‚¿ã§ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°â†’è¨“ç·´/ãƒ†ã‚¹ãƒˆåˆ†å‰²ã ã¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆæƒ…å ±ãŒè¨“ç·´ã«æ¼ã‚Œã‚‹</li>
<li>ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®å¹³å‡ãƒ»æ¨™æº–åå·®ã‚’ä½¿ç”¨ã—ã¦ã—ã¾ã†</li>
</ul></li>

<li><strong>ç‰¹å¾´é¸æŠã§ã®ãƒªãƒ¼ã‚¯</strong>
<ul>
<li>å…¨ãƒ‡ãƒ¼ã‚¿ã§ç‰¹å¾´é¸æŠâ†’è¨“ç·´/ãƒ†ã‚¹ãƒˆåˆ†å‰²ã ã¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®æƒ…å ±ãŒé¸æŠã«å½±éŸ¿</li>
</ul></li>

<li><strong>äº¤å·®æ¤œè¨¼ã§ã®ãƒªãƒ¼ã‚¯</strong>
<ul>
<li>CVå¤–ã§å‰å‡¦ç†â†’å„foldã«ãƒ†ã‚¹ãƒˆfoldã®æƒ…å ±ãŒæ¼ã‚Œã‚‹</li>
</ul></li>
</ol>

<p><strong>èª¤ã£ãŸå®Ÿè£…ä¾‹</strong>ï¼š</p>

<pre><code class="language-python">from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import cross_val_score
from sklearn.ensemble import RandomForestClassifier

# âŒ é–“é•ã„ï¼šå…¨ãƒ‡ãƒ¼ã‚¿ã§ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)  # å…¨ãƒ‡ãƒ¼ã‚¿ã§fit

# ãã®å¾Œã«äº¤å·®æ¤œè¨¼
scores = cross_val_score(RandomForestClassifier(), X_scaled, y, cv=5)
# â†’ ãƒ†ã‚¹ãƒˆfoldã®æƒ…å ±ãŒè¨“ç·´foldã«æ¼ã‚Œã¦ã„ã‚‹
</code></pre>

<p><strong>æ­£ã—ã„å®Ÿè£…ä¾‹</strong>ï¼š</p>

<pre><code class="language-python">from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import cross_val_score, GridSearchCV
from sklearn.ensemble import RandomForestClassifier

# âœ… æ­£ã—ã„ï¼šPipelineã‚’ä½¿ç”¨
pipeline = Pipeline([
    ('scaler', StandardScaler()),
    ('classifier', RandomForestClassifier())
])

# Pipelineã§äº¤å·®æ¤œè¨¼
# å„foldã§è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®ã¿ã§ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ã‚’fit
scores = cross_val_score(pipeline, X, y, cv=5)

# ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¢ç´¢ã‚‚åŒæ§˜
param_grid = {
    'classifier__n_estimators': [100, 200, 300],
    'classifier__max_depth': [10, 20, None]
}

grid_search = GridSearchCV(pipeline, param_grid, cv=5)
grid_search.fit(X_train, y_train)
</code></pre>

<p><strong>å®Ÿè¨¼å®Ÿé¨“</strong>ï¼š</p>

<pre><code class="language-python">from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.pipeline import Pipeline
import numpy as np

# ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆï¼ˆã‚¹ã‚±ãƒ¼ãƒ«ã®ç•°ãªã‚‹ç‰¹å¾´é‡ï¼‰
X, y = make_classification(n_samples=1000, n_features=20,
                          n_informative=10, random_state=42)

# æ„å›³çš„ã«ã‚¹ã‚±ãƒ¼ãƒ«ã‚’å¤‰ãˆã‚‹
X[:, :10] = X[:, :10] * 1000  # æœ€åˆã®10ç‰¹å¾´ã‚’1000å€

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

print("=== ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯ã®å®Ÿè¨¼ ===\n")

# 1. èª¤ã£ãŸæ–¹æ³•ï¼ˆãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯ã‚ã‚Šï¼‰
scaler_wrong = StandardScaler()
X_train_wrong = scaler_wrong.fit_transform(X_train)
X_test_wrong = scaler_wrong.transform(X_test)

# CVã§ã‚‚ãƒªãƒ¼ã‚¯ãŒç™ºç”Ÿ
X_all_scaled = StandardScaler().fit_transform(X)
cv_scores_wrong = cross_val_score(
    RandomForestClassifier(random_state=42),
    X_all_scaled, y, cv=5
)

print("âŒ èª¤ã£ãŸæ–¹æ³•ï¼ˆå…¨ãƒ‡ãƒ¼ã‚¿ã§ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°å¾Œã«CVï¼‰")
print(f"CVç²¾åº¦: {cv_scores_wrong.mean():.4f} (Â±{cv_scores_wrong.std():.4f})")

# 2. æ­£ã—ã„æ–¹æ³•ï¼ˆPipelineã§ãƒªãƒ¼ã‚¯é˜²æ­¢ï¼‰
pipeline = Pipeline([
    ('scaler', StandardScaler()),
    ('classifier', RandomForestClassifier(random_state=42))
])

cv_scores_correct = cross_val_score(pipeline, X, y, cv=5)

print(f"\nâœ… æ­£ã—ã„æ–¹æ³•ï¼ˆPipelineä½¿ç”¨ï¼‰")
print(f"CVç²¾åº¦: {cv_scores_correct.mean():.4f} (Â±{cv_scores_correct.std():.4f})")

# å·®ã‚’è¨ˆç®—
difference = cv_scores_wrong.mean() - cv_scores_correct.mean()
print(f"\néå¤§è©•ä¾¡ã®ç¨‹åº¦: {difference:.4f} ({difference*100:.2f}%ãƒã‚¤ãƒ³ãƒˆ)")

print("\n=== çµè«– ===")
print("ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯ã«ã‚ˆã‚Šæ€§èƒ½ãŒéå¤§è©•ä¾¡ã•ã‚Œã¦ã„ã‚‹")
print("Pipelineã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã§æ­£ã—ã„è©•ä¾¡ãŒå¯èƒ½")
</code></pre>

<p><strong>å‡ºåŠ›ä¾‹</strong>ï¼š</p>
<pre><code>=== ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯ã®å®Ÿè¨¼ ===

âŒ èª¤ã£ãŸæ–¹æ³•ï¼ˆå…¨ãƒ‡ãƒ¼ã‚¿ã§ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°å¾Œã«CVï¼‰
CVç²¾åº¦: 0.9120 (Â±0.0234)

âœ… æ­£ã—ã„æ–¹æ³•ï¼ˆPipelineä½¿ç”¨ï¼‰
CVç²¾åº¦: 0.9050 (Â±0.0287)

éå¤§è©•ä¾¡ã®ç¨‹åº¦: 0.0070 (0.70%ãƒã‚¤ãƒ³ãƒˆ)

=== çµè«– ===
ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯ã«ã‚ˆã‚Šæ€§èƒ½ãŒéå¤§è©•ä¾¡ã•ã‚Œã¦ã„ã‚‹
Pipelineã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã§æ­£ã—ã„è©•ä¾¡ãŒå¯èƒ½
</code></pre>

<p><strong>ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹</strong>ï¼š</p>
<ul>
<li>å¸¸ã«Pipelineã‚’ä½¿ç”¨ã—ã¦å‰å‡¦ç†ã¨ãƒ¢ãƒ‡ãƒ«ã‚’çµ±åˆ</li>
<li>äº¤å·®æ¤œè¨¼ã¯å‰å‡¦ç†ã‚’å«ã‚€å…¨ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã«å¯¾ã—ã¦å®Ÿè¡Œ</li>
<li>è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã§fitã—ã€ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§ã¯transformã®ã¿</li>
<li>ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¢ç´¢ã‚‚Pipelineå…¨ä½“ã«å¯¾ã—ã¦å®Ÿæ–½</li>
</ul>

</details>

<hr>

<h2>å‚è€ƒæ–‡çŒ®</h2>

<ol>
<li>Bergstra, J., & Bengio, Y. (2012). Random search for hyper-parameter optimization. <em>Journal of Machine Learning Research</em>, 13(1), 281-305.</li>
<li>Feurer, M., & Hutter, F. (2019). Hyperparameter optimization. In <em>Automated Machine Learning</em> (pp. 3-33). Springer.</li>
<li>Hastie, T., Tibshirani, R., & Friedman, J. (2009). <em>The Elements of Statistical Learning</em> (2nd ed.). Springer.</li>
<li>GÃ©ron, A. (2019). <em>Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow</em> (2nd ed.). O'Reilly Media.</li>
</ol>

<div class="navigation">
    <a href="index.html" class="nav-button">â† ã‚·ãƒªãƒ¼ã‚ºç›®æ¬¡</a>
    <a href="chapter2-bayesian-optimization.html" class="nav-button">æ¬¡ã®ç« : ãƒ™ã‚¤ã‚ºæœ€é©åŒ– â†’</a>
</div>

    </main>

    
    <section class="disclaimer">
        <h3>å…è²¬äº‹é …</h3>
        <ul>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯æ•™è‚²ãƒ»ç ”ç©¶ãƒ»æƒ…å ±æä¾›ã®ã¿ã‚’ç›®çš„ã¨ã—ã¦ãŠã‚Šã€å°‚é–€çš„ãªåŠ©è¨€(æ³•å¾‹ãƒ»ä¼šè¨ˆãƒ»æŠ€è¡“çš„ä¿è¨¼ãªã©)ã‚’æä¾›ã™ã‚‹ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŠã‚ˆã³ä»˜éšã™ã‚‹ã‚³ãƒ¼ãƒ‰ä¾‹ã¯ã€Œç¾çŠ¶æœ‰å§¿(AS IS)ã€ã§æä¾›ã•ã‚Œã€æ˜ç¤ºã¾ãŸã¯é»™ç¤ºã‚’å•ã‚ãšã€å•†å“æ€§ã€ç‰¹å®šç›®çš„é©åˆæ€§ã€æ¨©åˆ©éä¾µå®³ã€æ­£ç¢ºæ€§ãƒ»å®Œå…¨æ€§ã€å‹•ä½œãƒ»å®‰å…¨æ€§ç­‰ã„ã‹ãªã‚‹ä¿è¨¼ã‚‚ã—ã¾ã›ã‚“ã€‚</li>
            <li>å¤–éƒ¨ãƒªãƒ³ã‚¯ã€ç¬¬ä¸‰è€…ãŒæä¾›ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ»ãƒ„ãƒ¼ãƒ«ãƒ»ãƒ©ã‚¤ãƒ–ãƒ©ãƒªç­‰ã®å†…å®¹ãƒ»å¯ç”¨æ€§ãƒ»å®‰å…¨æ€§ã«ã¤ã„ã¦ã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯ä¸€åˆ‡ã®è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®åˆ©ç”¨ãƒ»å®Ÿè¡Œãƒ»è§£é‡ˆã«ã‚ˆã‚Šç›´æ¥çš„ãƒ»é–“æ¥çš„ãƒ»ä»˜éšçš„ãƒ»ç‰¹åˆ¥ãƒ»çµæœçš„ãƒ»æ‡²ç½°çš„æå®³ãŒç”Ÿã˜ãŸå ´åˆã§ã‚‚ã€é©ç”¨æ³•ã§è¨±å®¹ã•ã‚Œã‚‹æœ€å¤§é™ã®ç¯„å›²ã§ã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å†…å®¹ã¯ã€äºˆå‘Šãªãå¤‰æ›´ãƒ»æ›´æ–°ãƒ»æä¾›åœæ­¢ã•ã‚Œã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®è‘—ä½œæ¨©ãƒ»ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯æ˜è¨˜ã•ã‚ŒãŸæ¡ä»¶(ä¾‹: CC BY 4.0)ã«å¾“ã„ã¾ã™ã€‚å½“è©²ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯é€šå¸¸ã€ç„¡ä¿è¨¼æ¡é …ã‚’å«ã¿ã¾ã™ã€‚</li>
        </ul>
    </section>

<footer>
        <p><strong>ä½œæˆè€…</strong>: AI Terakoya Content Team</p>
        <p><strong>ãƒãƒ¼ã‚¸ãƒ§ãƒ³</strong>: 1.0 | <strong>ä½œæˆæ—¥</strong>: 2025-10-21</p>
        <p><strong>ãƒ©ã‚¤ã‚»ãƒ³ã‚¹</strong>: Creative Commons BY 4.0</p>
        <p>Â© 2025 AI Terakoya. All rights reserved.</p>
    </footer>
</body>
</html>
