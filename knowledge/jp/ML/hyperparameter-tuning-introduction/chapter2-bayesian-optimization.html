<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
<meta content="ç¬¬2ç« ï¼šãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã¨Optuna - AI Terakoya" name="description"/>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ç¬¬2ç« ï¼šãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã¨Optuna - AI Terakoya</title>

    <style>
        :root {
            --color-primary: #2c3e50;
            --color-primary-dark: #1a252f;
            --color-accent: #7b2cbf;
            --color-accent-light: #9d4edd;
            --color-text: #2d3748;
            --color-text-light: #4a5568;
            --color-bg: #ffffff;
            --color-bg-alt: #f7fafc;
            --color-border: #e2e8f0;
            --color-code-bg: #f8f9fa;
            --color-link: #3182ce;
            --color-link-hover: #2c5aa0;

            --spacing-xs: 0.5rem;
            --spacing-sm: 1rem;
            --spacing-md: 1.5rem;
            --spacing-lg: 2rem;
            --spacing-xl: 3rem;

            --font-body: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            --font-mono: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;

            --border-radius: 8px;
            --box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: var(--font-body);
            line-height: 1.7;
            color: var(--color-text);
            background-color: var(--color-bg);
            font-size: 16px;
        }

        header {
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            padding: var(--spacing-xl) var(--spacing-md);
            margin-bottom: var(--spacing-xl);
            box-shadow: var(--box-shadow);
        }

        .header-content {
            max-width: 900px;
            margin: 0 auto;
        }

        h1 {
            font-size: 2rem;
            font-weight: 700;
            margin-bottom: var(--spacing-sm);
            line-height: 1.2;
        }

        .subtitle {
            font-size: 1.1rem;
            opacity: 0.95;
            font-weight: 400;
            margin-bottom: var(--spacing-md);
        }

        .meta {
            display: flex;
            flex-wrap: wrap;
            gap: var(--spacing-md);
            font-size: 0.9rem;
            opacity: 0.9;
        }

        .meta-item {
            display: flex;
            align-items: center;
            gap: 0.3rem;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 0 var(--spacing-md) var(--spacing-xl);
        }

        h2 {
            font-size: 1.75rem;
            color: var(--color-primary);
            margin-top: var(--spacing-xl);
            margin-bottom: var(--spacing-md);
            padding-bottom: var(--spacing-xs);
            border-bottom: 3px solid var(--color-accent);
        }

        h3 {
            font-size: 1.4rem;
            color: var(--color-primary);
            margin-top: var(--spacing-lg);
            margin-bottom: var(--spacing-sm);
        }

        h4 {
            font-size: 1.1rem;
            color: var(--color-primary-dark);
            margin-top: var(--spacing-md);
            margin-bottom: var(--spacing-sm);
        }

        p {
            margin-bottom: var(--spacing-md);
            color: var(--color-text);
        }

        a {
            color: var(--color-link);
            text-decoration: none;
            transition: color 0.2s;
        }

        a:hover {
            color: var(--color-link-hover);
            text-decoration: underline;
        }

        ul, ol {
            margin-left: var(--spacing-lg);
            margin-bottom: var(--spacing-md);
        }

        li {
            margin-bottom: var(--spacing-xs);
            color: var(--color-text);
        }

        pre {
            background-color: var(--color-code-bg);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            overflow-x: auto;
            margin-bottom: var(--spacing-md);
            font-family: var(--font-mono);
            font-size: 0.9rem;
            line-height: 1.5;
        }

        code {
            font-family: var(--font-mono);
            font-size: 0.9em;
            background-color: var(--color-code-bg);
            padding: 0.2em 0.4em;
            border-radius: 3px;
        }

        pre code {
            background-color: transparent;
            padding: 0;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: var(--spacing-md);
            font-size: 0.95rem;
        }

        th, td {
            border: 1px solid var(--color-border);
            padding: var(--spacing-sm);
            text-align: left;
        }

        th {
            background-color: var(--color-bg-alt);
            font-weight: 600;
            color: var(--color-primary);
        }

        blockquote {
            border-left: 4px solid var(--color-accent);
            padding-left: var(--spacing-md);
            margin: var(--spacing-md) 0;
            color: var(--color-text-light);
            font-style: italic;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        .mermaid {
            text-align: center;
            margin: var(--spacing-lg) 0;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        details {
            background-color: var(--color-bg-alt);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            margin-bottom: var(--spacing-md);
        }

        summary {
            cursor: pointer;
            font-weight: 600;
            color: var(--color-primary);
            user-select: none;
            padding: var(--spacing-xs);
            margin: calc(-1 * var(--spacing-md));
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        summary:hover {
            background-color: rgba(123, 44, 191, 0.1);
        }

        details[open] summary {
            margin-bottom: var(--spacing-md);
            border-bottom: 1px solid var(--color-border);
        }

        .navigation {
            display: flex;
            justify-content: space-between;
            gap: var(--spacing-md);
            margin: var(--spacing-xl) 0;
            padding-top: var(--spacing-lg);
            border-top: 2px solid var(--color-border);
        }

        .nav-button {
            flex: 1;
            padding: var(--spacing-md);
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            border-radius: var(--border-radius);
            text-align: center;
            font-weight: 600;
            transition: transform 0.2s, box-shadow 0.2s;
            box-shadow: var(--box-shadow);
        }

        .nav-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
            text-decoration: none;
        }

        footer {
            margin-top: var(--spacing-xl);
            padding: var(--spacing-lg) var(--spacing-md);
            background-color: var(--color-bg-alt);
            border-top: 1px solid var(--color-border);
            text-align: center;
            font-size: 0.9rem;
            color: var(--color-text-light);
        }
        .disclaimer {
            max-width: 900px;
            margin: 2rem auto;
            padding: 1.5rem;
            background: #f8f9fa;
            border-left: 4px solid #6c757d;
            border-radius: 4px;
        }

        .disclaimer h3 {
            color: #495057;
            margin-bottom: 1rem;
            font-size: 1.1rem;
        }

        .disclaimer ul {
            list-style: none;
            padding-left: 0;
        }

        .disclaimer li {
            padding: 0.5rem 0;
            padding-left: 1.5rem;
            position: relative;
            font-size: 0.9rem;
            color: #6c757d;
            line-height: 1.6;
        }

        .disclaimer li::before {
            content: "âš ï¸";
            position: absolute;
            left: 0;
        }


        @media (max-width: 768px) {
            h1 {
                font-size: 1.5rem;
            }

            h2 {
                font-size: 1.4rem;
            }

            h3 {
                font-size: 1.2rem;
            }

            .meta {
                font-size: 0.85rem;
            }

            .navigation {
                flex-direction: column;
            }

            table {
                font-size: 0.85rem;
            }

            th, td {
                padding: var(--spacing-xs);
            }
        }
    
        
    
        /* Breadcrumb styles */
        .breadcrumb {
            background: #f7fafc;
            padding: 0.75rem 1rem;
            border-bottom: 1px solid #e2e8f0;
            font-size: 0.9rem;
        }

        .breadcrumb-content {
            max-width: 900px;
            margin: 0 auto;
            display: flex;
            align-items: center;
            flex-wrap: wrap;
            gap: 0.5rem;
        }

        .breadcrumb a {
            color: #667eea;
            text-decoration: none;
            transition: color 0.2s;
        }

        .breadcrumb a:hover {
            color: #764ba2;
            text-decoration: underline;
        }

        .breadcrumb-separator {
            color: #a0aec0;
            margin: 0 0.25rem;
        }

        .breadcrumb-current {
            color: #4a5568;
            font-weight: 500;
        }
    </style>

    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
        mermaid.initialize({ startOnLoad: true, theme: 'default' });
    </script>

    <!-- MathJax for LaTeX equation rendering -->
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                displayMath: [['$$', '$$'], ['\\[', '\\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
                ignoreHtmlClass: 'mermaid'
            }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" async></script>

    <style>
        /* Locale Switcher Styles */
        .locale-switcher {
            display: flex;
            align-items: center;
            gap: 0.5rem;
            padding: 0.5rem 1rem;
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
            border-radius: 6px;
            font-size: 0.9rem;
            margin-bottom: 1rem;
            box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);
        }

        .current-locale {
            font-weight: 600;
            color: #7b2cbf;
            display: flex;
            align-items: center;
            gap: 0.25rem;
        }

        .locale-separator {
            color: #adb5bd;
            font-weight: 300;
        }

        .locale-link {
            color: #f093fb;
            text-decoration: none;
            font-weight: 500;
            transition: all 0.2s ease;
            display: flex;
            align-items: center;
            gap: 0.25rem;
            padding: 0.2rem 0.5rem;
            border-radius: 4px;
        }

        .locale-link:hover {
            background: rgba(240, 147, 251, 0.1);
            color: #d07be8;
            transform: translateY(-1px);
        }

        .locale-meta {
            color: #868e96;
            font-size: 0.85rem;
            font-style: italic;
            margin-left: auto;
        }

        @media (max-width: 768px) {
            .locale-switcher {
                font-size: 0.85rem;
                padding: 0.4rem 0.8rem;
            }
            .locale-meta {
                display: none;
            }
        }
    </style>
</head>
<body>
            <div class="locale-switcher">
<span class="current-locale">ğŸŒ JP</span>
<span class="locale-separator">|</span>
<a href="../../../en/ML/hyperparameter-tuning-introduction/chapter2-bayesian-optimization.html" class="locale-link">ğŸ‡¬ğŸ‡§ EN</a>
<span class="locale-separator">|</span>
<span class="locale-meta">Last sync: 2025-11-16</span>
</div>
<nav class="breadcrumb">
        <div class="breadcrumb-content">
            <a href="../../index.html">AIå¯ºå­å±‹ãƒˆãƒƒãƒ—</a><span class="breadcrumb-separator">â€º</span><a href="../../ML/index.html">æ©Ÿæ¢°å­¦ç¿’</a><span class="breadcrumb-separator">â€º</span><a href="../../ML/hyperparameter-tuning-introduction/index.html">Hyperparameter Tuning</a><span class="breadcrumb-separator">â€º</span><span class="breadcrumb-current">Chapter 2</span>
        </div>
    </nav>

        <header>
        <div class="header-content">
            <h1>ç¬¬2ç« ï¼šãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã¨Optuna</h1>
            <p class="subtitle">åŠ¹ç‡çš„ãªãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚° - è³¢ã„æ¢ç´¢æˆ¦ç•¥</p>
            <div class="meta">
                <span class="meta-item">ğŸ“– èª­äº†æ™‚é–“: 25-30åˆ†</span>
                <span class="meta-item">ğŸ“Š é›£æ˜“åº¦: ä¸­ç´š</span>
                <span class="meta-item">ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹: 8å€‹</span>
                <span class="meta-item">ğŸ¯ é‡è¦åº¦: é«˜</span>
            </div>
        </div>
    </header>

    <main class="container">

<h2>å­¦ç¿’ç›®æ¨™</h2>
<p>ã“ã®ç« ã‚’èª­ã‚€ã“ã¨ã§ã€ä»¥ä¸‹ã‚’ç¿’å¾—ã§ãã¾ã™ï¼š</p>
<ul>
<li>âœ… ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã®åŸºæœ¬åŸç†ã‚’ç†è§£ã™ã‚‹</li>
<li>âœ… TPEï¼ˆTree-structured Parzen Estimatorï¼‰ã®ä»•çµ„ã¿ã‚’å­¦ã¶</li>
<li>âœ… Optunaã®åŸºæœ¬æ¦‚å¿µã¨APIã‚’ç¿’å¾—ã™ã‚‹</li>
<li>âœ… Pruningï¼ˆæåˆˆã‚Šï¼‰ã§åŠ¹ç‡çš„ãªæ¢ç´¢ã‚’å®Ÿç¾ã™ã‚‹</li>
<li>âœ… æ·±å±¤å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æœ€é©åŒ–ã§ãã‚‹</li>
<li>âœ… å¯è¦–åŒ–ãƒ„ãƒ¼ãƒ«ã§æœ€é©åŒ–ãƒ—ãƒ­ã‚»ã‚¹ã‚’åˆ†æã§ãã‚‹</li>
</ul>

<hr>

<h2>2.1 ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã®åŸºç¤</h2>

<h3>ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã¨ã¯</h3>

<p><strong>ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ï¼ˆBayesian Optimizationï¼‰</strong>ã¯ã€è©•ä¾¡ã‚³ã‚¹ãƒˆãŒé«˜ã„ç›®çš„é–¢æ•°ã‚’åŠ¹ç‡çš„ã«æœ€é©åŒ–ã™ã‚‹æ‰‹æ³•ã§ã™ã€‚ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒã‚„ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ¼ãƒã¨æ¯”è¼ƒã—ã¦ã€ä»¥ä¸‹ã®ç‰¹å¾´ãŒã‚ã‚Šã¾ã™ï¼š</p>

<ul>
<li>éå»ã®è©¦è¡Œçµæœã‚’æ´»ç”¨ã—ã¦æ¬¡ã®æ¢ç´¢ç‚¹ã‚’æ±ºå®š</li>
<li>æ¢ç´¢ã¨æ´»ç”¨ã®ãƒãƒ©ãƒ³ã‚¹ã‚’è‡ªå‹•èª¿æ•´</li>
<li>å°‘ãªã„è©¦è¡Œå›æ•°ã§è‰¯ã„è§£ã‚’ç™ºè¦‹</li>
</ul>

<h3>æ¢ç´¢ã¨æ´»ç”¨ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•</h3>

<p>ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã®æ ¸å¿ƒã¯ã€<strong>æ¢ç´¢ï¼ˆExplorationï¼‰</strong>ã¨<strong>æ´»ç”¨ï¼ˆExploitationï¼‰</strong>ã®ãƒãƒ©ãƒ³ã‚¹ã§ã™ã€‚</p>

<table>
<thead>
<tr>
<th>æˆ¦ç•¥</th>
<th>èª¬æ˜</th>
<th>ãƒ¡ãƒªãƒƒãƒˆ</th>
<th>ãƒ‡ãƒ¡ãƒªãƒƒãƒˆ</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>æ¢ç´¢ï¼ˆExplorationï¼‰</strong></td>
<td>æœªçŸ¥ã®é ˜åŸŸã‚’èª¿æŸ»</td>
<td>ã‚°ãƒ­ãƒ¼ãƒãƒ«æœ€é©è§£ã®ç™ºè¦‹</td>
<td>ç„¡é§„ãªè©¦è¡ŒãŒå¢—ãˆã‚‹å¯èƒ½æ€§</td>
</tr>
<tr>
<td><strong>æ´»ç”¨ï¼ˆExploitationï¼‰</strong></td>
<td>è‰¯ã„æ€§èƒ½ã®å‘¨è¾ºã‚’é›†ä¸­èª¿æŸ»</td>
<td>æ—©ãè‰¯ã„è§£ã«åæŸ</td>
<td>å±€æ‰€æœ€é©è§£ã«é™¥ã‚‹å¯èƒ½æ€§</td>
</tr>
</tbody>
</table>

<div class="mermaid">
graph LR
    A[åˆæœŸãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°] --> B[ã‚µãƒ­ã‚²ãƒ¼ãƒˆãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰]
    B --> C[ç²å¾—é–¢æ•°ã§æ¬¡ã®ç‚¹ã‚’é¸æŠ]
    C --> D[ç›®çš„é–¢æ•°ã‚’è©•ä¾¡]
    D --> E{åœæ­¢æ¡ä»¶?}
    E -->|No| B
    E -->|Yes| F[æœ€è‰¯ã®ç‚¹ã‚’è¿”ã™]

    style A fill:#ffebee
    style B fill:#e3f2fd
    style C fill:#f3e5f5
    style D fill:#fff3e0
    style E fill:#fce4ec
    style F fill:#c8e6c9
</div>

<h3>ã‚µãƒ­ã‚²ãƒ¼ãƒˆãƒ¢ãƒ‡ãƒ«ï¼ˆã‚¬ã‚¦ã‚¹éç¨‹ï¼‰</h3>

<p><strong>ã‚µãƒ­ã‚²ãƒ¼ãƒˆãƒ¢ãƒ‡ãƒ«ï¼ˆSurrogate Modelï¼‰</strong>ã¯ã€ç›®çš„é–¢æ•°ã®ä»£ç†ãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚æœ€ã‚‚ä¸€èˆ¬çš„ãªã®ã¯<strong>ã‚¬ã‚¦ã‚¹éç¨‹ï¼ˆGaussian Process, GPï¼‰</strong>ã§ã™ã€‚</p>

<p>ã‚¬ã‚¦ã‚¹éç¨‹ã¯ã€å„ç‚¹ã§ã®äºˆæ¸¬å€¤ã¨ä¸ç¢ºå®Ÿæ€§ã‚’æä¾›ã—ã¾ã™ï¼š</p>

<p>$$
f(x) \sim \mathcal{N}(\mu(x), \sigma^2(x))
$$</p>

<ul>
<li>$\mu(x)$: äºˆæ¸¬å¹³å‡ï¼ˆæœŸå¾…å€¤ï¼‰</li>
<li>$\sigma^2(x)$: äºˆæ¸¬åˆ†æ•£ï¼ˆä¸ç¢ºå®Ÿæ€§ï¼‰</li>
</ul>

<blockquote>
<p><strong>é‡è¦</strong>: è¦³æ¸¬ç‚¹ã‹ã‚‰é ã„ã»ã©ä¸ç¢ºå®Ÿæ€§ãŒå¤§ãããªã‚Šã€æ¢ç´¢ãŒä¿ƒé€²ã•ã‚Œã¾ã™ã€‚</p>
</blockquote>

<h3>ç²å¾—é–¢æ•°ï¼ˆAcquisition Functionï¼‰</h3>

<p><strong>ç²å¾—é–¢æ•°</strong>ã¯ã€æ¬¡ã«è©•ä¾¡ã™ã¹ãç‚¹ã‚’æ±ºå®šã™ã‚‹æŒ‡æ¨™ã§ã™ã€‚ä¸»è¦ãªç²å¾—é–¢æ•°ï¼š</p>

<h4>1. Expected Improvement (EI)</h4>

<p>ç¾åœ¨ã®æœ€è‰¯å€¤ã‹ã‚‰ã®æ”¹å–„æœŸå¾…å€¤ï¼š</p>

<p>$$
\text{EI}(x) = \mathbb{E}[\max(f(x) - f(x^+), 0)]
$$</p>

<ul>
<li>$f(x^+)$: ç¾åœ¨ã®æœ€è‰¯å€¤</li>
<li>æ”¹å–„ãŒæœŸå¾…ã•ã‚Œã‚‹ç‚¹ã‚’å„ªå…ˆ</li>
</ul>

<h4>2. Upper Confidence Bound (UCB)</h4>

<p>å¹³å‡ã¨ä¸ç¢ºå®Ÿæ€§ã®ãƒãƒ©ãƒ³ã‚¹ï¼š</p>

<p>$$
\text{UCB}(x) = \mu(x) + \kappa \sigma(x)
$$</p>

<ul>
<li>$\kappa$: æ¢ç´¢ã®å¼·ã•ã‚’åˆ¶å¾¡ï¼ˆé€šå¸¸1.96ï¼‰</li>
<li>é«˜ã„å¹³å‡ã¾ãŸã¯é«˜ã„ä¸ç¢ºå®Ÿæ€§ã®ç‚¹ã‚’é¸æŠ</li>
</ul>

<h4>3. Probability of Improvement (PI)</h4>

<p>æ”¹å–„ã™ã‚‹ç¢ºç‡ï¼š</p>

<p>$$
\text{PI}(x) = P(f(x) > f(x^+))
$$</p>

<ul>
<li>æ”¹å–„ç¢ºç‡ãŒé«˜ã„ç‚¹ã‚’é¸æŠ</li>
<li>æ¯”è¼ƒçš„ä¿å®ˆçš„</li>
</ul>

<h3>ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã®å®Ÿè£…ä¾‹</h3>

<pre><code class="language-python">import numpy as np
import matplotlib.pyplot as plt
from sklearn.gaussian_process import GaussianProcessRegressor
from sklearn.gaussian_process.kernels import RBF, ConstantKernel
from scipy.stats import norm

# ç›®çš„é–¢æ•°ï¼ˆä¾‹ï¼š1æ¬¡å…ƒã®è¤‡é›‘ãªé–¢æ•°ï¼‰
def objective_function(x):
    return -(x ** 2) * np.sin(5 * x)

# ç²å¾—é–¢æ•°: Expected Improvement (EI)
def expected_improvement(X, X_sample, Y_sample, gpr, xi=0.01):
    mu, sigma = gpr.predict(X, return_std=True)
    mu_sample = gpr.predict(X_sample)

    sigma = sigma.reshape(-1, 1)

    # ç¾åœ¨ã®æœ€è‰¯å€¤
    mu_sample_opt = np.max(mu_sample)

    with np.errstate(divide='warn'):
        imp = mu - mu_sample_opt - xi
        Z = imp / sigma
        ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)
        ei[sigma == 0.0] = 0.0

    return ei

# ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã®å®Ÿè¡Œ
np.random.seed(42)

# æ¢ç´¢ç©ºé–“
X_true = np.linspace(-3, 3, 1000).reshape(-1, 1)
y_true = objective_function(X_true)

# åˆæœŸã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
n_initial = 3
X_sample = np.random.uniform(-3, 3, n_initial).reshape(-1, 1)
Y_sample = objective_function(X_sample)

# ã‚¬ã‚¦ã‚¹éç¨‹ã®å®šç¾©
kernel = ConstantKernel(1.0) * RBF(length_scale=1.0)
gpr = GaussianProcessRegressor(kernel=kernel, alpha=1e-6, n_restarts_optimizer=10)

# åå¾©æœ€é©åŒ–
n_iterations = 7
plt.figure(figsize=(16, 12))

for i in range(n_iterations):
    # ã‚¬ã‚¦ã‚¹éç¨‹ã®ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°
    gpr.fit(X_sample, Y_sample)

    # äºˆæ¸¬
    mu, sigma = gpr.predict(X_true, return_std=True)

    # ç²å¾—é–¢æ•°ã®è¨ˆç®—
    ei = expected_improvement(X_true, X_sample, Y_sample, gpr)

    # æ¬¡ã®ç‚¹ã‚’é¸æŠï¼ˆEIãŒæœ€å¤§ï¼‰
    X_next = X_true[np.argmax(ei)]
    Y_next = objective_function(X_next)

    # ãƒ—ãƒ­ãƒƒãƒˆ
    plt.subplot(3, 3, i + 1)

    # çœŸã®é–¢æ•°
    plt.plot(X_true, y_true, 'r--', label='çœŸã®é–¢æ•°', alpha=0.7)

    # ã‚¬ã‚¦ã‚¹éç¨‹ã®äºˆæ¸¬
    plt.plot(X_true, mu, 'b-', label='GPå¹³å‡')
    plt.fill_between(X_true.ravel(),
                     mu.ravel() - 1.96 * sigma,
                     mu.ravel() + 1.96 * sigma,
                     alpha=0.2, label='95%ä¿¡é ¼åŒºé–“')

    # è¦³æ¸¬ç‚¹
    plt.scatter(X_sample, Y_sample, c='green', s=100,
                zorder=10, label='è¦³æ¸¬ç‚¹', edgecolors='black')

    # æ¬¡ã®ç‚¹
    plt.axvline(x=X_next, color='purple', linestyle='--',
                linewidth=2, label='æ¬¡ã®æ¢ç´¢ç‚¹')

    plt.xlabel('x')
    plt.ylabel('f(x)')
    plt.title(f'åå¾© {i+1}/{n_iterations}', fontsize=12)
    plt.legend(loc='best', fontsize=8)
    plt.grid(True, alpha=0.3)

    # ã‚µãƒ³ãƒ—ãƒ«ã‚’è¿½åŠ 
    X_sample = np.vstack((X_sample, X_next))
    Y_sample = np.vstack((Y_sample, Y_next))

plt.tight_layout()
plt.show()

# æœ€çµ‚çµæœ
best_idx = np.argmax(Y_sample)
print(f"\n=== ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã®çµæœ ===")
print(f"æœ€è‰¯ã® x: {X_sample[best_idx][0]:.4f}")
print(f"æœ€è‰¯ã® f(x): {Y_sample[best_idx][0]:.4f}")
print(f"ç·è©•ä¾¡å›æ•°: {len(X_sample)}")
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>=== ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã®çµæœ ===
æœ€è‰¯ã® x: 1.7854
æœ€è‰¯ã® f(x): 2.8561
ç·è©•ä¾¡å›æ•°: 10
</code></pre>

<blockquote>
<p><strong>è¦³å¯Ÿ</strong>: å°‘ãªã„è©¦è¡Œå›æ•°ã§åŠ¹ç‡çš„ã«æœ€å¤§å€¤ã«åæŸã—ã¦ã„ã¾ã™ã€‚</p>
</blockquote>

<hr>

<h2>2.2 TPE (Tree-structured Parzen Estimator)</h2>

<h3>TPEã®ä»•çµ„ã¿</h3>

<p><strong>TPEï¼ˆTree-structured Parzen Estimatorï¼‰</strong>ã¯ã€ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã®åŠ¹ç‡çš„ãªå®Ÿè£…ã§ã™ã€‚Optunaã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆæœ€é©åŒ–ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã§ã™ã€‚</p>

<p>TPEã®æ ¸å¿ƒçš„ãªã‚¢ã‚¤ãƒ‡ã‚¢ï¼š</p>

<ol>
<li>è¦³æ¸¬ãƒ‡ãƒ¼ã‚¿ã‚’è‰¯ã„çµæœã¨æ‚ªã„çµæœã«åˆ†å‰²</li>
<li>ãã‚Œãã‚Œã®åˆ†å¸ƒã‚’ãƒ¢ãƒ‡ãƒ«åŒ–</li>
<li>è‰¯ã„åˆ†å¸ƒã‹ã‚‰å¤šãã€æ‚ªã„åˆ†å¸ƒã‹ã‚‰å°‘ãªãã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã•ã‚Œã‚‹ç‚¹ã‚’é¸æŠ</li>
</ol>

<h3>ã‚¬ã‚¦ã‚¹éç¨‹ã¨ã®é•ã„</h3>

<table>
<thead>
<tr>
<th>å´é¢</th>
<th>ã‚¬ã‚¦ã‚¹éç¨‹ï¼ˆGPï¼‰</th>
<th>TPE</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>ãƒ¢ãƒ‡ãƒ«åŒ–å¯¾è±¡</strong></td>
<td>$P(y|x)$ - å‡ºåŠ›ã‚’äºˆæ¸¬</td>
<td>$P(x|y)$ - å…¥åŠ›ã®æ¡ä»¶ä»˜ãåˆ†å¸ƒ</td>
</tr>
<tr>
<td><strong>è¨ˆç®—ã‚³ã‚¹ãƒˆ</strong></td>
<td>$O(n^3)$ - ã‚µãƒ³ãƒ—ãƒ«æ•°ã«å¯¾ã—ã¦é«˜ã„</td>
<td>$O(n)$ - ç·šå½¢</td>
</tr>
<tr>
<td><strong>é«˜æ¬¡å…ƒæ€§èƒ½</strong></td>
<td>æ¬¡å…ƒãŒé«˜ã„ã¨ä½ä¸‹</td>
<td>é«˜æ¬¡å…ƒã§ã‚‚å®‰å®š</td>
</tr>
<tr>
<td><strong>ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°</strong></td>
<td>æ‰±ã„ãŒé›£ã—ã„</td>
<td>è‡ªç„¶ã«æ‰±ãˆã‚‹</td>
</tr>
<tr>
<td><strong>ä¸¦åˆ—åŒ–</strong></td>
<td>é›£ã—ã„</td>
<td>å®¹æ˜“</td>
</tr>
</tbody>
</table>

<h3>TPEã®æ•°å¼</h3>

<p>TPEã¯ä»¥ä¸‹ã®ã‚ˆã†ã«2ã¤ã®åˆ†å¸ƒã‚’å®šç¾©ã—ã¾ã™ï¼š</p>

<p>$$
P(x|y) = \begin{cases}
\ell(x) & \text{if } y < y^* \\
g(x) & \text{if } y \geq y^*
\end{cases}
$$</p>

<ul>
<li>$\ell(x)$: è‰¯ã„çµæœã®åˆ†å¸ƒ</li>
<li>$g(x)$: æ‚ªã„çµæœã®åˆ†å¸ƒ</li>
<li>$y^*$: é–¾å€¤ï¼ˆé€šå¸¸ã€ä¸Šä½20-25%ï¼‰</li>
</ul>

<p>ç²å¾—é–¢æ•°ã¯ä»¥ä¸‹ã®æ¯”ç‡ã‚’æœ€å¤§åŒ–ï¼š</p>

<p>$$
\text{EI}(x) \propto \frac{\ell(x)}{g(x)}
$$</p>

<blockquote>
<p><strong>ç›´æ„Ÿ</strong>: è‰¯ã„çµæœã®åˆ†å¸ƒã§ç¢ºç‡ãŒé«˜ãã€æ‚ªã„çµæœã®åˆ†å¸ƒã§ç¢ºç‡ãŒä½ã„ç‚¹ã‚’é¸æŠã—ã¾ã™ã€‚</p>
</blockquote>

<h3>å®Ÿè£…ã®åŠ¹ç‡æ€§</h3>

<p>TPEã®ä¸»ãªåˆ©ç‚¹ï¼š</p>

<ol>
<li><strong>ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£</strong>: å¤§è¦æ¨¡ãªæ¢ç´¢ç©ºé–“ã§ã‚‚é«˜é€Ÿ</li>
<li><strong>æŸ”è»Ÿæ€§</strong>: é€£ç¶šã€é›¢æ•£ã€ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°ã‚’çµ±ä¸€çš„ã«æ‰±ãˆã‚‹</li>
<li><strong>ä¸¦åˆ—åŒ–</strong>: è¤‡æ•°ã®è©¦è¡Œã‚’åŒæ™‚å®Ÿè¡Œå¯èƒ½</li>
<li><strong>æ¡ä»¶ä»˜ãç©ºé–“</strong>: ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿é–“ã®ä¾å­˜é–¢ä¿‚ã«å¯¾å¿œ</li>
</ol>

<pre><code class="language-python"># TPEã®å‹•ä½œã‚¤ãƒ¡ãƒ¼ã‚¸ï¼ˆOptunaã®å†…éƒ¨å‹•ä½œï¼‰
import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import gaussian_kde

# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ï¼ˆãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨æ€§èƒ½ï¼‰
np.random.seed(42)
n_trials = 50

# ãƒ©ãƒ³ãƒ€ãƒ ãªãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å€¤
x_trials = np.random.uniform(0, 10, n_trials)

# æ€§èƒ½ï¼ˆçœŸã®é–¢æ•° + ãƒã‚¤ã‚ºï¼‰
y_trials = -(x_trials - 6) ** 2 + 30 + np.random.normal(0, 2, n_trials)

# é–¾å€¤ã®è¨­å®šï¼ˆä¸Šä½25%ï¼‰
threshold_idx = int(n_trials * 0.75)
sorted_indices = np.argsort(y_trials)
threshold_value = y_trials[sorted_indices[threshold_idx]]

# è‰¯ã„è©¦è¡Œã¨æ‚ªã„è©¦è¡Œã«åˆ†å‰²
good_x = x_trials[y_trials >= threshold_value]
bad_x = x_trials[y_trials < threshold_value]

# ã‚«ãƒ¼ãƒãƒ«å¯†åº¦æ¨å®š
x_range = np.linspace(0, 10, 1000)

if len(good_x) > 1:
    kde_good = gaussian_kde(good_x)
    density_good = kde_good(x_range)
else:
    density_good = np.zeros_like(x_range)

if len(bad_x) > 1:
    kde_bad = gaussian_kde(bad_x)
    density_bad = kde_bad(x_range)
else:
    density_bad = np.zeros_like(x_range)

# EIã®è¿‘ä¼¼ï¼ˆâ„“(x) / g(x)ï¼‰
ei_approx = np.zeros_like(x_range)
mask = density_bad > 1e-6
ei_approx[mask] = density_good[mask] / density_bad[mask]

# ãƒ—ãƒ­ãƒƒãƒˆ
fig, axes = plt.subplots(2, 2, figsize=(14, 10))

# 1. è©¦è¡Œã®åˆ†å¸ƒ
axes[0, 0].scatter(x_trials, y_trials, c='blue', alpha=0.6,
                   s=50, edgecolors='black')
axes[0, 0].axhline(y=threshold_value, color='red',
                   linestyle='--', linewidth=2, label=f'é–¾å€¤ (ä¸Šä½25%)')
axes[0, 0].scatter(good_x, y_trials[y_trials >= threshold_value],
                   c='green', s=100, label='è‰¯ã„è©¦è¡Œ',
                   edgecolors='black', zorder=5)
axes[0, 0].set_xlabel('ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ x')
axes[0, 0].set_ylabel('æ€§èƒ½ y')
axes[0, 0].set_title('è©¦è¡Œã®åˆ†å¸ƒ', fontsize=12)
axes[0, 0].legend()
axes[0, 0].grid(True, alpha=0.3)

# 2. è‰¯ã„è©¦è¡Œã®åˆ†å¸ƒ â„“(x)
axes[0, 1].fill_between(x_range, density_good, alpha=0.5,
                        color='green', label='â„“(x): è‰¯ã„è©¦è¡Œã®åˆ†å¸ƒ')
axes[0, 1].scatter(good_x, np.zeros_like(good_x),
                   c='green', s=50, marker='|', linewidths=2)
axes[0, 1].set_xlabel('ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ x')
axes[0, 1].set_ylabel('å¯†åº¦')
axes[0, 1].set_title('è‰¯ã„è©¦è¡Œã®åˆ†å¸ƒ â„“(x)', fontsize=12)
axes[0, 1].legend()
axes[0, 1].grid(True, alpha=0.3)

# 3. æ‚ªã„è©¦è¡Œã®åˆ†å¸ƒ g(x)
axes[1, 0].fill_between(x_range, density_bad, alpha=0.5,
                        color='red', label='g(x): æ‚ªã„è©¦è¡Œã®åˆ†å¸ƒ')
axes[1, 0].scatter(bad_x, np.zeros_like(bad_x),
                   c='red', s=50, marker='|', linewidths=2)
axes[1, 0].set_xlabel('ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ x')
axes[1, 0].set_ylabel('å¯†åº¦')
axes[1, 0].set_title('æ‚ªã„è©¦è¡Œã®åˆ†å¸ƒ g(x)', fontsize=12)
axes[1, 0].legend()
axes[1, 0].grid(True, alpha=0.3)

# 4. ç²å¾—é–¢æ•° EI âˆ â„“(x) / g(x)
axes[1, 1].plot(x_range, ei_approx, 'purple', linewidth=2,
                label='EI âˆ â„“(x) / g(x)')
next_x = x_range[np.argmax(ei_approx)]
axes[1, 1].axvline(x=next_x, color='purple', linestyle='--',
                   linewidth=2, label=f'æ¬¡ã®æ¢ç´¢ç‚¹: {next_x:.2f}')
axes[1, 1].set_xlabel('ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ x')
axes[1, 1].set_ylabel('ç²å¾—é–¢æ•°å€¤')
axes[1, 1].set_title('ç²å¾—é–¢æ•°ï¼ˆTPEï¼‰', fontsize=12)
axes[1, 1].legend()
axes[1, 1].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

print(f"\n=== TPEã®å‹•ä½œ ===")
print(f"ç·è©¦è¡Œæ•°: {n_trials}")
print(f"è‰¯ã„è©¦è¡Œ: {len(good_x)}å€‹")
print(f"æ‚ªã„è©¦è¡Œ: {len(bad_x)}å€‹")
print(f"é–¾å€¤: {threshold_value:.2f}")
print(f"æ¬¡ã®æ¢ç´¢ç‚¹: {next_x:.2f}")
</code></pre>

<hr>

<h2>2.3 Optunaã®åŸºæœ¬</h2>

<h3>Optunaã¨ã¯</h3>

<p><strong>Optuna</strong>ã¯ã€Preferred NetworksãŒé–‹ç™ºã—ãŸãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã™ã€‚</p>

<p>ç‰¹å¾´ï¼š</p>
<ul>
<li>Define-by-Run API: å‹•çš„ãªæ¢ç´¢ç©ºé–“å®šç¾©</li>
<li>åŠ¹ç‡çš„ãªã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ : TPEãŒãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ</li>
<li>Pruning: æ—©æœŸçµ‚äº†ã§åŠ¹ç‡åŒ–</li>
<li>ä¸¦åˆ—åŒ–: åˆ†æ•£æœ€é©åŒ–ã‚’ã‚µãƒãƒ¼ãƒˆ</li>
<li>å¯è¦–åŒ–: è±Šå¯Œãªãƒ—ãƒ­ãƒƒãƒˆæ©Ÿèƒ½</li>
</ul>

<h3>ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«</h3>

<pre><code class="language-bash"># åŸºæœ¬ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install optuna

# å¯è¦–åŒ–ä»˜ã
pip install optuna[visualization]

# PyTorchçµ±åˆ
pip install optuna[pytorch]
</code></pre>

<h3>åŸºæœ¬æ¦‚å¿µ</h3>

<table>
<thead>
<tr>
<th>æ¦‚å¿µ</th>
<th>èª¬æ˜</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Study</strong></td>
<td>æœ€é©åŒ–ã‚¿ã‚¹ã‚¯å…¨ä½“ã€‚è¤‡æ•°ã®Trialã‚’ç®¡ç†</td>
</tr>
<tr>
<td><strong>Trial</strong></td>
<td>1å›ã®è©¦è¡Œã€‚ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®çµ„ã¿åˆã‚ã›</td>
</tr>
<tr>
<td><strong>Objective</strong></td>
<td>æœ€å°åŒ–ã¾ãŸã¯æœ€å¤§åŒ–ã™ã‚‹ç›®çš„é–¢æ•°</td>
</tr>
<tr>
<td><strong>Sampler</strong></td>
<td>ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æˆ¦ç•¥ï¼ˆTPEãªã©ï¼‰</td>
</tr>
<tr>
<td><strong>Pruner</strong></td>
<td>é€”ä¸­çµŒéã‹ã‚‰æœ‰æœ›ã§ãªã„è©¦è¡Œã‚’æ—©æœŸçµ‚äº†</td>
</tr>
</tbody>
</table>

<div class="mermaid">
graph TD
    A[Studyä½œæˆ] --> B[Objectiveé–¢æ•°å®šç¾©]
    B --> C[Trialé–‹å§‹]
    C --> D[suggest_*ã§ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å–å¾—]
    D --> E[ãƒ¢ãƒ‡ãƒ«è¨“ç·´]
    E --> F[è©•ä¾¡æŒ‡æ¨™ã‚’è¿”ã™]
    F --> G{æœ€é©åŒ–çµ‚äº†?}
    G -->|No| C
    G -->|Yes| H[æœ€è‰¯ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å–å¾—]

    style A fill:#e3f2fd
    style B fill:#fff3e0
    style C fill:#f3e5f5
    style D fill:#e8f5e9
    style E fill:#fce4ec
    style F fill:#ffebee
    style G fill:#f3e5f5
    style H fill:#c8e6c9
</div>

<h3>åŸºæœ¬çš„ãªæœ€é©åŒ–ä¾‹</h3>

<pre><code class="language-python">import optuna
from sklearn.datasets import load_iris
from sklearn.model_selection import cross_val_score
from sklearn.ensemble import RandomForestClassifier

# ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
iris = load_iris()
X, y = iris.data, iris.target

# Objectiveé–¢æ•°ã®å®šç¾©
def objective(trial):
    # ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ææ¡ˆ
    n_estimators = trial.suggest_int('n_estimators', 10, 100)
    max_depth = trial.suggest_int('max_depth', 2, 32, log=True)
    min_samples_split = trial.suggest_int('min_samples_split', 2, 10)
    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)

    # ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ã¨è©•ä¾¡
    clf = RandomForestClassifier(
        n_estimators=n_estimators,
        max_depth=max_depth,
        min_samples_split=min_samples_split,
        min_samples_leaf=min_samples_leaf,
        random_state=42
    )

    # Cross-validation
    score = cross_val_score(clf, X, y, cv=3, scoring='accuracy').mean()

    return score

# Studyã®ä½œæˆã¨æœ€é©åŒ–
study = optuna.create_study(
    direction='maximize',  # ç²¾åº¦ã‚’æœ€å¤§åŒ–
    sampler=optuna.samplers.TPESampler(seed=42)
)

study.optimize(objective, n_trials=50)

# çµæœã®è¡¨ç¤º
print("\n=== Optunaæœ€é©åŒ–çµæœ ===")
print(f"æœ€è‰¯ã®ç²¾åº¦: {study.best_value:.4f}")
print(f"æœ€è‰¯ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:")
for key, value in study.best_params.items():
    print(f"  {key}: {value}")

print(f"\nç·è©¦è¡Œå›æ•°: {len(study.trials)}")
print(f"å®Œäº†ã—ãŸè©¦è¡Œ: {len([t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE])}")
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>=== Optunaæœ€é©åŒ–çµæœ ===
æœ€è‰¯ã®ç²¾åº¦: 0.9733
æœ€è‰¯ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:
  n_estimators: 87
  max_depth: 8
  min_samples_split: 2
  min_samples_leaf: 1

ç·è©¦è¡Œå›æ•°: 50
å®Œäº†ã—ãŸè©¦è¡Œ: 50
</code></pre>

<hr>

<h2>2.4 Optunaå®Ÿè·µãƒ†ã‚¯ãƒ‹ãƒƒã‚¯</h2>

<h3>æ¢ç´¢ç©ºé–“ã®å®šç¾©</h3>

<p>Optunaã¯å¤šæ§˜ãª<code>suggest_*</code>ãƒ¡ã‚½ãƒƒãƒ‰ã‚’æä¾›ã—ã¾ã™ï¼š</p>

<h4>suggestç³»ãƒ¡ã‚½ãƒƒãƒ‰ä¸€è¦§</h4>

<table>
<thead>
<tr>
<th>ãƒ¡ã‚½ãƒƒãƒ‰</th>
<th>ç”¨é€”</th>
<th>ä¾‹</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>suggest_int</code></td>
<td>æ•´æ•°å€¤</td>
<td><code>trial.suggest_int('n_layers', 1, 5)</code></td>
</tr>
<tr>
<td><code>suggest_float</code></td>
<td>æµ®å‹•å°æ•°ç‚¹</td>
<td><code>trial.suggest_float('lr', 1e-5, 1e-1, log=True)</code></td>
</tr>
<tr>
<td><code>suggest_categorical</code></td>
<td>ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«</td>
<td><code>trial.suggest_categorical('optimizer', ['adam', 'sgd'])</code></td>
</tr>
<tr>
<td><code>suggest_uniform</code></td>
<td>ä¸€æ§˜åˆ†å¸ƒï¼ˆéæ¨å¥¨ã€floatã‚’ä½¿ç”¨ï¼‰</td>
<td><code>trial.suggest_float('dropout', 0.0, 0.5)</code></td>
</tr>
<tr>
<td><code>suggest_loguniform</code></td>
<td>å¯¾æ•°ä¸€æ§˜åˆ†å¸ƒï¼ˆéæ¨å¥¨ã€float+logã‚’ä½¿ç”¨ï¼‰</td>
<td><code>trial.suggest_float('lr', 1e-5, 1e-1, log=True)</code></td>
</tr>
</tbody>
</table>

<pre><code class="language-python">import optuna

def objective_comprehensive(trial):
    # æ•´æ•°ï¼ˆç·šå½¢ã‚¹ã‚±ãƒ¼ãƒ«ï¼‰
    batch_size = trial.suggest_int('batch_size', 16, 128, step=16)

    # æ•´æ•°ï¼ˆå¯¾æ•°ã‚¹ã‚±ãƒ¼ãƒ«ï¼‰- å¤§ããªç¯„å›²ã§æœ‰åŠ¹
    hidden_size = trial.suggest_int('hidden_size', 32, 512, log=True)

    # æµ®å‹•å°æ•°ç‚¹ï¼ˆç·šå½¢ã‚¹ã‚±ãƒ¼ãƒ«ï¼‰
    dropout_rate = trial.suggest_float('dropout', 0.0, 0.5)

    # æµ®å‹•å°æ•°ç‚¹ï¼ˆå¯¾æ•°ã‚¹ã‚±ãƒ¼ãƒ«ï¼‰- å­¦ç¿’ç‡ãªã©ã§æœ‰åŠ¹
    learning_rate = trial.suggest_float('lr', 1e-5, 1e-1, log=True)

    # ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°
    optimizer_name = trial.suggest_categorical('optimizer', ['adam', 'sgd', 'rmsprop'])
    activation = trial.suggest_categorical('activation', ['relu', 'tanh', 'sigmoid'])

    # æ¡ä»¶ä»˜ããƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    if optimizer_name == 'sgd':
        momentum = trial.suggest_float('momentum', 0.0, 0.99)
    else:
        momentum = None

    print(f"\n--- Trial {trial.number} ---")
    print(f"batch_size: {batch_size}")
    print(f"hidden_size: {hidden_size}")
    print(f"dropout: {dropout_rate:.4f}")
    print(f"lr: {learning_rate:.6f}")
    print(f"optimizer: {optimizer_name}")
    print(f"activation: {activation}")
    if momentum is not None:
        print(f"momentum: {momentum:.4f}")

    # ãƒ€ãƒŸãƒ¼ã®è©•ä¾¡å€¤
    score = 0.85 + 0.1 * (learning_rate / 1e-1)

    return score

# å®Ÿè¡Œä¾‹
study = optuna.create_study(direction='maximize')
study.optimize(objective_comprehensive, n_trials=5, show_progress_bar=True)
</code></pre>

<h3>Pruningï¼ˆæåˆˆã‚Šï¼‰ã®æ´»ç”¨</h3>

<p><strong>Pruning</strong>ã¯ã€è¨“ç·´é€”ä¸­ã§æœ‰æœ›ã§ãªã„è©¦è¡Œã‚’æ—©æœŸçµ‚äº†ã•ã›ã‚‹æ©Ÿèƒ½ã§ã™ã€‚æ·±å±¤å­¦ç¿’ã§ç‰¹ã«æœ‰åŠ¹ã§ã™ã€‚</p>

<h4>ä¸»è¦ãªPruner</h4>

<table>
<thead>
<tr>
<th>Pruner</th>
<th>èª¬æ˜</th>
<th>ä½¿ç”¨å ´é¢</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>MedianPruner</strong></td>
<td>ä¸­å¤®å€¤ä»¥ä¸‹ã®è©¦è¡Œã‚’æåˆˆã‚Š</td>
<td>ä¸€èˆ¬çš„ãªç”¨é€”</td>
</tr>
<tr>
<td><strong>PercentilePruner</strong></td>
<td>æŒ‡å®šãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«ä»¥ä¸‹ã‚’æåˆˆã‚Š</td>
<td>ã‚ˆã‚Šä¿å®ˆçš„/ç©æ¥µçš„ãªæåˆˆã‚Š</td>
</tr>
<tr>
<td><strong>SuccessiveHalvingPruner</strong></td>
<td>ãƒªã‚½ãƒ¼ã‚¹ã‚’æ®µéšçš„ã«é…åˆ†</td>
<td>å¤šæ•°ã®è©¦è¡Œ</td>
</tr>
<tr>
<td><strong>HyperbandPruner</strong></td>
<td>Successive Halvingã®æ”¹è‰¯ç‰ˆ</td>
<td>å¤§è¦æ¨¡æœ€é©åŒ–</td>
</tr>
</tbody>
</table>

<pre><code class="language-python">import optuna
from optuna.pruners import MedianPruner
import numpy as np
import time

def objective_with_pruning(trial):
    # ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ææ¡ˆ
    lr = trial.suggest_float('lr', 1e-5, 1e-1, log=True)
    n_layers = trial.suggest_int('n_layers', 1, 5)

    # ã‚¨ãƒãƒƒã‚¯ã”ã¨ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
    n_epochs = 20

    for epoch in range(n_epochs):
        # ãƒ€ãƒŸãƒ¼ã®æ€§èƒ½ï¼ˆå¾ã€…ã«æ”¹å–„ï¼‰
        # æ‚ªã„ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯æ”¹å–„ãŒé…ã„
        score = 0.5 + 0.5 * (epoch / n_epochs) * lr * n_layers / 5
        score += np.random.normal(0, 0.05)  # ãƒã‚¤ã‚º

        # é€”ä¸­çµŒéã‚’å ±å‘Š
        trial.report(score, epoch)

        # æåˆˆã‚Šã®åˆ¤å®š
        if trial.should_prune():
            print(f"  Trial {trial.number} pruned at epoch {epoch}")
            raise optuna.TrialPruned()

        time.sleep(0.05)  # è¨“ç·´ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³

    return score

# MedianPrunerã‚’ä½¿ç”¨
study = optuna.create_study(
    direction='maximize',
    pruner=MedianPruner(
        n_startup_trials=5,  # æœ€åˆã®5è©¦è¡Œã¯æåˆˆã‚Šã—ãªã„
        n_warmup_steps=5,    # æœ€åˆã®5ã‚¹ãƒ†ãƒƒãƒ—ã¯æåˆˆã‚Šã—ãªã„
        interval_steps=1     # æ¯ã‚¹ãƒ†ãƒƒãƒ—åˆ¤å®š
    )
)

print("=== Pruningä»˜ãæœ€é©åŒ– ===")
study.optimize(objective_with_pruning, n_trials=20, show_progress_bar=False)

# çµæœã®åˆ†æ
n_complete = len([t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE])
n_pruned = len([t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED])

print(f"\nå®Œäº†ã—ãŸè©¦è¡Œ: {n_complete}")
print(f"æåˆˆã‚Šã•ã‚ŒãŸè©¦è¡Œ: {n_pruned}")
print(f"å‰Šæ¸›ç‡: {n_pruned / len(study.trials) * 100:.1f}%")
print(f"\næœ€è‰¯ã®ç²¾åº¦: {study.best_value:.4f}")
print(f"æœ€è‰¯ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: {study.best_params}")
</code></pre>

<p><strong>å‡ºåŠ›ä¾‹</strong>ï¼š</p>
<pre><code>=== Pruningä»˜ãæœ€é©åŒ– ===
  Trial 5 pruned at epoch 7
  Trial 7 pruned at epoch 6
  Trial 9 pruned at epoch 8
  ...

å®Œäº†ã—ãŸè©¦è¡Œ: 12
æåˆˆã‚Šã•ã‚ŒãŸè©¦è¡Œ: 8
å‰Šæ¸›ç‡: 40.0%

æœ€è‰¯ã®ç²¾åº¦: 0.9234
æœ€è‰¯ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: {'lr': 0.08234, 'n_layers': 5}
</code></pre>

<blockquote>
<p><strong>åŠ¹æœ</strong>: Pruningã«ã‚ˆã‚Šã€ç„¡é§„ãªè¨ˆç®—ã‚’40%å‰Šæ¸›ã—ã¾ã—ãŸã€‚</p>
</blockquote>

<h3>ä¸¦åˆ—æœ€é©åŒ–</h3>

<p>Optunaã¯ç°¡å˜ã«ä¸¦åˆ—æœ€é©åŒ–ãŒå¯èƒ½ã§ã™ï¼š</p>

<pre><code class="language-python">import optuna
from joblib import Parallel, delayed

def objective(trial):
    x = trial.suggest_float('x', -10, 10)
    return (x - 2) ** 2

# æ–¹æ³•1: n_jobsãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
study = optuna.create_study(direction='minimize')
study.optimize(objective, n_trials=100, n_jobs=4)  # 4ä¸¦åˆ—

# æ–¹æ³•2: å…±æœ‰ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ï¼ˆRDBï¼‰
storage = 'sqlite:///optuna_study.db'
study = optuna.create_study(
    study_name='parallel_optimization',
    storage=storage,
    load_if_exists=True
)

# è¤‡æ•°ãƒ—ãƒ­ã‚»ã‚¹ã‹ã‚‰åŒæ™‚ã«å®Ÿè¡Œå¯èƒ½
study.optimize(objective, n_trials=50)
</code></pre>

<hr>

<h2>2.5 å®Ÿè·µ: æ·±å±¤å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°</h2>

<h3>PyTorchãƒ¢ãƒ‡ãƒ«ã®Optunaçµ±åˆ</h3>

<p>å®Ÿéš›ã®æ·±å±¤å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã§Optunaã‚’æ´»ç”¨ã™ã‚‹å®Œå…¨ãªä¾‹ã‚’ç¤ºã—ã¾ã™ã€‚</p>

<pre><code class="language-python">import optuna
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import numpy as np

# ãƒ‡ãƒã‚¤ã‚¹ã®è¨­å®š
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹: {device}")

# ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
X, y = make_classification(
    n_samples=5000, n_features=20, n_informative=15,
    n_redundant=5, n_classes=2, random_state=42
)

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# PyTorchãƒ†ãƒ³ã‚½ãƒ«ã«å¤‰æ›
X_train_t = torch.FloatTensor(X_train).to(device)
y_train_t = torch.LongTensor(y_train).to(device)
X_test_t = torch.FloatTensor(X_test).to(device)
y_test_t = torch.LongTensor(y_test).to(device)

# ãƒ¢ãƒ‡ãƒ«å®šç¾©é–¢æ•°
def create_model(trial, input_size, output_size):
    # ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ææ¡ˆ
    n_layers = trial.suggest_int('n_layers', 1, 4)
    hidden_sizes = []

    for i in range(n_layers):
        hidden_size = trial.suggest_int(f'hidden_size_l{i}', 32, 256, log=True)
        hidden_sizes.append(hidden_size)

    dropout_rate = trial.suggest_float('dropout', 0.0, 0.5)
    activation_name = trial.suggest_categorical('activation', ['relu', 'tanh', 'elu'])

    # æ´»æ€§åŒ–é–¢æ•°ã®é¸æŠ
    if activation_name == 'relu':
        activation = nn.ReLU()
    elif activation_name == 'tanh':
        activation = nn.Tanh()
    else:
        activation = nn.ELU()

    # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ§‹ç¯‰
    layers = []
    in_features = input_size

    for hidden_size in hidden_sizes:
        layers.append(nn.Linear(in_features, hidden_size))
        layers.append(activation)
        layers.append(nn.Dropout(dropout_rate))
        in_features = hidden_size

    layers.append(nn.Linear(in_features, output_size))

    model = nn.Sequential(*layers)
    return model

# Objectiveé–¢æ•°
def objective(trial):
    # ãƒ¢ãƒ‡ãƒ«ã®ä½œæˆ
    model = create_model(trial, input_size=20, output_size=2).to(device)

    # ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãƒ¼ã®ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    optimizer_name = trial.suggest_categorical('optimizer', ['Adam', 'SGD', 'RMSprop'])
    lr = trial.suggest_float('lr', 1e-5, 1e-1, log=True)

    if optimizer_name == 'Adam':
        optimizer = optim.Adam(model.parameters(), lr=lr)
    elif optimizer_name == 'SGD':
        momentum = trial.suggest_float('momentum', 0.0, 0.99)
        optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)
    else:
        optimizer = optim.RMSprop(model.parameters(), lr=lr)

    # ãƒãƒƒãƒã‚µã‚¤ã‚º
    batch_size = trial.suggest_int('batch_size', 16, 256, step=16)

    # DataLoader
    train_dataset = TensorDataset(X_train_t, y_train_t)
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)

    # æå¤±é–¢æ•°
    criterion = nn.CrossEntropyLoss()

    # è¨“ç·´ãƒ«ãƒ¼ãƒ—
    n_epochs = 20

    for epoch in range(n_epochs):
        model.train()
        train_loss = 0.0

        for batch_X, batch_y in train_loader:
            optimizer.zero_grad()
            outputs = model(batch_X)
            loss = criterion(outputs, batch_y)
            loss.backward()
            optimizer.step()
            train_loss += loss.item()

        # æ¤œè¨¼ï¼ˆãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆï¼‰
        model.eval()
        with torch.no_grad():
            outputs = model(X_test_t)
            _, predicted = torch.max(outputs.data, 1)
            accuracy = (predicted == y_test_t).sum().item() / len(y_test_t)

        # é€”ä¸­çµŒéã‚’å ±å‘Šï¼ˆPruningç”¨ï¼‰
        trial.report(accuracy, epoch)

        # Pruningã®åˆ¤å®š
        if trial.should_prune():
            raise optuna.TrialPruned()

    return accuracy

# Studyä½œæˆã¨æœ€é©åŒ–
study = optuna.create_study(
    direction='maximize',
    sampler=optuna.samplers.TPESampler(seed=42),
    pruner=optuna.pruners.MedianPruner(
        n_startup_trials=10,
        n_warmup_steps=5
    )
)

print("\n=== æ·±å±¤å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®æœ€é©åŒ–é–‹å§‹ ===")
study.optimize(objective, n_trials=50, timeout=600)

# çµæœã®è¡¨ç¤º
print("\n=== æœ€é©åŒ–å®Œäº† ===")
print(f"æœ€è‰¯ã®ç²¾åº¦: {study.best_value:.4f}")
print(f"\næœ€è‰¯ã®ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:")
for key, value in study.best_params.items():
    print(f"  {key}: {value}")

# çµ±è¨ˆæƒ…å ±
n_complete = len([t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE])
n_pruned = len([t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED])
print(f"\nå®Œäº†ã—ãŸè©¦è¡Œ: {n_complete}")
print(f"æåˆˆã‚Šã•ã‚ŒãŸè©¦è¡Œ: {n_pruned}")
</code></pre>

<h3>å¯è¦–åŒ–</h3>

<p>Optunaã¯å¼·åŠ›ãªå¯è¦–åŒ–æ©Ÿèƒ½ã‚’æä¾›ã—ã¾ã™ï¼š</p>

<pre><code class="language-python">import optuna
from optuna.visualization import (
    plot_optimization_history,
    plot_param_importances,
    plot_slice,
    plot_parallel_coordinate,
    plot_contour
)
import matplotlib.pyplot as plt

# 1. æœ€é©åŒ–å±¥æ­´
fig = plot_optimization_history(study)
fig.show()

# 2. ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿é‡è¦åº¦
fig = plot_param_importances(study)
fig.show()

# 3. ã‚¹ãƒ©ã‚¤ã‚¹ãƒ—ãƒ­ãƒƒãƒˆï¼ˆå„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å½±éŸ¿ï¼‰
fig = plot_slice(study)
fig.show()

# 4. å¹³è¡Œåº§æ¨™ãƒ—ãƒ­ãƒƒãƒˆ
fig = plot_parallel_coordinate(study)
fig.show()

# 5. ç­‰é«˜ç·šãƒ—ãƒ­ãƒƒãƒˆï¼ˆ2æ¬¡å…ƒã®é–¢ä¿‚ï¼‰
fig = plot_contour(study, params=['lr', 'n_layers'])
fig.show()

# Matplotlibã§ã‚«ã‚¹ã‚¿ãƒ Plot
fig, axes = plt.subplots(2, 2, figsize=(14, 10))

# 1. è©¦è¡Œã”ã¨ã®ç²¾åº¦
trial_numbers = [t.number for t in study.trials]
values = [t.value for t in study.trials if t.value is not None]
axes[0, 0].plot(trial_numbers[:len(values)], values, 'o-', alpha=0.6)
axes[0, 0].axhline(y=study.best_value, color='r',
                   linestyle='--', label=f'æœ€è‰¯: {study.best_value:.4f}')
axes[0, 0].set_xlabel('Trialç•ªå·')
axes[0, 0].set_ylabel('ç²¾åº¦')
axes[0, 0].set_title('è©¦è¡Œã”ã¨ã®ç²¾åº¦æ¨ç§»')
axes[0, 0].legend()
axes[0, 0].grid(True, alpha=0.3)

# 2. å­¦ç¿’ç‡ vs ç²¾åº¦
lrs = [t.params['lr'] for t in study.trials if t.value is not None]
values = [t.value for t in study.trials if t.value is not None]
axes[0, 1].scatter(lrs, values, alpha=0.6, s=50, edgecolors='black')
axes[0, 1].set_xscale('log')
axes[0, 1].set_xlabel('å­¦ç¿’ç‡')
axes[0, 1].set_ylabel('ç²¾åº¦')
axes[0, 1].set_title('å­¦ç¿’ç‡ vs ç²¾åº¦')
axes[0, 1].grid(True, alpha=0.3)

# 3. å±¤æ•° vs ç²¾åº¦
n_layers_list = [t.params['n_layers'] for t in study.trials if t.value is not None]
values = [t.value for t in study.trials if t.value is not None]
axes[1, 0].scatter(n_layers_list, values, alpha=0.6, s=50, edgecolors='black')
axes[1, 0].set_xlabel('å±¤æ•°')
axes[1, 0].set_ylabel('ç²¾åº¦')
axes[1, 0].set_title('å±¤æ•° vs ç²¾åº¦')
axes[1, 0].grid(True, alpha=0.3)

# 4. ãƒãƒƒãƒã‚µã‚¤ã‚º vs ç²¾åº¦
batch_sizes = [t.params['batch_size'] for t in study.trials if t.value is not None]
values = [t.value for t in study.trials if t.value is not None]
axes[1, 1].scatter(batch_sizes, values, alpha=0.6, s=50, edgecolors='black')
axes[1, 1].set_xlabel('ãƒãƒƒãƒã‚µã‚¤ã‚º')
axes[1, 1].set_ylabel('ç²¾åº¦')
axes[1, 1].set_title('ãƒãƒƒãƒã‚µã‚¤ã‚º vs ç²¾åº¦')
axes[1, 1].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
</code></pre>

<h3>Optuna Dashboard</h3>

<p>ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªWebãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã§çµæœã‚’å¯è¦–åŒ–ï¼š</p>

<pre><code class="language-bash"># ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install optuna-dashboard

# ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰èµ·å‹•
optuna-dashboard sqlite:///optuna_study.db
</code></pre>

<p>ãƒ–ãƒ©ã‚¦ã‚¶ã§ <code>http://127.0.0.1:8080</code> ã«ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ã¨ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§æœ€é©åŒ–ã®é€²æ—ã‚’ç¢ºèªã§ãã¾ã™ã€‚</p>

<hr>

<h2>2.6 æœ¬ç« ã®ã¾ã¨ã‚</h2>

<h3>å­¦ã‚“ã ã“ã¨</h3>

<ol>
<li><p><strong>ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã®åŸç†</strong></p>
<ul>
<li>ã‚µãƒ­ã‚²ãƒ¼ãƒˆãƒ¢ãƒ‡ãƒ«ï¼ˆã‚¬ã‚¦ã‚¹éç¨‹ï¼‰ã§ç›®çš„é–¢æ•°ã‚’è¿‘ä¼¼</li>
<li>ç²å¾—é–¢æ•°ï¼ˆEI, UCB, PIï¼‰ã§æ¬¡ã®æ¢ç´¢ç‚¹ã‚’æ±ºå®š</li>
<li>æ¢ç´¢ã¨æ´»ç”¨ã®ãƒãƒ©ãƒ³ã‚¹ã§åŠ¹ç‡çš„ã«æœ€é©åŒ–</li>
</ul></li>

<li><p><strong>TPEã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ </strong></p>
<ul>
<li>P(x|y)ã‚’ãƒ¢ãƒ‡ãƒ«åŒ–ã™ã‚‹åŠ¹ç‡çš„ãªæ‰‹æ³•</li>
<li>é«˜æ¬¡å…ƒãƒ»ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°ã«å¼·ã„</li>
<li>ä¸¦åˆ—åŒ–ãŒå®¹æ˜“</li>
</ul></li>

<li><p><strong>Optunaã®åŸºæœ¬</strong></p>
<ul>
<li>Study, Trial, Objectiveã®æ¦‚å¿µ</li>
<li>Define-by-Run APIã§æŸ”è»Ÿãªæ¢ç´¢ç©ºé–“å®šç¾©</li>
<li>è±Šå¯Œãªsuggest_*ãƒ¡ã‚½ãƒƒãƒ‰</li>
</ul></li>

<li><p><strong>å®Ÿè·µãƒ†ã‚¯ãƒ‹ãƒƒã‚¯</strong></p>
<ul>
<li>Pruningã§è¨ˆç®—æ™‚é–“ã‚’å‰Šæ¸›</li>
<li>ä¸¦åˆ—æœ€é©åŒ–ã§é«˜é€ŸåŒ–</li>
<li>æ¡ä»¶ä»˜ããƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æ‰±ã„</li>
</ul></li>

<li><p><strong>æ·±å±¤å­¦ç¿’ã¸ã®å¿œç”¨</strong></p>
<ul>
<li>PyTorchãƒ¢ãƒ‡ãƒ«ã®çµ±åˆ</li>
<li>å­¦ç¿’ç‡ã€ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã€ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãƒ¼ã®æœ€é©åŒ–</li>
<li>å¯è¦–åŒ–ã«ã‚ˆã‚‹æ´å¯Ÿã®ç²å¾—</li>
</ul></li>
</ol>

<h3>ãƒ™ã‚¤ã‚ºæœ€é©åŒ– vs ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ¼ãƒ</h3>

<table>
<thead>
<tr>
<th>å´é¢</th>
<th>ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ¼ãƒ</th>
<th>ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ï¼ˆOptunaï¼‰</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>è©¦è¡Œå›æ•°</strong></td>
<td>å¤šæ•°å¿…è¦</td>
<td>å°‘æ•°ã§åæŸ</td>
</tr>
<tr>
<td><strong>éå»æƒ…å ±ã®æ´»ç”¨</strong></td>
<td>ãªã—</td>
<td>ã‚ã‚Šï¼ˆã‚µãƒ­ã‚²ãƒ¼ãƒˆãƒ¢ãƒ‡ãƒ«ï¼‰</td>
</tr>
<tr>
<td><strong>è¨ˆç®—ã‚³ã‚¹ãƒˆ</strong></td>
<td>ä½ã„</td>
<td>ã‚„ã‚„é«˜ã„ï¼ˆTPEã¯è»½é‡ï¼‰</td>
</tr>
<tr>
<td><strong>é«˜æ¬¡å…ƒæ€§èƒ½</strong></td>
<td>è‰¯å¥½</td>
<td>TPEã¯è‰¯å¥½ã€GPã¯ä½ä¸‹</td>
</tr>
<tr>
<td><strong>ä¸¦åˆ—åŒ–</strong></td>
<td>å®¹æ˜“</td>
<td>å®¹æ˜“ï¼ˆOptunaï¼‰</td>
</tr>
<tr>
<td><strong>å®Ÿè£…ã®è¤‡é›‘ã•</strong></td>
<td>ã‚·ãƒ³ãƒ—ãƒ«</td>
<td>Optunaã§ç°¡å˜</td>
</tr>
</tbody>
</table>

<h3>æ¨å¥¨ã™ã‚‹ä½¿ã„åˆ†ã‘</h3>

<table>
<thead>
<tr>
<th>çŠ¶æ³</th>
<th>æ¨å¥¨æ‰‹æ³•</th>
<th>ç†ç”±</th>
</tr>
</thead>
<tbody>
<tr>
<td>è¨“ç·´ã‚³ã‚¹ãƒˆãŒé«˜ã„</td>
<td>Optuna + Pruning</td>
<td>æ—©æœŸçµ‚äº†ã§åŠ¹ç‡åŒ–</td>
</tr>
<tr>
<td>ä½æ¬¡å…ƒï¼ˆ< 10ï¼‰</td>
<td>ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒ or Optuna</td>
<td>ã©ã¡ã‚‰ã‚‚æœ‰åŠ¹</td>
</tr>
<tr>
<td>é«˜æ¬¡å…ƒï¼ˆ> 20ï¼‰</td>
<td>Optunaï¼ˆTPEï¼‰</td>
<td>æ¬¡å…ƒã®å‘ªã„ã«å¼·ã„</td>
</tr>
<tr>
<td>ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°å¤šã„</td>
<td>Optuna</td>
<td>è‡ªç„¶ã«æ‰±ãˆã‚‹</td>
</tr>
<tr>
<td>åˆæœŸæ¢ç´¢</td>
<td>ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ¼ãƒ</td>
<td>ã‚·ãƒ³ãƒ—ãƒ«ã§é«˜é€Ÿ</td>
</tr>
<tr>
<td>æœ€çµ‚èª¿æ•´</td>
<td>Optuna</td>
<td>ç²¾å¯†ãªæœ€é©åŒ–</td>
</tr>
</tbody>
</table>

<h3>æ¬¡ã®ç« ã¸</h3>

<p>ç¬¬3ç« ã§ã¯ã€<strong>è‡ªå‹•æ©Ÿæ¢°å­¦ç¿’ï¼ˆAutoMLï¼‰</strong>ã‚’å­¦ã³ã¾ã™ï¼š</p>
<ul>
<li>Auto-sklearn: è‡ªå‹•ãƒ¢ãƒ‡ãƒ«é¸æŠã¨ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«</li>
<li>H2O AutoML: å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿å‘ã‘</li>
<li>PyCaret: ãƒ­ãƒ¼ã‚³ãƒ¼ãƒ‰ML</li>
<li>TPOT: éºä¼çš„ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°</li>
<li>AutoMLã®é™ç•Œã¨ä½¿ã„ã©ã“ã‚</li>
</ul>

<hr>

<h2>å‚è€ƒæ–‡çŒ®</h2>

<ol>
<li>Akiba, T., Sano, S., Yanase, T., Ohta, T., & Koyama, M. (2019). Optuna: A Next-generation Hyperparameter Optimization Framework. <em>Proceedings of the 25th ACM SIGKDD</em>.</li>
<li>Bergstra, J., Bardenet, R., Bengio, Y., & KÃ©gl, B. (2011). Algorithms for Hyper-Parameter Optimization. <em>NIPS</em>.</li>
<li>Shahriari, B., Swersky, K., Wang, Z., Adams, R. P., & de Freitas, N. (2016). Taking the Human Out of the Loop: A Review of Bayesian Optimization. <em>Proceedings of the IEEE</em>, 104(1), 148-175.</li>
<li>Snoek, J., Larochelle, H., & Adams, R. P. (2012). Practical Bayesian Optimization of Machine Learning Algorithms. <em>NIPS</em>.</li>
<li>Falkner, S., Klein, A., & Hutter, F. (2018). BOHB: Robust and Efficient Hyperparameter Optimization at Scale. <em>ICML</em>.</li>
</ol>

<div class="navigation">
    <a href="chapter1-grid-random-search.html" class="nav-button">â† å‰ã®ç« : ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒã¨ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ¼ãƒ</a>
    <a href="chapter3-automl.html" class="nav-button">æ¬¡ã®ç« : AutoML â†’</a>
</div>

    </main>

    
    <section class="disclaimer">
        <h3>å…è²¬äº‹é …</h3>
        <ul>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯æ•™è‚²ãƒ»ç ”ç©¶ãƒ»æƒ…å ±æä¾›ã®ã¿ã‚’ç›®çš„ã¨ã—ã¦ãŠã‚Šã€å°‚é–€çš„ãªåŠ©è¨€(æ³•å¾‹ãƒ»ä¼šè¨ˆãƒ»æŠ€è¡“çš„ä¿è¨¼ãªã©)ã‚’æä¾›ã™ã‚‹ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŠã‚ˆã³ä»˜éšã™ã‚‹ã‚³ãƒ¼ãƒ‰ä¾‹ã¯ã€Œç¾çŠ¶æœ‰å§¿(AS IS)ã€ã§æä¾›ã•ã‚Œã€æ˜ç¤ºã¾ãŸã¯é»™ç¤ºã‚’å•ã‚ãšã€å•†å“æ€§ã€ç‰¹å®šç›®çš„é©åˆæ€§ã€æ¨©åˆ©éä¾µå®³ã€æ­£ç¢ºæ€§ãƒ»å®Œå…¨æ€§ã€å‹•ä½œãƒ»å®‰å…¨æ€§ç­‰ã„ã‹ãªã‚‹ä¿è¨¼ã‚‚ã—ã¾ã›ã‚“ã€‚</li>
            <li>å¤–éƒ¨ãƒªãƒ³ã‚¯ã€ç¬¬ä¸‰è€…ãŒæä¾›ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ»ãƒ„ãƒ¼ãƒ«ãƒ»ãƒ©ã‚¤ãƒ–ãƒ©ãƒªç­‰ã®å†…å®¹ãƒ»å¯ç”¨æ€§ãƒ»å®‰å…¨æ€§ã«ã¤ã„ã¦ã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯ä¸€åˆ‡ã®è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®åˆ©ç”¨ãƒ»å®Ÿè¡Œãƒ»è§£é‡ˆã«ã‚ˆã‚Šç›´æ¥çš„ãƒ»é–“æ¥çš„ãƒ»ä»˜éšçš„ãƒ»ç‰¹åˆ¥ãƒ»çµæœçš„ãƒ»æ‡²ç½°çš„æå®³ãŒç”Ÿã˜ãŸå ´åˆã§ã‚‚ã€é©ç”¨æ³•ã§è¨±å®¹ã•ã‚Œã‚‹æœ€å¤§é™ã®ç¯„å›²ã§ã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å†…å®¹ã¯ã€äºˆå‘Šãªãå¤‰æ›´ãƒ»æ›´æ–°ãƒ»æä¾›åœæ­¢ã•ã‚Œã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®è‘—ä½œæ¨©ãƒ»ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯æ˜è¨˜ã•ã‚ŒãŸæ¡ä»¶(ä¾‹: CC BY 4.0)ã«å¾“ã„ã¾ã™ã€‚å½“è©²ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯é€šå¸¸ã€ç„¡ä¿è¨¼æ¡é …ã‚’å«ã¿ã¾ã™ã€‚</li>
        </ul>
    </section>

<footer>
        <p><strong>ä½œæˆè€…</strong>: AI Terakoya Content Team</p>
        <p><strong>ãƒãƒ¼ã‚¸ãƒ§ãƒ³</strong>: 1.0 | <strong>ä½œæˆæ—¥</strong>: 2025-10-21</p>
        <p><strong>ãƒ©ã‚¤ã‚»ãƒ³ã‚¹</strong>: Creative Commons BY 4.0</p>
        <p>Â© 2025 AI Terakoya. All rights reserved.</p>
    </footer>
</body>
</html>
