<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ç¬¬3ç« ï¼šã‚¯ãƒ©ã‚¦ãƒ‰ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆ - AI Terakoya</title>

    <style>
        :root {
            --color-primary: #2c3e50;
            --color-primary-dark: #1a252f;
            --color-accent: #7b2cbf;
            --color-accent-light: #9d4edd;
            --color-text: #2d3748;
            --color-text-light: #4a5568;
            --color-bg: #ffffff;
            --color-bg-alt: #f7fafc;
            --color-border: #e2e8f0;
            --color-code-bg: #f8f9fa;
            --color-link: #3182ce;
            --color-link-hover: #2c5aa0;

            --spacing-xs: 0.5rem;
            --spacing-sm: 1rem;
            --spacing-md: 1.5rem;
            --spacing-lg: 2rem;
            --spacing-xl: 3rem;

            --font-body: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            --font-mono: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;

            --border-radius: 8px;
            --box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: var(--font-body);
            line-height: 1.7;
            color: var(--color-text);
            background-color: var(--color-bg);
            font-size: 16px;
        }

        header {
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            padding: var(--spacing-xl) var(--spacing-md);
            margin-bottom: var(--spacing-xl);
            box-shadow: var(--box-shadow);
        }

        .header-content {
            max-width: 900px;
            margin: 0 auto;
        }

        h1 {
            font-size: 2rem;
            font-weight: 700;
            margin-bottom: var(--spacing-sm);
            line-height: 1.2;
        }

        .subtitle {
            font-size: 1.1rem;
            opacity: 0.95;
            font-weight: 400;
            margin-bottom: var(--spacing-md);
        }

        .meta {
            display: flex;
            flex-wrap: wrap;
            gap: var(--spacing-md);
            font-size: 0.9rem;
            opacity: 0.9;
        }

        .meta-item {
            display: flex;
            align-items: center;
            gap: 0.3rem;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 0 var(--spacing-md) var(--spacing-xl);
        }

        h2 {
            font-size: 1.75rem;
            color: var(--color-primary);
            margin-top: var(--spacing-xl);
            margin-bottom: var(--spacing-md);
            padding-bottom: var(--spacing-xs);
            border-bottom: 3px solid var(--color-accent);
        }

        h3 {
            font-size: 1.4rem;
            color: var(--color-primary);
            margin-top: var(--spacing-lg);
            margin-bottom: var(--spacing-sm);
        }

        h4 {
            font-size: 1.1rem;
            color: var(--color-primary-dark);
            margin-top: var(--spacing-md);
            margin-bottom: var(--spacing-sm);
        }

        p {
            margin-bottom: var(--spacing-md);
            color: var(--color-text);
        }

        a {
            color: var(--color-link);
            text-decoration: none;
            transition: color 0.2s;
        }

        a:hover {
            color: var(--color-link-hover);
            text-decoration: underline;
        }

        ul, ol {
            margin-left: var(--spacing-lg);
            margin-bottom: var(--spacing-md);
        }

        li {
            margin-bottom: var(--spacing-xs);
            color: var(--color-text);
        }

        pre {
            background-color: var(--color-code-bg);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            overflow-x: auto;
            margin-bottom: var(--spacing-md);
            font-family: var(--font-mono);
            font-size: 0.9rem;
            line-height: 1.5;
        }

        code {
            font-family: var(--font-mono);
            font-size: 0.9em;
            background-color: var(--color-code-bg);
            padding: 0.2em 0.4em;
            border-radius: 3px;
        }

        pre code {
            background-color: transparent;
            padding: 0;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: var(--spacing-md);
            font-size: 0.95rem;
        }

        th, td {
            border: 1px solid var(--color-border);
            padding: var(--spacing-sm);
            text-align: left;
        }

        th {
            background-color: var(--color-bg-alt);
            font-weight: 600;
            color: var(--color-primary);
        }

        blockquote {
            border-left: 4px solid var(--color-accent);
            padding-left: var(--spacing-md);
            margin: var(--spacing-md) 0;
            color: var(--color-text-light);
            font-style: italic;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        .mermaid {
            text-align: center;
            margin: var(--spacing-lg) 0;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        details {
            background-color: var(--color-bg-alt);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            margin-bottom: var(--spacing-md);
        }

        summary {
            cursor: pointer;
            font-weight: 600;
            color: var(--color-primary);
            user-select: none;
            padding: var(--spacing-xs);
            margin: calc(-1 * var(--spacing-md));
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        summary:hover {
            background-color: rgba(123, 44, 191, 0.1);
        }

        details[open] summary {
            margin-bottom: var(--spacing-md);
            border-bottom: 1px solid var(--color-border);
        }

        .navigation {
            display: flex;
            justify-content: space-between;
            gap: var(--spacing-md);
            margin: var(--spacing-xl) 0;
            padding-top: var(--spacing-lg);
            border-top: 2px solid var(--color-border);
        }

        .nav-button {
            flex: 1;
            padding: var(--spacing-md);
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            border-radius: var(--border-radius);
            text-align: center;
            font-weight: 600;
            transition: transform 0.2s, box-shadow 0.2s;
            box-shadow: var(--box-shadow);
        }

        .nav-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
            text-decoration: none;
        }

        footer {
            margin-top: var(--spacing-xl);
            padding: var(--spacing-lg) var(--spacing-md);
            background-color: var(--color-bg-alt);
            border-top: 1px solid var(--color-border);
            text-align: center;
            font-size: 0.9rem;
            color: var(--color-text-light);
        }
        .disclaimer {
            max-width: 900px;
            margin: 2rem auto;
            padding: 1.5rem;
            background: #f8f9fa;
            border-left: 4px solid #6c757d;
            border-radius: 4px;
        }

        .disclaimer h3 {
            color: #495057;
            margin-bottom: 1rem;
            font-size: 1.1rem;
        }

        .disclaimer ul {
            list-style: none;
            padding-left: 0;
        }

        .disclaimer li {
            padding: 0.5rem 0;
            padding-left: 1.5rem;
            position: relative;
            font-size: 0.9rem;
            color: #6c757d;
            line-height: 1.6;
        }

        .disclaimer li::before {
            content: "âš ï¸";
            position: absolute;
            left: 0;
        }


        @media (max-width: 768px) {
            h1 {
                font-size: 1.5rem;
            }

            h2 {
                font-size: 1.4rem;
            }

            h3 {
                font-size: 1.2rem;
            }

            .meta {
                font-size: 0.85rem;
            }

            .navigation {
                flex-direction: column;
            }

            table {
                font-size: 0.85rem;
            }

            th, td {
                padding: var(--spacing-xs);
            }
        }
    
        
    
        /* Breadcrumb styles */
        .breadcrumb {
            background: #f7fafc;
            padding: 0.75rem 1rem;
            border-bottom: 1px solid #e2e8f0;
            font-size: 0.9rem;
        }

        .breadcrumb-content {
            max-width: 900px;
            margin: 0 auto;
            display: flex;
            align-items: center;
            flex-wrap: wrap;
            gap: 0.5rem;
        }

        .breadcrumb a {
            color: #667eea;
            text-decoration: none;
            transition: color 0.2s;
        }

        .breadcrumb a:hover {
            color: #764ba2;
            text-decoration: underline;
        }

        .breadcrumb-separator {
            color: #a0aec0;
            margin: 0 0.25rem;
        }

        .breadcrumb-current {
            color: #4a5568;
            font-weight: 500;
        }
    </style>

    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
        mermaid.initialize({ startOnLoad: true, theme: 'default' });
    </script>

    <style>
        /* Locale Switcher Styles */
        .locale-switcher {
            display: flex;
            align-items: center;
            gap: 0.5rem;
            padding: 0.5rem 1rem;
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
            border-radius: 6px;
            font-size: 0.9rem;
            margin-bottom: 1rem;
            box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);
        }

        .current-locale {
            font-weight: 600;
            color: #7b2cbf;
            display: flex;
            align-items: center;
            gap: 0.25rem;
        }

        .locale-separator {
            color: #adb5bd;
            font-weight: 300;
        }

        .locale-link {
            color: #f093fb;
            text-decoration: none;
            font-weight: 500;
            transition: all 0.2s ease;
            display: flex;
            align-items: center;
            gap: 0.25rem;
            padding: 0.2rem 0.5rem;
            border-radius: 4px;
        }

        .locale-link:hover {
            background: rgba(240, 147, 251, 0.1);
            color: #d07be8;
            transform: translateY(-1px);
        }

        .locale-meta {
            color: #868e96;
            font-size: 0.85rem;
            font-style: italic;
            margin-left: auto;
        }

        @media (max-width: 768px) {
            .locale-switcher {
                font-size: 0.85rem;
                padding: 0.4rem 0.8rem;
            }
            .locale-meta {
                display: none;
            }
        }
    </style>
</head>
<body>
            <div class="locale-switcher">
<span class="current-locale">ğŸŒ JP</span>
<span class="locale-separator">|</span>
<a href="../../../en/ML/model-deployment-introduction/chapter3-cloud-deployment.html" class="locale-link">ğŸ‡¬ğŸ‡§ EN</a>
<span class="locale-separator">|</span>
<span class="locale-meta">Last sync: 2025-11-16</span>
</div>
<nav class="breadcrumb">
        <div class="breadcrumb-content">
            <a href="../../index.html">AIå¯ºå­å±‹ãƒˆãƒƒãƒ—</a><span class="breadcrumb-separator">â€º</span><a href="../../ML/index.html">æ©Ÿæ¢°å­¦ç¿’</a><span class="breadcrumb-separator">â€º</span><a href="../../ML/model-deployment-introduction/index.html">Model Deployment</a><span class="breadcrumb-separator">â€º</span><span class="breadcrumb-current">Chapter 3</span>
        </div>
    </nav>

        <header>
        <div class="header-content">
            <h1>ç¬¬3ç« ï¼šã‚¯ãƒ©ã‚¦ãƒ‰ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆ</h1>
            <p class="subtitle">AWSã€GCPã€Azureã§å®Ÿç¾ã™ã‚‹ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªMLã‚·ã‚¹ãƒ†ãƒ </p>
            <div class="meta">
                <span class="meta-item">ğŸ“– èª­äº†æ™‚é–“: 30-35åˆ†</span>
                <span class="meta-item">ğŸ“Š é›£æ˜“åº¦: ä¸­ç´š</span>
                <span class="meta-item">ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹: 8å€‹</span>
                <span class="meta-item">ğŸ“ æ¼”ç¿’å•é¡Œ: 3å•</span>
            </div>
        </div>
    </header>

    <main class="container">

<h2>å­¦ç¿’ç›®æ¨™</h2>
<p>ã“ã®ç« ã‚’èª­ã‚€ã“ã¨ã§ã€ä»¥ä¸‹ã‚’ç¿’å¾—ã§ãã¾ã™ï¼š</p>
<ul>
<li>âœ… ä¸»è¦ã‚¯ãƒ©ã‚¦ãƒ‰ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ï¼ˆAWSã€GCPã€Azureï¼‰ã®ç‰¹å¾´ã‚’ç†è§£ã™ã‚‹</li>
<li>âœ… AWS SageMakerã§ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ‡ãƒ—ãƒ­ã‚¤ã§ãã‚‹</li>
<li>âœ… AWS Lambdaã§ã‚µãƒ¼ãƒãƒ¼ãƒ¬ã‚¹æ¨è«–ç’°å¢ƒã‚’æ§‹ç¯‰ã§ãã‚‹</li>
<li>âœ… GCP Vertex AIã¨Azure MLã®åŸºæœ¬çš„ãªä½¿ã„æ–¹ã‚’ç†è§£ã™ã‚‹</li>
<li>âœ… Terraformã¨CI/CDã§ãƒãƒ«ãƒã‚¯ãƒ©ã‚¦ãƒ‰æˆ¦ç•¥ã‚’å®Ÿè£…ã§ãã‚‹</li>
</ul>

<hr>

<h2>3.1 ã‚¯ãƒ©ã‚¦ãƒ‰ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆã®é¸æŠè‚¢</h2>

<h3>ä¸»è¦ã‚¯ãƒ©ã‚¦ãƒ‰ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ æ¯”è¼ƒ</h3>

<p>æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆã«ã¯ã€ä¸»ã«3ã¤ã®ä¸»è¦ã‚¯ãƒ©ã‚¦ãƒ‰ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ãŒä½¿ç”¨ã•ã‚Œã¾ã™ã€‚</p>

<table>
<thead>
<tr>
<th>ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ </th>
<th>MLã‚µãƒ¼ãƒ“ã‚¹</th>
<th>å¼·ã¿</th>
<th>ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>AWS</strong></td>
<td>SageMaker, Lambda, ECS</td>
<td>æœ€å¤§ã®ã‚·ã‚§ã‚¢ã€è±Šå¯Œãªã‚µãƒ¼ãƒ“ã‚¹</td>
<td>ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚ºã€å¤§è¦æ¨¡ã‚·ã‚¹ãƒ†ãƒ </td>
</tr>
<tr>
<td><strong>GCP</strong></td>
<td>Vertex AI, Cloud Run</td>
<td>TensorFlowçµ±åˆã€BigQueryé€£æº</td>
<td>ãƒ‡ãƒ¼ã‚¿åˆ†æé‡è¦–ã€ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—</td>
</tr>
<tr>
<td><strong>Azure</strong></td>
<td>Azure ML, Functions</td>
<td>Microsoftè£½å“çµ±åˆ</td>
<td>ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚ºï¼ˆMicrosoftç’°å¢ƒï¼‰</td>
</tr>
</tbody>
</table>

<h3>ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆã‚µãƒ¼ãƒ“ã‚¹ã®ç¨®é¡</h3>

<table>
<thead>
<tr>
<th>ç¨®é¡</th>
<th>èª¬æ˜</th>
<th>AWS</th>
<th>GCP</th>
<th>Azure</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>ãƒãƒãƒ¼ã‚¸ãƒ‰</strong></td>
<td>ãƒ•ãƒ«ãƒãƒãƒ¼ã‚¸ãƒ‰MLãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ </td>
<td>SageMaker</td>
<td>Vertex AI</td>
<td>Azure ML</td>
</tr>
<tr>
<td><strong>ã‚µãƒ¼ãƒãƒ¼ãƒ¬ã‚¹</strong></td>
<td>ã‚¤ãƒ™ãƒ³ãƒˆé§†å‹•ã€è‡ªå‹•ã‚¹ã‚±ãƒ¼ãƒ«</td>
<td>Lambda</td>
<td>Cloud Functions</td>
<td>Azure Functions</td>
</tr>
<tr>
<td><strong>ã‚³ãƒ³ãƒ†ãƒŠ</strong></td>
<td>Docker/KubernetesåŸºç›¤</td>
<td>ECS/EKS</td>
<td>Cloud Run/GKE</td>
<td>AKS</td>
</tr>
</tbody>
</table>

<h3>ã‚³ã‚¹ãƒˆè€ƒæ…®</h3>

<p>ã‚¯ãƒ©ã‚¦ãƒ‰ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆã®ã‚³ã‚¹ãƒˆè¦å› ï¼š</p>

<ul>
<li><strong>ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°</strong>: ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚¿ã‚¤ãƒ—ã€ç¨¼åƒæ™‚é–“</li>
<li><strong>ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸</strong>: ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã€ãƒ­ã‚°ä¿å­˜</li>
<li><strong>ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯</strong>: ãƒ‡ãƒ¼ã‚¿è»¢é€é‡</li>
<li><strong>æ¨è«–ãƒªã‚¯ã‚¨ã‚¹ãƒˆ</strong>: APIå‘¼ã³å‡ºã—å›æ•°</li>
</ul>

<blockquote>
<p><strong>ã‚³ã‚¹ãƒˆæœ€é©åŒ–ã®ãƒã‚¤ãƒ³ãƒˆ</strong>: ã‚ªãƒ¼ãƒˆã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã€ã‚¹ãƒãƒƒãƒˆã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã€é©åˆ‡ãªã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚µã‚¤ã‚ºé¸æŠãŒé‡è¦ã§ã™ã€‚</p>
</blockquote>

<div class="mermaid">
graph TD
    A[ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆæˆ¦ç•¥] --> B[ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ãƒ‘ã‚¿ãƒ¼ãƒ³]
    B --> C{ãƒªã‚¯ã‚¨ã‚¹ãƒˆé »åº¦}
    C -->|é«˜é »åº¦ãƒ»å®‰å®š| D[ãƒãƒãƒ¼ã‚¸ãƒ‰<br/>SageMaker/Vertex AI]
    C -->|ä½é »åº¦ãƒ»ä¸è¦å‰‡| E[ã‚µãƒ¼ãƒãƒ¼ãƒ¬ã‚¹<br/>Lambda/Cloud Functions]
    C -->|ãƒãƒ¼ã‚¹ãƒˆå¯¾å¿œ| F[ã‚ªãƒ¼ãƒˆã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°<br/>ECS/Cloud Run]

    A --> G[ã‚³ã‚¹ãƒˆåˆ¶ç´„]
    G --> H{äºˆç®—}
    H -->|ä½äºˆç®—| I[ã‚µãƒ¼ãƒãƒ¼ãƒ¬ã‚¹]
    H -->|ä¸­äºˆç®—| J[ã‚³ãƒ³ãƒ†ãƒŠ]
    H -->|é«˜äºˆç®—| K[å°‚ç”¨ãƒãƒãƒ¼ã‚¸ãƒ‰]

    style D fill:#e3f2fd
    style E fill:#fff3e0
    style F fill:#f3e5f5
</div>

<hr>

<h2>3.2 AWS SageMakerãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆ</h2>

<h3>SageMaker Endpointã¨ã¯</h3>

<p><strong>Amazon SageMaker</strong>ã¯ã€æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰ã€è¨“ç·´ã€ãƒ‡ãƒ—ãƒ­ã‚¤ã‚’çµ±åˆçš„ã«è¡Œã†ãƒãƒãƒ¼ã‚¸ãƒ‰ã‚µãƒ¼ãƒ“ã‚¹ã§ã™ã€‚</p>

<h3>ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãƒ³ã‚°</h3>

<pre><code class="language-python"># model_package.py
import joblib
import numpy as np
from sklearn.ensemble import RandomForestClassifier

# ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´
model = RandomForestClassifier(n_estimators=100, random_state=42)
X_train = np.random.randn(1000, 10)
y_train = np.random.randint(0, 2, 1000)
model.fit(X_train, y_train)

# ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜
joblib.dump(model, 'model.joblib')
print("âœ“ ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸ: model.joblib")
</code></pre>

<h3>ã‚«ã‚¹ã‚¿ãƒ æ¨è«–ã‚¹ã‚¯ãƒªãƒ—ãƒˆ</h3>

<pre><code class="language-python"># inference.py
import joblib
import json
import numpy as np

def model_fn(model_dir):
    """ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰"""
    model = joblib.load(f"{model_dir}/model.joblib")
    return model

def input_fn(request_body, content_type):
    """å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ‘ãƒ¼ã‚¹"""
    if content_type == 'application/json':
        data = json.loads(request_body)
        return np.array(data['instances'])
    raise ValueError(f"Unsupported content type: {content_type}")

def predict_fn(input_data, model):
    """æ¨è«–å®Ÿè¡Œ"""
    predictions = model.predict(input_data)
    probabilities = model.predict_proba(input_data)
    return {
        'predictions': predictions.tolist(),
        'probabilities': probabilities.tolist()
    }

def output_fn(prediction, accept):
    """ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
    if accept == 'application/json':
        return json.dumps(prediction), accept
    raise ValueError(f"Unsupported accept type: {accept}")
</code></pre>

<h3>SageMakerã¸ã®ãƒ‡ãƒ—ãƒ­ã‚¤</h3>

<pre><code class="language-python">import boto3
import sagemaker
from sagemaker.sklearn.model import SKLearnModel
from datetime import datetime

# ã‚»ãƒƒã‚·ãƒ§ãƒ³è¨­å®š
session = sagemaker.Session()
role = 'arn:aws:iam::123456789012:role/SageMakerRole'
bucket = session.default_bucket()

# ãƒ¢ãƒ‡ãƒ«ã‚’S3ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
model_data = session.upload_data(
    path='model.joblib',
    bucket=bucket,
    key_prefix='models/sklearn-model'
)

# SageMakerãƒ¢ãƒ‡ãƒ«ã®ä½œæˆ
sklearn_model = SKLearnModel(
    model_data=model_data,
    role=role,
    entry_point='inference.py',
    framework_version='1.0-1',
    py_version='py3'
)

# ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®ãƒ‡ãƒ—ãƒ­ã‚¤
endpoint_name = f'sklearn-endpoint-{datetime.now().strftime("%Y%m%d-%H%M%S")}'
predictor = sklearn_model.deploy(
    initial_instance_count=1,
    instance_type='ml.m5.large',
    endpoint_name=endpoint_name
)

print(f"âœ“ ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’ãƒ‡ãƒ—ãƒ­ã‚¤ã—ã¾ã—ãŸ: {endpoint_name}")
print(f"âœ“ ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚¿ã‚¤ãƒ—: ml.m5.large")
print(f"âœ“ ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹æ•°: 1")
</code></pre>

<h3>æ¨è«–ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®å®Ÿè¡Œ</h3>

<pre><code class="language-python">import boto3
import json
import numpy as np

# SageMaker Runtimeã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
runtime = boto3.client('sagemaker-runtime', region_name='us-east-1')

# ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
test_data = {
    'instances': np.random.randn(5, 10).tolist()
}

# æ¨è«–ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
response = runtime.invoke_endpoint(
    EndpointName=endpoint_name,
    ContentType='application/json',
    Accept='application/json',
    Body=json.dumps(test_data)
)

# ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®ãƒ‘ãƒ¼ã‚¹
result = json.loads(response['Body'].read().decode())
print("\n=== æ¨è«–çµæœ ===")
print(f"äºˆæ¸¬: {result['predictions']}")
print(f"ç¢ºç‡: {result['probabilities']}")

# ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æƒ…å ±
print(f"\næ¨è«–æ™‚é–“: {response['ResponseMetadata']['HTTPHeaders'].get('x-amzn-invocation-timestamp', 'N/A')}")
</code></pre>

<h3>ã‚ªãƒ¼ãƒˆã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã®è¨­å®š</h3>

<pre><code class="language-python">import boto3

# Auto Scalingã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
autoscaling = boto3.client('application-autoscaling', region_name='us-east-1')

# ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®ç™»éŒ²
resource_id = f'endpoint/{endpoint_name}/variant/AllTraffic'
autoscaling.register_scalable_target(
    ServiceNamespace='sagemaker',
    ResourceId=resource_id,
    ScalableDimension='sagemaker:variant:DesiredInstanceCount',
    MinCapacity=1,
    MaxCapacity=5
)

# ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ãƒãƒªã‚·ãƒ¼ã®è¨­å®š
autoscaling.put_scaling_policy(
    PolicyName=f'{endpoint_name}-scaling-policy',
    ServiceNamespace='sagemaker',
    ResourceId=resource_id,
    ScalableDimension='sagemaker:variant:DesiredInstanceCount',
    PolicyType='TargetTrackingScaling',
    TargetTrackingScalingPolicyConfiguration={
        'TargetValue': 70.0,  # ç›®æ¨™CPUä½¿ç”¨ç‡70%
        'PredefinedMetricSpecification': {
            'PredefinedMetricType': 'SageMakerVariantInvocationsPerInstance'
        },
        'ScaleInCooldown': 300,   # ã‚¹ã‚±ãƒ¼ãƒ«ã‚¤ãƒ³å¾…æ©Ÿæ™‚é–“ï¼ˆç§’ï¼‰
        'ScaleOutCooldown': 60    # ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆå¾…æ©Ÿæ™‚é–“ï¼ˆç§’ï¼‰
    }
)

print("âœ“ ã‚ªãƒ¼ãƒˆã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã‚’è¨­å®šã—ã¾ã—ãŸ")
print(f"  æœ€å°ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹æ•°: 1")
print(f"  æœ€å¤§ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹æ•°: 5")
print(f"  ç›®æ¨™ãƒ¡ãƒˆãƒªãƒƒã‚¯: ãƒªã‚¯ã‚¨ã‚¹ãƒˆ/ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹")
</code></pre>

<blockquote>
<p><strong>ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹</strong>: æœ¬ç•ªç’°å¢ƒã§ã¯ã€æœ€å°2ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã§å¯ç”¨æ€§ã‚’ç¢ºä¿ã—ã€ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ãƒ‘ã‚¿ãƒ¼ãƒ³ã«å¿œã˜ã¦ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆé–¾å€¤ã‚’èª¿æ•´ã—ã¾ã™ã€‚</p>
</blockquote>

<hr>

<h2>3.3 AWS Lambdaã‚µãƒ¼ãƒãƒ¼ãƒ¬ã‚¹ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆ</h2>

<h3>ã‚µãƒ¼ãƒãƒ¼ãƒ¬ã‚¹ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®åˆ©ç‚¹</h3>

<ul>
<li><strong>ã‚³ã‚¹ãƒˆåŠ¹ç‡</strong>: å®Ÿè¡Œæ™‚é–“åˆ†ã®ã¿èª²é‡‘</li>
<li><strong>è‡ªå‹•ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°</strong>: åŒæ™‚å®Ÿè¡Œæ•°ã«å¿œã˜ã¦è‡ªå‹•èª¿æ•´</li>
<li><strong>é‹ç”¨è² è·è»½æ¸›</strong>: ã‚¤ãƒ³ãƒ•ãƒ©ç®¡ç†ä¸è¦</li>
<li><strong>é«˜å¯ç”¨æ€§</strong>: ãƒãƒ«ãƒAZè‡ªå‹•é…ç½®</li>
</ul>

<h3>Lambdaé–¢æ•°ã®ä½œæˆ</h3>

<pre><code class="language-python"># lambda_function.py
import json
import joblib
import numpy as np
import base64
import io

# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¹ã‚³ãƒ¼ãƒ—ã§ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ï¼ˆã‚³ãƒ¼ãƒ«ãƒ‰ã‚¹ã‚¿ãƒ¼ãƒˆæœ€é©åŒ–ï¼‰
model = None

def load_model():
    """ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ï¼ˆåˆå›ã®ã¿å®Ÿè¡Œï¼‰"""
    global model
    if model is None:
        # S3ã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã€ã¾ãŸã¯ãƒ¬ã‚¤ãƒ¤ãƒ¼ã«å«ã‚ã‚‹
        model = joblib.load('/opt/model.joblib')
    return model

def lambda_handler(event, context):
    """Lambdaé–¢æ•°ã®ãƒ¡ã‚¤ãƒ³ãƒãƒ³ãƒ‰ãƒ©ãƒ¼"""
    try:
        # ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰
        ml_model = load_model()

        # ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒœãƒ‡ã‚£ã®ãƒ‘ãƒ¼ã‚¹
        body = json.loads(event.get('body', '{}'))
        instances = body.get('instances', [])

        if not instances:
            return {
                'statusCode': 400,
                'body': json.dumps({'error': 'No instances provided'})
            }

        # æ¨è«–å®Ÿè¡Œ
        input_data = np.array(instances)
        predictions = ml_model.predict(input_data)
        probabilities = ml_model.predict_proba(input_data)

        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹
        response = {
            'predictions': predictions.tolist(),
            'probabilities': probabilities.tolist(),
            'model_version': '1.0'
        }

        return {
            'statusCode': 200,
            'headers': {
                'Content-Type': 'application/json',
                'Access-Control-Allow-Origin': '*'
            },
            'body': json.dumps(response)
        }

    except Exception as e:
        return {
            'statusCode': 500,
            'body': json.dumps({'error': str(e)})
        }
</code></pre>

<h3>ã‚³ãƒ³ãƒ†ãƒŠã‚¤ãƒ¡ãƒ¼ã‚¸ã§ã®ãƒ‡ãƒ—ãƒ­ã‚¤</h3>

<pre><code class="language-dockerfile"># Dockerfile
FROM public.ecr.aws/lambda/python:3.9

# ä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
COPY requirements.txt .
RUN pip install -r requirements.txt --target "${LAMBDA_TASK_ROOT}"

# ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚³ãƒ”ãƒ¼
COPY model.joblib ${LAMBDA_TASK_ROOT}/opt/

# Lambdaé–¢æ•°ã‚³ãƒ¼ãƒ‰ã®ã‚³ãƒ”ãƒ¼
COPY lambda_function.py ${LAMBDA_TASK_ROOT}

# ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã®æŒ‡å®š
CMD ["lambda_function.lambda_handler"]
</code></pre>

<pre><code class="language-bash">#!/bin/bash
# deploy.sh - Lambdaã‚³ãƒ³ãƒ†ãƒŠã‚¤ãƒ¡ãƒ¼ã‚¸ã®ãƒ“ãƒ«ãƒ‰ã¨ãƒ‡ãƒ—ãƒ­ã‚¤

# å¤‰æ•°è¨­å®š
AWS_REGION="us-east-1"
AWS_ACCOUNT_ID="123456789012"
ECR_REPO="ml-inference-lambda"
IMAGE_TAG="latest"

# ECRãƒªãƒã‚¸ãƒˆãƒªã®ä½œæˆï¼ˆåˆå›ã®ã¿ï¼‰
aws ecr create-repository \
    --repository-name ${ECR_REPO} \
    --region ${AWS_REGION} 2>/dev/null || true

# ECRã«ãƒ­ã‚°ã‚¤ãƒ³
aws ecr get-login-password --region ${AWS_REGION} | \
    docker login --username AWS --password-stdin \
    ${AWS_ACCOUNT_ID}.dkr.ecr.${AWS_REGION}.amazonaws.com

# Dockerã‚¤ãƒ¡ãƒ¼ã‚¸ã®ãƒ“ãƒ«ãƒ‰
docker build -t ${ECR_REPO}:${IMAGE_TAG} .

# ã‚¤ãƒ¡ãƒ¼ã‚¸ã®ã‚¿ã‚°ä»˜ã‘
docker tag ${ECR_REPO}:${IMAGE_TAG} \
    ${AWS_ACCOUNT_ID}.dkr.ecr.${AWS_REGION}.amazonaws.com/${ECR_REPO}:${IMAGE_TAG}

# ECRã«ãƒ—ãƒƒã‚·ãƒ¥
docker push ${AWS_ACCOUNT_ID}.dkr.ecr.${AWS_REGION}.amazonaws.com/${ECR_REPO}:${IMAGE_TAG}

echo "âœ“ ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’ECRã«ãƒ—ãƒƒã‚·ãƒ¥ã—ã¾ã—ãŸ"
</code></pre>

<h3>API Gatewayã¨ã®çµ±åˆ</h3>

<pre><code class="language-python">import boto3
import json

# API Gatewayä½œæˆ
apigateway = boto3.client('apigateway', region_name='us-east-1')
lambda_client = boto3.client('lambda', region_name='us-east-1')

# REST APIã®ä½œæˆ
api = apigateway.create_rest_api(
    name='ML-Inference-API',
    description='Machine Learning Inference API',
    endpointConfiguration={'types': ['REGIONAL']}
)
api_id = api['id']

# ãƒªã‚½ãƒ¼ã‚¹ã®å–å¾—
resources = apigateway.get_resources(restApiId=api_id)
root_id = resources['items'][0]['id']

# /predictãƒªã‚½ãƒ¼ã‚¹ã®ä½œæˆ
predict_resource = apigateway.create_resource(
    restApiId=api_id,
    parentId=root_id,
    pathPart='predict'
)

# POSTãƒ¡ã‚½ãƒƒãƒ‰ã®ä½œæˆ
apigateway.put_method(
    restApiId=api_id,
    resourceId=predict_resource['id'],
    httpMethod='POST',
    authorizationType='NONE'
)

# Lambdaçµ±åˆã®è¨­å®š
lambda_arn = f"arn:aws:lambda:us-east-1:123456789012:function:ml-inference"
apigateway.put_integration(
    restApiId=api_id,
    resourceId=predict_resource['id'],
    httpMethod='POST',
    type='AWS_PROXY',
    integrationHttpMethod='POST',
    uri=f'arn:aws:apigateway:us-east-1:lambda:path/2015-03-31/functions/{lambda_arn}/invocations'
)

# ãƒ‡ãƒ—ãƒ­ã‚¤
deployment = apigateway.create_deployment(
    restApiId=api_id,
    stageName='prod'
)

endpoint_url = f"https://{api_id}.execute-api.us-east-1.amazonaws.com/prod/predict"
print(f"âœ“ API Gatewayã‚’ãƒ‡ãƒ—ãƒ­ã‚¤ã—ã¾ã—ãŸ")
print(f"âœ“ ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ: {endpoint_url}")
</code></pre>

<h3>ã‚³ãƒ¼ãƒ«ãƒ‰ã‚¹ã‚¿ãƒ¼ãƒˆå¯¾ç­–</h3>

<p>Lambdaã®<strong>ã‚³ãƒ¼ãƒ«ãƒ‰ã‚¹ã‚¿ãƒ¼ãƒˆ</strong>ï¼ˆåˆå›èµ·å‹•ã®é…å»¶ï¼‰ã‚’è»½æ¸›ã™ã‚‹æ–¹æ³•ï¼š</p>

<table>
<thead>
<tr>
<th>æ‰‹æ³•</th>
<th>èª¬æ˜</th>
<th>åŠ¹æœ</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>ãƒ—ãƒ­ãƒ“ã‚¸ãƒ§ãƒ‹ãƒ³ã‚°åŒæ™‚å®Ÿè¡Œ</strong></td>
<td>å¸¸æ™‚èµ·å‹•ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ç¢ºä¿</td>
<td>ã‚³ãƒ¼ãƒ«ãƒ‰ã‚¹ã‚¿ãƒ¼ãƒˆå®Œå…¨å›é¿</td>
</tr>
<tr>
<td><strong>ãƒ¢ãƒ‡ãƒ«æœ€é©åŒ–</strong></td>
<td>è»½é‡ãƒ¢ãƒ‡ãƒ«ã€é‡å­åŒ–</td>
<td>ãƒ­ãƒ¼ãƒ‰æ™‚é–“çŸ­ç¸®</td>
</tr>
<tr>
<td><strong>ãƒ¬ã‚¤ãƒ¤ãƒ¼æ´»ç”¨</strong></td>
<td>ä¾å­˜é–¢ä¿‚ã‚’åˆ¥ãƒ¬ã‚¤ãƒ¤ãƒ¼ã«åˆ†é›¢</td>
<td>ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸å‰Šæ¸›</td>
</tr>
<tr>
<td><strong>å®šæœŸã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—</strong></td>
<td>EventBridgeã§å®šæœŸå®Ÿè¡Œ</td>
<td>ã‚¢ã‚¤ãƒ‰ãƒ«çŠ¶æ…‹å›é¿</td>
</tr>
</tbody>
</table>

<hr>

<h2>3.4 GCP Vertex AIã¨Azure ML</h2>

<h3>GCP Vertex AI Endpoints</h3>

<p><strong>Vertex AI</strong>ã¯ã€Googleã®ãƒãƒãƒ¼ã‚¸ãƒ‰MLãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã§ã€TensorFlowã¨ã®æ·±ã„çµ±åˆãŒç‰¹å¾´ã§ã™ã€‚</p>

<pre><code class="language-python"># vertex_ai_deploy.py
from google.cloud import aiplatform

# Vertex AIã®åˆæœŸåŒ–
aiplatform.init(
    project='my-gcp-project',
    location='us-central1',
    staging_bucket='gs://my-ml-models'
)

# ãƒ¢ãƒ‡ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
model = aiplatform.Model.upload(
    display_name='sklearn-classifier',
    artifact_uri='gs://my-ml-models/sklearn-model',
    serving_container_image_uri='us-docker.pkg.dev/vertex-ai/prediction/sklearn-cpu.1-0:latest'
)

# ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®ä½œæˆ
endpoint = aiplatform.Endpoint.create(display_name='sklearn-endpoint')

# ãƒ¢ãƒ‡ãƒ«ã®ãƒ‡ãƒ—ãƒ­ã‚¤
endpoint.deploy(
    model=model,
    deployed_model_display_name='sklearn-v1',
    machine_type='n1-standard-4',
    min_replica_count=1,
    max_replica_count=5,
    traffic_percentage=100
)

print(f"âœ“ ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’ãƒ‡ãƒ—ãƒ­ã‚¤ã—ã¾ã—ãŸ: {endpoint.resource_name}")

# æ¨è«–ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
instances = [[1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0]]
prediction = endpoint.predict(instances=instances)
print(f"äºˆæ¸¬çµæœ: {prediction.predictions}")
</code></pre>

<h3>Azure ML Managed Endpoints</h3>

<p><strong>Azure Machine Learning</strong>ã¯ã€Microsoft Azureã®ãƒãƒãƒ¼ã‚¸ãƒ‰æ©Ÿæ¢°å­¦ç¿’ã‚µãƒ¼ãƒ“ã‚¹ã§ã™ã€‚</p>

<pre><code class="language-python"># azure_ml_deploy.py
from azure.ai.ml import MLClient
from azure.ai.ml.entities import (
    ManagedOnlineEndpoint,
    ManagedOnlineDeployment,
    Model,
    Environment,
    CodeConfiguration
)
from azure.identity import DefaultAzureCredential

# Azure ML Clientã®åˆæœŸåŒ–
credential = DefaultAzureCredential()
ml_client = MLClient(
    credential=credential,
    subscription_id='subscription-id',
    resource_group_name='ml-resources',
    workspace_name='ml-workspace'
)

# ãƒ¢ãƒ‡ãƒ«ã®ç™»éŒ²
model = Model(
    path='./model',
    name='sklearn-classifier',
    description='Scikit-learn classification model'
)
registered_model = ml_client.models.create_or_update(model)

# ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®ä½œæˆ
endpoint = ManagedOnlineEndpoint(
    name='sklearn-endpoint',
    description='Sklearn classification endpoint',
    auth_mode='key'
)
ml_client.online_endpoints.begin_create_or_update(endpoint).result()

# ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆã®ä½œæˆ
deployment = ManagedOnlineDeployment(
    name='blue',
    endpoint_name='sklearn-endpoint',
    model=registered_model,
    environment='AzureML-sklearn-1.0-ubuntu20.04-py38-cpu',
    code_configuration=CodeConfiguration(
        code='./src',
        scoring_script='score.py'
    ),
    instance_type='Standard_DS3_v2',
    instance_count=1
)
ml_client.online_deployments.begin_create_or_update(deployment).result()

# ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã®å‰²ã‚Šå½“ã¦
endpoint.traffic = {'blue': 100}
ml_client.online_endpoints.begin_create_or_update(endpoint).result()

print(f"âœ“ Azure MLã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’ãƒ‡ãƒ—ãƒ­ã‚¤ã—ã¾ã—ãŸ: {endpoint.name}")
</code></pre>

<h3>ã‚¯ãƒ©ã‚¦ãƒ‰ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ æ¯”è¼ƒ</h3>

<table>
<thead>
<tr>
<th>æ©Ÿèƒ½</th>
<th>AWS SageMaker</th>
<th>GCP Vertex AI</th>
<th>Azure ML</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>ãƒ‡ãƒ—ãƒ­ã‚¤æ–¹æ³•</strong></td>
<td>Endpoint, Lambda</td>
<td>Endpoint, Cloud Run</td>
<td>Managed Endpoint</td>
</tr>
<tr>
<td><strong>ã‚ªãƒ¼ãƒˆã‚¹ã‚±ãƒ¼ãƒ«</strong></td>
<td>â—ï¼ˆæŸ”è»Ÿï¼‰</td>
<td>â—ï¼ˆè‡ªå‹•ï¼‰</td>
<td>â—‹ï¼ˆè¨­å®šå¿…è¦ï¼‰</td>
</tr>
<tr>
<td><strong>ãƒ¢ãƒ‡ãƒ«ç®¡ç†</strong></td>
<td>Model Registry</td>
<td>Model Registry</td>
<td>Model Registry</td>
</tr>
<tr>
<td><strong>ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°</strong></td>
<td>CloudWatch</td>
<td>Cloud Monitoring</td>
<td>Application Insights</td>
</tr>
<tr>
<td><strong>æ–™é‡‘ä½“ç³»</strong></td>
<td>ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹æ™‚é–“</td>
<td>ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹æ™‚é–“</td>
<td>ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹æ™‚é–“</td>
</tr>
<tr>
<td><strong>å­¦ç¿’ã‚³ã‚¹ãƒˆ</strong></td>
<td>ä¸­</td>
<td>ä½ï¼ˆGCPçµŒé¨“è€…ï¼‰</td>
<td>ä½ï¼ˆAzureçµŒé¨“è€…ï¼‰</td>
</tr>
</tbody>
</table>

<hr>

<h2>3.5 å®Ÿè·µï¼šãƒãƒ«ãƒã‚¯ãƒ©ã‚¦ãƒ‰æˆ¦ç•¥ã¨CI/CD</h2>

<h3>Terraformã«ã‚ˆã‚‹ã‚¤ãƒ³ãƒ•ãƒ©ç®¡ç†</h3>

<p><strong>Infrastructure as Codeï¼ˆIaCï¼‰</strong>ã§ã€å†ç¾å¯èƒ½ãªãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆã‚’å®Ÿç¾ã—ã¾ã™ã€‚</p>

<pre><code class="language-hcl"># terraform/main.tf - AWS SageMakerã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
terraform {
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 5.0"
    }
  }
}

provider "aws" {
  region = var.aws_region
}

# SageMakerå®Ÿè¡Œãƒ­ãƒ¼ãƒ«
resource "aws_iam_role" "sagemaker_role" {
  name = "sagemaker-execution-role"

  assume_role_policy = jsonencode({
    Version = "2012-10-17"
    Statement = [{
      Action = "sts:AssumeRole"
      Effect = "Allow"
      Principal = {
        Service = "sagemaker.amazonaws.com"
      }
    }]
  })
}

# SageMakerãƒ¢ãƒ‡ãƒ«
resource "aws_sagemaker_model" "ml_model" {
  name               = "sklearn-model-${var.environment}"
  execution_role_arn = aws_iam_role.sagemaker_role.arn

  primary_container {
    image          = var.container_image
    model_data_url = var.model_data_s3_uri
  }

  tags = {
    Environment = var.environment
    ManagedBy   = "Terraform"
  }
}

# SageMakerã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆè¨­å®š
resource "aws_sagemaker_endpoint_configuration" "endpoint_config" {
  name = "sklearn-endpoint-config-${var.environment}"

  production_variants {
    variant_name           = "AllTraffic"
    model_name             = aws_sagemaker_model.ml_model.name
    initial_instance_count = var.initial_instance_count
    instance_type          = var.instance_type
  }

  tags = {
    Environment = var.environment
    ManagedBy   = "Terraform"
  }
}

# SageMakerã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
resource "aws_sagemaker_endpoint" "endpoint" {
  name                 = "sklearn-endpoint-${var.environment}"
  endpoint_config_name = aws_sagemaker_endpoint_configuration.endpoint_config.name

  tags = {
    Environment = var.environment
    ManagedBy   = "Terraform"
  }
}

# å¤‰æ•°å®šç¾©
variable "aws_region" {
  default = "us-east-1"
}

variable "environment" {
  description = "Environment name (dev, staging, prod)"
  type        = string
}

variable "container_image" {
  description = "SageMaker container image URI"
  type        = string
}

variable "model_data_s3_uri" {
  description = "S3 URI of model artifacts"
  type        = string
}

variable "instance_type" {
  default = "ml.m5.large"
}

variable "initial_instance_count" {
  default = 1
}

# å‡ºåŠ›
output "endpoint_name" {
  value = aws_sagemaker_endpoint.endpoint.name
}

output "endpoint_arn" {
  value = aws_sagemaker_endpoint.endpoint.arn
}
</code></pre>

<h3>GitHub Actionsã«ã‚ˆã‚‹CI/CD</h3>

<pre><code class="language-yaml"># .github/workflows/deploy-ml-model.yml
name: Deploy ML Model

on:
  push:
    branches:
      - main
      - develop
  pull_request:
    branches:
      - main

env:
  AWS_REGION: us-east-1
  MODEL_BUCKET: ml-models-artifacts

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install pytest pytest-cov

      - name: Run tests
        run: |
          pytest tests/ --cov=src --cov-report=xml

      - name: Upload coverage
        uses: codecov/codecov-action@v3

  build-and-deploy:
    needs: test
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/develop'

    steps:
      - uses: actions/checkout@v3

      - name: Set environment
        run: |
          if [[ "${{ github.ref }}" == "refs/heads/main" ]]; then
            echo "ENVIRONMENT=prod" >> $GITHUB_ENV
          else
            echo "ENVIRONMENT=dev" >> $GITHUB_ENV
          fi

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Train and package model
        run: |
          python src/train.py
          tar -czf model.tar.gz model.joblib

      - name: Upload model to S3
        run: |
          TIMESTAMP=$(date +%Y%m%d-%H%M%S)
          aws s3 cp model.tar.gz \
            s3://${{ env.MODEL_BUCKET }}/${{ env.ENVIRONMENT }}/model-${TIMESTAMP}.tar.gz
          echo "MODEL_S3_URI=s3://${{ env.MODEL_BUCKET }}/${{ env.ENVIRONMENT }}/model-${TIMESTAMP}.tar.gz" >> $GITHUB_ENV

      - name: Build Docker image
        run: |
          docker build -t ml-inference:${{ github.sha }} .

      - name: Push to ECR
        run: |
          aws ecr get-login-password --region ${{ env.AWS_REGION }} | \
            docker login --username AWS --password-stdin \
            ${{ secrets.AWS_ACCOUNT_ID }}.dkr.ecr.${{ env.AWS_REGION }}.amazonaws.com

          docker tag ml-inference:${{ github.sha }} \
            ${{ secrets.AWS_ACCOUNT_ID }}.dkr.ecr.${{ env.AWS_REGION }}.amazonaws.com/ml-inference:${{ github.sha }}

          docker push \
            ${{ secrets.AWS_ACCOUNT_ID }}.dkr.ecr.${{ env.AWS_REGION }}.amazonaws.com/ml-inference:${{ github.sha }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2

      - name: Terraform Init
        working-directory: ./terraform
        run: terraform init

      - name: Terraform Plan
        working-directory: ./terraform
        run: |
          terraform plan \
            -var="environment=${{ env.ENVIRONMENT }}" \
            -var="model_data_s3_uri=${{ env.MODEL_S3_URI }}" \
            -var="container_image=${{ secrets.AWS_ACCOUNT_ID }}.dkr.ecr.${{ env.AWS_REGION }}.amazonaws.com/ml-inference:${{ github.sha }}" \
            -out=tfplan

      - name: Terraform Apply
        if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/develop'
        working-directory: ./terraform
        run: terraform apply -auto-approve tfplan

      - name: Smoke test
        run: |
          ENDPOINT_NAME=$(terraform -chdir=./terraform output -raw endpoint_name)
          python scripts/smoke_test.py --endpoint-name $ENDPOINT_NAME

  notify:
    needs: build-and-deploy
    runs-on: ubuntu-latest
    if: always()
    steps:
      - name: Send Slack notification
        uses: 8398a7/action-slack@v3
        with:
          status: ${{ job.status }}
          text: 'ML Model deployment ${{ job.status }}'
          webhook_url: ${{ secrets.SLACK_WEBHOOK }}
</code></pre>

<h3>ç’°å¢ƒåˆ¥ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆæˆ¦ç•¥</h3>

<div class="mermaid">
graph LR
    A[ã‚³ãƒ¼ãƒ‰å¤‰æ›´] --> B[GitHub Push]
    B --> C{ãƒ–ãƒ©ãƒ³ãƒ}
    C -->|develop| D[Devç’°å¢ƒ]
    C -->|staging| E[Stagingç’°å¢ƒ]
    C -->|main| F[Productionç’°å¢ƒ]

    D --> G[è‡ªå‹•ãƒ†ã‚¹ãƒˆ]
    E --> H[çµ±åˆãƒ†ã‚¹ãƒˆ]
    F --> I[ã‚¹ãƒ¢ãƒ¼ã‚¯ãƒ†ã‚¹ãƒˆ]

    G --> J[è‡ªå‹•ãƒ‡ãƒ—ãƒ­ã‚¤]
    H --> K[æ‰‹å‹•æ‰¿èª]
    K --> L[ãƒ‡ãƒ—ãƒ­ã‚¤]
    I --> M[ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯]

    style D fill:#e8f5e9
    style E fill:#fff3e0
    style F fill:#ffebee
</div>

<table>
<thead>
<tr>
<th>ç’°å¢ƒ</th>
<th>ç”¨é€”</th>
<th>ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹æ•°</th>
<th>ãƒ‡ãƒ—ãƒ­ã‚¤æ–¹æ³•</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Dev</strong></td>
<td>é–‹ç™ºãƒ»ãƒ†ã‚¹ãƒˆ</td>
<td>1</td>
<td>è‡ªå‹•ï¼ˆdevelopãƒ–ãƒ©ãƒ³ãƒï¼‰</td>
</tr>
<tr>
<td><strong>Staging</strong></td>
<td>çµ±åˆãƒ†ã‚¹ãƒˆãƒ»QA</td>
<td>2</td>
<td>è‡ªå‹•ï¼ˆstagingãƒ–ãƒ©ãƒ³ãƒï¼‰</td>
</tr>
<tr>
<td><strong>Production</strong></td>
<td>æœ¬ç•ªé‹ç”¨</td>
<td>3+ï¼ˆã‚ªãƒ¼ãƒˆã‚¹ã‚±ãƒ¼ãƒ«ï¼‰</td>
<td>æ‰‹å‹•æ‰¿èªå¾Œ</td>
</tr>
</tbody>
</table>

<hr>

<h2>3.6 æœ¬ç« ã®ã¾ã¨ã‚</h2>

<h3>å­¦ã‚“ã ã“ã¨</h3>

<ol>
<li><p><strong>ã‚¯ãƒ©ã‚¦ãƒ‰ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã®é¸æŠ</strong></p>
<ul>
<li>AWSã€GCPã€Azureã®ç‰¹å¾´ã¨ä½¿ã„åˆ†ã‘</li>
<li>ãƒãƒãƒ¼ã‚¸ãƒ‰ã€ã‚µãƒ¼ãƒãƒ¼ãƒ¬ã‚¹ã€ã‚³ãƒ³ãƒ†ãƒŠã®æ¯”è¼ƒ</li>
<li>ã‚³ã‚¹ãƒˆæœ€é©åŒ–ã®è€ƒæ…®äº‹é …</li>
</ul></li>

<li><p><strong>AWS SageMaker</strong></p>
<ul>
<li>ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®ä½œæˆã¨ãƒ‡ãƒ—ãƒ­ã‚¤</li>
<li>ã‚«ã‚¹ã‚¿ãƒ æ¨è«–ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®å®Ÿè£…</li>
<li>ã‚ªãƒ¼ãƒˆã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã®è¨­å®š</li>
</ul></li>

<li><p><strong>AWS Lambdaã‚µãƒ¼ãƒãƒ¼ãƒ¬ã‚¹</strong></p>
<ul>
<li>Lambdaé–¢æ•°ã®ä½œæˆã¨ã‚³ãƒ³ãƒ†ãƒŠãƒ‡ãƒ—ãƒ­ã‚¤</li>
<li>API Gatewayã¨ã®çµ±åˆ</li>
<li>ã‚³ãƒ¼ãƒ«ãƒ‰ã‚¹ã‚¿ãƒ¼ãƒˆå¯¾ç­–</li>
</ul></li>

<li><p><strong>GCP Vertex AIã¨Azure ML</strong></p>
<ul>
<li>Vertex AI Endpointsã®ãƒ‡ãƒ—ãƒ­ã‚¤</li>
<li>Azure ML Managed Endpointsã®æ´»ç”¨</li>
<li>ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ é–“ã®æ¯”è¼ƒ</li>
</ul></li>

<li><p><strong>ãƒãƒ«ãƒã‚¯ãƒ©ã‚¦ãƒ‰æˆ¦ç•¥</strong></p>
<ul>
<li>Terraformã«ã‚ˆã‚‹ã‚¤ãƒ³ãƒ•ãƒ©ã‚³ãƒ¼ãƒ‰åŒ–</li>
<li>GitHub Actionsã§ã®CI/CDãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³</li>
<li>ç’°å¢ƒåˆ¥ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆç®¡ç†</li>
</ul></li>
</ol>

<h3>é¸æŠã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³</h3>

<table>
<thead>
<tr>
<th>è¦ä»¶</th>
<th>æ¨å¥¨ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³</th>
<th>ç†ç”±</th>
</tr>
</thead>
<tbody>
<tr>
<td>é«˜é »åº¦ãƒªã‚¯ã‚¨ã‚¹ãƒˆ</td>
<td>SageMaker/Vertex AI</td>
<td>å°‚ç”¨ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã§ä½ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·</td>
</tr>
<tr>
<td>ä½é »åº¦ãƒ»ä¸è¦å‰‡</td>
<td>Lambda/Cloud Functions</td>
<td>ã‚³ã‚¹ãƒˆåŠ¹ç‡ãŒé«˜ã„</td>
</tr>
<tr>
<td>ãƒãƒ¼ã‚¹ãƒˆå¯¾å¿œ</td>
<td>ECS/Cloud Run</td>
<td>æŸ”è»Ÿãªã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°</td>
</tr>
<tr>
<td>ãƒãƒ«ãƒãƒ¢ãƒ‡ãƒ«</td>
<td>Kubernetes (EKS/GKE)</td>
<td>çµ±ä¸€ç®¡ç†ã¨ãƒªã‚½ãƒ¼ã‚¹åŠ¹ç‡</td>
</tr>
<tr>
<td>TensorFlowä¸­å¿ƒ</td>
<td>GCP Vertex AI</td>
<td>ãƒã‚¤ãƒ†ã‚£ãƒ–çµ±åˆ</td>
</tr>
<tr>
<td>Microsoftç’°å¢ƒ</td>
<td>Azure ML</td>
<td>æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã¨ã®è¦ªå’Œæ€§</td>
</tr>
</tbody>
</table>

<h3>æ¬¡ã®ç« ã¸</h3>

<p>ç¬¬4ç« ã§ã¯ã€<strong>ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ã¨é‹ç”¨ç®¡ç†</strong>ã‚’å­¦ã³ã¾ã™ï¼š</p>
<ul>
<li>ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°</li>
<li>ãƒ­ã‚°ç®¡ç†ã¨ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°</li>
<li>ãƒ¢ãƒ‡ãƒ«ãƒ‰ãƒªãƒ•ãƒˆæ¤œå‡º</li>
<li>A/Bãƒ†ã‚¹ãƒˆã¨ã‚«ãƒŠãƒªã‚¢ãƒ‡ãƒ—ãƒ­ã‚¤</li>
<li>ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆå¯¾å¿œ</li>
</ul>

<hr>

<h2>æ¼”ç¿’å•é¡Œ</h2>

<h3>å•é¡Œ1ï¼ˆé›£æ˜“åº¦ï¼šmediumï¼‰</h3>
<p>AWS SageMakerã¨AWS Lambdaã®ã©ã¡ã‚‰ã‚’é¸ã¶ã¹ãã‹ã€ä»¥ä¸‹ã®ã‚·ãƒŠãƒªã‚ªã§åˆ¤æ–­ã—ã€ç†ç”±ã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚</p>

<p><strong>ã‚·ãƒŠãƒªã‚ªA</strong>: ECã‚µã‚¤ãƒˆã®å•†å“æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ ï¼ˆ1æ—¥10ä¸‡ãƒªã‚¯ã‚¨ã‚¹ãƒˆã€ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“100msä»¥å†…ï¼‰<br>
<strong>ã‚·ãƒŠãƒªã‚ªB</strong>: ãƒãƒƒãƒå‡¦ç†ã«ã‚ˆã‚‹æœˆæ¬¡ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆï¼ˆæœˆ1å›ã€å‡¦ç†æ™‚é–“1æ™‚é–“ï¼‰</p>

<details>
<summary>è§£ç­”ä¾‹</summary>

<p><strong>è§£ç­”</strong>ï¼š</p>

<p><strong>ã‚·ãƒŠãƒªã‚ªAï¼šAWS SageMakeræ¨å¥¨</strong></p>
<ul>
<li><strong>ç†ç”±</strong>:
<ul>
<li>é«˜é »åº¦ãƒªã‚¯ã‚¨ã‚¹ãƒˆï¼ˆ1æ—¥10ä¸‡ = 1ç§’ã‚ãŸã‚Šç´„1.2ãƒªã‚¯ã‚¨ã‚¹ãƒˆï¼‰ã§å®‰å®šã—ãŸãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯</li>
<li>ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“100msä»¥å†…ãŒæ±‚ã‚ã‚‰ã‚Œã€ã‚³ãƒ¼ãƒ«ãƒ‰ã‚¹ã‚¿ãƒ¼ãƒˆã¯è¨±å®¹ã§ããªã„</li>
<li>å°‚ç”¨ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã§å¸¸æ™‚ç¨¼åƒã«ã‚ˆã‚Šã€ä½ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã‚’ä¿è¨¼</li>
<li>ã‚ªãƒ¼ãƒˆã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã§ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã®ãƒ”ãƒ¼ã‚¯ã«å¯¾å¿œå¯èƒ½</li>
</ul></li>
<li><strong>æ§‹æˆ</strong>: ml.m5.large Ã— 2ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ï¼ˆæœ€å°ï¼‰ã€ã‚ªãƒ¼ãƒˆã‚¹ã‚±ãƒ¼ãƒ«æœ€å¤§5ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹</li>
<li><strong>ã‚³ã‚¹ãƒˆ</strong>: æœˆé¡ç´„$300-500ï¼ˆã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ç¨¼åƒæ™‚é–“ãƒ™ãƒ¼ã‚¹ï¼‰</li>
</ul>

<p><strong>ã‚·ãƒŠãƒªã‚ªBï¼šAWS Lambdaæ¨å¥¨</strong></p>
<ul>
<li><strong>ç†ç”±</strong>:
<ul>
<li>ä½é »åº¦ï¼ˆæœˆ1å›ï¼‰ã®å®Ÿè¡Œã§ã€å¸¸æ™‚ç¨¼åƒã¯ä¸è¦</li>
<li>å‡¦ç†æ™‚é–“1æ™‚é–“ã§ã‚‚ã€Lambdaï¼ˆæœ€å¤§15åˆ†ï¼‰Ã— 4å›ã®åˆ†å‰²å®Ÿè¡Œã§å¯¾å¿œå¯èƒ½</li>
<li>å®Ÿè¡Œæ™‚é–“ã®ã¿èª²é‡‘ã§ã€å¤§å¹…ãªã‚³ã‚¹ãƒˆå‰Šæ¸›</li>
<li>ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“ã®å³ã—ã„è¦ä»¶ãŒãªã„</li>
</ul></li>
<li><strong>æ§‹æˆ</strong>: Lambdaï¼ˆãƒ¡ãƒ¢ãƒª3008MBï¼‰ã€Step Functionsã§å‡¦ç†ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³</li>
<li><strong>ã‚³ã‚¹ãƒˆ</strong>: æœˆé¡ç´„$5-10ï¼ˆå®Ÿè¡Œæ™‚é–“ã®ã¿ï¼‰</li>
</ul>

<p><strong>åˆ¤æ–­åŸºæº–ã¾ã¨ã‚</strong>ï¼š</p>
<table>
<thead>
<tr>
<th>è¦å› </th>
<th>SageMaker</th>
<th>Lambda</th>
</tr>
</thead>
<tbody>
<tr>
<td>ãƒªã‚¯ã‚¨ã‚¹ãƒˆé »åº¦</td>
<td>é«˜é »åº¦ãƒ»å®‰å®š</td>
<td>ä½é »åº¦ãƒ»ä¸è¦å‰‡</td>
</tr>
<tr>
<td>ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·è¦ä»¶</td>
<td>å³ã—ã„ï¼ˆ< 100msï¼‰</td>
<td>ç·©ã„ï¼ˆ> 1ç§’OKï¼‰</td>
</tr>
<tr>
<td>ã‚³ã‚¹ãƒˆç‰¹æ€§</td>
<td>å›ºå®šã‚³ã‚¹ãƒˆé«˜</td>
<td>å¾“é‡èª²é‡‘</td>
</tr>
<tr>
<td>é‹ç”¨è² è·</td>
<td>ä¸­ï¼ˆã‚¹ã‚±ãƒ¼ãƒ«ç®¡ç†ï¼‰</td>
<td>ä½ï¼ˆãƒ•ãƒ«ãƒãƒãƒ¼ã‚¸ãƒ‰ï¼‰</td>
</tr>
</tbody>
</table>

</details>

<h3>å•é¡Œ2ï¼ˆé›£æ˜“åº¦ï¼šhardï¼‰</h3>
<p>Terraformã¨GitHub Actionsã‚’ä½¿ç”¨ã—ã¦ã€é–‹ç™ºç’°å¢ƒã¨æœ¬ç•ªç’°å¢ƒã§ç•°ãªã‚‹è¨­å®šï¼ˆã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹æ•°ã€ã‚¿ã‚¤ãƒ—ï¼‰ã‚’æŒã¤SageMakerã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’ãƒ‡ãƒ—ãƒ­ã‚¤ã™ã‚‹æ§‹æˆã‚’è¨­è¨ˆã—ã¦ãã ã•ã„ã€‚</p>

<details>
<summary>è§£ç­”ä¾‹</summary>

<p><strong>è§£ç­”</strong>ï¼š</p>

<p><strong>1. Terraformå¤‰æ•°ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆç’°å¢ƒåˆ¥ï¼‰</strong></p>

<pre><code class="language-hcl"># terraform/environments/dev.tfvars
environment            = "dev"
instance_type          = "ml.t3.medium"
initial_instance_count = 1
min_capacity           = 1
max_capacity           = 2
enable_autoscaling     = false

# terraform/environments/prod.tfvars
environment            = "prod"
instance_type          = "ml.m5.xlarge"
initial_instance_count = 2
min_capacity           = 2
max_capacity           = 10
enable_autoscaling     = true
</code></pre>

<p><strong>2. Terraformãƒ¡ã‚¤ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«</strong></p>

<pre><code class="language-hcl"># terraform/main.tf
resource "aws_sagemaker_endpoint_configuration" "endpoint_config" {
  name = "sklearn-endpoint-config-${var.environment}"

  production_variants {
    variant_name           = "AllTraffic"
    model_name             = aws_sagemaker_model.ml_model.name
    initial_instance_count = var.initial_instance_count
    instance_type          = var.instance_type
  }
}

resource "aws_appautoscaling_target" "sagemaker_target" {
  count              = var.enable_autoscaling ? 1 : 0
  service_namespace  = "sagemaker"
  resource_id        = "endpoint/${aws_sagemaker_endpoint.endpoint.name}/variant/AllTraffic"
  scalable_dimension = "sagemaker:variant:DesiredInstanceCount"
  min_capacity       = var.min_capacity
  max_capacity       = var.max_capacity
}

resource "aws_appautoscaling_policy" "sagemaker_policy" {
  count              = var.enable_autoscaling ? 1 : 0
  name               = "sagemaker-scaling-policy-${var.environment}"
  service_namespace  = "sagemaker"
  resource_id        = aws_appautoscaling_target.sagemaker_target[0].resource_id
  scalable_dimension = aws_appautoscaling_target.sagemaker_target[0].scalable_dimension
  policy_type        = "TargetTrackingScaling"

  target_tracking_scaling_policy_configuration {
    predefined_metric_specification {
      predefined_metric_type = "SageMakerVariantInvocationsPerInstance"
    }
    target_value = 1000.0
  }
}
</code></pre>

<p><strong>3. GitHub Actions Workflow</strong></p>

<pre><code class="language-yaml"># .github/workflows/deploy.yml
jobs:
  deploy:
    steps:
      - name: Set environment variables
        run: |
          if [[ "${{ github.ref }}" == "refs/heads/main" ]]; then
            echo "TFVARS_FILE=prod.tfvars" >> $GITHUB_ENV
            echo "REQUIRE_APPROVAL=true" >> $GITHUB_ENV
          else
            echo "TFVARS_FILE=dev.tfvars" >> $GITHUB_ENV
            echo "REQUIRE_APPROVAL=false" >> $GITHUB_ENV
          fi

      - name: Terraform Plan
        working-directory: ./terraform
        run: |
          terraform plan \
            -var-file="environments/${{ env.TFVARS_FILE }}" \
            -out=tfplan

      - name: Wait for approval (prod only)
        if: env.REQUIRE_APPROVAL == 'true'
        uses: trstringer/manual-approval@v1
        with:
          approvers: platform-team
          minimum-approvals: 2

      - name: Terraform Apply
        working-directory: ./terraform
        run: terraform apply -auto-approve tfplan
</code></pre>

<p><strong>4. ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ•ãƒ­ãƒ¼</strong></p>

<div class="mermaid">
graph TD
    A[Git Push] --> B{ãƒ–ãƒ©ãƒ³ãƒåˆ¤å®š}
    B -->|develop| C[Devç’°å¢ƒè¨­å®š<br/>ml.t3.mediumÃ—1]
    B -->|main| D[Prodç’°å¢ƒè¨­å®š<br/>ml.m5.xlargeÃ—2]
    C --> E[è‡ªå‹•ãƒ‡ãƒ—ãƒ­ã‚¤]
    D --> F[æ‰¿èªå¾…æ©Ÿ]
    F --> G[æ‰‹å‹•æ‰¿èª]
    G --> H[ãƒ‡ãƒ—ãƒ­ã‚¤å®Ÿè¡Œ]
    E --> I[ã‚¹ãƒ¢ãƒ¼ã‚¯ãƒ†ã‚¹ãƒˆ]
    H --> I
</div>

<p><strong>æ§‹æˆã®ãƒã‚¤ãƒ³ãƒˆ</strong>ï¼š</p>
<ul>
<li>ç’°å¢ƒã”ã¨ã«ç•°ãªã‚‹ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚¿ã‚¤ãƒ—ãƒ»æ•°ã‚’å®šç¾©</li>
<li>æœ¬ç•ªç’°å¢ƒã®ã¿ã‚ªãƒ¼ãƒˆã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æœ‰åŠ¹åŒ–</li>
<li>æœ¬ç•ªãƒ‡ãƒ—ãƒ­ã‚¤ã¯æ‰‹å‹•æ‰¿èªã‚²ãƒ¼ãƒˆè¿½åŠ </li>
<li>Terraform Workspaceã§ç’°å¢ƒåˆ†é›¢</li>
</ul>

</details>

<h3>å•é¡Œ3ï¼ˆé›£æ˜“åº¦ï¼šhardï¼‰</h3>
<p>AWS Lambdaã®ã‚³ãƒ¼ãƒ«ãƒ‰ã‚¹ã‚¿ãƒ¼ãƒˆå•é¡Œã‚’è»½æ¸›ã™ã‚‹ãŸã‚ã«ã€ã©ã®ã‚ˆã†ãªæ‰‹æ³•ã‚’çµ„ã¿åˆã‚ã›ã‚‹ã¹ãã‹ã€å…·ä½“çš„ãªå®Ÿè£…ã‚’å«ã‚ã¦èª¬æ˜ã—ã¦ãã ã•ã„ã€‚</p>

<details>
<summary>è§£ç­”ä¾‹</summary>

<p><strong>è§£ç­”</strong>ï¼š</p>

<p><strong>1. ãƒ—ãƒ­ãƒ“ã‚¸ãƒ§ãƒ‹ãƒ³ã‚°åŒæ™‚å®Ÿè¡Œã®è¨­å®š</strong></p>

<pre><code class="language-python">import boto3

lambda_client = boto3.client('lambda')

# ãƒ—ãƒ­ãƒ“ã‚¸ãƒ§ãƒ‹ãƒ³ã‚°åŒæ™‚å®Ÿè¡Œã®è¨­å®š
lambda_client.put_provisioned_concurrency_config(
    FunctionName='ml-inference',
    Qualifier='$LATEST',  # ã¾ãŸã¯ãƒãƒ¼ã‚¸ãƒ§ãƒ³/ã‚¨ã‚¤ãƒªã‚¢ã‚¹
    ProvisionedConcurrentExecutions=5  # å¸¸æ™‚5ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’èµ·å‹•
)

print("âœ“ ãƒ—ãƒ­ãƒ“ã‚¸ãƒ§ãƒ‹ãƒ³ã‚°åŒæ™‚å®Ÿè¡Œã‚’è¨­å®šã—ã¾ã—ãŸï¼ˆ5ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ï¼‰")
</code></pre>

<p><strong>åŠ¹æœ</strong>: å¸¸æ™‚èµ·å‹•ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã§ã‚³ãƒ¼ãƒ«ãƒ‰ã‚¹ã‚¿ãƒ¼ãƒˆå®Œå…¨å›é¿<br>
<strong>ã‚³ã‚¹ãƒˆ</strong>: é€šå¸¸å®Ÿè¡Œã®ç´„2å€ï¼ˆå¸¸æ™‚èª²é‡‘ï¼‰</p>

<p><strong>2. è»½é‡ãƒ¢ãƒ‡ãƒ«ã¨ãƒ¬ã‚¤ãƒ¤ãƒ¼åˆ†é›¢</strong></p>

<pre><code class="language-python"># ãƒ¢ãƒ‡ãƒ«ã®è»½é‡åŒ–
import joblib
from sklearn.ensemble import RandomForestClassifier

# å…ƒã®ãƒ¢ãƒ‡ãƒ«
model = RandomForestClassifier(n_estimators=100, max_depth=10)
# ã‚µã‚¤ã‚º: ç´„50MB

# è»½é‡åŒ–ï¼ˆæœ¨ã®æ•°ã‚’å‰Šæ¸›ï¼‰
model_light = RandomForestClassifier(n_estimators=20, max_depth=8)
# ã‚µã‚¤ã‚º: ç´„10MBï¼ˆ80%å‰Šæ¸›ï¼‰

# é‡å­åŒ–ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
import onnx
import onnxruntime
# ONNXå½¢å¼ã§é‡å­åŒ–ã—ã¦ã‚µã‚¤ã‚ºå‰Šæ¸›
</code></pre>

<p><strong>Lambda Layerã®æ´»ç”¨</strong>:</p>

<pre><code class="language-bash"># ä¾å­˜é–¢ä¿‚ã‚’ãƒ¬ã‚¤ãƒ¤ãƒ¼ã«åˆ†é›¢
mkdir -p layer/python/lib/python3.9/site-packages
pip install scikit-learn numpy -t layer/python/lib/python3.9/site-packages
cd layer
zip -r layer.zip .

# ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®å…¬é–‹
aws lambda publish-layer-version \
    --layer-name ml-dependencies \
    --zip-file fileb://layer.zip \
    --compatible-runtimes python3.9
</code></pre>

<p><strong>åŠ¹æœ</strong>: ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸å‰Šæ¸›ã§ã‚³ãƒ¼ãƒ«ãƒ‰ã‚¹ã‚¿ãƒ¼ãƒˆæ™‚é–“çŸ­ç¸®ï¼ˆ10MB â†’ 1-2ç§’ã€50MB â†’ 5-10ç§’ï¼‰</p>

<p><strong>3. EventBridgeã«ã‚ˆã‚‹å®šæœŸã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—</strong></p>

<pre><code class="language-python">import boto3

events = boto3.client('events')
lambda_arn = 'arn:aws:lambda:us-east-1:123456789012:function:ml-inference'

# CloudWatch Eventsãƒ«ãƒ¼ãƒ«ã®ä½œæˆ
rule_response = events.put_rule(
    Name='lambda-warmup-rule',
    ScheduleExpression='rate(5 minutes)',  # 5åˆ†ã”ã¨ã«å®Ÿè¡Œ
    State='ENABLED',
    Description='Keep Lambda warm to avoid cold starts'
)

# Lambdaé–¢æ•°ã‚’ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã«è¨­å®š
events.put_targets(
    Rule='lambda-warmup-rule',
    Targets=[
        {
            'Id': '1',
            'Arn': lambda_arn,
            'Input': json.dumps({'warmup': True})  # ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—ãƒ•ãƒ©ã‚°
        }
    ]
)

print("âœ“ 5åˆ†ã”ã¨ã®ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—ã‚’è¨­å®šã—ã¾ã—ãŸ")
</code></pre>

<p><strong>Lambdaé–¢æ•°ã®ä¿®æ­£</strong>:</p>

<pre><code class="language-python">def lambda_handler(event, context):
    # ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®åˆ¤å®š
    if event.get('warmup'):
        print("Warmup request - keeping instance alive")
        return {'statusCode': 200, 'body': 'warmed up'}

    # é€šå¸¸ã®æ¨è«–å‡¦ç†
    # ...
</code></pre>

<p><strong>åŠ¹æœ</strong>: ã‚¢ã‚¤ãƒ‰ãƒ«çŠ¶æ…‹å›é¿ï¼ˆã‚³ã‚¹ãƒˆå¢—åŠ : æœˆé¡$1-5ç¨‹åº¦ï¼‰</p>

<p><strong>4. æœ€é©ãªçµ„ã¿åˆã‚ã›æˆ¦ç•¥</strong></p>

<table>
<thead>
<tr>
<th>ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ãƒ‘ã‚¿ãƒ¼ãƒ³</th>
<th>æ¨å¥¨æ‰‹æ³•</th>
<th>æœŸå¾…åŠ¹æœ</th>
</tr>
</thead>
<tbody>
<tr>
<td>å¸¸æ™‚é«˜é »åº¦ï¼ˆ>10 req/sï¼‰</td>
<td>ãƒ—ãƒ­ãƒ“ã‚¸ãƒ§ãƒ‹ãƒ³ã‚°åŒæ™‚å®Ÿè¡Œ</td>
<td>ã‚³ãƒ¼ãƒ«ãƒ‰ã‚¹ã‚¿ãƒ¼ãƒˆ0%</td>
</tr>
<tr>
<td>ä¸­é »åº¦ï¼ˆ1-10 req/sï¼‰</td>
<td>è»½é‡åŒ– + å®šæœŸã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—</td>
<td>ã‚³ãƒ¼ãƒ«ãƒ‰ã‚¹ã‚¿ãƒ¼ãƒˆ<5%</td>
</tr>
<tr>
<td>ä½é »åº¦ï¼ˆ<1 req/sï¼‰</td>
<td>è»½é‡åŒ–ã®ã¿</td>
<td>èµ·å‹•æ™‚é–“1-2ç§’</td>
</tr>
<tr>
<td>ãƒãƒ¼ã‚¹ãƒˆå¯¾å¿œ</td>
<td>å…¨æ‰‹æ³•çµ„ã¿åˆã‚ã›</td>
<td>æœ€å¤§ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹</td>
</tr>
</tbody>
</table>

<p><strong>å®Ÿè£…ä¾‹ï¼ˆå…¨æ‰‹æ³•çµ±åˆï¼‰</strong>:</p>

<pre><code class="language-python"># çµ±åˆæˆ¦ç•¥
# 1. è»½é‡ãƒ¢ãƒ‡ãƒ«ï¼ˆ10MBä»¥ä¸‹ï¼‰
# 2. Lambda Layeræ´»ç”¨
# 3. ãƒ—ãƒ­ãƒ“ã‚¸ãƒ§ãƒ‹ãƒ³ã‚°åŒæ™‚å®Ÿè¡Œï¼ˆãƒ”ãƒ¼ã‚¯æ™‚é–“ã®ã¿ï¼‰
# 4. EventBridgeã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—ï¼ˆ5åˆ†é–“éš”ï¼‰

# ã‚³ã‚¹ãƒˆè©¦ç®—ï¼ˆæœˆé–“10ä¸‡ãƒªã‚¯ã‚¨ã‚¹ãƒˆæƒ³å®šï¼‰
# - é€šå¸¸Lambda: $5
# - ãƒ—ãƒ­ãƒ“ã‚¸ãƒ§ãƒ‹ãƒ³ã‚°: $30ï¼ˆãƒ”ãƒ¼ã‚¯8æ™‚é–“/æ—¥ï¼‰
# - ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—: $3
# - åˆè¨ˆ: ç´„$40/æœˆï¼ˆSageMakeræ¯”70%å‰Šæ¸›ï¼‰
</code></pre>

</details>

<hr>

<h2>å‚è€ƒæ–‡çŒ®</h2>

<ol>
<li>Amazon Web Services. (2024). <em>Amazon SageMaker Developer Guide</em>. AWS Documentation.</li>
<li>Google Cloud. (2024). <em>Vertex AI Documentation</em>. Google Cloud Documentation.</li>
<li>Microsoft Azure. (2024). <em>Azure Machine Learning Documentation</em>. Microsoft Learn.</li>
<li>HashiCorp. (2024). <em>Terraform AWS Provider Documentation</em>. Terraform Registry.</li>
<li>GÃ©ron, A. (2022). <em>Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow</em> (3rd ed.). O'Reilly Media.</li>
</ol>

<div class="navigation">
    <a href="chapter2-containerization.html" class="nav-button">â† å‰ã®ç« : ã‚³ãƒ³ãƒ†ãƒŠåŒ–ã¨Docker</a>
    <a href="chapter4-monitoring.html" class="nav-button">æ¬¡ã®ç« : ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ã¨é‹ç”¨ç®¡ç† â†’</a>
</div>

    </main>

    
    <section class="disclaimer">
        <h3>å…è²¬äº‹é …</h3>
        <ul>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯æ•™è‚²ãƒ»ç ”ç©¶ãƒ»æƒ…å ±æä¾›ã®ã¿ã‚’ç›®çš„ã¨ã—ã¦ãŠã‚Šã€å°‚é–€çš„ãªåŠ©è¨€(æ³•å¾‹ãƒ»ä¼šè¨ˆãƒ»æŠ€è¡“çš„ä¿è¨¼ãªã©)ã‚’æä¾›ã™ã‚‹ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŠã‚ˆã³ä»˜éšã™ã‚‹ã‚³ãƒ¼ãƒ‰ä¾‹ã¯ã€Œç¾çŠ¶æœ‰å§¿(AS IS)ã€ã§æä¾›ã•ã‚Œã€æ˜ç¤ºã¾ãŸã¯é»™ç¤ºã‚’å•ã‚ãšã€å•†å“æ€§ã€ç‰¹å®šç›®çš„é©åˆæ€§ã€æ¨©åˆ©éä¾µå®³ã€æ­£ç¢ºæ€§ãƒ»å®Œå…¨æ€§ã€å‹•ä½œãƒ»å®‰å…¨æ€§ç­‰ã„ã‹ãªã‚‹ä¿è¨¼ã‚‚ã—ã¾ã›ã‚“ã€‚</li>
            <li>å¤–éƒ¨ãƒªãƒ³ã‚¯ã€ç¬¬ä¸‰è€…ãŒæä¾›ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ»ãƒ„ãƒ¼ãƒ«ãƒ»ãƒ©ã‚¤ãƒ–ãƒ©ãƒªç­‰ã®å†…å®¹ãƒ»å¯ç”¨æ€§ãƒ»å®‰å…¨æ€§ã«ã¤ã„ã¦ã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯ä¸€åˆ‡ã®è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®åˆ©ç”¨ãƒ»å®Ÿè¡Œãƒ»è§£é‡ˆã«ã‚ˆã‚Šç›´æ¥çš„ãƒ»é–“æ¥çš„ãƒ»ä»˜éšçš„ãƒ»ç‰¹åˆ¥ãƒ»çµæœçš„ãƒ»æ‡²ç½°çš„æå®³ãŒç”Ÿã˜ãŸå ´åˆã§ã‚‚ã€é©ç”¨æ³•ã§è¨±å®¹ã•ã‚Œã‚‹æœ€å¤§é™ã®ç¯„å›²ã§ã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å†…å®¹ã¯ã€äºˆå‘Šãªãå¤‰æ›´ãƒ»æ›´æ–°ãƒ»æä¾›åœæ­¢ã•ã‚Œã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®è‘—ä½œæ¨©ãƒ»ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯æ˜è¨˜ã•ã‚ŒãŸæ¡ä»¶(ä¾‹: CC BY 4.0)ã«å¾“ã„ã¾ã™ã€‚å½“è©²ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯é€šå¸¸ã€ç„¡ä¿è¨¼æ¡é …ã‚’å«ã¿ã¾ã™ã€‚</li>
        </ul>
    </section>

<footer>
        <p><strong>ä½œæˆè€…</strong>: AI Terakoya Content Team</p>
        <p><strong>ãƒãƒ¼ã‚¸ãƒ§ãƒ³</strong>: 1.0 | <strong>ä½œæˆæ—¥</strong>: 2025-10-23</p>
        <p><strong>ãƒ©ã‚¤ã‚»ãƒ³ã‚¹</strong>: Creative Commons BY 4.0</p>
        <p>Â© 2025 AI Terakoya. All rights reserved.</p>
    </footer>
</body>
</html>
