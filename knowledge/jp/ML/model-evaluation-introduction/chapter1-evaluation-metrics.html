<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ç¬¬1ç« ï¼šè©•ä¾¡æŒ‡æ¨™åŸºç¤ - AI Terakoya</title>

    <style>
        :root {
            --color-primary: #2c3e50;
            --color-primary-dark: #1a252f;
            --color-accent: #7b2cbf;
            --color-accent-light: #9d4edd;
            --color-text: #2d3748;
            --color-text-light: #4a5568;
            --color-bg: #ffffff;
            --color-bg-alt: #f7fafc;
            --color-border: #e2e8f0;
            --color-code-bg: #f8f9fa;
            --color-link: #3182ce;
            --color-link-hover: #2c5aa0;

            --spacing-xs: 0.5rem;
            --spacing-sm: 1rem;
            --spacing-md: 1.5rem;
            --spacing-lg: 2rem;
            --spacing-xl: 3rem;

            --font-body: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            --font-mono: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;

            --border-radius: 8px;
            --box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: var(--font-body);
            line-height: 1.7;
            color: var(--color-text);
            background-color: var(--color-bg);
            font-size: 16px;
        }

        header {
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            padding: var(--spacing-xl) var(--spacing-md);
            margin-bottom: var(--spacing-xl);
            box-shadow: var(--box-shadow);
        }

        .header-content {
            max-width: 900px;
            margin: 0 auto;
        }

        h1 {
            font-size: 2rem;
            font-weight: 700;
            margin-bottom: var(--spacing-sm);
            line-height: 1.2;
        }

        .subtitle {
            font-size: 1.1rem;
            opacity: 0.95;
            font-weight: 400;
            margin-bottom: var(--spacing-md);
        }

        .meta {
            display: flex;
            flex-wrap: wrap;
            gap: var(--spacing-md);
            font-size: 0.9rem;
            opacity: 0.9;
        }

        .meta-item {
            display: flex;
            align-items: center;
            gap: 0.3rem;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 0 var(--spacing-md) var(--spacing-xl);
        }

        h2 {
            font-size: 1.75rem;
            color: var(--color-primary);
            margin-top: var(--spacing-xl);
            margin-bottom: var(--spacing-md);
            padding-bottom: var(--spacing-xs);
            border-bottom: 3px solid var(--color-accent);
        }

        h3 {
            font-size: 1.4rem;
            color: var(--color-primary);
            margin-top: var(--spacing-lg);
            margin-bottom: var(--spacing-sm);
        }

        h4 {
            font-size: 1.1rem;
            color: var(--color-primary-dark);
            margin-top: var(--spacing-md);
            margin-bottom: var(--spacing-sm);
        }

        p {
            margin-bottom: var(--spacing-md);
            color: var(--color-text);
        }

        a {
            color: var(--color-link);
            text-decoration: none;
            transition: color 0.2s;
        }

        a:hover {
            color: var(--color-link-hover);
            text-decoration: underline;
        }

        ul, ol {
            margin-left: var(--spacing-lg);
            margin-bottom: var(--spacing-md);
        }

        li {
            margin-bottom: var(--spacing-xs);
            color: var(--color-text);
        }

        pre {
            background-color: var(--color-code-bg);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            overflow-x: auto;
            margin-bottom: var(--spacing-md);
            font-family: var(--font-mono);
            font-size: 0.9rem;
            line-height: 1.5;
        }

        code {
            font-family: var(--font-mono);
            font-size: 0.9em;
            background-color: var(--color-code-bg);
            padding: 0.2em 0.4em;
            border-radius: 3px;
        }

        pre code {
            background-color: transparent;
            padding: 0;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: var(--spacing-md);
            font-size: 0.95rem;
        }

        th, td {
            border: 1px solid var(--color-border);
            padding: var(--spacing-sm);
            text-align: left;
        }

        th {
            background-color: var(--color-bg-alt);
            font-weight: 600;
            color: var(--color-primary);
        }

        blockquote {
            border-left: 4px solid var(--color-accent);
            padding-left: var(--spacing-md);
            margin: var(--spacing-md) 0;
            color: var(--color-text-light);
            font-style: italic;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        .mermaid {
            text-align: center;
            margin: var(--spacing-lg) 0;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        details {
            background-color: var(--color-bg-alt);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            margin-bottom: var(--spacing-md);
        }

        summary {
            cursor: pointer;
            font-weight: 600;
            color: var(--color-primary);
            user-select: none;
            padding: var(--spacing-xs);
            margin: calc(-1 * var(--spacing-md));
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        summary:hover {
            background-color: rgba(123, 44, 191, 0.1);
        }

        details[open] summary {
            margin-bottom: var(--spacing-md);
            border-bottom: 1px solid var(--color-border);
        }

        .navigation {
            display: flex;
            justify-content: space-between;
            gap: var(--spacing-md);
            margin: var(--spacing-xl) 0;
            padding-top: var(--spacing-lg);
            border-top: 2px solid var(--color-border);
        }

        .nav-button {
            flex: 1;
            padding: var(--spacing-md);
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            border-radius: var(--border-radius);
            text-align: center;
            font-weight: 600;
            transition: transform 0.2s, box-shadow 0.2s;
            box-shadow: var(--box-shadow);
        }

        .nav-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
            text-decoration: none;
        }

        footer {
            margin-top: var(--spacing-xl);
            padding: var(--spacing-lg) var(--spacing-md);
            background-color: var(--color-bg-alt);
            border-top: 1px solid var(--color-border);
            text-align: center;
            font-size: 0.9rem;
            color: var(--color-text-light);
        }
        .disclaimer {
            max-width: 900px;
            margin: 2rem auto;
            padding: 1.5rem;
            background: #f8f9fa;
            border-left: 4px solid #6c757d;
            border-radius: 4px;
        }

        .disclaimer h3 {
            color: #495057;
            margin-bottom: 1rem;
            font-size: 1.1rem;
        }

        .disclaimer ul {
            list-style: none;
            padding-left: 0;
        }

        .disclaimer li {
            padding: 0.5rem 0;
            padding-left: 1.5rem;
            position: relative;
            font-size: 0.9rem;
            color: #6c757d;
            line-height: 1.6;
        }

        .disclaimer li::before {
            content: "âš ï¸";
            position: absolute;
            left: 0;
        }


        @media (max-width: 768px) {
            h1 {
                font-size: 1.5rem;
            }

            h2 {
                font-size: 1.4rem;
            }

            h3 {
                font-size: 1.2rem;
            }

            .meta {
                font-size: 0.85rem;
            }

            .navigation {
                flex-direction: column;
            }

            table {
                font-size: 0.85rem;
            }

            th, td {
                padding: var(--spacing-xs);
            }
        }
    
        
    
        /* Breadcrumb styles */
        .breadcrumb {
            background: #f7fafc;
            padding: 0.75rem 1rem;
            border-bottom: 1px solid #e2e8f0;
            font-size: 0.9rem;
        }

        .breadcrumb-content {
            max-width: 900px;
            margin: 0 auto;
            display: flex;
            align-items: center;
            flex-wrap: wrap;
            gap: 0.5rem;
        }

        .breadcrumb a {
            color: #667eea;
            text-decoration: none;
            transition: color 0.2s;
        }

        .breadcrumb a:hover {
            color: #764ba2;
            text-decoration: underline;
        }

        .breadcrumb-separator {
            color: #a0aec0;
            margin: 0 0.25rem;
        }

        .breadcrumb-current {
            color: #4a5568;
            font-weight: 500;
        }
    </style>

    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
        mermaid.initialize({ startOnLoad: true, theme: 'default' });
    </script>

    <!-- MathJax for LaTeX equation rendering -->
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                displayMath: [['$$', '$$'], ['\\[', '\\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
                ignoreHtmlClass: 'mermaid'
            }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" async></script>

    <style>
        /* Locale Switcher Styles */
        .locale-switcher {
            display: flex;
            align-items: center;
            gap: 0.5rem;
            padding: 0.5rem 1rem;
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
            border-radius: 6px;
            font-size: 0.9rem;
            margin-bottom: 1rem;
            box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);
        }

        .current-locale {
            font-weight: 600;
            color: #7b2cbf;
            display: flex;
            align-items: center;
            gap: 0.25rem;
        }

        .locale-separator {
            color: #adb5bd;
            font-weight: 300;
        }

        .locale-link {
            color: #f093fb;
            text-decoration: none;
            font-weight: 500;
            transition: all 0.2s ease;
            display: flex;
            align-items: center;
            gap: 0.25rem;
            padding: 0.2rem 0.5rem;
            border-radius: 4px;
        }

        .locale-link:hover {
            background: rgba(240, 147, 251, 0.1);
            color: #d07be8;
            transform: translateY(-1px);
        }

        .locale-meta {
            color: #868e96;
            font-size: 0.85rem;
            font-style: italic;
            margin-left: auto;
        }

        @media (max-width: 768px) {
            .locale-switcher {
                font-size: 0.85rem;
                padding: 0.4rem 0.8rem;
            }
            .locale-meta {
                display: none;
            }
        }
    </style>
</head>
<body>
            <div class="locale-switcher">
<span class="current-locale">ğŸŒ JP</span>
<span class="locale-separator">|</span>
<a href="../../../en/ML/model-evaluation-introduction/chapter1-evaluation-metrics.html" class="locale-link">ğŸ‡¬ğŸ‡§ EN</a>
<span class="locale-separator">|</span>
<span class="locale-meta">Last sync: 2025-11-16</span>
</div>
<nav class="breadcrumb">
        <div class="breadcrumb-content">
            <a href="../../index.html">AIå¯ºå­å±‹ãƒˆãƒƒãƒ—</a><span class="breadcrumb-separator">â€º</span><a href="../../ML/index.html">æ©Ÿæ¢°å­¦ç¿’</a><span class="breadcrumb-separator">â€º</span><a href="../../ML/model-evaluation-introduction/index.html">Model Evaluation</a><span class="breadcrumb-separator">â€º</span><span class="breadcrumb-current">Chapter 1</span>
        </div>
    </nav>

        <header>
        <div class="header-content">
            <h1>ç¬¬1ç« ï¼šè©•ä¾¡æŒ‡æ¨™åŸºç¤</h1>
            <p class="subtitle">ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ã‚’æ­£ã—ãæ¸¬ã‚‹ - åˆ†é¡ã¨å›å¸°ã®è©•ä¾¡æŒ‡æ¨™å®Œå…¨ã‚¬ã‚¤ãƒ‰</p>
            <div class="meta">
                <span class="meta-item">ğŸ“– èª­äº†æ™‚é–“: 25-30åˆ†</span>
                <span class="meta-item">ğŸ“Š é›£æ˜“åº¦: åˆç´šã€œä¸­ç´š</span>
                <span class="meta-item">ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹: 12å€‹</span>
                <span class="meta-item">ğŸ“ æ¼”ç¿’å•é¡Œ: 5å•</span>
            </div>
        </div>
    </header>

    <main class="container">

<h2>å­¦ç¿’ç›®æ¨™</h2>
<p>ã“ã®ç« ã‚’èª­ã‚€ã“ã¨ã§ã€ä»¥ä¸‹ã‚’ç¿’å¾—ã§ãã¾ã™ï¼š</p>
<ul>
<li>âœ… è©•ä¾¡æŒ‡æ¨™ã®é‡è¦æ€§ã¨ãƒ“ã‚¸ãƒã‚¹ã¸ã®å½±éŸ¿ã‚’ç†è§£ã™ã‚‹</li>
<li>âœ… åˆ†é¡å•é¡Œã®ä¸»è¦ãªè©•ä¾¡æŒ‡æ¨™ã‚’è¨ˆç®—ã—ã€è§£é‡ˆã§ãã‚‹</li>
<li>âœ… Confusion Matrixã‹ã‚‰Precisionã€Recallã€F1-scoreã‚’å°å‡ºã§ãã‚‹</li>
<li>âœ… ROC-AUCã¨PR-AUCã®é•ã„ã‚’ç†è§£ã—ã€ä½¿ã„åˆ†ã‘ã‚‰ã‚Œã‚‹</li>
<li>âœ… å›å¸°å•é¡Œã®è©•ä¾¡æŒ‡æ¨™ã‚’é¸æŠã—ã€é©åˆ‡ã«è§£é‡ˆã§ãã‚‹</li>
<li>âœ… ãƒ“ã‚¸ãƒã‚¹ç›®çš„ã«å¿œã˜ãŸè©•ä¾¡æŒ‡æ¨™ã‚’é¸æŠã§ãã‚‹</li>
</ul>

<hr>

<h2>1.1 è©•ä¾¡æŒ‡æ¨™ã®é‡è¦æ€§</h2>

<h3>ãªãœè©•ä¾¡æŒ‡æ¨™ãŒé‡è¦ã‹</h3>

<p><strong>è©•ä¾¡æŒ‡æ¨™ï¼ˆEvaluation Metricsï¼‰</strong>ã¯ã€æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’å®šé‡çš„ã«æ¸¬å®šã™ã‚‹æ‰‹æ®µã§ã™ã€‚</p>

<blockquote>
<p>ã€Œæ¸¬å®šã§ããªã„ã‚‚ã®ã¯æ”¹å–„ã§ããªã„ã€- Peter Drucker</p>
</blockquote>

<p>é©åˆ‡ãªè©•ä¾¡æŒ‡æ¨™ã‚’é¸ã¶ã“ã¨ã¯ã€ä»¥ä¸‹ã®ç†ç”±ã§æ¥µã‚ã¦é‡è¦ã§ã™ï¼š</p>

<ul>
<li><strong>ãƒ¢ãƒ‡ãƒ«é¸æŠ</strong>: è¤‡æ•°ã®ãƒ¢ãƒ‡ãƒ«ã‚’æ¯”è¼ƒã—ã€æœ€é©ãªã‚‚ã®ã‚’é¸æŠ</li>
<li><strong>ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´</strong>: ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã®æ–¹å‘æ€§ã‚’æ±ºå®š</li>
<li><strong>ãƒ“ã‚¸ãƒã‚¹ä¾¡å€¤</strong>: ãƒ¢ãƒ‡ãƒ«ã®ãƒ“ã‚¸ãƒã‚¹ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆã‚’å®šé‡åŒ–</li>
<li><strong>æ”¹å–„ã®æŒ‡é‡</strong>: ã©ã“ã‚’æ”¹å–„ã™ã¹ãã‹æ˜ç¢ºåŒ–</li>
</ul>

<h3>è©•ä¾¡æŒ‡æ¨™ã®é¸æŠãƒŸã‚¹ã«ã‚ˆã‚‹å½±éŸ¿</h3>

<table>
<thead>
<tr>
<th>ã‚·ãƒŠãƒªã‚ª</th>
<th>ä¸é©åˆ‡ãªæŒ‡æ¨™</th>
<th>å•é¡Œ</th>
<th>é©åˆ‡ãªæŒ‡æ¨™</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>ãŒã‚“æ¤œå‡º</strong></td>
<td>Accuracy</td>
<td>é™½æ€§ã‚’è¦‹é€ƒã™ï¼ˆå½é™°æ€§ï¼‰</td>
<td>Recallã€F2-score</td>
</tr>
<tr>
<td><strong>ã‚¹ãƒ‘ãƒ ãƒ•ã‚£ãƒ«ã‚¿</strong></td>
<td>Recall</td>
<td>æ­£å¸¸ãƒ¡ãƒ¼ãƒ«ã‚’èª¤åˆ¤å®šï¼ˆå½é™½æ€§ï¼‰</td>
<td>Precisionã€F0.5-score</td>
</tr>
<tr>
<td><strong>ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿</strong></td>
<td>Accuracy</td>
<td>å¤šæ•°æ´¾ã‚¯ãƒ©ã‚¹ã«åã‚‹</td>
<td>F1-scoreã€AUC</td>
</tr>
<tr>
<td><strong>ä½å®…ä¾¡æ ¼äºˆæ¸¬</strong></td>
<td>MSE</td>
<td>é«˜é¡ç‰©ä»¶ã®èª¤å·®ã«éæ•</td>
<td>MAPEã€MAE</td>
</tr>
</tbody>
</table>

<h3>è©•ä¾¡æŒ‡æ¨™ã®å…¨ä½“åƒ</h3>

<div class="mermaid">
graph TD
    A[è©•ä¾¡æŒ‡æ¨™] --> B[åˆ†é¡å•é¡Œ]
    A --> C[å›å¸°å•é¡Œ]

    B --> D[äºŒå€¤åˆ†é¡]
    B --> E[å¤šã‚¯ãƒ©ã‚¹åˆ†é¡]

    D --> F[Accuracy]
    D --> G[Precision / Recall]
    D --> H[F1-score]
    D --> I[ROC-AUC]
    D --> J[PR-AUC]
    D --> K[Log Loss]

    E --> L[Macro / Micro / Weighted]

    C --> M[MAE / MSE / RMSE]
    C --> N[RÂ² / Adjusted RÂ²]
    C --> O[MAPE / MSLE]

    style A fill:#e8f5e9
    style B fill:#fff3e0
    style C fill:#e3f2fd
    style D fill:#fce4ec
    style E fill:#f3e5f5
</div>

<h3>å®Ÿä¾‹ï¼šè©•ä¾¡æŒ‡æ¨™ã®é¸æŠã®é‡è¦æ€§</h3>

<pre><code class="language-python">import numpy as np
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# ãŒã‚“æ¤œå‡ºã‚·ãƒŠãƒªã‚ªï¼ˆä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿ï¼‰
# é™½æ€§ï¼ˆãŒã‚“ï¼‰: 10ä¾‹ã€é™°æ€§ï¼ˆæ­£å¸¸ï¼‰: 990ä¾‹
y_true = np.array([0]*990 + [1]*10)

# ãƒ¢ãƒ‡ãƒ«A: å…¨ã¦é™°æ€§ã¨äºˆæ¸¬ï¼ˆä¿å®ˆçš„ï¼‰
y_pred_A = np.array([0]*1000)

# ãƒ¢ãƒ‡ãƒ«B: é©åº¦ã«ãƒãƒ©ãƒ³ã‚¹ã®å–ã‚ŒãŸäºˆæ¸¬
y_pred_B = np.array([0]*985 + [1]*5 + [0]*3 + [1]*7)

print("=== ãŒã‚“æ¤œå‡ºã‚·ãƒŠãƒªã‚ªï¼šè©•ä¾¡æŒ‡æ¨™ã®æ¯”è¼ƒ ===\n")

print("ãƒ¢ãƒ‡ãƒ«Aï¼ˆå…¨ã¦é™°æ€§ã¨äºˆæ¸¬ï¼‰:")
print(f"  Accuracy:  {accuracy_score(y_true, y_pred_A):.3f}")
print(f"  Precision: N/A (é™½æ€§äºˆæ¸¬ãªã—)")
print(f"  Recall:    {recall_score(y_true, y_pred_A, zero_division=0):.3f}")
print(f"  F1-score:  {f1_score(y_true, y_pred_A, zero_division=0):.3f}")

print("\nãƒ¢ãƒ‡ãƒ«Bï¼ˆãƒãƒ©ãƒ³ã‚¹å‹ï¼‰:")
print(f"  Accuracy:  {accuracy_score(y_true, y_pred_B):.3f}")
print(f"  Precision: {precision_score(y_true, y_pred_B):.3f}")
print(f"  Recall:    {recall_score(y_true, y_pred_B):.3f}")
print(f"  F1-score:  {f1_score(y_true, y_pred_B):.3f}")

print("\nçµè«–:")
print("- Accuracyã ã‘ã‚’è¦‹ã‚‹ã¨ãƒ¢ãƒ‡ãƒ«AãŒå„ªç§€ã«è¦‹ãˆã‚‹ï¼ˆ99.0%ï¼‰")
print("- ã—ã‹ã—ã€ãŒã‚“æ‚£è€…ã‚’1äººã‚‚æ¤œå‡ºã§ãã¦ã„ãªã„ï¼ˆRecall=0ï¼‰")
print("- åŒ»ç™‚ç¾å ´ã§ã¯Recallã‚„F1-scoreãŒé‡è¦ï¼")
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>=== ãŒã‚“æ¤œå‡ºã‚·ãƒŠãƒªã‚ªï¼šè©•ä¾¡æŒ‡æ¨™ã®æ¯”è¼ƒ ===

ãƒ¢ãƒ‡ãƒ«Aï¼ˆå…¨ã¦é™°æ€§ã¨äºˆæ¸¬ï¼‰:
  Accuracy:  0.990
  Precision: N/A (é™½æ€§äºˆæ¸¬ãªã—)
  Recall:    0.000
  F1-score:  0.000

ãƒ¢ãƒ‡ãƒ«Bï¼ˆãƒãƒ©ãƒ³ã‚¹å‹ï¼‰:
  Accuracy:  0.982
  Precision: 0.583
  Recall:    0.700
  F1-score:  0.636

çµè«–:
- Accuracyã ã‘ã‚’è¦‹ã‚‹ã¨ãƒ¢ãƒ‡ãƒ«AãŒå„ªç§€ã«è¦‹ãˆã‚‹ï¼ˆ99.0%ï¼‰
- ã—ã‹ã—ã€ãŒã‚“æ‚£è€…ã‚’1äººã‚‚æ¤œå‡ºã§ãã¦ã„ãªã„ï¼ˆRecall=0ï¼‰
- åŒ»ç™‚ç¾å ´ã§ã¯Recallã‚„F1-scoreãŒé‡è¦ï¼
</code></pre>

<blockquote>
<p><strong>é‡è¦</strong>: è©•ä¾¡æŒ‡æ¨™ã¯ã€Œãƒ“ã‚¸ãƒã‚¹ç›®çš„ã€ã¨ã€Œãƒ‡ãƒ¼ã‚¿ã®ç‰¹æ€§ã€ã«åŸºã¥ã„ã¦é¸æŠã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚</p>
</blockquote>

<hr>

<h2>1.2 åˆ†é¡å•é¡Œã®è©•ä¾¡æŒ‡æ¨™</h2>

<h3>Confusion Matrixï¼ˆæ··åŒè¡Œåˆ—ï¼‰</h3>

<p><strong>Confusion Matrix</strong>ã¯ã€åˆ†é¡ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬çµæœã‚’æ•´ç†ã—ãŸè¡¨ã§ã€ã™ã¹ã¦ã®åˆ†é¡æŒ‡æ¨™ã®åŸºç¤ã¨ãªã‚Šã¾ã™ã€‚</p>

<table>
<thead>
<tr>
<th></th>
<th><strong>äºˆæ¸¬: Positive</strong></th>
<th><strong>äºˆæ¸¬: Negative</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>å®Ÿéš›: Positive</strong></td>
<td>TP (True Positive)</td>
<td>FN (False Negative)</td>
</tr>
<tr>
<td><strong>å®Ÿéš›: Negative</strong></td>
<td>FP (False Positive)</td>
<td>TN (True Negative)</td>
</tr>
</tbody>
</table>

<ul>
<li><strong>TP (True Positive)</strong>: æ­£ã—ãé™½æ€§ã¨äºˆæ¸¬</li>
<li><strong>TN (True Negative)</strong>: æ­£ã—ãé™°æ€§ã¨äºˆæ¸¬</li>
<li><strong>FP (False Positive)</strong>: èª¤ã£ã¦é™½æ€§ã¨äºˆæ¸¬ï¼ˆç¬¬ä¸€ç¨®éèª¤ã€Type I Errorï¼‰</li>
<li><strong>FN (False Negative)</strong>: èª¤ã£ã¦é™°æ€§ã¨äºˆæ¸¬ï¼ˆç¬¬äºŒç¨®éèª¤ã€Type II Errorï¼‰</li>
</ul>

<h3>Confusion Matrixã®å¯è¦–åŒ–</h3>

<pre><code class="language-python">import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.datasets import make_classification

# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
X, y = make_classification(n_samples=1000, n_features=20,
                           n_informative=15, n_redundant=5,
                           n_classes=2, weights=[0.7, 0.3],
                           random_state=42)

# è¨“ç·´ãƒ»ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿åˆ†å‰²
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42
)

# ãƒ¢ãƒ‡ãƒ«è¨“ç·´
model = LogisticRegression(random_state=42, max_iter=1000)
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

# Confusion Matrixè¨ˆç®—
cm = confusion_matrix(y_test, y_pred)

print("=== Confusion Matrix ===")
print(cm)
print(f"\nTP (True Positive):  {cm[1, 1]}")
print(f"TN (True Negative):  {cm[0, 0]}")
print(f"FP (False Positive): {cm[0, 1]}")
print(f"FN (False Negative): {cm[1, 0]}")

# å¯è¦–åŒ–
fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# æ¨™æº–çš„ãªè¡¨ç¤º
disp = ConfusionMatrixDisplay(confusion_matrix=cm,
                               display_labels=['Negative', 'Positive'])
disp.plot(ax=axes[0], cmap='Blues', values_format='d')
axes[0].set_title('Confusion Matrixï¼ˆã‚«ã‚¦ãƒ³ãƒˆï¼‰', fontsize=14)

# æ­£è¦åŒ–ï¼ˆå‰²åˆï¼‰è¡¨ç¤º
cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
disp_norm = ConfusionMatrixDisplay(confusion_matrix=cm_normalized,
                                    display_labels=['Negative', 'Positive'])
disp_norm.plot(ax=axes[1], cmap='Greens', values_format='.2f')
axes[1].set_title('Confusion Matrixï¼ˆæ­£è¦åŒ–ï¼‰', fontsize=14)

plt.tight_layout()
plt.show()
</code></pre>

<h3>Accuracyï¼ˆæ­£è§£ç‡ï¼‰</h3>

<p><strong>Accuracy</strong>ã¯ã€å…¨äºˆæ¸¬ã®ã†ã¡æ­£ã—ãäºˆæ¸¬ã—ãŸå‰²åˆã§ã™ã€‚</p>

<p>$$
\text{Accuracy} = \frac{TP + TN}{TP + TN + FP + FN}
$$</p>

<pre><code class="language-python">from sklearn.metrics import accuracy_score

accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy:.3f}")

# æ‰‹å‹•è¨ˆç®—ã§ã®ç¢ºèª
accuracy_manual = (cm[1, 1] + cm[0, 0]) / cm.sum()
print(f"Accuracy (æ‰‹å‹•è¨ˆç®—): {accuracy_manual:.3f}")
</code></pre>

<p><strong>Accuracyã®é•·æ‰€ã¨çŸ­æ‰€</strong>ï¼š</p>

<table>
<thead>
<tr>
<th>é•·æ‰€</th>
<th>çŸ­æ‰€</th>
</tr>
</thead>
<tbody>
<tr>
<td>ç›´æ„Ÿçš„ã§ç†è§£ã—ã‚„ã™ã„</td>
<td>ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿ã§èª¤è§£ã‚’æ‹›ã</td>
</tr>
<tr>
<td>å…¨ä½“çš„ãªæ€§èƒ½ã®æ¦‚è¦</td>
<td>ã‚¯ãƒ©ã‚¹ã”ã¨ã®æ€§èƒ½ãŒä¸æ˜</td>
</tr>
<tr>
<td>å‡è¡¡ãƒ‡ãƒ¼ã‚¿ã§æœ‰åŠ¹</td>
<td>ãƒ“ã‚¸ãƒã‚¹ã‚³ã‚¹ãƒˆã‚’è€ƒæ…®ã—ãªã„</td>
</tr>
</tbody>
</table>

<h3>Precisionï¼ˆé©åˆç‡ï¼‰ã¨Recallï¼ˆå†ç¾ç‡ï¼‰</h3>

<h4>Precisionï¼ˆé©åˆç‡ï¼‰</h4>

<p><strong>Precision</strong>ã¯ã€é™½æ€§ã¨äºˆæ¸¬ã—ãŸã‚‚ã®ã®ã†ã¡ã€å®Ÿéš›ã«é™½æ€§ã ã£ãŸå‰²åˆã§ã™ã€‚</p>

<p>$$
\text{Precision} = \frac{TP}{TP + FP}
$$</p>

<p><strong>æ„å‘³</strong>: ã€Œäºˆæ¸¬ã®ç²¾åº¦ã€- é™½æ€§ã¨è¨€ã£ãŸã¨ãã®ä¿¡é ¼æ€§</p>

<h4>Recallï¼ˆå†ç¾ç‡ï¼‰</h4>

<p><strong>Recall</strong>ã¯ã€å®Ÿéš›ã«é™½æ€§ã®ã‚‚ã®ã®ã†ã¡ã€æ­£ã—ãé™½æ€§ã¨äºˆæ¸¬ã—ãŸå‰²åˆã§ã™ã€‚</p>

<p>$$
\text{Recall} = \frac{TP}{TP + FN}
$$</p>

<p><strong>æ„å‘³</strong>: ã€Œæ¤œå‡ºç‡ã€- é™½æ€§ã‚’ã©ã‚Œã ã‘è¦‹é€ƒã•ãªã„ã‹</p>

<pre><code class="language-python">from sklearn.metrics import precision_score, recall_score, classification_report

precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)

print("=== Precision ã¨ Recall ===")
print(f"Precision: {precision:.3f}")
print(f"Recall:    {recall:.3f}")

# æ‰‹å‹•è¨ˆç®—
TP = cm[1, 1]
FP = cm[0, 1]
FN = cm[1, 0]

precision_manual = TP / (TP + FP)
recall_manual = TP / (TP + FN)

print(f"\nPrecision (æ‰‹å‹•): {precision_manual:.3f}")
print(f"Recall (æ‰‹å‹•):    {recall_manual:.3f}")

# è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆ
print("\n=== Classification Report ===")
print(classification_report(y_test, y_pred,
                           target_names=['Negative', 'Positive']))
</code></pre>

<h3>Precisionã¨Recallã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•</h3>

<pre><code class="language-python">from sklearn.metrics import precision_recall_curve

# äºˆæ¸¬ç¢ºç‡ã®å–å¾—
y_proba = model.predict_proba(X_test)[:, 1]

# Precision-Recallæ›²ç·šã®è¨ˆç®—
precisions, recalls, thresholds = precision_recall_curve(y_test, y_proba)

# å¯è¦–åŒ–
fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# Precision-Recallæ›²ç·š
axes[0].plot(recalls, precisions, linewidth=2, color='purple')
axes[0].set_xlabel('Recall', fontsize=12)
axes[0].set_ylabel('Precision', fontsize=12)
axes[0].set_title('Precision-Recall Curve', fontsize=14)
axes[0].grid(True, alpha=0.3)
axes[0].set_xlim([0, 1])
axes[0].set_ylim([0, 1])

# é–¾å€¤ã«ã‚ˆã‚‹å¤‰åŒ–
axes[1].plot(thresholds, precisions[:-1], label='Precision', linewidth=2)
axes[1].plot(thresholds, recalls[:-1], label='Recall', linewidth=2)
axes[1].set_xlabel('Threshold', fontsize=12)
axes[1].set_ylabel('Score', fontsize=12)
axes[1].set_title('Precision & Recall vs Threshold', fontsize=14)
axes[1].legend()
axes[1].grid(True, alpha=0.3)
axes[1].set_xlim([0, 1])
axes[1].set_ylim([0, 1])

plt.tight_layout()
plt.show()

print("=== Precision-Recallãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ• ===")
print("é–¾å€¤ã‚’ä¸Šã’ã‚‹ â†’ Precisionâ†‘ã€Recallâ†“ï¼ˆå³æ ¼ãªåˆ¤å®šï¼‰")
print("é–¾å€¤ã‚’ä¸‹ã’ã‚‹ â†’ Precisionâ†“ã€Recallâ†‘ï¼ˆå¯›å®¹ãªåˆ¤å®šï¼‰")
</code></pre>

<h3>F1-scoreï¼ˆFå€¤ï¼‰</h3>

<p><strong>F1-score</strong>ã¯ã€Precisionã¨Recallã®èª¿å’Œå¹³å‡ã§ã€ä¸¡è€…ã®ãƒãƒ©ãƒ³ã‚¹ã‚’è©•ä¾¡ã—ã¾ã™ã€‚</p>

<p>$$
\text{F1-score} = 2 \times \frac{\text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}} = \frac{2TP}{2TP + FP + FN}
$$</p>

<pre><code class="language-python">from sklearn.metrics import f1_score, fbeta_score

f1 = f1_score(y_test, y_pred)
print(f"F1-score: {f1:.3f}")

# æ‰‹å‹•è¨ˆç®—
f1_manual = 2 * (precision * recall) / (precision + recall)
print(f"F1-score (æ‰‹å‹•): {f1_manual:.3f}")

# F-beta scoreï¼ˆé‡ã¿ä»˜ã‘Få€¤ï¼‰
f2 = fbeta_score(y_test, y_pred, beta=2)  # Recallé‡è¦–
f05 = fbeta_score(y_test, y_pred, beta=0.5)  # Precisioné‡è¦–

print("\n=== F-beta Score ===")
print(f"F2-score (Recallé‡è¦–):    {f2:.3f}")
print(f"F1-score (ãƒãƒ©ãƒ³ã‚¹):       {f1:.3f}")
print(f"F0.5-score (Precisioné‡è¦–): {f05:.3f}")
</code></pre>

<p><strong>F-beta scoreã®ä¸€èˆ¬å½¢</strong>ï¼š</p>

<p>$$
F_\beta = (1 + \beta^2) \times \frac{\text{Precision} \times \text{Recall}}{\beta^2 \times \text{Precision} + \text{Recall}}
$$</p>

<ul>
<li>$\beta > 1$: Recallã‚’é‡è¦–ï¼ˆãŒã‚“æ¤œå‡ºãªã©ï¼‰</li>
<li>$\beta = 1$: Precision = Recallï¼ˆãƒãƒ©ãƒ³ã‚¹ï¼‰</li>
<li>$\beta < 1$: Precisionã‚’é‡è¦–ï¼ˆã‚¹ãƒ‘ãƒ ãƒ•ã‚£ãƒ«ã‚¿ãªã©ï¼‰</li>
</ul>

<h3>ROCæ›²ç·šã¨AUC</h3>

<p><strong>ROCæ›²ç·šï¼ˆReceiver Operating Characteristic Curveï¼‰</strong>ã¯ã€é–¾å€¤ã‚’å¤‰åŒ–ã•ã›ãŸã¨ãã®TPRï¼ˆTrue Positive Rateï¼‰ã¨FPRï¼ˆFalse Positive Rateï¼‰ã®é–¢ä¿‚ã‚’ç¤ºã—ã¾ã™ã€‚</p>

<p>$$
\text{TPR (True Positive Rate)} = \text{Recall} = \frac{TP}{TP + FN}
$$</p>

<p>$$
\text{FPR (False Positive Rate)} = \frac{FP}{FP + TN}
$$</p>

<p><strong>AUCï¼ˆArea Under the Curveï¼‰</strong>ã¯ã€ROCæ›²ç·šã®ä¸‹ã®é¢ç©ã§ã€ãƒ¢ãƒ‡ãƒ«ã®ç·åˆçš„ãªæ€§èƒ½ã‚’ç¤ºã—ã¾ã™ã€‚</p>

<pre><code class="language-python">from sklearn.metrics import roc_curve, roc_auc_score

# ROCæ›²ç·šã®è¨ˆç®—
fpr, tpr, thresholds_roc = roc_curve(y_test, y_proba)
roc_auc = roc_auc_score(y_test, y_proba)

print(f"=== ROC-AUC ===")
print(f"AUC: {roc_auc:.3f}")

# å¯è¦–åŒ–
plt.figure(figsize=(10, 8))
plt.plot(fpr, tpr, color='darkorange', linewidth=2,
         label=f'ROC curve (AUC = {roc_auc:.3f})')
plt.plot([0, 1], [0, 1], color='navy', linewidth=2,
         linestyle='--', label='Random classifier (AUC = 0.5)')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate (FPR)', fontsize=12)
plt.ylabel('True Positive Rate (TPR)', fontsize=12)
plt.title('ROC Curve', fontsize=14)
plt.legend(loc="lower right", fontsize=12)
plt.grid(True, alpha=0.3)
plt.show()

print("\n=== AUCã®è§£é‡ˆ ===")
print("AUC = 1.0: å®Œç’§ãªåˆ†é¡å™¨")
print("AUC = 0.9-1.0: å„ªç§€")
print("AUC = 0.8-0.9: è‰¯å¥½")
print("AUC = 0.7-0.8: ã¾ã‚ã¾ã‚")
print("AUC = 0.5-0.7: ä¸ååˆ†")
print("AUC = 0.5: ãƒ©ãƒ³ãƒ€ãƒ åˆ†é¡å™¨ï¼ˆæ„å‘³ãªã—ï¼‰")
</code></pre>

<h3>PR-AUCï¼ˆPrecision-Recall AUCï¼‰</h3>

<p><strong>PR-AUC</strong>ã¯ã€Precision-Recallæ›²ç·šã®ä¸‹ã®é¢ç©ã§ã™ã€‚ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿ã§ã¯ROC-AUCã‚ˆã‚Šã‚‚æœ‰ç”¨ã§ã™ã€‚</p>

<pre><code class="language-python">from sklearn.metrics import average_precision_score

# PR-AUCã®è¨ˆç®—
pr_auc = average_precision_score(y_test, y_proba)

print(f"=== PR-AUC ===")
print(f"PR-AUC: {pr_auc:.3f}")

# ROC-AUCã¨PR-AUCã®æ¯”è¼ƒå¯è¦–åŒ–
fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# ROCæ›²ç·š
axes[0].plot(fpr, tpr, color='darkorange', linewidth=2,
            label=f'ROC (AUC = {roc_auc:.3f})')
axes[0].plot([0, 1], [0, 1], color='navy', linewidth=2,
            linestyle='--', label='Random')
axes[0].set_xlabel('False Positive Rate', fontsize=12)
axes[0].set_ylabel('True Positive Rate', fontsize=12)
axes[0].set_title('ROC Curve', fontsize=14)
axes[0].legend()
axes[0].grid(True, alpha=0.3)

# PRæ›²ç·š
axes[1].plot(recalls, precisions, color='purple', linewidth=2,
            label=f'PR (AUC = {pr_auc:.3f})')
# ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ï¼ˆé™½æ€§ã‚¯ãƒ©ã‚¹ã®å‰²åˆï¼‰
baseline = y_test.sum() / len(y_test)
axes[1].axhline(y=baseline, color='navy', linewidth=2,
               linestyle='--', label=f'Baseline = {baseline:.2f}')
axes[1].set_xlabel('Recall', fontsize=12)
axes[1].set_ylabel('Precision', fontsize=12)
axes[1].set_title('Precision-Recall Curve', fontsize=14)
axes[1].legend()
axes[1].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

print("\n=== ROC-AUC vs PR-AUC ===")
print("ROC-AUC: å‡è¡¡ãƒ‡ãƒ¼ã‚¿ã«é©ã—ã¦ã„ã‚‹")
print("PR-AUC: ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿ï¼ˆé™½æ€§ã‚¯ãƒ©ã‚¹ãŒå°‘ãªã„ï¼‰ã«é©ã—ã¦ã„ã‚‹")
</code></pre>

<h3>Log Lossï¼ˆå¯¾æ•°æå¤±ï¼‰</h3>

<p><strong>Log Loss</strong>ã¯ã€äºˆæ¸¬ç¢ºç‡ã¨å®Ÿéš›ã®ãƒ©ãƒ™ãƒ«ã®ä¹–é›¢ã‚’æ¸¬å®šã—ã¾ã™ã€‚å°ã•ã„ã»ã©è‰¯å¥½ã§ã™ã€‚</p>

<p>$$
\text{Log Loss} = -\frac{1}{N} \sum_{i=1}^{N} \left[ y_i \log(\hat{p}_i) + (1 - y_i) \log(1 - \hat{p}_i) \right]
$$</p>

<pre><code class="language-python">from sklearn.metrics import log_loss

# Log Lossã®è¨ˆç®—
logloss = log_loss(y_test, y_proba)

print(f"=== Log Loss ===")
print(f"Log Loss: {logloss:.3f}")

# å®Œç’§ãªäºˆæ¸¬ã¨ã®æ¯”è¼ƒ
y_proba_perfect = y_test.astype(float)
logloss_perfect = log_loss(y_test, y_proba_perfect)

# ãƒ©ãƒ³ãƒ€ãƒ äºˆæ¸¬ã¨ã®æ¯”è¼ƒ
y_proba_random = np.random.rand(len(y_test))
logloss_random = log_loss(y_test, y_proba_random)

print(f"\næ¯”è¼ƒ:")
print(f"  ç¾åœ¨ã®ãƒ¢ãƒ‡ãƒ«: {logloss:.3f}")
print(f"  å®Œç’§ãªäºˆæ¸¬:   {logloss_perfect:.6f}")
print(f"  ãƒ©ãƒ³ãƒ€ãƒ äºˆæ¸¬: {logloss_random:.3f}")

print("\nè§£é‡ˆ:")
print("Log Lossã¯ç¢ºç‡äºˆæ¸¬ã®è³ªã‚’è©•ä¾¡")
print("0ã«è¿‘ã„ã»ã©è‰¯å¥½ï¼ˆå®Œç’§ãªäºˆæ¸¬ã§ã¯0ï¼‰")
print("Kaggleãªã©ç¢ºç‡äºˆæ¸¬ãŒé‡è¦ãªã‚³ãƒ³ãƒšã§ä½¿ç”¨")
</code></pre>

<h3>å¤šã‚¯ãƒ©ã‚¹åˆ†é¡ã®è©•ä¾¡æŒ‡æ¨™</h3>

<h4>Macro / Micro / Weighted Averaging</h4>

<pre><code class="language-python">from sklearn.datasets import make_classification
from sklearn.multiclass import OneVsRestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix

# å¤šã‚¯ãƒ©ã‚¹ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
X_multi, y_multi = make_classification(n_samples=1000, n_features=20,
                                       n_informative=15, n_redundant=5,
                                       n_classes=3, n_clusters_per_class=1,
                                       weights=[0.5, 0.3, 0.2],
                                       random_state=42)

# è¨“ç·´ãƒ»ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿åˆ†å‰²
X_train_m, X_test_m, y_train_m, y_test_m = train_test_split(
    X_multi, y_multi, test_size=0.3, random_state=42
)

# ãƒ¢ãƒ‡ãƒ«è¨“ç·´
model_multi = LogisticRegression(random_state=42, max_iter=1000)
model_multi.fit(X_train_m, y_train_m)
y_pred_m = model_multi.predict(X_test_m)

print("=== å¤šã‚¯ãƒ©ã‚¹åˆ†é¡ã®è©•ä¾¡ ===")
print(classification_report(y_test_m, y_pred_m,
                           target_names=['Class 0', 'Class 1', 'Class 2']))

# Confusion Matrix
cm_multi = confusion_matrix(y_test_m, y_pred_m)
plt.figure(figsize=(8, 6))
sns.heatmap(cm_multi, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Class 0', 'Class 1', 'Class 2'],
            yticklabels=['Class 0', 'Class 1', 'Class 2'])
plt.xlabel('Predicted', fontsize=12)
plt.ylabel('Actual', fontsize=12)
plt.title('Confusion Matrix (Multi-class)', fontsize=14)
plt.show()

print("\n=== å¹³å‡åŒ–æ‰‹æ³•ã®èª¬æ˜ ===")
print("Macro-average: å„ã‚¯ãƒ©ã‚¹ã®æŒ‡æ¨™ã‚’å˜ç´”å¹³å‡ï¼ˆã‚¯ãƒ©ã‚¹ä¸å‡è¡¡ã«æ•æ„Ÿï¼‰")
print("Micro-average: å…¨ä½“ã®TP, FP, FNã‹ã‚‰è¨ˆç®—ï¼ˆã‚µãƒ³ãƒ—ãƒ«æ•°é‡è¦–ï¼‰")
print("Weighted-average: ã‚¯ãƒ©ã‚¹ã‚µã‚¤ã‚ºã§é‡ã¿ä»˜ã‘å¹³å‡ï¼ˆå®Ÿç”¨çš„ï¼‰")
</code></pre>

<hr>

<h2>1.3 å›å¸°å•é¡Œã®è©•ä¾¡æŒ‡æ¨™</h2>

<h3>å›å¸°å•é¡Œã¨ã¯</h3>

<p><strong>å›å¸°å•é¡Œ</strong>ã¯ã€é€£ç¶šå€¤ã‚’äºˆæ¸¬ã™ã‚‹ã‚¿ã‚¹ã‚¯ã§ã™ï¼ˆä¾‹: ä½å®…ä¾¡æ ¼ã€æ°—æ¸©ã€å£²ä¸Šï¼‰ã€‚</p>

<h3>MAEï¼ˆMean Absolute Errorï¼‰</h3>

<p><strong>MAE</strong>ã¯ã€äºˆæ¸¬å€¤ã¨å®Ÿéš›ã®å€¤ã®çµ¶å¯¾èª¤å·®ã®å¹³å‡ã§ã™ã€‚</p>

<p>$$
\text{MAE} = \frac{1}{N} \sum_{i=1}^{N} |y_i - \hat{y}_i|
$$</p>

<pre><code class="language-python">from sklearn.datasets import make_regression
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import numpy as np
import matplotlib.pyplot as plt

# å›å¸°ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
X_reg, y_reg = make_regression(n_samples=1000, n_features=10,
                                n_informative=8, noise=20,
                                random_state=42)

# è¨“ç·´ãƒ»ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿åˆ†å‰²
X_train_r, X_test_r, y_train_r, y_test_r = train_test_split(
    X_reg, y_reg, test_size=0.3, random_state=42
)

# ãƒ¢ãƒ‡ãƒ«è¨“ç·´
model_reg = LinearRegression()
model_reg.fit(X_train_r, y_train_r)
y_pred_r = model_reg.predict(X_test_r)

# MAEã®è¨ˆç®—
mae = mean_absolute_error(y_test_r, y_pred_r)

print("=== MAE (Mean Absolute Error) ===")
print(f"MAE: {mae:.3f}")

# æ‰‹å‹•è¨ˆç®—
mae_manual = np.mean(np.abs(y_test_r - y_pred_r))
print(f"MAE (æ‰‹å‹•è¨ˆç®—): {mae_manual:.3f}")

print("\nç‰¹å¾´:")
print("- å¤–ã‚Œå€¤ã«é ‘å¥")
print("- è§£é‡ˆã—ã‚„ã™ã„ï¼ˆå…ƒã®å˜ä½ï¼‰")
print("- ã™ã¹ã¦ã®èª¤å·®ã‚’ç­‰ã—ãæ‰±ã†")
</code></pre>

<h3>MSEï¼ˆMean Squared Errorï¼‰ã¨RMSE</h3>

<p><strong>MSE</strong>ã¯ã€äºˆæ¸¬å€¤ã¨å®Ÿéš›ã®å€¤ã®äºŒä¹—èª¤å·®ã®å¹³å‡ã§ã™ã€‚</p>

<p>$$
\text{MSE} = \frac{1}{N} \sum_{i=1}^{N} (y_i - \hat{y}_i)^2
$$</p>

<p><strong>RMSEï¼ˆRoot Mean Squared Errorï¼‰</strong>ã¯ã€MSEã®å¹³æ–¹æ ¹ã§ã€å…ƒã®å˜ä½ã«æˆ»ã—ã¾ã™ã€‚</p>

<p>$$
\text{RMSE} = \sqrt{\text{MSE}} = \sqrt{\frac{1}{N} \sum_{i=1}^{N} (y_i - \hat{y}_i)^2}
$$</p>

<pre><code class="language-python">from sklearn.metrics import mean_squared_error

# MSEã®è¨ˆç®—
mse = mean_squared_error(y_test_r, y_pred_r)
rmse = np.sqrt(mse)

# ã¾ãŸã¯ç›´æ¥è¨ˆç®—
rmse_direct = mean_squared_error(y_test_r, y_pred_r, squared=False)

print("=== MSE ã¨ RMSE ===")
print(f"MSE:  {mse:.3f}")
print(f"RMSE: {rmse:.3f}")
print(f"RMSE (ç›´æ¥è¨ˆç®—): {rmse_direct:.3f}")

print("\nç‰¹å¾´:")
print("- å¤§ããªèª¤å·®ã‚’å¼·ãç½°ã™ã‚‹")
print("- å¤–ã‚Œå€¤ã«æ•æ„Ÿ")
print("- å¾®åˆ†å¯èƒ½ï¼ˆæœ€é©åŒ–ã«æœ‰åˆ©ï¼‰")
print("- RMSEã¯å…ƒã®å˜ä½ã§è§£é‡ˆå¯èƒ½")
</code></pre>

<h3>MAE vs MSE/RMSEã®æ¯”è¼ƒ</h3>

<pre><code class="language-python"># å¤–ã‚Œå€¤ã®å½±éŸ¿ã‚’å¯è¦–åŒ–
# å®Œç’§ãªäºˆæ¸¬ã«å°‘æ•°ã®å¤–ã‚Œå€¤ã‚’è¿½åŠ 
y_pred_with_outliers = y_test_r.copy()
outlier_indices = np.random.choice(len(y_test_r), size=5, replace=False)
y_pred_with_outliers[outlier_indices] += np.random.uniform(100, 200, 5)

mae_with_outliers = mean_absolute_error(y_test_r, y_pred_with_outliers)
rmse_with_outliers = mean_squared_error(y_test_r, y_pred_with_outliers, squared=False)

print("=== å¤–ã‚Œå€¤ã®å½±éŸ¿ ===")
print(f"å…ƒã®äºˆæ¸¬:")
print(f"  MAE:  {mae:.3f}")
print(f"  RMSE: {rmse:.3f}")
print(f"\nå¤–ã‚Œå€¤è¿½åŠ å¾Œ:")
print(f"  MAE:  {mae_with_outliers:.3f} (å¢—åŠ : {mae_with_outliers/mae:.2f}å€)")
print(f"  RMSE: {rmse_with_outliers:.3f} (å¢—åŠ : {rmse_with_outliers/rmse:.2f}å€)")

print("\nçµè«–:")
print("RMSEã¯å¤–ã‚Œå€¤ã«éå¸¸ã«æ•æ„Ÿï¼ˆäºŒä¹—ã™ã‚‹ãŸã‚ï¼‰")
print("MAEã¯å¤–ã‚Œå€¤ã«é ‘å¥")
</code></pre>

<h3>RÂ²ï¼ˆæ±ºå®šä¿‚æ•°ï¼‰</h3>

<p><strong>RÂ²ï¼ˆR-squaredï¼‰</strong>ã¯ã€ãƒ¢ãƒ‡ãƒ«ãŒãƒ‡ãƒ¼ã‚¿ã®åˆ†æ•£ã‚’ã©ã‚Œã ã‘èª¬æ˜ã§ãã‚‹ã‹ã‚’ç¤ºã—ã¾ã™ã€‚</p>

<p>$$
R^2 = 1 - \frac{\sum_{i=1}^{N} (y_i - \hat{y}_i)^2}{\sum_{i=1}^{N} (y_i - \bar{y})^2} = 1 - \frac{\text{SSR}}{\text{SST}}
$$</p>

<ul>
<li>$\text{SSR}$: Residual Sum of Squaresï¼ˆæ®‹å·®å¹³æ–¹å’Œï¼‰</li>
<li>$\text{SST}$: Total Sum of Squaresï¼ˆå…¨å¹³æ–¹å’Œï¼‰</li>
</ul>

<pre><code class="language-python">from sklearn.metrics import r2_score

# RÂ²ã®è¨ˆç®—
r2 = r2_score(y_test_r, y_pred_r)

print("=== RÂ² (æ±ºå®šä¿‚æ•°) ===")
print(f"RÂ²: {r2:.3f}")

# æ‰‹å‹•è¨ˆç®—
ss_res = np.sum((y_test_r - y_pred_r) ** 2)
ss_tot = np.sum((y_test_r - y_test_r.mean()) ** 2)
r2_manual = 1 - (ss_res / ss_tot)

print(f"RÂ² (æ‰‹å‹•è¨ˆç®—): {r2_manual:.3f}")

print("\n=== RÂ²ã®è§£é‡ˆ ===")
print("RÂ² = 1.0: å®Œç’§ãªäºˆæ¸¬")
print("RÂ² = 0.9-1.0: éå¸¸ã«è‰¯å¥½")
print("RÂ² = 0.7-0.9: è‰¯å¥½")
print("RÂ² = 0.5-0.7: ã¾ã‚ã¾ã‚")
print("RÂ² = 0.0: ãƒ¢ãƒ‡ãƒ«ãŒå¹³å‡å€¤ã¨åŒç­‰")
print("RÂ² < 0.0: ãƒ¢ãƒ‡ãƒ«ãŒå¹³å‡å€¤ã‚ˆã‚Šæ‚ªã„")

print(f"\næ„å‘³: ãƒ¢ãƒ‡ãƒ«ã¯åˆ†æ•£ã®{r2*100:.1f}%ã‚’èª¬æ˜ã—ã¦ã„ã‚‹")
</code></pre>

<h3>Adjusted RÂ²ï¼ˆèª¿æ•´æ¸ˆã¿æ±ºå®šä¿‚æ•°ï¼‰</h3>

<p><strong>Adjusted RÂ²</strong>ã¯ã€ç‰¹å¾´é‡ã®æ•°ã‚’è€ƒæ…®ã—ãŸRÂ²ã§ã™ã€‚</p>

<p>$$
\text{Adjusted } R^2 = 1 - \frac{(1 - R^2)(N - 1)}{N - p - 1}
$$</p>

<ul>
<li>$N$: ã‚µãƒ³ãƒ—ãƒ«æ•°</li>
<li>$p$: ç‰¹å¾´é‡ã®æ•°</li>
</ul>

<pre><code class="language-python"># Adjusted RÂ²ã®è¨ˆç®—
n = len(y_test_r)
p = X_test_r.shape[1]
adjusted_r2 = 1 - (1 - r2) * (n - 1) / (n - p - 1)

print("=== Adjusted RÂ² ===")
print(f"RÂ²:          {r2:.3f}")
print(f"Adjusted RÂ²: {adjusted_r2:.3f}")
print(f"ç‰¹å¾´é‡ã®æ•°:   {p}")
print(f"ã‚µãƒ³ãƒ—ãƒ«æ•°:   {n}")

print("\nç‰¹å¾´:")
print("- ç‰¹å¾´é‡ãŒå¢—ãˆã¦ã‚‚ãƒšãƒŠãƒ«ãƒ†ã‚£ã‚’èª²ã™")
print("- ãƒ¢ãƒ‡ãƒ«é¸æŠï¼ˆç‰¹å¾´é‡é¸æŠï¼‰ã«æœ‰ç”¨")
print("- éå­¦ç¿’ã®æ¤œå‡ºã«å½¹ç«‹ã¤")
</code></pre>

<h3>MAPEï¼ˆMean Absolute Percentage Errorï¼‰</h3>

<p><strong>MAPE</strong>ã¯ã€ç›¸å¯¾èª¤å·®ã®å¹³å‡ã‚’ç™¾åˆ†ç‡ã§è¡¨ã—ã¾ã™ã€‚</p>

<p>$$
\text{MAPE} = \frac{100\%}{N} \sum_{i=1}^{N} \left| \frac{y_i - \hat{y}_i}{y_i} \right|
$$</p>

<pre><code class="language-python">from sklearn.metrics import mean_absolute_percentage_error

# MAPEã®è¨ˆç®—ï¼ˆscikit-learn 0.24+ï¼‰
mape = mean_absolute_percentage_error(y_test_r, y_pred_r)

# æ‰‹å‹•è¨ˆç®—
mape_manual = np.mean(np.abs((y_test_r - y_pred_r) / y_test_r)) * 100

print("=== MAPE (Mean Absolute Percentage Error) ===")
print(f"MAPE: {mape*100:.2f}%")
print(f"MAPE (æ‰‹å‹•): {mape_manual:.2f}%")

print("\nç‰¹å¾´:")
print("- ã‚¹ã‚±ãƒ¼ãƒ«ã«ä¾å­˜ã—ãªã„ï¼ˆç•°ãªã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§æ¯”è¼ƒå¯èƒ½ï¼‰")
print("- ãƒ“ã‚¸ãƒã‚¹ã§ç†è§£ã—ã‚„ã™ã„ï¼ˆãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆè¡¨ç¤ºï¼‰")
print("- y=0ãŒã‚ã‚‹ã¨è¨ˆç®—ä¸å¯")
print("- å°ã•ã„å€¤ã§èª¤å·®ãŒå¤§ããè¦‹ãˆã‚‹")
</code></pre>

<h3>MSLEï¼ˆMean Squared Logarithmic Errorï¼‰</h3>

<p><strong>MSLE</strong>ã¯ã€å¯¾æ•°ã‚¹ã‚±ãƒ¼ãƒ«ã§ã®äºŒä¹—èª¤å·®ã§ã™ã€‚</p>

<p>$$
\text{MSLE} = \frac{1}{N} \sum_{i=1}^{N} (\log(1 + y_i) - \log(1 + \hat{y}_i))^2
$$</p>

<pre><code class="language-python">from sklearn.metrics import mean_squared_log_error

# MSLEã®è¨ˆç®—ï¼ˆæ­£ã®å€¤ã®ã¿ï¼‰
y_test_r_positive = np.abs(y_test_r) + 1
y_pred_r_positive = np.abs(y_pred_r) + 1

msle = mean_squared_log_error(y_test_r_positive, y_pred_r_positive)

print("=== MSLE (Mean Squared Logarithmic Error) ===")
print(f"MSLE: {msle:.4f}")

print("\nç‰¹å¾´:")
print("- å¤§ãã„å€¤ã®èª¤å·®ã‚’ç›¸å¯¾çš„ã«å°ã•ãè©•ä¾¡")
print("- å°ã•ã„å€¤ã®äºˆæ¸¬ç²¾åº¦ã‚’é‡è¦–")
print("- æ­£ã®å€¤ã®ã¿ä½¿ç”¨å¯èƒ½")
print("- ä¾¡æ ¼äºˆæ¸¬ãªã©å³è£¾ã®é•·ã„åˆ†å¸ƒã«æœ‰ç”¨")
</code></pre>

<h3>å›å¸°æŒ‡æ¨™ã®å¯è¦–åŒ–</h3>

<pre><code class="language-python"># äºˆæ¸¬å€¤ vs å®Ÿéš›ã®å€¤
fig, axes = plt.subplots(2, 2, figsize=(14, 12))

# 1. æ•£å¸ƒå›³
axes[0, 0].scatter(y_test_r, y_pred_r, alpha=0.5, edgecolors='black')
axes[0, 0].plot([y_test_r.min(), y_test_r.max()],
               [y_test_r.min(), y_test_r.max()],
               'r--', linewidth=2, label='Perfect prediction')
axes[0, 0].set_xlabel('Actual', fontsize=12)
axes[0, 0].set_ylabel('Predicted', fontsize=12)
axes[0, 0].set_title('Predicted vs Actual', fontsize=14)
axes[0, 0].legend()
axes[0, 0].grid(True, alpha=0.3)

# 2. æ®‹å·®ãƒ—ãƒ­ãƒƒãƒˆ
residuals = y_test_r - y_pred_r
axes[0, 1].scatter(y_pred_r, residuals, alpha=0.5, edgecolors='black')
axes[0, 1].axhline(y=0, color='r', linestyle='--', linewidth=2)
axes[0, 1].set_xlabel('Predicted', fontsize=12)
axes[0, 1].set_ylabel('Residuals', fontsize=12)
axes[0, 1].set_title('Residual Plot', fontsize=14)
axes[0, 1].grid(True, alpha=0.3)

# 3. æ®‹å·®ã®åˆ†å¸ƒ
axes[1, 0].hist(residuals, bins=30, alpha=0.7, edgecolor='black')
axes[1, 0].set_xlabel('Residuals', fontsize=12)
axes[1, 0].set_ylabel('Frequency', fontsize=12)
axes[1, 0].set_title('Residual Distribution', fontsize=14)
axes[1, 0].axvline(x=0, color='r', linestyle='--', linewidth=2)
axes[1, 0].grid(True, alpha=0.3)

# 4. è©•ä¾¡æŒ‡æ¨™ã®æ¯”è¼ƒ
metrics = {
    'MAE': mae,
    'RMSE': rmse,
    'RÂ²': r2,
    'Adj RÂ²': adjusted_r2,
    'MAPE (%)': mape * 100
}
metric_names = list(metrics.keys())
metric_values = list(metrics.values())

bars = axes[1, 1].bar(range(len(metrics)), metric_values,
                       color=['skyblue', 'lightcoral', 'lightgreen', 'orange', 'pink'],
                       edgecolor='black')
axes[1, 1].set_xticks(range(len(metrics)))
axes[1, 1].set_xticklabels(metric_names, rotation=45, ha='right')
axes[1, 1].set_ylabel('Value', fontsize=12)
axes[1, 1].set_title('Regression Metrics', fontsize=14)
axes[1, 1].grid(True, alpha=0.3, axis='y')

# å„ãƒãƒ¼ã«å€¤ã‚’è¡¨ç¤º
for i, (bar, value) in enumerate(zip(bars, metric_values)):
    height = bar.get_height()
    axes[1, 1].text(bar.get_x() + bar.get_width()/2., height,
                    f'{value:.2f}',
                    ha='center', va='bottom', fontsize=10)

plt.tight_layout()
plt.show()
</code></pre>

<h3>å›å¸°æŒ‡æ¨™ã®é¸æŠã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³</h3>

<table>
<thead>
<tr>
<th>çŠ¶æ³</th>
<th>æ¨å¥¨æŒ‡æ¨™</th>
<th>ç†ç”±</th>
</tr>
</thead>
<tbody>
<tr>
<td>å¤–ã‚Œå€¤ãŒå¤šã„</td>
<td>MAE</td>
<td>å¤–ã‚Œå€¤ã«é ‘å¥</td>
</tr>
<tr>
<td>å¤§ããªèª¤å·®ã‚’é‡è¦–</td>
<td>MSEã€RMSE</td>
<td>äºŒä¹—ã«ã‚ˆã‚Šå¤§ããªèª¤å·®ã‚’å¼·èª¿</td>
</tr>
<tr>
<td>èª¬æ˜åŠ›ã‚’è©•ä¾¡</td>
<td>RÂ²ã€Adjusted RÂ²</td>
<td>åˆ†æ•£ã®èª¬æ˜å‰²åˆ</td>
</tr>
<tr>
<td>ç›¸å¯¾èª¤å·®ãŒé‡è¦</td>
<td>MAPE</td>
<td>ãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆè¡¨ç¤º</td>
</tr>
<tr>
<td>å³è£¾ã®é•·ã„åˆ†å¸ƒ</td>
<td>MSLE</td>
<td>å¯¾æ•°ã‚¹ã‚±ãƒ¼ãƒ«</td>
</tr>
<tr>
<td>ç•°ãªã‚‹ã‚¹ã‚±ãƒ¼ãƒ«ã®æ¯”è¼ƒ</td>
<td>MAPEã€RÂ²</td>
<td>ã‚¹ã‚±ãƒ¼ãƒ«ã«ä¾å­˜ã—ãªã„</td>
</tr>
</tbody>
</table>

<hr>

<h2>1.4 è©•ä¾¡æŒ‡æ¨™ã®é¸ã³æ–¹</h2>

<h3>ãƒ“ã‚¸ãƒã‚¹ç›®çš„ã«å¿œã˜ãŸé¸æŠ</h3>

<table>
<thead>
<tr>
<th>ãƒ“ã‚¸ãƒã‚¹èª²é¡Œ</th>
<th>é‡è¦–ã™ã¹ãã“ã¨</th>
<th>æ¨å¥¨æŒ‡æ¨™</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>åŒ»ç™‚è¨ºæ–­ï¼ˆãŒã‚“æ¤œå‡ºï¼‰</strong></td>
<td>å½é™°æ€§ã‚’æœ€å°åŒ–</td>
<td>Recallã€F2-score</td>
</tr>
<tr>
<td><strong>ã‚¹ãƒ‘ãƒ ãƒ•ã‚£ãƒ«ã‚¿</strong></td>
<td>å½é™½æ€§ã‚’æœ€å°åŒ–</td>
<td>Precisionã€F0.5-score</td>
</tr>
<tr>
<td><strong>ä¸ä¿¡å¯©æŸ»</strong></td>
<td>ãƒãƒ©ãƒ³ã‚¹</td>
<td>F1-scoreã€AUC</td>
</tr>
<tr>
<td><strong>ä¸æ­£æ¤œå‡º</strong></td>
<td>ç•°å¸¸ã‚’è¦‹é€ƒã•ãªã„</td>
<td>Recallã€PR-AUC</td>
</tr>
<tr>
<td><strong>ä½å®…ä¾¡æ ¼äºˆæ¸¬</strong></td>
<td>å¹³å‡çš„ãªèª¤å·®</td>
<td>MAEã€RMSE</td>
</tr>
<tr>
<td><strong>éœ€è¦äºˆæ¸¬</strong></td>
<td>ç›¸å¯¾èª¤å·®</td>
<td>MAPE</td>
</tr>
<tr>
<td><strong>å£²ä¸Šäºˆæ¸¬</strong></td>
<td>èª¬æ˜åŠ›</td>
<td>RÂ²ã€Adjusted RÂ²</td>
</tr>
</tbody>
</table>

<h3>ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿ã§ã®æ³¨æ„ç‚¹</h3>

<pre><code class="language-python"># æ¥µç«¯ãªä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿ã®ä¾‹
from sklearn.datasets import make_classification
from sklearn.metrics import accuracy_score, f1_score, roc_auc_score

# ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆï¼ˆé™½æ€§ã‚¯ãƒ©ã‚¹1%ï¼‰
X_imb, y_imb = make_classification(n_samples=10000, n_features=20,
                                   n_informative=15, n_redundant=5,
                                   n_classes=2, weights=[0.99, 0.01],
                                   random_state=42)

X_train_imb, X_test_imb, y_train_imb, y_test_imb = train_test_split(
    X_imb, y_imb, test_size=0.3, random_state=42
)

# 2ã¤ã®ãƒ¢ãƒ‡ãƒ«
# ãƒ¢ãƒ‡ãƒ«A: å¸¸ã«é™°æ€§ã¨äºˆæ¸¬ï¼ˆãƒŠã‚¤ãƒ¼ãƒ–ï¼‰
y_pred_A = np.zeros(len(y_test_imb))

# ãƒ¢ãƒ‡ãƒ«B: å®Ÿéš›ã«å­¦ç¿’ï¼ˆãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ï¼‰
model_imb = LogisticRegression(random_state=42, max_iter=1000)
model_imb.fit(X_train_imb, y_train_imb)
y_pred_B = model_imb.predict(X_test_imb)
y_proba_B = model_imb.predict_proba(X_test_imb)[:, 1]

print("=== ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿ã§ã®è©•ä¾¡æŒ‡æ¨™ã®æ¯”è¼ƒ ===\n")
print(f"é™½æ€§ã‚¯ãƒ©ã‚¹ã®å‰²åˆ: {y_test_imb.sum() / len(y_test_imb) * 100:.2f}%\n")

print("ãƒ¢ãƒ‡ãƒ«Aï¼ˆå¸¸ã«é™°æ€§ã¨äºˆæ¸¬ï¼‰:")
print(f"  Accuracy:  {accuracy_score(y_test_imb, y_pred_A):.3f}")
print(f"  F1-score:  {f1_score(y_test_imb, y_pred_A, zero_division=0):.3f}")
print(f"  ROC-AUC:   è¨ˆç®—ä¸å¯ï¼ˆäºˆæ¸¬ã«å¤‰åŒ–ãªã—ï¼‰")

print("\nãƒ¢ãƒ‡ãƒ«Bï¼ˆå®Ÿéš›ã«å­¦ç¿’ï¼‰:")
print(f"  Accuracy:  {accuracy_score(y_test_imb, y_pred_B):.3f}")
print(f"  F1-score:  {f1_score(y_test_imb, y_pred_B):.3f}")
print(f"  ROC-AUC:   {roc_auc_score(y_test_imb, y_proba_B):.3f}")

print("\nçµè«–:")
print("- Accuracyã¯ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿ã§èª¤è§£ã‚’æ‹›ã")
print("- F1-scoreã€AUCã¯ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿ã§ã‚‚ä¿¡é ¼ã§ãã‚‹")
print("- å¸¸ã«è¤‡æ•°ã®æŒ‡æ¨™ã‚’ç¢ºèªã™ã¹ã")
</code></pre>

<h3>ã‚³ã‚¹ãƒˆè€ƒæ…®å‹ã®è©•ä¾¡</h3>

<pre><code class="language-python"># ã‚³ã‚¹ãƒˆã‚’è€ƒæ…®ã—ãŸè©•ä¾¡
def cost_based_evaluation(y_true, y_pred, cost_fp, cost_fn):
    """
    ã‚³ã‚¹ãƒˆãƒ™ãƒ¼ã‚¹ã®è©•ä¾¡

    Parameters:
    -----------
    y_true : array-like
        å®Ÿéš›ã®ãƒ©ãƒ™ãƒ«
    y_pred : array-like
        äºˆæ¸¬ãƒ©ãƒ™ãƒ«
    cost_fp : float
        å½é™½æ€§ã®ã‚³ã‚¹ãƒˆ
    cost_fn : float
        å½é™°æ€§ã®ã‚³ã‚¹ãƒˆ

    Returns:
    --------
    total_cost : float
        ç·ã‚³ã‚¹ãƒˆ
    """
    cm = confusion_matrix(y_true, y_pred)
    fp = cm[0, 1]
    fn = cm[1, 0]

    total_cost = (fp * cost_fp) + (fn * cost_fn)
    return total_cost, fp, fn

# ä¾‹: ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆã‚«ãƒ¼ãƒ‰ä¸æ­£æ¤œå‡º
# å½é™½æ€§ï¼ˆæ­£å¸¸ã‚’ä¸æ­£ã¨èª¤åˆ¤å®šï¼‰: é¡§å®¢ã®ä¸ä¾¿ã€ã‚³ã‚¹ãƒˆ = 10
# å½é™°æ€§ï¼ˆä¸æ­£ã‚’è¦‹é€ƒã™ï¼‰: é‡‘éŠ­æå¤±ã€ã‚³ã‚¹ãƒˆ = 100

cost_fp = 10
cost_fn = 100

total_cost, fp, fn = cost_based_evaluation(y_test, y_pred, cost_fp, cost_fn)

print("=== ã‚³ã‚¹ãƒˆãƒ™ãƒ¼ã‚¹è©•ä¾¡ ===")
print(f"å½é™½æ€§ï¼ˆFPï¼‰ã®æ•°: {fp}, ã‚³ã‚¹ãƒˆ: {fp * cost_fp}")
print(f"å½é™°æ€§ï¼ˆFNï¼‰ã®æ•°: {fn}, ã‚³ã‚¹ãƒˆ: {fn * cost_fn}")
print(f"ç·ã‚³ã‚¹ãƒˆ: {total_cost}")

print("\næ„å‘³:")
print("ãƒ“ã‚¸ãƒã‚¹ã‚³ã‚¹ãƒˆã‚’è€ƒæ…®ã™ã‚‹ã“ã¨ã§ã€")
print("ç²¾åº¦ä»¥å¤–ã®é‡è¦ãªè¦ç´ ã‚’å®šé‡åŒ–ã§ãã‚‹")
</code></pre>

<h3>ã‚«ã‚¹ã‚¿ãƒ è©•ä¾¡æŒ‡æ¨™ã®ä½œæˆ</h3>

<pre><code class="language-python">from sklearn.metrics import make_scorer

# ã‚«ã‚¹ã‚¿ãƒ è©•ä¾¡é–¢æ•°
def custom_business_metric(y_true, y_pred):
    """
    ãƒ“ã‚¸ãƒã‚¹ç›®çš„ã«ç‰¹åŒ–ã—ãŸã‚«ã‚¹ã‚¿ãƒ è©•ä¾¡æŒ‡æ¨™
    ä¾‹: å½é™°æ€§ã‚’å¼·ãç½°ã™ã‚‹
    """
    cm = confusion_matrix(y_true, y_pred)
    tp = cm[1, 1]
    tn = cm[0, 0]
    fp = cm[0, 1]
    fn = cm[1, 0]

    # ã‚«ã‚¹ã‚¿ãƒ ã‚¹ã‚³ã‚¢: æ­£è§£ã«å ±é…¬ã€å½é™°æ€§ã«å¤§ããªãƒšãƒŠãƒ«ãƒ†ã‚£
    score = (tp * 1.0) + (tn * 0.5) - (fp * 0.3) - (fn * 2.0)
    return score

# scikit-learnã§ä½¿ãˆã‚‹ã‚ˆã†ã«scorerã‚’ä½œæˆ
custom_scorer = make_scorer(custom_business_metric)

# ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒãªã©ã§ä½¿ç”¨å¯èƒ½
print("=== ã‚«ã‚¹ã‚¿ãƒ è©•ä¾¡æŒ‡æ¨™ ===")
print(f"ã‚«ã‚¹ã‚¿ãƒ ã‚¹ã‚³ã‚¢: {custom_business_metric(y_test, y_pred):.2f}")

print("\nç”¨é€”:")
print("- ãƒ“ã‚¸ãƒã‚¹å›ºæœ‰ã®å„ªå…ˆé †ä½ã‚’åæ˜ ")
print("- ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´ã«ä½¿ç”¨")
print("- ãƒ¢ãƒ‡ãƒ«é¸æŠã®åŸºæº–ã¨ã—ã¦æ´»ç”¨")
</code></pre>

<hr>

<h2>1.5 æœ¬ç« ã®ã¾ã¨ã‚</h2>

<h3>å­¦ã‚“ã ã“ã¨</h3>

<ol>
<li><p><strong>è©•ä¾¡æŒ‡æ¨™ã®é‡è¦æ€§</strong></p>
<ul>
<li>é©åˆ‡ãªæŒ‡æ¨™é¸æŠãŒãƒ¢ãƒ‡ãƒ«é–‹ç™ºã®æˆå¦ã‚’æ±ºã‚ã‚‹</li>
<li>ãƒ“ã‚¸ãƒã‚¹ç›®çš„ã¨ãƒ‡ãƒ¼ã‚¿ç‰¹æ€§ã«åŸºã¥ã„ã¦é¸æŠ</li>
</ul></li>

<li><p><strong>åˆ†é¡å•é¡Œã®è©•ä¾¡æŒ‡æ¨™</strong></p>
<ul>
<li>Confusion Matrix: ã™ã¹ã¦ã®æŒ‡æ¨™ã®åŸºç¤</li>
<li>Accuracy: å…¨ä½“ã®æ­£è§£ç‡ï¼ˆä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿ã§æ³¨æ„ï¼‰</li>
<li>Precision: é™½æ€§äºˆæ¸¬ã®ç²¾åº¦</li>
<li>Recall: é™½æ€§ã®æ¤œå‡ºç‡</li>
<li>F1-score: Precisionã¨Recallã®ãƒãƒ©ãƒ³ã‚¹</li>
<li>ROC-AUC: é–¾å€¤ã«ä¾å­˜ã—ãªã„ç·åˆè©•ä¾¡</li>
<li>PR-AUC: ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿ã«é©ã—ãŸè©•ä¾¡</li>
<li>Log Loss: ç¢ºç‡äºˆæ¸¬ã®è³ª</li>
</ul></li>

<li><p><strong>å›å¸°å•é¡Œã®è©•ä¾¡æŒ‡æ¨™</strong></p>
<ul>
<li>MAE: å¤–ã‚Œå€¤ã«é ‘å¥</li>
<li>MSE/RMSE: å¤§ããªèª¤å·®ã‚’å¼·èª¿</li>
<li>RÂ²: åˆ†æ•£ã®èª¬æ˜åŠ›</li>
<li>MAPE: ç›¸å¯¾èª¤å·®ï¼ˆãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆè¡¨ç¤ºï¼‰</li>
<li>MSLE: å³è£¾ã®é•·ã„åˆ†å¸ƒã«æœ‰ç”¨</li>
</ul></li>

<li><p><strong>è©•ä¾¡æŒ‡æ¨™ã®é¸ã³æ–¹</strong></p>
<ul>
<li>ãƒ“ã‚¸ãƒã‚¹ã‚³ã‚¹ãƒˆã®è€ƒæ…®</li>
<li>ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿ã¸ã®å¯¾å¿œ</li>
<li>ã‚«ã‚¹ã‚¿ãƒ æŒ‡æ¨™ã®ä½œæˆ</li>
</ul></li>
</ol>

<h3>è©•ä¾¡æŒ‡æ¨™é¸æŠã®ãƒ•ãƒ­ãƒ¼ãƒãƒ£ãƒ¼ãƒˆ</h3>

<div class="mermaid">
graph TD
    A[å•é¡Œã®ç¨®é¡] --> B{åˆ†é¡ or å›å¸°?}

    B -->|åˆ†é¡| C{ãƒ‡ãƒ¼ã‚¿ã¯å‡è¡¡?}
    B -->|å›å¸°| D{å¤–ã‚Œå€¤ã¯å¤šã„?}

    C -->|å‡è¡¡| E[Accuracy, F1-score]
    C -->|ä¸å‡è¡¡| F{ä½•ã‚’é‡è¦–?}

    F -->|å½é™°æ€§ã‚’é¿ã‘ã‚‹| G[Recall, F2-score]
    F -->|å½é™½æ€§ã‚’é¿ã‘ã‚‹| H[Precision, F0.5-score]
    F -->|ãƒãƒ©ãƒ³ã‚¹| I[F1-score, AUC]

    D -->|å¤šã„| J[MAE, RobustScaler]
    D -->|å°‘ãªã„| K{ç›¸å¯¾ or çµ¶å¯¾èª¤å·®?}

    K -->|ç›¸å¯¾| L[MAPE]
    K -->|çµ¶å¯¾| M[RMSE, RÂ²]

    style A fill:#e8f5e9
    style B fill:#fff3e0
    style C fill:#e3f2fd
    style D fill:#fce4ec
</div>

<h3>ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹</h3>

<table>
<thead>
<tr>
<th>åŸå‰‡</th>
<th>èª¬æ˜</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>è¤‡æ•°æŒ‡æ¨™ã®ç¢ºèª</strong></td>
<td>å˜ä¸€æŒ‡æ¨™ã«é ¼ã‚‰ãšã€è¤‡æ•°ã®è§’åº¦ã‹ã‚‰è©•ä¾¡</td>
</tr>
<tr>
<td><strong>ãƒ“ã‚¸ãƒã‚¹ç›®çš„å„ªå…ˆ</strong></td>
<td>æŠ€è¡“çš„ãªç²¾åº¦ã‚ˆã‚Šãƒ“ã‚¸ãƒã‚¹ä¾¡å€¤ã‚’é‡è¦–</td>
</tr>
<tr>
<td><strong>ãƒ‡ãƒ¼ã‚¿ç‰¹æ€§ã®ç†è§£</strong></td>
<td>ä¸å‡è¡¡ã€å¤–ã‚Œå€¤ãªã©ãƒ‡ãƒ¼ã‚¿ã®ç‰¹å¾´ã‚’æŠŠæ¡</td>
</tr>
<tr>
<td><strong>é–¾å€¤ã®èª¿æ•´</strong></td>
<td>Precisionã¨Recallã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’è€ƒæ…®</td>
</tr>
<tr>
<td><strong>æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã§è©•ä¾¡</strong></td>
<td>è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã§ã¯ãªãã€æœªçŸ¥ãƒ‡ãƒ¼ã‚¿ã§æ€§èƒ½æ¸¬å®š</td>
</tr>
</tbody>
</table>

<h3>æ¬¡ã®ç« ã¸</h3>

<p>ç¬¬2ç« ã§ã¯ã€<strong>äº¤å·®æ¤œè¨¼ã¨ãƒ¢ãƒ‡ãƒ«é¸æŠ</strong>ã‚’å­¦ã³ã¾ã™ï¼š</p>
<ul>
<li>K-fold Cross-Validation</li>
<li>Stratified K-fold</li>
<li>Time Series Cross-Validation</li>
<li>ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°</li>
<li>å­¦ç¿’æ›²ç·šã¨æ¤œè¨¼æ›²ç·š</li>
</ul>

<hr>

<h2>æ¼”ç¿’å•é¡Œ</h2>

<h3>å•é¡Œ1ï¼ˆé›£æ˜“åº¦ï¼šeasyï¼‰</h3>
<p>ä»¥ä¸‹ã®Confusion Matrixã‹ã‚‰ã€Accuracyã€Precisionã€Recallã€F1-scoreã‚’è¨ˆç®—ã—ã¦ãã ã•ã„ã€‚</p>

<table>
<thead>
<tr>
<th></th>
<th>äºˆæ¸¬: Positive</th>
<th>äºˆæ¸¬: Negative</th>
</tr>
</thead>
<tbody>
<tr>
<td>å®Ÿéš›: Positive</td>
<td>80</td>
<td>20</td>
</tr>
<tr>
<td>å®Ÿéš›: Negative</td>
<td>10</td>
<td>90</td>
</tr>
</tbody>
</table>

<details>
<summary>è§£ç­”ä¾‹</summary>

<p><strong>è§£ç­”</strong>ï¼š</p>

<pre><code class="language-python"># Confusion Matrixã®å€¤
TP = 80
FN = 20
FP = 10
TN = 90

# Accuracy
accuracy = (TP + TN) / (TP + TN + FP + FN)
print(f"Accuracy: {accuracy:.3f}")

# Precision
precision = TP / (TP + FP)
print(f"Precision: {precision:.3f}")

# Recall
recall = TP / (TP + FN)
print(f"Recall: {recall:.3f}")

# F1-score
f1 = 2 * (precision * recall) / (precision + recall)
print(f"F1-score: {f1:.3f}")
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>Accuracy: 0.850
Precision: 0.889
Recall: 0.800
F1-score: 0.842
</code></pre>

</details>

<h3>å•é¡Œ2ï¼ˆé›£æ˜“åº¦ï¼šmediumï¼‰</h3>
<p>ãŒã‚“æ¤œå‡ºã‚·ãƒŠãƒªã‚ªã§ã€ä»¥ä¸‹ã®2ã¤ã®ãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚Šã¾ã™ã€‚ã©ã¡ã‚‰ãŒå„ªã‚Œã¦ã„ã¾ã™ã‹ï¼Ÿç†ç”±ã¨ã¨ã‚‚ã«èª¬æ˜ã—ã¦ãã ã•ã„ã€‚</p>

<ul>
<li>ãƒ¢ãƒ‡ãƒ«A: Precision=0.95, Recall=0.60</li>
<li>ãƒ¢ãƒ‡ãƒ«B: Precision=0.70, Recall=0.90</li>
</ul>

<details>
<summary>è§£ç­”ä¾‹</summary>

<p><strong>è§£ç­”</strong>ï¼š</p>

<p><strong>ãƒ¢ãƒ‡ãƒ«BãŒå„ªã‚Œã¦ã„ã‚‹</strong></p>

<p><strong>ç†ç”±</strong>ï¼š</p>

<ol>
<li><p><strong>ãŒã‚“æ¤œå‡ºã§ã¯RecallãŒæœ€é‡è¦</strong></p>
<ul>
<li>ãŒã‚“æ‚£è€…ã‚’è¦‹é€ƒã™ï¼ˆå½é™°æ€§ï¼‰ã¯ç”Ÿå‘½ã«é–¢ã‚ã‚‹</li>
<li>å¥åº·ãªäººã‚’ãŒã‚“ã¨èª¤åˆ¤å®šï¼ˆå½é™½æ€§ï¼‰ã¯å†æ¤œæŸ»ã§å¯¾å¿œå¯èƒ½</li>
</ul></li>

<li><p><strong>æ•°å€¤åˆ†æ</strong></p>
<ul>
<li>ãƒ¢ãƒ‡ãƒ«A: 100äººã®æ‚£è€…ã®ã†ã¡40äººã‚’è¦‹é€ƒã™ï¼ˆRecall=0.60ï¼‰</li>
<li>ãƒ¢ãƒ‡ãƒ«B: 100äººã®æ‚£è€…ã®ã†ã¡10äººã‚’è¦‹é€ƒã™ï¼ˆRecall=0.90ï¼‰</li>
</ul></li>

<li><p><strong>F-beta scoreã§è©•ä¾¡ï¼ˆRecallé‡è¦–ï¼‰</strong></p></li>
</ol>

<pre><code class="language-python">import numpy as np

# ãƒ¢ãƒ‡ãƒ«A
precision_A = 0.95
recall_A = 0.60
f2_A = (1 + 2**2) * (precision_A * recall_A) / (2**2 * precision_A + recall_A)

# ãƒ¢ãƒ‡ãƒ«B
precision_B = 0.70
recall_B = 0.90
f2_B = (1 + 2**2) * (precision_B * recall_B) / (2**2 * precision_B + recall_B)

print(f"ãƒ¢ãƒ‡ãƒ«A F2-score: {f2_A:.3f}")
print(f"ãƒ¢ãƒ‡ãƒ«B F2-score: {f2_B:.3f}")
print(f"\nãƒ¢ãƒ‡ãƒ«BãŒ{(f2_B/f2_A - 1)*100:.1f}%å„ªã‚Œã¦ã„ã‚‹")
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>ãƒ¢ãƒ‡ãƒ«A F2-score: 0.635
ãƒ¢ãƒ‡ãƒ«B F2-score: 0.847
ãƒ¢ãƒ‡ãƒ«BãŒ33.4%å„ªã‚Œã¦ã„ã‚‹
</code></pre>

</details>

<h3>å•é¡Œ3ï¼ˆé›£æ˜“åº¦ï¼šmediumï¼‰</h3>
<p>ROC-AUCã¨PR-AUCã®é•ã„ã‚’èª¬æ˜ã—ã€ãã‚Œãã‚Œã‚’ã©ã®ã‚ˆã†ãªå ´é¢ã§ä½¿ã†ã¹ãã‹è¿°ã¹ã¦ãã ã•ã„ã€‚</p>

<details>
<summary>è§£ç­”ä¾‹</summary>

<p><strong>è§£ç­”</strong>ï¼š</p>

<p><strong>ROC-AUCï¼ˆROCæ›²ç·šã®ä¸‹ã®é¢ç©ï¼‰</strong>ï¼š</p>
<ul>
<li>è»¸: FPR (False Positive Rate) vs TPR (True Positive Rate)</li>
<li>ç‰¹å¾´: é™°æ€§ã‚¯ãƒ©ã‚¹ã¨é™½æ€§ã‚¯ãƒ©ã‚¹ã‚’å‡ç­‰ã«è©•ä¾¡</li>
<li>é©ç”¨: ãƒ‡ãƒ¼ã‚¿ãŒå‡è¡¡ã—ã¦ã„ã‚‹å ´åˆ</li>
</ul>

<p><strong>PR-AUCï¼ˆPrecision-Recallæ›²ç·šã®ä¸‹ã®é¢ç©ï¼‰</strong>ï¼š</p>
<ul>
<li>è»¸: Recall vs Precision</li>
<li>ç‰¹å¾´: é™½æ€§ã‚¯ãƒ©ã‚¹ã®äºˆæ¸¬æ€§èƒ½ã«ç„¦ç‚¹</li>
<li>é©ç”¨: ãƒ‡ãƒ¼ã‚¿ãŒä¸å‡è¡¡ï¼ˆé™½æ€§ã‚¯ãƒ©ã‚¹ãŒå°‘ãªã„ï¼‰å ´åˆ</li>
</ul>

<p><strong>ä½¿ã„åˆ†ã‘</strong>ï¼š</p>

<table>
<thead>
<tr>
<th>ã‚·ãƒŠãƒªã‚ª</th>
<th>æ¨å¥¨</th>
<th>ç†ç”±</th>
</tr>
</thead>
<tbody>
<tr>
<td>å‡è¡¡ãƒ‡ãƒ¼ã‚¿ï¼ˆ50:50ï¼‰</td>
<td>ROC-AUC</td>
<td>ä¸¡ã‚¯ãƒ©ã‚¹ã‚’å‡ç­‰ã«è©•ä¾¡</td>
</tr>
<tr>
<td>ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿ï¼ˆ1:99ï¼‰</td>
<td>PR-AUC</td>
<td>å°‘æ•°ã‚¯ãƒ©ã‚¹ã®æ€§èƒ½ã«ç„¦ç‚¹</td>
</tr>
<tr>
<td>ä¸æ­£æ¤œå‡º</td>
<td>PR-AUC</td>
<td>ä¸æ­£ï¼ˆå°‘æ•°ï¼‰ã‚’è¦‹é€ƒã•ãªã„</td>
</tr>
<tr>
<td>åŒ»ç™‚è¨ºæ–­ï¼ˆã¾ã‚Œãªç—…æ°—ï¼‰</td>
<td>PR-AUC</td>
<td>ç—…æ°—ï¼ˆå°‘æ•°ï¼‰ã®æ¤œå‡ºãŒé‡è¦</td>
</tr>
<tr>
<td>ã‚¹ãƒ‘ãƒ ãƒ•ã‚£ãƒ«ã‚¿</td>
<td>PR-AUC</td>
<td>ã‚¹ãƒ‘ãƒ ï¼ˆå¤‰å‹•ã‚ã‚Šï¼‰ã®æ¤œå‡º</td>
</tr>
</tbody>
</table>

<p><strong>å®Ÿä¾‹</strong>ï¼š</p>

<pre><code class="language-python">from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import roc_auc_score, average_precision_score

# ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
X_imb, y_imb = make_classification(n_samples=1000, n_features=20,
                                   weights=[0.95, 0.05], random_state=42)

X_train, X_test, y_train, y_test = train_test_split(
    X_imb, y_imb, test_size=0.3, random_state=42
)

model = LogisticRegression(random_state=42, max_iter=1000)
model.fit(X_train, y_train)
y_proba = model.predict_proba(X_test)[:, 1]

roc_auc = roc_auc_score(y_test, y_proba)
pr_auc = average_precision_score(y_test, y_proba)

print(f"é™½æ€§ã‚¯ãƒ©ã‚¹ã®å‰²åˆ: {y_test.sum() / len(y_test) * 100:.1f}%")
print(f"ROC-AUC: {roc_auc:.3f}")
print(f"PR-AUC:  {pr_auc:.3f}")
print("\nä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿ã§ã¯ã€PR-AUCãŒã‚ˆã‚Šç¾å®Ÿçš„ãªæ€§èƒ½ã‚’ç¤ºã™")
</code></pre>

</details>

<h3>å•é¡Œ4ï¼ˆé›£æ˜“åº¦ï¼šhardï¼‰</h3>
<p>ä»¥ä¸‹ã®å›å¸°ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬çµæœã«å¯¾ã—ã¦ã€MAEã€RMSEã€RÂ²ã€MAPEã‚’è¨ˆç®—ã—ã€çµæœã‚’è§£é‡ˆã—ã¦ãã ã•ã„ã€‚</p>

<pre><code class="language-python">import numpy as np

y_true = np.array([100, 150, 200, 250, 300])
y_pred = np.array([110, 140, 210, 240, 320])
</code></pre>

<details>
<summary>è§£ç­”ä¾‹</summary>

<pre><code class="language-python">import numpy as np
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error

y_true = np.array([100, 150, 200, 250, 300])
y_pred = np.array([110, 140, 210, 240, 320])

# å„æŒ‡æ¨™ã®è¨ˆç®—
mae = mean_absolute_error(y_true, y_pred)
mse = mean_squared_error(y_true, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_true, y_pred)
mape = mean_absolute_percentage_error(y_true, y_pred) * 100

print("=== å›å¸°è©•ä¾¡æŒ‡æ¨™ ===")
print(f"MAE:  {mae:.2f}")
print(f"RMSE: {rmse:.2f}")
print(f"RÂ²:   {r2:.3f}")
print(f"MAPE: {mape:.2f}%")

# è©³ç´°åˆ†æ
residuals = y_true - y_pred
abs_residuals = np.abs(residuals)
percentage_errors = np.abs(residuals / y_true) * 100

print("\n=== è©³ç´°åˆ†æ ===")
print(f"å®Ÿéš›ã®å€¤:   {y_true}")
print(f"äºˆæ¸¬å€¤:     {y_pred}")
print(f"æ®‹å·®:       {residuals}")
print(f"çµ¶å¯¾æ®‹å·®:   {abs_residuals}")
print(f"èª¤å·®ç‡(%):  {percentage_errors.round(2)}")

print("\n=== è§£é‡ˆ ===")
print(f"1. MAE = {mae:.2f}")
print("   å¹³å‡ã—ã¦ç´„12å˜ä½ã®èª¤å·®ãŒã‚ã‚‹")
print(f"\n2. RMSE = {rmse:.2f}")
print("   RMSEãŒMAEã‚ˆã‚Šå¤§ãã„ â†’ å¤§ããªèª¤å·®ãŒå­˜åœ¨")
print(f"\n3. RÂ² = {r2:.3f}")
print(f"   ãƒ¢ãƒ‡ãƒ«ã¯åˆ†æ•£ã®{r2*100:.1f}%ã‚’èª¬æ˜ â†’ å„ªç§€")
print(f"\n4. MAPE = {mape:.2f}%")
print("   å¹³å‡çš„ã«6%ç¨‹åº¦ã®ç›¸å¯¾èª¤å·® â†’ è‰¯å¥½")

# å¯è¦–åŒ–
import matplotlib.pyplot as plt

fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# äºˆæ¸¬ vs å®Ÿéš›
axes[0].scatter(y_true, y_pred, s=100, alpha=0.7, edgecolors='black')
axes[0].plot([y_true.min(), y_true.max()],
            [y_true.min(), y_true.max()],
            'r--', linewidth=2, label='Perfect prediction')
axes[0].set_xlabel('Actual', fontsize=12)
axes[0].set_ylabel('Predicted', fontsize=12)
axes[0].set_title('Predicted vs Actual', fontsize=14)
axes[0].legend()
axes[0].grid(True, alpha=0.3)

# æ®‹å·®ãƒ—ãƒ­ãƒƒãƒˆ
axes[1].bar(range(len(residuals)), residuals,
           color=['red' if r < 0 else 'blue' for r in residuals],
           alpha=0.7, edgecolor='black')
axes[1].axhline(y=0, color='black', linestyle='-', linewidth=2)
axes[1].set_xlabel('Index', fontsize=12)
axes[1].set_ylabel('Residuals', fontsize=12)
axes[1].set_title('Residuals (Actual - Predicted)', fontsize=14)
axes[1].grid(True, alpha=0.3, axis='y')

plt.tight_layout()
plt.show()
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>=== å›å¸°è©•ä¾¡æŒ‡æ¨™ ===
MAE:  12.00
RMSE: 13.04
RÂ²:   0.984
MAPE: 5.96%

=== è©³ç´°åˆ†æ ===
å®Ÿéš›ã®å€¤:   [100 150 200 250 300]
äºˆæ¸¬å€¤:     [110 140 210 240 320]
æ®‹å·®:       [-10  10 -10  10 -20]
çµ¶å¯¾æ®‹å·®:   [10 10 10 10 20]
èª¤å·®ç‡(%):  [10.    6.67  5.    4.    6.67]

=== è§£é‡ˆ ===
1. MAE = 12.00
   å¹³å‡ã—ã¦ç´„12å˜ä½ã®èª¤å·®ãŒã‚ã‚‹

2. RMSE = 13.04
   RMSEãŒMAEã‚ˆã‚Šå¤§ãã„ â†’ å¤§ããªèª¤å·®ãŒå­˜åœ¨

3. RÂ² = 0.984
   ãƒ¢ãƒ‡ãƒ«ã¯åˆ†æ•£ã®98.4%ã‚’èª¬æ˜ â†’ å„ªç§€

4. MAPE = 5.96%
   å¹³å‡çš„ã«6%ç¨‹åº¦ã®ç›¸å¯¾èª¤å·® â†’ è‰¯å¥½
</code></pre>

</details>

<h3>å•é¡Œ5ï¼ˆé›£æ˜“åº¦ï¼šhardï¼‰</h3>
<p>ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿ï¼ˆé™½æ€§:é™°æ€§ = 1:99ï¼‰ã«ãŠã„ã¦ã€AccuracyãŒé«˜ã„ã«ã‚‚ã‹ã‹ã‚ã‚‰ãšãƒ¢ãƒ‡ãƒ«ãŒå®Ÿç”¨çš„ã§ãªã„å ´åˆãŒã‚ã‚Šã¾ã™ã€‚å…·ä½“ä¾‹ã‚’ä½œæˆã—ã€é©åˆ‡ãªè©•ä¾¡æŒ‡æ¨™ã‚’ææ¡ˆã—ã¦ãã ã•ã„ã€‚</p>

<details>
<summary>è§£ç­”ä¾‹</summary>

<pre><code class="language-python">import numpy as np
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
from sklearn.metrics import confusion_matrix, classification_report

# ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
# ã‚·ãƒŠãƒªã‚ª: ä¸æ­£å–å¼•æ¤œå‡ºï¼ˆä¸æ­£=1%ã€æ­£å¸¸=99%ï¼‰
np.random.seed(42)
n_samples = 10000

# å®Ÿéš›ã®ãƒ©ãƒ™ãƒ«
y_true = np.array([0] * 9900 + [1] * 100)

# ãƒ¢ãƒ‡ãƒ«A: å¸¸ã«ã€Œæ­£å¸¸ã€ã¨äºˆæ¸¬ï¼ˆãƒŠã‚¤ãƒ¼ãƒ–ãªå¤šæ•°æ´¾åˆ†é¡å™¨ï¼‰
y_pred_A = np.zeros(n_samples)

# ãƒ¢ãƒ‡ãƒ«B: å®Ÿéš›ã«ä¸æ­£ã‚’æ¤œå‡ºã—ã‚ˆã†ã¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«
# ä¸æ­£ã®80%ã‚’æ¤œå‡ºã€ãŸã ã—æ­£å¸¸ã®5%ã‚’èª¤æ¤œå‡º
y_pred_B = y_true.copy()
# ä¸æ­£ã®ã†ã¡20%ã‚’è¦‹é€ƒã™
false_negatives = np.random.choice(np.where(y_true == 1)[0], size=20, replace=False)
y_pred_B[false_negatives] = 0
# æ­£å¸¸ã®ã†ã¡5%ã‚’èª¤æ¤œå‡º
false_positives = np.random.choice(np.where(y_true == 0)[0], size=495, replace=False)
y_pred_B[false_positives] = 1

print("=== ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿ã§ã®è©•ä¾¡æŒ‡æ¨™ã®å•é¡Œ ===\n")
print(f"ãƒ‡ãƒ¼ã‚¿ã®ä¸å‡è¡¡åº¦: é™½æ€§={y_true.sum()}ä»¶ ({y_true.sum()/len(y_true)*100:.1f}%), "
      f"é™°æ€§={len(y_true)-y_true.sum()}ä»¶ ({(len(y_true)-y_true.sum())/len(y_true)*100:.1f}%)\n")

# ãƒ¢ãƒ‡ãƒ«Aã®è©•ä¾¡
print("ã€ãƒ¢ãƒ‡ãƒ«A: å¸¸ã«ã€Œæ­£å¸¸ã€ã¨äºˆæ¸¬ã€‘")
print(f"Accuracy:  {accuracy_score(y_true, y_pred_A):.3f} â† é«˜ã„ãŒç„¡æ„å‘³ï¼")
print(f"Precision: è¨ˆç®—ä¸å¯ï¼ˆé™½æ€§äºˆæ¸¬ãªã—ï¼‰")
print(f"Recall:    {recall_score(y_true, y_pred_A, zero_division=0):.3f} â† ä¸æ­£ã‚’1ä»¶ã‚‚æ¤œå‡ºã§ããªã„ï¼")
print(f"F1-score:  {f1_score(y_true, y_pred_A, zero_division=0):.3f}")
print("\nConfusion Matrix:")
print(confusion_matrix(y_true, y_pred_A))

# ãƒ¢ãƒ‡ãƒ«Bã®è©•ä¾¡
print("\nã€ãƒ¢ãƒ‡ãƒ«B: å®Ÿéš›ã«ä¸æ­£ã‚’æ¤œå‡ºã€‘")
print(f"Accuracy:  {accuracy_score(y_true, y_pred_B):.3f}")
print(f"Precision: {precision_score(y_true, y_pred_B):.3f}")
print(f"Recall:    {recall_score(y_true, y_pred_B):.3f} â† ä¸æ­£ã®80%ã‚’æ¤œå‡º")
print(f"F1-score:  {f1_score(y_true, y_pred_B):.3f}")
print("\nConfusion Matrix:")
print(confusion_matrix(y_true, y_pred_B))

print("\n=== çµè«–ã¨æ¨å¥¨æŒ‡æ¨™ ===")
print("\nå•é¡Œç‚¹:")
print("- ãƒ¢ãƒ‡ãƒ«Aã¯Accuracy=99.0%ã ãŒã€ä¸æ­£ã‚’1ä»¶ã‚‚æ¤œå‡ºã§ããªã„")
print("- Accuracyã¯ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿ã§èª¤è§£ã‚’æ‹›ã")
print("- å®Ÿç”¨çš„ã«ã¯å®Œå…¨ã«ç„¡ä¾¡å€¤ãªãƒ¢ãƒ‡ãƒ«")

print("\næ¨å¥¨ã™ã‚‹è©•ä¾¡æŒ‡æ¨™:")
print("1. F1-score: Precisionã¨Recallã®ãƒãƒ©ãƒ³ã‚¹ã‚’è©•ä¾¡")
print("2. Recall: ä¸æ­£æ¤œå‡ºç‡ï¼ˆè¦‹é€ƒã—ã‚’æœ€å°åŒ–ï¼‰")
print("3. PR-AUC: ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿ã«ç‰¹åŒ–ã—ãŸç·åˆè©•ä¾¡")
print("4. Cohen's Kappa: å¶ç„¶ã«ã‚ˆã‚‹ä¸€è‡´ã‚’è£œæ­£")

print("\nå®Ÿç”¨çš„ãªåˆ¤æ–­:")
print(f"- ãƒ¢ãƒ‡ãƒ«Aã¯å®Ÿç”¨ä¸å¯ï¼ˆRecall=0ï¼‰")
print(f"- ãƒ¢ãƒ‡ãƒ«Bã¯å®Ÿç”¨çš„ï¼ˆF1={f1_score(y_true, y_pred_B):.3f}, Recall={recall_score(y_true, y_pred_B):.3f}ï¼‰")

# è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆ
print("\nã€è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆã€‘")
print("\nãƒ¢ãƒ‡ãƒ«A:")
print(classification_report(y_true, y_pred_A, target_names=['æ­£å¸¸', 'ä¸æ­£'], zero_division=0))

print("\nãƒ¢ãƒ‡ãƒ«B:")
print(classification_report(y_true, y_pred_B, target_names=['æ­£å¸¸', 'ä¸æ­£']))

# ãƒ“ã‚¸ãƒã‚¹çš„ãªè§£é‡ˆ
print("\n=== ãƒ“ã‚¸ãƒã‚¹ã¸ã®å½±éŸ¿ ===")
cm_B = confusion_matrix(y_true, y_pred_B)
tp, fp, fn = cm_B[1,1], cm_B[0,1], cm_B[1,0]

# ã‚³ã‚¹ãƒˆè¨ˆç®—ï¼ˆä¾‹ï¼‰
cost_per_fraud = 10000  # ä¸æ­£1ä»¶ã‚ãŸã‚Šã®æå¤±
cost_per_false_alarm = 100  # èª¤æ¤œå‡º1ä»¶ã‚ãŸã‚Šã®ã‚³ã‚¹ãƒˆ

loss_A = 100 * cost_per_fraud  # å…¨ã¦ã®ä¸æ­£ã‚’è¦‹é€ƒã™
loss_B = (fn * cost_per_fraud) + (fp * cost_per_false_alarm)

print(f"\nãƒ¢ãƒ‡ãƒ«A:")
print(f"  è¦‹é€ƒã—ãŸä¸æ­£: {100}ä»¶")
print(f"  æ¨å®šæå¤±: Â¥{loss_A:,}")

print(f"\nãƒ¢ãƒ‡ãƒ«B:")
print(f"  è¦‹é€ƒã—ãŸä¸æ­£: {fn}ä»¶")
print(f"  èª¤æ¤œå‡º: {fp}ä»¶")
print(f"  æ¨å®šæå¤±: Â¥{loss_B:,}")

print(f"\nãƒ¢ãƒ‡ãƒ«Bã®æ¡ç”¨ã«ã‚ˆã‚Šã€Â¥{loss_A - loss_B:,}ã®æå¤±ã‚’é˜²ã’ã‚‹")
</code></pre>

<p><strong>å‡ºåŠ›ï¼ˆä¾‹ï¼‰</strong>ï¼š</p>
<pre><code>=== ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿ã§ã®è©•ä¾¡æŒ‡æ¨™ã®å•é¡Œ ===

ãƒ‡ãƒ¼ã‚¿ã®ä¸å‡è¡¡åº¦: é™½æ€§=100ä»¶ (1.0%), é™°æ€§=9900ä»¶ (99.0%)

ã€ãƒ¢ãƒ‡ãƒ«A: å¸¸ã«ã€Œæ­£å¸¸ã€ã¨äºˆæ¸¬ã€‘
Accuracy:  0.990 â† é«˜ã„ãŒç„¡æ„å‘³ï¼
Precision: è¨ˆç®—ä¸å¯ï¼ˆé™½æ€§äºˆæ¸¬ãªã—ï¼‰
Recall:    0.000 â† ä¸æ­£ã‚’1ä»¶ã‚‚æ¤œå‡ºã§ããªã„ï¼
F1-score:  0.000

Confusion Matrix:
[[9900    0]
 [ 100    0]]

ã€ãƒ¢ãƒ‡ãƒ«B: å®Ÿéš›ã«ä¸æ­£ã‚’æ¤œå‡ºã€‘
Accuracy:  0.948
Precision: 0.139
Recall:    0.800 â† ä¸æ­£ã®80%ã‚’æ¤œå‡º
F1-score:  0.237

Confusion Matrix:
[[9405  495]
 [  20   80]]

=== çµè«–ã¨æ¨å¥¨æŒ‡æ¨™ ===

å•é¡Œç‚¹:
- ãƒ¢ãƒ‡ãƒ«Aã¯Accuracy=99.0%ã ãŒã€ä¸æ­£ã‚’1ä»¶ã‚‚æ¤œå‡ºã§ããªã„
- Accuracyã¯ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿ã§èª¤è§£ã‚’æ‹›ã
- å®Ÿç”¨çš„ã«ã¯å®Œå…¨ã«ç„¡ä¾¡å€¤ãªãƒ¢ãƒ‡ãƒ«

æ¨å¥¨ã™ã‚‹è©•ä¾¡æŒ‡æ¨™:
1. F1-score: Precisionã¨Recallã®ãƒãƒ©ãƒ³ã‚¹ã‚’è©•ä¾¡
2. Recall: ä¸æ­£æ¤œå‡ºç‡ï¼ˆè¦‹é€ƒã—ã‚’æœ€å°åŒ–ï¼‰
3. PR-AUC: ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿ã«ç‰¹åŒ–ã—ãŸç·åˆè©•ä¾¡
4. Cohen's Kappa: å¶ç„¶ã«ã‚ˆã‚‹ä¸€è‡´ã‚’è£œæ­£

å®Ÿç”¨çš„ãªåˆ¤æ–­:
- ãƒ¢ãƒ‡ãƒ«Aã¯å®Ÿç”¨ä¸å¯ï¼ˆRecall=0ï¼‰
- ãƒ¢ãƒ‡ãƒ«Bã¯å®Ÿç”¨çš„ï¼ˆF1=0.237, Recall=0.800ï¼‰

=== ãƒ“ã‚¸ãƒã‚¹ã¸ã®å½±éŸ¿ ===

ãƒ¢ãƒ‡ãƒ«A:
  è¦‹é€ƒã—ãŸä¸æ­£: 100ä»¶
  æ¨å®šæå¤±: Â¥1,000,000

ãƒ¢ãƒ‡ãƒ«B:
  è¦‹é€ƒã—ãŸä¸æ­£: 20ä»¶
  èª¤æ¤œå‡º: 495ä»¶
  æ¨å®šæå¤±: Â¥249,500

ãƒ¢ãƒ‡ãƒ«Bã®æ¡ç”¨ã«ã‚ˆã‚Šã€Â¥750,500ã®æå¤±ã‚’é˜²ã’ã‚‹
</code></pre>

</details>

<hr>

<h2>å‚è€ƒæ–‡çŒ®</h2>

<ol>
<li>GÃ©ron, A. (2019). <em>Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow</em> (2nd ed.). O'Reilly Media.</li>
<li>Hastie, T., Tibshirani, R., & Friedman, J. (2009). <em>The Elements of Statistical Learning</em> (2nd ed.). Springer.</li>
<li>Kuhn, M., & Johnson, K. (2013). <em>Applied Predictive Modeling</em>. Springer.</li>
<li>Provost, F., & Fawcett, T. (2013). <em>Data Science for Business</em>. O'Reilly Media.</li>
<li>Saito, T., & Rehmsmeier, M. (2015). The Precision-Recall Plot Is More Informative than the ROC Plot When Evaluating Binary Classifiers on Imbalanced Datasets. <em>PLOS ONE</em>, 10(3).</li>
</ol>

<div class="navigation">
    <a href="index.html" class="nav-button">â† ã‚·ãƒªãƒ¼ã‚ºç›®æ¬¡</a>
    <a href="chapter2-cross-validation.html" class="nav-button">æ¬¡ã®ç« : äº¤å·®æ¤œè¨¼ã¨ãƒ¢ãƒ‡ãƒ«é¸æŠ â†’</a>
</div>

    </main>

    
    <section class="disclaimer">
        <h3>å…è²¬äº‹é …</h3>
        <ul>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯æ•™è‚²ãƒ»ç ”ç©¶ãƒ»æƒ…å ±æä¾›ã®ã¿ã‚’ç›®çš„ã¨ã—ã¦ãŠã‚Šã€å°‚é–€çš„ãªåŠ©è¨€(æ³•å¾‹ãƒ»ä¼šè¨ˆãƒ»æŠ€è¡“çš„ä¿è¨¼ãªã©)ã‚’æä¾›ã™ã‚‹ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŠã‚ˆã³ä»˜éšã™ã‚‹ã‚³ãƒ¼ãƒ‰ä¾‹ã¯ã€Œç¾çŠ¶æœ‰å§¿(AS IS)ã€ã§æä¾›ã•ã‚Œã€æ˜ç¤ºã¾ãŸã¯é»™ç¤ºã‚’å•ã‚ãšã€å•†å“æ€§ã€ç‰¹å®šç›®çš„é©åˆæ€§ã€æ¨©åˆ©éä¾µå®³ã€æ­£ç¢ºæ€§ãƒ»å®Œå…¨æ€§ã€å‹•ä½œãƒ»å®‰å…¨æ€§ç­‰ã„ã‹ãªã‚‹ä¿è¨¼ã‚‚ã—ã¾ã›ã‚“ã€‚</li>
            <li>å¤–éƒ¨ãƒªãƒ³ã‚¯ã€ç¬¬ä¸‰è€…ãŒæä¾›ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ»ãƒ„ãƒ¼ãƒ«ãƒ»ãƒ©ã‚¤ãƒ–ãƒ©ãƒªç­‰ã®å†…å®¹ãƒ»å¯ç”¨æ€§ãƒ»å®‰å…¨æ€§ã«ã¤ã„ã¦ã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯ä¸€åˆ‡ã®è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®åˆ©ç”¨ãƒ»å®Ÿè¡Œãƒ»è§£é‡ˆã«ã‚ˆã‚Šç›´æ¥çš„ãƒ»é–“æ¥çš„ãƒ»ä»˜éšçš„ãƒ»ç‰¹åˆ¥ãƒ»çµæœçš„ãƒ»æ‡²ç½°çš„æå®³ãŒç”Ÿã˜ãŸå ´åˆã§ã‚‚ã€é©ç”¨æ³•ã§è¨±å®¹ã•ã‚Œã‚‹æœ€å¤§é™ã®ç¯„å›²ã§ã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å†…å®¹ã¯ã€äºˆå‘Šãªãå¤‰æ›´ãƒ»æ›´æ–°ãƒ»æä¾›åœæ­¢ã•ã‚Œã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®è‘—ä½œæ¨©ãƒ»ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯æ˜è¨˜ã•ã‚ŒãŸæ¡ä»¶(ä¾‹: CC BY 4.0)ã«å¾“ã„ã¾ã™ã€‚å½“è©²ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯é€šå¸¸ã€ç„¡ä¿è¨¼æ¡é …ã‚’å«ã¿ã¾ã™ã€‚</li>
        </ul>
    </section>

<footer>
        <p><strong>ä½œæˆè€…</strong>: AI Terakoya Content Team</p>
        <p><strong>ãƒãƒ¼ã‚¸ãƒ§ãƒ³</strong>: 1.0 | <strong>ä½œæˆæ—¥</strong>: 2025-10-21</p>
        <p><strong>ãƒ©ã‚¤ã‚»ãƒ³ã‚¹</strong>: Creative Commons BY 4.0</p>
        <p>Â© 2025 AI Terakoya. All rights reserved.</p>
    </footer>
</body>
</html>
