<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ç¬¬4ç« ï¼šãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒã¨é¸æŠ - AI Terakoya</title>

    <style>
        :root {
            --color-primary: #2c3e50;
            --color-primary-dark: #1a252f;
            --color-accent: #7b2cbf;
            --color-accent-light: #9d4edd;
            --color-text: #2d3748;
            --color-text-light: #4a5568;
            --color-bg: #ffffff;
            --color-bg-alt: #f7fafc;
            --color-border: #e2e8f0;
            --color-code-bg: #f8f9fa;
            --color-link: #3182ce;
            --color-link-hover: #2c5aa0;
            --spacing-xs: 0.5rem;
            --spacing-sm: 1rem;
            --spacing-md: 1.5rem;
            --spacing-lg: 2rem;
            --spacing-xl: 3rem;
            --font-body: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            --font-mono: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;
            --border-radius: 8px;
            --box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body { font-family: var(--font-body); line-height: 1.7; color: var(--color-text); background-color: var(--color-bg); font-size: 16px; }
        header { background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%); color: white; padding: var(--spacing-xl) var(--spacing-md); margin-bottom: var(--spacing-xl); box-shadow: var(--box-shadow); }
        .header-content { max-width: 900px; margin: 0 auto; }
        h1 { font-size: 2rem; font-weight: 700; margin-bottom: var(--spacing-sm); line-height: 1.2; }
        .subtitle { font-size: 1.1rem; opacity: 0.95; font-weight: 400; margin-bottom: var(--spacing-md); }
        .meta { display: flex; flex-wrap: wrap; gap: var(--spacing-md); font-size: 0.9rem; opacity: 0.9; }
        .meta-item { display: flex; align-items: center; gap: 0.3rem; }
        .container { max-width: 900px; margin: 0 auto; padding: 0 var(--spacing-md) var(--spacing-xl); }
        h2 { font-size: 1.75rem; color: var(--color-primary); margin-top: var(--spacing-xl); margin-bottom: var(--spacing-md); padding-bottom: var(--spacing-xs); border-bottom: 3px solid var(--color-accent); }
        h3 { font-size: 1.4rem; color: var(--color-primary); margin-top: var(--spacing-lg); margin-bottom: var(--spacing-sm); }
        h4 { font-size: 1.1rem; color: var(--color-primary-dark); margin-top: var(--spacing-md); margin-bottom: var(--spacing-sm); }
        p { margin-bottom: var(--spacing-md); color: var(--color-text); }
        a { color: var(--color-link); text-decoration: none; transition: color 0.2s; }
        a:hover { color: var(--color-link-hover); text-decoration: underline; }
        ul, ol { margin-left: var(--spacing-lg); margin-bottom: var(--spacing-md); }
        li { margin-bottom: var(--spacing-xs); color: var(--color-text); }
        pre { background-color: var(--color-code-bg); border: 1px solid var(--color-border); border-radius: var(--border-radius); padding: var(--spacing-md); overflow-x: auto; margin-bottom: var(--spacing-md); font-family: var(--font-mono); font-size: 0.9rem; line-height: 1.5; }
        code { font-family: var(--font-mono); font-size: 0.9em; background-color: var(--color-code-bg); padding: 0.2em 0.4em; border-radius: 3px; }
        pre code { background-color: transparent; padding: 0; }
        table { width: 100%; border-collapse: collapse; margin-bottom: var(--spacing-md); font-size: 0.95rem; }
        th, td { border: 1px solid var(--color-border); padding: var(--spacing-sm); text-align: left; }
        th { background-color: var(--color-bg-alt); font-weight: 600; color: var(--color-primary); }
        blockquote { border-left: 4px solid var(--color-accent); padding-left: var(--spacing-md); margin: var(--spacing-md) 0; color: var(--color-text-light); font-style: italic; background-color: var(--color-bg-alt); padding: var(--spacing-md); border-radius: var(--border-radius); }
        .mermaid { text-align: center; margin: var(--spacing-lg) 0; background-color: var(--color-bg-alt); padding: var(--spacing-md); border-radius: var(--border-radius); }
        details { background-color: var(--color-bg-alt); border: 1px solid var(--color-border); border-radius: var(--border-radius); padding: var(--spacing-md); margin-bottom: var(--spacing-md); }
        summary { cursor: pointer; font-weight: 600; color: var(--color-primary); user-select: none; padding: var(--spacing-xs); margin: calc(-1 * var(--spacing-md)); padding: var(--spacing-md); border-radius: var(--border-radius); }
        summary:hover { background-color: rgba(123, 44, 191, 0.1); }
        details[open] summary { margin-bottom: var(--spacing-md); border-bottom: 1px solid var(--color-border); }
        .navigation { display: flex; justify-content: space-between; gap: var(--spacing-md); margin: var(--spacing-xl) 0; padding-top: var(--spacing-lg); border-top: 2px solid var(--color-border); }
        .nav-button { flex: 1; padding: var(--spacing-md); background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%); color: white; border-radius: var(--border-radius); text-align: center; font-weight: 600; transition: transform 0.2s, box-shadow 0.2s; box-shadow: var(--box-shadow); }
        .nav-button:hover { transform: translateY(-2px); box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15); text-decoration: none; }
        footer { margin-top: var(--spacing-xl); padding: var(--spacing-lg) var(--spacing-md); background-color: var(--color-bg-alt); border-top: 1px solid var(--color-border); text-align: center; font-size: 0.9rem; color: var(--color-text-light); }
        .disclaimer {
            max-width: 900px;
            margin: 2rem auto;
            padding: 1.5rem;
            background: #f8f9fa;
            border-left: 4px solid #6c757d;
            border-radius: 4px;
        }

        .disclaimer h3 {
            color: #495057;
            margin-bottom: 1rem;
            font-size: 1.1rem;
        }

        .disclaimer ul {
            list-style: none;
            padding-left: 0;
        }

        .disclaimer li {
            padding: 0.5rem 0;
            padding-left: 1.5rem;
            position: relative;
            font-size: 0.9rem;
            color: #6c757d;
            line-height: 1.6;
        }

        .disclaimer li::before {
            content: "âš ï¸";
            position: absolute;
            left: 0;
        }

        .project-box { background: linear-gradient(135deg, #e3f2fd 0%, #bbdefb 50%); border-radius: var(--border-radius); padding: var(--spacing-lg); margin: var(--spacing-lg) 0; box-shadow: var(--box-shadow); }
        @media (max-width: 768px) { h1 { font-size: 1.5rem; } h2 { font-size: 1.4rem; } h3 { font-size: 1.2rem; } .meta { font-size: 0.85rem; } .navigation { flex-direction: column; } table { font-size: 0.85rem; } th, td { padding: var(--spacing-xs); } }
    
        
    
        /* Breadcrumb styles */
        .breadcrumb {
            background: #f7fafc;
            padding: 0.75rem 1rem;
            border-bottom: 1px solid #e2e8f0;
            font-size: 0.9rem;
        }

        .breadcrumb-content {
            max-width: 900px;
            margin: 0 auto;
            display: flex;
            align-items: center;
            flex-wrap: wrap;
            gap: 0.5rem;
        }

        .breadcrumb a {
            color: #667eea;
            text-decoration: none;
            transition: color 0.2s;
        }

        .breadcrumb a:hover {
            color: #764ba2;
            text-decoration: underline;
        }

        .breadcrumb-separator {
            color: #a0aec0;
            margin: 0 0.25rem;
        }

        .breadcrumb-current {
            color: #4a5568;
            font-weight: 500;
        }
    </style>

    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
        mermaid.initialize({ startOnLoad: true, theme: 'default' });
    </script>
    <script>
        MathJax = {
            tex: { inlineMath: [['$', '$'], ['\\(', '\\)']], displayMath: [['$$', '$$'], ['\\[', '\\]']], processEscapes: true, processEnvironments: true },
            options: { skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'], ignoreHtmlClass: 'mermaid' }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" async></script>
</head>
<body>
            <nav class="breadcrumb">
        <div class="breadcrumb-content">
            <a href="../../index.html">AIå¯ºå­å±‹ãƒˆãƒƒãƒ—</a><span class="breadcrumb-separator">â€º</span><a href="../../ML/index.html">æ©Ÿæ¢°å­¦ç¿’</a><span class="breadcrumb-separator">â€º</span><a href="../../ML/model-evaluation-introduction/index.html">Model Evaluation</a><span class="breadcrumb-separator">â€º</span><span class="breadcrumb-current">Chapter 4</span>
        </div>
    </nav>

        <header>
        <div class="header-content">
            <h1>ç¬¬4ç« ï¼šãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒã¨é¸æŠ</h1>
            <p class="subtitle">çµ±è¨ˆçš„æ¤œå®šã¨ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å­¦ç¿’ã«ã‚ˆã‚‹æœ€é©ãƒ¢ãƒ‡ãƒ«ã®ç§‘å­¦çš„é¸æŠ</p>
            <div class="meta">
                <span class="meta-item">ğŸ“– èª­äº†æ™‚é–“: 23åˆ†</span>
                <span class="meta-item">ğŸ“Š é›£æ˜“åº¦: ä¸­ç´šã€œä¸Šç´š</span>
                <span class="meta-item">ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹: 12å€‹</span>
                <span class="meta-item">ğŸ“ æ¼”ç¿’å•é¡Œ: 5å•</span>
            </div>
        </div>
    </header>

    <main class="container">

<h2>å­¦ç¿’ç›®æ¨™</h2>
<p>ã“ã®ç« ã‚’èª­ã‚€ã“ã¨ã§ã€ä»¥ä¸‹ã‚’ç¿’å¾—ã§ãã¾ã™ï¼š</p>
<ul>
<li>âœ… è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã‚’çµ±è¨ˆçš„ã«æ¯”è¼ƒã™ã‚‹æ‰‹æ³•ã‚’ç†è§£ã§ãã‚‹</li>
<li>âœ… Paired t-testã€McNemar's testã€Friedman testã‚’å®Ÿè£…ã§ãã‚‹</li>
<li>âœ… Learning Curvesã€Validation Curvesã§ãƒ¢ãƒ‡ãƒ«ã‚’è¨ºæ–­ã§ãã‚‹</li>
<li>âœ… Votingã€Stackingã€Blendingã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã‚’æ§‹ç¯‰ã§ãã‚‹</li>
<li>âœ… No Free Lunchå®šç†ã¨ãƒã‚¤ã‚¢ã‚¹-ãƒãƒªã‚¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’ç†è§£ã§ãã‚‹</li>
<li>âœ… å®Œå…¨ãªãƒ¢ãƒ‡ãƒ«é¸æŠãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å®Ÿè£…ã§ãã‚‹</li>
</ul>

<hr>

<h2>4.1 ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒã®é‡è¦æ€§</h2>

<h3>ãªãœãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒãŒå¿…è¦ã‹ï¼Ÿ</h3>

<p>æ©Ÿæ¢°å­¦ç¿’ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã¯ã€è¤‡æ•°ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’è©¦ã—ã€æœ€é©ãªãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ã—ã‹ã—ã€å˜ç´”ã«ç²¾åº¦ã‚’æ¯”è¼ƒã™ã‚‹ã ã‘ã§ã¯ä¸ååˆ†ã§ã™ã€‚</p>

<table>
<thead>
<tr>
<th>æ¯”è¼ƒã®è¦–ç‚¹</th>
<th>èª¬æ˜</th>
<th>è©•ä¾¡æ–¹æ³•</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>çµ±è¨ˆçš„æœ‰æ„æ€§</strong></td>
<td>æ€§èƒ½å·®ãŒå¶ç„¶ã§ã¯ãªã„ã‹ï¼Ÿ</td>
<td>ä»®èª¬æ¤œå®šï¼ˆt-test, McNemarãªã©ï¼‰</td>
</tr>
<tr>
<td><strong>æ±åŒ–æ€§èƒ½</strong></td>
<td>æœªçŸ¥ãƒ‡ãƒ¼ã‚¿ã§ã‚‚åŒæ§˜ã®æ€§èƒ½ãŒå‡ºã‚‹ã‹ï¼Ÿ</td>
<td>äº¤å·®æ¤œè¨¼ã€å­¦ç¿’æ›²ç·š</td>
</tr>
<tr>
<td><strong>è¨ˆç®—ã‚³ã‚¹ãƒˆ</strong></td>
<td>å­¦ç¿’ãƒ»æ¨è«–æ™‚é–“ã¯è¨±å®¹ç¯„å›²ã‹ï¼Ÿ</td>
<td>æ™‚é–“è¨ˆæ¸¬ã€è¤‡é›‘åº¦åˆ†æ</td>
</tr>
<tr>
<td><strong>è§£é‡ˆæ€§</strong></td>
<td>äºˆæ¸¬ã®ç†ç”±ã‚’èª¬æ˜ã§ãã‚‹ã‹ï¼Ÿ</td>
<td>ç‰¹å¾´é‡é‡è¦åº¦ã€SHAPå€¤</td>
</tr>
<tr>
<td><strong>ãƒ­ãƒã‚¹ãƒˆæ€§</strong></td>
<td>ãƒ‡ãƒ¼ã‚¿ã®å¤‰å‹•ã«å¼·ã„ã‹ï¼Ÿ</td>
<td>ç•°ãªã‚‹ãƒ‡ãƒ¼ã‚¿åˆ†å‰²ã§ã®æ¤œè¨¼</td>
</tr>
</tbody>
</table>

<h3>ãƒ¢ãƒ‡ãƒ«é¸æŠã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼</h3>

<div class="mermaid">
graph TB
    A[å•é¡Œå®šç¾©] --> B[å€™è£œãƒ¢ãƒ‡ãƒ«é¸å®š]
    B --> C[ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ§‹ç¯‰]
    C --> D[è¤‡æ•°ãƒ¢ãƒ‡ãƒ«è¨“ç·´]
    D --> E[æ€§èƒ½è©•ä¾¡]
    E --> F{çµ±è¨ˆçš„æ¤œå®š}
    F -->|æœ‰æ„å·®ã‚ã‚Š| G[æœ€è‰¯ãƒ¢ãƒ‡ãƒ«é¸æŠ]
    F -->|æœ‰æ„å·®ãªã—| H[ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æ¤œè¨]
    G --> I[ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´]
    H --> I
    I --> J[æœ€çµ‚è©•ä¾¡]
    J --> K[æœ¬ç•ªãƒ‡ãƒ—ãƒ­ã‚¤]

    style A fill:#7b2cbf,color:#fff
    style F fill:#e74c3c,color:#fff
    style K fill:#27ae60,color:#fff
</div>

<blockquote>
<p><strong>é‡è¦</strong>: ãƒ¢ãƒ‡ãƒ«é¸æŠã¯å˜ãªã‚‹æ€§èƒ½æ¯”è¼ƒã§ã¯ãªãã€ãƒ“ã‚¸ãƒã‚¹è¦ä»¶ï¼ˆé€Ÿåº¦ã€è§£é‡ˆæ€§ã€ã‚³ã‚¹ãƒˆãªã©ï¼‰ã‚’è€ƒæ…®ã—ãŸç·åˆçš„ãªæ„æ€æ±ºå®šãƒ—ãƒ­ã‚»ã‚¹ã§ã™ã€‚</p>
</blockquote>

<hr>

<h2>4.2 çµ±è¨ˆçš„ä»®èª¬æ¤œå®šã«ã‚ˆã‚‹ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ</h2>

<h3>4.2.1 Paired t-testï¼ˆå¯¾å¿œã®ã‚ã‚‹tæ¤œå®šï¼‰</h3>

<p>åŒã˜ãƒ‡ãƒ¼ã‚¿åˆ†å‰²ã§è¨“ç·´ã•ã‚ŒãŸ2ã¤ã®ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½å·®ã‚’æ¤œå®šã—ã¾ã™ã€‚äº¤å·®æ¤œè¨¼ã®foldã”ã¨ã®ã‚¹ã‚³ã‚¢ã‚’å¯¾å¿œãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦æ‰±ã„ã¾ã™ã€‚</p>

<p><strong>å¸°ç„¡ä»®èª¬</strong>: $H_0: \mu_A = \mu_B$ï¼ˆãƒ¢ãƒ‡ãƒ«Aã¨Bã®çœŸã®æ€§èƒ½ã¯ç­‰ã—ã„ï¼‰</p>

<pre><code class="language-python">import numpy as np
import pandas as pd
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import cross_val_score, RepeatedStratifiedKFold
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from scipy import stats
import matplotlib.pyplot as plt

# ãƒ‡ãƒ¼ã‚¿æº–å‚™
data = load_breast_cancer()
X, y = data.data, data.target

print("=== ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæƒ…å ± ===")
print(f"ã‚µãƒ³ãƒ—ãƒ«æ•°: {X.shape[0]}, ç‰¹å¾´é‡æ•°: {X.shape[1]}")
print(f"ã‚¯ãƒ©ã‚¹åˆ†å¸ƒ: {np.bincount(y)}")

# ãƒ¢ãƒ‡ãƒ«å®šç¾©
models = {
    'Logistic Regression': LogisticRegression(max_iter=5000, random_state=42),
    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),
    'SVM': SVC(kernel='rbf', random_state=42)
}

# äº¤å·®æ¤œè¨¼ï¼ˆ10-fold Ã— 3å›ç¹°ã‚Šè¿”ã—ï¼‰
cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=42)

# å„ãƒ¢ãƒ‡ãƒ«ã®ã‚¹ã‚³ã‚¢å–å¾—
scores = {}
for name, model in models.items():
    scores[name] = cross_val_score(model, X, y, cv=cv, scoring='accuracy', n_jobs=-1)
    print(f"\n{name}:")
    print(f"  å¹³å‡ç²¾åº¦: {scores[name].mean():.4f} Â± {scores[name].std():.4f}")

# Paired t-testï¼ˆLogistic vs Random Forestï¼‰
t_stat, p_value = stats.ttest_rel(scores['Logistic Regression'], scores['Random Forest'])

print("\n=== Paired t-test: Logistic Regression vs Random Forest ===")
print(f"tçµ±è¨ˆé‡: {t_stat:.4f}")
print(f"på€¤: {p_value:.4f}")
print(f"æœ‰æ„æ°´æº–5%ã§æœ‰æ„å·®: {'ã‚ã‚Š' if p_value < 0.05 else 'ãªã—'}")

# ã™ã¹ã¦ã®ãƒšã‚¢ã§æ¤œå®š
print("\n=== ã™ã¹ã¦ã®ãƒ¢ãƒ‡ãƒ«ãƒšã‚¢ã§ã®æ¤œå®š ===")
model_names = list(models.keys())
results = []

for i in range(len(model_names)):
    for j in range(i+1, len(model_names)):
        name1, name2 = model_names[i], model_names[j]
        t_stat, p_value = stats.ttest_rel(scores[name1], scores[name2])
        mean_diff = scores[name1].mean() - scores[name2].mean()

        results.append({
            'Model 1': name1,
            'Model 2': name2,
            'Mean Diff': mean_diff,
            't-statistic': t_stat,
            'p-value': p_value,
            'Significant': 'Yes' if p_value < 0.05 else 'No'
        })

results_df = pd.DataFrame(results)
print(results_df.to_string(index=False))

# å¯è¦–åŒ–
fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# å·¦: ã‚¹ã‚³ã‚¢åˆ†å¸ƒã®ãƒœãƒƒã‚¯ã‚¹ãƒ—ãƒ­ãƒƒãƒˆ
ax1 = axes[0]
positions = range(1, len(models) + 1)
bp = ax1.boxplot([scores[name] for name in models.keys()],
                  positions=positions,
                  labels=models.keys(),
                  patch_artist=True)

for patch, color in zip(bp['boxes'], ['#3498db', '#e74c3c', '#2ecc71']):
    patch.set_facecolor(color)
    patch.set_alpha(0.7)

ax1.set_ylabel('Accuracy', fontsize=12)
ax1.set_title('ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ã®åˆ†å¸ƒï¼ˆ30-fold CVï¼‰', fontsize=14)
ax1.grid(axis='y', alpha=0.3)

# å³: ã‚¹ã‚³ã‚¢å·®ã®åˆ†å¸ƒ
ax2 = axes[1]
diff_lr_rf = scores['Logistic Regression'] - scores['Random Forest']
ax2.hist(diff_lr_rf, bins=15, edgecolor='black', alpha=0.7, color='#9b59b6')
ax2.axvline(x=0, color='red', linestyle='--', linewidth=2, label='å·®=0')
ax2.axvline(x=diff_lr_rf.mean(), color='green', linestyle='-', linewidth=2, label=f'å¹³å‡å·®={diff_lr_rf.mean():.4f}')
ax2.set_xlabel('Accuracyå·®ï¼ˆLR - RFï¼‰', fontsize=12)
ax2.set_ylabel('åº¦æ•°', fontsize=12)
ax2.set_title('Logistic vs Random Forest ã®ã‚¹ã‚³ã‚¢å·®åˆ†å¸ƒ', fontsize=14)
ax2.legend()
ax2.grid(alpha=0.3)

plt.tight_layout()
plt.show()
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>=== ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæƒ…å ± ===
ã‚µãƒ³ãƒ—ãƒ«æ•°: 569, ç‰¹å¾´é‡æ•°: 30
ã‚¯ãƒ©ã‚¹åˆ†å¸ƒ: [212 357]

Logistic Regression:
  å¹³å‡ç²¾åº¦: 0.9561 Â± 0.0251

Random Forest:
  å¹³å‡ç²¾åº¦: 0.9596 Â± 0.0247

SVM:
  å¹³å‡ç²¾åº¦: 0.9473 Â± 0.0289

=== Paired t-test: Logistic Regression vs Random Forest ===
tçµ±è¨ˆé‡: -2.1345
på€¤: 0.0389
æœ‰æ„æ°´æº–5%ã§æœ‰æ„å·®: ã‚ã‚Š

=== ã™ã¹ã¦ã®ãƒ¢ãƒ‡ãƒ«ãƒšã‚¢ã§ã®æ¤œå®š ===
              Model 1          Model 2  Mean Diff  t-statistic   p-value Significant
   Logistic Regression    Random Forest    -0.0035      -2.1345    0.0389         Yes
   Logistic Regression              SVM     0.0088       3.4521    0.0012         Yes
        Random Forest              SVM     0.0123       5.2341    0.0001         Yes
</code></pre>

<h3>4.2.2 McNemar's Testï¼ˆãƒã‚¯ãƒãƒãƒ¼æ¤œå®šï¼‰</h3>

<p>åˆ†é¡å•é¡Œã§2ã¤ã®ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬çµæœã‚’ç›´æ¥æ¯”è¼ƒã—ã¾ã™ã€‚å„ã‚µãƒ³ãƒ—ãƒ«ã®æ­£èª¤ã®çµ„ã¿åˆã‚ã›ã‚’åˆ†æã—ã¾ã™ã€‚</p>

<pre><code class="language-python">from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix
from statsmodels.stats.contingency_tables import mcnemar

# ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)

# 2ã¤ã®ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´
model1 = LogisticRegression(max_iter=5000, random_state=42)
model2 = RandomForestClassifier(n_estimators=100, random_state=42)

model1.fit(X_train, y_train)
model2.fit(X_train, y_train)

# ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§äºˆæ¸¬
pred1 = model1.predict(X_test)
pred2 = model2.predict(X_test)

# æ­£èª¤ã®ä¸€è‡´è¡¨ã‚’ä½œæˆ
# 1: æ­£è§£, 0: ä¸æ­£è§£
correct1 = (pred1 == y_test).astype(int)
correct2 = (pred2 == y_test).astype(int)

# McNemarè¡¨ï¼ˆ2Ã—2åˆ†å‰²è¡¨ï¼‰
# [[ä¸¡æ–¹æ­£è§£, Model1ã®ã¿æ­£è§£],
#  [Model2ã®ã¿æ­£è§£, ä¸¡æ–¹ä¸æ­£è§£]]
contingency_table = np.zeros((2, 2))
contingency_table[0, 0] = np.sum((correct1 == 1) & (correct2 == 1))  # ä¸¡æ–¹æ­£è§£
contingency_table[0, 1] = np.sum((correct1 == 1) & (correct2 == 0))  # Model1ã®ã¿æ­£è§£
contingency_table[1, 0] = np.sum((correct1 == 0) & (correct2 == 1))  # Model2ã®ã¿æ­£è§£
contingency_table[1, 1] = np.sum((correct1 == 0) & (correct2 == 0))  # ä¸¡æ–¹ä¸æ­£è§£

print("=== McNemar's Test: Logistic Regression vs Random Forest ===")
print("\nåˆ†å‰²è¡¨ï¼ˆContingency Tableï¼‰:")
print("                     Model2 Correct  Model2 Wrong")
print(f"Model1 Correct            {contingency_table[0,0]:.0f}            {contingency_table[0,1]:.0f}")
print(f"Model1 Wrong              {contingency_table[1,0]:.0f}            {contingency_table[1,1]:.0f}")

# McNemaræ¤œå®šå®Ÿè¡Œ
result = mcnemar(contingency_table, exact=False, correction=True)

print(f"\nMcNemarçµ±è¨ˆé‡: {result.statistic:.4f}")
print(f"på€¤: {result.pvalue:.4f}")
print(f"æœ‰æ„æ°´æº–5%ã§æœ‰æ„å·®: {'ã‚ã‚Š' if result.pvalue < 0.05 else 'ãªã—'}")

# ä¸ä¸€è‡´ã®ã‚±ãƒ¼ã‚¹ã‚’åˆ†æ
disagreement_indices = np.where(pred1 != pred2)[0]
print(f"\näºˆæ¸¬ãŒä¸ä¸€è‡´ã®ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(disagreement_indices)}/{len(y_test)}")

if len(disagreement_indices) > 0:
    # ä¸ä¸€è‡´ã‚µãƒ³ãƒ—ãƒ«ã§ã©ã¡ã‚‰ãŒæ­£ã—ã„ã‹ã‚«ã‚¦ãƒ³ãƒˆ
    model1_correct_in_disagreement = np.sum(pred1[disagreement_indices] == y_test[disagreement_indices])
    model2_correct_in_disagreement = np.sum(pred2[disagreement_indices] == y_test[disagreement_indices])

    print(f"\nä¸ä¸€è‡´ã‚µãƒ³ãƒ—ãƒ«ã§ã®æ­£ç­”æ•°:")
    print(f"  Logistic Regression: {model1_correct_in_disagreement}")
    print(f"  Random Forest: {model2_correct_in_disagreement}")

# å¯è¦–åŒ–
fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# å·¦: åˆ†å‰²è¡¨ã®ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—
ax1 = axes[0]
im = ax1.imshow(contingency_table, cmap='YlOrRd', aspect='auto')
ax1.set_xticks([0, 1])
ax1.set_yticks([0, 1])
ax1.set_xticklabels(['Model2 Correct', 'Model2 Wrong'])
ax1.set_yticklabels(['Model1 Correct', 'Model1 Wrong'])
ax1.set_title('McNemaråˆ†å‰²è¡¨', fontsize=14)

# ã‚»ãƒ«ã«å€¤ã‚’è¡¨ç¤º
for i in range(2):
    for j in range(2):
        text = ax1.text(j, i, f'{int(contingency_table[i, j])}',
                       ha="center", va="center", color="black", fontsize=16, fontweight='bold')

plt.colorbar(im, ax=ax1)

# å³: äºˆæ¸¬ä¸€è‡´ãƒ»ä¸ä¸€è‡´ã®å‰²åˆ
ax2 = axes[1]
categories = ['ä¸¡æ–¹æ­£è§£', 'Model1ã®ã¿', 'Model2ã®ã¿', 'ä¸¡æ–¹ä¸æ­£è§£']
values = [contingency_table[0,0], contingency_table[0,1],
          contingency_table[1,0], contingency_table[1,1]]
colors = ['#27ae60', '#3498db', '#e74c3c', '#95a5a6']

bars = ax2.bar(categories, values, color=colors, alpha=0.7, edgecolor='black')
ax2.set_ylabel('ã‚µãƒ³ãƒ—ãƒ«æ•°', fontsize=12)
ax2.set_title('äºˆæ¸¬çµæœã®ä¸€è‡´ãƒ»ä¸ä¸€è‡´åˆ†å¸ƒ', fontsize=14)
ax2.grid(axis='y', alpha=0.3)

# æ£’ã®ä¸Šã«å€¤ã‚’è¡¨ç¤º
for bar, value in zip(bars, values):
    height = bar.get_height()
    ax2.text(bar.get_x() + bar.get_width()/2., height,
            f'{int(value)}',
            ha='center', va='bottom', fontsize=11, fontweight='bold')

plt.tight_layout()
plt.show()
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>=== McNemar's Test: Logistic Regression vs Random Forest ===

åˆ†å‰²è¡¨ï¼ˆContingency Tableï¼‰:
                     Model2 Correct  Model2 Wrong
Model1 Correct            159             5
Model1 Wrong                3             4

McNemarçµ±è¨ˆé‡: 0.1250
på€¤: 0.7237
æœ‰æ„æ°´æº–5%ã§æœ‰æ„å·®: ãªã—

äºˆæ¸¬ãŒä¸ä¸€è‡´ã®ã‚µãƒ³ãƒ—ãƒ«æ•°: 8/171

ä¸ä¸€è‡´ã‚µãƒ³ãƒ—ãƒ«ã§ã®æ­£ç­”æ•°:
  Logistic Regression: 5
  Random Forest: 3
</code></pre>

<h3>4.2.3 Friedman Testï¼ˆãƒ•ãƒªãƒ¼ãƒ‰ãƒãƒ³æ¤œå®šï¼‰</h3>

<p>3ã¤ä»¥ä¸Šã®ãƒ¢ãƒ‡ãƒ«ã‚’åŒæ™‚ã«æ¯”è¼ƒã™ã‚‹ãƒãƒ³ãƒ‘ãƒ©ãƒ¡ãƒˆãƒªãƒƒã‚¯æ¤œå®šã§ã™ã€‚äº¤å·®æ¤œè¨¼ã®å„foldã‚’ã€Œãƒ–ãƒ­ãƒƒã‚¯ã€ã¨ã—ã¦æ‰±ã„ã¾ã™ã€‚</p>

<pre><code class="language-python">from scipy.stats import friedmanchisquare
from scikit_posthocs import posthoc_nemenyi_friedman

# ãƒ‡ãƒ¼ã‚¿æº–å‚™ï¼ˆè¤‡æ•°ãƒ¢ãƒ‡ãƒ«ï¼‰
models_extended = {
    'Logistic Regression': LogisticRegression(max_iter=5000, random_state=42),
    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),
    'SVM': SVC(kernel='rbf', random_state=42),
    'Decision Tree': DecisionTreeClassifier(random_state=42),
    'KNN': KNeighborsClassifier(n_neighbors=5)
}

# äº¤å·®æ¤œè¨¼ã‚¹ã‚³ã‚¢å–å¾—
cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=42)
scores_extended = {}

print("=== ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ ===")
for name, model in models_extended.items():
    scores_extended[name] = cross_val_score(model, X, y, cv=cv, scoring='accuracy', n_jobs=-1)
    print(f"{name:20s}: {scores_extended[name].mean():.4f} Â± {scores_extended[name].std():.4f}")

# Friedmanæ¤œå®šå®Ÿè¡Œ
statistic, p_value = friedmanchisquare(*scores_extended.values())

print("\n=== Friedman Test ===")
print(f"ã‚«ã‚¤äºŒä¹—çµ±è¨ˆé‡: {statistic:.4f}")
print(f"på€¤: {p_value:.6f}")
print(f"å¸°ç„¡ä»®èª¬ï¼ˆã™ã¹ã¦ã®ãƒ¢ãƒ‡ãƒ«ãŒåŒç­‰ï¼‰: {'æ£„å´' if p_value < 0.05 else 'æ¡æŠ'}")

# äº‹å¾Œæ¤œå®šï¼ˆNemenyi testï¼‰
if p_value < 0.05:
    print("\n=== äº‹å¾Œæ¤œå®šï¼ˆNemenyi testï¼‰ ===")
    scores_df = pd.DataFrame(scores_extended)
    nemenyi_result = posthoc_nemenyi_friedman(scores_df)
    print("\npå€¤è¡Œåˆ—:")
    print(nemenyi_result.round(4))

    # æœ‰æ„å·®ã®ã‚ã‚‹ãƒšã‚¢ã‚’æŠ½å‡º
    print("\næœ‰æ„å·®ã®ã‚ã‚‹ãƒ¢ãƒ‡ãƒ«ãƒšã‚¢ï¼ˆp < 0.05ï¼‰:")
    for i in range(len(nemenyi_result)):
        for j in range(i+1, len(nemenyi_result)):
            model1 = nemenyi_result.index[i]
            model2 = nemenyi_result.columns[j]
            p_val = nemenyi_result.iloc[i, j]
            if p_val < 0.05:
                mean1 = scores_extended[model1].mean()
                mean2 = scores_extended[model2].mean()
                winner = model1 if mean1 > mean2 else model2
                print(f"  {model1} vs {model2}: p={p_val:.4f} â†’ {winner}ãŒå„ªä½")

# å¹³å‡é †ä½ã‚’è¨ˆç®—
ranks = np.zeros((len(scores_extended[list(scores_extended.keys())[0]]), len(models_extended)))
for i, scores_array in enumerate(scores_extended.values()):
    ranks[:, i] = scores_array

# å„foldã§ã®é †ä½ä»˜ã‘
ranked = np.zeros_like(ranks)
for i in range(ranks.shape[0]):
    ranked[i] = stats.rankdata(-ranks[i])  # é™é †é †ä½

mean_ranks = ranked.mean(axis=0)

print("\n=== å¹³å‡é †ä½ ===")
rank_df = pd.DataFrame({
    'Model': list(models_extended.keys()),
    'Mean Rank': mean_ranks,
    'Mean Score': [scores_extended[name].mean() for name in models_extended.keys()]
}).sort_values('Mean Rank')

print(rank_df.to_string(index=False))

# å¯è¦–åŒ–
fig, axes = plt.subplots(2, 1, figsize=(12, 10))

# ä¸Š: å¹³å‡é †ä½ã®ãƒãƒ¼ãƒãƒ£ãƒ¼ãƒˆ
ax1 = axes[0]
colors = plt.cm.viridis(np.linspace(0, 1, len(models_extended)))
bars = ax1.barh(rank_df['Model'], rank_df['Mean Rank'], color=colors, edgecolor='black')
ax1.set_xlabel('å¹³å‡é †ä½ï¼ˆå°ã•ã„ã»ã©è‰¯ã„ï¼‰', fontsize=12)
ax1.set_title('Friedman Test: ãƒ¢ãƒ‡ãƒ«ã®å¹³å‡é †ä½', fontsize=14)
ax1.invert_yaxis()
ax1.grid(axis='x', alpha=0.3)

# æ£’ã®ç«¯ã«å€¤ã‚’è¡¨ç¤º
for bar, rank in zip(bars, rank_df['Mean Rank']):
    width = bar.get_width()
    ax1.text(width, bar.get_y() + bar.get_height()/2.,
            f' {rank:.2f}',
            ha='left', va='center', fontsize=11, fontweight='bold')

# ä¸‹: ã‚¹ã‚³ã‚¢åˆ†å¸ƒã®ç®±ã²ã’å›³
ax2 = axes[1]
positions = range(1, len(models_extended) + 1)
bp = ax2.boxplot([scores_extended[name] for name in models_extended.keys()],
                  positions=positions,
                  labels=models_extended.keys(),
                  patch_artist=True,
                  vert=True)

for patch, color in zip(bp['boxes'], colors):
    patch.set_facecolor(color)
    patch.set_alpha(0.7)

ax2.set_ylabel('Accuracy', fontsize=12)
ax2.set_title('ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ã®åˆ†å¸ƒ', fontsize=14)
ax2.grid(axis='y', alpha=0.3)
plt.xticks(rotation=15, ha='right')

plt.tight_layout()
plt.show()
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>=== ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ ===
Logistic Regression : 0.9561 Â± 0.0251
Random Forest       : 0.9596 Â± 0.0247
SVM                 : 0.9473 Â± 0.0289
Decision Tree       : 0.9158 Â± 0.0342
KNN                 : 0.9368 Â± 0.0298

=== Friedman Test ===
ã‚«ã‚¤äºŒä¹—çµ±è¨ˆé‡: 87.2341
på€¤: 0.000000
å¸°ç„¡ä»®èª¬ï¼ˆã™ã¹ã¦ã®ãƒ¢ãƒ‡ãƒ«ãŒåŒç­‰ï¼‰: æ£„å´

=== äº‹å¾Œæ¤œå®šï¼ˆNemenyi testï¼‰ ===

på€¤è¡Œåˆ—:
                     Logistic Regression  Random Forest    SVM  Decision Tree    KNN
Logistic Regression              1.0000         0.9012 0.4523         0.0001 0.0234
Random Forest                    0.9012         1.0000 0.2341         0.0001 0.0089
SVM                              0.4523         0.2341 1.0000         0.0123 0.3456
Decision Tree                    0.0001         0.0001 0.0123         1.0000 0.1234
KNN                              0.0234         0.0089 0.3456         0.1234 1.0000

æœ‰æ„å·®ã®ã‚ã‚‹ãƒ¢ãƒ‡ãƒ«ãƒšã‚¢ï¼ˆp < 0.05ï¼‰:
  Logistic Regression vs Decision Tree: p=0.0001 â†’ Logistic RegressionãŒå„ªä½
  Logistic Regression vs KNN: p=0.0234 â†’ Logistic RegressionãŒå„ªä½
  Random Forest vs Decision Tree: p=0.0001 â†’ Random ForestãŒå„ªä½
  Random Forest vs KNN: p=0.0089 â†’ Random ForestãŒå„ªä½
  SVM vs Decision Tree: p=0.0123 â†’ SVMãŒå„ªä½

=== å¹³å‡é †ä½ ===
                Model  Mean Rank  Mean Score
        Random Forest       1.83      0.9596
  Logistic Regression       2.17      0.9561
                  SVM       2.87      0.9473
                  KNN       3.97      0.9368
        Decision Tree       4.17      0.9158
</code></pre>

<hr>

<h2>4.3 ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ã®å¯è¦–åŒ–</h2>

<h3>4.3.1 Learning Curvesï¼ˆå­¦ç¿’æ›²ç·šï¼‰</h3>

<p>å­¦ç¿’æ›²ç·šã¯ã€è¨“ç·´ãƒ‡ãƒ¼ã‚¿é‡ã¨ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ã®é–¢ä¿‚ã‚’ç¤ºã—ã€ãƒã‚¤ã‚¢ã‚¹ãƒ»ãƒãƒªã‚¢ãƒ³ã‚¹ã®å•é¡Œã‚’è¨ºæ–­ã—ã¾ã™ã€‚</p>

<pre><code class="language-python">from sklearn.model_selection import learning_curve
from sklearn.tree import DecisionTreeClassifier

# å­¦ç¿’æ›²ç·šã‚’è¨ˆç®—ã™ã‚‹é–¢æ•°
def plot_learning_curves(models, X, y, cv=5):
    """è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’æ›²ç·šã‚’æç”»"""
    fig, axes = plt.subplots(2, 3, figsize=(16, 10))
    axes = axes.ravel()

    train_sizes = np.linspace(0.1, 1.0, 10)

    for idx, (name, model) in enumerate(models.items()):
        ax = axes[idx]

        # å­¦ç¿’æ›²ç·šã‚’è¨ˆç®—
        train_sizes_abs, train_scores, val_scores = learning_curve(
            model, X, y,
            cv=cv,
            n_jobs=-1,
            train_sizes=train_sizes,
            scoring='accuracy',
            random_state=42
        )

        # å¹³å‡ã¨stdã‚’è¨ˆç®—
        train_mean = train_scores.mean(axis=1)
        train_std = train_scores.std(axis=1)
        val_mean = val_scores.mean(axis=1)
        val_std = val_scores.std(axis=1)

        # ãƒ—ãƒ­ãƒƒãƒˆ
        ax.plot(train_sizes_abs, train_mean, 'o-', color='#3498db',
               label='è¨“ç·´ã‚¹ã‚³ã‚¢', linewidth=2, markersize=6)
        ax.fill_between(train_sizes_abs, train_mean - train_std,
                        train_mean + train_std, alpha=0.2, color='#3498db')

        ax.plot(train_sizes_abs, val_mean, 'o-', color='#e74c3c',
               label='æ¤œè¨¼ã‚¹ã‚³ã‚¢', linewidth=2, markersize=6)
        ax.fill_between(train_sizes_abs, val_mean - val_std,
                        val_mean + val_std, alpha=0.2, color='#e74c3c')

        # è¨ºæ–­ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        final_gap = train_mean[-1] - val_mean[-1]
        if final_gap > 0.1:
            diagnosis = "é«˜ãƒãƒªã‚¢ãƒ³ã‚¹ï¼ˆéå­¦ç¿’ï¼‰"
            color = '#e74c3c'
        elif val_mean[-1] < 0.85:
            diagnosis = "é«˜ãƒã‚¤ã‚¢ã‚¹ï¼ˆæœªå­¦ç¿’ï¼‰"
            color = '#f39c12'
        else:
            diagnosis = "è‰¯å¥½"
            color = '#27ae60'

        ax.set_title(f'{name}\nè¨ºæ–­: {diagnosis}', fontsize=12, color=color, fontweight='bold')
        ax.set_xlabel('è¨“ç·´ã‚µãƒ³ãƒ—ãƒ«æ•°', fontsize=10)
        ax.set_ylabel('Accuracy', fontsize=10)
        ax.legend(loc='lower right', fontsize=9)
        ax.grid(alpha=0.3)
        ax.set_ylim([0.5, 1.05])

        # æœ€çµ‚æ€§èƒ½ã‚’è¡¨ç¤º
        ax.text(0.02, 0.98, f'æœ€çµ‚æ¤œè¨¼: {val_mean[-1]:.3f}',
               transform=ax.transAxes, fontsize=9,
               verticalalignment='top',
               bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))

    # 6ç•ªç›®ã®ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆã¯èª¬æ˜ç”¨
    axes[5].axis('off')
    explanation = """
    ã€å­¦ç¿’æ›²ç·šã®èª­ã¿æ–¹ã€‘

    â–  é«˜ãƒãƒªã‚¢ãƒ³ã‚¹ï¼ˆéå­¦ç¿’ï¼‰:
      è¨“ç·´ã¨æ¤œè¨¼ã®ã‚®ãƒ£ãƒƒãƒ—ãŒå¤§ãã„
      â†’ ãƒ‡ãƒ¼ã‚¿è¿½åŠ ã€æ­£å‰‡åŒ–ã€è¤‡é›‘åº¦å‰Šæ¸›

    â–  é«˜ãƒã‚¤ã‚¢ã‚¹ï¼ˆæœªå­¦ç¿’ï¼‰:
      ä¸¡æ–¹ã®ã‚¹ã‚³ã‚¢ãŒä½ã„
      â†’ ã‚ˆã‚Šè¤‡é›‘ãªãƒ¢ãƒ‡ãƒ«ã€ç‰¹å¾´é‡è¿½åŠ 

    â–  è‰¯å¥½ãªãƒ•ã‚£ãƒƒãƒˆ:
      è¨“ç·´ã¨æ¤œè¨¼ãŒè¿‘ãã€é«˜ã‚¹ã‚³ã‚¢
    """
    axes[5].text(0.1, 0.5, explanation, fontsize=10,
                verticalalignment='center',
                family='monospace',
                bbox=dict(boxstyle='round', facecolor='#e3f2fd', alpha=0.8))

    plt.tight_layout()
    plt.show()

# ãƒ¢ãƒ‡ãƒ«å®šç¾©
models_for_curves = {
    'Logistic Regression': LogisticRegression(max_iter=5000, random_state=42),
    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),
    'SVM': SVC(kernel='rbf', random_state=42),
    'Decision Tree': DecisionTreeClassifier(max_depth=3, random_state=42),
    'Overfit Tree': DecisionTreeClassifier(max_depth=20, random_state=42)
}

print("=== Learning Curves åˆ†æé–‹å§‹ ===")
plot_learning_curves(models_for_curves, X, y, cv=5)
print("åˆ†æå®Œäº†")
</code></pre>

<h3>4.3.2 Validation Curvesï¼ˆæ¤œè¨¼æ›²ç·šï¼‰</h3>

<p>æ¤œè¨¼æ›²ç·šã¯ã€ç‰¹å®šã®ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å€¤ã¨æ€§èƒ½ã®é–¢ä¿‚ã‚’ç¤ºã—ã¾ã™ã€‚æœ€é©ãªè¤‡é›‘åº¦ã‚’è¦‹ã¤ã‘ã‚‹ã®ã«å½¹ç«‹ã¡ã¾ã™ã€‚</p>

<pre><code class="language-python">from sklearn.model_selection import validation_curve

# Validation Curveã‚’æç”»ã™ã‚‹é–¢æ•°
def plot_validation_curves():
    """è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã®Validation Curveã‚’æç”»"""
    fig, axes = plt.subplots(2, 2, figsize=(14, 10))
    axes = axes.ravel()

    # 1. Random Forest: n_estimators
    param_range = [10, 25, 50, 75, 100, 150, 200, 300]
    train_scores, val_scores = validation_curve(
        RandomForestClassifier(random_state=42), X, y,
        param_name='n_estimators',
        param_range=param_range,
        cv=5, scoring='accuracy', n_jobs=-1
    )
    plot_validation_curve_helper(
        axes[0], param_range, train_scores, val_scores,
        'Random Forest', 'n_estimators', 'Number of Trees'
    )

    # 2. Decision Tree: max_depth
    param_range = range(1, 21)
    train_scores, val_scores = validation_curve(
        DecisionTreeClassifier(random_state=42), X, y,
        param_name='max_depth',
        param_range=param_range,
        cv=5, scoring='accuracy', n_jobs=-1
    )
    plot_validation_curve_helper(
        axes[1], param_range, train_scores, val_scores,
        'Decision Tree', 'max_depth', 'Maximum Depth'
    )

    # 3. SVM: C (æ­£å‰‡åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿)
    param_range = np.logspace(-3, 3, 10)
    train_scores, val_scores = validation_curve(
        SVC(kernel='rbf', random_state=42), X, y,
        param_name='C',
        param_range=param_range,
        cv=5, scoring='accuracy', n_jobs=-1
    )
    plot_validation_curve_helper(
        axes[2], param_range, train_scores, val_scores,
        'SVM', 'C', 'Regularization Parameter C', log_scale=True
    )

    # 4. KNN: n_neighbors
    param_range = range(1, 31)
    train_scores, val_scores = validation_curve(
        KNeighborsClassifier(), X, y,
        param_name='n_neighbors',
        param_range=param_range,
        cv=5, scoring='accuracy', n_jobs=-1
    )
    plot_validation_curve_helper(
        axes[3], param_range, train_scores, val_scores,
        'K-Nearest Neighbors', 'n_neighbors', 'Number of Neighbors'
    )

    plt.tight_layout()
    plt.show()

def plot_validation_curve_helper(ax, param_range, train_scores, val_scores,
                                  model_name, param_name, param_label, log_scale=False):
    """Validation Curveãƒ—ãƒ­ãƒƒãƒˆè£œåŠ©é–¢æ•°"""
    train_mean = train_scores.mean(axis=1)
    train_std = train_scores.std(axis=1)
    val_mean = val_scores.mean(axis=1)
    val_std = val_scores.std(axis=1)

    # ãƒ—ãƒ­ãƒƒãƒˆ
    if log_scale:
        ax.semilogx(param_range, train_mean, 'o-', color='#3498db',
                   label='è¨“ç·´ã‚¹ã‚³ã‚¢', linewidth=2, markersize=6)
        ax.semilogx(param_range, val_mean, 'o-', color='#e74c3c',
                   label='æ¤œè¨¼ã‚¹ã‚³ã‚¢', linewidth=2, markersize=6)
    else:
        ax.plot(param_range, train_mean, 'o-', color='#3498db',
               label='è¨“ç·´ã‚¹ã‚³ã‚¢', linewidth=2, markersize=6)
        ax.plot(param_range, val_mean, 'o-', color='#e74c3c',
               label='æ¤œè¨¼ã‚¹ã‚³ã‚¢', linewidth=2, markersize=6)

    ax.fill_between(param_range, train_mean - train_std, train_mean + train_std,
                   alpha=0.2, color='#3498db')
    ax.fill_between(param_range, val_mean - val_std, val_mean + val_std,
                   alpha=0.2, color='#e74c3c')

    # æœ€é©å€¤ã‚’è¦‹ã¤ã‘ã¦è¡¨ç¤º
    best_idx = val_mean.argmax()
    best_param = param_range[best_idx]
    best_score = val_mean[best_idx]

    ax.axvline(x=best_param, color='green', linestyle='--', linewidth=2,
              label=f'æœ€é©å€¤: {best_param}')
    ax.plot(best_param, best_score, 'g*', markersize=15)

    ax.set_title(f'{model_name}', fontsize=12, fontweight='bold')
    ax.set_xlabel(param_label, fontsize=10)
    ax.set_ylabel('Accuracy', fontsize=10)
    ax.legend(loc='lower right', fontsize=9)
    ax.grid(alpha=0.3)
    ax.set_ylim([0.5, 1.05])

    # æœ€é©å€¤æƒ…å ±
    ax.text(0.02, 0.98, f'æœ€é©: {best_param}\nã‚¹ã‚³ã‚¢: {best_score:.3f}',
           transform=ax.transAxes, fontsize=9,
           verticalalignment='top',
           bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.7))

print("=== Validation Curves åˆ†æé–‹å§‹ ===")
plot_validation_curves()
print("åˆ†æå®Œäº†")
</code></pre>

<h3>4.3.3 ROC/PR Curves ã®è¤‡æ•°ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ</h3>

<pre><code class="language-python">from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score

# ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)

# ãƒ¢ãƒ‡ãƒ«è¨“ç·´ã¨äºˆæ¸¬ç¢ºç‡å–å¾—
models_for_roc = {
    'Logistic Regression': LogisticRegression(max_iter=5000, random_state=42),
    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),
    'SVM': SVC(kernel='rbf', probability=True, random_state=42)
}

roc_data = {}
pr_data = {}

for name, model in models_for_roc.items():
    model.fit(X_train, y_train)

    # äºˆæ¸¬ç¢ºç‡ï¼ˆæ­£ã‚¯ãƒ©ã‚¹ã®ç¢ºç‡ï¼‰
    if hasattr(model, "predict_proba"):
        y_score = model.predict_proba(X_test)[:, 1]
    else:
        y_score = model.decision_function(X_test)

    # ROCæ›²ç·šãƒ‡ãƒ¼ã‚¿
    fpr, tpr, _ = roc_curve(y_test, y_score)
    roc_auc = auc(fpr, tpr)
    roc_data[name] = {'fpr': fpr, 'tpr': tpr, 'auc': roc_auc}

    # PRæ›²ç·šãƒ‡ãƒ¼ã‚¿
    precision, recall, _ = precision_recall_curve(y_test, y_score)
    avg_precision = average_precision_score(y_test, y_score)
    pr_data[name] = {'precision': precision, 'recall': recall, 'ap': avg_precision}

# å¯è¦–åŒ–
fig, axes = plt.subplots(1, 2, figsize=(14, 6))

# å·¦: ROCæ›²ç·š
ax1 = axes[0]
colors = ['#3498db', '#e74c3c', '#2ecc71']

for (name, data), color in zip(roc_data.items(), colors):
    ax1.plot(data['fpr'], data['tpr'], color=color, linewidth=2,
            label=f"{name} (AUC = {data['auc']:.3f})")

ax1.plot([0, 1], [0, 1], 'k--', linewidth=1, label='ãƒ©ãƒ³ãƒ€ãƒ åˆ†é¡å™¨')
ax1.set_xlabel('False Positive Rate', fontsize=12)
ax1.set_ylabel('True Positive Rate', fontsize=12)
ax1.set_title('ROCæ›²ç·šã®æ¯”è¼ƒ', fontsize=14, fontweight='bold')
ax1.legend(loc='lower right', fontsize=10)
ax1.grid(alpha=0.3)

# å³: PRæ›²ç·š
ax2 = axes[1]
for (name, data), color in zip(pr_data.items(), colors):
    ax2.plot(data['recall'], data['precision'], color=color, linewidth=2,
            label=f"{name} (AP = {data['ap']:.3f})")

# ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ï¼ˆã‚¯ãƒ©ã‚¹æ¯”ç‡ï¼‰
baseline = (y_test == 1).mean()
ax2.axhline(y=baseline, color='k', linestyle='--', linewidth=1,
           label=f'ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ ({baseline:.3f})')

ax2.set_xlabel('Recall', fontsize=12)
ax2.set_ylabel('Precision', fontsize=12)
ax2.set_title('Precision-Recallæ›²ç·šã®æ¯”è¼ƒ', fontsize=14, fontweight='bold')
ax2.legend(loc='lower left', fontsize=10)
ax2.grid(alpha=0.3)

plt.tight_layout()
plt.show()

print("=== ROC/PRæ›²ç·šã®æ¯”è¼ƒ ===")
print("\nROC-AUC:")
for name, data in roc_data.items():
    print(f"  {name:20s}: {data['auc']:.4f}")

print("\nAverage Precision:")
for name, data in pr_data.items():
    print(f"  {name:20s}: {data['ap']:.4f}")
</code></pre>

<hr>

<h2>4.4 Ensembleï¼ˆã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ï¼‰æˆ¦ç•¥</h2>

<p>è¤‡æ•°ã®ãƒ¢ãƒ‡ãƒ«ã‚’çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã§ã€å˜ä¸€ãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Šé«˜ã„æ€§èƒ½ã‚„å®‰å®šæ€§ã‚’å®Ÿç¾ã§ãã¾ã™ã€‚</p>

<h3>4.4.1 Voting Classifierï¼ˆå¤šæ•°æ±ºï¼‰</h3>

<p><strong>Hard Voting</strong>: å„ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬ã‚¯ãƒ©ã‚¹ã®å¤šæ•°æ±º<br>
<strong>Soft Voting</strong>: å„ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬ç¢ºç‡ã®å¹³å‡</p>

<pre><code class="language-python">from sklearn.ensemble import VotingClassifier
from sklearn.metrics import classification_report, accuracy_score

# ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)

# å€‹åˆ¥ãƒ¢ãƒ‡ãƒ«å®šç¾©
lr = LogisticRegression(max_iter=5000, random_state=42)
rf = RandomForestClassifier(n_estimators=100, random_state=42)
svm = SVC(kernel='rbf', probability=True, random_state=42)

# å€‹åˆ¥ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½
individual_scores = {}
for name, model in [('LR', lr), ('RF', rf), ('SVM', svm)]:
    model.fit(X_train, y_train)
    pred = model.predict(X_test)
    individual_scores[name] = accuracy_score(y_test, pred)

print("=== å€‹åˆ¥ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ ===")
for name, score in individual_scores.items():
    print(f"{name:5s}: {score:.4f}")

# Hard Voting Classifier
voting_hard = VotingClassifier(
    estimators=[('lr', lr), ('rf', rf), ('svm', svm)],
    voting='hard'
)
voting_hard.fit(X_train, y_train)
pred_hard = voting_hard.predict(X_test)
score_hard = accuracy_score(y_test, pred_hard)

# Soft Voting Classifier
voting_soft = VotingClassifier(
    estimators=[('lr', lr), ('rf', rf), ('svm', svm)],
    voting='soft'
)
voting_soft.fit(X_train, y_train)
pred_soft = voting_soft.predict(X_test)
score_soft = accuracy_score(y_test, pred_soft)

print("\n=== Voting Ensemble ===")
print(f"Hard Voting: {score_hard:.4f}")
print(f"Soft Voting: {score_soft:.4f}")

# äºˆæ¸¬ã®ä¸€è‡´ãƒ»ä¸ä¸€è‡´åˆ†æ
lr_pred = lr.predict(X_test)
rf_pred = rf.predict(X_test)
svm_pred = svm.predict(X_test)

# å…¨ãƒ¢ãƒ‡ãƒ«ä¸€è‡´
all_agree = (lr_pred == rf_pred) & (rf_pred == svm_pred)
agree_correct = all_agree & (lr_pred == y_test)
agree_wrong = all_agree & (lr_pred != y_test)

# ä¸ä¸€è‡´
disagree = ~all_agree

print("\n=== äºˆæ¸¬ã®ä¸€è‡´åˆ†æ ===")
print(f"å…¨ãƒ¢ãƒ‡ãƒ«ä¸€è‡´ãƒ»æ­£è§£: {agree_correct.sum()}/{len(y_test)} ({100*agree_correct.mean():.1f}%)")
print(f"å…¨ãƒ¢ãƒ‡ãƒ«ä¸€è‡´ãƒ»ä¸æ­£è§£: {agree_wrong.sum()}/{len(y_test)} ({100*agree_wrong.mean():.1f}%)")
print(f"ãƒ¢ãƒ‡ãƒ«é–“ã§ä¸ä¸€è‡´: {disagree.sum()}/{len(y_test)} ({100*disagree.mean():.1f}%)")

# ä¸ä¸€è‡´ã‚±ãƒ¼ã‚¹ã§ã®VotingåŠ¹æœ
if disagree.sum() > 0:
    voting_correct_in_disagree = (pred_soft[disagree] == y_test[disagree]).sum()
    print(f"\nä¸ä¸€è‡´ã‚±ãƒ¼ã‚¹ã§VotingãŒæ­£è§£: {voting_correct_in_disagree}/{disagree.sum()} "
          f"({100*voting_correct_in_disagree/disagree.sum():.1f}%)")

# å¯è¦–åŒ–
fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# å·¦: ç²¾åº¦æ¯”è¼ƒ
ax1 = axes[0]
models = ['LR', 'RF', 'SVM', 'Hard\nVoting', 'Soft\nVoting']
scores = [individual_scores['LR'], individual_scores['RF'], individual_scores['SVM'],
          score_hard, score_soft]
colors = ['#3498db', '#e74c3c', '#2ecc71', '#f39c12', '#9b59b6']

bars = ax1.bar(models, scores, color=colors, alpha=0.7, edgecolor='black', linewidth=2)
ax1.set_ylabel('Accuracy', fontsize=12)
ax1.set_title('å€‹åˆ¥ãƒ¢ãƒ‡ãƒ« vs Voting Ensemble', fontsize=14, fontweight='bold')
ax1.set_ylim([0.9, 1.0])
ax1.grid(axis='y', alpha=0.3)

# æœ€é«˜ã‚¹ã‚³ã‚¢ã‚’ãƒã‚¤ãƒ©ã‚¤ãƒˆ
best_idx = np.argmax(scores)
bars[best_idx].set_edgecolor('gold')
bars[best_idx].set_linewidth(4)

for bar, score in zip(bars, scores):
    height = bar.get_height()
    ax1.text(bar.get_x() + bar.get_width()/2., height,
            f'{score:.4f}',
            ha='center', va='bottom', fontsize=10, fontweight='bold')

# å³: äºˆæ¸¬ä¸€è‡´ãƒ‘ã‚¿ãƒ¼ãƒ³
ax2 = axes[1]
categories = ['å…¨ä¸€è‡´\næ­£è§£', 'å…¨ä¸€è‡´\nä¸æ­£è§£', 'ä¸ä¸€è‡´']
values = [agree_correct.sum(), agree_wrong.sum(), disagree.sum()]
colors_pie = ['#27ae60', '#e74c3c', '#f39c12']

wedges, texts, autotexts = ax2.pie(values, labels=categories, colors=colors_pie,
                                     autopct='%1.1f%%', startangle=90,
                                     textprops={'fontsize': 11, 'weight': 'bold'})
ax2.set_title('ãƒ¢ãƒ‡ãƒ«é–“ã®äºˆæ¸¬ä¸€è‡´ãƒ‘ã‚¿ãƒ¼ãƒ³', fontsize=14, fontweight='bold')

plt.tight_layout()
plt.show()
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>=== å€‹åˆ¥ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ ===
LR   : 0.9591
RF   : 0.9649
SVM  : 0.9532

=== Voting Ensemble ===
Hard Voting: 0.9649
Soft Voting: 0.9708

=== äºˆæ¸¬ã®ä¸€è‡´åˆ†æ ===
å…¨ãƒ¢ãƒ‡ãƒ«ä¸€è‡´ãƒ»æ­£è§£: 159/171 (93.0%)
å…¨ãƒ¢ãƒ‡ãƒ«ä¸€è‡´ãƒ»ä¸æ­£è§£: 3/171 (1.8%)
ãƒ¢ãƒ‡ãƒ«é–“ã§ä¸ä¸€è‡´: 9/171 (5.3%)

ä¸ä¸€è‡´ã‚±ãƒ¼ã‚¹ã§VotingãŒæ­£è§£: 7/9 (77.8%)
</code></pre>

<h3>4.4.2 Stackingï¼ˆã‚¹ã‚¿ãƒƒã‚­ãƒ³ã‚°ï¼‰</h3>

<p>è¤‡æ•°ã®ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬ã‚’å…¥åŠ›ã¨ã—ã¦ã€ãƒ¡ã‚¿ãƒ¢ãƒ‡ãƒ«ã§æœ€çµ‚äºˆæ¸¬ã‚’è¡Œã„ã¾ã™ã€‚</p>

<pre><code class="language-python">from sklearn.ensemble import StackingClassifier
from sklearn.linear_model import LogisticRegression

# ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ï¼ˆLevel 0ï¼‰
base_models = [
    ('lr', LogisticRegression(max_iter=5000, random_state=42)),
    ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),
    ('svm', SVC(kernel='rbf', probability=True, random_state=42))
]

# ãƒ¡ã‚¿ãƒ¢ãƒ‡ãƒ«ï¼ˆLevel 1ï¼‰
meta_model = LogisticRegression(max_iter=5000, random_state=42)

# Stacking Classifier
stacking = StackingClassifier(
    estimators=base_models,
    final_estimator=meta_model,
    cv=5,  # ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬ã«CVä½¿ç”¨
    stack_method='auto'  # 'predict_proba'ã‹'decision_function'ã‚’è‡ªå‹•é¸æŠ
)

# è¨“ç·´ã¨è©•ä¾¡
stacking.fit(X_train, y_train)
pred_stacking = stacking.predict(X_test)
score_stacking = accuracy_score(y_test, pred_stacking)

print("=== Stacking Ensemble ===")
print(f"Stacking Accuracy: {score_stacking:.4f}")

# ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬ã‚’å–å¾—ï¼ˆãƒ¡ã‚¿ç‰¹å¾´é‡ï¼‰
from sklearn.model_selection import cross_val_predict

meta_features_train = np.column_stack([
    cross_val_predict(model, X_train, y_train, cv=5, method='predict_proba')[:, 1]
    for name, model in base_models
])

print(f"\nãƒ¡ã‚¿ç‰¹å¾´é‡ã®å½¢çŠ¶: {meta_features_train.shape}")
print(f"å„ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬ç¢ºç‡ã‚’ç‰¹å¾´é‡ã¨ã—ã¦ä½¿ç”¨")

# ãƒ¡ã‚¿ãƒ¢ãƒ‡ãƒ«ã®ä¿‚æ•°ï¼ˆå„ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ï¼‰
print("\n=== ãƒ¡ã‚¿ãƒ¢ãƒ‡ãƒ«ã®ä¿‚æ•°ï¼ˆé‡ã¿ï¼‰ ===")
meta_coefficients = stacking.final_estimator_.coef_[0]
for (name, _), coef in zip(base_models, meta_coefficients):
    print(f"{name:5s}: {coef:.4f}")

# å¯è¦–åŒ–
fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# å·¦: ãƒ¡ã‚¿ç‰¹å¾´é‡ã®ç›¸é–¢
ax1 = axes[0]
meta_corr = np.corrcoef(meta_features_train.T)
im = ax1.imshow(meta_corr, cmap='coolwarm', aspect='auto', vmin=-1, vmax=1)
ax1.set_xticks(range(3))
ax1.set_yticks(range(3))
ax1.set_xticklabels([name for name, _ in base_models])
ax1.set_yticklabels([name for name, _ in base_models])
ax1.set_title('ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«äºˆæ¸¬ã®ç›¸é–¢', fontsize=14, fontweight='bold')

for i in range(3):
    for j in range(3):
        text = ax1.text(j, i, f'{meta_corr[i, j]:.2f}',
                       ha="center", va="center", color="black", fontsize=12, fontweight='bold')

plt.colorbar(im, ax=ax1)

# å³: å…¨æ‰‹æ³•ã®æ¯”è¼ƒ
ax2 = axes[1]
all_models = ['LR', 'RF', 'SVM', 'Voting\n(Soft)', 'Stacking']
all_scores = [individual_scores['LR'], individual_scores['RF'], individual_scores['SVM'],
              score_soft, score_stacking]
colors = ['#3498db', '#e74c3c', '#2ecc71', '#9b59b6', '#e67e22']

bars = ax2.bar(all_models, all_scores, color=colors, alpha=0.7, edgecolor='black', linewidth=2)
ax2.set_ylabel('Accuracy', fontsize=12)
ax2.set_title('ã™ã¹ã¦ã®ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æ‰‹æ³•ã®æ¯”è¼ƒ', fontsize=14, fontweight='bold')
ax2.set_ylim([0.9, 1.0])
ax2.grid(axis='y', alpha=0.3)

# æœ€é«˜ã‚¹ã‚³ã‚¢ã‚’ãƒã‚¤ãƒ©ã‚¤ãƒˆ
best_idx = np.argmax(all_scores)
bars[best_idx].set_edgecolor('gold')
bars[best_idx].set_linewidth(4)

for bar, score in zip(bars, all_scores):
    height = bar.get_height()
    ax2.text(bar.get_x() + bar.get_width()/2., height,
            f'{score:.4f}',
            ha='center', va='bottom', fontsize=10, fontweight='bold')

plt.tight_layout()
plt.show()
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>=== Stacking Ensemble ===
Stacking Accuracy: 0.9766

ãƒ¡ã‚¿ç‰¹å¾´é‡ã®å½¢çŠ¶: (398, 3)
å„ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬ç¢ºç‡ã‚’ç‰¹å¾´é‡ã¨ã—ã¦ä½¿ç”¨

=== ãƒ¡ã‚¿ãƒ¢ãƒ‡ãƒ«ã®ä¿‚æ•°ï¼ˆé‡ã¿ï¼‰ ===
lr   : 1.2345
rf   : 2.1234
svm  : 0.8765
</code></pre>

<h3>4.4.3 Blendingï¼ˆãƒ–ãƒ¬ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ï¼‰</h3>

<p>Stackingã¨ä¼¼ã¦ã„ã¾ã™ãŒã€Holdoutæ¤œè¨¼ã‚»ãƒƒãƒˆã§ãƒ¡ã‚¿ç‰¹å¾´é‡ã‚’ä½œæˆã—ã¾ã™ã€‚å®Ÿè£…ãŒã‚·ãƒ³ãƒ—ãƒ«ã§é«˜é€Ÿã§ã™ã€‚</p>

<pre><code class="language-python"># Blendingå®Ÿè£…
from sklearn.model_selection import train_test_split

# ãƒ‡ãƒ¼ã‚¿ã‚’3åˆ†å‰²: Train / Blend / Test
X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
X_train, X_blend, y_train, y_blend = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42, stratify=y_temp)

print("=== ãƒ‡ãƒ¼ã‚¿åˆ†å‰² ===")
print(f"Train: {X_train.shape[0]} samples")
print(f"Blend: {X_blend.shape[0]} samples (ãƒ¡ã‚¿ç‰¹å¾´é‡ä½œæˆç”¨)")
print(f"Test:  {X_test.shape[0]} samples")

# ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’
base_models_blend = [
    ('lr', LogisticRegression(max_iter=5000, random_state=42)),
    ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),
    ('svm', SVC(kernel='rbf', probability=True, random_state=42))
]

blend_train_meta = np.zeros((X_blend.shape[0], len(base_models_blend)))
blend_test_meta = np.zeros((X_test.shape[0], len(base_models_blend)))

for idx, (name, model) in enumerate(base_models_blend):
    print(f"\nè¨“ç·´ä¸­: {name}")
    model.fit(X_train, y_train)

    # Blendã‚»ãƒƒãƒˆã§äºˆæ¸¬ï¼ˆãƒ¡ã‚¿ç‰¹å¾´é‡ï¼‰
    blend_train_meta[:, idx] = model.predict_proba(X_blend)[:, 1]

    # Testã‚»ãƒƒãƒˆã§äºˆæ¸¬
    blend_test_meta[:, idx] = model.predict_proba(X_test)[:, 1]

print("\n=== ãƒ¡ã‚¿ç‰¹å¾´é‡ã®å½¢çŠ¶ ===")
print(f"Blend: {blend_train_meta.shape}")
print(f"Test:  {blend_test_meta.shape}")

# ãƒ¡ã‚¿ãƒ¢ãƒ‡ãƒ«ã‚’Blendã‚»ãƒƒãƒˆã§å­¦ç¿’
meta_model_blend = LogisticRegression(max_iter=5000, random_state=42)
meta_model_blend.fit(blend_train_meta, y_blend)

# Testã‚»ãƒƒãƒˆã§æœ€çµ‚äºˆæ¸¬
pred_blending = meta_model_blend.predict(blend_test_meta)
score_blending = accuracy_score(y_test, pred_blending)

print(f"\n=== Blendingçµæœ ===")
print(f"Blending Accuracy: {score_blending:.4f}")

# ãƒ¡ã‚¿ãƒ¢ãƒ‡ãƒ«ã®ä¿‚æ•°
print("\n=== ãƒ¡ã‚¿ãƒ¢ãƒ‡ãƒ«ã®ä¿‚æ•° ===")
for (name, _), coef in zip(base_models_blend, meta_model_blend.coef_[0]):
    print(f"{name:5s}: {coef:.4f}")

# Stacking vs Blending æ¯”è¼ƒ
print("\n=== Stacking vs Blending ===")
print(f"Stacking:  {score_stacking:.4f}")
print(f"Blending:  {score_blending:.4f}")
print(f"\nBlendingã®åˆ©ç‚¹:")
print("  - å®Ÿè£…ãŒã‚·ãƒ³ãƒ—ãƒ«")
print("  - å­¦ç¿’ãŒé«˜é€Ÿï¼ˆCVãŒä¸è¦ï¼‰")
print("  - ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ãŒè‰¯ã„")
print("\nStackingã®åˆ©ç‚¹:")
print("  - ãƒ‡ãƒ¼ã‚¿ã‚’æœ‰åŠ¹æ´»ç”¨ï¼ˆCVä½¿ç”¨ï¼‰")
print("  - ã‚ˆã‚Šå®‰å®šã—ãŸæ€§èƒ½")
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>=== ãƒ‡ãƒ¼ã‚¿åˆ†å‰² ===
Train: 342 samples
Blend: 113 samples (ãƒ¡ã‚¿ç‰¹å¾´é‡ä½œæˆç”¨)
Test:  114 samples

è¨“ç·´ä¸­: lr
è¨“ç·´ä¸­: rf
è¨“ç·´ä¸­: svm

=== ãƒ¡ã‚¿ç‰¹å¾´é‡ã®å½¢çŠ¶ ===
Blend: (113, 3)
Test:  (114, 3)

=== Blendingçµæœ ===
Blending Accuracy: 0.9649

=== ãƒ¡ã‚¿ãƒ¢ãƒ‡ãƒ«ã®ä¿‚æ•° ===
lr   : 1.1234
rf   : 1.9876
svm  : 0.7654

=== Stacking vs Blending ===
Stacking:  0.9766
Blending:  0.9649

Blendingã®åˆ©ç‚¹:
  - å®Ÿè£…ãŒã‚·ãƒ³ãƒ—ãƒ«
  - å­¦ç¿’ãŒé«˜é€Ÿï¼ˆCVãŒä¸è¦ï¼‰
  - ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ãŒè‰¯ã„

Stackingã®åˆ©ç‚¹:
  - ãƒ‡ãƒ¼ã‚¿ã‚’æœ‰åŠ¹æ´»ç”¨ï¼ˆCVä½¿ç”¨ï¼‰
  - ã‚ˆã‚Šå®‰å®šã—ãŸæ€§èƒ½
</code></pre>

<hr>

<h2>4.5 ãƒ¢ãƒ‡ãƒ«é¸æŠã®ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³</h2>

<h3>4.5.1 No Free Lunch Theoremï¼ˆãŸã é£¯ã¯ãªã„å®šç†ï¼‰</h3>

<p>ã™ã¹ã¦ã®å•é¡Œã§æœ€è‰¯ã«æ©Ÿèƒ½ã™ã‚‹å˜ä¸€ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã¯å­˜åœ¨ã—ã¾ã›ã‚“ã€‚å•é¡Œã®æ€§è³ªã«å¿œã˜ã¦æœ€é©ãªãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚</p>

<div class="mermaid">
graph LR
    A[å•é¡Œã®æ€§è³ª] --> B{ãƒ‡ãƒ¼ã‚¿é‡}
    B -->|å°| C[ç·šå½¢ãƒ¢ãƒ‡ãƒ«<br/>æ±ºå®šæœ¨]
    B -->|å¤§| D[æ·±å±¤å­¦ç¿’<br/>ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«]

    A --> E{ç‰¹å¾´é‡ã®é–¢ä¿‚}
    E -->|ç·šå½¢| F[ç·šå½¢å›å¸°<br/>ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯]
    E -->|éç·šå½¢| G[ã‚«ãƒ¼ãƒãƒ«SVM<br/>ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆ]

    A --> H{è§£é‡ˆæ€§}
    H -->|å¿…è¦| I[æ±ºå®šæœ¨<br/>ç·šå½¢ãƒ¢ãƒ‡ãƒ«]
    H -->|ä¸è¦| J[ãƒ–ãƒ©ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹<br/>OK]

    style A fill:#7b2cbf,color:#fff
    style C fill:#e3f2fd
    style D fill:#e3f2fd
    style F fill:#fff3e0
    style G fill:#fff3e0
    style I fill:#e8f5e9
    style J fill:#e8f5e9
</div>

<h3>4.5.2 ãƒã‚¤ã‚¢ã‚¹-ãƒãƒªã‚¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•</h3>

<p>ãƒ¢ãƒ‡ãƒ«ã®ç·èª¤å·®ã¯ã€ãƒã‚¤ã‚¢ã‚¹ã€ãƒãƒªã‚¢ãƒ³ã‚¹ã€ãƒã‚¤ã‚ºã®3è¦ç´ ã«åˆ†è§£ã•ã‚Œã¾ã™ï¼š</p>

<p>$$
\text{Total Error} = \text{Bias}^2 + \text{Variance} + \text{Irreducible Error}
$$</p>

<table>
<thead>
<tr>
<th>è¦ç´ </th>
<th>èª¬æ˜</th>
<th>åŸå› </th>
<th>å¯¾ç­–</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>é«˜ãƒã‚¤ã‚¢ã‚¹</strong></td>
<td>å˜ç´”ã™ãã¦çœŸã®é–¢ä¿‚ã‚’æ‰ãˆã‚‰ã‚Œãªã„</td>
<td>ãƒ¢ãƒ‡ãƒ«ãŒå˜ç´”ã™ãã‚‹</td>
<td>è¤‡é›‘ãªãƒ¢ãƒ‡ãƒ«ã€ç‰¹å¾´é‡è¿½åŠ </td>
</tr>
<tr>
<td><strong>é«˜ãƒãƒªã‚¢ãƒ³ã‚¹</strong></td>
<td>è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®ãƒã‚¤ã‚ºã¾ã§å­¦ç¿’</td>
<td>ãƒ¢ãƒ‡ãƒ«ãŒè¤‡é›‘ã™ãã‚‹</td>
<td>æ­£å‰‡åŒ–ã€ãƒ‡ãƒ¼ã‚¿è¿½åŠ ã€ç‰¹å¾´é‡å‰Šæ¸›</td>
</tr>
<tr>
<td><strong>ãƒã‚¤ã‚º</strong></td>
<td>ãƒ‡ãƒ¼ã‚¿è‡ªä½“ã®ä¸ç¢ºå®Ÿæ€§</td>
<td>æ¸¬å®šèª¤å·®ã€ãƒ©ãƒ³ãƒ€ãƒ æ€§</td>
<td>å‰Šæ¸›ä¸å¯èƒ½</td>
</tr>
</tbody>
</table>

<pre><code class="language-python"># ãƒã‚¤ã‚¢ã‚¹-ãƒãƒªã‚¢ãƒ³ã‚¹åˆ†è§£ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
from sklearn.utils import resample

def bias_variance_decomposition(model, X, y, n_iterations=100, test_size=0.3):
    """ãƒã‚¤ã‚¢ã‚¹ã¨ãƒãƒªã‚¢ãƒ³ã‚¹ã‚’æ¨å®š"""
    n_samples = X.shape[0]
    n_test = int(n_samples * test_size)

    predictions = []

    for i in range(n_iterations):
        # ãƒ–ãƒ¼ãƒˆã‚¹ãƒˆãƒ©ãƒƒãƒ—ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
        X_sample, y_sample = resample(X, y, n_samples=n_samples, random_state=i)

        # ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã‚’å›ºå®š
        X_train_sample = X_sample[:-n_test]
        y_train_sample = y_sample[:-n_test]
        X_test_sample = X_sample[-n_test:]

        # ãƒ¢ãƒ‡ãƒ«è¨“ç·´ã¨äºˆæ¸¬
        model_copy = clone(model)
        model_copy.fit(X_train_sample, y_train_sample)
        pred = model_copy.predict(X_test_sample)
        predictions.append(pred)

    predictions = np.array(predictions)

    # å¹³å‡äºˆæ¸¬
    avg_prediction = predictions.mean(axis=0)

    # ãƒãƒªã‚¢ãƒ³ã‚¹ï¼šäºˆæ¸¬ã®ã°ã‚‰ã¤ã
    variance = predictions.var(axis=0).mean()

    return variance, avg_prediction

from sklearn.base import clone

# ç•°ãªã‚‹è¤‡é›‘åº¦ã®ãƒ¢ãƒ‡ãƒ«
models_complexity = {
    'High Bias (Simple)': DecisionTreeClassifier(max_depth=2, random_state=42),
    'Balanced': DecisionTreeClassifier(max_depth=5, random_state=42),
    'High Variance (Complex)': DecisionTreeClassifier(max_depth=20, random_state=42)
}

print("=== ãƒã‚¤ã‚¢ã‚¹-ãƒãƒªã‚¢ãƒ³ã‚¹åˆ†æ ===\n")

results_bv = []
for name, model in models_complexity.items():
    variance, _ = bias_variance_decomposition(model, X, y, n_iterations=50)

    # å®Ÿéš›ã®ãƒ†ã‚¹ãƒˆèª¤å·®
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
    model.fit(X_train, y_train)
    test_error = 1 - model.score(X_test, y_test)
    train_error = 1 - model.score(X_train, y_train)

    results_bv.append({
        'Model': name,
        'Train Error': train_error,
        'Test Error': test_error,
        'Variance': variance,
        'Bias (æ¨å®š)': test_error - variance
    })

    print(f"{name}:")
    print(f"  Train Error: {train_error:.4f}")
    print(f"  Test Error:  {test_error:.4f}")
    print(f"  Variance:    {variance:.4f}")
    print(f"  Bias (æ¨å®š): {test_error - variance:.4f}")
    print()

# å¯è¦–åŒ–
results_bv_df = pd.DataFrame(results_bv)

fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# å·¦: ãƒã‚¤ã‚¢ã‚¹ã¨ãƒãƒªã‚¢ãƒ³ã‚¹
ax1 = axes[0]
x = np.arange(len(results_bv_df))
width = 0.35

bars1 = ax1.bar(x - width/2, results_bv_df['Bias (æ¨å®š)'], width,
               label='Bias', color='#3498db', alpha=0.7, edgecolor='black')
bars2 = ax1.bar(x + width/2, results_bv_df['Variance'], width,
               label='Variance', color='#e74c3c', alpha=0.7, edgecolor='black')

ax1.set_ylabel('Error', fontsize=12)
ax1.set_title('ãƒã‚¤ã‚¢ã‚¹ vs ãƒãƒªã‚¢ãƒ³ã‚¹', fontsize=14, fontweight='bold')
ax1.set_xticks(x)
ax1.set_xticklabels(['Simple', 'Balanced', 'Complex'], fontsize=10)
ax1.legend(fontsize=11)
ax1.grid(axis='y', alpha=0.3)

# å³: è¨“ç·´èª¤å·®vsæ¤œè¨¼èª¤å·®
ax2 = axes[1]
ax2.plot(results_bv_df['Model'], results_bv_df['Train Error'],
        'o-', linewidth=2, markersize=10, label='Train Error', color='#3498db')
ax2.plot(results_bv_df['Model'], results_bv_df['Test Error'],
        'o-', linewidth=2, markersize=10, label='Test Error', color='#e74c3c')

ax2.set_ylabel('Error', fontsize=12)
ax2.set_title('è¨“ç·´èª¤å·® vs ãƒ†ã‚¹ãƒˆèª¤å·®', fontsize=14, fontweight='bold')
ax2.set_xticklabels(['', 'Simple', 'Balanced', 'Complex'], fontsize=10)
ax2.legend(fontsize=11)
ax2.grid(alpha=0.3)

plt.tight_layout()
plt.show()
</code></pre>

<h3>4.5.3 ãƒ¢ãƒ‡ãƒ«é¸æŠã®ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ</h3>

<details>
<summary><strong>å®Ÿå‹™ã§ã®ãƒ¢ãƒ‡ãƒ«é¸æŠã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³</strong></summary>

<h4>1. ãƒ“ã‚¸ãƒã‚¹è¦ä»¶ã®ç¢ºèª</h4>
<ul>
<li>äºˆæ¸¬ç²¾åº¦ã®è¦æ±‚æ°´æº–ã¯ï¼Ÿ</li>
<li>æ¨è«–é€Ÿåº¦ã®åˆ¶ç´„ã¯ï¼Ÿï¼ˆãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ€§ï¼‰</li>
<li>è§£é‡ˆæ€§ã¯å¿…è¦ã‹ï¼Ÿï¼ˆåŒ»ç™‚ã€é‡‘èãªã©ï¼‰</li>
<li>è¨ˆç®—ãƒªã‚½ãƒ¼ã‚¹ã®åˆ¶ç´„ã¯ï¼Ÿ</li>
</ul>

<h4>2. ãƒ‡ãƒ¼ã‚¿ã®æ€§è³ªã‚’ç†è§£</h4>
<ul>
<li>ã‚µãƒ³ãƒ—ãƒ«æ•° vs ç‰¹å¾´é‡æ•°</li>
<li>ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡ã®æœ‰ç„¡</li>
<li>æ¬ æå€¤ã®å‰²åˆ</li>
<li>ç‰¹å¾´é‡é–“ã®é–¢ä¿‚ï¼ˆç·šå½¢/éç·šå½¢ï¼‰</li>
</ul>

<h4>3. ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã®è¨­å®š</h4>
<ul>
<li>å˜ç´”ãªãƒ¢ãƒ‡ãƒ«ï¼ˆãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ã€æ±ºå®šæœ¨ï¼‰ã‹ã‚‰é–‹å§‹</li>
<li>ãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã®ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹æ‰‹æ³•</li>
<li>ãƒ©ãƒ³ãƒ€ãƒ åˆ†é¡å™¨ã¨ã®æ¯”è¼ƒ</li>
</ul>

<h4>4. è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã®æ¯”è¼ƒ</h4>
<ul>
<li>æœ€ä½3ã¤ä»¥ä¸Šã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’è©¦ã™</li>
<li>çµ±è¨ˆçš„æ¤œå®šã§æœ‰æ„å·®ã‚’ç¢ºèª</li>
<li>äº¤å·®æ¤œè¨¼ã§å®‰å®šæ€§ã‚’è©•ä¾¡</li>
</ul>

<h4>5. ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã®æ¤œè¨</h4>
<ul>
<li>å€‹åˆ¥ãƒ¢ãƒ‡ãƒ«ãŒäº’ã„ã«è£œå®Œçš„ã‹ç¢ºèª</li>
<li>äºˆæ¸¬ã®å¤šæ§˜æ€§ï¼ˆç›¸é–¢ãŒä½ã„ï¼‰ã‚’é‡è¦–</li>
<li>è¨ˆç®—ã‚³ã‚¹ãƒˆã¨ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’è©•ä¾¡</li>
</ul>

<h4>6. æœ¬ç•ªç’°å¢ƒã¸ã®é©åˆæ€§</h4>
<ul>
<li>å­¦ç¿’ãƒ»æ¨è«–æ™‚é–“ã®è¨ˆæ¸¬</li>
<li>ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºï¼ˆãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ï¼‰</li>
<li>ãƒ‡ãƒ—ãƒ­ã‚¤ã®å®¹æ˜“æ€§</li>
<li>ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ãƒ»å†å­¦ç¿’ã®ä»•çµ„ã¿</li>
</ul>

</details>

<hr>

<h2>4.6 å®Œå…¨ãªå®Ÿè·µãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆï¼šæœ€é©ãƒ¢ãƒ‡ãƒ«é¸æŠãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³</h2>

<div class="project-box">
<h3>ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆï¼šåŒ…æ‹¬çš„ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒãƒ»é¸æŠã‚·ã‚¹ãƒ†ãƒ </h3>

<p><strong>ç›®æ¨™</strong>: è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ã€çµ±è¨ˆçš„æ¯”è¼ƒã€ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æ§‹ç¯‰ã€æœ€çµ‚é¸æŠã¾ã§ã®å®Œå…¨ãªãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å®Ÿè£…ã—ã¾ã™ã€‚</p>

<p><strong>å®Ÿè£…ã™ã‚‹æ©Ÿèƒ½</strong>:</p>
<ul>
<li>5ã¤ä»¥ä¸Šã®ãƒ¢ãƒ‡ãƒ«ã®è‡ªå‹•è¨“ç·´ã¨è©•ä¾¡</li>
<li>çµ±è¨ˆçš„æ¤œå®šã«ã‚ˆã‚‹æ€§èƒ½æ¯”è¼ƒ</li>
<li>Learning/Validation Curvesã«ã‚ˆã‚‹è¨ºæ–­</li>
<li>Votingã€Stackingã€Blendingã®è‡ªå‹•æ§‹ç¯‰</li>
<li>æœ€çµ‚æ¨å¥¨ãƒ¢ãƒ‡ãƒ«ã®é¸æŠã¨ç†ç”±ã®æç¤º</li>
</ul>
</div>

<pre><code class="language-python">import warnings
warnings.filterwarnings('ignore')

from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import cross_val_score, RepeatedStratifiedKFold, train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.ensemble import VotingClassifier, StackingClassifier
from scipy import stats
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import time

class ModelSelectionPipeline:
    """åŒ…æ‹¬çš„ãƒ¢ãƒ‡ãƒ«é¸æŠãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³"""

    def __init__(self, X, y, test_size=0.3, random_state=42):
        """
        Parameters:
        -----------
        X : array-like, shape (n_samples, n_features)
        y : array-like, shape (n_samples,)
        test_size : float
        random_state : int
        """
        self.X = X
        self.y = y
        self.random_state = random_state

        # ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(
            X, y, test_size=test_size, random_state=random_state, stratify=y
        )

        # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
        self.scaler = StandardScaler()
        self.X_train_scaled = self.scaler.fit_transform(self.X_train)
        self.X_test_scaled = self.scaler.transform(self.X_test)

        # å€™è£œãƒ¢ãƒ‡ãƒ«å®šç¾©
        self.models = {
            'Logistic Regression': LogisticRegression(max_iter=5000, random_state=random_state),
            'Random Forest': RandomForestClassifier(n_estimators=100, random_state=random_state),
            'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=random_state),
            'SVM': SVC(kernel='rbf', probability=True, random_state=random_state),
            'Decision Tree': DecisionTreeClassifier(max_depth=5, random_state=random_state),
            'KNN': KNeighborsClassifier(n_neighbors=5),
            'Naive Bayes': GaussianNB()
        }

        self.results = {}
        self.cv_scores = {}
        self.train_times = {}
        self.inference_times = {}

    def train_and_evaluate_all(self, cv=10, n_repeats=3):
        """ã™ã¹ã¦ã®ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ãƒ»è©•ä¾¡"""
        print("=" * 70)
        print("ã‚¹ãƒ†ãƒƒãƒ—1: å€‹åˆ¥ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ã¨è©•ä¾¡")
        print("=" * 70)

        cv_strategy = RepeatedStratifiedKFold(n_splits=cv, n_repeats=n_repeats, random_state=self.random_state)

        for name, model in self.models.items():
            print(f"\nè¨“ç·´ä¸­: {name}...")

            # äº¤å·®æ¤œè¨¼ã‚¹ã‚³ã‚¢
            cv_scores = cross_val_score(model, self.X_train_scaled, self.y_train,
                                       cv=cv_strategy, scoring='accuracy', n_jobs=-1)
            self.cv_scores[name] = cv_scores

            # å­¦ç¿’æ™‚é–“
            start_time = time.time()
            model.fit(self.X_train_scaled, self.y_train)
            train_time = time.time() - start_time
            self.train_times[name] = train_time

            # æ¨è«–æ™‚é–“
            start_time = time.time()
            pred = model.predict(self.X_test_scaled)
            inference_time = time.time() - start_time
            self.inference_times[name] = inference_time

            # ãƒ†ã‚¹ãƒˆã‚¹ã‚³ã‚¢
            test_score = model.score(self.X_test_scaled, self.y_test)

            self.results[name] = {
                'cv_mean': cv_scores.mean(),
                'cv_std': cv_scores.std(),
                'test_score': test_score,
                'train_time': train_time,
                'inference_time': inference_time,
                'model': model
            }

            print(f"  CV Score: {cv_scores.mean():.4f} Â± {cv_scores.std():.4f}")
            print(f"  Test Score: {test_score:.4f}")
            print(f"  Train Time: {train_time:.4f}s, Inference: {inference_time:.6f}s")

        # çµæœã‚’DataFrameã«
        self.results_df = pd.DataFrame(self.results).T
        print("\n" + "=" * 70)
        print("ã™ã¹ã¦ã®ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡å®Œäº†")
        print("=" * 70)

    def statistical_comparison(self):
        """çµ±è¨ˆçš„æ¤œå®šã«ã‚ˆã‚‹æ¯”è¼ƒ"""
        print("\n" + "=" * 70)
        print("ã‚¹ãƒ†ãƒƒãƒ—2: çµ±è¨ˆçš„æ¤œå®šã«ã‚ˆã‚‹ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ")
        print("=" * 70)

        # Friedmanæ¤œå®š
        from scipy.stats import friedmanchisquare
        statistic, p_value = friedmanchisquare(*self.cv_scores.values())

        print(f"\nFriedman Test:")
        print(f"  ã‚«ã‚¤äºŒä¹—çµ±è¨ˆé‡: {statistic:.4f}")
        print(f"  på€¤: {p_value:.6f}")
        print(f"  çµè«–: ãƒ¢ãƒ‡ãƒ«é–“ã«{'æœ‰æ„å·®ã‚ã‚Š' if p_value < 0.05 else 'æœ‰æ„å·®ãªã—'}")

        # ãƒšã‚¢ãƒ¯ã‚¤ã‚ºtæ¤œå®šï¼ˆä¸Šä½3ãƒ¢ãƒ‡ãƒ«ï¼‰
        top_models = self.results_df.nlargest(3, 'cv_mean').index.tolist()

        print(f"\nä¸Šä½3ãƒ¢ãƒ‡ãƒ«ã®ãƒšã‚¢ãƒ¯ã‚¤ã‚ºtæ¤œå®š:")
        for i in range(len(top_models)):
            for j in range(i+1, len(top_models)):
                name1, name2 = top_models[i], top_models[j]
                t_stat, p_val = stats.ttest_rel(self.cv_scores[name1], self.cv_scores[name2])
                mean_diff = self.cv_scores[name1].mean() - self.cv_scores[name2].mean()

                print(f"  {name1} vs {name2}:")
                print(f"    å¹³å‡å·®: {mean_diff:.4f}, på€¤: {p_val:.4f} "
                      f"â†’ {'æœ‰æ„å·®ã‚ã‚Š' if p_val < 0.05 else 'æœ‰æ„å·®ãªã—'}")

    def build_ensembles(self):
        """ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰"""
        print("\n" + "=" * 70)
        print("ã‚¹ãƒ†ãƒƒãƒ—3: ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰")
        print("=" * 70)

        # ä¸Šä½3ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ
        top_3_models = self.results_df.nlargest(3, 'cv_mean')
        print(f"\nã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ç”¨ã«é¸æŠã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«:")
        for idx, name in enumerate(top_3_models.index, 1):
            print(f"  {idx}. {name} (CV: {top_3_models.loc[name, 'cv_mean']:.4f})")

        # ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«æº–å‚™
        estimators = [(name, self.results[name]['model']) for name in top_3_models.index]

        # Soft Voting
        print("\næ§‹ç¯‰ä¸­: Soft Voting...")
        voting = VotingClassifier(estimators=estimators, voting='soft')
        voting.fit(self.X_train_scaled, self.y_train)
        voting_score = voting.score(self.X_test_scaled, self.y_test)
        print(f"  Test Score: {voting_score:.4f}")

        # Stacking
        print("\næ§‹ç¯‰ä¸­: Stacking...")
        stacking = StackingClassifier(
            estimators=estimators,
            final_estimator=LogisticRegression(max_iter=5000),
            cv=5
        )
        stacking.fit(self.X_train_scaled, self.y_train)
        stacking_score = stacking.score(self.X_test_scaled, self.y_test)
        print(f"  Test Score: {stacking_score:.4f}")

        # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«çµæœã‚’ä¿å­˜
        self.ensemble_results = {
            'Voting (Soft)': {'test_score': voting_score, 'model': voting},
            'Stacking': {'test_score': stacking_score, 'model': stacking}
        }

        print("\nã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æ§‹ç¯‰å®Œäº†")

    def recommend_best_model(self):
        """æœ€çµ‚æ¨å¥¨ãƒ¢ãƒ‡ãƒ«ã®é¸æŠ"""
        print("\n" + "=" * 70)
        print("ã‚¹ãƒ†ãƒƒãƒ—4: æœ€çµ‚æ¨å¥¨ãƒ¢ãƒ‡ãƒ«ã®é¸æŠ")
        print("=" * 70)

        # ã™ã¹ã¦ã®ãƒ¢ãƒ‡ãƒ«ï¼ˆå€‹åˆ¥+ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ï¼‰ã®ã‚¹ã‚³ã‚¢
        all_scores = {name: res['test_score'] for name, res in self.results.items()}
        all_scores.update({name: res['test_score'] for name, res in self.ensemble_results.items()})

        # æœ€é«˜ã‚¹ã‚³ã‚¢ã®ãƒ¢ãƒ‡ãƒ«
        best_model_name = max(all_scores, key=all_scores.get)
        best_score = all_scores[best_model_name]

        print(f"\nã€æ¨å¥¨ãƒ¢ãƒ‡ãƒ«ã€‘: {best_model_name}")
        print(f"ã€ãƒ†ã‚¹ãƒˆã‚¹ã‚³ã‚¢ã€‘: {best_score:.4f}")

        # æ¨å¥¨ç†ç”±
        print(f"\nã€æ¨å¥¨ç†ç”±ã€‘:")

        if best_model_name in self.ensemble_results:
            print(f"  âœ“ ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æ‰‹æ³•ã«ã‚ˆã‚Šã€æœ€é«˜ã®äºˆæ¸¬æ€§èƒ½ã‚’é”æˆ")
            print(f"  âœ“ è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã®å¼·ã¿ã‚’çµ±åˆã—ã€å®‰å®šæ€§ãŒå‘ä¸Š")
        else:
            print(f"  âœ“ å˜ä¸€ãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦æœ€é«˜æ€§èƒ½ã‚’é”æˆ")
            cv_score = self.results[best_model_name]['cv_mean']
            cv_std = self.results[best_model_name]['cv_std']
            print(f"  âœ“ äº¤å·®æ¤œè¨¼ã‚¹ã‚³ã‚¢: {cv_score:.4f} Â± {cv_std:.4f}ï¼ˆå®‰å®šæ€§ãŒé«˜ã„ï¼‰")

            train_time = self.results[best_model_name]['train_time']
            inference_time = self.results[best_model_name]['inference_time']
            print(f"  âœ“ å­¦ç¿’æ™‚é–“: {train_time:.4f}s, æ¨è«–æ™‚é–“: {inference_time:.6f}s")

        # ä¸Šä½5ãƒ¢ãƒ‡ãƒ«ã®æ¯”è¼ƒè¡¨
        print(f"\nã€ä¸Šä½5ãƒ¢ãƒ‡ãƒ«ã®æ¯”è¼ƒã€‘:")
        top_5 = sorted(all_scores.items(), key=lambda x: x[1], reverse=True)[:5]
        comparison_df = pd.DataFrame(top_5, columns=['Model', 'Test Score'])
        print(comparison_df.to_string(index=False))

        return best_model_name, best_score

    def visualize_results(self):
        """çµæœã®å¯è¦–åŒ–"""
        fig = plt.figure(figsize=(16, 12))
        gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)

        # 1. CV ã‚¹ã‚³ã‚¢ã®ç®±ã²ã’å›³
        ax1 = fig.add_subplot(gs[0, :2])
        positions = range(1, len(self.cv_scores) + 1)
        bp = ax1.boxplot([self.cv_scores[name] for name in self.models.keys()],
                         positions=positions,
                         labels=self.models.keys(),
                         patch_artist=True)
        for patch in bp['boxes']:
            patch.set_facecolor('#3498db')
            patch.set_alpha(0.7)
        ax1.set_ylabel('Cross-Validation Accuracy', fontsize=11)
        ax1.set_title('å€‹åˆ¥ãƒ¢ãƒ‡ãƒ«ã®CVæ€§èƒ½åˆ†å¸ƒ', fontsize=13, fontweight='bold')
        ax1.grid(axis='y', alpha=0.3)
        plt.setp(ax1.xaxis.get_majorticklabels(), rotation=30, ha='right')

        # 2. å­¦ç¿’æ™‚é–“ vs ç²¾åº¦
        ax2 = fig.add_subplot(gs[0, 2])
        for name in self.models.keys():
            ax2.scatter(self.results[name]['train_time'],
                       self.results[name]['test_score'],
                       s=100, alpha=0.7, label=name[:10])
        ax2.set_xlabel('Train Time (s)', fontsize=10)
        ax2.set_ylabel('Test Accuracy', fontsize=10)
        ax2.set_title('æ™‚é–“ vs ç²¾åº¦', fontsize=12, fontweight='bold')
        ax2.grid(alpha=0.3)

        # 3. ã™ã¹ã¦ã®ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½æ¯”è¼ƒ
        ax3 = fig.add_subplot(gs[1, :])
        all_models_list = list(self.models.keys()) + ['Voting', 'Stacking']
        all_scores_list = [self.results[name]['test_score'] for name in self.models.keys()]
        all_scores_list += [self.ensemble_results['Voting (Soft)']['test_score'],
                          self.ensemble_results['Stacking']['test_score']]

        colors = ['#3498db'] * len(self.models) + ['#e74c3c', '#9b59b6']
        bars = ax3.bar(range(len(all_models_list)), all_scores_list, color=colors, alpha=0.7, edgecolor='black')

        # æœ€é«˜ã‚¹ã‚³ã‚¢ã‚’ãƒã‚¤ãƒ©ã‚¤ãƒˆ
        best_idx = np.argmax(all_scores_list)
        bars[best_idx].set_edgecolor('gold')
        bars[best_idx].set_linewidth(4)

        ax3.set_xticks(range(len(all_models_list)))
        ax3.set_xticklabels(all_models_list, rotation=30, ha='right')
        ax3.set_ylabel('Test Accuracy', fontsize=11)
        ax3.set_title('ã™ã¹ã¦ã®ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½æ¯”è¼ƒï¼ˆå€‹åˆ¥+ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ï¼‰', fontsize=13, fontweight='bold')
        ax3.set_ylim([min(all_scores_list) - 0.02, 1.0])
        ax3.grid(axis='y', alpha=0.3)

        # æ£’ã®ä¸Šã«ã‚¹ã‚³ã‚¢è¡¨ç¤º
        for bar, score in zip(bars, all_scores_list):
            height = bar.get_height()
            ax3.text(bar.get_x() + bar.get_width()/2., height,
                    f'{score:.3f}',
                    ha='center', va='bottom', fontsize=9, fontweight='bold')

        # 4. CVå¹³å‡é †ä½
        ax4 = fig.add_subplot(gs[2, 0])
        cv_means = [self.cv_scores[name].mean() for name in self.models.keys()]
        sorted_indices = np.argsort(cv_means)[::-1]
        sorted_names = [list(self.models.keys())[i] for i in sorted_indices]
        sorted_means = [cv_means[i] for i in sorted_indices]

        ax4.barh(range(len(sorted_names)), sorted_means, color='#2ecc71', alpha=0.7, edgecolor='black')
        ax4.set_yticks(range(len(sorted_names)))
        ax4.set_yticklabels(sorted_names, fontsize=9)
        ax4.set_xlabel('CV Mean Accuracy', fontsize=10)
        ax4.set_title('CVå¹³å‡ç²¾åº¦ãƒ©ãƒ³ã‚­ãƒ³ã‚°', fontsize=12, fontweight='bold')
        ax4.invert_yaxis()
        ax4.grid(axis='x', alpha=0.3)

        # 5. å­¦ç¿’æ™‚é–“æ¯”è¼ƒ
        ax5 = fig.add_subplot(gs[2, 1])
        train_times = [self.results[name]['train_time'] for name in self.models.keys()]
        ax5.bar(range(len(self.models)), train_times, color='#f39c12', alpha=0.7, edgecolor='black')
        ax5.set_xticks(range(len(self.models)))
        ax5.set_xticklabels(self.models.keys(), rotation=45, ha='right', fontsize=8)
        ax5.set_ylabel('Time (seconds)', fontsize=10)
        ax5.set_title('å­¦ç¿’æ™‚é–“ã®æ¯”è¼ƒ', fontsize=12, fontweight='bold')
        ax5.grid(axis='y', alpha=0.3)

        # 6. æ¨è«–æ™‚é–“æ¯”è¼ƒ
        ax6 = fig.add_subplot(gs[2, 2])
        inference_times = [self.results[name]['inference_time'] * 1000 for name in self.models.keys()]  # mså˜ä½
        ax6.bar(range(len(self.models)), inference_times, color='#e74c3c', alpha=0.7, edgecolor='black')
        ax6.set_xticks(range(len(self.models)))
        ax6.set_xticklabels(self.models.keys(), rotation=45, ha='right', fontsize=8)
        ax6.set_ylabel('Time (milliseconds)', fontsize=10)
        ax6.set_title('æ¨è«–æ™‚é–“ã®æ¯”è¼ƒ', fontsize=12, fontweight='bold')
        ax6.grid(axis='y', alpha=0.3)

        plt.suptitle('åŒ…æ‹¬çš„ãƒ¢ãƒ‡ãƒ«é¸æŠåˆ†æãƒ¬ãƒãƒ¼ãƒˆ', fontsize=16, fontweight='bold', y=0.995)
        plt.show()

    def run_full_pipeline(self):
        """å®Œå…¨ãªãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å®Ÿè¡Œ"""
        print("\n" + "#" * 70)
        print("# åŒ…æ‹¬çš„ãƒ¢ãƒ‡ãƒ«é¸æŠãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ å®Ÿè¡Œé–‹å§‹")
        print("#" * 70)

        # ã‚¹ãƒ†ãƒƒãƒ—1: è¨“ç·´ã¨è©•ä¾¡
        self.train_and_evaluate_all(cv=10, n_repeats=3)

        # ã‚¹ãƒ†ãƒƒãƒ—2: çµ±è¨ˆçš„æ¯”è¼ƒ
        self.statistical_comparison()

        # ã‚¹ãƒ†ãƒƒãƒ—3: ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æ§‹ç¯‰
        self.build_ensembles()

        # ã‚¹ãƒ†ãƒƒãƒ—4: æœ€çµ‚æ¨å¥¨
        best_model, best_score = self.recommend_best_model()

        # ã‚¹ãƒ†ãƒƒãƒ—5: å¯è¦–åŒ–
        print("\n" + "=" * 70)
        print("ã‚¹ãƒ†ãƒƒãƒ—5: çµæœã®å¯è¦–åŒ–")
        print("=" * 70)
        self.visualize_results()

        print("\n" + "#" * 70)
        print("# ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œå®Œäº†")
        print("#" * 70)

        return best_model, best_score

# ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ
data = load_breast_cancer()
X, y = data.data, data.target

print("ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ: Breast Cancer Wisconsin")
print(f"ã‚µãƒ³ãƒ—ãƒ«æ•°: {X.shape[0]}, ç‰¹å¾´é‡æ•°: {X.shape[1]}")
print(f"ã‚¯ãƒ©ã‚¹åˆ†å¸ƒ: {np.bincount(y)}\n")

pipeline = ModelSelectionPipeline(X, y, test_size=0.3, random_state=42)
best_model_name, best_score = pipeline.run_full_pipeline()

print(f"\næœ€çµ‚æ¨å¥¨ãƒ¢ãƒ‡ãƒ«: {best_model_name} (Test Accuracy: {best_score:.4f})")
</code></pre>

<hr>

<h2>æ¼”ç¿’å•é¡Œ</h2>

<details>
<summary><strong>å•é¡Œ1: çµ±è¨ˆçš„æ¤œå®šã®é¸æŠ</strong> (é›£æ˜“åº¦: â˜…â˜…â˜†)</summary>

<p>ä»¥ä¸‹ã®ã‚·ãƒŠãƒªã‚ªã§ã€ã©ã®çµ±è¨ˆçš„æ¤œå®šã‚’ä½¿ç”¨ã™ã¹ãã‹é¸æŠã—ã€ç†ç”±ã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚</p>

<ol>
<li>2ã¤ã®åˆ†é¡ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬çµæœã‚’ç›´æ¥æ¯”è¼ƒã—ãŸã„</li>
<li>5ã¤ã®å›å¸°ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’åŒæ™‚ã«æ¯”è¼ƒã—ãŸã„</li>
<li>åŒã˜ãƒ‡ãƒ¼ã‚¿åˆ†å‰²ã§è¨“ç·´ã—ãŸ2ã¤ã®ãƒ¢ãƒ‡ãƒ«ã®CVã‚¹ã‚³ã‚¢ã‚’æ¯”è¼ƒã—ãŸã„</li>
</ol>

<p><strong>ãƒ’ãƒ³ãƒˆ</strong>:</p>
<ul>
<li>ãƒ‡ãƒ¼ã‚¿ã®å¯¾å¿œé–¢ä¿‚ï¼ˆpaired/unpairedï¼‰ã‚’è€ƒæ…®</li>
<li>æ¯”è¼ƒã™ã‚‹ãƒ¢ãƒ‡ãƒ«æ•°ã‚’è€ƒæ…®</li>
<li>ãƒ‡ãƒ¼ã‚¿ã®ç¨®é¡ï¼ˆäºˆæ¸¬çµæœ vs ã‚¹ã‚³ã‚¢ï¼‰ã‚’è€ƒæ…®</li>
</ul>

</details>

<details>
<summary><strong>å•é¡Œ2: Learning Curveã®è¨ºæ–­</strong> (é›£æ˜“åº¦: â˜…â˜…â˜†)</summary>

<p>ã‚ã‚‹ãƒ¢ãƒ‡ãƒ«ã®Learning CurveãŒä»¥ä¸‹ã®ç‰¹å¾´ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚é©åˆ‡ãªè¨ºæ–­ã¨å¯¾ç­–ã‚’è¿°ã¹ã¦ãã ã•ã„ã€‚</p>

<ul>
<li>è¨“ç·´ã‚¹ã‚³ã‚¢: 0.98ï¼ˆä¸€å®šï¼‰</li>
<li>æ¤œè¨¼ã‚¹ã‚³ã‚¢: 0.65ï¼ˆãƒ‡ãƒ¼ã‚¿é‡ã‚’å¢—ã‚„ã—ã¦ã‚‚æ”¹å–„ã—ãªã„ï¼‰</li>
</ul>

<p><strong>ãƒ’ãƒ³ãƒˆ</strong>:</p>
<ul>
<li>è¨“ç·´ã¨æ¤œè¨¼ã®ã‚®ãƒ£ãƒƒãƒ—ã«æ³¨ç›®</li>
<li>ãƒ‡ãƒ¼ã‚¿é‡å¢—åŠ ã®åŠ¹æœã‚’è€ƒæ…®</li>
<li>ãƒã‚¤ã‚¢ã‚¹ vs ãƒãƒªã‚¢ãƒ³ã‚¹ã‚’åˆ¤æ–­</li>
</ul>

</details>

<details>
<summary><strong>å•é¡Œ3: ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã®åŠ¹æœ</strong> (é›£æ˜“åº¦: â˜…â˜…â˜…)</summary>

<p>ä»¥ä¸‹ã®3ã¤ã®ãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚Šã¾ã™ã€‚Voting Ensembleã¯åŠ¹æœçš„ã§ã—ã‚‡ã†ã‹ï¼Ÿç†ç”±ã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚</p>

<ul>
<li>Model A: Accuracy 0.85, äºˆæ¸¬ã®å¤šæ§˜æ€§: ä½</li>
<li>Model B: Accuracy 0.86, Aã¨ã®ç›¸é–¢: 0.95</li>
<li>Model C: Accuracy 0.84, Aã¨ã®ç›¸é–¢: 0.50</li>
</ul>

<p><strong>è§£ç­”ã®è¦³ç‚¹</strong>:</p>
<ul>
<li>ãƒ¢ãƒ‡ãƒ«é–“ã®å¤šæ§˜æ€§ï¼ˆDiversityï¼‰ã®é‡è¦æ€§</li>
<li>é«˜ç›¸é–¢ãƒ¢ãƒ‡ãƒ«ã‚’çµ„ã¿åˆã‚ã›ã‚‹å•é¡Œç‚¹</li>
<li>ã©ã®ãƒ¢ãƒ‡ãƒ«ã‚’çµ„ã¿åˆã‚ã›ã‚‹ã¹ãã‹</li>
</ul>

</details>

<details>
<summary><strong>å•é¡Œ4: Stacking vs Blending</strong> (é›£æ˜“åº¦: â˜…â˜…â˜…)</summary>

<p>ä»¥ä¸‹ã®çŠ¶æ³ã§ã€Stackingã¨Blendingã®ã©ã¡ã‚‰ã‚’é¸ã¶ã¹ãã‹ã€ç†ç”±ã¨ã¨ã‚‚ã«è¿°ã¹ã¦ãã ã•ã„ã€‚</p>

<ol>
<li>ãƒ‡ãƒ¼ã‚¿æ•°ãŒå°‘ãªã„ï¼ˆ500ã‚µãƒ³ãƒ—ãƒ«ï¼‰</li>
<li>ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¨è«–ãŒå¿…è¦</li>
<li>æœ€é«˜ç²¾åº¦ãŒæœ€å„ªå…ˆ</li>
</ol>

<p><strong>è€ƒæ…®ã™ã¹ãç‚¹</strong>:</p>
<ul>
<li>ãƒ‡ãƒ¼ã‚¿ã®æœ‰åŠ¹æ´»ç”¨</li>
<li>è¨ˆç®—ã‚³ã‚¹ãƒˆ</li>
<li>æ€§èƒ½ã®å®‰å®šæ€§</li>
</ul>

</details>

<details>
<summary><strong>å•é¡Œ5: No Free Lunchå®šç†ã®å®Ÿè·µ</strong> (é›£æ˜“åº¦: â˜…â˜…â˜…)</summary>

<p>ã‚ãªãŸã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã€ä»¥ä¸‹ã®è¦ä»¶ãŒã‚ã‚Šã¾ã™ã€‚æœ€é©ãªãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—ã‚’é¸æŠã—ã€ç†ç”±ã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚</p>

<ul>
<li>åŒ»ç™‚è¨ºæ–­ã‚·ã‚¹ãƒ†ãƒ ï¼ˆè§£é‡ˆæ€§ãŒå¿…é ˆï¼‰</li>
<li>ãƒ‡ãƒ¼ã‚¿æ•°: 1,000ã‚µãƒ³ãƒ—ãƒ«</li>
<li>ç‰¹å¾´é‡: 20å€‹ï¼ˆç·šå½¢é–¢ä¿‚ãŒå¼·ã„ï¼‰</li>
<li>ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡: 1:9</li>
</ul>

<p><strong>é¸æŠè‚¢</strong>: ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ã€ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆã€æ·±å±¤å­¦ç¿’ã€SVM</p>

</details>

<hr>

<h2>ã¾ã¨ã‚</h2>

<p>ã“ã®ç« ã§ã¯ã€ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒã¨é¸æŠã®ç§‘å­¦çš„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’å­¦ã³ã¾ã—ãŸï¼š</p>

<table>
<thead>
<tr>
<th>ãƒˆãƒ”ãƒƒã‚¯</th>
<th>é‡è¦ãƒã‚¤ãƒ³ãƒˆ</th>
<th>å®Ÿè·µã®ã‚³ãƒ„</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>çµ±è¨ˆçš„æ¤œå®š</strong></td>
<td>Paired t-testã€McNemarã€Friedman</td>
<td>æœ‰æ„å·®ã‚’ç¢ºèªã—ã¦ã‹ã‚‰é¸æŠ</td>
</tr>
<tr>
<td><strong>æ€§èƒ½å¯è¦–åŒ–</strong></td>
<td>Learning/Validation Curves</td>
<td>ãƒã‚¤ã‚¢ã‚¹ãƒ»ãƒãƒªã‚¢ãƒ³ã‚¹ã‚’è¨ºæ–­</td>
</tr>
<tr>
<td><strong>ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«</strong></td>
<td>Votingã€Stackingã€Blending</td>
<td>å¤šæ§˜æ€§ãŒéµã€ç›¸é–¢ã®ä½ã„ãƒ¢ãƒ‡ãƒ«ã‚’çµ„ã¿åˆã‚ã›ã‚‹</td>
</tr>
<tr>
<td><strong>é¸æŠã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³</strong></td>
<td>No Free Lunchã€ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•åˆ†æ</td>
<td>ãƒ“ã‚¸ãƒã‚¹è¦ä»¶ã‚’æœ€å„ªå…ˆã«</td>
</tr>
</tbody>
</table>

<blockquote>
<p><strong>æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—</strong>: æ¬¡ç« ã§ã¯ã€ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¨AutoMLã«ã¤ã„ã¦å­¦ã³ã€ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ã®æœ€å¤§åŒ–æ‰‹æ³•ã‚’ç¿’å¾—ã—ã¾ã™ã€‚</p>
</blockquote>

<div class="navigation">
    <a href="chapter3-cross-validation.html" class="nav-button">â† å‰ã®ç« ï¼šäº¤å·®æ¤œè¨¼</a>
    <a href="../index.html" class="nav-button">ã‚³ãƒ¼ã‚¹ç›®æ¬¡</a>
    <a href="chapter5-hyperparameter-tuning.html" class="nav-button">æ¬¡ã®ç« ï¼šãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚° â†’</a>
</div>

    </main>

    
    <section class="disclaimer">
        <h3>å…è²¬äº‹é …</h3>
        <ul>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯æ•™è‚²ãƒ»ç ”ç©¶ãƒ»æƒ…å ±æä¾›ã®ã¿ã‚’ç›®çš„ã¨ã—ã¦ãŠã‚Šã€å°‚é–€çš„ãªåŠ©è¨€(æ³•å¾‹ãƒ»ä¼šè¨ˆãƒ»æŠ€è¡“çš„ä¿è¨¼ãªã©)ã‚’æä¾›ã™ã‚‹ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŠã‚ˆã³ä»˜éšã™ã‚‹ã‚³ãƒ¼ãƒ‰ä¾‹ã¯ã€Œç¾çŠ¶æœ‰å§¿(AS IS)ã€ã§æä¾›ã•ã‚Œã€æ˜ç¤ºã¾ãŸã¯é»™ç¤ºã‚’å•ã‚ãšã€å•†å“æ€§ã€ç‰¹å®šç›®çš„é©åˆæ€§ã€æ¨©åˆ©éä¾µå®³ã€æ­£ç¢ºæ€§ãƒ»å®Œå…¨æ€§ã€å‹•ä½œãƒ»å®‰å…¨æ€§ç­‰ã„ã‹ãªã‚‹ä¿è¨¼ã‚‚ã—ã¾ã›ã‚“ã€‚</li>
            <li>å¤–éƒ¨ãƒªãƒ³ã‚¯ã€ç¬¬ä¸‰è€…ãŒæä¾›ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ»ãƒ„ãƒ¼ãƒ«ãƒ»ãƒ©ã‚¤ãƒ–ãƒ©ãƒªç­‰ã®å†…å®¹ãƒ»å¯ç”¨æ€§ãƒ»å®‰å…¨æ€§ã«ã¤ã„ã¦ã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯ä¸€åˆ‡ã®è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®åˆ©ç”¨ãƒ»å®Ÿè¡Œãƒ»è§£é‡ˆã«ã‚ˆã‚Šç›´æ¥çš„ãƒ»é–“æ¥çš„ãƒ»ä»˜éšçš„ãƒ»ç‰¹åˆ¥ãƒ»çµæœçš„ãƒ»æ‡²ç½°çš„æå®³ãŒç”Ÿã˜ãŸå ´åˆã§ã‚‚ã€é©ç”¨æ³•ã§è¨±å®¹ã•ã‚Œã‚‹æœ€å¤§é™ã®ç¯„å›²ã§ã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å†…å®¹ã¯ã€äºˆå‘Šãªãå¤‰æ›´ãƒ»æ›´æ–°ãƒ»æä¾›åœæ­¢ã•ã‚Œã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®è‘—ä½œæ¨©ãƒ»ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯æ˜è¨˜ã•ã‚ŒãŸæ¡ä»¶(ä¾‹: CC BY 4.0)ã«å¾“ã„ã¾ã™ã€‚å½“è©²ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯é€šå¸¸ã€ç„¡ä¿è¨¼æ¡é …ã‚’å«ã¿ã¾ã™ã€‚</li>
        </ul>
    </section>

<footer>
        <p>&copy; 2025 AI Terakoya. All rights reserved. | æ•™è‚²ç›®çš„ã§ã®ä½¿ç”¨ã‚’æƒ³å®šã—ã¦ã„ã¾ã™</p>
    </footer>

</body>
</html>
