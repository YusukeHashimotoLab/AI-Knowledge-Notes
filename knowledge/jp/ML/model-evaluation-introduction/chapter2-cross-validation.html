<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ç¬¬2ç« ï¼šäº¤å·®æ¤œè¨¼ã¨ãƒ‡ãƒ¼ã‚¿åˆ†å‰² - AI Terakoya</title>

    <style>
        :root {
            --color-primary: #2c3e50;
            --color-primary-dark: #1a252f;
            --color-accent: #7b2cbf;
            --color-accent-light: #9d4edd;
            --color-text: #2d3748;
            --color-text-light: #4a5568;
            --color-bg: #ffffff;
            --color-bg-alt: #f7fafc;
            --color-border: #e2e8f0;
            --color-code-bg: #f8f9fa;
            --color-link: #3182ce;
            --color-link-hover: #2c5aa0;

            --spacing-xs: 0.5rem;
            --spacing-sm: 1rem;
            --spacing-md: 1.5rem;
            --spacing-lg: 2rem;
            --spacing-xl: 3rem;

            --font-body: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            --font-mono: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;

            --border-radius: 8px;
            --box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: var(--font-body);
            line-height: 1.7;
            color: var(--color-text);
            background-color: var(--color-bg);
            font-size: 16px;
        }

        header {
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            padding: var(--spacing-xl) var(--spacing-md);
            margin-bottom: var(--spacing-xl);
            box-shadow: var(--box-shadow);
        }

        .header-content {
            max-width: 900px;
            margin: 0 auto;
        }

        h1 {
            font-size: 2rem;
            font-weight: 700;
            margin-bottom: var(--spacing-sm);
            line-height: 1.2;
        }

        .subtitle {
            font-size: 1.1rem;
            opacity: 0.95;
            font-weight: 400;
            margin-bottom: var(--spacing-md);
        }

        .meta {
            display: flex;
            flex-wrap: wrap;
            gap: var(--spacing-md);
            font-size: 0.9rem;
            opacity: 0.9;
        }

        .meta-item {
            display: flex;
            align-items: center;
            gap: 0.3rem;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 0 var(--spacing-md) var(--spacing-xl);
        }

        h2 {
            font-size: 1.75rem;
            color: var(--color-primary);
            margin-top: var(--spacing-xl);
            margin-bottom: var(--spacing-md);
            padding-bottom: var(--spacing-xs);
            border-bottom: 3px solid var(--color-accent);
        }

        h3 {
            font-size: 1.4rem;
            color: var(--color-primary);
            margin-top: var(--spacing-lg);
            margin-bottom: var(--spacing-sm);
        }

        h4 {
            font-size: 1.1rem;
            color: var(--color-primary-dark);
            margin-top: var(--spacing-md);
            margin-bottom: var(--spacing-sm);
        }

        p {
            margin-bottom: var(--spacing-md);
            color: var(--color-text);
        }

        a {
            color: var(--color-link);
            text-decoration: none;
            transition: color 0.2s;
        }

        a:hover {
            color: var(--color-link-hover);
            text-decoration: underline;
        }

        ul, ol {
            margin-left: var(--spacing-lg);
            margin-bottom: var(--spacing-md);
        }

        li {
            margin-bottom: var(--spacing-xs);
            color: var(--color-text);
        }

        pre {
            background-color: var(--color-code-bg);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            overflow-x: auto;
            margin-bottom: var(--spacing-md);
            font-family: var(--font-mono);
            font-size: 0.9rem;
            line-height: 1.5;
        }

        code {
            font-family: var(--font-mono);
            font-size: 0.9em;
            background-color: var(--color-code-bg);
            padding: 0.2em 0.4em;
            border-radius: 3px;
        }

        pre code {
            background-color: transparent;
            padding: 0;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: var(--spacing-md);
            font-size: 0.95rem;
        }

        th, td {
            border: 1px solid var(--color-border);
            padding: var(--spacing-sm);
            text-align: left;
        }

        th {
            background-color: var(--color-bg-alt);
            font-weight: 600;
            color: var(--color-primary);
        }

        blockquote {
            border-left: 4px solid var(--color-accent);
            padding-left: var(--spacing-md);
            margin: var(--spacing-md) 0;
            color: var(--color-text-light);
            font-style: italic;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        .mermaid {
            text-align: center;
            margin: var(--spacing-lg) 0;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        details {
            background-color: var(--color-bg-alt);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            margin-bottom: var(--spacing-md);
        }

        summary {
            cursor: pointer;
            font-weight: 600;
            color: var(--color-primary);
            user-select: none;
            padding: var(--spacing-xs);
            margin: calc(-1 * var(--spacing-md));
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        summary:hover {
            background-color: rgba(123, 44, 191, 0.1);
        }

        details[open] summary {
            margin-bottom: var(--spacing-md);
            border-bottom: 1px solid var(--color-border);
        }

        .navigation {
            display: flex;
            justify-content: space-between;
            gap: var(--spacing-md);
            margin: var(--spacing-xl) 0;
            padding-top: var(--spacing-lg);
            border-top: 2px solid var(--color-border);
        }

        .nav-button {
            flex: 1;
            padding: var(--spacing-md);
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            border-radius: var(--border-radius);
            text-align: center;
            font-weight: 600;
            transition: transform 0.2s, box-shadow 0.2s;
            box-shadow: var(--box-shadow);
        }

        .nav-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
            text-decoration: none;
        }

        footer {
            margin-top: var(--spacing-xl);
            padding: var(--spacing-lg) var(--spacing-md);
            background-color: var(--color-bg-alt);
            border-top: 1px solid var(--color-border);
            text-align: center;
            font-size: 0.9rem;
            color: var(--color-text-light);
        }
        .disclaimer {
            max-width: 900px;
            margin: 2rem auto;
            padding: 1.5rem;
            background: #f8f9fa;
            border-left: 4px solid #6c757d;
            border-radius: 4px;
        }

        .disclaimer h3 {
            color: #495057;
            margin-bottom: 1rem;
            font-size: 1.1rem;
        }

        .disclaimer ul {
            list-style: none;
            padding-left: 0;
        }

        .disclaimer li {
            padding: 0.5rem 0;
            padding-left: 1.5rem;
            position: relative;
            font-size: 0.9rem;
            color: #6c757d;
            line-height: 1.6;
        }

        .disclaimer li::before {
            content: "âš ï¸";
            position: absolute;
            left: 0;
        }


        @media (max-width: 768px) {
            h1 {
                font-size: 1.5rem;
            }

            h2 {
                font-size: 1.4rem;
            }

            h3 {
                font-size: 1.2rem;
            }

            .meta {
                font-size: 0.85rem;
            }

            .navigation {
                flex-direction: column;
            }

            table {
                font-size: 0.85rem;
            }

            th, td {
                padding: var(--spacing-xs);
            }
        }
    
        /* Breadcrumb styles */
        .breadcrumb {
            background: #f7fafc;
            padding: 0.75rem 1rem;
            border-bottom: 1px solid #e2e8f0;
            font-size: 0.9rem;
        }

        .breadcrumb-content {
            max-width: 900px;
            margin: 0 auto;
            display: flex;
            align-items: center;
            flex-wrap: wrap;
            gap: 0.5rem;
        }

        .breadcrumb a {
            color: #667eea;
            text-decoration: none;
            transition: color 0.2s;
        }

        .breadcrumb a:hover {
            color: #764ba2;
            text-decoration: underline;
        }

        .breadcrumb-separator {
            color: #a0aec0;
            margin: 0 0.25rem;
        }

        .breadcrumb-current {
            color: #4a5568;
            font-weight: 500;
        }
    </style>

    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
        mermaid.initialize({ startOnLoad: true, theme: 'default' });
    </script>

    <!-- MathJax for LaTeX equation rendering -->
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                displayMath: [['$$', '$$'], ['\\[', '\\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
                ignoreHtmlClass: 'mermaid'
            }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" async></script>
</head>
<body>
        <nav class="breadcrumb">
        <div class="breadcrumb-content">
            <a href="/wp/knowledge/jp/index.html">AIå¯ºå­å±‹ãƒˆãƒƒãƒ—</a><span class="breadcrumb-separator">â€º</span><a href="/wp/knowledge/jp/ML/index.html">æ©Ÿæ¢°å­¦ç¿’</a><span class="breadcrumb-separator">â€º</span><a href="/wp/knowledge/jp/ML/model-evaluation-introduction/index.html">Model Evaluation</a><span class="breadcrumb-separator">â€º</span><span class="breadcrumb-current">Chapter 2</span>
        </div>
    </nav>

    <header>
        <div class="header-content">
            <h1>ç¬¬2ç« ï¼šäº¤å·®æ¤œè¨¼ã¨ãƒ‡ãƒ¼ã‚¿åˆ†å‰²</h1>
            <p class="subtitle">ãƒ¢ãƒ‡ãƒ«ã®æ±åŒ–æ€§èƒ½ã‚’æ­£ã—ãè©•ä¾¡ã™ã‚‹ãŸã‚ã®ãƒ‡ãƒ¼ã‚¿åˆ†å‰²æˆ¦ç•¥</p>
            <div class="meta">
                <span class="meta-item">ğŸ“– èª­äº†æ™‚é–“: 20-25åˆ†</span>
                <span class="meta-item">ğŸ“Š é›£æ˜“åº¦: åˆç´šã€œä¸­ç´š</span>
                <span class="meta-item">ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹: 12å€‹</span>
                <span class="meta-item">ğŸ“ æ¼”ç¿’å•é¡Œ: 5å•</span>
            </div>
        </div>
    </header>

    <main class="container">

<h2>å­¦ç¿’ç›®æ¨™</h2>
<p>ã“ã®ç« ã‚’èª­ã‚€ã“ã¨ã§ã€ä»¥ä¸‹ã‚’ç¿’å¾—ã§ãã¾ã™ï¼š</p>
<ul>
<li>âœ… Train/Validation/Testã‚»ãƒƒãƒˆã®å½¹å‰²ã¨åˆ†å‰²æ–¹æ³•ã‚’ç†è§£ã™ã‚‹</li>
<li>âœ… Hold-outæ³•ã®å•é¡Œç‚¹ã¨ãã®è§£æ±ºç­–ã‚’èª¬æ˜ã§ãã‚‹</li>
<li>âœ… K-Foldäº¤å·®æ¤œè¨¼ã®åŸç†ã¨å®Ÿè£…ãŒã§ãã‚‹</li>
<li>âœ… Stratified K-Foldã®å¿…è¦æ€§ã‚’ç†è§£ã™ã‚‹</li>
<li>âœ… æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã«ãŠã‘ã‚‹äº¤å·®æ¤œè¨¼ã®ç‰¹æ®Šæ€§ã‚’æŠŠæ¡ã™ã‚‹</li>
<li>âœ… ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚±ãƒ¼ã‚¸ã‚’é˜²ãå‰å‡¦ç†ã®æ–¹æ³•ã‚’å®Ÿè·µã§ãã‚‹</li>
<li>âœ… Nested Cross-Validationã§ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´ãŒã§ãã‚‹</li>
</ul>

<hr>

<h2>2.1 ãƒ‡ãƒ¼ã‚¿åˆ†å‰²ã®åŸºç¤</h2>

<h3>ãªãœãƒ‡ãƒ¼ã‚¿ã‚’åˆ†å‰²ã™ã‚‹ã®ã‹</h3>

<p>æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®æœ€çµ‚ç›®çš„ã¯ã€<strong>æœªçŸ¥ã®ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦æ­£ç¢ºãªäºˆæ¸¬ã‚’è¡Œã†ã“ã¨</strong>ã§ã™ã€‚ãã®ãŸã‚ã€ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’è©•ä¾¡ã™ã‚‹éš›ã«ã¯ã€è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨ã¯åˆ¥ã®ã€Œè¦‹ãŸã“ã¨ã®ãªã„ãƒ‡ãƒ¼ã‚¿ã€ã§ãƒ†ã‚¹ãƒˆã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚</p>

<blockquote>
<p>ã€Œè¨“ç·´ãƒ‡ãƒ¼ã‚¿ã§ã®æ€§èƒ½ãŒè‰¯ãã¦ã‚‚ã€æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã§æ€§èƒ½ãŒæ‚ªã‘ã‚Œã°ã€ãã®ãƒ¢ãƒ‡ãƒ«ã¯å®Ÿç”¨çš„ã§ã¯ãªã„ã€</p>
</blockquote>

<h3>3ã¤ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ</h3>

<table>
<thead>
<tr>
<th>ã‚»ãƒƒãƒˆå</th>
<th>è‹±èªå</th>
<th>å½¹å‰²</th>
<th>å…¸å‹çš„ãªå‰²åˆ</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>è¨“ç·´ã‚»ãƒƒãƒˆ</strong></td>
<td>Training Set</td>
<td>ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å­¦ç¿’ã™ã‚‹</td>
<td>60-80%</td>
</tr>
<tr>
<td><strong>æ¤œè¨¼ã‚»ãƒƒãƒˆ</strong></td>
<td>Validation Set</td>
<td>ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®èª¿æ•´ã¨ãƒ¢ãƒ‡ãƒ«é¸æŠ</td>
<td>10-20%</td>
</tr>
<tr>
<td><strong>ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆ</strong></td>
<td>Test Set</td>
<td>æœ€çµ‚çš„ãªæ±åŒ–æ€§èƒ½ã®è©•ä¾¡</td>
<td>10-20%</td>
</tr>
</tbody>
</table>

<div class="mermaid">
graph LR
    A[å…¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ] --> B[è¨“ç·´ã‚»ãƒƒãƒˆ 60-80%]
    A --> C[æ¤œè¨¼ã‚»ãƒƒãƒˆ 10-20%]
    A --> D[ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆ 10-20%]

    B --> E[ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å­¦ç¿’]
    C --> F[ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´]
    D --> G[æœ€çµ‚æ€§èƒ½è©•ä¾¡]

    style A fill:#e1f5ff
    style B fill:#b3e5fc
    style C fill:#81d4fa
    style D fill:#4fc3f7
</div>

<h3>Hold-outæ³•ï¼šåŸºæœ¬çš„ãªãƒ‡ãƒ¼ã‚¿åˆ†å‰²</h3>

<p><strong>Hold-outæ³•</strong>ã¯ã€ãƒ‡ãƒ¼ã‚¿ã‚’ä¸€åº¦ã ã‘è¨“ç·´ã‚»ãƒƒãƒˆã¨ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã«åˆ†å‰²ã™ã‚‹æœ€ã‚‚ã‚·ãƒ³ãƒ—ãƒ«ãªæ–¹æ³•ã§ã™ã€‚</p>

<pre><code class="language-python">import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.datasets import load_iris
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
iris = load_iris()
X, y = iris.data, iris.target

# è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«åˆ†å‰²ï¼ˆ8:2ï¼‰
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

print(f"è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {X_train.shape[0]}")
print(f"ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {X_test.shape[0]}")

# ãƒ¢ãƒ‡ãƒ«è¨“ç·´
model = LogisticRegression(max_iter=200)
model.fit(X_train, y_train)

# è©•ä¾¡
train_score = accuracy_score(y_train, model.predict(X_train))
test_score = accuracy_score(y_test, model.predict(X_test))

print(f"\nè¨“ç·´ç²¾åº¦: {train_score:.4f}")
print(f"ãƒ†ã‚¹ãƒˆç²¾åº¦: {test_score:.4f}")
</code></pre>

<h3>Hold-outæ³•ã®å•é¡Œç‚¹</h3>

<p>Hold-outæ³•ã«ã¯ã„ãã¤ã‹ã®<strong>é‡å¤§ãªå•é¡Œ</strong>ãŒã‚ã‚Šã¾ã™ï¼š</p>

<ol>
<li><strong>ãƒ‡ãƒ¼ã‚¿ã®åã‚Š</strong>ï¼šãŸã¾ãŸã¾é›£ã—ã„ã‚µãƒ³ãƒ—ãƒ«ãŒãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã«é›†ä¸­ã™ã‚‹å¯èƒ½æ€§</li>
<li><strong>ãƒ‡ãƒ¼ã‚¿ã®ç„¡é§„</strong>ï¼šãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã¨ã—ã¦åˆ†é›¢ã—ãŸãƒ‡ãƒ¼ã‚¿ã¯è¨“ç·´ã«ä½¿ãˆãªã„</li>
<li><strong>ä¸å®‰å®šæ€§</strong>ï¼šåˆ†å‰²æ–¹æ³•ã«ã‚ˆã£ã¦è©•ä¾¡çµæœãŒå¤§ããå¤‰å‹•ã™ã‚‹</li>
<li><strong>å°è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã§ã®å•é¡Œ</strong>ï¼šãƒ‡ãƒ¼ã‚¿ãŒå°‘ãªã„å ´åˆã€ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆãŒæ¥µç«¯ã«å°ã•ããªã‚‹</li>
</ol>

<details>
<summary><strong>å®Ÿé¨“ï¼šHold-outæ³•ã®ä¸å®‰å®šæ€§ã‚’ç¢ºèª</strong></summary>

<pre><code class="language-python">import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.datasets import load_iris
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
iris = load_iris()
X, y = iris.data, iris.target

# ç•°ãªã‚‹random_stateã§10å›å®Ÿé¨“
test_scores = []
for seed in range(10):
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=seed
    )

    model = LogisticRegression(max_iter=200)
    model.fit(X_train, y_train)
    score = accuracy_score(y_test, model.predict(X_test))
    test_scores.append(score)

print("=== Hold-outæ³•ã®ä¸å®‰å®šæ€§ ===")
print(f"ãƒ†ã‚¹ãƒˆç²¾åº¦ã®å¹³å‡: {np.mean(test_scores):.4f}")
print(f"ãƒ†ã‚¹ãƒˆç²¾åº¦ã®æ¨™æº–åå·®: {np.std(test_scores):.4f}")
print(f"æœ€å°å€¤: {np.min(test_scores):.4f}")
print(f"æœ€å¤§å€¤: {np.max(test_scores):.4f}")
print(f"\nç²¾åº¦ã®å¤‰å‹•å¹…: {np.max(test_scores) - np.min(test_scores):.4f}")
</code></pre>

<p>å‡ºåŠ›ä¾‹ï¼š</p>
<pre><code>=== Hold-outæ³•ã®ä¸å®‰å®šæ€§ ===
ãƒ†ã‚¹ãƒˆç²¾åº¦ã®å¹³å‡: 0.9533
ãƒ†ã‚¹ãƒˆç²¾åº¦ã®æ¨™æº–åå·®: 0.0356
æœ€å°å€¤: 0.9000
æœ€å¤§å€¤: 1.0000

ç²¾åº¦ã®å¤‰å‹•å¹…: 0.1000
</code></pre>

<p>ã“ã®ã‚ˆã†ã«ã€åŒã˜ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã§ã‚‚ãƒ‡ãƒ¼ã‚¿åˆ†å‰²æ–¹æ³•ã«ã‚ˆã£ã¦<strong>æœ€å¤§10%ã‚‚ã®ç²¾åº¦å·®</strong>ãŒç”Ÿã˜ã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚</p>

</details>

<hr>

<h2>2.2 K-Foldäº¤å·®æ¤œè¨¼</h2>

<h3>K-Fold Cross-Validationã¨ã¯</h3>

<p><strong>K-Foldäº¤å·®æ¤œè¨¼ï¼ˆK-Fold Cross-Validationï¼‰</strong>ã¯ã€ãƒ‡ãƒ¼ã‚¿ã‚’Kå€‹ã®ã‚µãƒ–ã‚»ãƒƒãƒˆï¼ˆFoldï¼‰ã«åˆ†å‰²ã—ã€å„Foldã‚’ä¸€åº¦ãšã¤ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã¨ã—ã¦ä½¿ç”¨ã™ã‚‹æ‰‹æ³•ã§ã™ã€‚</p>

<div class="mermaid">
graph TD
    A[å…¨ãƒ‡ãƒ¼ã‚¿] --> B[Fold 1]
    A --> C[Fold 2]
    A --> D[Fold 3]
    A --> E[Fold 4]
    A --> F[Fold 5]

    G[Round 1] --> H[Test: Fold 1<br/>Train: Fold 2,3,4,5]
    I[Round 2] --> J[Test: Fold 2<br/>Train: Fold 1,3,4,5]
    K[Round 3] --> L[Test: Fold 3<br/>Train: Fold 1,2,4,5]
    M[Round 4] --> N[Test: Fold 4<br/>Train: Fold 1,2,3,5]
    O[Round 5] --> P[Test: Fold 5<br/>Train: Fold 1,2,3,4]

    H --> Q[Score 1]
    J --> R[Score 2]
    L --> S[Score 3]
    N --> T[Score 4]
    P --> U[Score 5]

    Q --> V[å¹³å‡ã‚¹ã‚³ã‚¢]
    R --> V
    S --> V
    T --> V
    U --> V

    style A fill:#e1f5ff
    style V fill:#4fc3f7
</div>

<h3>K-Foldäº¤å·®æ¤œè¨¼ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ </h3>

<ol>
<li>ãƒ‡ãƒ¼ã‚¿ã‚’$K$å€‹ã®ã‚µãƒ–ã‚»ãƒƒãƒˆï¼ˆFoldï¼‰ã«ãƒ©ãƒ³ãƒ€ãƒ åˆ†å‰²</li>
<li>å„Fold $i$ ($i = 1, 2, ..., K$) ã«å¯¾ã—ã¦ï¼š
<ul>
<li>Fold $i$ ã‚’ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã¨ã™ã‚‹</li>
<li>æ®‹ã‚Šã® $K-1$ å€‹ã®Foldã‚’è¨“ç·´ã‚»ãƒƒãƒˆã¨ã™ã‚‹</li>
<li>ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã—ã€Fold $i$ ã§è©•ä¾¡ã—ã¦ã‚¹ã‚³ã‚¢ $S_i$ ã‚’å¾—ã‚‹</li>
</ul>
</li>
<li>$K$å€‹ã®ã‚¹ã‚³ã‚¢ã®å¹³å‡ã‚’æœ€çµ‚è©•ä¾¡ã¨ã™ã‚‹ï¼š
$$
\text{CV Score} = \frac{1}{K} \sum_{i=1}^{K} S_i
$$
</li>
</ol>

<h3>åŸºæœ¬çš„ãªå®Ÿè£…</h3>

<pre><code class="language-python">import numpy as np
from sklearn.model_selection import KFold, cross_val_score
from sklearn.datasets import load_iris
from sklearn.linear_model import LogisticRegression

# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
iris = load_iris()
X, y = iris.data, iris.target

# ãƒ¢ãƒ‡ãƒ«ä½œæˆ
model = LogisticRegression(max_iter=200)

# 5-Foldäº¤å·®æ¤œè¨¼
kfold = KFold(n_splits=5, shuffle=True, random_state=42)
scores = cross_val_score(model, X, y, cv=kfold, scoring='accuracy')

print("=== 5-Foldäº¤å·®æ¤œè¨¼ã®çµæœ ===")
for i, score in enumerate(scores, 1):
    print(f"Fold {i}: {score:.4f}")

print(f"\nå¹³å‡ç²¾åº¦: {scores.mean():.4f}")
print(f"æ¨™æº–åå·®: {scores.std():.4f}")
print(f"95%ä¿¡é ¼åŒºé–“: [{scores.mean() - 1.96*scores.std():.4f}, "
      f"{scores.mean() + 1.96*scores.std():.4f}]")
</code></pre>

<h3>K-Foldäº¤å·®æ¤œè¨¼ã®åˆ©ç‚¹</h3>

<ul>
<li><strong>å®‰å®šã—ãŸè©•ä¾¡</strong>ï¼šè¤‡æ•°å›ã®è©•ä¾¡ã®å¹³å‡ã‚’å–ã‚‹ãŸã‚ã€å¶ç„¶ã®å½±éŸ¿ã‚’æ¸›ã‚‰ã›ã‚‹</li>
<li><strong>ãƒ‡ãƒ¼ã‚¿ã®æœ‰åŠ¹æ´»ç”¨</strong>ï¼šã™ã¹ã¦ã®ãƒ‡ãƒ¼ã‚¿ãŒè¨“ç·´ã¨ãƒ†ã‚¹ãƒˆã®ä¸¡æ–¹ã«ä½¿ã‚ã‚Œã‚‹</li>
<li><strong>ä¿¡é ¼åŒºé–“ã®æ¨å®š</strong>ï¼šæ¨™æº–åå·®ã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ã®å®‰å®šæ€§ã‚’è©•ä¾¡ã§ãã‚‹</li>
<li><strong>å°è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã§ã‚‚æœ‰åŠ¹</strong>ï¼šé™ã‚‰ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã§ã‚‚ä¿¡é ¼æ€§ã®é«˜ã„è©•ä¾¡ãŒå¯èƒ½</li>
</ul>

<h3>Kå€¤ã®é¸æŠ</h3>

<table>
<thead>
<tr>
<th>Kå€¤</th>
<th>è¨“ç·´ãƒ‡ãƒ¼ã‚¿å‰²åˆ</th>
<th>ãƒ¡ãƒªãƒƒãƒˆ</th>
<th>ãƒ‡ãƒ¡ãƒªãƒƒãƒˆ</th>
<th>æ¨å¥¨ã‚±ãƒ¼ã‚¹</th>
</tr>
</thead>
<tbody>
<tr>
<td>3</td>
<td>67%</td>
<td>è¨ˆç®—ãŒé«˜é€Ÿ</td>
<td>è©•ä¾¡ãŒä¸å®‰å®š</td>
<td>å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã€åˆæœŸå®Ÿé¨“</td>
</tr>
<tr>
<td>5</td>
<td>80%</td>
<td>ãƒãƒ©ãƒ³ã‚¹ãŒè‰¯ã„</td>
<td>-</td>
<td>æ¨™æº–çš„ãªé¸æŠ</td>
</tr>
<tr>
<td>10</td>
<td>90%</td>
<td>è©•ä¾¡ãŒå®‰å®š</td>
<td>è¨ˆç®—ã‚³ã‚¹ãƒˆãŒé«˜ã„</td>
<td>ä¸­è¦æ¨¡ãƒ‡ãƒ¼ã‚¿</td>
</tr>
<tr>
<td>N (LOOCV)</td>
<td>100% - 1</td>
<td>ãƒã‚¤ã‚¢ã‚¹ãŒæœ€å°</td>
<td>è¨ˆç®—ã‚³ã‚¹ãƒˆãŒæ¥µã‚ã¦é«˜ã„</td>
<td>å°è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ï¼ˆN &lt; 100ï¼‰</td>
</tr>
</tbody>
</table>

<blockquote>
<p><strong>çµŒé¨“å‰‡</strong>ï¼šå®Ÿå‹™ã§ã¯<strong>K=5</strong>ã¾ãŸã¯<strong>K=10</strong>ãŒæœ€ã‚‚ã‚ˆãä½¿ã‚ã‚Œã¾ã™ã€‚K=5ã¯è¨ˆç®—åŠ¹ç‡ã¨è©•ä¾¡ã®å®‰å®šæ€§ã®ãƒãƒ©ãƒ³ã‚¹ãŒè‰¯ã„ãŸã‚ã€å¤šãã®å ´åˆã«æ¨å¥¨ã•ã‚Œã¾ã™ã€‚</p>
</blockquote>

<hr>

<h2>2.3 Stratified K-Fold</h2>

<h3>ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡å•é¡Œ</h3>

<p>é€šå¸¸ã®K-Foldäº¤å·®æ¤œè¨¼ã§ã¯ã€å„Foldã«ã‚¯ãƒ©ã‚¹ãŒå‡ç­‰ã«åˆ†é…ã•ã‚Œã‚‹ä¿è¨¼ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ç‰¹ã«<strong>ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿</strong>ï¼ˆä¾‹ï¼šæ­£ä¾‹10%ã€è² ä¾‹90%ï¼‰ã§ã¯ã€ä»¥ä¸‹ã®å•é¡ŒãŒç™ºç”Ÿã—ã¾ã™ï¼š</p>

<ul>
<li>ã‚ã‚‹Foldã«ç‰¹å®šã®ã‚¯ãƒ©ã‚¹ãŒã»ã¨ã‚“ã©å«ã¾ã‚Œãªã„</li>
<li>å°‘æ•°ã‚¯ãƒ©ã‚¹ãŒãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã«å…¨ãå«ã¾ã‚Œãªã„</li>
<li>è©•ä¾¡æŒ‡æ¨™ãŒä¸å®‰å®šã«ãªã‚‹</li>
</ul>

<h3>Stratified K-Foldã®åŸç†</h3>

<p><strong>Stratified K-Fold</strong>ã¯ã€å„Foldã§<strong>ã‚¯ãƒ©ã‚¹ã®æ¯”ç‡ã‚’å…ƒãƒ‡ãƒ¼ã‚¿ã¨åŒã˜ã«ä¿ã¤</strong>ã‚ˆã†ã«åˆ†å‰²ã—ã¾ã™ã€‚</p>

<div class="mermaid">
graph TD
    A[å…ƒãƒ‡ãƒ¼ã‚¿<br/>Class A: 70%<br/>Class B: 30%] --> B[Stratifiedåˆ†å‰²]

    B --> C[Fold 1<br/>Class A: 70%<br/>Class B: 30%]
    B --> D[Fold 2<br/>Class A: 70%<br/>Class B: 30%]
    B --> E[Fold 3<br/>Class A: 70%<br/>Class B: 30%]
    B --> F[Fold 4<br/>Class A: 70%<br/>Class B: 30%]
    B --> G[Fold 5<br/>Class A: 70%<br/>Class B: 30%]

    style A fill:#e1f5ff
    style C fill:#b3e5fc
    style D fill:#b3e5fc
    style E fill:#b3e5fc
    style F fill:#b3e5fc
    style G fill:#b3e5fc
</div>

<h3>å®Ÿè£…ã¨æ¯”è¼ƒ</h3>

<pre><code class="language-python">import numpy as np
from sklearn.model_selection import KFold, StratifiedKFold, cross_val_score
from sklearn.datasets import make_classification
from sklearn.linear_model import LogisticRegression

# ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆï¼ˆæ­£ä¾‹:è² ä¾‹ = 1:9ï¼‰
X, y = make_classification(
    n_samples=1000,
    n_features=20,
    n_informative=15,
    n_redundant=5,
    weights=[0.9, 0.1],  # 90% vs 10%
    random_state=42
)

print(f"ã‚¯ãƒ©ã‚¹åˆ†å¸ƒ: Class 0 = {np.sum(y==0)}, Class 1 = {np.sum(y==1)}")
print(f"ã‚¯ãƒ©ã‚¹æ¯”ç‡: {np.sum(y==1)/len(y):.2%} ãŒ Class 1\n")

# ãƒ¢ãƒ‡ãƒ«ä½œæˆ
model = LogisticRegression(max_iter=200)

# é€šå¸¸ã®K-Fold
kfold = KFold(n_splits=5, shuffle=True, random_state=42)
scores_kfold = cross_val_score(model, X, y, cv=kfold, scoring='f1')

# Stratified K-Fold
stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
scores_stratified = cross_val_score(model, X, y, cv=stratified_kfold, scoring='f1')

print("=== K-Fold vs Stratified K-Fold ===")
print(f"é€šå¸¸ã®K-Fold:")
print(f"  å¹³å‡F1ã‚¹ã‚³ã‚¢: {scores_kfold.mean():.4f} Â± {scores_kfold.std():.4f}")

print(f"\nStratified K-Fold:")
print(f"  å¹³å‡F1ã‚¹ã‚³ã‚¢: {scores_stratified.mean():.4f} Â± {scores_stratified.std():.4f}")

print(f"\næ”¹å–„ç‡: {(scores_stratified.mean() - scores_kfold.mean()) / scores_kfold.mean() * 100:.2f}%")
</code></pre>

<h3>å„Foldã®ã‚¯ãƒ©ã‚¹åˆ†å¸ƒã‚’ç¢ºèª</h3>

<pre><code class="language-python">import numpy as np
from sklearn.model_selection import KFold, StratifiedKFold
from sklearn.datasets import make_classification

# ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿ä½œæˆ
X, y = make_classification(
    n_samples=1000,
    weights=[0.9, 0.1],
    random_state=42
)

# é€šå¸¸ã®K-Fold
print("=== é€šå¸¸ã®K-Fold ã®ã‚¯ãƒ©ã‚¹åˆ†å¸ƒ ===")
kfold = KFold(n_splits=5, shuffle=True, random_state=42)
for i, (train_idx, test_idx) in enumerate(kfold.split(X), 1):
    y_test = y[test_idx]
    class_1_ratio = np.sum(y_test == 1) / len(y_test)
    print(f"Fold {i}: Class 1 ã®å‰²åˆ = {class_1_ratio:.2%}")

# Stratified K-Fold
print("\n=== Stratified K-Fold ã®ã‚¯ãƒ©ã‚¹åˆ†å¸ƒ ===")
stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
for i, (train_idx, test_idx) in enumerate(stratified_kfold.split(X, y), 1):
    y_test = y[test_idx]
    class_1_ratio = np.sum(y_test == 1) / len(y_test)
    print(f"Fold {i}: Class 1 ã®å‰²åˆ = {class_1_ratio:.2%}")
</code></pre>

<h3>ã„ã¤Stratified K-Foldã‚’ä½¿ã†ã¹ãã‹</h3>

<ul>
<li><strong>å¿…ãšä½¿ã†ã¹ã</strong>ï¼šåˆ†é¡å•é¡Œã§ã‚¯ãƒ©ã‚¹ãŒä¸å‡è¡¡ãªå ´åˆ</li>
<li><strong>æ¨å¥¨</strong>ï¼šã™ã¹ã¦ã®åˆ†é¡å•é¡Œï¼ˆãƒãƒ©ãƒ³ã‚¹ãŒè‰¯ãã¦ã‚‚å®‰å®šæ€§å‘ä¸Šï¼‰</li>
<li><strong>ä½¿ãˆãªã„</strong>ï¼šå›å¸°å•é¡Œï¼ˆç›®çš„å¤‰æ•°ãŒé€£ç¶šå€¤ï¼‰</li>
</ul>

<blockquote>
<p><strong>ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹</strong>ï¼šåˆ†é¡å•é¡Œã§ã¯ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§<code>StratifiedKFold</code>ã‚’ä½¿ã„ã¾ã—ã‚‡ã†ã€‚ã‚¯ãƒ©ã‚¹ãŒãƒãƒ©ãƒ³ã‚¹ã—ã¦ã„ã¦ã‚‚ã€è©•ä¾¡ã®å®‰å®šæ€§ãŒå‘ä¸Šã—ã¾ã™ã€‚</p>
</blockquote>

<hr>

<h2>2.4 Leave-One-Outäº¤å·®æ¤œè¨¼</h2>

<h3>Leave-One-Out Cross-Validation (LOOCV)</h3>

<p><strong>LOOCV</strong>ã¯ã€K-Foldã®ç‰¹æ®Šã‚±ãƒ¼ã‚¹ã§ã€$K = N$ï¼ˆãƒ‡ãƒ¼ã‚¿æ•°ï¼‰ã¨ã—ãŸæ¥µç«¯ãªäº¤å·®æ¤œè¨¼ã§ã™ã€‚</p>

<ul>
<li>å„ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§<strong>1ã¤ã®ã‚µãƒ³ãƒ—ãƒ«ã ã‘</strong>ã‚’ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã¨ã™ã‚‹</li>
<li>æ®‹ã‚Šã®$N-1$å€‹ã®ã‚µãƒ³ãƒ—ãƒ«ã§è¨“ç·´</li>
<li>$N$å›ã®è¨“ç·´ã¨è©•ä¾¡ã‚’å®Ÿè¡Œ</li>
</ul>

<h3>LOOCVã®ç‰¹å¾´</h3>

<table>
<thead>
<tr>
<th>é …ç›®</th>
<th>LOOCV</th>
<th>K-Fold (K=5)</th>
</tr>
</thead>
<tbody>
<tr>
<td>è¨“ç·´ãƒ‡ãƒ¼ã‚¿å‰²åˆ</td>
<td>$(N-1)/N$ â‰ˆ 100%</td>
<td>80%</td>
</tr>
<tr>
<td>è©•ä¾¡å›æ•°</td>
<td>$N$å›</td>
<td>5å›</td>
</tr>
<tr>
<td>ãƒã‚¤ã‚¢ã‚¹</td>
<td>æ¥µã‚ã¦ä½ã„</td>
<td>ã‚„ã‚„é«˜ã„</td>
</tr>
<tr>
<td>åˆ†æ•£</td>
<td>é«˜ã„</td>
<td>ä½ã„</td>
</tr>
<tr>
<td>è¨ˆç®—ã‚³ã‚¹ãƒˆ</td>
<td>éå¸¸ã«é«˜ã„</td>
<td>ä½ã„</td>
</tr>
<tr>
<td>æ¨å¥¨ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º</td>
<td>$N < 100$</td>
<td>ä»»æ„</td>
</tr>
</tbody>
</table>

<h3>å®Ÿè£…ä¾‹</h3>

<pre><code class="language-python">import numpy as np
from sklearn.model_selection import LeaveOneOut, cross_val_score
from sklearn.datasets import load_iris
from sklearn.linear_model import LogisticRegression
import time

# å°è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã§å®Ÿé¨“
iris = load_iris()
X, y = iris.data[:50], iris.target[:50]  # 50ã‚µãƒ³ãƒ—ãƒ«ã®ã¿

model = LogisticRegression(max_iter=200)

# LOOCV
loo = LeaveOneOut()
start_time = time.time()
scores_loo = cross_val_score(model, X, y, cv=loo, scoring='accuracy')
loo_time = time.time() - start_time

print("=== Leave-One-Outäº¤å·®æ¤œè¨¼ ===")
print(f"è©•ä¾¡å›æ•°: {len(scores_loo)}å›")
print(f"å¹³å‡ç²¾åº¦: {scores_loo.mean():.4f}")
print(f"æ¨™æº–åå·®: {scores_loo.std():.4f}")
print(f"å®Ÿè¡Œæ™‚é–“: {loo_time:.3f}ç§’")

# 5-Fold CVã¨æ¯”è¼ƒ
from sklearn.model_selection import KFold
kfold = KFold(n_splits=5, shuffle=True, random_state=42)
start_time = time.time()
scores_kfold = cross_val_score(model, X, y, cv=kfold, scoring='accuracy')
kfold_time = time.time() - start_time

print("\n=== 5-Foldäº¤å·®æ¤œè¨¼ï¼ˆæ¯”è¼ƒï¼‰ ===")
print(f"è©•ä¾¡å›æ•°: {len(scores_kfold)}å›")
print(f"å¹³å‡ç²¾åº¦: {scores_kfold.mean():.4f}")
print(f"æ¨™æº–åå·®: {scores_kfold.std():.4f}")
print(f"å®Ÿè¡Œæ™‚é–“: {kfold_time:.3f}ç§’")

print(f"\né€Ÿåº¦æ¯”: LOOCV ã¯ 5-Fold ã® {loo_time/kfold_time:.1f}å€é…ã„")
</code></pre>

<h3>LOOCVã®ãƒ¡ãƒªãƒƒãƒˆã¨ãƒ‡ãƒ¡ãƒªãƒƒãƒˆ</h3>

<p><strong>ãƒ¡ãƒªãƒƒãƒˆ</strong>ï¼š</p>
<ul>
<li>è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚’æœ€å¤§é™æ´»ç”¨ã§ãã‚‹ï¼ˆãƒã‚¤ã‚¢ã‚¹ãŒæœ€å°ï¼‰</li>
<li>æ±ºå®šè«–çš„ï¼ˆãƒ©ãƒ³ãƒ€ãƒ æ€§ãŒãªã„ï¼‰</li>
<li>å°è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã§æœ‰åŠ¹</li>
</ul>

<p><strong>ãƒ‡ãƒ¡ãƒªãƒƒãƒˆ</strong>ï¼š</p>
<ul>
<li>è¨ˆç®—ã‚³ã‚¹ãƒˆãŒæ¥µã‚ã¦é«˜ã„ï¼ˆ$N$å›ã®è¨“ç·´ï¼‰</li>
<li>åˆ†æ•£ãŒå¤§ãã„ï¼ˆå„ãƒ†ã‚¹ãƒˆãŒ1ã‚µãƒ³ãƒ—ãƒ«ã®ã¿ï¼‰</li>
<li>å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã§ã¯å®Ÿç”¨çš„ã§ãªã„</li>
</ul>

<blockquote>
<p><strong>å®Ÿå‹™ã§ã®ä½¿ã„åˆ†ã‘</strong>ï¼šãƒ‡ãƒ¼ã‚¿æ•°ãŒ100æœªæº€ã®å ´åˆã®ã¿LOOCVã‚’æ¤œè¨ã—ã€ãã‚Œä»¥å¤–ã¯K-Foldã‚’ä½¿ç”¨ã™ã‚‹ã®ãŒç¾å®Ÿçš„ã§ã™ã€‚</p>
</blockquote>

<hr>

<h2>2.5 æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã®äº¤å·®æ¤œè¨¼</h2>

<h3>æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã®ç‰¹æ®Šæ€§</h3>

<p>æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã§ã¯ã€<strong>æ™‚é–“çš„ãªé †åºãŒé‡è¦</strong>ã§ã™ã€‚é€šå¸¸ã®K-Foldã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«é©ç”¨ã™ã‚‹ã¨ã€ä»¥ä¸‹ã®å•é¡ŒãŒç™ºç”Ÿã—ã¾ã™ï¼š</p>

<ul>
<li><strong>æœªæ¥ã®æƒ…å ±ãƒªãƒ¼ã‚¯</strong>ï¼šè¨“ç·´ãƒ‡ãƒ¼ã‚¿ã«æœªæ¥ã®ãƒ‡ãƒ¼ã‚¿ãŒå«ã¾ã‚Œã‚‹</li>
<li><strong>æ™‚é–“ä¾å­˜æ€§ã®ç„¡è¦–</strong>ï¼šéå»â†’ç¾åœ¨â†’æœªæ¥ã¨ã„ã†å› æœé–¢ä¿‚ãŒå´©ã‚Œã‚‹</li>
<li><strong>éç¾å®Ÿçš„ãªè©•ä¾¡</strong>ï¼šå®Ÿé‹ç”¨ã§ã¯å¸¸ã«æœªæ¥ã‚’äºˆæ¸¬ã™ã‚‹ã®ã«ã€éå»ã‚‚æœªæ¥ã‚‚æ··ãœã¦è¨“ç·´ã—ã¦ã—ã¾ã†</li>
</ul>

<div class="mermaid">
graph LR
    A[âŒ é€šå¸¸ã®K-Fold] --> B[æ™‚é–“é †åºã‚’ç„¡è¦–]
    B --> C[æœªæ¥ãƒ‡ãƒ¼ã‚¿ã§è¨“ç·´<br/>éå»ãƒ‡ãƒ¼ã‚¿ã§ãƒ†ã‚¹ãƒˆ]
    C --> D[éå¤§è©•ä¾¡]

    E[âœ… Time Series Split] --> F[æ™‚é–“é †åºã‚’ä¿æŒ]
    F --> G[éå»ãƒ‡ãƒ¼ã‚¿ã§è¨“ç·´<br/>æœªæ¥ãƒ‡ãƒ¼ã‚¿ã§ãƒ†ã‚¹ãƒˆ]
    G --> H[æ­£ã—ã„è©•ä¾¡]

    style A fill:#ffcdd2
    style E fill:#c8e6c9
</div>

<h3>TimeSeriesSplit</h3>

<p><strong>TimeSeriesSplit</strong>ã¯ã€æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã®ãŸã‚ã«è¨­è¨ˆã•ã‚ŒãŸäº¤å·®æ¤œè¨¼ã§ã€ä»¥ä¸‹ã®ç‰¹å¾´ãŒã‚ã‚Šã¾ã™ï¼š</p>

<ul>
<li>è¨“ç·´ã‚»ãƒƒãƒˆã¯å¸¸ã«<strong>ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã‚ˆã‚Šå‰</strong>ã®æ™‚é–“ã®ãƒ‡ãƒ¼ã‚¿</li>
<li>å„Foldã§è¨“ç·´ã‚»ãƒƒãƒˆãŒ<strong>æ‹¡å¤§</strong>ã—ã¦ã„ãï¼ˆç´¯ç©å‹ï¼‰</li>
<li>ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã¯å¸¸ã«æœªæ¥ã®ä¸€å®šæœŸé–“</li>
</ul>

<div class="mermaid">
graph TD
    A[æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿: t1, t2, t3, t4, t5, t6, t7, t8, t9] --> B[Fold 1]
    A --> C[Fold 2]
    A --> D[Fold 3]
    A --> E[Fold 4]

    B --> F[Train: t1,t2,t3 | Test: t4,t5]
    C --> G[Train: t1,t2,t3,t4,t5 | Test: t6,t7]
    D --> H[Train: t1,t2,t3,t4,t5,t6,t7 | Test: t8,t9]

    style A fill:#e1f5ff
    style F fill:#b3e5fc
    style G fill:#81d4fa
    style H fill:#4fc3f7
</div>

<h3>å®Ÿè£…ä¾‹</h3>

<pre><code class="language-python">import numpy as np
import pandas as pd
from sklearn.model_selection import TimeSeriesSplit, cross_val_score
from sklearn.linear_model import Ridge
from sklearn.metrics import mean_squared_error
import matplotlib.pyplot as plt

# æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆï¼ˆæ—¥æ¬¡å£²ä¸Šãƒ‡ãƒ¼ã‚¿ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆï¼‰
np.random.seed(42)
n_samples = 365  # 1å¹´é–“ã®æ—¥æ¬¡ãƒ‡ãƒ¼ã‚¿
dates = pd.date_range('2023-01-01', periods=n_samples, freq='D')

# ãƒˆãƒ¬ãƒ³ãƒ‰ + å­£ç¯€æ€§ + ãƒã‚¤ã‚º
trend = np.linspace(100, 150, n_samples)
seasonality = 20 * np.sin(2 * np.pi * np.arange(n_samples) / 7)  # é€±æ¬¡å‘¨æœŸ
noise = np.random.randn(n_samples) * 5
y = trend + seasonality + noise

# ç‰¹å¾´é‡ä½œæˆï¼ˆéå»7æ—¥é–“ã®ç§»å‹•å¹³å‡ãªã©ï¼‰
X = np.column_stack([
    np.roll(y, 1),  # 1æ—¥å‰
    np.roll(y, 7),  # 7æ—¥å‰
    pd.Series(y).rolling(7).mean().fillna(method='bfill'),  # 7æ—¥ç§»å‹•å¹³å‡
])

# æœ€åˆã®7æ—¥é–“ã‚’é™¤å»ï¼ˆrollã«ã‚ˆã‚‹ãƒ‡ãƒ¼ã‚¿ä¸è¶³ã‚’å›é¿ï¼‰
X, y = X[7:], y[7:]

# TimeSeriesSplit
tscv = TimeSeriesSplit(n_splits=5)

print("=== TimeSeriesSplit ã®åˆ†å‰²ãƒ‘ã‚¿ãƒ¼ãƒ³ ===")
for i, (train_index, test_index) in enumerate(tscv.split(X), 1):
    print(f"Fold {i}:")
    print(f"  è¨“ç·´: {len(train_index)}ã‚µãƒ³ãƒ—ãƒ« (index {train_index[0]} ~ {train_index[-1]})")
    print(f"  ãƒ†ã‚¹ãƒˆ: {len(test_index)}ã‚µãƒ³ãƒ—ãƒ« (index {test_index[0]} ~ {test_index[-1]})")

# ãƒ¢ãƒ‡ãƒ«è©•ä¾¡
model = Ridge(alpha=1.0)
scores = cross_val_score(model, X, y, cv=tscv, scoring='neg_mean_squared_error')
rmse_scores = np.sqrt(-scores)

print(f"\n=== å„Foldã®æ€§èƒ½ ===")
for i, rmse in enumerate(rmse_scores, 1):
    print(f"Fold {i} RMSE: {rmse:.2f}")

print(f"\nå¹³å‡RMSE: {rmse_scores.mean():.2f} Â± {rmse_scores.std():.2f}")
</code></pre>

<h3>é€šå¸¸ã®K-Foldã¨ã®æ¯”è¼ƒ</h3>

<pre><code class="language-python">import numpy as np
from sklearn.model_selection import KFold, TimeSeriesSplit, cross_val_score
from sklearn.linear_model import Ridge

# åŒã˜ãƒ‡ãƒ¼ã‚¿ã§é€šå¸¸ã®K-Foldã‚’å®Ÿè¡Œ
kfold = KFold(n_splits=5, shuffle=False)  # shuffle=Falseã§æ™‚ç³»åˆ—é †åºã‚’ç¶­æŒ
scores_kfold = cross_val_score(model, X, y, cv=kfold, scoring='neg_mean_squared_error')
rmse_kfold = np.sqrt(-scores_kfold)

# TimeSeriesSplit
tscv = TimeSeriesSplit(n_splits=5)
scores_tscv = cross_val_score(model, X, y, cv=tscv, scoring='neg_mean_squared_error')
rmse_tscv = np.sqrt(-scores_tscv)

print("=== K-Fold vs TimeSeriesSplit ===")
print(f"K-Fold å¹³å‡RMSE: {rmse_kfold.mean():.2f} Â± {rmse_kfold.std():.2f}")
print(f"TimeSeriesSplit å¹³å‡RMSE: {rmse_tscv.mean():.2f} Â± {rmse_tscv.std():.2f}")

print(f"\nå·®åˆ†: {rmse_kfold.mean() - rmse_tscv.mean():.2f}")
print("ï¼ˆK-Foldã®æ–¹ãŒè‰¯ã„çµæœ = æœªæ¥æƒ…å ±ãƒªãƒ¼ã‚¯ã«ã‚ˆã‚‹éå¤§è©•ä¾¡ã®å¯èƒ½æ€§ï¼‰")
</code></pre>

<h3>æ™‚ç³»åˆ—CVã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹</h3>

<ul>
<li><strong>å¿…é ˆ</strong>ï¼šæ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã«ã¯å¿…ãšTimeSeriesSplitã‚’ä½¿ã†</li>
<li><strong>æ¨å¥¨</strong>ï¼šãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆæœŸé–“ã‚’å®Ÿé‹ç”¨ã¨åŒã˜é•·ã•ã«è¨­å®šã™ã‚‹</li>
<li><strong>æ³¨æ„</strong>ï¼šç‰¹å¾´é‡ä½œæˆæ™‚ã«ã‚‚æœªæ¥æƒ…å ±ã‚’ä½¿ã‚ãªã„ï¼ˆãƒ©ã‚°ç‰¹å¾´é‡ã‚’ä½¿ç”¨ï¼‰</li>
<li><strong>æ¤œè¨</strong>ï¼šWalking Forward Validationï¼ˆæ®µéšçš„æ¤œè¨¼ï¼‰ã‚‚æ¤œè¨ã™ã‚‹</li>
</ul>

<hr>

<h2>2.6 ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚±ãƒ¼ã‚¸ã®é˜²æ­¢</h2>

<h3>ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚±ãƒ¼ã‚¸ã¨ã¯</h3>

<p><strong>ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚±ãƒ¼ã‚¸ï¼ˆData Leakageï¼‰</strong>ã¨ã¯ã€è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã«<strong>æœ¬æ¥çŸ¥ã‚Šå¾—ãªã„æƒ…å ±</strong>ãŒæ··å…¥ã—ã€ãƒ¢ãƒ‡ãƒ«ãŒéå¤§è©•ä¾¡ã•ã‚Œã‚‹ç¾è±¡ã§ã™ã€‚</p>

<blockquote>
<p>ã€Œè¨“ç·´æ™‚ã«æœªæ¥ã‚„ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®æƒ…å ±ã‚’ä½¿ã£ã¦ã—ã¾ã„ã€å®Ÿé‹ç”¨ã§ã¯å†ç¾ã§ããªã„é«˜æ€§èƒ½ãŒå‡ºã¦ã—ã¾ã†ã€</p>
</blockquote>

<h3>ã‚ˆãã‚ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚±ãƒ¼ã‚¸ã®ãƒ‘ã‚¿ãƒ¼ãƒ³</h3>

<table>
<thead>
<tr>
<th>ãƒªãƒ¼ã‚±ãƒ¼ã‚¸ã®ç¨®é¡</th>
<th>åŸå› </th>
<th>çµæœ</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>å‰å‡¦ç†ãƒªãƒ¼ã‚±ãƒ¼ã‚¸</strong></td>
<td>å…¨ãƒ‡ãƒ¼ã‚¿ã§æ­£è¦åŒ–ã—ã¦ã‹ã‚‰åˆ†å‰²</td>
<td>ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã®çµ±è¨ˆé‡ã‚’è¨“ç·´ã«ä½¿ç”¨</td>
</tr>
<tr>
<td><strong>æ™‚é–“çš„ãƒªãƒ¼ã‚±ãƒ¼ã‚¸</strong></td>
<td>æœªæ¥ã®ãƒ‡ãƒ¼ã‚¿ã§è¨“ç·´</td>
<td>å› æœé–¢ä¿‚ãŒé€†è»¢</td>
</tr>
<tr>
<td><strong>ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒªãƒ¼ã‚±ãƒ¼ã‚¸</strong></td>
<td>ç›®çš„å¤‰æ•°ã‹ã‚‰ä½œã£ãŸç‰¹å¾´é‡</td>
<td>ãƒ†ã‚¹ãƒˆæ™‚ã«åˆ©ç”¨ä¸å¯èƒ½ãªæƒ…å ±</td>
</tr>
<tr>
<td><strong>é‡è¤‡ãƒ‡ãƒ¼ã‚¿</strong></td>
<td>åŒã˜ãƒ‡ãƒ¼ã‚¿ãŒè¨“ç·´ã¨ãƒ†ã‚¹ãƒˆã«å­˜åœ¨</td>
<td>è¨˜æ†¶ã«ã‚ˆã‚‹éå¤§è©•ä¾¡</td>
</tr>
</tbody>
</table>

<h3>é–“é•ã£ãŸå‰å‡¦ç†ã®ä¾‹</h3>

<pre><code class="language-python">import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from sklearn.datasets import make_classification

# ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
X, y = make_classification(n_samples=1000, n_features=20, random_state=42)

# âŒ é–“é•ã„ï¼šåˆ†å‰²å‰ã«å…¨ãƒ‡ãƒ¼ã‚¿ã§æ­£è¦åŒ–
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)  # å…¨ãƒ‡ãƒ¼ã‚¿ã®å¹³å‡ãƒ»æ¨™æº–åå·®ã‚’ä½¿ç”¨

X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, random_state=42
)

model = LogisticRegression(max_iter=200)
model.fit(X_train, y_train)
score_wrong = accuracy_score(y_test, model.predict(X_test))

print(f"âŒ ãƒªãƒ¼ã‚±ãƒ¼ã‚¸ã‚ã‚Šï¼ˆé–“é•ã„ï¼‰: ãƒ†ã‚¹ãƒˆç²¾åº¦ = {score_wrong:.4f}")
</code></pre>

<h3>æ­£ã—ã„å‰å‡¦ç†ã®ä¾‹</h3>

<pre><code class="language-python">import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from sklearn.datasets import make_classification

# ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
X, y = make_classification(n_samples=1000, n_features=20, random_state=42)

# âœ… æ­£ã—ã„ï¼šå…ˆã«åˆ†å‰²ã—ã¦ã‹ã‚‰è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®ã¿ã§æ­£è¦åŒ–
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)  # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®ã¿ã§å­¦ç¿’
X_test_scaled = scaler.transform(X_test)  # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆé‡ã‚’é©ç”¨

model = LogisticRegression(max_iter=200)
model.fit(X_train_scaled, y_train)
score_correct = accuracy_score(y_test, model.predict(X_test_scaled))

print(f"âœ… ãƒªãƒ¼ã‚±ãƒ¼ã‚¸ãªã—ï¼ˆæ­£ã—ã„ï¼‰: ãƒ†ã‚¹ãƒˆç²¾åº¦ = {score_correct:.4f}")
</code></pre>

<h3>Pipelineã‚’ä½¿ã£ãŸå®‰å…¨ãªå®Ÿè£…</h3>

<p><code>sklearn.pipeline.Pipeline</code>ã‚’ä½¿ã†ã¨ã€å‰å‡¦ç†ã¨ãƒ¢ãƒ‡ãƒ«ã‚’ä¸€ä½“åŒ–ã—ã€ãƒªãƒ¼ã‚±ãƒ¼ã‚¸ã‚’é˜²ã’ã¾ã™ã€‚</p>

<pre><code class="language-python">import numpy as np
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import cross_val_score, StratifiedKFold
from sklearn.datasets import make_classification

# ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
X, y = make_classification(n_samples=1000, n_features=20, random_state=42)

# Pipelineã§å‰å‡¦ç†ã¨ãƒ¢ãƒ‡ãƒ«ã‚’çµ±åˆ
pipeline = Pipeline([
    ('scaler', StandardScaler()),
    ('classifier', LogisticRegression(max_iter=200))
])

# äº¤å·®æ¤œè¨¼ï¼ˆå„Foldã§è‡ªå‹•çš„ã«æ­£ã—ãå‰å‡¦ç†ã•ã‚Œã‚‹ï¼‰
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
scores = cross_val_score(pipeline, X, y, cv=cv, scoring='accuracy')

print("=== Pipeline + Cross-Validation ===")
print(f"å„Foldã§è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’ä½¿ã£ã¦æ­£è¦åŒ–ãŒå®Ÿè¡Œã•ã‚Œã¾ã™")
print(f"å¹³å‡ç²¾åº¦: {scores.mean():.4f} Â± {scores.std():.4f}")
</code></pre>

<h3>Pipelineã®ãƒ¡ãƒªãƒƒãƒˆ</h3>

<ul>
<li><strong>å®‰å…¨æ€§</strong>ï¼šãƒªãƒ¼ã‚±ãƒ¼ã‚¸ã‚’æ§‹é€ çš„ã«é˜²æ­¢</li>
<li><strong>ç°¡æ½”æ€§</strong>ï¼šã‚³ãƒ¼ãƒ‰ãŒçŸ­ãèª­ã¿ã‚„ã™ã„</li>
<li><strong>å†ç¾æ€§</strong>ï¼šå‰å‡¦ç†ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒä¸€ç·’ã«ä¿å­˜ã•ã‚Œã‚‹</li>
<li><strong>ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´</strong>ï¼šGridSearchCVã§ã‚‚æ­£ã—ãå‹•ä½œ</li>
</ul>

<blockquote>
<p><strong>ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹</strong>ï¼šå®Ÿå‹™ã§ã¯å¿…ãš<code>Pipeline</code>ã‚’ä½¿ã„ã€å‰å‡¦ç†ã‚’ãƒ¢ãƒ‡ãƒ«ã¨ä¸€ä½“åŒ–ã•ã›ã¾ã—ã‚‡ã†ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚±ãƒ¼ã‚¸ã‚’é˜²ãã€ã‚³ãƒ¼ãƒ‰ã®ä¿å®ˆæ€§ã‚‚å‘ä¸Šã—ã¾ã™ã€‚</p>
</blockquote>

<hr>

<h2>2.7 Group K-Fold</h2>

<h3>ã‚°ãƒ«ãƒ¼ãƒ—æ§‹é€ ã‚’æŒã¤ãƒ‡ãƒ¼ã‚¿</h3>

<p>å®Ÿä¸–ç•Œã®ãƒ‡ãƒ¼ã‚¿ã«ã¯ã€<strong>åŒã˜ã‚°ãƒ«ãƒ¼ãƒ—ã«å±ã™ã‚‹ã‚µãƒ³ãƒ—ãƒ«ãŒè¤‡æ•°å­˜åœ¨</strong>ã™ã‚‹ã‚±ãƒ¼ã‚¹ãŒã‚ã‚Šã¾ã™ï¼š</p>

<ul>
<li><strong>åŒ»ç™‚ãƒ‡ãƒ¼ã‚¿</strong>ï¼šåŒã˜æ‚£è€…ã‹ã‚‰è¤‡æ•°ã®æ¸¬å®šå€¤</li>
<li><strong>ç”»åƒãƒ‡ãƒ¼ã‚¿</strong>ï¼šåŒã˜äººç‰©ã®è¤‡æ•°æšã®å†™çœŸ</li>
<li><strong>æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿</strong>ï¼šåŒã˜åº—èˆ—ã®è¤‡æ•°æ—¥ã®ãƒ‡ãƒ¼ã‚¿</li>
</ul>

<p>é€šå¸¸ã®K-Foldã§ã¯ã€<strong>åŒã˜ã‚°ãƒ«ãƒ¼ãƒ—ã®ãƒ‡ãƒ¼ã‚¿ãŒè¨“ç·´ã¨ãƒ†ã‚¹ãƒˆã«åˆ†æ•£</strong>ã—ã¦ã—ã¾ã„ã€éå¤§è©•ä¾¡ã«ã¤ãªãŒã‚Šã¾ã™ã€‚</p>

<h3>Group K-Foldã®åŸç†</h3>

<p><strong>Group K-Fold</strong>ã¯ã€åŒã˜ã‚°ãƒ«ãƒ¼ãƒ—ã®ãƒ‡ãƒ¼ã‚¿ã‚’å¿…ãšåŒã˜Foldã«é…ç½®ã—ã¾ã™ã€‚</p>

<div class="mermaid">
graph TD
    A[ãƒ‡ãƒ¼ã‚¿<br/>Patient A: 5æš<br/>Patient B: 3æš<br/>Patient C: 4æš] --> B[Group K-Fold]

    B --> C[Fold 1<br/>Patient A ã®å…¨ãƒ‡ãƒ¼ã‚¿]
    B --> D[Fold 2<br/>Patient B ã®å…¨ãƒ‡ãƒ¼ã‚¿]
    B --> E[Fold 3<br/>Patient C ã®å…¨ãƒ‡ãƒ¼ã‚¿]

    F[âŒ é€šå¸¸ã®K-Fold] --> G[Patient A ã®ãƒ‡ãƒ¼ã‚¿ãŒ<br/>è¨“ç·´ã¨ãƒ†ã‚¹ãƒˆã«åˆ†æ•£]

    style A fill:#e1f5ff
    style B fill:#c8e6c9
    style F fill:#ffcdd2
</div>

<h3>å®Ÿè£…ä¾‹</h3>

<pre><code class="language-python">import numpy as np
from sklearn.model_selection import GroupKFold, KFold, cross_val_score
from sklearn.linear_model import LogisticRegression
from sklearn.datasets import make_classification

# ã‚°ãƒ«ãƒ¼ãƒ—æ§‹é€ ã‚’æŒã¤ãƒ‡ãƒ¼ã‚¿ä½œæˆ
X, y = make_classification(n_samples=100, n_features=20, random_state=42)

# ã‚°ãƒ«ãƒ¼ãƒ—IDï¼ˆä¾‹ï¼šæ‚£è€…IDã€åº—èˆ—IDãªã©ï¼‰
# æ‚£è€…1ãŒ30ã‚µãƒ³ãƒ—ãƒ«ã€æ‚£è€…2ãŒ25ã‚µãƒ³ãƒ—ãƒ«ã€æ‚£è€…3ãŒ20ã‚µãƒ³ãƒ—ãƒ«...
groups = np.array([1]*30 + [2]*25 + [3]*20 + [4]*15 + [5]*10)

print(f"ã‚°ãƒ«ãƒ¼ãƒ—æ•°: {len(np.unique(groups))}")
print(f"å„ã‚°ãƒ«ãƒ¼ãƒ—ã®ã‚µãƒ³ãƒ—ãƒ«æ•°: {[np.sum(groups==g) for g in np.unique(groups)]}\n")

# ãƒ¢ãƒ‡ãƒ«
model = LogisticRegression(max_iter=200)

# Group K-Fold
group_kfold = GroupKFold(n_splits=5)
scores_group = cross_val_score(model, X, y, cv=group_kfold.split(X, y, groups),
                                scoring='accuracy')

print("=== Group K-Fold ===")
print(f"å¹³å‡ç²¾åº¦: {scores_group.mean():.4f} Â± {scores_group.std():.4f}")

# é€šå¸¸ã®K-Foldï¼ˆæ¯”è¼ƒï¼‰
kfold = KFold(n_splits=5, shuffle=True, random_state=42)
scores_kfold = cross_val_score(model, X, y, cv=kfold, scoring='accuracy')

print("\n=== é€šå¸¸ã®K-Foldï¼ˆå‚è€ƒï¼‰ ===")
print(f"å¹³å‡ç²¾åº¦: {scores_kfold.mean():.4f} Â± {scores_kfold.std():.4f}")

print(f"\nå·®åˆ†: {scores_kfold.mean() - scores_group.mean():.4f}")
print("ï¼ˆK-Foldã®æ–¹ãŒè‰¯ã„ = ã‚°ãƒ«ãƒ¼ãƒ—ãƒªãƒ¼ã‚±ãƒ¼ã‚¸ã«ã‚ˆã‚‹éå¤§è©•ä¾¡ï¼‰")
</code></pre>

<h3>å„Foldã®ã‚°ãƒ«ãƒ¼ãƒ—æ§‹æˆã‚’ç¢ºèª</h3>

<pre><code class="language-python">import numpy as np
from sklearn.model_selection import GroupKFold

# ã‚°ãƒ«ãƒ¼ãƒ—K-Foldã®åˆ†å‰²ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç¢ºèª
group_kfold = GroupKFold(n_splits=5)

print("=== Group K-Fold ã®åˆ†å‰²ãƒ‘ã‚¿ãƒ¼ãƒ³ ===")
for i, (train_idx, test_idx) in enumerate(group_kfold.split(X, y, groups), 1):
    train_groups = np.unique(groups[train_idx])
    test_groups = np.unique(groups[test_idx])

    print(f"Fold {i}:")
    print(f"  è¨“ç·´ã‚°ãƒ«ãƒ¼ãƒ—: {train_groups}")
    print(f"  ãƒ†ã‚¹ãƒˆã‚°ãƒ«ãƒ¼ãƒ—: {test_groups}")
    print(f"  è¨“ç·´ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(train_idx)}, ãƒ†ã‚¹ãƒˆã‚µãƒ³ãƒ—ãƒ«æ•°: {len(test_idx)}")
</code></pre>

<h3>ã„ã¤Group K-Foldã‚’ä½¿ã†ã¹ãã‹</h3>

<ul>
<li><strong>å¿…é ˆ</strong>ï¼šåŒã˜ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã‹ã‚‰è¤‡æ•°ã®ã‚µãƒ³ãƒ—ãƒ«ãŒã‚ã‚‹å ´åˆ</li>
<li><strong>æ¨å¥¨</strong>ï¼šåŒ»ç™‚ãƒ‡ãƒ¼ã‚¿ã€æ™‚ç³»åˆ—ã®è¤‡æ•°è¦³æ¸¬ã€ç”»åƒã®è¤‡æ•°ã‚·ãƒ§ãƒƒãƒˆ</li>
<li><strong>æ³¨æ„</strong>ï¼šã‚°ãƒ«ãƒ¼ãƒ—æ•°ãŒå°‘ãªã„ï¼ˆ<10ï¼‰å ´åˆã¯è©•ä¾¡ãŒä¸å®‰å®š</li>
</ul>

<hr>

<h2>2.8 Nested Cross-Validation</h2>

<h3>ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´ã®å•é¡Œ</h3>

<p>ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹éš›ã€ä»¥ä¸‹ã®ã‚ˆã†ãª<strong>é–“é•ã£ãŸã‚¢ãƒ—ãƒ­ãƒ¼ãƒ</strong>ã‚’ã™ã‚‹ã¨ã€ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã«ãƒ•ã‚£ãƒƒãƒˆã—ã¦ã—ã¾ã„ã¾ã™ï¼š</p>

<pre><code class="language-python"># âŒ é–“é•ã£ãŸã‚¢ãƒ—ãƒ­ãƒ¼ãƒ
from sklearn.model_selection import GridSearchCV, train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

# ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã‚’ä½¿ã£ã¦ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´
best_params = try_different_hyperparameters(X_train, y_train, X_test, y_test)

# åŒã˜ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã§æœ€çµ‚è©•ä¾¡ â†’ éå¤§è©•ä¾¡ï¼
final_score = evaluate(best_model, X_test, y_test)
</code></pre>

<h3>Nested CVã®åŸç†</h3>

<p><strong>Nested Cross-Validationï¼ˆå…¥ã‚Œå­äº¤å·®æ¤œè¨¼ï¼‰</strong>ã¯ã€äº¤å·®æ¤œè¨¼ã‚’2æ®µéšã«åˆ†ã‘ã¾ã™ï¼š</p>

<ul>
<li><strong>å¤–å´ã®CV</strong>ï¼šæ±åŒ–æ€§èƒ½ã®è©•ä¾¡</li>
<li><strong>å†…å´ã®CV</strong>ï¼šãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®é¸æŠ</li>
</ul>

<div class="mermaid">
graph TD
    A[å…¨ãƒ‡ãƒ¼ã‚¿] --> B[å¤–å´CV: 5-Fold]

    B --> C[Fold 1]
    B --> D[Fold 2]
    B --> E[Fold 3]

    C --> F[è¨“ç·´ãƒ‡ãƒ¼ã‚¿<br/>80%]
    C --> G[ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿<br/>20%]

    F --> H[å†…å´CV: 5-Fold<br/>ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´]
    H --> I[æœ€è‰¯ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿]
    I --> J[å…¨è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã§å†å­¦ç¿’]
    J --> K[å¤–å´ãƒ†ã‚¹ãƒˆã§è©•ä¾¡]

    style A fill:#e1f5ff
    style H fill:#fff9c4
    style K fill:#c8e6c9
</div>

<h3>å®Ÿè£…ä¾‹</h3>

<pre><code class="language-python">import numpy as np
from sklearn.model_selection import GridSearchCV, cross_val_score, KFold
from sklearn.svm import SVC
from sklearn.datasets import make_classification

# ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
X, y = make_classification(n_samples=500, n_features=20, random_state=42)

# ãƒ¢ãƒ‡ãƒ«ã¨ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç©ºé–“
model = SVC()
param_grid = {
    'C': [0.1, 1, 10, 100],
    'gamma': [0.001, 0.01, 0.1, 1],
    'kernel': ['rbf', 'linear']
}

# å†…å´CVï¼šãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´
inner_cv = KFold(n_splits=3, shuffle=True, random_state=42)
clf = GridSearchCV(
    estimator=model,
    param_grid=param_grid,
    cv=inner_cv,
    scoring='accuracy',
    n_jobs=-1
)

# å¤–å´CVï¼šæ±åŒ–æ€§èƒ½è©•ä¾¡
outer_cv = KFold(n_splits=5, shuffle=True, random_state=42)
nested_scores = cross_val_score(clf, X, y, cv=outer_cv, scoring='accuracy')

print("=== Nested Cross-Validation ===")
print(f"å¤–å´CVã®å„Foldã‚¹ã‚³ã‚¢: {nested_scores}")
print(f"å¹³å‡ç²¾åº¦: {nested_scores.mean():.4f} Â± {nested_scores.std():.4f}")

# æ¯”è¼ƒï¼šé€šå¸¸ã®CVï¼ˆãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å›ºå®šï¼‰
simple_model = SVC(C=1.0, gamma=0.01, kernel='rbf')
simple_scores = cross_val_score(simple_model, X, y, cv=outer_cv, scoring='accuracy')

print("\n=== é€šå¸¸ã®CVï¼ˆC=1.0, gamma=0.01 å›ºå®šï¼‰ ===")
print(f"å¹³å‡ç²¾åº¦: {simple_scores.mean():.4f} Â± {simple_scores.std():.4f}")
</code></pre>

<h3>Nested CVã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹</h3>

<ul>
<li><strong>å¤–å´CV</strong>ï¼šK=5ã¾ãŸã¯10ï¼ˆæ±åŒ–æ€§èƒ½ã®ä¿¡é ¼æ€§ã®é«˜ã„æ¨å®šï¼‰</li>
<li><strong>å†…å´CV</strong>ï¼šK=3ã¾ãŸã¯5ï¼ˆè¨ˆç®—ã‚³ã‚¹ãƒˆã¨ã®ãƒãƒ©ãƒ³ã‚¹ï¼‰</li>
<li><strong>ç·è¨“ç·´å›æ•°</strong>ï¼šå¤–å´K Ã— å†…å´K Ã— ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°</li>
<li><strong>ä¸¦åˆ—åŒ–</strong>ï¼š<code>n_jobs=-1</code>ã§é«˜é€ŸåŒ–</li>
</ul>

<h3>è¨ˆç®—ã‚³ã‚¹ãƒˆã®ä¾‹</h3>

<table>
<thead>
<tr>
<th>è¨­å®š</th>
<th>è¨“ç·´å›æ•°</th>
<th>æ¨å¥¨ã‚±ãƒ¼ã‚¹</th>
</tr>
</thead>
<tbody>
<tr>
<td>å¤–å´5 Ã— å†…å´3</td>
<td>15å› Ã— ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°</td>
<td>æ¨™æº–çš„ãªè¨­å®š</td>
</tr>
<tr>
<td>å¤–å´5 Ã— å†…å´5</td>
<td>25å› Ã— ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°</td>
<td>é«˜ç²¾åº¦ãŒå¿…è¦ãªå ´åˆ</td>
</tr>
<tr>
<td>å¤–å´10 Ã— å†…å´5</td>
<td>50å› Ã— ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°</td>
<td>å°ã€œä¸­è¦æ¨¡ãƒ‡ãƒ¼ã‚¿</td>
</tr>
</tbody>
</table>

<blockquote>
<p><strong>æ³¨æ„</strong>ï¼šNested CVã¯è¨ˆç®—ã‚³ã‚¹ãƒˆãŒé«˜ã„ãŸã‚ã€å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã‚„ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ã§ã¯å®Ÿç”¨çš„ã§ãªã„å ´åˆãŒã‚ã‚Šã¾ã™ã€‚ãã®å ´åˆã¯ã€Hold-outæ³•ã§æ¤œè¨¼ã‚»ãƒƒãƒˆã‚’æ˜ç¤ºçš„ã«åˆ†é›¢ã—ã€ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã¯æœ€å¾Œã¾ã§è§¦ã‚‰ãªã„æˆ¦ç•¥ã‚’å–ã‚Šã¾ã™ã€‚</p>
</blockquote>

<hr>

<h2>2.9 äº¤å·®æ¤œè¨¼ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹</h2>

<h3>ã‚¿ã‚¹ã‚¯åˆ¥ã®äº¤å·®æ¤œè¨¼é¸æŠãƒ•ãƒ­ãƒ¼ãƒãƒ£ãƒ¼ãƒˆ</h3>

<div class="mermaid">
graph TD
    A[ãƒ‡ãƒ¼ã‚¿åˆ†æé–‹å§‹] --> B{æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿?}
    B -->|Yes| C[TimeSeriesSplit]
    B -->|No| D{ã‚°ãƒ«ãƒ¼ãƒ—æ§‹é€ ?}

    D -->|Yes| E[GroupKFold]
    D -->|No| F{åˆ†é¡ã‚¿ã‚¹ã‚¯?}

    F -->|Yes| G{ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡?}
    G -->|Yes| H[StratifiedKFold]
    G -->|No| I{ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º?}

    F -->|No| J[å›å¸°ã‚¿ã‚¹ã‚¯]
    J --> I

    I -->|N < 100| K[LeaveOneOut]
    I -->|N >= 100| L[KFold K=5 or 10]

    H --> M{ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´?}
    L --> M
    K --> M
    C --> M
    E --> M

    M -->|Yes| N[Nested CV]
    M -->|No| O[é€šå¸¸ã®CV]

    style A fill:#e1f5ff
    style C fill:#b3e5fc
    style E fill:#81d4fa
    style H fill:#4fc3f7
    style N fill:#c8e6c9
</div>

<h3>ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆï¼šãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚±ãƒ¼ã‚¸é˜²æ­¢</h3>

<ul>
<li>âœ… <strong>å‰å‡¦ç†</strong>ï¼šåˆ†å‰²å¾Œã«è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®ã¿ã§å­¦ç¿’ï¼ˆStandardScalerç­‰ï¼‰</li>
<li>âœ… <strong>ç‰¹å¾´é‡é¸æŠ</strong>ï¼šå„Foldå†…ã§ç‹¬ç«‹ã—ã¦å®Ÿè¡Œ</li>
<li>âœ… <strong>æ¬ æå€¤è£œå®Œ</strong>ï¼šè¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆé‡ã®ã¿ä½¿ç”¨</li>
<li>âœ… <strong>Pipelineä½¿ç”¨</strong>ï¼šå‰å‡¦ç†ã¨ãƒ¢ãƒ‡ãƒ«ã‚’çµ±åˆ</li>
<li>âœ… <strong>æ™‚ç³»åˆ—</strong>ï¼šTimeSeriesSplitã‚’ä½¿ç”¨</li>
<li>âœ… <strong>ã‚°ãƒ«ãƒ¼ãƒ—</strong>ï¼šGroupKFoldã§åŒä¸€ã‚°ãƒ«ãƒ¼ãƒ—ã‚’åˆ†é›¢</li>
<li>âœ… <strong>ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆ</strong>ï¼šæœ€çµ‚è©•ä¾¡ã¾ã§ä¸€åˆ‡è§¦ã‚‰ãªã„</li>
</ul>

<h3>ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–</h3>

<pre><code class="language-python">from sklearn.model_selection import cross_val_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.datasets import make_classification

X, y = make_classification(n_samples=10000, n_features=50, random_state=42)

# n_jobs=-1 ã§ä¸¦åˆ—åŒ–ï¼ˆå…¨CPUã‚³ã‚¢ã‚’ä½¿ç”¨ï¼‰
model = RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state=42)

# cross_val_score ã§ã‚‚ä¸¦åˆ—åŒ–å¯èƒ½
from sklearn.model_selection import StratifiedKFold
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

# ä¸¦åˆ—å®Ÿè¡Œï¼ˆæ¨å¥¨ï¼‰
scores = cross_val_score(model, X, y, cv=cv, scoring='accuracy', n_jobs=-1)
print(f"ä¸¦åˆ—å®Ÿè¡Œ: å¹³å‡ç²¾åº¦ = {scores.mean():.4f}")
</code></pre>

<h3>å®Ÿå‹™ã§ã®äº¤å·®æ¤œè¨¼æˆ¦ç•¥</h3>

<table>
<thead>
<tr>
<th>ãƒ•ã‚§ãƒ¼ã‚º</th>
<th>æ¨å¥¨æ‰‹æ³•</th>
<th>ç†ç”±</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>åˆæœŸæ¢ç´¢</strong></td>
<td>3-Fold CV</td>
<td>é«˜é€Ÿã«ãƒ¢ãƒ‡ãƒ«ã®æ–¹å‘æ€§ã‚’ç¢ºèª</td>
</tr>
<tr>
<td><strong>ãƒ¢ãƒ‡ãƒ«é–‹ç™º</strong></td>
<td>5-Fold Stratified CV</td>
<td>ãƒãƒ©ãƒ³ã‚¹ã¨è¨ˆç®—ã‚³ã‚¹ãƒˆã®æœ€é©åŒ–</td>
</tr>
<tr>
<td><strong>ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´</strong></td>
<td>Nested CV (5Ã—3)</td>
<td>éå­¦ç¿’ã‚’é˜²ããªãŒã‚‰ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°</td>
</tr>
<tr>
<td><strong>æœ€çµ‚è©•ä¾¡</strong></td>
<td>Hold-out Test Set</td>
<td>æœªä½¿ç”¨ãƒ‡ãƒ¼ã‚¿ã§çœŸã®æ±åŒ–æ€§èƒ½æ¸¬å®š</td>
</tr>
</tbody>
</table>

<h3>ã¾ã¨ã‚ï¼šæ¨å¥¨ã•ã‚Œã‚‹å®Ÿè£…ãƒ‘ã‚¿ãƒ¼ãƒ³</h3>

<pre><code class="language-python">import numpy as np
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import StratifiedKFold, cross_val_score
from sklearn.datasets import make_classification

# ãƒ‡ãƒ¼ã‚¿æº–å‚™
X, y = make_classification(n_samples=1000, n_features=20, random_state=42)

# ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ï¼šPipeline + Stratified K-Fold
pipeline = Pipeline([
    ('scaler', StandardScaler()),  # å‰å‡¦ç†
    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))
])

# Stratified K-Foldï¼ˆåˆ†é¡ã‚¿ã‚¹ã‚¯ã®æ¨™æº–ï¼‰
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

# äº¤å·®æ¤œè¨¼å®Ÿè¡Œ
scores = cross_val_score(
    pipeline, X, y,
    cv=cv,
    scoring='accuracy',
    n_jobs=-1  # ä¸¦åˆ—åŒ–
)

print("=== æ¨å¥¨å®Ÿè£…ãƒ‘ã‚¿ãƒ¼ãƒ³ ===")
print(f"å¹³å‡ç²¾åº¦: {scores.mean():.4f}")
print(f"æ¨™æº–åå·®: {scores.std():.4f}")
print(f"95%ä¿¡é ¼åŒºé–“: [{scores.mean() - 1.96*scores.std():.4f}, "
      f"{scores.mean() + 1.96*scores.std():.4f}]")
</code></pre>

<hr>

<h2>æ¼”ç¿’å•é¡Œ</h2>

<details>
<summary><strong>æ¼”ç¿’1ï¼šHold-outæ³•ã¨K-Foldã®æ¯”è¼ƒ</strong></summary>

<p>ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã‚’å®Œæˆã•ã›ã€Hold-outæ³•ï¼ˆãƒ†ã‚¹ãƒˆ20%ï¼‰ã¨5-Fold CVã®æ€§èƒ½ã‚’æ¯”è¼ƒã—ã¦ãã ã•ã„ã€‚ã©ã¡ã‚‰ãŒã‚ˆã‚Šå®‰å®šã—ãŸè©•ä¾¡ã‚’ä¸ãˆã¾ã™ã‹ï¼Ÿ</p>

<pre><code class="language-python">from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split, cross_val_score, KFold
from sklearn.tree import DecisionTreeClassifier

# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
data = load_breast_cancer()
X, y = data.data, data.target

# TODO: Hold-outæ³•ã§è©•ä¾¡
# ãƒ’ãƒ³ãƒˆ: train_test_split ã‚’ä½¿ç”¨

# TODO: 5-Fold CVã§è©•ä¾¡
# ãƒ’ãƒ³ãƒˆ: cross_val_score ã‚’ä½¿ç”¨

# TODO: çµæœã‚’æ¯”è¼ƒ
</code></pre>

</details>

<details>
<summary><strong>æ¼”ç¿’2ï¼šStratified K-Foldã®é‡è¦æ€§</strong></summary>

<p>ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿ï¼ˆæ­£ä¾‹5%ï¼‰ã‚’ä½œæˆã—ã€é€šå¸¸ã®K-Foldã¨Stratified K-Foldã§ã‚¯ãƒ©ã‚¹åˆ†å¸ƒãŒã©ã†ç•°ãªã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚</p>

<pre><code class="language-python">from sklearn.datasets import make_classification
from sklearn.model_selection import KFold, StratifiedKFold
import numpy as np

# ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
X, y = make_classification(
    n_samples=1000,
    weights=[0.95, 0.05],  # 5% positive class
    random_state=42
)

# TODO: å„Foldã®ã‚¯ãƒ©ã‚¹åˆ†å¸ƒã‚’ç¢ºèª
# ãƒ’ãƒ³ãƒˆ: å„Foldã®y_testã§ã‚¯ãƒ©ã‚¹1ã®å‰²åˆã‚’è¨ˆç®—
</code></pre>

</details>

<details>
<summary><strong>æ¼”ç¿’3ï¼šæ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã®äº¤å·®æ¤œè¨¼</strong></summary>

<p>æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã§é€šå¸¸ã®K-Foldã¨TimeSeriesSplitã‚’æ¯”è¼ƒã—ã€æƒ…å ±ãƒªãƒ¼ã‚±ãƒ¼ã‚¸ã®å½±éŸ¿ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚</p>

<pre><code class="language-python">import numpy as np
import pandas as pd
from sklearn.model_selection import KFold, TimeSeriesSplit
from sklearn.linear_model import Ridge

# æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
np.random.seed(42)
n = 200
t = np.arange(n)
y = 0.5 * t + 10 * np.sin(t / 10) + np.random.randn(n) * 5

# ç‰¹å¾´é‡ï¼ˆéå»ã®å€¤ï¼‰
X = np.column_stack([np.roll(y, i) for i in range(1, 6)])
X, y = X[5:], y[5:]

# TODO: K-Foldã¨TimeSeriesSplitã§è©•ä¾¡ã‚’æ¯”è¼ƒ
# ã©ã¡ã‚‰ã®æ–¹ãŒRMSEãŒè‰¯ã„ã§ã™ã‹ï¼Ÿãã®ç†ç”±ã¯ï¼Ÿ
</code></pre>

</details>

<details>
<summary><strong>æ¼”ç¿’4ï¼šãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚±ãƒ¼ã‚¸ã®æ¤œå‡º</strong></summary>

<p>ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã«ã¯ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚±ãƒ¼ã‚¸ãŒã‚ã‚Šã¾ã™ã€‚ã©ã“ãŒå•é¡Œã§ã€ã©ã†ä¿®æ­£ã™ã¹ãã§ã™ã‹ï¼Ÿ</p>

<pre><code class="language-python">from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import cross_val_score, KFold
from sklearn.linear_model import LogisticRegression
from sklearn.datasets import make_classification

X, y = make_classification(n_samples=500, n_features=20, random_state=42)

# å…¨ãƒ‡ãƒ¼ã‚¿ã§æ­£è¦åŒ–
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# äº¤å·®æ¤œè¨¼
model = LogisticRegression(max_iter=200)
cv = KFold(n_splits=5, shuffle=True, random_state=42)
scores = cross_val_score(model, X_scaled, y, cv=cv)

print(f"ç²¾åº¦: {scores.mean():.4f}")

# TODO: ã“ã®å®Ÿè£…ã®å•é¡Œç‚¹ã‚’æŒ‡æ‘˜ã—ã€Pipelineã‚’ä½¿ã£ã¦ä¿®æ­£ã—ã¦ãã ã•ã„
</code></pre>

</details>

<details>
<summary><strong>æ¼”ç¿’5ï¼šNested CVã®å®Ÿè£…</strong></summary>

<p>SVMã®ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆCã¨Gammaï¼‰ã‚’Nested CVã§èª¿æ•´ã—ã€çœŸã®æ±åŒ–æ€§èƒ½ã‚’æ¨å®šã—ã¦ãã ã•ã„ã€‚</p>

<pre><code class="language-python">from sklearn.model_selection import GridSearchCV, cross_val_score, KFold
from sklearn.svm import SVC
from sklearn.datasets import load_digits

# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
digits = load_digits()
X, y = digits.data, digits.target

# TODO: Nested CVã‚’å®Ÿè£…
# å¤–å´CV: 5-Fold
# å†…å´CV: 3-Fold
# ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: C=[0.1, 1, 10], gamma=[0.001, 0.01, 0.1]

# ãƒ’ãƒ³ãƒˆ: GridSearchCVã‚’cross_val_scoreã«æ¸¡ã™
</code></pre>

</details>

<hr>

<h2>ã¾ã¨ã‚</h2>

<p>ã“ã®ç« ã§ã¯ã€ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ã®è¦ã¨ãªã‚‹<strong>äº¤å·®æ¤œè¨¼ã¨ãƒ‡ãƒ¼ã‚¿åˆ†å‰²</strong>ã«ã¤ã„ã¦å­¦ã³ã¾ã—ãŸã€‚</p>

<h3>é‡è¦ãƒã‚¤ãƒ³ãƒˆ</h3>

<ul>
<li><strong>Hold-outæ³•</strong>ã¯ç°¡å˜ã ãŒä¸å®‰å®šã€‚K-Fold CVã§å®‰å®šã—ãŸè©•ä¾¡ã‚’å¾—ã‚‹</li>
<li><strong>K-Fold CV</strong>ï¼šãƒ‡ãƒ¼ã‚¿ã‚’æœ‰åŠ¹æ´»ç”¨ã—ã€è¤‡æ•°å›ã®è©•ä¾¡ã§ä¿¡é ¼æ€§ã‚’å‘ä¸Š</li>
<li><strong>Stratified K-Fold</strong>ï¼šåˆ†é¡å•é¡Œã§ã¯å¿…é ˆã€‚ã‚¯ãƒ©ã‚¹æ¯”ç‡ã‚’ä¿æŒ</li>
<li><strong>TimeSeriesSplit</strong>ï¼šæ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã§ã¯æ™‚é–“é †åºã‚’å®ˆã‚‹</li>
<li><strong>Group K-Fold</strong>ï¼šåŒã˜ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã®ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†é›¢</li>
<li><strong>ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚±ãƒ¼ã‚¸</strong>ï¼šPipelineã§é˜²æ­¢ã€‚å‰å‡¦ç†ã¯è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®ã¿ã§å­¦ç¿’</li>
<li><strong>Nested CV</strong>ï¼šãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´ã¨æ€§èƒ½è©•ä¾¡ã‚’åˆ†é›¢</li>
</ul>

<h3>æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—</h3>

<p>æ¬¡ç« ã§ã¯ã€äº¤å·®æ¤œè¨¼ã§å¾—ãŸã‚¹ã‚³ã‚¢ã‚’ã‚‚ã¨ã«ã€ã•ã¾ã–ã¾ãª<strong>è©•ä¾¡æŒ‡æ¨™</strong>ï¼ˆç²¾åº¦ã€é©åˆç‡ã€å†ç¾ç‡ã€F1ã‚¹ã‚³ã‚¢ã€AUC-ROCãªã©ï¼‰ã‚’å­¦ã³ã€ã‚¿ã‚¹ã‚¯ã«å¿œã˜ãŸé©åˆ‡ãªæŒ‡æ¨™é¸æŠã‚’ç¿’å¾—ã—ã¾ã™ã€‚</p>

<div class="navigation">
    <a href="chapter1-evaluation-basics.html" class="nav-button">â† ç¬¬1ç« ï¼šãƒ¢ãƒ‡ãƒ«è©•ä¾¡ã®åŸºç¤</a>
    <a href="chapter3-classification-metrics.html" class="nav-button">ç¬¬3ç« ï¼šåˆ†é¡è©•ä¾¡æŒ‡æ¨™ â†’</a>
</div>

</main>


    <section class="disclaimer">
        <h3>å…è²¬äº‹é …</h3>
        <ul>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯æ•™è‚²ãƒ»ç ”ç©¶ãƒ»æƒ…å ±æä¾›ã®ã¿ã‚’ç›®çš„ã¨ã—ã¦ãŠã‚Šã€å°‚é–€çš„ãªåŠ©è¨€(æ³•å¾‹ãƒ»ä¼šè¨ˆãƒ»æŠ€è¡“çš„ä¿è¨¼ãªã©)ã‚’æä¾›ã™ã‚‹ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŠã‚ˆã³ä»˜éšã™ã‚‹ã‚³ãƒ¼ãƒ‰ä¾‹ã¯ã€Œç¾çŠ¶æœ‰å§¿(AS IS)ã€ã§æä¾›ã•ã‚Œã€æ˜ç¤ºã¾ãŸã¯é»™ç¤ºã‚’å•ã‚ãšã€å•†å“æ€§ã€ç‰¹å®šç›®çš„é©åˆæ€§ã€æ¨©åˆ©éä¾µå®³ã€æ­£ç¢ºæ€§ãƒ»å®Œå…¨æ€§ã€å‹•ä½œãƒ»å®‰å…¨æ€§ç­‰ã„ã‹ãªã‚‹ä¿è¨¼ã‚‚ã—ã¾ã›ã‚“ã€‚</li>
            <li>å¤–éƒ¨ãƒªãƒ³ã‚¯ã€ç¬¬ä¸‰è€…ãŒæä¾›ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ»ãƒ„ãƒ¼ãƒ«ãƒ»ãƒ©ã‚¤ãƒ–ãƒ©ãƒªç­‰ã®å†…å®¹ãƒ»å¯ç”¨æ€§ãƒ»å®‰å…¨æ€§ã«ã¤ã„ã¦ã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯ä¸€åˆ‡ã®è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®åˆ©ç”¨ãƒ»å®Ÿè¡Œãƒ»è§£é‡ˆã«ã‚ˆã‚Šç›´æ¥çš„ãƒ»é–“æ¥çš„ãƒ»ä»˜éšçš„ãƒ»ç‰¹åˆ¥ãƒ»çµæœçš„ãƒ»æ‡²ç½°çš„æå®³ãŒç”Ÿã˜ãŸå ´åˆã§ã‚‚ã€é©ç”¨æ³•ã§è¨±å®¹ã•ã‚Œã‚‹æœ€å¤§é™ã®ç¯„å›²ã§ã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å†…å®¹ã¯ã€äºˆå‘Šãªãå¤‰æ›´ãƒ»æ›´æ–°ãƒ»æä¾›åœæ­¢ã•ã‚Œã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®è‘—ä½œæ¨©ãƒ»ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯æ˜è¨˜ã•ã‚ŒãŸæ¡ä»¶(ä¾‹: CC BY 4.0)ã«å¾“ã„ã¾ã™ã€‚å½“è©²ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯é€šå¸¸ã€ç„¡ä¿è¨¼æ¡é …ã‚’å«ã¿ã¾ã™ã€‚</li>
        </ul>
    </section>

<footer>
    <p>&copy; 2024 AI Terakoya. All rights reserved.</p>
</footer>

</body>
</html>
