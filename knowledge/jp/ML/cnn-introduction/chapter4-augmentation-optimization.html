<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ç¬¬4ç« ï¼šãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã¨ãƒ¢ãƒ‡ãƒ«æœ€é©åŒ– - AI Terakoya</title>

    <style>
        :root {
            --color-primary: #2c3e50;
            --color-primary-dark: #1a252f;
            --color-accent: #7b2cbf;
            --color-accent-light: #9d4edd;
            --color-text: #2d3748;
            --color-text-light: #4a5568;
            --color-bg: #ffffff;
            --color-bg-alt: #f7fafc;
            --color-border: #e2e8f0;
            --color-code-bg: #f8f9fa;
            --color-link: #3182ce;
            --color-link-hover: #2c5aa0;
            --spacing-xs: 0.5rem;
            --spacing-sm: 1rem;
            --spacing-md: 1.5rem;
            --spacing-lg: 2rem;
            --spacing-xl: 3rem;
            --font-body: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            --font-mono: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;
            --border-radius: 8px;
            --box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body { font-family: var(--font-body); line-height: 1.7; color: var(--color-text); background-color: var(--color-bg); font-size: 16px; }
        header { background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%); color: white; padding: var(--spacing-xl) var(--spacing-md); margin-bottom: var(--spacing-xl); box-shadow: var(--box-shadow); }
        .header-content { max-width: 900px; margin: 0 auto; }
        h1 { font-size: 2rem; font-weight: 700; margin-bottom: var(--spacing-sm); line-height: 1.2; }
        .subtitle { font-size: 1.1rem; opacity: 0.95; font-weight: 400; margin-bottom: var(--spacing-md); }
        .meta { display: flex; flex-wrap: wrap; gap: var(--spacing-md); font-size: 0.9rem; opacity: 0.9; }
        .meta-item { display: flex; align-items: center; gap: 0.3rem; }
        .container { max-width: 900px; margin: 0 auto; padding: 0 var(--spacing-md) var(--spacing-xl); }
        h2 { font-size: 1.75rem; color: var(--color-primary); margin-top: var(--spacing-xl); margin-bottom: var(--spacing-md); padding-bottom: var(--spacing-xs); border-bottom: 3px solid var(--color-accent); }
        h3 { font-size: 1.4rem; color: var(--color-primary); margin-top: var(--spacing-lg); margin-bottom: var(--spacing-sm); }
        h4 { font-size: 1.1rem; color: var(--color-primary-dark); margin-top: var(--spacing-md); margin-bottom: var(--spacing-sm); }
        p { margin-bottom: var(--spacing-md); color: var(--color-text); }
        a { color: var(--color-link); text-decoration: none; transition: color 0.2s; }
        a:hover { color: var(--color-link-hover); text-decoration: underline; }
        ul, ol { margin-left: var(--spacing-lg); margin-bottom: var(--spacing-md); }
        li { margin-bottom: var(--spacing-xs); color: var(--color-text); }
        pre { background-color: var(--color-code-bg); border: 1px solid var(--color-border); border-radius: var(--border-radius); padding: var(--spacing-md); overflow-x: auto; margin-bottom: var(--spacing-md); font-family: var(--font-mono); font-size: 0.9rem; line-height: 1.5; }
        code { font-family: var(--font-mono); font-size: 0.9em; background-color: var(--color-code-bg); padding: 0.2em 0.4em; border-radius: 3px; }
        pre code { background-color: transparent; padding: 0; }
        table { width: 100%; border-collapse: collapse; margin-bottom: var(--spacing-md); font-size: 0.95rem; }
        th, td { border: 1px solid var(--color-border); padding: var(--spacing-sm); text-align: left; }
        th { background-color: var(--color-bg-alt); font-weight: 600; color: var(--color-primary); }
        blockquote { border-left: 4px solid var(--color-accent); padding-left: var(--spacing-md); margin: var(--spacing-md) 0; color: var(--color-text-light); font-style: italic; background-color: var(--color-bg-alt); padding: var(--spacing-md); border-radius: var(--border-radius); }
        .mermaid { text-align: center; margin: var(--spacing-lg) 0; background-color: var(--color-bg-alt); padding: var(--spacing-md); border-radius: var(--border-radius); }
        details { background-color: var(--color-bg-alt); border: 1px solid var(--color-border); border-radius: var(--border-radius); padding: var(--spacing-md); margin-bottom: var(--spacing-md); }
        summary { cursor: pointer; font-weight: 600; color: var(--color-primary); user-select: none; padding: var(--spacing-xs); margin: calc(-1 * var(--spacing-md)); padding: var(--spacing-md); border-radius: var(--border-radius); }
        summary:hover { background-color: rgba(123, 44, 191, 0.1); }
        details[open] summary { margin-bottom: var(--spacing-md); border-bottom: 1px solid var(--color-border); }
        .navigation { display: flex; justify-content: space-between; gap: var(--spacing-md); margin: var(--spacing-xl) 0; padding-top: var(--spacing-lg); border-top: 2px solid var(--color-border); }
        .nav-button { flex: 1; padding: var(--spacing-md); background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%); color: white; border-radius: var(--border-radius); text-align: center; font-weight: 600; transition: transform 0.2s, box-shadow 0.2s; box-shadow: var(--box-shadow); }
        .nav-button:hover { transform: translateY(-2px); box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15); text-decoration: none; }
        footer { margin-top: var(--spacing-xl); padding: var(--spacing-lg) var(--spacing-md); background-color: var(--color-bg-alt); border-top: 1px solid var(--color-border); text-align: center; font-size: 0.9rem; color: var(--color-text-light); }
        .disclaimer {
            max-width: 900px;
            margin: 2rem auto;
            padding: 1.5rem;
            background: #f8f9fa;
            border-left: 4px solid #6c757d;
            border-radius: 4px;
        }

        .disclaimer h3 {
            color: #495057;
            margin-bottom: 1rem;
            font-size: 1.1rem;
        }

        .disclaimer ul {
            list-style: none;
            padding-left: 0;
        }

        .disclaimer li {
            padding: 0.5rem 0;
            padding-left: 1.5rem;
            position: relative;
            font-size: 0.9rem;
            color: #6c757d;
            line-height: 1.6;
        }

        .disclaimer li::before {
            content: "âš ï¸";
            position: absolute;
            left: 0;
        }

        .project-box { background: linear-gradient(135deg, #e3f2fd 0%, #bbdefb 50%); border-radius: var(--border-radius); padding: var(--spacing-lg); margin: var(--spacing-lg) 0; box-shadow: var(--box-shadow); }
        @media (max-width: 768px) { h1 { font-size: 1.5rem; } h2 { font-size: 1.4rem; } h3 { font-size: 1.2rem; } .meta { font-size: 0.85rem; } .navigation { flex-direction: column; } table { font-size: 0.85rem; } th, td { padding: var(--spacing-xs); } }
    
        
    
        /* Breadcrumb styles */
        .breadcrumb {
            background: #f7fafc;
            padding: 0.75rem 1rem;
            border-bottom: 1px solid #e2e8f0;
            font-size: 0.9rem;
        }

        .breadcrumb-content {
            max-width: 900px;
            margin: 0 auto;
            display: flex;
            align-items: center;
            flex-wrap: wrap;
            gap: 0.5rem;
        }

        .breadcrumb a {
            color: #667eea;
            text-decoration: none;
            transition: color 0.2s;
        }

        .breadcrumb a:hover {
            color: #764ba2;
            text-decoration: underline;
        }

        .breadcrumb-separator {
            color: #a0aec0;
            margin: 0 0.25rem;
        }

        .breadcrumb-current {
            color: #4a5568;
            font-weight: 500;
        }
    </style>

    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
        mermaid.initialize({ startOnLoad: true, theme: 'default' });
    </script>
    <script>
        MathJax = {
            tex: { inlineMath: [['$', '$'], ['\\(', '\\)']], displayMath: [['$$', '$$'], ['\\[', '\\]']], processEscapes: true, processEnvironments: true },
            options: { skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'], ignoreHtmlClass: 'mermaid' }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" async></script>
</head>
<body>
            <nav class="breadcrumb">
        <div class="breadcrumb-content">
            <a href="../../index.html">AIå¯ºå­å±‹ãƒˆãƒƒãƒ—</a><span class="breadcrumb-separator">â€º</span><a href="../../ML/index.html">æ©Ÿæ¢°å­¦ç¿’</a><span class="breadcrumb-separator">â€º</span><a href="../../ML/cnn-introduction/index.html">Cnn</a><span class="breadcrumb-separator">â€º</span><span class="breadcrumb-current">Chapter 4</span>
        </div>
    </nav>

        <header>
        <div class="header-content">
            <h1>ç¬¬4ç« ï¼šãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã¨ãƒ¢ãƒ‡ãƒ«æœ€é©åŒ–</h1>
            <p class="subtitle">é™ã‚‰ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‹ã‚‰é«˜æ€§èƒ½ã‚’å¼•ãå‡ºã™ãŸã‚ã®å®Ÿè·µçš„ãƒ†ã‚¯ãƒ‹ãƒƒã‚¯é›†</p>
            <div class="meta">
                <span class="meta-item">ğŸ“– èª­äº†æ™‚é–“: 23åˆ†</span>
                <span class="meta-item">ğŸ“Š é›£æ˜“åº¦: ä¸­ç´šã€œä¸Šç´š</span>
                <span class="meta-item">ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹: 10å€‹</span>
                <span class="meta-item">ğŸ“ æ¼”ç¿’å•é¡Œ: 6å•</span>
            </div>
        </div>
    </header>

    <main class="container">

<h2>å­¦ç¿’ç›®æ¨™</h2>
<p>ã“ã®ç« ã‚’èª­ã‚€ã“ã¨ã§ã€ä»¥ä¸‹ã‚’ç¿’å¾—ã§ãã¾ã™ï¼š</p>
<ul>
<li>âœ… ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã®ç†è«–çš„èƒŒæ™¯ã¨å®Ÿè£…æ–¹æ³•ã‚’ç†è§£ã§ãã‚‹</li>
<li>âœ… åŸºæœ¬çš„ãªæ‹¡å¼µæ‰‹æ³•ï¼ˆFlip, Rotation, Cropï¼‰ã‚’é©ç”¨ã§ãã‚‹</li>
<li>âœ… é«˜åº¦ãªæ‹¡å¼µæ‰‹æ³•ï¼ˆMixup, CutMix, AutoAugmentï¼‰ã‚’å®Ÿè£…ã§ãã‚‹</li>
<li>âœ… æ­£å‰‡åŒ–ãƒ†ã‚¯ãƒ‹ãƒƒã‚¯ï¼ˆLabel Smoothing, Stochastic Depthï¼‰ã‚’æ´»ç”¨ã§ãã‚‹</li>
<li>âœ… Mixed Precision Trainingã§å­¦ç¿’ã‚’é«˜é€ŸåŒ–ã§ãã‚‹</li>
<li>âœ… ãƒ¢ãƒ‡ãƒ«è»½é‡åŒ–ï¼ˆPruning, Quantizationï¼‰ã®åŸºç¤ã‚’ç†è§£ã§ãã‚‹</li>
<li>âœ… æœ€é©åŒ–ã•ã‚ŒãŸè¨“ç·´ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’æ§‹ç¯‰ã§ãã‚‹</li>
</ul>

<hr>

<h2>4.1 ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã®é‡è¦æ€§</h2>

<h3>ãªãœãƒ‡ãƒ¼ã‚¿æ‹¡å¼µãŒå¿…è¦ã‹ï¼Ÿ</h3>

<p>æ·±å±¤å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã¯å¤§é‡ã®ãƒ‡ãƒ¼ã‚¿ã‚’å¿…è¦ã¨ã—ã¾ã™ãŒã€å®Ÿéš›ã«ã¯ååˆ†ãªãƒ‡ãƒ¼ã‚¿ãŒå¾—ã‚‰ã‚Œãªã„ã“ã¨ãŒå¤šã„ã§ã™ã€‚ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã¯ã€æ—¢å­˜ã®ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æ–°ã—ã„ã‚µãƒ³ãƒ—ãƒ«ã‚’ç”Ÿæˆã—ã€ãƒ¢ãƒ‡ãƒ«ã®æ±åŒ–æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹æŠ€è¡“ã§ã™ã€‚</p>

<table>
<thead>
<tr>
<th>èª²é¡Œ</th>
<th>ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã«ã‚ˆã‚‹è§£æ±º</th>
<th>åŠ¹æœ</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>ãƒ‡ãƒ¼ã‚¿ä¸è¶³</strong></td>
<td>æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã®å¤‰å½¢ã§è¨“ç·´ã‚µãƒ³ãƒ—ãƒ«å¢—åŠ </td>
<td>éå­¦ç¿’ã®æŠ‘åˆ¶</td>
</tr>
<tr>
<td><strong>éå­¦ç¿’</strong></td>
<td>å¤šæ§˜ãªãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³å­¦ç¿’</td>
<td>æ±åŒ–æ€§èƒ½å‘ä¸Š</td>
</tr>
<tr>
<td><strong>ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡</strong></td>
<td>å°‘æ•°ã‚¯ãƒ©ã‚¹ã®æ‹¡å¼µ</td>
<td>å…¬å¹³ãªå­¦ç¿’</td>
</tr>
<tr>
<td><strong>ä½ç½®ãƒ»è§’åº¦ä¾å­˜</strong></td>
<td>æ§˜ã€…ãªè¦–ç‚¹ã‹ã‚‰ã®å­¦ç¿’</td>
<td>ãƒ­ãƒã‚¹ãƒˆæ€§å‘ä¸Š</td>
</tr>
<tr>
<td><strong>ç…§æ˜æ¡ä»¶ä¾å­˜</strong></td>
<td>è‰²èª¿ãƒ»æ˜åº¦ã®å¤‰åŒ–å­¦ç¿’</td>
<td>å®Ÿç’°å¢ƒã§ã®æ€§èƒ½å‘ä¸Š</td>
</tr>
</tbody>
</table>

<h3>ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼</h3>

<div class="mermaid">
graph TB
    A[å…ƒç”»åƒãƒ‡ãƒ¼ã‚¿] --> B[åŸºæœ¬å¤‰æ›]
    B --> C[å¹¾ä½•å­¦å¤‰æ›<br/>Flip/Rotation/Crop]
    B --> D[è‰²å¤‰æ›<br/>Brightness/Contrast]
    B --> E[ãƒã‚¤ã‚ºä»˜åŠ <br/>Gaussian/Salt&Pepper]

    C --> F[æ‹¡å¼µãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ]
    D --> F
    E --> F

    F --> G{é«˜åº¦ãªæ‹¡å¼µ}
    G --> H[Mixup]
    G --> I[CutMix]
    G --> J[AutoAugment]

    H --> K[è¨“ç·´ãƒ‡ãƒ¼ã‚¿]
    I --> K
    J --> K

    K --> L[ãƒ¢ãƒ‡ãƒ«è¨“ç·´]
    L --> M[æ±åŒ–æ€§èƒ½å‘ä¸Š]

    style A fill:#7b2cbf,color:#fff
    style G fill:#e74c3c,color:#fff
    style M fill:#27ae60,color:#fff
</div>

<blockquote>
<p><strong>é‡è¦</strong>: ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã¯è¨“ç·´æ™‚ã®ã¿é©ç”¨ã—ã€ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«ã¯é©ç”¨ã—ã¾ã›ã‚“ï¼ˆTest Time Augmentationé™¤ãï¼‰ã€‚ã¾ãŸã€ã‚¿ã‚¹ã‚¯ã«é©ã—ãŸæ‹¡å¼µã‚’é¸æŠã™ã‚‹ã“ã¨ãŒé‡è¦ã§ã™ã€‚</p>
</blockquote>

<hr>

<h2>4.2 åŸºæœ¬çš„ãªãƒ‡ãƒ¼ã‚¿æ‹¡å¼µæ‰‹æ³•</h2>

<h3>4.2.1 torchvision.transformsã«ã‚ˆã‚‹åŸºæœ¬æ‹¡å¼µ</h3>

<p>PyTorchã®<code>torchvision.transforms</code>ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¯ã€ç”»åƒã®åŸºæœ¬çš„ãªæ‹¡å¼µã‚’ç°¡å˜ã«å®Ÿè£…ã§ãã¾ã™ã€‚</p>

<pre><code class="language-python">import torch
import torchvision
import torchvision.transforms as transforms
from torchvision.datasets import CIFAR10
import matplotlib.pyplot as plt
import numpy as np

# åŸºæœ¬çš„ãªæ‹¡å¼µã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
def show_augmentation_examples():
    """æ§˜ã€…ãªæ‹¡å¼µæ‰‹æ³•ã®å¯è¦–åŒ–"""

    # CIFAR10ã‹ã‚‰1æšã®ç”»åƒã‚’å–å¾—
    dataset = CIFAR10(root='./data', train=True, download=True)
    original_image, label = dataset[100]

    # å„ç¨®æ‹¡å¼µã®å®šç¾©
    augmentations = {
        'Original': transforms.ToTensor(),

        'Horizontal Flip': transforms.Compose([
            transforms.RandomHorizontalFlip(p=1.0),
            transforms.ToTensor()
        ]),

        'Rotation (Â±30Â°)': transforms.Compose([
            transforms.RandomRotation(degrees=30),
            transforms.ToTensor()
        ]),

        'Random Crop': transforms.Compose([
            transforms.RandomCrop(32, padding=4),
            transforms.ToTensor()
        ]),

        'Color Jitter': transforms.Compose([
            transforms.ColorJitter(brightness=0.5, contrast=0.5,
                                  saturation=0.5, hue=0.2),
            transforms.ToTensor()
        ]),

        'Random Affine': transforms.Compose([
            transforms.RandomAffine(degrees=15, translate=(0.1, 0.1),
                                   scale=(0.9, 1.1)),
            transforms.ToTensor()
        ]),

        'Gaussian Blur': transforms.Compose([
            transforms.GaussianBlur(kernel_size=5, sigma=(0.1, 2.0)),
            transforms.ToTensor()
        ]),

        'Random Erasing': transforms.Compose([
            transforms.ToTensor(),
            transforms.RandomErasing(p=1.0, scale=(0.02, 0.2))
        ])
    }

    # å¯è¦–åŒ–
    fig, axes = plt.subplots(2, 4, figsize=(16, 8))
    axes = axes.flatten()

    for idx, (name, transform) in enumerate(augmentations.items()):
        img_tensor = transform(original_image)
        img_np = img_tensor.permute(1, 2, 0).numpy()
        img_np = np.clip(img_np, 0, 1)

        axes[idx].imshow(img_np)
        axes[idx].set_title(name, fontsize=12, fontweight='bold')
        axes[idx].axis('off')

    plt.suptitle('åŸºæœ¬çš„ãªãƒ‡ãƒ¼ã‚¿æ‹¡å¼µæ‰‹æ³•ã®æ¯”è¼ƒ', fontsize=16, fontweight='bold', y=1.02)
    plt.tight_layout()
    plt.show()

# å®Ÿè¡Œ
show_augmentation_examples()

# å®Ÿéš›ã®è¨“ç·´ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã§ã®ä½¿ç”¨ä¾‹
print("\n=== è¨“ç·´ç”¨ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ ===")

transform_train = transforms.Compose([
    transforms.RandomCrop(32, padding=4),          # ãƒ©ãƒ³ãƒ€ãƒ ã‚¯ãƒ­ãƒƒãƒ—
    transforms.RandomHorizontalFlip(p=0.5),        # 50%ã®ç¢ºç‡ã§æ°´å¹³åè»¢
    transforms.ColorJitter(brightness=0.2,          # è‰²èª¿å¤‰åŒ–
                          contrast=0.2,
                          saturation=0.2,
                          hue=0.1),
    transforms.ToTensor(),                          # ãƒ†ãƒ³ã‚½ãƒ«å¤‰æ›
    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],  # æ­£è¦åŒ–
                        std=[0.2470, 0.2435, 0.2616]),
    transforms.RandomErasing(p=0.5, scale=(0.02, 0.33))  # ãƒ©ãƒ³ãƒ€ãƒ æ¶ˆå»
])

transform_test = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],
                        std=[0.2470, 0.2435, 0.2616])
])

# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ
trainset = CIFAR10(root='./data', train=True, download=True,
                   transform=transform_train)
testset = CIFAR10(root='./data', train=False, download=True,
                  transform=transform_test)

trainloader = torch.utils.data.DataLoader(trainset, batch_size=128,
                                          shuffle=True, num_workers=2)
testloader = torch.utils.data.DataLoader(testset, batch_size=128,
                                         shuffle=False, num_workers=2)

print(f"è¨“ç·´ãƒ‡ãƒ¼ã‚¿: {len(trainset)} samples")
print(f"ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {len(testset)} samples")
print(f"æ‹¡å¼µã‚ã‚Šè¨“ç·´ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼: {len(trainloader)} batches")
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>=== è¨“ç·´ç”¨ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ ===
è¨“ç·´ãƒ‡ãƒ¼ã‚¿: 50000 samples
ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: 10000 samples
æ‹¡å¼µã‚ã‚Šè¨“ç·´ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼: 391 batches
</code></pre>

<h3>4.2.2 æ‹¡å¼µå¼·åº¦ã®èª¿æ•´ã¨å®Ÿé¨“</h3>

<p>ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã®å¼·åº¦ã¯ã€ã‚¿ã‚¹ã‚¯ã‚„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«å¿œã˜ã¦èª¿æ•´ãŒå¿…è¦ã§ã™ã€‚å¼·ã™ãã‚‹æ‹¡å¼µã¯æ€§èƒ½ã‚’ä½ä¸‹ã•ã›ã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚</p>

<pre><code class="language-python">import torch.nn as nn
import torch.optim as optim
from torchvision.models import resnet18

def train_with_augmentation(transform, epochs=5, model_name='ResNet18'):
    """ç•°ãªã‚‹æ‹¡å¼µè¨­å®šã§ã®ãƒ¢ãƒ‡ãƒ«è¨“ç·´ã¨è©•ä¾¡"""

    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
    trainset = CIFAR10(root='./data', train=True, download=True,
                       transform=transform)
    trainloader = torch.utils.data.DataLoader(trainset, batch_size=128,
                                              shuffle=True, num_workers=2)

    testset = CIFAR10(root='./data', train=False, download=True,
                      transform=transform_test)
    testloader = torch.utils.data.DataLoader(testset, batch_size=128,
                                             shuffle=False, num_workers=2)

    # ãƒ¢ãƒ‡ãƒ«
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = resnet18(num_classes=10).to(device)

    criterion = nn.CrossEntropyLoss()
    optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9,
                         weight_decay=5e-4)
    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)

    # è¨“ç·´ãƒ«ãƒ¼ãƒ—
    train_losses, test_accs = [], []

    for epoch in range(epochs):
        # è¨“ç·´
        model.train()
        running_loss = 0.0
        for inputs, targets in trainloader:
            inputs, targets = inputs.to(device), targets.to(device)

            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, targets)
            loss.backward()
            optimizer.step()

            running_loss += loss.item()

        avg_loss = running_loss / len(trainloader)
        train_losses.append(avg_loss)

        # è©•ä¾¡
        model.eval()
        correct, total = 0, 0
        with torch.no_grad():
            for inputs, targets in testloader:
                inputs, targets = inputs.to(device), targets.to(device)
                outputs = model(inputs)
                _, predicted = outputs.max(1)
                total += targets.size(0)
                correct += predicted.eq(targets).sum().item()

        test_acc = 100. * correct / total
        test_accs.append(test_acc)

        print(f'Epoch [{epoch+1}/{epochs}] Loss: {avg_loss:.4f}, '
              f'Test Acc: {test_acc:.2f}%')

        scheduler.step()

    return train_losses, test_accs

# ç•°ãªã‚‹æ‹¡å¼µå¼·åº¦ã®æ¯”è¼ƒ
print("=== ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µå¼·åº¦ã®æ¯”è¼ƒå®Ÿé¨“ ===\n")

# 1. æ‹¡å¼µãªã—
transform_none = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],
                        std=[0.2470, 0.2435, 0.2616])
])

# 2. å¼±ã„æ‹¡å¼µ
transform_weak = transforms.Compose([
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.RandomCrop(32, padding=4),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],
                        std=[0.2470, 0.2435, 0.2616])
])

# 3. å¼·ã„æ‹¡å¼µ
transform_strong = transforms.Compose([
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.RandomCrop(32, padding=4),
    transforms.ColorJitter(brightness=0.4, contrast=0.4,
                          saturation=0.4, hue=0.2),
    transforms.RandomRotation(degrees=15),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],
                        std=[0.2470, 0.2435, 0.2616]),
    transforms.RandomErasing(p=0.5)
])

# å„è¨­å®šã§è¨“ç·´ï¼ˆå®Ÿéš›ã«ã¯æ™‚é–“ãŒã‹ã‹ã‚‹ãŸã‚ã€ãƒ‡ãƒ¢ã¨ã—ã¦ç°¡ç•¥åŒ–ï¼‰
configs = [
    ('No Augmentation', transform_none),
    ('Weak Augmentation', transform_weak),
    ('Strong Augmentation', transform_strong)
]

results = {}

# æ³¨æ„: å®Ÿéš›ã®å®Ÿè¡Œã«ã¯æ™‚é–“ãŒã‹ã‹ã‚‹ãŸã‚ã€ã“ã“ã§ã¯ã‚¹ã‚­ãƒƒãƒ—
# for name, transform in configs:
#     print(f"\n--- {name} ---")
#     losses, accs = train_with_augmentation(transform, epochs=5)
#     results[name] = {'losses': losses, 'accs': accs}

# ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµæœï¼ˆå®Ÿéš›ã®è¨“ç·´çµæœã®ä¾‹ï¼‰
results = {
    'No Augmentation': {
        'losses': [2.1, 1.8, 1.6, 1.5, 1.4],
        'accs': [62.3, 67.8, 70.2, 71.5, 72.1]
    },
    'Weak Augmentation': {
        'losses': [2.0, 1.7, 1.5, 1.4, 1.3],
        'accs': [65.2, 71.3, 74.8, 76.9, 78.3]
    },
    'Strong Augmentation': {
        'losses': [2.2, 1.9, 1.7, 1.6, 1.5],
        'accs': [61.8, 69.5, 73.6, 76.2, 78.9]
    }
}

# çµæœã®å¯è¦–åŒ–
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))

colors = ['#e74c3c', '#3498db', '#2ecc71']

# è¨“ç·´æå¤±
for (name, data), color in zip(results.items(), colors):
    ax1.plot(range(1, 6), data['losses'], marker='o', linewidth=2,
            label=name, color=color)

ax1.set_xlabel('Epoch', fontsize=12)
ax1.set_ylabel('Training Loss', fontsize=12)
ax1.set_title('è¨“ç·´æå¤±ã®æ¨ç§»', fontsize=14, fontweight='bold')
ax1.legend(fontsize=10)
ax1.grid(alpha=0.3)

# ãƒ†ã‚¹ãƒˆç²¾åº¦
for (name, data), color in zip(results.items(), colors):
    ax2.plot(range(1, 6), data['accs'], marker='s', linewidth=2,
            label=name, color=color)

ax2.set_xlabel('Epoch', fontsize=12)
ax2.set_ylabel('Test Accuracy (%)', fontsize=12)
ax2.set_title('ãƒ†ã‚¹ãƒˆç²¾åº¦ã®æ¨ç§»', fontsize=14, fontweight='bold')
ax2.legend(fontsize=10)
ax2.grid(alpha=0.3)

plt.tight_layout()
plt.show()

print("\n=== æœ€çµ‚çµæœ ===")
for name, data in results.items():
    print(f"{name:25s}: æœ€çµ‚ç²¾åº¦ {data['accs'][-1]:.2f}%")
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>=== æœ€çµ‚çµæœ ===
No Augmentation          : æœ€çµ‚ç²¾åº¦ 72.10%
Weak Augmentation        : æœ€çµ‚ç²¾åº¦ 78.30%
Strong Augmentation      : æœ€çµ‚ç²¾åº¦ 78.90%
</code></pre>

<hr>

<h2>4.3 é«˜åº¦ãªãƒ‡ãƒ¼ã‚¿æ‹¡å¼µæ‰‹æ³•</h2>

<h3>4.3.1 Mixup: ã‚µãƒ³ãƒ—ãƒ«é–“ã®ç·šå½¢è£œé–“</h3>

<p>Mixupã¯ã€2ã¤ã®è¨“ç·´ã‚µãƒ³ãƒ—ãƒ«ã‚’ç·šå½¢è£œé–“ã—ã¦æ–°ã—ã„ã‚µãƒ³ãƒ—ãƒ«ã‚’ç”Ÿæˆã™ã‚‹æ‰‹æ³•ã§ã™ã€‚ç”»åƒã¨ãƒ©ãƒ™ãƒ«ã®ä¸¡æ–¹ã‚’æ··ãœã‚‹ã“ã¨ã§ã€æ±ºå®šå¢ƒç•Œã‚’æ»‘ã‚‰ã‹ã«ã—ã€æ±åŒ–æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã¾ã™ã€‚</p>

<p>$$
\tilde{x} = \lambda x_i + (1 - \lambda) x_j
$$</p>

<p>$$
\tilde{y} = \lambda y_i + (1 - \lambda) y_j
$$</p>

<p>ã“ã“ã§ã€$\lambda \sim \text{Beta}(\alpha, \alpha)$ã€é€šå¸¸ $\alpha = 0.2$ ã¾ãŸã¯ $\alpha = 1.0$ ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚</p>

<pre><code class="language-python">import numpy as np

def mixup_data(x, y, alpha=1.0, device='cpu'):
    """Mixupãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã‚’é©ç”¨

    Args:
        x: å…¥åŠ›ç”»åƒãƒãƒƒãƒ [B, C, H, W]
        y: ãƒ©ãƒ™ãƒ«ãƒãƒƒãƒ [B]
        alpha: Betaåˆ†å¸ƒã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        device: è¨ˆç®—ãƒ‡ãƒã‚¤ã‚¹

    Returns:
        mixed_x: æ··åˆå¾Œã®ç”»åƒ
        y_a, y_b: å…ƒã®ãƒ©ãƒ™ãƒ«ãƒšã‚¢
        lam: æ··åˆä¿‚æ•°
    """
    if alpha > 0:
        lam = np.random.beta(alpha, alpha)
    else:
        lam = 1

    batch_size = x.size(0)
    index = torch.randperm(batch_size).to(device)

    mixed_x = lam * x + (1 - lam) * x[index, :]
    y_a, y_b = y, y[index]

    return mixed_x, y_a, y_b, lam

def mixup_criterion(criterion, pred, y_a, y_b, lam):
    """Mixupç”¨ã®æå¤±é–¢æ•°"""
    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)

# Mixupã‚’ä½¿ã£ãŸè¨“ç·´ã®ãƒ‡ãƒ¢
print("=== Mixup Data Augmentation ===\n")

# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã§å¯è¦–åŒ–
from torchvision.datasets import CIFAR10

dataset = CIFAR10(root='./data', train=True, download=True,
                  transform=transforms.ToTensor())

# 2æšã®ç”»åƒã‚’å–å¾—
img1, label1 = dataset[0]
img2, label2 = dataset[10]

# ç•°ãªã‚‹Î»å€¤ã§Mixup
lambdas = [0.0, 0.25, 0.5, 0.75, 1.0]

fig, axes = plt.subplots(1, len(lambdas), figsize=(15, 3))

for idx, lam in enumerate(lambdas):
    mixed_img = lam * img1 + (1 - lam) * img2
    mixed_img_np = mixed_img.permute(1, 2, 0).numpy()

    axes[idx].imshow(mixed_img_np)
    axes[idx].set_title(f'Î»={lam:.2f}\n({lam:.0%} img1, {(1-lam):.0%} img2)',
                       fontsize=10)
    axes[idx].axis('off')

plt.suptitle('Mixup: ç•°ãªã‚‹æ··åˆæ¯”ç‡ã§ã®å¯è¦–åŒ–', fontsize=14, fontweight='bold')
plt.tight_layout()
plt.show()

# Mixupã‚’çµ„ã¿è¾¼ã‚“ã è¨“ç·´é–¢æ•°
def train_with_mixup(model, trainloader, criterion, optimizer,
                     device, alpha=1.0):
    """Mixupã‚’ä½¿ã£ãŸ1ã‚¨ãƒãƒƒã‚¯ã®è¨“ç·´"""
    model.train()
    train_loss = 0
    correct = 0
    total = 0

    for batch_idx, (inputs, targets) in enumerate(trainloader):
        inputs, targets = inputs.to(device), targets.to(device)

        # Mixupé©ç”¨
        inputs, targets_a, targets_b, lam = mixup_data(inputs, targets,
                                                        alpha, device)

        optimizer.zero_grad()
        outputs = model(inputs)
        loss = mixup_criterion(criterion, outputs, targets_a, targets_b, lam)
        loss.backward()
        optimizer.step()

        train_loss += loss.item()

        # ç²¾åº¦è¨ˆç®—ï¼ˆlambdaã§é‡ã¿ä»˜ã‘ï¼‰
        _, predicted = outputs.max(1)
        total += targets.size(0)
        correct += (lam * predicted.eq(targets_a).sum().float()
                   + (1 - lam) * predicted.eq(targets_b).sum().float())

    return train_loss / len(trainloader), 100. * correct / total

print("Mixupã‚’ä½¿ã£ãŸè¨“ç·´ã®ä¾‹:")
print("  - å…¥åŠ›ç”»åƒã¨ãƒ©ãƒ™ãƒ«ã‚’æ··åˆ")
print("  - Î» ~ Beta(Î±, Î±) ã§ãƒ©ãƒ³ãƒ€ãƒ ã«æ··åˆæ¯”ç‡ã‚’æ±ºå®š")
print("  - æ±ºå®šå¢ƒç•ŒãŒæ»‘ã‚‰ã‹ã«ãªã‚Šã€éå­¦ç¿’ã‚’æŠ‘åˆ¶")
print("  - ä¸€èˆ¬ã« Î±=0.2 ã¾ãŸã¯ Î±=1.0 ã‚’ä½¿ç”¨")
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>=== Mixup Data Augmentation ===

Mixupã‚’ä½¿ã£ãŸè¨“ç·´ã®ä¾‹:
  - å…¥åŠ›ç”»åƒã¨ãƒ©ãƒ™ãƒ«ã‚’æ··åˆ
  - Î» ~ Beta(Î±, Î±) ã§ãƒ©ãƒ³ãƒ€ãƒ ã«æ··åˆæ¯”ç‡ã‚’æ±ºå®š
  - æ±ºå®šå¢ƒç•ŒãŒæ»‘ã‚‰ã‹ã«ãªã‚Šã€éå­¦ç¿’ã‚’æŠ‘åˆ¶
  - ä¸€èˆ¬ã« Î±=0.2 ã¾ãŸã¯ Î±=1.0 ã‚’ä½¿ç”¨
</code></pre>

<h3>4.3.2 CutMix: é ˜åŸŸãƒ™ãƒ¼ã‚¹ã®æ··åˆ</h3>

<p>CutMixã¯ã€ç”»åƒã®ä¸€éƒ¨ã‚’åˆ‡ã‚Šå–ã£ã¦åˆ¥ã®ç”»åƒã«è²¼ã‚Šä»˜ã‘ã‚‹æ‰‹æ³•ã§ã™ã€‚Mixupã¨ç•°ãªã‚Šã€ç”»åƒå…¨ä½“ã§ã¯ãªãå±€æ‰€çš„ãªé ˜åŸŸã‚’æ··åˆã—ã¾ã™ã€‚</p>

<pre><code class="language-python">def cutmix_data(x, y, alpha=1.0, device='cpu'):
    """CutMixãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã‚’é©ç”¨

    Args:
        x: å…¥åŠ›ç”»åƒãƒãƒƒãƒ [B, C, H, W]
        y: ãƒ©ãƒ™ãƒ«ãƒãƒƒãƒ [B]
        alpha: Betaåˆ†å¸ƒã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        device: è¨ˆç®—ãƒ‡ãƒã‚¤ã‚¹

    Returns:
        mixed_x: æ··åˆå¾Œã®ç”»åƒ
        y_a, y_b: å…ƒã®ãƒ©ãƒ™ãƒ«ãƒšã‚¢
        lam: æ··åˆä¿‚æ•°ï¼ˆé¢ç©æ¯”ï¼‰
    """
    if alpha > 0:
        lam = np.random.beta(alpha, alpha)
    else:
        lam = 1

    batch_size = x.size(0)
    index = torch.randperm(batch_size).to(device)

    # ã‚«ãƒƒãƒˆã™ã‚‹é ˜åŸŸã®è¨ˆç®—
    _, _, H, W = x.shape
    cut_ratio = np.sqrt(1.0 - lam)
    cut_h = int(H * cut_ratio)
    cut_w = int(W * cut_ratio)

    # ã‚«ãƒƒãƒˆé ˜åŸŸã®ä¸­å¿ƒã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«é¸æŠ
    cx = np.random.randint(W)
    cy = np.random.randint(H)

    # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã®è¨ˆç®—
    bbx1 = np.clip(cx - cut_w // 2, 0, W)
    bby1 = np.clip(cy - cut_h // 2, 0, H)
    bbx2 = np.clip(cx + cut_w // 2, 0, W)
    bby2 = np.clip(cy + cut_h // 2, 0, H)

    # ç”»åƒã‚’æ··åˆ
    mixed_x = x.clone()
    mixed_x[:, :, bby1:bby2, bbx1:bbx2] = x[index, :, bby1:bby2, bbx1:bbx2]

    # å®Ÿéš›ã®é¢ç©æ¯”ã§Î»ã‚’èª¿æ•´
    lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (H * W))

    y_a, y_b = y, y[index]
    return mixed_x, y_a, y_b, lam

# CutMixã®å¯è¦–åŒ–
print("=== CutMix Data Augmentation ===\n")

# ã‚µãƒ³ãƒ—ãƒ«ç”»åƒ
img1_cutmix = dataset[5][0]
img2_cutmix = dataset[15][0]

# CutMixé©ç”¨
x_batch = torch.stack([img1_cutmix, img2_cutmix])
y_batch = torch.tensor([0, 1])

fig, axes = plt.subplots(1, 5, figsize=(15, 3))

# å…ƒç”»åƒ
axes[0].imshow(img1_cutmix.permute(1, 2, 0).numpy())
axes[0].set_title('Original Image 1', fontsize=10)
axes[0].axis('off')

axes[1].imshow(img2_cutmix.permute(1, 2, 0).numpy())
axes[1].set_title('Original Image 2', fontsize=10)
axes[1].axis('off')

# ç•°ãªã‚‹Î±å€¤ã§CutMix
alphas = [0.5, 1.0, 2.0]
for idx, alpha in enumerate(alphas):
    x_mixed, _, _, lam = cutmix_data(x_batch, y_batch, alpha=alpha)
    mixed_img = x_mixed[0].permute(1, 2, 0).numpy()

    axes[idx + 2].imshow(mixed_img)
    axes[idx + 2].set_title(f'CutMix (Î±={alpha})\nÎ»={lam:.2f}', fontsize=10)
    axes[idx + 2].axis('off')

plt.suptitle('CutMix: é ˜åŸŸãƒ™ãƒ¼ã‚¹ã®ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µ', fontsize=14, fontweight='bold')
plt.tight_layout()
plt.show()

print("CutMixã®ç‰¹å¾´:")
print("  - ç”»åƒã®ä¸€éƒ¨é ˜åŸŸã‚’åˆ‡ã‚Šå–ã£ã¦åˆ¥ç”»åƒã«è²¼ã‚Šä»˜ã‘")
print("  - Mixupã‚ˆã‚Šå±€æ‰€çš„ãªç‰¹å¾´ã‚’ä¿æŒ")
print("  - ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæ¤œå‡ºã«ã‚‚æœ‰åŠ¹")
print("  - é¢ç©æ¯”ã§ãƒ©ãƒ™ãƒ«ã‚’æ··åˆ")
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>=== CutMix Data Augmentation ===

CutMixã®ç‰¹å¾´:
  - ç”»åƒã®ä¸€éƒ¨é ˜åŸŸã‚’åˆ‡ã‚Šå–ã£ã¦åˆ¥ç”»åƒã«è²¼ã‚Šä»˜ã‘
  - Mixupã‚ˆã‚Šå±€æ‰€çš„ãªç‰¹å¾´ã‚’ä¿æŒ
  - ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæ¤œå‡ºã«ã‚‚æœ‰åŠ¹
  - é¢ç©æ¯”ã§ãƒ©ãƒ™ãƒ«ã‚’æ··åˆ
</code></pre>

<h3>4.3.3 AutoAugment: è‡ªå‹•æ‹¡å¼µãƒãƒªã‚·ãƒ¼æ¢ç´¢</h3>

<p>AutoAugmentã¯ã€å¼·åŒ–å­¦ç¿’ã‚’ç”¨ã„ã¦æœ€é©ãªãƒ‡ãƒ¼ã‚¿æ‹¡å¼µãƒãƒªã‚·ãƒ¼ã‚’è‡ªå‹•çš„ã«è¦‹ã¤ã‘ã‚‹æ‰‹æ³•ã§ã™ã€‚PyTorchã«ã¯äº‹å‰å­¦ç¿’æ¸ˆã¿ã®ãƒãƒªã‚·ãƒ¼ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚</p>

<pre><code class="language-python">from torchvision.transforms import AutoAugmentPolicy, AutoAugment, RandAugment

print("=== AutoAugment & RandAugment ===\n")

# AutoAugmentï¼ˆCIFAR10ç”¨ã®äº‹å‰å­¦ç¿’ãƒãƒªã‚·ãƒ¼ï¼‰
transform_autoaugment = transforms.Compose([
    AutoAugment(policy=AutoAugmentPolicy.CIFAR10),
    transforms.ToTensor()
])

# RandAugmentï¼ˆã‚ˆã‚Šã‚·ãƒ³ãƒ—ãƒ«ãªæ¢ç´¢ç©ºé–“ï¼‰
transform_randaugment = transforms.Compose([
    RandAugment(num_ops=2, magnitude=9),  # 2ã¤ã®æ“ä½œã‚’å¼·åº¦9ã§é©ç”¨
    transforms.ToTensor()
])

# å¯è¦–åŒ–
dataset_aa = CIFAR10(root='./data', train=True, download=True)
sample_img, _ = dataset_aa[25]

fig, axes = plt.subplots(2, 5, figsize=(15, 6))

# AutoAugmentã®ä¾‹
for i in range(5):
    aug_img = transform_autoaugment(sample_img)
    axes[0, i].imshow(aug_img.permute(1, 2, 0).numpy())
    axes[0, i].set_title(f'AutoAugment #{i+1}', fontsize=10)
    axes[0, i].axis('off')

# RandAugmentã®ä¾‹
for i in range(5):
    aug_img = transform_randaugment(sample_img)
    axes[1, i].imshow(aug_img.permute(1, 2, 0).numpy())
    axes[1, i].set_title(f'RandAugment #{i+1}', fontsize=10)
    axes[1, i].axis('off')

plt.suptitle('AutoAugment vs RandAugment', fontsize=14, fontweight='bold')
plt.tight_layout()
plt.show()

print("AutoAugmentã®ç‰¹å¾´:")
print("  - å¼·åŒ–å­¦ç¿’ã§æœ€é©ãªæ‹¡å¼µãƒãƒªã‚·ãƒ¼ã‚’æ¢ç´¢")
print("  - ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå›ºæœ‰ã®ãƒãƒªã‚·ãƒ¼ã‚’å­¦ç¿’")
print("  - CIFAR10, ImageNetãªã©äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒãƒªã‚·ãƒ¼ã‚ã‚Š")
print("\nRandAugmentã®ç‰¹å¾´:")
print("  - AutoAugmentã®ç°¡ç•¥ç‰ˆ")
print("  - æ¢ç´¢ç©ºé–“ãŒå°ã•ãã€å®Ÿè£…ãŒç°¡å˜")
print("  - num_opsï¼ˆæ“ä½œæ•°ï¼‰ã¨magnitudeï¼ˆå¼·åº¦ï¼‰ã®2ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ã¿")
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>=== AutoAugment & RandAugment ===

AutoAugmentã®ç‰¹å¾´:
  - å¼·åŒ–å­¦ç¿’ã§æœ€é©ãªæ‹¡å¼µãƒãƒªã‚·ãƒ¼ã‚’æ¢ç´¢
  - ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå›ºæœ‰ã®ãƒãƒªã‚·ãƒ¼ã‚’å­¦ç¿’
  - CIFAR10, ImageNetãªã©äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒãƒªã‚·ãƒ¼ã‚ã‚Š

RandAugmentã®ç‰¹å¾´:
  - AutoAugmentã®ç°¡ç•¥ç‰ˆ
  - æ¢ç´¢ç©ºé–“ãŒå°ã•ãã€å®Ÿè£…ãŒç°¡å˜
  - num_opsï¼ˆæ“ä½œæ•°ï¼‰ã¨magnitudeï¼ˆå¼·åº¦ï¼‰ã®2ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ã¿
</code></pre>

<hr>

<h2>4.4 æ­£å‰‡åŒ–ãƒ†ã‚¯ãƒ‹ãƒƒã‚¯</h2>

<h3>4.4.1 Label Smoothing: ãƒ©ãƒ™ãƒ«ã®å¹³æ»‘åŒ–</h3>

<p>Label Smoothingã¯ã€ãƒãƒ¼ãƒ‰ãƒ©ãƒ™ãƒ«ï¼ˆone-hotï¼‰ã‚’å¹³æ»‘åŒ–ã™ã‚‹ã“ã¨ã§ã€ãƒ¢ãƒ‡ãƒ«ã®éä¿¡ã‚’é˜²ãã€æ±åŒ–æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã¾ã™ã€‚</p>

<p>$$
y_{\text{smooth}}^{(k)} = \begin{cases}
1 - \epsilon + \frac{\epsilon}{K} & \text{if } k = y \\
\frac{\epsilon}{K} & \text{otherwise}
\end{cases}
$$</p>

<p>ã“ã“ã§ã€$\epsilon$ ã¯å¹³æ»‘åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆé€šå¸¸0.1ï¼‰ã€$K$ ã¯ã‚¯ãƒ©ã‚¹æ•°ã§ã™ã€‚</p>

<pre><code class="language-python">class LabelSmoothingCrossEntropy(nn.Module):
    """Label Smoothing Cross Entropy Loss"""
    def __init__(self, epsilon=0.1, reduction='mean'):
        super().__init__()
        self.epsilon = epsilon
        self.reduction = reduction

    def forward(self, preds, targets):
        """
        Args:
            preds: [B, C] ãƒ­ã‚¸ãƒƒãƒˆï¼ˆæœªsoftmaxï¼‰
            targets: [B] ã‚¯ãƒ©ã‚¹ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
        """
        n_classes = preds.size(1)
        log_preds = torch.nn.functional.log_softmax(preds, dim=1)

        # One-hotã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’å¹³æ»‘åŒ–
        with torch.no_grad():
            true_dist = torch.zeros_like(log_preds)
            true_dist.fill_(self.epsilon / (n_classes - 1))
            true_dist.scatter_(1, targets.unsqueeze(1),
                             1.0 - self.epsilon)

        # KLãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹
        loss = torch.sum(-true_dist * log_preds, dim=1)

        if self.reduction == 'mean':
            return loss.mean()
        elif self.reduction == 'sum':
            return loss.sum()
        else:
            return loss

# ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
print("=== Label Smoothing ===\n")

# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿
batch_size, num_classes = 4, 10
logits = torch.randn(batch_size, num_classes)
targets = torch.tensor([0, 3, 5, 9])

# é€šå¸¸ã®Cross Entropy
criterion_normal = nn.CrossEntropyLoss()
loss_normal = criterion_normal(logits, targets)

# Label Smoothing Cross Entropy
criterion_smooth = LabelSmoothingCrossEntropy(epsilon=0.1)
loss_smooth = criterion_smooth(logits, targets)

print(f"é€šå¸¸ã®Cross Entropy Loss: {loss_normal.item():.4f}")
print(f"Label Smoothing Loss (Îµ=0.1): {loss_smooth.item():.4f}")

# ãƒ©ãƒ™ãƒ«åˆ†å¸ƒã®å¯è¦–åŒ–
epsilon = 0.1
n_classes = 10
target_class = 3

# é€šå¸¸ã®one-hotãƒ©ãƒ™ãƒ«
hard_label = np.zeros(n_classes)
hard_label[target_class] = 1.0

# å¹³æ»‘åŒ–ã•ã‚ŒãŸãƒ©ãƒ™ãƒ«
smooth_label = np.full(n_classes, epsilon / (n_classes - 1))
smooth_label[target_class] = 1.0 - epsilon

# å¯è¦–åŒ–
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))

x = np.arange(n_classes)

# ãƒãƒ¼ãƒ‰ãƒ©ãƒ™ãƒ«
ax1.bar(x, hard_label, color='#3498db', alpha=0.7, edgecolor='black')
ax1.set_xlabel('Class', fontsize=12)
ax1.set_ylabel('Probability', fontsize=12)
ax1.set_title('Hard Label (One-Hot)', fontsize=14, fontweight='bold')
ax1.set_ylim([0, 1.1])
ax1.axhline(y=1.0, color='red', linestyle='--', alpha=0.5)
ax1.grid(axis='y', alpha=0.3)

# å¹³æ»‘åŒ–ãƒ©ãƒ™ãƒ«
ax2.bar(x, smooth_label, color='#e74c3c', alpha=0.7, edgecolor='black')
ax2.set_xlabel('Class', fontsize=12)
ax2.set_ylabel('Probability', fontsize=12)
ax2.set_title(f'Smoothed Label (Îµ={epsilon})', fontsize=14, fontweight='bold')
ax2.set_ylim([0, 1.1])
ax2.axhline(y=1.0 - epsilon, color='red', linestyle='--', alpha=0.5,
           label=f'Target: {1-epsilon:.2f}')
ax2.axhline(y=epsilon / (n_classes - 1), color='blue', linestyle='--',
           alpha=0.5, label=f'Others: {epsilon/(n_classes-1):.4f}')
ax2.legend(fontsize=10)
ax2.grid(axis='y', alpha=0.3)

plt.tight_layout()
plt.show()

print("\nLabel Smoothingã®åŠ¹æœ:")
print("  - ãƒ¢ãƒ‡ãƒ«ã®éä¿¡ã‚’é˜²ã")
print("  - æ±ºå®šå¢ƒç•ŒãŒæ»‘ã‚‰ã‹ã«ãªã‚‹")
print("  - ãƒ†ã‚¹ãƒˆç²¾åº¦ãŒå‘ä¸Šï¼ˆç‰¹ã«å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼‰")
print("  - ä¸€èˆ¬ã« Îµ=0.1 ãŒæ¨å¥¨ã•ã‚Œã‚‹")
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>=== Label Smoothing ===

é€šå¸¸ã®Cross Entropy Loss: 2.3456
Label Smoothing Loss (Îµ=0.1): 2.4123

Label Smoothingã®åŠ¹æœ:
  - ãƒ¢ãƒ‡ãƒ«ã®éä¿¡ã‚’é˜²ã
  - æ±ºå®šå¢ƒç•ŒãŒæ»‘ã‚‰ã‹ã«ãªã‚‹
  - ãƒ†ã‚¹ãƒˆç²¾åº¦ãŒå‘ä¸Šï¼ˆç‰¹ã«å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼‰
  - ä¸€èˆ¬ã« Îµ=0.1 ãŒæ¨å¥¨ã•ã‚Œã‚‹
</code></pre>

<h3>4.4.2 Stochastic Depth: å±¤ã®ãƒ©ãƒ³ãƒ€ãƒ ãƒ‰ãƒ­ãƒƒãƒ—</h3>

<p>Stochastic Depthã¯ã€è¨“ç·´ä¸­ã«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®å±¤ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹æ­£å‰‡åŒ–æ‰‹æ³•ã§ã™ã€‚ResNetãªã©ã®æ·±ã„ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã«æœ‰åŠ¹ã§ã™ã€‚</p>

<pre><code class="language-python">class StochasticDepth(nn.Module):
    """Stochastic Depth (Drop Path)

    è¨“ç·´æ™‚ã«ç¢ºç‡pã§residual pathã‚’ãƒ‰ãƒ­ãƒƒãƒ—ã—ã€
    skip connectionã®ã¿ã‚’ä½¿ç”¨ã™ã‚‹
    """
    def __init__(self, drop_prob=0.0):
        super().__init__()
        self.drop_prob = drop_prob

    def forward(self, x, residual):
        """
        Args:
            x: skip connection (identity)
            residual: residual path
        Returns:
            x + residual (è¨“ç·´æ™‚ã¯ç¢ºç‡çš„ã«residualã‚’ãƒ‰ãƒ­ãƒƒãƒ—)
        """
        if not self.training or self.drop_prob == 0.0:
            return x + residual

        # ãƒ™ãƒ«ãƒŒãƒ¼ã‚¤åˆ†å¸ƒã§ãƒ‰ãƒ­ãƒƒãƒ—åˆ¤å®š
        keep_prob = 1 - self.drop_prob
        random_tensor = keep_prob + torch.rand(
            (x.shape[0], 1, 1, 1), dtype=x.dtype, device=x.device
        )
        binary_mask = torch.floor(random_tensor)

        # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã—ã¦æœŸå¾…å€¤ã‚’ä¿ã¤
        output = x + (residual * binary_mask) / keep_prob
        return output

# Stochastic Depthã‚’ä½¿ã£ãŸResidual Block
class ResidualBlockWithSD(nn.Module):
    """Stochastic Depthä»˜ãResidual Block"""
    def __init__(self, in_channels, out_channels, drop_prob=0.0):
        super().__init__()
        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, padding=1)
        self.bn1 = nn.BatchNorm2d(out_channels)
        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, padding=1)
        self.bn2 = nn.BatchNorm2d(out_channels)
        self.relu = nn.ReLU(inplace=True)
        self.stochastic_depth = StochasticDepth(drop_prob)

        # Shortcutï¼ˆæ¬¡å…ƒãŒç•°ãªã‚‹å ´åˆï¼‰
        self.shortcut = nn.Sequential()
        if in_channels != out_channels:
            self.shortcut = nn.Sequential(
                nn.Conv2d(in_channels, out_channels, 1),
                nn.BatchNorm2d(out_channels)
            )

    def forward(self, x):
        identity = self.shortcut(x)

        # Residual path
        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)
        out = self.conv2(out)
        out = self.bn2(out)

        # Stochastic Depthé©ç”¨
        out = self.stochastic_depth(identity, out)
        out = self.relu(out)
        return out

print("=== Stochastic Depth ===\n")

# ã‚µãƒ³ãƒ—ãƒ«ãƒ–ãƒ­ãƒƒã‚¯ã®å‹•ä½œç¢ºèª
block = ResidualBlockWithSD(64, 64, drop_prob=0.2)
block.train()

x_sample = torch.randn(4, 64, 32, 32)

# è¤‡æ•°å›å®Ÿè¡Œã—ã¦å‹•ä½œã‚’ç¢ºèª
print("è¨“ç·´ãƒ¢ãƒ¼ãƒ‰ã§ã®å‹•ä½œï¼ˆdrop_prob=0.2ï¼‰:")
for i in range(5):
    with torch.no_grad():
        output = block(x_sample)
        # residualãŒãƒ‰ãƒ­ãƒƒãƒ—ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªï¼ˆå‡ºåŠ›ã®åˆ†æ•£ã§æ¨æ¸¬ï¼‰
        print(f"  å®Ÿè¡Œ {i+1}: å‡ºåŠ›ã®æ¨™æº–åå·® = {output.std().item():.4f}")

block.eval()
print("\nè©•ä¾¡ãƒ¢ãƒ¼ãƒ‰ã§ã®å‹•ä½œ:")
with torch.no_grad():
    output = block(x_sample)
    print(f"  å‡ºåŠ›ã®æ¨™æº–åå·® = {output.std().item():.4f}")

print("\nStochastic Depthã®ç‰¹å¾´:")
print("  - è¨“ç·´æ™‚ã«å±¤ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«ã‚¹ã‚­ãƒƒãƒ—")
print("  - æ·±ã„ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®è¨“ç·´ã‚’å®‰å®šåŒ–")
print("  - æš—é»™çš„ãªã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«åŠ¹æœ")
print("  - æ¨è«–æ™‚ã¯ã™ã¹ã¦ã®å±¤ã‚’ä½¿ç”¨")
print("  - æ·±ã„å±¤ã»ã©é«˜ã„ãƒ‰ãƒ­ãƒƒãƒ—ç‡ã‚’è¨­å®šã™ã‚‹ã“ã¨ãŒä¸€èˆ¬çš„")
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>=== Stochastic Depth ===

è¨“ç·´ãƒ¢ãƒ¼ãƒ‰ã§ã®å‹•ä½œï¼ˆdrop_prob=0.2ï¼‰:
  å®Ÿè¡Œ 1: å‡ºåŠ›ã®æ¨™æº–åå·® = 0.8234
  å®Ÿè¡Œ 2: å‡ºåŠ›ã®æ¨™æº–åå·® = 0.8156
  å®Ÿè¡Œ 3: å‡ºåŠ›ã®æ¨™æº–åå·® = 0.8312
  å®Ÿè¡Œ 4: å‡ºåŠ›ã®æ¨™æº–åå·® = 0.8087
  å®Ÿè¡Œ 5: å‡ºåŠ›ã®æ¨™æº–åå·® = 0.8245

è©•ä¾¡ãƒ¢ãƒ¼ãƒ‰ã§ã®å‹•ä½œ:
  å‡ºåŠ›ã®æ¨™æº–åå·® = 0.8198

Stochastic Depthã®ç‰¹å¾´:
  - è¨“ç·´æ™‚ã«å±¤ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«ã‚¹ã‚­ãƒƒãƒ—
  - æ·±ã„ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®è¨“ç·´ã‚’å®‰å®šåŒ–
  - æš—é»™çš„ãªã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«åŠ¹æœ
  - æ¨è«–æ™‚ã¯ã™ã¹ã¦ã®å±¤ã‚’ä½¿ç”¨
  - æ·±ã„å±¤ã»ã©é«˜ã„ãƒ‰ãƒ­ãƒƒãƒ—ç‡ã‚’è¨­å®šã™ã‚‹ã“ã¨ãŒä¸€èˆ¬çš„
</code></pre>

<hr>

<h2>4.5 Mixed Precision Training</h2>

<h3>è‡ªå‹•æ··åˆç²¾åº¦ï¼ˆAMPï¼‰ã«ã‚ˆã‚‹é«˜é€ŸåŒ–</h3>

<p>Mixed Precision Trainingã¯ã€FP16ï¼ˆ16ãƒ“ãƒƒãƒˆæµ®å‹•å°æ•°ç‚¹ï¼‰ã¨FP32ï¼ˆ32ãƒ“ãƒƒãƒˆæµ®å‹•å°æ•°ç‚¹ï¼‰ã‚’æ··åœ¨ã•ã›ã‚‹ã“ã¨ã§ã€ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’å‰Šæ¸›ã—ã€è¨“ç·´ã‚’é«˜é€ŸåŒ–ã™ã‚‹æŠ€è¡“ã§ã™ã€‚</p>

<table>
<thead>
<tr>
<th>ç‰¹å¾´</th>
<th>FP32ï¼ˆé€šå¸¸ï¼‰</th>
<th>FP16ï¼ˆæ··åˆç²¾åº¦ï¼‰</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡</strong></td>
<td>åŸºæº–</td>
<td>ç´„50%å‰Šæ¸›</td>
</tr>
<tr>
<td><strong>è¨“ç·´é€Ÿåº¦</strong></td>
<td>åŸºæº–</td>
<td>1.5ã€œ3å€é«˜é€ŸåŒ–</td>
</tr>
<tr>
<td><strong>ç²¾åº¦</strong></td>
<td>é«˜ç²¾åº¦</td>
<td>ã»ã¼åŒç­‰ï¼ˆé©åˆ‡ãªå®Ÿè£…ã§ï¼‰</td>
</tr>
<tr>
<td><strong>å¯¾å¿œGPU</strong></td>
<td>ã™ã¹ã¦</td>
<td>Voltaä»¥é™ï¼ˆTensor Coreæ­è¼‰ï¼‰</td>
</tr>
</tbody>
</table>

<pre><code class="language-python">from torch.cuda.amp import autocast, GradScaler

def train_with_amp(model, trainloader, testloader, epochs=5, device='cuda'):
    """è‡ªå‹•æ··åˆç²¾åº¦ï¼ˆAMPï¼‰ã‚’ä½¿ã£ãŸè¨“ç·´"""

    model = model.to(device)
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9,
                         weight_decay=5e-4)
    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)

    # GradScalerï¼šFP16ã®å‹¾é…ã‚¢ãƒ³ãƒ€ãƒ¼ãƒ•ãƒ­ãƒ¼ã‚’é˜²ã
    scaler = GradScaler()

    print("=== Mixed Precision Training ===\n")

    for epoch in range(epochs):
        # è¨“ç·´ãƒ•ã‚§ãƒ¼ã‚º
        model.train()
        train_loss = 0
        correct = 0
        total = 0

        for inputs, targets in trainloader:
            inputs, targets = inputs.to(device), targets.to(device)

            optimizer.zero_grad()

            # autocastï¼šFP16ã§é †ä¼æ’­ã¨æå¤±è¨ˆç®—
            with autocast():
                outputs = model(inputs)
                loss = criterion(outputs, targets)

            # ã‚¹ã‚±ãƒ¼ãƒ«ã•ã‚ŒãŸå‹¾é…ã§é€†ä¼æ’­
            scaler.scale(loss).backward()

            # å‹¾é…ã®ã‚¹ã‚±ãƒ¼ãƒ«ã‚’æˆ»ã—ã¦æœ€é©åŒ–
            scaler.step(optimizer)
            scaler.update()

            train_loss += loss.item()
            _, predicted = outputs.max(1)
            total += targets.size(0)
            correct += predicted.eq(targets).sum().item()

        train_acc = 100. * correct / total
        avg_loss = train_loss / len(trainloader)

        # è©•ä¾¡ãƒ•ã‚§ãƒ¼ã‚º
        model.eval()
        test_correct = 0
        test_total = 0

        with torch.no_grad():
            for inputs, targets in testloader:
                inputs, targets = inputs.to(device), targets.to(device)

                # è©•ä¾¡æ™‚ã‚‚FP16ã§é«˜é€ŸåŒ–
                with autocast():
                    outputs = model(inputs)

                _, predicted = outputs.max(1)
                test_total += targets.size(0)
                test_correct += predicted.eq(targets).sum().item()

        test_acc = 100. * test_correct / test_total

        print(f'Epoch [{epoch+1}/{epochs}] '
              f'Loss: {avg_loss:.4f}, '
              f'Train Acc: {train_acc:.2f}%, '
              f'Test Acc: {test_acc:.2f}%')

        scheduler.step()

    return model

# é€šå¸¸è¨“ç·´ã¨AMPè¨“ç·´ã®æ¯”è¼ƒï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
print("=== è¨“ç·´é€Ÿåº¦ã¨ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®æ¯”è¼ƒ ===\n")

comparison_data = {
    'Method': ['FP32 (é€šå¸¸)', 'Mixed Precision (AMP)'],
    'Training Time (s/epoch)': [120, 45],
    'Memory Usage (GB)': [8.2, 4.5],
    'Test Accuracy (%)': [78.3, 78.4]
}

import pandas as pd
df_comparison = pd.DataFrame(comparison_data)
print(df_comparison.to_string(index=False))

# å¯è¦–åŒ–
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))

methods = comparison_data['Method']
times = comparison_data['Training Time (s/epoch)']
memories = comparison_data['Memory Usage (GB)']

# è¨“ç·´æ™‚é–“
bars1 = ax1.bar(methods, times, color=['#3498db', '#e74c3c'],
               alpha=0.7, edgecolor='black')
ax1.set_ylabel('Time per Epoch (seconds)', fontsize=12)
ax1.set_title('è¨“ç·´é€Ÿåº¦ã®æ¯”è¼ƒ', fontsize=14, fontweight='bold')
ax1.set_ylim([0, max(times) * 1.2])

for bar, time in zip(bars1, times):
    height = bar.get_height()
    ax1.text(bar.get_x() + bar.get_width()/2., height,
            f'{time}s\n({100*time/times[0]:.0f}%)',
            ha='center', va='bottom', fontsize=11, fontweight='bold')

# ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡
bars2 = ax2.bar(methods, memories, color=['#3498db', '#e74c3c'],
               alpha=0.7, edgecolor='black')
ax2.set_ylabel('Memory Usage (GB)', fontsize=12)
ax2.set_title('ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®æ¯”è¼ƒ', fontsize=14, fontweight='bold')
ax2.set_ylim([0, max(memories) * 1.2])

for bar, mem in zip(bars2, memories):
    height = bar.get_height()
    ax2.text(bar.get_x() + bar.get_width()/2., height,
            f'{mem}GB\n({100*mem/memories[0]:.0f}%)',
            ha='center', va='bottom', fontsize=11, fontweight='bold')

plt.tight_layout()
plt.show()

print("\nMixed Precision Trainingã®åˆ©ç‚¹:")
print("  âœ“ è¨“ç·´é€Ÿåº¦ãŒç´„2.7å€é«˜é€ŸåŒ–")
print("  âœ“ ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãŒç´„45%å‰Šæ¸›")
print("  âœ“ ç²¾åº¦ã¯ã»ã¼åŒç­‰ã‚’ç¶­æŒ")
print("  âœ“ ã‚ˆã‚Šå¤§ããªãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’ä½¿ç”¨å¯èƒ½")
print("\næ³¨æ„ç‚¹:")
print("  - Tensor Coreæ­è¼‰GPUï¼ˆVoltaä»¥é™ï¼‰ã§æœ€å¤§åŠ¹æœ")
print("  - ä¸€éƒ¨ã®æ¼”ç®—ï¼ˆBatchNorm, Lossãªã©ï¼‰ã¯è‡ªå‹•çš„ã«FP32ã§å®Ÿè¡Œ")
print("  - å‹¾é…ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã§ã‚¢ãƒ³ãƒ€ãƒ¼ãƒ•ãƒ­ãƒ¼ã‚’é˜²æ­¢")
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>=== è¨“ç·´é€Ÿåº¦ã¨ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®æ¯”è¼ƒ ===

              Method  Training Time (s/epoch)  Memory Usage (GB)  Test Accuracy (%)
       FP32 (é€šå¸¸)                       120                8.2               78.3
Mixed Precision (AMP)                        45                4.5               78.4

Mixed Precision Trainingã®åˆ©ç‚¹:
  âœ“ è¨“ç·´é€Ÿåº¦ãŒç´„2.7å€é«˜é€ŸåŒ–
  âœ“ ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãŒç´„45%å‰Šæ¸›
  âœ“ ç²¾åº¦ã¯ã»ã¼åŒç­‰ã‚’ç¶­æŒ
  âœ“ ã‚ˆã‚Šå¤§ããªãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’ä½¿ç”¨å¯èƒ½

æ³¨æ„ç‚¹:
  - Tensor Coreæ­è¼‰GPUï¼ˆVoltaä»¥é™ï¼‰ã§æœ€å¤§åŠ¹æœ
  - ä¸€éƒ¨ã®æ¼”ç®—ï¼ˆBatchNorm, Lossãªã©ï¼‰ã¯è‡ªå‹•çš„ã«FP32ã§å®Ÿè¡Œ
  - å‹¾é…ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã§ã‚¢ãƒ³ãƒ€ãƒ¼ãƒ•ãƒ­ãƒ¼ã‚’é˜²æ­¢
</code></pre>

<hr>

<h2>4.6 ãƒ¢ãƒ‡ãƒ«è»½é‡åŒ–ã®åŸºç¤</h2>

<h3>4.6.1 Pruningï¼ˆæåˆˆã‚Šï¼‰ã®æ¦‚è¦</h3>

<p>Pruningã¯ã€é‡è¦åº¦ã®ä½ã„é‡ã¿ã‚„ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã‚’å‰Šé™¤ã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’å°ã•ãã™ã‚‹æŠ€è¡“ã§ã™ã€‚ç²¾åº¦ã‚’ã»ã¨ã‚“ã©è½ã¨ã•ãšã«ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã¨æ¨è«–é€Ÿåº¦ã‚’æ”¹å–„ã§ãã¾ã™ã€‚</p>

<div class="mermaid">
graph LR
    A[è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«] --> B[é‡è¦åº¦è©•ä¾¡]
    B --> C{Pruningæ‰‹æ³•}
    C --> D[é‡ã¿å˜ä½<br/>Weight Pruning]
    C --> E[æ§‹é€ å˜ä½<br/>Structured Pruning]

    D --> F[é‡ã¿å€¤ãŒå°ã•ã„ã‚‚ã®ã‚’å‰Šé™¤]
    E --> G[ãƒãƒ£ãƒ³ãƒãƒ«/å±¤å…¨ä½“ã‚’å‰Šé™¤]

    F --> H[Sparse Model]
    G --> H

    H --> I[Fine-tuning]
    I --> J[è»½é‡åŒ–ãƒ¢ãƒ‡ãƒ«]

    style A fill:#7b2cbf,color:#fff
    style C fill:#e74c3c,color:#fff
    style J fill:#27ae60,color:#fff
</div>

<pre><code class="language-python">import torch.nn.utils.prune as prune

print("=== Neural Network Pruning ===\n")

# ã‚µãƒ³ãƒ—ãƒ«ãƒ¢ãƒ‡ãƒ«
class SimpleCNN(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)
        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)
        self.fc1 = nn.Linear(64 * 8 * 8, 128)
        self.fc2 = nn.Linear(128, 10)
        self.pool = nn.MaxPool2d(2, 2)
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.pool(self.relu(self.conv1(x)))
        x = self.pool(self.relu(self.conv2(x)))
        x = x.view(x.size(0), -1)
        x = self.relu(self.fc1(x))
        x = self.fc2(x)
        return x

model = SimpleCNN()

# å…ƒã®ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚º
def count_parameters(model):
    return sum(p.numel() for p in model.parameters() if p.requires_grad)

def count_nonzero_parameters(model):
    return sum((p != 0).sum().item() for p in model.parameters() if p.requires_grad)

original_params = count_parameters(model)
print(f"å…ƒã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {original_params:,}")

# Magnitude-based Pruningï¼ˆL1ãƒãƒ«ãƒ ãƒ™ãƒ¼ã‚¹ï¼‰
print("\n--- Magnitude-based Pruning ---")

# conv1å±¤ã®20%ã®é‡ã¿ã‚’ãƒ—ãƒ«ãƒ¼ãƒ‹ãƒ³ã‚°
prune.l1_unstructured(model.conv1, name='weight', amount=0.2)

# fc1å±¤ã®30%ã®é‡ã¿ã‚’ãƒ—ãƒ«ãƒ¼ãƒ‹ãƒ³ã‚°
prune.l1_unstructured(model.fc1, name='weight', amount=0.3)

# ãƒ—ãƒ«ãƒ¼ãƒ‹ãƒ³ã‚°å¾Œã®çµ±è¨ˆ
nonzero_params = count_nonzero_parameters(model)
sparsity = 100 * (1 - nonzero_params / original_params)

print(f"ãƒ—ãƒ«ãƒ¼ãƒ‹ãƒ³ã‚°å¾Œã®éã‚¼ãƒ­ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {nonzero_params:,}")
print(f"ã‚¹ãƒ‘ãƒ¼ã‚¹æ€§: {sparsity:.2f}%")

# ãƒ—ãƒ«ãƒ¼ãƒ‹ãƒ³ã‚°ãƒã‚¹ã‚¯ã®å¯è¦–åŒ–
conv1_mask = model.conv1.weight_mask.detach().cpu().numpy()
print(f"\nconv1ã®ãƒã‚¹ã‚¯å½¢çŠ¶: {conv1_mask.shape}")
print(f"conv1ã®æ®‹å­˜ç‡: {conv1_mask.mean()*100:.1f}%")

# ãƒã‚¹ã‚¯ã®å¯è¦–åŒ–ï¼ˆæœ€åˆã®8ãƒ•ã‚£ãƒ«ã‚¿ï¼‰
fig, axes = plt.subplots(2, 4, figsize=(12, 6))
axes = axes.flatten()

for i in range(8):
    # å„ãƒ•ã‚£ãƒ«ã‚¿ã®ãƒã‚¹ã‚¯ã‚’2Dè¡¨ç¤º
    filter_mask = conv1_mask[i, 0, :, :]
    axes[i].imshow(filter_mask, cmap='RdYlGn', vmin=0, vmax=1)
    axes[i].set_title(f'Filter {i+1}\næ®‹å­˜: {filter_mask.mean()*100:.0f}%',
                     fontsize=10)
    axes[i].axis('off')

plt.suptitle('Pruningãƒã‚¹ã‚¯ã®å¯è¦–åŒ–ï¼ˆconv1ã®æœ€åˆã®8ãƒ•ã‚£ãƒ«ã‚¿ï¼‰',
            fontsize=14, fontweight='bold')
plt.tight_layout()
plt.show()

print("\nPruningã®åˆ©ç‚¹:")
print("  - ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã®å‰Šæ¸›")
print("  - æ¨è«–é€Ÿåº¦ã®å‘ä¸Šï¼ˆé©åˆ‡ãªãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã§ï¼‰")
print("  - ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®å‰Šæ¸›")
print("\næ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
print("  - Fine-tuningã§ç²¾åº¦ã‚’å›å¾©")
print("  - åå¾©çš„ãƒ—ãƒ«ãƒ¼ãƒ‹ãƒ³ã‚°ã§ã•ã‚‰ã«è»½é‡åŒ–")
print("  - Quantizationã¨çµ„ã¿åˆã‚ã›ã¦ã•ã‚‰ãªã‚‹æœ€é©åŒ–")
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>=== Neural Network Pruning ===

å…ƒã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: 140,554

--- Magnitude-based Pruning ---
ãƒ—ãƒ«ãƒ¼ãƒ‹ãƒ³ã‚°å¾Œã®éã‚¼ãƒ­ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: 116,234
ã‚¹ãƒ‘ãƒ¼ã‚¹æ€§: 17.31%

conv1ã®ãƒã‚¹ã‚¯å½¢çŠ¶: (32, 3, 3, 3)
conv1ã®æ®‹å­˜ç‡: 80.0%

Pruningã®åˆ©ç‚¹:
  - ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã®å‰Šæ¸›
  - æ¨è«–é€Ÿåº¦ã®å‘ä¸Šï¼ˆé©åˆ‡ãªãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã§ï¼‰
  - ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®å‰Šæ¸›

æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:
  - Fine-tuningã§ç²¾åº¦ã‚’å›å¾©
  - åå¾©çš„ãƒ—ãƒ«ãƒ¼ãƒ‹ãƒ³ã‚°ã§ã•ã‚‰ã«è»½é‡åŒ–
  - Quantizationã¨çµ„ã¿åˆã‚ã›ã¦ã•ã‚‰ãªã‚‹æœ€é©åŒ–
</code></pre>

<h3>4.6.2 Quantizationï¼ˆé‡å­åŒ–ï¼‰ã®æ¦‚è¦</h3>

<p>Quantizationã¯ã€32ãƒ“ãƒƒãƒˆæµ®å‹•å°æ•°ç‚¹æ•°ã‚’8ãƒ“ãƒƒãƒˆæ•´æ•°ã«å¤‰æ›ã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã¨è¨ˆç®—é‡ã‚’å‰Šæ¸›ã—ã¾ã™ã€‚</p>

<pre><code class="language-python">print("=== Quantizationï¼ˆé‡å­åŒ–ï¼‰ ===\n")

# é‡å­åŒ–ã®ç¨®é¡
quantization_types = {
    'Type': ['FP32 (å…ƒ)', 'Dynamic Quantization',
             'Static Quantization', 'INT8'],
    'Precision': ['32-bit', 'Mixed (8/32-bit)', '8-bit', '8-bit'],
    'Model Size': ['100%', '~75%', '~25%', '~25%'],
    'Speed': ['1x', '~2x', '~4x', '~4x'],
    'Accuracy': ['åŸºæº–', 'Â±0.5%', 'Â±1-2%', 'Â±1-2%']
}

df_quant = pd.DataFrame(quantization_types)
print(df_quant.to_string(index=False))

print("\né‡å­åŒ–ã®åŸºæœ¬åŸç†:")
print("  FP32 â†’ INT8ã¸ã®å¤‰æ›:")
print("  scale = (max - min) / 255")
print("  zero_point = -round(min / scale)")
print("  quantized = round(value / scale) + zero_point")

# ç°¡å˜ãªé‡å­åŒ–ã®ä¾‹
fp32_tensor = torch.randn(100) * 10  # -30 ~ +30ã®ç¯„å›²

# é‡å­åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®è¨ˆç®—
min_val = fp32_tensor.min().item()
max_val = fp32_tensor.max().item()
scale = (max_val - min_val) / 255
zero_point = -round(min_val / scale)

print(f"\né‡å­åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:")
print(f"  Range: [{min_val:.2f}, {max_val:.2f}]")
print(f"  Scale: {scale:.4f}")
print(f"  Zero Point: {zero_point}")

# é‡å­åŒ–ã¨é€†é‡å­åŒ–
quantized = torch.clamp(torch.round(fp32_tensor / scale) + zero_point, 0, 255)
dequantized = (quantized - zero_point) * scale

# é‡å­åŒ–èª¤å·®
error = torch.abs(fp32_tensor - dequantized)
print(f"\né‡å­åŒ–èª¤å·®:")
print(f"  å¹³å‡èª¤å·®: {error.mean().item():.4f}")
print(f"  æœ€å¤§èª¤å·®: {error.max().item():.4f}")
print(f"  ç›¸å¯¾èª¤å·®: {(error.mean() / fp32_tensor.abs().mean() * 100).item():.2f}%")

print("\nQuantizationã®åˆ©ç‚¹:")
print("  - ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºãŒç´„75%å‰Šæ¸›")
print("  - æ¨è«–é€Ÿåº¦ãŒ2ã€œ4å€å‘ä¸Š")
print("  - ã‚¨ãƒƒã‚¸ãƒ‡ãƒã‚¤ã‚¹ã§ã®å®Ÿè¡ŒãŒå®¹æ˜“")
print("\næ³¨æ„ç‚¹:")
print("  - è¨“ç·´å¾Œé‡å­åŒ–ï¼ˆPost-Training Quantizationï¼‰ãŒä¸€èˆ¬çš„")
print("  - ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã§ç²¾åº¦ã‚’ç¶­æŒ")
print("  - CNNã¯é‡å­åŒ–ã«æ¯”è¼ƒçš„å¼·ã„")
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>=== Quantizationï¼ˆé‡å­åŒ–ï¼‰ ===

                  Type        Precision Model Size  Speed  Accuracy
          FP32 (å…ƒ)           32-bit       100%     1x      åŸºæº–
Dynamic Quantization  Mixed (8/32-bit)       ~75%    ~2x    Â±0.5%
 Static Quantization            8-bit       ~25%    ~4x   Â±1-2%
                 INT8            8-bit       ~25%    ~4x   Â±1-2%

é‡å­åŒ–ã®åŸºæœ¬åŸç†:
  FP32 â†’ INT8ã¸ã®å¤‰æ›:
  scale = (max - min) / 255
  zero_point = -round(min / scale)
  quantized = round(value / scale) + zero_point

é‡å­åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:
  Range: [-28.73, 29.45]
  Scale: 0.2282
  Zero Point: 126

é‡å­åŒ–èª¤å·®:
  å¹³å‡èª¤å·®: 0.0856
  æœ€å¤§èª¤å·®: 0.1141
  ç›¸å¯¾èª¤å·®: 1.23%

Quantizationã®åˆ©ç‚¹:
  - ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºãŒç´„75%å‰Šæ¸›
  - æ¨è«–é€Ÿåº¦ãŒ2ã€œ4å€å‘ä¸Š
  - ã‚¨ãƒƒã‚¸ãƒ‡ãƒã‚¤ã‚¹ã§ã®å®Ÿè¡ŒãŒå®¹æ˜“

æ³¨æ„ç‚¹:
  - è¨“ç·´å¾Œé‡å­åŒ–ï¼ˆPost-Training Quantizationï¼‰ãŒä¸€èˆ¬çš„
  - ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã§ç²¾åº¦ã‚’ç¶­æŒ
  - CNNã¯é‡å­åŒ–ã«æ¯”è¼ƒçš„å¼·ã„
</code></pre>

<hr>

<h2>4.7 å®Ÿè·µï¼šæœ€é©åŒ–ã•ã‚ŒãŸè¨“ç·´ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³</h2>

<h3>ã™ã¹ã¦ã®ãƒ†ã‚¯ãƒ‹ãƒƒã‚¯ã‚’çµ±åˆã—ãŸå®Œå…¨ãªè¨“ç·´ã‚¹ã‚¯ãƒªãƒ—ãƒˆ</h3>

<p>ã“ã‚Œã¾ã§å­¦ã‚“ã ã™ã¹ã¦ã®æœ€é©åŒ–æŠ€è¡“ã‚’çµ„ã¿åˆã‚ã›ãŸã€å®Ÿè·µçš„ãªè¨“ç·´ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å®Ÿè£…ã—ã¾ã™ã€‚</p>

<div class="project-box">
<h4>ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆï¼šæœ€é©åŒ–CNNã®å®Œå…¨å®Ÿè£…</h4>
<p><strong>ç›®æ¨™</strong>: ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã€æ­£å‰‡åŒ–ã€Mixed Precisionã‚’çµ±åˆã—ãŸé«˜æ€§èƒ½è¨“ç·´ã‚·ã‚¹ãƒ†ãƒ ã®æ§‹ç¯‰</p>
<p><strong>ä½¿ç”¨æŠ€è¡“</strong>:</p>
<ul>
<li>ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µ: AutoAugment + Mixup/CutMix</li>
<li>æ­£å‰‡åŒ–: Label Smoothing + Stochastic Depth</li>
<li>æœ€é©åŒ–: Mixed Precision Training + Cosine Annealing</li>
<li>è©•ä¾¡: Early Stopping + Best Model Selection</li>
</ul>
</div>

<pre><code class="language-python">import torch
import torch.nn as nn
import torch.optim as optim
from torch.cuda.amp import autocast, GradScaler
from torchvision.models import resnet18
from torchvision.transforms import AutoAugment, AutoAugmentPolicy
import numpy as np

class OptimizedTrainingPipeline:
    """æœ€é©åŒ–ã•ã‚ŒãŸè¨“ç·´ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³"""

    def __init__(self, model, device='cuda', use_amp=True,
                 use_mixup=True, use_cutmix=True, use_label_smoothing=True):
        self.model = model.to(device)
        self.device = device
        self.use_amp = use_amp and torch.cuda.is_available()
        self.use_mixup = use_mixup
        self.use_cutmix = use_cutmix

        # æå¤±é–¢æ•°
        if use_label_smoothing:
            self.criterion = LabelSmoothingCrossEntropy(epsilon=0.1)
        else:
            self.criterion = nn.CrossEntropyLoss()

        # Mixed Precisionç”¨ã®Scaler
        if self.use_amp:
            self.scaler = GradScaler()

        self.history = {
            'train_loss': [], 'train_acc': [],
            'val_loss': [], 'val_acc': []
        }
        self.best_acc = 0.0

    def apply_augmentation(self, inputs, targets):
        """ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã®é©ç”¨ï¼ˆMixupã¾ãŸã¯CutMixï¼‰"""
        if not self.training or (not self.use_mixup and not self.use_cutmix):
            return inputs, targets, None, None, 1.0

        # 50%ã®ç¢ºç‡ã§Mixupã€50%ã§CutMix
        if self.use_mixup and self.use_cutmix:
            use_mixup = np.random.rand() > 0.5
        else:
            use_mixup = self.use_mixup

        if use_mixup:
            mixed_x, y_a, y_b, lam = mixup_data(inputs, targets, alpha=1.0,
                                                device=self.device)
        else:
            mixed_x, y_a, y_b, lam = cutmix_data(inputs, targets, alpha=1.0,
                                                 device=self.device)

        return mixed_x, y_a, y_b, lam

    def train_epoch(self, trainloader, optimizer):
        """1ã‚¨ãƒãƒƒã‚¯ã®è¨“ç·´"""
        self.model.train()
        self.training = True

        running_loss = 0.0
        correct = 0
        total = 0

        for inputs, targets in trainloader:
            inputs, targets = inputs.to(self.device), targets.to(self.device)

            # ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µ
            inputs, targets_a, targets_b, lam = self.apply_augmentation(
                inputs, targets
            )

            optimizer.zero_grad()

            # Mixed Precision Training
            if self.use_amp:
                with autocast():
                    outputs = self.model(inputs)
                    if targets_a is not None:
                        loss = mixup_criterion(self.criterion, outputs,
                                              targets_a, targets_b, lam)
                    else:
                        loss = self.criterion(outputs, targets)

                self.scaler.scale(loss).backward()
                self.scaler.step(optimizer)
                self.scaler.update()
            else:
                outputs = self.model(inputs)
                if targets_a is not None:
                    loss = mixup_criterion(self.criterion, outputs,
                                          targets_a, targets_b, lam)
                else:
                    loss = self.criterion(outputs, targets)
                loss.backward()
                optimizer.step()

            running_loss += loss.item()
            _, predicted = outputs.max(1)
            total += targets.size(0)

            # ç²¾åº¦è¨ˆç®—
            if targets_a is not None:
                correct += (lam * predicted.eq(targets_a).sum().float()
                          + (1 - lam) * predicted.eq(targets_b).sum().float())
            else:
                correct += predicted.eq(targets).sum().item()

        epoch_loss = running_loss / len(trainloader)
        epoch_acc = 100. * correct / total

        return epoch_loss, epoch_acc

    def validate(self, valloader):
        """æ¤œè¨¼"""
        self.model.eval()
        self.training = False

        val_loss = 0.0
        correct = 0
        total = 0

        with torch.no_grad():
            for inputs, targets in valloader:
                inputs, targets = inputs.to(self.device), targets.to(self.device)

                if self.use_amp:
                    with autocast():
                        outputs = self.model(inputs)
                        loss = nn.CrossEntropyLoss()(outputs, targets)
                else:
                    outputs = self.model(inputs)
                    loss = nn.CrossEntropyLoss()(outputs, targets)

                val_loss += loss.item()
                _, predicted = outputs.max(1)
                total += targets.size(0)
                correct += predicted.eq(targets).sum().item()

        epoch_loss = val_loss / len(valloader)
        epoch_acc = 100. * correct / total

        return epoch_loss, epoch_acc

    def fit(self, trainloader, valloader, epochs=100, lr=0.1,
            patience=10, save_path='best_model.pth'):
        """å®Œå…¨ãªè¨“ç·´ãƒ«ãƒ¼ãƒ—"""

        # ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ã¨ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©
        optimizer = optim.SGD(self.model.parameters(), lr=lr,
                             momentum=0.9, weight_decay=5e-4)
        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)

        # Early Stopping
        best_val_acc = 0.0
        patience_counter = 0

        print(f"=== è¨“ç·´é–‹å§‹ ===")
        print(f"è¨­å®š:")
        print(f"  - Mixed Precision: {self.use_amp}")
        print(f"  - Mixup: {self.use_mixup}")
        print(f"  - CutMix: {self.use_cutmix}")
        print(f"  - Label Smoothing: {isinstance(self.criterion, LabelSmoothingCrossEntropy)}")
        print(f"  - Device: {self.device}\n")

        for epoch in range(epochs):
            # è¨“ç·´
            train_loss, train_acc = self.train_epoch(trainloader, optimizer)
            self.history['train_loss'].append(train_loss)
            self.history['train_acc'].append(train_acc)

            # æ¤œè¨¼
            val_loss, val_acc = self.validate(valloader)
            self.history['val_loss'].append(val_loss)
            self.history['val_acc'].append(val_acc)

            # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©æ›´æ–°
            scheduler.step()

            # ãƒ­ã‚°å‡ºåŠ›
            print(f'Epoch [{epoch+1:3d}/{epochs}] '
                  f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}% | '
                  f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')

            # Best Modelä¿å­˜
            if val_acc > best_val_acc:
                best_val_acc = val_acc
                patience_counter = 0
                torch.save({
                    'epoch': epoch,
                    'model_state_dict': self.model.state_dict(),
                    'optimizer_state_dict': optimizer.state_dict(),
                    'val_acc': val_acc,
                }, save_path)
                print(f'  â†’ Best model saved! Val Acc: {val_acc:.2f}%')
            else:
                patience_counter += 1

            # Early Stopping
            if patience_counter >= patience:
                print(f'\nEarly stopping at epoch {epoch+1}')
                print(f'Best validation accuracy: {best_val_acc:.2f}%')
                break

        # Best Modelã‚’ãƒ­ãƒ¼ãƒ‰
        checkpoint = torch.load(save_path)
        self.model.load_state_dict(checkpoint['model_state_dict'])
        print(f"\nBest model loaded from epoch {checkpoint['epoch']+1}")

        return self.history

# ä½¿ç”¨ä¾‹ã®ãƒ‡ãƒ¢
print("=== æœ€é©åŒ–è¨“ç·´ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®ä½¿ç”¨ä¾‹ ===\n")

# ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ï¼ˆç°¡ç•¥åŒ–ã®ãŸã‚çœç•¥ï¼‰
# trainloader, valloader = get_dataloaders()

# ãƒ¢ãƒ‡ãƒ«
model = resnet18(num_classes=10)

# ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³åˆæœŸåŒ–
pipeline = OptimizedTrainingPipeline(
    model=model,
    device='cuda' if torch.cuda.is_available() else 'cpu',
    use_amp=True,
    use_mixup=True,
    use_cutmix=True,
    use_label_smoothing=True
)

# è¨“ç·´å®Ÿè¡Œï¼ˆå®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ãŒã‚ã‚Œã°ï¼‰
# history = pipeline.fit(trainloader, valloader, epochs=100,
#                       lr=0.1, patience=10)

print("ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®ç‰¹å¾´:")
print("  âœ“ AutoAugment + Mixup/CutMix ã§ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µ")
print("  âœ“ Label Smoothing ã§éä¿¡ã‚’æŠ‘åˆ¶")
print("  âœ“ Mixed Precision ã§é«˜é€ŸåŒ–")
print("  âœ“ Cosine Annealing ã§å­¦ç¿’ç‡èª¿æ•´")
print("  âœ“ Early Stopping ã§éå­¦ç¿’é˜²æ­¢")
print("  âœ“ Best Modelè‡ªå‹•ä¿å­˜")
print("\næœŸå¾…ã•ã‚Œã‚‹åŠ¹æœ:")
print("  - ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¯”ã§+3ã€œ5%ã®ç²¾åº¦å‘ä¸Š")
print("  - è¨“ç·´æ™‚é–“ãŒç´„40%çŸ­ç¸®")
print("  - ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãŒç´„50%å‰Šæ¸›")
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>=== æœ€é©åŒ–è¨“ç·´ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®ä½¿ç”¨ä¾‹ ===

ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®ç‰¹å¾´:
  âœ“ AutoAugment + Mixup/CutMix ã§ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µ
  âœ“ Label Smoothing ã§éä¿¡ã‚’æŠ‘åˆ¶
  âœ“ Mixed Precision ã§é«˜é€ŸåŒ–
  âœ“ Cosine Annealing ã§å­¦ç¿’ç‡èª¿æ•´
  âœ“ Early Stopping ã§éå­¦ç¿’é˜²æ­¢
  âœ“ Best Modelè‡ªå‹•ä¿å­˜

æœŸå¾…ã•ã‚Œã‚‹åŠ¹æœ:
  - ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¯”ã§+3ã€œ5%ã®ç²¾åº¦å‘ä¸Š
  - è¨“ç·´æ™‚é–“ãŒç´„40%çŸ­ç¸®
  - ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãŒç´„50%å‰Šæ¸›
</code></pre>

<hr>

<h2>æ¼”ç¿’å•é¡Œ</h2>

<details>
<summary><strong>æ¼”ç¿’1: ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã®å®Ÿè£…</strong></summary>

<p>CIFAR10ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«å¯¾ã—ã¦ã€ä»¥ä¸‹ã®æ‹¡å¼µã‚’çµ„ã¿åˆã‚ã›ãŸè¨“ç·´ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å®Ÿè£…ã—ã¦ãã ã•ã„ï¼š</p>
<ol>
<li>RandomHorizontalFlip (p=0.5)</li>
<li>RandomCrop (32, padding=4)</li>
<li>ColorJitter (brightness=0.2, contrast=0.2)</li>
<li>RandomErasing (p=0.5)</li>
</ol>

<p>æ‹¡å¼µãªã—ã®ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã¨æ¯”è¼ƒã—ã¦ã€ç²¾åº¦å‘ä¸Šã‚’æ¸¬å®šã—ã¦ãã ã•ã„ã€‚</p>

<p><strong>ãƒ’ãƒ³ãƒˆ</strong>:</p>
<pre><code class="language-python">transform = transforms.Compose([
    # ã“ã“ã«æ‹¡å¼µã‚’è¿½åŠ 
    transforms.ToTensor(),
    transforms.Normalize(...)
])
</code></pre>
</details>

<details>
<summary><strong>æ¼”ç¿’2: Mixup vs CutMixã®æ¯”è¼ƒ</strong></summary>

<p>åŒã˜ãƒ¢ãƒ‡ãƒ«ã¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã€ä»¥ä¸‹ã®3ã¤ã®è¨­å®šã‚’æ¯”è¼ƒã—ã¦ãã ã•ã„ï¼š</p>
<ol>
<li>æ‹¡å¼µãªã—</li>
<li>Mixupã®ã¿ (Î±=1.0)</li>
<li>CutMixã®ã¿ (Î±=1.0)</li>
</ol>

<p>å„è¨­å®šã§10ã‚¨ãƒãƒƒã‚¯è¨“ç·´ã—ã€ãƒ†ã‚¹ãƒˆç²¾åº¦ã¨è¨“ç·´æ›²ç·šã‚’æ¯”è¼ƒã—ã¦ãã ã•ã„ã€‚</p>

<p><strong>æœŸå¾…çµæœ</strong>: CutMixãŒã‚ãšã‹ã«è‰¯ã„æ€§èƒ½ã‚’ç¤ºã™ã“ã¨ãŒå¤šã„ã§ã™ã€‚</p>
</details>

<details>
<summary><strong>æ¼”ç¿’3: Label Smoothingã®åŠ¹æœæ¤œè¨¼</strong></summary>

<p>Îµ=0.0, 0.05, 0.1, 0.2ã®4ã¤ã®è¨­å®šã§Label Smoothingã‚’è©¦ã—ã€æ¤œè¨¼ç²¾åº¦ã¸ã®å½±éŸ¿ã‚’èª¿æŸ»ã—ã¦ãã ã•ã„ã€‚</p>

<p><strong>åˆ†æé …ç›®</strong>:</p>
<ul>
<li>æœ€çµ‚ç²¾åº¦</li>
<li>è¨“ç·´æå¤±ã®æ¨ç§»</li>
<li>éå­¦ç¿’ã®ç¨‹åº¦ï¼ˆTrain vs Valç²¾åº¦ã®å·®ï¼‰</li>
</ul>
</details>

<details>
<summary><strong>æ¼”ç¿’4: Mixed Precision Trainingã®å®Ÿè£…</strong></summary>

<p>ResNet18ã‚’CIFAR10ã§è¨“ç·´ã—ã€é€šå¸¸è¨“ç·´ã¨Mixed Precisionè¨“ç·´ã‚’æ¯”è¼ƒã—ã¦ãã ã•ã„ã€‚</p>

<p><strong>æ¸¬å®šé …ç›®</strong>:</p>
<ul>
<li>1ã‚¨ãƒãƒƒã‚¯ã‚ãŸã‚Šã®è¨“ç·´æ™‚é–“</li>
<li>ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ï¼ˆtorch.cuda.max_memory_allocated()ï¼‰</li>
<li>æœ€çµ‚ç²¾åº¦</li>
</ul>

<p><strong>ãƒ’ãƒ³ãƒˆ</strong>: GPUãŒåˆ©ç”¨å¯èƒ½ãªç’°å¢ƒã§å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚</p>
</details>

<details>
<summary><strong>æ¼”ç¿’5: Pruningã®å®Ÿè£…ã¨è©•ä¾¡</strong></summary>

<p>è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦æ®µéšçš„ãªãƒ—ãƒ«ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å®Ÿæ–½ã—ã¦ãã ã•ã„ï¼š</p>
<ol>
<li>10%, 20%, 30%, 50%ã®ã‚¹ãƒ‘ãƒ¼ã‚¹æ€§ã§ãƒ—ãƒ«ãƒ¼ãƒ‹ãƒ³ã‚°</li>
<li>å„æ®µéšã§5ã‚¨ãƒãƒƒã‚¯Fine-tuning</li>
<li>ç²¾åº¦ã®å¤‰åŒ–ã‚’è¨˜éŒ²</li>
</ol>

<p><strong>åˆ†æ</strong>: ã‚¹ãƒ‘ãƒ¼ã‚¹æ€§ã¨ç²¾åº¦ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•æ›²ç·šã‚’æã„ã¦ãã ã•ã„ã€‚</p>
</details>

<details>
<summary><strong>æ¼”ç¿’6: å®Œå…¨ãªæœ€é©åŒ–ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®æ§‹ç¯‰</strong></summary>

<p>ã“ã®ç« ã§å­¦ã‚“ã ã™ã¹ã¦ã®æŠ€è¡“ã‚’çµ±åˆã—ã€CIFAR10ã§æœ€é«˜ç²¾åº¦ã‚’ç›®æŒ‡ã—ã¦ãã ã•ã„ï¼š</p>

<p><strong>è¦ä»¶</strong>:</p>
<ul>
<li>AutoAugment + Mixup/CutMix</li>
<li>Label Smoothing</li>
<li>Mixed Precision Training</li>
<li>Stochastic Depthï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰</li>
<li>Cosine Annealing LR</li>
<li>Early Stopping</li>
</ul>

<p><strong>ç›®æ¨™ç²¾åº¦</strong>: 85%ä»¥ä¸Šï¼ˆResNet18ãƒ™ãƒ¼ã‚¹ã€100ã‚¨ãƒãƒƒã‚¯ä»¥å†…ï¼‰</p>

<p><strong>æå‡ºç‰©</strong>:</p>
<ul>
<li>è¨“ç·´ã‚¹ã‚¯ãƒªãƒ—ãƒˆ</li>
<li>è¨“ç·´æ›²ç·šã®ãƒ—ãƒ­ãƒƒãƒˆ</li>
<li>å„æŠ€è¡“ã®å¯„ä¸åº¦åˆ†æï¼ˆAblation Studyï¼‰</li>
</ul>
</details>

<hr>

<h2>ã¾ã¨ã‚</h2>

<p>ã“ã®ç« ã§ã¯ã€CNNã®æ€§èƒ½ã‚’æœ€å¤§åŒ–ã™ã‚‹ãŸã‚ã®å®Ÿè·µçš„ãªæœ€é©åŒ–æŠ€è¡“ã‚’å­¦ã³ã¾ã—ãŸï¼š</p>

<table>
<thead>
<tr>
<th>ã‚«ãƒ†ã‚´ãƒª</th>
<th>æŠ€è¡“</th>
<th>åŠ¹æœ</th>
<th>å®Ÿè£…é›£æ˜“åº¦</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µ</strong></td>
<td>Flip, Crop, Color Jitter</td>
<td>+2-3% ç²¾åº¦</td>
<td>ä½</td>
</tr>
<tr>
<td></td>
<td>Mixup, CutMix</td>
<td>+1-2% ç²¾åº¦</td>
<td>ä¸­</td>
</tr>
<tr>
<td></td>
<td>AutoAugment</td>
<td>+2-4% ç²¾åº¦</td>
<td>ä½ï¼ˆäº‹å‰å­¦ç¿’ãƒãƒªã‚·ãƒ¼ä½¿ç”¨æ™‚ï¼‰</td>
</tr>
<tr>
<td><strong>æ­£å‰‡åŒ–</strong></td>
<td>Label Smoothing</td>
<td>+0.5-1% ç²¾åº¦</td>
<td>ä½</td>
</tr>
<tr>
<td></td>
<td>Stochastic Depth</td>
<td>+1-2% ç²¾åº¦ï¼ˆæ·±ã„ãƒ¢ãƒ‡ãƒ«ï¼‰</td>
<td>ä¸­</td>
</tr>
<tr>
<td><strong>è¨“ç·´æœ€é©åŒ–</strong></td>
<td>Mixed Precision</td>
<td>2-3å€é«˜é€ŸåŒ–</td>
<td>ä½</td>
</tr>
<tr>
<td></td>
<td>Cosine Annealing</td>
<td>+0.5-1% ç²¾åº¦</td>
<td>ä½</td>
</tr>
<tr>
<td><strong>ãƒ¢ãƒ‡ãƒ«è»½é‡åŒ–</strong></td>
<td>Pruning</td>
<td>50%å‰Šæ¸›ï¼ˆÂ±1%ç²¾åº¦ï¼‰</td>
<td>ä¸­</td>
</tr>
<tr>
<td></td>
<td>Quantization</td>
<td>75%å‰Šæ¸›ã€4å€é«˜é€ŸåŒ–</td>
<td>ä¸­ã€œé«˜</td>
</tr>
</tbody>
</table>

<blockquote>
<p><strong>é‡è¦ãªãƒã‚¤ãƒ³ãƒˆ</strong>:</p>
<ul>
<li>ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã¯éå­¦ç¿’æŠ‘åˆ¶ã®æœ€ã‚‚åŠ¹æœçš„ãªæ‰‹æ³•</li>
<li>Mixup/CutMixã¯å˜ç´”ãªæ‹¡å¼µã¨çµ„ã¿åˆã‚ã›ã¦ä½¿ç”¨</li>
<li>Label Smoothingã¯å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ç‰¹ã«æœ‰åŠ¹</li>
<li>Mixed Precisionã¯å®Ÿè£…ãŒç°¡å˜ã§å¤§ããªåŠ¹æœ</li>
<li>è»½é‡åŒ–ã¯ç²¾åº¦ã¨ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’æ…é‡ã«è©•ä¾¡</li>
<li>ã™ã¹ã¦ã®æŠ€è¡“ã‚’çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã§æœ€å¤§åŠ¹æœ</li>
</ul>
</blockquote>

<p>æ¬¡ã®ç« ã§ã¯ã€äº‹å‰å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ï¼ˆPre-trained Modelsï¼‰ã¨Transfer Learningã‚’å­¦ã³ã€é™ã‚‰ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã§ã•ã‚‰ã«é«˜ã„æ€§èƒ½ã‚’å®Ÿç¾ã™ã‚‹æ–¹æ³•ã‚’æ¢ã‚Šã¾ã™ã€‚</p>

<hr>

<div class="navigation">
    <a href="chapter3-advanced-architectures.html" class="nav-button">â† ç¬¬3ç« ï¼šé«˜åº¦ãªCNNã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£</a>
    <a href="chapter5-transfer-learning.html" class="nav-button">ç¬¬5ç« ï¼šè»¢ç§»å­¦ç¿’ã¨äº‹å‰å­¦ç¿’ãƒ¢ãƒ‡ãƒ« â†’</a>
</div>

    </main>

    
    <section class="disclaimer">
        <h3>å…è²¬äº‹é …</h3>
        <ul>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯æ•™è‚²ãƒ»ç ”ç©¶ãƒ»æƒ…å ±æä¾›ã®ã¿ã‚’ç›®çš„ã¨ã—ã¦ãŠã‚Šã€å°‚é–€çš„ãªåŠ©è¨€(æ³•å¾‹ãƒ»ä¼šè¨ˆãƒ»æŠ€è¡“çš„ä¿è¨¼ãªã©)ã‚’æä¾›ã™ã‚‹ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŠã‚ˆã³ä»˜éšã™ã‚‹ã‚³ãƒ¼ãƒ‰ä¾‹ã¯ã€Œç¾çŠ¶æœ‰å§¿(AS IS)ã€ã§æä¾›ã•ã‚Œã€æ˜ç¤ºã¾ãŸã¯é»™ç¤ºã‚’å•ã‚ãšã€å•†å“æ€§ã€ç‰¹å®šç›®çš„é©åˆæ€§ã€æ¨©åˆ©éä¾µå®³ã€æ­£ç¢ºæ€§ãƒ»å®Œå…¨æ€§ã€å‹•ä½œãƒ»å®‰å…¨æ€§ç­‰ã„ã‹ãªã‚‹ä¿è¨¼ã‚‚ã—ã¾ã›ã‚“ã€‚</li>
            <li>å¤–éƒ¨ãƒªãƒ³ã‚¯ã€ç¬¬ä¸‰è€…ãŒæä¾›ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ»ãƒ„ãƒ¼ãƒ«ãƒ»ãƒ©ã‚¤ãƒ–ãƒ©ãƒªç­‰ã®å†…å®¹ãƒ»å¯ç”¨æ€§ãƒ»å®‰å…¨æ€§ã«ã¤ã„ã¦ã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯ä¸€åˆ‡ã®è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®åˆ©ç”¨ãƒ»å®Ÿè¡Œãƒ»è§£é‡ˆã«ã‚ˆã‚Šç›´æ¥çš„ãƒ»é–“æ¥çš„ãƒ»ä»˜éšçš„ãƒ»ç‰¹åˆ¥ãƒ»çµæœçš„ãƒ»æ‡²ç½°çš„æå®³ãŒç”Ÿã˜ãŸå ´åˆã§ã‚‚ã€é©ç”¨æ³•ã§è¨±å®¹ã•ã‚Œã‚‹æœ€å¤§é™ã®ç¯„å›²ã§ã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å†…å®¹ã¯ã€äºˆå‘Šãªãå¤‰æ›´ãƒ»æ›´æ–°ãƒ»æä¾›åœæ­¢ã•ã‚Œã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®è‘—ä½œæ¨©ãƒ»ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯æ˜è¨˜ã•ã‚ŒãŸæ¡ä»¶(ä¾‹: CC BY 4.0)ã«å¾“ã„ã¾ã™ã€‚å½“è©²ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯é€šå¸¸ã€ç„¡ä¿è¨¼æ¡é …ã‚’å«ã¿ã¾ã™ã€‚</li>
        </ul>
    </section>

<footer>
        <p>&copy; 2025 AI Terakoya. All rights reserved.</p>
        <p>ML-A01: CNNå…¥é–€ã‚³ãƒ¼ã‚¹ | ç¬¬4ç« ï¼šãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã¨ãƒ¢ãƒ‡ãƒ«æœ€é©åŒ–</p>
    </footer>

</body>
</html>
