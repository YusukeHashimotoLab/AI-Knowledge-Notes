<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="畳み込みニューラルネットワーク（CNN）入門シリーズ - 完全ガイド">
    <title>畳み込みニューラルネットワーク（CNN）入門シリーズ v1.0 - AI Terakoya</title>

    <!-- CSS Styling -->
    <style>
        :root {
            --primary-color: #2c3e50;
            --secondary-color: #3498db;
            --accent-color: #e74c3c;
            --bg-color: #ffffff;
            --text-color: #333333;
            --border-color: #e0e0e0;
            --code-bg: #f5f5f5;
            --link-color: #3498db;
            --link-hover: #2980b9;
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", "Hiragino Sans", "Hiragino Kaku Gothic ProN", Meiryo, sans-serif;
            line-height: 1.8;
            color: var(--text-color);
            background: var(--bg-color);
            padding: 0;
            margin: 0;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 2rem 1.5rem;
        }

        /* Header */
        header {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 2rem 0;
            margin-bottom: 2rem;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }

        header .container {
            padding: 0 1.5rem;
        }

        h1 {
            font-size: 2rem;
            margin-bottom: 0.5rem;
            font-weight: 700;
        }

        .meta {
            display: flex;
            gap: 1.5rem;
            flex-wrap: wrap;
            font-size: 0.9rem;
            opacity: 0.95;
            margin-top: 1rem;
        }

        .meta span {
            display: inline-flex;
            align-items: center;
            gap: 0.3rem;
        }

        /* Typography */
        h2 {
            font-size: 1.75rem;
            margin-top: 2.5rem;
            margin-bottom: 1rem;
            padding-bottom: 0.5rem;
            border-bottom: 3px solid var(--secondary-color);
            color: var(--primary-color);
        }

        h3 {
            font-size: 1.4rem;
            margin-top: 2rem;
            margin-bottom: 0.8rem;
            color: var(--primary-color);
        }

        h4 {
            font-size: 1.2rem;
            margin-top: 1.5rem;
            margin-bottom: 0.6rem;
            color: var(--primary-color);
        }

        p {
            margin-bottom: 1.2rem;
        }

        a {
            color: var(--link-color);
            text-decoration: none;
            transition: color 0.2s;
        }

        a:hover {
            color: var(--link-hover);
            text-decoration: underline;
        }

        /* Lists */
        ul, ol {
            margin-left: 2rem;
            margin-bottom: 1.2rem;
        }

        li {
            margin-bottom: 0.5rem;
        }

        /* Code blocks */
        code {
            background: var(--code-bg);
            padding: 0.2rem 0.4rem;
            border-radius: 3px;
            font-family: 'Menlo', 'Monaco', 'Courier New', monospace;
            font-size: 0.9em;
        }

        pre {
            background: var(--code-bg);
            padding: 1.5rem;
            border-radius: 8px;
            overflow-x: auto;
            margin-bottom: 1.5rem;
            border: 1px solid var(--border-color);
        }

        pre code {
            background: none;
            padding: 0;
            font-size: 0.9rem;
        }

        /* Tables */
        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: 1.5rem;
            overflow-x: auto;
            display: block;
        }

        thead {
            display: table;
            width: 100%;
            table-layout: fixed;
        }

        tbody {
            display: table;
            width: 100%;
            table-layout: fixed;
        }

        th, td {
            padding: 0.8rem;
            text-align: left;
            border: 1px solid var(--border-color);
        }

        th {
            background: var(--primary-color);
            color: white;
            font-weight: 600;
        }

        tr:nth-child(even) {
            background: #f9f9f9;
        }

        /* Blockquotes */
        blockquote {
            border-left: 4px solid var(--secondary-color);
            padding-left: 1.5rem;
            margin: 1.5rem 0;
            font-style: italic;
            color: #666;
        }

        /* Images */
        img {
            max-width: 100%;
            height: auto;
            border-radius: 8px;
            margin: 1rem 0;
        }

        /* Mermaid diagrams */
        .mermaid {
            text-align: center;
            margin: 2rem 0;
            background: white;
            padding: 1rem;
            border-radius: 8px;
            border: 1px solid var(--border-color);
        }

        /* Details/Summary (for exercises) */
        details {
            margin: 1rem 0;
            padding: 1rem;
            background: #f8f9fa;
            border-radius: 8px;
            border: 1px solid var(--border-color);
        }

        summary {
            cursor: pointer;
            font-weight: 600;
            color: var(--primary-color);
            padding: 0.5rem;
        }

        summary:hover {
            color: var(--secondary-color);
        }

        /* Footer */
        footer {
            margin-top: 4rem;
            padding: 2rem 0;
            border-top: 2px solid var(--border-color);
            text-align: center;
            color: #666;
            font-size: 0.9rem;
        }
        .disclaimer {
            max-width: 900px;
            margin: 2rem auto;
            padding: 1.5rem;
            background: #f8f9fa;
            border-left: 4px solid #6c757d;
            border-radius: 4px;
        }

        .disclaimer h3 {
            color: #495057;
            margin-bottom: 1rem;
            font-size: 1.1rem;
        }

        .disclaimer ul {
            list-style: none;
            padding-left: 0;
        }

        .disclaimer li {
            padding: 0.5rem 0;
            padding-left: 1.5rem;
            position: relative;
            font-size: 0.9rem;
            color: #6c757d;
            line-height: 1.6;
        }

        .disclaimer li::before {
            content: "⚠️";
            position: absolute;
            left: 0;
        }


        /* Navigation buttons */
        .nav-buttons {
            display: flex;
            justify-content: space-between;
            margin: 3rem 0;
            gap: 1rem;
            flex-wrap: wrap;
        }

        .nav-button {
            display: inline-block;
            padding: 0.8rem 1.5rem;
            background: var(--secondary-color);
            color: white;
            border-radius: 6px;
            text-decoration: none;
            transition: all 0.3s;
            font-weight: 600;
        }

        .nav-button:hover {
            background: var(--link-hover);
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(52, 152, 219, 0.3);
        }

        /* Responsive */
        @media (max-width: 768px) {
            .container {
                padding: 1rem;
            }

            h1 {
                font-size: 1.6rem;
            }

            h2 {
                font-size: 1.4rem;
            }

            .meta {
                font-size: 0.85rem;
            }

            pre {
                padding: 1rem;
                font-size: 0.85rem;
            }

            table {
                font-size: 0.9rem;
            }
        }
    </style>

    <!-- Mermaid for diagrams -->
    <script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
    <script>
        // Mermaid.js Converter - Converts markdown-style mermaid code blocks to renderable divs
        document.addEventListener('DOMContentLoaded', function() {
            // Find all code blocks with class="language-mermaid"
            const mermaidCodeBlocks = document.querySelectorAll('pre.codehilite code.language-mermaid, pre code.language-mermaid');

            mermaidCodeBlocks.forEach(function(codeBlock) {
                const pre = codeBlock.parentElement;
                const mermaidCode = codeBlock.textContent;

                // Create a new div with mermaid class
                const mermaidDiv = document.createElement('div');
                mermaidDiv.className = 'mermaid';
                mermaidDiv.textContent = mermaidCode.trim();

                // Replace the pre element with the new div
                pre.parentNode.replaceChild(mermaidDiv, pre);
            });

            // Re-initialize mermaid after conversion
            if (typeof mermaid !== 'undefined') {
                mermaid.initialize({ startOnLoad: true, theme: 'default' });
                mermaid.init(undefined, document.querySelectorAll('.mermaid'));
            }
        });
    </script>
</head>
<body>
    <header>
        <div class="container">
            <h1>🖼️ 畳み込みニューラルネットワーク（CNN）入門シリーズ v1.0</h1>
            <p style="font-size: 1.1rem; margin-top: 0.5rem; opacity: 0.95;">画像認識の基礎から転移学習・物体検出まで</p>
            <div class="meta">
                <span>📖 総学習時間: 100-120分</span>
                <span>📊 レベル: 中級</span>
            </div>
        </div>
    </header>

    <main class="container">
        <p><strong>画像認識のための最重要アーキテクチャを体系的にマスター</strong></p>

        <h2 id="overview">シリーズ概要</h2>
        <p>このシリーズは、畳み込みニューラルネットワーク（Convolutional Neural Network, CNN）を基礎から段階的に学べる全5章構成の実践的教育コンテンツです。</p>

        <p><strong>CNN</strong>は、画像認識・物体検出・セグメンテーションなどのコンピュータビジョンタスクにおいて最も重要な深層学習アーキテクチャです。畳み込み層による局所的特徴抽出、プーリング層による次元削減、そして転移学習による効率的なモデル構築手法を習得することで、実務で使える画像認識システムを構築できます。基礎的なCNNの仕組みから、ResNet・EfficientNetなどの最新アーキテクチャ、YOLOによる物体検出まで、体系的な知識を提供します。</p>

        <p><strong>特徴:</strong></p>
        <ul>
            <li>✅ <strong>基礎から応用まで</strong>: 畳み込みの原理から物体検出まで体系的に学習</li>
            <li>✅ <strong>実装重視</strong>: 40個以上の実行可能なPyTorchコード例、実践的なテクニック</li>
            <li>✅ <strong>直感的理解</strong>: フィルタ・特徴マップの可視化で動作原理を理解</li>
            <li>✅ <strong>PyTorch完全準拠</strong>: 業界標準フレームワークを使った最新の実装手法</li>
            <li>✅ <strong>転移学習実践</strong>: 事前学習済みモデルによる効率的な開発手法</li>
        </ul>

        <p><strong>総学習時間</strong>: 100-120分（コード実行と演習を含む）</p>

        <h2 id="learning">学習の進め方</h2>

        <h3>推奨学習順序</h3>

        <div class="mermaid">
graph TD
    A[第1章: CNNの基礎と畳み込み層] --> B[第2章: プーリング層とCNNアーキテクチャ]
    B --> C[第3章: 転移学習とファインチューニング]
    C --> D[第4章: データ拡張とモデル最適化]
    D --> E[第5章: 物体検出入門]

    style A fill:#e3f2fd
    style B fill:#fff3e0
    style C fill:#f3e5f5
    style D fill:#e8f5e9
    style E fill:#fce4ec
</div>

        <p><strong>初学者の方（CNNをまったく知らない）:</strong><br>
        - 第1章 → 第2章 → 第3章 → 第4章 → 第5章（全章推奨）<br>
        - 所要時間: 100-120分</p>

        <p><strong>中級者の方（深層学習の経験あり）:</strong><br>
        - 第2章 → 第3章 → 第4章 → 第5章<br>
        - 所要時間: 80-90分</p>

        <p><strong>特定トピックの強化:</strong><br>
        - 転移学習: 第3章（集中学習）<br>
        - データ拡張: 第4章（集中学習）<br>
        - 物体検出: 第5章（集中学習）<br>
        - 所要時間: 20-25分/章</p>

        <h2 id="chapters">各章の詳細</h2>

        <h3><a href="./chapter1-cnn-basics.html">第1章：CNNの基礎と畳み込み層</a></h3>
        <p><strong>難易度</strong>: 初級〜中級<br>
        <strong>読了時間</strong>: 20-25分<br>
        <strong>コード例</strong>: 8個</p>

        <h4>学習内容</h4>
        <ol>
            <li><strong>畳み込み演算の原理</strong> - カーネル、ストライド、パディングの理解</li>
            <li><strong>フィルタと特徴マップ</strong> - エッジ検出、テクスチャ抽出の仕組み</li>
            <li><strong>チャネルと次元</strong> - RGB画像の処理、多チャネル畳み込み</li>
            <li><strong>畳み込み層の実装</strong> - PyTorchによるConv2Dの実装と可視化</li>
            <li><strong>受容野の概念</strong> - 畳み込み層の重ね方と視野の広がり</li>
        </ol>

        <h4>学習目標</h4>
        <ul>
            <li>✅ 畳み込み演算の数学的原理を理解する</li>
            <li>✅ フィルタによる特徴抽出の仕組みを説明できる</li>
            <li>✅ パディングとストライドの効果を理解する</li>
            <li>✅ PyTorchでConv2Dを実装できる</li>
            <li>✅ 特徴マップを可視化して解釈できる</li>
        </ul>

        <p><strong><a href="./chapter1-cnn-basics.html">第1章を読む →</a></strong></p>

        <hr>

        <h3><a href="./chapter2-pooling-architectures.html">第2章：プーリング層とCNNアーキテクチャ</a></h3>
        <p><strong>難易度</strong>: 中級<br>
        <strong>読了時間</strong>: 20-25分<br>
        <strong>コード例</strong>: 8個</p>

        <h4>学習内容</h4>
        <ol>
            <li><strong>プーリング層の役割</strong> - Max Pooling、Average Pooling、次元削減</li>
            <li><strong>LeNetとAlexNet</strong> - 初期のCNNアーキテクチャの特徴と実装</li>
            <li><strong>VGGNet</strong> - 小さなフィルタを重ねる設計思想</li>
            <li><strong>ResNet</strong> - 残差接続による深層化と勾配消失問題の解決</li>
            <li><strong>EfficientNet</strong> - 効率的なスケーリング手法</li>
        </ol>

        <h4>学習目標</h4>
        <ul>
            <li>✅ プーリング層の役割と種類を理解する</li>
            <li>✅ 代表的なCNNアーキテクチャの特徴を説明できる</li>
            <li>✅ ResNetの残差接続の重要性を理解する</li>
            <li>✅ PyTorchでVGG/ResNetを実装できる</li>
            <li>✅ アーキテクチャの選択基準を理解する</li>
        </ul>

        <p><strong><a href="./chapter2-pooling-architectures.html">第2章を読む →</a></strong></p>

        <hr>

        <h3><a href="./chapter3-transfer-learning.html">第3章：転移学習とファインチューニング</a></h3>
        <p><strong>難易度</strong>: 中級<br>
        <strong>読了時間</strong>: 20-25分<br>
        <strong>コード例</strong>: 8個</p>

        <h4>学習内容</h4>
        <ol>
            <li><strong>転移学習の原理</strong> - ImageNet事前学習モデルの活用</li>
            <li><strong>特徴抽出アプローチ</strong> - 凍結層による高速学習</li>
            <li><strong>ファインチューニング</strong> - 段階的な層の解凍と学習</li>
            <li><strong>timmライブラリの活用</strong> - 数百種類の事前学習済みモデル</li>
            <li><strong>ドメイン適応</strong> - 異なるデータセットへの適用戦略</li>
        </ol>

        <h4>学習目標</h4>
        <ul>
            <li>✅ 転移学習のメリットと原理を理解する</li>
            <li>✅ torchvisionで事前学習済みモデルを読み込める</li>
            <li>✅ 特徴抽出とファインチューニングを使い分けられる</li>
            <li>✅ timmで最新モデルを活用できる</li>
            <li>✅ データサイズに応じた転移学習戦略を設計できる</li>
        </ul>

        <p><strong><a href="./chapter3-transfer-learning.html">第3章を読む →</a></strong></p>

        <hr>

        <h3><a href="./chapter4-data-augmentation.html">第4章：データ拡張とモデル最適化</a></h3>
        <p><strong>難易度</strong>: 中級<br>
        <strong>読了時間</strong>: 20-25分<br>
        <strong>コード例</strong>: 8個</p>

        <h4>学習内容</h4>
        <ol>
            <li><strong>基本的なデータ拡張</strong> - 回転、反転、クロッピング、色変換</li>
            <li><strong>高度な拡張手法</strong> - Mixup、CutMix、RandAugment</li>
            <li><strong>正則化テクニック</strong> - Dropout、Batch Normalization、Weight Decay</li>
            <li><strong>Mixed Precision学習</strong> - FP16による高速化とメモリ削減</li>
            <li><strong>学習率スケジューリング</strong> - Cosine Annealing、Warmup</li>
        </ol>

        <h4>学習目標</h4>
        <ul>
            <li>✅ torchvision.transformsでデータ拡張を実装できる</li>
            <li>✅ Mixup/CutMixの効果を理解する</li>
            <li>✅ 正則化手法を適切に適用できる</li>
            <li>✅ Mixed Precision学習で高速化できる</li>
            <li>✅ 学習率スケジューラを効果的に使える</li>
        </ul>

        <p><strong><a href="./chapter4-data-augmentation.html">第4章を読む →</a></strong></p>

        <hr>

        <h3><a href="./chapter5-object-detection.html">第5章：物体検出入門</a></h3>
        <p><strong>難易度</strong>: 中級<br>
        <strong>読了時間</strong>: 25-30分<br>
        <strong>コード例</strong>: 8個</p>

        <h4>学習内容</h4>
        <ol>
            <li><strong>物体検出の基礎</strong> - Bounding Box、IoU、Non-Maximum Suppression</li>
            <li><strong>YOLOアーキテクチャ</strong> - ワンステージ検出の仕組みと実装</li>
            <li><strong>Faster R-CNN</strong> - ツーステージ検出とRegion Proposal Network</li>
            <li><strong>検出評価指標</strong> - mAP、Precision-Recall曲線</li>
            <li><strong>実践的な物体検出</strong> - OpenCVとの連携、リアルタイム推論</li>
        </ol>

        <h4>学習目標</h4>
        <ul>
            <li>✅ 物体検出の基本概念を理解する</li>
            <li>✅ IoUとNMSの仕組みを説明できる</li>
            <li>✅ YOLOで物体検出を実装できる</li>
            <li>✅ mAPで検出性能を評価できる</li>
            <li>✅ OpenCVと連携してリアルタイム検出できる</li>
        </ul>

        <p><strong><a href="./chapter5-object-detection.html">第5章を読む →</a></strong></p>

        <hr>

        <h2 id="outcomes">全体の学習成果</h2>

        <p>このシリーズを完了すると、以下のスキルと知識を習得できます：</p>

        <h3>知識レベル（Understanding）</h3>
        <ul>
            <li>✅ CNNの畳み込み演算とプーリングの原理を説明できる</li>
            <li>✅ 代表的なCNNアーキテクチャの特徴と進化を理解している</li>
            <li>✅ 転移学習の仕組みとメリットを説明できる</li>
            <li>✅ データ拡張と正則化の効果を理解している</li>
            <li>✅ 物体検出の基本アルゴリズムを説明できる</li>
        </ul>

        <h3>実践スキル（Doing）</h3>
        <ul>
            <li>✅ PyTorchでCNNを実装できる</li>
            <li>✅ 事前学習済みモデルで転移学習を実行できる</li>
            <li>✅ データ拡張パイプラインを構築できる</li>
            <li>✅ Mixed Precisionで学習を高速化できる</li>
            <li>✅ YOLOで物体検出システムを構築できる</li>
        </ul>

        <h3>応用力（Applying）</h3>
        <ul>
            <li>✅ 新しい画像分類タスクに適切なアーキテクチャを選択できる</li>
            <li>✅ データサイズに応じた転移学習戦略を設計できる</li>
            <li>✅ 過学習を防ぎながらモデルを最適化できる</li>
            <li>✅ リアルタイム推論システムを構築できる</li>
        </ul>

        <hr>

        <h2 id="prerequisites">前提知識</h2>

        <p>このシリーズを効果的に学習するために、以下の知識があることが望ましいです：</p>

        <h3>必須（Must Have）</h3>
        <ul>
            <li>✅ <strong>Python基礎</strong>: 変数、関数、クラス、ループ、条件分岐</li>
            <li>✅ <strong>NumPy基礎</strong>: 配列操作、ブロードキャスト、基本的な数学関数</li>
            <li>✅ <strong>深層学習の基礎</strong>: ニューラルネットワーク、誤差逆伝播、勾配降下法</li>
            <li>✅ <strong>PyTorch基礎</strong>: テンソル操作、nn.Module、DatasetとDataLoader</li>
            <li>✅ <strong>線形代数の基礎</strong>: 行列演算、内積、形状変換</li>
        </ul>

        <h3>推奨（Nice to Have）</h3>
        <ul>
            <li>💡 <strong>画像処理の基礎</strong>: ピクセル、チャネル、画像フォーマット</li>
            <li>💡 <strong>最適化アルゴリズム</strong>: Adam、SGD、学習率スケジューリング</li>
            <li>💡 <strong>Matplotlib/PIL</strong>: 画像の読み込みと可視化</li>
            <li>💡 <strong>GPU環境</strong>: CUDAの基本的な理解</li>
        </ul>

        <p><strong>推奨される前の学習</strong>:</p>
        <ul>
            <li>📚 <a href="../deep-learning-basics/">深層学習の基礎シリーズ</a> - ニューラルネットワークの基本</li>
            <li>📚 <a href="../pytorch-introduction/">PyTorch入門シリーズ</a> - PyTorchの基本操作</li>
        </ul>

        <hr>

        <h2 id="tech">使用技術とツール</h2>

        <h3>主要ライブラリ</h3>
        <ul>
            <li><strong>PyTorch 2.0+</strong> - 深層学習フレームワーク</li>
            <li><strong>torchvision 0.15+</strong> - 画像処理とモデルライブラリ</li>
            <li><strong>timm 0.9+</strong> - PyTorch Image Models、事前学習済みモデル集</li>
            <li><strong>OpenCV 4.8+</strong> - 画像処理と物体検出</li>
            <li><strong>NumPy 1.24+</strong> - 数値計算</li>
            <li><strong>Matplotlib 3.7+</strong> - 可視化</li>
            <li><strong>Pillow 10.0+</strong> - 画像読み込みと変換</li>
        </ul>

        <h3>開発環境</h3>
        <ul>
            <li><strong>Python 3.8+</strong> - プログラミング言語</li>
            <li><strong>Jupyter Notebook / Lab</strong> - 対話的開発環境</li>
            <li><strong>Google Colab</strong> - GPU環境（無料で利用可能）</li>
            <li><strong>CUDA 11.8+ / cuDNN</strong> - GPU高速化（推奨）</li>
        </ul>

        <h3>データセット</h3>
        <ul>
            <li><strong>CIFAR-10/100</strong> - 画像分類の基礎学習</li>
            <li><strong>ImageNet</strong> - 大規模画像分類（事前学習）</li>
            <li><strong>COCO</strong> - 物体検出とセグメンテーション</li>
        </ul>

        <hr>

        <h2 id="start">さあ、始めましょう！</h2>
        <p>準備はできましたか？ 第1章から始めて、CNNの技術を習得しましょう！</p>

        <p><strong><a href="./chapter1-cnn-basics.html">第1章: CNNの基礎と畳み込み層 →</a></strong></p>

        <hr>

        <h2 id="next">次のステップ</h2>

        <p>このシリーズを完了した後、以下のトピックへ進むことをお勧めします：</p>

        <h3>深掘り学習</h3>
        <ul>
            <li>📚 <strong>セグメンテーション</strong>: U-Net、Mask R-CNN、セマンティックセグメンテーション</li>
            <li>📚 <strong>Vision Transformer</strong>: ViT、Swin Transformer、Attention機構</li>
            <li>📚 <strong>画像生成</strong>: GAN、VAE、Diffusion Models</li>
            <li>📚 <strong>モデル軽量化</strong>: 量子化、プルーニング、Knowledge Distillation</li>
        </ul>

        <h3>関連シリーズ</h3>
        <ul>
            <li>🎯 <a href="../deep-learning-advanced/">深層学習応用</a> - Attention、Transformer、最新アーキテクチャ</li>
            <li>🎯 <a href="../computer-vision/">コンピュータビジョン応用</a> - セグメンテーション、姿勢推定</li>
            <li>🎯 <a href="../model-deployment/">モデルデプロイメント</a> - ONNX、TensorRT、本番環境への展開</li>
        </ul>

        <h3>実践プロジェクト</h3>
        <ul>
            <li>🚀 画像分類システム - 転移学習による独自データセットの分類</li>
            <li>🚀 顔認識アプリ - リアルタイム顔検出と認証</li>
            <li>🚀 医療画像診断 - X線画像の異常検出</li>
            <li>🚀 自動運転シミュレーション - 物体検出と車線認識</li>
        </ul>

        <hr>

        <p><strong>更新履歴</strong></p>
        <ul>
            <li><strong>2025-10-21</strong>: v1.0 初版公開</li>
        </ul>

        <hr>

        <p><strong>あなたのCNN学習の旅はここから始まります！</strong></p>

    </main>

    
    <section class="disclaimer">
        <h3>免責事項</h3>
        <ul>
            <li>本コンテンツは教育・研究・情報提供のみを目的としており、専門的な助言(法律・会計・技術的保証など)を提供するものではありません。</li>
            <li>本コンテンツおよび付随するコード例は「現状有姿(AS IS)」で提供され、明示または黙示を問わず、商品性、特定目的適合性、権利非侵害、正確性・完全性、動作・安全性等いかなる保証もしません。</li>
            <li>外部リンク、第三者が提供するデータ・ツール・ライブラリ等の内容・可用性・安全性について、作成者および東北大学は一切の責任を負いません。</li>
            <li>本コンテンツの利用・実行・解釈により直接的・間接的・付随的・特別・結果的・懲罰的損害が生じた場合でも、適用法で許容される最大限の範囲で、作成者および東北大学は責任を負いません。</li>
            <li>本コンテンツの内容は、予告なく変更・更新・提供停止されることがあります。</li>
            <li>本コンテンツの著作権・ライセンスは明記された条件(例: CC BY 4.0)に従います。当該ライセンスは通常、無保証条項を含みます。</li>
        </ul>
    </section>

<footer>
        <div class="container">
            <p>&copy; 2025 AI Terakoya - Dr. Yusuke Hashimoto, Tohoku University</p>
            <p>Licensed under CC BY 4.0</p>
        </div>
    </footer>
</body>
</html>
