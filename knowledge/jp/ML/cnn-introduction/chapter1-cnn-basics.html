<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ç¬¬1ç« ï¼šCNNã®åŸºç¤ã¨ç•³ã¿è¾¼ã¿å±¤ - AI Terakoya</title>

    <style>
        :root {
            --color-primary: #2c3e50;
            --color-primary-dark: #1a252f;
            --color-accent: #7b2cbf;
            --color-accent-light: #9d4edd;
            --color-text: #2d3748;
            --color-text-light: #4a5568;
            --color-bg: #ffffff;
            --color-bg-alt: #f7fafc;
            --color-border: #e2e8f0;
            --color-code-bg: #f8f9fa;
            --color-link: #3182ce;
            --color-link-hover: #2c5aa0;

            --spacing-xs: 0.5rem;
            --spacing-sm: 1rem;
            --spacing-md: 1.5rem;
            --spacing-lg: 2rem;
            --spacing-xl: 3rem;

            --font-body: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            --font-mono: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;

            --border-radius: 8px;
            --box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: var(--font-body);
            line-height: 1.7;
            color: var(--color-text);
            background-color: var(--color-bg);
            font-size: 16px;
        }

        header {
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            padding: var(--spacing-xl) var(--spacing-md);
            margin-bottom: var(--spacing-xl);
            box-shadow: var(--box-shadow);
        }

        .header-content {
            max-width: 900px;
            margin: 0 auto;
        }

        h1 {
            font-size: 2rem;
            font-weight: 700;
            margin-bottom: var(--spacing-sm);
            line-height: 1.2;
        }

        .subtitle {
            font-size: 1.1rem;
            opacity: 0.95;
            font-weight: 400;
            margin-bottom: var(--spacing-md);
        }

        .meta {
            display: flex;
            flex-wrap: wrap;
            gap: var(--spacing-md);
            font-size: 0.9rem;
            opacity: 0.9;
        }

        .meta-item {
            display: flex;
            align-items: center;
            gap: 0.3rem;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 0 var(--spacing-md) var(--spacing-xl);
        }

        h2 {
            font-size: 1.75rem;
            color: var(--color-primary);
            margin-top: var(--spacing-xl);
            margin-bottom: var(--spacing-md);
            padding-bottom: var(--spacing-xs);
            border-bottom: 3px solid var(--color-accent);
        }

        h3 {
            font-size: 1.4rem;
            color: var(--color-primary);
            margin-top: var(--spacing-lg);
            margin-bottom: var(--spacing-sm);
        }

        h4 {
            font-size: 1.1rem;
            color: var(--color-primary-dark);
            margin-top: var(--spacing-md);
            margin-bottom: var(--spacing-sm);
        }

        p {
            margin-bottom: var(--spacing-md);
            color: var(--color-text);
        }

        a {
            color: var(--color-link);
            text-decoration: none;
            transition: color 0.2s;
        }

        a:hover {
            color: var(--color-link-hover);
            text-decoration: underline;
        }

        ul, ol {
            margin-left: var(--spacing-lg);
            margin-bottom: var(--spacing-md);
        }

        li {
            margin-bottom: var(--spacing-xs);
            color: var(--color-text);
        }

        pre {
            background-color: var(--color-code-bg);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            overflow-x: auto;
            margin-bottom: var(--spacing-md);
            font-family: var(--font-mono);
            font-size: 0.9rem;
            line-height: 1.5;
        }

        code {
            font-family: var(--font-mono);
            font-size: 0.9em;
            background-color: var(--color-code-bg);
            padding: 0.2em 0.4em;
            border-radius: 3px;
        }

        pre code {
            background-color: transparent;
            padding: 0;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: var(--spacing-md);
            font-size: 0.95rem;
        }

        th, td {
            border: 1px solid var(--color-border);
            padding: var(--spacing-sm);
            text-align: left;
        }

        th {
            background-color: var(--color-bg-alt);
            font-weight: 600;
            color: var(--color-primary);
        }

        blockquote {
            border-left: 4px solid var(--color-accent);
            padding-left: var(--spacing-md);
            margin: var(--spacing-md) 0;
            color: var(--color-text-light);
            font-style: italic;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        .mermaid {
            text-align: center;
            margin: var(--spacing-lg) 0;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        details {
            background-color: var(--color-bg-alt);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            margin-bottom: var(--spacing-md);
        }

        summary {
            cursor: pointer;
            font-weight: 600;
            color: var(--color-primary);
            user-select: none;
            padding: var(--spacing-xs);
            margin: calc(-1 * var(--spacing-md));
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        summary:hover {
            background-color: rgba(123, 44, 191, 0.1);
        }

        details[open] summary {
            margin-bottom: var(--spacing-md);
            border-bottom: 1px solid var(--color-border);
        }

        .navigation {
            display: flex;
            justify-content: space-between;
            gap: var(--spacing-md);
            margin: var(--spacing-xl) 0;
            padding-top: var(--spacing-lg);
            border-top: 2px solid var(--color-border);
        }

        .nav-button {
            flex: 1;
            padding: var(--spacing-md);
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            border-radius: var(--border-radius);
            text-align: center;
            font-weight: 600;
            transition: transform 0.2s, box-shadow 0.2s;
            box-shadow: var(--box-shadow);
        }

        .nav-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
            text-decoration: none;
        }

        footer {
            margin-top: var(--spacing-xl);
            padding: var(--spacing-lg) var(--spacing-md);
            background-color: var(--color-bg-alt);
            border-top: 1px solid var(--color-border);
            text-align: center;
            font-size: 0.9rem;
            color: var(--color-text-light);
        }
        .disclaimer {
            max-width: 900px;
            margin: 2rem auto;
            padding: 1.5rem;
            background: #f8f9fa;
            border-left: 4px solid #6c757d;
            border-radius: 4px;
        }

        .disclaimer h3 {
            color: #495057;
            margin-bottom: 1rem;
            font-size: 1.1rem;
        }

        .disclaimer ul {
            list-style: none;
            padding-left: 0;
        }

        .disclaimer li {
            padding: 0.5rem 0;
            padding-left: 1.5rem;
            position: relative;
            font-size: 0.9rem;
            color: #6c757d;
            line-height: 1.6;
        }

        .disclaimer li::before {
            content: "âš ï¸";
            position: absolute;
            left: 0;
        }


        @media (max-width: 768px) {
            h1 {
                font-size: 1.5rem;
            }

            h2 {
                font-size: 1.4rem;
            }

            h3 {
                font-size: 1.2rem;
            }

            .meta {
                font-size: 0.85rem;
            }

            .navigation {
                flex-direction: column;
            }

            table {
                font-size: 0.85rem;
            }

            th, td {
                padding: var(--spacing-xs);
            }
        }
    
        
    
        /* Breadcrumb styles */
        .breadcrumb {
            background: #f7fafc;
            padding: 0.75rem 1rem;
            border-bottom: 1px solid #e2e8f0;
            font-size: 0.9rem;
        }

        .breadcrumb-content {
            max-width: 900px;
            margin: 0 auto;
            display: flex;
            align-items: center;
            flex-wrap: wrap;
            gap: 0.5rem;
        }

        .breadcrumb a {
            color: #667eea;
            text-decoration: none;
            transition: color 0.2s;
        }

        .breadcrumb a:hover {
            color: #764ba2;
            text-decoration: underline;
        }

        .breadcrumb-separator {
            color: #a0aec0;
            margin: 0 0.25rem;
        }

        .breadcrumb-current {
            color: #4a5568;
            font-weight: 500;
        }
    </style>

    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
        mermaid.initialize({ startOnLoad: true, theme: 'default' });
    </script>

    <!-- MathJax for LaTeX equation rendering -->
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                displayMath: [['$$', '$$'], ['\\[', '\\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
                ignoreHtmlClass: 'mermaid'
            }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" async></script>
</head>
<body>
            <nav class="breadcrumb">
        <div class="breadcrumb-content">
            <a href="/AI-Knowledge-Notes/knowledge/jp/index.html">AIå¯ºå­å±‹ãƒˆãƒƒãƒ—</a><span class="breadcrumb-separator">â€º</span><a href="/AI-Knowledge-Notes/knowledge/jp/ML/index.html">æ©Ÿæ¢°å­¦ç¿’</a><span class="breadcrumb-separator">â€º</span><a href="/AI-Knowledge-Notes/knowledge/jp/ML/cnn-introduction/index.html">Cnn</a><span class="breadcrumb-separator">â€º</span><span class="breadcrumb-current">Chapter 1</span>
        </div>
    </nav>

        <header>
        <div class="header-content">
            <h1>ç¬¬1ç« ï¼šCNNã®åŸºç¤ã¨ç•³ã¿è¾¼ã¿å±¤</h1>
            <p class="subtitle">ç”»åƒèªè­˜ã®é©å‘½ - ç•³ã¿è¾¼ã¿ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®åŸºæœ¬åŸç†ã‚’ç†è§£ã™ã‚‹</p>
            <div class="meta">
                <span class="meta-item">ğŸ“– èª­äº†æ™‚é–“: 25-30åˆ†</span>
                <span class="meta-item">ğŸ“Š é›£æ˜“åº¦: åˆç´šã€œä¸­ç´š</span>
                <span class="meta-item">ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹: 11å€‹</span>
                <span class="meta-item">ğŸ“ æ¼”ç¿’å•é¡Œ: 5å•</span>
            </div>
        </div>
    </header>

    <main class="container">

<h2>å­¦ç¿’ç›®æ¨™</h2>
<p>ã“ã®ç« ã‚’èª­ã‚€ã“ã¨ã§ã€ä»¥ä¸‹ã‚’ç¿’å¾—ã§ãã¾ã™ï¼š</p>
<ul>
<li>âœ… ç”»åƒèªè­˜ã«ãŠã‘ã‚‹å¾“æ¥æ‰‹æ³•ã®èª²é¡Œã¨CNNã®å„ªä½æ€§ã‚’ç†è§£ã™ã‚‹</li>
<li>âœ… ç•³ã¿è¾¼ã¿æ¼”ç®—ã®æ•°å­¦çš„å®šç¾©ã¨è¨ˆç®—ãƒ—ãƒ­ã‚»ã‚¹ã‚’ç¿’å¾—ã™ã‚‹</li>
<li>âœ… ã‚¹ãƒˆãƒ©ã‚¤ãƒ‰ã€ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã€ã‚«ãƒ¼ãƒãƒ«ã‚µã‚¤ã‚ºã®å½¹å‰²ã‚’ç†è§£ã™ã‚‹</li>
<li>âœ… ç‰¹å¾´ãƒãƒƒãƒ—ã¨å—å®¹é‡ã®æ¦‚å¿µã‚’èª¬æ˜ã§ãã‚‹</li>
<li>âœ… PyTorchã§Conv2då±¤ã‚’å®Ÿè£…ã—ã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¨ˆç®—ã§ãã‚‹</li>
<li>âœ… ãƒ•ã‚£ãƒ«ã‚¿ã®å¯è¦–åŒ–ã¨ç‰¹å¾´æŠ½å‡ºã®ä»•çµ„ã¿ã‚’ç†è§£ã™ã‚‹</li>
</ul>

<hr>

<h2>1.1 ç”»åƒèªè­˜ã®èª²é¡Œã¨CNNã®ç™»å ´</h2>

<h3>å¾“æ¥ã®ç”»åƒèªè­˜æ‰‹æ³•ã®é™ç•Œ</h3>

<p><strong>å…¨çµåˆãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼ˆFully Connected Networkï¼‰</strong>ã‚’ç”»åƒèªè­˜ã«ä½¿ç”¨ã™ã‚‹å ´åˆã€æ·±åˆ»ãªå•é¡ŒãŒç™ºç”Ÿã—ã¾ã™ã€‚</p>

<blockquote>
<p>ã€Œç”»åƒã¯ç©ºé–“æ§‹é€ ã‚’æŒã¤2æ¬¡å…ƒãƒ‡ãƒ¼ã‚¿ã§ã‚ã‚‹ã€‚ã“ã®æ§‹é€ ã‚’ç„¡è¦–ã™ã‚‹ã¨ã€è†¨å¤§ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨éå­¦ç¿’ã‚’æ‹›ãã€‚ã€</p>
</blockquote>

<h4>å•é¡Œ1ï¼šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã®çˆ†ç™º</h4>

<p>ä¾‹ãˆã°ã€224Ã—224ãƒ”ã‚¯ã‚»ãƒ«ã®ã‚«ãƒ©ãƒ¼ç”»åƒï¼ˆRGBï¼‰ã‚’å…¨çµåˆå±¤ã«å…¥åŠ›ã™ã‚‹å ´åˆï¼š</p>

<ul>
<li>å…¥åŠ›æ¬¡å…ƒæ•°ï¼š$224 \times 224 \times 3 = 150,528$</li>
<li>éš ã‚Œå±¤ãŒ1,000ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã®å ´åˆï¼š$150,528 \times 1,000 = 150,528,000$ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿</li>
<li>ã“ã‚Œã¯ç¬¬1å±¤ã ã‘ã§1å„„5åƒä¸‡ä»¥ä¸Šã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼</li>
</ul>

<h4>å•é¡Œ2ï¼šä½ç½®ä¸å¤‰æ€§ã®æ¬ å¦‚</h4>

<p>å…¨çµåˆå±¤ã§ã¯ã€ç”»åƒå†…ã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ä½ç½®ãŒå°‘ã—å¤‰ã‚ã‚‹ã ã‘ã§ã€å…¨ãç•°ãªã‚‹å…¥åŠ›ã¨ã—ã¦æ‰±ã‚ã‚Œã¾ã™ã€‚</p>

<pre><code class="language-python">import numpy as np
import matplotlib.pyplot as plt

# ç°¡å˜ãªä¾‹ï¼š5Ã—5ç”»åƒã§ã€ŒçŒ«ã€ã®ç‰¹å¾´ï¼ˆè€³ï¼‰ã‚’è¡¨ç¾
original = np.zeros((5, 5))
original[0, 1] = 1  # å·¦è€³
original[0, 3] = 1  # å³è€³
original[2, 2] = 1  # é¼»

# 1ãƒ”ã‚¯ã‚»ãƒ«å³ã«ç§»å‹•
shifted = np.zeros((5, 5))
shifted[0, 2] = 1  # å·¦è€³
shifted[0, 4] = 1  # å³è€³
shifted[2, 3] = 1  # é¼»

print("å…ƒã®ç”»åƒã‚’å¹³å¦åŒ–:", original.flatten())
print("ç§»å‹•å¾Œã®ç”»åƒã‚’å¹³å¦åŒ–:", shifted.flatten())
print(f"ãƒ¦ãƒ¼ã‚¯ãƒªãƒƒãƒ‰è·é›¢: {np.linalg.norm(original.flatten() - shifted.flatten()):.2f}")

# å…¨çµåˆå±¤ã§ã¯ã€ã“ã®2ã¤ã¯å®Œå…¨ã«ç•°ãªã‚‹å…¥åŠ›ã¨ã—ã¦æ‰±ã‚ã‚Œã‚‹
print("\nçµè«–: å…¨çµåˆå±¤ã§ã¯ä½ç½®ã®å¾®å°ãªå¤‰åŒ–ã«å¯¾å¿œã§ããªã„")
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>å…ƒã®ç”»åƒã‚’å¹³å¦åŒ–: [0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
ç§»å‹•å¾Œã®ç”»åƒã‚’å¹³å¦åŒ–: [0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
ãƒ¦ãƒ¼ã‚¯ãƒªãƒƒãƒ‰è·é›¢: 2.45

çµè«–: å…¨çµåˆå±¤ã§ã¯ä½ç½®ã®å¾®å°ãªå¤‰åŒ–ã«å¯¾å¿œã§ããªã„
</code></pre>

<h3>CNNã®3ã¤ã®é‡è¦ãªæ€§è³ª</h3>

<p><strong>ç•³ã¿è¾¼ã¿ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼ˆConvolutional Neural Network, CNNï¼‰</strong>ã¯ã€ç”»åƒã®ç©ºé–“æ§‹é€ ã‚’æ´»ç”¨ã™ã‚‹ä»¥ä¸‹ã®æ€§è³ªã‚’æŒã¡ã¾ã™ï¼š</p>

<table>
<thead>
<tr>
<th>æ€§è³ª</th>
<th>èª¬æ˜</th>
<th>åŠ¹æœ</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>å±€æ‰€æ¥ç¶šæ€§</strong></td>
<td>å„ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã¯å…¥åŠ›ã®å°ã•ãªé ˜åŸŸã®ã¿ã«æ¥ç¶š</td>
<td>ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã®å‰Šæ¸›</td>
</tr>
<tr>
<td><strong>é‡ã¿å…±æœ‰</strong></td>
<td>åŒã˜ãƒ•ã‚£ãƒ«ã‚¿ã‚’ç”»åƒå…¨ä½“ã§ä½¿ç”¨</td>
<td>ä½ç½®ä¸å¤‰æ€§ã®ç²å¾—</td>
</tr>
<tr>
<td><strong>éšå±¤çš„ç‰¹å¾´å­¦ç¿’</strong></td>
<td>ä½ãƒ¬ãƒ™ãƒ«â†’é«˜ãƒ¬ãƒ™ãƒ«ç‰¹å¾´ã‚’æ®µéšçš„ã«æŠ½å‡º</td>
<td>è¤‡é›‘ãªãƒ‘ã‚¿ãƒ¼ãƒ³èªè­˜</td>
</tr>
</tbody>
</table>

<h3>CNNã®å…¨ä½“æ§‹é€ </h3>

<div class="mermaid">
graph LR
    A[å…¥åŠ›ç”»åƒ<br/>28Ã—28Ã—1] --> B[Convå±¤<br/>26Ã—26Ã—32]
    B --> C[æ´»æ€§åŒ–<br/>ReLU]
    C --> D[ãƒ—ãƒ¼ãƒªãƒ³ã‚°<br/>13Ã—13Ã—32]
    D --> E[Convå±¤<br/>11Ã—11Ã—64]
    E --> F[æ´»æ€§åŒ–<br/>ReLU]
    F --> G[ãƒ—ãƒ¼ãƒªãƒ³ã‚°<br/>5Ã—5Ã—64]
    G --> H[å¹³å¦åŒ–<br/>1600]
    H --> I[å…¨çµåˆå±¤<br/>128]
    I --> J[å‡ºåŠ›å±¤<br/>10ã‚¯ãƒ©ã‚¹]

    style A fill:#e3f2fd
    style B fill:#fff3e0
    style C fill:#e8f5e9
    style D fill:#fce4ec
    style E fill:#fff3e0
    style F fill:#e8f5e9
    style G fill:#fce4ec
    style H fill:#f3e5f5
    style I fill:#fff9c4
    style J fill:#ffebee
</div>

<hr>

<h2>1.2 ç•³ã¿è¾¼ã¿æ¼”ç®—ã®åŸºç¤</h2>

<h3>ç•³ã¿è¾¼ã¿æ¼”ç®—ã¨ã¯</h3>

<p><strong>ç•³ã¿è¾¼ã¿ï¼ˆConvolutionï¼‰</strong>ã¯ã€ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆã‚«ãƒ¼ãƒãƒ«ï¼‰ã‚’ç”»åƒä¸Šã§ã‚¹ãƒ©ã‚¤ãƒ‰ã•ã›ãªãŒã‚‰ã€è¦ç´ ã”ã¨ã®ç©å’Œæ¼”ç®—ã‚’è¡Œã†æ“ä½œã§ã™ã€‚</p>

<h4>æ•°å­¦çš„å®šç¾©</h4>

<p>2æ¬¡å…ƒã®é›¢æ•£ç•³ã¿è¾¼ã¿ã¯ä»¥ä¸‹ã®ã‚ˆã†ã«å®šç¾©ã•ã‚Œã¾ã™ï¼š</p>

$$
(I * K)(i, j) = \sum_{m}\sum_{n} I(i+m, j+n) \cdot K(m, n)
$$

<p>ã“ã“ã§ï¼š</p>
<ul>
<li>$I$: å…¥åŠ›ç”»åƒï¼ˆInputï¼‰</li>
<li>$K$: ã‚«ãƒ¼ãƒãƒ«ï¼ˆKernelï¼‰ã¾ãŸã¯ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆFilterï¼‰</li>
<li>$(i, j)$: å‡ºåŠ›ä½ç½®</li>
<li>$(m, n)$: ã‚«ãƒ¼ãƒãƒ«å†…ã®ä½ç½®</li>
</ul>

<h4>å…·ä½“ä¾‹ï¼š3Ã—3ã‚«ãƒ¼ãƒãƒ«ã«ã‚ˆã‚‹ç•³ã¿è¾¼ã¿</h4>

<pre><code class="language-python">import numpy as np

# å…¥åŠ›ç”»åƒï¼ˆ5Ã—5ï¼‰
image = np.array([
    [1, 2, 3, 0, 1],
    [4, 5, 6, 1, 2],
    [7, 8, 9, 2, 3],
    [1, 2, 3, 4, 5],
    [2, 3, 4, 5, 6]
])

# ã‚¨ãƒƒã‚¸æ¤œå‡ºã‚«ãƒ¼ãƒãƒ«ï¼ˆ3Ã—3ï¼‰
kernel = np.array([
    [-1, -1, -1],
    [-1,  8, -1],
    [-1, -1, -1]
])

def manual_convolution(image, kernel):
    """
    æ‰‹å‹•ã§ç•³ã¿è¾¼ã¿æ¼”ç®—ã‚’å®Ÿè¡Œ
    """
    img_h, img_w = image.shape
    ker_h, ker_w = kernel.shape

    # å‡ºåŠ›ã‚µã‚¤ã‚ºã®è¨ˆç®—
    out_h = img_h - ker_h + 1
    out_w = img_w - ker_w + 1

    output = np.zeros((out_h, out_w))

    # ç•³ã¿è¾¼ã¿æ¼”ç®—
    for i in range(out_h):
        for j in range(out_w):
            # ç”»åƒã®éƒ¨åˆ†é ˜åŸŸã‚’åˆ‡ã‚Šå‡ºã—
            region = image[i:i+ker_h, j:j+ker_w]
            # è¦ç´ ã”ã¨ã®ç©ã®åˆè¨ˆ
            output[i, j] = np.sum(region * kernel)

    return output

# ç•³ã¿è¾¼ã¿å®Ÿè¡Œ
result = manual_convolution(image, kernel)

print("å…¥åŠ›ç”»åƒ (5Ã—5):")
print(image)
print("\nã‚«ãƒ¼ãƒãƒ« (3Ã—3, ã‚¨ãƒƒã‚¸æ¤œå‡º):")
print(kernel)
print("\nå‡ºåŠ› (3Ã—3):")
print(result)

# è©³ç´°ãªè¨ˆç®—ä¾‹ï¼ˆå·¦ä¸Šã®ä½ç½®ï¼‰
print("\n=== è¨ˆç®—ä¾‹ï¼ˆä½ç½® [0, 0]ï¼‰===")
region = image[0:3, 0:3]
print("ç”»åƒã®éƒ¨åˆ†é ˜åŸŸ:")
print(region)
print("\nã‚«ãƒ¼ãƒãƒ«:")
print(kernel)
print("\nè¦ç´ ã”ã¨ã®ç©:")
print(region * kernel)
print(f"\nåˆè¨ˆ: {np.sum(region * kernel)}")
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>å…¥åŠ›ç”»åƒ (5Ã—5):
[[1 2 3 0 1]
 [4 5 6 1 2]
 [7 8 9 2 3]
 [1 2 3 4 5]
 [2 3 4 5 6]]

ã‚«ãƒ¼ãƒãƒ« (3Ã—3, ã‚¨ãƒƒã‚¸æ¤œå‡º):
[[-1 -1 -1]
 [-1  8 -1]
 [-1 -1 -1]]

å‡ºåŠ› (3Ã—3):
[[-13. -15. -12.]
 [ -8.  -9.  -6.]
 [ -5.  -6.   0.]]

=== è¨ˆç®—ä¾‹ï¼ˆä½ç½® [0, 0]ï¼‰===
ç”»åƒã®éƒ¨åˆ†é ˜åŸŸ:
[[1 2 3]
 [4 5 6]
 [7 8 9]]

ã‚«ãƒ¼ãƒãƒ«:
[[-1 -1 -1]
 [-1  8 -1]
 [-1 -1 -1]]

è¦ç´ ã”ã¨ã®ç©:
[[-1 -2 -3]
 [-4 40 -6]
 [-7 -8 -9]]

åˆè¨ˆ: -13
</code></pre>

<h3>ãƒ•ã‚£ãƒ«ã‚¿ã¨ã‚«ãƒ¼ãƒãƒ«</h3>

<p><strong>ã‚«ãƒ¼ãƒãƒ«ï¼ˆKernelï¼‰</strong>ã¨<strong>ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆFilterï¼‰</strong>ã¯ã€å¤šãã®å ´åˆåŒã˜æ„å‘³ã§ä½¿ã‚ã‚Œã¾ã™ãŒã€å³å¯†ã«ã¯ï¼š</p>

<ul>
<li><strong>ã‚«ãƒ¼ãƒãƒ«</strong>: 2æ¬¡å…ƒã®é‡ã¿é…åˆ—ï¼ˆä¾‹ï¼š3Ã—3è¡Œåˆ—ï¼‰</li>
<li><strong>ãƒ•ã‚£ãƒ«ã‚¿</strong>: å…¨ãƒãƒ£ãƒãƒ«ã«ã‚ãŸã‚‹ã‚«ãƒ¼ãƒãƒ«ã®é›†åˆï¼ˆä¾‹ï¼š3Ã—3Ã—3ã®RGBç”»åƒç”¨ãƒ•ã‚£ãƒ«ã‚¿ï¼‰</li>
</ul>

<h4>ä»£è¡¨çš„ãªã‚«ãƒ¼ãƒãƒ«ã®ä¾‹</h4>

<pre><code class="language-python">import matplotlib.pyplot as plt
from scipy import signal

# å„ç¨®ã‚«ãƒ¼ãƒãƒ«ã®å®šç¾©
kernels = {
    "æ’ç­‰å¤‰æ›": np.array([[0, 0, 0],
                       [0, 1, 0],
                       [0, 0, 0]]),

    "ã‚¨ãƒƒã‚¸æ¤œå‡ºï¼ˆç¸¦ï¼‰": np.array([[-1, 0, 1],
                              [-2, 0, 2],
                              [-1, 0, 1]]),  # Sobelãƒ•ã‚£ãƒ«ã‚¿

    "ã‚¨ãƒƒã‚¸æ¤œå‡ºï¼ˆæ¨ªï¼‰": np.array([[-1, -2, -1],
                              [ 0,  0,  0],
                              [ 1,  2,  1]]),

    "å¹³æ»‘åŒ–ï¼ˆblurï¼‰": np.array([[1, 1, 1],
                            [1, 1, 1],
                            [1, 1, 1]]) / 9,

    "ã‚·ãƒ£ãƒ¼ãƒ—åŒ–": np.array([[ 0, -1,  0],
                         [-1,  5, -1],
                         [ 0, -1,  0]])
}

# ãƒ†ã‚¹ãƒˆç”»åƒï¼ˆç°¡å˜ãªãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰
test_image = np.array([
    [0, 0, 0, 0, 0, 0, 0],
    [0, 255, 255, 255, 255, 0, 0],
    [0, 255, 0, 0, 255, 0, 0],
    [0, 255, 0, 0, 255, 0, 0],
    [0, 255, 255, 255, 255, 0, 0],
    [0, 0, 0, 0, 0, 0, 0]
], dtype=float)

# å„ã‚«ãƒ¼ãƒãƒ«ã®åŠ¹æœã‚’å¯è¦–åŒ–
fig, axes = plt.subplots(2, 3, figsize=(12, 8))
axes = axes.flatten()

axes[0].imshow(test_image, cmap='gray')
axes[0].set_title('å…ƒç”»åƒ')
axes[0].axis('off')

for idx, (name, kernel) in enumerate(kernels.items(), 1):
    result = signal.correlate2d(test_image, kernel, mode='same', boundary='symm')
    axes[idx].imshow(result, cmap='gray')
    axes[idx].set_title(name)
    axes[idx].axis('off')

plt.tight_layout()
print("ã‚«ãƒ¼ãƒãƒ«ã®åŠ¹æœã‚’å¯è¦–åŒ–ã—ã¾ã—ãŸ")
</code></pre>

<h3>ã‚¹ãƒˆãƒ©ã‚¤ãƒ‰ã¨ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°</h3>

<h4>ã‚¹ãƒˆãƒ©ã‚¤ãƒ‰ï¼ˆStrideï¼‰</h4>

<p><strong>ã‚¹ãƒˆãƒ©ã‚¤ãƒ‰</strong>ã¯ã€ã‚«ãƒ¼ãƒãƒ«ã‚’ç§»å‹•ã•ã›ã‚‹éš›ã®ã‚¹ãƒ†ãƒƒãƒ—å¹…ã§ã™ã€‚</p>

<ul>
<li>ã‚¹ãƒˆãƒ©ã‚¤ãƒ‰ = 1: ã‚«ãƒ¼ãƒãƒ«ã‚’1ãƒ”ã‚¯ã‚»ãƒ«ãšã¤ç§»å‹•ï¼ˆæ¨™æº–ï¼‰</li>
<li>ã‚¹ãƒˆãƒ©ã‚¤ãƒ‰ = 2: ã‚«ãƒ¼ãƒãƒ«ã‚’2ãƒ”ã‚¯ã‚»ãƒ«ãšã¤ç§»å‹•ï¼ˆå‡ºåŠ›ã‚µã‚¤ã‚ºãŒåŠåˆ†ã«ï¼‰</li>
</ul>

<p>å‡ºåŠ›ã‚µã‚¤ã‚ºã®è¨ˆç®—å¼ï¼š</p>

$$
\text{å‡ºåŠ›ã‚µã‚¤ã‚º} = \left\lfloor \frac{\text{å…¥åŠ›ã‚µã‚¤ã‚º} - \text{ã‚«ãƒ¼ãƒãƒ«ã‚µã‚¤ã‚º}}{\text{ã‚¹ãƒˆãƒ©ã‚¤ãƒ‰}} \right\rfloor + 1
$$

<h4>ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ï¼ˆPaddingï¼‰</h4>

<p><strong>ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°</strong>ã¯ã€å…¥åŠ›ç”»åƒã®å‘¨å›²ã«å€¤ï¼ˆé€šå¸¸ã¯0ï¼‰ã‚’è¿½åŠ ã™ã‚‹æ“ä½œã§ã™ã€‚</p>

<table>
<thead>
<tr>
<th>ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã®ç¨®é¡</th>
<th>èª¬æ˜</th>
<th>ç”¨é€”</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Valid</strong></td>
<td>ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ãªã—</td>
<td>å‡ºåŠ›ã‚µã‚¤ã‚ºã‚’ç¸®å°ã—ãŸã„å ´åˆ</td>
</tr>
<tr>
<td><strong>Same</strong></td>
<td>å‡ºåŠ›ã‚µã‚¤ã‚º = å…¥åŠ›ã‚µã‚¤ã‚ºã«ãªã‚‹ã‚ˆã†ã«èª¿æ•´</td>
<td>ç©ºé–“ã‚µã‚¤ã‚ºã‚’ç¶­æŒã—ãŸã„å ´åˆ</td>
</tr>
<tr>
<td><strong>Full</strong></td>
<td>ã‚«ãƒ¼ãƒãƒ«å…¨ä½“ãŒç”»åƒã¨é‡ãªã‚‹ã‚ˆã†ã«</td>
<td>å¢ƒç•Œæƒ…å ±ã‚’æœ€å¤§é™åˆ©ç”¨ã—ãŸã„å ´åˆ</td>
</tr>
</tbody>
</table>

<p>Sameãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã®ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°é‡ã®è¨ˆç®—ï¼š</p>

$$
\text{ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°} = \frac{\text{ã‚«ãƒ¼ãƒãƒ«ã‚µã‚¤ã‚º} - 1}{2}
$$

<pre><code class="language-python">def calculate_output_size(input_size, kernel_size, stride, padding):
    """
    ç•³ã¿è¾¼ã¿æ¼”ç®—å¾Œã®å‡ºåŠ›ã‚µã‚¤ã‚ºã‚’è¨ˆç®—

    Parameters:
    -----------
    input_size : int
        å…¥åŠ›ã®é«˜ã•ã¾ãŸã¯å¹…
    kernel_size : int
        ã‚«ãƒ¼ãƒãƒ«ã®é«˜ã•ã¾ãŸã¯å¹…
    stride : int
        ã‚¹ãƒˆãƒ©ã‚¤ãƒ‰
    padding : int
        ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°é‡

    Returns:
    --------
    int : å‡ºåŠ›ã‚µã‚¤ã‚º
    """
    return (input_size + 2 * padding - kernel_size) // stride + 1

# æ§˜ã€…ãªè¨­å®šã§ã®å‡ºåŠ›ã‚µã‚¤ã‚ºã‚’è¨ˆç®—
print("=== å‡ºåŠ›ã‚µã‚¤ã‚ºã®è¨ˆç®—ä¾‹ ===\n")

configurations = [
    (28, 3, 1, 0, "Validï¼ˆãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ãªã—ï¼‰"),
    (28, 3, 1, 1, "Sameï¼ˆã‚µã‚¤ã‚ºç¶­æŒï¼‰"),
    (28, 5, 2, 2, "ã‚¹ãƒˆãƒ©ã‚¤ãƒ‰2ã€ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°2"),
    (32, 3, 1, 1, "32Ã—32ç”»åƒã€3Ã—3ã‚«ãƒ¼ãƒãƒ«"),
]

for input_size, kernel_size, stride, padding, description in configurations:
    output_size = calculate_output_size(input_size, kernel_size, stride, padding)
    print(f"{description}")
    print(f"  å…¥åŠ›: {input_size}Ã—{input_size}")
    print(f"  ã‚«ãƒ¼ãƒãƒ«: {kernel_size}Ã—{kernel_size}, ã‚¹ãƒˆãƒ©ã‚¤ãƒ‰: {stride}, ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°: {padding}")
    print(f"  â†’ å‡ºåŠ›: {output_size}Ã—{output_size}\n")
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>=== å‡ºåŠ›ã‚µã‚¤ã‚ºã®è¨ˆç®—ä¾‹ ===

Validï¼ˆãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ãªã—ï¼‰
  å…¥åŠ›: 28Ã—28
  ã‚«ãƒ¼ãƒãƒ«: 3Ã—3, ã‚¹ãƒˆãƒ©ã‚¤ãƒ‰: 1, ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°: 0
  â†’ å‡ºåŠ›: 26Ã—26

Sameï¼ˆã‚µã‚¤ã‚ºç¶­æŒï¼‰
  å…¥åŠ›: 28Ã—28
  ã‚«ãƒ¼ãƒãƒ«: 3Ã—3, ã‚¹ãƒˆãƒ©ã‚¤ãƒ‰: 1, ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°: 1
  â†’ å‡ºåŠ›: 28Ã—28

ã‚¹ãƒˆãƒ©ã‚¤ãƒ‰2ã€ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°2
  å…¥åŠ›: 28Ã—28
  ã‚«ãƒ¼ãƒãƒ«: 5Ã—5, ã‚¹ãƒˆãƒ©ã‚¤ãƒ‰: 2, ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°: 2
  â†’ å‡ºåŠ›: 14Ã—14

32Ã—32ç”»åƒã€3Ã—3ã‚«ãƒ¼ãƒãƒ«
  å…¥åŠ›: 32Ã—32
  ã‚«ãƒ¼ãƒãƒ«: 3Ã—3, ã‚¹ãƒˆãƒ©ã‚¤ãƒ‰: 1, ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°: 1
  â†’ å‡ºåŠ›: 32Ã—32
</code></pre>

<hr>

<h2>1.3 ç‰¹å¾´ãƒãƒƒãƒ—ã¨å—å®¹é‡</h2>

<h3>ç‰¹å¾´ãƒãƒƒãƒ—ï¼ˆFeature Mapï¼‰</h3>

<p><strong>ç‰¹å¾´ãƒãƒƒãƒ—</strong>ã¯ã€ç•³ã¿è¾¼ã¿æ¼”ç®—ã®å‡ºåŠ›çµæœã§ã™ã€‚å„ãƒ•ã‚£ãƒ«ã‚¿ã¯ç•°ãªã‚‹ç‰¹å¾´ï¼ˆã‚¨ãƒƒã‚¸ã€ãƒ†ã‚¯ã‚¹ãƒãƒ£ãªã©ï¼‰ã‚’æ¤œå‡ºã—ã€ãã‚Œãã‚Œã®ç‰¹å¾´ãƒãƒƒãƒ—ã‚’ç”Ÿæˆã—ã¾ã™ã€‚</p>

<ul>
<li>å…¥åŠ›ãƒãƒ£ãƒãƒ«æ•° = $C_{in}$</li>
<li>å‡ºåŠ›ãƒãƒ£ãƒãƒ«æ•° = $C_{out}$ï¼ˆãƒ•ã‚£ãƒ«ã‚¿æ•°ï¼‰</li>
<li>å„ãƒ•ã‚£ãƒ«ã‚¿ã®ã‚µã‚¤ã‚º = $K \times K \times C_{in}$</li>
</ul>

<h4>å¤šãƒãƒ£ãƒãƒ«ç•³ã¿è¾¼ã¿ã®è¨ˆç®—</h4>

<p>ã‚«ãƒ©ãƒ¼ç”»åƒï¼ˆRGBã€3ãƒãƒ£ãƒãƒ«ï¼‰ã®å ´åˆï¼š</p>

$$
\text{å‡ºåŠ›}(i, j) = \sum_{c=1}^{3} \sum_{m}\sum_{n} I_c(i+m, j+n) \cdot K_c(m, n) + b
$$

<p>ã“ã“ã§ $b$ ã¯ãƒã‚¤ã‚¢ã‚¹é …ã§ã™ã€‚</p>

<pre><code class="language-python">import torch
import torch.nn as nn

# RGBç”»åƒï¼ˆãƒãƒƒãƒã‚µã‚¤ã‚º1ã€3ãƒãƒ£ãƒãƒ«ã€28Ã—28ï¼‰
input_image = torch.randn(1, 3, 28, 28)

# ç•³ã¿è¾¼ã¿å±¤ã®å®šç¾©
# å…¥åŠ›: 3ãƒãƒ£ãƒãƒ«ï¼ˆRGBï¼‰
# å‡ºåŠ›: 16ãƒãƒ£ãƒãƒ«ï¼ˆ16å€‹ã®ç‰¹å¾´ãƒãƒƒãƒ—ï¼‰
# ã‚«ãƒ¼ãƒãƒ«ã‚µã‚¤ã‚º: 3Ã—3
conv_layer = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)

# é †ä¼æ’­
output = conv_layer(input_image)

print(f"å…¥åŠ›ã‚µã‚¤ã‚º: {input_image.shape}")
print(f"  â†’ [ãƒãƒƒãƒ, ãƒãƒ£ãƒãƒ«, é«˜ã•, å¹…] = [1, 3, 28, 28]")
print(f"\nç•³ã¿è¾¼ã¿å±¤ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:")
print(f"  å…¥åŠ›ãƒãƒ£ãƒãƒ«: 3")
print(f"  å‡ºåŠ›ãƒãƒ£ãƒãƒ«: 16")
print(f"  ã‚«ãƒ¼ãƒãƒ«ã‚µã‚¤ã‚º: 3Ã—3")
print(f"  ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°: 1 (Sameãƒ‘ãƒ‡ã‚£ãƒ³ã‚°)")
print(f"\nå‡ºåŠ›ã‚µã‚¤ã‚º: {output.shape}")
print(f"  â†’ [ãƒãƒƒãƒ, ãƒãƒ£ãƒãƒ«, é«˜ã•, å¹…] = [1, 16, 28, 28]")

# ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã®è¨ˆç®—
weight_params = 3 * 16 * 3 * 3  # in_ch Ã— out_ch Ã— k_h Ã— k_w
bias_params = 16  # å„å‡ºåŠ›ãƒãƒ£ãƒãƒ«ã«1ã¤
total_params = weight_params + bias_params

print(f"\nãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°:")
print(f"  é‡ã¿: {weight_params:,} (= 3 Ã— 16 Ã— 3 Ã— 3)")
print(f"  ãƒã‚¤ã‚¢ã‚¹: {bias_params}")
print(f"  åˆè¨ˆ: {total_params:,}")
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>å…¥åŠ›ã‚µã‚¤ã‚º: torch.Size([1, 3, 28, 28])
  â†’ [ãƒãƒƒãƒ, ãƒãƒ£ãƒãƒ«, é«˜ã•, å¹…] = [1, 3, 28, 28]

ç•³ã¿è¾¼ã¿å±¤ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:
  å…¥åŠ›ãƒãƒ£ãƒãƒ«: 3
  å‡ºåŠ›ãƒãƒ£ãƒãƒ«: 16
  ã‚«ãƒ¼ãƒãƒ«ã‚µã‚¤ã‚º: 3Ã—3
  ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°: 1 (Sameãƒ‘ãƒ‡ã‚£ãƒ³ã‚°)

å‡ºåŠ›ã‚µã‚¤ã‚º: torch.Size([1, 16, 28, 28])
  â†’ [ãƒãƒƒãƒ, ãƒãƒ£ãƒãƒ«, é«˜ã•, å¹…] = [1, 16, 28, 28]

ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°:
  é‡ã¿: 432 (= 3 Ã— 16 Ã— 3 Ã— 3)
  ãƒã‚¤ã‚¢ã‚¹: 16
  åˆè¨ˆ: 448
</code></pre>

<h3>å—å®¹é‡ï¼ˆReceptive Fieldï¼‰</h3>

<p><strong>å—å®¹é‡</strong>ã¯ã€ã‚ã‚‹å‡ºåŠ›ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ãŒã€Œè¦‹ã¦ã„ã‚‹ã€å…¥åŠ›ç”»åƒã®é ˜åŸŸã§ã™ã€‚CNNã§ã¯å±¤ã‚’é‡ã­ã‚‹ã”ã¨ã«å—å®¹é‡ãŒæ‹¡å¤§ã—ã¾ã™ã€‚</p>

<h4>å—å®¹é‡ã®ã‚µã‚¤ã‚ºè¨ˆç®—</h4>

<p>å—å®¹é‡ã‚µã‚¤ã‚º $R$ ã®è¨ˆç®—å¼ï¼ˆã‚¹ãƒˆãƒ©ã‚¤ãƒ‰1ã€ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã‚ã‚Šã®å ´åˆï¼‰ï¼š</p>

$$
R_l = R_{l-1} + (K_l - 1)
$$

<p>ã“ã“ã§ï¼š</p>
<ul>
<li>$R_l$: ç¬¬ $l$ å±¤ã®å—å®¹é‡ã‚µã‚¤ã‚º</li>
<li>$K_l$: ç¬¬ $l$ å±¤ã®ã‚«ãƒ¼ãƒãƒ«ã‚µã‚¤ã‚º</li>
<li>$R_0 = 1$ï¼ˆå…¥åŠ›å±¤ï¼‰</li>
</ul>

<pre><code class="language-python">def calculate_receptive_field(layers_info):
    """
    CNNã®å—å®¹é‡ã‚µã‚¤ã‚ºã‚’è¨ˆç®—

    Parameters:
    -----------
    layers_info : list of tuples
        å„å±¤ã® (ã‚«ãƒ¼ãƒãƒ«ã‚µã‚¤ã‚º, ã‚¹ãƒˆãƒ©ã‚¤ãƒ‰) ã®ãƒªã‚¹ãƒˆ

    Returns:
    --------
    list : å„å±¤ã®å—å®¹é‡ã‚µã‚¤ã‚º
    """
    receptive_fields = [1]  # å…¥åŠ›å±¤

    for kernel_size, stride in layers_info:
        # ç°¡ç•¥åŒ–ã—ãŸè¨ˆç®—ï¼ˆã‚¹ãƒˆãƒ©ã‚¤ãƒ‰1ã®å ´åˆï¼‰
        rf = receptive_fields[-1] + (kernel_size - 1)
        receptive_fields.append(rf)

    return receptive_fields

# VGGé¢¨ã®ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ§‹æˆ
vgg_layers = [
    (3, 1),  # Conv1
    (3, 1),  # Conv2
    (2, 2),  # MaxPool
    (3, 1),  # Conv3
    (3, 1),  # Conv4
    (2, 2),  # MaxPool
]

receptive_fields = calculate_receptive_field(vgg_layers)

print("=== å—å®¹é‡ã®æ‹¡å¤§éç¨‹ ===\n")
print("å±¤                å—å®¹é‡ã‚µã‚¤ã‚º")
print("-" * 35)
print(f"å…¥åŠ›å±¤            {receptive_fields[0]}Ã—{receptive_fields[0]}")

layer_names = ["Conv1 (3Ã—3)", "Conv2 (3Ã—3)", "MaxPool (2Ã—2)",
               "Conv3 (3Ã—3)", "Conv4 (3Ã—3)", "MaxPool (2Ã—2)"]

for i, name in enumerate(layer_names, 1):
    print(f"{name:18}{receptive_fields[i]:2}Ã—{receptive_fields[i]:2}")

print(f"\næœ€çµ‚çš„ãªå—å®¹é‡: {receptive_fields[-1]}Ã—{receptive_fields[-1]} ãƒ”ã‚¯ã‚»ãƒ«")
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>=== å—å®¹é‡ã®æ‹¡å¤§éç¨‹ ===

å±¤                å—å®¹é‡ã‚µã‚¤ã‚º
-----------------------------------
å…¥åŠ›å±¤             1Ã—1
Conv1 (3Ã—3)        3Ã—3
Conv2 (3Ã—3)        5Ã—5
MaxPool (2Ã—2)      6Ã—6
Conv3 (3Ã—3)        8Ã—8
Conv4 (3Ã—3)       10Ã—10
MaxPool (2Ã—2)     11Ã—11

æœ€çµ‚çš„ãªå—å®¹é‡: 11Ã—11 ãƒ”ã‚¯ã‚»ãƒ«
</code></pre>

<h4>å—å®¹é‡ã®å¯è¦–åŒ–</h4>

<div class="mermaid">
graph TD
    subgraph "å…¥åŠ›ç”»åƒ"
    A1[" "]
    A2[" "]
    A3[" "]
    A4[" "]
    A5[" "]
    end

    subgraph "Conv1: 3Ã—3ã‚«ãƒ¼ãƒãƒ«"
    B1[å—å®¹é‡: 3Ã—3]
    end

    subgraph "Conv2: 3Ã—3ã‚«ãƒ¼ãƒãƒ«"
    C1[å—å®¹é‡: 5Ã—5]
    end

    subgraph "Conv3: 3Ã—3ã‚«ãƒ¼ãƒãƒ«"
    D1[å—å®¹é‡: 7Ã—7]
    end

    A1 --> B1
    A2 --> B1
    A3 --> B1
    B1 --> C1
    C1 --> D1

    style B1 fill:#fff3e0
    style C1 fill:#ffe0b2
    style D1 fill:#ffcc80
</div>

<blockquote>
<p><strong>é‡è¦</strong>: æ·±ã„ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã»ã©å¤§ããªå—å®¹é‡ã‚’æŒã¡ã€åºƒç¯„å›²ã®æƒ…å ±ã‚’çµ±åˆã§ãã¾ã™ã€‚ã“ã‚ŒãŒæ·±å±¤å­¦ç¿’ã®å¼·åŠ›ãªç‰¹å¾´æŠ½å‡ºèƒ½åŠ›ã®æºæ³‰ã§ã™ã€‚</p>
</blockquote>

<hr>

<h2>1.4 PyTorchã§ã®ç•³ã¿è¾¼ã¿å±¤ã®å®Ÿè£…</h2>

<h3>Conv2dã®åŸºæœ¬çš„ãªä½¿ã„æ–¹</h3>

<p>PyTorchã§ã¯<code>torch.nn.Conv2d</code>ã‚¯ãƒ©ã‚¹ã‚’ä½¿ç”¨ã—ã¦ç•³ã¿è¾¼ã¿å±¤ã‚’å®šç¾©ã—ã¾ã™ã€‚</p>

<pre><code class="language-python">import torch
import torch.nn as nn

# Conv2dã®åŸºæœ¬æ§‹æ–‡
conv = nn.Conv2d(
    in_channels=3,      # å…¥åŠ›ãƒãƒ£ãƒãƒ«æ•°ï¼ˆRGBãªã‚‰3ï¼‰
    out_channels=64,    # å‡ºåŠ›ãƒãƒ£ãƒãƒ«æ•°ï¼ˆãƒ•ã‚£ãƒ«ã‚¿æ•°ï¼‰
    kernel_size=3,      # ã‚«ãƒ¼ãƒãƒ«ã‚µã‚¤ã‚ºï¼ˆ3Ã—3ï¼‰
    stride=1,           # ã‚¹ãƒˆãƒ©ã‚¤ãƒ‰
    padding=1,          # ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°
    bias=True           # ãƒã‚¤ã‚¢ã‚¹é …ã‚’ä½¿ç”¨ã™ã‚‹ã‹
)

# ãƒ€ãƒŸãƒ¼å…¥åŠ›ï¼ˆãƒãƒƒãƒã‚µã‚¤ã‚º8ã€RGBç”»åƒã€224Ã—224ï¼‰
x = torch.randn(8, 3, 224, 224)

# é †ä¼æ’­
output = conv(x)

print("=== Conv2dã®å‹•ä½œç¢ºèª ===\n")
print(f"å…¥åŠ›ã‚µã‚¤ã‚º: {x.shape}")
print(f"  [ãƒãƒƒãƒ, ãƒãƒ£ãƒãƒ«, é«˜ã•, å¹…] = [{x.shape[0]}, {x.shape[1]}, {x.shape[2]}, {x.shape[3]}]")
print(f"\nå‡ºåŠ›ã‚µã‚¤ã‚º: {output.shape}")
print(f"  [ãƒãƒƒãƒ, ãƒãƒ£ãƒãƒ«, é«˜ã•, å¹…] = [{output.shape[0]}, {output.shape[1]}, {output.shape[2]}, {output.shape[3]}]")

# ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®è©³ç´°
print(f"\nãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è©³ç´°:")
print(f"  é‡ã¿ã®ã‚µã‚¤ã‚º: {conv.weight.shape}")
print(f"  â†’ [å‡ºåŠ›ch, å…¥åŠ›ch, é«˜ã•, å¹…] = [{conv.weight.shape[0]}, {conv.weight.shape[1]}, {conv.weight.shape[2]}, {conv.weight.shape[3]}]")
print(f"  ãƒã‚¤ã‚¢ã‚¹ã®ã‚µã‚¤ã‚º: {conv.bias.shape}")
print(f"  â†’ [å‡ºåŠ›ch] = [{conv.bias.shape[0]}]")

# ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°
total_params = conv.weight.numel() + conv.bias.numel()
print(f"\nç·ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {total_params:,}")
print(f"  è¨ˆç®—å¼: (3 Ã— 64 Ã— 3 Ã— 3) + 64 = {total_params:,}")
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>=== Conv2dã®å‹•ä½œç¢ºèª ===

å…¥åŠ›ã‚µã‚¤ã‚º: torch.Size([8, 3, 224, 224])
  [ãƒãƒƒãƒ, ãƒãƒ£ãƒãƒ«, é«˜ã•, å¹…] = [8, 3, 224, 224]

å‡ºåŠ›ã‚µã‚¤ã‚º: torch.Size([8, 64, 224, 224])
  [ãƒãƒƒãƒ, ãƒãƒ£ãƒãƒ«, é«˜ã•, å¹…] = [8, 64, 224, 224]

ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è©³ç´°:
  é‡ã¿ã®ã‚µã‚¤ã‚º: torch.Size([64, 3, 3, 3])
  â†’ [å‡ºåŠ›ch, å…¥åŠ›ch, é«˜ã•, å¹…] = [64, 3, 3, 3]
  ãƒã‚¤ã‚¢ã‚¹ã®ã‚µã‚¤ã‚º: torch.Size([64])
  â†’ [å‡ºåŠ›ch] = [64]

ç·ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: 1,792
  è¨ˆç®—å¼: (3 Ã— 64 Ã— 3 Ã— 3) + 64 = 1,792
</code></pre>

<h3>ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã®è¨ˆç®—å¼</h3>

<p>ç•³ã¿è¾¼ã¿å±¤ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã¯ä»¥ä¸‹ã®å¼ã§è¨ˆç®—ã•ã‚Œã¾ã™ï¼š</p>

$$
\text{ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°} = (C_{in} \times K_h \times K_w \times C_{out}) + C_{out}
$$

<p>ã“ã“ã§ï¼š</p>
<ul>
<li>$C_{in}$: å…¥åŠ›ãƒãƒ£ãƒãƒ«æ•°</li>
<li>$C_{out}$: å‡ºåŠ›ãƒãƒ£ãƒãƒ«æ•°ï¼ˆãƒ•ã‚£ãƒ«ã‚¿æ•°ï¼‰</li>
<li>$K_h, K_w$: ã‚«ãƒ¼ãƒãƒ«ã®é«˜ã•ã¨å¹…</li>
<li>æœ€å¾Œã® $C_{out}$ ã¯ãƒã‚¤ã‚¢ã‚¹é …</li>
</ul>

<pre><code class="language-python">def calculate_conv_params(in_channels, out_channels, kernel_size, bias=True):
    """
    ç•³ã¿è¾¼ã¿å±¤ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã‚’è¨ˆç®—
    """
    if isinstance(kernel_size, int):
        kernel_h = kernel_w = kernel_size
    else:
        kernel_h, kernel_w = kernel_size

    weight_params = in_channels * out_channels * kernel_h * kernel_w
    bias_params = out_channels if bias else 0

    return weight_params + bias_params

# æ§˜ã€…ãªè¨­å®šã§ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã‚’è¨ˆç®—
print("=== ç•³ã¿è¾¼ã¿å±¤ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°æ¯”è¼ƒ ===\n")

configs = [
    (3, 32, 3, "ç¬¬1å±¤ï¼ˆRGB â†’ 32ãƒãƒ£ãƒãƒ«ï¼‰"),
    (32, 64, 3, "ç¬¬2å±¤ï¼ˆ32 â†’ 64ãƒãƒ£ãƒãƒ«ï¼‰"),
    (64, 128, 3, "ç¬¬3å±¤ï¼ˆ64 â†’ 128ãƒãƒ£ãƒãƒ«ï¼‰"),
    (128, 256, 3, "ç¬¬4å±¤ï¼ˆ128 â†’ 256ãƒãƒ£ãƒãƒ«ï¼‰"),
    (3, 64, 7, "å¤§ããªã‚«ãƒ¼ãƒãƒ«ï¼ˆ7Ã—7ï¼‰"),
    (512, 512, 3, "æ·±ã„å±¤ï¼ˆ512 â†’ 512ãƒãƒ£ãƒãƒ«ï¼‰"),
]

for in_ch, out_ch, k_size, description in configs:
    params = calculate_conv_params(in_ch, out_ch, k_size)
    print(f"{description}")
    print(f"  è¨­å®š: {in_ch}ch â†’ {out_ch}ch, ã‚«ãƒ¼ãƒãƒ«{k_size}Ã—{k_size}")
    print(f"  ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {params:,}\n")

# å…¨çµåˆå±¤ã¨ã®æ¯”è¼ƒ
print("=== å…¨çµåˆå±¤ã¨ã®æ¯”è¼ƒ ===\n")
fc_input = 224 * 224 * 3
fc_output = 1000
fc_params = fc_input * fc_output + fc_output

print(f"å…¨çµåˆå±¤ï¼ˆ224Ã—224Ã—3 â†’ 1000ï¼‰:")
print(f"  ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {fc_params:,}")

conv_params = calculate_conv_params(3, 64, 3)
print(f"\nç•³ã¿è¾¼ã¿å±¤ï¼ˆ3ch â†’ 64ch, 3Ã—3ï¼‰:")
print(f"  ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {conv_params:,}")
print(f"\nå‰Šæ¸›ç‡: {(1 - conv_params/fc_params)*100:.2f}%")
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>=== ç•³ã¿è¾¼ã¿å±¤ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°æ¯”è¼ƒ ===

ç¬¬1å±¤ï¼ˆRGB â†’ 32ãƒãƒ£ãƒãƒ«ï¼‰
  è¨­å®š: 3ch â†’ 32ch, ã‚«ãƒ¼ãƒãƒ«3Ã—3
  ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: 896

ç¬¬2å±¤ï¼ˆ32 â†’ 64ãƒãƒ£ãƒãƒ«ï¼‰
  è¨­å®š: 32ch â†’ 64ch, ã‚«ãƒ¼ãƒãƒ«3Ã—3
  ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: 18,496

ç¬¬3å±¤ï¼ˆ64 â†’ 128ãƒãƒ£ãƒãƒ«ï¼‰
  è¨­å®š: 64ch â†’ 128ch, ã‚«ãƒ¼ãƒãƒ«3Ã—3
  ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: 73,856

ç¬¬4å±¤ï¼ˆ128 â†’ 256ãƒãƒ£ãƒãƒ«ï¼‰
  è¨­å®š: 128ch â†’ 256ch, ã‚«ãƒ¼ãƒãƒ«3Ã—3
  ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: 295,168

å¤§ããªã‚«ãƒ¼ãƒãƒ«ï¼ˆ7Ã—7ï¼‰
  è¨­å®š: 3ch â†’ 64ch, ã‚«ãƒ¼ãƒãƒ«7Ã—7
  ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: 9,472

æ·±ã„å±¤ï¼ˆ512 â†’ 512ãƒãƒ£ãƒãƒ«ï¼‰
  è¨­å®š: 512ch â†’ 512ch, ã‚«ãƒ¼ãƒãƒ«3Ã—3
  ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: 2,359,808

=== å…¨çµåˆå±¤ã¨ã®æ¯”è¼ƒ ===

å…¨çµåˆå±¤ï¼ˆ224Ã—224Ã—3 â†’ 1000ï¼‰:
  ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: 150,529,000

ç•³ã¿è¾¼ã¿å±¤ï¼ˆ3ch â†’ 64ch, 3Ã—3ï¼‰:
  ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: 1,792

å‰Šæ¸›ç‡: 100.00%
</code></pre>

<h3>ç•³ã¿è¾¼ã¿ãƒ•ã‚£ãƒ«ã‚¿ã®å¯è¦–åŒ–</h3>

<pre><code class="language-python">import matplotlib.pyplot as plt
import torch.nn as nn

# ç•³ã¿è¾¼ã¿å±¤ã‚’å®šç¾©
conv_layer = nn.Conv2d(1, 8, kernel_size=3, padding=1)

# å­¦ç¿’æ¸ˆã¿ã®ãƒ•ã‚£ãƒ«ã‚¿ã‚’å¯è¦–åŒ–ï¼ˆã“ã“ã§ã¯ãƒ©ãƒ³ãƒ€ãƒ åˆæœŸå€¤ï¼‰
filters = conv_layer.weight.data.cpu().numpy()

# 8å€‹ã®ãƒ•ã‚£ãƒ«ã‚¿ã‚’2è¡Œ4åˆ—ã§è¡¨ç¤º
fig, axes = plt.subplots(2, 4, figsize=(12, 6))
axes = axes.flatten()

for i in range(8):
    # filters[i, 0]ã¯ç¬¬iç•ªç›®ã®ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆ1ãƒãƒ£ãƒãƒ«ç›®ï¼‰
    axes[i].imshow(filters[i, 0], cmap='gray')
    axes[i].set_title(f'ãƒ•ã‚£ãƒ«ã‚¿ {i+1}')
    axes[i].axis('off')

plt.suptitle('ç•³ã¿è¾¼ã¿ãƒ•ã‚£ãƒ«ã‚¿ã®å¯è¦–åŒ–ï¼ˆ3Ã—3ã‚«ãƒ¼ãƒãƒ«ï¼‰', fontsize=16)
plt.tight_layout()
print("ãƒ•ã‚£ãƒ«ã‚¿ã‚’å¯è¦–åŒ–ã—ã¾ã—ãŸï¼ˆãƒ©ãƒ³ãƒ€ãƒ åˆæœŸå€¤ï¼‰")
print("å­¦ç¿’å¾Œã¯ã€ã‚¨ãƒƒã‚¸æ¤œå‡ºã‚„ãƒ†ã‚¯ã‚¹ãƒãƒ£æ¤œå‡ºãªã©ã®ç‰¹å¾´ã‚’æŒã¤ãƒ•ã‚£ãƒ«ã‚¿ã«å¤‰åŒ–ã—ã¾ã™")
</code></pre>

<hr>

<h2>1.5 æ´»æ€§åŒ–é–¢æ•°ï¼šReLU</h2>

<h3>ãªãœæ´»æ€§åŒ–é–¢æ•°ãŒå¿…è¦ã‹</h3>

<p>ç•³ã¿è¾¼ã¿æ¼”ç®—ã¯ç·šå½¢å¤‰æ›ã§ã™ã€‚æ´»æ€§åŒ–é–¢æ•°ã‚’ä½¿ã‚ãªã„ã¨ã€è¤‡æ•°ã®å±¤ã‚’é‡ã­ã¦ã‚‚å˜ãªã‚‹ç·šå½¢å¤‰æ›ã®çµ„ã¿åˆã‚ã›ã«ãªã‚Šã€è¤‡é›‘ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å­¦ç¿’ã§ãã¾ã›ã‚“ã€‚</p>

<blockquote>
<p>æ´»æ€§åŒ–é–¢æ•°ã¯<strong>éç·šå½¢æ€§</strong>ã‚’å°å…¥ã—ã€ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã«è¤‡é›‘ãªé–¢æ•°ã‚’è¿‘ä¼¼ã™ã‚‹èƒ½åŠ›ã‚’ä¸ãˆã¾ã™ã€‚</p>
</blockquote>

<h3>ReLUï¼ˆRectified Linear Unitï¼‰</h3>

<p>CNNã§æœ€ã‚‚ä¸€èˆ¬çš„ã«ä½¿ç”¨ã•ã‚Œã‚‹æ´»æ€§åŒ–é–¢æ•°ã¯<strong>ReLU</strong>ã§ã™ã€‚</p>

$$
\text{ReLU}(x) = \max(0, x) = \begin{cases}
x & \text{if } x > 0 \\
0 & \text{if } x \leq 0
\end{cases}
$$

<h4>ReLUã®åˆ©ç‚¹</h4>

<table>
<thead>
<tr>
<th>åˆ©ç‚¹</th>
<th>èª¬æ˜</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>è¨ˆç®—åŠ¹ç‡</strong></td>
<td>å˜ç´”ãªmaxæ¼”ç®—ã®ã¿</td>
</tr>
<tr>
<td><strong>å‹¾é…æ¶ˆå¤±ã®è»½æ¸›</strong></td>
<td>æ­£ã®é ˜åŸŸã§å‹¾é…ãŒ1ï¼ˆSigmoidã‚„Tanhã‚ˆã‚Šå„ªã‚Œã‚‹ï¼‰</td>
</tr>
<tr>
<td><strong>ã‚¹ãƒ‘ãƒ¼ã‚¹æ€§</strong></td>
<td>è² ã®å€¤ã‚’0ã«ã™ã‚‹ã“ã¨ã§ã€ã‚¹ãƒ‘ãƒ¼ã‚¹ãªè¡¨ç¾ã‚’ç”Ÿæˆ</td>
</tr>
<tr>
<td><strong>ç”Ÿç‰©å­¦çš„å¦¥å½“æ€§</strong></td>
<td>ç¥çµŒç´°èƒã®ç™ºç«ãƒ‘ã‚¿ãƒ¼ãƒ³ã«é¡ä¼¼</td>
</tr>
</tbody>
</table>

<pre><code class="language-python">import torch
import torch.nn as nn
import matplotlib.pyplot as plt
import numpy as np

# å„ç¨®æ´»æ€§åŒ–é–¢æ•°ã®æ¯”è¼ƒ
x = np.linspace(-3, 3, 100)

# ReLU
relu = np.maximum(0, x)

# Sigmoid
sigmoid = 1 / (1 + np.exp(-x))

# Tanh
tanh = np.tanh(x)

# Leaky ReLU
leaky_relu = np.where(x > 0, x, 0.1 * x)

# å¯è¦–åŒ–
fig, axes = plt.subplots(2, 2, figsize=(12, 10))

axes[0, 0].plot(x, relu, 'b-', linewidth=2)
axes[0, 0].set_title('ReLU: max(0, x)', fontsize=14)
axes[0, 0].grid(True, alpha=0.3)
axes[0, 0].axhline(y=0, color='k', linewidth=0.5)
axes[0, 0].axvline(x=0, color='k', linewidth=0.5)

axes[0, 1].plot(x, sigmoid, 'r-', linewidth=2)
axes[0, 1].set_title('Sigmoid: 1/(1+exp(-x))', fontsize=14)
axes[0, 1].grid(True, alpha=0.3)
axes[0, 1].axhline(y=0, color='k', linewidth=0.5)
axes[0, 1].axvline(x=0, color='k', linewidth=0.5)

axes[1, 0].plot(x, tanh, 'g-', linewidth=2)
axes[1, 0].set_title('Tanh: tanh(x)', fontsize=14)
axes[1, 0].grid(True, alpha=0.3)
axes[1, 0].axhline(y=0, color='k', linewidth=0.5)
axes[1, 0].axvline(x=0, color='k', linewidth=0.5)

axes[1, 1].plot(x, leaky_relu, 'm-', linewidth=2)
axes[1, 1].set_title('Leaky ReLU: max(0.1x, x)', fontsize=14)
axes[1, 1].grid(True, alpha=0.3)
axes[1, 1].axhline(y=0, color='k', linewidth=0.5)
axes[1, 1].axvline(x=0, color='k', linewidth=0.5)

plt.tight_layout()
print("æ´»æ€§åŒ–é–¢æ•°ã®å½¢çŠ¶ã‚’æ¯”è¼ƒã—ã¾ã—ãŸ")

# PyTorchã§ã®ä½¿ç”¨ä¾‹
print("\n=== PyTorchã§ã®æ´»æ€§åŒ–é–¢æ•°ã®ä½¿ç”¨ ===\n")

x_tensor = torch.tensor([-2.0, -1.0, 0.0, 1.0, 2.0])

relu_layer = nn.ReLU()
print(f"å…¥åŠ›: {x_tensor.numpy()}")
print(f"ReLU: {relu_layer(x_tensor).numpy()}")
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>æ´»æ€§åŒ–é–¢æ•°ã®å½¢çŠ¶ã‚’æ¯”è¼ƒã—ã¾ã—ãŸ

=== PyTorchã§ã®æ´»æ€§åŒ–é–¢æ•°ã®ä½¿ç”¨ ===

å…¥åŠ›: [-2. -1.  0.  1.  2.]
ReLU: [0. 0. 0. 1. 2.]
</code></pre>

<h3>Conv + ReLUã®ãƒ‘ã‚¿ãƒ¼ãƒ³</h3>

<pre><code class="language-python">import torch
import torch.nn as nn

# æ¨™æº–çš„ãªConv-ReLUãƒ–ãƒ­ãƒƒã‚¯
class ConvBlock(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(ConvBlock, self).__init__()
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.conv(x)
        x = self.relu(x)
        return x

# ä½¿ç”¨ä¾‹
block = ConvBlock(3, 64)
x = torch.randn(1, 3, 224, 224)
output = block(x)

print(f"å…¥åŠ›ã‚µã‚¤ã‚º: {x.shape}")
print(f"å‡ºåŠ›ã‚µã‚¤ã‚º: {output.shape}")
print(f"\nå‡¦ç†ã®æµã‚Œ:")
print(f"  1. Conv2d(3 â†’ 64, 3Ã—3) ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°")
print(f"  2. ReLU()ã§éç·šå½¢å¤‰æ›")
print(f"  â†’ ç‰¹å¾´ãƒãƒƒãƒ—å†…ã®è² ã®å€¤ãŒ0ã«ãªã‚‹")
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>å…¥åŠ›ã‚µã‚¤ã‚º: torch.Size([1, 3, 224, 224])
å‡ºåŠ›ã‚µã‚¤ã‚º: torch.Size([1, 64, 224, 224])

å‡¦ç†ã®æµã‚Œ:
  1. Conv2d(3 â†’ 64, 3Ã—3) ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
  2. ReLU()ã§éç·šå½¢å¤‰æ›
  â†’ ç‰¹å¾´ãƒãƒƒãƒ—å†…ã®è² ã®å€¤ãŒ0ã«ãªã‚‹
</code></pre>

<hr>

<h2>1.6 å®Ÿè·µï¼šæ‰‹æ›¸ãæ•°å­—èªè­˜ï¼ˆMNISTï¼‰</h2>

<h3>ã‚·ãƒ³ãƒ—ãƒ«ãªCNNã®æ§‹ç¯‰</h3>

<p>MNISTãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆ28Ã—28ã®ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«æ‰‹æ›¸ãæ•°å­—ç”»åƒï¼‰ã‚’åˆ†é¡ã™ã‚‹åŸºæœ¬çš„ãªCNNã‚’å®Ÿè£…ã—ã¾ã™ã€‚</p>

<pre><code class="language-python">import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision import datasets, transforms
from torch.utils.data import DataLoader

# ã‚·ãƒ³ãƒ—ãƒ«ãªCNNãƒ¢ãƒ‡ãƒ«
class SimpleCNN(nn.Module):
    def __init__(self):
        super(SimpleCNN, self).__init__()
        # ç•³ã¿è¾¼ã¿å±¤1: 1ch â†’ 32ch, 3Ã—3ã‚«ãƒ¼ãƒãƒ«
        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)
        # ç•³ã¿è¾¼ã¿å±¤2: 32ch â†’ 64ch, 3Ã—3ã‚«ãƒ¼ãƒãƒ«
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)
        # å…¨çµåˆå±¤
        self.fc1 = nn.Linear(64 * 7 * 7, 128)
        self.fc2 = nn.Linear(128, 10)
        # ãã®ä»–
        self.pool = nn.MaxPool2d(2, 2)
        self.dropout = nn.Dropout(0.25)

    def forward(self, x):
        # Conv1 â†’ ReLU â†’ MaxPool
        x = self.pool(F.relu(self.conv1(x)))  # 28Ã—28 â†’ 14Ã—14
        # Conv2 â†’ ReLU â†’ MaxPool
        x = self.pool(F.relu(self.conv2(x)))  # 14Ã—14 â†’ 7Ã—7
        # å¹³å¦åŒ–
        x = x.view(-1, 64 * 7 * 7)
        # å…¨çµåˆå±¤
        x = F.relu(self.fc1(x))
        x = self.dropout(x)
        x = self.fc2(x)
        return x

# ãƒ¢ãƒ‡ãƒ«ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–
model = SimpleCNN()

# ãƒ¢ãƒ‡ãƒ«æ§‹é€ ã®è¡¨ç¤º
print("=== SimpleCNN ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ ===\n")
print(model)

# ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã®è¨ˆç®—
total_params = sum(p.numel() for p in model.parameters())
trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)

print(f"\nç·ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {total_params:,}")
print(f"å­¦ç¿’å¯èƒ½ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {trainable_params:,}")

# å„å±¤ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°è©³ç´°
print("\n=== å„å±¤ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•° ===")
for name, param in model.named_parameters():
    print(f"{name:20} {str(list(param.shape)):30} {param.numel():>10,} params")
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>=== SimpleCNN ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ ===

SimpleCNN(
  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (fc1): Linear(in_features=3136, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=10, bias=True)
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (dropout): Dropout(p=0.25, inplace=False)
)

ç·ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: 421,066
å­¦ç¿’å¯èƒ½ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: 421,066

=== å„å±¤ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•° ===
conv1.weight         [32, 1, 3, 3]                         288 params
conv1.bias           [32]                                   32 params
conv2.weight         [64, 32, 3, 3]                     18,432 params
conv2.bias           [64]                                   64 params
fc1.weight           [128, 3136]                       401,408 params
fc1.bias             [128]                                 128 params
fc2.weight           [10, 128]                           1,280 params
fc2.bias             [10]                                   10 params
</code></pre>

<h3>ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™ã¨å­¦ç¿’</h3>

<pre><code class="language-python">import torch.optim as optim

# ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.1307,), (0.3081,))  # MNISTã®å¹³å‡ãƒ»æ¨™æº–åå·®
])

# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®èª­ã¿è¾¼ã¿ï¼ˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã¯åˆå›ã®ã¿ï¼‰
train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)
test_dataset = datasets.MNIST('./data', train=False, transform=transform)

# ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã®ä½œæˆ
train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)

# å­¦ç¿’ã®è¨­å®š
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = SimpleCNN().to(device)
optimizer = optim.Adam(model.parameters(), lr=0.001)
criterion = nn.CrossEntropyLoss()

# å­¦ç¿’é–¢æ•°
def train_epoch(model, train_loader, optimizer, criterion, device):
    model.train()
    running_loss = 0.0
    correct = 0
    total = 0

    for batch_idx, (data, target) in enumerate(train_loader):
        data, target = data.to(device), target.to(device)

        optimizer.zero_grad()
        output = model(data)
        loss = criterion(output, target)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()
        _, predicted = output.max(1)
        total += target.size(0)
        correct += predicted.eq(target).sum().item()

    avg_loss = running_loss / len(train_loader)
    accuracy = 100. * correct / total
    return avg_loss, accuracy

# è©•ä¾¡é–¢æ•°
def evaluate(model, test_loader, criterion, device):
    model.eval()
    test_loss = 0
    correct = 0

    with torch.no_grad():
        for data, target in test_loader:
            data, target = data.to(device), target.to(device)
            output = model(data)
            test_loss += criterion(output, target).item()
            pred = output.argmax(dim=1, keepdim=True)
            correct += pred.eq(target.view_as(pred)).sum().item()

    test_loss /= len(test_loader)
    accuracy = 100. * correct / len(test_loader.dataset)
    return test_loss, accuracy

# å­¦ç¿’å®Ÿè¡Œï¼ˆç°¡ç•¥ç‰ˆï¼š3ã‚¨ãƒãƒƒã‚¯ï¼‰
print("\n=== å­¦ç¿’é–‹å§‹ ===\n")
num_epochs = 3

for epoch in range(num_epochs):
    train_loss, train_acc = train_epoch(model, train_loader, optimizer, criterion, device)
    test_loss, test_acc = evaluate(model, test_loader, criterion, device)

    print(f"Epoch {epoch+1}/{num_epochs}")
    print(f"  Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%")
    print(f"  Test Loss:  {test_loss:.4f}, Test Acc:  {test_acc:.2f}%\n")

print("å­¦ç¿’å®Œäº†ï¼")
</code></pre>

<p><strong>æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›</strong>ï¼š</p>
<pre><code>=== å­¦ç¿’é–‹å§‹ ===

Epoch 1/3
  Train Loss: 0.2145, Train Acc: 93.52%
  Test Loss:  0.0789, Test Acc:  97.56%

Epoch 2/3
  Train Loss: 0.0701, Train Acc: 97.89%
  Test Loss:  0.0512, Test Acc:  98.34%

Epoch 3/3
  Train Loss: 0.0512, Train Acc: 98.42%
  Test Loss:  0.0401, Test Acc:  98.67%

å­¦ç¿’å®Œäº†ï¼
</code></pre>

<h3>å­¦ç¿’æ¸ˆã¿ãƒ•ã‚£ãƒ«ã‚¿ã®å¯è¦–åŒ–</h3>

<pre><code class="language-python">import matplotlib.pyplot as plt
import numpy as np

# ç¬¬1å±¤ã®ç•³ã¿è¾¼ã¿ãƒ•ã‚£ãƒ«ã‚¿ã‚’å¯è¦–åŒ–
conv1_weights = model.conv1.weight.data.cpu().numpy()

# æœ€åˆã®16å€‹ã®ãƒ•ã‚£ãƒ«ã‚¿ã‚’è¡¨ç¤º
fig, axes = plt.subplots(4, 8, figsize=(16, 8))
axes = axes.flatten()

for i in range(min(32, len(axes))):
    axes[i].imshow(conv1_weights[i, 0], cmap='viridis')
    axes[i].set_title(f'Filter {i+1}', fontsize=9)
    axes[i].axis('off')

plt.suptitle('å­¦ç¿’æ¸ˆã¿ç•³ã¿è¾¼ã¿ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆç¬¬1å±¤ã€32å€‹ä¸­32å€‹ï¼‰', fontsize=16)
plt.tight_layout()
print("å­¦ç¿’æ¸ˆã¿ãƒ•ã‚£ãƒ«ã‚¿ã‚’å¯è¦–åŒ–ã—ã¾ã—ãŸ")
print("å„ãƒ•ã‚£ãƒ«ã‚¿ã¯ã€ã‚¨ãƒƒã‚¸ã€æ›²ç·šã€ã‚³ãƒ¼ãƒŠãƒ¼ãªã©ã®ç•°ãªã‚‹ç‰¹å¾´ã‚’æ¤œå‡ºã™ã‚‹ã‚ˆã†ã«å­¦ç¿’ã•ã‚Œã¦ã„ã¾ã™")
</code></pre>

<hr>

<h2>ã¾ã¨ã‚</h2>

<p>ã“ã®ç« ã§ã¯ã€CNNã®åŸºç¤ã¨ç•³ã¿è¾¼ã¿å±¤ã«ã¤ã„ã¦å­¦ç¿’ã—ã¾ã—ãŸã€‚</p>

<h3>é‡è¦ãªãƒã‚¤ãƒ³ãƒˆ</h3>

<ul>
<li><strong>å±€æ‰€æ¥ç¶šæ€§ã¨é‡ã¿å…±æœ‰</strong>ã«ã‚ˆã‚Šã€CNNã¯ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã‚’å¤§å¹…ã«å‰Šæ¸›</li>
<li><strong>ç•³ã¿è¾¼ã¿æ¼”ç®—</strong>ã¯ã€ãƒ•ã‚£ãƒ«ã‚¿ã‚’ç”»åƒä¸Šã§ã‚¹ãƒ©ã‚¤ãƒ‰ã•ã›ã¦ç‰¹å¾´ã‚’æŠ½å‡º</li>
<li><strong>ã‚¹ãƒˆãƒ©ã‚¤ãƒ‰ã¨ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°</strong>ã§å‡ºåŠ›ã‚µã‚¤ã‚ºã‚’åˆ¶å¾¡</li>
<li><strong>å—å®¹é‡</strong>ã¯å±¤ã‚’é‡ã­ã‚‹ã”ã¨ã«æ‹¡å¤§ã—ã€åºƒç¯„å›²ã®æƒ…å ±ã‚’çµ±åˆ</li>
<li><strong>ReLUæ´»æ€§åŒ–é–¢æ•°</strong>ãŒéç·šå½¢æ€§ã‚’å°å…¥ã—ã€è¤‡é›‘ãªãƒ‘ã‚¿ãƒ¼ãƒ³å­¦ç¿’ã‚’å¯èƒ½ã«</li>
</ul>

<h3>æ¬¡ç« ã®äºˆå‘Š</h3>

<p>ç¬¬2ç« ã§ã¯ã€ä»¥ä¸‹ã®ãƒˆãƒ”ãƒƒã‚¯ã‚’æ‰±ã„ã¾ã™ï¼š</p>
<ul>
<li>ãƒ—ãƒ¼ãƒªãƒ³ã‚°å±¤ï¼ˆMaxPoolingã€AveragePoolingï¼‰</li>
<li>ãƒãƒƒãƒæ­£è¦åŒ–ï¼ˆBatch Normalizationï¼‰</li>
<li>Dropout ã«ã‚ˆã‚‹æ­£å‰‡åŒ–</li>
<li>ä»£è¡¨çš„ãªCNNã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ï¼ˆVGGã€ResNetï¼‰</li>
</ul>

<hr>

<h2>æ¼”ç¿’å•é¡Œ</h2>

<details>
<summary><strong>æ¼”ç¿’1ï¼šå‡ºåŠ›ã‚µã‚¤ã‚ºã®è¨ˆç®—</strong></summary>

<p><strong>å•é¡Œ</strong>ï¼šä»¥ä¸‹ã®ç•³ã¿è¾¼ã¿å±¤ã®å‡ºåŠ›ã‚µã‚¤ã‚ºã‚’è¨ˆç®—ã—ã¦ãã ã•ã„ã€‚</p>

<ul>
<li>å…¥åŠ›: 64Ã—64Ã—3</li>
<li>ã‚«ãƒ¼ãƒãƒ«: 5Ã—5</li>
<li>ã‚¹ãƒˆãƒ©ã‚¤ãƒ‰: 2</li>
<li>ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°: 2</li>
<li>å‡ºåŠ›ãƒãƒ£ãƒãƒ«æ•°: 128</li>
</ul>

<p><strong>è§£ç­”</strong>ï¼š</p>
<pre><code># å‡ºåŠ›ã‚µã‚¤ã‚ºã®è¨ˆç®—
output_h = (64 + 2*2 - 5) // 2 + 1 = 32
output_w = (64 + 2*2 - 5) // 2 + 1 = 32

# ç­”ãˆ: 32Ã—32Ã—128
</code></pre>
</details>

<details>
<summary><strong>æ¼”ç¿’2ï¼šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã®è¨ˆç®—</strong></summary>

<p><strong>å•é¡Œ</strong>ï¼šä»¥ä¸‹ã®CNNã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã‚’è¨ˆç®—ã—ã¦ãã ã•ã„ã€‚</p>

<ul>
<li>Conv1: 3ch â†’ 64ch, 7Ã—7ã‚«ãƒ¼ãƒãƒ«</li>
<li>Conv2: 64ch â†’ 128ch, 3Ã—3ã‚«ãƒ¼ãƒãƒ«</li>
<li>Conv3: 128ch â†’ 256ch, 3Ã—3ã‚«ãƒ¼ãƒãƒ«</li>
</ul>

<p><strong>è§£ç­”</strong>ï¼š</p>
<pre><code># Conv1ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°
conv1_params = (3 * 64 * 7 * 7) + 64 = 9,472

# Conv2ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°
conv2_params = (64 * 128 * 3 * 3) + 128 = 73,856

# Conv3ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°
conv3_params = (128 * 256 * 3 * 3) + 256 = 295,168

# åˆè¨ˆ
total_params = 9,472 + 73,856 + 295,168 = 378,496
</code></pre>
</details>

<details>
<summary><strong>æ¼”ç¿’3ï¼šå—å®¹é‡ã®è¨ˆç®—</strong></summary>

<p><strong>å•é¡Œ</strong>ï¼šä»¥ä¸‹ã®æ§‹æˆã®CNNã®æœ€çµ‚çš„ãªå—å®¹é‡ã‚µã‚¤ã‚ºã‚’è¨ˆç®—ã—ã¦ãã ã•ã„ï¼ˆå…¨ã¦ã‚¹ãƒˆãƒ©ã‚¤ãƒ‰1ã€ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã‚ã‚Šï¼‰ã€‚</p>

<ul>
<li>Conv1: 3Ã—3ã‚«ãƒ¼ãƒãƒ«</li>
<li>Conv2: 3Ã—3ã‚«ãƒ¼ãƒãƒ«</li>
<li>Conv3: 3Ã—3ã‚«ãƒ¼ãƒãƒ«</li>
<li>Conv4: 3Ã—3ã‚«ãƒ¼ãƒãƒ«</li>
</ul>

<p><strong>è§£ç­”</strong>ï¼š</p>
<pre><code># å—å®¹é‡ã®è¨ˆç®—
# R_0 = 1 (å…¥åŠ›)
# R_1 = 1 + (3-1) = 3
# R_2 = 3 + (3-1) = 5
# R_3 = 5 + (3-1) = 7
# R_4 = 7 + (3-1) = 9

# ç­”ãˆ: 9Ã—9ãƒ”ã‚¯ã‚»ãƒ«
</code></pre>
</details>

<details>
<summary><strong>æ¼”ç¿’4ï¼šã‚«ã‚¹ã‚¿ãƒ CNNã®å®Ÿè£…</strong></summary>

<p><strong>å•é¡Œ</strong>ï¼šä»¥ä¸‹ã®ä»•æ§˜ã®CNNã‚’PyTorchã§å®Ÿè£…ã—ã¦ãã ã•ã„ã€‚</p>

<ul>
<li>å…¥åŠ›: 32Ã—32Ã—3ï¼ˆCIFAR-10å½¢å¼ï¼‰</li>
<li>Conv1: 32ãƒ•ã‚£ãƒ«ã‚¿ã€3Ã—3ã‚«ãƒ¼ãƒãƒ«ã€ReLU</li>
<li>MaxPool: 2Ã—2</li>
<li>Conv2: 64ãƒ•ã‚£ãƒ«ã‚¿ã€3Ã—3ã‚«ãƒ¼ãƒãƒ«ã€ReLU</li>
<li>MaxPool: 2Ã—2</li>
<li>å…¨çµåˆ: 10ã‚¯ãƒ©ã‚¹åˆ†é¡</li>
</ul>

<p><strong>è§£ç­”ä¾‹</strong>ï¼š</p>
<pre><code class="language-python">import torch.nn as nn
import torch.nn.functional as F

class CustomCNN(nn.Module):
    def __init__(self):
        super(CustomCNN, self).__init__()
        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)
        self.pool = nn.MaxPool2d(2, 2)
        self.fc = nn.Linear(64 * 8 * 8, 10)

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))  # 32Ã—32 â†’ 16Ã—16
        x = self.pool(F.relu(self.conv2(x)))  # 16Ã—16 â†’ 8Ã—8
        x = x.view(-1, 64 * 8 * 8)
        x = self.fc(x)
        return x
</code></pre>
</details>

<details>
<summary><strong>æ¼”ç¿’5ï¼šå…¨çµåˆå±¤ã¨CNNã®æ¯”è¼ƒ</strong></summary>

<p><strong>å•é¡Œ</strong>ï¼š224Ã—224Ã—3ã®ç”»åƒã‚’å…¥åŠ›ã¨ã™ã‚‹å ´åˆã€ä»¥ä¸‹ã®2ã¤ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã‚’æ¯”è¼ƒã—ã¦ãã ã•ã„ã€‚</p>

<ul>
<li>ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ1: å…¨çµåˆå±¤ï¼ˆå…¥åŠ›â†’1000ãƒ¦ãƒ‹ãƒƒãƒˆï¼‰</li>
<li>ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ2: Convå±¤ï¼ˆ3châ†’64chã€3Ã—3ã‚«ãƒ¼ãƒãƒ«ï¼‰ã‚’3å±¤</li>
</ul>

<p><strong>è§£ç­”</strong>ï¼š</p>
<pre><code># ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ1: å…¨çµåˆå±¤
fc_params = (224 * 224 * 3 * 1000) + 1000 = 150,529,000

# ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ2: CNNï¼ˆ3å±¤ï¼‰
conv1_params = (3 * 64 * 3 * 3) + 64 = 1,792
conv2_params = (64 * 64 * 3 * 3) + 64 = 36,928
conv3_params = (64 * 64 * 3 * 3) + 64 = 36,928
cnn_total = 1,792 + 36,928 + 36,928 = 75,648

# å‰Šæ¸›ç‡
reduction = (1 - 75,648/150,529,000) * 100 = 99.95%

# CNNã¯å…¨çµåˆå±¤ã®0.05%ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§æ¸ˆã‚€ï¼
</code></pre>
</details>

<hr>

<div class="navigation">
    <a href="../index.html" class="nav-button">ğŸ“š ã‚³ãƒ¼ã‚¹ç›®æ¬¡ã«æˆ»ã‚‹</a>
    <a href="chapter2-pooling-normalization.html" class="nav-button">æ¬¡ã®ç« ã¸ï¼šãƒ—ãƒ¼ãƒªãƒ³ã‚°ã¨æ­£è¦åŒ– â†’</a>
</div>

</main>


    <section class="disclaimer">
        <h3>å…è²¬äº‹é …</h3>
        <ul>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯æ•™è‚²ãƒ»ç ”ç©¶ãƒ»æƒ…å ±æä¾›ã®ã¿ã‚’ç›®çš„ã¨ã—ã¦ãŠã‚Šã€å°‚é–€çš„ãªåŠ©è¨€(æ³•å¾‹ãƒ»ä¼šè¨ˆãƒ»æŠ€è¡“çš„ä¿è¨¼ãªã©)ã‚’æä¾›ã™ã‚‹ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŠã‚ˆã³ä»˜éšã™ã‚‹ã‚³ãƒ¼ãƒ‰ä¾‹ã¯ã€Œç¾çŠ¶æœ‰å§¿(AS IS)ã€ã§æä¾›ã•ã‚Œã€æ˜ç¤ºã¾ãŸã¯é»™ç¤ºã‚’å•ã‚ãšã€å•†å“æ€§ã€ç‰¹å®šç›®çš„é©åˆæ€§ã€æ¨©åˆ©éä¾µå®³ã€æ­£ç¢ºæ€§ãƒ»å®Œå…¨æ€§ã€å‹•ä½œãƒ»å®‰å…¨æ€§ç­‰ã„ã‹ãªã‚‹ä¿è¨¼ã‚‚ã—ã¾ã›ã‚“ã€‚</li>
            <li>å¤–éƒ¨ãƒªãƒ³ã‚¯ã€ç¬¬ä¸‰è€…ãŒæä¾›ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ»ãƒ„ãƒ¼ãƒ«ãƒ»ãƒ©ã‚¤ãƒ–ãƒ©ãƒªç­‰ã®å†…å®¹ãƒ»å¯ç”¨æ€§ãƒ»å®‰å…¨æ€§ã«ã¤ã„ã¦ã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯ä¸€åˆ‡ã®è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®åˆ©ç”¨ãƒ»å®Ÿè¡Œãƒ»è§£é‡ˆã«ã‚ˆã‚Šç›´æ¥çš„ãƒ»é–“æ¥çš„ãƒ»ä»˜éšçš„ãƒ»ç‰¹åˆ¥ãƒ»çµæœçš„ãƒ»æ‡²ç½°çš„æå®³ãŒç”Ÿã˜ãŸå ´åˆã§ã‚‚ã€é©ç”¨æ³•ã§è¨±å®¹ã•ã‚Œã‚‹æœ€å¤§é™ã®ç¯„å›²ã§ã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å†…å®¹ã¯ã€äºˆå‘Šãªãå¤‰æ›´ãƒ»æ›´æ–°ãƒ»æä¾›åœæ­¢ã•ã‚Œã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®è‘—ä½œæ¨©ãƒ»ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯æ˜è¨˜ã•ã‚ŒãŸæ¡ä»¶(ä¾‹: CC BY 4.0)ã«å¾“ã„ã¾ã™ã€‚å½“è©²ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯é€šå¸¸ã€ç„¡ä¿è¨¼æ¡é …ã‚’å«ã¿ã¾ã™ã€‚</li>
        </ul>
    </section>

<footer>
    <p>&copy; 2025 AI Terakoya. All rights reserved.</p>
</footer>

</body>
</html>