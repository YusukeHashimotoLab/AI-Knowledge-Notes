<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
<meta content="ç¬¬3ç« ï¼šFew-Shotå­¦ç¿’æ‰‹æ³• - AI Terakoya" name="description"/>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ç¬¬3ç« ï¼šFew-Shotå­¦ç¿’æ‰‹æ³• - AI Terakoya</title>

    <style>
        :root {
            --color-primary: #2c3e50;
            --color-primary-dark: #1a252f;
            --color-accent: #7b2cbf;
            --color-accent-light: #9d4edd;
            --color-text: #2d3748;
            --color-text-light: #4a5568;
            --color-bg: #ffffff;
            --color-bg-alt: #f7fafc;
            --color-border: #e2e8f0;
            --color-code-bg: #f8f9fa;
            --color-link: #3182ce;
            --color-link-hover: #2c5aa0;
            --spacing-xs: 0.5rem;
            --spacing-sm: 1rem;
            --spacing-md: 1.5rem;
            --spacing-lg: 2rem;
            --spacing-xl: 3rem;
            --font-body: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            --font-mono: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;
            --border-radius: 8px;
            --box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body { font-family: var(--font-body); line-height: 1.7; color: var(--color-text); background-color: var(--color-bg); font-size: 16px; }
        header { background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%); color: white; padding: var(--spacing-xl) var(--spacing-md); margin-bottom: var(--spacing-xl); box-shadow: var(--box-shadow); }
        .header-content { max-width: 900px; margin: 0 auto; }
        h1 { font-size: 2rem; font-weight: 700; margin-bottom: var(--spacing-sm); line-height: 1.2; }
        .subtitle { font-size: 1.1rem; opacity: 0.95; font-weight: 400; margin-bottom: var(--spacing-md); }
        .meta { display: flex; flex-wrap: wrap; gap: var(--spacing-md); font-size: 0.9rem; opacity: 0.9; }
        .meta-item { display: flex; align-items: center; gap: 0.3rem; }
        .container { max-width: 900px; margin: 0 auto; padding: 0 var(--spacing-md) var(--spacing-xl); }
        h2 { font-size: 1.75rem; color: var(--color-primary); margin-top: var(--spacing-xl); margin-bottom: var(--spacing-md); padding-bottom: var(--spacing-xs); border-bottom: 3px solid var(--color-accent); }
        h3 { font-size: 1.4rem; color: var(--color-primary); margin-top: var(--spacing-lg); margin-bottom: var(--spacing-sm); }
        h4 { font-size: 1.1rem; color: var(--color-primary-dark); margin-top: var(--spacing-md); margin-bottom: var(--spacing-sm); }
        p { margin-bottom: var(--spacing-md); color: var(--color-text); }
        a { color: var(--color-link); text-decoration: none; transition: color 0.2s; }
        a:hover { color: var(--color-link-hover); text-decoration: underline; }
        ul, ol { margin-left: var(--spacing-lg); margin-bottom: var(--spacing-md); }
        li { margin-bottom: var(--spacing-xs); color: var(--color-text); }
        pre { background-color: var(--color-code-bg); border: 1px solid var(--color-border); border-radius: var(--border-radius); padding: var(--spacing-md); overflow-x: auto; margin-bottom: var(--spacing-md); font-family: var(--font-mono); font-size: 0.9rem; line-height: 1.5; }
        code { font-family: var(--font-mono); font-size: 0.9em; background-color: var(--color-code-bg); padding: 0.2em 0.4em; border-radius: 3px; }
        pre code { background-color: transparent; padding: 0; }
        table { width: 100%; border-collapse: collapse; margin-bottom: var(--spacing-md); font-size: 0.95rem; }
        th, td { border: 1px solid var(--color-border); padding: var(--spacing-sm); text-align: left; }
        th { background-color: var(--color-bg-alt); font-weight: 600; color: var(--color-primary); }
        blockquote { border-left: 4px solid var(--color-accent); padding-left: var(--spacing-md); margin: var(--spacing-md) 0; color: var(--color-text-light); font-style: italic; background-color: var(--color-bg-alt); padding: var(--spacing-md); border-radius: var(--border-radius); }
        .mermaid { text-align: center; margin: var(--spacing-lg) 0; background-color: var(--color-bg-alt); padding: var(--spacing-md); border-radius: var(--border-radius); }
        details { background-color: var(--color-bg-alt); border: 1px solid var(--color-border); border-radius: var(--border-radius); padding: var(--spacing-md); margin-bottom: var(--spacing-md); }
        summary { cursor: pointer; font-weight: 600; color: var(--color-primary); user-select: none; padding: var(--spacing-xs); margin: calc(-1 * var(--spacing-md)); padding: var(--spacing-md); border-radius: var(--border-radius); }
        summary:hover { background-color: rgba(123, 44, 191, 0.1); }
        details[open] summary { margin-bottom: var(--spacing-md); border-bottom: 1px solid var(--color-border); }
        .navigation { display: flex; justify-content: space-between; gap: var(--spacing-md); margin: var(--spacing-xl) 0; padding-top: var(--spacing-lg); border-top: 2px solid var(--color-border); }
        .nav-button { flex: 1; padding: var(--spacing-md); background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%); color: white; border-radius: var(--border-radius); text-align: center; font-weight: 600; transition: transform 0.2s, box-shadow 0.2s; box-shadow: var(--box-shadow); }
        .nav-button:hover { transform: translateY(-2px); box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15); text-decoration: none; }
        footer { margin-top: var(--spacing-xl); padding: var(--spacing-lg) var(--spacing-md); background-color: var(--color-bg-alt); border-top: 1px solid var(--color-border); text-align: center; font-size: 0.9rem; color: var(--color-text-light); }
        .disclaimer {
            max-width: 900px;
            margin: 2rem auto;
            padding: 1.5rem;
            background: #f8f9fa;
            border-left: 4px solid #6c757d;
            border-radius: 4px;
        }

        .disclaimer h3 {
            color: #495057;
            margin-bottom: 1rem;
            font-size: 1.1rem;
        }

        .disclaimer ul {
            list-style: none;
            padding-left: 0;
        }

        .disclaimer li {
            padding: 0.5rem 0;
            padding-left: 1.5rem;
            position: relative;
            font-size: 0.9rem;
            color: #6c757d;
            line-height: 1.6;
        }

        .disclaimer li::before {
            content: "âš ï¸";
            position: absolute;
            left: 0;
        }

        .project-box { background: linear-gradient(135deg, #e3f2fd 0%, #bbdefb 50%); border-radius: var(--border-radius); padding: var(--spacing-lg); margin: var(--spacing-lg) 0; box-shadow: var(--box-shadow); }
        @media (max-width: 768px) { h1 { font-size: 1.5rem; } h2 { font-size: 1.4rem; } h3 { font-size: 1.2rem; } .meta { font-size: 0.85rem; } .navigation { flex-direction: column; } table { font-size: 0.85rem; } th, td { padding: var(--spacing-xs); } }
    
        
    
        /* Breadcrumb styles */
        .breadcrumb {
            background: #f7fafc;
            padding: 0.75rem 1rem;
            border-bottom: 1px solid #e2e8f0;
            font-size: 0.9rem;
        }

        .breadcrumb-content {
            max-width: 900px;
            margin: 0 auto;
            display: flex;
            align-items: center;
            flex-wrap: wrap;
            gap: 0.5rem;
        }

        .breadcrumb a {
            color: #667eea;
            text-decoration: none;
            transition: color 0.2s;
        }

        .breadcrumb a:hover {
            color: #764ba2;
            text-decoration: underline;
        }

        .breadcrumb-separator {
            color: #a0aec0;
            margin: 0 0.25rem;
        }

        .breadcrumb-current {
            color: #4a5568;
            font-weight: 500;
        }
    </style>

    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
        mermaid.initialize({ startOnLoad: true, theme: 'default' });
    </script>
    <script>
        MathJax = {
            tex: { inlineMath: [['$', '$'], ['\\(', '\\)']], displayMath: [['$$', '$$'], ['\\[', '\\]']], processEscapes: true, processEnvironments: true },
            options: { skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'], ignoreHtmlClass: 'mermaid' }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" async></script>

    <style>
        /* Locale Switcher Styles */
        .locale-switcher {
            display: flex;
            align-items: center;
            gap: 0.5rem;
            padding: 0.5rem 1rem;
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
            border-radius: 6px;
            font-size: 0.9rem;
            margin-bottom: 1rem;
            box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);
        }

        .current-locale {
            font-weight: 600;
            color: #7b2cbf;
            display: flex;
            align-items: center;
            gap: 0.25rem;
        }

        .locale-separator {
            color: #adb5bd;
            font-weight: 300;
        }

        .locale-link {
            color: #f093fb;
            text-decoration: none;
            font-weight: 500;
            transition: all 0.2s ease;
            display: flex;
            align-items: center;
            gap: 0.25rem;
            padding: 0.2rem 0.5rem;
            border-radius: 4px;
        }

        .locale-link:hover {
            background: rgba(240, 147, 251, 0.1);
            color: #d07be8;
            transform: translateY(-1px);
        }

        .locale-meta {
            color: #868e96;
            font-size: 0.85rem;
            font-style: italic;
            margin-left: auto;
        }

        @media (max-width: 768px) {
            .locale-switcher {
                font-size: 0.85rem;
                padding: 0.4rem 0.8rem;
            }
            .locale-meta {
                display: none;
            }
        }
    </style>
</head>
<body>
            <div class="locale-switcher">
<span class="current-locale">ğŸŒ JP</span>
<span class="locale-separator">|</span>
<a href="../../../en/ML/meta-learning-introduction/chapter3-few-shot-methods.html" class="locale-link">ğŸ‡¬ğŸ‡§ EN</a>
<span class="locale-separator">|</span>
<span class="locale-meta">Last sync: 2025-11-16</span>
</div>
<nav class="breadcrumb">
        <div class="breadcrumb-content">
            <a href="../../index.html">AIå¯ºå­å±‹ãƒˆãƒƒãƒ—</a><span class="breadcrumb-separator">â€º</span><a href="../../ML/index.html">æ©Ÿæ¢°å­¦ç¿’</a><span class="breadcrumb-separator">â€º</span><a href="../../ML/meta-learning-introduction/index.html">Meta Learning</a><span class="breadcrumb-separator">â€º</span><span class="breadcrumb-current">Chapter 3</span>
        </div>
    </nav>

        <header>
        <div class="header-content">
            <h1>ç¬¬3ç« ï¼šFew-Shotå­¦ç¿’æ‰‹æ³•</h1>
            <p class="subtitle">ãƒ¡ãƒˆãƒªãƒƒã‚¯å­¦ç¿’ã«åŸºã¥ãå°‘æ•°ã‚µãƒ³ãƒ—ãƒ«åˆ†é¡ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£</p>
            <div class="meta">
                <span class="meta-item">ğŸ“– èª­äº†æ™‚é–“: 32åˆ†</span>
                <span class="meta-item">ğŸ“Š é›£æ˜“åº¦: ä¸­ç´šã€œä¸Šç´š</span>
                <span class="meta-item">ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹: 8å€‹</span>
                <span class="meta-item">ğŸ“ æ¼”ç¿’å•é¡Œ: 4å•</span>
            </div>
        </div>
    </header>

    <main class="container">

<h2>å­¦ç¿’ç›®æ¨™</h2>
<p>ã“ã®ç« ã‚’èª­ã‚€ã“ã¨ã§ã€ä»¥ä¸‹ã‚’ç¿’å¾—ã§ãã¾ã™ï¼š</p>
<ul>
<li>âœ… Siamese Networksã«ã‚ˆã‚‹ãƒšã‚¢å­¦ç¿’ã¨Contrastive Lossã‚’ç†è§£ã§ãã‚‹</li>
<li>âœ… Prototypical Networksã®ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ãƒ™ãƒ¼ã‚¹åˆ†é¡ã‚’å®Ÿè£…ã§ãã‚‹</li>
<li>âœ… Matching Networksã®Attentionæ©Ÿæ§‹ã‚’æ´»ç”¨ã—ãŸåˆ†é¡ã‚’å®Ÿè£…ã§ãã‚‹</li>
<li>âœ… Relation Networksã®å­¦ç¿’å¯èƒ½ãªè·é›¢ãƒ¡ãƒˆãƒªãƒƒã‚¯ã‚’ç†è§£ã§ãã‚‹</li>
<li>âœ… Few-Shotå­¦ç¿’æ‰‹æ³•ã®æ¯”è¼ƒå®Ÿé¨“ã‚’è¨­è¨ˆãƒ»å®Ÿæ–½ã§ãã‚‹</li>
</ul>

<h2>1. Siamese Networks</h2>

<h3>1.1 ãƒšã‚¢å­¦ç¿’ã®åŸç†</h3>

<p>Siamese Networksï¼ˆã‚·ãƒ£ãƒ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼‰ã¯ã€2ã¤ã®å…¥åŠ›ã‚’åŒã˜ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼ˆé‡ã¿å…±æœ‰ï¼‰ã§å‡¦ç†ã—ã€ãã®é¡ä¼¼åº¦ã‚’å­¦ç¿’ã™ã‚‹ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§ã™ã€‚Few-Shotå­¦ç¿’ã«ãŠã„ã¦ã€ã‚µãƒ³ãƒ—ãƒ«é–“ã®é–¢ä¿‚æ€§ã‚’ç›´æ¥å­¦ç¿’ã™ã‚‹åŸºæœ¬çš„ãªæ‰‹æ³•ã§ã™ã€‚</p>

<div class="mermaid">
graph LR
    A[ç”»åƒ1] --> B[CNN]
    C[ç”»åƒ2] --> D[CNN]
    B --> E[åŸ‹ã‚è¾¼ã¿1]
    D --> F[åŸ‹ã‚è¾¼ã¿2]
    E --> G[è·é›¢è¨ˆç®—]
    F --> G
    G --> H[é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢]

    style B fill:#9d4edd
    style D fill:#9d4edd
    style G fill:#3182ce
</div>

<p><strong>ä¸»è¦ãªç‰¹å¾´ï¼š</strong></p>
<ul>
<li><strong>é‡ã¿å…±æœ‰ï¼š</strong> 2ã¤ã®å…¥åŠ›ã«åŒã˜ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’é©ç”¨ã™ã‚‹ã“ã¨ã§ã€ä¸€è²«ã—ãŸç‰¹å¾´ç©ºé–“ã‚’å­¦ç¿’</li>
<li><strong>ãƒšã‚¢å˜ä½å­¦ç¿’ï¼š</strong> 2ã¤ã®ã‚µãƒ³ãƒ—ãƒ«ãŒåŒã˜ã‚¯ãƒ©ã‚¹ã‹ç•°ãªã‚‹ã‚¯ãƒ©ã‚¹ã‹ã‚’ç›´æ¥å­¦ç¿’</li>
<li><strong>è¨ˆé‡å­¦ç¿’ï¼š</strong> æ„å‘³çš„ã«é¡ä¼¼ã—ãŸã‚µãƒ³ãƒ—ãƒ«ã¯è¿‘ãã€ç•°ãªã‚‹ã‚µãƒ³ãƒ—ãƒ«ã¯é ãé…ç½®</li>
</ul>

<h3>1.2 Contrastive Loss</h3>

<p>Contrastive Lossã¯ã€åŒã˜ã‚¯ãƒ©ã‚¹ã®ãƒšã‚¢ã¯è¿‘ãã€ç•°ãªã‚‹ã‚¯ãƒ©ã‚¹ã®ãƒšã‚¢ã¯é ããªã‚‹ã‚ˆã†ã«å­¦ç¿’ã™ã‚‹æå¤±é–¢æ•°ã§ã™ã€‚</p>

<p><strong>æ•°å¼å®šç¾©ï¼š</strong></p>
$$
\mathcal{L}(x_1, x_2, y) = y \cdot d(x_1, x_2)^2 + (1-y) \cdot \max(0, m - d(x_1, x_2))^2
$$

<p>ã“ã“ã§ï¼š</p>
<ul>
<li>$d(x_1, x_2)$ ã¯ãƒ¦ãƒ¼ã‚¯ãƒªãƒƒãƒ‰è·é›¢</li>
<li>$y \in \{0, 1\}$ ã¯ãƒ©ãƒ™ãƒ«ï¼ˆ1=åŒã˜ã‚¯ãƒ©ã‚¹ã€0=ç•°ãªã‚‹ã‚¯ãƒ©ã‚¹ï¼‰</li>
<li>$m$ ã¯ãƒãƒ¼ã‚¸ãƒ³ï¼ˆç•°ãªã‚‹ã‚¯ãƒ©ã‚¹é–“ã®æœ€å°è·é›¢ï¼‰</li>
</ul>

<h3>1.3 ç”»åƒãƒšã‚¢ã§ã®é¡ä¼¼åº¦å­¦ç¿’</h3>

<pre><code class="language-python">import torch
import torch.nn as nn
import torch.nn.functional as F

class SiameseNetwork(nn.Module):
    """Siamese Networkå®Ÿè£…"""

    def __init__(self, input_channels=3, embedding_dim=128):
        super(SiameseNetwork, self).__init__()

        # å…±æœ‰ã•ã‚Œã‚‹ç‰¹å¾´æŠ½å‡ºå™¨
        self.encoder = nn.Sequential(
            # Conv Block 1
            nn.Conv2d(input_channels, 64, 3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2, 2),

            # Conv Block 2
            nn.Conv2d(64, 128, 3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2, 2),

            # Conv Block 3
            nn.Conv2d(128, 256, 3, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2, 2),

            nn.Flatten(),
        )

        # å…¨çµåˆå±¤ã§åŸ‹ã‚è¾¼ã¿ç©ºé–“ã¸
        self.fc = nn.Sequential(
            nn.Linear(256 * 8 * 8, 512),
            nn.ReLU(inplace=True),
            nn.Linear(512, embedding_dim)
        )

    def forward_one(self, x):
        """1ã¤ã®å…¥åŠ›ã‚’åŸ‹ã‚è¾¼ã¿ç©ºé–“ã¸å¤‰æ›"""
        x = self.encoder(x)
        x = self.fc(x)
        return F.normalize(x, p=2, dim=1)  # L2æ­£è¦åŒ–

    def forward(self, x1, x2):
        """ãƒšã‚¢å…¥åŠ›ã‚’å‡¦ç†"""
        emb1 = self.forward_one(x1)
        emb2 = self.forward_one(x2)
        return emb1, emb2

class ContrastiveLoss(nn.Module):
    """Contrastive Losså®Ÿè£…"""

    def __init__(self, margin=1.0):
        super(ContrastiveLoss, self).__init__()
        self.margin = margin

    def forward(self, emb1, emb2, label):
        """
        Args:
            emb1, emb2: åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ« (batch_size, embedding_dim)
            label: ãƒ©ãƒ™ãƒ« (1=åŒã˜ã‚¯ãƒ©ã‚¹, 0=ç•°ãªã‚‹ã‚¯ãƒ©ã‚¹)
        """
        # ãƒ¦ãƒ¼ã‚¯ãƒªãƒƒãƒ‰è·é›¢
        distance = F.pairwise_distance(emb1, emb2, p=2)

        # Contrastive Loss
        loss_positive = label * torch.pow(distance, 2)
        loss_negative = (1 - label) * torch.pow(
            torch.clamp(self.margin - distance, min=0.0), 2
        )

        loss = torch.mean(loss_positive + loss_negative)
        return loss

# å­¦ç¿’ä¾‹
def train_siamese(model, train_loader, num_epochs=10):
    """Siamese Networkã®å­¦ç¿’"""
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = model.to(device)

    criterion = ContrastiveLoss(margin=1.0)
    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

    for epoch in range(num_epochs):
        model.train()
        total_loss = 0

        for batch_idx, (img1, img2, labels) in enumerate(train_loader):
            img1, img2, labels = img1.to(device), img2.to(device), labels.to(device)

            # Forward
            emb1, emb2 = model(img1, img2)
            loss = criterion(emb1, emb2, labels.float())

            # Backward
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            total_loss += loss.item()

        avg_loss = total_loss / len(train_loader)
        print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}")

# ä½¿ç”¨ä¾‹
model = SiameseNetwork(input_channels=3, embedding_dim=128)
print(f"Total parameters: {sum(p.numel() for p in model.parameters()):,}")
</code></pre>

<h2>2. Prototypical Networks</h2>

<h3>2.1 ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ï¼ˆã‚¯ãƒ©ã‚¹ä¸­å¿ƒï¼‰ã®è¨ˆç®—</h3>

<p>Prototypical Networksã¯ã€å„ã‚¯ãƒ©ã‚¹ã®ã€Œãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ã€ï¼ˆä»£è¡¨çš„ãªåŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ï¼‰ã‚’è¨ˆç®—ã—ã€æ–°ã—ã„ã‚µãƒ³ãƒ—ãƒ«ã‚’æœ€ã‚‚è¿‘ã„ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ã®ã‚¯ãƒ©ã‚¹ã«åˆ†é¡ã—ã¾ã™ã€‚</p>

<div class="mermaid">
graph TB
    subgraph Support Set
        A1[ã‚¯ãƒ©ã‚¹A ã‚µãƒ³ãƒ—ãƒ«1] --> E1[ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€]
        A2[ã‚¯ãƒ©ã‚¹A ã‚µãƒ³ãƒ—ãƒ«2] --> E2[ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€]
        B1[ã‚¯ãƒ©ã‚¹B ã‚µãƒ³ãƒ—ãƒ«1] --> E3[ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€]
        B2[ã‚¯ãƒ©ã‚¹B ã‚µãƒ³ãƒ—ãƒ«2] --> E4[ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€]
    end

    E1 --> PA[ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—A<br/>å¹³å‡]
    E2 --> PA
    E3 --> PB[ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—B<br/>å¹³å‡]
    E4 --> PB

    Q[Query] --> EQ[ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€]
    EQ --> D[è·é›¢è¨ˆç®—]
    PA --> D
    PB --> D
    D --> C[åˆ†é¡]

    style PA fill:#9d4edd
    style PB fill:#9d4edd
    style D fill:#3182ce
</div>

<p><strong>ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ã®å®šç¾©ï¼š</strong></p>
$$
c_k = \frac{1}{|S_k|} \sum_{(x_i, y_i) \in S_k} f_\theta(x_i)
$$

<p>ã“ã“ã§ï¼š</p>
<ul>
<li>$c_k$ ã¯ã‚¯ãƒ©ã‚¹$k$ã®ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—</li>
<li>$S_k$ ã¯ã‚¯ãƒ©ã‚¹$k$ã®ã‚µãƒãƒ¼ãƒˆã‚»ãƒƒãƒˆ</li>
<li>$f_\theta$ ã¯ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯</li>
</ul>

<h3>2.2 ãƒ¦ãƒ¼ã‚¯ãƒªãƒƒãƒ‰è·é›¢ãƒ™ãƒ¼ã‚¹ã®åˆ†é¡</h3>

<p>ã‚¯ã‚¨ãƒªã‚µãƒ³ãƒ—ãƒ«$x$ã®ã‚¯ãƒ©ã‚¹ç¢ºç‡ã¯softmaxã§è¨ˆç®—ã•ã‚Œã¾ã™ï¼š</p>

$$
P(y=k|x) = \frac{\exp(-d(f_\theta(x), c_k))}{\sum_{k'} \exp(-d(f_\theta(x), c_{k'}))}
$$

<h3>2.3 PyTorchå®Ÿè£…</h3>

<pre><code class="language-python">import torch
import torch.nn as nn
import torch.nn.functional as F

class PrototypicalNetwork(nn.Module):
    """Prototypical Networkå®Ÿè£…"""

    def __init__(self, input_channels=3, hidden_dim=64):
        super(PrototypicalNetwork, self).__init__()

        # ç‰¹å¾´æŠ½å‡ºå™¨ï¼ˆ4å±¤CNNãƒ–ãƒ­ãƒƒã‚¯ï¼‰
        def conv_block(in_channels, out_channels):
            return nn.Sequential(
                nn.Conv2d(in_channels, out_channels, 3, padding=1),
                nn.BatchNorm2d(out_channels),
                nn.ReLU(inplace=True),
                nn.MaxPool2d(2)
            )

        self.encoder = nn.Sequential(
            conv_block(input_channels, hidden_dim),
            conv_block(hidden_dim, hidden_dim),
            conv_block(hidden_dim, hidden_dim),
            conv_block(hidden_dim, hidden_dim),
            nn.Flatten()
        )

    def forward(self, support_images, support_labels, query_images, n_way, k_shot):
        """
        Args:
            support_images: (n_way * k_shot, C, H, W)
            support_labels: (n_way * k_shot,)
            query_images: (n_query, C, H, W)
            n_way: ã‚¯ãƒ©ã‚¹æ•°
            k_shot: ã‚¯ãƒ©ã‚¹ã‚ãŸã‚Šã®ã‚µãƒ³ãƒ—ãƒ«æ•°
        """
        # ã‚µãƒãƒ¼ãƒˆã‚»ãƒƒãƒˆã¨ã‚¯ã‚¨ãƒªã‚»ãƒƒãƒˆã®åŸ‹ã‚è¾¼ã¿
        support_embeddings = self.encoder(support_images)
        query_embeddings = self.encoder(query_images)

        # ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ã®è¨ˆç®—ï¼ˆå„ã‚¯ãƒ©ã‚¹ã®å¹³å‡ï¼‰
        prototypes = self.compute_prototypes(
            support_embeddings, support_labels, n_way
        )

        # ã‚¯ã‚¨ãƒªã¨ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—é–“ã®è·é›¢ã‚’è¨ˆç®—
        distances = self.euclidean_distance(query_embeddings, prototypes)

        # è² ã®è·é›¢ã‚’logitsã¨ã—ã¦ä½¿ç”¨
        logits = -distances
        return logits

    def compute_prototypes(self, embeddings, labels, n_way):
        """å„ã‚¯ãƒ©ã‚¹ã®ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ã‚’è¨ˆç®—"""
        prototypes = torch.zeros(n_way, embeddings.size(1), device=embeddings.device)

        for k in range(n_way):
            # ã‚¯ãƒ©ã‚¹kã«å±ã™ã‚‹ã‚µãƒ³ãƒ—ãƒ«ã®ãƒã‚¹ã‚¯
            mask = (labels == k)
            # ã‚¯ãƒ©ã‚¹kã®ã‚µãƒ³ãƒ—ãƒ«ã®å¹³å‡ã‚’è¨ˆç®—
            prototypes[k] = embeddings[mask].mean(dim=0)

        return prototypes

    def euclidean_distance(self, x, y):
        """
        ãƒ¦ãƒ¼ã‚¯ãƒªãƒƒãƒ‰è·é›¢ã®è¨ˆç®—
        Args:
            x: (n_query, d)
            y: (n_way, d)
        Returns:
            distances: (n_query, n_way)
        """
        n = x.size(0)
        m = y.size(0)
        d = x.size(1)

        # ãƒ–ãƒ­ãƒ¼ãƒ‰ã‚­ãƒ£ã‚¹ãƒˆã§åŠ¹ç‡çš„ã«è¨ˆç®—
        x = x.unsqueeze(1).expand(n, m, d)  # (n, m, d)
        y = y.unsqueeze(0).expand(n, m, d)  # (n, m, d)

        return torch.pow(x - y, 2).sum(2)  # (n, m)

def train_prototypical(model, train_loader, num_epochs=100, n_way=5, k_shot=1):
    """Prototypical Networkã®å­¦ç¿’"""
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = model.to(device)

    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
    criterion = nn.CrossEntropyLoss()

    for epoch in range(num_epochs):
        model.train()
        total_loss = 0
        total_acc = 0

        for batch_idx, (support_imgs, support_labels, query_imgs, query_labels) in enumerate(train_loader):
            support_imgs = support_imgs.to(device)
            support_labels = support_labels.to(device)
            query_imgs = query_imgs.to(device)
            query_labels = query_labels.to(device)

            # Forward
            logits = model(support_imgs, support_labels, query_imgs, n_way, k_shot)
            loss = criterion(logits, query_labels)

            # ç²¾åº¦è¨ˆç®—
            pred = logits.argmax(dim=1)
            acc = (pred == query_labels).float().mean()

            # Backward
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            total_loss += loss.item()
            total_acc += acc.item()

        avg_loss = total_loss / len(train_loader)
        avg_acc = total_acc / len(train_loader)

        if (epoch + 1) % 10 == 0:
            print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}, Acc: {avg_acc:.4f}")

# ä½¿ç”¨ä¾‹
model = PrototypicalNetwork(input_channels=3, hidden_dim=64)
print(f"Model architecture:\n{model}")
</code></pre>

<h2>3. Matching Networks</h2>

<h3>3.1 Attentionæ©Ÿæ§‹ã®æ´»ç”¨</h3>

<p>Matching Networksã¯ã€ã‚¯ã‚¨ãƒªã‚µãƒ³ãƒ—ãƒ«ã¨ã‚µãƒãƒ¼ãƒˆã‚»ãƒƒãƒˆã®å„ã‚µãƒ³ãƒ—ãƒ«é–“ã§Attentionæ©Ÿæ§‹ã‚’ä½¿ç”¨ã—ã€åŠ é‡å¹³å‡ã§ã‚¯ãƒ©ã‚¹ç¢ºç‡ã‚’è¨ˆç®—ã—ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ã‚µãƒãƒ¼ãƒˆã‚»ãƒƒãƒˆå…¨ä½“ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’è€ƒæ…®ã—ãŸåˆ†é¡ãŒå¯èƒ½ã«ãªã‚Šã¾ã™ã€‚</p>

<div class="mermaid">
graph TB
    subgraph Support Set
        S1[ã‚µãƒãƒ¼ãƒˆ1] --> ES1[åŸ‹ã‚è¾¼ã¿]
        S2[ã‚µãƒãƒ¼ãƒˆ2] --> ES2[åŸ‹ã‚è¾¼ã¿]
        S3[ã‚µãƒãƒ¼ãƒˆ3] --> ES3[åŸ‹ã‚è¾¼ã¿]
    end

    Q[ã‚¯ã‚¨ãƒª] --> EQ[åŸ‹ã‚è¾¼ã¿ + LSTM]

    EQ --> A1[Attention<br/>é‡ã¿1]
    EQ --> A2[Attention<br/>é‡ã¿2]
    EQ --> A3[Attention<br/>é‡ã¿3]

    ES1 --> A1
    ES2 --> A2
    ES3 --> A3

    A1 --> W[åŠ é‡å¹³å‡]
    A2 --> W
    A3 --> W

    W --> P[äºˆæ¸¬]

    style EQ fill:#9d4edd
    style W fill:#3182ce
</div>

<h3>3.2 Full Context Embeddings</h3>

<p>Matching Networksã®é‡è¦ãªç‰¹å¾´ã¯ã€ã‚µãƒãƒ¼ãƒˆã‚»ãƒƒãƒˆå…¨ä½“ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’è€ƒæ…®ã—ãŸåŸ‹ã‚è¾¼ã¿ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ã§ã™ã€‚ã“ã‚Œã¯LSTMãªã©ã®ç³»åˆ—ãƒ¢ãƒ‡ãƒ«ã§å®Ÿç¾ã•ã‚Œã¾ã™ã€‚</p>

<p><strong>Attentioné‡ã¿ã®è¨ˆç®—ï¼š</strong></p>
$$
a(x, x_i) = \frac{\exp(c(\hat{x}, \hat{x}_i))}{\sum_j \exp(c(\hat{x}, \hat{x}_j))}
$$

<p><strong>äºˆæ¸¬åˆ†å¸ƒï¼š</strong></p>
$$
P(y|x, S) = \sum_{i=1}^k a(x, x_i) y_i
$$

<h3>3.3 å®Ÿè£…ã¨è©•ä¾¡</h3>

<pre><code class="language-python">import torch
import torch.nn as nn
import torch.nn.functional as F

class MatchingNetwork(nn.Module):
    """Matching Networkå®Ÿè£…"""

    def __init__(self, input_channels=3, hidden_dim=64, lstm_layers=1):
        super(MatchingNetwork, self).__init__()

        # ç‰¹å¾´æŠ½å‡ºå™¨ï¼ˆCNNã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ï¼‰
        self.encoder = nn.Sequential(
            self._conv_block(input_channels, hidden_dim),
            self._conv_block(hidden_dim, hidden_dim),
            self._conv_block(hidden_dim, hidden_dim),
            self._conv_block(hidden_dim, hidden_dim),
        )

        # åŸ‹ã‚è¾¼ã¿æ¬¡å…ƒã‚’è¨ˆç®—
        self.embedding_dim = hidden_dim * 5 * 5

        # Full Context Embeddingsç”¨ã®LSTM
        self.lstm = nn.LSTM(
            input_size=self.embedding_dim,
            hidden_size=self.embedding_dim,
            num_layers=lstm_layers,
            bidirectional=True,
            batch_first=True
        )

        # åŒæ–¹å‘LSTMã®å‡ºåŠ›ã‚’å…ƒã®æ¬¡å…ƒã«å¤‰æ›
        self.fc = nn.Linear(self.embedding_dim * 2, self.embedding_dim)

    def _conv_block(self, in_channels, out_channels):
        """CNNãƒ–ãƒ­ãƒƒã‚¯"""
        return nn.Sequential(
            nn.Conv2d(in_channels, out_channels, 3, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2)
        )

    def encode(self, x):
        """ç”»åƒã‚’åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã«å¤‰æ›"""
        batch_size = x.size(0)
        x = self.encoder(x)
        x = x.view(batch_size, -1)
        return x

    def full_context_embeddings(self, embeddings):
        """
        LSTMã§ã‚µãƒãƒ¼ãƒˆã‚»ãƒƒãƒˆå…¨ä½“ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’è€ƒæ…®
        Args:
            embeddings: (batch_size, seq_len, embedding_dim)
        """
        output, _ = self.lstm(embeddings)
        output = self.fc(output)
        return output

    def attention(self, query_emb, support_emb):
        """
        Attentioné‡ã¿ã‚’è¨ˆç®—
        Args:
            query_emb: (n_query, embedding_dim)
            support_emb: (n_support, embedding_dim)
        Returns:
            attention_weights: (n_query, n_support)
        """
        # ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã‚’è¨ˆç®—
        query_norm = F.normalize(query_emb, p=2, dim=1)
        support_norm = F.normalize(support_emb, p=2, dim=1)

        similarities = torch.mm(query_norm, support_norm.t())

        # Softmaxã§attentioné‡ã¿ã«å¤‰æ›
        attention_weights = F.softmax(similarities, dim=1)
        return attention_weights

    def forward(self, support_images, support_labels, query_images, n_way):
        """
        Args:
            support_images: (n_way * k_shot, C, H, W)
            support_labels: (n_way * k_shot,) one-hot encoded
            query_images: (n_query, C, H, W)
        """
        # åŸ‹ã‚è¾¼ã¿ã‚’è¨ˆç®—
        support_emb = self.encode(support_images)  # (n_support, emb_dim)
        query_emb = self.encode(query_images)      # (n_query, emb_dim)

        # Full Context Embeddingsï¼ˆã‚µãƒãƒ¼ãƒˆã‚»ãƒƒãƒˆã®ã¿ï¼‰
        support_emb_context = self.full_context_embeddings(
            support_emb.unsqueeze(0)  # (1, n_support, emb_dim)
        ).squeeze(0)  # (n_support, emb_dim)

        # Attentioné‡ã¿ã‚’è¨ˆç®—
        attention_weights = self.attention(query_emb, support_emb_context)

        # One-hotãƒ©ãƒ™ãƒ«ã«å¤‰æ›
        support_labels_one_hot = F.one_hot(support_labels, n_way).float()

        # Attentioné‡ã¿ä»˜ãäºˆæ¸¬
        predictions = torch.mm(attention_weights, support_labels_one_hot)

        return predictions

# å­¦ç¿’é–¢æ•°
def train_matching(model, train_loader, num_epochs=100, n_way=5):
    """Matching Networkã®å­¦ç¿’"""
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = model.to(device)

    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
    criterion = nn.CrossEntropyLoss()

    for epoch in range(num_epochs):
        model.train()
        total_loss = 0
        total_acc = 0

        for batch_idx, (support_imgs, support_labels, query_imgs, query_labels) in enumerate(train_loader):
            support_imgs = support_imgs.to(device)
            support_labels = support_labels.to(device)
            query_imgs = query_imgs.to(device)
            query_labels = query_labels.to(device)

            # Forward
            predictions = model(support_imgs, support_labels, query_imgs, n_way)
            loss = criterion(predictions, query_labels)

            # ç²¾åº¦è¨ˆç®—
            pred = predictions.argmax(dim=1)
            acc = (pred == query_labels).float().mean()

            # Backward
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            total_loss += loss.item()
            total_acc += acc.item()

        avg_loss = total_loss / len(train_loader)
        avg_acc = total_acc / len(train_loader)

        if (epoch + 1) % 10 == 0:
            print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}, Acc: {avg_acc:.4f}")

# ä½¿ç”¨ä¾‹
model = MatchingNetwork(input_channels=3, hidden_dim=64)
</code></pre>

<h2>4. Relation Networks</h2>

<h3>4.1 å­¦ç¿’å¯èƒ½ãªè·é›¢ãƒ¡ãƒˆãƒªãƒƒã‚¯</h3>

<p>Relation Networksã¯ã€å›ºå®šçš„ãªãƒ¦ãƒ¼ã‚¯ãƒªãƒƒãƒ‰è·é›¢ã‚„ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã®ä»£ã‚ã‚Šã«ã€å­¦ç¿’å¯èƒ½ãªãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã§é¡ä¼¼åº¦ã‚’è¨ˆç®—ã—ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ã‚¿ã‚¹ã‚¯å›ºæœ‰ã®æœ€é©ãªè·é›¢é–¢æ•°ã‚’å­¦ç¿’ã§ãã¾ã™ã€‚</p>

<div class="mermaid">
graph TB
    S[ã‚µãƒãƒ¼ãƒˆ] --> ES[ç‰¹å¾´æŠ½å‡ºå™¨]
    Q[ã‚¯ã‚¨ãƒª] --> EQ[ç‰¹å¾´æŠ½å‡ºå™¨]

    ES --> C[çµåˆ<br/>Concatenation]
    EQ --> C

    C --> R[é–¢ä¿‚ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«<br/>CNN]
    R --> SC[é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢]

    style ES fill:#9d4edd
    style EQ fill:#9d4edd
    style R fill:#3182ce
</div>

<p><strong>é–¢ä¿‚ã‚¹ã‚³ã‚¢ã®è¨ˆç®—ï¼š</strong></p>
$$
r_{i,j} = g_\phi(\text{concat}(f_\theta(x_i), f_\theta(x_j)))
$$

<p>ã“ã“ã§ï¼š</p>
<ul>
<li>$f_\theta$ ã¯ç‰¹å¾´æŠ½å‡ºå™¨</li>
<li>$g_\phi$ ã¯é–¢ä¿‚ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼ˆå­¦ç¿’å¯èƒ½ãªCNNï¼‰</li>
<li>$r_{i,j}$ ã¯ã‚µãƒ³ãƒ—ãƒ«$i$ã¨$j$ã®é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢</li>
</ul>

<h3>4.2 CNNãƒ™ãƒ¼ã‚¹ã®é–¢ä¿‚ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«</h3>

<p>é–¢ä¿‚ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¯ã€çµåˆã•ã‚ŒãŸç‰¹å¾´ãƒ™ã‚¯ãƒˆãƒ«ã‹ã‚‰é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢ã‚’å‡ºåŠ›ã™ã‚‹ç•³ã¿è¾¼ã¿ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã§ã™ã€‚</p>

<h3>4.3 å®Ÿè£…ä¾‹</h3>

<pre><code class="language-python">import torch
import torch.nn as nn
import torch.nn.functional as F

class RelationNetwork(nn.Module):
    """Relation Networkå®Ÿè£…"""

    def __init__(self, input_channels=3, feature_dim=64):
        super(RelationNetwork, self).__init__()

        # ç‰¹å¾´æŠ½å‡ºå™¨ï¼ˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ï¼‰
        self.encoder = nn.Sequential(
            self._conv_block(input_channels, feature_dim),
            self._conv_block(feature_dim, feature_dim),
            self._conv_block(feature_dim, feature_dim),
            self._conv_block(feature_dim, feature_dim),
        )

        # é–¢ä¿‚ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼ˆçµåˆã•ã‚ŒãŸç‰¹å¾´ã‹ã‚‰é¡ä¼¼åº¦ã‚’è¨ˆç®—ï¼‰
        self.relation_module = nn.Sequential(
            self._conv_block(feature_dim * 2, feature_dim),
            self._conv_block(feature_dim, feature_dim),
            nn.Flatten(),
            nn.Linear(feature_dim * 5 * 5, 256),
            nn.ReLU(inplace=True),
            nn.Linear(256, 1),
            nn.Sigmoid()  # é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢ã‚’[0, 1]ã«æ­£è¦åŒ–
        )

    def _conv_block(self, in_channels, out_channels):
        """CNNãƒ–ãƒ­ãƒƒã‚¯"""
        return nn.Sequential(
            nn.Conv2d(in_channels, out_channels, 3, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2)
        )

    def forward(self, support_images, query_images, n_way, k_shot):
        """
        Args:
            support_images: (n_way * k_shot, C, H, W)
            query_images: (n_query, C, H, W)
        """
        # ç‰¹å¾´æŠ½å‡º
        support_features = self.encoder(support_images)  # (n_support, D, H, W)
        query_features = self.encoder(query_images)      # (n_query, D, H, W)

        n_support = support_features.size(0)
        n_query = query_features.size(0)
        D, H, W = support_features.size(1), support_features.size(2), support_features.size(3)

        # ã‚µãƒãƒ¼ãƒˆã‚»ãƒƒãƒˆã®ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ã‚’è¨ˆç®—ï¼ˆå„ã‚¯ãƒ©ã‚¹ã®å¹³å‡ï¼‰
        support_features_proto = support_features.view(n_way, k_shot, D, H, W).mean(dim=1)

        # ã‚¯ã‚¨ãƒªã¨ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ã®ãƒšã‚¢ã‚’ä½œæˆ
        # ã‚¯ã‚¨ãƒªç‰¹å¾´ã‚’æ‹¡å¼µ: (n_query, n_way, D, H, W)
        query_features_ext = query_features.unsqueeze(1).repeat(1, n_way, 1, 1, 1)

        # ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ç‰¹å¾´ã‚’æ‹¡å¼µ: (n_query, n_way, D, H, W)
        support_features_ext = support_features_proto.unsqueeze(0).repeat(n_query, 1, 1, 1, 1)

        # ç‰¹å¾´ã‚’çµåˆ
        relation_pairs = torch.cat([query_features_ext, support_features_ext], dim=2)
        relation_pairs = relation_pairs.view(-1, D * 2, H, W)

        # é–¢ä¿‚ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—
        relation_scores = self.relation_module(relation_pairs).view(n_query, n_way)

        return relation_scores

class MSELoss4RelationNetwork(nn.Module):
    """Relation Networkç”¨ã®MSE Loss"""

    def forward(self, relation_scores, labels, n_way):
        """
        Args:
            relation_scores: (n_query, n_way)
            labels: (n_query,)
        """
        # One-hotãƒ©ãƒ™ãƒ«ã‚’ä½œæˆ
        one_hot_labels = F.one_hot(labels, n_way).float()

        # MSE Loss
        loss = F.mse_loss(relation_scores, one_hot_labels)
        return loss

# å­¦ç¿’é–¢æ•°
def train_relation(model, train_loader, num_epochs=100, n_way=5, k_shot=1):
    """Relation Networkã®å­¦ç¿’"""
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = model.to(device)

    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
    criterion = MSELoss4RelationNetwork()

    for epoch in range(num_epochs):
        model.train()
        total_loss = 0
        total_acc = 0

        for batch_idx, (support_imgs, support_labels, query_imgs, query_labels) in enumerate(train_loader):
            support_imgs = support_imgs.to(device)
            query_imgs = query_imgs.to(device)
            query_labels = query_labels.to(device)

            # Forward
            relation_scores = model(support_imgs, query_imgs, n_way, k_shot)
            loss = criterion(relation_scores, query_labels, n_way)

            # ç²¾åº¦è¨ˆç®—
            pred = relation_scores.argmax(dim=1)
            acc = (pred == query_labels).float().mean()

            # Backward
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            total_loss += loss.item()
            total_acc += acc.item()

        avg_loss = total_loss / len(train_loader)
        avg_acc = total_acc / len(train_loader)

        if (epoch + 1) % 10 == 0:
            print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}, Acc: {avg_acc:.4f}")

# ä½¿ç”¨ä¾‹
model = RelationNetwork(input_channels=3, feature_dim=64)
print(f"Total parameters: {sum(p.numel() for p in model.parameters()):,}")
</code></pre>

<h2>5. å®Ÿè·µï¼šæ‰‹æ³•ã®æ¯”è¼ƒå®Ÿé¨“</h2>

<h3>5.1 miniImageNetãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ</h3>

<p>miniImageNetã¯ã€ImageNetã®ã‚µãƒ–ã‚»ãƒƒãƒˆã§ã€Few-Shotå­¦ç¿’ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¨ã—ã¦åºƒãä½¿ç”¨ã•ã‚Œã¦ã„ã¾ã™ã€‚</p>

<p><strong>ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ§‹æˆï¼š</strong></p>
<table>
<thead>
<tr>
<th>åˆ†å‰²</th>
<th>ã‚¯ãƒ©ã‚¹æ•°</th>
<th>ã‚¯ãƒ©ã‚¹ã‚ãŸã‚Šã‚µãƒ³ãƒ—ãƒ«æ•°</th>
<th>ç”¨é€”</th>
</tr>
</thead>
<tbody>
<tr>
<td>Train</td>
<td>64</td>
<td>600</td>
<td>ãƒ¡ã‚¿å­¦ç¿’ã®è¨“ç·´</td>
</tr>
<tr>
<td>Validation</td>
<td>16</td>
<td>600</td>
<td>ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´</td>
</tr>
<tr>
<td>Test</td>
<td>20</td>
<td>600</td>
<td>æœ€çµ‚æ€§èƒ½è©•ä¾¡</td>
</tr>
</tbody>
</table>

<h3>5.2 5-way 1-shot/5-shotè©•ä¾¡</h3>

<pre><code class="language-python">import torch
import numpy as np
from torch.utils.data import DataLoader

def evaluate_few_shot(model, test_loader, n_way=5, k_shot=1, n_query=15, n_episodes=600):
    """
    Few-Shotå­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡

    Args:
        model: è©•ä¾¡ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ï¼ˆPrototypical, Matching, Relationã®ã„ãšã‚Œã‹ï¼‰
        test_loader: ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼
        n_way: ã‚¯ãƒ©ã‚¹æ•°
        k_shot: ã‚µãƒãƒ¼ãƒˆã‚»ãƒƒãƒˆã®ã‚µãƒ³ãƒ—ãƒ«æ•°
        n_query: ã‚¯ã‚¨ãƒªã‚»ãƒƒãƒˆã®ã‚µãƒ³ãƒ—ãƒ«æ•°
        n_episodes: è©•ä¾¡ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰æ•°
    """
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = model.to(device)
    model.eval()

    accuracies = []

    with torch.no_grad():
        for episode in range(n_episodes):
            # ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿ã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
            support_imgs, support_labels, query_imgs, query_labels = next(iter(test_loader))

            support_imgs = support_imgs.to(device)
            support_labels = support_labels.to(device)
            query_imgs = query_imgs.to(device)
            query_labels = query_labels.to(device)

            # ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã£ã¦ç•°ãªã‚‹æ¨è«–æ–¹æ³•
            if hasattr(model, 'relation_module'):  # Relation Network
                predictions = model(support_imgs, query_imgs, n_way, k_shot)
                pred_labels = predictions.argmax(dim=1)
            else:  # Prototypical or Matching Network
                logits = model(support_imgs, support_labels, query_imgs, n_way, k_shot)
                pred_labels = logits.argmax(dim=1)

            # ç²¾åº¦è¨ˆç®—
            acc = (pred_labels == query_labels).float().mean().item()
            accuracies.append(acc)

            if (episode + 1) % 100 == 0:
                current_avg = np.mean(accuracies)
                current_std = np.std(accuracies)
                print(f"Episode [{episode+1}/{n_episodes}], "
                      f"Acc: {current_avg:.4f} Â± {1.96 * current_std / np.sqrt(len(accuracies)):.4f}")

    # æœ€çµ‚çµæœï¼ˆ95%ä¿¡é ¼åŒºé–“ï¼‰
    mean_acc = np.mean(accuracies)
    std_acc = np.std(accuracies)
    confidence_interval = 1.96 * std_acc / np.sqrt(n_episodes)

    return mean_acc, confidence_interval

# ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼è¨­å®šã®ä¾‹
class FewShotDataLoader:
    """Few-Shotå­¦ç¿’ç”¨ã®ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼"""

    def __init__(self, dataset, n_way=5, k_shot=1, n_query=15):
        self.dataset = dataset
        self.n_way = n_way
        self.k_shot = k_shot
        self.n_query = n_query

    def sample_episode(self):
        """1ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰åˆ†ã®ãƒ‡ãƒ¼ã‚¿ã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°"""
        # n_wayã‚¯ãƒ©ã‚¹ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«é¸æŠ
        classes = np.random.choice(len(self.dataset.classes), self.n_way, replace=False)

        support_imgs = []
        support_labels = []
        query_imgs = []
        query_labels = []

        for i, cls in enumerate(classes):
            # ã‚¯ãƒ©ã‚¹ã‹ã‚‰k_shot + n_queryã‚µãƒ³ãƒ—ãƒ«ã‚’é¸æŠ
            cls_samples = self.dataset.get_samples_by_class(cls)
            indices = np.random.choice(len(cls_samples), self.k_shot + self.n_query, replace=False)

            # ã‚µãƒãƒ¼ãƒˆã‚»ãƒƒãƒˆ
            support_imgs.extend([cls_samples[idx] for idx in indices[:self.k_shot]])
            support_labels.extend([i] * self.k_shot)

            # ã‚¯ã‚¨ãƒªã‚»ãƒƒãƒˆ
            query_imgs.extend([cls_samples[idx] for idx in indices[self.k_shot:]])
            query_labels.extend([i] * self.n_query)

        return (torch.stack(support_imgs), torch.tensor(support_labels),
                torch.stack(query_imgs), torch.tensor(query_labels))
</code></pre>

<h3>5.3 ç²¾åº¦æ¯”è¼ƒã¨è€ƒå¯Ÿ</h3>

<pre><code class="language-python"># å„æ‰‹æ³•ã®æ¯”è¼ƒå®Ÿé¨“
import pandas as pd
import matplotlib.pyplot as plt

def compare_few_shot_methods(test_loader, n_way=5, k_shot_list=[1, 5]):
    """è¤‡æ•°ã®Few-Shotå­¦ç¿’æ‰‹æ³•ã‚’æ¯”è¼ƒ"""

    results = []

    for k_shot in k_shot_list:
        print(f"\n{'='*50}")
        print(f"{n_way}-way {k_shot}-shot evaluation")
        print(f"{'='*50}\n")

        # Prototypical Network
        print("Evaluating Prototypical Network...")
        proto_model = PrototypicalNetwork(input_channels=3, hidden_dim=64)
        proto_acc, proto_ci = evaluate_few_shot(proto_model, test_loader, n_way, k_shot)
        results.append({
            'Method': 'Prototypical',
            'Setting': f'{n_way}-way {k_shot}-shot',
            'Accuracy': proto_acc,
            'CI': proto_ci
        })
        print(f"Prototypical Network: {proto_acc:.4f} Â± {proto_ci:.4f}\n")

        # Matching Network
        print("Evaluating Matching Network...")
        match_model = MatchingNetwork(input_channels=3, hidden_dim=64)
        match_acc, match_ci = evaluate_few_shot(match_model, test_loader, n_way, k_shot)
        results.append({
            'Method': 'Matching',
            'Setting': f'{n_way}-way {k_shot}-shot',
            'Accuracy': match_acc,
            'CI': match_ci
        })
        print(f"Matching Network: {match_acc:.4f} Â± {match_ci:.4f}\n")

        # Relation Network
        print("Evaluating Relation Network...")
        relation_model = RelationNetwork(input_channels=3, feature_dim=64)
        relation_acc, relation_ci = evaluate_few_shot(relation_model, test_loader, n_way, k_shot)
        results.append({
            'Method': 'Relation',
            'Setting': f'{n_way}-way {k_shot}-shot',
            'Accuracy': relation_acc,
            'CI': relation_ci
        })
        print(f"Relation Network: {relation_acc:.4f} Â± {relation_ci:.4f}\n")

    return pd.DataFrame(results)

# çµæœã®å¯è¦–åŒ–
def plot_comparison(results_df):
    """æ¯”è¼ƒçµæœã‚’å¯è¦–åŒ–"""
    fig, ax = plt.subplots(figsize=(10, 6))

    # 1-shotã¨5-shotã§åˆ†é›¢
    settings = results_df['Setting'].unique()
    x = np.arange(len(results_df['Method'].unique()))
    width = 0.35

    for i, setting in enumerate(settings):
        data = results_df[results_df['Setting'] == setting]
        accuracies = data['Accuracy'].values
        cis = data['CI'].values

        ax.bar(x + i * width, accuracies, width,
               yerr=cis, label=setting, capsize=5)

    ax.set_xlabel('Method')
    ax.set_ylabel('Accuracy')
    ax.set_title('Few-Shot Learning Methods Comparison on miniImageNet')
    ax.set_xticks(x + width / 2)
    ax.set_xticklabels(results_df['Method'].unique())
    ax.legend()
    ax.grid(axis='y', alpha=0.3)

    plt.tight_layout()
    plt.savefig('few_shot_comparison.png', dpi=300, bbox_inches='tight')
    plt.show()

# å®Ÿè¡Œä¾‹
# results_df = compare_few_shot_methods(test_loader, n_way=5, k_shot_list=[1, 5])
# plot_comparison(results_df)
</code></pre>

<p><strong>å…¸å‹çš„ãªçµæœï¼ˆminiImageNetï¼‰ï¼š</strong></p>

<table>
<thead>
<tr>
<th>æ‰‹æ³•</th>
<th>5-way 1-shot</th>
<th>5-way 5-shot</th>
<th>ä¸»ãªç‰¹å¾´</th>
</tr>
</thead>
<tbody>
<tr>
<td>Prototypical Networks</td>
<td>49.42% Â± 0.78%</td>
<td>68.20% Â± 0.66%</td>
<td>ã‚·ãƒ³ãƒ—ãƒ«ã§åŠ¹ç‡çš„</td>
</tr>
<tr>
<td>Matching Networks</td>
<td>46.60% Â± 0.78%</td>
<td>60.00% Â± 0.71%</td>
<td>Attentionæ©Ÿæ§‹</td>
</tr>
<tr>
<td>Relation Networks</td>
<td>50.44% Â± 0.82%</td>
<td>65.32% Â± 0.70%</td>
<td>å­¦ç¿’å¯èƒ½ãªè·é›¢</td>
</tr>
</tbody>
</table>

<h3>5.4 è€ƒå¯Ÿã¨æ‰‹æ³•é¸æŠã®ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³</h3>

<p><strong>Prototypical Networks</strong></p>
<ul>
<li><strong>é•·æ‰€ï¼š</strong> å®Ÿè£…ãŒã‚·ãƒ³ãƒ—ãƒ«ã€è¨ˆç®—åŠ¹ç‡ãŒè‰¯ã„ã€å¤šãã®ã‚¿ã‚¹ã‚¯ã§é«˜ç²¾åº¦</li>
<li><strong>çŸ­æ‰€ï¼š</strong> å›ºå®šçš„ãªãƒ¦ãƒ¼ã‚¯ãƒªãƒƒãƒ‰è·é›¢ã«ä¾å­˜</li>
<li><strong>æ¨å¥¨ç”¨é€”ï¼š</strong> ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ‰‹æ³•ã¨ã—ã¦ã€ãƒªã‚½ãƒ¼ã‚¹ãŒé™ã‚‰ã‚ŒãŸç’°å¢ƒ</li>
</ul>

<p><strong>Matching Networks</strong></p>
<ul>
<li><strong>é•·æ‰€ï¼š</strong> Attentionæ©Ÿæ§‹ã§ã‚µãƒãƒ¼ãƒˆã‚»ãƒƒãƒˆå…¨ä½“ã‚’è€ƒæ…®</li>
<li><strong>çŸ­æ‰€ï¼š</strong> LSTMã«ã‚ˆã‚‹è¨ˆç®—ã‚³ã‚¹ãƒˆãŒé«˜ã„</li>
<li><strong>æ¨å¥¨ç”¨é€”ï¼š</strong> ã‚µãƒãƒ¼ãƒˆã‚»ãƒƒãƒˆé–“ã®é–¢ä¿‚æ€§ãŒé‡è¦ãªã‚¿ã‚¹ã‚¯</li>
</ul>

<p><strong>Relation Networks</strong></p>
<ul>
<li><strong>é•·æ‰€ï¼š</strong> ã‚¿ã‚¹ã‚¯å›ºæœ‰ã®æœ€é©ãªè·é›¢é–¢æ•°ã‚’å­¦ç¿’å¯èƒ½</li>
<li><strong>çŸ­æ‰€ï¼š</strong> ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ãŒå¤šãã€å­¦ç¿’ã«æ™‚é–“ãŒã‹ã‹ã‚‹</li>
<li><strong>æ¨å¥¨ç”¨é€”ï¼š</strong> è¤‡é›‘ãªé¡ä¼¼åº¦ãŒå¿…è¦ãªã‚¿ã‚¹ã‚¯ã€ååˆ†ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆ</li>
</ul>

<blockquote>
<p><strong>å®Ÿè·µçš„ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹ï¼š</strong> æ–°ã—ã„ã‚¿ã‚¹ã‚¯ã§ã¯ã€ã¾ãšPrototypical Networksã‚’ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã¨ã—ã¦è©¦ã—ã€æ€§èƒ½ãŒä¸ååˆ†ãªå ´åˆã«Relation Networksã‚’æ¤œè¨ã™ã‚‹ã®ãŒåŠ¹ç‡çš„ã§ã™ã€‚</p>
</blockquote>

<h2>æ¼”ç¿’å•é¡Œ</h2>

<details>
<summary><strong>æ¼”ç¿’1ï¼šSiamese Networkã®æ”¹è‰¯</strong></summary>
<p>æä¾›ã•ã‚ŒãŸSiamese Networkã«Triplet Lossã‚’å®Ÿè£…ã—ã€Contrastive Lossã¨ã®æ€§èƒ½ã‚’æ¯”è¼ƒã—ã¦ãã ã•ã„ã€‚Triplet Lossã¯ã€ã‚¢ãƒ³ã‚«ãƒ¼ã€ãƒã‚¸ãƒ†ã‚£ãƒ–ã€ãƒã‚¬ãƒ†ã‚£ãƒ–ã®3ã¤ã®ã‚µãƒ³ãƒ—ãƒ«ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚</p>

<pre><code class="language-python">class TripletLoss(nn.Module):
    def __init__(self, margin=1.0):
        super(TripletLoss, self).__init__()
        self.margin = margin

    def forward(self, anchor, positive, negative):
        # TODO: Triplet Lossã‚’å®Ÿè£…
        # ãƒ’ãƒ³ãƒˆ: L = max(0, d(a,p) - d(a,n) + margin)
        pass
</code></pre>
</details>

<details>
<summary><strong>æ¼”ç¿’2ï¼šPrototypical Networksã®æ‹¡å¼µ</strong></summary>
<p>Prototypical Networksã‚’æ‹¡å¼µã—ã€å„ã‚¯ãƒ©ã‚¹ã®ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ã‚’å˜ç´”ãªå¹³å‡ã§ã¯ãªãã€Attentionæ©Ÿæ§‹ã‚’ä½¿ã£ãŸåŠ é‡å¹³å‡ã§è¨ˆç®—ã—ã¦ãã ã•ã„ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒã‚¤ã‚ºã®å¤šã„ã‚µãƒ³ãƒ—ãƒ«ã®å½±éŸ¿ã‚’æ¸›ã‚‰ã›ã¾ã™ã€‚</p>

<pre><code class="language-python">def compute_prototypes_with_attention(self, embeddings, labels, n_way):
    """Attentionæ©Ÿæ§‹ã‚’ä½¿ã£ãŸãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—è¨ˆç®—"""
    # TODO: å®Ÿè£…
    # ãƒ’ãƒ³ãƒˆ: ã‚µãƒ³ãƒ—ãƒ«é–“ã®é¡ä¼¼åº¦ã«åŸºã¥ã„ã¦attentioné‡ã¿ã‚’è¨ˆç®—
    pass
</code></pre>
</details>

<details>
<summary><strong>æ¼”ç¿’3ï¼šãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«Few-Shotå­¦ç¿’</strong></summary>
<p>ç”»åƒã¨ãƒ†ã‚­ã‚¹ãƒˆã®ä¸¡æ–¹ã‚’å…¥åŠ›ã¨ã™ã‚‹ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«Prototypical Networkã‚’è¨­è¨ˆã—ã¦ãã ã•ã„ã€‚ç”»åƒã«ã¯CNNã€ãƒ†ã‚­ã‚¹ãƒˆã«ã¯Transformerã‚’ä½¿ç”¨ã—ã€ä¸¡æ–¹ã®åŸ‹ã‚è¾¼ã¿ã‚’çµåˆã—ã¾ã™ã€‚</p>

<pre><code class="language-python">class MultimodalPrototypicalNetwork(nn.Module):
    def __init__(self):
        super().__init__()
        # TODO: ç”»åƒã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã¨ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã‚’å®šç¾©
        pass

    def forward(self, images, texts):
        # TODO: ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«åŸ‹ã‚è¾¼ã¿ã‚’è¨ˆç®—
        pass
</code></pre>
</details>

<details>
<summary><strong>æ¼”ç¿’4ï¼šFew-Shotå­¦ç¿’ã®å®Ÿã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³</strong></summary>
<p>åŒ»ç™‚ç”»åƒè¨ºæ–­ã®ã‚·ãƒŠãƒªã‚ªã‚’æƒ³å®šã—ã€é™ã‚‰ã‚ŒãŸç—‡ä¾‹ç”»åƒï¼ˆå„ç–¾æ‚£5æšç¨‹åº¦ï¼‰ã‹ã‚‰æ–°ã—ã„ç–¾æ‚£ã‚’åˆ†é¡ã™ã‚‹ã‚·ã‚¹ãƒ†ãƒ ã‚’è¨­è¨ˆã—ã¦ãã ã•ã„ã€‚ã©ã®æ‰‹æ³•ãŒæœ€é©ã‹ã€ãã®ç†ç”±ã¨ã¨ã‚‚ã«èª¬æ˜ã—ã¦ãã ã•ã„ã€‚ã¾ãŸã€ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã‚„ãƒ‰ãƒ¡ã‚¤ãƒ³é©å¿œã®æˆ¦ç•¥ã‚‚è€ƒãˆã¦ãã ã•ã„ã€‚</p>
</details>

<h2>ã¾ã¨ã‚</h2>

<p>ã“ã®ç« ã§ã¯ã€Few-Shotå­¦ç¿’ã®ä¸»è¦ãªæ‰‹æ³•ã«ã¤ã„ã¦å­¦ã³ã¾ã—ãŸï¼š</p>

<ul>
<li><strong>Siamese Networksï¼š</strong> ãƒšã‚¢å­¦ç¿’ã¨Contrastive Lossã«ã‚ˆã‚‹é¡ä¼¼åº¦å­¦ç¿’ã®åŸºç¤</li>
<li><strong>Prototypical Networksï¼š</strong> ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ãƒ™ãƒ¼ã‚¹ã®ã‚·ãƒ³ãƒ—ãƒ«ã§åŠ¹æœçš„ãªåˆ†é¡</li>
<li><strong>Matching Networksï¼š</strong> Attentionæ©Ÿæ§‹ã«ã‚ˆã‚‹ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆè€ƒæ…®å‹åˆ†é¡</li>
<li><strong>Relation Networksï¼š</strong> å­¦ç¿’å¯èƒ½ãªè·é›¢ãƒ¡ãƒˆãƒªãƒƒã‚¯ã«ã‚ˆã‚‹æŸ”è»Ÿãªé¡ä¼¼åº¦è¨ˆç®—</li>
</ul>

<p>ã“ã‚Œã‚‰ã®æ‰‹æ³•ã¯ã€ãã‚Œãã‚Œç•°ãªã‚‹å¼·ã¿ã‚’æŒã¡ã€ã‚¿ã‚¹ã‚¯ã‚„ãƒªã‚½ãƒ¼ã‚¹ã«å¿œã˜ã¦é¸æŠã§ãã¾ã™ã€‚æ¬¡ç« ã§ã¯ã€ã“ã‚Œã‚‰ã®æ‰‹æ³•ã‚’ã‚ˆã‚Šé«˜åº¦ãªæœ€é©åŒ–ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ï¼ˆMAMLç­‰ï¼‰ã¨çµ„ã¿åˆã‚ã›ã‚‹æ–¹æ³•ã‚’å­¦ã³ã¾ã™ã€‚</p>

<div class="navigation">
    <a href="chapter2-maml.html" class="nav-button">â† ç¬¬2ç« ï¼šMAML</a>
    <a href="chapter4-transfer-learning.html" class="nav-button">ç¬¬4ç« ï¼šå¿œç”¨ãƒ¡ã‚¿å­¦ç¿’ â†’</a>
</div>

</main>


    <section class="disclaimer">
        <h3>å…è²¬äº‹é …</h3>
        <ul>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯æ•™è‚²ãƒ»ç ”ç©¶ãƒ»æƒ…å ±æä¾›ã®ã¿ã‚’ç›®çš„ã¨ã—ã¦ãŠã‚Šã€å°‚é–€çš„ãªåŠ©è¨€(æ³•å¾‹ãƒ»ä¼šè¨ˆãƒ»æŠ€è¡“çš„ä¿è¨¼ãªã©)ã‚’æä¾›ã™ã‚‹ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŠã‚ˆã³ä»˜éšã™ã‚‹ã‚³ãƒ¼ãƒ‰ä¾‹ã¯ã€Œç¾çŠ¶æœ‰å§¿(AS IS)ã€ã§æä¾›ã•ã‚Œã€æ˜ç¤ºã¾ãŸã¯é»™ç¤ºã‚’å•ã‚ãšã€å•†å“æ€§ã€ç‰¹å®šç›®çš„é©åˆæ€§ã€æ¨©åˆ©éä¾µå®³ã€æ­£ç¢ºæ€§ãƒ»å®Œå…¨æ€§ã€å‹•ä½œãƒ»å®‰å…¨æ€§ç­‰ã„ã‹ãªã‚‹ä¿è¨¼ã‚‚ã—ã¾ã›ã‚“ã€‚</li>
            <li>å¤–éƒ¨ãƒªãƒ³ã‚¯ã€ç¬¬ä¸‰è€…ãŒæä¾›ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ»ãƒ„ãƒ¼ãƒ«ãƒ»ãƒ©ã‚¤ãƒ–ãƒ©ãƒªç­‰ã®å†…å®¹ãƒ»å¯ç”¨æ€§ãƒ»å®‰å…¨æ€§ã«ã¤ã„ã¦ã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯ä¸€åˆ‡ã®è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®åˆ©ç”¨ãƒ»å®Ÿè¡Œãƒ»è§£é‡ˆã«ã‚ˆã‚Šç›´æ¥çš„ãƒ»é–“æ¥çš„ãƒ»ä»˜éšçš„ãƒ»ç‰¹åˆ¥ãƒ»çµæœçš„ãƒ»æ‡²ç½°çš„æå®³ãŒç”Ÿã˜ãŸå ´åˆã§ã‚‚ã€é©ç”¨æ³•ã§è¨±å®¹ã•ã‚Œã‚‹æœ€å¤§é™ã®ç¯„å›²ã§ã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å†…å®¹ã¯ã€äºˆå‘Šãªãå¤‰æ›´ãƒ»æ›´æ–°ãƒ»æä¾›åœæ­¢ã•ã‚Œã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®è‘—ä½œæ¨©ãƒ»ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯æ˜è¨˜ã•ã‚ŒãŸæ¡ä»¶(ä¾‹: CC BY 4.0)ã«å¾“ã„ã¾ã™ã€‚å½“è©²ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯é€šå¸¸ã€ç„¡ä¿è¨¼æ¡é …ã‚’å«ã¿ã¾ã™ã€‚</li>
        </ul>
    </section>

<footer>
    <p>&copy; 2024 AI Terakoya. All rights reserved.</p>
</footer>

</body>
</html>
