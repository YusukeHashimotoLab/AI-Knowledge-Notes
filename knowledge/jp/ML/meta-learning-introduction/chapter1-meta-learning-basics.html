<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
<meta content="ç¬¬1ç« ï¼šãƒ¡ã‚¿å­¦ç¿’ã®åŸºç¤ - AI Terakoya" name="description"/>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ç¬¬1ç« ï¼šãƒ¡ã‚¿å­¦ç¿’ã®åŸºç¤ - AI Terakoya</title>

    <style>
        :root {
            --color-primary: #2c3e50;
            --color-primary-dark: #1a252f;
            --color-accent: #7b2cbf;
            --color-accent-light: #9d4edd;
            --color-text: #2d3748;
            --color-text-light: #4a5568;
            --color-bg: #ffffff;
            --color-bg-alt: #f7fafc;
            --color-border: #e2e8f0;
            --color-code-bg: #f8f9fa;
            --color-link: #3182ce;
            --color-link-hover: #2c5aa0;

            --spacing-xs: 0.5rem;
            --spacing-sm: 1rem;
            --spacing-md: 1.5rem;
            --spacing-lg: 2rem;
            --spacing-xl: 3rem;

            --font-body: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            --font-mono: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;

            --border-radius: 8px;
            --box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: var(--font-body);
            line-height: 1.7;
            color: var(--color-text);
            background-color: var(--color-bg);
            font-size: 16px;
        }

        header {
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            padding: var(--spacing-xl) var(--spacing-md);
            margin-bottom: var(--spacing-xl);
            box-shadow: var(--box-shadow);
        }

        .header-content {
            max-width: 900px;
            margin: 0 auto;
        }

        h1 {
            font-size: 2rem;
            font-weight: 700;
            margin-bottom: var(--spacing-sm);
            line-height: 1.2;
        }

        .subtitle {
            font-size: 1.1rem;
            opacity: 0.95;
            font-weight: 400;
            margin-bottom: var(--spacing-md);
        }

        .meta {
            display: flex;
            flex-wrap: wrap;
            gap: var(--spacing-md);
            font-size: 0.9rem;
            opacity: 0.9;
        }

        .meta-item {
            display: flex;
            align-items: center;
            gap: 0.3rem;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 0 var(--spacing-md) var(--spacing-xl);
        }

        h2 {
            font-size: 1.75rem;
            color: var(--color-primary);
            margin-top: var(--spacing-xl);
            margin-bottom: var(--spacing-md);
            padding-bottom: var(--spacing-xs);
            border-bottom: 3px solid var(--color-accent);
        }

        h3 {
            font-size: 1.4rem;
            color: var(--color-primary);
            margin-top: var(--spacing-lg);
            margin-bottom: var(--spacing-sm);
        }

        h4 {
            font-size: 1.1rem;
            color: var(--color-primary-dark);
            margin-top: var(--spacing-md);
            margin-bottom: var(--spacing-sm);
        }

        p {
            margin-bottom: var(--spacing-md);
            color: var(--color-text);
        }

        a {
            color: var(--color-link);
            text-decoration: none;
            transition: color 0.2s;
        }

        a:hover {
            color: var(--color-link-hover);
            text-decoration: underline;
        }

        ul, ol {
            margin-left: var(--spacing-lg);
            margin-bottom: var(--spacing-md);
        }

        li {
            margin-bottom: var(--spacing-xs);
            color: var(--color-text);
        }

        pre {
            background-color: var(--color-code-bg);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            overflow-x: auto;
            margin-bottom: var(--spacing-md);
            font-family: var(--font-mono);
            font-size: 0.9rem;
            line-height: 1.5;
        }

        code {
            font-family: var(--font-mono);
            font-size: 0.9em;
            background-color: var(--color-code-bg);
            padding: 0.2em 0.4em;
            border-radius: 3px;
        }

        pre code {
            background-color: transparent;
            padding: 0;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: var(--spacing-md);
            font-size: 0.95rem;
        }

        th, td {
            border: 1px solid var(--color-border);
            padding: var(--spacing-sm);
            text-align: left;
        }

        th {
            background-color: var(--color-bg-alt);
            font-weight: 600;
            color: var(--color-primary);
        }

        blockquote {
            border-left: 4px solid var(--color-accent);
            padding-left: var(--spacing-md);
            margin: var(--spacing-md) 0;
            color: var(--color-text-light);
            font-style: italic;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        .mermaid {
            text-align: center;
            margin: var(--spacing-lg) 0;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        details {
            background-color: var(--color-bg-alt);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            margin-bottom: var(--spacing-md);
        }

        summary {
            cursor: pointer;
            font-weight: 600;
            color: var(--color-primary);
            user-select: none;
            padding: var(--spacing-xs);
            margin: calc(-1 * var(--spacing-md));
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        summary:hover {
            background-color: rgba(123, 44, 191, 0.1);
        }

        details[open] summary {
            margin-bottom: var(--spacing-md);
            border-bottom: 1px solid var(--color-border);
        }

        .navigation {
            display: flex;
            justify-content: space-between;
            gap: var(--spacing-md);
            margin: var(--spacing-xl) 0;
            padding-top: var(--spacing-lg);
            border-top: 2px solid var(--color-border);
        }

        .nav-button {
            flex: 1;
            padding: var(--spacing-md);
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            border-radius: var(--border-radius);
            text-align: center;
            font-weight: 600;
            transition: transform 0.2s, box-shadow 0.2s;
            box-shadow: var(--box-shadow);
        }

        .nav-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
            text-decoration: none;
        }

        footer {
            margin-top: var(--spacing-xl);
            padding: var(--spacing-lg) var(--spacing-md);
            background-color: var(--color-bg-alt);
            border-top: 1px solid var(--color-border);
            text-align: center;
            font-size: 0.9rem;
            color: var(--color-text-light);
        }
        .disclaimer {
            max-width: 900px;
            margin: 2rem auto;
            padding: 1.5rem;
            background: #f8f9fa;
            border-left: 4px solid #6c757d;
            border-radius: 4px;
        }

        .disclaimer h3 {
            color: #495057;
            margin-bottom: 1rem;
            font-size: 1.1rem;
        }

        .disclaimer ul {
            list-style: none;
            padding-left: 0;
        }

        .disclaimer li {
            padding: 0.5rem 0;
            padding-left: 1.5rem;
            position: relative;
            font-size: 0.9rem;
            color: #6c757d;
            line-height: 1.6;
        }

        .disclaimer li::before {
            content: "âš ï¸";
            position: absolute;
            left: 0;
        }


        @media (max-width: 768px) {
            h1 {
                font-size: 1.5rem;
            }

            h2 {
                font-size: 1.4rem;
            }

            h3 {
                font-size: 1.2rem;
            }

            .meta {
                font-size: 0.85rem;
            }

            .navigation {
                flex-direction: column;
            }

            table {
                font-size: 0.85rem;
            }

            th, td {
                padding: var(--spacing-xs);
            }
        }
    
        
    
        /* Breadcrumb styles */
        .breadcrumb {
            background: #f7fafc;
            padding: 0.75rem 1rem;
            border-bottom: 1px solid #e2e8f0;
            font-size: 0.9rem;
        }

        .breadcrumb-content {
            max-width: 900px;
            margin: 0 auto;
            display: flex;
            align-items: center;
            flex-wrap: wrap;
            gap: 0.5rem;
        }

        .breadcrumb a {
            color: #667eea;
            text-decoration: none;
            transition: color 0.2s;
        }

        .breadcrumb a:hover {
            color: #764ba2;
            text-decoration: underline;
        }

        .breadcrumb-separator {
            color: #a0aec0;
            margin: 0 0.25rem;
        }

        .breadcrumb-current {
            color: #4a5568;
            font-weight: 500;
        }
    </style>

    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
        mermaid.initialize({ startOnLoad: true, theme: 'default' });
    </script>

    <!-- MathJax for LaTeX equation rendering -->
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                displayMath: [['$$', '$$'], ['\\[', '\\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
                ignoreHtmlClass: 'mermaid'
            }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" async></script>

    <style>
        /* Locale Switcher Styles */
        .locale-switcher {
            display: flex;
            align-items: center;
            gap: 0.5rem;
            padding: 0.5rem 1rem;
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
            border-radius: 6px;
            font-size: 0.9rem;
            margin-bottom: 1rem;
            box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);
        }

        .current-locale {
            font-weight: 600;
            color: #7b2cbf;
            display: flex;
            align-items: center;
            gap: 0.25rem;
        }

        .locale-separator {
            color: #adb5bd;
            font-weight: 300;
        }

        .locale-link {
            color: #f093fb;
            text-decoration: none;
            font-weight: 500;
            transition: all 0.2s ease;
            display: flex;
            align-items: center;
            gap: 0.25rem;
            padding: 0.2rem 0.5rem;
            border-radius: 4px;
        }

        .locale-link:hover {
            background: rgba(240, 147, 251, 0.1);
            color: #d07be8;
            transform: translateY(-1px);
        }

        .locale-meta {
            color: #868e96;
            font-size: 0.85rem;
            font-style: italic;
            margin-left: auto;
        }

        @media (max-width: 768px) {
            .locale-switcher {
                font-size: 0.85rem;
                padding: 0.4rem 0.8rem;
            }
            .locale-meta {
                display: none;
            }
        }
    </style>
</head>
<body>
            <div class="locale-switcher">
<span class="current-locale">ğŸŒ JP</span>
<span class="locale-separator">|</span>
<a href="../../../en/ML/meta-learning-introduction/chapter1-meta-learning-basics.html" class="locale-link">ğŸ‡¬ğŸ‡§ EN</a>
<span class="locale-separator">|</span>
<span class="locale-meta">Last sync: 2025-11-16</span>
</div>
<nav class="breadcrumb">
        <div class="breadcrumb-content">
            <a href="../../index.html">AIå¯ºå­å±‹ãƒˆãƒƒãƒ—</a><span class="breadcrumb-separator">â€º</span><a href="../../ML/index.html">æ©Ÿæ¢°å­¦ç¿’</a><span class="breadcrumb-separator">â€º</span><a href="../../ML/meta-learning-introduction/index.html">Meta Learning</a><span class="breadcrumb-separator">â€º</span><span class="breadcrumb-current">Chapter 1</span>
        </div>
    </nav>

        <header>
        <div class="header-content">
            <h1>ç¬¬1ç« ï¼šãƒ¡ã‚¿å­¦ç¿’ã®åŸºç¤</h1>
            <p class="subtitle">Learning to Learn - å°‘æ•°ã‚µãƒ³ãƒ—ãƒ«ã‹ã‚‰å­¦ã¶æ–°ã—ã„ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ </p>
            <div class="meta">
                <span class="meta-item">ğŸ“– èª­äº†æ™‚é–“: 25-30åˆ†</span>
                <span class="meta-item">ğŸ“Š é›£æ˜“åº¦: åˆç´šã€œä¸­ç´š</span>
                <span class="meta-item">ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹: 7å€‹</span>
                <span class="meta-item">ğŸ“ æ¼”ç¿’å•é¡Œ: 5å•</span>
            </div>
        </div>
    </header>

    <main class="container">

<h2>å­¦ç¿’ç›®æ¨™</h2>
<p>ã“ã®ç« ã‚’èª­ã‚€ã“ã¨ã§ã€ä»¥ä¸‹ã‚’ç¿’å¾—ã§ãã¾ã™ï¼š</p>
<ul>
<li>âœ… ãƒ¡ã‚¿å­¦ç¿’ï¼ˆLearning to Learnï¼‰ã®æ¦‚å¿µã¨é€šå¸¸ã®å­¦ç¿’ã¨ã®é•ã„ã‚’ç†è§£ã™ã‚‹</li>
<li>âœ… Few-Shot Learningã®å•é¡Œè¨­å®šã¨N-way K-shotåˆ†é¡ã‚’èª¬æ˜ã§ãã‚‹</li>
<li>âœ… Support Setã¨Query Setã®å½¹å‰²ã‚’ç†è§£ã™ã‚‹</li>
<li>âœ… ãƒ¡ã‚¿å­¦ç¿’ã®3ã¤ã®ä¸»è¦ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’åˆ†é¡ã§ãã‚‹</li>
<li>âœ… Omniglotãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æ§‹é€ ã¨ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ç”Ÿæˆæ–¹æ³•ã‚’ç†è§£ã™ã‚‹</li>
<li>âœ… ã‚·ãƒ³ãƒ—ãƒ«ãªFew-Shotåˆ†é¡ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’å®Ÿè£…ã§ãã‚‹</li>
</ul>

<hr>

<h2>1.1 ãƒ¡ã‚¿å­¦ç¿’ã¨ã¯</h2>

<h3>Learning to Learnã®æ¦‚å¿µ</h3>

<p><strong>ãƒ¡ã‚¿å­¦ç¿’ï¼ˆMeta-Learningï¼‰</strong>ã¯ã€ã€Œå­¦ç¿’æ–¹æ³•ã‚’å­¦ç¿’ã™ã‚‹ã€ã¨ã„ã†ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã§ã™ã€‚å¾“æ¥ã®æ©Ÿæ¢°å­¦ç¿’ãŒç‰¹å®šã®ã‚¿ã‚¹ã‚¯ã‚’è§£ãã®ã«å¯¾ã—ã€ãƒ¡ã‚¿å­¦ç¿’ã¯ã€Œæ–°ã—ã„ã‚¿ã‚¹ã‚¯ã«ç´ æ—©ãé©å¿œã™ã‚‹èƒ½åŠ›ã€ãã®ã‚‚ã®ã‚’å­¦ç¿’ã—ã¾ã™ã€‚</p>

<blockquote>
<p>ã€Œäººé–“ã¯æ•°å€‹ã®ä¾‹ã‚’è¦‹ãŸã ã‘ã§æ–°ã—ã„æ¦‚å¿µã‚’å­¦ã¹ã‚‹ã€‚æ©Ÿæ¢°ã‚‚åŒã˜ã“ã¨ãŒã§ãã‚‹ã¹ãã ã€‚ã€</p>
</blockquote>

<h3>é€šå¸¸ã®å­¦ç¿’ã¨ã®é•ã„</h3>

<table>
<thead>
<tr>
<th>è¦³ç‚¹</th>
<th>é€šå¸¸ã®æ©Ÿæ¢°å­¦ç¿’</th>
<th>ãƒ¡ã‚¿å­¦ç¿’</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>ç›®æ¨™</strong></td>
<td>å˜ä¸€ã‚¿ã‚¹ã‚¯ã®æ€§èƒ½æœ€å¤§åŒ–</td>
<td>æ–°ã—ã„ã‚¿ã‚¹ã‚¯ã¸ã®é©å¿œèƒ½åŠ›ç²å¾—</td>
</tr>
<tr>
<td><strong>è¨“ç·´ãƒ‡ãƒ¼ã‚¿</strong></td>
<td>å¤§é‡ã®ãƒ©ãƒ™ãƒ«ä»˜ããƒ‡ãƒ¼ã‚¿</td>
<td>å¤šæ§˜ãªã‚¿ã‚¹ã‚¯ã‹ã‚‰ã®å°‘æ•°ã‚µãƒ³ãƒ—ãƒ«</td>
</tr>
<tr>
<td><strong>å­¦ç¿’å˜ä½</strong></td>
<td>å€‹åˆ¥ã‚µãƒ³ãƒ—ãƒ«</td>
<td>ã‚¿ã‚¹ã‚¯ï¼ˆã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ï¼‰</td>
</tr>
<tr>
<td><strong>è©•ä¾¡</strong></td>
<td>åŒä¸€åˆ†å¸ƒã®ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆ</td>
<td>æœªçŸ¥ã®ã‚¿ã‚¹ã‚¯ã§ã®é©å¿œé€Ÿåº¦</td>
</tr>
<tr>
<td><strong>ç”¨é€”</strong></td>
<td>å›ºå®šã‚¿ã‚¹ã‚¯ï¼ˆä¾‹ï¼šçŒ«vsçŠ¬åˆ†é¡ï¼‰</td>
<td>å‹•çš„ã‚¿ã‚¹ã‚¯ï¼ˆä¾‹ï¼šæ–°ç¨®ã®å‹•ç‰©èªè­˜ï¼‰</td>
</tr>
</tbody>
</table>

<h3>ãƒ¡ã‚¿å­¦ç¿’ã®å­¦ç¿’ãƒ—ãƒ­ã‚»ã‚¹</h3>

<div class="mermaid">
graph TD
    A[å¤šæ•°ã®ã‚¿ã‚¹ã‚¯] --> B[ã‚¿ã‚¹ã‚¯1: 5ã‚µãƒ³ãƒ—ãƒ«ã§å­¦ç¿’]
    A --> C[ã‚¿ã‚¹ã‚¯2: 5ã‚µãƒ³ãƒ—ãƒ«ã§å­¦ç¿’]
    A --> D[ã‚¿ã‚¹ã‚¯3: 5ã‚µãƒ³ãƒ—ãƒ«ã§å­¦ç¿’]
    B --> E[ãƒ¡ã‚¿çŸ¥è­˜ã®è“„ç©]
    C --> E
    D --> E
    E --> F[æ–°ã—ã„ã‚¿ã‚¹ã‚¯N]
    F --> G[5ã‚µãƒ³ãƒ—ãƒ«ã§é«˜ç²¾åº¦]

    style A fill:#e3f2fd
    style E fill:#fff3e0
    style G fill:#c8e6c9
</div>

<h3>ãƒ¡ã‚¿å­¦ç¿’ãŒæœ‰åŠ¹ãªã‚·ãƒŠãƒªã‚ª</h3>

<ul>
<li><strong>åŒ»ç™‚ç”»åƒè¨ºæ–­</strong>: ç¨€ãªç–¾æ‚£ã®ä¾‹ãŒå°‘ãªã„</li>
<li><strong>å€‹äººåŒ–æ¨è–¦</strong>: æ–°è¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å±¥æ­´ãŒå°‘ãªã„</li>
<li><strong>ãƒ­ãƒœãƒƒãƒˆå·¥å­¦</strong>: æ–°ã—ã„ç’°å¢ƒã¸ã®è¿…é€Ÿãªé©å¿œ</li>
<li><strong>å‰µè–¬</strong>: æ–°è¦åŒ–åˆç‰©ã®ãƒ‡ãƒ¼ã‚¿ãŒé™å®šçš„</li>
<li><strong>å¤šè¨€èªå‡¦ç†</strong>: ä½ãƒªã‚½ãƒ¼ã‚¹è¨€èªã§ã®å­¦ç¿’</li>
</ul>

<h3>å®Ÿä¾‹ï¼šäººé–“ã®å­¦ç¿’ã¨ã®æ¯”è¼ƒ</h3>

<pre><code class="language-python">import numpy as np
import matplotlib.pyplot as plt

# æ¯”è¼ƒ: é€šå¸¸å­¦ç¿’ vs ãƒ¡ã‚¿å­¦ç¿’ã®å­¦ç¿’æ›²ç·šã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³

def standard_learning_curve(n_samples):
    """é€šå¸¸ã®å­¦ç¿’: ç·šå½¢çš„ãªæ”¹å–„"""
    return 0.5 + 0.45 * (1 - np.exp(-n_samples / 500))

def meta_learning_curve(n_samples):
    """ãƒ¡ã‚¿å­¦ç¿’: å°‘æ•°ã‚µãƒ³ãƒ—ãƒ«ã§æ€¥é€Ÿã«å­¦ç¿’"""
    return 0.5 + 0.45 * (1 - np.exp(-n_samples / 20))

# ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆ
samples = np.arange(1, 101, 1)
standard_acc = standard_learning_curve(samples)
meta_acc = meta_learning_curve(samples)

# å¯è¦–åŒ–
plt.figure(figsize=(12, 6))
plt.plot(samples, standard_acc, 'b-', linewidth=2, label='é€šå¸¸ã®æ©Ÿæ¢°å­¦ç¿’')
plt.plot(samples, meta_acc, 'r-', linewidth=2, label='ãƒ¡ã‚¿å­¦ç¿’')
plt.axhline(y=0.9, color='gray', linestyle='--', alpha=0.5, label='ç›®æ¨™ç²¾åº¦ 90%')
plt.axvline(x=10, color='green', linestyle=':', alpha=0.5, label='Few-Shoté ˜åŸŸ (10ã‚µãƒ³ãƒ—ãƒ«)')

plt.xlabel('è¨“ç·´ã‚µãƒ³ãƒ—ãƒ«æ•°', fontsize=12)
plt.ylabel('ç²¾åº¦', fontsize=12)
plt.title('å­¦ç¿’ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã®æ¯”è¼ƒ: é€šå¸¸å­¦ç¿’ vs ãƒ¡ã‚¿å­¦ç¿’', fontsize=14)
plt.legend(fontsize=11)
plt.grid(True, alpha=0.3)
plt.xlim(0, 100)
plt.ylim(0.4, 1.0)

# é‡è¦ãƒã‚¤ãƒ³ãƒˆã‚’æ³¨é‡ˆ
plt.annotate('ãƒ¡ã‚¿å­¦ç¿’: 10ã‚µãƒ³ãƒ—ãƒ«ã§85%é”æˆ',
             xy=(10, meta_learning_curve(10)),
             xytext=(30, 0.75),
             arrowprops=dict(arrowstyle='->', color='red', lw=1.5),
             fontsize=10, color='red')

plt.annotate('é€šå¸¸å­¦ç¿’: 10ã‚µãƒ³ãƒ—ãƒ«ã§ã¯60%ç¨‹åº¦',
             xy=(10, standard_learning_curve(10)),
             xytext=(30, 0.55),
             arrowprops=dict(arrowstyle='->', color='blue', lw=1.5),
             fontsize=10, color='blue')

plt.tight_layout()
plt.show()

print("=== å­¦ç¿’åŠ¹ç‡ã®æ¯”è¼ƒ ===")
print(f"10ã‚µãƒ³ãƒ—ãƒ«ã§ã®ç²¾åº¦:")
print(f"  é€šå¸¸å­¦ç¿’: {standard_learning_curve(10):.3f}")
print(f"  ãƒ¡ã‚¿å­¦ç¿’: {meta_learning_curve(10):.3f}")
print(f"  å·®: {(meta_learning_curve(10) - standard_learning_curve(10)):.3f}")
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>=== å­¦ç¿’åŠ¹ç‡ã®æ¯”è¼ƒ ===
10ã‚µãƒ³ãƒ—ãƒ«ã§ã®ç²¾åº¦:
  é€šå¸¸å­¦ç¿’: 0.591
  ãƒ¡ã‚¿å­¦ç¿’: 0.873
  å·®: 0.282
</code></pre>

<blockquote>
<p><strong>é‡è¦</strong>: ãƒ¡ã‚¿å­¦ç¿’ã¯å°‘æ•°ã‚µãƒ³ãƒ—ãƒ«ã§é«˜ç²¾åº¦ã‚’é”æˆã§ãã‚‹ç‚¹ãŒæœ€å¤§ã®åˆ©ç‚¹ã§ã™ã€‚</p>
</blockquote>

<hr>

<h2>1.2 Few-Shot Learningå•é¡Œè¨­å®š</h2>

<h3>N-way K-shotåˆ†é¡</h3>

<p>Few-Shot Learningã®æ¨™æº–çš„ãªå•é¡Œè¨­å®šã¯<strong>N-way K-shotåˆ†é¡</strong>ã§ã™ï¼š</p>

<ul>
<li><strong>N-way</strong>: Nå€‹ã®ã‚¯ãƒ©ã‚¹ã‚’åˆ†é¡</li>
<li><strong>K-shot</strong>: å„ã‚¯ãƒ©ã‚¹ã«Kå€‹ã®ãƒ©ãƒ™ãƒ«ä»˜ãã‚µãƒ³ãƒ—ãƒ«</li>
</ul>

<p>ä¾‹ï¼š<strong>5-way 1-shot</strong>åˆ†é¡ = 5ã‚¯ãƒ©ã‚¹ã‚’å„ã‚¯ãƒ©ã‚¹1ã‚µãƒ³ãƒ—ãƒ«ã‹ã‚‰å­¦ç¿’</p>

<h3>Support Setã¨Query Set</h3>

<p>å„ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ï¼ˆã‚¿ã‚¹ã‚¯ï¼‰ã¯2ã¤ã®ã‚»ãƒƒãƒˆã§æ§‹æˆã•ã‚Œã¾ã™ï¼š</p>

<table>
<thead>
<tr>
<th>ã‚»ãƒƒãƒˆ</th>
<th>å½¹å‰²</th>
<th>ã‚µã‚¤ã‚º</th>
<th>ç”¨é€”</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Support Set</strong></td>
<td>å­¦ç¿’ç”¨ã‚µãƒ³ãƒ—ãƒ«</td>
<td>N Ã— K å€‹</td>
<td>ãƒ¢ãƒ‡ãƒ«ã®é©å¿œãƒ»æ›´æ–°</td>
</tr>
<tr>
<td><strong>Query Set</strong></td>
<td>è©•ä¾¡ç”¨ã‚µãƒ³ãƒ—ãƒ«</td>
<td>N Ã— Q å€‹</td>
<td>ã‚¿ã‚¹ã‚¯ã§ã®æ€§èƒ½è©•ä¾¡</td>
</tr>
</tbody>
</table>

<h3>ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã®æ§‹é€ </h3>

<div class="mermaid">
graph LR
    A[1ã¤ã®ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰] --> B[Support Set<br/>NÃ—K ã‚µãƒ³ãƒ—ãƒ«]
    A --> C[Query Set<br/>NÃ—Q ã‚µãƒ³ãƒ—ãƒ«]
    B --> D[ãƒ¢ãƒ‡ãƒ«ã‚’é©å¿œ]
    C --> E[æ€§èƒ½ã‚’è©•ä¾¡]

    style A fill:#e3f2fd
    style B fill:#fff3e0
    style C fill:#f3e5f5
    style D fill:#e8f5e9
    style E fill:#ffebee
</div>

<h3>å…·ä½“ä¾‹ï¼š5-way 1-shotåˆ†é¡</h3>

<pre><code class="language-python">import numpy as np

# 5-way 1-shot ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã®æ§‹é€ ã‚’å¯è¦–åŒ–

def create_episode_structure(n_way=5, k_shot=1, n_query=5):
    """
    N-way K-shot ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã®æ§‹é€ ã‚’ç”Ÿæˆ

    Args:
        n_way: ã‚¯ãƒ©ã‚¹æ•°
        k_shot: å„ã‚¯ãƒ©ã‚¹ã®ã‚µãƒãƒ¼ãƒˆã‚µãƒ³ãƒ—ãƒ«æ•°
        n_query: å„ã‚¯ãƒ©ã‚¹ã®ã‚¯ã‚¨ãƒªã‚µãƒ³ãƒ—ãƒ«æ•°

    Returns:
        support_set, query_set ã®ã‚µã‚¤ã‚ºæƒ…å ±
    """
    support_size = n_way * k_shot
    query_size = n_way * n_query

    print(f"=== {n_way}-way {k_shot}-shot ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰æ§‹é€  ===\n")
    print(f"ã€Support Setã€‘")
    print(f"  ç›®çš„: ãƒ¢ãƒ‡ãƒ«ã®é©å¿œãƒ»å­¦ç¿’")
    print(f"  æ§‹æˆ: {n_way} ã‚¯ãƒ©ã‚¹ Ã— {k_shot} ã‚µãƒ³ãƒ—ãƒ«/ã‚¯ãƒ©ã‚¹ = {support_size} ã‚µãƒ³ãƒ—ãƒ«")

    for i in range(n_way):
        samples = [f"S_{i}_{j}" for j in range(k_shot)]
        print(f"    ã‚¯ãƒ©ã‚¹ {i}: {samples}")

    print(f"\nã€Query Setã€‘")
    print(f"  ç›®çš„: æ€§èƒ½è©•ä¾¡")
    print(f"  æ§‹æˆ: {n_way} ã‚¯ãƒ©ã‚¹ Ã— {n_query} ã‚µãƒ³ãƒ—ãƒ«/ã‚¯ãƒ©ã‚¹ = {query_size} ã‚µãƒ³ãƒ—ãƒ«")

    for i in range(n_way):
        samples = [f"Q_{i}_{j}" for j in range(min(n_query, 3))]
        if n_query > 3:
            samples.append("...")
        print(f"    ã‚¯ãƒ©ã‚¹ {i}: {samples}")

    return support_size, query_size

# 5-way 1-shot ã®ä¾‹
support_size, query_size = create_episode_structure(n_way=5, k_shot=1, n_query=5)

print(f"\nç·ã‚µãƒ³ãƒ—ãƒ«æ•°: {support_size + query_size}")
print(f"  Support: {support_size}")
print(f"  Query: {query_size}")
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>=== 5-way 1-shot ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰æ§‹é€  ===

ã€Support Setã€‘
  ç›®çš„: ãƒ¢ãƒ‡ãƒ«ã®é©å¿œãƒ»å­¦ç¿’
  æ§‹æˆ: 5 ã‚¯ãƒ©ã‚¹ Ã— 1 ã‚µãƒ³ãƒ—ãƒ«/ã‚¯ãƒ©ã‚¹ = 5 ã‚µãƒ³ãƒ—ãƒ«
    ã‚¯ãƒ©ã‚¹ 0: ['S_0_0']
    ã‚¯ãƒ©ã‚¹ 1: ['S_1_0']
    ã‚¯ãƒ©ã‚¹ 2: ['S_2_0']
    ã‚¯ãƒ©ã‚¹ 3: ['S_3_0']
    ã‚¯ãƒ©ã‚¹ 4: ['S_4_0']

ã€Query Setã€‘
  ç›®çš„: æ€§èƒ½è©•ä¾¡
  æ§‹æˆ: 5 ã‚¯ãƒ©ã‚¹ Ã— 5 ã‚µãƒ³ãƒ—ãƒ«/ã‚¯ãƒ©ã‚¹ = 25 ã‚µãƒ³ãƒ—ãƒ«
    ã‚¯ãƒ©ã‚¹ 0: ['Q_0_0', 'Q_0_1', 'Q_0_2', '...']
    ã‚¯ãƒ©ã‚¹ 1: ['Q_1_0', 'Q_1_1', 'Q_1_2', '...']
    ã‚¯ãƒ©ã‚¹ 2: ['Q_2_0', 'Q_2_1', 'Q_2_2', '...']
    ã‚¯ãƒ©ã‚¹ 3: ['Q_3_0', 'Q_3_1', 'Q_3_2', '...']
    ã‚¯ãƒ©ã‚¹ 4: ['Q_4_0', 'Q_4_1', 'Q_4_2', '...']

ç·ã‚µãƒ³ãƒ—ãƒ«æ•°: 30
  Support: 5
  Query: 25
</code></pre>

<h3>Episode-basedå­¦ç¿’</h3>

<p>ãƒ¡ã‚¿å­¦ç¿’ã§ã¯ã€å¤šæ•°ã®ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‚’é€šã˜ã¦å­¦ç¿’ã—ã¾ã™ï¼š</p>

<ol>
<li>ãƒ©ãƒ³ãƒ€ãƒ ã«Nå€‹ã®ã‚¯ãƒ©ã‚¹ã‚’é¸æŠ</li>
<li>å„ã‚¯ãƒ©ã‚¹ã‹ã‚‰Kå€‹ã®ã‚µãƒãƒ¼ãƒˆã‚µãƒ³ãƒ—ãƒ«ã¨Qå€‹ã®ã‚¯ã‚¨ãƒªã‚µãƒ³ãƒ—ãƒ«ã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°</li>
<li>ã‚µãƒãƒ¼ãƒˆã‚»ãƒƒãƒˆã§ãƒ¢ãƒ‡ãƒ«ã‚’é©å¿œ</li>
<li>ã‚¯ã‚¨ãƒªã‚»ãƒƒãƒˆã§è©•ä¾¡ã—ã€ãƒ¡ã‚¿çŸ¥è­˜ã‚’æ›´æ–°</li>
<li>1ã€œ4ã‚’ç¹°ã‚Šè¿”ã™</li>
</ol>

<pre><code class="language-python">import numpy as np

def meta_training_simulation(n_episodes=1000, n_way=5, k_shot=1):
    """
    ãƒ¡ã‚¿å­¦ç¿’ã®è¨“ç·´ãƒ—ãƒ­ã‚»ã‚¹ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³

    Args:
        n_episodes: ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰æ•°
        n_way: ã‚¯ãƒ©ã‚¹æ•°
        k_shot: ã‚µãƒãƒ¼ãƒˆã‚µãƒ³ãƒ—ãƒ«æ•°
    """
    episode_accuracies = []

    for episode in range(n_episodes):
        # å„ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã§ãƒ©ãƒ³ãƒ€ãƒ ã«ã‚¿ã‚¹ã‚¯ã‚’ç”Ÿæˆ
        # ï¼ˆå®Ÿéš›ã«ã¯ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‹ã‚‰ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼‰

        # ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³: ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ãŒé€²ã‚€ã«ã¤ã‚Œã¦ç²¾åº¦å‘ä¸Š
        base_acc = 0.2  # ãƒ©ãƒ³ãƒ€ãƒ æ¨æ¸¬ (5-way: 20%)
        improvement = 0.7 * (1 - np.exp(-episode / 200))
        noise = np.random.normal(0, 0.05)  # ãƒ©ãƒ³ãƒ€ãƒ ãƒã‚¤ã‚º

        acc = min(max(base_acc + improvement + noise, 0), 1)
        episode_accuracies.append(acc)

    # å¯è¦–åŒ–
    import matplotlib.pyplot as plt

    plt.figure(figsize=(12, 6))

    # ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã”ã¨ã®ç²¾åº¦
    plt.subplot(1, 2, 1)
    plt.plot(episode_accuracies, alpha=0.3, color='blue')

    # ç§»å‹•å¹³å‡
    window = 50
    moving_avg = np.convolve(episode_accuracies,
                             np.ones(window)/window, mode='valid')
    plt.plot(range(window-1, n_episodes), moving_avg,
             'r-', linewidth=2, label=f'{window}-ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ç§»å‹•å¹³å‡')

    plt.axhline(y=0.2, color='gray', linestyle='--',
                alpha=0.5, label='ãƒ©ãƒ³ãƒ€ãƒ æ¨æ¸¬ (20%)')
    plt.xlabel('ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰', fontsize=12)
    plt.ylabel('Query Set ç²¾åº¦', fontsize=12)
    plt.title(f'{n_way}-way {k_shot}-shot ãƒ¡ã‚¿è¨“ç·´ã®é€²è¡Œ', fontsize=14)
    plt.legend()
    plt.grid(True, alpha=0.3)

    # ç²¾åº¦åˆ†å¸ƒã®å¤‰åŒ–
    plt.subplot(1, 2, 2)
    early = episode_accuracies[:200]
    late = episode_accuracies[-200:]

    plt.hist(early, bins=20, alpha=0.5, label='åˆæœŸ (0-200)', color='blue')
    plt.hist(late, bins=20, alpha=0.5, label='å¾ŒæœŸ (800-1000)', color='red')
    plt.xlabel('ç²¾åº¦', fontsize=12)
    plt.ylabel('é »åº¦', fontsize=12)
    plt.title('ç²¾åº¦åˆ†å¸ƒã®å¤‰åŒ–', fontsize=14)
    plt.legend()
    plt.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.show()

    print(f"=== ãƒ¡ã‚¿è¨“ç·´çµ±è¨ˆ ({n_episodes} ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰) ===")
    print(f"åˆæœŸ100ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã®å¹³å‡ç²¾åº¦: {np.mean(episode_accuracies[:100]):.3f}")
    print(f"æœ€çµ‚100ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã®å¹³å‡ç²¾åº¦: {np.mean(episode_accuracies[-100:]):.3f}")
    print(f"æ”¹å–„: {(np.mean(episode_accuracies[-100:]) - np.mean(episode_accuracies[:100])):.3f}")

# ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
meta_training_simulation(n_episodes=1000, n_way=5, k_shot=1)
</code></pre>

<blockquote>
<p><strong>é‡è¦</strong>: ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã®å­¦ç¿’ã«ã‚ˆã‚Šã€ãƒ¢ãƒ‡ãƒ«ã¯ã€Œå°‘æ•°ã‚µãƒ³ãƒ—ãƒ«ã‹ã‚‰å­¦ã¶èƒ½åŠ›ã€ãã®ã‚‚ã®ã‚’ç²å¾—ã—ã¾ã™ã€‚</p>
</blockquote>

<hr>

<h2>1.3 ãƒ¡ã‚¿å­¦ç¿’ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒåˆ†é¡</h2>

<p>ãƒ¡ã‚¿å­¦ç¿’ã®æ‰‹æ³•ã¯ã€å¤§ãã3ã¤ã®ã‚«ãƒ†ã‚´ãƒªã«åˆ†é¡ã•ã‚Œã¾ã™ï¼š</p>

<h3>1. Metric-basedï¼ˆè·é›¢ãƒ™ãƒ¼ã‚¹ï¼‰</h3>

<p><strong>åŸºæœ¬ã‚¢ã‚¤ãƒ‡ã‚¢</strong>: è‰¯ã„è·é›¢ç©ºé–“ã‚’å­¦ç¿’ã—ã€è¿‘å‚ã«åŸºã¥ã„ã¦åˆ†é¡</p>

<table>
<thead>
<tr>
<th>æ‰‹æ³•</th>
<th>ç‰¹å¾´</th>
<th>è·é›¢è¨ˆç®—</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Siamese Networks</strong></td>
<td>ãƒšã‚¢ãƒ¯ã‚¤ã‚ºæ¯”è¼ƒ</td>
<td>ãƒ¦ãƒ¼ã‚¯ãƒªãƒƒãƒ‰è·é›¢ã€ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦</td>
</tr>
<tr>
<td><strong>Matching Networks</strong></td>
<td>æ³¨æ„æ©Ÿæ§‹ã§åŠ é‡å¹³å‡</td>
<td>ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ + æ³¨æ„</td>
</tr>
<tr>
<td><strong>Prototypical Networks</strong></td>
<td>ã‚¯ãƒ©ã‚¹ã”ã¨ã®ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—</td>
<td>ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ã¾ã§ã®è·é›¢</td>
</tr>
<tr>
<td><strong>Relation Networks</strong></td>
<td>å­¦ç¿’å¯èƒ½ãªè·é›¢é–¢æ•°</td>
<td>ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆã§è·é›¢å­¦ç¿’</td>
</tr>
</tbody>
</table>

<h4>Prototypical Networksã®æ¦‚å¿µ</h4>

<pre><code class="language-python">import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import make_blobs

# Prototypical Networksã®æ¦‚å¿µã‚’å¯è¦–åŒ–

# ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³: 3ã‚¯ãƒ©ã‚¹ã®åŸ‹ã‚è¾¼ã¿ç©ºé–“
np.random.seed(42)

# å„ã‚¯ãƒ©ã‚¹ã®ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
n_samples_per_class = 20
centers = np.array([[0, 0], [3, 3], [0, 3]])
X, y = make_blobs(n_samples=n_samples_per_class * 3,
                  centers=centers,
                  cluster_std=0.5,
                  random_state=42)

# Support Set (å„ã‚¯ãƒ©ã‚¹3ã‚µãƒ³ãƒ—ãƒ«)
support_indices = []
for cls in range(3):
    cls_indices = np.where(y == cls)[0]
    support_indices.extend(cls_indices[:3])

support_X = X[support_indices]
support_y = y[support_indices]

# Query Set (æ®‹ã‚Šã®ã‚µãƒ³ãƒ—ãƒ«)
query_indices = [i for i in range(len(X)) if i not in support_indices]
query_X = X[query_indices]
query_y = y[query_indices]

# ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—è¨ˆç®—ï¼ˆå„ã‚¯ãƒ©ã‚¹ã®ã‚µãƒãƒ¼ãƒˆã‚µãƒ³ãƒ—ãƒ«ã®å¹³å‡ï¼‰
prototypes = []
for cls in range(3):
    cls_support = support_X[support_y == cls]
    prototype = cls_support.mean(axis=0)
    prototypes.append(prototype)

prototypes = np.array(prototypes)

# å¯è¦–åŒ–
plt.figure(figsize=(12, 5))

# å·¦: Support Set ã¨ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—
plt.subplot(1, 2, 1)
colors = ['red', 'blue', 'green']
for cls in range(3):
    cls_support = support_X[support_y == cls]
    plt.scatter(cls_support[:, 0], cls_support[:, 1],
                c=colors[cls], s=100, alpha=0.6,
                label=f'Class {cls} Support', marker='o')

plt.scatter(prototypes[:, 0], prototypes[:, 1],
            c=colors, s=300, marker='*',
            edgecolors='black', linewidth=2,
            label='Prototypes')

plt.xlabel('åŸ‹ã‚è¾¼ã¿æ¬¡å…ƒ1', fontsize=12)
plt.ylabel('åŸ‹ã‚è¾¼ã¿æ¬¡å…ƒ2', fontsize=12)
plt.title('Support Set ã¨ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—', fontsize=14)
plt.legend()
plt.grid(True, alpha=0.3)

# å³: Query Set ã®åˆ†é¡
plt.subplot(1, 2, 2)

# å…¨ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆ
for cls in range(3):
    cls_query = query_X[query_y == cls]
    plt.scatter(cls_query[:, 0], cls_query[:, 1],
                c=colors[cls], s=50, alpha=0.3,
                label=f'Class {cls} Query')

# ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—
plt.scatter(prototypes[:, 0], prototypes[:, 1],
            c=colors, s=300, marker='*',
            edgecolors='black', linewidth=2,
            label='Prototypes')

# 1ã¤ã®ã‚¯ã‚¨ãƒªã‚µãƒ³ãƒ—ãƒ«ã®åˆ†é¡ã‚’ç¤ºã™
query_sample = query_X[0]
plt.scatter(query_sample[0], query_sample[1],
            c='orange', s=200, marker='X',
            edgecolors='black', linewidth=2,
            label='Query Sample', zorder=5)

# ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ã¾ã§ã®è·é›¢ã‚’ç·šã§ç¤ºã™
for i, proto in enumerate(prototypes):
    dist = np.linalg.norm(query_sample - proto)
    plt.plot([query_sample[0], proto[0]],
             [query_sample[1], proto[1]],
             'k--', alpha=0.3, linewidth=1)
    mid = (query_sample + proto) / 2
    plt.text(mid[0], mid[1], f'd={dist:.2f}', fontsize=9)

plt.xlabel('åŸ‹ã‚è¾¼ã¿æ¬¡å…ƒ1', fontsize=12)
plt.ylabel('åŸ‹ã‚è¾¼ã¿æ¬¡å…ƒ2', fontsize=12)
plt.title('Prototypical Networks: è·é›¢ãƒ™ãƒ¼ã‚¹åˆ†é¡', fontsize=14)
plt.legend()
plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

print("=== Prototypical Networks ===")
print(f"ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—åº§æ¨™:")
for i, proto in enumerate(prototypes):
    print(f"  Class {i}: [{proto[0]:.2f}, {proto[1]:.2f}]")
</code></pre>

<h3>2. Model-basedï¼ˆãƒ¢ãƒ‡ãƒ«ãƒ™ãƒ¼ã‚¹ï¼‰</h3>

<p><strong>åŸºæœ¬ã‚¢ã‚¤ãƒ‡ã‚¢</strong>: ãƒ¡ãƒ¢ãƒªã‚„å†å¸°æ§‹é€ ã‚’æŒã¤ãƒ¢ãƒ‡ãƒ«ã§é«˜é€Ÿé©å¿œ</p>

<ul>
<li><strong>Memory-Augmented Neural Networks (MANN)</strong>: å¤–éƒ¨ãƒ¡ãƒ¢ãƒªã§éå»ã®çµŒé¨“ã‚’ä¿å­˜</li>
<li><strong>Meta Networks</strong>: é«˜é€Ÿãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç”Ÿæˆå™¨ã‚’å­¦ç¿’</li>
<li><strong>SNAIL</strong>: æ™‚ç³»åˆ—ã¨ã—ã¦éå»ã‚µãƒ³ãƒ—ãƒ«ã‚’å‡¦ç†</li>
</ul>

<h3>3. Optimization-basedï¼ˆæœ€é©åŒ–ãƒ™ãƒ¼ã‚¹ï¼‰</h3>

<p><strong>åŸºæœ¬ã‚¢ã‚¤ãƒ‡ã‚¢</strong>: è‰¯ã„åˆæœŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å­¦ç¿’ã—ã€å°‘æ•°ã‚¹ãƒ†ãƒƒãƒ—ã§é©å¿œ</p>

<table>
<thead>
<tr>
<th>æ‰‹æ³•</th>
<th>ç‰¹å¾´</th>
<th>é©å¿œæ–¹æ³•</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>MAML</strong></td>
<td>ãƒ¢ãƒ‡ãƒ«éä¾å­˜ã€å‹¾é…ãƒ™ãƒ¼ã‚¹</td>
<td>æ•°ã‚¹ãƒ†ãƒƒãƒ—ã®å‹¾é…é™ä¸‹</td>
</tr>
<tr>
<td><strong>Reptile</strong></td>
<td>MAMLã®ç°¡æ˜“ç‰ˆ</td>
<td>1æ¬¡å¾®åˆ†ã®ã¿</td>
</tr>
<tr>
<td><strong>Meta-SGD</strong></td>
<td>å­¦ç¿’ç‡ã‚‚å­¦ç¿’</td>
<td>é©å¿œçš„å­¦ç¿’ç‡ + å‹¾é…é™ä¸‹</td>
</tr>
</tbody>
</table>

<h3>ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã®æ¯”è¼ƒ</h3>

<table>
<thead>
<tr>
<th>ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ</th>
<th>é•·æ‰€</th>
<th>çŸ­æ‰€</th>
<th>é©ç”¨ä¾‹</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Metric-based</strong></td>
<td>ã‚·ãƒ³ãƒ—ãƒ«ã€é«˜é€Ÿã€è§£é‡ˆæ€§</td>
<td>è¤‡é›‘ãªã‚¿ã‚¹ã‚¯ã«é™ç•Œ</td>
<td>ç”»åƒåˆ†é¡ã€å°‘æ•°ã‚µãƒ³ãƒ—ãƒ«èªè­˜</td>
</tr>
<tr>
<td><strong>Model-based</strong></td>
<td>æŸ”è»Ÿã€è¡¨ç¾åŠ›é«˜ã„</td>
<td>è¨“ç·´ãŒè¤‡é›‘</td>
<td>ã‚·ãƒ¼ã‚±ãƒ³ã‚·ãƒ£ãƒ«ã‚¿ã‚¹ã‚¯</td>
</tr>
<tr>
<td><strong>Optimization-based</strong></td>
<td>æ±ç”¨æ€§ã€å¼·åŠ›</td>
<td>è¨ˆç®—ã‚³ã‚¹ãƒˆé«˜ã„</td>
<td>å¼·åŒ–å­¦ç¿’ã€è¤‡é›‘ã‚¿ã‚¹ã‚¯</td>
</tr>
</tbody>
</table>

<hr>

<h2>1.4 Omniglotãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ</h2>

<h3>ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æ§‹é€ </h3>

<p><strong>Omniglot</strong>ã¯ã€Œãƒ¡ã‚¿å­¦ç¿’ã®MNISTã€ã¨å‘¼ã°ã‚Œã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã™ï¼š</p>

<ul>
<li><strong>1,623 æ–‡å­—ã‚¯ãƒ©ã‚¹</strong>ï¼ˆ50ã®ç•°ãªã‚‹æ–‡å­—ä½“ç³»ã‹ã‚‰ï¼‰</li>
<li><strong>å„ã‚¯ãƒ©ã‚¹20ã‚µãƒ³ãƒ—ãƒ«</strong>ï¼ˆ20äººãŒæã„ãŸæ‰‹æ›¸ãæ–‡å­—ï¼‰</li>
<li><strong>ç”»åƒã‚µã‚¤ã‚º</strong>: 105Ã—105 ãƒ”ã‚¯ã‚»ãƒ«ã€ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«</li>
<li><strong>ç·ã‚µãƒ³ãƒ—ãƒ«æ•°</strong>: 32,460 æš</li>
</ul>

<h3>ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã¨æº–å‚™</h3>

<pre><code class="language-python">import torch
import torchvision.transforms as transforms
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt
import numpy as np

# Omniglotãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æº–å‚™
# æ³¨: torchvision.datasets.Omniglot ã‚’ä½¿ç”¨

from torchvision.datasets import Omniglot

# ãƒ‡ãƒ¼ã‚¿å¤‰æ›
transform = transforms.Compose([
    transforms.Resize((28, 28)),  # MNISTã‚µã‚¤ã‚ºã«ç¸®å°
    transforms.ToTensor(),
])

# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ­ãƒ¼ãƒ‰
try:
    # èƒŒæ™¯ã‚»ãƒƒãƒˆï¼ˆè¨“ç·´ç”¨ï¼‰
    omniglot_train = Omniglot(
        root='./data',
        background=True,
        download=True,
        transform=transform
    )

    # è©•ä¾¡ã‚»ãƒƒãƒˆï¼ˆãƒ†ã‚¹ãƒˆç”¨ï¼‰
    omniglot_test = Omniglot(
        root='./data',
        background=False,
        download=True,
        transform=transform
    )

    print("=== Omniglot ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ ===")
    print(f"è¨“ç·´ã‚»ãƒƒãƒˆ: {len(omniglot_train)} ã‚µãƒ³ãƒ—ãƒ«")
    print(f"ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆ: {len(omniglot_test)} ã‚µãƒ³ãƒ—ãƒ«")

    # ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®ç¢ºèª
    print(f"\nãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ§‹é€ :")
    print(f"  è¨“ç·´ã‚¯ãƒ©ã‚¹æ•°: {len(omniglot_train._alphabets)} æ–‡å­—ä½“ç³»")
    print(f"  ãƒ†ã‚¹ãƒˆã‚¯ãƒ©ã‚¹æ•°: {len(omniglot_test._alphabets)} æ–‡å­—ä½“ç³»")

    # ã‚µãƒ³ãƒ—ãƒ«å¯è¦–åŒ–
    fig, axes = plt.subplots(2, 10, figsize=(15, 3))

    for i in range(10):
        # è¨“ç·´ã‚»ãƒƒãƒˆã‹ã‚‰
        img, label = omniglot_train[i * 100]
        axes[0, i].imshow(img.squeeze(), cmap='gray')
        axes[0, i].axis('off')
        axes[0, i].set_title(f'Train {i}', fontsize=9)

        # ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã‹ã‚‰
        img, label = omniglot_test[i * 50]
        axes[1, i].imshow(img.squeeze(), cmap='gray')
        axes[1, i].axis('off')
        axes[1, i].set_title(f'Test {i}', fontsize=9)

    plt.suptitle('Omniglot ã‚µãƒ³ãƒ—ãƒ«ï¼ˆä¸Š: è¨“ç·´ã‚»ãƒƒãƒˆã€ä¸‹: ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆï¼‰', fontsize=14)
    plt.tight_layout()
    plt.show()

except Exception as e:
    print(f"ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
    print("æ³¨: å®Ÿè¡Œã«ã¯ torchvision ã¨ ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆæ¥ç¶šãŒå¿…è¦ã§ã™")
</code></pre>

<h3>Episodeç”Ÿæˆ</h3>

<pre><code class="language-python">import random

class OmniglotEpisodeSampler:
    """
    Omniglotç”¨ã®ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‚µãƒ³ãƒ—ãƒ©ãƒ¼
    N-way K-shot ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‚’ç”Ÿæˆ
    """
    def __init__(self, dataset, n_way=5, k_shot=1, n_query=5):
        self.dataset = dataset
        self.n_way = n_way
        self.k_shot = k_shot
        self.n_query = n_query

        # ã‚¯ãƒ©ã‚¹ã”ã¨ã«ã‚µãƒ³ãƒ—ãƒ«ã‚’ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
        self.class_to_indices = {}
        for idx, (_, label) in enumerate(dataset):
            if label not in self.class_to_indices:
                self.class_to_indices[label] = []
            self.class_to_indices[label].append(idx)

        self.classes = list(self.class_to_indices.keys())
        print(f"ã‚µãƒ³ãƒ—ãƒ©ãƒ¼åˆæœŸåŒ–: {len(self.classes)} ã‚¯ãƒ©ã‚¹")

    def sample_episode(self):
        """
        1ã¤ã®ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°

        Returns:
            support_set: (n_way * k_shot, C, H, W) tensor
            query_set: (n_way * n_query, C, H, W) tensor
            support_labels: (n_way * k_shot,) tensor
            query_labels: (n_way * n_query,) tensor
        """
        # Nå€‹ã®ã‚¯ãƒ©ã‚¹ã‚’ãƒ©ãƒ³ãƒ€ãƒ é¸æŠ
        episode_classes = random.sample(self.classes, self.n_way)

        support_set = []
        query_set = []
        support_labels = []
        query_labels = []

        for class_idx, cls in enumerate(episode_classes):
            # ã“ã®ã‚¯ãƒ©ã‚¹ã®ã‚µãƒ³ãƒ—ãƒ«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
            cls_indices = self.class_to_indices[cls]

            # K+Qå€‹ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆé‡è¤‡ãªã—ï¼‰
            sampled_indices = random.sample(cls_indices,
                                           self.k_shot + self.n_query)

            # Support Set
            for i in range(self.k_shot):
                img, _ = self.dataset[sampled_indices[i]]
                support_set.append(img)
                support_labels.append(class_idx)

            # Query Set
            for i in range(self.k_shot, self.k_shot + self.n_query):
                img, _ = self.dataset[sampled_indices[i]]
                query_set.append(img)
                query_labels.append(class_idx)

        # Tensorã«å¤‰æ›
        support_set = torch.stack(support_set)
        query_set = torch.stack(query_set)
        support_labels = torch.tensor(support_labels)
        query_labels = torch.tensor(query_labels)

        return support_set, query_set, support_labels, query_labels

# ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‚µãƒ³ãƒ—ãƒ©ãƒ¼ã®ä½¿ç”¨ä¾‹
try:
    sampler = OmniglotEpisodeSampler(
        omniglot_train,
        n_way=5,
        k_shot=1,
        n_query=5
    )

    # 1ã¤ã®ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
    support, query, support_labels, query_labels = sampler.sample_episode()

    print(f"\n=== ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰æ§‹é€  ===")
    print(f"Support Set: {support.shape}")
    print(f"Query Set: {query.shape}")
    print(f"Support Labels: {support_labels}")
    print(f"Query Labels: {query_labels}")

    # å¯è¦–åŒ–
    fig, axes = plt.subplots(2, 5, figsize=(12, 5))

    # Support Set
    for i in range(5):
        axes[0, i].imshow(support[i].squeeze(), cmap='gray')
        axes[0, i].axis('off')
        axes[0, i].set_title(f'Support\nClass {support_labels[i].item()}',
                            fontsize=10)

    # Query Setï¼ˆå„ã‚¯ãƒ©ã‚¹ã‹ã‚‰1ã¤ï¼‰
    for i in range(5):
        axes[1, i].imshow(query[i].squeeze(), cmap='gray')
        axes[1, i].axis('off')
        axes[1, i].set_title(f'Query\nClass {query_labels[i].item()}',
                            fontsize=10)

    plt.suptitle('5-way 1-shot ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã®ä¾‹', fontsize=14)
    plt.tight_layout()
    plt.show()

except NameError:
    print("æ³¨: Omniglotãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™")
</code></pre>

<hr>

<h2>1.5 å®Ÿè·µ: ã‚·ãƒ³ãƒ—ãƒ«ãªFew-Shotåˆ†é¡</h2>

<h3>åŸºæœ¬çš„ãªN-way K-shotã‚¿ã‚¹ã‚¯</h3>

<p>æœ€ã‚‚ã‚·ãƒ³ãƒ—ãƒ«ãªFew-Shotåˆ†é¡ã¯ã€ã‚µãƒãƒ¼ãƒˆã‚»ãƒƒãƒˆã¨ã‚¯ã‚¨ãƒªã‚µãƒ³ãƒ—ãƒ«ã®è·é›¢ã‚’è¨ˆç®—ã™ã‚‹æ–¹æ³•ã§ã™ã€‚</p>

<h3>Nearest Neighbor Baseline</h3>

<pre><code class="language-python">import torch
import torch.nn.functional as F
import numpy as np

class NearestNeighborClassifier:
    """
    æœ€è¿‘å‚æ³•ã«ã‚ˆã‚‹Few-Shotåˆ†é¡ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³
    """
    def __init__(self, distance_metric='euclidean'):
        self.distance_metric = distance_metric

    def fit(self, support_set, support_labels):
        """
        Support Setã‚’è¨˜æ†¶

        Args:
            support_set: (N*K, feature_dim) tensor
            support_labels: (N*K,) tensor
        """
        self.support_set = support_set
        self.support_labels = support_labels

    def predict(self, query_set):
        """
        Query Setã‚’åˆ†é¡

        Args:
            query_set: (N*Q, feature_dim) tensor

        Returns:
            predictions: (N*Q,) tensor
        """
        n_queries = query_set.size(0)
        predictions = []

        for i in range(n_queries):
            query = query_set[i]

            # å…¨ã‚µãƒãƒ¼ãƒˆã‚µãƒ³ãƒ—ãƒ«ã¨ã®è·é›¢è¨ˆç®—
            if self.distance_metric == 'euclidean':
                distances = torch.norm(self.support_set - query, dim=1)
            elif self.distance_metric == 'cosine':
                # ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ï¼ˆè·é›¢ã«å¤‰æ›ï¼‰
                similarities = F.cosine_similarity(
                    self.support_set,
                    query.unsqueeze(0),
                    dim=1
                )
                distances = 1 - similarities

            # æœ€è¿‘å‚ã®ãƒ©ãƒ™ãƒ«ã‚’äºˆæ¸¬
            nearest_idx = torch.argmin(distances)
            pred_label = self.support_labels[nearest_idx]
            predictions.append(pred_label)

        return torch.tensor(predictions)

    def evaluate(self, query_set, query_labels):
        """
        ç²¾åº¦ã‚’è¨ˆç®—
        """
        predictions = self.predict(query_set)
        accuracy = (predictions == query_labels).float().mean()
        return accuracy.item()

# å®Ÿé¨“: ã‚·ãƒ³ãƒ—ãƒ«ãª2æ¬¡å…ƒãƒ‡ãƒ¼ã‚¿ã§å‹•ä½œç¢ºèª
def test_nearest_neighbor():
    """Nearest Neighborã®å‹•ä½œç¢ºèª"""

    # 5-way 1-shot ã‚¿ã‚¹ã‚¯ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
    n_way = 5
    k_shot = 1
    n_query = 10

    # Support Setç”Ÿæˆï¼ˆå„ã‚¯ãƒ©ã‚¹ã‚’ç•°ãªã‚‹é ˜åŸŸã«é…ç½®ï¼‰
    support_set = []
    support_labels = []

    for cls in range(n_way):
        # ã‚¯ãƒ©ã‚¹ã”ã¨ã«ä¸­å¿ƒã‚’è¨­å®š
        center = torch.tensor([cls * 2.0, cls * 2.0])
        sample = center + torch.randn(2) * 0.5  # ãƒã‚¤ã‚ºè¿½åŠ 
        support_set.append(sample)
        support_labels.append(cls)

    support_set = torch.stack(support_set)
    support_labels = torch.tensor(support_labels)

    # Query Setç”Ÿæˆï¼ˆå„ã‚¯ãƒ©ã‚¹ã‹ã‚‰è¤‡æ•°ã‚µãƒ³ãƒ—ãƒ«ï¼‰
    query_set = []
    query_labels = []

    for cls in range(n_way):
        center = torch.tensor([cls * 2.0, cls * 2.0])
        for _ in range(n_query // n_way):
            sample = center + torch.randn(2) * 0.5
            query_set.append(sample)
            query_labels.append(cls)

    query_set = torch.stack(query_set)
    query_labels = torch.tensor(query_labels)

    # Nearest Neighboråˆ†é¡
    nn_classifier = NearestNeighborClassifier(distance_metric='euclidean')
    nn_classifier.fit(support_set, support_labels)
    accuracy = nn_classifier.evaluate(query_set, query_labels)

    print(f"=== Nearest Neighbor ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ ===")
    print(f"ã‚¿ã‚¹ã‚¯: {n_way}-way {k_shot}-shot")
    print(f"ç²¾åº¦: {accuracy:.3f}")

    # å¯è¦–åŒ–
    import matplotlib.pyplot as plt

    plt.figure(figsize=(10, 8))

    colors = ['red', 'blue', 'green', 'orange', 'purple']

    # Support Set
    for cls in range(n_way):
        cls_support = support_set[support_labels == cls]
        plt.scatter(cls_support[:, 0], cls_support[:, 1],
                   c=colors[cls], s=300, marker='*',
                   edgecolors='black', linewidth=2,
                   label=f'Support Class {cls}', zorder=5)

    # Query Set
    for cls in range(n_way):
        cls_query = query_set[query_labels == cls]
        plt.scatter(cls_query[:, 0], cls_query[:, 1],
                   c=colors[cls], s=100, alpha=0.5,
                   marker='o', edgecolors='black')

    # äºˆæ¸¬çµæœ
    predictions = nn_classifier.predict(query_set)
    correct = (predictions == query_labels)
    incorrect = ~correct

    # èª¤åˆ†é¡ã‚’Ã—ã§ç¤ºã™
    if incorrect.any():
        plt.scatter(query_set[incorrect, 0], query_set[incorrect, 1],
                   s=200, marker='x', c='black', linewidth=3,
                   label='èª¤åˆ†é¡', zorder=6)

    plt.xlabel('ç‰¹å¾´æ¬¡å…ƒ1', fontsize=12)
    plt.ylabel('ç‰¹å¾´æ¬¡å…ƒ2', fontsize=12)
    plt.title(f'Nearest Neighbor: {n_way}-way {k_shot}-shot\nç²¾åº¦: {accuracy:.1%}',
             fontsize=14)
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.show()

# å®Ÿé¨“å®Ÿè¡Œ
test_nearest_neighbor()
</code></pre>

<h3>è©•ä¾¡ãƒ—ãƒ­ãƒˆã‚³ãƒ«</h3>

<p>Few-Shotå­¦ç¿’ã®æ¨™æº–çš„ãªè©•ä¾¡æ–¹æ³•ï¼š</p>

<ol>
<li><strong>å¤šæ•°ã®ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ç”Ÿæˆ</strong>ï¼ˆä¾‹ï¼š600ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ï¼‰</li>
<li>å„ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã§ç²¾åº¦ã‚’è¨ˆç®—</li>
<li>å¹³å‡ç²¾åº¦ã¨æ¨™æº–åå·®ã‚’å ±å‘Š</li>
</ol>

<pre><code class="language-python">def evaluate_fewshot_model(model, dataset_sampler, n_episodes=600):
    """
    Few-Shotãƒ¢ãƒ‡ãƒ«ã®æ¨™æº–è©•ä¾¡ãƒ—ãƒ­ãƒˆã‚³ãƒ«

    Args:
        model: Few-Shotåˆ†é¡ãƒ¢ãƒ‡ãƒ«
        dataset_sampler: ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‚µãƒ³ãƒ—ãƒ©ãƒ¼
        n_episodes: è©•ä¾¡ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰æ•°

    Returns:
        mean_accuracy: å¹³å‡ç²¾åº¦
        std_accuracy: æ¨™æº–åå·®
    """
    accuracies = []

    for episode in range(n_episodes):
        # ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
        support, query, support_labels, query_labels = \
            dataset_sampler.sample_episode()

        # å¹³å¦åŒ–ï¼ˆç‰¹å¾´é‡ã¨ã—ã¦æ‰±ã†ï¼‰
        support_flat = support.view(support.size(0), -1)
        query_flat = query.view(query.size(0), -1)

        # ãƒ¢ãƒ‡ãƒ«ã§è©•ä¾¡
        model.fit(support_flat, support_labels)
        accuracy = model.evaluate(query_flat, query_labels)
        accuracies.append(accuracy)

        if (episode + 1) % 100 == 0:
            print(f"ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ {episode + 1}/{n_episodes} å®Œäº†")

    mean_acc = np.mean(accuracies)
    std_acc = np.std(accuracies)

    # 95% ä¿¡é ¼åŒºé–“
    conf_interval = 1.96 * std_acc / np.sqrt(n_episodes)

    print(f"\n=== è©•ä¾¡çµæœ ({n_episodes} ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰) ===")
    print(f"å¹³å‡ç²¾åº¦: {mean_acc:.3f} Â± {conf_interval:.3f}")
    print(f"æ¨™æº–åå·®: {std_acc:.3f}")
    print(f"æœ€å°ç²¾åº¦: {min(accuracies):.3f}")
    print(f"æœ€å¤§ç²¾åº¦: {max(accuracies):.3f}")

    # ç²¾åº¦åˆ†å¸ƒã®å¯è¦–åŒ–
    import matplotlib.pyplot as plt

    plt.figure(figsize=(10, 6))
    plt.hist(accuracies, bins=30, alpha=0.7, edgecolor='black', color='skyblue')
    plt.axvline(mean_acc, color='red', linestyle='--', linewidth=2,
               label=f'å¹³å‡: {mean_acc:.3f}')
    plt.axvline(mean_acc - conf_interval, color='orange', linestyle=':',
               linewidth=2, label=f'95% CI')
    plt.axvline(mean_acc + conf_interval, color='orange', linestyle=':',
               linewidth=2)
    plt.xlabel('ç²¾åº¦', fontsize=12)
    plt.ylabel('é »åº¦', fontsize=12)
    plt.title(f'Few-Shotç²¾åº¦åˆ†å¸ƒ ({n_episodes} ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰)', fontsize=14)
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.show()

    return mean_acc, std_acc

# è©•ä¾¡å®Ÿè¡Œï¼ˆOmniglotãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰
try:
    nn_model = NearestNeighborClassifier(distance_metric='euclidean')
    mean_acc, std_acc = evaluate_fewshot_model(
        nn_model,
        sampler,
        n_episodes=100  # ãƒ‡ãƒ¢ç”¨ã«å°‘ãªã‚
    )
except NameError:
    print("æ³¨: Omniglotãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨ã‚µãƒ³ãƒ—ãƒ©ãƒ¼ãŒå¿…è¦ã§ã™")
</code></pre>

<blockquote>
<p><strong>é‡è¦</strong>: Nearest Neighborãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã¯ã€ã‚·ãƒ³ãƒ—ãƒ«ãªãŒã‚‰å¤šãã®Few-Shotã‚¿ã‚¹ã‚¯ã§ç«¶äº‰åŠ›ã®ã‚ã‚‹æ€§èƒ½ã‚’ç¤ºã—ã¾ã™ã€‚</p>
</blockquote>

<hr>

<h2>1.6 æœ¬ç« ã®ã¾ã¨ã‚</h2>

<h3>å­¦ã‚“ã ã“ã¨</h3>

<ol>
<li><p><strong>ãƒ¡ã‚¿å­¦ç¿’ã®æœ¬è³ª</strong></p>
<ul>
<li>Learning to Learn: å­¦ç¿’æ–¹æ³•ãã®ã‚‚ã®ã‚’å­¦ç¿’</li>
<li>å°‘æ•°ã‚µãƒ³ãƒ—ãƒ«ã§ã®é«˜é€Ÿé©å¿œãŒç›®æ¨™</li>
<li>ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã®è¨“ç·´ãƒ—ãƒ­ã‚»ã‚¹</li>
</ul></li>

<li><p><strong>Few-Shot Learningå•é¡Œè¨­å®š</strong></p>
<ul>
<li>N-way K-shotåˆ†é¡ã®å®šç¾©</li>
<li>Support Setã¨Query Setã®å½¹å‰²</li>
<li>è©•ä¾¡ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã®æ¨™æº–åŒ–</li>
</ul></li>

<li><p><strong>ãƒ¡ã‚¿å­¦ç¿’ã®3ã¤ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ</strong></p>
<ul>
<li>Metric-based: è·é›¢å­¦ç¿’</li>
<li>Model-based: ãƒ¡ãƒ¢ãƒªã¨å†å¸°</li>
<li>Optimization-based: è‰¯ã„åˆæœŸåŒ–</li>
</ul></li>

<li><p><strong>Omniglotãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ</strong></p>
<ul>
<li>1,623ã‚¯ãƒ©ã‚¹ã€å„20ã‚µãƒ³ãƒ—ãƒ«</li>
<li>ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ç”Ÿæˆã®å®Ÿè£…</li>
<li>Few-Shotå­¦ç¿’ã®æ¨™æº–ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯</li>
</ul></li>

<li><p><strong>ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³å®Ÿè£…</strong></p>
<ul>
<li>Nearest Neighboråˆ†é¡å™¨</li>
<li>æ¨™æº–è©•ä¾¡ãƒ—ãƒ­ãƒˆã‚³ãƒ«</li>
<li>ç²¾åº¦ã¨ä¿¡é ¼åŒºé–“ã®å ±å‘Š</li>
</ul></li>
</ol>

<h3>ãƒ¡ã‚¿å­¦ç¿’ã®é‡è¦æ¦‚å¿µ</h3>

<table>
<thead>
<tr>
<th>æ¦‚å¿µ</th>
<th>èª¬æ˜</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰</strong></td>
<td>1ã¤ã®å­¦ç¿’ã‚¿ã‚¹ã‚¯ï¼ˆSupport + Queryï¼‰</td>
</tr>
<tr>
<td><strong>ãƒ¡ã‚¿è¨“ç·´</strong></td>
<td>å¤šæ•°ã®ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‹ã‚‰é©å¿œèƒ½åŠ›ã‚’å­¦ç¿’</td>
</tr>
<tr>
<td><strong>ãƒ¡ã‚¿ãƒ†ã‚¹ãƒˆ</strong></td>
<td>æœªçŸ¥ã®ã‚¿ã‚¹ã‚¯ã§ã®é©å¿œæ€§èƒ½ã‚’è©•ä¾¡</td>
</tr>
<tr>
<td><strong>Few-Shot</strong></td>
<td>å°‘æ•°ã‚µãƒ³ãƒ—ãƒ«ï¼ˆé€šå¸¸1ã€œ5å€‹ï¼‰ã§ã®å­¦ç¿’</td>
</tr>
<tr>
<td><strong>Zero-Shot</strong></td>
<td>è¨“ç·´ã‚µãƒ³ãƒ—ãƒ«ãªã—ã§ã®æ¨è«–</td>
</tr>
</tbody>
</table>

<h3>æ¬¡ã®ç« ã¸</h3>

<p>ç¬¬2ç« ã§ã¯ã€<strong>Prototypical Networks</strong>ã‚’è©³ã—ãå­¦ã³ã¾ã™ï¼š</p>
<ul>
<li>ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ãƒ™ãƒ¼ã‚¹ã®åˆ†é¡</li>
<li>åŸ‹ã‚è¾¼ã¿ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®è¨­è¨ˆ</li>
<li>ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰è¨“ç·´ã®å®Ÿè£…</li>
<li>Omniglotã§ã®æ€§èƒ½è©•ä¾¡</li>
<li>ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°</li>
</ul>

<hr>

<h2>æ¼”ç¿’å•é¡Œ</h2>

<h3>å•é¡Œ1ï¼ˆé›£æ˜“åº¦ï¼šeasyï¼‰</h3>
<p>ãƒ¡ã‚¿å­¦ç¿’ã¨é€šå¸¸ã®æ©Ÿæ¢°å­¦ç¿’ã®é•ã„ã‚’ã€ã€Œå­¦ç¿’å˜ä½ã€ã€Œè¨“ç·´ãƒ‡ãƒ¼ã‚¿ã€ã€Œè©•ä¾¡æ–¹æ³•ã€ã®3ã¤ã®è¦³ç‚¹ã‹ã‚‰èª¬æ˜ã—ã¦ãã ã•ã„ã€‚</p>

<details>
<summary>è§£ç­”ä¾‹</summary>

<p><strong>è§£ç­”</strong>ï¼š</p>

<table>
<thead>
<tr>
<th>è¦³ç‚¹</th>
<th>é€šå¸¸ã®æ©Ÿæ¢°å­¦ç¿’</th>
<th>ãƒ¡ã‚¿å­¦ç¿’</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>å­¦ç¿’å˜ä½</strong></td>
<td>å€‹åˆ¥ã‚µãƒ³ãƒ—ãƒ«ï¼ˆç”»åƒã€ãƒ†ã‚­ã‚¹ãƒˆãªã©ï¼‰</td>
<td>ã‚¿ã‚¹ã‚¯å…¨ä½“ï¼ˆã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰å˜ä½ï¼‰</td>
</tr>
<tr>
<td><strong>è¨“ç·´ãƒ‡ãƒ¼ã‚¿</strong></td>
<td>1ã¤ã®ã‚¿ã‚¹ã‚¯ã«å¯¾ã™ã‚‹å¤§é‡ãƒ©ãƒ™ãƒ«ä»˜ããƒ‡ãƒ¼ã‚¿</td>
<td>å¤šæ§˜ãªã‚¿ã‚¹ã‚¯ã‹ã‚‰ã®å°‘æ•°ã‚µãƒ³ãƒ—ãƒ«é›†åˆ</td>
</tr>
<tr>
<td><strong>è©•ä¾¡æ–¹æ³•</strong></td>
<td>åŒä¸€åˆ†å¸ƒã®ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã§ã®ç²¾åº¦</td>
<td>æœªçŸ¥ã‚¿ã‚¹ã‚¯ã¸ã®é©å¿œé€Ÿåº¦ã¨ç²¾åº¦</td>
</tr>
</tbody>
</table>

<p><strong>å…·ä½“ä¾‹</strong>ï¼š</p>
<ul>
<li><strong>é€šå¸¸å­¦ç¿’</strong>: 10ä¸‡æšã®çŒ«vsçŠ¬ç”»åƒã§åˆ†é¡å™¨ã‚’è¨“ç·´ â†’ åŒã˜åˆ†å¸ƒã®ãƒ†ã‚¹ãƒˆç”»åƒã§è©•ä¾¡</li>
<li><strong>ãƒ¡ã‚¿å­¦ç¿’</strong>: 1000ç¨®é¡ã®å‹•ç‰©ï¼ˆå„5æšï¼‰ã§å­¦ç¿’ â†’ æ–°ç¨®ã®å‹•ç‰©ã‚’5æšã ã‘è¦‹ã¦åˆ†é¡</li>
</ul>

</details>

<h3>å•é¡Œ2ï¼ˆé›£æ˜“åº¦ï¼šmediumï¼‰</h3>
<p>5-way 3-shotåˆ†é¡ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦ã€Support Setã¨Query Setï¼ˆå„ã‚¯ãƒ©ã‚¹5ã‚µãƒ³ãƒ—ãƒ«ï¼‰ã®ã‚µã‚¤ã‚ºã‚’ãã‚Œãã‚Œè¨ˆç®—ã—ã¦ãã ã•ã„ã€‚ã¾ãŸã€1ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‚ãŸã‚Šã®ç·ã‚µãƒ³ãƒ—ãƒ«æ•°ã‚‚æ±‚ã‚ã¦ãã ã•ã„ã€‚</p>

<details>
<summary>è§£ç­”ä¾‹</summary>

<p><strong>è§£ç­”</strong>ï¼š</p>

<p><strong>æ¡ä»¶</strong>ï¼š</p>
<ul>
<li>N-way = 5 ã‚¯ãƒ©ã‚¹</li>
<li>K-shot = 3 ã‚µãƒ³ãƒ—ãƒ«/ã‚¯ãƒ©ã‚¹ï¼ˆSupportï¼‰</li>
<li>Q = 5 ã‚µãƒ³ãƒ—ãƒ«/ã‚¯ãƒ©ã‚¹ï¼ˆQueryï¼‰</li>
</ul>

<p><strong>è¨ˆç®—</strong>ï¼š</p>

<ol>
<li><strong>Support Set ã‚µã‚¤ã‚º</strong>:
   $$\text{Support} = N \times K = 5 \times 3 = 15 \text{ ã‚µãƒ³ãƒ—ãƒ«}$$</li>

<li><strong>Query Set ã‚µã‚¤ã‚º</strong>:
   $$\text{Query} = N \times Q = 5 \times 5 = 25 \text{ ã‚µãƒ³ãƒ—ãƒ«}$$</li>

<li><strong>ç·ã‚µãƒ³ãƒ—ãƒ«æ•°</strong>:
   $$\text{Total} = \text{Support} + \text{Query} = 15 + 25 = 40 \text{ ã‚µãƒ³ãƒ—ãƒ«}$$</li>
</ol>

<p><strong>æ§‹é€ </strong>ï¼š</p>
<pre><code>Support Set (15ã‚µãƒ³ãƒ—ãƒ«):
  Class 0: [S_0_0, S_0_1, S_0_2]
  Class 1: [S_1_0, S_1_1, S_1_2]
  Class 2: [S_2_0, S_2_1, S_2_2]
  Class 3: [S_3_0, S_3_1, S_3_2]
  Class 4: [S_4_0, S_4_1, S_4_2]

Query Set (25ã‚µãƒ³ãƒ—ãƒ«):
  Class 0: [Q_0_0, Q_0_1, Q_0_2, Q_0_3, Q_0_4]
  Class 1: [Q_1_0, Q_1_1, Q_1_2, Q_1_3, Q_1_4]
  Class 2: [Q_2_0, Q_2_1, Q_2_2, Q_2_3, Q_2_4]
  Class 3: [Q_3_0, Q_3_1, Q_3_2, Q_3_3, Q_3_4]
  Class 4: [Q_4_0, Q_4_1, Q_4_2, Q_4_3, Q_4_4]
</code></pre>

</details>

<h3>å•é¡Œ3ï¼ˆé›£æ˜“åº¦ï¼šmediumï¼‰</h3>
<p>Metric-basedã€Model-basedã€Optimization-basedã®3ã¤ã®ãƒ¡ã‚¿å­¦ç¿’ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã«ã¤ã„ã¦ã€ãã‚Œãã‚Œã®åŸºæœ¬ã‚¢ã‚¤ãƒ‡ã‚¢ã¨ä»£è¡¨çš„ãªæ‰‹æ³•ã‚’1ã¤ãšã¤æŒ™ã’ã¦ãã ã•ã„ã€‚</p>

<details>
<summary>è§£ç­”ä¾‹</summary>

<p><strong>è§£ç­”</strong>ï¼š</p>

<table>
<thead>
<tr>
<th>ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ</th>
<th>åŸºæœ¬ã‚¢ã‚¤ãƒ‡ã‚¢</th>
<th>ä»£è¡¨æ‰‹æ³•</th>
<th>ç‰¹å¾´</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Metric-based</strong></td>
<td>è‰¯ã„è·é›¢ç©ºé–“ã‚’å­¦ç¿’ã—ã€<br>è¿‘å‚ã«åŸºã¥ã„ã¦åˆ†é¡</td>
<td>Prototypical<br>Networks</td>
<td>å„ã‚¯ãƒ©ã‚¹ã®ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ã‚’è¨ˆç®—ã—ã€<br>æœ€ã‚‚è¿‘ã„ã‚¯ãƒ©ã‚¹ã«åˆ†é¡</td>
</tr>
<tr>
<td><strong>Model-based</strong></td>
<td>ãƒ¡ãƒ¢ãƒªã‚„å†å¸°æ§‹é€ ã§<br>é«˜é€Ÿé©å¿œ</td>
<td>Memory-Augmented<br>Neural Networks</td>
<td>å¤–éƒ¨ãƒ¡ãƒ¢ãƒªã«éå»ã®çµŒé¨“ã‚’ä¿å­˜ã—ã€<br>æ–°ã‚¿ã‚¹ã‚¯ã§å‚ç…§</td>
</tr>
<tr>
<td><strong>Optimization-based</strong></td>
<td>è‰¯ã„åˆæœŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å­¦ç¿’ã—ã€<br>å°‘æ•°ã‚¹ãƒ†ãƒƒãƒ—ã§é©å¿œ</td>
<td>MAML<br>(Model-Agnostic Meta-Learning)</td>
<td>æ•°ã‚¹ãƒ†ãƒƒãƒ—ã®å‹¾é…é™ä¸‹ã§<br>é«˜ç²¾åº¦ã«åˆ°é”ã™ã‚‹åˆæœŸå€¤ã‚’å­¦ç¿’</td>
</tr>
</tbody>
</table>

<p><strong>ä½¿ã„åˆ†ã‘</strong>ï¼š</p>
<ul>
<li><strong>Metric-based</strong>: ã‚·ãƒ³ãƒ—ãƒ«ã§é«˜é€Ÿã€ç”»åƒåˆ†é¡ã«æœ€é©</li>
<li><strong>Model-based</strong>: è¤‡é›‘ãªã‚·ãƒ¼ã‚±ãƒ³ã‚·ãƒ£ãƒ«ã‚¿ã‚¹ã‚¯å‘ã‘</li>
<li><strong>Optimization-based</strong>: æ±ç”¨æ€§ãŒé«˜ãã€å¼·åŒ–å­¦ç¿’ã«ã‚‚é©ç”¨å¯èƒ½</li>
</ul>

</details>

<h3>å•é¡Œ4ï¼ˆé›£æ˜“åº¦ï¼šhardï¼‰</h3>
<p>Omniglotãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§5-way 1-shotåˆ†é¡ã‚’è¡Œã†éš›ã€ãƒ©ãƒ³ãƒ€ãƒ æ¨æ¸¬ã®ç²¾åº¦ã¨ã€ç†æƒ³çš„ãªNearest Neighboråˆ†é¡å™¨ã®æœŸå¾…ç²¾åº¦ã‚’æ¨å®šã—ã¦ãã ã•ã„ã€‚ã¾ãŸã€å®Ÿéš›ã®ãƒ¡ã‚¿å­¦ç¿’æ‰‹æ³•ãŒç›®æŒ‡ã™ã¹ãç²¾åº¦ç¯„å›²ã‚’è€ƒå¯Ÿã—ã¦ãã ã•ã„ã€‚</p>

<details>
<summary>è§£ç­”ä¾‹</summary>

<p><strong>è§£ç­”</strong>ï¼š</p>

<p><strong>1. ãƒ©ãƒ³ãƒ€ãƒ æ¨æ¸¬ã®ç²¾åº¦</strong>ï¼š</p>
<ul>
<li>5ã‚¯ãƒ©ã‚¹ã‹ã‚‰1ã¤ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«é¸ã¶</li>
<li>ç²¾åº¦ = 1/5 = <strong>20%</strong></li>
</ul>

<p><strong>2. ç†æƒ³çš„ãªNearest Neighboråˆ†é¡å™¨ã®æœŸå¾…ç²¾åº¦</strong>ï¼š</p>

<p>Omniglotã®ç‰¹æ€§ã‚’è€ƒæ…®ï¼š</p>
<ul>
<li>å„ã‚¯ãƒ©ã‚¹ã¯è¦–è¦šçš„ã«è­˜åˆ¥å¯èƒ½ï¼ˆç•°ãªã‚‹æ–‡å­—ï¼‰</li>
<li>åŒä¸€ã‚¯ãƒ©ã‚¹å†…ã®å¤‰å‹•ï¼ˆ20äººã®æ‰‹æ›¸ãï¼‰ã‚ã‚Š</li>
<li>ãƒ”ã‚¯ã‚»ãƒ«ãƒ™ãƒ¼ã‚¹ã®è·é›¢ã¯ä¸å®Œå…¨</li>
</ul>

<p>æœŸå¾…ç²¾åº¦: <strong>60-75%</strong>ç¨‹åº¦</p>

<p>ç†ç”±ï¼š</p>
<ul>
<li>Support Set ã¯1ã‚µãƒ³ãƒ—ãƒ«ã®ã¿ â†’ ã‚¯ãƒ©ã‚¹å†…å¤‰å‹•ã‚’æ‰ãˆã‚‰ã‚Œãªã„</li>
<li>ãƒ”ã‚¯ã‚»ãƒ«ãƒ¬ãƒ™ãƒ«ã®è·é›¢ã¯ã€å›è»¢ã‚„å¤‰å½¢ã«æ•æ„Ÿ</li>
<li>ãã‚Œã§ã‚‚ãƒ©ãƒ³ãƒ€ãƒ ã‚ˆã‚Šã¯é¥ã‹ã«è‰¯ã„</li>
</ul>

<p><strong>3. ãƒ¡ã‚¿å­¦ç¿’æ‰‹æ³•ã®ç›®æ¨™ç²¾åº¦ç¯„å›²</strong>ï¼š</p>

<table>
<thead>
<tr>
<th>æ‰‹æ³•ã‚¿ã‚¤ãƒ—</th>
<th>æœŸå¾…ç²¾åº¦</th>
<th>ç†ç”±</th>
</tr>
</thead>
<tbody>
<tr>
<td>ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ï¼ˆNNï¼‰</td>
<td>60-75%</td>
<td>ãƒ”ã‚¯ã‚»ãƒ«è·é›¢ã®ã¿</td>
</tr>
<tr>
<td>Metric-based</td>
<td>85-95%</td>
<td>å­¦ç¿’ã•ã‚ŒãŸåŸ‹ã‚è¾¼ã¿ç©ºé–“</td>
</tr>
<tr>
<td>Optimization-based</td>
<td>95-98%</td>
<td>ã‚¿ã‚¹ã‚¯ã”ã¨ã«é©å¿œ</td>
</tr>
<tr>
<td>æœ€å…ˆç«¯</td>
<td>98%+</td>
<td>ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µ + ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«</td>
</tr>
</tbody>
</table>

<p><strong>å®Ÿä¾‹ï¼ˆè«–æ–‡çµæœï¼‰</strong>ï¼š</p>
<ul>
<li>Siamese Networks: ~92%</li>
<li>Matching Networks: ~93%</li>
<li>Prototypical Networks: ~95%</li>
<li>MAML: ~95-98%</li>
</ul>

</details>

<h3>å•é¡Œ5ï¼ˆé›£æ˜“åº¦ï¼šhardï¼‰</h3>
<p>ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã‚’å®Œæˆã•ã›ã¦ã€ã‚·ãƒ³ãƒ—ãƒ«ãªPrototypeåˆ†é¡å™¨ã‚’å®Ÿè£…ã—ã¦ãã ã•ã„ã€‚å„ã‚¯ãƒ©ã‚¹ã®ã‚µãƒãƒ¼ãƒˆã‚µãƒ³ãƒ—ãƒ«ã®å¹³å‡ï¼ˆãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ï¼‰ã‚’è¨ˆç®—ã—ã€ã‚¯ã‚¨ãƒªã‚µãƒ³ãƒ—ãƒ«ã‚’æœ€ã‚‚è¿‘ã„ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ã®ã‚¯ãƒ©ã‚¹ã«åˆ†é¡ã™ã‚‹é–¢æ•°ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚</p>

<pre><code class="language-python">import torch

def prototype_classify(support_set, support_labels, query_set, n_way):
    """
    Prototypeãƒ™ãƒ¼ã‚¹ã®åˆ†é¡

    Args:
        support_set: (N*K, feature_dim) tensor
        support_labels: (N*K,) tensor
        query_set: (N*Q, feature_dim) tensor
        n_way: ã‚¯ãƒ©ã‚¹æ•°

    Returns:
        predictions: (N*Q,) tensor
    """
    # TODO: ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ã‚’è¨ˆç®—
    prototypes = None  # ã“ã“ã‚’å®Ÿè£…

    # TODO: è·é›¢ã‚’è¨ˆç®—ã—ã¦åˆ†é¡
    predictions = None  # ã“ã“ã‚’å®Ÿè£…

    return predictions
</code></pre>

<details>
<summary>è§£ç­”ä¾‹</summary>

<pre><code class="language-python">import torch

def prototype_classify(support_set, support_labels, query_set, n_way):
    """
    Prototypeãƒ™ãƒ¼ã‚¹ã®åˆ†é¡

    Args:
        support_set: (N*K, feature_dim) tensor
        support_labels: (N*K,) tensor
        query_set: (N*Q, feature_dim) tensor
        n_way: ã‚¯ãƒ©ã‚¹æ•°

    Returns:
        predictions: (N*Q,) tensor
    """
    # 1. å„ã‚¯ãƒ©ã‚¹ã®ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ã‚’è¨ˆç®—
    prototypes = []
    for c in range(n_way):
        # ã‚¯ãƒ©ã‚¹cã®ã‚µãƒãƒ¼ãƒˆã‚µãƒ³ãƒ—ãƒ«ã‚’æŠ½å‡º
        class_support = support_set[support_labels == c]
        # å¹³å‡ã‚’è¨ˆç®—ã—ã¦ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ã¨ã™ã‚‹
        prototype = class_support.mean(dim=0)
        prototypes.append(prototype)

    prototypes = torch.stack(prototypes)  # (n_way, feature_dim)

    # 2. å„ã‚¯ã‚¨ãƒªã‚µãƒ³ãƒ—ãƒ«ã‚’æœ€ã‚‚è¿‘ã„ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ã®ã‚¯ãƒ©ã‚¹ã«åˆ†é¡
    n_queries = query_set.size(0)
    predictions = []

    for i in range(n_queries):
        query = query_set[i]  # (feature_dim,)

        # å…¨ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ã¨ã®è·é›¢ã‚’è¨ˆç®—
        distances = torch.norm(prototypes - query, dim=1)  # (n_way,)

        # æœ€å°è·é›¢ã®ã‚¯ãƒ©ã‚¹ã‚’äºˆæ¸¬
        pred_class = torch.argmin(distances)
        predictions.append(pred_class)

    predictions = torch.stack(predictions)

    return predictions


# ãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰
def test_prototype_classifier():
    """Prototypeåˆ†é¡å™¨ã®ãƒ†ã‚¹ãƒˆ"""

    # 5-way 2-shot ã‚¿ã‚¹ã‚¯ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
    n_way = 5
    k_shot = 2
    n_query = 10
    feature_dim = 128

    # ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    support_set = torch.randn(n_way * k_shot, feature_dim)
    support_labels = torch.tensor([i for i in range(n_way) for _ in range(k_shot)])

    # Query Set: å„ã‚¯ãƒ©ã‚¹ã‹ã‚‰2ã‚µãƒ³ãƒ—ãƒ«
    query_set = torch.randn(n_query, feature_dim)
    query_labels = torch.tensor([i % n_way for i in range(n_query)])

    # åˆ†é¡å®Ÿè¡Œ
    predictions = prototype_classify(support_set, support_labels, query_set, n_way)

    # ç²¾åº¦è¨ˆç®—
    accuracy = (predictions == query_labels).float().mean()

    print("=== Prototypeåˆ†é¡å™¨ãƒ†ã‚¹ãƒˆ ===")
    print(f"ã‚¿ã‚¹ã‚¯: {n_way}-way {k_shot}-shot")
    print(f"Support Set: {support_set.shape}")
    print(f"Query Set: {query_set.shape}")
    print(f"äºˆæ¸¬: {predictions}")
    print(f"æ­£è§£: {query_labels}")
    print(f"ç²¾åº¦: {accuracy:.3f}")

    # ã‚ˆã‚Šç¾å®Ÿçš„ãªãƒ†ã‚¹ãƒˆ: ã‚¯ãƒ©ã‚¹ã‚’ç©ºé–“çš„ã«åˆ†é›¢
    print("\n=== åˆ†é›¢ã•ã‚ŒãŸã‚¯ãƒ©ã‚¹ã§ã®ãƒ†ã‚¹ãƒˆ ===")

    support_set = []
    support_labels = []
    query_set = []
    query_labels = []

    for c in range(n_way):
        # ã‚¯ãƒ©ã‚¹ã”ã¨ã«ä¸­å¿ƒã‚’è¨­å®š
        center = torch.randn(feature_dim) * 5  # å¤§ããåˆ†é›¢

        # Support samples
        for _ in range(k_shot):
            sample = center + torch.randn(feature_dim) * 0.5  # å°ã•ãªãƒã‚¤ã‚º
            support_set.append(sample)
            support_labels.append(c)

        # Query samples
        for _ in range(2):
            sample = center + torch.randn(feature_dim) * 0.5
            query_set.append(sample)
            query_labels.append(c)

    support_set = torch.stack(support_set)
    support_labels = torch.tensor(support_labels)
    query_set = torch.stack(query_set)
    query_labels = torch.tensor(query_labels)

    # åˆ†é¡å®Ÿè¡Œ
    predictions = prototype_classify(support_set, support_labels, query_set, n_way)
    accuracy = (predictions == query_labels).float().mean()

    print(f"åˆ†é›¢ãƒ‡ãƒ¼ã‚¿ã§ã®ç²¾åº¦: {accuracy:.3f}")
    print("ï¼ˆã‚¯ãƒ©ã‚¹ãŒæ˜ç¢ºã«åˆ†é›¢ã•ã‚Œã¦ã„ã‚‹å ´åˆã€ç²¾åº¦ã¯é«˜ããªã‚‹ï¼‰")

# ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
test_prototype_classifier()
</code></pre>

<p><strong>å‡ºåŠ›ä¾‹</strong>ï¼š</p>
<pre><code>=== Prototypeåˆ†é¡å™¨ãƒ†ã‚¹ãƒˆ ===
ã‚¿ã‚¹ã‚¯: 5-way 2-shot
Support Set: torch.Size([10, 128])
Query Set: torch.Size([10, 128])
äºˆæ¸¬: tensor([1, 3, 0, 2, 4, 0, 1, 2, 3, 4])
æ­£è§£: tensor([0, 1, 2, 3, 4, 0, 1, 2, 3, 4])
ç²¾åº¦: 0.300

=== åˆ†é›¢ã•ã‚ŒãŸã‚¯ãƒ©ã‚¹ã§ã®ãƒ†ã‚¹ãƒˆ ===
åˆ†é›¢ãƒ‡ãƒ¼ã‚¿ã§ã®ç²¾åº¦: 1.000
ï¼ˆã‚¯ãƒ©ã‚¹ãŒæ˜ç¢ºã«åˆ†é›¢ã•ã‚Œã¦ã„ã‚‹å ´åˆã€ç²¾åº¦ã¯é«˜ããªã‚‹ï¼‰
</code></pre>

<p><strong>è§£èª¬</strong>ï¼š</p>
<ol>
<li><strong>ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—è¨ˆç®—</strong>: å„ã‚¯ãƒ©ã‚¹ã®ã‚µãƒãƒ¼ãƒˆã‚µãƒ³ãƒ—ãƒ«ã®å¹³å‡ã‚’å–ã‚‹</li>
<li><strong>è·é›¢è¨ˆç®—</strong>: ã‚¯ã‚¨ãƒªã‚µãƒ³ãƒ—ãƒ«ã¨å…¨ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—é–“ã®ãƒ¦ãƒ¼ã‚¯ãƒªãƒƒãƒ‰è·é›¢</li>
<li><strong>åˆ†é¡</strong>: æœ€å°è·é›¢ã®ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ã®ã‚¯ãƒ©ã‚¹ã‚’äºˆæ¸¬</li>
<li><strong>æ€§èƒ½</strong>: ã‚¯ãƒ©ã‚¹ãŒç©ºé–“çš„ã«åˆ†é›¢ã•ã‚Œã¦ã„ã‚‹å ´åˆã€é«˜ç²¾åº¦ã‚’é”æˆ</li>
</ol>

</details>

<hr>

<h2>å‚è€ƒæ–‡çŒ®</h2>

<ol>
<li>Vinyals, O., et al. (2016). "Matching Networks for One Shot Learning." <em>NeurIPS</em>.</li>
<li>Snell, J., Swersky, K., & Zemel, R. (2017). "Prototypical Networks for Few-shot Learning." <em>NeurIPS</em>.</li>
<li>Finn, C., Abbeel, P., & Levine, S. (2017). "Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks." <em>ICML</em>.</li>
<li>Lake, B. M., et al. (2015). "Human-level concept learning through probabilistic program induction." <em>Science</em>.</li>
<li>Hospedales, T., et al. (2020). "Meta-Learning in Neural Networks: A Survey." <em>arXiv:2004.05439</em>.</li>
</ol>

<div class="navigation">
    <a href="index.html" class="nav-button">â† ã‚·ãƒªãƒ¼ã‚ºç›®æ¬¡</a>
    <a href="chapter2-prototypical-networks.html" class="nav-button">æ¬¡ã®ç« : Prototypical Networks â†’</a>
</div>

    </main>

    
    <section class="disclaimer">
        <h3>å…è²¬äº‹é …</h3>
        <ul>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯æ•™è‚²ãƒ»ç ”ç©¶ãƒ»æƒ…å ±æä¾›ã®ã¿ã‚’ç›®çš„ã¨ã—ã¦ãŠã‚Šã€å°‚é–€çš„ãªåŠ©è¨€(æ³•å¾‹ãƒ»ä¼šè¨ˆãƒ»æŠ€è¡“çš„ä¿è¨¼ãªã©)ã‚’æä¾›ã™ã‚‹ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŠã‚ˆã³ä»˜éšã™ã‚‹ã‚³ãƒ¼ãƒ‰ä¾‹ã¯ã€Œç¾çŠ¶æœ‰å§¿(AS IS)ã€ã§æä¾›ã•ã‚Œã€æ˜ç¤ºã¾ãŸã¯é»™ç¤ºã‚’å•ã‚ãšã€å•†å“æ€§ã€ç‰¹å®šç›®çš„é©åˆæ€§ã€æ¨©åˆ©éä¾µå®³ã€æ­£ç¢ºæ€§ãƒ»å®Œå…¨æ€§ã€å‹•ä½œãƒ»å®‰å…¨æ€§ç­‰ã„ã‹ãªã‚‹ä¿è¨¼ã‚‚ã—ã¾ã›ã‚“ã€‚</li>
            <li>å¤–éƒ¨ãƒªãƒ³ã‚¯ã€ç¬¬ä¸‰è€…ãŒæä¾›ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ»ãƒ„ãƒ¼ãƒ«ãƒ»ãƒ©ã‚¤ãƒ–ãƒ©ãƒªç­‰ã®å†…å®¹ãƒ»å¯ç”¨æ€§ãƒ»å®‰å…¨æ€§ã«ã¤ã„ã¦ã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯ä¸€åˆ‡ã®è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®åˆ©ç”¨ãƒ»å®Ÿè¡Œãƒ»è§£é‡ˆã«ã‚ˆã‚Šç›´æ¥çš„ãƒ»é–“æ¥çš„ãƒ»ä»˜éšçš„ãƒ»ç‰¹åˆ¥ãƒ»çµæœçš„ãƒ»æ‡²ç½°çš„æå®³ãŒç”Ÿã˜ãŸå ´åˆã§ã‚‚ã€é©ç”¨æ³•ã§è¨±å®¹ã•ã‚Œã‚‹æœ€å¤§é™ã®ç¯„å›²ã§ã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å†…å®¹ã¯ã€äºˆå‘Šãªãå¤‰æ›´ãƒ»æ›´æ–°ãƒ»æä¾›åœæ­¢ã•ã‚Œã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®è‘—ä½œæ¨©ãƒ»ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯æ˜è¨˜ã•ã‚ŒãŸæ¡ä»¶(ä¾‹: CC BY 4.0)ã«å¾“ã„ã¾ã™ã€‚å½“è©²ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯é€šå¸¸ã€ç„¡ä¿è¨¼æ¡é …ã‚’å«ã¿ã¾ã™ã€‚</li>
        </ul>
    </section>

<footer>
        <p><strong>ä½œæˆè€…</strong>: AI Terakoya Content Team</p>
        <p><strong>ãƒãƒ¼ã‚¸ãƒ§ãƒ³</strong>: 1.0 | <strong>ä½œæˆæ—¥</strong>: 2025-10-23</p>
        <p><strong>ãƒ©ã‚¤ã‚»ãƒ³ã‚¹</strong>: Creative Commons BY 4.0</p>
        <p>Â© 2025 AI Terakoya. All rights reserved.</p>
    </footer>
</body>
</html>
