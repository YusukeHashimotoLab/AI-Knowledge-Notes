<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
<meta content="ç¬¬2ç« ï¼šVAEï¼ˆVariational Autoencoderï¼‰ - AI Terakoya" name="description"/>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ç¬¬2ç« ï¼šVAEï¼ˆVariational Autoencoderï¼‰ - AI Terakoya</title>

    <style>
        :root {
            --color-primary: #2c3e50;
            --color-primary-dark: #1a252f;
            --color-accent: #7b2cbf;
            --color-accent-light: #9d4edd;
            --color-text: #2d3748;
            --color-text-light: #4a5568;
            --color-bg: #ffffff;
            --color-bg-alt: #f7fafc;
            --color-border: #e2e8f0;
            --color-code-bg: #f8f9fa;
            --color-link: #3182ce;
            --color-link-hover: #2c5aa0;

            --spacing-xs: 0.5rem;
            --spacing-sm: 1rem;
            --spacing-md: 1.5rem;
            --spacing-lg: 2rem;
            --spacing-xl: 3rem;

            --font-body: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            --font-mono: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;

            --border-radius: 8px;
            --box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: var(--font-body);
            line-height: 1.7;
            color: var(--color-text);
            background-color: var(--color-bg);
            font-size: 16px;
        }

        header {
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            padding: var(--spacing-xl) var(--spacing-md);
            margin-bottom: var(--spacing-xl);
            box-shadow: var(--box-shadow);
        }

        .header-content {
            max-width: 900px;
            margin: 0 auto;
        }

        h1 {
            font-size: 2rem;
            font-weight: 700;
            margin-bottom: var(--spacing-sm);
            line-height: 1.2;
        }

        .subtitle {
            font-size: 1.1rem;
            opacity: 0.95;
            font-weight: 400;
            margin-bottom: var(--spacing-md);
        }

        .meta {
            display: flex;
            flex-wrap: wrap;
            gap: var(--spacing-md);
            font-size: 0.9rem;
            opacity: 0.9;
        }

        .meta-item {
            display: flex;
            align-items: center;
            gap: 0.3rem;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 0 var(--spacing-md) var(--spacing-xl);
        }

        h2 {
            font-size: 1.75rem;
            color: var(--color-primary);
            margin-top: var(--spacing-xl);
            margin-bottom: var(--spacing-md);
            padding-bottom: var(--spacing-xs);
            border-bottom: 3px solid var(--color-accent);
        }

        h3 {
            font-size: 1.4rem;
            color: var(--color-primary);
            margin-top: var(--spacing-lg);
            margin-bottom: var(--spacing-sm);
        }

        h4 {
            font-size: 1.1rem;
            color: var(--color-primary-dark);
            margin-top: var(--spacing-md);
            margin-bottom: var(--spacing-sm);
        }

        p {
            margin-bottom: var(--spacing-md);
            color: var(--color-text);
        }

        a {
            color: var(--color-link);
            text-decoration: none;
            transition: color 0.2s;
        }

        a:hover {
            color: var(--color-link-hover);
            text-decoration: underline;
        }

        ul, ol {
            margin-left: var(--spacing-lg);
            margin-bottom: var(--spacing-md);
        }

        li {
            margin-bottom: var(--spacing-xs);
            color: var(--color-text);
        }

        pre {
            background-color: var(--color-code-bg);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            overflow-x: auto;
            margin-bottom: var(--spacing-md);
            font-family: var(--font-mono);
            font-size: 0.9rem;
            line-height: 1.5;
        }

        code {
            font-family: var(--font-mono);
            font-size: 0.9em;
            background-color: var(--color-code-bg);
            padding: 0.2em 0.4em;
            border-radius: 3px;
        }

        pre code {
            background-color: transparent;
            padding: 0;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: var(--spacing-md);
            font-size: 0.95rem;
        }

        th, td {
            border: 1px solid var(--color-border);
            padding: var(--spacing-sm);
            text-align: left;
        }

        th {
            background-color: var(--color-bg-alt);
            font-weight: 600;
            color: var(--color-primary);
        }

        blockquote {
            border-left: 4px solid var(--color-accent);
            padding-left: var(--spacing-md);
            margin: var(--spacing-md) 0;
            color: var(--color-text-light);
            font-style: italic;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        .mermaid {
            text-align: center;
            margin: var(--spacing-lg) 0;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        details {
            background-color: var(--color-bg-alt);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            margin-bottom: var(--spacing-md);
        }

        summary {
            cursor: pointer;
            font-weight: 600;
            color: var(--color-primary);
            user-select: none;
            padding: var(--spacing-xs);
            margin: calc(-1 * var(--spacing-md));
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        summary:hover {
            background-color: rgba(123, 44, 191, 0.1);
        }

        details[open] summary {
            margin-bottom: var(--spacing-md);
            border-bottom: 1px solid var(--color-border);
        }

        .navigation {
            display: flex;
            justify-content: space-between;
            gap: var(--spacing-md);
            margin: var(--spacing-xl) 0;
            padding-top: var(--spacing-lg);
            border-top: 2px solid var(--color-border);
        }

        .nav-button {
            flex: 1;
            padding: var(--spacing-md);
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            border-radius: var(--border-radius);
            text-align: center;
            font-weight: 600;
            transition: transform 0.2s, box-shadow 0.2s;
            box-shadow: var(--box-shadow);
        }

        .nav-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
            text-decoration: none;
        }

        footer {
            margin-top: var(--spacing-xl);
            padding: var(--spacing-lg) var(--spacing-md);
            background-color: var(--color-bg-alt);
            border-top: 1px solid var(--color-border);
            text-align: center;
            font-size: 0.9rem;
            color: var(--color-text-light);
        }
        .disclaimer {
            max-width: 900px;
            margin: 2rem auto;
            padding: 1.5rem;
            background: #f8f9fa;
            border-left: 4px solid #6c757d;
            border-radius: 4px;
        }

        .disclaimer h3 {
            color: #495057;
            margin-bottom: 1rem;
            font-size: 1.1rem;
        }

        .disclaimer ul {
            list-style: none;
            padding-left: 0;
        }

        .disclaimer li {
            padding: 0.5rem 0;
            padding-left: 1.5rem;
            position: relative;
            font-size: 0.9rem;
            color: #6c757d;
            line-height: 1.6;
        }

        .disclaimer li::before {
            content: "âš ï¸";
            position: absolute;
            left: 0;
        }


        @media (max-width: 768px) {
            h1 {
                font-size: 1.5rem;
            }

            h2 {
                font-size: 1.4rem;
            }

            h3 {
                font-size: 1.2rem;
            }

            .meta {
                font-size: 0.85rem;
            }

            .navigation {
                flex-direction: column;
            }

            table {
                font-size: 0.85rem;
            }

            th, td {
                padding: var(--spacing-xs);
            }
        }
    
        
    
        /* Breadcrumb styles */
        .breadcrumb {
            background: #f7fafc;
            padding: 0.75rem 1rem;
            border-bottom: 1px solid #e2e8f0;
            font-size: 0.9rem;
        }

        .breadcrumb-content {
            max-width: 900px;
            margin: 0 auto;
            display: flex;
            align-items: center;
            flex-wrap: wrap;
            gap: 0.5rem;
        }

        .breadcrumb a {
            color: #667eea;
            text-decoration: none;
            transition: color 0.2s;
        }

        .breadcrumb a:hover {
            color: #764ba2;
            text-decoration: underline;
        }

        .breadcrumb-separator {
            color: #a0aec0;
            margin: 0 0.25rem;
        }

        .breadcrumb-current {
            color: #4a5568;
            font-weight: 500;
        }
    </style>

    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
        mermaid.initialize({ startOnLoad: true, theme: 'default' });
    </script>

    <!-- MathJax for LaTeX equation rendering -->
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                displayMath: [['$$', '$$'], ['\\[', '\\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
                ignoreHtmlClass: 'mermaid'
            }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" async></script>

    <style>
        /* Locale Switcher Styles */
        .locale-switcher {
            display: flex;
            align-items: center;
            gap: 0.5rem;
            padding: 0.5rem 1rem;
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
            border-radius: 6px;
            font-size: 0.9rem;
            margin-bottom: 1rem;
            box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);
        }

        .current-locale {
            font-weight: 600;
            color: #7b2cbf;
            display: flex;
            align-items: center;
            gap: 0.25rem;
        }

        .locale-separator {
            color: #adb5bd;
            font-weight: 300;
        }

        .locale-link {
            color: #f093fb;
            text-decoration: none;
            font-weight: 500;
            transition: all 0.2s ease;
            display: flex;
            align-items: center;
            gap: 0.25rem;
            padding: 0.2rem 0.5rem;
            border-radius: 4px;
        }

        .locale-link:hover {
            background: rgba(240, 147, 251, 0.1);
            color: #d07be8;
            transform: translateY(-1px);
        }

        .locale-meta {
            color: #868e96;
            font-size: 0.85rem;
            font-style: italic;
            margin-left: auto;
        }

        @media (max-width: 768px) {
            .locale-switcher {
                font-size: 0.85rem;
                padding: 0.4rem 0.8rem;
            }
            .locale-meta {
                display: none;
            }
        }
    </style>
</head>
<body>
            <div class="locale-switcher">
<span class="current-locale">ğŸŒ JP</span>
<span class="locale-separator">|</span>
<a href="../../../en/ML/generative-models-introduction/chapter2-vae.html" class="locale-link">ğŸ‡¬ğŸ‡§ EN</a>
<span class="locale-separator">|</span>
<span class="locale-meta">Last sync: 2025-11-16</span>
</div>
<nav class="breadcrumb">
        <div class="breadcrumb-content">
            <a href="../../index.html">AIå¯ºå­å±‹ãƒˆãƒƒãƒ—</a><span class="breadcrumb-separator">â€º</span><a href="../../ML/index.html">æ©Ÿæ¢°å­¦ç¿’</a><span class="breadcrumb-separator">â€º</span><a href="../../ML/generative-models-introduction/index.html">Generative Models</a><span class="breadcrumb-separator">â€º</span><span class="breadcrumb-current">Chapter 2</span>
        </div>
    </nav>

        <header>
        <div class="header-content">
            <h1>ç¬¬2ç« ï¼šVAEï¼ˆVariational Autoencoderï¼‰</h1>
            <p class="subtitle">ç¢ºç‡çš„æ½œåœ¨å¤‰æ•°ãƒ¢ãƒ‡ãƒ«ã¨ELBOã«ã‚ˆã‚‹å®Œå…¨ç†è§£</p>
            <div class="meta">
                <span class="meta-item">ğŸ“– èª­äº†æ™‚é–“: 25-30åˆ†</span>
                <span class="meta-item">ğŸ“Š é›£æ˜“åº¦: ä¸­ç´šã€œä¸Šç´š</span>
                <span class="meta-item">ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹: 10å€‹</span>
                <span class="meta-item">ğŸ“ æ¼”ç¿’å•é¡Œ: 5å•</span>
            </div>
        </div>
    </header>

    <main class="container">

<h2>å­¦ç¿’ç›®æ¨™</h2>
<p>ã“ã®ç« ã‚’èª­ã‚€ã“ã¨ã§ã€ä»¥ä¸‹ã‚’ç¿’å¾—ã§ãã¾ã™ï¼š</p>
<ul>
<li>âœ… é€šå¸¸ã®Autoencoderã®é™ç•Œã¨VAEã®å‹•æ©Ÿã‚’ç†è§£ã™ã‚‹</li>
<li>âœ… ELBOï¼ˆEvidence Lower Boundï¼‰ã¨KL divergenceã®ç†è«–ã‚’èª¬æ˜ã§ãã‚‹</li>
<li>âœ… Reparameterization Trickã®ä»•çµ„ã¿ã¨å¿…è¦æ€§ã‚’ç†è§£ã™ã‚‹</li>
<li>âœ… VAEã®Encoderï¼ˆRecognition networkï¼‰ã¨Decoderï¼ˆGenerative networkï¼‰ã‚’å®Ÿè£…ã§ãã‚‹</li>
<li>âœ… PyTorchã§MNIST/CelebAç”»åƒç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ã§ãã‚‹</li>
<li>âœ… æ½œåœ¨ç©ºé–“ã‚’å¯è¦–åŒ–ã—ã€è£œé–“ï¼ˆinterpolationï¼‰ã‚’å®Ÿè¡Œã§ãã‚‹</li>
</ul>

<hr>

<h2>2.1 Autoencoderã®å¾©ç¿’ã¨é™ç•Œ</h2>

<h3>é€šå¸¸ã®Autoencoderã®æ§‹é€ </h3>

<p><strong>Autoencoderï¼ˆAEï¼‰</strong>ã¯ã€å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã‚’ä½æ¬¡å…ƒã®æ½œåœ¨è¡¨ç¾ã«åœ§ç¸®ã—ã€ãã‚Œã‚’å¾©å…ƒã™ã‚‹æ•™å¸«ãªã—å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚</p>

<div class="mermaid">
graph LR
    X["å…¥åŠ› x<br/>(784æ¬¡å…ƒ)"] --> E["Encoder<br/>q(z|x)"]
    E --> Z["æ½œåœ¨å¤‰æ•° z<br/>(2-20æ¬¡å…ƒ)"]
    Z --> D["Decoder<br/>p(x|z)"]
    D --> X2["å¾©å…ƒ xÌ‚<br/>(784æ¬¡å…ƒ)"]

    style E fill:#b3e5fc
    style Z fill:#fff9c4
    style D fill:#ffab91
</div>

<h3>Autoencoderã®ç›®çš„é–¢æ•°</h3>

<p>é€šå¸¸ã®Autoencoderã¯ã€<strong>å†æ§‹æˆèª¤å·®</strong>ã‚’æœ€å°åŒ–ã—ã¾ã™ï¼š</p>

$$
\mathcal{L}_{\text{AE}} = \|x - \hat{x}\|^2 = \|x - \text{Decoder}(\text{Encoder}(x))\|^2
$$

<h3>åŸºæœ¬çš„ãªAutoencoderã®å®Ÿè£…</h3>

<pre><code class="language-python">import torch
import torch.nn as nn
import torch.nn.functional as F

class Autoencoder(nn.Module):
    """é€šå¸¸ã®Autoencoderï¼ˆæ±ºå®šè«–çš„ï¼‰"""
    def __init__(self, input_dim=784, hidden_dim=400, latent_dim=20):
        super(Autoencoder, self).__init__()

        # Encoder
        self.fc1 = nn.Linear(input_dim, hidden_dim)
        self.fc2 = nn.Linear(hidden_dim, latent_dim)

        # Decoder
        self.fc3 = nn.Linear(latent_dim, hidden_dim)
        self.fc4 = nn.Linear(hidden_dim, input_dim)

    def encode(self, x):
        """å…¥åŠ›ã‚’æ½œåœ¨è¡¨ç¾ã«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰"""
        h = F.relu(self.fc1(x))
        z = self.fc2(h)
        return z

    def decode(self, z):
        """æ½œåœ¨è¡¨ç¾ã‹ã‚‰å…¥åŠ›ã‚’å¾©å…ƒ"""
        h = F.relu(self.fc3(z))
        x_recon = torch.sigmoid(self.fc4(h))
        return x_recon

    def forward(self, x):
        z = self.encode(x)
        x_recon = self.decode(z)
        return x_recon, z


# å‹•ä½œç¢ºèª
print("=== é€šå¸¸ã®Autoencoderã®å‹•ä½œ ===")
ae = Autoencoder(input_dim=784, hidden_dim=400, latent_dim=20)

# ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ï¼ˆ28x28ã®MNISTç”»åƒï¼‰
batch_size = 32
x = torch.randn(batch_size, 784)

x_recon, z = ae(x)

print(f"å…¥åŠ›: {x.shape}")
print(f"æ½œåœ¨å¤‰æ•°: {z.shape}")
print(f"å¾©å…ƒ: {x_recon.shape}")

# å†æ§‹æˆèª¤å·®
recon_loss = F.mse_loss(x_recon, x)
print(f"å†æ§‹æˆèª¤å·®: {recon_loss.item():.4f}")

# ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°
total_params = sum(p.numel() for p in ae.parameters())
print(f"ç·ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {total_params:,}")
</code></pre>

<h3>Autoencoderã®é™ç•Œ</h3>

<table>
<thead>
<tr>
<th>å•é¡Œç‚¹</th>
<th>èª¬æ˜</th>
<th>å½±éŸ¿</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>æ±ºå®šè«–çš„</strong></td>
<td>åŒã˜å…¥åŠ›ã¯å¸¸ã«åŒã˜æ½œåœ¨å¤‰æ•°ã‚’ç”Ÿæˆ</td>
<td>å¤šæ§˜æ€§ã®ã‚ã‚‹ã‚µãƒ³ãƒ—ãƒ«ç”ŸæˆãŒã§ããªã„</td>
</tr>
<tr>
<td><strong>æ§‹é€ åŒ–ã•ã‚Œã¦ã„ãªã„æ½œåœ¨ç©ºé–“</strong></td>
<td>æ½œåœ¨ç©ºé–“ã«æ˜ç¢ºãªç¢ºç‡åˆ†å¸ƒãŒãªã„</td>
<td>ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãŒå›°é›£</td>
</tr>
<tr>
<td><strong>éå­¦ç¿’ã—ã‚„ã™ã„</strong></td>
<td>è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚’è¨˜æ†¶ã—ã¦ã—ã¾ã†</td>
<td>æ–°è¦ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã«å¼±ã„</td>
</tr>
<tr>
<td><strong>è£œé–“ã®å“è³ª</strong></td>
<td>æ½œåœ¨ç©ºé–“ã®è£œé–“ãŒæ„å‘³ã‚’æŒãŸãªã„å ´åˆãŒã‚ã‚‹</td>
<td>ã‚¹ãƒ ãƒ¼ã‚ºãªå¤‰æ›ãŒã§ããªã„</td>
</tr>
</tbody>
</table>

<blockquote>
<p>ã€Œé€šå¸¸ã®Autoencoderã¯åœ§ç¸®ãƒ»å¾©å…ƒã¯ã§ãã‚‹ãŒã€æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã™ã‚‹ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦ã¯ä¸ååˆ†ã§ã™ã€</p>
</blockquote>

<h3>æ½œåœ¨ç©ºé–“ã®å•é¡Œã®å¯è¦–åŒ–</h3>

<pre><code class="language-python">import torch
import numpy as np
import matplotlib.pyplot as plt

# é€šå¸¸ã®Autoencoderã®æ½œåœ¨ç©ºé–“ã®å•é¡Œ
print("\n=== Autoencoderã®æ½œåœ¨ç©ºé–“ã®å•é¡Œ ===")

# ãƒ©ãƒ³ãƒ€ãƒ ãªå…¥åŠ›ã‚’è¤‡æ•°ç”Ÿæˆ
num_samples = 100
x_samples = torch.randn(num_samples, 784)

# Encoderã§æ½œåœ¨è¡¨ç¾ã‚’å–å¾—
ae.eval()
with torch.no_grad():
    z_samples = ae.encode(x_samples)

print(f"æ½œåœ¨å¤‰æ•°ã®ã‚µãƒ³ãƒ—ãƒ«æ•°: {z_samples.shape[0]}")
print(f"æ½œåœ¨æ¬¡å…ƒ: {z_samples.shape[1]}")

# æ½œåœ¨ç©ºé–“ã®çµ±è¨ˆ
z_mean = z_samples.mean(dim=0)
z_std = z_samples.std(dim=0)

print(f"\næ½œåœ¨å¤‰æ•°ã®å¹³å‡ï¼ˆä¸€éƒ¨ï¼‰: {z_mean[:5].numpy()}")
print(f"æ½œåœ¨å¤‰æ•°ã®æ¨™æº–åå·®ï¼ˆä¸€éƒ¨ï¼‰: {z_std[:5].numpy()}")
print("â†’ å¹³å‡ãƒ»åˆ†æ•£ãŒãƒãƒ©ãƒãƒ©ã§æ§‹é€ åŒ–ã•ã‚Œã¦ã„ãªã„")

# ãƒ©ãƒ³ãƒ€ãƒ ã«æ½œåœ¨ç©ºé–“ã‹ã‚‰ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ã¦å¾©å…ƒã‚’è©¦ã¿ã‚‹
z_random = torch.randn(10, 20)  # ãƒ©ãƒ³ãƒ€ãƒ ãªæ½œåœ¨å¤‰æ•°
with torch.no_grad():
    x_from_random = ae.decode(z_random)

print(f"\nãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã‹ã‚‰ã®å¾©å…ƒ: {x_from_random.shape}")
print("â†’ æ„å‘³ã®ã‚ã‚‹ç”»åƒãŒç”Ÿæˆã•ã‚Œãªã„å¯èƒ½æ€§ãŒé«˜ã„")
print("â†’ ã“ã‚ŒãŒVAEãŒå¿…è¦ãªç†ç”±ï¼")
</code></pre>

<hr>

<h2>2.2 VAEã®å‹•æ©Ÿã¨ç†è«–</h2>

<h3>VAEã®åŸºæœ¬ã‚¢ã‚¤ãƒ‡ã‚¢</h3>

<p><strong>Variational Autoencoderï¼ˆVAEï¼‰</strong>ã¯ã€Autoencoderã«<strong>ç¢ºç‡çš„ãªæ çµ„ã¿</strong>ã‚’å°å…¥ã™ã‚‹ã“ã¨ã§ã€ä»¥ä¸‹ã‚’å®Ÿç¾ã—ã¾ã™ï¼š</p>

<ol>
<li><strong>æ§‹é€ åŒ–ã•ã‚ŒãŸæ½œåœ¨ç©ºé–“</strong>ï¼šæ½œåœ¨å¤‰æ•°ã‚’æ­£è¦åˆ†å¸ƒ $\mathcal{N}(0, I)$ ã«å¾“ã†ã‚ˆã†æ­£å‰‡åŒ–</li>
<li><strong>ç¢ºç‡çš„ç”Ÿæˆ</strong>ï¼šæ½œåœ¨ç©ºé–“ã‹ã‚‰ã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã§æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆå¯èƒ½</li>
<li><strong>æ»‘ã‚‰ã‹ãªè£œé–“</strong>ï¼šæ½œåœ¨ç©ºé–“ã§è£œé–“ã™ã‚‹ã¨æ„å‘³ã®ã‚ã‚‹ä¸­é–“ãƒ‡ãƒ¼ã‚¿ãŒå¾—ã‚‰ã‚Œã‚‹</li>
</ol>

<div class="mermaid">
graph TB
    X["å…¥åŠ› x"] --> E["Encoder<br/>q_Ï†(z|x)"]
    E --> Mu["å¹³å‡ Î¼"]
    E --> Logvar["å¯¾æ•°åˆ†æ•£ log ÏƒÂ²"]
    Mu --> Sample["ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°<br/>z ~ N(Î¼, ÏƒÂ²)"]
    Logvar --> Sample
    Sample --> Z["æ½œåœ¨å¤‰æ•° z"]
    Z --> D["Decoder<br/>p_Î¸(x|z)"]
    D --> X2["å¾©å…ƒ xÌ‚"]

    Prior["äº‹å‰åˆ†å¸ƒ<br/>p(z) = N(0,I)"] -.->|KLæ­£å‰‡åŒ–| Sample

    style E fill:#b3e5fc
    style Sample fill:#fff59d
    style D fill:#ffab91
    style Prior fill:#c5e1a5
</div>

<h3>ç¢ºç‡çš„å®šå¼åŒ–</h3>

<p>VAEã¯ä»¥ä¸‹ã®ç¢ºç‡ãƒ¢ãƒ‡ãƒ«ã‚’ä»®å®šã—ã¾ã™ï¼š</p>

<ul>
<li><strong>ç”Ÿæˆéç¨‹ï¼ˆGenerative processï¼‰</strong>ï¼š
$$
\begin{align}
z &\sim p(z) = \mathcal{N}(0, I) \quad \text{ï¼ˆäº‹å‰åˆ†å¸ƒï¼‰} \\
x &\sim p_\theta(x|z) \quad \text{ï¼ˆå°¤åº¦ï¼‰}
\end{align}
$$
</li>
<li><strong>æ¨è«–éç¨‹ï¼ˆInferenceï¼‰</strong>ï¼š
$$
q_\phi(z|x) \approx p(z|x) \quad \text{ï¼ˆå¤‰åˆ†è¿‘ä¼¼ï¼‰}
$$
</li>
</ul>

<h3>ELBOï¼ˆEvidence Lower Boundï¼‰</h3>

<p>VAEã®ç›®çš„ã¯ã€ãƒ‡ãƒ¼ã‚¿ã®å¯¾æ•°å°¤åº¦ $\log p_\theta(x)$ ã‚’æœ€å¤§åŒ–ã™ã‚‹ã“ã¨ã§ã™ãŒã€ã“ã‚Œã¯è¨ˆç®—å›°é›£ã§ã™ã€‚ãã“ã§<strong>ELBO</strong>ã‚’æœ€å¤§åŒ–ã—ã¾ã™ï¼š</p>

$$
\begin{align}
\log p_\theta(x) &\geq \mathbb{E}_{q_\phi(z|x)}\left[\log p_\theta(x|z)\right] - D_{KL}(q_\phi(z|x) \| p(z)) \\
&= \text{ELBO}(\theta, \phi; x)
\end{align}
$$

<p>ã“ã“ã§ï¼š</p>
<ul>
<li><strong>ç¬¬1é …</strong>ï¼šå†æ§‹æˆé …ï¼ˆReconstruction termï¼‰- Decoderã®å¾©å…ƒæ€§èƒ½</li>
<li><strong>ç¬¬2é …</strong>ï¼šKLæ­£å‰‡åŒ–é …ï¼ˆKL divergenceï¼‰- Encoderã®åˆ†å¸ƒã‚’äº‹å‰åˆ†å¸ƒã«è¿‘ã¥ã‘ã‚‹</li>
</ul>

<h3>KL Divergenceã®è§£æè§£</h3>

<p>Encoderã¨DecoderãŒã‚¬ã‚¦ã‚¹åˆ†å¸ƒã®å ´åˆã€KL divergenceã¯è§£æçš„ã«è¨ˆç®—ã§ãã¾ã™ï¼š</p>

$$
D_{KL}(q_\phi(z|x) \| p(z)) = \frac{1}{2}\sum_{j=1}^{J}\left(1 + \log \sigma_j^2 - \mu_j^2 - \sigma_j^2\right)
$$

<p>ã“ã“ã§ã€$J$ã¯æ½œåœ¨æ¬¡å…ƒæ•°ã€$\mu_j$ã¨$\sigma_j^2$ã¯EncoderãŒå‡ºåŠ›ã™ã‚‹å¹³å‡ã¨åˆ†æ•£ã§ã™ã€‚</p>

<h3>ELBOã®å°å‡ºã¨å¯è¦–åŒ–</h3>

<pre><code class="language-python">import torch
import torch.nn.functional as F

def kl_divergence_gaussian(mu, logvar):
    """
    ã‚¬ã‚¦ã‚¹åˆ†å¸ƒé–“ã®KL divergenceã‚’è¨ˆç®—

    Args:
        mu: (batch, latent_dim) - EncoderãŒå‡ºåŠ›ã™ã‚‹å¹³å‡
        logvar: (batch, latent_dim) - EncoderãŒå‡ºåŠ›ã™ã‚‹å¯¾æ•°åˆ†æ•£

    Returns:
        kl_loss: (batch,) - å„ã‚µãƒ³ãƒ—ãƒ«ã®KL divergence
    """
    # KL(q(z|x) || N(0,I)) = -0.5 * sum(1 + log(ÏƒÂ²) - Î¼Â² - ÏƒÂ²)
    kl = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp(), dim=1)
    return kl


def vae_loss(x_recon, x, mu, logvar):
    """
    VAEã®æå¤±é–¢æ•°ï¼ˆELBOï¼‰

    Args:
        x_recon: (batch, input_dim) - å¾©å…ƒã•ã‚ŒãŸå…¥åŠ›
        x: (batch, input_dim) - å…ƒã®å…¥åŠ›
        mu: (batch, latent_dim) - å¹³å‡
        logvar: (batch, latent_dim) - å¯¾æ•°åˆ†æ•£

    Returns:
        total_loss: ã‚¹ã‚«ãƒ©ãƒ¼ - ELBOï¼ˆè² ã®å€¤ï¼‰
        recon_loss: ã‚¹ã‚«ãƒ©ãƒ¼ - å†æ§‹æˆèª¤å·®
        kl_loss: ã‚¹ã‚«ãƒ©ãƒ¼ - KL divergence
    """
    # å†æ§‹æˆèª¤å·®ï¼ˆBinary Cross Entropyï¼‰
    recon_loss = F.binary_cross_entropy(x_recon, x, reduction='sum')

    # KL divergence
    kl_loss = kl_divergence_gaussian(mu, logvar).sum()

    # ELBO = å†æ§‹æˆé … - KLé …ï¼ˆæœ€å¤§åŒ– = è² ã®æœ€å°åŒ–ï¼‰
    total_loss = recon_loss + kl_loss

    return total_loss, recon_loss, kl_loss


# æ•°å€¤ä¾‹ã§ELBOã‚’è¨ˆç®—
print("=== ELBOã®æ•°å€¤ä¾‹ ===")

batch_size = 32
input_dim = 784
latent_dim = 20

# ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿
x = torch.rand(batch_size, input_dim)
x_recon = torch.rand(batch_size, input_dim)
mu = torch.randn(batch_size, latent_dim)
logvar = torch.randn(batch_size, latent_dim)

total_loss, recon_loss, kl_loss = vae_loss(x_recon, x, mu, logvar)

print(f"ç·æå¤±ï¼ˆELBOï¼‰: {total_loss.item():.2f}")
print(f"å†æ§‹æˆèª¤å·®: {recon_loss.item():.2f}")
print(f"KL divergence: {kl_loss.item():.2f}")
print(f"\nãƒãƒƒãƒå¹³å‡:")
print(f"  å†æ§‹æˆèª¤å·®: {recon_loss.item()/batch_size:.2f}")
print(f"  KL divergence: {kl_loss.item()/batch_size:.2f}")
print("\nâ†’ 2ã¤ã®é …ã®ãƒãƒ©ãƒ³ã‚¹ãŒé‡è¦ï¼")
</code></pre>

<h3>Autoencoderã¨VAEã®æ¯”è¼ƒ</h3>

<table>
<thead>
<tr>
<th>é …ç›®</th>
<th>Autoencoder</th>
<th>VAE</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>æ½œåœ¨å¤‰æ•°</strong></td>
<td>æ±ºå®šè«–çš„ $z = f(x)$</td>
<td>ç¢ºç‡çš„ $z \sim q_\phi(z|x)$</td>
</tr>
<tr>
<td><strong>ç›®çš„é–¢æ•°</strong></td>
<td>å†æ§‹æˆèª¤å·®ã®ã¿</td>
<td>ELBOï¼ˆå†æ§‹æˆ + KLï¼‰</td>
</tr>
<tr>
<td><strong>æ½œåœ¨ç©ºé–“</strong></td>
<td>æ§‹é€ ãªã—</td>
<td>æ­£è¦åˆ†å¸ƒã«æ­£å‰‡åŒ–</td>
</tr>
<tr>
<td><strong>ç”Ÿæˆèƒ½åŠ›</strong></td>
<td>å¼±ã„</td>
<td>å¼·ã„ï¼ˆã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°å¯èƒ½ï¼‰</td>
</tr>
<tr>
<td><strong>è£œé–“</strong></td>
<td>ä¸å®‰å®š</td>
<td>æ»‘ã‚‰ã‹</td>
</tr>
<tr>
<td><strong>è¨“ç·´</strong></td>
<td>ã‚·ãƒ³ãƒ—ãƒ«</td>
<td>Reparameterization Trickå¿…è¦</td>
</tr>
</tbody>
</table>

<blockquote>
<p>ã€ŒVAEã¯Autoencoderã«ç¢ºç‡çš„ãªæ çµ„ã¿ã‚’åŠ ãˆã‚‹ã“ã¨ã§ã€ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦ã®èƒ½åŠ›ã‚’å¤§å¹…ã«å‘ä¸Šã•ã›ã¾ã™ã€</p>
</blockquote>

<hr>

<h2>2.3 Reparameterization Trick</h2>

<h3>ãªãœReparameterization TrickãŒå¿…è¦ã‹</h3>

<p>VAEã®è¨“ç·´ã§ã¯ã€$z \sim q_\phi(z|x)$ ã‹ã‚‰ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ã—ã‹ã—ã€<strong>ç¢ºç‡çš„ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã¯å¾®åˆ†ä¸å¯èƒ½</strong>ãªãŸã‚ã€ãã®ã¾ã¾ã§ã¯èª¤å·®é€†ä¼æ’­ã§ãã¾ã›ã‚“ã€‚</p>

<div class="mermaid">
graph LR
    X["x"] --> E["Encoder"]
    E --> Mu["Î¼"]
    E --> Sigma["Ïƒ"]
    Mu --> Sample["z ~ N(Î¼, ÏƒÂ²)"]
    Sigma --> Sample
    Sample -.->|å‹¾é…ãŒæµã‚Œãªã„!| D["Decoder"]

    style Sample fill:#ffccbc
</div>

<h3>Reparameterization Trickã®ä»•çµ„ã¿</h3>

<p>ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã‚’ä»¥ä¸‹ã®ã‚ˆã†ã«<strong>æ±ºå®šè«–çš„å¤‰æ›</strong>ã«æ›¸ãæ›ãˆã¾ã™ï¼š</p>

$$
\begin{align}
z &\sim \mathcal{N}(\mu, \sigma^2) \\
&\Downarrow \text{ï¼ˆReparameterizationï¼‰} \\
z &= \mu + \sigma \cdot \epsilon, \quad \epsilon \sim \mathcal{N}(0, 1)
\end{align}
$$

<p>ã“ã“ã§ã€$\epsilon$ã¯ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«ä¾å­˜ã—ãªã„<strong>ãƒã‚¤ã‚º</strong>ã§ã™ã€‚ã“ã®å¤‰æ›ã«ã‚ˆã‚Šã€$\mu$ã¨$\sigma$ã‚’é€šã˜ã¦å‹¾é…ãŒæµã‚Œã¾ã™ã€‚</p>

<div class="mermaid">
graph LR
    X["x"] --> E["Encoder"]
    E --> Mu["Î¼"]
    E --> Sigma["Ïƒ"]
    Epsilon["Ïµ ~ N(0,1)"] --> Reparam["z = Î¼ + ÏƒÂ·Ïµ"]
    Mu --> Reparam
    Sigma --> Reparam
    Reparam -->|å‹¾é…ãŒæµã‚Œã‚‹!| D["Decoder"]

    style Reparam fill:#c5e1a5
    style Epsilon fill:#fff59d
</div>

<h3>Reparameterization Trickã®å®Ÿè£…</h3>

<pre><code class="language-python">import torch
import torch.nn as nn

class VAEEncoder(nn.Module):
    """VAEã®Encoderï¼ˆRecognition networkï¼‰"""
    def __init__(self, input_dim=784, hidden_dim=400, latent_dim=20):
        super(VAEEncoder, self).__init__()

        self.fc1 = nn.Linear(input_dim, hidden_dim)
        self.fc_mu = nn.Linear(hidden_dim, latent_dim)
        self.fc_logvar = nn.Linear(hidden_dim, latent_dim)

    def forward(self, x):
        """
        Args:
            x: (batch, input_dim)

        Returns:
            mu: (batch, latent_dim) - å¹³å‡
            logvar: (batch, latent_dim) - å¯¾æ•°åˆ†æ•£
        """
        h = torch.relu(self.fc1(x))
        mu = self.fc_mu(h)
        logvar = self.fc_logvar(h)
        return mu, logvar


def reparameterize(mu, logvar):
    """
    Reparameterization Trick

    Args:
        mu: (batch, latent_dim) - å¹³å‡
        logvar: (batch, latent_dim) - å¯¾æ•°åˆ†æ•£

    Returns:
        z: (batch, latent_dim) - ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã•ã‚ŒãŸæ½œåœ¨å¤‰æ•°
    """
    # æ¨™æº–åå·®ã‚’è¨ˆç®—ï¼ˆæ•°å€¤å®‰å®šæ€§ã®ãŸã‚å¯¾æ•°åˆ†æ•£ã‚’ä½¿ç”¨ï¼‰
    std = torch.exp(0.5 * logvar)

    # æ¨™æº–æ­£è¦åˆ†å¸ƒã‹ã‚‰ãƒã‚¤ã‚ºã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
    epsilon = torch.randn_like(std)

    # z = Î¼ + ÏƒÂ·Ïµ
    z = mu + std * epsilon

    return z


# å‹•ä½œç¢ºèª
print("=== Reparameterization Trickã®å‹•ä½œ ===")

encoder = VAEEncoder(input_dim=784, hidden_dim=400, latent_dim=20)
x = torch.randn(32, 784)

# Encoderã§å¹³å‡ã¨åˆ†æ•£ã‚’å–å¾—
mu, logvar = encoder(x)
print(f"å¹³å‡: {mu.shape}")
print(f"å¯¾æ•°åˆ†æ•£: {logvar.shape}")

# Reparameterization Trickã§ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
z = reparameterize(mu, logvar)
print(f"ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã•ã‚ŒãŸæ½œåœ¨å¤‰æ•°: {z.shape}")

# å‹¾é…ã®ç¢ºèª
print("\n=== å‹¾é…ã®æµã‚Œã‚’ç¢ºèª ===")
z.sum().backward()
print(f"Î¼ã®å‹¾é…: {encoder.fc_mu.weight.grad is not None}")
print(f"log(ÏƒÂ²)ã®å‹¾é…: {encoder.fc_logvar.weight.grad is not None}")
print("â†’ Reparameterization Trickã«ã‚ˆã‚Šå‹¾é…ãŒæµã‚Œã‚‹ï¼")

# åŒã˜å…¥åŠ›ã‹ã‚‰è¤‡æ•°å›ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆç¢ºç‡çš„ï¼‰
print("\n=== ç¢ºç‡çš„ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã®ç¢ºèª ===")
z1 = reparameterize(mu, logvar)
z2 = reparameterize(mu, logvar)
z3 = reparameterize(mu, logvar)

print(f"ã‚µãƒ³ãƒ—ãƒ«1ï¼ˆæœ€åˆã®5æ¬¡å…ƒï¼‰: {z1[0, :5].detach().numpy()}")
print(f"ã‚µãƒ³ãƒ—ãƒ«2ï¼ˆæœ€åˆã®5æ¬¡å…ƒï¼‰: {z2[0, :5].detach().numpy()}")
print(f"ã‚µãƒ³ãƒ—ãƒ«3ï¼ˆæœ€åˆã®5æ¬¡å…ƒï¼‰: {z3[0, :5].detach().numpy()}")
print("â†’ åŒã˜å…¥åŠ›ã§ã‚‚ç•°ãªã‚‹ã‚µãƒ³ãƒ—ãƒ«ãŒå¾—ã‚‰ã‚Œã‚‹ï¼ˆå¤šæ§˜æ€§ï¼‰")
</code></pre>

<h3>æ•°å€¤å®‰å®šæ€§ã®è€ƒæ…®</h3>

<pre><code class="language-python">import torch
import torch.nn as nn

# å¯¾æ•°åˆ†æ•£ã‚’ä½¿ã†ç†ç”±
print("\n=== æ•°å€¤å®‰å®šæ€§ã®é‡è¦æ€§ ===")

# æ‚ªã„ä¾‹ï¼šç›´æ¥åˆ†æ•£ã‚’ä½¿ã†
sigma_bad = torch.tensor([0.001, 1.0, 100.0])
print(f"åˆ†æ•£ï¼ˆç›´æ¥ï¼‰: {sigma_bad}")
print(f"â†’ æ¥µç«¯ãªå€¤ãŒå­˜åœ¨ã—ã€æ•°å€¤ä¸å®‰å®š")

# è‰¯ã„ä¾‹ï¼šå¯¾æ•°åˆ†æ•£ã‚’ä½¿ã†
logvar_good = torch.log(sigma_bad)
print(f"\nå¯¾æ•°åˆ†æ•£: {logvar_good}")
print(f"â†’ æ•°å€¤çš„ã«å®‰å®šã—ãŸç¯„å›²")

# å¾©å…ƒ
sigma_recovered = torch.exp(0.5 * logvar_good)
print(f"\næ¨™æº–åå·®ï¼ˆå¾©å…ƒï¼‰: {sigma_recovered}")
print(f"â†’ å…ƒã®å€¤ãŒæ­£ç¢ºã«å¾©å…ƒã•ã‚Œã‚‹")

# ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°ã§ã•ã‚‰ã«å®‰å®šåŒ–
logvar_clipped = torch.clamp(logvar_good, min=-10, max=10)
print(f"\nã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°å¾Œ: {logvar_clipped}")
print("â†’ æ¥µç«¯ãªå€¤ã‚’é˜²ã")
</code></pre>

<hr>

<h2>2.4 VAEã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®å®Œå…¨å®Ÿè£…</h2>

<h3>Encoderã¨Decoderã®å®Ÿè£…</h3>

<pre><code class="language-python">import torch
import torch.nn as nn
import torch.nn.functional as F

class VAE(nn.Module):
    """å®Œå…¨ãªVAEãƒ¢ãƒ‡ãƒ«"""
    def __init__(self, input_dim=784, hidden_dim=400, latent_dim=20):
        super(VAE, self).__init__()

        self.input_dim = input_dim
        self.latent_dim = latent_dim

        # ===== Encoderï¼ˆRecognition networkï¼‰ =====
        self.encoder_fc1 = nn.Linear(input_dim, hidden_dim)
        self.encoder_fc_mu = nn.Linear(hidden_dim, latent_dim)
        self.encoder_fc_logvar = nn.Linear(hidden_dim, latent_dim)

        # ===== Decoderï¼ˆGenerative networkï¼‰ =====
        self.decoder_fc1 = nn.Linear(latent_dim, hidden_dim)
        self.decoder_fc2 = nn.Linear(hidden_dim, input_dim)

    def encode(self, x):
        """
        Encoder: x -> (Î¼, log ÏƒÂ²)

        Args:
            x: (batch, input_dim)

        Returns:
            mu: (batch, latent_dim)
            logvar: (batch, latent_dim)
        """
        h = F.relu(self.encoder_fc1(x))
        mu = self.encoder_fc_mu(h)
        logvar = self.encoder_fc_logvar(h)
        return mu, logvar

    def reparameterize(self, mu, logvar):
        """
        Reparameterization Trick: z = Î¼ + ÏƒÂ·Ïµ

        Args:
            mu: (batch, latent_dim)
            logvar: (batch, latent_dim)

        Returns:
            z: (batch, latent_dim)
        """
        std = torch.exp(0.5 * logvar)
        epsilon = torch.randn_like(std)
        z = mu + std * epsilon
        return z

    def decode(self, z):
        """
        Decoder: z -> xÌ‚

        Args:
            z: (batch, latent_dim)

        Returns:
            x_recon: (batch, input_dim)
        """
        h = F.relu(self.decoder_fc1(z))
        x_recon = torch.sigmoid(self.decoder_fc2(h))
        return x_recon

    def forward(self, x):
        """
        Forward pass: x -> z -> xÌ‚

        Args:
            x: (batch, input_dim)

        Returns:
            x_recon: (batch, input_dim) - å¾©å…ƒã•ã‚ŒãŸå…¥åŠ›
            mu: (batch, latent_dim) - å¹³å‡
            logvar: (batch, latent_dim) - å¯¾æ•°åˆ†æ•£
        """
        # Encode
        mu, logvar = self.encode(x)

        # Reparameterize
        z = self.reparameterize(mu, logvar)

        # Decode
        x_recon = self.decode(z)

        return x_recon, mu, logvar

    def sample(self, num_samples, device='cpu'):
        """
        æ½œåœ¨ç©ºé–“ã‹ã‚‰ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ã¦ç”»åƒã‚’ç”Ÿæˆ

        Args:
            num_samples: ç”Ÿæˆã™ã‚‹ã‚µãƒ³ãƒ—ãƒ«æ•°
            device: ãƒ‡ãƒã‚¤ã‚¹

        Returns:
            samples: (num_samples, input_dim)
        """
        # æ¨™æº–æ­£è¦åˆ†å¸ƒã‹ã‚‰æ½œåœ¨å¤‰æ•°ã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
        z = torch.randn(num_samples, self.latent_dim).to(device)

        # Decoderã§ç”Ÿæˆ
        samples = self.decode(z)

        return samples


# ãƒ¢ãƒ‡ãƒ«ä½œæˆ
print("=== VAEãƒ¢ãƒ‡ãƒ«ã®ä½œæˆ ===")
vae = VAE(input_dim=784, hidden_dim=400, latent_dim=20)

# å‹•ä½œç¢ºèª
batch_size = 32
x = torch.rand(batch_size, 784)  # 0-1ã«æ­£è¦åŒ–ã•ã‚ŒãŸMNISTç”»åƒ

x_recon, mu, logvar = vae(x)

print(f"å…¥åŠ›: {x.shape}")
print(f"å¾©å…ƒ: {x_recon.shape}")
print(f"å¹³å‡: {mu.shape}")
print(f"å¯¾æ•°åˆ†æ•£: {logvar.shape}")

# æå¤±è¨ˆç®—
total_loss, recon_loss, kl_loss = vae_loss(x_recon, x, mu, logvar)
print(f"\næå¤±:")
print(f"  ç·æå¤±: {total_loss.item():.2f}")
print(f"  å†æ§‹æˆ: {recon_loss.item():.2f}")
print(f"  KL divergence: {kl_loss.item():.2f}")

# ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°
total_params = sum(p.numel() for p in vae.parameters())
print(f"\nç·ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {total_params:,}")

# ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
print("\n=== ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚° ===")
samples = vae.sample(num_samples=10)
print(f"ç”Ÿæˆã•ã‚ŒãŸã‚µãƒ³ãƒ—ãƒ«: {samples.shape}")
print("â†’ VAEã¯æ½œåœ¨ç©ºé–“ã‹ã‚‰æ–°ã—ã„ç”»åƒã‚’ç”Ÿæˆå¯èƒ½ï¼")
</code></pre>

<h3>ç•³ã¿è¾¼ã¿VAEï¼ˆConvolutional VAEï¼‰</h3>

<pre><code class="language-python">import torch
import torch.nn as nn
import torch.nn.functional as F

class ConvVAE(nn.Module):
    """ç•³ã¿è¾¼ã¿VAEï¼ˆç”»åƒç”¨ï¼‰"""
    def __init__(self, input_channels=1, latent_dim=128):
        super(ConvVAE, self).__init__()

        self.latent_dim = latent_dim

        # ===== Encoder =====
        self.encoder_conv = nn.Sequential(
            # 28x28 -> 14x14
            nn.Conv2d(input_channels, 32, kernel_size=4, stride=2, padding=1),
            nn.ReLU(),
            # 14x14 -> 7x7
            nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=1),
            nn.ReLU(),
            # 7x7 -> 3x3
            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),
            nn.ReLU(),
        )

        # æ½œåœ¨å¤‰æ•°ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.fc_mu = nn.Linear(128 * 3 * 3, latent_dim)
        self.fc_logvar = nn.Linear(128 * 3 * 3, latent_dim)

        # ===== Decoder =====
        self.decoder_fc = nn.Linear(latent_dim, 128 * 3 * 3)

        self.decoder_conv = nn.Sequential(
            # 3x3 -> 7x7
            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),
            nn.ReLU(),
            # 7x7 -> 14x14
            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),
            nn.ReLU(),
            # 14x14 -> 28x28
            nn.ConvTranspose2d(32, input_channels, kernel_size=4, stride=2, padding=1),
            nn.Sigmoid(),
        )

    def encode(self, x):
        """
        Args:
            x: (batch, channels, 28, 28)
        Returns:
            mu, logvar: (batch, latent_dim)
        """
        h = self.encoder_conv(x)  # (batch, 128, 3, 3)
        h = h.view(h.size(0), -1)  # (batch, 128*3*3)

        mu = self.fc_mu(h)
        logvar = self.fc_logvar(h)

        return mu, logvar

    def reparameterize(self, mu, logvar):
        std = torch.exp(0.5 * logvar)
        epsilon = torch.randn_like(std)
        z = mu + std * epsilon
        return z

    def decode(self, z):
        """
        Args:
            z: (batch, latent_dim)
        Returns:
            x_recon: (batch, channels, 28, 28)
        """
        h = self.decoder_fc(z)  # (batch, 128*3*3)
        h = h.view(h.size(0), 128, 3, 3)  # (batch, 128, 3, 3)
        x_recon = self.decoder_conv(h)  # (batch, channels, 28, 28)
        return x_recon

    def forward(self, x):
        mu, logvar = self.encode(x)
        z = self.reparameterize(mu, logvar)
        x_recon = self.decode(z)
        return x_recon, mu, logvar

    def sample(self, num_samples, device='cpu'):
        z = torch.randn(num_samples, self.latent_dim).to(device)
        samples = self.decode(z)
        return samples


# ãƒ¢ãƒ‡ãƒ«ä½œæˆ
print("\n=== ç•³ã¿è¾¼ã¿VAEã®ä½œæˆ ===")
conv_vae = ConvVAE(input_channels=1, latent_dim=128)

# å‹•ä½œç¢ºèª
batch_size = 16
x_img = torch.rand(batch_size, 1, 28, 28)  # MNISTç”»åƒ

x_recon, mu, logvar = conv_vae(x_img)

print(f"å…¥åŠ›ç”»åƒ: {x_img.shape}")
print(f"å¾©å…ƒç”»åƒ: {x_recon.shape}")
print(f"æ½œåœ¨å¤‰æ•°: {mu.shape}")

# ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°
total_params = sum(p.numel() for p in conv_vae.parameters())
print(f"ç·ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {total_params:,}")
print("â†’ ç•³ã¿è¾¼ã¿å±¤ã§ç”»åƒã®ç©ºé–“æ§‹é€ ã‚’ä¿æŒ")
</code></pre>

<hr>

<h2>2.5 PyTorchã§ã®è¨“ç·´ã¨MNISTç”»åƒç”Ÿæˆ</h2>

<h3>ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æº–å‚™</h3>

<pre><code class="language-python">import torch
from torch.utils.data import DataLoader
from torchvision import datasets, transforms

# MNISTãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æº–å‚™
print("=== MNISTãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æº–å‚™ ===")

transform = transforms.Compose([
    transforms.ToTensor(),  # 0-1ã«æ­£è¦åŒ–
])

# ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆåˆå›ã®ã¿ï¼‰
train_dataset = datasets.MNIST(
    root='./data',
    train=True,
    download=True,
    transform=transform
)

test_dataset = datasets.MNIST(
    root='./data',
    train=False,
    download=True,
    transform=transform
)

# DataLoader
batch_size = 128
train_loader = DataLoader(
    train_dataset,
    batch_size=batch_size,
    shuffle=True,
    num_workers=2
)

test_loader = DataLoader(
    test_dataset,
    batch_size=batch_size,
    shuffle=False,
    num_workers=2
)

print(f"è¨“ç·´ãƒ‡ãƒ¼ã‚¿æ•°: {len(train_dataset)}")
print(f"ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿æ•°: {len(test_dataset)}")
print(f"ãƒãƒƒãƒã‚µã‚¤ã‚º: {batch_size}")
print(f"è¨“ç·´ãƒãƒƒãƒæ•°: {len(train_loader)}")
</code></pre>

<h3>è¨“ç·´ãƒ«ãƒ¼ãƒ—ã®å®Ÿè£…</h3>

<pre><code class="language-python">import torch
import torch.optim as optim

def train_epoch(model, train_loader, optimizer, device):
    """1ã‚¨ãƒãƒƒã‚¯ã®è¨“ç·´"""
    model.train()
    train_loss = 0
    train_recon_loss = 0
    train_kl_loss = 0

    for batch_idx, (data, _) in enumerate(train_loader):
        data = data.to(device)

        # ç”»åƒã‚’å¹³å¦åŒ–ï¼ˆFully-connected VAEã®å ´åˆï¼‰
        data_flat = data.view(data.size(0), -1)

        # Forward
        optimizer.zero_grad()
        x_recon, mu, logvar = model(data_flat)

        # æå¤±è¨ˆç®—
        total_loss, recon_loss, kl_loss = vae_loss(x_recon, data_flat, mu, logvar)

        # Backward
        total_loss.backward()
        optimizer.step()

        # ç´¯ç©
        train_loss += total_loss.item()
        train_recon_loss += recon_loss.item()
        train_kl_loss += kl_loss.item()

    # å¹³å‡æå¤±
    num_samples = len(train_loader.dataset)
    avg_loss = train_loss / num_samples
    avg_recon = train_recon_loss / num_samples
    avg_kl = train_kl_loss / num_samples

    return avg_loss, avg_recon, avg_kl


def test_epoch(model, test_loader, device):
    """ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§ã®è©•ä¾¡"""
    model.eval()
    test_loss = 0
    test_recon_loss = 0
    test_kl_loss = 0

    with torch.no_grad():
        for data, _ in test_loader:
            data = data.to(device)
            data_flat = data.view(data.size(0), -1)

            x_recon, mu, logvar = model(data_flat)
            total_loss, recon_loss, kl_loss = vae_loss(x_recon, data_flat, mu, logvar)

            test_loss += total_loss.item()
            test_recon_loss += recon_loss.item()
            test_kl_loss += kl_loss.item()

    num_samples = len(test_loader.dataset)
    avg_loss = test_loss / num_samples
    avg_recon = test_recon_loss / num_samples
    avg_kl = test_kl_loss / num_samples

    return avg_loss, avg_recon, avg_kl


# è¨“ç·´è¨­å®š
print("\n=== VAEã®è¨“ç·´ ===")

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"ãƒ‡ãƒã‚¤ã‚¹: {device}")

# ãƒ¢ãƒ‡ãƒ«ä½œæˆ
model = VAE(input_dim=784, hidden_dim=400, latent_dim=20).to(device)

# ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶
optimizer = optim.Adam(model.parameters(), lr=1e-3)

# è¨“ç·´
num_epochs = 10
print(f"ã‚¨ãƒãƒƒã‚¯æ•°: {num_epochs}\n")

for epoch in range(1, num_epochs + 1):
    # è¨“ç·´
    train_loss, train_recon, train_kl = train_epoch(model, train_loader, optimizer, device)

    # ãƒ†ã‚¹ãƒˆ
    test_loss, test_recon, test_kl = test_epoch(model, test_loader, device)

    print(f"Epoch {epoch}/{num_epochs}")
    print(f"  Train - Loss: {train_loss:.4f}, Recon: {train_recon:.4f}, KL: {train_kl:.4f}")
    print(f"  Test  - Loss: {test_loss:.4f}, Recon: {test_recon:.4f}, KL: {test_kl:.4f}")

print("\nè¨“ç·´å®Œäº†ï¼")
</code></pre>

<h3>ç”»åƒç”Ÿæˆã¨å¯è¦–åŒ–</h3>

<pre><code class="language-python">import torch
import matplotlib.pyplot as plt
import numpy as np

def visualize_reconstruction(model, test_loader, device, num_samples=10):
    """å†æ§‹æˆçµæœã‚’å¯è¦–åŒ–"""
    model.eval()

    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‹ã‚‰1ãƒãƒƒãƒå–å¾—
    data, _ = next(iter(test_loader))
    data = data[:num_samples].to(device)
    data_flat = data.view(data.size(0), -1)

    # å†æ§‹æˆ
    with torch.no_grad():
        x_recon, mu, logvar = model(data_flat)

    # CPUã«ç§»å‹•
    data = data.cpu().numpy()
    x_recon = x_recon.view(-1, 1, 28, 28).cpu().numpy()

    # å¯è¦–åŒ–
    fig, axes = plt.subplots(2, num_samples, figsize=(num_samples, 2))

    for i in range(num_samples):
        # å…ƒç”»åƒ
        axes[0, i].imshow(data[i, 0], cmap='gray')
        axes[0, i].axis('off')
        if i == 0:
            axes[0, i].set_title('Original', fontsize=10)

        # å†æ§‹æˆç”»åƒ
        axes[1, i].imshow(x_recon[i, 0], cmap='gray')
        axes[1, i].axis('off')
        if i == 0:
            axes[1, i].set_title('Reconstructed', fontsize=10)

    plt.tight_layout()
    plt.savefig('vae_reconstruction.png', dpi=150, bbox_inches='tight')
    print("å†æ§‹æˆçµæœã‚’ä¿å­˜: vae_reconstruction.png")
    plt.close()


def visualize_samples(model, device, num_samples=16):
    """ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã§ç”Ÿæˆã—ãŸç”»åƒã‚’å¯è¦–åŒ–"""
    model.eval()

    # ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
    with torch.no_grad():
        samples = model.sample(num_samples, device)

    samples = samples.view(-1, 1, 28, 28).cpu().numpy()

    # å¯è¦–åŒ–
    fig, axes = plt.subplots(4, 4, figsize=(6, 6))

    for i, ax in enumerate(axes.flat):
        ax.imshow(samples[i, 0], cmap='gray')
        ax.axis('off')

    plt.suptitle('Randomly Generated Samples', fontsize=14)
    plt.tight_layout()
    plt.savefig('vae_samples.png', dpi=150, bbox_inches='tight')
    print("ç”Ÿæˆã‚µãƒ³ãƒ—ãƒ«ã‚’ä¿å­˜: vae_samples.png")
    plt.close()


# å¯è¦–åŒ–å®Ÿè¡Œ
print("\n=== çµæœã®å¯è¦–åŒ– ===")
visualize_reconstruction(model, test_loader, device, num_samples=10)
visualize_samples(model, device, num_samples=16)
print("â†’ VAEã¯å…ƒç”»åƒã‚’å¾©å…ƒã—ã€æ–°ã—ã„ç”»åƒã‚’ç”Ÿæˆã§ãã‚‹ï¼")
</code></pre>

<hr>

<h2>2.6 æ½œåœ¨ç©ºé–“ã®å¯è¦–åŒ–ã¨è£œé–“</h2>

<h3>2æ¬¡å…ƒæ½œåœ¨ç©ºé–“ã®å¯è¦–åŒ–</h3>

<pre><code class="language-python">import torch
import matplotlib.pyplot as plt
import numpy as np

def visualize_latent_space_2d(model, test_loader, device):
    """2æ¬¡å…ƒæ½œåœ¨ç©ºé–“ã‚’å¯è¦–åŒ–ï¼ˆlatent_dim=2ã®å ´åˆï¼‰"""
    model.eval()

    z_list = []
    label_list = []

    with torch.no_grad():
        for data, labels in test_loader:
            data = data.to(device)
            data_flat = data.view(data.size(0), -1)

            mu, logvar = model.encode(data_flat)
            z_list.append(mu.cpu())
            label_list.append(labels)

    z = torch.cat(z_list, dim=0).numpy()
    labels = torch.cat(label_list, dim=0).numpy()

    # æ•£å¸ƒå›³
    plt.figure(figsize=(10, 8))
    scatter = plt.scatter(z[:, 0], z[:, 1], c=labels, cmap='tab10', alpha=0.6, s=5)
    plt.colorbar(scatter)
    plt.xlabel('Latent Dimension 1')
    plt.ylabel('Latent Dimension 2')
    plt.title('2D Latent Space Visualization (MNIST)')
    plt.grid(True, alpha=0.3)
    plt.savefig('vae_latent_2d.png', dpi=150, bbox_inches='tight')
    print("2Dæ½œåœ¨ç©ºé–“ã‚’ä¿å­˜: vae_latent_2d.png")
    plt.close()


# 2æ¬¡å…ƒVAEã§å®Ÿé¨“
print("\n=== 2æ¬¡å…ƒæ½œåœ¨ç©ºé–“ã®å¯è¦–åŒ– ===")
model_2d = VAE(input_dim=784, hidden_dim=400, latent_dim=2).to(device)

# ç°¡æ˜“è¨“ç·´ï¼ˆçœç•¥å¯èƒ½ - äº‹å‰è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ï¼‰
optimizer_2d = optim.Adam(model_2d.parameters(), lr=1e-3)
for epoch in range(3):
    train_loss, _, _ = train_epoch(model_2d, train_loader, optimizer_2d, device)
    print(f"Epoch {epoch+1}: Loss = {train_loss:.4f}")

# å¯è¦–åŒ–
visualize_latent_space_2d(model_2d, test_loader, device)
print("â†’ ç•°ãªã‚‹æ•°å­—ãŒã‚¯ãƒ©ã‚¹ã‚¿ã‚’å½¢æˆã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª")
</code></pre>

<h3>æ½œåœ¨ç©ºé–“ã®è£œé–“ï¼ˆInterpolationï¼‰</h3>

<pre><code class="language-python">import torch
import matplotlib.pyplot as plt

def interpolate_latent_space(model, z_start, z_end, num_steps=10):
    """
    æ½œåœ¨ç©ºé–“ã§2ç‚¹ã‚’è£œé–“

    Args:
        model: VAEãƒ¢ãƒ‡ãƒ«
        z_start: (latent_dim,) - é–‹å§‹ç‚¹
        z_end: (latent_dim,) - çµ‚äº†ç‚¹
        num_steps: è£œé–“ã‚¹ãƒ†ãƒƒãƒ—æ•°

    Returns:
        interpolated_images: (num_steps, 1, 28, 28)
    """
    model.eval()

    # ç·šå½¢è£œé–“
    alphas = torch.linspace(0, 1, num_steps)
    z_interp = torch.stack([
        (1 - alpha) * z_start + alpha * z_end
        for alpha in alphas
    ])

    # Decoderã§ç”Ÿæˆ
    with torch.no_grad():
        images = model.decode(z_interp)

    images = images.view(-1, 1, 28, 28)

    return images


def visualize_interpolation(model, test_loader, device, num_pairs=3, num_steps=10):
    """è£œé–“çµæœã‚’å¯è¦–åŒ–"""
    model.eval()

    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ç”»åƒã‚’é¸æŠ
    data, _ = next(iter(test_loader))
    data = data[:num_pairs*2].to(device)
    data_flat = data.view(data.size(0), -1)

    # Encodeã—ã¦æ½œåœ¨å¤‰æ•°ã‚’å–å¾—
    with torch.no_grad():
        mu, _ = model.encode(data_flat)

    # å¯è¦–åŒ–
    fig, axes = plt.subplots(num_pairs, num_steps, figsize=(num_steps, num_pairs))

    for i in range(num_pairs):
        z_start = mu[i*2]
        z_end = mu[i*2 + 1]

        # è£œé–“
        images = interpolate_latent_space(model, z_start, z_end, num_steps)
        images = images.cpu().numpy()

        for j in range(num_steps):
            ax = axes[i, j] if num_pairs > 1 else axes[j]
            ax.imshow(images[j, 0], cmap='gray')
            ax.axis('off')

    plt.suptitle('Latent Space Interpolation', fontsize=14)
    plt.tight_layout()
    plt.savefig('vae_interpolation.png', dpi=150, bbox_inches='tight')
    print("è£œé–“çµæœã‚’ä¿å­˜: vae_interpolation.png")
    plt.close()


# è£œé–“ã®å¯è¦–åŒ–
print("\n=== æ½œåœ¨ç©ºé–“ã®è£œé–“ ===")
visualize_interpolation(model, test_loader, device, num_pairs=3, num_steps=10)
print("â†’ æ»‘ã‚‰ã‹ã«å¤‰åŒ–ã™ã‚‹ä¸­é–“ç”»åƒãŒç”Ÿæˆã•ã‚Œã‚‹")
</code></pre>

<h3>æ½œåœ¨ç©ºé–“ã®æ§‹é€ ã‚’æ¢ç´¢</h3>

<pre><code class="language-python">import torch
import matplotlib.pyplot as plt
import numpy as np

def visualize_latent_manifold(model, device, n=20, digit_size=28):
    """
    2æ¬¡å…ƒæ½œåœ¨ç©ºé–“ã®ãƒãƒ‹ãƒ•ã‚©ãƒ¼ãƒ«ãƒ‰ã‚’å¯è¦–åŒ–

    Args:
        model: 2æ¬¡å…ƒæ½œåœ¨å¤‰æ•°ã‚’æŒã¤VAE
        device: ãƒ‡ãƒã‚¤ã‚¹
        n: ã‚°ãƒªãƒƒãƒ‰ã‚µã‚¤ã‚º
        digit_size: ç”»åƒã‚µã‚¤ã‚º
    """
    model.eval()

    # ã‚°ãƒªãƒƒãƒ‰ç¯„å›²ï¼ˆæ­£è¦åˆ†å¸ƒã®99%ã‚’ã‚«ãƒãƒ¼ï¼‰
    grid_range = 3
    grid_x = np.linspace(-grid_range, grid_range, n)
    grid_y = np.linspace(-grid_range, grid_range, n)

    # å…¨ä½“ç”»åƒã®æº–å‚™
    figure = np.zeros((digit_size * n, digit_size * n))

    with torch.no_grad():
        for i, yi in enumerate(grid_y):
            for j, xi in enumerate(grid_x):
                # æ½œåœ¨å¤‰æ•°
                z = torch.tensor([[xi, yi]], dtype=torch.float32).to(device)

                # Decoderã§ç”Ÿæˆ
                x_recon = model.decode(z)
                digit = x_recon.view(digit_size, digit_size).cpu().numpy()

                # é…ç½®
                figure[i * digit_size: (i + 1) * digit_size,
                       j * digit_size: (j + 1) * digit_size] = digit

    # å¯è¦–åŒ–
    plt.figure(figsize=(10, 10))
    plt.imshow(figure, cmap='gray')
    plt.axis('off')
    plt.title('Latent Space Manifold (2D)', fontsize=14)
    plt.savefig('vae_manifold.png', dpi=150, bbox_inches='tight')
    print("æ½œåœ¨ç©ºé–“ãƒãƒ‹ãƒ•ã‚©ãƒ¼ãƒ«ãƒ‰ã‚’ä¿å­˜: vae_manifold.png")
    plt.close()


# ãƒãƒ‹ãƒ•ã‚©ãƒ¼ãƒ«ãƒ‰ã®å¯è¦–åŒ–
print("\n=== æ½œåœ¨ç©ºé–“ãƒãƒ‹ãƒ•ã‚©ãƒ¼ãƒ«ãƒ‰ ===")
visualize_latent_manifold(model_2d, device, n=20, digit_size=28)
print("â†’ 2æ¬¡å…ƒç©ºé–“ã§æ•°å­—ãŒã©ã®ã‚ˆã†ã«åˆ†å¸ƒã—ã¦ã„ã‚‹ã‹ã‚’ç¢ºèª")
</code></pre>

<hr>

<h2>2.7 å®Ÿè·µï¼šCelebAé¡”ç”»åƒç”Ÿæˆ</h2>

<h3>CelebAç”¨ç•³ã¿è¾¼ã¿VAE</h3>

<pre><code class="language-python">import torch
import torch.nn as nn
import torch.nn.functional as F

class CelebAVAE(nn.Module):
    """CelebAé¡”ç”»åƒç”¨ã®VAEï¼ˆ64x64è§£åƒåº¦ï¼‰"""
    def __init__(self, input_channels=3, latent_dim=256):
        super(CelebAVAE, self).__init__()

        self.latent_dim = latent_dim

        # ===== Encoder =====
        self.encoder = nn.Sequential(
            # 64x64 -> 32x32
            nn.Conv2d(input_channels, 32, kernel_size=4, stride=2, padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(),
            # 32x32 -> 16x16
            nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(),
            # 16x16 -> 8x8
            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(),
            # 8x8 -> 4x4
            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(),
        )

        self.fc_mu = nn.Linear(256 * 4 * 4, latent_dim)
        self.fc_logvar = nn.Linear(256 * 4 * 4, latent_dim)

        # ===== Decoder =====
        self.decoder_fc = nn.Linear(latent_dim, 256 * 4 * 4)

        self.decoder = nn.Sequential(
            # 4x4 -> 8x8
            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(),
            # 8x8 -> 16x16
            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(),
            # 16x16 -> 32x32
            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(),
            # 32x32 -> 64x64
            nn.ConvTranspose2d(32, input_channels, kernel_size=4, stride=2, padding=1),
            nn.Sigmoid(),
        )

    def encode(self, x):
        h = self.encoder(x)
        h = h.view(h.size(0), -1)
        mu = self.fc_mu(h)
        logvar = self.fc_logvar(h)
        return mu, logvar

    def reparameterize(self, mu, logvar):
        std = torch.exp(0.5 * logvar)
        epsilon = torch.randn_like(std)
        z = mu + std * epsilon
        return z

    def decode(self, z):
        h = self.decoder_fc(z)
        h = h.view(h.size(0), 256, 4, 4)
        x_recon = self.decoder(h)
        return x_recon

    def forward(self, x):
        mu, logvar = self.encode(x)
        z = self.reparameterize(mu, logvar)
        x_recon = self.decode(z)
        return x_recon, mu, logvar

    def sample(self, num_samples, device='cpu'):
        z = torch.randn(num_samples, self.latent_dim).to(device)
        samples = self.decode(z)
        return samples


# ãƒ¢ãƒ‡ãƒ«ä½œæˆ
print("\n=== CelebA VAEã®ä½œæˆ ===")
celeba_vae = CelebAVAE(input_channels=3, latent_dim=256)

# å‹•ä½œç¢ºèª
batch_size = 16
x_celeba = torch.rand(batch_size, 3, 64, 64)  # RGB 64x64ç”»åƒ

x_recon, mu, logvar = celeba_vae(x_celeba)

print(f"å…¥åŠ›ç”»åƒ: {x_celeba.shape}")
print(f"å¾©å…ƒç”»åƒ: {x_recon.shape}")
print(f"æ½œåœ¨å¤‰æ•°: {mu.shape}")

# ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°
total_params = sum(p.numel() for p in celeba_vae.parameters())
print(f"ç·ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {total_params:,}")
print("â†’ é«˜è§£åƒåº¦ç”»åƒç”¨ã®æ·±ã„ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£")
</code></pre>

<hr>

<h2>æ¼”ç¿’å•é¡Œ</h2>

<details>
<summary><strong>æ¼”ç¿’1ï¼šÎ²-VAEã®å®Ÿè£…</strong></summary>

<p>KLé …ã«é‡ã¿$\beta$ã‚’å°å…¥ã—ãŸ<strong>Î²-VAE</strong>ã‚’å®Ÿè£…ã—ã€$\beta$ã®å€¤ã«ã‚ˆã‚‹æ½œåœ¨ç©ºé–“ã®é•ã„ã‚’åˆ†æã—ã¦ãã ã•ã„ã€‚</p>

<pre><code class="language-python">import torch

# TODO: Î²-VAEã®æå¤±é–¢æ•°ã‚’å®Ÿè£…
# Loss = Reconstruction + Î² * KL divergence

# TODO: Î² = 0.5, 1.0, 2.0, 4.0 ã§è¨“ç·´
# TODO: æ½œåœ¨ç©ºé–“ã®å¯è¦–åŒ–ã§ disentanglementï¼ˆåˆ†é›¢æ€§ï¼‰ã‚’è©•ä¾¡
# ãƒ’ãƒ³ãƒˆ: Î²ãŒå¤§ãã„ã»ã©æ½œåœ¨å¤‰æ•°ãŒç‹¬ç«‹ã«ãªã‚‹
</code></pre>

</details>

<details>
<summary><strong>æ¼”ç¿’2ï¼šæ½œåœ¨æ¬¡å…ƒæ•°ã®å½±éŸ¿ã‚’èª¿æŸ»</strong></summary>

<p>æ½œåœ¨æ¬¡å…ƒæ•°ï¼ˆ2, 10, 20, 50, 100ï¼‰ã‚’å¤‰ãˆã¦ã€å†æ§‹æˆå“è³ªã¨ç”Ÿæˆå¤šæ§˜æ€§ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’èª¿æŸ»ã—ã¦ãã ã•ã„ã€‚</p>

<pre><code class="language-python">import torch

# TODO: ç•°ãªã‚‹æ½œåœ¨æ¬¡å…ƒæ•°ã§ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´
# TODO: å†æ§‹æˆèª¤å·®ã€KL divergenceã€ç”Ÿæˆç”»åƒã®å“è³ªã‚’æ¯”è¼ƒ
# TODO: æ¬¡å…ƒæ•° vs æ€§èƒ½ã®ã‚°ãƒ©ãƒ•ã‚’ä½œæˆ
# æœŸå¾…: æ¬¡å…ƒæ•°ãŒå¤šã„ã»ã©å†æ§‹æˆã¯è‰¯ã„ãŒã€ç”Ÿæˆã®å¤šæ§˜æ€§ãŒä½ä¸‹
</code></pre>

</details>

<details>
<summary><strong>æ¼”ç¿’3ï¼šæ¡ä»¶ä»˜ãVAEï¼ˆCVAEï¼‰ã®å®Ÿè£…</strong></summary>

<p>ã‚¯ãƒ©ã‚¹ãƒ©ãƒ™ãƒ«ã‚’æ¡ä»¶ã¨ã—ã¦ä¸ãˆã‚‹<strong>Conditional VAE</strong>ã‚’å®Ÿè£…ã—ã¦ãã ã•ã„ã€‚</p>

<pre><code class="language-python">import torch
import torch.nn as nn

# TODO: Encoderã¨Decoderã«ã‚¯ãƒ©ã‚¹ãƒ©ãƒ™ãƒ«ã‚’å…¥åŠ›
# TODO: æŒ‡å®šã—ãŸã‚¯ãƒ©ã‚¹ã®ç”»åƒã‚’ç”Ÿæˆã§ãã‚‹ã“ã¨ã‚’ç¢ºèª
# TODO: ç•°ãªã‚‹ã‚¯ãƒ©ã‚¹é–“ã®è£œé–“ã‚’å¯è¦–åŒ–
</code></pre>

</details>

<details>
<summary><strong>æ¼”ç¿’4ï¼šå†æ§‹æˆèª¤å·®ã®æ¯”è¼ƒï¼ˆMSE vs BCEï¼‰</strong></summary>

<p>å†æ§‹æˆèª¤å·®ã¨ã—ã¦ã€MSEï¼ˆå¹³å‡äºŒä¹—èª¤å·®ï¼‰ã¨BCEï¼ˆBinary Cross Entropyï¼‰ã‚’æ¯”è¼ƒã—ã¦ãã ã•ã„ã€‚</p>

<pre><code class="language-python">import torch
import torch.nn.functional as F

# TODO: 2ã¤ã®æå¤±é–¢æ•°ã§ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´
# TODO: å†æ§‹æˆç”»åƒã®å“è³ªã‚’è¦–è¦šçš„ã«æ¯”è¼ƒ
# TODO: æå¤±ã®åæŸé€Ÿåº¦ã¨æœ€çµ‚å€¤ã‚’è¨˜éŒ²
# åˆ†æ: BCEã¯ç¢ºç‡çš„è§£é‡ˆãŒã‚ã‚Šã€MNISTã®ã‚ˆã†ãª2å€¤ç”»åƒã«é©ã—ã¦ã„ã‚‹
</code></pre>

</details>

<details>
<summary><strong>æ¼”ç¿’5ï¼šKL Annealingã®å®Ÿè£…</strong></summary>

<p>è¨“ç·´åˆæœŸã¯KLé …ã®é‡ã¿ã‚’å°ã•ãã—ã€å¾ã€…ã«å¢—ã‚„ã™<strong>KL Annealing</strong>ã‚’å®Ÿè£…ã—ã¦ãã ã•ã„ã€‚</p>

<pre><code class="language-python">import torch

# TODO: KLé …ã®é‡ã¿ã‚’ã‚¨ãƒãƒƒã‚¯ã”ã¨ã«ç·šå½¢å¢—åŠ 
# weight = min(1.0, epoch / num_annealing_epochs)

# TODO: Annealingã‚ã‚Šãƒ»ãªã—ã§åæŸé€Ÿåº¦ã‚’æ¯”è¼ƒ
# TODO: æœ€çµ‚çš„ãªæ½œåœ¨ç©ºé–“ã®å“è³ªã‚’è©•ä¾¡
# æœŸå¾…: Annealingã«ã‚ˆã‚Šè¨“ç·´ãŒå®‰å®šã—ã€ã‚ˆã‚Šè‰¯ã„æ½œåœ¨ç©ºé–“ãŒå¾—ã‚‰ã‚Œã‚‹
</code></pre>

</details>

<hr>

<h2>ã¾ã¨ã‚</h2>

<p>ã“ã®ç« ã§ã¯ã€VAEï¼ˆVariational Autoencoderï¼‰ã®ç†è«–ã¨å®Ÿè£…ã‚’å­¦ã³ã¾ã—ãŸã€‚</p>

<h3>é‡è¦ãƒã‚¤ãƒ³ãƒˆ</h3>

<ul>
<li><strong>Autoencoderã®é™ç•Œ</strong>ï¼šæ±ºå®šè«–çš„ã§æ§‹é€ åŒ–ã•ã‚Œã¦ã„ãªã„æ½œåœ¨ç©ºé–“</li>
<li><strong>VAEã®å‹•æ©Ÿ</strong>ï¼šç¢ºç‡çš„æ çµ„ã¿ã§ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦ã®èƒ½åŠ›ã‚’ç²å¾—</li>
<li><strong>ELBO</strong>ï¼šå†æ§‹æˆé …ã¨KLæ­£å‰‡åŒ–é …ã®2ã¤ã§æ§‹æˆã•ã‚Œã‚‹ç›®çš„é–¢æ•°</li>
<li><strong>KL Divergence</strong>ï¼šæ½œåœ¨å¤‰æ•°ã‚’æ¨™æº–æ­£è¦åˆ†å¸ƒã«æ­£å‰‡åŒ–</li>
<li><strong>Reparameterization Trick</strong>ï¼šç¢ºç‡çš„ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã‚’å¾®åˆ†å¯èƒ½ã«ã™ã‚‹æŠ€è¡“</li>
<li><strong>Encoder/Decoder</strong>ï¼šã‚¬ã‚¦ã‚¹åˆ†å¸ƒã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆå¹³å‡ãƒ»åˆ†æ•£ï¼‰ã‚’å‡ºåŠ›</li>
<li><strong>æ½œåœ¨ç©ºé–“</strong>ï¼šæ§‹é€ åŒ–ã•ã‚Œã¦ãŠã‚Šã€è£œé–“ã‚„æ¢ç´¢ãŒå¯èƒ½</li>
<li><strong>å®Ÿè£…</strong>ï¼šMNIST/CelebAç”»åƒç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ ã®å®Œå…¨å®Ÿè£…</li>
<li><strong>å¿œç”¨</strong>ï¼šÎ²-VAEã€CVAEã€KL Annealingãªã©ã®æ‹¡å¼µæŠ€è¡“</li>
</ul>

<h3>æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—</h3>

<p>æ¬¡ç« ã§ã¯ã€<strong>GANï¼ˆGenerative Adversarial Networksï¼‰</strong>ã«ã¤ã„ã¦å­¦ã³ã¾ã™ã€‚æ•µå¯¾çš„å­¦ç¿’ã«ã‚ˆã‚‹ã‚ˆã‚Šé«˜å“è³ªãªç”»åƒç”Ÿæˆã€Generator/Discriminatorã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã€è¨“ç·´ã®å®‰å®šåŒ–æŠ€è¡“ãªã©ã€VAEã¨ã¯ç•°ãªã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã®ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã‚’ç¿’å¾—ã—ã¾ã™ã€‚</p>

<div class="navigation">
    <a href="chapter1-fundamentals.html" class="nav-button">â† ç¬¬1ç« ï¼šAutoencoderåŸºç¤</a>
    <a href="chapter3-gan.html" class="nav-button">ç¬¬3ç« ï¼šGAN â†’</a>
</div>

</main>


    <section class="disclaimer">
        <h3>å…è²¬äº‹é …</h3>
        <ul>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯æ•™è‚²ãƒ»ç ”ç©¶ãƒ»æƒ…å ±æä¾›ã®ã¿ã‚’ç›®çš„ã¨ã—ã¦ãŠã‚Šã€å°‚é–€çš„ãªåŠ©è¨€(æ³•å¾‹ãƒ»ä¼šè¨ˆãƒ»æŠ€è¡“çš„ä¿è¨¼ãªã©)ã‚’æä¾›ã™ã‚‹ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŠã‚ˆã³ä»˜éšã™ã‚‹ã‚³ãƒ¼ãƒ‰ä¾‹ã¯ã€Œç¾çŠ¶æœ‰å§¿(AS IS)ã€ã§æä¾›ã•ã‚Œã€æ˜ç¤ºã¾ãŸã¯é»™ç¤ºã‚’å•ã‚ãšã€å•†å“æ€§ã€ç‰¹å®šç›®çš„é©åˆæ€§ã€æ¨©åˆ©éä¾µå®³ã€æ­£ç¢ºæ€§ãƒ»å®Œå…¨æ€§ã€å‹•ä½œãƒ»å®‰å…¨æ€§ç­‰ã„ã‹ãªã‚‹ä¿è¨¼ã‚‚ã—ã¾ã›ã‚“ã€‚</li>
            <li>å¤–éƒ¨ãƒªãƒ³ã‚¯ã€ç¬¬ä¸‰è€…ãŒæä¾›ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ»ãƒ„ãƒ¼ãƒ«ãƒ»ãƒ©ã‚¤ãƒ–ãƒ©ãƒªç­‰ã®å†…å®¹ãƒ»å¯ç”¨æ€§ãƒ»å®‰å…¨æ€§ã«ã¤ã„ã¦ã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯ä¸€åˆ‡ã®è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®åˆ©ç”¨ãƒ»å®Ÿè¡Œãƒ»è§£é‡ˆã«ã‚ˆã‚Šç›´æ¥çš„ãƒ»é–“æ¥çš„ãƒ»ä»˜éšçš„ãƒ»ç‰¹åˆ¥ãƒ»çµæœçš„ãƒ»æ‡²ç½°çš„æå®³ãŒç”Ÿã˜ãŸå ´åˆã§ã‚‚ã€é©ç”¨æ³•ã§è¨±å®¹ã•ã‚Œã‚‹æœ€å¤§é™ã®ç¯„å›²ã§ã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å†…å®¹ã¯ã€äºˆå‘Šãªãå¤‰æ›´ãƒ»æ›´æ–°ãƒ»æä¾›åœæ­¢ã•ã‚Œã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®è‘—ä½œæ¨©ãƒ»ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯æ˜è¨˜ã•ã‚ŒãŸæ¡ä»¶(ä¾‹: CC BY 4.0)ã«å¾“ã„ã¾ã™ã€‚å½“è©²ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯é€šå¸¸ã€ç„¡ä¿è¨¼æ¡é …ã‚’å«ã¿ã¾ã™ã€‚</li>
        </ul>
    </section>

<footer>
    <p>&copy; 2024 AI Terakoya. All rights reserved.</p>
</footer>

</body>
</html>
