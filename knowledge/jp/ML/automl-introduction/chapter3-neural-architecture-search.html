<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Á¨¨3Á´†ÔºöNeural Architecture Search - AI Terakoya</title>

    <style>
        :root {
            --color-primary: #2c3e50;
            --color-primary-dark: #1a252f;
            --color-accent: #7b2cbf;
            --color-accent-light: #9d4edd;
            --color-text: #2d3748;
            --color-text-light: #4a5568;
            --color-bg: #ffffff;
            --color-bg-alt: #f7fafc;
            --color-border: #e2e8f0;
            --color-code-bg: #f8f9fa;
            --color-link: #3182ce;
            --color-link-hover: #2c5aa0;

            --spacing-xs: 0.5rem;
            --spacing-sm: 1rem;
            --spacing-md: 1.5rem;
            --spacing-lg: 2rem;
            --spacing-xl: 3rem;

            --font-body: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            --font-mono: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;

            --border-radius: 8px;
            --box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: var(--font-body);
            line-height: 1.7;
            color: var(--color-text);
            background-color: var(--color-bg);
            font-size: 16px;
        }

        header {
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            padding: var(--spacing-xl) var(--spacing-md);
            margin-bottom: var(--spacing-xl);
            box-shadow: var(--box-shadow);
        }

        .header-content {
            max-width: 900px;
            margin: 0 auto;
        }

        h1 {
            font-size: 2rem;
            font-weight: 700;
            margin-bottom: var(--spacing-sm);
            line-height: 1.2;
        }

        .subtitle {
            font-size: 1.1rem;
            opacity: 0.95;
            font-weight: 400;
            margin-bottom: var(--spacing-md);
        }

        .meta {
            display: flex;
            flex-wrap: wrap;
            gap: var(--spacing-md);
            font-size: 0.9rem;
            opacity: 0.9;
        }

        .meta-item {
            display: flex;
            align-items: center;
            gap: 0.3rem;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 0 var(--spacing-md) var(--spacing-xl);
        }

        h2 {
            font-size: 1.75rem;
            color: var(--color-primary);
            margin-top: var(--spacing-xl);
            margin-bottom: var(--spacing-md);
            padding-bottom: var(--spacing-xs);
            border-bottom: 3px solid var(--color-accent);
        }

        h3 {
            font-size: 1.4rem;
            color: var(--color-primary);
            margin-top: var(--spacing-lg);
            margin-bottom: var(--spacing-sm);
        }

        h4 {
            font-size: 1.1rem;
            color: var(--color-primary-dark);
            margin-top: var(--spacing-md);
            margin-bottom: var(--spacing-sm);
        }

        p {
            margin-bottom: var(--spacing-md);
            color: var(--color-text);
        }

        a {
            color: var(--color-link);
            text-decoration: none;
            transition: color 0.2s;
        }

        a:hover {
            color: var(--color-link-hover);
            text-decoration: underline;
        }

        ul, ol {
            margin-left: var(--spacing-lg);
            margin-bottom: var(--spacing-md);
        }

        li {
            margin-bottom: var(--spacing-xs);
            color: var(--color-text);
        }

        pre {
            background-color: var(--color-code-bg);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            overflow-x: auto;
            margin-bottom: var(--spacing-md);
            font-family: var(--font-mono);
            font-size: 0.9rem;
            line-height: 1.5;
        }

        code {
            font-family: var(--font-mono);
            font-size: 0.9em;
            background-color: var(--color-code-bg);
            padding: 0.2em 0.4em;
            border-radius: 3px;
        }

        pre code {
            background-color: transparent;
            padding: 0;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: var(--spacing-md);
            font-size: 0.95rem;
        }

        th, td {
            border: 1px solid var(--color-border);
            padding: var(--spacing-sm);
            text-align: left;
        }

        th {
            background-color: var(--color-bg-alt);
            font-weight: 600;
            color: var(--color-primary);
        }

        blockquote {
            border-left: 4px solid var(--color-accent);
            padding-left: var(--spacing-md);
            margin: var(--spacing-md) 0;
            color: var(--color-text-light);
            font-style: italic;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        .mermaid {
            text-align: center;
            margin: var(--spacing-lg) 0;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        details {
            background-color: var(--color-bg-alt);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            margin-bottom: var(--spacing-md);
        }

        summary {
            cursor: pointer;
            font-weight: 600;
            color: var(--color-primary);
            user-select: none;
            padding: var(--spacing-xs);
            margin: calc(-1 * var(--spacing-md));
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        summary:hover {
            background-color: rgba(123, 44, 191, 0.1);
        }

        details[open] summary {
            margin-bottom: var(--spacing-md);
            border-bottom: 1px solid var(--color-border);
        }

        .navigation {
            display: flex;
            justify-content: space-between;
            gap: var(--spacing-md);
            margin: var(--spacing-xl) 0;
            padding-top: var(--spacing-lg);
            border-top: 2px solid var(--color-border);
        }

        .nav-button {
            flex: 1;
            padding: var(--spacing-md);
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            border-radius: var(--border-radius);
            text-align: center;
            font-weight: 600;
            transition: transform 0.2s, box-shadow 0.2s;
            box-shadow: var(--box-shadow);
        }

        .nav-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
            text-decoration: none;
        }

        footer {
            margin-top: var(--spacing-xl);
            padding: var(--spacing-lg) var(--spacing-md);
            background-color: var(--color-bg-alt);
            border-top: 1px solid var(--color-border);
            text-align: center;
            font-size: 0.9rem;
            color: var(--color-text-light);
        }

        @media (max-width: 768px) {
            h1 {
                font-size: 1.5rem;
            }

            h2 {
                font-size: 1.4rem;
            }

            h3 {
                font-size: 1.2rem;
            }

            .meta {
                font-size: 0.85rem;
            }

            .navigation {
                flex-direction: column;
            }

            table {
                font-size: 0.85rem;
            }

            th, td {
                padding: var(--spacing-xs);
            }
        }
    </style>

    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
        mermaid.initialize({ startOnLoad: true, theme: 'default' });
    </script>

    <!-- MathJax for LaTeX equation rendering -->
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                displayMath: [['$$', '$$'], ['\\[', '\\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
                ignoreHtmlClass: 'mermaid'
            }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" async></script>
</head>
<body>
    <header>
        <div class="header-content">
            <h1>Á¨¨3Á´†ÔºöNeural Architecture Search</h1>
            <p class="subtitle">„Éã„É•„Éº„É©„É´„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ„ÅÆËá™ÂãïË®≠Ë®à - DARTS„Å®AutoKeras„Å´„Çà„ÇãÊúÄÈÅ©„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£„ÅÆÊé¢Á¥¢</p>
            <div class="meta">
                <span class="meta-item">üìñ Ë™≠‰∫ÜÊôÇÈñì: 35-40ÂàÜ</span>
                <span class="meta-item">üìä Èõ£ÊòìÂ∫¶: ‰∏≠Á¥ö-‰∏äÁ¥ö</span>
                <span class="meta-item">üíª „Ç≥„Éº„Éâ‰æã: 8ÂÄã</span>
                <span class="meta-item">üìù ÊºîÁøíÂïèÈ°å: 5Âïè</span>
            </div>
        </div>
    </header>

    <main class="container">

<h2>Â≠¶ÁøíÁõÆÊ®ô</h2>
<p>„Åì„ÅÆÁ´†„ÇíË™≠„ÇÄ„Åì„Å®„Åß„ÄÅ‰ª•‰∏ã„ÇíÁøíÂæó„Åß„Åç„Åæ„ÅôÔºö</p>
<ul>
<li>‚úÖ Neural Architecture SearchÔºàNASÔºâ„ÅÆÊé¢Á¥¢Á©∫ÈñìË®≠Ë®à„ÇíÁêÜËß£„Åô„Çã</li>
<li>‚úÖ NAS„ÅÆ‰∏ªË¶Å„Å™Êé¢Á¥¢Êà¶Áï•ÔºàÂº∑ÂåñÂ≠¶Áøí„ÄÅÈÄ≤Âåñ„Ç¢„É´„Ç¥„É™„Ç∫„É†„ÄÅÂãæÈÖç„Éô„Éº„ÇπÔºâ„ÇíÁêÜËß£„Åô„Çã</li>
<li>‚úÖ AutoKeras„Çí‰Ωø„Å£„ÅüËá™Âãï„É¢„Éá„É´Êé¢Á¥¢„ÇíÂÆüË£Ö„Åß„Åç„Çã</li>
<li>‚úÖ DARTSÔºàÂæÆÂàÜÂèØËÉΩ„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£Êé¢Á¥¢Ôºâ„ÅÆÂéüÁêÜ„Å®ÂÆüË£Ö„ÇíÁêÜËß£„Åô„Çã</li>
<li>‚úÖ NAS„ÅÆÂäπÁéáÂåñÊâãÊ≥ïÔºàWeight Sharing„ÄÅProxy TasksÔºâ„ÇíÁêÜËß£„Åô„Çã</li>
<li>‚úÖ ÂÆü„Éá„Éº„Çø„ÅßAutoKeras„Å®DARTS„ÇíÊ¥ªÁî®„Åß„Åç„Çã</li>
</ul>

<hr>

<h2>3.1 NAS„ÅÆÊé¢Á¥¢Á©∫Èñì</h2>

<h3>Neural Architecture Search„Å®„ÅØ</h3>
<p><strong>Neural Architecture SearchÔºàNASÔºâ</strong>„ÅØ„ÄÅ„Éã„É•„Éº„É©„É´„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ„ÅÆ„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£„ÇíËá™ÂãïÁöÑ„Å´Ë®≠Ë®à„Åô„ÇãÊäÄË°ì„Åß„Åô„ÄÇ</p>

<blockquote>
<p>„ÄåÊâãÂãïË®≠Ë®à vs Ëá™ÂãïË®≠Ë®à„Äç- NAS„ÅØ‰∫∫Èñì„ÅÆÂ∞ÇÈñÄÁü•Ë≠ò„ÇíË∂Ö„Åà„Çã„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£„ÇíÁô∫Ë¶ã„Åß„Åç„Åæ„Åô„ÄÇ</p>
</blockquote>

<h3>NAS„ÅÆ3Ë¶ÅÁ¥†</h3>

<table>
<thead>
<tr>
<th>Ë¶ÅÁ¥†</th>
<th>Ë™¨Êòé</th>
<th>‰æã</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Êé¢Á¥¢Á©∫Èñì</strong></td>
<td>Êé¢Á¥¢ÂèØËÉΩ„Å™„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£„ÅÆÈõÜÂêà</td>
<td>Cell-based„ÄÅMacro„ÄÅMicro</td>
</tr>
<tr>
<td><strong>Êé¢Á¥¢Êà¶Áï•</strong></td>
<td>„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£„ÅÆÊé¢Á¥¢ÊñπÊ≥ï</td>
<td>Âº∑ÂåñÂ≠¶Áøí„ÄÅÈÄ≤Âåñ„ÄÅÂãæÈÖç„Éô„Éº„Çπ</td>
</tr>
<tr>
<td><strong>ÊÄßËÉΩË©ï‰æ°</strong></td>
<td>„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£„ÅÆËâØ„ÅóÊÇ™„Åó„ÅÆÂà§ÂÆö</td>
<td>Á≤æÂ∫¶„ÄÅFLOPs„ÄÅ„É¨„Ç§„ÉÜ„É≥„Ç∑</td>
</tr>
</tbody>
</table>

<h3>Cell-based Search Space</h3>

<p><strong>Cell-basedÊé¢Á¥¢Á©∫Èñì</strong>„Åß„ÅØ„ÄÅÁπ∞„ÇäËøî„Åó‰ΩøÁî®„Åï„Çå„Çã„ÄåCell„Äç„ÇíÊé¢Á¥¢„Åó„Åæ„Åô„ÄÇ</p>

<div class="mermaid">
graph TD
    A[ÂÖ•ÂäõÁîªÂÉè] --> B[Stem Convolution]
    B --> C[Normal Cell 1]
    C --> D[Normal Cell 2]
    D --> E[Reduction Cell]
    E --> F[Normal Cell 3]
    F --> G[Normal Cell 4]
    G --> H[Reduction Cell]
    H --> I[Normal Cell 5]
    I --> J[Global Pool]
    J --> K[Softmax]

    style C fill:#e3f2fd
    style D fill:#e3f2fd
    style E fill:#ffebee
    style F fill:#e3f2fd
    style G fill:#e3f2fd
    style H fill:#ffebee
    style I fill:#e3f2fd
</div>

<h4>Cell„ÅÆÁ®ÆÈ°û</h4>

<table>
<thead>
<tr>
<th>CellÁ®ÆÈ°û</th>
<th>ÂΩπÂâ≤</th>
<th>Á©∫ÈñìËß£ÂÉèÂ∫¶</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Normal Cell</strong></td>
<td>ÁâπÂæ¥ÊäΩÂá∫</td>
<td>Á∂≠ÊåÅ</td>
</tr>
<tr>
<td><strong>Reduction Cell</strong></td>
<td>„ÉÄ„Ç¶„É≥„Çµ„É≥„Éó„É™„É≥„Ç∞</td>
<td>1/2„Å´ÂâäÊ∏õ</td>
</tr>
</tbody>
</table>

<h3>Macro vs Micro Architecture</h3>

<table>
<thead>
<tr>
<th>„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£</th>
<th>Êé¢Á¥¢ÂØæË±°</th>
<th>Âà©ÁÇπ</th>
<th>Ê¨†ÁÇπ</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Macro</strong></td>
<td>ÂÖ®‰ΩìÊßãÈÄ†ÔºàÂ±§Êï∞„ÄÅÁµêÂêàÔºâ</td>
<td>ÊüîËªüÊÄß„ÅåÈ´ò„ÅÑ</td>
<td>Êé¢Á¥¢Á©∫Èñì„ÅåÂ∑®Â§ß</td>
</tr>
<tr>
<td><strong>Micro</strong></td>
<td>CellÂÜÖÈÉ®„ÅÆÊßãÈÄ†</td>
<td>ÂäπÁéáÁöÑ„ÄÅËª¢ÁßªÂèØËÉΩ</td>
<td>Âà∂Á¥Ñ„ÅåÂ§ö„ÅÑ</td>
</tr>
</tbody>
</table>

<h3>Êé¢Á¥¢Á©∫Èñì„ÅÆ„Çµ„Ç§„Ç∫</h3>

<p>Cell-basedÊé¢Á¥¢Á©∫Èñì„ÅÆ„Çµ„Ç§„Ç∫„ÅØËÜ®Â§ß„Åß„ÅôÔºö</p>

<p>$$
\text{Search Space Size} \approx O^{E}
$$</p>

<ul>
<li>$O$: Êìç‰Ωú„ÅÆÁ®ÆÈ°ûÔºà‰æã: 8Á®ÆÈ°ûÔºâ</li>
<li>$E$: „Ç®„ÉÉ„Ç∏„ÅÆÊï∞Ôºà‰æã: 14ÂÄãÔºâ</li>
<li>‰æã: $8^{14} \approx 4.4 \times 10^{12}$ ÈÄö„Çä</li>
</ul>

<h3>Êé¢Á¥¢Á©∫ÈñìË®≠Ë®à„ÅÆÂÆü‰æã</h3>

<pre><code class="language-python">import numpy as np

# NASÊé¢Á¥¢Á©∫Èñì„ÅÆÂÆöÁæ©
class SearchSpace:
    def __init__(self):
        # Âà©Áî®ÂèØËÉΩ„Å™Êìç‰Ωú
        self.operations = [
            'conv_3x3',
            'conv_5x5',
            'sep_conv_3x3',
            'sep_conv_5x5',
            'max_pool_3x3',
            'avg_pool_3x3',
            'identity',
            'zero'
        ]

        # Cell„ÅÆÊßãÈÄ†„Éë„É©„É°„Éº„Çø
        self.num_nodes = 4  # CellÂÜÖ„ÅÆ„Éé„Éº„ÉâÊï∞
        self.num_edges_per_node = 2  # ÂêÑ„Éé„Éº„Éâ„Å∏„ÅÆÂÖ•Âäõ„Ç®„ÉÉ„Ç∏Êï∞

    def calculate_space_size(self):
        """Êé¢Á¥¢Á©∫Èñì„ÅÆ„Çµ„Ç§„Ç∫„ÇíË®àÁÆó"""
        num_ops = len(self.operations)

        # ÂêÑ„Éé„Éº„Éâ„Åî„Å®„Å´ÈÅ∏ÊäûËÇ¢„ÇíË®àÁÆó
        total_choices = 1
        for node_id in range(2, self.num_nodes + 2):
            # „Ç®„ÉÉ„Ç∏ÂÖÉ„ÅÆÈÅ∏ÊäûÔºàÂâç„ÅÆ„Éé„Éº„Éâ„Åã„ÇâÈÅ∏„Å∂Ôºâ
            edge_choices = node_id
            # Êìç‰Ωú„ÅÆÈÅ∏Êäû
            op_choices = num_ops
            # „Åì„ÅÆ„Éé„Éº„Éâ„ÅÆÈÅ∏ÊäûËÇ¢
            node_choices = (edge_choices * op_choices) ** self.num_edges_per_node
            total_choices *= node_choices

        return total_choices

    def sample_architecture(self):
        """„É©„É≥„ÉÄ„É†„Å´„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£„Çí„Çµ„É≥„Éó„É™„É≥„Ç∞"""
        architecture = []

        for node_id in range(2, self.num_nodes + 2):
            # „Åì„ÅÆ„Éé„Éº„Éâ„Å∏„ÅÆÂÖ•Âäõ„ÇíÈÅ∏Êäû
            node_config = []
            for _ in range(self.num_edges_per_node):
                # ÂÖ•ÂäõÂÖÉ„Éé„Éº„Éâ
                input_node = np.random.randint(0, node_id)
                # Êìç‰Ωú
                operation = np.random.choice(self.operations)
                node_config.append((input_node, operation))

            architecture.append(node_config)

        return architecture

# Êé¢Á¥¢Á©∫Èñì„ÅÆ„Çµ„Ç§„Ç∫„ÇíË®àÁÆó
search_space = SearchSpace()
space_size = search_space.calculate_space_size()

print("=== NASÊé¢Á¥¢Á©∫Èñì„ÅÆÂàÜÊûê ===")
print(f"Êìç‰Ωú„ÅÆÁ®ÆÈ°û: {len(search_space.operations)}")
print(f"CellÂÜÖ„ÅÆ„Éé„Éº„ÉâÊï∞: {search_space.num_nodes}")
print(f"Êé¢Á¥¢Á©∫Èñì„ÅÆ„Çµ„Ç§„Ç∫: {space_size:,}")
print(f"ÁßëÂ≠¶ÁöÑË®òÊ≥ï: {space_size:.2e}")

# „Çµ„É≥„Éó„É´„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£
sample = search_space.sample_architecture()
print(f"\n=== „Çµ„É≥„Éó„É´„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£ ===")
for i, node in enumerate(sample, start=2):
    print(f"„Éé„Éº„Éâ {i}:")
    for j, (input_node, op) in enumerate(node):
        print(f"  ÂÖ•Âäõ{j}: „Éé„Éº„Éâ{input_node} ‚Üí {op}")
</code></pre>

<p><strong>Âá∫Âäõ</strong>Ôºö</p>
<pre><code>=== NASÊé¢Á¥¢Á©∫Èñì„ÅÆÂàÜÊûê ===
Êìç‰Ωú„ÅÆÁ®ÆÈ°û: 8
CellÂÜÖ„ÅÆ„Éé„Éº„ÉâÊï∞: 4
Êé¢Á¥¢Á©∫Èñì„ÅÆ„Çµ„Ç§„Ç∫: 17,179,869,184
ÁßëÂ≠¶ÁöÑË®òÊ≥ï: 1.72e+10

=== „Çµ„É≥„Éó„É´„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£ ===
„Éé„Éº„Éâ 2:
  ÂÖ•Âäõ0: „Éé„Éº„Éâ0 ‚Üí sep_conv_3x3
  ÂÖ•Âäõ1: „Éé„Éº„Éâ1 ‚Üí max_pool_3x3
„Éé„Éº„Éâ 3:
  ÂÖ•Âäõ0: „Éé„Éº„Éâ2 ‚Üí conv_5x5
  ÂÖ•Âäõ1: „Éé„Éº„Éâ0 ‚Üí identity
„Éé„Éº„Éâ 4:
  ÂÖ•Âäõ0: „Éé„Éº„Éâ3 ‚Üí avg_pool_3x3
  ÂÖ•Âäõ1: „Éé„Éº„Éâ1 ‚Üí sep_conv_5x5
„Éé„Éº„Éâ 5:
  ÂÖ•Âäõ0: „Éé„Éº„Éâ2 ‚Üí conv_3x3
  ÂÖ•Âäõ1: „Éé„Éº„Éâ4 ‚Üí zero
</code></pre>

<hr>

<h2>3.2 NAS„ÅÆÊé¢Á¥¢Êà¶Áï•</h2>

<h3>‰∏ªË¶Å„Å™Êé¢Á¥¢Êà¶Áï•„ÅÆÊØîËºÉ</h3>

<table>
<thead>
<tr>
<th>Êé¢Á¥¢Êà¶Áï•</th>
<th>ÂéüÁêÜ</th>
<th>Ë®àÁÆó„Ç≥„Çπ„Éà</th>
<th>‰ª£Ë°®ÊâãÊ≥ï</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Âº∑ÂåñÂ≠¶Áøí</strong></td>
<td>„Ç≥„É≥„Éà„É≠„Éº„É©„Åå„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£„ÇíÁîüÊàê</td>
<td>ÈùûÂ∏∏„Å´È´ò„ÅÑ</td>
<td>NASNet</td>
</tr>
<tr>
<td><strong>ÈÄ≤Âåñ„Ç¢„É´„Ç¥„É™„Ç∫„É†</strong></td>
<td>Á™ÅÁÑ∂Â§âÁï∞„Å®ÈÅ∏Êäû„ÇíÁπ∞„ÇäËøî„Åô</td>
<td>È´ò„ÅÑ</td>
<td>AmoebaNet</td>
</tr>
<tr>
<td><strong>ÂãæÈÖç„Éô„Éº„Çπ</strong></td>
<td>ÈÄ£Á∂öÁ∑©Âíå„ÅßÂæÆÂàÜÂèØËÉΩ„Å´</td>
<td>‰Ωé„ÅÑ</td>
<td>DARTS</td>
</tr>
<tr>
<td><strong>One-shot</strong></td>
<td>„Çπ„Éº„Éë„Éº„Éç„ÉÉ„Éà„Çí‰∏ÄÂ∫¶Â≠¶Áøí</td>
<td>‰∏≠Á®ãÂ∫¶</td>
<td>ENAS</td>
</tr>
</tbody>
</table>

<h3>1. Âº∑ÂåñÂ≠¶Áøí„Éô„Éº„ÇπÔºàNASNetÔºâ</h3>

<p>NASNet„ÅØ„ÄÅRNN„Ç≥„É≥„Éà„É≠„Éº„É©„Åå„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£„ÇíÁîüÊàê„Åó„ÄÅÁ≤æÂ∫¶„ÇíÂ†±ÈÖ¨„Å®„Åó„Å¶Â≠¶Áøí„Åó„Åæ„Åô„ÄÇ</p>

<div class="mermaid">
graph LR
    A[RNN„Ç≥„É≥„Éà„É≠„Éº„É©] -->|„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£ÁîüÊàê| B[Â≠ê„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ]
    B -->|Â≠¶Áøí„ÉªË©ï‰æ°| C[Ê§úË®ºÁ≤æÂ∫¶]
    C -->|Â†±ÈÖ¨| A

    style A fill:#e3f2fd
    style B fill:#fff3e0
    style C fill:#e8f5e9
</div>

<h4>Âº∑ÂåñÂ≠¶ÁøíNAS„ÅÆÁñë‰ºº„Ç≥„Éº„Éâ</h4>

<pre><code class="language-python"># NASNet„Çπ„Çø„Ç§„É´„ÅÆÂº∑ÂåñÂ≠¶ÁøíÊé¢Á¥¢ÔºàÊ¶ÇÂøµÁöÑÂÆüË£ÖÔºâ
import numpy as np

class RLController:
    """Âº∑ÂåñÂ≠¶Áøí„Éô„Éº„Çπ„ÅÆNAS„Ç≥„É≥„Éà„É≠„Éº„É©"""

    def __init__(self, search_space):
        self.search_space = search_space
        self.history = []

    def sample_architecture(self, epsilon=0.1):
        """Œµ-greedyÊà¶Áï•„Åß„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£„Çí„Çµ„É≥„Éó„É™„É≥„Ç∞"""
        if np.random.random() < epsilon:
            # Êé¢Á¥¢: „É©„É≥„ÉÄ„É†„Çµ„É≥„Éó„É™„É≥„Ç∞
            return self.search_space.sample_architecture()
        else:
            # Ê¥ªÁî®: ÈÅéÂéª„ÅÆËâØ„ÅÑ„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£„Åã„ÇâÂ§âÁï∞
            if self.history:
                best_arch = max(self.history, key=lambda x: x['reward'])
                return self.mutate_architecture(best_arch['architecture'])
            else:
                return self.search_space.sample_architecture()

    def mutate_architecture(self, architecture):
        """„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£„Å´Â∞è„Åï„Å™Â§âÁï∞„ÇíÂä†„Åà„Çã"""
        mutated = [node[:] for node in architecture]

        # „É©„É≥„ÉÄ„É†„Å´1„Å§„ÅÆ„Éé„Éº„Éâ„ÇíÂ§âÁï∞
        node_idx = np.random.randint(len(mutated))
        edge_idx = np.random.randint(len(mutated[node_idx]))

        input_node, _ = mutated[node_idx][edge_idx]
        new_op = np.random.choice(self.search_space.operations)
        mutated[node_idx][edge_idx] = (input_node, new_op)

        return mutated

    def update(self, architecture, reward):
        """Â†±ÈÖ¨„ÇíÂèó„ÅëÂèñ„Å£„Å¶Â±•Ê≠¥„ÇíÊõ¥Êñ∞"""
        self.history.append({
            'architecture': architecture,
            'reward': reward
        })

# „Ç∑„Éü„É•„É¨„Éº„Ç∑„Éß„É≥
search_space = SearchSpace()
controller = RLController(search_space)

print("=== Âº∑ÂåñÂ≠¶ÁøíNAS„ÅÆ„Ç∑„Éü„É•„É¨„Éº„Ç∑„Éß„É≥ ===")
for iteration in range(10):
    # „Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£„ÅÆ„Çµ„É≥„Éó„É™„É≥„Ç∞
    arch = controller.sample_architecture(epsilon=0.3)

    # Â†±ÈÖ¨„Çí„Ç∑„Éü„É•„É¨„Éº„ÉàÔºàÂÆüÈöõ„Å´„ÅØÂ≠¶Áøí„Åó„Å¶Á≤æÂ∫¶„ÇíÂèñÂæóÔºâ
    # „Åì„Åì„Åß„ÅØÊìç‰Ωú„ÅÆÂ§öÊßòÊÄß„Å´Âü∫„Å•„Åè„ÉÄ„Éü„ÉºÂ†±ÈÖ¨
    ops_used = set()
    for node in arch:
        for _, op in node:
            ops_used.add(op)
    reward = len(ops_used) / len(search_space.operations) + np.random.normal(0, 0.1)

    # „Ç≥„É≥„Éà„É≠„Éº„É©„ÇíÊõ¥Êñ∞
    controller.update(arch, reward)

    print(f"Iteration {iteration + 1}: Â†±ÈÖ¨ = {reward:.3f}")

# ÊúÄËâØ„ÅÆ„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£„ÇíË°®Á§∫
best = max(controller.history, key=lambda x: x['reward'])
print(f"\n=== ÊúÄËâØ„ÅÆ„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£ÔºàÂ†±ÈÖ¨: {best['reward']:.3f}Ôºâ===")
for i, node in enumerate(best['architecture'], start=2):
    print(f"„Éé„Éº„Éâ {i}:")
    for j, (input_node, op) in enumerate(node):
        print(f"  ÂÖ•Âäõ{j}: „Éé„Éº„Éâ{input_node} ‚Üí {op}")
</code></pre>

<h3>2. ÈÄ≤Âåñ„Ç¢„É´„Ç¥„É™„Ç∫„É†</h3>

<p>ÈÄ≤Âåñ„Ç¢„É´„Ç¥„É™„Ç∫„É†„ÅØ„ÄÅÁîüÁâ©ÈÄ≤Âåñ„ÇíÊ®°ÂÄ£„Åó„Å¶„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£„ÇíÊúÄÈÅ©Âåñ„Åó„Åæ„Åô„ÄÇ</p>

<pre><code class="language-python"># ÈÄ≤Âåñ„Ç¢„É´„Ç¥„É™„Ç∫„É†„Å´„Çà„ÇãNASÔºàÁ∞°ÊòìÁâàÔºâ
import random
import copy

class EvolutionaryNAS:
    """ÈÄ≤Âåñ„Ç¢„É´„Ç¥„É™„Ç∫„É†„Éô„Éº„Çπ„ÅÆNAS"""

    def __init__(self, search_space, population_size=20, num_generations=10):
        self.search_space = search_space
        self.population_size = population_size
        self.num_generations = num_generations

    def initialize_population(self):
        """ÂàùÊúüÈõÜÂõ£„ÇíÁîüÊàê"""
        return [self.search_space.sample_architecture()
                for _ in range(self.population_size)]

    def evaluate_fitness(self, architecture):
        """ÈÅ©ÂøúÂ∫¶„ÇíË©ï‰æ°Ôºà„ÉÄ„Éü„ÉºÂÆüË£ÖÔºâ"""
        # ÂÆüÈöõ„Å´„ÅØ„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ„ÇíÂ≠¶Áøí„Åó„Å¶Á≤æÂ∫¶„ÇíÊ∏¨ÂÆö
        # „Åì„Åì„Åß„ÅØÊìç‰Ωú„ÅÆÂ§öÊßòÊÄß„Çí„Çπ„Ç≥„Ç¢„Å®„Åô„Çã
        ops_used = set()
        for node in architecture:
            for _, op in node:
                ops_used.add(op)
        return len(ops_used) + random.gauss(0, 1)

    def select_parents(self, population, fitness_scores, k=2):
        """„Éà„Éº„Éä„É°„É≥„ÉàÈÅ∏Êäû"""
        selected = []
        for _ in range(2):
            candidates_idx = random.sample(range(len(population)), k)
            best_idx = max(candidates_idx, key=lambda i: fitness_scores[i])
            selected.append(copy.deepcopy(population[best_idx]))
        return selected

    def crossover(self, parent1, parent2):
        """‰∫§ÂèâÔºà‰∏ÄÁÇπ‰∫§ÂèâÔºâ"""
        crossover_point = random.randint(1, len(parent1) - 1)
        child1 = parent1[:crossover_point] + parent2[crossover_point:]
        child2 = parent2[:crossover_point] + parent1[crossover_point:]
        return child1, child2

    def mutate(self, architecture, mutation_rate=0.1):
        """Á™ÅÁÑ∂Â§âÁï∞"""
        mutated = copy.deepcopy(architecture)

        for node_idx in range(len(mutated)):
            for edge_idx in range(len(mutated[node_idx])):
                if random.random() < mutation_rate:
                    input_node, _ = mutated[node_idx][edge_idx]
                    new_op = random.choice(self.search_space.operations)
                    mutated[node_idx][edge_idx] = (input_node, new_op)

        return mutated

    def run(self):
        """ÈÄ≤Âåñ„Ç¢„É´„Ç¥„É™„Ç∫„É†„ÇíÂÆüË°å"""
        # ÂàùÊúüÈõÜÂõ£
        population = self.initialize_population()

        best_history = []

        for generation in range(self.num_generations):
            # ÈÅ©ÂøúÂ∫¶Ë©ï‰æ°
            fitness_scores = [self.evaluate_fitness(arch) for arch in population]

            # Áµ±Ë®à
            best_fitness = max(fitness_scores)
            avg_fitness = sum(fitness_scores) / len(fitness_scores)
            best_history.append(best_fitness)

            print(f"‰∏ñ‰ª£ {generation + 1}: ÊúÄËâØ={best_fitness:.3f}, Âπ≥Âùá={avg_fitness:.3f}")

            # Êñ∞‰∏ñ‰ª£„ÅÆÁîüÊàê
            new_population = []

            # „Ç®„É™„Éº„Éà‰øùÂ≠ò
            elite_idx = fitness_scores.index(max(fitness_scores))
            new_population.append(copy.deepcopy(population[elite_idx]))

            # ÈÅ∏Êäû„ÄÅ‰∫§Âèâ„ÄÅÁ™ÅÁÑ∂Â§âÁï∞
            while len(new_population) < self.population_size:
                parents = self.select_parents(population, fitness_scores)
                offspring1, offspring2 = self.crossover(parents[0], parents[1])
                offspring1 = self.mutate(offspring1)
                offspring2 = self.mutate(offspring2)

                new_population.extend([offspring1, offspring2])

            population = new_population[:self.population_size]

        # ÊúÄËâØ„ÅÆÂÄã‰Ωì„ÇíËøî„Åô
        fitness_scores = [self.evaluate_fitness(arch) for arch in population]
        best_idx = fitness_scores.index(max(fitness_scores))

        return population[best_idx], best_history

# ÂÆüË°å
search_space = SearchSpace()
evo_nas = EvolutionaryNAS(search_space, population_size=20, num_generations=10)

print("=== ÈÄ≤Âåñ„Ç¢„É´„Ç¥„É™„Ç∫„É†„Å´„Çà„ÇãNAS ===")
best_arch, history = evo_nas.run()

print(f"\n=== ÊúÄËâØ„ÅÆ„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£ ===")
for i, node in enumerate(best_arch, start=2):
    print(f"„Éé„Éº„Éâ {i}:")
    for j, (input_node, op) in enumerate(node):
        print(f"  ÂÖ•Âäõ{j}: „Éé„Éº„Éâ{input_node} ‚Üí {op}")
</code></pre>

<h3>3. ÂãæÈÖç„Éô„Éº„ÇπÔºàDARTSÊ¶ÇË¶ÅÔºâ</h3>

<p>DARTS„ÅØÊé¢Á¥¢Á©∫Èñì„ÇíÈÄ£Á∂öÁ∑©Âíå„Åó„ÄÅÂãæÈÖçÈôç‰∏ãÊ≥ï„ÅßÊúÄÈÅ©Âåñ„Åó„Åæ„ÅôÔºàË©≥Á¥∞„ÅØ3.4ÁØÄÔºâ„ÄÇ</p>

<blockquote>
<p><strong>ÈáçË¶Å</strong>: ÂãæÈÖç„Éô„Éº„ÇπÊâãÊ≥ï„ÅØ„ÄÅÂº∑ÂåñÂ≠¶Áøí„ÇÑÈÄ≤Âåñ„Ç¢„É´„Ç¥„É™„Ç∫„É†„Å®ÊØî„Åπ„Å¶1000ÂÄç‰ª•‰∏äÈ´òÈÄü„Åß„Åô„ÄÇ</p>
</blockquote>

<hr>

<h2>3.3 AutoKeras</h2>

<h3>AutoKeras„Å®„ÅØ</h3>

<p><strong>AutoKeras</strong>„ÅØ„ÄÅKeras„Éô„Éº„Çπ„ÅÆAutoML„É©„Ç§„Éñ„É©„É™„Åß„ÄÅNAS„ÇíÁ∞°Âçò„Å´Âà©Áî®„Åß„Åç„Åæ„Åô„ÄÇ</p>

<h3>AutoKeras„ÅÆ„Ç§„É≥„Çπ„Éà„Éº„É´</h3>

<pre><code class="language-bash">pip install autokeras
</code></pre>

<h3>AutoKeras„ÅÆÂü∫Êú¨ÁöÑ„Å™‰Ωø„ÅÑÊñπ</h3>

<pre><code class="language-python"># AutoKeras„ÅÆÂü∫Êú¨‰æãÔºöÁîªÂÉèÂàÜÈ°û
import numpy as np
import autokeras as ak
from tensorflow.keras.datasets import mnist

# „Éá„Éº„Çø„ÅÆÊ∫ñÂÇô
(x_train, y_train), (x_test, y_test) = mnist.load_data()

# Ê≠£Ë¶èÂåñ
x_train = x_train.astype('float32') / 255.0
x_test = x_test.astype('float32') / 255.0

# Ë®ìÁ∑¥„Éá„Éº„Çø„ÇíÂâäÊ∏õÔºà„Éá„É¢Áî®Ôºâ
x_train = x_train[:5000]
y_train = y_train[:5000]
x_test = x_test[:1000]
y_test = y_test[:1000]

print("=== AutoKeras„Å´„Çà„ÇãÁîªÂÉèÂàÜÈ°û ===")
print(f"Ë®ìÁ∑¥„Éá„Éº„Çø: {x_train.shape}")
print(f"„ÉÜ„Çπ„Éà„Éá„Éº„Çø: {x_test.shape}")

# AutoKeras„ÅÆImageClassifier
clf = ak.ImageClassifier(
    max_trials=5,  # Ë©¶Ë°å„Åô„Çã„É¢„Éá„É´Êï∞
    overwrite=True,
    directory='autokeras_results',
    project_name='mnist_classification'
)

# „É¢„Éá„É´„ÅÆÊé¢Á¥¢„Å®Â≠¶Áøí
print("\nÊé¢Á¥¢„ÇíÈñãÂßã...")
clf.fit(
    x_train, y_train,
    validation_split=0.2,
    epochs=3,
    verbose=1
)

# Ë©ï‰æ°
print("\n=== „É¢„Éá„É´„ÅÆË©ï‰æ° ===")
test_loss, test_acc = clf.evaluate(x_test, y_test, verbose=0)
print(f"„ÉÜ„Çπ„ÉàÁ≤æÂ∫¶: {test_acc:.4f}")
print(f"„ÉÜ„Çπ„ÉàÊêçÂ§±: {test_loss:.4f}")

# ÊúÄËâØ„É¢„Éá„É´„ÅÆÂèñÂæó
best_model = clf.export_model()
print("\n=== ÊúÄËâØ„É¢„Éá„É´„ÅÆÊßãÈÄ† ===")
best_model.summary()
</code></pre>

<h3>AutoKeras„ÅÆÊßò„ÄÖ„Å™„Çø„Çπ„ÇØ</h3>

<h4>1. ÊßãÈÄ†Âåñ„Éá„Éº„Çø„ÅÆÂàÜÈ°û</h4>

<pre><code class="language-python"># AutoKeras„ÅßÊßãÈÄ†Âåñ„Éá„Éº„Çø„ÇíÊâ±„ÅÜ
import numpy as np
import pandas as pd
import autokeras as ak
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split

# „Éá„Éº„Çø„ÅÆÊ∫ñÂÇô
data = load_breast_cancer()
X = pd.DataFrame(data.data, columns=data.feature_names)
y = data.target

# Ë®ìÁ∑¥„Éª„ÉÜ„Çπ„ÉàÂàÜÂâ≤
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

print("=== ÊßãÈÄ†Âåñ„Éá„Éº„ÇøÂàÜÈ°û ===")
print(f"ÁâπÂæ¥Èáè: {X.shape[1]}ÂÄã")
print(f"Ë®ìÁ∑¥„Çµ„É≥„Éó„É´: {len(X_train)}")

# AutoKeras„ÅÆStructuredDataClassifier
clf = ak.StructuredDataClassifier(
    max_trials=3,
    overwrite=True,
    directory='autokeras_structured',
    project_name='breast_cancer'
)

# Êé¢Á¥¢„Å®Â≠¶Áøí
clf.fit(
    X_train, y_train,
    validation_split=0.2,
    epochs=10,
    verbose=0
)

# Ë©ï‰æ°
test_loss, test_acc = clf.evaluate(X_test, y_test, verbose=0)
print(f"\n=== Ë©ï‰æ°ÁµêÊûú ===")
print(f"„ÉÜ„Çπ„ÉàÁ≤æÂ∫¶: {test_acc:.4f}")

# ‰∫àÊ∏¨
predictions = clf.predict(X_test[:5])
print(f"\n=== „Çµ„É≥„Éó„É´‰∫àÊ∏¨ ===")
for i, pred in enumerate(predictions[:5]):
    true_label = y_test.iloc[i] if isinstance(y_test, pd.Series) else y_test[i]
    print(f"„Çµ„É≥„Éó„É´ {i+1}: ‰∫àÊ∏¨={pred[0][0]:.3f}, ÁúüÂÄ§={true_label}")
</code></pre>

<h4>2. „ÉÜ„Ç≠„Çπ„ÉàÂàÜÈ°û</h4>

<pre><code class="language-python"># AutoKeras„Åß„ÉÜ„Ç≠„Çπ„ÉàÂàÜÈ°û
import numpy as np
import autokeras as ak
from tensorflow.keras.datasets import imdb

# IMDB„Éá„Éº„Çø„Çª„ÉÉ„ÉàÔºàÊò†Áîª„É¨„Éì„É•„Éº„ÅÆÊÑüÊÉÖÂàÜÊûêÔºâ
max_features = 10000
maxlen = 200

print("=== „ÉÜ„Ç≠„Çπ„ÉàÂàÜÈ°ûÔºàIMDBÔºâ===")
(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)

# „Éá„Éº„Çø„ÇíÂâäÊ∏õÔºà„Éá„É¢Áî®Ôºâ
x_train = x_train[:1000]
y_train = y_train[:1000]
x_test = x_test[:200]
y_test = y_test[:200]

# „Éë„Éá„Ç£„É≥„Ç∞
from tensorflow.keras.preprocessing.sequence import pad_sequences
x_train = pad_sequences(x_train, maxlen=maxlen)
x_test = pad_sequences(x_test, maxlen=maxlen)

print(f"Ë®ìÁ∑¥„Éá„Éº„Çø: {x_train.shape}")
print(f"„ÉÜ„Çπ„Éà„Éá„Éº„Çø: {x_test.shape}")

# AutoKeras„ÅÆTextClassifier
clf = ak.TextClassifier(
    max_trials=3,
    overwrite=True,
    directory='autokeras_text',
    project_name='imdb_sentiment'
)

# Êé¢Á¥¢„Å®Â≠¶Áøí
clf.fit(
    x_train, y_train,
    validation_split=0.2,
    epochs=3,
    verbose=0
)

# Ë©ï‰æ°
test_loss, test_acc = clf.evaluate(x_test, y_test, verbose=0)
print(f"\n=== Ë©ï‰æ°ÁµêÊûú ===")
print(f"„ÉÜ„Çπ„ÉàÁ≤æÂ∫¶: {test_acc:.4f}")
</code></pre>

<h3>AutoKeras„ÅÆ„Ç´„Çπ„Çø„É†Êé¢Á¥¢Á©∫Èñì</h3>

<pre><code class="language-python"># AutoKeras„ÅßÊé¢Á¥¢Á©∫Èñì„Çí„Ç´„Çπ„Çø„Éû„Ç§„Ç∫
import autokeras as ak
from tensorflow.keras.datasets import mnist

# „Éá„Éº„ÇøÊ∫ñÂÇô
(x_train, y_train), (x_test, y_test) = mnist.load_data()
x_train = x_train[:5000].astype('float32') / 255.0
y_train = y_train[:5000]
x_test = x_test[:1000].astype('float32') / 255.0
y_test = y_test[:1000]

print("=== „Ç´„Çπ„Çø„É†Êé¢Á¥¢Á©∫Èñì ===")

# ÂÖ•Âäõ„Éé„Éº„Éâ
input_node = ak.ImageInput()

# Ê≠£Ë¶èÂåñ„Éñ„É≠„ÉÉ„ÇØ
output = ak.Normalization()(input_node)

# ConvBlock„ÅÆÊé¢Á¥¢Á©∫Èñì„Çí„Ç´„Çπ„Çø„Éû„Ç§„Ç∫
output = ak.ConvBlock(
    num_blocks=2,  # Áï≥„ÅøËæº„Åø„Éñ„É≠„ÉÉ„ÇØ„ÅÆÊï∞
    num_layers=2,  # „Éñ„É≠„ÉÉ„ÇØÂÜÖ„ÅÆÂ±§Êï∞
    max_pooling=True,
    dropout=0.25
)(output)

# ÂàÜÈ°û„Éò„ÉÉ„Éâ
output = ak.ClassificationHead(
    num_classes=10,
    dropout=0.5
)(output)

# „É¢„Éá„É´ÊßãÁØâ
clf = ak.AutoModel(
    inputs=input_node,
    outputs=output,
    max_trials=3,
    overwrite=True,
    directory='autokeras_custom',
    project_name='mnist_custom'
)

# Â≠¶Áøí
clf.fit(
    x_train, y_train,
    validation_split=0.2,
    epochs=3,
    verbose=0
)

# Ë©ï‰æ°
test_loss, test_acc = clf.evaluate(x_test, y_test, verbose=0)
print(f"\n„ÉÜ„Çπ„ÉàÁ≤æÂ∫¶: {test_acc:.4f}")

# ÊúÄËâØ„É¢„Éá„É´„ÅÆÂèñÂæó
best_model = clf.export_model()
print("\n=== Áô∫Ë¶ã„Åï„Çå„Åü„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£ ===")
best_model.summary()
</code></pre>

<hr>

<h2>3.4 DARTSÔºàDifferentiable Architecture SearchÔºâ</h2>

<h3>DARTS„ÅÆÂéüÁêÜ</h3>

<p><strong>DARTS</strong>„ÅØ„ÄÅÈõ¢Êï£ÁöÑ„Å™Êé¢Á¥¢Á©∫Èñì„ÇíÈÄ£Á∂öÁ∑©Âíå„Åô„Çã„Åì„Å®„Åß„ÄÅÂãæÈÖçÈôç‰∏ãÊ≥ï„ÇíÈÅ©Áî®ÂèØËÉΩ„Å´„Åó„Åæ„Åô„ÄÇ</p>

<h3>ÈÄ£Á∂öÁ∑©ÂíåÔºàContinuous RelaxationÔºâ</h3>

<p>ÂêÑ„Ç®„ÉÉ„Ç∏„ÅÆÊìç‰Ωú„Çí„ÄÅÂÖ®Êìç‰Ωú„ÅÆÈáç„Åø‰ªò„ÅçÂíå„Å®„Åó„Å¶Ë°®Áèæ„Åó„Åæ„ÅôÔºö</p>

<p>$$
\bar{o}^{(i,j)}(x) = \sum_{o \in \mathcal{O}} \frac{\exp(\alpha_o^{(i,j)})}{\sum_{o' \in \mathcal{O}} \exp(\alpha_{o'}^{(i,j)})} \cdot o(x)
$$</p>

<ul>
<li>$\mathcal{O}$: Êìç‰Ωú„ÅÆÈõÜÂêà</li>
<li>$\alpha_o^{(i,j)}$: „Ç®„ÉÉ„Ç∏$(i,j)$„Åß„ÅÆÊìç‰Ωú$o$„ÅÆÈáç„ÅøÔºà„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£„Éë„É©„É°„Éº„ÇøÔºâ</li>
<li>„ÇΩ„Éï„Éà„Éû„ÉÉ„ÇØ„Çπ„ÅßÊ≠£Ë¶èÂåñ„Åó„ÄÅÂæÆÂàÜÂèØËÉΩ„Å´</li>
</ul>

<h3>Bi-level Optimization</h3>

<p>DARTS„ÅØ2„Å§„ÅÆ„Éë„É©„É°„Éº„Çø„Çí‰∫§‰∫í„Å´ÊúÄÈÅ©Âåñ„Åó„Åæ„ÅôÔºö</p>

<table>
<thead>
<tr>
<th>„Éë„É©„É°„Éº„Çø</th>
<th>Ë™¨Êòé</th>
<th>ÊúÄÈÅ©Âåñ</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Èáç„Åø $w$</strong></td>
<td>„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ„ÅÆÈáç„Åø</td>
<td>Ë®ìÁ∑¥„Éá„Éº„Çø„ÅßÊúÄÂ∞èÂåñ</td>
</tr>
<tr>
<td><strong>„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£ $\alpha$</strong></td>
<td>Êìç‰Ωú„ÅÆÈáç„Åø</td>
<td>Ê§úË®º„Éá„Éº„Çø„ÅßÊúÄÂ∞èÂåñ</td>
</tr>
</tbody>
</table>

<p>ÊúÄÈÅ©ÂåñÂïèÈ°åÔºö</p>

<p>$$
\begin{aligned}
\min_{\alpha} \quad & \mathcal{L}_{\text{val}}(w^*(\alpha), \alpha) \\
\text{s.t.} \quad & w^*(\alpha) = \arg\min_{w} \mathcal{L}_{\text{train}}(w, \alpha)
\end{aligned}
$$</p>

<h3>DARTS„ÅÆÂÆüË£ÖÔºàÁ∞°ÊòìÁâàÔºâ</h3>

<pre><code class="language-python"># DARTS„ÅÆÊ¶ÇÂøµÁöÑÂÆüË£ÖÔºàÁ∞°ÊòìÁâàÔºâ
import torch
import torch.nn as nn
import torch.nn.functional as F

class MixedOp(nn.Module):
    """Ë§áÊï∞„ÅÆÊìç‰Ωú„ÅÆÈáç„Åø‰ªò„ÅçÂíå"""

    def __init__(self, C, stride):
        super(MixedOp, self).__init__()
        self._ops = nn.ModuleList()

        # Âà©Áî®ÂèØËÉΩ„Å™Êìç‰Ωú
        self.operations = [
            ('sep_conv_3x3', lambda C, stride: SepConv(C, C, 3, stride, 1)),
            ('sep_conv_5x5', lambda C, stride: SepConv(C, C, 5, stride, 2)),
            ('avg_pool_3x3', lambda C, stride: nn.AvgPool2d(3, stride=stride, padding=1)),
            ('max_pool_3x3', lambda C, stride: nn.MaxPool2d(3, stride=stride, padding=1)),
            ('skip_connect', lambda C, stride: nn.Identity() if stride == 1 else FactorizedReduce(C, C)),
        ]

        for name, op in self.operations:
            self._ops.append(op(C, stride))

    def forward(self, x, weights):
        """Èáç„Åø‰ªò„ÅçÂíå„ÇíË®àÁÆó"""
        return sum(w * op(x) for w, op in zip(weights, self._ops))

class Cell(nn.Module):
    """DARTS„ÅÆCell"""

    def __init__(self, num_nodes, C_prev, C, reduction):
        super(Cell, self).__init__()
        self.num_nodes = num_nodes

        # ÂêÑ„Ç®„ÉÉ„Ç∏„Å´ÂØæ„Åô„ÇãÊìç‰Ωú
        self._ops = nn.ModuleList()
        for i in range(num_nodes):
            for j in range(2 + i):
                stride = 2 if reduction and j < 2 else 1
                op = MixedOp(C, stride)
                self._ops.append(op)

    def forward(self, s0, s1, weights):
        """È†Ü‰ºùÊí≠"""
        states = [s0, s1]
        offset = 0

        for i in range(self.num_nodes):
            s = sum(self._ops[offset + j](h, weights[offset + j])
                   for j, h in enumerate(states))
            offset += len(states)
            states.append(s)

        return torch.cat(states[-self.num_nodes:], dim=1)

class DARTSNetwork(nn.Module):
    """DARTSÊé¢Á¥¢„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ"""

    def __init__(self, C=16, num_cells=8, num_nodes=4, num_classes=10):
        super(DARTSNetwork, self).__init__()
        self.num_cells = num_cells
        self.num_nodes = num_nodes

        # „Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£„Éë„É©„É°„Éº„ÇøÔºàŒ±Ôºâ
        num_ops = 5  # Êìç‰Ωú„ÅÆÁ®ÆÈ°û
        num_edges = sum(2 + i for i in range(num_nodes))
        self.alphas_normal = nn.Parameter(torch.randn(num_edges, num_ops))
        self.alphas_reduce = nn.Parameter(torch.randn(num_edges, num_ops))

        # „Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ„ÅÆÈáç„ÅøÔºàwÔºâ
        self.stem = nn.Sequential(
            nn.Conv2d(3, C, 3, padding=1, bias=False),
            nn.BatchNorm2d(C)
        )

        # Cells„ÅÆÊßãÁØâ„ÅØÁ∞°Áï•Âåñ
        self.cells = nn.ModuleList()
        # ... (ÂÆüÈöõ„ÅÆÂÆüË£Ö„Åß„ÅØË§áÊï∞„ÅÆCell„ÇíËøΩÂä†)

        self.classifier = nn.Linear(C, num_classes)

    def arch_parameters(self):
        """„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£„Éë„É©„É°„Éº„Çø„ÇíËøî„Åô"""
        return [self.alphas_normal, self.alphas_reduce]

    def weights_parameters(self):
        """„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ„ÅÆÈáç„Åø„ÇíËøî„Åô"""
        return [p for n, p in self.named_parameters()
                if 'alpha' not in n]

# DARTS„ÅÆ‰ΩøÁî®‰æã
print("=== DARTSÊ¶ÇÂøµ„É¢„Éá„É´ ===")
model = DARTSNetwork(C=16, num_cells=8, num_nodes=4, num_classes=10)

print(f"„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£„Éë„É©„É°„Éº„ÇøÊï∞: {sum(p.numel() for p in model.arch_parameters())}")
print(f"„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØÈáç„Åø„Éë„É©„É°„Éº„ÇøÊï∞: {sum(p.numel() for p in model.weights_parameters())}")

# „Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£„Éë„É©„É°„Éº„Çø„ÅÆÂΩ¢Áä∂
print(f"\nNormal cell Œ±: {model.alphas_normal.shape}")
print(f"Reduction cell Œ±: {model.alphas_reduce.shape}")

# „ÇΩ„Éï„Éà„Éû„ÉÉ„ÇØ„Çπ„ÅßÊ≠£Ë¶èÂåñ
weights_normal = F.softmax(model.alphas_normal, dim=-1)
print(f"\nÊ≠£Ë¶èÂåñÂæå„ÅÆÈáç„ÅøÔºàNormal cell, ÊúÄÂàù„ÅÆ„Ç®„ÉÉ„Ç∏Ôºâ:")
print(weights_normal[0].detach().numpy())
</code></pre>

<h3>DARTS„ÅÆÂ≠¶Áøí„Ç¢„É´„Ç¥„É™„Ç∫„É†</h3>

<pre><code class="language-python"># DARTS„ÅÆÂ≠¶ÁøíÊâãÈ†ÜÔºàÁñë‰ºº„Ç≥„Éº„ÉâÔºâ
import torch
import torch.optim as optim

class DARTSTrainer:
    """DARTS„ÅÆÂ≠¶Áøí„ÇØ„É©„Çπ"""

    def __init__(self, model, train_loader, val_loader):
        self.model = model
        self.train_loader = train_loader
        self.val_loader = val_loader

        # 2„Å§„ÅÆ„Ç™„Éó„ÉÜ„Ç£„Éû„Ç§„Ç∂
        self.optimizer_w = optim.SGD(
            model.weights_parameters(),
            lr=0.025,
            momentum=0.9,
            weight_decay=3e-4
        )

        self.optimizer_alpha = optim.Adam(
            model.arch_parameters(),
            lr=3e-4,
            betas=(0.5, 0.999),
            weight_decay=1e-3
        )

        self.criterion = nn.CrossEntropyLoss()

    def train_step(self, train_data, val_data):
        """1„Çπ„ÉÜ„ÉÉ„Éó„ÅÆÂ≠¶Áøí"""
        # 1. „Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£„Éë„É©„É°„Éº„ÇøÔºàŒ±Ôºâ„ÅÆÊõ¥Êñ∞
        self.model.train()
        x_val, y_val = val_data

        self.optimizer_alpha.zero_grad()
        logits = self.model(x_val)
        loss_alpha = self.criterion(logits, y_val)
        loss_alpha.backward()
        self.optimizer_alpha.step()

        # 2. „Éç„ÉÉ„Éà„ÉØ„Éº„ÇØÈáç„ÅøÔºàwÔºâ„ÅÆÊõ¥Êñ∞
        x_train, y_train = train_data

        self.optimizer_w.zero_grad()
        logits = self.model(x_train)
        loss_w = self.criterion(logits, y_train)
        loss_w.backward()
        self.optimizer_w.step()

        return loss_w.item(), loss_alpha.item()

    def derive_architecture(self):
        """ÊúÄÁµÇÁöÑ„Å™„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£„ÇíÂ∞éÂá∫"""
        # ÂêÑ„Ç®„ÉÉ„Ç∏„ÅßÊúÄ„ÇÇÈáç„Åø„ÅÆÂ§ß„Åç„ÅÑÊìç‰Ωú„ÇíÈÅ∏Êäû
        def parse_alpha(alpha):
            gene = []
            n = 2
            start = 0
            for i in range(self.model.num_nodes):
                end = start + n
                W = alpha[start:end].copy()

                # ÂêÑ„Ç®„ÉÉ„Ç∏„ÅßÊúÄËâØ„ÅÆÊìç‰Ωú„Çí2„Å§ÈÅ∏Êäû
                edges = sorted(range(W.shape[0]),
                              key=lambda x: -max(W[x]))[:2]

                for j in edges:
                    k_best = W[j].argmax()
                    gene.append((j, k_best))

                start = end
                n += 1

            return gene

        # „ÇΩ„Éï„Éà„Éû„ÉÉ„ÇØ„Çπ„ÅßÊ≠£Ë¶èÂåñ
        weights_normal = F.softmax(self.model.alphas_normal, dim=-1)
        weights_reduce = F.softmax(self.model.alphas_reduce, dim=-1)

        gene_normal = parse_alpha(weights_normal.data.cpu().numpy())
        gene_reduce = parse_alpha(weights_reduce.data.cpu().numpy())

        return gene_normal, gene_reduce

# „Ç∑„Éü„É•„É¨„Éº„Ç∑„Éß„É≥‰æã
print("=== DARTSÂ≠¶ÁøíÊâãÈ†Ü ===")
print("1. „É¢„Éá„É´„ÅÆÂàùÊúüÂåñ")
print("2. ÂêÑ„Ç®„Éù„ÉÉ„ÇØ„Åß:")
print("   a. Ê§úË®º„Éá„Éº„Çø„ÅßŒ±„ÇíÊõ¥Êñ∞Ôºà„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£ÊúÄÈÅ©ÂåñÔºâ")
print("   b. Ë®ìÁ∑¥„Éá„Éº„Çø„Åßw„ÇíÊõ¥Êñ∞ÔºàÈáç„ÅøÊúÄÈÅ©ÂåñÔºâ")
print("3. Â≠¶ÁøíÁµÇ‰∫ÜÂæå„ÄÅÂêÑ„Ç®„ÉÉ„Ç∏„ÅßÊúÄ„ÇÇÈáç„Åø„ÅÆÂ§ß„Åç„ÅÑÊìç‰Ωú„ÇíÈÅ∏Êäû")
print("4. ÈÅ∏Êäû„Åï„Çå„ÅüÊìç‰Ωú„Åß„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ„ÇíÂÜçÊßãÁØâ„Åó„ÄÅÊúÄÁµÇÂ≠¶Áøí")
</code></pre>

<h3>DARTS„ÅÆÂÆüÁî®‰æãÔºàPyTorchÔºâ</h3>

<pre><code class="language-python"># ÂÆüÈöõ„ÅÆDARTSÂÆüË£Ö„Çí‰Ωø„Å£„Åü‰æãÔºàpt-darts„É©„Ç§„Éñ„É©„É™‰ΩøÁî®Ôºâ
# Ê≥®: pt-darts„ÅØÂ§ñÈÉ®„É©„Ç§„Éñ„É©„É™Ôºàpip install pt-dartsÔºâ

# ‰ª•‰∏ã„ÅØÊ¶ÇÂøµÁöÑ„Å™„Ç≥„Éº„Éâ‰æã
"""
import torch
from darts import DARTS
from darts.api import spaces
from darts.trainer import DARTSTrainer

# Êé¢Á¥¢Á©∫Èñì„ÅÆÂÆöÁæ©
search_space = spaces.get_search_space('darts', 'cifar10')

# DARTS„É¢„Éá„É´„ÅÆÊßãÁØâ
model = DARTS(
    C=16,
    num_classes=10,
    layers=8,
    criterion=nn.CrossEntropyLoss(),
    steps=4,
    multiplier=4,
    stem_multiplier=3
)

# „Éà„É¨„Éº„Éä„Éº„ÅÆÂàùÊúüÂåñ
trainer = DARTSTrainer(
    model,
    optimizer_config={
        'w_lr': 0.025,
        'w_momentum': 0.9,
        'w_weight_decay': 3e-4,
        'alpha_lr': 3e-4,
        'alpha_weight_decay': 1e-3
    }
)

# Êé¢Á¥¢„ÅÆÂÆüË°å
trainer.search(
    train_loader,
    val_loader,
    epochs=50
)

# ÊúÄËâØ„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£„ÅÆÂèñÂæó
best_architecture = model.genotype()
print(f"Áô∫Ë¶ã„Åï„Çå„Åü„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£: {best_architecture}")
"""

print("=== DARTS„ÅÆÂÆüÁî®ÁöÑ„Å™‰Ωø„ÅÑÊñπ ===")
print("1. pt-darts„Å™„Å©„ÅÆ„É©„Ç§„Éñ„É©„É™„Çí„Ç§„É≥„Çπ„Éà„Éº„É´")
print("2. Êé¢Á¥¢Á©∫Èñì„Å®„É¢„Éá„É´„ÇíÂÆöÁæ©")
print("3. Bi-levelÊúÄÈÅ©Âåñ„ÅßÊé¢Á¥¢")
print("4. Áô∫Ë¶ã„Åï„Çå„Åü„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£„ÅßÂÜçÂ≠¶Áøí")
print("\nDARTS„ÅÆÂà©ÁÇπ:")
print("- Êé¢Á¥¢ÊôÇÈñì: 4 GPUÊó•ÔºàNASNet„ÅØ1800 GPUÊó•Ôºâ")
print("- È´òÁ≤æÂ∫¶: CIFAR-10„Åß97%‰ª•‰∏ä")
print("- Ëª¢ÁßªÂèØËÉΩ: ImageNet„Å™„Å©„Å´„ÇÇÈÅ©Áî®ÂèØËÉΩ")
</code></pre>

<hr>

<h2>3.5 NAS„ÅÆÂäπÁéáÂåñ</h2>

<h3>ÂäπÁéáÂåñÊâãÊ≥ï„ÅÆÊØîËºÉ</h3>

<table>
<thead>
<tr>
<th>ÊâãÊ≥ï</th>
<th>ÂéüÁêÜ</th>
<th>È´òÈÄüÂåñÁéá</th>
<th>Á≤æÂ∫¶„Å∏„ÅÆÂΩ±Èüø</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Weight Sharing</strong></td>
<td>ÂÄôË£ú„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£Èñì„ÅßÈáç„Åø„ÇíÂÖ±Êúâ</td>
<td>1000ÂÄç</td>
<td>Â∞è</td>
</tr>
<tr>
<td><strong>Proxy Tasks</strong></td>
<td>Á∞°Êòì„Çø„Çπ„ÇØ„ÅßË©ï‰æ°</td>
<td>10-100ÂÄç</td>
<td>‰∏≠</td>
</tr>
<tr>
<td><strong>Early Stopping</strong></td>
<td>‰ΩéÊÄßËÉΩ„É¢„Éá„É´„ÇíÊó©Êúü„Å´Êâì„Å°Âàá„Çä</td>
<td>2-5ÂÄç</td>
<td>Â∞è</td>
</tr>
<tr>
<td><strong>Transfer Learning</strong></td>
<td>È°û‰ºº„Çø„Çπ„ÇØ„Åã„ÇâÁü•Ë≠òËª¢Áßª</td>
<td>5-10ÂÄç</td>
<td>Â∞è</td>
</tr>
</tbody>
</table>

<h3>1. Weight SharingÔºàENASÔºâ</h3>

<p><strong>Weight Sharing</strong>„ÅØ„ÄÅÂÖ®„Å¶„ÅÆÂÄôË£ú„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£„ÅåÈáç„Åø„ÇíÂÖ±Êúâ„Åô„Çã„Çπ„Éº„Éë„Éº„Éç„ÉÉ„Éà„ÇíÊßãÁØâ„Åó„Åæ„Åô„ÄÇ</p>

<pre><code class="language-python"># Weight Sharing„ÅÆÊ¶ÇÂøµÔºàENASÈ¢®Ôºâ
import torch
import torch.nn as nn

class SharedWeightSuperNet(nn.Module):
    """Èáç„ÅøÂÖ±Êúâ„Çπ„Éº„Éë„Éº„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ"""

    def __init__(self, num_nodes=4, C=16):
        super(SharedWeightSuperNet, self).__init__()
        self.num_nodes = num_nodes

        # ÂÖ®„Å¶„ÅÆÂèØËÉΩ„Å™Êìç‰Ωú„Çí‰∫ãÂâç„Å´ÊßãÁØâÔºàÈáç„Åø„ÇíÂÖ±ÊúâÔºâ
        self.ops = nn.ModuleDict({
            'conv_3x3': nn.Conv2d(C, C, 3, padding=1),
            'conv_5x5': nn.Conv2d(C, C, 5, padding=2),
            'max_pool': nn.MaxPool2d(3, stride=1, padding=1),
            'avg_pool': nn.AvgPool2d(3, stride=1, padding=1),
            'identity': nn.Identity()
        })

    def forward(self, x, architecture):
        """
        architecture: ÂêÑ„Éé„Éº„Éâ„ÅÆÊìç‰Ωú„ÇíÊåáÂÆö
        ‰æã: [('conv_3x3', 0), ('max_pool', 1), ...]
        """
        states = [x, x]  # ÂàùÊúüÁä∂ÊÖã

        for node_id, (op_name, input_id) in enumerate(architecture):
            # ÊåáÂÆö„Åï„Çå„ÅüÊìç‰Ωú„Å®ÂÖ•Âäõ„ÅßË®àÁÆó
            s = self.ops[op_name](states[input_id])
            states.append(s)

        # ÊúÄÂæå„ÅÆ„Éé„Éº„Éâ„ÅÆÂá∫Âäõ„ÇíËøî„Åô
        return states[-1]

# „Çπ„Éº„Éë„Éº„Éç„ÉÉ„Éà„ÅÆÊßãÁØâ
supernet = SharedWeightSuperNet(num_nodes=4, C=16)

print("=== Weight SharingÔºàENASÈ¢®Ôºâ===")
print(f"„Çπ„Éº„Éë„Éº„Éç„ÉÉ„Éà„ÅÆ„Éë„É©„É°„Éº„ÇøÊï∞: {sum(p.numel() for p in supernet.parameters()):,}")

# Áï∞„Å™„Çã„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£„ÅßÂêå„ÅòÈáç„Åø„Çí‰ΩøÁî®
arch1 = [('conv_3x3', 0), ('max_pool', 1), ('identity', 2), ('avg_pool', 1)]
arch2 = [('conv_5x5', 1), ('identity', 0), ('max_pool', 2), ('conv_3x3', 3)]

# „ÉÄ„Éü„ÉºÂÖ•Âäõ
x = torch.randn(1, 16, 32, 32)

output1 = supernet(x, arch1)
output2 = supernet(x, arch2)

print(f"\n„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£1„ÅÆÂá∫ÂäõÂΩ¢Áä∂: {output1.shape}")
print(f"„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£2„ÅÆÂá∫ÂäõÂΩ¢Áä∂: {output2.shape}")
print("\n‚Üí Âêå„ÅòÈáç„Åø„ÇíÂÖ±Êúâ„Åó„Å™„Åå„Çâ„ÄÅÁï∞„Å™„Çã„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£„ÇíË©ï‰æ°ÂèØËÉΩ")
</code></pre>

<h3>2. Proxy Tasks„Å´„Çà„ÇãÈ´òÈÄüÂåñ</h3>

<p>Proxy Tasks„Åß„ÅØ„ÄÅ‰ª•‰∏ã„ÅÆ„Çà„ÅÜ„Å™Á∞°ÊòìÂåñ„Åß„Ç≥„Çπ„Éà„ÇíÂâäÊ∏õ„Åó„Åæ„ÅôÔºö</p>

<table>
<thead>
<tr>
<th>Á∞°ÊòìÂåñ</th>
<th>‰æã</th>
<th>È´òÈÄüÂåñ</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>„Éá„Éº„Çø„Çµ„Ç§„Ç∫ÂâäÊ∏õ</strong></td>
<td>CIFAR-10„ÅÆ‰∏ÄÈÉ®„ÅÆ„Åø‰ΩøÁî®</td>
<td>2-5ÂÄç</td>
</tr>
<tr>
<td><strong>„Ç®„Éù„ÉÉ„ÇØÊï∞ÂâäÊ∏õ</strong></td>
<td>10„Ç®„Éù„ÉÉ„ÇØ„ÅßË©ï‰æ°</td>
<td>5-10ÂÄç</td>
</tr>
<tr>
<td><strong>„É¢„Éá„É´„Çµ„Ç§„Ç∫ÂâäÊ∏õ</strong></td>
<td>„ÉÅ„É£„Éç„É´Êï∞„Çí1/4„Å´</td>
<td>4-8ÂÄç</td>
</tr>
<tr>
<td><strong>Ëß£ÂÉèÂ∫¶ÂâäÊ∏õ</strong></td>
<td>32x32„ÅÆ‰ª£„Çè„Çä„Å´16x16</td>
<td>4ÂÄç</td>
</tr>
</tbody>
</table>

<h3>3. NAS-Bench„Éá„Éº„Çø„Çª„ÉÉ„Éà</h3>

<p><strong>NAS-Bench</strong>„ÅØ„ÄÅ‰∫ãÂâçË®àÁÆó„Åï„Çå„Åü„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£„ÅÆÊÄßËÉΩ„Éá„Éº„Çø„Éô„Éº„Çπ„Åß„Åô„ÄÇ</p>

<pre><code class="language-python"># NAS-Bench„ÅÆÊ¶ÇÂøµÁöÑ‰ΩøÁî®‰æã
# Ê≥®: ÂÆüÈöõ„Å´„ÅØnasbenchi„É©„Ç§„Éñ„É©„É™„Çí‰ΩøÁî®Ôºàpip install nasbenchÔºâ

class NASBenchSimulator:
    """NAS-Bench„ÅÆ„Ç∑„Éü„É•„É¨„Éº„Çø"""

    def __init__(self):
        # ‰∫ãÂâçË®àÁÆó„Åï„Çå„ÅüÊÄßËÉΩ„Éá„Éº„ÇøÔºà„ÉÄ„Éü„ÉºÔºâ
        self.benchmark_data = {}
        self._populate_dummy_data()

    def _populate_dummy_data(self):
        """„ÉÄ„Éü„Éº„Éô„É≥„ÉÅ„Éû„Éº„ÇØ„Éá„Éº„Çø„ÅÆÁîüÊàê"""
        import random
        random.seed(42)

        # 100ÂÄã„ÅÆ„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£„ÅÆÊÄßËÉΩ„Çí‰∫ãÂâçË®àÁÆó
        for i in range(100):
            arch_hash = f"arch_{i:03d}"
            self.benchmark_data[arch_hash] = {
                'val_accuracy': random.uniform(0.88, 0.95),
                'test_accuracy': random.uniform(0.87, 0.94),
                'training_time': random.uniform(100, 500),
                'params': random.randint(1_000_000, 10_000_000),
                'flops': random.randint(50_000_000, 500_000_000)
            }

    def query(self, architecture):
        """„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£„ÅÆÊÄßËÉΩ„Çí„ÇØ„Ç®„É™ÔºàÂç≥Â∫ß„Å´Ëøî„ÇãÔºâ"""
        # „Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£„Çí„Éè„ÉÉ„Ç∑„É•Âåñ
        arch_hash = self._hash_architecture(architecture)

        if arch_hash in self.benchmark_data:
            return self.benchmark_data[arch_hash]
        else:
            # Êú™Áü•„ÅÆ„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£„ÅØÊé®ÂÆö
            return {
                'val_accuracy': 0.90,
                'test_accuracy': 0.89,
                'training_time': 300,
                'params': 5_000_000,
                'flops': 250_000_000
            }

    def _hash_architecture(self, architecture):
        """„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£„Çí„Éè„ÉÉ„Ç∑„É•Âåñ"""
        # Á∞°Êòì„Éè„ÉÉ„Ç∑„É•ÔºàÂÆüÈöõ„ÅØ„ÇÇ„Å£„Å®Ë§áÈõëÔºâ
        arch_str = str(architecture)
        hash_val = sum(ord(c) for c in arch_str) % 100
        return f"arch_{hash_val:03d}"

# NAS-Bench„ÅÆ‰ΩøÁî®
bench = NASBenchSimulator()

print("=== NAS-Bench„Å´„Çà„ÇãÈ´òÈÄüË©ï‰æ° ===")

# „Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£„ÅÆÊé¢Á¥¢
import time

architectures = [
    [('conv_3x3', 0), ('max_pool', 1)],
    [('conv_5x5', 0), ('identity', 1)],
    [('avg_pool', 0), ('conv_3x3', 1)]
]

start_time = time.time()
results = []

for arch in architectures:
    result = bench.query(arch)
    results.append((arch, result))

end_time = time.time()

print(f"Êé¢Á¥¢ÊôÇÈñì: {end_time - start_time:.4f}Áßí")
print(f"\n=== Êé¢Á¥¢ÁµêÊûú ===")
for arch, result in results:
    print(f"„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£: {arch}")
    print(f"  Ê§úË®ºÁ≤æÂ∫¶: {result['val_accuracy']:.3f}")
    print(f"  „ÉÜ„Çπ„ÉàÁ≤æÂ∫¶: {result['test_accuracy']:.3f}")
    print(f"  Â≠¶ÁøíÊôÇÈñì: {result['training_time']:.1f}Áßí")
    print(f"  „Éë„É©„É°„Éº„ÇøÊï∞: {result['params']:,}")
    print()

print("‚Üí ÂÆüÈöõ„ÅÆÂ≠¶Áøí„Å™„Åó„ÅßÊÄßËÉΩ„ÇíÂç≥Â∫ß„Å´ÂèñÂæóÂèØËÉΩ")
</code></pre>

<h3>ÂäπÁéáÂåñÊâãÊ≥ï„ÅÆÁµÑ„ÅøÂêà„Çè„Åõ</h3>

<pre><code class="language-python"># Ë§áÊï∞„ÅÆÂäπÁéáÂåñÊâãÊ≥ï„ÇíÁµÑ„ÅøÂêà„Çè„Åõ„ÅüÊé¢Á¥¢
import numpy as np

class EfficientNAS:
    """ÂäπÁéáÂåñ„Åï„Çå„ÅüNAS"""

    def __init__(self, use_weight_sharing=True, use_proxy=True,
                 use_early_stopping=True):
        self.use_weight_sharing = use_weight_sharing
        self.use_proxy = use_proxy
        self.use_early_stopping = use_early_stopping

        if use_weight_sharing:
            self.supernet = SharedWeightSuperNet()

        if use_proxy:
            self.proxy_epochs = 10  # ÂÆåÂÖ®Â≠¶Áøí„ÅÆ‰ª£„Çè„Çä„Å´10„Ç®„Éù„ÉÉ„ÇØ
            self.proxy_data_fraction = 0.2  # „Éá„Éº„Çø„ÅÆ20%„ÅÆ„Åø‰ΩøÁî®

    def evaluate_architecture(self, architecture, full_evaluation=False):
        """„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£„ÇíË©ï‰æ°"""
        if full_evaluation:
            # ÂÆåÂÖ®Ë©ï‰æ°ÔºàÊúÄÁµÇÂÄôË£ú„ÅÆ„ÅøÔºâ
            epochs = 50
            data_fraction = 1.0
        else:
            # ProxyË©ï‰æ°
            epochs = self.proxy_epochs if self.use_proxy else 50
            data_fraction = self.proxy_data_fraction if self.use_proxy else 1.0

        # Early stopping„ÅÆ„Ç∑„Éü„É•„É¨„Éº„Ç∑„Éß„É≥
        if self.use_early_stopping:
            # ÊúÄÂàù„ÅÆÊï∞„Ç®„Éù„ÉÉ„ÇØ„ÅßÊÄßËÉΩ„ÅåÊÇ™„Åë„Çå„Å∞Êâì„Å°Âàá„Çä
            early_acc = np.random.random()
            if early_acc < 0.5:  # ÈñæÂÄ§
                return {'accuracy': early_acc, 'stopped_early': True}

        # Ë©ï‰æ°Ôºà„ÉÄ„Éü„ÉºÔºâ
        accuracy = np.random.uniform(0.85, 0.95)

        return {
            'accuracy': accuracy,
            'epochs': epochs,
            'data_fraction': data_fraction,
            'stopped_early': False
        }

    def search(self, num_candidates=100, top_k=5):
        """NASÊé¢Á¥¢„ÅÆÂÆüË°å"""
        print("=== ÂäπÁéáÁöÑNASÊé¢Á¥¢ ===")
        print(f"Weight Sharing: {self.use_weight_sharing}")
        print(f"Proxy Tasks: {self.use_proxy}")
        print(f"Early Stopping: {self.use_early_stopping}")
        print()

        candidates = []

        # 1. Â§ßË¶èÊ®°„Å™ProxyË©ï‰æ°
        for i in range(num_candidates):
            arch = [('conv_3x3', 0), ('max_pool', 1)]  # „ÉÄ„Éü„Éº
            result = self.evaluate_architecture(arch, full_evaluation=False)
            candidates.append((arch, result))

        # Early stopping„ÅßÊâì„Å°Âàá„Çâ„Çå„Å™„Åã„Å£„ÅüÂÄôË£ú
        valid_candidates = [c for c in candidates if not c[1]['stopped_early']]

        print(f"ÂàùÊúüÂÄôË£ú: {num_candidates}")
        print(f"Early stopping„ÅßÂâäÊ∏õ: {num_candidates - len(valid_candidates)}")

        # 2. „Éà„ÉÉ„ÉóK„ÇíÂÆåÂÖ®Ë©ï‰æ°
        top_candidates = sorted(valid_candidates,
                               key=lambda x: x[1]['accuracy'],
                               reverse=True)[:top_k]

        print(f"ÂÆåÂÖ®Ë©ï‰æ°„Åô„ÇãÂÄôË£ú: {top_k}")
        print()

        final_results = []
        for arch, proxy_result in top_candidates:
            full_result = self.evaluate_architecture(arch, full_evaluation=True)
            final_results.append((arch, full_result))

        # ÊúÄËâØ„ÅÆÂÄôË£ú„ÇíËøî„Åô
        best = max(final_results, key=lambda x: x[1]['accuracy'])

        return best, final_results

# ÂÆüË°å
nas = EfficientNAS(
    use_weight_sharing=True,
    use_proxy=True,
    use_early_stopping=True
)

best_arch, all_results = nas.search(num_candidates=100, top_k=5)

print("=== Êé¢Á¥¢ÁµêÊûú ===")
print(f"ÊúÄËâØ„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£: {best_arch[0]}")
print(f"ÊúÄËâØÁ≤æÂ∫¶: {best_arch[1]['accuracy']:.3f}")
print(f"\n„Éà„ÉÉ„Éó5„ÅÆÁ≤æÂ∫¶:")
for i, (arch, result) in enumerate(all_results, 1):
    print(f"{i}. Á≤æÂ∫¶={result['accuracy']:.3f}")
</code></pre>

<hr>

<h2>3.6 Êú¨Á´†„ÅÆ„Åæ„Å®„ÇÅ</h2>

<h3>Â≠¶„Çì„Å†„Åì„Å®</h3>

<ol>
<li><p><strong>NAS„ÅÆÊé¢Á¥¢Á©∫Èñì</strong></p>
<ul>
<li>Cell-basedÊé¢Á¥¢Á©∫Èñì„ÅÆË®≠Ë®à</li>
<li>Macro vs Micro architecture</li>
<li>Êé¢Á¥¢Á©∫Èñì„ÅÆ„Çµ„Ç§„Ç∫„Å®Ë§áÈõëÊÄß</li>
</ul></li>

<li><p><strong>NAS„ÅÆÊé¢Á¥¢Êà¶Áï•</strong></p>
<ul>
<li>Âº∑ÂåñÂ≠¶ÁøíÔºàNASNetÔºâ: RNN„Ç≥„É≥„Éà„É≠„Éº„É©„ÅßÁîüÊàê</li>
<li>ÈÄ≤Âåñ„Ç¢„É´„Ç¥„É™„Ç∫„É†: Á™ÅÁÑ∂Â§âÁï∞„Å®ÈÅ∏Êäû</li>
<li>ÂãæÈÖç„Éô„Éº„ÇπÔºàDARTSÔºâ: ÈÄ£Á∂öÁ∑©Âíå„ÅßÈ´òÈÄüÂåñ</li>
<li>One-shotÔºàENASÔºâ: Weight Sharing„ÅßÂäπÁéáÂåñ</li>
</ul></li>

<li><p><strong>AutoKeras</strong></p>
<ul>
<li>ÁîªÂÉè„ÄÅ„ÉÜ„Ç≠„Çπ„Éà„ÄÅÊßãÈÄ†Âåñ„Éá„Éº„Çø„ÅÆËá™ÂãïÂ≠¶Áøí</li>
<li>„Ç´„Çπ„Çø„É†Êé¢Á¥¢Á©∫Èñì„ÅÆÂÆöÁæ©</li>
<li>Á∞°Âçò„Å™API„ÅßÈ´òÂ∫¶„Å™NAS„ÇíÂà©Áî®</li>
</ul></li>

<li><p><strong>DARTS</strong></p>
<ul>
<li>ÈÄ£Á∂öÁ∑©Âíå„Å´„Çà„ÇãÂæÆÂàÜÂèØËÉΩ„Å™NAS</li>
<li>Bi-level optimizationÔºàw „Å® Œ±Ôºâ</li>
<li>1000ÂÄç‰ª•‰∏ä„ÅÆÈ´òÈÄüÂåñ„ÇíÂÆüÁèæ</li>
</ul></li>

<li><p><strong>NAS„ÅÆÂäπÁéáÂåñ</strong></p>
<ul>
<li>Weight Sharing: „Çπ„Éº„Éë„Éº„Éç„ÉÉ„Éà„ÅßÈáç„Åø„ÇíÂÖ±Êúâ</li>
<li>Proxy Tasks: Á∞°Êòì„Çø„Çπ„ÇØ„ÅßË©ï‰æ°</li>
<li>Early Stopping: ‰ΩéÊÄßËÉΩ„ÇíÊó©ÊúüÊâì„Å°Âàá„Çä</li>
<li>NAS-Bench: ‰∫ãÂâçË®àÁÆó„Éá„Éº„Çø„Éô„Éº„Çπ</li>
</ul></li>
</ol>

<h3>Êé¢Á¥¢Êà¶Áï•„ÅÆÈÅ∏Êäû„Ç¨„Ç§„Éâ„É©„Ç§„É≥</h3>

<table>
<thead>
<tr>
<th>Áä∂Ê≥Å</th>
<th>Êé®Â•®ÊâãÊ≥ï</th>
<th>ÁêÜÁî±</th>
</tr>
</thead>
<tbody>
<tr>
<td>Ë®àÁÆóË≥áÊ∫ê„ÅåË±äÂØå</td>
<td>Âº∑ÂåñÂ≠¶Áøí„ÄÅÈÄ≤Âåñ</td>
<td>È´òÁ≤æÂ∫¶„ÅåÊúüÂæÖ„Åß„Åç„Çã</td>
</tr>
<tr>
<td>Ë®àÁÆóË≥áÊ∫ê„ÅåÈôêÂÆöÁöÑ</td>
<td>DARTS„ÄÅENAS</td>
<td>È´òÈÄü„ÅßÂÆüÁî®ÁöÑ</td>
</tr>
<tr>
<td>Âàù„ÇÅ„Å¶„ÅÆNAS</td>
<td>AutoKeras</td>
<td>Á∞°Âçò„Åß‰Ωø„ÅÑ„ÇÑ„Åô„ÅÑ</td>
</tr>
<tr>
<td>„Ç´„Çπ„Çø„Éû„Ç§„Ç∫„ÅåÂøÖË¶Å</td>
<td>DARTS„ÅÆÂÆüË£Ö</td>
<td>ÊüîËªüÊÄß„ÅåÈ´ò„ÅÑ</td>
</tr>
<tr>
<td>„Éô„É≥„ÉÅ„Éû„Éº„ÇØÁ†îÁ©∂</td>
<td>NAS-Bench</td>
<td>ÂÜçÁèæÊÄß„Å®ÂÖ¨Âπ≥ÊÄß</td>
</tr>
</tbody>
</table>

<h3>Ê¨°„ÅÆÁ´†„Å∏</h3>

<p>Á¨¨4Á´†„Åß„ÅØ„ÄÅ<strong>Feature Engineering Automation</strong>„ÇíÂ≠¶„Å≥„Åæ„ÅôÔºö</p>
<ul>
<li>Ëá™ÂãïÁâπÂæ¥ÈáèÁîüÊàê</li>
<li>ÁâπÂæ¥ÈÅ∏Êäû„ÅÆËá™ÂãïÂåñ</li>
<li>ÁâπÂæ¥ÈáèÈáçË¶ÅÂ∫¶„ÅÆÂèØË¶ñÂåñ</li>
<li>AutoML„Éë„Ç§„Éó„É©„Ç§„É≥„ÅÆÁµ±Âêà</li>
<li>ÂÆüË∑µÁöÑ„Å™Feature Engineering</li>
</ul>

<hr>

<h2>ÊºîÁøíÂïèÈ°å</h2>

<h3>ÂïèÈ°å1ÔºàÈõ£ÊòìÂ∫¶ÔºöeasyÔºâ</h3>
<p>NAS„ÅÆ3Ë¶ÅÁ¥†ÔºàÊé¢Á¥¢Á©∫Èñì„ÄÅÊé¢Á¥¢Êà¶Áï•„ÄÅÊÄßËÉΩË©ï‰æ°Ôºâ„Å´„Å§„ÅÑ„Å¶„ÄÅ„Åù„Çå„Åû„ÇåË™¨Êòé„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ</p>

<details>
<summary>Ëß£Á≠î‰æã</summary>

<p><strong>Ëß£Á≠î</strong>Ôºö</p>

<ol>
<li><p><strong>Êé¢Á¥¢Á©∫ÈñìÔºàSearch SpaceÔºâ</strong></p>
<ul>
<li>Ë™¨Êòé: Êé¢Á¥¢ÂèØËÉΩ„Å™„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£„ÅÆÈõÜÂêà</li>
<li>‰æã: Cell-basedÔºàNormal Cell„Å®Reduction CellÔºâ„ÄÅÂ±§„ÅÆÁ®ÆÈ°ûÔºàConv„ÄÅPoolingÔºâ„ÄÅÁµêÂêà„Éë„Çø„Éº„É≥</li>
<li>ÈáçË¶ÅÊÄß: Êé¢Á¥¢Á©∫Èñì„ÅåÂ§ß„Åç„Åô„Åé„Çã„Å®Ë®àÁÆó„Ç≥„Çπ„Éà„ÅåÈ´ò„Åè„ÄÅÂ∞è„Åï„Åô„Åé„Çã„Å®ÊúÄÈÅ©Ëß£„ÇíÈÄÉ„Åô</li>
</ul></li>

<li><p><strong>Êé¢Á¥¢Êà¶Áï•ÔºàSearch StrategyÔºâ</strong></p>
<ul>
<li>Ë™¨Êòé: „Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£„Çí„Å©„ÅÆ„Çà„ÅÜ„Å´Êé¢Á¥¢„Åô„Çã„Åã</li>
<li>‰æã: Âº∑ÂåñÂ≠¶ÁøíÔºàNASNetÔºâ„ÄÅÈÄ≤Âåñ„Ç¢„É´„Ç¥„É™„Ç∫„É†ÔºàAmoebaNetÔºâ„ÄÅÂãæÈÖç„Éô„Éº„ÇπÔºàDARTSÔºâ</li>
<li>„Éà„É¨„Éº„Éâ„Ç™„Éï: Á≤æÂ∫¶ vs Ë®àÁÆó„Ç≥„Çπ„Éà</li>
</ul></li>

<li><p><strong>ÊÄßËÉΩË©ï‰æ°ÔºàPerformance EstimationÔºâ</strong></p>
<ul>
<li>Ë™¨Êòé: „Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£„ÅÆËâØ„ÅóÊÇ™„Åó„ÇíÂà§ÂÆö„Åô„ÇãÊñπÊ≥ï</li>
<li>ÊåáÊ®ô: Á≤æÂ∫¶„ÄÅFLOPs„ÄÅ„Éë„É©„É°„Éº„ÇøÊï∞„ÄÅ„É¨„Ç§„ÉÜ„É≥„Ç∑„ÄÅ„É°„É¢„É™‰ΩøÁî®Èáè</li>
<li>ÂäπÁéáÂåñ: Proxy tasks„ÄÅWeight sharing„ÄÅEarly stopping</li>
</ul></li>
</ol>

</details>

<h3>ÂïèÈ°å2ÔºàÈõ£ÊòìÂ∫¶ÔºömediumÔºâ</h3>
<p>DARTS„ÅåÂº∑ÂåñÂ≠¶Áøí„Éô„Éº„Çπ„ÅÆNAS„Å´ÊØî„Åπ„Å¶È´òÈÄü„Å™ÁêÜÁî±„Çí„ÄÅÈÄ£Á∂öÁ∑©Âíå„ÅÆË¶≥ÁÇπ„Åã„ÇâË™¨Êòé„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ</p>

<details>
<summary>Ëß£Á≠î‰æã</summary>

<p><strong>Ëß£Á≠î</strong>Ôºö</p>

<p><strong>Âº∑ÂåñÂ≠¶Áøí„Éô„Éº„Çπ„ÅÆNASÔºà‰æã: NASNetÔºâ</strong>Ôºö</p>
<ul>
<li>Èõ¢Êï£ÁöÑÊé¢Á¥¢: „Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£„Çí„Çµ„É≥„Éó„É™„É≥„Ç∞ ‚Üí Â≠¶Áøí ‚Üí Ë©ï‰æ°„ÇíÁπ∞„ÇäËøî„Åô</li>
<li>ÂêÑÂÄôË£ú„ÇíÂÄãÂà•„Å´Â≠¶Áøí„Åô„ÇãÂøÖË¶Å„Åå„ÅÇ„Çã</li>
<li>Ë®àÁÆó„Ç≥„Çπ„Éà: Êï∞ÂçÉ„ÅÆ„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£ √ó ÂÆåÂÖ®Â≠¶Áøí = ÈùûÂ∏∏„Å´È´ò„ÅÑÔºà1800 GPUÊó•Ôºâ</li>
</ul>

<p><strong>DARTSÔºàÂãæÈÖç„Éô„Éº„ÇπÔºâ</strong>Ôºö</p>
<ul>
<li>ÈÄ£Á∂öÁ∑©Âíå: Èõ¢Êï£ÁöÑ„Å™ÈÅ∏ÊäûÔºà„Å©„ÅÆÊìç‰Ωú„Çí‰Ωø„ÅÜ„ÅãÔºâ„ÇíÈÄ£Á∂öÁöÑ„Å™Èáç„Åø‰ªò„ÅçÂíå„Å´Â§âÊèõ</li>
<li>Âºè: $\bar{o}(x) = \sum_o \frac{\exp(\alpha_o)}{\sum_{o'} \exp(\alpha_{o'})} \cdot o(x)$</li>
<li>ÂãæÈÖçÈôç‰∏ãÊ≥ï„ÅåÈÅ©Áî®ÂèØËÉΩ: Œ±„ÇíÂãæÈÖç„ÅßÊúÄÈÅ©Âåñ„Åß„Åç„Çã</li>
<li>Weight sharing: ÂÖ®„Å¶„ÅÆÂÄôË£ú„ÅåÂêå„Åò„Çπ„Éº„Éë„Éº„Éç„ÉÉ„Éà„ÇíÂÖ±Êúâ</li>
<li>Ë®àÁÆó„Ç≥„Çπ„Éà: 1Âõû„ÅÆ„Çπ„Éº„Éë„Éº„Éç„ÉÉ„ÉàÂ≠¶Áøí = Â§ßÂπÖÂâäÊ∏õÔºà4 GPUÊó•Ôºâ</li>
</ul>

<p><strong>È´òÈÄüÂåñ„ÅÆÁêÜÁî±</strong>Ôºö</p>
<ol>
<li>Èõ¢Êï£‚ÜíÈÄ£Á∂ö: ÂæÆÂàÜÂèØËÉΩ„Å´„Å™„Çä„ÄÅÂäπÁéáÁöÑ„Å™ÂãæÈÖçÊúÄÈÅ©Âåñ„ÅåÂèØËÉΩ</li>
<li>Weight sharing: ÂÄôË£úÈñì„ÅßÈáç„Åø„ÇíÂÖ±Êúâ„Åó„ÄÅÂÄãÂà•Â≠¶Áøí„ÇíÂõûÈÅø</li>
<li>Bi-level optimization: w„Å®Œ±„Çí‰∫§‰∫í„Å´Êõ¥Êñ∞„Åó„ÄÅÂäπÁéáÁöÑ„Å´Êé¢Á¥¢</li>
</ol>

<p><strong>ÁµêÊûú</strong>Ôºö</p>
<ul>
<li>NASNet: 1800 GPUÊó•</li>
<li>DARTS: 4 GPUÊó•</li>
<li>È´òÈÄüÂåñÁéá: Á¥Ñ450ÂÄç</li>
</ul>

</details>

<h3>ÂïèÈ°å3ÔºàÈõ£ÊòìÂ∫¶ÔºömediumÔºâ</h3>
<p>‰ª•‰∏ã„ÅÆ„Ç≥„Éº„Éâ„ÇíÂÆåÊàê„Åï„Åõ„Å¶„ÄÅAutoKeras„ÅßÁîªÂÉèÂàÜÈ°û„É¢„Éá„É´„ÇíÊé¢Á¥¢„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ</p>

<pre><code class="language-python">import autokeras as ak
from tensorflow.keras.datasets import fashion_mnist

# „Éá„Éº„Çø„ÅÆÊ∫ñÂÇô
(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()

# TODO: „Éá„Éº„Çø„ÅÆÊ≠£Ë¶èÂåñ
# x_train = ...
# x_test = ...

# TODO: AutoKeras„ÅÆImageClassifier„ÇíÊßãÁØâ
# clf = ak.ImageClassifier(...)

# TODO: „É¢„Éá„É´„ÅÆÂ≠¶Áøí
# clf.fit(...)

# TODO: Ë©ï‰æ°
# test_acc = ...
# print(f"„ÉÜ„Çπ„ÉàÁ≤æÂ∫¶: {test_acc:.4f}")
</code></pre>

<details>
<summary>Ëß£Á≠î‰æã</summary>

<pre><code class="language-python">import autokeras as ak
from tensorflow.keras.datasets import fashion_mnist

# „Éá„Éº„Çø„ÅÆÊ∫ñÂÇô
(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()

# „Éá„Éº„Çø„ÅÆÊ≠£Ë¶èÂåñ
x_train = x_train.astype('float32') / 255.0
x_test = x_test.astype('float32') / 255.0

# „Éá„Éº„Çø„Çµ„Ç§„Ç∫ÂâäÊ∏õÔºà„Éá„É¢Áî®Ôºâ
x_train = x_train[:5000]
y_train = y_train[:5000]
x_test = x_test[:1000]
y_test = y_test[:1000]

print("=== Fashion-MNISTÂàÜÈ°û ===")
print(f"Ë®ìÁ∑¥„Éá„Éº„Çø: {x_train.shape}")
print(f"„ÉÜ„Çπ„Éà„Éá„Éº„Çø: {x_test.shape}")

# AutoKeras„ÅÆImageClassifier
clf = ak.ImageClassifier(
    max_trials=5,  # Êé¢Á¥¢„Åô„ÇãÂÄôË£úÊï∞
    epochs=10,     # ÂêÑÂÄôË£ú„ÅÆÂ≠¶Áøí„Ç®„Éù„ÉÉ„ÇØÊï∞
    overwrite=True,
    directory='autokeras_fashion',
    project_name='fashion_mnist'
)

# „É¢„Éá„É´„ÅÆÂ≠¶Áøí
print("\nÊé¢Á¥¢„ÇíÈñãÂßã...")
clf.fit(
    x_train, y_train,
    validation_split=0.2,
    verbose=1
)

# Ë©ï‰æ°
print("\n=== Ë©ï‰æ° ===")
test_loss, test_acc = clf.evaluate(x_test, y_test, verbose=0)
print(f"„ÉÜ„Çπ„ÉàÁ≤æÂ∫¶: {test_acc:.4f}")
print(f"„ÉÜ„Çπ„ÉàÊêçÂ§±: {test_loss:.4f}")

# ÊúÄËâØ„É¢„Éá„É´„ÅÆÂèñÂæó
best_model = clf.export_model()
print("\n=== Áô∫Ë¶ã„Åï„Çå„Åü„É¢„Éá„É´ ===")
best_model.summary()

# ‰∫àÊ∏¨‰æã
import numpy as np
predictions = clf.predict(x_test[:5])
print("\n=== ‰∫àÊ∏¨‰æã ===")
for i in range(5):
    print(f"„Çµ„É≥„Éó„É´ {i+1}: ‰∫àÊ∏¨={np.argmax(predictions[i])}, ÁúüÂÄ§={y_test[i]}")
</code></pre>

</details>

<h3>ÂïèÈ°å4ÔºàÈõ£ÊòìÂ∫¶ÔºöhardÔºâ</h3>
<p>Weight Sharing„Çí‰Ωø„Å£„Åü„Çπ„Éº„Éë„Éº„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ„ÇíÂÆüË£Ö„Åó„ÄÅÁï∞„Å™„Çã2„Å§„ÅÆ„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£„ÅßÈáç„Åø„ÅåÂÖ±Êúâ„Åï„Çå„Çã„Åì„Å®„ÇíÁ¢∫Ë™ç„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ</p>

<details>
<summary>Ëß£Á≠î‰æã</summary>

<pre><code class="language-python">import torch
import torch.nn as nn
import torch.nn.functional as F

class SharedOperations(nn.Module):
    """Èáç„Åø„ÇíÂÖ±Êúâ„Åô„ÇãÊìç‰Ωú„ÅÆ„Éó„Éº„É´"""

    def __init__(self, C):
        super(SharedOperations, self).__init__()

        # ÂÖ®„Å¶„ÅÆÂèØËÉΩ„Å™Êìç‰ΩúÔºàÈáç„Åø„ÅØ1Â∫¶„Å†„ÅëÂÆöÁæ©Ôºâ
        self.ops = nn.ModuleDict({
            'conv_3x3': nn.Conv2d(C, C, 3, padding=1, bias=False),
            'conv_5x5': nn.Conv2d(C, C, 5, padding=2, bias=False),
            'sep_conv_3x3': nn.Sequential(
                nn.Conv2d(C, C, 3, padding=1, groups=C, bias=False),
                nn.Conv2d(C, C, 1, bias=False)
            ),
            'max_pool_3x3': nn.MaxPool2d(3, stride=1, padding=1),
            'avg_pool_3x3': nn.AvgPool2d(3, stride=1, padding=1),
            'identity': nn.Identity()
        })

    def forward(self, x, op_name):
        """ÊåáÂÆö„Åï„Çå„ÅüÊìç‰Ωú„ÇíÈÅ©Áî®"""
        return self.ops[op_name](x)

class SuperNet(nn.Module):
    """„Çπ„Éº„Éë„Éº„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ"""

    def __init__(self, C=16):
        super(SuperNet, self).__init__()
        self.shared_ops = SharedOperations(C)

    def forward(self, x, architecture):
        """
        architecture: [(op_name, input_id), ...]„ÅÆÂΩ¢Âºè
        """
        # ÂàùÊúüÁä∂ÊÖã
        states = [x]

        for op_name, input_id in architecture:
            s = self.shared_ops(states[input_id], op_name)
            states.append(s)

        # ÊúÄÂæå„ÅÆÁä∂ÊÖã„ÇíËøî„Åô
        return states[-1]

# „Çπ„Éº„Éë„Éº„Éç„ÉÉ„Éà„ÅÆÊßãÁØâ
supernet = SuperNet(C=16)

print("=== Weight Sharing„ÅÆÊ§úË®º ===")
print(f"„Çπ„Éº„Éë„Éº„Éç„ÉÉ„Éà„ÅÆ„Éë„É©„É°„Éº„ÇøÊï∞: {sum(p.numel() for p in supernet.parameters()):,}")

# Êìç‰Ωú„Åî„Å®„ÅÆ„Éë„É©„É°„Éº„ÇøÊï∞
print("\nÂêÑÊìç‰Ωú„ÅÆ„Éë„É©„É°„Éº„ÇøÊï∞:")
for name, op in supernet.shared_ops.ops.items():
    num_params = sum(p.numel() for p in op.parameters())
    print(f"  {name}: {num_params:,}")

# 2„Å§„ÅÆÁï∞„Å™„Çã„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£
arch1 = [('conv_3x3', 0), ('max_pool_3x3', 0), ('identity', 1)]
arch2 = [('conv_5x5', 0), ('avg_pool_3x3', 0), ('conv_3x3', 1)]

# Âêå„ÅòÂÖ•Âäõ
x = torch.randn(2, 16, 32, 32)

# „Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£1„ÅßÈ†Ü‰ºùÊí≠
output1 = supernet(x, arch1)

# „Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£2„ÅßÈ†Ü‰ºùÊí≠
output2 = supernet(x, arch2)

print(f"\n=== È†Ü‰ºùÊí≠„ÅÆÊ§úË®º ===")
print(f"„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£1„ÅÆÂá∫ÂäõÂΩ¢Áä∂: {output1.shape}")
print(f"„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£2„ÅÆÂá∫ÂäõÂΩ¢Áä∂: {output2.shape}")

# Èáç„Åø„ÅåÂÖ±Êúâ„Åï„Çå„Å¶„ÅÑ„Çã„Åì„Å®„ÇíÁ¢∫Ë™ç
print("\n=== Èáç„ÅøÂÖ±Êúâ„ÅÆÁ¢∫Ë™ç ===")
conv_3x3_params_before = list(supernet.shared_ops.ops['conv_3x3'].parameters())[0].clone()

# „Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£1„ÅßÈÄÜ‰ºùÊí≠Ôºàconv_3x3„Çí‰ΩøÁî®Ôºâ
loss1 = output1.sum()
loss1.backward()

conv_3x3_params_after = list(supernet.shared_ops.ops['conv_3x3'].parameters())[0]

# ÂãæÈÖç„ÅåËìÑÁ©ç„Åï„Çå„Å¶„ÅÑ„Çã„ÅãÁ¢∫Ë™ç
has_gradient = conv_3x3_params_after.grad is not None
print(f"conv_3x3„Å´ÂãæÈÖç„ÅåËìÑÁ©ç: {has_gradient}")

# Èáç„Åø„ÅÆÂÖ±Êúâ„ÇíË¶ñË¶öÁöÑ„Å´Á¢∫Ë™ç
print("\n=== Èáç„ÅøÂÖ±Êúâ„ÅÆÂà©ÁÇπ ===")
print("1. „É°„É¢„É™ÂäπÁéá: ÂÖ®„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£„ÅßÂêå„ÅòÈáç„Åø„Çí‰ΩøÁî®")
print("2. Â≠¶ÁøíÂäπÁéá: 1„Å§„ÅÆ„Çπ„Éº„Éë„Éº„Éç„ÉÉ„Éà„ÅßÂÖ®ÂÄôË£ú„ÇíË©ï‰æ°")
print("3. È´òÈÄüÂåñ: ÂÄãÂà•Â≠¶Áøí„ÅÆ‰ª£„Çè„Çä„Å´ÂÖ±ÊúâÂ≠¶Áøí")

# Áï∞„Å™„Çã„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£„ÇíË©¶„Åô
print("\n=== Ë§áÊï∞„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£„ÅÆË©ï‰æ° ===")
architectures = [
    [('conv_3x3', 0), ('max_pool_3x3', 0)],
    [('conv_5x5', 0), ('identity', 0)],
    [('sep_conv_3x3', 0), ('avg_pool_3x3', 0)],
]

for i, arch in enumerate(architectures, 1):
    output = supernet(x, arch)
    print(f"„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£ {i}: Âá∫ÂäõÂΩ¢Áä∂ = {output.shape}, Âπ≥ÂùáÂÄ§ = {output.mean():.4f}")

print("\n‚Üí ÂÖ®„Å¶„ÅÆ„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£„ÅåÂêå„ÅòÈáç„Åø„ÇíÂÖ±Êúâ„Åó„Å™„Åå„ÇâË©ï‰æ°„Åï„Çå„Åæ„Åó„Åü")
</code></pre>

</details>

<h3>ÂïèÈ°å5ÔºàÈõ£ÊòìÂ∫¶ÔºöhardÔºâ</h3>
<p>DARTS„ÅÆBi-levelÊúÄÈÅ©Âåñ„Å´„Åä„ÅÑ„Å¶„ÄÅ„Å™„ÅúË®ìÁ∑¥„Éá„Éº„Çø„Å®Ê§úË®º„Éá„Éº„Çø„ÇíÂàÜ„Åë„Å¶ÊúÄÈÅ©Âåñ„Åô„ÇãÂøÖË¶Å„Åå„ÅÇ„Çã„ÅÆ„ÅãË™¨Êòé„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ„Åæ„Åü„ÄÅÂêå„Åò„Éá„Éº„Çø„ÅßÊúÄÈÅ©Âåñ„Åó„ÅüÂ†¥Âêà„Å´‰Ωï„ÅåËµ∑„Åì„Çã„Åã‰∫àÊÉ≥„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ</p>

<details>
<summary>Ëß£Á≠î‰æã</summary>

<p><strong>Ëß£Á≠î</strong>Ôºö</p>

<p><strong>Bi-levelÊúÄÈÅ©Âåñ„ÅÆÁõÆÁöÑ</strong>Ôºö</p>

<p>DARTS„ÅØ2Á®ÆÈ°û„ÅÆ„Éë„É©„É°„Éº„Çø„ÇíÊúÄÈÅ©Âåñ„Åó„Åæ„ÅôÔºö</p>
<ol>
<li><strong>„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ„ÅÆÈáç„ÅøÔºàwÔºâ</strong>: Ë®ìÁ∑¥„Éá„Éº„Çø„ÅßÊúÄÂ∞èÂåñ</li>
<li><strong>„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£„Éë„É©„É°„Éº„ÇøÔºàŒ±Ôºâ</strong>: Ê§úË®º„Éá„Éº„Çø„ÅßÊúÄÂ∞èÂåñ</li>
</ol>

<p>ÊúÄÈÅ©ÂåñÂïèÈ°åÔºö</p>
<p>$$
\begin{aligned}
\min_{\alpha} \quad & \mathcal{L}_{\text{val}}(w^*(\alpha), \alpha) \\
\text{s.t.} \quad & w^*(\alpha) = \arg\min_{w} \mathcal{L}_{\text{train}}(w, \alpha)
\end{aligned}
$$</p>

<p><strong>Ë®ìÁ∑¥„ÉªÊ§úË®º„Éá„Éº„Çø„ÇíÂàÜ„Åë„ÇãÁêÜÁî±</strong>Ôºö</p>

<ol>
<li><p><strong>ÈÅéÂ≠¶Áøí„ÅÆÈò≤Ê≠¢</strong></p>
<ul>
<li>Œ±„ÇíË®ìÁ∑¥„Éá„Éº„Çø„ÅßÊúÄÈÅ©Âåñ„Åô„Çã„Å®„ÄÅË®ìÁ∑¥„Éá„Éº„Çø„Å´ÈÅéÈÅ©Âêà„Åó„Åü„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£„ÇíÈÅ∏Êäû</li>
<li>Ê§úË®º„Éá„Éº„Çø„ÅßÊúÄÈÅ©Âåñ„Åô„Çã„Åì„Å®„Åß„ÄÅÊ±éÂåñÊÄßËÉΩ„ÅÆÈ´ò„ÅÑ„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£„ÇíÈÅ∏Êäû</li>
</ul></li>

<li><p><strong>ÂΩπÂâ≤„ÅÆÂàÜÈõ¢</strong></p>
<ul>
<li>w: ‰∏é„Åà„Çâ„Çå„Åü„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£„ÅßÊúÄËâØ„ÅÆÈáç„Åø„ÇíÂ≠¶ÁøíÔºàË®ìÁ∑¥„Éá„Éº„ÇøÔºâ</li>
<li>Œ±: Ê§úË®ºÊÄßËÉΩ„ÅåÊúÄ„ÇÇÈ´ò„ÅÑ„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£„ÇíÈÅ∏ÊäûÔºàÊ§úË®º„Éá„Éº„ÇøÔºâ</li>
</ul></li>

<li><p><strong>ÂÖ¨Âπ≥„Å™Ë©ï‰æ°</strong></p>
<ul>
<li>Ë®ìÁ∑¥„Éá„Éº„Çø„ÅßÂ≠¶Áøí„Åó„Åüw„Çí„ÄÅÁã¨Á´ã„Åó„ÅüÊ§úË®º„Éá„Éº„Çø„ÅßË©ï‰æ°</li>
<li>Áúü„ÅÆÊ±éÂåñÊÄßËÉΩ„ÇíÂèçÊò†„Åó„Åü„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£ÈÅ∏Êäû</li>
</ul></li>
</ol>

<p><strong>Âêå„Åò„Éá„Éº„Çø„ÅßÊúÄÈÅ©Âåñ„Åó„ÅüÂ†¥Âêà„ÅÆÂïèÈ°å</strong>Ôºö</p>

<pre><code class="language-python"># Ë™§„Å£„ÅüÊñπÊ≥ïÔºàÂêå„Åò„Éá„Éº„Çø„Åßw„Å®Œ±„ÇíÊúÄÈÅ©ÂåñÔºâ
# ‚ùå ÂïèÈ°å„ÅÆ„ÅÇ„Çã„Ç≥„Éº„Éâ‰æã
for epoch in range(num_epochs):
    # Ë®ìÁ∑¥„Éá„Éº„Çø„Åßw„ÇíÊõ¥Êñ∞
    loss_w = train_loss(w, alpha, train_data)
    w.update(-lr * grad(loss_w, w))

    # Âêå„ÅòË®ìÁ∑¥„Éá„Éº„Çø„ÅßŒ±„ÇíÊõ¥Êñ∞ ‚Üê ÂïèÈ°åÔºÅ
    loss_alpha = train_loss(w, alpha, train_data)
    alpha.update(-lr * grad(loss_alpha, alpha))
</code></pre>

<p><strong>Ëµ∑„Åì„ÇãÂïèÈ°å</strong>Ôºö</p>
<ol>
<li><strong>ÈÅéÂ≠¶Áøí</strong>: Ë®ìÁ∑¥„Éá„Éº„Çø„Å´ÁâπÂåñ„Åó„Åü„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£„ÇíÈÅ∏Êäû</li>
<li><strong>IdentityÊìç‰Ωú„ÅÆÂÑ™ÂÖà</strong>: Ë®àÁÆó„Ç≥„Çπ„Éà„Å™„Åó„ÅßË®ìÁ∑¥ÊêçÂ§±„Çí‰∏ã„Åí„Çâ„Çå„Çã„Åü„ÇÅ„ÄÅskip connection„Å∞„Åã„ÇäÈÅ∏Êäû</li>
<li><strong>Ê±éÂåñÊÄßËÉΩ„ÅÆ‰Ωé‰∏ã</strong>: „ÉÜ„Çπ„Éà„Éá„Éº„Çø„Åß„ÅÆÊÄßËÉΩ„ÅåÊÇ™Âåñ</li>
<li><strong>ÊÑèÂë≥„ÅÆ„ÅÇ„ÇãÊé¢Á¥¢„ÅÆÂ§±Êïó</strong>: Áúü„Å´ÊúâÁî®„Å™„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£„ÇíÁô∫Ë¶ã„Åß„Åç„Å™„ÅÑ</li>
</ol>

<p><strong>Ê≠£„Åó„ÅÑÊñπÊ≥ï</strong>Ôºö</p>
<pre><code class="language-python"># ‚úÖ Ê≠£„Åó„ÅÑÊñπÊ≥ï
for epoch in range(num_epochs):
    # Ë®ìÁ∑¥„Éá„Éº„Çø„Åßw„ÇíÊõ¥Êñ∞
    loss_w = train_loss(w, alpha, train_data)
    w.update(-lr * grad(loss_w, w))

    # Ê§úË®º„Éá„Éº„Çø„ÅßŒ±„ÇíÊõ¥Êñ∞ ‚Üê Ê≠£„Åó„ÅÑÔºÅ
    loss_alpha = val_loss(w, alpha, val_data)
    alpha.update(-lr * grad(loss_alpha, alpha))
</code></pre>

<p><strong>„Åæ„Å®„ÇÅ</strong>Ôºö</p>
<table>
<thead>
<tr>
<th>ÂÅ¥Èù¢</th>
<th>Ë®ìÁ∑¥„ÉªÊ§úË®ºÂàÜÈõ¢</th>
<th>Âêå„Åò„Éá„Éº„Çø‰ΩøÁî®</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>ÈÅéÂ≠¶Áøí</strong></td>
<td>Èò≤Ê≠¢„Åß„Åç„Çã</td>
<td>ÈÅéÂ≠¶Áøí„Åó„ÇÑ„Åô„ÅÑ</td>
</tr>
<tr>
<td><strong>Ê±éÂåñÊÄßËÉΩ</strong></td>
<td>È´ò„ÅÑ</td>
<td>‰Ωé„ÅÑ</td>
</tr>
<tr>
<td><strong>„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£</strong></td>
<td>ÊúâÁî®</td>
<td>trivialÔºàidentityÂÅèÈáçÔºâ</td>
</tr>
<tr>
<td><strong>ÂÆüÁî®ÊÄß</strong></td>
<td>È´ò„ÅÑ</td>
<td>‰Ωé„ÅÑ</td>
</tr>
</tbody>
</table>

</details>

<hr>

<h2>ÂèÇËÄÉÊñáÁåÆ</h2>

<ol>
<li>Zoph, B., & Le, Q. V. (2017). <em>Neural Architecture Search with Reinforcement Learning</em>. ICLR 2017.</li>
<li>Liu, H., Simonyan, K., & Yang, Y. (2019). <em>DARTS: Differentiable Architecture Search</em>. ICLR 2019.</li>
<li>Pham, H., Guan, M., Zoph, B., Le, Q., & Dean, J. (2018). <em>Efficient Neural Architecture Search via Parameter Sharing</em>. ICML 2018.</li>
<li>Real, E., et al. (2019). <em>Regularized Evolution for Image Classifier Architecture Search</em>. AAAI 2019.</li>
<li>Jin, H., Song, Q., & Hu, X. (2019). <em>Auto-Keras: An Efficient Neural Architecture Search System</em>. KDD 2019.</li>
<li>Elsken, T., Metzen, J. H., & Hutter, F. (2019). <em>Neural Architecture Search: A Survey</em>. JMLR 2019.</li>
</ol>

<div class="navigation">
    <a href="chapter2-hyperparameter-optimization.html" class="nav-button">‚Üê Ââç„ÅÆÁ´†: „Éè„Ç§„Éë„Éº„Éë„É©„É°„Éº„ÇøÊúÄÈÅ©Âåñ</a>
    <a href="chapter4-feature-engineering.html" class="nav-button">Ê¨°„ÅÆÁ´†: Feature EngineeringËá™ÂãïÂåñ ‚Üí</a>
</div>

    </main>

    <footer>
        <p><strong>‰ΩúÊàêËÄÖ</strong>: AI Terakoya Content Team</p>
        <p><strong>„Éê„Éº„Ç∏„Éß„É≥</strong>: 1.0 | <strong>‰ΩúÊàêÊó•</strong>: 2025-10-21</p>
        <p><strong>„É©„Ç§„Çª„É≥„Çπ</strong>: Creative Commons BY 4.0</p>
        <p>¬© 2025 AI Terakoya. All rights reserved.</p>
    </footer>
</body>
</html>
