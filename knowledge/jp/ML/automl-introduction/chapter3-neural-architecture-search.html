<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ç¬¬3ç« ï¼šNeural Architecture Search - AI Terakoya</title>

    <style>
        :root {
            --color-primary: #2c3e50;
            --color-primary-dark: #1a252f;
            --color-accent: #7b2cbf;
            --color-accent-light: #9d4edd;
            --color-text: #2d3748;
            --color-text-light: #4a5568;
            --color-bg: #ffffff;
            --color-bg-alt: #f7fafc;
            --color-border: #e2e8f0;
            --color-code-bg: #f8f9fa;
            --color-link: #3182ce;
            --color-link-hover: #2c5aa0;

            --spacing-xs: 0.5rem;
            --spacing-sm: 1rem;
            --spacing-md: 1.5rem;
            --spacing-lg: 2rem;
            --spacing-xl: 3rem;

            --font-body: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            --font-mono: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;

            --border-radius: 8px;
            --box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: var(--font-body);
            line-height: 1.7;
            color: var(--color-text);
            background-color: var(--color-bg);
            font-size: 16px;
        }

        header {
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            padding: var(--spacing-xl) var(--spacing-md);
            margin-bottom: var(--spacing-xl);
            box-shadow: var(--box-shadow);
        }

        .header-content {
            max-width: 900px;
            margin: 0 auto;
        }

        h1 {
            font-size: 2rem;
            font-weight: 700;
            margin-bottom: var(--spacing-sm);
            line-height: 1.2;
        }

        .subtitle {
            font-size: 1.1rem;
            opacity: 0.95;
            font-weight: 400;
            margin-bottom: var(--spacing-md);
        }

        .meta {
            display: flex;
            flex-wrap: wrap;
            gap: var(--spacing-md);
            font-size: 0.9rem;
            opacity: 0.9;
        }

        .meta-item {
            display: flex;
            align-items: center;
            gap: 0.3rem;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 0 var(--spacing-md) var(--spacing-xl);
        }

        h2 {
            font-size: 1.75rem;
            color: var(--color-primary);
            margin-top: var(--spacing-xl);
            margin-bottom: var(--spacing-md);
            padding-bottom: var(--spacing-xs);
            border-bottom: 3px solid var(--color-accent);
        }

        h3 {
            font-size: 1.4rem;
            color: var(--color-primary);
            margin-top: var(--spacing-lg);
            margin-bottom: var(--spacing-sm);
        }

        h4 {
            font-size: 1.1rem;
            color: var(--color-primary-dark);
            margin-top: var(--spacing-md);
            margin-bottom: var(--spacing-sm);
        }

        p {
            margin-bottom: var(--spacing-md);
            color: var(--color-text);
        }

        a {
            color: var(--color-link);
            text-decoration: none;
            transition: color 0.2s;
        }

        a:hover {
            color: var(--color-link-hover);
            text-decoration: underline;
        }

        ul, ol {
            margin-left: var(--spacing-lg);
            margin-bottom: var(--spacing-md);
        }

        li {
            margin-bottom: var(--spacing-xs);
            color: var(--color-text);
        }

        pre {
            background-color: var(--color-code-bg);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            overflow-x: auto;
            margin-bottom: var(--spacing-md);
            font-family: var(--font-mono);
            font-size: 0.9rem;
            line-height: 1.5;
        }

        code {
            font-family: var(--font-mono);
            font-size: 0.9em;
            background-color: var(--color-code-bg);
            padding: 0.2em 0.4em;
            border-radius: 3px;
        }

        pre code {
            background-color: transparent;
            padding: 0;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: var(--spacing-md);
            font-size: 0.95rem;
        }

        th, td {
            border: 1px solid var(--color-border);
            padding: var(--spacing-sm);
            text-align: left;
        }

        th {
            background-color: var(--color-bg-alt);
            font-weight: 600;
            color: var(--color-primary);
        }

        blockquote {
            border-left: 4px solid var(--color-accent);
            padding-left: var(--spacing-md);
            margin: var(--spacing-md) 0;
            color: var(--color-text-light);
            font-style: italic;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        .mermaid {
            text-align: center;
            margin: var(--spacing-lg) 0;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        details {
            background-color: var(--color-bg-alt);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            margin-bottom: var(--spacing-md);
        }

        summary {
            cursor: pointer;
            font-weight: 600;
            color: var(--color-primary);
            user-select: none;
            padding: var(--spacing-xs);
            margin: calc(-1 * var(--spacing-md));
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        summary:hover {
            background-color: rgba(123, 44, 191, 0.1);
        }

        details[open] summary {
            margin-bottom: var(--spacing-md);
            border-bottom: 1px solid var(--color-border);
        }

        .navigation {
            display: flex;
            justify-content: space-between;
            gap: var(--spacing-md);
            margin: var(--spacing-xl) 0;
            padding-top: var(--spacing-lg);
            border-top: 2px solid var(--color-border);
        }

        .nav-button {
            flex: 1;
            padding: var(--spacing-md);
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            border-radius: var(--border-radius);
            text-align: center;
            font-weight: 600;
            transition: transform 0.2s, box-shadow 0.2s;
            box-shadow: var(--box-shadow);
        }

        .nav-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
            text-decoration: none;
        }

        footer {
            margin-top: var(--spacing-xl);
            padding: var(--spacing-lg) var(--spacing-md);
            background-color: var(--color-bg-alt);
            border-top: 1px solid var(--color-border);
            text-align: center;
            font-size: 0.9rem;
            color: var(--color-text-light);
        }
        .disclaimer {
            max-width: 900px;
            margin: 2rem auto;
            padding: 1.5rem;
            background: #f8f9fa;
            border-left: 4px solid #6c757d;
            border-radius: 4px;
        }

        .disclaimer h3 {
            color: #495057;
            margin-bottom: 1rem;
            font-size: 1.1rem;
        }

        .disclaimer ul {
            list-style: none;
            padding-left: 0;
        }

        .disclaimer li {
            padding: 0.5rem 0;
            padding-left: 1.5rem;
            position: relative;
            font-size: 0.9rem;
            color: #6c757d;
            line-height: 1.6;
        }

        .disclaimer li::before {
            content: "âš ï¸";
            position: absolute;
            left: 0;
        }


        @media (max-width: 768px) {
            h1 {
                font-size: 1.5rem;
            }

            h2 {
                font-size: 1.4rem;
            }

            h3 {
                font-size: 1.2rem;
            }

            .meta {
                font-size: 0.85rem;
            }

            .navigation {
                flex-direction: column;
            }

            table {
                font-size: 0.85rem;
            }

            th, td {
                padding: var(--spacing-xs);
            }
        }
    
        
    
        /* Breadcrumb styles */
        .breadcrumb {
            background: #f7fafc;
            padding: 0.75rem 1rem;
            border-bottom: 1px solid #e2e8f0;
            font-size: 0.9rem;
        }

        .breadcrumb-content {
            max-width: 900px;
            margin: 0 auto;
            display: flex;
            align-items: center;
            flex-wrap: wrap;
            gap: 0.5rem;
        }

        .breadcrumb a {
            color: #667eea;
            text-decoration: none;
            transition: color 0.2s;
        }

        .breadcrumb a:hover {
            color: #764ba2;
            text-decoration: underline;
        }

        .breadcrumb-separator {
            color: #a0aec0;
            margin: 0 0.25rem;
        }

        .breadcrumb-current {
            color: #4a5568;
            font-weight: 500;
        }
    </style>

    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
        mermaid.initialize({ startOnLoad: true, theme: 'default' });
    </script>

    <!-- MathJax for LaTeX equation rendering -->
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                displayMath: [['$$', '$$'], ['\\[', '\\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
                ignoreHtmlClass: 'mermaid'
            }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" async></script>
</head>
<body>
            <nav class="breadcrumb">
        <div class="breadcrumb-content">
            <a href="../../index.html">AIå¯ºå­å±‹ãƒˆãƒƒãƒ—</a><span class="breadcrumb-separator">â€º</span><a href="../../ML/index.html">æ©Ÿæ¢°å­¦ç¿’</a><span class="breadcrumb-separator">â€º</span><a href="../../ML/automl-introduction/index.html">Automl</a><span class="breadcrumb-separator">â€º</span><span class="breadcrumb-current">Chapter 3</span>
        </div>
    </nav>

        <header>
        <div class="header-content">
            <h1>ç¬¬3ç« ï¼šNeural Architecture Search</h1>
            <p class="subtitle">ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®è‡ªå‹•è¨­è¨ˆ - DARTSã¨AutoKerasã«ã‚ˆã‚‹æœ€é©ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®æ¢ç´¢</p>
            <div class="meta">
                <span class="meta-item">ğŸ“– èª­äº†æ™‚é–“: 35-40åˆ†</span>
                <span class="meta-item">ğŸ“Š é›£æ˜“åº¦: ä¸­ç´š-ä¸Šç´š</span>
                <span class="meta-item">ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹: 8å€‹</span>
                <span class="meta-item">ğŸ“ æ¼”ç¿’å•é¡Œ: 5å•</span>
            </div>
        </div>
    </header>

    <main class="container">

<h2>å­¦ç¿’ç›®æ¨™</h2>
<p>ã“ã®ç« ã‚’èª­ã‚€ã“ã¨ã§ã€ä»¥ä¸‹ã‚’ç¿’å¾—ã§ãã¾ã™ï¼š</p>
<ul>
<li>âœ… Neural Architecture Searchï¼ˆNASï¼‰ã®æ¢ç´¢ç©ºé–“è¨­è¨ˆã‚’ç†è§£ã™ã‚‹</li>
<li>âœ… NASã®ä¸»è¦ãªæ¢ç´¢æˆ¦ç•¥ï¼ˆå¼·åŒ–å­¦ç¿’ã€é€²åŒ–ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã€å‹¾é…ãƒ™ãƒ¼ã‚¹ï¼‰ã‚’ç†è§£ã™ã‚‹</li>
<li>âœ… AutoKerasã‚’ä½¿ã£ãŸè‡ªå‹•ãƒ¢ãƒ‡ãƒ«æ¢ç´¢ã‚’å®Ÿè£…ã§ãã‚‹</li>
<li>âœ… DARTSï¼ˆå¾®åˆ†å¯èƒ½ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æ¢ç´¢ï¼‰ã®åŸç†ã¨å®Ÿè£…ã‚’ç†è§£ã™ã‚‹</li>
<li>âœ… NASã®åŠ¹ç‡åŒ–æ‰‹æ³•ï¼ˆWeight Sharingã€Proxy Tasksï¼‰ã‚’ç†è§£ã™ã‚‹</li>
<li>âœ… å®Ÿãƒ‡ãƒ¼ã‚¿ã§AutoKerasã¨DARTSã‚’æ´»ç”¨ã§ãã‚‹</li>
</ul>

<hr>

<h2>3.1 NASã®æ¢ç´¢ç©ºé–“</h2>

<h3>Neural Architecture Searchã¨ã¯</h3>
<p><strong>Neural Architecture Searchï¼ˆNASï¼‰</strong>ã¯ã€ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’è‡ªå‹•çš„ã«è¨­è¨ˆã™ã‚‹æŠ€è¡“ã§ã™ã€‚</p>

<blockquote>
<p>ã€Œæ‰‹å‹•è¨­è¨ˆ vs è‡ªå‹•è¨­è¨ˆã€- NASã¯äººé–“ã®å°‚é–€çŸ¥è­˜ã‚’è¶…ãˆã‚‹ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’ç™ºè¦‹ã§ãã¾ã™ã€‚</p>
</blockquote>

<h3>NASã®3è¦ç´ </h3>

<table>
<thead>
<tr>
<th>è¦ç´ </th>
<th>èª¬æ˜</th>
<th>ä¾‹</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>æ¢ç´¢ç©ºé–“</strong></td>
<td>æ¢ç´¢å¯èƒ½ãªã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®é›†åˆ</td>
<td>Cell-basedã€Macroã€Micro</td>
</tr>
<tr>
<td><strong>æ¢ç´¢æˆ¦ç•¥</strong></td>
<td>ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®æ¢ç´¢æ–¹æ³•</td>
<td>å¼·åŒ–å­¦ç¿’ã€é€²åŒ–ã€å‹¾é…ãƒ™ãƒ¼ã‚¹</td>
</tr>
<tr>
<td><strong>æ€§èƒ½è©•ä¾¡</strong></td>
<td>ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®è‰¯ã—æ‚ªã—ã®åˆ¤å®š</td>
<td>ç²¾åº¦ã€FLOPsã€ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·</td>
</tr>
</tbody>
</table>

<h3>Cell-based Search Space</h3>

<p><strong>Cell-basedæ¢ç´¢ç©ºé–“</strong>ã§ã¯ã€ç¹°ã‚Šè¿”ã—ä½¿ç”¨ã•ã‚Œã‚‹ã€ŒCellã€ã‚’æ¢ç´¢ã—ã¾ã™ã€‚</p>

<div class="mermaid">
graph TD
    A[å…¥åŠ›ç”»åƒ] --> B[Stem Convolution]
    B --> C[Normal Cell 1]
    C --> D[Normal Cell 2]
    D --> E[Reduction Cell]
    E --> F[Normal Cell 3]
    F --> G[Normal Cell 4]
    G --> H[Reduction Cell]
    H --> I[Normal Cell 5]
    I --> J[Global Pool]
    J --> K[Softmax]

    style C fill:#e3f2fd
    style D fill:#e3f2fd
    style E fill:#ffebee
    style F fill:#e3f2fd
    style G fill:#e3f2fd
    style H fill:#ffebee
    style I fill:#e3f2fd
</div>

<h4>Cellã®ç¨®é¡</h4>

<table>
<thead>
<tr>
<th>Cellç¨®é¡</th>
<th>å½¹å‰²</th>
<th>ç©ºé–“è§£åƒåº¦</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Normal Cell</strong></td>
<td>ç‰¹å¾´æŠ½å‡º</td>
<td>ç¶­æŒ</td>
</tr>
<tr>
<td><strong>Reduction Cell</strong></td>
<td>ãƒ€ã‚¦ãƒ³ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°</td>
<td>1/2ã«å‰Šæ¸›</td>
</tr>
</tbody>
</table>

<h3>Macro vs Micro Architecture</h3>

<table>
<thead>
<tr>
<th>ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£</th>
<th>æ¢ç´¢å¯¾è±¡</th>
<th>åˆ©ç‚¹</th>
<th>æ¬ ç‚¹</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Macro</strong></td>
<td>å…¨ä½“æ§‹é€ ï¼ˆå±¤æ•°ã€çµåˆï¼‰</td>
<td>æŸ”è»Ÿæ€§ãŒé«˜ã„</td>
<td>æ¢ç´¢ç©ºé–“ãŒå·¨å¤§</td>
</tr>
<tr>
<td><strong>Micro</strong></td>
<td>Cellå†…éƒ¨ã®æ§‹é€ </td>
<td>åŠ¹ç‡çš„ã€è»¢ç§»å¯èƒ½</td>
<td>åˆ¶ç´„ãŒå¤šã„</td>
</tr>
</tbody>
</table>

<h3>æ¢ç´¢ç©ºé–“ã®ã‚µã‚¤ã‚º</h3>

<p>Cell-basedæ¢ç´¢ç©ºé–“ã®ã‚µã‚¤ã‚ºã¯è†¨å¤§ã§ã™ï¼š</p>

<p>$$
\text{Search Space Size} \approx O^{E}
$$</p>

<ul>
<li>$O$: æ“ä½œã®ç¨®é¡ï¼ˆä¾‹: 8ç¨®é¡ï¼‰</li>
<li>$E$: ã‚¨ãƒƒã‚¸ã®æ•°ï¼ˆä¾‹: 14å€‹ï¼‰</li>
<li>ä¾‹: $8^{14} \approx 4.4 \times 10^{12}$ é€šã‚Š</li>
</ul>

<h3>æ¢ç´¢ç©ºé–“è¨­è¨ˆã®å®Ÿä¾‹</h3>

<pre><code class="language-python">import numpy as np

# NASæ¢ç´¢ç©ºé–“ã®å®šç¾©
class SearchSpace:
    def __init__(self):
        # åˆ©ç”¨å¯èƒ½ãªæ“ä½œ
        self.operations = [
            'conv_3x3',
            'conv_5x5',
            'sep_conv_3x3',
            'sep_conv_5x5',
            'max_pool_3x3',
            'avg_pool_3x3',
            'identity',
            'zero'
        ]

        # Cellã®æ§‹é€ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.num_nodes = 4  # Cellå†…ã®ãƒãƒ¼ãƒ‰æ•°
        self.num_edges_per_node = 2  # å„ãƒãƒ¼ãƒ‰ã¸ã®å…¥åŠ›ã‚¨ãƒƒã‚¸æ•°

    def calculate_space_size(self):
        """æ¢ç´¢ç©ºé–“ã®ã‚µã‚¤ã‚ºã‚’è¨ˆç®—"""
        num_ops = len(self.operations)

        # å„ãƒãƒ¼ãƒ‰ã”ã¨ã«é¸æŠè‚¢ã‚’è¨ˆç®—
        total_choices = 1
        for node_id in range(2, self.num_nodes + 2):
            # ã‚¨ãƒƒã‚¸å…ƒã®é¸æŠï¼ˆå‰ã®ãƒãƒ¼ãƒ‰ã‹ã‚‰é¸ã¶ï¼‰
            edge_choices = node_id
            # æ“ä½œã®é¸æŠ
            op_choices = num_ops
            # ã“ã®ãƒãƒ¼ãƒ‰ã®é¸æŠè‚¢
            node_choices = (edge_choices * op_choices) ** self.num_edges_per_node
            total_choices *= node_choices

        return total_choices

    def sample_architecture(self):
        """ãƒ©ãƒ³ãƒ€ãƒ ã«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°"""
        architecture = []

        for node_id in range(2, self.num_nodes + 2):
            # ã“ã®ãƒãƒ¼ãƒ‰ã¸ã®å…¥åŠ›ã‚’é¸æŠ
            node_config = []
            for _ in range(self.num_edges_per_node):
                # å…¥åŠ›å…ƒãƒãƒ¼ãƒ‰
                input_node = np.random.randint(0, node_id)
                # æ“ä½œ
                operation = np.random.choice(self.operations)
                node_config.append((input_node, operation))

            architecture.append(node_config)

        return architecture

# æ¢ç´¢ç©ºé–“ã®ã‚µã‚¤ã‚ºã‚’è¨ˆç®—
search_space = SearchSpace()
space_size = search_space.calculate_space_size()

print("=== NASæ¢ç´¢ç©ºé–“ã®åˆ†æ ===")
print(f"æ“ä½œã®ç¨®é¡: {len(search_space.operations)}")
print(f"Cellå†…ã®ãƒãƒ¼ãƒ‰æ•°: {search_space.num_nodes}")
print(f"æ¢ç´¢ç©ºé–“ã®ã‚µã‚¤ã‚º: {space_size:,}")
print(f"ç§‘å­¦çš„è¨˜æ³•: {space_size:.2e}")

# ã‚µãƒ³ãƒ—ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£
sample = search_space.sample_architecture()
print(f"\n=== ã‚µãƒ³ãƒ—ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ ===")
for i, node in enumerate(sample, start=2):
    print(f"ãƒãƒ¼ãƒ‰ {i}:")
    for j, (input_node, op) in enumerate(node):
        print(f"  å…¥åŠ›{j}: ãƒãƒ¼ãƒ‰{input_node} â†’ {op}")
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>=== NASæ¢ç´¢ç©ºé–“ã®åˆ†æ ===
æ“ä½œã®ç¨®é¡: 8
Cellå†…ã®ãƒãƒ¼ãƒ‰æ•°: 4
æ¢ç´¢ç©ºé–“ã®ã‚µã‚¤ã‚º: 17,179,869,184
ç§‘å­¦çš„è¨˜æ³•: 1.72e+10

=== ã‚µãƒ³ãƒ—ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ ===
ãƒãƒ¼ãƒ‰ 2:
  å…¥åŠ›0: ãƒãƒ¼ãƒ‰0 â†’ sep_conv_3x3
  å…¥åŠ›1: ãƒãƒ¼ãƒ‰1 â†’ max_pool_3x3
ãƒãƒ¼ãƒ‰ 3:
  å…¥åŠ›0: ãƒãƒ¼ãƒ‰2 â†’ conv_5x5
  å…¥åŠ›1: ãƒãƒ¼ãƒ‰0 â†’ identity
ãƒãƒ¼ãƒ‰ 4:
  å…¥åŠ›0: ãƒãƒ¼ãƒ‰3 â†’ avg_pool_3x3
  å…¥åŠ›1: ãƒãƒ¼ãƒ‰1 â†’ sep_conv_5x5
ãƒãƒ¼ãƒ‰ 5:
  å…¥åŠ›0: ãƒãƒ¼ãƒ‰2 â†’ conv_3x3
  å…¥åŠ›1: ãƒãƒ¼ãƒ‰4 â†’ zero
</code></pre>

<hr>

<h2>3.2 NASã®æ¢ç´¢æˆ¦ç•¥</h2>

<h3>ä¸»è¦ãªæ¢ç´¢æˆ¦ç•¥ã®æ¯”è¼ƒ</h3>

<table>
<thead>
<tr>
<th>æ¢ç´¢æˆ¦ç•¥</th>
<th>åŸç†</th>
<th>è¨ˆç®—ã‚³ã‚¹ãƒˆ</th>
<th>ä»£è¡¨æ‰‹æ³•</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>å¼·åŒ–å­¦ç¿’</strong></td>
<td>ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©ãŒã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’ç”Ÿæˆ</td>
<td>éå¸¸ã«é«˜ã„</td>
<td>NASNet</td>
</tr>
<tr>
<td><strong>é€²åŒ–ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ </strong></td>
<td>çªç„¶å¤‰ç•°ã¨é¸æŠã‚’ç¹°ã‚Šè¿”ã™</td>
<td>é«˜ã„</td>
<td>AmoebaNet</td>
</tr>
<tr>
<td><strong>å‹¾é…ãƒ™ãƒ¼ã‚¹</strong></td>
<td>é€£ç¶šç·©å’Œã§å¾®åˆ†å¯èƒ½ã«</td>
<td>ä½ã„</td>
<td>DARTS</td>
</tr>
<tr>
<td><strong>One-shot</strong></td>
<td>ã‚¹ãƒ¼ãƒ‘ãƒ¼ãƒãƒƒãƒˆã‚’ä¸€åº¦å­¦ç¿’</td>
<td>ä¸­ç¨‹åº¦</td>
<td>ENAS</td>
</tr>
</tbody>
</table>

<h3>1. å¼·åŒ–å­¦ç¿’ãƒ™ãƒ¼ã‚¹ï¼ˆNASNetï¼‰</h3>

<p>NASNetã¯ã€RNNã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©ãŒã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’ç”Ÿæˆã—ã€ç²¾åº¦ã‚’å ±é…¬ã¨ã—ã¦å­¦ç¿’ã—ã¾ã™ã€‚</p>

<div class="mermaid">
graph LR
    A[RNNã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©] -->|ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ç”Ÿæˆ| B[å­ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯]
    B -->|å­¦ç¿’ãƒ»è©•ä¾¡| C[æ¤œè¨¼ç²¾åº¦]
    C -->|å ±é…¬| A

    style A fill:#e3f2fd
    style B fill:#fff3e0
    style C fill:#e8f5e9
</div>

<h4>å¼·åŒ–å­¦ç¿’NASã®ç–‘ä¼¼ã‚³ãƒ¼ãƒ‰</h4>

<pre><code class="language-python"># NASNetã‚¹ã‚¿ã‚¤ãƒ«ã®å¼·åŒ–å­¦ç¿’æ¢ç´¢ï¼ˆæ¦‚å¿µçš„å®Ÿè£…ï¼‰
import numpy as np

class RLController:
    """å¼·åŒ–å­¦ç¿’ãƒ™ãƒ¼ã‚¹ã®NASã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©"""

    def __init__(self, search_space):
        self.search_space = search_space
        self.history = []

    def sample_architecture(self, epsilon=0.1):
        """Îµ-greedyæˆ¦ç•¥ã§ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°"""
        if np.random.random() < epsilon:
            # æ¢ç´¢: ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
            return self.search_space.sample_architecture()
        else:
            # æ´»ç”¨: éå»ã®è‰¯ã„ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‹ã‚‰å¤‰ç•°
            if self.history:
                best_arch = max(self.history, key=lambda x: x['reward'])
                return self.mutate_architecture(best_arch['architecture'])
            else:
                return self.search_space.sample_architecture()

    def mutate_architecture(self, architecture):
        """ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã«å°ã•ãªå¤‰ç•°ã‚’åŠ ãˆã‚‹"""
        mutated = [node[:] for node in architecture]

        # ãƒ©ãƒ³ãƒ€ãƒ ã«1ã¤ã®ãƒãƒ¼ãƒ‰ã‚’å¤‰ç•°
        node_idx = np.random.randint(len(mutated))
        edge_idx = np.random.randint(len(mutated[node_idx]))

        input_node, _ = mutated[node_idx][edge_idx]
        new_op = np.random.choice(self.search_space.operations)
        mutated[node_idx][edge_idx] = (input_node, new_op)

        return mutated

    def update(self, architecture, reward):
        """å ±é…¬ã‚’å—ã‘å–ã£ã¦å±¥æ­´ã‚’æ›´æ–°"""
        self.history.append({
            'architecture': architecture,
            'reward': reward
        })

# ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
search_space = SearchSpace()
controller = RLController(search_space)

print("=== å¼·åŒ–å­¦ç¿’NASã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ ===")
for iteration in range(10):
    # ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
    arch = controller.sample_architecture(epsilon=0.3)

    # å ±é…¬ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆï¼ˆå®Ÿéš›ã«ã¯å­¦ç¿’ã—ã¦ç²¾åº¦ã‚’å–å¾—ï¼‰
    # ã“ã“ã§ã¯æ“ä½œã®å¤šæ§˜æ€§ã«åŸºã¥ããƒ€ãƒŸãƒ¼å ±é…¬
    ops_used = set()
    for node in arch:
        for _, op in node:
            ops_used.add(op)
    reward = len(ops_used) / len(search_space.operations) + np.random.normal(0, 0.1)

    # ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©ã‚’æ›´æ–°
    controller.update(arch, reward)

    print(f"Iteration {iteration + 1}: å ±é…¬ = {reward:.3f}")

# æœ€è‰¯ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’è¡¨ç¤º
best = max(controller.history, key=lambda x: x['reward'])
print(f"\n=== æœ€è‰¯ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ï¼ˆå ±é…¬: {best['reward']:.3f}ï¼‰===")
for i, node in enumerate(best['architecture'], start=2):
    print(f"ãƒãƒ¼ãƒ‰ {i}:")
    for j, (input_node, op) in enumerate(node):
        print(f"  å…¥åŠ›{j}: ãƒãƒ¼ãƒ‰{input_node} â†’ {op}")
</code></pre>

<h3>2. é€²åŒ–ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ </h3>

<p>é€²åŒ–ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã¯ã€ç”Ÿç‰©é€²åŒ–ã‚’æ¨¡å€£ã—ã¦ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’æœ€é©åŒ–ã—ã¾ã™ã€‚</p>

<pre><code class="language-python"># é€²åŒ–ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã«ã‚ˆã‚‹NASï¼ˆç°¡æ˜“ç‰ˆï¼‰
import random
import copy

class EvolutionaryNAS:
    """é€²åŒ–ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ãƒ™ãƒ¼ã‚¹ã®NAS"""

    def __init__(self, search_space, population_size=20, num_generations=10):
        self.search_space = search_space
        self.population_size = population_size
        self.num_generations = num_generations

    def initialize_population(self):
        """åˆæœŸé›†å›£ã‚’ç”Ÿæˆ"""
        return [self.search_space.sample_architecture()
                for _ in range(self.population_size)]

    def evaluate_fitness(self, architecture):
        """é©å¿œåº¦ã‚’è©•ä¾¡ï¼ˆãƒ€ãƒŸãƒ¼å®Ÿè£…ï¼‰"""
        # å®Ÿéš›ã«ã¯ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’å­¦ç¿’ã—ã¦ç²¾åº¦ã‚’æ¸¬å®š
        # ã“ã“ã§ã¯æ“ä½œã®å¤šæ§˜æ€§ã‚’ã‚¹ã‚³ã‚¢ã¨ã™ã‚‹
        ops_used = set()
        for node in architecture:
            for _, op in node:
                ops_used.add(op)
        return len(ops_used) + random.gauss(0, 1)

    def select_parents(self, population, fitness_scores, k=2):
        """ãƒˆãƒ¼ãƒŠãƒ¡ãƒ³ãƒˆé¸æŠ"""
        selected = []
        for _ in range(2):
            candidates_idx = random.sample(range(len(population)), k)
            best_idx = max(candidates_idx, key=lambda i: fitness_scores[i])
            selected.append(copy.deepcopy(population[best_idx]))
        return selected

    def crossover(self, parent1, parent2):
        """äº¤å‰ï¼ˆä¸€ç‚¹äº¤å‰ï¼‰"""
        crossover_point = random.randint(1, len(parent1) - 1)
        child1 = parent1[:crossover_point] + parent2[crossover_point:]
        child2 = parent2[:crossover_point] + parent1[crossover_point:]
        return child1, child2

    def mutate(self, architecture, mutation_rate=0.1):
        """çªç„¶å¤‰ç•°"""
        mutated = copy.deepcopy(architecture)

        for node_idx in range(len(mutated)):
            for edge_idx in range(len(mutated[node_idx])):
                if random.random() < mutation_rate:
                    input_node, _ = mutated[node_idx][edge_idx]
                    new_op = random.choice(self.search_space.operations)
                    mutated[node_idx][edge_idx] = (input_node, new_op)

        return mutated

    def run(self):
        """é€²åŒ–ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’å®Ÿè¡Œ"""
        # åˆæœŸé›†å›£
        population = self.initialize_population()

        best_history = []

        for generation in range(self.num_generations):
            # é©å¿œåº¦è©•ä¾¡
            fitness_scores = [self.evaluate_fitness(arch) for arch in population]

            # çµ±è¨ˆ
            best_fitness = max(fitness_scores)
            avg_fitness = sum(fitness_scores) / len(fitness_scores)
            best_history.append(best_fitness)

            print(f"ä¸–ä»£ {generation + 1}: æœ€è‰¯={best_fitness:.3f}, å¹³å‡={avg_fitness:.3f}")

            # æ–°ä¸–ä»£ã®ç”Ÿæˆ
            new_population = []

            # ã‚¨ãƒªãƒ¼ãƒˆä¿å­˜
            elite_idx = fitness_scores.index(max(fitness_scores))
            new_population.append(copy.deepcopy(population[elite_idx]))

            # é¸æŠã€äº¤å‰ã€çªç„¶å¤‰ç•°
            while len(new_population) < self.population_size:
                parents = self.select_parents(population, fitness_scores)
                offspring1, offspring2 = self.crossover(parents[0], parents[1])
                offspring1 = self.mutate(offspring1)
                offspring2 = self.mutate(offspring2)

                new_population.extend([offspring1, offspring2])

            population = new_population[:self.population_size]

        # æœ€è‰¯ã®å€‹ä½“ã‚’è¿”ã™
        fitness_scores = [self.evaluate_fitness(arch) for arch in population]
        best_idx = fitness_scores.index(max(fitness_scores))

        return population[best_idx], best_history

# å®Ÿè¡Œ
search_space = SearchSpace()
evo_nas = EvolutionaryNAS(search_space, population_size=20, num_generations=10)

print("=== é€²åŒ–ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã«ã‚ˆã‚‹NAS ===")
best_arch, history = evo_nas.run()

print(f"\n=== æœ€è‰¯ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ ===")
for i, node in enumerate(best_arch, start=2):
    print(f"ãƒãƒ¼ãƒ‰ {i}:")
    for j, (input_node, op) in enumerate(node):
        print(f"  å…¥åŠ›{j}: ãƒãƒ¼ãƒ‰{input_node} â†’ {op}")
</code></pre>

<h3>3. å‹¾é…ãƒ™ãƒ¼ã‚¹ï¼ˆDARTSæ¦‚è¦ï¼‰</h3>

<p>DARTSã¯æ¢ç´¢ç©ºé–“ã‚’é€£ç¶šç·©å’Œã—ã€å‹¾é…é™ä¸‹æ³•ã§æœ€é©åŒ–ã—ã¾ã™ï¼ˆè©³ç´°ã¯3.4ç¯€ï¼‰ã€‚</p>

<blockquote>
<p><strong>é‡è¦</strong>: å‹¾é…ãƒ™ãƒ¼ã‚¹æ‰‹æ³•ã¯ã€å¼·åŒ–å­¦ç¿’ã‚„é€²åŒ–ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã¨æ¯”ã¹ã¦1000å€ä»¥ä¸Šé«˜é€Ÿã§ã™ã€‚</p>
</blockquote>

<hr>

<h2>3.3 AutoKeras</h2>

<h3>AutoKerasã¨ã¯</h3>

<p><strong>AutoKeras</strong>ã¯ã€Kerasãƒ™ãƒ¼ã‚¹ã®AutoMLãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§ã€NASã‚’ç°¡å˜ã«åˆ©ç”¨ã§ãã¾ã™ã€‚</p>

<h3>AutoKerasã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«</h3>

<pre><code class="language-bash">pip install autokeras
</code></pre>

<h3>AutoKerasã®åŸºæœ¬çš„ãªä½¿ã„æ–¹</h3>

<pre><code class="language-python"># AutoKerasã®åŸºæœ¬ä¾‹ï¼šç”»åƒåˆ†é¡
import numpy as np
import autokeras as ak
from tensorflow.keras.datasets import mnist

# ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
(x_train, y_train), (x_test, y_test) = mnist.load_data()

# æ­£è¦åŒ–
x_train = x_train.astype('float32') / 255.0
x_test = x_test.astype('float32') / 255.0

# è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šæ¸›ï¼ˆãƒ‡ãƒ¢ç”¨ï¼‰
x_train = x_train[:5000]
y_train = y_train[:5000]
x_test = x_test[:1000]
y_test = y_test[:1000]

print("=== AutoKerasã«ã‚ˆã‚‹ç”»åƒåˆ†é¡ ===")
print(f"è¨“ç·´ãƒ‡ãƒ¼ã‚¿: {x_train.shape}")
print(f"ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {x_test.shape}")

# AutoKerasã®ImageClassifier
clf = ak.ImageClassifier(
    max_trials=5,  # è©¦è¡Œã™ã‚‹ãƒ¢ãƒ‡ãƒ«æ•°
    overwrite=True,
    directory='autokeras_results',
    project_name='mnist_classification'
)

# ãƒ¢ãƒ‡ãƒ«ã®æ¢ç´¢ã¨å­¦ç¿’
print("\næ¢ç´¢ã‚’é–‹å§‹...")
clf.fit(
    x_train, y_train,
    validation_split=0.2,
    epochs=3,
    verbose=1
)

# è©•ä¾¡
print("\n=== ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡ ===")
test_loss, test_acc = clf.evaluate(x_test, y_test, verbose=0)
print(f"ãƒ†ã‚¹ãƒˆç²¾åº¦: {test_acc:.4f}")
print(f"ãƒ†ã‚¹ãƒˆæå¤±: {test_loss:.4f}")

# æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ã®å–å¾—
best_model = clf.export_model()
print("\n=== æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ã®æ§‹é€  ===")
best_model.summary()
</code></pre>

<h3>AutoKerasã®æ§˜ã€…ãªã‚¿ã‚¹ã‚¯</h3>

<h4>1. æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã®åˆ†é¡</h4>

<pre><code class="language-python"># AutoKerasã§æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã‚’æ‰±ã†
import numpy as np
import pandas as pd
import autokeras as ak
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split

# ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
data = load_breast_cancer()
X = pd.DataFrame(data.data, columns=data.feature_names)
y = data.target

# è¨“ç·´ãƒ»ãƒ†ã‚¹ãƒˆåˆ†å‰²
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

print("=== æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿åˆ†é¡ ===")
print(f"ç‰¹å¾´é‡: {X.shape[1]}å€‹")
print(f"è¨“ç·´ã‚µãƒ³ãƒ—ãƒ«: {len(X_train)}")

# AutoKerasã®StructuredDataClassifier
clf = ak.StructuredDataClassifier(
    max_trials=3,
    overwrite=True,
    directory='autokeras_structured',
    project_name='breast_cancer'
)

# æ¢ç´¢ã¨å­¦ç¿’
clf.fit(
    X_train, y_train,
    validation_split=0.2,
    epochs=10,
    verbose=0
)

# è©•ä¾¡
test_loss, test_acc = clf.evaluate(X_test, y_test, verbose=0)
print(f"\n=== è©•ä¾¡çµæœ ===")
print(f"ãƒ†ã‚¹ãƒˆç²¾åº¦: {test_acc:.4f}")

# äºˆæ¸¬
predictions = clf.predict(X_test[:5])
print(f"\n=== ã‚µãƒ³ãƒ—ãƒ«äºˆæ¸¬ ===")
for i, pred in enumerate(predictions[:5]):
    true_label = y_test.iloc[i] if isinstance(y_test, pd.Series) else y_test[i]
    print(f"ã‚µãƒ³ãƒ—ãƒ« {i+1}: äºˆæ¸¬={pred[0][0]:.3f}, çœŸå€¤={true_label}")
</code></pre>

<h4>2. ãƒ†ã‚­ã‚¹ãƒˆåˆ†é¡</h4>

<pre><code class="language-python"># AutoKerasã§ãƒ†ã‚­ã‚¹ãƒˆåˆ†é¡
import numpy as np
import autokeras as ak
from tensorflow.keras.datasets import imdb

# IMDBãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆæ˜ ç”»ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®æ„Ÿæƒ…åˆ†æï¼‰
max_features = 10000
maxlen = 200

print("=== ãƒ†ã‚­ã‚¹ãƒˆåˆ†é¡ï¼ˆIMDBï¼‰===")
(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)

# ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šæ¸›ï¼ˆãƒ‡ãƒ¢ç”¨ï¼‰
x_train = x_train[:1000]
y_train = y_train[:1000]
x_test = x_test[:200]
y_test = y_test[:200]

# ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°
from tensorflow.keras.preprocessing.sequence import pad_sequences
x_train = pad_sequences(x_train, maxlen=maxlen)
x_test = pad_sequences(x_test, maxlen=maxlen)

print(f"è¨“ç·´ãƒ‡ãƒ¼ã‚¿: {x_train.shape}")
print(f"ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {x_test.shape}")

# AutoKerasã®TextClassifier
clf = ak.TextClassifier(
    max_trials=3,
    overwrite=True,
    directory='autokeras_text',
    project_name='imdb_sentiment'
)

# æ¢ç´¢ã¨å­¦ç¿’
clf.fit(
    x_train, y_train,
    validation_split=0.2,
    epochs=3,
    verbose=0
)

# è©•ä¾¡
test_loss, test_acc = clf.evaluate(x_test, y_test, verbose=0)
print(f"\n=== è©•ä¾¡çµæœ ===")
print(f"ãƒ†ã‚¹ãƒˆç²¾åº¦: {test_acc:.4f}")
</code></pre>

<h3>AutoKerasã®ã‚«ã‚¹ã‚¿ãƒ æ¢ç´¢ç©ºé–“</h3>

<pre><code class="language-python"># AutoKerasã§æ¢ç´¢ç©ºé–“ã‚’ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º
import autokeras as ak
from tensorflow.keras.datasets import mnist

# ãƒ‡ãƒ¼ã‚¿æº–å‚™
(x_train, y_train), (x_test, y_test) = mnist.load_data()
x_train = x_train[:5000].astype('float32') / 255.0
y_train = y_train[:5000]
x_test = x_test[:1000].astype('float32') / 255.0
y_test = y_test[:1000]

print("=== ã‚«ã‚¹ã‚¿ãƒ æ¢ç´¢ç©ºé–“ ===")

# å…¥åŠ›ãƒãƒ¼ãƒ‰
input_node = ak.ImageInput()

# æ­£è¦åŒ–ãƒ–ãƒ­ãƒƒã‚¯
output = ak.Normalization()(input_node)

# ConvBlockã®æ¢ç´¢ç©ºé–“ã‚’ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º
output = ak.ConvBlock(
    num_blocks=2,  # ç•³ã¿è¾¼ã¿ãƒ–ãƒ­ãƒƒã‚¯ã®æ•°
    num_layers=2,  # ãƒ–ãƒ­ãƒƒã‚¯å†…ã®å±¤æ•°
    max_pooling=True,
    dropout=0.25
)(output)

# åˆ†é¡ãƒ˜ãƒƒãƒ‰
output = ak.ClassificationHead(
    num_classes=10,
    dropout=0.5
)(output)

# ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰
clf = ak.AutoModel(
    inputs=input_node,
    outputs=output,
    max_trials=3,
    overwrite=True,
    directory='autokeras_custom',
    project_name='mnist_custom'
)

# å­¦ç¿’
clf.fit(
    x_train, y_train,
    validation_split=0.2,
    epochs=3,
    verbose=0
)

# è©•ä¾¡
test_loss, test_acc = clf.evaluate(x_test, y_test, verbose=0)
print(f"\nãƒ†ã‚¹ãƒˆç²¾åº¦: {test_acc:.4f}")

# æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ã®å–å¾—
best_model = clf.export_model()
print("\n=== ç™ºè¦‹ã•ã‚ŒãŸã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ ===")
best_model.summary()
</code></pre>

<hr>

<h2>3.4 DARTSï¼ˆDifferentiable Architecture Searchï¼‰</h2>

<h3>DARTSã®åŸç†</h3>

<p><strong>DARTS</strong>ã¯ã€é›¢æ•£çš„ãªæ¢ç´¢ç©ºé–“ã‚’é€£ç¶šç·©å’Œã™ã‚‹ã“ã¨ã§ã€å‹¾é…é™ä¸‹æ³•ã‚’é©ç”¨å¯èƒ½ã«ã—ã¾ã™ã€‚</p>

<h3>é€£ç¶šç·©å’Œï¼ˆContinuous Relaxationï¼‰</h3>

<p>å„ã‚¨ãƒƒã‚¸ã®æ“ä½œã‚’ã€å…¨æ“ä½œã®é‡ã¿ä»˜ãå’Œã¨ã—ã¦è¡¨ç¾ã—ã¾ã™ï¼š</p>

<p>$$
\bar{o}^{(i,j)}(x) = \sum_{o \in \mathcal{O}} \frac{\exp(\alpha_o^{(i,j)})}{\sum_{o' \in \mathcal{O}} \exp(\alpha_{o'}^{(i,j)})} \cdot o(x)
$$</p>

<ul>
<li>$\mathcal{O}$: æ“ä½œã®é›†åˆ</li>
<li>$\alpha_o^{(i,j)}$: ã‚¨ãƒƒã‚¸$(i,j)$ã§ã®æ“ä½œ$o$ã®é‡ã¿ï¼ˆã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼‰</li>
<li>ã‚½ãƒ•ãƒˆãƒãƒƒã‚¯ã‚¹ã§æ­£è¦åŒ–ã—ã€å¾®åˆ†å¯èƒ½ã«</li>
</ul>

<h3>Bi-level Optimization</h3>

<p>DARTSã¯2ã¤ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’äº¤äº’ã«æœ€é©åŒ–ã—ã¾ã™ï¼š</p>

<table>
<thead>
<tr>
<th>ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿</th>
<th>èª¬æ˜</th>
<th>æœ€é©åŒ–</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>é‡ã¿ $w$</strong></td>
<td>ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®é‡ã¿</td>
<td>è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã§æœ€å°åŒ–</td>
</tr>
<tr>
<td><strong>ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ $\alpha$</strong></td>
<td>æ“ä½œã®é‡ã¿</td>
<td>æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã§æœ€å°åŒ–</td>
</tr>
</tbody>
</table>

<p>æœ€é©åŒ–å•é¡Œï¼š</p>

<p>$$
\begin{aligned}
\min_{\alpha} \quad & \mathcal{L}_{\text{val}}(w^*(\alpha), \alpha) \\
\text{s.t.} \quad & w^*(\alpha) = \arg\min_{w} \mathcal{L}_{\text{train}}(w, \alpha)
\end{aligned}
$$</p>

<h3>DARTSã®å®Ÿè£…ï¼ˆç°¡æ˜“ç‰ˆï¼‰</h3>

<pre><code class="language-python"># DARTSã®æ¦‚å¿µçš„å®Ÿè£…ï¼ˆç°¡æ˜“ç‰ˆï¼‰
import torch
import torch.nn as nn
import torch.nn.functional as F

class MixedOp(nn.Module):
    """è¤‡æ•°ã®æ“ä½œã®é‡ã¿ä»˜ãå’Œ"""

    def __init__(self, C, stride):
        super(MixedOp, self).__init__()
        self._ops = nn.ModuleList()

        # åˆ©ç”¨å¯èƒ½ãªæ“ä½œ
        self.operations = [
            ('sep_conv_3x3', lambda C, stride: SepConv(C, C, 3, stride, 1)),
            ('sep_conv_5x5', lambda C, stride: SepConv(C, C, 5, stride, 2)),
            ('avg_pool_3x3', lambda C, stride: nn.AvgPool2d(3, stride=stride, padding=1)),
            ('max_pool_3x3', lambda C, stride: nn.MaxPool2d(3, stride=stride, padding=1)),
            ('skip_connect', lambda C, stride: nn.Identity() if stride == 1 else FactorizedReduce(C, C)),
        ]

        for name, op in self.operations:
            self._ops.append(op(C, stride))

    def forward(self, x, weights):
        """é‡ã¿ä»˜ãå’Œã‚’è¨ˆç®—"""
        return sum(w * op(x) for w, op in zip(weights, self._ops))

class Cell(nn.Module):
    """DARTSã®Cell"""

    def __init__(self, num_nodes, C_prev, C, reduction):
        super(Cell, self).__init__()
        self.num_nodes = num_nodes

        # å„ã‚¨ãƒƒã‚¸ã«å¯¾ã™ã‚‹æ“ä½œ
        self._ops = nn.ModuleList()
        for i in range(num_nodes):
            for j in range(2 + i):
                stride = 2 if reduction and j < 2 else 1
                op = MixedOp(C, stride)
                self._ops.append(op)

    def forward(self, s0, s1, weights):
        """é †ä¼æ’­"""
        states = [s0, s1]
        offset = 0

        for i in range(self.num_nodes):
            s = sum(self._ops[offset + j](h, weights[offset + j])
                   for j, h in enumerate(states))
            offset += len(states)
            states.append(s)

        return torch.cat(states[-self.num_nodes:], dim=1)

class DARTSNetwork(nn.Module):
    """DARTSæ¢ç´¢ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯"""

    def __init__(self, C=16, num_cells=8, num_nodes=4, num_classes=10):
        super(DARTSNetwork, self).__init__()
        self.num_cells = num_cells
        self.num_nodes = num_nodes

        # ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆÎ±ï¼‰
        num_ops = 5  # æ“ä½œã®ç¨®é¡
        num_edges = sum(2 + i for i in range(num_nodes))
        self.alphas_normal = nn.Parameter(torch.randn(num_edges, num_ops))
        self.alphas_reduce = nn.Parameter(torch.randn(num_edges, num_ops))

        # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®é‡ã¿ï¼ˆwï¼‰
        self.stem = nn.Sequential(
            nn.Conv2d(3, C, 3, padding=1, bias=False),
            nn.BatchNorm2d(C)
        )

        # Cellsã®æ§‹ç¯‰ã¯ç°¡ç•¥åŒ–
        self.cells = nn.ModuleList()
        # ... (å®Ÿéš›ã®å®Ÿè£…ã§ã¯è¤‡æ•°ã®Cellã‚’è¿½åŠ )

        self.classifier = nn.Linear(C, num_classes)

    def arch_parameters(self):
        """ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¿”ã™"""
        return [self.alphas_normal, self.alphas_reduce]

    def weights_parameters(self):
        """ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®é‡ã¿ã‚’è¿”ã™"""
        return [p for n, p in self.named_parameters()
                if 'alpha' not in n]

# DARTSã®ä½¿ç”¨ä¾‹
print("=== DARTSæ¦‚å¿µãƒ¢ãƒ‡ãƒ« ===")
model = DARTSNetwork(C=16, num_cells=8, num_nodes=4, num_classes=10)

print(f"ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {sum(p.numel() for p in model.arch_parameters())}")
print(f"ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯é‡ã¿ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {sum(p.numel() for p in model.weights_parameters())}")

# ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å½¢çŠ¶
print(f"\nNormal cell Î±: {model.alphas_normal.shape}")
print(f"Reduction cell Î±: {model.alphas_reduce.shape}")

# ã‚½ãƒ•ãƒˆãƒãƒƒã‚¯ã‚¹ã§æ­£è¦åŒ–
weights_normal = F.softmax(model.alphas_normal, dim=-1)
print(f"\næ­£è¦åŒ–å¾Œã®é‡ã¿ï¼ˆNormal cell, æœ€åˆã®ã‚¨ãƒƒã‚¸ï¼‰:")
print(weights_normal[0].detach().numpy())
</code></pre>

<h3>DARTSã®å­¦ç¿’ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ </h3>

<pre><code class="language-python"># DARTSã®å­¦ç¿’æ‰‹é †ï¼ˆç–‘ä¼¼ã‚³ãƒ¼ãƒ‰ï¼‰
import torch
import torch.optim as optim

class DARTSTrainer:
    """DARTSã®å­¦ç¿’ã‚¯ãƒ©ã‚¹"""

    def __init__(self, model, train_loader, val_loader):
        self.model = model
        self.train_loader = train_loader
        self.val_loader = val_loader

        # 2ã¤ã®ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶
        self.optimizer_w = optim.SGD(
            model.weights_parameters(),
            lr=0.025,
            momentum=0.9,
            weight_decay=3e-4
        )

        self.optimizer_alpha = optim.Adam(
            model.arch_parameters(),
            lr=3e-4,
            betas=(0.5, 0.999),
            weight_decay=1e-3
        )

        self.criterion = nn.CrossEntropyLoss()

    def train_step(self, train_data, val_data):
        """1ã‚¹ãƒ†ãƒƒãƒ—ã®å­¦ç¿’"""
        # 1. ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆÎ±ï¼‰ã®æ›´æ–°
        self.model.train()
        x_val, y_val = val_data

        self.optimizer_alpha.zero_grad()
        logits = self.model(x_val)
        loss_alpha = self.criterion(logits, y_val)
        loss_alpha.backward()
        self.optimizer_alpha.step()

        # 2. ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯é‡ã¿ï¼ˆwï¼‰ã®æ›´æ–°
        x_train, y_train = train_data

        self.optimizer_w.zero_grad()
        logits = self.model(x_train)
        loss_w = self.criterion(logits, y_train)
        loss_w.backward()
        self.optimizer_w.step()

        return loss_w.item(), loss_alpha.item()

    def derive_architecture(self):
        """æœ€çµ‚çš„ãªã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’å°å‡º"""
        # å„ã‚¨ãƒƒã‚¸ã§æœ€ã‚‚é‡ã¿ã®å¤§ãã„æ“ä½œã‚’é¸æŠ
        def parse_alpha(alpha):
            gene = []
            n = 2
            start = 0
            for i in range(self.model.num_nodes):
                end = start + n
                W = alpha[start:end].copy()

                # å„ã‚¨ãƒƒã‚¸ã§æœ€è‰¯ã®æ“ä½œã‚’2ã¤é¸æŠ
                edges = sorted(range(W.shape[0]),
                              key=lambda x: -max(W[x]))[:2]

                for j in edges:
                    k_best = W[j].argmax()
                    gene.append((j, k_best))

                start = end
                n += 1

            return gene

        # ã‚½ãƒ•ãƒˆãƒãƒƒã‚¯ã‚¹ã§æ­£è¦åŒ–
        weights_normal = F.softmax(self.model.alphas_normal, dim=-1)
        weights_reduce = F.softmax(self.model.alphas_reduce, dim=-1)

        gene_normal = parse_alpha(weights_normal.data.cpu().numpy())
        gene_reduce = parse_alpha(weights_reduce.data.cpu().numpy())

        return gene_normal, gene_reduce

# ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ä¾‹
print("=== DARTSå­¦ç¿’æ‰‹é † ===")
print("1. ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–")
print("2. å„ã‚¨ãƒãƒƒã‚¯ã§:")
print("   a. æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã§Î±ã‚’æ›´æ–°ï¼ˆã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æœ€é©åŒ–ï¼‰")
print("   b. è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã§wã‚’æ›´æ–°ï¼ˆé‡ã¿æœ€é©åŒ–ï¼‰")
print("3. å­¦ç¿’çµ‚äº†å¾Œã€å„ã‚¨ãƒƒã‚¸ã§æœ€ã‚‚é‡ã¿ã®å¤§ãã„æ“ä½œã‚’é¸æŠ")
print("4. é¸æŠã•ã‚ŒãŸæ“ä½œã§ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’å†æ§‹ç¯‰ã—ã€æœ€çµ‚å­¦ç¿’")
</code></pre>

<h3>DARTSã®å®Ÿç”¨ä¾‹ï¼ˆPyTorchï¼‰</h3>

<pre><code class="language-python"># å®Ÿéš›ã®DARTSå®Ÿè£…ã‚’ä½¿ã£ãŸä¾‹ï¼ˆpt-dartsãƒ©ã‚¤ãƒ–ãƒ©ãƒªä½¿ç”¨ï¼‰
# æ³¨: pt-dartsã¯å¤–éƒ¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒªï¼ˆpip install pt-dartsï¼‰

# ä»¥ä¸‹ã¯æ¦‚å¿µçš„ãªã‚³ãƒ¼ãƒ‰ä¾‹
"""
import torch
from darts import DARTS
from darts.api import spaces
from darts.trainer import DARTSTrainer

# æ¢ç´¢ç©ºé–“ã®å®šç¾©
search_space = spaces.get_search_space('darts', 'cifar10')

# DARTSãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰
model = DARTS(
    C=16,
    num_classes=10,
    layers=8,
    criterion=nn.CrossEntropyLoss(),
    steps=4,
    multiplier=4,
    stem_multiplier=3
)

# ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ã®åˆæœŸåŒ–
trainer = DARTSTrainer(
    model,
    optimizer_config={
        'w_lr': 0.025,
        'w_momentum': 0.9,
        'w_weight_decay': 3e-4,
        'alpha_lr': 3e-4,
        'alpha_weight_decay': 1e-3
    }
)

# æ¢ç´¢ã®å®Ÿè¡Œ
trainer.search(
    train_loader,
    val_loader,
    epochs=50
)

# æœ€è‰¯ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®å–å¾—
best_architecture = model.genotype()
print(f"ç™ºè¦‹ã•ã‚ŒãŸã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£: {best_architecture}")
"""

print("=== DARTSã®å®Ÿç”¨çš„ãªä½¿ã„æ–¹ ===")
print("1. pt-dartsãªã©ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«")
print("2. æ¢ç´¢ç©ºé–“ã¨ãƒ¢ãƒ‡ãƒ«ã‚’å®šç¾©")
print("3. Bi-levelæœ€é©åŒ–ã§æ¢ç´¢")
print("4. ç™ºè¦‹ã•ã‚ŒãŸã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§å†å­¦ç¿’")
print("\nDARTSã®åˆ©ç‚¹:")
print("- æ¢ç´¢æ™‚é–“: 4 GPUæ—¥ï¼ˆNASNetã¯1800 GPUæ—¥ï¼‰")
print("- é«˜ç²¾åº¦: CIFAR-10ã§97%ä»¥ä¸Š")
print("- è»¢ç§»å¯èƒ½: ImageNetãªã©ã«ã‚‚é©ç”¨å¯èƒ½")
</code></pre>

<hr>

<h2>3.5 NASã®åŠ¹ç‡åŒ–</h2>

<h3>åŠ¹ç‡åŒ–æ‰‹æ³•ã®æ¯”è¼ƒ</h3>

<table>
<thead>
<tr>
<th>æ‰‹æ³•</th>
<th>åŸç†</th>
<th>é«˜é€ŸåŒ–ç‡</th>
<th>ç²¾åº¦ã¸ã®å½±éŸ¿</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Weight Sharing</strong></td>
<td>å€™è£œã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£é–“ã§é‡ã¿ã‚’å…±æœ‰</td>
<td>1000å€</td>
<td>å°</td>
</tr>
<tr>
<td><strong>Proxy Tasks</strong></td>
<td>ç°¡æ˜“ã‚¿ã‚¹ã‚¯ã§è©•ä¾¡</td>
<td>10-100å€</td>
<td>ä¸­</td>
</tr>
<tr>
<td><strong>Early Stopping</strong></td>
<td>ä½æ€§èƒ½ãƒ¢ãƒ‡ãƒ«ã‚’æ—©æœŸã«æ‰“ã¡åˆ‡ã‚Š</td>
<td>2-5å€</td>
<td>å°</td>
</tr>
<tr>
<td><strong>Transfer Learning</strong></td>
<td>é¡ä¼¼ã‚¿ã‚¹ã‚¯ã‹ã‚‰çŸ¥è­˜è»¢ç§»</td>
<td>5-10å€</td>
<td>å°</td>
</tr>
</tbody>
</table>

<h3>1. Weight Sharingï¼ˆENASï¼‰</h3>

<p><strong>Weight Sharing</strong>ã¯ã€å…¨ã¦ã®å€™è£œã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãŒé‡ã¿ã‚’å…±æœ‰ã™ã‚‹ã‚¹ãƒ¼ãƒ‘ãƒ¼ãƒãƒƒãƒˆã‚’æ§‹ç¯‰ã—ã¾ã™ã€‚</p>

<pre><code class="language-python"># Weight Sharingã®æ¦‚å¿µï¼ˆENASé¢¨ï¼‰
import torch
import torch.nn as nn

class SharedWeightSuperNet(nn.Module):
    """é‡ã¿å…±æœ‰ã‚¹ãƒ¼ãƒ‘ãƒ¼ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯"""

    def __init__(self, num_nodes=4, C=16):
        super(SharedWeightSuperNet, self).__init__()
        self.num_nodes = num_nodes

        # å…¨ã¦ã®å¯èƒ½ãªæ“ä½œã‚’äº‹å‰ã«æ§‹ç¯‰ï¼ˆé‡ã¿ã‚’å…±æœ‰ï¼‰
        self.ops = nn.ModuleDict({
            'conv_3x3': nn.Conv2d(C, C, 3, padding=1),
            'conv_5x5': nn.Conv2d(C, C, 5, padding=2),
            'max_pool': nn.MaxPool2d(3, stride=1, padding=1),
            'avg_pool': nn.AvgPool2d(3, stride=1, padding=1),
            'identity': nn.Identity()
        })

    def forward(self, x, architecture):
        """
        architecture: å„ãƒãƒ¼ãƒ‰ã®æ“ä½œã‚’æŒ‡å®š
        ä¾‹: [('conv_3x3', 0), ('max_pool', 1), ...]
        """
        states = [x, x]  # åˆæœŸçŠ¶æ…‹

        for node_id, (op_name, input_id) in enumerate(architecture):
            # æŒ‡å®šã•ã‚ŒãŸæ“ä½œã¨å…¥åŠ›ã§è¨ˆç®—
            s = self.ops[op_name](states[input_id])
            states.append(s)

        # æœ€å¾Œã®ãƒãƒ¼ãƒ‰ã®å‡ºåŠ›ã‚’è¿”ã™
        return states[-1]

# ã‚¹ãƒ¼ãƒ‘ãƒ¼ãƒãƒƒãƒˆã®æ§‹ç¯‰
supernet = SharedWeightSuperNet(num_nodes=4, C=16)

print("=== Weight Sharingï¼ˆENASé¢¨ï¼‰===")
print(f"ã‚¹ãƒ¼ãƒ‘ãƒ¼ãƒãƒƒãƒˆã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {sum(p.numel() for p in supernet.parameters()):,}")

# ç•°ãªã‚‹ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§åŒã˜é‡ã¿ã‚’ä½¿ç”¨
arch1 = [('conv_3x3', 0), ('max_pool', 1), ('identity', 2), ('avg_pool', 1)]
arch2 = [('conv_5x5', 1), ('identity', 0), ('max_pool', 2), ('conv_3x3', 3)]

# ãƒ€ãƒŸãƒ¼å…¥åŠ›
x = torch.randn(1, 16, 32, 32)

output1 = supernet(x, arch1)
output2 = supernet(x, arch2)

print(f"\nã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£1ã®å‡ºåŠ›å½¢çŠ¶: {output1.shape}")
print(f"ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£2ã®å‡ºåŠ›å½¢çŠ¶: {output2.shape}")
print("\nâ†’ åŒã˜é‡ã¿ã‚’å…±æœ‰ã—ãªãŒã‚‰ã€ç•°ãªã‚‹ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’è©•ä¾¡å¯èƒ½")
</code></pre>

<h3>2. Proxy Tasksã«ã‚ˆã‚‹é«˜é€ŸåŒ–</h3>

<p>Proxy Tasksã§ã¯ã€ä»¥ä¸‹ã®ã‚ˆã†ãªç°¡æ˜“åŒ–ã§ã‚³ã‚¹ãƒˆã‚’å‰Šæ¸›ã—ã¾ã™ï¼š</p>

<table>
<thead>
<tr>
<th>ç°¡æ˜“åŒ–</th>
<th>ä¾‹</th>
<th>é«˜é€ŸåŒ–</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºå‰Šæ¸›</strong></td>
<td>CIFAR-10ã®ä¸€éƒ¨ã®ã¿ä½¿ç”¨</td>
<td>2-5å€</td>
</tr>
<tr>
<td><strong>ã‚¨ãƒãƒƒã‚¯æ•°å‰Šæ¸›</strong></td>
<td>10ã‚¨ãƒãƒƒã‚¯ã§è©•ä¾¡</td>
<td>5-10å€</td>
</tr>
<tr>
<td><strong>ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºå‰Šæ¸›</strong></td>
<td>ãƒãƒ£ãƒãƒ«æ•°ã‚’1/4ã«</td>
<td>4-8å€</td>
</tr>
<tr>
<td><strong>è§£åƒåº¦å‰Šæ¸›</strong></td>
<td>32x32ã®ä»£ã‚ã‚Šã«16x16</td>
<td>4å€</td>
</tr>
</tbody>
</table>

<h3>3. NAS-Benchãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ</h3>

<p><strong>NAS-Bench</strong>ã¯ã€äº‹å‰è¨ˆç®—ã•ã‚ŒãŸã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®æ€§èƒ½ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã§ã™ã€‚</p>

<pre><code class="language-python"># NAS-Benchã®æ¦‚å¿µçš„ä½¿ç”¨ä¾‹
# æ³¨: å®Ÿéš›ã«ã¯nasbenchiãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ç”¨ï¼ˆpip install nasbenchï¼‰

class NASBenchSimulator:
    """NAS-Benchã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿"""

    def __init__(self):
        # äº‹å‰è¨ˆç®—ã•ã‚ŒãŸæ€§èƒ½ãƒ‡ãƒ¼ã‚¿ï¼ˆãƒ€ãƒŸãƒ¼ï¼‰
        self.benchmark_data = {}
        self._populate_dummy_data()

    def _populate_dummy_data(self):
        """ãƒ€ãƒŸãƒ¼ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆ"""
        import random
        random.seed(42)

        # 100å€‹ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®æ€§èƒ½ã‚’äº‹å‰è¨ˆç®—
        for i in range(100):
            arch_hash = f"arch_{i:03d}"
            self.benchmark_data[arch_hash] = {
                'val_accuracy': random.uniform(0.88, 0.95),
                'test_accuracy': random.uniform(0.87, 0.94),
                'training_time': random.uniform(100, 500),
                'params': random.randint(1_000_000, 10_000_000),
                'flops': random.randint(50_000_000, 500_000_000)
            }

    def query(self, architecture):
        """ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®æ€§èƒ½ã‚’ã‚¯ã‚¨ãƒªï¼ˆå³åº§ã«è¿”ã‚‹ï¼‰"""
        # ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’ãƒãƒƒã‚·ãƒ¥åŒ–
        arch_hash = self._hash_architecture(architecture)

        if arch_hash in self.benchmark_data:
            return self.benchmark_data[arch_hash]
        else:
            # æœªçŸ¥ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¯æ¨å®š
            return {
                'val_accuracy': 0.90,
                'test_accuracy': 0.89,
                'training_time': 300,
                'params': 5_000_000,
                'flops': 250_000_000
            }

    def _hash_architecture(self, architecture):
        """ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’ãƒãƒƒã‚·ãƒ¥åŒ–"""
        # ç°¡æ˜“ãƒãƒƒã‚·ãƒ¥ï¼ˆå®Ÿéš›ã¯ã‚‚ã£ã¨è¤‡é›‘ï¼‰
        arch_str = str(architecture)
        hash_val = sum(ord(c) for c in arch_str) % 100
        return f"arch_{hash_val:03d}"

# NAS-Benchã®ä½¿ç”¨
bench = NASBenchSimulator()

print("=== NAS-Benchã«ã‚ˆã‚‹é«˜é€Ÿè©•ä¾¡ ===")

# ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®æ¢ç´¢
import time

architectures = [
    [('conv_3x3', 0), ('max_pool', 1)],
    [('conv_5x5', 0), ('identity', 1)],
    [('avg_pool', 0), ('conv_3x3', 1)]
]

start_time = time.time()
results = []

for arch in architectures:
    result = bench.query(arch)
    results.append((arch, result))

end_time = time.time()

print(f"æ¢ç´¢æ™‚é–“: {end_time - start_time:.4f}ç§’")
print(f"\n=== æ¢ç´¢çµæœ ===")
for arch, result in results:
    print(f"ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£: {arch}")
    print(f"  æ¤œè¨¼ç²¾åº¦: {result['val_accuracy']:.3f}")
    print(f"  ãƒ†ã‚¹ãƒˆç²¾åº¦: {result['test_accuracy']:.3f}")
    print(f"  å­¦ç¿’æ™‚é–“: {result['training_time']:.1f}ç§’")
    print(f"  ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {result['params']:,}")
    print()

print("â†’ å®Ÿéš›ã®å­¦ç¿’ãªã—ã§æ€§èƒ½ã‚’å³åº§ã«å–å¾—å¯èƒ½")
</code></pre>

<h3>åŠ¹ç‡åŒ–æ‰‹æ³•ã®çµ„ã¿åˆã‚ã›</h3>

<pre><code class="language-python"># è¤‡æ•°ã®åŠ¹ç‡åŒ–æ‰‹æ³•ã‚’çµ„ã¿åˆã‚ã›ãŸæ¢ç´¢
import numpy as np

class EfficientNAS:
    """åŠ¹ç‡åŒ–ã•ã‚ŒãŸNAS"""

    def __init__(self, use_weight_sharing=True, use_proxy=True,
                 use_early_stopping=True):
        self.use_weight_sharing = use_weight_sharing
        self.use_proxy = use_proxy
        self.use_early_stopping = use_early_stopping

        if use_weight_sharing:
            self.supernet = SharedWeightSuperNet()

        if use_proxy:
            self.proxy_epochs = 10  # å®Œå…¨å­¦ç¿’ã®ä»£ã‚ã‚Šã«10ã‚¨ãƒãƒƒã‚¯
            self.proxy_data_fraction = 0.2  # ãƒ‡ãƒ¼ã‚¿ã®20%ã®ã¿ä½¿ç”¨

    def evaluate_architecture(self, architecture, full_evaluation=False):
        """ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’è©•ä¾¡"""
        if full_evaluation:
            # å®Œå…¨è©•ä¾¡ï¼ˆæœ€çµ‚å€™è£œã®ã¿ï¼‰
            epochs = 50
            data_fraction = 1.0
        else:
            # Proxyè©•ä¾¡
            epochs = self.proxy_epochs if self.use_proxy else 50
            data_fraction = self.proxy_data_fraction if self.use_proxy else 1.0

        # Early stoppingã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        if self.use_early_stopping:
            # æœ€åˆã®æ•°ã‚¨ãƒãƒƒã‚¯ã§æ€§èƒ½ãŒæ‚ªã‘ã‚Œã°æ‰“ã¡åˆ‡ã‚Š
            early_acc = np.random.random()
            if early_acc < 0.5:  # é–¾å€¤
                return {'accuracy': early_acc, 'stopped_early': True}

        # è©•ä¾¡ï¼ˆãƒ€ãƒŸãƒ¼ï¼‰
        accuracy = np.random.uniform(0.85, 0.95)

        return {
            'accuracy': accuracy,
            'epochs': epochs,
            'data_fraction': data_fraction,
            'stopped_early': False
        }

    def search(self, num_candidates=100, top_k=5):
        """NASæ¢ç´¢ã®å®Ÿè¡Œ"""
        print("=== åŠ¹ç‡çš„NASæ¢ç´¢ ===")
        print(f"Weight Sharing: {self.use_weight_sharing}")
        print(f"Proxy Tasks: {self.use_proxy}")
        print(f"Early Stopping: {self.use_early_stopping}")
        print()

        candidates = []

        # 1. å¤§è¦æ¨¡ãªProxyè©•ä¾¡
        for i in range(num_candidates):
            arch = [('conv_3x3', 0), ('max_pool', 1)]  # ãƒ€ãƒŸãƒ¼
            result = self.evaluate_architecture(arch, full_evaluation=False)
            candidates.append((arch, result))

        # Early stoppingã§æ‰“ã¡åˆ‡ã‚‰ã‚Œãªã‹ã£ãŸå€™è£œ
        valid_candidates = [c for c in candidates if not c[1]['stopped_early']]

        print(f"åˆæœŸå€™è£œ: {num_candidates}")
        print(f"Early stoppingã§å‰Šæ¸›: {num_candidates - len(valid_candidates)}")

        # 2. ãƒˆãƒƒãƒ—Kã‚’å®Œå…¨è©•ä¾¡
        top_candidates = sorted(valid_candidates,
                               key=lambda x: x[1]['accuracy'],
                               reverse=True)[:top_k]

        print(f"å®Œå…¨è©•ä¾¡ã™ã‚‹å€™è£œ: {top_k}")
        print()

        final_results = []
        for arch, proxy_result in top_candidates:
            full_result = self.evaluate_architecture(arch, full_evaluation=True)
            final_results.append((arch, full_result))

        # æœ€è‰¯ã®å€™è£œã‚’è¿”ã™
        best = max(final_results, key=lambda x: x[1]['accuracy'])

        return best, final_results

# å®Ÿè¡Œ
nas = EfficientNAS(
    use_weight_sharing=True,
    use_proxy=True,
    use_early_stopping=True
)

best_arch, all_results = nas.search(num_candidates=100, top_k=5)

print("=== æ¢ç´¢çµæœ ===")
print(f"æœ€è‰¯ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£: {best_arch[0]}")
print(f"æœ€è‰¯ç²¾åº¦: {best_arch[1]['accuracy']:.3f}")
print(f"\nãƒˆãƒƒãƒ—5ã®ç²¾åº¦:")
for i, (arch, result) in enumerate(all_results, 1):
    print(f"{i}. ç²¾åº¦={result['accuracy']:.3f}")
</code></pre>

<hr>

<h2>3.6 æœ¬ç« ã®ã¾ã¨ã‚</h2>

<h3>å­¦ã‚“ã ã“ã¨</h3>

<ol>
<li><p><strong>NASã®æ¢ç´¢ç©ºé–“</strong></p>
<ul>
<li>Cell-basedæ¢ç´¢ç©ºé–“ã®è¨­è¨ˆ</li>
<li>Macro vs Micro architecture</li>
<li>æ¢ç´¢ç©ºé–“ã®ã‚µã‚¤ã‚ºã¨è¤‡é›‘æ€§</li>
</ul></li>

<li><p><strong>NASã®æ¢ç´¢æˆ¦ç•¥</strong></p>
<ul>
<li>å¼·åŒ–å­¦ç¿’ï¼ˆNASNetï¼‰: RNNã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©ã§ç”Ÿæˆ</li>
<li>é€²åŒ–ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ : çªç„¶å¤‰ç•°ã¨é¸æŠ</li>
<li>å‹¾é…ãƒ™ãƒ¼ã‚¹ï¼ˆDARTSï¼‰: é€£ç¶šç·©å’Œã§é«˜é€ŸåŒ–</li>
<li>One-shotï¼ˆENASï¼‰: Weight Sharingã§åŠ¹ç‡åŒ–</li>
</ul></li>

<li><p><strong>AutoKeras</strong></p>
<ul>
<li>ç”»åƒã€ãƒ†ã‚­ã‚¹ãƒˆã€æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã®è‡ªå‹•å­¦ç¿’</li>
<li>ã‚«ã‚¹ã‚¿ãƒ æ¢ç´¢ç©ºé–“ã®å®šç¾©</li>
<li>ç°¡å˜ãªAPIã§é«˜åº¦ãªNASã‚’åˆ©ç”¨</li>
</ul></li>

<li><p><strong>DARTS</strong></p>
<ul>
<li>é€£ç¶šç·©å’Œã«ã‚ˆã‚‹å¾®åˆ†å¯èƒ½ãªNAS</li>
<li>Bi-level optimizationï¼ˆw ã¨ Î±ï¼‰</li>
<li>1000å€ä»¥ä¸Šã®é«˜é€ŸåŒ–ã‚’å®Ÿç¾</li>
</ul></li>

<li><p><strong>NASã®åŠ¹ç‡åŒ–</strong></p>
<ul>
<li>Weight Sharing: ã‚¹ãƒ¼ãƒ‘ãƒ¼ãƒãƒƒãƒˆã§é‡ã¿ã‚’å…±æœ‰</li>
<li>Proxy Tasks: ç°¡æ˜“ã‚¿ã‚¹ã‚¯ã§è©•ä¾¡</li>
<li>Early Stopping: ä½æ€§èƒ½ã‚’æ—©æœŸæ‰“ã¡åˆ‡ã‚Š</li>
<li>NAS-Bench: äº‹å‰è¨ˆç®—ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹</li>
</ul></li>
</ol>

<h3>æ¢ç´¢æˆ¦ç•¥ã®é¸æŠã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³</h3>

<table>
<thead>
<tr>
<th>çŠ¶æ³</th>
<th>æ¨å¥¨æ‰‹æ³•</th>
<th>ç†ç”±</th>
</tr>
</thead>
<tbody>
<tr>
<td>è¨ˆç®—è³‡æºãŒè±Šå¯Œ</td>
<td>å¼·åŒ–å­¦ç¿’ã€é€²åŒ–</td>
<td>é«˜ç²¾åº¦ãŒæœŸå¾…ã§ãã‚‹</td>
</tr>
<tr>
<td>è¨ˆç®—è³‡æºãŒé™å®šçš„</td>
<td>DARTSã€ENAS</td>
<td>é«˜é€Ÿã§å®Ÿç”¨çš„</td>
</tr>
<tr>
<td>åˆã‚ã¦ã®NAS</td>
<td>AutoKeras</td>
<td>ç°¡å˜ã§ä½¿ã„ã‚„ã™ã„</td>
</tr>
<tr>
<td>ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºãŒå¿…è¦</td>
<td>DARTSã®å®Ÿè£…</td>
<td>æŸ”è»Ÿæ€§ãŒé«˜ã„</td>
</tr>
<tr>
<td>ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ç ”ç©¶</td>
<td>NAS-Bench</td>
<td>å†ç¾æ€§ã¨å…¬å¹³æ€§</td>
</tr>
</tbody>
</table>

<h3>æ¬¡ã®ç« ã¸</h3>

<p>ç¬¬4ç« ã§ã¯ã€<strong>Feature Engineering Automation</strong>ã‚’å­¦ã³ã¾ã™ï¼š</p>
<ul>
<li>è‡ªå‹•ç‰¹å¾´é‡ç”Ÿæˆ</li>
<li>ç‰¹å¾´é¸æŠã®è‡ªå‹•åŒ–</li>
<li>ç‰¹å¾´é‡é‡è¦åº¦ã®å¯è¦–åŒ–</li>
<li>AutoMLãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®çµ±åˆ</li>
<li>å®Ÿè·µçš„ãªFeature Engineering</li>
</ul>

<hr>

<h2>æ¼”ç¿’å•é¡Œ</h2>

<h3>å•é¡Œ1ï¼ˆé›£æ˜“åº¦ï¼šeasyï¼‰</h3>
<p>NASã®3è¦ç´ ï¼ˆæ¢ç´¢ç©ºé–“ã€æ¢ç´¢æˆ¦ç•¥ã€æ€§èƒ½è©•ä¾¡ï¼‰ã«ã¤ã„ã¦ã€ãã‚Œãã‚Œèª¬æ˜ã—ã¦ãã ã•ã„ã€‚</p>

<details>
<summary>è§£ç­”ä¾‹</summary>

<p><strong>è§£ç­”</strong>ï¼š</p>

<ol>
<li><p><strong>æ¢ç´¢ç©ºé–“ï¼ˆSearch Spaceï¼‰</strong></p>
<ul>
<li>èª¬æ˜: æ¢ç´¢å¯èƒ½ãªã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®é›†åˆ</li>
<li>ä¾‹: Cell-basedï¼ˆNormal Cellã¨Reduction Cellï¼‰ã€å±¤ã®ç¨®é¡ï¼ˆConvã€Poolingï¼‰ã€çµåˆãƒ‘ã‚¿ãƒ¼ãƒ³</li>
<li>é‡è¦æ€§: æ¢ç´¢ç©ºé–“ãŒå¤§ãã™ãã‚‹ã¨è¨ˆç®—ã‚³ã‚¹ãƒˆãŒé«˜ãã€å°ã•ã™ãã‚‹ã¨æœ€é©è§£ã‚’é€ƒã™</li>
</ul></li>

<li><p><strong>æ¢ç´¢æˆ¦ç•¥ï¼ˆSearch Strategyï¼‰</strong></p>
<ul>
<li>èª¬æ˜: ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’ã©ã®ã‚ˆã†ã«æ¢ç´¢ã™ã‚‹ã‹</li>
<li>ä¾‹: å¼·åŒ–å­¦ç¿’ï¼ˆNASNetï¼‰ã€é€²åŒ–ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ï¼ˆAmoebaNetï¼‰ã€å‹¾é…ãƒ™ãƒ¼ã‚¹ï¼ˆDARTSï¼‰</li>
<li>ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•: ç²¾åº¦ vs è¨ˆç®—ã‚³ã‚¹ãƒˆ</li>
</ul></li>

<li><p><strong>æ€§èƒ½è©•ä¾¡ï¼ˆPerformance Estimationï¼‰</strong></p>
<ul>
<li>èª¬æ˜: ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®è‰¯ã—æ‚ªã—ã‚’åˆ¤å®šã™ã‚‹æ–¹æ³•</li>
<li>æŒ‡æ¨™: ç²¾åº¦ã€FLOPsã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã€ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã€ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡</li>
<li>åŠ¹ç‡åŒ–: Proxy tasksã€Weight sharingã€Early stopping</li>
</ul></li>
</ol>

</details>

<h3>å•é¡Œ2ï¼ˆé›£æ˜“åº¦ï¼šmediumï¼‰</h3>
<p>DARTSãŒå¼·åŒ–å­¦ç¿’ãƒ™ãƒ¼ã‚¹ã®NASã«æ¯”ã¹ã¦é«˜é€Ÿãªç†ç”±ã‚’ã€é€£ç¶šç·©å’Œã®è¦³ç‚¹ã‹ã‚‰èª¬æ˜ã—ã¦ãã ã•ã„ã€‚</p>

<details>
<summary>è§£ç­”ä¾‹</summary>

<p><strong>è§£ç­”</strong>ï¼š</p>

<p><strong>å¼·åŒ–å­¦ç¿’ãƒ™ãƒ¼ã‚¹ã®NASï¼ˆä¾‹: NASNetï¼‰</strong>ï¼š</p>
<ul>
<li>é›¢æ•£çš„æ¢ç´¢: ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚° â†’ å­¦ç¿’ â†’ è©•ä¾¡ã‚’ç¹°ã‚Šè¿”ã™</li>
<li>å„å€™è£œã‚’å€‹åˆ¥ã«å­¦ç¿’ã™ã‚‹å¿…è¦ãŒã‚ã‚‹</li>
<li>è¨ˆç®—ã‚³ã‚¹ãƒˆ: æ•°åƒã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ Ã— å®Œå…¨å­¦ç¿’ = éå¸¸ã«é«˜ã„ï¼ˆ1800 GPUæ—¥ï¼‰</li>
</ul>

<p><strong>DARTSï¼ˆå‹¾é…ãƒ™ãƒ¼ã‚¹ï¼‰</strong>ï¼š</p>
<ul>
<li>é€£ç¶šç·©å’Œ: é›¢æ•£çš„ãªé¸æŠï¼ˆã©ã®æ“ä½œã‚’ä½¿ã†ã‹ï¼‰ã‚’é€£ç¶šçš„ãªé‡ã¿ä»˜ãå’Œã«å¤‰æ›</li>
<li>å¼: $\bar{o}(x) = \sum_o \frac{\exp(\alpha_o)}{\sum_{o'} \exp(\alpha_{o'})} \cdot o(x)$</li>
<li>å‹¾é…é™ä¸‹æ³•ãŒé©ç”¨å¯èƒ½: Î±ã‚’å‹¾é…ã§æœ€é©åŒ–ã§ãã‚‹</li>
<li>Weight sharing: å…¨ã¦ã®å€™è£œãŒåŒã˜ã‚¹ãƒ¼ãƒ‘ãƒ¼ãƒãƒƒãƒˆã‚’å…±æœ‰</li>
<li>è¨ˆç®—ã‚³ã‚¹ãƒˆ: 1å›ã®ã‚¹ãƒ¼ãƒ‘ãƒ¼ãƒãƒƒãƒˆå­¦ç¿’ = å¤§å¹…å‰Šæ¸›ï¼ˆ4 GPUæ—¥ï¼‰</li>
</ul>

<p><strong>é«˜é€ŸåŒ–ã®ç†ç”±</strong>ï¼š</p>
<ol>
<li>é›¢æ•£â†’é€£ç¶š: å¾®åˆ†å¯èƒ½ã«ãªã‚Šã€åŠ¹ç‡çš„ãªå‹¾é…æœ€é©åŒ–ãŒå¯èƒ½</li>
<li>Weight sharing: å€™è£œé–“ã§é‡ã¿ã‚’å…±æœ‰ã—ã€å€‹åˆ¥å­¦ç¿’ã‚’å›é¿</li>
<li>Bi-level optimization: wã¨Î±ã‚’äº¤äº’ã«æ›´æ–°ã—ã€åŠ¹ç‡çš„ã«æ¢ç´¢</li>
</ol>

<p><strong>çµæœ</strong>ï¼š</p>
<ul>
<li>NASNet: 1800 GPUæ—¥</li>
<li>DARTS: 4 GPUæ—¥</li>
<li>é«˜é€ŸåŒ–ç‡: ç´„450å€</li>
</ul>

</details>

<h3>å•é¡Œ3ï¼ˆé›£æ˜“åº¦ï¼šmediumï¼‰</h3>
<p>ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã‚’å®Œæˆã•ã›ã¦ã€AutoKerasã§ç”»åƒåˆ†é¡ãƒ¢ãƒ‡ãƒ«ã‚’æ¢ç´¢ã—ã¦ãã ã•ã„ã€‚</p>

<pre><code class="language-python">import autokeras as ak
from tensorflow.keras.datasets import fashion_mnist

# ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()

# TODO: ãƒ‡ãƒ¼ã‚¿ã®æ­£è¦åŒ–
# x_train = ...
# x_test = ...

# TODO: AutoKerasã®ImageClassifierã‚’æ§‹ç¯‰
# clf = ak.ImageClassifier(...)

# TODO: ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’
# clf.fit(...)

# TODO: è©•ä¾¡
# test_acc = ...
# print(f"ãƒ†ã‚¹ãƒˆç²¾åº¦: {test_acc:.4f}")
</code></pre>

<details>
<summary>è§£ç­”ä¾‹</summary>

<pre><code class="language-python">import autokeras as ak
from tensorflow.keras.datasets import fashion_mnist

# ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()

# ãƒ‡ãƒ¼ã‚¿ã®æ­£è¦åŒ–
x_train = x_train.astype('float32') / 255.0
x_test = x_test.astype('float32') / 255.0

# ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºå‰Šæ¸›ï¼ˆãƒ‡ãƒ¢ç”¨ï¼‰
x_train = x_train[:5000]
y_train = y_train[:5000]
x_test = x_test[:1000]
y_test = y_test[:1000]

print("=== Fashion-MNISTåˆ†é¡ ===")
print(f"è¨“ç·´ãƒ‡ãƒ¼ã‚¿: {x_train.shape}")
print(f"ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {x_test.shape}")

# AutoKerasã®ImageClassifier
clf = ak.ImageClassifier(
    max_trials=5,  # æ¢ç´¢ã™ã‚‹å€™è£œæ•°
    epochs=10,     # å„å€™è£œã®å­¦ç¿’ã‚¨ãƒãƒƒã‚¯æ•°
    overwrite=True,
    directory='autokeras_fashion',
    project_name='fashion_mnist'
)

# ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’
print("\næ¢ç´¢ã‚’é–‹å§‹...")
clf.fit(
    x_train, y_train,
    validation_split=0.2,
    verbose=1
)

# è©•ä¾¡
print("\n=== è©•ä¾¡ ===")
test_loss, test_acc = clf.evaluate(x_test, y_test, verbose=0)
print(f"ãƒ†ã‚¹ãƒˆç²¾åº¦: {test_acc:.4f}")
print(f"ãƒ†ã‚¹ãƒˆæå¤±: {test_loss:.4f}")

# æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ã®å–å¾—
best_model = clf.export_model()
print("\n=== ç™ºè¦‹ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ« ===")
best_model.summary()

# äºˆæ¸¬ä¾‹
import numpy as np
predictions = clf.predict(x_test[:5])
print("\n=== äºˆæ¸¬ä¾‹ ===")
for i in range(5):
    print(f"ã‚µãƒ³ãƒ—ãƒ« {i+1}: äºˆæ¸¬={np.argmax(predictions[i])}, çœŸå€¤={y_test[i]}")
</code></pre>

</details>

<h3>å•é¡Œ4ï¼ˆé›£æ˜“åº¦ï¼šhardï¼‰</h3>
<p>Weight Sharingã‚’ä½¿ã£ãŸã‚¹ãƒ¼ãƒ‘ãƒ¼ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’å®Ÿè£…ã—ã€ç•°ãªã‚‹2ã¤ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§é‡ã¿ãŒå…±æœ‰ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚</p>

<details>
<summary>è§£ç­”ä¾‹</summary>

<pre><code class="language-python">import torch
import torch.nn as nn
import torch.nn.functional as F

class SharedOperations(nn.Module):
    """é‡ã¿ã‚’å…±æœ‰ã™ã‚‹æ“ä½œã®ãƒ—ãƒ¼ãƒ«"""

    def __init__(self, C):
        super(SharedOperations, self).__init__()

        # å…¨ã¦ã®å¯èƒ½ãªæ“ä½œï¼ˆé‡ã¿ã¯1åº¦ã ã‘å®šç¾©ï¼‰
        self.ops = nn.ModuleDict({
            'conv_3x3': nn.Conv2d(C, C, 3, padding=1, bias=False),
            'conv_5x5': nn.Conv2d(C, C, 5, padding=2, bias=False),
            'sep_conv_3x3': nn.Sequential(
                nn.Conv2d(C, C, 3, padding=1, groups=C, bias=False),
                nn.Conv2d(C, C, 1, bias=False)
            ),
            'max_pool_3x3': nn.MaxPool2d(3, stride=1, padding=1),
            'avg_pool_3x3': nn.AvgPool2d(3, stride=1, padding=1),
            'identity': nn.Identity()
        })

    def forward(self, x, op_name):
        """æŒ‡å®šã•ã‚ŒãŸæ“ä½œã‚’é©ç”¨"""
        return self.ops[op_name](x)

class SuperNet(nn.Module):
    """ã‚¹ãƒ¼ãƒ‘ãƒ¼ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯"""

    def __init__(self, C=16):
        super(SuperNet, self).__init__()
        self.shared_ops = SharedOperations(C)

    def forward(self, x, architecture):
        """
        architecture: [(op_name, input_id), ...]ã®å½¢å¼
        """
        # åˆæœŸçŠ¶æ…‹
        states = [x]

        for op_name, input_id in architecture:
            s = self.shared_ops(states[input_id], op_name)
            states.append(s)

        # æœ€å¾Œã®çŠ¶æ…‹ã‚’è¿”ã™
        return states[-1]

# ã‚¹ãƒ¼ãƒ‘ãƒ¼ãƒãƒƒãƒˆã®æ§‹ç¯‰
supernet = SuperNet(C=16)

print("=== Weight Sharingã®æ¤œè¨¼ ===")
print(f"ã‚¹ãƒ¼ãƒ‘ãƒ¼ãƒãƒƒãƒˆã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {sum(p.numel() for p in supernet.parameters()):,}")

# æ“ä½œã”ã¨ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°
print("\nå„æ“ä½œã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°:")
for name, op in supernet.shared_ops.ops.items():
    num_params = sum(p.numel() for p in op.parameters())
    print(f"  {name}: {num_params:,}")

# 2ã¤ã®ç•°ãªã‚‹ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£
arch1 = [('conv_3x3', 0), ('max_pool_3x3', 0), ('identity', 1)]
arch2 = [('conv_5x5', 0), ('avg_pool_3x3', 0), ('conv_3x3', 1)]

# åŒã˜å…¥åŠ›
x = torch.randn(2, 16, 32, 32)

# ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£1ã§é †ä¼æ’­
output1 = supernet(x, arch1)

# ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£2ã§é †ä¼æ’­
output2 = supernet(x, arch2)

print(f"\n=== é †ä¼æ’­ã®æ¤œè¨¼ ===")
print(f"ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£1ã®å‡ºåŠ›å½¢çŠ¶: {output1.shape}")
print(f"ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£2ã®å‡ºåŠ›å½¢çŠ¶: {output2.shape}")

# é‡ã¿ãŒå…±æœ‰ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
print("\n=== é‡ã¿å…±æœ‰ã®ç¢ºèª ===")
conv_3x3_params_before = list(supernet.shared_ops.ops['conv_3x3'].parameters())[0].clone()

# ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£1ã§é€†ä¼æ’­ï¼ˆconv_3x3ã‚’ä½¿ç”¨ï¼‰
loss1 = output1.sum()
loss1.backward()

conv_3x3_params_after = list(supernet.shared_ops.ops['conv_3x3'].parameters())[0]

# å‹¾é…ãŒè“„ç©ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
has_gradient = conv_3x3_params_after.grad is not None
print(f"conv_3x3ã«å‹¾é…ãŒè“„ç©: {has_gradient}")

# é‡ã¿ã®å…±æœ‰ã‚’è¦–è¦šçš„ã«ç¢ºèª
print("\n=== é‡ã¿å…±æœ‰ã®åˆ©ç‚¹ ===")
print("1. ãƒ¡ãƒ¢ãƒªåŠ¹ç‡: å…¨ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§åŒã˜é‡ã¿ã‚’ä½¿ç”¨")
print("2. å­¦ç¿’åŠ¹ç‡: 1ã¤ã®ã‚¹ãƒ¼ãƒ‘ãƒ¼ãƒãƒƒãƒˆã§å…¨å€™è£œã‚’è©•ä¾¡")
print("3. é«˜é€ŸåŒ–: å€‹åˆ¥å­¦ç¿’ã®ä»£ã‚ã‚Šã«å…±æœ‰å­¦ç¿’")

# ç•°ãªã‚‹ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’è©¦ã™
print("\n=== è¤‡æ•°ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®è©•ä¾¡ ===")
architectures = [
    [('conv_3x3', 0), ('max_pool_3x3', 0)],
    [('conv_5x5', 0), ('identity', 0)],
    [('sep_conv_3x3', 0), ('avg_pool_3x3', 0)],
]

for i, arch in enumerate(architectures, 1):
    output = supernet(x, arch)
    print(f"ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ {i}: å‡ºåŠ›å½¢çŠ¶ = {output.shape}, å¹³å‡å€¤ = {output.mean():.4f}")

print("\nâ†’ å…¨ã¦ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãŒåŒã˜é‡ã¿ã‚’å…±æœ‰ã—ãªãŒã‚‰è©•ä¾¡ã•ã‚Œã¾ã—ãŸ")
</code></pre>

</details>

<h3>å•é¡Œ5ï¼ˆé›£æ˜“åº¦ï¼šhardï¼‰</h3>
<p>DARTSã®Bi-levelæœ€é©åŒ–ã«ãŠã„ã¦ã€ãªãœè¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†ã‘ã¦æœ€é©åŒ–ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã®ã‹èª¬æ˜ã—ã¦ãã ã•ã„ã€‚ã¾ãŸã€åŒã˜ãƒ‡ãƒ¼ã‚¿ã§æœ€é©åŒ–ã—ãŸå ´åˆã«ä½•ãŒèµ·ã“ã‚‹ã‹äºˆæƒ³ã—ã¦ãã ã•ã„ã€‚</p>

<details>
<summary>è§£ç­”ä¾‹</summary>

<p><strong>è§£ç­”</strong>ï¼š</p>

<p><strong>Bi-levelæœ€é©åŒ–ã®ç›®çš„</strong>ï¼š</p>

<p>DARTSã¯2ç¨®é¡ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æœ€é©åŒ–ã—ã¾ã™ï¼š</p>
<ol>
<li><strong>ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®é‡ã¿ï¼ˆwï¼‰</strong>: è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã§æœ€å°åŒ–</li>
<li><strong>ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆÎ±ï¼‰</strong>: æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã§æœ€å°åŒ–</li>
</ol>

<p>æœ€é©åŒ–å•é¡Œï¼š</p>
<p>$$
\begin{aligned}
\min_{\alpha} \quad & \mathcal{L}_{\text{val}}(w^*(\alpha), \alpha) \\
\text{s.t.} \quad & w^*(\alpha) = \arg\min_{w} \mathcal{L}_{\text{train}}(w, \alpha)
\end{aligned}
$$</p>

<p><strong>è¨“ç·´ãƒ»æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†ã‘ã‚‹ç†ç”±</strong>ï¼š</p>

<ol>
<li><p><strong>éå­¦ç¿’ã®é˜²æ­¢</strong></p>
<ul>
<li>Î±ã‚’è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã§æœ€é©åŒ–ã™ã‚‹ã¨ã€è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã«éé©åˆã—ãŸã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’é¸æŠ</li>
<li>æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã§æœ€é©åŒ–ã™ã‚‹ã“ã¨ã§ã€æ±åŒ–æ€§èƒ½ã®é«˜ã„ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’é¸æŠ</li>
</ul></li>

<li><p><strong>å½¹å‰²ã®åˆ†é›¢</strong></p>
<ul>
<li>w: ä¸ãˆã‚‰ã‚ŒãŸã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§æœ€è‰¯ã®é‡ã¿ã‚’å­¦ç¿’ï¼ˆè¨“ç·´ãƒ‡ãƒ¼ã‚¿ï¼‰</li>
<li>Î±: æ¤œè¨¼æ€§èƒ½ãŒæœ€ã‚‚é«˜ã„ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’é¸æŠï¼ˆæ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ï¼‰</li>
</ul></li>

<li><p><strong>å…¬å¹³ãªè©•ä¾¡</strong></p>
<ul>
<li>è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’ã—ãŸwã‚’ã€ç‹¬ç«‹ã—ãŸæ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã§è©•ä¾¡</li>
<li>çœŸã®æ±åŒ–æ€§èƒ½ã‚’åæ˜ ã—ãŸã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£é¸æŠ</li>
</ul></li>
</ol>

<p><strong>åŒã˜ãƒ‡ãƒ¼ã‚¿ã§æœ€é©åŒ–ã—ãŸå ´åˆã®å•é¡Œ</strong>ï¼š</p>

<pre><code class="language-python"># èª¤ã£ãŸæ–¹æ³•ï¼ˆåŒã˜ãƒ‡ãƒ¼ã‚¿ã§wã¨Î±ã‚’æœ€é©åŒ–ï¼‰
# âŒ å•é¡Œã®ã‚ã‚‹ã‚³ãƒ¼ãƒ‰ä¾‹
for epoch in range(num_epochs):
    # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã§wã‚’æ›´æ–°
    loss_w = train_loss(w, alpha, train_data)
    w.update(-lr * grad(loss_w, w))

    # åŒã˜è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã§Î±ã‚’æ›´æ–° â† å•é¡Œï¼
    loss_alpha = train_loss(w, alpha, train_data)
    alpha.update(-lr * grad(loss_alpha, alpha))
</code></pre>

<p><strong>èµ·ã“ã‚‹å•é¡Œ</strong>ï¼š</p>
<ol>
<li><strong>éå­¦ç¿’</strong>: è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã«ç‰¹åŒ–ã—ãŸã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’é¸æŠ</li>
<li><strong>Identityæ“ä½œã®å„ªå…ˆ</strong>: è¨ˆç®—ã‚³ã‚¹ãƒˆãªã—ã§è¨“ç·´æå¤±ã‚’ä¸‹ã’ã‚‰ã‚Œã‚‹ãŸã‚ã€skip connectionã°ã‹ã‚Šé¸æŠ</li>
<li><strong>æ±åŒ–æ€§èƒ½ã®ä½ä¸‹</strong>: ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§ã®æ€§èƒ½ãŒæ‚ªåŒ–</li>
<li><strong>æ„å‘³ã®ã‚ã‚‹æ¢ç´¢ã®å¤±æ•—</strong>: çœŸã«æœ‰ç”¨ãªã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’ç™ºè¦‹ã§ããªã„</li>
</ol>

<p><strong>æ­£ã—ã„æ–¹æ³•</strong>ï¼š</p>
<pre><code class="language-python"># âœ… æ­£ã—ã„æ–¹æ³•
for epoch in range(num_epochs):
    # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã§wã‚’æ›´æ–°
    loss_w = train_loss(w, alpha, train_data)
    w.update(-lr * grad(loss_w, w))

    # æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã§Î±ã‚’æ›´æ–° â† æ­£ã—ã„ï¼
    loss_alpha = val_loss(w, alpha, val_data)
    alpha.update(-lr * grad(loss_alpha, alpha))
</code></pre>

<p><strong>ã¾ã¨ã‚</strong>ï¼š</p>
<table>
<thead>
<tr>
<th>å´é¢</th>
<th>è¨“ç·´ãƒ»æ¤œè¨¼åˆ†é›¢</th>
<th>åŒã˜ãƒ‡ãƒ¼ã‚¿ä½¿ç”¨</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>éå­¦ç¿’</strong></td>
<td>é˜²æ­¢ã§ãã‚‹</td>
<td>éå­¦ç¿’ã—ã‚„ã™ã„</td>
</tr>
<tr>
<td><strong>æ±åŒ–æ€§èƒ½</strong></td>
<td>é«˜ã„</td>
<td>ä½ã„</td>
</tr>
<tr>
<td><strong>ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£</strong></td>
<td>æœ‰ç”¨</td>
<td>trivialï¼ˆidentityåé‡ï¼‰</td>
</tr>
<tr>
<td><strong>å®Ÿç”¨æ€§</strong></td>
<td>é«˜ã„</td>
<td>ä½ã„</td>
</tr>
</tbody>
</table>

</details>

<hr>

<h2>å‚è€ƒæ–‡çŒ®</h2>

<ol>
<li>Zoph, B., & Le, Q. V. (2017). <em>Neural Architecture Search with Reinforcement Learning</em>. ICLR 2017.</li>
<li>Liu, H., Simonyan, K., & Yang, Y. (2019). <em>DARTS: Differentiable Architecture Search</em>. ICLR 2019.</li>
<li>Pham, H., Guan, M., Zoph, B., Le, Q., & Dean, J. (2018). <em>Efficient Neural Architecture Search via Parameter Sharing</em>. ICML 2018.</li>
<li>Real, E., et al. (2019). <em>Regularized Evolution for Image Classifier Architecture Search</em>. AAAI 2019.</li>
<li>Jin, H., Song, Q., & Hu, X. (2019). <em>Auto-Keras: An Efficient Neural Architecture Search System</em>. KDD 2019.</li>
<li>Elsken, T., Metzen, J. H., & Hutter, F. (2019). <em>Neural Architecture Search: A Survey</em>. JMLR 2019.</li>
</ol>

<div class="navigation">
    <a href="chapter2-hyperparameter-optimization.html" class="nav-button">â† å‰ã®ç« : ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–</a>
    <a href="chapter4-feature-engineering.html" class="nav-button">æ¬¡ã®ç« : Feature Engineeringè‡ªå‹•åŒ– â†’</a>
</div>

    </main>

    
    <section class="disclaimer">
        <h3>å…è²¬äº‹é …</h3>
        <ul>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯æ•™è‚²ãƒ»ç ”ç©¶ãƒ»æƒ…å ±æä¾›ã®ã¿ã‚’ç›®çš„ã¨ã—ã¦ãŠã‚Šã€å°‚é–€çš„ãªåŠ©è¨€(æ³•å¾‹ãƒ»ä¼šè¨ˆãƒ»æŠ€è¡“çš„ä¿è¨¼ãªã©)ã‚’æä¾›ã™ã‚‹ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŠã‚ˆã³ä»˜éšã™ã‚‹ã‚³ãƒ¼ãƒ‰ä¾‹ã¯ã€Œç¾çŠ¶æœ‰å§¿(AS IS)ã€ã§æä¾›ã•ã‚Œã€æ˜ç¤ºã¾ãŸã¯é»™ç¤ºã‚’å•ã‚ãšã€å•†å“æ€§ã€ç‰¹å®šç›®çš„é©åˆæ€§ã€æ¨©åˆ©éä¾µå®³ã€æ­£ç¢ºæ€§ãƒ»å®Œå…¨æ€§ã€å‹•ä½œãƒ»å®‰å…¨æ€§ç­‰ã„ã‹ãªã‚‹ä¿è¨¼ã‚‚ã—ã¾ã›ã‚“ã€‚</li>
            <li>å¤–éƒ¨ãƒªãƒ³ã‚¯ã€ç¬¬ä¸‰è€…ãŒæä¾›ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ»ãƒ„ãƒ¼ãƒ«ãƒ»ãƒ©ã‚¤ãƒ–ãƒ©ãƒªç­‰ã®å†…å®¹ãƒ»å¯ç”¨æ€§ãƒ»å®‰å…¨æ€§ã«ã¤ã„ã¦ã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯ä¸€åˆ‡ã®è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®åˆ©ç”¨ãƒ»å®Ÿè¡Œãƒ»è§£é‡ˆã«ã‚ˆã‚Šç›´æ¥çš„ãƒ»é–“æ¥çš„ãƒ»ä»˜éšçš„ãƒ»ç‰¹åˆ¥ãƒ»çµæœçš„ãƒ»æ‡²ç½°çš„æå®³ãŒç”Ÿã˜ãŸå ´åˆã§ã‚‚ã€é©ç”¨æ³•ã§è¨±å®¹ã•ã‚Œã‚‹æœ€å¤§é™ã®ç¯„å›²ã§ã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å†…å®¹ã¯ã€äºˆå‘Šãªãå¤‰æ›´ãƒ»æ›´æ–°ãƒ»æä¾›åœæ­¢ã•ã‚Œã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®è‘—ä½œæ¨©ãƒ»ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯æ˜è¨˜ã•ã‚ŒãŸæ¡ä»¶(ä¾‹: CC BY 4.0)ã«å¾“ã„ã¾ã™ã€‚å½“è©²ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯é€šå¸¸ã€ç„¡ä¿è¨¼æ¡é …ã‚’å«ã¿ã¾ã™ã€‚</li>
        </ul>
    </section>

<footer>
        <p><strong>ä½œæˆè€…</strong>: AI Terakoya Content Team</p>
        <p><strong>ãƒãƒ¼ã‚¸ãƒ§ãƒ³</strong>: 1.0 | <strong>ä½œæˆæ—¥</strong>: 2025-10-21</p>
        <p><strong>ãƒ©ã‚¤ã‚»ãƒ³ã‚¹</strong>: Creative Commons BY 4.0</p>
        <p>Â© 2025 AI Terakoya. All rights reserved.</p>
    </footer>
</body>
</html>
