<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ç¬¬1ç« ï¼šAutoMLåŸºç¤ - AI Terakoya</title>

    <style>
        :root {
            --color-primary: #2c3e50;
            --color-primary-dark: #1a252f;
            --color-accent: #7b2cbf;
            --color-accent-light: #9d4edd;
            --color-text: #2d3748;
            --color-text-light: #4a5568;
            --color-bg: #ffffff;
            --color-bg-alt: #f7fafc;
            --color-border: #e2e8f0;
            --color-code-bg: #f8f9fa;
            --color-link: #3182ce;
            --color-link-hover: #2c5aa0;

            --spacing-xs: 0.5rem;
            --spacing-sm: 1rem;
            --spacing-md: 1.5rem;
            --spacing-lg: 2rem;
            --spacing-xl: 3rem;

            --font-body: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            --font-mono: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;

            --border-radius: 8px;
            --box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: var(--font-body);
            line-height: 1.7;
            color: var(--color-text);
            background-color: var(--color-bg);
            font-size: 16px;
        }

        header {
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            padding: var(--spacing-xl) var(--spacing-md);
            margin-bottom: var(--spacing-xl);
            box-shadow: var(--box-shadow);
        }

        .header-content {
            max-width: 900px;
            margin: 0 auto;
        }

        h1 {
            font-size: 2rem;
            font-weight: 700;
            margin-bottom: var(--spacing-sm);
            line-height: 1.2;
        }

        .subtitle {
            font-size: 1.1rem;
            opacity: 0.95;
            font-weight: 400;
            margin-bottom: var(--spacing-md);
        }

        .meta {
            display: flex;
            flex-wrap: wrap;
            gap: var(--spacing-md);
            font-size: 0.9rem;
            opacity: 0.9;
        }

        .meta-item {
            display: flex;
            align-items: center;
            gap: 0.3rem;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 0 var(--spacing-md) var(--spacing-xl);
        }

        h2 {
            font-size: 1.75rem;
            color: var(--color-primary);
            margin-top: var(--spacing-xl);
            margin-bottom: var(--spacing-md);
            padding-bottom: var(--spacing-xs);
            border-bottom: 3px solid var(--color-accent);
        }

        h3 {
            font-size: 1.4rem;
            color: var(--color-primary);
            margin-top: var(--spacing-lg);
            margin-bottom: var(--spacing-sm);
        }

        h4 {
            font-size: 1.1rem;
            color: var(--color-primary-dark);
            margin-top: var(--spacing-md);
            margin-bottom: var(--spacing-sm);
        }

        p {
            margin-bottom: var(--spacing-md);
            color: var(--color-text);
        }

        a {
            color: var(--color-link);
            text-decoration: none;
            transition: color 0.2s;
        }

        a:hover {
            color: var(--color-link-hover);
            text-decoration: underline;
        }

        ul, ol {
            margin-left: var(--spacing-lg);
            margin-bottom: var(--spacing-md);
        }

        li {
            margin-bottom: var(--spacing-xs);
            color: var(--color-text);
        }

        pre {
            background-color: var(--color-code-bg);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            overflow-x: auto;
            margin-bottom: var(--spacing-md);
            font-family: var(--font-mono);
            font-size: 0.9rem;
            line-height: 1.5;
        }

        code {
            font-family: var(--font-mono);
            font-size: 0.9em;
            background-color: var(--color-code-bg);
            padding: 0.2em 0.4em;
            border-radius: 3px;
        }

        pre code {
            background-color: transparent;
            padding: 0;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: var(--spacing-md);
            font-size: 0.95rem;
        }

        th, td {
            border: 1px solid var(--color-border);
            padding: var(--spacing-sm);
            text-align: left;
        }

        th {
            background-color: var(--color-bg-alt);
            font-weight: 600;
            color: var(--color-primary);
        }

        blockquote {
            border-left: 4px solid var(--color-accent);
            padding-left: var(--spacing-md);
            margin: var(--spacing-md) 0;
            color: var(--color-text-light);
            font-style: italic;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        .mermaid {
            text-align: center;
            margin: var(--spacing-lg) 0;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        details {
            background-color: var(--color-bg-alt);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            margin-bottom: var(--spacing-md);
        }

        summary {
            cursor: pointer;
            font-weight: 600;
            color: var(--color-primary);
            user-select: none;
            padding: var(--spacing-xs);
            margin: calc(-1 * var(--spacing-md));
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        summary:hover {
            background-color: rgba(123, 44, 191, 0.1);
        }

        details[open] summary {
            margin-bottom: var(--spacing-md);
            border-bottom: 1px solid var(--color-border);
        }

        .navigation {
            display: flex;
            justify-content: space-between;
            gap: var(--spacing-md);
            margin: var(--spacing-xl) 0;
            padding-top: var(--spacing-lg);
            border-top: 2px solid var(--color-border);
        }

        .nav-button {
            flex: 1;
            padding: var(--spacing-md);
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            border-radius: var(--border-radius);
            text-align: center;
            font-weight: 600;
            transition: transform 0.2s, box-shadow 0.2s;
            box-shadow: var(--box-shadow);
        }

        .nav-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
            text-decoration: none;
        }

        footer {
            margin-top: var(--spacing-xl);
            padding: var(--spacing-lg) var(--spacing-md);
            background-color: var(--color-bg-alt);
            border-top: 1px solid var(--color-border);
            text-align: center;
            font-size: 0.9rem;
            color: var(--color-text-light);
        }
        .disclaimer {
            max-width: 900px;
            margin: 2rem auto;
            padding: 1.5rem;
            background: #f8f9fa;
            border-left: 4px solid #6c757d;
            border-radius: 4px;
        }

        .disclaimer h3 {
            color: #495057;
            margin-bottom: 1rem;
            font-size: 1.1rem;
        }

        .disclaimer ul {
            list-style: none;
            padding-left: 0;
        }

        .disclaimer li {
            padding: 0.5rem 0;
            padding-left: 1.5rem;
            position: relative;
            font-size: 0.9rem;
            color: #6c757d;
            line-height: 1.6;
        }

        .disclaimer li::before {
            content: "âš ï¸";
            position: absolute;
            left: 0;
        }


        @media (max-width: 768px) {
            h1 {
                font-size: 1.5rem;
            }

            h2 {
                font-size: 1.4rem;
            }

            h3 {
                font-size: 1.2rem;
            }

            .meta {
                font-size: 0.85rem;
            }

            .navigation {
                flex-direction: column;
            }

            table {
                font-size: 0.85rem;
            }

            th, td {
                padding: var(--spacing-xs);
            }
        }
    
        
    
        /* Breadcrumb styles */
        .breadcrumb {
            background: #f7fafc;
            padding: 0.75rem 1rem;
            border-bottom: 1px solid #e2e8f0;
            font-size: 0.9rem;
        }

        .breadcrumb-content {
            max-width: 900px;
            margin: 0 auto;
            display: flex;
            align-items: center;
            flex-wrap: wrap;
            gap: 0.5rem;
        }

        .breadcrumb a {
            color: #667eea;
            text-decoration: none;
            transition: color 0.2s;
        }

        .breadcrumb a:hover {
            color: #764ba2;
            text-decoration: underline;
        }

        .breadcrumb-separator {
            color: #a0aec0;
            margin: 0 0.25rem;
        }

        .breadcrumb-current {
            color: #4a5568;
            font-weight: 500;
        }
    </style>

    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
        mermaid.initialize({ startOnLoad: true, theme: 'default' });
    </script>

    <!-- MathJax for LaTeX equation rendering -->
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                displayMath: [['$$', '$$'], ['\\[', '\\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
                ignoreHtmlClass: 'mermaid'
            }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" async></script>
</head>
<body>
            <nav class="breadcrumb">
        <div class="breadcrumb-content">
            <a href="/AI-Knowledge-Notes/knowledge/jp/index.html">AIå¯ºå­å±‹ãƒˆãƒƒãƒ—</a><span class="breadcrumb-separator">â€º</span><a href="/AI-Knowledge-Notes/knowledge/jp/ML/index.html">æ©Ÿæ¢°å­¦ç¿’</a><span class="breadcrumb-separator">â€º</span><a href="/AI-Knowledge-Notes/knowledge/jp/ML/automl-introduction/index.html">Automl</a><span class="breadcrumb-separator">â€º</span><span class="breadcrumb-current">Chapter 1</span>
        </div>
    </nav>

        <header>
        <div class="header-content">
            <h1>ç¬¬1ç« ï¼šAutoMLåŸºç¤</h1>
            <p class="subtitle">æ©Ÿæ¢°å­¦ç¿’ã®æ°‘ä¸»åŒ– - AutoMLã®æ¦‚å¿µã¨æ§‹æˆè¦ç´ </p>
            <div class="meta">
                <span class="meta-item">ğŸ“– èª­äº†æ™‚é–“: 25-30åˆ†</span>
                <span class="meta-item">ğŸ“Š é›£æ˜“åº¦: åˆç´š</span>
                <span class="meta-item">ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹: 7å€‹</span>
                <span class="meta-item">ğŸ“ æ¼”ç¿’å•é¡Œ: 5å•</span>
            </div>
        </div>
    </header>

    <main class="container">

<h2>å­¦ç¿’ç›®æ¨™</h2>
<p>ã“ã®ç« ã‚’èª­ã‚€ã“ã¨ã§ã€ä»¥ä¸‹ã‚’ç¿’å¾—ã§ãã¾ã™ï¼š</p>
<ul>
<li>âœ… AutoMLã®æ¦‚å¿µã¨ç›®çš„ã‚’ç†è§£ã™ã‚‹</li>
<li>âœ… å¾“æ¥ã®MLãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã¨ã®é•ã„ã‚’èª¬æ˜ã§ãã‚‹</li>
<li>âœ… AutoMLã®æ§‹æˆè¦ç´ ã¨ãã®å½¹å‰²ã‚’æŠŠæ¡ã™ã‚‹</li>
<li>âœ… Neural Architecture Searchï¼ˆNASï¼‰ã®åŸºæœ¬ã‚’ç†è§£ã™ã‚‹</li>
<li>âœ… Meta-Learningã®æ¦‚å¿µã¨å¿œç”¨ã‚’å­¦ã¶</li>
<li>âœ… AutoMLã®è©•ä¾¡æ–¹æ³•ã‚’ç¿’å¾—ã™ã‚‹</li>
</ul>

<hr>

<h2>1.1 AutoMLã¨ã¯</h2>

<h3>æ©Ÿæ¢°å­¦ç¿’ã®æ°‘ä¸»åŒ–</h3>
<p><strong>AutoMLï¼ˆAutomated Machine Learningï¼‰</strong>ã¯ã€æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®é–‹ç™ºãƒ—ãƒ­ã‚»ã‚¹ã‚’è‡ªå‹•åŒ–ã™ã‚‹æŠ€è¡“ã§ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ãƒ†ã‚£ã‚¹ãƒˆã§ãªãã¦ã‚‚ã€é«˜å“è³ªãªæ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã—ã¦ã„ã¾ã™ã€‚</p>

<blockquote>
<p>ã€ŒAutoMLã¯æ©Ÿæ¢°å­¦ç¿’ã®æ°‘ä¸»åŒ–ã‚’å®Ÿç¾ã—ã€ã‚ˆã‚Šå¤šãã®äººã€…ãŒAIæŠ€è¡“ã‚’æ´»ç”¨ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹ã€</p>
</blockquote>

<h3>AutoMLã®ç›®çš„</h3>

<table>
<thead>
<tr>
<th>ç›®çš„</th>
<th>èª¬æ˜</th>
<th>åŠ¹æœ</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>åŠ¹ç‡åŒ–</strong></td>
<td>æ‰‹ä½œæ¥­ã®ãƒ—ãƒ­ã‚»ã‚¹ã‚’è‡ªå‹•åŒ–</td>
<td>é–‹ç™ºæ™‚é–“ã‚’çŸ­ç¸®</td>
</tr>
<tr>
<td><strong>å°‚é–€çŸ¥è­˜ã®è»½æ¸›</strong></td>
<td>æ©Ÿæ¢°å­¦ç¿’ã®æ·±ã„çŸ¥è­˜ãŒä¸è¦ã«</td>
<td>å‚å…¥éšœå£ã‚’ä¸‹ã’ã‚‹</td>
</tr>
<tr>
<td><strong>æ€§èƒ½å‘ä¸Š</strong></td>
<td>ä½“ç³»çš„ãªæ¢ç´¢ã§æœ€é©è§£ã‚’ç™ºè¦‹</td>
<td>äººé–“ã®ãƒã‚¤ã‚¢ã‚¹ã‚’æ’é™¤</td>
</tr>
<tr>
<td><strong>å†ç¾æ€§</strong></td>
<td>æ¨™æº–åŒ–ã•ã‚ŒãŸãƒ—ãƒ­ã‚»ã‚¹</td>
<td>çµæœã®ä¿¡é ¼æ€§å‘ä¸Š</td>
</tr>
</tbody>
</table>

<h3>å¾“æ¥ã®MLãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã¨ã®æ¯”è¼ƒ</h3>

<div class="mermaid">
graph TD
    subgraph "å¾“æ¥ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼"
    A1[ãƒ‡ãƒ¼ã‚¿åé›†] --> B1[æ‰‹å‹•å‰å‡¦ç†]
    B1 --> C1[ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°]
    C1 --> D1[ãƒ¢ãƒ‡ãƒ«é¸æŠ]
    D1 --> E1[ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´]
    E1 --> F1[è©•ä¾¡]
    F1 -->|è©¦è¡ŒéŒ¯èª¤| C1
    end

    subgraph "AutoMLãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼"
    A2[ãƒ‡ãƒ¼ã‚¿åé›†] --> B2[è‡ªå‹•å‰å‡¦ç†]
    B2 --> C2[è‡ªå‹•ç‰¹å¾´é‡ç”Ÿæˆ]
    C2 --> D2[è‡ªå‹•ãƒ¢ãƒ‡ãƒ«é¸æŠ]
    D2 --> E2[è‡ªå‹•ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–]
    E2 --> F2[è©•ä¾¡]
    end

    style A1 fill:#ffebee
    style A2 fill:#ffebee
    style B1 fill:#fff3e0
    style B2 fill:#e8f5e9
    style C1 fill:#f3e5f5
    style C2 fill:#e8f5e9
    style D1 fill:#e3f2fd
    style D2 fill:#e8f5e9
    style E1 fill:#fce4ec
    style E2 fill:#e8f5e9
</div>

<h3>AutoMLã®ãƒ¡ãƒªãƒƒãƒˆãƒ»ãƒ‡ãƒ¡ãƒªãƒƒãƒˆ</h3>

<h4>ãƒ¡ãƒªãƒƒãƒˆ</h4>
<ul>
<li><strong>æ™‚é–“çŸ­ç¸®</strong>: æ•°é€±é–“ã‹ã‹ã‚‹ä½œæ¥­ã‚’æ•°æ™‚é–“ã«çŸ­ç¸®</li>
<li><strong>ã‚¢ã‚¯ã‚»ã‚·ãƒ“ãƒªãƒ†ã‚£</strong>: å°‚é–€çŸ¥è­˜ãŒå°‘ãªã„äººã§ã‚‚åˆ©ç”¨å¯èƒ½</li>
<li><strong>æœ€é©åŒ–</strong>: äººé–“ãŒè¦‹è½ã¨ã™çµ„ã¿åˆã‚ã›ã‚’ç™ºè¦‹</li>
<li><strong>ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹</strong>: è‡ªå‹•çš„ã«é©ç”¨ã•ã‚Œã‚‹</li>
</ul>

<h4>ãƒ‡ãƒ¡ãƒªãƒƒãƒˆ</h4>
<ul>
<li><strong>è¨ˆç®—ã‚³ã‚¹ãƒˆ</strong>: å¤§è¦æ¨¡ãªæ¢ç´¢ã«ã¯å¤šãã®ãƒªã‚½ãƒ¼ã‚¹ãŒå¿…è¦</li>
<li><strong>ãƒ–ãƒ©ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹åŒ–</strong>: ãƒ—ãƒ­ã‚»ã‚¹ã®é€æ˜æ€§ãŒä½ä¸‹</li>
<li><strong>æŸ”è»Ÿæ€§ã®åˆ¶ç´„</strong>: ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºãŒå›°é›£ãªå ´åˆãŒã‚ã‚‹</li>
<li><strong>ãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜ã®è»½è¦–</strong>: ãƒ‡ãƒ¼ã‚¿ã®èƒŒæ™¯çŸ¥è­˜ãŒæ´»ã‹ã›ãªã„</li>
</ul>

<h3>å®Ÿä¾‹ï¼šAutoMLã®åŠ¹æœ</h3>

<pre><code class="language-python">import numpy as np
import pandas as pd
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
import time

# ãƒ‡ãƒ¼ã‚¿æº–å‚™
data = load_breast_cancer()
X, y = data.data, data.target
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# å¾“æ¥ã®æ‰‹æ³•ï¼ˆå›ºå®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼‰
start_time = time.time()
model_manual = RandomForestClassifier(n_estimators=100, random_state=42)
model_manual.fit(X_train, y_train)
y_pred_manual = model_manual.predict(X_test)
acc_manual = accuracy_score(y_test, y_pred_manual)
time_manual = time.time() - start_time

# AutoMLé¢¨ã®ç°¡æ˜“å®Ÿè£…ï¼ˆã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒï¼‰
from sklearn.model_selection import GridSearchCV

start_time = time.time()
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10]
}
model_auto = GridSearchCV(
    RandomForestClassifier(random_state=42),
    param_grid,
    cv=3,
    n_jobs=-1
)
model_auto.fit(X_train, y_train)
y_pred_auto = model_auto.predict(X_test)
acc_auto = accuracy_score(y_test, y_pred_auto)
time_auto = time.time() - start_time

print("=== å¾“æ¥æ‰‹æ³• vs AutoMLçš„æ‰‹æ³• ===")
print(f"\nå¾“æ¥æ‰‹æ³•:")
print(f"  ç²¾åº¦: {acc_manual:.4f}")
print(f"  æ™‚é–“: {time_manual:.2f}ç§’")

print(f"\nAutoMLçš„æ‰‹æ³•:")
print(f"  ç²¾åº¦: {acc_auto:.4f}")
print(f"  æ™‚é–“: {time_auto:.2f}ç§’")
print(f"  æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: {model_auto.best_params_}")

print(f"\næ”¹å–„:")
print(f"  ç²¾åº¦å‘ä¸Š: {(acc_auto - acc_manual) * 100:.2f}%")
</code></pre>

<p><strong>å‡ºåŠ›ä¾‹</strong>ï¼š</p>
<pre><code>=== å¾“æ¥æ‰‹æ³• vs AutoMLçš„æ‰‹æ³• ===

å¾“æ¥æ‰‹æ³•:
  ç²¾åº¦: 0.9649
  æ™‚é–“: 0.15ç§’

AutoMLçš„æ‰‹æ³•:
  ç²¾åº¦: 0.9737
  æ™‚é–“: 12.34ç§’
  æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: {'max_depth': 20, 'min_samples_split': 2, 'n_estimators': 100}

æ”¹å–„:
  ç²¾åº¦å‘ä¸Š: 0.88%
</code></pre>

<hr>

<h2>1.2 AutoMLã®æ§‹æˆè¦ç´ </h2>

<p>AutoMLã‚·ã‚¹ãƒ†ãƒ ã¯ã€æ©Ÿæ¢°å­¦ç¿’ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å…¨ä½“ã‚’è‡ªå‹•åŒ–ã™ã‚‹ãŸã‚ã«ã€è¤‡æ•°ã®æ§‹æˆè¦ç´ ã‹ã‚‰æˆã‚Šç«‹ã£ã¦ã„ã¾ã™ã€‚</p>

<h3>ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ã®è‡ªå‹•åŒ–</h3>

<p>ç”Ÿãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å­¦ç¿’å¯èƒ½ãªå½¢å¼ã¸ã®å¤‰æ›ã‚’è‡ªå‹•åŒ–ã—ã¾ã™ï¼š</p>

<ul>
<li><strong>æ¬ æå€¤å‡¦ç†</strong>: è‡ªå‹•æ¤œå‡ºã¨è£œå®Œæˆ¦ç•¥ã®é¸æŠ</li>
<li><strong>å¤–ã‚Œå€¤æ¤œå‡º</strong>: çµ±è¨ˆçš„æ‰‹æ³•ã‚„Isolation Forestã«ã‚ˆã‚‹æ¤œå‡º</li>
<li><strong>ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°</strong>: StandardScalerã€MinMaxScalerã®è‡ªå‹•é¸æŠ</li>
<li><strong>ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°</strong>: ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°ã®è‡ªå‹•å¤‰æ›</li>
</ul>

<pre><code class="language-python">import numpy as np
import pandas as pd
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.impute import SimpleImputer
from sklearn.pipeline import Pipeline

# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ï¼ˆæ¬ æå€¤ã‚’å«ã‚€ï¼‰
np.random.seed(42)
data = pd.DataFrame({
    'age': [25, 30, np.nan, 45, 50, 35],
    'salary': [50000, 60000, 55000, np.nan, 80000, 65000],
    'department': ['Sales', 'IT', 'HR', 'IT', 'Sales', np.nan]
})

print("=== å…ƒã®ãƒ‡ãƒ¼ã‚¿ ===")
print(data)

# è‡ªå‹•å‰å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
numeric_features = ['age', 'salary']
categorical_features = ['department']

numeric_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler())
])

categorical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('encoder', OneHotEncoder(handle_unknown='ignore'))
])

preprocessor = ColumnTransformer(
    transformers=[
        ('num', numeric_transformer, numeric_features),
        ('cat', categorical_transformer, categorical_features)
    ])

# å‰å‡¦ç†ã®å®Ÿè¡Œ
data_transformed = preprocessor.fit_transform(data)

print("\n=== å‰å‡¦ç†å¾Œã®ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶ ===")
print(f"å½¢çŠ¶: {data_transformed.shape}")
print(f"æ¬ æå€¤: 0ï¼ˆã™ã¹ã¦å‡¦ç†æ¸ˆã¿ï¼‰")
</code></pre>

<h3>ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°</h3>

<p>æ–°ã—ã„ç‰¹å¾´é‡ã‚’è‡ªå‹•ç”Ÿæˆã—ã¾ã™ï¼š</p>

<ul>
<li><strong>å¤šé …å¼ç‰¹å¾´é‡</strong>: æ—¢å­˜ç‰¹å¾´é‡ã®çµ„ã¿åˆã‚ã›</li>
<li><strong>é›†ç´„ç‰¹å¾´é‡</strong>: ã‚°ãƒ«ãƒ¼ãƒ—ã”ã¨ã®çµ±è¨ˆé‡</li>
<li><strong>æ™‚ç³»åˆ—ç‰¹å¾´é‡</strong>: ãƒ©ã‚°ã€ç§»å‹•å¹³å‡ã€å­£ç¯€æ€§</li>
<li><strong>ãƒ†ã‚­ã‚¹ãƒˆç‰¹å¾´é‡</strong>: TF-IDFã€åŸ‹ã‚è¾¼ã¿è¡¨ç¾</li>
</ul>

<pre><code class="language-python">from sklearn.preprocessing import PolynomialFeatures
from sklearn.datasets import make_regression
import matplotlib.pyplot as plt

# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿
X, y = make_regression(n_samples=100, n_features=2, noise=10, random_state=42)

# å¤šé …å¼ç‰¹å¾´é‡ã®ç”Ÿæˆ
poly = PolynomialFeatures(degree=2, include_bias=False)
X_poly = poly.fit_transform(X)

print("=== ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚° ===")
print(f"å…ƒã®ç‰¹å¾´é‡æ•°: {X.shape[1]}")
print(f"ç”Ÿæˆå¾Œã®ç‰¹å¾´é‡æ•°: {X_poly.shape[1]}")
print(f"\nç”Ÿæˆã•ã‚ŒãŸç‰¹å¾´é‡:")
print(poly.get_feature_names_out(['x1', 'x2']))

# æ€§èƒ½æ¯”è¼ƒ
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score

# å…ƒã®ç‰¹å¾´é‡
model_original = LinearRegression()
model_original.fit(X, y)
y_pred_original = model_original.predict(X)
r2_original = r2_score(y, y_pred_original)

# å¤šé …å¼ç‰¹å¾´é‡
model_poly = LinearRegression()
model_poly.fit(X_poly, y)
y_pred_poly = model_poly.predict(X_poly)
r2_poly = r2_score(y, y_pred_poly)

print(f"\n=== æ€§èƒ½æ¯”è¼ƒ ===")
print(f"å…ƒã®ç‰¹å¾´é‡ã®RÂ²: {r2_original:.4f}")
print(f"å¤šé …å¼ç‰¹å¾´é‡ã®RÂ²: {r2_poly:.4f}")
print(f"æ”¹å–„: {(r2_poly - r2_original) * 100:.2f}%")
</code></pre>

<h3>ãƒ¢ãƒ‡ãƒ«é¸æŠ</h3>

<p>ã‚¿ã‚¹ã‚¯ã¨ãƒ‡ãƒ¼ã‚¿ã«æœ€é©ãªã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’è‡ªå‹•é¸æŠã—ã¾ã™ï¼š</p>

<ul>
<li><strong>ç·šå½¢ãƒ¢ãƒ‡ãƒ«</strong>: Logistic Regression, Ridge, Lasso</li>
<li><strong>ãƒ„ãƒªãƒ¼ãƒ™ãƒ¼ã‚¹</strong>: Decision Tree, Random Forest, XGBoost</li>
<li><strong>ã‚µãƒãƒ¼ãƒˆãƒ™ã‚¯ã‚¿ãƒ¼ãƒã‚·ãƒ³</strong>: SVC, SVR</li>
<li><strong>ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯</strong>: MLP, CNN, RNN</li>
</ul>

<pre><code class="language-python">from sklearn.datasets import load_iris
from sklearn.model_selection import cross_val_score
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier

# ãƒ‡ãƒ¼ã‚¿æº–å‚™
iris = load_iris()
X, y = iris.data, iris.target

# è¤‡æ•°ã®ãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡
models = {
    'Logistic Regression': LogisticRegression(max_iter=1000),
    'Decision Tree': DecisionTreeClassifier(),
    'Random Forest': RandomForestClassifier(),
    'SVM': SVC(),
    'KNN': KNeighborsClassifier()
}

print("=== è‡ªå‹•ãƒ¢ãƒ‡ãƒ«é¸æŠ ===")
results = {}
for name, model in models.items():
    scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')
    results[name] = scores.mean()
    print(f"{name:20s}: {scores.mean():.4f} (+/- {scores.std():.4f})")

# æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ã®é¸æŠ
best_model = max(results, key=results.get)
print(f"\næœ€è‰¯ãƒ¢ãƒ‡ãƒ«: {best_model} (ç²¾åº¦: {results[best_model]:.4f})")
</code></pre>

<h3>ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–</h3>

<p>ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è‡ªå‹•èª¿æ•´ã—ã¾ã™ï¼š</p>

<ul>
<li><strong>ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒ</strong>: å…¨çµ„ã¿åˆã‚ã›ã‚’æ¢ç´¢</li>
<li><strong>ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ¼ãƒ</strong>: ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°</li>
<li><strong>ãƒ™ã‚¤ã‚ºæœ€é©åŒ–</strong>: åŠ¹ç‡çš„ãªæ¢ç´¢</li>
<li><strong>é€²åŒ–çš„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ </strong>: éºä¼çš„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ </li>
</ul>

<pre><code class="language-python">from sklearn.model_selection import RandomizedSearchCV
from scipy.stats import randint, uniform

# ãƒ‡ãƒ¼ã‚¿æº–å‚™
X, y = load_breast_cancer(return_X_y=True)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¢ç´¢ç©ºé–“
param_distributions = {
    'n_estimators': randint(50, 500),
    'max_depth': [None] + list(range(5, 50, 5)),
    'min_samples_split': randint(2, 20),
    'min_samples_leaf': randint(1, 10),
    'max_features': uniform(0.1, 0.9)
}

# ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ¼ãƒ
random_search = RandomizedSearchCV(
    RandomForestClassifier(random_state=42),
    param_distributions=param_distributions,
    n_iter=50,
    cv=3,
    random_state=42,
    n_jobs=-1,
    verbose=0
)

print("=== ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ– ===")
random_search.fit(X_train, y_train)

print(f"æœ€è‰¯ã‚¹ã‚³ã‚¢ (CV): {random_search.best_score_:.4f}")
print(f"æœ€è‰¯ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:")
for param, value in random_search.best_params_.items():
    print(f"  {param}: {value}")

# ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã§ã®è©•ä¾¡
test_score = random_search.score(X_test, y_test)
print(f"\nãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆç²¾åº¦: {test_score:.4f}")
</code></pre>

<h3>AutoMLãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å›³</h3>

<div class="mermaid">
graph TD
    A[ç”Ÿãƒ‡ãƒ¼ã‚¿] --> B[ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ã®è‡ªå‹•åŒ–]
    B --> C[ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°]
    C --> D[ãƒ¢ãƒ‡ãƒ«é¸æŠ]
    D --> E[ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–]
    E --> F[ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«]
    F --> G[æœ€çµ‚ãƒ¢ãƒ‡ãƒ«]

    B --> B1[æ¬ æå€¤å‡¦ç†]
    B --> B2[å¤–ã‚Œå€¤æ¤œå‡º]
    B --> B3[ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°]

    C --> C1[å¤šé …å¼ç‰¹å¾´é‡]
    C --> C2[é›†ç´„ç‰¹å¾´é‡]
    C --> C3[ç‰¹å¾´é¸æŠ]

    D --> D1[ç·šå½¢ãƒ¢ãƒ‡ãƒ«]
    D --> D2[ãƒ„ãƒªãƒ¼ãƒ™ãƒ¼ã‚¹]
    D --> D3[ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆ]

    E --> E1[ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒ]
    E --> E2[ãƒ™ã‚¤ã‚ºæœ€é©åŒ–]
    E --> E3[é€²åŒ–çš„æ‰‹æ³•]

    style A fill:#ffebee
    style B fill:#fff3e0
    style C fill:#f3e5f5
    style D fill:#e3f2fd
    style E fill:#fce4ec
    style F fill:#e8f5e9
    style G fill:#c8e6c9
</div>

<hr>

<h2>1.3 Neural Architecture Search (NAS)</h2>

<h3>NASã®æ¦‚å¿µ</h3>

<p><strong>Neural Architecture Searchï¼ˆNASï¼‰</strong>ã¯ã€ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’è‡ªå‹•çš„ã«è¨­è¨ˆã™ã‚‹æŠ€è¡“ã§ã™ã€‚äººé–“ãŒæ‰‹ä½œæ¥­ã§è¨­è¨ˆã—ã¦ã„ãŸãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ§‹é€ ã‚’ã€ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ãŒè‡ªå‹•çš„ã«æ¢ç´¢ã—ã¾ã™ã€‚</p>

<blockquote>
<p>NASã¯ã€Œãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’è¨­è¨ˆã™ã‚‹ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã€ã¨ã‚‚è¨€ãˆã¾ã™</p>
</blockquote>

<h3>æ¢ç´¢ç©ºé–“</h3>

<p>NASãŒæ¢ç´¢ã™ã‚‹è¨­è¨ˆè¦ç´ ï¼š</p>

<ul>
<li><strong>å±¤ã®ç¨®é¡</strong>: ç•³ã¿è¾¼ã¿å±¤ã€å…¨çµåˆå±¤ã€ãƒ—ãƒ¼ãƒªãƒ³ã‚°å±¤ãªã©</li>
<li><strong>å±¤ã®æ•°</strong>: ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®æ·±ã•</li>
<li><strong>å±¤ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿</strong>: ãƒ•ã‚£ãƒ«ã‚¿æ•°ã€ã‚«ãƒ¼ãƒãƒ«ã‚µã‚¤ã‚ºã€ã‚¹ãƒˆãƒ©ã‚¤ãƒ‰ãªã©</li>
<li><strong>æ¥ç¶šãƒ‘ã‚¿ãƒ¼ãƒ³</strong>: ã‚¹ã‚­ãƒƒãƒ—æ¥ç¶šã€æ®‹å·®æ¥ç¶šãªã©</li>
<li><strong>æ´»æ€§åŒ–é–¢æ•°</strong>: ReLUã€Sigmoidã€Tanhãªã©</li>
</ul>

<h3>æ¢ç´¢æˆ¦ç•¥</h3>

<h4>1. ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ¼ãƒ</h4>
<p>ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ã¦è©•ä¾¡ã—ã¾ã™ã€‚ã‚·ãƒ³ãƒ—ãƒ«ã§ã™ãŒã€åŠ¹ç‡ã¯ä½ã„ã§ã™ã€‚</p>

<h4>2. å¼·åŒ–å­¦ç¿’ãƒ™ãƒ¼ã‚¹</h4>
<p>ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©ï¼ˆRNNï¼‰ãŒã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’ç”Ÿæˆã—ã€ãã®æ€§èƒ½ã‚’å ±é…¬ã¨ã—ã¦å­¦ç¿’ã—ã¾ã™ã€‚</p>

<p>å ±é…¬é–¢æ•°ï¼š</p>
<p>$$
R = \text{Accuracy} - \lambda \cdot \text{Complexity}
$$</p>

<ul>
<li>$\text{Accuracy}$: æ¤œè¨¼ç²¾åº¦</li>
<li>$\text{Complexity}$: ãƒ¢ãƒ‡ãƒ«ã®è¤‡é›‘ã•ï¼ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ãªã©ï¼‰</li>
<li>$\lambda$: è¤‡é›‘ã•ã®ãƒšãƒŠãƒ«ãƒ†ã‚£ä¿‚æ•°</li>
</ul>

<h4>3. é€²åŒ–çš„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ </h4>
<p>éºä¼çš„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ç”¨ã„ã¦ã€å„ªã‚ŒãŸã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’é€²åŒ–ã•ã›ã¾ã™ã€‚</p>

<ul>
<li><strong>çªç„¶å¤‰ç•°</strong>: å±¤ã®è¿½åŠ ãƒ»å‰Šé™¤ã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å¤‰æ›´</li>
<li><strong>äº¤å‰</strong>: 2ã¤ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®çµ„ã¿åˆã‚ã›</li>
<li><strong>é¸æŠ</strong>: æ€§èƒ½ã®é«˜ã„ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’æ®‹ã™</li>
</ul>

<h4>4. å‹¾é…ãƒ™ãƒ¼ã‚¹æ‰‹æ³•ï¼ˆDARTSï¼‰</h4>
<p>æ¢ç´¢ç©ºé–“ã‚’é€£ç¶šç·©å’Œã—ã€å‹¾é…é™ä¸‹æ³•ã§æœ€é©åŒ–ã—ã¾ã™ã€‚è¨ˆç®—åŠ¹ç‡ãŒé«˜ã„ã§ã™ã€‚</p>

<h3>NASå®Ÿè£…ä¾‹ï¼ˆç°¡æ˜“ç‰ˆï¼‰</h3>

<pre><code class="language-python">import numpy as np
from sklearn.datasets import load_digits
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.neural_network import MLPClassifier

# ãƒ‡ãƒ¼ã‚¿æº–å‚™
digits = load_digits()
X_train, X_test, y_train, y_test = train_test_split(
    digits.data, digits.target, test_size=0.2, random_state=42
)

# ç°¡æ˜“NAS: ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ¼ãƒã§ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’æ¢ç´¢
def random_architecture_search(n_trials=10):
    best_score = 0
    best_architecture = None

    print("=== Neural Architecture Search ===")
    for i in range(n_trials):
        # ãƒ©ãƒ³ãƒ€ãƒ ã«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’ç”Ÿæˆ
        n_layers = np.random.randint(1, 4)  # 1-3å±¤
        hidden_layer_sizes = tuple(
            np.random.choice([32, 64, 128, 256]) for _ in range(n_layers)
        )
        activation = np.random.choice(['relu', 'tanh', 'logistic'])

        # ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ã¨è©•ä¾¡
        model = MLPClassifier(
            hidden_layer_sizes=hidden_layer_sizes,
            activation=activation,
            max_iter=100,
            random_state=42
        )
        model.fit(X_train, y_train)
        score = model.score(X_test, y_test)

        print(f"Trial {i+1}: layers={hidden_layer_sizes}, "
              f"activation={activation}, score={score:.4f}")

        if score > best_score:
            best_score = score
            best_architecture = {
                'hidden_layer_sizes': hidden_layer_sizes,
                'activation': activation,
                'score': score
            }

    return best_architecture

# NASã®å®Ÿè¡Œ
best_arch = random_architecture_search(n_trials=10)

print(f"\n=== æœ€è‰¯ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ ===")
print(f"å±¤æ§‹æˆ: {best_arch['hidden_layer_sizes']}")
print(f"æ´»æ€§åŒ–é–¢æ•°: {best_arch['activation']}")
print(f"ç²¾åº¦: {best_arch['score']:.4f}")
</code></pre>

<h3>NASã®èª²é¡Œ</h3>

<table>
<thead>
<tr>
<th>èª²é¡Œ</th>
<th>èª¬æ˜</th>
<th>å¯¾ç­–</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>è¨ˆç®—ã‚³ã‚¹ãƒˆ</strong></td>
<td>æ•°åƒã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’è©•ä¾¡</td>
<td>æ—©æœŸåœæ­¢ã€ãƒ—ãƒ­ã‚­ã‚·ã‚¿ã‚¹ã‚¯ä½¿ç”¨</td>
</tr>
<tr>
<td><strong>æ¢ç´¢ç©ºé–“ã®åºƒã•</strong></td>
<td>çµ„ã¿åˆã‚ã›çˆ†ç™º</td>
<td>æ¢ç´¢ç©ºé–“ã®åˆ¶ç´„ã€éšå±¤çš„æ¢ç´¢</td>
</tr>
<tr>
<td><strong>è»¢ç§»æ€§ã®æ¬ å¦‚</strong></td>
<td>ã‚¿ã‚¹ã‚¯ã”ã¨ã«æ¢ç´¢ãŒå¿…è¦</td>
<td>è»¢ç§»å­¦ç¿’ã€ãƒ¡ã‚¿ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°æ´»ç”¨</td>
</tr>
<tr>
<td><strong>éå­¦ç¿’</strong></td>
<td>æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã¸ã®éé©åˆ</td>
<td>æ­£å‰‡åŒ–ã€è¤‡æ•°ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½¿ç”¨</td>
</tr>
</tbody>
</table>

<hr>

<h2>1.4 Meta-Learning</h2>

<h3>Learning to Learn</h3>

<p><strong>Meta-Learningï¼ˆãƒ¡ã‚¿å­¦ç¿’ï¼‰</strong>ã¯ã€ã€Œå­¦ç¿’ã®ä»•æ–¹ã‚’å­¦ç¿’ã™ã‚‹ã€æ‰‹æ³•ã§ã™ã€‚éå»ã®ã‚¿ã‚¹ã‚¯ã§ã®çµŒé¨“ã‚’æ´»ç”¨ã—ã¦ã€æ–°ã—ã„ã‚¿ã‚¹ã‚¯ã‚’åŠ¹ç‡çš„ã«å­¦ç¿’ã—ã¾ã™ã€‚</p>

<blockquote>
<p>ã€Œå­¦ç¿’ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ è‡ªä½“ã‚’å­¦ç¿’ã™ã‚‹ã€- ãƒ¡ã‚¿å­¦ç¿’ã®æœ¬è³ª</p>
</blockquote>

<h3>Few-shot Learning</h3>

<p>å°‘æ•°ã®ã‚µãƒ³ãƒ—ãƒ«ã‹ã‚‰åŠ¹ç‡çš„ã«å­¦ç¿’ã™ã‚‹æ‰‹æ³•ã§ã™ã€‚</p>

<p><strong>N-way K-shotå­¦ç¿’</strong>ï¼š</p>
<ul>
<li>N: ã‚¯ãƒ©ã‚¹æ•°</li>
<li>K: å„ã‚¯ãƒ©ã‚¹ã®ã‚µãƒ³ãƒ—ãƒ«æ•°</li>
<li>ä¾‹: 5-way 1-shot = 5ã‚¯ãƒ©ã‚¹ã€å„1ã‚µãƒ³ãƒ—ãƒ«</li>
</ul>

<pre><code class="language-python">import numpy as np
from sklearn.neighbors import KNeighborsClassifier
from sklearn.datasets import load_digits
from sklearn.model_selection import train_test_split

# Few-shotå­¦ç¿’ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
def few_shot_learning_demo(n_way=5, k_shot=3):
    # ãƒ‡ãƒ¼ã‚¿æº–å‚™
    digits = load_digits()
    X, y = digits.data, digits.target

    # ã‚¿ã‚¹ã‚¯ã®é¸æŠï¼ˆn_wayã‚¯ãƒ©ã‚¹ï¼‰
    selected_classes = np.random.choice(10, n_way, replace=False)

    # ã‚µãƒãƒ¼ãƒˆã‚»ãƒƒãƒˆï¼ˆå­¦ç¿’ç”¨: k_shot Ã— n_way ã‚µãƒ³ãƒ—ãƒ«ï¼‰
    support_X, support_y = [], []
    # ã‚¯ã‚¨ãƒªã‚»ãƒƒãƒˆï¼ˆãƒ†ã‚¹ãƒˆç”¨ï¼‰
    query_X, query_y = [], []

    for cls in selected_classes:
        cls_indices = np.where(y == cls)[0]
        selected = np.random.choice(cls_indices, k_shot + 10, replace=False)

        # k_shotã‚µãƒ³ãƒ—ãƒ«ã‚’ã‚µãƒãƒ¼ãƒˆã‚»ãƒƒãƒˆã«
        support_X.extend(X[selected[:k_shot]])
        support_y.extend([cls] * k_shot)

        # æ®‹ã‚Šã‚’ã‚¯ã‚¨ãƒªã‚»ãƒƒãƒˆã«
        query_X.extend(X[selected[k_shot:]])
        query_y.extend([cls] * 10)

    support_X = np.array(support_X)
    support_y = np.array(support_y)
    query_X = np.array(query_X)
    query_y = np.array(query_y)

    # Few-shotå­¦ç¿’ï¼ˆKNNä½¿ç”¨ï¼‰
    model = KNeighborsClassifier(n_neighbors=min(3, k_shot))
    model.fit(support_X, support_y)

    # è©•ä¾¡
    accuracy = model.score(query_X, query_y)

    print(f"=== {n_way}-way {k_shot}-shotå­¦ç¿’ ===")
    print(f"ã‚µãƒãƒ¼ãƒˆã‚»ãƒƒãƒˆ: {len(support_X)}ã‚µãƒ³ãƒ—ãƒ«")
    print(f"ã‚¯ã‚¨ãƒªã‚»ãƒƒãƒˆ: {len(query_X)}ã‚µãƒ³ãƒ—ãƒ«")
    print(f"ç²¾åº¦: {accuracy:.4f}")

    return accuracy

# ç•°ãªã‚‹è¨­å®šã§å®Ÿé¨“
for k in [1, 3, 5]:
    few_shot_learning_demo(n_way=5, k_shot=k)
    print()
</code></pre>

<h3>Transfer Learning</h3>

<p>ã‚ã‚‹ ã‚¿ã‚¹ã‚¯ã§å­¦ç¿’ã—ãŸçŸ¥è­˜ã‚’åˆ¥ã®ã‚¿ã‚¹ã‚¯ã«è»¢ç§»ã•ã›ã¾ã™ã€‚</p>

<ul>
<li><strong>äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«</strong>: ImageNetç­‰ã§å­¦ç¿’ã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’åˆ©ç”¨</li>
<li><strong>ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°</strong>: æ–°ã—ã„ã‚¿ã‚¹ã‚¯ã§èª¿æ•´</li>
<li><strong>ãƒ‰ãƒ¡ã‚¤ãƒ³é©å¿œ</strong>: ãƒ‰ãƒ¡ã‚¤ãƒ³é–“ã®å·®ã‚’ç¸®å°</li>
</ul>

<h3>Warm-starting</h3>

<p>éå»ã®ã‚¿ã‚¹ã‚¯ã§ã®æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’åˆæœŸå€¤ã¨ã—ã¦ä½¿ç”¨ã—ã€æ–°ã—ã„ã‚¿ã‚¹ã‚¯ã®å­¦ç¿’ã‚’é«˜é€ŸåŒ–ã—ã¾ã™ã€‚</p>

<pre><code class="language-python">from sklearn.linear_model import SGDClassifier
from sklearn.datasets import make_classification

# ã‚¿ã‚¹ã‚¯1ã¨ã‚¿ã‚¹ã‚¯2ï¼ˆé¡ä¼¼ã—ãŸã‚¿ã‚¹ã‚¯ï¼‰
X1, y1 = make_classification(n_samples=1000, n_features=20,
                             n_informative=15, random_state=42)
X2, y2 = make_classification(n_samples=1000, n_features=20,
                             n_informative=15, random_state=43)

print("=== Warm-startingåŠ¹æœã®æ¤œè¨¼ ===")

# ã‚³ãƒ¼ãƒ«ãƒ‰ã‚¹ã‚¿ãƒ¼ãƒˆï¼ˆã‚¿ã‚¹ã‚¯2ã‚’æœ€åˆã‹ã‚‰å­¦ç¿’ï¼‰
model_cold = SGDClassifier(max_iter=100, random_state=42)
model_cold.fit(X2[:100], y2[:100])  # å°‘ãªã„ãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’
score_cold = model_cold.score(X2[100:], y2[100:])

# ã‚¦ã‚©ãƒ¼ãƒ ã‚¹ã‚¿ãƒ¼ãƒˆï¼ˆã‚¿ã‚¹ã‚¯1ã§äº‹å‰å­¦ç¿’ï¼‰
model_warm = SGDClassifier(max_iter=100, random_state=42)
model_warm.fit(X1, y1)  # ã‚¿ã‚¹ã‚¯1ã§å­¦ç¿’
model_warm.partial_fit(X2[:100], y2[:100])  # ã‚¿ã‚¹ã‚¯2ã§è¿½åŠ å­¦ç¿’
score_warm = model_warm.score(X2[100:], y2[100:])

print(f"ã‚³ãƒ¼ãƒ«ãƒ‰ã‚¹ã‚¿ãƒ¼ãƒˆç²¾åº¦: {score_cold:.4f}")
print(f"ã‚¦ã‚©ãƒ¼ãƒ ã‚¹ã‚¿ãƒ¼ãƒˆç²¾åº¦: {score_warm:.4f}")
print(f"æ”¹å–„: {(score_warm - score_cold) * 100:.2f}%")
</code></pre>

<hr>

<h2>1.5 AutoMLã®è©•ä¾¡</h2>

<h3>Performance Metrics</h3>

<p>AutoMLã‚·ã‚¹ãƒ†ãƒ ã®æ€§èƒ½ã‚’è©•ä¾¡ã™ã‚‹æŒ‡æ¨™ï¼š</p>

<table>
<thead>
<tr>
<th>æŒ‡æ¨™</th>
<th>èª¬æ˜</th>
<th>é‡è¦æ€§</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>äºˆæ¸¬ç²¾åº¦</strong></td>
<td>ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬æ€§èƒ½</td>
<td>æœ€ã‚‚é‡è¦</td>
</tr>
<tr>
<td><strong>æ¢ç´¢æ™‚é–“</strong></td>
<td>æœ€é©ãƒ¢ãƒ‡ãƒ«ã‚’è¦‹ã¤ã‘ã‚‹ã¾ã§ã®æ™‚é–“</td>
<td>å®Ÿç”¨ä¸Šé‡è¦</td>
</tr>
<tr>
<td><strong>è¨ˆç®—ã‚³ã‚¹ãƒˆ</strong></td>
<td>å¿…è¦ãªãƒªã‚½ãƒ¼ã‚¹ï¼ˆCPUã€GPUã€ãƒ¡ãƒ¢ãƒªï¼‰</td>
<td>ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£</td>
</tr>
<tr>
<td><strong>ãƒ­ãƒã‚¹ãƒˆæ€§</strong></td>
<td>ç•°ãªã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã®å®‰å®šæ€§</td>
<td>æ±ç”¨æ€§</td>
</tr>
</tbody>
</table>

<h3>è¨ˆç®—ã‚³ã‚¹ãƒˆ</h3>

<p>AutoMLã®è¨ˆç®—ã‚³ã‚¹ãƒˆã‚’å®šé‡åŒ–ï¼š</p>

<p>$$
\text{Total Cost} = \sum_{i=1}^{n} C_i \times T_i
$$</p>

<ul>
<li>$C_i$: iç•ªç›®ã®ãƒ¢ãƒ‡ãƒ«ã®è¨ˆç®—ã‚³ã‚¹ãƒˆï¼ˆFLOPSç­‰ï¼‰</li>
<li>$T_i$: iç•ªç›®ã®ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´æ™‚é–“</li>
<li>$n$: è©•ä¾¡ã—ãŸãƒ¢ãƒ‡ãƒ«ã®ç·æ•°</li>
</ul>

<h3>å†ç¾æ€§</h3>

<p>åŒã˜å…¥åŠ›ã§åŒã˜çµæœãŒå¾—ã‚‰ã‚Œã‚‹ã‹ï¼š</p>

<ul>
<li><strong>ä¹±æ•°ã‚·ãƒ¼ãƒ‰å›ºå®š</strong>: å†ç¾å¯èƒ½ãªå®Ÿé¨“</li>
<li><strong>ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®ä¿å­˜</strong>: å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã¨å‰å‡¦ç†ã®ä¿å­˜</li>
<li><strong>ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†</strong>: ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®è¨˜éŒ²</li>
</ul>

<h3>è§£é‡ˆå¯èƒ½æ€§</h3>

<p>AutoMLã®æ±ºå®šãƒ—ãƒ­ã‚»ã‚¹ã‚’ç†è§£ã™ã‚‹ï¼š</p>

<ul>
<li><strong>ç‰¹å¾´é‡é‡è¦åº¦</strong>: ã©ã®ç‰¹å¾´é‡ãŒé‡è¦ã‹</li>
<li><strong>ãƒ¢ãƒ‡ãƒ«é¸æŠç†ç”±</strong>: ãªãœãã®ãƒ¢ãƒ‡ãƒ«ãŒé¸ã°ã‚ŒãŸã‹</li>
<li><strong>ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å½±éŸ¿</strong>: å„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å¯„ä¸åº¦</li>
</ul>

<pre><code class="language-python">from sklearn.ensemble import RandomForestClassifier
from sklearn.inspection import permutation_importance
import matplotlib.pyplot as plt

# ãƒ‡ãƒ¼ã‚¿æº–å‚™
iris = load_iris()
X, y = iris.data, iris.target
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# ãƒ¢ãƒ‡ãƒ«è¨“ç·´
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# ç‰¹å¾´é‡é‡è¦åº¦
feature_importance = model.feature_importances_
feature_names = iris.feature_names

# Permutation Importance
perm_importance = permutation_importance(
    model, X_test, y_test, n_repeats=10, random_state=42
)

# å¯è¦–åŒ–
fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# ç‰¹å¾´é‡é‡è¦åº¦
axes[0].barh(feature_names, feature_importance)
axes[0].set_xlabel('é‡è¦åº¦')
axes[0].set_title('ç‰¹å¾´é‡é‡è¦åº¦ï¼ˆGiniï¼‰')
axes[0].grid(True, alpha=0.3)

# Permutation Importance
axes[1].barh(feature_names, perm_importance.importances_mean)
axes[1].set_xlabel('é‡è¦åº¦')
axes[1].set_title('Permutation Importance')
axes[1].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

print("=== è§£é‡ˆå¯èƒ½æ€§åˆ†æ ===")
for name, importance in zip(feature_names, feature_importance):
    print(f"{name:20s}: {importance:.4f}")
</code></pre>

<hr>

<h2>1.6 æœ¬ç« ã®ã¾ã¨ã‚</h2>

<h3>å­¦ã‚“ã ã“ã¨</h3>

<ol>
<li><p><strong>AutoMLã®æ¦‚å¿µ</strong></p>
<ul>
<li>æ©Ÿæ¢°å­¦ç¿’ã®æ°‘ä¸»åŒ–ã‚’å®Ÿç¾</li>
<li>åŠ¹ç‡åŒ–ã¨å°‚é–€çŸ¥è­˜ã®è»½æ¸›</li>
<li>å¾“æ¥æ‰‹æ³•ã¨ã®é•ã„ã¨åˆ©ç‚¹</li>
</ul></li>

<li><p><strong>AutoMLã®æ§‹æˆè¦ç´ </strong></p>
<ul>
<li>ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ã®è‡ªå‹•åŒ–</li>
<li>ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°</li>
<li>ãƒ¢ãƒ‡ãƒ«é¸æŠã¨ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–</li>
</ul></li>

<li><p><strong>Neural Architecture Search</strong></p>
<ul>
<li>ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ§‹é€ ã®è‡ªå‹•è¨­è¨ˆ</li>
<li>æ¢ç´¢æˆ¦ç•¥ï¼ˆRLã€é€²åŒ–çš„ã€å‹¾é…ãƒ™ãƒ¼ã‚¹ï¼‰</li>
<li>è¨ˆç®—ã‚³ã‚¹ãƒˆã¨ã®æˆ¦ã„</li>
</ul></li>

<li><p><strong>Meta-Learning</strong></p>
<ul>
<li>å­¦ç¿’ã®ä»•æ–¹ã‚’å­¦ç¿’</li>
<li>Few-shot learningã€Transfer learning</li>
<li>Warm-startingã«ã‚ˆã‚‹é«˜é€ŸåŒ–</li>
</ul></li>

<li><p><strong>AutoMLã®è©•ä¾¡</strong></p>
<ul>
<li>æ€§èƒ½æŒ‡æ¨™ï¼ˆç²¾åº¦ã€æ™‚é–“ã€ã‚³ã‚¹ãƒˆï¼‰</li>
<li>å†ç¾æ€§ã¨è§£é‡ˆå¯èƒ½æ€§ã®é‡è¦æ€§</li>
</ul></li>
</ol>

<h3>AutoMLã®åŸå‰‡</h3>

<table>
<thead>
<tr>
<th>åŸå‰‡</th>
<th>èª¬æ˜</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>è‡ªå‹•åŒ–ã¨é€æ˜æ€§ã®ãƒãƒ©ãƒ³ã‚¹</strong></td>
<td>ãƒ–ãƒ©ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹åŒ–ã‚’é¿ã‘ã€è§£é‡ˆå¯èƒ½æ€§ã‚’ç¶­æŒ</td>
</tr>
<tr>
<td><strong>åŠ¹ç‡æ€§</strong></td>
<td>è¨ˆç®—ãƒªã‚½ãƒ¼ã‚¹ã‚’è€ƒæ…®ã—ãŸæ¢ç´¢æˆ¦ç•¥</td>
</tr>
<tr>
<td><strong>æ±ç”¨æ€§</strong></td>
<td>æ§˜ã€…ãªã‚¿ã‚¹ã‚¯ã¨ãƒ‡ãƒ¼ã‚¿ã«é©ç”¨å¯èƒ½</td>
</tr>
<tr>
<td><strong>ãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜ã®æ´»ç”¨</strong></td>
<td>è‡ªå‹•åŒ–ã¨å°‚é–€çŸ¥è­˜ã®çµ„ã¿åˆã‚ã›</td>
</tr>
<tr>
<td><strong>ç¶™ç¶šçš„æ”¹å–„</strong></td>
<td>ãƒ¡ã‚¿å­¦ç¿’ã«ã‚ˆã‚‹å­¦ç¿’åŠ¹ç‡ã®å‘ä¸Š</td>
</tr>
</tbody>
</table>

<h3>æ¬¡ã®ç« ã¸</h3>

<p>ç¬¬2ç« ã§ã¯ã€<strong>AutoMLãƒ„ãƒ¼ãƒ«ã¨ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯</strong>ã‚’å­¦ã³ã¾ã™ï¼š</p>
<ul>
<li>Auto-sklearn</li>
<li>TPOT</li>
<li>H2O AutoML</li>
<li>Google Cloud AutoML</li>
<li>AutoKeras</li>
</ul>

<hr>

<h2>æ¼”ç¿’å•é¡Œ</h2>

<h3>å•é¡Œ1ï¼ˆé›£æ˜“åº¦ï¼šeasyï¼‰</h3>
<p>AutoMLã®ä¸»ãªç›®çš„ã‚’3ã¤æŒ™ã’ã€ãã‚Œãã‚Œã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚</p>

<details>
<summary>è§£ç­”ä¾‹</summary>

<p><strong>è§£ç­”</strong>ï¼š</p>

<ol>
<li><p><strong>åŠ¹ç‡åŒ–</strong></p>
<ul>
<li>èª¬æ˜: æ‰‹ä½œæ¥­ã§è¡Œã£ã¦ã„ãŸãƒ¢ãƒ‡ãƒ«é–‹ç™ºãƒ—ãƒ­ã‚»ã‚¹ã‚’è‡ªå‹•åŒ–ã—ã€é–‹ç™ºæ™‚é–“ã‚’å¤§å¹…ã«çŸ­ç¸®ã™ã‚‹</li>
<li>åŠ¹æœ: æ•°é€±é–“ã‹ã‹ã‚‹ä½œæ¥­ã‚’æ•°æ™‚é–“ã«çŸ­ç¸®å¯èƒ½</li>
</ul></li>

<li><p><strong>å°‚é–€çŸ¥è­˜ã®è»½æ¸›</strong></p>
<ul>
<li>èª¬æ˜: æ©Ÿæ¢°å­¦ç¿’ã®æ·±ã„å°‚é–€çŸ¥è­˜ãŒãªãã¦ã‚‚ã€é«˜å“è³ªãªãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹</li>
<li>åŠ¹æœ: ã‚ˆã‚Šå¤šãã®äººã€…ãŒAIæŠ€è¡“ã‚’æ´»ç”¨å¯èƒ½ã«ãªã‚‹ï¼ˆæ°‘ä¸»åŒ–ï¼‰</li>
</ul></li>

<li><p><strong>æ€§èƒ½å‘ä¸Š</strong></p>
<ul>
<li>èª¬æ˜: ä½“ç³»çš„ãªæ¢ç´¢ã«ã‚ˆã‚Šã€äººé–“ãŒè¦‹è½ã¨ã—ãŒã¡ãªæœ€é©ãªçµ„ã¿åˆã‚ã›ã‚’ç™ºè¦‹ã™ã‚‹</li>
<li>åŠ¹æœ: äººé–“ã®ãƒã‚¤ã‚¢ã‚¹ã‚’æ’é™¤ã—ã€å®¢è¦³çš„ã«æœ€è‰¯ã®ãƒ¢ãƒ‡ãƒ«ã‚’è¦‹ã¤ã‘ã‚‹</li>
</ul></li>
</ol>

</details>

<h3>å•é¡Œ2ï¼ˆé›£æ˜“åº¦ï¼šmediumï¼‰</h3>
<p>Neural Architecture Searchï¼ˆNASï¼‰ã®4ã¤ã®æ¢ç´¢æˆ¦ç•¥ã‚’èª¬æ˜ã—ã€ãã‚Œãã‚Œã®é•·æ‰€ã¨çŸ­æ‰€ã‚’è¿°ã¹ã¦ãã ã•ã„ã€‚</p>

<details>
<summary>è§£ç­”ä¾‹</summary>

<p><strong>è§£ç­”</strong>ï¼š</p>

<table>
<thead>
<tr>
<th>æ¢ç´¢æˆ¦ç•¥</th>
<th>èª¬æ˜</th>
<th>é•·æ‰€</th>
<th>çŸ­æ‰€</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ¼ãƒ</strong></td>
<td>ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°</td>
<td>å®Ÿè£…ãŒç°¡å˜ã€ä¸¦åˆ—åŒ–ãŒå®¹æ˜“</td>
<td>åŠ¹ç‡ãŒä½ã„ã€å¤§è¦æ¨¡æ¢ç´¢ã«ä¸å‘ã</td>
</tr>
<tr>
<td><strong>å¼·åŒ–å­¦ç¿’ãƒ™ãƒ¼ã‚¹</strong></td>
<td>RNNã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©ãŒã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’ç”Ÿæˆ</td>
<td>æœ‰æœ›ãªé ˜åŸŸã‚’åŠ¹ç‡çš„ã«æ¢ç´¢</td>
<td>è¨ˆç®—ã‚³ã‚¹ãƒˆãŒé«˜ã„ã€å®‰å®šæ€§ã«èª²é¡Œ</td>
</tr>
<tr>
<td><strong>é€²åŒ–çš„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ </strong></td>
<td>éºä¼çš„æ“ä½œã§å„ªã‚ŒãŸã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’é€²åŒ–</td>
<td>å¤šæ§˜æ€§ã‚’ä¿æŒã€å±€æ‰€æœ€é©ã‚’å›é¿</td>
<td>åæŸãŒé…ã„ã€å¤§è¦æ¨¡ãªé›†å›£ãŒå¿…è¦</td>
</tr>
<tr>
<td><strong>å‹¾é…ãƒ™ãƒ¼ã‚¹ï¼ˆDARTSï¼‰</strong></td>
<td>æ¢ç´¢ç©ºé–“ã‚’é€£ç¶šç·©å’Œã—å‹¾é…é™ä¸‹æ³•ã§æœ€é©åŒ–</td>
<td>è¨ˆç®—åŠ¹ç‡ãŒé«˜ã„ã€é«˜é€Ÿ</td>
<td>é›¢æ•£åŒ–èª¤å·®ã€æ¢ç´¢ç©ºé–“ã«åˆ¶ç´„</td>
</tr>
</tbody>
</table>

</details>

<h3>å•é¡Œ3ï¼ˆé›£æ˜“åº¦ï¼šmediumï¼‰</h3>
<p>Few-shot learningã«ãŠã‘ã‚‹ã€Œ5-way 3-shotå­¦ç¿’ã€ã¨ã¯ä½•ã‚’æ„å‘³ã™ã‚‹ã‹èª¬æ˜ã—ã€ã“ã®è¨­å®šã§ã®å­¦ç¿’ã‚µãƒ³ãƒ—ãƒ«æ•°ã‚’è¨ˆç®—ã—ã¦ãã ã•ã„ã€‚</p>

<details>
<summary>è§£ç­”ä¾‹</summary>

<p><strong>è§£ç­”</strong>ï¼š</p>

<p><strong>ã€Œ5-way 3-shotå­¦ç¿’ã€ã®æ„å‘³</strong>ï¼š</p>
<ul>
<li><strong>5-way</strong>: 5ã¤ã®ã‚¯ãƒ©ã‚¹ã‚’åˆ†é¡ã™ã‚‹ã‚¿ã‚¹ã‚¯</li>
<li><strong>3-shot</strong>: å„ã‚¯ãƒ©ã‚¹ã«ã¤ã3å€‹ã®ã‚µãƒ³ãƒ—ãƒ«ã®ã¿ã‚’å­¦ç¿’ã«ä½¿ç”¨</li>
</ul>

<p><strong>å­¦ç¿’ã‚µãƒ³ãƒ—ãƒ«æ•°</strong>ï¼š</p>
<p>$$
\text{ã‚µãƒ³ãƒ—ãƒ«æ•°} = \text{ã‚¯ãƒ©ã‚¹æ•°} \times \text{å„ã‚¯ãƒ©ã‚¹ã®ã‚µãƒ³ãƒ—ãƒ«æ•°} = 5 \times 3 = 15
$$</p>

<p>ã¤ã¾ã‚Šã€ã‚ãšã‹15ã‚µãƒ³ãƒ—ãƒ«ã§5ã‚¯ãƒ©ã‚¹åˆ†é¡ã‚’å­¦ç¿’ã—ã¾ã™ã€‚</p>

<p><strong>å…·ä½“ä¾‹</strong>ï¼š</p>
<ul>
<li>5ç¨®é¡ã®å‹•ç‰©ï¼ˆçŠ¬ã€çŒ«ã€é³¥ã€é­šã€é¦¬ï¼‰ã‚’åˆ†é¡</li>
<li>å„å‹•ç‰©ã®ç”»åƒã‚’3æšãšã¤ï¼ˆåˆè¨ˆ15æšï¼‰ã ã‘å­¦ç¿’ã«ä½¿ç”¨</li>
<li>æ–°ã—ã„å‹•ç‰©ã®ç”»åƒã‚’æ­£ã—ãåˆ†é¡ã§ãã‚‹ã‚ˆã†ã«ãªã‚‹</li>
</ul>

</details>

<h3>å•é¡Œ4ï¼ˆé›£æ˜“åº¦ï¼šhardï¼‰</h3>
<p>ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã‚’å®Œæˆã•ã›ã¦ã€ç°¡æ˜“çš„ãªAutoMLã‚·ã‚¹ãƒ†ãƒ ã‚’å®Ÿè£…ã—ã¦ãã ã•ã„ã€‚ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ã€ãƒ¢ãƒ‡ãƒ«é¸æŠã€ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–ã‚’å«ã‚ã‚‹ã“ã¨ã€‚</p>

<pre><code class="language-python">from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split

# ãƒ‡ãƒ¼ã‚¿æº–å‚™
X, y = load_breast_cancer(return_X_y=True)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# ã“ã“ã«AutoMLã‚·ã‚¹ãƒ†ãƒ ã‚’å®Ÿè£…
# TODO: å‰å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã€ãƒ¢ãƒ‡ãƒ«é¸æŠã€ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–
</code></pre>

<details>
<summary>è§£ç­”ä¾‹</summary>

<pre><code class="language-python">from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
import numpy as np

# ãƒ‡ãƒ¼ã‚¿æº–å‚™
X, y = load_breast_cancer(return_X_y=True)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

print("=== ç°¡æ˜“AutoMLã‚·ã‚¹ãƒ†ãƒ  ===\n")

# ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ¢ãƒ‡ãƒ«å€™è£œã¨ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç©ºé–“ã®å®šç¾©
models = {
    'Logistic Regression': {
        'model': LogisticRegression(max_iter=1000),
        'params': {
            'classifier__C': [0.1, 1.0, 10.0],
            'classifier__penalty': ['l2']
        }
    },
    'Random Forest': {
        'model': RandomForestClassifier(random_state=42),
        'params': {
            'classifier__n_estimators': [50, 100, 200],
            'classifier__max_depth': [None, 10, 20],
            'classifier__min_samples_split': [2, 5]
        }
    },
    'SVM': {
        'model': SVC(),
        'params': {
            'classifier__C': [0.1, 1.0, 10.0],
            'classifier__kernel': ['rbf', 'linear']
        }
    }
}

# ã‚¹ãƒ†ãƒƒãƒ—2: å„ãƒ¢ãƒ‡ãƒ«ã§å‰å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ + ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–
best_overall_score = 0
best_overall_model = None
best_overall_name = None

for name, config in models.items():
    print(f"--- {name} ---")

    # ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ§‹ç¯‰ï¼ˆå‰å‡¦ç† + ãƒ¢ãƒ‡ãƒ«ï¼‰
    pipeline = Pipeline([
        ('scaler', StandardScaler()),
        ('classifier', config['model'])
    ])

    # ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒã§ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–
    grid_search = GridSearchCV(
        pipeline,
        param_grid=config['params'],
        cv=5,
        scoring='accuracy',
        n_jobs=-1
    )

    grid_search.fit(X_train, y_train)

    # çµæœ
    cv_score = grid_search.best_score_
    test_score = grid_search.score(X_test, y_test)

    print(f"  æœ€è‰¯CVã‚¹ã‚³ã‚¢: {cv_score:.4f}")
    print(f"  ãƒ†ã‚¹ãƒˆã‚¹ã‚³ã‚¢: {test_score:.4f}")
    print(f"  æœ€è‰¯ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: {grid_search.best_params_}")
    print()

    # æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ã®æ›´æ–°
    if cv_score > best_overall_score:
        best_overall_score = cv_score
        best_overall_model = grid_search.best_estimator_
        best_overall_name = name

# ã‚¹ãƒ†ãƒƒãƒ—3: æœ€çµ‚çµæœ
print("=" * 50)
print(f"æœ€è‰¯ãƒ¢ãƒ‡ãƒ«: {best_overall_name}")
print(f"CVã‚¹ã‚³ã‚¢: {best_overall_score:.4f}")
print(f"ãƒ†ã‚¹ãƒˆã‚¹ã‚³ã‚¢: {best_overall_model.score(X_test, y_test):.4f}")
print("=" * 50)
</code></pre>

<p><strong>å‡ºåŠ›ä¾‹</strong>ï¼š</p>
<pre><code>=== ç°¡æ˜“AutoMLã‚·ã‚¹ãƒ†ãƒ  ===

--- Logistic Regression ---
  æœ€è‰¯CVã‚¹ã‚³ã‚¢: 0.9780
  ãƒ†ã‚¹ãƒˆã‚¹ã‚³ã‚¢: 0.9825
  æœ€è‰¯ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: {'classifier__C': 1.0, 'classifier__penalty': 'l2'}

--- Random Forest ---
  æœ€è‰¯CVã‚¹ã‚³ã‚¢: 0.9648
  ãƒ†ã‚¹ãƒˆã‚¹ã‚³ã‚¢: 0.9649
  æœ€è‰¯ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: {'classifier__max_depth': None, ...}

--- SVM ---
  æœ€è‰¯CVã‚¹ã‚³ã‚¢: 0.9758
  ãƒ†ã‚¹ãƒˆã‚¹ã‚³ã‚¢: 0.9737
  æœ€è‰¯ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: {'classifier__C': 1.0, 'classifier__kernel': 'linear'}

==================================================
æœ€è‰¯ãƒ¢ãƒ‡ãƒ«: Logistic Regression
CVã‚¹ã‚³ã‚¢: 0.9780
ãƒ†ã‚¹ãƒˆã‚¹ã‚³ã‚¢: 0.9825
==================================================
</code></pre>

</details>

<h3>å•é¡Œ5ï¼ˆé›£æ˜“åº¦ï¼šhardï¼‰</h3>
<p>AutoMLã«ãŠã‘ã‚‹ã€Œè¨ˆç®—ã‚³ã‚¹ãƒˆã€ã¨ã€Œäºˆæ¸¬ç²¾åº¦ã€ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã«ã¤ã„ã¦èª¬æ˜ã—ã€å®Ÿç”¨ä¸Šã©ã®ã‚ˆã†ã«ãƒãƒ©ãƒ³ã‚¹ã‚’å–ã‚‹ã¹ãã‹è¿°ã¹ã¦ãã ã•ã„ã€‚</p>

<details>
<summary>è§£ç­”ä¾‹</summary>

<p><strong>è§£ç­”</strong>ï¼š</p>

<p><strong>ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã®æœ¬è³ª</strong>ï¼š</p>

<table>
<thead>
<tr>
<th>å´é¢</th>
<th>é«˜ç²¾åº¦è¿½æ±‚</th>
<th>ä½ã‚³ã‚¹ãƒˆè¿½æ±‚</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>æ¢ç´¢ç¯„å›²</strong></td>
<td>åºƒç¯„å›²ã®æ¢ç´¢ï¼ˆæ•°åƒãƒ¢ãƒ‡ãƒ«ï¼‰</td>
<td>é™å®šçš„ãªæ¢ç´¢ï¼ˆæ•°åãƒ¢ãƒ‡ãƒ«ï¼‰</td>
</tr>
<tr>
<td><strong>æ™‚é–“</strong></td>
<td>æ•°æ—¥ã€œæ•°é€±é–“</td>
<td>æ•°æ™‚é–“ã€œæ•°æ—¥</td>
</tr>
<tr>
<td><strong>ãƒªã‚½ãƒ¼ã‚¹</strong></td>
<td>å¤§è¦æ¨¡GPU/ã‚¯ãƒ©ã‚¹ã‚¿</td>
<td>å˜ä¸€ãƒã‚·ãƒ³</td>
</tr>
<tr>
<td><strong>ç²¾åº¦å‘ä¸Š</strong></td>
<td>+1-2%ã®æ”¹å–„</td>
<td>ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³é”æˆ</td>
</tr>
</tbody>
</table>

<p><strong>ãƒãƒ©ãƒ³ã‚¹ã‚’å–ã‚‹æˆ¦ç•¥</strong>ï¼š</p>

<ol>
<li><p><strong>æ®µéšçš„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ</strong></p>
<ul>
<li>Phase 1: é«˜é€Ÿæ¢ç´¢ã§æœ‰æœ›ãªãƒ¢ãƒ‡ãƒ«å€™è£œã‚’çµã‚Šè¾¼ã¿ï¼ˆæ•°æ™‚é–“ï¼‰</li>
<li>Phase 2: å€™è£œã«å¯¾ã—ã¦è©³ç´°ãªæœ€é©åŒ–ï¼ˆæ•°æ—¥ï¼‰</li>
</ul></li>

<li><p><strong>æ—©æœŸåœæ­¢</strong></p>
<ul>
<li>æ¤œè¨¼ç²¾åº¦ãŒæ”¹å–„ã—ãªã‘ã‚Œã°æ¢ç´¢ã‚’æ‰“ã¡åˆ‡ã‚Š</li>
<li>è¨ˆç®—äºˆç®—ï¼ˆæ™‚é–“ãƒ»ã‚³ã‚¹ãƒˆï¼‰ã®ä¸Šé™ã‚’è¨­å®š</li>
</ul></li>

<li><p><strong>åŠ¹ç‡çš„ãªæ¢ç´¢æ‰‹æ³•</strong></p>
<ul>
<li>ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ¼ãƒã§ã¯ãªããƒ™ã‚¤ã‚ºæœ€é©åŒ–ã‚’ä½¿ç”¨</li>
<li>è»¢ç§»å­¦ç¿’ã‚„ãƒ¡ã‚¿å­¦ç¿’ã§åˆæœŸçŠ¶æ…‹ã‚’æ”¹å–„</li>
</ul></li>

<li><p><strong>ã‚¿ã‚¹ã‚¯ã«å¿œã˜ãŸå„ªå…ˆé †ä½</strong></p>
<ul>
<li>æœ¬ç•ªã‚·ã‚¹ãƒ†ãƒ : ç²¾åº¦å„ªå…ˆï¼ˆé«˜ã‚³ã‚¹ãƒˆè¨±å®¹ï¼‰</li>
<li>ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—: é€Ÿåº¦å„ªå…ˆï¼ˆä½ã‚³ã‚¹ãƒˆé‡è¦–ï¼‰</li>
<li>ç ”ç©¶: ä¸¡æ–¹ã®ãƒãƒ©ãƒ³ã‚¹</li>
</ul></li>

<li><p><strong>å¤šç›®çš„æœ€é©åŒ–</strong></p>
<ul>
<li>ç›®çš„é–¢æ•°ã«è¨ˆç®—ã‚³ã‚¹ãƒˆã‚’å«ã‚ã‚‹</li>
</ul></li>
</ol>

<p>$$
\text{Objective} = \alpha \cdot \text{Accuracy} - (1-\alpha) \cdot \log(\text{Cost})
$$</p>

<ul>
<li>$\alpha$: ç²¾åº¦ã¨ã‚³ã‚¹ãƒˆã®é‡ã¿ï¼ˆ0ã€œ1ï¼‰</li>
</ul>

<p><strong>å®Ÿç”¨çš„ãªæ¨å¥¨</strong>ï¼š</p>
<ul>
<li>ã¾ãšä½ã‚³ã‚¹ãƒˆã§æ¢ç´¢ã—ã€ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ€§èƒ½ã‚’æŠŠæ¡</li>
<li>ãƒ“ã‚¸ãƒã‚¹ä¾¡å€¤ãŒé«˜ã„å ´åˆã®ã¿é«˜ã‚³ã‚¹ãƒˆæ¢ç´¢ã‚’å®Ÿæ–½</li>
<li>ç²¾åº¦1%æ”¹å–„ã®ã‚³ã‚¹ãƒˆã¨åŠ¹æœã‚’å®šé‡çš„ã«è©•ä¾¡</li>
</ul>

</details>

<hr>

<h2>å‚è€ƒæ–‡çŒ®</h2>

<ol>
<li>Hutter, F., Kotthoff, L., & Vanschoren, J. (Eds.). (2019). <em>Automated Machine Learning: Methods, Systems, Challenges</em>. Springer.</li>
<li>Elsken, T., Metzen, J. H., & Hutter, F. (2019). Neural Architecture Search: A Survey. <em>Journal of Machine Learning Research</em>, 20(55), 1-21.</li>
<li>Hospedales, T., Antoniou, A., Micaelli, P., & Storkey, A. (2021). Meta-Learning in Neural Networks: A Survey. <em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em>.</li>
<li>Feurer, M., & Hutter, F. (2019). Hyperparameter Optimization. In <em>Automated Machine Learning</em> (pp. 3-33). Springer.</li>
<li>He, X., Zhao, K., & Chu, X. (2021). AutoML: A survey of the state-of-the-art. <em>Knowledge-Based Systems</em>, 212, 106622.</li>
</ol>

<div class="navigation">
    <a href="index.html" class="nav-button">â† ã‚·ãƒªãƒ¼ã‚ºç›®æ¬¡</a>
    <a href="chapter2-automl-tools.html" class="nav-button">æ¬¡ã®ç« : AutoMLãƒ„ãƒ¼ãƒ«ã¨ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ â†’</a>
</div>

    </main>

    
    <section class="disclaimer">
        <h3>å…è²¬äº‹é …</h3>
        <ul>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯æ•™è‚²ãƒ»ç ”ç©¶ãƒ»æƒ…å ±æä¾›ã®ã¿ã‚’ç›®çš„ã¨ã—ã¦ãŠã‚Šã€å°‚é–€çš„ãªåŠ©è¨€(æ³•å¾‹ãƒ»ä¼šè¨ˆãƒ»æŠ€è¡“çš„ä¿è¨¼ãªã©)ã‚’æä¾›ã™ã‚‹ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŠã‚ˆã³ä»˜éšã™ã‚‹ã‚³ãƒ¼ãƒ‰ä¾‹ã¯ã€Œç¾çŠ¶æœ‰å§¿(AS IS)ã€ã§æä¾›ã•ã‚Œã€æ˜ç¤ºã¾ãŸã¯é»™ç¤ºã‚’å•ã‚ãšã€å•†å“æ€§ã€ç‰¹å®šç›®çš„é©åˆæ€§ã€æ¨©åˆ©éä¾µå®³ã€æ­£ç¢ºæ€§ãƒ»å®Œå…¨æ€§ã€å‹•ä½œãƒ»å®‰å…¨æ€§ç­‰ã„ã‹ãªã‚‹ä¿è¨¼ã‚‚ã—ã¾ã›ã‚“ã€‚</li>
            <li>å¤–éƒ¨ãƒªãƒ³ã‚¯ã€ç¬¬ä¸‰è€…ãŒæä¾›ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ»ãƒ„ãƒ¼ãƒ«ãƒ»ãƒ©ã‚¤ãƒ–ãƒ©ãƒªç­‰ã®å†…å®¹ãƒ»å¯ç”¨æ€§ãƒ»å®‰å…¨æ€§ã«ã¤ã„ã¦ã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯ä¸€åˆ‡ã®è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®åˆ©ç”¨ãƒ»å®Ÿè¡Œãƒ»è§£é‡ˆã«ã‚ˆã‚Šç›´æ¥çš„ãƒ»é–“æ¥çš„ãƒ»ä»˜éšçš„ãƒ»ç‰¹åˆ¥ãƒ»çµæœçš„ãƒ»æ‡²ç½°çš„æå®³ãŒç”Ÿã˜ãŸå ´åˆã§ã‚‚ã€é©ç”¨æ³•ã§è¨±å®¹ã•ã‚Œã‚‹æœ€å¤§é™ã®ç¯„å›²ã§ã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å†…å®¹ã¯ã€äºˆå‘Šãªãå¤‰æ›´ãƒ»æ›´æ–°ãƒ»æä¾›åœæ­¢ã•ã‚Œã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®è‘—ä½œæ¨©ãƒ»ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯æ˜è¨˜ã•ã‚ŒãŸæ¡ä»¶(ä¾‹: CC BY 4.0)ã«å¾“ã„ã¾ã™ã€‚å½“è©²ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯é€šå¸¸ã€ç„¡ä¿è¨¼æ¡é …ã‚’å«ã¿ã¾ã™ã€‚</li>
        </ul>
    </section>

<footer>
        <p><strong>ä½œæˆè€…</strong>: AI Terakoya Content Team</p>
        <p><strong>ãƒãƒ¼ã‚¸ãƒ§ãƒ³</strong>: 1.0 | <strong>ä½œæˆæ—¥</strong>: 2025-10-21</p>
        <p><strong>ãƒ©ã‚¤ã‚»ãƒ³ã‚¹</strong>: Creative Commons BY 4.0</p>
        <p>Â© 2025 AI Terakoya. All rights reserved.</p>
    </footer>
</body>
</html>
