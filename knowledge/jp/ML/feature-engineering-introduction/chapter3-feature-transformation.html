<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ç¬¬3ç« ï¼šç‰¹å¾´é‡å¤‰æ›ã¨ç”Ÿæˆ - AI Terakoya</title>

    <style>
        :root {
            --color-primary: #2c3e50;
            --color-primary-dark: #1a252f;
            --color-accent: #7b2cbf;
            --color-accent-light: #9d4edd;
            --color-text: #2d3748;
            --color-text-light: #4a5568;
            --color-bg: #ffffff;
            --color-bg-alt: #f7fafc;
            --color-border: #e2e8f0;
            --color-code-bg: #f8f9fa;
            --color-link: #3182ce;
            --color-link-hover: #2c5aa0;
            --spacing-xs: 0.5rem;
            --spacing-sm: 1rem;
            --spacing-md: 1.5rem;
            --spacing-lg: 2rem;
            --spacing-xl: 3rem;
            --font-body: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            --font-mono: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;
            --border-radius: 8px;
            --box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body { font-family: var(--font-body); line-height: 1.7; color: var(--color-text); background-color: var(--color-bg); font-size: 16px; }
        header { background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%); color: white; padding: var(--spacing-xl) var(--spacing-md); margin-bottom: var(--spacing-xl); box-shadow: var(--box-shadow); }
        .header-content { max-width: 900px; margin: 0 auto; }
        h1 { font-size: 2rem; font-weight: 700; margin-bottom: var(--spacing-sm); line-height: 1.2; }
        .subtitle { font-size: 1.1rem; opacity: 0.95; font-weight: 400; margin-bottom: var(--spacing-md); }
        .meta { display: flex; flex-wrap: wrap; gap: var(--spacing-md); font-size: 0.9rem; opacity: 0.9; }
        .meta-item { display: flex; align-items: center; gap: 0.3rem; }
        .container { max-width: 900px; margin: 0 auto; padding: 0 var(--spacing-md) var(--spacing-xl); }
        h2 { font-size: 1.75rem; color: var(--color-primary); margin-top: var(--spacing-xl); margin-bottom: var(--spacing-md); padding-bottom: var(--spacing-xs); border-bottom: 3px solid var(--color-accent); }
        h3 { font-size: 1.4rem; color: var(--color-primary); margin-top: var(--spacing-lg); margin-bottom: var(--spacing-sm); }
        h4 { font-size: 1.1rem; color: var(--color-primary-dark); margin-top: var(--spacing-md); margin-bottom: var(--spacing-sm); }
        p { margin-bottom: var(--spacing-md); color: var(--color-text); }
        a { color: var(--color-link); text-decoration: none; transition: color 0.2s; }
        a:hover { color: var(--color-link-hover); text-decoration: underline; }
        ul, ol { margin-left: var(--spacing-lg); margin-bottom: var(--spacing-md); }
        li { margin-bottom: var(--spacing-xs); color: var(--color-text); }
        pre { background-color: var(--color-code-bg); border: 1px solid var(--color-border); border-radius: var(--border-radius); padding: var(--spacing-md); overflow-x: auto; margin-bottom: var(--spacing-md); font-family: var(--font-mono); font-size: 0.9rem; line-height: 1.5; }
        code { font-family: var(--font-mono); font-size: 0.9em; background-color: var(--color-code-bg); padding: 0.2em 0.4em; border-radius: 3px; }
        pre code { background-color: transparent; padding: 0; }
        table { width: 100%; border-collapse: collapse; margin-bottom: var(--spacing-md); font-size: 0.95rem; }
        th, td { border: 1px solid var(--color-border); padding: var(--spacing-sm); text-align: left; }
        th { background-color: var(--color-bg-alt); font-weight: 600; color: var(--color-primary); }
        blockquote { border-left: 4px solid var(--color-accent); padding-left: var(--spacing-md); margin: var(--spacing-md) 0; color: var(--color-text-light); font-style: italic; background-color: var(--color-bg-alt); padding: var(--spacing-md); border-radius: var(--border-radius); }
        .mermaid { text-align: center; margin: var(--spacing-lg) 0; background-color: var(--color-bg-alt); padding: var(--spacing-md); border-radius: var(--border-radius); }
        details { background-color: var(--color-bg-alt); border: 1px solid var(--color-border); border-radius: var(--border-radius); padding: var(--spacing-md); margin-bottom: var(--spacing-md); }
        summary { cursor: pointer; font-weight: 600; color: var(--color-primary); user-select: none; padding: var(--spacing-xs); margin: calc(-1 * var(--spacing-md)); padding: var(--spacing-md); border-radius: var(--border-radius); }
        summary:hover { background-color: rgba(123, 44, 191, 0.1); }
        details[open] summary { margin-bottom: var(--spacing-md); border-bottom: 1px solid var(--color-border); }
        .navigation { display: flex; justify-content: space-between; gap: var(--spacing-md); margin: var(--spacing-xl) 0; padding-top: var(--spacing-lg); border-top: 2px solid var(--color-border); }
        .nav-button { flex: 1; padding: var(--spacing-md); background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%); color: white; border-radius: var(--border-radius); text-align: center; font-weight: 600; transition: transform 0.2s, box-shadow 0.2s; box-shadow: var(--box-shadow); }
        .nav-button:hover { transform: translateY(-2px); box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15); text-decoration: none; }
        footer { margin-top: var(--spacing-xl); padding: var(--spacing-lg) var(--spacing-md); background-color: var(--color-bg-alt); border-top: 1px solid var(--color-border); text-align: center; font-size: 0.9rem; color: var(--color-text-light); }
        @media (max-width: 768px) { h1 { font-size: 1.5rem; } h2 { font-size: 1.4rem; } h3 { font-size: 1.2rem; } .meta { font-size: 0.85rem; } .navigation { flex-direction: column; } table { font-size: 0.85rem; } th, td { padding: var(--spacing-xs); } }
    </style>

    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
        mermaid.initialize({ startOnLoad: true, theme: 'default' });
    </script>
    <script>
        MathJax = {
            tex: { inlineMath: [['$', '$'], ['\\(', '\\)']], displayMath: [['$$', '$$'], ['\\[', '\\]']], processEscapes: true, processEnvironments: true },
            options: { skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'], ignoreHtmlClass: 'mermaid' }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" async></script>
</head>
<body>
    <header>
        <div class="header-content">
            <h1>ç¬¬3ç« ï¼šç‰¹å¾´é‡å¤‰æ›ã¨ç”Ÿæˆ</h1>
            <p class="subtitle">ãƒ‡ãƒ¼ã‚¿ã®æ½œåœ¨åŠ›ã‚’å¼•ãå‡ºã™ - å¤‰æ›æ‰‹æ³•ã‹ã‚‰ãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜ã¾ã§ã€Kaggleçš„ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°</p>
            <div class="meta">
                <span class="meta-item">ğŸ“– èª­äº†æ™‚é–“: 20-25åˆ†</span>
                <span class="meta-item">ğŸ“Š é›£æ˜“åº¦: ä¸­ç´š</span>
                <span class="meta-item">ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹: 12å€‹</span>
                <span class="meta-item">ğŸ“ æ¼”ç¿’å•é¡Œ: 5å•</span>
            </div>
        </div>
    </header>

    <main class="container">

<h2>å­¦ç¿’ç›®æ¨™</h2>
<p>ã“ã®ç« ã‚’èª­ã‚€ã“ã¨ã§ã€ä»¥ä¸‹ã‚’ç¿’å¾—ã§ãã¾ã™ï¼š</p>
<ul>
<li>âœ… ç‰¹å¾´é‡å¤‰æ›ã®ç›®çš„ã¨åŠ¹æœã‚’ç†è§£ã™ã‚‹</li>
<li>âœ… å¯¾æ•°å¤‰æ›ã€Box-Coxå¤‰æ›ã‚’é©ç”¨ã§ãã‚‹</li>
<li>âœ… ãƒ“ãƒ‹ãƒ³ã‚°ï¼ˆé›¢æ•£åŒ–ï¼‰ã‚’å®Ÿè£…ã—æ´»ç”¨ã§ãã‚‹</li>
<li>âœ… å¤šé …å¼ç‰¹å¾´é‡ã¨äº¤äº’ä½œç”¨é …ã‚’ç”Ÿæˆã§ãã‚‹</li>
<li>âœ… ãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã®ç‰¹å¾´é‡ã‚’è¨­è¨ˆã§ãã‚‹</li>
<li>âœ… æ—¥æ™‚ãƒ»ãƒ†ã‚­ã‚¹ãƒˆãƒ»é›†ç´„ç‰¹å¾´é‡ã‚’ä½œæˆã§ãã‚‹</li>
<li>âœ… Kaggleç«¶æŠ€ã§ä½¿ãˆã‚‹ç‰¹å¾´é‡ç”Ÿæˆãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç¿’å¾—ã™ã‚‹</li>
</ul>

<hr>

<h2>3.1 ç‰¹å¾´é‡å¤‰æ›ã®ç›®çš„</h2>

<h3>ãªãœç‰¹å¾´é‡å¤‰æ›ãŒå¿…è¦ã‹</h3>
<p>ç”Ÿãƒ‡ãƒ¼ã‚¿ã‚’ãã®ã¾ã¾ä½¿ã†ã¨ã€ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ãŒåˆ¶é™ã•ã‚Œã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚ç‰¹å¾´é‡å¤‰æ›ã«ã‚ˆã‚Šã€ä»¥ä¸‹ã‚’å®Ÿç¾ã§ãã¾ã™ï¼š</p>

<blockquote>
<p>ã€Œè‰¯ã„ç‰¹å¾´é‡ã¯ã€è¤‡é›‘ãªãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Šã‚‚å¼·åŠ›ã§ã‚ã‚‹ã€‚å¤‰æ›ã«ã‚ˆã‚Šã€ãƒ‡ãƒ¼ã‚¿ã«éš ã•ã‚ŒãŸæƒ…å ±ã‚’é¡•åœ¨åŒ–ã•ã›ã‚‹ã€</p>
</blockquote>

<h3>ä¸»è¦ãªå¤‰æ›ã®ç¨®é¡</h3>

<div class="mermaid">
graph TD
    A[ç‰¹å¾´é‡å¤‰æ›] --> B[æ•°å€¤å¤‰æ›]
    A --> C[é›¢æ•£åŒ–]
    A --> D[ç‰¹å¾´é‡ç”Ÿæˆ]

    B --> B1[å¯¾æ•°å¤‰æ›<br/>æ­£è¦åŒ–]
    B --> B2[ã¹ãä¹—å¤‰æ›<br/>Box-Cox]

    C --> C1[ãƒ“ãƒ‹ãƒ³ã‚°<br/>ã‚«ãƒ†ã‚´ãƒªåŒ–]
    C --> C2[ç­‰å¹…ãƒ»ç­‰é »åº¦<br/>ã‚«ã‚¹ã‚¿ãƒ ]

    D --> D1[å¤šé …å¼ç‰¹å¾´é‡<br/>äº¤äº’ä½œç”¨]
    D --> D2[ãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜<br/>é›†ç´„çµ±è¨ˆ]

    style A fill:#e3f2fd
    style B fill:#fff3e0
    style C fill:#f3e5f5
    style D fill:#e8f5e9
</div>

<h3>å¤‰æ›ã®åŠ¹æœ</h3>

<table>
<thead>
<tr>
<th>å¤‰æ›ç›®çš„</th>
<th>é©ç”¨å ´é¢</th>
<th>åŠ¹æœ</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>åˆ†å¸ƒã®æ­£è¦åŒ–</strong></td>
<td>æ­ªã‚“ã åˆ†å¸ƒ</td>
<td>ç·šå½¢ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½å‘ä¸Š</td>
</tr>
<tr>
<td><strong>å¤–ã‚Œå€¤ã®å½±éŸ¿è»½æ¸›</strong></td>
<td>æ¥µç«¯ãªå€¤ãŒå­˜åœ¨</td>
<td>ãƒ­ãƒã‚¹ãƒˆæ€§ã®å‘ä¸Š</td>
</tr>
<tr>
<td><strong>éç·šå½¢é–¢ä¿‚ã®æ•æ‰</strong></td>
<td>è¤‡é›‘ãªé–¢ä¿‚æ€§</td>
<td>è¡¨ç¾åŠ›ã®å‘ä¸Š</td>
</tr>
<tr>
<td><strong>è§£é‡ˆæ€§ã®å‘ä¸Š</strong></td>
<td>ã‚«ãƒ†ã‚´ãƒªåŒ–ãŒè‡ªç„¶</td>
<td>ãƒ“ã‚¸ãƒã‚¹ç†è§£ã®ä¿ƒé€²</td>
</tr>
<tr>
<td><strong>ç‰¹å¾´é‡ã®ç›¸äº’ä½œç”¨</strong></td>
<td>çµ„åˆã›ãŒé‡è¦</td>
<td>äºˆæ¸¬ç²¾åº¦ã®å‘ä¸Š</td>
</tr>
</tbody>
</table>

<hr>

<h2>3.2 æ•°å€¤å¤‰æ›</h2>

<h3>å¯¾æ•°å¤‰æ›ï¼ˆLog Transformï¼‰</h3>

<p><strong>å¯¾æ•°å¤‰æ›</strong>ã¯ã€å³ã«æ­ªã‚“ã åˆ†å¸ƒã‚’æ­£è¦åˆ†å¸ƒã«è¿‘ã¥ã‘ã‚‹åŠ¹æœãŒã‚ã‚Šã¾ã™ã€‚</p>

<p>$$
y = \log(x) \quad \text{ã¾ãŸã¯} \quad y = \log(x + 1)
$$</p>

<ul>
<li><code>log(x)</code>: $x > 0$ ãŒå¿…è¦</li>
<li><code>log1p(x)</code>: $x \geq 0$ ã§å®‰å…¨ï¼ˆ$\log(1 + x)$ï¼‰</li>
</ul>

<h3>å®Ÿè£…ä¾‹: å¯¾æ•°å¤‰æ›</h3>

<pre><code class="language-python">import numpy as np
import matplotlib.pyplot as plt
from scipy import stats

# å³ã«æ­ªã‚“ã åˆ†å¸ƒã‚’ç”Ÿæˆ
np.random.seed(42)
data_skewed = np.random.lognormal(mean=0, sigma=1, size=1000)

# å¯¾æ•°å¤‰æ›
data_log = np.log(data_skewed)
data_log1p = np.log1p(data_skewed)

print("=== å¯¾æ•°å¤‰æ›ã«ã‚ˆã‚‹åˆ†å¸ƒã®å¤‰åŒ– ===")
print(f"å…ƒãƒ‡ãƒ¼ã‚¿: æ­ªåº¦={stats.skew(data_skewed):.3f}, å°–åº¦={stats.kurtosis(data_skewed):.3f}")
print(f"logå¤‰æ›å¾Œ: æ­ªåº¦={stats.skew(data_log):.3f}, å°–åº¦={stats.kurtosis(data_log):.3f}")

# å¯è¦–åŒ–
fig, axes = plt.subplots(2, 2, figsize=(14, 10))

# å…ƒãƒ‡ãƒ¼ã‚¿
axes[0, 0].hist(data_skewed, bins=50, edgecolor='black', alpha=0.7, color='steelblue')
axes[0, 0].set_xlabel('å€¤', fontsize=12)
axes[0, 0].set_ylabel('é »åº¦', fontsize=12)
axes[0, 0].set_title(f'å…ƒãƒ‡ãƒ¼ã‚¿ (æ­ªåº¦: {stats.skew(data_skewed):.3f})', fontsize=14)
axes[0, 0].grid(True, alpha=0.3)

# Q-Qãƒ—ãƒ­ãƒƒãƒˆï¼ˆå…ƒãƒ‡ãƒ¼ã‚¿ï¼‰
stats.probplot(data_skewed, dist="norm", plot=axes[0, 1])
axes[0, 1].set_title('å…ƒãƒ‡ãƒ¼ã‚¿ã®Q-Qãƒ—ãƒ­ãƒƒãƒˆ', fontsize=14)
axes[0, 1].grid(True, alpha=0.3)

# å¯¾æ•°å¤‰æ›å¾Œ
axes[1, 0].hist(data_log, bins=50, edgecolor='black', alpha=0.7, color='green')
axes[1, 0].set_xlabel('å€¤', fontsize=12)
axes[1, 0].set_ylabel('é »åº¦', fontsize=12)
axes[1, 0].set_title(f'logå¤‰æ›å¾Œ (æ­ªåº¦: {stats.skew(data_log):.3f})', fontsize=14)
axes[1, 0].grid(True, alpha=0.3)

# Q-Qãƒ—ãƒ­ãƒƒãƒˆï¼ˆå¤‰æ›å¾Œï¼‰
stats.probplot(data_log, dist="norm", plot=axes[1, 1])
axes[1, 1].set_title('logå¤‰æ›å¾Œã®Q-Qãƒ—ãƒ­ãƒƒãƒˆ', fontsize=14)
axes[1, 1].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>=== å¯¾æ•°å¤‰æ›ã«ã‚ˆã‚‹åˆ†å¸ƒã®å¤‰åŒ– ===
å…ƒãƒ‡ãƒ¼ã‚¿: æ­ªåº¦=6.251, å°–åº¦=110.582
logå¤‰æ›å¾Œ: æ­ªåº¦=0.034, å°–åº¦=-0.157
</code></pre>

<h3>Box-Coxå¤‰æ›</h3>

<p><strong>Box-Coxå¤‰æ›</strong>ã¯ã€æœ€é©ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ $\lambda$ ã‚’è‡ªå‹•çš„ã«è¦‹ã¤ã‘ã¦å¤‰æ›ã—ã¾ã™ã€‚</p>

<p>$$
y(\lambda) = \begin{cases}
\frac{x^\lambda - 1}{\lambda} & \text{if } \lambda \neq 0 \\
\log(x) & \text{if } \lambda = 0
\end{cases}
$$</p>

<ul>
<li>$\lambda = 1$: å¤‰æ›ãªã—</li>
<li>$\lambda = 0.5$: å¹³æ–¹æ ¹å¤‰æ›</li>
<li>$\lambda = 0$: å¯¾æ•°å¤‰æ›</li>
<li>$\lambda = -1$: é€†æ•°å¤‰æ›</li>
</ul>

<h3>å®Ÿè£…ä¾‹: Box-Coxå¤‰æ›ã¨PowerTransformer</h3>

<pre><code class="language-python">from sklearn.preprocessing import PowerTransformer
from scipy.stats import boxcox

# Box-Coxå¤‰æ›ï¼ˆscipyç‰ˆï¼‰
data_boxcox, lambda_param = boxcox(data_skewed)

print(f"\n=== Box-Coxå¤‰æ› ===")
print(f"æœ€é©ãªÎ»: {lambda_param:.4f}")
print(f"å¤‰æ›å¾Œã®æ­ªåº¦: {stats.skew(data_boxcox):.3f}")

# PowerTransformerï¼ˆsklearnç‰ˆï¼‰- è¤‡æ•°ç‰¹å¾´é‡ã«å¯¾å¿œ
X = data_skewed.reshape(-1, 1)

# Box-Coxæ³•
pt_boxcox = PowerTransformer(method='box-cox', standardize=True)
X_boxcox = pt_boxcox.fit_transform(X)

# Yeo-Johnsonæ³•ï¼ˆè² ã®å€¤ã‚‚æ‰±ãˆã‚‹ï¼‰
X_with_negative = np.concatenate([data_skewed, -data_skewed[:100]])
X_neg = X_with_negative.reshape(-1, 1)

pt_yeojohnson = PowerTransformer(method='yeo-johnson', standardize=True)
X_yeojohnson = pt_yeojohnson.fit_transform(X_neg)

print(f"\n=== PowerTransformer ===")
print(f"Box-Cox lambda: {pt_boxcox.lambdas_[0]:.4f}")
print(f"Yeo-Johnson lambda: {pt_yeojohnson.lambdas_[0]:.4f}")

# å¯è¦–åŒ–
fig, axes = plt.subplots(2, 3, figsize=(15, 10))

# å…ƒãƒ‡ãƒ¼ã‚¿
axes[0, 0].hist(data_skewed, bins=50, edgecolor='black', alpha=0.7, color='steelblue')
axes[0, 0].set_title('å…ƒãƒ‡ãƒ¼ã‚¿', fontsize=14)
axes[0, 0].set_xlabel('å€¤', fontsize=12)
axes[0, 0].grid(True, alpha=0.3)

# Box-Coxï¼ˆscipyï¼‰
axes[0, 1].hist(data_boxcox, bins=50, edgecolor='black', alpha=0.7, color='green')
axes[0, 1].set_title(f'Box-Cox (Î»={lambda_param:.3f})', fontsize=14)
axes[0, 1].set_xlabel('å€¤', fontsize=12)
axes[0, 1].grid(True, alpha=0.3)

# PowerTransformer Box-Cox
axes[0, 2].hist(X_boxcox, bins=50, edgecolor='black', alpha=0.7, color='orange')
axes[0, 2].set_title('PowerTransformer (Box-Cox)', fontsize=14)
axes[0, 2].set_xlabel('å€¤', fontsize=12)
axes[0, 2].grid(True, alpha=0.3)

# Q-Qãƒ—ãƒ­ãƒƒãƒˆ
for i, (data, title) in enumerate([
    (data_skewed, 'å…ƒãƒ‡ãƒ¼ã‚¿'),
    (data_boxcox, 'Box-Cox'),
    (X_boxcox.flatten(), 'PowerTransformer')
]):
    stats.probplot(data, dist="norm", plot=axes[1, i])
    axes[1, i].set_title(f'{title} Q-Q', fontsize=14)
    axes[1, i].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>=== Box-Coxå¤‰æ› ===
æœ€é©ãªÎ»: 0.0234
å¤‰æ›å¾Œã®æ­ªåº¦: 0.028

=== PowerTransformer ===
Box-Cox lambda: 0.0234
Yeo-Johnson lambda: 0.1456
</code></pre>

<h3>å¤‰æ›æ‰‹æ³•ã®é¸æŠã‚¬ã‚¤ãƒ‰</h3>

<table>
<thead>
<tr>
<th>æ‰‹æ³•</th>
<th>é©ç”¨æ¡ä»¶</th>
<th>ç‰¹å¾´</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>logå¤‰æ›</strong></td>
<td>$x > 0$</td>
<td>ã‚·ãƒ³ãƒ—ãƒ«ã€è§£é‡ˆã—ã‚„ã™ã„</td>
</tr>
<tr>
<td><strong>log1på¤‰æ›</strong></td>
<td>$x \geq 0$</td>
<td>ã‚¼ãƒ­å€¤ã‚’å«ã‚€ãƒ‡ãƒ¼ã‚¿ã«å®‰å…¨</td>
</tr>
<tr>
<td><strong>å¹³æ–¹æ ¹å¤‰æ›</strong></td>
<td>$x \geq 0$</td>
<td>ã‚«ã‚¦ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã«é©ã—ã¦ã„ã‚‹</td>
</tr>
<tr>
<td><strong>Box-Cox</strong></td>
<td>$x > 0$</td>
<td>æœ€é©ãªå¤‰æ›ã‚’è‡ªå‹•é¸æŠ</td>
</tr>
<tr>
<td><strong>Yeo-Johnson</strong></td>
<td>ä»»æ„ã®å€¤</td>
<td>è² ã®å€¤ã‚‚æ‰±ãˆã‚‹</td>
</tr>
</tbody>
</table>

<hr>

<h2>3.3 ãƒ“ãƒ‹ãƒ³ã‚°ï¼ˆBinningï¼‰</h2>

<h3>æ¦‚è¦</h3>

<p><strong>ãƒ“ãƒ‹ãƒ³ã‚°</strong>ã¯ã€é€£ç¶šå€¤ã‚’é›¢æ•£çš„ãªã‚«ãƒ†ã‚´ãƒªã«å¤‰æ›ã™ã‚‹æ‰‹æ³•ã§ã™ã€‚</p>

<h3>ãƒ“ãƒ‹ãƒ³ã‚°ã®ç¨®é¡</h3>

<div class="mermaid">
graph LR
    A[ãƒ“ãƒ‹ãƒ³ã‚°æ‰‹æ³•] --> B[ç­‰å¹…ãƒ“ãƒ‹ãƒ³ã‚°<br/>Equal Width]
    A --> C[ç­‰é »åº¦ãƒ“ãƒ‹ãƒ³ã‚°<br/>Equal Frequency]
    A --> D[ã‚«ã‚¹ã‚¿ãƒ ãƒ“ãƒ‹ãƒ³ã‚°<br/>Domain Knowledge]

    B --> B1[å„ãƒ“ãƒ³ã®å¹…ãŒåŒã˜]
    C --> C1[å„ãƒ“ãƒ³ã®ãƒ‡ãƒ¼ã‚¿æ•°ãŒåŒã˜]
    D --> D1[ãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜ã§å¢ƒç•Œè¨­å®š]

    style A fill:#e3f2fd
    style B fill:#fff3e0
    style C fill:#f3e5f5
    style D fill:#e8f5e9
</div>

<h3>å®Ÿè£…ä¾‹: KBinsDiscretizer</h3>

<pre><code class="language-python">from sklearn.preprocessing import KBinsDiscretizer
import pandas as pd

# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿: å¹´é½¢
np.random.seed(42)
ages = np.random.normal(40, 15, 500)
ages = np.clip(ages, 18, 80)  # 18-80æ­³ã«åˆ¶é™
X_age = ages.reshape(-1, 1)

print("=== ãƒ“ãƒ‹ãƒ³ã‚° ===")
print(f"å¹´é½¢ãƒ‡ãƒ¼ã‚¿: æœ€å°={ages.min():.1f}, æœ€å¤§={ages.max():.1f}, å¹³å‡={ages.mean():.1f}")

# ç­‰å¹…ãƒ“ãƒ‹ãƒ³ã‚°
kbd_uniform = KBinsDiscretizer(n_bins=5, encode='ordinal', strategy='uniform')
age_binned_uniform = kbd_uniform.fit_transform(X_age)

# ç­‰é »åº¦ãƒ“ãƒ‹ãƒ³ã‚°
kbd_quantile = KBinsDiscretizer(n_bins=5, encode='ordinal', strategy='quantile')
age_binned_quantile = kbd_quantile.fit_transform(X_age)

# ã‚«ã‚¹ã‚¿ãƒ ãƒ“ãƒ‹ãƒ³ã‚°ï¼ˆpandas.cutï¼‰
age_custom_bins = pd.cut(ages,
                         bins=[0, 25, 35, 50, 65, 100],
                         labels=['è‹¥å¹´å±¤', 'é’å¹´å±¤', 'ä¸­å¹´å±¤', 'ã‚·ãƒ‹ã‚¢å±¤', 'é«˜é½¢å±¤'])

# ãƒ“ãƒ³ã®å¢ƒç•Œã‚’è¡¨ç¤º
print("\n--- ç­‰å¹…ãƒ“ãƒ‹ãƒ³ã‚° ---")
for i, edge in enumerate(kbd_uniform.bin_edges_[0]):
    print(f"å¢ƒç•Œ {i}: {edge:.2f}")

print("\n--- ç­‰é »åº¦ãƒ“ãƒ‹ãƒ³ã‚° ---")
for i, edge in enumerate(kbd_quantile.bin_edges_[0]):
    print(f"å¢ƒç•Œ {i}: {edge:.2f}")

# å¯è¦–åŒ–
fig, axes = plt.subplots(2, 2, figsize=(14, 12))

# å…ƒãƒ‡ãƒ¼ã‚¿ã®ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ 
axes[0, 0].hist(ages, bins=30, edgecolor='black', alpha=0.7, color='steelblue')
axes[0, 0].set_xlabel('å¹´é½¢', fontsize=12)
axes[0, 0].set_ylabel('é »åº¦', fontsize=12)
axes[0, 0].set_title('å…ƒãƒ‡ãƒ¼ã‚¿', fontsize=14)
axes[0, 0].grid(True, alpha=0.3)

# ç­‰å¹…ãƒ“ãƒ‹ãƒ³ã‚°
for i in range(5):
    mask = age_binned_uniform.flatten() == i
    axes[0, 1].hist(ages[mask], bins=10, alpha=0.7, label=f'Bin {i}')
axes[0, 1].set_xlabel('å¹´é½¢', fontsize=12)
axes[0, 1].set_ylabel('é »åº¦', fontsize=12)
axes[0, 1].set_title('ç­‰å¹…ãƒ“ãƒ‹ãƒ³ã‚°ï¼ˆå„ãƒ“ãƒ³ã®å¹…ãŒåŒã˜ï¼‰', fontsize=14)
axes[0, 1].legend()
axes[0, 1].grid(True, alpha=0.3)

# ç­‰é »åº¦ãƒ“ãƒ‹ãƒ³ã‚°
for i in range(5):
    mask = age_binned_quantile.flatten() == i
    axes[1, 0].hist(ages[mask], bins=10, alpha=0.7, label=f'Bin {i}')
axes[1, 0].set_xlabel('å¹´é½¢', fontsize=12)
axes[1, 0].set_ylabel('é »åº¦', fontsize=12)
axes[1, 0].set_title('ç­‰é »åº¦ãƒ“ãƒ‹ãƒ³ã‚°ï¼ˆå„ãƒ“ãƒ³ã®ãƒ‡ãƒ¼ã‚¿æ•°ãŒåŒã˜ï¼‰', fontsize=14)
axes[1, 0].legend()
axes[1, 0].grid(True, alpha=0.3)

# ã‚«ã‚¹ã‚¿ãƒ ãƒ“ãƒ‹ãƒ³ã‚°
age_custom_bins.value_counts().sort_index().plot(kind='bar',
                                                   ax=axes[1, 1],
                                                   color='green',
                                                   alpha=0.7)
axes[1, 1].set_xlabel('å¹´é½¢å±¤', fontsize=12)
axes[1, 1].set_ylabel('ãƒ‡ãƒ¼ã‚¿æ•°', fontsize=12)
axes[1, 1].set_title('ã‚«ã‚¹ã‚¿ãƒ ãƒ“ãƒ‹ãƒ³ã‚°ï¼ˆãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ï¼‰', fontsize=14)
axes[1, 1].tick_params(axis='x', rotation=45)
axes[1, 1].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

# å„ãƒ“ãƒ³ã®ãƒ‡ãƒ¼ã‚¿æ•°
print("\n--- ãƒ‡ãƒ¼ã‚¿æ•°ã®æ¯”è¼ƒ ---")
print(f"ç­‰å¹…ãƒ“ãƒ‹ãƒ³ã‚°: {np.bincount(age_binned_uniform.astype(int).flatten())}")
print(f"ç­‰é »åº¦ãƒ“ãƒ‹ãƒ³ã‚°: {np.bincount(age_binned_quantile.astype(int).flatten())}")
print(f"ã‚«ã‚¹ã‚¿ãƒ ãƒ“ãƒ‹ãƒ³ã‚°: {age_custom_bins.value_counts().sort_index().values}")
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>=== ãƒ“ãƒ‹ãƒ³ã‚° ===
å¹´é½¢ãƒ‡ãƒ¼ã‚¿: æœ€å°=18.0, æœ€å¤§=79.9, å¹³å‡=40.1

--- ç­‰å¹…ãƒ“ãƒ‹ãƒ³ã‚° ---
å¢ƒç•Œ 0: 18.00
å¢ƒç•Œ 1: 30.38
å¢ƒç•Œ 2: 42.76
å¢ƒç•Œ 3: 55.14
å¢ƒç•Œ 4: 67.52
å¢ƒç•Œ 5: 79.90

--- ç­‰é »åº¦ãƒ“ãƒ‹ãƒ³ã‚° ---
å¢ƒç•Œ 0: 18.00
å¢ƒç•Œ 1: 30.89
å¢ƒç•Œ 2: 38.12
å¢ƒç•Œ 3: 46.54
å¢ƒç•Œ 4: 56.23
å¢ƒç•Œ 5: 79.90

--- ãƒ‡ãƒ¼ã‚¿æ•°ã®æ¯”è¼ƒ ---
ç­‰å¹…ãƒ“ãƒ‹ãƒ³ã‚°: [172 136  99  65  28]
ç­‰é »åº¦ãƒ“ãƒ‹ãƒ³ã‚°: [100 100 100 100 100]
ã‚«ã‚¹ã‚¿ãƒ ãƒ“ãƒ‹ãƒ³ã‚°: [ 76 112 167 111  34]
</code></pre>

<h3>ãƒ“ãƒ‹ãƒ³ã‚°ã®ãƒ¡ãƒªãƒƒãƒˆãƒ»ãƒ‡ãƒ¡ãƒªãƒƒãƒˆ</h3>

<table>
<thead>
<tr>
<th>é …ç›®</th>
<th>ãƒ¡ãƒªãƒƒãƒˆ</th>
<th>ãƒ‡ãƒ¡ãƒªãƒƒãƒˆ</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>è§£é‡ˆæ€§</strong></td>
<td>ã‚«ãƒ†ã‚´ãƒªã¨ã—ã¦ç†è§£ã—ã‚„ã™ã„</td>
<td>å…ƒã®è©³ç´°æƒ…å ±ãŒå¤±ã‚ã‚Œã‚‹</td>
</tr>
<tr>
<td><strong>å¤–ã‚Œå€¤</strong></td>
<td>å¤–ã‚Œå€¤ã®å½±éŸ¿ã‚’è»½æ¸›</td>
<td>æœ‰ç”¨ãªæƒ…å ±ã‚‚å¹³æ»‘åŒ–ã•ã‚Œã‚‹</td>
</tr>
<tr>
<td><strong>éç·šå½¢æ€§</strong></td>
<td>éç·šå½¢é–¢ä¿‚ã‚’æ•æ‰ã§ãã‚‹</td>
<td>ãƒ“ãƒ³æ•°ã®é¸æŠãŒé›£ã—ã„</td>
</tr>
<tr>
<td><strong>ãƒ¢ãƒ‡ãƒ«</strong></td>
<td>ç·šå½¢ãƒ¢ãƒ‡ãƒ«ã§éšæ®µçŠ¶ã®é–¢ä¿‚ã‚’è¡¨ç¾</td>
<td>æ±ºå®šæœ¨ç³»ã«ã¯ä¸è¦</td>
</tr>
</tbody>
</table>

<hr>

<h2>3.4 å¤šé …å¼ç‰¹å¾´é‡</h2>

<h3>æ¦‚è¦</h3>

<p><strong>å¤šé …å¼ç‰¹å¾´é‡</strong>ã¯ã€å…ƒã®ç‰¹å¾´é‡ã®ã¹ãä¹—ã‚„çµ„åˆã›ã‚’ä½œã‚‹ã“ã¨ã§ã€éç·šå½¢é–¢ä¿‚ã‚’æ•æ‰ã—ã¾ã™ã€‚</p>

<p>ä¾‹ãˆã°ã€ç‰¹å¾´é‡ $x_1, x_2$ ã‹ã‚‰2æ¬¡ã®å¤šé …å¼ç‰¹å¾´é‡ã‚’ç”Ÿæˆã™ã‚‹ã¨ï¼š</p>

<p>$$
[x_1, x_2] \rightarrow [1, x_1, x_2, x_1^2, x_1 x_2, x_2^2]
$$</p>

<h3>å®Ÿè£…ä¾‹: PolynomialFeatures</h3>

<pre><code class="language-python">from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# éç·šå½¢ãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆ
np.random.seed(42)
X_poly = np.random.uniform(-3, 3, 200).reshape(-1, 1)
y_poly = 0.5 * X_poly**2 + X_poly + 2 + np.random.normal(0, 0.5, X_poly.shape)

# ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
X_train, X_test, y_train, y_test = train_test_split(
    X_poly, y_poly, test_size=0.3, random_state=42
)

# ãƒ¢ãƒ‡ãƒ«1: ç·šå½¢å›å¸°ï¼ˆå¤šé …å¼ç‰¹å¾´é‡ãªã—ï¼‰
model_linear = LinearRegression()
model_linear.fit(X_train, y_train)
y_pred_linear = model_linear.predict(X_test)

# ãƒ¢ãƒ‡ãƒ«2: 2æ¬¡å¤šé …å¼ç‰¹å¾´é‡
poly2 = PolynomialFeatures(degree=2, include_bias=True)
X_train_poly2 = poly2.fit_transform(X_train)
X_test_poly2 = poly2.transform(X_test)

model_poly2 = LinearRegression()
model_poly2.fit(X_train_poly2, y_train)
y_pred_poly2 = model_poly2.predict(X_test_poly2)

# ãƒ¢ãƒ‡ãƒ«3: 3æ¬¡å¤šé …å¼ç‰¹å¾´é‡
poly3 = PolynomialFeatures(degree=3, include_bias=True)
X_train_poly3 = poly3.fit_transform(X_train)
X_test_poly3 = poly3.transform(X_test)

model_poly3 = LinearRegression()
model_poly3.fit(X_train_poly3, y_train)
y_pred_poly3 = model_poly3.predict(X_test_poly3)

# è©•ä¾¡
print("=== å¤šé …å¼ç‰¹å¾´é‡ã®åŠ¹æœ ===")
print(f"ç·šå½¢å›å¸°: RMSE={np.sqrt(mean_squared_error(y_test, y_pred_linear)):.4f}, "
      f"RÂ²={r2_score(y_test, y_pred_linear):.4f}")
print(f"2æ¬¡å¤šé …å¼: RMSE={np.sqrt(mean_squared_error(y_test, y_pred_poly2)):.4f}, "
      f"RÂ²={r2_score(y_test, y_pred_poly2):.4f}")
print(f"3æ¬¡å¤šé …å¼: RMSE={np.sqrt(mean_squared_error(y_test, y_pred_poly3)):.4f}, "
      f"RÂ²={r2_score(y_test, y_pred_poly3):.4f}")

# ç”Ÿæˆã•ã‚ŒãŸç‰¹å¾´é‡
print(f"\nå…ƒã®ç‰¹å¾´é‡æ•°: {X_train.shape[1]}")
print(f"2æ¬¡å¤šé …å¼å¾Œã®ç‰¹å¾´é‡æ•°: {X_train_poly2.shape[1]}")
print(f"3æ¬¡å¤šé …å¼å¾Œã®ç‰¹å¾´é‡æ•°: {X_train_poly3.shape[1]}")
print(f"2æ¬¡å¤šé …å¼ã®ç‰¹å¾´é‡å: {poly2.get_feature_names_out(['x'])}")

# å¯è¦–åŒ–
X_range = np.linspace(-3, 3, 300).reshape(-1, 1)
y_pred_range_linear = model_linear.predict(X_range)
y_pred_range_poly2 = model_poly2.predict(poly2.transform(X_range))
y_pred_range_poly3 = model_poly3.predict(poly3.transform(X_range))

plt.figure(figsize=(14, 6))

# å·¦: ãƒ‡ãƒ¼ã‚¿ã¨äºˆæ¸¬æ›²ç·š
plt.subplot(1, 2, 1)
plt.scatter(X_test, y_test, alpha=0.5, label='ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿', color='gray')
plt.plot(X_range, y_pred_range_linear, linewidth=2, label='ç·šå½¢å›å¸°', color='blue')
plt.plot(X_range, y_pred_range_poly2, linewidth=2, label='2æ¬¡å¤šé …å¼', color='green')
plt.plot(X_range, y_pred_range_poly3, linewidth=2, label='3æ¬¡å¤šé …å¼', color='red', linestyle='--')
plt.xlabel('x', fontsize=12)
plt.ylabel('y', fontsize=12)
plt.title('å¤šé …å¼ç‰¹å¾´é‡ã«ã‚ˆã‚‹å›å¸°', fontsize=14)
plt.legend()
plt.grid(True, alpha=0.3)

# å³: æ®‹å·®ãƒ—ãƒ­ãƒƒãƒˆ
plt.subplot(1, 2, 2)
residuals_linear = y_test - y_pred_linear
residuals_poly2 = y_test - y_pred_poly2
residuals_poly3 = y_test - y_pred_poly3

plt.scatter(y_pred_linear, residuals_linear, alpha=0.5, label='ç·šå½¢å›å¸°', color='blue')
plt.scatter(y_pred_poly2, residuals_poly2, alpha=0.5, label='2æ¬¡å¤šé …å¼', color='green')
plt.scatter(y_pred_poly3, residuals_poly3, alpha=0.5, label='3æ¬¡å¤šé …å¼', color='red')
plt.axhline(y=0, color='black', linestyle='--', linewidth=1)
plt.xlabel('äºˆæ¸¬å€¤', fontsize=12)
plt.ylabel('æ®‹å·®', fontsize=12)
plt.title('æ®‹å·®ãƒ—ãƒ­ãƒƒãƒˆ', fontsize=14)
plt.legend()
plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>=== å¤šé …å¼ç‰¹å¾´é‡ã®åŠ¹æœ ===
ç·šå½¢å›å¸°: RMSE=1.8456, RÂ²=0.4821
2æ¬¡å¤šé …å¼: RMSE=0.5234, RÂ²=0.9567
3æ¬¡å¤šé …å¼: RMSE=0.5289, RÂ²=0.9558

å…ƒã®ç‰¹å¾´é‡æ•°: 1
2æ¬¡å¤šé …å¼å¾Œã®ç‰¹å¾´é‡æ•°: 3
3æ¬¡å¤šé …å¼å¾Œã®ç‰¹å¾´é‡æ•°: 4
2æ¬¡å¤šé …å¼ã®ç‰¹å¾´é‡å: ['1' 'x' 'x^2']
</code></pre>

<h3>äº¤äº’ä½œç”¨é …ã®é‡è¦æ€§</h3>

<pre><code class="language-python"># 2ã¤ã®ç‰¹å¾´é‡ãŒã‚ã‚‹å ´åˆ
np.random.seed(42)
X1 = np.random.uniform(0, 10, 200)
X2 = np.random.uniform(0, 10, 200)

# äº¤äº’ä½œç”¨ãŒã‚ã‚‹ç›®çš„å¤‰æ•°: y = X1 + X2 + 0.5 * X1 * X2
y_interact = X1 + X2 + 0.5 * X1 * X2 + np.random.normal(0, 1, 200)

X_interact = np.column_stack([X1, X2])

# ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
X_train_int, X_test_int, y_train_int, y_test_int = train_test_split(
    X_interact, y_interact, test_size=0.3, random_state=42
)

# ãƒ¢ãƒ‡ãƒ«1: äº¤äº’ä½œç”¨é …ãªã—
model_no_interact = LinearRegression()
model_no_interact.fit(X_train_int, y_train_int)
y_pred_no_interact = model_no_interact.predict(X_test_int)

# ãƒ¢ãƒ‡ãƒ«2: äº¤äº’ä½œç”¨é …ã‚ã‚Šï¼ˆinteraction_only=Trueï¼‰
poly_interact = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)
X_train_interact = poly_interact.fit_transform(X_train_int)
X_test_interact = poly_interact.transform(X_test_int)

model_interact = LinearRegression()
model_interact.fit(X_train_interact, y_train_int)
y_pred_interact = model_interact.predict(X_test_interact)

# ãƒ¢ãƒ‡ãƒ«3: å®Œå…¨ãª2æ¬¡å¤šé …å¼ï¼ˆã¹ãä¹—é …ã‚‚å«ã‚€ï¼‰
poly_full = PolynomialFeatures(degree=2, include_bias=False)
X_train_full = poly_full.fit_transform(X_train_int)
X_test_full = poly_full.transform(X_test_int)

model_full = LinearRegression()
model_full.fit(X_train_full, y_train_int)
y_pred_full = model_full.predict(X_test_full)

print("=== äº¤äº’ä½œç”¨é …ã®åŠ¹æœ ===")
print(f"äº¤äº’ä½œç”¨ãªã—: RMSE={np.sqrt(mean_squared_error(y_test_int, y_pred_no_interact)):.4f}, "
      f"RÂ²={r2_score(y_test_int, y_pred_no_interact):.4f}")
print(f"äº¤äº’ä½œç”¨ã®ã¿: RMSE={np.sqrt(mean_squared_error(y_test_int, y_pred_interact)):.4f}, "
      f"RÂ²={r2_score(y_test_int, y_pred_interact):.4f}")
print(f"å®Œå…¨ãª2æ¬¡: RMSE={np.sqrt(mean_squared_error(y_test_int, y_pred_full)):.4f}, "
      f"RÂ²={r2_score(y_test_int, y_pred_full):.4f}")

print(f"\näº¤äº’ä½œç”¨ã®ã¿ã®ç‰¹å¾´é‡: {poly_interact.get_feature_names_out(['X1', 'X2'])}")
print(f"å®Œå…¨ãª2æ¬¡ã®ç‰¹å¾´é‡: {poly_full.get_feature_names_out(['X1', 'X2'])}")

# ä¿‚æ•°ã®æ¯”è¼ƒ
print("\n--- å­¦ç¿’ã•ã‚ŒãŸä¿‚æ•° ---")
print(f"äº¤äº’ä½œç”¨ãªã—: X1={model_no_interact.coef_[0]:.3f}, X2={model_no_interact.coef_[1]:.3f}")
print(f"äº¤äº’ä½œç”¨ã‚ã‚Š: X1={model_interact.coef_[0]:.3f}, X2={model_interact.coef_[1]:.3f}, "
      f"X1*X2={model_interact.coef_[2]:.3f}")
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>=== äº¤äº’ä½œç”¨é …ã®åŠ¹æœ ===
äº¤äº’ä½œç”¨ãªã—: RMSE=12.8456, RÂ²=0.6234
äº¤äº’ä½œç”¨ã®ã¿: RMSE=0.9823, RÂ²=0.9987
å®Œå…¨ãª2æ¬¡: RMSE=0.9876, RÂ²=0.9986

äº¤äº’ä½œç”¨ã®ã¿ã®ç‰¹å¾´é‡: ['X1' 'X2' 'X1 X2']
å®Œå…¨ãª2æ¬¡ã®ç‰¹å¾´é‡: ['X1' 'X2' 'X1^2' 'X1 X2' 'X2^2']

--- å­¦ç¿’ã•ã‚ŒãŸä¿‚æ•° ---
äº¤äº’ä½œç”¨ãªã—: X1=3.567, X2=3.489
äº¤äº’ä½œç”¨ã‚ã‚Š: X1=1.012, X2=0.989, X1*X2=0.498
</code></pre>

<h3>æ¬¡æ•°ã®é¸æŠ</h3>

<table>
<thead>
<tr>
<th>æ¬¡æ•°</th>
<th>ç‰¹å¾´é‡æ•°ï¼ˆpå€‹ã®ç‰¹å¾´é‡ï¼‰</th>
<th>é©ç”¨å ´é¢</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>1æ¬¡</strong></td>
<td>$p$</td>
<td>ç·šå½¢é–¢ä¿‚</td>
</tr>
<tr>
<td><strong>2æ¬¡</strong></td>
<td>$\frac{p(p+3)}{2}$</td>
<td>æ›²ç·šé–¢ä¿‚ã€äº¤äº’ä½œç”¨</td>
</tr>
<tr>
<td><strong>3æ¬¡</strong></td>
<td>$\frac{p(p+1)(p+2)}{6}$</td>
<td>è¤‡é›‘ãªéç·šå½¢é–¢ä¿‚</td>
</tr>
<tr>
<td><strong>äº¤äº’ä½œç”¨ã®ã¿</strong></td>
<td>$p + \frac{p(p-1)}{2}$</td>
<td>ã¹ãä¹—ã¯ä¸è¦</td>
</tr>
</tbody>
</table>

<hr>

<h2>3.5 ãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ç‰¹å¾´é‡</h2>

<h3>æ—¥æ™‚ç‰¹å¾´é‡</h3>

<p>æ—¥æ™‚ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã€å¹´ã€æœˆã€æ›œæ—¥ã€ç¥æ—¥ãªã©ã®æƒ…å ±ã‚’æŠ½å‡ºã—ã¾ã™ã€‚</p>

<h3>å®Ÿè£…ä¾‹: æ—¥æ™‚ç‰¹å¾´é‡ã®æŠ½å‡º</h3>

<pre><code class="language-python">import pandas as pd
from datetime import datetime, timedelta

# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿: å£²ä¸Šãƒ‡ãƒ¼ã‚¿
np.random.seed(42)
dates = pd.date_range('2023-01-01', '2024-12-31', freq='D')
n = len(dates)

# å£²ä¸Šãƒ‡ãƒ¼ã‚¿ï¼ˆæ›œæ—¥ã€å­£ç¯€ã€ç¥æ—¥ã®å½±éŸ¿ã‚’å«ã‚€ï¼‰
df_sales = pd.DataFrame({
    'date': dates,
    'sales': np.random.poisson(100, n) + \
             10 * (dates.dayofweek < 5) + \  # å¹³æ—¥ãƒœãƒ¼ãƒŠã‚¹
             20 * (dates.month.isin([11, 12]))  # å¹´æœ«ãƒœãƒ¼ãƒŠã‚¹
})

print("=== æ—¥æ™‚ç‰¹å¾´é‡ã®ç”Ÿæˆ ===")
print(df_sales.head())

# æ—¥æ™‚ç‰¹å¾´é‡ã®æŠ½å‡º
df_sales['year'] = df_sales['date'].dt.year
df_sales['month'] = df_sales['date'].dt.month
df_sales['day'] = df_sales['date'].dt.day
df_sales['dayofweek'] = df_sales['date'].dt.dayofweek  # 0=æœˆæ›œ, 6=æ—¥æ›œ
df_sales['dayofyear'] = df_sales['date'].dt.dayofyear
df_sales['quarter'] = df_sales['date'].dt.quarter
df_sales['is_weekend'] = (df_sales['dayofweek'] >= 5).astype(int)
df_sales['is_month_start'] = df_sales['date'].dt.is_month_start.astype(int)
df_sales['is_month_end'] = df_sales['date'].dt.is_month_end.astype(int)
df_sales['week_of_year'] = df_sales['date'].dt.isocalendar().week

# å‘¨æœŸçš„ç‰¹å¾´é‡ï¼ˆsin/coså¤‰æ›ï¼‰
df_sales['month_sin'] = np.sin(2 * np.pi * df_sales['month'] / 12)
df_sales['month_cos'] = np.cos(2 * np.pi * df_sales['month'] / 12)
df_sales['dayofweek_sin'] = np.sin(2 * np.pi * df_sales['dayofweek'] / 7)
df_sales['dayofweek_cos'] = np.cos(2 * np.pi * df_sales['dayofweek'] / 7)

print("\n--- ç”Ÿæˆã•ã‚ŒãŸç‰¹å¾´é‡ ---")
print(df_sales.head(10))
print(f"\nç‰¹å¾´é‡æ•°: {df_sales.shape[1]}")

# å¯è¦–åŒ–
fig, axes = plt.subplots(2, 2, figsize=(15, 10))

# æ›œæ—¥åˆ¥å£²ä¸Š
dayofweek_sales = df_sales.groupby('dayofweek')['sales'].mean()
axes[0, 0].bar(range(7), dayofweek_sales.values, color='steelblue', alpha=0.7)
axes[0, 0].set_xlabel('æ›œæ—¥', fontsize=12)
axes[0, 0].set_ylabel('å¹³å‡å£²ä¸Š', fontsize=12)
axes[0, 0].set_title('æ›œæ—¥åˆ¥å¹³å‡å£²ä¸Š', fontsize=14)
axes[0, 0].set_xticks(range(7))
axes[0, 0].set_xticklabels(['æœˆ', 'ç«', 'æ°´', 'æœ¨', 'é‡‘', 'åœŸ', 'æ—¥'])
axes[0, 0].grid(True, alpha=0.3)

# æœˆåˆ¥å£²ä¸Š
month_sales = df_sales.groupby('month')['sales'].mean()
axes[0, 1].bar(range(1, 13), month_sales.values, color='green', alpha=0.7)
axes[0, 1].set_xlabel('æœˆ', fontsize=12)
axes[0, 1].set_ylabel('å¹³å‡å£²ä¸Š', fontsize=12)
axes[0, 1].set_title('æœˆåˆ¥å¹³å‡å£²ä¸Š', fontsize=14)
axes[0, 1].grid(True, alpha=0.3)

# å‘¨æœŸçš„ç‰¹å¾´é‡ã®å¯è¦–åŒ–ï¼ˆæœˆï¼‰
axes[1, 0].scatter(df_sales['month_sin'], df_sales['month_cos'],
                  c=df_sales['month'], cmap='viridis', alpha=0.6)
axes[1, 0].set_xlabel('month_sin', fontsize=12)
axes[1, 0].set_ylabel('month_cos', fontsize=12)
axes[1, 0].set_title('æœˆã®å‘¨æœŸçš„è¡¨ç¾ï¼ˆsin/cosï¼‰', fontsize=14)
axes[1, 0].grid(True, alpha=0.3)

# æ™‚ç³»åˆ—ãƒ—ãƒ­ãƒƒãƒˆï¼ˆ3ãƒ¶æœˆåˆ†ï¼‰
df_sample = df_sales[df_sales['date'] < '2023-04-01']
axes[1, 1].plot(df_sample['date'], df_sample['sales'], linewidth=1, color='steelblue')
axes[1, 1].set_xlabel('æ—¥ä»˜', fontsize=12)
axes[1, 1].set_ylabel('å£²ä¸Š', fontsize=12)
axes[1, 1].set_title('å£²ä¸Šã®æ™‚ç³»åˆ—ï¼ˆ2023å¹´1-3æœˆï¼‰', fontsize=14)
axes[1, 1].grid(True, alpha=0.3)
axes[1, 1].tick_params(axis='x', rotation=45)

plt.tight_layout()
plt.show()
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>=== æ—¥æ™‚ç‰¹å¾´é‡ã®ç”Ÿæˆ ===
        date  sales
0 2023-01-01    105
1 2023-01-02    118
2 2023-01-03    113
3 2023-01-04    121
4 2023-01-05    115

--- ç”Ÿæˆã•ã‚ŒãŸç‰¹å¾´é‡ ---
ç‰¹å¾´é‡æ•°: 16
</code></pre>

<h3>ãƒ†ã‚­ã‚¹ãƒˆç‰¹å¾´é‡</h3>

<pre><code class="language-python"># ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ç‰¹å¾´é‡ã‚’ç”Ÿæˆ
texts = [
    "Machine Learning is awesome!",
    "Deep learning revolutionizes AI",
    "Natural Language Processing",
    "Computer Vision applications",
    "Data Science for everyone"
]

df_text = pd.DataFrame({'text': texts})

# åŸºæœ¬çš„ãªç‰¹å¾´é‡
df_text['text_length'] = df_text['text'].str.len()
df_text['word_count'] = df_text['text'].str.split().str.len()
df_text['avg_word_length'] = df_text['text_length'] / df_text['word_count']
df_text['uppercase_count'] = df_text['text'].str.count(r'[A-Z]')
df_text['digit_count'] = df_text['text'].str.count(r'\d')
df_text['special_char_count'] = df_text['text'].str.count(r'[!@#$%^&*(),.?":{}|<>]')

# ç‰¹å®šã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®æœ‰ç„¡
df_text['has_learning'] = df_text['text'].str.contains('learning', case=False).astype(int)
df_text['has_ai'] = df_text['text'].str.contains('AI|artificial', case=False).astype(int)

print("=== ãƒ†ã‚­ã‚¹ãƒˆç‰¹å¾´é‡ ===")
print(df_text)

# TF-IDFç‰¹å¾´é‡ï¼ˆå‚è€ƒï¼‰
from sklearn.feature_extraction.text import TfidfVectorizer

tfidf = TfidfVectorizer(max_features=10, stop_words='english')
tfidf_features = tfidf.fit_transform(texts).toarray()

print("\n--- TF-IDFç‰¹å¾´é‡ ---")
print(f"ç‰¹å¾´é‡æ•°: {tfidf_features.shape[1]}")
print(f"ç‰¹å¾´é‡å: {tfidf.get_feature_names_out()}")
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>=== ãƒ†ã‚­ã‚¹ãƒˆç‰¹å¾´é‡ ===
                              text  text_length  word_count  avg_word_length  ...
0  Machine Learning is awesome!            29           4             7.25  ...
1  Deep learning revolutionizes AI           31           4             7.75  ...
2  Natural Language Processing            27           3             9.00  ...
3  Computer Vision applications             28           3             9.33  ...
4  Data Science for everyone                25           4             6.25  ...

--- TF-IDFç‰¹å¾´é‡ ---
ç‰¹å¾´é‡æ•°: 10
ç‰¹å¾´é‡å: ['ai' 'applications' 'awesome' 'computer' 'data' 'deep' 'learning' 'machine' 'natural' 'processing']
</code></pre>

<h3>é›†ç´„ç‰¹å¾´é‡</h3>

<pre><code class="language-python"># ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³¼è²·å±¥æ­´
np.random.seed(42)
df_purchase = pd.DataFrame({
    'user_id': np.repeat(range(1, 101), 10),
    'product_id': np.random.randint(1, 50, 1000),
    'price': np.random.uniform(10, 500, 1000),
    'quantity': np.random.randint(1, 5, 1000)
})

df_purchase['total_amount'] = df_purchase['price'] * df_purchase['quantity']

print("=== é›†ç´„ç‰¹å¾´é‡ã®ç”Ÿæˆ ===")
print(df_purchase.head(10))

# ãƒ¦ãƒ¼ã‚¶ãƒ¼ã”ã¨ã®é›†ç´„çµ±è¨ˆé‡
user_features = df_purchase.groupby('user_id').agg({
    'total_amount': ['sum', 'mean', 'std', 'min', 'max', 'count'],
    'price': ['mean', 'std'],
    'quantity': ['sum', 'mean'],
    'product_id': ['nunique']  # ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªå•†å“æ•°
}).reset_index()

# ã‚«ãƒ©ãƒ åã‚’æ•´ç†
user_features.columns = ['user_id',
                        'total_spent', 'avg_purchase', 'std_purchase',
                        'min_purchase', 'max_purchase', 'num_purchases',
                        'avg_price', 'std_price',
                        'total_quantity', 'avg_quantity',
                        'num_unique_products']

# è¿½åŠ ã®ç‰¹å¾´é‡
user_features['purchase_variety'] = user_features['num_unique_products'] / user_features['num_purchases']
user_features['avg_items_per_purchase'] = user_features['total_quantity'] / user_features['num_purchases']
user_features['price_range'] = user_features['max_purchase'] - user_features['min_purchase']

print("\n--- ãƒ¦ãƒ¼ã‚¶ãƒ¼åˆ¥é›†ç´„ç‰¹å¾´é‡ ---")
print(user_features.head(10))
print(f"\nç”Ÿæˆã•ã‚ŒãŸç‰¹å¾´é‡æ•°: {user_features.shape[1] - 1}")  # user_idã‚’é™¤ã

# çµ±è¨ˆé‡ã®å¯è¦–åŒ–
fig, axes = plt.subplots(2, 2, figsize=(14, 10))

# ç·è³¼å…¥é¡ã®åˆ†å¸ƒ
axes[0, 0].hist(user_features['total_spent'], bins=30,
               edgecolor='black', alpha=0.7, color='steelblue')
axes[0, 0].set_xlabel('ç·è³¼å…¥é¡', fontsize=12)
axes[0, 0].set_ylabel('ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°', fontsize=12)
axes[0, 0].set_title('ç·è³¼å…¥é¡ã®åˆ†å¸ƒ', fontsize=14)
axes[0, 0].grid(True, alpha=0.3)

# è³¼å…¥å›æ•° vs ç·è³¼å…¥é¡
axes[0, 1].scatter(user_features['num_purchases'],
                  user_features['total_spent'], alpha=0.6)
axes[0, 1].set_xlabel('è³¼å…¥å›æ•°', fontsize=12)
axes[0, 1].set_ylabel('ç·è³¼å…¥é¡', fontsize=12)
axes[0, 1].set_title('è³¼å…¥å›æ•°ã¨ç·è³¼å…¥é¡ã®é–¢ä¿‚', fontsize=14)
axes[0, 1].grid(True, alpha=0.3)

# å•†å“å¤šæ§˜æ€§ã®åˆ†å¸ƒ
axes[1, 0].hist(user_features['purchase_variety'], bins=20,
               edgecolor='black', alpha=0.7, color='green')
axes[1, 0].set_xlabel('è³¼å…¥å•†å“ã®å¤šæ§˜æ€§', fontsize=12)
axes[1, 0].set_ylabel('ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°', fontsize=12)
axes[1, 0].set_title('è³¼å…¥å•†å“ã®å¤šæ§˜æ€§ï¼ˆunique/totalï¼‰', fontsize=14)
axes[1, 0].grid(True, alpha=0.3)

# å¹³å‡ä¾¡æ ¼ vs æ¨™æº–åå·®
axes[1, 1].scatter(user_features['avg_price'],
                  user_features['std_price'], alpha=0.6, color='red')
axes[1, 1].set_xlabel('å¹³å‡ä¾¡æ ¼', fontsize=12)
axes[1, 1].set_ylabel('ä¾¡æ ¼ã®æ¨™æº–åå·®', fontsize=12)
axes[1, 1].set_title('å¹³å‡ä¾¡æ ¼ã¨ä¾¡æ ¼ã®ã°ã‚‰ã¤ã', fontsize=14)
axes[1, 1].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>=== é›†ç´„ç‰¹å¾´é‡ã®ç”Ÿæˆ ===
   user_id  product_id   price  quantity  total_amount
0        1          40  234.56         3        703.68
1        1          23  123.45         2        246.90
...

--- ãƒ¦ãƒ¼ã‚¶ãƒ¼åˆ¥é›†ç´„ç‰¹å¾´é‡ ---
   user_id  total_spent  avg_purchase  ...  avg_items_per_purchase  price_range
0        1      5234.56        523.46  ...                    2.30       678.90
1        2      6789.12        678.91  ...                    2.50       890.23
...

ç”Ÿæˆã•ã‚ŒãŸç‰¹å¾´é‡æ•°: 14
</code></pre>

<hr>

<h2>3.6 å®Ÿè·µä¾‹: Kaggleçš„ç‰¹å¾´é‡ç”Ÿæˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³</h2>

<h3>å•é¡Œè¨­å®š</h3>

<p>ä½å®…ä¾¡æ ¼äºˆæ¸¬ã®ãŸã‚ã®åŒ…æ‹¬çš„ãªç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã‚’å®Ÿè£…ã—ã¾ã™ã€‚</p>

<h3>å®Ÿè£…ä¾‹: å®Œå…¨ãªç‰¹å¾´é‡ç”Ÿæˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³</h3>

<pre><code class="language-python">from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
housing = fetch_california_housing()
X_original = pd.DataFrame(housing.data, columns=housing.feature_names)
y = housing.target

print("=== Kaggleçš„ç‰¹å¾´é‡ç”Ÿæˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ ===")
print(f"å…ƒã®ç‰¹å¾´é‡æ•°: {X_original.shape[1]}")
print("\nå…ƒã®ç‰¹å¾´é‡:")
print(X_original.head())

# ===== ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚° =====

X_fe = X_original.copy()

# 1. æ•°å€¤å¤‰æ›
X_fe['Population_log'] = np.log1p(X_fe['Population'])
X_fe['AveRooms_log'] = np.log1p(X_fe['AveRooms'])

# 2. ãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ç‰¹å¾´é‡
X_fe['RoomsPerHousehold'] = X_fe['AveRooms'] / X_fe['AveBedrms']
X_fe['PopulationPerHousehold'] = X_fe['Population'] / X_fe['HouseAge']
X_fe['BedroomsRatio'] = X_fe['AveBedrms'] / X_fe['AveRooms']

# 3. çµ±è¨ˆçš„ç‰¹å¾´é‡
X_fe['Income_squared'] = X_fe['MedInc'] ** 2
X_fe['AveRooms_squared'] = X_fe['AveRooms'] ** 2

# 4. äº¤äº’ä½œç”¨é …
X_fe['Income_x_Rooms'] = X_fe['MedInc'] * X_fe['AveRooms']
X_fe['Income_x_HouseAge'] = X_fe['MedInc'] * X_fe['HouseAge']
X_fe['Latitude_x_Longitude'] = X_fe['Latitude'] * X_fe['Longitude']

# 5. ãƒ“ãƒ‹ãƒ³ã‚°
X_fe['Income_binned'] = pd.cut(X_fe['MedInc'], bins=5, labels=False)
X_fe['HouseAge_binned'] = pd.cut(X_fe['HouseAge'], bins=5, labels=False)

# 6. é›†ç´„ç‰¹å¾´é‡ï¼ˆåœ°ç†çš„ãªé›†ç´„ï¼‰
# ç·¯åº¦ãƒ»çµŒåº¦ã‚’ã‚°ãƒªãƒƒãƒ‰åŒ–
X_fe['Lat_grid'] = (X_fe['Latitude'] * 10).astype(int)
X_fe['Lon_grid'] = (X_fe['Longitude'] * 10).astype(int)
X_fe['Grid_id'] = X_fe['Lat_grid'].astype(str) + '_' + X_fe['Lon_grid'].astype(str)

# ã‚°ãƒªãƒƒãƒ‰ã”ã¨ã®çµ±è¨ˆé‡
grid_stats = X_fe.groupby('Grid_id')['MedInc'].agg(['mean', 'std', 'count']).reset_index()
grid_stats.columns = ['Grid_id', 'Grid_avg_income', 'Grid_std_income', 'Grid_count']

X_fe = X_fe.merge(grid_stats, on='Grid_id', how='left')

# ã‚°ãƒªãƒƒãƒ‰çµ±è¨ˆã¨ã®å·®åˆ†
X_fe['Income_vs_grid_avg'] = X_fe['MedInc'] - X_fe['Grid_avg_income']

# ä¸è¦ãªã‚«ãƒ©ãƒ ã‚’å‰Šé™¤
X_fe = X_fe.drop(['Lat_grid', 'Lon_grid', 'Grid_id'], axis=1)

print(f"\nç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°å¾Œã®ç‰¹å¾´é‡æ•°: {X_fe.shape[1]}")
print("\nç”Ÿæˆã•ã‚ŒãŸç‰¹å¾´é‡:")
print(X_fe.head())

# ===== ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ =====

# ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
X_train_orig, X_test_orig, y_train, y_test = train_test_split(
    X_original, y, test_size=0.2, random_state=42
)

X_train_fe, X_test_fe, _, _ = train_test_split(
    X_fe, y, test_size=0.2, random_state=42
)

# ãƒ¢ãƒ‡ãƒ«1: å…ƒã®ç‰¹å¾´é‡
model_orig = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)
model_orig.fit(X_train_orig, y_train)
y_pred_orig = model_orig.predict(X_test_orig)

# ãƒ¢ãƒ‡ãƒ«2: ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°å¾Œ
model_fe = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)
model_fe.fit(X_train_fe, y_train)
y_pred_fe = model_fe.predict(X_test_fe)

# è©•ä¾¡
print("\n=== ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ã®æ¯”è¼ƒ ===")
print(f"ã€å…ƒã®ç‰¹å¾´é‡ã€‘")
print(f"  RMSE: {np.sqrt(mean_squared_error(y_test, y_pred_orig)):.4f}")
print(f"  MAE: {mean_absolute_error(y_test, y_pred_orig):.4f}")
print(f"  RÂ²: {r2_score(y_test, y_pred_orig):.4f}")

print(f"\nã€ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°å¾Œã€‘")
print(f"  RMSE: {np.sqrt(mean_squared_error(y_test, y_pred_fe)):.4f}")
print(f"  MAE: {mean_absolute_error(y_test, y_pred_fe):.4f}")
print(f"  RÂ²: {r2_score(y_test, y_pred_fe):.4f}")

# ç‰¹å¾´é‡é‡è¦åº¦
importances_fe = model_fe.feature_importances_
indices = np.argsort(importances_fe)[::-1][:15]

print("\n--- Top 15 é‡è¦ãªç‰¹å¾´é‡ ---")
for i, idx in enumerate(indices, 1):
    print(f"{i}. {X_fe.columns[idx]}: {importances_fe[idx]:.4f}")

# å¯è¦–åŒ–
fig, axes = plt.subplots(2, 2, figsize=(15, 12))

# äºˆæ¸¬å€¤ vs å®Ÿæ¸¬å€¤ï¼ˆå…ƒã®ç‰¹å¾´é‡ï¼‰
axes[0, 0].scatter(y_test, y_pred_orig, alpha=0.5, color='blue')
axes[0, 0].plot([y_test.min(), y_test.max()],
               [y_test.min(), y_test.max()],
               'r--', linewidth=2)
axes[0, 0].set_xlabel('å®Ÿæ¸¬å€¤', fontsize=12)
axes[0, 0].set_ylabel('äºˆæ¸¬å€¤', fontsize=12)
axes[0, 0].set_title(f'å…ƒã®ç‰¹å¾´é‡ (RÂ²={r2_score(y_test, y_pred_orig):.4f})', fontsize=14)
axes[0, 0].grid(True, alpha=0.3)

# äºˆæ¸¬å€¤ vs å®Ÿæ¸¬å€¤ï¼ˆFEå¾Œï¼‰
axes[0, 1].scatter(y_test, y_pred_fe, alpha=0.5, color='green')
axes[0, 1].plot([y_test.min(), y_test.max()],
               [y_test.min(), y_test.max()],
               'r--', linewidth=2)
axes[0, 1].set_xlabel('å®Ÿæ¸¬å€¤', fontsize=12)
axes[0, 1].set_ylabel('äºˆæ¸¬å€¤', fontsize=12)
axes[0, 1].set_title(f'FEå¾Œ (RÂ²={r2_score(y_test, y_pred_fe):.4f})', fontsize=14)
axes[0, 1].grid(True, alpha=0.3)

# æ®‹å·®åˆ†å¸ƒã®æ¯”è¼ƒ
residuals_orig = y_test - y_pred_orig
residuals_fe = y_test - y_pred_fe

axes[1, 0].hist(residuals_orig, bins=50, alpha=0.5, label='å…ƒ', color='blue', edgecolor='black')
axes[1, 0].hist(residuals_fe, bins=50, alpha=0.5, label='FEå¾Œ', color='green', edgecolor='black')
axes[1, 0].set_xlabel('æ®‹å·®', fontsize=12)
axes[1, 0].set_ylabel('é »åº¦', fontsize=12)
axes[1, 0].set_title('æ®‹å·®ã®åˆ†å¸ƒ', fontsize=14)
axes[1, 0].legend()
axes[1, 0].grid(True, alpha=0.3)

# ç‰¹å¾´é‡é‡è¦åº¦
top_features = X_fe.columns[indices[:15]]
top_importances = importances_fe[indices[:15]]

axes[1, 1].barh(range(len(top_features)), top_importances, color='steelblue', alpha=0.7)
axes[1, 1].set_yticks(range(len(top_features)))
axes[1, 1].set_yticklabels(top_features, fontsize=10)
axes[1, 1].set_xlabel('é‡è¦åº¦', fontsize=12)
axes[1, 1].set_title('Top 15 ç‰¹å¾´é‡é‡è¦åº¦', fontsize=14)
axes[1, 1].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

# æ€§èƒ½æ”¹å–„ç‡
rmse_improvement = (np.sqrt(mean_squared_error(y_test, y_pred_orig)) -
                   np.sqrt(mean_squared_error(y_test, y_pred_fe))) / \
                   np.sqrt(mean_squared_error(y_test, y_pred_orig)) * 100

print(f"\n=== ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ”¹å–„ ===")
print(f"RMSEæ”¹å–„ç‡: {rmse_improvement:.2f}%")
print(f"ç‰¹å¾´é‡æ•°: {X_original.shape[1]} â†’ {X_fe.shape[1]} ({X_fe.shape[1] - X_original.shape[1]}å€‹è¿½åŠ )")
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>=== Kaggleçš„ç‰¹å¾´é‡ç”Ÿæˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ ===
å…ƒã®ç‰¹å¾´é‡æ•°: 8

å…ƒã®ç‰¹å¾´é‡:
   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  Longitude
0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88    -122.23
...

ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°å¾Œã®ç‰¹å¾´é‡æ•°: 24

ç”Ÿæˆã•ã‚ŒãŸç‰¹å¾´é‡:
   MedInc  HouseAge  ...  Grid_std_income  Income_vs_grid_avg
0  8.3252      41.0  ...          2.45678              0.8765
...

=== ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ã®æ¯”è¼ƒ ===
ã€å…ƒã®ç‰¹å¾´é‡ã€‘
  RMSE: 0.4934
  MAE: 0.3245
  RÂ²: 0.8123

ã€ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°å¾Œã€‘
  RMSE: 0.4567
  MAE: 0.2987
  RÂ²: 0.8456

--- Top 15 é‡è¦ãªç‰¹å¾´é‡ ---
1. MedInc: 0.4234
2. Latitude: 0.1234
3. Longitude: 0.0987
4. Income_x_Rooms: 0.0765
5. Grid_avg_income: 0.0654
...

=== ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ”¹å–„ ===
RMSEæ”¹å–„ç‡: 7.43%
ç‰¹å¾´é‡æ•°: 8 â†’ 24 (16å€‹è¿½åŠ )
</code></pre>

<hr>

<h2>3.7 æœ¬ç« ã®ã¾ã¨ã‚</h2>

<h3>å­¦ã‚“ã ã“ã¨</h3>

<ol>
<li><p><strong>æ•°å€¤å¤‰æ›</strong></p>
<ul>
<li>å¯¾æ•°å¤‰æ›ã§æ­ªã‚“ã åˆ†å¸ƒã‚’æ­£è¦åŒ–</li>
<li>Box-Cox/PowerTransformerã§æœ€é©å¤‰æ›</li>
<li>å¤–ã‚Œå€¤ã®å½±éŸ¿ã‚’è»½æ¸›</li>
</ul></li>
<li><p><strong>ãƒ“ãƒ‹ãƒ³ã‚°</strong></p>
<ul>
<li>ç­‰å¹…ãƒ»ç­‰é »åº¦ãƒ»ã‚«ã‚¹ã‚¿ãƒ ãƒ“ãƒ‹ãƒ³ã‚°</li>
<li>é€£ç¶šå€¤ã‚’ã‚«ãƒ†ã‚´ãƒªåŒ–</li>
<li>è§£é‡ˆæ€§ã¨éç·šå½¢æ€§ã®ãƒãƒ©ãƒ³ã‚¹</li>
</ul></li>
<li><p><strong>å¤šé …å¼ç‰¹å¾´é‡</strong></p>
<ul>
<li>ã¹ãä¹—é …ã§éç·šå½¢é–¢ä¿‚ã‚’æ•æ‰</li>
<li>äº¤äº’ä½œç”¨é …ã§ç‰¹å¾´é‡ã®çµ„åˆã›</li>
<li>æ¬¡æ•°ã®é¸æŠãŒé‡è¦</li>
</ul></li>
<li><p><strong>ãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜ç‰¹å¾´é‡</strong></p>
<ul>
<li>æ—¥æ™‚ç‰¹å¾´é‡ï¼ˆå¹´æœˆæ—¥ã€æ›œæ—¥ã€å‘¨æœŸæ€§ï¼‰</li>
<li>ãƒ†ã‚­ã‚¹ãƒˆç‰¹å¾´é‡ï¼ˆé•·ã•ã€å˜èªæ•°ï¼‰</li>
<li>é›†ç´„ç‰¹å¾´é‡ï¼ˆçµ±è¨ˆé‡ã€ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ï¼‰</li>
</ul></li>
<li><p><strong>å®Ÿè·µãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³</strong></p>
<ul>
<li>è¤‡æ•°ã®å¤‰æ›æ‰‹æ³•ã‚’çµ„åˆã›</li>
<li>ç‰¹å¾´é‡é‡è¦åº¦ã§åŠ¹æœã‚’æ¤œè¨¼</li>
<li>Kaggleç«¶æŠ€ã§ä½¿ãˆã‚‹æŠ€è¡“</li>
</ul></li>
</ol>

<h3>ç‰¹å¾´é‡å¤‰æ›ã®é¸æŠã‚¬ã‚¤ãƒ‰</h3>

<table>
<thead>
<tr>
<th>ãƒ‡ãƒ¼ã‚¿ã®ç‰¹æ€§</th>
<th>æ¨å¥¨å¤‰æ›</th>
<th>ç†ç”±</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>å³ã«æ­ªã‚“ã åˆ†å¸ƒ</strong></td>
<td>logå¤‰æ›</td>
<td>æ­£è¦åˆ†å¸ƒã«è¿‘ã¥ã‘ã‚‹</td>
</tr>
<tr>
<td><strong>ã‚«ã‚¦ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿</strong></td>
<td>log1p, å¹³æ–¹æ ¹</td>
<td>ã‚¼ãƒ­å€¤ã‚’å®‰å…¨ã«æ‰±ã†</td>
</tr>
<tr>
<td><strong>å¤–ã‚Œå€¤ãŒå¤šã„</strong></td>
<td>ãƒ“ãƒ‹ãƒ³ã‚°</td>
<td>å¤–ã‚Œå€¤ã®å½±éŸ¿ã‚’è»½æ¸›</td>
</tr>
<tr>
<td><strong>éç·šå½¢é–¢ä¿‚</strong></td>
<td>å¤šé …å¼ç‰¹å¾´é‡</td>
<td>æ›²ç·šçš„ãªé–¢ä¿‚ã‚’æ•æ‰</td>
</tr>
<tr>
<td><strong>äº¤äº’ä½œç”¨ãŒã‚ã‚‹</strong></td>
<td>äº¤äº’ä½œç”¨é …</td>
<td>ç‰¹å¾´é‡ã®çµ„åˆã›åŠ¹æœ</td>
</tr>
<tr>
<td><strong>æ—¥æ™‚ãƒ‡ãƒ¼ã‚¿</strong></td>
<td>æ—¥æ™‚åˆ†è§£ + sin/cos</td>
<td>å‘¨æœŸæ€§ã‚’æ•æ‰</td>
</tr>
<tr>
<td><strong>ã‚°ãƒ«ãƒ¼ãƒ—æ§‹é€ </strong></td>
<td>é›†ç´„çµ±è¨ˆé‡</td>
<td>ã‚°ãƒ«ãƒ¼ãƒ—ç‰¹æ€§ã‚’æ•æ‰</td>
</tr>
</tbody>
</table>

<h3>æ¬¡ã®ç« ã¸</h3>

<p>ç¬¬4ç« ã§ã¯ã€<strong>ç‰¹å¾´é‡é¸æŠ</strong>ã‚’å­¦ã³ã¾ã™ï¼š</p>
<ul>
<li>ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ³•ã€ãƒ©ãƒƒãƒ‘ãƒ¼æ³•ã€åŸ‹ã‚è¾¼ã¿æ³•</li>
<li>æ¬¡å…ƒå‰Šæ¸›ã¨ã®çµ„åˆã›</li>
<li>å®Ÿè·µçš„ãªç‰¹å¾´é‡é¸æŠãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³</li>
</ul>

<hr>

<h2>æ¼”ç¿’å•é¡Œ</h2>

<h3>å•é¡Œ1ï¼ˆé›£æ˜“åº¦ï¼šeasyï¼‰</h3>
<p>å¯¾æ•°å¤‰æ›ã¨Box-Coxå¤‰æ›ã®é•ã„ã‚’3ã¤æŒ™ã’ã€ãã‚Œãã‚Œã©ã®ã‚ˆã†ãªå ´é¢ã§ä½¿ã†ã¹ãã‹èª¬æ˜ã—ã¦ãã ã•ã„ã€‚</p>

<details>
<summary>è§£ç­”ä¾‹</summary>

<p><strong>è§£ç­”</strong>ï¼š</p>

<p><strong>å¯¾æ•°å¤‰æ›</strong>ï¼š</p>
<ul>
<li><strong>å®šç¾©</strong>: $y = \log(x)$ ã¾ãŸã¯ $y = \log(x + 1)$</li>
<li><strong>é©ç”¨æ¡ä»¶</strong>: $x > 0$ï¼ˆlog1pã¯$x \geq 0$ï¼‰</li>
<li><strong>ç‰¹å¾´</strong>: ã‚·ãƒ³ãƒ—ãƒ«ã§è§£é‡ˆã—ã‚„ã™ã„</li>
<li><strong>ä½¿ç”¨å ´é¢</strong>: å³ã«æ­ªã‚“ã åˆ†å¸ƒã€ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã€ã‚«ã‚¦ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿</li>
</ul>

<p><strong>Box-Coxå¤‰æ›</strong>ï¼š</p>
<ul>
<li><strong>å®šç¾©</strong>: $\lambda$ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«ã‚ˆã‚‹æŸ”è»Ÿãªå¤‰æ›</li>
<li><strong>é©ç”¨æ¡ä»¶</strong>: $x > 0$ï¼ˆYeo-Johnsonã¯ä»»æ„ã®å€¤ï¼‰</li>
<li><strong>ç‰¹å¾´</strong>: æœ€é©ãªå¤‰æ›ã‚’è‡ªå‹•çš„ã«è¦‹ã¤ã‘ã‚‹</li>
<li><strong>ä½¿ç”¨å ´é¢</strong>: æœ€é©ãªå¤‰æ›ãŒä¸æ˜ã€è¤‡æ•°ç‰¹å¾´é‡ã®ä¸€æ‹¬å¤‰æ›</li>
</ul>

<p><strong>3ã¤ã®ä¸»ãªé•ã„</strong>ï¼š</p>
<ol>
<li><strong>ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿</strong>: å¯¾æ•°å¤‰æ›ã¯å›ºå®šã€Box-Coxã¯æœ€é©ãªÎ»ã‚’æ¢ç´¢</li>
<li><strong>æŸ”è»Ÿæ€§</strong>: Box-Coxã¯å¯¾æ•°å¤‰æ›ã‚’å«ã‚€åºƒç¯„ãªå¤‰æ›ã‚’è¡¨ç¾å¯èƒ½</li>
<li><strong>è§£é‡ˆæ€§</strong>: å¯¾æ•°å¤‰æ›ã¯ç›´æ„Ÿçš„ã€Box-Coxã¯è¤‡é›‘ï¼ˆÎ»ãŒ0ä»¥å¤–ï¼‰</li>
</ol>

<p><strong>ä½¿ã„åˆ†ã‘</strong>ï¼š</p>
<ul>
<li>è§£é‡ˆæ€§é‡è¦–ã€ç°¡å˜ãªå¤‰æ›ã§ååˆ† â†’ å¯¾æ•°å¤‰æ›</li>
<li>æœ€é©ãªå¤‰æ›ã‚’æ¢ç´¢ã€æ€§èƒ½é‡è¦– â†’ Box-Coxå¤‰æ›</li>
<li>è² ã®å€¤ã‚’å«ã‚€ â†’ Yeo-Johnsonå¤‰æ›ï¼ˆBox-Coxã®æ‹¡å¼µï¼‰</li>
</ul>

</details>

<h3>å•é¡Œ2ï¼ˆé›£æ˜“åº¦ï¼šmediumï¼‰</h3>
<p>ä»¥ä¸‹ã®ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦ã€ç­‰å¹…ãƒ“ãƒ‹ãƒ³ã‚°ã¨ç­‰é »åº¦ãƒ“ãƒ‹ãƒ³ã‚°ã‚’é©ç”¨ã—ã€ãã‚Œãã‚Œã®ç‰¹æ€§ã‚’æ¯”è¼ƒã—ã¦ãã ã•ã„ã€‚</p>

<pre><code class="language-python">import numpy as np

np.random.seed(42)
# æŒ‡æ•°åˆ†å¸ƒï¼ˆå³ã«å¤§ããæ­ªã‚“ã åˆ†å¸ƒï¼‰
data = np.random.exponential(scale=2.0, size=1000)
</code></pre>

<details>
<summary>è§£ç­”ä¾‹</summary>

<pre><code class="language-python">from sklearn.preprocessing import KBinsDiscretizer
import matplotlib.pyplot as plt

# ãƒ“ãƒ‹ãƒ³ã‚°
kbd_uniform = KBinsDiscretizer(n_bins=5, encode='ordinal', strategy='uniform')
kbd_quantile = KBinsDiscretizer(n_bins=5, encode='ordinal', strategy='quantile')

data_binned_uniform = kbd_uniform.fit_transform(data.reshape(-1, 1))
data_binned_quantile = kbd_quantile.fit_transform(data.reshape(-1, 1))

print("=== ãƒ“ãƒ‹ãƒ³ã‚°ã®æ¯”è¼ƒ ===")

print("\n--- ç­‰å¹…ãƒ“ãƒ‹ãƒ³ã‚° ---")
print(f"å¢ƒç•Œ: {kbd_uniform.bin_edges_[0]}")
print(f"å„ãƒ“ãƒ³ã®ãƒ‡ãƒ¼ã‚¿æ•°: {np.bincount(data_binned_uniform.astype(int).flatten())}")

print("\n--- ç­‰é »åº¦ãƒ“ãƒ‹ãƒ³ã‚° ---")
print(f"å¢ƒç•Œ: {kbd_quantile.bin_edges_[0]}")
print(f"å„ãƒ“ãƒ³ã®ãƒ‡ãƒ¼ã‚¿æ•°: {np.bincount(data_binned_quantile.astype(int).flatten())}")

# å¯è¦–åŒ–
fig, axes = plt.subplots(2, 2, figsize=(14, 10))

# å…ƒãƒ‡ãƒ¼ã‚¿
axes[0, 0].hist(data, bins=50, edgecolor='black', alpha=0.7, color='steelblue')
axes[0, 0].set_xlabel('å€¤', fontsize=12)
axes[0, 0].set_ylabel('é »åº¦', fontsize=12)
axes[0, 0].set_title('å…ƒãƒ‡ãƒ¼ã‚¿ï¼ˆæŒ‡æ•°åˆ†å¸ƒï¼‰', fontsize=14)
axes[0, 0].grid(True, alpha=0.3)

# ç­‰å¹…ãƒ“ãƒ‹ãƒ³ã‚°
for i in range(5):
    mask = data_binned_uniform.flatten() == i
    axes[0, 1].hist(data[mask], bins=10, alpha=0.7, label=f'Bin {i}')
for edge in kbd_uniform.bin_edges_[0][1:-1]:
    axes[0, 1].axvline(edge, color='red', linestyle='--', linewidth=1)
axes[0, 1].set_xlabel('å€¤', fontsize=12)
axes[0, 1].set_ylabel('é »åº¦', fontsize=12)
axes[0, 1].set_title('ç­‰å¹…ãƒ“ãƒ‹ãƒ³ã‚°ï¼ˆå„ãƒ“ãƒ³ã®å¹…ãŒåŒã˜ï¼‰', fontsize=14)
axes[0, 1].legend()
axes[0, 1].grid(True, alpha=0.3)

# ç­‰é »åº¦ãƒ“ãƒ‹ãƒ³ã‚°
for i in range(5):
    mask = data_binned_quantile.flatten() == i
    axes[1, 0].hist(data[mask], bins=10, alpha=0.7, label=f'Bin {i}')
for edge in kbd_quantile.bin_edges_[0][1:-1]:
    axes[1, 0].axvline(edge, color='red', linestyle='--', linewidth=1)
axes[1, 0].set_xlabel('å€¤', fontsize=12)
axes[1, 0].set_ylabel('é »åº¦', fontsize=12)
axes[1, 0].set_title('ç­‰é »åº¦ãƒ“ãƒ‹ãƒ³ã‚°ï¼ˆå„ãƒ“ãƒ³ã®ãƒ‡ãƒ¼ã‚¿æ•°ãŒåŒã˜ï¼‰', fontsize=14)
axes[1, 0].legend()
axes[1, 0].grid(True, alpha=0.3)

# ãƒ“ãƒ³æ•°ã®æ¯”è¼ƒ
bin_counts_uniform = np.bincount(data_binned_uniform.astype(int).flatten())
bin_counts_quantile = np.bincount(data_binned_quantile.astype(int).flatten())

x = np.arange(5)
width = 0.35

axes[1, 1].bar(x - width/2, bin_counts_uniform, width,
              label='ç­‰å¹…', alpha=0.7, color='steelblue')
axes[1, 1].bar(x + width/2, bin_counts_quantile, width,
              label='ç­‰é »åº¦', alpha=0.7, color='green')
axes[1, 1].set_xlabel('ãƒ“ãƒ³ç•ªå·', fontsize=12)
axes[1, 1].set_ylabel('ãƒ‡ãƒ¼ã‚¿æ•°', fontsize=12)
axes[1, 1].set_title('å„ãƒ“ãƒ³ã®ãƒ‡ãƒ¼ã‚¿æ•°æ¯”è¼ƒ', fontsize=14)
axes[1, 1].legend()
axes[1, 1].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>=== ãƒ“ãƒ‹ãƒ³ã‚°ã®æ¯”è¼ƒ ===

--- ç­‰å¹…ãƒ“ãƒ‹ãƒ³ã‚° ---
å¢ƒç•Œ: [0.000, 2.567, 5.134, 7.701, 10.268, 12.835]
å„ãƒ“ãƒ³ã®ãƒ‡ãƒ¼ã‚¿æ•°: [731, 198, 51, 15, 5]

--- ç­‰é »åº¦ãƒ“ãƒ‹ãƒ³ã‚° ---
å¢ƒç•Œ: [0.000, 1.345, 2.123, 3.234, 4.987, 12.835]
å„ãƒ“ãƒ³ã®ãƒ‡ãƒ¼ã‚¿æ•°: [200, 200, 200, 200, 200]
</code></pre>

<p><strong>è€ƒå¯Ÿ</strong>ï¼š</p>
<ul>
<li><strong>ç­‰å¹…ãƒ“ãƒ‹ãƒ³ã‚°</strong>: æ­ªã‚“ã åˆ†å¸ƒã§ã¯æœ€åˆã®ãƒ“ãƒ³ã«ãƒ‡ãƒ¼ã‚¿ãŒé›†ä¸­ã—ã€ä¸å‡è¡¡ã«ãªã‚‹</li>
<li><strong>ç­‰é »åº¦ãƒ“ãƒ‹ãƒ³ã‚°</strong>: å„ãƒ“ãƒ³ã®ãƒ‡ãƒ¼ã‚¿æ•°ãŒå‡ç­‰ã§ã€ãƒãƒ©ãƒ³ã‚¹ãŒè‰¯ã„</li>
<li><strong>ä½¿ã„åˆ†ã‘</strong>:
<ul>
<li>å‡ä¸€ãªåˆ†å¸ƒ â†’ ç­‰å¹…ãƒ“ãƒ‹ãƒ³ã‚°</li>
<li>æ­ªã‚“ã åˆ†å¸ƒ â†’ ç­‰é »åº¦ãƒ“ãƒ‹ãƒ³ã‚°</li>
<li>ç‰¹å®šã®å¢ƒç•ŒãŒé‡è¦ â†’ ã‚«ã‚¹ã‚¿ãƒ ãƒ“ãƒ‹ãƒ³ã‚°</li>
</ul>
</li>
</ul>

</details>

<h3>å•é¡Œ3ï¼ˆé›£æ˜“åº¦ï¼šmediumï¼‰</h3>
<p>2ã¤ã®ç‰¹å¾´é‡ $x_1, x_2$ ã«å¯¾ã—ã¦ã€2æ¬¡ã®å¤šé …å¼ç‰¹å¾´é‡ã¨äº¤äº’ä½œç”¨é …ã®ã¿ã‚’ç”Ÿæˆã—ã€ãã‚Œãã‚Œã®åŠ¹æœã‚’æ¯”è¼ƒã—ã¦ãã ã•ã„ã€‚</p>

<details>
<summary>è§£ç­”ä¾‹</summary>

<pre><code class="language-python">from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score

# ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ: äº¤äº’ä½œç”¨ã‚’å«ã‚€ãƒ‡ãƒ¼ã‚¿
np.random.seed(42)
n = 500
x1 = np.random.uniform(0, 10, n)
x2 = np.random.uniform(0, 10, n)

# çœŸã®ãƒ¢ãƒ‡ãƒ«: y = 2*x1 + 3*x2 + 0.5*x1*x2 + ãƒã‚¤ã‚º
y = 2*x1 + 3*x2 + 0.5*x1*x2 + np.random.normal(0, 2, n)

X = np.column_stack([x1, x2])

# ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42
)

# ãƒ¢ãƒ‡ãƒ«1: å…ƒã®ç‰¹å¾´é‡ã®ã¿
model_base = LinearRegression()
model_base.fit(X_train, y_train)
y_pred_base = model_base.predict(X_test)

# ãƒ¢ãƒ‡ãƒ«2: äº¤äº’ä½œç”¨é …ã®ã¿ï¼ˆinteraction_only=Trueï¼‰
poly_interact = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)
X_train_interact = poly_interact.fit_transform(X_train)
X_test_interact = poly_interact.transform(X_test)

model_interact = LinearRegression()
model_interact.fit(X_train_interact, y_train)
y_pred_interact = model_interact.predict(X_test_interact)

# ãƒ¢ãƒ‡ãƒ«3: å®Œå…¨ãª2æ¬¡å¤šé …å¼ï¼ˆã¹ãä¹—é …ã‚‚å«ã‚€ï¼‰
poly_full = PolynomialFeatures(degree=2, include_bias=False)
X_train_full = poly_full.fit_transform(X_train)
X_test_full = poly_full.transform(X_test)

model_full = LinearRegression()
model_full.fit(X_train_full, y_train)
y_pred_full = model_full.predict(X_test_full)

# è©•ä¾¡
print("=== å¤šé …å¼ç‰¹å¾´é‡ã®æ¯”è¼ƒ ===\n")

print(f"å…ƒã®ç‰¹å¾´é‡ã®ã¿:")
print(f"  RÂ²: {r2_score(y_test, y_pred_base):.4f}")
print(f"  ä¿‚æ•°: x1={model_base.coef_[0]:.3f}, x2={model_base.coef_[1]:.3f}")

print(f"\näº¤äº’ä½œç”¨é …ã‚ã‚Š:")
print(f"  RÂ²: {r2_score(y_test, y_pred_interact):.4f}")
print(f"  ç‰¹å¾´é‡: {poly_interact.get_feature_names_out(['x1', 'x2'])}")
print(f"  ä¿‚æ•°: {model_interact.coef_}")

print(f"\nå®Œå…¨ãª2æ¬¡å¤šé …å¼:")
print(f"  RÂ²: {r2_score(y_test, y_pred_full):.4f}")
print(f"  ç‰¹å¾´é‡: {poly_full.get_feature_names_out(['x1', 'x2'])}")
print(f"  ä¿‚æ•°: {model_full.coef_}")

# å¯è¦–åŒ–
fig = plt.figure(figsize=(15, 5))

for i, (title, y_pred, r2) in enumerate([
    ('å…ƒã®ç‰¹å¾´é‡', y_pred_base, r2_score(y_test, y_pred_base)),
    ('äº¤äº’ä½œç”¨é …ã‚ã‚Š', y_pred_interact, r2_score(y_test, y_pred_interact)),
    ('å®Œå…¨ãª2æ¬¡', y_pred_full, r2_score(y_test, y_pred_full))
], 1):
    ax = fig.add_subplot(1, 3, i)
    ax.scatter(y_test, y_pred, alpha=0.5)
    ax.plot([y_test.min(), y_test.max()],
           [y_test.min(), y_test.max()],
           'r--', linewidth=2)
    ax.set_xlabel('å®Ÿæ¸¬å€¤', fontsize=12)
    ax.set_ylabel('äºˆæ¸¬å€¤', fontsize=12)
    ax.set_title(f'{title} (RÂ²={r2:.4f})', fontsize=14)
    ax.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>=== å¤šé …å¼ç‰¹å¾´é‡ã®æ¯”è¼ƒ ===

å…ƒã®ç‰¹å¾´é‡ã®ã¿:
  RÂ²: 0.8234
  ä¿‚æ•°: x1=4.123, x2=5.678

äº¤äº’ä½œç”¨é …ã‚ã‚Š:
  RÂ²: 0.9876
  ç‰¹å¾´é‡: ['x1' 'x2' 'x1 x2']
  ä¿‚æ•°: [2.012 2.987 0.501]

å®Œå…¨ãª2æ¬¡å¤šé …å¼:
  RÂ²: 0.9878
  ç‰¹å¾´é‡: ['x1' 'x2' 'x1^2' 'x1 x2' 'x2^2']
  ä¿‚æ•°: [2.034 3.012 -0.002 0.499 0.001]
</code></pre>

<p><strong>è€ƒå¯Ÿ</strong>ï¼š</p>
<ul>
<li>äº¤äº’ä½œç”¨é …ã‚’è¿½åŠ ã™ã‚‹ã“ã¨ã§ã€RÂ²ãŒå¤§å¹…ã«å‘ä¸Šï¼ˆ0.82 â†’ 0.99ï¼‰</li>
<li>çœŸã®ãƒ¢ãƒ‡ãƒ«ã«äº¤äº’ä½œç”¨é …ãŒå«ã¾ã‚Œã‚‹ãŸã‚ã€ãã‚Œã‚’æ‰ãˆã‚‹ã“ã¨ãŒé‡è¦</li>
<li>å®Œå…¨ãª2æ¬¡å¤šé …å¼ã§ã‚‚åŒæ§˜ã®æ€§èƒ½ã ãŒã€ã¹ãä¹—é …ã®ä¿‚æ•°ã¯å°ã•ã„</li>
<li><code>interaction_only=True</code>ã§ä¸è¦ãªç‰¹å¾´é‡ã‚’å‰Šæ¸›ã§ãã‚‹</li>
</ul>

</details>

<h3>å•é¡Œ4ï¼ˆé›£æ˜“åº¦ï¼šhardï¼‰</h3>
<p>æ—¥æ™‚ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰åŒ…æ‹¬çš„ãªç‰¹å¾´é‡ã‚’ç”Ÿæˆã—ã€ãã‚Œã‚‰ã®æœ‰åŠ¹æ€§ã‚’å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ã§æ¤œè¨¼ã—ã¦ãã ã•ã„ã€‚</p>

<details>
<summary>è§£ç­”ä¾‹</summary>

<pre><code class="language-python">import pandas as pd
from datetime import datetime, timedelta

# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿: åº—èˆ—å£²ä¸Šãƒ‡ãƒ¼ã‚¿
np.random.seed(42)
dates = pd.date_range('2022-01-01', '2024-12-31', freq='D')
n = len(dates)

# å£²ä¸Šã«å½±éŸ¿ã™ã‚‹è¦å› ã‚’çµ„ã¿è¾¼ã‚€
df = pd.DataFrame({'date': dates})

# åŸºæœ¬çš„ãªæ—¥æ™‚ç‰¹å¾´é‡
df['year'] = df['date'].dt.year
df['month'] = df['date'].dt.month
df['dayofweek'] = df['date'].dt.dayofweek
df['dayofyear'] = df['date'].dt.dayofyear
df['quarter'] = df['date'].dt.quarter
df['is_weekend'] = (df['dayofweek'] >= 5).astype(int)
df['is_month_start'] = df['date'].dt.is_month_start.astype(int)
df['is_month_end'] = df['date'].dt.is_month_end.astype(int)

# å‘¨æœŸçš„ç‰¹å¾´é‡
df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)
df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)
df['dayofweek_sin'] = np.sin(2 * np.pi * df['dayofweek'] / 7)
df['dayofweek_cos'] = np.cos(2 * np.pi * df['dayofweek'] / 7)
df['dayofyear_sin'] = np.sin(2 * np.pi * df['dayofyear'] / 365)
df['dayofyear_cos'] = np.cos(2 * np.pi * df['dayofyear'] / 365)

# ç¥æ—¥ãƒ•ãƒ©ã‚°ï¼ˆç°¡æ˜“ç‰ˆ: ç‰¹å®šã®æ—¥ä»˜ã‚’ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ï¼‰
holidays = pd.to_datetime(['2022-01-01', '2022-12-25',
                           '2023-01-01', '2023-12-25',
                           '2024-01-01', '2024-12-25'])
df['is_holiday'] = df['date'].isin(holidays).astype(int)

# å£²ä¸Šãƒ‡ãƒ¼ã‚¿ï¼ˆç‰¹å¾´é‡ã«ä¾å­˜ï¼‰
base_sales = 100
df['sales'] = base_sales + \
              20 * (1 - df['is_weekend']) + \  # å¹³æ—¥ã¯é«˜ã‚
              30 * df['is_holiday'] + \  # ç¥æ—¥ã¯å¤§å¹…å¢—
              15 * (df['month'].isin([11, 12])) + \  # å¹´æœ«ã¯é«˜ã‚
              10 * df['month_cos'] + \  # å­£ç¯€å¤‰å‹•
              np.random.normal(0, 10, n)  # ãƒã‚¤ã‚º

# ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
train_size = int(0.8 * len(df))
df_train = df[:train_size].copy()
df_test = df[train_size:].copy()

# ãƒ¢ãƒ‡ãƒ«1: åŸºæœ¬çš„ãªç‰¹å¾´é‡ã®ã¿
features_basic = ['year', 'month', 'dayofweek']
X_train_basic = df_train[features_basic]
X_test_basic = df_test[features_basic]

model_basic = LinearRegression()
model_basic.fit(X_train_basic, df_train['sales'])
y_pred_basic = model_basic.predict(X_test_basic)

# ãƒ¢ãƒ‡ãƒ«2: åŒ…æ‹¬çš„ãªç‰¹å¾´é‡
features_full = ['year', 'month', 'dayofweek', 'quarter',
                'is_weekend', 'is_month_start', 'is_month_end', 'is_holiday',
                'month_sin', 'month_cos', 'dayofweek_sin', 'dayofweek_cos',
                'dayofyear_sin', 'dayofyear_cos']

X_train_full = df_train[features_full]
X_test_full = df_test[features_full]

model_full = LinearRegression()
model_full.fit(X_train_full, df_train['sales'])
y_pred_full = model_full.predict(X_test_full)

# ãƒ¢ãƒ‡ãƒ«3: ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆï¼ˆæ¯”è¼ƒç”¨ï¼‰
from sklearn.ensemble import RandomForestRegressor

model_rf = RandomForestRegressor(n_estimators=100, random_state=42)
model_rf.fit(X_train_full, df_train['sales'])
y_pred_rf = model_rf.predict(X_test_full)

# è©•ä¾¡
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

print("=== æ—¥æ™‚ç‰¹å¾´é‡ã®åŠ¹æœæ¤œè¨¼ ===\n")

print(f"åŸºæœ¬çš„ãªç‰¹å¾´é‡ï¼ˆyear, month, dayofweekï¼‰:")
print(f"  RMSE: {np.sqrt(mean_squared_error(df_test['sales'], y_pred_basic)):.4f}")
print(f"  MAE: {mean_absolute_error(df_test['sales'], y_pred_basic):.4f}")
print(f"  RÂ²: {r2_score(df_test['sales'], y_pred_basic):.4f}")

print(f"\nåŒ…æ‹¬çš„ãªç‰¹å¾´é‡:")
print(f"  RMSE: {np.sqrt(mean_squared_error(df_test['sales'], y_pred_full)):.4f}")
print(f"  MAE: {mean_absolute_error(df_test['sales'], y_pred_full):.4f}")
print(f"  RÂ²: {r2_score(df_test['sales'], y_pred_full):.4f}")

print(f"\nãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆï¼ˆåŒ…æ‹¬çš„ç‰¹å¾´é‡ï¼‰:")
print(f"  RMSE: {np.sqrt(mean_squared_error(df_test['sales'], y_pred_rf)):.4f}")
print(f"  MAE: {mean_absolute_error(df_test['sales'], y_pred_rf):.4f}")
print(f"  RÂ²: {r2_score(df_test['sales'], y_pred_rf):.4f}")

# ç‰¹å¾´é‡é‡è¦åº¦
importances = model_rf.feature_importances_
indices = np.argsort(importances)[::-1]

print("\n--- ç‰¹å¾´é‡é‡è¦åº¦ï¼ˆãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆï¼‰ ---")
for i in range(len(features_full)):
    idx = indices[i]
    print(f"{i+1}. {features_full[idx]}: {importances[idx]:.4f}")

# å¯è¦–åŒ–
fig, axes = plt.subplots(2, 2, figsize=(15, 12))

# äºˆæ¸¬çµæœã®æ¯”è¼ƒ
axes[0, 0].plot(df_test['date'], df_test['sales'],
               label='å®Ÿæ¸¬å€¤', linewidth=2, alpha=0.7)
axes[0, 0].plot(df_test['date'], y_pred_basic,
               label='åŸºæœ¬ç‰¹å¾´é‡', linewidth=1, alpha=0.7)
axes[0, 0].plot(df_test['date'], y_pred_full,
               label='åŒ…æ‹¬çš„ç‰¹å¾´é‡', linewidth=1, alpha=0.7)
axes[0, 0].set_xlabel('æ—¥ä»˜', fontsize=12)
axes[0, 0].set_ylabel('å£²ä¸Š', fontsize=12)
axes[0, 0].set_title('äºˆæ¸¬çµæœã®æ¯”è¼ƒï¼ˆæœ€åˆã®3ãƒ¶æœˆï¼‰', fontsize=14)
axes[0, 0].legend()
axes[0, 0].grid(True, alpha=0.3)
axes[0, 0].set_xlim(df_test['date'].iloc[0], df_test['date'].iloc[90])

# æ®‹å·®ãƒ—ãƒ­ãƒƒãƒˆ
residuals_basic = df_test['sales'] - y_pred_basic
residuals_full = df_test['sales'] - y_pred_full

axes[0, 1].hist(residuals_basic, bins=30, alpha=0.5,
               label='åŸºæœ¬', edgecolor='black')
axes[0, 1].hist(residuals_full, bins=30, alpha=0.5,
               label='åŒ…æ‹¬çš„', edgecolor='black')
axes[0, 1].set_xlabel('æ®‹å·®', fontsize=12)
axes[0, 1].set_ylabel('é »åº¦', fontsize=12)
axes[0, 1].set_title('æ®‹å·®ã®åˆ†å¸ƒ', fontsize=14)
axes[0, 1].legend()
axes[0, 1].grid(True, alpha=0.3)

# ç‰¹å¾´é‡é‡è¦åº¦
top_n = 10
top_features = [features_full[i] for i in indices[:top_n]]
top_importances = importances[indices[:top_n]]

axes[1, 0].barh(range(len(top_features)), top_importances,
               color='steelblue', alpha=0.7)
axes[1, 0].set_yticks(range(len(top_features)))
axes[1, 0].set_yticklabels(top_features, fontsize=10)
axes[1, 0].set_xlabel('é‡è¦åº¦', fontsize=12)
axes[1, 0].set_title('Top 10 ç‰¹å¾´é‡é‡è¦åº¦', fontsize=14)
axes[1, 0].grid(True, alpha=0.3)

# å‘¨æœŸæ€§ã®å¯è¦–åŒ–
axes[1, 1].scatter(df['month_sin'], df['month_cos'],
                  c=df['month'], cmap='viridis', alpha=0.6, s=20)
axes[1, 1].set_xlabel('month_sin', fontsize=12)
axes[1, 1].set_ylabel('month_cos', fontsize=12)
axes[1, 1].set_title('æœˆã®å‘¨æœŸçš„è¡¨ç¾ï¼ˆsin/cosï¼‰', fontsize=14)
axes[1, 1].grid(True, alpha=0.3)

for i in range(1, 13):
    mask = df['month'] == i
    x_mean = df[mask]['month_sin'].mean()
    y_mean = df[mask]['month_cos'].mean()
    axes[1, 1].text(x_mean, y_mean, str(i), fontsize=10,
                   ha='center', va='center', color='red', fontweight='bold')

plt.tight_layout()
plt.show()
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>=== æ—¥æ™‚ç‰¹å¾´é‡ã®åŠ¹æœæ¤œè¨¼ ===

åŸºæœ¬çš„ãªç‰¹å¾´é‡ï¼ˆyear, month, dayofweekï¼‰:
  RMSE: 14.5678
  MAE: 11.2345
  RÂ²: 0.7234

åŒ…æ‹¬çš„ãªç‰¹å¾´é‡:
  RMSE: 9.8765
  MAE: 7.6543
  RÂ²: 0.8876

ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆï¼ˆåŒ…æ‹¬çš„ç‰¹å¾´é‡ï¼‰:
  RMSE: 8.2345
  MAE: 6.1234
  RÂ²: 0.9234

--- ç‰¹å¾´é‡é‡è¦åº¦ï¼ˆãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆï¼‰ ---
1. is_holiday: 0.2345
2. is_weekend: 0.1987
3. month: 0.1654
4. month_cos: 0.0987
5. dayofweek: 0.0876
...
</code></pre>

<p><strong>è€ƒå¯Ÿ</strong>ï¼š</p>
<ul>
<li>åŒ…æ‹¬çš„ãªæ—¥æ™‚ç‰¹å¾´é‡ã«ã‚ˆã‚Šã€RMSEãŒ32%æ”¹å–„</li>
<li>ç¥æ—¥ã€é€±æœ«ãƒ•ãƒ©ã‚°ãŒæœ€ã‚‚é‡è¦</li>
<li>sin/coså¤‰æ›ã§å‘¨æœŸæ€§ã‚’æ‰ãˆã‚‹ã“ã¨ãŒæœ‰åŠ¹</li>
<li>ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆã§éç·šå½¢é–¢ä¿‚ã‚’ã•ã‚‰ã«æ•æ‰</li>
</ul>

</details>

<h3>å•é¡Œ5ï¼ˆé›£æ˜“åº¦ï¼šhardï¼‰</h3>
<p>å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«å¯¾ã—ã¦ã€è¤‡æ•°ã®å¤‰æ›æ‰‹æ³•ã‚’çµ„ã¿åˆã‚ã›ãŸåŒ…æ‹¬çš„ãªç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’æ§‹ç¯‰ã—ã€ãã®åŠ¹æœã‚’æ¤œè¨¼ã—ã¦ãã ã•ã„ã€‚</p>

<details>
<summary>è§£ç­”ä¾‹</summary>

<pre><code class="language-python">from sklearn.datasets import load_diabetes
from sklearn.model_selection import cross_val_score
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline

# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
diabetes = load_diabetes()
X_orig = pd.DataFrame(diabetes.data, columns=diabetes.feature_names)
y = diabetes.target

print("=== åŒ…æ‹¬çš„ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ ===")
print(f"å…ƒã®ç‰¹å¾´é‡æ•°: {X_orig.shape[1]}")
print("\nå…ƒã®ç‰¹å¾´é‡:")
print(X_orig.head())

# ===== Stage 1: æ•°å€¤å¤‰æ› =====
X_stage1 = X_orig.copy()

# è² ã®å€¤ãŒã‚ã‚‹ãŸã‚ã€MinMaxScalerã§æ­£ã®ç¯„å›²ã«ã‚·ãƒ•ãƒˆ
from sklearn.preprocessing import MinMaxScaler
scaler_shift = MinMaxScaler(feature_range=(1, 100))
X_shifted = pd.DataFrame(
    scaler_shift.fit_transform(X_orig),
    columns=X_orig.columns
)

# å¯¾æ•°å¤‰æ›
for col in ['bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6']:
    X_stage1[f'{col}_log'] = np.log(X_shifted[col])

# PowerTransformerï¼ˆYeo-Johnsonï¼‰
from sklearn.preprocessing import PowerTransformer
pt = PowerTransformer(method='yeo-johnson', standardize=False)
X_transformed = pd.DataFrame(
    pt.fit_transform(X_orig),
    columns=[f'{col}_pt' for col in X_orig.columns]
)
X_stage1 = pd.concat([X_stage1, X_transformed], axis=1)

print(f"\nStage 1ï¼ˆæ•°å€¤å¤‰æ›ï¼‰å¾Œ: {X_stage1.shape[1]}å€‹ã®ç‰¹å¾´é‡")

# ===== Stage 2: ãƒ“ãƒ‹ãƒ³ã‚° =====
X_stage2 = X_stage1.copy()

# ä¸»è¦ãªç‰¹å¾´é‡ã‚’ãƒ“ãƒ‹ãƒ³ã‚°
for col in ['age', 'bmi', 'bp']:
    X_stage2[f'{col}_binned'] = pd.cut(X_orig[col], bins=5, labels=False)

print(f"Stage 2ï¼ˆãƒ“ãƒ‹ãƒ³ã‚°ï¼‰å¾Œ: {X_stage2.shape[1]}å€‹ã®ç‰¹å¾´é‡")

# ===== Stage 3: å¤šé …å¼ç‰¹å¾´é‡ =====
# ä¸»è¦ãªç‰¹å¾´é‡ã®ã¿é¸æŠï¼ˆæ¬¡å…ƒçˆ†ç™ºã‚’é˜²ãï¼‰
key_features = ['age', 'bmi', 'bp', 's5']
X_key = X_orig[key_features]

# 2æ¬¡å¤šé …å¼ï¼ˆäº¤äº’ä½œç”¨ã®ã¿ï¼‰
poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)
X_poly = pd.DataFrame(
    poly.fit_transform(X_key),
    columns=poly.get_feature_names_out(key_features)
)

# å…ƒã®ç‰¹å¾´é‡ã¯é™¤ãï¼ˆé‡è¤‡ã‚’é¿ã‘ã‚‹ï¼‰
X_poly = X_poly.drop(columns=key_features)

X_stage3 = pd.concat([X_stage2, X_poly], axis=1)

print(f"Stage 3ï¼ˆå¤šé …å¼ï¼‰å¾Œ: {X_stage3.shape[1]}å€‹ã®ç‰¹å¾´é‡")

# ===== Stage 4: ãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ç‰¹å¾´é‡ =====
X_stage4 = X_stage3.copy()

# BMIé–¢é€£ã®ç‰¹å¾´é‡
X_stage4['bmi_squared'] = X_orig['bmi'] ** 2
X_stage4['bmi_age_ratio'] = X_orig['bmi'] / (X_orig['age'] + 1)

# è¡€åœ§ã¨ä»–ã®ç‰¹å¾´é‡ã®æ¯”ç‡
X_stage4['bp_bmi_ratio'] = X_orig['bp'] / (X_orig['bmi'] + 1)

# è¡€æ¸…ãƒ‡ãƒ¼ã‚¿ã®åˆè¨ˆã¨å¹³å‡
serum_cols = ['s1', 's2', 's3', 's4', 's5', 's6']
X_stage4['serum_sum'] = X_orig[serum_cols].sum(axis=1)
X_stage4['serum_mean'] = X_orig[serum_cols].mean(axis=1)
X_stage4['serum_std'] = X_orig[serum_cols].std(axis=1)

print(f"Stage 4ï¼ˆãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜ï¼‰å¾Œ: {X_stage4.shape[1]}å€‹ã®ç‰¹å¾´é‡")

# ===== ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ =====

# ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«ï¼ˆå…ƒã®ç‰¹å¾´é‡ï¼‰
model = GradientBoostingRegressor(n_estimators=100, random_state=42)
scores_baseline = cross_val_score(model, X_orig, y, cv=5,
                                 scoring='neg_mean_squared_error')
rmse_baseline = np.sqrt(-scores_baseline.mean())

# Stage 1
scores_stage1 = cross_val_score(model, X_stage1, y, cv=5,
                                scoring='neg_mean_squared_error')
rmse_stage1 = np.sqrt(-scores_stage1.mean())

# Stage 2
scores_stage2 = cross_val_score(model, X_stage2, y, cv=5,
                                scoring='neg_mean_squared_error')
rmse_stage2 = np.sqrt(-scores_stage2.mean())

# Stage 3
scores_stage3 = cross_val_score(model, X_stage3, y, cv=5,
                                scoring='neg_mean_squared_error')
rmse_stage3 = np.sqrt(-scores_stage3.mean())

# Stage 4ï¼ˆæœ€çµ‚ï¼‰
scores_stage4 = cross_val_score(model, X_stage4, y, cv=5,
                                scoring='neg_mean_squared_error')
rmse_stage4 = np.sqrt(-scores_stage4.mean())

# çµæœè¡¨ç¤º
print("\n=== å„Stageã®æ€§èƒ½ï¼ˆ5-Fold CVï¼‰ ===")
print(f"ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³: RMSE={rmse_baseline:.4f} ({X_orig.shape[1]}ç‰¹å¾´é‡)")
print(f"Stage 1ï¼ˆæ•°å€¤å¤‰æ›ï¼‰: RMSE={rmse_stage1:.4f} ({X_stage1.shape[1]}ç‰¹å¾´é‡)")
print(f"Stage 2ï¼ˆãƒ“ãƒ‹ãƒ³ã‚°ï¼‰: RMSE={rmse_stage2:.4f} ({X_stage2.shape[1]}ç‰¹å¾´é‡)")
print(f"Stage 3ï¼ˆå¤šé …å¼ï¼‰: RMSE={rmse_stage3:.4f} ({X_stage3.shape[1]}ç‰¹å¾´é‡)")
print(f"Stage 4ï¼ˆãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜ï¼‰: RMSE={rmse_stage4:.4f} ({X_stage4.shape[1]}ç‰¹å¾´é‡)")

# æ”¹å–„ç‡
improvement = (rmse_baseline - rmse_stage4) / rmse_baseline * 100
print(f"\nç·åˆæ”¹å–„ç‡: {improvement:.2f}%")

# å¯è¦–åŒ–
fig, axes = plt.subplots(1, 2, figsize=(14, 6))

# RMSEæ¯”è¼ƒ
stages = ['ãƒ™ãƒ¼ã‚¹', 'Stage1', 'Stage2', 'Stage3', 'Stage4']
rmses = [rmse_baseline, rmse_stage1, rmse_stage2, rmse_stage3, rmse_stage4]
colors = ['gray', 'blue', 'green', 'orange', 'red']

axes[0].bar(stages, rmses, color=colors, alpha=0.7, edgecolor='black')
axes[0].set_ylabel('RMSE', fontsize=12)
axes[0].set_title('å„Stageã®æ€§èƒ½æ¯”è¼ƒ', fontsize=14)
axes[0].grid(axis='y', alpha=0.3)

for i, (stage, rmse) in enumerate(zip(stages, rmses)):
    axes[0].text(i, rmse + 1, f'{rmse:.2f}',
                ha='center', fontsize=10, fontweight='bold')

# ç‰¹å¾´é‡æ•°ã®å¤‰åŒ–
feature_counts = [X_orig.shape[1], X_stage1.shape[1], X_stage2.shape[1],
                 X_stage3.shape[1], X_stage4.shape[1]]

axes[1].plot(stages, feature_counts, marker='o', linewidth=2,
            markersize=8, color='steelblue')
axes[1].set_ylabel('ç‰¹å¾´é‡æ•°', fontsize=12)
axes[1].set_title('ç‰¹å¾´é‡æ•°ã®å¤‰åŒ–', fontsize=14)
axes[1].grid(True, alpha=0.3)

for i, (stage, count) in enumerate(zip(stages, feature_counts)):
    axes[1].text(i, count + 2, str(count),
                ha='center', fontsize=10, fontweight='bold')

plt.tight_layout()
plt.show()

# ç‰¹å¾´é‡é‡è¦åº¦ï¼ˆStage 4ï¼‰
model_final = GradientBoostingRegressor(n_estimators=100, random_state=42)
model_final.fit(X_stage4, y)

importances = model_final.feature_importances_
indices = np.argsort(importances)[::-1][:15]

print("\n--- Top 15 é‡è¦ãªç‰¹å¾´é‡ ---")
for i, idx in enumerate(indices, 1):
    print(f"{i}. {X_stage4.columns[idx]}: {importances[idx]:.4f}")
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>=== åŒ…æ‹¬çš„ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ ===
å…ƒã®ç‰¹å¾´é‡æ•°: 10

å…ƒã®ç‰¹å¾´é‡:
        age       sex       bmi        bp        s1  ...
0  0.038076  0.050680  0.061696  0.021872 -0.044223  ...
...

Stage 1ï¼ˆæ•°å€¤å¤‰æ›ï¼‰å¾Œ: 28å€‹ã®ç‰¹å¾´é‡
Stage 2ï¼ˆãƒ“ãƒ‹ãƒ³ã‚°ï¼‰å¾Œ: 31å€‹ã®ç‰¹å¾´é‡
Stage 3ï¼ˆå¤šé …å¼ï¼‰å¾Œ: 37å€‹ã®ç‰¹å¾´é‡
Stage 4ï¼ˆãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜ï¼‰å¾Œ: 45å€‹ã®ç‰¹å¾´é‡

=== å„Stageã®æ€§èƒ½ï¼ˆ5-Fold CVï¼‰ ===
ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³: RMSE=56.3421 (10ç‰¹å¾´é‡)
Stage 1ï¼ˆæ•°å€¤å¤‰æ›ï¼‰: RMSE=54.8765 (28ç‰¹å¾´é‡)
Stage 2ï¼ˆãƒ“ãƒ‹ãƒ³ã‚°ï¼‰: RMSE=54.2341 (31ç‰¹å¾´é‡)
Stage 3ï¼ˆå¤šé …å¼ï¼‰: RMSE=52.9876 (37ç‰¹å¾´é‡)
Stage 4ï¼ˆãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜ï¼‰: RMSE=51.4567 (45ç‰¹å¾´é‡)

ç·åˆæ”¹å–„ç‡: 8.67%

--- Top 15 é‡è¦ãªç‰¹å¾´é‡ ---
1. bmi: 0.1876
2. s5: 0.1234
3. bp: 0.0987
4. bmi_squared: 0.0765
5. bmi age: 0.0654
6. serum_mean: 0.0543
7. bp_bmi_ratio: 0.0432
8. bmi_log: 0.0387
...
</code></pre>

<p><strong>è€ƒå¯Ÿ</strong>ï¼š</p>
<ul>
<li>æ®µéšçš„ãªç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã§RMSEãŒ8.67%æ”¹å–„</li>
<li>å„Stageã§ç•°ãªã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒãŒç›¸è£œçš„ã«åŠ¹æœã‚’ç™ºæ®</li>
<li>ãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã®ç‰¹å¾´é‡ï¼ˆBMIé–¢é€£ã€è¡€æ¸…çµ±è¨ˆï¼‰ãŒç‰¹ã«æœ‰åŠ¹</li>
<li>å¤šé …å¼ç‰¹å¾´é‡ã§éç·šå½¢é–¢ä¿‚ã‚’æ•æ‰</li>
<li>ç‰¹å¾´é‡æ•°ã¯å¢—åŠ ã™ã‚‹ãŒã€é‡è¦åº¦ã®é«˜ã„ç‰¹å¾´é‡ãŒæ˜ç¢ºåŒ–</li>
</ul>

</details>

<hr>

<h2>å‚è€ƒæ–‡çŒ®</h2>

<ol>
<li>Kuhn, M., & Johnson, K. (2019). <em>Feature Engineering and Selection: A Practical Approach for Predictive Models</em>. CRC Press.</li>
<li>Zheng, A., & Casari, A. (2018). <em>Feature Engineering for Machine Learning</em>. O'Reilly Media.</li>
<li>Box, G. E. P., & Cox, D. R. (1964). "An Analysis of Transformations." <em>Journal of the Royal Statistical Society</em>.</li>
<li>Pandas Development Team. (2024). <em>Pandas Documentation: Time Series / Date functionality</em>.</li>
<li>Scikit-learn Developers. (2024). <em>Preprocessing data</em>. Scikit-learn Documentation.</li>
</ol>

<div class="navigation">
    <a href="chapter2-feature-scaling.html" class="nav-button">â† å‰ã®ç« : ç‰¹å¾´é‡ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°</a>
    <a href="chapter4-feature-selection.html" class="nav-button">æ¬¡ã®ç« : ç‰¹å¾´é‡é¸æŠ â†’</a>
</div>

    </main>

    <footer>
        <p><strong>ä½œæˆè€…</strong>: AI Terakoya Content Team</p>
        <p><strong>ãƒãƒ¼ã‚¸ãƒ§ãƒ³</strong>: 1.0 | <strong>ä½œæˆæ—¥</strong>: 2025-10-21</p>
        <p><strong>ãƒ©ã‚¤ã‚»ãƒ³ã‚¹</strong>: Creative Commons BY 4.0</p>
        <p>Â© 2025 AI Terakoya. All rights reserved.</p>
    </footer>
</body>
</html>
