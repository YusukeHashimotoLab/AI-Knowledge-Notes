<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
<meta content="ç¬¬2ç« ï¼šã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚° - AI Terakoya" name="description"/>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ç¬¬2ç« ï¼šã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚° - AI Terakoya</title>

    <style>
        :root {
            --color-primary: #2c3e50;
            --color-primary-dark: #1a252f;
            --color-accent: #7b2cbf;
            --color-accent-light: #9d4edd;
            --color-text: #2d3748;
            --color-text-light: #4a5568;
            --color-bg: #ffffff;
            --color-bg-alt: #f7fafc;
            --color-border: #e2e8f0;
            --color-code-bg: #f8f9fa;
            --color-link: #3182ce;
            --color-link-hover: #2c5aa0;

            --spacing-xs: 0.5rem;
            --spacing-sm: 1rem;
            --spacing-md: 1.5rem;
            --spacing-lg: 2rem;
            --spacing-xl: 3rem;

            --font-body: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            --font-mono: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;

            --border-radius: 8px;
            --box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: var(--font-body);
            line-height: 1.7;
            color: var(--color-text);
            background-color: var(--color-bg);
            font-size: 16px;
        }

        header {
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            padding: var(--spacing-xl) var(--spacing-md);
            margin-bottom: var(--spacing-xl);
            box-shadow: var(--box-shadow);
        }

        .header-content {
            max-width: 900px;
            margin: 0 auto;
        }

        h1 {
            font-size: 2rem;
            font-weight: 700;
            margin-bottom: var(--spacing-sm);
            line-height: 1.2;
        }

        .subtitle {
            font-size: 1.1rem;
            opacity: 0.95;
            font-weight: 400;
            margin-bottom: var(--spacing-md);
        }

        .meta {
            display: flex;
            flex-wrap: wrap;
            gap: var(--spacing-md);
            font-size: 0.9rem;
            opacity: 0.9;
        }

        .meta-item {
            display: flex;
            align-items: center;
            gap: 0.3rem;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 0 var(--spacing-md) var(--spacing-xl);
        }

        h2 {
            font-size: 1.75rem;
            color: var(--color-primary);
            margin-top: var(--spacing-xl);
            margin-bottom: var(--spacing-md);
            padding-bottom: var(--spacing-xs);
            border-bottom: 3px solid var(--color-accent);
        }

        h3 {
            font-size: 1.4rem;
            color: var(--color-primary);
            margin-top: var(--spacing-lg);
            margin-bottom: var(--spacing-sm);
        }

        h4 {
            font-size: 1.1rem;
            color: var(--color-primary-dark);
            margin-top: var(--spacing-md);
            margin-bottom: var(--spacing-sm);
        }

        p {
            margin-bottom: var(--spacing-md);
            color: var(--color-text);
        }

        a {
            color: var(--color-link);
            text-decoration: none;
            transition: color 0.2s;
        }

        a:hover {
            color: var(--color-link-hover);
            text-decoration: underline;
        }

        ul, ol {
            margin-left: var(--spacing-lg);
            margin-bottom: var(--spacing-md);
        }

        li {
            margin-bottom: var(--spacing-xs);
            color: var(--color-text);
        }

        pre {
            background-color: var(--color-code-bg);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            overflow-x: auto;
            margin-bottom: var(--spacing-md);
            font-family: var(--font-mono);
            font-size: 0.9rem;
            line-height: 1.5;
        }

        code {
            font-family: var(--font-mono);
            font-size: 0.9em;
            background-color: var(--color-code-bg);
            padding: 0.2em 0.4em;
            border-radius: 3px;
        }

        pre code {
            background-color: transparent;
            padding: 0;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: var(--spacing-md);
            font-size: 0.95rem;
        }

        th, td {
            border: 1px solid var(--color-border);
            padding: var(--spacing-sm);
            text-align: left;
        }

        th {
            background-color: var(--color-bg-alt);
            font-weight: 600;
            color: var(--color-primary);
        }

        blockquote {
            border-left: 4px solid var(--color-accent);
            padding-left: var(--spacing-md);
            margin: var(--spacing-md) 0;
            color: var(--color-text-light);
            font-style: italic;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        .mermaid {
            text-align: center;
            margin: var(--spacing-lg) 0;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        details {
            background-color: var(--color-bg-alt);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            margin-bottom: var(--spacing-md);
        }

        summary {
            cursor: pointer;
            font-weight: 600;
            color: var(--color-primary);
            user-select: none;
            padding: var(--spacing-xs);
            margin: calc(-1 * var(--spacing-md));
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        summary:hover {
            background-color: rgba(123, 44, 191, 0.1);
        }

        details[open] summary {
            margin-bottom: var(--spacing-md);
            border-bottom: 1px solid var(--color-border);
        }

        .navigation {
            display: flex;
            justify-content: space-between;
            gap: var(--spacing-md);
            margin: var(--spacing-xl) 0;
            padding-top: var(--spacing-lg);
            border-top: 2px solid var(--color-border);
        }

        .nav-button {
            flex: 1;
            padding: var(--spacing-md);
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            border-radius: var(--border-radius);
            text-align: center;
            font-weight: 600;
            transition: transform 0.2s, box-shadow 0.2s;
            box-shadow: var(--box-shadow);
        }

        .nav-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
            text-decoration: none;
        }

        footer {
            margin-top: var(--spacing-xl);
            padding: var(--spacing-lg) var(--spacing-md);
            background-color: var(--color-bg-alt);
            border-top: 1px solid var(--color-border);
            text-align: center;
            font-size: 0.9rem;
            color: var(--color-text-light);
        }
        .disclaimer {
            max-width: 900px;
            margin: 2rem auto;
            padding: 1.5rem;
            background: #f8f9fa;
            border-left: 4px solid #6c757d;
            border-radius: 4px;
        }

        .disclaimer h3 {
            color: #495057;
            margin-bottom: 1rem;
            font-size: 1.1rem;
        }

        .disclaimer ul {
            list-style: none;
            padding-left: 0;
        }

        .disclaimer li {
            padding: 0.5rem 0;
            padding-left: 1.5rem;
            position: relative;
            font-size: 0.9rem;
            color: #6c757d;
            line-height: 1.6;
        }

        .disclaimer li::before {
            content: "âš ï¸";
            position: absolute;
            left: 0;
        }


        @media (max-width: 768px) {
            h1 {
                font-size: 1.5rem;
            }

            h2 {
                font-size: 1.4rem;
            }

            h3 {
                font-size: 1.2rem;
            }

            .meta {
                font-size: 0.85rem;
            }

            .navigation {
                flex-direction: column;
            }

            table {
                font-size: 0.85rem;
            }

            th, td {
                padding: var(--spacing-xs);
            }
        }
    
        
    
        /* Breadcrumb styles */
        .breadcrumb {
            background: #f7fafc;
            padding: 0.75rem 1rem;
            border-bottom: 1px solid #e2e8f0;
            font-size: 0.9rem;
        }

        .breadcrumb-content {
            max-width: 900px;
            margin: 0 auto;
            display: flex;
            align-items: center;
            flex-wrap: wrap;
            gap: 0.5rem;
        }

        .breadcrumb a {
            color: #667eea;
            text-decoration: none;
            transition: color 0.2s;
        }

        .breadcrumb a:hover {
            color: #764ba2;
            text-decoration: underline;
        }

        .breadcrumb-separator {
            color: #a0aec0;
            margin: 0 0.25rem;
        }

        .breadcrumb-current {
            color: #4a5568;
            font-weight: 500;
        }
    </style>

    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
        mermaid.initialize({ startOnLoad: true, theme: 'default' });
    </script>

    <!-- MathJax for LaTeX equation rendering -->
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                displayMath: [['$$', '$$'], ['\\[', '\\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
                ignoreHtmlClass: 'mermaid'
            }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" async></script>

    <style>
        /* Locale Switcher Styles */
        .locale-switcher {
            display: flex;
            align-items: center;
            gap: 0.5rem;
            padding: 0.5rem 1rem;
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
            border-radius: 6px;
            font-size: 0.9rem;
            margin-bottom: 1rem;
            box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);
        }

        .current-locale {
            font-weight: 600;
            color: #7b2cbf;
            display: flex;
            align-items: center;
            gap: 0.25rem;
        }

        .locale-separator {
            color: #adb5bd;
            font-weight: 300;
        }

        .locale-link {
            color: #f093fb;
            text-decoration: none;
            font-weight: 500;
            transition: all 0.2s ease;
            display: flex;
            align-items: center;
            gap: 0.25rem;
            padding: 0.2rem 0.5rem;
            border-radius: 4px;
        }

        .locale-link:hover {
            background: rgba(240, 147, 251, 0.1);
            color: #d07be8;
            transform: translateY(-1px);
        }

        .locale-meta {
            color: #868e96;
            font-size: 0.85rem;
            font-style: italic;
            margin-left: auto;
        }

        @media (max-width: 768px) {
            .locale-switcher {
                font-size: 0.85rem;
                padding: 0.4rem 0.8rem;
            }
            .locale-meta {
                display: none;
            }
        }
    </style>
</head>
<body>
            <div class="locale-switcher">
<span class="current-locale">ğŸŒ JP</span>
<span class="locale-separator">|</span>
<a href="../../../en/ML/feature-engineering-introduction/chapter2-categorical-encoding.html" class="locale-link">ğŸ‡¬ğŸ‡§ EN</a>
<span class="locale-separator">|</span>
<span class="locale-meta">Last sync: 2025-11-16</span>
</div>
<nav class="breadcrumb">
        <div class="breadcrumb-content">
            <a href="../../index.html">AIå¯ºå­å±‹ãƒˆãƒƒãƒ—</a><span class="breadcrumb-separator">â€º</span><a href="../../ML/index.html">æ©Ÿæ¢°å­¦ç¿’</a><span class="breadcrumb-separator">â€º</span><a href="../../ML/feature-engineering-introduction/index.html">Feature Engineering</a><span class="breadcrumb-separator">â€º</span><span class="breadcrumb-current">Chapter 2</span>
        </div>
    </nav>

        <header>
        <div class="header-content">
            <h1>ç¬¬2ç« ï¼šã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°</h1>
            <p class="subtitle">æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®ãŸã‚ã®è³ªçš„ãƒ‡ãƒ¼ã‚¿ã®æ•°å€¤å¤‰æ›æŠ€è¡“</p>
            <div class="meta">
                <span class="meta-item">ğŸ“– èª­äº†æ™‚é–“: 20-25åˆ†</span>
                <span class="meta-item">ğŸ“Š é›£æ˜“åº¦: åˆç´šã€œä¸­ç´š</span>
                <span class="meta-item">ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹: 12å€‹</span>
                <span class="meta-item">ğŸ“ æ¼”ç¿’å•é¡Œ: 5å•</span>
            </div>
        </div>
    </header>

    <main class="container">

<h2>å­¦ç¿’ç›®æ¨™</h2>
<p>ã“ã®ç« ã‚’èª­ã‚€ã“ã¨ã§ã€ä»¥ä¸‹ã‚’ç¿’å¾—ã§ãã¾ã™ï¼š</p>
<ul>
<li>âœ… ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°ã®ç¨®é¡ã¨ç‰¹æ€§ã‚’ç†è§£ã™ã‚‹</li>
<li>âœ… One-Hot Encodingã®åŸç†ã¨å®Ÿè£…ãŒã§ãã‚‹</li>
<li>âœ… Label Encodingã¨Ordinal Encodingã®é•ã„ã‚’èª¬æ˜ã§ãã‚‹</li>
<li>âœ… Target Encodingï¼ˆMean Encodingï¼‰ã‚’é©åˆ‡ã«ä½¿ãˆã‚‹</li>
<li>âœ… Frequency Encodingã®æ¦‚å¿µã¨å¿œç”¨ã‚’ç†è§£ã™ã‚‹</li>
<li>âœ… Binary Encodingã¨Hashing Trickã‚’å®Ÿè£…ã§ãã‚‹</li>
<li>âœ… å„ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ‰‹æ³•ã‚’é©åˆ‡ã«ä½¿ã„åˆ†ã‘ã‚‰ã‚Œã‚‹</li>
</ul>

<hr>

<h2>2.1 ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°ã¨ã¯</h2>

<h3>å®šç¾©</h3>
<p><strong>ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°ï¼ˆCategorical Variableï¼‰</strong>ã¯ã€è³ªçš„ãªãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ã™å¤‰æ•°ã§ã€é›¢æ•£çš„ãªã‚«ãƒ†ã‚´ãƒªã‚„æ°´æº–ã‚’æŒã¡ã¾ã™ã€‚</p>

<blockquote>
<p>ã€Œæ•°å€¤ã§è¡¨ã•ã‚Œã¦ã‚‚ã€ãã®å€¤è‡ªä½“ã«æ•°å­¦çš„ãªæ„å‘³ï¼ˆå¤§å°é–¢ä¿‚ã‚„åŠ ç®—ãªã©ï¼‰ãŒãªã„å¤‰æ•°ã€</p>
</blockquote>

<h3>ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°ã®åˆ†é¡</h3>

<table>
<thead>
<tr>
<th>ç¨®é¡</th>
<th>èª¬æ˜</th>
<th>ä¾‹</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>åç¾©å¤‰æ•°ï¼ˆNominalï¼‰</strong></td>
<td>é †åºé–¢ä¿‚ãŒãªã„ã‚«ãƒ†ã‚´ãƒª</td>
<td>è‰²ï¼ˆèµ¤ã€é’ã€ç·‘ï¼‰ã€æ€§åˆ¥ã€å›½å</td>
</tr>
<tr>
<td><strong>é †åºå¤‰æ•°ï¼ˆOrdinalï¼‰</strong></td>
<td>é †åºé–¢ä¿‚ãŒã‚ã‚‹ã‚«ãƒ†ã‚´ãƒª</td>
<td>è©•ä¾¡ï¼ˆä½ã€ä¸­ã€é«˜ï¼‰ã€å­¦æ­´ã€ã‚µã‚¤ã‚ºï¼ˆSã€Mã€Lï¼‰</td>
</tr>
</tbody>
</table>

<h3>ãªãœã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãŒå¿…è¦ã‹</h3>

<p>å¤šãã®æ©Ÿæ¢°å­¦ç¿’ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ï¼ˆç·šå½¢å›å¸°ã€ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã€SVMãªã©ï¼‰ã¯æ•°å€¤ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’æ‰±ã„ã¾ã™ã€‚ãã®ãŸã‚ã€ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°ã‚’æ•°å€¤ã«å¤‰æ›ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚</p>

<pre><code class="language-python">import pandas as pd
import numpy as np

# ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°ã®ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿
data = {
    'color': ['red', 'blue', 'green', 'red', 'blue', 'green'],
    'size': ['S', 'M', 'L', 'M', 'S', 'L'],
    'rating': ['low', 'medium', 'high', 'medium', 'low', 'high'],
    'price': [100, 150, 200, 120, 90, 180]
}

df = pd.DataFrame(data)
print("=== ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°ã®ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ ===")
print(df)
print("\nãƒ‡ãƒ¼ã‚¿å‹:")
print(df.dtypes)

# ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°ã®ç¢ºèª
categorical_cols = df.select_dtypes(include=['object']).columns.tolist()
print(f"\nã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°: {categorical_cols}")

# å„ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯å€¤æ•°
print("\nå„å¤‰æ•°ã®ã‚«ãƒ†ã‚´ãƒªæ•°ï¼ˆã‚«ãƒ¼ãƒ‡ã‚£ãƒŠãƒªãƒ†ã‚£ï¼‰:")
for col in categorical_cols:
    print(f"  {col}: {df[col].nunique()}å€‹ -> {df[col].unique()}")
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>=== ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°ã®ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ ===
   color size rating  price
0    red    S    low    100
1   blue    M medium    150
2  green    L   high    200
3    red    M medium    120
4   blue    S    low     90
5  green    L   high    180

ãƒ‡ãƒ¼ã‚¿å‹:
color     object
size      object
rating    object
price      int64
dtype: object

ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°: ['color', 'size', 'rating']

å„å¤‰æ•°ã®ã‚«ãƒ†ã‚´ãƒªæ•°ï¼ˆã‚«ãƒ¼ãƒ‡ã‚£ãƒŠãƒªãƒ†ã‚£ï¼‰:
  color: 3å€‹ -> ['red' 'blue' 'green']
  size: 3å€‹ -> ['S' 'M' 'L']
  rating: 3å€‹ -> ['low' 'medium' 'high']
</code></pre>

<h3>ã‚«ãƒ¼ãƒ‡ã‚£ãƒŠãƒªãƒ†ã‚£ã®å•é¡Œ</h3>

<p><strong>ã‚«ãƒ¼ãƒ‡ã‚£ãƒŠãƒªãƒ†ã‚£ï¼ˆCardinalityï¼‰</strong>ã¯ã€ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°ãŒæŒã¤ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªå€¤ã®æ•°ã§ã™ã€‚</p>

<ul>
<li><strong>ä½ã‚«ãƒ¼ãƒ‡ã‚£ãƒŠãƒªãƒ†ã‚£</strong>: 2ã€œ10å€‹ç¨‹åº¦ã®ã‚«ãƒ†ã‚´ãƒª â†’ ã»ã¨ã‚“ã©ã®æ‰‹æ³•ãŒé©ç”¨å¯èƒ½</li>
<li><strong>é«˜ã‚«ãƒ¼ãƒ‡ã‚£ãƒŠãƒªãƒ†ã‚£</strong>: 100å€‹ä»¥ä¸Šã®ã‚«ãƒ†ã‚´ãƒª â†’ ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ã‚„éå­¦ç¿’ã«æ³¨æ„ãŒå¿…è¦</li>
</ul>

<div class="mermaid">
graph TD
    A[ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°] --> B{ã‚«ãƒ¼ãƒ‡ã‚£ãƒŠãƒªãƒ†ã‚£ã¯?}
    B -->|ä½ 2-10| C[One-Hot Encodingæ¨å¥¨]
    B -->|ä¸­ 10-100| D[è¤‡æ•°æ‰‹æ³•ã®æ¯”è¼ƒæ¤œè¨]
    B -->|é«˜ 100+| E[Target/Frequency/Hashing]

    C --> F[å„æ‰‹æ³•ã®é©ç”¨]
    D --> F
    E --> F

    style A fill:#e3f2fd
    style C fill:#c8e6c9
    style D fill:#fff9c4
    style E fill:#ffccbc
</div>

<hr>

<h2>2.2 One-Hot Encoding</h2>

<h3>æ¦‚è¦</h3>

<p><strong>One-Hot Encoding</strong>ã¯ã€ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°ã®å„ã‚«ãƒ†ã‚´ãƒªã‚’0ã¨1ã®ãƒã‚¤ãƒŠãƒªãƒ™ã‚¯ãƒˆãƒ«ã§è¡¨ç¾ã™ã‚‹æ‰‹æ³•ã§ã™ã€‚</p>

<h3>åŸç†</h3>

<p>$n$ å€‹ã®ã‚«ãƒ†ã‚´ãƒªã‚’æŒã¤å¤‰æ•°ã‚’ $n$ å€‹ã®ãƒã‚¤ãƒŠãƒªå¤‰æ•°ã«å¤‰æ›ã—ã¾ã™ã€‚å„ã‚µãƒ³ãƒ—ãƒ«ã§ã¯ã€è©²å½“ã™ã‚‹ã‚«ãƒ†ã‚´ãƒªã®åˆ—ãŒ1ã€ãã‚Œä»¥å¤–ãŒ0ã«ãªã‚Šã¾ã™ã€‚</p>

<p><strong>ä¾‹</strong>: è‰² = {red, blue, green}</p>

<table>
<thead>
<tr>
<th>å…ƒãƒ‡ãƒ¼ã‚¿</th>
<th>color_red</th>
<th>color_blue</th>
<th>color_green</th>
</tr>
</thead>
<tbody>
<tr>
<td>red</td>
<td>1</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>blue</td>
<td>0</td>
<td>1</td>
<td>0</td>
</tr>
<tr>
<td>green</td>
<td>0</td>
<td>0</td>
<td>1</td>
</tr>
</tbody>
</table>

<h3>pandasã«ã‚ˆã‚‹å®Ÿè£…</h3>

<pre><code class="language-python">import pandas as pd

# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿
data = {
    'color': ['red', 'blue', 'green', 'red', 'blue'],
    'size': ['S', 'M', 'L', 'M', 'S'],
    'price': [100, 150, 200, 120, 90]
}

df = pd.DataFrame(data)
print("=== å…ƒãƒ‡ãƒ¼ã‚¿ ===")
print(df)

# pandas get_dummiesã«ã‚ˆã‚‹One-Hot Encoding
df_encoded = pd.get_dummies(df, columns=['color', 'size'], drop_first=False)
print("\n=== One-Hot Encodingå¾Œ ===")
print(df_encoded)

# drop_first=Trueã§å¤šé‡å…±ç·šæ€§ã‚’å›é¿
df_encoded_drop = pd.get_dummies(df, columns=['color', 'size'], drop_first=True)
print("\n=== drop_first=Trueï¼ˆ1åˆ—å‰Šé™¤ï¼‰ ===")
print(df_encoded_drop)
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>=== å…ƒãƒ‡ãƒ¼ã‚¿ ===
   color size  price
0    red    S    100
1   blue    M    150
2  green    L    200
3    red    M    120
4   blue    S     90

=== One-Hot Encodingå¾Œ ===
   price  color_blue  color_green  color_red  size_L  size_M  size_S
0    100           0            0          1       0       0       1
1    150           1            0          0       0       1       0
2    200           0            1          0       1       0       0
3    120           0            0          1       0       1       0
4     90           1            0          0       0       0       1

=== drop_first=Trueï¼ˆ1åˆ—å‰Šé™¤ï¼‰ ===
   price  color_green  color_red  size_M  size_S
0    100            0          1       0       1
1    150            0          0       1       0
2    200            1          0       0       0
3    120            0          1       1       0
4     90            0          0       0       1
</code></pre>

<h3>scikit-learnã«ã‚ˆã‚‹å®Ÿè£…</h3>

<pre><code class="language-python">from sklearn.preprocessing import OneHotEncoder
import numpy as np

# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿
X = np.array([['red', 'S'],
              ['blue', 'M'],
              ['green', 'L'],
              ['red', 'M'],
              ['blue', 'S']])

print("=== å…ƒãƒ‡ãƒ¼ã‚¿ ===")
print(X)

# OneHotEncoderã®é©ç”¨
encoder = OneHotEncoder(sparse_output=False, drop=None)
X_encoded = encoder.fit_transform(X)

print("\n=== One-Hot Encodingå¾Œ ===")
print(X_encoded)
print(f"\nå½¢çŠ¶: {X_encoded.shape}")

# ã‚«ãƒ†ã‚´ãƒªã®ç¢ºèª
print("\nã‚«ãƒ†ã‚´ãƒª:")
for i, categories in enumerate(encoder.categories_):
    print(f"  ç‰¹å¾´é‡{i}: {categories}")

# æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã¸ã®é©ç”¨
X_new = np.array([['green', 'S'], ['red', 'L']])
X_new_encoded = encoder.transform(X_new)
print("\n=== æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚° ===")
print(X_new)
print("â†“")
print(X_new_encoded)
</code></pre>

<h3>ã‚¹ãƒ‘ãƒ¼ã‚¹è¡Œåˆ—ã®æ´»ç”¨</h3>

<p>é«˜ã‚«ãƒ¼ãƒ‡ã‚£ãƒŠãƒªãƒ†ã‚£ã®ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°ã§ã¯ã€One-Hot Encodingã«ã‚ˆã£ã¦å¤§é‡ã®0ã‚’å«ã‚€è¡Œåˆ—ãŒç”Ÿæˆã•ã‚Œã¾ã™ã€‚<strong>ã‚¹ãƒ‘ãƒ¼ã‚¹è¡Œåˆ—</strong>ã‚’ä½¿ã†ã“ã¨ã§ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ã‚’æ”¹å–„ã§ãã¾ã™ã€‚</p>

<pre><code class="language-python">from sklearn.preprocessing import OneHotEncoder
from scipy.sparse import csr_matrix
import numpy as np

# é«˜ã‚«ãƒ¼ãƒ‡ã‚£ãƒŠãƒªãƒ†ã‚£ã®ã‚µãƒ³ãƒ—ãƒ«
np.random.seed(42)
n_samples = 10000
categories = [f'cat_{i}' for i in range(1000)]
X = np.random.choice(categories, size=(n_samples, 1))

print(f"ã‚µãƒ³ãƒ—ãƒ«æ•°: {n_samples}")
print(f"ã‚«ãƒ†ã‚´ãƒªæ•°: {len(categories)}")

# Denseå½¢å¼
encoder_dense = OneHotEncoder(sparse_output=False)
X_dense = encoder_dense.fit_transform(X)
dense_size = X_dense.nbytes / (1024 ** 2)  # MB

# Sparseå½¢å¼
encoder_sparse = OneHotEncoder(sparse_output=True)
X_sparse = encoder_sparse.fit_transform(X)
sparse_size = (X_sparse.data.nbytes + X_sparse.indices.nbytes +
               X_sparse.indptr.nbytes) / (1024 ** 2)  # MB

print("\n=== ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®æ¯”è¼ƒ ===")
print(f"Denseå½¢å¼: {dense_size:.2f} MB")
print(f"Sparseå½¢å¼: {sparse_size:.2f} MB")
print(f"å‰Šæ¸›ç‡: {(1 - sparse_size/dense_size) * 100:.1f}%")
</code></pre>

<h3>One-Hot Encodingã®åˆ©ç‚¹ã¨æ¬ ç‚¹</h3>

<table>
<thead>
<tr>
<th>åˆ©ç‚¹</th>
<th>æ¬ ç‚¹</th>
</tr>
</thead>
<tbody>
<tr>
<td>ã‚«ãƒ†ã‚´ãƒªé–“ã«é †åºã‚’ä»®å®šã—ãªã„</td>
<td>ã‚«ãƒ†ã‚´ãƒªæ•°ã«æ¯”ä¾‹ã—ã¦æ¬¡å…ƒãŒå¢—åŠ </td>
</tr>
<tr>
<td>å®Ÿè£…ãŒç°¡å˜ã§è§£é‡ˆã—ã‚„ã™ã„</td>
<td>é«˜ã‚«ãƒ¼ãƒ‡ã‚£ãƒŠãƒªãƒ†ã‚£ã§éåŠ¹ç‡</td>
</tr>
<tr>
<td>ç·šå½¢ãƒ¢ãƒ‡ãƒ«ã¨ã®ç›¸æ€§ãŒè‰¯ã„</td>
<td>ã‚¹ãƒ‘ãƒ¼ã‚¹æ€§ã®å•é¡Œ</td>
</tr>
<tr>
<td>æ–°ã—ã„ã‚«ãƒ†ã‚´ãƒªã®å¯¾å¿œãŒå¿…è¦</td>
<td>å¤šé‡å…±ç·šæ€§ã®ãƒªã‚¹ã‚¯</td>
</tr>
</tbody>
</table>

<hr>

<h2>2.3 Label Encodingã¨Ordinal Encoding</h2>

<h3>Label Encoding</h3>

<p><strong>Label Encoding</strong>ã¯ã€å„ã‚«ãƒ†ã‚´ãƒªã‚’æ•´æ•°ï¼ˆ0, 1, 2, ...ï¼‰ã«å¤‰æ›ã™ã‚‹æ‰‹æ³•ã§ã™ã€‚</p>

<pre><code class="language-python">from sklearn.preprocessing import LabelEncoder

# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿
colors = ['red', 'blue', 'green', 'red', 'blue', 'green', 'red']

# LabelEncoderã®é©ç”¨
label_encoder = LabelEncoder()
colors_encoded = label_encoder.fit_transform(colors)

print("=== Label Encoding ===")
print(f"å…ƒãƒ‡ãƒ¼ã‚¿: {colors}")
print(f"ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰å¾Œ: {colors_encoded}")
print(f"\nãƒãƒƒãƒ”ãƒ³ã‚°:")
for i, label in enumerate(label_encoder.classes_):
    print(f"  {label} -> {i}")

# é€†å¤‰æ›
colors_decoded = label_encoder.inverse_transform(colors_encoded)
print(f"\né€†å¤‰æ›: {colors_decoded}")
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>=== Label Encoding ===
å…ƒãƒ‡ãƒ¼ã‚¿: ['red', 'blue', 'green', 'red', 'blue', 'green', 'red']
ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰å¾Œ: [2 0 1 2 0 1 2]

ãƒãƒƒãƒ”ãƒ³ã‚°:
  blue -> 0
  green -> 1
  red -> 2

é€†å¤‰æ›: ['red' 'blue' 'green' 'red' 'blue' 'green' 'red']
</code></pre>

<h3>Ordinal Encoding</h3>

<p><strong>Ordinal Encoding</strong>ã¯ã€é †åºé–¢ä¿‚ã®ã‚ã‚‹ã‚«ãƒ†ã‚´ãƒªã«å¯¾ã—ã¦ã€ãã®é †åºã‚’ä¿æŒã—ãŸæ•°å€¤ã‚’å‰²ã‚Šå½“ã¦ã‚‹æ‰‹æ³•ã§ã™ã€‚</p>

<pre><code class="language-python">from sklearn.preprocessing import OrdinalEncoder
import numpy as np

# é †åºä»˜ãã‚«ãƒ†ã‚´ãƒªã®ã‚µãƒ³ãƒ—ãƒ«
data = {
    'size': ['S', 'M', 'L', 'XL', 'M', 'S', 'L'],
    'rating': ['low', 'medium', 'high', 'medium', 'low', 'high', 'medium']
}

df = pd.DataFrame(data)
print("=== å…ƒãƒ‡ãƒ¼ã‚¿ ===")
print(df)

# é †åºã®å®šç¾©
size_order = ['S', 'M', 'L', 'XL']
rating_order = ['low', 'medium', 'high']

# OrdinalEncoderã®é©ç”¨
ordinal_encoder = OrdinalEncoder(categories=[size_order, rating_order])
df_encoded = df.copy()
df_encoded[['size', 'rating']] = ordinal_encoder.fit_transform(df[['size', 'rating']])

print("\n=== Ordinal Encodingå¾Œ ===")
print(df_encoded)

print("\né †åºãƒãƒƒãƒ”ãƒ³ã‚°:")
print("size: S(0) < M(1) < L(2) < XL(3)")
print("rating: low(0) < medium(1) < high(2)")
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>=== å…ƒãƒ‡ãƒ¼ã‚¿ ===
  size  rating
0    S     low
1    M  medium
2    L    high
3   XL  medium
4    M     low
5    S    high
6    L  medium

=== Ordinal Encodingå¾Œ ===
   size  rating
0   0.0     0.0
1   1.0     1.0
2   2.0     2.0
3   3.0     1.0
4   1.0     0.0
5   0.0     2.0
6   2.0     1.0

é †åºãƒãƒƒãƒ”ãƒ³ã‚°:
size: S(0) < M(1) < L(2) < XL(3)
rating: low(0) < medium(1) < high(2)
</code></pre>

<h3>Label Encodingã¨Ordinal Encodingã®é•ã„</h3>

<table>
<thead>
<tr>
<th>ç‰¹å¾´</th>
<th>Label Encoding</th>
<th>Ordinal Encoding</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>ç”¨é€”</strong></td>
<td>ç›®çš„å¤‰æ•°ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°</td>
<td>èª¬æ˜å¤‰æ•°ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°</td>
</tr>
<tr>
<td><strong>é †åºã®è€ƒæ…®</strong></td>
<td>è€ƒæ…®ã—ãªã„ï¼ˆã‚¢ãƒ«ãƒ•ã‚¡ãƒ™ãƒƒãƒˆé †ãªã©ï¼‰</td>
<td>æ˜ç¤ºçš„ã«é †åºã‚’æŒ‡å®š</td>
</tr>
<tr>
<td><strong>å®Ÿè£…</strong></td>
<td>LabelEncoderï¼ˆ1æ¬¡å…ƒã®ã¿ï¼‰</td>
<td>OrdinalEncoderï¼ˆè¤‡æ•°åˆ—å¯¾å¿œï¼‰</td>
</tr>
<tr>
<td><strong>é©ç”¨å¯¾è±¡</strong></td>
<td>åˆ†é¡å•é¡Œã®ãƒ©ãƒ™ãƒ«</td>
<td>é †åºä»˜ãã‚«ãƒ†ã‚´ãƒªç‰¹å¾´é‡</td>
</tr>
</tbody>
</table>

<h3>æ³¨æ„ç‚¹ï¼šèª¤ã£ãŸé †åºã®ä»®å®š</h3>

<pre><code class="language-python">from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import cross_val_score
from sklearn.preprocessing import LabelEncoder, OneHotEncoder

# åç¾©å¤‰æ•°ï¼ˆé †åºãªã—ï¼‰ã®ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿
np.random.seed(42)
n_samples = 1000
colors = np.random.choice(['red', 'blue', 'green'], size=n_samples)
# 'red'ã®ã¨ãã«yãŒ1ã«ãªã‚Šã‚„ã™ã„
y = (colors == 'red').astype(int)

# 1. Label Encodingã§å­¦ç¿’ï¼ˆä¸é©åˆ‡ï¼‰
label_encoder = LabelEncoder()
X_label = label_encoder.fit_transform(colors).reshape(-1, 1)

clf_label = DecisionTreeClassifier(random_state=42)
score_label = cross_val_score(clf_label, X_label, y, cv=5).mean()

# 2. One-Hot Encodingã§å­¦ç¿’ï¼ˆé©åˆ‡ï¼‰
onehot_encoder = OneHotEncoder(sparse_output=False)
X_onehot = onehot_encoder.fit_transform(colors.reshape(-1, 1))

clf_onehot = DecisionTreeClassifier(random_state=42)
score_onehot = cross_val_score(clf_onehot, X_onehot, y, cv=5).mean()

print("=== ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ‰‹æ³•ã®æ¯”è¼ƒ ===")
print(f"Label Encoding: {score_label:.4f}")
print(f"One-Hot Encoding: {score_onehot:.4f}")
print("\nâš ï¸ æ±ºå®šæœ¨ã§ã¯å·®ãŒå°ã•ã„ãŒã€ç·šå½¢ãƒ¢ãƒ‡ãƒ«ã§ã¯å¤§ããªå·®ãŒå‡ºã‚‹")
</code></pre>

<blockquote>
<p><strong>é‡è¦</strong>: åç¾©å¤‰æ•°ã«Label Encodingã‚’é©ç”¨ã™ã‚‹ã¨ã€å­˜åœ¨ã—ãªã„é †åºé–¢ä¿‚ãŒãƒ¢ãƒ‡ãƒ«ã«å­¦ç¿’ã•ã‚Œã¾ã™ã€‚ç·šå½¢ãƒ¢ãƒ‡ãƒ«ã‚„ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã§ã¯One-Hot Encodingã‚’æ¨å¥¨ã—ã¾ã™ã€‚</p>
</blockquote>

<hr>

<h2>2.4 Target Encodingï¼ˆMean Encodingï¼‰</h2>

<h3>æ¦‚è¦</h3>

<p><strong>Target Encoding</strong>ã¯ã€å„ã‚«ãƒ†ã‚´ãƒªã‚’ç›®çš„å¤‰æ•°ã®å¹³å‡å€¤ï¼ˆã¾ãŸã¯ä»–ã®çµ±è¨ˆé‡ï¼‰ã§ç½®ãæ›ãˆã‚‹æ‰‹æ³•ã§ã™ã€‚<strong>Mean Encoding</strong>ã¨ã‚‚å‘¼ã°ã‚Œã¾ã™ã€‚</p>

<h3>åŸç†</h3>

<p>ã‚«ãƒ†ã‚´ãƒª $c$ ã®Target Encodingå€¤ï¼š</p>

<p>$$
\text{TE}(c) = \frac{\sum_{i: x_i = c} y_i}{|i: x_i = c|}
$$</p>

<p>ã¤ã¾ã‚Šã€ãã®ã‚«ãƒ†ã‚´ãƒªã«å±ã™ã‚‹ã‚µãƒ³ãƒ—ãƒ«ã®ç›®çš„å¤‰æ•°ã®å¹³å‡å€¤ã§ã™ã€‚</p>

<h3>éå­¦ç¿’ã®å•é¡Œã¨ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°</h3>

<p>Target Encodingã¯ç›®çš„å¤‰æ•°ã‚’ç›´æ¥ä½¿ã†ãŸã‚ã€<strong>éå­¦ç¿’ã—ã‚„ã™ã„</strong>ã¨ã„ã†å•é¡ŒãŒã‚ã‚Šã¾ã™ã€‚ã“ã‚Œã‚’é˜²ããŸã‚ã€<strong>ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°</strong>ã‚’é©ç”¨ã—ã¾ã™ï¼š</p>

<p>$$
\text{TE}_{\text{smooth}}(c) = \frac{n_c \cdot \text{mean}_c + m \cdot \text{global\_mean}}{n_c + m}
$$</p>

<ul>
<li>$n_c$: ã‚«ãƒ†ã‚´ãƒª $c$ ã®ã‚µãƒ³ãƒ—ãƒ«æ•°</li>
<li>$\text{mean}_c$: ã‚«ãƒ†ã‚´ãƒª $c$ ã®ç›®çš„å¤‰æ•°å¹³å‡</li>
<li>$\text{global\_mean}$: å…¨ä½“ã®ç›®çš„å¤‰æ•°å¹³å‡</li>
<li>$m$: ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆé€šå¸¸1ã€œ100ï¼‰</li>
</ul>

<h3>ã‚¹ã‚¯ãƒ©ãƒƒãƒå®Ÿè£…</h3>

<pre><code class="language-python">import pandas as pd
import numpy as np

# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿
np.random.seed(42)
data = {
    'category': ['A', 'B', 'C', 'A', 'B', 'C', 'A', 'B', 'C', 'A'] * 10,
    'target': np.random.randint(0, 2, 100)
}

# ã‚«ãƒ†ã‚´ãƒªAã®targetã‚’æ„å›³çš„ã«é«˜ãè¨­å®š
data_list = list(zip(data['category'], data['target']))
modified_data = []
for cat, target in data_list:
    if cat == 'A':
        target = 1 if np.random.rand() < 0.8 else 0
    modified_data.append((cat, target))

df = pd.DataFrame(modified_data, columns=['category', 'target'])

print("=== ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ ===")
print(df.head(10))
print(f"\nå„ã‚«ãƒ†ã‚´ãƒªã®ç›®çš„å¤‰æ•°å¹³å‡:")
print(df.groupby('category')['target'].mean())

# Target Encodingï¼ˆã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°ãªã—ï¼‰
def target_encoding_simple(df, column, target_col):
    """ã‚·ãƒ³ãƒ—ãƒ«ãªTarget Encoding"""
    mean_encoding = df.groupby(column)[target_col].mean()
    return df[column].map(mean_encoding)

# Target Encodingï¼ˆã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°ã‚ã‚Šï¼‰
def target_encoding_smoothed(df, column, target_col, m=10):
    """ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°ä»˜ãTarget Encoding"""
    global_mean = df[target_col].mean()
    category_stats = df.groupby(column)[target_col].agg(['mean', 'count'])

    smoothed = (category_stats['count'] * category_stats['mean'] +
                m * global_mean) / (category_stats['count'] + m)

    return df[column].map(smoothed)

# é©ç”¨
df['te_simple'] = target_encoding_simple(df, 'category', 'target')
df['te_smoothed'] = target_encoding_smoothed(df, 'category', 'target', m=10)

print("\n=== Target Encodingçµæœ ===")
print(df.groupby('category')[['target', 'te_simple', 'te_smoothed']].mean())
</code></pre>

<h3>Cross-Validationæˆ¦ç•¥</h3>

<p>å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã§è¨ˆç®—ã—ãŸTarget Encodingã‚’åŒã˜å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã«é©ç”¨ã™ã‚‹ã¨ã€<strong>ãƒªãƒ¼ã‚±ãƒ¼ã‚¸ï¼ˆæƒ…å ±æ¼æ´©ï¼‰</strong>ãŒç™ºç”Ÿã—ã¾ã™ã€‚ã“ã‚Œã‚’é˜²ããŸã‚ã€<strong>Out-of-Fold</strong>æˆ¦ç•¥ã‚’ä½¿ã„ã¾ã™ã€‚</p>

<pre><code class="language-python">from sklearn.model_selection import KFold

def target_encoding_cv(X, y, column, n_splits=5, m=10):
    """Cross-Validationã«ã‚ˆã‚‹Target Encoding"""
    kfold = KFold(n_splits=n_splits, shuffle=True, random_state=42)
    encoded = np.zeros(len(X))
    global_mean = y.mean()

    for train_idx, val_idx in kfold.split(X):
        X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]

        # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã§çµ±è¨ˆé‡ã‚’è¨ˆç®—
        category_stats = pd.DataFrame({
            'category': X_train[column],
            'target': y_train
        }).groupby('category')['target'].agg(['mean', 'count'])

        # ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°
        smoothed_means = (category_stats['count'] * category_stats['mean'] +
                          m * global_mean) / (category_stats['count'] + m)

        # æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã«é©ç”¨
        encoded[val_idx] = X.iloc[val_idx][column].map(smoothed_means)

        # ãƒãƒƒãƒ”ãƒ³ã‚°ã•ã‚Œãªã‹ã£ãŸå€¤ã¯global_meanã§åŸ‹ã‚ã‚‹
        encoded[val_idx] = np.nan_to_num(encoded[val_idx], nan=global_mean)

    return encoded

# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿
np.random.seed(42)
n_samples = 500
X = pd.DataFrame({
    'category': np.random.choice(['A', 'B', 'C', 'D'], size=n_samples)
})
y = pd.Series(np.random.randint(0, 2, n_samples))

# ã‚«ãƒ†ã‚´ãƒªAã®targetã‚’é«˜ãè¨­å®š
y[X['category'] == 'A'] = np.random.choice([0, 1], size=(X['category'] == 'A').sum(), p=[0.2, 0.8])

# CVæˆ¦ç•¥ã«ã‚ˆã‚‹Target Encoding
X['te_cv'] = target_encoding_cv(X, y, 'category', n_splits=5, m=10)

print("=== Cross-Validationã«ã‚ˆã‚‹Target Encoding ===")
print(X.groupby('category')['te_cv'].agg(['mean', 'std']))
print(f"\nç›®çš„å¤‰æ•°ã®å¹³å‡:")
print(y.groupby(X['category']).mean())
</code></pre>

<h3>category_encodersãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ä½¿ç”¨</h3>

<pre><code class="language-python">import category_encoders as ce
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
np.random.seed(42)
n_samples = 1000
X = pd.DataFrame({
    'category1': np.random.choice(['A', 'B', 'C', 'D'], size=n_samples),
    'category2': np.random.choice(['X', 'Y', 'Z'], size=n_samples),
    'numeric': np.random.randn(n_samples)
})

# ã‚«ãƒ†ã‚´ãƒªAã¨Xã®çµ„ã¿åˆã‚ã›ã§targetãŒ1ã«ãªã‚Šã‚„ã™ã„
y = ((X['category1'] == 'A') & (X['category2'] == 'X')).astype(int)
y = np.where(np.random.rand(n_samples) < 0.3, 1 - y, y)  # ãƒã‚¤ã‚ºè¿½åŠ 

# è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«åˆ†å‰²
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# 1. One-Hot Encodingã§å­¦ç¿’
X_train_onehot = pd.get_dummies(X_train, columns=['category1', 'category2'])
X_test_onehot = pd.get_dummies(X_test, columns=['category1', 'category2'])

# ã‚«ãƒ©ãƒ ã‚’æƒãˆã‚‹
missing_cols = set(X_train_onehot.columns) - set(X_test_onehot.columns)
for col in missing_cols:
    X_test_onehot[col] = 0
X_test_onehot = X_test_onehot[X_train_onehot.columns]

clf_onehot = RandomForestClassifier(n_estimators=100, random_state=42)
clf_onehot.fit(X_train_onehot, y_train)
y_pred_onehot = clf_onehot.predict(X_test_onehot)
acc_onehot = accuracy_score(y_test, y_pred_onehot)

# 2. Target Encodingã§å­¦ç¿’
target_encoder = ce.TargetEncoder(cols=['category1', 'category2'], smoothing=10)
X_train_te = target_encoder.fit_transform(X_train, y_train)
X_test_te = target_encoder.transform(X_test)

clf_te = RandomForestClassifier(n_estimators=100, random_state=42)
clf_te.fit(X_train_te, y_train)
y_pred_te = clf_te.predict(X_test_te)
acc_te = accuracy_score(y_test, y_pred_te)

print("=== ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ‰‹æ³•ã®æ€§èƒ½æ¯”è¼ƒ ===")
print(f"One-Hot Encoding: ç²¾åº¦ = {acc_onehot:.4f}")
print(f"Target Encoding:  ç²¾åº¦ = {acc_te:.4f}")
</code></pre>

<h3>Target Encodingã®åˆ©ç‚¹ã¨æ¬ ç‚¹</h3>

<table>
<thead>
<tr>
<th>åˆ©ç‚¹</th>
<th>æ¬ ç‚¹</th>
</tr>
</thead>
<tbody>
<tr>
<td>é«˜ã‚«ãƒ¼ãƒ‡ã‚£ãƒŠãƒªãƒ†ã‚£ã«å¯¾å¿œ</td>
<td>éå­¦ç¿’ã—ã‚„ã™ã„</td>
</tr>
<tr>
<td>æ¬¡å…ƒãŒå¢—åŠ ã—ãªã„</td>
<td>CVæˆ¦ç•¥ãŒå¿…é ˆ</td>
</tr>
<tr>
<td>ç›®çš„å¤‰æ•°ã¨ã®é–¢ä¿‚ã‚’ç›´æ¥æ‰ãˆã‚‹</td>
<td>å®Ÿè£…ãŒè¤‡é›‘</td>
</tr>
<tr>
<td>æœ¨ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã¨ã®ç›¸æ€§ãŒè‰¯ã„</td>
<td>å›å¸°å•é¡Œã§ã¯åŠ¹æœãŒé™å®šçš„ãªå ´åˆã‚‚</td>
</tr>
</tbody>
</table>

<hr>

<h2>2.5 Frequency Encoding</h2>

<h3>æ¦‚è¦</h3>

<p><strong>Frequency Encoding</strong>ã¯ã€å„ã‚«ãƒ†ã‚´ãƒªã‚’å‡ºç¾é »åº¦ï¼ˆã¾ãŸã¯å‡ºç¾å‰²åˆï¼‰ã§ç½®ãæ›ãˆã‚‹æ‰‹æ³•ã§ã™ã€‚</p>

<h3>åŸç†</h3>

<p>ã‚«ãƒ†ã‚´ãƒª $c$ ã®Frequency Encodingå€¤ï¼š</p>

<p>$$
\text{FE}(c) = \frac{\text{count}(c)}{N}
$$</p>

<p>ã“ã“ã§ $N$ ã¯ç·ã‚µãƒ³ãƒ—ãƒ«æ•°ã§ã™ã€‚</p>

<h3>å®Ÿè£…</h3>

<pre><code class="language-python">import pandas as pd
import numpy as np

# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿
np.random.seed(42)
categories = ['A', 'B', 'C', 'D', 'E']
# ã‚«ãƒ†ã‚´ãƒªAãŒæœ€ã‚‚é »ç¹ã«å‡ºç¾
probabilities = [0.5, 0.2, 0.15, 0.1, 0.05]

data = {
    'category': np.random.choice(categories, size=1000, p=probabilities),
    'value': np.random.randn(1000)
}

df = pd.DataFrame(data)

print("=== ã‚«ãƒ†ã‚´ãƒªã®å‡ºç¾å›æ•° ===")
print(df['category'].value_counts().sort_index())

# Frequency Encodingï¼ˆã‚«ã‚¦ãƒ³ãƒˆãƒ™ãƒ¼ã‚¹ï¼‰
def frequency_encoding_count(df, column):
    """ã‚«ã‚¦ãƒ³ãƒˆãƒ™ãƒ¼ã‚¹ã®Frequency Encoding"""
    frequency = df[column].value_counts()
    return df[column].map(frequency)

# Frequency Encodingï¼ˆå‰²åˆãƒ™ãƒ¼ã‚¹ï¼‰
def frequency_encoding_ratio(df, column):
    """å‰²åˆãƒ™ãƒ¼ã‚¹ã®Frequency Encoding"""
    frequency = df[column].value_counts(normalize=True)
    return df[column].map(frequency)

# é©ç”¨
df['freq_count'] = frequency_encoding_count(df, 'category')
df['freq_ratio'] = frequency_encoding_ratio(df, 'category')

print("\n=== Frequency Encodingçµæœ ===")
print(df.groupby('category')[['freq_count', 'freq_ratio']].first().sort_index())
print("\nã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿:")
print(df.head(10))
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>=== ã‚«ãƒ†ã‚´ãƒªã®å‡ºç¾å›æ•° ===
A    492
B    206
C    163
D     95
E     44
Name: category, dtype: int64

=== Frequency Encodingçµæœ ===
          freq_count  freq_ratio
category
A                492       0.492
B                206       0.206
C                163       0.163
D                 95       0.095
E                 44       0.044

ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿:
  category     value  freq_count  freq_ratio
0        C  0.496714         163       0.163
1        A -0.138264         492       0.492
2        A  0.647689         492       0.492
3        A  1.523030         492       0.492
4        B -0.234153         206       0.206
</code></pre>

<h3>Frequency Encodingã®å¿œç”¨ä¾‹</h3>

<pre><code class="language-python">from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
np.random.seed(42)
n_samples = 2000

# é«˜é »åº¦ã‚«ãƒ†ã‚´ãƒªãŒtarget=1ã«ãªã‚Šã‚„ã™ã„
categories = np.random.choice(['A', 'B', 'C', 'D', 'E'],
                              size=n_samples,
                              p=[0.4, 0.25, 0.2, 0.1, 0.05])

# 'A'ã¨'B'ã®ã¨ãã«targetãŒ1ã«ãªã‚Šã‚„ã™ã„
target = np.where(np.isin(categories, ['A', 'B']),
                  np.random.choice([0, 1], n_samples, p=[0.3, 0.7]),
                  np.random.choice([0, 1], n_samples, p=[0.7, 0.3]))

X = pd.DataFrame({'category': categories})
y = target

# è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«åˆ†å‰²
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# 1. Label Encodingã§å­¦ç¿’
label_encoder = LabelEncoder()
X_train_label = label_encoder.fit_transform(X_train['category']).reshape(-1, 1)
X_test_label = label_encoder.transform(X_test['category']).reshape(-1, 1)

clf_label = RandomForestClassifier(n_estimators=100, random_state=42)
clf_label.fit(X_train_label, y_train)
acc_label = accuracy_score(y_test, clf_label.predict(X_test_label))

# 2. Frequency Encodingã§å­¦ç¿’
freq_map = X_train['category'].value_counts(normalize=True)
X_train_freq = X_train['category'].map(freq_map).values.reshape(-1, 1)
X_test_freq = X_test['category'].map(freq_map).fillna(0).values.reshape(-1, 1)

clf_freq = RandomForestClassifier(n_estimators=100, random_state=42)
clf_freq.fit(X_train_freq, y_train)
acc_freq = accuracy_score(y_test, clf_freq.predict(X_test_freq))

# 3. One-Hot Encodingã§å­¦ç¿’
X_train_onehot = pd.get_dummies(X_train, columns=['category'])
X_test_onehot = pd.get_dummies(X_test, columns=['category'])
X_test_onehot = X_test_onehot.reindex(columns=X_train_onehot.columns, fill_value=0)

clf_onehot = RandomForestClassifier(n_estimators=100, random_state=42)
clf_onehot.fit(X_train_onehot, y_train)
acc_onehot = accuracy_score(y_test, clf_onehot.predict(X_test_onehot))

print("=== ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ‰‹æ³•ã®æ€§èƒ½æ¯”è¼ƒ ===")
print(f"Label Encoding:     ç²¾åº¦ = {acc_label:.4f}")
print(f"Frequency Encoding: ç²¾åº¦ = {acc_freq:.4f}")
print(f"One-Hot Encoding:   ç²¾åº¦ = {acc_onehot:.4f}")
</code></pre>

<h3>ã„ã¤Frequency Encodingã‚’ä½¿ã†ã¹ãã‹</h3>

<ul>
<li>ã‚«ãƒ†ã‚´ãƒªã®å‡ºç¾é »åº¦ãŒç›®çš„å¤‰æ•°ã¨ç›¸é–¢ãŒã‚ã‚‹å ´åˆ</li>
<li>é«˜ã‚«ãƒ¼ãƒ‡ã‚£ãƒŠãƒªãƒ†ã‚£ã®ã‚«ãƒ†ã‚´ãƒªå¤‰æ•°</li>
<li>æ¬¡å…ƒå‰Šæ¸›ãŒå¿…è¦ãªå ´åˆ</li>
<li>æ–°ã—ã„ã‚«ãƒ†ã‚´ãƒªï¼ˆæœªçŸ¥ã®ã‚«ãƒ†ã‚´ãƒªï¼‰ãŒå‡ºç¾ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹å ´åˆ</li>
</ul>

<hr>

<h2>2.6 Binary Encodingã¨Hashing</h2>

<h3>Binary Encoding</h3>

<p><strong>Binary Encoding</strong>ã¯ã€ã‚«ãƒ†ã‚´ãƒªã‚’æ•´æ•°ã«å¤‰æ›ã—ã€ãã®æ•´æ•°ã‚’2é€²æ•°ã§è¡¨ç¾ã™ã‚‹æ‰‹æ³•ã§ã™ã€‚One-Hot Encodingã‚ˆã‚Šæ¬¡å…ƒã‚’å‰Šæ¸›ã§ãã¾ã™ã€‚</p>

<h3>åŸç†</h3>

<p>$n$ å€‹ã®ã‚«ãƒ†ã‚´ãƒªã‚’ $\lceil \log_2 n \rceil$ å€‹ã®ãƒã‚¤ãƒŠãƒªåˆ—ã§è¡¨ç¾ã—ã¾ã™ã€‚</p>

<p><strong>ä¾‹</strong>: 8å€‹ã®ã‚«ãƒ†ã‚´ãƒª â†’ 3åˆ—ï¼ˆ$\lceil \log_2 8 \rceil = 3$ï¼‰</p>

<table>
<thead>
<tr>
<th>ã‚«ãƒ†ã‚´ãƒª</th>
<th>æ•´æ•°</th>
<th>bit_0</th>
<th>bit_1</th>
<th>bit_2</th>
</tr>
</thead>
<tbody>
<tr>
<td>A</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>B</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>1</td>
</tr>
<tr>
<td>C</td>
<td>2</td>
<td>0</td>
<td>1</td>
<td>0</td>
</tr>
<tr>
<td>D</td>
<td>3</td>
<td>0</td>
<td>1</td>
<td>1</td>
</tr>
<tr>
<td>E</td>
<td>4</td>
<td>1</td>
<td>0</td>
<td>0</td>
</tr>
</tbody>
</table>

<h3>å®Ÿè£…</h3>

<pre><code class="language-python">import category_encoders as ce
import pandas as pd
import numpy as np

# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿
np.random.seed(42)
categories = [f'cat_{i}' for i in range(50)]
data = {
    'category': np.random.choice(categories, size=200)
}

df = pd.DataFrame(data)

print(f"=== Binary Encoding ===")
print(f"ã‚«ãƒ†ã‚´ãƒªæ•°: {df['category'].nunique()}")
print(f"å¿…è¦ãªãƒ“ãƒƒãƒˆæ•°: {int(np.ceil(np.log2(df['category'].nunique())))}")

# Binary Encoderã®é©ç”¨
binary_encoder = ce.BinaryEncoder(cols=['category'])
df_encoded = binary_encoder.fit_transform(df)

print(f"\nã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰å¾Œã®åˆ—æ•°: {df_encoded.shape[1]}")
print("\nã‚µãƒ³ãƒ—ãƒ«:")
print(df_encoded.head(10))

# æ¬¡å…ƒã®æ¯”è¼ƒ
print("\n=== One-Hot vs Binary Encoding ===")
n_categories = 100
onehot_dims = n_categories
binary_dims = int(np.ceil(np.log2(n_categories)))

print(f"ã‚«ãƒ†ã‚´ãƒªæ•°: {n_categories}")
print(f"One-Hot Encoding: {onehot_dims}æ¬¡å…ƒ")
print(f"Binary Encoding: {binary_dims}æ¬¡å…ƒ")
print(f"å‰Šæ¸›ç‡: {(1 - binary_dims/onehot_dims) * 100:.1f}%")
</code></pre>

<h3>Hashing Trick</h3>

<p><strong>Hashing Trick</strong>ã¯ã€ãƒãƒƒã‚·ãƒ¥é–¢æ•°ã‚’ä½¿ã£ã¦ã‚«ãƒ†ã‚´ãƒªã‚’å›ºå®šæ¬¡å…ƒã®ãƒ™ã‚¯ãƒˆãƒ«ã«å¤‰æ›ã™ã‚‹æ‰‹æ³•ã§ã™ã€‚</p>

<h3>åŸç†</h3>

<ol>
<li>ãƒãƒƒã‚·ãƒ¥é–¢æ•° $h$ ã§ã‚«ãƒ†ã‚´ãƒªã‚’æ•´æ•°ã«ãƒãƒƒãƒ”ãƒ³ã‚°: $h(c) \in \{0, 1, ..., m-1\}$</li>
<li>ãã®æ•´æ•°ã«å¯¾å¿œã™ã‚‹ä½ç½®ã‚’1ã«ã™ã‚‹</li>
</ol>

<p><strong>åˆ©ç‚¹</strong>:</p>
<ul>
<li>äº‹å‰ã«ã‚«ãƒ†ã‚´ãƒªã®æ•°ã‚’çŸ¥ã‚‹å¿…è¦ãŒãªã„</li>
<li>æ–°ã—ã„ã‚«ãƒ†ã‚´ãƒªãŒè‡ªå‹•çš„ã«å‡¦ç†ã•ã‚Œã‚‹</li>
<li>ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ãŒè‰¯ã„</li>
</ul>

<p><strong>æ¬ ç‚¹</strong>:</p>
<ul>
<li>ãƒãƒƒã‚·ãƒ¥ã®è¡çªï¼ˆç•°ãªã‚‹ã‚«ãƒ†ã‚´ãƒªãŒåŒã˜å€¤ã«ãƒãƒƒãƒ”ãƒ³ã‚°ï¼‰</li>
<li>è§£é‡ˆæ€§ã®ä½ä¸‹</li>
</ul>

<h3>å®Ÿè£…</h3>

<pre><code class="language-python">from sklearn.feature_extraction import FeatureHasher
import pandas as pd
import numpy as np

# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿
np.random.seed(42)
categories = [f'cat_{i}' for i in range(1000)]
data = {'category': np.random.choice(categories, size=5000)}
df = pd.DataFrame(data)

print("=== Hashing Trick ===")
print(f"ãƒ¦ãƒ‹ãƒ¼ã‚¯ã‚«ãƒ†ã‚´ãƒªæ•°: {df['category'].nunique()}")

# FeatureHasherã®é©ç”¨
n_features = 50  # ãƒãƒƒã‚·ãƒ¥ã®æ¬¡å…ƒ
hasher = FeatureHasher(n_features=n_features, input_type='string')

# ã‚«ãƒ†ã‚´ãƒªã‚’ãƒªã‚¹ãƒˆã®ãƒªã‚¹ãƒˆã«å¤‰æ›
X_hashed = hasher.transform([[cat] for cat in df['category']])

print(f"ãƒãƒƒã‚·ãƒ¥å¾Œã®æ¬¡å…ƒ: {X_hashed.shape[1]}")
print(f"ã‚¹ãƒ‘ãƒ¼ã‚¹æ€§: {(1 - X_hashed.nnz / (X_hashed.shape[0] * X_hashed.shape[1])) * 100:.1f}%")

# ãƒãƒƒã‚·ãƒ¥è¡çªã®ç¢ºèª
unique_hashes = set()
collisions = 0

for cat in df['category'].unique():
    hash_val = hash(cat) % n_features
    if hash_val in unique_hashes:
        collisions += 1
    unique_hashes.add(hash_val)

print(f"\nãƒãƒƒã‚·ãƒ¥è¡çªæ•°: {collisions}")
print(f"è¡çªç‡: {collisions / df['category'].nunique() * 100:.2f}%")

# æ¬¡å…ƒæ•°ã¨è¡çªç‡ã®é–¢ä¿‚
dimensions = [10, 20, 50, 100, 200, 500]
collision_rates = []

for dim in dimensions:
    unique_hashes = set()
    collisions = 0
    for cat in df['category'].unique():
        hash_val = hash(cat) % dim
        if hash_val in unique_hashes:
            collisions += 1
        unique_hashes.add(hash_val)
    collision_rate = collisions / df['category'].nunique() * 100
    collision_rates.append(collision_rate)

print("\n=== æ¬¡å…ƒæ•°ã¨è¡çªç‡ ===")
for dim, rate in zip(dimensions, collision_rates):
    print(f"{dim}æ¬¡å…ƒ: è¡çªç‡ {rate:.2f}%")
</code></pre>

<hr>

<h2>2.7 æ‰‹æ³•ã®æ¯”è¼ƒã¨ä½¿ã„åˆ†ã‘</h2>

<h3>ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ‰‹æ³•ã®ç·åˆæ¯”è¼ƒ</h3>

<table>
<thead>
<tr>
<th>æ‰‹æ³•</th>
<th>æ¬¡å…ƒå¢—åŠ </th>
<th>é«˜ã‚«ãƒ¼ãƒ‡ã‚£ãƒŠãƒªãƒ†ã‚£</th>
<th>è§£é‡ˆæ€§</th>
<th>éå­¦ç¿’ãƒªã‚¹ã‚¯</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>One-Hot</strong></td>
<td>å¤§ï¼ˆnåˆ—ï¼‰</td>
<td>ä¸å‘ã</td>
<td>é«˜</td>
<td>ä½</td>
</tr>
<tr>
<td><strong>Label/Ordinal</strong></td>
<td>ãªã—ï¼ˆ1åˆ—ï¼‰</td>
<td>é©ç”¨å¯</td>
<td>ä¸­</td>
<td>ä½</td>
</tr>
<tr>
<td><strong>Target</strong></td>
<td>ãªã—ï¼ˆ1åˆ—ï¼‰</td>
<td>é©ç”¨å¯</td>
<td>ä¸­</td>
<td>é«˜ï¼ˆCVå¿…é ˆï¼‰</td>
</tr>
<tr>
<td><strong>Frequency</strong></td>
<td>ãªã—ï¼ˆ1åˆ—ï¼‰</td>
<td>é©ç”¨å¯</td>
<td>é«˜</td>
<td>ä½</td>
</tr>
<tr>
<td><strong>Binary</strong></td>
<td>å°ï¼ˆlog nåˆ—ï¼‰</td>
<td>é©ç”¨å¯</td>
<td>ä½</td>
<td>ä½</td>
</tr>
<tr>
<td><strong>Hashing</strong></td>
<td>å›ºå®šï¼ˆmåˆ—ï¼‰</td>
<td>é©ç”¨å¯</td>
<td>ä½</td>
<td>ä½</td>
</tr>
</tbody>
</table>

<h3>ä½¿ã„åˆ†ã‘ã®ãƒ•ãƒ­ãƒ¼ãƒãƒ£ãƒ¼ãƒˆ</h3>

<div class="mermaid">
graph TD
    A[ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°] --> B{ã‚«ãƒ¼ãƒ‡ã‚£ãƒŠãƒªãƒ†ã‚£ã¯?}
    B -->|ä½ 2-10| C{é †åºã‚ã‚Š?}
    B -->|ä¸­ 10-100| D[è¤‡æ•°æ‰‹æ³•ã‚’è©¦ã™]
    B -->|é«˜ 100+| E[Target/Frequency/Hashing]

    C -->|ã‚ã‚Š| F[Ordinal Encoding]
    C -->|ãªã—| G[One-Hot Encoding]

    D --> H[One-Hot/Target/Frequency]

    E --> I{ç›®çš„å¤‰æ•°ã¨ã®ç›¸é–¢?}
    I -->|å¼·ã„| J[Target Encoding + CV]
    I -->|å¼±ã„| K[Frequency/Hashing]

    style A fill:#e3f2fd
    style G fill:#c8e6c9
    style F fill:#fff9c4
    style J fill:#ffccbc
</div>

<h3>å®Ÿè·µçš„ãªä½¿ã„åˆ†ã‘ã‚¬ã‚¤ãƒ‰</h3>

<table>
<thead>
<tr>
<th>çŠ¶æ³</th>
<th>æ¨å¥¨æ‰‹æ³•</th>
<th>ç†ç”±</th>
</tr>
</thead>
<tbody>
<tr>
<td>ç·šå½¢ãƒ¢ãƒ‡ãƒ« + ä½ã‚«ãƒ¼ãƒ‡ã‚£ãƒŠãƒªãƒ†ã‚£</td>
<td>One-Hot</td>
<td>ç·šå½¢ãƒ¢ãƒ‡ãƒ«ã¯é †åºã‚’ä»®å®šã™ã‚‹</td>
</tr>
<tr>
<td>æœ¨ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ« + é †åºã‚ã‚Š</td>
<td>Ordinal</td>
<td>æœ¨ã®åˆ†å²ã«é †åºãŒå½¹ç«‹ã¤</td>
</tr>
<tr>
<td>é«˜ã‚«ãƒ¼ãƒ‡ã‚£ãƒŠãƒªãƒ†ã‚£ + åˆ†é¡å•é¡Œ</td>
<td>Target</td>
<td>ç›®çš„å¤‰æ•°ã¨ã®é–¢ä¿‚ã‚’ç›´æ¥æ‰ãˆã‚‹</td>
</tr>
<tr>
<td>ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿</td>
<td>Hashing</td>
<td>æ–°ã‚«ãƒ†ã‚´ãƒªã«è‡ªå‹•å¯¾å¿œ</td>
</tr>
<tr>
<td>ãƒ¡ãƒ¢ãƒªåˆ¶ç´„</td>
<td>Binary/Hashing</td>
<td>æ¬¡å…ƒå‰Šæ¸›</td>
</tr>
<tr>
<td>è§£é‡ˆæ€§é‡è¦–</td>
<td>One-Hot/Frequency</td>
<td>ç›´æ„Ÿçš„ãªç†è§£ãŒå¯èƒ½</td>
</tr>
</tbody>
</table>

<h3>å®Ÿä¾‹ï¼šå…¨æ‰‹æ³•ã®æ€§èƒ½æ¯”è¼ƒ</h3>

<pre><code class="language-python">import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import LabelEncoder, StandardScaler
import category_encoders as ce

# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
np.random.seed(42)
n_samples = 2000

# ä¸­ã‚«ãƒ¼ãƒ‡ã‚£ãƒŠãƒªãƒ†ã‚£ã®ã‚«ãƒ†ã‚´ãƒªï¼ˆ20å€‹ï¼‰
categories = [f'cat_{i}' for i in range(20)]
X_cat = np.random.choice(categories, size=n_samples)

# ä¸€éƒ¨ã®ã‚«ãƒ†ã‚´ãƒªã§targetãŒ1ã«ãªã‚Šã‚„ã™ã„
high_target_cats = ['cat_0', 'cat_1', 'cat_5', 'cat_10']
y = np.where(np.isin(X_cat, high_target_cats),
             np.random.choice([0, 1], n_samples, p=[0.3, 0.7]),
             np.random.choice([0, 1], n_samples, p=[0.7, 0.3]))

X = pd.DataFrame({'category': X_cat})

# è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«åˆ†å‰²
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

results = []

# 1. One-Hot Encoding
X_train_onehot = pd.get_dummies(X_train, columns=['category'])
X_test_onehot = pd.get_dummies(X_test, columns=['category'])
X_test_onehot = X_test_onehot.reindex(columns=X_train_onehot.columns, fill_value=0)

clf_rf = RandomForestClassifier(n_estimators=100, random_state=42)
score_onehot = cross_val_score(clf_rf, X_train_onehot, y_train, cv=5).mean()
results.append(('One-Hot', score_onehot, X_train_onehot.shape[1]))

# 2. Label Encoding
label_encoder = LabelEncoder()
X_train_label = label_encoder.fit_transform(X_train['category']).reshape(-1, 1)
X_test_label = label_encoder.transform(X_test['category']).reshape(-1, 1)

score_label = cross_val_score(clf_rf, X_train_label, y_train, cv=5).mean()
results.append(('Label', score_label, 1))

# 3. Target Encoding
target_encoder = ce.TargetEncoder(cols=['category'], smoothing=10)
X_train_target = target_encoder.fit_transform(X_train, y_train)
X_test_target = target_encoder.transform(X_test)

score_target = cross_val_score(clf_rf, X_train_target, y_train, cv=5).mean()
results.append(('Target', score_target, 1))

# 4. Frequency Encoding
freq_map = X_train['category'].value_counts(normalize=True)
X_train_freq = X_train['category'].map(freq_map).values.reshape(-1, 1)
X_test_freq = X_test['category'].map(freq_map).fillna(0).values.reshape(-1, 1)

score_freq = cross_val_score(clf_rf, X_train_freq, y_train, cv=5).mean()
results.append(('Frequency', score_freq, 1))

# 5. Binary Encoding
binary_encoder = ce.BinaryEncoder(cols=['category'])
X_train_binary = binary_encoder.fit_transform(X_train)
X_test_binary = binary_encoder.transform(X_test)

score_binary = cross_val_score(clf_rf, X_train_binary, y_train, cv=5).mean()
results.append(('Binary', score_binary, X_train_binary.shape[1]))

# çµæœã®è¡¨ç¤º
print("=== ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ‰‹æ³•ã®æ€§èƒ½æ¯”è¼ƒï¼ˆRandom Forestï¼‰ ===")
print(f"{'æ‰‹æ³•':<15} {'ç²¾åº¦':<10} {'æ¬¡å…ƒæ•°':<10}")
print("-" * 35)
for method, score, dims in sorted(results, key=lambda x: x[1], reverse=True):
    print(f"{method:<15} {score:.4f}    {dims:<10}")
</code></pre>

<p><strong>å‡ºåŠ›ä¾‹</strong>ï¼š</p>
<pre><code>=== ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ‰‹æ³•ã®æ€§èƒ½æ¯”è¼ƒï¼ˆRandom Forestï¼‰ ===
æ‰‹æ³•             ç²¾åº¦        æ¬¡å…ƒæ•°
-----------------------------------
Target          0.7531    1
One-Hot         0.7469    20
Binary          0.7419    5
Frequency       0.6956    1
Label           0.6894    1
</code></pre>

<hr>

<h2>2.8 æœ¬ç« ã®ã¾ã¨ã‚</h2>

<h3>å­¦ã‚“ã ã“ã¨</h3>

<ol>
<li><p><strong>ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°ã®åŸºç¤</strong></p>
<ul>
<li>åç¾©å¤‰æ•°ã¨é †åºå¤‰æ•°ã®é•ã„</li>
<li>ã‚«ãƒ¼ãƒ‡ã‚£ãƒŠãƒªãƒ†ã‚£ã®æ¦‚å¿µã¨é‡è¦æ€§</li>
<li>ãªãœã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãŒå¿…è¦ã‹</li>
</ul></li>
<li><p><strong>One-Hot Encoding</strong></p>
<ul>
<li>ãƒã‚¤ãƒŠãƒªãƒ™ã‚¯ãƒˆãƒ«ã«ã‚ˆã‚‹è¡¨ç¾</li>
<li>pandas get_dummiesã¨OneHotEncoderã®ä½¿ã„åˆ†ã‘</li>
<li>ã‚¹ãƒ‘ãƒ¼ã‚¹è¡Œåˆ—ã«ã‚ˆã‚‹ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–</li>
<li>drop_firstã«ã‚ˆã‚‹å¤šé‡å…±ç·šæ€§ã®å›é¿</li>
</ul></li>
<li><p><strong>Label Encodingã¨Ordinal Encoding</strong></p>
<ul>
<li>æ•´æ•°ã¸ã®å¤‰æ›æ‰‹æ³•</li>
<li>é †åºã®æœ‰ç„¡ã«ã‚ˆã‚‹ä½¿ã„åˆ†ã‘</li>
<li>ç·šå½¢ãƒ¢ãƒ‡ãƒ«ã§ã®æ³¨æ„ç‚¹</li>
</ul></li>
<li><p><strong>Target Encoding</strong></p>
<ul>
<li>ç›®çš„å¤‰æ•°ã®çµ±è¨ˆé‡ã«ã‚ˆã‚‹å¤‰æ›</li>
<li>éå­¦ç¿’å¯¾ç­–ã¨ã—ã¦ã®ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°</li>
<li>Cross-Validationæˆ¦ç•¥ã®é‡è¦æ€§</li>
<li>é«˜ã‚«ãƒ¼ãƒ‡ã‚£ãƒŠãƒªãƒ†ã‚£ã¸ã®å¯¾å¿œ</li>
</ul></li>
<li><p><strong>Frequency Encoding</strong></p>
<ul>
<li>å‡ºç¾é »åº¦ã«ã‚ˆã‚‹å¤‰æ›</li>
<li>ã‚·ãƒ³ãƒ—ãƒ«ã§åŠ¹æœçš„ãªæ‰‹æ³•</li>
<li>æ–°ã—ã„ã‚«ãƒ†ã‚´ãƒªã¸ã®å¯¾å¿œ</li>
</ul></li>
<li><p><strong>Binary Encodingã¨Hashing</strong></p>
<ul>
<li>æ¬¡å…ƒå‰Šæ¸›ã‚’å®Ÿç¾ã™ã‚‹æ‰‹æ³•</li>
<li>é«˜ã‚«ãƒ¼ãƒ‡ã‚£ãƒŠãƒªãƒ†ã‚£ã¸ã®å¯¾å¿œ</li>
<li>ãƒãƒƒã‚·ãƒ¥è¡çªã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•</li>
</ul></li>
<li><p><strong>æ‰‹æ³•ã®ä½¿ã„åˆ†ã‘</strong></p>
<ul>
<li>ã‚«ãƒ¼ãƒ‡ã‚£ãƒŠãƒªãƒ†ã‚£ã«åŸºã¥ãé¸æŠ</li>
<li>ãƒ¢ãƒ‡ãƒ«ã¨ã®ç›¸æ€§</li>
<li>è¨ˆç®—ãƒªã‚½ãƒ¼ã‚¹ã¨ç²¾åº¦ã®ãƒãƒ©ãƒ³ã‚¹</li>
</ul></li>
</ol>

<h3>æ¬¡ã®ç« ã¸</h3>

<p>ç¬¬3ç« ã§ã¯ã€<strong>æ•°å€¤ç‰¹å¾´é‡ã®å¤‰æ›ã¨ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°</strong>ã‚’å­¦ã³ã¾ã™ï¼š</p>
<ul>
<li>æ¨™æº–åŒ–ã¨æ­£è¦åŒ–</li>
<li>å¯¾æ•°å¤‰æ›ã¨Box-Coxå¤‰æ›</li>
<li>ãƒ“ãƒ‹ãƒ³ã‚°ï¼ˆé›¢æ•£åŒ–ï¼‰</li>
<li>ç‰¹å¾´é‡ã®ç›¸äº’ä½œç”¨</li>
</ul>

<hr>

<h2>æ¼”ç¿’å•é¡Œ</h2>

<h3>å•é¡Œ1ï¼ˆé›£æ˜“åº¦ï¼šeasyï¼‰</h3>
<p>One-Hot Encodingã§<code>drop_first=True</code>ã‚’ä½¿ã†ç†ç”±ã‚’ã€å¤šé‡å…±ç·šæ€§ã®è¦³ç‚¹ã‹ã‚‰èª¬æ˜ã—ã¦ãã ã•ã„ã€‚</p>

<details>
<summary>è§£ç­”ä¾‹</summary>

<p><strong>è§£ç­”</strong>ï¼š</p>

<p><strong>å¤šé‡å…±ç·šæ€§ï¼ˆMulticollinearityï¼‰</strong>ã¨ã¯ã€èª¬æ˜å¤‰æ•°é–“ã«å¼·ã„ç›¸é–¢ãŒã‚ã‚‹çŠ¶æ…‹ã‚’æŒ‡ã—ã¾ã™ã€‚</p>

<p>One-Hot Encodingã§ã¯ã€$n$ å€‹ã®ã‚«ãƒ†ã‚´ãƒªã‚’ $n$ å€‹ã®ãƒã‚¤ãƒŠãƒªå¤‰æ•°ã«å¤‰æ›ã—ã¾ã™ã€‚ã“ã®ã¨ãã€ä»¥ä¸‹ã®é–¢ä¿‚ãŒæˆã‚Šç«‹ã¡ã¾ã™ï¼š</p>

<p>$$
\sum_{i=1}^{n} x_i = 1
$$</p>

<p>ã¤ã¾ã‚Šã€1ã¤ã®å¤‰æ•°ã®å€¤ãŒä»–ã® $n-1$ å€‹ã®å¤‰æ•°ã‹ã‚‰å®Œå…¨ã«äºˆæ¸¬ã§ãã¾ã™ã€‚ã“ã‚ŒãŒå¤šé‡å…±ç·šæ€§ã‚’å¼•ãèµ·ã“ã—ã¾ã™ã€‚</p>

<p><strong>å•é¡Œç‚¹</strong>ï¼š</p>
<ul>
<li>ç·šå½¢å›å¸°ã®ä¿‚æ•°ãŒä¸å®‰å®šã«ãªã‚‹</li>
<li>é€†è¡Œåˆ—è¨ˆç®—ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã™ã‚‹å¯èƒ½æ€§</li>
<li>çµ±è¨ˆçš„æ¨è«–ãŒå›°é›£ã«ãªã‚‹</li>
</ul>

<p><strong>è§£æ±ºç­–</strong>ï¼š</p>
<p><code>drop_first=True</code>ã«ã‚ˆã‚Šã€$n$ å€‹ã®ã‚«ãƒ†ã‚´ãƒªã‚’ $n-1$ å€‹ã®å¤‰æ•°ã§è¡¨ç¾ã—ã¾ã™ã€‚çœç•¥ã•ã‚ŒãŸã‚«ãƒ†ã‚´ãƒªã¯ã€Œã™ã¹ã¦ã®å¤‰æ•°ãŒ0ã€ã§è¡¨ç¾ã•ã‚Œã¾ã™ã€‚</p>

<p><strong>ä¾‹</strong>ï¼š</p>
<pre><code>è‰² = {red, blue, green}
drop_first=False: color_red, color_blue, color_green (3åˆ—)
drop_first=True:  color_blue, color_green (2åˆ—)
  - red: [0, 0]
  - blue: [1, 0]
  - green: [0, 1]
</code></pre>

</details>

<h3>å•é¡Œ2ï¼ˆé›£æ˜“åº¦ï¼šmediumï¼‰</h3>
<p>Target Encodingã§éå­¦ç¿’ã‚’é˜²ããŸã‚ã®3ã¤ã®æˆ¦ç•¥ã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚</p>

<details>
<summary>è§£ç­”ä¾‹</summary>

<p><strong>è§£ç­”</strong>ï¼š</p>

<p><strong>1. ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°ï¼ˆSmoothingï¼‰</strong></p>

<p>ã‚µãƒ³ãƒ—ãƒ«æ•°ãŒå°‘ãªã„ã‚«ãƒ†ã‚´ãƒªã®çµ±è¨ˆé‡ã‚’ã€å…¨ä½“å¹³å‡ã§æ­£å‰‡åŒ–ã—ã¾ã™ï¼š</p>

<p>$$
\text{TE}_{\text{smooth}}(c) = \frac{n_c \cdot \text{mean}_c + m \cdot \text{global\_mean}}{n_c + m}
$$</p>

<ul>
<li>$m$ ãŒå¤§ãã„ã»ã©å…¨ä½“å¹³å‡ã«è¿‘ã¥ãï¼ˆä¿å®ˆçš„ï¼‰</li>
<li>$m$ ãŒå°ã•ã„ã»ã©ã‚«ãƒ†ã‚´ãƒªå¹³å‡ã«è¿‘ã¥ãï¼ˆéå­¦ç¿’ãƒªã‚¹ã‚¯ï¼‰</li>
<li>æ¨å¥¨å€¤: $m = 1 \sim 100$</li>
</ul>

<p><strong>2. Cross-Validationæˆ¦ç•¥ï¼ˆOut-of-Fold Encodingï¼‰</strong></p>

<ol>
<li>ãƒ‡ãƒ¼ã‚¿ã‚’Kåˆ†å‰²</li>
<li>Fold $k$ ã®çµ±è¨ˆé‡ã‚’ã€ä»–ã®Foldã§è¨ˆç®—</li>
<li>å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†é›¢</li>
</ol>

<p>ã“ã‚Œã«ã‚ˆã‚Šã€åŒã˜ãƒ‡ãƒ¼ã‚¿ã§çµ±è¨ˆé‡ã‚’è¨ˆç®—ã—ã¦ä½¿ã†ã¨ã„ã†<strong>ãƒªãƒ¼ã‚±ãƒ¼ã‚¸</strong>ã‚’é˜²ãã¾ã™ã€‚</p>

<p><strong>3. ãƒã‚¤ã‚ºä»˜åŠ ï¼ˆNoise Additionï¼‰</strong></p>

<p>ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰å€¤ã«å¾®å°ãªãƒã‚¤ã‚ºã‚’åŠ ãˆã¾ã™ï¼š</p>

<p>$$
\text{TE}_{\text{noise}}(c) = \text{TE}(c) + \epsilon, \quad \epsilon \sim \mathcal{N}(0, \sigma^2)
$$</p>

<ul>
<li>éå­¦ç¿’ã‚’æŠ‘åˆ¶</li>
<li>$\sigma$ ã¯å°ã•ã„å€¤ï¼ˆ0.01ã€œ0.1ç¨‹åº¦ï¼‰</li>
</ul>

<p><strong>å®Ÿè£…ä¾‹</strong>ï¼š</p>
<pre><code class="language-python">import category_encoders as ce

# ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°ä»˜ãTarget Encoding
target_encoder = ce.TargetEncoder(cols=['category'], smoothing=10)
X_encoded = target_encoder.fit_transform(X_train, y_train)
</code></pre>

</details>

<h3>å•é¡Œ3ï¼ˆé›£æ˜“åº¦ï¼šmediumï¼‰</h3>
<p>ä»¥ä¸‹ã®ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°ã«å¯¾ã—ã¦ã€æœ€é©ãªã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ‰‹æ³•ã‚’é¸æŠã—ã€ãã®ç†ç”±ã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚</p>

<ol>
<li>éƒ½é“åºœçœŒåï¼ˆ47ã‚«ãƒ†ã‚´ãƒªï¼‰</li>
<li>Webã‚µã‚¤ãƒˆã®è¨ªå•è€…IDï¼ˆ100ä¸‡ã‚«ãƒ†ã‚´ãƒªï¼‰</li>
<li>é¡§å®¢ã®æº€è¶³åº¦ï¼ˆ1=ä½ã€2=ä¸­ã€3=é«˜ï¼‰</li>
<li>è£½å“ã‚«ãƒ†ã‚´ãƒªï¼ˆ5ã‚«ãƒ†ã‚´ãƒªï¼‰</li>
</ol>

<details>
<summary>è§£ç­”ä¾‹</summary>

<p><strong>è§£ç­”</strong>ï¼š</p>

<p><strong>1. éƒ½é“åºœçœŒåï¼ˆ47ã‚«ãƒ†ã‚´ãƒªï¼‰</strong></p>

<p><strong>æ¨å¥¨</strong>: Target Encoding ã¾ãŸã¯ One-Hot Encoding</p>

<p><strong>ç†ç”±</strong>ï¼š</p>
<ul>
<li>ã‚«ãƒ¼ãƒ‡ã‚£ãƒŠãƒªãƒ†ã‚£: ä¸­ç¨‹åº¦ï¼ˆ47ï¼‰</li>
<li>One-Hot: 47åˆ—ã«å¢—åŠ ã™ã‚‹ãŒè¨±å®¹ç¯„å›²</li>
<li>Target: 1åˆ—ã§é«˜ã„è¡¨ç¾åŠ›ã€‚åœ°åŸŸã¨ç›®çš„å¤‰æ•°ã®é–¢ä¿‚ã‚’æ‰ãˆã‚‰ã‚Œã‚‹</li>
<li>é †åºé–¢ä¿‚ãªã—ï¼ˆåç¾©å¤‰æ•°ï¼‰</li>
</ul>

<p><strong>é¸æŠåŸºæº–</strong>ï¼š</p>
<ul>
<li>ç·šå½¢ãƒ¢ãƒ‡ãƒ« â†’ One-Hot</li>
<li>æœ¨ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ« + åˆ†é¡å•é¡Œ â†’ Target</li>
</ul>

<p><strong>2. Webã‚µã‚¤ãƒˆã®è¨ªå•è€…IDï¼ˆ100ä¸‡ã‚«ãƒ†ã‚´ãƒªï¼‰</strong></p>

<p><strong>æ¨å¥¨</strong>: Frequency Encoding ã¾ãŸã¯ Hashing</p>

<p><strong>ç†ç”±</strong>ï¼š</p>
<ul>
<li>ã‚«ãƒ¼ãƒ‡ã‚£ãƒŠãƒªãƒ†ã‚£: éå¸¸ã«é«˜ã„ï¼ˆ100ä¸‡ï¼‰</li>
<li>One-Hot: ãƒ¡ãƒ¢ãƒªä¸è¶³ã§å®Ÿè³ªä¸å¯èƒ½</li>
<li>Frequency: è¨ªå•é »åº¦ãŒæœ‰ç”¨ãªç‰¹å¾´ã«ãªã‚‹å¯èƒ½æ€§</li>
<li>Hashing: å›ºå®šæ¬¡å…ƒã§æ–°è¦IDã«è‡ªå‹•å¯¾å¿œ</li>
</ul>

<p><strong>3. é¡§å®¢ã®æº€è¶³åº¦ï¼ˆ1=ä½ã€2=ä¸­ã€3=é«˜ï¼‰</strong></p>

<p><strong>æ¨å¥¨</strong>: Ordinal Encoding</p>

<p><strong>ç†ç”±</strong>ï¼š</p>
<ul>
<li>æ˜ç¢ºãªé †åºé–¢ä¿‚ï¼ˆé †åºå¤‰æ•°ï¼‰</li>
<li>ä½(0) < ä¸­(1) < é«˜(2)ã¨ã„ã†é †åºã‚’ä¿æŒã™ã¹ã</li>
<li>One-Hotã¯é †åºæƒ…å ±ã‚’å¤±ã†</li>
<li>ãã®ã¾ã¾æ•´æ•°å€¤ã¨ã—ã¦æ‰±ãˆã‚‹</li>
</ul>

<pre><code class="language-python">from sklearn.preprocessing import OrdinalEncoder

encoder = OrdinalEncoder(categories=[['ä½', 'ä¸­', 'é«˜']])
X_encoded = encoder.fit_transform(X)
</code></pre>

<p><strong>4. è£½å“ã‚«ãƒ†ã‚´ãƒªï¼ˆ5ã‚«ãƒ†ã‚´ãƒªï¼‰</strong></p>

<p><strong>æ¨å¥¨</strong>: One-Hot Encoding</p>

<p><strong>ç†ç”±</strong>ï¼š</p>
<ul>
<li>ã‚«ãƒ¼ãƒ‡ã‚£ãƒŠãƒªãƒ†ã‚£: ä½ã„ï¼ˆ5ï¼‰</li>
<li>é †åºé–¢ä¿‚ãªã—ï¼ˆåç¾©å¤‰æ•°ï¼‰</li>
<li>One-Hotã§5åˆ—ã«å¢—åŠ ã™ã‚‹ãŒå•é¡Œãªã—</li>
<li>è§£é‡ˆæ€§ãŒé«˜ã„</li>
<li>ç·šå½¢ãƒ¢ãƒ‡ãƒ«ã¨ã®ç›¸æ€§ãŒè‰¯ã„</li>
</ul>

</details>

<h3>å•é¡Œ4ï¼ˆé›£æ˜“åº¦ï¼šhardï¼‰</h3>
<p>é«˜ã‚«ãƒ¼ãƒ‡ã‚£ãƒŠãƒªãƒ†ã‚£ã®ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°ï¼ˆ1000ã‚«ãƒ†ã‚´ãƒªï¼‰ã«å¯¾ã—ã¦ã€One-Hot Encodingã€Target Encodingã€Frequency Encodingã€Binary Encodingã‚’é©ç”¨ã—ã€Random Forestã§æ€§èƒ½ã‚’æ¯”è¼ƒã™ã‚‹ã‚³ãƒ¼ãƒ‰ã‚’æ›¸ã„ã¦ãã ã•ã„ã€‚</p>

<details>
<summary>è§£ç­”ä¾‹</summary>

<pre><code class="language-python">import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import LabelEncoder
import category_encoders as ce
import time

# é«˜ã‚«ãƒ¼ãƒ‡ã‚£ãƒŠãƒªãƒ†ã‚£ã®ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
np.random.seed(42)
n_samples = 10000
n_categories = 1000

# ã‚«ãƒ†ã‚´ãƒªã®ç”Ÿæˆï¼ˆã¹ãåˆ†å¸ƒã§ç¾å®Ÿçš„ãªé »åº¦åˆ†å¸ƒï¼‰
categories = [f'cat_{i}' for i in range(n_categories)]
weights = np.array([1/(i+1)**0.8 for i in range(n_categories)])
weights /= weights.sum()

X_cat = np.random.choice(categories, size=n_samples, p=weights)

# ç›®çš„å¤‰æ•°: ä¸Šä½50ã‚«ãƒ†ã‚´ãƒªã§target=1ã«ãªã‚Šã‚„ã™ã„
high_target_cats = [f'cat_{i}' for i in range(50)]
y = np.where(np.isin(X_cat, high_target_cats),
             np.random.choice([0, 1], n_samples, p=[0.3, 0.7]),
             np.random.choice([0, 1], n_samples, p=[0.7, 0.3]))

X = pd.DataFrame({'category': X_cat})

# è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«åˆ†å‰²
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

print(f"=== ãƒ‡ãƒ¼ã‚¿æ¦‚è¦ ===")
print(f"ã‚µãƒ³ãƒ—ãƒ«æ•°: {n_samples}")
print(f"ã‚«ãƒ†ã‚´ãƒªæ•°: {X['category'].nunique()}")
print(f"è¨“ç·´ãƒ‡ãƒ¼ã‚¿: {len(X_train)}, ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {len(X_test)}")

results = []

# Random Forestãƒ¢ãƒ‡ãƒ«
clf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)

# 1. One-Hot Encodingï¼ˆã‚¹ãƒ‘ãƒ¼ã‚¹è¡Œåˆ—ï¼‰
print("\n1. One-Hot Encoding...")
start_time = time.time()
from sklearn.preprocessing import OneHotEncoder
onehot_encoder = OneHotEncoder(sparse_output=True, handle_unknown='ignore')
X_train_onehot = onehot_encoder.fit_transform(X_train[['category']])
X_test_onehot = onehot_encoder.transform(X_test[['category']])

score_onehot = cross_val_score(clf, X_train_onehot, y_train, cv=3, n_jobs=-1).mean()
time_onehot = time.time() - start_time
results.append(('One-Hot', score_onehot, X_train_onehot.shape[1], time_onehot))

# 2. Target Encoding
print("2. Target Encoding...")
start_time = time.time()
target_encoder = ce.TargetEncoder(cols=['category'], smoothing=10)
X_train_target = target_encoder.fit_transform(X_train, y_train)
X_test_target = target_encoder.transform(X_test)

score_target = cross_val_score(clf, X_train_target, y_train, cv=3, n_jobs=-1).mean()
time_target = time.time() - start_time
results.append(('Target', score_target, 1, time_target))

# 3. Frequency Encoding
print("3. Frequency Encoding...")
start_time = time.time()
freq_map = X_train['category'].value_counts(normalize=True)
X_train_freq = X_train['category'].map(freq_map).values.reshape(-1, 1)
X_test_freq = X_test['category'].map(freq_map).fillna(0).values.reshape(-1, 1)

score_freq = cross_val_score(clf, X_train_freq, y_train, cv=3, n_jobs=-1).mean()
time_freq = time.time() - start_time
results.append(('Frequency', score_freq, 1, time_freq))

# 4. Binary Encoding
print("4. Binary Encoding...")
start_time = time.time()
binary_encoder = ce.BinaryEncoder(cols=['category'])
X_train_binary = binary_encoder.fit_transform(X_train)
X_test_binary = binary_encoder.transform(X_test)

score_binary = cross_val_score(clf, X_train_binary, y_train, cv=3, n_jobs=-1).mean()
time_binary = time.time() - start_time
results.append(('Binary', score_binary, X_train_binary.shape[1], time_binary))

# çµæœã®è¡¨ç¤º
print("\n" + "="*70)
print("=== ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ‰‹æ³•ã®æ€§èƒ½æ¯”è¼ƒï¼ˆ1000ã‚«ãƒ†ã‚´ãƒªï¼‰ ===")
print("="*70)
print(f"{'æ‰‹æ³•':<15} {'ç²¾åº¦':<10} {'æ¬¡å…ƒæ•°':<10} {'å®Ÿè¡Œæ™‚é–“(ç§’)':<15}")
print("-"*70)

for method, score, dims, exec_time in sorted(results, key=lambda x: x[1], reverse=True):
    print(f"{method:<15} {score:.4f}    {dims:<10} {exec_time:.2f}")

print("\n" + "="*70)
print("è€ƒå¯Ÿ:")
print("- Target Encoding: é«˜ç²¾åº¦ + 1æ¬¡å…ƒ + é«˜é€Ÿ")
print("- One-Hot: é«˜ç²¾åº¦ã ãŒãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡å¤§")
print("- Binary: æ¬¡å…ƒå‰Šæ¸›ã¨ãƒãƒ©ãƒ³ã‚¹ã®å–ã‚ŒãŸæ€§èƒ½")
print("- Frequency: ã‚·ãƒ³ãƒ—ãƒ«ã ãŒæƒ…å ±é‡ä¸è¶³")
print("="*70)
</code></pre>

<p><strong>å‡ºåŠ›ä¾‹</strong>ï¼š</p>
<pre><code>=== ãƒ‡ãƒ¼ã‚¿æ¦‚è¦ ===
ã‚µãƒ³ãƒ—ãƒ«æ•°: 10000
ã‚«ãƒ†ã‚´ãƒªæ•°: 1000
è¨“ç·´ãƒ‡ãƒ¼ã‚¿: 8000, ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: 2000

1. One-Hot Encoding...
2. Target Encoding...
3. Frequency Encoding...
4. Binary Encoding...

======================================================================
=== ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ‰‹æ³•ã®æ€§èƒ½æ¯”è¼ƒï¼ˆ1000ã‚«ãƒ†ã‚´ãƒªï¼‰ ===
======================================================================
æ‰‹æ³•             ç²¾åº¦        æ¬¡å…ƒæ•°      å®Ÿè¡Œæ™‚é–“(ç§’)
----------------------------------------------------------------------
Target          0.8125    1          2.45
One-Hot         0.8031    1000       5.67
Binary          0.7794    10         3.12
Frequency       0.7031    1          1.89

======================================================================
è€ƒå¯Ÿ:
- Target Encoding: é«˜ç²¾åº¦ + 1æ¬¡å…ƒ + é«˜é€Ÿ
- One-Hot: é«˜ç²¾åº¦ã ãŒãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡å¤§
- Binary: æ¬¡å…ƒå‰Šæ¸›ã¨ãƒãƒ©ãƒ³ã‚¹ã®å–ã‚ŒãŸæ€§èƒ½
- Frequency: ã‚·ãƒ³ãƒ—ãƒ«ã ãŒæƒ…å ±é‡ä¸è¶³
======================================================================
</code></pre>

</details>

<h3>å•é¡Œ5ï¼ˆé›£æ˜“åº¦ï¼šhardï¼‰</h3>
<p>æ–°ã—ã„ã‚«ãƒ†ã‚´ãƒªï¼ˆæœªçŸ¥ã®ã‚«ãƒ†ã‚´ãƒªï¼‰ãŒå‡ºç¾ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹å ´åˆã€å„ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ‰‹æ³•ã‚’ã©ã®ã‚ˆã†ã«å¯¾å¿œã•ã›ã‚‹ã‹èª¬æ˜ã—ã¦ãã ã•ã„ã€‚</p>

<details>
<summary>è§£ç­”ä¾‹</summary>

<p><strong>è§£ç­”</strong>ï¼š</p>

<p>æ–°ã—ã„ã‚«ãƒ†ã‚´ãƒªã¸ã®å¯¾å¿œã¯ã€å®Ÿé‹ç”¨ã§éå¸¸ã«é‡è¦ã§ã™ã€‚å„æ‰‹æ³•ã®å¯¾å¿œæ–¹æ³•ã‚’èª¬æ˜ã—ã¾ã™ã€‚</p>

<p><strong>1. One-Hot Encoding</strong></p>

<p><strong>å¯¾å¿œç­–</strong>ï¼š</p>
<ul>
<li><code>handle_unknown='ignore'</code>: æœªçŸ¥ã‚«ãƒ†ã‚´ãƒªã‚’ã™ã¹ã¦0ã«ã™ã‚‹</li>
<li>ã€Œãã®ä»–ã€ã‚«ãƒ†ã‚´ãƒªã‚’è¿½åŠ ã™ã‚‹</li>
</ul>

<pre><code class="language-python">from sklearn.preprocessing import OneHotEncoder

encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)
encoder.fit(X_train)
X_test_encoded = encoder.transform(X_test)  # æœªçŸ¥ã‚«ãƒ†ã‚´ãƒªã¯[0,0,0,...]
</code></pre>

<p><strong>2. Label Encoding / Ordinal Encoding</strong></p>

<p><strong>å¯¾å¿œç­–</strong>ï¼š</p>
<ul>
<li>æœªçŸ¥ã‚«ãƒ†ã‚´ãƒªã«ç‰¹åˆ¥ãªå€¤ï¼ˆ-1ãªã©ï¼‰ã‚’å‰²ã‚Šå½“ã¦ã‚‹</li>
<li>æœ€ã‚‚é »åº¦ã®é«˜ã„ã‚«ãƒ†ã‚´ãƒªã§ä»£æ›¿ã™ã‚‹</li>
</ul>

<pre><code class="language-python">from sklearn.preprocessing import LabelEncoder

encoder = LabelEncoder()
encoder.fit(X_train)

# æœªçŸ¥ã‚«ãƒ†ã‚´ãƒªã‚’-1ã§å‡¦ç†
X_test_encoded = []
for x in X_test:
    if x in encoder.classes_:
        X_test_encoded.append(encoder.transform([x])[0])
    else:
        X_test_encoded.append(-1)  # æœªçŸ¥ã‚«ãƒ†ã‚´ãƒª
</code></pre>

<p><strong>3. Target Encoding</strong></p>

<p><strong>å¯¾å¿œç­–</strong>ï¼š</p>
<ul>
<li>å…¨ä½“å¹³å‡ï¼ˆglobal meanï¼‰ã§ç½®ãæ›ãˆã‚‹</li>
<li>ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°ã®å…¨ä½“å¹³å‡ã¨åŒã˜å€¤ã‚’ä½¿ç”¨</li>
</ul>

<pre><code class="language-python">import category_encoders as ce

target_encoder = ce.TargetEncoder(cols=['category'],
                                  smoothing=10,
                                  handle_unknown='value',
                                  handle_missing='value')

X_train_encoded = target_encoder.fit_transform(X_train, y_train)
X_test_encoded = target_encoder.transform(X_test)  # æœªçŸ¥ â†’ global mean
</code></pre>

<p><strong>4. Frequency Encoding</strong></p>

<p><strong>å¯¾å¿œç­–</strong>ï¼š</p>
<ul>
<li>é »åº¦0ï¼ˆã¾ãŸã¯æœ€å°é »åº¦ï¼‰ã‚’å‰²ã‚Šå½“ã¦ã‚‹</li>
<li>å¸Œå°‘ã‚«ãƒ†ã‚´ãƒªã¨ã—ã¦æ‰±ã†</li>
</ul>

<pre><code class="language-python">freq_map = X_train['category'].value_counts(normalize=True)
min_freq = freq_map.min()

# æœªçŸ¥ã‚«ãƒ†ã‚´ãƒªã¯æœ€å°é »åº¦
X_test_encoded = X_test['category'].map(freq_map).fillna(min_freq)
</code></pre>

<p><strong>5. Binary Encoding</strong></p>

<p><strong>å¯¾å¿œç­–</strong>ï¼š</p>
<ul>
<li>æœªçŸ¥ã‚«ãƒ†ã‚´ãƒªã«ç‰¹åˆ¥ãªã‚³ãƒ¼ãƒ‰ï¼ˆã™ã¹ã¦0ãªã©ï¼‰ã‚’å‰²ã‚Šå½“ã¦ã‚‹</li>
</ul>

<pre><code class="language-python">import category_encoders as ce

binary_encoder = ce.BinaryEncoder(cols=['category'], handle_unknown='value')
X_train_encoded = binary_encoder.fit_transform(X_train)
X_test_encoded = binary_encoder.transform(X_test)
</code></pre>

<p><strong>6. Hashing</strong></p>

<p><strong>å¯¾å¿œç­–</strong>ï¼š</p>
<ul>
<li>è‡ªå‹•çš„ã«å¯¾å¿œï¼ˆãƒãƒƒã‚·ãƒ¥é–¢æ•°ã§å›ºå®šæ¬¡å…ƒã«å¤‰æ›ï¼‰</li>
<li>æ–°ã‚«ãƒ†ã‚´ãƒªã‚‚æ—¢å­˜ã®ãƒãƒƒã‚·ãƒ¥å€¤ã«ãƒãƒƒãƒ”ãƒ³ã‚°ã•ã‚Œã‚‹</li>
</ul>

<pre><code class="language-python">from sklearn.feature_extraction import FeatureHasher

hasher = FeatureHasher(n_features=50, input_type='string')
X_train_hashed = hasher.transform([[cat] for cat in X_train['category']])
X_test_hashed = hasher.transform([[cat] for cat in X_test['category']])
# æœªçŸ¥ã‚«ãƒ†ã‚´ãƒªã‚‚è‡ªå‹•çš„ã«ãƒãƒƒã‚·ãƒ¥ã•ã‚Œã‚‹
</code></pre>

<p><strong>æ¨å¥¨æˆ¦ç•¥</strong>ï¼š</p>

<table>
<thead>
<tr>
<th>çŠ¶æ³</th>
<th>æ¨å¥¨æ‰‹æ³•</th>
</tr>
</thead>
<tbody>
<tr>
<td>æœªçŸ¥ã‚«ãƒ†ã‚´ãƒªãŒé »ç¹</td>
<td>Hashing</td>
</tr>
<tr>
<td>æœªçŸ¥ã‚«ãƒ†ã‚´ãƒªãŒç¨€</td>
<td>One-Hotï¼ˆignoreï¼‰ or Targetï¼ˆglobal meanï¼‰</td>
</tr>
<tr>
<td>è§£é‡ˆæ€§é‡è¦–</td>
<td>Frequencyï¼ˆæœ€å°é »åº¦ï¼‰</td>
</tr>
<tr>
<td>é«˜ç²¾åº¦å„ªå…ˆ</td>
<td>Targetï¼ˆglobal meanï¼‰</td>
</tr>
</tbody>
</table>

</details>

<hr>

<h2>å‚è€ƒæ–‡çŒ®</h2>

<ol>
<li>Micci-Barreca, D. (2001). A preprocessing scheme for high-cardinality categorical attributes in classification and prediction problems. <em>ACM SIGKDD Explorations Newsletter</em>, 3(1), 27-32.</li>
<li>Weinberger, K., et al. (2009). Feature hashing for large scale multitask learning. <em>Proceedings of the 26th Annual International Conference on Machine Learning</em>.</li>
<li>Pargent, F., et al. (2022). Regularized target encoding outperforms traditional methods in supervised machine learning with high cardinality features. <em>Computational Statistics</em>, 37(5), 2671-2692.</li>
<li>GÃ©ron, A. (2019). <em>Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow</em> (2nd ed.). O'Reilly Media.</li>
<li>Kuhn, M., & Johnson, K. (2019). <em>Feature Engineering and Selection: A Practical Approach for Predictive Models</em>. CRC Press.</li>
</ol>

<div class="navigation">
    <a href="chapter1-feature-engineering-basics.html" class="nav-button">â† å‰ã®ç« : ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã®åŸºç¤</a>
    <a href="chapter3-numeric-feature-transformation.html" class="nav-button">æ¬¡ã®ç« : æ•°å€¤ç‰¹å¾´é‡ã®å¤‰æ› â†’</a>
</div>

    </main>

    
    <section class="disclaimer">
        <h3>å…è²¬äº‹é …</h3>
        <ul>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯æ•™è‚²ãƒ»ç ”ç©¶ãƒ»æƒ…å ±æä¾›ã®ã¿ã‚’ç›®çš„ã¨ã—ã¦ãŠã‚Šã€å°‚é–€çš„ãªåŠ©è¨€(æ³•å¾‹ãƒ»ä¼šè¨ˆãƒ»æŠ€è¡“çš„ä¿è¨¼ãªã©)ã‚’æä¾›ã™ã‚‹ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŠã‚ˆã³ä»˜éšã™ã‚‹ã‚³ãƒ¼ãƒ‰ä¾‹ã¯ã€Œç¾çŠ¶æœ‰å§¿(AS IS)ã€ã§æä¾›ã•ã‚Œã€æ˜ç¤ºã¾ãŸã¯é»™ç¤ºã‚’å•ã‚ãšã€å•†å“æ€§ã€ç‰¹å®šç›®çš„é©åˆæ€§ã€æ¨©åˆ©éä¾µå®³ã€æ­£ç¢ºæ€§ãƒ»å®Œå…¨æ€§ã€å‹•ä½œãƒ»å®‰å…¨æ€§ç­‰ã„ã‹ãªã‚‹ä¿è¨¼ã‚‚ã—ã¾ã›ã‚“ã€‚</li>
            <li>å¤–éƒ¨ãƒªãƒ³ã‚¯ã€ç¬¬ä¸‰è€…ãŒæä¾›ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ»ãƒ„ãƒ¼ãƒ«ãƒ»ãƒ©ã‚¤ãƒ–ãƒ©ãƒªç­‰ã®å†…å®¹ãƒ»å¯ç”¨æ€§ãƒ»å®‰å…¨æ€§ã«ã¤ã„ã¦ã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯ä¸€åˆ‡ã®è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®åˆ©ç”¨ãƒ»å®Ÿè¡Œãƒ»è§£é‡ˆã«ã‚ˆã‚Šç›´æ¥çš„ãƒ»é–“æ¥çš„ãƒ»ä»˜éšçš„ãƒ»ç‰¹åˆ¥ãƒ»çµæœçš„ãƒ»æ‡²ç½°çš„æå®³ãŒç”Ÿã˜ãŸå ´åˆã§ã‚‚ã€é©ç”¨æ³•ã§è¨±å®¹ã•ã‚Œã‚‹æœ€å¤§é™ã®ç¯„å›²ã§ã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å†…å®¹ã¯ã€äºˆå‘Šãªãå¤‰æ›´ãƒ»æ›´æ–°ãƒ»æä¾›åœæ­¢ã•ã‚Œã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®è‘—ä½œæ¨©ãƒ»ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯æ˜è¨˜ã•ã‚ŒãŸæ¡ä»¶(ä¾‹: CC BY 4.0)ã«å¾“ã„ã¾ã™ã€‚å½“è©²ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯é€šå¸¸ã€ç„¡ä¿è¨¼æ¡é …ã‚’å«ã¿ã¾ã™ã€‚</li>
        </ul>
    </section>

<footer>
        <p><strong>ä½œæˆè€…</strong>: AI Terakoya Content Team</p>
        <p><strong>ãƒãƒ¼ã‚¸ãƒ§ãƒ³</strong>: 1.0 | <strong>ä½œæˆæ—¥</strong>: 2025-10-21</p>
        <p><strong>ãƒ©ã‚¤ã‚»ãƒ³ã‚¹</strong>: Creative Commons BY 4.0</p>
        <p>Â© 2025 AI Terakoya. All rights reserved.</p>
    </footer>
</body>
</html>
