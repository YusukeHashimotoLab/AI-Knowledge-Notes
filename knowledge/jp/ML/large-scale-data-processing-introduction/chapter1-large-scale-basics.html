<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ç¬¬1ç« ï¼šå¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã®åŸºç¤ - AI Terakoya</title>

    <style>
        :root {
            --color-primary: #2c3e50;
            --color-primary-dark: #1a252f;
            --color-accent: #7b2cbf;
            --color-accent-light: #9d4edd;
            --color-text: #2d3748;
            --color-text-light: #4a5568;
            --color-bg: #ffffff;
            --color-bg-alt: #f7fafc;
            --color-border: #e2e8f0;
            --color-code-bg: #f8f9fa;
            --color-link: #3182ce;
            --color-link-hover: #2c5aa0;

            --spacing-xs: 0.5rem;
            --spacing-sm: 1rem;
            --spacing-md: 1.5rem;
            --spacing-lg: 2rem;
            --spacing-xl: 3rem;

            --font-body: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            --font-mono: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;

            --border-radius: 8px;
            --box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: var(--font-body);
            line-height: 1.7;
            color: var(--color-text);
            background-color: var(--color-bg);
            font-size: 16px;
        }

        header {
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            padding: var(--spacing-xl) var(--spacing-md);
            margin-bottom: var(--spacing-xl);
            box-shadow: var(--box-shadow);
        }

        .header-content {
            max-width: 900px;
            margin: 0 auto;
        }

        h1 {
            font-size: 2rem;
            font-weight: 700;
            margin-bottom: var(--spacing-sm);
            line-height: 1.2;
        }

        .subtitle {
            font-size: 1.1rem;
            opacity: 0.95;
            font-weight: 400;
            margin-bottom: var(--spacing-md);
        }

        .meta {
            display: flex;
            flex-wrap: wrap;
            gap: var(--spacing-md);
            font-size: 0.9rem;
            opacity: 0.9;
        }

        .meta-item {
            display: flex;
            align-items: center;
            gap: 0.3rem;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 0 var(--spacing-md) var(--spacing-xl);
        }

        h2 {
            font-size: 1.75rem;
            color: var(--color-primary);
            margin-top: var(--spacing-xl);
            margin-bottom: var(--spacing-md);
            padding-bottom: var(--spacing-xs);
            border-bottom: 3px solid var(--color-accent);
        }

        h3 {
            font-size: 1.4rem;
            color: var(--color-primary);
            margin-top: var(--spacing-lg);
            margin-bottom: var(--spacing-sm);
        }

        h4 {
            font-size: 1.1rem;
            color: var(--color-primary-dark);
            margin-top: var(--spacing-md);
            margin-bottom: var(--spacing-sm);
        }

        p {
            margin-bottom: var(--spacing-md);
            color: var(--color-text);
        }

        a {
            color: var(--color-link);
            text-decoration: none;
            transition: color 0.2s;
        }

        a:hover {
            color: var(--color-link-hover);
            text-decoration: underline;
        }

        ul, ol {
            margin-left: var(--spacing-lg);
            margin-bottom: var(--spacing-md);
        }

        li {
            margin-bottom: var(--spacing-xs);
            color: var(--color-text);
        }

        pre {
            background-color: var(--color-code-bg);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            overflow-x: auto;
            margin-bottom: var(--spacing-md);
            font-family: var(--font-mono);
            font-size: 0.9rem;
            line-height: 1.5;
        }

        code {
            font-family: var(--font-mono);
            font-size: 0.9em;
            background-color: var(--color-code-bg);
            padding: 0.2em 0.4em;
            border-radius: 3px;
        }

        pre code {
            background-color: transparent;
            padding: 0;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: var(--spacing-md);
            font-size: 0.95rem;
        }

        th, td {
            border: 1px solid var(--color-border);
            padding: var(--spacing-sm);
            text-align: left;
        }

        th {
            background-color: var(--color-bg-alt);
            font-weight: 600;
            color: var(--color-primary);
        }

        blockquote {
            border-left: 4px solid var(--color-accent);
            padding-left: var(--spacing-md);
            margin: var(--spacing-md) 0;
            color: var(--color-text-light);
            font-style: italic;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        .mermaid {
            text-align: center;
            margin: var(--spacing-lg) 0;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        details {
            background-color: var(--color-bg-alt);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            margin-bottom: var(--spacing-md);
        }

        summary {
            cursor: pointer;
            font-weight: 600;
            color: var(--color-primary);
            user-select: none;
            padding: var(--spacing-xs);
            margin: calc(-1 * var(--spacing-md));
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        summary:hover {
            background-color: rgba(123, 44, 191, 0.1);
        }

        details[open] summary {
            margin-bottom: var(--spacing-md);
            border-bottom: 1px solid var(--color-border);
        }

        .navigation {
            display: flex;
            justify-content: space-between;
            gap: var(--spacing-md);
            margin: var(--spacing-xl) 0;
            padding-top: var(--spacing-lg);
            border-top: 2px solid var(--color-border);
        }

        .nav-button {
            flex: 1;
            padding: var(--spacing-md);
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            border-radius: var(--border-radius);
            text-align: center;
            font-weight: 600;
            transition: transform 0.2s, box-shadow 0.2s;
            box-shadow: var(--box-shadow);
        }

        .nav-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
            text-decoration: none;
        }

        footer {
            margin-top: var(--spacing-xl);
            padding: var(--spacing-lg) var(--spacing-md);
            background-color: var(--color-bg-alt);
            border-top: 1px solid var(--color-border);
            text-align: center;
            font-size: 0.9rem;
            color: var(--color-text-light);
        }
        .disclaimer {
            max-width: 900px;
            margin: 2rem auto;
            padding: 1.5rem;
            background: #f8f9fa;
            border-left: 4px solid #6c757d;
            border-radius: 4px;
        }

        .disclaimer h3 {
            color: #495057;
            margin-bottom: 1rem;
            font-size: 1.1rem;
        }

        .disclaimer ul {
            list-style: none;
            padding-left: 0;
        }

        .disclaimer li {
            padding: 0.5rem 0;
            padding-left: 1.5rem;
            position: relative;
            font-size: 0.9rem;
            color: #6c757d;
            line-height: 1.6;
        }

        .disclaimer li::before {
            content: "âš ï¸";
            position: absolute;
            left: 0;
        }


        @media (max-width: 768px) {
            h1 {
                font-size: 1.5rem;
            }

            h2 {
                font-size: 1.4rem;
            }

            h3 {
                font-size: 1.2rem;
            }

            .meta {
                font-size: 0.85rem;
            }

            .navigation {
                flex-direction: column;
            }

            table {
                font-size: 0.85rem;
            }

            th, td {
                padding: var(--spacing-xs);
            }
        }
    
        
    
        /* Breadcrumb styles */
        .breadcrumb {
            background: #f7fafc;
            padding: 0.75rem 1rem;
            border-bottom: 1px solid #e2e8f0;
            font-size: 0.9rem;
        }

        .breadcrumb-content {
            max-width: 900px;
            margin: 0 auto;
            display: flex;
            align-items: center;
            flex-wrap: wrap;
            gap: 0.5rem;
        }

        .breadcrumb a {
            color: #667eea;
            text-decoration: none;
            transition: color 0.2s;
        }

        .breadcrumb a:hover {
            color: #764ba2;
            text-decoration: underline;
        }

        .breadcrumb-separator {
            color: #a0aec0;
            margin: 0 0.25rem;
        }

        .breadcrumb-current {
            color: #4a5568;
            font-weight: 500;
        }
    </style>

    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
        mermaid.initialize({ startOnLoad: true, theme: 'default' });
    </script>

    <!-- MathJax for LaTeX equation rendering -->
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                displayMath: [['$$', '$$'], ['\\[', '\\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
                ignoreHtmlClass: 'mermaid'
            }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" async></script>

    <style>
        /* Locale Switcher Styles */
        .locale-switcher {
            display: flex;
            align-items: center;
            gap: 0.5rem;
            padding: 0.5rem 1rem;
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
            border-radius: 6px;
            font-size: 0.9rem;
            margin-bottom: 1rem;
            box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);
        }

        .current-locale {
            font-weight: 600;
            color: #7b2cbf;
            display: flex;
            align-items: center;
            gap: 0.25rem;
        }

        .locale-separator {
            color: #adb5bd;
            font-weight: 300;
        }

        .locale-link {
            color: #f093fb;
            text-decoration: none;
            font-weight: 500;
            transition: all 0.2s ease;
            display: flex;
            align-items: center;
            gap: 0.25rem;
            padding: 0.2rem 0.5rem;
            border-radius: 4px;
        }

        .locale-link:hover {
            background: rgba(240, 147, 251, 0.1);
            color: #d07be8;
            transform: translateY(-1px);
        }

        .locale-meta {
            color: #868e96;
            font-size: 0.85rem;
            font-style: italic;
            margin-left: auto;
        }

        @media (max-width: 768px) {
            .locale-switcher {
                font-size: 0.85rem;
                padding: 0.4rem 0.8rem;
            }
            .locale-meta {
                display: none;
            }
        }
    </style>
</head>
<body>
            <div class="locale-switcher">
<span class="current-locale">ğŸŒ JP</span>
<span class="locale-separator">|</span>
<a href="../../../en/ML/large-scale-data-processing-introduction/chapter1-large-scale-basics.html" class="locale-link">ğŸ‡¬ğŸ‡§ EN</a>
<span class="locale-separator">|</span>
<span class="locale-meta">Last sync: 2025-11-16</span>
</div>
<nav class="breadcrumb">
        <div class="breadcrumb-content">
            <a href="../../index.html">AIå¯ºå­å±‹ãƒˆãƒƒãƒ—</a><span class="breadcrumb-separator">â€º</span><a href="../../ML/index.html">æ©Ÿæ¢°å­¦ç¿’</a><span class="breadcrumb-separator">â€º</span><a href="../../ML/large-scale-data-processing-introduction/index.html">Large Scale Data Processing</a><span class="breadcrumb-separator">â€º</span><span class="breadcrumb-current">Chapter 1</span>
        </div>
    </nav>

        <header>
        <div class="header-content">
            <h1>ç¬¬1ç« ï¼šå¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã®åŸºç¤</h1>
            <p class="subtitle">ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã¨åˆ†æ•£å‡¦ç†ã®åŸç†ã‚’ç†è§£ã™ã‚‹</p>
            <div class="meta">
                <span class="meta-item">ğŸ“– èª­äº†æ™‚é–“: 25-30åˆ†</span>
                <span class="meta-item">ğŸ“Š é›£æ˜“åº¦: åˆç´šã€œä¸­ç´š</span>
                <span class="meta-item">ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹: 7å€‹</span>
                <span class="meta-item">ğŸ“ æ¼”ç¿’å•é¡Œ: 5å•</span>
            </div>
        </div>
    </header>

    <main class="container">

<h2>å­¦ç¿’ç›®æ¨™</h2>
<p>ã“ã®ç« ã‚’èª­ã‚€ã“ã¨ã§ã€ä»¥ä¸‹ã‚’ç¿’å¾—ã§ãã¾ã™ï¼š</p>
<ul>
<li>âœ… å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã«ãŠã‘ã‚‹ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã®èª²é¡Œã‚’ç†è§£ã™ã‚‹</li>
<li>âœ… åˆ†æ•£å‡¦ç†ã®åŸºæœ¬æ¦‚å¿µã¨ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’æŠŠæ¡ã™ã‚‹</li>
<li>âœ… ä¸¦åˆ—åŒ–æˆ¦ç•¥ã®ç¨®é¡ã¨ä½¿ã„åˆ†ã‘ã‚’å­¦ã¶</li>
<li>âœ… åˆ†æ•£ã‚·ã‚¹ãƒ†ãƒ ã®èª²é¡Œã¨è§£æ±ºç­–ã‚’çŸ¥ã‚‹</li>
<li>âœ… ä¸»è¦ãªåˆ†æ•£å‡¦ç†ãƒ„ãƒ¼ãƒ«ã¨ã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ ã‚’ç†è§£ã™ã‚‹</li>
<li>âœ… å®Ÿéš›ã®ã‚³ãƒ¼ãƒ‰ã§ä¸¦åˆ—åŒ–ã‚’å®Ÿè£…ã§ãã‚‹</li>
</ul>

<hr>

<h2>1.1 ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã®èª²é¡Œ</h2>

<h3>ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã®å¢—å¤§</h3>

<p>ç¾ä»£ã®æ©Ÿæ¢°å­¦ç¿’ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã¯ã€ãƒ‡ãƒ¼ã‚¿é‡ãŒçˆ†ç™ºçš„ã«å¢—åŠ ã—ã¦ã„ã¾ã™ã€‚</p>

<blockquote>
<p>ã€Œå˜ä¸€ãƒã‚·ãƒ³ã§ã¯å‡¦ç†ã—ãã‚Œãªã„ãƒ‡ãƒ¼ã‚¿é‡ã«ç›´é¢ã™ã‚‹ã“ã¨ã¯ã€ã‚‚ã¯ã‚„ä¾‹å¤–ã§ã¯ãªãæ¨™æº–ã¨ãªã£ã¦ã„ã¾ã™ã€‚ã€</p>
</blockquote>

<table>
<thead>
<tr>
<th>ãƒ‡ãƒ¼ã‚¿è¦æ¨¡</th>
<th>ã‚µã‚¤ã‚ºã®ç›®å®‰</th>
<th>å‡¦ç†æ–¹æ³•</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>å°è¦æ¨¡</strong></td>
<td>ã€œ1GB</td>
<td>å˜ä¸€ãƒã‚·ãƒ³ã®ãƒ¡ãƒ¢ãƒªå†…å‡¦ç†</td>
</tr>
<tr>
<td><strong>ä¸­è¦æ¨¡</strong></td>
<td>1GBã€œ100GB</td>
<td>ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ã€ãƒãƒ£ãƒ³ã‚¯å‡¦ç†</td>
</tr>
<tr>
<td><strong>å¤§è¦æ¨¡</strong></td>
<td>100GBã€œ1TB</td>
<td>åˆ†æ•£å‡¦ç†ã€ä¸¦åˆ—åŒ–</td>
</tr>
<tr>
<td><strong>è¶…å¤§è¦æ¨¡</strong></td>
<td>1TBä»¥ä¸Š</td>
<td>ã‚¯ãƒ©ã‚¹ã‚¿ã€åˆ†æ•£ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ </td>
</tr>
</tbody>
</table>

<h3>ãƒ¡ãƒ¢ãƒªåˆ¶ç´„</h3>

<p>æœ€ã‚‚ä¸€èˆ¬çš„ãªå•é¡Œã¯ã€ãƒ‡ãƒ¼ã‚¿ãŒãƒ¡ãƒ¢ãƒªã«åã¾ã‚‰ãªã„ã“ã¨ã§ã™ã€‚</p>

<pre><code class="language-python">import numpy as np
import sys

# ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®ç¢ºèª
def memory_usage_mb(data):
    """ãƒ‡ãƒ¼ã‚¿ã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’MBã§è¿”ã™"""
    return sys.getsizeof(data) / (1024 ** 2)

# å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã®ä¾‹
n_samples = 10_000_000  # 1000ä¸‡ã‚µãƒ³ãƒ—ãƒ«
n_features = 100

# é€šå¸¸ã®é…åˆ—ï¼ˆå…¨ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ¡ãƒ¢ãƒªã«èª­ã¿è¾¼ã¿ï¼‰
# ã“ã‚Œã¯ç´„7.5GBã®ãƒ¡ãƒ¢ãƒªã‚’æ¶ˆè²»
# data = np.random.random((n_samples, n_features))  # ãƒ¡ãƒ¢ãƒªä¸è¶³ã®å¯èƒ½æ€§

# ã‚ˆã‚Šå°ã•ã„ãƒ‡ãƒ¼ã‚¿ã§ç¢ºèª
n_samples_small = 1_000_000  # 100ä¸‡ã‚µãƒ³ãƒ—ãƒ«
data_small = np.random.random((n_samples_small, n_features))

print("=== ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®ç¢ºèª ===")
print(f"ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: {data_small.shape}")
print(f"ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {memory_usage_mb(data_small):.2f} MB")
print(f"\næ¨å®š: {n_samples:,}ã‚µãƒ³ãƒ—ãƒ«ã®å ´åˆ")
print(f"ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {memory_usage_mb(data_small) * 10:.2f} MB ({memory_usage_mb(data_small) * 10 / 1024:.2f} GB)")
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>=== ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®ç¢ºèª ===
ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (1000000, 100)
ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: 762.94 MB

æ¨å®š: 10,000,000ã‚µãƒ³ãƒ—ãƒ«ã®å ´åˆ
ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: 7629.40 MB (7.45 GB)
</code></pre>

<h3>è¨ˆç®—æ™‚é–“ã®å•é¡Œ</h3>

<p>ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºãŒå¢—åŠ ã™ã‚‹ã¨ã€è¨ˆç®—æ™‚é–“ãŒéç·šå½¢ã«å¢—åŠ ã—ã¾ã™ã€‚</p>

<pre><code class="language-python">import time
import numpy as np
import matplotlib.pyplot as plt

# ç•°ãªã‚‹ã‚µã‚¤ã‚ºã§ã®è¨ˆç®—æ™‚é–“ã‚’æ¸¬å®š
sizes = [1000, 5000, 10000, 50000, 100000]
times = []

print("=== è¨ˆç®—æ™‚é–“ã®æ¸¬å®š ===")
for size in sizes:
    X = np.random.random((size, 100))

    start = time.time()
    # ç°¡å˜ãªè¡Œåˆ—æ¼”ç®—
    result = X @ X.T
    elapsed = time.time() - start

    times.append(elapsed)
    print(f"ã‚µã‚¤ã‚º {size:6d}: {elapsed:.4f}ç§’")

# å¯è¦–åŒ–
plt.figure(figsize=(10, 6))
plt.plot(sizes, times, marker='o', linewidth=2, markersize=8)
plt.xlabel('ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºï¼ˆã‚µãƒ³ãƒ—ãƒ«æ•°ï¼‰', fontsize=12)
plt.ylabel('è¨ˆç®—æ™‚é–“ï¼ˆç§’ï¼‰', fontsize=12)
plt.title('ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã¨è¨ˆç®—æ™‚é–“ã®é–¢ä¿‚', fontsize=14)
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()

# æ™‚é–“è¤‡é›‘åº¦ã®æ¨å®š
print(f"\n10å€ã®ã‚µã‚¤ã‚ºå¢—åŠ ã«ã‚ˆã‚‹æ™‚é–“å¢—åŠ ç‡: {times[-1] / times[0]:.1f}x")
</code></pre>

<h3>I/Oãƒœãƒˆãƒ«ãƒãƒƒã‚¯</h3>

<p>ãƒ‡ã‚£ã‚¹ã‚¯I/Oã¯ã€å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã«ãŠã‘ã‚‹ä¸»è¦ãªãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã§ã™ã€‚</p>

<table>
<thead>
<tr>
<th>ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ç¨®é¡</th>
<th>èª­ã¿å–ã‚Šé€Ÿåº¦</th>
<th>ç›¸å¯¾æ€§èƒ½</th>
</tr>
</thead>
<tbody>
<tr>
<td>ãƒ¡ãƒ¢ãƒªï¼ˆRAMï¼‰</td>
<td>ã€œ50 GB/s</td>
<td>1,000å€</td>
</tr>
<tr>
<td>SSD</td>
<td>ã€œ500 MB/s</td>
<td>10å€</td>
</tr>
<tr>
<td>HDD</td>
<td>ã€œ100 MB/s</td>
<td>1å€ï¼ˆåŸºæº–ï¼‰</td>
</tr>
<tr>
<td>ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼ˆ1Gbpsï¼‰</td>
<td>ã€œ125 MB/s</td>
<td>1.25å€</td>
</tr>
</tbody>
</table>

<hr>

<h2>1.2 åˆ†æ•£å‡¦ç†ã®æ¦‚å¿µ</h2>

<h3>æ°´å¹³ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚° vs å‚ç›´ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°</h3>

<p>ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã‚’å®Ÿç¾ã™ã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã«ã¯2ç¨®é¡ã‚ã‚Šã¾ã™ã€‚</p>

<table>
<thead>
<tr>
<th>ç¨®é¡</th>
<th>èª¬æ˜</th>
<th>é•·æ‰€</th>
<th>çŸ­æ‰€</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>å‚ç›´ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°</strong><br>(Scale Up)</td>
<td>å˜ä¸€ãƒã‚·ãƒ³ã®æ€§èƒ½å‘ä¸Š<br>ï¼ˆCPUã€ãƒ¡ãƒ¢ãƒªã€ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸å¢—å¼·ï¼‰</td>
<td>ãƒ»ã‚·ãƒ³ãƒ—ãƒ«ãªå®Ÿè£…<br>ãƒ»é€šä¿¡ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ãªã—</td>
<td>ãƒ»ç‰©ç†çš„é™ç•Œã‚ã‚Š<br>ãƒ»ã‚³ã‚¹ãƒˆãŒéç·šå½¢ã«å¢—åŠ </td>
</tr>
<tr>
<td><strong>æ°´å¹³ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°</strong><br>(Scale Out)</td>
<td>è¤‡æ•°ãƒã‚·ãƒ³ã§åˆ†æ•£å‡¦ç†<br>ï¼ˆãƒãƒ¼ãƒ‰æ•°ã‚’å¢—ã‚„ã™ï¼‰</td>
<td>ãƒ»ç†è«–ä¸Šç„¡é™ã«æ‹¡å¼µå¯èƒ½<br>ãƒ»è€éšœå®³æ€§å‘ä¸Š</td>
<td>ãƒ»å®Ÿè£…ãŒè¤‡é›‘<br>ãƒ»é€šä¿¡ã‚³ã‚¹ãƒˆç™ºç”Ÿ</td>
</tr>
</tbody>
</table>

<blockquote>
<p><strong>å®Ÿå‹™ã§ã®é¸æŠ</strong>: é€šå¸¸ã€å‚ç›´ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã‚’é™ç•Œã¾ã§è¡Œã„ã€ãã®å¾Œã«æ°´å¹³ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã«ç§»è¡Œã—ã¾ã™ã€‚</p>
</blockquote>

<h3>ãƒã‚¹ã‚¿ãƒ¼ãƒ»ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£</h3>

<p>åˆ†æ•£å‡¦ç†ã®æœ€ã‚‚ä¸€èˆ¬çš„ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã¯ã€<strong>ãƒã‚¹ã‚¿ãƒ¼ãƒ»ãƒ¯ãƒ¼ã‚«ãƒ¼ï¼ˆMaster-Workerï¼‰</strong>ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§ã™ã€‚</p>

<div class="mermaid">
graph TD
    M[ãƒã‚¹ã‚¿ãƒ¼ãƒãƒ¼ãƒ‰<br/>ã‚¿ã‚¹ã‚¯åˆ†é…ãƒ»çµæœé›†ç´„] --> W1[ãƒ¯ãƒ¼ã‚«ãƒ¼ 1<br/>éƒ¨åˆ†è¨ˆç®—]
    M --> W2[ãƒ¯ãƒ¼ã‚«ãƒ¼ 2<br/>éƒ¨åˆ†è¨ˆç®—]
    M --> W3[ãƒ¯ãƒ¼ã‚«ãƒ¼ 3<br/>éƒ¨åˆ†è¨ˆç®—]
    M --> W4[ãƒ¯ãƒ¼ã‚«ãƒ¼ 4<br/>éƒ¨åˆ†è¨ˆç®—]

    W1 --> R[çµæœçµ±åˆ]
    W2 --> R
    W3 --> R
    W4 --> R

    style M fill:#9d4edd
    style W1 fill:#e3f2fd
    style W2 fill:#e3f2fd
    style W3 fill:#e3f2fd
    style W4 fill:#e3f2fd
    style R fill:#c8e6c9
</div>

<h4>å½¹å‰²åˆ†æ‹…</h4>

<ul>
<li><strong>ãƒã‚¹ã‚¿ãƒ¼ãƒãƒ¼ãƒ‰</strong>:
<ul>
<li>ã‚¿ã‚¹ã‚¯ã®åˆ†å‰²ã¨å‰²ã‚Šå½“ã¦</li>
<li>ãƒ¯ãƒ¼ã‚«ãƒ¼ã®ç›£è¦–</li>
<li>çµæœã®é›†ç´„</li>
<li>éšœå®³ã®æ¤œå‡ºã¨å›å¾©</li>
</ul></li>
<li><strong>ãƒ¯ãƒ¼ã‚«ãƒ¼ãƒãƒ¼ãƒ‰</strong>:
<ul>
<li>å‰²ã‚Šå½“ã¦ã‚‰ã‚ŒãŸã‚¿ã‚¹ã‚¯ã®å®Ÿè¡Œ</li>
<li>çµæœã®è¿”é€</li>
<li>ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã®å ±å‘Š</li>
</ul></li>
</ul>

<h3>ãƒ‡ãƒ¼ã‚¿åˆ†å‰²ã¨ã‚·ãƒ£ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°</h3>

<p><strong>ã‚·ãƒ£ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ï¼ˆShardingï¼‰</strong>ã¯ã€ãƒ‡ãƒ¼ã‚¿ã‚’è¤‡æ•°ã®ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³ã«åˆ†å‰²ã™ã‚‹æŠ€è¡“ã§ã™ã€‚</p>

<h4>åˆ†å‰²æˆ¦ç•¥</h4>

<table>
<thead>
<tr>
<th>æˆ¦ç•¥</th>
<th>èª¬æ˜</th>
<th>ä½¿ç”¨ä¾‹</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>æ°´å¹³åˆ†å‰²</strong></td>
<td>è¡Œå˜ä½ã§åˆ†å‰²</td>
<td>æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‡ãƒ¼ã‚¿</td>
</tr>
<tr>
<td><strong>å‚ç›´åˆ†å‰²</strong></td>
<td>åˆ—å˜ä½ã§åˆ†å‰²</td>
<td>ç‰¹å¾´é‡ãŒå¤šã„å ´åˆ</td>
</tr>
<tr>
<td><strong>ãƒãƒƒã‚·ãƒ¥ãƒ™ãƒ¼ã‚¹</strong></td>
<td>ã‚­ãƒ¼ã®ãƒãƒƒã‚·ãƒ¥å€¤ã§åˆ†å‰²</td>
<td>å‡ç­‰ãªåˆ†æ•£ãŒå¿…è¦</td>
</tr>
<tr>
<td><strong>ç¯„å›²ãƒ™ãƒ¼ã‚¹</strong></td>
<td>å€¤ã®ç¯„å›²ã§åˆ†å‰²</td>
<td>ã‚½ãƒ¼ãƒˆæ¸ˆã¿ãƒ‡ãƒ¼ã‚¿</td>
</tr>
</tbody>
</table>

<pre><code class="language-python">import numpy as np
import pandas as pd

# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿
n_samples = 1000
data = pd.DataFrame({
    'user_id': np.random.randint(1, 100, n_samples),
    'timestamp': pd.date_range('2024-01-01', periods=n_samples, freq='1min'),
    'value': np.random.random(n_samples)
})

# 1. æ°´å¹³åˆ†å‰²ï¼ˆè¡Œå˜ä½ï¼‰
n_partitions = 4
partition_size = len(data) // n_partitions

horizontal_shards = []
for i in range(n_partitions):
    start = i * partition_size
    end = start + partition_size if i < n_partitions - 1 else len(data)
    shard = data.iloc[start:end]
    horizontal_shards.append(shard)
    print(f"ã‚·ãƒ£ãƒ¼ãƒ‰ {i+1}: {len(shard)}è¡Œ")

# 2. ãƒãƒƒã‚·ãƒ¥ãƒ™ãƒ¼ã‚¹åˆ†å‰²
def hash_partition(user_id, n_partitions):
    return hash(user_id) % n_partitions

data['partition'] = data['user_id'].apply(lambda x: hash_partition(x, n_partitions))

hash_shards = []
for i in range(n_partitions):
    shard = data[data['partition'] == i]
    hash_shards.append(shard)
    print(f"ãƒãƒƒã‚·ãƒ¥ã‚·ãƒ£ãƒ¼ãƒ‰ {i+1}: {len(shard)}è¡Œ")

# åˆ†æ•£ã®ç¢ºèª
print("\n=== åˆ†å‰²ãƒãƒ©ãƒ³ã‚¹ã®ç¢ºèª ===")
hash_sizes = [len(shard) for shard in hash_shards]
print(f"æœ€å°: {min(hash_sizes)}, æœ€å¤§: {max(hash_sizes)}, å¹³å‡: {np.mean(hash_sizes):.1f}")
</code></pre>

<h3>åˆ†æ•£å‡¦ç†ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®å›³è§£</h3>

<div class="mermaid">
graph LR
    subgraph "å…¥åŠ›ãƒ‡ãƒ¼ã‚¿"
        D[å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ<br/>1TB]
    end

    subgraph "åˆ†æ•£ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸"
        S1[ã‚·ãƒ£ãƒ¼ãƒ‰ 1<br/>250GB]
        S2[ã‚·ãƒ£ãƒ¼ãƒ‰ 2<br/>250GB]
        S3[ã‚·ãƒ£ãƒ¼ãƒ‰ 3<br/>250GB]
        S4[ã‚·ãƒ£ãƒ¼ãƒ‰ 4<br/>250GB]
    end

    subgraph "ä¸¦åˆ—å‡¦ç†"
        P1[ãƒ—ãƒ­ã‚»ã‚¹ 1]
        P2[ãƒ—ãƒ­ã‚»ã‚¹ 2]
        P3[ãƒ—ãƒ­ã‚»ã‚¹ 3]
        P4[ãƒ—ãƒ­ã‚»ã‚¹ 4]
    end

    subgraph "çµæœé›†ç´„"
        A[é›†ç´„ãƒ»çµ±åˆ]
    end

    D --> S1
    D --> S2
    D --> S3
    D --> S4

    S1 --> P1
    S2 --> P2
    S3 --> P3
    S4 --> P4

    P1 --> A
    P2 --> A
    P3 --> A
    P4 --> A

    style D fill:#ffebee
    style S1 fill:#e3f2fd
    style S2 fill:#e3f2fd
    style S3 fill:#e3f2fd
    style S4 fill:#e3f2fd
    style P1 fill:#fff3e0
    style P2 fill:#fff3e0
    style P3 fill:#fff3e0
    style P4 fill:#fff3e0
    style A fill:#c8e6c9
</div>

<hr>

<h2>1.3 ä¸¦åˆ—åŒ–æˆ¦ç•¥</h2>

<h3>ãƒ‡ãƒ¼ã‚¿ä¸¦åˆ—åŒ–</h3>

<p><strong>ãƒ‡ãƒ¼ã‚¿ä¸¦åˆ—åŒ–ï¼ˆData Parallelismï¼‰</strong>ã¯ã€ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†å‰²ã—ã€å„ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³ã§åŒã˜å‡¦ç†ã‚’ä¸¦åˆ—å®Ÿè¡Œã—ã¾ã™ã€‚</p>

<blockquote>
<p>æœ€ã‚‚ä¸€èˆ¬çš„ã§å®Ÿè£…ã—ã‚„ã™ã„ä¸¦åˆ—åŒ–æ‰‹æ³•ã§ã™ã€‚</p>
</blockquote>

<pre><code class="language-python">import numpy as np
import multiprocessing as mp
import time

# å‡¦ç†é–¢æ•°
def process_chunk(data_chunk):
    """ãƒ‡ãƒ¼ã‚¿ãƒãƒ£ãƒ³ã‚¯ã«å¯¾ã™ã‚‹å‡¦ç†ï¼ˆä¾‹ï¼šå¹³å‡è¨ˆç®—ï¼‰"""
    return np.mean(data_chunk, axis=0)

# ã‚·ãƒ³ã‚°ãƒ«ãƒ—ãƒ­ã‚»ã‚¹ç‰ˆ
def single_process_compute(data):
    start = time.time()
    result = np.mean(data, axis=0)
    elapsed = time.time() - start
    return result, elapsed

# ãƒãƒ«ãƒãƒ—ãƒ­ã‚»ã‚¹ç‰ˆï¼ˆãƒ‡ãƒ¼ã‚¿ä¸¦åˆ—åŒ–ï¼‰
def multi_process_compute(data, n_workers=4):
    start = time.time()

    # ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†å‰²
    chunks = np.array_split(data, n_workers)

    # ä¸¦åˆ—å‡¦ç†
    with mp.Pool(n_workers) as pool:
        results = pool.map(process_chunk, chunks)

    # çµæœã‚’çµ±åˆ
    final_result = np.mean(results, axis=0)
    elapsed = time.time() - start

    return final_result, elapsed

# ãƒ†ã‚¹ãƒˆ
if __name__ == '__main__':
    # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿
    data = np.random.random((10_000_000, 10))

    print("=== ãƒ‡ãƒ¼ã‚¿ä¸¦åˆ—åŒ–ã®æ¯”è¼ƒ ===")
    print(f"ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {data.shape}")

    # ã‚·ãƒ³ã‚°ãƒ«ãƒ—ãƒ­ã‚»ã‚¹
    result_single, time_single = single_process_compute(data)
    print(f"\nã‚·ãƒ³ã‚°ãƒ«ãƒ—ãƒ­ã‚»ã‚¹: {time_single:.4f}ç§’")

    # ãƒãƒ«ãƒãƒ—ãƒ­ã‚»ã‚¹
    n_workers = mp.cpu_count()
    result_multi, time_multi = multi_process_compute(data, n_workers)
    print(f"ãƒãƒ«ãƒãƒ—ãƒ­ã‚»ã‚¹ ({n_workers}ãƒ¯ãƒ¼ã‚«ãƒ¼): {time_multi:.4f}ç§’")

    # ã‚¹ãƒ”ãƒ¼ãƒ‰ã‚¢ãƒƒãƒ—
    speedup = time_single / time_multi
    print(f"\nã‚¹ãƒ”ãƒ¼ãƒ‰ã‚¢ãƒƒãƒ—: {speedup:.2f}x")
    print(f"åŠ¹ç‡: {speedup / n_workers * 100:.1f}%")
</code></pre>

<h3>ãƒ¢ãƒ‡ãƒ«ä¸¦åˆ—åŒ–</h3>

<p><strong>ãƒ¢ãƒ‡ãƒ«ä¸¦åˆ—åŒ–ï¼ˆModel Parallelismï¼‰</strong>ã¯ã€ãƒ¢ãƒ‡ãƒ«è‡ªä½“ã‚’åˆ†å‰²ã—ã¦è¤‡æ•°ãƒ‡ãƒã‚¤ã‚¹ã«é…ç½®ã—ã¾ã™ã€‚</p>

<p>å¤§è¦æ¨¡ãªãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã§ä½¿ç”¨ã•ã‚Œã¾ã™ï¼š</p>

<ul>
<li>å„å±¤ã‚’ç•°ãªã‚‹GPUã«é…ç½®</li>
<li>ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒå˜ä¸€ãƒ‡ãƒã‚¤ã‚¹ã®ãƒ¡ãƒ¢ãƒªã«åã¾ã‚‰ãªã„å ´åˆ</li>
</ul>

<pre><code class="language-python">import numpy as np

# æ¦‚å¿µçš„ãªä¾‹ï¼šå¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã®åˆ†å‰²
class DistributedModel:
    """ãƒ¢ãƒ‡ãƒ«ä¸¦åˆ—åŒ–ã®æ¦‚å¿µå®Ÿè£…"""

    def __init__(self, layer_sizes):
        self.layers = []
        for i in range(len(layer_sizes) - 1):
            # å„å±¤ã‚’ç•°ãªã‚‹ãƒ‡ãƒã‚¤ã‚¹ï¼ˆã“ã“ã§ã¯é…åˆ—ï¼‰ã«é…ç½®
            weight = np.random.randn(layer_sizes[i], layer_sizes[i+1]) * 0.01
            self.layers.append({
                'weight': weight,
                'device': f'GPU_{i % 4}'  # 4ã¤ã®GPUã«åˆ†æ•£
            })

    def forward(self, x):
        """é †ä¼æ’­ï¼ˆå„å±¤ã¯ç•°ãªã‚‹ãƒ‡ãƒã‚¤ã‚¹ã§å®Ÿè¡Œï¼‰"""
        activation = x
        for i, layer in enumerate(self.layers):
            print(f"å±¤ {i+1} ã‚’ {layer['device']} ã§å®Ÿè¡Œ")
            activation = np.dot(activation, layer['weight'])
            activation = np.maximum(0, activation)  # ReLU
        return activation

# ä½¿ç”¨ä¾‹
print("=== ãƒ¢ãƒ‡ãƒ«ä¸¦åˆ—åŒ–ã®ä¾‹ ===")
layer_sizes = [1000, 2000, 2000, 2000, 100]  # å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«
model = DistributedModel(layer_sizes)

# å…¥åŠ›ãƒ‡ãƒ¼ã‚¿
x = np.random.randn(1, 1000)
output = model.forward(x)

print(f"\nå…¥åŠ›å½¢çŠ¶: {x.shape}")
print(f"å‡ºåŠ›å½¢çŠ¶: {output.shape}")
print(f"ç·ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {sum(layer['weight'].size for layer in model.layers):,}")
</code></pre>

<h3>ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ä¸¦åˆ—åŒ–</h3>

<p><strong>ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ä¸¦åˆ—åŒ–ï¼ˆPipeline Parallelismï¼‰</strong>ã¯ã€å‡¦ç†ã‚’è¤‡æ•°ã®ã‚¹ãƒ†ãƒ¼ã‚¸ã«åˆ†å‰²ã—ã€å„ã‚¹ãƒ†ãƒ¼ã‚¸ã‚’ä¸¦åˆ—å®Ÿè¡Œã—ã¾ã™ã€‚</p>

<pre><code class="language-python">import multiprocessing as mp
from queue import Queue
import time

# ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®ã‚¹ãƒ†ãƒ¼ã‚¸
def stage1_preprocess(input_queue, output_queue):
    """ã‚¹ãƒ†ãƒ¼ã‚¸1: å‰å‡¦ç†"""
    while True:
        item = input_queue.get()
        if item is None:
            output_queue.put(None)
            break
        # å‰å‡¦ç†ï¼ˆä¾‹ï¼šæ­£è¦åŒ–ï¼‰
        processed = item / 255.0
        output_queue.put(processed)

def stage2_feature_extract(input_queue, output_queue):
    """ã‚¹ãƒ†ãƒ¼ã‚¸2: ç‰¹å¾´æŠ½å‡º"""
    while True:
        item = input_queue.get()
        if item is None:
            output_queue.put(None)
            break
        # ç‰¹å¾´æŠ½å‡ºï¼ˆä¾‹ï¼šçµ±è¨ˆé‡è¨ˆç®—ï¼‰
        features = [item.mean(), item.std(), item.max(), item.min()]
        output_queue.put(features)

def stage3_predict(input_queue, results):
    """ã‚¹ãƒ†ãƒ¼ã‚¸3: äºˆæ¸¬"""
    while True:
        item = input_queue.get()
        if item is None:
            break
        # äºˆæ¸¬ï¼ˆç°¡æ˜“ç‰ˆï¼‰
        prediction = sum(item) > 2.0
        results.append(prediction)

# ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ä¸¦åˆ—åŒ–ã®å®Ÿè£…ä¾‹ï¼ˆæ¦‚å¿µï¼‰
print("=== ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ä¸¦åˆ—åŒ–ã®æ¦‚å¿µ ===")
print("ã‚¹ãƒ†ãƒ¼ã‚¸1: å‰å‡¦ç† â†’ ã‚¹ãƒ†ãƒ¼ã‚¸2: ç‰¹å¾´æŠ½å‡º â†’ ã‚¹ãƒ†ãƒ¼ã‚¸3: äºˆæ¸¬")
print("\nå„ã‚¹ãƒ†ãƒ¼ã‚¸ãŒç•°ãªã‚‹ãƒ—ãƒ­ã‚»ã‚¹ã§ä¸¦åˆ—å®Ÿè¡Œã•ã‚Œã‚‹ã“ã¨ã§ã€")
print("ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆãŒå‘ä¸Šã—ã¾ã™ã€‚")
</code></pre>

<h3>ä¸¦åˆ—åŒ–æˆ¦ç•¥ã®æ¯”è¼ƒ</h3>

<table>
<thead>
<tr>
<th>æˆ¦ç•¥</th>
<th>é©ç”¨å ´é¢</th>
<th>é•·æ‰€</th>
<th>çŸ­æ‰€</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>ãƒ‡ãƒ¼ã‚¿ä¸¦åˆ—åŒ–</strong></td>
<td>å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã€åŒä¸€å‡¦ç†</td>
<td>å®Ÿè£…ãŒç°¡å˜ã€ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«</td>
<td>é€šä¿¡ã‚³ã‚¹ãƒˆã€ãƒ¡ãƒ¢ãƒªè¤‡è£½</td>
</tr>
<tr>
<td><strong>ãƒ¢ãƒ‡ãƒ«ä¸¦åˆ—åŒ–</strong></td>
<td>å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã€GPUåˆ¶ç´„</td>
<td>ãƒ¡ãƒ¢ãƒªåˆ¶ç´„ã‚’å›é¿</td>
<td>å®Ÿè£…ãŒè¤‡é›‘ã€ãƒ‡ãƒã‚¤ã‚¹é–“é€šä¿¡</td>
</tr>
<tr>
<td><strong>ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ä¸¦åˆ—åŒ–</strong></td>
<td>å¤šæ®µéšå‡¦ç†ã€ETL</td>
<td>ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆå‘ä¸Š</td>
<td>ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·å¢—åŠ ã€ãƒãƒ©ãƒ³ã‚¹èª¿æ•´</td>
</tr>
</tbody>
</table>

<hr>

<h2>1.4 åˆ†æ•£ã‚·ã‚¹ãƒ†ãƒ ã®èª²é¡Œ</h2>

<h3>é€šä¿¡ã‚³ã‚¹ãƒˆ</h3>

<p>åˆ†æ•£å‡¦ç†ã«ãŠã‘ã‚‹æœ€å¤§ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ã¯ã€ãƒãƒ¼ãƒ‰é–“ã®é€šä¿¡ã§ã™ã€‚</p>

<blockquote>
<p><strong>Amdahlã®æ³•å‰‡</strong>: ä¸¦åˆ—åŒ–ã§ããªã„éƒ¨åˆ†ï¼ˆé€šä¿¡ãªã©ï¼‰ãŒå…¨ä½“ã®æ€§èƒ½ã‚’åˆ¶é™ã—ã¾ã™ã€‚</p>
</blockquote>

<p>$$
\text{Speedup} = \frac{1}{(1-P) + \frac{P}{N}}
$$</p>

<ul>
<li>$P$: ä¸¦åˆ—åŒ–å¯èƒ½ãªéƒ¨åˆ†ã®å‰²åˆ</li>
<li>$N$: ãƒ—ãƒ­ã‚»ãƒƒã‚µæ•°</li>
</ul>

<pre><code class="language-python">import numpy as np
import matplotlib.pyplot as plt

# Amdahlã®æ³•å‰‡ã®å¯è¦–åŒ–
def amdahl_speedup(P, N):
    """Amdahlã®æ³•å‰‡ã«ã‚ˆã‚‹ã‚¹ãƒ”ãƒ¼ãƒ‰ã‚¢ãƒƒãƒ—è¨ˆç®—"""
    return 1 / ((1 - P) + P / N)

# ä¸¦åˆ—åŒ–ç‡ã®ç•°ãªã‚‹ã‚±ãƒ¼ã‚¹
P_values = [0.5, 0.75, 0.9, 0.95, 0.99]
N_range = np.arange(1, 65)

plt.figure(figsize=(10, 6))
for P in P_values:
    speedups = [amdahl_speedup(P, N) for N in N_range]
    plt.plot(N_range, speedups, label=f'P = {P:.0%}', linewidth=2)

plt.xlabel('ãƒ—ãƒ­ã‚»ãƒƒã‚µæ•°', fontsize=12)
plt.ylabel('ã‚¹ãƒ”ãƒ¼ãƒ‰ã‚¢ãƒƒãƒ—', fontsize=12)
plt.title('Amdahlã®æ³•å‰‡ï¼šä¸¦åˆ—åŒ–ç‡ã¨æ€§èƒ½', fontsize=14)
plt.legend()
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()

print("=== Amdahlã®æ³•å‰‡ã®ç¤ºå”† ===")
print("ä¸¦åˆ—åŒ–ç‡ãŒä½ã„ã¨ã€ãƒ—ãƒ­ã‚»ãƒƒã‚µã‚’å¢—ã‚„ã—ã¦ã‚‚æ€§èƒ½å‘ä¸Šã¯é™å®šçš„")
print(f"ä¾‹: P=90%, 64ãƒ—ãƒ­ã‚»ãƒƒã‚µã§æœ€å¤§{amdahl_speedup(0.9, 64):.1f}å€")
</code></pre>

<h3>åŒæœŸ vs éåŒæœŸ</h3>

<table>
<thead>
<tr>
<th>æ–¹å¼</th>
<th>èª¬æ˜</th>
<th>é•·æ‰€</th>
<th>çŸ­æ‰€</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>åŒæœŸå‡¦ç†</strong></td>
<td>å…¨ãƒ¯ãƒ¼ã‚«ãƒ¼ãŒå®Œäº†ã‚’å¾…ã¤</td>
<td>å®Ÿè£…ãŒã‚·ãƒ³ãƒ—ãƒ«ã€ä¸€è²«æ€§ä¿è¨¼</td>
<td>æœ€ã‚‚é…ã„ãƒ¯ãƒ¼ã‚«ãƒ¼ã«ä¾å­˜</td>
</tr>
<tr>
<td><strong>éåŒæœŸå‡¦ç†</strong></td>
<td>å®Œäº†ã‚’å¾…ãŸãšã«æ¬¡ã®å‡¦ç†</td>
<td>ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆå‘ä¸Š</td>
<td>ä¸€è²«æ€§ã®ç®¡ç†ãŒè¤‡é›‘</td>
</tr>
</tbody>
</table>

<h3>è€éšœå®³æ€§</h3>

<p>åˆ†æ•£ã‚·ã‚¹ãƒ†ãƒ ã§ã¯ã€ãƒãƒ¼ãƒ‰ã‚„ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®éšœå®³ãŒé¿ã‘ã‚‰ã‚Œã¾ã›ã‚“ã€‚</p>

<h4>éšœå®³å¯¾ç­–ã®æ‰‹æ³•</h4>

<ul>
<li><strong>ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ</strong>: å®šæœŸçš„ã«çŠ¶æ…‹ã‚’ä¿å­˜</li>
<li><strong>ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³</strong>: ãƒ‡ãƒ¼ã‚¿ã‚’è¤‡æ•°ãƒãƒ¼ãƒ‰ã«è¤‡è£½</li>
<li><strong>ãƒªãƒˆãƒ©ã‚¤</strong>: å¤±æ•—ã—ãŸã‚¿ã‚¹ã‚¯ã‚’å†å®Ÿè¡Œ</li>
<li><strong>å†—é•·æ€§</strong>: è¤‡æ•°ãƒãƒ¼ãƒ‰ã§åŒã˜å‡¦ç†ã‚’å®Ÿè¡Œ</li>
</ul>

<h3>ãƒ‡ãƒãƒƒã‚°ã®å›°é›£ã•</h3>

<p>åˆ†æ•£ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ‡ãƒãƒƒã‚°ã¯ã€ä»¥ä¸‹ã®ç†ç”±ã§å›°é›£ã§ã™ï¼š</p>

<ul>
<li>éæ±ºå®šçš„ãªå®Ÿè¡Œé †åº</li>
<li>ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã«ä¾å­˜ã™ã‚‹ãƒã‚°</li>
<li>è¤‡æ•°ãƒãƒ¼ãƒ‰ã«ã¾ãŸãŒã‚‹ãƒ­ã‚°</li>
<li>å†ç¾ãŒå›°é›£</li>
</ul>

<hr>

<h2>1.5 ãƒ„ãƒ¼ãƒ«ã¨ã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ </h2>

<h3>Apache Hadoop / Spark</h3>

<p><strong>Apache Hadoop</strong>ã¨<strong>Apache Spark</strong>ã¯ã€å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã®ãƒ‡ãƒ•ã‚¡ã‚¯ãƒˆã‚¹ã‚¿ãƒ³ãƒ€ãƒ¼ãƒ‰ã§ã™ã€‚</p>

<table>
<thead>
<tr>
<th>ãƒ„ãƒ¼ãƒ«</th>
<th>ç‰¹å¾´</th>
<th>ä½¿ç”¨ä¾‹</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Hadoop</strong></td>
<td>ãƒ»MapReduceãƒ™ãƒ¼ã‚¹<br>ãƒ»ãƒ‡ã‚£ã‚¹ã‚¯ä¸­å¿ƒã®å‡¦ç†<br>ãƒ»ãƒãƒƒãƒå‡¦ç†å‘ã</td>
<td>å¤§è¦æ¨¡ETLã€ãƒ­ã‚°è§£æ</td>
</tr>
<tr>
<td><strong>Spark</strong></td>
<td>ãƒ»ã‚¤ãƒ³ãƒ¡ãƒ¢ãƒªå‡¦ç†<br>ãƒ»é«˜é€Ÿï¼ˆHadoopã®100å€ï¼‰<br>ãƒ»æ©Ÿæ¢°å­¦ç¿’ãƒ©ã‚¤ãƒ–ãƒ©ãƒªï¼ˆMLlibï¼‰</td>
<td>åå¾©è¨ˆç®—ã€æ©Ÿæ¢°å­¦ç¿’</td>
</tr>
</tbody>
</table>

<pre><code class="language-python"># Apache Spark ã®æ¦‚å¿µçš„ãªä½¿ç”¨ä¾‹ï¼ˆPySparkï¼‰
# æ³¨: å®Ÿè¡Œã«ã¯Sparkã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãŒå¿…è¦

"""
from pyspark.sql import SparkSession

# Sparkã‚»ãƒƒã‚·ãƒ§ãƒ³ä½œæˆ
spark = SparkSession.builder \
    .appName("LargeScaleProcessing") \
    .getOrCreate()

# å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
df = spark.read.parquet("hdfs://path/to/large/data")

# åˆ†æ•£å‡¦ç†
result = df.groupBy("category") \
    .agg({"value": "mean"}) \
    .orderBy("category")

# çµæœã®ä¿å­˜
result.write.parquet("hdfs://path/to/output")

spark.stop()
"""

print("=== Apache Spark ã®ç‰¹å¾´ ===")
print("1. é…å»¶è©•ä¾¡ï¼ˆLazy Evaluationï¼‰: æœ€é©ãªå®Ÿè¡Œè¨ˆç”»ã‚’è‡ªå‹•ç”Ÿæˆ")
print("2. ã‚¤ãƒ³ãƒ¡ãƒ¢ãƒªå‡¦ç†: ä¸­é–“çµæœã‚’ãƒ¡ãƒ¢ãƒªã«ã‚­ãƒ£ãƒƒã‚·ãƒ¥")
print("3. è€éšœå®³æ€§: RDDï¼ˆResilient Distributed Datasetï¼‰ã«ã‚ˆã‚‹è‡ªå‹•å¾©æ—§")
print("4. çµ±åˆAPI: SQLã€æ©Ÿæ¢°å­¦ç¿’ã€ã‚°ãƒ©ãƒ•å‡¦ç†ã‚’çµ±ä¸€çš„ã«æ‰±ãˆã‚‹")
</code></pre>

<h3>Dask</h3>

<p><strong>Dask</strong>ã¯ã€Pythonãƒã‚¤ãƒ†ã‚£ãƒ–ã®ä¸¦åˆ—å‡¦ç†ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§ã™ã€‚</p>

<pre><code class="language-python">import numpy as np

# Daskã®æ¦‚å¿µçš„ãªä½¿ç”¨ä¾‹
"""
import dask.array as da
import dask.dataframe as dd

# Daské…åˆ—ï¼ˆNumPyãƒ©ã‚¤ã‚¯ãªAPIï¼‰
x = da.random.random((100000, 10000), chunks=(1000, 1000))
result = x.mean(axis=0).compute()  # é…å»¶è©•ä¾¡ â†’ å®Ÿè¡Œ

# Dask DataFrameï¼ˆpandasãƒ©ã‚¤ã‚¯ãªAPIï¼‰
df = dd.read_csv('large_file_*.csv')
result = df.groupby('category').value.mean().compute()
"""

print("=== Dask ã®ç‰¹å¾´ ===")
print("1. NumPy/pandasäº’æ›API: æ—¢å­˜ã‚³ãƒ¼ãƒ‰ã®ç§»è¡ŒãŒå®¹æ˜“")
print("2. ã‚¿ã‚¹ã‚¯ã‚°ãƒ©ãƒ•: å‡¦ç†ã®ä¾å­˜é–¢ä¿‚ã‚’è‡ªå‹•ç®¡ç†")
print("3. ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«: å˜ä¸€ãƒã‚·ãƒ³ â†’ ã‚¯ãƒ©ã‚¹ã‚¿ã¸ã‚·ãƒ¼ãƒ ãƒ¬ã‚¹ã«æ‹¡å¼µ")
print("4. Pythonã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ ã¨ã®çµ±åˆ: scikit-learnã€XGBoostãªã©")

# ç°¡å˜ãªDaské¢¨ã®å‡¦ç†ä¾‹ï¼ˆæ¦‚å¿µï¼‰
print("\n=== ãƒãƒ£ãƒ³ã‚¯å‡¦ç†ã®ä¾‹ ===")
data = np.random.random((10000, 100))
chunk_size = 1000
results = []

for i in range(0, len(data), chunk_size):
    chunk = data[i:i+chunk_size]
    result = np.mean(chunk, axis=0)
    results.append(result)

final_result = np.mean(results, axis=0)
print(f"ãƒãƒ£ãƒ³ã‚¯æ•°: {len(results)}")
print(f"æœ€çµ‚çµæœå½¢çŠ¶: {final_result.shape}")
</code></pre>

<h3>Ray</h3>

<p><strong>Ray</strong>ã¯ã€åˆ†æ•£ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ç”¨ã®çµ±åˆãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã™ã€‚</p>

<pre><code class="language-python"># Rayã®æ¦‚å¿µçš„ãªä½¿ç”¨ä¾‹
"""
import ray

# RayåˆæœŸåŒ–
ray.init()

# ãƒªãƒ¢ãƒ¼ãƒˆé–¢æ•°
@ray.remote
def process_data(data):
    return data.sum()

# ä¸¦åˆ—å®Ÿè¡Œ
data_chunks = [np.random.random(1000) for _ in range(10)]
futures = [process_data.remote(chunk) for chunk in data_chunks]
results = ray.get(futures)  # çµæœã‚’å–å¾—

ray.shutdown()
"""

print("=== Ray ã®ç‰¹å¾´ ===")
print("1. ä½ãƒ¬ãƒ™ãƒ«åˆ¶å¾¡: ã‚¿ã‚¹ã‚¯ãƒ»ã‚¢ã‚¯ã‚¿ãƒ¼ãƒ¢ãƒ‡ãƒ«ã§æŸ”è»Ÿãªä¸¦åˆ—åŒ–")
print("2. é«˜æ€§èƒ½: åˆ†æ•£ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°ã¨å…±æœ‰ãƒ¡ãƒ¢ãƒª")
print("3. ã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ : Ray Tuneï¼ˆãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´ï¼‰ã€RLlibï¼ˆå¼·åŒ–å­¦ç¿’ï¼‰")
print("4. ä½¿ã„ã‚„ã™ã•: Pythonãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ã§ç°¡å˜ã«ä¸¦åˆ—åŒ–")
</code></pre>

<h3>é¸æŠåŸºæº–</h3>

<table>
<thead>
<tr>
<th>çŠ¶æ³</th>
<th>æ¨å¥¨ãƒ„ãƒ¼ãƒ«</th>
<th>ç†ç”±</th>
</tr>
</thead>
<tbody>
<tr>
<td>å¤§è¦æ¨¡ãƒãƒƒãƒå‡¦ç†ï¼ˆTBç´šï¼‰</td>
<td>Apache Spark</td>
<td>æˆç†Ÿã—ãŸã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ ã€è€éšœå®³æ€§</td>
</tr>
<tr>
<td>Pythonä¸­å¿ƒã®é–‹ç™º</td>
<td>Dask</td>
<td>NumPy/pandasäº’æ›ã€å­¦ç¿’ã‚³ã‚¹ãƒˆä½</td>
</tr>
<tr>
<td>è¤‡é›‘ãªåˆ†æ•£ã‚¢ãƒ—ãƒª</td>
<td>Ray</td>
<td>æŸ”è»Ÿãªåˆ¶å¾¡ã€é«˜æ€§èƒ½</td>
</tr>
<tr>
<td>å˜ä¸€ãƒã‚·ãƒ³é«˜é€ŸåŒ–</td>
<td>multiprocessing, joblib</td>
<td>ã‚·ãƒ³ãƒ—ãƒ«ã€è¿½åŠ ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ä¸è¦</td>
</tr>
<tr>
<td>æ©Ÿæ¢°å­¦ç¿’ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³</td>
<td>Spark MLlib, Ray Tune</td>
<td>çµ±åˆã•ã‚ŒãŸæ©Ÿæ¢°å­¦ç¿’ãƒ„ãƒ¼ãƒ«</td>
</tr>
</tbody>
</table>

<hr>

<h2>1.6 æœ¬ç« ã®ã¾ã¨ã‚</h2>

<h3>å­¦ã‚“ã ã“ã¨</h3>

<ol>
<li><p><strong>ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã®èª²é¡Œ</strong></p>
<ul>
<li>ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã€ãƒ¡ãƒ¢ãƒªã€è¨ˆç®—æ™‚é–“ã€I/Oã®åˆ¶ç´„</li>
<li>å˜ä¸€ãƒã‚·ãƒ³ã®é™ç•Œã¨åˆ†æ•£å‡¦ç†ã®å¿…è¦æ€§</li>
</ul></li>

<li><p><strong>åˆ†æ•£å‡¦ç†ã®æ¦‚å¿µ</strong></p>
<ul>
<li>æ°´å¹³ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚° vs å‚ç›´ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°</li>
<li>ãƒã‚¹ã‚¿ãƒ¼ãƒ»ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£</li>
<li>ãƒ‡ãƒ¼ã‚¿åˆ†å‰²ã¨ã‚·ãƒ£ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æˆ¦ç•¥</li>
</ul></li>

<li><p><strong>ä¸¦åˆ—åŒ–æˆ¦ç•¥</strong></p>
<ul>
<li>ãƒ‡ãƒ¼ã‚¿ä¸¦åˆ—åŒ–ï¼šæœ€ã‚‚ä¸€èˆ¬çš„ã€å®Ÿè£…ãŒå®¹æ˜“</li>
<li>ãƒ¢ãƒ‡ãƒ«ä¸¦åˆ—åŒ–ï¼šå¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«å‘ã‘</li>
<li>ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ä¸¦åˆ—åŒ–ï¼šå¤šæ®µéšå‡¦ç†ã«æœ‰åŠ¹</li>
</ul></li>

<li><p><strong>åˆ†æ•£ã‚·ã‚¹ãƒ†ãƒ ã®èª²é¡Œ</strong></p>
<ul>
<li>é€šä¿¡ã‚³ã‚¹ãƒˆã¨Amdahlã®æ³•å‰‡</li>
<li>åŒæœŸ vs éåŒæœŸã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•</li>
<li>è€éšœå®³æ€§ã¨ãƒ‡ãƒãƒƒã‚°ã®å›°é›£ã•</li>
</ul></li>

<li><p><strong>ãƒ„ãƒ¼ãƒ«ã¨ã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ </strong></p>
<ul>
<li>Hadoop/Spark: å¤§è¦æ¨¡ãƒãƒƒãƒå‡¦ç†</li>
<li>Dask: Pythonä¸­å¿ƒã®ä¸¦åˆ—åŒ–</li>
<li>Ray: æŸ”è»Ÿãªåˆ†æ•£ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³</li>
</ul></li>
</ol>

<h3>é‡è¦ãªåŸå‰‡</h3>

<table>
<thead>
<tr>
<th>åŸå‰‡</th>
<th>èª¬æ˜</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>æœ€é©åŒ–ã®é †åº</strong></td>
<td>ã¾ãšã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã€æ¬¡ã«å®Ÿè£…ã€æœ€å¾Œã«ä¸¦åˆ—åŒ–</td>
</tr>
<tr>
<td><strong>é€šä¿¡æœ€å°åŒ–</strong></td>
<td>ãƒãƒ¼ãƒ‰é–“é€šä¿¡ã‚’æ¸›ã‚‰ã™ã“ã¨ãŒæ€§èƒ½å‘ä¸Šã®éµ</td>
</tr>
<tr>
<td><strong>é©åˆ‡ãªç²’åº¦</strong></td>
<td>ã‚¿ã‚¹ã‚¯åˆ†å‰²ãŒç´°ã‹ã™ãã‚‹ã¨ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰å¢—</td>
</tr>
<tr>
<td><strong>æ¸¬å®šé§†å‹•</strong></td>
<td>æ¨æ¸¬ã›ãšã€å®Ÿéš›ã®æ€§èƒ½ã‚’æ¸¬å®šã—ã¦åˆ¤æ–­</td>
</tr>
<tr>
<td><strong>æ®µéšçš„ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°</strong></td>
<td>å°è¦æ¨¡ã§æ¤œè¨¼ã—ã¦ã‹ã‚‰å¤§è¦æ¨¡åŒ–</td>
</tr>
</tbody>
</table>

<h3>æ¬¡ã®ç« ã¸</h3>

<p>ç¬¬2ç« ã§ã¯ã€<strong>MapReduceã¨SparkåŸºç¤</strong>ã‚’å­¦ã³ã¾ã™ï¼š</p>
<ul>
<li>MapReduceãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«</li>
<li>Apache Sparkã®åŸºæœ¬æ“ä½œ</li>
<li>RDDã¨DataFrame</li>
<li>å®Ÿè·µçš„ãªåˆ†æ•£å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³</li>
</ul>

<hr>

<h2>æ¼”ç¿’å•é¡Œ</h2>

<h3>å•é¡Œ1ï¼ˆé›£æ˜“åº¦ï¼šeasyï¼‰</h3>
<p>æ°´å¹³ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã¨å‚ç›´ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã®é•ã„ã‚’èª¬æ˜ã—ã€ãã‚Œãã‚Œã®é•·æ‰€ã¨çŸ­æ‰€ã‚’è¿°ã¹ã¦ãã ã•ã„ã€‚</p>

<details>
<summary>è§£ç­”ä¾‹</summary>

<p><strong>è§£ç­”</strong>ï¼š</p>

<p><strong>å‚ç›´ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ï¼ˆScale Upï¼‰</strong>ï¼š</p>
<ul>
<li>å®šç¾©: å˜ä¸€ãƒã‚·ãƒ³ã®æ€§èƒ½ã‚’å‘ä¸Šï¼ˆCPUã€ãƒ¡ãƒ¢ãƒªã€ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã®å¢—å¼·ï¼‰</li>
<li>é•·æ‰€:
<ul>
<li>å®Ÿè£…ãŒã‚·ãƒ³ãƒ—ãƒ«ï¼ˆæ—¢å­˜ã‚³ãƒ¼ãƒ‰ã‚’ãã®ã¾ã¾ä½¿ç”¨å¯èƒ½ï¼‰</li>
<li>ãƒãƒ¼ãƒ‰é–“é€šä¿¡ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ãŒãªã„</li>
<li>ãƒ‡ãƒ¼ã‚¿ã®ä¸€è²«æ€§ãŒä¿ã¡ã‚„ã™ã„</li>
</ul></li>
<li>çŸ­æ‰€:
<ul>
<li>ç‰©ç†çš„ãªé™ç•ŒãŒã‚ã‚‹</li>
<li>ã‚³ã‚¹ãƒˆãŒéç·šå½¢ã«å¢—åŠ ï¼ˆé«˜æ€§èƒ½ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã¯å‰²é«˜ï¼‰</li>
<li>å˜ä¸€éšœå®³ç‚¹ï¼ˆSPOFï¼‰ã®ãƒªã‚¹ã‚¯</li>
</ul></li>
</ul>

<p><strong>æ°´å¹³ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ï¼ˆScale Outï¼‰</strong>ï¼š</p>
<ul>
<li>å®šç¾©: ãƒã‚·ãƒ³ï¼ˆãƒãƒ¼ãƒ‰ï¼‰ã®æ•°ã‚’å¢—ã‚„ã—ã¦åˆ†æ•£å‡¦ç†</li>
<li>é•·æ‰€:
<ul>
<li>ç†è«–ä¸Šç„¡é™ã«æ‹¡å¼µå¯èƒ½</li>
<li>ã‚³ã‚¹ãƒˆãŒç·šå½¢ï¼ˆé€šå¸¸ã®ã‚µãƒ¼ãƒãƒ¼ã‚’è¿½åŠ ï¼‰</li>
<li>è€éšœå®³æ€§ãŒé«˜ã„ï¼ˆãƒãƒ¼ãƒ‰ã®å†—é•·åŒ–ï¼‰</li>
</ul></li>
<li>çŸ­æ‰€:
<ul>
<li>å®Ÿè£…ãŒè¤‡é›‘ï¼ˆåˆ†æ•£å‡¦ç†ã®ãƒ­ã‚¸ãƒƒã‚¯å¿…è¦ï¼‰</li>
<li>ãƒãƒ¼ãƒ‰é–“é€šä¿¡ã®ã‚³ã‚¹ãƒˆç™ºç”Ÿ</li>
<li>ãƒ‡ãƒ¼ã‚¿ã®ä¸€è²«æ€§ç®¡ç†ãŒé›£ã—ã„</li>
</ul></li>
</ul>

<p><strong>å®Ÿå‹™ã§ã®é¸æŠ</strong>ï¼šé€šå¸¸ã€å‚ç›´ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã‚’é™ç•Œã¾ã§è¡Œã„ã€ãã®å¾Œã«æ°´å¹³ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã«ç§»è¡Œã™ã‚‹ã®ãŒä¸€èˆ¬çš„ã§ã™ã€‚</p>

</details>

<h3>å•é¡Œ2ï¼ˆé›£æ˜“åº¦ï¼šmediumï¼‰</h3>
<p>Amdahlã®æ³•å‰‡ã‚’ç”¨ã„ã¦ã€ä¸¦åˆ—åŒ–ç‡ãŒ80%ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’16ãƒ—ãƒ­ã‚»ãƒƒã‚µã§å®Ÿè¡Œã—ãŸå ´åˆã®ã‚¹ãƒ”ãƒ¼ãƒ‰ã‚¢ãƒƒãƒ—ã‚’è¨ˆç®—ã—ã¦ãã ã•ã„ã€‚</p>

<details>
<summary>è§£ç­”ä¾‹</summary>

<pre><code class="language-python">def amdahl_speedup(P, N):
    """
    Amdahlã®æ³•å‰‡ã«ã‚ˆã‚‹ã‚¹ãƒ”ãƒ¼ãƒ‰ã‚¢ãƒƒãƒ—è¨ˆç®—

    Parameters:
    P: ä¸¦åˆ—åŒ–å¯èƒ½ãªéƒ¨åˆ†ã®å‰²åˆï¼ˆ0ã€œ1ï¼‰
    N: ãƒ—ãƒ­ã‚»ãƒƒã‚µæ•°

    Returns:
    ã‚¹ãƒ”ãƒ¼ãƒ‰ã‚¢ãƒƒãƒ—å€ç‡
    """
    return 1 / ((1 - P) + P / N)

# å•é¡Œã®è¨ˆç®—
P = 0.8  # 80%
N = 16   # 16ãƒ—ãƒ­ã‚»ãƒƒã‚µ

speedup = amdahl_speedup(P, N)

print("=== Amdahlã®æ³•å‰‡ã«ã‚ˆã‚‹è¨ˆç®— ===")
print(f"ä¸¦åˆ—åŒ–ç‡: {P:.0%}")
print(f"ãƒ—ãƒ­ã‚»ãƒƒã‚µæ•°: {N}")
print(f"ã‚¹ãƒ”ãƒ¼ãƒ‰ã‚¢ãƒƒãƒ—: {speedup:.2f}x")
print(f"\nè§£èª¬:")
print(f"ç†è«–ä¸Šã®æœ€å¤§ã‚¹ãƒ”ãƒ¼ãƒ‰ã‚¢ãƒƒãƒ—ï¼ˆç„¡é™ãƒ—ãƒ­ã‚»ãƒƒã‚µï¼‰: {1/(1-P):.2f}x")
print(f"åŠ¹ç‡: {speedup/N*100:.1f}%")
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>=== Amdahlã®æ³•å‰‡ã«ã‚ˆã‚‹è¨ˆç®— ===
ä¸¦åˆ—åŒ–ç‡: 80%
ãƒ—ãƒ­ã‚»ãƒƒã‚µæ•°: 16
ã‚¹ãƒ”ãƒ¼ãƒ‰ã‚¢ãƒƒãƒ—: 4.21x

è§£èª¬:
ç†è«–ä¸Šã®æœ€å¤§ã‚¹ãƒ”ãƒ¼ãƒ‰ã‚¢ãƒƒãƒ—ï¼ˆç„¡é™ãƒ—ãƒ­ã‚»ãƒƒã‚µï¼‰: 5.00x
åŠ¹ç‡: 26.3%
</code></pre>

<p><strong>è¨ˆç®—å¼</strong>ï¼š</p>
<p>$$
\text{Speedup} = \frac{1}{(1-0.8) + \frac{0.8}{16}} = \frac{1}{0.2 + 0.05} = \frac{1}{0.25} = 4
$$</p>

<p><strong>è§£èª¬</strong>ï¼š</p>
<ul>
<li>16ãƒ—ãƒ­ã‚»ãƒƒã‚µã§ã‚‚4.21å€ã®ã‚¹ãƒ”ãƒ¼ãƒ‰ã‚¢ãƒƒãƒ—ã«ã¨ã©ã¾ã‚‹</li>
<li>ä¸¦åˆ—åŒ–ã§ããªã„20%ã®éƒ¨åˆ†ãŒæ€§èƒ½ã®ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã«ãªã‚‹</li>
<li>ãƒ—ãƒ­ã‚»ãƒƒã‚µã‚’å¢—ã‚„ã—ã¦ã‚‚5å€ä»¥ä¸Šã®ã‚¹ãƒ”ãƒ¼ãƒ‰ã‚¢ãƒƒãƒ—ã¯ä¸å¯èƒ½</li>
</ul>

</details>

<h3>å•é¡Œ3ï¼ˆé›£æ˜“åº¦ï¼šmediumï¼‰</h3>
<p>ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã‚’ã€multiprocessingã‚’ä½¿ã£ã¦ãƒ‡ãƒ¼ã‚¿ä¸¦åˆ—åŒ–ã—ã¦ãã ã•ã„ã€‚</p>

<pre><code class="language-python">import numpy as np

# å‡¦ç†å¯¾è±¡ã®ãƒ‡ãƒ¼ã‚¿
data = np.random.random((1_000_000, 10))

# å„è¡Œã®çµ±è¨ˆé‡ã‚’è¨ˆç®—
result = []
for row in data:
    stats = {
        'mean': row.mean(),
        'std': row.std(),
        'max': row.max(),
        'min': row.min()
    }
    result.append(stats)
</code></pre>

<details>
<summary>è§£ç­”ä¾‹</summary>

<pre><code class="language-python">import numpy as np
import multiprocessing as mp
import time

# å‡¦ç†é–¢æ•°
def compute_stats(chunk):
    """ãƒ‡ãƒ¼ã‚¿ãƒãƒ£ãƒ³ã‚¯ã®çµ±è¨ˆé‡ã‚’è¨ˆç®—"""
    result = []
    for row in chunk:
        stats = {
            'mean': row.mean(),
            'std': row.std(),
            'max': row.max(),
            'min': row.min()
        }
        result.append(stats)
    return result

# ã‚·ãƒ³ã‚°ãƒ«ãƒ—ãƒ­ã‚»ã‚¹ç‰ˆ
def single_process_version(data):
    start = time.time()
    result = []
    for row in data:
        stats = {
            'mean': row.mean(),
            'std': row.std(),
            'max': row.max(),
            'min': row.min()
        }
        result.append(stats)
    elapsed = time.time() - start
    return result, elapsed

# ãƒãƒ«ãƒãƒ—ãƒ­ã‚»ã‚¹ç‰ˆï¼ˆãƒ‡ãƒ¼ã‚¿ä¸¦åˆ—åŒ–ï¼‰
def multi_process_version(data, n_workers=4):
    start = time.time()

    # ãƒ‡ãƒ¼ã‚¿ã‚’ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²
    chunks = np.array_split(data, n_workers)

    # ä¸¦åˆ—å‡¦ç†
    with mp.Pool(n_workers) as pool:
        results = pool.map(compute_stats, chunks)

    # çµæœã‚’çµ±åˆ
    final_result = []
    for chunk_result in results:
        final_result.extend(chunk_result)

    elapsed = time.time() - start
    return final_result, elapsed

if __name__ == '__main__':
    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
    data = np.random.random((100_000, 10))  # ã‚µã‚¤ã‚ºã‚’èª¿æ•´

    print("=== ãƒ‡ãƒ¼ã‚¿ä¸¦åˆ—åŒ–ã®å®Ÿè£… ===")
    print(f"ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: {data.shape}")

    # ã‚·ãƒ³ã‚°ãƒ«ãƒ—ãƒ­ã‚»ã‚¹
    result_single, time_single = single_process_version(data)
    print(f"\nã‚·ãƒ³ã‚°ãƒ«ãƒ—ãƒ­ã‚»ã‚¹: {time_single:.4f}ç§’")

    # ãƒãƒ«ãƒãƒ—ãƒ­ã‚»ã‚¹
    n_workers = mp.cpu_count()
    result_multi, time_multi = multi_process_version(data, n_workers)
    print(f"ãƒãƒ«ãƒãƒ—ãƒ­ã‚»ã‚¹ ({n_workers}ãƒ¯ãƒ¼ã‚«ãƒ¼): {time_multi:.4f}ç§’")

    # æ¤œè¨¼
    assert len(result_single) == len(result_multi), "çµæœã®é•·ã•ãŒç•°ãªã‚Šã¾ã™"
    print(f"\nã‚¹ãƒ”ãƒ¼ãƒ‰ã‚¢ãƒƒãƒ—: {time_single / time_multi:.2f}x")
    print(f"âœ“ ä¸¦åˆ—åŒ–æˆåŠŸ")
</code></pre>

<p><strong>ãƒã‚¤ãƒ³ãƒˆ</strong>ï¼š</p>
<ul>
<li><code>np.array_split()</code>ã§ãƒ‡ãƒ¼ã‚¿ã‚’å‡ç­‰ã«åˆ†å‰²</li>
<li><code>multiprocessing.Pool</code>ã§ãƒ¯ãƒ¼ã‚«ãƒ¼ãƒ—ãƒ¼ãƒ«ã‚’ä½œæˆ</li>
<li><code>pool.map()</code>ã§å„ãƒãƒ£ãƒ³ã‚¯ã‚’ä¸¦åˆ—å‡¦ç†</li>
<li>çµæœã‚’<code>extend()</code>ã§çµ±åˆ</li>
</ul>

</details>

<h3>å•é¡Œ4ï¼ˆé›£æ˜“åº¦ï¼šhardï¼‰</h3>
<p>1000ä¸‡è¡Œã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’å‡¦ç†ã™ã‚‹å ´åˆã€ãƒ¡ãƒ¢ãƒªåˆ¶ç´„ã‚’è€ƒæ…®ã—ãŸãƒãƒ£ãƒ³ã‚¯å‡¦ç†ã‚’å®Ÿè£…ã—ã¦ãã ã•ã„ã€‚å„ãƒãƒ£ãƒ³ã‚¯ã¯100ä¸‡è¡Œã¨ã—ã€çµæœã‚’é›†ç´„ã—ã¦ãã ã•ã„ã€‚</p>

<details>
<summary>è§£ç­”ä¾‹</summary>

<pre><code class="language-python">import numpy as np
import time

def process_chunk(chunk):
    """ãƒãƒ£ãƒ³ã‚¯ã”ã¨ã®å‡¦ç†ï¼ˆä¾‹ï¼šå¹³å‡ã€æ¨™æº–åå·®ã€åˆè¨ˆï¼‰"""
    stats = {
        'mean': chunk.mean(axis=0),
        'std': chunk.std(axis=0),
        'sum': chunk.sum(axis=0),
        'count': len(chunk)
    }
    return stats

def aggregate_results(chunk_results):
    """ãƒãƒ£ãƒ³ã‚¯çµæœã‚’æœ€çµ‚çš„ã«é›†ç´„"""
    # å…¨ä½“ã®åˆè¨ˆã‚’è¨ˆç®—
    total_sum = sum(r['sum'] for r in chunk_results)
    total_count = sum(r['count'] for r in chunk_results)

    # å…¨ä½“ã®å¹³å‡
    global_mean = total_sum / total_count

    # å…¨ä½“ã®æ¨™æº–åå·®ï¼ˆåŠ é‡å¹³å‡ï¼‰
    # ã‚ˆã‚Šæ­£ç¢ºã«ã¯åˆ†æ•£ã®åŠ é‡å¹³å‡ã®å¹³æ–¹æ ¹
    weighted_var = sum(
        r['count'] * (r['std']**2 + (r['mean'] - global_mean)**2)
        for r in chunk_results
    ) / total_count
    global_std = np.sqrt(weighted_var)

    return {
        'global_mean': global_mean,
        'global_std': global_std,
        'total_count': total_count
    }

def chunked_processing(n_samples=10_000_000, n_features=10, chunk_size=1_000_000):
    """ãƒ¡ãƒ¢ãƒªåŠ¹ç‡çš„ãªãƒãƒ£ãƒ³ã‚¯å‡¦ç†"""
    print(f"=== ãƒãƒ£ãƒ³ã‚¯å‡¦ç† ===")
    print(f"ç·ã‚µãƒ³ãƒ—ãƒ«æ•°: {n_samples:,}")
    print(f"ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚º: {chunk_size:,}")
    print(f"ãƒãƒ£ãƒ³ã‚¯æ•°: {n_samples // chunk_size}")

    start = time.time()
    chunk_results = []

    # ãƒãƒ£ãƒ³ã‚¯ã”ã¨ã«å‡¦ç†
    for i in range(0, n_samples, chunk_size):
        # ãƒãƒ£ãƒ³ã‚¯ã®ã‚µã‚¤ã‚ºã‚’æ±ºå®š
        current_chunk_size = min(chunk_size, n_samples - i)

        # ãƒãƒ£ãƒ³ã‚¯ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆï¼ˆå®Ÿéš›ã«ã¯ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿ï¼‰
        chunk = np.random.random((current_chunk_size, n_features))

        # ãƒãƒ£ãƒ³ã‚¯å‡¦ç†
        result = process_chunk(chunk)
        chunk_results.append(result)

        print(f"ãƒãƒ£ãƒ³ã‚¯ {len(chunk_results)}: {current_chunk_size:,}è¡Œå‡¦ç†å®Œäº†")

    # çµæœã‚’é›†ç´„
    final_result = aggregate_results(chunk_results)

    elapsed = time.time() - start

    print(f"\n=== å‡¦ç†çµæœ ===")
    print(f"å‡¦ç†æ™‚é–“: {elapsed:.2f}ç§’")
    print(f"å…¨ä½“ã®å¹³å‡ï¼ˆæœ€åˆã®3æ¬¡å…ƒï¼‰: {final_result['global_mean'][:3]}")
    print(f"å…¨ä½“ã®æ¨™æº–åå·®ï¼ˆæœ€åˆã®3æ¬¡å…ƒï¼‰: {final_result['global_std'][:3]}")
    print(f"ç·ã‚µãƒ³ãƒ—ãƒ«æ•°: {final_result['total_count']:,}")

    # ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ã®ç¢ºèª
    import sys
    chunk_memory = sys.getsizeof(np.random.random((chunk_size, n_features))) / (1024**2)
    print(f"\nãƒãƒ£ãƒ³ã‚¯ã‚ãŸã‚Šã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {chunk_memory:.2f} MB")
    print(f"ï¼ˆå…¨ãƒ‡ãƒ¼ã‚¿ã‚’ä¸€åº¦ã«èª­ã¿è¾¼ã‚€å ´åˆã®1/{n_samples//chunk_size}ã®ãƒ¡ãƒ¢ãƒªã§å‡¦ç†ï¼‰")

if __name__ == '__main__':
    # å®Ÿè¡Œï¼ˆå®Ÿéš›ã®ã‚µã‚¤ã‚ºã ã¨æ™‚é–“ãŒã‹ã‹ã‚‹ãŸã‚ã€ç¸®å°ç‰ˆï¼‰
    chunked_processing(n_samples=1_000_000, n_features=10, chunk_size=100_000)
</code></pre>

<p><strong>å‡ºåŠ›ä¾‹</strong>ï¼š</p>
<pre><code>=== ãƒãƒ£ãƒ³ã‚¯å‡¦ç† ===
ç·ã‚µãƒ³ãƒ—ãƒ«æ•°: 1,000,000
ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚º: 100,000
ãƒãƒ£ãƒ³ã‚¯æ•°: 10
ãƒãƒ£ãƒ³ã‚¯ 1: 100,000è¡Œå‡¦ç†å®Œäº†
ãƒãƒ£ãƒ³ã‚¯ 2: 100,000è¡Œå‡¦ç†å®Œäº†
...
ãƒãƒ£ãƒ³ã‚¯ 10: 100,000è¡Œå‡¦ç†å®Œäº†

=== å‡¦ç†çµæœ ===
å‡¦ç†æ™‚é–“: 2.45ç§’
å…¨ä½“ã®å¹³å‡ï¼ˆæœ€åˆã®3æ¬¡å…ƒï¼‰: [0.500 0.499 0.501]
å…¨ä½“ã®æ¨™æº–åå·®ï¼ˆæœ€åˆã®3æ¬¡å…ƒï¼‰: [0.289 0.288 0.290]
ç·ã‚µãƒ³ãƒ—ãƒ«æ•°: 1,000,000

ãƒãƒ£ãƒ³ã‚¯ã‚ãŸã‚Šã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: 7.63 MB
ï¼ˆå…¨ãƒ‡ãƒ¼ã‚¿ã‚’ä¸€åº¦ã«èª­ã¿è¾¼ã‚€å ´åˆã®1/10ã®ãƒ¡ãƒ¢ãƒªã§å‡¦ç†ï¼‰
</code></pre>

<p><strong>ãƒã‚¤ãƒ³ãƒˆ</strong>ï¼š</p>
<ul>
<li>ãƒãƒ£ãƒ³ã‚¯å˜ä½ã§å‡¦ç†ã—ã¦ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’åˆ¶é™</li>
<li>å„ãƒãƒ£ãƒ³ã‚¯ã®çµ±è¨ˆé‡ã‚’ä¿å­˜</li>
<li>æœ€å¾Œã«çµ±è¨ˆçš„ã«æ­£ã—ã„æ–¹æ³•ã§é›†ç´„ï¼ˆåŠ é‡å¹³å‡ï¼‰</li>
<li>å®Ÿéš›ã«ã¯ãƒ•ã‚¡ã‚¤ãƒ«I/Oã‚„ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¯ã‚¨ãƒªã¨çµ„ã¿åˆã‚ã›ã‚‹</li>
</ul>

</details>

<h3>å•é¡Œ5ï¼ˆé›£æ˜“åº¦ï¼šhardï¼‰</h3>
<p>ãƒ‡ãƒ¼ã‚¿ä¸¦åˆ—åŒ–ã€ãƒ¢ãƒ‡ãƒ«ä¸¦åˆ—åŒ–ã€ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ä¸¦åˆ—åŒ–ã®3ã¤ã®æˆ¦ç•¥ã«ã¤ã„ã¦ã€ãã‚Œãã‚Œã®é©ç”¨å ´é¢ã¨ã€çµ„ã¿åˆã‚ã›ã¦ä½¿ã†å ´åˆã®è€ƒæ…®ç‚¹ã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚</p>

<details>
<summary>è§£ç­”ä¾‹</summary>

<p><strong>è§£ç­”</strong>ï¼š</p>

<h4>1. ãƒ‡ãƒ¼ã‚¿ä¸¦åˆ—åŒ–ï¼ˆData Parallelismï¼‰</h4>

<p><strong>é©ç”¨å ´é¢</strong>ï¼š</p>
<ul>
<li>å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆTBç´šï¼‰ã®å‡¦ç†</li>
<li>å„ã‚µãƒ³ãƒ—ãƒ«ãŒç‹¬ç«‹ã«å‡¦ç†å¯èƒ½</li>
<li>åŒã˜ãƒ¢ãƒ‡ãƒ«ã‚’ç•°ãªã‚‹ãƒ‡ãƒ¼ã‚¿ã§è¨“ç·´ï¼ˆãƒŸãƒ‹ãƒãƒƒãƒå­¦ç¿’ï¼‰</li>
</ul>

<p><strong>ä¾‹</strong>ï¼š</p>
<ul>
<li>ç”»åƒåˆ†é¡ã®å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆè¨“ç·´</li>
<li>ãƒ­ã‚°ãƒ‡ãƒ¼ã‚¿ã®é›†ç´„ãƒ»åˆ†æ</li>
<li>ãƒãƒƒãƒäºˆæ¸¬å‡¦ç†</li>
</ul>

<h4>2. ãƒ¢ãƒ‡ãƒ«ä¸¦åˆ—åŒ–ï¼ˆModel Parallelismï¼‰</h4>

<p><strong>é©ç”¨å ´é¢</strong>ï¼š</p>
<ul>
<li>ãƒ¢ãƒ‡ãƒ«ãŒå˜ä¸€ãƒ‡ãƒã‚¤ã‚¹ã®ãƒ¡ãƒ¢ãƒªã«åã¾ã‚‰ãªã„</li>
<li>å¤§è¦æ¨¡ãªãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼ˆæ•°åå„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼‰</li>
<li>è¨ˆç®—ã‚°ãƒ©ãƒ•ã‚’åˆ†å‰²ã§ãã‚‹å ´åˆ</li>
</ul>

<p><strong>ä¾‹</strong>ï¼š</p>
<ul>
<li>GPT-3ã®ã‚ˆã†ãªå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«</li>
<li>é«˜è§£åƒåº¦ç”»åƒå‡¦ç†ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯</li>
<li>ã‚°ãƒ©ãƒ•ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯</li>
</ul>

<h4>3. ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ä¸¦åˆ—åŒ–ï¼ˆPipeline Parallelismï¼‰</h4>

<p><strong>é©ç”¨å ´é¢</strong>ï¼š</p>
<ul>
<li>è¤‡æ•°ã®å‡¦ç†ã‚¹ãƒ†ãƒ¼ã‚¸ãŒã‚ã‚‹</li>
<li>å„ã‚¹ãƒ†ãƒ¼ã‚¸ãŒç•°ãªã‚‹ãƒªã‚½ãƒ¼ã‚¹è¦ä»¶</li>
<li>ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿å‡¦ç†</li>
</ul>

<p><strong>ä¾‹</strong>ï¼š</p>
<ul>
<li>ETLãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ï¼ˆæŠ½å‡ºâ†’å¤‰æ›â†’ãƒ­ãƒ¼ãƒ‰ï¼‰</li>
<li>ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ‡ãƒ¼ã‚¿å‡¦ç†ï¼ˆå‰å‡¦ç†â†’æ¨è«–â†’å¾Œå‡¦ç†ï¼‰</li>
<li>æ·±å±¤å­¦ç¿’ã®å±¤é–“ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³</li>
</ul>

<h4>çµ„ã¿åˆã‚ã›ä½¿ç”¨ã®è€ƒæ…®ç‚¹</h4>

<p><strong>1. ãƒ‡ãƒ¼ã‚¿ä¸¦åˆ—åŒ– + ãƒ¢ãƒ‡ãƒ«ä¸¦åˆ—åŒ–</strong>ï¼š</p>
<pre><code class="language-python">"""
è¶…å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´

ä¾‹: GPT-3ã®è¨“ç·´
- ãƒ¢ãƒ‡ãƒ«ä¸¦åˆ—åŒ–: å„å±¤ã‚’è¤‡æ•°GPUã«åˆ†å‰²
- ãƒ‡ãƒ¼ã‚¿ä¸¦åˆ—åŒ–: ç•°ãªã‚‹ãƒŸãƒ‹ãƒãƒƒãƒã‚’è¤‡æ•°ã®ãƒ¢ãƒ‡ãƒ«ãƒ¬ãƒ—ãƒªã‚«ã§å‡¦ç†
- çµæœ: æ•°åƒGPUã§åŠ¹ç‡çš„ã«è¨“ç·´å¯èƒ½
"""
</code></pre>

<p><strong>è€ƒæ…®ç‚¹</strong>ï¼š</p>
<ul>
<li>é€šä¿¡ãƒ‘ã‚¿ãƒ¼ãƒ³ã®è¤‡é›‘åŒ–ï¼ˆå±¤é–“é€šä¿¡ + ãƒ¬ãƒ—ãƒªã‚«é–“å‹¾é…åŒæœŸï¼‰</li>
<li>ãƒ¡ãƒ¢ãƒªç®¡ç†ã®æœ€é©åŒ–ï¼ˆã‚¢ã‚¯ãƒ†ã‚£ãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ã€å‹¾é…ã®ä¿å­˜å ´æ‰€ï¼‰</li>
<li>è² è·ãƒãƒ©ãƒ³ã‚·ãƒ³ã‚°ï¼ˆãƒ‡ãƒ¼ã‚¿ã¨ãƒ¢ãƒ‡ãƒ«ã®ä¸¡æ–¹ï¼‰</li>
</ul>

<p><strong>2. ãƒ‡ãƒ¼ã‚¿ä¸¦åˆ—åŒ– + ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ä¸¦åˆ—åŒ–</strong>ï¼š</p>
<pre><code class="language-python">"""
å¤§è¦æ¨¡ETLã¨æ©Ÿæ¢°å­¦ç¿’ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

ä¾‹: ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ 
- ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³: ãƒ‡ãƒ¼ã‚¿å–å¾— â†’ å‰å‡¦ç† â†’ æ¨è«– â†’ å¾Œå‡¦ç†
- ãƒ‡ãƒ¼ã‚¿ä¸¦åˆ—: å„ã‚¹ãƒ†ãƒ¼ã‚¸ã§è¤‡æ•°ãƒ¯ãƒ¼ã‚«ãƒ¼ãŒä¸¦åˆ—å®Ÿè¡Œ
- çµæœ: é«˜ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã®äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ 
"""
</code></pre>

<p><strong>è€ƒæ…®ç‚¹</strong>ï¼š</p>
<ul>
<li>ã‚¹ãƒ†ãƒ¼ã‚¸é–“ã®ãƒãƒƒãƒ•ã‚¡ç®¡ç†</li>
<li>èƒŒåœ§åˆ¶å¾¡ï¼ˆé…ã„ã‚¹ãƒ†ãƒ¼ã‚¸ãŒé€Ÿã„ã‚¹ãƒ†ãƒ¼ã‚¸ã‚’ãƒ–ãƒ­ãƒƒã‚¯ï¼‰</li>
<li>ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ã®ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ç®¡ç†</li>
</ul>

<p><strong>3. 3ã¤å…¨ã¦ã®çµ„ã¿åˆã‚ã›</strong>ï¼š</p>
<pre><code class="language-python">"""
è¶…å¤§è¦æ¨¡åˆ†æ•£è¨“ç·´ã‚·ã‚¹ãƒ†ãƒ 

ä¾‹: å¤§è¦æ¨¡æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ 
- ãƒ‡ãƒ¼ã‚¿ä¸¦åˆ—: ç•°ãªã‚‹ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’ä¸¦åˆ—å‡¦ç†
- ãƒ¢ãƒ‡ãƒ«ä¸¦åˆ—: åŸ‹ã‚è¾¼ã¿å±¤ã‚’è¤‡æ•°GPUã«åˆ†æ•£
- ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³: ç‰¹å¾´æŠ½å‡º â†’ ãƒ¢ãƒ‡ãƒ«è¨“ç·´ â†’ è©•ä¾¡ã®ã‚¹ãƒ†ãƒ¼ã‚¸åŒ–
"""
</code></pre>

<p><strong>è€ƒæ…®ç‚¹</strong>ï¼š</p>
<ul>
<li>ã‚·ã‚¹ãƒ†ãƒ è¤‡é›‘æ€§ã®ç®¡ç†ï¼ˆãƒ‡ãƒãƒƒã‚°ã€ç›£è¦–ãŒå›°é›£ï¼‰</li>
<li>å…¨ä½“çš„ãªåŠ¹ç‡ã®æœ€é©åŒ–ï¼ˆã©ã®æˆ¦ç•¥ãŒæœ€ã‚‚ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆãŒã‚ã‚‹ã‹ï¼‰</li>
<li>æ®µéšçš„ãªå®Ÿè£…ï¼ˆã¾ãšå˜ç´”ãªæˆ¦ç•¥ã‹ã‚‰é–‹å§‹ï¼‰</li>
</ul>

<h4>é¸æŠã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³</h4>

<table>
<thead>
<tr>
<th>ãƒœãƒˆãƒ«ãƒãƒƒã‚¯</th>
<th>æ¨å¥¨æˆ¦ç•¥</th>
<th>å„ªå…ˆé †ä½</th>
</tr>
</thead>
<tbody>
<tr>
<td>ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºãŒå¤§ãã„</td>
<td>ãƒ‡ãƒ¼ã‚¿ä¸¦åˆ—åŒ–</td>
<td>1st</td>
</tr>
<tr>
<td>ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºãŒå¤§ãã„</td>
<td>ãƒ¢ãƒ‡ãƒ«ä¸¦åˆ—åŒ–</td>
<td>1st</td>
</tr>
<tr>
<td>å‡¦ç†ã‚¹ãƒ†ãƒ¼ã‚¸ãŒå¤šã„</td>
<td>ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ä¸¦åˆ—åŒ–</td>
<td>2nd</td>
</tr>
<tr>
<td>ä¸¡æ–¹å¤§ãã„</td>
<td>ãƒ‡ãƒ¼ã‚¿+ãƒ¢ãƒ‡ãƒ«ä¸¦åˆ—åŒ–</td>
<td>æ®µéšçš„</td>
</tr>
<tr>
<td>ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¦ä»¶</td>
<td>ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ä¸¦åˆ—åŒ–</td>
<td>1st</td>
</tr>
</tbody>
</table>

<p><strong>å®Ÿè£…ã®åŸå‰‡</strong>ï¼š</p>
<ol>
<li>ã¾ãšå˜ä¸€æˆ¦ç•¥ã§æœ€é©åŒ–</li>
<li>æ¸¬å®šã—ã¦æ¬¡ã®ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã‚’ç‰¹å®š</li>
<li>å¿…è¦ã«å¿œã˜ã¦è¿½åŠ ã®æˆ¦ç•¥ã‚’å°å…¥</li>
<li>å¸¸ã«ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã®åŠ¹ç‡ã‚’æ¸¬å®š</li>
</ol>

</details>

<hr>

<h2>å‚è€ƒæ–‡çŒ®</h2>

<ol>
<li>Dean, J., & Ghemawat, S. (2008). MapReduce: Simplified data processing on large clusters. <em>Communications of the ACM</em>, 51(1), 107-113.</li>
<li>Zaharia, M., et al. (2016). Apache Spark: A unified engine for big data processing. <em>Communications of the ACM</em>, 59(11), 56-65.</li>
<li>Moritz, P., et al. (2018). Ray: A distributed framework for emerging AI applications. <em>OSDI</em>, 561-577.</li>
<li>Rocklin, M. (2015). Dask: Parallel computation with blocked algorithms and task scheduling. <em>SciPy</em>, 126-132.</li>
<li>Barroso, L. A., Clidaras, J., & HÃ¶lzle, U. (2013). <em>The datacenter as a computer</em> (2nd ed.). Morgan & Claypool Publishers.</li>
</ol>

<div class="navigation">
    <a href="index.html" class="nav-button">â† ã‚·ãƒªãƒ¼ã‚ºç›®æ¬¡</a>
    <a href="chapter2-mapreduce-spark.html" class="nav-button">æ¬¡ã®ç« : MapReduceã¨SparkåŸºç¤ â†’</a>
</div>

    </main>

    
    <section class="disclaimer">
        <h3>å…è²¬äº‹é …</h3>
        <ul>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯æ•™è‚²ãƒ»ç ”ç©¶ãƒ»æƒ…å ±æä¾›ã®ã¿ã‚’ç›®çš„ã¨ã—ã¦ãŠã‚Šã€å°‚é–€çš„ãªåŠ©è¨€(æ³•å¾‹ãƒ»ä¼šè¨ˆãƒ»æŠ€è¡“çš„ä¿è¨¼ãªã©)ã‚’æä¾›ã™ã‚‹ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŠã‚ˆã³ä»˜éšã™ã‚‹ã‚³ãƒ¼ãƒ‰ä¾‹ã¯ã€Œç¾çŠ¶æœ‰å§¿(AS IS)ã€ã§æä¾›ã•ã‚Œã€æ˜ç¤ºã¾ãŸã¯é»™ç¤ºã‚’å•ã‚ãšã€å•†å“æ€§ã€ç‰¹å®šç›®çš„é©åˆæ€§ã€æ¨©åˆ©éä¾µå®³ã€æ­£ç¢ºæ€§ãƒ»å®Œå…¨æ€§ã€å‹•ä½œãƒ»å®‰å…¨æ€§ç­‰ã„ã‹ãªã‚‹ä¿è¨¼ã‚‚ã—ã¾ã›ã‚“ã€‚</li>
            <li>å¤–éƒ¨ãƒªãƒ³ã‚¯ã€ç¬¬ä¸‰è€…ãŒæä¾›ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ»ãƒ„ãƒ¼ãƒ«ãƒ»ãƒ©ã‚¤ãƒ–ãƒ©ãƒªç­‰ã®å†…å®¹ãƒ»å¯ç”¨æ€§ãƒ»å®‰å…¨æ€§ã«ã¤ã„ã¦ã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯ä¸€åˆ‡ã®è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®åˆ©ç”¨ãƒ»å®Ÿè¡Œãƒ»è§£é‡ˆã«ã‚ˆã‚Šç›´æ¥çš„ãƒ»é–“æ¥çš„ãƒ»ä»˜éšçš„ãƒ»ç‰¹åˆ¥ãƒ»çµæœçš„ãƒ»æ‡²ç½°çš„æå®³ãŒç”Ÿã˜ãŸå ´åˆã§ã‚‚ã€é©ç”¨æ³•ã§è¨±å®¹ã•ã‚Œã‚‹æœ€å¤§é™ã®ç¯„å›²ã§ã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å†…å®¹ã¯ã€äºˆå‘Šãªãå¤‰æ›´ãƒ»æ›´æ–°ãƒ»æä¾›åœæ­¢ã•ã‚Œã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®è‘—ä½œæ¨©ãƒ»ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯æ˜è¨˜ã•ã‚ŒãŸæ¡ä»¶(ä¾‹: CC BY 4.0)ã«å¾“ã„ã¾ã™ã€‚å½“è©²ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯é€šå¸¸ã€ç„¡ä¿è¨¼æ¡é …ã‚’å«ã¿ã¾ã™ã€‚</li>
        </ul>
    </section>

<footer>
        <p><strong>ä½œæˆè€…</strong>: AI Terakoya Content Team</p>
        <p><strong>ãƒãƒ¼ã‚¸ãƒ§ãƒ³</strong>: 1.0 | <strong>ä½œæˆæ—¥</strong>: 2025-10-21</p>
        <p><strong>ãƒ©ã‚¤ã‚»ãƒ³ã‚¹</strong>: Creative Commons BY 4.0</p>
        <p>Â© 2025 AI Terakoya. All rights reserved.</p>
    </footer>
</body>
</html>
