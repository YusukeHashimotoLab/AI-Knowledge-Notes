<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ç¬¬5ç« ï¼šãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆ†æã®å®Ÿè·µå¿œç”¨ - AI Terakoya</title>

    <style>
        :root {
            --color-primary: #2c3e50;
            --color-primary-dark: #1a252f;
            --color-accent: #7b2cbf;
            --color-accent-light: #9d4edd;
            --color-text: #2d3748;
            --color-text-light: #4a5568;
            --color-bg: #ffffff;
            --color-bg-alt: #f7fafc;
            --color-border: #e2e8f0;
            --color-code-bg: #f8f9fa;
            --color-link: #3182ce;
            --color-link-hover: #2c5aa0;

            --spacing-xs: 0.5rem;
            --spacing-sm: 1rem;
            --spacing-md: 1.5rem;
            --spacing-lg: 2rem;
            --spacing-xl: 3rem;

            --font-body: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            --font-mono: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;

            --border-radius: 8px;
            --box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: var(--font-body);
            line-height: 1.7;
            color: var(--color-text);
            background-color: var(--color-bg);
            font-size: 16px;
        }

        header {
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            padding: var(--spacing-xl) var(--spacing-md);
            margin-bottom: var(--spacing-xl);
            box-shadow: var(--box-shadow);
        }

        .header-content {
            max-width: 900px;
            margin: 0 auto;
        }

        h1 {
            font-size: 2rem;
            font-weight: 700;
            margin-bottom: var(--spacing-sm);
            line-height: 1.2;
        }

        .subtitle {
            font-size: 1.1rem;
            opacity: 0.95;
            font-weight: 400;
            margin-bottom: var(--spacing-md);
        }

        .meta {
            display: flex;
            flex-wrap: wrap;
            gap: var(--spacing-md);
            font-size: 0.9rem;
            opacity: 0.9;
        }

        .meta-item {
            display: flex;
            align-items: center;
            gap: 0.3rem;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 0 var(--spacing-md) var(--spacing-xl);
        }

        h2 {
            font-size: 1.75rem;
            color: var(--color-primary);
            margin-top: var(--spacing-xl);
            margin-bottom: var(--spacing-md);
            padding-bottom: var(--spacing-xs);
            border-bottom: 3px solid var(--color-accent);
        }

        h3 {
            font-size: 1.4rem;
            color: var(--color-primary);
            margin-top: var(--spacing-lg);
            margin-bottom: var(--spacing-sm);
        }

        h4 {
            font-size: 1.1rem;
            color: var(--color-primary-dark);
            margin-top: var(--spacing-md);
            margin-bottom: var(--spacing-sm);
        }

        p {
            margin-bottom: var(--spacing-md);
            color: var(--color-text);
        }

        a {
            color: var(--color-link);
            text-decoration: none;
            transition: color 0.2s;
        }

        a:hover {
            color: var(--color-link-hover);
            text-decoration: underline;
        }

        ul, ol {
            margin-left: var(--spacing-lg);
            margin-bottom: var(--spacing-md);
        }

        li {
            margin-bottom: var(--spacing-xs);
            color: var(--color-text);
        }

        pre {
            background-color: var(--color-code-bg);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            overflow-x: auto;
            margin-bottom: var(--spacing-md);
            font-family: var(--font-mono);
            font-size: 0.9rem;
            line-height: 1.5;
        }

        code {
            font-family: var(--font-mono);
            font-size: 0.9em;
            background-color: var(--color-code-bg);
            padding: 0.2em 0.4em;
            border-radius: 3px;
        }

        pre code {
            background-color: transparent;
            padding: 0;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: var(--spacing-md);
            font-size: 0.95rem;
        }

        th, td {
            border: 1px solid var(--color-border);
            padding: var(--spacing-sm);
            text-align: left;
        }

        th {
            background-color: var(--color-bg-alt);
            font-weight: 600;
            color: var(--color-primary);
        }

        blockquote {
            border-left: 4px solid var(--color-accent);
            padding-left: var(--spacing-md);
            margin: var(--spacing-md) 0;
            color: var(--color-text-light);
            font-style: italic;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        .mermaid {
            text-align: center;
            margin: var(--spacing-lg) 0;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        details {
            background-color: var(--color-bg-alt);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            margin-bottom: var(--spacing-md);
        }

        summary {
            cursor: pointer;
            font-weight: 600;
            color: var(--color-primary);
            user-select: none;
            padding: var(--spacing-xs);
            margin: calc(-1 * var(--spacing-md));
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        summary:hover {
            background-color: rgba(123, 44, 191, 0.1);
        }

        details[open] summary {
            margin-bottom: var(--spacing-md);
            border-bottom: 1px solid var(--color-border);
        }

        .navigation {
            display: flex;
            justify-content: space-between;
            gap: var(--spacing-md);
            margin: var(--spacing-xl) 0;
            padding-top: var(--spacing-lg);
            border-top: 2px solid var(--color-border);
        }

        .nav-button {
            flex: 1;
            padding: var(--spacing-md);
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            border-radius: var(--border-radius);
            text-align: center;
            font-weight: 600;
            transition: transform 0.2s, box-shadow 0.2s;
            box-shadow: var(--box-shadow);
        }

        .nav-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
            text-decoration: none;
        }

        footer {
            margin-top: var(--spacing-xl);
            padding: var(--spacing-lg) var(--spacing-md);
            background-color: var(--color-bg-alt);
            border-top: 1px solid var(--color-border);
            text-align: center;
            font-size: 0.9rem;
            color: var(--color-text-light);
        }

        @media (max-width: 768px) {
            h1 {
                font-size: 1.5rem;
            }

            h2 {
                font-size: 1.4rem;
            }

            h3 {
                font-size: 1.2rem;
            }

            .meta {
                font-size: 0.85rem;
            }

            .navigation {
                flex-direction: column;
            }

            table {
                font-size: 0.85rem;
            }

            th, td {
                padding: var(--spacing-xs);
            }
        }
    </style>

    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
        mermaid.initialize({ startOnLoad: true, theme: 'default' });
    </script>

    <!-- MathJax for LaTeX equation rendering -->
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                displayMath: [['$$', '$$'], ['\\[', '\\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
                ignoreHtmlClass: 'mermaid'
            }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" async></script>
</head>
<body>
    <header>
        <div class="header-content">
            <h1>ç¬¬5ç« ï¼šãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆ†æã®å®Ÿè·µå¿œç”¨</h1>
            <p class="subtitle">å®Ÿä¸–ç•Œã®å•é¡Œã‚’ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã§è§£æ±ºã™ã‚‹ - ç·åˆãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ</p>
            <div class="meta">
                <span class="meta-item">ğŸ“– èª­äº†æ™‚é–“: 35-40åˆ†</span>
                <span class="meta-item">ğŸ“Š é›£æ˜“åº¦: ä¸­ç´šã€œä¸Šç´š</span>
                <span class="meta-item">ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹: 8å€‹</span>
                <span class="meta-item">ğŸ¯ å®Ÿè·µãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: 1å€‹</span>
            </div>
        </div>
    </header>

    <main class="container">

<h2>å­¦ç¿’ç›®æ¨™</h2>
<p>ã“ã®ç« ã‚’èª­ã‚€ã“ã¨ã§ã€ä»¥ä¸‹ã‚’ç¿’å¾—ã§ãã¾ã™ï¼š</p>
<ul>
<li>âœ… ã‚½ãƒ¼ã‚·ãƒ£ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã§ã®å½±éŸ¿åŠ›ä¼æ’­ã¨æƒ…å ±æ‹¡æ•£ã‚’åˆ†æã§ãã‚‹</li>
<li>âœ… çŸ¥è­˜ã‚°ãƒ©ãƒ•ã¨ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’æ§‹ç¯‰ã§ãã‚‹</li>
<li>âœ… ç”Ÿç‰©å­¦çš„ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’è§£æã—ã€ãƒ‘ã‚¹ã‚¦ã‚§ã‚¤ã‚’ç‰¹å®šã§ãã‚‹</li>
<li>âœ… ã‚°ãƒ©ãƒ•ãƒ™ãƒ¼ã‚¹ã®æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ ã‚’å®Ÿè£…ã§ãã‚‹</li>
<li>âœ… å®Ÿè·µçš„ãªãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆ†æãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’è¨­è¨ˆãƒ»å®Ÿè¡Œã§ãã‚‹</li>
</ul>

<hr>

<h2>5.1 ã‚½ãƒ¼ã‚·ãƒ£ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆ†æ</h2>

<h3>å½±éŸ¿åŠ›ä¼æ’­ãƒ¢ãƒ‡ãƒ«</h3>

<p><strong>å½±éŸ¿åŠ›ä¼æ’­ï¼ˆInfluence Propagationï¼‰</strong>ã¯ã€ã‚½ãƒ¼ã‚·ãƒ£ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ä¸Šã§æƒ…å ±ã‚„è¡Œå‹•ãŒã©ã®ã‚ˆã†ã«åºƒãŒã‚‹ã‹ã‚’ç ”ç©¶ã™ã‚‹åˆ†é‡ã§ã™ã€‚</p>

<h4>Linear Threshold Modelï¼ˆç·šå½¢é–¾å€¤ãƒ¢ãƒ‡ãƒ«ï¼‰</h4>

<p>å„ãƒãƒ¼ãƒ‰ã«ã¯é–¾å€¤ãŒã‚ã‚Šã€å½±éŸ¿ã‚’å—ã‘ãŸéš£æ¥ãƒãƒ¼ãƒ‰ã®å‰²åˆãŒé–¾å€¤ã‚’è¶…ãˆã‚‹ã¨æ´»æ€§åŒ–ã•ã‚Œã¾ã™ã€‚</p>

<pre><code class="language-python">import networkx as nx
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.animation import FuncAnimation

def linear_threshold_model(G, seed_nodes, thresholds=None, iterations=20):
    """
    Linear Threshold Modelã«ã‚ˆã‚‹å½±éŸ¿åŠ›ä¼æ’­ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³

    Parameters:
    -----------
    G : NetworkX graph
        ã‚½ãƒ¼ã‚·ãƒ£ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯
    seed_nodes : list
        åˆæœŸã®å½±éŸ¿ã‚’å—ã‘ãŸãƒãƒ¼ãƒ‰ï¼ˆã‚·ãƒ¼ãƒ‰ï¼‰
    thresholds : dict
        å„ãƒãƒ¼ãƒ‰ã®é–¾å€¤ï¼ˆNoneã®å ´åˆã¯ãƒ©ãƒ³ãƒ€ãƒ ï¼‰
    iterations : int
        ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®æœ€å¤§ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ•°

    Returns:
    --------
    history : list
        å„ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§ã®æ´»æ€§åŒ–ãƒãƒ¼ãƒ‰é›†åˆ
    """
    # é–¾å€¤ã®åˆæœŸåŒ–
    if thresholds is None:
        thresholds = {node: np.random.uniform(0.3, 0.7) for node in G.nodes()}

    # åˆæœŸçŠ¶æ…‹
    active = set(seed_nodes)
    history = [active.copy()]

    for iteration in range(iterations):
        new_active = set()

        for node in G.nodes():
            if node in active:
                continue

            # éš£æ¥ãƒãƒ¼ãƒ‰ã‹ã‚‰ã®å½±éŸ¿ã‚’è¨ˆç®—
            neighbors = list(G.neighbors(node))
            if len(neighbors) == 0:
                continue

            active_neighbors = sum(1 for n in neighbors if n in active)
            influence = active_neighbors / len(neighbors)

            # é–¾å€¤ã‚’è¶…ãˆãŸã‚‰æ´»æ€§åŒ–
            if influence >= thresholds[node]:
                new_active.add(node)

        if len(new_active) == 0:
            break

        active.update(new_active)
        history.append(active.copy())

    return history

# ã‚µãƒ³ãƒ—ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ä½œæˆ
np.random.seed(42)
G = nx.watts_strogatz_graph(50, 6, 0.3)

# ã‚·ãƒ¼ãƒ‰ãƒãƒ¼ãƒ‰ã®é¸æŠï¼ˆä¸­å¿ƒæ€§ã®é«˜ã„ãƒãƒ¼ãƒ‰ï¼‰
centrality = nx.degree_centrality(G)
seed_nodes = sorted(centrality, key=centrality.get, reverse=True)[:3]

# ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
history = linear_threshold_model(G, seed_nodes)

print("=== Linear Threshold Model ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ ===")
print(f"ã‚·ãƒ¼ãƒ‰ãƒãƒ¼ãƒ‰æ•°: {len(seed_nodes)}")
print(f"ç·ãƒãƒ¼ãƒ‰æ•°: {G.number_of_nodes()}")
print(f"å½±éŸ¿æ‹¡æ•£ã®ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ•°: {len(history)}")
print(f"\nå„ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§ã®æ´»æ€§åŒ–ãƒãƒ¼ãƒ‰æ•°:")
for i, active_set in enumerate(history):
    print(f"  ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ {i}: {len(active_set)}ãƒãƒ¼ãƒ‰ ({len(active_set)/G.number_of_nodes()*100:.1f}%)")

# å¯è¦–åŒ–
fig, axes = plt.subplots(2, 3, figsize=(15, 10))
pos = nx.spring_layout(G, seed=42)

snapshots = [0, 1, 2, 3, 4, len(history)-1]
for idx, (ax, snap_idx) in enumerate(zip(axes.flat, snapshots)):
    if snap_idx >= len(history):
        snap_idx = len(history) - 1

    active_nodes = history[snap_idx]
    node_colors = ['red' if n in active_nodes else 'lightblue' for n in G.nodes()]

    nx.draw(G, pos, node_color=node_colors, node_size=100,
            edge_color='gray', alpha=0.6, ax=ax)
    ax.set_title(f'ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ {snap_idx}\næ´»æ€§åŒ–: {len(active_nodes)}ãƒãƒ¼ãƒ‰',
                 fontsize=12)

plt.tight_layout()
plt.show()
</code></pre>

<h4>Independent Cascade Modelï¼ˆç‹¬ç«‹ã‚«ã‚¹ã‚±ãƒ¼ãƒ‰ãƒ¢ãƒ‡ãƒ«ï¼‰</h4>

<p>æ´»æ€§åŒ–ã•ã‚ŒãŸãƒãƒ¼ãƒ‰ã¯ã€å„éš£æ¥ãƒãƒ¼ãƒ‰ã‚’ç¢ºç‡çš„ã«æ´»æ€§åŒ–ã—ã‚ˆã†ã¨è©¦ã¿ã¾ã™ã€‚</p>

<pre><code class="language-python">def independent_cascade_model(G, seed_nodes, prob=0.1, iterations=20):
    """
    Independent Cascade Modelã«ã‚ˆã‚‹å½±éŸ¿åŠ›ä¼æ’­ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³

    Parameters:
    -----------
    G : NetworkX graph
        ã‚½ãƒ¼ã‚·ãƒ£ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯
    seed_nodes : list
        åˆæœŸã®å½±éŸ¿ã‚’å—ã‘ãŸãƒãƒ¼ãƒ‰
    prob : float
        å„ã‚¨ãƒƒã‚¸ã§ã®æ´»æ€§åŒ–ç¢ºç‡
    iterations : int
        æœ€å¤§ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ•°

    Returns:
    --------
    history : list
        å„ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§ã®æ´»æ€§åŒ–ãƒãƒ¼ãƒ‰é›†åˆ
    """
    active = set(seed_nodes)
    newly_active = set(seed_nodes)
    history = [active.copy()]

    for iteration in range(iterations):
        next_active = set()

        for node in newly_active:
            for neighbor in G.neighbors(node):
                if neighbor not in active:
                    # ç¢ºç‡çš„ã«æ´»æ€§åŒ–
                    if np.random.random() < prob:
                        next_active.add(neighbor)

        if len(next_active) == 0:
            break

        active.update(next_active)
        newly_active = next_active
        history.append(active.copy())

    return history

# ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œï¼ˆè¤‡æ•°å›ã®å¹³å‡ï¼‰
num_simulations = 100
all_spreads = []

for _ in range(num_simulations):
    history = independent_cascade_model(G, seed_nodes, prob=0.15)
    all_spreads.append(len(history[-1]))

print("\n=== Independent Cascade Model ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ ===")
print(f"ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å›æ•°: {num_simulations}")
print(f"å½±éŸ¿æ‹¡æ•£ã®çµ±è¨ˆ:")
print(f"  å¹³å‡: {np.mean(all_spreads):.2f}ãƒãƒ¼ãƒ‰ ({np.mean(all_spreads)/G.number_of_nodes()*100:.1f}%)")
print(f"  æ¨™æº–åå·®: {np.std(all_spreads):.2f}")
print(f"  æœ€å°: {np.min(all_spreads)}ãƒãƒ¼ãƒ‰")
print(f"  æœ€å¤§: {np.max(all_spreads)}ãƒãƒ¼ãƒ‰")

# åˆ†å¸ƒã®å¯è¦–åŒ–
plt.figure(figsize=(10, 6))
plt.hist(all_spreads, bins=20, alpha=0.7, edgecolor='black')
plt.axvline(np.mean(all_spreads), color='red', linestyle='--',
            linewidth=2, label=f'å¹³å‡: {np.mean(all_spreads):.2f}')
plt.xlabel('å½±éŸ¿ã‚’å—ã‘ãŸãƒãƒ¼ãƒ‰æ•°', fontsize=12)
plt.ylabel('é »åº¦', fontsize=12)
plt.title('Independent Cascade Model: å½±éŸ¿æ‹¡æ•£ã®åˆ†å¸ƒ', fontsize=14)
plt.legend()
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()
</code></pre>

<h3>ã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚µãƒ¼ç‰¹å®š</h3>

<p>åŠ¹æœçš„ãªæƒ…å ±æ‹¡æ•£ã®ãŸã‚ã€å½±éŸ¿åŠ›ã®é«˜ã„ãƒãƒ¼ãƒ‰ï¼ˆã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚µãƒ¼ï¼‰ã‚’ç‰¹å®šã—ã¾ã™ã€‚</p>

<pre><code class="language-python">def identify_influencers(G, k=5, method='degree'):
    """
    ã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚µãƒ¼ã®ç‰¹å®š

    Parameters:
    -----------
    G : NetworkX graph
        ã‚½ãƒ¼ã‚·ãƒ£ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯
    k : int
        ç‰¹å®šã™ã‚‹ã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚µãƒ¼ã®æ•°
    method : str
        ä½¿ç”¨ã™ã‚‹ä¸­å¿ƒæ€§æŒ‡æ¨™ ('degree', 'betweenness', 'closeness', 'pagerank')

    Returns:
    --------
    influencers : list
        ä¸Šä½kãƒãƒ¼ãƒ‰ã®ãƒªã‚¹ãƒˆ
    scores : dict
        å„ãƒãƒ¼ãƒ‰ã®ã‚¹ã‚³ã‚¢
    """
    if method == 'degree':
        scores = nx.degree_centrality(G)
    elif method == 'betweenness':
        scores = nx.betweenness_centrality(G)
    elif method == 'closeness':
        scores = nx.closeness_centrality(G)
    elif method == 'pagerank':
        scores = nx.pagerank(G)
    else:
        raise ValueError(f"Unknown method: {method}")

    influencers = sorted(scores, key=scores.get, reverse=True)[:k]
    return influencers, scores

# å®Ÿéš›ã®ã‚½ãƒ¼ã‚·ãƒ£ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã§å®Ÿé¨“ï¼ˆKarate Clubãƒ‡ãƒ¼ã‚¿ï¼‰
G_karate = nx.karate_club_graph()

# ç•°ãªã‚‹æ–¹æ³•ã§ã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚µãƒ¼ã‚’ç‰¹å®š
methods = ['degree', 'betweenness', 'closeness', 'pagerank']
k = 5

print("\n=== ã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚µãƒ¼ç‰¹å®šã®æ¯”è¼ƒ ===")
print(f"ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯: Karate Club ({G_karate.number_of_nodes()}ãƒãƒ¼ãƒ‰)")
print(f"ä¸Šä½{k}ã®ã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚µãƒ¼ã‚’ç‰¹å®š:\n")

fig, axes = plt.subplots(2, 2, figsize=(14, 14))
pos = nx.spring_layout(G_karate, seed=42)

for ax, method in zip(axes.flat, methods):
    influencers, scores = identify_influencers(G_karate, k=k, method=method)

    print(f"{method.capitalize()}:")
    for i, node in enumerate(influencers):
        print(f"  {i+1}. ãƒãƒ¼ãƒ‰ {node}: ã‚¹ã‚³ã‚¢ = {scores[node]:.4f}")
    print()

    # å¯è¦–åŒ–
    node_colors = ['red' if n in influencers else 'lightblue' for n in G_karate.nodes()]
    node_sizes = [scores[n] * 2000 for n in G_karate.nodes()]

    nx.draw(G_karate, pos, node_color=node_colors, node_size=node_sizes,
            edge_color='gray', alpha=0.6, with_labels=True, ax=ax)
    ax.set_title(f'{method.capitalize()} Centrality\n(èµ¤ = ä¸Šä½{k}ã®ã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚µãƒ¼)',
                 fontsize=12)

plt.tight_layout()
plt.show()

# å„æ–¹æ³•ã§ã®å½±éŸ¿æ‹¡æ•£ã‚’æ¯”è¼ƒ
print("\n=== å„ã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚µãƒ¼é¸æŠæ–¹æ³•ã®åŠ¹æœæ¯”è¼ƒ ===")
results = {}

for method in methods:
    influencers, _ = identify_influencers(G_karate, k=3, method=method)

    # 100å›ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã—ã¦å¹³å‡
    spreads = []
    for _ in range(100):
        history = independent_cascade_model(G_karate, influencers, prob=0.2)
        spreads.append(len(history[-1]))

    results[method] = {
        'mean': np.mean(spreads),
        'std': np.std(spreads)
    }

    print(f"{method.capitalize()}:")
    print(f"  å¹³å‡å½±éŸ¿ãƒãƒ¼ãƒ‰æ•°: {results[method]['mean']:.2f} Â± {results[method]['std']:.2f}")
    print(f"  ã‚«ãƒãƒ¬ãƒƒã‚¸: {results[method]['mean']/G_karate.number_of_nodes()*100:.1f}%")

# çµæœã®å¯è¦–åŒ–
plt.figure(figsize=(10, 6))
methods_list = list(results.keys())
means = [results[m]['mean'] for m in methods_list]
stds = [results[m]['std'] for m in methods_list]

plt.bar(methods_list, means, yerr=stds, alpha=0.7, capsize=5, edgecolor='black')
plt.xlabel('ä¸­å¿ƒæ€§æŒ‡æ¨™', fontsize=12)
plt.ylabel('å¹³å‡å½±éŸ¿ãƒãƒ¼ãƒ‰æ•°', fontsize=12)
plt.title('ã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚µãƒ¼é¸æŠæ–¹æ³•ã®åŠ¹æœæ¯”è¼ƒ', fontsize=14)
plt.grid(True, alpha=0.3, axis='y')
plt.tight_layout()
plt.show()
</code></pre>

<hr>

<h2>5.2 çŸ¥è­˜ã‚°ãƒ©ãƒ•ã¨ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯</h2>

<h3>çŸ¥è­˜ã‚°ãƒ©ãƒ•ã®æ§‹ç¯‰</h3>

<p><strong>çŸ¥è­˜ã‚°ãƒ©ãƒ•ï¼ˆKnowledge Graphï¼‰</strong>ã¯ã€ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã¨ãã®é–¢ä¿‚ã‚’è¡¨ç¾ã™ã‚‹ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã§ã™ã€‚</p>

<pre><code class="language-python">import networkx as nx
import matplotlib.pyplot as plt

class KnowledgeGraph:
    """çŸ¥è­˜ã‚°ãƒ©ãƒ•ã®æ§‹ç¯‰ã¨ç®¡ç†"""

    def __init__(self):
        self.G = nx.DiGraph()

    def add_triple(self, subject, predicate, obj):
        """
        ãƒˆãƒªãƒ—ãƒ«ï¼ˆä¸»èª-è¿°èª-ç›®çš„èªï¼‰ã‚’è¿½åŠ 

        Parameters:
        -----------
        subject : str
            ä¸»èªï¼ˆã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ï¼‰
        predicate : str
            è¿°èªï¼ˆé–¢ä¿‚ï¼‰
        obj : str
            ç›®çš„èªï¼ˆã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã¾ãŸã¯å€¤ï¼‰
        """
        self.G.add_edge(subject, obj, relation=predicate)

    def query_relations(self, entity):
        """ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã«é–¢é€£ã™ã‚‹å…¨ã¦ã®é–¢ä¿‚ã‚’å–å¾—"""
        outgoing = [(entity, self.G[entity][neighbor]['relation'], neighbor)
                    for neighbor in self.G.successors(entity)]
        incoming = [(source, self.G[source][entity]['relation'], entity)
                    for source in self.G.predecessors(entity)]
        return {'outgoing': outgoing, 'incoming': incoming}

    def find_path(self, start, end, max_length=3):
        """2ã¤ã®ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£é–“ã®ãƒ‘ã‚¹ã‚’æ¤œç´¢"""
        try:
            paths = list(nx.all_simple_paths(self.G, start, end, cutoff=max_length))
            return paths
        except nx.NetworkXNoPath:
            return []

    def visualize(self, figsize=(12, 8)):
        """çŸ¥è­˜ã‚°ãƒ©ãƒ•ã®å¯è¦–åŒ–"""
        plt.figure(figsize=figsize)
        pos = nx.spring_layout(self.G, k=2, seed=42)

        # ãƒãƒ¼ãƒ‰æç”»
        nx.draw_networkx_nodes(self.G, pos, node_color='lightblue',
                               node_size=2000, alpha=0.9)

        # ã‚¨ãƒƒã‚¸æç”»
        nx.draw_networkx_edges(self.G, pos, edge_color='gray',
                               arrows=True, arrowsize=20, alpha=0.6,
                               connectionstyle='arc3,rad=0.1')

        # ãƒ©ãƒ™ãƒ«æç”»
        nx.draw_networkx_labels(self.G, pos, font_size=10, font_weight='bold')

        # ã‚¨ãƒƒã‚¸ãƒ©ãƒ™ãƒ«ï¼ˆé–¢ä¿‚ï¼‰æç”»
        edge_labels = nx.get_edge_attributes(self.G, 'relation')
        nx.draw_networkx_edge_labels(self.G, pos, edge_labels, font_size=8)

        plt.title('Knowledge Graph', fontsize=14, fontweight='bold')
        plt.axis('off')
        plt.tight_layout()
        plt.show()

# æ˜ ç”»ã«é–¢ã™ã‚‹çŸ¥è­˜ã‚°ãƒ©ãƒ•ã®æ§‹ç¯‰
kg = KnowledgeGraph()

# ãƒˆãƒªãƒ—ãƒ«ã®è¿½åŠ 
triples = [
    # æ˜ ç”»ã¨ã‚¸ãƒ£ãƒ³ãƒ«
    ('The Matrix', 'genre', 'Sci-Fi'),
    ('The Matrix', 'genre', 'Action'),
    ('Inception', 'genre', 'Sci-Fi'),
    ('Inception', 'genre', 'Thriller'),

    # ç›£ç£
    ('The Matrix', 'directed_by', 'Wachowski'),
    ('Inception', 'directed_by', 'Nolan'),
    ('Interstellar', 'directed_by', 'Nolan'),

    # ä¿³å„ª
    ('The Matrix', 'starring', 'Keanu Reeves'),
    ('Inception', 'starring', 'Leonardo DiCaprio'),
    ('Interstellar', 'starring', 'Matthew McConaughey'),

    # å¹´ä»£
    ('The Matrix', 'released_in', '1999'),
    ('Inception', 'released_in', '2010'),
    ('Interstellar', 'released_in', '2014'),
]

for subject, predicate, obj in triples:
    kg.add_triple(subject, predicate, obj)

print("=== çŸ¥è­˜ã‚°ãƒ©ãƒ•ã®æ§‹ç¯‰ ===")
print(f"ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£æ•°: {kg.G.number_of_nodes()}")
print(f"é–¢ä¿‚æ•°: {kg.G.number_of_edges()}")

# ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã®ã‚¯ã‚¨ãƒª
print("\n=== 'Inception'ã«é–¢ã™ã‚‹é–¢ä¿‚ ===")
relations = kg.query_relations('Inception')
print("Outgoing relations:")
for s, p, o in relations['outgoing']:
    print(f"  {s} --[{p}]--> {o}")

# ãƒ‘ã‚¹æ¤œç´¢
print("\n=== 'The Matrix'ã¨'Interstellar'ã®é–¢é€£æ€§ ===")
paths = kg.find_path('The Matrix', 'Interstellar')
if paths:
    print(f"{len(paths)}å€‹ã®ãƒ‘ã‚¹ã‚’ç™ºè¦‹:")
    for i, path in enumerate(paths):
        print(f"  ãƒ‘ã‚¹ {i+1}: {' -> '.join(path)}")
else:
    print("ç›´æ¥çš„ãªãƒ‘ã‚¹ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")

# å¯è¦–åŒ–
kg.visualize()
</code></pre>

<h3>ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£é–¢ä¿‚æŠ½å‡ºã¨Neo4jåŸºç¤</h3>

<p>å®Ÿéš›ã®ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã¨é–¢ä¿‚ã‚’æŠ½å‡ºã—ã€ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«æ ¼ç´ã™ã‚‹ä¾‹ã§ã™ã€‚</p>

<pre><code class="language-python">import spacy
import networkx as nx
import matplotlib.pyplot as plt

# ç°¡æ˜“çš„ãªã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£é–¢ä¿‚æŠ½å‡ºï¼ˆå®Ÿéš›ã¯spaCyãªã©ã®NLPãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ç”¨ï¼‰
def extract_triples_simple(text):
    """
    ç°¡æ˜“çš„ãªãƒˆãƒªãƒ—ãƒ«æŠ½å‡º
    ï¼ˆå®Ÿéš›ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã¯spaCyã‚„BERTãƒ™ãƒ¼ã‚¹ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ï¼‰
    """
    # ã‚µãƒ³ãƒ—ãƒ«ã¨ã—ã¦æ‰‹å‹•ã§ãƒˆãƒªãƒ—ãƒ«ã‚’å®šç¾©
    triples = [
        ('Albert Einstein', 'born_in', 'Germany'),
        ('Albert Einstein', 'developed', 'Theory of Relativity'),
        ('Albert Einstein', 'won', 'Nobel Prize'),
        ('Nobel Prize', 'awarded_for', 'Physics'),
        ('Theory of Relativity', 'is_type_of', 'Physics Theory'),
    ]
    return triples

# Neo4jé¢¨ã®Cypherã‚¯ã‚¨ãƒªã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
class SimpleGraphDB:
    """ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ç°¡æ˜“å®Ÿè£…ï¼ˆNeo4jé¢¨ï¼‰"""

    def __init__(self):
        self.kg = KnowledgeGraph()

    def create_node(self, label, properties=None):
        """ãƒãƒ¼ãƒ‰ä½œæˆ"""
        node_id = f"{label}_{len(self.kg.G.nodes())}"
        self.kg.G.add_node(node_id, label=label, **properties if properties else {})
        return node_id

    def create_relationship(self, node1, node2, rel_type):
        """é–¢ä¿‚ä½œæˆ"""
        self.kg.add_triple(node1, rel_type, node2)

    def match(self, pattern):
        """
        ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°ï¼ˆç°¡æ˜“ç‰ˆï¼‰
        ä¾‹: MATCH (a)-[r]->(b) WHERE a.label = 'Person'
        """
        results = []
        for u, v, data in self.kg.G.edges(data=True):
            u_label = self.kg.G.nodes[u].get('label', '')
            v_label = self.kg.G.nodes[v].get('label', '')

            if pattern.get('source_label') and u_label != pattern['source_label']:
                continue
            if pattern.get('relation') and data['relation'] != pattern['relation']:
                continue
            if pattern.get('target_label') and v_label != pattern['target_label']:
                continue

            results.append((u, data['relation'], v))

        return results

# ã‚°ãƒ©ãƒ•DBã®ä½¿ç”¨ä¾‹
print("\n=== ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ä½¿ç”¨ä¾‹ ===")
db = SimpleGraphDB()

# ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ãƒˆãƒªãƒ—ãƒ«æŠ½å‡º
text = "Albert Einstein was born in Germany and developed the Theory of Relativity."
triples = extract_triples_simple(text)

# ã‚°ãƒ©ãƒ•DBã«æ ¼ç´
for subject, predicate, obj in triples:
    db.create_relationship(subject, predicate, obj)

print(f"æ ¼ç´ã•ã‚ŒãŸãƒˆãƒªãƒ—ãƒ«æ•°: {len(triples)}")
print("\nå…¨ãƒˆãƒªãƒ—ãƒ«:")
for s, p, o in triples:
    print(f"  ({s}) -[{p}]-> ({o})")

# ã‚¯ã‚¨ãƒªå®Ÿè¡Œ
print("\n=== ã‚¯ã‚¨ãƒª: 'Albert Einstein'ã®å…¨é–¢ä¿‚ ===")
pattern = {'source_label': None}  # å…¨ã¦ã®é–¢ä¿‚
einstein_relations = db.kg.query_relations('Albert Einstein')
for s, p, o in einstein_relations['outgoing']:
    print(f"  {s} -[{p}]-> {o}")

# å¯è¦–åŒ–
db.kg.visualize(figsize=(14, 10))
</code></pre>

<blockquote>
<p><strong>å®Ÿè·µã®ãƒ’ãƒ³ãƒˆ</strong>: æœ¬ç•ªç’°å¢ƒã§ã¯ã€Neo4jã€Amazon Neptuneã€ã¾ãŸã¯TigerGraphãªã©ã®å°‚ç”¨ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã§ã€å¤§è¦æ¨¡ãªçŸ¥è­˜ã‚°ãƒ©ãƒ•ã®åŠ¹ç‡çš„ãªç®¡ç†ã¨ã‚¯ã‚¨ãƒªãŒå¯èƒ½ã«ãªã‚Šã¾ã™ã€‚</p>
</blockquote>

<hr>

<h2>5.3 ç”Ÿç‰©å­¦çš„ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯</h2>

<h3>ã‚¿ãƒ³ãƒ‘ã‚¯è³ªç›¸äº’ä½œç”¨ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼ˆPPIï¼‰</h3>

<p><strong>ã‚¿ãƒ³ãƒ‘ã‚¯è³ªç›¸äº’ä½œç”¨ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼ˆProtein-Protein Interaction Networkï¼‰</strong>ã¯ã€ç´°èƒå†…ã®ã‚¿ãƒ³ãƒ‘ã‚¯è³ªé–“ã®ç›¸äº’ä½œç”¨ã‚’è¡¨ç¾ã—ã¾ã™ã€‚</p>

<pre><code class="language-python">import networkx as nx
import numpy as np
import matplotlib.pyplot as plt
from collections import defaultdict

def create_ppi_network(n_proteins=100, interaction_prob=0.05):
    """
    ã‚¿ãƒ³ãƒ‘ã‚¯è³ªç›¸äº’ä½œç”¨ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³

    Parameters:
    -----------
    n_proteins : int
        ã‚¿ãƒ³ãƒ‘ã‚¯è³ªã®æ•°
    interaction_prob : float
        ç›¸äº’ä½œç”¨ã®ç¢ºç‡

    Returns:
    --------
    G : NetworkX graph
        PPIãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯
    """
    G = nx.erdos_renyi_graph(n_proteins, interaction_prob)

    # ã‚¿ãƒ³ãƒ‘ã‚¯è³ªã®æ©Ÿèƒ½ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«å‰²ã‚Šå½“ã¦
    functions = ['Metabolism', 'Signaling', 'Transport', 'Regulation', 'Structure']
    for node in G.nodes():
        G.nodes[node]['function'] = np.random.choice(functions)
        G.nodes[node]['expression'] = np.random.uniform(0, 10)  # ç™ºç¾ãƒ¬ãƒ™ãƒ«

    return G

def identify_protein_complexes(G, min_size=3):
    """
    ã‚¿ãƒ³ãƒ‘ã‚¯è³ªè¤‡åˆä½“ã®ç‰¹å®šï¼ˆã‚¯ãƒªãƒ¼ã‚¯æ¤œå‡ºï¼‰

    Parameters:
    -----------
    G : NetworkX graph
        PPIãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯
    min_size : int
        æœ€å°ã®è¤‡åˆä½“ã‚µã‚¤ã‚º

    Returns:
    --------
    complexes : list
        æ¤œå‡ºã•ã‚ŒãŸã‚¿ãƒ³ãƒ‘ã‚¯è³ªè¤‡åˆä½“
    """
    cliques = list(nx.find_cliques(G))
    complexes = [c for c in cliques if len(c) >= min_size]
    return complexes

def analyze_hub_proteins(G, top_k=10):
    """
    ãƒãƒ–ã‚¿ãƒ³ãƒ‘ã‚¯è³ªï¼ˆé«˜æ¬¡æ•°ãƒãƒ¼ãƒ‰ï¼‰ã®åˆ†æ

    Parameters:
    -----------
    G : NetworkX graph
        PPIãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯
    top_k : int
        ä¸Šä½kå€‹ã®ãƒãƒ–

    Returns:
    --------
    hubs : list
        ãƒãƒ–ã‚¿ãƒ³ãƒ‘ã‚¯è³ªã®ãƒªã‚¹ãƒˆ
    """
    degrees = dict(G.degree())
    hubs = sorted(degrees, key=degrees.get, reverse=True)[:top_k]
    return hubs, degrees

# PPIãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®ä½œæˆ
np.random.seed(42)
ppi = create_ppi_network(n_proteins=80, interaction_prob=0.08)

print("=== ã‚¿ãƒ³ãƒ‘ã‚¯è³ªç›¸äº’ä½œç”¨ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼ˆPPIï¼‰===")
print(f"ã‚¿ãƒ³ãƒ‘ã‚¯è³ªæ•°: {ppi.number_of_nodes()}")
print(f"ç›¸äº’ä½œç”¨æ•°: {ppi.number_of_edges()}")
print(f"å¹³å‡æ¬¡æ•°: {np.mean([d for _, d in ppi.degree()]):.2f}")

# ã‚¿ãƒ³ãƒ‘ã‚¯è³ªè¤‡åˆä½“ã®ç‰¹å®š
complexes = identify_protein_complexes(ppi, min_size=3)
print(f"\næ¤œå‡ºã•ã‚ŒãŸã‚¿ãƒ³ãƒ‘ã‚¯è³ªè¤‡åˆä½“: {len(complexes)}å€‹")
print(f"è¤‡åˆä½“ã‚µã‚¤ã‚ºåˆ†å¸ƒ:")
complex_sizes = [len(c) for c in complexes]
for size in sorted(set(complex_sizes)):
    count = complex_sizes.count(size)
    print(f"  ã‚µã‚¤ã‚º {size}: {count}å€‹")

# ãƒãƒ–ã‚¿ãƒ³ãƒ‘ã‚¯è³ªã®åˆ†æ
hubs, degrees = analyze_hub_proteins(ppi, top_k=5)
print(f"\nä¸Šä½5ã¤ã®ãƒãƒ–ã‚¿ãƒ³ãƒ‘ã‚¯è³ª:")
for i, hub in enumerate(hubs):
    func = ppi.nodes[hub]['function']
    deg = degrees[hub]
    print(f"  {i+1}. ã‚¿ãƒ³ãƒ‘ã‚¯è³ª {hub}: æ¬¡æ•°={deg}, æ©Ÿèƒ½={func}")

# å¯è¦–åŒ–
fig, axes = plt.subplots(1, 2, figsize=(16, 7))

# å…¨ä½“ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯
pos = nx.spring_layout(ppi, seed=42)
node_colors = [ppi.nodes[n]['expression'] for n in ppi.nodes()]
node_sizes = [degrees[n] * 30 for n in ppi.nodes()]

nx.draw(ppi, pos, node_color=node_colors, node_size=node_sizes,
        cmap='YlOrRd', edge_color='gray', alpha=0.7, ax=axes[0])
axes[0].set_title('PPI Network (è‰² = ç™ºç¾ãƒ¬ãƒ™ãƒ«, ã‚µã‚¤ã‚º = æ¬¡æ•°)', fontsize=12)

# æœ€å¤§ã®ã‚¿ãƒ³ãƒ‘ã‚¯è³ªè¤‡åˆä½“ã‚’å¼·èª¿
if complexes:
    largest_complex = max(complexes, key=len)
    subgraph = ppi.subgraph(largest_complex)
    sub_pos = nx.spring_layout(subgraph, seed=42)

    nx.draw(subgraph, sub_pos, node_color='lightcoral', node_size=500,
            edge_color='black', width=2, with_labels=True, ax=axes[1])
    axes[1].set_title(f'æœ€å¤§ã®ã‚¿ãƒ³ãƒ‘ã‚¯è³ªè¤‡åˆä½“ (ã‚µã‚¤ã‚º: {len(largest_complex)})',
                      fontsize=12)

plt.tight_layout()
plt.show()
</code></pre>

<h3>éºä¼å­åˆ¶å¾¡ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã¨ãƒ‘ã‚¹ã‚¦ã‚§ã‚¤è§£æ</h3>

<p>éºä¼å­åˆ¶å¾¡ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã¯ã€éºä¼å­é–“ã®åˆ¶å¾¡é–¢ä¿‚ã‚’è¡¨ç¾ã™ã‚‹æœ‰å‘ã‚°ãƒ©ãƒ•ã§ã™ã€‚</p>

<pre><code class="language-python">def create_gene_regulatory_network(n_genes=50, regulation_prob=0.1):
    """
    éºä¼å­åˆ¶å¾¡ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®ç”Ÿæˆ

    Parameters:
    -----------
    n_genes : int
        éºä¼å­ã®æ•°
    regulation_prob : float
        åˆ¶å¾¡é–¢ä¿‚ã®ç¢ºç‡

    Returns:
    --------
    G : NetworkX DiGraph
        éºä¼å­åˆ¶å¾¡ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯
    """
    G = nx.DiGraph()

    # éºä¼å­ãƒãƒ¼ãƒ‰ã®è¿½åŠ 
    for i in range(n_genes):
        G.add_node(f'Gene_{i}',
                   expression=np.random.uniform(0, 1),
                   type=np.random.choice(['TF', 'target']))  # TF = è»¢å†™å› å­

    # åˆ¶å¾¡é–¢ä¿‚ã®è¿½åŠ 
    for i in range(n_genes):
        for j in range(n_genes):
            if i != j and np.random.random() < regulation_prob:
                # activation (+1) or repression (-1)
                regulation_type = np.random.choice([1, -1])
                G.add_edge(f'Gene_{i}', f'Gene_{j}',
                          weight=regulation_type)

    return G

def find_regulatory_motifs(G):
    """
    åˆ¶å¾¡ãƒ¢ãƒãƒ¼ãƒ•ï¼ˆãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ«ãƒ¼ãƒ—ãªã©ï¼‰ã®æ¤œå‡º

    Parameters:
    -----------
    G : NetworkX DiGraph
        éºä¼å­åˆ¶å¾¡ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯

    Returns:
    --------
    motifs : dict
        æ¤œå‡ºã•ã‚ŒãŸãƒ¢ãƒãƒ¼ãƒ•
    """
    motifs = {
        'feedback_loops': [],
        'feedforward_loops': [],
        'cascades': []
    }

    # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ«ãƒ¼ãƒ—ï¼ˆã‚µã‚¤ã‚¯ãƒ«ï¼‰
    try:
        cycles = list(nx.simple_cycles(G))
        motifs['feedback_loops'] = [c for c in cycles if len(c) <= 4]
    except:
        pass

    # ã‚«ã‚¹ã‚±ãƒ¼ãƒ‰ï¼ˆé•·ã„ãƒ‘ã‚¹ï¼‰
    for node in G.nodes():
        descendants = nx.descendants(G, node)
        if len(descendants) >= 3:
            motifs['cascades'].append((node, len(descendants)))

    return motifs

def pathway_enrichment_analysis(G, target_genes):
    """
    ãƒ‘ã‚¹ã‚¦ã‚§ã‚¤æ¿ƒç¸®è§£æï¼ˆç°¡æ˜“ç‰ˆï¼‰

    Parameters:
    -----------
    G : NetworkX DiGraph
        éºä¼å­åˆ¶å¾¡ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯
    target_genes : list
        æ³¨ç›®ã—ã¦ã„ã‚‹éºä¼å­ã®ãƒªã‚¹ãƒˆ

    Returns:
    --------
    enriched_regulators : list
        æ¿ƒç¸®ã•ã‚ŒãŸä¸Šæµåˆ¶å¾¡å› å­
    """
    # å„éºä¼å­ã‹ã‚‰æ¨™çš„éºä¼å­ã¸ã®åˆ°é”å¯èƒ½æ€§
    regulators = defaultdict(int)

    for target in target_genes:
        if target in G:
            # ä¸Šæµã®å…¨ã¦ã®åˆ¶å¾¡å› å­ã‚’å–å¾—
            ancestors = nx.ancestors(G, target)
            for anc in ancestors:
                regulators[anc] += 1

    # ã‚¹ã‚³ã‚¢ã§ã‚½ãƒ¼ãƒˆ
    enriched = sorted(regulators.items(), key=lambda x: x[1], reverse=True)
    return enriched

# éºä¼å­åˆ¶å¾¡ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®ä½œæˆ
np.random.seed(42)
grn = create_gene_regulatory_network(n_genes=40, regulation_prob=0.12)

print("\n=== éºä¼å­åˆ¶å¾¡ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼ˆGRNï¼‰===")
print(f"éºä¼å­æ•°: {grn.number_of_nodes()}")
print(f"åˆ¶å¾¡é–¢ä¿‚æ•°: {grn.number_of_edges()}")

# è»¢å†™å› å­ã®ç‰¹å®š
tfs = [n for n in grn.nodes() if grn.nodes[n]['type'] == 'TF']
print(f"è»¢å†™å› å­æ•°: {len(tfs)}")

# ãƒ¢ãƒãƒ¼ãƒ•æ¤œå‡º
motifs = find_regulatory_motifs(grn)
print(f"\n=== åˆ¶å¾¡ãƒ¢ãƒãƒ¼ãƒ• ===")
print(f"ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ«ãƒ¼ãƒ—: {len(motifs['feedback_loops'])}å€‹")
if motifs['feedback_loops']:
    print(f"  ä¾‹: {motifs['feedback_loops'][0]}")
print(f"åˆ¶å¾¡ã‚«ã‚¹ã‚±ãƒ¼ãƒ‰: {len(motifs['cascades'])}å€‹")
if motifs['cascades']:
    top_cascade = max(motifs['cascades'], key=lambda x: x[1])
    print(f"  æœ€å¤§ã‚«ã‚¹ã‚±ãƒ¼ãƒ‰: {top_cascade[0]} â†’ {top_cascade[1]}å€‹ã®ä¸‹æµéºä¼å­")

# ãƒ‘ã‚¹ã‚¦ã‚§ã‚¤æ¿ƒç¸®è§£æ
target_genes = list(grn.nodes())[:10]  # æœ€åˆã®10éºä¼å­ã‚’æ¨™çš„ã¨ã™ã‚‹
enriched = pathway_enrichment_analysis(grn, target_genes)

print(f"\n=== ãƒ‘ã‚¹ã‚¦ã‚§ã‚¤æ¿ƒç¸®è§£æ ===")
print(f"æ¨™çš„éºä¼å­æ•°: {len(target_genes)}")
print(f"ä¸Šä½5ã¤ã®æ¿ƒç¸®ã•ã‚ŒãŸåˆ¶å¾¡å› å­:")
for i, (reg, score) in enumerate(enriched[:5]):
    print(f"  {i+1}. {reg}: ã‚¹ã‚³ã‚¢={score}")

# å¯è¦–åŒ–
fig, axes = plt.subplots(1, 2, figsize=(16, 7))

# å…¨ä½“ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯
pos = nx.spring_layout(grn, seed=42, k=0.5)
node_colors = ['red' if grn.nodes[n]['type'] == 'TF' else 'lightblue'
               for n in grn.nodes()]

# ã‚¨ãƒƒã‚¸ã®è‰²ï¼ˆæ´»æ€§åŒ–=ç·‘ã€æŠ‘åˆ¶=èµ¤ï¼‰
edge_colors = ['green' if grn[u][v]['weight'] > 0 else 'red'
               for u, v in grn.edges()]

nx.draw(grn, pos, node_color=node_colors, edge_color=edge_colors,
        node_size=300, alpha=0.7, arrows=True, arrowsize=10, ax=axes[0])
axes[0].set_title('éºä¼å­åˆ¶å¾¡ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯\n(èµ¤=è»¢å†™å› å­, ç·‘=æ´»æ€§åŒ–, èµ¤=æŠ‘åˆ¶)',
                  fontsize=12)

# ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ«ãƒ¼ãƒ—ã®å¼·èª¿è¡¨ç¤º
if motifs['feedback_loops']:
    loop = motifs['feedback_loops'][0]
    subgraph = grn.subgraph(loop)
    sub_pos = nx.circular_layout(subgraph)

    edge_colors_sub = ['green' if subgraph[u][v]['weight'] > 0 else 'red'
                       for u, v in subgraph.edges()]

    nx.draw(subgraph, sub_pos, node_color='yellow', edge_color=edge_colors_sub,
            node_size=800, width=2, with_labels=True, arrows=True,
            arrowsize=20, ax=axes[1])
    axes[1].set_title(f'ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ«ãƒ¼ãƒ—ã®ä¾‹\n({len(loop)}éºä¼å­)',
                      fontsize=12)

plt.tight_layout()
plt.show()
</code></pre>

<hr>

<h2>5.4 æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ ã¸ã®å¿œç”¨</h2>

<h3>ã‚°ãƒ©ãƒ•ãƒ™ãƒ¼ã‚¹å”èª¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°</h3>

<p>ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ã‚¢ã‚¤ãƒ†ãƒ ã‚’äºŒéƒ¨ã‚°ãƒ©ãƒ•ã¨ã—ã¦è¡¨ç¾ã—ã€æ¨è–¦ã‚’è¡Œã„ã¾ã™ã€‚</p>

<pre><code class="language-python">import networkx as nx
from networkx.algorithms import bipartite
import numpy as np
import matplotlib.pyplot as plt

class GraphBasedRecommender:
    """ã‚°ãƒ©ãƒ•ãƒ™ãƒ¼ã‚¹ã®æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ """

    def __init__(self):
        self.G = nx.Graph()
        self.users = set()
        self.items = set()

    def add_interaction(self, user, item, rating=1.0):
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ã‚¢ã‚¤ãƒ†ãƒ ã®ç›¸äº’ä½œç”¨ã‚’è¿½åŠ """
        self.G.add_node(user, bipartite=0)  # ãƒ¦ãƒ¼ã‚¶ãƒ¼å´
        self.G.add_node(item, bipartite=1)  # ã‚¢ã‚¤ãƒ†ãƒ å´
        self.G.add_edge(user, item, weight=rating)
        self.users.add(user)
        self.items.add(item)

    def recommend_by_neighbors(self, user, top_k=5):
        """
        éš£æ¥ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ™ãƒ¼ã‚¹ã®æ¨è–¦

        1. ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®éš£æ¥ã‚¢ã‚¤ãƒ†ãƒ ã‚’å–å¾—
        2. ãã‚Œã‚‰ã®ã‚¢ã‚¤ãƒ†ãƒ ã«æ¥ç¶šã—ã¦ã„ã‚‹ä»–ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’è¦‹ã¤ã‘ã‚‹
        3. ãã‚Œã‚‰ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒå¥½ã‚€ã‚¢ã‚¤ãƒ†ãƒ ã‚’æ¨è–¦
        """
        if user not in self.G:
            return []

        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæ—¢ã«è©•ä¾¡ã—ãŸã‚¢ã‚¤ãƒ†ãƒ 
        user_items = set(self.G.neighbors(user))

        # å€™è£œã‚¢ã‚¤ãƒ†ãƒ ã®ã‚¹ã‚³ã‚¢è¨ˆç®—
        candidate_scores = {}

        for item in user_items:
            # ã“ã®ã‚¢ã‚¤ãƒ†ãƒ ã‚’å¥½ã‚€ä»–ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼
            for other_user in self.G.neighbors(item):
                if other_user == user:
                    continue

                # ä»–ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒå¥½ã‚€ã‚¢ã‚¤ãƒ†ãƒ 
                for candidate in self.G.neighbors(other_user):
                    if candidate not in user_items:
                        # ã‚¹ã‚³ã‚¢ = çµŒè·¯ã®é‡ã¿ã®ç©
                        score = (self.G[user][item]['weight'] *
                                self.G[other_user][candidate]['weight'])
                        candidate_scores[candidate] = candidate_scores.get(candidate, 0) + score

        # ã‚¹ã‚³ã‚¢ã§ã‚½ãƒ¼ãƒˆ
        recommendations = sorted(candidate_scores.items(),
                                key=lambda x: x[1], reverse=True)[:top_k]
        return recommendations

    def recommend_by_random_walk(self, user, walk_length=10, n_walks=100, top_k=5):
        """
        ãƒ©ãƒ³ãƒ€ãƒ ã‚¦ã‚©ãƒ¼ã‚¯ãƒ™ãƒ¼ã‚¹ã®æ¨è–¦

        Parameters:
        -----------
        user : str
            å¯¾è±¡ãƒ¦ãƒ¼ã‚¶ãƒ¼
        walk_length : int
            å„ã‚¦ã‚©ãƒ¼ã‚¯ã®é•·ã•
        n_walks : int
            å®Ÿè¡Œã™ã‚‹ã‚¦ã‚©ãƒ¼ã‚¯æ•°
        top_k : int
            æ¨è–¦ã™ã‚‹ã‚¢ã‚¤ãƒ†ãƒ æ•°
        """
        if user not in self.G:
            return []

        user_items = set(self.G.neighbors(user))
        visit_counts = {}

        for _ in range(n_walks):
            current = user
            for step in range(walk_length):
                neighbors = list(self.G.neighbors(current))
                if not neighbors:
                    break

                # é‡ã¿ä»˜ããƒ©ãƒ³ãƒ€ãƒ é¸æŠ
                weights = [self.G[current][n]['weight'] for n in neighbors]
                weights = np.array(weights) / sum(weights)
                current = np.random.choice(neighbors, p=weights)

                # ã‚¢ã‚¤ãƒ†ãƒ ã®è¨ªå•ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
                if current in self.items and current not in user_items:
                    visit_counts[current] = visit_counts.get(current, 0) + 1

        # è¨ªå•å›æ•°ã§ã‚½ãƒ¼ãƒˆ
        recommendations = sorted(visit_counts.items(),
                                key=lambda x: x[1], reverse=True)[:top_k]
        return recommendations

# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã®ä½œæˆï¼ˆMovieLensé¢¨ï¼‰
np.random.seed(42)
recommender = GraphBasedRecommender()

# ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ã‚¢ã‚¤ãƒ†ãƒ 
users = [f'User_{i}' for i in range(20)]
items = [f'Movie_{i}' for i in range(15)]

# ãƒ©ãƒ³ãƒ€ãƒ ãªè©•ä¾¡ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
for user in users:
    n_ratings = np.random.randint(3, 8)
    rated_items = np.random.choice(items, n_ratings, replace=False)
    for item in rated_items:
        rating = np.random.uniform(3, 5)
        recommender.add_interaction(user, item, rating)

print("=== ã‚°ãƒ©ãƒ•ãƒ™ãƒ¼ã‚¹æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ  ===")
print(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°: {len(recommender.users)}")
print(f"ã‚¢ã‚¤ãƒ†ãƒ æ•°: {len(recommender.items)}")
print(f"è©•ä¾¡æ•°: {recommender.G.number_of_edges()}")

# æ¨è–¦ã®å®Ÿè¡Œ
test_user = 'User_0'
print(f"\n=== '{test_user}'ã¸ã®æ¨è–¦ ===")

# æ—¢ã«è©•ä¾¡ã—ãŸã‚¢ã‚¤ãƒ†ãƒ 
user_items = list(recommender.G.neighbors(test_user))
print(f"æ—¢ã«è©•ä¾¡ã—ãŸã‚¢ã‚¤ãƒ†ãƒ : {user_items}")

# éš£æ¥ãƒ™ãƒ¼ã‚¹ã®æ¨è–¦
neighbor_recs = recommender.recommend_by_neighbors(test_user, top_k=5)
print(f"\néš£æ¥ãƒ™ãƒ¼ã‚¹ã®æ¨è–¦:")
for i, (item, score) in enumerate(neighbor_recs):
    print(f"  {i+1}. {item}: ã‚¹ã‚³ã‚¢={score:.3f}")

# ãƒ©ãƒ³ãƒ€ãƒ ã‚¦ã‚©ãƒ¼ã‚¯ãƒ™ãƒ¼ã‚¹ã®æ¨è–¦
rw_recs = recommender.recommend_by_random_walk(test_user, top_k=5)
print(f"\nãƒ©ãƒ³ãƒ€ãƒ ã‚¦ã‚©ãƒ¼ã‚¯ãƒ™ãƒ¼ã‚¹ã®æ¨è–¦:")
for i, (item, count) in enumerate(rw_recs):
    print(f"  {i+1}. {item}: è¨ªå•å›æ•°={count}")

# å¯è¦–åŒ–
plt.figure(figsize=(14, 10))
pos = nx.spring_layout(recommender.G, seed=42, k=2)

# ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ã‚¢ã‚¤ãƒ†ãƒ ã§è‰²åˆ†ã‘
node_colors = ['lightblue' if n in recommender.users else 'lightcoral'
               for n in recommender.G.nodes()]

# å¯¾è±¡ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’å¼·èª¿
node_colors = ['yellow' if n == test_user else c
               for n, c in zip(recommender.G.nodes(), node_colors)]

nx.draw(recommender.G, pos, node_color=node_colors, node_size=300,
        alpha=0.7, edge_color='gray', with_labels=True, font_size=8)
plt.title('äºŒéƒ¨ã‚°ãƒ©ãƒ•æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ \n(é’=ãƒ¦ãƒ¼ã‚¶ãƒ¼, èµ¤=ã‚¢ã‚¤ãƒ†ãƒ , é»„=å¯¾è±¡ãƒ¦ãƒ¼ã‚¶ãƒ¼)',
          fontsize=14)
plt.tight_layout()
plt.show()
</code></pre>

<h3>ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åŸ‹ã‚è¾¼ã¿ï¼ˆNode2Vecï¼‰ã«ã‚ˆã‚‹æ¨è–¦</h3>

<p>Node2Vecã‚’ä½¿ã£ã¦ãƒãƒ¼ãƒ‰ã‚’ãƒ™ã‚¯ãƒˆãƒ«ç©ºé–“ã«åŸ‹ã‚è¾¼ã¿ã€é¡ä¼¼åº¦ãƒ™ãƒ¼ã‚¹ã®æ¨è–¦ã‚’è¡Œã„ã¾ã™ã€‚</p>

<pre><code class="language-python">from sklearn.metrics.pairwise import cosine_similarity
import numpy as np

def simple_node2vec(G, dimensions=64, walk_length=10, num_walks=80, p=1, q=1):
    """
    Node2Vecã®ç°¡æ˜“å®Ÿè£…ï¼ˆæ¦‚å¿µå®Ÿè¨¼ç”¨ï¼‰

    Parameters:
    -----------
    G : NetworkX graph
        ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯
    dimensions : int
        åŸ‹ã‚è¾¼ã¿ã®æ¬¡å…ƒæ•°
    walk_length : int
        ãƒ©ãƒ³ãƒ€ãƒ ã‚¦ã‚©ãƒ¼ã‚¯ã®é•·ã•
    num_walks : int
        å„ãƒãƒ¼ãƒ‰ã‹ã‚‰ã®ã‚¦ã‚©ãƒ¼ã‚¯æ•°
    p : float
        Return parameter
    q : float
        In-out parameter

    Returns:
    --------
    embeddings : dict
        ãƒãƒ¼ãƒ‰ã®åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«
    """
    # ãƒ©ãƒ³ãƒ€ãƒ ã‚¦ã‚©ãƒ¼ã‚¯ã®ç”Ÿæˆ
    walks = []
    nodes = list(G.nodes())

    for _ in range(num_walks):
        np.random.shuffle(nodes)
        for node in nodes:
            walk = [node]
            for _ in range(walk_length - 1):
                current = walk[-1]
                neighbors = list(G.neighbors(current))
                if neighbors:
                    walk.append(np.random.choice(neighbors))
                else:
                    break
            walks.append(walk)

    # ç°¡æ˜“çš„ãªåŸ‹ã‚è¾¼ã¿ï¼ˆå®Ÿéš›ã¯Skip-gramãªã©ã‚’ä½¿ç”¨ï¼‰
    # ã“ã“ã§ã¯å…±èµ·è¡Œåˆ—ãƒ™ãƒ¼ã‚¹ã®ç°¡æ˜“å®Ÿè£…
    node_to_id = {node: i for i, node in enumerate(G.nodes())}
    cooccurrence = np.zeros((len(nodes), len(nodes)))

    for walk in walks:
        for i, node in enumerate(walk):
            for j in range(max(0, i-2), min(len(walk), i+3)):
                if i != j:
                    cooccurrence[node_to_id[node]][node_to_id[walk[j]]] += 1

    # SVDã§æ¬¡å…ƒå‰Šæ¸›
    from sklearn.decomposition import TruncatedSVD
    svd = TruncatedSVD(n_components=min(dimensions, len(nodes)-1))
    embeddings_matrix = svd.fit_transform(cooccurrence)

    embeddings = {node: embeddings_matrix[node_to_id[node]]
                  for node in G.nodes()}

    return embeddings

# Node2Vecã®é©ç”¨
print("\n=== Node2VecåŸ‹ã‚è¾¼ã¿ ===")
embeddings = simple_node2vec(recommender.G, dimensions=32, walk_length=10, num_walks=50)
print(f"åŸ‹ã‚è¾¼ã¿æ¬¡å…ƒ: {len(list(embeddings.values())[0])}")

# åŸ‹ã‚è¾¼ã¿ãƒ™ãƒ¼ã‚¹ã®æ¨è–¦
def recommend_by_embedding(embeddings, user, items, user_items, top_k=5):
    """åŸ‹ã‚è¾¼ã¿ãƒ™ãƒ¼ã‚¹ã®æ¨è–¦"""
    user_emb = embeddings[user].reshape(1, -1)

    # æœªè©•ä¾¡ã‚¢ã‚¤ãƒ†ãƒ ã®ã¿ã‚’å€™è£œã¨ã™ã‚‹
    candidate_items = [item for item in items if item not in user_items]

    if not candidate_items:
        return []

    # é¡ä¼¼åº¦è¨ˆç®—
    similarities = {}
    for item in candidate_items:
        item_emb = embeddings[item].reshape(1, -1)
        sim = cosine_similarity(user_emb, item_emb)[0][0]
        similarities[item] = sim

    # ã‚¹ã‚³ã‚¢ã§ã‚½ãƒ¼ãƒˆ
    recommendations = sorted(similarities.items(),
                            key=lambda x: x[1], reverse=True)[:top_k]
    return recommendations

# æ¨è–¦å®Ÿè¡Œ
user_items_set = set(recommender.G.neighbors(test_user))
emb_recs = recommend_by_embedding(embeddings, test_user,
                                  recommender.items, user_items_set, top_k=5)

print(f"\n=== Node2VecåŸ‹ã‚è¾¼ã¿ãƒ™ãƒ¼ã‚¹ã®æ¨è–¦ ===")
for i, (item, sim) in enumerate(emb_recs):
    print(f"  {i+1}. {item}: é¡ä¼¼åº¦={sim:.3f}")

# åŸ‹ã‚è¾¼ã¿ã®å¯è¦–åŒ–ï¼ˆt-SNEï¼‰
from sklearn.manifold import TSNE

print("\n=== åŸ‹ã‚è¾¼ã¿ã®å¯è¦–åŒ– ===")
node_list = list(embeddings.keys())
embedding_matrix = np.array([embeddings[n] for n in node_list])

tsne = TSNE(n_components=2, random_state=42)
embeddings_2d = tsne.fit_transform(embedding_matrix)

plt.figure(figsize=(12, 8))
user_indices = [i for i, n in enumerate(node_list) if n in recommender.users]
item_indices = [i for i, n in enumerate(node_list) if n in recommender.items]

plt.scatter(embeddings_2d[user_indices, 0], embeddings_2d[user_indices, 1],
            c='blue', label='Users', alpha=0.6, s=100)
plt.scatter(embeddings_2d[item_indices, 0], embeddings_2d[item_indices, 1],
            c='red', label='Items', alpha=0.6, s=100)

# å¯¾è±¡ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’å¼·èª¿
test_user_idx = node_list.index(test_user)
plt.scatter(embeddings_2d[test_user_idx, 0], embeddings_2d[test_user_idx, 1],
            c='yellow', s=300, marker='*', edgecolors='black', linewidths=2,
            label='Target User')

plt.xlabel('Dimension 1', fontsize=12)
plt.ylabel('Dimension 2', fontsize=12)
plt.title('Node2Vec Embeddings (t-SNEå¯è¦–åŒ–)', fontsize=14)
plt.legend()
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()
</code></pre>

<hr>

<h2>5.5 å®Ÿè·µãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: ç·åˆãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆ†æ</h2>

<h3>ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: Twitterãƒ©ã‚¤ã‚¯ãªã‚½ãƒ¼ã‚·ãƒ£ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®åˆ†æ</h3>

<p>å®Ÿè·µçš„ãªãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¨ã—ã¦ã€ã‚½ãƒ¼ã‚·ãƒ£ãƒ«ãƒ¡ãƒ‡ã‚£ã‚¢ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®åŒ…æ‹¬çš„ãªåˆ†æã‚’è¡Œã„ã¾ã™ã€‚</p>

<h4>ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆè¨­è¨ˆ</h4>

<p><strong>ç›®æ¨™</strong>ï¼šã‚½ãƒ¼ã‚·ãƒ£ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’åˆ†æã—ã€ä»¥ä¸‹ã‚’å®Ÿç¾ã™ã‚‹</p>
<ol>
<li>ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£æ¤œå‡ºã¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°</li>
<li>ã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚µãƒ¼ã®ç‰¹å®š</li>
<li>æƒ…å ±æ‹¡æ•£ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³</li>
<li>æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ ã®æ§‹ç¯‰</li>
<li>ãƒ¬ãƒãƒ¼ãƒˆä½œæˆã¨ã‚¤ãƒ³ã‚µã‚¤ãƒˆæŠ½å‡º</li>
</ol>

<pre><code class="language-python">import networkx as nx
import numpy as np
import matplotlib.pyplot as plt
from collections import Counter, defaultdict
import pandas as pd

class SocialNetworkAnalyzer:
    """ã‚½ãƒ¼ã‚·ãƒ£ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®ç·åˆåˆ†æã‚·ã‚¹ãƒ†ãƒ """

    def __init__(self, name="Social Network"):
        self.name = name
        self.G = nx.DiGraph()  # æœ‰å‘ã‚°ãƒ©ãƒ•ï¼ˆãƒ•ã‚©ãƒ­ãƒ¼é–¢ä¿‚ï¼‰
        self.metrics = {}
        self.communities = None
        self.influencers = None

    def load_network(self, edges, user_attributes=None):
        """
        ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿

        Parameters:
        -----------
        edges : list of tuples
            (follower, followee) ã®ãƒªã‚¹ãƒˆ
        user_attributes : dict
            ãƒ¦ãƒ¼ã‚¶ãƒ¼å±æ€§ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        """
        self.G.add_edges_from(edges)

        if user_attributes:
            for user, attrs in user_attributes.items():
                if user in self.G:
                    for key, value in attrs.items():
                        self.G.nodes[user][key] = value

        print(f"âœ“ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯èª­ã¿è¾¼ã¿å®Œäº†")
        print(f"  ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°: {self.G.number_of_nodes()}")
        print(f"  ãƒ•ã‚©ãƒ­ãƒ¼é–¢ä¿‚æ•°: {self.G.number_of_edges()}")

    def compute_basic_metrics(self):
        """åŸºæœ¬çš„ãªãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æŒ‡æ¨™ã‚’è¨ˆç®—"""
        # æ¬¡æ•°ï¼ˆãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼æ•°ãƒ»ãƒ•ã‚©ãƒ­ãƒ¼æ•°ï¼‰
        in_degree = dict(self.G.in_degree())  # ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼æ•°
        out_degree = dict(self.G.out_degree())  # ãƒ•ã‚©ãƒ­ãƒ¼æ•°

        # ä¸­å¿ƒæ€§æŒ‡æ¨™
        pagerank = nx.pagerank(self.G)

        # å¼±é€£çµæˆåˆ†
        undirected = self.G.to_undirected()
        n_components = nx.number_connected_components(undirected)

        # ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ä¿‚æ•°
        clustering = nx.average_clustering(undirected)

        self.metrics = {
            'in_degree': in_degree,
            'out_degree': out_degree,
            'pagerank': pagerank,
            'n_components': n_components,
            'avg_clustering': clustering,
            'density': nx.density(self.G)
        }

        print(f"\nâœ“ åŸºæœ¬æŒ‡æ¨™è¨ˆç®—å®Œäº†")
        print(f"  é€£çµæˆåˆ†æ•°: {n_components}")
        print(f"  å¹³å‡ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ä¿‚æ•°: {clustering:.3f}")
        print(f"  å¯†åº¦: {self.metrics['density']:.4f}")
        print(f"  å¹³å‡ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼æ•°: {np.mean(list(in_degree.values())):.2f}")
        print(f"  å¹³å‡ãƒ•ã‚©ãƒ­ãƒ¼æ•°: {np.mean(list(out_degree.values())):.2f}")

    def detect_communities(self, method='louvain'):
        """ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£æ¤œå‡º"""
        undirected = self.G.to_undirected()

        if method == 'louvain':
            # Louvainã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ï¼ˆNetworkXã®æ¨™æº–æ©Ÿèƒ½ï¼‰
            import networkx.algorithms.community as nx_comm
            self.communities = list(nx_comm.greedy_modularity_communities(undirected))

        print(f"\nâœ“ ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£æ¤œå‡ºå®Œäº†")
        print(f"  æ¤œå‡ºã•ã‚ŒãŸã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£æ•°: {len(self.communities)}")
        print(f"  ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã‚µã‚¤ã‚ºåˆ†å¸ƒ:")
        sizes = sorted([len(c) for c in self.communities], reverse=True)
        for i, size in enumerate(sizes[:5]):
            print(f"    ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ {i+1}: {size}ãƒ¦ãƒ¼ã‚¶ãƒ¼")

    def identify_influencers(self, top_k=10):
        """ã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚µãƒ¼ã®ç‰¹å®š"""
        # è¤‡æ•°ã®æŒ‡æ¨™ã‚’çµ„ã¿åˆã‚ã›ã¦ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°
        scores = {}

        for user in self.G.nodes():
            score = (
                0.4 * self.metrics['in_degree'][user] +  # ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼æ•°
                0.3 * self.metrics['pagerank'][user] * 1000 +  # PageRank
                0.3 * self.metrics['out_degree'][user]  # ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆ
            )
            scores[user] = score

        self.influencers = sorted(scores, key=scores.get, reverse=True)[:top_k]

        print(f"\nâœ“ ã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚µãƒ¼ç‰¹å®šå®Œäº†")
        print(f"  ä¸Šä½{top_k}ã®ã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚µãƒ¼:")
        for i, user in enumerate(self.influencers):
            print(f"    {i+1}. {user}:")
            print(f"       ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼: {self.metrics['in_degree'][user]}")
            print(f"       ãƒ•ã‚©ãƒ­ãƒ¼: {self.metrics['out_degree'][user]}")
            print(f"       PageRank: {self.metrics['pagerank'][user]:.4f}")

    def simulate_information_diffusion(self, seed_users, prob=0.1, iterations=10):
        """æƒ…å ±æ‹¡æ•£ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""
        active = set(seed_users)
        history = [len(active)]

        for _ in range(iterations):
            new_active = set()
            for user in active:
                for follower in self.G.predecessors(user):  # ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼
                    if follower not in active and np.random.random() < prob:
                        new_active.add(follower)

            if not new_active:
                break

            active.update(new_active)
            history.append(len(active))

        print(f"\nâœ“ æƒ…å ±æ‹¡æ•£ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Œäº†")
        print(f"  åˆæœŸãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°: {len(seed_users)}")
        print(f"  æœ€çµ‚åˆ°é”æ•°: {history[-1]}ãƒ¦ãƒ¼ã‚¶ãƒ¼ ({history[-1]/self.G.number_of_nodes()*100:.1f}%)")

        return history

    def generate_report(self):
        """åˆ†æãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ"""
        report = f"""
{'='*60}
ã‚½ãƒ¼ã‚·ãƒ£ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆ†æãƒ¬ãƒãƒ¼ãƒˆ: {self.name}
{'='*60}

1. ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¦‚è¦
   - ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°: {self.G.number_of_nodes():,}
   - ãƒ•ã‚©ãƒ­ãƒ¼é–¢ä¿‚æ•°: {self.G.number_of_edges():,}
   - ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å¯†åº¦: {self.metrics['density']:.4f}
   - é€£çµæˆåˆ†æ•°: {self.metrics['n_components']}

2. ãƒ¦ãƒ¼ã‚¶ãƒ¼è¡Œå‹•
   - å¹³å‡ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼æ•°: {np.mean(list(self.metrics['in_degree'].values())):.2f}
   - å¹³å‡ãƒ•ã‚©ãƒ­ãƒ¼æ•°: {np.mean(list(self.metrics['out_degree'].values())):.2f}
   - å¹³å‡ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ä¿‚æ•°: {self.metrics['avg_clustering']:.3f}

3. ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£æ§‹é€ 
   - ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£æ•°: {len(self.communities) if self.communities else 'N/A'}
   - æœ€å¤§ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã‚µã‚¤ã‚º: {max(len(c) for c in self.communities) if self.communities else 'N/A'}

4. ã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚µãƒ¼
   - ä¸Šä½ã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚µãƒ¼: {', '.join(self.influencers[:5]) if self.influencers else 'N/A'}

5. æ¨å¥¨äº‹é …
   - ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°å¯¾è±¡: ãƒˆãƒƒãƒ—5ã®ã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚µãƒ¼ã‚’æ´»ç”¨
   - ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£æˆ¦ç•¥: å„ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã«ç‰¹åŒ–ã—ãŸã‚³ãƒ³ãƒ†ãƒ³ãƒ„ä½œæˆ
   - ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆå‘ä¸Š: ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ä¿‚æ•°ã®é«˜ã„ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’ãƒãƒ–ã¨ã—ã¦æ´»ç”¨

{'='*60}
        """
        return report

# ã‚µãƒ³ãƒ—ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®ç”Ÿæˆã¨ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå®Ÿè¡Œ
print("=== ã‚½ãƒ¼ã‚·ãƒ£ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆ†æãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ ===\n")

# ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆï¼ˆå®Ÿéš›ã¯Twitter APIãªã©ã‹ã‚‰å–å¾—ï¼‰
np.random.seed(42)
n_users = 100

# ã‚¹ã‚±ãƒ¼ãƒ«ãƒ•ãƒªãƒ¼ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼ˆç¾å®Ÿçš„ãªã‚½ãƒ¼ã‚·ãƒ£ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼‰
G_sample = nx.scale_free_graph(n_users, seed=42)
edges = [(u, v) for u, v in G_sample.edges()]

# ãƒ¦ãƒ¼ã‚¶ãƒ¼å±æ€§
user_attributes = {
    i: {
        'join_date': f'2020-{np.random.randint(1, 13):02d}',
        'posts': np.random.randint(10, 1000),
        'active': np.random.choice([True, False], p=[0.7, 0.3])
    }
    for i in range(n_users)
}

# åˆ†æå®Ÿè¡Œ
analyzer = SocialNetworkAnalyzer(name="Twitter-like Network")
analyzer.load_network(edges, user_attributes)
analyzer.compute_basic_metrics()
analyzer.detect_communities()
analyzer.identify_influencers(top_k=10)

# æƒ…å ±æ‹¡æ•£ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆãƒˆãƒƒãƒ—ã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚µãƒ¼ã‹ã‚‰é–‹å§‹ï¼‰
diffusion_history = analyzer.simulate_information_diffusion(
    seed_users=analyzer.influencers[:3],
    prob=0.15,
    iterations=10
)

# ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
report = analyzer.generate_report()
print(report)

# å¯è¦–åŒ–
fig = plt.figure(figsize=(16, 12))
gs = fig.add_gridspec(3, 2, hspace=0.3, wspace=0.3)

# 1. ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å…¨ä½“å›³
ax1 = fig.add_subplot(gs[0, :])
pos = nx.spring_layout(analyzer.G, seed=42, k=0.5)
node_colors = [analyzer.metrics['pagerank'][n] * 1000 for n in analyzer.G.nodes()]
node_sizes = [analyzer.metrics['in_degree'][n] * 20 + 50 for n in analyzer.G.nodes()]
nx.draw(analyzer.G, pos, node_color=node_colors, node_size=node_sizes,
        cmap='YlOrRd', edge_color='gray', alpha=0.6, arrows=False, ax=ax1)
ax1.set_title('ã‚½ãƒ¼ã‚·ãƒ£ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å…¨ä½“å›³\n(è‰²=PageRank, ã‚µã‚¤ã‚º=ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼æ•°)',
              fontsize=14, fontweight='bold')

# 2. æ¬¡æ•°åˆ†å¸ƒ
ax2 = fig.add_subplot(gs[1, 0])
in_degrees = list(analyzer.metrics['in_degree'].values())
ax2.hist(in_degrees, bins=30, alpha=0.7, edgecolor='black')
ax2.set_xlabel('ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼æ•°', fontsize=11)
ax2.set_ylabel('ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°', fontsize=11)
ax2.set_title('ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼æ•°ã®åˆ†å¸ƒ', fontsize=12)
ax2.grid(True, alpha=0.3)

# 3. ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£å¯è¦–åŒ–
ax3 = fig.add_subplot(gs[1, 1])
if analyzer.communities:
    community_map = {}
    for i, comm in enumerate(analyzer.communities):
        for node in comm:
            community_map[node] = i

    comm_colors = [community_map.get(n, 0) for n in analyzer.G.nodes()]
    nx.draw(analyzer.G, pos, node_color=comm_colors, node_size=100,
            cmap='tab10', edge_color='gray', alpha=0.6, arrows=False, ax=ax3)
    ax3.set_title(f'ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£æ§‹é€  ({len(analyzer.communities)}ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£)',
                  fontsize=12)

# 4. æƒ…å ±æ‹¡æ•£
ax4 = fig.add_subplot(gs[2, 0])
ax4.plot(range(len(diffusion_history)), diffusion_history,
         marker='o', linewidth=2, markersize=8)
ax4.set_xlabel('ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³', fontsize=11)
ax4.set_ylabel('åˆ°é”ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°', fontsize=11)
ax4.set_title('æƒ…å ±æ‹¡æ•£ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³', fontsize=12)
ax4.grid(True, alpha=0.3)

# 5. ã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚µãƒ¼æ¯”è¼ƒ
ax5 = fig.add_subplot(gs[2, 1])
influencer_data = {
    'User': analyzer.influencers[:5],
    'Followers': [analyzer.metrics['in_degree'][u] for u in analyzer.influencers[:5]],
}
df_inf = pd.DataFrame(influencer_data)
ax5.barh(df_inf['User'], df_inf['Followers'], alpha=0.7, edgecolor='black')
ax5.set_xlabel('ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼æ•°', fontsize=11)
ax5.set_title('ãƒˆãƒƒãƒ—5ã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚µãƒ¼', fontsize=12)
ax5.grid(True, alpha=0.3, axis='x')

plt.tight_layout()
plt.show()

print("\nâœ“ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå®Œäº†!")
print("  å¯è¦–åŒ–ã€åˆ†æãƒ¬ãƒãƒ¼ãƒˆã€ã‚¤ãƒ³ã‚µã‚¤ãƒˆã‚’ç”Ÿæˆã—ã¾ã—ãŸã€‚")
</code></pre>

<h3>ã‚¹ãƒˆãƒ¼ãƒªãƒ¼ãƒ†ãƒªãƒ³ã‚°ã¨ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ</h3>

<blockquote>
<p><strong>å®Ÿè·µã®ãƒ’ãƒ³ãƒˆ</strong>: åˆ†æçµæœã‚’åŠ¹æœçš„ã«ä¼ãˆã‚‹ãŸã‚ã®ã‚¹ãƒˆãƒ¼ãƒªãƒ¼ãƒ†ãƒªãƒ³ã‚°</p>

<ol>
<li><strong>èƒŒæ™¯ã¨ç›®çš„</strong>: ãªãœã“ã®åˆ†æãŒå¿…è¦ã‹æ˜ç¢ºã«ã™ã‚‹</li>
<li><strong>ãƒ‡ãƒ¼ã‚¿ã®ç‰¹å¾´</strong>: ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®åŸºæœ¬çµ±è¨ˆã‚’æç¤º</li>
<li><strong>ä¸»è¦ãªç™ºè¦‹</strong>: é‡è¦ãªã‚¤ãƒ³ã‚µã‚¤ãƒˆã‚’3-5å€‹ã«çµã‚‹</li>
<li><strong>å¯è¦–åŒ–</strong>: ç›´æ„Ÿçš„ã§åˆ†ã‹ã‚Šã‚„ã™ã„ã‚°ãƒ©ãƒ•ã‚’ä½¿ç”¨</li>
<li><strong>æ¨å¥¨äº‹é …</strong>: å…·ä½“çš„ãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³ã‚’æç¤º</li>
<li><strong>æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—</strong>: ã•ã‚‰ãªã‚‹åˆ†æã®æ–¹å‘æ€§ã‚’ç¤ºã™</li>
</ol>
</blockquote>

<hr>

<h2>æœ¬ç« ã®ã¾ã¨ã‚</h2>

<h3>å­¦ã‚“ã ã“ã¨</h3>

<ol>
<li><p><strong>ã‚½ãƒ¼ã‚·ãƒ£ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆ†æ</strong></p>
<ul>
<li>Linear Thresholdãƒ¢ãƒ‡ãƒ«ã¨Independent Cascadeãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹å½±éŸ¿åŠ›ä¼æ’­</li>
<li>è¤‡æ•°ã®ä¸­å¿ƒæ€§æŒ‡æ¨™ã‚’ç”¨ã„ãŸã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚µãƒ¼ç‰¹å®š</li>
<li>æƒ…å ±æ‹¡æ•£ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã¨äºˆæ¸¬</li>
</ul></li>

<li><p><strong>çŸ¥è­˜ã‚°ãƒ©ãƒ•</strong></p>
<ul>
<li>ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã¨é–¢ä¿‚ã®ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ï¼ˆãƒˆãƒªãƒ—ãƒ«æ§‹é€ ï¼‰</li>
<li>ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®åŸºç¤ï¼ˆNeo4jé¢¨ã®ã‚¯ã‚¨ãƒªï¼‰</li>
<li>ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®æ§‹ç¯‰ã¨æ´»ç”¨</li>
</ul></li>

<li><p><strong>ç”Ÿç‰©å­¦çš„ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯</strong></p>
<ul>
<li>ã‚¿ãƒ³ãƒ‘ã‚¯è³ªç›¸äº’ä½œç”¨ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®è§£æ</li>
<li>éºä¼å­åˆ¶å¾¡ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã¨ãƒ¢ãƒãƒ¼ãƒ•æ¤œå‡º</li>
<li>ãƒ‘ã‚¹ã‚¦ã‚§ã‚¤æ¿ƒç¸®è§£æã®åŸºç¤</li>
</ul></li>

<li><p><strong>æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ </strong></p>
<ul>
<li>ã‚°ãƒ©ãƒ•ãƒ™ãƒ¼ã‚¹å”èª¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°</li>
<li>ãƒ©ãƒ³ãƒ€ãƒ ã‚¦ã‚©ãƒ¼ã‚¯ã‚’ç”¨ã„ãŸæ¨è–¦</li>
<li>Node2VecåŸ‹ã‚è¾¼ã¿ã«ã‚ˆã‚‹é¡ä¼¼åº¦æ¨è–¦</li>
</ul></li>

<li><p><strong>å®Ÿè·µãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ</strong></p>
<ul>
<li>åŒ…æ‹¬çš„ãªãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆ†æãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®è¨­è¨ˆ</li>
<li>è¤‡æ•°ã®åˆ†ææ‰‹æ³•ã®çµ±åˆ</li>
<li>åŠ¹æœçš„ãªãƒ¬ãƒãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã¨ã‚¹ãƒˆãƒ¼ãƒªãƒ¼ãƒ†ãƒªãƒ³ã‚°</li>
</ul></li>
</ol>

<h3>å®Ÿä¸–ç•Œã¸ã®å¿œç”¨</h3>

<table>
<thead>
<tr>
<th>åˆ†é‡</th>
<th>å¿œç”¨ä¾‹</th>
<th>ä¸»è¦æŠ€è¡“</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°</strong></td>
<td>ã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚µãƒ¼ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°ã€ãƒã‚¤ãƒ©ãƒ«æˆ¦ç•¥</td>
<td>å½±éŸ¿åŠ›ä¼æ’­ã€ä¸­å¿ƒæ€§åˆ†æ</td>
</tr>
<tr>
<td><strong>eã‚³ãƒãƒ¼ã‚¹</strong></td>
<td>å•†å“æ¨è–¦ã€ã‚¯ãƒ­ã‚¹ã‚»ãƒ«</td>
<td>ã‚°ãƒ©ãƒ•ãƒ™ãƒ¼ã‚¹æ¨è–¦ã€Node2Vec</td>
</tr>
<tr>
<td><strong>è£½è–¬</strong></td>
<td>å‰µè–¬ã€ç–¾æ‚£ãƒ¡ã‚«ãƒ‹ã‚ºãƒ è§£æ˜</td>
<td>PPIåˆ†æã€ãƒ‘ã‚¹ã‚¦ã‚§ã‚¤è§£æ</td>
</tr>
<tr>
<td><strong>é‡‘è</strong></td>
<td>ä¸æ­£æ¤œå‡ºã€ãƒªã‚¹ã‚¯åˆ†æ</td>
<td>ç•°å¸¸æ¤œå‡ºã€ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£æ¤œå‡º</td>
</tr>
<tr>
<td><strong>AI/NLP</strong></td>
<td>çŸ¥è­˜ãƒ™ãƒ¼ã‚¹æ§‹ç¯‰ã€è³ªå•å¿œç­”ã‚·ã‚¹ãƒ†ãƒ </td>
<td>çŸ¥è­˜ã‚°ãƒ©ãƒ•ã€ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢</td>
</tr>
</tbody>
</table>

<h3>æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—</h3>

<p>ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆ†æã‚’ã•ã‚‰ã«æ·±ã‚ã‚‹ãŸã‚ã«ï¼š</p>

<ul>
<li><strong>æ·±å±¤å­¦ç¿’ã¨ã®çµ±åˆ</strong>: Graph Neural Networks (GNN)ã€Graph Attention Networks (GAT)</li>
<li><strong>å‹•çš„ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯</strong>: æ™‚é–“ç™ºå±•ã™ã‚‹ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®åˆ†æ</li>
<li><strong>å¤§è¦æ¨¡ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯</strong>: åˆ†æ•£å‡¦ç†ã€è¿‘ä¼¼ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ </li>
<li><strong>å› æœæ¨è«–</strong>: ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã«ãŠã‘ã‚‹å› æœé–¢ä¿‚ã®ç‰¹å®š</li>
<li><strong>å®Ÿãƒ‡ãƒ¼ã‚¿ã§ã®å®Ÿè·µ</strong>: Kaggleã‚³ãƒ³ãƒšã€ç ”ç©¶ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ</li>
</ul>

<hr>

<h2>å‚è€ƒæ–‡çŒ®</h2>

<ol>
<li>BarabÃ¡si, A. L. (2016). <em>Network Science</em>. Cambridge University Press.</li>
<li>Newman, M. (2018). <em>Networks: An Introduction</em> (2nd ed.). Oxford University Press.</li>
<li>Easley, D., & Kleinberg, J. (2010). <em>Networks, Crowds, and Markets</em>. Cambridge University Press.</li>
<li>Hamilton, W. L. (2020). <em>Graph Representation Learning</em>. Morgan & Claypool.</li>
<li>Grover, A., & Leskovec, J. (2016). node2vec: Scalable Feature Learning for Networks. <em>KDD</em>.</li>
</ol>

<div class="navigation">
    <a href="chapter4-advanced.html" class="nav-button">â† å‰ã®ç« : é«˜åº¦ãªãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆ†æ</a>
    <a href="index.html" class="nav-button">ã‚·ãƒªãƒ¼ã‚ºç›®æ¬¡ã«æˆ»ã‚‹</a>
</div>

    </main>

    <footer>
        <p><strong>ä½œæˆè€…</strong>: AI Terakoya Content Team</p>
        <p><strong>ãƒãƒ¼ã‚¸ãƒ§ãƒ³</strong>: 1.0 | <strong>ä½œæˆæ—¥</strong>: 2025-10-23</p>
        <p><strong>ãƒ©ã‚¤ã‚»ãƒ³ã‚¹</strong>: Creative Commons BY 4.0</p>
        <p>Â© 2025 AI Terakoya. All rights reserved.</p>
    </footer>
</body>
</html>
