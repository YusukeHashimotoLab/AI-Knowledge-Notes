<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ç¬¬4ç« ï¼šã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ - AI Terakoya</title>

    <style>
        :root {
            --color-primary: #2c3e50;
            --color-primary-dark: #1a252f;
            --color-accent: #7b2cbf;
            --color-accent-light: #9d4edd;
            --color-text: #2d3748;
            --color-text-light: #4a5568;
            --color-bg: #ffffff;
            --color-bg-alt: #f7fafc;
            --color-border: #e2e8f0;
            --color-code-bg: #f8f9fa;
            --color-link: #3182ce;
            --color-link-hover: #2c5aa0;

            --spacing-xs: 0.5rem;
            --spacing-sm: 1rem;
            --spacing-md: 1.5rem;
            --spacing-lg: 2rem;
            --spacing-xl: 3rem;

            --font-body: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            --font-mono: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;

            --border-radius: 8px;
            --box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: var(--font-body);
            line-height: 1.7;
            color: var(--color-text);
            background-color: var(--color-bg);
            font-size: 16px;
        }

        header {
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            padding: var(--spacing-xl) var(--spacing-md);
            margin-bottom: var(--spacing-xl);
            box-shadow: var(--box-shadow);
        }

        .header-content {
            max-width: 900px;
            margin: 0 auto;
        }

        h1 {
            font-size: 2rem;
            font-weight: 700;
            margin-bottom: var(--spacing-sm);
            line-height: 1.2;
        }

        .subtitle {
            font-size: 1.1rem;
            opacity: 0.95;
            font-weight: 400;
            margin-bottom: var(--spacing-md);
        }

        .meta {
            display: flex;
            flex-wrap: wrap;
            gap: var(--spacing-md);
            font-size: 0.9rem;
            opacity: 0.9;
        }

        .meta-item {
            display: flex;
            align-items: center;
            gap: 0.3rem;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 0 var(--spacing-md) var(--spacing-xl);
        }

        h2 {
            font-size: 1.75rem;
            color: var(--color-primary);
            margin-top: var(--spacing-xl);
            margin-bottom: var(--spacing-md);
            padding-bottom: var(--spacing-xs);
            border-bottom: 3px solid var(--color-accent);
        }

        h3 {
            font-size: 1.4rem;
            color: var(--color-primary);
            margin-top: var(--spacing-lg);
            margin-bottom: var(--spacing-sm);
        }

        h4 {
            font-size: 1.1rem;
            color: var(--color-primary-dark);
            margin-top: var(--spacing-md);
            margin-bottom: var(--spacing-sm);
        }

        p {
            margin-bottom: var(--spacing-md);
            color: var(--color-text);
        }

        a {
            color: var(--color-link);
            text-decoration: none;
            transition: color 0.2s;
        }

        a:hover {
            color: var(--color-link-hover);
            text-decoration: underline;
        }

        ul, ol {
            margin-left: var(--spacing-lg);
            margin-bottom: var(--spacing-md);
        }

        li {
            margin-bottom: var(--spacing-xs);
            color: var(--color-text);
        }

        pre {
            background-color: var(--color-code-bg);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            overflow-x: auto;
            margin-bottom: var(--spacing-md);
            font-family: var(--font-mono);
            font-size: 0.9rem;
            line-height: 1.5;
        }

        code {
            font-family: var(--font-mono);
            font-size: 0.9em;
            background-color: var(--color-code-bg);
            padding: 0.2em 0.4em;
            border-radius: 3px;
        }

        pre code {
            background-color: transparent;
            padding: 0;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: var(--spacing-md);
            font-size: 0.95rem;
        }

        th, td {
            border: 1px solid var(--color-border);
            padding: var(--spacing-sm);
            text-align: left;
        }

        th {
            background-color: var(--color-bg-alt);
            font-weight: 600;
            color: var(--color-primary);
        }

        blockquote {
            border-left: 4px solid var(--color-accent);
            padding-left: var(--spacing-md);
            margin: var(--spacing-md) 0;
            color: var(--color-text-light);
            font-style: italic;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        .mermaid {
            text-align: center;
            margin: var(--spacing-lg) 0;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        details {
            background-color: var(--color-bg-alt);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            margin-bottom: var(--spacing-md);
        }

        summary {
            cursor: pointer;
            font-weight: 600;
            color: var(--color-primary);
            user-select: none;
            padding: var(--spacing-xs);
            margin: calc(-1 * var(--spacing-md));
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        summary:hover {
            background-color: rgba(123, 44, 191, 0.1);
        }

        details[open] summary {
            margin-bottom: var(--spacing-md);
            border-bottom: 1px solid var(--color-border);
        }

        .navigation {
            display: flex;
            justify-content: space-between;
            gap: var(--spacing-md);
            margin: var(--spacing-xl) 0;
            padding-top: var(--spacing-lg);
            border-top: 2px solid var(--color-border);
        }

        .nav-button {
            flex: 1;
            padding: var(--spacing-md);
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            border-radius: var(--border-radius);
            text-align: center;
            font-weight: 600;
            transition: transform 0.2s, box-shadow 0.2s;
            box-shadow: var(--box-shadow);
        }

        .nav-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
            text-decoration: none;
        }

        footer {
            margin-top: var(--spacing-xl);
            padding: var(--spacing-lg) var(--spacing-md);
            background-color: var(--color-bg-alt);
            border-top: 1px solid var(--color-border);
            text-align: center;
            font-size: 0.9rem;
            color: var(--color-text-light);
        }
        .disclaimer {
            max-width: 900px;
            margin: 2rem auto;
            padding: 1.5rem;
            background: #f8f9fa;
            border-left: 4px solid #6c757d;
            border-radius: 4px;
        }

        .disclaimer h3 {
            color: #495057;
            margin-bottom: 1rem;
            font-size: 1.1rem;
        }

        .disclaimer ul {
            list-style: none;
            padding-left: 0;
        }

        .disclaimer li {
            padding: 0.5rem 0;
            padding-left: 1.5rem;
            position: relative;
            font-size: 0.9rem;
            color: #6c757d;
            line-height: 1.6;
        }

        .disclaimer li::before {
            content: "âš ï¸";
            position: absolute;
            left: 0;
        }


        @media (max-width: 768px) {
            h1 {
                font-size: 1.5rem;
            }

            h2 {
                font-size: 1.4rem;
            }

            h3 {
                font-size: 1.2rem;
            }

            .meta {
                font-size: 0.85rem;
            }

            .navigation {
                flex-direction: column;
            }

            table {
                font-size: 0.85rem;
            }

            th, td {
                padding: var(--spacing-xs);
            }
        }
    </style>

    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
        mermaid.initialize({ startOnLoad: true, theme: 'default' });
    </script>

    <!-- MathJax for LaTeX equation rendering -->
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                displayMath: [['$$', '$$'], ['\\[', '\\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
                ignoreHtmlClass: 'mermaid'
            }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" async></script>
</head>
<body>
    <header>
        <div class="header-content">
            <h1>ç¬¬4ç« ï¼šã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³</h1>
            <p class="subtitle">ç”»åƒã®é ˜åŸŸåˆ†å‰² - ãƒ”ã‚¯ã‚»ãƒ«ãƒ¬ãƒ™ãƒ«ã®ç†è§£</p>
            <div class="meta">
                <span class="meta-item">ğŸ“– èª­äº†æ™‚é–“: 35-40åˆ†</span>
                <span class="meta-item">ğŸ“Š é›£æ˜“åº¦: ä¸­ç´šï½ä¸Šç´š</span>
                <span class="meta-item">ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹: 8å€‹</span>
                <span class="meta-item">ğŸ“ æ¼”ç¿’å•é¡Œ: 5å•</span>
            </div>
        </div>
    </header>

    <main class="container">

<h2>å­¦ç¿’ç›®æ¨™</h2>
<p>ã“ã®ç« ã‚’èª­ã‚€ã“ã¨ã§ã€ä»¥ä¸‹ã‚’ç¿’å¾—ã§ãã¾ã™ï¼š</p>
<ul>
<li>âœ… ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã®ç¨®é¡ã¨è©•ä¾¡æŒ‡æ¨™ã‚’ç†è§£ã™ã‚‹</li>
<li>âœ… U-Netã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¨ãã®å¿œç”¨ã‚’å®Ÿè£…ã§ãã‚‹</li>
<li>âœ… DeepLabã€PSPNetç­‰ã®é«˜åº¦ãªã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’æ´»ç”¨ã§ãã‚‹</li>
<li>âœ… Mask R-CNNã‚’ç”¨ã„ãŸInstance Segmentationã‚’å®Ÿè£…ã§ãã‚‹</li>
<li>âœ… ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã®å®Ÿè·µãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’å®Œæˆã§ãã‚‹</li>
<li>âœ… Detectron2ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ä½¿ã„ã“ãªã›ã‚‹</li>
</ul>

<hr>

<h2>4.1 ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã®ç¨®é¡</h2>

<h3>ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã¨ã¯</h3>
<p><strong>ç”»åƒã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆImage Segmentationï¼‰</strong>ã¯ã€ç”»åƒã®å„ãƒ”ã‚¯ã‚»ãƒ«ã«ã‚¯ãƒ©ã‚¹ãƒ©ãƒ™ãƒ«ã‚’å‰²ã‚Šå½“ã¦ã‚‹ã‚¿ã‚¹ã‚¯ã§ã™ã€‚ç‰©ä½“æ¤œå‡ºãŒçŸ©å½¢ã®ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã§ç‰©ä½“ã‚’ç‰¹å®šã™ã‚‹ã®ã«å¯¾ã—ã€ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã¯ãƒ”ã‚¯ã‚»ãƒ«ãƒ¬ãƒ™ãƒ«ã§æ­£ç¢ºãªå¢ƒç•Œã‚’è­˜åˆ¥ã—ã¾ã™ã€‚</p>

<blockquote>
<p>ã€Œã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã¯ã€ç”»åƒã‚’æ„å‘³ã®ã‚ã‚‹é ˜åŸŸã«åˆ†å‰²ã—ã€å„ãƒ”ã‚¯ã‚»ãƒ«ã«æ„å‘³ã‚’ä¸ãˆã‚‹æŠ€è¡“ã§ã™ã€‚ã€</p>
</blockquote>

<h3>1. Semantic Segmentationï¼ˆæ„å‘³çš„ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰</h3>

<p><strong>Semantic Segmentation</strong>ã¯ã€å„ãƒ”ã‚¯ã‚»ãƒ«ã‚’ã‚¯ãƒ©ã‚¹ã«åˆ†é¡ã—ã¾ã™ãŒã€åŒã˜ã‚¯ãƒ©ã‚¹ã®ç•°ãªã‚‹ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã¯åŒºåˆ¥ã—ã¾ã›ã‚“ã€‚</p>

<table>
<thead>
<tr>
<th>ç‰¹å¾´</th>
<th>èª¬æ˜</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>ç›®çš„</strong></td>
<td>å„ãƒ”ã‚¯ã‚»ãƒ«ã®ã‚¯ãƒ©ã‚¹åˆ†é¡</td>
</tr>
<tr>
<td><strong>å‡ºåŠ›</strong></td>
<td>ã‚¯ãƒ©ã‚¹ãƒ©ãƒ™ãƒ«ãƒãƒƒãƒ—</td>
</tr>
<tr>
<td><strong>ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒºåˆ¥</strong></td>
<td>ãªã—</td>
</tr>
<tr>
<td><strong>ç”¨é€”</strong></td>
<td>è‡ªå‹•é‹è»¢ã€åŒ»ç™‚ç”»åƒã€è¡›æ˜Ÿç”»åƒ</td>
</tr>
</tbody>
</table>

<h3>2. Instance Segmentationï¼ˆã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰</h3>

<p><strong>Instance Segmentation</strong>ã¯ã€åŒã˜ã‚¯ãƒ©ã‚¹ã®ç•°ãªã‚‹ç‰©ä½“ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’åŒºåˆ¥ã—ã¾ã™ã€‚</p>

<table>
<thead>
<tr>
<th>ç‰¹å¾´</th>
<th>èª¬æ˜</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>ç›®çš„</strong></td>
<td>å„ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®åˆ†é›¢</td>
</tr>
<tr>
<td><strong>å‡ºåŠ›</strong></td>
<td>ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã”ã¨ã®ãƒã‚¹ã‚¯</td>
</tr>
<tr>
<td><strong>ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒºåˆ¥</strong></td>
<td>ã‚ã‚Š</td>
</tr>
<tr>
<td><strong>ç”¨é€”</strong></td>
<td>ãƒ­ãƒœãƒƒãƒˆå·¥å­¦ã€ç”»åƒç·¨é›†ã€ç´°èƒã‚«ã‚¦ãƒ³ãƒˆ</td>
</tr>
</tbody>
</table>

<h3>3. Panoptic Segmentationï¼ˆå…¨æ™¯ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰</h3>

<p><strong>Panoptic Segmentation</strong>ã¯ã€Semantic Segmentationã¨Instance Segmentationã‚’çµ±åˆã—ãŸã‚¿ã‚¹ã‚¯ã§ã™ã€‚</p>

<table>
<thead>
<tr>
<th>ç‰¹å¾´</th>
<th>èª¬æ˜</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>ç›®çš„</strong></td>
<td>ã‚·ãƒ¼ãƒ³å…¨ä½“ã®å®Œå…¨ãªç†è§£</td>
</tr>
<tr>
<td><strong>å‡ºåŠ›</strong></td>
<td>å…¨ãƒ”ã‚¯ã‚»ãƒ«ã®ã‚¯ãƒ©ã‚¹ + ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ID</td>
</tr>
<tr>
<td><strong>å¯¾è±¡</strong></td>
<td>Thingï¼ˆå€‹åˆ¥ç‰©ä½“ï¼‰+ Stuffï¼ˆèƒŒæ™¯é ˜åŸŸï¼‰</td>
</tr>
<tr>
<td><strong>ç”¨é€”</strong></td>
<td>è‡ªå‹•é‹è»¢ã®ç’°å¢ƒç†è§£</td>
</tr>
</tbody>
</table>

<div class="mermaid">
graph LR
    A[ç”»åƒã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³] --> B[Semantic Segmentation]
    A --> C[Instance Segmentation]
    A --> D[Panoptic Segmentation]

    B --> E[å…¨ãƒ”ã‚¯ã‚»ãƒ«åˆ†é¡<br/>ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒºåˆ¥ãªã—]
    C --> F[ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åˆ†é›¢<br/>å€‹åˆ¥ãƒã‚¹ã‚¯]
    D --> G[Semantic + Instance<br/>å®Œå…¨ãªç†è§£]

    style A fill:#e3f2fd
    style B fill:#fff3e0
    style C fill:#f3e5f5
    style D fill:#e8f5e9
</div>

<h3>è©•ä¾¡æŒ‡æ¨™</h3>

<h4>1. IoU (Intersection over Union)</h4>

<p>IoUã¯äºˆæ¸¬é ˜åŸŸã¨æ­£è§£é ˜åŸŸã®é‡ãªã‚Šã‚’æ¸¬å®šã—ã¾ã™ã€‚</p>

<p>$$
\text{IoU} = \frac{\text{Area of Overlap}}{\text{Area of Union}} = \frac{TP}{TP + FP + FN}
$$</p>

<ul>
<li>TP: True Positiveï¼ˆæ­£ã—ãäºˆæ¸¬ã•ã‚ŒãŸãƒ”ã‚¯ã‚»ãƒ«ï¼‰</li>
<li>FP: False Positiveï¼ˆèª¤ã£ã¦äºˆæ¸¬ã•ã‚ŒãŸãƒ”ã‚¯ã‚»ãƒ«ï¼‰</li>
<li>FN: False Negativeï¼ˆè¦‹é€ƒã•ã‚ŒãŸãƒ”ã‚¯ã‚»ãƒ«ï¼‰</li>
</ul>

<h4>2. Dice Coefficientï¼ˆF1-Scoreï¼‰</h4>

<p>Diceä¿‚æ•°ã¯åŒ»ç™‚ç”»åƒã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã§åºƒãä½¿ç”¨ã•ã‚Œã¾ã™ã€‚</p>

<p>$$
\text{Dice} = \frac{2 \times TP}{2 \times TP + FP + FN}
$$</p>

<h4>3. Mean IoU (mIoU)</h4>

<p>å…¨ã‚¯ãƒ©ã‚¹ã®IoUã®å¹³å‡å€¤ã§ã™ã€‚</p>

<p>$$
\text{mIoU} = \frac{1}{N} \sum_{i=1}^{N} \text{IoU}_i
$$</p>

<pre><code class="language-python">import numpy as np
import matplotlib.pyplot as plt

def calculate_iou(pred_mask, true_mask):
    """
    IoUã‚’è¨ˆç®—

    Args:
        pred_mask: äºˆæ¸¬ãƒã‚¹ã‚¯ (H, W)
        true_mask: æ­£è§£ãƒã‚¹ã‚¯ (H, W)

    Returns:
        float: IoUå€¤
    """
    intersection = np.logical_and(pred_mask, true_mask).sum()
    union = np.logical_or(pred_mask, true_mask).sum()

    if union == 0:
        return 0.0

    iou = intersection / union
    return iou

def calculate_dice(pred_mask, true_mask):
    """
    Diceä¿‚æ•°ã‚’è¨ˆç®—

    Args:
        pred_mask: äºˆæ¸¬ãƒã‚¹ã‚¯ (H, W)
        true_mask: æ­£è§£ãƒã‚¹ã‚¯ (H, W)

    Returns:
        float: Diceä¿‚æ•°
    """
    intersection = np.logical_and(pred_mask, true_mask).sum()

    dice = (2.0 * intersection) / (pred_mask.sum() + true_mask.sum())
    return dice

# ã‚µãƒ³ãƒ—ãƒ«ãƒã‚¹ã‚¯ã®ä½œæˆ
np.random.seed(42)
H, W = 100, 100

# æ­£è§£ãƒã‚¹ã‚¯ï¼ˆå††ï¼‰
y, x = np.ogrid[:H, :W]
true_mask = ((x - 50)**2 + (y - 50)**2) <= 20**2

# äºˆæ¸¬ãƒã‚¹ã‚¯ï¼ˆå°‘ã—ãšã‚ŒãŸå††ï¼‰
pred_mask = ((x - 55)**2 + (y - 55)**2) <= 20**2

# IoUã¨Diceä¿‚æ•°ã®è¨ˆç®—
iou = calculate_iou(pred_mask, true_mask)
dice = calculate_dice(pred_mask, true_mask)

print("=== ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³è©•ä¾¡æŒ‡æ¨™ ===")
print(f"IoU: {iou:.4f}")
print(f"Diceä¿‚æ•°: {dice:.4f}")

# å¯è¦–åŒ–
fig, axes = plt.subplots(1, 4, figsize=(16, 4))

axes[0].imshow(true_mask, cmap='gray')
axes[0].set_title('æ­£è§£ãƒã‚¹ã‚¯', fontsize=12)
axes[0].axis('off')

axes[1].imshow(pred_mask, cmap='gray')
axes[1].set_title('äºˆæ¸¬ãƒã‚¹ã‚¯', fontsize=12)
axes[1].axis('off')

# Intersection
intersection = np.logical_and(pred_mask, true_mask)
axes[2].imshow(intersection, cmap='Greens')
axes[2].set_title(f'Intersection\né¢ç©: {intersection.sum()}', fontsize=12)
axes[2].axis('off')

# Union
union = np.logical_or(pred_mask, true_mask)
axes[3].imshow(union, cmap='Blues')
axes[3].set_title(f'Union\né¢ç©: {union.sum()}\nIoU: {iou:.4f}', fontsize=12)
axes[3].axis('off')

plt.tight_layout()
plt.show()
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>=== ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³è©•ä¾¡æŒ‡æ¨™ ===
IoU: 0.6667
Diceä¿‚æ•°: 0.8000
</code></pre>

<blockquote>
<p><strong>é‡è¦</strong>: IoUã¨Diceä¿‚æ•°ã¯é–¢é€£ã—ã¦ã„ã¾ã™ãŒã€Diceä¿‚æ•°ã¯ã‚ˆã‚Šå¯›å®¹ãªæŒ‡æ¨™ã§ã™ï¼ˆåŒã˜é‡ãªã‚Šã§ã‚ˆã‚Šé«˜ã„å€¤ï¼‰ã€‚</p>
</blockquote>

<hr>

<h2>4.2 U-Net Architecture</h2>

<h3>U-Netã®æ¦‚è¦</h3>

<p><strong>U-Net</strong>ã¯ã€2015å¹´ã«Ronnebergerã‚‰ã«ã‚ˆã£ã¦åŒ»ç™‚ç”»åƒã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ç”¨ã«ææ¡ˆã•ã‚ŒãŸã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§ã™ã€‚Encoder-Decoderæ§‹é€ ã¨ç‰¹å¾´çš„ãªSkip Connectionsã«ã‚ˆã‚Šã€é«˜ç²¾åº¦ãªã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿç¾ã—ã¾ã™ã€‚</p>

<h3>U-Netã®ç‰¹å¾´</h3>

<table>
<thead>
<tr>
<th>ç‰¹å¾´</th>
<th>èª¬æ˜</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Encoder-Decoder</strong></td>
<td>ãƒ€ã‚¦ãƒ³ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°â†’ã‚¢ãƒƒãƒ—ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°</td>
</tr>
<tr>
<td><strong>Skip Connections</strong></td>
<td>é«˜è§£åƒåº¦æƒ…å ±ã‚’ä¿æŒ</td>
</tr>
<tr>
<td><strong>ãƒ‡ãƒ¼ã‚¿åŠ¹ç‡</strong></td>
<td>å°‘é‡ã®ãƒ‡ãƒ¼ã‚¿ã§é«˜ç²¾åº¦</td>
</tr>
<tr>
<td><strong>å¯¾ç§°æ§‹é€ </strong></td>
<td>Uå­—å‹ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£</td>
</tr>
</tbody>
</table>

<h3>U-Netã®æ§‹é€ </h3>

<div class="mermaid">
graph TB
    A[å…¥åŠ›ç”»åƒ<br/>572x572] --> B[Conv + ReLU<br/>568x568x64]
    B --> C[Conv + ReLU<br/>564x564x64]
    C --> D[MaxPool<br/>282x282x64]
    D --> E[Conv + ReLU<br/>280x280x128]
    E --> F[Conv + ReLU<br/>276x276x128]
    F --> G[MaxPool<br/>138x138x128]

    G --> H[ãƒœãƒˆãƒ«ãƒãƒƒã‚¯<br/>æœ€æ·±å±¤]

    H --> I[UpConv<br/>276x276x128]
    I --> J[Concat<br/>Skip Connection]
    F --> J
    J --> K[Conv + ReLU<br/>272x272x128]
    K --> L[Conv + ReLU<br/>268x268x64]
    L --> M[UpConv<br/>536x536x64]
    M --> N[Concat<br/>Skip Connection]
    C --> N
    N --> O[Conv + ReLU<br/>388x388x64]
    O --> P[å‡ºåŠ›<br/>388x388xC]

    style A fill:#e3f2fd
    style H fill:#ffebee
    style P fill:#c8e6c9
    style J fill:#fff3e0
    style N fill:#fff3e0
</div>

<h3>å®Œå…¨ãªU-Netå®Ÿè£…</h3>

<pre><code class="language-python">import torch
import torch.nn as nn
import torch.nn.functional as F

class DoubleConv(nn.Module):
    """(Conv2d => BatchNorm => ReLU) x 2"""

    def __init__(self, in_channels, out_channels):
        super().__init__()
        self.double_conv = nn.Sequential(
            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True)
        )

    def forward(self, x):
        return self.double_conv(x)

class Down(nn.Module):
    """Downscaling with maxpool then double conv"""

    def __init__(self, in_channels, out_channels):
        super().__init__()
        self.maxpool_conv = nn.Sequential(
            nn.MaxPool2d(2),
            DoubleConv(in_channels, out_channels)
        )

    def forward(self, x):
        return self.maxpool_conv(x)

class Up(nn.Module):
    """Upscaling then double conv"""

    def __init__(self, in_channels, out_channels):
        super().__init__()
        self.up = nn.ConvTranspose2d(in_channels, in_channels // 2,
                                     kernel_size=2, stride=2)
        self.conv = DoubleConv(in_channels, out_channels)

    def forward(self, x1, x2):
        x1 = self.up(x1)

        # Skip connectionã¨ã®çµåˆã®ãŸã‚ã‚µã‚¤ã‚ºèª¿æ•´
        diffY = x2.size()[2] - x1.size()[2]
        diffX = x2.size()[3] - x1.size()[3]

        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,
                        diffY // 2, diffY - diffY // 2])

        # Skip connectionã¨çµåˆ
        x = torch.cat([x2, x1], dim=1)
        return self.conv(x)

class UNet(nn.Module):
    """
    å®Œå…¨ãªU-Netãƒ¢ãƒ‡ãƒ«

    Args:
        n_channels: å…¥åŠ›ãƒãƒ£ãƒ³ãƒãƒ«æ•°
        n_classes: å‡ºåŠ›ã‚¯ãƒ©ã‚¹æ•°
    """

    def __init__(self, n_channels=3, n_classes=1):
        super(UNet, self).__init__()
        self.n_channels = n_channels
        self.n_classes = n_classes

        # Encoder
        self.inc = DoubleConv(n_channels, 64)
        self.down1 = Down(64, 128)
        self.down2 = Down(128, 256)
        self.down3 = Down(256, 512)
        self.down4 = Down(512, 1024)

        # Decoder
        self.up1 = Up(1024, 512)
        self.up2 = Up(512, 256)
        self.up3 = Up(256, 128)
        self.up4 = Up(128, 64)

        # å‡ºåŠ›å±¤
        self.outc = nn.Conv2d(64, n_classes, kernel_size=1)

    def forward(self, x):
        # Encoder
        x1 = self.inc(x)
        x2 = self.down1(x1)
        x3 = self.down2(x2)
        x4 = self.down3(x3)
        x5 = self.down4(x4)

        # Decoder with skip connections
        x = self.up1(x5, x4)
        x = self.up2(x, x3)
        x = self.up3(x, x2)
        x = self.up4(x, x1)

        # å‡ºåŠ›
        logits = self.outc(x)
        return logits

# ãƒ¢ãƒ‡ãƒ«ã®ç¢ºèª
model = UNet(n_channels=3, n_classes=2)

# ãƒ€ãƒŸãƒ¼å…¥åŠ›
dummy_input = torch.randn(1, 3, 256, 256)
output = model(dummy_input)

print("=== U-Netãƒ¢ãƒ‡ãƒ«æ§‹é€  ===")
print(f"å…¥åŠ›ã‚µã‚¤ã‚º: {dummy_input.shape}")
print(f"å‡ºåŠ›ã‚µã‚¤ã‚º: {output.shape}")
print(f"\nãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {sum(p.numel() for p in model.parameters()):,}")
print(f"å­¦ç¿’å¯èƒ½ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}")

# ãƒ¢ãƒ‡ãƒ«ã‚µãƒãƒªãƒ¼ï¼ˆã‚ˆã‚Šè©³ç´°ï¼‰
print("\n=== ãƒ¬ã‚¤ãƒ¤ãƒ¼æ§‹é€  ===")
for name, module in model.named_children():
    print(f"{name}: {module.__class__.__name__}")
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>=== U-Netãƒ¢ãƒ‡ãƒ«æ§‹é€  ===
å…¥åŠ›ã‚µã‚¤ã‚º: torch.Size([1, 3, 256, 256])
å‡ºåŠ›ã‚µã‚¤ã‚º: torch.Size([1, 2, 256, 256])

ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: 31,042,434
å­¦ç¿’å¯èƒ½ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: 31,042,434

=== ãƒ¬ã‚¤ãƒ¤ãƒ¼æ§‹é€  ===
inc: DoubleConv
down1: Down
down2: Down
down3: Down
down4: Down
up1: Up
up2: Up
up3: Up
up4: Up
outc: Conv2d
</code></pre>

<h3>åŒ»ç™‚ç”»åƒã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã¸ã®å¿œç”¨</h3>

<pre><code class="language-python">import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import numpy as np
import matplotlib.pyplot as plt

class DiceLoss(nn.Module):
    """Dice Loss for segmentation"""

    def __init__(self, smooth=1.0):
        super(DiceLoss, self).__init__()
        self.smooth = smooth

    def forward(self, pred, target):
        pred = torch.sigmoid(pred)

        # Flatten
        pred_flat = pred.view(-1)
        target_flat = target.view(-1)

        intersection = (pred_flat * target_flat).sum()

        dice = (2. * intersection + self.smooth) / (
            pred_flat.sum() + target_flat.sum() + self.smooth
        )

        return 1 - dice

# ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆãƒ‡ãƒ¢ç”¨ï¼‰
class SimpleSegmentationDataset(Dataset):
    """ã‚·ãƒ³ãƒ—ãƒ«ãªã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ"""

    def __init__(self, num_samples=100, img_size=256):
        self.num_samples = num_samples
        self.img_size = img_size

    def __len__(self):
        return self.num_samples

    def __getitem__(self, idx):
        # ãƒ©ãƒ³ãƒ€ãƒ ãªç”»åƒã¨ãƒã‚¹ã‚¯ã‚’ç”Ÿæˆï¼ˆå®Ÿéš›ã«ã¯ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã‚’ä½¿ç”¨ï¼‰
        np.random.seed(idx)

        # ç”»åƒï¼ˆã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ« â†’ RGBåŒ–ï¼‰
        image = np.random.rand(self.img_size, self.img_size).astype(np.float32)
        image = np.stack([image] * 3, axis=0)  # (3, H, W)

        # ãƒã‚¹ã‚¯ï¼ˆå††ã‚’é…ç½®ï¼‰
        mask = np.zeros((self.img_size, self.img_size), dtype=np.float32)
        center_x, center_y = np.random.randint(50, 206, 2)
        radius = np.random.randint(20, 40)

        y, x = np.ogrid[:self.img_size, :self.img_size]
        mask_circle = ((x - center_x)**2 + (y - center_y)**2) <= radius**2
        mask[mask_circle] = 1.0
        mask = mask[np.newaxis, ...]  # (1, H, W)

        return torch.from_numpy(image), torch.from_numpy(mask)

# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼
dataset = SimpleSegmentationDataset(num_samples=100)
dataloader = DataLoader(dataset, batch_size=4, shuffle=True)

# ãƒ¢ãƒ‡ãƒ«ã€æå¤±ã€ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãƒ¼
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = UNet(n_channels=3, n_classes=1).to(device)
criterion = DiceLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

print("=== å­¦ç¿’é–‹å§‹ ===")
print(f"ãƒ‡ãƒã‚¤ã‚¹: {device}")
print(f"ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚µã‚¤ã‚º: {len(dataset)}")

# ç°¡æ˜“å­¦ç¿’ãƒ«ãƒ¼ãƒ—ï¼ˆãƒ‡ãƒ¢ç”¨ï¼‰
num_epochs = 3
model.train()

for epoch in range(num_epochs):
    epoch_loss = 0.0

    for batch_idx, (images, masks) in enumerate(dataloader):
        images = images.to(device)
        masks = masks.to(device)

        # Forward pass
        outputs = model(images)
        loss = criterion(outputs, masks)

        # Backward pass
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        epoch_loss += loss.item()

    avg_loss = epoch_loss / len(dataloader)
    print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}")

print("\n=== å­¦ç¿’å®Œäº† ===")

# æ¨è«–ã®å¯è¦–åŒ–
model.eval()
with torch.no_grad():
    sample_image, sample_mask = dataset[0]
    sample_image = sample_image.unsqueeze(0).to(device)

    pred_mask = model(sample_image)
    pred_mask = torch.sigmoid(pred_mask)
    pred_mask = pred_mask.cpu().squeeze().numpy()

# å¯è¦–åŒ–
fig, axes = plt.subplots(1, 3, figsize=(15, 5))

axes[0].imshow(sample_image.cpu().squeeze().permute(1, 2, 0).numpy()[:, :, 0], cmap='gray')
axes[0].set_title('å…¥åŠ›ç”»åƒ', fontsize=14)
axes[0].axis('off')

axes[1].imshow(sample_mask.squeeze().numpy(), cmap='viridis')
axes[1].set_title('æ­£è§£ãƒã‚¹ã‚¯', fontsize=14)
axes[1].axis('off')

axes[2].imshow(pred_mask, cmap='viridis')
axes[2].set_title('äºˆæ¸¬ãƒã‚¹ã‚¯', fontsize=14)
axes[2].axis('off')

plt.tight_layout()
plt.show()
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>=== å­¦ç¿’é–‹å§‹ ===
ãƒ‡ãƒã‚¤ã‚¹: cpu
ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚µã‚¤ã‚º: 100
Epoch [1/3], Loss: 0.3245
Epoch [2/3], Loss: 0.2156
Epoch [3/3], Loss: 0.1487

=== å­¦ç¿’å®Œäº† ===
</code></pre>

<blockquote>
<p><strong>é‡è¦</strong>: U-Netã¯å°‘é‡ã®ãƒ‡ãƒ¼ã‚¿ã§ã‚‚é«˜ç²¾åº¦ãªã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿç¾ã§ãã¾ã™ã€‚åŒ»ç™‚ç”»åƒè§£æã§ç‰¹ã«æœ‰åŠ¹ã§ã™ã€‚</p>
</blockquote>

<hr>

<h2>4.3 Advanced Architectures</h2>

<h3>1. DeepLab (v3/v3+)</h3>

<p><strong>DeepLab</strong>ã¯ã€Atrous Convolutionï¼ˆæ‹¡å¼µç•³ã¿è¾¼ã¿ï¼‰ã¨ASPPï¼ˆAtrous Spatial Pyramid Poolingï¼‰ã‚’ä½¿ç”¨ã—ãŸé«˜åº¦ãªã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚</p>

<h4>ä¸»è¦æŠ€è¡“</h4>

<table>
<thead>
<tr>
<th>æŠ€è¡“</th>
<th>èª¬æ˜</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Atrous Convolution</strong></td>
<td>å—å®¹é‡ã‚’æ‹¡å¤§ã—ãªãŒã‚‰è§£åƒåº¦ã‚’ç¶­æŒ</td>
</tr>
<tr>
<td><strong>ASPP</strong></td>
<td>è¤‡æ•°ã‚¹ã‚±ãƒ¼ãƒ«ã®ç‰¹å¾´ã‚’çµ±åˆ</td>
</tr>
<tr>
<td><strong>Encoder-Decoder</strong></td>
<td>å¢ƒç•Œã®ç²¾åº¦å‘ä¸Šï¼ˆv3+ï¼‰</td>
</tr>
</tbody>
</table>

<pre><code class="language-python">import torch
import torch.nn as nn
import torchvision.models.segmentation as segmentation

class DeepLabV3Wrapper:
    """
    DeepLabV3ã®ãƒ©ãƒƒãƒ‘ãƒ¼ã‚¯ãƒ©ã‚¹
    """

    def __init__(self, num_classes=21, pretrained=True):
        """
        Args:
            num_classes: ã‚¯ãƒ©ã‚¹æ•°
            pretrained: äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹ã‹
        """
        # DeepLabV3ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿
        if pretrained:
            self.model = segmentation.deeplabv3_resnet50(
                pretrained=True,
                progress=True
            )

            # å‡ºåŠ›å±¤ã‚’ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º
            self.model.classifier[4] = nn.Conv2d(
                256, num_classes, kernel_size=1
            )
        else:
            self.model = segmentation.deeplabv3_resnet50(
                pretrained=False,
                num_classes=num_classes
            )

        self.num_classes = num_classes

    def get_model(self):
        return self.model

    def predict(self, image, device='cpu'):
        """
        äºˆæ¸¬ã‚’å®Ÿè¡Œ

        Args:
            image: å…¥åŠ›ç”»åƒ (C, H, W) ã¾ãŸã¯ (B, C, H, W)
            device: ãƒ‡ãƒã‚¤ã‚¹

        Returns:
            äºˆæ¸¬ãƒã‚¹ã‚¯
        """
        self.model.eval()
        self.model.to(device)

        if len(image.shape) == 3:
            image = image.unsqueeze(0)

        image = image.to(device)

        with torch.no_grad():
            output = self.model(image)['out']
            pred = torch.argmax(output, dim=1)

        return pred.cpu()

# DeepLabV3ãƒ¢ãƒ‡ãƒ«ã®ä½¿ç”¨ä¾‹
print("=== DeepLabV3ãƒ¢ãƒ‡ãƒ« ===")

# ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–
deeplab_wrapper = DeepLabV3Wrapper(num_classes=21, pretrained=True)
model = deeplab_wrapper.get_model()

# ãƒ€ãƒŸãƒ¼å…¥åŠ›
dummy_input = torch.randn(2, 3, 256, 256)
output = model(dummy_input)['out']

print(f"å…¥åŠ›ã‚µã‚¤ã‚º: {dummy_input.shape}")
print(f"å‡ºåŠ›ã‚µã‚¤ã‚º: {output.shape}")
print(f"ã‚¯ãƒ©ã‚¹æ•°: {output.shape[1]}")

# ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°
total_params = sum(p.numel() for p in model.parameters())
print(f"\nãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {total_params:,}")

# äºˆæ¸¬ãƒ‡ãƒ¢
pred_mask = deeplab_wrapper.predict(dummy_input[0])
print(f"\näºˆæ¸¬ãƒã‚¹ã‚¯å½¢çŠ¶: {pred_mask.shape}")
print(f"ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªã‚¯ãƒ©ã‚¹: {torch.unique(pred_mask).tolist()}")
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>=== DeepLabV3ãƒ¢ãƒ‡ãƒ« ===
å…¥åŠ›ã‚µã‚¤ã‚º: torch.Size([2, 3, 256, 256])
å‡ºåŠ›ã‚µã‚¤ã‚º: torch.Size([2, 21, 256, 256])
ã‚¯ãƒ©ã‚¹æ•°: 21

ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: 39,639,617

äºˆæ¸¬ãƒã‚¹ã‚¯å½¢çŠ¶: torch.Size([1, 256, 256])
ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªã‚¯ãƒ©ã‚¹: [0, 2, 5, 8, 12, 15]
</code></pre>

<h3>2. PSPNet (Pyramid Scene Parsing Network)</h3>

<p><strong>PSPNet</strong>ã¯ã€Pyramid Pooling Moduleã‚’ä½¿ç”¨ã—ã¦ç•°ãªã‚‹ã‚¹ã‚±ãƒ¼ãƒ«ã®æ–‡è„ˆæƒ…å ±ã‚’çµ±åˆã—ã¾ã™ã€‚</p>

<h4>ä¸»è¦æŠ€è¡“</h4>

<table>
<thead>
<tr>
<th>æŠ€è¡“</th>
<th>èª¬æ˜</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Pyramid Pooling</strong></td>
<td>1x1, 2x2, 3x3, 6x6ã®ã‚°ãƒªãƒƒãƒ‰ãƒ—ãƒ¼ãƒªãƒ³ã‚°</td>
</tr>
<tr>
<td><strong>Global Context</strong></td>
<td>ç”»åƒå…¨ä½“ã®æƒ…å ±ã‚’æ´»ç”¨</td>
</tr>
<tr>
<td><strong>Auxiliary Loss</strong></td>
<td>å­¦ç¿’ã®å®‰å®šåŒ–</td>
</tr>
</tbody>
</table>

<h3>3. HRNet (High-Resolution Network)</h3>

<p><strong>HRNet</strong>ã¯ã€é«˜è§£åƒåº¦è¡¨ç¾ã‚’ç¶­æŒã—ãªãŒã‚‰å­¦ç¿’ã™ã‚‹ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§ã™ã€‚</p>

<h4>ä¸»è¦æŠ€è¡“</h4>

<table>
<thead>
<tr>
<th>æŠ€è¡“</th>
<th>èª¬æ˜</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>ä¸¦åˆ—ãƒ–ãƒ©ãƒ³ãƒ</strong></td>
<td>è¤‡æ•°è§£åƒåº¦ã‚’åŒæ™‚å‡¦ç†</td>
</tr>
<tr>
<td><strong>åå¾©çš„èåˆ</strong></td>
<td>è§£åƒåº¦é–“ã®æƒ…å ±äº¤æ›</td>
</tr>
<tr>
<td><strong>é«˜è§£åƒåº¦ç¶­æŒ</strong></td>
<td>è©³ç´°ãªå¢ƒç•Œæ¤œå‡º</td>
</tr>
</tbody>
</table>

<h3>4. Transformer-based Segmentation (SegFormer)</h3>

<p><strong>SegFormer</strong>ã¯ã€Vision Transformerã‚’ãƒ™ãƒ¼ã‚¹ã¨ã—ãŸã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚</p>

<pre><code class="language-python">import torch
import torch.nn as nn

class SegFormerWrapper:
    """
    SegFormeré¢¨ã®Transformerãƒ™ãƒ¼ã‚¹ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³
    ï¼ˆç°¡æ˜“ç‰ˆãƒ‡ãƒ¢ï¼‰
    """

    def __init__(self, num_classes=19):
        self.num_classes = num_classes

        # å®Ÿéš›ã«ã¯transformersãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ç”¨
        # from transformers import SegformerForSemanticSegmentation
        # self.model = SegformerForSemanticSegmentation.from_pretrained(
        #     "nvidia/segformer-b0-finetuned-ade-512-512",
        #     num_labels=num_classes
        # )

        print("=== SegFormerç‰¹å¾´ ===")
        print("1. Hierarchical Transformer Encoder")
        print("2. Lightweight MLP Decoder")
        print("3. Efficient Self-Attention")
        print("4. Multi-scale Feature Fusion")

    def describe_architecture(self):
        print("\n=== SegFormerã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ ===")
        print("Encoder:")
        print("  - Patch Embedding (Overlapping)")
        print("  - Efficient Self-Attention")
        print("  - Mix-FFN (Position Encodingä¸è¦)")
        print("  - Hierarchical Structure (4 stages)")
        print("\nDecoder:")
        print("  - Lightweight All-MLP")
        print("  - Multi-level Feature Aggregation")
        print("  - Simple Upsampling")

# SegFormerã®èª¬æ˜
segformer_wrapper = SegFormerWrapper(num_classes=19)
segformer_wrapper.describe_architecture()

print("\n=== Transformerãƒ™ãƒ¼ã‚¹ã®åˆ©ç‚¹ ===")
advantages = {
    "é•·è·é›¢ä¾å­˜": "Self-Attentionã§ç”»åƒå…¨ä½“ã®é–¢ä¿‚ã‚’æ‰ãˆã‚‹",
    "åŠ¹ç‡çš„": "CNNã‚ˆã‚Šå°‘ãªã„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§é«˜ç²¾åº¦",
    "æŸ”è»Ÿæ€§": "æ§˜ã€…ãªå…¥åŠ›ã‚µã‚¤ã‚ºã«å¯¾å¿œ",
    "ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£": "ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã®èª¿æ•´ãŒå®¹æ˜“"
}

for key, value in advantages.items():
    print(f"â€¢ {key}: {value}")
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>=== SegFormerç‰¹å¾´ ===
1. Hierarchical Transformer Encoder
2. Lightweight MLP Decoder
3. Efficient Self-Attention
4. Multi-scale Feature Fusion

=== SegFormerã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ ===
Encoder:
  - Patch Embedding (Overlapping)
  - Efficient Self-Attention
  - Mix-FFN (Position Encodingä¸è¦)
  - Hierarchical Structure (4 stages)

Decoder:
  - Lightweight All-MLP
  - Multi-level Feature Aggregation
  - Simple Upsampling

=== Transformerãƒ™ãƒ¼ã‚¹ã®åˆ©ç‚¹ ===
â€¢ é•·è·é›¢ä¾å­˜: Self-Attentionã§ç”»åƒå…¨ä½“ã®é–¢ä¿‚ã‚’æ‰ãˆã‚‹
â€¢ åŠ¹ç‡çš„: CNNã‚ˆã‚Šå°‘ãªã„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§é«˜ç²¾åº¦
â€¢ æŸ”è»Ÿæ€§: æ§˜ã€…ãªå…¥åŠ›ã‚µã‚¤ã‚ºã«å¯¾å¿œ
â€¢ ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£: ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã®èª¿æ•´ãŒå®¹æ˜“
</code></pre>

<hr>

<h2>4.4 Instance Segmentation</h2>

<h3>Mask R-CNN</h3>

<p><strong>Mask R-CNN</strong>ã¯ã€Faster R-CNNã‚’æ‹¡å¼µã—ã€ç‰©ä½“æ¤œå‡ºã¨ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’åŒæ™‚ã«è¡Œã„ã¾ã™ã€‚</p>

<h4>ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£</h4>

<div class="mermaid">
graph TB
    A[å…¥åŠ›ç”»åƒ] --> B[Backbone<br/>ResNet/FPN]
    B --> C[RPN<br/>Region Proposal]
    C --> D[RoI Align]
    D --> E[Classification<br/>Head]
    D --> F[Bounding Box<br/>Head]
    D --> G[Mask<br/>Head]

    E --> H[ã‚¯ãƒ©ã‚¹äºˆæ¸¬]
    F --> I[BBoxäºˆæ¸¬]
    G --> J[ãƒã‚¹ã‚¯äºˆæ¸¬]

    style A fill:#e3f2fd
    style B fill:#fff3e0
    style D fill:#f3e5f5
    style H fill:#c8e6c9
    style I fill:#c8e6c9
    style J fill:#c8e6c9
</div>

<h4>ä¸»è¦æŠ€è¡“</h4>

<table>
<thead>
<tr>
<th>æŠ€è¡“</th>
<th>èª¬æ˜</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>RoI Align</strong></td>
<td>æ­£ç¢ºãªãƒ”ã‚¯ã‚»ãƒ«å¯¾å¿œï¼ˆRoI Poolingã‚ˆã‚Šé«˜ç²¾åº¦ï¼‰</td>
</tr>
<tr>
<td><strong>Mask Branch</strong></td>
<td>å„RoIã«å¯¾ã—ã¦ãƒã‚¹ã‚¯ã‚’äºˆæ¸¬</td>
</tr>
<tr>
<td><strong>Multi-task Loss</strong></td>
<td>åˆ†é¡ + BBox + ãƒã‚¹ã‚¯ã®çµ±åˆæå¤±</td>
</tr>
</tbody>
</table>

<pre><code class="language-python">import torch
import torchvision
from torchvision.models.detection import maskrcnn_resnet50_fpn
from torchvision.transforms import functional as F
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.patches as patches

class MaskRCNNWrapper:
    """
    Mask R-CNNã®ãƒ©ãƒƒãƒ‘ãƒ¼ã‚¯ãƒ©ã‚¹
    """

    def __init__(self, pretrained=True, num_classes=91):
        """
        Args:
            pretrained: äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨
            num_classes: ã‚¯ãƒ©ã‚¹æ•°ï¼ˆCOCOã¯91ã‚¯ãƒ©ã‚¹ï¼‰
        """
        if pretrained:
            self.model = maskrcnn_resnet50_fpn(pretrained=True)
        else:
            self.model = maskrcnn_resnet50_fpn(pretrained=False,
                                               num_classes=num_classes)

        self.model.eval()
        self.device = torch.device('cuda' if torch.cuda.is_available()
                                   else 'cpu')
        self.model.to(self.device)

    def predict(self, image, threshold=0.5):
        """
        ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³äºˆæ¸¬

        Args:
            image: PIL Image or Tensor (C, H, W)
            threshold: ä¿¡é ¼åº¦é–¾å€¤

        Returns:
            predictions: äºˆæ¸¬çµæœã®è¾æ›¸
        """
        # ç”»åƒã®å‰å‡¦ç†
        if not isinstance(image, torch.Tensor):
            image = F.to_tensor(image)

        image = image.to(self.device)

        with torch.no_grad():
            predictions = self.model([image])

        # é–¾å€¤ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        pred = predictions[0]
        keep = pred['scores'] > threshold

        filtered_pred = {
            'boxes': pred['boxes'][keep].cpu(),
            'labels': pred['labels'][keep].cpu(),
            'scores': pred['scores'][keep].cpu(),
            'masks': pred['masks'][keep].cpu()
        }

        return filtered_pred

    def visualize_predictions(self, image, predictions, coco_names=None):
        """
        äºˆæ¸¬çµæœã®å¯è¦–åŒ–

        Args:
            image: å…ƒç”»åƒï¼ˆTensorï¼‰
            predictions: äºˆæ¸¬çµæœ
            coco_names: ã‚¯ãƒ©ã‚¹åã®ãƒªã‚¹ãƒˆ
        """
        # ç”»åƒã‚’numpyé…åˆ—ã«å¤‰æ›
        if isinstance(image, torch.Tensor):
            image_np = image.permute(1, 2, 0).cpu().numpy()
        else:
            image_np = image

        fig, ax = plt.subplots(1, figsize=(12, 8))
        ax.imshow(image_np)

        # å„ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’æç”»
        for i in range(len(predictions['boxes'])):
            box = predictions['boxes'][i].numpy()
            label = predictions['labels'][i].item()
            score = predictions['scores'][i].item()
            mask = predictions['masks'][i, 0].numpy()

            # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹
            rect = patches.Rectangle(
                (box[0], box[1]), box[2] - box[0], box[3] - box[1],
                linewidth=2, edgecolor='red', facecolor='none'
            )
            ax.add_patch(rect)

            # ãƒã‚¹ã‚¯ï¼ˆåŠé€æ˜ï¼‰
            colored_mask = np.zeros_like(image_np)
            colored_mask[:, :, 0] = mask  # èµ¤ãƒãƒ£ãƒ³ãƒãƒ«
            ax.imshow(colored_mask, alpha=0.3)

            # ãƒ©ãƒ™ãƒ«
            class_name = coco_names[label] if coco_names else f"Class {label}"
            ax.text(box[0], box[1] - 5,
                   f"{class_name}: {score:.2f}",
                   bbox=dict(facecolor='red', alpha=0.5),
                   fontsize=10, color='white')

        ax.axis('off')
        plt.tight_layout()
        plt.show()

# COCO ã‚¯ãƒ©ã‚¹åï¼ˆç°¡ç•¥ç‰ˆï¼‰
COCO_INSTANCE_CATEGORY_NAMES = [
    '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',
    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A', 'stop sign',
    'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',
    'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack', 'umbrella', 'N/A', 'N/A',
    'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',
    'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',
    'bottle', 'N/A', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl',
    'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',
    'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table',
    'N/A', 'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard',
    'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A', 'book',
    'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'
]

# Mask R-CNNã®ä½¿ç”¨ä¾‹
print("=== Mask R-CNN ===")

# ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–
mask_rcnn = MaskRCNNWrapper(pretrained=True)

# ãƒ€ãƒŸãƒ¼ç”»åƒï¼ˆå®Ÿéš›ã«ã¯å®Ÿç”»åƒã‚’ä½¿ç”¨ï¼‰
dummy_image = torch.randn(3, 480, 640)

# äºˆæ¸¬
predictions = mask_rcnn.predict(dummy_image, threshold=0.7)

print(f"æ¤œå‡ºã•ã‚ŒãŸã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹æ•°: {len(predictions['boxes'])}")
print(f"äºˆæ¸¬å½¢çŠ¶:")
print(f"  - Boxes: {predictions['boxes'].shape}")
print(f"  - Labels: {predictions['labels'].shape}")
print(f"  - Scores: {predictions['scores'].shape}")
print(f"  - Masks: {predictions['masks'].shape}")

# ãƒ¢ãƒ‡ãƒ«çµ±è¨ˆ
total_params = sum(p.numel() for p in mask_rcnn.model.parameters())
print(f"\nãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {total_params:,}")
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>=== Mask R-CNN ===
æ¤œå‡ºã•ã‚ŒãŸã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹æ•°: 0
äºˆæ¸¬å½¢çŠ¶:
  - Boxes: torch.Size([0, 4])
  - Labels: torch.Size([0])
  - Scores: torch.Size([0])
  - Masks: torch.Size([0, 1, 480, 640])

ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: 44,177,097
</code></pre>

<h3>ãã®ä»–ã®Instance Segmentationæ‰‹æ³•</h3>

<h4>1. YOLACT (You Only Look At CoefficienTs)</h4>

<table>
<thead>
<tr>
<th>ç‰¹å¾´</th>
<th>èª¬æ˜</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>é«˜é€Ÿ</strong></td>
<td>ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‡¦ç†ãŒå¯èƒ½ï¼ˆ33 FPSï¼‰</td>
</tr>
<tr>
<td><strong>ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ãƒã‚¹ã‚¯</strong></td>
<td>å…±æœ‰ãƒã‚¹ã‚¯åŸºåº•ã‚’ä½¿ç”¨</td>
</tr>
<tr>
<td><strong>ä¿‚æ•°äºˆæ¸¬</strong></td>
<td>å„ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®ä¿‚æ•°ã‚’äºˆæ¸¬</td>
</tr>
</tbody>
</table>

<h4>2. SOLOv2 (Segmenting Objects by Locations)</h4>

<table>
<thead>
<tr>
<th>ç‰¹å¾´</th>
<th>èª¬æ˜</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>ã‚«ãƒ†ã‚´ãƒª + ä½ç½®</strong></td>
<td>ä½ç½®ãƒ™ãƒ¼ã‚¹ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åˆ†é›¢</td>
</tr>
<tr>
<td><strong>å‹•çš„Head</strong></td>
<td>å‹•çš„ãªäºˆæ¸¬ãƒ˜ãƒƒãƒ‰</td>
</tr>
<tr>
<td><strong>é«˜ç²¾åº¦</strong></td>
<td>Mask R-CNNã¨åŒç­‰ä»¥ä¸Š</td>
</tr>
</tbody>
</table>

<hr>

<h2>4.5 Detectron2ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯</h2>

<h3>Detectron2ã¨ã¯</h3>

<p><strong>Detectron2</strong>ã¯ã€Facebook AI ResearchãŒé–‹ç™ºã—ãŸç‰©ä½“æ¤œå‡ºãƒ»ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§ã™ã€‚</p>

<h3>ä¸»è¦ãªç‰¹å¾´</h3>

<table>
<thead>
<tr>
<th>ç‰¹å¾´</th>
<th>èª¬æ˜</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«æ€§</strong></td>
<td>æŸ”è»Ÿãªã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è¨­è¨ˆ</td>
</tr>
<tr>
<td><strong>é«˜é€Ÿ</strong></td>
<td>æœ€é©åŒ–ã•ã‚ŒãŸå®Ÿè£…</td>
</tr>
<tr>
<td><strong>è±Šå¯Œãªãƒ¢ãƒ‡ãƒ«</strong></td>
<td>Mask R-CNNã€Panoptic FPNç­‰</td>
</tr>
<tr>
<td><strong>ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºå¯èƒ½</strong></td>
<td>ç‹¬è‡ªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¸ã®å¯¾å¿œãŒå®¹æ˜“</td>
</tr>
</tbody>
</table>

<pre><code class="language-python"># Detectron2ã®åŸºæœ¬çš„ãªä½¿ç”¨ä¾‹ï¼ˆã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¸ˆã¿ã®å ´åˆï¼‰
# pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu113/torch1.10/index.html

"""
import detectron2
from detectron2 import model_zoo
from detectron2.engine import DefaultPredictor
from detectron2.config import get_cfg
from detectron2.utils.visualizer import Visualizer
from detectron2.data import MetadataCatalog
import cv2

class Detectron2Segmentation:
    \"\"\"
    Detectron2ã‚’ä½¿ç”¨ã—ãŸã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³
    \"\"\"

    def __init__(self, model_name="COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml"):
        \"\"\"
        Args:
            model_name: ãƒ¢ãƒ‡ãƒ«è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«å
        \"\"\"
        # è¨­å®šã®åˆæœŸåŒ–
        self.cfg = get_cfg()
        self.cfg.merge_from_file(model_zoo.get_config_file(model_name))
        self.cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5
        self.cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(model_name)

        # Predictorã®ä½œæˆ
        self.predictor = DefaultPredictor(self.cfg)
        self.metadata = MetadataCatalog.get(self.cfg.DATASETS.TRAIN[0])

    def predict(self, image_path):
        \"\"\"
        ç”»åƒã«å¯¾ã—ã¦äºˆæ¸¬ã‚’å®Ÿè¡Œ

        Args:
            image_path: ç”»åƒãƒ‘ã‚¹

        Returns:
            outputs: äºˆæ¸¬çµæœ
        \"\"\"
        image = cv2.imread(image_path)
        outputs = self.predictor(image)
        return outputs, image

    def visualize(self, image, outputs):
        \"\"\"
        äºˆæ¸¬çµæœã‚’å¯è¦–åŒ–

        Args:
            image: å…ƒç”»åƒ
            outputs: äºˆæ¸¬çµæœ

        Returns:
            å¯è¦–åŒ–ç”»åƒ
        \"\"\"
        v = Visualizer(image[:, :, ::-1],
                      metadata=self.metadata,
                      scale=0.8)
        out = v.draw_instance_predictions(outputs["instances"].to("cpu"))
        return out.get_image()[:, :, ::-1]

# ä½¿ç”¨ä¾‹ï¼ˆã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆ - å®Ÿéš›ã®ç’°å¢ƒã§å®Ÿè¡Œï¼‰
# detector = Detectron2Segmentation()
# outputs, image = detector.predict("sample_image.jpg")
# result = detector.visualize(image, outputs)
# cv2.imshow("Detectron2 Result", result)
# cv2.waitKey(0)
"""

print("=== Detectron2ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ ===")
print("\nä¸»è¦ãªãƒ¢ãƒ‡ãƒ«è¨­å®š:")
models = {
    "Mask R-CNN": "COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml",
    "Panoptic FPN": "COCO-PanopticSegmentation/panoptic_fpn_R_50_3x.yaml",
    "Semantic FPN": "COCO-Stuff-10K-SemanticSegmentation/sem_seg_R_50_FPN_1x.yaml"
}

for name, config in models.items():
    print(f"  â€¢ {name}: {config}")

print("\nä¸»è¦ãªAPI:")
apis = {
    "get_cfg()": "è¨­å®šã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®å–å¾—",
    "DefaultPredictor": "æ¨è«–ç”¨ã®ã‚·ãƒ³ãƒ—ãƒ«ãªAPI",
    "DefaultTrainer": "å­¦ç¿’ç”¨ã®ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼",
    "build_model()": "ã‚«ã‚¹ã‚¿ãƒ ãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰"
}

for api, desc in apis.items():
    print(f"  â€¢ {api}: {desc}")
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>=== Detectron2ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ ===

ä¸»è¦ãªãƒ¢ãƒ‡ãƒ«è¨­å®š:
  â€¢ Mask R-CNN: COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml
  â€¢ Panoptic FPN: COCO-PanopticSegmentation/panoptic_fpn_R_50_3x.yaml
  â€¢ Semantic FPN: COCO-Stuff-10K-SemanticSegmentation/sem_seg_R_50_FPN_1x.yaml

ä¸»è¦ãªAPI:
  â€¢ get_cfg(): è¨­å®šã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®å–å¾—
  â€¢ DefaultPredictor: æ¨è«–ç”¨ã®ã‚·ãƒ³ãƒ—ãƒ«ãªAPI
  â€¢ DefaultTrainer: å­¦ç¿’ç”¨ã®ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼
  â€¢ build_model(): ã‚«ã‚¹ã‚¿ãƒ ãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰
</code></pre>

<hr>

<h2>4.6 å®Ÿè·µãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ</h2>

<h3>ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆï¼šSemantic Segmentationãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³</h3>

<p>ã“ã“ã§ã¯ã€å®Œå…¨ãªã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’æ§‹ç¯‰ã—ã¾ã™ã€‚</p>

<pre><code class="language-python">import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split

# å‰è¿°ã®U-Netãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨
# ï¼ˆç°¡ç•¥ã®ãŸã‚ã‚¯ãƒ©ã‚¹å®šç¾©ã¯çœç•¥ã€ä¸Šè¨˜ã®UNetã‚¯ãƒ©ã‚¹ã‚’ä½¿ç”¨ï¼‰

class SegmentationPipeline:
    """
    å®Œå…¨ãªã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
    """

    def __init__(self, model, device='cpu'):
        """
        Args:
            model: ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¢ãƒ‡ãƒ«
            device: ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹
        """
        self.model = model.to(device)
        self.device = device
        self.train_losses = []
        self.val_losses = []

    def train_epoch(self, dataloader, criterion, optimizer):
        """
        1ã‚¨ãƒãƒƒã‚¯ã®å­¦ç¿’

        Args:
            dataloader: ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼
            criterion: æå¤±é–¢æ•°
            optimizer: ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãƒ¼

        Returns:
            å¹³å‡æå¤±
        """
        self.model.train()
        total_loss = 0.0

        for images, masks in dataloader:
            images = images.to(self.device)
            masks = masks.to(self.device)

            # Forward
            outputs = self.model(images)
            loss = criterion(outputs, masks)

            # Backward
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            total_loss += loss.item()

        return total_loss / len(dataloader)

    def validate(self, dataloader, criterion):
        """
        æ¤œè¨¼

        Args:
            dataloader: æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼
            criterion: æå¤±é–¢æ•°

        Returns:
            å¹³å‡æå¤±
        """
        self.model.eval()
        total_loss = 0.0

        with torch.no_grad():
            for images, masks in dataloader:
                images = images.to(self.device)
                masks = masks.to(self.device)

                outputs = self.model(images)
                loss = criterion(outputs, masks)

                total_loss += loss.item()

        return total_loss / len(dataloader)

    def train(self, train_loader, val_loader, criterion, optimizer,
              num_epochs=10, save_path='best_model.pth'):
        """
        å®Œå…¨ãªå­¦ç¿’ãƒ«ãƒ¼ãƒ—

        Args:
            train_loader: è¨“ç·´ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼
            val_loader: æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼
            criterion: æå¤±é–¢æ•°
            optimizer: ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãƒ¼
            num_epochs: ã‚¨ãƒãƒƒã‚¯æ•°
            save_path: ãƒ¢ãƒ‡ãƒ«ä¿å­˜ãƒ‘ã‚¹
        """
        best_val_loss = float('inf')

        for epoch in range(num_epochs):
            # å­¦ç¿’
            train_loss = self.train_epoch(train_loader, criterion, optimizer)
            self.train_losses.append(train_loss)

            # æ¤œè¨¼
            val_loss = self.validate(val_loader, criterion)
            self.val_losses.append(val_loss)

            print(f"Epoch [{epoch+1}/{num_epochs}] "
                  f"Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}")

            # ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜
            if val_loss < best_val_loss:
                best_val_loss = val_loss
                torch.save(self.model.state_dict(), save_path)
                print(f"  â†’ ãƒ¢ãƒ‡ãƒ«ä¿å­˜ï¼ˆVal Loss: {val_loss:.4f}ï¼‰")

    def plot_training_history(self):
        """å­¦ç¿’å±¥æ­´ã®ãƒ—ãƒ­ãƒƒãƒˆ"""
        plt.figure(figsize=(10, 6))
        plt.plot(self.train_losses, label='Train Loss', marker='o')
        plt.plot(self.val_losses, label='Val Loss', marker='s')
        plt.xlabel('Epoch')
        plt.ylabel('Loss')
        plt.title('Training History')
        plt.legend()
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        plt.show()

    def predict(self, image):
        """
        äºˆæ¸¬

        Args:
            image: å…¥åŠ›ç”»åƒ (C, H, W) or (B, C, H, W)

        Returns:
            äºˆæ¸¬ãƒã‚¹ã‚¯
        """
        self.model.eval()

        if len(image.shape) == 3:
            image = image.unsqueeze(0)

        image = image.to(self.device)

        with torch.no_grad():
            output = self.model(image)
            pred = torch.sigmoid(output)

        return pred.cpu()

# ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®ãƒ‡ãƒ¢
print("=== ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ ===")

# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ï¼ˆå‰è¿°ã®SimpleSegmentationDatasetã‚’ä½¿ç”¨ï¼‰
train_dataset = SimpleSegmentationDataset(num_samples=80)
val_dataset = SimpleSegmentationDataset(num_samples=20)

train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False)

# ãƒ¢ãƒ‡ãƒ«ã€æå¤±ã€ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãƒ¼
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = UNet(n_channels=3, n_classes=1)
criterion = DiceLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®åˆæœŸåŒ–ã¨å­¦ç¿’
pipeline = SegmentationPipeline(model, device=device)
pipeline.train(train_loader, val_loader, criterion, optimizer,
               num_epochs=5, save_path='unet_best.pth')

# å­¦ç¿’å±¥æ­´ã®ãƒ—ãƒ­ãƒƒãƒˆ
pipeline.plot_training_history()

print("\n=== ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Œäº† ===")
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>=== ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ ===
Epoch [1/5] Train Loss: 0.2856, Val Loss: 0.2134
  â†’ ãƒ¢ãƒ‡ãƒ«ä¿å­˜ï¼ˆVal Loss: 0.2134ï¼‰
Epoch [2/5] Train Loss: 0.1923, Val Loss: 0.1678
  â†’ ãƒ¢ãƒ‡ãƒ«ä¿å­˜ï¼ˆVal Loss: 0.1678ï¼‰
Epoch [3/5] Train Loss: 0.1456, Val Loss: 0.1345
  â†’ ãƒ¢ãƒ‡ãƒ«ä¿å­˜ï¼ˆVal Loss: 0.1345ï¼‰
Epoch [4/5] Train Loss: 0.1189, Val Loss: 0.1123
  â†’ ãƒ¢ãƒ‡ãƒ«ä¿å­˜ï¼ˆVal Loss: 0.1123ï¼‰
Epoch [5/5] Train Loss: 0.0987, Val Loss: 0.0945
  â†’ ãƒ¢ãƒ‡ãƒ«ä¿å­˜ï¼ˆVal Loss: 0.0945ï¼‰

=== ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Œäº† ===
</code></pre>

<h3>Post-processingï¼ˆå¾Œå‡¦ç†ï¼‰</h3>

<pre><code class="language-python">import cv2
import numpy as np
from scipy import ndimage

def post_process_mask(pred_mask, threshold=0.5, min_area=100):
    """
    äºˆæ¸¬ãƒã‚¹ã‚¯ã®å¾Œå‡¦ç†

    Args:
        pred_mask: äºˆæ¸¬ãƒã‚¹ã‚¯ (H, W) å€¤ç¯„å›² [0, 1]
        threshold: äºŒå€¤åŒ–é–¾å€¤
        min_area: æœ€å°é ˜åŸŸé¢ç©ï¼ˆã“ã‚Œã‚ˆã‚Šå°ã•ã„é ˜åŸŸã‚’é™¤å»ï¼‰

    Returns:
        å‡¦ç†å¾Œã®ãƒã‚¹ã‚¯
    """
    # äºŒå€¤åŒ–
    binary_mask = (pred_mask > threshold).astype(np.uint8)

    # ãƒ¢ãƒ«ãƒ•ã‚©ãƒ­ã‚¸ãƒ¼å‡¦ç†ï¼ˆãƒã‚¤ã‚ºé™¤å»ï¼‰
    kernel = np.ones((3, 3), np.uint8)
    binary_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_OPEN, kernel)
    binary_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_CLOSE, kernel)

    # å°ã•ãªé ˜åŸŸã‚’é™¤å»
    labeled_mask, num_features = ndimage.label(binary_mask)

    for i in range(1, num_features + 1):
        region = (labeled_mask == i)
        if region.sum() < min_area:
            binary_mask[region] = 0

    return binary_mask

# å¾Œå‡¦ç†ã®ãƒ‡ãƒ¢
print("=== å¾Œå‡¦ç†ãƒ‡ãƒ¢ ===")

# ã‚µãƒ³ãƒ—ãƒ«äºˆæ¸¬ãƒã‚¹ã‚¯ï¼ˆãƒã‚¤ã‚ºã‚’å«ã‚€ï¼‰
np.random.seed(42)
H, W = 256, 256
pred_mask = np.random.rand(H, W) * 0.3  # ãƒã‚¤ã‚º

# çœŸã®é ˜åŸŸã‚’è¿½åŠ 
y, x = np.ogrid[:H, :W]
circle1 = ((x - 80)**2 + (y - 80)**2) <= 30**2
circle2 = ((x - 180)**2 + (y - 180)**2) <= 25**2
pred_mask[circle1] = 0.9
pred_mask[circle2] = 0.85

# ãƒ©ãƒ³ãƒ€ãƒ ãƒã‚¤ã‚ºã‚’è¿½åŠ 
noise_points = np.random.rand(H, W) > 0.98
pred_mask[noise_points] = 0.7

# å¾Œå‡¦ç†
processed_mask = post_process_mask(pred_mask, threshold=0.5, min_area=50)

# å¯è¦–åŒ–
fig, axes = plt.subplots(1, 3, figsize=(15, 5))

axes[0].imshow(pred_mask, cmap='viridis')
axes[0].set_title('äºˆæ¸¬ãƒã‚¹ã‚¯ï¼ˆç”Ÿï¼‰', fontsize=14)
axes[0].axis('off')

axes[1].imshow(pred_mask > 0.5, cmap='gray')
axes[1].set_title('äºŒå€¤åŒ–ã®ã¿', fontsize=14)
axes[1].axis('off')

axes[2].imshow(processed_mask, cmap='gray')
axes[2].set_title('å¾Œå‡¦ç†å¾Œ', fontsize=14)
axes[2].axis('off')

plt.tight_layout()
plt.show()

print(f"å¾Œå‡¦ç†å‰ã®é ˜åŸŸæ•°: {ndimage.label(pred_mask > 0.5)[1]}")
print(f"å¾Œå‡¦ç†å¾Œã®é ˜åŸŸæ•°: {ndimage.label(processed_mask)[1]}")
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>=== å¾Œå‡¦ç†ãƒ‡ãƒ¢ ===
å¾Œå‡¦ç†å‰ã®é ˜åŸŸæ•°: 15
å¾Œå‡¦ç†å¾Œã®é ˜åŸŸæ•°: 2
</code></pre>

<blockquote>
<p><strong>é‡è¦</strong>: å¾Œå‡¦ç†ã«ã‚ˆã‚Šã€ãƒã‚¤ã‚ºã‚’é™¤å»ã—ã€ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³çµæœã®å“è³ªã‚’å‘ä¸Šã§ãã¾ã™ã€‚</p>
</blockquote>

<hr>

<h2>4.7 æœ¬ç« ã®ã¾ã¨ã‚</h2>

<h3>å­¦ã‚“ã ã“ã¨</h3>

<ol>
<li><p><strong>ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã®ç¨®é¡</strong></p>
<ul>
<li>Semantic Segmentation: ãƒ”ã‚¯ã‚»ãƒ«åˆ†é¡</li>
<li>Instance Segmentation: ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åˆ†é›¢</li>
<li>Panoptic Segmentation: çµ±åˆçš„ç†è§£</li>
<li>è©•ä¾¡æŒ‡æ¨™: IoUã€Diceä¿‚æ•°ã€mIoU</li>
</ul></li>

<li><p><strong>U-Net</strong></p>
<ul>
<li>Encoder-Decoderæ§‹é€ </li>
<li>Skip Connectionsã§é«˜è§£åƒåº¦æƒ…å ±ã‚’ä¿æŒ</li>
<li>åŒ»ç™‚ç”»åƒã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã§é«˜ç²¾åº¦</li>
<li>å°‘é‡ãƒ‡ãƒ¼ã‚¿ã§ã‚‚åŠ¹æœçš„</li>
</ul></li>

<li><p><strong>é«˜åº¦ãªã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£</strong></p>
<ul>
<li>DeepLab: Atrous Convolutionã¨ASPP</li>
<li>PSPNet: Pyramid Pooling Module</li>
<li>HRNet: é«˜è§£åƒåº¦è¡¨ç¾ã®ç¶­æŒ</li>
<li>SegFormer: Transformerãƒ™ãƒ¼ã‚¹ã®åŠ¹ç‡çš„ãƒ¢ãƒ‡ãƒ«</li>
</ul></li>

<li><p><strong>Instance Segmentation</strong></p>
<ul>
<li>Mask R-CNN: RoI Alignã¨Mask Branch</li>
<li>YOLACT: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‡¦ç†</li>
<li>SOLOv2: ä½ç½®ãƒ™ãƒ¼ã‚¹åˆ†é›¢</li>
<li>Detectron2: å¼·åŠ›ãªãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯</li>
</ul></li>

<li><p><strong>å®Ÿè·µãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³</strong></p>
<ul>
<li>ãƒ‡ãƒ¼ã‚¿æº–å‚™ã¨å‰å‡¦ç†</li>
<li>å­¦ç¿’ã¨æ¤œè¨¼ã®ãƒ«ãƒ¼ãƒ—</li>
<li>å¾Œå‡¦ç†ã«ã‚ˆã‚‹ãƒã‚¤ã‚ºé™¤å»</li>
<li>ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜ã¨å†åˆ©ç”¨</li>
</ul></li>
</ol>

<h3>ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³æ‰‹æ³•ã®é¸æŠã‚¬ã‚¤ãƒ‰</h3>

<table>
<thead>
<tr>
<th>ã‚¿ã‚¹ã‚¯</th>
<th>æ¨å¥¨æ‰‹æ³•</th>
<th>ç†ç”±</th>
</tr>
</thead>
<tbody>
<tr>
<td>åŒ»ç™‚ç”»åƒ</td>
<td>U-Net</td>
<td>å°‘é‡ãƒ‡ãƒ¼ã‚¿ã§é«˜ç²¾åº¦</td>
</tr>
<tr>
<td>è‡ªå‹•é‹è»¢ï¼ˆã‚·ãƒ¼ãƒ³ç†è§£ï¼‰</td>
<td>DeepLabã€PSPNet</td>
<td>ãƒãƒ«ãƒã‚¹ã‚±ãƒ¼ãƒ«å‡¦ç†</td>
</tr>
<tr>
<td>ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åˆ†é›¢</td>
<td>Mask R-CNN</td>
<td>é«˜ç²¾åº¦ã€æŸ”è»Ÿæ€§</td>
</tr>
<tr>
<td>ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‡¦ç†</td>
<td>YOLACT</td>
<td>é«˜é€Ÿ</td>
</tr>
<tr>
<td>å¢ƒç•Œã®ç²¾åº¦é‡è¦–</td>
<td>HRNet</td>
<td>é«˜è§£åƒåº¦ç¶­æŒ</td>
</tr>
<tr>
<td>åŠ¹ç‡æ€§é‡è¦–</td>
<td>SegFormer</td>
<td>ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŠ¹ç‡</td>
</tr>
</tbody>
</table>

<h3>æ¬¡ã®ç« ã¸</h3>

<p>ç¬¬5ç« ã§ã¯ã€<strong>ç‰©ä½“è¿½è·¡ï¼ˆObject Trackingï¼‰</strong>ã‚’å­¦ã³ã¾ã™ï¼š</p>
<ul>
<li>Single Object Tracking (SOT)</li>
<li>Multiple Object Tracking (MOT)</li>
<li>DeepSORTã€FairMOT</li>
<li>ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¿½è·¡ã‚·ã‚¹ãƒ†ãƒ </li>
</ul>

<hr>

<h2>æ¼”ç¿’å•é¡Œ</h2>

<h3>å•é¡Œ1ï¼ˆé›£æ˜“åº¦ï¼šeasyï¼‰</h3>
<p>Semantic Segmentationã¨Instance Segmentationã®é•ã„ã‚’èª¬æ˜ã—ã€ãã‚Œãã‚Œã®ç”¨é€”ä¾‹ã‚’æŒ™ã’ã¦ãã ã•ã„ã€‚</p>

<details>
<summary>è§£ç­”ä¾‹</summary>

<p><strong>è§£ç­”</strong>ï¼š</p>

<p><strong>Semantic Segmentation</strong>ï¼š</p>
<ul>
<li>èª¬æ˜: å„ãƒ”ã‚¯ã‚»ãƒ«ã‚’ã‚¯ãƒ©ã‚¹ã«åˆ†é¡ã™ã‚‹ãŒã€åŒã˜ã‚¯ãƒ©ã‚¹ã®ç•°ãªã‚‹ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã¯åŒºåˆ¥ã—ãªã„</li>
<li>å‡ºåŠ›: ã‚¯ãƒ©ã‚¹ãƒ©ãƒ™ãƒ«ãƒãƒƒãƒ—ï¼ˆå„ãƒ”ã‚¯ã‚»ãƒ«ã«ã‚¯ãƒ©ã‚¹IDã‚’å‰²ã‚Šå½“ã¦ï¼‰</li>
<li>ç”¨é€”ä¾‹:
<ul>
<li>è‡ªå‹•é‹è»¢: é“è·¯ã€æ­©é“ã€å»ºç‰©ãªã©ã®ã‚·ãƒ¼ãƒ³ç†è§£</li>
<li>è¡›æ˜Ÿç”»åƒ: æ£®æ—ã€éƒ½å¸‚ã€æ°´åŸŸã®åˆ†é¡</li>
<li>åŒ»ç™‚ç”»åƒ: è‡“å™¨ã‚„ç—…å¤‰ã®é ˜åŸŸç‰¹å®š</li>
</ul></li>
</ul>

<p><strong>Instance Segmentation</strong>ï¼š</p>
<ul>
<li>èª¬æ˜: åŒã˜ã‚¯ãƒ©ã‚¹ã§ã‚‚ç•°ãªã‚‹ç‰©ä½“ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’åŒºåˆ¥ã™ã‚‹</li>
<li>å‡ºåŠ›: ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã”ã¨ã®å€‹åˆ¥ãƒã‚¹ã‚¯</li>
<li>ç”¨é€”ä¾‹:
<ul>
<li>ãƒ­ãƒœãƒƒãƒˆå·¥å­¦: å€‹åˆ¥ã®ç‰©ä½“ã‚’èªè­˜ã—ã¦æŠŠæŒ</li>
<li>ç´°èƒã‚«ã‚¦ãƒ³ãƒˆ: é¡•å¾®é¡ç”»åƒã§å€‹ã€…ã®ç´°èƒã‚’åˆ†é›¢</li>
<li>ç”»åƒç·¨é›†: ç‰¹å®šã®äººç‰©ã‚„ç‰©ä½“ã®ã¿ã‚’æŠ½å‡º</li>
</ul></li>
</ul>

<p><strong>ä¸»ãªé•ã„</strong>ï¼š</p>

<table>
<thead>
<tr>
<th>é …ç›®</th>
<th>Semantic Segmentation</th>
<th>Instance Segmentation</th>
</tr>
</thead>
<tbody>
<tr>
<td>ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒºåˆ¥</td>
<td>ãªã—</td>
<td>ã‚ã‚Š</td>
</tr>
<tr>
<td>å‡ºåŠ›</td>
<td>ã‚¯ãƒ©ã‚¹ãƒãƒƒãƒ—</td>
<td>å€‹åˆ¥ãƒã‚¹ã‚¯</td>
</tr>
<tr>
<td>è¤‡é›‘åº¦</td>
<td>ä½</td>
<td>é«˜</td>
</tr>
</tbody>
</table>

</details>

<h3>å•é¡Œ2ï¼ˆé›£æ˜“åº¦ï¼šmediumï¼‰</h3>
<p>IoUã¨Diceä¿‚æ•°ã‚’è¨ˆç®—ã™ã‚‹é–¢æ•°ã‚’å®Ÿè£…ã—ã€ä»¥ä¸‹ã®2ã¤ã®ãƒã‚¹ã‚¯ã«å¯¾ã—ã¦ä¸¡æ–¹ã®æŒ‡æ¨™ã‚’è¨ˆç®—ã—ã¦ãã ã•ã„ã€‚</p>

<pre><code class="language-python">import numpy as np

# ãƒã‚¹ã‚¯1ï¼ˆæ­£è§£ï¼‰
mask1 = np.array([
    [0, 0, 1, 1, 0],
    [0, 1, 1, 1, 0],
    [1, 1, 1, 1, 1],
    [0, 1, 1, 1, 0],
    [0, 0, 1, 1, 0]
])

# ãƒã‚¹ã‚¯2ï¼ˆäºˆæ¸¬ï¼‰
mask2 = np.array([
    [0, 0, 0, 1, 1],
    [0, 0, 1, 1, 1],
    [0, 1, 1, 1, 1],
    [0, 1, 1, 1, 0],
    [0, 0, 1, 1, 0]
])
</code></pre>

<details>
<summary>è§£ç­”ä¾‹</summary>

<pre><code class="language-python">import numpy as np

def calculate_iou(mask1, mask2):
    """IoUè¨ˆç®—"""
    intersection = np.logical_and(mask1, mask2).sum()
    union = np.logical_or(mask1, mask2).sum()

    if union == 0:
        return 0.0

    iou = intersection / union
    return iou

def calculate_dice(mask1, mask2):
    """Diceä¿‚æ•°è¨ˆç®—"""
    intersection = np.logical_and(mask1, mask2).sum()

    dice = (2.0 * intersection) / (mask1.sum() + mask2.sum())
    return dice

# ãƒã‚¹ã‚¯1ï¼ˆæ­£è§£ï¼‰
mask1 = np.array([
    [0, 0, 1, 1, 0],
    [0, 1, 1, 1, 0],
    [1, 1, 1, 1, 1],
    [0, 1, 1, 1, 0],
    [0, 0, 1, 1, 0]
])

# ãƒã‚¹ã‚¯2ï¼ˆäºˆæ¸¬ï¼‰
mask2 = np.array([
    [0, 0, 0, 1, 1],
    [0, 0, 1, 1, 1],
    [0, 1, 1, 1, 1],
    [0, 1, 1, 1, 0],
    [0, 0, 1, 1, 0]
])

# è¨ˆç®—
iou = calculate_iou(mask1, mask2)
dice = calculate_dice(mask1, mask2)

print("=== è©•ä¾¡æŒ‡æ¨™ã®è¨ˆç®— ===")
print(f"IoU: {iou:.4f}")
print(f"Diceä¿‚æ•°: {dice:.4f}")

# è©³ç´°åˆ†æ
intersection = np.logical_and(mask1, mask2).sum()
union = np.logical_or(mask1, mask2).sum()

print(f"\nè©³ç´°:")
print(f"  Intersectionï¼ˆé‡ãªã‚Šï¼‰: {intersection} ãƒ”ã‚¯ã‚»ãƒ«")
print(f"  Unionï¼ˆå’Œé›†åˆï¼‰: {union} ãƒ”ã‚¯ã‚»ãƒ«")
print(f"  Mask1ã®é¢ç©: {mask1.sum()} ãƒ”ã‚¯ã‚»ãƒ«")
print(f"  Mask2ã®é¢ç©: {mask2.sum()} ãƒ”ã‚¯ã‚»ãƒ«")
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>=== è©•ä¾¡æŒ‡æ¨™ã®è¨ˆç®— ===
IoU: 0.6111
Diceä¿‚æ•°: 0.7586

è©³ç´°:
  Intersectionï¼ˆé‡ãªã‚Šï¼‰: 11 ãƒ”ã‚¯ã‚»ãƒ«
  Unionï¼ˆå’Œé›†åˆï¼‰: 18 ãƒ”ã‚¯ã‚»ãƒ«
  Mask1ã®é¢ç©: 13 ãƒ”ã‚¯ã‚»ãƒ«
  Mask2ã®é¢ç©: 14 ãƒ”ã‚¯ã‚»ãƒ«
</code></pre>

</details>

<h3>å•é¡Œ3ï¼ˆé›£æ˜“åº¦ï¼šmediumï¼‰</h3>
<p>U-Netã«ãŠã‘ã‚‹Skip Connectionsã®å½¹å‰²ã‚’èª¬æ˜ã—ã€ãã‚ŒãŒãªã‹ã£ãŸå ´åˆã«ã©ã®ã‚ˆã†ãªå•é¡ŒãŒç™ºç”Ÿã™ã‚‹ã‹è¿°ã¹ã¦ãã ã•ã„ã€‚</p>

<details>
<summary>è§£ç­”ä¾‹</summary>

<p><strong>è§£ç­”</strong>ï¼š</p>

<p><strong>Skip Connectionsã®å½¹å‰²</strong>ï¼š</p>

<ol>
<li><p><strong>é«˜è§£åƒåº¦æƒ…å ±ã®ä¿æŒ</strong></p>
<ul>
<li>Encoderã®æµ…ã„å±¤ã‹ã‚‰Decoderã®å¯¾å¿œã™ã‚‹å±¤ã¸ç‰¹å¾´ã‚’ç›´æ¥ä¼é”</li>
<li>ãƒ€ã‚¦ãƒ³ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã§å¤±ã‚ã‚Œã‚‹è©³ç´°æƒ…å ±ã‚’è£œå®Œ</li>
</ul></li>

<li><p><strong>å‹¾é…ã®æµã‚Œã®æ”¹å–„</strong></p>
<ul>
<li>æ·±ã„ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã§ã®å‹¾é…æ¶ˆå¤±å•é¡Œã‚’ç·©å’Œ</li>
<li>å­¦ç¿’ã®å®‰å®šåŒ–ã¨é«˜é€ŸåŒ–</li>
</ul></li>

<li><p><strong>ä½ç½®æƒ…å ±ã®ç²¾åº¦å‘ä¸Š</strong></p>
<ul>
<li>å…ƒç”»åƒã®ç©ºé–“çš„ä½ç½®æƒ…å ±ã‚’ä¿æŒ</li>
<li>æ­£ç¢ºãªå¢ƒç•Œæ¤œå‡ºã‚’å¯èƒ½ã«ã™ã‚‹</li>
</ul></li>

<li><p><strong>ãƒãƒ«ãƒã‚¹ã‚±ãƒ¼ãƒ«ç‰¹å¾´ã®çµ±åˆ</strong></p>
<ul>
<li>ç•°ãªã‚‹æŠ½è±¡åº¦ã®ç‰¹å¾´ã‚’çµ„ã¿åˆã‚ã›ã‚‹</li>
<li>å¤§ããªç‰©ä½“ã¨å°ã•ãªç‰©ä½“ã®ä¸¡æ–¹ã‚’æ‰ãˆã‚‹</li>
</ul></li>
</ol>

<p><strong>Skip ConnectionsãŒãªã„å ´åˆã®å•é¡Œ</strong>ï¼š</p>

<table>
<thead>
<tr>
<th>å•é¡Œ</th>
<th>èª¬æ˜</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>å¢ƒç•Œã®æ›–æ˜§åŒ–</strong></td>
<td>ç‰©ä½“ã®è¼ªéƒ­ãŒä¸æ˜ç­ã«ãªã‚‹</td>
</tr>
<tr>
<td><strong>å°ã•ãªæ§‹é€ ã®æ¶ˆå¤±</strong></td>
<td>ç´°ã‹ã„è©³ç´°ãŒå†ç¾ã•ã‚Œãªã„</td>
</tr>
<tr>
<td><strong>ä½ç½®ç²¾åº¦ã®ä½ä¸‹</strong></td>
<td>äºˆæ¸¬ä½ç½®ãŒãšã‚Œã‚‹</td>
</tr>
<tr>
<td><strong>å­¦ç¿’ã®å›°é›£</strong></td>
<td>æ·±ã„ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã§ã®å‹¾é…æ¶ˆå¤±</td>
</tr>
</tbody>
</table>

<p><strong>å®Ÿé¨“çš„æ¤œè¨¼</strong>ï¼š</p>
<pre><code class="language-python"># Skip Connectionsã‚ã‚Šã¨ãªã—ã®æ¯”è¼ƒï¼ˆæ¦‚å¿µï¼‰

# ã‚ã‚Š: U-Netæ¨™æº–
# â†’ é®®æ˜ãªå¢ƒç•Œã€è©³ç´°ãªæ§‹é€ ã®ä¿æŒ

# ãªã—: å˜ç´”ãªEncoder-Decoder
# â†’ ã¼ã‚„ã‘ãŸå¢ƒç•Œã€è©³ç´°ã®æå¤±
</code></pre>

</details>

<h3>å•é¡Œ4ï¼ˆé›£æ˜“åº¦ï¼šhardï¼‰</h3>
<p>Mask R-CNNã®3ã¤ã®å‡ºåŠ›ãƒ–ãƒ©ãƒ³ãƒï¼ˆåˆ†é¡ã€BBoxã€ãƒã‚¹ã‚¯ï¼‰ãã‚Œãã‚Œã®æå¤±é–¢æ•°ã‚’èª¬æ˜ã—ã€å…¨ä½“ã®æå¤±é–¢æ•°ãŒã©ã®ã‚ˆã†ã«å®šç¾©ã•ã‚Œã‚‹ã‹è¿°ã¹ã¦ãã ã•ã„ã€‚</p>

<details>
<summary>è§£ç­”ä¾‹</summary>

<p><strong>è§£ç­”</strong>ï¼š</p>

<p>Mask R-CNNã¯ã€Multi-task Learningã®æ çµ„ã¿ã§3ã¤ã®ã‚¿ã‚¹ã‚¯ã‚’åŒæ™‚ã«å­¦ç¿’ã—ã¾ã™ã€‚</p>

<p><strong>1. åˆ†é¡ãƒ–ãƒ©ãƒ³ãƒï¼ˆClassificationï¼‰</strong>ï¼š</p>
<ul>
<li>ç›®çš„: RoIï¼ˆRegion of Interestï¼‰ã®ã‚¯ãƒ©ã‚¹åˆ†é¡</li>
<li>æå¤±é–¢æ•°: Cross Entropy Loss</li>
</ul>

<p>$$
L_{\text{cls}} = -\log p_{\text{true\_class}}
$$</p>

<p><strong>2. ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ãƒ–ãƒ©ãƒ³ãƒï¼ˆBBox Regressionï¼‰</strong>ï¼š</p>
<ul>
<li>ç›®çš„: BBoxã®ä½ç½®ã¨ã‚µã‚¤ã‚ºã®å›å¸°</li>
<li>æå¤±é–¢æ•°: Smooth L1 Loss</li>
</ul>

<p>$$
L_{\text{box}} = \sum_{i \in \{x, y, w, h\}} \text{smooth}_{L1}(t_i - t_i^*)
$$</p>

<p>where:
$$
\text{smooth}_{L1}(x) = \begin{cases}
0.5x^2 & \text{if } |x| < 1 \\
|x| - 0.5 & \text{otherwise}
\end{cases}
$$</p>

<p><strong>3. ãƒã‚¹ã‚¯ãƒ–ãƒ©ãƒ³ãƒï¼ˆMask Predictionï¼‰</strong>ï¼š</p>
<ul>
<li>ç›®çš„: å„ãƒ”ã‚¯ã‚»ãƒ«ã®äºŒå€¤ãƒã‚¹ã‚¯äºˆæ¸¬</li>
<li>æå¤±é–¢æ•°: Binary Cross Entropy Lossï¼ˆãƒ”ã‚¯ã‚»ãƒ«å˜ä½ï¼‰</li>
</ul>

<p>$$
L_{\text{mask}} = -\frac{1}{m^2} \sum_{i,j} [y_{ij} \log \hat{y}_{ij} + (1-y_{ij}) \log(1-\hat{y}_{ij})]
$$</p>

<p>where $m \times m$ ã¯ãƒã‚¹ã‚¯ã®è§£åƒåº¦</p>

<p><strong>å…¨ä½“ã®æå¤±é–¢æ•°</strong>ï¼š</p>

<p>$$
L = L_{\text{cls}} + L_{\text{box}} + L_{\text{mask}}
$$</p>

<p><strong>å®Ÿè£…ä¾‹</strong>ï¼š</p>
<pre><code class="language-python">import torch
import torch.nn as nn
import torch.nn.functional as F

class MaskRCNNLoss:
    """Mask R-CNNã®æå¤±é–¢æ•°"""

    def __init__(self):
        self.cls_loss_fn = nn.CrossEntropyLoss()
        self.mask_loss_fn = nn.BCEWithLogitsLoss()

    def smooth_l1_loss(self, pred, target, beta=1.0):
        """Smooth L1 Loss"""
        diff = torch.abs(pred - target)
        loss = torch.where(
            diff < beta,
            0.5 * diff ** 2 / beta,
            diff - 0.5 * beta
        )
        return loss.mean()

    def __call__(self, cls_pred, bbox_pred, mask_pred,
                 cls_target, bbox_target, mask_target):
        """
        å…¨ä½“ã®æå¤±è¨ˆç®—

        Args:
            cls_pred: ã‚¯ãƒ©ã‚¹äºˆæ¸¬ (N, num_classes)
            bbox_pred: BBoxäºˆæ¸¬ (N, 4)
            mask_pred: ãƒã‚¹ã‚¯äºˆæ¸¬ (N, num_classes, H, W)
            cls_target: ã‚¯ãƒ©ã‚¹æ­£è§£ (N,)
            bbox_target: BBoxæ­£è§£ (N, 4)
            mask_target: ãƒã‚¹ã‚¯æ­£è§£ (N, H, W)

        Returns:
            total_loss, loss_dict
        """
        # åˆ†é¡æå¤±
        loss_cls = self.cls_loss_fn(cls_pred, cls_target)

        # BBoxæå¤±
        loss_bbox = self.smooth_l1_loss(bbox_pred, bbox_target)

        # ãƒã‚¹ã‚¯æå¤±ï¼ˆè©²å½“ã‚¯ãƒ©ã‚¹ã®ãƒã‚¹ã‚¯ã®ã¿ï¼‰
        # å®Ÿéš›ã«ã¯ã‚¯ãƒ©ã‚¹ã”ã¨ã«ãƒã‚¹ã‚¯ã‚’äºˆæ¸¬ã—ã€æ­£è§£ã‚¯ãƒ©ã‚¹ã®ãƒã‚¹ã‚¯ã®ã¿ä½¿ç”¨
        loss_mask = self.mask_loss_fn(mask_pred, mask_target)

        # å…¨ä½“æå¤±
        total_loss = loss_cls + loss_bbox + loss_mask

        loss_dict = {
            'loss_cls': loss_cls.item(),
            'loss_bbox': loss_bbox.item(),
            'loss_mask': loss_mask.item(),
            'total_loss': total_loss.item()
        }

        return total_loss, loss_dict

# ä½¿ç”¨ä¾‹ï¼ˆãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ï¼‰
loss_fn = MaskRCNNLoss()

# ãƒ€ãƒŸãƒ¼äºˆæ¸¬ã¨æ­£è§£
cls_pred = torch.randn(10, 80)  # 10 RoIs, 80 classes
bbox_pred = torch.randn(10, 4)
mask_pred = torch.randn(10, 1, 28, 28)
cls_target = torch.randint(0, 80, (10,))
bbox_target = torch.randn(10, 4)
mask_target = torch.randint(0, 2, (10, 1, 28, 28)).float()

total_loss, loss_dict = loss_fn(
    cls_pred, bbox_pred, mask_pred,
    cls_target, bbox_target, mask_target
)

print("=== Mask R-CNNæå¤± ===")
for key, value in loss_dict.items():
    print(f"{key}: {value:.4f}")
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>=== Mask R-CNNæå¤± ===
loss_cls: 4.3821
loss_bbox: 0.8234
loss_mask: 0.6931
total_loss: 5.8986
</code></pre>

<p><strong>é‡è¦ãªãƒã‚¤ãƒ³ãƒˆ</strong>ï¼š</p>
<ul>
<li>3ã¤ã®æå¤±ã¯å˜ç´”ã«åŠ ç®—ã•ã‚Œã‚‹ï¼ˆé‡ã¿ä»˜ã‘ã‚‚å¯èƒ½ï¼‰</li>
<li>ãƒã‚¹ã‚¯æå¤±ã¯è©²å½“ã‚¯ãƒ©ã‚¹ã®ãƒã‚¹ã‚¯ã®ã¿è¨ˆç®—ã•ã‚Œã‚‹</li>
<li>å­¦ç¿’æ™‚ã¯å…¨ã¦ã®æå¤±ã‚’åŒæ™‚ã«æœ€å°åŒ–</li>
</ul>

</details>

<h3>å•é¡Œ5ï¼ˆé›£æ˜“åº¦ï¼šhardï¼‰</h3>
<p>åŒ»ç™‚ç”»åƒã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã§ã€ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡ï¼ˆå‰æ™¯ãƒ”ã‚¯ã‚»ãƒ«ãŒå…¨ä½“ã®5%ä»¥ä¸‹ï¼‰ãŒç™ºç”Ÿã—ã¦ã„ã‚‹å ´åˆã€ã©ã®ã‚ˆã†ãªæå¤±é–¢æ•°ã‚„å­¦ç¿’æˆ¦ç•¥ã‚’ç”¨ã„ã‚‹ã¹ãã‹ææ¡ˆã—ã¦ãã ã•ã„ã€‚</p>

<details>
<summary>è§£ç­”ä¾‹</summary>

<p><strong>è§£ç­”</strong>ï¼š</p>

<p>åŒ»ç™‚ç”»åƒã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã§ã¯ã€ç—…å¤‰é ˜åŸŸãŒéå¸¸ã«å°ã•ã„ã“ã¨ãŒå¤šãã€ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡ãŒæ·±åˆ»ãªå•é¡Œã§ã™ã€‚ä»¥ä¸‹ã®æˆ¦ç•¥ã‚’çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ãŒåŠ¹æœçš„ã§ã™ã€‚</p>

<p><strong>1. æå¤±é–¢æ•°ã®æ”¹å–„</strong>ï¼š</p>

<h4>ï¼ˆaï¼‰Focal Loss</h4>
<p>ç°¡å˜ãªä¾‹ï¼ˆèƒŒæ™¯ï¼‰ã®æå¤±ã‚’æŠ‘åˆ¶ã—ã€é›£ã—ã„ä¾‹ï¼ˆå¢ƒç•Œï¼‰ã«ç„¦ç‚¹ã‚’å½“ã¦ã¾ã™ã€‚</p>

<p>$$
\text{FL}(p_t) = -(1 - p_t)^\gamma \log(p_t)
$$</p>

<pre><code class="language-python">class FocalLoss(nn.Module):
    def __init__(self, alpha=0.25, gamma=2.0):
        super().__init__()
        self.alpha = alpha
        self.gamma = gamma

    def forward(self, pred, target):
        pred = torch.sigmoid(pred)

        # Focal weight
        pt = torch.where(target == 1, pred, 1 - pred)
        focal_weight = (1 - pt) ** self.gamma

        # BCE with focal weight
        bce = F.binary_cross_entropy(pred, target, reduction='none')
        focal_loss = self.alpha * focal_weight * bce

        return focal_loss.mean()
</code></pre>

<h4>ï¼ˆbï¼‰Tversky Loss</h4>
<p>FalsePositiveã¨FalseNegativeã®ãƒãƒ©ãƒ³ã‚¹ã‚’èª¿æ•´ã§ãã¾ã™ã€‚</p>

<p>$$
\text{TL} = 1 - \frac{TP}{TP + \alpha FP + \beta FN}
$$</p>

<pre><code class="language-python">class TverskyLoss(nn.Module):
    def __init__(self, alpha=0.3, beta=0.7, smooth=1.0):
        super().__init__()
        self.alpha = alpha  # FPã®é‡ã¿
        self.beta = beta    # FNã®é‡ã¿
        self.smooth = smooth

    def forward(self, pred, target):
        pred = torch.sigmoid(pred)

        TP = (pred * target).sum()
        FP = (pred * (1 - target)).sum()
        FN = ((1 - pred) * target).sum()

        tversky = (TP + self.smooth) / (
            TP + self.alpha * FP + self.beta * FN + self.smooth
        )

        return 1 - tversky
</code></pre>

<h4>ï¼ˆcï¼‰Dice Loss + BCE ã®çµ„ã¿åˆã‚ã›</h4>
<pre><code class="language-python">class CombinedLoss(nn.Module):
    def __init__(self, dice_weight=0.5, bce_weight=0.5):
        super().__init__()
        self.dice_loss = DiceLoss()
        self.bce_loss = nn.BCEWithLogitsLoss()
        self.dice_weight = dice_weight
        self.bce_weight = bce_weight

    def forward(self, pred, target):
        dice = self.dice_loss(pred, target)
        bce = self.bce_loss(pred, target)

        return self.dice_weight * dice + self.bce_weight * bce
</code></pre>

<p><strong>2. ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µæˆ¦ç•¥</strong>ï¼š</p>

<pre><code class="language-python">import albumentations as A

# åŒ»ç™‚ç”»åƒå‘ã‘ã®å¼·åŠ›ãªæ‹¡å¼µ
transform = A.Compose([
    A.RandomRotate90(p=0.5),
    A.Flip(p=0.5),
    A.ShiftScaleRotate(
        shift_limit=0.1,
        scale_limit=0.2,
        rotate_limit=45,
        p=0.5
    ),
    A.ElasticTransform(p=0.3),  # åŒ»ç™‚ç”»åƒã§æœ‰åŠ¹
    A.GridDistortion(p=0.3),
    A.RandomBrightnessContrast(p=0.5),
])
</code></pre>

<p><strong>3. ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æˆ¦ç•¥</strong>ï¼š</p>

<pre><code class="language-python">class BalancedSampler:
    """ç—…å¤‰é ˜åŸŸã‚’å«ã‚€ãƒ‘ãƒƒãƒã‚’å„ªå…ˆçš„ã«ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°"""

    def __init__(self, image, mask, patch_size=256,
                 positive_ratio=0.7):
        self.image = image
        self.mask = mask
        self.patch_size = patch_size
        self.positive_ratio = positive_ratio

    def sample_patch(self):
        H, W = self.image.shape[:2]

        if np.random.rand() < self.positive_ratio:
            # ç—…å¤‰é ˜åŸŸã‚’å«ã‚€ãƒ‘ãƒƒãƒ
            positive_coords = np.argwhere(self.mask > 0)
            if len(positive_coords) > 0:
                center = positive_coords[
                    np.random.randint(len(positive_coords))
                ]
                y, x = center
            else:
                y = np.random.randint(0, H)
                x = np.random.randint(0, W)
        else:
            # ãƒ©ãƒ³ãƒ€ãƒ ãƒ‘ãƒƒãƒ
            y = np.random.randint(0, H)
            x = np.random.randint(0, W)

        # ãƒ‘ãƒƒãƒæŠ½å‡ºï¼ˆå¢ƒç•Œå‡¦ç†å«ã‚€ï¼‰
        # ... (å®Ÿè£…çœç•¥)

        return patch_image, patch_mask
</code></pre>

<p><strong>4. å¾Œå‡¦ç†</strong>ï¼š</p>

<pre><code class="language-python">def post_process_with_threshold_optimization(pred_mask, true_mask):
    """æœ€é©é–¾å€¤ã®æ¢ç´¢"""
    best_threshold = 0.5
    best_dice = 0.0

    for threshold in np.arange(0.1, 0.9, 0.05):
        binary_pred = (pred_mask > threshold).astype(int)
        dice = calculate_dice(binary_pred, true_mask)

        if dice > best_dice:
            best_dice = dice
            best_threshold = threshold

    return best_threshold, best_dice
</code></pre>

<p><strong>æ¨å¥¨ã•ã‚Œã‚‹çµ±åˆæˆ¦ç•¥</strong>ï¼š</p>

<table>
<thead>
<tr>
<th>æ‰‹æ³•</th>
<th>å„ªå…ˆåº¦</th>
<th>ç†ç”±</th>
</tr>
</thead>
<tbody>
<tr>
<td>Dice + BCE Loss</td>
<td>é«˜</td>
<td>ä¸å‡è¡¡ã«é ‘å¥</td>
</tr>
<tr>
<td>Focal Loss</td>
<td>é«˜</td>
<td>é›£ã—ã„ä¾‹ã«ç„¦ç‚¹</td>
</tr>
<tr>
<td>Tversky Loss</td>
<td>ä¸­</td>
<td>FP/FNèª¿æ•´å¯</td>
</tr>
<tr>
<td>ç—…å¤‰ä¸­å¿ƒã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°</td>
<td>é«˜</td>
<td>å­¦ç¿’åŠ¹ç‡å‘ä¸Š</td>
</tr>
<tr>
<td>å¼·åŠ›ãªãƒ‡ãƒ¼ã‚¿æ‹¡å¼µ</td>
<td>é«˜</td>
<td>æ±åŒ–æ€§èƒ½å‘ä¸Š</td>
</tr>
<tr>
<td>é–¾å€¤æœ€é©åŒ–</td>
<td>ä¸­</td>
<td>æ¨è«–æ™‚ã®æ€§èƒ½å‘ä¸Š</td>
</tr>
</tbody>
</table>

</details>

<hr>

<h2>å‚è€ƒæ–‡çŒ®</h2>

<ol>
<li>Ronneberger, O., Fischer, P., & Brox, T. (2015). <em>U-Net: Convolutional Networks for Biomedical Image Segmentation</em>. MICCAI.</li>
<li>Chen, L. C., et al. (2018). <em>Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation</em>. ECCV.</li>
<li>He, K., et al. (2017). <em>Mask R-CNN</em>. ICCV.</li>
<li>Zhao, H., et al. (2017). <em>Pyramid Scene Parsing Network</em>. CVPR.</li>
<li>Wang, J., et al. (2020). <em>Deep High-Resolution Representation Learning for Visual Recognition</em>. TPAMI.</li>
<li>Xie, E., et al. (2021). <em>SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers</em>. NeurIPS.</li>
<li>Bolya, D., et al. (2019). <em>YOLACT: Real-time Instance Segmentation</em>. ICCV.</li>
<li>Wu, Y., et al. (2019). <em>Detectron2</em>. Facebook AI Research.</li>
</ol>

<div class="navigation">
    <a href="chapter3-object-detection.html" class="nav-button">â† å‰ã®ç« : ç‰©ä½“æ¤œå‡º</a>
    <a href="chapter5-object-tracking.html" class="nav-button">æ¬¡ã®ç« : ç‰©ä½“è¿½è·¡ â†’</a>
</div>

    </main>

    
    <section class="disclaimer">
        <h3>å…è²¬äº‹é …</h3>
        <ul>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯æ•™è‚²ãƒ»ç ”ç©¶ãƒ»æƒ…å ±æä¾›ã®ã¿ã‚’ç›®çš„ã¨ã—ã¦ãŠã‚Šã€å°‚é–€çš„ãªåŠ©è¨€(æ³•å¾‹ãƒ»ä¼šè¨ˆãƒ»æŠ€è¡“çš„ä¿è¨¼ãªã©)ã‚’æä¾›ã™ã‚‹ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŠã‚ˆã³ä»˜éšã™ã‚‹ã‚³ãƒ¼ãƒ‰ä¾‹ã¯ã€Œç¾çŠ¶æœ‰å§¿(AS IS)ã€ã§æä¾›ã•ã‚Œã€æ˜ç¤ºã¾ãŸã¯é»™ç¤ºã‚’å•ã‚ãšã€å•†å“æ€§ã€ç‰¹å®šç›®çš„é©åˆæ€§ã€æ¨©åˆ©éä¾µå®³ã€æ­£ç¢ºæ€§ãƒ»å®Œå…¨æ€§ã€å‹•ä½œãƒ»å®‰å…¨æ€§ç­‰ã„ã‹ãªã‚‹ä¿è¨¼ã‚‚ã—ã¾ã›ã‚“ã€‚</li>
            <li>å¤–éƒ¨ãƒªãƒ³ã‚¯ã€ç¬¬ä¸‰è€…ãŒæä¾›ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ»ãƒ„ãƒ¼ãƒ«ãƒ»ãƒ©ã‚¤ãƒ–ãƒ©ãƒªç­‰ã®å†…å®¹ãƒ»å¯ç”¨æ€§ãƒ»å®‰å…¨æ€§ã«ã¤ã„ã¦ã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯ä¸€åˆ‡ã®è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®åˆ©ç”¨ãƒ»å®Ÿè¡Œãƒ»è§£é‡ˆã«ã‚ˆã‚Šç›´æ¥çš„ãƒ»é–“æ¥çš„ãƒ»ä»˜éšçš„ãƒ»ç‰¹åˆ¥ãƒ»çµæœçš„ãƒ»æ‡²ç½°çš„æå®³ãŒç”Ÿã˜ãŸå ´åˆã§ã‚‚ã€é©ç”¨æ³•ã§è¨±å®¹ã•ã‚Œã‚‹æœ€å¤§é™ã®ç¯„å›²ã§ã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å†…å®¹ã¯ã€äºˆå‘Šãªãå¤‰æ›´ãƒ»æ›´æ–°ãƒ»æä¾›åœæ­¢ã•ã‚Œã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®è‘—ä½œæ¨©ãƒ»ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯æ˜è¨˜ã•ã‚ŒãŸæ¡ä»¶(ä¾‹: CC BY 4.0)ã«å¾“ã„ã¾ã™ã€‚å½“è©²ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯é€šå¸¸ã€ç„¡ä¿è¨¼æ¡é …ã‚’å«ã¿ã¾ã™ã€‚</li>
        </ul>
    </section>

<footer>
        <p><strong>ä½œæˆè€…</strong>: AI Terakoya Content Team</p>
        <p><strong>ãƒãƒ¼ã‚¸ãƒ§ãƒ³</strong>: 1.0 | <strong>ä½œæˆæ—¥</strong>: 2025-10-21</p>
        <p><strong>ãƒ©ã‚¤ã‚»ãƒ³ã‚¹</strong>: Creative Commons BY 4.0</p>
        <p>Â© 2025 AI Terakoya. All rights reserved.</p>
    </footer>
</body>
</html>
