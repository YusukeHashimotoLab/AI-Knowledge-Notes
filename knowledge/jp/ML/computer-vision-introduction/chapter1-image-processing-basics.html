<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
<meta content="ç¬¬1ç« ï¼šç”»åƒå‡¦ç†ã®åŸºç¤ - AI Terakoya" name="description"/>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ç¬¬1ç« ï¼šç”»åƒå‡¦ç†ã®åŸºç¤ - AI Terakoya</title>

    <style>
        :root {
            --color-primary: #2c3e50;
            --color-primary-dark: #1a252f;
            --color-accent: #7b2cbf;
            --color-accent-light: #9d4edd;
            --color-text: #2d3748;
            --color-text-light: #4a5568;
            --color-bg: #ffffff;
            --color-bg-alt: #f7fafc;
            --color-border: #e2e8f0;
            --color-code-bg: #f8f9fa;
            --color-link: #3182ce;
            --color-link-hover: #2c5aa0;

            --spacing-xs: 0.5rem;
            --spacing-sm: 1rem;
            --spacing-md: 1.5rem;
            --spacing-lg: 2rem;
            --spacing-xl: 3rem;

            --font-body: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            --font-mono: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;

            --border-radius: 8px;
            --box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: var(--font-body);
            line-height: 1.7;
            color: var(--color-text);
            background-color: var(--color-bg);
            font-size: 16px;
        }

        header {
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            padding: var(--spacing-xl) var(--spacing-md);
            margin-bottom: var(--spacing-xl);
            box-shadow: var(--box-shadow);
        }

        .header-content {
            max-width: 900px;
            margin: 0 auto;
        }

        h1 {
            font-size: 2rem;
            font-weight: 700;
            margin-bottom: var(--spacing-sm);
            line-height: 1.2;
        }

        .subtitle {
            font-size: 1.1rem;
            opacity: 0.95;
            font-weight: 400;
            margin-bottom: var(--spacing-md);
        }

        .meta {
            display: flex;
            flex-wrap: wrap;
            gap: var(--spacing-md);
            font-size: 0.9rem;
            opacity: 0.9;
        }

        .meta-item {
            display: flex;
            align-items: center;
            gap: 0.3rem;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 0 var(--spacing-md) var(--spacing-xl);
        }

        h2 {
            font-size: 1.75rem;
            color: var(--color-primary);
            margin-top: var(--spacing-xl);
            margin-bottom: var(--spacing-md);
            padding-bottom: var(--spacing-xs);
            border-bottom: 3px solid var(--color-accent);
        }

        h3 {
            font-size: 1.4rem;
            color: var(--color-primary);
            margin-top: var(--spacing-lg);
            margin-bottom: var(--spacing-sm);
        }

        h4 {
            font-size: 1.1rem;
            color: var(--color-primary-dark);
            margin-top: var(--spacing-md);
            margin-bottom: var(--spacing-sm);
        }

        p {
            margin-bottom: var(--spacing-md);
            color: var(--color-text);
        }

        a {
            color: var(--color-link);
            text-decoration: none;
            transition: color 0.2s;
        }

        a:hover {
            color: var(--color-link-hover);
            text-decoration: underline;
        }

        ul, ol {
            margin-left: var(--spacing-lg);
            margin-bottom: var(--spacing-md);
        }

        li {
            margin-bottom: var(--spacing-xs);
            color: var(--color-text);
        }

        pre {
            background-color: var(--color-code-bg);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            overflow-x: auto;
            margin-bottom: var(--spacing-md);
            font-family: var(--font-mono);
            font-size: 0.9rem;
            line-height: 1.5;
        }

        code {
            font-family: var(--font-mono);
            font-size: 0.9em;
            background-color: var(--color-code-bg);
            padding: 0.2em 0.4em;
            border-radius: 3px;
        }

        pre code {
            background-color: transparent;
            padding: 0;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: var(--spacing-md);
            font-size: 0.95rem;
        }

        th, td {
            border: 1px solid var(--color-border);
            padding: var(--spacing-sm);
            text-align: left;
        }

        th {
            background-color: var(--color-bg-alt);
            font-weight: 600;
            color: var(--color-primary);
        }

        blockquote {
            border-left: 4px solid var(--color-accent);
            padding-left: var(--spacing-md);
            margin: var(--spacing-md) 0;
            color: var(--color-text-light);
            font-style: italic;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        .mermaid {
            text-align: center;
            margin: var(--spacing-lg) 0;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        details {
            background-color: var(--color-bg-alt);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            margin-bottom: var(--spacing-md);
        }

        summary {
            cursor: pointer;
            font-weight: 600;
            color: var(--color-primary);
            user-select: none;
            padding: var(--spacing-xs);
            margin: calc(-1 * var(--spacing-md));
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        summary:hover {
            background-color: rgba(123, 44, 191, 0.1);
        }

        details[open] summary {
            margin-bottom: var(--spacing-md);
            border-bottom: 1px solid var(--color-border);
        }

        .navigation {
            display: flex;
            justify-content: space-between;
            gap: var(--spacing-md);
            margin: var(--spacing-xl) 0;
            padding-top: var(--spacing-lg);
            border-top: 2px solid var(--color-border);
        }

        .nav-button {
            flex: 1;
            padding: var(--spacing-md);
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            border-radius: var(--border-radius);
            text-align: center;
            font-weight: 600;
            transition: transform 0.2s, box-shadow 0.2s;
            box-shadow: var(--box-shadow);
        }

        .nav-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
            text-decoration: none;
        }

        footer {
            margin-top: var(--spacing-xl);
            padding: var(--spacing-lg) var(--spacing-md);
            background-color: var(--color-bg-alt);
            border-top: 1px solid var(--color-border);
            text-align: center;
            font-size: 0.9rem;
            color: var(--color-text-light);
        }
        .disclaimer {
            max-width: 900px;
            margin: 2rem auto;
            padding: 1.5rem;
            background: #f8f9fa;
            border-left: 4px solid #6c757d;
            border-radius: 4px;
        }

        .disclaimer h3 {
            color: #495057;
            margin-bottom: 1rem;
            font-size: 1.1rem;
        }

        .disclaimer ul {
            list-style: none;
            padding-left: 0;
        }

        .disclaimer li {
            padding: 0.5rem 0;
            padding-left: 1.5rem;
            position: relative;
            font-size: 0.9rem;
            color: #6c757d;
            line-height: 1.6;
        }

        .disclaimer li::before {
            content: "âš ï¸";
            position: absolute;
            left: 0;
        }


        @media (max-width: 768px) {
            h1 {
                font-size: 1.5rem;
            }

            h2 {
                font-size: 1.4rem;
            }

            h3 {
                font-size: 1.2rem;
            }

            .meta {
                font-size: 0.85rem;
            }

            .navigation {
                flex-direction: column;
            }

            table {
                font-size: 0.85rem;
            }

            th, td {
                padding: var(--spacing-xs);
            }
        }
    
        
    
        /* Breadcrumb styles */
        .breadcrumb {
            background: #f7fafc;
            padding: 0.75rem 1rem;
            border-bottom: 1px solid #e2e8f0;
            font-size: 0.9rem;
        }

        .breadcrumb-content {
            max-width: 900px;
            margin: 0 auto;
            display: flex;
            align-items: center;
            flex-wrap: wrap;
            gap: 0.5rem;
        }

        .breadcrumb a {
            color: #667eea;
            text-decoration: none;
            transition: color 0.2s;
        }

        .breadcrumb a:hover {
            color: #764ba2;
            text-decoration: underline;
        }

        .breadcrumb-separator {
            color: #a0aec0;
            margin: 0 0.25rem;
        }

        .breadcrumb-current {
            color: #4a5568;
            font-weight: 500;
        }
    </style>

    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
        mermaid.initialize({ startOnLoad: true, theme: 'default' });
    </script>

    <!-- MathJax for LaTeX equation rendering -->
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                displayMath: [['$$', '$$'], ['\\[', '\\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
                ignoreHtmlClass: 'mermaid'
            }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" async></script>

    <style>
        /* Locale Switcher Styles */
        .locale-switcher {
            display: flex;
            align-items: center;
            gap: 0.5rem;
            padding: 0.5rem 1rem;
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
            border-radius: 6px;
            font-size: 0.9rem;
            margin-bottom: 1rem;
            box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);
        }

        .current-locale {
            font-weight: 600;
            color: #7b2cbf;
            display: flex;
            align-items: center;
            gap: 0.25rem;
        }

        .locale-separator {
            color: #adb5bd;
            font-weight: 300;
        }

        .locale-link {
            color: #f093fb;
            text-decoration: none;
            font-weight: 500;
            transition: all 0.2s ease;
            display: flex;
            align-items: center;
            gap: 0.25rem;
            padding: 0.2rem 0.5rem;
            border-radius: 4px;
        }

        .locale-link:hover {
            background: rgba(240, 147, 251, 0.1);
            color: #d07be8;
            transform: translateY(-1px);
        }

        .locale-meta {
            color: #868e96;
            font-size: 0.85rem;
            font-style: italic;
            margin-left: auto;
        }

        @media (max-width: 768px) {
            .locale-switcher {
                font-size: 0.85rem;
                padding: 0.4rem 0.8rem;
            }
            .locale-meta {
                display: none;
            }
        }
    </style>
</head>
<body>
            <div class="locale-switcher">
<span class="current-locale">ğŸŒ JP</span>
<span class="locale-separator">|</span>
<a href="../../../en/ML/computer-vision-introduction/chapter1-image-processing-basics.html" class="locale-link">ğŸ‡¬ğŸ‡§ EN</a>
<span class="locale-separator">|</span>
<span class="locale-meta">Last sync: 2025-11-16</span>
</div>
<nav class="breadcrumb">
        <div class="breadcrumb-content">
            <a href="../../index.html">AIå¯ºå­å±‹ãƒˆãƒƒãƒ—</a><span class="breadcrumb-separator">â€º</span><a href="../../ML/index.html">æ©Ÿæ¢°å­¦ç¿’</a><span class="breadcrumb-separator">â€º</span><a href="../../ML/computer-vision-introduction/index.html">Computer Vision</a><span class="breadcrumb-separator">â€º</span><span class="breadcrumb-current">Chapter 1</span>
        </div>
    </nav>

        <header>
        <div class="header-content">
            <h1>ç¬¬1ç« ï¼šç”»åƒå‡¦ç†ã®åŸºç¤</h1>
            <p class="subtitle">ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ãƒ“ã‚¸ãƒ§ãƒ³ã®ç¬¬ä¸€æ­© - ãƒ‡ã‚¸ã‚¿ãƒ«ç”»åƒã®è¡¨ç¾ã¨åŸºæœ¬å‡¦ç†ã‚’ç†è§£ã™ã‚‹</p>
            <div class="meta">
                <span class="meta-item">ğŸ“– èª­äº†æ™‚é–“: 30-35åˆ†</span>
                <span class="meta-item">ğŸ“Š é›£æ˜“åº¦: åˆç´š</span>
                <span class="meta-item">ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹: 10å€‹</span>
                <span class="meta-item">ğŸ“ æ¼”ç¿’å•é¡Œ: 5å•</span>
            </div>
        </div>
    </header>

    <main class="container">

<h2>å­¦ç¿’ç›®æ¨™</h2>
<p>ã“ã®ç« ã‚’èª­ã‚€ã“ã¨ã§ã€ä»¥ä¸‹ã‚’ç¿’å¾—ã§ãã¾ã™ï¼š</p>
<ul>
<li>âœ… ãƒ‡ã‚¸ã‚¿ãƒ«ç”»åƒã®è¡¨ç¾æ–¹æ³•ï¼ˆãƒ”ã‚¯ã‚»ãƒ«ã€ãƒãƒ£ãƒ³ãƒãƒ«ï¼‰ã‚’ç†è§£ã™ã‚‹</li>
<li>âœ… RGBã€HSVã€LABãªã©ã®ã‚«ãƒ©ãƒ¼ç©ºé–“ã®é•ã„ã¨ç”¨é€”ã‚’èª¬æ˜ã§ãã‚‹</li>
<li>âœ… OpenCVã¨PILã‚’ä½¿ã£ãŸç”»åƒã®èª­ã¿è¾¼ã¿ãƒ»ä¿å­˜ãƒ»è¡¨ç¤ºãŒã§ãã‚‹</li>
<li>âœ… ãƒªã‚µã‚¤ã‚ºã€å›è»¢ã€è‰²å¤‰æ›ãªã©ã®åŸºæœ¬çš„ãªç”»åƒå‡¦ç†ã‚’å®Ÿè£…ã§ãã‚‹</li>
<li>âœ… å¹³æ»‘åŒ–ã€ã‚¨ãƒƒã‚¸æ¤œå‡ºãªã©ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ‰‹æ³•ã‚’é©ç”¨ã§ãã‚‹</li>
<li>âœ… æ©Ÿæ¢°å­¦ç¿’ã®ãŸã‚ã®ç”»åƒãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’æ§‹ç¯‰ã§ãã‚‹</li>
</ul>

<hr>

<h2>1.1 ç”»åƒã®è¡¨ç¾</h2>

<h3>ãƒ‡ã‚¸ã‚¿ãƒ«ç”»åƒã¨ãƒ”ã‚¯ã‚»ãƒ«</h3>

<p><strong>ãƒ‡ã‚¸ã‚¿ãƒ«ç”»åƒ</strong>ã¯ã€é›¢æ•£çš„ãªç‚¹ï¼ˆãƒ”ã‚¯ã‚»ãƒ«ï¼‰ã®é›†åˆã¨ã—ã¦è¡¨ç¾ã•ã‚Œã¾ã™ã€‚å„ãƒ”ã‚¯ã‚»ãƒ«ã¯è‰²æƒ…å ±ï¼ˆå¼·åº¦å€¤ï¼‰ã‚’æŒã¡ã¾ã™ã€‚</p>

<blockquote>
<p>ã€Œç”»åƒã¯ãƒ”ã‚¯ã‚»ãƒ«ã®2æ¬¡å…ƒé…åˆ—ã¨ã—ã¦æ‰±ã‚ã‚Œã€æ•°å€¤è¨ˆç®—å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿æ§‹é€ ã«ãªã‚Šã¾ã™ã€‚ã€</p>
</blockquote>

<h4>ç”»åƒã®åŸºæœ¬æ§‹é€ </h4>

<ul>
<li><strong>é«˜ã•ï¼ˆHeightï¼‰</strong>: ç¸¦æ–¹å‘ã®ãƒ”ã‚¯ã‚»ãƒ«æ•°</li>
<li><strong>å¹…ï¼ˆWidthï¼‰</strong>: æ¨ªæ–¹å‘ã®ãƒ”ã‚¯ã‚»ãƒ«æ•°</li>
<li><strong>ãƒãƒ£ãƒ³ãƒãƒ«ï¼ˆChannelï¼‰</strong>: è‰²æˆåˆ†ã®æ•°ï¼ˆã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«=1ã€RGB=3ï¼‰</li>
</ul>

<p>ç”»åƒã®å½¢çŠ¶ã¯é€šå¸¸ã€ä»¥ä¸‹ã®ã„ãšã‚Œã‹ã®å½¢å¼ã§è¡¨ç¾ã•ã‚Œã¾ã™ï¼š</p>

<table>
<thead>
<tr>
<th>å½¢å¼</th>
<th>æ¬¡å…ƒé †åº</th>
<th>ä½¿ç”¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒª</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>HWC</strong></td>
<td>(Height, Width, Channels)</td>
<td>OpenCV, PIL, matplotlib</td>
</tr>
<tr>
<td><strong>CHW</strong></td>
<td>(Channels, Height, Width)</td>
<td>PyTorch, Caffe</td>
</tr>
<tr>
<td><strong>NHWC</strong></td>
<td>(Batch, Height, Width, Channels)</td>
<td>TensorFlow, Keras</td>
</tr>
<tr>
<td><strong>NCHW</strong></td>
<td>(Batch, Channels, Height, Width)</td>
<td>PyTorch</td>
</tr>
</tbody>
</table>

<pre><code class="language-python">import numpy as np
import matplotlib.pyplot as plt

# ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«ç”»åƒã®ä½œæˆï¼ˆé«˜ã•5ã€å¹…5ï¼‰
gray_image = np.array([
    [0, 50, 100, 150, 200],
    [50, 100, 150, 200, 250],
    [100, 150, 200, 250, 255],
    [150, 200, 250, 255, 200],
    [200, 250, 255, 200, 150]
], dtype=np.uint8)

# RGBç”»åƒã®ä½œæˆï¼ˆé«˜ã•3ã€å¹…3ã€ãƒãƒ£ãƒ³ãƒãƒ«3ï¼‰
rgb_image = np.zeros((3, 3, 3), dtype=np.uint8)
rgb_image[0, 0] = [255, 0, 0]      # èµ¤
rgb_image[0, 1] = [0, 255, 0]      # ç·‘
rgb_image[0, 2] = [0, 0, 255]      # é’
rgb_image[1, 1] = [255, 255, 0]    # é»„
rgb_image[2, 2] = [255, 255, 255]  # ç™½

print("=== ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«ç”»åƒ ===")
print(f"å½¢çŠ¶: {gray_image.shape}")
print(f"ãƒ‡ãƒ¼ã‚¿å‹: {gray_image.dtype}")
print(f"æœ€å°å€¤: {gray_image.min()}, æœ€å¤§å€¤: {gray_image.max()}")
print(f"\nç”»åƒãƒ‡ãƒ¼ã‚¿:\n{gray_image}")

print("\n=== RGBç”»åƒ ===")
print(f"å½¢çŠ¶: {rgb_image.shape} (Height, Width, Channels)")
print(f"å·¦ä¸Šã®ãƒ”ã‚¯ã‚»ãƒ«å€¤ (R,G,B): {rgb_image[0, 0]}")

# å¯è¦–åŒ–
fig, axes = plt.subplots(1, 2, figsize=(10, 4))
axes[0].imshow(gray_image, cmap='gray')
axes[0].set_title('ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«ç”»åƒ (5Ã—5)')
axes[0].axis('off')

axes[1].imshow(rgb_image)
axes[1].set_title('RGBç”»åƒ (3Ã—3)')
axes[1].axis('off')

plt.tight_layout()
print("\nç”»åƒã‚’å¯è¦–åŒ–ã—ã¾ã—ãŸ")
</code></pre>

<h3>ã‚«ãƒ©ãƒ¼ç©ºé–“ï¼ˆColor Spaceï¼‰</h3>

<p>ã‚«ãƒ©ãƒ¼ç©ºé–“ã¯ã€è‰²ã‚’æ•°å€¤ã§è¡¨ç¾ã™ã‚‹æ–¹æ³•ã§ã™ã€‚ç”¨é€”ã«å¿œã˜ã¦é©åˆ‡ãªã‚«ãƒ©ãƒ¼ç©ºé–“ã‚’é¸æŠã™ã‚‹ã“ã¨ãŒé‡è¦ã§ã™ã€‚</p>

<h4>RGBï¼ˆRed, Green, Blueï¼‰</h4>

<p>æœ€ã‚‚ä¸€èˆ¬çš„ãªã‚«ãƒ©ãƒ¼ç©ºé–“ã€‚åŠ æ³•æ··è‰²ï¼ˆå…‰ã®ä¸‰åŸè‰²ï¼‰ã«åŸºã¥ãã¾ã™ã€‚</p>

<ul>
<li>å„ãƒãƒ£ãƒ³ãƒãƒ«ã®å€¤åŸŸ: 0ã€œ255ï¼ˆ8bitæ•´æ•°ï¼‰ã¾ãŸã¯ 0.0ã€œ1.0ï¼ˆæµ®å‹•å°æ•°ç‚¹ï¼‰</li>
<li>ç”¨é€”: ãƒ‡ã‚¸ã‚¿ãƒ«ã‚«ãƒ¡ãƒ©ã€ãƒ‡ã‚£ã‚¹ãƒ—ãƒ¬ã‚¤ã€ç”»åƒä¿å­˜</li>
<li>ç‰¹å¾´: ç›´æ„Ÿçš„ã ãŒã€äººé–“ã®è‰²çŸ¥è¦šã¨ã¯ä¸€è‡´ã—ãªã„</li>
</ul>

<h4>HSVï¼ˆHue, Saturation, Valueï¼‰</h4>

<p>è‰²ç›¸ã€å½©åº¦ã€æ˜åº¦ã§è‰²ã‚’è¡¨ç¾ã—ã¾ã™ã€‚</p>

<ul>
<li><strong>Hueï¼ˆè‰²ç›¸ï¼‰</strong>: 0ã€œ179åº¦ï¼ˆOpenCVã§ã¯0ã€œ180ï¼‰ã€è‰²ã®ç¨®é¡</li>
<li><strong>Saturationï¼ˆå½©åº¦ï¼‰</strong>: 0ã€œ255ã€è‰²ã®é®®ã‚„ã‹ã•</li>
<li><strong>Valueï¼ˆæ˜åº¦ï¼‰</strong>: 0ã€œ255ã€è‰²ã®æ˜ã‚‹ã•</li>
<li>ç”¨é€”: è‰²ãƒ™ãƒ¼ã‚¹ã®ç‰©ä½“æ¤œå‡ºã€ç”»åƒã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³</li>
</ul>

<h4>LABï¼ˆL*a*b*ï¼‰</h4>

<p>äººé–“ã®è¦–è¦šã«è¿‘ã„è‰²ç©ºé–“ã§ã™ã€‚</p>

<ul>
<li><strong>L</strong>: è¼åº¦ï¼ˆ0ã€œ100ï¼‰</li>
<li><strong>a</strong>: ç·‘ã€œèµ¤ã®è»¸ï¼ˆ-128ã€œ127ï¼‰</li>
<li><strong>b</strong>: é’ã€œé»„ã®è»¸ï¼ˆ-128ã€œ127ï¼‰</li>
<li>ç”¨é€”: è‰²å·®è¨ˆç®—ã€ç”»åƒè£œæ­£</li>
</ul>

<pre><code class="language-python">import cv2
import numpy as np
import matplotlib.pyplot as plt

# ã‚µãƒ³ãƒ—ãƒ«ç”»åƒã®ä½œæˆï¼ˆèµ¤ã€ç·‘ã€é’ã®ãƒ–ãƒ­ãƒƒã‚¯ï¼‰
sample = np.zeros((100, 300, 3), dtype=np.uint8)
sample[:, 0:100] = [255, 0, 0]     # èµ¤
sample[:, 100:200] = [0, 255, 0]   # ç·‘
sample[:, 200:300] = [0, 0, 255]   # é’

# BGRã‹ã‚‰RGBã¸å¤‰æ›ï¼ˆOpenCVã¯BGRé †åºã‚’ä½¿ç”¨ï¼‰
sample_rgb = cv2.cvtColor(sample, cv2.COLOR_BGR2RGB)

# å„ç¨®ã‚«ãƒ©ãƒ¼ç©ºé–“ã¸ã®å¤‰æ›
sample_hsv = cv2.cvtColor(sample, cv2.COLOR_BGR2HSV)
sample_lab = cv2.cvtColor(sample, cv2.COLOR_BGR2LAB)
sample_gray = cv2.cvtColor(sample, cv2.COLOR_BGR2GRAY)

# å¯è¦–åŒ–
fig, axes = plt.subplots(2, 4, figsize=(16, 8))

# å…ƒç”»åƒï¼ˆRGBï¼‰
axes[0, 0].imshow(sample_rgb)
axes[0, 0].set_title('Original (RGB)')
axes[0, 0].axis('off')

# HSVï¼ˆå„ãƒãƒ£ãƒ³ãƒãƒ«ã‚’å€‹åˆ¥è¡¨ç¤ºï¼‰
axes[0, 1].imshow(sample_hsv[:, :, 0], cmap='hsv')
axes[0, 1].set_title('HSV - Hueï¼ˆè‰²ç›¸ï¼‰')
axes[0, 1].axis('off')

axes[0, 2].imshow(sample_hsv[:, :, 1], cmap='gray')
axes[0, 2].set_title('HSV - Saturationï¼ˆå½©åº¦ï¼‰')
axes[0, 2].axis('off')

axes[0, 3].imshow(sample_hsv[:, :, 2], cmap='gray')
axes[0, 3].set_title('HSV - Valueï¼ˆæ˜åº¦ï¼‰')
axes[0, 3].axis('off')

# LABï¼ˆå„ãƒãƒ£ãƒ³ãƒãƒ«ã‚’å€‹åˆ¥è¡¨ç¤ºï¼‰
axes[1, 0].imshow(sample_lab[:, :, 0], cmap='gray')
axes[1, 0].set_title('LAB - Lï¼ˆè¼åº¦ï¼‰')
axes[1, 0].axis('off')

axes[1, 1].imshow(sample_lab[:, :, 1], cmap='RdYlGn_r')
axes[1, 1].set_title('LAB - aï¼ˆç·‘ã€œèµ¤ï¼‰')
axes[1, 1].axis('off')

axes[1, 2].imshow(sample_lab[:, :, 2], cmap='RdYlBu_r')
axes[1, 2].set_title('LAB - bï¼ˆé’ã€œé»„ï¼‰')
axes[1, 2].axis('off')

# ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«
axes[1, 3].imshow(sample_gray, cmap='gray')
axes[1, 3].set_title('Grayscale')
axes[1, 3].axis('off')

plt.tight_layout()
print("å„ç¨®ã‚«ãƒ©ãƒ¼ç©ºé–“ã¸ã®å¤‰æ›ã‚’å¯è¦–åŒ–ã—ã¾ã—ãŸ")

# æ•°å€¤ã®ç¢ºèª
print(f"\nä¸­å¤®ã®èµ¤ãƒ–ãƒ­ãƒƒã‚¯ã®ãƒ”ã‚¯ã‚»ãƒ«å€¤ï¼ˆä½ç½® [50, 50]ï¼‰:")
print(f"  RGB: {sample_rgb[50, 50]}")
print(f"  HSV: {sample_hsv[50, 50]}")
print(f"  LAB: {sample_lab[50, 50]}")
print(f"  Gray: {sample_gray[50, 50]}")
</code></pre>

<h3>ç”»åƒã®èª­ã¿è¾¼ã¿ã¨ä¿å­˜</h3>

<h4>OpenCVã‚’ä½¿ç”¨</h4>

<pre><code class="language-python">import cv2
import numpy as np

# ç”»åƒã®èª­ã¿è¾¼ã¿ï¼ˆå­˜åœ¨ã—ãªã„å ´åˆã¯ãƒ€ãƒŸãƒ¼ç”»åƒã‚’ä½œæˆï¼‰
try:
    image = cv2.imread('sample.jpg')
    if image is None:
        raise FileNotFoundError
except:
    # ãƒ€ãƒŸãƒ¼ç”»åƒã®ä½œæˆï¼ˆã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
    image = np.zeros((480, 640, 3), dtype=np.uint8)
    for i in range(480):
        for j in range(640):
            image[i, j] = [i * 255 // 480, j * 255 // 640, 128]
    print("ãƒ€ãƒŸãƒ¼ç”»åƒã‚’ä½œæˆã—ã¾ã—ãŸ")

print(f"ç”»åƒã®å½¢çŠ¶: {image.shape}")
print(f"ãƒ‡ãƒ¼ã‚¿å‹: {image.dtype}")

# ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«ã¨ã—ã¦èª­ã¿è¾¼ã¿
gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

# ç”»åƒã®ä¿å­˜
cv2.imwrite('output_color.jpg', image)
cv2.imwrite('output_gray.jpg', gray)

print("\nç”»åƒã‚’ä¿å­˜ã—ã¾ã—ãŸ:")
print("  - output_color.jpg (ã‚«ãƒ©ãƒ¼)")
print("  - output_gray.jpg (ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«)")

# ç”»åƒæƒ…å ±ã®è¡¨ç¤º
print(f"\nã‚«ãƒ©ãƒ¼ç”»åƒ:")
print(f"  å½¢çŠ¶: {image.shape}")
print(f"  ãƒ¡ãƒ¢ãƒªã‚µã‚¤ã‚º: {image.nbytes / 1024:.2f} KB")

print(f"\nã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«ç”»åƒ:")
print(f"  å½¢çŠ¶: {gray.shape}")
print(f"  ãƒ¡ãƒ¢ãƒªã‚µã‚¤ã‚º: {gray.nbytes / 1024:.2f} KB")
</code></pre>

<h4>PILã‚’ä½¿ç”¨</h4>

<pre><code class="language-python">from PIL import Image
import numpy as np

# PIL Imageã®ä½œæˆï¼ˆã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
width, height = 640, 480
array = np.zeros((height, width, 3), dtype=np.uint8)
for i in range(height):
    for j in range(width):
        array[i, j] = [i * 255 // height, j * 255 // width, 128]

pil_image = Image.fromarray(array)

print(f"PILç”»åƒã®ã‚µã‚¤ã‚º: {pil_image.size}")  # (width, height)
print(f"PILç”»åƒã®ãƒ¢ãƒ¼ãƒ‰: {pil_image.mode}")

# ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«å¤‰æ›
pil_gray = pil_image.convert('L')

# ä¿å­˜
pil_image.save('output_pil_color.png')
pil_gray.save('output_pil_gray.png')

# PIL â†’ NumPyé…åˆ—
np_array = np.array(pil_image)
print(f"\nNumPyé…åˆ—ã«å¤‰æ›:")
print(f"  å½¢çŠ¶: {np_array.shape}")

# NumPyé…åˆ— â†’ PIL
pil_from_numpy = Image.fromarray(np_array)
print(f"\nPILç”»åƒã«å¤‰æ›:")
print(f"  ã‚µã‚¤ã‚º: {pil_from_numpy.size}")

print("\nPILã‚’ä½¿ç”¨ã—ãŸç”»åƒã‚’ä¿å­˜ã—ã¾ã—ãŸ:")
print("  - output_pil_color.png")
print("  - output_pil_gray.png")
</code></pre>

<hr>

<h2>1.2 åŸºæœ¬çš„ãªç”»åƒå‡¦ç†</h2>

<h3>ãƒªã‚µã‚¤ã‚ºã¨ã‚¯ãƒ­ãƒƒãƒ—</h3>

<p><strong>ãƒªã‚µã‚¤ã‚º</strong>ã¯ç”»åƒã®ã‚µã‚¤ã‚ºã‚’å¤‰æ›´ã™ã‚‹æ“ä½œã§ã™ã€‚è£œé–“æ–¹æ³•ã«ã‚ˆã£ã¦å“è³ªãŒå¤‰ã‚ã‚Šã¾ã™ã€‚</p>

<table>
<thead>
<tr>
<th>è£œé–“æ–¹æ³•</th>
<th>ç‰¹å¾´</th>
<th>ç”¨é€”</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>NEAREST</strong></td>
<td>æœ€è¿‘å‚è£œé–“ã€é«˜é€Ÿã ãŒå“è³ªä½ã„</td>
<td>æ•´æ•°å€ã®æ‹¡å¤§ãƒ»ç¸®å°</td>
</tr>
<tr>
<td><strong>LINEAR</strong></td>
<td>ç·šå½¢è£œé–“ã€ãƒãƒ©ãƒ³ã‚¹ãŒè‰¯ã„</td>
<td>ä¸€èˆ¬çš„ãªç¸®å°</td>
</tr>
<tr>
<td><strong>CUBIC</strong></td>
<td>3æ¬¡è£œé–“ã€é«˜å“è³ªã ãŒä½é€Ÿ</td>
<td>æ‹¡å¤§å‡¦ç†</td>
</tr>
<tr>
<td><strong>LANCZOS</strong></td>
<td>æœ€é«˜å“è³ªã€æœ€ã‚‚ä½é€Ÿ</td>
<td>é«˜å“è³ªãŒå¿…è¦ãªå ´åˆ</td>
</tr>
</tbody>
</table>

<pre><code class="language-python">import cv2
import numpy as np
import matplotlib.pyplot as plt

# ã‚µãƒ³ãƒ—ãƒ«ç”»åƒã®ä½œæˆï¼ˆãƒã‚§ãƒƒã‚«ãƒ¼ãƒœãƒ¼ãƒ‰ï¼‰
def create_checkerboard(size=200, square_size=20):
    image = np.zeros((size, size, 3), dtype=np.uint8)
    for i in range(0, size, square_size):
        for j in range(0, size, square_size):
            if (i // square_size + j // square_size) % 2 == 0:
                image[i:i+square_size, j:j+square_size] = [255, 255, 255]
    return image

original = create_checkerboard(200, 20)

# å„ç¨®è£œé–“æ–¹æ³•ã§ãƒªã‚µã‚¤ã‚º
resized_nearest = cv2.resize(original, (400, 400), interpolation=cv2.INTER_NEAREST)
resized_linear = cv2.resize(original, (400, 400), interpolation=cv2.INTER_LINEAR)
resized_cubic = cv2.resize(original, (400, 400), interpolation=cv2.INTER_CUBIC)
resized_lanczos = cv2.resize(original, (400, 400), interpolation=cv2.INTER_LANCZOS4)

# ç¸®å°
resized_small = cv2.resize(original, (100, 100), interpolation=cv2.INTER_AREA)

# å¯è¦–åŒ–
fig, axes = plt.subplots(2, 3, figsize=(15, 10))
axes = axes.flatten()

images = [
    (cv2.cvtColor(original, cv2.COLOR_BGR2RGB), "Original (200Ã—200)"),
    (cv2.cvtColor(resized_nearest, cv2.COLOR_BGR2RGB), "NEAREST (400Ã—400)"),
    (cv2.cvtColor(resized_linear, cv2.COLOR_BGR2RGB), "LINEAR (400Ã—400)"),
    (cv2.cvtColor(resized_cubic, cv2.COLOR_BGR2RGB), "CUBIC (400Ã—400)"),
    (cv2.cvtColor(resized_lanczos, cv2.COLOR_BGR2RGB), "LANCZOS (400Ã—400)"),
    (cv2.cvtColor(resized_small, cv2.COLOR_BGR2RGB), "AREA (100Ã—100 ç¸®å°)"),
]

for ax, (img, title) in zip(axes, images):
    ax.imshow(img)
    ax.set_title(title)
    ax.axis('off')

plt.tight_layout()
print("å„ç¨®è£œé–“æ–¹æ³•ã«ã‚ˆã‚‹ãƒªã‚µã‚¤ã‚ºã‚’æ¯”è¼ƒã—ã¾ã—ãŸ")

# ã‚¯ãƒ­ãƒƒãƒ—ï¼ˆãƒˆãƒªãƒŸãƒ³ã‚°ï¼‰
print("\n=== ã‚¯ãƒ­ãƒƒãƒ—ã®ä¾‹ ===")
height, width = original.shape[:2]
x, y, w, h = 50, 50, 100, 100  # (x, y, width, height)

cropped = original[y:y+h, x:x+w]
print(f"å…ƒç”»åƒ: {original.shape}")
print(f"ã‚¯ãƒ­ãƒƒãƒ—å¾Œ: {cropped.shape}")
print(f"ã‚¯ãƒ­ãƒƒãƒ—ç¯„å›²: x={x}, y={y}, width={w}, height={h}")
</code></pre>

<h3>å›è»¢ã¨åè»¢</h3>

<pre><code class="language-python">import cv2
import numpy as np
import matplotlib.pyplot as plt

# ãƒ†ã‚¹ãƒˆç”»åƒã®ä½œæˆï¼ˆçŸ¢å°ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰
def create_arrow(size=200):
    image = np.ones((size, size, 3), dtype=np.uint8) * 255
    # çŸ¢å°ã‚’æç”»
    pts = np.array([[100, 50], [150, 100], [125, 100], [125, 150],
                    [75, 150], [75, 100], [50, 100]], np.int32)
    cv2.fillPoly(image, [pts], (0, 0, 255))
    return image

original = create_arrow()

# å›è»¢ï¼ˆ90åº¦ã€180åº¦ã€270åº¦ï¼‰
rotated_90 = cv2.rotate(original, cv2.ROTATE_90_CLOCKWISE)
rotated_180 = cv2.rotate(original, cv2.ROTATE_180)
rotated_270 = cv2.rotate(original, cv2.ROTATE_90_COUNTERCLOCKWISE)

# ä»»æ„è§’åº¦ã®å›è»¢ï¼ˆ45åº¦ï¼‰
height, width = original.shape[:2]
center = (width // 2, height // 2)
rotation_matrix = cv2.getRotationMatrix2D(center, 45, 1.0)
rotated_45 = cv2.warpAffine(original, rotation_matrix, (width, height))

# åè»¢
flipped_horizontal = cv2.flip(original, 1)  # å·¦å³åè»¢
flipped_vertical = cv2.flip(original, 0)    # ä¸Šä¸‹åè»¢
flipped_both = cv2.flip(original, -1)       # ä¸¡æ–¹å‘åè»¢

# å¯è¦–åŒ–
fig, axes = plt.subplots(2, 4, figsize=(16, 8))
axes = axes.flatten()

images = [
    (cv2.cvtColor(original, cv2.COLOR_BGR2RGB), "Original"),
    (cv2.cvtColor(rotated_90, cv2.COLOR_BGR2RGB), "å›è»¢ 90Â°"),
    (cv2.cvtColor(rotated_180, cv2.COLOR_BGR2RGB), "å›è»¢ 180Â°"),
    (cv2.cvtColor(rotated_270, cv2.COLOR_BGR2RGB), "å›è»¢ 270Â°"),
    (cv2.cvtColor(rotated_45, cv2.COLOR_BGR2RGB), "å›è»¢ 45Â°"),
    (cv2.cvtColor(flipped_horizontal, cv2.COLOR_BGR2RGB), "å·¦å³åè»¢"),
    (cv2.cvtColor(flipped_vertical, cv2.COLOR_BGR2RGB), "ä¸Šä¸‹åè»¢"),
    (cv2.cvtColor(flipped_both, cv2.COLOR_BGR2RGB), "ä¸¡æ–¹å‘åè»¢"),
]

for ax, (img, title) in zip(axes, images):
    ax.imshow(img)
    ax.set_title(title)
    ax.axis('off')

plt.tight_layout()
print("å›è»¢ã¨åè»¢ã®æ“ä½œã‚’å¯è¦–åŒ–ã—ã¾ã—ãŸ")

# å›è»¢è¡Œåˆ—ã®è©³ç´°
print("\n=== 45åº¦å›è»¢ã®å¤‰æ›è¡Œåˆ— ===")
print(rotation_matrix)
</code></pre>

<h3>è‰²å¤‰æ›ã¨ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ </h3>

<pre><code class="language-python">import cv2
import numpy as np
import matplotlib.pyplot as plt

# ã‚µãƒ³ãƒ—ãƒ«ç”»åƒã®ä½œæˆï¼ˆã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ + ãƒã‚¤ã‚ºï¼‰
def create_sample_image():
    image = np.zeros((300, 400, 3), dtype=np.uint8)
    for i in range(300):
        for j in range(400):
            image[i, j] = [
                int(i * 255 / 300),
                int(j * 255 / 400),
                128
            ]
    # ãƒã‚¤ã‚ºã‚’è¿½åŠ 
    noise = np.random.randint(-30, 30, image.shape, dtype=np.int16)
    image = np.clip(image.astype(np.int16) + noise, 0, 255).astype(np.uint8)
    return image

image = create_sample_image()
image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

# ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ã®è¨ˆç®—
fig, axes = plt.subplots(2, 2, figsize=(14, 10))

# å…ƒç”»åƒ
axes[0, 0].imshow(image_rgb)
axes[0, 0].set_title('å…ƒç”»åƒ')
axes[0, 0].axis('off')

# RGBãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ 
colors = ('r', 'g', 'b')
for i, color in enumerate(colors):
    hist = cv2.calcHist([image_rgb], [i], None, [256], [0, 256])
    axes[0, 1].plot(hist, color=color, label=f'{color.upper()} channel')
axes[0, 1].set_title('RGBãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ')
axes[0, 1].set_xlabel('ãƒ”ã‚¯ã‚»ãƒ«å€¤')
axes[0, 1].set_ylabel('é »åº¦')
axes[0, 1].legend()
axes[0, 1].grid(True, alpha=0.3)

# ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ å‡ç­‰åŒ–
gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
equalized = cv2.equalizeHist(gray)

axes[1, 0].imshow(equalized, cmap='gray')
axes[1, 0].set_title('ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ å‡ç­‰åŒ–å¾Œ')
axes[1, 0].axis('off')

# å‡ç­‰åŒ–å‰å¾Œã®ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ æ¯”è¼ƒ
hist_before = cv2.calcHist([gray], [0], None, [256], [0, 256])
hist_after = cv2.calcHist([equalized], [0], None, [256], [0, 256])
axes[1, 1].plot(hist_before, 'b-', label='å‡ç­‰åŒ–å‰', alpha=0.7)
axes[1, 1].plot(hist_after, 'r-', label='å‡ç­‰åŒ–å¾Œ', alpha=0.7)
axes[1, 1].set_title('ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ')
axes[1, 1].set_xlabel('ãƒ”ã‚¯ã‚»ãƒ«å€¤')
axes[1, 1].set_ylabel('é »åº¦')
axes[1, 1].legend()
axes[1, 1].grid(True, alpha=0.3)

plt.tight_layout()
print("ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ã¨å‡ç­‰åŒ–ã‚’å¯è¦–åŒ–ã—ã¾ã—ãŸ")

# çµ±è¨ˆæƒ…å ±
print("\n=== ç”»åƒã®çµ±è¨ˆæƒ…å ± ===")
print(f"å¹³å‡å€¤ï¼ˆå‡ç­‰åŒ–å‰ï¼‰: {gray.mean():.2f}")
print(f"å¹³å‡å€¤ï¼ˆå‡ç­‰åŒ–å¾Œï¼‰: {equalized.mean():.2f}")
print(f"æ¨™æº–åå·®ï¼ˆå‡ç­‰åŒ–å‰ï¼‰: {gray.std():.2f}")
print(f"æ¨™æº–åå·®ï¼ˆå‡ç­‰åŒ–å¾Œï¼‰: {equalized.std():.2f}")
</code></pre>

<hr>

<h2>1.3 ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°</h2>

<h3>å¹³æ»‘åŒ–ãƒ•ã‚£ãƒ«ã‚¿</h3>

<p><strong>å¹³æ»‘åŒ–</strong>ã¯ã€ç”»åƒã®ãƒã‚¤ã‚ºã‚’é™¤å»ã—ãŸã‚Šã€ã¼ã‹ã—åŠ¹æœã‚’ä¸ãˆã‚‹å‡¦ç†ã§ã™ã€‚</p>

<pre><code class="language-python">import cv2
import numpy as np
import matplotlib.pyplot as plt

# ãƒã‚¤ã‚ºã‚’å«ã‚€ç”»åƒã®ä½œæˆ
def create_noisy_image(size=200):
    # ã‚¯ãƒªãƒ¼ãƒ³ãªç”»åƒï¼ˆå††ï¼‰
    image = np.zeros((size, size), dtype=np.uint8)
    cv2.circle(image, (size//2, size//2), size//3, 255, -1)

    # ã‚¬ã‚¦ã‚·ã‚¢ãƒ³ãƒã‚¤ã‚ºã‚’è¿½åŠ 
    noise = np.random.normal(0, 25, image.shape)
    noisy = np.clip(image + noise, 0, 255).astype(np.uint8)

    # ã‚½ãƒ«ãƒˆ&ãƒšãƒƒãƒ‘ãƒ¼ãƒã‚¤ã‚ºã‚’è¿½åŠ 
    salt_pepper = noisy.copy()
    salt = np.random.random(image.shape) < 0.02
    pepper = np.random.random(image.shape) < 0.02
    salt_pepper[salt] = 255
    salt_pepper[pepper] = 0

    return image, noisy, salt_pepper

clean, gaussian_noisy, sp_noisy = create_noisy_image()

# å„ç¨®å¹³æ»‘åŒ–ãƒ•ã‚£ãƒ«ã‚¿ã®é©ç”¨
# å¹³å‡ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆMean Filterï¼‰
mean_blur = cv2.blur(gaussian_noisy, (5, 5))

# ã‚¬ã‚¦ã‚·ã‚¢ãƒ³ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆGaussian Filterï¼‰
gaussian_blur = cv2.GaussianBlur(gaussian_noisy, (5, 5), 0)

# ãƒ¡ãƒ‡ã‚£ã‚¢ãƒ³ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆMedian Filterï¼‰- ã‚½ãƒ«ãƒˆ&ãƒšãƒƒãƒ‘ãƒ¼ãƒã‚¤ã‚ºã«åŠ¹æœçš„
median_blur = cv2.medianBlur(sp_noisy, 5)

# ãƒã‚¤ãƒ©ãƒ†ãƒ©ãƒ«ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆBilateral Filterï¼‰- ã‚¨ãƒƒã‚¸ã‚’ä¿æŒã—ãªãŒã‚‰å¹³æ»‘åŒ–
bilateral = cv2.bilateralFilter(gaussian_noisy, 9, 75, 75)

# å¯è¦–åŒ–
fig, axes = plt.subplots(2, 4, figsize=(16, 8))
axes = axes.flatten()

images = [
    (clean, "ã‚¯ãƒªãƒ¼ãƒ³ç”»åƒ"),
    (gaussian_noisy, "ã‚¬ã‚¦ã‚·ã‚¢ãƒ³ãƒã‚¤ã‚º"),
    (mean_blur, "å¹³å‡ãƒ•ã‚£ãƒ«ã‚¿"),
    (gaussian_blur, "ã‚¬ã‚¦ã‚·ã‚¢ãƒ³ãƒ•ã‚£ãƒ«ã‚¿"),
    (sp_noisy, "ã‚½ãƒ«ãƒˆ&ãƒšãƒƒãƒ‘ãƒ¼ãƒã‚¤ã‚º"),
    (median_blur, "ãƒ¡ãƒ‡ã‚£ã‚¢ãƒ³ãƒ•ã‚£ãƒ«ã‚¿"),
    (bilateral, "ãƒã‚¤ãƒ©ãƒ†ãƒ©ãƒ«ãƒ•ã‚£ãƒ«ã‚¿"),
    (gaussian_noisy - gaussian_blur, "ãƒã‚¤ã‚ºæˆåˆ†ï¼ˆå·®åˆ†ï¼‰"),
]

for ax, (img, title) in zip(axes, images):
    ax.imshow(img, cmap='gray')
    ax.set_title(title)
    ax.axis('off')

plt.tight_layout()
print("å„ç¨®å¹³æ»‘åŒ–ãƒ•ã‚£ãƒ«ã‚¿ã®åŠ¹æœã‚’æ¯”è¼ƒã—ã¾ã—ãŸ")

# PSNRï¼ˆãƒ”ãƒ¼ã‚¯ä¿¡å·å¯¾é›‘éŸ³æ¯”ï¼‰ã®è¨ˆç®—
def calculate_psnr(original, filtered):
    mse = np.mean((original - filtered) ** 2)
    if mse == 0:
        return float('inf')
    max_pixel = 255.0
    psnr = 20 * np.log10(max_pixel / np.sqrt(mse))
    return psnr

print("\n=== ãƒã‚¤ã‚ºé™¤å»æ€§èƒ½ï¼ˆPSNRã€é«˜ã„ã»ã©è‰¯ã„ï¼‰===")
print(f"ãƒã‚¤ã‚ºç”»åƒ: {calculate_psnr(clean, gaussian_noisy):.2f} dB")
print(f"å¹³å‡ãƒ•ã‚£ãƒ«ã‚¿: {calculate_psnr(clean, mean_blur):.2f} dB")
print(f"ã‚¬ã‚¦ã‚·ã‚¢ãƒ³ãƒ•ã‚£ãƒ«ã‚¿: {calculate_psnr(clean, gaussian_blur):.2f} dB")
print(f"ãƒã‚¤ãƒ©ãƒ†ãƒ©ãƒ«ãƒ•ã‚£ãƒ«ã‚¿: {calculate_psnr(clean, bilateral):.2f} dB")
</code></pre>

<h3>ã‚¨ãƒƒã‚¸æ¤œå‡º</h3>

<p><strong>ã‚¨ãƒƒã‚¸æ¤œå‡º</strong>ã¯ã€ç”»åƒå†…ã®æ€¥æ¿€ãªè¼åº¦å¤‰åŒ–ã‚’æ¤œå‡ºã™ã‚‹å‡¦ç†ã§ã™ã€‚</p>

<pre><code class="language-python">import cv2
import numpy as np
import matplotlib.pyplot as plt

# ãƒ†ã‚¹ãƒˆç”»åƒã®ä½œæˆï¼ˆè¤‡æ•°ã®å›³å½¢ï¼‰
def create_shapes_image(size=300):
    image = np.ones((size, size), dtype=np.uint8) * 200
    # å››è§’å½¢
    cv2.rectangle(image, (50, 50), (120, 120), 50, -1)
    # å††
    cv2.circle(image, (220, 80), 40, 100, -1)
    # ä¸‰è§’å½¢
    pts = np.array([[150, 200], [100, 280], [200, 280]], np.int32)
    cv2.fillPoly(image, [pts], 150)
    return image

image = create_shapes_image()

# Sobelãƒ•ã‚£ãƒ«ã‚¿ï¼ˆXæ–¹å‘ã€Yæ–¹å‘ï¼‰
sobel_x = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=3)
sobel_y = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=3)
sobel_combined = np.sqrt(sobel_x**2 + sobel_y**2)
sobel_combined = np.uint8(sobel_combined / sobel_combined.max() * 255)

# Laplacianãƒ•ã‚£ãƒ«ã‚¿
laplacian = cv2.Laplacian(image, cv2.CV_64F)
laplacian = np.uint8(np.absolute(laplacian))

# Cannyã‚¨ãƒƒã‚¸æ¤œå‡º
canny = cv2.Canny(image, 50, 150)

# Scharrãƒ•ã‚£ãƒ«ã‚¿ï¼ˆSobelã‚ˆã‚Šç²¾åº¦ãŒé«˜ã„ï¼‰
scharr_x = cv2.Scharr(image, cv2.CV_64F, 1, 0)
scharr_y = cv2.Scharr(image, cv2.CV_64F, 0, 1)
scharr_combined = np.sqrt(scharr_x**2 + scharr_y**2)
scharr_combined = np.uint8(scharr_combined / scharr_combined.max() * 255)

# å¯è¦–åŒ–
fig, axes = plt.subplots(2, 4, figsize=(16, 8))
axes = axes.flatten()

images = [
    (image, "å…ƒç”»åƒ"),
    (sobel_x, "Sobel X"),
    (sobel_y, "Sobel Y"),
    (sobel_combined, "Sobel çµåˆ"),
    (laplacian, "Laplacian"),
    (canny, "Canny"),
    (scharr_combined, "Scharr çµåˆ"),
    (image, "å…ƒç”»åƒï¼ˆå‚è€ƒï¼‰"),
]

for ax, (img, title) in zip(axes, images):
    ax.imshow(img, cmap='gray')
    ax.set_title(title)
    ax.axis('off')

plt.tight_layout()
print("å„ç¨®ã‚¨ãƒƒã‚¸æ¤œå‡ºãƒ•ã‚£ãƒ«ã‚¿ã‚’æ¯”è¼ƒã—ã¾ã—ãŸ")

# ã‚¨ãƒƒã‚¸å¼·åº¦ã®åˆ†æ
print("\n=== ã‚¨ãƒƒã‚¸æ¤œå‡ºçµæœã®çµ±è¨ˆ ===")
print(f"Sobel: å¹³å‡å¼·åº¦ = {sobel_combined.mean():.2f}")
print(f"Laplacian: å¹³å‡å¼·åº¦ = {laplacian.mean():.2f}")
print(f"Canny: ã‚¨ãƒƒã‚¸ãƒ”ã‚¯ã‚»ãƒ«æ•° = {np.sum(canny > 0)}")
print(f"Scharr: å¹³å‡å¼·åº¦ = {scharr_combined.mean():.2f}")
</code></pre>

<h3>ãƒ¢ãƒ«ãƒ•ã‚©ãƒ­ã‚¸ãƒ¼æ¼”ç®—</h3>

<p><strong>ãƒ¢ãƒ«ãƒ•ã‚©ãƒ­ã‚¸ãƒ¼æ¼”ç®—</strong>ã¯ã€äºŒå€¤ç”»åƒã«å¯¾ã™ã‚‹å½¢çŠ¶å‡¦ç†ã§ã™ã€‚</p>

<table>
<thead>
<tr>
<th>æ¼”ç®—</th>
<th>åŠ¹æœ</th>
<th>ç”¨é€”</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>è†¨å¼µï¼ˆDilationï¼‰</strong></td>
<td>ç™½é ˜åŸŸã‚’æ‹¡å¤§</td>
<td>ç©´ã‚’åŸ‹ã‚ã‚‹ã€é€”åˆ‡ã‚Œã‚’æ¥ç¶š</td>
</tr>
<tr>
<td><strong>åç¸®ï¼ˆErosionï¼‰</strong></td>
<td>ç™½é ˜åŸŸã‚’ç¸®å°</td>
<td>ãƒã‚¤ã‚ºé™¤å»ã€ç´°ã„ç·šã‚’é™¤å»</td>
</tr>
<tr>
<td><strong>ã‚ªãƒ¼ãƒ—ãƒ‹ãƒ³ã‚°</strong></td>
<td>åç¸®â†’è†¨å¼µ</td>
<td>å°ã•ãªãƒã‚¤ã‚ºé™¤å»</td>
</tr>
<tr>
<td><strong>ã‚¯ãƒ­ãƒ¼ã‚¸ãƒ³ã‚°</strong></td>
<td>è†¨å¼µâ†’åç¸®</td>
<td>ç©´ã‚„éš™é–“ã‚’åŸ‹ã‚ã‚‹</td>
</tr>
</tbody>
</table>

<pre><code class="language-python">import cv2
import numpy as np
import matplotlib.pyplot as plt

# ãƒã‚¤ã‚ºã‚’å«ã‚€äºŒå€¤ç”»åƒã®ä½œæˆ
def create_noisy_binary_image(size=200):
    image = np.zeros((size, size), dtype=np.uint8)
    # ä¸»è¦ãªå½¢çŠ¶ï¼ˆé•·æ–¹å½¢ï¼‰
    cv2.rectangle(image, (50, 50), (150, 150), 255, -1)
    # å°ã•ãªç©´ã‚’è¿½åŠ 
    for _ in range(10):
        x, y = np.random.randint(60, 140, 2)
        cv2.circle(image, (x, y), 3, 0, -1)
    # å°ã•ãªãƒã‚¤ã‚ºã‚’è¿½åŠ 
    for _ in range(20):
        x, y = np.random.randint(0, size, 2)
        cv2.circle(image, (x, y), 2, 255, -1)
    return image

binary = create_noisy_binary_image()

# ã‚«ãƒ¼ãƒãƒ«ï¼ˆæ§‹é€ è¦ç´ ï¼‰ã®ä½œæˆ
kernel = np.ones((5, 5), np.uint8)

# ãƒ¢ãƒ«ãƒ•ã‚©ãƒ­ã‚¸ãƒ¼æ¼”ç®—
erosion = cv2.erode(binary, kernel, iterations=1)
dilation = cv2.dilate(binary, kernel, iterations=1)
opening = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel)
closing = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)
gradient = cv2.morphologyEx(binary, cv2.MORPH_GRADIENT, kernel)
tophat = cv2.morphologyEx(binary, cv2.MORPH_TOPHAT, kernel)
blackhat = cv2.morphologyEx(binary, cv2.MORPH_BLACKHAT, kernel)

# å¯è¦–åŒ–
fig, axes = plt.subplots(2, 4, figsize=(16, 8))
axes = axes.flatten()

images = [
    (binary, "å…ƒç”»åƒï¼ˆãƒã‚¤ã‚ºå«ã‚€ï¼‰"),
    (erosion, "åç¸®ï¼ˆErosionï¼‰"),
    (dilation, "è†¨å¼µï¼ˆDilationï¼‰"),
    (opening, "ã‚ªãƒ¼ãƒ—ãƒ‹ãƒ³ã‚°"),
    (closing, "ã‚¯ãƒ­ãƒ¼ã‚¸ãƒ³ã‚°"),
    (gradient, "å‹¾é…ï¼ˆGradientï¼‰"),
    (tophat, "ãƒˆãƒƒãƒ—ãƒãƒƒãƒˆ"),
    (blackhat, "ãƒ–ãƒ©ãƒƒã‚¯ãƒãƒƒãƒˆ"),
]

for ax, (img, title) in zip(axes, images):
    ax.imshow(img, cmap='gray')
    ax.set_title(title)
    ax.axis('off')

plt.tight_layout()
print("ãƒ¢ãƒ«ãƒ•ã‚©ãƒ­ã‚¸ãƒ¼æ¼”ç®—ã‚’å¯è¦–åŒ–ã—ã¾ã—ãŸ")

# ãƒ”ã‚¯ã‚»ãƒ«æ•°ã®æ¯”è¼ƒ
print("\n=== ç™½ãƒ”ã‚¯ã‚»ãƒ«æ•°ã®å¤‰åŒ– ===")
print(f"å…ƒç”»åƒ: {np.sum(binary == 255):,} pixels")
print(f"åç¸®å¾Œ: {np.sum(erosion == 255):,} pixels ({np.sum(erosion == 255) / np.sum(binary == 255) * 100:.1f}%)")
print(f"è†¨å¼µå¾Œ: {np.sum(dilation == 255):,} pixels ({np.sum(dilation == 255) / np.sum(binary == 255) * 100:.1f}%)")
print(f"ã‚ªãƒ¼ãƒ—ãƒ‹ãƒ³ã‚°å¾Œ: {np.sum(opening == 255):,} pixels")
print(f"ã‚¯ãƒ­ãƒ¼ã‚¸ãƒ³ã‚°å¾Œ: {np.sum(closing == 255):,} pixels")
</code></pre>

<hr>

<h2>1.4 ç‰¹å¾´æŠ½å‡º</h2>

<h3>ã‚³ãƒ¼ãƒŠãƒ¼æ¤œå‡º</h3>

<p><strong>ã‚³ãƒ¼ãƒŠãƒ¼</strong>ã¯ã€ç”»åƒå†…ã®é‡è¦ãªç‰¹å¾´ç‚¹ã§ã™ã€‚ç‰©ä½“èªè­˜ã‚„è¿½è·¡ã«ä½¿ç”¨ã•ã‚Œã¾ã™ã€‚</p>

<h4>Harris Corner Detection</h4>

<pre><code class="language-python">import cv2
import numpy as np
import matplotlib.pyplot as plt

# ãƒã‚§ãƒƒã‚«ãƒ¼ãƒœãƒ¼ãƒ‰ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ä½œæˆ
def create_checkerboard_complex(size=400):
    image = np.zeros((size, size), dtype=np.uint8)
    square_size = 40
    for i in range(0, size, square_size):
        for j in range(0, size, square_size):
            if (i // square_size + j // square_size) % 2 == 0:
                image[i:i+square_size, j:j+square_size] = 255
    # è¿½åŠ ã®å½¢çŠ¶
    cv2.circle(image, (300, 300), 50, 128, -1)
    return image

image = create_checkerboard_complex()

# Harrisã‚³ãƒ¼ãƒŠãƒ¼æ¤œå‡º
harris = cv2.cornerHarris(image, blockSize=2, ksize=3, k=0.04)
harris = cv2.dilate(harris, None)  # çµæœã‚’å¼·èª¿

# é–¾å€¤å‡¦ç†ã§ã‚³ãƒ¼ãƒŠãƒ¼ã‚’æ¤œå‡º
image_harris = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)
image_harris[harris > 0.01 * harris.max()] = [0, 0, 255]

# Shi-Tomasiã‚³ãƒ¼ãƒŠãƒ¼æ¤œå‡ºï¼ˆGood Features to Trackï¼‰
corners = cv2.goodFeaturesToTrack(image, maxCorners=100, qualityLevel=0.01, minDistance=10)
image_shi = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)
if corners is not None:
    for corner in corners:
        x, y = corner.ravel()
        cv2.circle(image_shi, (int(x), int(y)), 5, (0, 255, 0), -1)

# å¯è¦–åŒ–
fig, axes = plt.subplots(1, 3, figsize=(15, 5))

axes[0].imshow(image, cmap='gray')
axes[0].set_title('å…ƒç”»åƒ')
axes[0].axis('off')

axes[1].imshow(cv2.cvtColor(image_harris, cv2.COLOR_BGR2RGB))
axes[1].set_title(f'Harris Corner Detection')
axes[1].axis('off')

axes[2].imshow(cv2.cvtColor(image_shi, cv2.COLOR_BGR2RGB))
axes[2].set_title(f'Shi-Tomasi ({len(corners) if corners is not None else 0} corners)')
axes[2].axis('off')

plt.tight_layout()
print("ã‚³ãƒ¼ãƒŠãƒ¼æ¤œå‡ºã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’æ¯”è¼ƒã—ã¾ã—ãŸ")

if corners is not None:
    print(f"\næ¤œå‡ºã•ã‚ŒãŸã‚³ãƒ¼ãƒŠãƒ¼æ•°: {len(corners)}")
    print(f"æœ€åˆã®5ã¤ã®ã‚³ãƒ¼ãƒŠãƒ¼åº§æ¨™:")
    for i, corner in enumerate(corners[:5]):
        x, y = corner.ravel()
        print(f"  ã‚³ãƒ¼ãƒŠãƒ¼{i+1}: ({x:.1f}, {y:.1f})")
</code></pre>

<h3>SIFT / ORBç‰¹å¾´é‡</h3>

<p><strong>SIFTï¼ˆScale-Invariant Feature Transformï¼‰</strong>ã¨ã¯ã€ã‚¹ã‚±ãƒ¼ãƒ«ã‚„å›è»¢ã«ä¸å¤‰ãªç‰¹å¾´é‡ã§ã™ã€‚</p>

<blockquote>
<p>æ³¨æ„: OpenCVã®ä¸€éƒ¨ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã§ã¯ã€SIFTã¯ç‰¹è¨±ã®é–¢ä¿‚ã§opencv-contribã«å«ã¾ã‚Œã¦ã„ã¾ã™ã€‚ã“ã“ã§ã¯ORBï¼ˆOriented FAST and Rotated BRIEFï¼‰ã‚’ä¸»ã«ä½¿ç”¨ã—ã¾ã™ã€‚</p>
</blockquote>

<pre><code class="language-python">import cv2
import numpy as np
import matplotlib.pyplot as plt

# ç‰¹å¾´çš„ãªç”»åƒã®ä½œæˆ
def create_feature_image(size=400):
    image = np.ones((size, size), dtype=np.uint8) * 200
    # è¤‡æ•°ã®å›³å½¢
    cv2.rectangle(image, (50, 50), (150, 150), 50, -1)
    cv2.circle(image, (300, 100), 50, 100, -1)
    cv2.rectangle(image, (100, 250), (200, 350), 150, 3)
    pts = np.array([[250, 250], [350, 280], [320, 350]], np.int32)
    cv2.fillPoly(image, [pts], 80)
    return image

image = create_feature_image()

# ORBç‰¹å¾´é‡æ¤œå‡ºå™¨ã®ä½œæˆ
orb = cv2.ORB_create(nfeatures=100)

# ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆã¨è¨˜è¿°å­ã®æ¤œå‡º
keypoints, descriptors = orb.detectAndCompute(image, None)

# ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆã‚’æç”»
image_keypoints = cv2.drawKeypoints(
    image, keypoints, None,
    color=(0, 255, 0),
    flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS
)

# å¯è¦–åŒ–
fig, axes = plt.subplots(1, 2, figsize=(14, 6))

axes[0].imshow(image, cmap='gray')
axes[0].set_title('å…ƒç”»åƒ')
axes[0].axis('off')

axes[1].imshow(image_keypoints)
axes[1].set_title(f'ORBç‰¹å¾´ç‚¹ ({len(keypoints)} points)')
axes[1].axis('off')

plt.tight_layout()
print(f"ORBç‰¹å¾´é‡ã‚’æ¤œå‡ºã—ã¾ã—ãŸ: {len(keypoints)} å€‹ã®ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆ")

# ç‰¹å¾´é‡ã®è©³ç´°
print("\n=== ORBç‰¹å¾´é‡ã®è©³ç´° ===")
print(f"ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆæ•°: {len(keypoints)}")
if descriptors is not None:
    print(f"è¨˜è¿°å­ã®å½¢çŠ¶: {descriptors.shape}")
    print(f"  å„ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆã¯ {descriptors.shape[1]} æ¬¡å…ƒã®ãƒ™ã‚¯ãƒˆãƒ«ã§è¨˜è¿°ã•ã‚Œã‚‹")

# æœ€åˆã®5ã¤ã®ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆæƒ…å ±
print("\næœ€åˆã®5ã¤ã®ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆ:")
for i, kp in enumerate(keypoints[:5]):
    print(f"  Point {i+1}: ä½ç½®=({kp.pt[0]:.1f}, {kp.pt[1]:.1f}), "
          f"ã‚µã‚¤ã‚º={kp.size:.1f}, è§’åº¦={kp.angle:.1f}Â°")
</code></pre>

<h3>HOGï¼ˆHistogram of Oriented Gradientsï¼‰</h3>

<p><strong>HOG</strong>ã¯ã€å‹¾é…æ–¹å‘ã®ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ã‚’ç‰¹å¾´é‡ã¨ã—ã¦ä½¿ç”¨ã—ã¾ã™ã€‚æ­©è¡Œè€…æ¤œå‡ºãªã©ã«åºƒãä½¿ç”¨ã•ã‚Œã¾ã™ã€‚</p>

<pre><code class="language-python">from skimage.feature import hog
from skimage import exposure
import numpy as np
import matplotlib.pyplot as plt

# äººå‹ã‚·ãƒ«ã‚¨ãƒƒãƒˆã®ç°¡æ˜“ä½œæˆ
def create_person_silhouette(size=128):
    image = np.zeros((size, size), dtype=np.uint8)
    # é ­
    cv2.circle(image, (size//2, size//4), size//8, 255, -1)
    # ä½“
    cv2.rectangle(image, (size//2 - size//10, size//4 + size//10),
                  (size//2 + size//10, size//2 + size//6), 255, -1)
    # è…•
    cv2.line(image, (size//2 - size//10, size//4 + size//6),
             (size//2 - size//4, size//2), 255, size//20)
    cv2.line(image, (size//2 + size//10, size//4 + size//6),
             (size//2 + size//4, size//2), 255, size//20)
    # è„š
    cv2.line(image, (size//2 - size//20, size//2 + size//6),
             (size//2 - size//10, size - size//8), 255, size//20)
    cv2.line(image, (size//2 + size//20, size//2 + size//6),
             (size//2 + size//10, size - size//8), 255, size//20)
    return image

image = create_person_silhouette()

# HOGç‰¹å¾´é‡ã®è¨ˆç®—
fd, hog_image = hog(image, orientations=9, pixels_per_cell=(8, 8),
                    cells_per_block=(2, 2), visualize=True)

# HOGç”»åƒã®ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆã‚’å¼·èª¿
hog_image_rescaled = exposure.rescale_intensity(hog_image, in_range=(0, 10))

# å¯è¦–åŒ–
fig, axes = plt.subplots(1, 3, figsize=(15, 5))

axes[0].imshow(image, cmap='gray')
axes[0].set_title('å…ƒç”»åƒï¼ˆäººå‹ã‚·ãƒ«ã‚¨ãƒƒãƒˆï¼‰')
axes[0].axis('off')

axes[1].imshow(hog_image_rescaled, cmap='gray')
axes[1].set_title('HOGç‰¹å¾´é‡ã®å¯è¦–åŒ–')
axes[1].axis('off')

# HOGç‰¹å¾´é‡ãƒ™ã‚¯ãƒˆãƒ«ã®ä¸€éƒ¨ã‚’è¡¨ç¤º
axes[2].bar(range(min(100, len(fd))), fd[:100])
axes[2].set_title('HOGç‰¹å¾´é‡ãƒ™ã‚¯ãƒˆãƒ«ï¼ˆæœ€åˆã®100æ¬¡å…ƒï¼‰')
axes[2].set_xlabel('æ¬¡å…ƒ')
axes[2].set_ylabel('å€¤')
axes[2].grid(True, alpha=0.3)

plt.tight_layout()
print("HOGç‰¹å¾´é‡ã‚’è¨ˆç®—ã—ã¾ã—ãŸ")

print(f"\n=== HOGç‰¹å¾´é‡ã®è©³ç´° ===")
print(f"ç‰¹å¾´é‡ãƒ™ã‚¯ãƒˆãƒ«ã®æ¬¡å…ƒæ•°: {len(fd)}")
print(f"å¹³å‡å€¤: {fd.mean():.4f}")
print(f"æ¨™æº–åå·®: {fd.std():.4f}")
print(f"æœ€å¤§å€¤: {fd.max():.4f}")
print(f"æœ€å°å€¤: {fd.min():.4f}")
</code></pre>

<hr>

<h2>1.5 ç”»åƒãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†</h2>

<h3>Normalizationï¼ˆæ­£è¦åŒ–ï¼‰ã¨Standardizationï¼ˆæ¨™æº–åŒ–ï¼‰</h3>

<p>æ©Ÿæ¢°å­¦ç¿’ã§ã¯ã€ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚’é©åˆ‡ã«ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã™ã‚‹ã“ã¨ãŒé‡è¦ã§ã™ã€‚</p>

<table>
<thead>
<tr>
<th>æ‰‹æ³•</th>
<th>è¨ˆç®—å¼</th>
<th>ç”¨é€”</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Min-Maxæ­£è¦åŒ–</strong></td>
<td>$x' = \frac{x - x_{min}}{x_{max} - x_{min}}$</td>
<td>å€¤åŸŸã‚’[0, 1]ã«å¤‰æ›</td>
</tr>
<tr>
<td><strong>æ¨™æº–åŒ–ï¼ˆZ-scoreï¼‰</strong></td>
<td>$x' = \frac{x - \mu}{\sigma}$</td>
<td>å¹³å‡0ã€åˆ†æ•£1ã«å¤‰æ›</td>
</tr>
<tr>
<td><strong>ImageNetæ­£è¦åŒ–</strong></td>
<td>ãƒãƒ£ãƒ³ãƒãƒ«ã”ã¨ã«æ¨™æº–åŒ–</td>
<td>äº‹å‰å­¦ç¿’ãƒ¢ãƒ‡ãƒ«åˆ©ç”¨æ™‚</td>
</tr>
</tbody>
</table>

<pre><code class="language-python">import numpy as np
import matplotlib.pyplot as plt

# ã‚µãƒ³ãƒ—ãƒ«ç”»åƒã®ä½œæˆ
np.random.seed(42)
image = np.random.randint(50, 200, (100, 100, 3), dtype=np.uint8)

print("=== å…ƒç”»åƒã®çµ±è¨ˆ ===")
print(f"å½¢çŠ¶: {image.shape}")
print(f"ãƒ‡ãƒ¼ã‚¿å‹: {image.dtype}")
print(f"å€¤åŸŸ: [{image.min()}, {image.max()}]")
print(f"å¹³å‡å€¤: {image.mean():.2f}")
print(f"æ¨™æº–åå·®: {image.std():.2f}")

# Min-Maxæ­£è¦åŒ– [0, 1]
normalized = image.astype(np.float32) / 255.0

print("\n=== Min-Maxæ­£è¦åŒ–å¾Œ ===")
print(f"ãƒ‡ãƒ¼ã‚¿å‹: {normalized.dtype}")
print(f"å€¤åŸŸ: [{normalized.min():.3f}, {normalized.max():.3f}]")
print(f"å¹³å‡å€¤: {normalized.mean():.3f}")

# æ¨™æº–åŒ–ï¼ˆZ-scoreï¼‰
mean = image.mean(axis=(0, 1), keepdims=True)
std = image.std(axis=(0, 1), keepdims=True)
standardized = (image.astype(np.float32) - mean) / (std + 1e-7)

print("\n=== æ¨™æº–åŒ–ï¼ˆZ-scoreï¼‰å¾Œ ===")
print(f"å¹³å‡å€¤: {standardized.mean():.6f} (â‰ˆ 0)")
print(f"æ¨™æº–åå·®: {standardized.std():.6f} (â‰ˆ 1)")
print(f"å€¤åŸŸ: [{standardized.min():.3f}, {standardized.max():.3f}]")

# ImageNetæ¨™æº–åŒ–ï¼ˆäº‹å‰å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ç”¨ï¼‰
imagenet_mean = np.array([0.485, 0.456, 0.406])
imagenet_std = np.array([0.229, 0.224, 0.225])
imagenet_normalized = (normalized - imagenet_mean) / imagenet_std

print("\n=== ImageNetæ¨™æº–åŒ–å¾Œ ===")
print(f"Rãƒãƒ£ãƒ³ãƒãƒ«å¹³å‡: {imagenet_normalized[:,:,0].mean():.3f}")
print(f"Gãƒãƒ£ãƒ³ãƒãƒ«å¹³å‡: {imagenet_normalized[:,:,1].mean():.3f}")
print(f"Bãƒãƒ£ãƒ³ãƒãƒ«å¹³å‡: {imagenet_normalized[:,:,2].mean():.3f}")

# å¯è¦–åŒ–
fig, axes = plt.subplots(1, 4, figsize=(16, 4))

axes[0].imshow(image)
axes[0].set_title('å…ƒç”»åƒ\n[50, 200]')
axes[0].axis('off')

axes[1].imshow(normalized)
axes[1].set_title('Min-Maxæ­£è¦åŒ–\n[0, 1]')
axes[1].axis('off')

# æ¨™æº–åŒ–ç”»åƒã¯å¯è¦–åŒ–ã®ãŸã‚ã«èª¿æ•´
standardized_vis = (standardized - standardized.min()) / (standardized.max() - standardized.min())
axes[2].imshow(standardized_vis)
axes[2].set_title('æ¨™æº–åŒ–\nå¹³å‡â‰ˆ0, åˆ†æ•£â‰ˆ1')
axes[2].axis('off')

# ImageNetæ­£è¦åŒ–ã‚‚èª¿æ•´
imagenet_vis = (imagenet_normalized - imagenet_normalized.min()) / \
               (imagenet_normalized.max() - imagenet_normalized.min())
axes[3].imshow(imagenet_vis)
axes[3].set_title('ImageNetæ¨™æº–åŒ–')
axes[3].axis('off')

plt.tight_layout()
print("\næ­£è¦åŒ–ãƒ»æ¨™æº–åŒ–ã®åŠ¹æœã‚’å¯è¦–åŒ–ã—ã¾ã—ãŸ")
</code></pre>

<h3>Data Augmentationï¼ˆãƒ‡ãƒ¼ã‚¿æ‹¡å¼µï¼‰</h3>

<p><strong>ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µ</strong>ã¯ã€é™ã‚‰ã‚ŒãŸè¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å¤šæ§˜ãªãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ç”Ÿæˆã—ã€ãƒ¢ãƒ‡ãƒ«ã®æ±åŒ–æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹æ‰‹æ³•ã§ã™ã€‚</p>

<pre><code class="language-python">import numpy as np
import cv2
import matplotlib.pyplot as plt
from PIL import Image, ImageEnhance

# ã‚µãƒ³ãƒ—ãƒ«ç”»åƒã®ä½œæˆ
def create_sample_object(size=128):
    image = np.ones((size, size, 3), dtype=np.uint8) * 255
    # çŸ¢å°å‹ã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
    pts = np.array([[size//2, size//4], [3*size//4, size//2],
                    [5*size//8, size//2], [5*size//8, 3*size//4],
                    [3*size//8, 3*size//4], [3*size//8, size//2],
                    [size//4, size//2]], np.int32)
    cv2.fillPoly(image, [pts], (30, 144, 255))
    return image

original = create_sample_object()

# å„ç¨®ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã®é©ç”¨
# 1. å›è»¢
rotated = cv2.rotate(original, cv2.ROTATE_90_CLOCKWISE)

# 2. å·¦å³åè»¢
flipped = cv2.flip(original, 1)

# 3. ãƒ©ãƒ³ãƒ€ãƒ ã‚¯ãƒ­ãƒƒãƒ—&ãƒªã‚µã‚¤ã‚º
h, w = original.shape[:2]
crop_size = 96
x, y = np.random.randint(0, w - crop_size), np.random.randint(0, h - crop_size)
cropped = original[y:y+crop_size, x:x+crop_size]
cropped_resized = cv2.resize(cropped, (128, 128))

# 4. æ˜åº¦å¤‰æ›´
pil_img = Image.fromarray(cv2.cvtColor(original, cv2.COLOR_BGR2RGB))
brightness = ImageEnhance.Brightness(pil_img).enhance(1.5)
brightness = cv2.cvtColor(np.array(brightness), cv2.COLOR_RGB2BGR)

# 5. ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆå¤‰æ›´
contrast = ImageEnhance.Contrast(pil_img).enhance(1.5)
contrast = cv2.cvtColor(np.array(contrast), cv2.COLOR_RGB2BGR)

# 6. ã‚¬ã‚¦ã‚·ã‚¢ãƒ³ãƒã‚¤ã‚º
noisy = original.copy().astype(np.float32)
noise = np.random.normal(0, 10, original.shape)
noisy = np.clip(noisy + noise, 0, 255).astype(np.uint8)

# 7. ã¼ã‹ã—
blurred = cv2.GaussianBlur(original, (5, 5), 0)

# 8. è‰²èª¿å¤‰æ›´ï¼ˆHSVç©ºé–“ã§æ“ä½œï¼‰
hsv = cv2.cvtColor(original, cv2.COLOR_BGR2HSV).astype(np.float32)
hsv[:, :, 0] = (hsv[:, :, 0] + 30) % 180  # è‰²ç›¸ã‚’ã‚·ãƒ•ãƒˆ
hue_shifted = cv2.cvtColor(hsv.astype(np.uint8), cv2.COLOR_HSV2BGR)

# å¯è¦–åŒ–
fig, axes = plt.subplots(3, 3, figsize=(12, 12))
axes = axes.flatten()

images = [
    (cv2.cvtColor(original, cv2.COLOR_BGR2RGB), "å…ƒç”»åƒ"),
    (cv2.cvtColor(rotated, cv2.COLOR_BGR2RGB), "å›è»¢ï¼ˆ90Â°ï¼‰"),
    (cv2.cvtColor(flipped, cv2.COLOR_BGR2RGB), "å·¦å³åè»¢"),
    (cv2.cvtColor(cropped_resized, cv2.COLOR_BGR2RGB), "ãƒ©ãƒ³ãƒ€ãƒ ã‚¯ãƒ­ãƒƒãƒ—"),
    (cv2.cvtColor(brightness, cv2.COLOR_BGR2RGB), "æ˜åº¦å¤‰æ›´ï¼ˆ1.5å€ï¼‰"),
    (cv2.cvtColor(contrast, cv2.COLOR_BGR2RGB), "ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆå¤‰æ›´"),
    (cv2.cvtColor(noisy, cv2.COLOR_BGR2RGB), "ã‚¬ã‚¦ã‚·ã‚¢ãƒ³ãƒã‚¤ã‚º"),
    (cv2.cvtColor(blurred, cv2.COLOR_BGR2RGB), "ã¼ã‹ã—"),
    (cv2.cvtColor(hue_shifted, cv2.COLOR_BGR2RGB), "è‰²èª¿å¤‰æ›´"),
]

for ax, (img, title) in zip(axes, images):
    ax.imshow(img)
    ax.set_title(title)
    ax.axis('off')

plt.tight_layout()
print("ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã®å„ç¨®æ‰‹æ³•ã‚’å¯è¦–åŒ–ã—ã¾ã—ãŸ")
print("\nã“ã‚Œã‚‰ã®æ‰‹æ³•ã‚’çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã§ã€1æšã®ç”»åƒã‹ã‚‰æ•°ç™¾ã€œæ•°åƒã®ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ç”Ÿæˆã§ãã¾ã™")
</code></pre>

<h3>PyTorch Transformsã«ã‚ˆã‚‹å‰å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³</h3>

<pre><code class="language-python">import torch
from torchvision import transforms
from PIL import Image
import numpy as np

# ã‚µãƒ³ãƒ—ãƒ«ç”»åƒã®ä½œæˆ
sample_np = np.random.randint(0, 255, (256, 256, 3), dtype=np.uint8)
sample_pil = Image.fromarray(sample_np)

print("=== PyTorch Transforms ã«ã‚ˆã‚‹å‰å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ ===\n")

# è¨“ç·´ç”¨ã®å¤‰æ›ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
train_transform = transforms.Compose([
    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),
    transforms.RandomRotation(15),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# æ¤œè¨¼ãƒ»ãƒ†ã‚¹ãƒˆç”¨ã®å¤‰æ›ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
val_transform = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# å¤‰æ›ã®é©ç”¨
train_tensor = train_transform(sample_pil)
val_tensor = val_transform(sample_pil)

print("è¨“ç·´ç”¨å¤‰æ›:")
print(f"  å…¥åŠ›: PIL Image {sample_pil.size}")
print(f"  å‡ºåŠ›: Tensor {train_tensor.shape}")
print(f"  ãƒ‡ãƒ¼ã‚¿å‹: {train_tensor.dtype}")
print(f"  å€¤åŸŸ: [{train_tensor.min():.3f}, {train_tensor.max():.3f}]")

print("\næ¤œè¨¼ç”¨å¤‰æ›:")
print(f"  å…¥åŠ›: PIL Image {sample_pil.size}")
print(f"  å‡ºåŠ›: Tensor {val_tensor.shape}")
print(f"  å€¤åŸŸ: [{val_tensor.min():.3f}, {val_tensor.max():.3f}]")

# ãƒãƒƒãƒå‡¦ç†ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
batch_size = 4
batch_tensors = [train_transform(sample_pil) for _ in range(batch_size)]
batch = torch.stack(batch_tensors)

print(f"\nãƒãƒƒãƒå‡¦ç†:")
print(f"  ãƒãƒƒãƒã‚µã‚¤ã‚º: {batch_size}")
print(f"  ãƒãƒƒãƒãƒ†ãƒ³ã‚½ãƒ«ã®å½¢çŠ¶: {batch.shape}")
print(f"  â†’ [Batch, Channels, Height, Width]")

# å€‹åˆ¥ã®å¤‰æ›ä¾‹
print("\n=== å€‹åˆ¥ã®å¤‰æ›ã®è©³ç´° ===")

# ToTensorã®ã¿
to_tensor = transforms.ToTensor()
tensor_only = to_tensor(sample_pil)
print(f"\n1. ToTensor:")
print(f"   PIL (H, W, C) â†’ Tensor (C, H, W)")
print(f"   å€¤åŸŸ: [0, 255] â†’ [0.0, 1.0]")
print(f"   å½¢çŠ¶å¤‰åŒ–: {sample_pil.size} â†’ {tensor_only.shape}")

# Normalizeã®åŠ¹æœ
normalize = transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
normalized = normalize(tensor_only)
print(f"\n2. Normalize (mean=0.5, std=0.5):")
print(f"   å¤‰æ›å‰ã®å¹³å‡: {tensor_only.mean():.3f}")
print(f"   å¤‰æ›å¾Œã®å¹³å‡: {normalized.mean():.3f}")
print(f"   å€¤åŸŸ: [0.0, 1.0] â†’ [{normalized.min():.3f}, {normalized.max():.3f}]")

print("\nå‰å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®æ§‹ç¯‰ãŒå®Œäº†ã—ã¾ã—ãŸ")
</code></pre>

<hr>

<h2>ã¾ã¨ã‚</h2>

<p>ã“ã®ç« ã§ã¯ã€ç”»åƒå‡¦ç†ã®åŸºç¤ã«ã¤ã„ã¦å­¦ç¿’ã—ã¾ã—ãŸã€‚</p>

<h3>é‡è¦ãªãƒã‚¤ãƒ³ãƒˆ</h3>

<ul>
<li><strong>ãƒ‡ã‚¸ã‚¿ãƒ«ç”»åƒ</strong>ã¯ãƒ”ã‚¯ã‚»ãƒ«ã®é…åˆ—ã¨ã—ã¦è¡¨ç¾ã•ã‚Œã€HWCã¾ãŸã¯CHWå½¢å¼ã§æ‰±ã‚ã‚Œã‚‹</li>
<li><strong>ã‚«ãƒ©ãƒ¼ç©ºé–“</strong>ï¼ˆRGBã€HSVã€LABï¼‰ã¯ç”¨é€”ã«å¿œã˜ã¦ä½¿ã„åˆ†ã‘ã‚‹</li>
<li><strong>åŸºæœ¬å‡¦ç†</strong>ï¼ˆãƒªã‚µã‚¤ã‚ºã€å›è»¢ã€è‰²å¤‰æ›ï¼‰ã¯ç”»åƒè§£æã®å‰å‡¦ç†ã¨ã—ã¦é‡è¦</li>
<li><strong>ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°</strong>ï¼ˆå¹³æ»‘åŒ–ã€ã‚¨ãƒƒã‚¸æ¤œå‡ºï¼‰ã§ç”»åƒã®ç‰¹å¾´ã‚’æŠ½å‡º</li>
<li><strong>ç‰¹å¾´é‡</strong>ï¼ˆã‚³ãƒ¼ãƒŠãƒ¼ã€SIFTã€HOGï¼‰ã¯ç‰©ä½“èªè­˜ã®åŸºç¤</li>
<li><strong>å‰å‡¦ç†ã¨ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µ</strong>ã¯æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½å‘ä¸Šã«ä¸å¯æ¬ </li>
</ul>

<h3>æ¬¡ç« ã®äºˆå‘Š</h3>

<p>ç¬¬2ç« ã§ã¯ã€ä»¥ä¸‹ã®ãƒˆãƒ”ãƒƒã‚¯ã‚’æ‰±ã„ã¾ã™ï¼š</p>
<ul>
<li>ç•³ã¿è¾¼ã¿ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼ˆCNNï¼‰ã®åŸºç¤</li>
<li>ç•³ã¿è¾¼ã¿å±¤ã¨ãƒ—ãƒ¼ãƒªãƒ³ã‚°å±¤ã®ä»•çµ„ã¿</li>
<li>ä»£è¡¨çš„ãªCNNã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ï¼ˆLeNetã€AlexNetï¼‰</li>
<li>PyTorchã«ã‚ˆã‚‹CNNã®å®Ÿè£…ã¨ç”»åƒåˆ†é¡</li>
</ul>

<hr>

<h2>æ¼”ç¿’å•é¡Œ</h2>

<details>
<summary><strong>æ¼”ç¿’1ï¼šã‚«ãƒ©ãƒ¼ç©ºé–“ã®ç†è§£</strong></summary>

<p><strong>å•é¡Œ</strong>ï¼šRGBç”»åƒã‚’HSVç©ºé–“ã«å¤‰æ›ã—ã€ç‰¹å®šã®è‰²ï¼ˆä¾‹ï¼šèµ¤è‰²ï¼‰ã®é ˜åŸŸã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚</p>

<p><strong>ãƒ’ãƒ³ãƒˆ</strong>ï¼š</p>
<ul>
<li>HSVç©ºé–“ã§ã¯è‰²ç›¸ï¼ˆHueï¼‰ã§è‰²ã‚’æŒ‡å®šã—ã‚„ã™ã„</li>
<li>èµ¤è‰²ã®è‰²ç›¸ç¯„å›²: 0-10 ãŠã‚ˆã³ 170-180ï¼ˆOpenCVï¼‰</li>
</ul>

<p><strong>è§£ç­”ä¾‹</strong>ï¼š</p>
<pre><code class="language-python">import cv2
import numpy as np

# RGBç”»åƒã®ä½œæˆï¼ˆèµ¤ã€ç·‘ã€é’ã®é ˜åŸŸï¼‰
image = np.zeros((300, 300, 3), dtype=np.uint8)
image[:, 0:100] = [0, 0, 255]    # èµ¤ï¼ˆBGRï¼‰
image[:, 100:200] = [0, 255, 0]  # ç·‘
image[:, 200:300] = [255, 0, 0]  # é’

# HSVã«å¤‰æ›
hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)

# èµ¤è‰²ã®ç¯„å›²ã‚’å®šç¾©
lower_red1 = np.array([0, 100, 100])
upper_red1 = np.array([10, 255, 255])
lower_red2 = np.array([170, 100, 100])
upper_red2 = np.array([180, 255, 255])

# ãƒã‚¹ã‚¯ã®ä½œæˆ
mask1 = cv2.inRange(hsv, lower_red1, upper_red1)
mask2 = cv2.inRange(hsv, lower_red2, upper_red2)
red_mask = cv2.bitwise_or(mask1, mask2)

# ãƒã‚¹ã‚¯ã‚’é©ç”¨
red_only = cv2.bitwise_and(image, image, mask=red_mask)

print(f"èµ¤è‰²é ˜åŸŸã®ãƒ”ã‚¯ã‚»ãƒ«æ•°: {np.sum(red_mask > 0)}")
</code></pre>
</details>

<details>
<summary><strong>æ¼”ç¿’2ï¼šè£œé–“æ–¹æ³•ã®æ¯”è¼ƒ</strong></summary>

<p><strong>å•é¡Œ</strong>ï¼š100Ã—100ã®ç”»åƒã‚’500Ã—500ã«æ‹¡å¤§ã™ã‚‹éš›ã€NEARESTã€LINEARã€CUBICã€LANCZOSã®4ã¤ã®è£œé–“æ–¹æ³•ã§å‡¦ç†æ™‚é–“ã¨è¦–è¦šçš„å“è³ªã‚’æ¯”è¼ƒã—ã¦ãã ã•ã„ã€‚</p>

<p><strong>è§£ç­”ä¾‹</strong>ï¼š</p>
<pre><code class="language-python">import cv2
import numpy as np
import time

# ãƒ†ã‚¹ãƒˆç”»åƒ
image = np.random.randint(0, 255, (100, 100, 3), dtype=np.uint8)

methods = {
    'NEAREST': cv2.INTER_NEAREST,
    'LINEAR': cv2.INTER_LINEAR,
    'CUBIC': cv2.INTER_CUBIC,
    'LANCZOS': cv2.INTER_LANCZOS4
}

print("è£œé–“æ–¹æ³•ã®å‡¦ç†æ™‚é–“æ¯”è¼ƒ:")
for name, method in methods.items():
    start = time.time()
    resized = cv2.resize(image, (500, 500), interpolation=method)
    elapsed = time.time() - start
    print(f"  {name:10s}: {elapsed*1000:.2f} ms")
</code></pre>
</details>

<details>
<summary><strong>æ¼”ç¿’3ï¼šã‚«ã‚¹ã‚¿ãƒ ãƒ•ã‚£ãƒ«ã‚¿ã®å®Ÿè£…</strong></summary>

<p><strong>å•é¡Œ</strong>ï¼šä»¥ä¸‹ã®ã‚«ãƒ¼ãƒãƒ«ã‚’ä½¿ç”¨ã—ã¦ã€æ‰‹å‹•ã§ç•³ã¿è¾¼ã¿æ¼”ç®—ã‚’å®Ÿè£…ã—ã¦ãã ã•ã„ã€‚</p>

<pre><code>ã‚·ãƒ£ãƒ¼ãƒ—åŒ–ã‚«ãƒ¼ãƒãƒ«:
 0  -1   0
-1   5  -1
 0  -1   0
</code></pre>

<p><strong>è§£ç­”ä¾‹</strong>ï¼š</p>
<pre><code class="language-python">import numpy as np
import cv2

def custom_convolution(image, kernel):
    """ã‚«ã‚¹ã‚¿ãƒ ç•³ã¿è¾¼ã¿é–¢æ•°"""
    img_h, img_w = image.shape
    ker_h, ker_w = kernel.shape
    pad_h, pad_w = ker_h // 2, ker_w // 2

    # ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°
    padded = np.pad(image, ((pad_h, pad_h), (pad_w, pad_w)), mode='edge')

    # å‡ºåŠ›ç”»åƒ
    output = np.zeros_like(image)

    # ç•³ã¿è¾¼ã¿
    for i in range(img_h):
        for j in range(img_w):
            region = padded[i:i+ker_h, j:j+ker_w]
            output[i, j] = np.sum(region * kernel)

    return np.clip(output, 0, 255).astype(np.uint8)

# ã‚·ãƒ£ãƒ¼ãƒ—åŒ–ã‚«ãƒ¼ãƒãƒ«
sharpen_kernel = np.array([[0, -1, 0],
                           [-1, 5, -1],
                           [0, -1, 0]])

# ãƒ†ã‚¹ãƒˆ
test_image = np.random.randint(50, 200, (100, 100), dtype=np.uint8)
sharpened = custom_convolution(test_image, sharpen_kernel)

print("ã‚«ã‚¹ã‚¿ãƒ ç•³ã¿è¾¼ã¿ã‚’å®Ÿè£…ã—ã¾ã—ãŸ")
print(f"å…¥åŠ›: {test_image.shape}")
print(f"å‡ºåŠ›: {sharpened.shape}")
</code></pre>
</details>

<details>
<summary><strong>æ¼”ç¿’4ï¼šPyTorch Transformsã®å¿œç”¨</strong></summary>

<p><strong>å•é¡Œ</strong>ï¼šä»¥ä¸‹ã®è¦ä»¶ã‚’æº€ãŸã™ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ä½œæˆã—ã¦ãã ã•ã„ï¼š</p>
<ul>
<li>80%ã®ç¢ºç‡ã§å·¦å³åè»¢</li>
<li>æ˜åº¦ã¨ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«Â±20%å¤‰æ›´</li>
<li>Â±10åº¦ã®ãƒ©ãƒ³ãƒ€ãƒ å›è»¢</li>
<li>æœ€çµ‚çš„ã«224Ã—224ã«ãƒªã‚µã‚¤ã‚º</li>
<li>ImageNetæ¨™æº–åŒ–ã‚’é©ç”¨</li>
</ul>

<p><strong>è§£ç­”ä¾‹</strong>ï¼š</p>
<pre><code class="language-python">from torchvision import transforms

augmentation_pipeline = transforms.Compose([
    transforms.RandomHorizontalFlip(p=0.8),
    transforms.ColorJitter(brightness=0.2, contrast=0.2),
    transforms.RandomRotation(10),
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(
        mean=[0.485, 0.456, 0.406],
        std=[0.229, 0.224, 0.225]
    )
])

print("ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ä½œæˆã—ã¾ã—ãŸ")
print(f"å¤‰æ›æ•°: {len(augmentation_pipeline.transforms)}")
</code></pre>
</details>

<details>
<summary><strong>æ¼”ç¿’5ï¼šã‚¨ãƒƒã‚¸æ¤œå‡ºã®å¿œç”¨</strong></summary>

<p><strong>å•é¡Œ</strong>ï¼šCannyã‚¨ãƒƒã‚¸æ¤œå‡ºã‚’ä½¿ç”¨ã—ã¦ã€ç”»åƒå†…ã®é•·æ–¹å½¢é ˜åŸŸã‚’æ¤œå‡ºã—ã€ãã®é¢ç©ã‚’è¨ˆç®—ã—ã¦ãã ã•ã„ã€‚</p>

<p><strong>è§£ç­”ä¾‹</strong>ï¼š</p>
<pre><code class="language-python">import cv2
import numpy as np

# é•·æ–¹å½¢ã‚’å«ã‚€ç”»åƒã‚’ä½œæˆ
image = np.zeros((300, 400), dtype=np.uint8)
cv2.rectangle(image, (50, 50), (200, 150), 255, -1)
cv2.rectangle(image, (250, 100), (350, 250), 255, -1)

# Cannyã‚¨ãƒƒã‚¸æ¤œå‡º
edges = cv2.Canny(image, 50, 150)

# è¼ªéƒ­æ¤œå‡º
contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL,
                                cv2.CHAIN_APPROX_SIMPLE)

print(f"æ¤œå‡ºã•ã‚ŒãŸè¼ªéƒ­æ•°: {len(contours)}")

for i, contour in enumerate(contours):
    area = cv2.contourArea(contour)
    perimeter = cv2.arcLength(contour, True)
    print(f"è¼ªéƒ­{i+1}: é¢ç©={area:.0f}, å‘¨å›²é•·={perimeter:.2f}")
</code></pre>
</details>

<hr>

<h2>å‚è€ƒæ–‡çŒ®</h2>

<ul>
<li><a href="https://docs.opencv.org/">OpenCV Documentation</a> - å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ</li>
<li><a href="https://pillow.readthedocs.io/">Pillow (PIL) Documentation</a> - Python Imaging Library</li>
<li><a href="https://pytorch.org/vision/stable/transforms.html">torchvision.transforms</a> - PyTorchç”»åƒå¤‰æ›</li>
<li>Szeliski, R. (2010). <em>Computer Vision: Algorithms and Applications</em>. Springer.</li>
<li>Gonzalez, R. C., & Woods, R. E. (2018). <em>Digital Image Processing</em> (4th ed.). Pearson.</li>
<li>Bradski, G., & Kaehler, A. (2008). <em>Learning OpenCV</em>. O'Reilly Media.</li>
</ul>

<hr>

<div class="navigation">
    <a href="index.html" class="nav-button">ğŸ“š ã‚³ãƒ¼ã‚¹ç›®æ¬¡ã«æˆ»ã‚‹</a>
    <a href="chapter2-cnn-basics.html" class="nav-button">æ¬¡ã®ç« ã¸ï¼šCNNã®åŸºç¤ â†’</a>
</div>

</main>


    <section class="disclaimer">
        <h3>å…è²¬äº‹é …</h3>
        <ul>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯æ•™è‚²ãƒ»ç ”ç©¶ãƒ»æƒ…å ±æä¾›ã®ã¿ã‚’ç›®çš„ã¨ã—ã¦ãŠã‚Šã€å°‚é–€çš„ãªåŠ©è¨€(æ³•å¾‹ãƒ»ä¼šè¨ˆãƒ»æŠ€è¡“çš„ä¿è¨¼ãªã©)ã‚’æä¾›ã™ã‚‹ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŠã‚ˆã³ä»˜éšã™ã‚‹ã‚³ãƒ¼ãƒ‰ä¾‹ã¯ã€Œç¾çŠ¶æœ‰å§¿(AS IS)ã€ã§æä¾›ã•ã‚Œã€æ˜ç¤ºã¾ãŸã¯é»™ç¤ºã‚’å•ã‚ãšã€å•†å“æ€§ã€ç‰¹å®šç›®çš„é©åˆæ€§ã€æ¨©åˆ©éä¾µå®³ã€æ­£ç¢ºæ€§ãƒ»å®Œå…¨æ€§ã€å‹•ä½œãƒ»å®‰å…¨æ€§ç­‰ã„ã‹ãªã‚‹ä¿è¨¼ã‚‚ã—ã¾ã›ã‚“ã€‚</li>
            <li>å¤–éƒ¨ãƒªãƒ³ã‚¯ã€ç¬¬ä¸‰è€…ãŒæä¾›ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ»ãƒ„ãƒ¼ãƒ«ãƒ»ãƒ©ã‚¤ãƒ–ãƒ©ãƒªç­‰ã®å†…å®¹ãƒ»å¯ç”¨æ€§ãƒ»å®‰å…¨æ€§ã«ã¤ã„ã¦ã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯ä¸€åˆ‡ã®è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®åˆ©ç”¨ãƒ»å®Ÿè¡Œãƒ»è§£é‡ˆã«ã‚ˆã‚Šç›´æ¥çš„ãƒ»é–“æ¥çš„ãƒ»ä»˜éšçš„ãƒ»ç‰¹åˆ¥ãƒ»çµæœçš„ãƒ»æ‡²ç½°çš„æå®³ãŒç”Ÿã˜ãŸå ´åˆã§ã‚‚ã€é©ç”¨æ³•ã§è¨±å®¹ã•ã‚Œã‚‹æœ€å¤§é™ã®ç¯„å›²ã§ã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å†…å®¹ã¯ã€äºˆå‘Šãªãå¤‰æ›´ãƒ»æ›´æ–°ãƒ»æä¾›åœæ­¢ã•ã‚Œã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®è‘—ä½œæ¨©ãƒ»ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯æ˜è¨˜ã•ã‚ŒãŸæ¡ä»¶(ä¾‹: CC BY 4.0)ã«å¾“ã„ã¾ã™ã€‚å½“è©²ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯é€šå¸¸ã€ç„¡ä¿è¨¼æ¡é …ã‚’å«ã¿ã¾ã™ã€‚</li>
        </ul>
    </section>

<footer>
    <p>&copy; 2025 AI Terakoya. All rights reserved.</p>
</footer>

</body>
</html>
