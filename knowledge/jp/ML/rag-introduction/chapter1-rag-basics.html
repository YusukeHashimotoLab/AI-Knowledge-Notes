<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="RAGã®åŸºç¤ - ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã€ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå‡¦ç†ã€ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°æˆ¦ç•¥">
    <title>ç¬¬1ç« ï¼šRAGã®åŸºç¤ - RAGå…¥é–€ã‚·ãƒªãƒ¼ã‚º</title>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js"></script>
    <style>
        :root {
            --primary-color: #2c3e50;
            --secondary-color: #3498db;
            --accent-color: #e74c3c;
            --bg-color: #ffffff;
            --text-color: #333333;
            --border-color: #e0e0e0;
            --code-bg: #f5f5f5;
            --link-color: #3498db;
            --link-hover: #2980b9;
        }
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", "Hiragino Sans", "Hiragino Kaku Gothic ProN", Meiryo, sans-serif;
            line-height: 1.8;
            color: var(--text-color);
            background: var(--bg-color);
            padding: 0;
            margin: 0;
        }
        .container { max-width: 900px; margin: 0 auto; padding: 2rem 1.5rem; }
        header {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 2rem 0;
            margin-bottom: 2rem;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        header .container { padding: 0 1.5rem; }
        h1 { font-size: 2rem; margin-bottom: 0.5rem; font-weight: 700; }
        .meta {
            display: flex;
            gap: 1.5rem;
            flex-wrap: wrap;
            font-size: 0.9rem;
            opacity: 0.95;
            margin-top: 1rem;
        }
        .meta span { display: inline-flex; align-items: center; gap: 0.3rem; }
        h2 {
            font-size: 1.75rem;
            margin-top: 2.5rem;
            margin-bottom: 1rem;
            padding-bottom: 0.5rem;
            border-bottom: 3px solid var(--secondary-color);
            color: var(--primary-color);
        }
        h3 { font-size: 1.4rem; margin-top: 2rem; margin-bottom: 0.8rem; color: var(--primary-color); }
        h4 { font-size: 1.2rem; margin-top: 1.5rem; margin-bottom: 0.6rem; color: var(--primary-color); }
        p { margin-bottom: 1.2rem; }
        a { color: var(--link-color); text-decoration: none; transition: color 0.2s; }
        a:hover { color: var(--link-hover); text-decoration: underline; }
        ul, ol { margin-left: 2rem; margin-bottom: 1.2rem; }
        li { margin-bottom: 0.5rem; }
        pre {
            background: var(--code-bg);
            padding: 1.2rem;
            border-radius: 6px;
            overflow-x: auto;
            margin-bottom: 1.5rem;
            border-left: 4px solid var(--secondary-color);
        }
        code {
            background: var(--code-bg);
            padding: 0.2rem 0.4rem;
            border-radius: 3px;
            font-family: 'Menlo', 'Monaco', 'Courier New', monospace;
            font-size: 0.9em;
        }
        pre code { background: none; padding: 0; }
        .nav-buttons {
            display: flex;
            justify-content: space-between;
            margin: 3rem 0;
            gap: 1rem;
            flex-wrap: wrap;
        }
        .nav-button {
            display: inline-block;
            padding: 0.8rem 1.5rem;
            background: var(--secondary-color);
            color: white;
            border-radius: 6px;
            text-decoration: none;
            transition: all 0.3s;
            font-weight: 600;
        }
        .nav-button:hover {
            background: var(--link-hover);
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(52, 152, 219, 0.3);
        }
        .example-box {
            background: #f8f9fa;
            border-left: 4px solid var(--accent-color);
            padding: 1.2rem;
            margin: 1.5rem 0;
            border-radius: 4px;
        }
        .note-box {
            background: #fff3cd;
            border-left: 4px solid #ffc107;
            padding: 1rem;
            margin: 1.5rem 0;
            border-radius: 4px;
        }
        footer {
            margin-top: 4rem;
            padding: 2rem 0;
            border-top: 2px solid var(--border-color);
            text-align: center;
            color: #666;
            font-size: 0.9rem;
        }
        @media (max-width: 768px) {
            .container { padding: 1rem; }
            h1 { font-size: 1.6rem; }
            h2 { font-size: 1.4rem; }
            .meta { font-size: 0.85rem; }
        }
    
        .feedback-notice {
            background: #fff3cd;
            border: 2px solid #ffc107;
            border-radius: 8px;
            padding: 2rem;
            margin: 3rem auto;
            max-width: 900px;
        }

        .feedback-notice h3 {
            color: #856404;
            font-size: 1.3rem;
            margin-bottom: 1rem;
            text-align: center;
        }

        .feedback-notice p {
            color: #856404;
            font-size: 1rem;
            margin-bottom: 1.5rem;
            text-align: center;
        }

        .feedback-options {
            display: flex;
            justify-content: center;
            gap: 1rem;
            flex-wrap: wrap;
        }

        .feedback-button {
            display: inline-block;
            padding: 0.8rem 1.5rem;
            background: #3498db;
            color: white;
            text-decoration: none;
            border-radius: 6px;
            font-weight: 600;
            transition: all 0.3s;
        }

        .feedback-button:hover {
            background: #2980b9;
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(52, 152, 219, 0.3);
        }

    
        
    
        /* Breadcrumb styles */
        .breadcrumb {
            background: #f7fafc;
            padding: 0.75rem 1rem;
            border-bottom: 1px solid #e2e8f0;
            font-size: 0.9rem;
        }

        .breadcrumb-content {
            max-width: 900px;
            margin: 0 auto;
            display: flex;
            align-items: center;
            flex-wrap: wrap;
            gap: 0.5rem;
        }

        .breadcrumb a {
            color: #667eea;
            text-decoration: none;
            transition: color 0.2s;
        }

        .breadcrumb a:hover {
            color: #764ba2;
            text-decoration: underline;
        }

        .breadcrumb-separator {
            color: #a0aec0;
            margin: 0 0.25rem;
        }

        .breadcrumb-current {
            color: #4a5568;
            font-weight: 500;
        }
    </style>

    <style>
        /* Locale Switcher Styles */
        .locale-switcher {
            display: flex;
            align-items: center;
            gap: 0.5rem;
            padding: 0.5rem 1rem;
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
            border-radius: 6px;
            font-size: 0.9rem;
            margin-bottom: 1rem;
            box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);
        }

        .current-locale {
            font-weight: 600;
            color: #7b2cbf;
            display: flex;
            align-items: center;
            gap: 0.25rem;
        }

        .locale-separator {
            color: #adb5bd;
            font-weight: 300;
        }

        .locale-link {
            color: #f093fb;
            text-decoration: none;
            font-weight: 500;
            transition: all 0.2s ease;
            display: flex;
            align-items: center;
            gap: 0.25rem;
            padding: 0.2rem 0.5rem;
            border-radius: 4px;
        }

        .locale-link:hover {
            background: rgba(240, 147, 251, 0.1);
            color: #d07be8;
            transform: translateY(-1px);
        }

        .locale-meta {
            color: #868e96;
            font-size: 0.85rem;
            font-style: italic;
            margin-left: auto;
        }

        @media (max-width: 768px) {
            .locale-switcher {
                font-size: 0.85rem;
                padding: 0.4rem 0.8rem;
            }
            .locale-meta {
                display: none;
            }
        }
    </style>
</head>
<body>
            <div class="locale-switcher">
<span class="current-locale">ğŸŒ JP</span>
<span class="locale-separator">|</span>
<a href="../../../en/ML/rag-introduction/chapter1-rag-basics.html" class="locale-link">ğŸ‡¬ğŸ‡§ EN</a>
<span class="locale-separator">|</span>
<span class="locale-meta">Last sync: 2025-11-16</span>
</div>
<nav class="breadcrumb">
        <div class="breadcrumb-content">
            <a href="../../index.html">AIå¯ºå­å±‹ãƒˆãƒƒãƒ—</a><span class="breadcrumb-separator">â€º</span><a href="../../ML/index.html">æ©Ÿæ¢°å­¦ç¿’</a><span class="breadcrumb-separator">â€º</span><a href="../../ML/rag-introduction/index.html">Rag</a><span class="breadcrumb-separator">â€º</span><span class="breadcrumb-current">Chapter 1</span>
        </div>
    </nav>

        <header>
        <div class="container">
            <h1>ç¬¬1ç« ï¼šRAGã®åŸºç¤</h1>
            <p style="font-size: 1.1rem; margin-top: 0.5rem; opacity: 0.95;">ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå‡¦ç†</p>
            <div class="meta">
                <span>ğŸ“– å­¦ç¿’æ™‚é–“: 30-35åˆ†</span>
                <span>ğŸ“Š é›£æ˜“åº¦: ä¸­ç´š</span>
                <span>ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹: 6å€‹</span>
            </div>
        </div>
    </header>

    <main class="container">
        <h2>1. RAGã¨ã¯ä½•ã‹</h2>

        <h3>1.1 RAGã®æ¦‚è¦</h3>
        <p>RAGï¼ˆRetrieval-Augmented Generationï¼‰ã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMï¼‰ã«å¤–éƒ¨çŸ¥è­˜ã‚’çµ„ã¿è¾¼ã‚€ãŸã‚ã®æ‰‹æ³•ã§ã™ã€‚LLMã®ç”Ÿæˆèƒ½åŠ›ã¨æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ ã‚’çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã§ã€æœ€æ–°æƒ…å ±ã‚„å°‚é–€çŸ¥è­˜ã«åŸºã¥ã„ãŸå›ç­”ã‚’å¯èƒ½ã«ã—ã¾ã™ã€‚</p>

        <p><strong>ä¸»ãªåˆ©ç‚¹:</strong></p>
        <ul>
            <li><strong>æœ€æ–°æƒ…å ±ã®æ´»ç”¨</strong>: ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã«å«ã¾ã‚Œãªã„æƒ…å ±ã«ã‚¢ã‚¯ã‚»ã‚¹</li>
            <li><strong>ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³å‰Šæ¸›</strong>: æ¤œç´¢çµæœã«åŸºã¥ãå›ç­”ã§ç²¾åº¦å‘ä¸Š</li>
            <li><strong>ã‚³ã‚¹ãƒˆåŠ¹ç‡</strong>: ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ä¸è¦ã§çŸ¥è­˜ã‚’è¿½åŠ </li>
            <li><strong>é€æ˜æ€§</strong>: æƒ…å ±æºã‚’æ˜ç¢ºåŒ–ã—ã€æ¤œè¨¼å¯èƒ½ãªå›ç­”ã‚’æä¾›</li>
        </ul>

        <h3>1.2 RAGã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£</h3>
        <p>RAGã‚·ã‚¹ãƒ†ãƒ ã¯ä»¥ä¸‹ã®3ã¤ã®ä¸»è¦ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã§æ§‹æˆã•ã‚Œã¾ã™ï¼š</p>

        <div class="example-box">
            <strong>RAGãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³:</strong>
            <ol>
                <li><strong>ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ§‹ç¯‰</strong>: ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆèª­ã¿è¾¼ã¿ â†’ ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚° â†’ ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚° â†’ ãƒ™ã‚¯ãƒˆãƒ«DBä¿å­˜</li>
                <li><strong>æ¤œç´¢</strong>: ã‚¯ã‚¨ãƒª â†’ ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚° â†’ é¡ä¼¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ¤œç´¢</li>
                <li><strong>ç”Ÿæˆ</strong>: æ¤œç´¢çµæœ + ã‚¯ã‚¨ãƒª â†’ LLMãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ â†’ å›ç­”ç”Ÿæˆ</li>
            </ol>
        </div>

        <h4>å®Ÿè£…ä¾‹1: åŸºæœ¬çš„ãªRAGã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£</h4>
        <pre><code>from langchain.document_loaders import TextLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import FAISS
from langchain.chat_models import ChatOpenAI
from langchain.chains import RetrievalQA

class SimpleRAG:
    def __init__(self, api_key):
        self.embeddings = OpenAIEmbeddings(openai_api_key=api_key)
        self.llm = ChatOpenAI(temperature=0, openai_api_key=api_key)
        self.vectorstore = None

    def index_documents(self, file_paths):
        """ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åŒ–"""
        documents = []
        for path in file_paths:
            loader = TextLoader(path, encoding='utf-8')
            documents.extend(loader.load())

        # ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=500,
            chunk_overlap=50
        )
        splits = text_splitter.split_documents(documents)

        # ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ä½œæˆ
        self.vectorstore = FAISS.from_documents(splits, self.embeddings)
        print(f"ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åŒ–å®Œäº†: {len(splits)}ãƒãƒ£ãƒ³ã‚¯")

    def query(self, question):
        """è³ªå•å¿œç­”"""
        if not self.vectorstore:
            raise ValueError("ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒæœªã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹")

        qa_chain = RetrievalQA.from_chain_type(
            llm=self.llm,
            chain_type="stuff",
            retriever=self.vectorstore.as_retriever(search_kwargs={"k": 3})
        )

        result = qa_chain({"query": question})
        return result["result"]

# ä½¿ç”¨ä¾‹
rag = SimpleRAG(api_key="your-api-key")
rag.index_documents(["docs/manual.txt", "docs/faq.txt"])
answer = rag.query("è£½å“ã®ä¿è¨¼æœŸé–“ã¯ï¼Ÿ")
print(answer)</code></pre>

        <h2>2. ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå‡¦ç†</h2>

        <h3>2.1 ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒ­ãƒ¼ãƒ€ãƒ¼</h3>
        <p>æ§˜ã€…ãªå½¢å¼ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’èª­ã¿è¾¼ã‚€ãŸã‚ã®ãƒ­ãƒ¼ãƒ€ãƒ¼ãŒç”¨æ„ã•ã‚Œã¦ã„ã¾ã™ï¼š</p>

        <h4>å®Ÿè£…ä¾‹2: è¤‡æ•°ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå¯¾å¿œãƒ­ãƒ¼ãƒ€ãƒ¼</h4>
        <pre><code>from langchain.document_loaders import (
    TextLoader, PDFLoader, CSVLoader,
    UnstructuredMarkdownLoader, UnstructuredHTMLLoader
)
import os

class UniversalDocumentLoader:
    """è¤‡æ•°ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå¯¾å¿œãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒ­ãƒ¼ãƒ€ãƒ¼"""

    LOADERS = {
        '.txt': TextLoader,
        '.pdf': PDFLoader,
        '.csv': CSVLoader,
        '.md': UnstructuredMarkdownLoader,
        '.html': UnstructuredHTMLLoader,
    }

    def load_documents(self, directory):
        """ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®å…¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆèª­ã¿è¾¼ã¿"""
        documents = []

        for root, _, files in os.walk(directory):
            for file in files:
                file_path = os.path.join(root, file)
                ext = os.path.splitext(file)[1].lower()

                if ext in self.LOADERS:
                    loader_class = self.LOADERS[ext]
                    try:
                        loader = loader_class(file_path)
                        docs = loader.load()

                        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿è¿½åŠ 
                        for doc in docs:
                            doc.metadata['source_file'] = file
                            doc.metadata['file_type'] = ext

                        documents.extend(docs)
                        print(f"èª­ã¿è¾¼ã¿: {file} ({len(docs)}ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ)")
                    except Exception as e:
                        print(f"ã‚¨ãƒ©ãƒ¼ ({file}): {e}")

        return documents

# ä½¿ç”¨ä¾‹
loader = UniversalDocumentLoader()
documents = loader.load_documents("./knowledge_base")
print(f"ç·ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•°: {len(documents)}")</code></pre>

        <h3>2.2 ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç®¡ç†</h3>
        <p>ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’é©åˆ‡ã«ç®¡ç†ã™ã‚‹ã“ã¨ã§ã€æ¤œç´¢ç²¾åº¦ã‚’å‘ä¸Šã•ã›ã€ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚’å¯èƒ½ã«ã—ã¾ã™ã€‚</p>

        <h4>å®Ÿè£…ä¾‹3: ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å¼·åŒ–</h4>
        <pre><code>from datetime import datetime
from langchain.schema import Document
import hashlib

class MetadataEnricher:
    """ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å¼·åŒ–"""

    def enrich_documents(self, documents):
        """ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿è¿½åŠ ãƒ»å¼·åŒ–"""
        enriched = []

        for doc in documents:
            # åŸºæœ¬ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
            metadata = doc.metadata.copy()

            # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—
            metadata['indexed_at'] = datetime.now().isoformat()

            # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆé•·
            metadata['char_count'] = len(doc.page_content)
            metadata['word_count'] = len(doc.page_content.split())

            # ãƒãƒƒã‚·ãƒ¥å€¤ï¼ˆé‡è¤‡æ¤œå‡ºç”¨ï¼‰
            content_hash = hashlib.md5(
                doc.page_content.encode()
            ).hexdigest()
            metadata['content_hash'] = content_hash

            # ã‚«ãƒ†ã‚´ãƒªæ¨å®šï¼ˆç°¡æ˜“ç‰ˆï¼‰
            metadata['category'] = self._estimate_category(doc.page_content)

            enriched.append(Document(
                page_content=doc.page_content,
                metadata=metadata
            ))

        return enriched

    def _estimate_category(self, text):
        """ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‹ã‚‰ã‚«ãƒ†ã‚´ãƒªæ¨å®š"""
        keywords = {
            'technical': ['API', 'ã‚³ãƒ¼ãƒ‰', 'å®Ÿè£…', 'é–¢æ•°'],
            'business': ['å¥‘ç´„', 'æ–™é‡‘', 'è²©å£²', 'ãƒ“ã‚¸ãƒã‚¹'],
            'support': ['å•é¡Œ', 'ã‚¨ãƒ©ãƒ¼', 'ãƒˆãƒ©ãƒ–ãƒ«', 'ã‚µãƒãƒ¼ãƒˆ']
        }

        text_lower = text.lower()
        scores = {}

        for category, terms in keywords.items():
            score = sum(1 for term in terms if term.lower() in text_lower)
            scores[category] = score

        return max(scores, key=scores.get) if max(scores.values()) > 0 else 'general'

# ä½¿ç”¨ä¾‹
enricher = MetadataEnricher()
enriched_docs = enricher.enrich_documents(documents)

# ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã«ã‚ˆã‚‹ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
technical_docs = [
    doc for doc in enriched_docs
    if doc.metadata.get('category') == 'technical'
]
print(f"æŠ€è¡“ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ: {len(technical_docs)}ä»¶")</code></pre>

        <h2>3. ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°æˆ¦ç•¥</h2>

        <h3>3.1 å›ºå®šé•·ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°</h3>
        <p>æœ€ã‚‚ã‚·ãƒ³ãƒ—ãƒ«ãªæ–¹æ³•ã§ã€æŒ‡å®šã—ãŸæ–‡å­—æ•°ã¾ãŸã¯ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã§ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’åˆ†å‰²ã—ã¾ã™ã€‚</p>

        <h4>å®Ÿè£…ä¾‹4: å›ºå®šé•·ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°</h4>
        <pre><code>from langchain.text_splitter import CharacterTextSplitter
import tiktoken

class FixedSizeChunker:
    """å›ºå®šé•·ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°"""

    def __init__(self, chunk_size=500, chunk_overlap=50):
        self.chunk_size = chunk_size
        self.chunk_overlap = chunk_overlap
        self.encoding = tiktoken.get_encoding("cl100k_base")

    def chunk_by_characters(self, text):
        """æ–‡å­—æ•°ãƒ™ãƒ¼ã‚¹åˆ†å‰²"""
        splitter = CharacterTextSplitter(
            separator="\n\n",
            chunk_size=self.chunk_size,
            chunk_overlap=self.chunk_overlap,
            length_function=len
        )
        return splitter.split_text(text)

    def chunk_by_tokens(self, text):
        """ãƒˆãƒ¼ã‚¯ãƒ³æ•°ãƒ™ãƒ¼ã‚¹åˆ†å‰²"""
        splitter = CharacterTextSplitter.from_tiktoken_encoder(
            encoding_name="cl100k_base",
            chunk_size=self.chunk_size,
            chunk_overlap=self.chunk_overlap
        )
        return splitter.split_text(text)

    def analyze_chunks(self, chunks):
        """ãƒãƒ£ãƒ³ã‚¯çµ±è¨ˆ"""
        stats = {
            'total_chunks': len(chunks),
            'avg_length': sum(len(c) for c in chunks) / len(chunks),
            'min_length': min(len(c) for c in chunks),
            'max_length': max(len(c) for c in chunks),
        }
        return stats

# ä½¿ç”¨ä¾‹
chunker = FixedSizeChunker(chunk_size=500, chunk_overlap=50)

text = """é•·ã„ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ãƒ†ã‚­ã‚¹ãƒˆ..."""
chunks = chunker.chunk_by_tokens(text)
stats = chunker.analyze_chunks(chunks)

print(f"ãƒãƒ£ãƒ³ã‚¯æ•°: {stats['total_chunks']}")
print(f"å¹³å‡é•·: {stats['avg_length']:.1f}æ–‡å­—")</code></pre>

        <h3>3.2 ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°</h3>
        <p>æ„å‘³çš„ãªã¾ã¨ã¾ã‚Šã‚’è€ƒæ…®ã—ã¦ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’åˆ†å‰²ã™ã‚‹é«˜åº¦ãªæ‰‹æ³•ã§ã™ã€‚</p>

        <h4>å®Ÿè£…ä¾‹5: ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°</h4>
        <pre><code>from langchain.text_splitter import RecursiveCharacterTextSplitter
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity

class SemanticChunker:
    """ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°"""

    def __init__(self, embeddings, similarity_threshold=0.7):
        self.embeddings = embeddings
        self.threshold = similarity_threshold

    def chunk_by_similarity(self, text, min_chunk_size=100):
        """é¡ä¼¼åº¦ãƒ™ãƒ¼ã‚¹åˆ†å‰²"""
        # ã¾ãšæ–‡å˜ä½ã«åˆ†å‰²
        sentences = self._split_sentences(text)

        if len(sentences) <= 1:
            return [text]

        # å„æ–‡ã®ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°å–å¾—
        sentence_embeddings = self.embeddings.embed_documents(sentences)

        # é¡ä¼¼åº¦ã«åŸºã¥ã„ã¦ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
        chunks = []
        current_chunk = [sentences[0]]

        for i in range(1, len(sentences)):
            # å‰ã®æ–‡ã¨ã®é¡ä¼¼åº¦è¨ˆç®—
            sim = cosine_similarity(
                [sentence_embeddings[i-1]],
                [sentence_embeddings[i]]
            )[0][0]

            if sim >= self.threshold:
                current_chunk.append(sentences[i])
            else:
                # æ–°ã—ã„ãƒãƒ£ãƒ³ã‚¯é–‹å§‹
                chunk_text = ' '.join(current_chunk)
                if len(chunk_text) >= min_chunk_size:
                    chunks.append(chunk_text)
                current_chunk = [sentences[i]]

        # æœ€å¾Œã®ãƒãƒ£ãƒ³ã‚¯è¿½åŠ 
        if current_chunk:
            chunks.append(' '.join(current_chunk))

        return chunks

    def _split_sentences(self, text):
        """æ–‡åˆ†å‰²ï¼ˆç°¡æ˜“ç‰ˆï¼‰"""
        import re
        sentences = re.split(r'[ã€‚ï¼ï¼Ÿ\n]+', text)
        return [s.strip() for s in sentences if s.strip()]

# ä½¿ç”¨ä¾‹
from langchain.embeddings import OpenAIEmbeddings

embeddings = OpenAIEmbeddings(openai_api_key="your-api-key")
semantic_chunker = SemanticChunker(embeddings, similarity_threshold=0.75)

text = """æ©Ÿæ¢°å­¦ç¿’ã¯äººå·¥çŸ¥èƒ½ã®ä¸€åˆ†é‡ã§ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å­¦ç¿’ã—ã¾ã™ã€‚
æ·±å±¤å­¦ç¿’ã¯ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚ç”»åƒèªè­˜ã«å„ªã‚Œã¦ã„ã¾ã™ã€‚
è‡ªç„¶è¨€èªå‡¦ç†ã¯ãƒ†ã‚­ã‚¹ãƒˆã‚’æ‰±ã„ã¾ã™ã€‚ç¿»è¨³ã‚„è¦ç´„ãŒå¯èƒ½ã§ã™ã€‚"""

chunks = semantic_chunker.chunk_by_similarity(text)
for i, chunk in enumerate(chunks, 1):
    print(f"ãƒãƒ£ãƒ³ã‚¯{i}: {chunk}")</code></pre>

        <h3>3.3 éšå±¤çš„ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°</h3>
        <p>ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®æ§‹é€ ï¼ˆè¦‹å‡ºã—ã€æ®µè½ãªã©ï¼‰ã‚’è€ƒæ…®ã—ãŸéšå±¤çš„ãªåˆ†å‰²ã‚’è¡Œã„ã¾ã™ã€‚</p>

        <h4>å®Ÿè£…ä¾‹6: éšå±¤çš„ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°</h4>
        <pre><code>from langchain.text_splitter import MarkdownHeaderTextSplitter
from typing import List, Dict

class HierarchicalChunker:
    """éšå±¤çš„ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°"""

    def chunk_markdown(self, markdown_text):
        """Markdownæ§‹é€ ã«åŸºã¥ãåˆ†å‰²"""
        headers_to_split_on = [
            ("#", "H1"),
            ("##", "H2"),
            ("###", "H3"),
        ]

        splitter = MarkdownHeaderTextSplitter(
            headers_to_split_on=headers_to_split_on
        )
        splits = splitter.split_text(markdown_text)

        # éšå±¤æƒ…å ±ã‚’å«ã‚€ãƒãƒ£ãƒ³ã‚¯ä½œæˆ
        hierarchical_chunks = []
        for split in splits:
            chunk = {
                'content': split.page_content,
                'metadata': split.metadata,
                'hierarchy': self._build_hierarchy(split.metadata)
            }
            hierarchical_chunks.append(chunk)

        return hierarchical_chunks

    def _build_hierarchy(self, metadata: Dict) -> str:
        """éšå±¤ãƒ‘ã‚¹æ§‹ç¯‰"""
        parts = []
        for level in ['H1', 'H2', 'H3']:
            if level in metadata:
                parts.append(metadata[level])
        return ' > '.join(parts)

    def chunk_with_context(self, text, chunk_size=500):
        """è¦ªãƒãƒ£ãƒ³ã‚¯ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ä¿æŒ"""
        from langchain.text_splitter import RecursiveCharacterTextSplitter

        # è¦ªãƒãƒ£ãƒ³ã‚¯ä½œæˆ
        parent_splitter = RecursiveCharacterTextSplitter(
            chunk_size=chunk_size * 3,
            chunk_overlap=0
        )
        parent_chunks = parent_splitter.split_text(text)

        # å­ãƒãƒ£ãƒ³ã‚¯ä½œæˆï¼ˆè¦ªæƒ…å ±ã‚’ä¿æŒï¼‰
        child_splitter = RecursiveCharacterTextSplitter(
            chunk_size=chunk_size,
            chunk_overlap=50
        )

        chunks_with_context = []
        for parent_idx, parent in enumerate(parent_chunks):
            child_chunks = child_splitter.split_text(parent)

            for child_idx, child in enumerate(child_chunks):
                chunks_with_context.append({
                    'content': child,
                    'parent_id': parent_idx,
                    'child_id': child_idx,
                    'parent_summary': parent[:200] + '...'  # è¦ªã®è¦ç´„
                })

        return chunks_with_context

# ä½¿ç”¨ä¾‹
hierarchical_chunker = HierarchicalChunker()

markdown_text = """
# ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹
ãƒ‡ãƒ¼ã‚¿åˆ†æã®åŸºç¤ã‚’å­¦ã³ã¾ã™ã€‚

## çµ±è¨ˆå­¦
### è¨˜è¿°çµ±è¨ˆ
å¹³å‡ã€åˆ†æ•£ã€æ¨™æº–åå·®ã‚’å­¦ç¿’ã—ã¾ã™ã€‚

### æ¨æ¸¬çµ±è¨ˆ
ä»®èª¬æ¤œå®šã¨ä¿¡é ¼åŒºé–“ã«ã¤ã„ã¦èª¬æ˜ã—ã¾ã™ã€‚

## æ©Ÿæ¢°å­¦ç¿’
### æ•™å¸«ã‚ã‚Šå­¦ç¿’
å›å¸°ã¨åˆ†é¡ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’æ‰±ã„ã¾ã™ã€‚
"""

chunks = hierarchical_chunker.chunk_markdown(markdown_text)
for chunk in chunks:
    print(f"éšå±¤: {chunk['hierarchy']}")
    print(f"å†…å®¹: {chunk['content'][:50]}...")
    print()</code></pre>

        <div class="note-box">
            <strong>ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°æˆ¦ç•¥ã®é¸æŠ:</strong>
            <ul>
                <li><strong>å›ºå®šé•·</strong>: ã‚·ãƒ³ãƒ—ãƒ«ã§é«˜é€Ÿã€ä¸€èˆ¬çš„ãªãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«é©ç”¨</li>
                <li><strong>ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯</strong>: æ„å‘³çš„ä¸€è²«æ€§ãŒé‡è¦ãªå ´åˆã«ä½¿ç”¨</li>
                <li><strong>éšå±¤çš„</strong>: æ§‹é€ åŒ–ã•ã‚ŒãŸãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆï¼ˆæŠ€è¡“æ–‡æ›¸ã€ãƒãƒ‹ãƒ¥ã‚¢ãƒ«ï¼‰ã«æœ€é©</li>
            </ul>
        </div>

        <h2>ã¾ã¨ã‚</h2>
        <ul>
            <li>RAGã¯æ¤œç´¢ã¨ç”Ÿæˆã‚’çµ„ã¿åˆã‚ã›ãŸå¼·åŠ›ãªLLMæ‹¡å¼µæ‰‹æ³•</li>
            <li>ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå‡¦ç†ã§ã¯é©åˆ‡ãªãƒ­ãƒ¼ãƒ€ãƒ¼ã¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç®¡ç†ãŒé‡è¦</li>
            <li>ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°æˆ¦ç•¥ã¯ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã«å¿œã˜ã¦é¸æŠ</li>
            <li>å›ºå®šé•·ã€ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ã€éšå±¤çš„ã®3ã¤ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ç†è§£</li>
        </ul>

        <div class="nav-buttons">
            <a href="./index.html" class="nav-button">â† ã‚·ãƒªãƒ¼ã‚ºç›®æ¬¡</a>
            <a href="./chapter2-embeddings.html" class="nav-button">ç¬¬2ç« ã¸ â†’</a>
        </div>
    <section class="disclaimer">
<h3>å…è²¬äº‹é …</h3>
<ul>
<li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯æ•™è‚²ãƒ»ç ”ç©¶ãƒ»æƒ…å ±æä¾›ã®ã¿ã‚’ç›®çš„ã¨ã—ã¦ãŠã‚Šã€å°‚é–€çš„ãªåŠ©è¨€(æ³•å¾‹ãƒ»ä¼šè¨ˆãƒ»æŠ€è¡“çš„ä¿è¨¼ãªã©)ã‚’æä¾›ã™ã‚‹ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚</li>
<li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŠã‚ˆã³ä»˜éšã™ã‚‹Code examplesã¯ã€Œç¾çŠ¶æœ‰å§¿(AS IS)ã€ã§æä¾›ã•ã‚Œã€æ˜ç¤ºã¾ãŸã¯é»™ç¤ºã‚’å•ã‚ãšã€å•†å“æ€§ã€ç‰¹å®šç›®çš„é©åˆæ€§ã€æ¨©åˆ©éä¾µå®³ã€æ­£ç¢ºæ€§ãƒ»å®Œå…¨æ€§ã€å‹•ä½œãƒ»å®‰å…¨æ€§ç­‰ã„ã‹ãªã‚‹ä¿è¨¼ã‚‚ã—ã¾ã›ã‚“ã€‚</li>
<li>å¤–éƒ¨ãƒªãƒ³ã‚¯ã€ç¬¬ä¸‰è€…ãŒæä¾›ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ»ãƒ„ãƒ¼ãƒ«ãƒ»ãƒ©ã‚¤ãƒ–ãƒ©ãƒªç­‰ã®å†…å®¹ãƒ»å¯ç”¨æ€§ãƒ»å®‰å…¨æ€§ã«ã¤ã„ã¦ã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯ä¸€åˆ‡ã®è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚</li>
<li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®åˆ©ç”¨ãƒ»å®Ÿè¡Œãƒ»è§£é‡ˆã«ã‚ˆã‚Šç›´æ¥çš„ãƒ»é–“æ¥çš„ãƒ»ä»˜éšçš„ãƒ»ç‰¹åˆ¥ãƒ»çµæœçš„ãƒ»æ‡²ç½°çš„æå®³ãŒç”Ÿã˜ãŸå ´åˆã§ã‚‚ã€é©ç”¨æ³•ã§è¨±å®¹ã•ã‚Œã‚‹æœ€å¤§é™ã®ç¯„å›²ã§ã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚</li>
<li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å†…å®¹ã¯ã€äºˆå‘Šãªãå¤‰æ›´ãƒ»æ›´æ–°ãƒ»æä¾›åœæ­¢ã•ã‚Œã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚</li>
<li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®è‘—ä½œæ¨©ãƒ»ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯æ˜è¨˜ã•ã‚ŒãŸæ¡ä»¶(ä¾‹: CC BY 4.0)ã«å¾“ã„ã¾ã™ã€‚å½“è©²ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯é€šå¸¸ã€ç„¡ä¿è¨¼æ¡é …ã‚’å«ã¿ã¾ã™ã€‚</li>
</ul>
</section>

</main>


        <div class="feedback-notice">
            <h3>âš ï¸ ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å“è³ªå‘ä¸Šã«ã”å”åŠ›ãã ã•ã„</h3>
            <p>ã“ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯AIã‚’æ´»ç”¨ã—ã¦ä½œæˆã•ã‚Œã¦ã„ã¾ã™ã€‚èª¤ã‚Šã‚„æ”¹å–„ç‚¹ã‚’è¦‹ã¤ã‘ã‚‰ã‚ŒãŸå ´åˆã¯ã€ä»¥ä¸‹ã®æ–¹æ³•ã§ã”å ±å‘Šãã ã•ã„ï¼š</p>
            <div class="feedback-options">
                <a href="https://forms.gle/9GfVBa2Qa7Uy9taQA" target="_blank" class="feedback-button">
                    ğŸ“ ä¿®æ­£ä¾é ¼ãƒ•ã‚©ãƒ¼ãƒ 
                </a>
                <a href="mailto:yusuke.hashimoto.d8@tohoku.ac.jp" class="feedback-button">
                    âœ‰ï¸ ãƒ¡ãƒ¼ãƒ«ã§é€£çµ¡
                </a>
            </div>
        </div>

    <footer>
        <div class="container">
            <p>&copy; 2025 AI Terakoya - Dr. Yusuke Hashimoto, Tohoku University</p>
            <p>Licensed under CC BY 4.0</p>
        </div>
    </footer>
</body>
</html>
