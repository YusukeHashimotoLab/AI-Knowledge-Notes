<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ã¨æ¤œç´¢ - ãƒ™ã‚¯ãƒˆãƒ«è¡¨ç¾ã€é¡ä¼¼åº¦æ¤œç´¢ã€ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹">
    <title>ç¬¬2ç« ï¼šã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ã¨æ¤œç´¢ - RAGå…¥é–€ã‚·ãƒªãƒ¼ã‚º</title>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js"></script>
    <style>
        :root {
            --primary-color: #2c3e50;
            --secondary-color: #3498db;
            --accent-color: #e74c3c;
            --bg-color: #ffffff;
            --text-color: #333333;
            --border-color: #e0e0e0;
            --code-bg: #f5f5f5;
            --link-color: #3498db;
            --link-hover: #2980b9;
        }
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", "Hiragino Sans", "Hiragino Kaku Gothic ProN", Meiryo, sans-serif;
            line-height: 1.8;
            color: var(--text-color);
            background: var(--bg-color);
            padding: 0;
            margin: 0;
        }
        .container { max-width: 900px; margin: 0 auto; padding: 2rem 1.5rem; }
        header {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 2rem 0;
            margin-bottom: 2rem;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        header .container { padding: 0 1.5rem; }
        h1 { font-size: 2rem; margin-bottom: 0.5rem; font-weight: 700; }
        .meta {
            display: flex;
            gap: 1.5rem;
            flex-wrap: wrap;
            font-size: 0.9rem;
            opacity: 0.95;
            margin-top: 1rem;
        }
        .meta span { display: inline-flex; align-items: center; gap: 0.3rem; }
        h2 {
            font-size: 1.75rem;
            margin-top: 2.5rem;
            margin-bottom: 1rem;
            padding-bottom: 0.5rem;
            border-bottom: 3px solid var(--secondary-color);
            color: var(--primary-color);
        }
        h3 { font-size: 1.4rem; margin-top: 2rem; margin-bottom: 0.8rem; color: var(--primary-color); }
        h4 { font-size: 1.2rem; margin-top: 1.5rem; margin-bottom: 0.6rem; color: var(--primary-color); }
        p { margin-bottom: 1.2rem; }
        a { color: var(--link-color); text-decoration: none; transition: color 0.2s; }
        a:hover { color: var(--link-hover); text-decoration: underline; }
        ul, ol { margin-left: 2rem; margin-bottom: 1.2rem; }
        li { margin-bottom: 0.5rem; }
        pre {
            background: var(--code-bg);
            padding: 1.2rem;
            border-radius: 6px;
            overflow-x: auto;
            margin-bottom: 1.5rem;
            border-left: 4px solid var(--secondary-color);
        }
        code {
            background: var(--code-bg);
            padding: 0.2rem 0.4rem;
            border-radius: 3px;
            font-family: 'Menlo', 'Monaco', 'Courier New', monospace;
            font-size: 0.9em;
        }
        pre code { background: none; padding: 0; }
        .nav-buttons {
            display: flex;
            justify-content: space-between;
            margin: 3rem 0;
            gap: 1rem;
            flex-wrap: wrap;
        }
        .nav-button {
            display: inline-block;
            padding: 0.8rem 1.5rem;
            background: var(--secondary-color);
            color: white;
            border-radius: 6px;
            text-decoration: none;
            transition: all 0.3s;
            font-weight: 600;
        }
        .nav-button:hover {
            background: var(--link-hover);
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(52, 152, 219, 0.3);
        }
        .example-box {
            background: #f8f9fa;
            border-left: 4px solid var(--accent-color);
            padding: 1.2rem;
            margin: 1.5rem 0;
            border-radius: 4px;
        }
        .note-box {
            background: #fff3cd;
            border-left: 4px solid #ffc107;
            padding: 1rem;
            margin: 1.5rem 0;
            border-radius: 4px;
        }
        footer {
            margin-top: 4rem;
            padding: 2rem 0;
            border-top: 2px solid var(--border-color);
            text-align: center;
            color: #666;
            font-size: 0.9rem;
        }
        @media (max-width: 768px) {
            .container { padding: 1rem; }
            h1 { font-size: 1.6rem; }
            h2 { font-size: 1.4rem; }
            .meta { font-size: 0.85rem; }
        }
    
        .feedback-notice {
            background: #fff3cd;
            border: 2px solid #ffc107;
            border-radius: 8px;
            padding: 2rem;
            margin: 3rem auto;
            max-width: 900px;
        }

        .feedback-notice h3 {
            color: #856404;
            font-size: 1.3rem;
            margin-bottom: 1rem;
            text-align: center;
        }

        .feedback-notice p {
            color: #856404;
            font-size: 1rem;
            margin-bottom: 1.5rem;
            text-align: center;
        }

        .feedback-options {
            display: flex;
            justify-content: center;
            gap: 1rem;
            flex-wrap: wrap;
        }

        .feedback-button {
            display: inline-block;
            padding: 0.8rem 1.5rem;
            background: #3498db;
            color: white;
            text-decoration: none;
            border-radius: 6px;
            font-weight: 600;
            transition: all 0.3s;
        }

        .feedback-button:hover {
            background: #2980b9;
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(52, 152, 219, 0.3);
        }

    
        
    
        /* Breadcrumb styles */
        .breadcrumb {
            background: #f7fafc;
            padding: 0.75rem 1rem;
            border-bottom: 1px solid #e2e8f0;
            font-size: 0.9rem;
        }

        .breadcrumb-content {
            max-width: 900px;
            margin: 0 auto;
            display: flex;
            align-items: center;
            flex-wrap: wrap;
            gap: 0.5rem;
        }

        .breadcrumb a {
            color: #667eea;
            text-decoration: none;
            transition: color 0.2s;
        }

        .breadcrumb a:hover {
            color: #764ba2;
            text-decoration: underline;
        }

        .breadcrumb-separator {
            color: #a0aec0;
            margin: 0 0.25rem;
        }

        .breadcrumb-current {
            color: #4a5568;
            font-weight: 500;
        }
    </style>

    <style>
        /* Locale Switcher Styles */
        .locale-switcher {
            display: flex;
            align-items: center;
            gap: 0.5rem;
            padding: 0.5rem 1rem;
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
            border-radius: 6px;
            font-size: 0.9rem;
            margin-bottom: 1rem;
            box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);
        }

        .current-locale {
            font-weight: 600;
            color: #7b2cbf;
            display: flex;
            align-items: center;
            gap: 0.25rem;
        }

        .locale-separator {
            color: #adb5bd;
            font-weight: 300;
        }

        .locale-link {
            color: #f093fb;
            text-decoration: none;
            font-weight: 500;
            transition: all 0.2s ease;
            display: flex;
            align-items: center;
            gap: 0.25rem;
            padding: 0.2rem 0.5rem;
            border-radius: 4px;
        }

        .locale-link:hover {
            background: rgba(240, 147, 251, 0.1);
            color: #d07be8;
            transform: translateY(-1px);
        }

        .locale-meta {
            color: #868e96;
            font-size: 0.85rem;
            font-style: italic;
            margin-left: auto;
        }

        @media (max-width: 768px) {
            .locale-switcher {
                font-size: 0.85rem;
                padding: 0.4rem 0.8rem;
            }
            .locale-meta {
                display: none;
            }
        }
    </style>
</head>
<body>
            <div class="locale-switcher">
<span class="current-locale">ğŸŒ JP</span>
<span class="locale-separator">|</span>
<a href="../../../en/ML/rag-introduction/chapter2-embeddings.html" class="locale-link">ğŸ‡¬ğŸ‡§ EN</a>
<span class="locale-separator">|</span>
<span class="locale-meta">Last sync: 2025-11-16</span>
</div>
<nav class="breadcrumb">
        <div class="breadcrumb-content">
            <a href="../../index.html">AIå¯ºå­å±‹ãƒˆãƒƒãƒ—</a><span class="breadcrumb-separator">â€º</span><a href="../../ML/index.html">æ©Ÿæ¢°å­¦ç¿’</a><span class="breadcrumb-separator">â€º</span><a href="../../ML/rag-introduction/index.html">Rag</a><span class="breadcrumb-separator">â€º</span><span class="breadcrumb-current">Chapter 2</span>
        </div>
    </nav>

        <header>
        <div class="container">
            <h1>ç¬¬2ç« ï¼šã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ã¨æ¤œç´¢</h1>
            <p style="font-size: 1.1rem; margin-top: 0.5rem; opacity: 0.95;">ãƒ™ã‚¯ãƒˆãƒ«è¡¨ç¾ã¨é¡ä¼¼åº¦æ¤œç´¢</p>
            <div class="meta">
                <span>ğŸ“– å­¦ç¿’æ™‚é–“: 30-35åˆ†</span>
                <span>ğŸ“Š é›£æ˜“åº¦: ä¸­ç´š</span>
                <span>ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹: 6å€‹</span>
            </div>
        </div>
    </header>

    <main class="container">
        <h2>1. ãƒ™ã‚¯ãƒˆãƒ«ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°</h2>

        <h3>1.1 ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ã®æ¦‚å¿µ</h3>
        <p>ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ã¨ã¯ã€ãƒ†ã‚­ã‚¹ãƒˆã‚’é«˜æ¬¡å…ƒãƒ™ã‚¯ãƒˆãƒ«ç©ºé–“ä¸Šã®ç‚¹ã¨ã—ã¦è¡¨ç¾ã™ã‚‹æŠ€è¡“ã§ã™ã€‚æ„å‘³çš„ã«é¡ä¼¼ã—ãŸãƒ†ã‚­ã‚¹ãƒˆã¯ã€ãƒ™ã‚¯ãƒˆãƒ«ç©ºé–“ã§ã‚‚è¿‘ã„ä½ç½®ã«é…ç½®ã•ã‚Œã¾ã™ã€‚</p>

        <p><strong>ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ã®ç‰¹æ€§:</strong></p>
        <ul>
            <li><strong>æ„å‘³è¡¨ç¾</strong>: å˜èªã‚„ãƒ†ã‚­ã‚¹ãƒˆã®æ„å‘³ã‚’æ•°å€¤ãƒ™ã‚¯ãƒˆãƒ«ã§æ‰ãˆã‚‹</li>
            <li><strong>æ¬¡å…ƒå‰Šæ¸›</strong>: é«˜æ¬¡å…ƒã®è¨€èªç©ºé–“ã‚’å›ºå®šæ¬¡å…ƒï¼ˆä¾‹: 1536æ¬¡å…ƒï¼‰ã«åœ§ç¸®</li>
            <li><strong>æ¯”è¼ƒå¯èƒ½æ€§</strong>: ãƒ™ã‚¯ãƒˆãƒ«æ¼”ç®—ã«ã‚ˆã‚Šé¡ä¼¼åº¦ã‚’è¨ˆç®—</li>
        </ul>

        <div class="example-box">
            <strong>ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦:</strong>
            <p>2ã¤ã®ãƒ™ã‚¯ãƒˆãƒ« \(\mathbf{u}\) ã¨ \(\mathbf{v}\) ã®é¡ä¼¼åº¦:</p>
            $$\text{similarity}(\mathbf{u}, \mathbf{v}) = \frac{\mathbf{u} \cdot \mathbf{v}}{\|\mathbf{u}\| \|\mathbf{v}\|}$$
            <p>ç¯„å›²: -1ï¼ˆæ­£åå¯¾ï¼‰ï½ 1ï¼ˆå®Œå…¨ä¸€è‡´ï¼‰</p>
        </div>

        <h4>å®Ÿè£…ä¾‹1: ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ç”Ÿæˆã¨é¡ä¼¼åº¦è¨ˆç®—</h4>
        <pre><code>from openai import OpenAI
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity

class EmbeddingGenerator:
    """ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ç”Ÿæˆã¨é¡ä¼¼åº¦è¨ˆç®—"""

    def __init__(self, api_key, model="text-embedding-3-small"):
        self.client = OpenAI(api_key=api_key)
        self.model = model

    def get_embedding(self, text):
        """å˜ä¸€ãƒ†ã‚­ã‚¹ãƒˆã®ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°å–å¾—"""
        response = self.client.embeddings.create(
            input=text,
            model=self.model
        )
        return np.array(response.data[0].embedding)

    def get_embeddings_batch(self, texts, batch_size=100):
        """ãƒãƒƒãƒå‡¦ç†ã§ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°å–å¾—"""
        embeddings = []

        for i in range(0, len(texts), batch_size):
            batch = texts[i:i + batch_size]
            response = self.client.embeddings.create(
                input=batch,
                model=self.model
            )
            batch_embeddings = [
                np.array(data.embedding) for data in response.data
            ]
            embeddings.extend(batch_embeddings)

        return np.array(embeddings)

    def cosine_similarity(self, vec1, vec2):
        """ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦è¨ˆç®—"""
        return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))

    def find_most_similar(self, query_text, document_texts, top_k=5):
        """æœ€ã‚‚é¡ä¼¼ã—ãŸãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’æ¤œç´¢"""
        # ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°å–å¾—
        query_emb = self.get_embedding(query_text)
        doc_embs = self.get_embeddings_batch(document_texts)

        # é¡ä¼¼åº¦è¨ˆç®—
        similarities = cosine_similarity([query_emb], doc_embs)[0]

        # Top-Kå–å¾—
        top_indices = np.argsort(similarities)[::-1][:top_k]

        results = [
            {
                'text': document_texts[idx],
                'score': float(similarities[idx]),
                'rank': rank + 1
            }
            for rank, idx in enumerate(top_indices)
        ]

        return results

# ä½¿ç”¨ä¾‹
generator = EmbeddingGenerator(api_key="your-api-key")

documents = [
    "æ©Ÿæ¢°å­¦ç¿’ã¯ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å­¦ç¿’ã™ã‚‹AIæŠ€è¡“ã§ã™",
    "æ·±å±¤å­¦ç¿’ã¯ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’ä½¿ç”¨ã—ã¾ã™",
    "è‡ªç„¶è¨€èªå‡¦ç†ã¯ãƒ†ã‚­ã‚¹ãƒˆåˆ†æã®æ‰‹æ³•ã§ã™",
    "ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ãƒ“ã‚¸ãƒ§ãƒ³ã¯ç”»åƒèªè­˜ã«ç‰¹åŒ–ã—ã¦ã„ã¾ã™"
]

query = "AIã«ã‚ˆã‚‹ãƒ†ã‚­ã‚¹ãƒˆè§£æ"
results = generator.find_most_similar(query, documents, top_k=3)

for result in results:
    print(f"ãƒ©ãƒ³ã‚¯{result['rank']}: {result['text']}")
    print(f"é¡ä¼¼åº¦: {result['score']:.4f}\n")</code></pre>

        <h3>1.2 ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«ã®é¸æŠ</h3>
        <p>æ§˜ã€…ãªã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«ãŒå­˜åœ¨ã—ã€ç”¨é€”ã«å¿œã˜ã¦é¸æŠã—ã¾ã™ã€‚</p>

        <h4>å®Ÿè£…ä¾‹2: è¤‡æ•°ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«ã®æ¯”è¼ƒ</h4>
        <pre><code>from sentence_transformers import SentenceTransformer
from langchain.embeddings import (
    OpenAIEmbeddings, HuggingFaceEmbeddings
)
import time

class EmbeddingComparison:
    """è¤‡æ•°ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«ã®æ¯”è¼ƒ"""

    def __init__(self):
        self.models = {}

    def load_models(self, openai_api_key=None):
        """å„ç¨®ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿"""
        # OpenAI
        if openai_api_key:
            self.models['openai-small'] = OpenAIEmbeddings(
                model="text-embedding-3-small",
                openai_api_key=openai_api_key
            )
            self.models['openai-large'] = OpenAIEmbeddings(
                model="text-embedding-3-large",
                openai_api_key=openai_api_key
            )

        # Sentence Transformers (ãƒ­ãƒ¼ã‚«ãƒ«)
        self.models['multilingual'] = SentenceTransformer(
            'paraphrase-multilingual-MiniLM-L12-v2'
        )
        self.models['japanese'] = SentenceTransformer(
            'sentence-transformers/distiluse-base-multilingual-cased-v1'
        )

    def benchmark_model(self, model_name, texts):
        """ãƒ¢ãƒ‡ãƒ«ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯"""
        model = self.models[model_name]

        start = time.time()

        if isinstance(model, SentenceTransformer):
            embeddings = model.encode(texts)
        else:
            embeddings = model.embed_documents(texts)

        elapsed = time.time() - start

        return {
            'model': model_name,
            'num_texts': len(texts),
            'time': elapsed,
            'time_per_text': elapsed / len(texts),
            'dimension': len(embeddings[0])
        }

    def compare_all_models(self, test_texts):
        """å…¨ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ"""
        results = []

        for model_name in self.models.keys():
            try:
                result = self.benchmark_model(model_name, test_texts)
                results.append(result)
                print(f"{model_name}: {result['time']:.2f}ç§’ "
                      f"(æ¬¡å…ƒ: {result['dimension']})")
            except Exception as e:
                print(f"{model_name}: ã‚¨ãƒ©ãƒ¼ - {e}")

        return results

# ä½¿ç”¨ä¾‹
comparator = EmbeddingComparison()
comparator.load_models(openai_api_key="your-api-key")

test_texts = [
    "æ©Ÿæ¢°å­¦ç¿’ã®åŸºç¤ã‚’å­¦ã¶",
    "æ·±å±¤å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰",
    "è‡ªç„¶è¨€èªå‡¦ç†ã®å¿œç”¨"
] * 10  # 30ãƒ†ã‚­ã‚¹ãƒˆ

results = comparator.compare_all_models(test_texts)</code></pre>

        <h2>2. é¡ä¼¼åº¦æ¤œç´¢</h2>

        <h3>2.1 æ¤œç´¢ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ </h3>
        <p>ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¯ã€å¤§è¦æ¨¡ãªã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‹ã‚‰é«˜é€Ÿã«é¡ä¼¼ãƒ™ã‚¯ãƒˆãƒ«ã‚’æ¤œç´¢ã—ã¾ã™ã€‚</p>

        <div class="example-box">
            <strong>ä¸»è¦ãªæ¤œç´¢æ‰‹æ³•:</strong>
            <ul>
                <li><strong>ç·å½“ãŸã‚Šæ¤œç´¢</strong>: å…¨ãƒ™ã‚¯ãƒˆãƒ«ã¨æ¯”è¼ƒï¼ˆå°è¦æ¨¡ãƒ‡ãƒ¼ã‚¿å‘ã‘ï¼‰</li>
                <li><strong>è¿‘ä¼¼æœ€è¿‘å‚æ¢ç´¢ï¼ˆANNï¼‰</strong>: HNSWã€IVFç­‰ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ§‹é€ </li>
                <li><strong>ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢</strong>: ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ + ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢</li>
            </ul>
        </div>

        <h2>3. ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹</h2>

        <h3>3.1 FAISSï¼ˆFacebook AI Similarity Searchï¼‰</h3>
        <p>MetaãŒé–‹ç™ºã—ãŸé«˜é€Ÿé¡ä¼¼åº¦æ¤œç´¢ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§ã€ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã§å‹•ä½œã—ã¾ã™ã€‚</p>

        <h4>å®Ÿè£…ä¾‹3: FAISSå®Ÿè£…</h4>
        <pre><code>import faiss
import numpy as np
from langchain.vectorstores import FAISS
from langchain.embeddings import OpenAIEmbeddings
from langchain.docstore.document import Document

class FAISSVectorStore:
    """FAISS ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢å®Ÿè£…"""

    def __init__(self, embeddings):
        self.embeddings = embeddings
        self.vectorstore = None

    def create_index(self, documents, index_type='flat'):
        """ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ"""
        # Langchain FAISSä½¿ç”¨
        self.vectorstore = FAISS.from_documents(
            documents,
            self.embeddings
        )

        # ã‚«ã‚¹ã‚¿ãƒ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹è¨­å®šã‚‚å¯èƒ½
        if index_type == 'ivf':
            self._create_ivf_index(documents)

        print(f"ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆå®Œäº†: {len(documents)}ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ")

    def _create_ivf_index(self, documents):
        """IVFï¼ˆInverted Fileï¼‰ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ"""
        # ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°å–å¾—
        texts = [doc.page_content for doc in documents]
        embeddings = self.embeddings.embed_documents(texts)
        embeddings_array = np.array(embeddings).astype('float32')

        # æ¬¡å…ƒæ•°
        dimension = embeddings_array.shape[1]

        # IVFã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ
        nlist = 100  # ã‚¯ãƒ©ã‚¹ã‚¿æ•°
        quantizer = faiss.IndexFlatL2(dimension)
        index = faiss.IndexIVFFlat(quantizer, dimension, nlist)

        # å­¦ç¿’
        index.train(embeddings_array)
        index.add(embeddings_array)

        print(f"IVFã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ: {nlist}ã‚¯ãƒ©ã‚¹ã‚¿")
        return index

    def search(self, query, k=5, score_threshold=None):
        """é¡ä¼¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ¤œç´¢"""
        if score_threshold:
            results = self.vectorstore.similarity_search_with_relevance_scores(
                query, k=k
            )
            # ã‚¹ã‚³ã‚¢ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            filtered = [
                (doc, score) for doc, score in results
                if score >= score_threshold
            ]
            return filtered
        else:
            return self.vectorstore.similarity_search(query, k=k)

    def search_with_metadata_filter(self, query, k=5, filter_dict=None):
        """ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ«ã‚¿ä»˜ãæ¤œç´¢"""
        if filter_dict:
            return self.vectorstore.similarity_search(
                query, k=k, filter=filter_dict
            )
        return self.search(query, k=k)

    def save_local(self, path):
        """ãƒ­ãƒ¼ã‚«ãƒ«ä¿å­˜"""
        self.vectorstore.save_local(path)
        print(f"ä¿å­˜å®Œäº†: {path}")

    def load_local(self, path):
        """ãƒ­ãƒ¼ã‚«ãƒ«èª­ã¿è¾¼ã¿"""
        self.vectorstore = FAISS.load_local(
            path, self.embeddings
        )
        print(f"èª­ã¿è¾¼ã¿å®Œäº†: {path}")

# ä½¿ç”¨ä¾‹
embeddings = OpenAIEmbeddings(openai_api_key="your-api-key")
faiss_store = FAISSVectorStore(embeddings)

# ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæº–å‚™
documents = [
    Document(
        page_content="Pythonã¯äººæ°—ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªã§ã™",
        metadata={"category": "programming", "language": "ja"}
    ),
    Document(
        page_content="æ©Ÿæ¢°å­¦ç¿’ã«ã¯PythonãŒã‚ˆãä½¿ã‚ã‚Œã¾ã™",
        metadata={"category": "ml", "language": "ja"}
    )
]

# ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ
faiss_store.create_index(documents)

# æ¤œç´¢
results = faiss_store.search("ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èª", k=2)
for doc in results:
    print(f"- {doc.page_content}")

# ä¿å­˜
faiss_store.save_local("./faiss_index")</code></pre>

        <h3>3.2 ChromaDB</h3>
        <p>ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã§ã€ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã«å„ªã‚Œã¦ã„ã¾ã™ã€‚</p>

        <h4>å®Ÿè£…ä¾‹4: ChromaDBå®Ÿè£…</h4>
        <pre><code>import chromadb
from chromadb.config import Settings
from langchain.vectorstores import Chroma
from langchain.embeddings import OpenAIEmbeddings

class ChromaVectorStore:
    """ChromaDB ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢å®Ÿè£…"""

    def __init__(self, embeddings, persist_directory="./chroma_db"):
        self.embeddings = embeddings
        self.persist_directory = persist_directory
        self.vectorstore = None

        # ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆè¨­å®š
        self.client = chromadb.Client(Settings(
            chroma_db_impl="duckdb+parquet",
            persist_directory=persist_directory
        ))

    def create_collection(self, documents, collection_name="default"):
        """ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ä½œæˆ"""
        self.vectorstore = Chroma.from_documents(
            documents=documents,
            embedding=self.embeddings,
            collection_name=collection_name,
            persist_directory=self.persist_directory
        )

        # æ°¸ç¶šåŒ–
        self.vectorstore.persist()
        print(f"ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ä½œæˆ: {collection_name}")

    def add_documents(self, documents):
        """ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆè¿½åŠ """
        if not self.vectorstore:
            raise ValueError("ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³æœªä½œæˆ")

        self.vectorstore.add_documents(documents)
        self.vectorstore.persist()
        print(f"{len(documents)}ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆè¿½åŠ ")

    def search_with_filter(self, query, k=5, where=None, where_document=None):
        """é«˜åº¦ãªãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ¤œç´¢"""
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ«ã‚¿
        if where:
            results = self.vectorstore.similarity_search(
                query, k=k, filter=where
            )
        # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå†…å®¹ãƒ•ã‚£ãƒ«ã‚¿
        elif where_document:
            results = self.vectorstore.similarity_search(
                query, k=k, where_document=where_document
            )
        else:
            results = self.vectorstore.similarity_search(query, k=k)

        return results

    def mmr_search(self, query, k=5, fetch_k=20, lambda_mult=0.5):
        """MMRï¼ˆMaximal Marginal Relevanceï¼‰æ¤œç´¢

        å¤šæ§˜æ€§ã¨é–¢é€£æ€§ã®ãƒãƒ©ãƒ³ã‚¹ã‚’å–ã‚‹æ¤œç´¢
        """
        results = self.vectorstore.max_marginal_relevance_search(
            query,
            k=k,
            fetch_k=fetch_k,
            lambda_mult=lambda_mult  # 0=å¤šæ§˜æ€§é‡è¦–, 1=é–¢é€£æ€§é‡è¦–
        )
        return results

    def delete_collection(self, collection_name):
        """ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å‰Šé™¤"""
        self.client.delete_collection(collection_name)
        print(f"å‰Šé™¤å®Œäº†: {collection_name}")

# ä½¿ç”¨ä¾‹
embeddings = OpenAIEmbeddings(openai_api_key="your-api-key")
chroma_store = ChromaVectorStore(embeddings, persist_directory="./chroma_db")

documents = [
    Document(
        page_content="Pythonæ©Ÿæ¢°å­¦ç¿’å…¥é–€",
        metadata={"type": "tutorial", "level": "beginner", "year": 2024}
    ),
    Document(
        page_content="é«˜åº¦ãªæ·±å±¤å­¦ç¿’ãƒ†ã‚¯ãƒ‹ãƒƒã‚¯",
        metadata={"type": "advanced", "level": "expert", "year": 2024}
    ),
    Document(
        page_content="ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹åŸºç¤",
        metadata={"type": "tutorial", "level": "beginner", "year": 2023}
    )
]

# ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ä½œæˆ
chroma_store.create_collection(documents, collection_name="ml_docs")

# ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ«ã‚¿æ¤œç´¢
results = chroma_store.search_with_filter(
    "æ©Ÿæ¢°å­¦ç¿’",
    k=2,
    where={"level": "beginner", "year": 2024}
)

for doc in results:
    print(f"- {doc.page_content}")
    print(f"  ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿: {doc.metadata}")

# MMRæ¤œç´¢ï¼ˆå¤šæ§˜æ€§é‡è¦–ï¼‰
diverse_results = chroma_store.mmr_search(
    "æ©Ÿæ¢°å­¦ç¿’ã®å­¦ç¿’",
    k=3,
    lambda_mult=0.3  # å¤šæ§˜æ€§é‡è¦–
)
print(f"\nMMRæ¤œç´¢çµæœ: {len(diverse_results)}ä»¶")</code></pre>

        <h3>3.3 Pinecone</h3>
        <p>ã‚¯ãƒ©ã‚¦ãƒ‰ãƒã‚¤ãƒ†ã‚£ãƒ–ãªãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã§ã€ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã«å„ªã‚Œã¦ã„ã¾ã™ã€‚</p>

        <h4>å®Ÿè£…ä¾‹5: Pineconeå®Ÿè£…</h4>
        <pre><code>import pinecone
from langchain.vectorstores import Pinecone
from langchain.embeddings import OpenAIEmbeddings
import time

class PineconeVectorStore:
    """Pinecone ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢å®Ÿè£…"""

    def __init__(self, api_key, environment, embeddings):
        self.embeddings = embeddings

        # PineconeåˆæœŸåŒ–
        pinecone.init(
            api_key=api_key,
            environment=environment
        )

    def create_index(self, index_name, dimension=1536, metric='cosine'):
        """ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ"""
        # æ—¢å­˜ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ç¢ºèª
        if index_name not in pinecone.list_indexes():
            pinecone.create_index(
                name=index_name,
                dimension=dimension,
                metric=metric,
                pods=1,
                pod_type='p1.x1'
            )
            # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æº–å‚™å¾…ã¡
            time.sleep(1)
            print(f"ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ: {index_name}")
        else:
            print(f"æ—¢å­˜ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½¿ç”¨: {index_name}")

    def upsert_documents(self, index_name, documents):
        """ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¢ãƒƒãƒ—ã‚µãƒ¼ãƒˆ"""
        vectorstore = Pinecone.from_documents(
            documents,
            self.embeddings,
            index_name=index_name
        )
        print(f"{len(documents)}ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¢ãƒƒãƒ—ã‚µãƒ¼ãƒˆå®Œäº†")
        return vectorstore

    def search_with_namespace(self, index_name, query, k=5, namespace=None):
        """åå‰ç©ºé–“æŒ‡å®šæ¤œç´¢"""
        vectorstore = Pinecone.from_existing_index(
            index_name=index_name,
            embedding=self.embeddings,
            namespace=namespace
        )

        results = vectorstore.similarity_search_with_score(query, k=k)
        return results

    def hybrid_search(self, index_name, query, k=5, alpha=0.5):
        """ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ï¼ˆå¯†ãƒ™ã‚¯ãƒˆãƒ« + ç–ãƒ™ã‚¯ãƒˆãƒ«ï¼‰

        alpha: 0=ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ã®ã¿, 1=ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã®ã¿
        """
        # Pineconeã®ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢æ©Ÿèƒ½
        index = pinecone.Index(index_name)

        # ã‚¯ã‚¨ãƒªã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°
        query_vector = self.embeddings.embed_query(query)

        # ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢å®Ÿè¡Œ
        results = index.query(
            vector=query_vector,
            top_k=k,
            include_metadata=True,
            # ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
            alpha=alpha
        )

        return results

    def delete_index(self, index_name):
        """ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å‰Šé™¤"""
        if index_name in pinecone.list_indexes():
            pinecone.delete_index(index_name)
            print(f"ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å‰Šé™¤: {index_name}")

    def get_index_stats(self, index_name):
        """ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹çµ±è¨ˆå–å¾—"""
        index = pinecone.Index(index_name)
        stats = index.describe_index_stats()
        return stats

# ä½¿ç”¨ä¾‹
embeddings = OpenAIEmbeddings(openai_api_key="your-openai-key")
pinecone_store = PineconeVectorStore(
    api_key="your-pinecone-key",
    environment="us-west1-gcp",
    embeddings=embeddings
)

# ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ
index_name = "ml-knowledge-base"
pinecone_store.create_index(index_name, dimension=1536)

# ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¢ãƒƒãƒ—ã‚µãƒ¼ãƒˆ
documents = [
    Document(
        page_content="æ©Ÿæ¢°å­¦ç¿’ã®åŸºç¤ç†è«–",
        metadata={"category": "ml", "level": "basic"}
    ),
    Document(
        page_content="æ·±å±¤å­¦ç¿’ã®å®Ÿè£…æ–¹æ³•",
        metadata={"category": "dl", "level": "advanced"}
    )
]

vectorstore = pinecone_store.upsert_documents(index_name, documents)

# æ¤œç´¢
results = pinecone_store.search_with_namespace(
    index_name, "æ©Ÿæ¢°å­¦ç¿’ã®å­¦ã³æ–¹", k=3
)

for doc, score in results:
    print(f"ã‚¹ã‚³ã‚¢: {score:.4f}")
    print(f"å†…å®¹: {doc.page_content}")
    print(f"ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿: {doc.metadata}\n")

# çµ±è¨ˆæƒ…å ±
stats = pinecone_store.get_index_stats(index_name)
print(f"ç·ãƒ™ã‚¯ãƒˆãƒ«æ•°: {stats['total_vector_count']}")</code></pre>

        <h3>3.4 ãƒ™ã‚¯ãƒˆãƒ«DBã®æ¯”è¼ƒã¨é¸æŠ</h3>

        <h4>å®Ÿè£…ä¾‹6: ãƒ™ã‚¯ãƒˆãƒ«DBæ€§èƒ½æ¯”è¼ƒ</h4>
        <pre><code>import time
from typing import List, Dict
from langchain.schema import Document

class VectorDBBenchmark:
    """ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ€§èƒ½æ¯”è¼ƒ"""

    def __init__(self):
        self.results = []

    def benchmark_indexing(self, db_name, vectorstore, documents):
        """ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆæ™‚é–“æ¸¬å®š"""
        start = time.time()

        if db_name == "FAISS":
            vectorstore.create_index(documents)
        elif db_name == "Chroma":
            vectorstore.create_collection(documents)
        elif db_name == "Pinecone":
            vectorstore.upsert_documents("benchmark", documents)

        elapsed = time.time() - start

        return {
            'db': db_name,
            'operation': 'indexing',
            'num_docs': len(documents),
            'time': elapsed,
            'docs_per_sec': len(documents) / elapsed
        }

    def benchmark_search(self, db_name, vectorstore, queries, k=5):
        """æ¤œç´¢æ™‚é–“æ¸¬å®š"""
        start = time.time()

        for query in queries:
            if db_name == "FAISS":
                vectorstore.search(query, k=k)
            elif db_name == "Chroma":
                vectorstore.search_with_filter(query, k=k)
            elif db_name == "Pinecone":
                vectorstore.search_with_namespace("benchmark", query, k=k)

        elapsed = time.time() - start

        return {
            'db': db_name,
            'operation': 'search',
            'num_queries': len(queries),
            'time': elapsed,
            'queries_per_sec': len(queries) / elapsed,
            'avg_latency_ms': (elapsed / len(queries)) * 1000
        }

    def compare_features(self):
        """æ©Ÿèƒ½æ¯”è¼ƒè¡¨"""
        comparison = {
            'FAISS': {
                'type': 'ãƒ­ãƒ¼ã‚«ãƒ«ãƒ©ã‚¤ãƒ–ãƒ©ãƒª',
                'deployment': 'ã‚»ãƒ«ãƒ•ãƒ›ã‚¹ãƒˆ',
                'scalability': 'ä¸­',
                'metadata_filter': 'é™å®šçš„',
                'cost': 'ç„¡æ–™ï¼ˆã‚¤ãƒ³ãƒ•ãƒ©ã‚³ã‚¹ãƒˆã®ã¿ï¼‰',
                'best_for': 'å°ã€œä¸­è¦æ¨¡ã€ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ç’°å¢ƒ'
            },
            'Chroma': {
                'type': 'ãƒ­ãƒ¼ã‚«ãƒ«/ã‚µãƒ¼ãƒãƒ¼',
                'deployment': 'ã‚»ãƒ«ãƒ•ãƒ›ã‚¹ãƒˆ/ã‚¯ãƒ©ã‚¦ãƒ‰',
                'scalability': 'ä¸­ã€œé«˜',
                'metadata_filter': 'å¼·åŠ›',
                'cost': 'ç„¡æ–™ï¼ˆã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ï¼‰',
                'best_for': 'ä¸­è¦æ¨¡ã€é–‹ç™ºç’°å¢ƒ'
            },
            'Pinecone': {
                'type': 'ã‚¯ãƒ©ã‚¦ãƒ‰ã‚µãƒ¼ãƒ“ã‚¹',
                'deployment': 'ãƒãƒãƒ¼ã‚¸ãƒ‰',
                'scalability': 'éå¸¸ã«é«˜ã„',
                'metadata_filter': 'å¼·åŠ›',
                'cost': 'æœ‰æ–™ï¼ˆå¾“é‡èª²é‡‘ï¼‰',
                'best_for': 'å¤§è¦æ¨¡ã€æœ¬ç•ªç’°å¢ƒ'
            }
        }
        return comparison

    def print_comparison(self):
        """æ¯”è¼ƒçµæœè¡¨ç¤º"""
        features = self.compare_features()

        print("=" * 80)
        print("ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ©Ÿèƒ½æ¯”è¼ƒ")
        print("=" * 80)

        for db_name, features_dict in features.items():
            print(f"\nã€{db_name}ã€‘")
            for key, value in features_dict.items():
                print(f"  {key:20s}: {value}")

# ä½¿ç”¨ä¾‹
benchmark = VectorDBBenchmark()

# æ©Ÿèƒ½æ¯”è¼ƒè¡¨ç¤º
benchmark.print_comparison()

# ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
test_documents = [
    Document(page_content=f"ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ{i}")
    for i in range(1000)
]

test_queries = [f"ã‚¯ã‚¨ãƒª{i}" for i in range(100)]

# å„DBã§ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ
# faiss_result = benchmark.benchmark_indexing("FAISS", faiss_store, test_documents)
# chroma_result = benchmark.benchmark_indexing("Chroma", chroma_store, test_documents)

print("\næ€§èƒ½ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Œäº†")</code></pre>

        <div class="note-box">
            <strong>ãƒ™ã‚¯ãƒˆãƒ«DBé¸æŠã‚¬ã‚¤ãƒ‰:</strong>
            <ul>
                <li><strong>FAISS</strong>: ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ã€å°è¦æ¨¡ã€ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ç’°å¢ƒ</li>
                <li><strong>Chroma</strong>: é–‹ç™ºç’°å¢ƒã€ä¸­è¦æ¨¡ã€ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ´»ç”¨</li>
                <li><strong>Pinecone</strong>: æœ¬ç•ªç’°å¢ƒã€å¤§è¦æ¨¡ã€ãƒãƒãƒ¼ã‚¸ãƒ‰ã‚µãƒ¼ãƒ“ã‚¹å¸Œæœ›</li>
            </ul>
        </div>

        <h2>ã¾ã¨ã‚</h2>
        <ul>
            <li>ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ã¯ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ™ã‚¯ãƒˆãƒ«ç©ºé–“ã«å¤‰æ›ã—ã€æ„å‘³çš„é¡ä¼¼åº¦ã‚’è¨ˆç®—å¯èƒ½ã«ã™ã‚‹</li>
            <li>ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ãŒæœ€ã‚‚ä¸€èˆ¬çš„ãªé¡ä¼¼åº¦ãƒ¡ãƒˆãƒªã‚¯ã‚¹</li>
            <li>FAISSã€Chromaã€Pineconeã¯ãã‚Œãã‚Œç•°ãªã‚‹ç‰¹æ€§ã‚’æŒã¤</li>
            <li>ç”¨é€”ã¨ã‚¹ã‚±ãƒ¼ãƒ«ã«å¿œã˜ã¦é©åˆ‡ãªãƒ™ã‚¯ãƒˆãƒ«DBã‚’é¸æŠ</li>
        </ul>

        <div class="nav-buttons">
            <a href="./chapter1-rag-basics.html" class="nav-button">â† ç¬¬1ç« </a>
            <a href="./chapter3-advanced-rag.html" class="nav-button">ç¬¬3ç« ã¸ â†’</a>
        </div>
    </main>


        <div class="feedback-notice">
            <h3>âš ï¸ ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å“è³ªå‘ä¸Šã«ã”å”åŠ›ãã ã•ã„</h3>
            <p>ã“ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯AIã‚’æ´»ç”¨ã—ã¦ä½œæˆã•ã‚Œã¦ã„ã¾ã™ã€‚èª¤ã‚Šã‚„æ”¹å–„ç‚¹ã‚’è¦‹ã¤ã‘ã‚‰ã‚ŒãŸå ´åˆã¯ã€ä»¥ä¸‹ã®æ–¹æ³•ã§ã”å ±å‘Šãã ã•ã„ï¼š</p>
            <div class="feedback-options">
                <a href="https://forms.gle/9GfVBa2Qa7Uy9taQA" target="_blank" class="feedback-button">
                    ğŸ“ ä¿®æ­£ä¾é ¼ãƒ•ã‚©ãƒ¼ãƒ 
                </a>
                <a href="mailto:yusuke.hashimoto.d8@tohoku.ac.jp" class="feedback-button">
                    âœ‰ï¸ ãƒ¡ãƒ¼ãƒ«ã§é€£çµ¡
                </a>
            </div>
        </div>

    <footer>
        <div class="container">
            <p>&copy; 2025 AI Terakoya - Dr. Yusuke Hashimoto, Tohoku University</p>
            <p>Licensed under CC BY 4.0</p>
        </div>
    </footer>
</body>
</html>
