<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ç¬¬2ç« ï¼šæ¬¡å…ƒå‰Šæ¸›å…¥é–€ - AI Terakoya</title>

    <style>
        :root {
            --color-primary: #2c3e50;
            --color-primary-dark: #1a252f;
            --color-accent: #7b2cbf;
            --color-accent-light: #9d4edd;
            --color-text: #2d3748;
            --color-text-light: #4a5568;
            --color-bg: #ffffff;
            --color-bg-alt: #f7fafc;
            --color-border: #e2e8f0;
            --color-code-bg: #f8f9fa;
            --color-link: #3182ce;
            --color-link-hover: #2c5aa0;

            --spacing-xs: 0.5rem;
            --spacing-sm: 1rem;
            --spacing-md: 1.5rem;
            --spacing-lg: 2rem;
            --spacing-xl: 3rem;

            --font-body: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            --font-mono: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;

            --border-radius: 8px;
            --box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: var(--font-body);
            line-height: 1.7;
            color: var(--color-text);
            background-color: var(--color-bg);
            font-size: 16px;
        }

        header {
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            padding: var(--spacing-xl) var(--spacing-md);
            margin-bottom: var(--spacing-xl);
            box-shadow: var(--box-shadow);
        }

        .header-content {
            max-width: 900px;
            margin: 0 auto;
        }

        h1 {
            font-size: 2rem;
            font-weight: 700;
            margin-bottom: var(--spacing-sm);
            line-height: 1.2;
        }

        .subtitle {
            font-size: 1.1rem;
            opacity: 0.95;
            font-weight: 400;
            margin-bottom: var(--spacing-md);
        }

        .meta {
            display: flex;
            flex-wrap: wrap;
            gap: var(--spacing-md);
            font-size: 0.9rem;
            opacity: 0.9;
        }

        .meta-item {
            display: flex;
            align-items: center;
            gap: 0.3rem;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 0 var(--spacing-md) var(--spacing-xl);
        }

        h2 {
            font-size: 1.75rem;
            color: var(--color-primary);
            margin-top: var(--spacing-xl);
            margin-bottom: var(--spacing-md);
            padding-bottom: var(--spacing-xs);
            border-bottom: 3px solid var(--color-accent);
        }

        h3 {
            font-size: 1.4rem;
            color: var(--color-primary);
            margin-top: var(--spacing-lg);
            margin-bottom: var(--spacing-sm);
        }

        h4 {
            font-size: 1.1rem;
            color: var(--color-primary-dark);
            margin-top: var(--spacing-md);
            margin-bottom: var(--spacing-sm);
        }

        p {
            margin-bottom: var(--spacing-md);
            color: var(--color-text);
        }

        a {
            color: var(--color-link);
            text-decoration: none;
            transition: color 0.2s;
        }

        a:hover {
            color: var(--color-link-hover);
            text-decoration: underline;
        }

        ul, ol {
            margin-left: var(--spacing-lg);
            margin-bottom: var(--spacing-md);
        }

        li {
            margin-bottom: var(--spacing-xs);
            color: var(--color-text);
        }

        pre {
            background-color: var(--color-code-bg);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            overflow-x: auto;
            margin-bottom: var(--spacing-md);
            font-family: var(--font-mono);
            font-size: 0.9rem;
            line-height: 1.5;
        }

        code {
            font-family: var(--font-mono);
            font-size: 0.9em;
            background-color: var(--color-code-bg);
            padding: 0.2em 0.4em;
            border-radius: 3px;
        }

        pre code {
            background-color: transparent;
            padding: 0;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: var(--spacing-md);
            font-size: 0.95rem;
        }

        th, td {
            border: 1px solid var(--color-border);
            padding: var(--spacing-sm);
            text-align: left;
        }

        th {
            background-color: var(--color-bg-alt);
            font-weight: 600;
            color: var(--color-primary);
        }

        blockquote {
            border-left: 4px solid var(--color-accent);
            padding-left: var(--spacing-md);
            margin: var(--spacing-md) 0;
            color: var(--color-text-light);
            font-style: italic;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        .mermaid {
            text-align: center;
            margin: var(--spacing-lg) 0;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        details {
            background-color: var(--color-bg-alt);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            margin-bottom: var(--spacing-md);
        }

        summary {
            cursor: pointer;
            font-weight: 600;
            color: var(--color-primary);
            user-select: none;
            padding: var(--spacing-xs);
            margin: calc(-1 * var(--spacing-md));
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        summary:hover {
            background-color: rgba(123, 44, 191, 0.1);
        }

        details[open] summary {
            margin-bottom: var(--spacing-md);
            border-bottom: 1px solid var(--color-border);
        }

        .navigation {
            display: flex;
            justify-content: space-between;
            gap: var(--spacing-md);
            margin: var(--spacing-xl) 0;
            padding-top: var(--spacing-lg);
            border-top: 2px solid var(--color-border);
        }

        .nav-button {
            flex: 1;
            padding: var(--spacing-md);
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            border-radius: var(--border-radius);
            text-align: center;
            font-weight: 600;
            transition: transform 0.2s, box-shadow 0.2s;
            box-shadow: var(--box-shadow);
        }

        .nav-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
            text-decoration: none;
        }

        footer {
            margin-top: var(--spacing-xl);
            padding: var(--spacing-lg) var(--spacing-md);
            background-color: var(--color-bg-alt);
            border-top: 1px solid var(--color-border);
            text-align: center;
            font-size: 0.9rem;
            color: var(--color-text-light);
        }
        .disclaimer {
            max-width: 900px;
            margin: 2rem auto;
            padding: 1.5rem;
            background: #f8f9fa;
            border-left: 4px solid #6c757d;
            border-radius: 4px;
        }

        .disclaimer h3 {
            color: #495057;
            margin-bottom: 1rem;
            font-size: 1.1rem;
        }

        .disclaimer ul {
            list-style: none;
            padding-left: 0;
        }

        .disclaimer li {
            padding: 0.5rem 0;
            padding-left: 1.5rem;
            position: relative;
            font-size: 0.9rem;
            color: #6c757d;
            line-height: 1.6;
        }

        .disclaimer li::before {
            content: "âš ï¸";
            position: absolute;
            left: 0;
        }


        @media (max-width: 768px) {
            h1 {
                font-size: 1.5rem;
            }

            h2 {
                font-size: 1.4rem;
            }

            h3 {
                font-size: 1.2rem;
            }

            .meta {
                font-size: 0.85rem;
            }

            .navigation {
                flex-direction: column;
            }

            table {
                font-size: 0.85rem;
            }

            th, td {
                padding: var(--spacing-xs);
            }
        }
    
        /* Breadcrumb styles */
        .breadcrumb {
            background: #f7fafc;
            padding: 0.75rem 1rem;
            border-bottom: 1px solid #e2e8f0;
            font-size: 0.9rem;
        }

        .breadcrumb-content {
            max-width: 900px;
            margin: 0 auto;
            display: flex;
            align-items: center;
            flex-wrap: wrap;
            gap: 0.5rem;
        }

        .breadcrumb a {
            color: #667eea;
            text-decoration: none;
            transition: color 0.2s;
        }

        .breadcrumb a:hover {
            color: #764ba2;
            text-decoration: underline;
        }

        .breadcrumb-separator {
            color: #a0aec0;
            margin: 0 0.25rem;
        }

        .breadcrumb-current {
            color: #4a5568;
            font-weight: 500;
        }
    </style>

    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
        mermaid.initialize({ startOnLoad: true, theme: 'default' });
    </script>

    <!-- MathJax for LaTeX equation rendering -->
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                displayMath: [['$$', '$$'], ['\\[', '\\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
                ignoreHtmlClass: 'mermaid'
            }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" async></script>
</head>
<body>
        <nav class="breadcrumb">
        <div class="breadcrumb-content">
            <a href="/wp/knowledge/jp/index.html">AIå¯ºå­å±‹ãƒˆãƒƒãƒ—</a><span class="breadcrumb-separator">â€º</span><a href="/wp/knowledge/jp/ML/index.html">æ©Ÿæ¢°å­¦ç¿’</a><span class="breadcrumb-separator">â€º</span><a href="/wp/knowledge/jp/ML/unsupervised-learning-introduction/index.html">Unsupervised Learning</a><span class="breadcrumb-separator">â€º</span><span class="breadcrumb-current">Chapter 2</span>
        </div>
    </nav>

    <header>
        <div class="header-content">
            <h1>ç¬¬2ç« ï¼šæ¬¡å…ƒå‰Šæ¸›å…¥é–€</h1>
            <p class="subtitle">é«˜æ¬¡å…ƒãƒ‡ãƒ¼ã‚¿ã®å¯è¦–åŒ–ã¨åŠ¹ç‡åŒ– - PCAã‹ã‚‰t-SNEã€UMAPã¾ã§</p>
            <div class="meta">
                <span class="meta-item">ğŸ“– èª­äº†æ™‚é–“: 25-30åˆ†</span>
                <span class="meta-item">ğŸ“Š é›£æ˜“åº¦: åˆç´šã€œä¸­ç´š</span>
                <span class="meta-item">ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹: 12å€‹</span>
                <span class="meta-item">ğŸ“ æ¼”ç¿’å•é¡Œ: 5å•</span>
            </div>
        </div>
    </header>

    <main class="container">

<h2>å­¦ç¿’ç›®æ¨™</h2>
<p>ã“ã®ç« ã‚’èª­ã‚€ã“ã¨ã§ã€ä»¥ä¸‹ã‚’ç¿’å¾—ã§ãã¾ã™ï¼š</p>
<ul>
<li>âœ… æ¬¡å…ƒå‰Šæ¸›ã®å¿…è¦æ€§ã¨ã€Œæ¬¡å…ƒã®å‘ªã„ã€ã‚’ç†è§£ã™ã‚‹</li>
<li>âœ… ä¸»æˆåˆ†åˆ†æï¼ˆPCAï¼‰ã®ç†è«–ã¨å®Ÿè£…ãŒã§ãã‚‹</li>
<li>âœ… å›ºæœ‰å€¤ãƒ»å›ºæœ‰ãƒ™ã‚¯ãƒˆãƒ«ã®æ„å‘³ã‚’èª¬æ˜ã§ãã‚‹</li>
<li>âœ… t-SNEã«ã‚ˆã‚‹å¯è¦–åŒ–ãŒã§ãã‚‹</li>
<li>âœ… UMAPã®ç‰¹å¾´ã¨ä½¿ã„æ–¹ã‚’ç†è§£ã™ã‚‹</li>
<li>âœ… PCAã€t-SNEã€UMAPã‚’é©åˆ‡ã«ä½¿ã„åˆ†ã‘ã‚‰ã‚Œã‚‹</li>
<li>âœ… æ¬¡å…ƒå‰Šæ¸›å¾Œã®ãƒ‡ãƒ¼ã‚¿ã§æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã§ãã‚‹</li>
</ul>

<hr>

<h2>2.1 æ¬¡å…ƒå‰Šæ¸›ã¨ã¯</h2>

<h3>å®šç¾©</h3>
<p><strong>æ¬¡å…ƒå‰Šæ¸›ï¼ˆDimensionality Reductionï¼‰</strong>ã¯ã€é«˜æ¬¡å…ƒãƒ‡ãƒ¼ã‚¿ã‚’ä½æ¬¡å…ƒç©ºé–“ã«å°„å½±ã—ã€é‡è¦ãªæƒ…å ±ã‚’ä¿æŒã—ãªãŒã‚‰ãƒ‡ãƒ¼ã‚¿ã®æ¬¡å…ƒæ•°ã‚’æ¸›ã‚‰ã™æŠ€è¡“ã§ã™ã€‚</p>

<blockquote>
<p>ã€Œ$d$ æ¬¡å…ƒã®ãƒ‡ãƒ¼ã‚¿ $\mathbf{X} \in \mathbb{R}^{n \times d}$ ã‚’ $k$ æ¬¡å…ƒï¼ˆ$k \ll d$ï¼‰ã«å¤‰æ›: $\mathbf{Z} \in \mathbb{R}^{n \times k}$ã€</p>
</blockquote>

<h3>æ¬¡å…ƒå‰Šæ¸›ã®ç›®çš„</h3>

<table>
<thead>
<tr>
<th>ç›®çš„</th>
<th>èª¬æ˜</th>
<th>å¿œç”¨ä¾‹</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>å¯è¦–åŒ–</strong></td>
<td>é«˜æ¬¡å…ƒãƒ‡ãƒ¼ã‚¿ã‚’2D/3Dã§å¯è¦–åŒ–</td>
<td>æ¢ç´¢çš„ãƒ‡ãƒ¼ã‚¿åˆ†æã€ãƒ‘ã‚¿ãƒ¼ãƒ³ç™ºè¦‹</td>
</tr>
<tr>
<td><strong>è¨ˆç®—åŠ¹ç‡åŒ–</strong></td>
<td>ç‰¹å¾´é‡ã‚’å‰Šæ¸›ã—å­¦ç¿’ã‚’é«˜é€ŸåŒ–</td>
<td>æ©Ÿæ¢°å­¦ç¿’ã®å‰å‡¦ç†</td>
</tr>
<tr>
<td><strong>ãƒã‚¤ã‚ºé™¤å»</strong></td>
<td>ãƒã‚¤ã‚ºã‚’å«ã‚€æ¬¡å…ƒã‚’å‰Šé™¤</td>
<td>ç”»åƒå‡¦ç†ã€ä¿¡å·å‡¦ç†</td>
</tr>
<tr>
<td><strong>éå­¦ç¿’é˜²æ­¢</strong></td>
<td>ç‰¹å¾´é‡æ•°ã‚’æ¸›ã‚‰ã—æ±åŒ–æ€§èƒ½å‘ä¸Š</td>
<td>ãƒ¢ãƒ‡ãƒ«å­¦ç¿’</td>
</tr>
</tbody>
</table>

<h3>æ¬¡å…ƒã®å‘ªã„ï¼ˆCurse of Dimensionalityï¼‰</h3>

<p>æ¬¡å…ƒãŒå¢—åŠ ã™ã‚‹ã¨ã€ä»¥ä¸‹ã®å•é¡ŒãŒç™ºç”Ÿã—ã¾ã™ï¼š</p>

<ol>
<li><strong>ãƒ‡ãƒ¼ã‚¿ã®ç–æ€§</strong>: ãƒ‡ãƒ¼ã‚¿ç‚¹é–“ã®è·é›¢ãŒå¤§ãããªã‚Šã€ãƒ‡ãƒ¼ã‚¿ãŒç©ºé–“ã«æ•£ã‚‰ã°ã‚‹</li>
<li><strong>è¨ˆç®—é‡ã®å¢—åŠ </strong>: æ¬¡å…ƒ $d$ ã«å¯¾ã—ã¦è¨ˆç®—é‡ãŒ $O(d^2)$ ã‚„ $O(d^3)$ ã§å¢—åŠ </li>
<li><strong>éå­¦ç¿’ã®ãƒªã‚¹ã‚¯</strong>: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã«å¯¾ã—ã¦ã‚µãƒ³ãƒ—ãƒ«æ•°ãŒä¸è¶³</li>
</ol>

<pre><code class="language-python">import numpy as np
import matplotlib.pyplot as plt

# æ¬¡å…ƒã®å‘ªã„ã®å¯è¦–åŒ–
np.random.seed(42)
dimensions = [1, 2, 5, 10, 20, 50, 100]
n_samples = 1000

# å„æ¬¡å…ƒã§ã®ãƒ¦ãƒ¼ã‚¯ãƒªãƒƒãƒ‰è·é›¢ã®å¹³å‡ãƒ»åˆ†æ•£
mean_distances = []
std_distances = []

for d in dimensions:
    # ãƒ©ãƒ³ãƒ€ãƒ ã«ã‚µãƒ³ãƒ—ãƒ«ç”Ÿæˆ
    data = np.random.randn(n_samples, d)

    # åŸç‚¹ã‹ã‚‰ã®è·é›¢ã‚’è¨ˆç®—
    distances = np.linalg.norm(data, axis=1)

    mean_distances.append(np.mean(distances))
    std_distances.append(np.std(distances))

plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.plot(dimensions, mean_distances, 'o-', linewidth=2, markersize=8)
plt.xlabel('æ¬¡å…ƒæ•°', fontsize=12)
plt.ylabel('åŸç‚¹ã‹ã‚‰ã®å¹³å‡è·é›¢', fontsize=12)
plt.title('æ¬¡å…ƒæ•°ã¨è·é›¢ã®é–¢ä¿‚', fontsize=14)
plt.grid(True, alpha=0.3)

plt.subplot(1, 2, 2)
plt.plot(dimensions, np.array(std_distances) / np.array(mean_distances),
         's-', linewidth=2, markersize=8, color='red')
plt.xlabel('æ¬¡å…ƒæ•°', fontsize=12)
plt.ylabel('å¤‰å‹•ä¿‚æ•° (std/mean)', fontsize=12)
plt.title('è·é›¢ã®ç›¸å¯¾çš„ãªã°ã‚‰ã¤ã', fontsize=14)
plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

print("=== æ¬¡å…ƒã®å‘ªã„ ===")
print(f"1æ¬¡å…ƒ: å¹³å‡è·é›¢ = {mean_distances[0]:.2f}")
print(f"100æ¬¡å…ƒ: å¹³å‡è·é›¢ = {mean_distances[-1]:.2f}")
print(f"è·é›¢ã®å¢—åŠ ç‡: {mean_distances[-1] / mean_distances[0]:.2f}å€")
</code></pre>

<h3>æ¬¡å…ƒå‰Šæ¸›æ‰‹æ³•ã®åˆ†é¡</h3>

<div class="mermaid">
graph TD
    A[æ¬¡å…ƒå‰Šæ¸›æ‰‹æ³•] --> B[ç·šå½¢æ‰‹æ³•]
    A --> C[éç·šå½¢æ‰‹æ³•]

    B --> B1[PCA ä¸»æˆåˆ†åˆ†æ]
    B --> B2[LDA ç·šå½¢åˆ¤åˆ¥åˆ†æ]
    B --> B3[å› å­åˆ†æ]

    C --> C1[t-SNE]
    C --> C2[UMAP]
    C --> C3[ã‚ªãƒ¼ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€]
    C --> C4[Isomap]

    style A fill:#e3f2fd
    style B fill:#fff3e0
    style C fill:#f3e5f5
</div>

<hr>

<h2>2.2 ä¸»æˆåˆ†åˆ†æï¼ˆPCAï¼‰</h2>

<h3>æ¦‚è¦</h3>

<p><strong>PCAï¼ˆPrincipal Component Analysisï¼‰</strong>ã¯ã€ãƒ‡ãƒ¼ã‚¿ã®åˆ†æ•£ãŒæœ€å¤§ã«ãªã‚‹æ–¹å‘ã‚’è¦‹ã¤ã‘ã€ãã®æ–¹å‘ã«å°„å½±ã™ã‚‹ç·šå½¢æ¬¡å…ƒå‰Šæ¸›æ‰‹æ³•ã§ã™ã€‚</p>

<h3>æ•°å­¦çš„å®šç¾©</h3>

<p><strong>ç›®çš„</strong>: ãƒ‡ãƒ¼ã‚¿ã®åˆ†æ•£ã‚’æœ€å¤§åŒ–ã™ã‚‹ç›´äº¤åŸºåº•ã‚’è¦‹ã¤ã‘ã‚‹</p>

<p>ãƒ‡ãƒ¼ã‚¿è¡Œåˆ— $\mathbf{X} \in \mathbb{R}^{n \times d}$ ã«å¯¾ã—ã¦ï¼š</p>

<ol>
<li><strong>ä¸­å¿ƒåŒ–</strong>: $\mathbf{X}_c = \mathbf{X} - \bar{\mathbf{X}}$</li>
<li><strong>å…±åˆ†æ•£è¡Œåˆ—</strong>: $\mathbf{C} = \frac{1}{n-1} \mathbf{X}_c^T \mathbf{X}_c$</li>
<li><strong>å›ºæœ‰å€¤åˆ†è§£</strong>: $\mathbf{C} = \mathbf{V} \mathbf{\Lambda} \mathbf{V}^T$</li>
</ol>

<p>ç¬¬ $k$ ä¸»æˆåˆ†ã¸ã®å°„å½±ï¼š</p>

<p>$$
\mathbf{Z} = \mathbf{X}_c \mathbf{V}_k
$$</p>

<p>ã“ã“ã§ $\mathbf{V}_k$ ã¯ä¸Šä½ $k$ å€‹ã®å›ºæœ‰ãƒ™ã‚¯ãƒˆãƒ«ï¼ˆä¸»æˆåˆ†ï¼‰</p>

<h3>å›ºæœ‰å€¤ã¨åˆ†æ•£</h3>

<ul>
<li><strong>å›ºæœ‰å€¤ $\lambda_i$</strong>: ç¬¬ $i$ ä¸»æˆåˆ†æ–¹å‘ã®åˆ†æ•£</li>
<li><strong>å›ºæœ‰ãƒ™ã‚¯ãƒˆãƒ« $\mathbf{v}_i$</strong>: ç¬¬ $i$ ä¸»æˆåˆ†ã®æ–¹å‘</li>
<li><strong>å¯„ä¸ç‡</strong>: $\frac{\lambda_i}{\sum_{j=1}^{d} \lambda_j}$ï¼ˆãã®ä¸»æˆåˆ†ãŒèª¬æ˜ã™ã‚‹åˆ†æ•£ã®å‰²åˆï¼‰</li>
</ul>

<h3>PCAã®å®Ÿè£…ï¼ˆNumPyã‚¹ã‚¯ãƒ©ãƒƒãƒï¼‰</h3>

<pre><code class="language-python">import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import load_iris

class PCA_Scratch:
    def __init__(self, n_components):
        self.n_components = n_components
        self.components_ = None
        self.mean_ = None
        self.explained_variance_ = None

    def fit(self, X):
        # ä¸­å¿ƒåŒ–
        self.mean_ = np.mean(X, axis=0)
        X_centered = X - self.mean_

        # å…±åˆ†æ•£è¡Œåˆ—
        cov_matrix = np.cov(X_centered.T)

        # å›ºæœ‰å€¤ãƒ»å›ºæœ‰ãƒ™ã‚¯ãƒˆãƒ«ã‚’è¨ˆç®—
        eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)

        # å›ºæœ‰å€¤ã®é™é †ã«ã‚½ãƒ¼ãƒˆ
        idx = eigenvalues.argsort()[::-1]
        eigenvalues = eigenvalues[idx]
        eigenvectors = eigenvectors[:, idx]

        # ä¸Šä½kå€‹ã®ä¸»æˆåˆ†ã‚’ä¿å­˜
        self.components_ = eigenvectors[:, :self.n_components]
        self.explained_variance_ = eigenvalues[:self.n_components]

        return self

    def transform(self, X):
        # ãƒ‡ãƒ¼ã‚¿ã‚’ä¸­å¿ƒåŒ–ã—ã¦å°„å½±
        X_centered = X - self.mean_
        return np.dot(X_centered, self.components_)

    def fit_transform(self, X):
        self.fit(X)
        return self.transform(X)

    def inverse_transform(self, Z):
        # ä½æ¬¡å…ƒã‹ã‚‰å…ƒã®æ¬¡å…ƒã«å¾©å…ƒ
        return np.dot(Z, self.components_.T) + self.mean_

# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
iris = load_iris()
X = iris.data
y = iris.target

# PCAã®é©ç”¨
pca = PCA_Scratch(n_components=2)
X_pca = pca.fit_transform(X)

# çµæœã®è¡¨ç¤º
print("=== PCAï¼ˆã‚¹ã‚¯ãƒ©ãƒƒãƒå®Ÿè£…ï¼‰ ===")
print(f"å…ƒã®æ¬¡å…ƒ: {X.shape[1]}")
print(f"å‰Šæ¸›å¾Œã®æ¬¡å…ƒ: {X_pca.shape[1]}")
print(f"\nä¸»æˆåˆ†ã®å½¢çŠ¶: {pca.components_.shape}")
print(f"èª¬æ˜ã•ã‚ŒãŸåˆ†æ•£: {pca.explained_variance_}")
print(f"å¯„ä¸ç‡: {pca.explained_variance_ / np.sum(pca.explained_variance_)}")

# å¯è¦–åŒ–
plt.figure(figsize=(10, 6))
colors = ['red', 'green', 'blue']
target_names = iris.target_names

for color, i, target_name in zip(colors, [0, 1, 2], target_names):
    plt.scatter(X_pca[y == i, 0], X_pca[y == i, 1],
                color=color, alpha=0.7, lw=2, label=target_name, s=80)

plt.xlabel('ç¬¬1ä¸»æˆåˆ†', fontsize=12)
plt.ylabel('ç¬¬2ä¸»æˆåˆ†', fontsize=12)
plt.title('PCA: Irisãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ', fontsize=14)
plt.legend(loc='best', shadow=True, fontsize=10)
plt.grid(True, alpha=0.3)
plt.show()
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>=== PCAï¼ˆã‚¹ã‚¯ãƒ©ãƒƒãƒå®Ÿè£…ï¼‰ ===
å…ƒã®æ¬¡å…ƒ: 4
å‰Šæ¸›å¾Œã®æ¬¡å…ƒ: 2

ä¸»æˆåˆ†ã®å½¢çŠ¶: (4, 2)
èª¬æ˜ã•ã‚ŒãŸåˆ†æ•£: [4.22824171 0.24267075]
å¯„ä¸ç‡: [0.94565341 0.05434659]
</code></pre>

<h3>scikit-learnã«ã‚ˆã‚‹PCA</h3>

<pre><code class="language-python">from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler

# ãƒ‡ãƒ¼ã‚¿ã®æ¨™æº–åŒ–ï¼ˆæ¨å¥¨ï¼‰
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# PCAã®é©ç”¨
pca_sklearn = PCA(n_components=2)
X_pca_sklearn = pca_sklearn.fit_transform(X_scaled)

print("\n=== PCAï¼ˆscikit-learnï¼‰ ===")
print(f"å¯„ä¸ç‡: {pca_sklearn.explained_variance_ratio_}")
print(f"ç´¯ç©å¯„ä¸ç‡: {np.cumsum(pca_sklearn.explained_variance_ratio_)}")

# å…¨ä¸»æˆåˆ†ã®å¯„ä¸ç‡
pca_full = PCA()
pca_full.fit(X_scaled)

plt.figure(figsize=(12, 5))

# å¯„ä¸ç‡
plt.subplot(1, 2, 1)
plt.bar(range(1, len(pca_full.explained_variance_ratio_) + 1),
        pca_full.explained_variance_ratio_, alpha=0.7, color='steelblue')
plt.xlabel('ä¸»æˆåˆ†ç•ªå·', fontsize=12)
plt.ylabel('å¯„ä¸ç‡', fontsize=12)
plt.title('å„ä¸»æˆåˆ†ã®å¯„ä¸ç‡', fontsize=14)
plt.grid(axis='y', alpha=0.3)

# ç´¯ç©å¯„ä¸ç‡
plt.subplot(1, 2, 2)
plt.plot(range(1, len(pca_full.explained_variance_ratio_) + 1),
         np.cumsum(pca_full.explained_variance_ratio_),
         'o-', linewidth=2, markersize=8, color='red')
plt.axhline(y=0.95, color='green', linestyle='--', label='95%ãƒ©ã‚¤ãƒ³')
plt.xlabel('ä¸»æˆåˆ†æ•°', fontsize=12)
plt.ylabel('ç´¯ç©å¯„ä¸ç‡', fontsize=12)
plt.title('ç´¯ç©å¯„ä¸ç‡', fontsize=14)
plt.legend()
plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>=== PCAï¼ˆscikit-learnï¼‰ ===
å¯„ä¸ç‡: [0.72962445 0.22850762]
ç´¯ç©å¯„ä¸ç‡: [0.72962445 0.95813207]
</code></pre>

<h3>PCAã«ã‚ˆã‚‹ç”»åƒåœ§ç¸®</h3>

<pre><code class="language-python">from sklearn.datasets import fetch_olivetti_faces

# é¡”ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
faces = fetch_olivetti_faces(shuffle=True, random_state=42)
X_faces = faces.data  # (400, 4096) - 64x64ãƒ”ã‚¯ã‚»ãƒ«

print(f"ç”»åƒãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: {X_faces.shape}")
print(f"å…ƒã®æ¬¡å…ƒ: {X_faces.shape[1]} (64x64ãƒ”ã‚¯ã‚»ãƒ«)")

# ç•°ãªã‚‹ä¸»æˆåˆ†æ•°ã§PCAã‚’é©ç”¨
n_components_list = [10, 50, 100, 200]

fig, axes = plt.subplots(2, 5, figsize=(16, 7))

# å…ƒã®ç”»åƒ
axes[0, 0].imshow(X_faces[0].reshape(64, 64), cmap='gray')
axes[0, 0].set_title('å…ƒç”»åƒ', fontsize=12)
axes[0, 0].axis('off')

axes[1, 0].imshow(X_faces[1].reshape(64, 64), cmap='gray')
axes[1, 0].set_title('å…ƒç”»åƒ', fontsize=12)
axes[1, 0].axis('off')

for idx, n_comp in enumerate(n_components_list, 1):
    pca = PCA(n_components=n_comp)
    X_compressed = pca.fit_transform(X_faces)
    X_reconstructed = pca.inverse_transform(X_compressed)

    cumulative_var = np.sum(pca.explained_variance_ratio_)

    axes[0, idx].imshow(X_reconstructed[0].reshape(64, 64), cmap='gray')
    axes[0, idx].set_title(f'{n_comp}æˆåˆ†\n({cumulative_var:.1%})', fontsize=10)
    axes[0, idx].axis('off')

    axes[1, idx].imshow(X_reconstructed[1].reshape(64, 64), cmap='gray')
    axes[1, idx].set_title(f'{n_comp}æˆåˆ†\n({cumulative_var:.1%})', fontsize=10)
    axes[1, idx].axis('off')

plt.tight_layout()
plt.show()

# åœ§ç¸®ç‡ã®è¨ˆç®—
original_size = X_faces.shape[1]
for n_comp in n_components_list:
    compressed_size = n_comp
    compression_ratio = (1 - compressed_size / original_size) * 100
    print(f"{n_comp}ä¸»æˆåˆ†: åœ§ç¸®ç‡ {compression_ratio:.1f}%")
</code></pre>

<hr>

<h2>2.3 t-SNEï¼ˆt-Distributed Stochastic Neighbor Embeddingï¼‰</h2>

<h3>æ¦‚è¦</h3>

<p><strong>t-SNE</strong>ã¯ã€é«˜æ¬¡å…ƒãƒ‡ãƒ¼ã‚¿ã®å±€æ‰€çš„ãªæ§‹é€ ã‚’ä¿æŒã—ãªãŒã‚‰ä½æ¬¡å…ƒï¼ˆé€šå¸¸2D/3Dï¼‰ã«å¯è¦–åŒ–ã™ã‚‹éç·šå½¢æ¬¡å…ƒå‰Šæ¸›æ‰‹æ³•ã§ã™ã€‚</p>

<h3>ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®ç›´æ„Ÿ</h3>

<ol>
<li><strong>é«˜æ¬¡å…ƒç©ºé–“</strong>: ãƒ‡ãƒ¼ã‚¿ç‚¹é–“ã®é¡ä¼¼åº¦ã‚’ç¢ºç‡åˆ†å¸ƒã§è¡¨ç¾ï¼ˆã‚¬ã‚¦ã‚¹åˆ†å¸ƒï¼‰</li>
<li><strong>ä½æ¬¡å…ƒç©ºé–“</strong>: ãƒ‡ãƒ¼ã‚¿ç‚¹é–“ã®é¡ä¼¼åº¦ã‚’tåˆ†å¸ƒã§è¡¨ç¾</li>
<li><strong>æœ€é©åŒ–</strong>: 2ã¤ã®åˆ†å¸ƒã®å·®ï¼ˆKLãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹ï¼‰ã‚’æœ€å°åŒ–</li>
</ol>

<h3>æ•°å¼</h3>

<p><strong>é«˜æ¬¡å…ƒã§ã®æ¡ä»¶ä»˜ãç¢ºç‡</strong>ï¼š</p>

<p>$$
p_{j|i} = \frac{\exp(-||\mathbf{x}_i - \mathbf{x}_j||^2 / 2\sigma_i^2)}{\sum_{k \neq i} \exp(-||\mathbf{x}_i - \mathbf{x}_k||^2 / 2\sigma_i^2)}
$$</p>

<p><strong>ä½æ¬¡å…ƒã§ã®ç¢ºç‡</strong>ï¼ˆtåˆ†å¸ƒã‚’ä½¿ç”¨ï¼‰ï¼š</p>

<p>$$
q_{ij} = \frac{(1 + ||\mathbf{y}_i - \mathbf{y}_j||^2)^{-1}}{\sum_{k \neq l}(1 + ||\mathbf{y}_k - \mathbf{y}_l||^2)^{-1}}
$$</p>

<p><strong>ç›®çš„é–¢æ•°</strong>ï¼ˆKLãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹ï¼‰ï¼š</p>

<p>$$
KL(P||Q) = \sum_{i \neq j} p_{ij} \log \frac{p_{ij}}{q_{ij}}
$$</p>

<h3>ä¸»è¦ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: Perplexity</h3>

<p><strong>Perplexity</strong>ã¯ã€å„ãƒ‡ãƒ¼ã‚¿ç‚¹ã®è¿‘å‚ç‚¹æ•°ã®ç›®å®‰ã‚’æ±ºã‚ã‚‹é‡è¦ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ã™ã€‚</p>

<ul>
<li>æ¨å¥¨ç¯„å›²: 5ã€œ50ï¼ˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚µã‚¤ã‚ºã«ä¾å­˜ï¼‰</li>
<li>å°ã•ã„å€¤: å±€æ‰€æ§‹é€ ã‚’å¼·èª¿</li>
<li>å¤§ãã„å€¤: å¤§åŸŸæ§‹é€ ã‚’ä¿æŒ</li>
</ul>

<h3>å®Ÿè£…ä¾‹: MNISTãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ</h3>

<pre><code class="language-python">from sklearn.manifold import TSNE
from sklearn.datasets import load_digits
import matplotlib.pyplot as plt

# æ‰‹æ›¸ãæ•°å­—ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆMNISTã®å°è¦æ¨¡ç‰ˆï¼‰
digits = load_digits()
X_digits = digits.data
y_digits = digits.target

print(f"ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: {X_digits.shape}")
print(f"ã‚¯ãƒ©ã‚¹æ•°: {len(np.unique(y_digits))}")

# t-SNEã®é©ç”¨
tsne = TSNE(n_components=2, perplexity=30, random_state=42, n_iter=1000)
X_tsne = tsne.fit_transform(X_digits)

# å¯è¦–åŒ–
plt.figure(figsize=(12, 10))
scatter = plt.scatter(X_tsne[:, 0], X_tsne[:, 1],
                     c=y_digits, cmap='tab10',
                     alpha=0.7, s=30, edgecolors='k', linewidth=0.5)
plt.colorbar(scatter, label='æ•°å­—')
plt.xlabel('t-SNE ç¬¬1æˆåˆ†', fontsize=12)
plt.ylabel('t-SNE ç¬¬2æˆåˆ†', fontsize=12)
plt.title('t-SNE: æ‰‹æ›¸ãæ•°å­—ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ', fontsize=14)
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()
</code></pre>

<h3>Perplexityã®å½±éŸ¿</h3>

<pre><code class="language-python"># ç•°ãªã‚‹Perplexityã§ã®æ¯”è¼ƒ
perplexities = [5, 30, 50, 100]

fig, axes = plt.subplots(2, 2, figsize=(14, 12))
axes = axes.ravel()

for idx, perp in enumerate(perplexities):
    tsne = TSNE(n_components=2, perplexity=perp, random_state=42, n_iter=1000)
    X_tsne_temp = tsne.fit_transform(X_digits)

    scatter = axes[idx].scatter(X_tsne_temp[:, 0], X_tsne_temp[:, 1],
                               c=y_digits, cmap='tab10', alpha=0.7, s=20)
    axes[idx].set_title(f'Perplexity = {perp}', fontsize=14)
    axes[idx].set_xlabel('ç¬¬1æˆåˆ†')
    axes[idx].set_ylabel('ç¬¬2æˆåˆ†')
    axes[idx].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
</code></pre>

<h3>t-SNEã®åˆ¶ç´„ã¨æ³¨æ„ç‚¹</h3>

<table>
<thead>
<tr>
<th>åˆ¶ç´„</th>
<th>èª¬æ˜</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>è¨ˆç®—ã‚³ã‚¹ãƒˆ</strong></td>
<td>$O(n^2)$ ã®è¨ˆç®—é‡ã€‚å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã«ã¯ä¸å‘ã</td>
</tr>
<tr>
<td><strong>éæ±ºå®šè«–çš„</strong></td>
<td>ãƒ©ãƒ³ãƒ€ãƒ åˆæœŸåŒ–ã«ã‚ˆã‚Šå®Ÿè¡Œã”ã¨ã«çµæœãŒç•°ãªã‚‹</td>
</tr>
<tr>
<td><strong>å¤§åŸŸæ§‹é€ </strong></td>
<td>ã‚¯ãƒ©ã‚¹ã‚¿é–“ã®è·é›¢ã¯æ„å‘³ã‚’æŒãŸãªã„</td>
</tr>
<tr>
<td><strong>æ–°ãƒ‡ãƒ¼ã‚¿å¯¾å¿œä¸å¯</strong></td>
<td>å­¦ç¿’å¾Œã«æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚’å°„å½±ã§ããªã„</td>
</tr>
</tbody>
</table>

<blockquote>
<p><strong>é‡è¦</strong>: t-SNEã¯å¯è¦–åŒ–å°‚ç”¨ã€‚æ¬¡å…ƒå‰Šæ¸›ã—ãŸãƒ‡ãƒ¼ã‚¿ã§æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã™ã‚‹ã«ã¯PCAã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã€‚</p>
</blockquote>

<hr>

<h2>2.4 UMAPï¼ˆUniform Manifold Approximation and Projectionï¼‰</h2>

<h3>æ¦‚è¦</h3>

<p><strong>UMAP</strong>ã¯ã€t-SNEã®æ¬ ç‚¹ã‚’æ”¹å–„ã—ãŸé«˜é€Ÿãªéç·šå½¢æ¬¡å…ƒå‰Šæ¸›æ‰‹æ³•ã§ã™ã€‚å¤šæ§˜ä½“å­¦ç¿’ã®ç†è«–ã«åŸºã¥ã„ã¦ã„ã¾ã™ã€‚</p>

<h3>UMAPã®åˆ©ç‚¹</h3>

<table>
<thead>
<tr>
<th>ç‰¹å¾´</th>
<th>UMAP</th>
<th>t-SNE</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>è¨ˆç®—é€Ÿåº¦</strong></td>
<td>é«˜é€Ÿï¼ˆæ•°åˆ†ï¼‰</td>
<td>é…ã„ï¼ˆæ•°ååˆ†ã€œæ•°æ™‚é–“ï¼‰</td>
</tr>
<tr>
<td><strong>å¤§åŸŸæ§‹é€ </strong></td>
<td>ä¿æŒ</td>
<td>ä¿æŒã•ã‚Œãªã„</td>
</tr>
<tr>
<td><strong>æ–°ãƒ‡ãƒ¼ã‚¿å¯¾å¿œ</strong></td>
<td>å¯èƒ½ï¼ˆtransformï¼‰</td>
<td>ä¸å¯èƒ½</td>
</tr>
<tr>
<td><strong>ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£</strong></td>
<td>100ä¸‡ç‚¹ä»¥ä¸Š</td>
<td>æ•°åƒã€œæ•°ä¸‡ç‚¹</td>
</tr>
</tbody>
</table>

<h3>ä¸»è¦ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿</h3>

<ol>
<li><strong>n_neighbors</strong>: å±€æ‰€è¿‘å‚ã®ã‚µã‚¤ã‚ºï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 15ï¼‰
<ul>
<li>å°ã•ã„å€¤: å±€æ‰€æ§‹é€ ã‚’å¼·èª¿</li>
<li>å¤§ãã„å€¤: å¤§åŸŸæ§‹é€ ã‚’ä¿æŒ</li>
</ul></li>
<li><strong>min_dist</strong>: ä½æ¬¡å…ƒç©ºé–“ã§ã®ç‚¹é–“ã®æœ€å°è·é›¢ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 0.1ï¼‰
<ul>
<li>å°ã•ã„å€¤: å¯†ãªã‚¯ãƒ©ã‚¹ã‚¿</li>
<li>å¤§ãã„å€¤: ç–ãªã‚¯ãƒ©ã‚¹ã‚¿</li>
</ul></li>
</ol>

<h3>å®Ÿè£…ä¾‹</h3>

<pre><code class="language-python">import umap
import matplotlib.pyplot as plt

# UMAPã®é©ç”¨
umap_model = umap.UMAP(n_neighbors=15, min_dist=0.1, random_state=42)
X_umap = umap_model.fit_transform(X_digits)

# å¯è¦–åŒ–
plt.figure(figsize=(12, 10))
scatter = plt.scatter(X_umap[:, 0], X_umap[:, 1],
                     c=y_digits, cmap='tab10',
                     alpha=0.7, s=30, edgecolors='k', linewidth=0.5)
plt.colorbar(scatter, label='æ•°å­—')
plt.xlabel('UMAP ç¬¬1æˆåˆ†', fontsize=12)
plt.ylabel('UMAP ç¬¬2æˆåˆ†', fontsize=12)
plt.title('UMAP: æ‰‹æ›¸ãæ•°å­—ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ', fontsize=14)
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()
</code></pre>

<h3>ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å½±éŸ¿</h3>

<pre><code class="language-python"># ç•°ãªã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ã®æ¯”è¼ƒ
fig, axes = plt.subplots(2, 3, figsize=(16, 11))

params = [
    {'n_neighbors': 5, 'min_dist': 0.1},
    {'n_neighbors': 15, 'min_dist': 0.1},
    {'n_neighbors': 50, 'min_dist': 0.1},
    {'n_neighbors': 15, 'min_dist': 0.01},
    {'n_neighbors': 15, 'min_dist': 0.5},
    {'n_neighbors': 15, 'min_dist': 0.99},
]

for idx, (ax, param) in enumerate(zip(axes.ravel(), params)):
    umap_temp = umap.UMAP(**param, random_state=42)
    X_umap_temp = umap_temp.fit_transform(X_digits)

    scatter = ax.scatter(X_umap_temp[:, 0], X_umap_temp[:, 1],
                        c=y_digits, cmap='tab10', alpha=0.7, s=15)
    ax.set_title(f"n_neighbors={param['n_neighbors']}, min_dist={param['min_dist']}",
                fontsize=11)
    ax.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
</code></pre>

<h3>æ–°ãƒ‡ãƒ¼ã‚¿ã¸ã®é©ç”¨</h3>

<pre><code class="language-python"># å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨æ–°ãƒ‡ãƒ¼ã‚¿
X_train = X_digits[:1500]
X_test = X_digits[1500:]
y_train = y_digits[:1500]
y_test = y_digits[1500:]

# UMAPã®å­¦ç¿’
umap_model = umap.UMAP(n_neighbors=15, min_dist=0.1, random_state=42)
umap_model.fit(X_train)

# å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®å¤‰æ›
X_train_umap = umap_model.transform(X_train)
X_test_umap = umap_model.transform(X_test)

# å¯è¦–åŒ–
plt.figure(figsize=(12, 10))
plt.scatter(X_train_umap[:, 0], X_train_umap[:, 1],
           c=y_train, cmap='tab10', alpha=0.5, s=20, label='è¨“ç·´ãƒ‡ãƒ¼ã‚¿')
plt.scatter(X_test_umap[:, 0], X_test_umap[:, 1],
           c=y_test, cmap='tab10', alpha=0.9, s=50,
           marker='s', edgecolors='black', linewidth=1.5, label='æ–°ãƒ‡ãƒ¼ã‚¿')
plt.xlabel('UMAP ç¬¬1æˆåˆ†', fontsize=12)
plt.ylabel('UMAP ç¬¬2æˆåˆ†', fontsize=12)
plt.title('UMAP: æ–°ãƒ‡ãƒ¼ã‚¿ã¸ã®é©ç”¨', fontsize=14)
plt.legend(fontsize=12)
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()

print("=== UMAP ===")
print(f"è¨“ç·´ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: {X_train_umap.shape}")
print(f"ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: {X_test_umap.shape}")
</code></pre>

<h3>3Då¯è¦–åŒ–</h3>

<pre><code class="language-python">from mpl_toolkits.mplot3d import Axes3D

# 3æ¬¡å…ƒUMAPã®é©ç”¨
umap_3d = umap.UMAP(n_components=3, n_neighbors=15, min_dist=0.1, random_state=42)
X_umap_3d = umap_3d.fit_transform(X_digits)

# 3Då¯è¦–åŒ–
fig = plt.figure(figsize=(14, 10))
ax = fig.add_subplot(111, projection='3d')

scatter = ax.scatter(X_umap_3d[:, 0], X_umap_3d[:, 1], X_umap_3d[:, 2],
                    c=y_digits, cmap='tab10', alpha=0.6, s=30)

ax.set_xlabel('UMAP 1', fontsize=12)
ax.set_ylabel('UMAP 2', fontsize=12)
ax.set_zlabel('UMAP 3', fontsize=12)
ax.set_title('UMAP: 3æ¬¡å…ƒå¯è¦–åŒ–', fontsize=14)

plt.colorbar(scatter, label='æ•°å­—', shrink=0.7)
plt.tight_layout()
plt.show()
</code></pre>

<hr>

<h2>2.5 æ‰‹æ³•ã®æ¯”è¼ƒã¨ä½¿ã„åˆ†ã‘</h2>

<h3>PCA vs t-SNE vs UMAP</h3>

<pre><code class="language-python">from sklearn.datasets import load_digits
import time

# ãƒ‡ãƒ¼ã‚¿æº–å‚™
digits = load_digits()
X = digits.data
y = digits.target

# å„æ‰‹æ³•ã®å®Ÿè¡Œã¨è¨ˆæ¸¬
fig, axes = plt.subplots(1, 3, figsize=(18, 5))

# PCA
start_time = time.time()
pca = PCA(n_components=2, random_state=42)
X_pca = pca.fit_transform(X)
pca_time = time.time() - start_time

axes[0].scatter(X_pca[:, 0], X_pca[:, 1], c=y, cmap='tab10', alpha=0.7, s=30)
axes[0].set_title(f'PCA\nå®Ÿè¡Œæ™‚é–“: {pca_time:.3f}ç§’', fontsize=14)
axes[0].set_xlabel('PC1')
axes[0].set_ylabel('PC2')
axes[0].grid(True, alpha=0.3)

# t-SNE
start_time = time.time()
tsne = TSNE(n_components=2, perplexity=30, random_state=42, n_iter=1000)
X_tsne = tsne.fit_transform(X)
tsne_time = time.time() - start_time

axes[1].scatter(X_tsne[:, 0], X_tsne[:, 1], c=y, cmap='tab10', alpha=0.7, s=30)
axes[1].set_title(f't-SNE\nå®Ÿè¡Œæ™‚é–“: {tsne_time:.3f}ç§’', fontsize=14)
axes[1].set_xlabel('t-SNE 1')
axes[1].set_ylabel('t-SNE 2')
axes[1].grid(True, alpha=0.3)

# UMAP
start_time = time.time()
umap_model = umap.UMAP(n_components=2, n_neighbors=15, min_dist=0.1, random_state=42)
X_umap = umap_model.fit_transform(X)
umap_time = time.time() - start_time

scatter = axes[2].scatter(X_umap[:, 0], X_umap[:, 1], c=y, cmap='tab10', alpha=0.7, s=30)
axes[2].set_title(f'UMAP\nå®Ÿè¡Œæ™‚é–“: {umap_time:.3f}ç§’', fontsize=14)
axes[2].set_xlabel('UMAP 1')
axes[2].set_ylabel('UMAP 2')
axes[2].grid(True, alpha=0.3)

plt.colorbar(scatter, ax=axes, label='æ•°å­—', fraction=0.02, pad=0.04)
plt.tight_layout()
plt.show()

# æ¯”è¼ƒè¡¨
print("\n=== å®Ÿè¡Œæ™‚é–“ã®æ¯”è¼ƒ ===")
print(f"PCA:   {pca_time:.3f}ç§’ (1.0x)")
print(f"t-SNE: {tsne_time:.3f}ç§’ ({tsne_time/pca_time:.1f}x)")
print(f"UMAP:  {umap_time:.3f}ç§’ ({umap_time/pca_time:.1f}x)")
</code></pre>

<h3>ä½¿ã„åˆ†ã‘ã®ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³</h3>

<table>
<thead>
<tr>
<th>ç›®çš„</th>
<th>æ¨å¥¨æ‰‹æ³•</th>
<th>ç†ç”±</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>æ©Ÿæ¢°å­¦ç¿’ã®å‰å‡¦ç†</strong></td>
<td>PCA</td>
<td>ç·šå½¢ã€é«˜é€Ÿã€é€†å¤‰æ›å¯èƒ½</td>
</tr>
<tr>
<td><strong>ãƒ‡ãƒ¼ã‚¿ã®å¯è¦–åŒ–</strong></td>
<td>t-SNE or UMAP</td>
<td>éç·šå½¢ã€å±€æ‰€æ§‹é€ ã®ä¿æŒ</td>
</tr>
<tr>
<td><strong>å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿</strong></td>
<td>UMAP</td>
<td>é«˜é€Ÿã€ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«</td>
</tr>
<tr>
<td><strong>ã‚¯ãƒ©ã‚¹ã‚¿åˆ†æ</strong></td>
<td>UMAP</td>
<td>å¤§åŸŸæ§‹é€ ã®ä¿æŒ</td>
</tr>
<tr>
<td><strong>ãƒã‚¤ã‚ºé™¤å»</strong></td>
<td>PCA</td>
<td>åˆ†æ•£ã®å°ã•ã„æ¬¡å…ƒã‚’å‰Šé™¤</td>
</tr>
<tr>
<td><strong>æ–°ãƒ‡ãƒ¼ã‚¿ã¸ã®é©ç”¨</strong></td>
<td>PCA or UMAP</td>
<td>transformãƒ¡ã‚½ãƒƒãƒ‰å¯¾å¿œ</td>
</tr>
</tbody>
</table>

<div class="mermaid">
graph TD
    A[æ¬¡å…ƒå‰Šæ¸›ã®é¸æŠ] --> B{ç›®çš„ã¯?}
    B -->|æ©Ÿæ¢°å­¦ç¿’ã®å‰å‡¦ç†| C[PCA]
    B -->|å¯è¦–åŒ–| D{ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã¯?}
    B -->|ãƒã‚¤ã‚ºé™¤å»| C

    D -->|å°ã€œä¸­è¦æ¨¡| E{å±€æ‰€ or å¤§åŸŸ?}
    D -->|å¤§è¦æ¨¡| F[UMAP]

    E -->|å±€æ‰€æ§‹é€ é‡è¦–| G[t-SNE]
    E -->|å¤§åŸŸæ§‹é€ é‡è¦–| F

    style A fill:#e3f2fd
    style C fill:#c8e6c9
    style F fill:#fff9c4
    style G fill:#ffccbc
</div>

<hr>

<h2>2.6 å®Ÿè·µ: æ¬¡å…ƒå‰Šæ¸›å¾Œã®æ©Ÿæ¢°å­¦ç¿’</h2>

<h3>PCAã«ã‚ˆã‚‹ç‰¹å¾´é‡å‰Šæ¸›ã¨ãƒ¢ãƒ‡ãƒ«å­¦ç¿’</h3>

<pre><code class="language-python">from sklearn.datasets import load_digits
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score
import time

# ãƒ‡ãƒ¼ã‚¿æº–å‚™
digits = load_digits()
X = digits.data
y = digits.target

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

print(f"å…ƒã®ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: {X_train.shape}")

# 1. å…ƒã®ãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’
start_time = time.time()
rf_original = RandomForestClassifier(n_estimators=100, random_state=42)
rf_original.fit(X_train, y_train)
original_time = time.time() - start_time

y_pred_original = rf_original.predict(X_test)
original_acc = accuracy_score(y_test, y_pred_original)

print("\n=== å…ƒã®ãƒ‡ãƒ¼ã‚¿ï¼ˆ64æ¬¡å…ƒï¼‰ ===")
print(f"è¨“ç·´æ™‚é–“: {original_time:.3f}ç§’")
print(f"ç²¾åº¦: {original_acc:.4f}")

# 2. PCAã§æ¬¡å…ƒå‰Šæ¸›å¾Œã«å­¦ç¿’
n_components_list = [10, 20, 30, 40]
results = []

for n_comp in n_components_list:
    # PCAé©ç”¨
    pca = PCA(n_components=n_comp, random_state=42)
    X_train_pca = pca.fit_transform(X_train)
    X_test_pca = pca.transform(X_test)

    # ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
    start_time = time.time()
    rf_pca = RandomForestClassifier(n_estimators=100, random_state=42)
    rf_pca.fit(X_train_pca, y_train)
    pca_time = time.time() - start_time

    # è©•ä¾¡
    y_pred_pca = rf_pca.predict(X_test_pca)
    pca_acc = accuracy_score(y_test, y_pred_pca)

    cumulative_var = np.sum(pca.explained_variance_ratio_)

    results.append({
        'n_components': n_comp,
        'accuracy': pca_acc,
        'time': pca_time,
        'variance': cumulative_var
    })

    print(f"\n=== PCAï¼ˆ{n_comp}æ¬¡å…ƒï¼‰ ===")
    print(f"ç´¯ç©å¯„ä¸ç‡: {cumulative_var:.4f}")
    print(f"è¨“ç·´æ™‚é–“: {pca_time:.3f}ç§’ ({pca_time/original_time:.2f}x)")
    print(f"ç²¾åº¦: {pca_acc:.4f} ({(pca_acc - original_acc):.4f})")

# çµæœã®å¯è¦–åŒ–
fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# ç²¾åº¦ã®æ¯”è¼ƒ
axes[0].axhline(y=original_acc, color='red', linestyle='--',
                linewidth=2, label=f'å…ƒãƒ‡ãƒ¼ã‚¿ ({original_acc:.4f})')
axes[0].plot([r['n_components'] for r in results],
            [r['accuracy'] for r in results],
            'o-', linewidth=2, markersize=10, label='PCAå¾Œ')
axes[0].set_xlabel('ä¸»æˆåˆ†æ•°', fontsize=12)
axes[0].set_ylabel('ç²¾åº¦', fontsize=12)
axes[0].set_title('ä¸»æˆåˆ†æ•°ã¨ç²¾åº¦ã®é–¢ä¿‚', fontsize=14)
axes[0].legend(fontsize=12)
axes[0].grid(True, alpha=0.3)

# è¨“ç·´æ™‚é–“ã®æ¯”è¼ƒ
axes[1].axhline(y=original_time, color='red', linestyle='--',
                linewidth=2, label=f'å…ƒãƒ‡ãƒ¼ã‚¿ ({original_time:.3f}ç§’)')
axes[1].plot([r['n_components'] for r in results],
            [r['time'] for r in results],
            's-', linewidth=2, markersize=10, color='green', label='PCAå¾Œ')
axes[1].set_xlabel('ä¸»æˆåˆ†æ•°', fontsize=12)
axes[1].set_ylabel('è¨“ç·´æ™‚é–“ï¼ˆç§’ï¼‰', fontsize=12)
axes[1].set_title('ä¸»æˆåˆ†æ•°ã¨è¨“ç·´æ™‚é–“ã®é–¢ä¿‚', fontsize=14)
axes[1].legend(fontsize=12)
axes[1].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
</code></pre>

<hr>

<h2>2.7 æœ¬ç« ã®ã¾ã¨ã‚</h2>

<h3>å­¦ã‚“ã ã“ã¨</h3>

<ol>
<li><p><strong>æ¬¡å…ƒå‰Šæ¸›ã®å¿…è¦æ€§</strong></p>
<ul>
<li>æ¬¡å…ƒã®å‘ªã„: é«˜æ¬¡å…ƒãƒ‡ãƒ¼ã‚¿ã®å•é¡Œç‚¹</li>
<li>å¯è¦–åŒ–ã€è¨ˆç®—åŠ¹ç‡åŒ–ã€ãƒã‚¤ã‚ºé™¤å»ã€éå­¦ç¿’é˜²æ­¢</li>
</ul></li>
<li><p><strong>PCAï¼ˆä¸»æˆåˆ†åˆ†æï¼‰</strong></p>
<ul>
<li>ç·šå½¢æ¬¡å…ƒå‰Šæ¸›æ‰‹æ³•</li>
<li>åˆ†æ•£ã‚’æœ€å¤§åŒ–ã™ã‚‹æ–¹å‘ã«å°„å½±</li>
<li>å›ºæœ‰å€¤ãƒ»å›ºæœ‰ãƒ™ã‚¯ãƒˆãƒ«ã«ã‚ˆã‚‹å®Ÿè£…</li>
<li>å¯„ä¸ç‡ã«ã‚ˆã‚‹æ¬¡å…ƒæ•°ã®é¸æŠ</li>
</ul></li>
<li><p><strong>t-SNE</strong></p>
<ul>
<li>éç·šå½¢æ¬¡å…ƒå‰Šæ¸›æ‰‹æ³•</li>
<li>å±€æ‰€æ§‹é€ ã®ä¿æŒã«å„ªã‚Œã‚‹</li>
<li>Perplexityãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®é‡è¦æ€§</li>
<li>å¯è¦–åŒ–å°‚ç”¨ï¼ˆæ©Ÿæ¢°å­¦ç¿’ã®å‰å‡¦ç†ã«ã¯ä¸å‘ãï¼‰</li>
</ul></li>
<li><p><strong>UMAP</strong></p>
<ul>
<li>t-SNEã‚ˆã‚Šé«˜é€Ÿ</li>
<li>å¤§åŸŸæ§‹é€ ã¨å±€æ‰€æ§‹é€ ã®ä¸¡æ–¹ã‚’ä¿æŒ</li>
<li>æ–°ãƒ‡ãƒ¼ã‚¿ã¸ã®é©ç”¨ãŒå¯èƒ½</li>
<li>å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã«å¯¾å¿œ</li>
</ul></li>
<li><p><strong>æ‰‹æ³•ã®ä½¿ã„åˆ†ã‘</strong></p>
<ul>
<li>æ©Ÿæ¢°å­¦ç¿’ã®å‰å‡¦ç†: PCA</li>
<li>å¯è¦–åŒ–: t-SNE or UMAP</li>
<li>å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿: UMAP</li>
</ul></li>
</ol>

<h3>æ¬¡ã®ç« ã¸</h3>

<p>ç¬¬3ç« ã§ã¯ã€<strong>ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°æ‰‹æ³•</strong>ã‚’å­¦ã³ã¾ã™ï¼š</p>
<ul>
<li>k-meansã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°</li>
<li>éšå±¤çš„ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°</li>
<li>DBSCANã¨ãã®ä»–ã®å¯†åº¦ãƒ™ãƒ¼ã‚¹æ‰‹æ³•</li>
<li>ã‚¯ãƒ©ã‚¹ã‚¿è©•ä¾¡æŒ‡æ¨™</li>
</ul>

<hr>

<h2>æ¼”ç¿’å•é¡Œ</h2>

<h3>å•é¡Œ1ï¼ˆé›£æ˜“åº¦ï¼šeasyï¼‰</h3>
<p>æ¬¡å…ƒå‰Šæ¸›ãŒå¿…è¦ãªç†ç”±ã‚’ã€ã€Œæ¬¡å…ƒã®å‘ªã„ã€ã®è¦³ç‚¹ã‹ã‚‰3ã¤èª¬æ˜ã—ã¦ãã ã•ã„ã€‚</p>

<details>
<summary>è§£ç­”ä¾‹</summary>

<p><strong>è§£ç­”</strong>ï¼š</p>

<ol>
<li><p><strong>ãƒ‡ãƒ¼ã‚¿ã®ç–æ€§</strong></p>
<ul>
<li>æ¬¡å…ƒãŒå¢—ãˆã‚‹ã¨ã€ãƒ‡ãƒ¼ã‚¿ç‚¹é–“ã®è·é›¢ãŒå¤§ãããªã‚‹</li>
<li>ãƒ‡ãƒ¼ã‚¿ãŒç©ºé–“ã«æ•£ã‚‰ã°ã‚Šã€å¯†åº¦ãŒä½ä¸‹</li>
<li>k-NNãªã©ã®è·é›¢ãƒ™ãƒ¼ã‚¹æ‰‹æ³•ãŒæ©Ÿèƒ½ã—ã«ãããªã‚‹</li>
</ul></li>
<li><p><strong>è¨ˆç®—é‡ã®å¢—åŠ </strong></p>
<ul>
<li>æ¬¡å…ƒ $d$ ã«å¯¾ã—ã¦è¨ˆç®—é‡ãŒ $O(d^2)$ ã‚„ $O(d^3)$ ã§å¢—åŠ </li>
<li>ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚‚å¢—å¤§</li>
<li>å­¦ç¿’æ™‚é–“ãŒç¾å®Ÿçš„ã§ãªããªã‚‹</li>
</ul></li>
<li><p><strong>éå­¦ç¿’ã®ãƒªã‚¹ã‚¯</strong></p>
<ul>
<li>ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ï¼ˆç‰¹å¾´é‡æ•°ï¼‰ã«å¯¾ã—ã¦ã‚µãƒ³ãƒ—ãƒ«æ•°ãŒä¸è¶³</li>
<li>è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã«éåº¦ã«é©åˆã—ã€æ±åŒ–æ€§èƒ½ãŒä½ä¸‹</li>
<li>å¿…è¦ãªã‚µãƒ³ãƒ—ãƒ«æ•°ãŒæ¬¡å…ƒã«å¯¾ã—ã¦æŒ‡æ•°çš„ã«å¢—åŠ </li>
</ul></li>
</ol>

</details>

<h3>å•é¡Œ2ï¼ˆé›£æ˜“åº¦ï¼šmediumï¼‰</h3>
<p>PCAã®ç¬¬1ä¸»æˆåˆ†ã¨ç¬¬2ä¸»æˆåˆ†ã¯ç›´äº¤ï¼ˆå†…ç©ãŒ0ï¼‰ã™ã‚‹ã“ã¨ã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚</p>

<details>
<summary>è§£ç­”ä¾‹</summary>

<p><strong>è§£ç­”</strong>ï¼š</p>

<p>PCAã¯å…±åˆ†æ•£è¡Œåˆ— $\mathbf{C}$ ã®å›ºæœ‰å€¤åˆ†è§£ã«ã‚ˆã‚Šä¸»æˆåˆ†ã‚’æ±‚ã‚ã¾ã™ï¼š</p>

<p>$$
\mathbf{C} = \mathbf{V} \mathbf{\Lambda} \mathbf{V}^T
$$</p>

<p>ã“ã“ã§ $\mathbf{V}$ ã¯å›ºæœ‰ãƒ™ã‚¯ãƒˆãƒ«è¡Œåˆ—ã€$\mathbf{\Lambda}$ ã¯å›ºæœ‰å€¤ã®å¯¾è§’è¡Œåˆ—ã§ã™ã€‚</p>

<p><strong>å›ºæœ‰ãƒ™ã‚¯ãƒˆãƒ«ã®ç›´äº¤æ€§</strong>ï¼š</p>
<ul>
<li>å®Ÿå¯¾ç§°è¡Œåˆ—ï¼ˆå…±åˆ†æ•£è¡Œåˆ—ï¼‰ã®ç•°ãªã‚‹å›ºæœ‰å€¤ã«å¯¾å¿œã™ã‚‹å›ºæœ‰ãƒ™ã‚¯ãƒˆãƒ«ã¯ç›´äº¤ã™ã‚‹</li>
<li>æ•°å­¦çš„ã«: $\mathbf{v}_i^T \mathbf{v}_j = 0$ ï¼ˆ$i \neq j$ï¼‰</li>
</ul>

<p><strong>æ„å‘³</strong>ï¼š</p>
<ul>
<li>å„ä¸»æˆåˆ†ã¯äº’ã„ã«ç‹¬ç«‹ãªæ–¹å‘ã‚’è¡¨ã™</li>
<li>æƒ…å ±ã®å†—é•·æ€§ãŒãªã„</li>
<li>ç›´äº¤åŸºåº•ã«ã‚ˆã‚Šã€å…ƒã®ãƒ‡ãƒ¼ã‚¿ã‚’ä¸€æ„ã«è¡¨ç¾å¯èƒ½</li>
</ul>

<p><strong>æ¤œè¨¼ã‚³ãƒ¼ãƒ‰</strong>ï¼š</p>
<pre><code class="language-python">pca = PCA(n_components=2)
pca.fit(X)

# ä¸»æˆåˆ†ãƒ™ã‚¯ãƒˆãƒ«
pc1 = pca.components_[0]
pc2 = pca.components_[1]

# å†…ç©ã‚’è¨ˆç®—
dot_product = np.dot(pc1, pc2)
print(f"å†…ç©: {dot_product:.10f}")  # â‰ˆ 0
</code></pre>

</details>

<h3>å•é¡Œ3ï¼ˆé›£æ˜“åº¦ï¼šmediumï¼‰</h3>
<p>t-SNEã§å¯è¦–åŒ–ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ã£ã¦æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã™ã‚‹ã®ãŒä¸é©åˆ‡ãªç†ç”±ã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚</p>

<details>
<summary>è§£ç­”ä¾‹</summary>

<p><strong>ä¸é©åˆ‡ãªç†ç”±</strong>ï¼š</p>

<ol>
<li><p><strong>å¤§åŸŸæ§‹é€ ãŒä¿å­˜ã•ã‚Œãªã„</strong></p>
<ul>
<li>t-SNEã¯å±€æ‰€çš„ãªé¡ä¼¼æ€§ã®ã¿ã‚’ä¿æŒ</li>
<li>ã‚¯ãƒ©ã‚¹ã‚¿é–“ã®è·é›¢ã¯æ„å‘³ã‚’æŒãŸãªã„</li>
<li>å…¨ä½“çš„ãªãƒ‡ãƒ¼ã‚¿æ§‹é€ ãŒæ­ªã‚€</li>
</ul></li>
<li><p><strong>éæ±ºå®šè«–çš„</strong></p>
<ul>
<li>ãƒ©ãƒ³ãƒ€ãƒ åˆæœŸåŒ–ã«ã‚ˆã‚Šå®Ÿè¡Œã”ã¨ã«çµæœãŒç•°ãªã‚‹</li>
<li>å†ç¾æ€§ãŒãªã„</li>
<li>ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½è©•ä¾¡ãŒä¸å®‰å®š</li>
</ul></li>
<li><p><strong>æ–°ãƒ‡ãƒ¼ã‚¿ã¸ã®é©ç”¨ä¸å¯</strong></p>
<ul>
<li>transformãƒ¡ã‚½ãƒƒãƒ‰ãŒãªã„</li>
<li>ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚„æ–°è¦ãƒ‡ãƒ¼ã‚¿ã‚’åŒã˜ç©ºé–“ã«å°„å½±ã§ããªã„</li>
<li>å®Ÿé‹ç”¨ã§ä½¿ãˆãªã„</li>
</ul></li>
<li><p><strong>è¨ˆç®—ã‚³ã‚¹ãƒˆ</strong></p>
<ul>
<li>$O(n^2)$ ã®è¨ˆç®—é‡</li>
<li>å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã§ã¯ç¾å®Ÿçš„ã§ãªã„</li>
</ul></li>
</ol>

<p><strong>é©åˆ‡ãªæ‰‹æ³•</strong>ï¼š</p>
<ul>
<li><strong>PCA</strong>: ç·šå½¢ã€é«˜é€Ÿã€é€†å¤‰æ›å¯èƒ½ã€transformãƒ¡ã‚½ãƒƒãƒ‰ã‚ã‚Š</li>
<li><strong>UMAP</strong>: éç·šå½¢ã ãŒæ–°ãƒ‡ãƒ¼ã‚¿ã¸ã®é©ç”¨ãŒå¯èƒ½ï¼ˆãŸã ã—å¯è¦–åŒ–ãŒä¸»ç›®çš„ï¼‰</li>
</ul>

</details>

<h3>å•é¡Œ4ï¼ˆé›£æ˜“åº¦ï¼šhardï¼‰</h3>
<p>PCAã®ç´¯ç©å¯„ä¸ç‡ãŒ95%ã«ãªã‚‹ä¸»æˆåˆ†æ•°ã‚’æ±‚ã‚ã€ãã®æ¬¡å…ƒæ•°ã§ãƒ‡ãƒ¼ã‚¿ã‚’å¤‰æ›ã™ã‚‹ã‚³ãƒ¼ãƒ‰ã‚’æ›¸ã„ã¦ãã ã•ã„ã€‚Irisãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚</p>

<details>
<summary>è§£ç­”ä¾‹</summary>

<pre><code class="language-python">from sklearn.datasets import load_iris
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
import numpy as np
import matplotlib.pyplot as plt

# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
iris = load_iris()
X = iris.data
y = iris.target

# æ¨™æº–åŒ–
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# å…¨ä¸»æˆåˆ†ã§PCAã‚’å®Ÿè¡Œ
pca_full = PCA()
pca_full.fit(X_scaled)

# å¯„ä¸ç‡
explained_variance_ratio = pca_full.explained_variance_ratio_
cumulative_variance_ratio = np.cumsum(explained_variance_ratio)

print("=== å„ä¸»æˆåˆ†ã®å¯„ä¸ç‡ ===")
for i, (var, cum_var) in enumerate(zip(explained_variance_ratio,
                                        cumulative_variance_ratio)):
    print(f"PC{i+1}: å¯„ä¸ç‡ {var:.4f}, ç´¯ç©å¯„ä¸ç‡ {cum_var:.4f}")

# ç´¯ç©å¯„ä¸ç‡95%ä»¥ä¸Šã¨ãªã‚‹ä¸»æˆåˆ†æ•°
n_components_95 = np.argmax(cumulative_variance_ratio >= 0.95) + 1
print(f"\nç´¯ç©å¯„ä¸ç‡95%ã«å¿…è¦ãªä¸»æˆåˆ†æ•°: {n_components_95}")

# ãã®ä¸»æˆåˆ†æ•°ã§PCAã‚’å†å®Ÿè¡Œ
pca = PCA(n_components=n_components_95)
X_pca = pca.fit_transform(X_scaled)

print(f"\nå…ƒã®æ¬¡å…ƒ: {X.shape[1]}")
print(f"å‰Šæ¸›å¾Œã®æ¬¡å…ƒ: {X_pca.shape[1]}")
print(f"å®Ÿéš›ã®ç´¯ç©å¯„ä¸ç‡: {np.sum(pca.explained_variance_ratio_):.4f}")

# å¯è¦–åŒ–
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.bar(range(1, len(explained_variance_ratio) + 1),
        explained_variance_ratio, alpha=0.7, color='steelblue')
plt.xlabel('ä¸»æˆåˆ†ç•ªå·')
plt.ylabel('å¯„ä¸ç‡')
plt.title('å„ä¸»æˆåˆ†ã®å¯„ä¸ç‡')
plt.grid(axis='y', alpha=0.3)

plt.subplot(1, 2, 2)
plt.plot(range(1, len(cumulative_variance_ratio) + 1),
         cumulative_variance_ratio, 'o-', linewidth=2, markersize=8)
plt.axhline(y=0.95, color='red', linestyle='--', linewidth=2, label='95%')
plt.axvline(x=n_components_95, color='green', linestyle='--',
            linewidth=2, label=f'{n_components_95}ä¸»æˆåˆ†')
plt.xlabel('ä¸»æˆåˆ†æ•°')
plt.ylabel('ç´¯ç©å¯„ä¸ç‡')
plt.title('ç´¯ç©å¯„ä¸ç‡')
plt.legend()
plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>=== å„ä¸»æˆåˆ†ã®å¯„ä¸ç‡ ===
PC1: å¯„ä¸ç‡ 0.7296, ç´¯ç©å¯„ä¸ç‡ 0.7296
PC2: å¯„ä¸ç‡ 0.2285, ç´¯ç©å¯„ä¸ç‡ 0.9581
PC3: å¯„ä¸ç‡ 0.0367, ç´¯ç©å¯„ä¸ç‡ 0.9948
PC4: å¯„ä¸ç‡ 0.0052, ç´¯ç©å¯„ä¸ç‡ 1.0000

ç´¯ç©å¯„ä¸ç‡95%ã«å¿…è¦ãªä¸»æˆåˆ†æ•°: 2

å…ƒã®æ¬¡å…ƒ: 4
å‰Šæ¸›å¾Œã®æ¬¡å…ƒ: 2
å®Ÿéš›ã®ç´¯ç©å¯„ä¸ç‡: 0.9581
</code></pre>

</details>

<h3>å•é¡Œ5ï¼ˆé›£æ˜“åº¦ï¼šhardï¼‰</h3>
<p>PCAã€t-SNEã€UMAPã‚’åŒã˜ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«é©ç”¨ã—ã€å¯è¦–åŒ–çµæœã‚’æ¯”è¼ƒã—ã¦ãã ã•ã„ã€‚MNISTã¾ãŸã¯Fashion-MNISTãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚</p>

<details>
<summary>è§£ç­”ä¾‹</summary>

<pre><code class="language-python">from sklearn.datasets import fetch_openml
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
import umap
import matplotlib.pyplot as plt
import time

# Fashion-MNISTãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆã¾ãŸã¯MNISTï¼‰
print("ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­...")
fashion_mnist = fetch_openml('Fashion-MNIST', version=1, parser='auto')
X = fashion_mnist.data.to_numpy()
y = fashion_mnist.target.astype(int).to_numpy()

# ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆè¨ˆç®—æ™‚é–“çŸ­ç¸®ã®ãŸã‚ï¼‰
n_samples = 5000
np.random.seed(42)
indices = np.random.choice(len(X), n_samples, replace=False)
X_sample = X[indices]
y_sample = y[indices]

print(f"ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: {X_sample.shape}")

# ã‚¯ãƒ©ã‚¹å
class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',
               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']

# 1. PCA
print("\nPCAå®Ÿè¡Œä¸­...")
start_time = time.time()
pca = PCA(n_components=2, random_state=42)
X_pca = pca.fit_transform(X_sample)
pca_time = time.time() - start_time
print(f"PCAå®Œäº†: {pca_time:.2f}ç§’")

# 2. t-SNE
print("t-SNEå®Ÿè¡Œä¸­...")
start_time = time.time()
tsne = TSNE(n_components=2, perplexity=30, random_state=42, n_iter=1000)
X_tsne = tsne.fit_transform(X_sample)
tsne_time = time.time() - start_time
print(f"t-SNEå®Œäº†: {tsne_time:.2f}ç§’")

# 3. UMAP
print("UMAPå®Ÿè¡Œä¸­...")
start_time = time.time()
umap_model = umap.UMAP(n_components=2, n_neighbors=15,
                       min_dist=0.1, random_state=42)
X_umap = umap_model.fit_transform(X_sample)
umap_time = time.time() - start_time
print(f"UMAPå®Œäº†: {umap_time:.2f}ç§’")

# å¯è¦–åŒ–
fig, axes = plt.subplots(1, 3, figsize=(20, 6))

# PCA
scatter1 = axes[0].scatter(X_pca[:, 0], X_pca[:, 1],
                          c=y_sample, cmap='tab10', alpha=0.6, s=10)
axes[0].set_title(f'PCA\nå®Ÿè¡Œæ™‚é–“: {pca_time:.2f}ç§’\n'
                 f'å¯„ä¸ç‡: {np.sum(pca.explained_variance_ratio_):.2%}',
                 fontsize=14)
axes[0].set_xlabel('PC1')
axes[0].set_ylabel('PC2')
axes[0].grid(True, alpha=0.3)

# t-SNE
scatter2 = axes[1].scatter(X_tsne[:, 0], X_tsne[:, 1],
                          c=y_sample, cmap='tab10', alpha=0.6, s=10)
axes[1].set_title(f't-SNE\nå®Ÿè¡Œæ™‚é–“: {tsne_time:.2f}ç§’',
                 fontsize=14)
axes[1].set_xlabel('t-SNE 1')
axes[1].set_ylabel('t-SNE 2')
axes[1].grid(True, alpha=0.3)

# UMAP
scatter3 = axes[2].scatter(X_umap[:, 0], X_umap[:, 1],
                          c=y_sample, cmap='tab10', alpha=0.6, s=10)
axes[2].set_title(f'UMAP\nå®Ÿè¡Œæ™‚é–“: {umap_time:.2f}ç§’',
                 fontsize=14)
axes[2].set_xlabel('UMAP 1')
axes[2].set_ylabel('UMAP 2')
axes[2].grid(True, alpha=0.3)

plt.colorbar(scatter3, ax=axes, label='ã‚¯ãƒ©ã‚¹',
            fraction=0.02, pad=0.04, ticks=range(10))

plt.tight_layout()
plt.show()

# å„æ‰‹æ³•ã®ç‰¹å¾´
print("\n=== æ¯”è¼ƒçµæœ ===")
print(f"PCA:   ã‚¯ãƒ©ã‚¹ã‚¿ã®åˆ†é›¢ã¯å¼±ã„ãŒã€é«˜é€Ÿ")
print(f"t-SNE: ã‚¯ãƒ©ã‚¹ã‚¿ãŒæ˜ç¢ºã«åˆ†é›¢ã€è¨ˆç®—æ™‚é–“ãŒé•·ã„")
print(f"UMAP:  ã‚¯ãƒ©ã‚¹ã‚¿åˆ†é›¢ã¨è¨ˆç®—é€Ÿåº¦ã®ãƒãƒ©ãƒ³ã‚¹ãŒè‰¯ã„")
</code></pre>

<p><strong>è¦³å¯Ÿãƒã‚¤ãƒ³ãƒˆ</strong>ï¼š</p>
<ul>
<li><strong>PCA</strong>: ç·šå½¢ãªã®ã§ã‚¯ãƒ©ã‚¹ã‚¿ã®é‡ãªã‚ŠãŒå¤šã„ã€‚é«˜é€Ÿã€‚</li>
<li><strong>t-SNE</strong>: ã‚¯ãƒ©ã‚¹ã‚¿ãŒæ˜ç¢ºã«åˆ†é›¢ã€‚å±€æ‰€æ§‹é€ ãŒå¼·èª¿ã•ã‚Œã‚‹ã€‚</li>
<li><strong>UMAP</strong>: t-SNEã«è¿‘ã„å“è³ªã§ã€ã‚ˆã‚Šé«˜é€Ÿã€‚å¤§åŸŸæ§‹é€ ã‚‚ä¿æŒã€‚</li>
</ul>

</details>

<hr>

<h2>å‚è€ƒæ–‡çŒ®</h2>

<ol>
<li>Jolliffe, I. T. (2002). <em>Principal Component Analysis</em>. Springer.</li>
<li>van der Maaten, L., & Hinton, G. (2008). Visualizing Data using t-SNE. <em>Journal of Machine Learning Research</em>, 9, 2579-2605.</li>
<li>McInnes, L., Healy, J., & Melville, J. (2018). UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction. <em>arXiv:1802.03426</em>.</li>
<li>Hastie, T., Tibshirani, R., & Friedman, J. (2009). <em>The Elements of Statistical Learning</em>. Springer.</li>
</ol>

<div class="navigation">
    <a href="chapter1-clustering-introduction.html" class="nav-button">â† å‰ã®ç« : ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°å…¥é–€</a>
    <a href="chapter3-clustering-advanced.html" class="nav-button">æ¬¡ã®ç« : é«˜åº¦ãªã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°æ‰‹æ³• â†’</a>
</div>

    </main>

    
    <section class="disclaimer">
        <h3>å…è²¬äº‹é …</h3>
        <ul>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯æ•™è‚²ãƒ»ç ”ç©¶ãƒ»æƒ…å ±æä¾›ã®ã¿ã‚’ç›®çš„ã¨ã—ã¦ãŠã‚Šã€å°‚é–€çš„ãªåŠ©è¨€(æ³•å¾‹ãƒ»ä¼šè¨ˆãƒ»æŠ€è¡“çš„ä¿è¨¼ãªã©)ã‚’æä¾›ã™ã‚‹ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŠã‚ˆã³ä»˜éšã™ã‚‹ã‚³ãƒ¼ãƒ‰ä¾‹ã¯ã€Œç¾çŠ¶æœ‰å§¿(AS IS)ã€ã§æä¾›ã•ã‚Œã€æ˜ç¤ºã¾ãŸã¯é»™ç¤ºã‚’å•ã‚ãšã€å•†å“æ€§ã€ç‰¹å®šç›®çš„é©åˆæ€§ã€æ¨©åˆ©éä¾µå®³ã€æ­£ç¢ºæ€§ãƒ»å®Œå…¨æ€§ã€å‹•ä½œãƒ»å®‰å…¨æ€§ç­‰ã„ã‹ãªã‚‹ä¿è¨¼ã‚‚ã—ã¾ã›ã‚“ã€‚</li>
            <li>å¤–éƒ¨ãƒªãƒ³ã‚¯ã€ç¬¬ä¸‰è€…ãŒæä¾›ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ»ãƒ„ãƒ¼ãƒ«ãƒ»ãƒ©ã‚¤ãƒ–ãƒ©ãƒªç­‰ã®å†…å®¹ãƒ»å¯ç”¨æ€§ãƒ»å®‰å…¨æ€§ã«ã¤ã„ã¦ã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯ä¸€åˆ‡ã®è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®åˆ©ç”¨ãƒ»å®Ÿè¡Œãƒ»è§£é‡ˆã«ã‚ˆã‚Šç›´æ¥çš„ãƒ»é–“æ¥çš„ãƒ»ä»˜éšçš„ãƒ»ç‰¹åˆ¥ãƒ»çµæœçš„ãƒ»æ‡²ç½°çš„æå®³ãŒç”Ÿã˜ãŸå ´åˆã§ã‚‚ã€é©ç”¨æ³•ã§è¨±å®¹ã•ã‚Œã‚‹æœ€å¤§é™ã®ç¯„å›²ã§ã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å†…å®¹ã¯ã€äºˆå‘Šãªãå¤‰æ›´ãƒ»æ›´æ–°ãƒ»æä¾›åœæ­¢ã•ã‚Œã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®è‘—ä½œæ¨©ãƒ»ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯æ˜è¨˜ã•ã‚ŒãŸæ¡ä»¶(ä¾‹: CC BY 4.0)ã«å¾“ã„ã¾ã™ã€‚å½“è©²ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯é€šå¸¸ã€ç„¡ä¿è¨¼æ¡é …ã‚’å«ã¿ã¾ã™ã€‚</li>
        </ul>
    </section>

<footer>
        <p><strong>ä½œæˆè€…</strong>: AI Terakoya Content Team</p>
        <p><strong>ãƒãƒ¼ã‚¸ãƒ§ãƒ³</strong>: 1.0 | <strong>ä½œæˆæ—¥</strong>: 2025-10-20</p>
        <p><strong>ãƒ©ã‚¤ã‚»ãƒ³ã‚¹</strong>: Creative Commons BY 4.0</p>
        <p>Â© 2025 AI Terakoya. All rights reserved.</p>
    </footer>
</body>
</html>
