<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ç¬¬2ç« ï¼šå®Ÿé¨“ç®¡ç†ã¨ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç† - AI Terakoya</title>

    <style>
        :root {
            --color-primary: #2c3e50;
            --color-primary-dark: #1a252f;
            --color-accent: #7b2cbf;
            --color-accent-light: #9d4edd;
            --color-text: #2d3748;
            --color-text-light: #4a5568;
            --color-bg: #ffffff;
            --color-bg-alt: #f7fafc;
            --color-border: #e2e8f0;
            --color-code-bg: #f8f9fa;
            --color-link: #3182ce;
            --color-link-hover: #2c5aa0;

            --spacing-xs: 0.5rem;
            --spacing-sm: 1rem;
            --spacing-md: 1.5rem;
            --spacing-lg: 2rem;
            --spacing-xl: 3rem;

            --font-body: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            --font-mono: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;

            --border-radius: 8px;
            --box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: var(--font-body);
            line-height: 1.7;
            color: var(--color-text);
            background-color: var(--color-bg);
            font-size: 16px;
        }

        header {
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            padding: var(--spacing-xl) var(--spacing-md);
            margin-bottom: var(--spacing-xl);
            box-shadow: var(--box-shadow);
        }

        .header-content {
            max-width: 900px;
            margin: 0 auto;
        }

        h1 {
            font-size: 2rem;
            font-weight: 700;
            margin-bottom: var(--spacing-sm);
            line-height: 1.2;
        }

        .subtitle {
            font-size: 1.1rem;
            opacity: 0.95;
            font-weight: 400;
            margin-bottom: var(--spacing-md);
        }

        .meta {
            display: flex;
            flex-wrap: wrap;
            gap: var(--spacing-md);
            font-size: 0.9rem;
            opacity: 0.9;
        }

        .meta-item {
            display: flex;
            align-items: center;
            gap: 0.3rem;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 0 var(--spacing-md) var(--spacing-xl);
        }

        h2 {
            font-size: 1.75rem;
            color: var(--color-primary);
            margin-top: var(--spacing-xl);
            margin-bottom: var(--spacing-md);
            padding-bottom: var(--spacing-xs);
            border-bottom: 3px solid var(--color-accent);
        }

        h3 {
            font-size: 1.4rem;
            color: var(--color-primary);
            margin-top: var(--spacing-lg);
            margin-bottom: var(--spacing-sm);
        }

        h4 {
            font-size: 1.1rem;
            color: var(--color-primary-dark);
            margin-top: var(--spacing-md);
            margin-bottom: var(--spacing-sm);
        }

        p {
            margin-bottom: var(--spacing-md);
            color: var(--color-text);
        }

        a {
            color: var(--color-link);
            text-decoration: none;
            transition: color 0.2s;
        }

        a:hover {
            color: var(--color-link-hover);
            text-decoration: underline;
        }

        ul, ol {
            margin-left: var(--spacing-lg);
            margin-bottom: var(--spacing-md);
        }

        li {
            margin-bottom: var(--spacing-xs);
            color: var(--color-text);
        }

        pre {
            background-color: var(--color-code-bg);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            overflow-x: auto;
            margin-bottom: var(--spacing-md);
            font-family: var(--font-mono);
            font-size: 0.9rem;
            line-height: 1.5;
        }

        code {
            font-family: var(--font-mono);
            font-size: 0.9em;
            background-color: var(--color-code-bg);
            padding: 0.2em 0.4em;
            border-radius: 3px;
        }

        pre code {
            background-color: transparent;
            padding: 0;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: var(--spacing-md);
            font-size: 0.95rem;
        }

        th, td {
            border: 1px solid var(--color-border);
            padding: var(--spacing-sm);
            text-align: left;
        }

        th {
            background-color: var(--color-bg-alt);
            font-weight: 600;
            color: var(--color-primary);
        }

        blockquote {
            border-left: 4px solid var(--color-accent);
            padding-left: var(--spacing-md);
            margin: var(--spacing-md) 0;
            color: var(--color-text-light);
            font-style: italic;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        .mermaid {
            text-align: center;
            margin: var(--spacing-lg) 0;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        details {
            background-color: var(--color-bg-alt);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            margin-bottom: var(--spacing-md);
        }

        summary {
            cursor: pointer;
            font-weight: 600;
            color: var(--color-primary);
            user-select: none;
            padding: var(--spacing-xs);
            margin: calc(-1 * var(--spacing-md));
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        summary:hover {
            background-color: rgba(123, 44, 191, 0.1);
        }

        details[open] summary {
            margin-bottom: var(--spacing-md);
            border-bottom: 1px solid var(--color-border);
        }

        .navigation {
            display: flex;
            justify-content: space-between;
            gap: var(--spacing-md);
            margin: var(--spacing-xl) 0;
            padding-top: var(--spacing-lg);
            border-top: 2px solid var(--color-border);
        }

        .nav-button {
            flex: 1;
            padding: var(--spacing-md);
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            border-radius: var(--border-radius);
            text-align: center;
            font-weight: 600;
            transition: transform 0.2s, box-shadow 0.2s;
            box-shadow: var(--box-shadow);
        }

        .nav-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
            text-decoration: none;
        }

        footer {
            margin-top: var(--spacing-xl);
            padding: var(--spacing-lg) var(--spacing-md);
            background-color: var(--color-bg-alt);
            border-top: 1px solid var(--color-border);
            text-align: center;
            font-size: 0.9rem;
            color: var(--color-text-light);
        }
        .disclaimer {
            max-width: 900px;
            margin: 2rem auto;
            padding: 1.5rem;
            background: #f8f9fa;
            border-left: 4px solid #6c757d;
            border-radius: 4px;
        }

        .disclaimer h3 {
            color: #495057;
            margin-bottom: 1rem;
            font-size: 1.1rem;
        }

        .disclaimer ul {
            list-style: none;
            padding-left: 0;
        }

        .disclaimer li {
            padding: 0.5rem 0;
            padding-left: 1.5rem;
            position: relative;
            font-size: 0.9rem;
            color: #6c757d;
            line-height: 1.6;
        }

        .disclaimer li::before {
            content: "âš ï¸";
            position: absolute;
            left: 0;
        }


        @media (max-width: 768px) {
            h1 {
                font-size: 1.5rem;
            }

            h2 {
                font-size: 1.4rem;
            }

            h3 {
                font-size: 1.2rem;
            }

            .meta {
                font-size: 0.85rem;
            }

            .navigation {
                flex-direction: column;
            }

            table {
                font-size: 0.85rem;
            }

            th, td {
                padding: var(--spacing-xs);
            }
        }
    
        
    
        /* Breadcrumb styles */
        .breadcrumb {
            background: #f7fafc;
            padding: 0.75rem 1rem;
            border-bottom: 1px solid #e2e8f0;
            font-size: 0.9rem;
        }

        .breadcrumb-content {
            max-width: 900px;
            margin: 0 auto;
            display: flex;
            align-items: center;
            flex-wrap: wrap;
            gap: 0.5rem;
        }

        .breadcrumb a {
            color: #667eea;
            text-decoration: none;
            transition: color 0.2s;
        }

        .breadcrumb a:hover {
            color: #764ba2;
            text-decoration: underline;
        }

        .breadcrumb-separator {
            color: #a0aec0;
            margin: 0 0.25rem;
        }

        .breadcrumb-current {
            color: #4a5568;
            font-weight: 500;
        }
    </style>

    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
        mermaid.initialize({ startOnLoad: true, theme: 'default' });
    </script>

    <!-- MathJax for LaTeX equation rendering -->
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                displayMath: [['$$', '$$'], ['\\[', '\\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
                ignoreHtmlClass: 'mermaid'
            }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" async></script>

    <style>
        /* Locale Switcher Styles */
        .locale-switcher {
            display: flex;
            align-items: center;
            gap: 0.5rem;
            padding: 0.5rem 1rem;
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
            border-radius: 6px;
            font-size: 0.9rem;
            margin-bottom: 1rem;
            box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);
        }

        .current-locale {
            font-weight: 600;
            color: #7b2cbf;
            display: flex;
            align-items: center;
            gap: 0.25rem;
        }

        .locale-separator {
            color: #adb5bd;
            font-weight: 300;
        }

        .locale-link {
            color: #f093fb;
            text-decoration: none;
            font-weight: 500;
            transition: all 0.2s ease;
            display: flex;
            align-items: center;
            gap: 0.25rem;
            padding: 0.2rem 0.5rem;
            border-radius: 4px;
        }

        .locale-link:hover {
            background: rgba(240, 147, 251, 0.1);
            color: #d07be8;
            transform: translateY(-1px);
        }

        .locale-meta {
            color: #868e96;
            font-size: 0.85rem;
            font-style: italic;
            margin-left: auto;
        }

        @media (max-width: 768px) {
            .locale-switcher {
                font-size: 0.85rem;
                padding: 0.4rem 0.8rem;
            }
            .locale-meta {
                display: none;
            }
        }
    </style>
</head>
<body>
            <div class="locale-switcher">
<span class="current-locale">ğŸŒ JP</span>
<span class="locale-separator">|</span>
<a href="../../../en/ML/mlops-introduction/chapter2-experiment-management.html" class="locale-link">ğŸ‡¬ğŸ‡§ EN</a>
<span class="locale-separator">|</span>
<span class="locale-meta">Last sync: 2025-11-16</span>
</div>
<nav class="breadcrumb">
        <div class="breadcrumb-content">
            <a href="../../index.html">AIå¯ºå­å±‹ãƒˆãƒƒãƒ—</a><span class="breadcrumb-separator">â€º</span><a href="../../ML/index.html">æ©Ÿæ¢°å­¦ç¿’</a><span class="breadcrumb-separator">â€º</span><a href="../../ML/mlops-introduction/index.html">Mlops</a><span class="breadcrumb-separator">â€º</span><span class="breadcrumb-current">Chapter 2</span>
        </div>
    </nav>

        <header>
        <div class="header-content">
            <h1>ç¬¬2ç« ï¼šå®Ÿé¨“ç®¡ç†ã¨ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†</h1>
            <p class="subtitle">å†ç¾å¯èƒ½ãªæ©Ÿæ¢°å­¦ç¿’ã®ãŸã‚ã®å®Ÿé¨“ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ã¨ãƒ‡ãƒ¼ã‚¿ãƒãƒ¼ã‚¸ãƒ§ãƒ‹ãƒ³ã‚°</p>
            <div class="meta">
                <span class="meta-item">ğŸ“– èª­äº†æ™‚é–“: 30-35åˆ†</span>
                <span class="meta-item">ğŸ“Š é›£æ˜“åº¦: ä¸­ç´š</span>
                <span class="meta-item">ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹: 12å€‹</span>
                <span class="meta-item">ğŸ“ æ¼”ç¿’å•é¡Œ: 5å•</span>
            </div>
        </div>
    </header>

    <main class="container">

<h2>å­¦ç¿’ç›®æ¨™</h2>
<p>ã“ã®ç« ã‚’èª­ã‚€ã“ã¨ã§ã€ä»¥ä¸‹ã‚’ç¿’å¾—ã§ãã¾ã™ï¼š</p>
<ul>
<li>âœ… æ©Ÿæ¢°å­¦ç¿’ã«ãŠã‘ã‚‹å®Ÿé¨“ç®¡ç†ã®é‡è¦æ€§ã‚’ç†è§£ã™ã‚‹</li>
<li>âœ… MLflowã‚’ä½¿ã£ãŸå®Ÿé¨“ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ã¨ãƒ¢ãƒ‡ãƒ«ç®¡ç†ã‚’å®Ÿè£…ã§ãã‚‹</li>
<li>âœ… Weights & Biasesã§ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–ã‚’å®Ÿè¡Œã§ãã‚‹</li>
<li>âœ… DVCã§ãƒ‡ãƒ¼ã‚¿ã¨ãƒ¢ãƒ‡ãƒ«ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ã‚’è¡Œãˆã‚‹</li>
<li>âœ… å®Ÿé¨“ç®¡ç†ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã‚’é©ç”¨ã§ãã‚‹</li>
<li>âœ… å†ç¾å¯èƒ½ãªæ©Ÿæ¢°å­¦ç¿’ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’æ§‹ç¯‰ã§ãã‚‹</li>
</ul>

<hr>

<h2>2.1 å®Ÿé¨“ç®¡ç†ã®é‡è¦æ€§</h2>

<h3>å®Ÿé¨“ç®¡ç†ã¨ã¯</h3>
<p><strong>å®Ÿé¨“ç®¡ç†ï¼ˆExperiment Managementï¼‰</strong>ã¯ã€æ©Ÿæ¢°å­¦ç¿’ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«ãŠã‘ã‚‹å®Ÿé¨“ã®è¨˜éŒ²ã€è¿½è·¡ã€æ¯”è¼ƒã€å†ç¾ã‚’ä½“ç³»çš„ã«è¡Œã†ãƒ—ãƒ­ã‚»ã‚¹ã§ã™ã€‚</p>

<blockquote>
<p>ã€Œå„ªã‚ŒãŸMLãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯ã€æ•°ç™¾ã‹ã‚‰æ•°åƒã®å®Ÿé¨“ã‚’ç®¡ç†ã™ã‚‹èƒ½åŠ›ã«ã‹ã‹ã£ã¦ã„ã¾ã™ã€‚ã€</p>
</blockquote>

<h3>å®Ÿé¨“ç®¡ç†ã®èª²é¡Œ</h3>

<table>
<thead>
<tr>
<th>èª²é¡Œ</th>
<th>å½±éŸ¿</th>
<th>è§£æ±ºç­–</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>å†ç¾æ€§ã®æ¬ å¦‚</strong></td>
<td>éå»ã®å®Ÿé¨“ã‚’å†ç¾ã§ããªã„</td>
<td>ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ»ã‚³ãƒ¼ãƒ‰ãƒ»ãƒ‡ãƒ¼ã‚¿ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†</td>
</tr>
<tr>
<td><strong>å®Ÿé¨“ã®æ¯”è¼ƒå›°é›£</strong></td>
<td>æœ€é©ãªãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã§ããªã„</td>
<td>çµ±ä¸€ã•ã‚ŒãŸãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨˜éŒ²</td>
</tr>
<tr>
<td><strong>çŸ¥è¦‹ã®æå¤±</strong></td>
<td>ãƒãƒ¼ãƒ é–“ã§æƒ…å ±ãŒå…±æœ‰ã•ã‚Œãªã„</td>
<td>ä¸€å…ƒåŒ–ã•ã‚ŒãŸå®Ÿé¨“ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°</td>
</tr>
<tr>
<td><strong>ãƒ‡ãƒ¼ã‚¿ãƒ‰ãƒªãƒ•ãƒˆ</strong></td>
<td>ãƒ‡ãƒ¼ã‚¿å¤‰æ›´ã‚’è¿½è·¡ã§ããªã„</td>
<td>ãƒ‡ãƒ¼ã‚¿ãƒãƒ¼ã‚¸ãƒ§ãƒ‹ãƒ³ã‚°</td>
</tr>
</tbody>
</table>

<h3>å®Ÿé¨“ç®¡ç†ã®å…¨ä½“åƒ</h3>

<div class="mermaid">
graph TD
    A[å®Ÿé¨“è¨­è¨ˆ] --> B[ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š]
    B --> C[ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰]
    C --> D[ãƒ¢ãƒ‡ãƒ«è¨“ç·´]
    D --> E[ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨˜éŒ²]
    E --> F[ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆä¿å­˜]
    F --> G[å®Ÿé¨“æ¯”è¼ƒ]
    G --> H{æ”¹å–„?}
    H -->|Yes| I[ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«é¸æŠ]
    H -->|No| B
    I --> J[ãƒ¢ãƒ‡ãƒ«ãƒ‡ãƒ—ãƒ­ã‚¤]

    style A fill:#ffebee
    style D fill:#e3f2fd
    style E fill:#fff3e0
    style F fill:#f3e5f5
    style I fill:#c8e6c9
    style J fill:#c8e6c9
</div>

<h3>å®Ÿé¨“ç®¡ç†ãŒã‚‚ãŸã‚‰ã™ä¾¡å€¤</h3>

<h4>1. å†ç¾æ€§ã®ç¢ºä¿</h4>
<ul>
<li>åŒã˜çµæœã‚’å†ç¾ã§ãã‚‹ç’°å¢ƒ</li>
<li>ã‚³ãƒ¼ãƒ‰ã€ãƒ‡ãƒ¼ã‚¿ã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å®Œå…¨ãªè¨˜éŒ²</li>
<li>ç›£æŸ»ã¨ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹ã®å®¹æ˜“åŒ–</li>
</ul>

<h4>2. å®Ÿé¨“ã®æ¯”è¼ƒã¨åˆ†æ</h4>
<ul>
<li>è¤‡æ•°ã®å®Ÿé¨“ã‚’ç³»çµ±çš„ã«æ¯”è¼ƒ</li>
<li>ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨æ€§èƒ½ã®é–¢ä¿‚ã‚’å¯è¦–åŒ–</li>
<li>ãƒ‡ãƒ¼ã‚¿ãƒ‰ãƒªãƒ–ãƒ³ãªæ„æ€æ±ºå®š</li>
</ul>

<h4>3. ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã®é¸æŠ</h4>
<ul>
<li>å®¢è¦³çš„ãªåŸºæº–ã§ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ</li>
<li>ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¨ã‚³ã‚¹ãƒˆã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•åˆ†æ</li>
<li>æœ¬ç•ªç’°å¢ƒã¸ã®è‡ªä¿¡ã‚’æŒã£ãŸãƒ‡ãƒ—ãƒ­ã‚¤</li>
</ul>

<hr>

<h2>2.2 MLflow</h2>

<h3>MLflowã¨ã¯</h3>
<p><strong>MLflow</strong>ã¯ã€æ©Ÿæ¢°å­¦ç¿’ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«å…¨ä½“ã‚’ç®¡ç†ã™ã‚‹ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã§ã™ã€‚</p>

<h3>MLflowã®ä¸»è¦ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ</h3>

<table>
<thead>
<tr>
<th>ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ</th>
<th>æ©Ÿèƒ½</th>
<th>ç”¨é€”</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>MLflow Tracking</strong></td>
<td>å®Ÿé¨“ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ»ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨˜éŒ²</td>
<td>å®Ÿé¨“ç®¡ç†</td>
</tr>
<tr>
<td><strong>MLflow Projects</strong></td>
<td>å†ç¾å¯èƒ½ãªã‚³ãƒ¼ãƒ‰å®Ÿè¡Œ</td>
<td>ç’°å¢ƒç®¡ç†</td>
</tr>
<tr>
<td><strong>MLflow Models</strong></td>
<td>ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãƒ³ã‚°ã¨ãƒ‡ãƒ—ãƒ­ã‚¤</td>
<td>ãƒ¢ãƒ‡ãƒ«ç®¡ç†</td>
</tr>
<tr>
<td><strong>MLflow Registry</strong></td>
<td>ãƒ¢ãƒ‡ãƒ«ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†</td>
<td>æœ¬ç•ªé‹ç”¨</td>
</tr>
</tbody>
</table>

<h3>MLflow Tracking: åŸºæœ¬çš„ãªä½¿ã„æ–¹</h3>

<pre><code class="language-python">import mlflow
import mlflow.sklearn
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score
from sklearn.datasets import make_classification

# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆ
X, y = make_classification(
    n_samples=1000,
    n_features=20,
    n_informative=15,
    n_redundant=5,
    random_state=42
)

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# MLflowå®Ÿé¨“ã®è¨­å®š
mlflow.set_experiment("random_forest_classification")

# å®Ÿé¨“ã®å®Ÿè¡Œ
with mlflow.start_run(run_name="rf_baseline"):
    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®è¨­å®š
    n_estimators = 100
    max_depth = 10
    random_state = 42

    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®è¨˜éŒ²
    mlflow.log_param("n_estimators", n_estimators)
    mlflow.log_param("max_depth", max_depth)
    mlflow.log_param("random_state", random_state)

    # ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´
    model = RandomForestClassifier(
        n_estimators=n_estimators,
        max_depth=max_depth,
        random_state=random_state
    )
    model.fit(X_train, y_train)

    # äºˆæ¸¬ã¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®è¨ˆç®—
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)

    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®è¨˜éŒ²
    mlflow.log_metric("accuracy", accuracy)
    mlflow.log_metric("precision", precision)
    mlflow.log_metric("recall", recall)

    # ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜
    mlflow.sklearn.log_model(model, "model")

    print(f"Accuracy: {accuracy:.3f}")
    print(f"Precision: {precision:.3f}")
    print(f"Recall: {recall:.3f}")
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>Accuracy: 0.895
Precision: 0.891
Recall: 0.902
</code></pre>

<h3>è¤‡æ•°ã®å®Ÿé¨“ã®å®Ÿè¡Œã¨æ¯”è¼ƒ</h3>

<pre><code class="language-python">import mlflow
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
import numpy as np

# å®Ÿé¨“è¨­å®šã®ãƒªã‚¹ãƒˆ
experiment_configs = [
    {"n_estimators": 50, "max_depth": 5, "name": "rf_shallow"},
    {"n_estimators": 100, "max_depth": 10, "name": "rf_medium"},
    {"n_estimators": 200, "max_depth": 20, "name": "rf_deep"},
    {"n_estimators": 300, "max_depth": None, "name": "rf_full"},
]

mlflow.set_experiment("rf_hyperparameter_tuning")

# å„è¨­å®šã§å®Ÿé¨“ã‚’å®Ÿè¡Œ
results = []
for config in experiment_configs:
    with mlflow.start_run(run_name=config["name"]):
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®è¨˜éŒ²
        mlflow.log_param("n_estimators", config["n_estimators"])
        mlflow.log_param("max_depth", config["max_depth"])

        # ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´
        model = RandomForestClassifier(
            n_estimators=config["n_estimators"],
            max_depth=config["max_depth"],
            random_state=42
        )
        model.fit(X_train, y_train)

        # è©•ä¾¡
        train_acc = accuracy_score(y_train, model.predict(X_train))
        test_acc = accuracy_score(y_test, model.predict(X_test))

        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®è¨˜éŒ²
        mlflow.log_metric("train_accuracy", train_acc)
        mlflow.log_metric("test_accuracy", test_acc)
        mlflow.log_metric("overfit_gap", train_acc - test_acc)

        # ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜
        mlflow.sklearn.log_model(model, "model")

        results.append({
            "name": config["name"],
            "train_acc": train_acc,
            "test_acc": test_acc,
            "overfit": train_acc - test_acc
        })

        print(f"{config['name']}: Train={train_acc:.3f}, Test={test_acc:.3f}, Overfit={train_acc - test_acc:.3f}")

print("\n=== å®Ÿé¨“çµæœã®æ¯”è¼ƒ ===")
for result in sorted(results, key=lambda x: x['test_acc'], reverse=True):
    print(f"{result['name']}: Test Accuracy = {result['test_acc']:.3f}")
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>rf_shallow: Train=0.862, Test=0.855, Overfit=0.007
rf_medium: Train=0.895, Test=0.895, Overfit=0.000
rf_deep: Train=0.987, Test=0.890, Overfit=0.097
rf_full: Train=1.000, Test=0.885, Overfit=0.115

=== å®Ÿé¨“çµæœã®æ¯”è¼ƒ ===
rf_medium: Test Accuracy = 0.895
rf_deep: Test Accuracy = 0.890
rf_full: Test Accuracy = 0.885
rf_shallow: Test Accuracy = 0.855
</code></pre>

<h3>MLflow Autolog: è‡ªå‹•ãƒ­ã‚®ãƒ³ã‚°</h3>

<pre><code class="language-python">import mlflow
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_val_score

# MLflow autologã‚’æœ‰åŠ¹åŒ–
mlflow.sklearn.autolog()

mlflow.set_experiment("rf_with_autolog")

with mlflow.start_run(run_name="rf_autolog_example"):
    # ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ï¼ˆè‡ªå‹•çš„ã«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãŒè¨˜éŒ²ã•ã‚Œã‚‹ï¼‰
    model = RandomForestClassifier(
        n_estimators=150,
        max_depth=15,
        min_samples_split=5,
        random_state=42
    )
    model.fit(X_train, y_train)

    # è¿½åŠ ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’æ‰‹å‹•ã§è¨˜éŒ²
    cv_scores = cross_val_score(model, X_train, y_train, cv=5)
    mlflow.log_metric("cv_mean", cv_scores.mean())
    mlflow.log_metric("cv_std", cv_scores.std())

    print(f"Test Accuracy: {model.score(X_test, y_test):.3f}")
    print(f"CV Mean: {cv_scores.mean():.3f} (+/- {cv_scores.std():.3f})")
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>Test Accuracy: 0.900
CV Mean: 0.893 (+/- 0.012)
</code></pre>

<blockquote>
<p><strong>Autologã®åˆ©ç‚¹</strong>: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã€ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã€ãƒ¢ãƒ‡ãƒ«ãŒè‡ªå‹•çš„ã«è¨˜éŒ²ã•ã‚Œã€æ‰‹å‹•ãƒ­ã‚°ã®è¨˜è¿°ãƒŸã‚¹ã‚’é˜²ãã¾ã™ã€‚</p>
</blockquote>

<h3>MLflow Models: ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãƒ³ã‚°</h3>

<pre><code class="language-python">import mlflow
import mlflow.pyfunc
import pandas as pd
from sklearn.ensemble import RandomForestClassifier

# ã‚«ã‚¹ã‚¿ãƒ ãƒ¢ãƒ‡ãƒ«ãƒ©ãƒƒãƒ‘ãƒ¼ã®å®šç¾©
class CustomModelWrapper(mlflow.pyfunc.PythonModel):
    def __init__(self, model):
        self.model = model

    def predict(self, context, model_input):
        """ã‚«ã‚¹ã‚¿ãƒ äºˆæ¸¬ãƒ­ã‚¸ãƒƒã‚¯"""
        predictions = self.model.predict_proba(model_input)
        # ä¿¡é ¼åº¦ãŒ0.7ä»¥ä¸Šã®å ´åˆã®ã¿äºˆæ¸¬ã‚’è¿”ã™
        confident_predictions = []
        for i, prob in enumerate(predictions):
            max_prob = max(prob)
            if max_prob >= 0.7:
                confident_predictions.append(int(prob.argmax()))
            else:
                confident_predictions.append(-1)  # ä¸æ˜
        return confident_predictions

# ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´
base_model = RandomForestClassifier(n_estimators=100, random_state=42)
base_model.fit(X_train, y_train)

# ã‚«ã‚¹ã‚¿ãƒ ãƒ¢ãƒ‡ãƒ«ã®ãƒ©ãƒƒãƒ—
wrapped_model = CustomModelWrapper(base_model)

mlflow.set_experiment("custom_model_packaging")

with mlflow.start_run(run_name="confident_predictor"):
    # ã‚«ã‚¹ã‚¿ãƒ ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜
    mlflow.pyfunc.log_model(
        artifact_path="confident_model",
        python_model=wrapped_model,
        conda_env={
            'name': 'mlflow-env',
            'channels': ['defaults'],
            'dependencies': [
                'python=3.8',
                'scikit-learn=1.0.2',
                'numpy',
            ]
        }
    )

    # ãƒ†ã‚¹ãƒˆäºˆæ¸¬
    test_predictions = wrapped_model.predict(None, X_test[:5])
    print(f"ä¿¡é ¼åº¦ä»˜ãäºˆæ¸¬: {test_predictions}")
    print(f"ä¿¡é ¼åº¦ã®ä½ã„äºˆæ¸¬ï¼ˆ-1ï¼‰ã®æ•°: {sum(1 for p in test_predictions if p == -1)}")
</code></pre>

<h3>MLflow UI: å®Ÿé¨“ã®å¯è¦–åŒ–</h3>

<pre><code class="language-bash"># MLflow UIã®èµ·å‹•
# mlflow ui --port 5000

# ãƒ–ãƒ©ã‚¦ã‚¶ã§ http://localhost:5000 ã«ã‚¢ã‚¯ã‚»ã‚¹
# - å®Ÿé¨“ã®ä¸€è¦§è¡¨ç¤º
# - ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®æ¯”è¼ƒ
# - ãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
# - å®Ÿé¨“ã®æ¤œç´¢ã¨ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
</code></pre>

<h3>MLflow Projects: å†ç¾å¯èƒ½ãªå®Ÿè¡Œ</h3>

<pre><code class="language-python"># MLproject ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆYAMLå½¢å¼ï¼‰
"""
name: my_ml_project

conda_env: conda.yaml

entry_points:
  main:
    parameters:
      n_estimators: {type: int, default: 100}
      max_depth: {type: int, default: 10}
      data_path: {type: string, default: "data/"}
    command: "python train.py --n-estimators {n_estimators} --max-depth {max_depth} --data-path {data_path}"
"""

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®å®Ÿè¡Œ
import mlflow

# ãƒ­ãƒ¼ã‚«ãƒ«ã§å®Ÿè¡Œ
mlflow.run(
    ".",
    parameters={
        "n_estimators": 200,
        "max_depth": 15,
        "data_path": "data/train.csv"
    }
)

# GitHubã‹ã‚‰å®Ÿè¡Œ
mlflow.run(
    "https://github.com/username/ml-project",
    version="main",
    parameters={"n_estimators": 150}
)
</code></pre>

<hr>

<h2>2.3 Weights & Biases (W&B)</h2>

<h3>Weights & Biasesã¨ã¯</h3>
<p><strong>Weights & Biases (W&B)</strong>ã¯ã€å®Ÿé¨“ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ã€å¯è¦–åŒ–ã€ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–ã®ãŸã‚ã®å¼·åŠ›ãªãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã§ã™ã€‚</p>

<h3>W&Bã®ä¸»è¦æ©Ÿèƒ½</h3>

<table>
<thead>
<tr>
<th>æ©Ÿèƒ½</th>
<th>èª¬æ˜</th>
<th>ç”¨é€”</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Experiment Tracking</strong></td>
<td>ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’å¯è¦–åŒ–</td>
<td>å®Ÿé¨“ç›£è¦–</td>
</tr>
<tr>
<td><strong>Sweeps</strong></td>
<td>ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è‡ªå‹•æœ€é©åŒ–</td>
<td>ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°</td>
</tr>
<tr>
<td><strong>Artifacts</strong></td>
<td>ãƒ¢ãƒ‡ãƒ«ãƒ»ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ä¿å­˜</td>
<td>ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†</td>
</tr>
<tr>
<td><strong>Reports</strong></td>
<td>å®Ÿé¨“ãƒ¬ãƒãƒ¼ãƒˆã®ä½œæˆã¨å…±æœ‰</td>
<td>ãƒãƒ¼ãƒ å”æ¥­</td>
</tr>
</tbody>
</table>

<h3>W&B: åŸºæœ¬çš„ãªå®Ÿé¨“ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°</h3>

<pre><code class="language-python">import wandb
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, f1_score, confusion_matrix
import numpy as np

# W&Bã®åˆæœŸåŒ–
wandb.init(
    project="ml-experiment-tracking",
    name="rf_baseline",
    config={
        "n_estimators": 100,
        "max_depth": 10,
        "min_samples_split": 2,
        "random_state": 42
    }
)

# è¨­å®šã®å–å¾—
config = wandb.config

# ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´
model = RandomForestClassifier(
    n_estimators=config.n_estimators,
    max_depth=config.max_depth,
    min_samples_split=config.min_samples_split,
    random_state=config.random_state
)
model.fit(X_train, y_train)

# è©•ä¾¡
y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

# ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®è¨˜éŒ²
wandb.log({
    "accuracy": accuracy,
    "f1_score": f1,
    "train_samples": len(X_train),
    "test_samples": len(X_test)
})

# æ··åŒè¡Œåˆ—ã®å¯è¦–åŒ–
wandb.log({
    "confusion_matrix": wandb.plot.confusion_matrix(
        probs=None,
        y_true=y_test,
        preds=y_pred,
        class_names=["Class 0", "Class 1"]
    )
})

print(f"Accuracy: {accuracy:.3f}, F1: {f1:.3f}")

# å®Ÿé¨“ã®çµ‚äº†
wandb.finish()
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>Accuracy: 0.895, F1: 0.897
View run at: https://wandb.ai/username/ml-experiment-tracking/runs/xxxxx
</code></pre>

<h3>W&B: å­¦ç¿’æ›²ç·šã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å¯è¦–åŒ–</h3>

<pre><code class="language-python">import wandb
from sklearn.model_selection import learning_curve
from sklearn.ensemble import RandomForestClassifier
import numpy as np

wandb.init(project="learning-curves", name="rf_learning_curve")

# å­¦ç¿’æ›²ç·šã®è¨ˆç®—
train_sizes = np.linspace(0.1, 1.0, 10)
train_sizes_abs, train_scores, test_scores = learning_curve(
    RandomForestClassifier(n_estimators=100, random_state=42),
    X_train, y_train,
    train_sizes=train_sizes,
    cv=5,
    scoring='accuracy',
    n_jobs=-1
)

# å„è¨“ç·´ã‚µã‚¤ã‚ºã§ã®ã‚¹ã‚³ã‚¢ã‚’è¨˜éŒ²
for i, size in enumerate(train_sizes_abs):
    wandb.log({
        "train_size": size,
        "train_score_mean": train_scores[i].mean(),
        "train_score_std": train_scores[i].std(),
        "test_score_mean": test_scores[i].mean(),
        "test_score_std": test_scores[i].std()
    })

print("å­¦ç¿’æ›²ç·šã®è¨ˆç®—å®Œäº†")
wandb.finish()
</code></pre>

<h3>W&B Sweeps: ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–</h3>

<pre><code class="language-python">import wandb
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

# Sweepè¨­å®šã®å®šç¾©
sweep_config = {
    'method': 'bayes',  # ãƒ™ã‚¤ã‚ºæœ€é©åŒ–
    'metric': {
        'name': 'accuracy',
        'goal': 'maximize'
    },
    'parameters': {
        'n_estimators': {
            'distribution': 'int_uniform',
            'min': 50,
            'max': 300
        },
        'max_depth': {
            'distribution': 'int_uniform',
            'min': 5,
            'max': 30
        },
        'min_samples_split': {
            'distribution': 'int_uniform',
            'min': 2,
            'max': 20
        },
        'min_samples_leaf': {
            'distribution': 'int_uniform',
            'min': 1,
            'max': 10
        }
    }
}

# è¨“ç·´é–¢æ•°ã®å®šç¾©
def train():
    # W&Bã®åˆæœŸåŒ–
    wandb.init()
    config = wandb.config

    # ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´
    model = RandomForestClassifier(
        n_estimators=config.n_estimators,
        max_depth=config.max_depth,
        min_samples_split=config.min_samples_split,
        min_samples_leaf=config.min_samples_leaf,
        random_state=42
    )
    model.fit(X_train, y_train)

    # è©•ä¾¡
    train_acc = accuracy_score(y_train, model.predict(X_train))
    test_acc = accuracy_score(y_test, model.predict(X_test))

    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®è¨˜éŒ²
    wandb.log({
        'accuracy': test_acc,
        'train_accuracy': train_acc,
        'overfit_gap': train_acc - test_acc
    })

# Sweepã®å®Ÿè¡Œ
sweep_id = wandb.sweep(sweep_config, project="hyperparameter-tuning")

# 10å›ã®å®Ÿé¨“ã‚’å®Ÿè¡Œ
wandb.agent(sweep_id, function=train, count=10)

print(f"Sweepå®Œäº†: {sweep_id}")
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>Sweepå®Œäº†: username/hyperparameter-tuning/sweep_xxxxx
æœ€è‰¯ã®ç²¾åº¦: 0.915
æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: n_estimators=220, max_depth=18, min_samples_split=3, min_samples_leaf=2
</code></pre>

<h3>W&B: ãƒ¢ãƒ‡ãƒ«ã¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ä¿å­˜</h3>

<pre><code class="language-python">import wandb
import joblib
from sklearn.ensemble import RandomForestClassifier

wandb.init(project="model-artifacts", name="rf_with_artifacts")

# ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜
model_path = "random_forest_model.pkl"
joblib.dump(model, model_path)

# W&Bã«ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆã¨ã—ã¦ä¿å­˜
artifact = wandb.Artifact(
    name="random_forest_model",
    type="model",
    description="Random Forest classifier trained on classification dataset"
)
artifact.add_file(model_path)
wandb.log_artifact(artifact)

# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ä¿å­˜
import pandas as pd
df_train = pd.DataFrame(X_train, columns=[f"feature_{i}" for i in range(X_train.shape[1])])
df_train['target'] = y_train
df_train.to_csv("train_data.csv", index=False)

data_artifact = wandb.Artifact(
    name="training_dataset",
    type="dataset",
    description="Training dataset for RF model"
)
data_artifact.add_file("train_data.csv")
wandb.log_artifact(data_artifact)

print("ãƒ¢ãƒ‡ãƒ«ã¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä¿å­˜ã—ã¾ã—ãŸ")
wandb.finish()
</code></pre>

<h3>W&B: è¤‡æ•°å®Ÿé¨“ã®å¯è¦–åŒ–æ¯”è¼ƒ</h3>

<pre><code class="language-python">import wandb
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score

# è¤‡æ•°ã®ãƒ¢ãƒ‡ãƒ«ã§å®Ÿé¨“
models = {
    "random_forest": RandomForestClassifier(n_estimators=100, random_state=42),
    "gradient_boosting": GradientBoostingClassifier(n_estimators=100, random_state=42),
    "logistic_regression": LogisticRegression(random_state=42, max_iter=1000)
}

for model_name, model in models.items():
    # å®Ÿé¨“ã®é–‹å§‹
    run = wandb.init(
        project="model-comparison",
        name=model_name,
        reinit=True
    )

    # ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´
    model.fit(X_train, y_train)

    # äºˆæ¸¬ã¨è©•ä¾¡
    y_pred = model.predict(X_test)

    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®è¨˜éŒ²
    wandb.log({
        "accuracy": accuracy_score(y_test, y_pred),
        "precision": precision_score(y_test, y_pred),
        "recall": recall_score(y_test, y_pred),
        "model_type": model_name
    })

    # ç‰¹å¾´é‡é‡è¦åº¦ã®è¨˜éŒ²ï¼ˆå¯èƒ½ãªå ´åˆï¼‰
    if hasattr(model, 'feature_importances_'):
        importance_data = [[i, imp] for i, imp in enumerate(model.feature_importances_)]
        table = wandb.Table(data=importance_data, columns=["feature", "importance"])
        wandb.log({"feature_importance": wandb.plot.bar(table, "feature", "importance")})

    run.finish()

print("å…¨ãƒ¢ãƒ‡ãƒ«ã®å®Ÿé¨“å®Œäº†")
</code></pre>

<hr>

<h2>2.4 DVC (Data Version Control)</h2>

<h3>DVCã¨ã¯</h3>
<p><strong>DVCï¼ˆData Version Controlï¼‰</strong>ã¯ã€ãƒ‡ãƒ¼ã‚¿ã¨ãƒ¢ãƒ‡ãƒ«ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ã‚’ã€Gitã®ã‚ˆã†ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã§å®Ÿç¾ã™ã‚‹ãƒ„ãƒ¼ãƒ«ã§ã™ã€‚</p>

<h3>DVCã®ä¸»è¦æ©Ÿèƒ½</h3>

<table>
<thead>
<tr>
<th>æ©Ÿèƒ½</th>
<th>èª¬æ˜</th>
<th>ç”¨é€”</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>ãƒ‡ãƒ¼ã‚¿ãƒãƒ¼ã‚¸ãƒ§ãƒ‹ãƒ³ã‚°</strong></td>
<td>å¤§å®¹é‡ãƒ‡ãƒ¼ã‚¿ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†</td>
<td>ãƒ‡ãƒ¼ã‚¿è¿½è·¡</td>
</tr>
<tr>
<td><strong>ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®šç¾©</strong></td>
<td>å†ç¾å¯èƒ½ãªMLãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³</td>
<td>ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ç®¡ç†</td>
</tr>
<tr>
<td><strong>ãƒªãƒ¢ãƒ¼ãƒˆã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸</strong></td>
<td>S3ã€GCSã€Azureç­‰ã¨ã®é€£æº</td>
<td>ãƒ‡ãƒ¼ã‚¿å…±æœ‰</td>
</tr>
<tr>
<td><strong>å®Ÿé¨“ç®¡ç†</strong></td>
<td>å®Ÿé¨“ã®è¿½è·¡ã¨æ¯”è¼ƒ</td>
<td>å®Ÿé¨“æ¯”è¼ƒ</td>
</tr>
</tbody>
</table>

<h3>DVCã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã¨åˆæœŸåŒ–</h3>

<pre><code class="language-bash"># DVCã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
# pip install dvc

# Gitãƒªãƒã‚¸ãƒˆãƒªã®åˆæœŸåŒ–ï¼ˆã¾ã ã®å ´åˆï¼‰
# git init

# DVCã®åˆæœŸåŒ–
# dvc init

# .dvc/config ãƒ•ã‚¡ã‚¤ãƒ«ãŒä½œæˆã•ã‚Œã‚‹
# git add .dvc .dvcignore
# git commit -m "Initialize DVC"
</code></pre>

<h3>ãƒ‡ãƒ¼ã‚¿ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†</h3>

<pre><code class="language-python"># Pythonã§ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
import pandas as pd
import numpy as np

# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆ
np.random.seed(42)
data = pd.DataFrame({
    'feature1': np.random.randn(1000),
    'feature2': np.random.randn(1000),
    'feature3': np.random.randn(1000),
    'target': np.random.randint(0, 2, 1000)
})

# ãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜
data.to_csv('data/raw_data.csv', index=False)
print("ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¾ã—ãŸ: data/raw_data.csv")
</code></pre>

<pre><code class="language-bash"># DVCã§ãƒ‡ãƒ¼ã‚¿ã‚’è¿½è·¡
# dvc add data/raw_data.csv

# ã“ã‚Œã«ã‚ˆã‚Šä»¥ä¸‹ãŒä½œæˆã•ã‚Œã‚‹:
# - data/raw_data.csv.dvc (ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«)
# - data/.gitignore (å®Ÿãƒ‡ãƒ¼ã‚¿ã‚’é™¤å¤–)

# ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’Gitã«ã‚³ãƒŸãƒƒãƒˆ
# git add data/raw_data.csv.dvc data/.gitignore
# git commit -m "Add raw data"

# ãƒªãƒ¢ãƒ¼ãƒˆã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã®è¨­å®šï¼ˆä¾‹: ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼‰
# dvc remote add -d local_storage /tmp/dvc-storage
# git add .dvc/config
# git commit -m "Configure DVC remote storage"

# ãƒ‡ãƒ¼ã‚¿ã‚’ãƒªãƒ¢ãƒ¼ãƒˆã«ãƒ—ãƒƒã‚·ãƒ¥
# dvc push
</code></pre>

<h3>DVCãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®å®šç¾©</h3>

<pre><code class="language-python"># prepare.py - ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
import pandas as pd
from sklearn.model_selection import train_test_split
import sys

def prepare_data(input_file, train_file, test_file):
    # ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
    data = pd.read_csv(input_file)

    # è¨“ç·´ãƒ»ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®åˆ†å‰²
    train, test = train_test_split(data, test_size=0.2, random_state=42)

    # ä¿å­˜
    train.to_csv(train_file, index=False)
    test.to_csv(test_file, index=False)

    print(f"è¨“ç·´ãƒ‡ãƒ¼ã‚¿: {len(train)}è¡Œ")
    print(f"ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {len(test)}è¡Œ")

if __name__ == "__main__":
    prepare_data(
        input_file="data/raw_data.csv",
        train_file="data/train.csv",
        test_file="data/test.csv"
    )
</code></pre>

<pre><code class="language-python"># train.py - ãƒ¢ãƒ‡ãƒ«è¨“ç·´ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
import joblib
import json

def train_model(train_file, model_file, metrics_file):
    # ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
    train = pd.read_csv(train_file)
    X_train = train.drop('target', axis=1)
    y_train = train['target']

    # ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´
    model = RandomForestClassifier(n_estimators=100, random_state=42)
    model.fit(X_train, y_train)

    # ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜
    joblib.dump(model, model_file)

    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®ä¿å­˜
    train_accuracy = model.score(X_train, y_train)
    metrics = {"train_accuracy": train_accuracy}

    with open(metrics_file, 'w') as f:
        json.dump(metrics, f)

    print(f"è¨“ç·´ç²¾åº¦: {train_accuracy:.3f}")

if __name__ == "__main__":
    train_model(
        train_file="data/train.csv",
        model_file="models/model.pkl",
        metrics_file="metrics/train_metrics.json"
    )
</code></pre>

<pre><code class="language-python"># evaluate.py - ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
import pandas as pd
import joblib
import json
from sklearn.metrics import accuracy_score, precision_score, recall_score

def evaluate_model(test_file, model_file, metrics_file):
    # ãƒ‡ãƒ¼ã‚¿ã¨ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿
    test = pd.read_csv(test_file)
    X_test = test.drop('target', axis=1)
    y_test = test['target']

    model = joblib.load(model_file)

    # äºˆæ¸¬ã¨è©•ä¾¡
    y_pred = model.predict(X_test)

    metrics = {
        "accuracy": accuracy_score(y_test, y_pred),
        "precision": precision_score(y_test, y_pred),
        "recall": recall_score(y_test, y_pred)
    }

    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®ä¿å­˜
    with open(metrics_file, 'w') as f:
        json.dump(metrics, f)

    print(f"ãƒ†ã‚¹ãƒˆç²¾åº¦: {metrics['accuracy']:.3f}")
    print(f"é©åˆç‡: {metrics['precision']:.3f}")
    print(f"å†ç¾ç‡: {metrics['recall']:.3f}")

if __name__ == "__main__":
    evaluate_model(
        test_file="data/test.csv",
        model_file="models/model.pkl",
        metrics_file="metrics/test_metrics.json"
    )
</code></pre>

<h3>dvc.yaml: ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®å®šç¾©</h3>

<pre><code class="language-yaml"># dvc.yaml
stages:
  prepare:
    cmd: python prepare.py
    deps:
      - data/raw_data.csv
      - prepare.py
    outs:
      - data/train.csv
      - data/test.csv

  train:
    cmd: python train.py
    deps:
      - data/train.csv
      - train.py
    outs:
      - models/model.pkl
    metrics:
      - metrics/train_metrics.json:
          cache: false

  evaluate:
    cmd: python evaluate.py
    deps:
      - data/test.csv
      - models/model.pkl
      - evaluate.py
    metrics:
      - metrics/test_metrics.json:
          cache: false
</code></pre>

<pre><code class="language-bash"># ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®å®Ÿè¡Œ
# dvc repro

# å‡ºåŠ›:
# Running stage 'prepare':
# > python prepare.py
# è¨“ç·´ãƒ‡ãƒ¼ã‚¿: 800è¡Œ
# ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: 200è¡Œ
#
# Running stage 'train':
# > python train.py
# è¨“ç·´ç²¾åº¦: 1.000
#
# Running stage 'evaluate':
# > python evaluate.py
# ãƒ†ã‚¹ãƒˆç²¾åº¦: 0.895
# é©åˆç‡: 0.891
# å†ç¾ç‡: 0.902

# ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®è¡¨ç¤º
# dvc metrics show

# ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®å¯è¦–åŒ–
# dvc dag
</code></pre>

<h3>DVC Experiments: å®Ÿé¨“ã®è¿½è·¡</h3>

<pre><code class="language-bash"># ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆ
# params.yaml
"""
model:
  n_estimators: 100
  max_depth: 10
  random_state: 42

data:
  test_size: 0.2
  random_state: 42
"""

# å®Ÿé¨“ã®å®Ÿè¡Œ
# dvc exp run

# è¤‡æ•°ã®å®Ÿé¨“ã‚’ä¸¦åˆ—å®Ÿè¡Œ
# dvc exp run --set-param model.n_estimators=150
# dvc exp run --set-param model.n_estimators=200
# dvc exp run --set-param model.max_depth=15

# å®Ÿé¨“çµæœã®è¡¨ç¤º
# dvc exp show

# å‡ºåŠ›:
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”“
# â”ƒ Experiment  â”ƒ n_estimatorsâ”ƒ max_depthâ”ƒ accuracy  â”ƒ
# â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”©
# â”‚ workspace   â”‚ 100         â”‚ 10       â”‚ 0.895     â”‚
# â”‚ exp-1       â”‚ 150         â”‚ 10       â”‚ 0.900     â”‚
# â”‚ exp-2       â”‚ 200         â”‚ 10       â”‚ 0.905     â”‚
# â”‚ exp-3       â”‚ 100         â”‚ 15       â”‚ 0.898     â”‚
# â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

# æœ€è‰¯ã®å®Ÿé¨“ã‚’é©ç”¨
# dvc exp apply exp-2
# git add .
# git commit -m "Apply best experiment: n_estimators=200"
</code></pre>

<h3>DVCã¨Gitã®çµ±åˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼</h3>

<pre><code class="language-python"># å®Œå…¨ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ä¾‹
import subprocess
import os

def dvc_workflow_example():
    """DVCã¨Gitã‚’ä½¿ã£ãŸå®Œå…¨ãªMLãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼"""

    # 1. æ–°ã—ã„ãƒ–ãƒ©ãƒ³ãƒã‚’ä½œæˆ
    subprocess.run(["git", "checkout", "-b", "experiment/new-features"])

    # 2. æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
    print("æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆä¸­...")
    import pandas as pd
    import numpy as np

    new_data = pd.DataFrame({
        'feature1': np.random.randn(1500),
        'feature2': np.random.randn(1500),
        'feature3': np.random.randn(1500),
        'feature4': np.random.randn(1500),  # æ–°ç‰¹å¾´é‡
        'target': np.random.randint(0, 2, 1500)
    })
    new_data.to_csv('data/raw_data_v2.csv', index=False)

    # 3. DVCã§æ–°ãƒ‡ãƒ¼ã‚¿ã‚’è¿½è·¡
    subprocess.run(["dvc", "add", "data/raw_data_v2.csv"])

    # 4. å¤‰æ›´ã‚’ã‚³ãƒŸãƒƒãƒˆ
    subprocess.run(["git", "add", "data/raw_data_v2.csv.dvc", "data/.gitignore"])
    subprocess.run(["git", "commit", "-m", "Add new dataset with feature4"])

    # 5. ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å®Ÿè¡Œ
    subprocess.run(["dvc", "repro"])

    # 6. çµæœã‚’ç¢ºèª
    subprocess.run(["dvc", "metrics", "show"])

    # 7. å¤‰æ›´ã‚’ãƒ—ãƒƒã‚·ãƒ¥
    subprocess.run(["git", "push", "origin", "experiment/new-features"])
    subprocess.run(["dvc", "push"])

    print("ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Œäº†")

# æ³¨æ„: å®Ÿéš›ã®å®Ÿè¡Œã«ã¯é©åˆ‡ãªGit/DVCã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ãŒå¿…è¦
print("DVCãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ä¾‹ï¼ˆã‚³ãƒãƒ³ãƒ‰è§£èª¬ï¼‰")
</code></pre>

<hr>

<h2>2.5 ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹</h2>

<h3>1. ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿è¨˜éŒ²ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹</h3>

<h4>è¨˜éŒ²ã™ã¹ãæƒ…å ±</h4>

<table>
<thead>
<tr>
<th>ã‚«ãƒ†ã‚´ãƒª</th>
<th>é …ç›®</th>
<th>ç†ç”±</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>å®Ÿé¨“æƒ…å ±</strong></td>
<td>å®Ÿé¨“åã€æ—¥æ™‚ã€å®Ÿè¡Œè€…</td>
<td>å®Ÿé¨“ã®è­˜åˆ¥ã¨è¿½è·¡</td>
</tr>
<tr>
<td><strong>ç’°å¢ƒæƒ…å ±</strong></td>
<td>Pythonç‰ˆã€ãƒ©ã‚¤ãƒ–ãƒ©ãƒªç‰ˆã€OS</td>
<td>å†ç¾æ€§ã®ç¢ºä¿</td>
</tr>
<tr>
<td><strong>ãƒ‡ãƒ¼ã‚¿æƒ…å ±</strong></td>
<td>ãƒ‡ãƒ¼ã‚¿ç‰ˆã€ã‚µãƒ³ãƒ—ãƒ«æ•°ã€åˆ†å¸ƒ</td>
<td>ãƒ‡ãƒ¼ã‚¿ãƒ‰ãƒªãƒ•ãƒˆæ¤œå‡º</td>
</tr>
<tr>
<td><strong>ãƒ¢ãƒ‡ãƒ«æƒ…å ±</strong></td>
<td>ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿</td>
<td>ãƒ¢ãƒ‡ãƒ«ã®å†æ§‹ç¯‰</td>
</tr>
<tr>
<td><strong>è©•ä¾¡æƒ…å ±</strong></td>
<td>ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã€æ··åŒè¡Œåˆ—</td>
<td>æ€§èƒ½ã®æ¯”è¼ƒ</td>
</tr>
</tbody>
</table>

<pre><code class="language-python">import mlflow
import platform
import sys
from datetime import datetime

def log_comprehensive_metadata(model, X_train, y_train, X_test, y_test):
    """åŒ…æ‹¬çš„ãªãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®è¨˜éŒ²"""

    with mlflow.start_run(run_name=f"exp_{datetime.now().strftime('%Y%m%d_%H%M%S')}"):
        # 1. ç’°å¢ƒæƒ…å ±
        mlflow.log_param("python_version", sys.version)
        mlflow.log_param("os", platform.system())
        mlflow.log_param("os_version", platform.version())

        # 2. ãƒ‡ãƒ¼ã‚¿æƒ…å ±
        mlflow.log_param("train_samples", len(X_train))
        mlflow.log_param("test_samples", len(X_test))
        mlflow.log_param("n_features", X_train.shape[1])
        mlflow.log_param("class_distribution", dict(zip(*np.unique(y_train, return_counts=True))))

        # 3. ãƒ¢ãƒ‡ãƒ«æƒ…å ±
        mlflow.log_param("model_type", type(model).__name__)
        mlflow.log_params(model.get_params())

        # 4. è¨“ç·´
        model.fit(X_train, y_train)

        # 5. è©•ä¾¡ãƒ¡ãƒˆãƒªã‚¯ã‚¹
        from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

        y_pred_train = model.predict(X_train)
        y_pred_test = model.predict(X_test)

        mlflow.log_metric("train_accuracy", accuracy_score(y_train, y_pred_train))
        mlflow.log_metric("test_accuracy", accuracy_score(y_test, y_pred_test))
        mlflow.log_metric("test_precision", precision_score(y_test, y_pred_test))
        mlflow.log_metric("test_recall", recall_score(y_test, y_pred_test))
        mlflow.log_metric("test_f1", f1_score(y_test, y_pred_test))

        # 6. å®Ÿé¨“ãƒ¡ãƒ¢
        mlflow.set_tag("experiment_description", "Comprehensive metadata logging example")
        mlflow.set_tag("data_version", "v1.0")
        mlflow.set_tag("experiment_type", "baseline")

        # 7. ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜
        mlflow.sklearn.log_model(model, "model")

        print("åŒ…æ‹¬çš„ãªãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’è¨˜éŒ²ã—ã¾ã—ãŸ")

# ä½¿ç”¨ä¾‹
from sklearn.ensemble import RandomForestClassifier
model = RandomForestClassifier(n_estimators=100, random_state=42)
log_comprehensive_metadata(model, X_train, y_train, X_test, y_test)
</code></pre>

<h3>2. ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç®¡ç†</h3>

<pre><code class="language-python">import yaml
from dataclasses import dataclass, asdict
from typing import Optional

@dataclass
class ModelConfig:
    """ãƒ¢ãƒ‡ãƒ«è¨­å®šã®æ§‹é€ åŒ–å®šç¾©"""
    n_estimators: int = 100
    max_depth: Optional[int] = 10
    min_samples_split: int = 2
    min_samples_leaf: int = 1
    random_state: int = 42

    def save(self, filepath: str):
        """è¨­å®šã‚’YAMLãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        with open(filepath, 'w') as f:
            yaml.dump(asdict(self), f)

    @classmethod
    def load(cls, filepath: str):
        """YAMLãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰è¨­å®šã‚’èª­ã¿è¾¼ã¿"""
        with open(filepath, 'r') as f:
            config_dict = yaml.safe_load(f)
        return cls(**config_dict)

# è¨­å®šã®ä¿å­˜
config = ModelConfig(n_estimators=150, max_depth=15)
config.save("configs/model_config.yaml")

# è¨­å®šã®èª­ã¿è¾¼ã¿
loaded_config = ModelConfig.load("configs/model_config.yaml")

# ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´
from sklearn.ensemble import RandomForestClassifier
model = RandomForestClassifier(**asdict(loaded_config))
model.fit(X_train, y_train)

print(f"è¨­å®šã‚’ä½¿ç”¨ã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´: {asdict(loaded_config)}")
</code></pre>

<h3>3. ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆç®¡ç†</h3>

<pre><code class="language-python">import mlflow
import joblib
import json
from pathlib import Path

def save_experiment_artifacts(
    model,
    metrics,
    config,
    feature_names,
    experiment_name="my_experiment"
):
    """å®Ÿé¨“ã®ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆã‚’ä½“ç³»çš„ã«ä¿å­˜"""

    mlflow.set_experiment(experiment_name)

    with mlflow.start_run():
        # 1. ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜
        mlflow.sklearn.log_model(model, "model")

        # 2. ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®ä¿å­˜
        for metric_name, metric_value in metrics.items():
            mlflow.log_metric(metric_name, metric_value)

        # 3. è¨­å®šã®ä¿å­˜
        for param_name, param_value in config.items():
            mlflow.log_param(param_name, param_value)

        # 4. ç‰¹å¾´é‡æƒ…å ±ã®ä¿å­˜
        feature_info = {
            "feature_names": feature_names,
            "n_features": len(feature_names)
        }

        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã—ã¦MLflowã«ãƒ­ã‚°
        temp_dir = Path("temp_artifacts")
        temp_dir.mkdir(exist_ok=True)

        feature_path = temp_dir / "feature_info.json"
        with open(feature_path, 'w') as f:
            json.dump(feature_info, f, indent=2)
        mlflow.log_artifact(str(feature_path))

        # 5. ç‰¹å¾´é‡é‡è¦åº¦ã®ä¿å­˜ï¼ˆå¯èƒ½ãªå ´åˆï¼‰
        if hasattr(model, 'feature_importances_'):
            importance_df = {
                name: float(imp)
                for name, imp in zip(feature_names, model.feature_importances_)
            }
            importance_path = temp_dir / "feature_importance.json"
            with open(importance_path, 'w') as f:
                json.dump(importance_df, f, indent=2)
            mlflow.log_artifact(str(importance_path))

        # 6. äºˆæ¸¬ä¾‹ã®ä¿å­˜
        sample_predictions = {
            "sample_input": X_test[:5].tolist(),
            "predictions": model.predict(X_test[:5]).tolist()
        }
        pred_path = temp_dir / "sample_predictions.json"
        with open(pred_path, 'w') as f:
            json.dump(sample_predictions, f, indent=2)
        mlflow.log_artifact(str(pred_path))

        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã®å‰Šé™¤
        import shutil
        shutil.rmtree(temp_dir)

        print("å…¨ã¦ã®ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆã‚’ä¿å­˜ã—ã¾ã—ãŸ")

# ä½¿ç”¨ä¾‹
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

metrics = {
    "accuracy": accuracy_score(y_test, model.predict(X_test)),
    "f1_score": f1_score(y_test, model.predict(X_test))
}

config = {
    "n_estimators": 100,
    "max_depth": 10,
    "random_state": 42
}

feature_names = [f"feature_{i}" for i in range(X_train.shape[1])]

save_experiment_artifacts(model, metrics, config, feature_names)
</code></pre>

<h3>4. å®Ÿé¨“ã®çµ„ç¹”åŒ–</h3>

<pre><code class="language-python">from enum import Enum
import mlflow
from datetime import datetime

class ExperimentType(Enum):
    """å®Ÿé¨“ã‚¿ã‚¤ãƒ—ã®å®šç¾©"""
    BASELINE = "baseline"
    FEATURE_ENGINEERING = "feature_engineering"
    HYPERPARAMETER_TUNING = "hyperparameter_tuning"
    MODEL_SELECTION = "model_selection"
    PRODUCTION = "production"

class ExperimentManager:
    """å®Ÿé¨“ã®çµ„ç¹”çš„ãªç®¡ç†"""

    def __init__(self, project_name: str):
        self.project_name = project_name

    def create_experiment_name(
        self,
        exp_type: ExperimentType,
        model_name: str,
        version: str = "v1"
    ) -> str:
        """éšå±¤çš„ãªå®Ÿé¨“åã‚’ç”Ÿæˆ"""
        return f"{self.project_name}/{exp_type.value}/{model_name}/{version}"

    def run_experiment(
        self,
        exp_type: ExperimentType,
        model_name: str,
        model,
        train_fn,
        evaluate_fn,
        version: str = "v1",
        description: str = ""
    ):
        """å®Ÿé¨“ã®å®Ÿè¡Œã¨è¨˜éŒ²"""

        # å®Ÿé¨“åã®ç”Ÿæˆ
        exp_name = self.create_experiment_name(exp_type, model_name, version)
        mlflow.set_experiment(exp_name)

        # å®Ÿè¡Œåã®ç”Ÿæˆï¼ˆã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ãï¼‰
        run_name = f"{model_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"

        with mlflow.start_run(run_name=run_name):
            # ã‚¿ã‚°ã®è¨­å®š
            mlflow.set_tag("experiment_type", exp_type.value)
            mlflow.set_tag("model_name", model_name)
            mlflow.set_tag("version", version)
            mlflow.set_tag("description", description)

            # è¨“ç·´
            train_metrics = train_fn(model)

            # è©•ä¾¡
            test_metrics = evaluate_fn(model)

            # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®è¨˜éŒ²
            for metric_name, metric_value in {**train_metrics, **test_metrics}.items():
                mlflow.log_metric(metric_name, metric_value)

            # ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜
            mlflow.sklearn.log_model(model, "model")

            print(f"å®Ÿé¨“å®Œäº†: {exp_name}/{run_name}")
            return test_metrics

# ä½¿ç”¨ä¾‹
manager = ExperimentManager(project_name="customer_churn")

def train_fn(model):
    model.fit(X_train, y_train)
    train_acc = model.score(X_train, y_train)
    return {"train_accuracy": train_acc}

def evaluate_fn(model):
    test_acc = model.score(X_test, y_test)
    test_f1 = f1_score(y_test, model.predict(X_test))
    return {"test_accuracy": test_acc, "test_f1": test_f1}

# ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«ã®å®Ÿé¨“
from sklearn.ensemble import RandomForestClassifier
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)

results = manager.run_experiment(
    exp_type=ExperimentType.BASELINE,
    model_name="random_forest",
    model=rf_model,
    train_fn=train_fn,
    evaluate_fn=evaluate_fn,
    version="v1",
    description="Initial baseline model with default parameters"
)

print(f"çµæœ: {results}")
</code></pre>

<hr>

<h2>2.6 æœ¬ç« ã®ã¾ã¨ã‚</h2>

<h3>å­¦ã‚“ã ã“ã¨</h3>

<ol>
<li><p><strong>å®Ÿé¨“ç®¡ç†ã®é‡è¦æ€§</strong></p>
<ul>
<li>å†ç¾æ€§ã®ç¢ºä¿ãŒæ©Ÿæ¢°å­¦ç¿’ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®åŸºç›¤</li>
<li>ä½“ç³»çš„ãªå®Ÿé¨“ç®¡ç†ã§åŠ¹ç‡çš„ãªãƒ¢ãƒ‡ãƒ«é–‹ç™º</li>
<li>ãƒ‡ãƒ¼ã‚¿ã¨ãƒ¢ãƒ‡ãƒ«ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ã®å¿…è¦æ€§</li>
</ul></li>

<li><p><strong>MLflow</strong></p>
<ul>
<li>MLflow Tracking: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®è¨˜éŒ²</li>
<li>MLflow Models: ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãƒ³ã‚°ã¨ãƒ‡ãƒ—ãƒ­ã‚¤</li>
<li>MLflow Projects: å†ç¾å¯èƒ½ãªå®Ÿé¨“ç’°å¢ƒ</li>
<li>Autologæ©Ÿèƒ½ã«ã‚ˆã‚‹è‡ªå‹•ãƒ­ã‚®ãƒ³ã‚°</li>
</ul></li>

<li><p><strong>Weights & Biases</strong></p>
<ul>
<li>ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãªå®Ÿé¨“å¯è¦–åŒ–</li>
<li>ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è‡ªå‹•æœ€é©åŒ–ï¼ˆSweepsï¼‰</li>
<li>ãƒãƒ¼ãƒ å”æ¥­ã¨ãƒ¬ãƒãƒ¼ãƒˆå…±æœ‰</li>
<li>ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆç®¡ç†ã¨ãƒãƒ¼ã‚¸ãƒ§ãƒ‹ãƒ³ã‚°</li>
</ul></li>

<li><p><strong>DVC</strong></p>
<ul>
<li>ãƒ‡ãƒ¼ã‚¿ã¨ãƒ¢ãƒ‡ãƒ«ã®Gitãƒ©ã‚¤ã‚¯ãªç®¡ç†</li>
<li>å†ç¾å¯èƒ½ãªMLãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®šç¾©</li>
<li>ãƒªãƒ¢ãƒ¼ãƒˆã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã¨ã®é€£æº</li>
<li>å®Ÿé¨“ã®è¿½è·¡ã¨æ¯”è¼ƒ</li>
</ul></li>

<li><p><strong>ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹</strong></p>
<ul>
<li>åŒ…æ‹¬çš„ãªãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®è¨˜éŒ²</li>
<li>æ§‹é€ åŒ–ã•ã‚ŒãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç®¡ç†</li>
<li>ä½“ç³»çš„ãªã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆä¿å­˜</li>
<li>éšå±¤çš„ãªå®Ÿé¨“ã®çµ„ç¹”åŒ–</li>
</ul></li>
</ol>

<h3>ãƒ„ãƒ¼ãƒ«ã®ä½¿ã„åˆ†ã‘ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³</h3>

<table>
<thead>
<tr>
<th>ãƒ„ãƒ¼ãƒ«</th>
<th>å¼·ã¿</th>
<th>æ¨å¥¨ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>MLflow</strong></td>
<td>ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã€æŸ”è»Ÿæ€§é«˜</td>
<td>ã‚ªãƒ³ãƒ—ãƒ¬ãƒŸã‚¹ç’°å¢ƒã€è‡ªç”±åº¦é‡è¦–</td>
</tr>
<tr>
<td><strong>W&B</strong></td>
<td>é«˜åº¦ãªå¯è¦–åŒ–ã€ãƒãƒ¼ãƒ å”æ¥­</td>
<td>ã‚¯ãƒ©ã‚¦ãƒ‰ç’°å¢ƒã€ãƒãƒ¼ãƒ é–‹ç™º</td>
</tr>
<tr>
<td><strong>DVC</strong></td>
<td>Gitã¨ã®è¦ªå’Œæ€§ã€ãƒ‡ãƒ¼ã‚¿ç®¡ç†</td>
<td>å¤§å®¹é‡ãƒ‡ãƒ¼ã‚¿ã€ãƒãƒ¼ã‚¸ãƒ§ãƒ³é‡è¦–</td>
</tr>
</tbody>
</table>

<h3>æ¬¡ã®ç« ã¸</h3>

<p>ç¬¬3ç« ã§ã¯ã€<strong>ç¶™ç¶šçš„ã‚¤ãƒ³ãƒ†ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³/ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆï¼ˆCI/CDï¼‰</strong>ã‚’å­¦ã³ã¾ã™ï¼š</p>
<ul>
<li>MLOpsã«ãŠã‘ã‚‹CI/CDãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³</li>
<li>è‡ªå‹•ãƒ†ã‚¹ãƒˆã¨ãƒ¢ãƒ‡ãƒ«æ¤œè¨¼</li>
<li>ãƒ¢ãƒ‡ãƒ«ã®ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆæˆ¦ç•¥</li>
<li>ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ã¨ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ«ãƒ¼ãƒ—</li>
</ul>

<hr>

<h2>æ¼”ç¿’å•é¡Œ</h2>

<h3>å•é¡Œ1ï¼ˆé›£æ˜“åº¦ï¼šeasyï¼‰</h3>
<p>å®Ÿé¨“ç®¡ç†ã«ãŠã‘ã‚‹ã€Œå†ç¾æ€§ã€ãŒé‡è¦ãªç†ç”±ã‚’3ã¤æŒ™ã’ã¦èª¬æ˜ã—ã¦ãã ã•ã„ã€‚</p>

<details>
<summary>è§£ç­”ä¾‹</summary>

<p><strong>è§£ç­”</strong>ï¼š</p>

<ol>
<li><p><strong>çµæœã®æ¤œè¨¼</strong></p>
<ul>
<li>åŒã˜æ¡ä»¶ã§å®Ÿé¨“ã‚’å†å®Ÿè¡Œã—ã€çµæœã®å¦¥å½“æ€§ã‚’ç¢ºèªã§ãã‚‹</li>
<li>äºˆæœŸã—ãªã„çµæœãŒå¶ç„¶ã‹ã€ä½“ç³»çš„ãªå•é¡Œã‹ã‚’åˆ¤æ–­å¯èƒ½</li>
</ul></li>

<li><p><strong>çŸ¥è¦‹ã®å…±æœ‰</strong></p>
<ul>
<li>ãƒãƒ¼ãƒ ãƒ¡ãƒ³ãƒãƒ¼ãŒåŒã˜å®Ÿé¨“ã‚’å†ç¾ã—ã¦ç†è§£ã‚’æ·±ã‚ã‚‰ã‚Œã‚‹</li>
<li>ç ”ç©¶æˆæœã®é€æ˜æ€§ã¨ä¿¡é ¼æ€§ãŒå‘ä¸Š</li>
</ul></li>

<li><p><strong>ãƒ‡ãƒãƒƒã‚°ã¨æ”¹å–„</strong></p>
<ul>
<li>å•é¡ŒãŒç™ºç”Ÿã—ãŸéš›ã«ã€ç‰¹å®šã®å®Ÿé¨“çŠ¶æ…‹ã‚’å†ç¾ã—ã¦ãƒ‡ãƒãƒƒã‚°å¯èƒ½</li>
<li>éå»ã®æˆåŠŸã—ãŸå®Ÿé¨“ã‚’åŸºã«ã€æ®µéšçš„ãªæ”¹å–„ãŒã§ãã‚‹</li>
</ul></li>
</ol>

</details>

<h3>å•é¡Œ2ï¼ˆé›£æ˜“åº¦ï¼šmediumï¼‰</h3>
<p>MLflowã‚’ä½¿ã£ã¦ã€ä»¥ä¸‹ã®è¦ä»¶ã‚’æº€ãŸã™å®Ÿé¨“ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ã‚’å®Ÿè£…ã—ã¦ãã ã•ã„ï¼š</p>
<ul>
<li>3ã¤ã®ç•°ãªã‚‹ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®šã§ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´</li>
<li>å„å®Ÿé¨“ã§è¨“ç·´ç²¾åº¦ã¨ãƒ†ã‚¹ãƒˆç²¾åº¦ã‚’è¨˜éŒ²</li>
<li>æœ€ã‚‚é«˜ã„ãƒ†ã‚¹ãƒˆç²¾åº¦ã‚’é”æˆã—ãŸå®Ÿé¨“ã‚’ç‰¹å®š</li>
</ul>

<details>
<summary>è§£ç­”ä¾‹</summary>

<pre><code class="language-python">import mlflow
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.datasets import make_classification
from sklearn.metrics import accuracy_score

# ãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆ
X, y = make_classification(n_samples=1000, n_features=20, random_state=42)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# å®Ÿé¨“è¨­å®š
mlflow.set_experiment("hyperparameter_comparison")

# ç•°ãªã‚‹ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š
configs = [
    {"n_estimators": 50, "max_depth": 5},
    {"n_estimators": 100, "max_depth": 10},
    {"n_estimators": 200, "max_depth": 20}
]

results = []

# å„è¨­å®šã§å®Ÿé¨“ã‚’å®Ÿè¡Œ
for i, config in enumerate(configs):
    with mlflow.start_run(run_name=f"experiment_{i+1}"):
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®è¨˜éŒ²
        mlflow.log_params(config)

        # ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´
        model = RandomForestClassifier(**config, random_state=42)
        model.fit(X_train, y_train)

        # ç²¾åº¦ã®è¨ˆç®—
        train_acc = accuracy_score(y_train, model.predict(X_train))
        test_acc = accuracy_score(y_test, model.predict(X_test))

        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®è¨˜éŒ²
        mlflow.log_metric("train_accuracy", train_acc)
        mlflow.log_metric("test_accuracy", test_acc)

        # çµæœã®ä¿å­˜
        results.append({
            "config": config,
            "train_acc": train_acc,
            "test_acc": test_acc,
            "run_id": mlflow.active_run().info.run_id
        })

        print(f"å®Ÿé¨“ {i+1}: Train={train_acc:.3f}, Test={test_acc:.3f}")

# æœ€è‰¯ã®å®Ÿé¨“ã‚’ç‰¹å®š
best_result = max(results, key=lambda x: x['test_acc'])

print("\n=== æœ€è‰¯ã®å®Ÿé¨“ ===")
print(f"è¨­å®š: {best_result['config']}")
print(f"ãƒ†ã‚¹ãƒˆç²¾åº¦: {best_result['test_acc']:.3f}")
print(f"Run ID: {best_result['run_id']}")
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>å®Ÿé¨“ 1: Train=0.862, Test=0.855
å®Ÿé¨“ 2: Train=0.895, Test=0.895
å®Ÿé¨“ 3: Train=0.987, Test=0.890

=== æœ€è‰¯ã®å®Ÿé¨“ ===
è¨­å®š: {'n_estimators': 100, 'max_depth': 10}
ãƒ†ã‚¹ãƒˆç²¾åº¦: 0.895
Run ID: xxxxxxxxxxxxx
</code></pre>

</details>

<h3>å•é¡Œ3ï¼ˆé›£æ˜“åº¦ï¼šmediumï¼‰</h3>
<p>DVCã‚’ä½¿ç”¨ã™ã‚‹ä¸»ãªåˆ©ç‚¹ã‚’ã€Gitã ã‘ã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã¨æ¯”è¼ƒã—ã¦èª¬æ˜ã—ã¦ãã ã•ã„ã€‚</p>

<details>
<summary>è§£ç­”ä¾‹</summary>

<p><strong>è§£ç­”</strong>ï¼š</p>

<p><strong>DVCã®ä¸»ãªåˆ©ç‚¹</strong>ï¼š</p>

<ol>
<li><p><strong>å¤§å®¹é‡ãƒ•ã‚¡ã‚¤ãƒ«ã®åŠ¹ç‡çš„ãªç®¡ç†</strong></p>
<ul>
<li>Git: å¤§å®¹é‡ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€ãƒ¢ãƒ‡ãƒ«ï¼‰ã§ãƒªãƒã‚¸ãƒˆãƒªãŒè‚¥å¤§åŒ–</li>
<li>DVC: å®Ÿãƒ•ã‚¡ã‚¤ãƒ«ã¯ãƒªãƒ¢ãƒ¼ãƒˆã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã«ä¿å­˜ã€Gitã«ã¯ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®ã¿</li>
</ul></li>

<li><p><strong>ãƒ‡ãƒ¼ã‚¿ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†</strong></p>
<ul>
<li>Git: ãƒã‚¤ãƒŠãƒªãƒ•ã‚¡ã‚¤ãƒ«ã®å·®åˆ†ç®¡ç†ãŒéåŠ¹ç‡</li>
<li>DVC: ãƒ‡ãƒ¼ã‚¿ã®å¤‰æ›´å±¥æ­´ã‚’åŠ¹ç‡çš„ã«è¿½è·¡ã€ä»»æ„ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã«å¾©å…ƒå¯èƒ½</li>
</ul></li>

<li><p><strong>å†ç¾å¯èƒ½ãªãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³</strong></p>
<ul>
<li>Git: ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ã®ã¿</li>
<li>DVC: ãƒ‡ãƒ¼ã‚¿ã€ã‚³ãƒ¼ãƒ‰ã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å«ã‚€å®Œå…¨ãªãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å®šç¾©ãƒ»å†ç¾</li>
</ul></li>

<li><p><strong>ãƒãƒ¼ãƒ å”æ¥­ã®å®¹æ˜“æ€§</strong></p>
<ul>
<li>Git: å¤§å®¹é‡ãƒ•ã‚¡ã‚¤ãƒ«ã®å…±æœ‰ãŒå›°é›£</li>
<li>DVC: ãƒªãƒ¢ãƒ¼ãƒˆã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸çµŒç”±ã§åŠ¹ç‡çš„ã«ãƒ‡ãƒ¼ã‚¿å…±æœ‰</li>
</ul></li>
</ol>

<p><strong>æ¯”è¼ƒè¡¨</strong>ï¼š</p>

<table>
<thead>
<tr>
<th>è¦³ç‚¹</th>
<th>Git ã®ã¿</th>
<th>DVC + Git</th>
</tr>
</thead>
<tbody>
<tr>
<td>ã‚³ãƒ¼ãƒ‰ç®¡ç†</td>
<td>â— å„ªç§€</td>
<td>â— å„ªç§€</td>
</tr>
<tr>
<td>ãƒ‡ãƒ¼ã‚¿ç®¡ç†</td>
<td>â–³ éåŠ¹ç‡</td>
<td>â— æœ€é©åŒ–</td>
</tr>
<tr>
<td>ãƒ¢ãƒ‡ãƒ«ç®¡ç†</td>
<td>â–³ å›°é›£</td>
<td>â— ä½“ç³»çš„</td>
</tr>
<tr>
<td>ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³</td>
<td>Ã— æœªã‚µãƒãƒ¼ãƒˆ</td>
<td>â— å®Œå…¨ã‚µãƒãƒ¼ãƒˆ</td>
</tr>
<tr>
<td>å†ç¾æ€§</td>
<td>â–³ éƒ¨åˆ†çš„</td>
<td>â— å®Œå…¨</td>
</tr>
</tbody>
</table>

</details>

<h3>å•é¡Œ4ï¼ˆé›£æ˜“åº¦ï¼šhardï¼‰</h3>
<p>åŒ…æ‹¬çš„ãªå®Ÿé¨“ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã‚’è¨­è¨ˆã—ã¦ãã ã•ã„ã€‚ä»¥ä¸‹ã®è¦ç´ ã‚’å«ã‚ã‚‹ã“ã¨ï¼š</p>
<ul>
<li>å®Ÿé¨“ã®è‡ªå‹•ãƒ­ã‚®ãƒ³ã‚°</li>
<li>ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æ§‹é€ åŒ–ç®¡ç†</li>
<li>å®Ÿé¨“çµæœã®æ¯”è¼ƒæ©Ÿèƒ½</li>
<li>ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã®è‡ªå‹•é¸æŠ</li>
</ul>

<details>
<summary>è§£ç­”ä¾‹</summary>

<pre><code class="language-python">import mlflow
import yaml
from dataclasses import dataclass, asdict
from typing import Dict, Any, List, Optional
from sklearn.base import BaseEstimator
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score
import pandas as pd

@dataclass
class ExperimentConfig:
    """å®Ÿé¨“è¨­å®šã®æ§‹é€ åŒ–å®šç¾©"""
    experiment_name: str
    model_params: Dict[str, Any]
    data_params: Dict[str, Any]
    description: str = ""
    tags: Dict[str, str] = None

class ComprehensiveExperimentManager:
    """åŒ…æ‹¬çš„ãªå®Ÿé¨“ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ """

    def __init__(self, tracking_uri: str = None):
        if tracking_uri:
            mlflow.set_tracking_uri(tracking_uri)
        self.results = []

    def run_experiment(
        self,
        config: ExperimentConfig,
        model: BaseEstimator,
        X_train, y_train,
        X_test, y_test
    ) -> Dict[str, float]:
        """å®Ÿé¨“ã®å®Ÿè¡Œã¨è‡ªå‹•ãƒ­ã‚®ãƒ³ã‚°"""

        # å®Ÿé¨“ã®è¨­å®š
        mlflow.set_experiment(config.experiment_name)

        with mlflow.start_run(description=config.description):
            # 1. ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒ­ã‚®ãƒ³ã‚°
            mlflow.log_params(config.model_params)
            mlflow.log_params(config.data_params)

            # 2. ã‚¿ã‚°ã®è¨­å®š
            if config.tags:
                for key, value in config.tags.items():
                    mlflow.set_tag(key, value)

            # 3. ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´
            model.fit(X_train, y_train)

            # 4. äºˆæ¸¬
            y_train_pred = model.predict(X_train)
            y_test_pred = model.predict(X_test)

            # 5. ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®è¨ˆç®—
            metrics = {
                "train_accuracy": accuracy_score(y_train, y_train_pred),
                "test_accuracy": accuracy_score(y_test, y_test_pred),
                "test_precision": precision_score(y_test, y_test_pred, average='weighted'),
                "test_recall": recall_score(y_test, y_test_pred, average='weighted'),
                "test_f1": f1_score(y_test, y_test_pred, average='weighted'),
                "overfit_gap": accuracy_score(y_train, y_train_pred) - accuracy_score(y_test, y_test_pred)
            }

            # 6. ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®ãƒ­ã‚®ãƒ³ã‚°
            for metric_name, metric_value in metrics.items():
                mlflow.log_metric(metric_name, metric_value)

            # 7. ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜
            mlflow.sklearn.log_model(model, "model")

            # 8. çµæœã®ä¿å­˜
            run_id = mlflow.active_run().info.run_id
            result = {
                "run_id": run_id,
                "config": asdict(config),
                "metrics": metrics
            }
            self.results.append(result)

            print(f"å®Ÿé¨“å®Œäº†: {config.experiment_name}")
            print(f"  ãƒ†ã‚¹ãƒˆç²¾åº¦: {metrics['test_accuracy']:.3f}")
            print(f"  Run ID: {run_id}")

            return metrics

    def compare_experiments(self) -> pd.DataFrame:
        """å®Ÿé¨“çµæœã®æ¯”è¼ƒ"""
        if not self.results:
            print("å®Ÿé¨“çµæœãŒã‚ã‚Šã¾ã›ã‚“")
            return pd.DataFrame()

        comparison_data = []
        for result in self.results:
            row = {
                "run_id": result["run_id"],
                "experiment": result["config"]["experiment_name"],
                **result["metrics"]
            }
            comparison_data.append(row)

        df = pd.DataFrame(comparison_data)
        return df.sort_values("test_accuracy", ascending=False)

    def get_best_model(self, metric: str = "test_accuracy") -> Dict[str, Any]:
        """æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ã®è‡ªå‹•é¸æŠ"""
        if not self.results:
            raise ValueError("å®Ÿé¨“çµæœãŒã‚ã‚Šã¾ã›ã‚“")

        best_result = max(self.results, key=lambda x: x["metrics"][metric])

        print(f"\n=== æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ï¼ˆ{metric}åŸºæº–ï¼‰===")
        print(f"Run ID: {best_result['run_id']}")
        print(f"å®Ÿé¨“å: {best_result['config']['experiment_name']}")
        print(f"{metric}: {best_result['metrics'][metric]:.3f}")
        print(f"\nå…¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹:")
        for m_name, m_value in best_result['metrics'].items():
            print(f"  {m_name}: {m_value:.3f}")

        return best_result

    def save_comparison_report(self, filepath: str = "experiment_comparison.csv"):
        """æ¯”è¼ƒãƒ¬ãƒãƒ¼ãƒˆã®ä¿å­˜"""
        df = self.compare_experiments()
        df.to_csv(filepath, index=False)
        print(f"æ¯”è¼ƒãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜: {filepath}")

# ä½¿ç”¨ä¾‹
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split

# ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
X, y = make_classification(n_samples=1000, n_features=20, random_state=42)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# å®Ÿé¨“ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã®åˆæœŸåŒ–
manager = ComprehensiveExperimentManager()

# å®Ÿé¨“1: Random Forestï¼ˆæµ…ã„ï¼‰
config1 = ExperimentConfig(
    experiment_name="model_comparison",
    model_params={"n_estimators": 50, "max_depth": 5, "random_state": 42},
    data_params={"train_size": len(X_train), "test_size": len(X_test)},
    description="Random Forest with shallow depth",
    tags={"model_type": "random_forest", "depth": "shallow"}
)
rf_shallow = RandomForestClassifier(**config1.model_params)
manager.run_experiment(config1, rf_shallow, X_train, y_train, X_test, y_test)

# å®Ÿé¨“2: Random Forestï¼ˆæ·±ã„ï¼‰
config2 = ExperimentConfig(
    experiment_name="model_comparison",
    model_params={"n_estimators": 100, "max_depth": 20, "random_state": 42},
    data_params={"train_size": len(X_train), "test_size": len(X_test)},
    description="Random Forest with deep depth",
    tags={"model_type": "random_forest", "depth": "deep"}
)
rf_deep = RandomForestClassifier(**config2.model_params)
manager.run_experiment(config2, rf_deep, X_train, y_train, X_test, y_test)

# å®Ÿé¨“3: Gradient Boosting
config3 = ExperimentConfig(
    experiment_name="model_comparison",
    model_params={"n_estimators": 100, "max_depth": 5, "random_state": 42},
    data_params={"train_size": len(X_train), "test_size": len(X_test)},
    description="Gradient Boosting Classifier",
    tags={"model_type": "gradient_boosting"}
)
gb = GradientBoostingClassifier(**config3.model_params)
manager.run_experiment(config3, gb, X_train, y_train, X_test, y_test)

# çµæœã®æ¯”è¼ƒ
print("\n=== å…¨å®Ÿé¨“ã®æ¯”è¼ƒ ===")
comparison_df = manager.compare_experiments()
print(comparison_df[['experiment', 'test_accuracy', 'test_f1', 'overfit_gap']])

# æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ã®é¸æŠ
best_model = manager.get_best_model(metric="test_accuracy")

# ãƒ¬ãƒãƒ¼ãƒˆã®ä¿å­˜
manager.save_comparison_report()
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>å®Ÿé¨“å®Œäº†: model_comparison
  ãƒ†ã‚¹ãƒˆç²¾åº¦: 0.855
  Run ID: xxxxx

å®Ÿé¨“å®Œäº†: model_comparison
  ãƒ†ã‚¹ãƒˆç²¾åº¦: 0.890
  Run ID: yyyyy

å®Ÿé¨“å®Œäº†: model_comparison
  ãƒ†ã‚¹ãƒˆç²¾åº¦: 0.905
  Run ID: zzzzz

=== å…¨å®Ÿé¨“ã®æ¯”è¼ƒ ===
       experiment  test_accuracy  test_f1  overfit_gap
2  model_comparison          0.905    0.903        0.032
1  model_comparison          0.890    0.891        0.097
0  model_comparison          0.855    0.856        0.007

=== æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ï¼ˆtest_accuracyåŸºæº–ï¼‰===
Run ID: zzzzz
å®Ÿé¨“å: model_comparison
test_accuracy: 0.905

å…¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹:
  train_accuracy: 0.937
  test_accuracy: 0.905
  test_precision: 0.906
  test_recall: 0.905
  test_f1: 0.903
  overfit_gap: 0.032

æ¯”è¼ƒãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜: experiment_comparison.csv
</code></pre>

</details>

<h3>å•é¡Œ5ï¼ˆé›£æ˜“åº¦ï¼šhardï¼‰</h3>
<p>MLflowã¨DVCã‚’çµ„ã¿åˆã‚ã›ãŸå®Œå…¨ãªæ©Ÿæ¢°å­¦ç¿’ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’è¨­è¨ˆã—ã€å®Ÿè£…ã—ã¦ãã ã•ã„ã€‚ãƒ‡ãƒ¼ã‚¿ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ã‹ã‚‰å®Ÿé¨“ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ã€ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜ã¾ã§å«ã‚ã‚‹ã“ã¨ã€‚</p>

<details>
<summary>è§£ç­”ä¾‹</summary>

<pre><code class="language-python">"""
å®Œå…¨ãªML ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼: DVC + MLflow

ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ :
project/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â””â”€â”€ processed/
â”œâ”€â”€ models/
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ prepare_data.py
â”‚   â”œâ”€â”€ train_model.py
â”‚   â””â”€â”€ evaluate_model.py
â”œâ”€â”€ dvc.yaml
â””â”€â”€ params.yaml
"""

# params.yaml ã®å†…å®¹
"""
data:
  raw_path: data/raw/dataset.csv
  train_path: data/processed/train.csv
  test_path: data/processed/test.csv
  test_size: 0.2
  random_state: 42

model:
  type: random_forest
  n_estimators: 100
  max_depth: 10
  min_samples_split: 2
  random_state: 42

mlflow:
  experiment_name: dvc_mlflow_integration
  tracking_uri: ./mlruns
"""

# scripts/prepare_data.py
import pandas as pd
import yaml
from sklearn.model_selection import train_test_split

def load_params():
    with open('params.yaml', 'r') as f:
        return yaml.safe_load(f)

def prepare_data():
    params = load_params()
    data_params = params['data']

    # ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
    df = pd.read_csv(data_params['raw_path'])

    # è¨“ç·´ãƒ»ãƒ†ã‚¹ãƒˆåˆ†å‰²
    train, test = train_test_split(
        df,
        test_size=data_params['test_size'],
        random_state=data_params['random_state']
    )

    # ä¿å­˜
    train.to_csv(data_params['train_path'], index=False)
    test.to_csv(data_params['test_path'], index=False)

    print(f"ãƒ‡ãƒ¼ã‚¿æº–å‚™å®Œäº†: Train={len(train)}, Test={len(test)}")

if __name__ == "__main__":
    prepare_data()

# scripts/train_model.py
import pandas as pd
import yaml
import mlflow
import mlflow.sklearn
from sklearn.ensemble import RandomForestClassifier
import joblib

def load_params():
    with open('params.yaml', 'r') as f:
        return yaml.safe_load(f)

def train_model():
    params = load_params()
    data_params = params['data']
    model_params = params['model']
    mlflow_params = params['mlflow']

    # MLflowã®è¨­å®š
    mlflow.set_tracking_uri(mlflow_params['tracking_uri'])
    mlflow.set_experiment(mlflow_params['experiment_name'])

    # ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
    train = pd.read_csv(data_params['train_path'])
    X_train = train.drop('target', axis=1)
    y_train = train['target']

    # MLflowå®Ÿé¨“ã®é–‹å§‹
    with mlflow.start_run():
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®è¨˜éŒ²
        mlflow.log_params(model_params)
        mlflow.log_param("train_size", len(X_train))

        # ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´
        model = RandomForestClassifier(
            n_estimators=model_params['n_estimators'],
            max_depth=model_params['max_depth'],
            min_samples_split=model_params['min_samples_split'],
            random_state=model_params['random_state']
        )
        model.fit(X_train, y_train)

        # è¨“ç·´ãƒ¡ãƒˆãƒªã‚¯ã‚¹
        train_score = model.score(X_train, y_train)
        mlflow.log_metric("train_accuracy", train_score)

        # ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜
        model_path = "models/model.pkl"
        joblib.dump(model, model_path)
        mlflow.sklearn.log_model(model, "model")

        print(f"è¨“ç·´å®Œäº†: Train Accuracy={train_score:.3f}")

if __name__ == "__main__":
    train_model()

# scripts/evaluate_model.py
import pandas as pd
import yaml
import mlflow
import joblib
from sklearn.metrics import accuracy_score, classification_report
import json

def load_params():
    with open('params.yaml', 'r') as f:
        return yaml.safe_load(f)

def evaluate_model():
    params = load_params()
    data_params = params['data']
    mlflow_params = params['mlflow']

    # MLflowã®è¨­å®š
    mlflow.set_tracking_uri(mlflow_params['tracking_uri'])
    mlflow.set_experiment(mlflow_params['experiment_name'])

    # ãƒ‡ãƒ¼ã‚¿ã¨ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿
    test = pd.read_csv(data_params['test_path'])
    X_test = test.drop('target', axis=1)
    y_test = test['target']

    model = joblib.load("models/model.pkl")

    # è©•ä¾¡
    y_pred = model.predict(X_test)
    test_accuracy = accuracy_score(y_test, y_pred)

    # è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆ
    report = classification_report(y_test, y_pred, output_dict=True)

    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®ä¿å­˜
    metrics = {
        "test_accuracy": test_accuracy,
        "precision": report['weighted avg']['precision'],
        "recall": report['weighted avg']['recall'],
        "f1_score": report['weighted avg']['f1-score']
    }

    with open("metrics/test_metrics.json", 'w') as f:
        json.dump(metrics, f, indent=2)

    # MLflowã«è¨˜éŒ²
    with mlflow.start_run():
        for metric_name, metric_value in metrics.items():
            mlflow.log_metric(metric_name, metric_value)

    print(f"è©•ä¾¡å®Œäº†: Test Accuracy={test_accuracy:.3f}")
    print(f"è©³ç´°ãƒ¡ãƒˆãƒªã‚¯ã‚¹: {metrics}")

if __name__ == "__main__":
    evaluate_model()

# dvc.yaml ã®å†…å®¹
"""
stages:
  prepare:
    cmd: python scripts/prepare_data.py
    deps:
      - data/raw/dataset.csv
      - scripts/prepare_data.py
    params:
      - data.test_size
      - data.random_state
    outs:
      - data/processed/train.csv
      - data/processed/test.csv

  train:
    cmd: python scripts/train_model.py
    deps:
      - data/processed/train.csv
      - scripts/train_model.py
    params:
      - model
    outs:
      - models/model.pkl

  evaluate:
    cmd: python scripts/evaluate_model.py
    deps:
      - data/processed/test.csv
      - models/model.pkl
      - scripts/evaluate_model.py
    metrics:
      - metrics/test_metrics.json:
          cache: false
"""

# å®Œå…¨ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®å®Ÿè¡Œä¾‹
"""
# 1. DVCã®åˆæœŸåŒ–
dvc init

# 2. ãƒ‡ãƒ¼ã‚¿ã®è¿½åŠ 
dvc add data/raw/dataset.csv
git add data/raw/dataset.csv.dvc data/.gitignore
git commit -m "Add raw data"

# 3. ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®å®Ÿè¡Œ
dvc repro

# 4. å®Ÿé¨“ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å¤‰æ›´
dvc exp run --set-param model.n_estimators=200

# 5. å®Ÿé¨“çµæœã®æ¯”è¼ƒ
dvc exp show

# 6. æœ€è‰¯ã®å®Ÿé¨“ã‚’é©ç”¨
dvc exp apply <experiment-name>
git add .
git commit -m "Apply best experiment"

# 7. MLflow UIã§çµæœã‚’ç¢ºèª
mlflow ui --backend-store-uri ./mlruns
"""

print("å®Œå…¨ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼è¨­è¨ˆå®Œäº†")
print("DVC: ãƒ‡ãƒ¼ã‚¿ã¨ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†")
print("MLflow: å®Ÿé¨“ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ã¨ãƒ¢ãƒ‡ãƒ«ç®¡ç†")
print("çµ±åˆ: å†ç¾å¯èƒ½ã§è¿½è·¡å¯èƒ½ãªMLãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼")
</code></pre>

</details>

<hr>

<h2>å‚è€ƒæ–‡çŒ®</h2>

<ol>
<li>GÃ©ron, A. (2019). <em>Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow</em> (2nd ed.). O'Reilly Media.</li>
<li>Huyen, C. (2022). <em>Designing Machine Learning Systems</em>. O'Reilly Media.</li>
<li>Lakshmanan, V., Robinson, S., & Munn, M. (2020). <em>Machine Learning Design Patterns</em>. O'Reilly Media.</li>
<li>Treveil, M., et al. (2020). <em>Introducing MLOps</em>. O'Reilly Media.</li>
<li>MLflow Documentation. <a href="https://mlflow.org/docs/latest/index.html">https://mlflow.org/docs/latest/index.html</a></li>
<li>Weights & Biases Documentation. <a href="https://docs.wandb.ai/">https://docs.wandb.ai/</a></li>
<li>DVC Documentation. <a href="https://dvc.org/doc">https://dvc.org/doc</a></li>
</ol>

<div class="navigation">
    <a href="chapter1-mlops-fundamentals.html" class="nav-button">â† å‰ã®ç« : MLOpsåŸºç¤</a>
    <a href="chapter3-ci-cd-pipeline.html" class="nav-button">æ¬¡ã®ç« : CI/CDãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ â†’</a>
</div>

    </main>

    
    <section class="disclaimer">
        <h3>å…è²¬äº‹é …</h3>
        <ul>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯æ•™è‚²ãƒ»ç ”ç©¶ãƒ»æƒ…å ±æä¾›ã®ã¿ã‚’ç›®çš„ã¨ã—ã¦ãŠã‚Šã€å°‚é–€çš„ãªåŠ©è¨€(æ³•å¾‹ãƒ»ä¼šè¨ˆãƒ»æŠ€è¡“çš„ä¿è¨¼ãªã©)ã‚’æä¾›ã™ã‚‹ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŠã‚ˆã³ä»˜éšã™ã‚‹ã‚³ãƒ¼ãƒ‰ä¾‹ã¯ã€Œç¾çŠ¶æœ‰å§¿(AS IS)ã€ã§æä¾›ã•ã‚Œã€æ˜ç¤ºã¾ãŸã¯é»™ç¤ºã‚’å•ã‚ãšã€å•†å“æ€§ã€ç‰¹å®šç›®çš„é©åˆæ€§ã€æ¨©åˆ©éä¾µå®³ã€æ­£ç¢ºæ€§ãƒ»å®Œå…¨æ€§ã€å‹•ä½œãƒ»å®‰å…¨æ€§ç­‰ã„ã‹ãªã‚‹ä¿è¨¼ã‚‚ã—ã¾ã›ã‚“ã€‚</li>
            <li>å¤–éƒ¨ãƒªãƒ³ã‚¯ã€ç¬¬ä¸‰è€…ãŒæä¾›ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ»ãƒ„ãƒ¼ãƒ«ãƒ»ãƒ©ã‚¤ãƒ–ãƒ©ãƒªç­‰ã®å†…å®¹ãƒ»å¯ç”¨æ€§ãƒ»å®‰å…¨æ€§ã«ã¤ã„ã¦ã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯ä¸€åˆ‡ã®è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®åˆ©ç”¨ãƒ»å®Ÿè¡Œãƒ»è§£é‡ˆã«ã‚ˆã‚Šç›´æ¥çš„ãƒ»é–“æ¥çš„ãƒ»ä»˜éšçš„ãƒ»ç‰¹åˆ¥ãƒ»çµæœçš„ãƒ»æ‡²ç½°çš„æå®³ãŒç”Ÿã˜ãŸå ´åˆã§ã‚‚ã€é©ç”¨æ³•ã§è¨±å®¹ã•ã‚Œã‚‹æœ€å¤§é™ã®ç¯„å›²ã§ã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å†…å®¹ã¯ã€äºˆå‘Šãªãå¤‰æ›´ãƒ»æ›´æ–°ãƒ»æä¾›åœæ­¢ã•ã‚Œã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®è‘—ä½œæ¨©ãƒ»ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯æ˜è¨˜ã•ã‚ŒãŸæ¡ä»¶(ä¾‹: CC BY 4.0)ã«å¾“ã„ã¾ã™ã€‚å½“è©²ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯é€šå¸¸ã€ç„¡ä¿è¨¼æ¡é …ã‚’å«ã¿ã¾ã™ã€‚</li>
        </ul>
    </section>

<footer>
        <p><strong>ä½œæˆè€…</strong>: AI Terakoya Content Team</p>
        <p><strong>ãƒãƒ¼ã‚¸ãƒ§ãƒ³</strong>: 1.0 | <strong>ä½œæˆæ—¥</strong>: 2025-10-21</p>
        <p><strong>ãƒ©ã‚¤ã‚»ãƒ³ã‚¹</strong>: Creative Commons BY 4.0</p>
        <p>Â© 2025 AI Terakoya. All rights reserved.</p>
    </footer>
</body>
</html>