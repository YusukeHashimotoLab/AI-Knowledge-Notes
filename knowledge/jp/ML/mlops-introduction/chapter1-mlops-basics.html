<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>第1章：MLOps基礎 - AI Terakoya</title>

    <style>
        :root {
            --color-primary: #2c3e50;
            --color-primary-dark: #1a252f;
            --color-accent: #7b2cbf;
            --color-accent-light: #9d4edd;
            --color-text: #2d3748;
            --color-text-light: #4a5568;
            --color-bg: #ffffff;
            --color-bg-alt: #f7fafc;
            --color-border: #e2e8f0;
            --color-code-bg: #f8f9fa;
            --color-link: #3182ce;
            --color-link-hover: #2c5aa0;

            --spacing-xs: 0.5rem;
            --spacing-sm: 1rem;
            --spacing-md: 1.5rem;
            --spacing-lg: 2rem;
            --spacing-xl: 3rem;

            --font-body: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            --font-mono: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;

            --border-radius: 8px;
            --box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: var(--font-body);
            line-height: 1.7;
            color: var(--color-text);
            background-color: var(--color-bg);
            font-size: 16px;
        }

        header {
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            padding: var(--spacing-xl) var(--spacing-md);
            margin-bottom: var(--spacing-xl);
            box-shadow: var(--box-shadow);
        }

        .header-content {
            max-width: 900px;
            margin: 0 auto;
        }

        h1 {
            font-size: 2rem;
            font-weight: 700;
            margin-bottom: var(--spacing-sm);
            line-height: 1.2;
        }

        .subtitle {
            font-size: 1.1rem;
            opacity: 0.95;
            font-weight: 400;
            margin-bottom: var(--spacing-md);
        }

        .meta {
            display: flex;
            flex-wrap: wrap;
            gap: var(--spacing-md);
            font-size: 0.9rem;
            opacity: 0.9;
        }

        .meta-item {
            display: flex;
            align-items: center;
            gap: 0.3rem;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 0 var(--spacing-md) var(--spacing-xl);
        }

        h2 {
            font-size: 1.75rem;
            color: var(--color-primary);
            margin-top: var(--spacing-xl);
            margin-bottom: var(--spacing-md);
            padding-bottom: var(--spacing-xs);
            border-bottom: 3px solid var(--color-accent);
        }

        h3 {
            font-size: 1.4rem;
            color: var(--color-primary);
            margin-top: var(--spacing-lg);
            margin-bottom: var(--spacing-sm);
        }

        h4 {
            font-size: 1.1rem;
            color: var(--color-primary-dark);
            margin-top: var(--spacing-md);
            margin-bottom: var(--spacing-sm);
        }

        p {
            margin-bottom: var(--spacing-md);
            color: var(--color-text);
        }

        a {
            color: var(--color-link);
            text-decoration: none;
            transition: color 0.2s;
        }

        a:hover {
            color: var(--color-link-hover);
            text-decoration: underline;
        }

        ul, ol {
            margin-left: var(--spacing-lg);
            margin-bottom: var(--spacing-md);
        }

        li {
            margin-bottom: var(--spacing-xs);
            color: var(--color-text);
        }

        pre {
            background-color: var(--color-code-bg);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            overflow-x: auto;
            margin-bottom: var(--spacing-md);
            font-family: var(--font-mono);
            font-size: 0.9rem;
            line-height: 1.5;
        }

        code {
            font-family: var(--font-mono);
            font-size: 0.9em;
            background-color: var(--color-code-bg);
            padding: 0.2em 0.4em;
            border-radius: 3px;
        }

        pre code {
            background-color: transparent;
            padding: 0;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: var(--spacing-md);
            font-size: 0.95rem;
        }

        th, td {
            border: 1px solid var(--color-border);
            padding: var(--spacing-sm);
            text-align: left;
        }

        th {
            background-color: var(--color-bg-alt);
            font-weight: 600;
            color: var(--color-primary);
        }

        blockquote {
            border-left: 4px solid var(--color-accent);
            padding-left: var(--spacing-md);
            margin: var(--spacing-md) 0;
            color: var(--color-text-light);
            font-style: italic;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        .mermaid {
            text-align: center;
            margin: var(--spacing-lg) 0;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        details {
            background-color: var(--color-bg-alt);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            margin-bottom: var(--spacing-md);
        }

        summary {
            cursor: pointer;
            font-weight: 600;
            color: var(--color-primary);
            user-select: none;
            padding: var(--spacing-xs);
            margin: calc(-1 * var(--spacing-md));
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        summary:hover {
            background-color: rgba(123, 44, 191, 0.1);
        }

        details[open] summary {
            margin-bottom: var(--spacing-md);
            border-bottom: 1px solid var(--color-border);
        }

        .navigation {
            display: flex;
            justify-content: space-between;
            gap: var(--spacing-md);
            margin: var(--spacing-xl) 0;
            padding-top: var(--spacing-lg);
            border-top: 2px solid var(--color-border);
        }

        .nav-button {
            flex: 1;
            padding: var(--spacing-md);
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            border-radius: var(--border-radius);
            text-align: center;
            font-weight: 600;
            transition: transform 0.2s, box-shadow 0.2s;
            box-shadow: var(--box-shadow);
        }

        .nav-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
            text-decoration: none;
        }

        footer {
            margin-top: var(--spacing-xl);
            padding: var(--spacing-lg) var(--spacing-md);
            background-color: var(--color-bg-alt);
            border-top: 1px solid var(--color-border);
            text-align: center;
            font-size: 0.9rem;
            color: var(--color-text-light);
        }

        @media (max-width: 768px) {
            h1 {
                font-size: 1.5rem;
            }

            h2 {
                font-size: 1.4rem;
            }

            h3 {
                font-size: 1.2rem;
            }

            .meta {
                font-size: 0.85rem;
            }

            .navigation {
                flex-direction: column;
            }

            table {
                font-size: 0.85rem;
            }

            th, td {
                padding: var(--spacing-xs);
            }
        }
    </style>

    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
        mermaid.initialize({ startOnLoad: true, theme: 'default' });
    </script>

    <!-- MathJax for LaTeX equation rendering -->
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                displayMath: [['$$', '$$'], ['\\[', '\\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
                ignoreHtmlClass: 'mermaid'
            }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" async></script>
</head>
<body>
    <header>
        <div class="header-content">
            <h1>第1章：MLOps基礎</h1>
            <p class="subtitle">機械学習システムの運用を支える基盤技術</p>
            <div class="meta">
                <span class="meta-item">📖 読了時間: 25-30分</span>
                <span class="meta-item">📊 難易度: 初級</span>
                <span class="meta-item">💻 コード例: 10個</span>
                <span class="meta-item">📝 演習問題: 5問</span>
            </div>
        </div>
    </header>

    <main class="container">

<h2>学習目標</h2>
<p>この章を読むことで、以下を習得できます：</p>
<ul>
<li>✅ MLOpsの定義と必要性を理解する</li>
<li>✅ 機械学習ライフサイクル全体を把握する</li>
<li>✅ MLOpsの主要コンポーネントを理解する</li>
<li>✅ MLOpsツールエコシステムの概要を知る</li>
<li>✅ MLOps成熟度モデルを理解し、現状を評価できる</li>
<li>✅ 実践的なMLOpsパイプラインの基礎を構築できる</li>
</ul>

<hr>

<h2>1.1 MLOpsとは</h2>

<h3>機械学習システムの課題</h3>

<p>機械学習プロジェクトの多くは、PoC（概念実証）段階で終わり、本番環境への展開に失敗します。その主な理由は以下の通りです：</p>

<table>
<thead>
<tr>
<th>課題</th>
<th>説明</th>
<th>影響</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>モデルとコードの乖離</strong></td>
<td>Jupyter Notebookのコードが本番環境で動作しない</td>
<td>デプロイの遅延、手作業の増加</td>
</tr>
<tr>
<td><strong>再現性の欠如</strong></td>
<td>同じ結果を再現できない（データ、コード、環境の不一致）</td>
<td>デバッグ困難、品質低下</td>
</tr>
<tr>
<td><strong>モデルの劣化</strong></td>
<td>時間経過によるモデル性能の低下</td>
<td>予測精度の悪化、ビジネス損失</td>
</tr>
<tr>
<td><strong>スケーラビリティ</strong></td>
<td>大量のリクエストに対応できない</td>
<td>システム停止、レスポンス遅延</td>
</tr>
<tr>
<td><strong>ガバナンスの欠如</strong></td>
<td>誰がいつどのモデルをデプロイしたか不明</td>
<td>コンプライアンス違反、監査不可</td>
</tr>
</tbody>
</table>

<blockquote>
<p><strong>統計</strong>: Gartnerの調査によると、機械学習プロジェクトの約85%が本番環境に到達しないと報告されています。</p>
</blockquote>

<h3>MLOpsの定義と目的</h3>

<p><strong>MLOps（Machine Learning Operations）</strong>は、機械学習モデルの開発・デプロイ・運用を自動化・標準化するための実践手法とツール群です。</p>

<p><strong>MLOpsの目的</strong>：</p>
<ul>
<li><strong>迅速なデプロイ</strong>: モデルを迅速かつ確実に本番環境へ展開</li>
<li><strong>再現性</strong>: 実験とモデルの完全な再現を保証</li>
<li><strong>自動化</strong>: 手作業を削減し、エラーを最小化</li>
<li><strong>モニタリング</strong>: モデル性能の継続的な監視と改善</li>
<li><strong>スケーラビリティ</strong>: 多数のモデルとデータに対応</li>
<li><strong>ガバナンス</strong>: コンプライアンスと監査対応</li>
</ul>

<h3>DevOps/DataOpsとの関係</h3>

<p>MLOpsは、DevOpsとDataOpsの原則を機械学習に適用したものです：</p>

<table>
<thead>
<tr>
<th>概念</th>
<th>焦点</th>
<th>主な実践</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>DevOps</strong></td>
<td>ソフトウェア開発と運用</td>
<td>CI/CD、インフラ自動化、モニタリング</td>
</tr>
<tr>
<td><strong>DataOps</strong></td>
<td>データパイプラインと品質</td>
<td>データバージョニング、品質チェック、メタデータ管理</td>
</tr>
<tr>
<td><strong>MLOps</strong></td>
<td>機械学習モデルのライフサイクル</td>
<td>実験管理、モデルバージョニング、自動再訓練</td>
</tr>
</tbody>
</table>

<div class="mermaid">
graph LR
    A[DevOps] --> D[MLOps]
    B[DataOps] --> D
    C[Machine Learning] --> D

    D --> E[自動化されたML<br/>ライフサイクル]

    style A fill:#e3f2fd
    style B fill:#f3e5f5
    style C fill:#fff3e0
    style D fill:#c8e6c9
    style E fill:#ffccbc
</div>

<h3>MLOpsが解決する問題の実例</h3>

<pre><code class="language-python">"""
問題: Jupyter Notebookで開発したモデルが本番環境で動作しない

原因:
- 開発環境と本番環境のライブラリバージョンが異なる
- データの前処理ステップが文書化されていない
- モデルの依存関係が不明確
"""

# ❌ 問題のあるアプローチ（再現性なし）
import pandas as pd
from sklearn.ensemble import RandomForestClassifier

# データ読み込み（どのバージョン？いつ？）
df = pd.read_csv('data.csv')

# 前処理（ステップが不明確）
df = df.dropna()
X = df.drop('target', axis=1)
y = df['target']

# モデル訓練（ハイパーパラメータ記録なし）
model = RandomForestClassifier()
model.fit(X, y)

# 保存（メタデータなし）
import pickle
pickle.dump(model, open('model.pkl', 'wb'))
</code></pre>

<pre><code class="language-python">"""
✅ MLOpsアプローチ（再現性あり）

特徴:
- バージョン管理（コード、データ、モデル）
- 環境の明示（requirements.txt, Docker）
- メタデータの記録（実験結果、パラメータ）
- パイプライン化（再現可能な処理フロー）
"""

import mlflow
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
import json
from datetime import datetime

# MLflow実験の開始
mlflow.set_experiment("customer_churn_prediction")

with mlflow.start_run():
    # 1. データバージョンの記録
    data_version = "v1.2.3"
    mlflow.log_param("data_version", data_version)

    # 2. データ読み込み（バージョン管理されたデータ）
    df = pd.read_csv(f'data/{data_version}/data.csv')

    # 3. 前処理（明示的なステップ）
    df = df.dropna()
    X = df.drop('target', axis=1)
    y = df['target']

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )

    # 4. ハイパーパラメータの記録
    params = {
        'n_estimators': 100,
        'max_depth': 10,
        'random_state': 42
    }
    mlflow.log_params(params)

    # 5. モデル訓練
    model = RandomForestClassifier(**params)
    model.fit(X_train, y_train)

    # 6. 評価と記録
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    mlflow.log_metric("accuracy", accuracy)

    # 7. モデルの保存（メタデータ付き）
    mlflow.sklearn.log_model(
        model,
        "model",
        registered_model_name="churn_predictor"
    )

    # 8. 追加メタデータ
    mlflow.set_tag("model_type", "RandomForest")
    mlflow.set_tag("created_by", "data_science_team")
    mlflow.set_tag("timestamp", datetime.now().isoformat())

    print(f"✓ モデル訓練完了 - 精度: {accuracy:.3f}")
    print(f"✓ 実験ID: {mlflow.active_run().info.run_id}")
</code></pre>

<hr>

<h2>1.2 MLライフサイクル</h2>

<h3>機械学習プロジェクトの全体像</h3>

<p>機械学習プロジェクトは、以下のフェーズで構成される反復的なプロセスです：</p>

<div class="mermaid">
graph TB
    A[ビジネス理解] --> B[データ収集・準備]
    B --> C[モデル開発・訓練]
    C --> D[モデル評価]
    D --> E{性能OK?}
    E -->|No| C
    E -->|Yes| F[デプロイメント]
    F --> G[モニタリング]
    G --> H{再訓練必要?}
    H -->|Yes| B
    H -->|No| G

    style A fill:#e3f2fd
    style B fill:#fff3e0
    style C fill:#f3e5f5
    style D fill:#fce4ec
    style F fill:#c8e6c9
    style G fill:#ffccbc
</div>

<h3>1. データ収集と準備</h3>

<p>データパイプラインの構築と品質保証：</p>

<pre><code class="language-python">"""
データ収集・準備フェーズ

目的:
- 高品質なデータセットの構築
- データの検証とバージョニング
- 再現可能な前処理パイプライン
"""

import pandas as pd
import great_expectations as ge
from sklearn.model_selection import train_test_split
import hashlib
import json

class DataPipeline:
    """データパイプラインクラス"""

    def __init__(self, data_path, version):
        self.data_path = data_path
        self.version = version
        self.metadata = {}

    def load_data(self):
        """データ読み込み"""
        df = pd.read_csv(self.data_path)

        # データのハッシュ値を計算（整合性確認用）
        data_hash = hashlib.md5(
            pd.util.hash_pandas_object(df).values
        ).hexdigest()

        self.metadata['data_hash'] = data_hash
        self.metadata['n_samples'] = len(df)
        self.metadata['n_features'] = len(df.columns)

        print(f"✓ データ読み込み完了: {len(df)}行, {len(df.columns)}列")
        print(f"✓ データハッシュ: {data_hash[:8]}...")

        return df

    def validate_data(self, df):
        """データ品質検証"""
        # Great Expectationsを使用したデータ検証
        df_ge = ge.from_pandas(df)

        # 期待値の定義
        expectations = []

        # 1. 欠損値チェック
        for col in df.columns:
            missing_pct = df[col].isnull().mean()
            expectations.append({
                'column': col,
                'check': 'missing_values',
                'value': f"{missing_pct:.2%}"
            })
            if missing_pct > 0.3:
                print(f"⚠️  警告: {col}の欠損率が30%を超えています")

        # 2. データ型チェック
        expectations.append({
            'check': 'data_types',
            'dtypes': df.dtypes.to_dict()
        })

        # 3. 重複チェック
        n_duplicates = df.duplicated().sum()
        expectations.append({
            'check': 'duplicates',
            'value': n_duplicates
        })

        self.metadata['validation'] = expectations

        print(f"✓ データ検証完了")
        print(f"  - 重複行: {n_duplicates}")

        return df

    def preprocess_data(self, df):
        """データ前処理"""
        # 欠損値処理
        df_clean = df.copy()

        # 数値列: 中央値補完
        numeric_cols = df_clean.select_dtypes(include=['float64', 'int64']).columns
        for col in numeric_cols:
            if df_clean[col].isnull().any():
                median_val = df_clean[col].median()
                df_clean[col].fillna(median_val, inplace=True)

        # カテゴリカル列: 最頻値補完
        cat_cols = df_clean.select_dtypes(include=['object']).columns
        for col in cat_cols:
            if df_clean[col].isnull().any():
                mode_val = df_clean[col].mode()[0]
                df_clean[col].fillna(mode_val, inplace=True)

        print(f"✓ 前処理完了")

        return df_clean

    def save_metadata(self, filepath):
        """メタデータの保存"""
        with open(filepath, 'w') as f:
            json.dump(self.metadata, f, indent=2, default=str)
        print(f"✓ メタデータ保存: {filepath}")

# 使用例
pipeline = DataPipeline('customer_data.csv', 'v1.0.0')
df = pipeline.load_data()
df = pipeline.validate_data(df)
df_clean = pipeline.preprocess_data(df)
pipeline.save_metadata('data_metadata.json')
</code></pre>

<h3>2. モデル開発と訓練</h3>

<p>実験管理と再現性の確保：</p>

<pre><code class="language-python">"""
モデル開発・訓練フェーズ

目的:
- 体系的な実験管理
- ハイパーパラメータの最適化
- モデルのバージョニング
"""

import mlflow
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import cross_val_score
import numpy as np

class ExperimentManager:
    """実験管理クラス"""

    def __init__(self, experiment_name):
        mlflow.set_experiment(experiment_name)
        self.experiment_name = experiment_name

    def train_and_log(self, model, X_train, y_train, model_name, params):
        """モデル訓練と記録"""
        with mlflow.start_run(run_name=model_name):
            # パラメータ記録
            mlflow.log_params(params)

            # Cross-validation
            cv_scores = cross_val_score(
                model, X_train, y_train, cv=5, scoring='accuracy'
            )

            # 訓練
            model.fit(X_train, y_train)

            # メトリクス記録
            mlflow.log_metric("cv_mean_accuracy", cv_scores.mean())
            mlflow.log_metric("cv_std_accuracy", cv_scores.std())

            # モデル保存
            mlflow.sklearn.log_model(model, "model")

            print(f"✓ {model_name}")
            print(f"  - CV精度: {cv_scores.mean():.3f} ± {cv_scores.std():.3f}")

            return cv_scores.mean()

    def compare_models(self, X_train, y_train):
        """複数モデルの比較実験"""
        models = {
            'LogisticRegression': {
                'model': LogisticRegression(max_iter=1000),
                'params': {'C': 1.0, 'max_iter': 1000}
            },
            'RandomForest': {
                'model': RandomForestClassifier(n_estimators=100, random_state=42),
                'params': {'n_estimators': 100, 'max_depth': 10}
            },
            'GradientBoosting': {
                'model': GradientBoostingClassifier(n_estimators=100, random_state=42),
                'params': {'n_estimators': 100, 'learning_rate': 0.1}
            }
        }

        results = {}
        for name, config in models.items():
            score = self.train_and_log(
                config['model'],
                X_train,
                y_train,
                name,
                config['params']
            )
            results[name] = score

        # 最良モデルの選択
        best_model = max(results, key=results.get)
        print(f"\n🏆 最良モデル: {best_model} (精度: {results[best_model]:.3f})")

        return results

# 使用例
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split

# サンプルデータ
X, y = make_classification(
    n_samples=1000, n_features=20, n_informative=15,
    n_redundant=5, random_state=42
)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# 実験実行
exp_manager = ExperimentManager("model_comparison")
results = exp_manager.compare_models(X_train, y_train)
</code></pre>

<h3>3. デプロイメントと運用</h3>

<p>モデルの本番環境への展開：</p>

<pre><code class="language-python">"""
デプロイメントフェーズ

目的:
- モデルのAPI化
- バージョン管理
- A/Bテストのサポート
"""

from flask import Flask, request, jsonify
import mlflow.pyfunc
import numpy as np
import logging

class ModelServer:
    """モデルサーバークラス"""

    def __init__(self, model_uri, model_version):
        """
        Args:
            model_uri: MLflowモデルのURI
            model_version: モデルバージョン
        """
        self.model = mlflow.pyfunc.load_model(model_uri)
        self.model_version = model_version
        self.prediction_count = 0

        # ロギング設定
        logging.basicConfig(level=logging.INFO)
        self.logger = logging.getLogger(__name__)

    def predict(self, features):
        """予測実行"""
        try:
            # 入力検証
            if not isinstance(features, (list, np.ndarray)):
                raise ValueError("入力は配列である必要があります")

            # 予測
            prediction = self.model.predict(np.array(features).reshape(1, -1))

            # カウント更新
            self.prediction_count += 1

            # ログ記録
            self.logger.info(f"予測実行 #{self.prediction_count}")

            return {
                'prediction': int(prediction[0]),
                'model_version': self.model_version,
                'prediction_id': self.prediction_count
            }

        except Exception as e:
            self.logger.error(f"予測エラー: {str(e)}")
            return {'error': str(e)}

# Flask API
app = Flask(__name__)

# モデルの読み込み（本番環境ではMLflow Model Registryから）
model_server = ModelServer(
    model_uri="models:/churn_predictor/production",
    model_version="1.0.0"
)

@app.route('/predict', methods=['POST'])
def predict():
    """予測エンドポイント"""
    data = request.get_json()
    features = data.get('features')

    if features is None:
        return jsonify({'error': 'featuresが必要です'}), 400

    result = model_server.predict(features)

    if 'error' in result:
        return jsonify(result), 500

    return jsonify(result), 200

@app.route('/health', methods=['GET'])
def health():
    """ヘルスチェックエンドポイント"""
    return jsonify({
        'status': 'healthy',
        'model_version': model_server.model_version,
        'total_predictions': model_server.prediction_count
    }), 200

# サンプルクライアント
def sample_client():
    """APIクライアントの使用例"""
    import requests

    # 予測リクエスト
    response = requests.post(
        'http://localhost:5000/predict',
        json={'features': [0.5, 1.2, -0.3, 2.1, 0.8]}
    )

    if response.status_code == 200:
        result = response.json()
        print(f"予測結果: {result['prediction']}")
        print(f"モデルバージョン: {result['model_version']}")
    else:
        print(f"エラー: {response.json()}")

# if __name__ == '__main__':
#     app.run(host='0.0.0.0', port=5000)
</code></pre>

<h3>4. モニタリングと改善</h3>

<p>本番環境でのモデル性能監視：</p>

<pre><code class="language-python">"""
モニタリングフェーズ

目的:
- モデル性能の継続的監視
- データドリフトの検出
- アラートと自動再訓練トリガー
"""

import numpy as np
import pandas as pd
from scipy import stats
from datetime import datetime, timedelta

class ModelMonitor:
    """モデルモニタリングクラス"""

    def __init__(self, baseline_data, threshold=0.05):
        """
        Args:
            baseline_data: ベースラインデータ（訓練データ）
            threshold: ドリフト検出の閾値
        """
        self.baseline_data = baseline_data
        self.threshold = threshold
        self.drift_history = []

    def detect_data_drift(self, new_data, feature_name):
        """データドリフト検出（Kolmogorov-Smirnov検定）"""
        baseline_feature = self.baseline_data[feature_name]
        new_feature = new_data[feature_name]

        # KS検定
        statistic, p_value = stats.ks_2samp(baseline_feature, new_feature)

        is_drift = p_value < self.threshold

        drift_info = {
            'timestamp': datetime.now(),
            'feature': feature_name,
            'statistic': statistic,
            'p_value': p_value,
            'drift_detected': is_drift
        }

        self.drift_history.append(drift_info)

        if is_drift:
            print(f"⚠️  データドリフト検出: {feature_name}")
            print(f"   KS統計量: {statistic:.4f}, p値: {p_value:.4f}")

        return is_drift

    def monitor_predictions(self, predictions, actuals=None):
        """予測のモニタリング"""
        monitoring_report = {
            'timestamp': datetime.now(),
            'n_predictions': len(predictions),
            'prediction_distribution': {
                'mean': np.mean(predictions),
                'std': np.std(predictions),
                'min': np.min(predictions),
                'max': np.max(predictions)
            }
        }

        # 実測値がある場合は精度を計算
        if actuals is not None:
            accuracy = np.mean(predictions == actuals)
            monitoring_report['accuracy'] = accuracy

            if accuracy < 0.7:  # 閾値例
                print(f"⚠️  精度低下検出: {accuracy:.3f}")
                print("   再訓練を推奨します")

        return monitoring_report

    def generate_report(self):
        """モニタリングレポート生成"""
        if not self.drift_history:
            return "モニタリングデータがありません"

        df_drift = pd.DataFrame(self.drift_history)

        report = f"""
=== モデルモニタリングレポート ===
期間: {df_drift['timestamp'].min()} ~ {df_drift['timestamp'].max()}
総チェック数: {len(df_drift)}
ドリフト検出数: {df_drift['drift_detected'].sum()}

ドリフト検出された特徴量:
{df_drift[df_drift['drift_detected']][['feature', 'p_value']].to_string()}
        """

        return report

# 使用例
from sklearn.datasets import make_classification

# ベースラインデータ（訓練時のデータ）
X_baseline, _ = make_classification(
    n_samples=1000, n_features=5, random_state=42
)
df_baseline = pd.DataFrame(
    X_baseline,
    columns=[f'feature_{i}' for i in range(5)]
)

# 新しいデータ（本番環境での入力データ）
# シフトを加えてドリフトをシミュレート
X_new, _ = make_classification(
    n_samples=500, n_features=5, random_state=43
)
X_new[:, 0] += 1.5  # feature_0にシフトを追加
df_new = pd.DataFrame(
    X_new,
    columns=[f'feature_{i}' for i in range(5)]
)

# モニタリング
monitor = ModelMonitor(df_baseline, threshold=0.05)

print("=== データドリフト検出 ===")
for col in df_baseline.columns:
    monitor.detect_data_drift(df_new, col)

print("\n" + monitor.generate_report())
</code></pre>

<hr>

<h2>1.3 MLOpsの主要コンポーネント</h2>

<h3>1. データ管理</h3>

<p>データのバージョニング、品質管理、系譜追跡：</p>

<table>
<thead>
<tr>
<th>コンポーネント</th>
<th>目的</th>
<th>ツール例</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>データバージョニング</strong></td>
<td>データセットの変更履歴管理</td>
<td>DVC, LakeFS, Delta Lake</td>
</tr>
<tr>
<td><strong>データ品質</strong></td>
<td>データの検証と異常検知</td>
<td>Great Expectations, Deequ</td>
</tr>
<tr>
<td><strong>データ系譜</strong></td>
<td>データの起源と変換履歴</td>
<td>Apache Atlas, Marquez</td>
</tr>
<tr>
<td><strong>特徴量ストア</strong></td>
<td>特徴量の再利用と一貫性</td>
<td>Feast, Tecton</td>
</tr>
</tbody>
</table>

<pre><code class="language-python">"""
データバージョニングの実装例（DVC風）
"""

import os
import hashlib
import json
from pathlib import Path

class SimpleDataVersioning:
    """シンプルなデータバージョニングシステム"""

    def __init__(self, storage_dir='.data_versions'):
        self.storage_dir = Path(storage_dir)
        self.storage_dir.mkdir(exist_ok=True)
        self.manifest_file = self.storage_dir / 'manifest.json'
        self.manifest = self._load_manifest()

    def _load_manifest(self):
        """マニフェストファイルの読み込み"""
        if self.manifest_file.exists():
            with open(self.manifest_file, 'r') as f:
                return json.load(f)
        return {}

    def _save_manifest(self):
        """マニフェストファイルの保存"""
        with open(self.manifest_file, 'w') as f:
            json.dump(self.manifest, f, indent=2)

    def _compute_hash(self, filepath):
        """ファイルのハッシュ値計算"""
        hasher = hashlib.md5()
        with open(filepath, 'rb') as f:
            for chunk in iter(lambda: f.read(4096), b''):
                hasher.update(chunk)
        return hasher.hexdigest()

    def add(self, filepath, version_tag):
        """データファイルをバージョン管理に追加"""
        filepath = Path(filepath)

        if not filepath.exists():
            raise FileNotFoundError(f"{filepath}が見つかりません")

        # ハッシュ値計算
        file_hash = self._compute_hash(filepath)

        # ストレージにコピー
        storage_path = self.storage_dir / f"{version_tag}_{file_hash[:8]}"
        import shutil
        shutil.copy(filepath, storage_path)

        # マニフェスト更新
        self.manifest[version_tag] = {
            'original_path': str(filepath),
            'storage_path': str(storage_path),
            'hash': file_hash,
            'size': filepath.stat().st_size,
            'timestamp': str(pd.Timestamp.now())
        }

        self._save_manifest()

        print(f"✓ {filepath.name}をバージョン{version_tag}として追加")
        print(f"  ハッシュ: {file_hash[:8]}...")

    def checkout(self, version_tag, output_path=None):
        """特定バージョンのデータを取得"""
        if version_tag not in self.manifest:
            raise ValueError(f"バージョン{version_tag}が見つかりません")

        version_info = self.manifest[version_tag]
        storage_path = Path(version_info['storage_path'])

        if output_path is None:
            output_path = version_info['original_path']

        import shutil
        shutil.copy(storage_path, output_path)

        print(f"✓ バージョン{version_tag}をチェックアウト")
        print(f"  出力先: {output_path}")

    def list_versions(self):
        """全バージョンの一覧表示"""
        if not self.manifest:
            print("バージョン管理されたデータはありません")
            return

        print("=== データバージョン一覧 ===")
        for tag, info in self.manifest.items():
            print(f"\nバージョン: {tag}")
            print(f"  パス: {info['original_path']}")
            print(f"  サイズ: {info['size']:,} bytes")
            print(f"  ハッシュ: {info['hash'][:8]}...")
            print(f"  作成日時: {info['timestamp']}")

# 使用例（デモ）
# dvc = SimpleDataVersioning()
# dvc.add('data.csv', 'v1.0.0')
# dvc.add('data.csv', 'v1.1.0')  # データ更新後
# dvc.list_versions()
# dvc.checkout('v1.0.0', 'data_old.csv')
</code></pre>

<h3>2. モデル管理</h3>

<p>モデルのライフサイクル全体を管理：</p>

<table>
<thead>
<tr>
<th>コンポーネント</th>
<th>目的</th>
<th>機能</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>実験トラッキング</strong></td>
<td>実験結果の記録と比較</td>
<td>パラメータ、メトリクス、成果物の記録</td>
</tr>
<tr>
<td><strong>モデルレジストリ</strong></td>
<td>モデルの中央管理</td>
<td>バージョン管理、ステージ管理、承認フロー</td>
</tr>
<tr>
<td><strong>モデルパッケージング</strong></td>
<td>デプロイ可能な形式に変換</td>
<td>依存関係の解決、コンテナ化</td>
</tr>
</tbody>
</table>

<h3>3. インフラ管理</h3>

<p>スケーラブルで再現可能なインフラ：</p>

<table>
<thead>
<tr>
<th>コンポーネント</th>
<th>目的</th>
<th>ツール例</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>コンテナ化</strong></td>
<td>環境の一貫性確保</td>
<td>Docker, Kubernetes</td>
</tr>
<tr>
<td><strong>オーケストレーション</strong></td>
<td>ワークフローの自動化</td>
<td>Airflow, Kubeflow, Argo</td>
</tr>
<tr>
<td><strong>リソース管理</strong></td>
<td>計算リソースの効率的利用</td>
<td>Kubernetes, Ray</td>
</tr>
</tbody>
</table>

<h3>4. ガバナンス</h3>

<p>コンプライアンスと監査対応：</p>

<table>
<thead>
<tr>
<th>要素</th>
<th>内容</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>モデル説明可能性</strong></td>
<td>予測の根拠を説明</td>
</tr>
<tr>
<td><strong>バイアス検出</strong></td>
<td>公平性の検証</td>
</tr>
<tr>
<td><strong>監査ログ</strong></td>
<td>全ての変更履歴を記録</td>
</tr>
<tr>
<td><strong>アクセス制御</strong></td>
<td>権限管理と承認フロー</td>
</tr>
</tbody>
</table>

<hr>

<h2>1.4 MLOpsツールエコシステム</h2>

<h3>実験管理ツール</h3>

<table>
<thead>
<tr>
<th>ツール</th>
<th>特徴</th>
<th>主な用途</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>MLflow</strong></td>
<td>オープンソース、多機能</td>
<td>実験管理、モデルレジストリ、デプロイ</td>
</tr>
<tr>
<td><strong>Weights & Biases</strong></td>
<td>リアルタイム可視化、コラボレーション</td>
<td>実験比較、ハイパーパラメータ最適化</td>
</tr>
<tr>
<td><strong>Neptune.ai</strong></td>
<td>メタデータ管理に特化</td>
<td>長期的な実験管理、チーム協働</td>
</tr>
</tbody>
</table>

<h3>パイプラインオーケストレーション</h3>

<table>
<thead>
<tr>
<th>ツール</th>
<th>特徴</th>
<th>主な用途</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Kubeflow</strong></td>
<td>Kubernetes上のML</td>
<td>エンドツーエンドMLパイプライン</td>
</tr>
<tr>
<td><strong>Apache Airflow</strong></td>
<td>汎用ワークフロー</td>
<td>データパイプライン、スケジューリング</td>
</tr>
<tr>
<td><strong>Prefect</strong></td>
<td>Pythonネイティブ、モダンAPI</td>
<td>データフロー、エラーハンドリング</td>
</tr>
</tbody>
</table>

<h3>モデルデプロイメント</h3>

<table>
<thead>
<tr>
<th>ツール</th>
<th>特徴</th>
<th>主な用途</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>BentoML</strong></td>
<td>モデルサービング特化</td>
<td>REST API、バッチ推論</td>
</tr>
<tr>
<td><strong>Seldon Core</strong></td>
<td>Kubernetes上のデプロイ</td>
<td>マイクロサービス、A/Bテスト</td>
</tr>
<tr>
<td><strong>TensorFlow Serving</strong></td>
<td>TensorFlow専用</td>
<td>高速推論、GPU対応</td>
</tr>
</tbody>
</table>

<h3>モニタリングツール</h3>

<table>
<thead>
<tr>
<th>ツール</th>
<th>特徴</th>
<th>主な用途</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Evidently</strong></td>
<td>データドリフト検出</td>
<td>モデル性能監視、レポート生成</td>
</tr>
<tr>
<td><strong>Prometheus + Grafana</strong></td>
<td>汎用メトリクス監視</td>
<td>システム監視、アラート</td>
</tr>
<tr>
<td><strong>Arize AI</strong></td>
<td>ML特化の可観測性</td>
<td>モデル監視、根本原因分析</td>
</tr>
</tbody>
</table>

<h3>統合プラットフォーム</h3>

<table>
<thead>
<tr>
<th>プラットフォーム</th>
<th>特徴</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>AWS SageMaker</strong></td>
<td>AWSネイティブ、フルマネージド</td>
</tr>
<tr>
<td><strong>Azure ML</strong></td>
<td>Azureエコシステム統合</td>
</tr>
<tr>
<td><strong>Google Vertex AI</strong></td>
<td>GCPサービス統合、AutoML</td>
</tr>
<tr>
<td><strong>Databricks</strong></td>
<td>データ+ML統合、Spark基盤</td>
</tr>
</tbody>
</table>

<hr>

<h2>1.5 MLOpsの成熟度モデル</h2>

<p>組織のMLOps成熟度を評価するフレームワーク（Google提唱）：</p>

<h3>Level 0: Manual Process（手動プロセス）</h3>

<p><strong>特徴</strong>：</p>
<ul>
<li>全てのステップが手動</li>
<li>Jupyter Notebookベースの開発</li>
<li>モデルのデプロイは手作業</li>
<li>再現性なし</li>
</ul>

<p><strong>課題</strong>：</p>
<ul>
<li>スケールしない</li>
<li>エラーが多発</li>
<li>デプロイに時間がかかる</li>
<li>モニタリングなし</li>
</ul>

<h3>Level 1: ML Pipeline Automation（MLパイプライン自動化）</h3>

<p><strong>特徴</strong>：</p>
<ul>
<li>訓練パイプラインの自動化</li>
<li>継続的な訓練（CT: Continuous Training）</li>
<li>実験トラッキング</li>
<li>モデルレジストリの使用</li>
</ul>

<p><strong>実現すること</strong>：</p>
<ul>
<li>新しいデータでの自動再訓練</li>
<li>モデルのバージョニング</li>
<li>基本的なモニタリング</li>
</ul>

<pre><code class="language-python">"""
Level 1の実装例: 自動訓練パイプライン
"""

from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
import mlflow
import schedule
import time

class AutoTrainingPipeline:
    """自動訓練パイプライン"""

    def __init__(self, experiment_name):
        mlflow.set_experiment(experiment_name)
        self.experiment_name = experiment_name

    def create_pipeline(self):
        """MLパイプラインの構築"""
        return Pipeline([
            ('scaler', StandardScaler()),
            ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))
        ])

    def train(self, X_train, y_train, X_val, y_val):
        """訓練実行"""
        with mlflow.start_run():
            # パイプライン作成
            pipeline = self.create_pipeline()

            # 訓練
            pipeline.fit(X_train, y_train)

            # 評価
            train_score = pipeline.score(X_train, y_train)
            val_score = pipeline.score(X_val, y_val)

            # MLflowに記録
            mlflow.log_metric("train_accuracy", train_score)
            mlflow.log_metric("val_accuracy", val_score)
            mlflow.sklearn.log_model(pipeline, "model")

            # モデルレジストリに登録
            if val_score > 0.8:  # 閾値を超えた場合のみ
                mlflow.register_model(
                    f"runs:/{mlflow.active_run().info.run_id}/model",
                    "production_model"
                )
                print(f"✓ 新モデルを登録（検証精度: {val_score:.3f}）")
            else:
                print(f"⚠️  精度が閾値未満（{val_score:.3f} < 0.8）")

            return pipeline

    def scheduled_training(self, data_loader, schedule_time="00:00"):
        """スケジュール訓練"""
        def job():
            print(f"=== 自動訓練開始: {pd.Timestamp.now()} ===")
            X_train, X_val, y_train, y_val = data_loader()
            self.train(X_train, X_val, y_train, y_val)

        # 毎日指定時刻に実行
        schedule.every().day.at(schedule_time).do(job)

        print(f"✓ 自動訓練スケジュール設定: 毎日{schedule_time}")

        # スケジュール実行（実際の環境ではバックグラウンドサービスとして実行）
        # while True:
        #     schedule.run_pending()
        #     time.sleep(60)

# 使用例（デモ）
# def load_latest_data():
#     # 最新データの読み込みロジック
#     return X_train, X_val, y_train, y_val
#
# pipeline = AutoTrainingPipeline("auto_training")
# pipeline.scheduled_training(load_latest_data, "02:00")
</code></pre>

<h3>Level 2: CI/CD Pipeline Automation（CI/CDパイプライン自動化）</h3>

<p><strong>特徴</strong>：</p>
<ul>
<li>完全な自動化（コード変更からデプロイまで）</li>
<li>CI/CD統合</li>
<li>自動テスト（データ、モデル、インフラ）</li>
<li>包括的モニタリング</li>
</ul>

<p><strong>実現すること</strong>：</p>
<ul>
<li>コード変更の自動デプロイ</li>
<li>A/Bテスト</li>
<li>カナリアデプロイメント</li>
<li>自動ロールバック</li>
</ul>

<div class="mermaid">
graph TB
    subgraph "Level 0: Manual"
        A1[Notebook開発] --> A2[手動訓練]
        A2 --> A3[手動デプロイ]
    end

    subgraph "Level 1: ML Pipeline"
        B1[コード開発] --> B2[自動訓練パイプライン]
        B2 --> B3[モデルレジストリ]
        B3 --> B4[手動デプロイ承認]
        B4 --> B5[デプロイ]
    end

    subgraph "Level 2: CI/CD"
        C1[コード変更] --> C2[CI: 自動テスト]
        C2 --> C3[自動訓練]
        C3 --> C4[自動検証]
        C4 --> C5[CD: 自動デプロイ]
        C5 --> C6[モニタリング]
        C6 --> C7{性能OK?}
        C7 -->|No| C8[自動ロールバック]
        C7 -->|Yes| C6
    end

    style A1 fill:#ffebee
    style B2 fill:#fff3e0
    style C5 fill:#e8f5e9
</div>

<h3>成熟度レベルの比較</h3>

<table>
<thead>
<tr>
<th>側面</th>
<th>Level 0</th>
<th>Level 1</th>
<th>Level 2</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>デプロイ頻度</strong></td>
<td>月〜年単位</td>
<td>週〜月単位</td>
<td>日〜週単位</td>
</tr>
<tr>
<td><strong>再現性</strong></td>
<td>低い</td>
<td>中程度</td>
<td>高い</td>
</tr>
<tr>
<td><strong>自動化</strong></td>
<td>なし</td>
<td>訓練のみ</td>
<td>エンドツーエンド</td>
</tr>
<tr>
<td><strong>モニタリング</strong></td>
<td>なし/手動</td>
<td>基本的</td>
<td>包括的</td>
</tr>
<tr>
<td><strong>テスト</strong></td>
<td>なし</td>
<td>モデルのみ</td>
<td>全コンポーネント</td>
</tr>
<tr>
<td><strong>適用規模</strong></td>
<td>1-2モデル</td>
<td>数モデル</td>
<td>多数のモデル</td>
</tr>
</tbody>
</table>

<hr>

<h2>1.6 本章のまとめ</h2>

<h3>学んだこと</h3>

<ol>
<li><p><strong>MLOpsの必要性</strong></p>
<ul>
<li>機械学習プロジェクトの85%が本番環境に到達しない</li>
<li>MLOpsは開発から運用までのギャップを埋める</li>
<li>DevOps、DataOps、MLの統合アプローチ</li>
</ul></li>

<li><p><strong>MLライフサイクル</strong></p>
<ul>
<li>データ収集・準備、モデル開発、デプロイ、モニタリングの4フェーズ</li>
<li>反復的・継続的なプロセス</li>
<li>各フェーズでの自動化と品質保証が重要</li>
</ul></li>

<li><p><strong>主要コンポーネント</strong></p>
<ul>
<li>データ管理: バージョニング、品質、系譜</li>
<li>モデル管理: 実験トラッキング、レジストリ</li>
<li>インフラ管理: コンテナ化、オーケストレーション</li>
<li>ガバナンス: 説明可能性、監査、アクセス制御</li>
</ul></li>

<li><p><strong>ツールエコシステム</strong></p>
<ul>
<li>実験管理: MLflow, Weights & Biases</li>
<li>パイプライン: Kubeflow, Airflow</li>
<li>デプロイ: BentoML, Seldon</li>
<li>モニタリング: Evidently, Prometheus</li>
</ul></li>

<li><p><strong>成熟度モデル</strong></p>
<ul>
<li>Level 0: 完全手動（スケールしない）</li>
<li>Level 1: 訓練パイプライン自動化</li>
<li>Level 2: CI/CD完全自動化（エンタープライズ対応）</li>
</ul></li>
</ol>

<h3>MLOps導入のベストプラクティス</h3>

<table>
<thead>
<tr>
<th>原則</th>
<th>説明</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>小さく始める</strong></td>
<td>Level 0 → Level 1 → Level 2 と段階的に進化</td>
</tr>
<tr>
<td><strong>自動化優先</strong></td>
<td>手作業を最小化し、エラーを削減</td>
</tr>
<tr>
<td><strong>モニタリング必須</strong></td>
<td>本番環境での性能を継続的に監視</td>
</tr>
<tr>
<td><strong>再現性確保</strong></td>
<td>全ての実験とモデルを再現可能に</td>
</tr>
<tr>
<td><strong>チーム協働</strong></td>
<td>データサイエンティストとエンジニアの協力</td>
</tr>
</tbody>
</table>

<h3>次の章へ</h3>

<p>第2章では、<strong>実験管理とモデルトラッキング</strong>を詳しく学びます：</p>
<ul>
<li>MLflowによる実験管理</li>
<li>ハイパーパラメータ最適化</li>
<li>モデルレジストリの活用</li>
<li>実験結果の可視化と比較</li>
<li>チームでの実験共有</li>
</ul>

<hr>

<h2>演習問題</h2>

<h3>問題1（難易度：easy）</h3>
<p>MLOpsとDevOpsの違いを3つ挙げて説明してください。機械学習特有の課題に焦点を当ててください。</p>

<details>
<summary>解答例</summary>

<p><strong>解答</strong>：</p>

<ol>
<li><p><strong>データの扱い</strong></p>
<ul>
<li><strong>DevOps</strong>: コードのバージョン管理が中心</li>
<li><strong>MLOps</strong>: コード、データ、モデルの3つをバージョン管理する必要がある</li>
<li>機械学習では、同じコードでもデータが異なれば結果が変わるため、データのバージョニングが必須</li>
</ul></li>

<li><p><strong>テストの複雑性</strong></p>
<ul>
<li><strong>DevOps</strong>: 決定論的なテスト（同じ入力 → 同じ出力）</li>
<li><strong>MLOps</strong>: 確率的なテスト（モデルの性能、データドリフト、バイアスなど）</li>
<li>モデルのテストは精度だけでなく、公平性、解釈可能性なども評価する必要がある</li>
</ul></li>

<li><p><strong>継続的なモニタリング</strong></p>
<ul>
<li><strong>DevOps</strong>: システムの稼働状態、エラーレートを監視</li>
<li><strong>MLOps</strong>: モデルの性能劣化、データドリフト、予測分布の変化を監視</li>
<li>時間経過によるモデルの劣化が避けられないため、自動再訓練の仕組みが必要</li>
</ul></li>
</ol>

</details>

<h3>問題2（難易度：medium）</h3>
<p>以下のコードを改善して、MLOpsのベストプラクティスに従った実験管理を実装してください。MLflowを使用して、パラメータ、メトリクス、モデルを記録してください。</p>

<pre><code class="language-python">import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

# データ読み込み
df = pd.read_csv('data.csv')
X = df.drop('target', axis=1)
y = df['target']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

# モデル訓練
model = RandomForestClassifier(n_estimators=100)
model.fit(X_train, y_train)

# 評価
y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy}")
</code></pre>

<details>
<summary>解答例</summary>

<pre><code class="language-python">import pandas as pd
import mlflow
import mlflow.sklearn
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
import hashlib
import json

# MLflow実験の設定
mlflow.set_experiment("customer_classification")

# データバージョンの計算
def compute_data_version(df):
    """データのハッシュ値を計算してバージョンとして使用"""
    data_str = pd.util.hash_pandas_object(df).values.tobytes()
    return hashlib.md5(data_str).hexdigest()[:8]

# データ読み込み
df = pd.read_csv('data.csv')
data_version = compute_data_version(df)

X = df.drop('target', axis=1)
y = df['target']

# 実験開始
with mlflow.start_run(run_name="rf_baseline"):

    # ハイパーパラメータの定義
    params = {
        'n_estimators': 100,
        'max_depth': 10,
        'min_samples_split': 5,
        'random_state': 42
    }

    # データ分割（固定シードで再現性確保）
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )

    # パラメータの記録
    mlflow.log_params(params)
    mlflow.log_param("data_version", data_version)
    mlflow.log_param("test_size", 0.2)
    mlflow.log_param("n_train_samples", len(X_train))
    mlflow.log_param("n_test_samples", len(X_test))

    # モデル訓練
    model = RandomForestClassifier(**params)
    model.fit(X_train, y_train)

    # Cross-validation
    cv_scores = cross_val_score(model, X_train, y_train, cv=5)
    mlflow.log_metric("cv_mean_accuracy", cv_scores.mean())
    mlflow.log_metric("cv_std_accuracy", cv_scores.std())

    # テストセットでの評価
    y_pred = model.predict(X_test)

    # 複数のメトリクスを記録
    metrics = {
        'test_accuracy': accuracy_score(y_test, y_pred),
        'test_precision': precision_score(y_test, y_pred, average='weighted'),
        'test_recall': recall_score(y_test, y_pred, average='weighted'),
        'test_f1': f1_score(y_test, y_pred, average='weighted')
    }

    mlflow.log_metrics(metrics)

    # 特徴量重要度の記録
    feature_importance = dict(zip(X.columns, model.feature_importances_))
    mlflow.log_dict(feature_importance, "feature_importance.json")

    # モデルの保存
    mlflow.sklearn.log_model(
        model,
        "model",
        registered_model_name="customer_classifier"
    )

    # タグの設定
    mlflow.set_tag("model_type", "RandomForest")
    mlflow.set_tag("framework", "scikit-learn")
    mlflow.set_tag("environment", "development")

    # 結果の表示
    print("=== 実験結果 ===")
    print(f"Run ID: {mlflow.active_run().info.run_id}")
    print(f"Data Version: {data_version}")
    print(f"\nMetrics:")
    for metric, value in metrics.items():
        print(f"  {metric}: {value:.4f}")
    print(f"\nCV Accuracy: {cv_scores.mean():.4f} ± {cv_scores.std():.4f}")

    # モデルの登録確認
    print(f"\n✓ モデルをMLflowに記録しました")
    print(f"✓ 実験名: customer_classification")
</code></pre>

<p><strong>改善ポイント</strong>：</p>
<ol>
<li>MLflowで実験を管理</li>
<li>データバージョンの記録</li>
<li>全ハイパーパラメータの記録</li>
<li>複数の評価メトリクスを記録</li>
<li>Cross-validationの実施</li>
<li>特徴量重要度の保存</li>
<li>モデルレジストリへの登録</li>
<li>再現性の確保（random_state、stratify）</li>
</ol>

</details>

<h3>問題3（難易度：medium）</h3>
<p>データドリフト検出システムを実装してください。Kolmogorov-Smirnov検定を使用して、新しいデータがベースラインデータと統計的に異なるかを判定し、アラートを出力してください。</p>

<details>
<summary>解答例</summary>

<pre><code class="language-python">import numpy as np
import pandas as pd
from scipy import stats
from datetime import datetime
import json

class DataDriftMonitor:
    """データドリフト監視システム"""

    def __init__(self, baseline_data, threshold=0.05, alert_features=None):
        """
        Args:
            baseline_data: ベースラインデータ（DataFrame）
            threshold: p値の閾値（デフォルト: 0.05）
            alert_features: 監視する特徴量のリスト（Noneの場合は全特徴量）
        """
        self.baseline_data = baseline_data
        self.threshold = threshold
        self.alert_features = alert_features or baseline_data.columns.tolist()
        self.drift_history = []
        self.baseline_stats = self._compute_baseline_stats()

    def _compute_baseline_stats(self):
        """ベースラインの統計量を計算"""
        stats_dict = {}
        for col in self.baseline_data.columns:
            if pd.api.types.is_numeric_dtype(self.baseline_data[col]):
                stats_dict[col] = {
                    'mean': self.baseline_data[col].mean(),
                    'std': self.baseline_data[col].std(),
                    'min': self.baseline_data[col].min(),
                    'max': self.baseline_data[col].max(),
                    'median': self.baseline_data[col].median()
                }
        return stats_dict

    def detect_drift(self, new_data, feature):
        """単一特徴量のドリフト検出"""
        if feature not in self.baseline_data.columns:
            raise ValueError(f"特徴量 {feature} が見つかりません")

        # 数値型のみ処理
        if not pd.api.types.is_numeric_dtype(self.baseline_data[feature]):
            return None

        # KS検定
        baseline_values = self.baseline_data[feature].dropna()
        new_values = new_data[feature].dropna()

        statistic, p_value = stats.ks_2samp(baseline_values, new_values)

        is_drift = p_value < self.threshold

        # 統計量の変化を計算
        baseline_mean = baseline_values.mean()
        new_mean = new_values.mean()
        mean_shift = (new_mean - baseline_mean) / baseline_mean * 100

        drift_info = {
            'timestamp': datetime.now().isoformat(),
            'feature': feature,
            'ks_statistic': float(statistic),
            'p_value': float(p_value),
            'drift_detected': bool(is_drift),
            'baseline_mean': float(baseline_mean),
            'new_mean': float(new_mean),
            'mean_shift_pct': float(mean_shift),
            'n_baseline': len(baseline_values),
            'n_new': len(new_values)
        }

        return drift_info

    def monitor_all_features(self, new_data):
        """全特徴量のドリフト監視"""
        results = []
        alerts = []

        print(f"=== データドリフト監視実行 ===")
        print(f"時刻: {datetime.now()}")
        print(f"監視特徴量数: {len(self.alert_features)}")
        print(f"新データサンプル数: {len(new_data)}\n")

        for feature in self.alert_features:
            if feature not in new_data.columns:
                continue

            drift_info = self.detect_drift(new_data, feature)

            if drift_info is None:
                continue

            results.append(drift_info)
            self.drift_history.append(drift_info)

            # ドリフト検出時のアラート
            if drift_info['drift_detected']:
                alert_msg = (
                    f"⚠️  ドリフト検出: {feature}\n"
                    f"   KS統計量: {drift_info['ks_statistic']:.4f}\n"
                    f"   p値: {drift_info['p_value']:.4f}\n"
                    f"   平均値シフト: {drift_info['mean_shift_pct']:.2f}%"
                )
                alerts.append(alert_msg)
                print(alert_msg + "\n")

        # サマリー
        n_drift = sum(r['drift_detected'] for r in results)
        print(f"=== 監視結果 ===")
        print(f"ドリフト検出: {n_drift}/{len(results)}特徴量")

        if n_drift > len(results) * 0.3:  # 30%以上でアラート
            print("⚠️  警告: 多数の特徴量でドリフトが検出されました")
            print("   モデルの再訓練を推奨します")

        return results, alerts

    def generate_report(self):
        """ドリフトレポート生成"""
        if not self.drift_history:
            return "ドリフト履歴がありません"

        df_history = pd.DataFrame(self.drift_history)

        report = f"""
=== データドリフト監視レポート ===

監視期間: {df_history['timestamp'].min()} ~ {df_history['timestamp'].max()}
総監視回数: {len(df_history)}
ユニーク特徴量数: {df_history['feature'].nunique()}

ドリフト検出サマリー:
{df_history.groupby('feature')['drift_detected'].agg(['sum', 'count']).to_string()}

ドリフト検出率トップ5:
{df_history[df_history['drift_detected']].groupby('feature').size().sort_values(ascending=False).head().to_string()}

平均シフト率（絶対値）トップ5:
{df_history.groupby('feature')['mean_shift_pct'].apply(lambda x: abs(x).mean()).sort_values(ascending=False).head().to_string()}
        """

        return report

    def save_report(self, filepath):
        """レポートをJSONで保存"""
        report_data = {
            'baseline_stats': self.baseline_stats,
            'drift_history': self.drift_history,
            'summary': {
                'total_checks': len(self.drift_history),
                'total_drifts': sum(d['drift_detected'] for d in self.drift_history)
            }
        }

        with open(filepath, 'w') as f:
            json.dump(report_data, f, indent=2)

        print(f"✓ レポート保存: {filepath}")

# 使用例
from sklearn.datasets import make_classification

# ベースラインデータ（訓練時のデータ）
X_baseline, _ = make_classification(
    n_samples=1000, n_features=10, random_state=42
)
df_baseline = pd.DataFrame(
    X_baseline,
    columns=[f'feature_{i}' for i in range(10)]
)

# 新しいデータ（ドリフトあり）
X_new, _ = make_classification(
    n_samples=500, n_features=10, random_state=43
)
# いくつかの特徴量にシフトを追加
X_new[:, 0] += 2.0  # feature_0に大きなシフト
X_new[:, 3] += 0.5  # feature_3に小さなシフト

df_new = pd.DataFrame(
    X_new,
    columns=[f'feature_{i}' for i in range(10)]
)

# ドリフト監視の実行
monitor = DataDriftMonitor(df_baseline, threshold=0.05)
results, alerts = monitor.monitor_all_features(df_new)

# レポート生成
print("\n" + monitor.generate_report())

# レポート保存
monitor.save_report('drift_report.json')
</code></pre>

<p><strong>出力例</strong>：</p>
<pre><code>=== データドリフト監視実行 ===
時刻: 2025-10-21 10:30:45.123456
監視特徴量数: 10
新データサンプル数: 500

⚠️  ドリフト検出: feature_0
   KS統計量: 0.8920
   p値: 0.0000
   平均値シフト: 412.34%

⚠️  ドリフト検出: feature_3
   KS統計量: 0.2145
   p値: 0.0023
   平均値シフト: 87.56%

=== 監視結果 ===
ドリフト検出: 2/10特徴量
</code></pre>

</details>

<h3>問題4（難易度：hard）</h3>
<p>MLOps成熟度レベル1の自動訓練パイプラインを実装してください。以下の機能を含めてください：
<ul>
<li>データの自動取得</li>
<li>前処理パイプライン</li>
<li>モデル訓練</li>
<li>性能評価と閾値判定</li>
<li>MLflowへの記録</li>
<li>条件を満たした場合のみモデルレジストリに登録</li>
</ul>
</p>

<details>
<summary>解答例</summary>

<pre><code class="language-python">import pandas as pd
import numpy as np
import mlflow
import mlflow.sklearn
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import accuracy_score, classification_report
from datetime import datetime
import logging

# ロギング設定
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class AutoMLPipeline:
    """自動ML訓練パイプライン（MLOps Level 1）"""

    def __init__(
        self,
        experiment_name,
        model_name,
        accuracy_threshold=0.75,
        cv_folds=5
    ):
        """
        Args:
            experiment_name: MLflow実験名
            model_name: モデル登録名
            accuracy_threshold: モデル登録の精度閾値
            cv_folds: Cross-validationのフォールド数
        """
        self.experiment_name = experiment_name
        self.model_name = model_name
        self.accuracy_threshold = accuracy_threshold
        self.cv_folds = cv_folds

        # MLflow実験の設定
        mlflow.set_experiment(experiment_name)

        logger.info(f"自動訓練パイプライン初期化完了")
        logger.info(f"実験名: {experiment_name}")
        logger.info(f"精度閾値: {accuracy_threshold}")

    def load_data(self, data_source):
        """データの自動取得"""
        logger.info(f"データ読み込み開始: {data_source}")

        # 実際の環境では、DBやAPIからデータを取得
        # ここではデモ用のデータ生成
        from sklearn.datasets import make_classification

        X, y = make_classification(
            n_samples=1000,
            n_features=20,
            n_informative=15,
            n_redundant=5,
            random_state=42
        )

        df = pd.DataFrame(
            X,
            columns=[f'feature_{i}' for i in range(20)]
        )
        df['target'] = y

        # 意図的に欠損値を追加
        missing_mask = np.random.random(df.shape) < 0.05
        df = df.mask(missing_mask)

        logger.info(f"データ読み込み完了: {len(df)}行, {len(df.columns)}列")
        logger.info(f"欠損値: {df.isnull().sum().sum()}個")

        return df

    def create_preprocessing_pipeline(self):
        """前処理パイプライン作成"""
        return Pipeline([
            ('imputer', SimpleImputer(strategy='mean')),
            ('scaler', StandardScaler())
        ])

    def create_model_pipeline(self, preprocessing_pipeline):
        """モデルパイプライン作成"""
        return Pipeline([
            ('preprocessing', preprocessing_pipeline),
            ('classifier', RandomForestClassifier(
                n_estimators=100,
                max_depth=10,
                random_state=42
            ))
        ])

    def evaluate_model(self, pipeline, X_train, X_test, y_train, y_test):
        """モデル評価"""
        # Cross-validation
        cv_scores = cross_val_score(
            pipeline,
            X_train,
            y_train,
            cv=self.cv_folds,
            scoring='accuracy'
        )

        # テストセット評価
        y_pred = pipeline.predict(X_test)
        test_accuracy = accuracy_score(y_test, y_pred)

        metrics = {
            'cv_mean_accuracy': cv_scores.mean(),
            'cv_std_accuracy': cv_scores.std(),
            'test_accuracy': test_accuracy
        }

        logger.info("モデル評価完了")
        logger.info(f"CV精度: {cv_scores.mean():.4f} ± {cv_scores.std():.4f}")
        logger.info(f"テスト精度: {test_accuracy:.4f}")

        return metrics, y_pred

    def should_register_model(self, metrics):
        """モデル登録判定"""
        test_acc = metrics['test_accuracy']
        cv_acc = metrics['cv_mean_accuracy']

        # 条件1: テスト精度が閾値以上
        # 条件2: CV精度との差が大きすぎない（過学習チェック）
        meets_threshold = test_acc >= self.accuracy_threshold
        not_overfitting = abs(test_acc - cv_acc) < 0.1

        should_register = meets_threshold and not_overfitting

        if should_register:
            logger.info(f"✓ モデル登録条件を満たしました")
        else:
            logger.warning(f"⚠️  モデル登録条件を満たしていません")
            if not meets_threshold:
                logger.warning(f"   精度不足: {test_acc:.4f} < {self.accuracy_threshold}")
            if not not_overfitting:
                logger.warning(f"   過学習の可能性: テスト精度とCV精度の差が大きい")

        return should_register

    def run_training(self, data_source):
        """訓練パイプライン実行"""
        logger.info("=" * 50)
        logger.info(f"自動訓練開始: {datetime.now()}")
        logger.info("=" * 50)

        with mlflow.start_run(run_name=f"auto_training_{datetime.now().strftime('%Y%m%d_%H%M%S')}"):

            # 1. データ読み込み
            df = self.load_data(data_source)

            # データ情報の記録
            mlflow.log_param("n_samples", len(df))
            mlflow.log_param("n_features", len(df.columns) - 1)
            mlflow.log_param("n_missing", df.isnull().sum().sum())

            # 2. データ分割
            X = df.drop('target', axis=1)
            y = df['target']

            X_train, X_test, y_train, y_test = train_test_split(
                X, y,
                test_size=0.2,
                random_state=42,
                stratify=y
            )

            mlflow.log_param("test_size", 0.2)
            mlflow.log_param("n_train", len(X_train))
            mlflow.log_param("n_test", len(X_test))

            # 3. パイプライン作成
            preprocessing_pipeline = self.create_preprocessing_pipeline()
            model_pipeline = self.create_model_pipeline(preprocessing_pipeline)

            # ハイパーパラメータ記録
            model_params = model_pipeline.named_steps['classifier'].get_params()
            mlflow.log_params({
                f"model_{k}": v for k, v in model_params.items()
                if not k.startswith('_')
            })

            # 4. モデル訓練
            logger.info("モデル訓練開始")
            model_pipeline.fit(X_train, y_train)
            logger.info("モデル訓練完了")

            # 5. モデル評価
            metrics, y_pred = self.evaluate_model(
                model_pipeline,
                X_train, X_test,
                y_train, y_test
            )

            # メトリクス記録
            mlflow.log_metrics(metrics)

            # 分類レポート
            report = classification_report(y_test, y_pred, output_dict=True)
            mlflow.log_dict(report, "classification_report.json")

            # 6. モデル保存
            mlflow.sklearn.log_model(
                model_pipeline,
                "model",
                signature=mlflow.models.signature.infer_signature(X_train, y_train)
            )

            # 7. モデル登録判定
            if self.should_register_model(metrics):
                model_uri = f"runs:/{mlflow.active_run().info.run_id}/model"

                mlflow.register_model(
                    model_uri,
                    self.model_name
                )

                logger.info(f"✓ モデルをレジストリに登録: {self.model_name}")
                logger.info(f"  精度: {metrics['test_accuracy']:.4f}")

                # タグ設定
                mlflow.set_tag("registered", "true")
                mlflow.set_tag("stage", "staging")
            else:
                logger.warning("モデルは登録されませんでした")
                mlflow.set_tag("registered", "false")

            # 8. 共通タグ
            mlflow.set_tag("training_type", "automatic")
            mlflow.set_tag("timestamp", datetime.now().isoformat())

            logger.info("=" * 50)
            logger.info(f"自動訓練完了: {datetime.now()}")
            logger.info(f"Run ID: {mlflow.active_run().info.run_id}")
            logger.info("=" * 50)

            return metrics

# 使用例
if __name__ == "__main__":
    # 自動訓練パイプラインの作成
    auto_pipeline = AutoMLPipeline(
        experiment_name="auto_training_demo",
        model_name="auto_classifier",
        accuracy_threshold=0.75,
        cv_folds=5
    )

    # 訓練実行
    metrics = auto_pipeline.run_training(data_source="production_db")

    print("\n=== 最終結果 ===")
    print(f"テスト精度: {metrics['test_accuracy']:.4f}")
    print(f"CV精度: {metrics['cv_mean_accuracy']:.4f} ± {metrics['cv_std_accuracy']:.4f}")
</code></pre>

<p><strong>スケジュール実行の例</strong>：</p>
<pre><code class="language-python">import schedule
import time

def scheduled_training():
    """スケジュール訓練ジョブ"""
    auto_pipeline = AutoMLPipeline(
        experiment_name="scheduled_training",
        model_name="production_model",
        accuracy_threshold=0.80
    )

    try:
        metrics = auto_pipeline.run_training("production_db")
        logger.info(f"スケジュール訓練成功: 精度={metrics['test_accuracy']:.4f}")
    except Exception as e:
        logger.error(f"スケジュール訓練失敗: {str(e)}")

# 毎日午前2時に実行
schedule.every().day.at("02:00").do(scheduled_training)

# 毎週月曜日に実行
# schedule.every().monday.at("02:00").do(scheduled_training)

print("スケジュール訓練を開始します...")
# while True:
#     schedule.run_pending()
#     time.sleep(60)
</code></pre>

</details>

<h3>問題5（難易度：hard）</h3>
<p>MLOps成熟度レベルを評価するチェックリストを作成してください。組織がLevel 0、1、2のどのレベルにあるかを判定できるようにしてください。</p>

<details>
<summary>解答例</summary>

<p><strong>解答</strong>：</p>

<pre><code class="language-python">class MLOpsMaturityAssessment:
    """MLOps成熟度評価システム"""

    def __init__(self):
        self.criteria = {
            'Level 0': {
                'データ管理': [
                    'データはローカルファイルで管理',
                    'データのバージョン管理なし',
                    'データ品質チェックは手動'
                ],
                'モデル開発': [
                    'Jupyter Notebookで開発',
                    '実験の記録は手動（Excelなど）',
                    'ハイパーパラメータは試行錯誤'
                ],
                'デプロイメント': [
                    'モデルのデプロイは手作業',
                    'デプロイ頻度は月〜年単位',
                    '本番環境との整合性確認なし'
                ],
                'モニタリング': [
                    'モデル性能の監視なし',
                    'アラート機能なし',
                    '問題発生時の対応は事後的'
                ]
            },
            'Level 1': {
                'データ管理': [
                    'データバージョニングツール使用（DVC等）',
                    '自動データ品質チェック',
                    'データ系譜の記録'
                ],
                'モデル開発': [
                    '実験管理ツール使用（MLflow等）',
                    'パラメータとメトリクスの自動記録',
                    'モデルレジストリでバージョン管理'
                ],
                'デプロイメント': [
                    '訓練パイプラインの自動化',
                    'モデルのパッケージング',
                    'ステージング環境でのテスト'
                ],
                'モニタリング': [
                    '基本的な性能監視',
                    'データドリフト検出',
                    '手動での再訓練トリガー'
                ]
            },
            'Level 2': {
                'データ管理': [
                    'データパイプラインの完全自動化',
                    '特徴量ストアの活用',
                    'データ品質の継続的監視'
                ],
                'モデル開発': [
                    'CI/CDパイプライン統合',
                    '自動テスト（データ、モデル、インフラ）',
                    '自動ハイパーパラメータ最適化'
                ],
                'デプロイメント': [
                    'コード変更からデプロイまで完全自動',
                    'カナリアデプロイメント/A/Bテスト',
                    '自動ロールバック機能'
                ],
                'モニタリング': [
                    '包括的な可観測性',
                    '自動再訓練トリガー',
                    '異常検知と自動対応'
                ]
            }
        }

        self.scores = {
            'Level 0': 0,
            'Level 1': 0,
            'Level 2': 0
        }

    def assess(self):
        """対話的な成熟度評価"""
        print("=" * 60)
        print("MLOps成熟度評価")
        print("=" * 60)
        print("各質問に 'yes' または 'no' で答えてください\n")

        for level, categories in self.criteria.items():
            print(f"\n### {level}の評価 ###\n")
            level_score = 0
            total_questions = 0

            for category, questions in categories.items():
                print(f"[{category}]")
                for i, question in enumerate(questions, 1):
                    total_questions += 1
                    while True:
                        answer = input(f"  {i}. {question}\n     → ").strip().lower()
                        if answer in ['yes', 'no', 'y', 'n']:
                            if answer in ['yes', 'y']:
                                level_score += 1
                            break
                        else:
                            print("     'yes'または'no'で答えてください")
                print()

            self.scores[level] = (level_score / total_questions) * 100
            print(f"{level}達成度: {self.scores[level]:.1f}%")

        return self.scores

    def determine_level(self):
        """成熟度レベルの判定"""
        # Level 2の基準を70%以上満たす場合
        if self.scores['Level 2'] >= 70:
            return 'Level 2', 'CI/CD完全自動化'

        # Level 1の基準を70%以上満たす場合
        elif self.scores['Level 1'] >= 70:
            return 'Level 1', 'MLパイプライン自動化'

        # それ以外
        else:
            return 'Level 0', '手動プロセス'

    def generate_recommendations(self, current_level):
        """改善推奨事項の生成"""
        recommendations = {
            'Level 0': [
                '1. 実験管理ツール（MLflow）の導入',
                '2. データバージョニング（DVC）の開始',
                '3. 訓練パイプラインのスクリプト化',
                '4. モデルレジストリの構築'
            ],
            'Level 1': [
                '1. CI/CDパイプラインの構築',
                '2. 自動テストの実装',
                '3. モデルモニタリングシステムの強化',
                '4. 自動再訓練の仕組み構築'
            ],
            'Level 2': [
                '1. 高度なA/Bテストフレームワーク',
                '2. マルチモデル管理の最適化',
                '3. MLOpsプラットフォームの統合',
                '4. 組織全体へのベストプラクティス展開'
            ]
        }

        return recommendations.get(current_level, [])

    def print_report(self):
        """評価レポートの出力"""
        print("\n" + "=" * 60)
        print("評価レポート")
        print("=" * 60)

        # スコア表示
        print("\n### 達成度スコア ###")
        for level, score in self.scores.items():
            bar = "█" * int(score / 5) + "░" * (20 - int(score / 5))
            print(f"{level}: {bar} {score:.1f}%")

        # レベル判定
        current_level, description = self.determine_level()
        print(f"\n### 現在の成熟度レベル ###")
        print(f"レベル: {current_level} - {description}")

        # 推奨事項
        print(f"\n### 次のステップへの推奨事項 ###")
        recommendations = self.generate_recommendations(current_level)
        for rec in recommendations:
            print(f"  {rec}")

        print("\n" + "=" * 60)

# 使用例（デモ用の自動評価）
def demo_assessment():
    """デモ用の評価（自動回答）"""
    assessment = MLOpsMaturityAssessment()

    # 模擬スコア（実際は対話的に評価）
    assessment.scores = {
        'Level 0': 90.0,  # Level 0の基準はほぼ満たしている
        'Level 1': 60.0,  # Level 1は部分的に達成
        'Level 2': 20.0   # Level 2はまだ初期段階
    }

    assessment.print_report()

# 実際の評価を実行する場合
# assessment = MLOpsMaturityAssessment()
# assessment.assess()
# assessment.print_report()

# デモ実行
demo_assessment()
</code></pre>

<p><strong>出力例</strong>：</p>
<pre><code>============================================================
評価レポート
============================================================

### 達成度スコア ###
Level 0: ██████████████████░░ 90.0%
Level 1: ████████████░░░░░░░░ 60.0%
Level 2: ████░░░░░░░░░░░░░░░░ 20.0%

### 現在の成熟度レベル ###
レベル: Level 0 - 手動プロセス

### 次のステップへの推奨事項 ###
  1. 実験管理ツール（MLflow）の導入
  2. データバージョニング（DVC）の開始
  3. 訓練パイプラインのスクリプト化
  4. モデルレジストリの構築

============================================================
</code></pre>

<p><strong>評価基準の詳細</strong>：</p>

<table>
<thead>
<tr>
<th>スコア範囲</th>
<th>判定レベル</th>
<th>説明</th>
</tr>
</thead>
<tbody>
<tr>
<td>Level 2 ≥ 70%</td>
<td>Level 2達成</td>
<td>CI/CD完全自動化、エンタープライズ対応</td>
</tr>
<tr>
<td>Level 1 ≥ 70%</td>
<td>Level 1達成</td>
<td>MLパイプライン自動化、スケール可能</td>
</tr>
<tr>
<td>上記以外</td>
<td>Level 0</td>
<td>手動プロセス、改善が必要</td>
</tr>
</tbody>
</table>

</details>

<hr>

<h2>参考文献</h2>

<ol>
<li>Géron, A. (2022). <em>Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow</em> (3rd ed.). O'Reilly Media.</li>
<li>Kreuzberger, D., Kühl, N., & Hirschl, S. (2023). Machine Learning Operations (MLOps): Overview, Definition, and Architecture. <em>IEEE Access</em>, 11, 31866-31879.</li>
<li>Google Cloud. (2023). <em>MLOps: Continuous delivery and automation pipelines in machine learning</em>. https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning</li>
<li>Huyen, C. (2022). <em>Designing Machine Learning Systems</em>. O'Reilly Media.</li>
<li>Treveil, M., et al. (2020). <em>Introducing MLOps</em>. O'Reilly Media.</li>
</ol>

<div class="navigation">
    <a href="index.html" class="nav-button">← シリーズ目次</a>
    <a href="chapter2-experiment-tracking.html" class="nav-button">次の章: 実験管理とモデルトラッキング →</a>
</div>

    </main>

    <footer>
        <p><strong>作成者</strong>: AI Terakoya Content Team</p>
        <p><strong>監修</strong>: Dr. Yusuke Hashimoto（東北大学）</p>
        <p><strong>バージョン</strong>: 1.0 | <strong>作成日</strong>: 2025-10-21</p>
        <p><strong>ライセンス</strong>: Creative Commons BY 4.0</p>
        <p>© 2025 AI Terakoya. All rights reserved.</p>
    </footer>
</body>
</html>
