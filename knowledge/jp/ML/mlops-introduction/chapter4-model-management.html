<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ç¬¬4ç« ï¼šãƒ¢ãƒ‡ãƒ«ç®¡ç†ã¨ãƒ¬ã‚¸ã‚¹ãƒˆãƒª - AI Terakoya</title>

    <style>
        :root {
            --color-primary: #2c3e50;
            --color-primary-dark: #1a252f;
            --color-accent: #7b2cbf;
            --color-accent-light: #9d4edd;
            --color-text: #2d3748;
            --color-text-light: #4a5568;
            --color-bg: #ffffff;
            --color-bg-alt: #f7fafc;
            --color-border: #e2e8f0;
            --color-code-bg: #f8f9fa;
            --color-link: #3182ce;
            --color-link-hover: #2c5aa0;

            --spacing-xs: 0.5rem;
            --spacing-sm: 1rem;
            --spacing-md: 1.5rem;
            --spacing-lg: 2rem;
            --spacing-xl: 3rem;

            --font-body: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            --font-mono: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;

            --border-radius: 8px;
            --box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: var(--font-body);
            line-height: 1.7;
            color: var(--color-text);
            background-color: var(--color-bg);
            font-size: 16px;
        }

        header {
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            padding: var(--spacing-xl) var(--spacing-md);
            margin-bottom: var(--spacing-xl);
            box-shadow: var(--box-shadow);
        }

        .header-content {
            max-width: 900px;
            margin: 0 auto;
        }

        h1 {
            font-size: 2rem;
            font-weight: 700;
            margin-bottom: var(--spacing-sm);
            line-height: 1.2;
        }

        .subtitle {
            font-size: 1.1rem;
            opacity: 0.95;
            font-weight: 400;
            margin-bottom: var(--spacing-md);
        }

        .meta {
            display: flex;
            flex-wrap: wrap;
            gap: var(--spacing-md);
            font-size: 0.9rem;
            opacity: 0.9;
        }

        .meta-item {
            display: flex;
            align-items: center;
            gap: 0.3rem;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 0 var(--spacing-md) var(--spacing-xl);
        }

        h2 {
            font-size: 1.75rem;
            color: var(--color-primary);
            margin-top: var(--spacing-xl);
            margin-bottom: var(--spacing-md);
            padding-bottom: var(--spacing-xs);
            border-bottom: 3px solid var(--color-accent);
        }

        h3 {
            font-size: 1.4rem;
            color: var(--color-primary);
            margin-top: var(--spacing-lg);
            margin-bottom: var(--spacing-sm);
        }

        h4 {
            font-size: 1.1rem;
            color: var(--color-primary-dark);
            margin-top: var(--spacing-md);
            margin-bottom: var(--spacing-sm);
        }

        p {
            margin-bottom: var(--spacing-md);
            color: var(--color-text);
        }

        a {
            color: var(--color-link);
            text-decoration: none;
            transition: color 0.2s;
        }

        a:hover {
            color: var(--color-link-hover);
            text-decoration: underline;
        }

        ul, ol {
            margin-left: var(--spacing-lg);
            margin-bottom: var(--spacing-md);
        }

        li {
            margin-bottom: var(--spacing-xs);
            color: var(--color-text);
        }

        pre {
            background-color: var(--color-code-bg);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            overflow-x: auto;
            margin-bottom: var(--spacing-md);
            font-family: var(--font-mono);
            font-size: 0.9rem;
            line-height: 1.5;
        }

        code {
            font-family: var(--font-mono);
            font-size: 0.9em;
            background-color: var(--color-code-bg);
            padding: 0.2em 0.4em;
            border-radius: 3px;
        }

        pre code {
            background-color: transparent;
            padding: 0;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: var(--spacing-md);
            font-size: 0.95rem;
        }

        th, td {
            border: 1px solid var(--color-border);
            padding: var(--spacing-sm);
            text-align: left;
        }

        th {
            background-color: var(--color-bg-alt);
            font-weight: 600;
            color: var(--color-primary);
        }

        blockquote {
            border-left: 4px solid var(--color-accent);
            padding-left: var(--spacing-md);
            margin: var(--spacing-md) 0;
            color: var(--color-text-light);
            font-style: italic;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        .mermaid {
            text-align: center;
            margin: var(--spacing-lg) 0;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        details {
            background-color: var(--color-bg-alt);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            margin-bottom: var(--spacing-md);
        }

        summary {
            cursor: pointer;
            font-weight: 600;
            color: var(--color-primary);
            user-select: none;
            padding: var(--spacing-xs);
            margin: calc(-1 * var(--spacing-md));
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        summary:hover {
            background-color: rgba(123, 44, 191, 0.1);
        }

        details[open] summary {
            margin-bottom: var(--spacing-md);
            border-bottom: 1px solid var(--color-border);
        }

        .navigation {
            display: flex;
            justify-content: space-between;
            gap: var(--spacing-md);
            margin: var(--spacing-xl) 0;
            padding-top: var(--spacing-lg);
            border-top: 2px solid var(--color-border);
        }

        .nav-button {
            flex: 1;
            padding: var(--spacing-md);
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            border-radius: var(--border-radius);
            text-align: center;
            font-weight: 600;
            transition: transform 0.2s, box-shadow 0.2s;
            box-shadow: var(--box-shadow);
        }

        .nav-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
            text-decoration: none;
        }

        footer {
            margin-top: var(--spacing-xl);
            padding: var(--spacing-lg) var(--spacing-md);
            background-color: var(--color-bg-alt);
            border-top: 1px solid var(--color-border);
            text-align: center;
            font-size: 0.9rem;
            color: var(--color-text-light);
        }
        .disclaimer {
            max-width: 900px;
            margin: 2rem auto;
            padding: 1.5rem;
            background: #f8f9fa;
            border-left: 4px solid #6c757d;
            border-radius: 4px;
        }

        .disclaimer h3 {
            color: #495057;
            margin-bottom: 1rem;
            font-size: 1.1rem;
        }

        .disclaimer ul {
            list-style: none;
            padding-left: 0;
        }

        .disclaimer li {
            padding: 0.5rem 0;
            padding-left: 1.5rem;
            position: relative;
            font-size: 0.9rem;
            color: #6c757d;
            line-height: 1.6;
        }

        .disclaimer li::before {
            content: "âš ï¸";
            position: absolute;
            left: 0;
        }


        @media (max-width: 768px) {
            h1 {
                font-size: 1.5rem;
            }

            h2 {
                font-size: 1.4rem;
            }

            h3 {
                font-size: 1.2rem;
            }

            .meta {
                font-size: 0.85rem;
            }

            .navigation {
                flex-direction: column;
            }

            table {
                font-size: 0.85rem;
            }

            th, td {
                padding: var(--spacing-xs);
            }
        }
    
        
    
        /* Breadcrumb styles */
        .breadcrumb {
            background: #f7fafc;
            padding: 0.75rem 1rem;
            border-bottom: 1px solid #e2e8f0;
            font-size: 0.9rem;
        }

        .breadcrumb-content {
            max-width: 900px;
            margin: 0 auto;
            display: flex;
            align-items: center;
            flex-wrap: wrap;
            gap: 0.5rem;
        }

        .breadcrumb a {
            color: #667eea;
            text-decoration: none;
            transition: color 0.2s;
        }

        .breadcrumb a:hover {
            color: #764ba2;
            text-decoration: underline;
        }

        .breadcrumb-separator {
            color: #a0aec0;
            margin: 0 0.25rem;
        }

        .breadcrumb-current {
            color: #4a5568;
            font-weight: 500;
        }
    </style>

    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
        mermaid.initialize({ startOnLoad: true, theme: 'default' });
    </script>

    <!-- MathJax for LaTeX equation rendering -->
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                displayMath: [['$$', '$$'], ['\\[', '\\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
                ignoreHtmlClass: 'mermaid'
            }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" async></script>
</head>
<body>
            <nav class="breadcrumb">
        <div class="breadcrumb-content">
            <a href="/AI-Knowledge-Notes/knowledge/jp/index.html">AIå¯ºå­å±‹ãƒˆãƒƒãƒ—</a><span class="breadcrumb-separator">â€º</span><a href="/AI-Knowledge-Notes/knowledge/jp/ML/index.html">æ©Ÿæ¢°å­¦ç¿’</a><span class="breadcrumb-separator">â€º</span><a href="/AI-Knowledge-Notes/knowledge/jp/ML/mlops-introduction/index.html">Mlops</a><span class="breadcrumb-separator">â€º</span><span class="breadcrumb-current">Chapter 4</span>
        </div>
    </nav>

        <header>
        <div class="header-content">
            <h1>ç¬¬4ç« ï¼šãƒ¢ãƒ‡ãƒ«ç®¡ç†ã¨ãƒ¬ã‚¸ã‚¹ãƒˆãƒª</h1>
            <p class="subtitle">MLOpsã®åŸºç›¤ - ãƒ¢ãƒ‡ãƒ«ã®ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«ã‚’ç®¡ç†ã™ã‚‹</p>
            <div class="meta">
                <span class="meta-item">ğŸ“– èª­äº†æ™‚é–“: 30-35åˆ†</span>
                <span class="meta-item">ğŸ“Š é›£æ˜“åº¦: ä¸­ç´š</span>
                <span class="meta-item">ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹: 12å€‹</span>
                <span class="meta-item">ğŸ“ æ¼”ç¿’å•é¡Œ: 5å•</span>
            </div>
        </div>
    </header>

    <main class="container">

<h2>å­¦ç¿’ç›®æ¨™</h2>
<p>ã“ã®ç« ã‚’èª­ã‚€ã“ã¨ã§ã€ä»¥ä¸‹ã‚’ç¿’å¾—ã§ãã¾ã™ï¼š</p>
<ul>
<li>âœ… ãƒ¢ãƒ‡ãƒ«ç®¡ç†ã®èª²é¡Œã¨é‡è¦æ€§ã‚’ç†è§£ã™ã‚‹</li>
<li>âœ… MLflow Model Registryã‚’ä½¿ç”¨ã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’ç™»éŒ²ãƒ»ç®¡ç†ã§ãã‚‹</li>
<li>âœ… ãƒ¢ãƒ‡ãƒ«ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ‹ãƒ³ã‚°ã¨ã‚¹ãƒ†ãƒ¼ã‚¸ç®¡ç†ã‚’å®Ÿè£…ã§ãã‚‹</li>
<li>âœ… ãƒ¢ãƒ‡ãƒ«ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã¨ã‚¹ã‚­ãƒ¼ãƒã‚’é©åˆ‡ã«ç®¡ç†ã§ãã‚‹</li>
<li>âœ… ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãƒ³ã‚°ã¨ç•°ãªã‚‹ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’ç†è§£ã™ã‚‹</li>
<li>âœ… ãƒ¢ãƒ‡ãƒ«ã‚¬ãƒãƒŠãƒ³ã‚¹ã¨ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹ã‚’å®Ÿç¾ã§ãã‚‹</li>
</ul>

<hr>

<h2>4.1 ãƒ¢ãƒ‡ãƒ«ç®¡ç†ã®èª²é¡Œ</h2>

<h3>ãƒ¢ãƒ‡ãƒ«ç®¡ç†ã¨ã¯</h3>
<p><strong>ãƒ¢ãƒ‡ãƒ«ç®¡ç†ï¼ˆModel Managementï¼‰</strong>ã¯ã€æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«å…¨ä½“ã‚’ä½“ç³»çš„ã«ç®¡ç†ã™ã‚‹ãƒ—ãƒ­ã‚»ã‚¹ã§ã™ã€‚</p>

<blockquote>
<p>ã€Œé©åˆ‡ãªãƒ¢ãƒ‡ãƒ«ç®¡ç†ãªã—ã«ã€MLOpsã®æˆåŠŸã¯ã‚ã‚Šãˆãªã„ã€- æœ¬ç•ªç’°å¢ƒã§ã®ãƒ¢ãƒ‡ãƒ«é‹ç”¨ã®åŸºç›¤</p>
</blockquote>

<h3>ãƒ¢ãƒ‡ãƒ«ç®¡ç†ã®ä¸»è¦èª²é¡Œ</h3>

<h4>1. ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ãƒ§ãƒ‹ãƒ³ã‚°</h4>

<table>
<thead>
<tr>
<th>èª²é¡Œ</th>
<th>èª¬æ˜</th>
<th>å½±éŸ¿</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®è¿½è·¡</strong></td>
<td>ã©ã®ãƒ¢ãƒ‡ãƒ«ãŒã„ã¤ä½œæˆã•ã‚ŒãŸã‹</td>
<td>å†ç¾æ€§ã®æ¬ å¦‚</td>
</tr>
<tr>
<td><strong>ãƒ¢ãƒ‡ãƒ«ã®æ¯”è¼ƒ</strong></td>
<td>è¤‡æ•°ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®æ€§èƒ½æ¯”è¼ƒ</td>
<td>æœ€é©ãƒ¢ãƒ‡ãƒ«é¸æŠã®å›°é›£</td>
</tr>
<tr>
<td><strong>ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯</strong></td>
<td>å•é¡Œç™ºç”Ÿæ™‚ã®æ—§ãƒãƒ¼ã‚¸ãƒ§ãƒ³å¾©å¸°</td>
<td>ãƒ€ã‚¦ãƒ³ã‚¿ã‚¤ãƒ å¢—åŠ </td>
</tr>
<tr>
<td><strong>ä¾å­˜é–¢ä¿‚ç®¡ç†</strong></td>
<td>ãƒ¢ãƒ‡ãƒ«ã¨å­¦ç¿’ã‚³ãƒ¼ãƒ‰ã®ç´ä»˜ã‘</td>
<td>å†å­¦ç¿’ã®å¤±æ•—</td>
</tr>
</tbody>
</table>

<h4>2. ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç®¡ç†</h4>

<p>ãƒ¢ãƒ‡ãƒ«ã«é–¢ã™ã‚‹é‡è¦æƒ…å ±ã®ç®¡ç†ï¼š</p>
<ul>
<li><strong>å­¦ç¿’ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿</strong>: ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã€å­¦ç¿’ãƒ‡ãƒ¼ã‚¿æƒ…å ±</li>
<li><strong>æ€§èƒ½ãƒ¡ãƒˆãƒªã‚¯ã‚¹</strong>: ç²¾åº¦ã€å†ç¾ç‡ã€F1ã‚¹ã‚³ã‚¢</li>
<li><strong>å…¥å‡ºåŠ›ã‚¹ã‚­ãƒ¼ãƒ</strong>: æœŸå¾…ã•ã‚Œã‚‹å…¥åŠ›å½¢å¼ã¨å‡ºåŠ›å½¢å¼</li>
<li><strong>ä¾å­˜ãƒ©ã‚¤ãƒ–ãƒ©ãƒª</strong>: Pythonã€scikit-learnã€PyTorchã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³</li>
</ul>

<h4>3. ãƒ¢ãƒ‡ãƒ«ã®ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«</h4>

<div class="mermaid">
graph LR
    A[é–‹ç™º] --> B[ã‚¹ãƒ†ãƒ¼ã‚¸ãƒ³ã‚°]
    B --> C[æœ¬ç•ªé‹ç”¨]
    C --> D[ç›£è¦–]
    D --> E{æ€§èƒ½åŠ£åŒ–?}
    E -->|ã¯ã„| F[ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–]
    E -->|ã„ã„ãˆ| C
    F --> A

    style A fill:#fff3e0
    style B fill:#e3f2fd
    style C fill:#c8e6c9
    style D fill:#f3e5f5
    style E fill:#ffebee
    style F fill:#e0e0e0
</div>

<h4>4. ã‚¬ãƒãƒŠãƒ³ã‚¹è¦ä»¶</h4>

<table>
<thead>
<tr>
<th>è¦ä»¶</th>
<th>ç›®çš„</th>
<th>å®Ÿè£…æ–¹æ³•</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>ã‚¢ã‚¯ã‚»ã‚¹åˆ¶å¾¡</strong></td>
<td>æ¨©é™ç®¡ç†</td>
<td>RBACã€APIèªè¨¼</td>
</tr>
<tr>
<td><strong>ç›£æŸ»ãƒ­ã‚°</strong></td>
<td>å¤‰æ›´å±¥æ­´è¿½è·¡</td>
<td>ã‚¤ãƒ™ãƒ³ãƒˆãƒ­ã‚°ã€ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—</td>
</tr>
<tr>
<td><strong>ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹</strong></td>
<td>è¦åˆ¶éµå®ˆ</td>
<td>ãƒ¢ãƒ‡ãƒ«ã‚«ãƒ¼ãƒ‰ã€èª¬æ˜è²¬ä»»</td>
</tr>
<tr>
<td><strong>æ‰¿èªãƒ—ãƒ­ã‚»ã‚¹</strong></td>
<td>å“è³ªä¿è¨¼</td>
<td>ãƒ¬ãƒ“ãƒ¥ãƒ¼ã€ãƒ†ã‚¹ãƒˆ</td>
</tr>
</tbody>
</table>

<h3>ãƒ¢ãƒ‡ãƒ«ç®¡ç†ã®å®Ÿè£…èª²é¡Œ</h3>

<pre><code class="language-python">import os
import json
from datetime import datetime
import numpy as np

# ãƒ¢ãƒ‡ãƒ«ç®¡ç†ã«ãŠã‘ã‚‹å…¸å‹çš„ãªèª²é¡Œã‚’ç¤ºã™ä¾‹

class ModelManagementChallenges:
    """ãƒ¢ãƒ‡ãƒ«ç®¡ç†ã®èª²é¡Œã‚’ç¤ºã™ã‚¯ãƒ©ã‚¹"""

    def __init__(self):
        self.models = {}
        self.challenges = []

    def demonstrate_version_chaos(self):
        """ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ã®æ··ä¹±ã‚’ç¤ºã™"""
        # èª²é¡Œ1: ä¸€è²«æ€§ã®ãªã„ãƒãƒ¼ã‚¸ãƒ§ãƒ³å‘½å
        model_files = [
            "model.pkl",
            "model_v2.pkl",
            "model_final.pkl",
            "model_final_v2.pkl",
            "model_REALLY_final.pkl",
            "model_2024_01_15.pkl"
        ]

        print("=== èª²é¡Œ1: ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ã®æ··ä¹± ===")
        print("éä½“ç³»çš„ãªãƒ•ã‚¡ã‚¤ãƒ«å:")
        for f in model_files:
            print(f"  - {f}")
        print("\nå•é¡Œç‚¹:")
        print("  - ã©ã‚ŒãŒæœ€æ–°ã‹ä¸æ˜")
        print("  - ä½œæˆé †åºãŒä¸æ˜")
        print("  - ãƒãƒ¼ã‚¸ãƒ§ãƒ³é–“ã®é•ã„ãŒä¸æ˜")

        return model_files

    def demonstrate_metadata_loss(self):
        """ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®æ¬ è½ã‚’ç¤ºã™"""
        print("\n=== èª²é¡Œ2: ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®æ¬ è½ ===")

        # ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã ã‘ãŒä¿å­˜ã•ã‚Œã¦ã„ã‚‹çŠ¶æ…‹
        model_info = {
            "filename": "model.pkl",
            "size_mb": 45.2
        }

        print("ä¿å­˜ã•ã‚Œã¦ã„ã‚‹æƒ…å ±:")
        print(json.dumps(model_info, indent=2))

        print("\næ¬ è½ã—ã¦ã„ã‚‹é‡è¦æƒ…å ±:")
        missing_metadata = [
            "å­¦ç¿’ã«ä½¿ç”¨ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ",
            "ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿",
            "æ€§èƒ½ãƒ¡ãƒˆãƒªã‚¯ã‚¹",
            "å…¥å‡ºåŠ›ã‚¹ã‚­ãƒ¼ãƒ",
            "ä¾å­˜ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³",
            "ä½œæˆè€…ã¨ä½œæˆæ—¥æ™‚",
            "å­¦ç¿’ç’°å¢ƒï¼ˆGPUã€CPUä»•æ§˜ï¼‰"
        ]
        for item in missing_metadata:
            print(f"  âŒ {item}")

    def demonstrate_deployment_risk(self):
        """ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆãƒªã‚¹ã‚¯ã‚’ç¤ºã™"""
        print("\n=== èª²é¡Œ3: ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆãƒªã‚¹ã‚¯ ===")

        scenarios = [
            {
                "scenario": "é–“é•ã£ãŸãƒ¢ãƒ‡ãƒ«ã®ãƒ‡ãƒ—ãƒ­ã‚¤",
                "cause": "ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ã®æ¬ å¦‚",
                "impact": "æ€§èƒ½åŠ£åŒ–ã€ãƒ“ã‚¸ãƒã‚¹æå¤±"
            },
            {
                "scenario": "ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯ä¸å¯",
                "cause": "æ—§ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®ä¿å­˜ä¸è¶³",
                "impact": "é•·æ™‚é–“ã®ãƒ€ã‚¦ãƒ³ã‚¿ã‚¤ãƒ "
            },
            {
                "scenario": "ä¾å­˜æ€§ã®ä¸æ•´åˆ",
                "cause": "ç’°å¢ƒæƒ…å ±ã®æœªè¨˜éŒ²",
                "impact": "å®Ÿè¡Œæ™‚ã‚¨ãƒ©ãƒ¼"
            }
        ]

        for s in scenarios:
            print(f"\nã‚·ãƒŠãƒªã‚ª: {s['scenario']}")
            print(f"  åŸå› : {s['cause']}")
            print(f"  å½±éŸ¿: {s['impact']}")

    def demonstrate_governance_gaps(self):
        """ã‚¬ãƒãƒŠãƒ³ã‚¹ã‚®ãƒ£ãƒƒãƒ—ã‚’ç¤ºã™"""
        print("\n=== èª²é¡Œ4: ã‚¬ãƒãƒŠãƒ³ã‚¹ã®æ¬ å¦‚ ===")

        governance_issues = [
            "èª°ãŒãƒ¢ãƒ‡ãƒ«ã‚’æœ¬ç•ªç’°å¢ƒã«ãƒ‡ãƒ—ãƒ­ã‚¤ã—ãŸã‹ä¸æ˜",
            "ãƒ¢ãƒ‡ãƒ«ã®å¤‰æ›´ãŒæ‰¿èªãƒ—ãƒ­ã‚»ã‚¹ãªã—ã§å®Ÿæ–½",
            "ç›£æŸ»ãƒ­ã‚°ãŒå­˜åœ¨ã—ãªã„",
            "ã‚¢ã‚¯ã‚»ã‚¹åˆ¶å¾¡ãŒæœªå®Ÿè£…",
            "ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹è¦ä»¶ãŒæœªå¯¾å¿œ"
        ]

        print("ä¸€èˆ¬çš„ãªã‚¬ãƒãƒŠãƒ³ã‚¹å•é¡Œ:")
        for issue in governance_issues:
            print(f"  âš ï¸  {issue}")

# å®Ÿè¡Œä¾‹
challenges = ModelManagementChallenges()
challenges.demonstrate_version_chaos()
challenges.demonstrate_metadata_loss()
challenges.demonstrate_deployment_risk()
challenges.demonstrate_governance_gaps()

print("\n" + "="*60)
print("çµè«–: ä½“ç³»çš„ãªãƒ¢ãƒ‡ãƒ«ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ãŒå¿…è¦")
print("="*60)
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>=== èª²é¡Œ1: ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ã®æ··ä¹± ===
éä½“ç³»çš„ãªãƒ•ã‚¡ã‚¤ãƒ«å:
  - model.pkl
  - model_v2.pkl
  - model_final.pkl
  - model_final_v2.pkl
  - model_REALLY_final.pkl
  - model_2024_01_15.pkl

å•é¡Œç‚¹:
  - ã©ã‚ŒãŒæœ€æ–°ã‹ä¸æ˜
  - ä½œæˆé †åºãŒä¸æ˜
  - ãƒãƒ¼ã‚¸ãƒ§ãƒ³é–“ã®é•ã„ãŒä¸æ˜

=== èª²é¡Œ2: ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®æ¬ è½ ===
ä¿å­˜ã•ã‚Œã¦ã„ã‚‹æƒ…å ±:
{
  "filename": "model.pkl",
  "size_mb": 45.2
}

æ¬ è½ã—ã¦ã„ã‚‹é‡è¦æƒ…å ±:
  âŒ å­¦ç¿’ã«ä½¿ç”¨ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
  âŒ ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
  âŒ æ€§èƒ½ãƒ¡ãƒˆãƒªã‚¯ã‚¹
  âŒ å…¥å‡ºåŠ›ã‚¹ã‚­ãƒ¼ãƒ
  âŒ ä¾å­˜ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³
  âŒ ä½œæˆè€…ã¨ä½œæˆæ—¥æ™‚
  âŒ å­¦ç¿’ç’°å¢ƒï¼ˆGPUã€CPUä»•æ§˜ï¼‰

=== èª²é¡Œ3: ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆãƒªã‚¹ã‚¯ ===

ã‚·ãƒŠãƒªã‚ª: é–“é•ã£ãŸãƒ¢ãƒ‡ãƒ«ã®ãƒ‡ãƒ—ãƒ­ã‚¤
  åŸå› : ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ã®æ¬ å¦‚
  å½±éŸ¿: æ€§èƒ½åŠ£åŒ–ã€ãƒ“ã‚¸ãƒã‚¹æå¤±

ã‚·ãƒŠãƒªã‚ª: ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯ä¸å¯
  åŸå› : æ—§ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®ä¿å­˜ä¸è¶³
  å½±éŸ¿: é•·æ™‚é–“ã®ãƒ€ã‚¦ãƒ³ã‚¿ã‚¤ãƒ 

ã‚·ãƒŠãƒªã‚ª: ä¾å­˜æ€§ã®ä¸æ•´åˆ
  åŸå› : ç’°å¢ƒæƒ…å ±ã®æœªè¨˜éŒ²
  å½±éŸ¿: å®Ÿè¡Œæ™‚ã‚¨ãƒ©ãƒ¼

=== èª²é¡Œ4: ã‚¬ãƒãƒŠãƒ³ã‚¹ã®æ¬ å¦‚ ===
ä¸€èˆ¬çš„ãªã‚¬ãƒãƒŠãƒ³ã‚¹å•é¡Œ:
  âš ï¸  èª°ãŒãƒ¢ãƒ‡ãƒ«ã‚’æœ¬ç•ªç’°å¢ƒã«ãƒ‡ãƒ—ãƒ­ã‚¤ã—ãŸã‹ä¸æ˜
  âš ï¸  ãƒ¢ãƒ‡ãƒ«ã®å¤‰æ›´ãŒæ‰¿èªãƒ—ãƒ­ã‚»ã‚¹ãªã—ã§å®Ÿæ–½
  âš ï¸  ç›£æŸ»ãƒ­ã‚°ãŒå­˜åœ¨ã—ãªã„
  âš ï¸  ã‚¢ã‚¯ã‚»ã‚¹åˆ¶å¾¡ãŒæœªå®Ÿè£…
  âš ï¸  ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹è¦ä»¶ãŒæœªå¯¾å¿œ

============================================================
çµè«–: ä½“ç³»çš„ãªãƒ¢ãƒ‡ãƒ«ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ãŒå¿…è¦
============================================================
</code></pre>

<hr>

<h2>4.2 ãƒ¢ãƒ‡ãƒ«ãƒ¬ã‚¸ã‚¹ãƒˆãƒª</h2>

<h3>MLflow Model Registryã¨ã¯</h3>

<p><strong>MLflow Model Registry</strong>ã¯ã€æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«å…¨ä½“ã‚’ç®¡ç†ã™ã‚‹ä¸­å¤®ãƒªãƒã‚¸ãƒˆãƒªã§ã™ã€‚</p>

<h3>Model Registryã®ä¸»è¦æ©Ÿèƒ½</h3>

<table>
<thead>
<tr>
<th>æ©Ÿèƒ½</th>
<th>èª¬æ˜</th>
<th>åˆ©ç‚¹</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>ãƒ¢ãƒ‡ãƒ«ç™»éŒ²</strong></td>
<td>ãƒ¢ãƒ‡ãƒ«ã‚’åå‰ä»˜ãã§ç™»éŒ²</td>
<td>çµ±ä¸€çš„ãªç®¡ç†</td>
</tr>
<tr>
<td><strong>ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†</strong></td>
<td>è‡ªå‹•çš„ãªãƒãƒ¼ã‚¸ãƒ§ãƒ³ç•ªå·ä»˜ä¸</td>
<td>å±¥æ­´è¿½è·¡</td>
</tr>
<tr>
<td><strong>ã‚¹ãƒ†ãƒ¼ã‚¸ç®¡ç†</strong></td>
<td>Staging/Production/Archive</td>
<td>ç’°å¢ƒã®æ˜ç¢ºåŒ–</td>
</tr>
<tr>
<td><strong>ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä¿å­˜</strong></td>
<td>èª¬æ˜ã€ã‚¿ã‚°ã€æ³¨é‡ˆ</td>
<td>æ¤œç´¢æ€§å‘ä¸Š</td>
</tr>
<tr>
<td><strong>ã‚¢ã‚¯ã‚»ã‚¹åˆ¶å¾¡</strong></td>
<td>æ¨©é™ãƒ™ãƒ¼ã‚¹ã®ç®¡ç†</td>
<td>ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£</td>
</tr>
</tbody>
</table>

<h3>MLflow Model Registryã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—</h3>

<pre><code class="language-python">import mlflow
import mlflow.sklearn
from mlflow.tracking import MlflowClient
from sklearn.ensemble import RandomForestClassifier
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, f1_score
import numpy as np

# MLflowãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ã‚µãƒ¼ãƒãƒ¼ã®è¨­å®š
mlflow.set_tracking_uri("sqlite:///mlflow.db")
mlflow.set_experiment("model-registry-demo")

# ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆä½œæˆ
client = MlflowClient()

print("=== MLflow Model Registry ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ— ===")
print(f"ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°URI: {mlflow.get_tracking_uri()}")
print(f"å®Ÿé¨“å: {mlflow.get_experiment_by_name('model-registry-demo').name}")

# ãƒ‡ãƒ¼ã‚¿æº–å‚™
X, y = make_classification(
    n_samples=1000,
    n_features=20,
    n_informative=15,
    n_redundant=5,
    random_state=42
)

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

print(f"\nãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ: {X_train.shape[0]} è¨“ç·´, {X_test.shape[0]} ãƒ†ã‚¹ãƒˆ")
</code></pre>

<h3>ãƒ¢ãƒ‡ãƒ«ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ‹ãƒ³ã‚°</h3>

<pre><code class="language-python">def train_and_register_model(model_name, n_estimators, max_depth):
    """ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã—ã¦Model Registryã«ç™»éŒ²"""

    with mlflow.start_run(run_name=f"rf_v{n_estimators}_{max_depth}") as run:
        # ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
        model = RandomForestClassifier(
            n_estimators=n_estimators,
            max_depth=max_depth,
            random_state=42
        )
        model.fit(X_train, y_train)

        # äºˆæ¸¬ã¨è©•ä¾¡
        y_pred = model.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        f1 = f1_score(y_test, y_pred)

        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®ãƒ­ã‚®ãƒ³ã‚°
        mlflow.log_params({
            "n_estimators": n_estimators,
            "max_depth": max_depth
        })
        mlflow.log_metrics({
            "accuracy": accuracy,
            "f1_score": f1
        })

        # ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ã‚®ãƒ³ã‚°
        mlflow.sklearn.log_model(
            sk_model=model,
            artifact_path="model",
            registered_model_name=model_name
        )

        print(f"\nâœ“ ãƒ¢ãƒ‡ãƒ«å­¦ç¿’å®Œäº†: {model_name}")
        print(f"  Run ID: {run.info.run_id}")
        print(f"  Accuracy: {accuracy:.4f}")
        print(f"  F1 Score: {f1:.4f}")

        return run.info.run_id, accuracy, f1

# è¤‡æ•°ã®ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ä½œæˆ
model_name = "credit-risk-classifier"

print("\n=== ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®ä½œæˆ ===")

# ãƒãƒ¼ã‚¸ãƒ§ãƒ³1: å°ã•ãªãƒ¢ãƒ‡ãƒ«
run_id_v1, acc_v1, f1_v1 = train_and_register_model(
    model_name, n_estimators=10, max_depth=5
)

# ãƒãƒ¼ã‚¸ãƒ§ãƒ³2: ä¸­è¦æ¨¡ãƒ¢ãƒ‡ãƒ«
run_id_v2, acc_v2, f1_v2 = train_and_register_model(
    model_name, n_estimators=50, max_depth=10
)

# ãƒãƒ¼ã‚¸ãƒ§ãƒ³3: å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«
run_id_v3, acc_v3, f1_v3 = train_and_register_model(
    model_name, n_estimators=100, max_depth=15
)

# ç™»éŒ²ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®ç¢ºèª
print(f"\n=== {model_name} ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ä¸€è¦§ ===")
for mv in client.search_model_versions(f"name='{model_name}'"):
    print(f"\nãƒãƒ¼ã‚¸ãƒ§ãƒ³: {mv.version}")
    print(f"  Run ID: {mv.run_id}")
    print(f"  ã‚¹ãƒ†ãƒ¼ã‚¸: {mv.current_stage}")
    print(f"  ä½œæˆæ—¥æ™‚: {mv.creation_timestamp}")
</code></pre>

<h3>ã‚¹ãƒ†ãƒ¼ã‚¸é·ç§»ï¼ˆStage Transitionsï¼‰</h3>

<pre><code class="language-python">def transition_model_stage(model_name, version, stage, description=""):
    """ãƒ¢ãƒ‡ãƒ«ã‚’æŒ‡å®šã®ã‚¹ãƒ†ãƒ¼ã‚¸ã«é·ç§»"""

    client.transition_model_version_stage(
        name=model_name,
        version=version,
        stage=stage,
        archive_existing_versions=False
    )

    # èª¬æ˜ã‚’è¿½åŠ 
    if description:
        client.update_model_version(
            name=model_name,
            version=version,
            description=description
        )

    print(f"âœ“ {model_name} v{version} ã‚’ {stage} ã«é·ç§»")

print("\n=== ã‚¹ãƒ†ãƒ¼ã‚¸ç®¡ç† ===")

# ãƒãƒ¼ã‚¸ãƒ§ãƒ³1: Stagingï¼ˆé–‹ç™ºç’°å¢ƒã§ãƒ†ã‚¹ãƒˆä¸­ï¼‰
transition_model_stage(
    model_name,
    version=1,
    stage="Staging",
    description="åˆæœŸãƒ¢ãƒ‡ãƒ«ã€‚è»½é‡ã ãŒç²¾åº¦ã¯ã‚„ã‚„ä½ã„ã€‚"
)

# ãƒãƒ¼ã‚¸ãƒ§ãƒ³2: Productionï¼ˆæœ¬ç•ªç’°å¢ƒï¼‰
transition_model_stage(
    model_name,
    version=2,
    stage="Production",
    description="ç¾åœ¨ã®æœ¬ç•ªãƒ¢ãƒ‡ãƒ«ã€‚ãƒãƒ©ãƒ³ã‚¹ã®å–ã‚ŒãŸæ€§èƒ½ã€‚"
)

# ãƒãƒ¼ã‚¸ãƒ§ãƒ³3: Stagingï¼ˆè©•ä¾¡ä¸­ï¼‰
transition_model_stage(
    model_name,
    version=3,
    stage="Staging",
    description="æœ€æ–°ãƒ¢ãƒ‡ãƒ«ã€‚é«˜ç²¾åº¦ã ãŒæ¨è«–æ™‚é–“ãŒé•·ã„å¯èƒ½æ€§ã€‚"
)

# ã‚¹ãƒ†ãƒ¼ã‚¸åˆ¥ã®ãƒ¢ãƒ‡ãƒ«å–å¾—
print("\n=== ã‚¹ãƒ†ãƒ¼ã‚¸åˆ¥ãƒ¢ãƒ‡ãƒ« ===")

def get_models_by_stage(model_name, stage):
    """ç‰¹å®šã‚¹ãƒ†ãƒ¼ã‚¸ã®ãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—"""
    versions = client.get_latest_versions(model_name, stages=[stage])
    return versions

# Productionç’°å¢ƒã®ãƒ¢ãƒ‡ãƒ«
prod_models = get_models_by_stage(model_name, "Production")
for model in prod_models:
    print(f"\nProduction: {model_name} v{model.version}")
    print(f"  èª¬æ˜: {model.description}")

# Stagingç’°å¢ƒã®ãƒ¢ãƒ‡ãƒ«
staging_models = get_models_by_stage(model_name, "Staging")
print(f"\nStagingç’°å¢ƒã®ãƒ¢ãƒ‡ãƒ«æ•°: {len(staging_models)}")
for model in staging_models:
    print(f"  - v{model.version}: {model.description}")
</code></pre>

<h3>å®Œå…¨ãªãƒ¢ãƒ‡ãƒ«ãƒ¬ã‚¸ã‚¹ãƒˆãƒªã®ä¾‹</h3>

<pre><code class="language-python">class ModelRegistry:
    """MLflow Model Registryã®åŒ…æ‹¬çš„ãªç®¡ç†ã‚¯ãƒ©ã‚¹"""

    def __init__(self, tracking_uri="sqlite:///mlflow.db"):
        mlflow.set_tracking_uri(tracking_uri)
        self.client = MlflowClient()

    def register_model(self, model, model_name, run_id,
                      params, metrics, tags=None):
        """ãƒ¢ãƒ‡ãƒ«ã‚’ç™»éŒ²"""
        # ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ã‚®ãƒ³ã‚°
        with mlflow.start_run(run_id=run_id):
            mlflow.sklearn.log_model(
                sk_model=model,
                artifact_path="model",
                registered_model_name=model_name
            )
            mlflow.log_params(params)
            mlflow.log_metrics(metrics)

            if tags:
                mlflow.set_tags(tags)

        # æœ€æ–°ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’å–å¾—
        versions = self.client.search_model_versions(
            f"name='{model_name}'"
        )
        latest_version = max([int(v.version) for v in versions])

        print(f"âœ“ ãƒ¢ãƒ‡ãƒ«ç™»éŒ²å®Œäº†: {model_name} v{latest_version}")
        return latest_version

    def promote_to_production(self, model_name, version,
                             archive_old=True):
        """ãƒ¢ãƒ‡ãƒ«ã‚’æœ¬ç•ªç’°å¢ƒã«æ˜‡æ ¼"""

        # æ—¢å­˜ã®Productionãƒ¢ãƒ‡ãƒ«ã‚’ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–
        if archive_old:
            prod_models = self.client.get_latest_versions(
                model_name, stages=["Production"]
            )
            for model in prod_models:
                self.client.transition_model_version_stage(
                    name=model_name,
                    version=model.version,
                    stage="Archived"
                )
                print(f"  å¤ã„ãƒãƒ¼ã‚¸ãƒ§ãƒ³ v{model.version} ã‚’ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–")

        # æ–°ã—ã„ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’Productionã«
        self.client.transition_model_version_stage(
            name=model_name,
            version=version,
            stage="Production"
        )

        print(f"âœ“ {model_name} v{version} ã‚’æœ¬ç•ªç’°å¢ƒã«æ˜‡æ ¼")

    def compare_versions(self, model_name, version1, version2):
        """2ã¤ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’æ¯”è¼ƒ"""

        print(f"\n=== {model_name}: v{version1} vs v{version2} ===")

        for version in [version1, version2]:
            mv = self.client.get_model_version(model_name, version)
            run = self.client.get_run(mv.run_id)

            print(f"\nãƒãƒ¼ã‚¸ãƒ§ãƒ³ {version}:")
            print(f"  ã‚¹ãƒ†ãƒ¼ã‚¸: {mv.current_stage}")
            print(f"  ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: {run.data.params}")
            print(f"  ãƒ¡ãƒˆãƒªã‚¯ã‚¹: {run.data.metrics}")

    def get_production_model(self, model_name):
        """æœ¬ç•ªç’°å¢ƒã®ãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—"""
        versions = self.client.get_latest_versions(
            model_name, stages=["Production"]
        )

        if not versions:
            raise ValueError(f"æœ¬ç•ªç’°å¢ƒã« {model_name} ãŒå­˜åœ¨ã—ã¾ã›ã‚“")

        model_uri = f"models:/{model_name}/Production"
        model = mlflow.sklearn.load_model(model_uri)

        print(f"âœ“ æœ¬ç•ªãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿: {model_name} v{versions[0].version}")
        return model

    def add_model_alias(self, model_name, version, alias):
        """ãƒ¢ãƒ‡ãƒ«ã«ã‚¨ã‚¤ãƒªã‚¢ã‚¹ã‚’è¿½åŠ """
        self.client.set_registered_model_alias(
            model_name, alias, version
        )
        print(f"âœ“ ã‚¨ã‚¤ãƒªã‚¢ã‚¹ '{alias}' ã‚’ v{version} ã«è¨­å®š")

    def delete_model_version(self, model_name, version):
        """ç‰¹å®šãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’å‰Šé™¤"""
        self.client.delete_model_version(model_name, version)
        print(f"âœ“ {model_name} v{version} ã‚’å‰Šé™¤")

# ä½¿ç”¨ä¾‹
registry = ModelRegistry()

print("\n=== Model Registryã®é«˜åº¦ãªä½¿ç”¨ä¾‹ ===")

# ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ¯”è¼ƒ
registry.compare_versions(model_name, version1=1, version2=3)

# æœ¬ç•ªç’°å¢ƒã¸ã®ãƒ—ãƒ­ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³
registry.promote_to_production(model_name, version=3, archive_old=True)

# æœ¬ç•ªãƒ¢ãƒ‡ãƒ«ã®å–å¾—ã¨æ¨è«–
prod_model = registry.get_production_model(model_name)
sample_prediction = prod_model.predict(X_test[:5])
print(f"\nã‚µãƒ³ãƒ—ãƒ«äºˆæ¸¬: {sample_prediction}")
</code></pre>

<hr>

<h2>4.3 ãƒ¢ãƒ‡ãƒ«ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç®¡ç†</h2>

<h3>ãƒ¢ãƒ‡ãƒ«ç½²åï¼ˆModel Signatureï¼‰</h3>

<p><strong>ãƒ¢ãƒ‡ãƒ«ç½²å</strong>ã¯ã€ãƒ¢ãƒ‡ãƒ«ã®å…¥å‡ºåŠ›ã‚¹ã‚­ãƒ¼ãƒã‚’å®šç¾©ã—ã€å‹å®‰å…¨æ€§ã‚’ç¢ºä¿ã—ã¾ã™ã€‚</p>

<pre><code class="language-python">import mlflow
from mlflow.models.signature import infer_signature, ModelSignature
from mlflow.types.schema import Schema, ColSpec
import pandas as pd
import numpy as np
from sklearn.ensemble import GradientBoostingClassifier

# ãƒ‡ãƒ¼ã‚¿æº–å‚™
X_train_df = pd.DataFrame(X_train, columns=[f"feature_{i}" for i in range(20)])
y_train_series = pd.Series(y_train, name="target")

# ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
model = GradientBoostingClassifier(n_estimators=100, random_state=42)
model.fit(X_train_df, y_train_series)

# äºˆæ¸¬
predictions = model.predict(X_train_df[:5])
predict_proba = model.predict_proba(X_train_df[:5])

print("=== ãƒ¢ãƒ‡ãƒ«ç½²åã®ä½œæˆ ===\n")

# æ–¹æ³•1: è‡ªå‹•æ¨è«–
signature = infer_signature(X_train_df, predictions)
print("è‡ªå‹•æ¨è«–ã•ã‚ŒãŸç½²å:")
print(signature)

# æ–¹æ³•2: æ˜ç¤ºçš„ã«å®šç¾©
from mlflow.types import Schema, ColSpec

input_schema = Schema([
    ColSpec("double", f"feature_{i}") for i in range(20)
])

output_schema = Schema([ColSpec("long")])

explicit_signature = ModelSignature(
    inputs=input_schema,
    outputs=output_schema
)

print("\næ˜ç¤ºçš„ã«å®šç¾©ã—ãŸç½²å:")
print(explicit_signature)

# ç½²åä»˜ãã§ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜
with mlflow.start_run(run_name="model-with-signature"):
    mlflow.sklearn.log_model(
        sk_model=model,
        artifact_path="model",
        signature=signature,
        input_example=X_train_df[:5]
    )

    print("\nâœ“ ç½²åä»˜ããƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜")

# ç½²åã®æ¤œè¨¼
print("\n=== ç½²åã®æ¤œè¨¼ ===")

# æ­£ã—ã„å…¥åŠ›
correct_input = pd.DataFrame(
    np.random.randn(3, 20),
    columns=[f"feature_{i}" for i in range(20)]
)
print("âœ“ æ­£ã—ã„å…¥åŠ›å½¢å¼: OK")

# é–“é•ã£ãŸå…¥åŠ›ï¼ˆåˆ—æ•°ãŒç•°ãªã‚‹ï¼‰
try:
    wrong_input = pd.DataFrame(
        np.random.randn(3, 15),  # åˆ—æ•°ãŒå°‘ãªã„
        columns=[f"feature_{i}" for i in range(15)]
    )
    # MLflowãŒç½²åã‚’ãƒã‚§ãƒƒã‚¯
    print("âŒ é–“é•ã£ãŸå…¥åŠ›å½¢å¼: ã‚¨ãƒ©ãƒ¼ãŒæ¤œå‡ºã•ã‚Œã‚‹ã¹ã")
except Exception as e:
    print(f"âœ“ ã‚¨ãƒ©ãƒ¼æ¤œå‡º: {type(e).__name__}")
</code></pre>

<h3>å…¥å‡ºåŠ›ã‚¹ã‚­ãƒ¼ãƒç®¡ç†</h3>

<pre><code class="language-python">from mlflow.types.schema import Schema, ColSpec, DataType
from mlflow.models.signature import ModelSignature
import json

class SchemaManager:
    """ãƒ¢ãƒ‡ãƒ«ã‚¹ã‚­ãƒ¼ãƒã®ç®¡ç†ã‚¯ãƒ©ã‚¹"""

    @staticmethod
    def create_detailed_schema(feature_info):
        """è©³ç´°ãªã‚¹ã‚­ãƒ¼ãƒã‚’ä½œæˆ"""

        col_specs = []
        for name, dtype, description in feature_info:
            col_spec = ColSpec(
                type=dtype,
                name=name
            )
            col_specs.append(col_spec)

        return Schema(col_specs)

    @staticmethod
    def validate_input(data, schema):
        """å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ãŒã‚¹ã‚­ãƒ¼ãƒã«é©åˆã™ã‚‹ã‹æ¤œè¨¼"""

        errors = []

        # åˆ—æ•°ãƒã‚§ãƒƒã‚¯
        if len(data.columns) != len(schema.inputs):
            errors.append(
                f"åˆ—æ•°ãŒä¸ä¸€è‡´: æœŸå¾…={len(schema.inputs)}, "
                f"å®Ÿéš›={len(data.columns)}"
            )

        # åˆ—åãƒã‚§ãƒƒã‚¯
        expected_cols = [col.name for col in schema.inputs]
        actual_cols = list(data.columns)

        if expected_cols != actual_cols:
            errors.append(f"åˆ—åãŒä¸ä¸€è‡´: {set(expected_cols) ^ set(actual_cols)}")

        # ãƒ‡ãƒ¼ã‚¿å‹ãƒã‚§ãƒƒã‚¯
        for col_spec in schema.inputs:
            if col_spec.name in data.columns:
                actual_dtype = data[col_spec.name].dtype
                # ç°¡æ˜“çš„ãªå‹ãƒã‚§ãƒƒã‚¯
                if col_spec.type == DataType.double:
                    if not np.issubdtype(actual_dtype, np.floating):
                        errors.append(
                            f"{col_spec.name}: å‹ä¸ä¸€è‡´ "
                            f"(æœŸå¾…=float, å®Ÿéš›={actual_dtype})"
                        )

        return len(errors) == 0, errors

    @staticmethod
    def export_schema_json(signature, filepath):
        """ã‚¹ã‚­ãƒ¼ãƒã‚’JSONå½¢å¼ã§ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""

        schema_dict = {
            "inputs": [
                {
                    "name": col.name,
                    "type": str(col.type)
                }
                for col in signature.inputs.inputs
            ],
            "outputs": [
                {
                    "name": col.name if hasattr(col, 'name') else "prediction",
                    "type": str(col.type)
                }
                for col in signature.outputs.inputs
            ]
        }

        with open(filepath, 'w') as f:
            json.dump(schema_dict, f, indent=2)

        print(f"âœ“ ã‚¹ã‚­ãƒ¼ãƒã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ: {filepath}")

# ä½¿ç”¨ä¾‹
print("\n=== è©³ç´°ãªã‚¹ã‚­ãƒ¼ãƒç®¡ç† ===")

# ç‰¹å¾´é‡æƒ…å ±ã®å®šç¾©
feature_info = [
    ("age", DataType.long, "å¹´é½¢"),
    ("income", DataType.double, "å¹´å"),
    ("credit_score", DataType.double, "ä¿¡ç”¨ã‚¹ã‚³ã‚¢"),
    ("loan_amount", DataType.double, "ãƒ­ãƒ¼ãƒ³é‡‘é¡"),
]

# ã‚¹ã‚­ãƒ¼ãƒä½œæˆ
manager = SchemaManager()
input_schema = manager.create_detailed_schema(feature_info)

output_schema = Schema([
    ColSpec(DataType.long, "prediction"),
    ColSpec(DataType.double, "probability")
])

signature = ModelSignature(inputs=input_schema, outputs=output_schema)

print("ä½œæˆã•ã‚ŒãŸã‚¹ã‚­ãƒ¼ãƒ:")
print(signature)

# ã‚¹ã‚­ãƒ¼ãƒã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
manager.export_schema_json(signature, "model_schema.json")

# æ¤œè¨¼ä¾‹
test_data_valid = pd.DataFrame({
    "age": [35, 42],
    "income": [50000.0, 75000.0],
    "credit_score": [720.0, 680.0],
    "loan_amount": [25000.0, 40000.0]
})

test_data_invalid = pd.DataFrame({
    "age": [35, 42],
    "income": [50000.0, 75000.0],
    "credit_score": [720.0, 680.0]
    # loan_amount ãŒæ¬ è½
})

print("\n=== å…¥åŠ›æ¤œè¨¼ ===")

valid, errors = manager.validate_input(test_data_valid, signature)
print(f"æœ‰åŠ¹ãªå…¥åŠ›: {valid}")

valid, errors = manager.validate_input(test_data_invalid, signature)
print(f"ç„¡åŠ¹ãªå…¥åŠ›: {valid}")
if errors:
    for error in errors:
        print(f"  - {error}")
</code></pre>

<h3>ä¾å­˜é–¢ä¿‚ç®¡ç†</h3>

<pre><code class="language-python">import mlflow
from mlflow.models import make_metric
import cloudpickle
import sys

def log_model_with_dependencies(model, model_name, conda_env=None,
                                pip_requirements=None):
    """ä¾å­˜é–¢ä¿‚ã‚’å«ã‚ã¦ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜"""

    with mlflow.start_run(run_name="model-with-deps"):

        # ç¾åœ¨ã®ç’°å¢ƒæƒ…å ±ã‚’ãƒ­ã‚®ãƒ³ã‚°
        mlflow.log_param("python_version", sys.version)
        mlflow.log_param("mlflow_version", mlflow.__version__)

        # Condaç’°å¢ƒã®å®šç¾©
        if conda_env is None:
            conda_env = {
                "name": "model_env",
                "channels": ["conda-forge"],
                "dependencies": [
                    f"python={sys.version_info.major}.{sys.version_info.minor}",
                    "pip",
                    {
                        "pip": [
                            f"mlflow=={mlflow.__version__}",
                            "scikit-learn==1.3.0",
                            "pandas==2.0.3",
                            "numpy==1.24.3"
                        ]
                    }
                ]
            }

        # pip requirements
        if pip_requirements is None:
            pip_requirements = [
                "scikit-learn==1.3.0",
                "pandas==2.0.3",
                "numpy==1.24.3"
            ]

        # ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜
        mlflow.sklearn.log_model(
            sk_model=model,
            artifact_path="model",
            conda_env=conda_env,
            pip_requirements=pip_requirements,
            registered_model_name=model_name
        )

        print(f"âœ“ ãƒ¢ãƒ‡ãƒ«ã¨ä¾å­˜é–¢ä¿‚ã‚’ä¿å­˜: {model_name}")
        print(f"\nCondaç’°å¢ƒ:")
        print(f"  Python: {conda_env['dependencies'][0]}")
        print(f"  ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸: {len(pip_requirements)} å€‹")

        return mlflow.active_run().info.run_id

# ä½¿ç”¨ä¾‹
print("=== ä¾å­˜é–¢ä¿‚ã‚’å«ã‚€ãƒ¢ãƒ‡ãƒ«ä¿å­˜ ===\n")

model = GradientBoostingClassifier(n_estimators=50, random_state=42)
model.fit(X_train, y_train)

run_id = log_model_with_dependencies(
    model=model,
    model_name="credit-model-with-deps"
)

print(f"\nRun ID: {run_id}")
</code></pre>

<h3>ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹ç®¡ç†</h3>

<pre><code class="language-python">from sklearn.metrics import (
    accuracy_score, precision_score, recall_score,
    f1_score, roc_auc_score, confusion_matrix
)
import json
from datetime import datetime

class PerformanceMetricsManager:
    """ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®åŒ…æ‹¬çš„ç®¡ç†"""

    def __init__(self):
        self.metrics_history = []

    def compute_classification_metrics(self, y_true, y_pred, y_prob=None):
        """åˆ†é¡å•é¡Œã®åŒ…æ‹¬çš„ãªãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è¨ˆç®—"""

        metrics = {
            "accuracy": accuracy_score(y_true, y_pred),
            "precision": precision_score(y_true, y_pred, average='binary'),
            "recall": recall_score(y_true, y_pred, average='binary'),
            "f1_score": f1_score(y_true, y_pred, average='binary')
        }

        if y_prob is not None:
            metrics["roc_auc"] = roc_auc_score(y_true, y_prob)

        # æ··åŒè¡Œåˆ—
        cm = confusion_matrix(y_true, y_pred)
        metrics["confusion_matrix"] = {
            "tn": int(cm[0, 0]),
            "fp": int(cm[0, 1]),
            "fn": int(cm[1, 0]),
            "tp": int(cm[1, 1])
        }

        # ãƒ“ã‚¸ãƒã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹
        metrics["false_positive_rate"] = cm[0, 1] / (cm[0, 0] + cm[0, 1])
        metrics["false_negative_rate"] = cm[1, 0] / (cm[1, 0] + cm[1, 1])

        return metrics

    def log_metrics_to_mlflow(self, metrics, model_version=None):
        """ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’MLflowã«ãƒ­ã‚®ãƒ³ã‚°"""

        # æ··åŒè¡Œåˆ—ã¯åˆ¥é€”ä¿å­˜
        cm = metrics.pop("confusion_matrix", None)

        # ã‚¹ã‚«ãƒ©ãƒ¼ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ãƒ­ã‚°
        mlflow.log_metrics(metrics)

        # æ··åŒè¡Œåˆ—ã‚’JSONå½¢å¼ã§ä¿å­˜
        if cm:
            mlflow.log_dict(cm, "confusion_matrix.json")

        # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ãã§å±¥æ­´ã«è¿½åŠ 
        metrics_with_time = {
            "timestamp": datetime.now().isoformat(),
            "model_version": model_version,
            **metrics,
            "confusion_matrix": cm
        }
        self.metrics_history.append(metrics_with_time)

        print("âœ“ ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’MLflowã«ãƒ­ã‚®ãƒ³ã‚°")

    def compare_model_performance(self, metrics1, metrics2,
                                  model1_name="Model 1",
                                  model2_name="Model 2"):
        """2ã¤ã®ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’æ¯”è¼ƒ"""

        print(f"\n=== {model1_name} vs {model2_name} ===\n")

        comparison = {}
        for metric in ["accuracy", "precision", "recall", "f1_score", "roc_auc"]:
            if metric in metrics1 and metric in metrics2:
                val1 = metrics1[metric]
                val2 = metrics2[metric]
                diff = val2 - val1
                pct_change = (diff / val1) * 100 if val1 > 0 else 0

                comparison[metric] = {
                    model1_name: val1,
                    model2_name: val2,
                    "difference": diff,
                    "pct_change": pct_change
                }

                print(f"{metric}:")
                print(f"  {model1_name}: {val1:.4f}")
                print(f"  {model2_name}: {val2:.4f}")
                print(f"  å·®åˆ†: {diff:+.4f} ({pct_change:+.2f}%)")
                print()

        return comparison

    def export_metrics_report(self, filepath="metrics_report.json"):
        """ãƒ¡ãƒˆãƒªã‚¯ã‚¹å±¥æ­´ã‚’ãƒ¬ãƒãƒ¼ãƒˆã¨ã—ã¦ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""

        with open(filepath, 'w') as f:
            json.dump(self.metrics_history, f, indent=2)

        print(f"âœ“ ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒ¬ãƒãƒ¼ãƒˆã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ: {filepath}")

# ä½¿ç”¨ä¾‹
print("\n=== ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹ç®¡ç† ===")

metrics_manager = PerformanceMetricsManager()

# ãƒ¢ãƒ‡ãƒ«1ã®è©•ä¾¡
model1 = RandomForestClassifier(n_estimators=10, random_state=42)
model1.fit(X_train, y_train)
y_pred1 = model1.predict(X_test)
y_prob1 = model1.predict_proba(X_test)[:, 1]

metrics1 = metrics_manager.compute_classification_metrics(
    y_test, y_pred1, y_prob1
)

# ãƒ¢ãƒ‡ãƒ«2ã®è©•ä¾¡
model2 = RandomForestClassifier(n_estimators=100, random_state=42)
model2.fit(X_train, y_train)
y_pred2 = model2.predict(X_test)
y_prob2 = model2.predict_proba(X_test)[:, 1]

metrics2 = metrics_manager.compute_classification_metrics(
    y_test, y_pred2, y_prob2
)

# æ¯”è¼ƒ
comparison = metrics_manager.compare_model_performance(
    metrics1, metrics2,
    model1_name="RF-10",
    model2_name="RF-100"
)

# MLflowã«ãƒ­ã‚®ãƒ³ã‚°
with mlflow.start_run(run_name="rf-10"):
    metrics_manager.log_metrics_to_mlflow(metrics1.copy(), model_version=1)

with mlflow.start_run(run_name="rf-100"):
    metrics_manager.log_metrics_to_mlflow(metrics2.copy(), model_version=2)

# ãƒ¬ãƒãƒ¼ãƒˆã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
metrics_manager.export_metrics_report()
</code></pre>

<hr>

<h2>4.4 ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãƒ³ã‚°</h2>

<h3>ONNXãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ</h3>

<p><strong>ONNXï¼ˆOpen Neural Network Exchangeï¼‰</strong>ã¯ã€ç•°ãªã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯é–“ã§ãƒ¢ãƒ‡ãƒ«ã‚’äº¤æ›å¯èƒ½ã«ã™ã‚‹ã‚ªãƒ¼ãƒ—ãƒ³ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§ã™ã€‚</p>

<pre><code class="language-python">import numpy as np
from sklearn.ensemble import RandomForestClassifier
from skl2onnx import convert_sklearn
from skl2onnx.common.data_types import FloatTensorType
import onnxruntime as rt
import mlflow

print("=== ONNXãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã¸ã®å¤‰æ› ===\n")

# ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
model = RandomForestClassifier(n_estimators=10, max_depth=5, random_state=42)
model.fit(X_train, y_train)

# ONNXå½¢å¼ã«å¤‰æ›
initial_type = [('float_input', FloatTensorType([None, X_train.shape[1]]))]

onnx_model = convert_sklearn(
    model,
    initial_types=initial_type,
    target_opset=12
)

# ONNX ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜
onnx_path = "model.onnx"
with open(onnx_path, "wb") as f:
    f.write(onnx_model.SerializeToString())

print(f"âœ“ ONNXãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜: {onnx_path}")

# ONNX Runtimeã§æ¨è«–
print("\n=== ONNX Runtimeã§ã®æ¨è«– ===")

sess = rt.InferenceSession(onnx_path)

input_name = sess.get_inputs()[0].name
output_name = sess.get_outputs()[0].name

# æ¨è«–å®Ÿè¡Œ
X_test_float = X_test.astype(np.float32)
onnx_pred = sess.run([output_name], {input_name: X_test_float})[0]

# scikit-learnã®äºˆæ¸¬ã¨æ¯”è¼ƒ
sklearn_pred = model.predict(X_test)

print(f"ONNXäºˆæ¸¬: {onnx_pred[:5]}")
print(f"sklearnäºˆæ¸¬: {sklearn_pred[:5]}")
print(f"ä¸€è‡´ç‡: {np.mean(onnx_pred == sklearn_pred):.2%}")

# MLflowã«ä¿å­˜
with mlflow.start_run(run_name="onnx-model"):
    mlflow.onnx.log_model(onnx_model, "onnx_model")
    mlflow.log_metric("accuracy", accuracy_score(y_test, onnx_pred))
    print("\nâœ“ ONNXãƒ¢ãƒ‡ãƒ«ã‚’MLflowã«ä¿å­˜")

print("\nåˆ©ç‚¹:")
print("  - ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯éä¾å­˜")
print("  - é«˜é€Ÿæ¨è«–")
print("  - ã‚¨ãƒƒã‚¸ãƒ‡ãƒã‚¤ã‚¹å¯¾å¿œ")
print("  - ã‚¯ãƒ­ã‚¹ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ")
</code></pre>

<h3>BentoML</h3>

<p><strong>BentoML</strong>ã¯ã€MLãƒ¢ãƒ‡ãƒ«ã‚’æœ¬ç•ªç’°å¢ƒç”¨ã®APIã‚µãƒ¼ãƒ“ã‚¹ã¨ã—ã¦ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸åŒ–ã™ã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã™ã€‚</p>

<pre><code class="language-python">import bentoml
from bentoml.io import NumpyNdarray, JSON
import numpy as np
from sklearn.ensemble import GradientBoostingClassifier

print("=== BentoMLã§ã®ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãƒ³ã‚° ===\n")

# ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
model = GradientBoostingClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# BentoMLã«ä¿å­˜
saved_model = bentoml.sklearn.save_model(
    "credit_risk_model",
    model,
    signatures={
        "predict": {
            "batchable": True,
            "batch_dim": 0,
        }
    },
    labels={
        "owner": "data-science-team",
        "stage": "production"
    },
    metadata={
        "accuracy": float(accuracy_score(y_test, model.predict(X_test))),
        "model_type": "GradientBoosting",
        "features": X_train.shape[1]
    }
)

print(f"âœ“ ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜: {saved_model.tag}")
print(f"  ä¿å­˜å…ˆ: {saved_model.path}")

# ã‚µãƒ¼ãƒ“ã‚¹å®šç¾©ã®ä½œæˆ
service_code = '''
import bentoml
import numpy as np
from bentoml.io import NumpyNdarray, JSON

# ãƒ¢ãƒ‡ãƒ«ã®å‚ç…§ã‚’å–å¾—
credit_model_runner = bentoml.sklearn.get("credit_risk_model:latest").to_runner()

# ã‚µãƒ¼ãƒ“ã‚¹ã®å®šç¾©
svc = bentoml.Service("credit_risk_classifier", runners=[credit_model_runner])

@svc.api(input=NumpyNdarray(), output=JSON())
async def classify(input_data: np.ndarray) -> dict:
    """ä¿¡ç”¨ãƒªã‚¹ã‚¯åˆ†é¡API"""

    # äºˆæ¸¬å®Ÿè¡Œ
    prediction = await credit_model_runner.predict.async_run(input_data)
    probabilities = await credit_model_runner.predict_proba.async_run(input_data)

    return {
        "predictions": prediction.tolist(),
        "probabilities": probabilities.tolist()
    }
'''

# service.pyã¨ã—ã¦ä¿å­˜
with open("service.py", "w") as f:
    f.write(service_code)

print("\nâœ“ ã‚µãƒ¼ãƒ“ã‚¹å®šç¾©ã‚’ä½œæˆ: service.py")

# Bentoã®ä½œæˆè¨­å®š
bentofile_content = '''
service: "service:svc"
labels:
  owner: data-science-team
  project: credit-risk
include:
  - "service.py"
python:
  packages:
    - scikit-learn==1.3.0
    - pandas==2.0.3
    - numpy==1.24.3
'''

with open("bentofile.yaml", "w") as f:
    f.write(bentofile_content)

print("âœ“ Bentoè¨­å®šã‚’ä½œæˆ: bentofile.yaml")

print("\næ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
print("  1. bentoml build  # Bentoã‚’ãƒ“ãƒ«ãƒ‰")
print("  2. bentoml containerize credit_risk_classifier:latest  # Dockerã‚¤ãƒ¡ãƒ¼ã‚¸ä½œæˆ")
print("  3. bentoml serve service:svc  # ãƒ­ãƒ¼ã‚«ãƒ«ã§ã‚µãƒ¼ãƒ“ã‚¹èµ·å‹•")

print("\nBentoMLã®åˆ©ç‚¹:")
print("  - ç°¡å˜ãªAPIåŒ–")
print("  - è‡ªå‹•ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°")
print("  - ãƒãƒƒãƒå‡¦ç†å¯¾å¿œ")
print("  - ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°çµ±åˆ")
print("  - Dockerã‚³ãƒ³ãƒ†ãƒŠåŒ–")
</code></pre>

<h3>TorchScript</h3>

<p><strong>TorchScript</strong>ã¯ã€PyTorchãƒ¢ãƒ‡ãƒ«ã‚’æœ€é©åŒ–ãƒ»ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚ºã™ã‚‹å½¢å¼ã§ã™ã€‚</p>

<pre><code class="language-python">import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import TensorDataset, DataLoader

print("=== TorchScriptã§ã®ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãƒ³ã‚° ===\n")

# ç°¡å˜ãªãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å®šç¾©
class SimpleClassifier(nn.Module):
    def __init__(self, input_size, hidden_size, num_classes):
        super(SimpleClassifier, self).__init__()
        self.fc1 = nn.Linear(input_size, hidden_size)
        self.fc2 = nn.Linear(hidden_size, hidden_size)
        self.fc3 = nn.Linear(hidden_size, num_classes)
        self.dropout = nn.Dropout(0.2)

    def forward(self, x):
        x = F.relu(self.fc1(x))
        x = self.dropout(x)
        x = F.relu(self.fc2(x))
        x = self.dropout(x)
        x = self.fc3(x)
        return x

# ãƒ¢ãƒ‡ãƒ«ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–
input_size = X_train.shape[1]
hidden_size = 64
num_classes = 2

model = SimpleClassifier(input_size, hidden_size, num_classes)

# ç°¡æ˜“å­¦ç¿’
X_train_tensor = torch.FloatTensor(X_train)
y_train_tensor = torch.LongTensor(y_train)

dataset = TensorDataset(X_train_tensor, y_train_tensor)
dataloader = DataLoader(dataset, batch_size=32, shuffle=True)

criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

# å­¦ç¿’ãƒ«ãƒ¼ãƒ—ï¼ˆç°¡ç•¥ç‰ˆï¼‰
model.train()
for epoch in range(5):
    for batch_X, batch_y in dataloader:
        optimizer.zero_grad()
        outputs = model(batch_X)
        loss = criterion(outputs, batch_y)
        loss.backward()
        optimizer.step()

print("âœ“ ãƒ¢ãƒ‡ãƒ«å­¦ç¿’å®Œäº†")

# TorchScriptã«å¤‰æ›ï¼ˆTracingæ–¹å¼ï¼‰
model.eval()
example_input = torch.randn(1, input_size)

traced_model = torch.jit.trace(model, example_input)

# ä¿å­˜
traced_model.save("model_traced.pt")
print("\nâœ“ TorchScript (traced) ã‚’ä¿å­˜: model_traced.pt")

# TorchScriptã«å¤‰æ›ï¼ˆScriptingæ–¹å¼ï¼‰
scripted_model = torch.jit.script(model)
scripted_model.save("model_scripted.pt")
print("âœ“ TorchScript (scripted) ã‚’ä¿å­˜: model_scripted.pt")

# ãƒ­ãƒ¼ãƒ‰ã¨æ¨è«–
print("\n=== TorchScriptãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ã¨æ¨è«– ===")

loaded_model = torch.jit.load("model_traced.pt")
loaded_model.eval()

# ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§æ¨è«–
X_test_tensor = torch.FloatTensor(X_test[:5])
with torch.no_grad():
    outputs = loaded_model(X_test_tensor)
    predictions = torch.argmax(outputs, dim=1)

print(f"äºˆæ¸¬çµæœ: {predictions.numpy()}")
print(f"å®Ÿéš›ã®ãƒ©ãƒ™ãƒ«: {y_test[:5]}")

print("\nTorchScriptã®åˆ©ç‚¹:")
print("  - Pythonä¾å­˜ãªã—ã§å®Ÿè¡Œå¯èƒ½")
print("  - C++ã‹ã‚‰åˆ©ç”¨å¯èƒ½")
print("  - ãƒ¢ãƒã‚¤ãƒ«/ã‚¨ãƒƒã‚¸ãƒ‡ãƒã‚¤ã‚¹å¯¾å¿œ")
print("  - æœ€é©åŒ–ã«ã‚ˆã‚‹é«˜é€ŸåŒ–")
print("  - ãƒ—ãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³ç’°å¢ƒã«æœ€é©")
</code></pre>

<h3>ãƒ¢ãƒ‡ãƒ«ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³ã®æ¯”è¼ƒ</h3>

<pre><code class="language-python">import pickle
import joblib
import json
import os
from datetime import datetime
import time

class ModelSerializationComparison:
    """ç•°ãªã‚‹ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³æ–¹æ³•ã‚’æ¯”è¼ƒ"""

    def __init__(self, model):
        self.model = model
        self.results = {}

    def compare_formats(self, X_test_sample):
        """å„ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’æ¯”è¼ƒ"""

        print("=== ãƒ¢ãƒ‡ãƒ«ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³æ¯”è¼ƒ ===\n")

        # 1. Pickle
        self._test_pickle(X_test_sample)

        # 2. Joblib
        self._test_joblib(X_test_sample)

        # 3. MLflow
        self._test_mlflow(X_test_sample)

        # 4. ONNX
        self._test_onnx(X_test_sample)

        # çµæœã®è¡¨ç¤º
        self._display_results()

    def _test_pickle(self, X_test):
        """Pickleå½¢å¼ã®ãƒ†ã‚¹ãƒˆ"""
        filepath = "model.pkl"

        # ä¿å­˜
        start = time.time()
        with open(filepath, 'wb') as f:
            pickle.dump(self.model, f)
        save_time = time.time() - start

        # ãƒ­ãƒ¼ãƒ‰
        start = time.time()
        with open(filepath, 'rb') as f:
            loaded_model = pickle.load(f)
        load_time = time.time() - start

        # æ¨è«–
        start = time.time()
        predictions = loaded_model.predict(X_test)
        inference_time = time.time() - start

        self.results['Pickle'] = {
            'size_mb': os.path.getsize(filepath) / 1024 / 1024,
            'save_time': save_time,
            'load_time': load_time,
            'inference_time': inference_time
        }

        os.remove(filepath)

    def _test_joblib(self, X_test):
        """Joblibå½¢å¼ã®ãƒ†ã‚¹ãƒˆ"""
        filepath = "model.joblib"

        start = time.time()
        joblib.dump(self.model, filepath)
        save_time = time.time() - start

        start = time.time()
        loaded_model = joblib.load(filepath)
        load_time = time.time() - start

        start = time.time()
        predictions = loaded_model.predict(X_test)
        inference_time = time.time() - start

        self.results['Joblib'] = {
            'size_mb': os.path.getsize(filepath) / 1024 / 1024,
            'save_time': save_time,
            'load_time': load_time,
            'inference_time': inference_time
        }

        os.remove(filepath)

    def _test_mlflow(self, X_test):
        """MLflowå½¢å¼ã®ãƒ†ã‚¹ãƒˆ"""
        model_path = "mlflow_model"

        start = time.time()
        mlflow.sklearn.save_model(self.model, model_path)
        save_time = time.time() - start

        start = time.time()
        loaded_model = mlflow.sklearn.load_model(model_path)
        load_time = time.time() - start

        start = time.time()
        predictions = loaded_model.predict(X_test)
        inference_time = time.time() - start

        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚µã‚¤ã‚ºã‚’è¨ˆç®—
        total_size = sum(
            os.path.getsize(os.path.join(dirpath, filename))
            for dirpath, dirnames, filenames in os.walk(model_path)
            for filename in filenames
        )

        self.results['MLflow'] = {
            'size_mb': total_size / 1024 / 1024,
            'save_time': save_time,
            'load_time': load_time,
            'inference_time': inference_time
        }

        # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        import shutil
        shutil.rmtree(model_path)

    def _test_onnx(self, X_test):
        """ONNXå½¢å¼ã®ãƒ†ã‚¹ãƒˆ"""
        try:
            from skl2onnx import convert_sklearn
            from skl2onnx.common.data_types import FloatTensorType
            import onnxruntime as rt

            filepath = "model.onnx"
            initial_type = [('float_input', FloatTensorType([None, X_test.shape[1]]))]

            start = time.time()
            onnx_model = convert_sklearn(self.model, initial_types=initial_type)
            with open(filepath, "wb") as f:
                f.write(onnx_model.SerializeToString())
            save_time = time.time() - start

            start = time.time()
            sess = rt.InferenceSession(filepath)
            load_time = time.time() - start

            input_name = sess.get_inputs()[0].name
            output_name = sess.get_outputs()[0].name

            start = time.time()
            predictions = sess.run([output_name], {input_name: X_test.astype(np.float32)})[0]
            inference_time = time.time() - start

            self.results['ONNX'] = {
                'size_mb': os.path.getsize(filepath) / 1024 / 1024,
                'save_time': save_time,
                'load_time': load_time,
                'inference_time': inference_time
            }

            os.remove(filepath)
        except ImportError:
            print("âš ï¸  ONNX: ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«")

    def _display_results(self):
        """çµæœã‚’è¡¨å½¢å¼ã§è¡¨ç¤º"""

        print("\n" + "="*70)
        print(f"{'ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ':<15} {'ã‚µã‚¤ã‚º(MB)':<12} {'ä¿å­˜æ™‚é–“(s)':<12} {'ãƒ­ãƒ¼ãƒ‰æ™‚é–“(s)':<12} {'æ¨è«–æ™‚é–“(s)':<12}")
        print("="*70)

        for format_name, metrics in self.results.items():
            print(f"{format_name:<15} "
                  f"{metrics['size_mb']:<12.3f} "
                  f"{metrics['save_time']:<12.4f} "
                  f"{metrics['load_time']:<12.4f} "
                  f"{metrics['inference_time']:<12.4f}")

        print("="*70)

# ä½¿ç”¨ä¾‹
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

comparison = ModelSerializationComparison(model)
comparison.compare_formats(X_test[:100])

print("\næ¨å¥¨:")
print("  - é–‹ç™º/å®Ÿé¨“: Pickle, Joblib")
print("  - MLOps: MLflow")
print("  - ãƒ—ãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³: ONNX, TorchScript")
print("  - APIåŒ–: BentoML")
</code></pre>

<hr>

<h2>4.5 ãƒ¢ãƒ‡ãƒ«ã‚¬ãƒãƒŠãƒ³ã‚¹</h2>

<h3>ã‚¢ã‚¯ã‚»ã‚¹åˆ¶å¾¡</h3>

<p>ãƒ¢ãƒ‡ãƒ«ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ã‚’é©åˆ‡ã«ç®¡ç†ã—ã€ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚’ç¢ºä¿ã—ã¾ã™ã€‚</p>

<pre><code class="language-python">from enum import Enum
from datetime import datetime
import hashlib

class UserRole(Enum):
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ­ãƒ¼ãƒ«å®šç¾©"""
    DATA_SCIENTIST = "data_scientist"
    ML_ENGINEER = "ml_engineer"
    ADMIN = "admin"
    VIEWER = "viewer"

class Permission(Enum):
    """æ¨©é™å®šç¾©"""
    READ = "read"
    WRITE = "write"
    DEPLOY = "deploy"
    DELETE = "delete"

class AccessControl:
    """ãƒ¢ãƒ‡ãƒ«ã‚¢ã‚¯ã‚»ã‚¹åˆ¶å¾¡ã‚·ã‚¹ãƒ†ãƒ """

    # ãƒ­ãƒ¼ãƒ«ã¨æ¨©é™ã®ãƒãƒƒãƒ”ãƒ³ã‚°
    ROLE_PERMISSIONS = {
        UserRole.VIEWER: [Permission.READ],
        UserRole.DATA_SCIENTIST: [Permission.READ, Permission.WRITE],
        UserRole.ML_ENGINEER: [Permission.READ, Permission.WRITE, Permission.DEPLOY],
        UserRole.ADMIN: [Permission.READ, Permission.WRITE, Permission.DEPLOY, Permission.DELETE]
    }

    def __init__(self):
        self.users = {}
        self.access_log = []

    def add_user(self, username, role):
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’è¿½åŠ """
        self.users[username] = {
            'role': role,
            'created_at': datetime.now(),
            'api_key': self._generate_api_key(username)
        }
        print(f"âœ“ ãƒ¦ãƒ¼ã‚¶ãƒ¼è¿½åŠ : {username} ({role.value})")

    def _generate_api_key(self, username):
        """APIã‚­ãƒ¼ã‚’ç”Ÿæˆ"""
        data = f"{username}-{datetime.now().isoformat()}".encode()
        return hashlib.sha256(data).hexdigest()[:32]

    def check_permission(self, username, permission):
        """æ¨©é™ãƒã‚§ãƒƒã‚¯"""
        if username not in self.users:
            return False

        user_role = self.users[username]['role']
        allowed_permissions = self.ROLE_PERMISSIONS.get(user_role, [])

        return permission in allowed_permissions

    def access_model(self, username, model_name, action):
        """ãƒ¢ãƒ‡ãƒ«ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹è©¦è¡Œ"""

        # ã‚¢ã‚¯ã‚»ã‚¹ãƒ­ã‚°è¨˜éŒ²
        log_entry = {
            'timestamp': datetime.now().isoformat(),
            'username': username,
            'model_name': model_name,
            'action': action.value,
            'granted': False
        }

        # æ¨©é™ãƒã‚§ãƒƒã‚¯
        if not self.check_permission(username, action):
            log_entry['reason'] = 'Insufficient permissions'
            self.access_log.append(log_entry)
            print(f"âŒ ã‚¢ã‚¯ã‚»ã‚¹æ‹’å¦: {username} - {action.value} on {model_name}")
            return False

        log_entry['granted'] = True
        self.access_log.append(log_entry)
        print(f"âœ“ ã‚¢ã‚¯ã‚»ã‚¹è¨±å¯: {username} - {action.value} on {model_name}")
        return True

    def get_access_log(self, username=None):
        """ã‚¢ã‚¯ã‚»ã‚¹ãƒ­ã‚°ã‚’å–å¾—"""
        if username:
            return [log for log in self.access_log if log['username'] == username]
        return self.access_log

    def export_access_log(self, filepath="access_log.json"):
        """ã‚¢ã‚¯ã‚»ã‚¹ãƒ­ã‚°ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
        import json
        with open(filepath, 'w') as f:
            json.dump(self.access_log, f, indent=2)
        print(f"âœ“ ã‚¢ã‚¯ã‚»ã‚¹ãƒ­ã‚°ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ: {filepath}")

# ä½¿ç”¨ä¾‹
print("=== ã‚¢ã‚¯ã‚»ã‚¹åˆ¶å¾¡ã‚·ã‚¹ãƒ†ãƒ  ===\n")

ac = AccessControl()

# ãƒ¦ãƒ¼ã‚¶ãƒ¼è¿½åŠ 
ac.add_user("alice", UserRole.DATA_SCIENTIST)
ac.add_user("bob", UserRole.ML_ENGINEER)
ac.add_user("charlie", UserRole.VIEWER)
ac.add_user("admin", UserRole.ADMIN)

print("\n--- ã‚¢ã‚¯ã‚»ã‚¹ãƒ†ã‚¹ãƒˆ ---")

# å„ç¨®ã‚¢ã‚¯ã‚»ã‚¹è©¦è¡Œ
ac.access_model("alice", "credit-model", Permission.READ)      # OK
ac.access_model("alice", "credit-model", Permission.WRITE)     # OK
ac.access_model("alice", "credit-model", Permission.DEPLOY)    # NG

ac.access_model("bob", "credit-model", Permission.DEPLOY)      # OK
ac.access_model("charlie", "credit-model", Permission.READ)    # OK
ac.access_model("charlie", "credit-model", Permission.WRITE)   # NG

ac.access_model("admin", "credit-model", Permission.DELETE)    # OK

# ãƒ­ã‚°ã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
ac.export_access_log()

print(f"\nç·ã‚¢ã‚¯ã‚»ã‚¹æ•°: {len(ac.access_log)}")
print(f"æ‹’å¦æ•°: {sum(1 for log in ac.access_log if not log['granted'])}")
</code></pre>

<h3>ç›£æŸ»ãƒ­ã‚°</h3>

<pre><code class="language-python">import json
from datetime import datetime
from enum import Enum

class AuditEventType(Enum):
    """ç›£æŸ»ã‚¤ãƒ™ãƒ³ãƒˆã‚¿ã‚¤ãƒ—"""
    MODEL_REGISTERED = "model_registered"
    MODEL_UPDATED = "model_updated"
    MODEL_DEPLOYED = "model_deployed"
    MODEL_ARCHIVED = "model_archived"
    MODEL_DELETED = "model_deleted"
    STAGE_TRANSITION = "stage_transition"
    PERMISSION_CHANGED = "permission_changed"

class AuditLogger:
    """åŒ…æ‹¬çš„ãªç›£æŸ»ãƒ­ã‚°ã‚·ã‚¹ãƒ†ãƒ """

    def __init__(self, log_file="audit_log.json"):
        self.log_file = log_file
        self.events = []

    def log_event(self, event_type, model_name, user, details=None):
        """ã‚¤ãƒ™ãƒ³ãƒˆã‚’ãƒ­ã‚°ã«è¨˜éŒ²"""

        event = {
            'timestamp': datetime.now().isoformat(),
            'event_type': event_type.value,
            'model_name': model_name,
            'user': user,
            'details': details or {}
        }

        self.events.append(event)

        # ãƒ•ã‚¡ã‚¤ãƒ«ã«è¿½è¨˜
        with open(self.log_file, 'a') as f:
            f.write(json.dumps(event) + '\n')

        print(f"ğŸ“ ç›£æŸ»ãƒ­ã‚°è¨˜éŒ²: {event_type.value} - {model_name} by {user}")

    def get_events(self, model_name=None, user=None, event_type=None):
        """ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã—ã¦ã‚¤ãƒ™ãƒ³ãƒˆã‚’å–å¾—"""

        filtered = self.events

        if model_name:
            filtered = [e for e in filtered if e['model_name'] == model_name]

        if user:
            filtered = [e for e in filtered if e['user'] == user]

        if event_type:
            filtered = [e for e in filtered if e['event_type'] == event_type.value]

        return filtered

    def generate_audit_report(self, model_name):
        """ãƒ¢ãƒ‡ãƒ«ã®ç›£æŸ»ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""

        events = self.get_events(model_name=model_name)

        print(f"\n=== {model_name} ç›£æŸ»ãƒ¬ãƒãƒ¼ãƒˆ ===")
        print(f"ç·ã‚¤ãƒ™ãƒ³ãƒˆæ•°: {len(events)}\n")

        for event in events:
            print(f"{event['timestamp']}")
            print(f"  ã‚¤ãƒ™ãƒ³ãƒˆ: {event['event_type']}")
            print(f"  å®Ÿè¡Œè€…: {event['user']}")
            if event['details']:
                print(f"  è©³ç´°: {event['details']}")
            print()

    def check_compliance(self, model_name, required_events):
        """ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹ãƒã‚§ãƒƒã‚¯"""

        events = self.get_events(model_name=model_name)
        event_types = set(e['event_type'] for e in events)

        compliance_status = {}
        for required in required_events:
            compliance_status[required.value] = required.value in event_types

        return compliance_status

# ä½¿ç”¨ä¾‹
print("=== ç›£æŸ»ãƒ­ã‚°ã‚·ã‚¹ãƒ†ãƒ  ===\n")

audit = AuditLogger()

# æ§˜ã€…ãªã‚¤ãƒ™ãƒ³ãƒˆã‚’è¨˜éŒ²
audit.log_event(
    AuditEventType.MODEL_REGISTERED,
    "credit-model",
    "alice",
    {"version": 1, "accuracy": 0.85}
)

audit.log_event(
    AuditEventType.STAGE_TRANSITION,
    "credit-model",
    "bob",
    {"from_stage": "None", "to_stage": "Staging", "version": 1}
)

audit.log_event(
    AuditEventType.MODEL_DEPLOYED,
    "credit-model",
    "admin",
    {"version": 1, "environment": "production", "approved_by": "manager"}
)

# ç›£æŸ»ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
audit.generate_audit_report("credit-model")

# ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹ãƒã‚§ãƒƒã‚¯
print("\n=== ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹ãƒã‚§ãƒƒã‚¯ ===")
required = [
    AuditEventType.MODEL_REGISTERED,
    AuditEventType.MODEL_DEPLOYED
]

compliance = audit.check_compliance("credit-model", required)
for req, status in compliance.items():
    symbol = "âœ“" if status else "âŒ"
    print(f"{symbol} {req}: {'æº–æ‹ ' if status else 'æœªæº–æ‹ '}")
</code></pre>

<h3>ãƒ¢ãƒ‡ãƒ«ã‚«ãƒ¼ãƒ‰</h3>

<p><strong>ãƒ¢ãƒ‡ãƒ«ã‚«ãƒ¼ãƒ‰</strong>ã¯ã€ãƒ¢ãƒ‡ãƒ«ã®æ„å›³ã€æ€§èƒ½ã€åˆ¶é™ã‚’æ–‡æ›¸åŒ–ã™ã‚‹æ¨™æº–å½¢å¼ã§ã™ã€‚</p>

<pre><code class="language-python">from dataclasses import dataclass, asdict
from typing import List, Dict
import json

@dataclass
class ModelCard:
    """ãƒ¢ãƒ‡ãƒ«ã‚«ãƒ¼ãƒ‰ - ãƒ¢ãƒ‡ãƒ«ã®åŒ…æ‹¬çš„ãªæ–‡æ›¸åŒ–"""

    # åŸºæœ¬æƒ…å ±
    model_name: str
    version: str
    date: str
    authors: List[str]

    # ãƒ¢ãƒ‡ãƒ«è©³ç´°
    model_type: str
    architecture: str
    training_data: Dict

    # æ€§èƒ½
    performance_metrics: Dict
    test_data: Dict

    # ä½¿ç”¨ç›®çš„
    intended_use: str
    out_of_scope_use: List[str]

    # åˆ¶é™äº‹é …
    limitations: List[str]
    biases: List[str]

    # å€«ç†çš„è€ƒæ…®äº‹é …
    ethical_considerations: List[str]

    # æ¨å¥¨äº‹é …
    recommendations: List[str]

    def to_dict(self):
        """è¾æ›¸å½¢å¼ã«å¤‰æ›"""
        return asdict(self)

    def to_json(self, filepath):
        """JSONå½¢å¼ã§ä¿å­˜"""
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(self.to_dict(), f, indent=2, ensure_ascii=False)
        print(f"âœ“ ãƒ¢ãƒ‡ãƒ«ã‚«ãƒ¼ãƒ‰ã‚’ä¿å­˜: {filepath}")

    def to_markdown(self, filepath):
        """Markdownå½¢å¼ã§ä¿å­˜"""

        md_content = f"""# ãƒ¢ãƒ‡ãƒ«ã‚«ãƒ¼ãƒ‰: {self.model_name}

## åŸºæœ¬æƒ…å ±
- **ãƒ¢ãƒ‡ãƒ«å**: {self.model_name}
- **ãƒãƒ¼ã‚¸ãƒ§ãƒ³**: {self.version}
- **ä½œæˆæ—¥**: {self.date}
- **ä½œæˆè€…**: {', '.join(self.authors)}

## ãƒ¢ãƒ‡ãƒ«è©³ç´°
- **ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—**: {self.model_type}
- **ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£**: {self.architecture}

### å­¦ç¿’ãƒ‡ãƒ¼ã‚¿
"""
        for key, value in self.training_data.items():
            md_content += f"- **{key}**: {value}\n"

        md_content += f"""
## æ€§èƒ½ãƒ¡ãƒˆãƒªã‚¯ã‚¹

### ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
"""
        for key, value in self.test_data.items():
            md_content += f"- **{key}**: {value}\n"

        md_content += "\n### æ€§èƒ½\n"
        for metric, value in self.performance_metrics.items():
            md_content += f"- **{metric}**: {value}\n"

        md_content += f"""
## ä½¿ç”¨ç›®çš„

### æ„å›³ã•ã‚ŒãŸä½¿ç”¨æ–¹æ³•
{self.intended_use}

### é©ç”¨ç¯„å›²å¤–ã®ä½¿ç”¨
"""
        for item in self.out_of_scope_use:
            md_content += f"- {item}\n"

        md_content += "\n## åˆ¶é™äº‹é …\n"
        for limitation in self.limitations:
            md_content += f"- {limitation}\n"

        md_content += "\n## ãƒã‚¤ã‚¢ã‚¹\n"
        for bias in self.biases:
            md_content += f"- {bias}\n"

        md_content += "\n## å€«ç†çš„è€ƒæ…®äº‹é …\n"
        for consideration in self.ethical_considerations:
            md_content += f"- {consideration}\n"

        md_content += "\n## æ¨å¥¨äº‹é …\n"
        for recommendation in self.recommendations:
            md_content += f"- {recommendation}\n"

        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(md_content)

        print(f"âœ“ ãƒ¢ãƒ‡ãƒ«ã‚«ãƒ¼ãƒ‰(Markdown)ã‚’ä¿å­˜: {filepath}")

# ä½¿ç”¨ä¾‹
print("=== ãƒ¢ãƒ‡ãƒ«ã‚«ãƒ¼ãƒ‰ã®ä½œæˆ ===\n")

model_card = ModelCard(
    model_name="ä¿¡ç”¨ãƒªã‚¹ã‚¯åˆ†é¡ãƒ¢ãƒ‡ãƒ«",
    version="1.2.0",
    date="2025-10-21",
    authors=["Data Science Team", "ML Engineering Team"],

    model_type="Random Forest Classifier",
    architecture="100 estimators, max_depth=10",
    training_data={
        "ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ": "é¡§å®¢ä¿¡ç”¨ãƒ‡ãƒ¼ã‚¿ 2023-2024",
        "ã‚µãƒ³ãƒ—ãƒ«æ•°": "100,000",
        "ç‰¹å¾´é‡æ•°": "20",
        "ã‚¯ãƒ©ã‚¹": "æ‰¿èª/æ‹’å¦ (ãƒãƒ©ãƒ³ã‚¹æ¸ˆã¿)"
    },

    performance_metrics={
        "Accuracy": "0.892",
        "Precision": "0.885",
        "Recall": "0.901",
        "F1 Score": "0.893",
        "ROC AUC": "0.945"
    },

    test_data={
        "ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ": "ãƒ›ãƒ¼ãƒ«ãƒ‰ã‚¢ã‚¦ãƒˆãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆ",
        "ã‚µãƒ³ãƒ—ãƒ«æ•°": "20,000",
        "æœŸé–“": "2024å¹´Q3"
    },

    intended_use="å€‹äººå‘ã‘ãƒ­ãƒ¼ãƒ³ã®ä¿¡ç”¨ãƒªã‚¹ã‚¯è©•ä¾¡ã€‚èè³‡åˆ¤æ–­ã®è£œåŠ©ãƒ„ãƒ¼ãƒ«ã¨ã—ã¦ä½¿ç”¨ã€‚",

    out_of_scope_use=[
        "ä¼æ¥­å‘ã‘èè³‡ã®è©•ä¾¡",
        "é›‡ç”¨åˆ¤æ–­ã¸ã®åˆ©ç”¨",
        "ä¿é™ºæ–™ç‡ã®è¨­å®š",
        "äººé–“ã«ã‚ˆã‚‹å¯©æŸ»ãªã—ã®è‡ªå‹•æ‰¿èª"
    ],

    limitations=[
        "éå»2å¹´é–“ã®ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã„ã¦ãŠã‚Šã€çµŒæ¸ˆç’°å¢ƒã®æ€¥å¤‰ã«ã¯å¯¾å¿œã§ããªã„å¯èƒ½æ€§",
        "18æ­³ä»¥ä¸Šã®å€‹äººã®ã¿ã‚’å¯¾è±¡ã¨ã—ã¦ãŠã‚Šã€æœªæˆå¹´è€…ã«ã¯é©ç”¨ä¸å¯",
        "å¹´åãƒ‡ãƒ¼ã‚¿ãŒè‡ªå·±ç”³å‘Šãƒ™ãƒ¼ã‚¹ã§ã‚ã‚Šã€æ¤œè¨¼ã•ã‚Œã¦ã„ãªã„",
        "åœ°åŸŸã«ã‚ˆã‚‹ä¿¡ç”¨æ…£ç¿’ã®é•ã„ã‚’ååˆ†ã«è€ƒæ…®ã—ã¦ã„ãªã„"
    ],

    biases=[
        "å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã«è‹¥å¹´å±¤ã®ã‚µãƒ³ãƒ—ãƒ«ãŒå°‘ãªãã€è‹¥å¹´å±¤ã¸ã®äºˆæ¸¬ç²¾åº¦ãŒä½ã„å¯èƒ½æ€§",
        "é«˜æ‰€å¾—å±¤ã«åã£ãŸãƒ‡ãƒ¼ã‚¿åˆ†å¸ƒã«ã‚ˆã‚Šã€ä½æ‰€å¾—å±¤ã¸ã®äºˆæ¸¬ãŒä¿å®ˆçš„",
        "éƒ½å¸‚éƒ¨ã®ãƒ‡ãƒ¼ã‚¿ãŒå¤šãã€åœ°æ–¹éƒ¨ã§ã®é©ç”¨ã«æ³¨æ„ãŒå¿…è¦"
    ],

    ethical_considerations=[
        "ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬ã¯å‚è€ƒæƒ…å ±ã§ã‚ã‚Šã€æœ€çµ‚åˆ¤æ–­ã¯äººé–“ãŒè¡Œã†ã“ã¨",
        "æ‹’å¦ã®ç†ç”±ã‚’é¡§å®¢ã«èª¬æ˜ã§ãã‚‹ä½“åˆ¶ã‚’æ•´å‚™ã™ã‚‹ã“ã¨",
        "å®šæœŸçš„ã«ãƒ¢ãƒ‡ãƒ«ã®å…¬å¹³æ€§ã‚’ç›£è¦–ã—ã€ãƒã‚¤ã‚¢ã‚¹ã‚’æ¤œå‡ºã™ã‚‹ã“ã¨",
        "å€‹äººæƒ…å ±ä¿è­·æ³•ã«æº–æ‹ ã—ãŸãƒ‡ãƒ¼ã‚¿ç®¡ç†ã‚’å®Ÿæ–½ã™ã‚‹ã“ã¨"
    ],

    recommendations=[
        "3ãƒ¶æœˆã”ã¨ã«ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’ç›£è¦–ã—ã€åŠ£åŒ–ãŒè¦‹ã‚‰ã‚ŒãŸå ´åˆã¯å†å­¦ç¿’ã‚’å®Ÿæ–½",
        "äººé–“ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ—ãƒ­ã‚»ã‚¹ã¨çµ„ã¿åˆã‚ã›ã¦ä½¿ç”¨ã™ã‚‹ã“ã¨",
        "ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬ã«åŸºã¥ãåˆ¤æ–­ã¯ã€é–¢é€£æ³•è¦åˆ¶ã‚’éµå®ˆã™ã‚‹ã“ã¨",
        "æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã§å®šæœŸçš„ã«ãƒã‚¤ã‚¢ã‚¹ç›£æŸ»ã‚’å®Ÿæ–½ã™ã‚‹ã“ã¨",
        "ã‚¹ãƒ†ãƒ¼ã‚¯ãƒ›ãƒ«ãƒ€ãƒ¼ã¸ã®é€æ˜æ€§ã‚’ç¢ºä¿ã—ã€ãƒ¢ãƒ‡ãƒ«ã®å‹•ä½œã‚’èª¬æ˜å¯èƒ½ã«ã™ã‚‹ã“ã¨"
    ]
)

# JSONå½¢å¼ã§ä¿å­˜
model_card.to_json("model_card.json")

# Markdownå½¢å¼ã§ä¿å­˜
model_card.to_markdown("model_card.md")

print("\nãƒ¢ãƒ‡ãƒ«ã‚«ãƒ¼ãƒ‰ã®åˆ©ç‚¹:")
print("  - é€æ˜æ€§ã®å‘ä¸Š")
print("  - èª¬æ˜è²¬ä»»ã®ç¢ºä¿")
print("  - é©åˆ‡ãªä½¿ç”¨ã®ä¿ƒé€²")
print("  - ãƒªã‚¹ã‚¯ã®æ˜ç¢ºåŒ–")
print("  - ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹å¯¾å¿œ")
</code></pre>

<hr>

<h2>4.6 æœ¬ç« ã®ã¾ã¨ã‚</h2>

<h3>å­¦ã‚“ã ã“ã¨</h3>

<ol>
<li><p><strong>ãƒ¢ãƒ‡ãƒ«ç®¡ç†ã®èª²é¡Œ</strong></p>
<ul>
<li>ãƒãƒ¼ã‚¸ãƒ§ãƒ‹ãƒ³ã‚°ã€ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã€ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«ã€ã‚¬ãƒãƒŠãƒ³ã‚¹</li>
<li>ä½“ç³»çš„ãªç®¡ç†ã®é‡è¦æ€§</li>
</ul></li>

<li><p><strong>ãƒ¢ãƒ‡ãƒ«ãƒ¬ã‚¸ã‚¹ãƒˆãƒª</strong></p>
<ul>
<li>MLflow Model Registryã§ã®ä¸­å¤®ç®¡ç†</li>
<li>ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ã¨ã‚¹ãƒ†ãƒ¼ã‚¸é·ç§»</li>
<li>ãƒ¢ãƒ‡ãƒ«ã®ãƒ—ãƒ­ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³ã¨ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯</li>
</ul></li>

<li><p><strong>ãƒ¢ãƒ‡ãƒ«ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç®¡ç†</strong></p>
<ul>
<li>ãƒ¢ãƒ‡ãƒ«ç½²åã«ã‚ˆã‚‹å‹å®‰å…¨æ€§</li>
<li>å…¥å‡ºåŠ›ã‚¹ã‚­ãƒ¼ãƒã®å®šç¾©ã¨æ¤œè¨¼</li>
<li>ä¾å­˜é–¢ä¿‚ã¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹</li>
</ul></li>

<li><p><strong>ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãƒ³ã‚°</strong></p>
<ul>
<li>ONNX: ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯éä¾å­˜</li>
<li>BentoML: APIåŒ–ã¨ãƒ‡ãƒ—ãƒ­ã‚¤</li>
<li>TorchScript: æœ€é©åŒ–ã¨é«˜é€ŸåŒ–</li>
<li>å„å½¢å¼ã®ä½¿ã„åˆ†ã‘</li>
</ul></li>

<li><p><strong>ãƒ¢ãƒ‡ãƒ«ã‚¬ãƒãƒŠãƒ³ã‚¹</strong></p>
<ul>
<li>ã‚¢ã‚¯ã‚»ã‚¹åˆ¶å¾¡ã¨RBAC</li>
<li>ç›£æŸ»ãƒ­ã‚°ã¨ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹</li>
<li>ãƒ¢ãƒ‡ãƒ«ã‚«ãƒ¼ãƒ‰ã«ã‚ˆã‚‹æ–‡æ›¸åŒ–</li>
</ul></li>
</ol>

<h3>ãƒ¢ãƒ‡ãƒ«ç®¡ç†ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹</h3>

<table>
<thead>
<tr>
<th>ãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹</th>
<th>èª¬æ˜</th>
<th>åˆ©ç‚¹</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>çµ±ä¸€çš„ãªãƒ¬ã‚¸ã‚¹ãƒˆãƒª</strong></td>
<td>ã™ã¹ã¦ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä¸€ç®‡æ‰€ã§ç®¡ç†</td>
<td>å¯è¦–æ€§ã€è¿½è·¡æ€§</td>
</tr>
<tr>
<td><strong>è‡ªå‹•ãƒãƒ¼ã‚¸ãƒ§ãƒ‹ãƒ³ã‚°</strong></td>
<td>ã™ã¹ã¦ã®å¤‰æ›´ã‚’è‡ªå‹•è¨˜éŒ²</td>
<td>å†ç¾æ€§ã€ç›£æŸ»</td>
</tr>
<tr>
<td><strong>ã‚¹ãƒ†ãƒ¼ã‚¸ç®¡ç†</strong></td>
<td>é–‹ç™º/Staging/æœ¬ç•ªã®æ˜ç¢ºåŒ–</td>
<td>ãƒªã‚¹ã‚¯ç®¡ç†</td>
</tr>
<tr>
<td><strong>ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®å……å®Ÿ</strong></td>
<td>ã™ã¹ã¦ã®é–¢é€£æƒ…å ±ã‚’è¨˜éŒ²</td>
<td>æ¤œç´¢æ€§ã€ç†è§£</td>
</tr>
<tr>
<td><strong>ã‚¢ã‚¯ã‚»ã‚¹åˆ¶å¾¡</strong></td>
<td>ãƒ­ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã®æ¨©é™ç®¡ç†</td>
<td>ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£</td>
</tr>
<tr>
<td><strong>ç›£æŸ»ãƒ­ã‚°</strong></td>
<td>ã™ã¹ã¦ã®æ“ä½œã‚’è¨˜éŒ²</td>
<td>ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹</td>
</tr>
<tr>
<td><strong>ãƒ¢ãƒ‡ãƒ«ã‚«ãƒ¼ãƒ‰</strong></td>
<td>æ„å›³ã€æ€§èƒ½ã€åˆ¶é™ã‚’æ–‡æ›¸åŒ–</td>
<td>é€æ˜æ€§ã€è²¬ä»»</td>
</tr>
</tbody>
</table>

<h3>æ¬¡ã®ç« ã¸</h3>

<p>ç¬¬5ç« ã§ã¯ã€<strong>ãƒ¢ãƒ‡ãƒ«ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆ</strong>ã‚’å­¦ã³ã¾ã™ï¼š</p>
<ul>
<li>ãƒãƒƒãƒæ¨è«–ã¨ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¨è«–</li>
<li>ãƒ¢ãƒ‡ãƒ«ã‚µãƒ¼ãƒ“ãƒ³ã‚°ï¼ˆFastAPIã€BentoMLï¼‰</li>
<li>ã‚³ãƒ³ãƒ†ãƒŠåŒ–ã¨Kubernetes</li>
<li>A/Bãƒ†ã‚¹ãƒˆã¨ã‚«ãƒŠãƒªã‚¢ãƒ‡ãƒ—ãƒ­ã‚¤</li>
<li>ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ã¨ã‚¢ãƒ©ãƒ¼ãƒˆ</li>
</ul>

<hr>

<h2>æ¼”ç¿’å•é¡Œ</h2>

<h3>å•é¡Œ1ï¼ˆé›£æ˜“åº¦ï¼šeasyï¼‰</h3>
<p>ãƒ¢ãƒ‡ãƒ«ãƒ¬ã‚¸ã‚¹ãƒˆãƒªã®ä¸»è¦ãªæ©Ÿèƒ½ã‚’3ã¤æŒ™ã’ã€ãã‚Œãã‚Œã®é‡è¦æ€§ã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚</p>

<details>
<summary>è§£ç­”ä¾‹</summary>

<p><strong>è§£ç­”</strong>ï¼š</p>

<ol>
<li><p><strong>ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†</strong></p>
<ul>
<li>æ©Ÿèƒ½: ãƒ¢ãƒ‡ãƒ«ã®å„ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’è‡ªå‹•çš„ã«è¿½è·¡</li>
<li>é‡è¦æ€§: å†ç¾æ€§ã®ç¢ºä¿ã€å•é¡Œç™ºç”Ÿæ™‚ã®ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯ã€ãƒ¢ãƒ‡ãƒ«é–“ã®æ¯”è¼ƒãŒå¯èƒ½</li>
</ul></li>

<li><p><strong>ã‚¹ãƒ†ãƒ¼ã‚¸ç®¡ç†</strong></p>
<ul>
<li>æ©Ÿèƒ½: Stagingã€Productionã€Archivedãªã©ã®ã‚¹ãƒ†ãƒ¼ã‚¸ã‚’å®šç¾©</li>
<li>é‡è¦æ€§: ç’°å¢ƒã®æ˜ç¢ºåŒ–ã€ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆãƒªã‚¹ã‚¯ã®ä½æ¸›ã€æ‰¿èªãƒ—ãƒ­ã‚»ã‚¹ã®å®Ÿè£…</li>
</ul></li>

<li><p><strong>ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä¿å­˜</strong></p>
<ul>
<li>æ©Ÿèƒ½: ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã€ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã€èª¬æ˜ãªã©ã‚’ä¿å­˜</li>
<li>é‡è¦æ€§: ãƒ¢ãƒ‡ãƒ«ã®æ¤œç´¢æ€§å‘ä¸Šã€æ„æ€æ±ºå®šã®æ”¯æ´ã€ç›£æŸ»ã¨ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹</li>
</ul></li>
</ol>

</details>

<h3>å•é¡Œ2ï¼ˆé›£æ˜“åº¦ï¼šmediumï¼‰</h3>
<p>MLflow Model Registryã‚’ä½¿ç”¨ã—ã¦ã€ãƒ¢ãƒ‡ãƒ«ã‚’ç™»éŒ²ã—ã€Stagingã‹ã‚‰ãƒ—ãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³ã«æ˜‡æ ¼ã•ã›ã‚‹ã‚³ãƒ¼ãƒ‰ã‚’æ›¸ã„ã¦ãã ã•ã„ã€‚</p>

<details>
<summary>è§£ç­”ä¾‹</summary>

<pre><code class="language-python">import mlflow
import mlflow.sklearn
from mlflow.tracking import MlflowClient
from sklearn.ensemble import RandomForestClassifier
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split

# ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
mlflow.set_tracking_uri("sqlite:///mlflow.db")
client = MlflowClient()

# ãƒ‡ãƒ¼ã‚¿æº–å‚™
X, y = make_classification(n_samples=1000, n_features=20, random_state=42)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

# ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã¨ç™»éŒ²
model_name = "my_classifier"

with mlflow.start_run():
    # ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
    model = RandomForestClassifier(n_estimators=100, random_state=42)
    model.fit(X_train, y_train)

    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—
    accuracy = model.score(X_test, y_test)
    mlflow.log_metric("accuracy", accuracy)

    # ãƒ¢ãƒ‡ãƒ«ç™»éŒ²
    mlflow.sklearn.log_model(
        sk_model=model,
        artifact_path="model",
        registered_model_name=model_name
    )

# æœ€æ–°ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’å–å¾—
versions = client.search_model_versions(f"name='{model_name}'")
latest_version = max([int(v.version) for v in versions])

# Stagingã«é·ç§»
client.transition_model_version_stage(
    name=model_name,
    version=latest_version,
    stage="Staging"
)
print(f"âœ“ ãƒãƒ¼ã‚¸ãƒ§ãƒ³ {latest_version} ã‚’ Staging ã«é·ç§»")

# ãƒ†ã‚¹ãƒˆå¾Œã€Productionã«æ˜‡æ ¼
client.transition_model_version_stage(
    name=model_name,
    version=latest_version,
    stage="Production",
    archive_existing_versions=True  # æ—¢å­˜ã®Productionã‚’ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–
)
print(f"âœ“ ãƒãƒ¼ã‚¸ãƒ§ãƒ³ {latest_version} ã‚’ Production ã«æ˜‡æ ¼")

# Productionãƒ¢ãƒ‡ãƒ«ã®å–å¾—
prod_model = mlflow.sklearn.load_model(f"models:/{model_name}/Production")
print(f"âœ“ Productionãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿")
</code></pre>

</details>

<h3>å•é¡Œ3ï¼ˆé›£æ˜“åº¦ï¼šmediumï¼‰</h3>
<p>ãƒ¢ãƒ‡ãƒ«ç½²åï¼ˆsignatureï¼‰ã‚’ä½œæˆã—ã€å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã®æ¤œè¨¼ã‚’è¡Œã†ã‚³ãƒ¼ãƒ‰ã‚’æ›¸ã„ã¦ãã ã•ã„ã€‚</p>

<details>
<summary>è§£ç­”ä¾‹</summary>

<pre><code class="language-python">import mlflow
import pandas as pd
import numpy as np
from sklearn.ensemble import GradientBoostingClassifier
from mlflow.models.signature import infer_signature

# ãƒ‡ãƒ¼ã‚¿æº–å‚™
np.random.seed(42)
X_train = pd.DataFrame({
    'feature_1': np.random.randn(100),
    'feature_2': np.random.randn(100),
    'feature_3': np.random.randn(100)
})
y_train = np.random.randint(0, 2, 100)

# ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
model = GradientBoostingClassifier(random_state=42)
model.fit(X_train, y_train)

# äºˆæ¸¬ï¼ˆç½²åã®æ¨è«–ç”¨ï¼‰
predictions = model.predict(X_train[:5])

# ç½²åã®ä½œæˆ
signature = infer_signature(X_train, predictions)

print("=== ãƒ¢ãƒ‡ãƒ«ç½²å ===")
print(signature)

# ç½²åä»˜ãã§ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜
with mlflow.start_run():
    mlflow.sklearn.log_model(
        sk_model=model,
        artifact_path="model",
        signature=signature,
        input_example=X_train[:5]
    )
    print("\nâœ“ ç½²åä»˜ããƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜")

# æ¤œè¨¼: æ­£ã—ã„å…¥åŠ›
print("\n=== å…¥åŠ›æ¤œè¨¼ ===")
correct_input = pd.DataFrame({
    'feature_1': [1.0],
    'feature_2': [2.0],
    'feature_3': [3.0]
})
print(f"âœ“ æ­£ã—ã„å…¥åŠ›å½¢å¼ï¼ˆåˆ—æ•°: {len(correct_input.columns)}ï¼‰")

# æ¤œè¨¼: é–“é•ã£ãŸå…¥åŠ›ï¼ˆåˆ—ãŒä¸è¶³ï¼‰
try:
    wrong_input = pd.DataFrame({
        'feature_1': [1.0],
        'feature_2': [2.0]
        # feature_3 ãŒæ¬ è½
    })
    print(f"âŒ é–“é•ã£ãŸå…¥åŠ›å½¢å¼ï¼ˆåˆ—æ•°: {len(wrong_input.columns)}ï¼‰")
    print("   â†’ å®Ÿéš›ã®ãƒ‡ãƒ—ãƒ­ã‚¤æ™‚ã«MLflowãŒã‚¨ãƒ©ãƒ¼ã‚’æ¤œå‡º")
except Exception as e:
    print(f"âœ“ ã‚¨ãƒ©ãƒ¼æ¤œå‡º: {e}")
</code></pre>

</details>

<h3>å•é¡Œ4ï¼ˆé›£æ˜“åº¦ï¼šhardï¼‰</h3>
<p>ã‚¢ã‚¯ã‚»ã‚¹åˆ¶å¾¡ã‚·ã‚¹ãƒ†ãƒ ã‚’å®Ÿè£…ã—ã€ç•°ãªã‚‹ãƒ­ãƒ¼ãƒ«ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦å®Ÿè¡Œã§ãã‚‹æ“ä½œã‚’åˆ¶é™ã—ã¦ãã ã•ã„ã€‚ç›£æŸ»ãƒ­ã‚°ã‚‚å«ã‚ã¦ãã ã•ã„ã€‚</p>

<details>
<summary>è§£ç­”ä¾‹</summary>

<pre><code class="language-python">from enum import Enum
from datetime import datetime
import json

class UserRole(Enum):
    VIEWER = "viewer"
    DATA_SCIENTIST = "data_scientist"
    ML_ENGINEER = "ml_engineer"
    ADMIN = "admin"

class Permission(Enum):
    READ = "read"
    WRITE = "write"
    DEPLOY = "deploy"
    DELETE = "delete"

class ModelAccessControl:
    """ãƒ¢ãƒ‡ãƒ«ã‚¢ã‚¯ã‚»ã‚¹åˆ¶å¾¡ã¨ç›£æŸ»ãƒ­ã‚°"""

    ROLE_PERMISSIONS = {
        UserRole.VIEWER: [Permission.READ],
        UserRole.DATA_SCIENTIST: [Permission.READ, Permission.WRITE],
        UserRole.ML_ENGINEER: [Permission.READ, Permission.WRITE, Permission.DEPLOY],
        UserRole.ADMIN: [Permission.READ, Permission.WRITE, Permission.DEPLOY, Permission.DELETE]
    }

    def __init__(self):
        self.users = {}
        self.audit_log = []

    def add_user(self, username, role):
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’è¿½åŠ """
        self.users[username] = {'role': role, 'created_at': datetime.now()}
        self._log_audit("USER_ADDED", None, username, {"role": role.value})

    def check_permission(self, username, permission):
        """æ¨©é™ã‚’ãƒã‚§ãƒƒã‚¯"""
        if username not in self.users:
            return False
        user_role = self.users[username]['role']
        return permission in self.ROLE_PERMISSIONS.get(user_role, [])

    def execute_action(self, username, model_name, action):
        """ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œï¼ˆæ¨©é™ãƒã‚§ãƒƒã‚¯ä»˜ãï¼‰"""

        # æ¨©é™ãƒã‚§ãƒƒã‚¯
        if not self.check_permission(username, action):
            self._log_audit(
                "ACCESS_DENIED",
                model_name,
                username,
                {"action": action.value, "reason": "insufficient_permissions"}
            )
            print(f"âŒ ã‚¢ã‚¯ã‚»ã‚¹æ‹’å¦: {username} - {action.value}")
            return False

        # ã‚¢ã‚¯ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
        self._log_audit("ACTION_EXECUTED", model_name, username, {"action": action.value})
        print(f"âœ“ ã‚¢ã‚¯ã‚·ãƒ§ãƒ³å®Ÿè¡Œ: {username} - {action.value} on {model_name}")
        return True

    def _log_audit(self, event_type, model_name, username, details):
        """ç›£æŸ»ãƒ­ã‚°ã«è¨˜éŒ²"""
        event = {
            'timestamp': datetime.now().isoformat(),
            'event_type': event_type,
            'model_name': model_name,
            'username': username,
            'details': details
        }
        self.audit_log.append(event)

    def export_audit_log(self, filepath="audit.json"):
        """ç›£æŸ»ãƒ­ã‚°ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
        with open(filepath, 'w') as f:
            json.dump(self.audit_log, f, indent=2)
        print(f"\nâœ“ ç›£æŸ»ãƒ­ã‚°ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ: {filepath}")

    def get_user_activity(self, username):
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚¢ã‚¯ãƒ†ã‚£ãƒ“ãƒ†ã‚£ã‚’å–å¾—"""
        return [log for log in self.audit_log if log['username'] == username]

    def get_model_activity(self, model_name):
        """ãƒ¢ãƒ‡ãƒ«ã®ã‚¢ã‚¯ãƒ†ã‚£ãƒ“ãƒ†ã‚£ã‚’å–å¾—"""
        return [log for log in self.audit_log
                if log['model_name'] == model_name]

# ä½¿ç”¨ä¾‹
print("=== ã‚¢ã‚¯ã‚»ã‚¹åˆ¶å¾¡ã¨ç›£æŸ»ãƒ­ã‚° ===\n")

access_control = ModelAccessControl()

# ãƒ¦ãƒ¼ã‚¶ãƒ¼è¿½åŠ 
access_control.add_user("alice", UserRole.DATA_SCIENTIST)
access_control.add_user("bob", UserRole.ML_ENGINEER)
access_control.add_user("charlie", UserRole.VIEWER)
access_control.add_user("admin", UserRole.ADMIN)

print("\n--- ã‚¢ã‚¯ã‚·ãƒ§ãƒ³å®Ÿè¡Œ ---")

# å„ç¨®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
access_control.execute_action("alice", "credit-model", Permission.READ)
access_control.execute_action("alice", "credit-model", Permission.WRITE)
access_control.execute_action("alice", "credit-model", Permission.DEPLOY)  # å¤±æ•—

access_control.execute_action("bob", "credit-model", Permission.DEPLOY)
access_control.execute_action("charlie", "credit-model", Permission.READ)
access_control.execute_action("charlie", "credit-model", Permission.WRITE)  # å¤±æ•—

access_control.execute_action("admin", "credit-model", Permission.DELETE)

# ç›£æŸ»ãƒ­ã‚°ã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
access_control.export_audit_log()

# ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¢ã‚¯ãƒ†ã‚£ãƒ“ãƒ†ã‚£
print("\n--- Aliceã®ã‚¢ã‚¯ãƒ†ã‚£ãƒ“ãƒ†ã‚£ ---")
alice_activity = access_control.get_user_activity("alice")
for activity in alice_activity:
    print(f"{activity['timestamp']}: {activity['event_type']} - {activity.get('details', {})}")

print(f"\nç·ç›£æŸ»ã‚¤ãƒ™ãƒ³ãƒˆæ•°: {len(access_control.audit_log)}")
</code></pre>

</details>

<h3>å•é¡Œ5ï¼ˆé›£æ˜“åº¦ï¼šhardï¼‰</h3>
<p>ãƒ¢ãƒ‡ãƒ«ã‚«ãƒ¼ãƒ‰ã‚’ä½œæˆã—ã€JSONå½¢å¼ã¨Markdownå½¢å¼ã®ä¸¡æ–¹ã§ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã—ã¦ãã ã•ã„ã€‚åˆ¶é™äº‹é …ã¨ãƒã‚¤ã‚¢ã‚¹ã‚‚å«ã‚ã¦ãã ã•ã„ã€‚</p>

<details>
<summary>è§£ç­”ä¾‹</summary>

<pre><code class="language-python">from dataclasses import dataclass, asdict
import json

@dataclass
class ModelCard:
    """åŒ…æ‹¬çš„ãªãƒ¢ãƒ‡ãƒ«ã‚«ãƒ¼ãƒ‰"""
    model_name: str
    version: str
    date: str
    authors: list
    model_type: str
    intended_use: str
    performance: dict
    limitations: list
    biases: list
    ethical_considerations: list

    def to_json(self, filepath):
        """JSONå½¢å¼ã§ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(asdict(self), f, indent=2, ensure_ascii=False)
        print(f"âœ“ JSONå½¢å¼ã§ä¿å­˜: {filepath}")

    def to_markdown(self, filepath):
        """Markdownå½¢å¼ã§ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
        md = f"""# ãƒ¢ãƒ‡ãƒ«ã‚«ãƒ¼ãƒ‰: {self.model_name}

## åŸºæœ¬æƒ…å ±
- ãƒ¢ãƒ‡ãƒ«å: {self.model_name}
- ãƒãƒ¼ã‚¸ãƒ§ãƒ³: {self.version}
- ä½œæˆæ—¥: {self.date}
- ä½œæˆè€…: {', '.join(self.authors)}
- ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—: {self.model_type}

## ä½¿ç”¨ç›®çš„
{self.intended_use}

## æ€§èƒ½ãƒ¡ãƒˆãƒªã‚¯ã‚¹
"""
        for metric, value in self.performance.items():
            md += f"- {metric}: {value}\n"

        md += "\n## åˆ¶é™äº‹é …\n"
        for limitation in self.limitations:
            md += f"- {limitation}\n"

        md += "\n## ãƒã‚¤ã‚¢ã‚¹\n"
        for bias in self.biases:
            md += f"- {bias}\n"

        md += "\n## å€«ç†çš„è€ƒæ…®äº‹é …\n"
        for consideration in self.ethical_considerations:
            md += f"- {consideration}\n"

        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(md)
        print(f"âœ“ Markdownå½¢å¼ã§ä¿å­˜: {filepath}")

# ãƒ¢ãƒ‡ãƒ«ã‚«ãƒ¼ãƒ‰ä½œæˆ
card = ModelCard(
    model_name="ä½å®…ãƒ­ãƒ¼ãƒ³æ‰¿èªãƒ¢ãƒ‡ãƒ«",
    version="2.1.0",
    date="2025-10-21",
    authors=["Data Science Team", "Risk Management Team"],
    model_type="Gradient Boosting Classifier",
    intended_use="ä½å®…ãƒ­ãƒ¼ãƒ³ç”³è«‹ã®åˆæœŸå¯©æŸ»ã«ãŠã‘ã‚‹æ‰¿èªå¯èƒ½æ€§ã®è©•ä¾¡",
    performance={
        "Accuracy": "0.87",
        "Precision": "0.84",
        "Recall": "0.89",
        "F1 Score": "0.865",
        "ROC AUC": "0.92"
    },
    limitations=[
        "å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¯éå»3å¹´é–“ã«é™å®šã•ã‚Œã¦ãŠã‚Šã€é•·æœŸçš„ãªçµŒæ¸ˆå¤‰å‹•ã«ã¯å¯¾å¿œã—ã¦ã„ãªã„",
        "ç”³è«‹è€…ã®å¹´é½¢ãŒ25æ­³æœªæº€ã®å ´åˆã€ã‚µãƒ³ãƒ—ãƒ«æ•°ãŒå°‘ãªãäºˆæ¸¬ç²¾åº¦ãŒä½ä¸‹ã™ã‚‹",
        "è‡ªå–¶æ¥­è€…ã®ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ãŠã‚Šã€ã“ã®å±¤ã¸ã®äºˆæ¸¬ã¯ä¿å®ˆçš„ã«ãªã‚‹å‚¾å‘"
    ],
    biases=[
        "éƒ½å¸‚éƒ¨ã®ãƒ‡ãƒ¼ã‚¿ãŒè¾²æ‘éƒ¨ã‚ˆã‚Šå¤šãã€åœ°åŸŸã«ã‚ˆã‚‹äºˆæ¸¬ç²¾åº¦ã«å·®ãŒã‚ã‚‹",
        "é«˜æ‰€å¾—å±¤ã®ãƒ‡ãƒ¼ã‚¿ãŒå¤šãã€ä½æ‰€å¾—å±¤ã¸ã®äºˆæ¸¬ãŒå³ã—ããªã‚‹å‚¾å‘",
        "æ€§åˆ¥ã«ã‚ˆã‚‹æ‰¿èªç‡ã®å·®ç•°ãŒè¦³å¯Ÿã•ã‚Œã¦ãŠã‚Šã€å®šæœŸçš„ãªç›£è¦–ãŒå¿…è¦"
    ],
    ethical_considerations=[
        "ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬ã¯å‚è€ƒæƒ…å ±ã§ã‚ã‚Šã€æœ€çµ‚åˆ¤æ–­ã¯äººé–“ã®å¯©æŸ»å“¡ãŒè¡Œã†",
        "æ‹’å¦ã•ã‚ŒãŸå ´åˆã€ãã®ç†ç”±ã‚’èª¬æ˜å¯èƒ½ãªå½¢ã§æä¾›ã™ã‚‹",
        "å…¬å¹³æ€§ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’å®šæœŸçš„ã«ç›£è¦–ã—ã€ä¸å½“ãªå·®åˆ¥ãŒãªã„ã“ã¨ã‚’ç¢ºèª",
        "å€‹äººæƒ…å ±ä¿è­·è¦åˆ¶ã«æº–æ‹ ã—ãŸãƒ‡ãƒ¼ã‚¿ç®¡ç†ã‚’å®Ÿæ–½"
    ]
)

# ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
print("=== ãƒ¢ãƒ‡ãƒ«ã‚«ãƒ¼ãƒ‰ã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ ===\n")
card.to_json("model_card.json")
card.to_markdown("MODEL_CARD.md")

print("\nãƒ¢ãƒ‡ãƒ«ã‚«ãƒ¼ãƒ‰ã«ã¯ä»¥ä¸‹ãŒå«ã¾ã‚Œã¾ã™:")
print("  âœ“ åŸºæœ¬æƒ…å ±ã¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿")
print("  âœ“ æ€§èƒ½ãƒ¡ãƒˆãƒªã‚¯ã‚¹")
print("  âœ“ åˆ¶é™äº‹é …ã®æ˜ç¤º")
print("  âœ“ ãƒã‚¤ã‚¢ã‚¹ã®é–‹ç¤º")
print("  âœ“ å€«ç†çš„è€ƒæ…®äº‹é …")
</code></pre>

</details>

<hr>

<h2>å‚è€ƒæ–‡çŒ®</h2>

<ol>
<li>Sato, D., Wider, A., & Windheuser, C. (2019). <em>Continuous Delivery for Machine Learning</em>. Martin Fowler's Blog.</li>
<li>Polyzotis, N., et al. (2018). <em>Data Lifecycle Challenges in Production Machine Learning: A Survey</em>. ACM SIGMOD Record.</li>
<li>Mitchell, M., et al. (2019). <em>Model Cards for Model Reporting</em>. Proceedings of FAT* 2019.</li>
<li>Paleyes, A., Urma, R. G., & Lawrence, N. D. (2022). <em>Challenges in Deploying Machine Learning: A Survey of Case Studies</em>. ACM Computing Surveys.</li>
<li>Sculley, D., et al. (2015). <em>Hidden Technical Debt in Machine Learning Systems</em>. NIPS 2015.</li>
</ol>

<div class="navigation">
    <a href="chapter3-experiment-tracking.html" class="nav-button">â† å‰ã®ç« : å®Ÿé¨“ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°</a>
    <a href="chapter5-model-deployment.html" class="nav-button">æ¬¡ã®ç« : ãƒ¢ãƒ‡ãƒ«ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆ â†’</a>
</div>

    </main>

    
    <section class="disclaimer">
        <h3>å…è²¬äº‹é …</h3>
        <ul>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯æ•™è‚²ãƒ»ç ”ç©¶ãƒ»æƒ…å ±æä¾›ã®ã¿ã‚’ç›®çš„ã¨ã—ã¦ãŠã‚Šã€å°‚é–€çš„ãªåŠ©è¨€(æ³•å¾‹ãƒ»ä¼šè¨ˆãƒ»æŠ€è¡“çš„ä¿è¨¼ãªã©)ã‚’æä¾›ã™ã‚‹ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŠã‚ˆã³ä»˜éšã™ã‚‹ã‚³ãƒ¼ãƒ‰ä¾‹ã¯ã€Œç¾çŠ¶æœ‰å§¿(AS IS)ã€ã§æä¾›ã•ã‚Œã€æ˜ç¤ºã¾ãŸã¯é»™ç¤ºã‚’å•ã‚ãšã€å•†å“æ€§ã€ç‰¹å®šç›®çš„é©åˆæ€§ã€æ¨©åˆ©éä¾µå®³ã€æ­£ç¢ºæ€§ãƒ»å®Œå…¨æ€§ã€å‹•ä½œãƒ»å®‰å…¨æ€§ç­‰ã„ã‹ãªã‚‹ä¿è¨¼ã‚‚ã—ã¾ã›ã‚“ã€‚</li>
            <li>å¤–éƒ¨ãƒªãƒ³ã‚¯ã€ç¬¬ä¸‰è€…ãŒæä¾›ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ»ãƒ„ãƒ¼ãƒ«ãƒ»ãƒ©ã‚¤ãƒ–ãƒ©ãƒªç­‰ã®å†…å®¹ãƒ»å¯ç”¨æ€§ãƒ»å®‰å…¨æ€§ã«ã¤ã„ã¦ã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯ä¸€åˆ‡ã®è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®åˆ©ç”¨ãƒ»å®Ÿè¡Œãƒ»è§£é‡ˆã«ã‚ˆã‚Šç›´æ¥çš„ãƒ»é–“æ¥çš„ãƒ»ä»˜éšçš„ãƒ»ç‰¹åˆ¥ãƒ»çµæœçš„ãƒ»æ‡²ç½°çš„æå®³ãŒç”Ÿã˜ãŸå ´åˆã§ã‚‚ã€é©ç”¨æ³•ã§è¨±å®¹ã•ã‚Œã‚‹æœ€å¤§é™ã®ç¯„å›²ã§ã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å†…å®¹ã¯ã€äºˆå‘Šãªãå¤‰æ›´ãƒ»æ›´æ–°ãƒ»æä¾›åœæ­¢ã•ã‚Œã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®è‘—ä½œæ¨©ãƒ»ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯æ˜è¨˜ã•ã‚ŒãŸæ¡ä»¶(ä¾‹: CC BY 4.0)ã«å¾“ã„ã¾ã™ã€‚å½“è©²ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯é€šå¸¸ã€ç„¡ä¿è¨¼æ¡é …ã‚’å«ã¿ã¾ã™ã€‚</li>
        </ul>
    </section>

<footer>
        <p><strong>ä½œæˆè€…</strong>: AI Terakoya Content Team</p>
        <p><strong>ãƒãƒ¼ã‚¸ãƒ§ãƒ³</strong>: 1.0 | <strong>ä½œæˆæ—¥</strong>: 2025-10-21</p>
        <p><strong>ãƒ©ã‚¤ã‚»ãƒ³ã‚¹</strong>: Creative Commons BY 4.0</p>
        <p>Â© 2025 AI Terakoya. All rights reserved.</p>
    </footer>
</body>
</html>
