<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Chapter 4: „É¢„Éá„É´Ë©ï‰æ°„Å®ÂÆüË∑µ - AI Terakoya</title>

    <style>
        :root {
            --color-primary: #2c3e50;
            --color-primary-dark: #1a252f;
            --color-accent: #7b2cbf;
            --color-accent-light: #9d4edd;
            --color-text: #2d3748;
            --color-text-light: #4a5568;
            --color-bg: #ffffff;
            --color-bg-alt: #f7fafc;
            --color-border: #e2e8f0;
            --color-code-bg: #f8f9fa;
            --color-link: #3182ce;
            --color-link-hover: #2c5aa0;

            --spacing-xs: 0.5rem;
            --spacing-sm: 1rem;
            --spacing-md: 1.5rem;
            --spacing-lg: 2rem;
            --spacing-xl: 3rem;

            --font-body: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            --font-mono: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;

            --border-radius: 8px;
            --box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: var(--font-body);
            line-height: 1.7;
            color: var(--color-text);
            background-color: var(--color-bg);
            font-size: 16px;
        }

        header {
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            padding: var(--spacing-xl) var(--spacing-md);
            margin-bottom: var(--spacing-xl);
            box-shadow: var(--box-shadow);
        }

        .header-content {
            max-width: 900px;
            margin: 0 auto;
        }

        h1 {
            font-size: 2rem;
            font-weight: 700;
            margin-bottom: var(--spacing-sm);
            line-height: 1.2;
        }

        .subtitle {
            font-size: 1.1rem;
            opacity: 0.95;
            font-weight: 400;
            margin-bottom: var(--spacing-md);
        }

        .meta {
            display: flex;
            flex-wrap: wrap;
            gap: var(--spacing-md);
            font-size: 0.9rem;
            opacity: 0.9;
        }

        .meta-item {
            display: flex;
            align-items: center;
            gap: 0.3rem;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 0 var(--spacing-md) var(--spacing-xl);
        }

        h2 {
            font-size: 1.75rem;
            color: var(--color-primary);
            margin-top: var(--spacing-xl);
            margin-bottom: var(--spacing-md);
            padding-bottom: var(--spacing-xs);
            border-bottom: 3px solid var(--color-accent);
        }

        h3 {
            font-size: 1.4rem;
            color: var(--color-primary);
            margin-top: var(--spacing-lg);
            margin-bottom: var(--spacing-sm);
        }

        h4 {
            font-size: 1.1rem;
            color: var(--color-primary-dark);
            margin-top: var(--spacing-md);
            margin-bottom: var(--spacing-sm);
        }

        p {
            margin-bottom: var(--spacing-md);
            color: var(--color-text);
        }

        a {
            color: var(--color-link);
            text-decoration: none;
            transition: color 0.2s;
        }

        a:hover {
            color: var(--color-link-hover);
            text-decoration: underline;
        }

        ul, ol {
            margin-left: var(--spacing-lg);
            margin-bottom: var(--spacing-md);
        }

        li {
            margin-bottom: var(--spacing-xs);
            color: var(--color-text);
        }

        pre {
            background-color: var(--color-code-bg);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            overflow-x: auto;
            margin-bottom: var(--spacing-md);
            font-family: var(--font-mono);
            font-size: 0.9rem;
            line-height: 1.5;
        }

        code {
            font-family: var(--font-mono);
            font-size: 0.9em;
            background-color: var(--color-code-bg);
            padding: 0.2em 0.4em;
            border-radius: 3px;
        }

        pre code {
            background-color: transparent;
            padding: 0;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: var(--spacing-md);
            font-size: 0.95rem;
        }

        th, td {
            border: 1px solid var(--color-border);
            padding: var(--spacing-sm);
            text-align: left;
        }

        th {
            background-color: var(--color-bg-alt);
            font-weight: 600;
            color: var(--color-primary);
        }

        blockquote {
            border-left: 4px solid var(--color-accent);
            padding-left: var(--spacing-md);
            margin: var(--spacing-md) 0;
            color: var(--color-text-light);
            font-style: italic;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        .mermaid {
            text-align: center;
            margin: var(--spacing-lg) 0;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        details {
            background-color: var(--color-bg-alt);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            margin-bottom: var(--spacing-md);
        }

        summary {
            cursor: pointer;
            font-weight: 600;
            color: var(--color-primary);
            user-select: none;
            padding: var(--spacing-xs);
            margin: calc(-1 * var(--spacing-md));
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        summary:hover {
            background-color: rgba(123, 44, 191, 0.1);
        }

        details[open] summary {
            margin-bottom: var(--spacing-md);
            border-bottom: 1px solid var(--color-border);
        }

        .learning-objectives {
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
            padding: var(--spacing-lg);
            border-radius: var(--border-radius);
            border-left: 4px solid var(--color-accent);
            margin-bottom: var(--spacing-xl);
        }

        .learning-objectives h2 {
            margin-top: 0;
            border-bottom: none;
        }

        .navigation {
            display: flex;
            justify-content: space-between;
            gap: var(--spacing-md);
            margin: var(--spacing-xl) 0;
            padding-top: var(--spacing-lg);
            border-top: 2px solid var(--color-border);
        }

        .nav-button {
            flex: 1;
            padding: var(--spacing-md);
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            border-radius: var(--border-radius);
            text-align: center;
            font-weight: 600;
            transition: transform 0.2s, box-shadow 0.2s;
            box-shadow: var(--box-shadow);
        }

        .nav-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
            text-decoration: none;
        }

        footer {
            margin-top: var(--spacing-xl);
            padding: var(--spacing-lg) var(--spacing-md);
            background-color: var(--color-bg-alt);
            border-top: 1px solid var(--color-border);
            text-align: center;
            font-size: 0.9rem;
            color: var(--color-text-light);
        }

        @media (max-width: 768px) {
            h1 {
                font-size: 1.5rem;
            }

            h2 {
                font-size: 1.4rem;
            }

            h3 {
                font-size: 1.2rem;
            }

            .meta {
                font-size: 0.85rem;
            }

            .navigation {
                flex-direction: column;
            }

            table {
                font-size: 0.85rem;
            }

            th, td {
                padding: var(--spacing-xs);
            }
        }
    </style>

    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
        mermaid.initialize({ startOnLoad: true, theme: 'default' });
    </script>

    <!-- MathJax for LaTeX equation rendering -->
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\(', '\)']],
                displayMath: [['$$', '$$'], ['\[', '\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
                ignoreHtmlClass: 'mermaid'
            }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" async></script>
</head>
<body>
    <header>
        <div class="header-content">
            <h1>Chapter 4: „É¢„Éá„É´Ë©ï‰æ°„Å®ÂÆüË∑µ</h1>
            <p class="subtitle"></p>
            <div class="meta">
                <span class="meta-item">üìñ Ë™≠‰∫ÜÊôÇÈñì: 30-35ÂàÜ</span>
                <span class="meta-item">üìä Èõ£ÊòìÂ∫¶: ÂàùÁ¥ö„Äú‰∏≠Á¥ö</span>
                <span class="meta-item">üíª „Ç≥„Éº„Éâ‰æã: 0ÂÄã</span>
                <span class="meta-item">üìù ÊºîÁøíÂïèÈ°å: 0Âïè</span>
            </div>
        </div>
    </header>

    <main class="container">
<h1>Chapter 4: „É¢„Éá„É´Ë©ï‰æ°„Å®ÂÆüË∑µ</h1>
<h2>Êú¨Á´†„ÅÆÊ¶ÇË¶Å</h2>
<p>Ê©üÊ¢∞Â≠¶Áøí„É¢„Éá„É´„ÅÆÁúü„ÅÆ‰æ°ÂÄ§„ÅØ„ÄÅÊñ∞„Åó„ÅÑ„Éá„Éº„Çø„Å´ÂØæ„Åô„ÇãÊÄßËÉΩ„ÅßÊ±∫„Åæ„Çä„Åæ„Åô„ÄÇÊú¨Á´†„Åß„ÅØ„ÄÅ„É¢„Éá„É´„ÇíÈÅ©Âàá„Å´Ë©ï‰æ°„Åó„ÄÅÈÅéÂ≠¶Áøí„ÇíÈò≤„Åé„ÄÅÊÄßËÉΩ„ÇíÊúÄÈÅ©Âåñ„Åô„Çã„Åü„ÇÅ„ÅÆÂÆüË∑µÁöÑ„Å™„ÉÜ„ÇØ„Éã„ÉÉ„ÇØ„ÇíÂ≠¶„Å≥„Åæ„Åô„ÄÇ</p>
<h3>Â≠¶ÁøíÁõÆÊ®ô</h3>
<ul>
<li>‚úÖ Ë®ìÁ∑¥„ÉªÊ§úË®º„Éª„ÉÜ„Çπ„Éà„Éá„Éº„Çø„ÅÆÂàÜÂâ≤ÊñπÊ≥ï„ÇíÁêÜËß£„Åô„Çã</li>
<li>‚úÖ ‰∫§Â∑ÆÊ§úË®º„Åß„É¢„Éá„É´„ÅÆÊ±éÂåñÊÄßËÉΩ„ÇíË©ï‰æ°„Åß„Åç„Çã</li>
<li>‚úÖ ÈÅ©Âàá„Å™Ë©ï‰æ°ÊåáÊ®ô„ÇíÈÅ∏Êäû„Åß„Åç„Çã</li>
<li>‚úÖ ÈÅéÂ≠¶Áøí„ÇíÊ§úÂá∫„Åó„ÄÅÂØæÁ≠ñ„Åß„Åç„Çã</li>
<li>‚úÖ „Éè„Ç§„Éë„Éº„Éë„É©„É°„Éº„Çø„ÉÅ„É•„Éº„Éã„É≥„Ç∞„ÇíÂÆüË∑µ„Åß„Åç„Çã</li>
</ul>
<hr />
<h2>1. „Éá„Éº„ÇøÂàÜÂâ≤„ÅÆÂü∫Á§é</h2>
<h3>1.1 „Å™„Åú„Éá„Éº„Çø„ÇíÂàÜÂâ≤„Åô„Çã„ÅÆ„Åã</h3>
<p><strong>ÁõÆÁöÑ</strong>: „É¢„Éá„É´„ÅåÊú™Áü•„ÅÆ„Éá„Éº„Çø„Å´ÂØæ„Åó„Å¶„Å©„Çå„Å†„Åë„ÅÜ„Åæ„ÅèÊ©üËÉΩ„Åô„Çã„Åã„ÇíË©ï‰æ°</p>
<div class="mermaid">
graph LR
    A[ÂÖ®„Éá„Éº„Çø] --> B[Ë®ìÁ∑¥„Éá„Éº„Çø<br/>70-80%]
    A --> C[„ÉÜ„Çπ„Éà„Éá„Éº„Çø<br/>20-30%]
    B --> D[„É¢„Éá„É´Â≠¶Áøí]
    D --> E[Ë®ìÁ∑¥„Éá„Éº„Çø„ÅßË©ï‰æ°]
    D --> F[„ÉÜ„Çπ„Éà„Éá„Éº„Çø„ÅßË©ï‰æ°]
    F --> G[Ê±éÂåñÊÄßËÉΩ]
</div>

<h3>1.2 Âü∫Êú¨ÁöÑ„Å™ÂàÜÂâ≤</h3>
<pre><code class="language-python">from sklearn.model_selection import train_test_split
from sklearn.datasets import load_iris

# „Éá„Éº„ÇøË™≠„ÅøËæº„Åø
iris = load_iris()
X, y = iris.data, iris.target

# Ë®ìÁ∑¥„Éá„Éº„Çø:„ÉÜ„Çπ„Éà„Éá„Éº„Çø = 7:3„Å´ÂàÜÂâ≤
X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.3,     # „ÉÜ„Çπ„Éà„Éá„Éº„Çø„ÅÆÂâ≤Âêà
    random_state=42,   # ÂÜçÁèæÊÄß„ÅÆ„Åü„ÇÅÂõ∫ÂÆö
    stratify=y         # „ÇØ„É©„ÇπÊØîÁéá„Çí‰øùÊåÅ
)

print(f&quot;Ë®ìÁ∑¥„Éá„Éº„ÇøÊï∞: {len(X_train)}&quot;)
print(f&quot;„ÉÜ„Çπ„Éà„Éá„Éº„ÇøÊï∞: {len(X_test)}&quot;)
print(f&quot;Ë®ìÁ∑¥„Éá„Éº„Çø„ÅÆ„ÇØ„É©„ÇπÂàÜÂ∏É: {np.bincount(y_train)}&quot;)
print(f&quot;„ÉÜ„Çπ„Éà„Éá„Éº„Çø„ÅÆ„ÇØ„É©„ÇπÂàÜÂ∏É: {np.bincount(y_test)}&quot;)
</code></pre>
<h3>1.3 Ë®ìÁ∑¥„ÉªÊ§úË®º„Éª„ÉÜ„Çπ„Éà„ÅÆ3ÂàÜÂâ≤</h3>
<p><strong>„Éô„Çπ„Éà„Éó„É©„ÇØ„ÉÜ„Ç£„Çπ:</strong></p>
<div class="mermaid">
graph TD
    A[ÂÖ®„Éá„Éº„Çø] --> B[Ë®ìÁ∑¥„Éá„Éº„Çø 60%]
    A --> C[Ê§úË®º„Éá„Éº„Çø 20%]
    A --> D[„ÉÜ„Çπ„Éà„Éá„Éº„Çø 20%]
    B --> E[„É¢„Éá„É´Â≠¶Áøí]
    C --> F[„Éè„Ç§„Éë„Éº„Éë„É©„É°„Éº„ÇøË™øÊï¥]
    E --> F
    F --> G[ÊúÄÁµÇ„É¢„Éá„É´]
    G --> H[„ÉÜ„Çπ„Éà„Éá„Éº„Çø„ÅßÊúÄÁµÇË©ï‰æ°]
    D --> H
</div>

<pre><code class="language-python"># 3ÂàÜÂâ≤„ÅÆÂÆüË£Ö
X_temp, X_test, y_temp, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

X_train, X_val, y_train, y_val = train_test_split(
    X_temp, y_temp, test_size=0.25, random_state=42, stratify=y_temp
)  # 0.25 * 0.8 = 0.2 (ÂÖ®‰Ωì„ÅÆ20%)

print(f&quot;Ë®ìÁ∑¥: {len(X_train)}, Ê§úË®º: {len(X_val)}, „ÉÜ„Çπ„Éà: {len(X_test)}&quot;)
</code></pre>
<hr />
<h2>2. ‰∫§Â∑ÆÊ§úË®ºÔºàCross-ValidationÔºâ</h2>
<h3>2.1 K-Fold‰∫§Â∑ÆÊ§úË®º</h3>
<p><strong>K-Fold CV</strong>„ÅØ„ÄÅ„Éá„Éº„Çø„ÇíKÂÄã„Å´ÂàÜÂâ≤„Åó„ÄÅKÂõû„ÅÆË®ìÁ∑¥„ÉªË©ï‰æ°„ÇíË°å„ÅÜÊâãÊ≥ï„Åß„Åô„ÄÇ</p>
<div class="mermaid">
graph TD
    A[„Éá„Éº„Çø„ÇíKÂàÜÂâ≤] --> B[Fold 1„Çí„ÉÜ„Çπ„Éà<br/>ÊÆã„Çä„ÅßË®ìÁ∑¥]
    A --> C[Fold 2„Çí„ÉÜ„Çπ„Éà<br/>ÊÆã„Çä„ÅßË®ìÁ∑¥]
    A --> D[Fold 3„Çí„ÉÜ„Çπ„Éà<br/>ÊÆã„Çä„ÅßË®ìÁ∑¥]
    A --> E[...]
    B --> F[KÂÄã„ÅÆ„Çπ„Ç≥„Ç¢]
    C --> F
    D --> F
    E --> F
    F --> G[Âπ≥Âùá„Çπ„Ç≥„Ç¢]
</div>

<h3>2.2 ÂÆüË£Ö‰æã</h3>
<pre><code class="language-python">from sklearn.model_selection import cross_val_score
from sklearn.tree import DecisionTreeClassifier
import numpy as np

# „É¢„Éá„É´‰ΩúÊàê
model = DecisionTreeClassifier(max_depth=5, random_state=42)

# 5-Fold‰∫§Â∑ÆÊ§úË®º
scores = cross_val_score(model, X, y, cv=5)

print(&quot;ÂêÑFold„ÅÆ„Çπ„Ç≥„Ç¢:&quot;, scores)
print(f&quot;Âπ≥Âùá„Çπ„Ç≥„Ç¢: {scores.mean():.3f} (+/- {scores.std():.3f})&quot;)
</code></pre>
<h3>2.3 Â±§ÂåñK-Fold‰∫§Â∑ÆÊ§úË®º</h3>
<p>„ÇØ„É©„Çπ„ÅÆÂàÜÂ∏É„ÇíÂêÑFold„Åß‰øùÊåÅÔºö</p>
<pre><code class="language-python">from sklearn.model_selection import StratifiedKFold, cross_validate

# Â±§ÂåñK-Fold
skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

# Ë§áÊï∞„ÅÆË©ï‰æ°ÊåáÊ®ô
scoring = ['accuracy', 'precision_macro', 'recall_macro', 'f1_macro']

results = cross_validate(model, X, y, cv=skf, scoring=scoring)

for metric in scoring:
    scores = results[f'test_{metric}']
    print(f&quot;{metric}: {scores.mean():.3f} (+/- {scores.std():.3f})&quot;)
</code></pre>
<h3>2.4 Leave-One-Out‰∫§Â∑ÆÊ§úË®ºÔºàLOOÔºâ</h3>
<p>„Éá„Éº„ÇøÊï∞„ÅåÂ∞ë„Å™„ÅÑÂ†¥Âêà„Å´ÊúâÂäπÔºö</p>
<pre><code class="language-python">from sklearn.model_selection import LeaveOneOut

loo = LeaveOneOut()
scores = cross_val_score(model, X, y, cv=loo)

print(f&quot;LOOÂπ≥Âùá„Çπ„Ç≥„Ç¢: {scores.mean():.3f}&quot;)
print(f&quot;ÂÆüË°åÂõûÊï∞: {len(scores)}&quot;)  # „Çµ„É≥„Éó„É´Êï∞„Å®Âêå„Åò
</code></pre>
<hr />
<h2>3. Ë©ï‰æ°ÊåáÊ®ô</h2>
<h3>3.1 ÂàÜÈ°ûÂïèÈ°å„ÅÆË©ï‰æ°ÊåáÊ®ô</h3>
<h4>Ê∑∑ÂêåË°åÂàóÔºàConfusion MatrixÔºâ</h4>
<pre><code class="language-python">from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier

# „Éá„Éº„ÇøÊ∫ñÂÇô
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42
)

# „É¢„Éá„É´Ë®ìÁ∑¥„Å®‰∫àÊ∏¨
model = DecisionTreeClassifier(max_depth=5, random_state=42)
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

# Ê∑∑ÂêåË°åÂàó
cm = confusion_matrix(y_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm,
                              display_labels=iris.target_names)
disp.plot(cmap='Blues')
plt.title('Ê∑∑ÂêåË°åÂàó')
plt.show()

print(&quot;Ê∑∑ÂêåË°åÂàó:&quot;)
print(cm)
</code></pre>
<h4>‰∏ªË¶Å„Å™Ë©ï‰æ°ÊåáÊ®ô</h4>
<pre><code class="language-python">from sklearn.metrics import (accuracy_score, precision_score,
                            recall_score, f1_score, classification_report)

# ÂêÑÊåáÊ®ô„ÅÆË®àÁÆó
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average='macro')
recall = recall_score(y_test, y_pred, average='macro')
f1 = f1_score(y_test, y_pred, average='macro')

print(f&quot;Ê≠£Ëß£ÁéáÔºàAccuracyÔºâ: {accuracy:.3f}&quot;)
print(f&quot;ÈÅ©ÂêàÁéáÔºàPrecisionÔºâ: {precision:.3f}&quot;)
print(f&quot;ÂÜçÁèæÁéáÔºàRecallÔºâ: {recall:.3f}&quot;)
print(f&quot;F1„Çπ„Ç≥„Ç¢: {f1:.3f}&quot;)

# Ë©≥Á¥∞„É¨„Éù„Éº„Éà
print(&quot;\nÂàÜÈ°û„É¨„Éù„Éº„Éà:&quot;)
print(classification_report(y_test, y_pred, target_names=iris.target_names))
</code></pre>
<p><strong>ÂêÑÊåáÊ®ô„ÅÆÊÑèÂë≥:</strong></p>
<table>
<thead>
<tr>
<th>ÊåáÊ®ô</th>
<th>ÂÆöÁæ©</th>
<th>‰Ωø„ÅÑ„Å©„Åì„Çç</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Ê≠£Ëß£ÁéáÔºàAccuracyÔºâ</strong></td>
<td>$\frac{TP + TN}{TP + TN + FP + FN}$</td>
<td>„Éê„É©„É≥„Çπ„ÅÆÂèñ„Çå„Åü„Éá„Éº„Çø</td>
</tr>
<tr>
<td><strong>ÈÅ©ÂêàÁéáÔºàPrecisionÔºâ</strong></td>
<td>$\frac{TP}{TP + FP}$</td>
<td>ÂÅΩÈôΩÊÄß„ÇíÊ∏õ„Çâ„Åó„Åü„ÅÑÂ†¥Âêà</td>
</tr>
<tr>
<td><strong>ÂÜçÁèæÁéáÔºàRecallÔºâ</strong></td>
<td>$\frac{TP}{TP + FN}$</td>
<td>ÂÅΩÈô∞ÊÄß„ÇíÊ∏õ„Çâ„Åó„Åü„ÅÑÂ†¥Âêà</td>
</tr>
<tr>
<td><strong>F1„Çπ„Ç≥„Ç¢</strong></td>
<td>$2 \times \frac{Precision \times Recall}{Precision + Recall}$</td>
<td>ÈÅ©ÂêàÁéá„Å®ÂÜçÁèæÁéá„ÅÆ„Éê„É©„É≥„Çπ</td>
</tr>
</tbody>
</table>
<h4>ROCÊõ≤Á∑ö„Å®AUC</h4>
<pre><code class="language-python">from sklearn.metrics import roc_curve, auc, RocCurveDisplay
from sklearn.preprocessing import label_binarize
from sklearn.multiclass import OneVsRestClassifier
from sklearn.linear_model import LogisticRegression

# 2ÂÄ§ÂàÜÈ°û„ÅÆ‰æãÔºàÁ∞°Áï•Âåñ„ÅÆ„Åü„ÇÅ2„ÇØ„É©„Çπ„ÅÆ„Åø‰ΩøÁî®Ôºâ
X_binary = X[y != 2]
y_binary = y[y != 2]

X_train, X_test, y_train, y_test = train_test_split(
    X_binary, y_binary, test_size=0.3, random_state=42
)

# „É≠„Ç∏„Çπ„ÉÜ„Ç£„ÉÉ„ÇØÂõûÂ∏∞„ÅßÁ¢∫Áéá‰∫àÊ∏¨
model = LogisticRegression(random_state=42)
model.fit(X_train, y_train)
y_score = model.predict_proba(X_test)[:, 1]

# ROCÊõ≤Á∑ö
fpr, tpr, thresholds = roc_curve(y_test, y_score)
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='darkorange', lw=2,
        label=f'ROCÊõ≤Á∑ö (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='„É©„É≥„ÉÄ„É†')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('ÂÅΩÈôΩÊÄßÁéáÔºàFPRÔºâ')
plt.ylabel('ÁúüÈôΩÊÄßÁéáÔºàTPRÔºâ')
plt.title('ROCÊõ≤Á∑ö')
plt.legend(loc=&quot;lower right&quot;)
plt.grid(True)
plt.show()
</code></pre>
<h3>3.2 ÂõûÂ∏∞ÂïèÈ°å„ÅÆË©ï‰æ°ÊåáÊ®ô</h3>
<pre><code class="language-python">from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.linear_model import LinearRegression
from sklearn.datasets import fetch_california_housing

# ÂõûÂ∏∞„Éá„Éº„Çø
housing = fetch_california_housing()
X_reg, y_reg = housing.data, housing.target

X_train, X_test, y_train, y_test = train_test_split(
    X_reg, y_reg, test_size=0.3, random_state=42
)

# Á∑öÂΩ¢ÂõûÂ∏∞
model = LinearRegression()
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

# Ë©ï‰æ°ÊåáÊ®ô
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f&quot;Âπ≥Âùá‰∫å‰πóË™§Â∑ÆÔºàMSEÔºâ: {mse:.3f}&quot;)
print(f&quot;Âπ≥ÂùáÂπ≥ÊñπÊ†πË™§Â∑ÆÔºàRMSEÔºâ: {rmse:.3f}&quot;)
print(f&quot;Âπ≥ÂùáÁµ∂ÂØæË™§Â∑ÆÔºàMAEÔºâ: {mae:.3f}&quot;)
print(f&quot;Ê±∫ÂÆö‰øÇÊï∞ÔºàR¬≤Ôºâ: {r2:.3f}&quot;)
</code></pre>
<p><strong>ÂõûÂ∏∞ÊåáÊ®ô„ÅÆÊÑèÂë≥:</strong></p>
<table>
<thead>
<tr>
<th>ÊåáÊ®ô</th>
<th>ÂÆöÁæ©</th>
<th>ÁâπÂæ¥</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>MSE</strong></td>
<td>$\frac{1}{n}\sum (y_i - \hat{y}_i)^2$</td>
<td>Â§ñ„ÇåÂÄ§„Å´ÊïèÊÑü</td>
</tr>
<tr>
<td><strong>RMSE</strong></td>
<td>$\sqrt{MSE}$</td>
<td>ÂÖÉ„ÅÆ„Çπ„Ç±„Éº„É´„ÅßËß£ÈáàÂèØËÉΩ</td>
</tr>
<tr>
<td><strong>MAE</strong></td>
<td>$\frac{1}{n}\sum</td>
<td>y_i - \hat{y}_i</td>
</tr>
<tr>
<td><strong>R¬≤</strong></td>
<td>$1 - \frac{SS_{res}}{SS_{tot}}$</td>
<td>„É¢„Éá„É´„ÅÆË™¨ÊòéÂäõÔºà0„Äú1Ôºâ</td>
</tr>
</tbody>
</table>
<hr />
<h2>4. ÈÅéÂ≠¶Áøí„Å®Ê≠£ÂâáÂåñ</h2>
<h3>4.1 ÈÅéÂ≠¶ÁøíÔºàOverfittingÔºâ„Å®„ÅØ</h3>
<p><strong>ÈÅéÂ≠¶Áøí</strong>„ÅØ„ÄÅ„É¢„Éá„É´„ÅåË®ìÁ∑¥„Éá„Éº„Çø„Å´ÈÅéÂ∫¶„Å´ÈÅ©Âêà„Åó„ÄÅÊñ∞„Åó„ÅÑ„Éá„Éº„Çø„Å´ÂØæ„Åô„ÇãÊÄßËÉΩ„Åå‰Ωé‰∏ã„Åô„ÇãÁèæË±°„Åß„Åô„ÄÇ</p>
<div class="mermaid">
graph LR
    A[„É¢„Éá„É´„ÅÆË§áÈõë„Åï] --> B[ÈÅéÂ∞ëÂ≠¶Áøí<br/>Underfitting]
    A --> C[ÈÅ©Âàá„Å™Â≠¶Áøí]
    A --> D[ÈÅéÂ≠¶Áøí<br/>Overfitting]
</div>

<h3>4.2 Â≠¶ÁøíÊõ≤Á∑ö„Å´„Çà„ÇãÊ§úÂá∫</h3>
<pre><code class="language-python">from sklearn.model_selection import learning_curve

# Â≠¶ÁøíÊõ≤Á∑ö„ÅÆ„Éó„É≠„ÉÉ„Éà
def plot_learning_curve(estimator, X, y, cv=5):
    train_sizes, train_scores, val_scores = learning_curve(
        estimator, X, y, cv=cv,
        train_sizes=np.linspace(0.1, 1.0, 10),
        random_state=42
    )

    train_mean = np.mean(train_scores, axis=1)
    train_std = np.std(train_scores, axis=1)
    val_mean = np.mean(val_scores, axis=1)
    val_std = np.std(val_scores, axis=1)

    plt.figure(figsize=(10, 6))
    plt.plot(train_sizes, train_mean, label='Ë®ìÁ∑¥„Çπ„Ç≥„Ç¢', color='blue', marker='o')
    plt.fill_between(train_sizes, train_mean - train_std,
                     train_mean + train_std, alpha=0.15, color='blue')
    plt.plot(train_sizes, val_mean, label='Ê§úË®º„Çπ„Ç≥„Ç¢', color='red', marker='s')
    plt.fill_between(train_sizes, val_mean - val_std,
                     val_mean + val_std, alpha=0.15, color='red')

    plt.xlabel('Ë®ìÁ∑¥„Çµ„É≥„Éó„É´Êï∞')
    plt.ylabel('„Çπ„Ç≥„Ç¢')
    plt.title('Â≠¶ÁøíÊõ≤Á∑ö')
    plt.legend(loc='best')
    plt.grid(True)
    plt.show()

# ‰ΩøÁî®‰æã
model = DecisionTreeClassifier(max_depth=10, random_state=42)
plot_learning_curve(model, X, y)
</code></pre>
<h3>4.3 ÈÅéÂ≠¶Áøí„ÅÆÂØæÁ≠ñ</h3>
<h4>1. Ê≠£ÂâáÂåñÔºàRegularizationÔºâ</h4>
<p><strong>RidgeÂõûÂ∏∞ÔºàL2Ê≠£ÂâáÂåñÔºâ:</strong>
$$
J(w) = MSE + \alpha \sum_{i=1}^{n} w_i^2
$$</p>
<p><strong>LassoÂõûÂ∏∞ÔºàL1Ê≠£ÂâáÂåñÔºâ:</strong>
$$
J(w) = MSE + \alpha \sum_{i=1}^{n} |w_i|
$$</p>
<pre><code class="language-python">from sklearn.linear_model import Ridge, Lasso

# RidgeÂõûÂ∏∞
ridge = Ridge(alpha=1.0)
ridge.fit(X_train, y_train)
print(f&quot;Ridge R¬≤: {ridge.score(X_test, y_test):.3f}&quot;)

# LassoÂõûÂ∏∞
lasso = Lasso(alpha=0.1)
lasso.fit(X_train, y_train)
print(f&quot;Lasso R¬≤: {lasso.score(X_test, y_test):.3f}&quot;)
</code></pre>
<h4>2. Êó©ÊúüÂÅúÊ≠¢ÔºàEarly StoppingÔºâ</h4>
<pre><code class="language-python">from sklearn.ensemble import GradientBoostingClassifier

# Êó©ÊúüÂÅúÊ≠¢„Çí‰Ωø„Å£„ÅüÂãæÈÖç„Éñ„Éº„Çπ„ÉÜ„Ç£„É≥„Ç∞
gb = GradientBoostingClassifier(
    n_estimators=1000,
    learning_rate=0.1,
    validation_fraction=0.2,
    n_iter_no_change=10,  # 10ÂõûÊîπÂñÑ„Åó„Å™„Åë„Çå„Å∞ÂÅúÊ≠¢
    random_state=42
)

gb.fit(X_train, y_train)
print(f&quot;‰ΩøÁî®„Åó„ÅüÊé®ÂÆöÂô®Êï∞: {gb.n_estimators_}&quot;)
</code></pre>
<h4>3. „Éâ„É≠„ÉÉ„Éó„Ç¢„Ç¶„ÉàÔºà„Éã„É•„Éº„É©„É´„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØÔºâ</h4>
<h4>4. „Éá„Éº„ÇøÊã°Âºµ</h4>
<h4>5. „Ç¢„É≥„Çµ„É≥„Éñ„É´Â≠¶Áøí</h4>
<hr />
<h2>5. „Éè„Ç§„Éë„Éº„Éë„É©„É°„Éº„Çø„ÉÅ„É•„Éº„Éã„É≥„Ç∞</h2>
<h3>5.1 „Ç∞„É™„ÉÉ„Éâ„Çµ„Éº„ÉÅÔºàGrid SearchÔºâ</h3>
<p>ÂÖ®„Å¶„ÅÆÁµÑ„ÅøÂêà„Çè„Åõ„ÇíË©¶„ÅôÁ∂≤ÁæÖÁöÑÊé¢Á¥¢Ôºö</p>
<pre><code class="language-python">from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import RandomForestClassifier

# „Éë„É©„É°„Éº„Çø„Ç∞„É™„ÉÉ„Éâ
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [3, 5, 7, 10],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}

# „Ç∞„É™„ÉÉ„Éâ„Çµ„Éº„ÉÅ
grid_search = GridSearchCV(
    RandomForestClassifier(random_state=42),
    param_grid,
    cv=5,
    scoring='f1_macro',
    n_jobs=-1,  # ‰∏¶ÂàóÂÆüË°å
    verbose=1
)

grid_search.fit(X_train, y_train)

# ÊúÄÈÅ©„Å™„Éë„É©„É°„Éº„Çø
print(&quot;ÊúÄÈÅ©„Å™„Éë„É©„É°„Éº„Çø:&quot;)
print(grid_search.best_params_)
print(f&quot;\nÊúÄËâØ„Çπ„Ç≥„Ç¢: {grid_search.best_score_:.3f}&quot;)

# „ÉÜ„Çπ„Éà„Éá„Éº„Çø„ÅßË©ï‰æ°
best_model = grid_search.best_estimator_
test_score = best_model.score(X_test, y_test)
print(f&quot;„ÉÜ„Çπ„Éà„Çπ„Ç≥„Ç¢: {test_score:.3f}&quot;)
</code></pre>
<h3>5.2 „É©„É≥„ÉÄ„É†„Çµ„Éº„ÉÅÔºàRandom SearchÔºâ</h3>
<p>„É©„É≥„ÉÄ„É†„Å´ÁµÑ„ÅøÂêà„Çè„Åõ„ÇíË©¶„ÅôÂäπÁéáÁöÑ„Å™Êé¢Á¥¢Ôºö</p>
<pre><code class="language-python">from sklearn.model_selection import RandomizedSearchCV
from scipy.stats import randint, uniform

# „Éë„É©„É°„Éº„ÇøÂàÜÂ∏É
param_distributions = {
    'n_estimators': randint(50, 300),
    'max_depth': randint(3, 20),
    'min_samples_split': randint(2, 20),
    'min_samples_leaf': randint(1, 10),
    'max_features': uniform(0.1, 0.9)
}

# „É©„É≥„ÉÄ„É†„Çµ„Éº„ÉÅ
random_search = RandomizedSearchCV(
    RandomForestClassifier(random_state=42),
    param_distributions,
    n_iter=100,  # Ë©¶Ë°åÂõûÊï∞
    cv=5,
    scoring='f1_macro',
    random_state=42,
    n_jobs=-1
)

random_search.fit(X_train, y_train)

print(&quot;ÊúÄÈÅ©„Å™„Éë„É©„É°„Éº„Çø:&quot;)
print(random_search.best_params_)
print(f&quot;ÊúÄËâØ„Çπ„Ç≥„Ç¢: {random_search.best_score_:.3f}&quot;)
</code></pre>
<h3>5.3 „Éô„Ç§„Ç∫ÊúÄÈÅ©ÂåñÔºàBayesian OptimizationÔºâ</h3>
<p>„Çà„ÇäË≥¢„ÅÑ„Éè„Ç§„Éë„Éº„Éë„É©„É°„Éº„ÇøÊé¢Á¥¢ÔºàOptuna„Å™„Å©„ÅÆ„É©„Ç§„Éñ„É©„É™‰ΩøÁî®ÔºâÔºö</p>
<pre><code class="language-python"># Optuna„ÅÆ‰æãÔºàÂà•ÈÄî„Ç§„É≥„Çπ„Éà„Éº„É´ÂøÖË¶Å: pip install optunaÔºâ
try:
    import optuna
    from sklearn.ensemble import RandomForestClassifier

    def objective(trial):
        params = {
            'n_estimators': trial.suggest_int('n_estimators', 50, 300),
            'max_depth': trial.suggest_int('max_depth', 3, 20),
            'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),
            'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10)
        }

        model = RandomForestClassifier(**params, random_state=42)
        score = cross_val_score(model, X_train, y_train, cv=5, scoring='f1_macro').mean()
        return score

    study = optuna.create_study(direction='maximize')
    study.optimize(objective, n_trials=50, show_progress_bar=True)

    print(&quot;ÊúÄÈÅ©„Å™„Éë„É©„É°„Éº„Çø:&quot;)
    print(study.best_params)
    print(f&quot;ÊúÄËâØ„Çπ„Ç≥„Ç¢: {study.best_value:.3f}&quot;)

except ImportError:
    print(&quot;Optuna„Åå„Ç§„É≥„Çπ„Éà„Éº„É´„Åï„Çå„Å¶„ÅÑ„Åæ„Åõ„Çì&quot;)
</code></pre>
<hr />
<h2>6. ÂÆüË∑µ„Éó„É≠„Ç∏„Çß„ÇØ„Éà: „Çø„Ç§„Çø„Éã„ÉÉ„ÇØÁîüÂ≠ò‰∫àÊ∏¨</h2>
<p>ÂÆåÂÖ®„Å™„Éë„Ç§„Éó„É©„Ç§„É≥„ÅÆÂÆüË£Ö‰æãÔºö</p>
<pre><code class="language-python">import pandas as pd
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix

# „Éá„Éº„ÇøÊ∫ñÂÇôÔºàÁ∞°ÊòìÁâàÔºâ
data = {
    'Age': [22, 38, 26, 35, 35, np.nan, 54, 2, 27, 14, 4, 58],
    'Fare': [7.25, 71.28, 7.92, 53.1, 8.05, 8.46, 51.86, 21.08, 11.13, 30.07, 16.7, 13.0],
    'Sex': [1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0],  # 1=male, 0=female
    'Pclass': [3, 1, 3, 1, 3, 3, 1, 3, 2, 2, 3, 2],
    'Survived': [0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1]
}
df = pd.DataFrame(data)

# 1. Ê¨†ÊêçÂÄ§Âá¶ÁêÜ
df['Age'].fillna(df['Age'].median(), inplace=True)

# 2. ÁâπÂæ¥Èáè„Å®„Çø„Éº„Ç≤„ÉÉ„Éà„ÅÆÂàÜÈõ¢
X = df[['Age', 'Fare', 'Sex', 'Pclass']]
y = df['Survived']

# 3. „Éá„Éº„ÇøÂàÜÂâ≤
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42, stratify=y
)

# 4. „Çπ„Ç±„Éº„É™„É≥„Ç∞
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# 5. „Éè„Ç§„Éë„Éº„Éë„É©„É°„Éº„Çø„ÉÅ„É•„Éº„Éã„É≥„Ç∞
param_grid = {
    'n_estimators': [50, 100, 150],
    'max_depth': [3, 5, 7],
    'min_samples_split': [2, 5]
}

grid_search = GridSearchCV(
    RandomForestClassifier(random_state=42),
    param_grid,
    cv=3,
    scoring='accuracy'
)

grid_search.fit(X_train_scaled, y_train)

# 6. ÊúÄÁµÇ„É¢„Éá„É´„Åß‰∫àÊ∏¨
best_model = grid_search.best_estimator_
y_pred = best_model.predict(X_test_scaled)

# 7. Ë©ï‰æ°
print(&quot;ÂàÜÈ°û„É¨„Éù„Éº„Éà:&quot;)
print(classification_report(y_test, y_pred, target_names=['Ê≠ª‰∫°', 'ÁîüÂ≠ò']))

print(&quot;\nÊ∑∑ÂêåË°åÂàó:&quot;)
print(confusion_matrix(y_test, y_pred))

print(f&quot;\n„ÉÜ„Çπ„ÉàÊ≠£Ëß£Áéá: {best_model.score(X_test_scaled, y_test):.2%}&quot;)
</code></pre>
<hr />
<h2>7. „Åæ„Å®„ÇÅ</h2>
<h3>7.1 Êú¨Á´†„ÅßÂ≠¶„Çì„Å†„Åì„Å®</h3>
<p>‚úÖ <strong>„Éá„Éº„ÇøÂàÜÂâ≤</strong>
- Ë®ìÁ∑¥„ÉªÊ§úË®º„Éª„ÉÜ„Çπ„Éà„ÅÆ3ÂàÜÂâ≤
- Â±§Âåñ„Çµ„É≥„Éó„É™„É≥„Ç∞</p>
<p>‚úÖ <strong>‰∫§Â∑ÆÊ§úË®º</strong>
- K-Fold„ÄÅÂ±§ÂåñK-Fold„ÄÅLOO
- „É¢„Éá„É´„ÅÆÊ±éÂåñÊÄßËÉΩË©ï‰æ°</p>
<p>‚úÖ <strong>Ë©ï‰æ°ÊåáÊ®ô</strong>
- ÂàÜÈ°û: Ê≠£Ëß£Áéá„ÄÅÈÅ©ÂêàÁéá„ÄÅÂÜçÁèæÁéá„ÄÅF1„ÄÅAUC
- ÂõûÂ∏∞: MSE, RMSE, MAE, R¬≤</p>
<p>‚úÖ <strong>ÈÅéÂ≠¶ÁøíÂØæÁ≠ñ</strong>
- Ê≠£ÂâáÂåñ„ÄÅÊó©ÊúüÂÅúÊ≠¢„ÄÅ„Ç¢„É≥„Çµ„É≥„Éñ„É´
- Â≠¶ÁøíÊõ≤Á∑ö„Å´„Çà„ÇãÊ§úÂá∫</p>
<p>‚úÖ <strong>„Éè„Ç§„Éë„Éº„Éë„É©„É°„Éº„Çø„ÉÅ„É•„Éº„Éã„É≥„Ç∞</strong>
- GridSearch, RandomSearch, „Éô„Ç§„Ç∫ÊúÄÈÅ©Âåñ</p>
<h3>7.2 Ê©üÊ¢∞Â≠¶Áøí„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÅÆ„ÉÅ„Çß„ÉÉ„ÇØ„É™„Çπ„Éà</h3>
<ul>
<li>[ ] „Éá„Éº„Çø„ÇíË®ìÁ∑¥„ÉªÊ§úË®º„Éª„ÉÜ„Çπ„Éà„Å´ÂàÜÂâ≤</li>
<li>[ ] ‰∫§Â∑ÆÊ§úË®º„ÅßÊÄßËÉΩ„ÇíË©ï‰æ°</li>
<li>[ ] ÈÅ©Âàá„Å™Ë©ï‰æ°ÊåáÊ®ô„ÇíÈÅ∏Êäû</li>
<li>[ ] ÈÅéÂ≠¶Áøí„ÇíÊ§úÂá∫„ÉªÂØæÁ≠ñ</li>
<li>[ ] „Éè„Ç§„Éë„Éº„Éë„É©„É°„Éº„Çø„ÇíÊúÄÈÅ©Âåñ</li>
<li>[ ] „ÉÜ„Çπ„Éà„Éá„Éº„Çø„ÅßÊúÄÁµÇË©ï‰æ°</li>
<li>[ ] „É¢„Éá„É´„Çí‰øùÂ≠ò„Éª„Éá„Éó„É≠„Ç§</li>
</ul>
<hr />
<h2>8. Á∑¥ÁøíÂïèÈ°å</h2>
<h3>ÂïèÈ°å1: Ë©ï‰æ°ÊåáÊ®ô„ÅÆÈÅ∏ÊäûÔºàÂü∫Á§éÔºâ</h3>
<p>‰ª•‰∏ã„ÅÆ„Ç∑„Éä„É™„Ç™„Å´ÊúÄÈÅ©„Å™Ë©ï‰æ°ÊåáÊ®ô„ÇíÈÅ∏„Çì„Åß„Åè„Å†„Åï„ÅÑ„ÄÇ</p>
<p>a) „Çπ„Éë„É†„É°„Éº„É´Ê§úÂá∫ÔºàÊ≠£Â∏∏„É°„Éº„É´„ÇíË™§„Å£„Å¶„Çπ„Éë„É†„Å´„Åó„Åü„Åè„Å™„ÅÑÔºâ
b) „Åå„ÇìÊ§úË®∫Ôºà„Åå„Çì„ÇíË¶ãÈÄÉ„Åó„Åü„Åè„Å™„ÅÑÔºâ
c) „Éê„É©„É≥„Çπ„ÅÆÂèñ„Çå„Åü3„ÇØ„É©„ÇπÂàÜÈ°û</p>
<details>
<summary>Ëß£Á≠î</summary>

**Ëß£Á≠î:**
a) **ÈÅ©ÂêàÁéáÔºàPrecisionÔºâ** - ÂÅΩÈôΩÊÄßÔºàÊ≠£Â∏∏„Çí„Çπ„Éë„É†„Å®Ë™§Âà§ÂÆöÔºâ„ÇíÊ∏õ„Çâ„Åô
b) **ÂÜçÁèæÁéáÔºàRecallÔºâ** - ÂÅΩÈô∞ÊÄßÔºà„Åå„Çì„ÇíË¶ãÈÄÉ„ÅôÔºâ„ÇíÊ∏õ„Çâ„Åô
c) **F1„Çπ„Ç≥„Ç¢** - „Éê„É©„É≥„Çπ„ÅÆÂèñ„Çå„ÅüË©ï‰æ°

</details>

<h3>ÂïèÈ°å2: ‰∫§Â∑ÆÊ§úË®º„ÅÆÂÆüË£ÖÔºà‰∏≠Á¥öÔºâ</h3>
<p>„Ç¢„Ç§„É™„Çπ„Éá„Éº„Çø„Çª„ÉÉ„Éà„Åß5-Fold‰∫§Â∑ÆÊ§úË®º„ÇíÂÆüË£Ö„Åó„ÄÅDecisionTree„Å®RandomForest„ÅÆÊÄßËÉΩ„ÇíÊØîËºÉ„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ</p>
<details>
<summary>Ëß£Á≠î‰æã</summary>


<pre><code class="language-python">from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_val_score

iris = load_iris()
X, y = iris.data, iris.target

models = {
    'DecisionTree': DecisionTreeClassifier(max_depth=5, random_state=42),
    'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42)
}

for name, model in models.items():
    scores = cross_val_score(model, X, y, cv=5)
    print(f&quot;{name}: {scores.mean():.3f} (+/- {scores.std():.3f})&quot;)
</code></pre>


</details>

<hr />
<h2>9. Ê¨°„ÅÆ„Çπ„ÉÜ„ÉÉ„Éó</h2>
<p>Ê©üÊ¢∞Â≠¶ÁøíÂÖ•ÈñÄ„Ç∑„É™„Éº„Ç∫„ÇíÂÆå‰∫Ü„Åó„Åæ„Åó„ÅüÔºÅÊ¨°„ÅØÔºö</p>
<ol>
<li><strong>ÂêÑ„Ç¢„É´„Ç¥„É™„Ç∫„É†„ÇíÊ∑±„ÅèÂ≠¶„Å∂</strong>: Á∑öÂΩ¢ÂõûÂ∏∞„ÄÅÊ±∫ÂÆöÊú®„ÄÅSVMÁ≠â„ÅÆÂ∞ÇÈñÄ„Ç∑„É™„Éº„Ç∫</li>
<li><strong>„Éá„Éº„ÇøÂâçÂá¶ÁêÜ„ÇíÂ≠¶„Å∂</strong>: ÂÆüË∑µÁöÑ„Å™„Éá„Éº„ÇøÂá¶ÁêÜÊäÄË°ì</li>
<li><strong>Ê∑±Â±§Â≠¶Áøí„Å∏ÈÄ≤„ÇÄ</strong>: „Éã„É•„Éº„É©„É´„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ„ÄÅCNN„ÄÅRNN</li>
</ol>
<hr />
<p><strong>Ââç„Å∏</strong>: <a href="chapter-3.html">‚Üê Chapter 3: ÊïôÂ∏´„Å™„ÅóÂ≠¶Áøí„ÅÆÂü∫Á§é</a></p>
<p><strong>ÁõÆÊ¨°„Å∏</strong>: <a href="index.html">‚Üë „Ç∑„É™„Éº„Ç∫ÁõÆÊ¨°</a></p>
<hr />
<p><strong>„Åä„ÇÅ„Åß„Å®„ÅÜ„Åî„Åñ„ÅÑ„Åæ„ÅôÔºÅÊ©üÊ¢∞Â≠¶ÁøíÂÖ•ÈñÄ„Ç∑„É™„Éº„Ç∫„ÇíÂÆå‰∫Ü„Åó„Åæ„Åó„ÅüÔºÅ</strong></p><div class="navigation">
    <a href="chapter-3.html" class="nav-button">‚Üê Á¨¨3Á´†</a>
    <a href="index.html" class="nav-button">„Ç∑„É™„Éº„Ç∫ÁõÆÊ¨°„Å´Êàª„Çã</a>
</div>
    </main>

    <footer>
        <p><strong>‰ΩúÊàêËÄÖ</strong>: AI Terakoya Content Team</p>
        <p><strong>Áõ£‰øÆ</strong>: Dr. Yusuke HashimotoÔºàÊù±ÂåóÂ§ßÂ≠¶Ôºâ</p>
        <p><strong>„Éê„Éº„Ç∏„Éß„É≥</strong>: 1.0 | <strong>‰ΩúÊàêÊó•</strong>: 2025-10-17</p>
        <p><strong>„É©„Ç§„Çª„É≥„Çπ</strong>: Creative Commons BY 4.0</p>
        <p>¬© 2025 AI Terakoya. All rights reserved.</p>
    </footer>
</body>
</html>
