<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Chapter 4: ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ã¨å®Ÿè·µ - AI Terakoya</title>

    <style>
        :root {
            --color-primary: #2c3e50;
            --color-primary-dark: #1a252f;
            --color-accent: #7b2cbf;
            --color-accent-light: #9d4edd;
            --color-text: #2d3748;
            --color-text-light: #4a5568;
            --color-bg: #ffffff;
            --color-bg-alt: #f7fafc;
            --color-border: #e2e8f0;
            --color-code-bg: #f8f9fa;
            --color-link: #3182ce;
            --color-link-hover: #2c5aa0;

            --spacing-xs: 0.5rem;
            --spacing-sm: 1rem;
            --spacing-md: 1.5rem;
            --spacing-lg: 2rem;
            --spacing-xl: 3rem;

            --font-body: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            --font-mono: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;

            --border-radius: 8px;
            --box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: var(--font-body);
            line-height: 1.7;
            color: var(--color-text);
            background-color: var(--color-bg);
            font-size: 16px;
        }

        header {
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            padding: var(--spacing-xl) var(--spacing-md);
            margin-bottom: var(--spacing-xl);
            box-shadow: var(--box-shadow);
        }

        .header-content {
            max-width: 900px;
            margin: 0 auto;
        }

        h1 {
            font-size: 2rem;
            font-weight: 700;
            margin-bottom: var(--spacing-sm);
            line-height: 1.2;
        }

        .subtitle {
            font-size: 1.1rem;
            opacity: 0.95;
            font-weight: 400;
            margin-bottom: var(--spacing-md);
        }

        .meta {
            display: flex;
            flex-wrap: wrap;
            gap: var(--spacing-md);
            font-size: 0.9rem;
            opacity: 0.9;
        }

        .meta-item {
            display: flex;
            align-items: center;
            gap: 0.3rem;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 0 var(--spacing-md) var(--spacing-xl);
        }

        h2 {
            font-size: 1.75rem;
            color: var(--color-primary);
            margin-top: var(--spacing-xl);
            margin-bottom: var(--spacing-md);
            padding-bottom: var(--spacing-xs);
            border-bottom: 3px solid var(--color-accent);
        }

        h3 {
            font-size: 1.4rem;
            color: var(--color-primary);
            margin-top: var(--spacing-lg);
            margin-bottom: var(--spacing-sm);
        }

        h4 {
            font-size: 1.1rem;
            color: var(--color-primary-dark);
            margin-top: var(--spacing-md);
            margin-bottom: var(--spacing-sm);
        }

        p {
            margin-bottom: var(--spacing-md);
            color: var(--color-text);
        }

        a {
            color: var(--color-link);
            text-decoration: none;
            transition: color 0.2s;
        }

        a:hover {
            color: var(--color-link-hover);
            text-decoration: underline;
        }

        ul, ol {
            margin-left: var(--spacing-lg);
            margin-bottom: var(--spacing-md);
        }

        li {
            margin-bottom: var(--spacing-xs);
            color: var(--color-text);
        }

        pre {
            background-color: var(--color-code-bg);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            overflow-x: auto;
            margin-bottom: var(--spacing-md);
            font-family: var(--font-mono);
            font-size: 0.9rem;
            line-height: 1.5;
        }

        code {
            font-family: var(--font-mono);
            font-size: 0.9em;
            background-color: var(--color-code-bg);
            padding: 0.2em 0.4em;
            border-radius: 3px;
        }

        pre code {
            background-color: transparent;
            padding: 0;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: var(--spacing-md);
            font-size: 0.95rem;
        }

        th, td {
            border: 1px solid var(--color-border);
            padding: var(--spacing-sm);
            text-align: left;
        }

        th {
            background-color: var(--color-bg-alt);
            font-weight: 600;
            color: var(--color-primary);
        }

        blockquote {
            border-left: 4px solid var(--color-accent);
            padding-left: var(--spacing-md);
            margin: var(--spacing-md) 0;
            color: var(--color-text-light);
            font-style: italic;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        .mermaid {
            text-align: center;
            margin: var(--spacing-lg) 0;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        details {
            background-color: var(--color-bg-alt);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            margin-bottom: var(--spacing-md);
        }

        summary {
            cursor: pointer;
            font-weight: 600;
            color: var(--color-primary);
            user-select: none;
            padding: var(--spacing-xs);
            margin: calc(-1 * var(--spacing-md));
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        summary:hover {
            background-color: rgba(123, 44, 191, 0.1);
        }

        details[open] summary {
            margin-bottom: var(--spacing-md);
            border-bottom: 1px solid var(--color-border);
        }

        .learning-objectives {
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
            padding: var(--spacing-lg);
            border-radius: var(--border-radius);
            border-left: 4px solid var(--color-accent);
            margin-bottom: var(--spacing-xl);
        }

        .learning-objectives h2 {
            margin-top: 0;
            border-bottom: none;
        }

        .navigation {
            display: flex;
            justify-content: space-between;
            gap: var(--spacing-md);
            margin: var(--spacing-xl) 0;
            padding-top: var(--spacing-lg);
            border-top: 2px solid var(--color-border);
        }

        .nav-button {
            flex: 1;
            padding: var(--spacing-md);
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            border-radius: var(--border-radius);
            text-align: center;
            font-weight: 600;
            transition: transform 0.2s, box-shadow 0.2s;
            box-shadow: var(--box-shadow);
        }

        .nav-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
            text-decoration: none;
        }

        footer {
            margin-top: var(--spacing-xl);
            padding: var(--spacing-lg) var(--spacing-md);
            background-color: var(--color-bg-alt);
            border-top: 1px solid var(--color-border);
            text-align: center;
            font-size: 0.9rem;
            color: var(--color-text-light);
        }

        @media (max-width: 768px) {
            h1 {
                font-size: 1.5rem;
            }

            h2 {
                font-size: 1.4rem;
            }

            h3 {
                font-size: 1.2rem;
            }

            .meta {
                font-size: 0.85rem;
            }

            .navigation {
                flex-direction: column;
            }

            table {
                font-size: 0.85rem;
            }

            th, td {
                padding: var(--spacing-xs);
            }
        }
    </style>

    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
        mermaid.initialize({ startOnLoad: true, theme: 'default' });
    </script>

    <!-- MathJax for LaTeX equation rendering -->
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\(', '\)']],
                displayMath: [['$$', '$$'], ['\[', '\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
                ignoreHtmlClass: 'mermaid'
            }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" async></script>
</head>
<body>
    <header>
        <div class="header-content">
            <h1>Chapter 4: ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ã¨å®Ÿè·µ</h1>
            <p class="subtitle"></p>
            <div class="meta">
                <span class="meta-item">ğŸ“– èª­äº†æ™‚é–“: 30-35åˆ†</span>
                <span class="meta-item">ğŸ“Š é›£æ˜“åº¦: åˆç´šã€œä¸­ç´š</span>
                <span class="meta-item">ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹: 0å€‹</span>
                <span class="meta-item">ğŸ“ æ¼”ç¿’å•é¡Œ: 0å•</span>
            </div>
        </div>
    </header>

    <main class="container">
<h1>Chapter 4: ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ã¨å®Ÿè·µ</h1>
<h2>æœ¬ç« ã®æ¦‚è¦</h2>
<p>æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®çœŸã®ä¾¡å€¤ã¯ã€æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã™ã‚‹æ€§èƒ½ã§æ±ºã¾ã‚Šã¾ã™ã€‚æœ¬ç« ã§ã¯ã€ãƒ¢ãƒ‡ãƒ«ã‚’é©åˆ‡ã«è©•ä¾¡ã—ã€éå­¦ç¿’ã‚’é˜²ãã€æ€§èƒ½ã‚’æœ€é©åŒ–ã™ã‚‹ãŸã‚ã®å®Ÿè·µçš„ãªãƒ†ã‚¯ãƒ‹ãƒƒã‚¯ã‚’å­¦ã³ã¾ã™ã€‚</p>
<h3>å­¦ç¿’ç›®æ¨™</h3>
<ul>
<li>âœ… è¨“ç·´ãƒ»æ¤œè¨¼ãƒ»ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®åˆ†å‰²æ–¹æ³•ã‚’ç†è§£ã™ã‚‹</li>
<li>âœ… äº¤å·®æ¤œè¨¼ã§ãƒ¢ãƒ‡ãƒ«ã®æ±åŒ–æ€§èƒ½ã‚’è©•ä¾¡ã§ãã‚‹</li>
<li>âœ… é©åˆ‡ãªè©•ä¾¡æŒ‡æ¨™ã‚’é¸æŠã§ãã‚‹</li>
<li>âœ… éå­¦ç¿’ã‚’æ¤œå‡ºã—ã€å¯¾ç­–ã§ãã‚‹</li>
<li>âœ… ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å®Ÿè·µã§ãã‚‹</li>
</ul>
<hr />
<h2>1. ãƒ‡ãƒ¼ã‚¿åˆ†å‰²ã®åŸºç¤</h2>
<h3>1.1 ãªãœãƒ‡ãƒ¼ã‚¿ã‚’åˆ†å‰²ã™ã‚‹ã®ã‹</h3>
<p><strong>ç›®çš„</strong>: ãƒ¢ãƒ‡ãƒ«ãŒæœªçŸ¥ã®ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦ã©ã‚Œã ã‘ã†ã¾ãæ©Ÿèƒ½ã™ã‚‹ã‹ã‚’è©•ä¾¡</p>
<div class="mermaid">
graph LR
    A[å…¨ãƒ‡ãƒ¼ã‚¿] --> B[è¨“ç·´ãƒ‡ãƒ¼ã‚¿<br/>70-80%]
    A --> C[ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿<br/>20-30%]
    B --> D[ãƒ¢ãƒ‡ãƒ«å­¦ç¿’]
    D --> E[è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã§è©•ä¾¡]
    D --> F[ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§è©•ä¾¡]
    F --> G[æ±åŒ–æ€§èƒ½]
</div>

<h3>1.2 åŸºæœ¬çš„ãªåˆ†å‰²</h3>
<pre><code class="language-python">from sklearn.model_selection import train_test_split
from sklearn.datasets import load_iris

# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
iris = load_iris()
X, y = iris.data, iris.target

# è¨“ç·´ãƒ‡ãƒ¼ã‚¿:ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ = 7:3ã«åˆ†å‰²
X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.3,     # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®å‰²åˆ
    random_state=42,   # å†ç¾æ€§ã®ãŸã‚å›ºå®š
    stratify=y         # ã‚¯ãƒ©ã‚¹æ¯”ç‡ã‚’ä¿æŒ
)

print(f&quot;è¨“ç·´ãƒ‡ãƒ¼ã‚¿æ•°: {len(X_train)}&quot;)
print(f&quot;ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿æ•°: {len(X_test)}&quot;)
print(f&quot;è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®ã‚¯ãƒ©ã‚¹åˆ†å¸ƒ: {np.bincount(y_train)}&quot;)
print(f&quot;ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®ã‚¯ãƒ©ã‚¹åˆ†å¸ƒ: {np.bincount(y_test)}&quot;)
</code></pre>
<h3>1.3 è¨“ç·´ãƒ»æ¤œè¨¼ãƒ»ãƒ†ã‚¹ãƒˆã®3åˆ†å‰²</h3>
<p><strong>ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹:</strong></p>
<div class="mermaid">
graph TD
    A[å…¨ãƒ‡ãƒ¼ã‚¿] --> B[è¨“ç·´ãƒ‡ãƒ¼ã‚¿ 60%]
    A --> C[æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ 20%]
    A --> D[ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ 20%]
    B --> E[ãƒ¢ãƒ‡ãƒ«å­¦ç¿’]
    C --> F[ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´]
    E --> F
    F --> G[æœ€çµ‚ãƒ¢ãƒ‡ãƒ«]
    G --> H[ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§æœ€çµ‚è©•ä¾¡]
    D --> H
</div>

<pre><code class="language-python"># 3åˆ†å‰²ã®å®Ÿè£…
X_temp, X_test, y_temp, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

X_train, X_val, y_train, y_val = train_test_split(
    X_temp, y_temp, test_size=0.25, random_state=42, stratify=y_temp
)  # 0.25 * 0.8 = 0.2 (å…¨ä½“ã®20%)

print(f&quot;è¨“ç·´: {len(X_train)}, æ¤œè¨¼: {len(X_val)}, ãƒ†ã‚¹ãƒˆ: {len(X_test)}&quot;)
</code></pre>
<hr />
<h2>2. äº¤å·®æ¤œè¨¼ï¼ˆCross-Validationï¼‰</h2>
<h3>2.1 K-Foldäº¤å·®æ¤œè¨¼</h3>
<p><strong>K-Fold CV</strong>ã¯ã€ãƒ‡ãƒ¼ã‚¿ã‚’Kå€‹ã«åˆ†å‰²ã—ã€Kå›ã®è¨“ç·´ãƒ»è©•ä¾¡ã‚’è¡Œã†æ‰‹æ³•ã§ã™ã€‚</p>
<div class="mermaid">
graph TD
    A[ãƒ‡ãƒ¼ã‚¿ã‚’Kåˆ†å‰²] --> B[Fold 1ã‚’ãƒ†ã‚¹ãƒˆ<br/>æ®‹ã‚Šã§è¨“ç·´]
    A --> C[Fold 2ã‚’ãƒ†ã‚¹ãƒˆ<br/>æ®‹ã‚Šã§è¨“ç·´]
    A --> D[Fold 3ã‚’ãƒ†ã‚¹ãƒˆ<br/>æ®‹ã‚Šã§è¨“ç·´]
    A --> E[...]
    B --> F[Kå€‹ã®ã‚¹ã‚³ã‚¢]
    C --> F
    D --> F
    E --> F
    F --> G[å¹³å‡ã‚¹ã‚³ã‚¢]
</div>

<h3>2.2 å®Ÿè£…ä¾‹</h3>
<pre><code class="language-python">from sklearn.model_selection import cross_val_score
from sklearn.tree import DecisionTreeClassifier
import numpy as np

# ãƒ¢ãƒ‡ãƒ«ä½œæˆ
model = DecisionTreeClassifier(max_depth=5, random_state=42)

# 5-Foldäº¤å·®æ¤œè¨¼
scores = cross_val_score(model, X, y, cv=5)

print(&quot;å„Foldã®ã‚¹ã‚³ã‚¢:&quot;, scores)
print(f&quot;å¹³å‡ã‚¹ã‚³ã‚¢: {scores.mean():.3f} (+/- {scores.std():.3f})&quot;)
</code></pre>
<h3>2.3 å±¤åŒ–K-Foldäº¤å·®æ¤œè¨¼</h3>
<p>ã‚¯ãƒ©ã‚¹ã®åˆ†å¸ƒã‚’å„Foldã§ä¿æŒï¼š</p>
<pre><code class="language-python">from sklearn.model_selection import StratifiedKFold, cross_validate

# å±¤åŒ–K-Fold
skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

# è¤‡æ•°ã®è©•ä¾¡æŒ‡æ¨™
scoring = ['accuracy', 'precision_macro', 'recall_macro', 'f1_macro']

results = cross_validate(model, X, y, cv=skf, scoring=scoring)

for metric in scoring:
    scores = results[f'test_{metric}']
    print(f&quot;{metric}: {scores.mean():.3f} (+/- {scores.std():.3f})&quot;)
</code></pre>
<h3>2.4 Leave-One-Outäº¤å·®æ¤œè¨¼ï¼ˆLOOï¼‰</h3>
<p>ãƒ‡ãƒ¼ã‚¿æ•°ãŒå°‘ãªã„å ´åˆã«æœ‰åŠ¹ï¼š</p>
<pre><code class="language-python">from sklearn.model_selection import LeaveOneOut

loo = LeaveOneOut()
scores = cross_val_score(model, X, y, cv=loo)

print(f&quot;LOOå¹³å‡ã‚¹ã‚³ã‚¢: {scores.mean():.3f}&quot;)
print(f&quot;å®Ÿè¡Œå›æ•°: {len(scores)}&quot;)  # ã‚µãƒ³ãƒ—ãƒ«æ•°ã¨åŒã˜
</code></pre>
<hr />
<h2>3. è©•ä¾¡æŒ‡æ¨™</h2>
<h3>3.1 åˆ†é¡å•é¡Œã®è©•ä¾¡æŒ‡æ¨™</h3>
<h4>æ··åŒè¡Œåˆ—ï¼ˆConfusion Matrixï¼‰</h4>
<pre><code class="language-python">from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier

# ãƒ‡ãƒ¼ã‚¿æº–å‚™
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42
)

# ãƒ¢ãƒ‡ãƒ«è¨“ç·´ã¨äºˆæ¸¬
model = DecisionTreeClassifier(max_depth=5, random_state=42)
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

# æ··åŒè¡Œåˆ—
cm = confusion_matrix(y_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm,
                              display_labels=iris.target_names)
disp.plot(cmap='Blues')
plt.title('æ··åŒè¡Œåˆ—')
plt.show()

print(&quot;æ··åŒè¡Œåˆ—:&quot;)
print(cm)
</code></pre>
<h4>ä¸»è¦ãªè©•ä¾¡æŒ‡æ¨™</h4>
<pre><code class="language-python">from sklearn.metrics import (accuracy_score, precision_score,
                            recall_score, f1_score, classification_report)

# å„æŒ‡æ¨™ã®è¨ˆç®—
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average='macro')
recall = recall_score(y_test, y_pred, average='macro')
f1 = f1_score(y_test, y_pred, average='macro')

print(f&quot;æ­£è§£ç‡ï¼ˆAccuracyï¼‰: {accuracy:.3f}&quot;)
print(f&quot;é©åˆç‡ï¼ˆPrecisionï¼‰: {precision:.3f}&quot;)
print(f&quot;å†ç¾ç‡ï¼ˆRecallï¼‰: {recall:.3f}&quot;)
print(f&quot;F1ã‚¹ã‚³ã‚¢: {f1:.3f}&quot;)

# è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆ
print(&quot;\nåˆ†é¡ãƒ¬ãƒãƒ¼ãƒˆ:&quot;)
print(classification_report(y_test, y_pred, target_names=iris.target_names))
</code></pre>
<p><strong>å„æŒ‡æ¨™ã®æ„å‘³:</strong></p>
<table>
<thead>
<tr>
<th>æŒ‡æ¨™</th>
<th>å®šç¾©</th>
<th>ä½¿ã„ã©ã“ã‚</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>æ­£è§£ç‡ï¼ˆAccuracyï¼‰</strong></td>
<td>$\frac{TP + TN}{TP + TN + FP + FN}$</td>
<td>ãƒãƒ©ãƒ³ã‚¹ã®å–ã‚ŒãŸãƒ‡ãƒ¼ã‚¿</td>
</tr>
<tr>
<td><strong>é©åˆç‡ï¼ˆPrecisionï¼‰</strong></td>
<td>$\frac{TP}{TP + FP}$</td>
<td>å½é™½æ€§ã‚’æ¸›ã‚‰ã—ãŸã„å ´åˆ</td>
</tr>
<tr>
<td><strong>å†ç¾ç‡ï¼ˆRecallï¼‰</strong></td>
<td>$\frac{TP}{TP + FN}$</td>
<td>å½é™°æ€§ã‚’æ¸›ã‚‰ã—ãŸã„å ´åˆ</td>
</tr>
<tr>
<td><strong>F1ã‚¹ã‚³ã‚¢</strong></td>
<td>$2 \times \frac{Precision \times Recall}{Precision + Recall}$</td>
<td>é©åˆç‡ã¨å†ç¾ç‡ã®ãƒãƒ©ãƒ³ã‚¹</td>
</tr>
</tbody>
</table>
<h4>ROCæ›²ç·šã¨AUC</h4>
<pre><code class="language-python">from sklearn.metrics import roc_curve, auc, RocCurveDisplay
from sklearn.preprocessing import label_binarize
from sklearn.multiclass import OneVsRestClassifier
from sklearn.linear_model import LogisticRegression

# 2å€¤åˆ†é¡ã®ä¾‹ï¼ˆç°¡ç•¥åŒ–ã®ãŸã‚2ã‚¯ãƒ©ã‚¹ã®ã¿ä½¿ç”¨ï¼‰
X_binary = X[y != 2]
y_binary = y[y != 2]

X_train, X_test, y_train, y_test = train_test_split(
    X_binary, y_binary, test_size=0.3, random_state=42
)

# ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ã§ç¢ºç‡äºˆæ¸¬
model = LogisticRegression(random_state=42)
model.fit(X_train, y_train)
y_score = model.predict_proba(X_test)[:, 1]

# ROCæ›²ç·š
fpr, tpr, thresholds = roc_curve(y_test, y_score)
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='darkorange', lw=2,
        label=f'ROCæ›²ç·š (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='ãƒ©ãƒ³ãƒ€ãƒ ')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('å½é™½æ€§ç‡ï¼ˆFPRï¼‰')
plt.ylabel('çœŸé™½æ€§ç‡ï¼ˆTPRï¼‰')
plt.title('ROCæ›²ç·š')
plt.legend(loc=&quot;lower right&quot;)
plt.grid(True)
plt.show()
</code></pre>
<h3>3.2 å›å¸°å•é¡Œã®è©•ä¾¡æŒ‡æ¨™</h3>
<pre><code class="language-python">from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.linear_model import LinearRegression
from sklearn.datasets import fetch_california_housing

# å›å¸°ãƒ‡ãƒ¼ã‚¿
housing = fetch_california_housing()
X_reg, y_reg = housing.data, housing.target

X_train, X_test, y_train, y_test = train_test_split(
    X_reg, y_reg, test_size=0.3, random_state=42
)

# ç·šå½¢å›å¸°
model = LinearRegression()
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

# è©•ä¾¡æŒ‡æ¨™
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f&quot;å¹³å‡äºŒä¹—èª¤å·®ï¼ˆMSEï¼‰: {mse:.3f}&quot;)
print(f&quot;å¹³å‡å¹³æ–¹æ ¹èª¤å·®ï¼ˆRMSEï¼‰: {rmse:.3f}&quot;)
print(f&quot;å¹³å‡çµ¶å¯¾èª¤å·®ï¼ˆMAEï¼‰: {mae:.3f}&quot;)
print(f&quot;æ±ºå®šä¿‚æ•°ï¼ˆRÂ²ï¼‰: {r2:.3f}&quot;)
</code></pre>
<p><strong>å›å¸°æŒ‡æ¨™ã®æ„å‘³:</strong></p>
<table>
<thead>
<tr>
<th>æŒ‡æ¨™</th>
<th>å®šç¾©</th>
<th>ç‰¹å¾´</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>MSE</strong></td>
<td>$\frac{1}{n}\sum (y_i - \hat{y}_i)^2$</td>
<td>å¤–ã‚Œå€¤ã«æ•æ„Ÿ</td>
</tr>
<tr>
<td><strong>RMSE</strong></td>
<td>$\sqrt{MSE}$</td>
<td>å…ƒã®ã‚¹ã‚±ãƒ¼ãƒ«ã§è§£é‡ˆå¯èƒ½</td>
</tr>
<tr>
<td><strong>MAE</strong></td>
<td>$\frac{1}{n}\sum</td>
<td>y_i - \hat{y}_i</td>
</tr>
<tr>
<td><strong>RÂ²</strong></td>
<td>$1 - \frac{SS_{res}}{SS_{tot}}$</td>
<td>ãƒ¢ãƒ‡ãƒ«ã®èª¬æ˜åŠ›ï¼ˆ0ã€œ1ï¼‰</td>
</tr>
</tbody>
</table>
<hr />
<h2>4. éå­¦ç¿’ã¨æ­£å‰‡åŒ–</h2>
<h3>4.1 éå­¦ç¿’ï¼ˆOverfittingï¼‰ã¨ã¯</h3>
<p><strong>éå­¦ç¿’</strong>ã¯ã€ãƒ¢ãƒ‡ãƒ«ãŒè¨“ç·´ãƒ‡ãƒ¼ã‚¿ã«éåº¦ã«é©åˆã—ã€æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã™ã‚‹æ€§èƒ½ãŒä½ä¸‹ã™ã‚‹ç¾è±¡ã§ã™ã€‚</p>
<div class="mermaid">
graph LR
    A[ãƒ¢ãƒ‡ãƒ«ã®è¤‡é›‘ã•] --> B[éå°‘å­¦ç¿’<br/>Underfitting]
    A --> C[é©åˆ‡ãªå­¦ç¿’]
    A --> D[éå­¦ç¿’<br/>Overfitting]
</div>

<h3>4.2 å­¦ç¿’æ›²ç·šã«ã‚ˆã‚‹æ¤œå‡º</h3>
<pre><code class="language-python">from sklearn.model_selection import learning_curve

# å­¦ç¿’æ›²ç·šã®ãƒ—ãƒ­ãƒƒãƒˆ
def plot_learning_curve(estimator, X, y, cv=5):
    train_sizes, train_scores, val_scores = learning_curve(
        estimator, X, y, cv=cv,
        train_sizes=np.linspace(0.1, 1.0, 10),
        random_state=42
    )

    train_mean = np.mean(train_scores, axis=1)
    train_std = np.std(train_scores, axis=1)
    val_mean = np.mean(val_scores, axis=1)
    val_std = np.std(val_scores, axis=1)

    plt.figure(figsize=(10, 6))
    plt.plot(train_sizes, train_mean, label='è¨“ç·´ã‚¹ã‚³ã‚¢', color='blue', marker='o')
    plt.fill_between(train_sizes, train_mean - train_std,
                     train_mean + train_std, alpha=0.15, color='blue')
    plt.plot(train_sizes, val_mean, label='æ¤œè¨¼ã‚¹ã‚³ã‚¢', color='red', marker='s')
    plt.fill_between(train_sizes, val_mean - val_std,
                     val_mean + val_std, alpha=0.15, color='red')

    plt.xlabel('è¨“ç·´ã‚µãƒ³ãƒ—ãƒ«æ•°')
    plt.ylabel('ã‚¹ã‚³ã‚¢')
    plt.title('å­¦ç¿’æ›²ç·š')
    plt.legend(loc='best')
    plt.grid(True)
    plt.show()

# ä½¿ç”¨ä¾‹
model = DecisionTreeClassifier(max_depth=10, random_state=42)
plot_learning_curve(model, X, y)
</code></pre>
<h3>4.3 éå­¦ç¿’ã®å¯¾ç­–</h3>
<h4>1. æ­£å‰‡åŒ–ï¼ˆRegularizationï¼‰</h4>
<p><strong>Ridgeå›å¸°ï¼ˆL2æ­£å‰‡åŒ–ï¼‰:</strong>
$$
J(w) = MSE + \alpha \sum_{i=1}^{n} w_i^2
$$</p>
<p><strong>Lassoå›å¸°ï¼ˆL1æ­£å‰‡åŒ–ï¼‰:</strong>
$$
J(w) = MSE + \alpha \sum_{i=1}^{n} |w_i|
$$</p>
<pre><code class="language-python">from sklearn.linear_model import Ridge, Lasso

# Ridgeå›å¸°
ridge = Ridge(alpha=1.0)
ridge.fit(X_train, y_train)
print(f&quot;Ridge RÂ²: {ridge.score(X_test, y_test):.3f}&quot;)

# Lassoå›å¸°
lasso = Lasso(alpha=0.1)
lasso.fit(X_train, y_train)
print(f&quot;Lasso RÂ²: {lasso.score(X_test, y_test):.3f}&quot;)
</code></pre>
<h4>2. æ—©æœŸåœæ­¢ï¼ˆEarly Stoppingï¼‰</h4>
<pre><code class="language-python">from sklearn.ensemble import GradientBoostingClassifier

# æ—©æœŸåœæ­¢ã‚’ä½¿ã£ãŸå‹¾é…ãƒ–ãƒ¼ã‚¹ãƒ†ã‚£ãƒ³ã‚°
gb = GradientBoostingClassifier(
    n_estimators=1000,
    learning_rate=0.1,
    validation_fraction=0.2,
    n_iter_no_change=10,  # 10å›æ”¹å–„ã—ãªã‘ã‚Œã°åœæ­¢
    random_state=42
)

gb.fit(X_train, y_train)
print(f&quot;ä½¿ç”¨ã—ãŸæ¨å®šå™¨æ•°: {gb.n_estimators_}&quot;)
</code></pre>
<h4>3. ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆï¼ˆãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼‰</h4>
<h4>4. ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µ</h4>
<h4>5. ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å­¦ç¿’</h4>
<hr />
<h2>5. ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°</h2>
<h3>5.1 ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒï¼ˆGrid Searchï¼‰</h3>
<p>å…¨ã¦ã®çµ„ã¿åˆã‚ã›ã‚’è©¦ã™ç¶²ç¾…çš„æ¢ç´¢ï¼š</p>
<pre><code class="language-python">from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import RandomForestClassifier

# ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚°ãƒªãƒƒãƒ‰
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [3, 5, 7, 10],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}

# ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒ
grid_search = GridSearchCV(
    RandomForestClassifier(random_state=42),
    param_grid,
    cv=5,
    scoring='f1_macro',
    n_jobs=-1,  # ä¸¦åˆ—å®Ÿè¡Œ
    verbose=1
)

grid_search.fit(X_train, y_train)

# æœ€é©ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
print(&quot;æœ€é©ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:&quot;)
print(grid_search.best_params_)
print(f&quot;\næœ€è‰¯ã‚¹ã‚³ã‚¢: {grid_search.best_score_:.3f}&quot;)

# ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§è©•ä¾¡
best_model = grid_search.best_estimator_
test_score = best_model.score(X_test, y_test)
print(f&quot;ãƒ†ã‚¹ãƒˆã‚¹ã‚³ã‚¢: {test_score:.3f}&quot;)
</code></pre>
<h3>5.2 ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ¼ãƒï¼ˆRandom Searchï¼‰</h3>
<p>ãƒ©ãƒ³ãƒ€ãƒ ã«çµ„ã¿åˆã‚ã›ã‚’è©¦ã™åŠ¹ç‡çš„ãªæ¢ç´¢ï¼š</p>
<pre><code class="language-python">from sklearn.model_selection import RandomizedSearchCV
from scipy.stats import randint, uniform

# ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åˆ†å¸ƒ
param_distributions = {
    'n_estimators': randint(50, 300),
    'max_depth': randint(3, 20),
    'min_samples_split': randint(2, 20),
    'min_samples_leaf': randint(1, 10),
    'max_features': uniform(0.1, 0.9)
}

# ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ¼ãƒ
random_search = RandomizedSearchCV(
    RandomForestClassifier(random_state=42),
    param_distributions,
    n_iter=100,  # è©¦è¡Œå›æ•°
    cv=5,
    scoring='f1_macro',
    random_state=42,
    n_jobs=-1
)

random_search.fit(X_train, y_train)

print(&quot;æœ€é©ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:&quot;)
print(random_search.best_params_)
print(f&quot;æœ€è‰¯ã‚¹ã‚³ã‚¢: {random_search.best_score_:.3f}&quot;)
</code></pre>
<h3>5.3 ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ï¼ˆBayesian Optimizationï¼‰</h3>
<p>ã‚ˆã‚Šè³¢ã„ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¢ç´¢ï¼ˆOptunaãªã©ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªä½¿ç”¨ï¼‰ï¼š</p>
<pre><code class="language-python"># Optunaã®ä¾‹ï¼ˆåˆ¥é€”ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å¿…è¦: pip install optunaï¼‰
try:
    import optuna
    from sklearn.ensemble import RandomForestClassifier

    def objective(trial):
        params = {
            'n_estimators': trial.suggest_int('n_estimators', 50, 300),
            'max_depth': trial.suggest_int('max_depth', 3, 20),
            'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),
            'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10)
        }

        model = RandomForestClassifier(**params, random_state=42)
        score = cross_val_score(model, X_train, y_train, cv=5, scoring='f1_macro').mean()
        return score

    study = optuna.create_study(direction='maximize')
    study.optimize(objective, n_trials=50, show_progress_bar=True)

    print(&quot;æœ€é©ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:&quot;)
    print(study.best_params)
    print(f&quot;æœ€è‰¯ã‚¹ã‚³ã‚¢: {study.best_value:.3f}&quot;)

except ImportError:
    print(&quot;OptunaãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“&quot;)
</code></pre>
<hr />
<h2>6. å®Ÿè·µãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: ã‚¿ã‚¤ã‚¿ãƒ‹ãƒƒã‚¯ç”Ÿå­˜äºˆæ¸¬</h2>
<p>å®Œå…¨ãªãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®å®Ÿè£…ä¾‹ï¼š</p>
<pre><code class="language-python">import pandas as pd
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix

# ãƒ‡ãƒ¼ã‚¿æº–å‚™ï¼ˆç°¡æ˜“ç‰ˆï¼‰
data = {
    'Age': [22, 38, 26, 35, 35, np.nan, 54, 2, 27, 14, 4, 58],
    'Fare': [7.25, 71.28, 7.92, 53.1, 8.05, 8.46, 51.86, 21.08, 11.13, 30.07, 16.7, 13.0],
    'Sex': [1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0],  # 1=male, 0=female
    'Pclass': [3, 1, 3, 1, 3, 3, 1, 3, 2, 2, 3, 2],
    'Survived': [0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1]
}
df = pd.DataFrame(data)

# 1. æ¬ æå€¤å‡¦ç†
df['Age'].fillna(df['Age'].median(), inplace=True)

# 2. ç‰¹å¾´é‡ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®åˆ†é›¢
X = df[['Age', 'Fare', 'Sex', 'Pclass']]
y = df['Survived']

# 3. ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42, stratify=y
)

# 4. ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# 5. ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°
param_grid = {
    'n_estimators': [50, 100, 150],
    'max_depth': [3, 5, 7],
    'min_samples_split': [2, 5]
}

grid_search = GridSearchCV(
    RandomForestClassifier(random_state=42),
    param_grid,
    cv=3,
    scoring='accuracy'
)

grid_search.fit(X_train_scaled, y_train)

# 6. æœ€çµ‚ãƒ¢ãƒ‡ãƒ«ã§äºˆæ¸¬
best_model = grid_search.best_estimator_
y_pred = best_model.predict(X_test_scaled)

# 7. è©•ä¾¡
print(&quot;åˆ†é¡ãƒ¬ãƒãƒ¼ãƒˆ:&quot;)
print(classification_report(y_test, y_pred, target_names=['æ­»äº¡', 'ç”Ÿå­˜']))

print(&quot;\næ··åŒè¡Œåˆ—:&quot;)
print(confusion_matrix(y_test, y_pred))

print(f&quot;\nãƒ†ã‚¹ãƒˆæ­£è§£ç‡: {best_model.score(X_test_scaled, y_test):.2%}&quot;)
</code></pre>
<hr />
<h2>7. ã¾ã¨ã‚</h2>
<h3>7.1 æœ¬ç« ã§å­¦ã‚“ã ã“ã¨</h3>
<p>âœ… <strong>ãƒ‡ãƒ¼ã‚¿åˆ†å‰²</strong>
- è¨“ç·´ãƒ»æ¤œè¨¼ãƒ»ãƒ†ã‚¹ãƒˆã®3åˆ†å‰²
- å±¤åŒ–ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°</p>
<p>âœ… <strong>äº¤å·®æ¤œè¨¼</strong>
- K-Foldã€å±¤åŒ–K-Foldã€LOO
- ãƒ¢ãƒ‡ãƒ«ã®æ±åŒ–æ€§èƒ½è©•ä¾¡</p>
<p>âœ… <strong>è©•ä¾¡æŒ‡æ¨™</strong>
- åˆ†é¡: æ­£è§£ç‡ã€é©åˆç‡ã€å†ç¾ç‡ã€F1ã€AUC
- å›å¸°: MSE, RMSE, MAE, RÂ²</p>
<p>âœ… <strong>éå­¦ç¿’å¯¾ç­–</strong>
- æ­£å‰‡åŒ–ã€æ—©æœŸåœæ­¢ã€ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«
- å­¦ç¿’æ›²ç·šã«ã‚ˆã‚‹æ¤œå‡º</p>
<p>âœ… <strong>ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°</strong>
- GridSearch, RandomSearch, ãƒ™ã‚¤ã‚ºæœ€é©åŒ–</p>
<h3>7.2 æ©Ÿæ¢°å­¦ç¿’ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ</h3>
<ul>
<li>[ ] ãƒ‡ãƒ¼ã‚¿ã‚’è¨“ç·´ãƒ»æ¤œè¨¼ãƒ»ãƒ†ã‚¹ãƒˆã«åˆ†å‰²</li>
<li>[ ] äº¤å·®æ¤œè¨¼ã§æ€§èƒ½ã‚’è©•ä¾¡</li>
<li>[ ] é©åˆ‡ãªè©•ä¾¡æŒ‡æ¨™ã‚’é¸æŠ</li>
<li>[ ] éå­¦ç¿’ã‚’æ¤œå‡ºãƒ»å¯¾ç­–</li>
<li>[ ] ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æœ€é©åŒ–</li>
<li>[ ] ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§æœ€çµ‚è©•ä¾¡</li>
<li>[ ] ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ãƒ»ãƒ‡ãƒ—ãƒ­ã‚¤</li>
</ul>
<hr />
<h2>8. ç·´ç¿’å•é¡Œ</h2>
<h3>å•é¡Œ1: è©•ä¾¡æŒ‡æ¨™ã®é¸æŠï¼ˆåŸºç¤ï¼‰</h3>
<p>ä»¥ä¸‹ã®ã‚·ãƒŠãƒªã‚ªã«æœ€é©ãªè©•ä¾¡æŒ‡æ¨™ã‚’é¸ã‚“ã§ãã ã•ã„ã€‚</p>
<p>a) ã‚¹ãƒ‘ãƒ ãƒ¡ãƒ¼ãƒ«æ¤œå‡ºï¼ˆæ­£å¸¸ãƒ¡ãƒ¼ãƒ«ã‚’èª¤ã£ã¦ã‚¹ãƒ‘ãƒ ã«ã—ãŸããªã„ï¼‰
b) ãŒã‚“æ¤œè¨ºï¼ˆãŒã‚“ã‚’è¦‹é€ƒã—ãŸããªã„ï¼‰
c) ãƒãƒ©ãƒ³ã‚¹ã®å–ã‚ŒãŸ3ã‚¯ãƒ©ã‚¹åˆ†é¡</p>
<details>
<summary>è§£ç­”</summary>

**è§£ç­”:**
a) **é©åˆç‡ï¼ˆPrecisionï¼‰** - å½é™½æ€§ï¼ˆæ­£å¸¸ã‚’ã‚¹ãƒ‘ãƒ ã¨èª¤åˆ¤å®šï¼‰ã‚’æ¸›ã‚‰ã™
b) **å†ç¾ç‡ï¼ˆRecallï¼‰** - å½é™°æ€§ï¼ˆãŒã‚“ã‚’è¦‹é€ƒã™ï¼‰ã‚’æ¸›ã‚‰ã™
c) **F1ã‚¹ã‚³ã‚¢** - ãƒãƒ©ãƒ³ã‚¹ã®å–ã‚ŒãŸè©•ä¾¡

</details>

<h3>å•é¡Œ2: äº¤å·®æ¤œè¨¼ã®å®Ÿè£…ï¼ˆä¸­ç´šï¼‰</h3>
<p>ã‚¢ã‚¤ãƒªã‚¹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§5-Foldäº¤å·®æ¤œè¨¼ã‚’å®Ÿè£…ã—ã€DecisionTreeã¨RandomForestã®æ€§èƒ½ã‚’æ¯”è¼ƒã—ã¦ãã ã•ã„ã€‚</p>
<details>
<summary>è§£ç­”ä¾‹</summary>


<pre><code class="language-python">from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_val_score

iris = load_iris()
X, y = iris.data, iris.target

models = {
    'DecisionTree': DecisionTreeClassifier(max_depth=5, random_state=42),
    'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42)
}

for name, model in models.items():
    scores = cross_val_score(model, X, y, cv=5)
    print(f&quot;{name}: {scores.mean():.3f} (+/- {scores.std():.3f})&quot;)
</code></pre>


</details>

<hr />
<h2>9. æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—</h2>
<p>æ©Ÿæ¢°å­¦ç¿’å…¥é–€ã‚·ãƒªãƒ¼ã‚ºã‚’å®Œäº†ã—ã¾ã—ãŸï¼æ¬¡ã¯ï¼š</p>
<ol>
<li><strong>å„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’æ·±ãå­¦ã¶</strong>: ç·šå½¢å›å¸°ã€æ±ºå®šæœ¨ã€SVMç­‰ã®å°‚é–€ã‚·ãƒªãƒ¼ã‚º</li>
<li><strong>ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ã‚’å­¦ã¶</strong>: å®Ÿè·µçš„ãªãƒ‡ãƒ¼ã‚¿å‡¦ç†æŠ€è¡“</li>
<li><strong>æ·±å±¤å­¦ç¿’ã¸é€²ã‚€</strong>: ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã€CNNã€RNN</li>
</ol>
<hr />
<p><strong>å‰ã¸</strong>: <a href="chapter-3.html">â† Chapter 3: æ•™å¸«ãªã—å­¦ç¿’ã®åŸºç¤</a></p>
<p><strong>ç›®æ¬¡ã¸</strong>: <a href="index.html">â†‘ ã‚·ãƒªãƒ¼ã‚ºç›®æ¬¡</a></p>
<hr />
<p><strong>ãŠã‚ã§ã¨ã†ã”ã–ã„ã¾ã™ï¼æ©Ÿæ¢°å­¦ç¿’å…¥é–€ã‚·ãƒªãƒ¼ã‚ºã‚’å®Œäº†ã—ã¾ã—ãŸï¼</strong></p><div class="navigation">
    <a href="chapter-3.html" class="nav-button">â† ç¬¬3ç« </a>
    <a href="index.html" class="nav-button">ã‚·ãƒªãƒ¼ã‚ºç›®æ¬¡ã«æˆ»ã‚‹</a>
</div>
    </main>

    <footer>
        <p><strong>ä½œæˆè€…</strong>: AI Terakoya Content Team</p>
        <p><strong>ç›£ä¿®</strong>: Dr. Yusuke Hashimotoï¼ˆæ±åŒ—å¤§å­¦ï¼‰</p>
        <p><strong>ãƒãƒ¼ã‚¸ãƒ§ãƒ³</strong>: 1.0 | <strong>ä½œæˆæ—¥</strong>: 2025-10-17</p>
        <p><strong>ãƒ©ã‚¤ã‚»ãƒ³ã‚¹</strong>: Creative Commons BY 4.0</p>
        <p>Â© 2025 AI Terakoya. All rights reserved.</p>
    </footer>
</body>
</html>
