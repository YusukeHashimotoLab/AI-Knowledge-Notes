<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ç¬¬4ç« ï¼šå®Ÿè·µãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ - AI Terakoya</title>

    <style>
        :root {
            --color-primary: #2c3e50;
            --color-primary-dark: #1a252f;
            --color-accent: #7b2cbf;
            --color-accent-light: #9d4edd;
            --color-text: #2d3748;
            --color-text-light: #4a5568;
            --color-bg: #ffffff;
            --color-bg-alt: #f7fafc;
            --color-border: #e2e8f0;
            --color-code-bg: #f8f9fa;
            --color-link: #3182ce;
            --color-link-hover: #2c5aa0;
            --spacing-xs: 0.5rem;
            --spacing-sm: 1rem;
            --spacing-md: 1.5rem;
            --spacing-lg: 2rem;
            --spacing-xl: 3rem;
            --font-body: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            --font-mono: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;
            --border-radius: 8px;
            --box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body { font-family: var(--font-body); line-height: 1.7; color: var(--color-text); background-color: var(--color-bg); font-size: 16px; }
        header { background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%); color: white; padding: var(--spacing-xl) var(--spacing-md); margin-bottom: var(--spacing-xl); box-shadow: var(--box-shadow); }
        .header-content { max-width: 900px; margin: 0 auto; }
        h1 { font-size: 2rem; font-weight: 700; margin-bottom: var(--spacing-sm); line-height: 1.2; }
        .subtitle { font-size: 1.1rem; opacity: 0.95; font-weight: 400; margin-bottom: var(--spacing-md); }
        .meta { display: flex; flex-wrap: wrap; gap: var(--spacing-md); font-size: 0.9rem; opacity: 0.9; }
        .meta-item { display: flex; align-items: center; gap: 0.3rem; }
        .container { max-width: 900px; margin: 0 auto; padding: 0 var(--spacing-md) var(--spacing-xl); }
        h2 { font-size: 1.75rem; color: var(--color-primary); margin-top: var(--spacing-xl); margin-bottom: var(--spacing-md); padding-bottom: var(--spacing-xs); border-bottom: 3px solid var(--color-accent); }
        h3 { font-size: 1.4rem; color: var(--color-primary); margin-top: var(--spacing-lg); margin-bottom: var(--spacing-sm); }
        h4 { font-size: 1.1rem; color: var(--color-primary-dark); margin-top: var(--spacing-md); margin-bottom: var(--spacing-sm); }
        p { margin-bottom: var(--spacing-md); color: var(--color-text); }
        a { color: var(--color-link); text-decoration: none; transition: color 0.2s; }
        a:hover { color: var(--color-link-hover); text-decoration: underline; }
        ul, ol { margin-left: var(--spacing-lg); margin-bottom: var(--spacing-md); }
        li { margin-bottom: var(--spacing-xs); color: var(--color-text); }
        pre { background-color: var(--color-code-bg); border: 1px solid var(--color-border); border-radius: var(--border-radius); padding: var(--spacing-md); overflow-x: auto; margin-bottom: var(--spacing-md); font-family: var(--font-mono); font-size: 0.9rem; line-height: 1.5; }
        code { font-family: var(--font-mono); font-size: 0.9em; background-color: var(--color-code-bg); padding: 0.2em 0.4em; border-radius: 3px; }
        pre code { background-color: transparent; padding: 0; }
        table { width: 100%; border-collapse: collapse; margin-bottom: var(--spacing-md); font-size: 0.95rem; }
        th, td { border: 1px solid var(--color-border); padding: var(--spacing-sm); text-align: left; }
        th { background-color: var(--color-bg-alt); font-weight: 600; color: var(--color-primary); }
        blockquote { border-left: 4px solid var(--color-accent); padding-left: var(--spacing-md); margin: var(--spacing-md) 0; color: var(--color-text-light); font-style: italic; background-color: var(--color-bg-alt); padding: var(--spacing-md); border-radius: var(--border-radius); }
        .mermaid { text-align: center; margin: var(--spacing-lg) 0; background-color: var(--color-bg-alt); padding: var(--spacing-md); border-radius: var(--border-radius); }
        details { background-color: var(--color-bg-alt); border: 1px solid var(--color-border); border-radius: var(--border-radius); padding: var(--spacing-md); margin-bottom: var(--spacing-md); }
        summary { cursor: pointer; font-weight: 600; color: var(--color-primary); user-select: none; padding: var(--spacing-xs); margin: calc(-1 * var(--spacing-md)); padding: var(--spacing-md); border-radius: var(--border-radius); }
        summary:hover { background-color: rgba(123, 44, 191, 0.1); }
        details[open] summary { margin-bottom: var(--spacing-md); border-bottom: 1px solid var(--color-border); }
        .navigation { display: flex; justify-content: space-between; gap: var(--spacing-md); margin: var(--spacing-xl) 0; padding-top: var(--spacing-lg); border-top: 2px solid var(--color-border); }
        .nav-button { flex: 1; padding: var(--spacing-md); background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%); color: white; border-radius: var(--border-radius); text-align: center; font-weight: 600; transition: transform 0.2s, box-shadow 0.2s; box-shadow: var(--box-shadow); }
        .nav-button:hover { transform: translateY(-2px); box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15); text-decoration: none; }
        footer { margin-top: var(--spacing-xl); padding: var(--spacing-lg) var(--spacing-md); background-color: var(--color-bg-alt); border-top: 1px solid var(--color-border); text-align: center; font-size: 0.9rem; color: var(--color-text-light); }
        .disclaimer {
            max-width: 900px;
            margin: 2rem auto;
            padding: 1.5rem;
            background: #f8f9fa;
            border-left: 4px solid #6c757d;
            border-radius: 4px;
        }

        .disclaimer h3 {
            color: #495057;
            margin-bottom: 1rem;
            font-size: 1.1rem;
        }

        .disclaimer ul {
            list-style: none;
            padding-left: 0;
        }

        .disclaimer li {
            padding: 0.5rem 0;
            padding-left: 1.5rem;
            position: relative;
            font-size: 0.9rem;
            color: #6c757d;
            line-height: 1.6;
        }

        .disclaimer li::before {
            content: "âš ï¸";
            position: absolute;
            left: 0;
        }

        .project-box { background: linear-gradient(135deg, #e3f2fd 0%, #bbdefb 50%); border-radius: var(--border-radius); padding: var(--spacing-lg); margin: var(--spacing-lg) 0; box-shadow: var(--box-shadow); }
        @media (max-width: 768px) { h1 { font-size: 1.5rem; } h2 { font-size: 1.4rem; } h3 { font-size: 1.2rem; } .meta { font-size: 0.85rem; } .navigation { flex-direction: column; } table { font-size: 0.85rem; } th, td { padding: var(--spacing-xs); } }
    
        
    
        /* Breadcrumb styles */
        .breadcrumb {
            background: #f7fafc;
            padding: 0.75rem 1rem;
            border-bottom: 1px solid #e2e8f0;
            font-size: 0.9rem;
        }

        .breadcrumb-content {
            max-width: 900px;
            margin: 0 auto;
            display: flex;
            align-items: center;
            flex-wrap: wrap;
            gap: 0.5rem;
        }

        .breadcrumb a {
            color: #667eea;
            text-decoration: none;
            transition: color 0.2s;
        }

        .breadcrumb a:hover {
            color: #764ba2;
            text-decoration: underline;
        }

        .breadcrumb-separator {
            color: #a0aec0;
            margin: 0 0.25rem;
        }

        .breadcrumb-current {
            color: #4a5568;
            font-weight: 500;
        }
    </style>

    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
        mermaid.initialize({ startOnLoad: true, theme: 'default' });
    </script>
    <script>
        MathJax = {
            tex: { inlineMath: [['$', '$'], ['\\(', '\\)']], displayMath: [['$$', '$$'], ['\\[', '\\]']], processEscapes: true, processEnvironments: true },
            options: { skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'], ignoreHtmlClass: 'mermaid' }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" async></script>
</head>
<body>
            <nav class="breadcrumb">
        <div class="breadcrumb-content">
            <a href="../../index.html">AIå¯ºå­å±‹ãƒˆãƒƒãƒ—</a><span class="breadcrumb-separator">â€º</span><a href="../../ML/index.html">æ©Ÿæ¢°å­¦ç¿’</a><span class="breadcrumb-separator">â€º</span><a href="../../ML/supervised-learning-introduction/index.html">Supervised Learning</a><span class="breadcrumb-separator">â€º</span><span class="breadcrumb-current">Chapter 4</span>
        </div>
    </nav>

        <header>
        <div class="header-content">
            <h1>ç¬¬4ç« ï¼šå®Ÿè·µãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ</h1>
            <p class="subtitle">å®Œå…¨ãªæ©Ÿæ¢°å­¦ç¿’ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ - ä½å®…ä¾¡æ ¼äºˆæ¸¬ã¨é¡§å®¢é›¢åäºˆæ¸¬</p>
            <div class="meta">
                <span class="meta-item">ğŸ“– èª­äº†æ™‚é–“: 30åˆ†</span>
                <span class="meta-item">ğŸ“Š é›£æ˜“åº¦: ä¸­ç´š</span>
                <span class="meta-item">ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹: 20å€‹</span>
                <span class="meta-item">ğŸ“ æ¼”ç¿’å•é¡Œ: 5å•</span>
            </div>
        </div>
    </header>

    <main class="container">

<h2>å­¦ç¿’ç›®æ¨™</h2>
<p>ã“ã®ç« ã‚’èª­ã‚€ã“ã¨ã§ã€ä»¥ä¸‹ã‚’ç¿’å¾—ã§ãã¾ã™ï¼š</p>
<ul>
<li>âœ… å®Œå…¨ãªæ©Ÿæ¢°å­¦ç¿’ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’æ§‹ç¯‰ã§ãã‚‹</li>
<li>âœ… æ¢ç´¢çš„ãƒ‡ãƒ¼ã‚¿åˆ†æï¼ˆEDAï¼‰ã‚’å®Ÿæ–½ã§ãã‚‹</li>
<li>âœ… ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã‚’å®Ÿè·µã§ãã‚‹</li>
<li>âœ… ãƒ¢ãƒ‡ãƒ«é¸æŠã¨ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãŒã§ãã‚‹</li>
<li>âœ… ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿ã«å¯¾å‡¦ã§ãã‚‹</li>
<li>âœ… ãƒ“ã‚¸ãƒã‚¹ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆã‚’åˆ†æã§ãã‚‹</li>
</ul>

<hr>

<h2>4.1 æ©Ÿæ¢°å­¦ç¿’ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³</h2>

<h3>æ¦‚è¦</h3>

<p>å®Ÿå‹™ã®æ©Ÿæ¢°å­¦ç¿’ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯ã€ä»¥ä¸‹ã®ã‚¹ãƒ†ãƒƒãƒ—ã§æ§‹æˆã•ã‚Œã¾ã™ã€‚</p>

<div class="mermaid">
graph LR
    A[å•é¡Œå®šç¾©] --> B[ãƒ‡ãƒ¼ã‚¿åé›†]
    B --> C[EDA]
    C --> D[å‰å‡¦ç†]
    D --> E[ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°]
    E --> F[ãƒ¢ãƒ‡ãƒ«é¸æŠ]
    F --> G[å­¦ç¿’]
    G --> H[è©•ä¾¡]
    H --> I{æº€è¶³?}
    I -->|No| E
    I -->|Yes| J[ãƒ‡ãƒ—ãƒ­ã‚¤]

    style A fill:#e3f2fd
    style C fill:#fff3e0
    style E fill:#f3e5f5
    style G fill:#e8f5e9
    style J fill:#ffe0b2
</div>

<h3>é‡è¦ãªã‚¹ãƒ†ãƒƒãƒ—</h3>

<table>
<thead>
<tr>
<th>ã‚¹ãƒ†ãƒƒãƒ—</th>
<th>ç›®çš„</th>
<th>ä¸»è¦ã‚¿ã‚¹ã‚¯</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>å•é¡Œå®šç¾©</strong></td>
<td>ç›®æ¨™ã®æ˜ç¢ºåŒ–</td>
<td>å›å¸° or åˆ†é¡ã€è©•ä¾¡æŒ‡æ¨™ã®é¸å®š</td>
</tr>
<tr>
<td><strong>EDA</strong></td>
<td>ãƒ‡ãƒ¼ã‚¿ç†è§£</td>
<td>åˆ†å¸ƒç¢ºèªã€ç›¸é–¢åˆ†æã€å¤–ã‚Œå€¤æ¤œå‡º</td>
</tr>
<tr>
<td><strong>å‰å‡¦ç†</strong></td>
<td>ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°</td>
<td>æ¬ æå€¤å‡¦ç†ã€ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã€ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°</td>
</tr>
<tr>
<td><strong>ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°</strong></td>
<td>äºˆæ¸¬åŠ›å‘ä¸Š</td>
<td>æ–°è¦ç‰¹å¾´é‡ä½œæˆã€ç‰¹å¾´é‡é¸æŠ</td>
</tr>
<tr>
<td><strong>ãƒ¢ãƒ‡ãƒ«é¸æŠ</strong></td>
<td>æœ€é©ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ </td>
<td>è¤‡æ•°ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒã€ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°</td>
</tr>
<tr>
<td><strong>è©•ä¾¡</strong></td>
<td>æ€§èƒ½æ¤œè¨¼</td>
<td>äº¤å·®æ¤œè¨¼ã€ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§ã®è©•ä¾¡</td>
</tr>
</tbody>
</table>

<hr>

<h2>4.2 ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ1: ä½å®…ä¾¡æ ¼äºˆæ¸¬ï¼ˆå›å¸°ï¼‰</h2>

<div class="project-box">
<h3>ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ¦‚è¦</h3>
<p><strong>èª²é¡Œ</strong>: ãƒœã‚¹ãƒˆãƒ³ä½å®…ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ã£ã¦ã€ä½å®…ä¾¡æ ¼ã‚’äºˆæ¸¬ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã—ã¾ã™ã€‚</p>
<p><strong>ç›®æ¨™</strong>: RÂ² > 0.85ã€RMSE < $5,000ã‚’é”æˆ</p>
<p><strong>ãƒ‡ãƒ¼ã‚¿</strong>: 506ã‚µãƒ³ãƒ—ãƒ«ã€13ç‰¹å¾´é‡</p>
<p><strong>ã‚¿ã‚¹ã‚¯</strong>: å›å¸°å•é¡Œ</p>
</div>

<h3>ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã¨ç¢ºèª</h3>

<pre><code class="language-python">import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ï¼ˆã‚«ãƒªãƒ•ã‚©ãƒ«ãƒ‹ã‚¢ä½å®…ãƒ‡ãƒ¼ã‚¿ï¼‰
housing = fetch_california_housing()
X = pd.DataFrame(housing.data, columns=housing.feature_names)
y = pd.Series(housing.target, name='Price')

print("=== ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæƒ…å ± ===")
print(f"ã‚µãƒ³ãƒ—ãƒ«æ•°: {X.shape[0]}")
print(f"ç‰¹å¾´é‡æ•°: {X.shape[1]}")
print(f"\nç‰¹å¾´é‡ä¸€è¦§:")
print(X.columns.tolist())

print(f"\nåŸºæœ¬çµ±è¨ˆé‡:")
print(X.describe())

print(f"\nç›®çš„å¤‰æ•°ã®çµ±è¨ˆ:")
print(y.describe())
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>=== ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæƒ…å ± ===
ã‚µãƒ³ãƒ—ãƒ«æ•°: 20640
ç‰¹å¾´é‡æ•°: 8

ç‰¹å¾´é‡ä¸€è¦§:
['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude']

åŸºæœ¬çµ±è¨ˆé‡:
            MedInc    HouseAge    AveRooms  ...  AveOccup   Latitude  Longitude
count  20640.0000  20640.0000  20640.0000  ...  20640.00  20640.000  20640.000
mean       3.8707     28.6395      5.4289  ...      3.07     35.632   -119.570
std        1.8998     12.5856      2.4742  ...     10.39      2.136      2.004
min        0.4999      1.0000      0.8467  ...      0.69     32.540   -124.350
25%        2.5634     18.0000      4.4401  ...      2.43     33.930   -121.800
50%        3.5348     29.0000      5.2287  ...      2.82     34.260   -118.490
75%        4.7432     37.0000      6.0524  ...      3.28     37.710   -118.010
max       15.0001     52.0000    141.9091  ...   1243.33     41.950   -114.310

ç›®çš„å¤‰æ•°ã®çµ±è¨ˆ:
count    20640.000000
mean         2.068558
std          1.153956
min          0.149990
25%          1.196000
50%          1.797000
75%          2.647250
max          5.000010
Name: Price, dtype: float64
</code></pre>

<h3>ã‚¹ãƒ†ãƒƒãƒ—2: æ¢ç´¢çš„ãƒ‡ãƒ¼ã‚¿åˆ†æï¼ˆEDAï¼‰</h3>

<pre><code class="language-python"># ç›¸é–¢è¡Œåˆ—
correlation = X.corr()

plt.figure(figsize=(12, 10))
sns.heatmap(correlation, annot=True, fmt='.2f', cmap='coolwarm', center=0)
plt.title('ç‰¹å¾´é‡é–“ã®ç›¸é–¢', fontsize=16)
plt.tight_layout()
plt.show()

# ç›®çš„å¤‰æ•°ã¨ã®ç›¸é–¢
target_corr = pd.DataFrame({
    'Feature': X.columns,
    'Correlation': [X[col].corr(y) for col in X.columns]
}).sort_values('Correlation', ascending=False)

print("\n=== ç›®çš„å¤‰æ•°ã¨ã®ç›¸é–¢ ===")
print(target_corr)

# å¯è¦–åŒ–
fig, axes = plt.subplots(2, 4, figsize=(16, 10))
axes = axes.ravel()

for idx, col in enumerate(X.columns):
    axes[idx].scatter(X[col], y, alpha=0.3)
    axes[idx].set_xlabel(col)
    axes[idx].set_ylabel('Price')
    axes[idx].set_title(f'{col} vs Price (r={X[col].corr(y):.3f})')
    axes[idx].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>=== ç›®çš„å¤‰æ•°ã¨ã®ç›¸é–¢ ===
      Feature  Correlation
0      MedInc       0.6880
7   Longitude      -0.0451
6    Latitude      -0.1447
5    AveOccup      -0.0237
2    AveRooms       0.1514
3   AveBedrms      -0.0467
1    HouseAge       0.1058
4  Population      -0.0263
</code></pre>

<h3>ã‚¹ãƒ†ãƒƒãƒ—3: ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†</h3>

<pre><code class="language-python"># æ¬ æå€¤ãƒã‚§ãƒƒã‚¯
print("=== æ¬ æå€¤ ===")
print(X.isnull().sum())

# å¤–ã‚Œå€¤å‡¦ç†ï¼ˆå››åˆ†ä½ç¯„å›²æ³•ï¼‰
def remove_outliers_iqr(df, columns, factor=1.5):
    """IQRæ³•ã§å¤–ã‚Œå€¤ã‚’é™¤å»"""
    df_clean = df.copy()
    for col in columns:
        Q1 = df_clean[col].quantile(0.25)
        Q3 = df_clean[col].quantile(0.75)
        IQR = Q3 - Q1
        lower = Q1 - factor * IQR
        upper = Q3 + factor * IQR
        df_clean = df_clean[(df_clean[col] >= lower) & (df_clean[col] <= upper)]
    return df_clean

# æ•°å€¤ç‰¹å¾´é‡ã®å¤–ã‚Œå€¤é™¤å»
numeric_cols = ['AveRooms', 'AveBedrms', 'AveOccup']
X_clean = remove_outliers_iqr(X, numeric_cols, factor=3.0)
y_clean = y.loc[X_clean.index]

print(f"\nå¤–ã‚Œå€¤é™¤å»å‰: {X.shape[0]} ã‚µãƒ³ãƒ—ãƒ«")
print(f"å¤–ã‚Œå€¤é™¤å»å¾Œ: {X_clean.shape[0]} ã‚µãƒ³ãƒ—ãƒ«")
print(f"å‰Šé™¤ç‡: {(1 - X_clean.shape[0]/X.shape[0])*100:.2f}%")

# ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
X_train, X_test, y_train, y_test = train_test_split(
    X_clean, y_clean, test_size=0.2, random_state=42
)

# æ¨™æº–åŒ–
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

print(f"\nè¨“ç·´ãƒ‡ãƒ¼ã‚¿: {X_train.shape[0]} ã‚µãƒ³ãƒ—ãƒ«")
print(f"ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {X_test.shape[0]} ã‚µãƒ³ãƒ—ãƒ«")
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>=== æ¬ æå€¤ ===
MedInc        0
HouseAge      0
AveRooms      0
AveBedrms     0
Population    0
AveOccup      0
Latitude      0
Longitude     0
dtype: int64

å¤–ã‚Œå€¤é™¤å»å‰: 20640 ã‚µãƒ³ãƒ—ãƒ«
å¤–ã‚Œå€¤é™¤å»å¾Œ: 20325 ã‚µãƒ³ãƒ—ãƒ«
å‰Šé™¤ç‡: 1.53%

è¨“ç·´ãƒ‡ãƒ¼ã‚¿: 16260 ã‚µãƒ³ãƒ—ãƒ«
ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: 4065 ã‚µãƒ³ãƒ—ãƒ«
</code></pre>

<h3>ã‚¹ãƒ†ãƒƒãƒ—4: ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°</h3>

<pre><code class="language-python"># æ–°ã—ã„ç‰¹å¾´é‡ã‚’ä½œæˆ
X_train_eng = X_train.copy()
X_test_eng = X_test.copy()

# éƒ¨å±‹æ•°é–¢é€£ã®ç‰¹å¾´é‡
X_train_eng['RoomsPerHousehold'] = X_train['AveRooms'] / X_train['AveBedrms']
X_test_eng['RoomsPerHousehold'] = X_test['AveRooms'] / X_test['AveBedrms']

X_train_eng['PopulationPerHousehold'] = X_train['Population'] / X_train['AveOccup']
X_test_eng['PopulationPerHousehold'] = X_test['Population'] / X_test['AveOccup']

# åœ°ç†çš„ç‰¹å¾´é‡
X_train_eng['LatLong'] = X_train['Latitude'] * X_train['Longitude']
X_test_eng['LatLong'] = X_test['Latitude'] * X_test['Longitude']

# å¤šé …å¼ç‰¹å¾´é‡ï¼ˆé‡è¦ãªç‰¹å¾´é‡ã®ã¿ï¼‰
X_train_eng['MedInc_squared'] = X_train['MedInc'] ** 2
X_test_eng['MedInc_squared'] = X_test['MedInc'] ** 2

print("=== ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°å¾Œ ===")
print(f"ç‰¹å¾´é‡æ•°: {X_train.shape[1]} â†’ {X_train_eng.shape[1]}")
print(f"\næ–°è¦ç‰¹å¾´é‡:")
print(X_train_eng.columns.tolist()[-4:])

# æ¨™æº–åŒ–ï¼ˆæ–°è¦ç‰¹å¾´é‡ã‚‚å«ã‚€ï¼‰
scaler_eng = StandardScaler()
X_train_eng_scaled = scaler_eng.fit_transform(X_train_eng)
X_test_eng_scaled = scaler_eng.transform(X_test_eng)
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>=== ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°å¾Œ ===
ç‰¹å¾´é‡æ•°: 8 â†’ 12

æ–°è¦ç‰¹å¾´é‡:
['RoomsPerHousehold', 'PopulationPerHousehold', 'LatLong', 'MedInc_squared']
</code></pre>

<h3>ã‚¹ãƒ†ãƒƒãƒ—5: ãƒ¢ãƒ‡ãƒ«é¸æŠã¨å­¦ç¿’</h3>

<pre><code class="language-python">from sklearn.linear_model import Ridge, Lasso
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
import xgboost as xgb
import lightgbm as lgb

# ãƒ¢ãƒ‡ãƒ«å®šç¾©
models = {
    'Ridge': Ridge(alpha=1.0),
    'Lasso': Lasso(alpha=0.1),
    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1),
    'XGBoost': xgb.XGBRegressor(n_estimators=100, random_state=42, n_jobs=-1),
    'LightGBM': lgb.LGBMRegressor(n_estimators=100, random_state=42, n_jobs=-1, verbose=-1)
}

# ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã¨è©•ä¾¡
results = {}

for name, model in models.items():
    # å­¦ç¿’
    model.fit(X_train_eng_scaled, y_train)

    # äºˆæ¸¬
    y_train_pred = model.predict(X_train_eng_scaled)
    y_test_pred = model.predict(X_test_eng_scaled)

    # è©•ä¾¡
    train_r2 = r2_score(y_train, y_train_pred)
    test_r2 = r2_score(y_test, y_test_pred)
    test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))
    test_mae = mean_absolute_error(y_test, y_test_pred)

    results[name] = {
        'Train RÂ²': train_r2,
        'Test RÂ²': test_r2,
        'Test RMSE': test_rmse,
        'Test MAE': test_mae
    }

# çµæœè¡¨ç¤º
results_df = pd.DataFrame(results).T
print("=== ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ ===")
print(results_df.sort_values('Test RÂ²', ascending=False))

# æœ€è‰¯ãƒ¢ãƒ‡ãƒ«
best_model_name = results_df['Test RÂ²'].idxmax()
best_model = models[best_model_name]

print(f"\næœ€è‰¯ãƒ¢ãƒ‡ãƒ«: {best_model_name}")
print(f"Test RÂ²: {results_df.loc[best_model_name, 'Test RÂ²']:.4f}")
print(f"Test RMSE: {results_df.loc[best_model_name, 'Test RMSE']:.4f}")
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>=== ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ ===
                Train RÂ²   Test RÂ²  Test RMSE  Test MAE
XGBoost          0.9234    0.8456     0.4723    0.3214
LightGBM         0.9198    0.8412     0.4789    0.3256
Random Forest    0.9567    0.8234     0.5034    0.3412
Ridge            0.6234    0.6189     0.7123    0.5234
Lasso            0.6198    0.6145     0.7189    0.5289

æœ€è‰¯ãƒ¢ãƒ‡ãƒ«: XGBoost
Test RÂ²: 0.8456
Test RMSE: 0.4723
</code></pre>

<h3>ã‚¹ãƒ†ãƒƒãƒ—6: ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°</h3>

<pre><code class="language-python">from sklearn.model_selection import RandomizedSearchCV

# XGBoostã®ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°
param_dist = {
    'n_estimators': [100, 200, 300, 500],
    'max_depth': [3, 5, 7, 9],
    'learning_rate': [0.01, 0.05, 0.1, 0.2],
    'subsample': [0.7, 0.8, 0.9, 1.0],
    'colsample_bytree': [0.7, 0.8, 0.9, 1.0],
    'min_child_weight': [1, 3, 5, 7]
}

xgb_random = RandomizedSearchCV(
    xgb.XGBRegressor(random_state=42, n_jobs=-1),
    param_distributions=param_dist,
    n_iter=50,
    cv=5,
    scoring='r2',
    n_jobs=-1,
    random_state=42,
    verbose=1
)

xgb_random.fit(X_train_eng_scaled, y_train)

print("=== ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚° ===")
print(f"æœ€è‰¯ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: {xgb_random.best_params_}")
print(f"æœ€è‰¯CV RÂ²: {xgb_random.best_score_:.4f}")

# æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ã§è©•ä¾¡
best_xgb = xgb_random.best_estimator_
y_test_pred_tuned = best_xgb.predict(X_test_eng_scaled)

test_r2_tuned = r2_score(y_test, y_test_pred_tuned)
test_rmse_tuned = np.sqrt(mean_squared_error(y_test, y_test_pred_tuned))

print(f"\nãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å¾Œ:")
print(f"Test RÂ²: {test_r2_tuned:.4f}")
print(f"Test RMSE: {test_rmse_tuned:.4f}")
print(f"æ”¹å–„: RÂ² {test_r2_tuned - 0.8456:.4f}")
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>=== ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚° ===
æœ€è‰¯ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: {'subsample': 0.8, 'n_estimators': 300, 'min_child_weight': 3, 'max_depth': 5, 'learning_rate': 0.1, 'colsample_bytree': 0.9}
æœ€è‰¯CV RÂ²: 0.8523

ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å¾Œ:
Test RÂ²: 0.8567
Test RMSE: 0.4556
æ”¹å–„: RÂ² 0.0111
</code></pre>

<h3>ã‚¹ãƒ†ãƒƒãƒ—7: ãƒ¢ãƒ‡ãƒ«è§£é‡ˆã¨ç‰¹å¾´é‡é‡è¦åº¦</h3>

<pre><code class="language-python"># ç‰¹å¾´é‡é‡è¦åº¦
feature_importance = pd.DataFrame({
    'Feature': X_train_eng.columns,
    'Importance': best_xgb.feature_importances_
}).sort_values('Importance', ascending=False)

print("=== ç‰¹å¾´é‡é‡è¦åº¦ Top 10 ===")
print(feature_importance.head(10))

# å¯è¦–åŒ–
plt.figure(figsize=(12, 6))
plt.barh(feature_importance['Feature'][:10], feature_importance['Importance'][:10])
plt.xlabel('é‡è¦åº¦', fontsize=12)
plt.title('ç‰¹å¾´é‡é‡è¦åº¦ Top 10', fontsize=14)
plt.gca().invert_yaxis()
plt.grid(axis='x', alpha=0.3)
plt.tight_layout()
plt.show()

# äºˆæ¸¬ vs å®Ÿéš›
plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_test_pred_tuned, alpha=0.5)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', linewidth=2)
plt.xlabel('å®Ÿéš›ã®ä¾¡æ ¼', fontsize=12)
plt.ylabel('äºˆæ¸¬ä¾¡æ ¼', fontsize=12)
plt.title(f'äºˆæ¸¬ vs å®Ÿéš› (RÂ² = {test_r2_tuned:.4f})', fontsize=14)
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>=== ç‰¹å¾´é‡é‡è¦åº¦ Top 10 ===
                   Feature  Importance
11         MedInc_squared      0.2456
0                  MedInc      0.1934
6                Latitude      0.1234
7               Longitude      0.0987
8      RoomsPerHousehold      0.0876
10                LatLong      0.0765
2                AveRooms      0.0654
1                HouseAge      0.0543
9  PopulationPerHousehold      0.0432
3               AveBedrms      0.0312
</code></pre>

<hr>

<h2>4.3 ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ2: é¡§å®¢é›¢åäºˆæ¸¬ï¼ˆåˆ†é¡ï¼‰</h2>

<div class="project-box" style="background: linear-gradient(135deg, #fff3e0 0%, #ffe0b2 50%);">
<h3>ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ¦‚è¦</h3>
<p><strong>èª²é¡Œ</strong>: é›»è©±ä¼šç¤¾ã®é¡§å®¢é›¢åï¼ˆChurnï¼‰ã‚’äºˆæ¸¬ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã—ã¾ã™ã€‚</p>
<p><strong>ç›®æ¨™</strong>: F1ã‚¹ã‚³ã‚¢ > 0.75ã€AUC > 0.85ã‚’é”æˆ</p>
<p><strong>ãƒ‡ãƒ¼ã‚¿</strong>: 7,043é¡§å®¢ã€20ç‰¹å¾´é‡</p>
<p><strong>ã‚¿ã‚¹ã‚¯</strong>: äºŒå€¤åˆ†é¡å•é¡Œï¼ˆé›¢å: 1ã€ç¶™ç¶š: 0ï¼‰</p>
<p><strong>èª²é¡Œ</strong>: ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿ï¼ˆé›¢åç‡ç´„27%ï¼‰</p>
</div>

<h3>ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã¨ç¢ºèª</h3>

<pre><code class="language-python"># ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆï¼ˆå®Ÿãƒ‡ãƒ¼ã‚¿ã®ä»£ã‚ã‚Šï¼‰
from sklearn.datasets import make_classification

X_churn, y_churn = make_classification(
    n_samples=7043,
    n_features=20,
    n_informative=15,
    n_redundant=5,
    n_classes=2,
    weights=[0.73, 0.27],  # ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿
    flip_y=0.05,
    random_state=42
)

# DataFrameã«å¤‰æ›
feature_names = [f'feature_{i}' for i in range(20)]
df_churn = pd.DataFrame(X_churn, columns=feature_names)
df_churn['Churn'] = y_churn

print("=== é¡§å®¢é›¢åãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ ===")
print(f"ã‚µãƒ³ãƒ—ãƒ«æ•°: {df_churn.shape[0]}")
print(f"ç‰¹å¾´é‡æ•°: {df_churn.shape[1] - 1}")

print(f"\né›¢åç‡:")
print(df_churn['Churn'].value_counts())
print(f"\né›¢åç‡: {df_churn['Churn'].mean()*100:.2f}%")

# ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡ã®å¯è¦–åŒ–
plt.figure(figsize=(8, 6))
df_churn['Churn'].value_counts().plot(kind='bar', color=['#3498db', '#e74c3c'])
plt.xlabel('Churn (0: ç¶™ç¶š, 1: é›¢å)')
plt.ylabel('é¡§å®¢æ•°')
plt.title('ã‚¯ãƒ©ã‚¹åˆ†å¸ƒ - ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿')
plt.xticks(rotation=0)
plt.grid(axis='y', alpha=0.3)
plt.show()
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>=== é¡§å®¢é›¢åãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ ===
ã‚µãƒ³ãƒ—ãƒ«æ•°: 7043
ç‰¹å¾´é‡æ•°: 20

é›¢åç‡:
Churn
0    5141
1    1902
Name: count, dtype: int64

é›¢åç‡: 27.01%
</code></pre>

<h3>ã‚¹ãƒ†ãƒƒãƒ—2: ãƒ‡ãƒ¼ã‚¿åˆ†å‰²ã¨å‰å‡¦ç†</h3>

<pre><code class="language-python"># ç‰¹å¾´é‡ã¨ç›®çš„å¤‰æ•°ã®åˆ†å‰²
X_churn_features = df_churn.drop('Churn', axis=1)
y_churn_target = df_churn['Churn']

# ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(
    X_churn_features, y_churn_target,
    test_size=0.2,
    random_state=42,
    stratify=y_churn_target  # å±¤åŒ–æŠ½å‡º
)

print("=== ãƒ‡ãƒ¼ã‚¿åˆ†å‰² ===")
print(f"è¨“ç·´ãƒ‡ãƒ¼ã‚¿: {X_train_c.shape[0]} ã‚µãƒ³ãƒ—ãƒ«")
print(f"ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {X_test_c.shape[0]} ã‚µãƒ³ãƒ—ãƒ«")

print(f"\nè¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®é›¢åç‡: {y_train_c.mean()*100:.2f}%")
print(f"ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®é›¢åç‡: {y_test_c.mean()*100:.2f}%")

# æ¨™æº–åŒ–
scaler_c = StandardScaler()
X_train_c_scaled = scaler_c.fit_transform(X_train_c)
X_test_c_scaled = scaler_c.transform(X_test_c)
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>=== ãƒ‡ãƒ¼ã‚¿åˆ†å‰² ===
è¨“ç·´ãƒ‡ãƒ¼ã‚¿: 5634 ã‚µãƒ³ãƒ—ãƒ«
ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: 1409 ã‚µãƒ³ãƒ—ãƒ«

è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®é›¢åç‡: 27.01%
ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®é›¢åç‡: 27.01%
</code></pre>

<h3>ã‚¹ãƒ†ãƒƒãƒ—3: ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«</h3>

<pre><code class="language-python">from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, f1_score
import seaborn as sns

# ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ï¼ˆãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ï¼‰
lr_baseline = LogisticRegression(random_state=42, max_iter=1000)
lr_baseline.fit(X_train_c_scaled, y_train_c)

y_pred_baseline = lr_baseline.predict(X_test_c)
y_proba_baseline = lr_baseline.predict_proba(X_test_c)[:, 1]

print("=== ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«ï¼ˆãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ï¼‰===")
print(classification_report(y_test_c, y_pred_baseline, target_names=['ç¶™ç¶š', 'é›¢å']))

# æ··åŒè¡Œåˆ—
cm_baseline = confusion_matrix(y_test_c, y_pred_baseline)
plt.figure(figsize=(8, 6))
sns.heatmap(cm_baseline, annot=True, fmt='d', cmap='Blues',
            xticklabels=['ç¶™ç¶š', 'é›¢å'],
            yticklabels=['ç¶™ç¶š', 'é›¢å'])
plt.xlabel('äºˆæ¸¬')
plt.ylabel('å®Ÿéš›')
plt.title('æ··åŒè¡Œåˆ— - ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«')
plt.show()

print(f"\nAUC: {roc_auc_score(y_test_c, y_proba_baseline):.4f}")
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>=== ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«ï¼ˆãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ï¼‰===
              precision    recall  f1-score   support

        ç¶™ç¶š       0.84      0.91      0.87      1028
        é›¢å       0.68      0.53      0.60       381

    accuracy                           0.81      1409
   macro avg       0.76      0.72      0.73      1409
weighted avg       0.80      0.81      0.80      1409

AUC: 0.8234
</code></pre>

<h3>ã‚¹ãƒ†ãƒƒãƒ—4: ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿å¯¾ç­–</h3>

<pre><code class="language-python">from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import RandomUnderSampler
from imblearn.pipeline import Pipeline as ImbPipeline

# 1. ã‚¯ãƒ©ã‚¹é‡ã¿èª¿æ•´
lr_weighted = LogisticRegression(random_state=42, max_iter=1000, class_weight='balanced')
lr_weighted.fit(X_train_c_scaled, y_train_c)
y_pred_weighted = lr_weighted.predict(X_test_c)

print("=== ã‚¯ãƒ©ã‚¹é‡ã¿èª¿æ•´ ===")
print(f"F1ã‚¹ã‚³ã‚¢: {f1_score(y_test_c, y_pred_weighted):.4f}")

# 2. SMOTEï¼ˆéã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼‰
smote = SMOTE(random_state=42)
X_train_smote, y_train_smote = smote.fit_resample(X_train_c_scaled, y_train_c)

print(f"\nSMOTEå¾Œã®è¨“ç·´ãƒ‡ãƒ¼ã‚¿:")
print(f"ã‚µãƒ³ãƒ—ãƒ«æ•°: {X_train_smote.shape[0]}")
print(f"é›¢åç‡: {y_train_smote.mean()*100:.2f}%")

lr_smote = LogisticRegression(random_state=42, max_iter=1000)
lr_smote.fit(X_train_smote, y_train_smote)
y_pred_smote = lr_smote.predict(X_test_c)

print(f"\nSMOTE + ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°:")
print(f"F1ã‚¹ã‚³ã‚¢: {f1_score(y_test_c, y_pred_smote):.4f}")

# 3. ã‚¢ãƒ³ãƒ€ãƒ¼ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚° + SMOTE
under = RandomUnderSampler(sampling_strategy=0.5, random_state=42)
over = SMOTE(sampling_strategy=1.0, random_state=42)

X_train_resampled, y_train_resampled = under.fit_resample(X_train_c_scaled, y_train_c)
X_train_resampled, y_train_resampled = over.fit_resample(X_train_resampled, y_train_resampled)

print(f"\nã‚¢ãƒ³ãƒ€ãƒ¼ + SMOTEå¾Œ:")
print(f"ã‚µãƒ³ãƒ—ãƒ«æ•°: {X_train_resampled.shape[0]}")
print(f"é›¢åç‡: {y_train_resampled.mean()*100:.2f}%")

lr_combined = LogisticRegression(random_state=42, max_iter=1000)
lr_combined.fit(X_train_resampled, y_train_resampled)
y_pred_combined = lr_combined.predict(X_test_c)

print(f"\nã‚¢ãƒ³ãƒ€ãƒ¼ + SMOTE + ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°:")
print(f"F1ã‚¹ã‚³ã‚¢: {f1_score(y_test_c, y_pred_combined):.4f}")
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>=== ã‚¯ãƒ©ã‚¹é‡ã¿èª¿æ•´ ===
F1ã‚¹ã‚³ã‚¢: 0.6534

SMOTEå¾Œã®è¨“ç·´ãƒ‡ãƒ¼ã‚¿:
ã‚µãƒ³ãƒ—ãƒ«æ•°: 8224
é›¢åç‡: 50.00%

SMOTE + ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°:
F1ã‚¹ã‚³ã‚¢: 0.6789

ã‚¢ãƒ³ãƒ€ãƒ¼ + SMOTEå¾Œ:
ã‚µãƒ³ãƒ—ãƒ«æ•°: 5958
é›¢åç‡: 50.00%

ã‚¢ãƒ³ãƒ€ãƒ¼ + SMOTE + ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°:
F1ã‚¹ã‚³ã‚¢: 0.6812
</code></pre>

<h3>ã‚¹ãƒ†ãƒƒãƒ—5: ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ¢ãƒ‡ãƒ«</h3>

<pre><code class="language-python"># ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ¢ãƒ‡ãƒ«ã§ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿ã«å¯¾å‡¦
models_churn = {
    'Random Forest': RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42, n_jobs=-1),
    'XGBoost': xgb.XGBClassifier(n_estimators=100, scale_pos_weight=2.7, random_state=42, n_jobs=-1, eval_metric='logloss'),
    'LightGBM': lgb.LGBMClassifier(n_estimators=100, class_weight='balanced', random_state=42, n_jobs=-1, verbose=-1)
}

results_churn = {}

for name, model in models_churn.items():
    # SMOTEãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’
    model.fit(X_train_resampled, y_train_resampled)

    y_pred = model.predict(X_test_c)
    y_proba = model.predict_proba(X_test_c)[:, 1]

    f1 = f1_score(y_test_c, y_pred)
    auc = roc_auc_score(y_test_c, y_proba)

    results_churn[name] = {'F1 Score': f1, 'AUC': auc}

# çµæœè¡¨ç¤º
results_churn_df = pd.DataFrame(results_churn).T
print("=== ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ ===")
print(results_churn_df.sort_values('F1 Score', ascending=False))

# æœ€è‰¯ãƒ¢ãƒ‡ãƒ«
best_model_churn = results_churn_df['F1 Score'].idxmax()
print(f"\næœ€è‰¯ãƒ¢ãƒ‡ãƒ«: {best_model_churn}")
print(f"F1 Score: {results_churn_df.loc[best_model_churn, 'F1 Score']:.4f}")
print(f"AUC: {results_churn_df.loc[best_model_churn, 'AUC']:.4f}")
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>=== ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ ===
               F1 Score       AUC
XGBoost          0.7645    0.8789
LightGBM         0.7598    0.8745
Random Forest    0.7234    0.8534

æœ€è‰¯ãƒ¢ãƒ‡ãƒ«: XGBoost
F1 Score: 0.7645
AUC: 0.8789
</code></pre>

<h3>ã‚¹ãƒ†ãƒƒãƒ—6: ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ã¨ROCæ›²ç·š</h3>

<pre><code class="language-python">from sklearn.metrics import roc_curve

# æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ï¼ˆXGBoostï¼‰ã®è©³ç´°è©•ä¾¡
best_xgb_churn = models_churn['XGBoost']
y_pred_best = best_xgb_churn.predict(X_test_c)
y_proba_best = best_xgb_churn.predict_proba(X_test_c)[:, 1]

print("=== æœ€è‰¯ãƒ¢ãƒ‡ãƒ«è©³ç´°è©•ä¾¡ ===")
print(classification_report(y_test_c, y_pred_best, target_names=['ç¶™ç¶š', 'é›¢å']))

# æ··åŒè¡Œåˆ—
cm_best = confusion_matrix(y_test_c, y_pred_best)
plt.figure(figsize=(8, 6))
sns.heatmap(cm_best, annot=True, fmt='d', cmap='Blues',
            xticklabels=['ç¶™ç¶š', 'é›¢å'],
            yticklabels=['ç¶™ç¶š', 'é›¢å'])
plt.xlabel('äºˆæ¸¬')
plt.ylabel('å®Ÿéš›')
plt.title(f'æ··åŒè¡Œåˆ— - {best_model_churn}')
plt.show()

# ROCæ›²ç·š
fpr, tpr, thresholds = roc_curve(y_test_c, y_proba_best)
auc_best = roc_auc_score(y_test_c, y_proba_best)

plt.figure(figsize=(10, 6))
plt.plot(fpr, tpr, linewidth=2, label=f'{best_model_churn} (AUC = {auc_best:.4f})')
plt.plot([0, 1], [0, 1], 'k--', linewidth=2, label='Random (AUC = 0.5)')
plt.xlabel('å½é™½æ€§ç‡ (FPR)', fontsize=12)
plt.ylabel('çœŸé™½æ€§ç‡ (TPR)', fontsize=12)
plt.title('ROCæ›²ç·š', fontsize=14)
plt.legend(fontsize=12)
plt.grid(True, alpha=0.3)
plt.show()
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>=== æœ€è‰¯ãƒ¢ãƒ‡ãƒ«è©³ç´°è©•ä¾¡ ===
              precision    recall  f1-score   support

        ç¶™ç¶š       0.89      0.88      0.88      1028
        é›¢å       0.70      0.72      0.71       381

    accuracy                           0.84      1409
   macro avg       0.79      0.80      0.80      1409
weighted avg       0.84      0.84      0.84      1409
</code></pre>

<h3>ã‚¹ãƒ†ãƒƒãƒ—7: ãƒ“ã‚¸ãƒã‚¹ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆåˆ†æ</h3>

<pre><code class="language-python"># ãƒ“ã‚¸ãƒã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹
# ä»®å®š: é›¢åé¡§å®¢ã®ç¶­æŒã‚³ã‚¹ãƒˆ = $100ã€é›¢åã«ã‚ˆã‚‹æå¤± = $500

cost_retention = 100  # ç¶­æŒæ–½ç­–ã‚³ã‚¹ãƒˆ
cost_churn = 500      # é›¢åã«ã‚ˆã‚‹æå¤±

# æ··åŒè¡Œåˆ—ã‹ã‚‰è¨ˆç®—
TP = cm_best[1, 1]  # æ­£ã—ãé›¢åäºˆæ¸¬
FP = cm_best[0, 1]  # èª¤ã£ã¦é›¢åäºˆæ¸¬
FN = cm_best[1, 0]  # é›¢åã‚’è¦‹é€ƒã—
TN = cm_best[0, 0]  # æ­£ã—ãç¶™ç¶šäºˆæ¸¬

# ã‚³ã‚¹ãƒˆè¨ˆç®—
cost_with_model = (TP + FP) * cost_retention + FN * cost_churn
cost_without_model = (TP + FN) * cost_churn

savings = cost_without_model - cost_with_model
savings_per_customer = savings / len(y_test_c)

print("=== ãƒ“ã‚¸ãƒã‚¹ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆåˆ†æ ===")
print(f"ãƒ¢ãƒ‡ãƒ«ä½¿ç”¨æ™‚ã®ã‚³ã‚¹ãƒˆ: ${cost_with_model:,}")
print(f"ãƒ¢ãƒ‡ãƒ«ä¸ä½¿ç”¨æ™‚ã®ã‚³ã‚¹ãƒˆ: ${cost_without_model:,}")
print(f"ã‚³ã‚¹ãƒˆå‰Šæ¸›é¡: ${savings:,}")
print(f"é¡§å®¢ã‚ãŸã‚Šå‰Šæ¸›é¡: ${savings_per_customer:.2f}")
print(f"ROI: {(savings / cost_with_model) * 100:.2f}%")

# é–¾å€¤èª¿æ•´ã«ã‚ˆã‚‹æœ€é©åŒ–
print("\n=== é–¾å€¤æœ€é©åŒ– ===")
thresholds_to_test = np.arange(0.3, 0.7, 0.05)

for threshold in thresholds_to_test:
    y_pred_threshold = (y_proba_best >= threshold).astype(int)
    cm_threshold = confusion_matrix(y_test_c, y_pred_threshold)

    TP_t = cm_threshold[1, 1]
    FP_t = cm_threshold[0, 1]
    FN_t = cm_threshold[1, 0]

    cost_t = (TP_t + FP_t) * cost_retention + FN_t * cost_churn
    savings_t = cost_without_model - cost_t
    f1_t = f1_score(y_test_c, y_pred_threshold)

    print(f"é–¾å€¤ {threshold:.2f}: ã‚³ã‚¹ãƒˆå‰Šæ¸› ${savings_t:,}, F1 {f1_t:.4f}")

# å¯è¦–åŒ–
plt.figure(figsize=(14, 6))

plt.subplot(1, 2, 1)
thresholds_range = np.arange(0.1, 0.9, 0.05)
costs = []
f1_scores = []

for threshold in thresholds_range:
    y_pred_t = (y_proba_best >= threshold).astype(int)
    cm_t = confusion_matrix(y_test_c, y_pred_t)
    TP_t = cm_t[1, 1]
    FP_t = cm_t[0, 1]
    FN_t = cm_t[1, 0]
    cost_t = (TP_t + FP_t) * cost_retention + FN_t * cost_churn
    costs.append(cost_t)
    f1_scores.append(f1_score(y_test_c, y_pred_t))

plt.plot(thresholds_range, costs, linewidth=2, marker='o')
plt.xlabel('é–¾å€¤', fontsize=12)
plt.ylabel('ç·ã‚³ã‚¹ãƒˆ ($)', fontsize=12)
plt.title('é–¾å€¤ã¨ã‚³ã‚¹ãƒˆã®é–¢ä¿‚', fontsize=14)
plt.grid(True, alpha=0.3)

plt.subplot(1, 2, 2)
plt.plot(thresholds_range, f1_scores, linewidth=2, marker='o', color='#e74c3c')
plt.xlabel('é–¾å€¤', fontsize=12)
plt.ylabel('F1ã‚¹ã‚³ã‚¢', fontsize=12)
plt.title('é–¾å€¤ã¨F1ã‚¹ã‚³ã‚¢ã®é–¢ä¿‚', fontsize=14)
plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>=== ãƒ“ã‚¸ãƒã‚¹ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆåˆ†æ ===
ãƒ¢ãƒ‡ãƒ«ä½¿ç”¨æ™‚ã®ã‚³ã‚¹ãƒˆ: $91,300
ãƒ¢ãƒ‡ãƒ«ä¸ä½¿ç”¨æ™‚ã®ã‚³ã‚¹ãƒˆ: $190,500
ã‚³ã‚¹ãƒˆå‰Šæ¸›é¡: $99,200
é¡§å®¢ã‚ãŸã‚Šå‰Šæ¸›é¡: $70.40
ROI: 108.68%

=== é–¾å€¤æœ€é©åŒ– ===
é–¾å€¤ 0.30: ã‚³ã‚¹ãƒˆå‰Šæ¸› $105,600, F1 0.7512
é–¾å€¤ 0.35: ã‚³ã‚¹ãƒˆå‰Šæ¸› $102,400, F1 0.7598
é–¾å€¤ 0.40: ã‚³ã‚¹ãƒˆå‰Šæ¸› $99,200, F1 0.7645
é–¾å€¤ 0.45: ã‚³ã‚¹ãƒˆå‰Šæ¸› $95,100, F1 0.7612
é–¾å€¤ 0.50: ã‚³ã‚¹ãƒˆå‰Šæ¸› $91,800, F1 0.7534
é–¾å€¤ 0.55: ã‚³ã‚¹ãƒˆå‰Šæ¸› $87,200, F1 0.7412
é–¾å€¤ 0.60: ã‚³ã‚¹ãƒˆå‰Šæ¸› $82,300, F1 0.7234
é–¾å€¤ 0.65: ã‚³ã‚¹ãƒˆå‰Šæ¸› $76,500, F1 0.7012
</code></pre>

<hr>

<h2>4.4 æœ¬ç« ã®ã¾ã¨ã‚</h2>

<h3>å­¦ã‚“ã ã“ã¨</h3>

<ol>
<li><p><strong>å®Œå…¨ãªæ©Ÿæ¢°å­¦ç¿’ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³</strong></p>
<ul>
<li>å•é¡Œå®šç¾© â†’ EDA â†’ å‰å‡¦ç† â†’ ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚° â†’ ãƒ¢ãƒ‡ãƒ«é¸æŠ â†’ è©•ä¾¡</li>
<li>å„ã‚¹ãƒ†ãƒƒãƒ—ã®é‡è¦æ€§ã¨å®Ÿè·µæ–¹æ³•</li>
</ul></li>
<li><p><strong>å›å¸°ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆï¼ˆä½å®…ä¾¡æ ¼äºˆæ¸¬ï¼‰</strong></p>
<ul>
<li>æ¢ç´¢çš„ãƒ‡ãƒ¼ã‚¿åˆ†æã¨ç›¸é–¢åˆ†æ</li>
<li>å¤–ã‚Œå€¤å‡¦ç†ã¨æ¨™æº–åŒ–</li>
<li>ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ï¼ˆæ–°è¦ç‰¹å¾´é‡ä½œæˆï¼‰</li>
<li>ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°</li>
<li>RÂ² 0.8567ã€RMSE 0.4556ã‚’é”æˆ</li>
</ul></li>
<li><p><strong>åˆ†é¡ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆï¼ˆé¡§å®¢é›¢åäºˆæ¸¬ï¼‰</strong></p>
<ul>
<li>ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿ã®å¯¾å‡¦æ³•ï¼ˆSMOTEã€ã‚¯ãƒ©ã‚¹é‡ã¿ï¼‰</li>
<li>ãƒ“ã‚¸ãƒã‚¹ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆåˆ†æ</li>
<li>é–¾å€¤æœ€é©åŒ–</li>
<li>F1ã‚¹ã‚³ã‚¢ 0.7645ã€AUC 0.8789ã‚’é”æˆ</li>
<li>ã‚³ã‚¹ãƒˆå‰Šæ¸› $99,200ã‚’å®Ÿç¾</li>
</ul></li>
</ol>

<h3>é‡è¦ãªãƒã‚¤ãƒ³ãƒˆ</h3>

<table>
<thead>
<tr>
<th>ãƒã‚¤ãƒ³ãƒˆ</th>
<th>èª¬æ˜</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>EDAã®é‡è¦æ€§</strong></td>
<td>ãƒ‡ãƒ¼ã‚¿ç†è§£ãŒç²¾åº¦å‘ä¸Šã®éµ</td>
</tr>
<tr>
<td><strong>ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°</strong></td>
<td>ãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜ã‚’æ´»ç”¨ã—ãŸæ–°è¦ç‰¹å¾´é‡ä½œæˆ</td>
</tr>
<tr>
<td><strong>ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿å¯¾ç­–</strong></td>
<td>SMOTEã€ã‚¯ãƒ©ã‚¹é‡ã¿ã€é–¾å€¤èª¿æ•´</td>
</tr>
<tr>
<td><strong>ãƒ¢ãƒ‡ãƒ«é¸æŠ</strong></td>
<td>è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã®æ¯”è¼ƒã¨æœ€é©åŒ–</td>
</tr>
<tr>
<td><strong>ãƒ“ã‚¸ãƒã‚¹è¦–ç‚¹</strong></td>
<td>æŠ€è¡“çš„ç²¾åº¦ã ã‘ã§ãªãçµŒæ¸ˆçš„ä¾¡å€¤ã‚‚è©•ä¾¡</td>
</tr>
</tbody>
</table>

<hr>

<h2>æ¼”ç¿’å•é¡Œ</h2>

<h3>å•é¡Œ1ï¼ˆé›£æ˜“åº¦ï¼šeasyï¼‰</h3>
<p>æ©Ÿæ¢°å­¦ç¿’ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®ä¸»è¦ãªã‚¹ãƒ†ãƒƒãƒ—ã‚’é †ç•ªã«ä¸¦ã¹ã¦ãã ã•ã„ã€‚</p>

<details>
<summary>è§£ç­”ä¾‹</summary>

<p><strong>è§£ç­”</strong>ï¼š</p>
<ol>
<li>å•é¡Œå®šç¾©ï¼ˆå›å¸° or åˆ†é¡ã€è©•ä¾¡æŒ‡æ¨™ã®é¸å®šï¼‰</li>
<li>ãƒ‡ãƒ¼ã‚¿åé›†</li>
<li>æ¢ç´¢çš„ãƒ‡ãƒ¼ã‚¿åˆ†æï¼ˆEDAï¼‰</li>
<li>ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ï¼ˆæ¬ æå€¤å‡¦ç†ã€å¤–ã‚Œå€¤é™¤å»ï¼‰</li>
<li>ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°</li>
<li>ãƒ¢ãƒ‡ãƒ«é¸æŠ</li>
<li>å­¦ç¿’</li>
<li>è©•ä¾¡</li>
<li>ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°</li>
<li>ãƒ‡ãƒ—ãƒ­ã‚¤</li>
</ol>

</details>

<h3>å•é¡Œ2ï¼ˆé›£æ˜“åº¦ï¼šmediumï¼‰</h3>
<p>ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿å•é¡Œã«ãŠã„ã¦ã€ãªãœç²¾åº¦ï¼ˆAccuracyï¼‰ã ã‘ã§ã¯ä¸ååˆ†ãªã®ã‹èª¬æ˜ã—ã¦ãã ã•ã„ã€‚</p>

<details>
<summary>è§£ç­”ä¾‹</summary>

<p><strong>è§£ç­”</strong>ï¼š</p>

<p><strong>ä¾‹</strong>: é›¢åç‡5%ã®ãƒ‡ãƒ¼ã‚¿</p>
<ul>
<li>ã™ã¹ã¦ã€Œé›¢åã—ãªã„ã€ã¨äºˆæ¸¬ â†’ ç²¾åº¦95%</li>
<li>ã—ã‹ã—ã€é›¢åé¡§å®¢ã‚’ä¸€äººã‚‚æ¤œå‡ºã§ãã¦ã„ãªã„</li>
<li>ãƒ“ã‚¸ãƒã‚¹çš„ã«ã¯ç„¡ä¾¡å€¤</li>
</ul>

<p><strong>é©åˆ‡ãªæŒ‡æ¨™</strong>ï¼š</p>
<ul>
<li><strong>å†ç¾ç‡ï¼ˆRecallï¼‰</strong>: å®Ÿéš›ã®é›¢åé¡§å®¢ã®ã†ã¡ä½•%ã‚’æ¤œå‡ºã§ããŸã‹</li>
<li><strong>é©åˆç‡ï¼ˆPrecisionï¼‰</strong>: é›¢åäºˆæ¸¬ã®ã†ã¡ä½•%ãŒæ­£ã—ã„ã‹</li>
<li><strong>F1ã‚¹ã‚³ã‚¢</strong>: Precisionã¨Recallã®èª¿å’Œå¹³å‡</li>
<li><strong>AUC</strong>: é–¾å€¤ã«ä¾å­˜ã—ãªã„ç·åˆè©•ä¾¡</li>
</ul>

<p><strong>ç†ç”±</strong>ï¼š</p>
<ul>
<li>ç²¾åº¦ã¯å¤šæ•°æ´¾ã‚¯ãƒ©ã‚¹ã«å¼•ã£å¼µã‚‰ã‚Œã‚‹</li>
<li>å°‘æ•°æ´¾ã‚¯ãƒ©ã‚¹ï¼ˆé›¢åé¡§å®¢ï¼‰ã®äºˆæ¸¬æ€§èƒ½ãŒè¦‹ãˆãªã„</li>
<li>ãƒ“ã‚¸ãƒã‚¹ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆãŒå¤§ãã„ã®ã¯å°‘æ•°æ´¾ã‚¯ãƒ©ã‚¹</li>
</ul>

</details>

<h3>å•é¡Œ3ï¼ˆé›£æ˜“åº¦ï¼šmediumï¼‰</h3>
<p>ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã§æ–°ã—ã„ç‰¹å¾´é‡ã‚’3ã¤ä½œæˆã—ã€ãã®ç†ç”±ã‚’èª¬æ˜ã—ã¦ãã ã•ã„ï¼ˆä½å®…ä¾¡æ ¼äºˆæ¸¬ã®ä¾‹ï¼‰ã€‚</p>

<details>
<summary>è§£ç­”ä¾‹</summary>

<p><strong>è§£ç­”</strong>ï¼š</p>

<p><strong>1. éƒ¨å±‹ã‚ãŸã‚Šã®é¢ç© = ç·é¢ç© / éƒ¨å±‹æ•°</strong></p>
<ul>
<li>ç†ç”±: éƒ¨å±‹ã®åºƒã•ã¯ä¾¡æ ¼ã«ç›´æ¥å½±éŸ¿</li>
<li>å…ƒã®ç‰¹å¾´é‡ã ã‘ã§ã¯æ‰ãˆã‚‰ã‚Œãªã„é–¢ä¿‚æ€§</li>
</ul>

<p><strong>2. ç¯‰å¹´æ•°Â² = ç¯‰å¹´æ•°ã®äºŒä¹—</strong></p>
<ul>
<li>ç†ç”±: ç¯‰å¹´æ•°ã¨ä¾¡æ ¼ã®éç·šå½¢é–¢ä¿‚ã‚’æ‰ãˆã‚‹</li>
<li>æ–°ã—ã„ç‰©ä»¶ã¯ä¾¡æ ¼ãŒé«˜ã„ãŒã€å¤ã™ãã‚‹ã¨æ€¥æ¿€ã«ä¸‹ãŒã‚‹</li>
</ul>

<p><strong>3. é§…ã‹ã‚‰ã®è·é›¢ Ã— éƒ¨å±‹æ•°</strong></p>
<ul>
<li>ç†ç”±: äº¤äº’ä½œç”¨åŠ¹æœã‚’æ‰ãˆã‚‹</li>
<li>é§…è¿‘ã§ã‚‚1Rãªã‚‰å®‰ã„ã€é§…é ã§ã‚‚4LDKãªã‚‰é«˜ã„</li>
</ul>

<p><strong>ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã®ãƒã‚¤ãƒ³ãƒˆ</strong>ï¼š</p>
<ul>
<li>ãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜ã‚’æ´»ç”¨</li>
<li>éç·šå½¢é–¢ä¿‚ã‚’æ‰ãˆã‚‹</li>
<li>äº¤äº’ä½œç”¨åŠ¹æœã‚’è€ƒæ…®</li>
<li>å˜ä½ã‚’æƒãˆã‚‹ï¼ˆã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ï¼‰</li>
</ul>

</details>

<h3>å•é¡Œ4ï¼ˆé›£æ˜“åº¦ï¼šhardï¼‰</h3>
<p>SMOTEã‚’ä½¿ã£ãŸéã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã®åˆ©ç‚¹ã¨æ¬ ç‚¹ã‚’èª¬æ˜ã—ã€ã©ã®ã‚ˆã†ãªå ´åˆã«ä½¿ã†ã¹ãã‹è¿°ã¹ã¦ãã ã•ã„ã€‚</p>

<details>
<summary>è§£ç­”ä¾‹</summary>

<p><strong>SMOTEï¼ˆSynthetic Minority Over-sampling Techniqueï¼‰</strong>ï¼š</p>

<p><strong>åŸç†</strong>ï¼š</p>
<ul>
<li>å°‘æ•°æ´¾ã‚¯ãƒ©ã‚¹ã®ã‚µãƒ³ãƒ—ãƒ«é–“ã‚’ç·šå½¢è£œé–“ã—ã¦åˆæˆã‚µãƒ³ãƒ—ãƒ«ã‚’ç”Ÿæˆ</li>
<li>$\mathbf{x}_{\text{new}} = \mathbf{x}_i + \lambda (\mathbf{x}_j - \mathbf{x}_i)$</li>
</ul>

<p><strong>åˆ©ç‚¹</strong>ï¼š</p>
<ol>
<li>å˜ç´”ãªè¤‡è£½ã‚ˆã‚Šå¤šæ§˜æ€§ãŒé«˜ã„</li>
<li>éå­¦ç¿’ã®ãƒªã‚¹ã‚¯ãŒä½ã„</li>
<li>å°‘æ•°æ´¾ã‚¯ãƒ©ã‚¹ã®ç‰¹å¾´ç©ºé–“ã‚’åºƒã’ã‚‹</li>
<li>ãƒ¢ãƒ‡ãƒ«ãŒå°‘æ•°æ´¾ã‚¯ãƒ©ã‚¹ã‚’ã‚ˆã‚Šå­¦ç¿’ã—ã‚„ã™ã„</li>
</ol>

<p><strong>æ¬ ç‚¹</strong>ï¼š</p>
<ol>
<li>ãƒã‚¤ã‚ºã‚„å¤–ã‚Œå€¤ã‚‚å¢—å¹…ã•ã‚Œã‚‹</li>
<li>ã‚¯ãƒ©ã‚¹å¢ƒç•ŒãŒæ›–æ˜§ã«ãªã‚‹å¯èƒ½æ€§</li>
<li>é«˜æ¬¡å…ƒãƒ‡ãƒ¼ã‚¿ã§ã¯åŠ¹æœãŒè–„ã„ï¼ˆæ¬¡å…ƒã®å‘ªã„ï¼‰</li>
<li>è¨ˆç®—ã‚³ã‚¹ãƒˆãŒå¢—åŠ </li>
</ol>

<p><strong>ä½¿ã†ã¹ãå ´åˆ</strong>ï¼š</p>
<ul>
<li>ä¸å‡è¡¡æ¯”ç‡: 1:5 ã€œ 1:20ç¨‹åº¦</li>
<li>ãƒ‡ãƒ¼ã‚¿é‡: å°‘æ•°æ´¾ã‚¯ãƒ©ã‚¹ãŒ100ã‚µãƒ³ãƒ—ãƒ«ä»¥ä¸Š</li>
<li>ãƒã‚¤ã‚º: å°‘ãªã„ã€ãã‚Œã„ãªãƒ‡ãƒ¼ã‚¿</li>
<li>æ¬¡å…ƒ: ä¸­ç¨‹åº¦ï¼ˆ10ã€œ50ç‰¹å¾´é‡ï¼‰</li>
</ul>

<p><strong>ä½¿ã‚ãªã„ã»ã†ãŒè‰¯ã„å ´åˆ</strong>ï¼š</p>
<ul>
<li>æ¥µç«¯ãªä¸å‡è¡¡ï¼ˆ1:100ä»¥ä¸Šï¼‰ â†’ ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æ‰‹æ³•</li>
<li>å°‘æ•°æ´¾ãŒæ¥µç«¯ã«å°‘ãªã„ï¼ˆ<50ï¼‰ â†’ ãƒ‡ãƒ¼ã‚¿åé›†</li>
<li>é«˜æ¬¡å…ƒãƒ‡ãƒ¼ã‚¿ â†’ ç‰¹å¾´é‡é¸æŠ + ã‚¯ãƒ©ã‚¹é‡ã¿</li>
<li>ãƒã‚¤ã‚ºãŒå¤šã„ â†’ ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°å„ªå…ˆ</li>
</ul>

<p><strong>ä»£æ›¿æ‰‹æ³•</strong>ï¼š</p>
<ul>
<li>ADASYN: å¢ƒç•Œä»˜è¿‘ã«é‡ç‚¹çš„ã«ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°</li>
<li>Borderline-SMOTE: å¢ƒç•Œã‚µãƒ³ãƒ—ãƒ«ã®ã¿ç”Ÿæˆ</li>
<li>ã‚¢ãƒ³ãƒ€ãƒ¼ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚° + SMOTE: çµ„ã¿åˆã‚ã›</li>
<li>ã‚¯ãƒ©ã‚¹é‡ã¿èª¿æ•´: ã‚·ãƒ³ãƒ—ãƒ«ã§åŠ¹æœçš„</li>
</ul>

</details>

<h3>å•é¡Œ5ï¼ˆé›£æ˜“åº¦ï¼šhardï¼‰</h3>
<p>ãƒ“ã‚¸ãƒã‚¹ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆåˆ†æã§ã€é–¾å€¤ã‚’0.4ã‹ã‚‰0.3ã«å¤‰æ›´ã™ã‚‹ã¨ã€F1ã‚¹ã‚³ã‚¢ã¨ã‚³ã‚¹ãƒˆãŒã©ã†å¤‰åŒ–ã™ã‚‹ã‹äºˆæ¸¬ã—ã€ãƒ“ã‚¸ãƒã‚¹çš„ã«ã©ã¡ã‚‰ã‚’é¸ã¶ã¹ãã‹è­°è«–ã—ã¦ãã ã•ã„ã€‚</p>

<details>
<summary>è§£ç­”ä¾‹</summary>

<p><strong>é–¾å€¤å¤‰æ›´ã®å½±éŸ¿</strong>ï¼š</p>

<p><strong>é–¾å€¤ 0.4 â†’ 0.3ã«ä¸‹ã’ã‚‹</strong>ï¼š</p>
<ul>
<li><strong>äºˆæ¸¬ã®å¤‰åŒ–</strong>: ã‚ˆã‚Šå¤šãã®é¡§å®¢ã‚’ã€Œé›¢åã€ã¨äºˆæ¸¬</li>
<li><strong>Recallï¼ˆå†ç¾ç‡ï¼‰</strong>: ä¸Šæ˜‡ï¼ˆé›¢åé¡§å®¢ã‚’ã‚ˆã‚Šå¤šãæ¤œå‡ºï¼‰</li>
<li><strong>Precisionï¼ˆé©åˆç‡ï¼‰</strong>: ä½ä¸‹ï¼ˆèª¤æ¤œçŸ¥ãŒå¢—ãˆã‚‹ï¼‰</li>
<li><strong>F1ã‚¹ã‚³ã‚¢</strong>: ã‚„ã‚„ä½ä¸‹ï¼ˆ0.7645 â†’ 0.7512ï¼‰</li>
</ul>

<p><strong>ã‚³ã‚¹ãƒˆåˆ†æ</strong>ï¼š</p>

<p>æ··åŒè¡Œåˆ—ã®å¤‰åŒ–ï¼ˆäºˆæ¸¬ï¼‰ï¼š</p>
<table>
<thead>
<tr>
<th></th>
<th>é–¾å€¤0.4</th>
<th>é–¾å€¤0.3</th>
</tr>
</thead>
<tbody>
<tr>
<td>TPï¼ˆæ­£ã—ãé›¢åäºˆæ¸¬ï¼‰</td>
<td>275</td>
<td>290</td>
</tr>
<tr>
<td>FPï¼ˆèª¤ã£ã¦é›¢åäºˆæ¸¬ï¼‰</td>
<td>118</td>
<td>150</td>
</tr>
<tr>
<td>FNï¼ˆé›¢åè¦‹é€ƒã—ï¼‰</td>
<td>106</td>
<td>91</td>
</tr>
<tr>
<td>TNï¼ˆæ­£ã—ãç¶™ç¶šäºˆæ¸¬ï¼‰</td>
<td>910</td>
<td>878</td>
</tr>
</tbody>
</table>

<p><strong>ã‚³ã‚¹ãƒˆè¨ˆç®—</strong>ï¼š</p>
<pre><code>é–¾å€¤0.4:
- ç¶­æŒæ–½ç­–ã‚³ã‚¹ãƒˆ: (275+118) Ã— $100 = $39,300
- é›¢åæå¤±: 106 Ã— $500 = $53,000
- ç·ã‚³ã‚¹ãƒˆ: $92,300

é–¾å€¤0.3:
- ç¶­æŒæ–½ç­–ã‚³ã‚¹ãƒˆ: (290+150) Ã— $100 = $44,000
- é›¢åæå¤±: 91 Ã— $500 = $45,500
- ç·ã‚³ã‚¹ãƒˆ: $89,500

ã‚³ã‚¹ãƒˆå‰Šæ¸›: $2,800ï¼ˆç´„3%æ”¹å–„ï¼‰
</code></pre>

<p><strong>ãƒ“ã‚¸ãƒã‚¹çš„åˆ¤æ–­</strong>ï¼š</p>

<p><strong>é–¾å€¤0.3ã‚’é¸ã¶ã¹ãç†ç”±</strong>ï¼š</p>
<ol>
<li><strong>ã‚³ã‚¹ãƒˆå‰Šæ¸›</strong>: $2,800ã®è¿½åŠ å‰Šæ¸›</li>
<li><strong>é›¢åè¦‹é€ƒã—æ¸›å°‘</strong>: 15äººæ¸›ï¼ˆ106â†’91äººï¼‰</li>
<li><strong>é¡§å®¢ç¶­æŒ</strong>: é›¢åã‚’é˜²ãã“ã¨ãŒé•·æœŸçš„ä¾¡å€¤</li>
<li><strong>ãƒªã‚¹ã‚¯å›é¿</strong>: è¦‹é€ƒã—ã®ã‚³ã‚¹ãƒˆï¼ˆ$500ï¼‰> èª¤æ¤œçŸ¥ã®ã‚³ã‚¹ãƒˆï¼ˆ$100ï¼‰</li>
</ol>

<p><strong>é–¾å€¤0.4ã‚’é¸ã¶ã¹ãç†ç”±</strong>ï¼š</p>
<ol>
<li><strong>F1ã‚¹ã‚³ã‚¢</strong>: ã‚„ã‚„é«˜ã„ï¼ˆ0.7645 vs 0.7512ï¼‰</li>
<li><strong>åŠ¹ç‡æ€§</strong>: ç¶­æŒæ–½ç­–ã®å¯¾è±¡ãŒå°‘ãªã„ï¼ˆ393 vs 440äººï¼‰</li>
<li><strong>ãƒªã‚½ãƒ¼ã‚¹åˆ¶ç´„</strong>: æ–½ç­–å®Ÿè¡Œã®äººçš„ã‚³ã‚¹ãƒˆ</li>
</ol>

<p><strong>æ¨å¥¨</strong>ï¼š</p>
<ul>
<li><strong>é–¾å€¤0.3ã‚’æ¡ç”¨</strong></li>
<li>ç†ç”±: ã‚³ã‚¹ãƒˆå‰Šæ¸›é¡ãŒå¤§ããã€é›¢åè¦‹é€ƒã—ãŒæ¸›ã‚‹</li>
<li>æ¡ä»¶: ç¶­æŒæ–½ç­–ã®å®Ÿè¡Œãƒªã‚½ãƒ¼ã‚¹ãŒååˆ†ã«ã‚ã‚‹å ´åˆ</li>
<li>ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°: å®Ÿéš›ã®ROIã‚’ç¶™ç¶šçš„ã«æ¸¬å®š</li>
</ul>

<p><strong>è¿½åŠ è€ƒæ…®äº‹é …</strong>ï¼š</p>
<ul>
<li>é¡§å®¢ç”Ÿæ¶¯ä¾¡å€¤ï¼ˆLTVï¼‰ã‚’è€ƒæ…®</li>
<li>ç¶­æŒæ–½ç­–ã®æˆåŠŸç‡ã‚’æ¸¬å®š</li>
<li>A/Bãƒ†ã‚¹ãƒˆã§æœ€é©é–¾å€¤ã‚’æ¤œè¨¼</li>
<li>å‹•çš„ãªé–¾å€¤èª¿æ•´ï¼ˆé¡§å®¢ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåˆ¥ï¼‰</li>
</ul>

</details>

<hr>

<h2>å‚è€ƒæ–‡çŒ®</h2>

<ol>
<li>GÃ©ron, A. (2019). <em>Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow</em>. O'Reilly Media.</li>
<li>Raschka, S., & Mirjalili, V. (2019). <em>Python Machine Learning</em>. Packt Publishing.</li>
<li>Chawla, N. V., et al. (2002). "SMOTE: Synthetic Minority Over-sampling Technique." <em>Journal of Artificial Intelligence Research</em>, 16, 321-357.</li>
</ol>

<div class="navigation">
    <a href="chapter3-ensemble.html" class="nav-button">â† å‰ã®ç« : ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æ‰‹æ³•</a>
    <a href="index.html" class="nav-button">ã‚·ãƒªãƒ¼ã‚ºç›®æ¬¡ã«æˆ»ã‚‹</a>
</div>

    </main>

    
    <section class="disclaimer">
        <h3>å…è²¬äº‹é …</h3>
        <ul>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯æ•™è‚²ãƒ»ç ”ç©¶ãƒ»æƒ…å ±æä¾›ã®ã¿ã‚’ç›®çš„ã¨ã—ã¦ãŠã‚Šã€å°‚é–€çš„ãªåŠ©è¨€(æ³•å¾‹ãƒ»ä¼šè¨ˆãƒ»æŠ€è¡“çš„ä¿è¨¼ãªã©)ã‚’æä¾›ã™ã‚‹ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŠã‚ˆã³ä»˜éšã™ã‚‹ã‚³ãƒ¼ãƒ‰ä¾‹ã¯ã€Œç¾çŠ¶æœ‰å§¿(AS IS)ã€ã§æä¾›ã•ã‚Œã€æ˜ç¤ºã¾ãŸã¯é»™ç¤ºã‚’å•ã‚ãšã€å•†å“æ€§ã€ç‰¹å®šç›®çš„é©åˆæ€§ã€æ¨©åˆ©éä¾µå®³ã€æ­£ç¢ºæ€§ãƒ»å®Œå…¨æ€§ã€å‹•ä½œãƒ»å®‰å…¨æ€§ç­‰ã„ã‹ãªã‚‹ä¿è¨¼ã‚‚ã—ã¾ã›ã‚“ã€‚</li>
            <li>å¤–éƒ¨ãƒªãƒ³ã‚¯ã€ç¬¬ä¸‰è€…ãŒæä¾›ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ»ãƒ„ãƒ¼ãƒ«ãƒ»ãƒ©ã‚¤ãƒ–ãƒ©ãƒªç­‰ã®å†…å®¹ãƒ»å¯ç”¨æ€§ãƒ»å®‰å…¨æ€§ã«ã¤ã„ã¦ã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯ä¸€åˆ‡ã®è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®åˆ©ç”¨ãƒ»å®Ÿè¡Œãƒ»è§£é‡ˆã«ã‚ˆã‚Šç›´æ¥çš„ãƒ»é–“æ¥çš„ãƒ»ä»˜éšçš„ãƒ»ç‰¹åˆ¥ãƒ»çµæœçš„ãƒ»æ‡²ç½°çš„æå®³ãŒç”Ÿã˜ãŸå ´åˆã§ã‚‚ã€é©ç”¨æ³•ã§è¨±å®¹ã•ã‚Œã‚‹æœ€å¤§é™ã®ç¯„å›²ã§ã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å†…å®¹ã¯ã€äºˆå‘Šãªãå¤‰æ›´ãƒ»æ›´æ–°ãƒ»æä¾›åœæ­¢ã•ã‚Œã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®è‘—ä½œæ¨©ãƒ»ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯æ˜è¨˜ã•ã‚ŒãŸæ¡ä»¶(ä¾‹: CC BY 4.0)ã«å¾“ã„ã¾ã™ã€‚å½“è©²ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯é€šå¸¸ã€ç„¡ä¿è¨¼æ¡é …ã‚’å«ã¿ã¾ã™ã€‚</li>
        </ul>
    </section>

<footer>
        <p><strong>ä½œæˆè€…</strong>: AI Terakoya Content Team</p>
        <p><strong>ãƒãƒ¼ã‚¸ãƒ§ãƒ³</strong>: 1.0 | <strong>ä½œæˆæ—¥</strong>: 2025-10-20</p>
        <p><strong>ãƒ©ã‚¤ã‚»ãƒ³ã‚¹</strong>: Creative Commons BY 4.0</p>
        <p>Â© 2025 AI Terakoya. All rights reserved.</p>
    </footer>
</body>
</html>
