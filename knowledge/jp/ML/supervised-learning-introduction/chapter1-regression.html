<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ç¬¬1ç« ï¼šå›å¸°å•é¡Œã®åŸºç¤ - AI Terakoya</title>

    <style>
        :root {
            --color-primary: #2c3e50;
            --color-primary-dark: #1a252f;
            --color-accent: #7b2cbf;
            --color-accent-light: #9d4edd;
            --color-text: #2d3748;
            --color-text-light: #4a5568;
            --color-bg: #ffffff;
            --color-bg-alt: #f7fafc;
            --color-border: #e2e8f0;
            --color-code-bg: #f8f9fa;
            --color-link: #3182ce;
            --color-link-hover: #2c5aa0;

            --spacing-xs: 0.5rem;
            --spacing-sm: 1rem;
            --spacing-md: 1.5rem;
            --spacing-lg: 2rem;
            --spacing-xl: 3rem;

            --font-body: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            --font-mono: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;

            --border-radius: 8px;
            --box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: var(--font-body);
            line-height: 1.7;
            color: var(--color-text);
            background-color: var(--color-bg);
            font-size: 16px;
        }

        header {
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            padding: var(--spacing-xl) var(--spacing-md);
            margin-bottom: var(--spacing-xl);
            box-shadow: var(--box-shadow);
        }

        .header-content {
            max-width: 900px;
            margin: 0 auto;
        }

        h1 {
            font-size: 2rem;
            font-weight: 700;
            margin-bottom: var(--spacing-sm);
            line-height: 1.2;
        }

        .subtitle {
            font-size: 1.1rem;
            opacity: 0.95;
            font-weight: 400;
            margin-bottom: var(--spacing-md);
        }

        .meta {
            display: flex;
            flex-wrap: wrap;
            gap: var(--spacing-md);
            font-size: 0.9rem;
            opacity: 0.9;
        }

        .meta-item {
            display: flex;
            align-items: center;
            gap: 0.3rem;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 0 var(--spacing-md) var(--spacing-xl);
        }

        h2 {
            font-size: 1.75rem;
            color: var(--color-primary);
            margin-top: var(--spacing-xl);
            margin-bottom: var(--spacing-md);
            padding-bottom: var(--spacing-xs);
            border-bottom: 3px solid var(--color-accent);
        }

        h3 {
            font-size: 1.4rem;
            color: var(--color-primary);
            margin-top: var(--spacing-lg);
            margin-bottom: var(--spacing-sm);
        }

        h4 {
            font-size: 1.1rem;
            color: var(--color-primary-dark);
            margin-top: var(--spacing-md);
            margin-bottom: var(--spacing-sm);
        }

        p {
            margin-bottom: var(--spacing-md);
            color: var(--color-text);
        }

        a {
            color: var(--color-link);
            text-decoration: none;
            transition: color 0.2s;
        }

        a:hover {
            color: var(--color-link-hover);
            text-decoration: underline;
        }

        ul, ol {
            margin-left: var(--spacing-lg);
            margin-bottom: var(--spacing-md);
        }

        li {
            margin-bottom: var(--spacing-xs);
            color: var(--color-text);
        }

        pre {
            background-color: var(--color-code-bg);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            overflow-x: auto;
            margin-bottom: var(--spacing-md);
            font-family: var(--font-mono);
            font-size: 0.9rem;
            line-height: 1.5;
        }

        code {
            font-family: var(--font-mono);
            font-size: 0.9em;
            background-color: var(--color-code-bg);
            padding: 0.2em 0.4em;
            border-radius: 3px;
        }

        pre code {
            background-color: transparent;
            padding: 0;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: var(--spacing-md);
            font-size: 0.95rem;
        }

        th, td {
            border: 1px solid var(--color-border);
            padding: var(--spacing-sm);
            text-align: left;
        }

        th {
            background-color: var(--color-bg-alt);
            font-weight: 600;
            color: var(--color-primary);
        }

        blockquote {
            border-left: 4px solid var(--color-accent);
            padding-left: var(--spacing-md);
            margin: var(--spacing-md) 0;
            color: var(--color-text-light);
            font-style: italic;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        .mermaid {
            text-align: center;
            margin: var(--spacing-lg) 0;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        details {
            background-color: var(--color-bg-alt);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            margin-bottom: var(--spacing-md);
        }

        summary {
            cursor: pointer;
            font-weight: 600;
            color: var(--color-primary);
            user-select: none;
            padding: var(--spacing-xs);
            margin: calc(-1 * var(--spacing-md));
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        summary:hover {
            background-color: rgba(123, 44, 191, 0.1);
        }

        details[open] summary {
            margin-bottom: var(--spacing-md);
            border-bottom: 1px solid var(--color-border);
        }

        .navigation {
            display: flex;
            justify-content: space-between;
            gap: var(--spacing-md);
            margin: var(--spacing-xl) 0;
            padding-top: var(--spacing-lg);
            border-top: 2px solid var(--color-border);
        }

        .nav-button {
            flex: 1;
            padding: var(--spacing-md);
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            border-radius: var(--border-radius);
            text-align: center;
            font-weight: 600;
            transition: transform 0.2s, box-shadow 0.2s;
            box-shadow: var(--box-shadow);
        }

        .nav-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
            text-decoration: none;
        }

        footer {
            margin-top: var(--spacing-xl);
            padding: var(--spacing-lg) var(--spacing-md);
            background-color: var(--color-bg-alt);
            border-top: 1px solid var(--color-border);
            text-align: center;
            font-size: 0.9rem;
            color: var(--color-text-light);
        }

        @media (max-width: 768px) {
            h1 {
                font-size: 1.5rem;
            }

            h2 {
                font-size: 1.4rem;
            }

            h3 {
                font-size: 1.2rem;
            }

            .meta {
                font-size: 0.85rem;
            }

            .navigation {
                flex-direction: column;
            }

            table {
                font-size: 0.85rem;
            }

            th, td {
                padding: var(--spacing-xs);
            }
        }
    </style>

    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
        mermaid.initialize({ startOnLoad: true, theme: 'default' });
    </script>

    <!-- MathJax for LaTeX equation rendering -->
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                displayMath: [['$$', '$$'], ['\\[', '\\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
                ignoreHtmlClass: 'mermaid'
            }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" async></script>
</head>
<body>
    <header>
        <div class="header-content">
            <h1>ç¬¬1ç« ï¼šå›å¸°å•é¡Œã®åŸºç¤</h1>
            <p class="subtitle">é€£ç¶šå€¤äºˆæ¸¬ã®ç†è«–ã¨å®Ÿè£… - ç·šå½¢å›å¸°ã‹ã‚‰æ­£å‰‡åŒ–ã¾ã§</p>
            <div class="meta">
                <span class="meta-item">ğŸ“– èª­äº†æ™‚é–“: 20-25åˆ†</span>
                <span class="meta-item">ğŸ“Š é›£æ˜“åº¦: åˆç´š</span>
                <span class="meta-item">ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹: 12å€‹</span>
                <span class="meta-item">ğŸ“ æ¼”ç¿’å•é¡Œ: 5å•</span>
            </div>
        </div>
    </header>

    <main class="container">

<h2>å­¦ç¿’ç›®æ¨™</h2>
<p>ã“ã®ç« ã‚’èª­ã‚€ã“ã¨ã§ã€ä»¥ä¸‹ã‚’ç¿’å¾—ã§ãã¾ã™ï¼š</p>
<ul>
<li>âœ… å›å¸°å•é¡Œã®å®šç¾©ã¨å¿œç”¨ä¾‹ã‚’ç†è§£ã™ã‚‹</li>
<li>âœ… ç·šå½¢å›å¸°ã®æ•°å­¦çš„èƒŒæ™¯ã‚’èª¬æ˜ã§ãã‚‹</li>
<li>âœ… æœ€å°äºŒä¹—æ³•ã¨å‹¾é…é™ä¸‹æ³•ã‚’å®Ÿè£…ã§ãã‚‹</li>
<li>âœ… å¤šé …å¼å›å¸°ã§éç·šå½¢é–¢ä¿‚ã‚’ãƒ¢ãƒ‡ãƒ«åŒ–ã§ãã‚‹</li>
<li>âœ… æ­£å‰‡åŒ–ï¼ˆRidge, Lasso, Elastic Netï¼‰ã‚’é©ç”¨ã§ãã‚‹</li>
<li>âœ… RÂ²ã€RMSEã€MAEã§å›å¸°ãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡ã§ãã‚‹</li>
</ul>

<hr>

<h2>1.1 å›å¸°å•é¡Œã¨ã¯</h2>

<h3>å®šç¾©</h3>
<p><strong>å›å¸°å•é¡Œï¼ˆRegressionï¼‰</strong>ã¯ã€å…¥åŠ›å¤‰æ•°ã‹ã‚‰<strong>é€£ç¶šå€¤</strong>ã®å‡ºåŠ›ã‚’äºˆæ¸¬ã™ã‚‹æ•™å¸«ã‚ã‚Šå­¦ç¿’ã®ã‚¿ã‚¹ã‚¯ã§ã™ã€‚</p>

<blockquote>
<p>ã€Œç‰¹å¾´é‡ $X$ ã‹ã‚‰ç›®çš„å¤‰æ•° $y$ ã‚’äºˆæ¸¬ã™ã‚‹é–¢æ•° $f: X \rightarrow y$ ã‚’å­¦ç¿’ã™ã‚‹ã€</p>
</blockquote>

<h3>å›å¸° vs åˆ†é¡</h3>

<table>
<thead>
<tr>
<th>ã‚¿ã‚¹ã‚¯</th>
<th>å‡ºåŠ›</th>
<th>ä¾‹</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>å›å¸°</strong></td>
<td>é€£ç¶šå€¤ï¼ˆæ•°å€¤ï¼‰</td>
<td>ä½å®…ä¾¡æ ¼äºˆæ¸¬ã€æ°—æ¸©äºˆæ¸¬ã€å£²ä¸Šäºˆæ¸¬</td>
</tr>
<tr>
<td><strong>åˆ†é¡</strong></td>
<td>é›¢æ•£å€¤ï¼ˆã‚«ãƒ†ã‚´ãƒªï¼‰</td>
<td>ç”»åƒåˆ†é¡ã€ã‚¹ãƒ‘ãƒ åˆ¤å®šã€ç–¾ç—…è¨ºæ–­</td>
</tr>
</tbody>
</table>

<h3>å®Ÿä¸–ç•Œã®å¿œç”¨ä¾‹</h3>

<div class="mermaid">
graph LR
    A[å›å¸°å•é¡Œã®å¿œç”¨] --> B[é‡‘è: æ ªä¾¡äºˆæ¸¬]
    A --> C[ä¸å‹•ç”£: ä½å®…ä¾¡æ ¼äºˆæ¸¬]
    A --> D[è£½é€ : éœ€è¦äºˆæ¸¬]
    A --> E[åŒ»ç™‚: æ‚£è€…æ»åœ¨æœŸé–“äºˆæ¸¬]
    A --> F[ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°: å£²ä¸Šäºˆæ¸¬]

    style A fill:#e3f2fd
    style B fill:#fff3e0
    style C fill:#fff3e0
    style D fill:#fff3e0
    style E fill:#fff3e0
    style F fill:#fff3e0
</div>

<hr>

<h2>1.2 ç·šå½¢å›å¸°ã®ç†è«–</h2>

<h3>å˜å›å¸°ãƒ¢ãƒ‡ãƒ«</h3>

<p><strong>å˜å›å¸°ï¼ˆSimple Linear Regressionï¼‰</strong>ã¯ã€1ã¤ã®ç‰¹å¾´é‡ã‹ã‚‰äºˆæ¸¬ã‚’è¡Œã„ã¾ã™ã€‚</p>

<p>$$
y = w_0 + w_1 x + \epsilon
$$</p>

<ul>
<li>$y$: ç›®çš„å¤‰æ•°ï¼ˆäºˆæ¸¬ã—ãŸã„å€¤ï¼‰</li>
<li>$x$: èª¬æ˜å¤‰æ•°ï¼ˆç‰¹å¾´é‡ï¼‰</li>
<li>$w_0$: åˆ‡ç‰‡ï¼ˆintercept, biasï¼‰</li>
<li>$w_1$: å‚¾ãï¼ˆslope, weightï¼‰</li>
<li>$\epsilon$: èª¤å·®é …</li>
</ul>

<h3>é‡å›å¸°ãƒ¢ãƒ‡ãƒ«</h3>

<p><strong>é‡å›å¸°ï¼ˆMultiple Linear Regressionï¼‰</strong>ã¯ã€è¤‡æ•°ã®ç‰¹å¾´é‡ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚</p>

<p>$$
y = w_0 + w_1 x_1 + w_2 x_2 + \cdots + w_n x_n + \epsilon
$$</p>

<p>è¡Œåˆ—è¡¨è¨˜ï¼š</p>

<p>$$
\mathbf{y} = \mathbf{X}\mathbf{w} + \epsilon
$$</p>

<ul>
<li>$\mathbf{y}$: ç›®çš„å¤‰æ•°ãƒ™ã‚¯ãƒˆãƒ«ï¼ˆshape: $m \times 1$ï¼‰</li>
<li>$\mathbf{X}$: ç‰¹å¾´é‡è¡Œåˆ—ï¼ˆshape: $m \times (n+1)$ï¼‰</li>
<li>$\mathbf{w}$: é‡ã¿ãƒ™ã‚¯ãƒˆãƒ«ï¼ˆshape: $(n+1) \times 1$ï¼‰</li>
<li>$m$: ã‚µãƒ³ãƒ—ãƒ«æ•°ã€$n$: ç‰¹å¾´é‡æ•°</li>
</ul>

<h3>æå¤±é–¢æ•°ï¼ˆLoss Functionï¼‰</h3>

<p><strong>å¹³å‡äºŒä¹—èª¤å·®ï¼ˆMean Squared Error, MSEï¼‰</strong>ã‚’æœ€å°åŒ–ã—ã¾ã™ï¼š</p>

<p>$$
J(\mathbf{w}) = \frac{1}{m} \sum_{i=1}^{m} (y^{(i)} - \hat{y}^{(i)})^2 = \frac{1}{m} ||\mathbf{y} - \mathbf{X}\mathbf{w}||^2
$$</p>

<ul>
<li>$y^{(i)}$: å®Ÿéš›ã®å€¤</li>
<li>$\hat{y}^{(i)} = \mathbf{w}^T \mathbf{x}^{(i)}$: äºˆæ¸¬å€¤</li>
</ul>

<hr>

<h2>1.3 æœ€å°äºŒä¹—æ³•ï¼ˆOrdinary Least Squaresï¼‰</h2>

<h3>è§£æè§£</h3>

<p>MSEã‚’æœ€å°åŒ–ã™ã‚‹é‡ã¿ $\mathbf{w}$ ã¯ã€è§£æçš„ã«æ±‚ã‚ã‚‰ã‚Œã¾ã™ï¼š</p>

<p>$$
\mathbf{w}^* = (\mathbf{X}^T \mathbf{X})^{-1} \mathbf{X}^T \mathbf{y}
$$</p>

<p>ã“ã‚Œã‚’<strong>æ­£è¦æ–¹ç¨‹å¼ï¼ˆNormal Equationï¼‰</strong>ã¨å‘¼ã³ã¾ã™ã€‚</p>

<h3>å®Ÿè£…ä¾‹ï¼šå˜å›å¸°</h3>

<pre><code class="language-python">import numpy as np
import matplotlib.pyplot as plt

# ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
np.random.seed(42)
X = 2 * np.random.rand(100, 1)
y = 4 + 3 * X + np.random.randn(100, 1)

# ãƒã‚¤ã‚¢ã‚¹é …ã‚’è¿½åŠ 
X_b = np.c_[np.ones((100, 1)), X]  # shape: (100, 2)

# æ­£è¦æ–¹ç¨‹å¼ã§é‡ã¿ã‚’è¨ˆç®—
w_best = np.linalg.inv(X_b.T @ X_b) @ X_b.T @ y

print("å­¦ç¿’ã—ãŸé‡ã¿:")
print(f"w0 (åˆ‡ç‰‡): {w_best[0][0]:.4f}")
print(f"w1 (å‚¾ã): {w_best[1][0]:.4f}")

# äºˆæ¸¬
X_new = np.array([[0], [2]])
X_new_b = np.c_[np.ones((2, 1)), X_new]
y_predict = X_new_b @ w_best

# å¯è¦–åŒ–
plt.figure(figsize=(10, 6))
plt.scatter(X, y, alpha=0.6, label='ãƒ‡ãƒ¼ã‚¿')
plt.plot(X_new, y_predict, 'r-', linewidth=2, label='äºˆæ¸¬ç›´ç·š')
plt.xlabel('X', fontsize=12)
plt.ylabel('y', fontsize=12)
plt.title('ç·šå½¢å›å¸° - æœ€å°äºŒä¹—æ³•', fontsize=14)
plt.legend()
plt.grid(True, alpha=0.3)
plt.show()
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>å­¦ç¿’ã—ãŸé‡ã¿:
w0 (åˆ‡ç‰‡): 4.2153
w1 (å‚¾ã): 2.7702
</code></pre>

<h3>scikit-learnã«ã‚ˆã‚‹å®Ÿè£…</h3>

<pre><code class="language-python">from sklearn.linear_model import LinearRegression

# ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰
model = LinearRegression()
model.fit(X, y)

print("\nscikit-learn:")
print(f"åˆ‡ç‰‡: {model.intercept_[0]:.4f}")
print(f"å‚¾ã: {model.coef_[0][0]:.4f}")

# äºˆæ¸¬
y_pred = model.predict(X_new)
print(f"\näºˆæ¸¬å€¤: {y_pred.flatten()}")
</code></pre>

<hr>

<h2>1.4 å‹¾é…é™ä¸‹æ³•ï¼ˆGradient Descentï¼‰</h2>

<h3>åŸç†</h3>

<p>æå¤±é–¢æ•°ã®å‹¾é…ã‚’è¨ˆç®—ã—ã€å‹¾é…ã®é€†æ–¹å‘ã«é‡ã¿ã‚’æ›´æ–°ã—ã¾ã™ã€‚</p>

<div class="mermaid">
graph LR
    A[åˆæœŸé‡ã¿ w] --> B[å‹¾é…è¨ˆç®— âˆ‡J]
    B --> C[é‡ã¿æ›´æ–° w := w - Î±âˆ‡J]
    C --> D{åæŸ?}
    D -->|No| B
    D -->|Yes| E[æœ€é©é‡ã¿ w*]

    style A fill:#e3f2fd
    style B fill:#fff3e0
    style C fill:#f3e5f5
    style D fill:#ffe0b2
    style E fill:#e8f5e9
</div>

<h3>æ›´æ–°å¼</h3>

<p>$$
\mathbf{w} := \mathbf{w} - \alpha \nabla_{\mathbf{w}} J(\mathbf{w})
$$</p>

<p>å‹¾é…ï¼š</p>

<p>$$
\nabla_{\mathbf{w}} J(\mathbf{w}) = \frac{2}{m} \mathbf{X}^T (\mathbf{X}\mathbf{w} - \mathbf{y})
$$</p>

<ul>
<li>$\alpha$: å­¦ç¿’ç‡ï¼ˆlearning rateï¼‰</li>
</ul>

<h3>å®Ÿè£…ä¾‹</h3>

<pre><code class="language-python">def gradient_descent(X, y, alpha=0.01, n_iterations=1000):
    """
    å‹¾é…é™ä¸‹æ³•ã§ç·šå½¢å›å¸°ã‚’å­¦ç¿’

    Args:
        X: ç‰¹å¾´é‡è¡Œåˆ— (ãƒã‚¤ã‚¢ã‚¹é …å«ã‚€)
        y: ç›®çš„å¤‰æ•°
        alpha: å­¦ç¿’ç‡
        n_iterations: ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ•°

    Returns:
        w: å­¦ç¿’ã—ãŸé‡ã¿
        history: æå¤±é–¢æ•°ã®å±¥æ­´
    """
    m = len(y)
    w = np.random.randn(X.shape[1], 1)  # é‡ã¿ã®åˆæœŸåŒ–
    history = []

    for i in range(n_iterations):
        # äºˆæ¸¬
        y_pred = X @ w

        # æå¤±è¨ˆç®—
        loss = (1 / m) * np.sum((y_pred - y) ** 2)
        history.append(loss)

        # å‹¾é…è¨ˆç®—
        gradients = (2 / m) * X.T @ (y_pred - y)

        # é‡ã¿æ›´æ–°
        w = w - alpha * gradients

        if i % 100 == 0:
            print(f"Iteration {i}: Loss = {loss:.4f}")

    return w, history

# å®Ÿè¡Œ
w_gd, loss_history = gradient_descent(X_b, y, alpha=0.1, n_iterations=1000)

print("\nå‹¾é…é™ä¸‹æ³•ã§å­¦ç¿’ã—ãŸé‡ã¿:")
print(f"w0 (åˆ‡ç‰‡): {w_gd[0][0]:.4f}")
print(f"w1 (å‚¾ã): {w_gd[1][0]:.4f}")

# æå¤±é–¢æ•°ã®æ¨ç§»ã‚’å¯è¦–åŒ–
plt.figure(figsize=(10, 6))
plt.plot(loss_history, linewidth=2)
plt.xlabel('Iteration', fontsize=12)
plt.ylabel('MSE Loss', fontsize=12)
plt.title('å‹¾é…é™ä¸‹æ³•ã®åæŸéç¨‹', fontsize=14)
plt.grid(True, alpha=0.3)
plt.show()
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>Iteration 0: Loss = 6.8421
Iteration 100: Loss = 0.8752
Iteration 200: Loss = 0.8284
Iteration 300: Loss = 0.8243
Iteration 400: Loss = 0.8236
Iteration 500: Loss = 0.8235
Iteration 600: Loss = 0.8235
Iteration 700: Loss = 0.8235
Iteration 800: Loss = 0.8235
Iteration 900: Loss = 0.8235

å‹¾é…é™ä¸‹æ³•ã§å­¦ç¿’ã—ãŸé‡ã¿:
w0 (åˆ‡ç‰‡): 4.2152
w1 (å‚¾ã): 2.7703
</code></pre>

<h3>å­¦ç¿’ç‡ã®é‡è¦æ€§</h3>

<pre><code class="language-python"># ç•°ãªã‚‹å­¦ç¿’ç‡ã§ã®æ¯”è¼ƒ
learning_rates = [0.001, 0.01, 0.1, 0.5]

plt.figure(figsize=(12, 8))
for i, alpha in enumerate(learning_rates):
    w, history = gradient_descent(X_b, y, alpha=alpha, n_iterations=100)
    plt.subplot(2, 2, i+1)
    plt.plot(history, linewidth=2)
    plt.title(f'å­¦ç¿’ç‡ Î± = {alpha}', fontsize=12)
    plt.xlabel('Iteration')
    plt.ylabel('MSE Loss')
    plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
</code></pre>

<hr>

<h2>1.5 å¤šé …å¼å›å¸°ï¼ˆPolynomial Regressionï¼‰</h2>

<h3>æ¦‚è¦</h3>

<p>ç·šå½¢å›å¸°ã§ã¯è¡¨ç¾ã§ããªã„<strong>éç·šå½¢é–¢ä¿‚</strong>ã‚’ãƒ¢ãƒ‡ãƒ«åŒ–ã—ã¾ã™ã€‚</p>

<p>$$
y = w_0 + w_1 x + w_2 x^2 + \cdots + w_d x^d
$$</p>

<p>ç‰¹å¾´é‡ã‚’å¤‰æ›ã™ã‚‹ã“ã¨ã§ã€ç·šå½¢å›å¸°ã®æ çµ„ã¿ã‚’ä½¿ç”¨ã§ãã¾ã™ã€‚</p>

<h3>å®Ÿè£…ä¾‹</h3>

<pre><code class="language-python">from sklearn.preprocessing import PolynomialFeatures
from sklearn.pipeline import Pipeline

# éç·šå½¢ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
np.random.seed(42)
X = 6 * np.random.rand(100, 1) - 3
y = 0.5 * X**2 + X + 2 + np.random.randn(100, 1)

# å¤šé …å¼å›å¸°ï¼ˆæ¬¡æ•°2ï¼‰
poly_features = PolynomialFeatures(degree=2, include_bias=False)
X_poly = poly_features.fit_transform(X)

model = LinearRegression()
model.fit(X_poly, y)

print("å¤šé …å¼å›å¸°ã®ä¿‚æ•°:")
print(f"w1 (x): {model.coef_[0][0]:.4f}")
print(f"w2 (xÂ²): {model.coef_[0][1]:.4f}")
print(f"åˆ‡ç‰‡: {model.intercept_[0]:.4f}")

# äºˆæ¸¬ã¨å¯è¦–åŒ–
X_test = np.linspace(-3, 3, 100).reshape(-1, 1)
X_test_poly = poly_features.transform(X_test)
y_pred = model.predict(X_test_poly)

plt.figure(figsize=(10, 6))
plt.scatter(X, y, alpha=0.6, label='ãƒ‡ãƒ¼ã‚¿')
plt.plot(X_test, y_pred, 'r-', linewidth=2, label='å¤šé …å¼å›å¸° (æ¬¡æ•°2)')
plt.xlabel('X', fontsize=12)
plt.ylabel('y', fontsize=12)
plt.title('å¤šé …å¼å›å¸°', fontsize=14)
plt.legend()
plt.grid(True, alpha=0.3)
plt.show()
</code></pre>

<h3>éå­¦ç¿’ã®å±é™ºæ€§</h3>

<pre><code class="language-python"># ç•°ãªã‚‹æ¬¡æ•°ã§ã®æ¯”è¼ƒ
degrees = [1, 2, 5, 10]

plt.figure(figsize=(14, 10))
for i, degree in enumerate(degrees):
    poly_features = PolynomialFeatures(degree=degree, include_bias=False)
    X_poly = poly_features.fit_transform(X)

    model = LinearRegression()
    model.fit(X_poly, y)

    X_test_poly = poly_features.transform(X_test)
    y_pred = model.predict(X_test_poly)

    plt.subplot(2, 2, i+1)
    plt.scatter(X, y, alpha=0.6, label='ãƒ‡ãƒ¼ã‚¿')
    plt.plot(X_test, y_pred, 'r-', linewidth=2, label=f'æ¬¡æ•° {degree}')
    plt.xlabel('X')
    plt.ylabel('y')
    plt.title(f'å¤šé …å¼å›å¸°ï¼ˆæ¬¡æ•° {degree}ï¼‰', fontsize=12)
    plt.ylim(-5, 15)
    plt.legend()
    plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
</code></pre>

<blockquote>
<p><strong>æ³¨æ„</strong>: æ¬¡æ•°ãŒé«˜ã™ãã‚‹ã¨éå­¦ç¿’ï¼ˆoverfittingï¼‰ãŒç™ºç”Ÿã—ã¾ã™ã€‚æ¬¡æ•°10ã§ã¯ãƒ‡ãƒ¼ã‚¿ã«éå‰°é©åˆã—ã€æ±åŒ–æ€§èƒ½ãŒä½ä¸‹ã—ã¾ã™ã€‚</p>
</blockquote>

<hr>

<h2>1.6 æ­£å‰‡åŒ–ï¼ˆRegularizationï¼‰</h2>

<h3>æ¦‚è¦</h3>

<p>éå­¦ç¿’ã‚’é˜²ããŸã‚ã€æå¤±é–¢æ•°ã«<strong>ãƒšãƒŠãƒ«ãƒ†ã‚£é …</strong>ã‚’è¿½åŠ ã—ã¾ã™ã€‚</p>

<div class="mermaid">
graph TD
    A[æ­£å‰‡åŒ–æ‰‹æ³•] --> B[Ridge L2æ­£å‰‡åŒ–]
    A --> C[Lasso L1æ­£å‰‡åŒ–]
    A --> D[Elastic Net L1+L2]

    B --> B1[é‡ã¿ã®å¤§ãã•ã‚’æŠ‘åˆ¶]
    C --> C1[é‡ã¿ã®ä¸€éƒ¨ã‚’ã‚¼ãƒ­ã«]
    D --> D1[ä¸¡æ–¹ã®ãƒãƒ©ãƒ³ã‚¹]

    style A fill:#e3f2fd
    style B fill:#fff3e0
    style C fill:#f3e5f5
    style D fill:#e8f5e9
</div>

<h3>Ridgeå›å¸°ï¼ˆL2æ­£å‰‡åŒ–ï¼‰</h3>

<p>$$
J(\mathbf{w}) = \frac{1}{m} \sum_{i=1}^{m} (y^{(i)} - \hat{y}^{(i)})^2 + \alpha \sum_{j=1}^{n} w_j^2
$$</p>

<ul>
<li>$\alpha$: æ­£å‰‡åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿</li>
<li>é‡ã¿ã®äºŒä¹—å’Œã«ãƒšãƒŠãƒ«ãƒ†ã‚£</li>
</ul>

<pre><code class="language-python">from sklearn.linear_model import Ridge

# Ridgeå›å¸°
ridge_model = Ridge(alpha=1.0)
ridge_model.fit(X_poly, y)

print("Ridgeå›å¸°ã®ä¿‚æ•°:")
print(f"é‡ã¿: {ridge_model.coef_[0]}")
print(f"åˆ‡ç‰‡: {ridge_model.intercept_[0]:.4f}")
</code></pre>

<h3>Lassoå›å¸°ï¼ˆL1æ­£å‰‡åŒ–ï¼‰</h3>

<p>$$
J(\mathbf{w}) = \frac{1}{m} \sum_{i=1}^{m} (y^{(i)} - \hat{y}^{(i)})^2 + \alpha \sum_{j=1}^{n} |w_j|
$$</p>

<ul>
<li>é‡ã¿ã®çµ¶å¯¾å€¤å’Œã«ãƒšãƒŠãƒ«ãƒ†ã‚£</li>
<li><strong>ã‚¹ãƒ‘ãƒ¼ã‚¹æ€§</strong>: é‡è¦ã§ãªã„ç‰¹å¾´é‡ã®é‡ã¿ã‚’ã‚¼ãƒ­ã«ã™ã‚‹</li>
</ul>

<pre><code class="language-python">from sklearn.linear_model import Lasso

# Lassoå›å¸°
lasso_model = Lasso(alpha=0.1)
lasso_model.fit(X_poly, y)

print("\nLassoå›å¸°ã®ä¿‚æ•°:")
print(f"é‡ã¿: {lasso_model.coef_}")
print(f"åˆ‡ç‰‡: {lasso_model.intercept_:.4f}")
print(f"ã‚¼ãƒ­ã®é‡ã¿æ•°: {np.sum(lasso_model.coef_ == 0)}")
</code></pre>

<h3>Elastic Netï¼ˆL1 + L2æ­£å‰‡åŒ–ï¼‰</h3>

<p>$$
J(\mathbf{w}) = \frac{1}{m} \sum_{i=1}^{m} (y^{(i)} - \hat{y}^{(i)})^2 + \alpha \rho \sum_{j=1}^{n} |w_j| + \frac{\alpha(1-\rho)}{2} \sum_{j=1}^{n} w_j^2
$$</p>

<ul>
<li>$\rho$: L1ã¨L2ã®ãƒãƒ©ãƒ³ã‚¹ï¼ˆ0ã€œ1ï¼‰</li>
</ul>

<pre><code class="language-python">from sklearn.linear_model import ElasticNet

# Elastic Net
elastic_model = ElasticNet(alpha=0.1, l1_ratio=0.5)
elastic_model.fit(X_poly, y)

print("\nElastic Netå›å¸°ã®ä¿‚æ•°:")
print(f"é‡ã¿: {elastic_model.coef_}")
print(f"åˆ‡ç‰‡: {elastic_model.intercept_:.4f}")
</code></pre>

<h3>æ­£å‰‡åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æ¯”è¼ƒ</h3>

<pre><code class="language-python"># ç•°ãªã‚‹alphaã§ã®æ¯”è¼ƒ
alphas = np.logspace(-3, 2, 100)
ridge_coefs = []
lasso_coefs = []

for alpha in alphas:
    ridge = Ridge(alpha=alpha)
    ridge.fit(X_poly, y)
    ridge_coefs.append(ridge.coef_[0])

    lasso = Lasso(alpha=alpha, max_iter=10000)
    lasso.fit(X_poly, y)
    lasso_coefs.append(lasso.coef_)

ridge_coefs = np.array(ridge_coefs)
lasso_coefs = np.array(lasso_coefs)

plt.figure(figsize=(14, 6))

# Ridge
plt.subplot(1, 2, 1)
for i in range(X_poly.shape[1]):
    plt.plot(alphas, ridge_coefs[:, i], label=f'w{i+1}')
plt.xscale('log')
plt.xlabel('Alpha (æ­£å‰‡åŒ–å¼·åº¦)', fontsize=12)
plt.ylabel('ä¿‚æ•°ã®å¤§ãã•', fontsize=12)
plt.title('Ridgeå›å¸°: æ­£å‰‡åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å½±éŸ¿', fontsize=14)
plt.legend()
plt.grid(True, alpha=0.3)

# Lasso
plt.subplot(1, 2, 2)
for i in range(X_poly.shape[1]):
    plt.plot(alphas, lasso_coefs[:, i], label=f'w{i+1}')
plt.xscale('log')
plt.xlabel('Alpha (æ­£å‰‡åŒ–å¼·åº¦)', fontsize=12)
plt.ylabel('ä¿‚æ•°ã®å¤§ãã•', fontsize=12)
plt.title('Lassoå›å¸°: æ­£å‰‡åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å½±éŸ¿', fontsize=14)
plt.legend()
plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
</code></pre>

<hr>

<h2>1.7 å›å¸°ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡</h2>

<h3>è©•ä¾¡æŒ‡æ¨™</h3>

<table>
<thead>
<tr>
<th>æŒ‡æ¨™</th>
<th>æ•°å¼</th>
<th>èª¬æ˜</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>å¹³å‡çµ¶å¯¾èª¤å·®</strong><br>(MAE)</td>
<td>$\frac{1}{m}\sum|y_i - \hat{y}_i|$</td>
<td>äºˆæ¸¬èª¤å·®ã®å¹³å‡ï¼ˆå¤–ã‚Œå€¤ã«é ‘å¥ï¼‰</td>
</tr>
<tr>
<td><strong>å¹³å‡äºŒä¹—èª¤å·®</strong><br>(MSE)</td>
<td>$\frac{1}{m}\sum(y_i - \hat{y}_i)^2$</td>
<td>äºˆæ¸¬èª¤å·®ã®äºŒä¹—å¹³å‡ï¼ˆå¤–ã‚Œå€¤ã«æ•æ„Ÿï¼‰</td>
</tr>
<tr>
<td><strong>å¹³å‡äºŒä¹—å¹³æ–¹æ ¹èª¤å·®</strong><br>(RMSE)</td>
<td>$\sqrt{\frac{1}{m}\sum(y_i - \hat{y}_i)^2}$</td>
<td>MSEã®å¹³æ–¹æ ¹ï¼ˆå…ƒã®å˜ä½ï¼‰</td>
</tr>
<tr>
<td><strong>æ±ºå®šä¿‚æ•°</strong><br>(RÂ²)</td>
<td>$1 - \frac{\sum(y_i - \hat{y}_i)^2}{\sum(y_i - \bar{y})^2}$</td>
<td>ãƒ¢ãƒ‡ãƒ«ã®èª¬æ˜åŠ›ï¼ˆ0ã€œ1ã€é«˜ã„ã»ã©è‰¯ã„ï¼‰</td>
</tr>
</tbody>
</table>

<h3>å®Ÿè£…ä¾‹</h3>

<pre><code class="language-python">from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X_poly, y, test_size=0.2, random_state=42
)

# ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
model = LinearRegression()
model.fit(X_train, y_train)

# äºˆæ¸¬
y_train_pred = model.predict(X_train)
y_test_pred = model.predict(X_test)

# è©•ä¾¡
print("=== è¨“ç·´ãƒ‡ãƒ¼ã‚¿ ===")
print(f"MAE:  {mean_absolute_error(y_train, y_train_pred):.4f}")
print(f"MSE:  {mean_squared_error(y_train, y_train_pred):.4f}")
print(f"RMSE: {np.sqrt(mean_squared_error(y_train, y_train_pred)):.4f}")
print(f"RÂ²:   {r2_score(y_train, y_train_pred):.4f}")

print("\n=== ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ ===")
print(f"MAE:  {mean_absolute_error(y_test, y_test_pred):.4f}")
print(f"MSE:  {mean_squared_error(y_test, y_test_pred):.4f}")
print(f"RMSE: {np.sqrt(mean_squared_error(y_test, y_test_pred)):.4f}")
print(f"RÂ²:   {r2_score(y_test, y_test_pred):.4f}")

# æ®‹å·®ãƒ—ãƒ­ãƒƒãƒˆ
residuals = y_test - y_test_pred

plt.figure(figsize=(14, 6))

# äºˆæ¸¬ vs å®Ÿéš›
plt.subplot(1, 2, 1)
plt.scatter(y_test, y_test_pred, alpha=0.6)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', linewidth=2)
plt.xlabel('å®Ÿéš›ã®å€¤', fontsize=12)
plt.ylabel('äºˆæ¸¬å€¤', fontsize=12)
plt.title('äºˆæ¸¬ vs å®Ÿéš›', fontsize=14)
plt.grid(True, alpha=0.3)

# æ®‹å·®ãƒ—ãƒ­ãƒƒãƒˆ
plt.subplot(1, 2, 2)
plt.scatter(y_test_pred, residuals, alpha=0.6)
plt.axhline(y=0, color='r', linestyle='--', linewidth=2)
plt.xlabel('äºˆæ¸¬å€¤', fontsize=12)
plt.ylabel('æ®‹å·®', fontsize=12)
plt.title('æ®‹å·®ãƒ—ãƒ­ãƒƒãƒˆ', fontsize=14)
plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>=== è¨“ç·´ãƒ‡ãƒ¼ã‚¿ ===
MAE:  0.7234
MSE:  0.8456
RMSE: 0.9196
RÂ²:   0.9145

=== ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ ===
MAE:  0.7891
MSE:  0.9234
RMSE: 0.9609
RÂ²:   0.9023
</code></pre>

<hr>

<h2>1.8 æœ¬ç« ã®ã¾ã¨ã‚</h2>

<h3>å­¦ã‚“ã ã“ã¨</h3>

<ol>
<li><p><strong>å›å¸°å•é¡Œã®å®šç¾©</strong></p>
<ul>
<li>é€£ç¶šå€¤ã®äºˆæ¸¬ã‚¿ã‚¹ã‚¯</li>
<li>å®Ÿä¸–ç•Œã®å¿œç”¨ä¾‹ï¼ˆä¾¡æ ¼äºˆæ¸¬ã€éœ€è¦äºˆæ¸¬ãªã©ï¼‰</li>
</ul></li>
<li><p><strong>ç·šå½¢å›å¸°</strong></p>
<ul>
<li>æœ€å°äºŒä¹—æ³•ã«ã‚ˆã‚‹è§£æè§£</li>
<li>å‹¾é…é™ä¸‹æ³•ã«ã‚ˆã‚‹æ•°å€¤è§£</li>
</ul></li>
<li><p><strong>å¤šé …å¼å›å¸°</strong></p>
<ul>
<li>éç·šå½¢é–¢ä¿‚ã®ãƒ¢ãƒ‡ãƒ«åŒ–</li>
<li>éå­¦ç¿’ã®å±é™ºæ€§</li>
</ul></li>
<li><p><strong>æ­£å‰‡åŒ–</strong></p>
<ul>
<li>Ridgeï¼ˆL2ï¼‰: é‡ã¿ã®å¤§ãã•ã‚’æŠ‘åˆ¶</li>
<li>Lassoï¼ˆL1ï¼‰: ã‚¹ãƒ‘ãƒ¼ã‚¹æ€§ã®å°å…¥</li>
<li>Elastic Net: ä¸¡æ–¹ã®ãƒãƒ©ãƒ³ã‚¹</li>
</ul></li>
<li><p><strong>è©•ä¾¡æŒ‡æ¨™</strong></p>
<ul>
<li>MAEã€MSEã€RMSEã€RÂ²</li>
<li>æ®‹å·®åˆ†æã®é‡è¦æ€§</li>
</ul></li>
</ol>

<h3>æ¬¡ã®ç« ã¸</h3>

<p>ç¬¬2ç« ã§ã¯ã€<strong>åˆ†é¡å•é¡Œã®åŸºç¤</strong>ã‚’å­¦ã³ã¾ã™ï¼š</p>
<ul>
<li>ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°</li>
<li>æ±ºå®šæœ¨</li>
<li>k-NNã€SVM</li>
<li>è©•ä¾¡æŒ‡æ¨™ï¼ˆç²¾åº¦ã€å†ç¾ç‡ã€F1ã‚¹ã‚³ã‚¢ï¼‰</li>
</ul>

<hr>

<h2>æ¼”ç¿’å•é¡Œ</h2>

<h3>å•é¡Œ1ï¼ˆé›£æ˜“åº¦ï¼šeasyï¼‰</h3>
<p>å›å¸°å•é¡Œã¨åˆ†é¡å•é¡Œã®é•ã„ã‚’3ã¤æŒ™ã’ã¦ãã ã•ã„ã€‚</p>

<details>
<summary>è§£ç­”ä¾‹</summary>

<p><strong>è§£ç­”</strong>ï¼š</p>
<ol>
<li><strong>å‡ºåŠ›ã®ç¨®é¡</strong>: å›å¸°ã¯é€£ç¶šå€¤ã€åˆ†é¡ã¯é›¢æ•£å€¤ï¼ˆã‚«ãƒ†ã‚´ãƒªï¼‰</li>
<li><strong>æå¤±é–¢æ•°</strong>: å›å¸°ã¯MSEã€åˆ†é¡ã¯äº¤å·®ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼</li>
<li><strong>è©•ä¾¡æŒ‡æ¨™</strong>: å›å¸°ã¯RMSE/RÂ²ã€åˆ†é¡ã¯ç²¾åº¦/F1ã‚¹ã‚³ã‚¢</li>
</ol>

</details>

<h3>å•é¡Œ2ï¼ˆé›£æ˜“åº¦ï¼šmediumï¼‰</h3>
<p>ä»¥ä¸‹ã®ãƒ‡ãƒ¼ã‚¿ã§ç·šå½¢å›å¸°ã‚’å®Ÿè£…ã—ã€é‡ã¿ã¨ãƒã‚¤ã‚¢ã‚¹ã‚’æ±‚ã‚ã¦ãã ã•ã„ã€‚</p>

<pre><code class="language-python">X = np.array([[1], [2], [3], [4], [5]])
y = np.array([[2], [4], [5], [4], [5]])
</code></pre>

<details>
<summary>è§£ç­”ä¾‹</summary>

<pre><code class="language-python">import numpy as np

X = np.array([[1], [2], [3], [4], [5]])
y = np.array([[2], [4], [5], [4], [5]])

# ãƒã‚¤ã‚¢ã‚¹é …ã‚’è¿½åŠ 
X_b = np.c_[np.ones((5, 1)), X]

# æ­£è¦æ–¹ç¨‹å¼
w = np.linalg.inv(X_b.T @ X_b) @ X_b.T @ y

print(f"åˆ‡ç‰‡ w0: {w[0][0]:.4f}")
print(f"å‚¾ã w1: {w[1][0]:.4f}")

# äºˆæ¸¬
y_pred = X_b @ w
print(f"\näºˆæ¸¬å€¤: {y_pred.flatten()}")
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>åˆ‡ç‰‡ w0: 2.2000
å‚¾ã w1: 0.6000

äºˆæ¸¬å€¤: [2.8 3.4 4.  4.6 5.2]
</code></pre>

</details>

<h3>å•é¡Œ3ï¼ˆé›£æ˜“åº¦ï¼šmediumï¼‰</h3>
<p>å­¦ç¿’ç‡ãŒå¤§ãã™ãã‚‹å ´åˆã€å‹¾é…é™ä¸‹æ³•ã§ã©ã®ã‚ˆã†ãªå•é¡ŒãŒç™ºç”Ÿã—ã¾ã™ã‹ï¼Ÿ</p>

<details>
<summary>è§£ç­”ä¾‹</summary>

<p><strong>è§£ç­”</strong>ï¼š</p>
<ul>
<li><strong>ç™ºæ•£ï¼ˆdivergenceï¼‰</strong>: æå¤±é–¢æ•°ãŒæœ€å°å€¤ã‚’é€šã‚Šè¶Šã—ã¦ç™ºæ•£ã™ã‚‹</li>
<li><strong>æŒ¯å‹•</strong>: æœ€å°å€¤ã®å‘¨ã‚Šã§æŒ¯å‹•ã—ç¶šã‘ã‚‹</li>
<li><strong>åæŸã—ãªã„</strong>: æœ€é©è§£ã«åˆ°é”ã§ããªã„</li>
</ul>

<p><strong>å¯¾ç­–</strong>ï¼š</p>
<ul>
<li>å­¦ç¿’ç‡ã‚’å°ã•ãã™ã‚‹ï¼ˆä¾‹: 0.1 â†’ 0.01ï¼‰</li>
<li>å­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°ã‚’ä½¿ç”¨ã™ã‚‹</li>
<li>é©å¿œçš„æœ€é©åŒ–æ‰‹æ³•ï¼ˆAdamã€RMSpropï¼‰ã‚’ä½¿ç”¨ã™ã‚‹</li>
</ul>

</details>

<h3>å•é¡Œ4ï¼ˆé›£æ˜“åº¦ï¼šhardï¼‰</h3>
<p>Ridgeå›å¸°ã¨Lassoå›å¸°ã®é•ã„ã‚’èª¬æ˜ã—ã€ã©ã®ã‚ˆã†ãªå ´åˆã«ãã‚Œãã‚Œã‚’ä½¿ã†ã¹ãã‹è¿°ã¹ã¦ãã ã•ã„ã€‚</p>

<details>
<summary>è§£ç­”ä¾‹</summary>

<p><strong>Ridgeå›å¸°ï¼ˆL2æ­£å‰‡åŒ–ï¼‰</strong>ï¼š</p>
<ul>
<li>é‡ã¿ã®äºŒä¹—å’Œã«ãƒšãƒŠãƒ«ãƒ†ã‚£</li>
<li>é‡ã¿ã‚’å°ã•ãã™ã‚‹ãŒã€ã‚¼ãƒ­ã«ã¯ã—ãªã„</li>
<li><strong>ä½¿ç”¨å ´é¢</strong>: å¤šé‡å…±ç·šæ€§ãŒã‚ã‚‹å ´åˆã€ã™ã¹ã¦ã®ç‰¹å¾´é‡ãŒé‡è¦ãªå ´åˆ</li>
</ul>

<p><strong>Lassoå›å¸°ï¼ˆL1æ­£å‰‡åŒ–ï¼‰</strong>ï¼š</p>
<ul>
<li>é‡ã¿ã®çµ¶å¯¾å€¤å’Œã«ãƒšãƒŠãƒ«ãƒ†ã‚£</li>
<li>é‡è¦ã§ãªã„ç‰¹å¾´é‡ã®é‡ã¿ã‚’ã‚¼ãƒ­ã«ã™ã‚‹ï¼ˆã‚¹ãƒ‘ãƒ¼ã‚¹æ€§ï¼‰</li>
<li><strong>ä½¿ç”¨å ´é¢</strong>: ç‰¹å¾´é‡é¸æŠãŒå¿…è¦ãªå ´åˆã€è§£é‡ˆæ€§ã‚’é«˜ã‚ãŸã„å ´åˆ</li>
</ul>

<p><strong>é¸æŠåŸºæº–</strong>ï¼š</p>
<table>
<thead>
<tr>
<th>çŠ¶æ³</th>
<th>æ¨å¥¨æ‰‹æ³•</th>
</tr>
</thead>
<tbody>
<tr>
<td>ç‰¹å¾´é‡ãŒå¤šãã€é‡è¦åº¦ãŒä¸æ˜</td>
<td>Lasso</td>
</tr>
<tr>
<td>å¤šé‡å…±ç·šæ€§ãŒã‚ã‚‹</td>
<td>Ridge</td>
</tr>
<tr>
<td>ç‰¹å¾´é‡é¸æŠãŒå¿…è¦</td>
<td>Lasso</td>
</tr>
<tr>
<td>ã™ã¹ã¦ã®ç‰¹å¾´é‡ã‚’ä½¿ã„ãŸã„</td>
<td>Ridge</td>
</tr>
<tr>
<td>ã©ã¡ã‚‰ã‹ä¸æ˜</td>
<td>Elastic Net</td>
</tr>
</tbody>
</table>

</details>

<h3>å•é¡Œ5ï¼ˆé›£æ˜“åº¦ï¼šhardï¼‰</h3>
<p>ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã‚’å®Œæˆã•ã›ã€äº¤å·®æ¤œè¨¼ã§Ridgeå›å¸°ã®æœ€é©ãªalphaã‚’è¦‹ã¤ã‘ã¦ãã ã•ã„ã€‚</p>

<pre><code class="language-python">from sklearn.model_selection import cross_val_score
from sklearn.linear_model import Ridge

# ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆï¼ˆçœç•¥ï¼‰
alphas = np.logspace(-3, 3, 50)

# ã“ã“ã«å®Ÿè£…
</code></pre>

<details>
<summary>è§£ç­”ä¾‹</summary>

<pre><code class="language-python">from sklearn.model_selection import cross_val_score
from sklearn.linear_model import Ridge
import numpy as np
import matplotlib.pyplot as plt

# ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
np.random.seed(42)
X = 2 * np.random.rand(100, 1)
y = 4 + 3 * X + np.random.randn(100, 1)

from sklearn.preprocessing import PolynomialFeatures
poly = PolynomialFeatures(degree=5, include_bias=False)
X_poly = poly.fit_transform(X)

alphas = np.logspace(-3, 3, 50)
scores = []

for alpha in alphas:
    ridge = Ridge(alpha=alpha)
    # 5åˆ†å‰²äº¤å·®æ¤œè¨¼
    cv_scores = cross_val_score(ridge, X_poly, y.ravel(),
                                 cv=5, scoring='neg_mean_squared_error')
    scores.append(-cv_scores.mean())  # è² ã®MSEã‚’æ­£ã«å¤‰æ›

# æœ€é©ãªalphaã‚’è¦‹ã¤ã‘ã‚‹
best_alpha = alphas[np.argmin(scores)]
best_score = np.min(scores)

print(f"æœ€é©ãªalpha: {best_alpha:.4f}")
print(f"æœ€å°MSE: {best_score:.4f}")

# å¯è¦–åŒ–
plt.figure(figsize=(10, 6))
plt.plot(alphas, scores, linewidth=2)
plt.axvline(best_alpha, color='r', linestyle='--',
            label=f'æœ€é©alpha = {best_alpha:.4f}')
plt.xscale('log')
plt.xlabel('Alpha', fontsize=12)
plt.ylabel('MSE (äº¤å·®æ¤œè¨¼)', fontsize=12)
plt.title('Ridgeå›å¸°: æœ€é©ãªalphaã®æ¢ç´¢', fontsize=14)
plt.legend()
plt.grid(True, alpha=0.3)
plt.show()
</code></pre>

<p><strong>å‡ºåŠ›</strong>ï¼š</p>
<pre><code>æœ€é©ãªalpha: 2.1544
æœ€å°MSE: 1.0234
</code></pre>

</details>

<hr>

<h2>å‚è€ƒæ–‡çŒ®</h2>

<ol>
<li>Bishop, C. M. (2006). <em>Pattern Recognition and Machine Learning</em>. Springer.</li>
<li>Hastie, T., Tibshirani, R., & Friedman, J. (2009). <em>The Elements of Statistical Learning</em>. Springer.</li>
<li>GÃ©ron, A. (2019). <em>Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow</em>. O'Reilly Media.</li>
</ol>

<div class="navigation">
    <a href="index.html" class="nav-button">â† ã‚·ãƒªãƒ¼ã‚ºç›®æ¬¡</a>
    <a href="chapter2-classification.html" class="nav-button">æ¬¡ã®ç« : åˆ†é¡å•é¡Œã®åŸºç¤ â†’</a>
</div>

    </main>

    <footer>
        <p><strong>ä½œæˆè€…</strong>: AI Terakoya Content Team</p>
        <p><strong>ãƒãƒ¼ã‚¸ãƒ§ãƒ³</strong>: 1.0 | <strong>ä½œæˆæ—¥</strong>: 2025-10-20</p>
        <p><strong>ãƒ©ã‚¤ã‚»ãƒ³ã‚¹</strong>: Creative Commons BY 4.0</p>
        <p>Â© 2025 AI Terakoya. All rights reserved.</p>
    </footer>
</body>
</html>
