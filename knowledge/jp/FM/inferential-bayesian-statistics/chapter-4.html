<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ç¬¬4ç« : ãƒ™ã‚¤ã‚ºæ¨è«–ã®åŸºç¤ã¨MCMC | æ¨æ¸¬çµ±è¨ˆå­¦ã¨ãƒ™ã‚¤ã‚ºçµ±è¨ˆ</title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.min.js"></script>
            <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif; line-height: 1.8; color: #333; background: #f5f5f5; }
        header { background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 1.5rem; text-align: center; }
        h1 { font-size: 1.8rem; margin-bottom: 0.5rem; }
        .subtitle { opacity: 0.9; }
        .container { max-width: 900px; margin: 2rem auto; padding: 0 1rem; }
        .breadcrumb { margin-bottom: 1.5rem; font-size: 0.9rem; }
        .breadcrumb a { color: #667eea; text-decoration: none; }
        .content { background: white; padding: 2.5rem; border-radius: 12px; box-shadow: 0 2px 8px rgba(0,0,0,0.1); margin-bottom: 2rem; }
        h2 { color: #667eea; margin: 2rem 0 1rem 0; padding-bottom: 0.5rem; border-bottom: 2px solid #e0e0e0; }
        h3 { color: #764ba2; margin: 1.5rem 0 0.8rem 0; }
        .definition { background: #e7f3ff; border-left: 4px solid #667eea; padding: 1rem 1.5rem; margin: 1.5rem 0; border-radius: 4px; }
        .theorem { background: #f3e5f5; border-left: 4px solid #764ba2; padding: 1rem 1.5rem; margin: 1.5rem 0; border-radius: 4px; }
        .example { background: #fff3e0; border-left: 4px solid #ff9800; padding: 1rem 1.5rem; margin: 1.5rem 0; border-radius: 4px; }
        .code-title {
            background: #667eea;
            color: white;
            padding: 0.5rem 1rem;
            border-radius: 6px 6px 0 0;
            font-weight: 600;
            margin-top: 1.5rem;
        }
        .code-example {
            background: #1e1e1e;
            color: #d4d4d4;
            padding: 1.5rem;
            border-radius: 0 0 8px 8px;
            overflow-x: auto;
            margin: 0 0 1rem 0;
            font-family: 'Courier New', monospace;
            font-size: 0.9rem;
            line-height: 1.6;
            white-space: pre-wrap;
        }
        .code-block {
            background: #1e1e1e;
            color: #d4d4d4;
            padding: 1.5rem;
            border-radius: 8px;
            overflow-x: auto;
            margin: 1rem 0;
            font-family: 'Courier New', monospace;
            font-size: 0.9rem;
            line-height: 1.6;
            white-space: pre-wrap;
        }
        .code-block code {
            font-family: 'Courier New', monospace;
            font-size: 0.9rem;
            line-height: 1.6;
            white-space: pre-wrap;
        }
        .output { background: #f8f9fa; border: 1px solid #dee2e6; padding: 1rem; border-radius: 6px; margin: 1rem 0; font-family: monospace; font-size: 0.9rem; }
        table { width: 100%; border-collapse: collapse; margin: 1.5rem 0; }
        th, td { padding: 0.8rem; text-align: left; border: 1px solid #ddd; }
        th { background: #667eea; color: white; }
        .note { background: #fff3cd; border-left: 4px solid #ffc107; padding: 1rem 1.5rem; margin: 1.5rem 0; border-radius: 4px; }
        .exercise { background: #d4edda; border-left: 4px solid #28a745; padding: 1rem 1.5rem; margin: 1.5rem 0; border-radius: 4px; }
        .nav-buttons { display: flex; justify-content: space-between; margin: 2rem 0; }
        .nav-button { padding: 0.8rem 1.5rem; background: #667eea; color: white; text-decoration: none; border-radius: 6px; font-weight: 600; }
        .nav-button:hover { background: #764ba2; }
        footer { background: #2c3e50; color: white; text-align: center; padding: 2rem 1rem; margin-top: 3rem; }
        @media (max-width: 768px) { .content { padding: 1.5rem; } h1 { font-size: 1.5rem; } }
    </style>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>
    <header>
        <h1>ç¬¬4ç« : ãƒ™ã‚¤ã‚ºæ¨è«–ã®åŸºç¤ã¨MCMC</h1>
        <p class="subtitle">Bayesian Inference and Markov Chain Monte Carlo</p>
    </header>

    <div class="container">
        <div class="breadcrumb">
            <a href="../index.html">åŸºç¤æ•°ç†é“å ´</a> &gt;
            <a href="index.html">æ¨æ¸¬çµ±è¨ˆå­¦ã¨ãƒ™ã‚¤ã‚ºçµ±è¨ˆ</a> &gt;
            ç¬¬4ç« 
        </div>


        <div class="content">
            <h2>4.1 ãƒ™ã‚¤ã‚ºæ¨è«–ã®åŸºæœ¬æ¦‚å¿µ</h2>
            
            <p>
                ãƒ™ã‚¤ã‚ºæ¨è«–ã¯ã€äº‹å‰çŸ¥è­˜ã¨ãƒ‡ãƒ¼ã‚¿ã‚’çµ„ã¿åˆã‚ã›ã¦ä¸ç¢ºå®Ÿæ€§ã‚’å®šé‡åŒ–ã™ã‚‹çµ±è¨ˆçš„æ çµ„ã¿ã§ã™ã€‚
                é »åº¦è«–çš„æ¨æ¸¬çµ±è¨ˆã¨ç•°ãªã‚Šã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ç¢ºç‡å¤‰æ•°ã¨ã—ã¦æ‰±ã„ã¾ã™ã€‚
            </p>

            <div class="theory-box">
                <h4>ğŸ“˜ ãƒ™ã‚¤ã‚ºã®å®šç†</h4>
                <p>ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ \( \theta \) ã¨ãƒ‡ãƒ¼ã‚¿ \( D \) ã«ã¤ã„ã¦ï¼š</p>
                <div class="formula">
                    $$ P(\theta | D) = \frac{P(D | \theta) P(\theta)}{P(D)} $$
                </div>
                <p>å„é …ã®æ„å‘³ï¼š</p>
                <ul>
                    <li><strong>äº‹å¾Œåˆ†å¸ƒ \( P(\theta | D) \)</strong>: ãƒ‡ãƒ¼ã‚¿è¦³æ¸¬å¾Œã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ç¢ºç‡åˆ†å¸ƒ</li>
                    <li><strong>å°¤åº¦ \( P(D | \theta) \)</strong>: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ \( \theta \) ã®ã‚‚ã¨ã§ãƒ‡ãƒ¼ã‚¿ \( D \) ãŒå¾—ã‚‰ã‚Œã‚‹ç¢ºç‡</li>
                    <li><strong>äº‹å‰åˆ†å¸ƒ \( P(\theta) \)</strong>: ãƒ‡ãƒ¼ã‚¿è¦³æ¸¬å‰ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«é–¢ã™ã‚‹ä¿¡å¿µ</li>
                    <li><strong>å‘¨è¾ºå°¤åº¦ \( P(D) \)</strong>: ãƒ‡ãƒ¼ã‚¿ã®ç¢ºç‡ï¼ˆæ­£è¦åŒ–å®šæ•°ï¼‰</li>
                </ul>
                <p>å®Ÿç”¨çš„ã«ã¯ï¼š</p>
                <div class="formula">
                    $$ P(\theta | D) \propto P(D | \theta) P(\theta) $$
                </div>
                <p>äº‹å¾Œåˆ†å¸ƒã¯å°¤åº¦ã¨äº‹å‰åˆ†å¸ƒã®ç©ã«æ¯”ä¾‹ã—ã¾ã™ã€‚</p>
            </div>

            <div class="example">
                <h4>ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹1: ãƒ™ã‚¤ã‚ºã®å®šç†ã®å®Ÿè£…ï¼ˆã‚³ã‚¤ãƒ³æŠ•ã’å•é¡Œï¼‰</h4>
                <pre><code>import numpy as np
import matplotlib.pyplot as plt
from scipy import stats

# ã‚³ã‚¤ãƒ³æŠ•ã’å•é¡Œ: ã‚³ã‚¤ãƒ³ã®è¡¨ãŒå‡ºã‚‹ç¢ºç‡pã‚’æ¨å®š
# ãƒ‡ãƒ¼ã‚¿: 10å›æŠ•ã’ã¦7å›è¡¨ãŒå‡ºãŸ
n_trials = 10
n_success = 7

# äº‹å‰åˆ†å¸ƒ: Beta(2, 2) (å¼±ã„æƒ…å ±ã®ã‚ã‚‹äº‹å‰åˆ†å¸ƒ)
alpha_prior = 2
beta_prior = 2

# å°¤åº¦: Binomial(n_success | n_trials, p)
# å…±å½¹äº‹å‰åˆ†å¸ƒã®æ€§è³ªã«ã‚ˆã‚Šã€äº‹å¾Œåˆ†å¸ƒã‚‚Betaåˆ†å¸ƒ
# Beta(alpha_prior + n_success, beta_prior + n_trials - n_success)
alpha_post = alpha_prior + n_success
beta_post = beta_prior + (n_trials - n_success)

print("=== ãƒ™ã‚¤ã‚ºæ¨è«–: ã‚³ã‚¤ãƒ³æŠ•ã’å•é¡Œ ===")
print(f"ãƒ‡ãƒ¼ã‚¿: {n_trials}å›ä¸­{n_success}å›è¡¨")
print(f"äº‹å‰åˆ†å¸ƒ: Beta({alpha_prior}, {beta_prior})")
print(f"äº‹å¾Œåˆ†å¸ƒ: Beta({alpha_post}, {beta_post})")
print(f"\näº‹å¾Œå¹³å‡: {alpha_post/(alpha_post + beta_post):.4f}")
print(f"äº‹å¾Œãƒ¢ãƒ¼ãƒ‰: {(alpha_post-1)/(alpha_post+beta_post-2):.4f}")

# 95%ä¿¡ç”¨åŒºé–“ (Credible Interval)
ci_lower = stats.beta.ppf(0.025, alpha_post, beta_post)
ci_upper = stats.beta.ppf(0.975, alpha_post, beta_post)
print(f"95%ä¿¡ç”¨åŒºé–“: [{ci_lower:.4f}, {ci_upper:.4f}]")

# æœ€å°¤æ¨å®šã¨ã®æ¯”è¼ƒ
mle = n_success / n_trials
print(f"\né »åº¦è«–çš„MLE: {mle:.4f}")

# å¯è¦–åŒ–
p_values = np.linspace(0, 1, 200)
prior_pdf = stats.beta.pdf(p_values, alpha_prior, beta_prior)
likelihood = stats.binom.pmf(n_success, n_trials, p_values)
posterior_pdf = stats.beta.pdf(p_values, alpha_post, beta_post)

fig, axes = plt.subplots(2, 2, figsize=(14, 10))

# äº‹å‰åˆ†å¸ƒ
axes[0, 0].plot(p_values, prior_pdf, 'b-', linewidth=2)
axes[0, 0].fill_between(p_values, 0, prior_pdf, alpha=0.3, color='blue')
axes[0, 0].set_xlabel('p (è¡¨ã®ç¢ºç‡)')
axes[0, 0].set_ylabel('ç¢ºç‡å¯†åº¦')
axes[0, 0].set_title(f'äº‹å‰åˆ†å¸ƒ Beta({alpha_prior}, {beta_prior})')
axes[0, 0].grid(True, alpha=0.3)

# å°¤åº¦é–¢æ•°
axes[0, 1].plot(p_values, likelihood, 'g-', linewidth=2)
axes[0, 1].fill_between(p_values, 0, likelihood, alpha=0.3, color='green')
axes[0, 1].axvline(mle, color='red', linestyle='--', linewidth=2,
                   label=f'MLE: {mle:.2f}')
axes[0, 1].set_xlabel('p')
axes[0, 1].set_ylabel('å°¤åº¦')
axes[0, 1].set_title(f'å°¤åº¦é–¢æ•° Bin({n_success}|{n_trials}, p)')
axes[0, 1].legend()
axes[0, 1].grid(True, alpha=0.3)

# äº‹å¾Œåˆ†å¸ƒ
axes[1, 0].plot(p_values, posterior_pdf, 'r-', linewidth=2)
axes[1, 0].fill_between(p_values, 0, posterior_pdf, alpha=0.3, color='red')
axes[1, 0].axvline(alpha_post/(alpha_post+beta_post), color='blue',
                   linestyle='--', linewidth=2, label='äº‹å¾Œå¹³å‡')
axes[1, 0].axvspan(ci_lower, ci_upper, alpha=0.2, color='yellow',
                   label='95%ä¿¡ç”¨åŒºé–“')
axes[1, 0].set_xlabel('p')
axes[1, 0].set_ylabel('ç¢ºç‡å¯†åº¦')
axes[1, 0].set_title(f'äº‹å¾Œåˆ†å¸ƒ Beta({alpha_post}, {beta_post})')
axes[1, 0].legend()
axes[1, 0].grid(True, alpha=0.3)

# 3ã¤ã®åˆ†å¸ƒã‚’é‡ã­ã¦è¡¨ç¤º
axes[1, 1].plot(p_values, prior_pdf / prior_pdf.max(), 'b-',
                linewidth=2, label='äº‹å‰åˆ†å¸ƒï¼ˆæ­£è¦åŒ–ï¼‰')
axes[1, 1].plot(p_values, likelihood / likelihood.max(), 'g--',
                linewidth=2, label='å°¤åº¦ï¼ˆæ­£è¦åŒ–ï¼‰')
axes[1, 1].plot(p_values, posterior_pdf / posterior_pdf.max(), 'r-',
                linewidth=2, label='äº‹å¾Œåˆ†å¸ƒï¼ˆæ­£è¦åŒ–ï¼‰')
axes[1, 1].axvline(mle, color='orange', linestyle=':', linewidth=2,
                   label=f'MLE: {mle:.2f}')
axes[1, 1].set_xlabel('p')
axes[1, 1].set_ylabel('æ­£è¦åŒ–ã•ã‚ŒãŸç¢ºç‡å¯†åº¦')
axes[1, 1].set_title('ãƒ™ã‚¤ã‚ºæ›´æ–°ã®å¯è¦–åŒ–')
axes[1, 1].legend()
axes[1, 1].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

# é€æ¬¡ãƒ™ã‚¤ã‚ºæ›´æ–°ã®ãƒ‡ãƒ¢
print("\n=== é€æ¬¡ãƒ™ã‚¤ã‚ºæ›´æ–° ===")
data_sequence = [1, 1, 0, 1, 1, 1, 0, 1, 1, 0]  # 1=è¡¨, 0=è£
alpha_seq = alpha_prior
beta_seq = beta_prior

print(f"åˆæœŸäº‹å‰åˆ†å¸ƒ: Beta({alpha_seq}, {beta_seq})")
for i, outcome in enumerate(data_sequence, 1):
    if outcome == 1:
        alpha_seq += 1
    else:
        beta_seq += 1
    mean = alpha_seq / (alpha_seq + beta_seq)
    print(f"  ãƒ‡ãƒ¼ã‚¿{i}ç‚¹å¾Œ: Beta({alpha_seq}, {beta_seq}), å¹³å‡={mean:.4f}")
</code></pre>
            </div>

            <div class="note">
                <strong>ğŸ“Œ ãƒ™ã‚¤ã‚ºæ¨è«– vs é »åº¦è«–çš„æ¨è«–</strong><br>
                <ul>
                    <li><strong>ãƒ™ã‚¤ã‚º</strong>: ã€ŒpãŒ0.6ï½0.8ã®ç¯„å›²ã«ã‚ã‚‹ç¢ºç‡ãŒ95%ã€ã¨è§£é‡ˆã§ãã‚‹</li>
                    <li><strong>é »åº¦è«–</strong>: ã€Œã“ã®ã‚ˆã†ãªåŒºé–“æ¨å®šã‚’100å›è¡Œãˆã°ã€95å›ã¯çœŸã®pã‚’å«ã‚€ã€</li>
                </ul>
                ãƒ™ã‚¤ã‚ºæ¨è«–ã¯ç¢ºç‡çš„è¨€æ˜ãŒç›´æ„Ÿçš„ã§ã€äº‹å‰çŸ¥è­˜ã‚’å½¢å¼çš„ã«çµ„ã¿è¾¼ã‚ã‚‹åˆ©ç‚¹ãŒã‚ã‚Šã¾ã™ã€‚
            </div>

            <h2>4.2 å…±å½¹äº‹å‰åˆ†å¸ƒ</h2>

            <div class="theory-box">
                <h4>ğŸ“˜ å…±å½¹äº‹å‰åˆ†å¸ƒã®æ€§è³ª</h4>
                <p>äº‹å‰åˆ†å¸ƒã¨äº‹å¾Œåˆ†å¸ƒãŒåŒã˜åˆ†å¸ƒæ—ã«å±ã™ã‚‹å ´åˆã€ãã®äº‹å‰åˆ†å¸ƒã‚’<strong>å…±å½¹äº‹å‰åˆ†å¸ƒ</strong>ã¨å‘¼ã³ã¾ã™ã€‚</p>
                
                <p><strong>ä¸»ãªå…±å½¹å¯¾ï¼š</strong></p>
                <ul>
                    <li>äºŒé …åˆ†å¸ƒã®å°¤åº¦ + Betaäº‹å‰åˆ†å¸ƒ â†’ Betaäº‹å¾Œåˆ†å¸ƒ</li>
                    <li>ãƒã‚¢ã‚½ãƒ³åˆ†å¸ƒã®å°¤åº¦ + Gammaäº‹å‰åˆ†å¸ƒ â†’ Gammaäº‹å¾Œåˆ†å¸ƒ</li>
                    <li>æ­£è¦åˆ†å¸ƒã®å°¤åº¦ï¼ˆæ—¢çŸ¥åˆ†æ•£ï¼‰+ æ­£è¦äº‹å‰åˆ†å¸ƒ â†’ æ­£è¦äº‹å¾Œåˆ†å¸ƒ</li>
                    <li>æ­£è¦åˆ†å¸ƒã®å°¤åº¦ï¼ˆæœªçŸ¥åˆ†æ•£ï¼‰+ Normal-Gammaäº‹å‰åˆ†å¸ƒ â†’ Normal-Gammaäº‹å¾Œåˆ†å¸ƒ</li>
                </ul>
                
                <p>å…±å½¹äº‹å‰åˆ†å¸ƒã‚’ä½¿ã†ã¨è§£æçš„ã«äº‹å¾Œåˆ†å¸ƒã‚’è¨ˆç®—ã§ãã€MCMCãŒä¸è¦ã«ãªã‚‹åˆ©ç‚¹ãŒã‚ã‚Šã¾ã™ã€‚</p>
            </div>

            <div class="example">
                <h4>ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹2: å…±å½¹äº‹å‰åˆ†å¸ƒï¼ˆBeta-Binomialï¼‰</h4>
                <pre><code>import numpy as np
import matplotlib.pyplot as plt
from scipy import stats

# æ§˜ã€…ãªäº‹å‰åˆ†å¸ƒã§ãƒ™ã‚¤ã‚ºæ›´æ–°ã‚’æ¯”è¼ƒ
n_trials = 20
n_success = 15

# 3ç¨®é¡ã®äº‹å‰åˆ†å¸ƒ
priors = [
    {"name": "ç„¡æƒ…å ± Uniform", "alpha": 1, "beta": 1},
    {"name": "å¼±æƒ…å ± Beta(2,2)", "alpha": 2, "beta": 2},
    {"name": "å¼·æƒ…å ± Beta(8,2)", "alpha": 8, "beta": 2}  # è¡¨ãŒå‡ºã‚„ã™ã„ã¨ä¿¡ã˜ã¦ã„ã‚‹
]

p_values = np.linspace(0, 1, 200)

fig, axes = plt.subplots(len(priors), 3, figsize=(15, 10))

for i, prior in enumerate(priors):
    alpha_pr = prior["alpha"]
    beta_pr = prior["beta"]
    alpha_po = alpha_pr + n_success
    beta_po = beta_pr + (n_trials - n_success)
    
    # äº‹å‰åˆ†å¸ƒ
    prior_pdf = stats.beta.pdf(p_values, alpha_pr, beta_pr)
    axes[i, 0].plot(p_values, prior_pdf, 'b-', linewidth=2)
    axes[i, 0].fill_between(p_values, 0, prior_pdf, alpha=0.3, color='blue')
    axes[i, 0].set_title(f'{prior["name"]}\nBeta({alpha_pr}, {beta_pr})')
    axes[i, 0].set_ylabel('ç¢ºç‡å¯†åº¦')
    axes[i, 0].grid(True, alpha=0.3)
    
    # å°¤åº¦
    likelihood = stats.binom.pmf(n_success, n_trials, p_values)
    axes[i, 1].plot(p_values, likelihood, 'g-', linewidth=2)
    axes[i, 1].fill_between(p_values, 0, likelihood, alpha=0.3, color='green')
    axes[i, 1].set_title(f'å°¤åº¦\nBin({n_success}|{n_trials}, p)')
    axes[i, 1].grid(True, alpha=0.3)
    
    # äº‹å¾Œåˆ†å¸ƒ
    posterior_pdf = stats.beta.pdf(p_values, alpha_po, beta_po)
    axes[i, 2].plot(p_values, posterior_pdf, 'r-', linewidth=2)
    axes[i, 2].fill_between(p_values, 0, posterior_pdf, alpha=0.3, color='red')
    post_mean = alpha_po / (alpha_po + beta_po)
    axes[i, 2].axvline(post_mean, color='blue', linestyle='--',
                       linewidth=2, label=f'å¹³å‡: {post_mean:.3f}')
    axes[i, 2].set_title(f'äº‹å¾Œåˆ†å¸ƒ\nBeta({alpha_po}, {beta_po})')
    axes[i, 2].legend()
    axes[i, 2].grid(True, alpha=0.3)
    
    if i == len(priors) - 1:
        axes[i, 0].set_xlabel('p')
        axes[i, 1].set_xlabel('p')
        axes[i, 2].set_xlabel('p')

plt.suptitle(f'äº‹å‰åˆ†å¸ƒã®é•ã„ã«ã‚ˆã‚‹äº‹å¾Œåˆ†å¸ƒã®å¤‰åŒ–ï¼ˆãƒ‡ãƒ¼ã‚¿: {n_trials}å›ä¸­{n_success}å›æˆåŠŸï¼‰',
             fontsize=14, y=1.00)
plt.tight_layout()
plt.show()

# æ•°å€¤çš„ã¾ã¨ã‚
print("=== äº‹å‰åˆ†å¸ƒã®å½±éŸ¿ ===")
print(f"ãƒ‡ãƒ¼ã‚¿: {n_trials}å›ä¸­{n_success}å›æˆåŠŸ (MLE={n_success/n_trials:.3f})\n")
for prior in priors:
    alpha_pr = prior["alpha"]
    beta_pr = prior["beta"]
    alpha_po = alpha_pr + n_success
    beta_po = beta_pr + (n_trials - n_success)
    
    prior_mean = alpha_pr / (alpha_pr + beta_pr)
    post_mean = alpha_po / (alpha_po + beta_po)
    
    print(f"{prior['name']}:")
    print(f"  äº‹å‰å¹³å‡: {prior_mean:.4f}")
    print(f"  äº‹å¾Œå¹³å‡: {post_mean:.4f}")
    print(f"  å¤‰åŒ–: {post_mean - prior_mean:+.4f}\n")
</code></pre>
            </div>

            <div class="example">
                <h4>ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹3: æ­£è¦åˆ†å¸ƒã®å…±å½¹äº‹å‰åˆ†å¸ƒ</h4>
                <pre><code>import numpy as np
import matplotlib.pyplot as plt
from scipy import stats

# æ­£è¦åˆ†å¸ƒãƒ‡ãƒ¼ã‚¿ã®å¹³å‡Î¼ã®æ¨å®šï¼ˆåˆ†æ•£ÏƒÂ²ã¯æ—¢çŸ¥ï¼‰
sigma_known = 10  # æ—¢çŸ¥ã®æ¨™æº–åå·®
n = 15
np.random.seed(42)
true_mu = 100
data = np.random.normal(true_mu, sigma_known, n)

# äº‹å‰åˆ†å¸ƒ: N(Î¼0, Ï„0Â²)
mu_0 = 95  # äº‹å‰å¹³å‡
tau_0 = 8  # äº‹å‰æ¨™æº–åå·®

# ãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆé‡
data_mean = np.mean(data)
data_se = sigma_known / np.sqrt(n)

# äº‹å¾Œåˆ†å¸ƒï¼ˆæ­£è¦åˆ†å¸ƒã®å…±å½¹æ€§ï¼‰
# ç²¾åº¦ï¼ˆåˆ†æ•£ã®é€†æ•°ï¼‰ã§ã®è¨ˆç®—ãŒä¾¿åˆ©
precision_prior = 1 / tau_0**2
precision_likelihood = n / sigma_known**2
precision_post = precision_prior + precision_likelihood

mu_post = (precision_prior * mu_0 + precision_likelihood * data_mean) / precision_post
tau_post = 1 / np.sqrt(precision_post)

print("=== æ­£è¦åˆ†å¸ƒã®å…±å½¹ãƒ™ã‚¤ã‚ºæ¨è«– ===")
print(f"ãƒ‡ãƒ¼ã‚¿: n={n}, æ¨™æœ¬å¹³å‡={data_mean:.2f}, æ—¢çŸ¥Ïƒ={sigma_known}")
print(f"\näº‹å‰åˆ†å¸ƒ: N({mu_0}, {tau_0}Â²)")
print(f"äº‹å¾Œåˆ†å¸ƒ: N({mu_post:.2f}, {tau_post:.2f}Â²)")
print(f"\né »åº¦è«–çš„æ¨å®š:")
print(f"  æ¨™æœ¬å¹³å‡: {data_mean:.2f}")
print(f"  æ¨™æº–èª¤å·®: {data_se:.2f}")

# å¯è¦–åŒ–
x = np.linspace(70, 120, 300)
prior_pdf = stats.norm.pdf(x, mu_0, tau_0)
likelihood_pdf = stats.norm.pdf(x, data_mean, data_se)
posterior_pdf = stats.norm.pdf(x, mu_post, tau_post)

fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# åˆ†å¸ƒã®é‡ã­åˆã‚ã›
axes[0].plot(x, prior_pdf, 'b-', linewidth=2, label=f'äº‹å‰åˆ†å¸ƒ N({mu_0}, {tau_0}Â²)')
axes[0].plot(x, likelihood_pdf, 'g--', linewidth=2,
             label=f'å°¤åº¦ N({data_mean:.1f}, {data_se:.1f}Â²)')
axes[0].plot(x, posterior_pdf, 'r-', linewidth=2,
             label=f'äº‹å¾Œåˆ†å¸ƒ N({mu_post:.1f}, {tau_post:.1f}Â²)')
axes[0].axvline(true_mu, color='black', linestyle=':', linewidth=2,
                label=f'çœŸã®å€¤: {true_mu}')
axes[0].set_xlabel('Î¼')
axes[0].set_ylabel('ç¢ºç‡å¯†åº¦')
axes[0].set_title('æ­£è¦åˆ†å¸ƒã®å…±å½¹ãƒ™ã‚¤ã‚ºæ¨è«–')
axes[0].legend()
axes[0].grid(True, alpha=0.3)

# ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã®å½±éŸ¿
sample_sizes = [5, 10, 20, 50, 100]
post_means = []
post_stds = []

np.random.seed(42)
for ns in sample_sizes:
    data_temp = np.random.normal(true_mu, sigma_known, ns)
    dm = np.mean(data_temp)
    prec_lik = ns / sigma_known**2
    prec_po = precision_prior + prec_lik
    mu_po = (precision_prior * mu_0 + prec_lik * dm) / prec_po
    tau_po = 1 / np.sqrt(prec_po)
    post_means.append(mu_po)
    post_stds.append(tau_po)

axes[1].errorbar(sample_sizes, post_means,
                 yerr=[2*s for s in post_stds],
                 fmt='o-', markersize=8, capsize=8, linewidth=2,
                 label='äº‹å¾Œå¹³å‡Â±2SD')
axes[1].axhline(mu_0, color='blue', linestyle='--', linewidth=2,
                label=f'äº‹å‰å¹³å‡: {mu_0}')
axes[1].axhline(true_mu, color='red', linestyle='--', linewidth=2,
                label=f'çœŸã®å€¤: {true_mu}')
axes[1].set_xlabel('ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º n')
axes[1].set_ylabel('Î¼ã®æ¨å®šå€¤')
axes[1].set_title('ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã®å½±éŸ¿ï¼ˆäº‹å‰åˆ†å¸ƒã‹ã‚‰çœŸã®å€¤ã¸ã®åæŸï¼‰')
axes[1].legend()
axes[1].grid(True, alpha=0.3)
axes[1].set_xscale('log')

plt.tight_layout()
plt.show()
</code></pre>
            </div>

            <h2>4.3 Markov Chain Monte Carlo (MCMC)</h2>

            <p>
                è¤‡é›‘ãªäº‹å¾Œåˆ†å¸ƒã¯è§£æçš„ã«è¨ˆç®—ã§ããªã„ã“ã¨ãŒå¤šãã€ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ‰‹æ³•ãŒå¿…è¦ã§ã™ã€‚
                MCMCã¯ãƒãƒ«ã‚³ãƒ•é€£é–ã‚’ç”¨ã„ã¦äº‹å¾Œåˆ†å¸ƒã‹ã‚‰ã‚µãƒ³ãƒ—ãƒ«ã‚’ç”Ÿæˆã™ã‚‹æ‰‹æ³•ã§ã™ã€‚
            </p>

            <div class="theory-box">
                <h4>ğŸ“˜ Metropolis-Hastingsæ³•</h4>
                <p>ä»»æ„ã®ç¢ºç‡åˆ†å¸ƒ \( p(\theta) \) ã‹ã‚‰ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã™ã‚‹æ±ç”¨çš„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ï¼š</p>
                <ol>
                    <li>ç¾åœ¨ã®çŠ¶æ…‹ \( \theta^{(t)} \) ã‹ã‚‰ææ¡ˆåˆ†å¸ƒ \( q(\theta^* | \theta^{(t)}) \) ã§å€™è£œ \( \theta^* \) ã‚’ç”Ÿæˆ</li>
                    <li>å—ç†ç¢ºç‡ã‚’è¨ˆç®—ï¼š
                        <div class="formula">
                            $$ \alpha = \min\left(1, \frac{p(\theta^*) q(\theta^{(t)} | \theta^*)}{p(\theta^{(t)}) q(\theta^* | \theta^{(t)})}\right) $$
                        </div>
                    </li>
                    <li>ç¢ºç‡ \( \alpha \) ã§å€™è£œã‚’å—ç†ï¼ˆ\( \theta^{(t+1)} = \theta^* \)ï¼‰ã€ã•ã‚‚ãªãã°æ£„å´ï¼ˆ\( \theta^{(t+1)} = \theta^{(t)} \)ï¼‰</li>
                </ol>
                <p>å¯¾ç§°ææ¡ˆåˆ†å¸ƒï¼ˆ\( q(\theta^* | \theta) = q(\theta | \theta^*) \)ï¼‰ã®å ´åˆã€å—ç†ç¢ºç‡ã¯ï¼š</p>
                <div class="formula">
                    $$ \alpha = \min\left(1, \frac{p(\theta^*)}{p(\theta^{(t)})}\right) $$
                </div>
            </div>

            <div class="example">
                <h4>ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹4: Metropolis-Hastingsæ³•ã®å®Ÿè£…</h4>
                <pre><code>import numpy as np
import matplotlib.pyplot as plt
from scipy import stats

# ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ†å¸ƒ: 2ã¤ã®æ­£è¦åˆ†å¸ƒã®æ··åˆï¼ˆè§£æçš„ã«æ‰±ã„ã«ãã„ä¾‹ï¼‰
def target_distribution(theta):
    """æ··åˆæ­£è¦åˆ†å¸ƒ 0.3*N(0,1) + 0.7*N(5,1.5)"""
    component1 = 0.3 * stats.norm.pdf(theta, 0, 1)
    component2 = 0.7 * stats.norm.pdf(theta, 5, 1.5)
    return component1 + component2

# Metropolis-Hastingsã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 
def metropolis_hastings(target_func, n_samples, proposal_std=1.0, initial=0):
    samples = np.zeros(n_samples)
    samples[0] = initial
    n_accept = 0
    
    for t in range(1, n_samples):
        current = samples[t-1]
        
        # ææ¡ˆï¼ˆå¯¾ç§°æ­£è¦åˆ†å¸ƒï¼‰
        proposal = current + np.random.normal(0, proposal_std)
        
        # å—ç†ç¢ºç‡
        p_current = target_func(current)
        p_proposal = target_func(proposal)
        alpha = min(1, p_proposal / p_current) if p_current > 0 else 1
        
        # å—ç†ãƒ»æ£„å´ã®åˆ¤å®š
        if np.random.rand() < alpha:
            samples[t] = proposal
            n_accept += 1
        else:
            samples[t] = current
    
    acceptance_rate = n_accept / (n_samples - 1)
    return samples, acceptance_rate

# MCMCã®å®Ÿè¡Œ
np.random.seed(42)
n_samples = 10000
samples, acc_rate = metropolis_hastings(target_distribution, n_samples,
                                        proposal_std=2.0, initial=0)

print("=== Metropolis-Hastingsæ³• ===")
print(f"ã‚µãƒ³ãƒ—ãƒ«æ•°: {n_samples}")
print(f"å—ç†ç‡: {acc_rate:.3f}")
print(f"ãƒãƒ¼ãƒ³ã‚¤ãƒ³å¾Œã®å¹³å‡: {np.mean(samples[1000:]):.4f}")
print(f"ãƒãƒ¼ãƒ³ã‚¤ãƒ³å¾Œã®æ¨™æº–åå·®: {np.std(samples[1000:]):.4f}")

# å¯è¦–åŒ–
fig, axes = plt.subplots(2, 2, figsize=(14, 10))

# ãƒˆãƒ¬ãƒ¼ã‚¹ãƒ—ãƒ­ãƒƒãƒˆ
axes[0, 0].plot(samples[:500], 'b-', linewidth=0.5, alpha=0.7)
axes[0, 0].axhline(0, color='red', linestyle='--', linewidth=1, alpha=0.5)
axes[0, 0].axhline(5, color='green', linestyle='--', linewidth=1, alpha=0.5)
axes[0, 0].set_xlabel('ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³')
axes[0, 0].set_ylabel('Î¸')
axes[0, 0].set_title(f'ãƒˆãƒ¬ãƒ¼ã‚¹ãƒ—ãƒ­ãƒƒãƒˆï¼ˆæœ€åˆã®500ã‚µãƒ³ãƒ—ãƒ«ï¼‰\nå—ç†ç‡: {acc_rate:.2%}')
axes[0, 0].grid(True, alpha=0.3)

# ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ã¨çœŸã®åˆ†å¸ƒ
burnin = 1000
x = np.linspace(-5, 10, 300)
true_pdf = target_distribution(x)

axes[0, 1].hist(samples[burnin:], bins=60, density=True, alpha=0.7,
                color='skyblue', edgecolor='black', label='MCMCã‚µãƒ³ãƒ—ãƒ«')
axes[0, 1].plot(x, true_pdf, 'r-', linewidth=2, label='çœŸã®åˆ†å¸ƒ')
axes[0, 1].set_xlabel('Î¸')
axes[0, 1].set_ylabel('ç¢ºç‡å¯†åº¦')
axes[0, 1].set_title(f'äº‹å¾Œåˆ†å¸ƒã®æ¨å®šï¼ˆãƒãƒ¼ãƒ³ã‚¤ãƒ³: {burnin}ã‚µãƒ³ãƒ—ãƒ«ï¼‰')
axes[0, 1].legend()
axes[0, 1].grid(True, alpha=0.3)

# è‡ªå·±ç›¸é–¢
from statsmodels.graphics.tsaplots import plot_acf
plot_acf(samples[burnin:], lags=50, ax=axes[1, 0], alpha=0.05)
axes[1, 0].set_title('è‡ªå·±ç›¸é–¢é–¢æ•°ï¼ˆåæŸã¨ç‹¬ç«‹æ€§ã®ç¢ºèªï¼‰')
axes[1, 0].grid(True, alpha=0.3)

# ææ¡ˆåˆ†å¸ƒã®æ¨™æº–åå·®ã®å½±éŸ¿
proposal_stds = [0.1, 0.5, 1.0, 2.0, 5.0]
acceptance_rates = []

for pstd in proposal_stds:
    _, ar = metropolis_hastings(target_distribution, 5000,
                                proposal_std=pstd, initial=0)
    acceptance_rates.append(ar)

axes[1, 1].plot(proposal_stds, acceptance_rates, 'bo-',
                markersize=8, linewidth=2)
axes[1, 1].axhline(0.234, color='red', linestyle='--', linewidth=2,
                   label='ç†æƒ³çš„å—ç†ç‡ (â‰ˆ23.4%)')
axes[1, 1].set_xlabel('ææ¡ˆåˆ†å¸ƒã®æ¨™æº–åå·®')
axes[1, 1].set_ylabel('å—ç†ç‡')
axes[1, 1].set_title('ææ¡ˆåˆ†å¸ƒã®ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°')
axes[1, 1].legend()
axes[1, 1].grid(True, alpha=0.3)
axes[1, 1].set_xscale('log')

plt.tight_layout()
plt.show()
</code></pre>
            </div>

            <div class="note">
                <strong>ğŸ“Œ MCMCã®å®Ÿè·µçš„ãƒã‚¤ãƒ³ãƒˆ</strong><br>
                <ul>
                    <li><strong>ãƒãƒ¼ãƒ³ã‚¤ãƒ³</strong>: åˆæœŸå€¤ã®å½±éŸ¿ã‚’é™¤ããŸã‚ã€æœ€åˆã®æ•°åƒã‚µãƒ³ãƒ—ãƒ«ã‚’æ¨ã¦ã‚‹</li>
                    <li><strong>å—ç†ç‡</strong>: 20ï½40%ãŒç›®å®‰ï¼ˆä½ã™ãã‚‹ã¨åæŸé…ã„ã€é«˜ã™ãã‚‹ã¨æ¢ç´¢ä¸ååˆ†ï¼‰</li>
                    <li><strong>è‡ªå·±ç›¸é–¢</strong>: ã‚µãƒ³ãƒ—ãƒ«é–“ã®ç‹¬ç«‹æ€§ã‚’ç¢ºèªï¼ˆé«˜ã„å ´åˆã¯é–“å¼•ãï¼‰</li>
                    <li><strong>åæŸè¨ºæ–­</strong>: è¤‡æ•°ãƒã‚§ãƒ¼ãƒ³ã€Gelman-Rubinçµ±è¨ˆé‡ã€ãƒˆãƒ¬ãƒ¼ã‚¹ãƒ—ãƒ­ãƒƒãƒˆ</li>
                </ul>
            </div>

            <div class="example">
                <h4>ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹5: Gibbs Samplingã«ã‚ˆã‚‹ãƒ™ã‚¤ã‚ºæ¨è«–</h4>
                <pre><code>import numpy as np
import matplotlib.pyplot as plt
from scipy import stats

# 2å¤‰æ•°ã®åŒæ™‚åˆ†å¸ƒã‹ã‚‰ã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
# ä¾‹: æ­£è¦åˆ†å¸ƒã®å¹³å‡Î¼ã¨ç²¾åº¦Ï„ï¼ˆåˆ†æ•£ã®é€†æ•°ï¼‰ã‚’åŒæ™‚æ¨å®š

# ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
np.random.seed(42)
true_mu = 50
true_sigma = 10
n = 30
data = np.random.normal(true_mu, true_sigma, n)

# äº‹å‰åˆ†å¸ƒã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
# Î¼ ~ N(Î¼0, (Î»0*Ï„)^{-1})
mu_0 = 45
lambda_0 = 0.1

# Ï„ ~ Gamma(Î±0, Î²0)
alpha_0 = 2
beta_0 = 20

# Gibbs Sampling
def gibbs_sampling_normal(data, n_iter=5000, burnin=1000):
    n = len(data)
    data_mean = np.mean(data)
    data_sum_sq = np.sum((data - data_mean)**2)
    
    # åˆæœŸå€¤
    mu = data_mean
    tau = 1 / np.var(data)
    
    # ã‚µãƒ³ãƒ—ãƒ«ä¿å­˜
    mu_samples = np.zeros(n_iter)
    tau_samples = np.zeros(n_iter)
    
    for i in range(n_iter):
        # Î¼ã®æ¡ä»¶ä»˜ãäº‹å¾Œåˆ†å¸ƒã‹ã‚‰ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
        lambda_n = lambda_0 + n * tau
        mu_n = (lambda_0 * mu_0 + n * tau * data_mean) / lambda_n
        mu = np.random.normal(mu_n, 1/np.sqrt(lambda_n))
        
        # Ï„ã®æ¡ä»¶ä»˜ãäº‹å¾Œåˆ†å¸ƒã‹ã‚‰ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
        alpha_n = alpha_0 + n/2
        beta_n = beta_0 + 0.5 * (np.sum((data - mu)**2) + lambda_0 * (mu - mu_0)**2)
        tau = np.random.gamma(alpha_n, 1/beta_n)
        
        mu_samples[i] = mu
        tau_samples[i] = tau
    
    return mu_samples[burnin:], tau_samples[burnin:]

# Gibbs Samplingã®å®Ÿè¡Œ
mu_samples, tau_samples = gibbs_sampling_normal(data, n_iter=10000, burnin=2000)
sigma_samples = 1 / np.sqrt(tau_samples)

print("=== Gibbs Sampling: æ­£è¦åˆ†å¸ƒã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¨å®š ===")
print(f"ãƒ‡ãƒ¼ã‚¿: n={n}, æ¨™æœ¬å¹³å‡={np.mean(data):.2f}, æ¨™æœ¬SD={np.std(data):.2f}")
print(f"çœŸã®å€¤: Î¼={true_mu}, Ïƒ={true_sigma}")
print(f"\näº‹å¾Œæ¨å®šï¼ˆå¹³å‡ï¼‰:")
print(f"  Î¼: {np.mean(mu_samples):.2f} (95%CI: [{np.percentile(mu_samples, 2.5):.2f}, {np.percentile(mu_samples, 97.5):.2f}])")
print(f"  Ïƒ: {np.mean(sigma_samples):.2f} (95%CI: [{np.percentile(sigma_samples, 2.5):.2f}, {np.percentile(sigma_samples, 97.5):.2f}])")

# å¯è¦–åŒ–
fig, axes = plt.subplots(2, 3, figsize=(16, 10))

# Î¼ã®ãƒˆãƒ¬ãƒ¼ã‚¹ãƒ—ãƒ­ãƒƒãƒˆ
axes[0, 0].plot(mu_samples[:1000], 'b-', linewidth=0.5, alpha=0.7)
axes[0, 0].axhline(true_mu, color='red', linestyle='--', linewidth=2)
axes[0, 0].set_xlabel('ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³')
axes[0, 0].set_ylabel('Î¼')
axes[0, 0].set_title('Î¼ã®ãƒˆãƒ¬ãƒ¼ã‚¹ãƒ—ãƒ­ãƒƒãƒˆ')
axes[0, 0].grid(True, alpha=0.3)

# Î¼ã®äº‹å¾Œåˆ†å¸ƒ
axes[0, 1].hist(mu_samples, bins=50, density=True, alpha=0.7,
                color='skyblue', edgecolor='black')
axes[0, 1].axvline(true_mu, color='red', linestyle='--',
                   linewidth=2, label=f'çœŸã®å€¤: {true_mu}')
axes[0, 1].axvline(np.mean(mu_samples), color='blue', linestyle='-',
                   linewidth=2, label=f'äº‹å¾Œå¹³å‡: {np.mean(mu_samples):.1f}')
axes[0, 1].set_xlabel('Î¼')
axes[0, 1].set_ylabel('ç¢ºç‡å¯†åº¦')
axes[0, 1].set_title('Î¼ã®äº‹å¾Œåˆ†å¸ƒ')
axes[0, 1].legend()
axes[0, 1].grid(True, alpha=0.3)

# Ïƒã®ãƒˆãƒ¬ãƒ¼ã‚¹ãƒ—ãƒ­ãƒƒãƒˆ
axes[0, 2].plot(sigma_samples[:1000], 'g-', linewidth=0.5, alpha=0.7)
axes[0, 2].axhline(true_sigma, color='red', linestyle='--', linewidth=2)
axes[0, 2].set_xlabel('ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³')
axes[0, 2].set_ylabel('Ïƒ')
axes[0, 2].set_title('Ïƒã®ãƒˆãƒ¬ãƒ¼ã‚¹ãƒ—ãƒ­ãƒƒãƒˆ')
axes[0, 2].grid(True, alpha=0.3)

# Ïƒã®äº‹å¾Œåˆ†å¸ƒ
axes[1, 0].hist(sigma_samples, bins=50, density=True, alpha=0.7,
                color='lightgreen', edgecolor='black')
axes[1, 0].axvline(true_sigma, color='red', linestyle='--',
                   linewidth=2, label=f'çœŸã®å€¤: {true_sigma}')
axes[1, 0].axvline(np.mean(sigma_samples), color='green', linestyle='-',
                   linewidth=2, label=f'äº‹å¾Œå¹³å‡: {np.mean(sigma_samples):.1f}')
axes[1, 0].set_xlabel('Ïƒ')
axes[1, 0].set_ylabel('ç¢ºç‡å¯†åº¦')
axes[1, 0].set_title('Ïƒã®äº‹å¾Œåˆ†å¸ƒ')
axes[1, 0].legend()
axes[1, 0].grid(True, alpha=0.3)

# åŒæ™‚äº‹å¾Œåˆ†å¸ƒ
axes[1, 1].hexbin(mu_samples, sigma_samples, gridsize=50, cmap='Blues')
axes[1, 1].plot(true_mu, true_sigma, 'r*', markersize=15, label='çœŸã®å€¤')
axes[1, 1].set_xlabel('Î¼')
axes[1, 1].set_ylabel('Ïƒ')
axes[1, 1].set_title('Î¼ã¨Ïƒã®åŒæ™‚äº‹å¾Œåˆ†å¸ƒ')
axes[1, 1].legend()
axes[1, 1].grid(True, alpha=0.3)

# äº‹å¾Œäºˆæ¸¬åˆ†å¸ƒ
n_pred = 1000
pred_samples = np.random.normal(mu_samples[:n_pred], sigma_samples[:n_pred])

axes[1, 2].hist(data, bins=15, density=True, alpha=0.5,
                color='orange', edgecolor='black', label='è¦³æ¸¬ãƒ‡ãƒ¼ã‚¿')
axes[1, 2].hist(pred_samples, bins=50, density=True, alpha=0.5,
                color='skyblue', edgecolor='black', label='äº‹å¾Œäºˆæ¸¬åˆ†å¸ƒ')
axes[1, 2].set_xlabel('å€¤')
axes[1, 2].set_ylabel('å¯†åº¦')
axes[1, 2].set_title('äº‹å¾Œäºˆæ¸¬åˆ†å¸ƒ')
axes[1, 2].legend()
axes[1, 2].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
</code></pre>
            </div>

            <h2>4.4 PyMC3ã«ã‚ˆã‚‹ãƒ™ã‚¤ã‚ºæ¨è«–</h2>

            <div class="example">
                <h4>ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹6: PyMC3ã‚’ç”¨ã„ãŸãƒ™ã‚¤ã‚ºæ¨è«–</h4>
                <pre><code>import numpy as np
import matplotlib.pyplot as plt
import pymc3 as pm
import arviz as az

# ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
np.random.seed(42)
true_alpha = 2.5
true_beta = 1.5
n = 50
x = np.linspace(0, 10, n)
y_true = true_alpha + true_beta * x
y = y_true + np.random.normal(0, 2, n)

print("=== PyMC3ã«ã‚ˆã‚‹ãƒ™ã‚¤ã‚ºç·šå½¢å›å¸° ===")
print(f"ãƒ‡ãƒ¼ã‚¿æ•°: {n}")
print(f"çœŸã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: Î±={true_alpha}, Î²={true_beta}")

# PyMC3ãƒ¢ãƒ‡ãƒ«ã®å®šç¾©
with pm.Model() as model:
    # äº‹å‰åˆ†å¸ƒ
    alpha = pm.Normal('alpha', mu=0, sd=10)
    beta = pm.Normal('beta', mu=0, sd=10)
    sigma = pm.HalfNormal('sigma', sd=5)
    
    # å°¤åº¦
    mu = alpha + beta * x
    y_obs = pm.Normal('y_obs', mu=mu, sd=sigma, observed=y)
    
    # ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
    trace = pm.sample(2000, tune=1000, return_inferencedata=True,
                      random_seed=42, progressbar=False)

# çµæœã®ã‚µãƒãƒªãƒ¼
print("\näº‹å¾Œåˆ†å¸ƒã®ã‚µãƒãƒªãƒ¼:")
print(az.summary(trace, var_names=['alpha', 'beta', 'sigma']))

# å¯è¦–åŒ–
fig, axes = plt.subplots(2, 2, figsize=(14, 10))

# ãƒ‡ãƒ¼ã‚¿ã¨å›å¸°ç›´ç·š
axes[0, 0].scatter(x, y, alpha=0.5, color='blue', s=50, label='ãƒ‡ãƒ¼ã‚¿')
axes[0, 0].plot(x, y_true, 'r-', linewidth=2, label=f'çœŸã®ç›´ç·š')

# äº‹å¾Œåˆ†å¸ƒã‹ã‚‰ã®å›å¸°ç›´ç·šã‚µãƒ³ãƒ—ãƒ«
alpha_samples = trace.posterior['alpha'].values.flatten()
beta_samples = trace.posterior['beta'].values.flatten()

for i in np.random.choice(len(alpha_samples), 100):
    y_pred = alpha_samples[i] + beta_samples[i] * x
    axes[0, 0].plot(x, y_pred, 'gray', alpha=0.05)

# äº‹å¾Œå¹³å‡ã®å›å¸°ç›´ç·š
y_mean = np.mean(alpha_samples) + np.mean(beta_samples) * x
axes[0, 0].plot(x, y_mean, 'g--', linewidth=2,
                label=f'äº‹å¾Œå¹³å‡ç›´ç·š')
axes[0, 0].set_xlabel('x')
axes[0, 0].set_ylabel('y')
axes[0, 0].set_title('ãƒ™ã‚¤ã‚ºç·šå½¢å›å¸°')
axes[0, 0].legend()
axes[0, 0].grid(True, alpha=0.3)

# äº‹å¾Œåˆ†å¸ƒï¼ˆÎ±, Î², Ïƒï¼‰
az.plot_posterior(trace, var_names=['alpha', 'beta', 'sigma'],
                  ref_val=[true_alpha, true_beta, 2], ax=axes[0, 1])
axes[0, 1].set_title('ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®äº‹å¾Œåˆ†å¸ƒ')

# ãƒˆãƒ¬ãƒ¼ã‚¹ãƒ—ãƒ­ãƒƒãƒˆ
az.plot_trace(trace, var_names=['alpha', 'beta', 'sigma'],
              compact=False)
plt.suptitle('ãƒˆãƒ¬ãƒ¼ã‚¹ãƒ—ãƒ­ãƒƒãƒˆï¼ˆåæŸè¨ºæ–­ï¼‰', y=1.02)

plt.tight_layout()
plt.show()

# äº‹å¾Œäºˆæ¸¬ãƒã‚§ãƒƒã‚¯
with model:
    ppc = pm.sample_posterior_predictive(trace, random_seed=42)

fig, ax = plt.subplots(figsize=(10, 6))
az.plot_ppc(az.from_pymc3(posterior_predictive=ppc, model=model), ax=ax)
ax.set_title('äº‹å¾Œäºˆæ¸¬ãƒã‚§ãƒƒã‚¯ï¼ˆãƒ¢ãƒ‡ãƒ«ã®é©åˆåº¦ç¢ºèªï¼‰')
plt.tight_layout()
plt.show()

print("\nGelman-Rubinçµ±è¨ˆé‡ï¼ˆåæŸè¨ºæ–­ã€1.0ã«è¿‘ã„ã»ã©è‰¯ã„ï¼‰:")
print(az.rhat(trace))
</code></pre>
            </div>

            <h2>4.5 ææ–™ç‰¹æ€§ã®ãƒ™ã‚¤ã‚ºæ¨å®š</h2>

            <div class="example">
                <h4>ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹7: ææ–™å¼·åº¦ãƒ‡ãƒ¼ã‚¿ã®ãƒ™ã‚¤ã‚ºæ¨å®šã¨äºˆæ¸¬</h4>
                <pre><code>import numpy as np
import matplotlib.pyplot as plt
import pymc3 as pm
import arviz as az
from scipy import stats

# ææ–™å¼·åº¦ãƒ‡ãƒ¼ã‚¿ï¼ˆå°‘æ•°ã‚µãƒ³ãƒ—ãƒ«ï¼‰
np.random.seed(42)
n_samples = 15
true_mean = 480
true_std = 25
strength_data = np.random.normal(true_mean, true_std, n_samples)

print("=== ææ–™å¼·åº¦ã®ãƒ™ã‚¤ã‚ºæ¨å®š ===")
print(f"ãƒ‡ãƒ¼ã‚¿æ•°: {n_samples}ï¼ˆå°‘æ•°ã‚µãƒ³ãƒ—ãƒ«ï¼‰")
print(f"æ¨™æœ¬å¹³å‡: {np.mean(strength_data):.2f} MPa")
print(f"æ¨™æœ¬SD: {np.std(strength_data, ddof=1):.2f} MPa")

# PyMC3ãƒ¢ãƒ‡ãƒ«
with pm.Model() as strength_model:
    # äº‹å‰åˆ†å¸ƒï¼ˆéå»ã®çµŒé¨“ã‹ã‚‰ï¼‰
    mu = pm.Normal('mu', mu=500, sd=50)  # éå»ã®ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰500Â±50 MPaç¨‹åº¦
    sigma = pm.HalfNormal('sigma', sd=30)  # ã°ã‚‰ã¤ãã¯æœ€å¤§30 MPaç¨‹åº¦
    
    # å°¤åº¦
    y_obs = pm.Normal('y_obs', mu=mu, sd=sigma, observed=strength_data)
    
    # ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
    trace = pm.sample(3000, tune=1500, return_inferencedata=True,
                      random_seed=42, progressbar=False)

# çµæœ
mu_samples = trace.posterior['mu'].values.flatten()
sigma_samples = trace.posterior['sigma'].values.flatten()

mu_mean = np.mean(mu_samples)
mu_ci = np.percentile(mu_samples, [2.5, 97.5])
sigma_mean = np.mean(sigma_samples)
sigma_ci = np.percentile(sigma_samples, [2.5, 97.5])

print(f"\nãƒ™ã‚¤ã‚ºæ¨å®šçµæœ:")
print(f"  å¹³å‡å¼·åº¦Î¼: {mu_mean:.2f} MPa (95%CI: [{mu_ci[0]:.2f}, {mu_ci[1]:.2f}])")
print(f"  æ¨™æº–åå·®Ïƒ: {sigma_mean:.2f} MPa (95%CI: [{sigma_ci[0]:.2f}, {sigma_ci[1]:.2f}])")

# é »åº¦è«–çš„æ¨å®šã¨ã®æ¯”è¼ƒ
freq_mean = np.mean(strength_data)
freq_std = np.std(strength_data, ddof=1)
freq_ci = stats.t.interval(0.95, n_samples-1,
                            loc=freq_mean,
                            scale=freq_std/np.sqrt(n_samples))

print(f"\né »åº¦è«–çš„æ¨å®šï¼ˆå‚è€ƒï¼‰:")
print(f"  å¹³å‡å¼·åº¦: {freq_mean:.2f} MPa (95%CI: [{freq_ci[0]:.2f}, {freq_ci[1]:.2f}])")
print(f"  æ¨™æº–åå·®: {freq_std:.2f} MPa")

# äº‹å¾Œäºˆæ¸¬åˆ†å¸ƒï¼ˆæ¬¡ã®ã‚µãƒ³ãƒ—ãƒ«ã®å¼·åº¦äºˆæ¸¬ï¼‰
n_pred = 5000
idx_random = np.random.choice(len(mu_samples), n_pred)
predicted_strength = np.random.normal(mu_samples[idx_random],
                                      sigma_samples[idx_random])

pred_mean = np.mean(predicted_strength)
pred_ci = np.percentile(predicted_strength, [2.5, 97.5])

print(f"\næ¬¡ã®ã‚µãƒ³ãƒ—ãƒ«ã®å¼·åº¦äºˆæ¸¬ï¼ˆäº‹å¾Œäºˆæ¸¬åˆ†å¸ƒï¼‰:")
print(f"  äºˆæ¸¬å¹³å‡: {pred_mean:.2f} MPa")
print(f"  95%äºˆæ¸¬åŒºé–“: [{pred_ci[0]:.2f}, {pred_ci[1]:.2f}] MPa")

# ç ´å£Šç¢ºç‡ã®æ¨å®š
design_strength = 450  # è¨­è¨ˆåŸºæº–å¼·åº¦
prob_failure = np.mean(predicted_strength < design_strength)
print(f"\nè¨­è¨ˆåŸºæº–å¼·åº¦{design_strength} MPaä»¥ä¸‹ã®ç¢ºç‡: {prob_failure:.4f} ({prob_failure*100:.2f}%)")

# å¯è¦–åŒ–
fig = plt.figure(figsize=(16, 10))
gs = fig.add_gridspec(3, 2, hspace=0.3, wspace=0.3)

# äº‹å¾Œåˆ†å¸ƒï¼ˆÎ¼, Ïƒï¼‰
ax1 = fig.add_subplot(gs[0, 0])
ax1.hist(mu_samples, bins=50, density=True, alpha=0.7,
         color='skyblue', edgecolor='black')
ax1.axvline(true_mean, color='red', linestyle='--',
            linewidth=2, label=f'çœŸã®å€¤: {true_mean}')
ax1.axvline(mu_mean, color='blue', linestyle='-',
            linewidth=2, label=f'äº‹å¾Œå¹³å‡: {mu_mean:.1f}')
ax1.axvspan(mu_ci[0], mu_ci[1], alpha=0.2, color='blue',
            label='95%ä¿¡ç”¨åŒºé–“')
ax1.set_xlabel('å¹³å‡å¼·åº¦Î¼ [MPa]')
ax1.set_ylabel('ç¢ºç‡å¯†åº¦')
ax1.set_title('å¹³å‡å¼·åº¦ã®äº‹å¾Œåˆ†å¸ƒ')
ax1.legend()
ax1.grid(True, alpha=0.3)

ax2 = fig.add_subplot(gs[0, 1])
ax2.hist(sigma_samples, bins=50, density=True, alpha=0.7,
         color='lightgreen', edgecolor='black')
ax2.axvline(true_std, color='red', linestyle='--',
            linewidth=2, label=f'çœŸã®å€¤: {true_std}')
ax2.axvline(sigma_mean, color='green', linestyle='-',
            linewidth=2, label=f'äº‹å¾Œå¹³å‡: {sigma_mean:.1f}')
ax2.set_xlabel('æ¨™æº–åå·®Ïƒ [MPa]')
ax2.set_ylabel('ç¢ºç‡å¯†åº¦')
ax2.set_title('æ¨™æº–åå·®ã®äº‹å¾Œåˆ†å¸ƒ')
ax2.legend()
ax2.grid(True, alpha=0.3)

# åŒæ™‚äº‹å¾Œåˆ†å¸ƒ
ax3 = fig.add_subplot(gs[1, :])
ax3.hexbin(mu_samples, sigma_samples, gridsize=50, cmap='Blues')
ax3.plot(true_mean, true_std, 'r*', markersize=20, label='çœŸã®å€¤')
ax3.set_xlabel('Î¼ [MPa]')
ax3.set_ylabel('Ïƒ [MPa]')
ax3.set_title('Î¼ã¨Ïƒã®åŒæ™‚äº‹å¾Œåˆ†å¸ƒ')
ax3.legend()
ax3.grid(True, alpha=0.3)

# äº‹å¾Œäºˆæ¸¬åˆ†å¸ƒã¨è¦³æ¸¬ãƒ‡ãƒ¼ã‚¿
ax4 = fig.add_subplot(gs[2, 0])
ax4.hist(predicted_strength, bins=60, density=True, alpha=0.6,
         color='lightblue', edgecolor='black', label='äº‹å¾Œäºˆæ¸¬åˆ†å¸ƒ')
ax4.hist(strength_data, bins=10, density=True, alpha=0.6,
         color='orange', edgecolor='black', label='è¦³æ¸¬ãƒ‡ãƒ¼ã‚¿')
ax4.axvline(design_strength, color='red', linestyle='--',
            linewidth=2, label=f'è¨­è¨ˆåŸºæº–: {design_strength} MPa')
ax4.axvspan(pred_ci[0], pred_ci[1], alpha=0.2, color='green',
            label='95%äºˆæ¸¬åŒºé–“')
ax4.set_xlabel('å¼·åº¦ [MPa]')
ax4.set_ylabel('ç¢ºç‡å¯†åº¦')
ax4.set_title('äº‹å¾Œäºˆæ¸¬åˆ†å¸ƒ')
ax4.legend()
ax4.grid(True, alpha=0.3)

# ç ´å£Šç¢ºç‡ã®å¯è¦–åŒ–
ax5 = fig.add_subplot(gs[2, 1])
threshold_range = np.linspace(400, 550, 100)
failure_probs = []

for threshold in threshold_range:
    prob = np.mean(predicted_strength < threshold)
    failure_probs.append(prob)

ax5.plot(threshold_range, failure_probs, 'b-', linewidth=2)
ax5.axvline(design_strength, color='red', linestyle='--',
            linewidth=2, label=f'è¨­è¨ˆåŸºæº–: {design_strength} MPa')
ax5.axhline(prob_failure, color='orange', linestyle=':',
            linewidth=2, label=f'ç ´å£Šç¢ºç‡: {prob_failure:.3f}')
ax5.fill_between(threshold_range, 0, failure_probs,
                  where=(np.array(threshold_range) <= design_strength),
                  alpha=0.3, color='red')
ax5.set_xlabel('å¼·åº¦é–¾å€¤ [MPa]')
ax5.set_ylabel('ç ´å£Šç¢ºç‡')
ax5.set_title('å¼·åº¦é–¾å€¤ã¨ç ´å£Šç¢ºç‡ã®é–¢ä¿‚')
ax5.legend()
ax5.grid(True, alpha=0.3)

plt.suptitle(f'ææ–™å¼·åº¦ã®ãƒ™ã‚¤ã‚ºæ¨å®šã¨äºˆæ¸¬ï¼ˆn={n_samples}ï¼‰', fontsize=14)
plt.tight_layout()
plt.show()

# å®Ÿè·µçš„ã¾ã¨ã‚
print("\n=== å®Ÿè·µçš„è§£é‡ˆ ===")
print(f"âœ“ å°‘æ•°ã‚µãƒ³ãƒ—ãƒ«ï¼ˆn={n_samples}ï¼‰ã§ã‚‚äº‹å‰çŸ¥è­˜ã‚’æ´»ç”¨ã—ã¦å®‰å®šã—ãŸæ¨å®š")
print(f"âœ“ å¹³å‡å¼·åº¦ã¯95%ã®ç¢ºç‡ã§{mu_ci[0]:.1f}ï½{mu_ci[1]:.1f} MPaã®ç¯„å›²")
print(f"âœ“ æ¬¡ã®ã‚µãƒ³ãƒ—ãƒ«ã¯95%ã®ç¢ºç‡ã§{pred_ci[0]:.1f}ï½{pred_ci[1]:.1f} MPa")
print(f"âœ“ è¨­è¨ˆåŸºæº–{design_strength} MPaä»¥ä¸‹ã§ç ´å£Šã™ã‚‹ç¢ºç‡ã¯{prob_failure*100:.2f}%")
</code></pre>
            </div>

            <div class="exercise">
                <h4>ğŸ“ ç·´ç¿’å•é¡Œ</h4>
                <ol>
                    <li>ãƒ™ã‚¤ã‚ºæ¨è«–ã¨é »åº¦è«–çš„æ¨è«–ã®é•ã„ã‚’ã€ç¢ºç‡ã®è§£é‡ˆã®è¦³ç‚¹ã‹ã‚‰èª¬æ˜ã—ã¦ãã ã•ã„ã€‚</li>
                    <li>äº‹å‰åˆ†å¸ƒãŒç„¡æƒ…å ±ï¼ˆä¸€æ§˜åˆ†å¸ƒï¼‰ã®å ´åˆã€äº‹å¾Œåˆ†å¸ƒã¯ã©ã†ãªã‚‹ã‹è­°è«–ã—ã¦ãã ã•ã„ã€‚</li>
                    <li>Metropolis-Hastingsæ³•ã§ã€å—ç†ç‡ãŒæ¥µç«¯ã«é«˜ã„ï¼ˆ>90%ï¼‰å ´åˆã¨ä½ã„ï¼ˆ<10%ï¼‰å ´åˆã®å•é¡Œç‚¹ã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚</li>
                    <li>PyMC3ã‚’ç”¨ã„ã¦ã€ãƒã‚¢ã‚½ãƒ³åˆ†å¸ƒã®Î»ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ãƒ™ã‚¤ã‚ºæ¨å®šã™ã‚‹ã‚³ãƒ¼ãƒ‰ã‚’æ›¸ã„ã¦ãã ã•ã„ã€‚</li>
                </ol>
            </div>

            <h2>ã¾ã¨ã‚</h2>
            <ul>
                <li>ãƒ™ã‚¤ã‚ºæ¨è«–ã¯äº‹å‰çŸ¥è­˜ã¨ãƒ‡ãƒ¼ã‚¿ã‚’çµ±åˆã—ã¦ä¸ç¢ºå®Ÿæ€§ã‚’å®šé‡åŒ–ã™ã‚‹</li>
                <li>äº‹å¾Œåˆ†å¸ƒã¯å°¤åº¦ã¨äº‹å‰åˆ†å¸ƒã®ç©ã«æ¯”ä¾‹ã™ã‚‹</li>
                <li>å…±å½¹äº‹å‰åˆ†å¸ƒã‚’ä½¿ã†ã¨è§£æçš„ã«äº‹å¾Œåˆ†å¸ƒã‚’è¨ˆç®—ã§ãã‚‹</li>
                <li>MCMCã¯è¤‡é›‘ãªäº‹å¾Œåˆ†å¸ƒã‹ã‚‰ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã™ã‚‹å¼·åŠ›ãªæ‰‹æ³•ã§ã‚ã‚‹</li>
                <li>Metropolis-Hastingsæ³•ã¨Gibbs SamplingãŒä»£è¡¨çš„ãªMCMCã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ </li>
                <li>PyMC3ã‚’ä½¿ãˆã°è¤‡é›‘ãªãƒ™ã‚¤ã‚ºãƒ¢ãƒ‡ãƒ«ã‚’ç°¡æ½”ã«è¨˜è¿°ãƒ»æ¨è«–ã§ãã‚‹</li>
                <li>ææ–™ç§‘å­¦ã§ã¯å°‘æ•°ã‚µãƒ³ãƒ—ãƒ«ã§ã‚‚äº‹å‰çŸ¥è­˜ã‚’æ´»ç”¨ã—ã¦ä¿¡é ¼æ€§ã®é«˜ã„æ¨å®šãŒå¯èƒ½</li>
                <li>äº‹å¾Œäºˆæ¸¬åˆ†å¸ƒã¯æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã®äºˆæ¸¬ã¨ä¸ç¢ºå®Ÿæ€§è©•ä¾¡ã«æœ‰ç”¨</li>
            </ul>
        </div>

        <div class="nav-buttons">
            <a href="chapter-3.html" class="nav-button">â† ç¬¬3ç« : ä»®èª¬æ¤œå®šã¨æ¤œå®šåŠ›åˆ†æ</a>
            <a href="chapter-5.html" class="nav-button">ç¬¬5ç« : éšå±¤ãƒ™ã‚¤ã‚ºãƒ¢ãƒ‡ãƒ«ã¨å¿œç”¨ â†’</a>
        </div>
    </div>

    <section class="disclaimer">
<h3>å…è²¬äº‹é …</h3>
<ul>
<li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯æ•™è‚²ãƒ»ç ”ç©¶ãƒ»æƒ…å ±æä¾›ã®ã¿ã‚’ç›®çš„ã¨ã—ã¦ãŠã‚Šã€å°‚é–€çš„ãªåŠ©è¨€(æ³•å¾‹ãƒ»ä¼šè¨ˆãƒ»æŠ€è¡“çš„ä¿è¨¼ãªã©)ã‚’æä¾›ã™ã‚‹ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚</li>
<li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŠã‚ˆã³ä»˜éšã™ã‚‹Code examplesã¯ã€Œç¾çŠ¶æœ‰å§¿(AS IS)ã€ã§æä¾›ã•ã‚Œã€æ˜ç¤ºã¾ãŸã¯é»™ç¤ºã‚’å•ã‚ãšã€å•†å“æ€§ã€ç‰¹å®šç›®çš„é©åˆæ€§ã€æ¨©åˆ©éä¾µå®³ã€æ­£ç¢ºæ€§ãƒ»å®Œå…¨æ€§ã€å‹•ä½œãƒ»å®‰å…¨æ€§ç­‰ã„ã‹ãªã‚‹ä¿è¨¼ã‚‚ã—ã¾ã›ã‚“ã€‚</li>
<li>å¤–éƒ¨ãƒªãƒ³ã‚¯ã€ç¬¬ä¸‰è€…ãŒæä¾›ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ»ãƒ„ãƒ¼ãƒ«ãƒ»ãƒ©ã‚¤ãƒ–ãƒ©ãƒªç­‰ã®å†…å®¹ãƒ»å¯ç”¨æ€§ãƒ»å®‰å…¨æ€§ã«ã¤ã„ã¦ã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯ä¸€åˆ‡ã®è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚</li>
<li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®åˆ©ç”¨ãƒ»å®Ÿè¡Œãƒ»è§£é‡ˆã«ã‚ˆã‚Šç›´æ¥çš„ãƒ»é–“æ¥çš„ãƒ»ä»˜éšçš„ãƒ»ç‰¹åˆ¥ãƒ»çµæœçš„ãƒ»æ‡²ç½°çš„æå®³ãŒç”Ÿã˜ãŸå ´åˆã§ã‚‚ã€é©ç”¨æ³•ã§è¨±å®¹ã•ã‚Œã‚‹æœ€å¤§é™ã®ç¯„å›²ã§ã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚</li>
<li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å†…å®¹ã¯ã€äºˆå‘Šãªãå¤‰æ›´ãƒ»æ›´æ–°ãƒ»æä¾›åœæ­¢ã•ã‚Œã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚</li>
<li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®è‘—ä½œæ¨©ãƒ»ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯æ˜è¨˜ã•ã‚ŒãŸæ¡ä»¶(ä¾‹: CC BY 4.0)ã«å¾“ã„ã¾ã™ã€‚å½“è©²ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯é€šå¸¸ã€ç„¡ä¿è¨¼æ¡é …ã‚’å«ã¿ã¾ã™ã€‚</li>
</ul>
</section>

<footer>
        <p>&copy; 2025 AI Terakoya - Fundamentals of Mathematics & Physics Dojo</p>
    </footer>
</body>
</html>