<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="ç¬¬3ç« ï¼šç²å¾—é–¢æ•° - ãƒ™ã‚¤ã‚ºæœ€é©åŒ–å…¥é–€ã‚·ãƒªãƒ¼ã‚º">
    <title>ç¬¬3ç« ï¼šç²å¾—é–¢æ•° - ãƒ™ã‚¤ã‚ºæœ€é©åŒ–å…¥é–€ | PI Terakoya</title>

        <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif;
            line-height: 1.8; color: #333; background: #f5f5f5;
        }
        header {
            background: linear-gradient(135deg, #11998e 0%, #38ef7d 100%);
            color: white; padding: 2rem 1rem; text-align: center;
        }
        h1 { font-size: 2rem; margin-bottom: 0.5rem; }
        .subtitle { opacity: 0.9; font-size: 1.1rem; }
        .container { max-width: 1200px; margin: 2rem auto; padding: 0 1rem; }
        .back-link {
            display: inline-block; margin-bottom: 2rem; padding: 0.5rem 1rem;
            background: white; color: #11998e; text-decoration: none;
            border-radius: 6px; font-weight: 600;
        }
        .content-box {
            background: white; padding: 2rem; border-radius: 12px;
            margin-bottom: 2rem; box-shadow: 0 2px 8px rgba(0,0,0,0.1);
        }
        h2 {
            color: #11998e; margin: 2rem 0 1rem 0;
            padding-bottom: 0.5rem; border-bottom: 3px solid #11998e;
        }
        h3 { color: #2c3e50; margin: 1.5rem 0 1rem 0; }
        h4 { color: #2c3e50; margin: 1rem 0 0.5rem 0; }
        p { margin-bottom: 1rem; }
        ul, ol { margin-left: 2rem; margin-bottom: 1rem; }
        li { margin-bottom: 0.5rem; }
        pre {
            background: #1e1e1e; color: #d4d4d4; padding: 1.5rem;
            border-radius: 8px; overflow-x: auto; margin: 1rem 0;
            border-left: 4px solid #11998e;
        }
        code {
            font-family: 'Courier New', monospace; font-size: 0.9rem;
        }
        .key-point {
            background: #e8f5e9; padding: 1rem; border-radius: 6px;
            border-left: 4px solid #4caf50; margin: 1rem 0;
        }
        .tech-note {
            background: #e3f2fd; padding: 1rem; border-radius: 6px;
            border-left: 4px solid #2196f3; margin: 1rem 0;
        }
        .formula {
            background: #f0f7ff; padding: 1rem; border-radius: 6px;
            margin: 1rem 0; overflow-x: auto;
        }
        table {
            width: 100%; border-collapse: collapse; margin: 1rem 0;
        }
        th, td {
            border: 1px solid #ddd; padding: 0.75rem; text-align: left;
        }
        th {
            background: #11998e; color: white; font-weight: 600;
        }
        tr:nth-child(even) { background: #f9f9f9; }
        .nav-buttons {
            display: flex; justify-content: space-between; margin-top: 3rem;
        }
        .nav-buttons a {
            padding: 0.75rem 1.5rem;
            background: linear-gradient(135deg, #11998e 0%, #38ef7d 100%);
            color: white; text-decoration: none; border-radius: 6px;
            font-weight: 600;
        }
        footer {
            background: #2c3e50; color: white; text-align: center;
            padding: 2rem 1rem; margin-top: 4rem;
        }
        @media (max-width: 768px) {
            h1 { font-size: 1.6rem; }
            .container { padding: 0 0.5rem; }
            pre { padding: 1rem; }
        }
    
        
    
        /* Breadcrumb styles */
        .breadcrumb {
            background: #f7fafc;
            padding: 0.75rem 1rem;
            border-bottom: 1px solid #e2e8f0;
            font-size: 0.9rem;
        }

        .breadcrumb-content {
            max-width: 900px;
            margin: 0 auto;
            display: flex;
            align-items: center;
            flex-wrap: wrap;
            gap: 0.5rem;
        }

        .breadcrumb a {
            color: #667eea;
            text-decoration: none;
            transition: color 0.2s;
        }

        .breadcrumb a:hover {
            color: #764ba2;
            text-decoration: underline;
        }

        .breadcrumb-separator {
            color: #a0aec0;
            margin: 0 0.25rem;
        }

        .breadcrumb-current {
            color: #4a5568;
            font-weight: 500;
        }
    </style>

    <style>
        /* Locale Switcher Styles */
        .locale-switcher {
            display: flex;
            align-items: center;
            gap: 0.5rem;
            padding: 0.5rem 1rem;
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
            border-radius: 6px;
            font-size: 0.9rem;
            margin-bottom: 1rem;
            box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);
        }

        .current-locale {
            font-weight: 600;
            color: #7b2cbf;
            display: flex;
            align-items: center;
            gap: 0.25rem;
        }

        .locale-separator {
            color: #adb5bd;
            font-weight: 300;
        }

        .locale-link {
            color: #f093fb;
            text-decoration: none;
            font-weight: 500;
            transition: all 0.2s ease;
            display: flex;
            align-items: center;
            gap: 0.25rem;
            padding: 0.2rem 0.5rem;
            border-radius: 4px;
        }

        .locale-link:hover {
            background: rgba(240, 147, 251, 0.1);
            color: #d07be8;
            transform: translateY(-1px);
        }

        .locale-meta {
            color: #868e96;
            font-size: 0.85rem;
            font-style: italic;
            margin-left: auto;
        }

        @media (max-width: 768px) {
            .locale-switcher {
                font-size: 0.85rem;
                padding: 0.4rem 0.8rem;
            }
            .locale-meta {
                display: none;
            }
        }
    </style>
</head>
<body>
            <div class="locale-switcher">
<span class="current-locale">ğŸŒ JP</span>
<span class="locale-separator">|</span>
<a href="../../../en/PI/bayesian-optimization/chapter-3.html" class="locale-link">ğŸ‡¬ğŸ‡§ EN</a>
<span class="locale-separator">|</span>
<span class="locale-meta">Last sync: 2025-11-16</span>
</div>
<nav class="breadcrumb">
        <div class="breadcrumb-content">
            <a href="../../index.html">AIå¯ºå­å±‹ãƒˆãƒƒãƒ—</a><span class="breadcrumb-separator">â€º</span><a href="../../PI/index.html">ãƒ—ãƒ­ã‚»ã‚¹ãƒ»ã‚¤ãƒ³ãƒ•ã‚©ãƒãƒ†ã‚£ã‚¯ã‚¹</a><span class="breadcrumb-separator">â€º</span><a href="../../PI/bayesian-optimization/index.html">Bayesian Optimization</a><span class="breadcrumb-separator">â€º</span><span class="breadcrumb-current">Chapter 3</span>
        </div>
    </nav>

        <header>
        <div class="container">
            <h1>ç¬¬3ç« ï¼šç²å¾—é–¢æ•°</h1>
            <p class="subtitle">æ¢ç´¢ã¨æ´»ç”¨ã®ãƒãƒ©ãƒ³ã‚¹ã‚’åˆ¶å¾¡ã™ã‚‹æˆ¦ç•¥</p>
            <div class="meta">
                <span class="meta">ğŸ“š ãƒ™ã‚¤ã‚ºæœ€é©åŒ–å…¥é–€ã‚·ãƒªãƒ¼ã‚º</span>
                <span class="meta">â±ï¸ èª­äº†æ™‚é–“: 30åˆ†</span>
                <span class="meta">ğŸ“Š é›£æ˜“åº¦: ä¸­ç´š</span>
                <span class="meta">ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹: 7å€‹</span>
            </div>
        </div>
    </header>

    <main class="container">
        <section>
            <h2>3.1 ç²å¾—é–¢æ•°ã¨ã¯</h2>

            <p>
                ç²å¾—é–¢æ•°ï¼ˆAcquisition Functionï¼‰ã¯ã€ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã«ãŠã„ã¦æ¬¡ã«è©•ä¾¡ã™ã¹ãå€™è£œç‚¹ã‚’æ±ºå®šã™ã‚‹é‡è¦ãªè¦ç´ ã§ã™ã€‚
                ã‚¬ã‚¦ã‚¹éç¨‹ãŒäºˆæ¸¬ã—ãŸå¹³å‡ã¨ä¸ç¢ºå®Ÿæ€§ã‚’å…¥åŠ›ã¨ã—ã¦ã€ã€Œã©ã®ç‚¹ã‚’æ¬¡ã«å®Ÿé¨“ã™ã¹ãã‹ã€ã‚’æ•°å€¤åŒ–ã—ã¾ã™ã€‚
            </p>

            <div class="info-box">
                <h4>ğŸ’¡ ç²å¾—é–¢æ•°ã®å½¹å‰²</h4>
                <ul>
                    <li><strong>æ¢ç´¢ï¼ˆExplorationï¼‰</strong>ï¼šä¸ç¢ºå®Ÿæ€§ãŒé«˜ã„é ˜åŸŸã‚’èª¿ã¹ã‚‹</li>
                    <li><strong>æ´»ç”¨ï¼ˆExploitationï¼‰</strong>ï¼šç¾åœ¨ã®æœ€è‰¯å€¤ã®å‘¨è¾ºã‚’è©³ç´°ã«èª¿ã¹ã‚‹</li>
                    <li><strong>ãƒãƒ©ãƒ³ã‚¹èª¿æ•´</strong>ï¼šå•é¡Œã‚„é€²æ—ã«å¿œã˜ã¦æ¢ç´¢ã¨æ´»ç”¨ã®æ¯”ç‡ã‚’åˆ¶å¾¡</li>
                </ul>
            </div>

            <p>
                æœ¬ç« ã§ã¯ã€7ã¤ã®ä»£è¡¨çš„ãªç²å¾—é–¢æ•°ã‚’å®Ÿè£…ã—ã€ãã‚Œãã‚Œã®ç‰¹æ€§ã¨é©ç”¨å ´é¢ã‚’ç†è§£ã—ã¾ã™ã€‚
            </p>
        </section>

        <section>
            <h2>3.2 Expected Improvement (EI)</h2>

            <p>
                æœ€ã‚‚åºƒãä½¿ã‚ã‚Œã‚‹ç²å¾—é–¢æ•°ã€‚ç¾åœ¨ã®æœ€è‰¯å€¤ã‹ã‚‰ã®æ”¹å–„é‡ã®æœŸå¾…å€¤ã‚’æœ€å¤§åŒ–ã—ã¾ã™ã€‚
            </p>

            <h3>Example 1: Expected Improvement ã®å®Ÿè£…</h3>

            <pre><code># Expected Improvement (EI) ã®å®Ÿè£…
import numpy as np
from scipy.stats import norm
from sklearn.gaussian_process import GaussianProcessRegressor
from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C
import matplotlib.pyplot as plt

# 1æ¬¡å…ƒãƒ†ã‚¹ãƒˆé–¢æ•°ï¼ˆãƒ—ãƒ­ã‚»ã‚¹æ¸©åº¦ã®æœ€é©åŒ–ï¼‰
def process_yield(x):
    """åå¿œåç‡ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆæ¸©åº¦ã«å¯¾ã™ã‚‹å¿œç­”ï¼‰"""
    return -(x - 2.5)**2 + 5 + 0.3 * np.sin(5 * x)

# Expected Improvement ã®è¨ˆç®—
def expected_improvement(X, gp, y_best, xi=0.01):
    """EIç²å¾—é–¢æ•°

    Args:
        X: è©•ä¾¡ç‚¹
        gp: å­¦ç¿’æ¸ˆã¿ã‚¬ã‚¦ã‚¹éç¨‹
        y_best: ç¾åœ¨ã®æœ€è‰¯å€¤
        xi: æ”¹å–„ã®é–¾å€¤ï¼ˆå°ã•ã„ã»ã©æ´»ç”¨é‡è¦–ï¼‰
    """
    mu, sigma = gp.predict(X, return_std=True)
    sigma = sigma.reshape(-1, 1)

    # æ”¹å–„é‡ã®è¨ˆç®—
    with np.errstate(divide='warn'):
        imp = mu - y_best - xi
        Z = imp / sigma
        ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)
        ei[sigma == 0.0] = 0.0

    return ei

# åˆæœŸã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
np.random.seed(42)
X_init = np.random.uniform(0, 5, 3).reshape(-1, 1)
y_init = process_yield(X_init)

# ã‚¬ã‚¦ã‚¹éç¨‹ã®æ§‹ç¯‰
kernel = C(1.0, (1e-3, 1e3)) * RBF(1.0, (1e-2, 1e2))
gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10)
gp.fit(X_init, y_init)

# EIã®è©•ä¾¡
X_test = np.linspace(0, 5, 200).reshape(-1, 1)
y_best = y_init.max()
ei_values = expected_improvement(X_test, gp, y_best)

# æ¬¡ã®å€™è£œç‚¹
next_x = X_test[np.argmax(ei_values)]

print(f"ç¾åœ¨ã®æœ€è‰¯å€¤: {y_best:.3f}")
print(f"æ¬¡ã®å®Ÿé¨“å€™è£œç‚¹: {next_x[0]:.3f}")
print(f"EIå€¤: {ei_values.max():.4f}")

# å¯è¦–åŒ–
fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 8))

# ä¸Šæ®µ: GPã®äºˆæ¸¬
mu, sigma = gp.predict(X_test, return_std=True)
ax1.plot(X_test, process_yield(X_test), 'r--', label='True function', alpha=0.5)
ax1.plot(X_test, mu, 'b-', label='GP mean')
ax1.fill_between(X_test.ravel(), mu - 1.96*sigma, mu + 1.96*sigma,
                 alpha=0.2, label='95% CI')
ax1.scatter(X_init, y_init, c='red', s=100, zorder=10, label='Observations')
ax1.axvline(next_x, color='green', linestyle=':', label='Next sample')
ax1.set_ylabel('Yield')
ax1.legend()
ax1.set_title('Gaussian Process Prediction')

# ä¸‹æ®µ: EIå€¤
ax2.plot(X_test, ei_values, 'g-', label='Expected Improvement')
ax2.axvline(next_x, color='green', linestyle=':', label='Maximum EI')
ax2.set_xlabel('Temperature (x)')
ax2.set_ylabel('EI')
ax2.legend()
ax2.set_title('Expected Improvement Acquisition Function')

plt.tight_layout()
plt.savefig('ei_acquisition.png', dpi=150, bbox_inches='tight')
print("ä¿å­˜å®Œäº†: ei_acquisition.png")
</code></pre>

            <div class="success-box">
                <h4>âœ… EIã®ç‰¹å¾´</h4>
                <ul>
                    <li>æ¢ç´¢ã¨æ´»ç”¨ã®ãƒãƒ©ãƒ³ã‚¹ãŒè‰¯ã„ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆæ¨å¥¨ï¼‰</li>
                    <li>ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ <code>xi</code> ã§èª¿æ•´å¯èƒ½ï¼ˆ0.01-0.1ãŒä¸€èˆ¬çš„ï¼‰</li>
                    <li>å±€æ‰€æœ€é©è§£ã«ã¯ã¾ã‚Šã«ãã„</li>
                </ul>
            </div>
        </section>

        <section>
            <h2>3.3 Probability of Improvement (PI)</h2>

            <p>
                ç¾åœ¨ã®æœ€è‰¯å€¤ã‚’æ”¹å–„ã™ã‚‹ç¢ºç‡ã‚’æœ€å¤§åŒ–ã™ã‚‹ç²å¾—é–¢æ•°ã€‚EIã‚ˆã‚Šã‚‚ä¿å®ˆçš„ãªæˆ¦ç•¥ã€‚
            </p>

            <h3>Example 2: Probability of Improvement ã®å®Ÿè£…</h3>

            <pre><code># Probability of Improvement (PI) ã®å®Ÿè£…
def probability_of_improvement(X, gp, y_best, xi=0.01):
    """PIç²å¾—é–¢æ•°

    Args:
        X: è©•ä¾¡ç‚¹
        gp: å­¦ç¿’æ¸ˆã¿ã‚¬ã‚¦ã‚¹éç¨‹
        y_best: ç¾åœ¨ã®æœ€è‰¯å€¤
        xi: æ”¹å–„ã®é–¾å€¤
    """
    mu, sigma = gp.predict(X, return_std=True)
    sigma = sigma.reshape(-1, 1)

    with np.errstate(divide='warn'):
        Z = (mu - y_best - xi) / sigma
        pi = norm.cdf(Z)
        pi[sigma == 0.0] = 0.0

    return pi

# PIã¨EIã®æ¯”è¼ƒ
pi_values = probability_of_improvement(X_test, gp, y_best)
next_x_pi = X_test[np.argmax(pi_values)]

# æ¯”è¼ƒãƒ—ãƒ­ãƒƒãƒˆ
fig, ax = plt.subplots(figsize=(10, 5))
ax.plot(X_test, ei_values/ei_values.max(), 'g-', label='EI (normalized)', linewidth=2)
ax.plot(X_test, pi_values, 'b-', label='PI', linewidth=2)
ax.axvline(next_x, color='green', linestyle=':', alpha=0.7, label=f'EI max: {next_x[0]:.2f}')
ax.axvline(next_x_pi, color='blue', linestyle=':', alpha=0.7, label=f'PI max: {next_x_pi[0]:.2f}')
ax.set_xlabel('Temperature')
ax.set_ylabel('Acquisition Value')
ax.legend()
ax.set_title('EI vs PI Acquisition Functions')
ax.grid(alpha=0.3)
plt.savefig('ei_vs_pi.png', dpi=150, bbox_inches='tight')

print(f"EIæ¨å¥¨ç‚¹: {next_x[0]:.3f}")
print(f"PIæ¨å¥¨ç‚¹: {next_x_pi[0]:.3f}")
print(f"å·®: {abs(next_x[0] - next_x_pi[0]):.3f}")
</code></pre>

            <div class="warning-box">
                <h4>âš ï¸ PIã®æ³¨æ„ç‚¹</h4>
                <p>PIã¯æ”¹å–„ã®ã€Œç¢ºç‡ã€ã®ã¿ã‚’è€ƒæ…®ã—ã€æ”¹å–„ã®ã€Œå¤§ãã•ã€ã‚’è€ƒæ…®ã—ã¾ã›ã‚“ã€‚ãã®ãŸã‚ã€å¾®å°ãªæ”¹å–„ã§ã‚‚ç¢ºç‡ãŒé«˜ã‘ã‚Œã°é¸æŠã•ã‚Œã¾ã™ã€‚EIã®æ–¹ãŒå®Ÿç”¨çš„ãªã‚±ãƒ¼ã‚¹ãŒå¤šã„ã§ã™ã€‚</p>
            </div>
        </section>

        <section>
            <h2>3.4 Upper Confidence Bound (UCB)</h2>

            <p>
                äºˆæ¸¬å¹³å‡ã¨ä¸ç¢ºå®Ÿæ€§ã®åŠ é‡å’Œã‚’æœ€å¤§åŒ–ã€‚ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§æ¢ç´¢åº¦åˆã„ã‚’æ˜ç¤ºçš„ã«åˆ¶å¾¡ã§ãã¾ã™ã€‚
            </p>

            <h3>Example 3: UCBã®å®Ÿè£…ã¨æ¢ç´¢ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å½±éŸ¿</h3>

            <pre><code># Upper Confidence Bound (UCB) ã®å®Ÿè£…
def upper_confidence_bound(X, gp, kappa=2.0):
    """UCBç²å¾—é–¢æ•°

    Args:
        X: è©•ä¾¡ç‚¹
        gp: å­¦ç¿’æ¸ˆã¿ã‚¬ã‚¦ã‚¹éç¨‹
        kappa: æ¢ç´¢ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆå¤§ãã„ã»ã©æ¢ç´¢é‡è¦–ï¼‰
    """
    mu, sigma = gp.predict(X, return_std=True)
    return mu + kappa * sigma

# ç•°ãªã‚‹kappaã§ã®æ¯”è¼ƒ
kappas = [0.5, 1.0, 2.0, 5.0]
fig, axes = plt.subplots(2, 2, figsize=(12, 10))

for i, kappa in enumerate(kappas):
    ax = axes[i//2, i%2]

    ucb_values = upper_confidence_bound(X_test, gp, kappa=kappa)
    next_x_ucb = X_test[np.argmax(ucb_values)]

    # GPã®äºˆæ¸¬
    mu, sigma = gp.predict(X_test, return_std=True)

    ax.plot(X_test, process_yield(X_test), 'r--', alpha=0.3, label='True')
    ax.plot(X_test, mu, 'b-', alpha=0.5, label='GP mean')
    ax.fill_between(X_test.ravel(), mu - sigma, mu + sigma, alpha=0.1)
    ax.plot(X_test, ucb_values, 'g-', linewidth=2, label='UCB')
    ax.scatter(X_init, y_init, c='red', s=80, zorder=10)
    ax.axvline(next_x_ucb, color='green', linestyle=':', linewidth=2)

    ax.set_title(f'Îº = {kappa} (Next: {next_x_ucb[0]:.2f})')
    ax.set_xlabel('Temperature')
    ax.set_ylabel('Value')
    ax.legend(loc='upper right', fontsize=8)
    ax.grid(alpha=0.3)

plt.tight_layout()
plt.savefig('ucb_kappa_comparison.png', dpi=150, bbox_inches='tight')

print("\nUCBã®æ¢ç´¢ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å½±éŸ¿:")
for kappa in kappas:
    ucb = upper_confidence_bound(X_test, gp, kappa=kappa)
    next_x = X_test[np.argmax(ucb)]
    print(f"Îº={kappa:.1f}: æ¬¡å®Ÿé¨“ç‚¹ = {next_x[0]:.3f}")
</code></pre>

            <div class="info-box">
                <h4>ğŸ’¡ UCBãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿é¸æŠã‚¬ã‚¤ãƒ‰</h4>
                <ul>
                    <li><code>kappa = 0.5-1.0</code>: æ´»ç”¨é‡è¦–ï¼ˆæœ€è‰¯å€¤å‘¨è¾ºã®ç²¾å¯†æ¢ç´¢ï¼‰</li>
                    <li><code>kappa = 2.0-3.0</code>: ãƒãƒ©ãƒ³ã‚¹å‹ï¼ˆæ¨å¥¨ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰</li>
                    <li><code>kappa = 5.0-10.0</code>: æ¢ç´¢é‡è¦–ï¼ˆæœªçŸ¥é ˜åŸŸã®èª¿æŸ»ï¼‰</li>
                </ul>
            </div>
        </section>

        <section>
            <h2>3.5 Thompson Sampling</h2>

            <p>
                ãƒ™ã‚¤ã‚ºçš„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã€‚ã‚¬ã‚¦ã‚¹éç¨‹ã®äº‹å¾Œåˆ†å¸ƒã‹ã‚‰ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ã€ãã®æœ€å¤§å€¤ã‚’æ¬¡ã®å€™è£œã¨ã—ã¾ã™ã€‚
            </p>

            <h3>Example 4: Thompson Samplingã®å®Ÿè£…</h3>

            <pre><code># Thompson Sampling ã®å®Ÿè£…
def thompson_sampling(X, gp, n_samples=10, random_state=None):
    """Thompson Samplingç²å¾—é–¢æ•°

    Args:
        X: è©•ä¾¡ç‚¹
        gp: å­¦ç¿’æ¸ˆã¿ã‚¬ã‚¦ã‚¹éç¨‹
        n_samples: ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ•°
        random_state: ä¹±æ•°ã‚·ãƒ¼ãƒ‰
    """
    if random_state is not None:
        np.random.seed(random_state)

    # GPã‹ã‚‰é–¢æ•°ã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
    y_samples = gp.sample_y(X, n_samples=n_samples)

    # å„ã‚µãƒ³ãƒ—ãƒ«ã®æœ€å¤§å€¤ã®ä½ç½®
    max_indices = np.argmax(y_samples, axis=0)

    # é »åº¦ãƒ™ãƒ¼ã‚¹ã®ã‚¹ã‚³ã‚¢ï¼ˆã©ã®ç‚¹ãŒæœ€ã‚‚é¸ã°ã‚Œã‚‹ã‹ï¼‰
    score = np.zeros(len(X))
    for idx in max_indices:
        score[idx] += 1

    return score, y_samples

# Thompson Samplingã®å®Ÿè¡Œ
ts_score, samples = thompson_sampling(X_test, gp, n_samples=50, random_state=42)
next_x_ts = X_test[np.argmax(ts_score)]

# å¯è¦–åŒ–
fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 8))

# ã‚µãƒ³ãƒ—ãƒ«ã—ãŸé–¢æ•°
mu, sigma = gp.predict(X_test, return_std=True)
ax1.plot(X_test, process_yield(X_test), 'r--', alpha=0.5, linewidth=2, label='True')
ax1.plot(X_test, mu, 'b-', linewidth=2, label='GP mean')
for i in range(min(10, samples.shape[1])):
    ax1.plot(X_test, samples[:, i], 'gray', alpha=0.3, linewidth=0.5)
ax1.scatter(X_init, y_init, c='red', s=100, zorder=10, label='Observations')
ax1.axvline(next_x_ts, color='green', linestyle=':', linewidth=2, label='TS selection')
ax1.set_ylabel('Yield')
ax1.legend()
ax1.set_title(f'Thompson Sampling (50 samples)')
ax1.grid(alpha=0.3)

# é¸æŠé »åº¦
ax2.bar(X_test.ravel(), ts_score, width=0.03, color='green', alpha=0.7)
ax2.axvline(next_x_ts, color='green', linestyle=':', linewidth=2)
ax2.set_xlabel('Temperature')
ax2.set_ylabel('Selection Frequency')
ax2.set_title('Thompson Sampling Scores')
ax2.grid(alpha=0.3)

plt.tight_layout()
plt.savefig('thompson_sampling.png', dpi=150, bbox_inches='tight')

print(f"Thompson Samplingæ¨å¥¨ç‚¹: {next_x_ts[0]:.3f}")
print(f"é¸æŠé »åº¦: {ts_score.max()}/50")
</code></pre>

            <div class="success-box">
                <h4>âœ… Thompson Samplingã®åˆ©ç‚¹</h4>
                <ul>
                    <li>ç†è«–çš„ã«æœ€é©ãªæ¢ç´¢æˆ¦ç•¥ï¼ˆãƒ™ã‚¤ã‚ºãƒªã‚°ãƒ¬ãƒƒãƒˆæœ€å°åŒ–ï¼‰</li>
                    <li>å¤šè…•ãƒãƒ³ãƒ‡ã‚£ãƒƒãƒˆå•é¡Œã§å®Ÿç¸¾ã‚ã‚Š</li>
                    <li>ãƒ©ãƒ³ãƒ€ãƒ æ€§ã«ã‚ˆã‚Šå±€æ‰€è§£å›é¿</li>
                </ul>
            </div>
        </section>

        <section>
            <h2>3.6 Knowledge Gradient (KG)</h2>

            <p>
                æ¬¡ã®ã‚µãƒ³ãƒ—ãƒ«ã‚’å–å¾—ã—ãŸå¾Œã®æ”¹å–„é‡ã‚’äºˆæ¸¬ã™ã‚‹å…ˆèª­ã¿å‹ç²å¾—é–¢æ•°ã€‚
            </p>

            <h3>Example 5: Knowledge Gradientã®å®Ÿè£…</h3>

            <pre><code># Knowledge Gradient ã®ç°¡æ˜“å®Ÿè£…
def knowledge_gradient(X, X_candidate, gp, n_samples=100):
    """Knowledge Gradientç²å¾—é–¢æ•°

    Args:
        X: æ—¢å­˜ã®è¦³æ¸¬ç‚¹
        X_candidate: å€™è£œç‚¹
        gp: å­¦ç¿’æ¸ˆã¿ã‚¬ã‚¦ã‚¹éç¨‹
        n_samples: ãƒ¢ãƒ³ãƒ†ã‚«ãƒ«ãƒ­ã‚µãƒ³ãƒ—ãƒ«æ•°
    """
    # ç¾åœ¨ã®æœ€è‰¯å€¤
    y_pred_current = gp.predict(X_candidate, return_std=False)
    current_best = y_pred_current.max()

    kg_values = np.zeros(len(X))

    for i, x_new in enumerate(X):
        # æ–°ã—ã„ç‚¹ã‚’è¿½åŠ ã—ãŸå ´åˆã®æœŸå¾…æ”¹å–„
        # ãƒ¢ãƒ³ãƒ†ã‚«ãƒ«ãƒ­è¿‘ä¼¼
        improvements = []

        for _ in range(n_samples):
            # æ–°ç‚¹ã§ã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
            y_new_sample = gp.sample_y(x_new.reshape(1, -1), n_samples=1)[0, 0]

            # GPã‚’æ›´æ–°ï¼ˆä»®æƒ³çš„ã«ï¼‰
            X_temp = np.vstack([gp.X_train_, x_new.reshape(1, -1)])
            y_temp = np.hstack([gp.y_train_, y_new_sample])

            gp_temp = GaussianProcessRegressor(kernel=gp.kernel_)
            gp_temp.fit(X_temp, y_temp)

            # æ›´æ–°å¾Œã®æœ€è‰¯äºˆæ¸¬
            y_pred_new = gp_temp.predict(X_candidate, return_std=False)
            new_best = y_pred_new.max()

            improvements.append(max(0, new_best - current_best))

        kg_values[i] = np.mean(improvements)

    return kg_values

# KGã®è¨ˆç®—ï¼ˆè¨ˆç®—ã‚³ã‚¹ãƒˆé«˜ã„ãŸã‚ç²—ã„ã‚°ãƒªãƒƒãƒ‰ã§ï¼‰
X_coarse = np.linspace(0, 5, 30).reshape(-1, 1)
X_candidate = np.linspace(0, 5, 50).reshape(-1, 1)

print("Knowledge Gradientè¨ˆç®—ä¸­ï¼ˆæ•°åˆ†ã‹ã‹ã‚Šã¾ã™ï¼‰...")
kg_values = knowledge_gradient(X_coarse, X_candidate, gp, n_samples=20)
next_x_kg = X_coarse[np.argmax(kg_values)]

# ä»–ã®ç²å¾—é–¢æ•°ã¨æ¯”è¼ƒ
ei_coarse = expected_improvement(X_coarse, gp, y_best)
ucb_coarse = upper_confidence_bound(X_coarse, gp, kappa=2.0)

fig, ax = plt.subplots(figsize=(10, 6))
ax.plot(X_coarse, ei_coarse/ei_coarse.max(), 'g-', label='EI (norm)', linewidth=2)
ax.plot(X_coarse, ucb_coarse/ucb_coarse.max(), 'b-', label='UCB (norm)', linewidth=2)
ax.plot(X_coarse, kg_values/kg_values.max(), 'r-', label='KG (norm)', linewidth=2)
ax.axvline(next_x_kg, color='red', linestyle=':', label=f'KG max: {next_x_kg[0]:.2f}')
ax.set_xlabel('Temperature')
ax.set_ylabel('Normalized Acquisition Value')
ax.legend()
ax.set_title('Knowledge Gradient vs Other Acquisition Functions')
ax.grid(alpha=0.3)
plt.savefig('knowledge_gradient.png', dpi=150, bbox_inches='tight')

print(f"\nKnowledge Gradientæ¨å¥¨ç‚¹: {next_x_kg[0]:.3f}")
print(f"KGå€¤: {kg_values.max():.4f}")
</code></pre>

            <div class="warning-box">
                <h4>âš ï¸ KGã®è¨ˆç®—ã‚³ã‚¹ãƒˆ</h4>
                <p>
                    Knowledge Gradientã¯å„å€™è£œç‚¹ã§GPã‚’å†å­¦ç¿’ã™ã‚‹ãŸã‚è¨ˆç®—ã‚³ã‚¹ãƒˆãŒé«˜ã„ã§ã™ã€‚
                    å®Ÿç”¨çš„ã«ã¯ç²—ã„ã‚°ãƒªãƒƒãƒ‰ã§ã®è©•ä¾¡ã€ã¾ãŸã¯è§£æçš„è¿‘ä¼¼ï¼ˆKG*ï¼‰ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚
                </p>
            </div>
        </section>

        <section>
            <h2>3.7 Entropy Search</h2>

            <p>
                æœ€é©è§£ã®ä½ç½®ã«é–¢ã™ã‚‹ä¸ç¢ºå®Ÿæ€§ï¼ˆã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ï¼‰ã‚’æœ€ã‚‚æ¸›å°‘ã•ã›ã‚‹ç‚¹ã‚’é¸æŠã—ã¾ã™ã€‚
            </p>

            <h3>Example 6: Entropy Searchã®æ¦‚å¿µå®Ÿè£…</h3>

            <pre><code># Entropy Search ã®æ¦‚å¿µçš„å®Ÿè£…
from scipy.stats import entropy

def entropy_search_approx(X, gp, X_candidate, n_samples=100):
    """Entropy Searchã®è¿‘ä¼¼å®Ÿè£…

    Args:
        X: è©•ä¾¡ç‚¹
        gp: å­¦ç¿’æ¸ˆã¿ã‚¬ã‚¦ã‚¹éç¨‹
        X_candidate: æœ€é©è§£ã®å€™è£œé ˜åŸŸ
        n_samples: ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ•°
    """
    # æœ€é©è§£ä½ç½®ã®äº‹å‰åˆ†å¸ƒï¼ˆå€™è£œç‚¹ã§ã®äºˆæ¸¬å€¤ã«åŸºã¥ãï¼‰
    mu_candidate, sigma_candidate = gp.predict(X_candidate, return_std=True)

    # æ­£è¦åŒ–ã—ã¦ç¢ºç‡åˆ†å¸ƒåŒ–
    prob_optimum = np.exp(mu_candidate / sigma_candidate.max())
    prob_optimum /= prob_optimum.sum()

    # ç¾åœ¨ã®ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼
    current_entropy = entropy(prob_optimum)

    es_values = np.zeros(len(X))

    for i, x_new in enumerate(X):
        # æ–°ç‚¹ã§ã®äºˆæ¸¬
        mu_new, sigma_new = gp.predict(x_new.reshape(1, -1), return_std=True)

        # ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ™ãƒ¼ã‚¹ã§ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼å‰Šæ¸›ã‚’è¿‘ä¼¼
        entropy_reductions = []

        for _ in range(n_samples):
            # æ–°ç‚¹ã®è¦³æ¸¬å€¤ã‚’ã‚µãƒ³ãƒ—ãƒ«
            y_new = np.random.normal(mu_new[0], sigma_new[0])

            # GPæ›´æ–°å¾Œã®æœ€é©è§£åˆ†å¸ƒã‚’è¿‘ä¼¼
            # ç°¡æ˜“åŒ–: æ–°ç‚¹ã®è¦³æ¸¬ãŒå€™è£œç‚¹ã®ç¢ºç‡ã«ä¸ãˆã‚‹å½±éŸ¿
            updated_prob = prob_optimum.copy()

            # æ–°ç‚¹ãŒå€™è£œã‚ˆã‚Šè‰¯ã„å ´åˆã®å½±éŸ¿
            for j, x_cand in enumerate(X_candidate):
                if y_new > mu_candidate[j]:
                    updated_prob[j] *= 0.5  # ç°¡æ˜“çš„ãªé‡ã¿ä»˜ã‘

            updated_prob /= updated_prob.sum() + 1e-10
            new_entropy = entropy(updated_prob)

            entropy_reductions.append(current_entropy - new_entropy)

        es_values[i] = np.mean(entropy_reductions)

    return es_values

# Entropy Searchã®å®Ÿè¡Œ
es_values = entropy_search_approx(X_coarse, gp, X_candidate, n_samples=50)
next_x_es = X_coarse[np.argmax(es_values)]

# å¯è¦–åŒ–
fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 8))

# æœ€é©è§£ã®ç¢ºç‡åˆ†å¸ƒ
mu_cand, sigma_cand = gp.predict(X_candidate, return_std=True)
prob_opt = np.exp(mu_cand / sigma_cand.max())
prob_opt /= prob_opt.sum()

ax1.plot(X_candidate, prob_opt, 'b-', linewidth=2, label='P(x is optimum)')
ax1.fill_between(X_candidate.ravel(), 0, prob_opt, alpha=0.3)
ax1.scatter(X_init, [0.01]*len(X_init), c='red', s=100, zorder=10, label='Observations')
ax1.set_ylabel('Probability')
ax1.legend()
ax1.set_title('Estimated Distribution of Optimal Point')
ax1.grid(alpha=0.3)

# Entropy Searchå€¤
ax2.plot(X_coarse, es_values, 'r-', linewidth=2, label='Entropy Reduction')
ax2.axvline(next_x_es, color='red', linestyle=':', linewidth=2, label=f'ES max: {next_x_es[0]:.2f}')
ax2.set_xlabel('Temperature')
ax2.set_ylabel('Expected Entropy Reduction')
ax2.legend()
ax2.set_title('Entropy Search Acquisition Function')
ax2.grid(alpha=0.3)

plt.tight_layout()
plt.savefig('entropy_search.png', dpi=150, bbox_inches='tight')

print(f"Entropy Searchæ¨å¥¨ç‚¹: {next_x_es[0]:.3f}")
print(f"æœŸå¾…ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼å‰Šæ¸›: {es_values.max():.4f}")
</code></pre>

            <div class="info-box">
                <h4>ğŸ’¡ Entropy Searchã®ç‰¹å¾´</h4>
                <ul>
                    <li>æƒ…å ±ç†è«–ã«åŸºã¥ãå³å¯†ãªå®šå¼åŒ–</li>
                    <li>æœ€é©è§£ã®åŒå®šã«åŠ¹ç‡çš„ï¼ˆåŒå®šå•é¡Œå‘ãï¼‰</li>
                    <li>å®Ÿè£…ãŒè¤‡é›‘ï¼ˆè¿‘ä¼¼æ‰‹æ³•ãŒä¸€èˆ¬çš„ï¼‰</li>
                </ul>
            </div>
        </section>

        <section>
            <h2>3.8 ç²å¾—é–¢æ•°ã®æ¯”è¼ƒå®Ÿé¨“</h2>

            <p>
                ã“ã‚Œã¾ã§å­¦ã‚“ã 6ã¤ã®ç²å¾—é–¢æ•°ã‚’å®Ÿãƒ—ãƒ­ã‚»ã‚¹æœ€é©åŒ–å•é¡Œã§æ¯”è¼ƒã—ã¾ã™ã€‚
            </p>

            <h3>Example 7: ç²å¾—é–¢æ•°ã®åŒ…æ‹¬çš„æ¯”è¼ƒ</h3>

            <pre><code># ç²å¾—é–¢æ•°ã®æ€§èƒ½æ¯”è¼ƒå®Ÿé¨“
from sklearn.gaussian_process import GaussianProcessRegressor
from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C

# ãƒ†ã‚¹ãƒˆé–¢æ•°: è¤‡é›‘ãªãƒ—ãƒ­ã‚»ã‚¹å¿œç­”
def complex_process(x):
    """å¤šå³°æ€§ãƒ—ãƒ­ã‚»ã‚¹å¿œç­”ï¼ˆæ¸©åº¦ãƒ»åœ§åŠ›ã®2æ¬¡å…ƒï¼‰"""
    x1, x2 = x[:, 0], x[:, 1]
    return (-(x1 - 3)**2 - (x2 - 2)**2 + 10 +
            2 * np.sin(3*x1) * np.cos(2*x2) +
            np.random.normal(0, 0.1, len(x1)))

# å„ç²å¾—é–¢æ•°ã§ã®ãƒ™ã‚¤ã‚ºæœ€é©åŒ–
def run_bo_with_acquisition(acquisition_func, n_iterations=20):
    """æŒ‡å®šã—ãŸç²å¾—é–¢æ•°ã§BOã‚’å®Ÿè¡Œ"""
    # åˆæœŸã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
    np.random.seed(42)
    X_init = np.random.uniform([0, 0], [5, 4], (5, 2))
    y_init = complex_process(X_init)

    X_all = X_init.copy()
    y_all = y_init.copy()
    best_values = [y_all.max()]

    for iteration in range(n_iterations):
        # GPãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰
        kernel = C(1.0) * RBF([1.0, 1.0])
        gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10,
                                      normalize_y=True, random_state=42)
        gp.fit(X_all, y_all)

        # å€™è£œç‚¹ã®ç”Ÿæˆ
        X_candidates = np.random.uniform([0, 0], [5, 4], (1000, 2))

        # ç²å¾—é–¢æ•°ã§æ¬¡ã®ç‚¹ã‚’é¸æŠ
        if acquisition_func == 'EI':
            acq_values = expected_improvement(X_candidates, gp, y_all.max())
        elif acquisition_func == 'PI':
            acq_values = probability_of_improvement(X_candidates, gp, y_all.max())
        elif acquisition_func == 'UCB':
            acq_values = upper_confidence_bound(X_candidates, gp, kappa=2.0)
        elif acquisition_func == 'Random':
            acq_values = np.random.rand(len(X_candidates))

        next_x = X_candidates[np.argmax(acq_values)]
        next_y = complex_process(next_x.reshape(1, -1))

        # ãƒ‡ãƒ¼ã‚¿è¿½åŠ 
        X_all = np.vstack([X_all, next_x])
        y_all = np.hstack([y_all, next_y])
        best_values.append(y_all.max())

    return best_values

# å„ç²å¾—é–¢æ•°ã§ã®å®Ÿè¡Œ
acquisition_functions = ['EI', 'PI', 'UCB', 'Random']
results = {}

print("å„ç²å¾—é–¢æ•°ã§ã®æœ€é©åŒ–å®Ÿè¡Œä¸­...")
for acq_func in acquisition_functions:
    print(f"  {acq_func}...")
    results[acq_func] = run_bo_with_acquisition(acq_func, n_iterations=20)

# çµæœã®å¯è¦–åŒ–
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))

# åæŸæ›²ç·š
for acq_func, best_vals in results.items():
    ax1.plot(best_vals, marker='o', label=acq_func, linewidth=2, markersize=4)

ax1.set_xlabel('Iteration')
ax1.set_ylabel('Best Value Found')
ax1.set_title('Convergence Comparison')
ax1.legend()
ax1.grid(alpha=0.3)

# æœ€çµ‚æ€§èƒ½ã®æ¯”è¼ƒ
final_values = [vals[-1] for vals in results.values()]
colors = ['green', 'blue', 'red', 'gray']
ax2.bar(acquisition_functions, final_values, color=colors, alpha=0.7)
ax2.set_ylabel('Final Best Value')
ax2.set_title('Final Performance Comparison')
ax2.grid(axis='y', alpha=0.3)

# å€¤ã‚’è¡¨ç¤º
for i, (func, val) in enumerate(zip(acquisition_functions, final_values)):
    ax2.text(i, val, f'{val:.2f}', ha='center', va='bottom', fontweight='bold')

plt.tight_layout()
plt.savefig('acquisition_comparison.png', dpi=150, bbox_inches='tight')

# çµ±è¨ˆã‚µãƒãƒªãƒ¼
print("\n=== ç²å¾—é–¢æ•°æ¯”è¼ƒçµæœ ===")
print(f"{'é–¢æ•°':<10} {'æœ€çµ‚å€¤':<10} {'æ”¹å–„é‡':<10} {'20å›ã§ã®åˆ°é”ç‡'}")
print("-" * 50)
for acq_func, best_vals in results.items():
    improvement = best_vals[-1] - best_vals[0]
    convergence = (best_vals[-1] - best_vals[0]) / (max(final_values) - best_vals[0]) * 100
    print(f"{acq_func:<10} {best_vals[-1]:<10.3f} {improvement:<10.3f} {convergence:>6.1f}%")

print("\næ¨å¥¨ç²å¾—é–¢æ•°:")
best_acq = max(results.keys(), key=lambda k: results[k][-1])
print(f"  æœ€è‰¯æ€§èƒ½: {best_acq}")
print(f"  æœ€çµ‚å€¤: {results[best_acq][-1]:.3f}")
</code></pre>

            <div class="success-box">
                <h4>âœ… æ¯”è¼ƒå®Ÿé¨“ã‹ã‚‰ã®çŸ¥è¦‹</h4>
                <ul>
                    <li><strong>EI</strong>: æœ€ã‚‚ãƒãƒ©ãƒ³ã‚¹ãŒè‰¯ãã€å¤šãã®ã‚±ãƒ¼ã‚¹ã§æ¨å¥¨</li>
                    <li><strong>UCB</strong>: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´ã§æŸ”è»Ÿæ€§é«˜ã„</li>
                    <li><strong>PI</strong>: ä¿å®ˆçš„ã€å±€æ‰€æœ€é©ã«é™¥ã‚Šã‚„ã™ã„</li>
                    <li><strong>Random</strong>: ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ï¼ˆBOã®å„ªä½æ€§ç¢ºèªç”¨ï¼‰</li>
                </ul>
            </div>
        </section>

        <section>
            <h2>3.9 å®Ÿå‹™ã§ã®ç²å¾—é–¢æ•°é¸æŠã‚¬ã‚¤ãƒ‰</h2>

            <table>
                <thead>
                    <tr>
                        <th>ç²å¾—é–¢æ•°</th>
                        <th>é©ç”¨å ´é¢</th>
                        <th>é•·æ‰€</th>
                        <th>çŸ­æ‰€</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><strong>EI</strong></td>
                        <td>ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆæ¨å¥¨ã€å¤šç›®çš„</td>
                        <td>ãƒãƒ©ãƒ³ã‚¹è‰¯å¥½ã€ç†è«–çš„è£ä»˜ã‘</td>
                        <td>ãƒã‚¤ã‚ºã«æ•æ„Ÿ</td>
                    </tr>
                    <tr>
                        <td><strong>PI</strong></td>
                        <td>ä¿å®ˆçš„ãªæœ€é©åŒ–</td>
                        <td>å®Ÿè£…ç°¡å˜ã€è§£é‡ˆå®¹æ˜“</td>
                        <td>æ´»ç”¨ã«åã‚ŠãŒã¡</td>
                    </tr>
                    <tr>
                        <td><strong>UCB</strong></td>
                        <td>æ¢ç´¢åº¦åˆã„ã®èª¿æ•´å¿…è¦</td>
                        <td>ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§åˆ¶å¾¡å¯èƒ½</td>
                        <td>ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿é¸æŠãŒé›£ã—ã„</td>
                    </tr>
                    <tr>
                        <td><strong>Thompson Sampling</strong></td>
                        <td>ä¸¦åˆ—å®Ÿé¨“ã€å¤šè…•ãƒãƒ³ãƒ‡ã‚£ãƒƒãƒˆ</td>
                        <td>ç†è«–çš„æœ€é©æ€§ã€å¤šæ§˜æ€§</td>
                        <td>ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã‚³ã‚¹ãƒˆ</td>
                    </tr>
                    <tr>
                        <td><strong>KG</strong></td>
                        <td>é«˜ä¾¡ãªå®Ÿé¨“ã€å°‘æ•°ã‚µãƒ³ãƒ—ãƒ«</td>
                        <td>å…ˆèª­ã¿æœ€é©ã€åŠ¹ç‡çš„</td>
                        <td>è¨ˆç®—ã‚³ã‚¹ãƒˆå¤§</td>
                    </tr>
                    <tr>
                        <td><strong>Entropy Search</strong></td>
                        <td>æœ€é©è§£ã®åŒå®šãŒç›®çš„</td>
                        <td>æƒ…å ±ç†è«–çš„å³å¯†æ€§</td>
                        <td>å®Ÿè£…è¤‡é›‘</td>
                    </tr>
                </tbody>
            </table>

            <div class="info-box">
                <h4>ğŸ’¡ å®Ÿå‹™ã§ã®æ¨å¥¨æˆ¦ç•¥</h4>
                <ol>
                    <li><strong>ã¾ãšEIã‚’è©¦ã™</strong>: å¤šãã®ã‚±ãƒ¼ã‚¹ã§è‰¯å¥½ãªæ€§èƒ½</li>
                    <li><strong>æ¢ç´¢ãŒä¸è¶³</strong>: UCBï¼ˆkappaå¢—åŠ ï¼‰ã¾ãŸã¯Thompson Sampling</li>
                    <li><strong>åæŸãŒé…ã„</strong>: PIï¼ˆæ´»ç”¨é‡è¦–ï¼‰ã¾ãŸã¯EIï¼ˆxiæ¸›å°‘ï¼‰</li>
                    <li><strong>ä¸¦åˆ—å®Ÿé¨“</strong>: Thompson Samplingã¾ãŸã¯ãƒãƒƒãƒUCB</li>
                    <li><strong>å®Ÿé¨“ã‚³ã‚¹ãƒˆæ¥µå¤§</strong>: Knowledge Gradient</li>
                </ol>
            </div>
        </section>

        <section>
            <h2>ã¾ã¨ã‚</h2>

            <p>æœ¬ç« ã§ã¯ã€ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã®å¿ƒè‡“éƒ¨ã§ã‚ã‚‹ç²å¾—é–¢æ•°ã‚’7ã¤ã®å®Ÿè£…ä¾‹ã¨ã¨ã‚‚ã«å­¦ç¿’ã—ã¾ã—ãŸã€‚</p>

            <h3>é‡è¦ãƒã‚¤ãƒ³ãƒˆ</h3>
            <ul>
                <li><strong>æ¢ç´¢ã¨æ´»ç”¨</strong>: ã™ã¹ã¦ã®ç²å¾—é–¢æ•°ã¯ã“ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’åˆ¶å¾¡</li>
                <li><strong>EIãŒåŸºæœ¬</strong>: è¿·ã£ãŸã‚‰Expected Improvementã‹ã‚‰é–‹å§‹</li>
                <li><strong>UCBã®æŸ”è»Ÿæ€§</strong>: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§æ¢ç´¢åº¦åˆã„ã‚’æ˜ç¤ºçš„ã«èª¿æ•´å¯èƒ½</li>
                <li><strong>Thompson Samplingã®ç†è«–æ€§</strong>: ãƒ™ã‚¤ã‚ºçš„ã«æœ€é©ã€ä¸¦åˆ—åŒ–ã«ã‚‚æœ‰åŠ¹</li>
                <li><strong>çŠ¶æ³ã«å¿œã˜ãŸé¸æŠ</strong>: å•é¡Œã®æ€§è³ªã‚„é€²æ—ã§ç²å¾—é–¢æ•°ã‚’å¤‰æ›´ã™ã‚‹ã“ã¨ã‚‚æœ‰åŠ¹</li>
            </ul>

            <h3>æ¬¡ç« ã®äºˆå‘Š</h3>
            <p>
                ç¬¬4ç« ã§ã¯ã€å®Ÿãƒ—ãƒ­ã‚»ã‚¹ã§é »å‡ºã™ã‚‹<strong>å¤šç›®çš„æœ€é©åŒ–</strong>ï¼ˆå“è³ªã¨åŠ¹ç‡ã®ä¸¡ç«‹ãªã©ï¼‰ã¨
                <strong>åˆ¶ç´„ä»˜ãæœ€é©åŒ–</strong>ï¼ˆå®‰å…¨é ˜åŸŸå†…ã§ã®æœ€é©åŒ–ï¼‰ã‚’æ‰±ã„ã¾ã™ã€‚
                è¤‡æ•°ã®ç²å¾—é–¢æ•°ã‚’çµ„ã¿åˆã‚ã›ãŸé«˜åº¦ãªæˆ¦ç•¥ã‚‚å­¦ã³ã¾ã™ã€‚
            </p>
        </section>

        <nav class="navigation">
            <a href="chapter-2.html" class="nav-button">â† ç¬¬2ç« : ã‚¬ã‚¦ã‚¹éç¨‹</a>
            <a href="index.html" class="nav-button">ç›®æ¬¡ã«æˆ»ã‚‹</a>
            <a href="chapter-4.html" class="nav-button">ç¬¬4ç« : å¤šç›®çš„ãƒ»åˆ¶ç´„ä»˜ãæœ€é©åŒ– â†’</a>
        </nav>
    <section class="disclaimer">
<h3>å…è²¬äº‹é …</h3>
<ul>
<li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯æ•™è‚²ãƒ»ç ”ç©¶ãƒ»æƒ…å ±æä¾›ã®ã¿ã‚’ç›®çš„ã¨ã—ã¦ãŠã‚Šã€å°‚é–€çš„ãªåŠ©è¨€(æ³•å¾‹ãƒ»ä¼šè¨ˆãƒ»æŠ€è¡“çš„ä¿è¨¼ãªã©)ã‚’æä¾›ã™ã‚‹ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚</li>
<li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŠã‚ˆã³ä»˜éšã™ã‚‹Code examplesã¯ã€Œç¾çŠ¶æœ‰å§¿(AS IS)ã€ã§æä¾›ã•ã‚Œã€æ˜ç¤ºã¾ãŸã¯é»™ç¤ºã‚’å•ã‚ãšã€å•†å“æ€§ã€ç‰¹å®šç›®çš„é©åˆæ€§ã€æ¨©åˆ©éä¾µå®³ã€æ­£ç¢ºæ€§ãƒ»å®Œå…¨æ€§ã€å‹•ä½œãƒ»å®‰å…¨æ€§ç­‰ã„ã‹ãªã‚‹ä¿è¨¼ã‚‚ã—ã¾ã›ã‚“ã€‚</li>
<li>å¤–éƒ¨ãƒªãƒ³ã‚¯ã€ç¬¬ä¸‰è€…ãŒæä¾›ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ»ãƒ„ãƒ¼ãƒ«ãƒ»ãƒ©ã‚¤ãƒ–ãƒ©ãƒªç­‰ã®å†…å®¹ãƒ»å¯ç”¨æ€§ãƒ»å®‰å…¨æ€§ã«ã¤ã„ã¦ã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯ä¸€åˆ‡ã®è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚</li>
<li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®åˆ©ç”¨ãƒ»å®Ÿè¡Œãƒ»è§£é‡ˆã«ã‚ˆã‚Šç›´æ¥çš„ãƒ»é–“æ¥çš„ãƒ»ä»˜éšçš„ãƒ»ç‰¹åˆ¥ãƒ»çµæœçš„ãƒ»æ‡²ç½°çš„æå®³ãŒç”Ÿã˜ãŸå ´åˆã§ã‚‚ã€é©ç”¨æ³•ã§è¨±å®¹ã•ã‚Œã‚‹æœ€å¤§é™ã®ç¯„å›²ã§ã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚</li>
<li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å†…å®¹ã¯ã€äºˆå‘Šãªãå¤‰æ›´ãƒ»æ›´æ–°ãƒ»æä¾›åœæ­¢ã•ã‚Œã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚</li>
<li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®è‘—ä½œæ¨©ãƒ»ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯æ˜è¨˜ã•ã‚ŒãŸæ¡ä»¶(ä¾‹: CC BY 4.0)ã«å¾“ã„ã¾ã™ã€‚å½“è©²ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯é€šå¸¸ã€ç„¡ä¿è¨¼æ¡é …ã‚’å«ã¿ã¾ã™ã€‚</li>
</ul>
</section>

</main>

    <footer style="text-align: center; padding: 2rem; color: #666; border-top: 1px solid #e2e8f0; margin-top: 3rem;">
        <p>&copy; 2025 PI Terakoya - Dr. Yusuke Hashimoto, Tohoku University</p>
        <p style="font-size: 0.9rem; margin-top: 0.5rem;">
            <a href="https://creativecommons.org/licenses/by/4.0/" style="color: #11998e;">CC BY 4.0</a> |
            <a href="mailto:yusuke.hashimoto.b8@tohoku.ac.jp" style="color: #11998e;">Contact</a>
        </p>
    </footer>
</body>
</html>
