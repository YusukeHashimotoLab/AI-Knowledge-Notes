<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="ç¬¬4ç« ï¼šå¤šç›®çš„ãƒ»åˆ¶ç´„ä»˜ãæœ€é©åŒ– - ãƒ™ã‚¤ã‚ºæœ€é©åŒ–å…¥é–€ã‚·ãƒªãƒ¼ã‚º">
    <title>ç¬¬4ç« ï¼šå¤šç›®çš„ãƒ»åˆ¶ç´„ä»˜ãæœ€é©åŒ– - ãƒ™ã‚¤ã‚ºæœ€é©åŒ–å…¥é–€ | PI Terakoya</title>

    <style>
        :root {
            --color-primary: #2c3e50;
            --color-primary-dark: #1a252f;
            --color-accent: #11998e;
            --color-accent-light: #38ef7d;
            --color-text: #2d3748;
            --color-text-light: #4a5568;
            --color-bg: #ffffff;
            --color-bg-alt: #f7fafc;
            --color-border: #e2e8f0;
            --color-code-bg: #f8f9fa;
            --color-link: #11998e;
            --color-link-hover: #0d7a6f;

            --spacing-xs: 0.5rem;
            --spacing-sm: 1rem;
            --spacing-md: 1.5rem;
            --spacing-lg: 2rem;
            --spacing-xl: 3rem;

            --font-body: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            --font-mono: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;

            --border-radius: 8px;
            --box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: var(--font-body);
            line-height: 1.7;
            color: var(--color-text);
            background-color: var(--color-bg);
            font-size: 16px;
        }

        header {
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            padding: var(--spacing-xl) var(--spacing-md);
            margin-bottom: var(--spacing-xl);
            box-shadow: var(--box-shadow);
        }

        .header-content {
            max-width: 900px;
            margin: 0 auto;
        }

        h1 {
            font-size: 2rem;
            font-weight: 700;
            margin-bottom: var(--spacing-sm);
            line-height: 1.2;
        }

        .subtitle {
            font-size: 1.1rem;
            opacity: 0.95;
            font-weight: 400;
            margin-bottom: var(--spacing-md);
        }

        .meta {
            display: flex;
            flex-wrap: wrap;
            gap: var(--spacing-md);
            font-size: 0.9rem;
            opacity: 0.9;
        }

        .meta-item {
            display: flex;
            align-items: center;
            gap: 0.3rem;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 0 var(--spacing-md) var(--spacing-xl);
        }

        h2 {
            font-size: 1.75rem;
            color: var(--color-primary);
            margin-top: var(--spacing-xl);
            margin-bottom: var(--spacing-md);
            padding-bottom: var(--spacing-xs);
            border-bottom: 3px solid var(--color-accent);
        }

        h3 {
            font-size: 1.3rem;
            color: var(--color-primary-dark);
            margin-top: var(--spacing-lg);
            margin-bottom: var(--spacing-sm);
        }

        h4 {
            font-size: 1.1rem;
            color: var(--color-text);
            margin-top: var(--spacing-md);
            margin-bottom: var(--spacing-sm);
        }

        p {
            margin-bottom: var(--spacing-md);
        }

        a {
            color: var(--color-link);
            text-decoration: none;
            border-bottom: 1px solid transparent;
            transition: border-color 0.3s;
        }

        a:hover {
            color: var(--color-link-hover);
            border-bottom-color: var(--color-link-hover);
        }

        code {
            font-family: var(--font-mono);
            background-color: var(--color-code-bg);
            padding: 0.2rem 0.4rem;
            border-radius: 3px;
            font-size: 0.9em;
            border: 1px solid var(--color-border);
        }

        pre {
            background-color: var(--color-code-bg);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            overflow-x: auto;
            margin-bottom: var(--spacing-md);
        }

        pre code {
            background: none;
            border: none;
            padding: 0;
            font-size: 0.9rem;
            line-height: 1.5;
        }

        ul, ol {
            margin-bottom: var(--spacing-md);
            padding-left: var(--spacing-lg);
        }

        li {
            margin-bottom: var(--spacing-xs);
        }

        .info-box {
            background-color: #e6f7ff;
            border-left: 4px solid #1890ff;
            padding: var(--spacing-md);
            margin-bottom: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        .warning-box {
            background-color: #fff7e6;
            border-left: 4px solid #fa8c16;
            padding: var(--spacing-md);
            margin-bottom: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        .success-box {
            background-color: #f6ffed;
            border-left: 4px solid #52c41a;
            padding: var(--spacing-md);
            margin-bottom: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        .navigation {
            display: flex;
            justify-content: space-between;
            margin-top: var(--spacing-xl);
            padding-top: var(--spacing-lg);
            border-top: 1px solid var(--color-border);
            flex-wrap: wrap;
            gap: var(--spacing-sm);
        }

        .nav-button {
            display: inline-block;
            padding: var(--spacing-sm) var(--spacing-md);
            background-color: var(--color-accent);
            color: white;
            border-radius: var(--border-radius);
            transition: background-color 0.3s, transform 0.2s;
            border: none;
            cursor: pointer;
        }

        .nav-button:hover {
            background-color: var(--color-link-hover);
            transform: translateY(-2px);
            color: white;
            border-bottom: none;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: var(--spacing-md);
            background-color: white;
            box-shadow: var(--box-shadow);
        }

        th, td {
            padding: var(--spacing-sm);
            text-align: left;
            border-bottom: 1px solid var(--color-border);
        }

        th {
            background-color: var(--color-bg-alt);
            font-weight: 600;
            color: var(--color-primary);
        }

        tr:hover {
            background-color: var(--color-bg-alt);
        }

        @media (max-width: 768px) {
            h1 {
                font-size: 1.5rem;
            }

            h2 {
                font-size: 1.3rem;
            }

            h3 {
                font-size: 1.1rem;
            }

            .meta {
                font-size: 0.85rem;
            }

            pre {
                padding: var(--spacing-sm);
            }

            pre code {
                font-size: 0.8rem;
            }
        }
    </style>
</head>
<body>
    <header>
        <div class="header-content">
            <h1>ç¬¬4ç« ï¼šå¤šç›®çš„ãƒ»åˆ¶ç´„ä»˜ãæœ€é©åŒ–</h1>
            <p class="subtitle">è¤‡é›‘ãªå®Ÿä¸–ç•Œå•é¡Œã¸ã®å¯¾å¿œ</p>
            <div class="meta">
                <span class="meta-item">ğŸ“š ãƒ™ã‚¤ã‚ºæœ€é©åŒ–å…¥é–€ã‚·ãƒªãƒ¼ã‚º</span>
                <span class="meta-item">â±ï¸ èª­äº†æ™‚é–“: 35åˆ†</span>
                <span class="meta-item">ğŸ“Š é›£æ˜“åº¦: ä¸­ç´šã€œä¸Šç´š</span>
                <span class="meta-item">ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹: 7å€‹</span>
            </div>
        </div>
    </header>

    <main class="container">
        <section>
            <h2>4.1 å®Ÿä¸–ç•Œã®è¤‡é›‘æ€§</h2>

            <p>
                å®Ÿéš›ã®ãƒ—ãƒ­ã‚»ã‚¹æœ€é©åŒ–ã§ã¯ã€å˜ä¸€ã®ç›®çš„é–¢æ•°ã‚’æœ€å¤§åŒ–ã™ã‚‹ã ã‘ã§ã¯ä¸ååˆ†ã§ã™ã€‚
                å“è³ªã¨åŠ¹ç‡ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã€å®‰å…¨æ€§åˆ¶ç´„ã€ç‰©ç†çš„åˆ¶ç´„ãªã©ã€è¤‡æ•°ã®è¦æ±‚ã‚’åŒæ™‚ã«æº€ãŸã™å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚
            </p>

            <div class="info-box">
                <h4>ğŸ’¡ å®Ÿãƒ—ãƒ­ã‚»ã‚¹ã®å…¸å‹çš„ãªè¦æ±‚</h4>
                <ul>
                    <li><strong>å¤šç›®çš„</strong>: åç‡â†‘ ã‹ã¤ ã‚¨ãƒãƒ«ã‚®ãƒ¼â†“ ã‹ã¤ ã‚³ã‚¹ãƒˆâ†“</li>
                    <li><strong>åˆ¶ç´„</strong>: æ¸©åº¦ â‰¤ 150Â°Cã€åœ§åŠ› â‰¤ 5 barã€pH 6-8</li>
                    <li><strong>å®Ÿç¾å¯èƒ½æ€§</strong>: ç‰©ç†çš„ã«å¯èƒ½ãªæ¡ä»¶ã®ã¿</li>
                    <li><strong>å®‰å…¨æ€§</strong>: çˆ†ç™ºé™ç•Œå¤–ã€æ¯’æ€§ç‰©è³ªæ¿ƒåº¦åˆ¶é™</li>
                </ul>
            </div>

            <p>
                æœ¬ç« ã§ã¯ã€ã“ã‚Œã‚‰ã®è¤‡é›‘ãªè¦æ±‚ã«å¯¾å¿œã™ã‚‹ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã®æ‹¡å¼µæ‰‹æ³•ã‚’å­¦ã³ã¾ã™ã€‚
            </p>
        </section>

        <section>
            <h2>4.2 ãƒ‘ãƒ¬ãƒ¼ãƒˆãƒ•ãƒ­ãƒ³ãƒˆæ¢ç´¢</h2>

            <p>
                å¤šç›®çš„æœ€é©åŒ–ã§ã¯ã€ã™ã¹ã¦ã®ç›®çš„ã§æœ€è‰¯ã®å˜ä¸€è§£ã¯å­˜åœ¨ã—ã¾ã›ã‚“ã€‚
                ä»£ã‚ã‚Šã«ã€ãƒ‘ãƒ¬ãƒ¼ãƒˆæœ€é©è§£ã®é›†åˆï¼ˆãƒ‘ãƒ¬ãƒ¼ãƒˆãƒ•ãƒ­ãƒ³ãƒˆï¼‰ã‚’æ±‚ã‚ã¾ã™ã€‚
            </p>

            <h3>Example 1: å¤šç›®çš„ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ï¼ˆåç‡ vs ã‚¨ãƒãƒ«ã‚®ãƒ¼ï¼‰</h3>

            <pre><code># å¤šç›®çš„ãƒ™ã‚¤ã‚ºæœ€é©åŒ–: ãƒ‘ãƒ¬ãƒ¼ãƒˆãƒ•ãƒ­ãƒ³ãƒˆæ¢ç´¢
import numpy as np
import matplotlib.pyplot as plt
from sklearn.gaussian_process import GaussianProcessRegressor
from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C

# 2ç›®çš„ã®ãƒ—ãƒ­ã‚»ã‚¹é–¢æ•°ï¼ˆåç‡ã¨ã‚¨ãƒãƒ«ã‚®ãƒ¼æ¶ˆè²»ï¼‰
def process_objectives(X):
    """
    Args:
        X: [temperature, pressure] (N, 2)
    Returns:
        yield: åç‡ (æœ€å¤§åŒ–ã—ãŸã„)
        energy: ã‚¨ãƒãƒ«ã‚®ãƒ¼æ¶ˆè²» (æœ€å°åŒ–ã—ãŸã„)
    """
    temp, pres = X[:, 0], X[:, 1]

    # åç‡ãƒ¢ãƒ‡ãƒ«ï¼ˆæ¸©åº¦ãƒ»åœ§åŠ›ã®é–¢æ•°ï¼‰
    yield_rate = (
        50 + 20 * np.sin(temp/20) +
        15 * np.cos(pres/10) -
        0.1 * (temp - 100)**2 -
        0.05 * (pres - 50)**2 +
        np.random.normal(0, 1, len(temp))
    )

    # ã‚¨ãƒãƒ«ã‚®ãƒ¼æ¶ˆè²»ï¼ˆæ¸©åº¦ãƒ»åœ§åŠ›ã«æ¯”ä¾‹ï¼‰
    energy = (
        0.5 * temp + 0.3 * pres +
        0.01 * temp * pres +
        np.random.normal(0, 2, len(temp))
    )

    return yield_rate, energy

# ãƒ‘ãƒ¬ãƒ¼ãƒˆæ”¯é…ã®åˆ¤å®š
def is_pareto_efficient(costs):
    """ãƒ‘ãƒ¬ãƒ¼ãƒˆæœ€é©è§£ã®åˆ¤å®šï¼ˆæœ€å°åŒ–å•é¡Œã«å¤‰æ›ï¼‰

    Args:
        costs: (N, M) ç›®çš„é–¢æ•°å€¤ï¼ˆæœ€å°åŒ–æ–¹å‘ï¼‰
    Returns:
        is_efficient: (N,) boolé…åˆ—
    """
    is_efficient = np.ones(costs.shape[0], dtype=bool)
    for i, c in enumerate(costs):
        if is_efficient[i]:
            # iã‚ˆã‚Šå…¨ã¦ã®ç›®çš„ã§åŠ£ã‚‹ç‚¹ã¯éåŠ¹ç‡
            is_efficient[is_efficient] = np.any(
                costs[is_efficient] < c, axis=1
            )
            is_efficient[i] = True
    return is_efficient

# å¤šç›®çš„ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã®å®Ÿè¡Œ
np.random.seed(42)
n_iterations = 30

# åˆæœŸã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
X = np.random.uniform([50, 20], [150, 80], (10, 2))
Y1, Y2 = process_objectives(X)

# è¨˜éŒ²ç”¨
all_X = X.copy()
all_Y1 = Y1.copy()
all_Y2 = Y2.copy()

for iteration in range(n_iterations):
    # å„ç›®çš„ã§GPãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰
    kernel = C(1.0) * RBF([10.0, 10.0])

    gp1 = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=5)
    gp1.fit(all_X, all_Y1)

    gp2 = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=5)
    gp2.fit(all_X, all_Y2)

    # å€™è£œç‚¹ã®ç”Ÿæˆ
    X_candidates = np.random.uniform([50, 20], [150, 80], (500, 2))

    # å„å€™è£œã§ã®äºˆæ¸¬
    mu1, sigma1 = gp1.predict(X_candidates, return_std=True)
    mu2, sigma2 = gp2.predict(X_candidates, return_std=True)

    # ã‚¹ã‚«ãƒ©ãƒ¼åŒ–: weighted sum with uncertainty
    # åç‡æœ€å¤§åŒ– = -åç‡æœ€å°åŒ–
    # é‡ã¿ã‚’åå¾©ã”ã¨ã«å¤‰åŒ–ã•ã›ã¦å¤šæ§˜ãªãƒ‘ãƒ¬ãƒ¼ãƒˆè§£ã‚’æ¢ç´¢
    weight = iteration / n_iterations  # 0â†’1
    scalarized = (
        -(1 - weight) * (mu1 + 2 * sigma1) +  # åç‡ï¼ˆæœ€å¤§åŒ–ï¼‰
        weight * (mu2 - 2 * sigma2)            # ã‚¨ãƒãƒ«ã‚®ãƒ¼ï¼ˆæœ€å°åŒ–ï¼‰
    )

    # æ¬¡ã®å®Ÿé¨“ç‚¹
    next_idx = np.argmin(scalarized)
    next_x = X_candidates[next_idx]

    # å®Ÿé¨“å®Ÿè¡Œ
    next_y1, next_y2 = process_objectives(next_x.reshape(1, -1))

    # ãƒ‡ãƒ¼ã‚¿è¿½åŠ 
    all_X = np.vstack([all_X, next_x])
    all_Y1 = np.hstack([all_Y1, next_y1])
    all_Y2 = np.hstack([all_Y2, next_y2])

# ãƒ‘ãƒ¬ãƒ¼ãƒˆãƒ•ãƒ­ãƒ³ãƒˆã®æŠ½å‡º
costs = np.column_stack([-all_Y1, all_Y2])  # åç‡ã¯è² ã«ï¼ˆæœ€å°åŒ–å•é¡ŒåŒ–ï¼‰
pareto_mask = is_pareto_efficient(costs)
pareto_X = all_X[pareto_mask]
pareto_Y1 = all_Y1[pareto_mask]
pareto_Y2 = all_Y2[pareto_mask]

# ã‚½ãƒ¼ãƒˆï¼ˆå¯è¦–åŒ–ç”¨ï¼‰
sorted_idx = np.argsort(pareto_Y1)
pareto_Y1_sorted = pareto_Y1[sorted_idx]
pareto_Y2_sorted = pareto_Y2[sorted_idx]

# å¯è¦–åŒ–
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))

# ç›®çš„é–¢æ•°ç©ºé–“
ax1.scatter(all_Y1, all_Y2, c='lightgray', alpha=0.5, s=30, label='All evaluations')
ax1.scatter(pareto_Y1, pareto_Y2, c='red', s=100, marker='*',
            label=f'Pareto front ({len(pareto_Y1)} points)', zorder=10)
ax1.plot(pareto_Y1_sorted, pareto_Y2_sorted, 'r--', alpha=0.5, linewidth=2)
ax1.set_xlabel('Yield (%)', fontsize=12)
ax1.set_ylabel('Energy Consumption (kWh)', fontsize=12)
ax1.set_title('Pareto Front in Objective Space', fontsize=13, fontweight='bold')
ax1.legend()
ax1.grid(alpha=0.3)

# æ±ºå®šå¤‰æ•°ç©ºé–“
scatter = ax2.scatter(pareto_X[:, 0], pareto_X[:, 1], c=pareto_Y1,
                      s=150, cmap='RdYlGn', marker='*', edgecolors='black', linewidth=1.5)
ax2.set_xlabel('Temperature (Â°C)', fontsize=12)
ax2.set_ylabel('Pressure (bar)', fontsize=12)
ax2.set_title('Pareto Solutions in Decision Space', fontsize=13, fontweight='bold')
cbar = plt.colorbar(scatter, ax=ax2)
cbar.set_label('Yield (%)', fontsize=10)
ax2.grid(alpha=0.3)

plt.tight_layout()
plt.savefig('pareto_front.png', dpi=150, bbox_inches='tight')

print(f"ç™ºè¦‹ã—ãŸãƒ‘ãƒ¬ãƒ¼ãƒˆæœ€é©è§£: {len(pareto_Y1)}å€‹")
print(f"\nä»£è¡¨çš„ãªãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•è§£:")
print(f"  é«˜åç‡é‡è¦–: åç‡={pareto_Y1.max():.1f}%, ã‚¨ãƒãƒ«ã‚®ãƒ¼={pareto_Y2[np.argmax(pareto_Y1)]:.1f}kWh")
print(f"  ä½ã‚¨ãƒãƒ«ã‚®ãƒ¼é‡è¦–: åç‡={pareto_Y1[np.argmin(pareto_Y2)]:.1f}%, ã‚¨ãƒãƒ«ã‚®ãƒ¼={pareto_Y2.min():.1f}kWh")
</code></pre>

            <div class="success-box">
                <h4>âœ… ãƒ‘ãƒ¬ãƒ¼ãƒˆæœ€é©åŒ–ã®åˆ©ç‚¹</h4>
                <ul>
                    <li>è¤‡æ•°ã®ç›®çš„é–“ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’å¯è¦–åŒ–</li>
                    <li>æ„æ€æ±ºå®šè€…ãŒå¥½ã¿ã«å¿œã˜ã¦è§£ã‚’é¸æŠå¯èƒ½</li>
                    <li>ç›®çš„ã®é‡è¦åº¦ãŒäº‹å‰ã«ä¸æ˜ã§ã‚‚å¯¾å¿œå¯èƒ½</li>
                </ul>
            </div>
        </section>

        <section>
            <h2>4.3 Expected Hypervolume Improvement (EHVI)</h2>

            <p>
                å¤šç›®çš„æœ€é©åŒ–å°‚ç”¨ã®ç²å¾—é–¢æ•°ã€‚ãƒ‘ãƒ¬ãƒ¼ãƒˆãƒ•ãƒ­ãƒ³ãƒˆãŒå ã‚ã‚‹è¶…ä½“ç©ã®æ”¹å–„ã‚’æœ€å¤§åŒ–ã—ã¾ã™ã€‚
            </p>

            <h3>Example 2: EHVIç²å¾—é–¢æ•°ã®å®Ÿè£…</h3>

            <pre><code># Expected Hypervolume Improvement (EHVI)
from scipy.stats import norm

def compute_hypervolume_2d(pareto_front, ref_point):
    """2æ¬¡å…ƒã®ãƒã‚¤ãƒ‘ãƒ¼ãƒœãƒªãƒ¥ãƒ¼ãƒ è¨ˆç®—ï¼ˆç°¡æ˜“ç‰ˆï¼‰

    Args:
        pareto_front: (N, 2) ãƒ‘ãƒ¬ãƒ¼ãƒˆæœ€é©è§£ï¼ˆæœ€å°åŒ–å•é¡Œï¼‰
        ref_point: (2,) å‚ç…§ç‚¹
    """
    # ã‚½ãƒ¼ãƒˆ
    sorted_front = pareto_front[np.argsort(pareto_front[:, 0])]

    hv = 0.0
    prev_x = ref_point[0]

    for point in sorted_front:
        width = prev_x - point[0]
        height = ref_point[1] - point[1]
        if width > 0 and height > 0:
            hv += width * height
        prev_x = point[0]

    return hv

def expected_hypervolume_improvement(X, gp1, gp2, pareto_front, ref_point, n_samples=100):
    """EHVIç²å¾—é–¢æ•°ï¼ˆãƒ¢ãƒ³ãƒ†ã‚«ãƒ«ãƒ­è¿‘ä¼¼ï¼‰

    Args:
        X: è©•ä¾¡ç‚¹
        gp1, gp2: å„ç›®çš„ã®GPãƒ¢ãƒ‡ãƒ«
        pareto_front: ç¾åœ¨ã®ãƒ‘ãƒ¬ãƒ¼ãƒˆãƒ•ãƒ­ãƒ³ãƒˆ
        ref_point: å‚ç…§ç‚¹
        n_samples: ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ•°
    """
    mu1, sigma1 = gp1.predict(X, return_std=True)
    mu2, sigma2 = gp2.predict(X, return_std=True)

    # ç¾åœ¨ã®ãƒã‚¤ãƒ‘ãƒ¼ãƒœãƒªãƒ¥ãƒ¼ãƒ 
    current_hv = compute_hypervolume_2d(pareto_front, ref_point)

    ehvi = np.zeros(len(X))

    for i in range(len(X)):
        hv_improvements = []

        for _ in range(n_samples):
            # æ–°ç‚¹ã§ã®ç›®çš„é–¢æ•°å€¤ã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
            y1_new = np.random.normal(mu1[i], sigma1[i])
            y2_new = np.random.normal(mu2[i], sigma2[i])

            # æ–°ç‚¹ã‚’è¿½åŠ ã—ãŸãƒ‘ãƒ¬ãƒ¼ãƒˆãƒ•ãƒ­ãƒ³ãƒˆ
            new_front_candidates = np.vstack([
                pareto_front,
                [-y1_new, y2_new]  # åç‡ã¯è² ã«å¤‰æ›
            ])

            # æ–°ã—ã„ãƒ‘ãƒ¬ãƒ¼ãƒˆãƒ•ãƒ­ãƒ³ãƒˆ
            new_pareto_mask = is_pareto_efficient(new_front_candidates)
            new_pareto_front = new_front_candidates[new_pareto_mask]

            # ãƒã‚¤ãƒ‘ãƒ¼ãƒœãƒªãƒ¥ãƒ¼ãƒ æ”¹å–„
            new_hv = compute_hypervolume_2d(new_pareto_front, ref_point)
            hv_improvements.append(max(0, new_hv - current_hv))

        ehvi[i] = np.mean(hv_improvements)

    return ehvi

# EHVIã‚’ç”¨ã„ãŸå¤šç›®çš„BO
print("EHVIæœ€é©åŒ–å®Ÿè¡Œä¸­...")

# åˆæœŸè¨­å®š
X_init = np.random.uniform([50, 20], [150, 80], (10, 2))
Y1_init, Y2_init = process_objectives(X_init)

X_all = X_init.copy()
Y1_all = Y1_init.copy()
Y2_all = Y2_init.copy()

n_iter = 20

for iteration in range(n_iter):
    # GPãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰
    gp1 = GaussianProcessRegressor(kernel=C(1.0)*RBF([10, 10]), normalize_y=True)
    gp1.fit(X_all, Y1_all)

    gp2 = GaussianProcessRegressor(kernel=C(1.0)*RBF([10, 10]), normalize_y=True)
    gp2.fit(X_all, Y2_all)

    # ç¾åœ¨ã®ãƒ‘ãƒ¬ãƒ¼ãƒˆãƒ•ãƒ­ãƒ³ãƒˆ
    costs = np.column_stack([-Y1_all, Y2_all])
    pareto_mask = is_pareto_efficient(costs)
    current_pareto = costs[pareto_mask]

    # å‚ç…§ç‚¹ï¼ˆæœ€æ‚ªå€¤ã‚ˆã‚Šå°‘ã—æ‚ªã„ç‚¹ï¼‰
    ref_point = np.array([
        costs[:, 0].max() + 10,
        costs[:, 1].max() + 10
    ])

    # å€™è£œç‚¹
    X_candidates = np.random.uniform([50, 20], [150, 80], (100, 2))

    # EHVIè¨ˆç®—
    if iteration % 5 == 0:
        print(f"  Iteration {iteration}/{n_iter}")

    ehvi = expected_hypervolume_improvement(
        X_candidates, gp1, gp2, current_pareto, ref_point, n_samples=50
    )

    # æ¬¡å®Ÿé¨“ç‚¹
    next_x = X_candidates[np.argmax(ehvi)]
    next_y1, next_y2 = process_objectives(next_x.reshape(1, -1))

    X_all = np.vstack([X_all, next_x])
    Y1_all = np.hstack([Y1_all, next_y1])
    Y2_all = np.hstack([Y2_all, next_y2])

# æœ€çµ‚ãƒ‘ãƒ¬ãƒ¼ãƒˆãƒ•ãƒ­ãƒ³ãƒˆ
costs_final = np.column_stack([-Y1_all, Y2_all])
pareto_mask_final = is_pareto_efficient(costs_final)

print(f"\nEHVIæœ€é©åŒ–çµæœ:")
print(f"  è©•ä¾¡ç‚¹æ•°: {len(X_all)}")
print(f"  ãƒ‘ãƒ¬ãƒ¼ãƒˆæœ€é©è§£: {pareto_mask_final.sum()}å€‹")
print(f"  ãƒã‚¤ãƒ‘ãƒ¼ãƒœãƒªãƒ¥ãƒ¼ãƒ : {compute_hypervolume_2d(costs_final[pareto_mask_final], ref_point):.2f}")
</code></pre>

            <div class="info-box">
                <h4>ğŸ’¡ EHVIã®ç‰¹å¾´</h4>
                <ul>
                    <li>ãƒ‘ãƒ¬ãƒ¼ãƒˆãƒ•ãƒ­ãƒ³ãƒˆå…¨ä½“ã®æ”¹å–„ã‚’è€ƒæ…®ï¼ˆå˜ä¸€ç‚¹ã§ã¯ãªãï¼‰</li>
                    <li>3ç›®çš„ä»¥ä¸Šã§ã‚‚ç†è«–çš„ã«æ‹¡å¼µå¯èƒ½</li>
                    <li>è¨ˆç®—ã‚³ã‚¹ãƒˆã¯é«˜ã„ï¼ˆè¿‘ä¼¼æ‰‹æ³•ãŒæ¨å¥¨ï¼‰</li>
                </ul>
            </div>
        </section>

        <section>
            <h2>4.4 åˆ¶ç´„ä»˜ãæœ€é©åŒ–</h2>

            <p>
                å®Ÿãƒ—ãƒ­ã‚»ã‚¹ã§ã¯ã€ç‰©ç†çš„ãƒ»å®‰å…¨æ€§ã®åˆ¶ç´„ãŒå­˜åœ¨ã—ã¾ã™ã€‚
                åˆ¶ç´„é•åç‚¹ã§ã®è©•ä¾¡ã‚’é¿ã‘ãªãŒã‚‰æœ€é©åŒ–ã™ã‚‹æ‰‹æ³•ã‚’å­¦ã³ã¾ã™ã€‚
            </p>

            <h3>Example 3: ã‚¬ã‚¦ã‚¹éç¨‹ã«ã‚ˆã‚‹åˆ¶ç´„ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°</h3>

            <pre><code># åˆ¶ç´„ä»˜ããƒ™ã‚¤ã‚ºæœ€é©åŒ–
def constrained_process(X):
    """åˆ¶ç´„ä»˜ããƒ—ãƒ­ã‚»ã‚¹

    ç›®çš„: åå¿œé€Ÿåº¦ã‚’æœ€å¤§åŒ–
    åˆ¶ç´„: æ¸©åº¦ < 130Â°C ã‹ã¤ åœ§åŠ› < 60 barï¼ˆå®‰å…¨æ€§ï¼‰
    """
    temp, pres = X[:, 0], X[:, 1]

    # ç›®çš„é–¢æ•°ï¼ˆåå¿œé€Ÿåº¦ï¼‰
    rate = (
        10 + 0.5*temp + 0.3*pres -
        0.002*temp**2 - 0.001*pres**2 +
        0.01*temp*pres +
        np.random.normal(0, 0.5, len(temp))
    )

    # åˆ¶ç´„é–¢æ•°ï¼ˆè² ãªã‚‰åˆ¶ç´„é•åï¼‰
    # g1: 130 - temp >= 0
    # g2: 60 - pres >= 0
    constraint1 = 130 - temp
    constraint2 = 60 - pres

    return rate, constraint1, constraint2

def probability_of_feasibility(X, gp_constraints):
    """å®Ÿè¡Œå¯èƒ½ç¢ºç‡ã®è¨ˆç®—

    Args:
        X: è©•ä¾¡ç‚¹
        gp_constraints: [GP(c1), GP(c2), ...]
    Returns:
        prob: å…¨åˆ¶ç´„ã‚’æº€ãŸã™ç¢ºç‡
    """
    prob = np.ones(len(X))

    for gp_c in gp_constraints:
        mu_c, sigma_c = gp_c.predict(X, return_std=True)
        # c >= 0 ã®ç¢ºç‡
        prob *= norm.cdf(mu_c / (sigma_c + 1e-6))

    return prob

def constrained_ei(X, gp_obj, gp_constraints, y_best, xi=0.01):
    """åˆ¶ç´„ä»˜ãExpected Improvement

    Args:
        X: è©•ä¾¡ç‚¹
        gp_obj: ç›®çš„é–¢æ•°ã®GP
        gp_constraints: åˆ¶ç´„é–¢æ•°ã®GPãƒªã‚¹ãƒˆ
        y_best: å®Ÿè¡Œå¯èƒ½é ˜åŸŸã§ã®æœ€è‰¯å€¤
    """
    # é€šå¸¸ã®EI
    mu, sigma = gp_obj.predict(X, return_std=True)
    imp = mu - y_best - xi
    Z = imp / (sigma + 1e-6)
    ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)

    # å®Ÿè¡Œå¯èƒ½ç¢ºç‡ã§é‡ã¿ä»˜ã‘
    pof = probability_of_feasibility(X, gp_constraints)

    return ei * pof

# åˆ¶ç´„ä»˜ãBOå®Ÿè¡Œ
np.random.seed(42)

# åˆæœŸã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆåˆ¶ç´„é•åå«ã‚€ï¼‰
X = np.random.uniform([80, 30], [150, 80], (15, 2))
rate, c1, c2 = constrained_process(X)

X_all = X.copy()
rate_all = rate.copy()
c1_all = c1.copy()
c2_all = c2.copy()

n_iter = 25

for iteration in range(n_iter):
    # GPæ§‹ç¯‰ï¼ˆç›®çš„ã¨åˆ¶ç´„ï¼‰
    gp_obj = GaussianProcessRegressor(kernel=C(1.0)*RBF([10, 10]), normalize_y=True)
    gp_obj.fit(X_all, rate_all)

    gp_c1 = GaussianProcessRegressor(kernel=C(1.0)*RBF([10, 10]), normalize_y=True)
    gp_c1.fit(X_all, c1_all)

    gp_c2 = GaussianProcessRegressor(kernel=C(1.0)*RBF([10, 10]), normalize_y=True)
    gp_c2.fit(X_all, c2_all)

    # å®Ÿè¡Œå¯èƒ½é ˜åŸŸã§ã®æœ€è‰¯å€¤
    feasible_mask = (c1_all >= 0) & (c2_all >= 0)
    if feasible_mask.any():
        y_best = rate_all[feasible_mask].max()
    else:
        y_best = rate_all.min()  # ã¾ã å®Ÿè¡Œå¯èƒ½è§£ãŒãªã„

    # å€™è£œç‚¹
    X_cand = np.random.uniform([80, 30], [150, 80], (500, 2))

    # åˆ¶ç´„ä»˜ãEI
    cei = constrained_ei(X_cand, gp_obj, [gp_c1, gp_c2], y_best)

    # æ¬¡å®Ÿé¨“ç‚¹
    next_x = X_cand[np.argmax(cei)]
    next_rate, next_c1, next_c2 = constrained_process(next_x.reshape(1, -1))

    X_all = np.vstack([X_all, next_x])
    rate_all = np.hstack([rate_all, next_rate])
    c1_all = np.hstack([c1_all, next_c1])
    c2_all = np.hstack([c2_all, next_c2])

# çµæœåˆ†æ
final_feasible = (c1_all >= 0) & (c2_all >= 0)
feasible_X = X_all[final_feasible]
feasible_rate = rate_all[final_feasible]

best_idx = np.argmax(feasible_rate)
best_X = feasible_X[best_idx]
best_rate = feasible_rate[best_idx]

# å¯è¦–åŒ–
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))

# æ¢ç´¢å±¥æ­´
colors = ['red' if not f else 'green' for f in final_feasible]
ax1.scatter(X_all[:, 0], X_all[:, 1], c=colors, alpha=0.6, s=50)
ax1.scatter(best_X[0], best_X[1], c='gold', s=300, marker='*',
            edgecolors='black', linewidth=2, label='Best feasible', zorder=10)
ax1.axvline(130, color='red', linestyle='--', alpha=0.7, label='Temp constraint')
ax1.axhline(60, color='blue', linestyle='--', alpha=0.7, label='Pressure constraint')
ax1.fill_between([80, 130], 30, 60, alpha=0.1, color='green', label='Feasible region')
ax1.set_xlabel('Temperature (Â°C)', fontsize=12)
ax1.set_ylabel('Pressure (bar)', fontsize=12)
ax1.set_title('Constrained Optimization History', fontsize=13, fontweight='bold')
ax1.legend()
ax1.grid(alpha=0.3)

# åæŸæ›²ç·š
feasible_best = []
for i in range(len(rate_all)):
    mask = final_feasible[:i+1]
    if mask.any():
        feasible_best.append(rate_all[:i+1][mask].max())
    else:
        feasible_best.append(np.nan)

ax2.plot(feasible_best, 'g-', linewidth=2, marker='o', markersize=4)
ax2.set_xlabel('Iteration', fontsize=12)
ax2.set_ylabel('Best Feasible Reaction Rate', fontsize=12)
ax2.set_title('Convergence in Feasible Region', fontsize=13, fontweight='bold')
ax2.grid(alpha=0.3)

plt.tight_layout()
plt.savefig('constrained_optimization.png', dpi=150, bbox_inches='tight')

print(f"\nåˆ¶ç´„ä»˜ãæœ€é©åŒ–çµæœ:")
print(f"  ç·è©•ä¾¡ç‚¹æ•°: {len(X_all)}")
print(f"  å®Ÿè¡Œå¯èƒ½ç‚¹: {final_feasible.sum()} ({final_feasible.sum()/len(X_all)*100:.1f}%)")
print(f"  æœ€è‰¯å®Ÿè¡Œå¯èƒ½è§£:")
print(f"    æ¸©åº¦ = {best_X[0]:.1f}Â°C, åœ§åŠ› = {best_X[1]:.1f} bar")
print(f"    åå¿œé€Ÿåº¦ = {best_rate:.2f}")
</code></pre>

            <div class="success-box">
                <h4>âœ… åˆ¶ç´„ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°æˆ¦ç•¥</h4>
                <ul>
                    <li><strong>ã‚½ãƒ•ãƒˆåˆ¶ç´„</strong>: å®Ÿè¡Œå¯èƒ½ç¢ºç‡ã§é‡ã¿ä»˜ã‘ï¼ˆä¸Šè¨˜ä¾‹ï¼‰</li>
                    <li><strong>ãƒãƒ¼ãƒ‰åˆ¶ç´„</strong>: åˆ¶ç´„é•åç‚¹ã‚’å€™è£œã‹ã‚‰é™¤å¤–</li>
                    <li><strong>ãƒšãƒŠãƒ«ãƒ†ã‚£æ³•</strong>: ç›®çš„é–¢æ•°ã«ãƒšãƒŠãƒ«ãƒ†ã‚£é …è¿½åŠ </li>
                </ul>
            </div>
        </section>

        <section>
            <h2>4.5 Probability of Feasibility</h2>

            <p>
                åˆ¶ç´„ã‚’æº€ãŸã™ç¢ºç‡ã‚’æ˜ç¤ºçš„ã«ãƒ¢ãƒ‡ãƒ«åŒ–ã™ã‚‹æ‰‹æ³•ã€‚
            </p>

            <h3>Example 4: Probability of Feasibilityã®å®Ÿè£…</h3>

            <pre><code># Probability of Feasibility (PoF)ã®è©³ç´°å®Ÿè£…
def visualize_feasibility_probability(gp_constraints, X_grid):
    """å®Ÿè¡Œå¯èƒ½ç¢ºç‡ã®å¯è¦–åŒ–"""
    pof = probability_of_feasibility(X_grid, gp_constraints)
    return pof

# ã‚°ãƒªãƒƒãƒ‰ç”Ÿæˆ
temp_range = np.linspace(80, 150, 100)
pres_range = np.linspace(30, 80, 100)
Temp, Pres = np.meshgrid(temp_range, pres_range)
X_grid = np.column_stack([Temp.ravel(), Pres.ravel()])

# æœ€çµ‚ãƒ¢ãƒ‡ãƒ«ã§ã®PoF
gp_c1_final = GaussianProcessRegressor(kernel=C(1.0)*RBF([10, 10]))
gp_c1_final.fit(X_all, c1_all)

gp_c2_final = GaussianProcessRegressor(kernel=C(1.0)*RBF([10, 10]))
gp_c2_final.fit(X_all, c2_all)

pof_grid = visualize_feasibility_probability([gp_c1_final, gp_c2_final], X_grid)
PoF = pof_grid.reshape(Temp.shape)

# ç›®çš„é–¢æ•°ã®äºˆæ¸¬
gp_obj_final = GaussianProcessRegressor(kernel=C(1.0)*RBF([10, 10]))
gp_obj_final.fit(X_all, rate_all)
rate_pred = gp_obj_final.predict(X_grid).reshape(Temp.shape)

# å¯è¦–åŒ–
fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 5))

# PoF
im1 = ax1.contourf(Temp, Pres, PoF, levels=20, cmap='RdYlGn')
ax1.contour(Temp, Pres, PoF, levels=[0.9, 0.95, 0.99], colors='black',
            linewidths=1.5, linestyles='--')
ax1.scatter(X_all[:, 0], X_all[:, 1], c='blue', s=30, alpha=0.6, edgecolors='white')
ax1.set_xlabel('Temperature (Â°C)')
ax1.set_ylabel('Pressure (bar)')
ax1.set_title('Probability of Feasibility')
plt.colorbar(im1, ax=ax1, label='PoF')

# äºˆæ¸¬åå¿œé€Ÿåº¦
im2 = ax2.contourf(Temp, Pres, rate_pred, levels=20, cmap='viridis')
ax2.contour(Temp, Pres, PoF, levels=[0.5], colors='red', linewidths=2, linestyles='-')
ax2.scatter(best_X[0], best_X[1], c='gold', s=300, marker='*', edgecolors='black', linewidth=2)
ax2.set_xlabel('Temperature (Â°C)')
ax2.set_ylabel('Pressure (bar)')
ax2.set_title('Predicted Reaction Rate')
plt.colorbar(im2, ax=ax2, label='Rate')

# åˆ¶ç´„ä»˜ãEI
cei_grid = constrained_ei(X_grid, gp_obj_final, [gp_c1_final, gp_c2_final],
                          rate_all[final_feasible].max())
CEI = cei_grid.reshape(Temp.shape)

im3 = ax3.contourf(Temp, Pres, CEI, levels=20, cmap='plasma')
ax3.scatter(X_all[:, 0], X_all[:, 1], c='white', s=20, alpha=0.8)
ax3.set_xlabel('Temperature (Â°C)')
ax3.set_ylabel('Pressure (bar)')
ax3.set_title('Constrained EI Acquisition')
plt.colorbar(im3, ax=ax3, label='CEI')

plt.tight_layout()
plt.savefig('pof_landscape.png', dpi=150, bbox_inches='tight')

print("\nå®Ÿè¡Œå¯èƒ½ç¢ºç‡ã®çµ±è¨ˆ:")
print(f"  PoF > 0.5: {(PoF > 0.5).sum() / PoF.size * 100:.1f}%")
print(f"  PoF > 0.9: {(PoF > 0.9).sum() / PoF.size * 100:.1f}%")
print(f"  PoF > 0.99: {(PoF > 0.99).sum() / PoF.size * 100:.1f}%")
</code></pre>

            <div class="warning-box">
                <h4>âš ï¸ PoFã®è§£é‡ˆ</h4>
                <p>
                    PoF = 0.9ã¯ã€Œ90%ã®ç¢ºç‡ã§åˆ¶ç´„ã‚’æº€ãŸã™ã€ã‚’æ„å‘³ã—ã¾ã™ã€‚
                    å®‰å…¨ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«ãªå¿œç”¨ã§ã¯ã€PoF > 0.95ã¾ãŸã¯0.99ã‚’è¦æ±‚ã™ã‚‹ã“ã¨ãŒæ¨å¥¨ã•ã‚Œã¾ã™ã€‚
                </p>
            </div>
        </section>

        <section>
            <h2>4.6 Safe Bayesian Optimization</h2>

            <p>
                æœªçŸ¥ã®åˆ¶ç´„é•åç‚¹ã§ã®è©•ä¾¡ã‚’é¿ã‘ã‚‹Safe BOã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã€‚
            </p>

            <h3>Example 5: Safe Bayesian Optimizationã®å®Ÿè£…</h3>

            <pre><code># Safe Bayesian Optimization
def safe_ucb(X, gp_obj, gp_constraints, beta_obj=2.0, beta_safe=3.0):
    """Safe UCBç²å¾—é–¢æ•°

    Args:
        X: å€™è£œç‚¹
        gp_obj: ç›®çš„é–¢æ•°GP
        gp_constraints: åˆ¶ç´„GP
        beta_obj: ç›®çš„é–¢æ•°ã®æ¢ç´¢ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        beta_safe: å®‰å…¨æ€§ã®ä¿¡é ¼åº¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    """
    # ç›®çš„é–¢æ•°ã®UCB
    mu_obj, sigma_obj = gp_obj.predict(X, return_std=True)
    ucb_obj = mu_obj + beta_obj * sigma_obj

    # å®‰å…¨æ€§ã®ç¢ºç‡ï¼ˆä¿å®ˆçš„: mu - beta*sigma >= 0ï¼‰
    safety_prob = np.ones(len(X))
    for gp_c in gp_constraints:
        mu_c, sigma_c = gp_c.predict(X, return_std=True)
        # Lower confidence bound ãŒæ­£ãªã‚‰å®‰å…¨
        lcb_c = mu_c - beta_safe * sigma_c
        safety_prob *= (lcb_c >= 0).astype(float)

    # å®‰å…¨ãªç‚¹ã®ã¿é¸æŠ
    ucb_obj[safety_prob == 0] = -np.inf

    return ucb_obj, safety_prob

# Safe BOå®Ÿè¡Œ
print("\nSafe Bayesian Optimizationå®Ÿè¡Œä¸­...")

# åˆæœŸç‚¹ï¼ˆæ—¢çŸ¥ã®å®‰å…¨é ˜åŸŸã‹ã‚‰é–‹å§‹ï¼‰
X_safe = np.array([
    [100, 40],
    [105, 45],
    [110, 50],
    [95, 35],
    [90, 40]
])
rate_safe, c1_safe, c2_safe = constrained_process(X_safe)

X_all_safe = X_safe.copy()
rate_all_safe = rate_safe.copy()
c1_all_safe = c1_safe.copy()
c2_all_safe = c2_safe.copy()

safety_violations = 0

for iteration in range(20):
    # GPæ§‹ç¯‰
    gp_obj_s = GaussianProcessRegressor(kernel=C(1.0)*RBF([10, 10]), normalize_y=True)
    gp_obj_s.fit(X_all_safe, rate_all_safe)

    gp_c1_s = GaussianProcessRegressor(kernel=C(1.0)*RBF([10, 10]), normalize_y=True)
    gp_c1_s.fit(X_all_safe, c1_all_safe)

    gp_c2_s = GaussianProcessRegressor(kernel=C(1.0)*RBF([10, 10]), normalize_y=True)
    gp_c2_s.fit(X_all_safe, c2_all_safe)

    # å€™è£œç‚¹
    X_cand = np.random.uniform([80, 30], [150, 80], (500, 2))

    # Safe UCB
    safe_ucb_values, safety = safe_ucb(X_cand, gp_obj_s, [gp_c1_s, gp_c2_s],
                                        beta_obj=2.0, beta_safe=3.0)

    if np.all(np.isinf(safe_ucb_values)):
        print(f"  è­¦å‘Š: Iteration {iteration} - å®‰å…¨ãªå€™è£œç‚¹ãªã—")
        # æœ€ã‚‚å®‰å…¨ãã†ãªç‚¹ã‚’é¸æŠï¼ˆç·Šæ€¥æªç½®ï¼‰
        pof = probability_of_feasibility(X_cand, [gp_c1_s, gp_c2_s])
        next_x = X_cand[np.argmax(pof)]
    else:
        next_x = X_cand[np.argmax(safe_ucb_values)]

    # å®Ÿé¨“
    next_rate, next_c1, next_c2 = constrained_process(next_x.reshape(1, -1))

    # å®‰å…¨æ€§ãƒã‚§ãƒƒã‚¯
    if next_c1[0] < 0 or next_c2[0] < 0:
        safety_violations += 1
        print(f"  âš ï¸ åˆ¶ç´„é•åç™ºç”Ÿ (Iteration {iteration})")

    X_all_safe = np.vstack([X_all_safe, next_x])
    rate_all_safe = np.hstack([rate_all_safe, next_rate])
    c1_all_safe = np.hstack([c1_all_safe, next_c1])
    c2_all_safe = np.hstack([c2_all_safe, next_c2])

print(f"\nSafe BOçµæœ:")
print(f"  ç·è©•ä¾¡ç‚¹æ•°: {len(X_all_safe)}")
print(f"  åˆ¶ç´„é•å: {safety_violations}å› ({safety_violations/len(X_all_safe)*100:.1f}%)")

# é€šå¸¸BOã¨æ¯”è¼ƒ
print(f"\né€šå¸¸BOï¼ˆå‚è€ƒï¼‰:")
print(f"  åˆ¶ç´„é•å: {(~final_feasible).sum()}å› ({(~final_feasible).sum()/len(X_all)*100:.1f}%)")

print(f"\nSafe BOã«ã‚ˆã‚‹å®‰å…¨æ€§å‘ä¸Š: {((~final_feasible).sum() - safety_violations)}å›å‰Šæ¸›")
</code></pre>

            <div class="success-box">
                <h4>âœ… Safe BOã®åˆ©ç‚¹</h4>
                <ul>
                    <li>å±é™ºé ˜åŸŸã§ã®å®Ÿé¨“ã‚’é«˜ç¢ºç‡ã§å›é¿</li>
                    <li>å®‰å…¨ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«ãªãƒ—ãƒ­ã‚»ã‚¹ã«é©ç”¨å¯èƒ½</li>
                    <li>ä¿å®ˆçš„ãªæ¢ç´¢ï¼ˆÎ²å€¤ã§èª¿æ•´å¯èƒ½ï¼‰</li>
                </ul>
            </div>
        </section>

        <section>
            <h2>4.7 ãƒãƒƒãƒãƒ™ã‚¤ã‚ºæœ€é©åŒ–</h2>

            <p>
                ä¸¦åˆ—å®Ÿé¨“è£…ç½®ã‚’æ´»ç”¨ã™ã‚‹ãŸã‚ã€è¤‡æ•°ç‚¹ã‚’åŒæ™‚ã«ææ¡ˆã™ã‚‹ãƒãƒƒãƒæœ€é©åŒ–ã€‚
            </p>

            <h3>Example 6: ãƒãƒƒãƒç²å¾—é–¢æ•°</h3>

            <pre><code># Batch Bayesian Optimization
def batch_ucb_selection(X_candidates, gp, batch_size=5, kappa=2.0, diversity_weight=0.1):
    """ãƒãƒƒãƒUCBé¸æŠï¼ˆé€æ¬¡çš„è²ªæ¬²æ³•ï¼‰

    Args:
        X_candidates: å€™è£œç‚¹
        gp: GP model
        batch_size: ãƒãƒƒãƒã‚µã‚¤ã‚º
        kappa: UCBæ¢ç´¢ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        diversity_weight: å¤šæ§˜æ€§é‡ã¿
    """
    selected_batch = []
    remaining_candidates = X_candidates.copy()

    for i in range(batch_size):
        # UCBè¨ˆç®—
        mu, sigma = gp.predict(remaining_candidates, return_std=True)
        ucb = mu + kappa * sigma

        # å¤šæ§˜æ€§ãƒšãƒŠãƒ«ãƒ†ã‚£ï¼ˆæ—¢é¸æŠç‚¹ã‹ã‚‰é ã„ç‚¹ã‚’å„ªé‡ï¼‰
        if len(selected_batch) > 0:
            selected_array = np.array(selected_batch)
            for selected_x in selected_array:
                distances = np.linalg.norm(remaining_candidates - selected_x, axis=1)
                diversity_bonus = diversity_weight * distances.min() / distances
                ucb += diversity_bonus

        # æœ€è‰¯ç‚¹ã‚’é¸æŠ
        best_idx = np.argmax(ucb)
        selected_batch.append(remaining_candidates[best_idx])

        # é¸æŠæ¸ˆã¿ç‚¹ã‚’é™¤å¤–
        remaining_candidates = np.delete(remaining_candidates, best_idx, axis=0)

    return np.array(selected_batch)

# ãƒãƒƒãƒBOã®å®Ÿè¡Œ
print("\nBatch Bayesian Optimizationå®Ÿè¡Œä¸­...")

batch_size = 5
n_batches = 8

# åˆæœŸã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
X_batch = np.random.uniform([50, 20], [150, 80], (10, 2))
Y1_batch, Y2_batch = process_objectives(X_batch)

for batch_idx in range(n_batches):
    # GPæ§‹ç¯‰ï¼ˆç›®çš„1ã®ã¿ã§ç°¡ç•¥åŒ–ï¼‰
    gp_batch = GaussianProcessRegressor(kernel=C(1.0)*RBF([10, 10]), normalize_y=True)
    gp_batch.fit(X_batch, Y1_batch)

    # ãƒãƒƒãƒé¸æŠ
    X_cand = np.random.uniform([50, 20], [150, 80], (200, 2))
    next_batch = batch_ucb_selection(X_cand, gp_batch, batch_size=batch_size,
                                     kappa=2.0, diversity_weight=0.5)

    # ä¸¦åˆ—å®Ÿé¨“ï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
    next_y1, next_y2 = process_objectives(next_batch)

    # ãƒ‡ãƒ¼ã‚¿è¿½åŠ 
    X_batch = np.vstack([X_batch, next_batch])
    Y1_batch = np.hstack([Y1_batch, next_y1])
    Y2_batch = np.hstack([Y2_batch, next_y2])

    print(f"  Batch {batch_idx+1}/{n_batches}: Best yield = {Y1_batch.max():.2f}")

# çµæœå¯è¦–åŒ–
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))

# ãƒãƒƒãƒã”ã¨ã®è‰²åˆ†ã‘
colors = np.repeat(np.arange(n_batches + 1), [10] + [batch_size]*n_batches)
scatter = ax1.scatter(X_batch[:, 0], X_batch[:, 1], c=colors, cmap='tab10',
                      s=100, alpha=0.7, edgecolors='black', linewidth=0.5)
ax1.set_xlabel('Temperature (Â°C)')
ax1.set_ylabel('Pressure (bar)')
ax1.set_title('Batch Optimization Trajectory')
plt.colorbar(scatter, ax=ax1, label='Batch Number', ticks=range(n_batches+1))
ax1.grid(alpha=0.3)

# ãƒãƒƒãƒå†…ã®å¤šæ§˜æ€§ï¼ˆæœ€å¾Œã®ãƒãƒƒãƒï¼‰
last_batch = X_batch[-batch_size:]
distances = []
for i in range(len(last_batch)):
    for j in range(i+1, len(last_batch)):
        dist = np.linalg.norm(last_batch[i] - last_batch[j])
        distances.append(dist)

ax2.hist(distances, bins=10, color='skyblue', alpha=0.7, edgecolor='black')
ax2.set_xlabel('Euclidean Distance')
ax2.set_ylabel('Frequency')
ax2.set_title(f'Diversity in Last Batch ({batch_size} points)')
ax2.axvline(np.mean(distances), color='red', linestyle='--', linewidth=2,
            label=f'Mean: {np.mean(distances):.2f}')
ax2.legend()
ax2.grid(alpha=0.3)

plt.tight_layout()
plt.savefig('batch_optimization.png', dpi=150, bbox_inches='tight')

print(f"\nãƒãƒƒãƒæœ€é©åŒ–çµæœ:")
print(f"  ç·è©•ä¾¡ç‚¹æ•°: {len(X_batch)}")
print(f"  ãƒãƒƒãƒæ•°: {n_batches}")
print(f"  ä¸¦åˆ—å®Ÿé¨“ã«ã‚ˆã‚‹é«˜é€ŸåŒ–: {batch_size}å€ï¼ˆç†è«–å€¤ï¼‰")
print(f"  æœ€è‰¯åç‡: {Y1_batch.max():.2f}")
</code></pre>

            <div class="info-box">
                <h4>ğŸ’¡ ãƒãƒƒãƒé¸æŠæˆ¦ç•¥</h4>
                <ul>
                    <li><strong>é€æ¬¡è²ªæ¬²æ³•</strong>: 1ç‚¹ãšã¤é¸æŠã€å¤šæ§˜æ€§ãƒšãƒŠãƒ«ãƒ†ã‚£è¿½åŠ </li>
                    <li><strong>ä¸¦åˆ—EI</strong>: Kriging Believerã‚¢ãƒ—ãƒ­ãƒ¼ãƒ</li>
                    <li><strong>Thompson Sampling</strong>: è‡ªç„¶ã«å¤šæ§˜æ€§ç¢ºä¿</li>
                    <li><strong>å¤šæ§˜æ€§é‡è¦–</strong>: ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ä½µç”¨</li>
                </ul>
            </div>
        </section>

        <section>
            <h2>4.8 é«˜æ¬¡å…ƒæœ€é©åŒ–</h2>

            <p>
                ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ãŒå¤šã„ï¼ˆ10æ¬¡å…ƒä»¥ä¸Šï¼‰å ´åˆã®æˆ¦ç•¥ã€‚
            </p>

            <h3>Example 7: é«˜æ¬¡å…ƒå•é¡Œã¸ã®å¯¾å¿œ</h3>

            <pre><code># é«˜æ¬¡å…ƒãƒ™ã‚¤ã‚ºæœ€é©åŒ–ï¼ˆæ¬¡å…ƒå‰Šæ¸›ã‚¢ãƒ—ãƒ­ãƒ¼ãƒï¼‰
from sklearn.decomposition import PCA

def high_dimensional_process(X):
    """10æ¬¡å…ƒãƒ—ãƒ­ã‚»ã‚¹é–¢æ•°

    Args:
        X: (N, 10) 10ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    Returns:
        y: ç›®çš„é–¢æ•°å€¤
    """
    # å®Ÿéš›ã¯ä½æ¬¡å…ƒéƒ¨åˆ†ç©ºé–“ã«æœ€é©è§£ãŒå­˜åœ¨ï¼ˆã‚ˆãã‚ã‚‹ã‚±ãƒ¼ã‚¹ï¼‰
    # æœ‰åŠ¹æ¬¡å…ƒ: x0, x1, x5ã®ã¿
    effective_dims = X[:, [0, 1, 5]]

    y = (
        -np.sum((effective_dims - 0.5)**2, axis=1) +
        0.1 * np.sum(X, axis=1) +  # ä»–æ¬¡å…ƒã®å°ã•ãªå½±éŸ¿
        np.random.normal(0, 0.01, len(X))
    )
    return y

# é«˜æ¬¡å…ƒBOã®æˆ¦ç•¥1: ãƒ©ãƒ³ãƒ€ãƒ åŸ‹ã‚è¾¼ã¿
print("\né«˜æ¬¡å…ƒBOå®Ÿè¡Œä¸­...")

n_dim = 10
n_effective_dim = 3  # æ¨å®šæœ‰åŠ¹æ¬¡å…ƒ

# åˆæœŸã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
n_init = 20  # é«˜æ¬¡å…ƒã§ã¯å¤šã‚ã«
X_high = np.random.uniform(0, 1, (n_init, n_dim))
y_high = high_dimensional_process(X_high)

X_all_high = X_high.copy()
y_all_high = y_high.copy()

# PCAã§æ¬¡å…ƒå‰Šæ¸›
pca = PCA(n_components=n_effective_dim)
X_reduced = pca.fit_transform(X_all_high)

best_values_high = [y_all_high.max()]

for iteration in range(30):
    # ä½æ¬¡å…ƒç©ºé–“ã§GPæ§‹ç¯‰
    gp_high = GaussianProcessRegressor(
        kernel=C(1.0) * RBF([1.0]*n_effective_dim),
        normalize_y=True,
        n_restarts_optimizer=5
    )
    gp_high.fit(X_reduced, y_all_high)

    # ä½æ¬¡å…ƒç©ºé–“ã§å€™è£œç”Ÿæˆ
    X_cand_reduced = np.random.uniform(
        X_reduced.min(axis=0),
        X_reduced.max(axis=0),
        (500, n_effective_dim)
    )

    # UCBã§é¸æŠ
    mu, sigma = gp_high.predict(X_cand_reduced, return_std=True)
    ucb = mu + 2.0 * sigma
    next_x_reduced = X_cand_reduced[np.argmax(ucb)]

    # å…ƒç©ºé–“ã«é€†å¤‰æ›
    next_x_high = pca.inverse_transform(next_x_reduced.reshape(1, -1))

    # ç¯„å›²ãƒã‚§ãƒƒã‚¯ãƒ»ã‚¯ãƒªãƒƒãƒ—
    next_x_high = np.clip(next_x_high, 0, 1)

    # å®Ÿé¨“
    next_y_high = high_dimensional_process(next_x_high)

    # ãƒ‡ãƒ¼ã‚¿è¿½åŠ 
    X_all_high = np.vstack([X_all_high, next_x_high])
    y_all_high = np.hstack([y_all_high, next_y_high])

    # PCAæ›´æ–°
    X_reduced = pca.fit_transform(X_all_high)

    best_values_high.append(y_all_high.max())

# æ¯”è¼ƒ: ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ¼ãƒ
X_random = np.random.uniform(0, 1, (len(y_all_high), n_dim))
y_random = high_dimensional_process(X_random)
best_random = [y_random[:i+1].max() for i in range(len(y_random))]

# å¯è¦–åŒ–
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))

# åæŸæ¯”è¼ƒ
ax1.plot(best_values_high, 'g-', linewidth=2, marker='o', markersize=4,
         label='BO with PCA (3D)')
ax1.plot(best_random, 'gray', linewidth=2, marker='s', markersize=4,
         alpha=0.6, label='Random Search')
ax1.set_xlabel('Iteration')
ax1.set_ylabel('Best Value Found')
ax1.set_title('High-Dimensional Optimization (10D)')
ax1.legend()
ax1.grid(alpha=0.3)

# PCAèª¬æ˜åˆ†æ•£
pca_final = PCA(n_components=n_dim)
pca_final.fit(X_all_high)
explained_var = pca_final.explained_variance_ratio_

ax2.bar(range(1, n_dim+1), explained_var, color='steelblue', alpha=0.7, edgecolor='black')
ax2.plot(range(1, n_dim+1), np.cumsum(explained_var), 'ro-', linewidth=2, markersize=6,
         label='Cumulative')
ax2.axhline(0.95, color='green', linestyle='--', label='95% threshold')
ax2.set_xlabel('Principal Component')
ax2.set_ylabel('Explained Variance Ratio')
ax2.set_title('PCA Analysis of Search Space')
ax2.legend()
ax2.grid(alpha=0.3)

plt.tight_layout()
plt.savefig('high_dimensional_bo.png', dpi=150, bbox_inches='tight')

print(f"\né«˜æ¬¡å…ƒBOçµæœ:")
print(f"  æ¬¡å…ƒæ•°: {n_dim}")
print(f"  æœ‰åŠ¹æ¬¡å…ƒï¼ˆæ¨å®šï¼‰: {n_effective_dim}")
print(f"  æœ€è‰¯å€¤ï¼ˆBO+PCAï¼‰: {y_all_high.max():.4f}")
print(f"  æœ€è‰¯å€¤ï¼ˆRandomï¼‰: {y_random.max():.4f}")
print(f"  æ”¹å–„ç‡: {(y_all_high.max() - y_random.max())/abs(y_random.max())*100:.1f}%")
print(f"\nPCAä¸Šä½3æˆåˆ†ã®èª¬æ˜åˆ†æ•£: {explained_var[:3].sum()*100:.1f}%")
</code></pre>

            <div class="warning-box">
                <h4>âš ï¸ é«˜æ¬¡å…ƒBOã®èª²é¡Œ</h4>
                <p>
                    æ¬¡å…ƒæ•°ãŒå¢—ãˆã‚‹ã¨GPã®è¨ˆç®—ã‚³ã‚¹ãƒˆãŒæ€¥å¢—ï¼ˆO(nÂ³)ï¼‰ã€ã‚µãƒ³ãƒ—ãƒ«åŠ¹ç‡ã‚‚ä½ä¸‹ã—ã¾ã™ã€‚
                    å¯¾ç­–: (1) æ¬¡å…ƒå‰Šæ¸›ï¼ˆPCAã€UMAPï¼‰ã€(2) Random Embeddingã€(3) Additive GPã€(4) ã‚¹ãƒ‘ãƒ¼ã‚¹è¿‘ä¼¼
                </p>
            </div>

            <table>
                <thead>
                    <tr>
                        <th>æ¬¡å…ƒæ•°</th>
                        <th>æ¨å¥¨æ‰‹æ³•</th>
                        <th>åˆæœŸã‚µãƒ³ãƒ—ãƒ«æ•°</th>
                        <th>æ³¨æ„ç‚¹</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>1-3D</td>
                        <td>æ¨™æº–BOï¼ˆEI, UCBï¼‰</td>
                        <td>5-10</td>
                        <td>å•é¡Œãªã—</td>
                    </tr>
                    <tr>
                        <td>4-7D</td>
                        <td>æ¨™æº–BO + è‰¯ã„ã‚«ãƒ¼ãƒãƒ«</td>
                        <td>10-20</td>
                        <td>è¨ˆç®—ã‚³ã‚¹ãƒˆå¢—</td>
                    </tr>
                    <tr>
                        <td>8-15D</td>
                        <td>æ¬¡å…ƒå‰Šæ¸› + BO</td>
                        <td>20-50</td>
                        <td>æœ‰åŠ¹æ¬¡å…ƒã®æ¨å®šé‡è¦</td>
                    </tr>
                    <tr>
                        <td>16D+</td>
                        <td>Random Embedding/TuRBO</td>
                        <td>50-100</td>
                        <td>ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£è¦</td>
                    </tr>
                </tbody>
            </table>
        </section>

        <section>
            <h2>ã¾ã¨ã‚</h2>

            <p>æœ¬ç« ã§ã¯ã€å®Ÿä¸–ç•Œã®è¤‡é›‘ãªæœ€é©åŒ–å•é¡Œã«å¯¾å¿œã™ã‚‹é«˜åº¦ãªæ‰‹æ³•ã‚’å­¦ç¿’ã—ã¾ã—ãŸã€‚</p>

            <h3>é‡è¦ãƒã‚¤ãƒ³ãƒˆ</h3>
            <ul>
                <li><strong>å¤šç›®çš„æœ€é©åŒ–</strong>: ãƒ‘ãƒ¬ãƒ¼ãƒˆãƒ•ãƒ­ãƒ³ãƒˆæ¢ç´¢ã€EHVIã§è¤‡æ•°ç›®çš„ã‚’åŒæ™‚é”æˆ</li>
                <li><strong>åˆ¶ç´„ä»˜ãæœ€é©åŒ–</strong>: PoFã¨CEIã§å®‰å…¨ãªå®Ÿé¨“è¨ˆç”»</li>
                <li><strong>Safe BO</strong>: å±é™ºé ˜åŸŸã‚’å›é¿ã—ãªãŒã‚‰æœ€é©åŒ–</li>
                <li><strong>ãƒãƒƒãƒæœ€é©åŒ–</strong>: ä¸¦åˆ—å®Ÿé¨“ã§é«˜é€ŸåŒ–ï¼ˆå¤šæ§˜æ€§ç¢ºä¿ãŒéµï¼‰</li>
                <li><strong>é«˜æ¬¡å…ƒå¯¾å¿œ</strong>: æ¬¡å…ƒå‰Šæ¸›ã€Random Embeddingã§å®Ÿç”¨åŒ–</li>
            </ul>

            <h3>æ¬¡ç« ã®äºˆå‘Š</h3>
            <p>
                ç¬¬5ç« ã§ã¯ã€ã“ã‚Œã¾ã§å­¦ã‚“ã æŠ€è¡“ã‚’çµ±åˆã—ã€<strong>å®Ÿéš›ã®ç”£æ¥­ãƒ—ãƒ­ã‚»ã‚¹</strong>ã¸ã®å¿œç”¨ã‚’è©³ã—ãè§£èª¬ã—ã¾ã™ã€‚
                åå¿œå™¨æœ€é©åŒ–ã€è§¦åª’è¨­è¨ˆã€å“è³ªç®¡ç†ãªã©ã€7ã¤ã®å®Ÿè·µçš„ã‚±ãƒ¼ã‚¹ã‚¹ã‚¿ãƒ‡ã‚£ã‚’é€šã˜ã¦å³æˆ¦åŠ›ã‚’é¤Šã„ã¾ã™ã€‚
            </p>
        </section>

        <nav class="navigation">
            <a href="chapter-3.html" class="nav-button">â† ç¬¬3ç« : ç²å¾—é–¢æ•°</a>
            <a href="index.html" class="nav-button">ç›®æ¬¡ã«æˆ»ã‚‹</a>
            <a href="chapter-5.html" class="nav-button">ç¬¬5ç« : ç”£æ¥­å¿œç”¨ â†’</a>
        </nav>
    </main>

    <footer style="text-align: center; padding: 2rem; color: #666; border-top: 1px solid #e2e8f0; margin-top: 3rem;">
        <p>&copy; 2025 PI Terakoya - Dr. Yusuke Hashimoto, Tohoku University</p>
        <p style="font-size: 0.9rem; margin-top: 0.5rem;">
            <a href="https://creativecommons.org/licenses/by/4.0/" style="color: #11998e;">CC BY 4.0</a> |
            <a href="mailto:yusuke.hashimoto.b8@tohoku.ac.jp" style="color: #11998e;">Contact</a>
        </p>
    </footer>
</body>
</html>
