<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="ç¬¬4ç« ï¼šã‚ªãƒ¼ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã¨ç”Ÿæˆãƒ¢ãƒ‡ãƒ« - ç•°å¸¸æ¤œçŸ¥ã¨åˆæˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ">
    <title>ç¬¬4ç« ï¼šã‚ªãƒ¼ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã¨ç”Ÿæˆãƒ¢ãƒ‡ãƒ« - æ·±å±¤å­¦ç¿’ã«ã‚ˆã‚‹ãƒ—ãƒ­ã‚»ã‚¹ãƒ¢ãƒ‡ãƒªãƒ³ã‚° | PI Terakoya</title>

        <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif;
            line-height: 1.8; color: #333; background: #f5f5f5;
        }
        header {
            background: linear-gradient(135deg, #11998e 0%, #38ef7d 100%);
            color: white; padding: 2rem 1rem; text-align: center;
        }
        h1 { font-size: 2rem; margin-bottom: 0.5rem; }
        .subtitle { opacity: 0.9; font-size: 1.1rem; }
        .container { max-width: 1200px; margin: 2rem auto; padding: 0 1rem; }
        .back-link {
            display: inline-block; margin-bottom: 2rem; padding: 0.5rem 1rem;
            background: white; color: #11998e; text-decoration: none;
            border-radius: 6px; font-weight: 600;
        }
        .content-box {
            background: white; padding: 2rem; border-radius: 12px;
            margin-bottom: 2rem; box-shadow: 0 2px 8px rgba(0,0,0,0.1);
        }
        h2 {
            color: #11998e; margin: 2rem 0 1rem 0;
            padding-bottom: 0.5rem; border-bottom: 3px solid #11998e;
        }
        h3 { color: #2c3e50; margin: 1.5rem 0 1rem 0; }
        h4 { color: #2c3e50; margin: 1rem 0 0.5rem 0; }
        p { margin-bottom: 1rem; }
        ul, ol { margin-left: 2rem; margin-bottom: 1rem; }
        li { margin-bottom: 0.5rem; }
        pre {
            background: #1e1e1e; color: #d4d4d4; padding: 1.5rem;
            border-radius: 8px; overflow-x: auto; margin: 1rem 0;
            border-left: 4px solid #11998e;
        }
        code {
            font-family: 'Courier New', monospace; font-size: 0.9rem;
        }
        .key-point {
            background: #e8f5e9; padding: 1rem; border-radius: 6px;
            border-left: 4px solid #4caf50; margin: 1rem 0;
        }
        .tech-note {
            background: #e3f2fd; padding: 1rem; border-radius: 6px;
            border-left: 4px solid #2196f3; margin: 1rem 0;
        }
        .formula {
            background: #f0f7ff; padding: 1rem; border-radius: 6px;
            margin: 1rem 0; overflow-x: auto;
        }
        table {
            width: 100%; border-collapse: collapse; margin: 1rem 0;
        }
        th, td {
            border: 1px solid #ddd; padding: 0.75rem; text-align: left;
        }
        th {
            background: #11998e; color: white; font-weight: 600;
        }
        tr:nth-child(even) { background: #f9f9f9; }
        .nav-buttons {
            display: flex; justify-content: space-between; margin-top: 3rem;
        }
        .nav-buttons a {
            padding: 0.75rem 1.5rem;
            background: linear-gradient(135deg, #11998e 0%, #38ef7d 100%);
            color: white; text-decoration: none; border-radius: 6px;
            font-weight: 600;
        }
        footer {
            background: #2c3e50; color: white; text-align: center;
            padding: 2rem 1rem; margin-top: 4rem;
        }
        @media (max-width: 768px) {
            h1 { font-size: 1.6rem; }
            .container { padding: 0 0.5rem; }
            pre { padding: 1rem; }
        }
    
        
    
        /* Breadcrumb styles */
        .breadcrumb {
            background: #f7fafc;
            padding: 0.75rem 1rem;
            border-bottom: 1px solid #e2e8f0;
            font-size: 0.9rem;
        }

        .breadcrumb-content {
            max-width: 900px;
            margin: 0 auto;
            display: flex;
            align-items: center;
            flex-wrap: wrap;
            gap: 0.5rem;
        }

        .breadcrumb a {
            color: #667eea;
            text-decoration: none;
            transition: color 0.2s;
        }

        .breadcrumb a:hover {
            color: #764ba2;
            text-decoration: underline;
        }

        .breadcrumb-separator {
            color: #a0aec0;
            margin: 0 0.25rem;
        }

        .breadcrumb-current {
            color: #4a5568;
            font-weight: 500;
        }
    </style>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

    <style>
        /* Locale Switcher Styles */
        .locale-switcher {
            display: flex;
            align-items: center;
            gap: 0.5rem;
            padding: 0.5rem 1rem;
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
            border-radius: 6px;
            font-size: 0.9rem;
            margin-bottom: 1rem;
            box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);
        }

        .current-locale {
            font-weight: 600;
            color: #7b2cbf;
            display: flex;
            align-items: center;
            gap: 0.25rem;
        }

        .locale-separator {
            color: #adb5bd;
            font-weight: 300;
        }

        .locale-link {
            color: #f093fb;
            text-decoration: none;
            font-weight: 500;
            transition: all 0.2s ease;
            display: flex;
            align-items: center;
            gap: 0.25rem;
            padding: 0.2rem 0.5rem;
            border-radius: 4px;
        }

        .locale-link:hover {
            background: rgba(240, 147, 251, 0.1);
            color: #d07be8;
            transform: translateY(-1px);
        }

        .locale-meta {
            color: #868e96;
            font-size: 0.85rem;
            font-style: italic;
            margin-left: auto;
        }

        @media (max-width: 768px) {
            .locale-switcher {
                font-size: 0.85rem;
                padding: 0.4rem 0.8rem;
            }
            .locale-meta {
                display: none;
            }
        }
    </style>
</head>
<body>
            <div class="locale-switcher">
<span class="current-locale">ğŸŒ JP</span>
<span class="locale-separator">|</span>
<a href="../../../en/PI/deep-learning-modeling/chapter-4.html" class="locale-link">ğŸ‡¬ğŸ‡§ EN</a>
<span class="locale-separator">|</span>
<span class="locale-meta">Last sync: 2025-11-16</span>
</div>
<nav class="breadcrumb">
        <div class="breadcrumb-content">
            <a href="../../index.html">AIå¯ºå­å±‹ãƒˆãƒƒãƒ—</a><span class="breadcrumb-separator">â€º</span><a href="../../PI/index.html">ãƒ—ãƒ­ã‚»ã‚¹ãƒ»ã‚¤ãƒ³ãƒ•ã‚©ãƒãƒ†ã‚£ã‚¯ã‚¹</a><span class="breadcrumb-separator">â€º</span><a href="../../PI/deep-learning-modeling/index.html">Deep Learning Modeling</a><span class="breadcrumb-separator">â€º</span><span class="breadcrumb-current">Chapter 4</span>
        </div>
    </nav>

        <header>
        <div class="container">
            <h1>ç¬¬4ç« ï¼šã‚ªãƒ¼ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã¨ç”Ÿæˆãƒ¢ãƒ‡ãƒ«</h1>
            <p class="subtitle">æ¬¡å…ƒå‰Šæ¸›ã€ç•°å¸¸æ¤œçŸ¥ã€ãƒ—ãƒ­ã‚»ã‚¹ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã¸ã®å¿œç”¨</p>
            <div class="meta">
                <span class="meta">ğŸ“– èª­äº†æ™‚é–“: 35-40åˆ†</span>
                <span class="meta">ğŸ’¡ é›£æ˜“åº¦: ä¸Šç´š</span>
                <span class="meta">ğŸ”¬ å®Ÿä¾‹: VAEãƒ»GANãƒ»ç•°å¸¸æ¤œçŸ¥</span>
            </div>
        </div>
    </header>

    <main class="container">
        <section>
            <h2>4.1 Vanilla Autoencoderï¼ˆåŸºæœ¬ã‚ªãƒ¼ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ï¼‰</h2>

            <p>ã‚ªãƒ¼ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã¯ã€å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã‚’ä½æ¬¡å…ƒã®æ½œåœ¨è¡¨ç¾ã«åœ§ç¸®ï¼ˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ï¼‰ã—ã€å…ƒã®ãƒ‡ãƒ¼ã‚¿ã‚’å†æ§‹æˆï¼ˆãƒ‡ã‚³ãƒ¼ãƒ‰ï¼‰ã™ã‚‹ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã§ã™ã€‚ãƒ—ãƒ­ã‚»ã‚¹ãƒ‡ãƒ¼ã‚¿ã®æ¬¡å…ƒå‰Šæ¸›ã‚„ç‰¹å¾´æŠ½å‡ºã«æœ‰åŠ¹ã§ã™ã€‚</p>

            <div class="info-box">
                <p><strong>ğŸ’¡ Autoencoderã®åŸºæœ¬æ§‹æˆ</strong></p>
                <ul>
                    <li><strong>Encoder</strong>: é«˜æ¬¡å…ƒãƒ‡ãƒ¼ã‚¿ â†’ ä½æ¬¡å…ƒæ½œåœ¨è¡¨ç¾ï¼ˆãƒœãƒˆãƒ«ãƒãƒƒã‚¯ï¼‰</li>
                    <li><strong>Decoder</strong>: æ½œåœ¨è¡¨ç¾ â†’ å†æ§‹æˆãƒ‡ãƒ¼ã‚¿</li>
                    <li><strong>ç›®çš„</strong>: å†æ§‹æˆèª¤å·®ã‚’æœ€å°åŒ– \(\mathcal{L} = ||x - \hat{x}||^2\)</li>
                </ul>
            </div>

            <h3>ä¾‹1: ãƒ—ãƒ­ã‚»ã‚¹ãƒ‡ãƒ¼ã‚¿ã®æ¬¡å…ƒå‰Šæ¸›</h3>

            <pre><code class="language-python">import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import matplotlib.pyplot as plt

class VanillaAutoencoder(nn.Module):
    """åŸºæœ¬çš„ãªã‚ªãƒ¼ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€"""

    def __init__(self, input_dim, latent_dim=8):
        """
        Args:
            input_dim: å…¥åŠ›æ¬¡å…ƒï¼ˆãƒ—ãƒ­ã‚»ã‚¹å¤‰æ•°ã®æ•°ï¼‰
            latent_dim: æ½œåœ¨ç©ºé–“ã®æ¬¡å…ƒ
        """
        super(VanillaAutoencoder, self).__init__()

        # Encoder: å…¥åŠ› â†’ æ½œåœ¨è¡¨ç¾
        self.encoder = nn.Sequential(
            nn.Linear(input_dim, 64),
            nn.ReLU(),
            nn.Linear(64, 32),
            nn.ReLU(),
            nn.Linear(32, latent_dim)
        )

        # Decoder: æ½œåœ¨è¡¨ç¾ â†’ å†æ§‹æˆ
        self.decoder = nn.Sequential(
            nn.Linear(latent_dim, 32),
            nn.ReLU(),
            nn.Linear(32, 64),
            nn.ReLU(),
            nn.Linear(64, input_dim)
        )

    def forward(self, x):
        """
        Args:
            x: [batch, input_dim] å…¥åŠ›ãƒ‡ãƒ¼ã‚¿
        Returns:
            reconstructed: [batch, input_dim] å†æ§‹æˆãƒ‡ãƒ¼ã‚¿
            latent: [batch, latent_dim] æ½œåœ¨è¡¨ç¾
        """
        latent = self.encoder(x)
        reconstructed = self.decoder(latent)
        return reconstructed, latent

# åˆæˆãƒ—ãƒ­ã‚»ã‚¹ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆï¼ˆ10å¤‰æ•° â†’ 2æ¬¡å…ƒã«åœ§ç¸®ï¼‰
def generate_process_data(n_samples=1000, n_features=10):
    """å¤šå¤‰é‡ãƒ—ãƒ­ã‚»ã‚¹ãƒ‡ãƒ¼ã‚¿ï¼ˆå®Ÿéš›ã¯2ã¤ã®ä¸»æˆåˆ†ã§æ±ºå®šï¼‰"""
    # 2ã¤ã®æ½œåœ¨å› å­
    z1 = np.random.randn(n_samples)
    z2 = np.random.randn(n_samples)

    # 10å¤‰æ•°ã‚’ç”Ÿæˆï¼ˆz1, z2ã®ç·šå½¢çµåˆ + ãƒã‚¤ã‚ºï¼‰
    data = np.zeros((n_samples, n_features))
    for i in range(n_features):
        w1 = np.random.randn()
        w2 = np.random.randn()
        data[:, i] = w1 * z1 + w2 * z2 + 0.1 * np.random.randn(n_samples)

    return data

# ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã¨æ­£è¦åŒ–
data = generate_process_data(n_samples=1000, n_features=10)
data_mean = data.mean(axis=0)
data_std = data.std(axis=0)
data_normalized = (data - data_mean) / (data_std + 1e-8)

# Tensorå¤‰æ›
data_tensor = torch.FloatTensor(data_normalized)

# ãƒ¢ãƒ‡ãƒ«è¨“ç·´
model = VanillaAutoencoder(input_dim=10, latent_dim=2)
criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

for epoch in range(100):
    model.train()
    optimizer.zero_grad()

    reconstructed, latent = model(data_tensor)
    loss = criterion(reconstructed, data_tensor)

    loss.backward()
    optimizer.step()

    if (epoch + 1) % 20 == 0:
        print(f'Epoch {epoch+1}, Reconstruction Loss: {loss.item():.6f}')

# æ½œåœ¨ç©ºé–“ã®å¯è¦–åŒ–
model.eval()
with torch.no_grad():
    _, latent_codes = model(data_tensor)
    latent_codes = latent_codes.numpy()

plt.figure(figsize=(8, 6))
plt.scatter(latent_codes[:, 0], latent_codes[:, 1], alpha=0.5, s=20)
plt.xlabel('Latent Dimension 1')
plt.ylabel('Latent Dimension 2')
plt.title('Latent Space Representation (10D â†’ 2D)')
plt.grid(True, alpha=0.3)
plt.tight_layout()
# plt.savefig('latent_space.png', dpi=150)

print(f"\nLatent space shape: {latent_codes.shape}")
print(f"Latent space range: [{latent_codes.min():.2f}, {latent_codes.max():.2f}]")

# å‡ºåŠ›ä¾‹:
# Epoch 20, Reconstruction Loss: 0.125678
# Epoch 40, Reconstruction Loss: 0.056789
# Epoch 60, Reconstruction Loss: 0.034567
# Epoch 80, Reconstruction Loss: 0.023456
# Epoch 100, Reconstruction Loss: 0.018901
#
# Latent space shape: (1000, 2)
# Latent space range: [-3.45, 3.78]
</code></pre>
        </section>

        <section>
            <h2>4.2 Denoising Autoencoderï¼ˆãƒã‚¤ã‚ºé™¤å»ï¼‰</h2>

            <p>ã‚»ãƒ³ã‚µãƒ¼ãƒã‚¤ã‚ºã‚’å«ã‚€ãƒ—ãƒ­ã‚»ã‚¹ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã€çœŸã®ä¿¡å·ã‚’å¾©å…ƒã—ã¾ã™ã€‚å…¥åŠ›ã«ãƒã‚¤ã‚ºã‚’åŠ ãˆã€å…ƒã®ä¿¡å·ã‚’å†æ§‹æˆã™ã‚‹ã‚ˆã†è¨“ç·´ã—ã¾ã™ã€‚</p>

            <h3>ä¾‹2: ã‚»ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿ã®ãƒã‚¤ã‚ºé™¤å»</h3>

            <pre><code class="language-python">class DenoisingAutoencoder(nn.Module):
    """ãƒã‚¤ã‚ºé™¤å»ã‚ªãƒ¼ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€"""

    def __init__(self, input_dim, latent_dim=16):
        super(DenoisingAutoencoder, self).__init__()

        # Encoder
        self.encoder = nn.Sequential(
            nn.Linear(input_dim, 128),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Linear(64, latent_dim)
        )

        # Decoder
        self.decoder = nn.Sequential(
            nn.Linear(latent_dim, 64),
            nn.ReLU(),
            nn.Linear(64, 128),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(128, input_dim)
        )

    def forward(self, x):
        latent = self.encoder(x)
        reconstructed = self.decoder(latent)
        return reconstructed

def add_noise(data, noise_factor=0.3):
    """ã‚¬ã‚¦ã‚¹ãƒã‚¤ã‚ºã‚’è¿½åŠ 

    Args:
        data: [samples, features] ã‚¯ãƒªãƒ¼ãƒ³ãƒ‡ãƒ¼ã‚¿
        noise_factor: ãƒã‚¤ã‚ºã®å¼·åº¦

    Returns:
        noisy_data: ãƒã‚¤ã‚ºãŒåŠ ã‚ã£ãŸãƒ‡ãƒ¼ã‚¿
    """
    noise = torch.randn_like(data) * noise_factor
    noisy_data = data + noise
    return noisy_data

# ã‚¯ãƒªãƒ¼ãƒ³ãªãƒ—ãƒ­ã‚»ã‚¹ãƒ‡ãƒ¼ã‚¿
clean_data = torch.FloatTensor(generate_process_data(n_samples=1000, n_features=20))

# æ­£è¦åŒ–
clean_mean = clean_data.mean(dim=0, keepdim=True)
clean_std = clean_data.std(dim=0, keepdim=True)
clean_normalized = (clean_data - clean_mean) / (clean_std + 1e-8)

# ãƒã‚¤ã‚ºè¿½åŠ 
noisy_data = add_noise(clean_normalized, noise_factor=0.5)

# ãƒ¢ãƒ‡ãƒ«è¨“ç·´
model = DenoisingAutoencoder(input_dim=20, latent_dim=16)
criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

for epoch in range(100):
    model.train()
    optimizer.zero_grad()

    # ãƒã‚¤ã‚ºå…¥åŠ› â†’ ã‚¯ãƒªãƒ¼ãƒ³å‡ºåŠ›ã‚’å­¦ç¿’
    denoised = model(noisy_data)
    loss = criterion(denoised, clean_normalized)

    loss.backward()
    optimizer.step()

    if (epoch + 1) % 20 == 0:
        print(f'Epoch {epoch+1}, Denoising Loss: {loss.item():.6f}')

# ãƒ†ã‚¹ãƒˆï¼šæ–°ã—ã„ãƒã‚¤ã‚ºãƒ‡ãƒ¼ã‚¿ã‚’é™¤å»
model.eval()
with torch.no_grad():
    test_clean = clean_normalized[:10]
    test_noisy = add_noise(test_clean, noise_factor=0.5)
    test_denoised = model(test_noisy)

    # SNRï¼ˆä¿¡å·å¯¾é›‘éŸ³æ¯”ï¼‰ã‚’è¨ˆç®—
    noise_power = torch.mean((test_noisy - test_clean) ** 2)
    residual_power = torch.mean((test_denoised - test_clean) ** 2)

    snr_before = 10 * torch.log10(torch.mean(test_clean ** 2) / noise_power)
    snr_after = 10 * torch.log10(torch.mean(test_clean ** 2) / residual_power)

print(f"\nSNR before denoising: {snr_before.item():.2f} dB")
print(f"SNR after denoising:  {snr_after.item():.2f} dB")
print(f"Improvement: {(snr_after - snr_before).item():.2f} dB")

# 1å¤‰æ•°ã®å¯è¦–åŒ–
time_steps = np.arange(10)
var_idx = 0

plt.figure(figsize=(10, 4))
plt.plot(time_steps, test_clean[:, var_idx].numpy(), 'g-', label='Clean', linewidth=2)
plt.plot(time_steps, test_noisy[:, var_idx].numpy(), 'r--', label='Noisy', alpha=0.7)
plt.plot(time_steps, test_denoised[:, var_idx].numpy(), 'b-', label='Denoised', linewidth=2)
plt.xlabel('Sample')
plt.ylabel('Normalized Value')
plt.title(f'Denoising Performance (Variable {var_idx+1})')
plt.legend()
plt.grid(True, alpha=0.3)
plt.tight_layout()

# å‡ºåŠ›ä¾‹:
# Epoch 20, Denoising Loss: 0.234567
# Epoch 40, Denoising Loss: 0.123456
# Epoch 60, Denoising Loss: 0.078901
# Epoch 80, Denoising Loss: 0.056789
# Epoch 100, Denoising Loss: 0.045678
#
# SNR before denoising: 5.23 dB
# SNR after denoising:  18.76 dB
# Improvement: 13.53 dB
</code></pre>
        </section>

        <section>
            <h2>4.3 Variational Autoencoderï¼ˆVAEï¼‰</h2>

            <p>VAEã¯ç¢ºç‡çš„ãªç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã§ã€æ½œåœ¨ç©ºé–“ã‹ã‚‰æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã§ãã¾ã™ã€‚ãƒ—ãƒ­ã‚»ã‚¹ãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆã‚„è£œå®Œã«åˆ©ç”¨ã—ã¾ã™ã€‚</p>

            <div class="info-box">
                <p><strong>ğŸ’¡ VAEã®ç‰¹å¾´</strong></p>
                <ul>
                    <li><strong>ç¢ºç‡çš„ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°</strong>: æ½œåœ¨å¤‰æ•° \(z \sim \mathcal{N}(\mu, \sigma^2)\)</li>
                    <li><strong>KL divergenceé …</strong>: æ½œåœ¨åˆ†å¸ƒã‚’æ¨™æº–æ­£è¦åˆ†å¸ƒã«è¿‘ã¥ã‘ã‚‹æ­£å‰‡åŒ–</li>
                    <li><strong>ç”Ÿæˆèƒ½åŠ›</strong>: æ½œåœ¨ç©ºé–“ã‹ã‚‰ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ã¦æ–°ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ</li>
                </ul>
            </div>

            <p>VAEã®æå¤±é–¢æ•°ï¼š</p>

            <p>$$\mathcal{L} = \mathbb{E}_{q(z|x)}[\log p(x|z)] - D_{KL}(q(z|x) || p(z))$$</p>

            <h3>ä¾‹3: VAEã«ã‚ˆã‚‹ãƒ—ãƒ­ã‚»ã‚¹ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ</h3>

            <pre><code class="language-python">class VAE(nn.Module):
    """Variational Autoencoder"""

    def __init__(self, input_dim, latent_dim=8):
        super(VAE, self).__init__()

        # Encoder
        self.fc1 = nn.Linear(input_dim, 128)
        self.fc2 = nn.Linear(128, 64)

        # å¹³å‡ã¨åˆ†æ•£ã‚’å‡ºåŠ›
        self.fc_mu = nn.Linear(64, latent_dim)
        self.fc_logvar = nn.Linear(64, latent_dim)

        # Decoder
        self.fc3 = nn.Linear(latent_dim, 64)
        self.fc4 = nn.Linear(64, 128)
        self.fc5 = nn.Linear(128, input_dim)

    def encode(self, x):
        """Encoder: å¹³å‡ã¨å¯¾æ•°åˆ†æ•£ã‚’å‡ºåŠ›

        Returns:
            mu: [batch, latent_dim] å¹³å‡
            logvar: [batch, latent_dim] log(ÏƒÂ²)
        """
        h = torch.relu(self.fc1(x))
        h = torch.relu(self.fc2(h))
        mu = self.fc_mu(h)
        logvar = self.fc_logvar(h)
        return mu, logvar

    def reparameterize(self, mu, logvar):
        """Reparameterization trick

        z = Î¼ + Ïƒ * Îµ, where Îµ ~ N(0, 1)
        """
        std = torch.exp(0.5 * logvar)
        eps = torch.randn_like(std)
        z = mu + eps * std
        return z

    def decode(self, z):
        """Decoder: æ½œåœ¨å¤‰æ•°ã‹ã‚‰å†æ§‹æˆ"""
        h = torch.relu(self.fc3(z))
        h = torch.relu(self.fc4(h))
        reconstructed = self.fc5(h)
        return reconstructed

    def forward(self, x):
        """
        Returns:
            reconstructed: å†æ§‹æˆãƒ‡ãƒ¼ã‚¿
            mu: æ½œåœ¨å¤‰æ•°ã®å¹³å‡
            logvar: æ½œåœ¨å¤‰æ•°ã®å¯¾æ•°åˆ†æ•£
        """
        mu, logvar = self.encode(x)
        z = self.reparameterize(mu, logvar)
        reconstructed = self.decode(z)
        return reconstructed, mu, logvar

def vae_loss(reconstructed, original, mu, logvar, beta=1.0):
    """VAE loss = Reconstruction + KL divergence

    Args:
        beta: KLé …ã®é‡ã¿ï¼ˆÎ²-VAEï¼‰
    """
    # Reconstruction loss (MSE)
    recon_loss = nn.functional.mse_loss(reconstructed, original, reduction='sum')

    # KL divergence: -0.5 * Î£(1 + log(ÏƒÂ²) - Î¼Â² - ÏƒÂ²)
    kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())

    return recon_loss + beta * kl_loss

# ãƒ—ãƒ­ã‚»ã‚¹ãƒ‡ãƒ¼ã‚¿
data = generate_process_data(n_samples=1000, n_features=15)
data_normalized = (data - data.mean(axis=0)) / (data.std(axis=0) + 1e-8)
data_tensor = torch.FloatTensor(data_normalized)

# VAEè¨“ç·´
model = VAE(input_dim=15, latent_dim=4)
optimizer = optim.Adam(model.parameters(), lr=0.001)

for epoch in range(150):
    model.train()
    optimizer.zero_grad()

    reconstructed, mu, logvar = model(data_tensor)
    loss = vae_loss(reconstructed, data_tensor, mu, logvar, beta=0.5)

    loss.backward()
    optimizer.step()

    if (epoch + 1) % 30 == 0:
        print(f'Epoch {epoch+1}, Loss: {loss.item():.2f}')

# æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
model.eval()
with torch.no_grad():
    # æ½œåœ¨ç©ºé–“ã‹ã‚‰ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
    z_samples = torch.randn(10, 4)  # æ¨™æº–æ­£è¦åˆ†å¸ƒã‹ã‚‰10ã‚µãƒ³ãƒ—ãƒ«
    generated_data = model.decode(z_samples)

    print(f"\nGenerated data shape: {generated_data.shape}")
    print(f"Generated data range: [{generated_data.min():.2f}, {generated_data.max():.2f}]")

    # å…ƒãƒ‡ãƒ¼ã‚¿ã¨ã®çµ±è¨ˆæ¯”è¼ƒ
    original_mean = data_tensor.mean(dim=0)
    generated_mean = generated_data.mean(dim=0)

    print(f"\nOriginal data mean (first 5 vars): {original_mean[:5].numpy()}")
    print(f"Generated data mean (first 5 vars): {generated_mean[:5].numpy()}")

# å‡ºåŠ›ä¾‹:
# Epoch 30, Loss: 8765.43
# Epoch 60, Loss: 4321.09
# Epoch 90, Loss: 2987.65
# Epoch 120, Loss: 2456.78
# Epoch 150, Loss: 2234.56
#
# Generated data shape: torch.Size([10, 15])
# Generated data range: [-2.87, 2.45]
#
# Original data mean (first 5 vars): [-0.01  0.02 -0.00  0.01 -0.02]
# Generated data mean (first 5 vars): [-0.15  0.23 -0.08  0.12 -0.18]
</code></pre>
        </section>

        <section>
            <h2>4.4 å†æ§‹æˆèª¤å·®ã«ã‚ˆã‚‹ç•°å¸¸æ¤œçŸ¥</h2>

            <p>æ­£å¸¸ãƒ‡ãƒ¼ã‚¿ã§è¨“ç·´ã—ãŸã‚ªãƒ¼ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã¯ã€ç•°å¸¸ãƒ‡ãƒ¼ã‚¿ã‚’æ­£ç¢ºã«å†æ§‹æˆã§ãã¾ã›ã‚“ã€‚ã“ã®æ€§è³ªã‚’åˆ©ç”¨ã—ã¦ç•°å¸¸ã‚’æ¤œçŸ¥ã—ã¾ã™ã€‚</p>

            <h3>ä¾‹4: ãƒ—ãƒ­ã‚»ã‚¹ç•°å¸¸æ¤œçŸ¥ã‚·ã‚¹ãƒ†ãƒ </h3>

            <pre><code class="language-python">class AnomalyDetector:
    """ã‚ªãƒ¼ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ™ãƒ¼ã‚¹ã®ç•°å¸¸æ¤œçŸ¥"""

    def __init__(self, autoencoder, threshold_percentile=95):
        """
        Args:
            autoencoder: è¨“ç·´æ¸ˆã¿ã‚ªãƒ¼ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€
            threshold_percentile: ç•°å¸¸åˆ¤å®šé–¾å€¤ï¼ˆæ­£å¸¸ãƒ‡ãƒ¼ã‚¿ã®å†æ§‹æˆèª¤å·®ã®ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«ï¼‰
        """
        self.autoencoder = autoencoder
        self.threshold = None
        self.threshold_percentile = threshold_percentile

    def fit_threshold(self, normal_data):
        """æ­£å¸¸ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰é–¾å€¤ã‚’æ±ºå®š

        Args:
            normal_data: [samples, features] æ­£å¸¸ãƒ—ãƒ­ã‚»ã‚¹ãƒ‡ãƒ¼ã‚¿
        """
        self.autoencoder.eval()
        with torch.no_grad():
            reconstructed, _ = self.autoencoder(normal_data)
            reconstruction_errors = torch.mean((normal_data - reconstructed) ** 2, dim=1)

        # ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«ã§é–¾å€¤ã‚’è¨­å®š
        self.threshold = torch.quantile(reconstruction_errors, self.threshold_percentile / 100.0)

        print(f"Anomaly threshold set to: {self.threshold.item():.6f}")
        print(f"Based on {self.threshold_percentile}th percentile of normal data errors")

        return reconstruction_errors

    def detect(self, data):
        """ç•°å¸¸æ¤œçŸ¥

        Args:
            data: [samples, features] ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿

        Returns:
            is_anomaly: [samples] ãƒ–ãƒ¼ãƒ«é…åˆ—ï¼ˆTrue=ç•°å¸¸ï¼‰
            scores: [samples] ç•°å¸¸ã‚¹ã‚³ã‚¢ï¼ˆå†æ§‹æˆèª¤å·®ï¼‰
        """
        self.autoencoder.eval()
        with torch.no_grad():
            reconstructed, _ = self.autoencoder(data)
            scores = torch.mean((data - reconstructed) ** 2, dim=1)

        is_anomaly = scores > self.threshold

        return is_anomaly, scores

# æ­£å¸¸ãƒ‡ãƒ¼ã‚¿ã§è¨“ç·´
normal_data = generate_process_data(n_samples=800, n_features=10)
normal_normalized = (normal_data - normal_data.mean(axis=0)) / (normal_data.std(axis=0) + 1e-8)
normal_tensor = torch.FloatTensor(normal_normalized)

# ã‚ªãƒ¼ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€è¨“ç·´
ae_model = VanillaAutoencoder(input_dim=10, latent_dim=3)
optimizer = optim.Adam(ae_model.parameters(), lr=0.001)
criterion = nn.MSELoss()

for epoch in range(100):
    ae_model.train()
    optimizer.zero_grad()
    reconstructed, _ = ae_model(normal_tensor)
    loss = criterion(reconstructed, normal_tensor)
    loss.backward()
    optimizer.step()

    if (epoch + 1) % 25 == 0:
        print(f'Training Epoch {epoch+1}, Loss: {loss.item():.6f}')

# ç•°å¸¸æ¤œçŸ¥å™¨ã®åˆæœŸåŒ–
detector = AnomalyDetector(ae_model, threshold_percentile=95)
normal_errors = detector.fit_threshold(normal_tensor)

# ç•°å¸¸ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆï¼ˆä¸€éƒ¨ã®å¤‰æ•°ã«å¤§ããªåå·®ã‚’è¿½åŠ ï¼‰
anomaly_data = generate_process_data(n_samples=200, n_features=10)
# ç•°å¸¸ãƒ‘ã‚¿ãƒ¼ãƒ³1: ç‰¹å®šå¤‰æ•°ãŒç•°å¸¸å€¤
anomaly_data[:100, 0] += 5.0  # å¤‰æ•°1ãŒç•°å¸¸
# ç•°å¸¸ãƒ‘ã‚¿ãƒ¼ãƒ³2: è¤‡æ•°å¤‰æ•°ã®ç•°å¸¸ãªç›¸é–¢
anomaly_data[100:, [2, 5, 7]] += 3.0

anomaly_normalized = (anomaly_data - normal_data.mean(axis=0)) / (normal_data.std(axis=0) + 1e-8)
anomaly_tensor = torch.FloatTensor(anomaly_normalized)

# ç•°å¸¸æ¤œçŸ¥
is_anomaly, anomaly_scores = detector.detect(anomaly_tensor)

# è©•ä¾¡
n_detected = is_anomaly.sum().item()
detection_rate = 100 * n_detected / len(anomaly_tensor)

print(f"\nAnomaly detection results:")
print(f"  Total test samples: {len(anomaly_tensor)}")
print(f"  Detected anomalies: {n_detected}")
print(f"  Detection rate: {detection_rate:.2f}%")
print(f"  Score range: [{anomaly_scores.min():.6f}, {anomaly_scores.max():.6f}]")

# æ­£å¸¸ãƒ‡ãƒ¼ã‚¿ã§ã®èª¤æ¤œçŸ¥ç‡
false_positive = (normal_errors > detector.threshold).sum().item()
fpr = 100 * false_positive / len(normal_errors)
print(f"  False positive rate: {fpr:.2f}%")

# å¯è¦–åŒ–
plt.figure(figsize=(10, 4))
plt.hist(normal_errors.numpy(), bins=50, alpha=0.7, label='Normal', color='green')
plt.hist(anomaly_scores.numpy(), bins=50, alpha=0.7, label='Anomaly', color='red')
plt.axvline(detector.threshold.item(), color='black', linestyle='--', label='Threshold')
plt.xlabel('Reconstruction Error')
plt.ylabel('Frequency')
plt.legend()
plt.title('Anomaly Detection: Reconstruction Error Distribution')
plt.yscale('log')
plt.grid(True, alpha=0.3)
plt.tight_layout()

# å‡ºåŠ›ä¾‹:
# Training Epoch 25, Loss: 0.045678
# Training Epoch 50, Loss: 0.023456
# Training Epoch 75, Loss: 0.015678
# Training Epoch 100, Loss: 0.012345
# Anomaly threshold set to: 0.034567
# Based on 95th percentile of normal data errors
#
# Anomaly detection results:
#   Total test samples: 200
#   Detected anomalies: 187
#   Detection rate: 93.50%
#   Score range: [0.012345, 0.234567]
#   False positive rate: 5.00%
</code></pre>
        </section>

        <section>
            <h2>4.5 Sparse Autoencoderï¼ˆç–ãªç‰¹å¾´æŠ½å‡ºï¼‰</h2>

            <p>ã‚¹ãƒ‘ãƒ¼ã‚¹æ€§æ­£å‰‡åŒ–ã«ã‚ˆã‚Šã€å°‘æ•°ã®é‡è¦ãªç‰¹å¾´ã®ã¿ã‚’æ´»æ€§åŒ–ã•ã›ã¾ã™ã€‚ãƒ—ãƒ­ã‚»ã‚¹å¤‰æ•°ã®ä¸­ã‹ã‚‰é‡è¦ãªçµ„ã¿åˆã‚ã›ã‚’ç™ºè¦‹ã§ãã¾ã™ã€‚</p>

            <h3>ä¾‹5: ã‚¹ãƒ‘ãƒ¼ã‚¹ç‰¹å¾´æŠ½å‡º</h3>

            <pre><code class="language-python">class SparseAutoencoder(nn.Module):
    """ã‚¹ãƒ‘ãƒ¼ã‚¹ã‚ªãƒ¼ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€"""

    def __init__(self, input_dim, latent_dim=20):
        super(SparseAutoencoder, self).__init__()

        # Encoderï¼ˆæ½œåœ¨å±¤ã‚’å¤§ãã‚ã«è¨­å®šã—ã€ã‚¹ãƒ‘ãƒ¼ã‚¹æ€§ã§åˆ¶ç´„ï¼‰
        self.encoder = nn.Sequential(
            nn.Linear(input_dim, 128),
            nn.ReLU(),
            nn.Linear(128, latent_dim),
            nn.ReLU()  # éè² åˆ¶ç´„ï¼ˆReLUï¼‰
        )

        # Decoder
        self.decoder = nn.Sequential(
            nn.Linear(latent_dim, 128),
            nn.ReLU(),
            nn.Linear(128, input_dim)
        )

    def forward(self, x):
        latent = self.encoder(x)
        reconstructed = self.decoder(latent)
        return reconstructed, latent

def sparse_loss(reconstructed, original, latent, sparsity_weight=0.01, sparsity_target=0.05):
    """ã‚¹ãƒ‘ãƒ¼ã‚¹æ€§ã‚’è€ƒæ…®ã—ãŸæå¤±é–¢æ•°

    Args:
        sparsity_weight: ã‚¹ãƒ‘ãƒ¼ã‚¹é …ã®é‡ã¿
        sparsity_target: ç›®æ¨™ã‚¹ãƒ‘ãƒ¼ã‚¹ç‡ï¼ˆ5%ã®æ´»æ€§åŒ–ãŒç†æƒ³ãªã©ï¼‰
    """
    # Reconstruction loss
    recon_loss = nn.functional.mse_loss(reconstructed, original)

    # Sparsity loss: KL divergence between target and actual activation
    # å„ãƒ¦ãƒ‹ãƒƒãƒˆã®å¹³å‡æ´»æ€§åŒ–ç‡
    rho = torch.mean(latent, dim=0)  # [latent_dim]
    rho_hat = torch.tensor([sparsity_target] * latent.size(1))

    # KL(Ï || ÏÌ‚)
    kl_div = sparsity_target * torch.log(sparsity_target / (rho + 1e-8)) + \
             (1 - sparsity_target) * torch.log((1 - sparsity_target) / (1 - rho + 1e-8))
    sparsity_loss = torch.sum(kl_div)

    return recon_loss + sparsity_weight * sparsity_loss

# ãƒ—ãƒ­ã‚»ã‚¹ãƒ‡ãƒ¼ã‚¿ï¼ˆ30å¤‰æ•°ï¼‰
large_data = generate_process_data(n_samples=1000, n_features=30)
large_normalized = (large_data - large_data.mean(axis=0)) / (large_data.std(axis=0) + 1e-8)
large_tensor = torch.FloatTensor(large_normalized)

# ã‚¹ãƒ‘ãƒ¼ã‚¹ã‚ªãƒ¼ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€è¨“ç·´
sparse_model = SparseAutoencoder(input_dim=30, latent_dim=20)
optimizer = optim.Adam(sparse_model.parameters(), lr=0.001)

for epoch in range(100):
    sparse_model.train()
    optimizer.zero_grad()

    reconstructed, latent = sparse_model(large_tensor)
    loss = sparse_loss(reconstructed, large_tensor, latent,
                      sparsity_weight=0.05, sparsity_target=0.1)

    loss.backward()
    optimizer.step()

    if (epoch + 1) % 20 == 0:
        # ã‚¹ãƒ‘ãƒ¼ã‚¹ç‡ã‚’è¨ˆç®—
        with torch.no_grad():
            _, latent_codes = sparse_model(large_tensor)
            sparsity_rate = (latent_codes < 0.01).float().mean().item()

        print(f'Epoch {epoch+1}, Loss: {loss.item():.6f}, Sparsity: {100*sparsity_rate:.2f}%')

# é‡è¦ç‰¹å¾´ã®åˆ†æ
sparse_model.eval()
with torch.no_grad():
    _, latent_codes = sparse_model(large_tensor)

    # å„æ½œåœ¨ãƒ¦ãƒ‹ãƒƒãƒˆã®æ´»æ€§åŒ–é »åº¦
    activation_freq = (latent_codes > 0.1).float().mean(dim=0).numpy()

    # Top-5ã®æ´»æ€§çš„ãªãƒ¦ãƒ‹ãƒƒãƒˆ
    top_units = np.argsort(activation_freq)[-5:][::-1]

    print(f"\nTop 5 active latent units:")
    for i, unit_id in enumerate(top_units):
        print(f"  {i+1}. Unit {unit_id}: {100*activation_freq[unit_id]:.2f}% activation")

    # å„ãƒ¦ãƒ‹ãƒƒãƒˆãŒè¡¨ç¾ã™ã‚‹å…¥åŠ›å¤‰æ•°ã®é‡è¦åº¦
    encoder_weights = sparse_model.encoder[2].weight.data.numpy()  # [latent, 128]

    print(f"\nLatent unit representations:")
    for unit_id in top_units[:3]:
        weights = encoder_weights[unit_id]
        top_inputs = np.argsort(np.abs(weights))[-5:][::-1]
        print(f"  Unit {unit_id} â†’ Input variables: {top_inputs}")

# å‡ºåŠ›ä¾‹:
# Epoch 20, Loss: 0.567890, Sparsity: 62.34%
# Epoch 40, Loss: 0.345678, Sparsity: 78.56%
# Epoch 60, Loss: 0.234567, Sparsity: 85.23%
# Epoch 80, Loss: 0.178901, Sparsity: 88.45%
# Epoch 100, Loss: 0.145678, Sparsity: 89.67%
#
# Top 5 active latent units:
#   1. Unit 12: 45.67% activation
#   2. Unit 7: 38.92% activation
#   3. Unit 18: 32.45% activation
#   4. Unit 3: 28.76% activation
#   5. Unit 15: 24.33% activation
#
# Latent unit representations:
#   Unit 12 â†’ Input variables: [ 3  7 12 18 23]
#   Unit 7 â†’ Input variables: [ 1  5 14 19 27]
#   Unit 18 â†’ Input variables: [ 2  9 11 16 25]
</code></pre>
        </section>

        <section>
            <h2>4.6 Convolutional Autoencoderï¼ˆç”»åƒåœ§ç¸®ï¼‰</h2>

            <p>ç•³ã¿è¾¼ã¿å±¤ã‚’ä½¿ç”¨ã—ãŸã‚ªãƒ¼ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã§ã€ãƒ—ãƒ­ã‚»ã‚¹ç”»åƒã‚’åŠ¹ç‡çš„ã«åœ§ç¸®ãƒ»å¾©å…ƒã—ã¾ã™ã€‚</p>

            <h3>ä¾‹6: ãƒ—ãƒ­ã‚»ã‚¹ç”»åƒã®åœ§ç¸®</h3>

            <pre><code class="language-python">class ConvAutoencoder(nn.Module):
    """ç•³ã¿è¾¼ã¿ã‚ªãƒ¼ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€"""

    def __init__(self, latent_dim=64):
        super(ConvAutoencoder, self).__init__()

        # Encoder
        self.encoder = nn.Sequential(
            # 224x224 â†’ 112x112
            nn.Conv2d(3, 32, 3, stride=2, padding=1),
            nn.ReLU(),
            nn.BatchNorm2d(32),

            # 112x112 â†’ 56x56
            nn.Conv2d(32, 64, 3, stride=2, padding=1),
            nn.ReLU(),
            nn.BatchNorm2d(64),

            # 56x56 â†’ 28x28
            nn.Conv2d(64, 128, 3, stride=2, padding=1),
            nn.ReLU(),
            nn.BatchNorm2d(128),

            # 28x28 â†’ 14x14
            nn.Conv2d(128, 256, 3, stride=2, padding=1),
            nn.ReLU(),
            nn.BatchNorm2d(256)
        )

        # Bottleneck: 256*14*14 â†’ latent_dim
        self.fc_encode = nn.Linear(256 * 14 * 14, latent_dim)

        # Bottleneck: latent_dim â†’ 256*14*14
        self.fc_decode = nn.Linear(latent_dim, 256 * 14 * 14)

        # Decoder
        self.decoder = nn.Sequential(
            # 14x14 â†’ 28x28
            nn.ConvTranspose2d(256, 128, 3, stride=2, padding=1, output_padding=1),
            nn.ReLU(),
            nn.BatchNorm2d(128),

            # 28x28 â†’ 56x56
            nn.ConvTranspose2d(128, 64, 3, stride=2, padding=1, output_padding=1),
            nn.ReLU(),
            nn.BatchNorm2d(64),

            # 56x56 â†’ 112x112
            nn.ConvTranspose2d(64, 32, 3, stride=2, padding=1, output_padding=1),
            nn.ReLU(),
            nn.BatchNorm2d(32),

            # 112x112 â†’ 224x224
            nn.ConvTranspose2d(32, 3, 3, stride=2, padding=1, output_padding=1),
            nn.Sigmoid()  # 0-1ã«æ­£è¦åŒ–
        )

    def forward(self, x):
        """
        Args:
            x: [batch, 3, 224, 224]
        Returns:
            reconstructed: [batch, 3, 224, 224]
            latent: [batch, latent_dim]
        """
        # Encode
        encoded = self.encoder(x)  # [batch, 256, 14, 14]
        encoded_flat = encoded.view(encoded.size(0), -1)  # [batch, 256*14*14]
        latent = self.fc_encode(encoded_flat)  # [batch, latent_dim]

        # Decode
        decoded_flat = self.fc_decode(latent)  # [batch, 256*14*14]
        decoded = decoded_flat.view(-1, 256, 14, 14)  # [batch, 256, 14, 14]
        reconstructed = self.decoder(decoded)  # [batch, 3, 224, 224]

        return reconstructed, latent

# ãƒ€ãƒŸãƒ¼ç”»åƒãƒ‡ãƒ¼ã‚¿ï¼ˆå®Ÿéš›ã¯ãƒ—ãƒ­ã‚»ã‚¹ç”»åƒï¼‰
dummy_images = torch.rand(16, 3, 224, 224)  # 0-1ã«æ­£è¦åŒ–æ¸ˆã¿

# ãƒ¢ãƒ‡ãƒ«
conv_ae = ConvAutoencoder(latent_dim=128)

# åœ§ç¸®ç‡ã®è¨ˆç®—
original_size = 3 * 224 * 224  # 150,528
compressed_size = 128
compression_ratio = original_size / compressed_size

print(f"Compression ratio: {compression_ratio:.2f}x")
print(f"Original: {original_size:,} â†’ Compressed: {compressed_size}")

# è¨“ç·´
criterion = nn.MSELoss()
optimizer = optim.Adam(conv_ae.parameters(), lr=0.001)

for epoch in range(30):
    conv_ae.train()
    optimizer.zero_grad()

    reconstructed, latent = conv_ae(dummy_images)
    loss = criterion(reconstructed, dummy_images)

    loss.backward()
    optimizer.step()

    if (epoch + 1) % 10 == 0:
        # PSNRï¼ˆPeak Signal-to-Noise Ratioï¼‰ã‚’è¨ˆç®—
        mse = loss.item()
        psnr = 10 * np.log10(1.0 / mse)
        print(f'Epoch {epoch+1}, MSE: {mse:.6f}, PSNR: {psnr:.2f} dB')

# ãƒ†ã‚¹ãƒˆ
conv_ae.eval()
with torch.no_grad():
    test_image = dummy_images[0:1]
    reconstructed_image, latent_code = conv_ae(test_image)

    # ç”»åƒã®æ¯”è¼ƒï¼ˆæœ€åˆã®ã‚µãƒ³ãƒ—ãƒ«ï¼‰
    original_np = test_image[0].permute(1, 2, 0).numpy()
    reconstructed_np = reconstructed_image[0].permute(1, 2, 0).numpy()

    # èª¤å·®
    pixel_error = np.abs(original_np - reconstructed_np)
    mean_error = pixel_error.mean()

    print(f"\nReconstruction quality:")
    print(f"  Mean pixel error: {mean_error:.6f}")
    print(f"  Max pixel error: {pixel_error.max():.6f}")

# å‡ºåŠ›ä¾‹:
# Compression ratio: 1176.00x
# Original: 150,528 â†’ Compressed: 128
# Epoch 10, MSE: 0.023456, PSNR: 16.30 dB
# Epoch 20, MSE: 0.012345, PSNR: 19.09 dB
# Epoch 30, MSE: 0.008901, PSNR: 20.51 dB
#
# Reconstruction quality:
#   Mean pixel error: 0.008234
#   Max pixel error: 0.234567
</code></pre>
        </section>

        <section>
            <h2>4.7 Conditional VAEï¼ˆæ¡ä»¶ä»˜ãç”Ÿæˆï¼‰</h2>

            <p>æ¡ä»¶ï¼ˆãƒ—ãƒ­ã‚»ã‚¹æ¡ä»¶ã€è¨­å®šæ¸©åº¦ãªã©ï¼‰ã‚’æŒ‡å®šã—ã¦ã€ãã®æ¡ä»¶ä¸‹ã§ã®ãƒ—ãƒ­ã‚»ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã¾ã™ã€‚</p>

            <h3>ä¾‹7: æ¡ä»¶ä»˜ããƒ—ãƒ­ã‚»ã‚¹ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ</h3>

            <pre><code class="language-python">class ConditionalVAE(nn.Module):
    """æ¡ä»¶ä»˜ãVAEï¼ˆC-VAEï¼‰"""

    def __init__(self, input_dim, condition_dim, latent_dim=8):
        """
        Args:
            input_dim: ãƒ‡ãƒ¼ã‚¿æ¬¡å…ƒ
            condition_dim: æ¡ä»¶æ¬¡å…ƒï¼ˆæ¸©åº¦ã€åœ§åŠ›è¨­å®šå€¤ãªã©ï¼‰
            latent_dim: æ½œåœ¨æ¬¡å…ƒ
        """
        super(ConditionalVAE, self).__init__()

        # Encoder: ãƒ‡ãƒ¼ã‚¿ + æ¡ä»¶ â†’ æ½œåœ¨å¤‰æ•°
        self.fc1 = nn.Linear(input_dim + condition_dim, 128)
        self.fc2 = nn.Linear(128, 64)
        self.fc_mu = nn.Linear(64, latent_dim)
        self.fc_logvar = nn.Linear(64, latent_dim)

        # Decoder: æ½œåœ¨å¤‰æ•° + æ¡ä»¶ â†’ ãƒ‡ãƒ¼ã‚¿
        self.fc3 = nn.Linear(latent_dim + condition_dim, 64)
        self.fc4 = nn.Linear(64, 128)
        self.fc5 = nn.Linear(128, input_dim)

    def encode(self, x, c):
        """Encode with condition

        Args:
            x: [batch, input_dim] ãƒ‡ãƒ¼ã‚¿
            c: [batch, condition_dim] æ¡ä»¶
        """
        h = torch.cat([x, c], dim=1)  # æ¡ä»¶ã‚’çµåˆ
        h = torch.relu(self.fc1(h))
        h = torch.relu(self.fc2(h))
        mu = self.fc_mu(h)
        logvar = self.fc_logvar(h)
        return mu, logvar

    def decode(self, z, c):
        """Decode with condition

        Args:
            z: [batch, latent_dim] æ½œåœ¨å¤‰æ•°
            c: [batch, condition_dim] æ¡ä»¶
        """
        h = torch.cat([z, c], dim=1)  # æ¡ä»¶ã‚’çµåˆ
        h = torch.relu(self.fc3(h))
        h = torch.relu(self.fc4(h))
        reconstructed = self.fc5(h)
        return reconstructed

    def reparameterize(self, mu, logvar):
        std = torch.exp(0.5 * logvar)
        eps = torch.randn_like(std)
        return mu + eps * std

    def forward(self, x, c):
        mu, logvar = self.encode(x, c)
        z = self.reparameterize(mu, logvar)
        reconstructed = self.decode(z, c)
        return reconstructed, mu, logvar

# æ¡ä»¶ä»˜ããƒ—ãƒ­ã‚»ã‚¹ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
def generate_conditional_data(n_samples=1000):
    """æ¡ä»¶ï¼ˆæ¸©åº¦ï¼‰ã«ä¾å­˜ã™ã‚‹ãƒ—ãƒ­ã‚»ã‚¹ãƒ‡ãƒ¼ã‚¿"""
    # æ¡ä»¶: åå¿œæ¸©åº¦ [300-500K]
    temperature = np.random.uniform(300, 500, n_samples)

    # ãƒ‡ãƒ¼ã‚¿: æ¸©åº¦ã«ä¾å­˜ã™ã‚‹5å¤‰æ•°
    data = np.zeros((n_samples, 5))

    for i in range(n_samples):
        T = temperature[i]

        # æ¸©åº¦ã«ä¾å­˜ã™ã‚‹ç‰©ç†åŒ–å­¦çš„é–¢ä¿‚
        data[i, 0] = 0.001 * T**2 - 0.3 * T + 50  # åå¿œé€Ÿåº¦å®šæ•°
        data[i, 1] = 100 * np.exp(-5000 / T)  # å¹³è¡¡å®šæ•°ï¼ˆArrheniuså‹ï¼‰
        data[i, 2] = 0.5 * T + 50  # åœ§åŠ›
        data[i, 3] = -0.002 * T + 2.0  # pH
        data[i, 4] = 0.01 * T  # æ¿ƒåº¦

        # ãƒã‚¤ã‚º
        data[i] += np.random.randn(5) * 2

    # æ­£è¦åŒ–
    condition = (temperature - 300) / 200  # 0-1ã«æ­£è¦åŒ–
    condition = condition.reshape(-1, 1)

    return data, condition

# ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
data, conditions = generate_conditional_data(n_samples=1000)
data_normalized = (data - data.mean(axis=0)) / (data.std(axis=0) + 1e-8)

data_tensor = torch.FloatTensor(data_normalized)
condition_tensor = torch.FloatTensor(conditions)

# C-VAEè¨“ç·´
cvae = ConditionalVAE(input_dim=5, condition_dim=1, latent_dim=4)
optimizer = optim.Adam(cvae.parameters(), lr=0.001)

for epoch in range(150):
    cvae.train()
    optimizer.zero_grad()

    reconstructed, mu, logvar = cvae(data_tensor, condition_tensor)
    loss = vae_loss(reconstructed, data_tensor, mu, logvar, beta=0.5)

    loss.backward()
    optimizer.step()

    if (epoch + 1) % 30 == 0:
        print(f'Epoch {epoch+1}, Loss: {loss.item():.2f}')

# æ¡ä»¶ã‚’æŒ‡å®šã—ã¦ç”Ÿæˆ
cvae.eval()
with torch.no_grad():
    # ç‰¹å®šæ¸©åº¦ï¼ˆä¾‹: 400Kï¼‰ã§ã®ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    target_temp = 400  # K
    target_condition = torch.FloatTensor([[(target_temp - 300) / 200]])  # æ­£è¦åŒ–

    # æ½œåœ¨ç©ºé–“ã‹ã‚‰ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
    z_samples = torch.randn(10, 4)

    # æ¡ä»¶ã‚’10ã‚µãƒ³ãƒ—ãƒ«å…¨ã¦ã«é©ç”¨
    conditions_repeated = target_condition.repeat(10, 1)

    # ç”Ÿæˆ
    generated_data = cvae.decode(z_samples, conditions_repeated)

    print(f"\nGenerated data for T={target_temp}K:")
    print(f"  Shape: {generated_data.shape}")
    print(f"  Mean (normalized): {generated_data.mean(dim=0).numpy()}")

    # ç•°ãªã‚‹æ¸©åº¦ã§ã®ç”Ÿæˆæ¯”è¼ƒ
    temps = [320, 380, 440, 500]
    print(f"\nData generation at different temperatures:")

    for temp in temps:
        cond = torch.FloatTensor([[(temp - 300) / 200]])
        z = torch.randn(1, 4)
        gen = cvae.decode(z, cond)
        print(f"  T={temp}K: Variable 0 = {gen[0, 0].item():.4f}")

# å‡ºåŠ›ä¾‹:
# Epoch 30, Loss: 6789.01
# Epoch 60, Loss: 3456.78
# Epoch 90, Loss: 2345.67
# Epoch 120, Loss: 1987.65
# Epoch 150, Loss: 1765.43
#
# Generated data for T=400K:
#   Shape: torch.Size([10, 5])
#   Mean (normalized): [-0.12  0.34 -0.08  0.15 -0.23]
#
# Data generation at different temperatures:
#   T=320K: Variable 0 = -1.2345
#   T=380K: Variable 0 = -0.4567
#   T=440K: Variable 0 = 0.6789
#   T=500K: Variable 0 = 1.5432
</code></pre>
        </section>

        <section>
            <h2>4.8 GANã«ã‚ˆã‚‹åˆæˆãƒ—ãƒ­ã‚»ã‚¹ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ</h2>

            <p>Generative Adversarial Networkï¼ˆGANï¼‰ã‚’ä½¿ç”¨ã—ã¦ã€å®Ÿãƒ‡ãƒ¼ã‚¿ã¨è¦‹åˆ†ã‘ãŒã¤ã‹ãªã„ãƒ—ãƒ­ã‚»ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã‚„å°‘é‡ãƒ‡ãƒ¼ã‚¿å•é¡Œã®è§£æ±ºã«åˆ©ç”¨ã—ã¾ã™ã€‚</p>

            <h3>ä¾‹8: Process GAN</h3>

            <pre><code class="language-python">class Generator(nn.Module):
    """ãƒ—ãƒ­ã‚»ã‚¹ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆå™¨"""

    def __init__(self, latent_dim=16, output_dim=10):
        super(Generator, self).__init__()

        self.model = nn.Sequential(
            nn.Linear(latent_dim, 64),
            nn.LeakyReLU(0.2),
            nn.BatchNorm1d(64),

            nn.Linear(64, 128),
            nn.LeakyReLU(0.2),
            nn.BatchNorm1d(128),

            nn.Linear(128, 256),
            nn.LeakyReLU(0.2),
            nn.BatchNorm1d(256),

            nn.Linear(256, output_dim),
            nn.Tanh()  # -1ï½1ã«æ­£è¦åŒ–
        )

    def forward(self, z):
        """
        Args:
            z: [batch, latent_dim] ãƒã‚¤ã‚ºãƒ™ã‚¯ãƒˆãƒ«
        Returns:
            fake_data: [batch, output_dim] ç”Ÿæˆãƒ‡ãƒ¼ã‚¿
        """
        return self.model(z)

class Discriminator(nn.Module):
    """ãƒ—ãƒ­ã‚»ã‚¹ãƒ‡ãƒ¼ã‚¿è­˜åˆ¥å™¨ï¼ˆæœ¬ç‰© vs å½ç‰©ï¼‰"""

    def __init__(self, input_dim=10):
        super(Discriminator, self).__init__()

        self.model = nn.Sequential(
            nn.Linear(input_dim, 256),
            nn.LeakyReLU(0.2),
            nn.Dropout(0.3),

            nn.Linear(256, 128),
            nn.LeakyReLU(0.2),
            nn.Dropout(0.3),

            nn.Linear(128, 64),
            nn.LeakyReLU(0.2),
            nn.Dropout(0.3),

            nn.Linear(64, 1),
            nn.Sigmoid()  # 0-1ã®ç¢ºç‡
        )

    def forward(self, x):
        """
        Args:
            x: [batch, input_dim] ãƒ‡ãƒ¼ã‚¿
        Returns:
            validity: [batch, 1] æœ¬ç‰©ã§ã‚ã‚‹ç¢ºç‡
        """
        return self.model(x)

# å®Ÿãƒ‡ãƒ¼ã‚¿
real_data = generate_process_data(n_samples=1000, n_features=10)
real_normalized = 2 * (real_data - real_data.min(axis=0)) / \
                  (real_data.max(axis=0) - real_data.min(axis=0) + 1e-8) - 1  # -1ï½1
real_tensor = torch.FloatTensor(real_normalized)

# GANåˆæœŸåŒ–
latent_dim = 16
generator = Generator(latent_dim=latent_dim, output_dim=10)
discriminator = Discriminator(input_dim=10)

# æœ€é©åŒ–
lr = 0.0002
optimizer_G = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))
optimizer_D = optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))

criterion = nn.BCELoss()

# è¨“ç·´
batch_size = 64
n_epochs = 100

for epoch in range(n_epochs):
    # Discriminatorã®è¨“ç·´
    for _ in range(2):  # Discriminatorã‚’2å›æ›´æ–°
        optimizer_D.zero_grad()

        # å®Ÿãƒ‡ãƒ¼ã‚¿
        idx = np.random.randint(0, len(real_tensor), batch_size)
        real_batch = real_tensor[idx]
        real_labels = torch.ones(batch_size, 1)

        # å½ãƒ‡ãƒ¼ã‚¿
        z = torch.randn(batch_size, latent_dim)
        fake_batch = generator(z).detach()
        fake_labels = torch.zeros(batch_size, 1)

        # Discriminatorã®æå¤±
        real_loss = criterion(discriminator(real_batch), real_labels)
        fake_loss = criterion(discriminator(fake_batch), fake_labels)
        d_loss = (real_loss + fake_loss) / 2

        d_loss.backward()
        optimizer_D.step()

    # Generatorã®è¨“ç·´
    optimizer_G.zero_grad()

    z = torch.randn(batch_size, latent_dim)
    fake_batch = generator(z)

    # Generatorã¯å½ç‰©ã‚’æœ¬ç‰©ã¨èª¤èªã•ã›ãŸã„
    g_loss = criterion(discriminator(fake_batch), torch.ones(batch_size, 1))

    g_loss.backward()
    optimizer_G.step()

    if (epoch + 1) % 20 == 0:
        print(f'Epoch {epoch+1}/{n_epochs}, D Loss: {d_loss.item():.4f}, G Loss: {g_loss.item():.4f}')

# ç”Ÿæˆãƒ‡ãƒ¼ã‚¿ã®è©•ä¾¡
generator.eval()
with torch.no_grad():
    z_samples = torch.randn(1000, latent_dim)
    generated_data = generator(z_samples).numpy()

# çµ±è¨ˆæ¯”è¼ƒ
print(f"\nStatistical comparison:")
print(f"Real data mean: {real_normalized.mean(axis=0)[:3]}")
print(f"Generated mean: {generated_data.mean(axis=0)[:3]}")
print(f"Real data std:  {real_normalized.std(axis=0)[:3]}")
print(f"Generated std:  {generated_data.std(axis=0)[:3]}")

# Discriminatorã«ã‚ˆã‚‹è©•ä¾¡
real_score = discriminator(real_tensor).mean().item()
fake_score = discriminator(torch.FloatTensor(generated_data)).mean().item()

print(f"\nDiscriminator scores:")
print(f"  Real data: {real_score:.4f} (1.0 = perfect real)")
print(f"  Generated data: {fake_score:.4f} (0.5 = indistinguishable)")

# å‡ºåŠ›ä¾‹:
# Epoch 20/100, D Loss: 0.5678, G Loss: 0.8901
# Epoch 40/100, D Loss: 0.4567, G Loss: 1.0234
# Epoch 60/100, D Loss: 0.3890, G Loss: 1.2345
# Epoch 80/100, D Loss: 0.3456, G Loss: 1.3456
# Epoch 100/100, D Loss: 0.3234, G Loss: 1.4123
#
# Statistical comparison:
# Real data mean: [-0.023  0.045 -0.012]
# Generated mean: [-0.034  0.056 -0.018]
# Real data std:  [0.567 0.623 0.589]
# Generated std:  [0.543 0.598 0.612]
#
# Discriminator scores:
#   Real data: 0.8234 (1.0 = perfect real)
#   Generated data: 0.4876 (0.5 = indistinguishable)
</code></pre>

            <div class="success-box">
                <p><strong>âœ… GANã®å¿œç”¨</strong></p>
                <ul>
                    <li><strong>ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µ</strong>: å°‘é‡ã®å®Ÿãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å¤§é‡ã®åˆæˆãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ</li>
                    <li><strong>ç•°å¸¸ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ</strong>: è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã«ä¸è¶³ã™ã‚‹ç•°å¸¸ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åˆæˆ</li>
                    <li><strong>ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ä»£æ›¿</strong>: ç‰©ç†ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®é«˜é€Ÿä»£æ›¿</li>
                    <li><strong>ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ä¿è­·</strong>: å®Ÿãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆçš„æ€§è³ªã‚’ä¿æŒã—ãŸåˆæˆãƒ‡ãƒ¼ã‚¿</li>
                </ul>
            </div>
        </section>

        <section>
            <h2>å­¦ç¿’ç›®æ¨™ã®ç¢ºèª</h2>

            <p>ã“ã®ç« ã‚’å®Œäº†ã™ã‚‹ã¨ã€ä»¥ä¸‹ã‚’å®Ÿè£…ãƒ»èª¬æ˜ã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã™ï¼š</p>

            <h3>åŸºæœ¬ç†è§£</h3>
            <ul>
                <li>ã‚ªãƒ¼ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ»ãƒ‡ã‚³ãƒ¼ãƒ€æ§‹é€ ã¨å†æ§‹æˆã‚¿ã‚¹ã‚¯ã‚’èª¬æ˜ã§ãã‚‹</li>
                <li>VAEã®reparameterization trickã¨KL divergenceé …ã®å½¹å‰²ã‚’ç†è§£ã—ã¦ã„ã‚‹</li>
                <li>GANã®æ•µå¯¾çš„å­¦ç¿’ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’èª¬æ˜ã§ãã‚‹</li>
                <li>å†æ§‹æˆèª¤å·®ã«åŸºã¥ãç•°å¸¸æ¤œçŸ¥ã®åŸç†ã‚’ç†è§£ã—ã¦ã„ã‚‹</li>
            </ul>

            <h3>å®Ÿè·µã‚¹ã‚­ãƒ«</h3>
            <ul>
                <li>PyTorchã§Autoencoderã‚’å®Ÿè£…ã—ã€ãƒ—ãƒ­ã‚»ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’æ¬¡å…ƒå‰Šæ¸›ã§ãã‚‹</li>
                <li>Denoising Autoencoderã§ã‚»ãƒ³ã‚µãƒ¼ãƒã‚¤ã‚ºã‚’é™¤å»ã§ãã‚‹</li>
                <li>VAEã§æ–°ã—ã„ãƒ—ãƒ­ã‚»ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã§ãã‚‹</li>
                <li>å†æ§‹æˆèª¤å·®ã«ã‚ˆã‚‹ç•°å¸¸æ¤œçŸ¥ã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ã§ãã‚‹</li>
                <li>Sparse Autoencoderã§é‡è¦ãªç‰¹å¾´çµ„ã¿åˆã‚ã›ã‚’æŠ½å‡ºã§ãã‚‹</li>
                <li>Convolutional Autoencoderã§ç”»åƒã‚’åœ§ç¸®ã§ãã‚‹</li>
                <li>Conditional VAEã§æ¡ä»¶ä»˜ããƒ‡ãƒ¼ã‚¿ç”ŸæˆãŒã§ãã‚‹</li>
                <li>GANã§çµ±è¨ˆçš„ã«å¦¥å½“ãªåˆæˆãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã§ãã‚‹</li>
            </ul>

            <h3>å¿œç”¨åŠ›</h3>
            <ul>
                <li>ãƒ—ãƒ­ã‚»ã‚¹ã®ç‰¹æ€§ã«å¿œã˜ã¦é©åˆ‡ãªAutoencoderã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’é¸æŠã§ãã‚‹</li>
                <li>ç•°å¸¸æ¤œçŸ¥ã®é–¾å€¤ã‚’é©åˆ‡ã«è¨­å®šã—ã€èª¤æ¤œçŸ¥ç‡ã‚’åˆ¶å¾¡ã§ãã‚‹</li>
                <li>å°‘é‡ãƒ‡ãƒ¼ã‚¿å•é¡Œã‚’GANã«ã‚ˆã‚‹ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã§è§£æ±ºã§ãã‚‹</li>
                <li>æ¡ä»¶ä»˜ãç”Ÿæˆã§ç‰¹å®šãƒ—ãƒ­ã‚»ã‚¹æ¡ä»¶ä¸‹ã®ãƒ‡ãƒ¼ã‚¿ã‚’åˆæˆã§ãã‚‹</li>
            </ul>
        </section>

        <section>
            <h2>å‚è€ƒæ–‡çŒ®</h2>
            <ol>
                <li>Hinton, G. E., & Salakhutdinov, R. R. (2006). "Reducing the Dimensionality of Data with Neural Networks." Science, 313(5786), 504-507.</li>
                <li>Vincent, P., et al. (2008). "Extracting and Composing Robust Features with Denoising Autoencoders." ICML 2008.</li>
                <li>Kingma, D. P., & Welling, M. (2014). "Auto-Encoding Variational Bayes." ICLR 2014.</li>
                <li>Goodfellow, I., et al. (2014). "Generative Adversarial Networks." NeurIPS 2014.</li>
                <li>Sakurada, M., & Yairi, T. (2014). "Anomaly Detection Using Autoencoders with Nonlinear Dimensionality Reduction." MLSDA Workshop 2014.</li>
                <li>Mirza, M., & Osindero, S. (2014). "Conditional Generative Adversarial Nets." arXiv:1411.1784.</li>
            </ol>
        </section>

        <div class="navigation">
            <a href="chapter-3.html" class="nav-button">â† ç¬¬3ç« ï¼šCNN</a>
            <a href="chapter-5.html" class="nav-button">ç¬¬5ç« ï¼šå¼·åŒ–å­¦ç¿’ â†’</a>
        </div>
    </main>
</body>
</html>
