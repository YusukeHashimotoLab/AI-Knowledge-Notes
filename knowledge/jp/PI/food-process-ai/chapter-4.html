<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ç¬¬4ç«  äºˆçŸ¥ä¿å…¨ã¨ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚° | ãƒ—ãƒ­ã‚»ã‚¹ãƒ»ã‚¤ãƒ³ãƒ•ã‚©ãƒãƒ†ã‚£ã‚¯ã‚¹é“å ´</title>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif;
            line-height: 1.8; color: #333; background: #f5f5f5;
        }
        header {
            background: linear-gradient(135deg, #11998e 0%, #38ef7d 100%);
            color: white; padding: 2rem 1rem; text-align: center;
        }
        h1 { font-size: 2rem; margin-bottom: 0.5rem; }
        .subtitle { opacity: 0.9; font-size: 1.1rem; }
        .container { max-width: 1200px; margin: 2rem auto; padding: 0 1rem; }
        .back-link {
            display: inline-block; margin-bottom: 2rem; padding: 0.5rem 1rem;
            background: white; color: #11998e; text-decoration: none;
            border-radius: 6px; font-weight: 600;
        }
        .content-box {
            background: white; padding: 2rem; border-radius: 12px;
            margin-bottom: 2rem; box-shadow: 0 2px 8px rgba(0,0,0,0.1);
        }
        h2 {
            color: #11998e; margin: 2rem 0 1rem 0;
            padding-bottom: 0.5rem; border-bottom: 3px solid #11998e;
        }
        h3 { color: #2c3e50; margin: 1.5rem 0 1rem 0; }
        p { margin-bottom: 1rem; }
        ul, ol { margin-left: 2rem; margin-bottom: 1rem; }
        li { margin-bottom: 0.5rem; }
        pre {
            background: #1e1e1e; color: #d4d4d4; padding: 1.5rem;
            border-radius: 8px; overflow-x: auto; margin: 1rem 0;
            border-left: 4px solid #11998e;
        }
        code {
            font-family: 'Courier New', monospace; font-size: 0.9rem;
        }
        .key-point {
            background: #e8f5e9; padding: 1rem; border-radius: 6px;
            border-left: 4px solid #4caf50; margin: 1rem 0;
        }
        .formula {
            background: #f0f7ff; padding: 1rem; border-radius: 6px;
            margin: 1rem 0; overflow-x: auto;
        }
        .nav-buttons {
            display: flex; justify-content: space-between; margin-top: 3rem;
        }
        .nav-buttons a {
            padding: 0.75rem 1.5rem;
            background: linear-gradient(135deg, #11998e 0%, #38ef7d 100%);
            color: white; text-decoration: none; border-radius: 6px;
            font-weight: 600;
        }
        footer {
            background: #2c3e50; color: white; text-align: center;
            padding: 2rem 1rem; margin-top: 4rem;
        }
    
        
    
        /* Breadcrumb styles */
        .breadcrumb {
            background: #f7fafc;
            padding: 0.75rem 1rem;
            border-bottom: 1px solid #e2e8f0;
            font-size: 0.9rem;
        }

        .breadcrumb-content {
            max-width: 900px;
            margin: 0 auto;
            display: flex;
            align-items: center;
            flex-wrap: wrap;
            gap: 0.5rem;
        }

        .breadcrumb a {
            color: #667eea;
            text-decoration: none;
            transition: color 0.2s;
        }

        .breadcrumb a:hover {
            color: #764ba2;
            text-decoration: underline;
        }

        .breadcrumb-separator {
            color: #a0aec0;
            margin: 0 0.25rem;
        }

        .breadcrumb-current {
            color: #4a5568;
            font-weight: 500;
        }
    </style>

    <style>
        /* Locale Switcher Styles */
        .locale-switcher {
            display: flex;
            align-items: center;
            gap: 0.5rem;
            padding: 0.5rem 1rem;
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
            border-radius: 6px;
            font-size: 0.9rem;
            margin-bottom: 1rem;
            box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);
        }

        .current-locale {
            font-weight: 600;
            color: #7b2cbf;
            display: flex;
            align-items: center;
            gap: 0.25rem;
        }

        .locale-separator {
            color: #adb5bd;
            font-weight: 300;
        }

        .locale-link {
            color: #f093fb;
            text-decoration: none;
            font-weight: 500;
            transition: all 0.2s ease;
            display: flex;
            align-items: center;
            gap: 0.25rem;
            padding: 0.2rem 0.5rem;
            border-radius: 4px;
        }

        .locale-link:hover {
            background: rgba(240, 147, 251, 0.1);
            color: #d07be8;
            transform: translateY(-1px);
        }

        .locale-meta {
            color: #868e96;
            font-size: 0.85rem;
            font-style: italic;
            margin-left: auto;
        }

        @media (max-width: 768px) {
            .locale-switcher {
                font-size: 0.85rem;
                padding: 0.4rem 0.8rem;
            }
            .locale-meta {
                display: none;
            }
        }
    </style>
</head>
<body>
            <div class="locale-switcher">
<span class="current-locale">ğŸŒ JP</span>
<span class="locale-separator">|</span>
<a href="../../../en/PI/food-process-ai/chapter-4.html" class="locale-link">ğŸ‡¬ğŸ‡§ EN</a>
<span class="locale-separator">|</span>
<span class="locale-meta">Last sync: 2025-11-16</span>
</div>
<nav class="breadcrumb">
        <div class="breadcrumb-content">
            <a href="../../index.html">AIå¯ºå­å±‹ãƒˆãƒƒãƒ—</a><span class="breadcrumb-separator">â€º</span><a href="../../PI/index.html">ãƒ—ãƒ­ã‚»ã‚¹ãƒ»ã‚¤ãƒ³ãƒ•ã‚©ãƒãƒ†ã‚£ã‚¯ã‚¹</a><span class="breadcrumb-separator">â€º</span><a href="../../PI/food-process-ai/index.html">Food Process Ai</a><span class="breadcrumb-separator">â€º</span><span class="breadcrumb-current">Chapter 4</span>
        </div>
    </nav>

        <header>
        <h1>ç¬¬4ç«  äºˆçŸ¥ä¿å…¨ã¨ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°</h1>
        <p class="subtitle">Predictive Maintenance and Troubleshooting</p>
    </header>

    <div class="container">
        <a href="index.html" class="back-link">â† ã‚·ãƒªãƒ¼ã‚ºç›®æ¬¡ã«æˆ»ã‚‹</a>

        <div class="content-box">
            <h2>ğŸ“– æœ¬ç« ã®æ¦‚è¦</h2>
            <p>
                é£Ÿå“è£½é€ ãƒ—ãƒ­ã‚»ã‚¹ã«ãŠã„ã¦ã€è¨­å‚™ã®çªç„¶ã®æ•…éšœã‚„å“è³ªãƒˆãƒ©ãƒ–ãƒ«ã¯ã€ç”Ÿç”£åœæ­¢ã‚„è£½å“å»ƒæ£„ã«ã¤ãªãŒã‚‹é‡å¤§ãªå•é¡Œã§ã™ã€‚
                æœ¬ç« ã§ã¯ã€AIã‚’æ´»ç”¨ã—ãŸäºˆçŸ¥ä¿å…¨ï¼ˆPredictive Maintenanceï¼‰æŠ€è¡“ã«ã‚ˆã‚Šã€è¨­å‚™æ•…éšœã‚’äº‹å‰ã«äºˆæ¸¬ã—ã€
                è¨ˆç”»çš„ãªä¿å…¨ã‚’å®Ÿç¾ã™ã‚‹æ–¹æ³•ã‚’å­¦ã³ã¾ã™ã€‚ã¾ãŸã€ç•°å¸¸ãŒç™ºç”Ÿã—ãŸéš›ã®æ ¹æœ¬åŸå› åˆ†æã‚„ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã®
                æ„æ€æ±ºå®šæ”¯æ´ã‚·ã‚¹ãƒ†ãƒ ã«ã¤ã„ã¦ã‚‚è§£èª¬ã—ã¾ã™ã€‚
            </p>

            <h3>ğŸ¯ å­¦ç¿’ç›®æ¨™</h3>
            <ul>
                <li>è¨­å‚™æ•…éšœäºˆæ¸¬ã®ãŸã‚ã®æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒªãƒ³ã‚°æ‰‹æ³•</li>
                <li>æ®‹å­˜æœ‰ç”¨å¯¿å‘½ï¼ˆRULï¼‰æ¨å®šã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ </li>
                <li>ç•°å¸¸æ¤œå‡ºã¨æ—©æœŸè­¦å ±ã‚·ã‚¹ãƒ†ãƒ ã®æ§‹ç¯‰</li>
                <li>æ ¹æœ¬åŸå› åˆ†æï¼ˆRCAï¼‰ã®ãŸã‚ã®ãƒ‡ãƒ¼ã‚¿è§£ææŠ€è¡“</li>
                <li>ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°æ„æ€æ±ºå®šæ”¯æ´ã‚·ã‚¹ãƒ†ãƒ </li>
                <li>ä¿å…¨è¨ˆç”»ã®æœ€é©åŒ–æ‰‹æ³•</li>
            </ul>
        </div>

        <div class="content-box">
            <h2>ğŸ”§ 4.1 è¨­å‚™æ•…éšœäºˆæ¸¬ã®åŸºç¤</h2>

            <h3>äºˆçŸ¥ä¿å…¨ã®3ã¤ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ</h3>
            <p>äºˆçŸ¥ä¿å…¨ã«ã¯ä¸»ã«ä»¥ä¸‹ã®3ã¤ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒãŒã‚ã‚Šã¾ã™ï¼š</p>
            <ul>
                <li><strong>æ™‚é–“åŸºæº–ä¿å…¨ï¼ˆTBMï¼‰</strong>: å›ºå®šã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã§ã®ä¿å…¨ï¼ˆå¾“æ¥å‹ï¼‰</li>
                <li><strong>çŠ¶æ…‹åŸºæº–ä¿å…¨ï¼ˆCBMï¼‰</strong>: ã‚»ãƒ³ã‚µãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ãé–¾å€¤ç®¡ç†</li>
                <li><strong>äºˆçŸ¥ä¿å…¨ï¼ˆPdMï¼‰</strong>: æ©Ÿæ¢°å­¦ç¿’ã«ã‚ˆã‚‹æ•…éšœäºˆæ¸¬ã¨æœ€é©ä¿å…¨ã‚¿ã‚¤ãƒŸãƒ³ã‚°æ±ºå®š</li>
            </ul>

            <div class="key-point">
                <strong>ğŸ’¡ äºˆçŸ¥ä¿å…¨ã®ãƒ¡ãƒªãƒƒãƒˆ</strong><br>
                ãƒ»è¨ˆç”»å¤–åœæ­¢æ™‚é–“ã®å‰Šæ¸›ï¼ˆ30-50%æ¸›ï¼‰<br>
                ãƒ»ä¿å…¨ã‚³ã‚¹ãƒˆã®å‰Šæ¸›ï¼ˆ20-30%æ¸›ï¼‰<br>
                ãƒ»è¨­å‚™å¯¿å‘½ã®å»¶é•·ï¼ˆ20-40%å¢—ï¼‰<br>
                ãƒ»éƒ¨å“åœ¨åº«ã®æœ€é©åŒ–
            </div>

            <h3>æ®‹å­˜æœ‰ç”¨å¯¿å‘½ï¼ˆRULï¼‰ã®å®šç¾©</h3>
            <div class="formula">
                $$ \text{RUL}(t) = T_{\text{failure}} - t $$
                <p>ã“ã“ã§ã€\( T_{\text{failure}} \) ã¯æ•…éšœç™ºç”Ÿæ™‚åˆ»ã€\( t \) ã¯ç¾åœ¨æ™‚åˆ»</p>
            </div>

            <h3>ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹4.1: Random Forestã«ã‚ˆã‚‹è¨­å‚™æ•…éšœäºˆæ¸¬</h3>
            <pre><code>import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc
import warnings
warnings.filterwarnings('ignore')

plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

# è¨­å‚™ã‚»ãƒ³ã‚µãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆï¼ˆ1000ã‚µãƒ³ãƒ—ãƒ«ï¼‰
np.random.seed(42)
n_samples = 1000

# æ­£å¸¸é‹è»¢ãƒ‡ãƒ¼ã‚¿ï¼ˆ70%ï¼‰
n_normal = int(n_samples * 0.7)
temp_normal = np.random.normal(75, 5, n_normal)  # æ¸©åº¦ï¼ˆâ„ƒï¼‰
vibration_normal = np.random.normal(0.3, 0.05, n_normal)  # æŒ¯å‹•ï¼ˆmm/sï¼‰
pressure_normal = np.random.normal(2.0, 0.2, n_normal)  # åœ§åŠ›ï¼ˆMPaï¼‰
current_normal = np.random.normal(15, 2, n_normal)  # é›»æµï¼ˆAï¼‰
runtime_normal = np.random.uniform(0, 5000, n_normal)  # ç¨¼åƒæ™‚é–“ï¼ˆhï¼‰

# æ•…éšœå‰å…†ãƒ‡ãƒ¼ã‚¿ï¼ˆ30%ï¼‰
n_failure = n_samples - n_normal
temp_failure = np.random.normal(90, 8, n_failure)  # é«˜æ¸©å‚¾å‘
vibration_failure = np.random.normal(0.6, 0.1, n_failure)  # æŒ¯å‹•å¢—åŠ 
pressure_failure = np.random.normal(2.5, 0.3, n_failure)  # åœ§åŠ›ä¸Šæ˜‡
current_failure = np.random.normal(20, 3, n_failure)  # é›»æµå¢—åŠ 
runtime_failure = np.random.uniform(4000, 8000, n_failure)  # é•·æ™‚é–“ç¨¼åƒ

# ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ä½œæˆ
data = pd.DataFrame({
    'temperature': np.concatenate([temp_normal, temp_failure]),
    'vibration': np.concatenate([vibration_normal, vibration_failure]),
    'pressure': np.concatenate([pressure_normal, pressure_failure]),
    'current': np.concatenate([current_normal, current_failure]),
    'runtime_hours': np.concatenate([runtime_normal, runtime_failure]),
    'failure_risk': np.concatenate([np.zeros(n_normal), np.ones(n_failure)])
})

# æ´¾ç”Ÿç‰¹å¾´é‡ã®ä½œæˆ
data['temp_vibration_ratio'] = data['temperature'] / (data['vibration'] * 100)
data['power_consumption'] = data['current'] * data['pressure']  # ä»®æƒ³çš„ãªé›»åŠ›æ¶ˆè²»é‡
data['runtime_category'] = pd.cut(data['runtime_hours'], bins=5, labels=['Very Low', 'Low', 'Medium', 'High', 'Very High'])
data['runtime_category'] = data['runtime_category'].cat.codes

# è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®åˆ†å‰²
X = data.drop('failure_risk', axis=1)
y = data['failure_risk']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)

# Random Forestãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´
rf_model = RandomForestClassifier(
    n_estimators=100,
    max_depth=10,
    min_samples_split=10,
    min_samples_leaf=5,
    random_state=42,
    class_weight='balanced'
)
rf_model.fit(X_train, y_train)

# äºˆæ¸¬ã¨è©•ä¾¡
y_pred = rf_model.predict(X_test)
y_pred_proba = rf_model.predict_proba(X_test)[:, 1]

print("=" * 60)
print("è¨­å‚™æ•…éšœäºˆæ¸¬ãƒ¢ãƒ‡ãƒ«è©•ä¾¡")
print("=" * 60)
print("\nåˆ†é¡ãƒ¬ãƒãƒ¼ãƒˆ:")
print(classification_report(y_test, y_pred, target_names=['æ­£å¸¸', 'æ•…éšœãƒªã‚¹ã‚¯']))

# å¯è¦–åŒ–
fig, axes = plt.subplots(2, 2, figsize=(14, 10))

# æ··åŒè¡Œåˆ—
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Greens', ax=axes[0, 0],
            xticklabels=['æ­£å¸¸', 'æ•…éšœãƒªã‚¹ã‚¯'], yticklabels=['æ­£å¸¸', 'æ•…éšœãƒªã‚¹ã‚¯'])
axes[0, 0].set_title('æ··åŒè¡Œåˆ—', fontsize=12, fontweight='bold')
axes[0, 0].set_ylabel('çœŸã®ãƒ©ãƒ™ãƒ«')
axes[0, 0].set_xlabel('äºˆæ¸¬ãƒ©ãƒ™ãƒ«')

# ROCæ›²ç·š
fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)
roc_auc = auc(fpr, tpr)
axes[0, 1].plot(fpr, tpr, color='#11998e', lw=2, label=f'ROCæ›²ç·š (AUC = {roc_auc:.3f})')
axes[0, 1].plot([0, 1], [0, 1], color='gray', lw=1, linestyle='--', label='ãƒ©ãƒ³ãƒ€ãƒ ')
axes[0, 1].set_xlim([0.0, 1.0])
axes[0, 1].set_ylim([0.0, 1.05])
axes[0, 1].set_xlabel('å½é™½æ€§ç‡ (False Positive Rate)')
axes[0, 1].set_ylabel('çœŸé™½æ€§ç‡ (True Positive Rate)')
axes[0, 1].set_title('ROCæ›²ç·š', fontsize=12, fontweight='bold')
axes[0, 1].legend(loc='lower right')
axes[0, 1].grid(alpha=0.3)

# ç‰¹å¾´é‡é‡è¦åº¦
feature_importance = pd.DataFrame({
    'feature': X.columns,
    'importance': rf_model.feature_importances_
}).sort_values('importance', ascending=True)

axes[1, 0].barh(feature_importance['feature'], feature_importance['importance'], color='#38ef7d')
axes[1, 0].set_xlabel('é‡è¦åº¦')
axes[1, 0].set_title('ç‰¹å¾´é‡é‡è¦åº¦', fontsize=12, fontweight='bold')
axes[1, 0].grid(axis='x', alpha=0.3)

# æ•…éšœãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢åˆ†å¸ƒ
axes[1, 1].hist(y_pred_proba[y_test == 0], bins=30, alpha=0.6, label='æ­£å¸¸', color='green')
axes[1, 1].hist(y_pred_proba[y_test == 1], bins=30, alpha=0.6, label='æ•…éšœãƒªã‚¹ã‚¯', color='red')
axes[1, 1].axvline(x=0.5, color='black', linestyle='--', linewidth=1, label='é–¾å€¤ (0.5)')
axes[1, 1].set_xlabel('æ•…éšœãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢')
axes[1, 1].set_ylabel('é »åº¦')
axes[1, 1].set_title('æ•…éšœãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢åˆ†å¸ƒ', fontsize=12, fontweight='bold')
axes[1, 1].legend()
axes[1, 1].grid(alpha=0.3)

plt.tight_layout()
plt.savefig('failure_prediction_analysis.png', dpi=300, bbox_inches='tight')
plt.show()

print(f"\nROC-AUC ã‚¹ã‚³ã‚¢: {roc_auc:.4f}")
print("\nç‰¹å¾´é‡é‡è¦åº¦ãƒˆãƒƒãƒ—3:")
print(feature_importance.tail(3).to_string(index=False))
</code></pre>

            <p><strong>å®Ÿè£…ã®ãƒã‚¤ãƒ³ãƒˆ:</strong></p>
            <ul>
                <li>ã‚»ãƒ³ã‚µãƒ‡ãƒ¼ã‚¿ï¼ˆæ¸©åº¦ã€æŒ¯å‹•ã€åœ§åŠ›ã€é›»æµï¼‰ã‚’çµ±åˆã—ãŸäºˆæ¸¬ãƒ¢ãƒ‡ãƒ«</li>
                <li>ç¨¼åƒæ™‚é–“ãªã©ã®å±¥æ­´æƒ…å ±ã‚‚ç‰¹å¾´é‡ã¨ã—ã¦æ´»ç”¨</li>
                <li>æ´¾ç”Ÿç‰¹å¾´é‡ï¼ˆæ¸©åº¦æŒ¯å‹•æ¯”ã€é›»åŠ›æ¶ˆè²»é‡ï¼‰ã®ç”Ÿæˆã§ç²¾åº¦å‘ä¸Š</li>
                <li>ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡ã¸ã®å¯¾å¿œï¼ˆclass_weight='balanced'ï¼‰</li>
                <li>ROC-AUCè©•ä¾¡ã«ã‚ˆã‚Šé–¾å€¤èª¿æ•´ã®æŒ‡é‡ã‚’æä¾›</li>
            </ul>
        </div>

        <div class="content-box">
            <h2>â±ï¸ 4.2 æ®‹å­˜æœ‰ç”¨å¯¿å‘½ï¼ˆRULï¼‰æ¨å®š</h2>

            <h3>RULæ¨å®šã®é‡è¦æ€§</h3>
            <p>
                æ•…éšœã‚’ã€Œã„ã¤èµ·ã“ã‚‹ã‹ã€ã¾ã§äºˆæ¸¬ã§ãã‚Œã°ã€æœ€é©ãªä¿å…¨ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã‚’è¨ˆç”»ã§ãã¾ã™ã€‚
                RULæ¨å®šã¯ã€ç¾åœ¨ã®è¨­å‚™çŠ¶æ…‹ã‹ã‚‰æ•…éšœã¾ã§ã®æ®‹ã‚Šæ™‚é–“ã‚’æ¨å®šã™ã‚‹æŠ€è¡“ã§ã™ã€‚
            </p>

            <h3>åŠ£åŒ–æ›²ç·šãƒ¢ãƒ‡ãƒ«</h3>
            <div class="formula">
                $$ \text{Health Index}(t) = 100 \times \exp\left(-\frac{t}{\tau}\right) $$
                <p>
                    ã“ã“ã§ã€\( \tau \) ã¯åŠ£åŒ–æ™‚å®šæ•°ã€å¥å…¨åº¦ãŒé–¾å€¤ï¼ˆä¾‹: 20%ï¼‰ã‚’ä¸‹å›ã‚‹ã¨æ•…éšœã¨åˆ¤å®š
                </p>
            </div>

            <h3>ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹4.2: LSTMã«ã‚ˆã‚‹æ®‹å­˜æœ‰ç”¨å¯¿å‘½æ¨å®š</h3>
            <pre><code>import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error
import warnings
warnings.filterwarnings('ignore')

# TensorFlow/Kerasã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆå®Ÿéš›ã®å®Ÿè£…ã§ã¯å¿…è¦ï¼‰
# from tensorflow.keras.models import Sequential
# from tensorflow.keras.layers import LSTM, Dense, Dropout

plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

# è¨­å‚™åŠ£åŒ–ãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆï¼ˆæ¨¡æ“¬çš„ãªRULãƒ‡ãƒ¼ã‚¿ï¼‰
np.random.seed(42)
n_cycles = 200  # ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«æ•°
time_steps = 100  # å„ã‚µã‚¤ã‚¯ãƒ«ã®ã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ—æ•°

# 3å°ã®è¨­å‚™ã®åŠ£åŒ–ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç”Ÿæˆ
def generate_degradation_data(n_cycles, time_steps, failure_threshold=20):
    """è¨­å‚™åŠ£åŒ–ãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆ"""
    data_list = []

    for cycle_id in range(n_cycles):
        # ãƒ©ãƒ³ãƒ€ãƒ ãªåŠ£åŒ–é€Ÿåº¦
        tau = np.random.uniform(60, 120)  # åŠ£åŒ–æ™‚å®šæ•°
        noise_level = np.random.uniform(2, 5)

        # å¥å…¨åº¦ã®è¨ˆç®—ï¼ˆæŒ‡æ•°é–¢æ•°çš„åŠ£åŒ– + ãƒã‚¤ã‚ºï¼‰
        t = np.arange(time_steps)
        health_index = 100 * np.exp(-t / tau) + np.random.normal(0, noise_level, time_steps)
        health_index = np.clip(health_index, 0, 100)

        # RULè¨ˆç®—ï¼ˆå¥å…¨åº¦ãŒé–¾å€¤ã‚’ä¸‹å›ã‚‹ã¾ã§ã®æ™‚é–“ï¼‰
        failure_time = np.where(health_index < failure_threshold)[0]
        if len(failure_time) > 0:
            failure_step = failure_time[0]
        else:
            failure_step = time_steps

        rul = np.maximum(0, failure_step - t)

        # ã‚»ãƒ³ã‚µãƒ‡ãƒ¼ã‚¿ï¼ˆå¥å…¨åº¦ã«å¿œã˜ã¦å¤‰åŒ–ï¼‰
        temperature = 60 + (100 - health_index) * 0.5 + np.random.normal(0, 2, time_steps)
        vibration = 0.2 + (100 - health_index) * 0.008 + np.random.normal(0, 0.05, time_steps)
        pressure = 1.8 + (100 - health_index) * 0.01 + np.random.normal(0, 0.1, time_steps)

        for step in range(time_steps):
            data_list.append({
                'cycle_id': cycle_id,
                'time_step': step,
                'temperature': temperature[step],
                'vibration': vibration[step],
                'pressure': pressure[step],
                'health_index': health_index[step],
                'RUL': rul[step]
            })

    return pd.DataFrame(data_list)

# ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
degradation_data = generate_degradation_data(n_cycles, time_steps)

# ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†
feature_columns = ['temperature', 'vibration', 'pressure', 'health_index']
scaler = MinMaxScaler()
degradation_data[feature_columns] = scaler.fit_transform(degradation_data[feature_columns])

# RULã®æ­£è¦åŒ–ï¼ˆ0-1ç¯„å›²ï¼‰
max_rul = degradation_data['RUL'].max()
degradation_data['RUL_normalized'] = degradation_data['RUL'] / max_rul

# è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®åˆ†å‰²
train_cycles = int(n_cycles * 0.8)
train_data = degradation_data[degradation_data['cycle_id'] < train_cycles]
test_data = degradation_data[degradation_data['cycle_id'] >= train_cycles]

print("=" * 60)
print("æ®‹å­˜æœ‰ç”¨å¯¿å‘½ï¼ˆRULï¼‰æ¨å®šã‚·ã‚¹ãƒ†ãƒ ")
print("=" * 60)
print(f"\nç·ã‚µã‚¤ã‚¯ãƒ«æ•°: {n_cycles}")
print(f"è¨“ç·´ã‚µã‚¤ã‚¯ãƒ«: {train_cycles}")
print(f"ãƒ†ã‚¹ãƒˆã‚µã‚¤ã‚¯ãƒ«: {n_cycles - train_cycles}")
print(f"å„ã‚µã‚¤ã‚¯ãƒ«ã®ã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ—æ•°: {time_steps}")
print(f"\nRULç¯„å›²: 0 ~ {max_rul:.0f} ã‚¹ãƒ†ãƒƒãƒ—")

# ç°¡æ˜“çš„ãªäºˆæ¸¬ï¼ˆå®Ÿéš›ã®LSTMã®ä»£ã‚ã‚Šã«ç§»å‹•å¹³å‡ãƒ™ãƒ¼ã‚¹ã®äºˆæ¸¬ã‚’ä½¿ç”¨ï¼‰
def simple_rul_prediction(data, window=10):
    """ç§»å‹•å¹³å‡ãƒ™ãƒ¼ã‚¹ã®ç°¡æ˜“RULäºˆæ¸¬"""
    predictions = []
    actuals = []

    for cycle_id in data['cycle_id'].unique():
        cycle_data = data[data['cycle_id'] == cycle_id].copy()

        for i in range(window, len(cycle_data)):
            # éå»windowã‚¹ãƒ†ãƒƒãƒ—ã®å¥å…¨åº¦ã®å¹³å‡çš„ãªä½ä¸‹ç‡ã‹ã‚‰äºˆæ¸¬
            recent_health = cycle_data.iloc[i-window:i]['health_index'].values
            health_decline_rate = (recent_health[0] - recent_health[-1]) / window

            current_health = cycle_data.iloc[i]['health_index']

            # å¥å…¨åº¦ãŒ20%ã«é”ã™ã‚‹ã¾ã§ã®ã‚¹ãƒ†ãƒƒãƒ—æ•°ã‚’æ¨å®š
            if health_decline_rate > 0.0001:
                estimated_rul = max(0, (current_health - 0.2) / health_decline_rate)
            else:
                estimated_rul = max_rul  # åŠ£åŒ–ãŒè¦‹ã‚‰ã‚Œãªã„å ´åˆ

            estimated_rul = min(estimated_rul, max_rul)  # ä¸Šé™åˆ¶ç´„

            predictions.append(estimated_rul / max_rul)  # æ­£è¦åŒ–
            actuals.append(cycle_data.iloc[i]['RUL_normalized'])

    return np.array(predictions), np.array(actuals)

# ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§äºˆæ¸¬
y_pred, y_true = simple_rul_prediction(test_data, window=10)

# è©•ä¾¡æŒ‡æ¨™
mae = mean_absolute_error(y_true * max_rul, y_pred * max_rul)
rmse = np.sqrt(mean_squared_error(y_true * max_rul, y_pred * max_rul))

print(f"\näºˆæ¸¬æ€§èƒ½:")
print(f"MAE (å¹³å‡çµ¶å¯¾èª¤å·®): {mae:.2f} ã‚¹ãƒ†ãƒƒãƒ—")
print(f"RMSE (äºŒä¹—å¹³å‡å¹³æ–¹æ ¹èª¤å·®): {rmse:.2f} ã‚¹ãƒ†ãƒƒãƒ—")

# å¯è¦–åŒ–
fig, axes = plt.subplots(2, 2, figsize=(14, 10))

# ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚¯ãƒ«ã®åŠ£åŒ–æ›²ç·š
sample_cycles = [0, 1, 2]
for i, cycle_id in enumerate(sample_cycles):
    cycle_data = degradation_data[degradation_data['cycle_id'] == cycle_id]
    axes[0, 0].plot(cycle_data['time_step'], cycle_data['health_index'],
                    label=f'ã‚µã‚¤ã‚¯ãƒ« {cycle_id}', alpha=0.7)

axes[0, 0].axhline(y=0.2, color='red', linestyle='--', linewidth=1, label='æ•…éšœé–¾å€¤ (20%)')
axes[0, 0].set_xlabel('ã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ—')
axes[0, 0].set_ylabel('å¥å…¨åº¦ï¼ˆæ­£è¦åŒ–ï¼‰')
axes[0, 0].set_title('è¨­å‚™åŠ£åŒ–æ›²ç·šï¼ˆã‚µãƒ³ãƒ—ãƒ«ï¼‰', fontsize=12, fontweight='bold')
axes[0, 0].legend()
axes[0, 0].grid(alpha=0.3)

# RULäºˆæ¸¬ vs å®Ÿæ¸¬
axes[0, 1].scatter(y_true * max_rul, y_pred * max_rul, alpha=0.3, s=10, color='#11998e')
axes[0, 1].plot([0, max_rul], [0, max_rul], 'r--', lw=2, label='ç†æƒ³çš„ãªäºˆæ¸¬')
axes[0, 1].set_xlabel('å®Ÿæ¸¬RULï¼ˆã‚¹ãƒ†ãƒƒãƒ—ï¼‰')
axes[0, 1].set_ylabel('äºˆæ¸¬RULï¼ˆã‚¹ãƒ†ãƒƒãƒ—ï¼‰')
axes[0, 1].set_title('RULäºˆæ¸¬ç²¾åº¦', fontsize=12, fontweight='bold')
axes[0, 1].legend()
axes[0, 1].grid(alpha=0.3)

# äºˆæ¸¬èª¤å·®ã®åˆ†å¸ƒ
errors = (y_pred - y_true) * max_rul
axes[1, 0].hist(errors, bins=50, color='#38ef7d', alpha=0.7, edgecolor='black')
axes[1, 0].axvline(x=0, color='red', linestyle='--', linewidth=2, label='èª¤å·®ã‚¼ãƒ­')
axes[1, 0].set_xlabel('äºˆæ¸¬èª¤å·®ï¼ˆã‚¹ãƒ†ãƒƒãƒ—ï¼‰')
axes[1, 0].set_ylabel('é »åº¦')
axes[1, 0].set_title('RULäºˆæ¸¬èª¤å·®åˆ†å¸ƒ', fontsize=12, fontweight='bold')
axes[1, 0].legend()
axes[1, 0].grid(alpha=0.3)

# ç‰¹å®šã‚µã‚¤ã‚¯ãƒ«ã®RULæ™‚ç³»åˆ—
test_cycle = test_data['cycle_id'].unique()[0]
test_cycle_data = test_data[test_data['cycle_id'] == test_cycle].iloc[10:]  # windowã‚µã‚¤ã‚ºåˆ†ã‚¹ã‚­ãƒƒãƒ—
cycle_pred, cycle_true = simple_rul_prediction(
    test_data[test_data['cycle_id'] == test_cycle], window=10
)

axes[1, 1].plot(test_cycle_data['time_step'].values, cycle_true * max_rul,
                label='å®Ÿæ¸¬RUL', color='blue', linewidth=2)
axes[1, 1].plot(test_cycle_data['time_step'].values, cycle_pred * max_rul,
                label='äºˆæ¸¬RUL', color='orange', linewidth=2, linestyle='--')
axes[1, 1].fill_between(test_cycle_data['time_step'].values,
                         cycle_pred * max_rul - 10, cycle_pred * max_rul + 10,
                         alpha=0.2, color='orange', label='äºˆæ¸¬èª¤å·®ç¯„å›² (Â±10)')
axes[1, 1].set_xlabel('ã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ—')
axes[1, 1].set_ylabel('RULï¼ˆã‚¹ãƒ†ãƒƒãƒ—ï¼‰')
axes[1, 1].set_title(f'RULæ™‚ç³»åˆ—äºˆæ¸¬ï¼ˆã‚µã‚¤ã‚¯ãƒ« {test_cycle}ï¼‰', fontsize=12, fontweight='bold')
axes[1, 1].legend()
axes[1, 1].grid(alpha=0.3)

plt.tight_layout()
plt.savefig('rul_estimation_analysis.png', dpi=300, bbox_inches='tight')
plt.show()
</code></pre>

            <p><strong>å®Ÿè£…ã®ãƒã‚¤ãƒ³ãƒˆ:</strong></p>
            <ul>
                <li>æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ï¼ˆæ¸©åº¦ã€æŒ¯å‹•ã€åœ§åŠ›ã€å¥å…¨åº¦ï¼‰ã‹ã‚‰å°†æ¥ã®æ•…éšœæ™‚æœŸã‚’æ¨å®š</li>
                <li>å®Ÿéš›ã®å®Ÿè£…ã§ã¯LSTMï¼ˆLong Short-Term Memoryï¼‰ãªã©ã®RNNã‚’ä½¿ç”¨</li>
                <li>å¥å…¨åº¦æŒ‡æ¨™ã‚’å®šç¾©ã—ã€åŠ£åŒ–ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å­¦ç¿’</li>
                <li>äºˆæ¸¬èª¤å·®ã®è©•ä¾¡ã«ã‚ˆã‚Šã€ä¿å…¨è¨ˆç”»ã®ä¿¡é ¼æ€§ã‚’å®šé‡åŒ–</li>
                <li>æ®‹ã‚Šæ™‚é–“ã®å¯è¦–åŒ–ã«ã‚ˆã‚Šã€ä¿å…¨æ‹…å½“è€…ã®æ„æ€æ±ºå®šã‚’æ”¯æ´</li>
            </ul>
        </div>

        <div class="content-box">
            <h2>ğŸš¨ 4.3 ç•°å¸¸æ¤œå‡ºã¨æ—©æœŸè­¦å ±ã‚·ã‚¹ãƒ†ãƒ </h2>

            <h3>ç•°å¸¸æ¤œå‡ºã®2ã¤ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ</h3>
            <ol>
                <li><strong>æ•™å¸«ã‚ã‚Šå­¦ç¿’</strong>: éå»ã®æ•…éšœäº‹ä¾‹ã‹ã‚‰å­¦ç¿’ï¼ˆãƒ©ãƒ™ãƒ«ä»˜ããƒ‡ãƒ¼ã‚¿å¿…è¦ï¼‰</li>
                <li><strong>æ•™å¸«ãªã—å­¦ç¿’</strong>: æ­£å¸¸ãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ã‚‰ã®é€¸è„±ã‚’æ¤œå‡ºï¼ˆç•°å¸¸ãƒ‡ãƒ¼ã‚¿ä¸è¦ï¼‰</li>
            </ol>

            <div class="key-point">
                <strong>ğŸ’¡ æ•™å¸«ãªã—ç•°å¸¸æ¤œå‡ºã®åˆ©ç‚¹</strong><br>
                ãƒ»æœªçŸ¥ã®ç•°å¸¸ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚‚æ¤œå‡ºå¯èƒ½<br>
                ãƒ»æ•…éšœäº‹ä¾‹ã®å°‘ãªã„æ–°è¨­å‚™ã«ã‚‚é©ç”¨å¯èƒ½<br>
                ãƒ»ãƒ©ãƒ™ãƒ«ä»˜ã‘ã‚³ã‚¹ãƒˆã®å‰Šæ¸›
            </div>

            <h3>ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹4.3: Isolation Forestã«ã‚ˆã‚‹ç•°å¸¸æ¤œå‡º</h3>
            <pre><code>import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.ensemble import IsolationForest
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
import warnings
warnings.filterwarnings('ignore')

plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

# æ­£å¸¸é‹è»¢ãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆ
np.random.seed(42)
n_normal = 800
n_anomaly = 50

# æ­£å¸¸ãƒ‡ãƒ¼ã‚¿ï¼ˆå¤šå¤‰é‡æ­£è¦åˆ†å¸ƒï¼‰
mean_normal = [70, 0.25, 2.0, 14, 50]
cov_normal = [[25, 0, 0, 0, 0],
              [0, 0.0025, 0, 0, 0],
              [0, 0, 0.04, 0, 0],
              [0, 0, 0, 4, 0],
              [0, 0, 0, 0, 100]]

normal_data = np.random.multivariate_normal(mean_normal, cov_normal, n_normal)

# ç•°å¸¸ãƒ‡ãƒ¼ã‚¿ï¼ˆæ§˜ã€…ãªç•°å¸¸ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰
anomaly_patterns = []

# ãƒ‘ã‚¿ãƒ¼ãƒ³1: é«˜æ¸©ç•°å¸¸
high_temp = np.random.multivariate_normal([95, 0.25, 2.0, 14, 50], cov_normal, n_anomaly // 5)
anomaly_patterns.append(high_temp)

# ãƒ‘ã‚¿ãƒ¼ãƒ³2: æŒ¯å‹•ç•°å¸¸
high_vibration = np.random.multivariate_normal([70, 0.7, 2.0, 14, 50], cov_normal, n_anomaly // 5)
anomaly_patterns.append(high_vibration)

# ãƒ‘ã‚¿ãƒ¼ãƒ³3: åœ§åŠ›ç•°å¸¸
high_pressure = np.random.multivariate_normal([70, 0.25, 3.5, 14, 50], cov_normal, n_anomaly // 5)
anomaly_patterns.append(high_pressure)

# ãƒ‘ã‚¿ãƒ¼ãƒ³4: é›»æµç•°å¸¸
high_current = np.random.multivariate_normal([70, 0.25, 2.0, 25, 50], cov_normal, n_anomaly // 5)
anomaly_patterns.append(high_current)

# ãƒ‘ã‚¿ãƒ¼ãƒ³5: è¤‡åˆç•°å¸¸
combined = np.random.multivariate_normal([90, 0.6, 2.8, 20, 80], cov_normal, n_anomaly // 5)
anomaly_patterns.append(combined)

anomaly_data = np.vstack(anomaly_patterns)

# ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ä½œæˆ
columns = ['temperature', 'vibration', 'pressure', 'current', 'humidity']
df_normal = pd.DataFrame(normal_data, columns=columns)
df_normal['label'] = 0  # æ­£å¸¸

df_anomaly = pd.DataFrame(anomaly_data, columns=columns)
df_anomaly['label'] = 1  # ç•°å¸¸

df = pd.concat([df_normal, df_anomaly], ignore_index=True)
df = df.sample(frac=1, random_state=42).reset_index(drop=True)  # ã‚·ãƒ£ãƒƒãƒ•ãƒ«

# ãƒ‡ãƒ¼ã‚¿ã®æ¨™æº–åŒ–
X = df[columns].values
y_true = df['label'].values

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Isolation Forest ãƒ¢ãƒ‡ãƒ«
iso_forest = IsolationForest(
    contamination=0.1,  # ç•°å¸¸ãƒ‡ãƒ¼ã‚¿ã®å‰²åˆã®æ¨å®šå€¤
    random_state=42,
    n_estimators=100,
    max_samples='auto'
)

# ç•°å¸¸ã‚¹ã‚³ã‚¢ã®è¨ˆç®—
y_pred = iso_forest.fit_predict(X_scaled)
anomaly_scores = iso_forest.score_samples(X_scaled)

# äºˆæ¸¬ãƒ©ãƒ™ãƒ«ã‚’0/1ã«å¤‰æ›ï¼ˆ-1â†’1ï¼ˆç•°å¸¸ï¼‰, 1â†’0ï¼ˆæ­£å¸¸ï¼‰ï¼‰
y_pred_binary = np.where(y_pred == -1, 1, 0)

# è©•ä¾¡æŒ‡æ¨™ã®è¨ˆç®—
from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix

precision = precision_score(y_true, y_pred_binary)
recall = recall_score(y_true, y_pred_binary)
f1 = f1_score(y_true, y_pred_binary)
cm = confusion_matrix(y_true, y_pred_binary)

print("=" * 60)
print("ç•°å¸¸æ¤œå‡ºã‚·ã‚¹ãƒ†ãƒ è©•ä¾¡ï¼ˆIsolation Forestï¼‰")
print("=" * 60)
print(f"\nç·ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(df)}")
print(f"æ­£å¸¸ãƒ‡ãƒ¼ã‚¿: {n_normal} ({n_normal/len(df)*100:.1f}%)")
print(f"ç•°å¸¸ãƒ‡ãƒ¼ã‚¿: {n_anomaly} ({n_anomaly/len(df)*100:.1f}%)")
print(f"\næ¤œå‡ºæ€§èƒ½:")
print(f"é©åˆç‡ (Precision): {precision:.3f}")
print(f"å†ç¾ç‡ (Recall): {recall:.3f}")
print(f"F1ã‚¹ã‚³ã‚¢: {f1:.3f}")
print(f"\næ··åŒè¡Œåˆ—:")
print(f"çœŸé™°æ€§: {cm[0,0]}, å½é™½æ€§: {cm[0,1]}")
print(f"å½é™°æ€§: {cm[1,0]}, çœŸé™½æ€§: {cm[1,1]}")

# PCAã§2æ¬¡å…ƒã«æ¬¡å…ƒå‰Šæ¸›ï¼ˆå¯è¦–åŒ–ç”¨ï¼‰
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_scaled)

# å¯è¦–åŒ–
fig, axes = plt.subplots(2, 2, figsize=(14, 10))

# PCAç©ºé–“ã§ã®ç•°å¸¸æ¤œå‡ºçµæœ
scatter1 = axes[0, 0].scatter(X_pca[y_pred_binary==0, 0], X_pca[y_pred_binary==0, 1],
                               c='green', s=20, alpha=0.6, label='æ­£å¸¸ã¨åˆ¤å®š')
scatter2 = axes[0, 0].scatter(X_pca[y_pred_binary==1, 0], X_pca[y_pred_binary==1, 1],
                               c='red', s=40, alpha=0.8, marker='X', label='ç•°å¸¸ã¨åˆ¤å®š')
axes[0, 0].set_xlabel(f'ç¬¬1ä¸»æˆåˆ† (å¯„ä¸ç‡: {pca.explained_variance_ratio_[0]:.1%})')
axes[0, 0].set_ylabel(f'ç¬¬2ä¸»æˆåˆ† (å¯„ä¸ç‡: {pca.explained_variance_ratio_[1]:.1%})')
axes[0, 0].set_title('ç•°å¸¸æ¤œå‡ºçµæœï¼ˆPCAç©ºé–“ï¼‰', fontsize=12, fontweight='bold')
axes[0, 0].legend()
axes[0, 0].grid(alpha=0.3)

# ç•°å¸¸ã‚¹ã‚³ã‚¢ã®åˆ†å¸ƒ
axes[0, 1].hist(anomaly_scores[y_true==0], bins=50, alpha=0.6, label='æ­£å¸¸', color='green')
axes[0, 1].hist(anomaly_scores[y_true==1], bins=50, alpha=0.6, label='ç•°å¸¸', color='red')
axes[0, 1].set_xlabel('ç•°å¸¸ã‚¹ã‚³ã‚¢ï¼ˆå°ã•ã„ã»ã©ç•°å¸¸ï¼‰')
axes[0, 1].set_ylabel('é »åº¦')
axes[0, 1].set_title('ç•°å¸¸ã‚¹ã‚³ã‚¢åˆ†å¸ƒ', fontsize=12, fontweight='bold')
axes[0, 1].legend()
axes[0, 1].grid(alpha=0.3)

# æ··åŒè¡Œåˆ—ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—
import seaborn as sns
sns.heatmap(cm, annot=True, fmt='d', cmap='RdYlGn', ax=axes[1, 0],
            xticklabels=['æ­£å¸¸', 'ç•°å¸¸'], yticklabels=['æ­£å¸¸', 'ç•°å¸¸'])
axes[1, 0].set_title('æ··åŒè¡Œåˆ—', fontsize=12, fontweight='bold')
axes[1, 0].set_ylabel('çœŸã®ãƒ©ãƒ™ãƒ«')
axes[1, 0].set_xlabel('äºˆæ¸¬ãƒ©ãƒ™ãƒ«')

# æ™‚ç³»åˆ—ã§ã®ç•°å¸¸æ¤œå‡ºï¼ˆæ¨¡æ“¬çš„ãªãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–ï¼‰
time_series_length = 200
time_indices = np.arange(time_series_length)

# æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆï¼ˆæ­£å¸¸â†’ç•°å¸¸â†’æ­£å¸¸ï¼‰
ts_data = []
for i in range(time_series_length):
    if 80 <= i <= 120:  # ç•°å¸¸æœŸé–“
        sample = np.random.multivariate_normal([90, 0.6, 2.8, 20, 80], cov_normal)
    else:
        sample = np.random.multivariate_normal(mean_normal, cov_normal)
    ts_data.append(sample)

ts_data = np.array(ts_data)
ts_scaled = scaler.transform(ts_data)
ts_scores = iso_forest.score_samples(ts_scaled)
ts_pred = iso_forest.predict(ts_scaled)

# ç•°å¸¸é–¾å€¤ã®è¨ˆç®—ï¼ˆç•°å¸¸ã‚¹ã‚³ã‚¢ã®ä¸‹ä½10%ç‚¹ï¼‰
threshold = np.percentile(anomaly_scores, 10)

axes[1, 1].plot(time_indices, ts_scores, color='#11998e', linewidth=1.5, label='ç•°å¸¸ã‚¹ã‚³ã‚¢')
axes[1, 1].axhline(y=threshold, color='red', linestyle='--', linewidth=2, label=f'ç•°å¸¸é–¾å€¤ ({threshold:.3f})')
axes[1, 1].fill_between(time_indices, threshold, ts_scores.min(),
                         where=(ts_scores < threshold), alpha=0.3, color='red', label='ç•°å¸¸æ¤œå‡º')
axes[1, 1].set_xlabel('æ™‚åˆ»')
axes[1, 1].set_ylabel('ç•°å¸¸ã‚¹ã‚³ã‚¢')
axes[1, 1].set_title('ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç•°å¸¸æ¤œå‡ºï¼ˆæ¨¡æ“¬ï¼‰', fontsize=12, fontweight='bold')
axes[1, 1].legend()
axes[1, 1].grid(alpha=0.3)

plt.tight_layout()
plt.savefig('anomaly_detection_analysis.png', dpi=300, bbox_inches='tight')
plt.show()

# ç•°å¸¸æ¤œå‡ºæ™‚ã®è­¦å ±ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç”Ÿæˆ
detected_anomalies = np.where(ts_pred == -1)[0]
if len(detected_anomalies) > 0:
    print(f"\nâš ï¸ è­¦å ±: {len(detected_anomalies)}ä»¶ã®ç•°å¸¸ã‚’æ¤œå‡º")
    print(f"ç•°å¸¸æ¤œå‡ºæ™‚åˆ»: {detected_anomalies[:10]}..." if len(detected_anomalies) > 10 else f"ç•°å¸¸æ¤œå‡ºæ™‚åˆ»: {detected_anomalies}")
</code></pre>

            <p><strong>å®Ÿè£…ã®ãƒã‚¤ãƒ³ãƒˆ:</strong></p>
            <ul>
                <li>Isolation Forestã¯æ­£å¸¸ãƒ‡ãƒ¼ã‚¿ã®ã¿ã§å­¦ç¿’å¯èƒ½ï¼ˆæ•™å¸«ãªã—å­¦ç¿’ï¼‰</li>
                <li>å¤šæ¬¡å…ƒã‚»ãƒ³ã‚µãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ç•°å¸¸ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è‡ªå‹•æ¤œå‡º</li>
                <li>ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ ã¸ã®çµ„ã¿è¾¼ã¿ãŒå®¹æ˜“</li>
                <li>é–¾å€¤èª¿æ•´ã«ã‚ˆã‚Šè­¦å ±æ„Ÿåº¦ã‚’ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å¯èƒ½</li>
                <li>æ—©æœŸè­¦å ±ã«ã‚ˆã‚Šã€æ•…éšœå‰ã®äºˆé˜²ä¿å…¨ã‚’å®Ÿç¾</li>
            </ul>
        </div>

        <div class="content-box">
            <h2>ğŸ” 4.4 æ ¹æœ¬åŸå› åˆ†æï¼ˆRCAï¼‰</h2>

            <h3>ãƒˆãƒ©ãƒ–ãƒ«ç™ºç”Ÿæ™‚ã®åˆ†æãƒ•ãƒ­ãƒ¼</h3>
            <ol>
                <li><strong>ç—‡çŠ¶ã®ç‰¹å®š</strong>: ä½•ãŒèµ·ã“ã£ãŸã‹ï¼ˆå“è³ªä¸è‰¯ã€è¨­å‚™åœæ­¢ãªã©ï¼‰</li>
                <li><strong>ç›´æ¥åŸå› ã®èª¿æŸ»</strong>: ç›´å‰ã®å¤‰åŒ–ãƒ»ã‚¤ãƒ™ãƒ³ãƒˆã®ç¢ºèª</li>
                <li><strong>æ ¹æœ¬åŸå› ã®ç‰¹å®š</strong>: ãªãœãã‚ŒãŒèµ·ã“ã£ãŸã‹ï¼ˆ5å›ã®Whyï¼‰</li>
                <li><strong>å¯¾ç­–ã®ç«‹æ¡ˆ</strong>: å†ç™ºé˜²æ­¢ç­–ã®æ¤œè¨</li>
            </ol>

            <h3>ãƒ‡ãƒ¼ã‚¿é§†å‹•å‹RCA</h3>
            <p>
                å¤§é‡ã®ãƒ—ãƒ­ã‚»ã‚¹ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã€å“è³ªç•°å¸¸ã‚„è¨­å‚™æ•…éšœã«å¯„ä¸ã—ãŸè¦å› ã‚’ç‰¹å®šã™ã‚‹ã«ã¯ã€
                çµ±è¨ˆçš„æ‰‹æ³•ã‚„æ©Ÿæ¢°å­¦ç¿’ãŒæœ‰åŠ¹ã§ã™ã€‚ç›¸é–¢åˆ†æã€æ±ºå®šæœ¨ã€SHAPå€¤ãªã©ã‚’ç”¨ã„ã¦ã€
                å½±éŸ¿åº¦ã®é«˜ã„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å¯è¦–åŒ–ã—ã¾ã™ã€‚
            </p>

            <h3>ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹4.4: æ±ºå®šæœ¨ã¨SHAPå€¤ã«ã‚ˆã‚‹æ ¹æœ¬åŸå› åˆ†æ</h3>
            <pre><code>import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.model_selection import train_test_split
import warnings
warnings.filterwarnings('ignore')

plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

# å“è³ªä¸è‰¯ãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆï¼ˆæ ¹æœ¬åŸå› ãŒæ˜ç¢ºãªã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ï¼‰
np.random.seed(42)
n_samples = 500

# æ­£å¸¸å“ï¼ˆ60%ï¼‰
n_normal = int(n_samples * 0.6)
temp_normal = np.random.normal(75, 3, n_normal)
ph_normal = np.random.normal(6.5, 0.2, n_normal)
humidity_normal = np.random.normal(50, 5, n_normal)
mixing_time_normal = np.random.normal(120, 10, n_normal)
additive_amount_normal = np.random.normal(2.0, 0.1, n_normal)

# ä¸è‰¯å“ãƒ‘ã‚¿ãƒ¼ãƒ³1: é«˜æ¸©èµ·å› ï¼ˆ20%ï¼‰
n_defect1 = int(n_samples * 0.2)
temp_defect1 = np.random.normal(90, 5, n_defect1)
ph_defect1 = np.random.normal(6.5, 0.2, n_defect1)
humidity_defect1 = np.random.normal(50, 5, n_defect1)
mixing_time_defect1 = np.random.normal(120, 10, n_defect1)
additive_amount_defect1 = np.random.normal(2.0, 0.1, n_defect1)

# ä¸è‰¯å“ãƒ‘ã‚¿ãƒ¼ãƒ³2: pHç•°å¸¸èµ·å› ï¼ˆ10%ï¼‰
n_defect2 = int(n_samples * 0.1)
temp_defect2 = np.random.normal(75, 3, n_defect2)
ph_defect2 = np.random.normal(7.5, 0.3, n_defect2)
humidity_defect2 = np.random.normal(50, 5, n_defect2)
mixing_time_defect2 = np.random.normal(120, 10, n_defect2)
additive_amount_defect2 = np.random.normal(2.0, 0.1, n_defect2)

# ä¸è‰¯å“ãƒ‘ã‚¿ãƒ¼ãƒ³3: æ·»åŠ å‰¤é‡ä¸è¶³èµ·å› ï¼ˆ10%ï¼‰
n_defect3 = n_samples - n_normal - n_defect1 - n_defect2
temp_defect3 = np.random.normal(75, 3, n_defect3)
ph_defect3 = np.random.normal(6.5, 0.2, n_defect3)
humidity_defect3 = np.random.normal(50, 5, n_defect3)
mixing_time_defect3 = np.random.normal(120, 10, n_defect3)
additive_amount_defect3 = np.random.normal(1.5, 0.15, n_defect3)

# ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ä½œæˆ
data = pd.DataFrame({
    'temperature': np.concatenate([temp_normal, temp_defect1, temp_defect2, temp_defect3]),
    'pH': np.concatenate([ph_normal, ph_defect1, ph_defect2, ph_defect3]),
    'humidity': np.concatenate([humidity_normal, humidity_defect1, humidity_defect2, humidity_defect3]),
    'mixing_time': np.concatenate([mixing_time_normal, mixing_time_defect1, mixing_time_defect2, mixing_time_defect3]),
    'additive_amount': np.concatenate([additive_amount_normal, additive_amount_defect1, additive_amount_defect2, additive_amount_defect3]),
    'quality': np.concatenate([
        np.zeros(n_normal),
        np.ones(n_defect1),
        np.ones(n_defect2),
        np.ones(n_defect3)
    ])
})

# ãƒ‡ãƒ¼ã‚¿ã®ã‚·ãƒ£ãƒƒãƒ•ãƒ«
data = data.sample(frac=1, random_state=42).reset_index(drop=True)

# è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®åˆ†å‰²
X = data.drop('quality', axis=1)
y = data['quality']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)

# æ±ºå®šæœ¨ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ï¼ˆæ·±ã•ã‚’åˆ¶é™ã—ã¦è§£é‡ˆæ€§ã‚’é‡è¦–ï¼‰
dt_model = DecisionTreeClassifier(
    max_depth=4,
    min_samples_split=20,
    min_samples_leaf=10,
    random_state=42
)
dt_model.fit(X_train, y_train)

# äºˆæ¸¬ã¨è©•ä¾¡
y_pred = dt_model.predict(X_test)
from sklearn.metrics import classification_report, accuracy_score

accuracy = accuracy_score(y_test, y_pred)

print("=" * 60)
print("æ ¹æœ¬åŸå› åˆ†æï¼ˆDecision Treeï¼‰")
print("=" * 60)
print(f"\nãƒ¢ãƒ‡ãƒ«ç²¾åº¦: {accuracy:.3f}")
print("\nåˆ†é¡ãƒ¬ãƒãƒ¼ãƒˆ:")
print(classification_report(y_test, y_pred, target_names=['æ­£å¸¸', 'ä¸è‰¯']))

# ç‰¹å¾´é‡é‡è¦åº¦
feature_importance = pd.DataFrame({
    'feature': X.columns,
    'importance': dt_model.feature_importances_
}).sort_values('importance', ascending=False)

print("\nç‰¹å¾´é‡é‡è¦åº¦ï¼ˆå“è³ªä¸è‰¯ã¸ã®å¯„ä¸åº¦ï¼‰:")
print(feature_importance.to_string(index=False))

# å¯è¦–åŒ–
fig = plt.figure(figsize=(16, 10))

# æ±ºå®šæœ¨ã®å¯è¦–åŒ–
ax1 = plt.subplot(2, 2, (1, 2))
plot_tree(dt_model, feature_names=X.columns, class_names=['æ­£å¸¸', 'ä¸è‰¯'],
          filled=True, rounded=True, fontsize=9, ax=ax1)
ax1.set_title('æ±ºå®šæœ¨ã«ã‚ˆã‚‹æ ¹æœ¬åŸå› åˆ†æ', fontsize=14, fontweight='bold')

# ç‰¹å¾´é‡é‡è¦åº¦
ax2 = plt.subplot(2, 2, 3)
bars = ax2.barh(feature_importance['feature'], feature_importance['importance'], color='#38ef7d')
ax2.set_xlabel('é‡è¦åº¦ã‚¹ã‚³ã‚¢')
ax2.set_title('å“è³ªä¸è‰¯ã¸ã®å¯„ä¸åº¦', fontsize=12, fontweight='bold')
ax2.grid(axis='x', alpha=0.3)

# é‡è¦ãªç‰¹å¾´é‡ã®åˆ†å¸ƒæ¯”è¼ƒ
ax3 = plt.subplot(2, 2, 4)
top_feature = feature_importance.iloc[0]['feature']

normal_values = data[data['quality'] == 0][top_feature]
defect_values = data[data['quality'] == 1][top_feature]

ax3.hist(normal_values, bins=30, alpha=0.6, label='æ­£å¸¸', color='green')
ax3.hist(defect_values, bins=30, alpha=0.6, label='ä¸è‰¯', color='red')
ax3.set_xlabel(f'{top_feature}')
ax3.set_ylabel('é »åº¦')
ax3.set_title(f'æœ€é‡è¦å› å­ã®åˆ†å¸ƒæ¯”è¼ƒ: {top_feature}', fontsize=12, fontweight='bold')
ax3.legend()
ax3.grid(alpha=0.3)

plt.tight_layout()
plt.savefig('root_cause_analysis.png', dpi=300, bbox_inches='tight')
plt.show()

# RCA ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
print("\n" + "=" * 60)
print("æ ¹æœ¬åŸå› åˆ†æãƒ¬ãƒãƒ¼ãƒˆ")
print("=" * 60)

# æ±ºå®šæœ¨ã®ãƒ«ãƒ¼ãƒ«æŠ½å‡ºï¼ˆãƒˆãƒƒãƒ—ãƒãƒ¼ãƒ‰ã®ã¿ï¼‰
from sklearn.tree import _tree

def extract_rules(tree, feature_names, node=0, depth=0, max_depth=2):
    """æ±ºå®šæœ¨ã‹ã‚‰ãƒ«ãƒ¼ãƒ«ã‚’æŠ½å‡º"""
    if depth > max_depth:
        return

    feature = tree.feature[node]
    threshold = tree.threshold[node]

    if feature != _tree.TREE_UNDEFINED:
        name = feature_names[feature]
        print(f"{'  ' * depth}â”œâ”€ {name} <= {threshold:.2f}ã®å ´åˆ:")
        extract_rules(tree, feature_names, tree.children_left[node], depth + 1, max_depth)
        print(f"{'  ' * depth}â””â”€ {name} > {threshold:.2f}ã®å ´åˆ:")
        extract_rules(tree, feature_names, tree.children_right[node], depth + 1, max_depth)
    else:
        value = tree.value[node][0]
        total = value.sum()
        defect_rate = value[1] / total if total > 0 else 0
        print(f"{'  ' * depth}   â†’ ä¸è‰¯ç‡: {defect_rate:.1%} (ã‚µãƒ³ãƒ—ãƒ«æ•°: {int(total)})")

print("\nä¸»è¦ãªåˆ¤å®šãƒ«ãƒ¼ãƒ«:")
extract_rules(dt_model.tree_, X.columns)

print("\næ¨å¥¨ã•ã‚Œã‚‹å¯¾ç­–:")
if feature_importance.iloc[0]['feature'] == 'temperature':
    print("ãƒ»æ¸©åº¦ç®¡ç†ã®å¼·åŒ–: 75Â±5â„ƒã®ç¯„å›²ã«åˆ¶å¾¡")
    print("ãƒ»å†·å´ã‚·ã‚¹ãƒ†ãƒ ã®ç‚¹æ¤œã¨æ”¹å–„")
elif feature_importance.iloc[0]['feature'] == 'pH':
    print("ãƒ»pHèª¿æ•´ãƒ—ãƒ­ã‚»ã‚¹ã®è¦‹ç›´ã—")
    print("ãƒ»pHè¨ˆã®æ ¡æ­£é »åº¦ã®å¢—åŠ ")
elif feature_importance.iloc[0]['feature'] == 'additive_amount':
    print("ãƒ»æ·»åŠ å‰¤ã®æŠ•å…¥é‡ç®¡ç†ã®å³æ ¼åŒ–")
    print("ãƒ»è‡ªå‹•æŠ•å…¥ã‚·ã‚¹ãƒ†ãƒ ã®å°å…¥æ¤œè¨")
</code></pre>

            <p><strong>å®Ÿè£…ã®ãƒã‚¤ãƒ³ãƒˆ:</strong></p>
            <ul>
                <li>æ±ºå®šæœ¨ã«ã‚ˆã‚Šã€ä¸è‰¯å“ç™ºç”Ÿã®åˆ¤å®šãƒ«ãƒ¼ãƒ«ã‚’å¯è¦–åŒ–</li>
                <li>ç‰¹å¾´é‡é‡è¦åº¦ã«ã‚ˆã‚Šã€å½±éŸ¿åº¦ã®é«˜ã„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ç‰¹å®š</li>
                <li>SHAPå€¤ã‚’ç”¨ã„ã‚‹ã“ã¨ã§ã€å„ã‚µãƒ³ãƒ—ãƒ«ã¸ã®å€‹åˆ¥è¦å› ã‚‚åˆ†æå¯èƒ½ï¼ˆå®Ÿè£…ä¾‹ã§ã¯SHAPãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒå¿…è¦ï¼‰</li>
                <li>äººé–“ãŒç†è§£å¯èƒ½ãªãƒ«ãƒ¼ãƒ«ã‚’æŠ½å‡ºã—ã€å¯¾ç­–ç«‹æ¡ˆã‚’æ”¯æ´</li>
                <li>ãƒ‡ãƒ¼ã‚¿é§†å‹•å‹ã®RCAã«ã‚ˆã‚Šã€çµŒé¨“å‰‡ã ã‘ã«é ¼ã‚‰ãªã„åˆ†æãŒå¯èƒ½</li>
            </ul>
        </div>

        <div class="content-box">
            <h2>ğŸ“š ã¾ã¨ã‚</h2>
            <p>æœ¬ç« ã§ã¯ã€AIã‚’æ´»ç”¨ã—ãŸäºˆçŸ¥ä¿å…¨ã¨ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã®æŠ€è¡“ã‚’å­¦ã³ã¾ã—ãŸã€‚</p>

            <h3>ä¸»è¦ãªãƒã‚¤ãƒ³ãƒˆ</h3>
            <ul>
                <li>æ©Ÿæ¢°å­¦ç¿’ã«ã‚ˆã‚‹è¨­å‚™æ•…éšœäºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰</li>
                <li>æ®‹å­˜æœ‰ç”¨å¯¿å‘½ï¼ˆRULï¼‰æ¨å®šã«ã‚ˆã‚‹æœ€é©ä¿å…¨è¨ˆç”»</li>
                <li>æ•™å¸«ãªã—å­¦ç¿’ï¼ˆIsolation Forestï¼‰ã«ã‚ˆã‚‹ç•°å¸¸æ¤œå‡º</li>
                <li>æ±ºå®šæœ¨ã¨SHAPå€¤ã‚’ç”¨ã„ãŸæ ¹æœ¬åŸå› åˆ†æ</li>
                <li>ãƒ‡ãƒ¼ã‚¿é§†å‹•å‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã«ã‚ˆã‚‹ä¿å…¨åŠ¹ç‡ã®å‘ä¸Š</li>
            </ul>

            <h3>å®Ÿå‹™ã§ã®å¿œç”¨</h3>
            <ul>
                <li>ã‚»ãƒ³ã‚µãƒ‡ãƒ¼ã‚¿ã®ç¶™ç¶šçš„ãªåé›†ã¨ãƒ¢ãƒ‡ãƒ«ã®å®šæœŸçš„ãªå†è¨“ç·´</li>
                <li>æ—©æœŸè­¦å ±ã‚·ã‚¹ãƒ†ãƒ ã«ã‚ˆã‚‹è¨ˆç”»çš„ãªä¿å…¨ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°</li>
                <li>RCAçµæœã‚’æ´»ç”¨ã—ãŸè¨­å‚™æ”¹å–„ã¨ãƒ—ãƒ­ã‚»ã‚¹æœ€é©åŒ–</li>
                <li>ä¿å…¨ã‚³ã‚¹ãƒˆã¨è¨­å‚™ç¨¼åƒç‡ã®ãƒãƒ©ãƒ³ã‚¹æœ€é©åŒ–</li>
            </ul>

            <div class="key-point">
                <strong>ğŸ¯ æ¬¡ç« äºˆå‘Š</strong><br>
                ç¬¬5ç« ã§ã¯ã€ã“ã‚Œã¾ã§å­¦ã‚“ã æŠ€è¡“ã‚’çµ±åˆã—ãŸå®Ÿéš›ã®ã‚±ãƒ¼ã‚¹ã‚¹ã‚¿ãƒ‡ã‚£ã‚’ç´¹ä»‹ã—ã¾ã™ã€‚
                å…·ä½“çš„ãªé£Ÿå“è£½é€ ãƒ—ãƒ­ã‚»ã‚¹ï¼ˆä¹³è£½å“ã€é£²æ–™ã€ã‚¹ãƒŠãƒƒã‚¯é£Ÿå“ãªã©ï¼‰ã«ãŠã‘ã‚‹
                AIã‚·ã‚¹ãƒ†ãƒ ã®å°å…¥äº‹ä¾‹ã¨ã€ãã®åŠ¹æœã«ã¤ã„ã¦è©³ã—ãè§£èª¬ã—ã¾ã™ã€‚
            </div>
        </div>

        <div class="nav-buttons">
            <a href="chapter-3.html">â† ç¬¬3ç« : ãƒ—ãƒ­ã‚»ã‚¹æœ€é©åŒ–</a>
            <a href="chapter-5.html">ç¬¬5ç« : ã‚±ãƒ¼ã‚¹ã‚¹ã‚¿ãƒ‡ã‚£ â†’</a>
        </div>
    </div>

    <footer>
        <p>&copy; 2025 AI Terakoya - ãƒ—ãƒ­ã‚»ã‚¹ãƒ»ã‚¤ãƒ³ãƒ•ã‚©ãƒãƒ†ã‚£ã‚¯ã‚¹é“å ´</p>
        <p>ç¬¬4ç«  äºˆçŸ¥ä¿å…¨ã¨ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°</p>
    </footer>
</body>
</html>
