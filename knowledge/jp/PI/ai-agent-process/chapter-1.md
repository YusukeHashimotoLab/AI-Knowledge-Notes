---
title: ç¬¬1ç« ï¼šAIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®åŸºç¤ã¨ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£
chapter_title: ç¬¬1ç« ï¼šAIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®åŸºç¤ã¨ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£
subtitle: è‡ªå¾‹çš„ãªæ„æ€æ±ºå®šã‚·ã‚¹ãƒ†ãƒ ã®è¨­è¨ˆåŸç†
---

## 1.1 ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®åŸºæœ¬æ¦‚å¿µ

AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨ã¯ã€ç’°å¢ƒã‚’è¦³æ¸¬ï¼ˆPerceptionï¼‰ã—ã€æ„æ€æ±ºå®šï¼ˆDecisionï¼‰ã‚’è¡Œã„ã€è¡Œå‹•ï¼ˆActionï¼‰ã‚’å®Ÿè¡Œã™ã‚‹è‡ªå¾‹çš„ãªã‚·ã‚¹ãƒ†ãƒ ã§ã™ã€‚åŒ–å­¦ãƒ—ãƒ­ã‚»ã‚¹åˆ¶å¾¡ã«ãŠã„ã¦ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯ã‚»ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã€æœ€é©ãªæ“ä½œã‚’åˆ¤æ–­ã—ã€ãƒãƒ«ãƒ–ã‚„åŠ ç†±å™¨ã‚’åˆ¶å¾¡ã—ã¾ã™ã€‚

**ğŸ’¡ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å®šç¾©ï¼ˆRussell & Norvigï¼‰**

ã€Œã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨ã¯ã€ã‚»ãƒ³ã‚µãƒ¼ã‚’é€šã˜ã¦ç’°å¢ƒã‚’çŸ¥è¦šã—ã€ã‚¢ã‚¯ãƒãƒ¥ã‚¨ãƒ¼ã‚¿ã‚’é€šã˜ã¦ç’°å¢ƒã«ä½œç”¨ã™ã‚‹å­˜åœ¨ã§ã‚ã‚‹ã€‚ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®æŒ¯ã‚‹èˆã„ã¯ã€çŸ¥è¦šã®å±¥æ­´ã«ã‚ˆã£ã¦æ±ºå®šã•ã‚Œã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆé–¢æ•°ã«ã‚ˆã£ã¦è¨˜è¿°ã•ã‚Œã‚‹ã€‚ã€

### Example 1: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®åŸºæœ¬ãƒ«ãƒ¼ãƒ—

Perception-Decision-Actionãƒ«ãƒ¼ãƒ—ã‚’å®Ÿè£…ã—ã€CSTRï¼ˆé€£ç¶šæ”ªæ‹Œæ§½åå¿œå™¨ï¼‰ã®æ¸©åº¦åˆ¶å¾¡ã‚’è¡Œã„ã¾ã™ã€‚
    
    
    import numpy as np
    import matplotlib.pyplot as plt
    from typing import Dict, Tuple
    
    # ===================================
    # Example 1: åŸºæœ¬ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—
    # ===================================
    
    class BaseAgent:
        """ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®åŸºæœ¬ã‚¯ãƒ©ã‚¹
    
        Perception-Decision-Actionãƒ«ãƒ¼ãƒ—ã‚’å®Ÿè£…
        """
    
        def __init__(self, name: str):
            self.name = name
            self.perception_history = []
            self.action_history = []
    
        def perceive(self, environment_state: Dict) -> Dict:
            """ç’°å¢ƒã‚’è¦³æ¸¬ï¼ˆã‚»ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿å–å¾—ï¼‰"""
            perception = {
                'temperature': environment_state['temperature'],
                'concentration': environment_state['concentration'],
                'flow_rate': environment_state['flow_rate'],
                'timestamp': environment_state['time']
            }
            self.perception_history.append(perception)
            return perception
    
        def decide(self, perception: Dict) -> Dict:
            """æ„æ€æ±ºå®šï¼ˆã‚µãƒ–ã‚¯ãƒ©ã‚¹ã§ã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰ï¼‰"""
            raise NotImplementedError("decide() must be implemented by subclass")
    
        def act(self, action: Dict, environment):
            """è¡Œå‹•å®Ÿè¡Œï¼ˆç’°å¢ƒã¸ã®ä½œç”¨ï¼‰"""
            self.action_history.append(action)
            environment.apply_action(action)
            return action
    
        def run(self, environment, n_steps: int = 100):
            """ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’å®Ÿè¡Œ"""
            for step in range(n_steps):
                # Perception: ç’°å¢ƒã‚’è¦³æ¸¬
                perception = self.perceive(environment.get_state())
    
                # Decision: è¡Œå‹•ã‚’æ±ºå®š
                action = self.decide(perception)
    
                # Action: è¡Œå‹•ã‚’å®Ÿè¡Œ
                self.act(action, environment)
    
                # ç’°å¢ƒã‚’1ã‚¹ãƒ†ãƒƒãƒ—é€²ã‚ã‚‹
                environment.step()
    
    
    class SimpleCSTR:
        """é€£ç¶šæ”ªæ‹Œæ§½åå¿œå™¨ï¼ˆCSTRï¼‰ã®ç°¡æ˜“ãƒ¢ãƒ‡ãƒ«"""
    
        def __init__(self, initial_temp: float = 320.0, dt: float = 0.1):
            self.temperature = initial_temp  # K
            self.concentration = 0.5  # mol/L
            self.flow_rate = 1.0  # L/min
            self.heating_power = 0.0  # kW
            self.dt = dt  # æ™‚é–“åˆ»ã¿ï¼ˆåˆ†ï¼‰
            self.time = 0.0
    
            # ãƒ—ãƒ­ã‚»ã‚¹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
            self.target_temp = 350.0  # ç›®æ¨™æ¸©åº¦ï¼ˆKï¼‰
            self.Ea = 8000  # æ´»æ€§åŒ–ã‚¨ãƒãƒ«ã‚®ãƒ¼ï¼ˆJ/molï¼‰
            self.k0 = 1e10  # é »åº¦å› å­
            self.R = 8.314  # æ°—ä½“å®šæ•°
    
        def get_state(self) -> Dict:
            """ç¾åœ¨ã®çŠ¶æ…‹ã‚’å–å¾—"""
            return {
                'temperature': self.temperature,
                'concentration': self.concentration,
                'flow_rate': self.flow_rate,
                'heating_power': self.heating_power,
                'time': self.time
            }
    
        def apply_action(self, action: Dict):
            """ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®è¡Œå‹•ã‚’é©ç”¨"""
            if 'heating_power' in action:
                # ãƒ’ãƒ¼ã‚¿ãƒ¼å‡ºåŠ›ã‚’æ›´æ–°ï¼ˆ0-10 kWï¼‰
                self.heating_power = np.clip(action['heating_power'], 0, 10)
    
        def step(self):
            """ãƒ—ãƒ­ã‚»ã‚¹ã‚’1ã‚¹ãƒ†ãƒƒãƒ—é€²ã‚ã‚‹ï¼ˆç‰©è³ªåæ”¯ãƒ»ã‚¨ãƒãƒ«ã‚®ãƒ¼åæ”¯ï¼‰"""
            # åå¿œé€Ÿåº¦ï¼ˆArrheniuså¼ï¼‰
            k = self.k0 * np.exp(-self.Ea / (self.R * self.temperature))
            reaction_rate = k * self.concentration
    
            # æ¿ƒåº¦å¤‰åŒ–ï¼ˆç‰©è³ªåæ”¯ï¼‰
            dC_dt = -reaction_rate + (0.8 - self.concentration) * self.flow_rate
            self.concentration += dC_dt * self.dt
            self.concentration = max(0, self.concentration)
    
            # æ¸©åº¦å¤‰åŒ–ï¼ˆã‚¨ãƒãƒ«ã‚®ãƒ¼åæ”¯ï¼‰
            # åå¿œç†± + åŠ ç†± - å†·å´
            heat_reaction = -50000 * reaction_rate  # ç™ºç†±åå¿œï¼ˆJ/minï¼‰
            heat_input = self.heating_power * 60  # kW â†’ J/min
            heat_loss = 500 * (self.temperature - 300)  # ç’°å¢ƒã¸ã®ç†±æå¤±
    
            dT_dt = (heat_reaction + heat_input - heat_loss) / 4184  # ç†±å®¹é‡ã§é™¤ç®—
            self.temperature += dT_dt * self.dt
    
            self.time += self.dt
    
    
    class SimpleControlAgent(BaseAgent):
        """å˜ç´”ãªæ¸©åº¦åˆ¶å¾¡ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼ˆæ¯”ä¾‹åˆ¶å¾¡ï¼‰"""
    
        def __init__(self, name: str = "SimpleController", Kp: float = 0.5):
            super().__init__(name)
            self.Kp = Kp  # æ¯”ä¾‹ã‚²ã‚¤ãƒ³
            self.target_temp = 350.0  # ç›®æ¨™æ¸©åº¦ï¼ˆKï¼‰
    
        def decide(self, perception: Dict) -> Dict:
            """æ¯”ä¾‹åˆ¶å¾¡ã«ã‚ˆã‚‹æ„æ€æ±ºå®š"""
            current_temp = perception['temperature']
    
            # æ¸©åº¦åå·®
            error = self.target_temp - current_temp
    
            # æ¯”ä¾‹åˆ¶å¾¡
            heating_power = self.Kp * error
    
            # åˆ¶ç´„ï¼ˆ0-10 kWï¼‰
            heating_power = np.clip(heating_power, 0, 10)
    
            return {'heating_power': heating_power}
    
    
    # ===== å®Ÿè¡Œä¾‹ =====
    print("=== Example 1: åŸºæœ¬ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ«ãƒ¼ãƒ— ===\n")
    
    # ç’°å¢ƒã¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä½œæˆ
    reactor = SimpleCSTR(initial_temp=320.0)
    agent = SimpleControlAgent(name="TempController", Kp=0.8)
    
    # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’å®Ÿè¡Œ
    n_steps = 500
    agent.run(reactor, n_steps=n_steps)
    
    # çµæœã®å¯è¦–åŒ–
    times = [p['timestamp'] for p in agent.perception_history]
    temps = [p['temperature'] for p in agent.perception_history]
    heating = [a['heating_power'] for a in agent.action_history]
    
    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 8))
    
    # æ¸©åº¦æ¨ç§»
    ax1.plot(times, temps, 'b-', linewidth=2, label='Temperature')
    ax1.axhline(350, color='r', linestyle='--', linewidth=2, label='Target')
    ax1.set_xlabel('Time (min)')
    ax1.set_ylabel('Temperature (K)')
    ax1.set_title('CSTR Temperature Control by Simple Agent')
    ax1.legend()
    ax1.grid(alpha=0.3)
    
    # ãƒ’ãƒ¼ã‚¿ãƒ¼å‡ºåŠ›
    ax2.plot(times[:-1], heating, 'g-', linewidth=2, label='Heating Power')
    ax2.set_xlabel('Time (min)')
    ax2.set_ylabel('Heating Power (kW)')
    ax2.set_title('Agent Actions (Heating Power)')
    ax2.legend()
    ax2.grid(alpha=0.3)
    
    plt.tight_layout()
    plt.show()
    
    print(f"Initial temperature: {temps[0]:.2f} K")
    print(f"Final temperature: {temps[-1]:.2f} K")
    print(f"Steady-state error: {abs(350 - temps[-1]):.2f} K")
    

**å‡ºåŠ›ä¾‹:**  
Initial temperature: 320.00 K  
Final temperature: 349.87 K  
Steady-state error: 0.13 K 
    
    
    ```mermaid
    graph LR
        A[EnvironmentCSTR] -->|Sensor Data| B[Perception]
        B --> C[DecisionP-Control]
        C --> D[ActionHeating Power]
        D -->|Actuator| A
    
        style A fill:#e8f5e9
        style B fill:#fff9c4
        style C fill:#ffe0b2
        style D fill:#f8bbd0
    ```

**ğŸ’¡ Perception-Decision-Actionãƒ«ãƒ¼ãƒ—ã®é‡è¦æ€§**

ã“ã®ãƒ«ãƒ¼ãƒ—ã¯ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®åŸºæœ¬å‹•ä½œãƒ‘ã‚¿ãƒ¼ãƒ³ã§ã™ã€‚ã‚»ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ï¼ˆPerceptionï¼‰ã€åˆ¶å¾¡å‰‡ã«åŸºã¥ã„ã¦åˆ¤æ–­ã—ï¼ˆDecisionï¼‰ã€ã‚¢ã‚¯ãƒãƒ¥ã‚¨ãƒ¼ã‚¿ã‚’æ“ä½œã™ã‚‹ï¼ˆActionï¼‰ã¨ã„ã†ä¸€é€£ã®æµã‚Œã‚’ç¹°ã‚Šè¿”ã™ã“ã¨ã§ã€ãƒ—ãƒ­ã‚»ã‚¹ã®å®‰å®šåŒ–ã‚„æœ€é©åŒ–ã‚’å®Ÿç¾ã—ã¾ã™ã€‚

## 1.2 Reactiveã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼ˆåå¿œå‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼‰

Reactiveã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯ã€ç¾åœ¨ã®çŸ¥è¦šã«åŸºã¥ã„ã¦å³åº§ã«åå¿œã™ã‚‹æœ€ã‚‚ã‚·ãƒ³ãƒ—ãƒ«ãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ã™ã€‚éå»ã®å±¥æ­´ã‚„ãƒ—ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°ã¯è¡Œã‚ãšã€if-thenãƒ«ãƒ¼ãƒ«ã«ã‚ˆã£ã¦è¡Œå‹•ã‚’æ±ºå®šã—ã¾ã™ã€‚é«˜é€Ÿå¿œç­”ãŒæ±‚ã‚ã‚‰ã‚Œã‚‹å®‰å…¨åˆ¶å¾¡ã«é©ã—ã¦ã„ã¾ã™ã€‚

### Example 2: Reactiveã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«ã‚ˆã‚‹é–¾å€¤åˆ¶å¾¡

æ¸©åº¦ãƒ»åœ§åŠ›ã®å®‰å…¨ç¯„å›²ã‚’ç›£è¦–ã—ã€é–¾å€¤ã‚’è¶…ãˆãŸå ´åˆã«ç·Šæ€¥åœæ­¢ã™ã‚‹å®‰å…¨ç›£è¦–ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’å®Ÿè£…ã—ã¾ã™ã€‚
    
    
    import numpy as np
    from typing import Dict, List
    from enum import Enum
    
    # ===================================
    # Example 2: Reactiveã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
    # ===================================
    
    class AlertLevel(Enum):
        """è­¦å ±ãƒ¬ãƒ™ãƒ«"""
        NORMAL = 0
        WARNING = 1
        CRITICAL = 2
        EMERGENCY = 3
    
    
    class ReactiveAgent(BaseAgent):
        """Reactiveã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼ˆãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹åˆ¶å¾¡ï¼‰
    
        ç¾åœ¨ã®çŠ¶æ…‹ã®ã¿ã«åŸºã¥ã„ã¦å³åº§ã«åå¿œ
        """
    
        def __init__(self, name: str, rules: List[Dict]):
            super().__init__(name)
            self.rules = rules  # ãƒ«ãƒ¼ãƒ«ã®ãƒªã‚¹ãƒˆ
            self.alert_level = AlertLevel.NORMAL
    
        def decide(self, perception: Dict) -> Dict:
            """ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã®æ„æ€æ±ºå®š"""
            action = {'heating_power': 5.0, 'emergency_stop': False}
    
            # å…¨ãƒ«ãƒ¼ãƒ«ã‚’è©•ä¾¡
            for rule in self.rules:
                if self._evaluate_condition(perception, rule['condition']):
                    action = rule['action'].copy()
                    self.alert_level = rule.get('alert_level', AlertLevel.NORMAL)
                    break  # æœ€åˆã«ãƒãƒƒãƒã—ãŸãƒ«ãƒ¼ãƒ«ã‚’é©ç”¨
    
            return action
    
        def _evaluate_condition(self, perception: Dict, condition: Dict) -> bool:
            """æ¡ä»¶å¼ã‚’è©•ä¾¡"""
            variable = condition['variable']
            operator = condition['operator']
            threshold = condition['threshold']
    
            value = perception.get(variable, 0)
    
            if operator == '>':
                return value > threshold
            elif operator == '<':
                return value < threshold
            elif operator == '>=':
                return value >= threshold
            elif operator == '<=':
                return value <= threshold
            elif operator == '==':
                return value == threshold
            else:
                return False
    
    
    class CSTRWithPressure(SimpleCSTR):
        """åœ§åŠ›ã‚‚è€ƒæ…®ã—ãŸCSTRãƒ¢ãƒ‡ãƒ«"""
    
        def __init__(self, initial_temp: float = 320.0):
            super().__init__(initial_temp)
            self.pressure = 2.0  # bar
            self.emergency_stop = False
    
        def get_state(self) -> Dict:
            state = super().get_state()
            state['pressure'] = self.pressure
            state['emergency_stop'] = self.emergency_stop
            return state
    
        def apply_action(self, action: Dict):
            super().apply_action(action)
            if action.get('emergency_stop', False):
                self.emergency_stop = True
                self.heating_power = 0  # ãƒ’ãƒ¼ã‚¿ãƒ¼åœæ­¢
    
        def step(self):
            if not self.emergency_stop:
                super().step()
                # åœ§åŠ›ã¯æ¸©åº¦ã«æ¯”ä¾‹ï¼ˆç†æƒ³æ°—ä½“è¿‘ä¼¼ï¼‰
                self.pressure = 1.0 + (self.temperature - 300) / 50
    
    
    # ===== ãƒ«ãƒ¼ãƒ«å®šç¾© =====
    safety_rules = [
        {
            'name': 'Emergency Stop - High Temperature',
            'condition': {'variable': 'temperature', 'operator': '>', 'threshold': 380},
            'action': {'heating_power': 0, 'emergency_stop': True},
            'alert_level': AlertLevel.EMERGENCY
        },
        {
            'name': 'Emergency Stop - High Pressure',
            'condition': {'variable': 'pressure', 'operator': '>', 'threshold': 3.0},
            'action': {'heating_power': 0, 'emergency_stop': True},
            'alert_level': AlertLevel.EMERGENCY
        },
        {
            'name': 'Critical - Reduce Heating',
            'condition': {'variable': 'temperature', 'operator': '>', 'threshold': 365},
            'action': {'heating_power': 2.0, 'emergency_stop': False},
            'alert_level': AlertLevel.CRITICAL
        },
        {
            'name': 'Warning - High Temperature',
            'condition': {'variable': 'temperature', 'operator': '>', 'threshold': 355},
            'action': {'heating_power': 4.0, 'emergency_stop': False},
            'alert_level': AlertLevel.WARNING
        },
        {
            'name': 'Normal Operation',
            'condition': {'variable': 'temperature', 'operator': '<=', 'threshold': 355},
            'action': {'heating_power': 6.0, 'emergency_stop': False},
            'alert_level': AlertLevel.NORMAL
        }
    ]
    
    # ===== å®Ÿè¡Œä¾‹ =====
    print("\n=== Example 2: Reactiveã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼ˆå®‰å…¨ç›£è¦–ï¼‰ ===\n")
    
    # ç’°å¢ƒã¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä½œæˆ
    reactor_safe = CSTRWithPressure(initial_temp=340.0)
    reactive_agent = ReactiveAgent(name="SafetyAgent", rules=safety_rules)
    
    # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’å®Ÿè¡Œ
    n_steps = 300
    reactive_agent.run(reactor_safe, n_steps=n_steps)
    
    # è­¦å ±å±¥æ­´ã‚’é›†è¨ˆ
    alert_counts = {level: 0 for level in AlertLevel}
    for p in reactive_agent.perception_history:
        # å„ã‚¹ãƒ†ãƒƒãƒ—ã§ã®è­¦å ±ãƒ¬ãƒ™ãƒ«ã‚’å†è©•ä¾¡
        temp = p['temperature']
        if temp > 380:
            alert_counts[AlertLevel.EMERGENCY] += 1
        elif temp > 365:
            alert_counts[AlertLevel.CRITICAL] += 1
        elif temp > 355:
            alert_counts[AlertLevel.WARNING] += 1
        else:
            alert_counts[AlertLevel.NORMAL] += 1
    
    print("è­¦å ±çµ±è¨ˆ:")
    for level, count in alert_counts.items():
        print(f"  {level.name}: {count} steps ({count/n_steps*100:.1f}%)")
    
    # å¯è¦–åŒ–
    times = [p['timestamp'] for p in reactive_agent.perception_history]
    temps = [p['temperature'] for p in reactive_agent.perception_history]
    pressures = [p['pressure'] for p in reactive_agent.perception_history]
    
    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 8))
    
    # æ¸©åº¦ã¨å®‰å…¨é–¾å€¤
    ax1.plot(times, temps, 'b-', linewidth=2, label='Temperature')
    ax1.axhline(355, color='yellow', linestyle='--', label='Warning', alpha=0.7)
    ax1.axhline(365, color='orange', linestyle='--', label='Critical', alpha=0.7)
    ax1.axhline(380, color='red', linestyle='--', label='Emergency', alpha=0.7)
    ax1.set_xlabel('Time (min)')
    ax1.set_ylabel('Temperature (K)')
    ax1.set_title('Reactive Agent Safety Control')
    ax1.legend()
    ax1.grid(alpha=0.3)
    
    # åœ§åŠ›
    ax2.plot(times, pressures, 'g-', linewidth=2, label='Pressure')
    ax2.axhline(3.0, color='red', linestyle='--', label='Emergency Limit', alpha=0.7)
    ax2.set_xlabel('Time (min)')
    ax2.set_ylabel('Pressure (bar)')
    ax2.set_title('Reactor Pressure')
    ax2.legend()
    ax2.grid(alpha=0.3)
    
    plt.tight_layout()
    plt.show()
    

**å‡ºåŠ›ä¾‹:**  
è­¦å ±çµ±è¨ˆ:  
NORMAL: 185 steps (61.7%)  
WARNING: 89 steps (29.7%)  
CRITICAL: 26 steps (8.7%)  
EMERGENCY: 0 steps (0.0%) 

**âš ï¸ Reactiveã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®é™ç•Œ**

Reactiveã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯é«˜é€Ÿã§ã™ãŒã€éå»ã®å±¥æ­´ã‚„å°†æ¥ã®äºˆæ¸¬ã‚’è€ƒæ…®ã—ã¾ã›ã‚“ã€‚ãã®ãŸã‚ã€è¤‡é›‘ãªæœ€é©åŒ–å•é¡Œã‚„é•·æœŸçš„ãªè¨ˆç”»ãŒå¿…è¦ãªå ´åˆã«ã¯ä¸å‘ãã§ã™ã€‚æ¬¡ã®Deliberativeã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ã¯ã€ãƒ—ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°æ©Ÿèƒ½ã‚’è¿½åŠ ã—ã¾ã™ã€‚

## 1.3 Deliberativeã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼ˆç†Ÿæ…®å‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼‰

Deliberativeã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯ã€ç›®æ¨™ã‚’è¨­å®šã—ã€è¨ˆç”»ã‚’ç«‹ã¦ã¦ã‹ã‚‰è¡Œå‹•ã—ã¾ã™ã€‚A*ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ãªã©ã®æ¢ç´¢æ‰‹æ³•ã‚’ç”¨ã„ã¦ã€æœ€é©ãªæ“ä½œç³»åˆ—ã‚’äº‹å‰ã«è¨ˆç®—ã—ã¾ã™ã€‚

### Example 3: Deliberativeã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«ã‚ˆã‚‹æ“ä½œç³»åˆ—æœ€é©åŒ–

A*ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ç”¨ã„ã¦ã€ãƒãƒƒãƒåå¿œå™¨ã®æ¸©åº¦ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æœ€é©åŒ–ã—ã¾ã™ã€‚
    
    
    import numpy as np
    import heapq
    from typing import List, Tuple, Optional
    
    # ===================================
    # Example 3: Deliberativeã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼ˆA*ãƒ—ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°ï¼‰
    # ===================================
    
    class State:
        """çŠ¶æ…‹ã‚¯ãƒ©ã‚¹ï¼ˆA*æ¢ç´¢ç”¨ï¼‰"""
    
        def __init__(self, temperature: float, time: float, heating_sequence: List[float]):
            self.temperature = temperature
            self.time = time
            self.heating_sequence = heating_sequence  # ã“ã‚Œã¾ã§ã®åŠ ç†±å±¥æ­´
            self.g_cost = 0  # é–‹å§‹ã‹ã‚‰ã®ã‚³ã‚¹ãƒˆ
            self.h_cost = 0  # ãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯ã‚³ã‚¹ãƒˆ
    
        @property
        def f_cost(self):
            """ç·ã‚³ã‚¹ãƒˆ"""
            return self.g_cost + self.h_cost
    
        def __lt__(self, other):
            """å„ªå…ˆåº¦ã‚­ãƒ¥ãƒ¼ã§ã®æ¯”è¼ƒ"""
            return self.f_cost < other.f_cost
    
    
    class DeliberativeAgent(BaseAgent):
        """Deliberativeã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼ˆA*ãƒ—ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°ï¼‰
    
        ç›®æ¨™æ¸©åº¦ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é”æˆã™ã‚‹æœ€é©ãªåŠ ç†±ç³»åˆ—ã‚’è¨ˆç”»
        """
    
        def __init__(self, name: str, target_profile: List[Tuple[float, float]]):
            super().__init__(name)
            self.target_profile = target_profile  # [(time, temp), ...]
            self.plan = []  # è¨ˆç”»ã•ã‚ŒãŸè¡Œå‹•ç³»åˆ—
            self.plan_index = 0
    
        def plan_heating_sequence(self, initial_temp: float, max_time: float) -> List[float]:
            """A*ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã§åŠ ç†±ç³»åˆ—ã‚’è¨ˆç”»"""
            # ç›®æ¨™: å„æ™‚åˆ»ã§ç›®æ¨™æ¸©åº¦ã«è¿‘ã¥ã
            # è¡Œå‹•: å„ã‚¹ãƒ†ãƒƒãƒ—ã§ã®åŠ ç†±é‡ï¼ˆ0-10 kWï¼‰
    
            # ç°¡æ˜“ç‰ˆ: ç›®æ¨™æ¸©åº¦ã¨ã®å·®ã‚’æœ€å°åŒ–ã™ã‚‹è²ªæ¬²æ¢ç´¢
            heating_sequence = []
            current_temp = initial_temp
            dt = 0.5  # æ™‚é–“åˆ»ã¿ï¼ˆåˆ†ï¼‰
    
            for t in np.arange(0, max_time, dt):
                # ç¾åœ¨æ™‚åˆ»ã®ç›®æ¨™æ¸©åº¦ã‚’å–å¾—
                target_temp = self._get_target_temp(t)
    
                # æ¸©åº¦å·®
                error = target_temp - current_temp
    
                # è²ªæ¬²ãªåŠ ç†±é‡é¸æŠï¼ˆæ¯”ä¾‹åˆ¶å¾¡çš„ï¼‰
                heating = np.clip(error * 0.5, 0, 10)
                heating_sequence.append(heating)
    
                # æ¸©åº¦ã‚’æ›´æ–°ï¼ˆç°¡æ˜“ãƒ¢ãƒ‡ãƒ«ï¼‰
                current_temp += (heating * 2 - 1) * dt  # ç°¡æ˜“çš„ãªæ¸©åº¦å¤‰åŒ–
    
            return heating_sequence
    
        def _get_target_temp(self, time: float) -> float:
            """æŒ‡å®šæ™‚åˆ»ã®ç›®æ¨™æ¸©åº¦ã‚’å–å¾—ï¼ˆç·šå½¢è£œé–“ï¼‰"""
            for i in range(len(self.target_profile) - 1):
                t1, temp1 = self.target_profile[i]
                t2, temp2 = self.target_profile[i + 1]
    
                if t1 <= time <= t2:
                    # ç·šå½¢è£œé–“
                    alpha = (time - t1) / (t2 - t1)
                    return temp1 + alpha * (temp2 - temp1)
    
            # ç¯„å›²å¤–ã®å ´åˆã¯æœ€å¾Œã®æ¸©åº¦
            return self.target_profile[-1][1]
    
        def decide(self, perception: Dict) -> Dict:
            """è¨ˆç”»ã«å¾“ã£ã¦è¡Œå‹•"""
            if not self.plan:
                # è¨ˆç”»ã‚’ä½œæˆ
                self.plan = self.plan_heating_sequence(
                    initial_temp=perception['temperature'],
                    max_time=30.0
                )
                self.plan_index = 0
    
            # è¨ˆç”»ã‹ã‚‰è¡Œå‹•ã‚’å–å¾—
            if self.plan_index < len(self.plan):
                heating = self.plan[self.plan_index]
                self.plan_index += 1
            else:
                heating = 0  # è¨ˆç”»çµ‚äº†å¾Œã¯åœæ­¢
    
            return {'heating_power': heating}
    
    
    # ===== å®Ÿè¡Œä¾‹ =====
    print("\n=== Example 3: Deliberativeã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼ˆA*ãƒ—ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°ï¼‰ ===\n")
    
    # ç›®æ¨™æ¸©åº¦ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆãƒãƒƒãƒåå¿œï¼‰
    target_profile = [
        (0, 320),    # é–‹å§‹: 320K
        (5, 350),    # 5åˆ†ã§350Kã«æ˜‡æ¸©
        (15, 350),   # 350Kã§10åˆ†ä¿æŒ
        (20, 330),   # 5åˆ†ã§330Kã«é™æ¸©
        (30, 330)    # 330Kã§ä¿æŒ
    ]
    
    # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆä½œæˆ
    delib_agent = DeliberativeAgent(name="BatchPlanner", target_profile=target_profile)
    
    # ãƒãƒƒãƒåå¿œå™¨
    batch_reactor = SimpleCSTR(initial_temp=320.0)
    
    # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’å®Ÿè¡Œ
    n_steps = 600  # 30åˆ†ï¼ˆdt=0.05åˆ†ï¼‰
    delib_agent.run(batch_reactor, n_steps=n_steps)
    
    # çµæœã®å¯è¦–åŒ–
    times = [p['timestamp'] for p in delib_agent.perception_history]
    temps = [p['temperature'] for p in delib_agent.perception_history]
    target_temps = [delib_agent._get_target_temp(t) for t in times]
    
    fig, ax = plt.subplots(figsize=(10, 6))
    
    ax.plot(times, temps, 'b-', linewidth=2, label='Actual Temperature')
    ax.plot(times, target_temps, 'r--', linewidth=2, label='Target Profile')
    ax.set_xlabel('Time (min)')
    ax.set_ylabel('Temperature (K)')
    ax.set_title('Deliberative Agent: Batch Reactor Temperature Profile Control')
    ax.legend()
    ax.grid(alpha=0.3)
    
    plt.tight_layout()
    plt.show()
    
    # è¿½å¾“èª¤å·®ã‚’è¨ˆç®—
    errors = [abs(actual - target) for actual, target in zip(temps, target_temps)]
    mean_error = np.mean(errors)
    max_error = np.max(errors)
    
    print(f"å¹³å‡è¿½å¾“èª¤å·®: {mean_error:.2f} K")
    print(f"æœ€å¤§è¿½å¾“èª¤å·®: {max_error:.2f} K")
    

**å‡ºåŠ›ä¾‹:**  
å¹³å‡è¿½å¾“èª¤å·®: 3.45 K  
æœ€å¤§è¿½å¾“èª¤å·®: 8.12 K 

## å­¦ç¿’ç›®æ¨™ã®ç¢ºèª

ã“ã®ç« ã‚’å®Œäº†ã™ã‚‹ã¨ã€ä»¥ä¸‹ã‚’èª¬æ˜ãƒ»å®Ÿè£…ã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã™ï¼š

### åŸºæœ¬ç†è§£

  * âœ… ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®åŸºæœ¬æ¦‚å¿µï¼ˆPerception-Decision-Actionï¼‰ã‚’èª¬æ˜ã§ãã‚‹
  * âœ… Reactive, Deliberative, Hybridã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®é•ã„ã‚’ç†è§£ã—ã¦ã„ã‚‹
  * âœ… BDIã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®æ¦‚å¿µã‚’çŸ¥ã£ã¦ã„ã‚‹

### å®Ÿè·µã‚¹ã‚­ãƒ«

  * âœ… Reactiveã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼ˆãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ï¼‰ã‚’å®Ÿè£…ã§ãã‚‹
  * âœ… Deliberativeã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼ˆãƒ—ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°ï¼‰ã‚’å®Ÿè£…ã§ãã‚‹
  * âœ… ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆé–“é€šä¿¡ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã‚’å®Ÿè£…ã§ãã‚‹

### å¿œç”¨åŠ›

  * âœ… åŒ–å­¦ãƒ—ãƒ­ã‚»ã‚¹åˆ¶å¾¡ã«ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’é©ç”¨ã§ãã‚‹
  * âœ… å®‰å…¨ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ ã‚’è¨­è¨ˆã§ãã‚‹
  * âœ… ãƒãƒƒãƒãƒ—ãƒ­ã‚»ã‚¹ã®æ“ä½œè¨ˆç”»ã‚’æœ€é©åŒ–ã§ãã‚‹

## æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

ç¬¬1ç« ã§ã¯ã€AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®åŸºç¤ã¨ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’å­¦ã³ã¾ã—ãŸã€‚æ¬¡ç« ã§ã¯ã€å¼·åŒ–å­¦ç¿’ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒå‹•ä½œã™ã‚‹ãƒ—ãƒ­ã‚»ã‚¹ç’°å¢ƒã®ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã«ã¤ã„ã¦è©³ã—ãå­¦ã³ã¾ã™ã€‚

**ğŸ“š æ¬¡ç« ã®å†…å®¹ï¼ˆç¬¬2ç« äºˆå‘Šï¼‰**

  * çŠ¶æ…‹ç©ºé–“ã¨è¡Œå‹•ç©ºé–“ã®å®šç¾©
  * OpenAI Gymæº–æ‹ ã®ç’°å¢ƒå®Ÿè£…
  * CSTRã€è’¸ç•™å¡”ã€ãƒãƒ«ãƒãƒ¦ãƒ‹ãƒƒãƒˆç’°å¢ƒ
  * å ±é…¬é–¢æ•°ã®åŸºç¤è¨­è¨ˆ

### å…è²¬äº‹é …

  * æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯æ•™è‚²ãƒ»ç ”ç©¶ãƒ»æƒ…å ±æä¾›ã®ã¿ã‚’ç›®çš„ã¨ã—ã¦ãŠã‚Šã€å°‚é–€çš„ãªåŠ©è¨€(æ³•å¾‹ãƒ»ä¼šè¨ˆãƒ»æŠ€è¡“çš„ä¿è¨¼ãªã©)ã‚’æä¾›ã™ã‚‹ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚
  * æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŠã‚ˆã³ä»˜éšã™ã‚‹Code examplesã¯ã€Œç¾çŠ¶æœ‰å§¿(AS IS)ã€ã§æä¾›ã•ã‚Œã€æ˜ç¤ºã¾ãŸã¯é»™ç¤ºã‚’å•ã‚ãšã€å•†å“æ€§ã€ç‰¹å®šç›®çš„é©åˆæ€§ã€æ¨©åˆ©éä¾µå®³ã€æ­£ç¢ºæ€§ãƒ»å®Œå…¨æ€§ã€å‹•ä½œãƒ»å®‰å…¨æ€§ç­‰ã„ã‹ãªã‚‹ä¿è¨¼ã‚‚ã—ã¾ã›ã‚“ã€‚
  * å¤–éƒ¨ãƒªãƒ³ã‚¯ã€ç¬¬ä¸‰è€…ãŒæä¾›ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ»ãƒ„ãƒ¼ãƒ«ãƒ»ãƒ©ã‚¤ãƒ–ãƒ©ãƒªç­‰ã®å†…å®¹ãƒ»å¯ç”¨æ€§ãƒ»å®‰å…¨æ€§ã«ã¤ã„ã¦ã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯ä¸€åˆ‡ã®è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚
  * æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®åˆ©ç”¨ãƒ»å®Ÿè¡Œãƒ»è§£é‡ˆã«ã‚ˆã‚Šç›´æ¥çš„ãƒ»é–“æ¥çš„ãƒ»ä»˜éšçš„ãƒ»ç‰¹åˆ¥ãƒ»çµæœçš„ãƒ»æ‡²ç½°çš„æå®³ãŒç”Ÿã˜ãŸå ´åˆã§ã‚‚ã€é©ç”¨æ³•ã§è¨±å®¹ã•ã‚Œã‚‹æœ€å¤§é™ã®ç¯„å›²ã§ã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚
  * æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å†…å®¹ã¯ã€äºˆå‘Šãªãå¤‰æ›´ãƒ»æ›´æ–°ãƒ»æä¾›åœæ­¢ã•ã‚Œã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚
  * æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®è‘—ä½œæ¨©ãƒ»ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯æ˜è¨˜ã•ã‚ŒãŸæ¡ä»¶(ä¾‹: CC BY 4.0)ã«å¾“ã„ã¾ã™ã€‚å½“è©²ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯é€šå¸¸ã€ç„¡ä¿è¨¼æ¡é …ã‚’å«ã¿ã¾ã™ã€‚
