---
title: ç¬¬2ç« ï¼šãƒ—ãƒ­ã‚»ã‚¹ç’°å¢ƒã®ãƒ¢ãƒ‡ãƒªãƒ³ã‚°
chapter_title: ç¬¬2ç« ï¼šãƒ—ãƒ­ã‚»ã‚¹ç’°å¢ƒã®ãƒ¢ãƒ‡ãƒªãƒ³ã‚°
subtitle: OpenAI Gymã§å¼·åŒ–å­¦ç¿’å¯èƒ½ãªåŒ–å­¦ãƒ—ãƒ­ã‚»ã‚¹ç’°å¢ƒã‚’æ§‹ç¯‰
---

## 2.1 çŠ¶æ…‹ç©ºé–“ã®å®šç¾©

å¼·åŒ–å­¦ç¿’ã«ãŠã„ã¦ã€çŠ¶æ…‹ç©ºé–“ï¼ˆState Spaceï¼‰ã¯ç’°å¢ƒã®ç¾åœ¨ã®çŠ¶æ³ã‚’è¡¨ã™å¤‰æ•°ã®é›†åˆã§ã™ã€‚åŒ–å­¦ãƒ—ãƒ­ã‚»ã‚¹ã§ã¯ã€æ¸©åº¦ã€åœ§åŠ›ã€æ¿ƒåº¦ã€æµé‡ãªã©ã®é€£ç¶šå¤‰æ•°ãŒçŠ¶æ…‹ã‚’æ§‹æˆã—ã¾ã™ã€‚

**ğŸ’¡ çŠ¶æ…‹ç©ºé–“ã®è¨­è¨ˆåŸå‰‡**

  * **ãƒãƒ«ã‚³ãƒ•æ€§** : ç¾åœ¨ã®çŠ¶æ…‹ã«æœªæ¥ã®æŒ™å‹•ã‚’æ±ºå®šã™ã‚‹æƒ…å ±ãŒå«ã¾ã‚Œã¦ã„ã‚‹
  * **è¦³æ¸¬å¯èƒ½æ€§** : ã‚»ãƒ³ã‚µãƒ¼ã§å®Ÿéš›ã«æ¸¬å®šå¯èƒ½ãªå¤‰æ•°ã‚’é¸æŠ
  * **æ­£è¦åŒ–** : å„å¤‰æ•°ã‚’åŒã˜ã‚¹ã‚±ãƒ¼ãƒ«ï¼ˆä¾‹: 0-1ï¼‰ã«å¤‰æ›
  * **æ¬¡å…ƒå‰Šæ¸›** : å†—é•·ãªå¤‰æ•°ã‚’é™¤å»ã—å­¦ç¿’åŠ¹ç‡ã‚’å‘ä¸Š

### Example 1: çŠ¶æ…‹ç©ºé–“ã®æ§‹æˆã¨æ­£è¦åŒ–

CSTRï¼ˆé€£ç¶šæ”ªæ‹Œæ§½åå¿œå™¨ï¼‰ã®çŠ¶æ…‹ç©ºé–“ã‚’å®šç¾©ã—ã€æ­£è¦åŒ–ã‚’å®Ÿè£…ã—ã¾ã™ã€‚
    
    
    import numpy as np
    from typing import Dict, Tuple
    import gym
    from gym import spaces
    
    # ===================================
    # Example 1: çŠ¶æ…‹ç©ºé–“ã®å®šç¾©ã¨æ­£è¦åŒ–
    # ===================================
    
    class StateSpace:
        """åŒ–å­¦ãƒ—ãƒ­ã‚»ã‚¹ã®çŠ¶æ…‹ç©ºé–“å®šç¾©"""
    
        def __init__(self):
            # ç‰©ç†å¤‰æ•°ã®ç¯„å›²ï¼ˆæœ€å°å€¤ã€æœ€å¤§å€¤ï¼‰
            self.bounds = {
                'temperature': (300.0, 400.0),      # K
                'pressure': (1.0, 10.0),            # bar
                'concentration': (0.0, 2.0),        # mol/L
                'flow_rate': (0.5, 5.0),            # L/min
                'level': (0.0, 100.0)               # %
            }
    
        def get_state_vector(self, physical_state: Dict) -> np.ndarray:
            """ç‰©ç†å¤‰æ•°ã‹ã‚‰çŠ¶æ…‹ãƒ™ã‚¯ãƒˆãƒ«ã‚’æ§‹æˆ"""
            state = np.array([
                physical_state['temperature'],
                physical_state['pressure'],
                physical_state['concentration'],
                physical_state['flow_rate'],
                physical_state['level']
            ])
            return state
    
        def normalize(self, state: np.ndarray) -> np.ndarray:
            """çŠ¶æ…‹ã‚’[0, 1]ç¯„å›²ã«æ­£è¦åŒ–"""
            normalized = np.zeros_like(state)
            for i, var_name in enumerate(self.bounds.keys()):
                min_val, max_val = self.bounds[var_name]
                normalized[i] = (state[i] - min_val) / (max_val - min_val)
                normalized[i] = np.clip(normalized[i], 0, 1)
            return normalized
    
        def denormalize(self, normalized_state: np.ndarray) -> np.ndarray:
            """æ­£è¦åŒ–ã•ã‚ŒãŸçŠ¶æ…‹ã‚’ç‰©ç†å€¤ã«æˆ»ã™"""
            state = np.zeros_like(normalized_state)
            for i, var_name in enumerate(self.bounds.keys()):
                min_val, max_val = self.bounds[var_name]
                state[i] = normalized_state[i] * (max_val - min_val) + min_val
            return state
    
        def get_gym_space(self) -> spaces.Box:
            """OpenAI Gymç”¨ã®çŠ¶æ…‹ç©ºé–“ã‚’å–å¾—"""
            low = np.array([bounds[0] for bounds in self.bounds.values()])
            high = np.array([bounds[1] for bounds in self.bounds.values()])
            return spaces.Box(low=low, high=high, dtype=np.float32)
    
    
    # ===== ä½¿ç”¨ä¾‹ =====
    print("=== Example 1: çŠ¶æ…‹ç©ºé–“ã®å®šç¾©ã¨æ­£è¦åŒ– ===\n")
    
    state_space = StateSpace()
    
    # ã‚µãƒ³ãƒ—ãƒ«çŠ¶æ…‹
    physical_state = {
        'temperature': 350.0,
        'pressure': 5.5,
        'concentration': 1.2,
        'flow_rate': 2.5,
        'level': 75.0
    }
    
    # çŠ¶æ…‹ãƒ™ã‚¯ãƒˆãƒ«ã®æ§‹æˆ
    state_vector = state_space.get_state_vector(physical_state)
    print("ç‰©ç†çŠ¶æ…‹ãƒ™ã‚¯ãƒˆãƒ«:")
    print(state_vector)
    
    # æ­£è¦åŒ–
    normalized = state_space.normalize(state_vector)
    print("\næ­£è¦åŒ–ã•ã‚ŒãŸçŠ¶æ…‹ï¼ˆ0-1ç¯„å›²ï¼‰:")
    print(normalized)
    
    # é€†æ­£è¦åŒ–ã§ç¢ºèª
    denormalized = state_space.denormalize(normalized)
    print("\né€†æ­£è¦åŒ–ã•ã‚ŒãŸçŠ¶æ…‹ï¼ˆå…ƒã®ç‰©ç†å€¤ï¼‰:")
    print(denormalized)
    
    # Gymç©ºé–“ã®å®šç¾©
    gym_space = state_space.get_gym_space()
    print(f"\nOpenAI GymçŠ¶æ…‹ç©ºé–“:")
    print(f"  Low: {gym_space.low}")
    print(f"  High: {gym_space.high}")
    print(f"  Shape: {gym_space.shape}")
    
    # ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
    random_state = gym_space.sample()
    print(f"\nãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒ«: {random_state}")
    

**å‡ºåŠ›ä¾‹:**  
ç‰©ç†çŠ¶æ…‹ãƒ™ã‚¯ãƒˆãƒ«:  
[350. 5.5 1.2 2.5 75. ]  
  
æ­£è¦åŒ–ã•ã‚ŒãŸçŠ¶æ…‹ï¼ˆ0-1ç¯„å›²ï¼‰:  
[0.5 0.5 0.6 0.44 0.75]  
  
OpenAI GymçŠ¶æ…‹ç©ºé–“:  
Shape: (5,) 

## 2.2 è¡Œå‹•ç©ºé–“ã®è¨­è¨ˆ

è¡Œå‹•ç©ºé–“ï¼ˆAction Spaceï¼‰ã¯ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒå®Ÿè¡Œã§ãã‚‹æ“ä½œã®é›†åˆã§ã™ã€‚é›¢æ•£è¡Œå‹•ï¼ˆãƒãƒ«ãƒ–é–‹é–‰ï¼‰ã¨é€£ç¶šè¡Œå‹•ï¼ˆæµé‡èª¿æ•´ï¼‰ãŒã‚ã‚Šã¾ã™ã€‚

### Example 2: é›¢æ•£ãƒ»é€£ç¶šãƒ»æ··åˆè¡Œå‹•ç©ºé–“ã®å®Ÿè£…
    
    
    import gym
    from gym import spaces
    import numpy as np
    
    # ===================================
    # Example 2: è¡Œå‹•ç©ºé–“ã®è¨­è¨ˆ
    # ===================================
    
    class ActionSpaceDesign:
        """è¡Œå‹•ç©ºé–“ã®è¨­è¨ˆãƒ‘ã‚¿ãƒ¼ãƒ³"""
    
        @staticmethod
        def discrete_action_space() -> spaces.Discrete:
            """é›¢æ•£è¡Œå‹•ç©ºé–“ï¼ˆä¾‹: ãƒãƒ«ãƒ–æ“ä½œï¼‰
    
            Actions:
                0: ãƒãƒ«ãƒ–å…¨é–‰
                1: ãƒãƒ«ãƒ–25%é–‹
                2: ãƒãƒ«ãƒ–50%é–‹
                3: ãƒãƒ«ãƒ–75%é–‹
                4: ãƒãƒ«ãƒ–å…¨é–‹
            """
            return spaces.Discrete(5)
    
        @staticmethod
        def continuous_action_space() -> spaces.Box:
            """é€£ç¶šè¡Œå‹•ç©ºé–“ï¼ˆä¾‹: æµé‡åˆ¶å¾¡ï¼‰
    
            Actions:
                [0]: ãƒ’ãƒ¼ã‚¿ãƒ¼å‡ºåŠ› (0-10 kW)
                [1]: å†·å´æ°´æµé‡ (0-5 L/min)
            """
            return spaces.Box(
                low=np.array([0.0, 0.0]),
                high=np.array([10.0, 5.0]),
                dtype=np.float32
            )
    
        @staticmethod
        def mixed_action_space() -> spaces.Dict:
            """æ··åˆè¡Œå‹•ç©ºé–“ï¼ˆé›¢æ•£+é€£ç¶šï¼‰
    
            Actions:
                'mode': é‹è»¢ãƒ¢ãƒ¼ãƒ‰é¸æŠ (0: å¾…æ©Ÿ, 1: é‹è»¢, 2: åœæ­¢)
                'heating': ãƒ’ãƒ¼ã‚¿ãƒ¼å‡ºåŠ› (0-10 kW)
                'flow': æµé‡ (0-5 L/min)
            """
            return spaces.Dict({
                'mode': spaces.Discrete(3),
                'heating': spaces.Box(low=0.0, high=10.0, shape=(1,), dtype=np.float32),
                'flow': spaces.Box(low=0.0, high=5.0, shape=(1,), dtype=np.float32)
            })
    
        @staticmethod
        def apply_safety_constraints(action: np.ndarray, state: np.ndarray) -> np.ndarray:
            """å®‰å…¨åˆ¶ç´„ã®é©ç”¨
    
            Args:
                action: å…ƒã®è¡Œå‹•
                state: ç¾åœ¨ã®çŠ¶æ…‹ [temp, pressure, ...]
    
            Returns:
                åˆ¶ç´„å¾Œã®è¡Œå‹•
            """
            safe_action = action.copy()
    
            # åˆ¶ç´„1: é«˜æ¸©æ™‚ã¯ãƒ’ãƒ¼ã‚¿ãƒ¼å‡ºåŠ›ã‚’åˆ¶é™
            if state[0] > 380:  # æ¸©åº¦ãŒ380Kä»¥ä¸Š
                safe_action[0] = min(safe_action[0], 2.0)  # ãƒ’ãƒ¼ã‚¿ãƒ¼æœ€å¤§2kW
    
            # åˆ¶ç´„2: é«˜åœ§æ™‚ã¯æµé‡ã‚’åˆ¶é™
            if len(state) > 1 and state[1] > 8:  # åœ§åŠ›ãŒ8barä»¥ä¸Š
                safe_action[1] = min(safe_action[1], 1.0)  # æµé‡æœ€å¤§1L/min
    
            # åˆ¶ç´„3: ç‰©ç†çš„ãªé™ç•Œ
            safe_action = np.clip(safe_action, [0.0, 0.0], [10.0, 5.0])
    
            return safe_action
    
    
    # ===== ä½¿ç”¨ä¾‹ =====
    print("\n=== Example 2: è¡Œå‹•ç©ºé–“ã®è¨­è¨ˆ ===\n")
    
    designer = ActionSpaceDesign()
    
    # 1. é›¢æ•£è¡Œå‹•ç©ºé–“
    discrete_space = designer.discrete_action_space()
    print("é›¢æ•£è¡Œå‹•ç©ºé–“:")
    print(f"  ã‚¢ã‚¯ã‚·ãƒ§ãƒ³æ•°: {discrete_space.n}")
    print(f"  ã‚µãƒ³ãƒ—ãƒ«: {discrete_space.sample()}")
    
    # 2. é€£ç¶šè¡Œå‹•ç©ºé–“
    continuous_space = designer.continuous_action_space()
    print("\né€£ç¶šè¡Œå‹•ç©ºé–“:")
    print(f"  Low: {continuous_space.low}")
    print(f"  High: {continuous_space.high}")
    print(f"  ã‚µãƒ³ãƒ—ãƒ«: {continuous_space.sample()}")
    
    # 3. æ··åˆè¡Œå‹•ç©ºé–“
    mixed_space = designer.mixed_action_space()
    print("\næ··åˆè¡Œå‹•ç©ºé–“:")
    sample_mixed = mixed_space.sample()
    print(f"  Mode: {sample_mixed['mode']}")
    print(f"  Heating: {sample_mixed['heating']}")
    print(f"  Flow: {sample_mixed['flow']}")
    
    # 4. å®‰å…¨åˆ¶ç´„ã®é©ç”¨
    print("\nå®‰å…¨åˆ¶ç´„ã®é©ç”¨:")
    unsafe_action = np.array([8.0, 4.0])  # ãƒ’ãƒ¼ã‚¿ãƒ¼8kW, æµé‡4L/min
    high_temp_state = np.array([385.0, 5.0])  # é«˜æ¸©çŠ¶æ…‹
    
    safe_action = designer.apply_safety_constraints(unsafe_action, high_temp_state)
    print(f"  å…ƒã®è¡Œå‹•: {unsafe_action}")
    print(f"  åˆ¶ç´„å¾Œ: {safe_action}")
    print(f"  ç†ç”±: æ¸©åº¦{high_temp_state[0]:.0f}K > 380K â†’ ãƒ’ãƒ¼ã‚¿ãƒ¼å‡ºåŠ›ã‚’2kWä»¥ä¸‹ã«åˆ¶é™")
    

**å‡ºåŠ›ä¾‹:**  
é›¢æ•£è¡Œå‹•ç©ºé–“:  
ã‚¢ã‚¯ã‚·ãƒ§ãƒ³æ•°: 5  
ã‚µãƒ³ãƒ—ãƒ«: 2  
  
é€£ç¶šè¡Œå‹•ç©ºé–“:  
ã‚µãƒ³ãƒ—ãƒ«: [6.23 2.84]  
  
å®‰å…¨åˆ¶ç´„ã®é©ç”¨:  
å…ƒã®è¡Œå‹•: [8. 4.]  
åˆ¶ç´„å¾Œ: [2. 4.] 

## 2.3 å ±é…¬é–¢æ•°ã®åŸºç¤è¨­è¨ˆ

å ±é…¬é–¢æ•°ï¼ˆReward Functionï¼‰ã¯ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®è¡Œå‹•ã®è‰¯ã—æ‚ªã—ã‚’æ•°å€¤åŒ–ã—ã¾ã™ã€‚åŒ–å­¦ãƒ—ãƒ­ã‚»ã‚¹ã§ã¯ã€è¨­å®šå€¤è¿½å¾“ã€ã‚¨ãƒãƒ«ã‚®ãƒ¼åŠ¹ç‡ã€å®‰å…¨æ€§ãªã©ã‚’è€ƒæ…®ã—ãŸå¤šç›®çš„å ±é…¬é–¢æ•°ã‚’è¨­è¨ˆã—ã¾ã™ã€‚

### Example 3: å¤šç›®çš„å ±é…¬é–¢æ•°ã®å®Ÿè£…
    
    
    import numpy as np
    from typing import Dict
    
    # ===================================
    # Example 3: å¤šç›®çš„å ±é…¬é–¢æ•°
    # ===================================
    
    class RewardFunction:
        """åŒ–å­¦ãƒ—ãƒ­ã‚»ã‚¹ç”¨ã®å ±é…¬é–¢æ•°"""
    
        def __init__(self, weights: Dict[str, float] = None):
            # å„ç›®çš„ã®é‡ã¿ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ï¼‰
            self.weights = weights or {
                'setpoint_tracking': 1.0,    # è¨­å®šå€¤è¿½å¾“
                'energy': 0.3,                # ã‚¨ãƒãƒ«ã‚®ãƒ¼åŠ¹ç‡
                'safety': 2.0,                # å®‰å…¨æ€§
                'stability': 0.5              # å®‰å®šæ€§
            }
    
        def compute_reward(self, state: np.ndarray, action: np.ndarray,
                          target_temp: float = 350.0) -> Tuple[float, Dict[str, float]]:
            """ç·åˆå ±é…¬ã‚’è¨ˆç®—
    
            Args:
                state: [temperature, pressure, concentration, ...]
                action: [heating_power, flow_rate]
                target_temp: ç›®æ¨™æ¸©åº¦
    
            Returns:
                total_reward: ç·åˆå ±é…¬
                components: å„æˆåˆ†ã®å ±é…¬ã®è©³ç´°
            """
            temp, pressure = state[0], state[1]
            heating, flow = action[0], action[1] if len(action) > 1 else 0
    
            # 1. è¨­å®šå€¤è¿½å¾“å ±é…¬ï¼ˆæ¸©åº¦ï¼‰
            temp_error = abs(temp - target_temp)
            r_tracking = -temp_error / 10.0  # -10ã€œ0ã®ç¯„å›²
    
            # 2. ã‚¨ãƒãƒ«ã‚®ãƒ¼åŠ¹ç‡å ±é…¬
            energy_cost = heating * 0.1 + flow * 0.05  # ã‚¨ãƒãƒ«ã‚®ãƒ¼ã‚³ã‚¹ãƒˆ
            r_energy = -energy_cost
    
            # 3. å®‰å…¨æ€§å ±é…¬ï¼ˆãƒšãƒŠãƒ«ãƒ†ã‚£ï¼‰
            r_safety = 0.0
            if temp > 380:  # é«˜æ¸©è­¦å‘Š
                r_safety = -10.0 * (temp - 380)
            if temp > 400:  # å±é™ºé ˜åŸŸ
                r_safety = -100.0
            if pressure > 9:  # é«˜åœ§è­¦å‘Š
                r_safety += -5.0 * (pressure - 9)
    
            # 4. å®‰å®šæ€§å ±é…¬ï¼ˆå¤‰å‹•ã®å°‘ãªã•ï¼‰
            # æ³¨: å®Ÿéš›ã¯å‰ã‚¹ãƒ†ãƒƒãƒ—ã¨ã®å·®åˆ†ã‚’ä½¿ç”¨
            r_stability = 0.0  # ç°¡ç•¥åŒ–ã®ãŸã‚çœç•¥
    
            # é‡ã¿ä»˜ã‘ç·å’Œ
            components = {
                'tracking': r_tracking * self.weights['setpoint_tracking'],
                'energy': r_energy * self.weights['energy'],
                'safety': r_safety * self.weights['safety'],
                'stability': r_stability * self.weights['stability']
            }
    
            total_reward = sum(components.values())
    
            return total_reward, components
    
        def reward_shaping(self, raw_reward: float, progress: float) -> float:
            """å ±é…¬ã‚·ã‚§ãƒ¼ãƒ”ãƒ³ã‚°ï¼ˆå­¦ç¿’åˆæœŸã®æ¢ç´¢ä¿ƒé€²ï¼‰
    
            Args:
                raw_reward: å…ƒã®å ±é…¬
                progress: å­¦ç¿’é€²æ—ï¼ˆ0-1ï¼‰
    
            Returns:
                shaped_reward: ã‚·ã‚§ãƒ¼ãƒ”ãƒ³ã‚°å¾Œã®å ±é…¬
            """
            # åˆæœŸã¯ãƒšãƒŠãƒ«ãƒ†ã‚£ã‚’ç·©å’Œ
            penalty_scale = 0.3 + 0.7 * progress
            if raw_reward < 0:
                return raw_reward * penalty_scale
            else:
                return raw_reward
    
    
    # ===== ä½¿ç”¨ä¾‹ =====
    print("\n=== Example 3: å¤šç›®çš„å ±é…¬é–¢æ•° ===\n")
    
    reward_func = RewardFunction()
    
    # ã‚·ãƒŠãƒªã‚ª1: æœ€é©çŠ¶æ…‹
    state_optimal = np.array([350.0, 5.0, 1.0])
    action_optimal = np.array([5.0, 2.0])
    
    reward, components = reward_func.compute_reward(state_optimal, action_optimal)
    print("ã‚·ãƒŠãƒªã‚ª1: æœ€é©çŠ¶æ…‹")
    print(f"  çŠ¶æ…‹: T={state_optimal[0]}K, P={state_optimal[1]}bar")
    print(f"  è¡Œå‹•: Heating={action_optimal[0]}kW, Flow={action_optimal[1]}L/min")
    print(f"  ç·åˆå ±é…¬: {reward:.3f}")
    for key, val in components.items():
        print(f"    {key}: {val:.3f}")
    
    # ã‚·ãƒŠãƒªã‚ª2: é«˜æ¸©å±é™ºçŠ¶æ…‹
    state_danger = np.array([390.0, 5.0, 1.0])
    action_danger = np.array([8.0, 2.0])
    
    reward, components = reward_func.compute_reward(state_danger, action_danger)
    print("\nã‚·ãƒŠãƒªã‚ª2: é«˜æ¸©å±é™ºçŠ¶æ…‹")
    print(f"  çŠ¶æ…‹: T={state_danger[0]}K, P={state_danger[1]}bar")
    print(f"  ç·åˆå ±é…¬: {reward:.3f}")
    for key, val in components.items():
        print(f"    {key}: {val:.3f}")
    
    # ã‚·ãƒŠãƒªã‚ª3: ã‚¨ãƒãƒ«ã‚®ãƒ¼éå‰°ä½¿ç”¨
    state_normal = np.array([345.0, 5.0, 1.0])
    action_waste = np.array([10.0, 5.0])
    
    reward, components = reward_func.compute_reward(state_normal, action_waste)
    print("\nã‚·ãƒŠãƒªã‚ª3: ã‚¨ãƒãƒ«ã‚®ãƒ¼éå‰°ä½¿ç”¨")
    print(f"  çŠ¶æ…‹: T={state_normal[0]}K, P={state_normal[1]}bar")
    print(f"  è¡Œå‹•: Heating={action_waste[0]}kW, Flow={action_waste[1]}L/min")
    print(f"  ç·åˆå ±é…¬: {reward:.3f}")
    for key, val in components.items():
        print(f"    {key}: {val:.3f}")
    

**å‡ºåŠ›ä¾‹:**  
ã‚·ãƒŠãƒªã‚ª1: æœ€é©çŠ¶æ…‹  
ç·åˆå ±é…¬: -0.250  
tracking: 0.000  
energy: -0.250  
safety: 0.000  
  
ã‚·ãƒŠãƒªã‚ª2: é«˜æ¸©å±é™ºçŠ¶æ…‹  
ç·åˆå ±é…¬: -204.550  
tracking: -4.000  
energy: -0.550  
safety: -200.000 

**âš ï¸ å ±é…¬é–¢æ•°è¨­è¨ˆã®æ³¨æ„ç‚¹**

  * **ã‚¹ã‚±ãƒ¼ãƒ«ã®çµ±ä¸€** : å„æˆåˆ†ã®å ±é…¬ã‚¹ã‚±ãƒ¼ãƒ«ã‚’åˆã‚ã›ã‚‹
  * **ã‚¹ãƒ‘ãƒ¼ã‚¹å ±é…¬ã®å›é¿** : é©åº¦ãªä¸­é–“å ±é…¬ã‚’ä¸ãˆã‚‹
  * **å ±é…¬ãƒãƒƒã‚­ãƒ³ã‚°é˜²æ­¢** : æ„å›³ã—ãªã„æŒ™å‹•ã‚’ç”Ÿã¾ãªã„ã‹æ¤œè¨¼

## å­¦ç¿’ç›®æ¨™ã®ç¢ºèª

### åŸºæœ¬ç†è§£

  * âœ… çŠ¶æ…‹ç©ºé–“ã¨è¡Œå‹•ç©ºé–“ã®å®šç¾©æ–¹æ³•ã‚’ç†è§£ã—ã¦ã„ã‚‹
  * âœ… å ±é…¬é–¢æ•°ã®è¨­è¨ˆåŸå‰‡ã‚’çŸ¥ã£ã¦ã„ã‚‹
  * âœ… OpenAI Gymç’°å¢ƒã®æ§‹é€ ã‚’ç†è§£ã—ã¦ã„ã‚‹

### å®Ÿè·µã‚¹ã‚­ãƒ«

  * âœ… çŠ¶æ…‹ã®æ­£è¦åŒ–ãƒ»é€†æ­£è¦åŒ–ã‚’å®Ÿè£…ã§ãã‚‹
  * âœ… é›¢æ•£ãƒ»é€£ç¶šãƒ»æ··åˆè¡Œå‹•ç©ºé–“ã‚’è¨­è¨ˆã§ãã‚‹
  * âœ… å¤šç›®çš„å ±é…¬é–¢æ•°ã‚’å®Ÿè£…ã§ãã‚‹
  * âœ… å®‰å…¨åˆ¶ç´„ã‚’çµ„ã¿è¾¼ã‚ã‚‹

### å¿œç”¨åŠ›

  * âœ… CSTRç’°å¢ƒã‚’Gymæº–æ‹ ã§å®Ÿè£…ã§ãã‚‹
  * âœ… è’¸ç•™å¡”ç’°å¢ƒã‚’ãƒ¢ãƒ‡ãƒ«åŒ–ã§ãã‚‹
  * âœ… ãƒãƒ«ãƒãƒ¦ãƒ‹ãƒƒãƒˆãƒ—ãƒ­ã‚»ã‚¹ã‚’çµ±åˆã§ãã‚‹

### å…è²¬äº‹é …

  * æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯æ•™è‚²ãƒ»ç ”ç©¶ãƒ»æƒ…å ±æä¾›ã®ã¿ã‚’ç›®çš„ã¨ã—ã¦ãŠã‚Šã€å°‚é–€çš„ãªåŠ©è¨€(æ³•å¾‹ãƒ»ä¼šè¨ˆãƒ»æŠ€è¡“çš„ä¿è¨¼ãªã©)ã‚’æä¾›ã™ã‚‹ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚
  * æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŠã‚ˆã³ä»˜éšã™ã‚‹Code examplesã¯ã€Œç¾çŠ¶æœ‰å§¿(AS IS)ã€ã§æä¾›ã•ã‚Œã€æ˜ç¤ºã¾ãŸã¯é»™ç¤ºã‚’å•ã‚ãšã€å•†å“æ€§ã€ç‰¹å®šç›®çš„é©åˆæ€§ã€æ¨©åˆ©éä¾µå®³ã€æ­£ç¢ºæ€§ãƒ»å®Œå…¨æ€§ã€å‹•ä½œãƒ»å®‰å…¨æ€§ç­‰ã„ã‹ãªã‚‹ä¿è¨¼ã‚‚ã—ã¾ã›ã‚“ã€‚
  * å¤–éƒ¨ãƒªãƒ³ã‚¯ã€ç¬¬ä¸‰è€…ãŒæä¾›ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ»ãƒ„ãƒ¼ãƒ«ãƒ»ãƒ©ã‚¤ãƒ–ãƒ©ãƒªç­‰ã®å†…å®¹ãƒ»å¯ç”¨æ€§ãƒ»å®‰å…¨æ€§ã«ã¤ã„ã¦ã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯ä¸€åˆ‡ã®è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚
  * æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®åˆ©ç”¨ãƒ»å®Ÿè¡Œãƒ»è§£é‡ˆã«ã‚ˆã‚Šç›´æ¥çš„ãƒ»é–“æ¥çš„ãƒ»ä»˜éšçš„ãƒ»ç‰¹åˆ¥ãƒ»çµæœçš„ãƒ»æ‡²ç½°çš„æå®³ãŒç”Ÿã˜ãŸå ´åˆã§ã‚‚ã€é©ç”¨æ³•ã§è¨±å®¹ã•ã‚Œã‚‹æœ€å¤§é™ã®ç¯„å›²ã§ã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚
  * æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å†…å®¹ã¯ã€äºˆå‘Šãªãå¤‰æ›´ãƒ»æ›´æ–°ãƒ»æä¾›åœæ­¢ã•ã‚Œã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚
  * æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®è‘—ä½œæ¨©ãƒ»ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯æ˜è¨˜ã•ã‚ŒãŸæ¡ä»¶(ä¾‹: CC BY 4.0)ã«å¾“ã„ã¾ã™ã€‚å½“è©²ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯é€šå¸¸ã€ç„¡ä¿è¨¼æ¡é …ã‚’å«ã¿ã¾ã™ã€‚
