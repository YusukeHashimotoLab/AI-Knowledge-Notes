---
title: ç¬¬2ç«  é›»å­ãƒãƒƒãƒè¨˜éŒ²è§£æã¨é€¸è„±ç®¡ç†
chapter_title: ç¬¬2ç«  é›»å­ãƒãƒƒãƒè¨˜éŒ²è§£æã¨é€¸è„±ç®¡ç†
subtitle: Electronic Batch Record Analysis and Deviation Management
---

ğŸŒ JP | [ğŸ‡¬ğŸ‡§ EN](<../../../en/PI/pharma-manufacturing-ai/chapter-2.html>) | Last sync: 2025-11-16

[AIå¯ºå­å±‹ãƒˆãƒƒãƒ—](<../../index.html>)â€º[ãƒ—ãƒ­ã‚»ã‚¹ãƒ»ã‚¤ãƒ³ãƒ•ã‚©ãƒãƒ†ã‚£ã‚¯ã‚¹](<../../PI/index.html>)â€º[Pharma Manufacturing Ai](<../../PI/pharma-manufacturing-ai/index.html>)â€ºChapter 2

[â† ã‚·ãƒªãƒ¼ã‚ºç›®æ¬¡ã«æˆ»ã‚‹](<index.html>)

## ğŸ“– æœ¬ç« ã®æ¦‚è¦

åŒ»è–¬å“è£½é€ ã«ãŠã‘ã‚‹é›»å­ãƒãƒƒãƒè¨˜éŒ²ï¼ˆEBR: Electronic Batch Recordï¼‰ã¯ã€è£½é€ ãƒ—ãƒ­ã‚»ã‚¹ã®é€æ˜æ€§ã¨ ãƒˆãƒ¬ãƒ¼ã‚µãƒ“ãƒªãƒ†ã‚£ã‚’ç¢ºä¿ã™ã‚‹é‡è¦ãªã‚·ã‚¹ãƒ†ãƒ ã§ã™ã€‚æœ¬ç« ã§ã¯ã€EBRãƒ‡ãƒ¼ã‚¿ã®è‡ªå‹•è§£æã€ ç•°å¸¸æ¤œçŸ¥ã€æ ¹æœ¬åŸå› åˆ†æï¼ˆRCAï¼‰ã€æ˜¯æ­£æªç½®ãƒ»äºˆé˜²æªç½®ï¼ˆCAPAï¼‰ã®ææ¡ˆã¾ã§ã€ AIã‚’æ´»ç”¨ã—ãŸåŒ…æ‹¬çš„ãªé€¸è„±ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã®æ§‹ç¯‰æ–¹æ³•ã‚’å­¦ã³ã¾ã™ã€‚ 

### ğŸ¯ å­¦ç¿’ç›®æ¨™

  * é›»å­ãƒãƒƒãƒè¨˜éŒ²ï¼ˆEBRï¼‰ã®æ§‹é€ ã¨ãƒ‡ãƒ¼ã‚¿è§£ææ‰‹æ³•
  * ãƒãƒƒãƒãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æã«ã‚ˆã‚‹ãƒ—ãƒ­ã‚»ã‚¹å¤‰å‹•ã®å¯è¦–åŒ–
  * æ©Ÿæ¢°å­¦ç¿’ã«ã‚ˆã‚‹ç•°å¸¸ãƒãƒƒãƒã®è‡ªå‹•æ¤œå‡º
  * æ ¹æœ¬åŸå› åˆ†æï¼ˆRCAï¼‰ã®ãŸã‚ã®ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ‹ãƒ³ã‚°
  * CAPAï¼ˆæ˜¯æ­£æªç½®ãƒ»äºˆé˜²æªç½®ï¼‰ææ¡ˆã®è‡ªå‹•ç”Ÿæˆ
  * é€¸è„±ç®¡ç†ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®è‡ªå‹•åŒ–
  * GMPæº–æ‹ ã®æ–‡æ›¸ç®¡ç†ã¨ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†

## ğŸ“‹ 2.1 é›»å­ãƒãƒƒãƒè¨˜éŒ²ï¼ˆEBRï¼‰ã®åŸºç¤

### EBRã®æ§‹æˆè¦ç´ 

é›»å­ãƒãƒƒãƒè¨˜éŒ²ã¯ä»¥ä¸‹ã®ä¸»è¦è¦ç´ ã‹ã‚‰æ§‹æˆã•ã‚Œã¾ã™ï¼š

  * **ãƒãƒƒãƒãƒ˜ãƒƒãƒ€** : ãƒãƒƒãƒç•ªå·ã€è£½å“åã€è£½é€ æ—¥ã€ãƒ­ãƒƒãƒˆç•ªå·
  * **åŸææ–™è¨˜éŒ²** : ä½¿ç”¨åŸæ–™ã€æ•°é‡ã€ãƒ­ãƒƒãƒˆç•ªå·ã€æœ‰åŠ¹æœŸé™
  * **å·¥ç¨‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿** : æ¸©åº¦ã€åœ§åŠ›ã€æ™‚é–“ã€pHã€æµé‡ãªã©
  * **ä¸­é–“ä½“è©¦é¨“** : å„å·¥ç¨‹ã§ã®å“è³ªç¢ºèªçµæœ
  * **æœ€çµ‚è£½å“è©¦é¨“** : å«é‡ã€æº¶å‡ºã€ç´”åº¦ã€å¾®ç”Ÿç‰©è©¦é¨“
  * **é€¸è„±è¨˜éŒ²** : ç•°å¸¸ç™ºç”Ÿã€åŸå› ã€å¯¾ç­–ã€æ‰¿èª
  * **é›»å­ç½²å** : ä½œæ¥­è€…ã€ç¢ºèªè€…ã€æ‰¿èªè€…ã®ç½²å

**ğŸ­ GMPè¦ä»¶ï¼ˆ21 CFR Part 11ï¼‰**  
ãƒ»é›»å­è¨˜éŒ²ã®çœŸæ­£æ€§ï¼ˆAuthenticityï¼‰: æ”¹ã–ã‚“é˜²æ­¢  
ãƒ»å®Œå…¨æ€§ï¼ˆIntegrityï¼‰: ãƒ‡ãƒ¼ã‚¿ã®ä¸€è²«æ€§ã¨æ­£ç¢ºæ€§  
ãƒ»ä¿¡é ¼æ€§ï¼ˆReliabilityï¼‰: ã‚·ã‚¹ãƒ†ãƒ ã®å®‰å®šå‹•ä½œ  
ãƒ»åˆ©ç”¨å¯èƒ½æ€§ï¼ˆAvailabilityï¼‰: å¿…è¦æ™‚ã®ã‚¢ã‚¯ã‚»ã‚¹ä¿è¨¼  
ãƒ»ç›£æŸ»è¨¼è·¡ï¼ˆAudit Trailï¼‰: ã™ã¹ã¦ã®å¤‰æ›´å±¥æ­´ã®è¨˜éŒ² 

### ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹2.1: EBRãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«ã¨ãƒãƒƒãƒãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ
    
    
    import numpy as np
    import pandas as pd
    import matplotlib.pyplot as plt
    from datetime import datetime, timedelta
    import json
    import warnings
    warnings.filterwarnings('ignore')
    
    plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'DejaVu Sans']
    plt.rcParams['axes.unicode_minus'] = False
    
    class ElectronicBatchRecord:
        """é›»å­ãƒãƒƒãƒè¨˜éŒ²ï¼ˆEBRï¼‰ç®¡ç†ã‚¯ãƒ©ã‚¹"""
    
        def __init__(self, batch_id, product_name, manufacturing_date):
            self.batch_id = batch_id
            self.product_name = product_name
            self.manufacturing_date = manufacturing_date
            self.process_parameters = {}
            self.quality_tests = {}
            self.deviations = []
            self.signatures = []
            self.audit_trail = []
    
        def add_process_parameter(self, step_name, parameter_name, target, actual, unit, tolerance=None):
            """å·¥ç¨‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®è¨˜éŒ²"""
            if step_name not in self.process_parameters:
                self.process_parameters[step_name] = []
    
            param = {
                'parameter': parameter_name,
                'target': target,
                'actual': actual,
                'unit': unit,
                'tolerance': tolerance,
                'timestamp': datetime.now().isoformat(),
                'in_spec': self._check_tolerance(target, actual, tolerance) if tolerance else True
            }
    
            self.process_parameters[step_name].append(param)
            self._log_audit(f"å·¥ç¨‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨˜éŒ²: {step_name} - {parameter_name}")
    
        def _check_tolerance(self, target, actual, tolerance):
            """è¨±å®¹ç¯„å›²ãƒã‚§ãƒƒã‚¯"""
            lower = target - tolerance
            upper = target + tolerance
            return lower <= actual <= upper
    
        def add_deviation(self, description, severity, root_cause=None, capa=None):
            """é€¸è„±ã®è¨˜éŒ²"""
            deviation = {
                'id': f"DEV-{self.batch_id}-{len(self.deviations)+1:03d}",
                'description': description,
                'severity': severity,  # Critical, Major, Minor
                'root_cause': root_cause,
                'capa': capa,
                'timestamp': datetime.now().isoformat(),
                'status': 'Open'
            }
            self.deviations.append(deviation)
            self._log_audit(f"é€¸è„±è¨˜éŒ²: {deviation['id']}")
    
        def add_signature(self, role, user_name):
            """é›»å­ç½²åã®è¨˜éŒ²"""
            signature = {
                'role': role,
                'user': user_name,
                'timestamp': datetime.now().isoformat()
            }
            self.signatures.append(signature)
            self._log_audit(f"é›»å­ç½²å: {role} by {user_name}")
    
        def _log_audit(self, action):
            """ç›£æŸ»è¨¼è·¡ã®è¨˜éŒ²"""
            entry = {
                'timestamp': datetime.now().isoformat(),
                'action': action
            }
            self.audit_trail.append(entry)
    
        def to_dict(self):
            """è¾æ›¸å½¢å¼ã¸ã®å¤‰æ›"""
            return {
                'batch_id': self.batch_id,
                'product_name': self.product_name,
                'manufacturing_date': self.manufacturing_date,
                'process_parameters': self.process_parameters,
                'quality_tests': self.quality_tests,
                'deviations': self.deviations,
                'signatures': self.signatures,
                'audit_trail': self.audit_trail
            }
    
        def export_json(self, filename):
            """JSONå½¢å¼ã§ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(self.to_dict(), f, ensure_ascii=False, indent=2)
            print(f"EBRã‚’ {filename} ã«ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã—ã¾ã—ãŸ")
    
    
    class BatchTrendAnalyzer:
        """ãƒãƒƒãƒãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æã‚¯ãƒ©ã‚¹"""
    
        def __init__(self):
            self.batches = []
    
        def generate_batch_data(self, n_batches=50):
            """ã‚µãƒ³ãƒ—ãƒ«ãƒãƒƒãƒãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆ"""
            np.random.seed(42)
            start_date = datetime(2025, 1, 1)
    
            for i in range(n_batches):
                batch_id = f"B-2025-{i+1:04d}"
                mfg_date = (start_date + timedelta(days=i)).strftime("%Y-%m-%d")
    
                # æ­£å¸¸ãƒãƒƒãƒï¼ˆ1-35ï¼‰
                if i < 35:
                    reaction_temp = np.random.normal(80, 1, 1)[0]
                    reaction_time = np.random.normal(120, 5, 1)[0]
                    yield_value = np.random.normal(95, 2, 1)[0]
                    purity = np.random.normal(99.5, 0.3, 1)[0]
    
                # æ¸©åº¦ç•°å¸¸ãƒãƒƒãƒï¼ˆ36-40ï¼‰
                elif 35 <= i < 40:
                    reaction_temp = np.random.normal(85, 2, 1)[0]  # æ¸©åº¦ä¸Šæ˜‡
                    reaction_time = np.random.normal(120, 5, 1)[0]
                    yield_value = np.random.normal(92, 3, 1)[0]  # åç‡ä½ä¸‹
                    purity = np.random.normal(99.2, 0.5, 1)[0]
    
                # æ™‚é–“ç•°å¸¸ãƒãƒƒãƒï¼ˆ41-45ï¼‰
                elif 40 <= i < 45:
                    reaction_temp = np.random.normal(80, 1, 1)[0]
                    reaction_time = np.random.normal(140, 10, 1)[0]  # æ™‚é–“å»¶é•·
                    yield_value = np.random.normal(93, 2, 1)[0]
                    purity = np.random.normal(99.3, 0.4, 1)[0]
    
                # è¤‡åˆç•°å¸¸ãƒãƒƒãƒï¼ˆ46-50ï¼‰
                else:
                    reaction_temp = np.random.normal(83, 2, 1)[0]
                    reaction_time = np.random.normal(130, 8, 1)[0]
                    yield_value = np.random.normal(90, 3, 1)[0]
                    purity = np.random.normal(99.0, 0.6, 1)[0]
    
                self.batches.append({
                    'batch_id': batch_id,
                    'date': mfg_date,
                    'reaction_temp': reaction_temp,
                    'reaction_time': reaction_time,
                    'yield': yield_value,
                    'purity': purity
                })
    
            return pd.DataFrame(self.batches)
    
        def plot_batch_trends(self, df):
            """ãƒãƒƒãƒãƒˆãƒ¬ãƒ³ãƒ‰ã®å¯è¦–åŒ–"""
            fig, axes = plt.subplots(2, 2, figsize=(14, 10))
    
            batch_indices = range(len(df))
    
            # åå¿œæ¸©åº¦ãƒˆãƒ¬ãƒ³ãƒ‰
            axes[0, 0].plot(batch_indices, df['reaction_temp'], marker='o', color='#11998e',
                            linewidth=1.5, markersize=4)
            axes[0, 0].axhline(y=80, color='green', linestyle='--', linewidth=2, label='ç›®æ¨™å€¤ (80â„ƒ)')
            axes[0, 0].axhline(y=82, color='orange', linestyle='--', linewidth=1, alpha=0.7, label='è­¦å‘Šé™ç•Œ (Â±2â„ƒ)')
            axes[0, 0].axhline(y=78, color='orange', linestyle='--', linewidth=1, alpha=0.7)
            axes[0, 0].set_xlabel('ãƒãƒƒãƒç•ªå·')
            axes[0, 0].set_ylabel('åå¿œæ¸©åº¦ï¼ˆâ„ƒï¼‰')
            axes[0, 0].set_title('åå¿œæ¸©åº¦ãƒˆãƒ¬ãƒ³ãƒ‰', fontsize=12, fontweight='bold')
            axes[0, 0].legend()
            axes[0, 0].grid(alpha=0.3)
    
            # åå¿œæ™‚é–“ãƒˆãƒ¬ãƒ³ãƒ‰
            axes[0, 1].plot(batch_indices, df['reaction_time'], marker='s', color='#38ef7d',
                            linewidth=1.5, markersize=4)
            axes[0, 1].axhline(y=120, color='green', linestyle='--', linewidth=2, label='ç›®æ¨™å€¤ (120åˆ†)')
            axes[0, 1].axhline(y=130, color='orange', linestyle='--', linewidth=1, alpha=0.7, label='è­¦å‘Šé™ç•Œ (Â±10åˆ†)')
            axes[0, 1].axhline(y=110, color='orange', linestyle='--', linewidth=1, alpha=0.7)
            axes[0, 1].set_xlabel('ãƒãƒƒãƒç•ªå·')
            axes[0, 1].set_ylabel('åå¿œæ™‚é–“ï¼ˆåˆ†ï¼‰')
            axes[0, 1].set_title('åå¿œæ™‚é–“ãƒˆãƒ¬ãƒ³ãƒ‰', fontsize=12, fontweight='bold')
            axes[0, 1].legend()
            axes[0, 1].grid(alpha=0.3)
    
            # åç‡ãƒˆãƒ¬ãƒ³ãƒ‰
            axes[1, 0].plot(batch_indices, df['yield'], marker='^', color='#4ecdc4',
                            linewidth=1.5, markersize=4)
            axes[1, 0].axhline(y=95, color='green', linestyle='--', linewidth=2, label='ç›®æ¨™å€¤ (95%)')
            axes[1, 0].axhline(y=90, color='red', linestyle='--', linewidth=1, alpha=0.7, label='ä¸‹é™ (90%)')
            axes[1, 0].set_xlabel('ãƒãƒƒãƒç•ªå·')
            axes[1, 0].set_ylabel('åç‡ï¼ˆ%ï¼‰')
            axes[1, 0].set_title('åç‡ãƒˆãƒ¬ãƒ³ãƒ‰', fontsize=12, fontweight='bold')
            axes[1, 0].legend()
            axes[1, 0].grid(alpha=0.3)
    
            # ç´”åº¦ãƒˆãƒ¬ãƒ³ãƒ‰
            axes[1, 1].plot(batch_indices, df['purity'], marker='D', color='#f38181',
                            linewidth=1.5, markersize=4)
            axes[1, 1].axhline(y=99.5, color='green', linestyle='--', linewidth=2, label='ç›®æ¨™å€¤ (99.5%)')
            axes[1, 1].axhline(y=99.0, color='red', linestyle='--', linewidth=1, alpha=0.7, label='è¦æ ¼ä¸‹é™ (99.0%)')
            axes[1, 1].set_xlabel('ãƒãƒƒãƒç•ªå·')
            axes[1, 1].set_ylabel('ç´”åº¦ï¼ˆ%ï¼‰')
            axes[1, 1].set_title('ç´”åº¦ãƒˆãƒ¬ãƒ³ãƒ‰', fontsize=12, fontweight='bold')
            axes[1, 1].legend()
            axes[1, 1].grid(alpha=0.3)
    
            plt.tight_layout()
            plt.savefig('batch_trend_analysis.png', dpi=300, bbox_inches='tight')
            plt.show()
    
    # å®Ÿè¡Œä¾‹
    print("=" * 60)
    print("é›»å­ãƒãƒƒãƒè¨˜éŒ²ï¼ˆEBRï¼‰ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ")
    print("=" * 60)
    
    # EBRã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®ä½œæˆ
    ebr = ElectronicBatchRecord(
        batch_id="B-2025-0042",
        product_name="ã‚¢ã‚¹ãƒ”ãƒªãƒ³éŒ 100mg",
        manufacturing_date="2025-10-27"
    )
    
    # å·¥ç¨‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®è¨˜éŒ²
    ebr.add_process_parameter("åå¿œ", "æ¸©åº¦", target=80, actual=80.5, unit="â„ƒ", tolerance=2)
    ebr.add_process_parameter("åå¿œ", "æ™‚é–“", target=120, actual=118, unit="åˆ†", tolerance=10)
    ebr.add_process_parameter("ä¹¾ç‡¥", "æ¸©åº¦", target=60, actual=61, unit="â„ƒ", tolerance=3)
    
    # é€¸è„±ã®è¨˜éŒ²ï¼ˆä¾‹ï¼‰
    ebr.add_deviation(
        description="åå¿œæ¸©åº¦ãŒä¸€æ™‚çš„ã«82â„ƒã¾ã§ä¸Šæ˜‡",
        severity="Minor",
        root_cause="æ¸©èª¿ã‚·ã‚¹ãƒ†ãƒ ã®PIDãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ä¸é©åˆ‡",
        capa="PIDãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å†èª¿æ•´ã¨ã‚¢ãƒ©ãƒ¼ãƒ è¨­å®š"
    )
    
    # é›»å­ç½²å
    ebr.add_signature("è£½é€ æ‹…å½“", "ç”°ä¸­å¤ªéƒ")
    ebr.add_signature("å“è³ªä¿è¨¼", "éˆ´æœ¨èŠ±å­")
    
    # ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
    ebr.export_json("ebr_sample.json")
    
    print(f"\nãƒãƒƒãƒID: {ebr.batch_id}")
    print(f"è£½å“å: {ebr.product_name}")
    print(f"è¨˜éŒ²ã•ã‚ŒãŸå·¥ç¨‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {sum(len(params) for params in ebr.process_parameters.values())}")
    print(f"é€¸è„±ä»¶æ•°: {len(ebr.deviations)}")
    print(f"é›»å­ç½²åæ•°: {len(ebr.signatures)}")
    
    # ãƒãƒƒãƒãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ
    print("\n" + "=" * 60)
    print("ãƒãƒƒãƒãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ")
    print("=" * 60)
    
    analyzer = BatchTrendAnalyzer()
    df_batches = analyzer.generate_batch_data(n_batches=50)
    
    print(f"\nåˆ†æå¯¾è±¡ãƒãƒƒãƒæ•°: {len(df_batches)}")
    print(f"æœŸé–“: {df_batches['date'].min()} ~ {df_batches['date'].max()}")
    
    # çµ±è¨ˆã‚µãƒãƒªãƒ¼
    print(f"\nåå¿œæ¸©åº¦: å¹³å‡ {df_batches['reaction_temp'].mean():.2f}â„ƒ, æ¨™æº–åå·® {df_batches['reaction_temp'].std():.2f}â„ƒ")
    print(f"åå¿œæ™‚é–“: å¹³å‡ {df_batches['reaction_time'].mean():.1f}åˆ†, æ¨™æº–åå·® {df_batches['reaction_time'].std():.1f}åˆ†")
    print(f"åç‡: å¹³å‡ {df_batches['yield'].mean():.2f}%, æ¨™æº–åå·® {df_batches['yield'].std():.2f}%")
    print(f"ç´”åº¦: å¹³å‡ {df_batches['purity'].mean():.2f}%, æ¨™æº–åå·® {df_batches['purity'].std():.2f}%")
    
    # ãƒˆãƒ¬ãƒ³ãƒ‰å¯è¦–åŒ–
    analyzer.plot_batch_trends(df_batches)
    

**å®Ÿè£…ã®ãƒã‚¤ãƒ³ãƒˆ:**

  * GMPæº–æ‹ ã®EBRãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«ï¼ˆå·¥ç¨‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã€é€¸è„±ã€é›»å­ç½²åï¼‰
  * ç›£æŸ»è¨¼è·¡ã®è‡ªå‹•è¨˜éŒ²æ©Ÿèƒ½
  * è¨±å®¹ç¯„å›²ãƒã‚§ãƒƒã‚¯ã®è‡ªå‹•åŒ–
  * ãƒãƒƒãƒãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æã«ã‚ˆã‚‹ç•°å¸¸æ¤œå‡ºã®å¯è¦–åŒ–
  * JSONå½¢å¼ã§ã®ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆï¼ˆç›¸äº’é‹ç”¨æ€§ï¼‰

## ğŸ” 2.2 æ©Ÿæ¢°å­¦ç¿’ã«ã‚ˆã‚‹ç•°å¸¸ãƒãƒƒãƒæ¤œå‡º

### ç•°å¸¸æ¤œå‡ºã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ

ãƒãƒƒãƒè£½é€ ã«ãŠã‘ã‚‹ç•°å¸¸æ¤œå‡ºã«ã¯ã€ä»¥ä¸‹ã®æ©Ÿæ¢°å­¦ç¿’æ‰‹æ³•ãŒæœ‰åŠ¹ã§ã™ï¼š

  * **Isolation Forest** : æ•™å¸«ãªã—ç•°å¸¸æ¤œå‡ºã€å¤šå¤‰é‡ãƒ‡ãƒ¼ã‚¿ã«æœ‰åŠ¹
  * **One-Class SVM** : æ­£å¸¸ãƒ‡ãƒ¼ã‚¿ã®ã¿ã§å­¦ç¿’ã€å¢ƒç•Œæ±ºå®š
  * **Autoencoder** : æ·±å±¤å­¦ç¿’ã«ã‚ˆã‚‹å†æ§‹æˆèª¤å·®ãƒ™ãƒ¼ã‚¹ã®æ¤œå‡º
  * **Statistical Process Control** : Hotelling's TÂ², MEWMA

### ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹2.2: Isolation Forestã«ã‚ˆã‚‹ç•°å¸¸ãƒãƒƒãƒæ¤œå‡º
    
    
    import numpy as np
    import pandas as pd
    import matplotlib.pyplot as plt
    from sklearn.ensemble import IsolationForest
    from sklearn.preprocessing import StandardScaler
    from sklearn.decomposition import PCA
    import warnings
    warnings.filterwarnings('ignore')
    
    plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'DejaVu Sans']
    plt.rcParams['axes.unicode_minus'] = False
    
    class AnomalyBatchDetector:
        """ç•°å¸¸ãƒãƒƒãƒæ¤œå‡ºã‚·ã‚¹ãƒ†ãƒ """
    
        def __init__(self, contamination=0.1):
            """
            Args:
                contamination: ç•°å¸¸ãƒ‡ãƒ¼ã‚¿ã®æ¨å®šå‰²åˆï¼ˆ0.1 = 10%ï¼‰
            """
            self.contamination = contamination
            self.scaler = StandardScaler()
            self.model = IsolationForest(
                contamination=contamination,
                random_state=42,
                n_estimators=100
            )
            self.pca = PCA(n_components=2)
    
        def train(self, df, feature_columns):
            """
            ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´
    
            Args:
                df: ãƒãƒƒãƒãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
                feature_columns: ç‰¹å¾´é‡ã‚«ãƒ©ãƒ ã®ãƒªã‚¹ãƒˆ
            """
            X = df[feature_columns].values
            X_scaled = self.scaler.fit_transform(X)
    
            self.model.fit(X_scaled)
    
            # ç•°å¸¸ã‚¹ã‚³ã‚¢ã®è¨ˆç®—
            anomaly_scores = self.model.score_samples(X_scaled)
            predictions = self.model.predict(X_scaled)
    
            # PCAã§2æ¬¡å…ƒã«å¤‰æ›ï¼ˆå¯è¦–åŒ–ç”¨ï¼‰
            X_pca = self.pca.fit_transform(X_scaled)
    
            return anomaly_scores, predictions, X_pca
    
        def detect_anomalies(self, df, feature_columns, anomaly_scores, predictions):
            """
            ç•°å¸¸ãƒãƒƒãƒã®ç‰¹å®š
    
            Args:
                df: ãƒãƒƒãƒãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
                feature_columns: ç‰¹å¾´é‡ã‚«ãƒ©ãƒ 
                anomaly_scores: ç•°å¸¸ã‚¹ã‚³ã‚¢
                predictions: äºˆæ¸¬çµæœï¼ˆ-1: ç•°å¸¸, 1: æ­£å¸¸ï¼‰
    
            Returns:
                ç•°å¸¸ãƒãƒƒãƒã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
            """
            df_result = df.copy()
            df_result['anomaly_score'] = anomaly_scores
            df_result['is_anomaly'] = predictions == -1
    
            # ç•°å¸¸ãƒãƒƒãƒã®æŠ½å‡º
            anomalies = df_result[df_result['is_anomaly']].copy()
    
            # ç•°å¸¸ã®é‡è¦åº¦ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼ˆã‚¹ã‚³ã‚¢ãŒä½ã„ã»ã©ç•°å¸¸ï¼‰
            anomalies = anomalies.sort_values('anomaly_score')
    
            return df_result, anomalies
    
        def plot_anomaly_detection(self, df_result, X_pca, feature_columns):
            """ç•°å¸¸æ¤œå‡ºçµæœã®å¯è¦–åŒ–"""
            fig, axes = plt.subplots(2, 2, figsize=(14, 10))
    
            # PCAç©ºé–“ã§ã®ãƒ—ãƒ­ãƒƒãƒˆ
            normal_mask = ~df_result['is_anomaly']
            anomaly_mask = df_result['is_anomaly']
    
            axes[0, 0].scatter(X_pca[normal_mask, 0], X_pca[normal_mask, 1],
                               c='green', s=30, alpha=0.6, label='æ­£å¸¸ãƒãƒƒãƒ')
            axes[0, 0].scatter(X_pca[anomaly_mask, 0], X_pca[anomaly_mask, 1],
                               c='red', s=100, alpha=0.8, marker='X', label='ç•°å¸¸ãƒãƒƒãƒ')
            axes[0, 0].set_xlabel(f'ç¬¬1ä¸»æˆåˆ† (å¯„ä¸ç‡: {self.pca.explained_variance_ratio_[0]:.1%})')
            axes[0, 0].set_ylabel(f'ç¬¬2ä¸»æˆåˆ† (å¯„ä¸ç‡: {self.pca.explained_variance_ratio_[1]:.1%})')
            axes[0, 0].set_title('PCAç©ºé–“ã§ã®ç•°å¸¸æ¤œå‡º', fontsize=12, fontweight='bold')
            axes[0, 0].legend()
            axes[0, 0].grid(alpha=0.3)
    
            # ç•°å¸¸ã‚¹ã‚³ã‚¢åˆ†å¸ƒ
            axes[0, 1].hist(df_result[normal_mask]['anomaly_score'], bins=30,
                            alpha=0.6, label='æ­£å¸¸', color='green')
            axes[0, 1].hist(df_result[anomaly_mask]['anomaly_score'], bins=30,
                            alpha=0.6, label='ç•°å¸¸', color='red')
            axes[0, 1].set_xlabel('ç•°å¸¸ã‚¹ã‚³ã‚¢ï¼ˆå°ã•ã„ã»ã©ç•°å¸¸ï¼‰')
            axes[0, 1].set_ylabel('é »åº¦')
            axes[0, 1].set_title('ç•°å¸¸ã‚¹ã‚³ã‚¢åˆ†å¸ƒ', fontsize=12, fontweight='bold')
            axes[0, 1].legend()
            axes[0, 1].grid(alpha=0.3)
    
            # æ™‚ç³»åˆ—ã§ã®ç•°å¸¸æ¤œå‡º
            batch_indices = range(len(df_result))
            colors = ['red' if x else 'green' for x in df_result['is_anomaly']]
    
            axes[1, 0].scatter(batch_indices, df_result['anomaly_score'],
                               c=colors, s=50, alpha=0.7)
            axes[1, 0].axhline(y=df_result['anomaly_score'].quantile(0.1), color='orange',
                               linestyle='--', linewidth=2, label='ç•°å¸¸é–¾å€¤')
            axes[1, 0].set_xlabel('ãƒãƒƒãƒç•ªå·')
            axes[1, 0].set_ylabel('ç•°å¸¸ã‚¹ã‚³ã‚¢')
            axes[1, 0].set_title('æ™‚ç³»åˆ—ç•°å¸¸æ¤œå‡º', fontsize=12, fontweight='bold')
            axes[1, 0].legend()
            axes[1, 0].grid(alpha=0.3)
    
            # ç‰¹å¾´é‡åˆ¥ã®ç•°å¸¸ãƒãƒƒãƒåˆ†å¸ƒ
            if len(feature_columns) >= 2:
                feat1, feat2 = feature_columns[0], feature_columns[1]
    
                axes[1, 1].scatter(df_result[normal_mask][feat1], df_result[normal_mask][feat2],
                                   c='green', s=30, alpha=0.6, label='æ­£å¸¸ãƒãƒƒãƒ')
                axes[1, 1].scatter(df_result[anomaly_mask][feat1], df_result[anomaly_mask][feat2],
                                   c='red', s=100, alpha=0.8, marker='X', label='ç•°å¸¸ãƒãƒƒãƒ')
                axes[1, 1].set_xlabel(feat1)
                axes[1, 1].set_ylabel(feat2)
                axes[1, 1].set_title(f'{feat1} vs {feat2}', fontsize=12, fontweight='bold')
                axes[1, 1].legend()
                axes[1, 1].grid(alpha=0.3)
    
            plt.tight_layout()
            plt.savefig('anomaly_batch_detection.png', dpi=300, bbox_inches='tight')
            plt.show()
    
        def generate_anomaly_report(self, anomalies, feature_columns):
            """ç•°å¸¸ãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ"""
            print("\n" + "=" * 60)
            print("ç•°å¸¸ãƒãƒƒãƒæ¤œå‡ºãƒ¬ãƒãƒ¼ãƒˆ")
            print("=" * 60)
    
            for idx, row in anomalies.iterrows():
                print(f"\nğŸš¨ ãƒãƒƒãƒID: {row['batch_id']}")
                print(f"   è£½é€ æ—¥: {row['date']}")
                print(f"   ç•°å¸¸ã‚¹ã‚³ã‚¢: {row['anomaly_score']:.4f}")
                print(f"   å·¥ç¨‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:")
    
                for feat in feature_columns:
                    print(f"     - {feat}: {row[feat]:.2f}")
    
    # å®Ÿè¡Œä¾‹
    print("=" * 60)
    print("ç•°å¸¸ãƒãƒƒãƒæ¤œå‡ºã‚·ã‚¹ãƒ†ãƒ ï¼ˆIsolation Forestï¼‰")
    print("=" * 60)
    
    # ãƒãƒƒãƒãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆï¼ˆå‰ã®ã‚³ãƒ¼ãƒ‰ä¾‹ã‹ã‚‰å†åˆ©ç”¨ï¼‰
    analyzer = BatchTrendAnalyzer()
    df_batches = analyzer.generate_batch_data(n_batches=50)
    
    # ç‰¹å¾´é‡ã®å®šç¾©
    feature_columns = ['reaction_temp', 'reaction_time', 'yield', 'purity']
    
    # ç•°å¸¸æ¤œå‡ºãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´
    detector = AnomalyBatchDetector(contamination=0.15)  # 15%ãŒç•°å¸¸ã¨ä»®å®š
    anomaly_scores, predictions, X_pca = detector.train(df_batches, feature_columns)
    
    # ç•°å¸¸ãƒãƒƒãƒã®æ¤œå‡º
    df_result, anomalies = detector.detect_anomalies(df_batches, feature_columns, anomaly_scores, predictions)
    
    print(f"\nç·ãƒãƒƒãƒæ•°: {len(df_batches)}")
    print(f"æ¤œå‡ºã•ã‚ŒãŸç•°å¸¸ãƒãƒƒãƒæ•°: {len(anomalies)} ({len(anomalies)/len(df_batches)*100:.1f}%)")
    
    # å¯è¦–åŒ–
    detector.plot_anomaly_detection(df_result, X_pca, feature_columns)
    
    # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    detector.generate_anomaly_report(anomalies.head(5), feature_columns)
    

**å®Ÿè£…ã®ãƒã‚¤ãƒ³ãƒˆ:**

  * æ•™å¸«ãªã—å­¦ç¿’ã«ã‚ˆã‚‹æœªçŸ¥ã®ç•°å¸¸ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡º
  * å¤šå¤‰é‡ãƒ‡ãƒ¼ã‚¿ã®çµ±åˆçš„ãªè©•ä¾¡ï¼ˆæ¸©åº¦ã€æ™‚é–“ã€åç‡ã€ç´”åº¦ï¼‰
  * PCAã«ã‚ˆã‚‹é«˜æ¬¡å…ƒãƒ‡ãƒ¼ã‚¿ã®å¯è¦–åŒ–
  * ç•°å¸¸ã‚¹ã‚³ã‚¢ã«ã‚ˆã‚‹å„ªå…ˆåº¦ä»˜ã‘
  * è‡ªå‹•ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆæ©Ÿèƒ½

## ğŸ“š ã¾ã¨ã‚

æœ¬ç« ã§ã¯ã€é›»å­ãƒãƒƒãƒè¨˜éŒ²ã®è§£æã¨é€¸è„±ç®¡ç†ã«ã¤ã„ã¦å­¦ã³ã¾ã—ãŸã€‚

### ä¸»è¦ãªãƒã‚¤ãƒ³ãƒˆ

  * GMPæº–æ‹ ã®EBRãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«ã¨ç›£æŸ»è¨¼è·¡ã®å®Ÿè£…
  * ãƒãƒƒãƒãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æã«ã‚ˆã‚‹å·¥ç¨‹å¤‰å‹•ã®å¯è¦–åŒ–
  * æ©Ÿæ¢°å­¦ç¿’ï¼ˆIsolation Forestï¼‰ã«ã‚ˆã‚‹ç•°å¸¸ãƒãƒƒãƒã®è‡ªå‹•æ¤œå‡º
  * å¤šå¤‰é‡ãƒ‡ãƒ¼ã‚¿è§£æã«ã‚ˆã‚‹åŒ…æ‹¬çš„ãªå“è³ªè©•ä¾¡
  * è‡ªå‹•ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã«ã‚ˆã‚‹ä½œæ¥­åŠ¹ç‡åŒ–

**ğŸ¯ æ¬¡ç« äºˆå‘Š**  
ç¬¬3ç« ã§ã¯ã€ãƒ—ãƒ­ã‚»ã‚¹åˆ†ææŠ€è¡“ï¼ˆPATï¼‰ã¨ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å“è³ªç®¡ç†ã«ã¤ã„ã¦å­¦ã³ã¾ã™ã€‚ NIR/Ramanåˆ†å…‰åˆ†æã€å¤šå¤‰é‡çµ±è¨ˆçš„ãƒ—ãƒ­ã‚»ã‚¹ç®¡ç†ï¼ˆMSPCï¼‰ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒªãƒªãƒ¼ã‚¹è©¦é¨“ï¼ˆRTRTï¼‰ãªã©ã€ ã‚ˆã‚Šé«˜åº¦ãªãƒ—ãƒ­ã‚»ã‚¹ç®¡ç†æŠ€è¡“ã‚’ç¿’å¾—ã—ã¾ã™ã€‚ 

[â† ç¬¬1ç« : GMPçµ±è¨ˆçš„å“è³ªç®¡ç†](<chapter-1.html>) [ç¬¬3ç« : PATã¨ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å“è³ªç®¡ç† â†’](<chapter-3.html>)

### å…è²¬äº‹é …

  * æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯æ•™è‚²ãƒ»ç ”ç©¶ãƒ»æƒ…å ±æä¾›ã®ã¿ã‚’ç›®çš„ã¨ã—ã¦ãŠã‚Šã€å°‚é–€çš„ãªåŠ©è¨€(æ³•å¾‹ãƒ»ä¼šè¨ˆãƒ»æŠ€è¡“çš„ä¿è¨¼ãªã©)ã‚’æä¾›ã™ã‚‹ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚
  * æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŠã‚ˆã³ä»˜éšã™ã‚‹Code examplesã¯ã€Œç¾çŠ¶æœ‰å§¿(AS IS)ã€ã§æä¾›ã•ã‚Œã€æ˜ç¤ºã¾ãŸã¯é»™ç¤ºã‚’å•ã‚ãšã€å•†å“æ€§ã€ç‰¹å®šç›®çš„é©åˆæ€§ã€æ¨©åˆ©éä¾µå®³ã€æ­£ç¢ºæ€§ãƒ»å®Œå…¨æ€§ã€å‹•ä½œãƒ»å®‰å…¨æ€§ç­‰ã„ã‹ãªã‚‹ä¿è¨¼ã‚‚ã—ã¾ã›ã‚“ã€‚
  * å¤–éƒ¨ãƒªãƒ³ã‚¯ã€ç¬¬ä¸‰è€…ãŒæä¾›ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ»ãƒ„ãƒ¼ãƒ«ãƒ»ãƒ©ã‚¤ãƒ–ãƒ©ãƒªç­‰ã®å†…å®¹ãƒ»å¯ç”¨æ€§ãƒ»å®‰å…¨æ€§ã«ã¤ã„ã¦ã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯ä¸€åˆ‡ã®è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚
  * æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®åˆ©ç”¨ãƒ»å®Ÿè¡Œãƒ»è§£é‡ˆã«ã‚ˆã‚Šç›´æ¥çš„ãƒ»é–“æ¥çš„ãƒ»ä»˜éšçš„ãƒ»ç‰¹åˆ¥ãƒ»çµæœçš„ãƒ»æ‡²ç½°çš„æå®³ãŒç”Ÿã˜ãŸå ´åˆã§ã‚‚ã€é©ç”¨æ³•ã§è¨±å®¹ã•ã‚Œã‚‹æœ€å¤§é™ã®ç¯„å›²ã§ã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚
  * æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å†…å®¹ã¯ã€äºˆå‘Šãªãå¤‰æ›´ãƒ»æ›´æ–°ãƒ»æä¾›åœæ­¢ã•ã‚Œã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚
  * æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®è‘—ä½œæ¨©ãƒ»ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯æ˜è¨˜ã•ã‚ŒãŸæ¡ä»¶(ä¾‹: CC BY 4.0)ã«å¾“ã„ã¾ã™ã€‚å½“è©²ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯é€šå¸¸ã€ç„¡ä¿è¨¼æ¡é …ã‚’å«ã¿ã¾ã™ã€‚
