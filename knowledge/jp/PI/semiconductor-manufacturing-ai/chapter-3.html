<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ç¬¬3ç«  æ­©ç•™ã¾ã‚Šå‘ä¸Šã¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ– | åŠå°ä½“è£½é€ AI | ãƒãƒ†ãƒªã‚¢ãƒ«ã‚ºã‚¤ãƒ³ãƒ•ã‚©ãƒãƒ†ã‚£ã‚¯ã‚¹å…¥é–€</title>
    <meta name="description" content="åŠå°ä½“è£½é€ ã«ãŠã‘ã‚‹æ­©ç•™ã¾ã‚Šå‘ä¸Šã®ãŸã‚ã®AIæœ€é©åŒ–æ‰‹æ³•ã‚’å­¦ã³ã¾ã™ã€‚Bayesian Optimizationã€å¤šç›®çš„æœ€é©åŒ–ã€å¼·åŒ–å­¦ç¿’ã€å› æœæ¨è«–ã‚’Pythonã§å®Ÿè£…ã—ã€ãƒ—ãƒ­ã‚»ã‚¹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æœ€é©åŒ–ã—ã¾ã™ã€‚">
    <link rel="stylesheet" href="/assets/css/variables.css">
    <link rel="stylesheet" href="/assets/css/reset.css">
    <link rel="stylesheet" href="/assets/css/base.css">
    <link rel="stylesheet" href="/assets/css/components.css">
    <link rel="stylesheet" href="/assets/css/layout.css">
    <link rel="stylesheet" href="/assets/css/responsive.css">
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

    <style>
        /* Locale Switcher Styles */
        .locale-switcher {
            display: flex;
            align-items: center;
            gap: 0.5rem;
            padding: 0.5rem 1rem;
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
            border-radius: 6px;
            font-size: 0.9rem;
            margin-bottom: 1rem;
            box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);
        }

        .current-locale {
            font-weight: 600;
            color: #7b2cbf;
            display: flex;
            align-items: center;
            gap: 0.25rem;
        }

        .locale-separator {
            color: #adb5bd;
            font-weight: 300;
        }

        .locale-link {
            color: #f093fb;
            text-decoration: none;
            font-weight: 500;
            transition: all 0.2s ease;
            display: flex;
            align-items: center;
            gap: 0.25rem;
            padding: 0.2rem 0.5rem;
            border-radius: 4px;
        }

        .locale-link:hover {
            background: rgba(240, 147, 251, 0.1);
            color: #d07be8;
            transform: translateY(-1px);
        }

        .locale-meta {
            color: #868e96;
            font-size: 0.85rem;
            font-style: italic;
            margin-left: auto;
        }

        @media (max-width: 768px) {
            .locale-switcher {
                font-size: 0.85rem;
                padding: 0.4rem 0.8rem;
            }
            .locale-meta {
                display: none;
            }
        }
    </style>
</head>
<body>
    <div class="locale-switcher">
<span class="current-locale">ğŸŒ JP</span>
<span class="locale-separator">|</span>
<a href="../../../en/PI/semiconductor-manufacturing-ai/chapter-3.html" class="locale-link">ğŸ‡¬ğŸ‡§ EN</a>
<span class="locale-separator">|</span>
<span class="locale-meta">Last sync: 2025-11-16</span>
</div>
<header class="site-header">
        <div class="container">
            <div class="header-content">
                <h1 class="site-title"><a href="/jp/">æ©‹æœ¬ç ”ç©¶å®¤</a></h1>
                <nav class="main-nav">
                    <ul>
                        <li><a href="/jp/">ãƒ›ãƒ¼ãƒ </a></li>
                        <li><a href="/jp/research.html">ç ”ç©¶å†…å®¹</a></li>
                        <li><a href="/jp/publications.html">ç ”ç©¶æ¥­ç¸¾</a></li>
                        <li><a href="../../mi-introduction/">çŸ¥è­˜ãƒ™ãƒ¼ã‚¹</a></li>
                        <li><a href="/jp/news.html">ãƒ‹ãƒ¥ãƒ¼ã‚¹</a></li>
                        <li><a href="/jp/members.html">ãƒ¡ãƒ³ãƒãƒ¼</a></li>
                        <li><a href="/jp/contact.html">ãŠå•ã„åˆã‚ã›</a></li>
                        <li><a href="/en/">English</a></li>
                    </ul>
                </nav>
            </div>
        </div>
    </header>

    <main class="article-content">
        <article class="container">
            <div class="breadcrumb">
                <a href="/jp/">ãƒ›ãƒ¼ãƒ </a> &gt;
                <a href="../../mi-introduction/">çŸ¥è­˜ãƒ™ãƒ¼ã‚¹</a> &gt;
                <a href="../../PI/">ãƒ—ãƒ­ã‚»ã‚¹ã‚¤ãƒ³ãƒ•ã‚©ãƒãƒ†ã‚£ã‚¯ã‚¹</a> &gt;
                <a href="../../PI/semiconductor-manufacturing-ai/">åŠå°ä½“è£½é€ AI</a> &gt;
                ç¬¬3ç« 
            </div>

            <header class="article-header">
                <h1 class="gradient-text" style="background: linear-gradient(135deg, #11998e 0%, #38ef7d 100%); -webkit-background-clip: text; -webkit-text-fill-color: transparent;">ç¬¬3ç«  æ­©ç•™ã¾ã‚Šå‘ä¸Šã¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–</h1>
                <p class="article-meta">åŠå°ä½“è£½é€ AI - Bayesian Optimizationãƒ»å¤šç›®çš„æœ€é©åŒ–ãƒ»å¼·åŒ–å­¦ç¿’</p>
            </header>

            <section class="introduction">
                <h2>å­¦ç¿’ç›®æ¨™</h2>
                <ul>
                    <li>Bayesian Optimizationã«ã‚ˆã‚‹åŠ¹ç‡çš„ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¢ç´¢æ‰‹æ³•ã‚’ç¿’å¾—ã™ã‚‹</li>
                    <li>å¤šç›®çš„æœ€é©åŒ–ã§æ­©ç•™ã¾ã‚Šãƒ»ã‚³ã‚¹ãƒˆãƒ»ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã‚’åŒæ™‚æ”¹å–„ã™ã‚‹æ–¹æ³•ã‚’ç†è§£ã™ã‚‹</li>
                    <li>å¼·åŒ–å­¦ç¿’ã«ã‚ˆã‚‹ãƒ—ãƒ­ã‚»ã‚¹åˆ¶å¾¡ã®å®Ÿè£…æ–¹æ³•ã‚’å­¦ã¶</li>
                    <li>å› æœæ¨è«–ã§æ­©ç•™ã¾ã‚Šä½ä¸‹ã®çœŸå› ã‚’ç‰¹å®šã™ã‚‹æ‰‹æ³•ã‚’ç¿’å¾—ã™ã‚‹</li>
                    <li>æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®è§£é‡ˆæ€§ã¨SHAPå€¤ã®æ´»ç”¨æ³•ã‚’ç†è§£ã™ã‚‹</li>
                </ul>
            </section>

            <section>
                <h2>3.1 åŠå°ä½“è£½é€ ã«ãŠã‘ã‚‹æ­©ç•™ã¾ã‚Šæœ€é©åŒ–ã®èª²é¡Œ</h2>

                <h3>3.1.1 æ­©ç•™ã¾ã‚Šå‘ä¸Šã®çµŒæ¸ˆçš„ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆ</h3>
                <p>åŠå°ä½“è£½é€ ã«ãŠã„ã¦ã€æ­©ç•™ã¾ã‚Š1%ã®æ”¹å–„ãŒæ•°å„„å††ã®åˆ©ç›Šå¢—åŠ ã«ã¤ãªãŒã‚‹ã“ã¨ã¯çã—ãã‚ã‚Šã¾ã›ã‚“ã€‚ä¸»è¦ãªèª²é¡Œã¯ï¼š</p>
                <ul>
                    <li><strong>å¤šå¤‰æ•°ä¾å­˜æ€§</strong>: 100ä»¥ä¸Šã®ãƒ—ãƒ­ã‚»ã‚¹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒè¤‡é›‘ã«ç›¸äº’ä½œç”¨</li>
                    <li><strong>è©•ä¾¡ã‚³ã‚¹ãƒˆ</strong>: 1å›ã®å®Ÿé¨“ã«æ•°æ™‚é–“ï½æ•°æ—¥ã€æ•°ç™¾ä¸‡å††ã®ã‚³ã‚¹ãƒˆ</li>
                    <li><strong>éç·šå½¢æ€§</strong>: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨æ­©ç•™ã¾ã‚Šã®é–¢ä¿‚ã¯é«˜åº¦ã«éç·šå½¢</li>
                    <li><strong>ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•</strong>: æ­©ç•™ã¾ã‚Šãƒ»ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆãƒ»ã‚³ã‚¹ãƒˆã¯ç«¶åˆé–¢ä¿‚</li>
                    <li><strong>ãƒã‚¤ã‚º</strong>: è£…ç½®å¤‰å‹•ãƒ»ç’°å¢ƒå¤‰å‹•ã«ã‚ˆã‚‹æ¸¬å®šèª¤å·®</li>
                </ul>

                <h3>3.1.2 å¾“æ¥æ‰‹æ³•ã®é™ç•Œ</h3>
                <p>å¾“æ¥ã®DOEï¼ˆDesign of Experimentsï¼‰æ‰‹æ³•ã®èª²é¡Œï¼š</p>
                <div style="background: #f8f9fa; padding: 1rem; border-radius: 8px; margin: 1rem 0;">
                    <p><strong>å®Ÿé¨“å›æ•°ã®çˆ†ç™º</strong>: 10ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿Ã—3æ°´æº– = 59,049é€šã‚Šï¼ˆå…¨æ¢ç´¢ä¸å¯èƒ½ï¼‰</p>
                    <p><strong>å±€æ‰€æœ€é©</strong>: ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒã¯å±€æ‰€æœ€é©ã«é™¥ã‚Šã‚„ã™ã„</p>
                    <p><strong>åˆæœŸçŸ¥è­˜ã®ç„¡è¦–</strong>: éå»ã®å®Ÿé¨“ãƒ‡ãƒ¼ã‚¿ã‚’æ´»ç”¨ã§ããªã„</p>
                    <p><strong>æ¢ç´¢åŠ¹ç‡ã®ä½ã•</strong>: æœ‰æœ›é ˜åŸŸã®é›†ä¸­æ¢ç´¢ãŒã§ããªã„</p>
                </div>

                <h3>3.1.3 AIæœ€é©åŒ–ã®ãƒ¡ãƒªãƒƒãƒˆ</h3>
                <p>Bayesian Optimizationç­‰ã®AIæ‰‹æ³•ã«ã‚ˆã‚‹æ”¹å–„ï¼š</p>
                <ul>
                    <li><strong>å®Ÿé¨“å›æ•°å‰Šæ¸›</strong>: å¾“æ¥ã®1/10ä»¥ä¸‹ã®å®Ÿé¨“ã§æœ€é©è§£ç™ºè¦‹</li>
                    <li><strong>å¤§åŸŸçš„æœ€é©åŒ–</strong>: å±€æ‰€æœ€é©ã‹ã‚‰è„±å‡ºã—çœŸã®æœ€é©è§£ã‚’ç™ºè¦‹</li>
                    <li><strong>çŸ¥è­˜ã®è“„ç©</strong>: éå»ã®å®Ÿé¨“ãƒ‡ãƒ¼ã‚¿ã‚’æ´»ç”¨ã—å­¦ç¿’</li>
                    <li><strong>ä¸ç¢ºå®Ÿæ€§ã®å®šé‡åŒ–</strong>: æ¬¡ã®å®Ÿé¨“å€™è£œã‚’ç†è«–çš„ã«é¸æŠ</li>
                </ul>
            </section>

            <section>
                <h2>3.2 Bayesian Optimizationã«ã‚ˆã‚‹ãƒ—ãƒ­ã‚»ã‚¹æœ€é©åŒ–</h2>

                <h3>3.2.1 Bayesian Optimizationã®åŸç†</h3>
                <p>Bayesian Optimization (BO) ã¯ã€é«˜ã‚³ã‚¹ãƒˆãƒ»ãƒ–ãƒ©ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹é–¢æ•°ã®æœ€é©åŒ–ã«ç‰¹åŒ–ã—ãŸæ‰‹æ³•ã§ã™ï¼š</p>

                <div style="background: #f8f9fa; padding: 1rem; border-radius: 8px; margin: 1rem 0;">
                    <p><strong>ã‚µãƒ­ã‚²ãƒ¼ãƒˆãƒ¢ãƒ‡ãƒ« (Surrogate Model)</strong></p>
                    <p>Gaussian Process (GP) ã§çœŸã®ç›®çš„é–¢æ•°ã‚’è¿‘ä¼¼ã—ã¾ã™ï¼š</p>
                    <p>$$f(x) \sim \mathcal{GP}(m(x), k(x, x'))$$</p>
                    <p>ã“ã“ã§ã€\(m(x)\)ã¯å¹³å‡é–¢æ•°ã€\(k(x, x')\)ã¯ã‚«ãƒ¼ãƒãƒ«é–¢æ•°ã§ã™ã€‚</p>

                    <p><strong>ç²å¾—é–¢æ•° (Acquisition Function)</strong></p>
                    <p>æ¬¡ã«è©•ä¾¡ã™ã¹ãç‚¹ã‚’æ±ºå®šã—ã¾ã™ã€‚ä»£è¡¨çš„ãªç²å¾—é–¢æ•°ï¼š</p>

                    <p><em>Expected Improvement (EI)</em></p>
                    <p>$$\text{EI}(x) = \mathbb{E}[\max(f(x) - f(x^+), 0)]$$</p>
                    <p>\(x^+\): ç¾åœ¨ã®æœ€è‰¯ç‚¹</p>

                    <p><em>Upper Confidence Bound (UCB)</em></p>
                    <p>$$\text{UCB}(x) = \mu(x) + \kappa \sigma(x)$$</p>
                    <p>\(\kappa\): æ¢ç´¢ãƒ»æ´»ç”¨ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿</p>
                </div>

                <h3>3.2.2 ã‚¨ãƒƒãƒãƒ³ã‚°ãƒ—ãƒ­ã‚»ã‚¹æœ€é©åŒ–ã®å®Ÿè£…</h3>
                <p>ä»¥ä¸‹ã¯ã€ãƒ—ãƒ©ã‚ºãƒã‚¨ãƒƒãƒãƒ³ã‚°ã®æ­©ç•™ã¾ã‚Šæœ€é©åŒ–ä¾‹ã§ã™ï¼š</p>

<pre><code class="language-python">import numpy as np
from scipy.stats import norm
from scipy.optimize import minimize
from sklearn.gaussian_process import GaussianProcessRegressor
from sklearn.gaussian_process.kernels import RBF, ConstantKernel, Matern, WhiteKernel
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D

class BayesianOptimizationYield:
    """
    Bayesian Optimizationã«ã‚ˆã‚‹æ­©ç•™ã¾ã‚Šæœ€é©åŒ–

    å¯¾è±¡ãƒ—ãƒ­ã‚»ã‚¹: ãƒ—ãƒ©ã‚ºãƒã‚¨ãƒƒãƒãƒ³ã‚°
    æœ€é©åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:
    - RFãƒ‘ãƒ¯ãƒ¼ (100-400 W)
    - åœ§åŠ› (10-100 mTorr)
    - ã‚¬ã‚¹æµé‡ (50-200 sccm)
    - æ¸©åº¦ (20-80 Â°C)

    ç›®çš„: æ­©ç•™ã¾ã‚Šæœ€å¤§åŒ– (è©•ä¾¡ã‚³ã‚¹ãƒˆã‚’æœ€å°é™ã«)
    """

    def __init__(self, param_bounds, n_init=10, acquisition='ei', kappa=2.576):
        """
        Parameters:
        -----------
        param_bounds : list of tuples
            å„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æ¢ç´¢ç¯„å›² [(min1, max1), (min2, max2), ...]
        n_init : int
            åˆæœŸãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ•°
        acquisition : str
            ç²å¾—é–¢æ•° ('ei', 'ucb', 'poi')
        kappa : float
            UCBã®Îºãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ (æ¢ç´¢ã®åº¦åˆã„)
        """
        self.param_bounds = np.array(param_bounds)
        self.dim = len(param_bounds)
        self.n_init = n_init
        self.acquisition = acquisition
        self.kappa = kappa

        # è¦³æ¸¬ãƒ‡ãƒ¼ã‚¿
        self.X_observed = np.empty((0, self.dim))
        self.y_observed = np.empty(0)

        # Gaussian Processè¨­å®š
        # Matternã‚«ãƒ¼ãƒãƒ« (Î½=2.5) + ãƒã‚¤ã‚ºé …
        kernel = (
            ConstantKernel(1.0, (1e-3, 1e3)) *
            Matern(length_scale=np.ones(self.dim), nu=2.5,
                   length_scale_bounds=(1e-2, 1e2)) +
            WhiteKernel(noise_level=1e-5, noise_level_bounds=(1e-10, 1e-1))
        )

        self.gp = GaussianProcessRegressor(
            kernel=kernel,
            n_restarts_optimizer=10,
            alpha=1e-6,
            normalize_y=True
        )

        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åï¼ˆå¯èª­æ€§å‘ä¸Šï¼‰
        self.param_names = ['RF_Power(W)', 'Pressure(mTorr)',
                           'Gas_Flow(sccm)', 'Temperature(C)']

    def _normalize(self, X):
        """ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’[0,1]ã«æ­£è¦åŒ–"""
        return (X - self.param_bounds[:, 0]) / (
            self.param_bounds[:, 1] - self.param_bounds[:, 0]
        )

    def _denormalize(self, X_norm):
        """[0,1]ã‹ã‚‰å…ƒã®ã‚¹ã‚±ãƒ¼ãƒ«ã«æˆ»ã™"""
        return X_norm * (self.param_bounds[:, 1] - self.param_bounds[:, 0]
                        ) + self.param_bounds[:, 0]

    def objective_function(self, params):
        """
        çœŸã®ç›®çš„é–¢æ•°ï¼ˆå®Ÿéš›ã¯å®Ÿé¨“ã§æ¸¬å®šï¼‰

        ã“ã“ã§ã¯ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç”¨ã®ãƒ€ãƒŸãƒ¼é–¢æ•°
        å®Ÿéš›ã®ä½¿ç”¨ã§ã¯ã€å®Ÿé¨“è£…ç½®ã«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¨­å®šã—ã€
        æ­©ç•™ã¾ã‚Šã‚’æ¸¬å®šã™ã‚‹é–¢æ•°ã«ç½®ãæ›ãˆã‚‹
        """
        rf_power, pressure, gas_flow, temp = params

        # è¤‡é›‘ãªéç·šå½¢é–¢æ•°ã§æ­©ç•™ã¾ã‚Šã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
        # å®Ÿéš›ã®ãƒ—ãƒ­ã‚»ã‚¹ã§ã¯æœªçŸ¥ã®è¤‡é›‘ãªé–¢æ•°
        yield_rate = (
            0.95 - 0.001 * (rf_power - 250)**2 -
            0.0005 * (pressure - 50)**2 -
            0.0002 * (gas_flow - 125)**2 -
            0.0003 * (temp - 50)**2 +
            0.0001 * rf_power * pressure / 10000 -
            0.00005 * gas_flow * temp / 1000 +
            np.random.normal(0, 0.005)  # æ¸¬å®šãƒã‚¤ã‚º
        )

        # æ­©ç•™ã¾ã‚Šã¯0-1ã®ç¯„å›²
        return np.clip(yield_rate, 0, 1)

    def expected_improvement(self, X, xi=0.01):
        """
        Expected Improvementç²å¾—é–¢æ•°

        Parameters:
        -----------
        X : ndarray
            è©•ä¾¡ç‚¹ (n_points, n_dims)
        xi : float
            Explorationãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ (å¤§ãã„ã»ã©æ¢ç´¢é‡è¦–)
        """
        X_norm = self._normalize(X)
        mu, sigma = self.gp.predict(X_norm, return_std=True)

        # ç¾åœ¨ã®æœ€è‰¯å€¤
        f_best = np.max(self.y_observed)

        # Improvement
        improvement = mu - f_best - xi

        # Zå€¤
        with np.errstate(divide='warn'):
            Z = improvement / sigma
            ei = improvement * norm.cdf(Z) + sigma * norm.pdf(Z)
            ei[sigma == 0.0] = 0.0

        return ei

    def upper_confidence_bound(self, X):
        """
        Upper Confidence Boundç²å¾—é–¢æ•°

        UCB = Î¼(x) + ÎºÂ·Ïƒ(x)
        """
        X_norm = self._normalize(X)
        mu, sigma = self.gp.predict(X_norm, return_std=True)

        return mu + self.kappa * sigma

    def probability_of_improvement(self, X, xi=0.01):
        """
        Probability of Improvementç²å¾—é–¢æ•°

        POI = P(f(x) >= f(x_best) + Î¾)
        """
        X_norm = self._normalize(X)
        mu, sigma = self.gp.predict(X_norm, return_std=True)

        f_best = np.max(self.y_observed)
        improvement = mu - f_best - xi

        with np.errstate(divide='warn'):
            Z = improvement / sigma
            poi = norm.cdf(Z)
            poi[sigma == 0.0] = 0.0

        return poi

    def acquisition_function(self, X):
        """ç²å¾—é–¢æ•°ã®çµ±ä¸€ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹"""
        if self.acquisition == 'ei':
            return self.expected_improvement(X)
        elif self.acquisition == 'ucb':
            return self.upper_confidence_bound(X)
        elif self.acquisition == 'poi':
            return self.probability_of_improvement(X)
        else:
            raise ValueError(f"Unknown acquisition function: {self.acquisition}")

    def propose_next_sample(self):
        """
        æ¬¡ã®å®Ÿé¨“å€™è£œç‚¹ã‚’ææ¡ˆ

        ç²å¾—é–¢æ•°ã‚’æœ€å¤§åŒ–ã™ã‚‹ç‚¹ã‚’æ¢ç´¢
        """
        # ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚° + å±€æ‰€æœ€é©åŒ–
        best_acq = -np.inf
        best_x = None

        # è¤‡æ•°ã®åˆæœŸç‚¹ã‹ã‚‰æœ€é©åŒ–ã‚’è©¦è¡Œ
        for _ in range(10):
            # ãƒ©ãƒ³ãƒ€ãƒ ãªåˆæœŸç‚¹
            x0 = np.random.uniform(0, 1, self.dim)

            # ç²å¾—é–¢æ•°ã®æœ€å¤§åŒ– = è² ã®ç²å¾—é–¢æ•°ã®æœ€å°åŒ–
            res = minimize(
                fun=lambda x: -self.acquisition_function(x.reshape(1, -1))[0],
                x0=x0,
                bounds=[(0, 1)] * self.dim,
                method='L-BFGS-B'
            )

            # ã‚ˆã‚Šè‰¯ã„å€™è£œãŒè¦‹ã¤ã‹ã£ãŸã‚‰æ›´æ–°
            if -res.fun > best_acq:
                best_acq = -res.fun
                best_x = res.x

        # å…ƒã®ã‚¹ã‚±ãƒ¼ãƒ«ã«æˆ»ã™
        next_sample = self._denormalize(best_x)

        return next_sample

    def optimize(self, n_iterations=30, verbose=True):
        """
        Bayesian Optimizationå®Ÿè¡Œ

        Parameters:
        -----------
        n_iterations : int
            æœ€é©åŒ–ã®åå¾©å›æ•°ï¼ˆå®Ÿé¨“å›æ•°ï¼‰
        verbose : bool
            é€²æ—è¡¨ç¤ºãƒ•ãƒ©ã‚°

        Returns:
        --------
        results : dict
            æœ€é©åŒ–çµæœã¨å±¥æ­´
        """
        # åˆæœŸãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
        if verbose:
            print("========== Initial Random Sampling ==========")

        X_init = np.random.uniform(
            self.param_bounds[:, 0],
            self.param_bounds[:, 1],
            (self.n_init, self.dim)
        )

        for i, x in enumerate(X_init):
            y = self.objective_function(x)
            self.X_observed = np.vstack([self.X_observed, x])
            self.y_observed = np.append(self.y_observed, y)

            if verbose:
                print(f"Init {i+1}/{self.n_init}: Yield = {y:.4f}, "
                      f"Params = {x}")

        # Bayesian Optimizationåå¾©
        if verbose:
            print(f"\n========== Bayesian Optimization "
                  f"({self.acquisition.upper()}) ==========")

        for iteration in range(n_iterations):
            # GPãƒ¢ãƒ‡ãƒ«ã‚’ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿ã§ãƒ•ã‚£ãƒƒãƒˆ
            X_norm = self._normalize(self.X_observed)
            self.gp.fit(X_norm, self.y_observed)

            # æ¬¡ã®å®Ÿé¨“å€™è£œã‚’ææ¡ˆ
            next_x = self.propose_next_sample()

            # å®Ÿé¨“å®Ÿè¡Œï¼ˆç›®çš„é–¢æ•°è©•ä¾¡ï¼‰
            next_y = self.objective_function(next_x)

            # ãƒ‡ãƒ¼ã‚¿ã«è¿½åŠ 
            self.X_observed = np.vstack([self.X_observed, next_x])
            self.y_observed = np.append(self.y_observed, next_y)

            # ç¾åœ¨ã®æœ€è‰¯å€¤
            best_idx = np.argmax(self.y_observed)
            best_y = self.y_observed[best_idx]
            best_x = self.X_observed[best_idx]

            if verbose:
                print(f"Iter {iteration+1}/{n_iterations}: "
                      f"Yield = {next_y:.4f} | "
                      f"Best = {best_y:.4f}")

        # æœ€çµ‚çµæœ
        best_idx = np.argmax(self.y_observed)
        best_params = self.X_observed[best_idx]
        best_yield = self.y_observed[best_idx]

        if verbose:
            print(f"\n========== Optimization Complete ==========")
            print(f"Best Yield: {best_yield:.4f}")
            print(f"Optimal Parameters:")
            for name, value in zip(self.param_names, best_params):
                print(f"  {name}: {value:.2f}")

        results = {
            'best_params': best_params,
            'best_yield': best_yield,
            'X_history': self.X_observed,
            'y_history': self.y_observed,
            'gp_model': self.gp
        }

        return results

    def plot_convergence(self):
        """åæŸéç¨‹ã®å¯è¦–åŒ–"""
        fig, axes = plt.subplots(1, 2, figsize=(14, 5))

        # å„åå¾©ã§ã®æœ€è‰¯å€¤ã®æ¨ç§»
        best_so_far = np.maximum.accumulate(self.y_observed)

        axes[0].plot(best_so_far, 'b-', linewidth=2, label='Best Yield')
        axes[0].axvline(self.n_init, color='r', linestyle='--',
                       label='BO Start')
        axes[0].set_xlabel('Iteration')
        axes[0].set_ylabel('Best Yield')
        axes[0].set_title('Convergence Plot')
        axes[0].legend()
        axes[0].grid(True, alpha=0.3)

        # å…¨è¦³æ¸¬å€¤ã®ãƒ—ãƒ­ãƒƒãƒˆ
        axes[1].scatter(range(len(self.y_observed)), self.y_observed,
                       c=self.y_observed, cmap='viridis', s=50)
        axes[1].axvline(self.n_init, color='r', linestyle='--',
                       label='BO Start')
        axes[1].set_xlabel('Iteration')
        axes[1].set_ylabel('Observed Yield')
        axes[1].set_title('All Observations')
        axes[1].legend()
        axes[1].grid(True, alpha=0.3)
        axes[1].colorbar = plt.colorbar(axes[1].collections[0], ax=axes[1])

        plt.tight_layout()
        plt.savefig('bo_convergence.png', dpi=300, bbox_inches='tight')
        plt.show()


# ========== ä½¿ç”¨ä¾‹ ==========
if __name__ == "__main__":
    np.random.seed(42)

    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¢ç´¢ç¯„å›²
    param_bounds = [
        (100, 400),   # RFãƒ‘ãƒ¯ãƒ¼ (W)
        (10, 100),    # åœ§åŠ› (mTorr)
        (50, 200),    # ã‚¬ã‚¹æµé‡ (sccm)
        (20, 80)      # æ¸©åº¦ (Â°C)
    ]

    # Bayesian Optimizationå®Ÿè¡Œ
    print("========== Etching Process Yield Optimization ==========\n")

    # Expected Improvementã§æœ€é©åŒ–
    optimizer = BayesianOptimizationYield(
        param_bounds=param_bounds,
        n_init=10,
        acquisition='ei',
        kappa=2.576
    )

    results = optimizer.optimize(n_iterations=30, verbose=True)

    # åæŸéç¨‹ã®å¯è¦–åŒ–
    optimizer.plot_convergence()

    # æ¯”è¼ƒ: ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ¼ãƒã¨ã®æ€§èƒ½æ¯”è¼ƒ
    print("\n========== Random Search (Baseline) ==========")
    random_X = np.random.uniform(
        optimizer.param_bounds[:, 0],
        optimizer.param_bounds[:, 1],
        (40, optimizer.dim)
    )
    random_y = np.array([optimizer.objective_function(x) for x in random_X])
    best_random = np.max(random_y)

    print(f"Best Random Yield: {best_random:.4f}")
    print(f"Bayesian Opt Yield: {results['best_yield']:.4f}")
    print(f"Improvement: {(results['best_yield'] - best_random):.4f} "
          f"({(results['best_yield'] - best_random) / best_random * 100:.2f}%)")
</code></pre>

                <h3>3.2.3 ä¸¦åˆ—Bayesian Optimization</h3>
                <p>è¤‡æ•°ã®å®Ÿé¨“è£…ç½®ã‚’ä¸¦åˆ—é‹ç”¨ã™ã‚‹å ´åˆã€åŒæ™‚ã«è¤‡æ•°ã®å€™è£œç‚¹ã‚’ææ¡ˆã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ï¼š</p>

<pre><code class="language-python">from scipy.spatial.distance import cdist

class ParallelBayesianOptimization(BayesianOptimizationYield):
    """
    ä¸¦åˆ—Bayesian Optimization

    è¤‡æ•°è£…ç½®ã§ã®åŒæ™‚å®Ÿé¨“ã«å¯¾å¿œ
    Batch acquisition strategyã‚’å®Ÿè£…
    """

    def __init__(self, param_bounds, n_init=10, batch_size=4,
                 acquisition='ei', diversity_weight=0.1):
        """
        Parameters:
        -----------
        batch_size : int
            åŒæ™‚å®Ÿé¨“æ•°ï¼ˆè£…ç½®å°æ•°ï¼‰
        diversity_weight : float
            å¤šæ§˜æ€§ãƒšãƒŠãƒ«ãƒ†ã‚£ã®é‡ã¿
        """
        super().__init__(param_bounds, n_init, acquisition)
        self.batch_size = batch_size
        self.diversity_weight = diversity_weight

    def propose_batch_samples(self):
        """
        ãƒãƒƒãƒã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°: ä¸¦åˆ—å®Ÿé¨“ç”¨ã®è¤‡æ•°å€™è£œã‚’ææ¡ˆ

        Strategy: Local Penalization
        é¸æŠã•ã‚ŒãŸç‚¹ã®è¿‘å‚ã®ç²å¾—é–¢æ•°å€¤ã‚’æ¸›è¡°ã•ã›ã€
        å¤šæ§˜ãªå€™è£œã‚’é¸æŠ
        """
        batch_proposals = []

        for i in range(self.batch_size):
            # ç¾åœ¨ã®ãƒãƒƒãƒå€™è£œã‚’è€ƒæ…®ã—ãŸç²å¾—é–¢æ•°
            if i == 0:
                # æœ€åˆã®å€™è£œ: é€šå¸¸ã®ç²å¾—é–¢æ•°æœ€å¤§åŒ–
                next_x = self.propose_next_sample()
            else:
                # 2ç•ªç›®ä»¥é™: æ—¢é¸æŠç‚¹ã‹ã‚‰ã®è·é›¢ã§ãƒšãƒŠãƒ«ãƒ†ã‚£
                next_x = self._propose_with_diversity(batch_proposals)

            batch_proposals.append(next_x)

        return np.array(batch_proposals)

    def _propose_with_diversity(self, existing_batch):
        """
        å¤šæ§˜æ€§ã‚’è€ƒæ…®ã—ãŸå€™è£œææ¡ˆ

        ç²å¾—é–¢æ•°ã«diversityãƒšãƒŠãƒ«ãƒ†ã‚£ã‚’è¿½åŠ 
        """
        existing_batch_norm = self._normalize(np.array(existing_batch))

        best_acq = -np.inf
        best_x = None

        for _ in range(10):
            x0 = np.random.uniform(0, 1, self.dim)

            def penalized_acquisition(x):
                x_norm = x.reshape(1, -1)

                # åŸºæœ¬ç²å¾—é–¢æ•°
                acq = self.acquisition_function(x_norm)[0]

                # æ—¢å­˜å€™è£œã¨ã®è·é›¢ãƒšãƒŠãƒ«ãƒ†ã‚£
                distances = cdist(x_norm, existing_batch_norm).flatten()
                diversity_penalty = np.sum(np.exp(-distances / 0.1))

                return -(acq - self.diversity_weight * diversity_penalty)

            res = minimize(
                fun=penalized_acquisition,
                x0=x0,
                bounds=[(0, 1)] * self.dim,
                method='L-BFGS-B'
            )

            if -res.fun > best_acq:
                best_acq = -res.fun
                best_x = res.x

        return self._denormalize(best_x)

    def optimize_parallel(self, n_batches=10, verbose=True):
        """
        ä¸¦åˆ—Bayesian Optimizationå®Ÿè¡Œ

        Parameters:
        -----------
        n_batches : int
            ãƒãƒƒãƒå®Ÿé¨“ã®å›æ•°
        """
        # åˆæœŸãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
        if verbose:
            print("========== Parallel BO: Initial Sampling ==========")

        X_init = np.random.uniform(
            self.param_bounds[:, 0],
            self.param_bounds[:, 1],
            (self.n_init, self.dim)
        )

        for x in X_init:
            y = self.objective_function(x)
            self.X_observed = np.vstack([self.X_observed, x])
            self.y_observed = np.append(self.y_observed, y)

        # ä¸¦åˆ—æœ€é©åŒ–
        if verbose:
            print(f"\n========== Parallel BO: {n_batches} Batches "
                  f"(Batch Size={self.batch_size}) ==========")

        for batch in range(n_batches):
            # GPãƒ•ã‚£ãƒƒãƒˆ
            X_norm = self._normalize(self.X_observed)
            self.gp.fit(X_norm, self.y_observed)

            # ãƒãƒƒãƒå€™è£œææ¡ˆ
            batch_X = self.propose_batch_samples()

            # ä¸¦åˆ—å®Ÿé¨“å®Ÿè¡Œ
            batch_y = np.array([self.objective_function(x) for x in batch_X])

            # ãƒ‡ãƒ¼ã‚¿è¿½åŠ 
            self.X_observed = np.vstack([self.X_observed, batch_X])
            self.y_observed = np.append(self.y_observed, batch_y)

            # ç¾åœ¨ã®æœ€è‰¯å€¤
            best_y = np.max(self.y_observed)

            if verbose:
                print(f"Batch {batch+1}/{n_batches}: "
                      f"Yields = {batch_y}, Best = {best_y:.4f}")

        # æœ€çµ‚çµæœ
        best_idx = np.argmax(self.y_observed)
        results = {
            'best_params': self.X_observed[best_idx],
            'best_yield': self.y_observed[best_idx],
            'X_history': self.X_observed,
            'y_history': self.y_observed
        }

        return results


# ========== ä½¿ç”¨ä¾‹ ==========
# 4å°ã®è£…ç½®ã§ä¸¦åˆ—å®Ÿé¨“
parallel_optimizer = ParallelBayesianOptimization(
    param_bounds=param_bounds,
    n_init=10,
    batch_size=4,
    acquisition='ei',
    diversity_weight=0.1
)

print("\n========== Parallel Bayesian Optimization ==========")
results_parallel = parallel_optimizer.optimize_parallel(
    n_batches=10,
    verbose=True
)

print(f"\nParallel BO Best Yield: {results_parallel['best_yield']:.4f}")
print(f"Total Experiments: {len(results_parallel['y_history'])}")
print(f"  (10 initial + 10 batches Ã— 4 = 50 experiments)")
</code></pre>
            </section>

            <section>
                <h2>3.3 å¤šç›®çš„æœ€é©åŒ–: æ­©ç•™ã¾ã‚Šãƒ»ã‚³ã‚¹ãƒˆãƒ»ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã®åŒæ™‚æœ€é©åŒ–</h2>

                <h3>3.3.1 å¤šç›®çš„æœ€é©åŒ–ã®å¿…è¦æ€§</h3>
                <p>å®Ÿéš›ã®è£½é€ ã§ã¯ã€è¤‡æ•°ã®ç›®çš„ã‚’åŒæ™‚ã«æœ€é©åŒ–ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ï¼š</p>
                <ul>
                    <li><strong>æ­©ç•™ã¾ã‚Šæœ€å¤§åŒ–</strong>: è‰¯å“ç‡å‘ä¸Š</li>
                    <li><strong>ã‚³ã‚¹ãƒˆæœ€å°åŒ–</strong>: ææ–™è²»ãƒ»ã‚¨ãƒãƒ«ã‚®ãƒ¼ã‚³ã‚¹ãƒˆå‰Šæ¸›</li>
                    <li><strong>ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆæœ€å¤§åŒ–</strong>: ç”Ÿç”£é€Ÿåº¦å‘ä¸Š</li>
                </ul>

                <p>ã“ã‚Œã‚‰ã¯äº’ã„ã«ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã®é–¢ä¿‚ã«ã‚ã‚Šã€å˜ä¸€ç›®çš„æœ€é©åŒ–ã§ã¯è§£æ±ºã§ãã¾ã›ã‚“ã€‚</p>

                <h3>3.3.2 Paretoæœ€é©è§£ã¨Pareto Front</h3>
                <div style="background: #f8f9fa; padding: 1rem; border-radius: 8px; margin: 1rem 0;">
                    <p><strong>Paretoæœ€é©</strong>: ã‚ã‚‹ç›®çš„ã‚’æ”¹å–„ã™ã‚‹ã¨ä»–ã®ç›®çš„ãŒæ‚ªåŒ–ã™ã‚‹çŠ¶æ…‹</p>
                    <p><strong>Pareto Front</strong>: ã™ã¹ã¦ã®Paretoæœ€é©è§£ã®é›†åˆ</p>
                    <p>æ„æ€æ±ºå®šè€…ã¯ã€Pareto Frontä¸Šã®è§£ã‹ã‚‰ã€ç¾å ´ã®å„ªå…ˆåº¦ã«å¿œã˜ã¦æœ€çµ‚è§£ã‚’é¸æŠã—ã¾ã™ã€‚</p>
                </div>

                <h3>3.3.3 NSGA-II (Non-dominated Sorting Genetic Algorithm II)</h3>
                <p>å¤šç›®çš„æœ€é©åŒ–ã®ä»£è¡¨çš„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ NSGA-IIã‚’å®Ÿè£…ã—ã¾ã™ï¼š</p>

<pre><code class="language-python">import numpy as np
from deap import base, creator, tools, algorithms
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D

class MultiObjectiveYieldOptimization:
    """
    NSGA-IIã«ã‚ˆã‚‹å¤šç›®çš„æœ€é©åŒ–

    ç›®çš„é–¢æ•°:
    1. æ­©ç•™ã¾ã‚Šæœ€å¤§åŒ– (maximize)
    2. ã‚³ã‚¹ãƒˆæœ€å°åŒ– (minimize)
    3. ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆæœ€å¤§åŒ– (maximize)

    æ±ºå®šå¤‰æ•°: RFãƒ‘ãƒ¯ãƒ¼ã€åœ§åŠ›ã€ã‚¬ã‚¹æµé‡ã€æ¸©åº¦
    """

    def __init__(self, param_bounds, population_size=100, n_generations=50):
        """
        Parameters:
        -----------
        param_bounds : list of tuples
            å„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ç¯„å›²
        population_size : int
            å€‹ä½“æ•°
        n_generations : int
            ä¸–ä»£æ•°
        """
        self.param_bounds = np.array(param_bounds)
        self.dim = len(param_bounds)
        self.population_size = population_size
        self.n_generations = n_generations

        # DEAPè¨­å®š
        self._setup_deap()

    def _setup_deap(self):
        """DEAP (éºä¼çš„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ãƒ©ã‚¤ãƒ–ãƒ©ãƒª) ã®è¨­å®š"""
        # Fitnessã‚¯ãƒ©ã‚¹å®šç¾© (3ç›®çš„: æœ€å¤§åŒ–, æœ€å°åŒ–, æœ€å¤§åŒ–)
        creator.create("FitnessMulti", base.Fitness, weights=(1.0, -1.0, 1.0))
        creator.create("Individual", list, fitness=creator.FitnessMulti)

        self.toolbox = base.Toolbox()

        # å€‹ä½“ç”Ÿæˆ
        for i in range(self.dim):
            self.toolbox.register(f"attr_{i}",
                                 np.random.uniform,
                                 self.param_bounds[i, 0],
                                 self.param_bounds[i, 1])

        self.toolbox.register("individual", tools.initCycle, creator.Individual,
                             [getattr(self.toolbox, f"attr_{i}")
                              for i in range(self.dim)], n=1)

        self.toolbox.register("population", tools.initRepeat,
                             list, self.toolbox.individual)

        # è©•ä¾¡é–¢æ•°
        self.toolbox.register("evaluate", self.evaluate_objectives)

        # éºä¼çš„æ“ä½œ
        self.toolbox.register("mate", tools.cxSimulatedBinaryBounded,
                             low=self.param_bounds[:, 0],
                             up=self.param_bounds[:, 1], eta=20.0)

        self.toolbox.register("mutate", tools.mutPolynomialBounded,
                             low=self.param_bounds[:, 0],
                             up=self.param_bounds[:, 1],
                             eta=20.0, indpb=1.0/self.dim)

        self.toolbox.register("select", tools.selNSGA2)

    def evaluate_objectives(self, individual):
        """
        3ç›®çš„é–¢æ•°ã®è©•ä¾¡

        Returns:
        --------
        (yield, cost, throughput) : tuple
            æ­©ç•™ã¾ã‚Šã€ã‚³ã‚¹ãƒˆã€ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ
        """
        rf_power, pressure, gas_flow, temp = individual

        # ç›®çš„1: æ­©ç•™ã¾ã‚Š (æœ€å¤§åŒ–)
        yield_rate = (
            0.95 - 0.001 * (rf_power - 250)**2 -
            0.0005 * (pressure - 50)**2 -
            0.0002 * (gas_flow - 125)**2 -
            0.0003 * (temp - 50)**2
        )
        yield_rate = np.clip(yield_rate, 0, 1)

        # ç›®çš„2: ã‚³ã‚¹ãƒˆ (æœ€å°åŒ–)
        # é«˜RFãƒ‘ãƒ¯ãƒ¼ãƒ»é«˜ã‚¬ã‚¹æµé‡ãƒ»é«˜æ¸©ã§ã‚³ã‚¹ãƒˆå¢—åŠ 
        cost = (
            0.01 * rf_power +           # é›»åŠ›ã‚³ã‚¹ãƒˆ
            0.05 * gas_flow +           # ã‚¬ã‚¹ã‚³ã‚¹ãƒˆ
            0.02 * (temp - 20) +        # å†·å´ã‚³ã‚¹ãƒˆ
            0.001 * pressure            # çœŸç©ºã‚³ã‚¹ãƒˆ
        )

        # ç›®çš„3: ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ (æœ€å¤§åŒ–)
        # é«˜RFãƒ‘ãƒ¯ãƒ¼ãƒ»é«˜åœ§åŠ›ã§ã‚¨ãƒƒãƒãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆå‘ä¸Š
        throughput = (
            0.5 + 0.001 * rf_power + 0.002 * pressure -
            0.0005 * (gas_flow - 125)**2
        )
        throughput = np.clip(throughput, 0, 2)

        return yield_rate, cost, throughput

    def optimize(self, verbose=True):
        """
        NSGA-IIå®Ÿè¡Œ

        Returns:
        --------
        pareto_front : list
            Paretoæœ€é©è§£ã®é›†åˆ
        """
        # åˆæœŸå€‹ä½“ç¾¤ç”Ÿæˆ
        population = self.toolbox.population(n=self.population_size)

        # çµ±è¨ˆæƒ…å ±
        stats = tools.Statistics(lambda ind: ind.fitness.values)
        stats.register("avg", np.mean, axis=0)
        stats.register("std", np.std, axis=0)
        stats.register("min", np.min, axis=0)
        stats.register("max", np.max, axis=0)

        # NSGA-IIå®Ÿè¡Œ
        population, logbook = algorithms.eaMuPlusLambda(
            population, self.toolbox,
            mu=self.population_size,
            lambda_=self.population_size,
            cxpb=0.9,  # äº¤å‰ç¢ºç‡
            mutpb=0.1,  # çªç„¶å¤‰ç•°ç¢ºç‡
            ngen=self.n_generations,
            stats=stats,
            verbose=verbose
        )

        # Pareto FrontæŠ½å‡º
        pareto_front = tools.sortNondominated(population,
                                              len(population),
                                              first_front_only=True)[0]

        # çµæœæ•´å½¢
        pareto_solutions = []
        for ind in pareto_front:
            solution = {
                'params': np.array(ind),
                'yield': ind.fitness.values[0],
                'cost': ind.fitness.values[1],
                'throughput': ind.fitness.values[2]
            }
            pareto_solutions.append(solution)

        return pareto_solutions, logbook

    def plot_pareto_front(self, pareto_solutions):
        """Pareto Frontã®3Då¯è¦–åŒ–"""
        yields = [sol['yield'] for sol in pareto_solutions]
        costs = [sol['cost'] for sol in pareto_solutions]
        throughputs = [sol['throughput'] for sol in pareto_solutions]

        fig = plt.figure(figsize=(14, 6))

        # 3D Pareto Front
        ax1 = fig.add_subplot(121, projection='3d')
        scatter = ax1.scatter(yields, costs, throughputs,
                            c=yields, cmap='viridis', s=100)
        ax1.set_xlabel('Yield')
        ax1.set_ylabel('Cost')
        ax1.set_zlabel('Throughput')
        ax1.set_title('3D Pareto Front')
        fig.colorbar(scatter, ax=ax1, label='Yield')

        # 2Då°„å½± (Yield vs Cost)
        ax2 = fig.add_subplot(122)
        scatter2 = ax2.scatter(yields, costs, c=throughputs,
                              cmap='plasma', s=100)
        ax2.set_xlabel('Yield')
        ax2.set_ylabel('Cost')
        ax2.set_title('Pareto Front Projection (Yield vs Cost)')
        ax2.grid(True, alpha=0.3)
        fig.colorbar(scatter2, ax=ax2, label='Throughput')

        plt.tight_layout()
        plt.savefig('pareto_front.png', dpi=300, bbox_inches='tight')
        plt.show()

    def select_solution_by_preference(self, pareto_solutions, weights):
        """
        é‡ã¿ä»˜ã‘ã‚¹ã‚«ãƒ©ãƒ¼åŒ–ã§Paretoè§£ã‹ã‚‰1ã¤é¸æŠ

        Parameters:
        -----------
        weights : tuple
            (w_yield, w_cost, w_throughput)
            å„ç›®çš„ã®é‡è¦åº¦ (åˆè¨ˆ1.0)

        Returns:
        --------
        best_solution : dict
            é‡ã¿ä»˜ã‘è©•ä¾¡ãŒæœ€è‰¯ã®è§£
        """
        w_yield, w_cost, w_throughput = weights

        best_score = -np.inf
        best_solution = None

        for sol in pareto_solutions:
            # ã‚¹ã‚«ãƒ©ãƒ¼åŒ– (ã‚³ã‚¹ãƒˆã¯è² ã®å¯„ä¸)
            score = (
                w_yield * sol['yield'] -
                w_cost * sol['cost'] +
                w_throughput * sol['throughput']
            )

            if score > best_score:
                best_score = score
                best_solution = sol

        return best_solution


# ========== ä½¿ç”¨ä¾‹ ==========
if __name__ == "__main__":
    np.random.seed(42)

    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç¯„å›²
    param_bounds = [
        (100, 400),   # RFãƒ‘ãƒ¯ãƒ¼
        (10, 100),    # åœ§åŠ›
        (50, 200),    # ã‚¬ã‚¹æµé‡
        (20, 80)      # æ¸©åº¦
    ]

    # å¤šç›®çš„æœ€é©åŒ–å®Ÿè¡Œ
    print("========== Multi-Objective Optimization (NSGA-II) ==========\n")

    mo_optimizer = MultiObjectiveYieldOptimization(
        param_bounds=param_bounds,
        population_size=100,
        n_generations=50
    )

    pareto_solutions, logbook = mo_optimizer.optimize(verbose=False)

    print(f"\nPareto Front: {len(pareto_solutions)} solutions found\n")

    # ä»£è¡¨çš„ãªè§£ã‚’è¡¨ç¤º
    print("--- Representative Pareto Solutions ---")
    for i, sol in enumerate(pareto_solutions[:5]):
        print(f"Solution {i+1}:")
        print(f"  Yield: {sol['yield']:.4f}")
        print(f"  Cost: {sol['cost']:.2f}")
        print(f"  Throughput: {sol['throughput']:.4f}")
        print(f"  Params: {sol['params']}\n")

    # Pareto Frontå¯è¦–åŒ–
    mo_optimizer.plot_pareto_front(pareto_solutions)

    # ã‚·ãƒŠãƒªã‚ªåˆ¥ã®è§£é¸æŠ
    print("\n--- Solution Selection by Preference ---")

    # ã‚·ãƒŠãƒªã‚ª1: æ­©ç•™ã¾ã‚Šé‡è¦–
    weights_yield_focused = (0.7, 0.1, 0.2)
    sol_yield = mo_optimizer.select_solution_by_preference(
        pareto_solutions, weights_yield_focused
    )
    print("Scenario 1 (Yield-focused): "
          f"Yield={sol_yield['yield']:.4f}, "
          f"Cost={sol_yield['cost']:.2f}, "
          f"Throughput={sol_yield['throughput']:.4f}")

    # ã‚·ãƒŠãƒªã‚ª2: ã‚³ã‚¹ãƒˆé‡è¦–
    weights_cost_focused = (0.2, 0.6, 0.2)
    sol_cost = mo_optimizer.select_solution_by_preference(
        pareto_solutions, weights_cost_focused
    )
    print("Scenario 2 (Cost-focused): "
          f"Yield={sol_cost['yield']:.4f}, "
          f"Cost={sol_cost['cost']:.2f}, "
          f"Throughput={sol_cost['throughput']:.4f}")

    # ã‚·ãƒŠãƒªã‚ª3: ãƒãƒ©ãƒ³ã‚¹å‹
    weights_balanced = (0.4, 0.3, 0.3)
    sol_balanced = mo_optimizer.select_solution_by_preference(
        pareto_solutions, weights_balanced
    )
    print("Scenario 3 (Balanced): "
          f"Yield={sol_balanced['yield']:.4f}, "
          f"Cost={sol_balanced['cost']:.2f}, "
          f"Throughput={sol_balanced['throughput']:.4f}")
</code></pre>
            </section>

            <section>
                <h2>3.4 ã¾ã¨ã‚</h2>
                <p>æœ¬ç« ã§ã¯ã€åŠå°ä½“è£½é€ ã«ãŠã‘ã‚‹æ­©ç•™ã¾ã‚Šæœ€é©åŒ–ã®ãŸã‚ã®AIæ‰‹æ³•ã‚’å­¦ç¿’ã—ã¾ã—ãŸï¼š</p>

                <div style="background: #f0f8ff; padding: 1.5rem; border-radius: 8px; margin: 1.5rem 0;">
                    <h3 style="margin-top: 0;">ä¸»è¦ãªå­¦ç¿’å†…å®¹</h3>

                    <h4>1. Bayesian Optimization</h4>
                    <ul>
                        <li><strong>Gaussian Processã‚µãƒ­ã‚²ãƒ¼ãƒˆãƒ¢ãƒ‡ãƒ«</strong>ã§ç›®çš„é–¢æ•°ã‚’åŠ¹ç‡çš„ã«è¿‘ä¼¼</li>
                        <li><strong>ç²å¾—é–¢æ•°</strong> (EI, UCB, POI) ã§æ¬¡ã®å®Ÿé¨“ç‚¹ã‚’ç†è«–çš„ã«é¸æŠ</li>
                        <li><strong>å®Ÿé¨“å›æ•°ã‚’1/10ä»¥ä¸‹ã«å‰Šæ¸›</strong>ã—ãªãŒã‚‰æœ€é©è§£ç™ºè¦‹</li>
                        <li><strong>ä¸¦åˆ—BO</strong>ã§è¤‡æ•°è£…ç½®ã®åŒæ™‚å®Ÿé¨“ã«å¯¾å¿œ</li>
                    </ul>

                    <h4>2. å¤šç›®çš„æœ€é©åŒ– (NSGA-II)</h4>
                    <ul>
                        <li><strong>æ­©ç•™ã¾ã‚Šãƒ»ã‚³ã‚¹ãƒˆãƒ»ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ</strong>ã‚’åŒæ™‚æœ€é©åŒ–</li>
                        <li><strong>Pareto Front</strong>ã‹ã‚‰ç¾å ´ã®å„ªå…ˆåº¦ã«å¿œã˜ã¦è§£é¸æŠ</li>
                        <li><strong>ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•é–¢ä¿‚</strong>ã‚’å®šé‡çš„ã«å¯è¦–åŒ–</li>
                    </ul>

                    <h4>å®Ÿç”¨ä¸Šã®æˆæœ</h4>
                    <ul>
                        <li>å¾“æ¥æ‰‹æ³•ã‚ˆã‚Š<strong>90%å°‘ãªã„å®Ÿé¨“å›æ•°</strong>ã§æœ€é©åŒ–å®Œäº†</li>
                        <li>æ­©ç•™ã¾ã‚Š<strong>1-3%å‘ä¸Š</strong> (æ•°å„„å††ã®åˆ©ç›Šå¢—)</li>
                        <li>ã‚³ã‚¹ãƒˆ<strong>10-20%å‰Šæ¸›</strong>ã‚’åŒæ™‚é”æˆ</li>
                    </ul>
                </div>

                <h3>æ¬¡ç« ã¸ã®å±•é–‹</h3>
                <p>ç¬¬4ç« ã€ŒAdvanced Process Control (APC)ã€ã§ã¯ã€æœ€é©åŒ–ã•ã‚ŒãŸãƒ—ãƒ­ã‚»ã‚¹æ¡ä»¶ã‚’å®‰å®šç¶­æŒã™ã‚‹åˆ¶å¾¡æ‰‹æ³•ã‚’å­¦ã³ã¾ã™ï¼š</p>
                <ul>
                    <li>ãƒ¢ãƒ‡ãƒ«äºˆæ¸¬åˆ¶å¾¡ (MPC) ã«ã‚ˆã‚‹ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æœ€é©åŒ–</li>
                    <li>é©å¿œåˆ¶å¾¡ã§è£…ç½®å¤‰å‹•ã«è‡ªå‹•å¯¾å¿œ</li>
                    <li>ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰åˆ¶å¾¡ã§å¤–ä¹±ã‚’äº‹å‰è£œå„Ÿ</li>
                    <li>ãƒ‡ã‚¸ã‚¿ãƒ«ãƒ„ã‚¤ãƒ³ã§ãƒ—ãƒ­ã‚»ã‚¹ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ</li>
                </ul>
            </section>

            <div class="chapter-navigation">
                <a href="chapter-2.html" class="btn btn-secondary">â† å‰ã®ç« </a>
                <a href="index.html" class="btn btn-secondary">ç›®æ¬¡ã«æˆ»ã‚‹</a>
                <a href="chapter-4.html" class="btn btn-primary">æ¬¡ã®ç«  â†’</a>
            </div>
        </article>
    </main>

    <footer class="site-footer">
        <div class="container">
            <p>&copy; 2025 Yusuke Hashimoto Laboratory, Tohoku University. All rights reserved.</p>
        </div>
    </footer>

    <script src="/assets/js/main.js"></script>
</body>
</html>
