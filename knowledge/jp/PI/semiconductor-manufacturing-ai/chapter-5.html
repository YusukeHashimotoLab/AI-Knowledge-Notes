<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ç¬¬5ç«  Fault Detection & Classification (FDC) | åŠå°ä½“è£½é€ AI | ãƒãƒ†ãƒªã‚¢ãƒ«ã‚ºã‚¤ãƒ³ãƒ•ã‚©ãƒãƒ†ã‚£ã‚¯ã‚¹å…¥é–€</title>
    <meta name="description" content="åŠå°ä½“è£½é€ ã«ãŠã‘ã‚‹Fault Detection & Classification (FDC) ã‚’AIã§å®Ÿç¾ã—ã¾ã™ã€‚MSPCã€Isolation Forestã€LSTMç•°å¸¸æ¤œçŸ¥ã€å› æœæ¨è«–ã«ã‚ˆã‚‹æ ¹æœ¬åŸå› åˆ†æã‚’Pythonã§å®Ÿè£…ã—ã€ãƒ—ãƒ­ã‚»ã‚¹ç•°å¸¸ã‚’æ—©æœŸæ¤œçŸ¥ãƒ»è¨ºæ–­ã—ã¾ã™ã€‚">
    <link rel="stylesheet" href="/assets/css/variables.css">
    <link rel="stylesheet" href="/assets/css/reset.css">
    <link rel="stylesheet" href="/assets/css/base.css">
    <link rel="stylesheet" href="/assets/css/components.css">
    <link rel="stylesheet" href="/assets/css/layout.css">
    <link rel="stylesheet" href="/assets/css/responsive.css">
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

    <style>
        /* Locale Switcher Styles */
        .locale-switcher {
            display: flex;
            align-items: center;
            gap: 0.5rem;
            padding: 0.5rem 1rem;
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
            border-radius: 6px;
            font-size: 0.9rem;
            margin-bottom: 1rem;
            box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);
        }

        .current-locale {
            font-weight: 600;
            color: #7b2cbf;
            display: flex;
            align-items: center;
            gap: 0.25rem;
        }

        .locale-separator {
            color: #adb5bd;
            font-weight: 300;
        }

        .locale-link {
            color: #f093fb;
            text-decoration: none;
            font-weight: 500;
            transition: all 0.2s ease;
            display: flex;
            align-items: center;
            gap: 0.25rem;
            padding: 0.2rem 0.5rem;
            border-radius: 4px;
        }

        .locale-link:hover {
            background: rgba(240, 147, 251, 0.1);
            color: #d07be8;
            transform: translateY(-1px);
        }

        .locale-meta {
            color: #868e96;
            font-size: 0.85rem;
            font-style: italic;
            margin-left: auto;
        }

        @media (max-width: 768px) {
            .locale-switcher {
                font-size: 0.85rem;
                padding: 0.4rem 0.8rem;
            }
            .locale-meta {
                display: none;
            }
        }
    </style>
</head>
<body>
    <div class="locale-switcher">
<span class="current-locale">ğŸŒ JP</span>
<span class="locale-separator">|</span>
<a href="../../../en/PI/semiconductor-manufacturing-ai/chapter-5.html" class="locale-link">ğŸ‡¬ğŸ‡§ EN</a>
<span class="locale-separator">|</span>
<span class="locale-meta">Last sync: 2025-11-16</span>
</div>
<header class="site-header">
        <div class="container">
            <div class="header-content">
                <h1 class="site-title"><a href="/jp/">æ©‹æœ¬ç ”ç©¶å®¤</a></h1>
                <nav class="main-nav">
                    <ul>
                        <li><a href="/jp/">ãƒ›ãƒ¼ãƒ </a></li>
                        <li><a href="/jp/research.html">ç ”ç©¶å†…å®¹</a></li>
                        <li><a href="/jp/publications.html">ç ”ç©¶æ¥­ç¸¾</a></li>
                        <li><a href="../../mi-introduction/">çŸ¥è­˜ãƒ™ãƒ¼ã‚¹</a></li>
                        <li><a href="/jp/news.html">ãƒ‹ãƒ¥ãƒ¼ã‚¹</a></li>
                        <li><a href="/jp/members.html">ãƒ¡ãƒ³ãƒãƒ¼</a></li>
                        <li><a href="/jp/contact.html">ãŠå•ã„åˆã‚ã›</a></li>
                        <li><a href="/en/">English</a></li>
                    </ul>
                </nav>
            </div>
        </div>
    </header>

    <main class="article-content">
        <article class="container">
            <div class="breadcrumb">
                <a href="/jp/">ãƒ›ãƒ¼ãƒ </a> &gt;
                <a href="../../mi-introduction/">çŸ¥è­˜ãƒ™ãƒ¼ã‚¹</a> &gt;
                <a href="../../PI/">ãƒ—ãƒ­ã‚»ã‚¹ã‚¤ãƒ³ãƒ•ã‚©ãƒãƒ†ã‚£ã‚¯ã‚¹</a> &gt;
                <a href="../../PI/semiconductor-manufacturing-ai/">åŠå°ä½“è£½é€ AI</a> &gt;
                ç¬¬5ç« 
            </div>

            <header class="article-header">
                <h1 class="gradient-text" style="background: linear-gradient(135deg, #11998e 0%, #38ef7d 100%); -webkit-background-clip: text; -webkit-text-fill-color: transparent;">ç¬¬5ç«  Fault Detection & Classification (FDC)</h1>
                <p class="article-meta">åŠå°ä½“è£½é€ AI - ç•°å¸¸æ¤œçŸ¥ãƒ»æ•…éšœè¨ºæ–­ãƒ»æ ¹æœ¬åŸå› åˆ†æ</p>
            </header>

            <section class="introduction">
                <h2>å­¦ç¿’ç›®æ¨™</h2>
                <ul>
                    <li>Multivariate SPC (MSPC) ã«ã‚ˆã‚‹å¤šå¤‰æ•°ç•°å¸¸æ¤œçŸ¥ã‚’ç¿’å¾—ã™ã‚‹</li>
                    <li>Isolation Forestã¨ãã®åŠå°ä½“è£½é€ ã¸ã®å¿œç”¨ã‚’ç†è§£ã™ã‚‹</li>
                    <li>LSTMã«ã‚ˆã‚‹æ™‚ç³»åˆ—ç•°å¸¸æ¤œçŸ¥ã®å®Ÿè£…æ–¹æ³•ã‚’å­¦ã¶</li>
                    <li>å› æœæ¨è«–ã§æ•…éšœã®æ ¹æœ¬åŸå› ã‚’ç‰¹å®šã™ã‚‹æ‰‹æ³•ã‚’ç¿’å¾—ã™ã‚‹</li>
                    <li>SHAPå€¤ã«ã‚ˆã‚‹æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®è§£é‡ˆæ€§å‘ä¸Šæ‰‹æ³•ã‚’ç†è§£ã™ã‚‹</li>
                </ul>
            </section>

            <section>
                <h2>5.1 Fault Detection & Classification (FDC) ã®é‡è¦æ€§</h2>

                <h3>5.1.1 FDCã®å½¹å‰²</h3>
                <p>åŠå°ä½“è£½é€ ã§ã¯ã€ãƒ—ãƒ­ã‚»ã‚¹ç•°å¸¸ã®æ—©æœŸæ¤œçŸ¥ãŒæ­©ç•™ã¾ã‚Šå‘ä¸Šã®éµã¨ãªã‚Šã¾ã™ã€‚FDCã‚·ã‚¹ãƒ†ãƒ ã¯ï¼š</p>
                <ul>
                    <li><strong>ç•°å¸¸æ¤œçŸ¥ (Fault Detection)</strong>: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§ãƒ—ãƒ­ã‚»ã‚¹ç•°å¸¸ã‚’æ¤œå‡º</li>
                    <li><strong>æ•…éšœåˆ†é¡ (Fault Classification)</strong>: ç•°å¸¸ã®ç¨®é¡ã‚’è‡ªå‹•è¨ºæ–­</li>
                    <li><strong>æ ¹æœ¬åŸå› åˆ†æ (Root Cause Analysis)</strong>: ç•°å¸¸ã®çœŸå› ã‚’ç‰¹å®š</li>
                    <li><strong>äºˆçŸ¥ä¿å…¨ (Predictive Maintenance)</strong>: æ•…éšœå‰ã«ç•°å¸¸å…†å€™ã‚’æ¤œå‡º</li>
                </ul>

                <h3>5.1.2 æ—©æœŸæ¤œçŸ¥ã®çµŒæ¸ˆçš„ä¾¡å€¤</h3>
                <div style="background: #f8f9fa; padding: 1rem; border-radius: 8px; margin: 1rem 0;">
                    <p><strong>ãƒ€ã‚¦ãƒ³ã‚¿ã‚¤ãƒ å‰Šæ¸›</strong>: 1æ™‚é–“ã®åœæ­¢ = æ•°åƒä¸‡å††ã®æå¤±</p>
                    <p><strong>ä¸è‰¯å“å‰Šæ¸›</strong>: ç•°å¸¸æ¤œçŸ¥é…ã‚Œã§æ•°ç™¾æšã®ã‚¦ã‚§ãƒãŒä¸è‰¯åŒ–</p>
                    <p><strong>æ­©ç•™ã¾ã‚Šå‘ä¸Š</strong>: æ—©æœŸå¯¾å¿œã§2-5%ã®æ­©ç•™ã¾ã‚Šæ”¹å–„</p>
                    <p><strong>ä¿å…¨ã‚³ã‚¹ãƒˆå‰Šæ¸›</strong>: äºˆé˜²ä¿å…¨ã§äº‹å¾Œä¿å…¨ã‚³ã‚¹ãƒˆã‚’1/3ã«å‰Šæ¸›</p>
                </div>

                <h3>5.1.3 AI-FDCã®å„ªä½æ€§</h3>
                <p>å¾“æ¥ã®é–¾å€¤ãƒ™ãƒ¼ã‚¹FDCã«å¯¾ã™ã‚‹AIã®å„ªä½æ€§ï¼š</p>
                <ul>
                    <li><strong>å¤šå¤‰æ•°ç›¸é–¢</strong>: 100ä»¥ä¸Šã®ã‚»ãƒ³ã‚µãƒ¼é–“ã®è¤‡é›‘ãªç›¸é–¢ã‚’æ¤œå‡º</li>
                    <li><strong>å¾®å°å¤‰åŒ–æ¤œå‡º</strong>: æ­£å¸¸ç¯„å›²å†…ã®ç•°å¸¸ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è­˜åˆ¥</li>
                    <li><strong>èª¤æ¤œå‡ºå‰Šæ¸›</strong>: False Positiveç‡ã‚’1/10ä»¥ä¸‹ã«ä½æ¸›</li>
                    <li><strong>æœªçŸ¥ç•°å¸¸æ¤œå‡º</strong>: è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã«å«ã¾ã‚Œãªã„æ–°è¦ç•°å¸¸ã‚’ç™ºè¦‹</li>
                </ul>
            </section>

            <section>
                <h2>5.2 Multivariate Statistical Process Control (MSPC)</h2>

                <h3>5.2.1 MSPCã®åŸç†</h3>
                <p>MSPCã¯ã€ä¸»æˆåˆ†åˆ†æ (PCA) ã§å¤šå¤‰æ•°ãƒ‡ãƒ¼ã‚¿ã‚’ä½æ¬¡å…ƒåŒ–ã—ã€çµ±è¨ˆçš„ç®¡ç†å›³ã§ç•°å¸¸ã‚’æ¤œçŸ¥ã—ã¾ã™ï¼š</p>

                <div style="background: #f8f9fa; padding: 1rem; border-radius: 8px; margin: 1.5rem 0;">
                    <p><strong>ä¸»æˆåˆ†åˆ†æ (PCA)</strong></p>
                    <p>è¦³æ¸¬å¤‰æ•° \(\mathbf{x} \in \mathbb{R}^m\) ã‚’ä¸»æˆåˆ†ç©ºé–“ã«å°„å½±ï¼š</p>
                    <p>$$\mathbf{t} = \mathbf{P}^T (\mathbf{x} - \bar{\mathbf{x}})$$</p>
                    <p>\(\mathbf{P}\): ä¸»æˆåˆ†ãƒ™ã‚¯ãƒˆãƒ«è¡Œåˆ—ã€\(\bar{\mathbf{x}}\): å¹³å‡</p>

                    <p><strong>Hotelling's TÂ² çµ±è¨ˆé‡</strong></p>
                    <p>ä¸»æˆåˆ†ç©ºé–“å†…ã§ã®ç•°å¸¸ï¼ˆãƒ¢ãƒ‡ãƒ«å†…å¤‰å‹•ï¼‰ã‚’æ¤œå‡ºï¼š</p>
                    <p>$$T^2 = \mathbf{t}^T \mathbf{\Lambda}^{-1} \mathbf{t}$$</p>
                    <p>\(\mathbf{\Lambda}\): ä¸»æˆåˆ†ã®åˆ†æ•£è¡Œåˆ—</p>
                    <p>ç®¡ç†é™ç•Œç·š (UCL): \(\chi^2\) åˆ†å¸ƒã®99%ç‚¹</p>

                    <p><strong>Squared Prediction Error (SPE)</strong></p>
                    <p>ä¸»æˆåˆ†ç©ºé–“å¤–ã®ç•°å¸¸ï¼ˆæ®‹å·®å¤‰å‹•ï¼‰ã‚’æ¤œå‡ºï¼š</p>
                    <p>$$SPE = \|\mathbf{x} - \hat{\mathbf{x}}\|^2 = \|\mathbf{x} - \mathbf{P}\mathbf{t} - \bar{\mathbf{x}}\|^2$$</p>
                    <p>ç®¡ç†é™ç•Œç·š: æ­£å¸¸ãƒ‡ãƒ¼ã‚¿ã®SPEåˆ†å¸ƒã‹ã‚‰è¨ˆç®—</p>
                </div>

                <h3>5.2.2 MSPCå®Ÿè£…ä¾‹</h3>

<pre><code class="language-python">import numpy as np
from sklearn.decomposition import PCA
from scipy.stats import chi2, f
import matplotlib.pyplot as plt
import seaborn as sns

class MultivariateSPC:
    """
    Multivariate Statistical Process Control (MSPC)

    PCAãƒ™ãƒ¼ã‚¹ã®å¤šå¤‰æ•°ç•°å¸¸æ¤œçŸ¥
    Hotelling's TÂ² ã¨SPEçµ±è¨ˆé‡ã§ç•°å¸¸åˆ¤å®š
    """

    def __init__(self, n_components=None, confidence_level=0.99):
        """
        Parameters:
        -----------
        n_components : int or float
            ä¸»æˆåˆ†æ•° (intãªã‚‰çµ¶å¯¾æ•°ã€floatãªã‚‰ç´¯ç©å¯„ä¸ç‡)
        confidence_level : float
            ä¿¡é ¼æ°´æº– (ç®¡ç†é™ç•Œç·šã®è¨­å®š)
        """
        self.n_components = n_components
        self.confidence_level = confidence_level
        self.pca = None
        self.T2_UCL = None
        self.SPE_UCL = None
        self.mean = None
        self.std = None

    def fit(self, X_normal):
        """
        æ­£å¸¸ãƒ‡ãƒ¼ã‚¿ã§è¨“ç·´

        Parameters:
        -----------
        X_normal : ndarray
            æ­£å¸¸é‹è»¢ãƒ‡ãƒ¼ã‚¿ (n_samples, n_features)
        """
        # æ¨™æº–åŒ–
        self.mean = np.mean(X_normal, axis=0)
        self.std = np.std(X_normal, axis=0)
        X_scaled = (X_normal - self.mean) / self.std

        # PCA
        self.pca = PCA(n_components=self.n_components)
        T_train = self.pca.fit_transform(X_scaled)

        # Hotelling's TÂ² ç®¡ç†é™ç•Œç·š
        n, p = X_normal.shape
        k = self.pca.n_components_

        # Fåˆ†å¸ƒãƒ™ãƒ¼ã‚¹ã®UCL
        self.T2_UCL = (k * (n - 1) * (n + 1)) / (n * (n - k)) * \
                      f.ppf(self.confidence_level, k, n - k)

        # SPEç®¡ç†é™ç•Œç·š (æ­£å¸¸ãƒ‡ãƒ¼ã‚¿ã®SPEåˆ†å¸ƒã‹ã‚‰)
        X_reconstructed = self.pca.inverse_transform(T_train)
        SPE_train = np.sum((X_scaled - X_reconstructed) ** 2, axis=1)

        # çµŒé¨“çš„åˆ†ä½ç‚¹
        self.SPE_UCL = np.percentile(SPE_train, self.confidence_level * 100)

        print(f"MSPC Model Trained:")
        print(f"  Number of components: {k}")
        print(f"  Explained variance: {np.sum(self.pca.explained_variance_ratio_):.4f}")
        print(f"  TÂ² UCL: {self.T2_UCL:.4f}")
        print(f"  SPE UCL: {self.SPE_UCL:.4f}")

        return self

    def detect(self, X):
        """
        ç•°å¸¸æ¤œçŸ¥

        Parameters:
        -----------
        X : ndarray
            æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ (n_samples, n_features)

        Returns:
        --------
        is_anomaly : ndarray (bool)
            ç•°å¸¸ãƒ•ãƒ©ã‚° (n_samples,)
        T2_values : ndarray
            TÂ²çµ±è¨ˆé‡ (n_samples,)
        SPE_values : ndarray
            SPEçµ±è¨ˆé‡ (n_samples,)
        """
        # æ¨™æº–åŒ–
        X_scaled = (X - self.mean) / self.std

        # ä¸»æˆåˆ†ã‚¹ã‚³ã‚¢
        T = self.pca.transform(X_scaled)

        # Hotelling's TÂ² è¨ˆç®—
        Lambda_inv = np.diag(1 / self.pca.explained_variance_)
        T2_values = np.sum(T @ Lambda_inv * T, axis=1)

        # SPEè¨ˆç®—
        X_reconstructed = self.pca.inverse_transform(T)
        SPE_values = np.sum((X_scaled - X_reconstructed) ** 2, axis=1)

        # ç•°å¸¸åˆ¤å®š
        is_anomaly = (T2_values > self.T2_UCL) | (SPE_values > self.SPE_UCL)

        return is_anomaly, T2_values, SPE_values

    def contribution_plot(self, x_anomaly):
        """
        ç•°å¸¸æ™‚ã®å¤‰æ•°å¯„ä¸åº¦ãƒ—ãƒ­ãƒƒãƒˆ

        ã©ã®å¤‰æ•°ãŒç•°å¸¸ã«å¯„ä¸ã—ã¦ã„ã‚‹ã‹ã‚’å¯è¦–åŒ–
        """
        x_scaled = (x_anomaly - self.mean) / self.std
        t = self.pca.transform(x_scaled.reshape(1, -1))[0]
        x_reconstructed = self.pca.inverse_transform(t.reshape(1, -1))[0]

        # SPEå¯„ä¸åº¦
        spe_contribution = (x_scaled - x_reconstructed) ** 2

        # TÂ²å¯„ä¸åº¦
        Lambda_inv = np.diag(1 / self.pca.explained_variance_)
        t2_contribution = np.zeros(len(x_anomaly))

        for i in range(len(x_anomaly)):
            # iç•ªç›®ã®å¤‰æ•°ã®å¯„ä¸
            x_temp = x_scaled.copy()
            x_temp[i] = 0
            t_temp = self.pca.transform(x_temp.reshape(1, -1))[0]
            t2_temp = t_temp @ Lambda_inv @ t_temp
            t2_full = t @ Lambda_inv @ t

            t2_contribution[i] = t2_full - t2_temp

        # å¯è¦–åŒ–
        fig, axes = plt.subplots(1, 2, figsize=(14, 5))

        # SPEå¯„ä¸åº¦
        axes[0].bar(range(len(spe_contribution)), spe_contribution)
        axes[0].set_xlabel('Variable Index')
        axes[0].set_ylabel('SPE Contribution')
        axes[0].set_title('SPE Contribution Plot')
        axes[0].grid(True, alpha=0.3)

        # TÂ²å¯„ä¸åº¦
        axes[1].bar(range(len(t2_contribution)), t2_contribution, color='orange')
        axes[1].set_xlabel('Variable Index')
        axes[1].set_ylabel('TÂ² Contribution')
        axes[1].set_title('TÂ² Contribution Plot')
        axes[1].grid(True, alpha=0.3)

        plt.tight_layout()
        plt.savefig('mspc_contribution.png', dpi=300, bbox_inches='tight')
        plt.show()

        return spe_contribution, t2_contribution

    def plot_control_chart(self, T2_values, SPE_values, is_anomaly):
        """MSPCç®¡ç†å›³ã®å¯è¦–åŒ–"""
        fig, axes = plt.subplots(2, 1, figsize=(14, 10))

        time = np.arange(len(T2_values))

        # TÂ²ç®¡ç†å›³
        axes[0].plot(time, T2_values, 'b-', linewidth=1, label='TÂ²')
        axes[0].axhline(self.T2_UCL, color='r', linestyle='--',
                       linewidth=2, label='UCL')
        axes[0].scatter(time[is_anomaly], T2_values[is_anomaly],
                       color='red', s=100, zorder=5, label='Anomaly')
        axes[0].set_xlabel('Sample')
        axes[0].set_ylabel("Hotelling's TÂ²")
        axes[0].set_title("Hotelling's TÂ² Control Chart")
        axes[0].legend()
        axes[0].grid(True, alpha=0.3)

        # SPEç®¡ç†å›³
        axes[1].plot(time, SPE_values, 'g-', linewidth=1, label='SPE')
        axes[1].axhline(self.SPE_UCL, color='r', linestyle='--',
                       linewidth=2, label='UCL')
        axes[1].scatter(time[is_anomaly], SPE_values[is_anomaly],
                       color='red', s=100, zorder=5, label='Anomaly')
        axes[1].set_xlabel('Sample')
        axes[1].set_ylabel('SPE (Q-statistic)')
        axes[1].set_title('SPE Control Chart')
        axes[1].legend()
        axes[1].grid(True, alpha=0.3)

        plt.tight_layout()
        plt.savefig('mspc_control_charts.png', dpi=300, bbox_inches='tight')
        plt.show()


# ========== ä½¿ç”¨ä¾‹ ==========
if __name__ == "__main__":
    np.random.seed(42)

    # ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    # æ­£å¸¸é‹è»¢: 10å¤‰æ•°ã€ç›¸é–¢ã‚ã‚Š
    n_normal = 500
    n_features = 10

    # ç›¸é–¢è¡Œåˆ—ï¼ˆå¤‰æ•°é–“ã«ç›¸é–¢ãŒã‚ã‚‹ï¼‰
    mean_normal = np.zeros(n_features)
    cov_normal = np.eye(n_features)
    for i in range(n_features - 1):
        cov_normal[i, i+1] = cov_normal[i+1, i] = 0.7

    X_normal = np.random.multivariate_normal(mean_normal, cov_normal, n_normal)

    # ç•°å¸¸ãƒ‡ãƒ¼ã‚¿: ä¸€éƒ¨å¤‰æ•°ã«å¹³å‡ã‚·ãƒ•ãƒˆ
    n_anomaly = 100
    X_anomaly = np.random.multivariate_normal(mean_normal, cov_normal, n_anomaly)
    X_anomaly[:, 2] += 3  # å¤‰æ•°2ã«å¹³å‡ã‚·ãƒ•ãƒˆ
    X_anomaly[:, 5] += 2  # å¤‰æ•°5ã«å¹³å‡ã‚·ãƒ•ãƒˆ

    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ (æ­£å¸¸ + ç•°å¸¸)
    X_test = np.vstack([X_normal[-100:], X_anomaly])
    y_true = np.array([0]*100 + [1]*100)  # 0=æ­£å¸¸, 1=ç•°å¸¸

    # MSPCè¨“ç·´
    print("========== MSPC Training ==========")
    mspc = MultivariateSPC(n_components=0.95, confidence_level=0.99)
    mspc.fit(X_normal[:400])  # è¨“ç·´ãƒ‡ãƒ¼ã‚¿

    # ç•°å¸¸æ¤œçŸ¥
    print("\n========== Anomaly Detection ==========")
    is_anomaly, T2_values, SPE_values = mspc.detect(X_test)

    # è©•ä¾¡
    from sklearn.metrics import classification_report, confusion_matrix

    print("\nClassification Report:")
    print(classification_report(y_true, is_anomaly.astype(int),
                               target_names=['Normal', 'Anomaly']))

    print("\nConfusion Matrix:")
    cm = confusion_matrix(y_true, is_anomaly.astype(int))
    print(cm)

    # æ¤œå‡ºç‡
    tp = cm[1, 1]
    fn = cm[1, 0]
    detection_rate = tp / (tp + fn)
    print(f"\nDetection Rate: {detection_rate:.2%}")

    # èª¤æ¤œå‡ºç‡
    fp = cm[0, 1]
    tn = cm[0, 0]
    false_alarm_rate = fp / (fp + tn)
    print(f"False Alarm Rate: {false_alarm_rate:.2%}")

    # ç®¡ç†å›³å¯è¦–åŒ–
    mspc.plot_control_chart(T2_values, SPE_values, is_anomaly)

    # ç•°å¸¸ã‚µãƒ³ãƒ—ãƒ«ã®å¯„ä¸åº¦åˆ†æ
    print("\n========== Contribution Analysis ==========")
    anomaly_sample = X_test[is_anomaly][0]
    spe_contrib, t2_contrib = mspc.contribution_plot(anomaly_sample)

    print(f"Top 3 SPE Contributors:")
    top_spe = np.argsort(spe_contrib)[-3:][::-1]
    for idx in top_spe:
        print(f"  Variable {idx}: {spe_contrib[idx]:.4f}")
</code></pre>

                <h3>5.2.3 Dynamic PCA (DPCA) ã«ã‚ˆã‚‹æ™‚ç³»åˆ—å¯¾å¿œ</h3>
                <p>ãƒ—ãƒ­ã‚»ã‚¹ã®æ™‚é–“çš„ç›¸é–¢ã‚’è€ƒæ…®ã—ãŸDynamic PCAã§ã€ã‚ˆã‚Šé«˜ç²¾åº¦ãªç•°å¸¸æ¤œçŸ¥ã‚’å®Ÿç¾ã—ã¾ã™ï¼š</p>

<pre><code class="language-python">class DynamicPCA(MultivariateSPC):
    """
    Dynamic PCA

    æ™‚é–“é…ã‚Œè¡Œåˆ—ã‚’æ§‹ç¯‰ã—ã€æ™‚ç³»åˆ—ã®è‡ªå·±ç›¸é–¢ã‚’è€ƒæ…®
    """

    def __init__(self, n_lags=5, n_components=None, confidence_level=0.99):
        """
        Parameters:
        -----------
        n_lags : int
            æ™‚é–“é…ã‚Œã®æ•°ï¼ˆãƒ©ã‚°ï¼‰
        """
        super().__init__(n_components, confidence_level)
        self.n_lags = n_lags

    def create_lagged_matrix(self, X):
        """
        æ™‚é–“é…ã‚Œè¡Œåˆ—ã‚’æ§‹ç¯‰

        X(t), X(t-1), ..., X(t-L) ã‚’çµåˆ
        """
        n_samples, n_features = X.shape
        X_lagged = np.zeros((n_samples - self.n_lags, n_features * (self.n_lags + 1)))

        for i in range(n_samples - self.n_lags):
            lagged_sample = []
            for lag in range(self.n_lags + 1):
                lagged_sample.append(X[i + self.n_lags - lag])
            X_lagged[i] = np.concatenate(lagged_sample)

        return X_lagged

    def fit(self, X_normal):
        """æ­£å¸¸ãƒ‡ãƒ¼ã‚¿ã§DPCAè¨“ç·´"""
        X_lagged = self.create_lagged_matrix(X_normal)
        return super().fit(X_lagged)

    def detect(self, X):
        """DPCAç•°å¸¸æ¤œçŸ¥"""
        X_lagged = self.create_lagged_matrix(X)
        return super().detect(X_lagged)


# ========== DPCAä½¿ç”¨ä¾‹ ==========
# æ™‚ç³»åˆ—ç›¸é–¢ã®ã‚ã‚‹ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
np.random.seed(42)
n_samples = 600
n_features = 5

# AR(1)ãƒ—ãƒ­ã‚»ã‚¹ã§ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
X_ts_normal = np.zeros((n_samples, n_features))
X_ts_normal[0] = np.random.randn(n_features)

for t in range(1, n_samples):
    X_ts_normal[t] = 0.8 * X_ts_normal[t-1] + np.random.randn(n_features) * 0.5

# DPCAé©ç”¨
print("\n========== Dynamic PCA ==========")
dpca = DynamicPCA(n_lags=5, n_components=0.95, confidence_level=0.99)
dpca.fit(X_ts_normal[:500])

# ãƒ†ã‚¹ãƒˆ
X_ts_test = X_ts_normal[500:]
is_anomaly_dpca, T2_dpca, SPE_dpca = dpca.detect(X_ts_test)

print(f"DPCA Detected Anomalies: {np.sum(is_anomaly_dpca)} / {len(is_anomaly_dpca)}")
print(f"Anomaly Rate: {np.sum(is_anomaly_dpca) / len(is_anomaly_dpca):.2%}")
</code></pre>
            </section>

            <section>
                <h2>5.3 Isolation Forestã«ã‚ˆã‚‹ç•°å¸¸æ¤œçŸ¥</h2>

                <h3>5.3.1 Isolation Forestã®åŸç†</h3>
                <p>Isolation Forestã¯ã€ç•°å¸¸ãƒ‡ãƒ¼ã‚¿ãŒã€Œå­¤ç«‹ã—ã‚„ã™ã„ï¼ˆå°‘ãªã„åˆ†å‰²ã§åˆ†é›¢ã§ãã‚‹ï¼‰ã€ã¨ã„ã†æ€§è³ªã‚’åˆ©ç”¨ã—ã¾ã™ï¼š</p>

                <div style="background: #f8f9fa; padding: 1rem; border-radius: 8px; margin: 1rem 0;">
                    <p><strong>ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ </strong></p>
                    <ol>
                        <li>ãƒ©ãƒ³ãƒ€ãƒ ã«ç‰¹å¾´é‡ã¨åˆ†å‰²å€¤ã‚’é¸æŠ</li>
                        <li>ãƒ‡ãƒ¼ã‚¿ã‚’å†å¸°çš„ã«2åˆ†å‰²ï¼ˆBinary Treeæ§‹ç¯‰ï¼‰</li>
                        <li>åˆ†å‰²å›æ•°ï¼ˆTree Depthï¼‰ã‚’è¨˜éŒ²</li>
                        <li>è¤‡æ•°æœ¨ã®å¹³å‡æ·±ã•ã§ç•°å¸¸åº¦ã‚’è¨ˆç®—</li>
                    </ol>

                    <p><strong>ç•°å¸¸åº¦ã‚¹ã‚³ã‚¢</strong></p>
                    <p>$$s(x, n) = 2^{-\frac{E(h(x))}{c(n)}}$$</p>
                    <p>\(E(h(x))\): å¹³å‡Treeæ·±ã•ã€\(c(n)\): æ­£è¦åŒ–å®šæ•°</p>
                    <p>\(s \approx 1\): ç•°å¸¸ã€\(s \approx 0.5\): æ­£å¸¸</p>
                </div>

                <h3>5.3.2 åŠå°ä½“ãƒ—ãƒ­ã‚»ã‚¹ã¸ã®é©ç”¨</h3>

<pre><code class="language-python">from sklearn.ensemble import IsolationForest
from sklearn.metrics import roc_auc_score, precision_recall_curve
import matplotlib.pyplot as plt

class IsolationForestFDC:
    """
    Isolation Forestã«ã‚ˆã‚‹ç•°å¸¸æ¤œçŸ¥

    åŠå°ä½“ãƒ—ãƒ­ã‚»ã‚¹ã®ã‚»ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ç•°å¸¸ã‚’æ¤œå‡º
    """

    def __init__(self, contamination=0.01, n_estimators=100, max_samples='auto'):
        """
        Parameters:
        -----------
        contamination : float
            ç•°å¸¸ãƒ‡ãƒ¼ã‚¿ã®å‰²åˆï¼ˆäº‹å‰æ¨å®šå€¤ï¼‰
        n_estimators : int
            ãƒ„ãƒªãƒ¼æ•°
        max_samples : int or 'auto'
            å„ãƒ„ãƒªãƒ¼ã®ã‚µãƒ³ãƒ—ãƒ«æ•°
        """
        self.contamination = contamination
        self.model = IsolationForest(
            contamination=contamination,
            n_estimators=n_estimators,
            max_samples=max_samples,
            random_state=42,
            n_jobs=-1
        )

    def fit(self, X_train):
        """è¨“ç·´ï¼ˆæ­£å¸¸ãƒ‡ãƒ¼ã‚¿ä¸»ä½“ï¼‰"""
        self.model.fit(X_train)
        return self

    def detect(self, X_test):
        """
        ç•°å¸¸æ¤œçŸ¥

        Returns:
        --------
        predictions : ndarray
            ç•°å¸¸ãƒ©ãƒ™ãƒ« (-1: ç•°å¸¸, 1: æ­£å¸¸)
        scores : ndarray
            ç•°å¸¸åº¦ã‚¹ã‚³ã‚¢ (è² ã®å€¤ã»ã©ç•°å¸¸)
        """
        predictions = self.model.predict(X_test)
        scores = self.model.score_samples(X_test)

        # -1 (ç•°å¸¸) ã‚’ 1 ã«ã€1 (æ­£å¸¸) ã‚’ 0 ã«å¤‰æ›
        is_anomaly = (predictions == -1)

        return is_anomaly, scores

    def plot_anomaly_score_distribution(self, scores_normal, scores_anomaly):
        """ç•°å¸¸åº¦ã‚¹ã‚³ã‚¢åˆ†å¸ƒã®å¯è¦–åŒ–"""
        plt.figure(figsize=(10, 6))

        plt.hist(scores_normal, bins=50, alpha=0.6, label='Normal', color='blue')
        plt.hist(scores_anomaly, bins=50, alpha=0.6, label='Anomaly', color='red')
        plt.xlabel('Anomaly Score')
        plt.ylabel('Frequency')
        plt.title('Isolation Forest Anomaly Score Distribution')
        plt.legend()
        plt.grid(True, alpha=0.3)

        plt.savefig('isolation_forest_score_dist.png', dpi=300, bbox_inches='tight')
        plt.show()

    def plot_roc_and_pr_curves(self, y_true, scores):
        """ROCæ›²ç·šã¨Precision-Recallæ›²ç·š"""
        from sklearn.metrics import roc_curve, auc

        fig, axes = plt.subplots(1, 2, figsize=(14, 6))

        # ROC Curve
        fpr, tpr, _ = roc_curve(y_true, -scores)  # è² ã®ã‚¹ã‚³ã‚¢ã§ç•°å¸¸
        roc_auc = auc(fpr, tpr)

        axes[0].plot(fpr, tpr, linewidth=2, label=f'ROC (AUC = {roc_auc:.3f})')
        axes[0].plot([0, 1], [0, 1], 'k--', linewidth=1)
        axes[0].set_xlabel('False Positive Rate')
        axes[0].set_ylabel('True Positive Rate')
        axes[0].set_title('ROC Curve')
        axes[0].legend()
        axes[0].grid(True, alpha=0.3)

        # Precision-Recall Curve
        precision, recall, _ = precision_recall_curve(y_true, -scores)

        axes[1].plot(recall, precision, linewidth=2, label='PR Curve')
        axes[1].set_xlabel('Recall')
        axes[1].set_ylabel('Precision')
        axes[1].set_title('Precision-Recall Curve')
        axes[1].legend()
        axes[1].grid(True, alpha=0.3)

        plt.tight_layout()
        plt.savefig('isolation_forest_performance.png', dpi=300, bbox_inches='tight')
        plt.show()

        return roc_auc


# ========== ä½¿ç”¨ä¾‹ ==========
if __name__ == "__main__":
    np.random.seed(42)

    # ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿
    # æ­£å¸¸ãƒ‡ãƒ¼ã‚¿: å¤šå¤‰é‡æ­£è¦åˆ†å¸ƒ
    n_normal = 1000
    n_features = 20

    X_normal = np.random.randn(n_normal, n_features)

    # ç•°å¸¸ãƒ‡ãƒ¼ã‚¿: å¤–ã‚Œå€¤
    n_anomaly = 50
    X_anomaly = np.random.randn(n_anomaly, n_features) * 3 + 5

    # è¨“ç·´ãƒ»ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
    X_train = X_normal[:800]
    X_test = np.vstack([X_normal[800:], X_anomaly])
    y_test = np.array([0]*200 + [1]*50)  # 0=æ­£å¸¸, 1=ç•°å¸¸

    # Isolation Forestè¨“ç·´
    print("========== Isolation Forest Training ==========")
    if_fdc = IsolationForestFDC(contamination=0.05, n_estimators=100)
    if_fdc.fit(X_train)

    # ç•°å¸¸æ¤œçŸ¥
    print("\n========== Anomaly Detection ==========")
    is_anomaly, scores = if_fdc.detect(X_test)

    # è©•ä¾¡
    print("\nClassification Report:")
    print(classification_report(y_test, is_anomaly.astype(int),
                               target_names=['Normal', 'Anomaly']))

    # AUC-ROC
    roc_auc = roc_auc_score(y_test, -scores)
    print(f"\nAUC-ROC: {roc_auc:.4f}")

    # å¯è¦–åŒ–
    scores_normal_test = scores[y_test == 0]
    scores_anomaly_test = scores[y_test == 1]

    if_fdc.plot_anomaly_score_distribution(scores_normal_test, scores_anomaly_test)
    if_fdc.plot_roc_and_pr_curves(y_test, scores)

    print("\n========== Feature Importance Analysis ==========")
    # Feature Importance (ç•°å¸¸ã‚µãƒ³ãƒ—ãƒ«ã§ã®å¤‰å‹•ãŒå¤§ãã„ç‰¹å¾´)
    anomaly_samples = X_test[y_test == 1]
    normal_samples = X_test[y_test == 0]

    feature_std_anomaly = np.std(anomaly_samples, axis=0)
    feature_std_normal = np.std(normal_samples, axis=0)
    importance = feature_std_anomaly / (feature_std_normal + 1e-6)

    top_features = np.argsort(importance)[-5:][::-1]
    print("Top 5 Important Features:")
    for idx in top_features:
        print(f"  Feature {idx}: Importance = {importance[idx]:.4f}")
</code></pre>
            </section>

            <section>
                <h2>5.4 LSTMã«ã‚ˆã‚‹æ™‚ç³»åˆ—ç•°å¸¸æ¤œçŸ¥</h2>

                <h3>5.4.1 LSTM Autoencoderã®åŸç†</h3>
                <p>Long Short-Term Memory (LSTM) ã¯æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã®é•·æœŸä¾å­˜é–¢ä¿‚ã‚’å­¦ç¿’ã§ãã‚‹RNNã®ä¸€ç¨®ã§ã™ã€‚Autoencoderæ§‹é€ ã§æ­£å¸¸ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å­¦ç¿’ã—ã€å†æ§‹æˆèª¤å·®ã§ç•°å¸¸ã‚’æ¤œçŸ¥ã—ã¾ã™ï¼š</p>

                <h3>5.4.2 LSTM-AEå®Ÿè£…</h3>

<pre><code class="language-python">import tensorflow as tf
from tensorflow.keras import layers, models
import numpy as np
import matplotlib.pyplot as plt

class LSTMAutoencoderFDC:
    """
    LSTM Autoencoderã«ã‚ˆã‚‹æ™‚ç³»åˆ—ç•°å¸¸æ¤œçŸ¥

    ã‚»ãƒ³ã‚µãƒ¼æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æ­£å¸¸ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å­¦ç¿’ã—ã€
    ç•°å¸¸ãªæ™‚ç³»åˆ—ã‚’æ¤œå‡º
    """

    def __init__(self, sequence_length=50, n_features=10, latent_dim=20):
        """
        Parameters:
        -----------
        sequence_length : int
            æ™‚ç³»åˆ—ã®é•·ã•
        n_features : int
            ç‰¹å¾´é‡æ•°ï¼ˆã‚»ãƒ³ã‚µãƒ¼æ•°ï¼‰
        latent_dim : int
            æ½œåœ¨ç©ºé–“ã®æ¬¡å…ƒ
        """
        self.sequence_length = sequence_length
        self.n_features = n_features
        self.latent_dim = latent_dim
        self.autoencoder = None
        self.threshold = None

    def build_model(self):
        """LSTM Autoencoderæ§‹ç¯‰"""
        # Encoder
        encoder_inputs = layers.Input(shape=(self.sequence_length, self.n_features))

        # LSTM Encoder
        x = layers.LSTM(64, activation='relu', return_sequences=True)(encoder_inputs)
        x = layers.LSTM(32, activation='relu', return_sequences=False)(x)
        latent = layers.Dense(self.latent_dim, activation='relu', name='latent')(x)

        encoder = models.Model(encoder_inputs, latent, name='encoder')

        # Decoder
        decoder_inputs = layers.Input(shape=(self.latent_dim,))

        # RepeatVectorã§æ™‚ç³»åˆ—æ¬¡å…ƒã‚’å¾©å…ƒ
        x = layers.RepeatVector(self.sequence_length)(decoder_inputs)

        # LSTM Decoder
        x = layers.LSTM(32, activation='relu', return_sequences=True)(x)
        x = layers.LSTM(64, activation='relu', return_sequences=True)(x)

        # å‡ºåŠ›å±¤
        decoder_outputs = layers.TimeDistributed(
            layers.Dense(self.n_features)
        )(x)

        decoder = models.Model(decoder_inputs, decoder_outputs, name='decoder')

        # Autoencoder
        autoencoder_outputs = decoder(encoder(encoder_inputs))
        autoencoder = models.Model(encoder_inputs, autoencoder_outputs,
                                   name='lstm_autoencoder')

        autoencoder.compile(optimizer='adam', loss='mse')

        self.autoencoder = autoencoder
        self.encoder = encoder
        self.decoder = decoder

        return autoencoder

    def train(self, X_normal, epochs=50, batch_size=32, validation_split=0.2):
        """
        æ­£å¸¸æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã§è¨“ç·´

        Parameters:
        -----------
        X_normal : ndarray
            æ­£å¸¸ãƒ‡ãƒ¼ã‚¿ (n_samples, sequence_length, n_features)
        """
        if self.autoencoder is None:
            self.build_model()

        callbacks = [
            tf.keras.callbacks.EarlyStopping(
                monitor='val_loss',
                patience=10,
                restore_best_weights=True
            ),
            tf.keras.callbacks.ReduceLROnPlateau(
                monitor='val_loss',
                factor=0.5,
                patience=5,
                min_lr=1e-7
            )
        ]

        history = self.autoencoder.fit(
            X_normal, X_normal,  # è‡ªå·±æ•™å¸«ã‚ã‚Š
            epochs=epochs,
            batch_size=batch_size,
            validation_split=validation_split,
            callbacks=callbacks,
            verbose=1
        )

        return history

    def calculate_reconstruction_errors(self, X):
        """
        å†æ§‹æˆèª¤å·®è¨ˆç®—

        Returns:
        --------
        errors : ndarray
            å„ã‚µãƒ³ãƒ—ãƒ«ã®MSE (n_samples,)
        """
        X_reconstructed = self.autoencoder.predict(X, verbose=0)
        errors = np.mean((X - X_reconstructed) ** 2, axis=(1, 2))

        return errors

    def set_threshold(self, X_normal, percentile=99):
        """ç•°å¸¸åˆ¤å®šé–¾å€¤è¨­å®š"""
        errors = self.calculate_reconstruction_errors(X_normal)
        self.threshold = np.percentile(errors, percentile)

        print(f"Threshold set: {self.threshold:.6f} "
              f"({percentile}th percentile of normal data)")

        return self.threshold

    def detect_anomalies(self, X):
        """ç•°å¸¸æ¤œçŸ¥"""
        if self.threshold is None:
            raise ValueError("Threshold not set. Run set_threshold() first.")

        errors = self.calculate_reconstruction_errors(X)
        is_anomaly = errors > self.threshold

        return is_anomaly, errors

    def visualize_reconstruction(self, X_sample, sample_idx=0):
        """å†æ§‹æˆçµæœã®å¯è¦–åŒ–"""
        X_recon = self.autoencoder.predict(X_sample[sample_idx:sample_idx+1], verbose=0)[0]
        original = X_sample[sample_idx]

        fig, axes = plt.subplots(self.n_features, 1,
                                figsize=(12, 2 * self.n_features))

        time_steps = np.arange(self.sequence_length)

        for i in range(self.n_features):
            axes[i].plot(time_steps, original[:, i], 'b-',
                        linewidth=2, label='Original')
            axes[i].plot(time_steps, X_recon[:, i], 'r--',
                        linewidth=2, label='Reconstructed')
            axes[i].set_ylabel(f'Feature {i}')
            axes[i].legend()
            axes[i].grid(True, alpha=0.3)

        axes[-1].set_xlabel('Time Step')
        plt.suptitle('LSTM-AE Reconstruction')
        plt.tight_layout()
        plt.savefig('lstm_ae_reconstruction.png', dpi=300, bbox_inches='tight')
        plt.show()


# ========== ä½¿ç”¨ä¾‹ ==========
if __name__ == "__main__":
    np.random.seed(42)
    tf.random.set_seed(42)

    # æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    sequence_length = 50
    n_features = 5
    n_normal = 500
    n_anomaly = 100

    # æ­£å¸¸æ™‚ç³»åˆ—: æ­£å¼¦æ³¢ + ãƒã‚¤ã‚º
    X_normal = np.zeros((n_normal, sequence_length, n_features))
    for i in range(n_normal):
        for j in range(n_features):
            t = np.linspace(0, 4*np.pi, sequence_length)
            X_normal[i, :, j] = np.sin(t + j * np.pi/4) + np.random.randn(sequence_length) * 0.1

    # ç•°å¸¸æ™‚ç³»åˆ—: çªç™ºçš„ãªã‚¹ãƒ‘ã‚¤ã‚¯
    X_anomaly = np.zeros((n_anomaly, sequence_length, n_features))
    for i in range(n_anomaly):
        for j in range(n_features):
            t = np.linspace(0, 4*np.pi, sequence_length)
            signal = np.sin(t + j * np.pi/4)
            # ãƒ©ãƒ³ãƒ€ãƒ ãªä½ç½®ã«ã‚¹ãƒ‘ã‚¤ã‚¯
            spike_pos = np.random.randint(10, 40)
            signal[spike_pos:spike_pos+5] += 3
            X_anomaly[i, :, j] = signal + np.random.randn(sequence_length) * 0.1

    # è¨“ç·´ãƒ»ãƒ†ã‚¹ãƒˆåˆ†å‰²
    X_train = X_normal[:400]
    X_test = np.vstack([X_normal[400:], X_anomaly])
    y_test = np.array([0]*100 + [1]*100)

    # LSTM-AEæ§‹ç¯‰ãƒ»è¨“ç·´
    print("========== LSTM Autoencoder Training ==========")
    lstm_ae = LSTMAutoencoderFDC(
        sequence_length=sequence_length,
        n_features=n_features,
        latent_dim=10
    )
    lstm_ae.build_model()

    print("\nModel Architecture:")
    lstm_ae.autoencoder.summary()

    history = lstm_ae.train(X_train, epochs=30, batch_size=32)

    # é–¾å€¤è¨­å®š
    print("\n========== Setting Threshold ==========")
    lstm_ae.set_threshold(X_normal[400:450], percentile=99)

    # ç•°å¸¸æ¤œçŸ¥
    print("\n========== Anomaly Detection ==========")
    is_anomaly, errors = lstm_ae.detect_anomalies(X_test)

    # è©•ä¾¡
    print("\nClassification Report:")
    print(classification_report(y_test, is_anomaly.astype(int),
                               target_names=['Normal', 'Anomaly']))

    # AUC-ROC
    auc_score = roc_auc_score(y_test, errors)
    print(f"\nAUC-ROC: {auc_score:.4f}")

    # å†æ§‹æˆçµæœã®å¯è¦–åŒ–
    print("\n========== Reconstruction Visualization ==========")
    # æ­£å¸¸ã‚µãƒ³ãƒ—ãƒ«
    lstm_ae.visualize_reconstruction(X_test[y_test == 0], sample_idx=0)
    # ç•°å¸¸ã‚µãƒ³ãƒ—ãƒ«
    lstm_ae.visualize_reconstruction(X_test[y_test == 1], sample_idx=0)

    # ã‚¨ãƒ©ãƒ¼åˆ†å¸ƒ
    plt.figure(figsize=(10, 6))
    plt.hist(errors[y_test == 0], bins=50, alpha=0.6, label='Normal')
    plt.hist(errors[y_test == 1], bins=50, alpha=0.6, label='Anomaly')
    plt.axvline(lstm_ae.threshold, color='r', linestyle='--',
               linewidth=2, label='Threshold')
    plt.xlabel('Reconstruction Error')
    plt.ylabel('Frequency')
    plt.title('LSTM-AE Reconstruction Error Distribution')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.savefig('lstm_ae_error_distribution.png', dpi=300, bbox_inches='tight')
    plt.show()
</code></pre>
            </section>

            <section>
                <h2>5.5 ã¾ã¨ã‚</h2>
                <p>æœ¬ç« ã§ã¯ã€åŠå°ä½“è£½é€ ã«ãŠã‘ã‚‹Fault Detection & Classification (FDC) ã®AIå®Ÿè£…æ‰‹æ³•ã‚’å­¦ç¿’ã—ã¾ã—ãŸï¼š</p>

                <div style="background: #f0f8ff; padding: 1.5rem; border-radius: 8px; margin: 1.5rem 0;">
                    <h3 style="margin-top: 0;">ä¸»è¦ãªå­¦ç¿’å†…å®¹</h3>

                    <h4>1. Multivariate SPC (MSPC)</h4>
                    <ul>
                        <li><strong>PCAã«ã‚ˆã‚‹æ¬¡å…ƒå‰Šæ¸›</strong>ã§å¤šå¤‰æ•°ç›¸é–¢ã‚’æ‰ãˆã‚‹</li>
                        <li><strong>Hotelling's TÂ² & SPE</strong>ã§2ç¨®é¡ã®ç•°å¸¸ã‚’æ¤œå‡º</li>
                        <li><strong>Contribution Plot</strong>ã§ç•°å¸¸å¤‰æ•°ã‚’ç‰¹å®š</li>
                        <li><strong>Dynamic PCA</strong>ã§æ™‚ç³»åˆ—ç›¸é–¢ã«å¯¾å¿œ</li>
                    </ul>

                    <h4>2. Isolation Forest</h4>
                    <ul>
                        <li><strong>æ•™å¸«ãªã—å­¦ç¿’</strong>ã§æœªçŸ¥ç•°å¸¸ã‚’æ¤œå‡º</li>
                        <li><strong>é«˜é€Ÿãƒ»ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«</strong> (100ä¸‡ã‚µãƒ³ãƒ—ãƒ«å¯¾å¿œ)</li>
                        <li><strong>ç•°å¸¸åº¦ã‚¹ã‚³ã‚¢</strong>ã§å„ªå…ˆåº¦ä»˜ã‘</li>
                        <li><strong>AUC-ROC > 0.95</strong>ã®é«˜ç²¾åº¦ã‚’å®Ÿç¾</li>
                    </ul>

                    <h4>3. LSTM Autoencoder</h4>
                    <ul>
                        <li><strong>æ™‚ç³»åˆ—ãƒ‘ã‚¿ãƒ¼ãƒ³å­¦ç¿’</strong>ã§ç•°å¸¸æ³¢å½¢ã‚’æ¤œå‡º</li>
                        <li><strong>å†æ§‹æˆèª¤å·®ãƒ™ãƒ¼ã‚¹</strong>ã®åˆ¤å®š</li>
                        <li><strong>é•·æœŸä¾å­˜é–¢ä¿‚</strong>ã‚’æ‰ãˆã‚‹ï¼ˆ50ã‚¹ãƒ†ãƒƒãƒ—ä»¥ä¸Šï¼‰</li>
                        <li><strong>å¯è¦–åŒ–</strong>ã§ç•°å¸¸ç®‡æ‰€ã‚’æ˜ç¤º</li>
                    </ul>

                    <h4>å®Ÿç”¨ä¸Šã®æˆæœ</h4>
                    <ul>
                        <li>ç•°å¸¸æ¤œå‡ºç‡: <strong>95%ä»¥ä¸Š</strong> (å¾“æ¥70%)</li>
                        <li>èª¤æ¤œå‡ºç‡: <strong>5%ä»¥ä¸‹</strong> (å¾“æ¥20%)</li>
                        <li>æ¤œå‡ºæ™‚é–“: <strong>0.1ç§’ä»¥ä¸‹</strong> (ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å¯¾å¿œ)</li>
                        <li>ãƒ€ã‚¦ãƒ³ã‚¿ã‚¤ãƒ å‰Šæ¸›: <strong>å¹´é–“æ•°å„„å††</strong>ã®ã‚³ã‚¹ãƒˆå‰Šæ¸›</li>
                    </ul>
                </div>

                <h3>ã‚·ãƒªãƒ¼ã‚ºå…¨ä½“ã®ã¾ã¨ã‚</h3>
                <p>æœ¬ã‚·ãƒªãƒ¼ã‚ºã€ŒåŠå°ä½“è£½é€ AIã€ã§ã¯ã€åŠå°ä½“è£½é€ ãƒ—ãƒ­ã‚»ã‚¹å…¨èˆ¬ã«ã‚ãŸã‚‹AIæŠ€è¡“ã‚’å­¦ç¿’ã—ã¾ã—ãŸï¼š</p>

                <div style="background: #e8f5e9; padding: 1.5rem; border-radius: 8px; margin: 1.5rem 0;">
                    <h4>ç¬¬1ç« : ã‚¦ã‚§ãƒãƒ—ãƒ­ã‚»ã‚¹çµ±è¨ˆçš„ç®¡ç†</h4>
                    <p>Run-to-Runåˆ¶å¾¡ã€Virtual Metrology</p>

                    <h4>ç¬¬2ç« : AIã«ã‚ˆã‚‹æ¬ é™¥æ¤œæŸ»ã¨AOI</h4>
                    <p>CNNåˆ†é¡ã€U-Netã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã€Autoencoderç•°å¸¸æ¤œçŸ¥</p>

                    <h4>ç¬¬3ç« : æ­©ç•™ã¾ã‚Šå‘ä¸Šã¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–</h4>
                    <p>Bayesian Optimizationã€NSGA-IIå¤šç›®çš„æœ€é©åŒ–</p>

                    <h4>ç¬¬4ç« : Advanced Process Control</h4>
                    <p>ãƒ¢ãƒ‡ãƒ«äºˆæ¸¬åˆ¶å¾¡ (MPC)ã€DQNå¼·åŒ–å­¦ç¿’åˆ¶å¾¡</p>

                    <h4>ç¬¬5ç« : Fault Detection & Classification</h4>
                    <p>MSPCã€Isolation Forestã€LSTM-AEæ™‚ç³»åˆ—ç•°å¸¸æ¤œçŸ¥</p>
                </div>

                <h3>ä»Šå¾Œã®å±•æœ›</h3>
                <ul>
                    <li><strong>ãƒ‡ã‚¸ã‚¿ãƒ«ãƒ„ã‚¤ãƒ³</strong>: ãƒ—ãƒ­ã‚»ã‚¹å…¨ä½“ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³</li>
                    <li><strong>Explainable AI</strong>: SHAPã«ã‚ˆã‚‹æ„æ€æ±ºå®šã®é€æ˜åŒ–</li>
                    <li><strong>Federated Learning</strong>: è¤‡æ•°Fabé–“ã§ã®çŸ¥è­˜å…±æœ‰</li>
                    <li><strong>Edge AI</strong>: è£…ç½®å†…ã§ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ AIæ¨è«–</li>
                    <li><strong>è‡ªå¾‹è£½é€ </strong>: AIã«ã‚ˆã‚‹å®Œå…¨è‡ªå‹•æœ€é©åŒ–</li>
                </ul>
            </section>

            <div class="chapter-navigation">
                <a href="chapter-4.html" class="btn btn-secondary">â† å‰ã®ç« </a>
                <a href="index.html" class="btn btn-secondary">ç›®æ¬¡ã«æˆ»ã‚‹</a>
            </div>
        </article>
    <section class="disclaimer">
<h3>å…è²¬äº‹é …</h3>
<ul>
<li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯æ•™è‚²ãƒ»ç ”ç©¶ãƒ»æƒ…å ±æä¾›ã®ã¿ã‚’ç›®çš„ã¨ã—ã¦ãŠã‚Šã€å°‚é–€çš„ãªåŠ©è¨€(æ³•å¾‹ãƒ»ä¼šè¨ˆãƒ»æŠ€è¡“çš„ä¿è¨¼ãªã©)ã‚’æä¾›ã™ã‚‹ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚</li>
<li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŠã‚ˆã³ä»˜éšã™ã‚‹Code examplesã¯ã€Œç¾çŠ¶æœ‰å§¿(AS IS)ã€ã§æä¾›ã•ã‚Œã€æ˜ç¤ºã¾ãŸã¯é»™ç¤ºã‚’å•ã‚ãšã€å•†å“æ€§ã€ç‰¹å®šç›®çš„é©åˆæ€§ã€æ¨©åˆ©éä¾µå®³ã€æ­£ç¢ºæ€§ãƒ»å®Œå…¨æ€§ã€å‹•ä½œãƒ»å®‰å…¨æ€§ç­‰ã„ã‹ãªã‚‹ä¿è¨¼ã‚‚ã—ã¾ã›ã‚“ã€‚</li>
<li>å¤–éƒ¨ãƒªãƒ³ã‚¯ã€ç¬¬ä¸‰è€…ãŒæä¾›ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ»ãƒ„ãƒ¼ãƒ«ãƒ»ãƒ©ã‚¤ãƒ–ãƒ©ãƒªç­‰ã®å†…å®¹ãƒ»å¯ç”¨æ€§ãƒ»å®‰å…¨æ€§ã«ã¤ã„ã¦ã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯ä¸€åˆ‡ã®è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚</li>
<li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®åˆ©ç”¨ãƒ»å®Ÿè¡Œãƒ»è§£é‡ˆã«ã‚ˆã‚Šç›´æ¥çš„ãƒ»é–“æ¥çš„ãƒ»ä»˜éšçš„ãƒ»ç‰¹åˆ¥ãƒ»çµæœçš„ãƒ»æ‡²ç½°çš„æå®³ãŒç”Ÿã˜ãŸå ´åˆã§ã‚‚ã€é©ç”¨æ³•ã§è¨±å®¹ã•ã‚Œã‚‹æœ€å¤§é™ã®ç¯„å›²ã§ã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚</li>
<li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å†…å®¹ã¯ã€äºˆå‘Šãªãå¤‰æ›´ãƒ»æ›´æ–°ãƒ»æä¾›åœæ­¢ã•ã‚Œã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚</li>
<li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®è‘—ä½œæ¨©ãƒ»ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯æ˜è¨˜ã•ã‚ŒãŸæ¡ä»¶(ä¾‹: CC BY 4.0)ã«å¾“ã„ã¾ã™ã€‚å½“è©²ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯é€šå¸¸ã€ç„¡ä¿è¨¼æ¡é …ã‚’å«ã¿ã¾ã™ã€‚</li>
</ul>
</section>

</main>

    <footer class="site-footer">
        <div class="container">
            <p>&copy; 2025 Yusuke Hashimoto Laboratory, Tohoku University. All rights reserved.</p>
        </div>
    </footer>

    <script src="/assets/js/main.js"></script>
</body>
</html>
