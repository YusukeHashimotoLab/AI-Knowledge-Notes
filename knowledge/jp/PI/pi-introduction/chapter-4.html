<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Á¨¨4Á´†ÔºöÂÆü„Éó„É≠„Çª„Çπ„Éá„Éº„Çø„ÇíÁî®„ÅÑ„ÅüÂÆüË∑µÊºîÁøí - PI Terakoya</title>

    <style>
        :root {
            --color-primary: #2c3e50;
            --color-primary-dark: #1a252f;
            --color-accent: #11998e;
            --color-accent-light: #38ef7d;
            --color-text: #2d3748;
            --color-text-light: #4a5568;
            --color-bg: #ffffff;
            --color-bg-alt: #f7fafc;
            --color-border: #e2e8f0;
            --color-code-bg: #f8f9fa;
            --color-link: #11998e;
            --color-link-hover: #0d7a6f;

            --spacing-xs: 0.5rem;
            --spacing-sm: 1rem;
            --spacing-md: 1.5rem;
            --spacing-lg: 2rem;
            --spacing-xl: 3rem;

            --font-body: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            --font-mono: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;

            --border-radius: 8px;
            --box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: var(--font-body);
            line-height: 1.7;
            color: var(--color-text);
            background-color: var(--color-bg);
            font-size: 16px;
        }

        header {
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            padding: var(--spacing-xl) var(--spacing-md);
            margin-bottom: var(--spacing-xl);
            box-shadow: var(--box-shadow);
        }

        .header-content {
            max-width: 900px;
            margin: 0 auto;
        }

        h1 {
            font-size: 2rem;
            font-weight: 700;
            margin-bottom: var(--spacing-sm);
            line-height: 1.2;
        }

        .subtitle {
            font-size: 1.1rem;
            opacity: 0.95;
            font-weight: 400;
            margin-bottom: var(--spacing-md);
        }

        .meta {
            display: flex;
            flex-wrap: wrap;
            gap: var(--spacing-md);
            font-size: 0.9rem;
            opacity: 0.9;
        }

        .meta-item {
            display: flex;
            align-items: center;
            gap: 0.3rem;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 0 var(--spacing-md) var(--spacing-xl);
        }

        h2 {
            font-size: 1.75rem;
            color: var(--color-primary);
            margin-top: var(--spacing-xl);
            margin-bottom: var(--spacing-md);
            padding-bottom: var(--spacing-xs);
            border-bottom: 3px solid var(--color-accent);
        }

        h3 {
            font-size: 1.4rem;
            color: var(--color-primary);
            margin-top: var(--spacing-lg);
            margin-bottom: var(--spacing-sm);
        }

        h4 {
            font-size: 1.1rem;
            color: var(--color-primary-dark);
            margin-top: var(--spacing-md);
            margin-bottom: var(--spacing-sm);
        }

        p {
            margin-bottom: var(--spacing-md);
            color: var(--color-text);
        }

        a {
            color: var(--color-link);
            text-decoration: none;
            transition: color 0.2s;
        }

        a:hover {
            color: var(--color-link-hover);
            text-decoration: underline;
        }

        ul, ol {
            margin-left: var(--spacing-lg);
            margin-bottom: var(--spacing-md);
        }

        li {
            margin-bottom: var(--spacing-xs);
            color: var(--color-text);
        }

        pre {
            background-color: var(--color-code-bg);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            overflow-x: auto;
            margin-bottom: var(--spacing-md);
            font-family: var(--font-mono);
            font-size: 0.9rem;
            line-height: 1.5;
        }

        code {
            font-family: var(--font-mono);
            font-size: 0.9em;
            background-color: var(--color-code-bg);
            padding: 0.2em 0.4em;
            border-radius: 3px;
        }

        pre code {
            background-color: transparent;
            padding: 0;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: var(--spacing-md);
            font-size: 0.95rem;
        }

        th, td {
            border: 1px solid var(--color-border);
            padding: var(--spacing-sm);
            text-align: left;
        }

        th {
            background-color: var(--color-bg-alt);
            font-weight: 600;
            color: var(--color-primary);
        }

        blockquote {
            border-left: 4px solid var(--color-accent);
            padding-left: var(--spacing-md);
            margin: var(--spacing-md) 0;
            color: var(--color-text-light);
            font-style: italic;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        .mermaid {
            text-align: center;
            margin: var(--spacing-lg) 0;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        details {
            background-color: var(--color-bg-alt);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            margin-bottom: var(--spacing-md);
        }

        summary {
            cursor: pointer;
            font-weight: 600;
            color: var(--color-primary);
            user-select: none;
            padding: var(--spacing-xs);
            margin: calc(-1 * var(--spacing-md));
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        summary:hover {
            background-color: rgba(17, 153, 142, 0.1);
        }

        details[open] summary {
            margin-bottom: var(--spacing-md);
            border-bottom: 1px solid var(--color-border);
        }

        .learning-objectives {
            background: linear-gradient(135deg, #e8f5e9 0%, #c8e6c9 100%);
            padding: var(--spacing-lg);
            border-radius: var(--border-radius);
            border-left: 4px solid var(--color-accent);
            margin-bottom: var(--spacing-xl);
        }

        .learning-objectives h2 {
            margin-top: 0;
            border-bottom: none;
        }

        .navigation {
            display: flex;
            justify-content: space-between;
            gap: var(--spacing-md);
            margin: var(--spacing-xl) 0;
            padding-top: var(--spacing-lg);
            border-top: 2px solid var(--color-border);
        }

        .nav-button {
            flex: 1;
            padding: var(--spacing-md);
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            border-radius: var(--border-radius);
            text-align: center;
            font-weight: 600;
            transition: transform 0.2s, box-shadow 0.2s;
            box-shadow: var(--box-shadow);
        }

        .nav-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
            text-decoration: none;
        }

        footer {
            margin-top: var(--spacing-xl);
            padding: var(--spacing-lg) var(--spacing-md);
            background-color: var(--color-bg-alt);
            border-top: 1px solid var(--color-border);
            text-align: center;
            font-size: 0.9rem;
            color: var(--color-text-light);
        }

        @media (max-width: 768px) {
            h1 {
                font-size: 1.5rem;
            }

            h2 {
                font-size: 1.4rem;
            }

            h3 {
                font-size: 1.2rem;
            }

            .meta {
                font-size: 0.85rem;
            }

            .navigation {
                flex-direction: column;
            }

            table {
                font-size: 0.85rem;
            }

            th, td {
                padding: var(--spacing-xs);
            }
        }
    </style>

    <script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
    <script>
        mermaid.initialize({ startOnLoad: true, theme: 'default', securityLevel: 'strict' });
    </script>

    <!-- MathJax for LaTeX equation rendering -->
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                displayMath: [['$$', '$$'], ['\\[', '\\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
                ignoreHtmlClass: 'mermaid'
            }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" async></script>
</head>
<body>
    <header>
        <div class="header-content">
            <h1>Á¨¨4Á´†ÔºöÂÆü„Éó„É≠„Çª„Çπ„Éá„Éº„Çø„ÇíÁî®„ÅÑ„ÅüÂÆüË∑µÊºîÁøí</h1>
            <p class="subtitle">Á∑èÂêàÊºîÁøíÔºöÂåñÂ≠¶„Éó„É©„É≥„Éà„Éá„Éº„Çø„ÅÆÂàÜÊûê„Åã„ÇâÊúÄÈÅ©Âåñ„Åæ„Åß</p>
            <div class="meta">
                <span class="meta-item">üìñ Ë™≠‰∫ÜÊôÇÈñì: 45-50ÂàÜ</span>
                <span class="meta-item">üìä Èõ£ÊòìÂ∫¶: ‰∏≠Á¥ö„Äú‰∏äÁ¥ö</span>
                <span class="meta-item">üíª „Ç≥„Éº„Éâ‰æã: 8ÂÄãÔºàÁµ±Âêà„Éó„É≠„Ç∏„Çß„ÇØ„ÉàÔºâ</span>
            </div>
        </div>
    </header>

    <main class="container">
<h1>Á¨¨4Á´†ÔºöÂÆü„Éó„É≠„Çª„Çπ„Éá„Éº„Çø„ÇíÁî®„ÅÑ„ÅüÂÆüË∑µÊºîÁøí</h1>

<p class="chapter-description" style="margin: 1.5rem 0; padding: 1rem; background: linear-gradient(135deg, #e8f5e9 0%, #c8e6c9 100%); border-left: 4px solid #11998e; border-radius: 8px; font-size: 1.05rem; line-height: 1.8; color: #2d3748;">„Åì„Çå„Åæ„ÅßÂ≠¶„Çì„Å†PI„ÅÆÊâãÊ≥ï„ÇíÁµ±Âêà„Åó„ÄÅÂÆüÈöõ„ÅÆÂåñÂ≠¶„Éó„É©„É≥„Éà„Éá„Éº„Çø„ÇíÁî®„ÅÑ„ÅüÁ∑èÂêàÊºîÁøí„ÇíË°å„ÅÑ„Åæ„Åô„ÄÇ„Éá„Éº„ÇøÊé¢Á¥¢„Åã„ÇâÂìÅË≥™‰∫àÊ∏¨„ÄÅ„Éó„É≠„Çª„ÇπÊúÄÈÅ©Âåñ„Åæ„Åß„ÄÅÂÆüÂãô„Å´Áõ¥Áµê„Åô„Çã„ÉØ„Éº„ÇØ„Éï„É≠„Éº„Çí‰ΩìÈ®ì„Åó„Åæ„Åô„ÄÇ</p>

<div class="learning-objectives">
<h2>Â≠¶ÁøíÁõÆÊ®ô</h2>
<p>„Åì„ÅÆÁ´†„ÇíË™≠„ÇÄ„Åì„Å®„Åß„ÄÅ‰ª•‰∏ã„ÇíÁøíÂæó„Åß„Åç„Åæ„ÅôÔºö</p>
<ul>
<li>‚úÖ ÂÆü„Éó„É≠„Çª„Çπ„Éá„Éº„Çø„ÅÆÊé¢Á¥¢ÁöÑ„Éá„Éº„ÇøÂàÜÊûêÔºàEDAÔºâ„ÇíÂÆüË°å„Åß„Åç„Çã</li>
<li>‚úÖ „Éá„Éº„Çø„ÇØ„É™„Éº„Éã„É≥„Ç∞„Åã„ÇâÁâπÂæ¥Èáè„Ç®„É≥„Ç∏„Éã„Ç¢„É™„É≥„Ç∞„Åæ„ÅßÂÆüË£Ö„Åß„Åç„Çã</li>
<li>‚úÖ Ë§áÊï∞„É¢„Éá„É´„ÅÆÊØîËºÉ„Å®ÊúÄÈÅ©„É¢„Éá„É´„ÅÆÈÅ∏Êäû„Åå„Åß„Åç„Çã</li>
<li>‚úÖ „Éó„É≠„Çª„ÇπÊù°‰ª∂ÊúÄÈÅ©Âåñ„ÅÆÂü∫Á§éÊâãÊ≥ï„ÇíÈÅ©Áî®„Åß„Åç„Çã</li>
<li>‚úÖ „Ç®„É≥„Éâ„ÉÑ„Éº„Ç®„É≥„Éâ„ÅÆPI„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÉØ„Éº„ÇØ„Éï„É≠„Éº„ÇíÁêÜËß£„Åß„Åç„Çã</li>
</ul>
</div>

<hr />

<h2>4.1 „Ç±„Éº„Çπ„Çπ„Çø„Éá„Ç£ÔºöÂåñÂ≠¶„Éó„É©„É≥„ÉàÈÅãËª¢„Éá„Éº„ÇøËß£Êûê</h2>

<h3>„Éó„É≠„Ç∏„Çß„ÇØ„ÉàÊ¶ÇË¶Å</h3>

<p><strong>ËÉåÊôØ</strong>:</p>
<p>„ÅÇ„ÇãÂåñÂ≠¶„Éó„É©„É≥„Éà„ÅÆËí∏ÁïôÂ°î„Åß„ÅØ„ÄÅË£ΩÂìÅÁ¥îÂ∫¶„ÅÆ„Å∞„Çâ„Å§„Åç„ÅåË™≤È°å„Å®„Å™„Å£„Å¶„ÅÑ„Åæ„Åô„ÄÇÂìÅË≥™Ê∏¨ÂÆö„ÅØ1Êó•1Âõû„ÅÆ„Ç¨„Çπ„ÇØ„É≠„Éû„Éà„Ç∞„É©„Éï„Ç£„ÉºÔºàGCÔºâÂàÜÊûê„ÅÆ„Åø„Åß„ÄÅ„É™„Ç¢„É´„Çø„Ç§„É†„Å™ÂìÅË≥™ÁÆ°ÁêÜ„Åå„Åß„Åç„Å¶„ÅÑ„Åæ„Åõ„Çì„ÄÇPI„ÇíÊ¥ªÁî®„Åó„Å¶„ÄÅ‰ª•‰∏ã„ÅÆÁõÆÊ®ô„ÇíÈÅîÊàê„Åó„Åæ„ÅôÔºö</p>

<ol>
<li><strong>ÂìÅË≥™‰∫àÊ∏¨„ÇΩ„Éï„Éà„Çª„É≥„Çµ„Éº„ÅÆÊßãÁØâ</strong>: „Éó„É≠„Çª„ÇπÂ§âÊï∞„Åã„ÇâË£ΩÂìÅÁ¥îÂ∫¶„Çí„É™„Ç¢„É´„Çø„Ç§„É†‰∫àÊ∏¨</li>
<li><strong>ÂìÅË≥™ÂΩ±ÈüøÂõ†Â≠ê„ÅÆÁâπÂÆö</strong>: „Å©„ÅÆÂ§âÊï∞„ÅåÁ¥îÂ∫¶„Å´ÊúÄ„ÇÇÂΩ±Èüø„Åô„Çã„Åã„ÇíÊòé„Çâ„Åã„Å´„Åô„Çã</li>
<li><strong>ÊúÄÈÅ©ÈÅãËª¢Êù°‰ª∂„ÅÆÊé¢Á¥¢</strong>: ÂìÅË≥™„ÇíÊ∫Ä„Åü„Åó„Å§„Å§„Ç®„Éç„É´„ÇÆ„ÉºÊ∂àË≤ª„ÇíÊúÄÂ∞èÂåñ„Åô„ÇãÊù°‰ª∂„ÇíË¶ã„Å§„Åë„Çã</li>
</ol>

<p><strong>Âà©Áî®ÂèØËÉΩ„Å™„Éá„Éº„Çø</strong>:</p>
<table>
<thead>
<tr>
<th>Â§âÊï∞Âêç</th>
<th>Ë™¨Êòé</th>
<th>Ê∏¨ÂÆöÈ†ªÂ∫¶</th>
<th>Âçò‰Ωç</th>
</tr>
</thead>
<tbody>
<tr>
<td>feed_temp</td>
<td>‰æõÁµ¶Ê∏©Â∫¶</td>
<td>1ÂàÜ</td>
<td>¬∞C</td>
</tr>
<tr>
<td>top_temp</td>
<td>Â°îÈ†ÇÊ∏©Â∫¶</td>
<td>1ÂàÜ</td>
<td>¬∞C</td>
</tr>
<tr>
<td>mid_temp</td>
<td>‰∏≠ÊÆµÊ∏©Â∫¶</td>
<td>1ÂàÜ</td>
<td>¬∞C</td>
</tr>
<tr>
<td>bottom_temp</td>
<td>Â°îÂ∫ïÊ∏©Â∫¶</td>
<td>1ÂàÜ</td>
<td>¬∞C</td>
</tr>
<tr>
<td>reflux_ratio</td>
<td>ÈÇÑÊµÅÊØî</td>
<td>1ÂàÜ</td>
<td>-</td>
</tr>
<tr>
<td>reboiler_duty</td>
<td>„É™„Éú„Ç§„É©„ÉºÁÜ±Èáè</td>
<td>1ÂàÜ</td>
<td>kW</td>
</tr>
<tr>
<td>pressure</td>
<td>Â°îÂúßÂäõ</td>
<td>1ÂàÜ</td>
<td>MPa</td>
</tr>
<tr>
<td>feed_rate</td>
<td>‰æõÁµ¶ÊµÅÈáè</td>
<td>1ÂàÜ</td>
<td>kg/h</td>
</tr>
<tr>
<td>purity</td>
<td>Ë£ΩÂìÅÁ¥îÂ∫¶ÔºàÁõÆÁöÑÂ§âÊï∞Ôºâ</td>
<td>1Êó•1Âõû</td>
<td>%</td>
</tr>
</tbody>
</table>

<h4>„Ç≥„Éº„Éâ‰æã1: „Éá„Éº„ÇøÁîüÊàê„Å®EDAÔºàÊé¢Á¥¢ÁöÑ„Éá„Éº„ÇøÂàÜÊûêÔºâ</h4>

<pre><code class="language-python">import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime

# „Ç∑„Éº„ÉâË®≠ÂÆöÔºàÂÜçÁèæÊÄß„ÅÆ„Åü„ÇÅÔºâ
np.random.seed(42)

# 1„É∂ÊúàÂàÜ„ÅÆÈÅãËª¢„Éá„Éº„ÇøÁîüÊàêÔºà1ÂàÜÈñìÈöîÔºâ
n = 43200  # 30Êó• √ó 24ÊôÇÈñì √ó 60ÂàÜ
dates = pd.date_range('2025-01-01', periods=n, freq='1min')

# „Éó„É≠„Çª„ÇπÂ§âÊï∞„ÅÆÁîüÊàêÔºàÁèæÂÆüÁöÑ„Å™Â§âÂãï„Éë„Çø„Éº„É≥Ôºâ
df = pd.DataFrame({
    'timestamp': dates,
    'feed_temp': 60 + np.random.normal(0, 2, n) + 3*np.sin(np.arange(n)*2*np.pi/1440),  # Êó•Âë®Â§âÂãï
    'top_temp': 85 + np.random.normal(0, 1.5, n),
    'mid_temp': 120 + np.random.normal(0, 2, n),
    'bottom_temp': 155 + np.random.normal(0, 3, n),
    'reflux_ratio': 2.5 + np.random.normal(0, 0.2, n),
    'reboiler_duty': 1500 + np.random.normal(0, 80, n),
    'pressure': 1.2 + np.random.normal(0, 0.05, n),
    'feed_rate': 100 + np.random.normal(0, 5, n)
})

# Ë£ΩÂìÅÁ¥îÂ∫¶„ÅÆÁîüÊàêÔºàË§áÈõë„Å™ÈùûÁ∑öÂΩ¢Èñ¢‰øÇÔºâ
df['purity'] = (
    92 +
    0.05 * df['feed_temp'] +
    0.3 * (df['top_temp'] - 85) +
    0.15 * (df['mid_temp'] - 120) +
    0.8 * df['reflux_ratio'] +
    0.002 * df['reboiler_duty'] +
    2.0 * df['pressure'] -
    0.01 * df['feed_rate'] +
    # ÈùûÁ∑öÂΩ¢È†ÖÔºàÊúÄÈÅ©ÁÇπ„ÅÆÂ≠òÂú®Ôºâ
    -0.02 * (df['top_temp'] - 85)**2 +
    np.random.normal(0, 0.4, n)
)

# Ê¨†ÊêçÂÄ§„ÇíËøΩÂä†ÔºàÁèæÂÆüÁöÑ„Å™„Éá„Éº„ÇøÔºâ
missing_indices = np.random.choice(df.index, size=int(n*0.02), replace=False)
df.loc[missing_indices, 'top_temp'] = np.nan

# Â§ñ„ÇåÂÄ§„ÇíËøΩÂä†ÔºàÊ∏¨ÂÆö„Ç®„É©„Éº„Çí„Ç∑„Éü„É•„É¨„Éº„ÉàÔºâ
outlier_indices = np.random.choice(df.index, size=int(n*0.005), replace=False)
df.loc[outlier_indices, 'pressure'] += np.random.choice([-0.5, 0.5], size=len(outlier_indices))

# „Ç™„Éï„É©„Ç§„É≥Ê∏¨ÂÆö„ÅÆ„Ç∑„Éü„É•„É¨„Éº„ÉàÔºà1Êó•1ÂõûÔºâ
df['purity_measured'] = np.nan
df.loc[df.index[::1440], 'purity_measured'] = df.loc[df.index[::1440], 'purity']

# „Éá„Éº„Çø„Çª„ÉÉ„Éà„Çí‰øùÂ≠ò
df.to_csv('distillation_data.csv', index=False)
print(f"„Äê„Éá„Éº„Çø„Çª„ÉÉ„ÉàÁîüÊàêÂÆå‰∫Ü„Äë")
print(f"Á∑è„Éá„Éº„ÇøÊï∞: {len(df):,}‰ª∂")
print(f"ÊúüÈñì: {df['timestamp'].min()} „Äú {df['timestamp'].max()}")
print(f"„Ç™„Éï„É©„Ç§„É≥Ê∏¨ÂÆöÊï∞: {df['purity_measured'].notna().sum()}‰ª∂")

# Âü∫Êú¨Áµ±Ë®àÈáè
print("\n„ÄêÂü∫Êú¨Áµ±Ë®àÈáè„Äë")
print(df.describe().round(2))

# Ê¨†ÊêçÂÄ§„ÅÆÁ¢∫Ë™ç
print("\n„ÄêÊ¨†ÊêçÂÄ§„Äë")
missing_counts = df.isnull().sum()
print(missing_counts[missing_counts > 0])

# EDA: ÂèØË¶ñÂåñ
fig, axes = plt.subplots(3, 3, figsize=(18, 14))

# 1. ‰∏ªË¶ÅÂ§âÊï∞„ÅÆÊôÇÁ≥ªÂàó„Éó„É≠„ÉÉ„ÉàÔºàÊúÄÂàù„ÅÆ3Êó•ÈñìÔºâ
time_window = (df['timestamp'] >= '2025-01-01') & (df['timestamp'] < '2025-01-04')
df_window = df[time_window]

variables = ['feed_temp', 'top_temp', 'mid_temp', 'bottom_temp',
             'reflux_ratio', 'reboiler_duty', 'pressure', 'feed_rate']

for i, var in enumerate(variables):
    ax = axes[i//3, i%3]
    ax.plot(df_window['timestamp'], df_window[var], linewidth=0.5, color='#11998e')
    ax.set_ylabel(var, fontsize=10)
    ax.set_title(f'{var} - 3-day trend', fontsize=11, fontweight='bold')
    ax.grid(alpha=0.3)
    if i >= 6:
        ax.set_xlabel('Time', fontsize=10)

# 9Áï™ÁõÆ„ÅÆ„Éó„É≠„ÉÉ„Éà: Á¥îÂ∫¶ÔºàÂÆüÊ∏¨„Å®„Ç™„Éï„É©„Ç§„É≥Ê∏¨ÂÆöÔºâ
ax = axes[2, 2]
ax.plot(df_window['timestamp'], df_window['purity'], linewidth=0.8,
        alpha=0.7, label='True purity (unknown)', color='gray')
ax.scatter(df_window['timestamp'], df_window['purity_measured'],
           s=100, color='red', marker='o', label='Offline measurement', zorder=3)
ax.set_ylabel('Purity (%)', fontsize=10)
ax.set_xlabel('Time', fontsize=10)
ax.set_title('Product Purity', fontsize=11, fontweight='bold')
ax.legend(fontsize=8)
ax.grid(alpha=0.3)

plt.tight_layout()
plt.savefig('eda_timeseries.png', dpi=150, bbox_inches='tight')
plt.show()

print("\n„ÄêEDAÂÆå‰∫Ü„Äë: eda_timeseries.png „Çí‰øùÂ≠ò„Åó„Åæ„Åó„Åü")
</code></pre>

<p><strong>Âá∫Âäõ‰æã</strong>:</p>
<pre><code>„Äê„Éá„Éº„Çø„Çª„ÉÉ„ÉàÁîüÊàêÂÆå‰∫Ü„Äë
Á∑è„Éá„Éº„ÇøÊï∞: 43,200‰ª∂
ÊúüÈñì: 2025-01-01 00:00:00 „Äú 2025-01-30 23:59:00
„Ç™„Éï„É©„Ç§„É≥Ê∏¨ÂÆöÊï∞: 31‰ª∂

„ÄêÂü∫Êú¨Áµ±Ë®àÈáè„Äë
         feed_temp  top_temp  mid_temp  bottom_temp  reflux_ratio  reboiler_duty  pressure  feed_rate   purity
count   43200.00  43200.00  43200.00     43200.00      43200.00       43200.00  43200.00   43200.00 43200.00
mean       60.01     85.00    120.00       155.00          2.50        1500.01      1.20     100.00    96.50
std         2.45      1.50      2.00         3.00          0.20          80.00      0.08       5.00     1.23
...
</code></pre>

<p><strong>Ëß£Ë™¨</strong>: ÂÆü„Éó„É≠„Çª„Çπ„Éá„Éº„Çø„Å´„ÅØ„ÄÅÊó•Âë®Â§âÂãï„ÄÅÊ¨†ÊêçÂÄ§„ÄÅÂ§ñ„ÇåÂÄ§„ÅåÂê´„Åæ„Çå„Åæ„Åô„ÄÇEDA„Åß„Åì„Çå„Çâ„ÅÆ„Éë„Çø„Éº„É≥„ÇíÊääÊè°„Åô„Çã„Åì„Å®„Åå„ÄÅÂæåÁ∂ö„ÅÆÂàÜÊûê„ÅÆË≥™„ÇíÊ±∫ÂÆö„Åó„Åæ„Åô„ÄÇ</p>

<h4>„Ç≥„Éº„Éâ‰æã2: „Éá„Éº„Çø„ÇØ„É™„Éº„Éã„É≥„Ç∞„Å®ÂâçÂá¶ÁêÜ</h4>

<pre><code class="language-python">import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import RobustScaler
from scipy import stats

# „Éá„Éº„ÇøË™≠„ÅøËæº„Åø
df = pd.read_csv('distillation_data.csv', parse_dates=['timestamp'])
df = df.set_index('timestamp')

print("„Äê„Éá„Éº„Çø„ÇØ„É™„Éº„Éã„É≥„Ç∞ÈñãÂßã„Äë")
print(f"ÂÖÉ„Éá„Éº„Çø: {len(df)}‰ª∂")

# „Çπ„ÉÜ„ÉÉ„Éó1: Ê¨†ÊêçÂÄ§Âá¶ÁêÜ
print("\n‚ñ† „Çπ„ÉÜ„ÉÉ„Éó1: Ê¨†ÊêçÂÄ§Âá¶ÁêÜ")
missing_before = df.isnull().sum().sum()
print(f"Ê¨†ÊêçÂÄ§Êï∞ÔºàÂá¶ÁêÜÂâçÔºâ: {missing_before}")

# Á∑öÂΩ¢Ë£úÈñìÔºàÊôÇÁ≥ªÂàó„Éá„Éº„Çø„Å´ÈÅ©ÂàáÔºâ
df_cleaned = df.copy()
df_cleaned['top_temp'] = df_cleaned['top_temp'].interpolate(method='linear')

missing_after = df_cleaned.isnull().sum().sum()
print(f"Ê¨†ÊêçÂÄ§Êï∞ÔºàÂá¶ÁêÜÂæåÔºâ: {missing_after}")

# „Çπ„ÉÜ„ÉÉ„Éó2: Â§ñ„ÇåÂÄ§Ê§úÂá∫„Å®Âá¶ÁêÜ
print("\n‚ñ† „Çπ„ÉÜ„ÉÉ„Éó2: Â§ñ„ÇåÂÄ§Ê§úÂá∫ÔºàIQRÊ≥ïÔºâ")

def detect_outliers_iqr(series, multiplier=1.5):
    """IQRÊ≥ï„ÅßÂ§ñ„ÇåÂÄ§„ÇíÊ§úÂá∫"""
    Q1 = series.quantile(0.25)
    Q3 = series.quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - multiplier * IQR
    upper_bound = Q3 + multiplier * IQR
    outliers = (series < lower_bound) | (series > upper_bound)
    return outliers, lower_bound, upper_bound

# ÂúßÂäõ„ÅÆÂ§ñ„ÇåÂÄ§Ê§úÂá∫
outliers, lower, upper = detect_outliers_iqr(df_cleaned['pressure'])
print(f"ÂúßÂäõ„ÅÆÂ§ñ„ÇåÂÄ§: {outliers.sum()}‰ª∂Ôºà{outliers.sum()/len(df_cleaned)*100:.2f}%Ôºâ")
print(f"  Ë®±ÂÆπÁØÑÂõ≤: {lower:.3f} „Äú {upper:.3f} MPa")

# Â§ñ„ÇåÂÄ§„Çí‰∏≠Â§ÆÂÄ§„ÅßÁΩÆÊèõÔºà‰øùÂÆàÁöÑ„Å™ÂØæÂá¶Ôºâ
df_cleaned.loc[outliers, 'pressure'] = df_cleaned['pressure'].median()

# „Çπ„ÉÜ„ÉÉ„Éó3: „Çπ„Ç±„Éº„É™„É≥„Ç∞
print("\n‚ñ† „Çπ„ÉÜ„ÉÉ„Éó3: „Éá„Éº„Çø„Çπ„Ç±„Éº„É™„É≥„Ç∞ÔºàRobustScalerÔºâ")

feature_cols = ['feed_temp', 'top_temp', 'mid_temp', 'bottom_temp',
                'reflux_ratio', 'reboiler_duty', 'pressure', 'feed_rate']

scaler = RobustScaler()
df_scaled = df_cleaned.copy()
df_scaled[feature_cols] = scaler.fit_transform(df_cleaned[feature_cols])

print("„Çπ„Ç±„Éº„É™„É≥„Ç∞ÂÆå‰∫ÜÔºàRobustScaler‰ΩøÁî®Ôºâ")

# „Çπ„ÉÜ„ÉÉ„Éó4: ÁâπÂæ¥Èáè„Ç®„É≥„Ç∏„Éã„Ç¢„É™„É≥„Ç∞
print("\n‚ñ† „Çπ„ÉÜ„ÉÉ„Éó4: ÁâπÂæ¥Èáè„Ç®„É≥„Ç∏„Éã„Ç¢„É™„É≥„Ç∞")

df_cleaned['temp_gradient'] = df_cleaned['top_temp'] - df_cleaned['bottom_temp']
df_cleaned['energy_efficiency'] = df_cleaned['reboiler_duty'] / df_cleaned['feed_rate']
df_cleaned['hour'] = df_cleaned.index.hour
df_cleaned['day_of_week'] = df_cleaned.index.dayofweek

# Âë®ÊúüÊÄß„ÅÆÁâπÂæ¥ÈáèÔºà„Çµ„Ç§„ÇØ„É™„ÉÉ„ÇØ„Ç®„É≥„Ç≥„Éº„Éá„Ç£„É≥„Ç∞Ôºâ
df_cleaned['hour_sin'] = np.sin(2 * np.pi * df_cleaned['hour'] / 24)
df_cleaned['hour_cos'] = np.cos(2 * np.pi * df_cleaned['hour'] / 24)

print(f"ËøΩÂä†ÁâπÂæ¥Èáè: {4}ÂÄã")
print("  - temp_gradient: Â°îÈ†Ç-Â°îÂ∫ï„ÅÆÊ∏©Â∫¶Â∑Æ")
print("  - energy_efficiency: Âçò‰Ωç‰æõÁµ¶Èáè„ÅÇ„Åü„Çä„ÅÆ„Ç®„Éç„É´„ÇÆ„Éº")
print("  - hour_sin/cos: ÊôÇÂàª„ÅÆÂë®ÊúüÊÄß„Ç®„É≥„Ç≥„Éº„Éá„Ç£„É≥„Ç∞")

# ÂèØË¶ñÂåñ: „ÇØ„É™„Éº„Éã„É≥„Ç∞ÂâçÂæå„ÅÆÊØîËºÉ
fig, axes = plt.subplots(2, 2, figsize=(14, 10))

# Ê¨†ÊêçÂÄ§Ë£úÂÆå„ÅÆÂäπÊûú
time_window = slice('2025-01-15 00:00', '2025-01-15 12:00')
axes[0, 0].plot(df.loc[time_window].index, df.loc[time_window, 'top_temp'],
                'o-', markersize=3, label='Before (with missing)', alpha=0.7)
axes[0, 0].plot(df_cleaned.loc[time_window].index, df_cleaned.loc[time_window, 'top_temp'],
                '-', linewidth=2, label='After (interpolated)', color='#11998e')
axes[0, 0].set_ylabel('Top Temperature (¬∞C)', fontsize=11)
axes[0, 0].set_title('Missing Value Imputation', fontsize=12, fontweight='bold')
axes[0, 0].legend()
axes[0, 0].grid(alpha=0.3)

# Â§ñ„ÇåÂÄ§Èô§Âéª„ÅÆÂäπÊûú
axes[0, 1].hist(df['pressure'], bins=50, alpha=0.5, label='Before', edgecolor='black')
axes[0, 1].hist(df_cleaned['pressure'], bins=50, alpha=0.5, label='After',
                color='#11998e', edgecolor='black')
axes[0, 1].axvline(lower, color='red', linestyle='--', label='Lower bound')
axes[0, 1].axvline(upper, color='red', linestyle='--', label='Upper bound')
axes[0, 1].set_xlabel('Pressure (MPa)', fontsize=11)
axes[0, 1].set_ylabel('Frequency', fontsize=11)
axes[0, 1].set_title('Outlier Removal', fontsize=12, fontweight='bold')
axes[0, 1].legend()
axes[0, 1].grid(alpha=0.3)

# „Çπ„Ç±„Éº„É™„É≥„Ç∞ÂâçÂæå„ÅÆÊØîËºÉ
axes[1, 0].boxplot([df_cleaned['feed_temp'], df_cleaned['reboiler_duty']],
                   labels=['feed_temp', 'reboiler_duty'], patch_artist=True)
axes[1, 0].set_ylabel('Original Scale', fontsize=11)
axes[1, 0].set_title('Before Scaling (Different Scales)', fontsize=12, fontweight='bold')
axes[1, 0].grid(alpha=0.3, axis='y')

axes[1, 1].boxplot([df_scaled['feed_temp'], df_scaled['reboiler_duty']],
                   labels=['feed_temp', 'reboiler_duty'], patch_artist=True,
                   boxprops=dict(facecolor='#11998e', alpha=0.7))
axes[1, 1].set_ylabel('Scaled Value', fontsize=11)
axes[1, 1].set_title('After Scaling (Unified Scale)', fontsize=12, fontweight='bold')
axes[1, 1].grid(alpha=0.3, axis='y')

plt.tight_layout()
plt.savefig('data_cleaning.png', dpi=150, bbox_inches='tight')
plt.show()

# „ÇØ„É™„Éº„Éã„É≥„Ç∞Ê∏à„Åø„Éá„Éº„Çø„ÅÆ‰øùÂ≠ò
df_cleaned.to_csv('distillation_data_cleaned.csv')
print(f"\n„Äê„ÇØ„É™„Éº„Éã„É≥„Ç∞ÂÆå‰∫Ü„Äë: distillation_data_cleaned.csv „Çí‰øùÂ≠ò„Åó„Åæ„Åó„Åü")
print(f"ÊúÄÁµÇ„Éá„Éº„ÇøÊï∞: {len(df_cleaned)}‰ª∂")
</code></pre>

<p><strong>Âá∫Âäõ‰æã</strong>:</p>
<pre><code>„Äê„Éá„Éº„Çø„ÇØ„É™„Éº„Éã„É≥„Ç∞ÈñãÂßã„Äë
ÂÖÉ„Éá„Éº„Çø: 43200‰ª∂

‚ñ† „Çπ„ÉÜ„ÉÉ„Éó1: Ê¨†ÊêçÂÄ§Âá¶ÁêÜ
Ê¨†ÊêçÂÄ§Êï∞ÔºàÂá¶ÁêÜÂâçÔºâ: 864
Ê¨†ÊêçÂÄ§Êï∞ÔºàÂá¶ÁêÜÂæåÔºâ: 0

‚ñ† „Çπ„ÉÜ„ÉÉ„Éó2: Â§ñ„ÇåÂÄ§Ê§úÂá∫ÔºàIQRÊ≥ïÔºâ
ÂúßÂäõ„ÅÆÂ§ñ„ÇåÂÄ§: 216‰ª∂Ôºà0.50%Ôºâ
  Ë®±ÂÆπÁØÑÂõ≤: 1.080 „Äú 1.320 MPa

‚ñ† „Çπ„ÉÜ„ÉÉ„Éó3: „Éá„Éº„Çø„Çπ„Ç±„Éº„É™„É≥„Ç∞ÔºàRobustScalerÔºâ
„Çπ„Ç±„Éº„É™„É≥„Ç∞ÂÆå‰∫ÜÔºàRobustScaler‰ΩøÁî®Ôºâ

‚ñ† „Çπ„ÉÜ„ÉÉ„Éó4: ÁâπÂæ¥Èáè„Ç®„É≥„Ç∏„Éã„Ç¢„É™„É≥„Ç∞
ËøΩÂä†ÁâπÂæ¥Èáè: 4ÂÄã
  - temp_gradient: Â°îÈ†Ç-Â°îÂ∫ï„ÅÆÊ∏©Â∫¶Â∑Æ
  - energy_efficiency: Âçò‰Ωç‰æõÁµ¶Èáè„ÅÇ„Åü„Çä„ÅÆ„Ç®„Éç„É´„ÇÆ„Éº
  - hour_sin/cos: ÊôÇÂàª„ÅÆÂë®ÊúüÊÄß„Ç®„É≥„Ç≥„Éº„Éá„Ç£„É≥„Ç∞
</code></pre>

<p><strong>Ëß£Ë™¨</strong>: „Éá„Éº„Çø„ÇØ„É™„Éº„Éã„É≥„Ç∞„Å®ÁâπÂæ¥Èáè„Ç®„É≥„Ç∏„Éã„Ç¢„É™„É≥„Ç∞„ÅØ„ÄÅ„É¢„Éá„É´ÊÄßËÉΩ„Å´Áõ¥Áµê„Åô„ÇãÈáçË¶Å„Å™„Çπ„ÉÜ„ÉÉ„Éó„Åß„Åô„ÄÇ„Éâ„É°„Ç§„É≥Áü•Ë≠ò„ÇíÊ¥ªÁî®„Åó„ÅüÁâπÂæ¥ÈáèÔºàÊ∏©Â∫¶ÂãæÈÖç„ÄÅ„Ç®„Éç„É´„ÇÆ„ÉºÂäπÁéáÔºâ„ÅåÁâπ„Å´ÊúâÂäπ„Åß„Åô„ÄÇ</p>

<hr />

<h2>4.2 ÂìÅË≥™‰∫àÊ∏¨„É¢„Éá„É´„ÅÆÊßãÁØâ</h2>

<p>„ÇØ„É™„Éº„Éã„É≥„Ç∞Ê∏à„Åø„Éá„Éº„Çø„Çí‰Ωø„Å£„Å¶„ÄÅË£ΩÂìÅÁ¥îÂ∫¶„Çí‰∫àÊ∏¨„Åô„Çã„ÇΩ„Éï„Éà„Çª„É≥„Çµ„Éº„ÇíÊßãÁØâ„Åó„Åæ„Åô„ÄÇË§áÊï∞„ÅÆ„É¢„Éá„É´„ÇíÊØîËºÉ„Åó„ÄÅÊúÄÈÅ©„Å™„É¢„Éá„É´„ÇíÈÅ∏Êäû„Åó„Åæ„Åô„ÄÇ</p>

<h4>„Ç≥„Éº„Éâ‰æã3: Ë®ìÁ∑¥„Éá„Éº„Çø„Å®„ÉÜ„Çπ„Éà„Éá„Éº„Çø„ÅÆÊ∫ñÂÇô</h4>

<pre><code class="language-python">import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, TimeSeriesSplit
from sklearn.preprocessing import RobustScaler

# „ÇØ„É™„Éº„Éã„É≥„Ç∞Ê∏à„Åø„Éá„Éº„ÇøË™≠„ÅøËæº„Åø
df = pd.read_csv('distillation_data_cleaned.csv', parse_dates=['timestamp'])
df = df.set_index('timestamp')

print("„Äê„Éá„Éº„ÇøÊ∫ñÂÇô„Äë")

# „Ç™„Éï„É©„Ç§„É≥Ê∏¨ÂÆö„Éá„Éº„Çø„ÅÆ„Åø„Çí‰ΩøÁî®ÔºàÂÆüÈÅãÁî®„ÇíÊÉ≥ÂÆöÔºâ
train_data = df[df['purity_measured'].notna()].copy()
print(f"Ë®ìÁ∑¥Áî®„Éá„Éº„ÇøÊï∞: {len(train_data)}‰ª∂Ôºà„Ç™„Éï„É©„Ç§„É≥Ê∏¨ÂÆö„ÅÆ„ÅøÔºâ")

# ÁâπÂæ¥Èáè„Å®ÁõÆÁöÑÂ§âÊï∞
feature_cols = ['feed_temp', 'top_temp', 'mid_temp', 'bottom_temp',
                'reflux_ratio', 'reboiler_duty', 'pressure', 'feed_rate',
                'temp_gradient', 'energy_efficiency', 'hour_sin', 'hour_cos']

X = train_data[feature_cols]
y = train_data['purity_measured']

print(f"ÁâπÂæ¥ÈáèÊï∞: {len(feature_cols)}")
print(f"ÁâπÂæ¥Èáè: {feature_cols}")

# ÊôÇÁ≥ªÂàóÂàÜÂâ≤ÔºàTime Series SplitÔºâ
# ÊôÇÁ≥ªÂàó„Éá„Éº„Çø„Åß„ÅØ„ÄÅÊú™Êù•„ÅÆ„Éá„Éº„Çø„ÅßÈÅéÂéª„Çí‰∫àÊ∏¨„Åó„Å™„ÅÑ„Çà„ÅÜ„Å´Ê≥®ÊÑè
tscv = TimeSeriesSplit(n_splits=5)

print(f"\nÊôÇÁ≥ªÂàóÂàÜÂâ≤: {tscv.n_splits} folds")

# ÊúÄÁµÇË©ï‰æ°Áî®„Å´„ÄÅÊúÄÂæå„ÅÆ20%„Çí„ÉÜ„Çπ„Éà„Éá„Éº„Çø„Å®„Åó„Å¶Á¢∫‰øù
split_index = int(len(X) * 0.8)
X_train, X_test = X.iloc[:split_index], X.iloc[split_index:]
y_train, y_test = y.iloc[:split_index], y.iloc[split_index:]

print(f"\nË®ìÁ∑¥„Éá„Éº„Çø: {len(X_train)}‰ª∂")
print(f"„ÉÜ„Çπ„Éà„Éá„Éº„Çø: {len(X_test)}‰ª∂")

# „Çπ„Ç±„Éº„É™„É≥„Ç∞
scaler = RobustScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# DataFrame„Å´Êàª„ÅôÔºà„Ç´„É©„É†Âêç‰øùÊåÅÔºâ
X_train_scaled = pd.DataFrame(X_train_scaled, columns=feature_cols, index=X_train.index)
X_test_scaled = pd.DataFrame(X_test_scaled, columns=feature_cols, index=X_test.index)

print("\n„Çπ„Ç±„Éº„É™„É≥„Ç∞ÂÆå‰∫Ü")
print(f"Ë®ìÁ∑¥„Éá„Éº„ÇøÂΩ¢Áä∂: {X_train_scaled.shape}")
print(f"„ÉÜ„Çπ„Éà„Éá„Éº„ÇøÂΩ¢Áä∂: {X_test_scaled.shape}")

# „Éá„Éº„Çø„ÅÆÂü∫Êú¨Áµ±Ë®à
print("\n„ÄêË®ìÁ∑¥„Éá„Éº„ÇøÁµ±Ë®à„Äë")
print(y_train.describe())
print("\n„Äê„ÉÜ„Çπ„Éà„Éá„Éº„ÇøÁµ±Ë®à„Äë")
print(y_test.describe())
</code></pre>

<p><strong>Âá∫Âäõ‰æã</strong>:</p>
<pre><code>„Äê„Éá„Éº„ÇøÊ∫ñÂÇô„Äë
Ë®ìÁ∑¥Áî®„Éá„Éº„ÇøÊï∞: 31‰ª∂Ôºà„Ç™„Éï„É©„Ç§„É≥Ê∏¨ÂÆö„ÅÆ„ÅøÔºâ
ÁâπÂæ¥ÈáèÊï∞: 12
ÁâπÂæ¥Èáè: ['feed_temp', 'top_temp', 'mid_temp', 'bottom_temp', 'reflux_ratio',
         'reboiler_duty', 'pressure', 'feed_rate', 'temp_gradient',
         'energy_efficiency', 'hour_sin', 'hour_cos']

ÊôÇÁ≥ªÂàóÂàÜÂâ≤: 5 folds

Ë®ìÁ∑¥„Éá„Éº„Çø: 25‰ª∂
„ÉÜ„Çπ„Éà„Éá„Éº„Çø: 6‰ª∂
</code></pre>

<p><strong>Ëß£Ë™¨</strong>: ÊôÇÁ≥ªÂàó„Éá„Éº„Çø„Åß„ÅØ„ÄÅ„É©„É≥„ÉÄ„É†ÂàÜÂâ≤„Åß„ÅØ„Å™„ÅèÊôÇÁ≥ªÂàóÂàÜÂâ≤„Çí‰ΩøÁî®„Åó„Åæ„Åô„ÄÇ„Åì„Çå„Å´„Çà„Çä„ÄÅÈÅéÂéª„ÅÆ„Éá„Éº„Çø„ÅßÊú™Êù•„Çí‰∫àÊ∏¨„Åô„ÇãÂÆüÈÅãÁî®„Å®Âêå„ÅòÊù°‰ª∂„ÅßË©ï‰æ°„Åß„Åç„Åæ„Åô„ÄÇ</p>

<h4>„Ç≥„Éº„Éâ‰æã4: Ë§áÊï∞„É¢„Éá„É´„ÅÆÊØîËºÉ„Å®ÈÅ∏Êäû</h4>

<pre><code class="language-python">import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.cross_decomposition import PLSRegression
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.svm import SVR
from sklearn.model_selection import cross_val_score
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
import time

# „É¢„Éá„É´„ÅÆÂÆöÁæ©
models = {
    'Linear Regression': LinearRegression(),
    'Ridge': Ridge(alpha=1.0),
    'Lasso': Lasso(alpha=0.1),
    'PLS': PLSRegression(n_components=5),
    'Random Forest': RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42),
    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, max_depth=5, random_state=42),
    'SVR': SVR(kernel='rbf', C=10, gamma=0.1)
}

print("„Äê„É¢„Éá„É´ÊØîËºÉ„Äë")
print("„ÇØ„É≠„Çπ„Éê„É™„Éá„Éº„Ç∑„Éß„É≥„ÅßÂêÑ„É¢„Éá„É´„ÇíË©ï‰æ°...")

results = []

for name, model in models.items():
    start_time = time.time()

    # „ÇØ„É≠„Çπ„Éê„É™„Éá„Éº„Ç∑„Éß„É≥ÔºàÊôÇÁ≥ªÂàóÂàÜÂâ≤Ôºâ
    cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='r2')

    # Ë®ìÁ∑¥
    model.fit(X_train_scaled, y_train)

    # ‰∫àÊ∏¨
    y_train_pred = model.predict(X_train_scaled)
    y_test_pred = model.predict(X_test_scaled)

    # Ë©ï‰æ°ÊåáÊ®ô
    train_r2 = r2_score(y_train, y_train_pred)
    test_r2 = r2_score(y_test, y_test_pred)
    test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))
    test_mae = mean_absolute_error(y_test, y_test_pred)

    training_time = time.time() - start_time

    results.append({
        'Model': name,
        'CV R¬≤ (mean)': cv_scores.mean(),
        'CV R¬≤ (std)': cv_scores.std(),
        'Train R¬≤': train_r2,
        'Test R¬≤': test_r2,
        'Test RMSE': test_rmse,
        'Test MAE': test_mae,
        'Training Time (s)': training_time
    })

    print(f"  {name}: CV R¬≤ = {cv_scores.mean():.4f} (¬±{cv_scores.std():.4f}), "
          f"Test R¬≤ = {test_r2:.4f}, RMSE = {test_rmse:.4f}")

# ÁµêÊûú„ÇíDataFrame„Å´
results_df = pd.DataFrame(results).sort_values('Test R¬≤', ascending=False)

print("\n„ÄêÁ∑èÂêàË©ï‰æ°ÁµêÊûú„Äë")
print(results_df.to_string(index=False))

# ÂèØË¶ñÂåñ
fig, axes = plt.subplots(2, 2, figsize=(14, 10))

# 1. „ÉÜ„Çπ„ÉàR¬≤„Çπ„Ç≥„Ç¢„ÅÆÊØîËºÉ
axes[0, 0].barh(results_df['Model'], results_df['Test R¬≤'], color='#11998e', alpha=0.7)
axes[0, 0].set_xlabel('Test R¬≤ Score', fontsize=11)
axes[0, 0].set_title('Model Performance Comparison (Test R¬≤)', fontsize=12, fontweight='bold')
axes[0, 0].grid(alpha=0.3, axis='x')

# 2. RMSE vs Ë®ìÁ∑¥ÊôÇÈñì
axes[0, 1].scatter(results_df['Training Time (s)'], results_df['Test RMSE'],
                   s=150, alpha=0.7, color='#11998e')
for i, row in results_df.iterrows():
    axes[0, 1].annotate(row['Model'], (row['Training Time (s)'], row['Test RMSE']),
                        fontsize=8, ha='right')
axes[0, 1].set_xlabel('Training Time (s)', fontsize=11)
axes[0, 1].set_ylabel('Test RMSE', fontsize=11)
axes[0, 1].set_title('Efficiency vs Accuracy Trade-off', fontsize=12, fontweight='bold')
axes[0, 1].grid(alpha=0.3)

# 3. Ë®ìÁ∑¥R¬≤ vs „ÉÜ„Çπ„ÉàR¬≤ÔºàÈÅéÂ≠¶Áøí„ÉÅ„Çß„ÉÉ„ÇØÔºâ
axes[1, 0].scatter(results_df['Train R¬≤'], results_df['Test R¬≤'],
                   s=150, alpha=0.7, color='#f59e0b')
axes[1, 0].plot([0.9, 1.0], [0.9, 1.0], 'r--', linewidth=2, label='Perfect generalization')
for i, row in results_df.iterrows():
    axes[1, 0].annotate(row['Model'], (row['Train R¬≤'], row['Test R¬≤']),
                        fontsize=8, ha='right')
axes[1, 0].set_xlabel('Train R¬≤', fontsize=11)
axes[1, 0].set_ylabel('Test R¬≤', fontsize=11)
axes[1, 0].set_title('Overfitting Check', fontsize=12, fontweight='bold')
axes[1, 0].legend()
axes[1, 0].grid(alpha=0.3)

# 4. CV„Çπ„Ç≥„Ç¢„ÅÆÂàÜÂ∏É
cv_means = results_df['CV R¬≤ (mean)']
cv_stds = results_df['CV R¬≤ (std)']
axes[1, 1].barh(results_df['Model'], cv_means, xerr=cv_stds,
                color='#7b2cbf', alpha=0.7, capsize=5)
axes[1, 1].set_xlabel('Cross-Validation R¬≤ Score', fontsize=11)
axes[1, 1].set_title('Cross-Validation Performance (Mean ¬± Std)', fontsize=12, fontweight='bold')
axes[1, 1].grid(alpha=0.3, axis='x')

plt.tight_layout()
plt.savefig('model_comparison.png', dpi=150, bbox_inches='tight')
plt.show()

# ÊúÄÂÑ™ÁßÄ„É¢„Éá„É´„ÅÆÈÅ∏Êäû
best_model_name = results_df.iloc[0]['Model']
print(f"\n„ÄêÊúÄÂÑ™ÁßÄ„É¢„Éá„É´„Äë: {best_model_name}")
print(f"  Test R¬≤: {results_df.iloc[0]['Test R¬≤']:.4f}")
print(f"  Test RMSE: {results_df.iloc[0]['Test RMSE']:.4f}%")
print(f"  Test MAE: {results_df.iloc[0]['Test MAE']:.4f}%")

# ÊúÄÂÑ™ÁßÄ„É¢„Éá„É´„Çí‰øùÂ≠òÔºàÂæå„Åß‰ΩøÁî®Ôºâ
best_model = models[best_model_name]
best_model.fit(X_train_scaled, y_train)

import joblib
joblib.dump(best_model, 'best_model.pkl')
joblib.dump(scaler, 'scaler.pkl')
print(f"\n„É¢„Éá„É´„Å®„Çπ„Ç±„Éº„É©„Éº„Çí‰øùÂ≠ò„Åó„Åæ„Åó„Åü")
</code></pre>

<p><strong>Âá∫Âäõ‰æã</strong>:</p>
<pre><code>„Äê„É¢„Éá„É´ÊØîËºÉ„Äë
„ÇØ„É≠„Çπ„Éê„É™„Éá„Éº„Ç∑„Éß„É≥„ÅßÂêÑ„É¢„Éá„É´„ÇíË©ï‰æ°...
  Linear Regression: CV R¬≤ = 0.8456 (¬±0.1234), Test R¬≤ = 0.8678, RMSE = 0.4321
  Ridge: CV R¬≤ = 0.8512 (¬±0.1198), Test R¬≤ = 0.8723, RMSE = 0.4256
  Lasso: CV R¬≤ = 0.8389 (¬±0.1276), Test R¬≤ = 0.8598, RMSE = 0.4456
  PLS: CV R¬≤ = 0.8623 (¬±0.1089), Test R¬≤ = 0.8845, RMSE = 0.4034
  Random Forest: CV R¬≤ = 0.9012 (¬±0.0789), Test R¬≤ = 0.9234, RMSE = 0.3287
  Gradient Boosting: CV R¬≤ = 0.9156 (¬±0.0723), Test R¬≤ = 0.9345, RMSE = 0.3041
  SVR: CV R¬≤ = 0.8876 (¬±0.0856), Test R¬≤ = 0.9087, RMSE = 0.3589

„ÄêÊúÄÂÑ™ÁßÄ„É¢„Éá„É´„Äë: Gradient Boosting
  Test R¬≤: 0.9345
  Test RMSE: 0.3041%
  Test MAE: 0.2456%
</code></pre>

<p><strong>Ëß£Ë™¨</strong>: Ë§áÊï∞„ÅÆ„É¢„Éá„É´„Çí‰ΩìÁ≥ªÁöÑ„Å´ÊØîËºÉ„Åô„Çã„Åì„Å®„Åß„ÄÅ„Éá„Éº„Çø„Å´ÊúÄÈÅ©„Å™„É¢„Éá„É´„ÇíÈÅ∏Êäû„Åß„Åç„Åæ„Åô„ÄÇ„Åì„ÅÆ‰æã„Åß„ÅØ„ÄÅGradient Boosting„ÅåÊúÄÈ´òÊÄßËÉΩ„ÇíÁ§∫„Åó„Åæ„Åó„Åü„ÄÇ</p>

<h4>„Ç≥„Éº„Éâ‰æã5: ÁâπÂæ¥ÈáèÈáçË¶ÅÂ∫¶ÂàÜÊûê</h4>

<pre><code class="language-python">import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import joblib
from sklearn.inspection import permutation_importance

# ÊúÄÂÑ™ÁßÄ„É¢„Éá„É´„ÅÆË™≠„ÅøËæº„Åø
best_model = joblib.load('best_model.pkl')
scaler = joblib.load('scaler.pkl')

print("„ÄêÁâπÂæ¥ÈáèÈáçË¶ÅÂ∫¶ÂàÜÊûê„Äë")

# ÊñπÊ≥ï1: „É¢„Éá„É´Âõ∫Êúâ„ÅÆÁâπÂæ¥ÈáèÈáçË¶ÅÂ∫¶ÔºàRandom Forest„ÇÑGradient Boosting„ÅÆÂ†¥ÂêàÔºâ
if hasattr(best_model, 'feature_importances_'):
    feature_importance = pd.DataFrame({
        'Feature': feature_cols,
        'Importance': best_model.feature_importances_
    }).sort_values('Importance', ascending=False)

    print("\n‚ñ† „É¢„Éá„É´Âõ∫Êúâ„ÅÆÁâπÂæ¥ÈáèÈáçË¶ÅÂ∫¶:")
    print(feature_importance.to_string(index=False))

# ÊñπÊ≥ï2: Permutation ImportanceÔºà„É¢„Éá„É´„Å´‰æùÂ≠ò„Åó„Å™„ÅÑÔºâ
perm_importance = permutation_importance(best_model, X_test_scaled, y_test,
                                          n_repeats=10, random_state=42)

perm_importance_df = pd.DataFrame({
    'Feature': feature_cols,
    'Importance': perm_importance.importances_mean,
    'Std': perm_importance.importances_std
}).sort_values('Importance', ascending=False)

print("\n‚ñ† Permutation Importance:")
print(perm_importance_df.to_string(index=False))

# ÂèØË¶ñÂåñ
fig, axes = plt.subplots(1, 2, figsize=(14, 6))

# „É¢„Éá„É´Âõ∫Êúâ„ÅÆÈáçË¶ÅÂ∫¶
if hasattr(best_model, 'feature_importances_'):
    axes[0].barh(feature_importance['Feature'], feature_importance['Importance'],
                 color='#11998e', alpha=0.7)
    axes[0].set_xlabel('Importance', fontsize=11)
    axes[0].set_title('Feature Importance (Model-specific)', fontsize=12, fontweight='bold')
    axes[0].grid(alpha=0.3, axis='x')
    axes[0].invert_yaxis()

# Permutation Importance
axes[1].barh(perm_importance_df['Feature'], perm_importance_df['Importance'],
             xerr=perm_importance_df['Std'], color='#f59e0b', alpha=0.7, capsize=5)
axes[1].set_xlabel('Importance', fontsize=11)
axes[1].set_title('Permutation Importance (Model-agnostic)', fontsize=12, fontweight='bold')
axes[1].grid(alpha=0.3, axis='x')
axes[1].invert_yaxis()

plt.tight_layout()
plt.savefig('feature_importance.png', dpi=150, bbox_inches='tight')
plt.show()

# ‰∏ªË¶ÅÂõ†Â≠ê„ÅÆËß£Èáà
print("\n„Äê‰∏ªË¶ÅÂΩ±ÈüøÂõ†Â≠ê„Äë")
top_features = perm_importance_df.head(5)
for i, row in top_features.iterrows():
    print(f"  {i+1}. {row['Feature']}: {row['Importance']:.4f} (¬±{row['Std']:.4f})")

print("\n„ÄêËß£Èáà„Äë")
print("‚úì ÈÇÑÊµÅÊØî„ÅåÁ¥îÂ∫¶„Å´ÊúÄ„ÇÇÂ§ß„Åç„Å™ÂΩ±Èüø„Çí‰∏é„Åà„Çã")
print("‚úì Â°îÈ†ÇÊ∏©Â∫¶„Å®Â°î‰∏≠ÊÆµÊ∏©Â∫¶„ÇÇÈáçË¶Å„Å™Âà∂Âæ°Â§âÊï∞")
print("‚úì „Ç®„Éç„É´„ÇÆ„ÉºÂäπÁéáÔºàÊ¥æÁîüÁâπÂæ¥ÈáèÔºâ„ÅåÊúâÊÑè„Å´ÂØÑ‰∏é")
print("‚Üí „Åì„Çå„Çâ„ÅÆÂ§âÊï∞„ÇíÈáçÁÇπÁöÑ„Å´ÁÆ°ÁêÜ„Åô„Çã„Åì„Å®„ÅßÂìÅË≥™ÂÆâÂÆöÂåñ„ÅåÂèØËÉΩ")
</code></pre>

<p><strong>Ëß£Ë™¨</strong>: ÁâπÂæ¥ÈáèÈáçË¶ÅÂ∫¶ÂàÜÊûê„Å´„Çà„Çä„ÄÅ„Å©„ÅÆÂ§âÊï∞„ÅåÂìÅË≥™„Å´ÂΩ±Èüø„Åô„Çã„Åã„ÅåÂÆöÈáèÁöÑ„Å´ÂàÜ„Åã„Çä„Åæ„Åô„ÄÇ„Åì„Çå„ÅØ„ÄÅ„Éó„É≠„Çª„ÇπÂà∂Âæ°„ÅÆÂÑ™ÂÖàÈ†Ü‰Ωç‰ªò„Åë„Å´Áõ¥Áµê„Åó„Åæ„Åô„ÄÇ</p>

<hr />

<h2>4.3 „Éó„É≠„Çª„ÇπÊù°‰ª∂ÊúÄÈÅ©Âåñ„ÅÆÂü∫Á§é</h2>

<p>ÊßãÁØâ„Åó„Åü„É¢„Éá„É´„Çí‰Ωø„Å£„Å¶„ÄÅÂìÅË≥™Âà∂Á¥Ñ„ÇíÊ∫Ä„Åü„Åó„Å§„Å§„Ç®„Éç„É´„ÇÆ„ÉºÊ∂àË≤ª„ÇíÊúÄÂ∞èÂåñ„Åô„ÇãÈÅãËª¢Êù°‰ª∂„ÇíÊé¢Á¥¢„Åó„Åæ„Åô„ÄÇ</p>

<h4>„Ç≥„Éº„Éâ‰æã6: Âà∂Á¥Ñ‰ªò„ÅçÊúÄÈÅ©ÂåñÔºàGrid SearchÔºâ</h4>

<pre><code class="language-python">import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import joblib
from itertools import product

# „É¢„Éá„É´„Å®„Çπ„Ç±„Éº„É©„Éº„ÅÆË™≠„ÅøËæº„Åø
best_model = joblib.load('best_model.pkl')
scaler = joblib.load('scaler.pkl')

print("„Äê„Éó„É≠„Çª„ÇπÊúÄÈÅ©Âåñ„Äë")
print("ÁõÆÁöÑ: ÂìÅË≥™ÔºàÁ¥îÂ∫¶‚â•97%Ôºâ„ÇíÊ∫Ä„Åü„Åó„Å§„Å§„ÄÅ„Ç®„Éç„É´„ÇÆ„ÉºÊ∂àË≤ªÔºàreboiler_dutyÔºâ„ÇíÊúÄÂ∞èÂåñ")

# ÊúÄÈÅ©ÂåñÂØæË±°„ÅÆÂ§âÊï∞„Å®Êé¢Á¥¢ÁØÑÂõ≤
# Âõ∫ÂÆö„Åô„ÇãÂ§âÊï∞ÔºàÂ§ñÈÉ®Êù°‰ª∂Ôºâ
feed_temp_fixed = 60.0
feed_rate_fixed = 100.0
pressure_fixed = 1.2

# ÊúÄÈÅ©Âåñ„Åô„ÇãÂ§âÊï∞
reflux_ratios = np.linspace(2.0, 3.5, 20)
reboiler_duties = np.linspace(1300, 1700, 20)

print(f"\nÊé¢Á¥¢ÁØÑÂõ≤:")
print(f"  ÈÇÑÊµÅÊØî: {reflux_ratios.min():.2f} „Äú {reflux_ratios.max():.2f}")
print(f"  „É™„Éú„Ç§„É©„ÉºÁÜ±Èáè: {reboiler_duties.min():.0f} „Äú {reboiler_duties.max():.0f} kW")
print(f"  Êé¢Á¥¢ÁÇπÊï∞: {len(reflux_ratios) √ó len(reboiler_duties)}ÁÇπ")

# „Ç∞„É™„ÉÉ„Éâ„Çµ„Éº„ÉÅ
results = []

for reflux_ratio, reboiler_duty in product(reflux_ratios, reboiler_duties):
    # ÈÅãËª¢Êù°‰ª∂„Åã„ÇâÊ¥æÁîüÁâπÂæ¥Èáè„ÇíË®àÁÆó
    # Ê≥®: top_temp, mid_temp, bottom_temp„ÅØÁõ∏Èñ¢Èñ¢‰øÇ„Åã„ÇâÊé®ÂÆöÔºàÁ∞°ÊòìÁâàÔºâ
    # ÂÆüÈöõ„ÅØÁâ©ÁêÜ„É¢„Éá„É´„ÇÑ„Çà„ÇäÈ´òÂ∫¶„Å™‰∫àÊ∏¨„ÅåÂøÖË¶Å
    top_temp = 85 + 0.5 * (reflux_ratio - 2.5)  # Á∞°ÊòìÊé®ÂÆö
    mid_temp = 120
    bottom_temp = 155

    temp_gradient = top_temp - bottom_temp
    energy_efficiency = reboiler_duty / feed_rate_fixed
    hour_sin = 0  # Ê≠£Âçà„ÇíÊÉ≥ÂÆö
    hour_cos = 1

    # ÁâπÂæ¥Èáè„Éô„ÇØ„Éà„É´‰ΩúÊàê
    features = np.array([[
        feed_temp_fixed, top_temp, mid_temp, bottom_temp,
        reflux_ratio, reboiler_duty, pressure_fixed, feed_rate_fixed,
        temp_gradient, energy_efficiency, hour_sin, hour_cos
    ]])

    # „Çπ„Ç±„Éº„É™„É≥„Ç∞
    features_df = pd.DataFrame(features, columns=feature_cols)
    features_scaled = scaler.transform(features_df)

    # Á¥îÂ∫¶‰∫àÊ∏¨
    purity_pred = best_model.predict(features_scaled)[0]

    results.append({
        'reflux_ratio': reflux_ratio,
        'reboiler_duty': reboiler_duty,
        'purity_pred': purity_pred,
        'feasible': purity_pred >= 97.0  # ÂìÅË≥™Âà∂Á¥Ñ
    })

results_df = pd.DataFrame(results)

print(f"\n„ÄêÊé¢Á¥¢ÁµêÊûú„Äë")
print(f"ÂÖ®Êé¢Á¥¢ÁÇπÊï∞: {len(results_df)}")
print(f"ÂìÅË≥™Âà∂Á¥Ñ„ÇíÊ∫Ä„Åü„ÅôÁÇπ: {results_df['feasible'].sum()}ÁÇπ")

# ÂÆüË°åÂèØËÉΩÈ†òÂüü„Åß„ÅÆÊúÄÈÅ©Ëß£
feasible_solutions = results_df[results_df['feasible']]

if len(feasible_solutions) > 0:
    optimal_solution = feasible_solutions.loc[feasible_solutions['reboiler_duty'].idxmin()]

    print(f"\n„ÄêÊúÄÈÅ©ÈÅãËª¢Êù°‰ª∂„Äë")
    print(f"  ÈÇÑÊµÅÊØî: {optimal_solution['reflux_ratio']:.3f}")
    print(f"  „É™„Éú„Ç§„É©„ÉºÁÜ±Èáè: {optimal_solution['reboiler_duty']:.1f} kW")
    print(f"  ‰∫àÊ∏¨Á¥îÂ∫¶: {optimal_solution['purity_pred']:.2f}%")

    # ÁèæÂú®„ÅÆÈÅãËª¢Êù°‰ª∂„Å®ÊØîËºÉÔºàÂπ≥ÂùáÂÄ§Ôºâ
    current_reflux = X_train['reflux_ratio'].mean()
    current_duty = X_train['reboiler_duty'].mean()
    current_purity = y_train.mean()

    print(f"\n„ÄêÁèæÁä∂„Å®„ÅÆÊØîËºÉ„Äë")
    print(f"  ÈÇÑÊµÅÊØî: {current_reflux:.3f} ‚Üí {optimal_solution['reflux_ratio']:.3f}")
    print(f"  „É™„Éú„Ç§„É©„ÉºÁÜ±Èáè: {current_duty:.1f} kW ‚Üí {optimal_solution['reboiler_duty']:.1f} kW")
    print(f"  ‰∫àÊ∏¨Á¥îÂ∫¶: {current_purity:.2f}% ‚Üí {optimal_solution['purity_pred']:.2f}%")

    energy_saving = (current_duty - optimal_solution['reboiler_duty']) / current_duty * 100
    print(f"\n„Ç®„Éç„É´„ÇÆ„ÉºÂâäÊ∏õ: {energy_saving:.1f}%")
    print(f"Âπ¥Èñì„Ç≥„Çπ„ÉàÂâäÊ∏õÔºà‰ªÆÂÆöÔºâ: ¬•{energy_saving * 100000:.0f}‰∏áÂÜÜ")

# ÂèØË¶ñÂåñ
fig, axes = plt.subplots(1, 2, figsize=(14, 6))

# „Ç≥„É≥„Çø„Éº„Éû„ÉÉ„Éó: Á¥îÂ∫¶
contour = axes[0].tricontourf(results_df['reflux_ratio'], results_df['reboiler_duty'],
                               results_df['purity_pred'], levels=20, cmap='RdYlGn')
axes[0].tricontour(results_df['reflux_ratio'], results_df['reboiler_duty'],
                   results_df['purity_pred'], levels=[97.0], colors='red',
                   linewidths=3, linestyles='--')
if len(feasible_solutions) > 0:
    axes[0].scatter(optimal_solution['reflux_ratio'], optimal_solution['reboiler_duty'],
                    s=200, color='blue', marker='*', edgecolor='white', linewidth=2,
                    label='Optimal point', zorder=5)
axes[0].set_xlabel('Reflux Ratio', fontsize=11)
axes[0].set_ylabel('Reboiler Duty (kW)', fontsize=11)
axes[0].set_title('Predicted Purity (% contour)', fontsize=12, fontweight='bold')
axes[0].legend()
plt.colorbar(contour, ax=axes[0], label='Purity (%)')

# ÂÆüË°åÂèØËÉΩÈ†òÂüü
axes[1].scatter(results_df[~results_df['feasible']]['reflux_ratio'],
                results_df[~results_df['feasible']]['reboiler_duty'],
                s=30, alpha=0.3, color='red', label='Infeasible (purity < 97%)')
axes[1].scatter(results_df[results_df['feasible']]['reflux_ratio'],
                results_df[results_df['feasible']]['reboiler_duty'],
                s=30, alpha=0.5, color='green', label='Feasible (purity ‚â• 97%)')
if len(feasible_solutions) > 0:
    axes[1].scatter(optimal_solution['reflux_ratio'], optimal_solution['reboiler_duty'],
                    s=200, color='blue', marker='*', edgecolor='white', linewidth=2,
                    label='Optimal point', zorder=5)
axes[1].set_xlabel('Reflux Ratio', fontsize=11)
axes[1].set_ylabel('Reboiler Duty (kW)', fontsize=11)
axes[1].set_title('Feasible Region', fontsize=12, fontweight='bold')
axes[1].legend()
axes[1].grid(alpha=0.3)

plt.tight_layout()
plt.savefig('process_optimization.png', dpi=150, bbox_inches='tight')
plt.show()

else:
    print("\n‚úó ÂìÅË≥™Âà∂Á¥Ñ„ÇíÊ∫Ä„Åü„ÅôÈÅãËª¢Êù°‰ª∂„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„Åß„Åó„Åü")
    print("  ‚Üí Êé¢Á¥¢ÁØÑÂõ≤„ÅÆÊã°Â§ß„Åæ„Åü„ÅØÂà∂Á¥Ñ„ÅÆÁ∑©Âíå„ÅåÂøÖË¶Å")
</code></pre>

<p><strong>Âá∫Âäõ‰æã</strong>:</p>
<pre><code>„Äê„Éó„É≠„Çª„ÇπÊúÄÈÅ©Âåñ„Äë
ÁõÆÁöÑ: ÂìÅË≥™ÔºàÁ¥îÂ∫¶‚â•97%Ôºâ„ÇíÊ∫Ä„Åü„Åó„Å§„Å§„ÄÅ„Ç®„Éç„É´„ÇÆ„ÉºÊ∂àË≤ªÔºàreboiler_dutyÔºâ„ÇíÊúÄÂ∞èÂåñ

Êé¢Á¥¢ÁØÑÂõ≤:
  ÈÇÑÊµÅÊØî: 2.00 „Äú 3.50
  „É™„Éú„Ç§„É©„ÉºÁÜ±Èáè: 1300 „Äú 1700 kW
  Êé¢Á¥¢ÁÇπÊï∞: 400ÁÇπ

„ÄêÊé¢Á¥¢ÁµêÊûú„Äë
ÂÖ®Êé¢Á¥¢ÁÇπÊï∞: 400
ÂìÅË≥™Âà∂Á¥Ñ„ÇíÊ∫Ä„Åü„ÅôÁÇπ: 156ÁÇπ

„ÄêÊúÄÈÅ©ÈÅãËª¢Êù°‰ª∂„Äë
  ÈÇÑÊµÅÊØî: 2.789
  „É™„Éú„Ç§„É©„ÉºÁÜ±Èáè: 1368.4 kW
  ‰∫àÊ∏¨Á¥îÂ∫¶: 97.12%

„ÄêÁèæÁä∂„Å®„ÅÆÊØîËºÉ„Äë
  ÈÇÑÊµÅÊØî: 2.503 ‚Üí 2.789
  „É™„Éú„Ç§„É©„ÉºÁÜ±Èáè: 1499.8 kW ‚Üí 1368.4 kW
  ‰∫àÊ∏¨Á¥îÂ∫¶: 96.51% ‚Üí 97.12%

„Ç®„Éç„É´„ÇÆ„ÉºÂâäÊ∏õ: 8.8%
Âπ¥Èñì„Ç≥„Çπ„ÉàÂâäÊ∏õÔºà‰ªÆÂÆöÔºâ: ¬•880‰∏áÂÜÜ
</code></pre>

<p><strong>Ëß£Ë™¨</strong>: Grid Search„Å´„Çà„ÇãÊúÄÈÅ©Âåñ„Åß„ÄÅÂìÅË≥™„ÇíÂêë‰∏ä„Åï„Åõ„Å§„Å§„Ç®„Éç„É´„ÇÆ„ÉºÂâäÊ∏õ„ÇíÈÅîÊàê„Åô„ÇãÊù°‰ª∂„ÇíÁô∫Ë¶ã„Åó„Åæ„Åó„Åü„ÄÇÂÆü„Éó„É©„É≥„Éà„Åß„ÅØ„ÄÅ„Åï„Çâ„Å´È´òÂ∫¶„Å™ÊúÄÈÅ©ÂåñÊâãÊ≥ïÔºàÈÅ∫‰ºùÁöÑ„Ç¢„É´„Ç¥„É™„Ç∫„É†„ÄÅ„Éô„Ç§„Ç∫ÊúÄÈÅ©Âåñ„Å™„Å©Ôºâ„ÇÇÊ¥ªÁî®„Åï„Çå„Åæ„Åô„ÄÇ</p>

<h4>„Ç≥„Éº„Éâ‰æã7: È´òÂ∫¶„Å™ÊúÄÈÅ©ÂåñÔºàScipy.optimizeÔºâ</h4>

<pre><code class="language-python">import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import joblib
from scipy.optimize import minimize, differential_evolution

# „É¢„Éá„É´„Å®„Çπ„Ç±„Éº„É©„Éº„ÅÆË™≠„ÅøËæº„Åø
best_model = joblib.load('best_model.pkl')
scaler = joblib.load('scaler.pkl')

print("„ÄêÈ´òÂ∫¶„Å™ÊúÄÈÅ©ÂåñÔºàScipy.optimizeÔºâ„Äë")

# Âõ∫ÂÆö„Éë„É©„É°„Éº„Çø
feed_temp_fixed = 60.0
feed_rate_fixed = 100.0
pressure_fixed = 1.2

# ÁõÆÁöÑÈñ¢Êï∞: „Ç®„Éç„É´„ÇÆ„ÉºÔºàÊúÄÂ∞èÂåñÔºâ
def objective(x):
    """„Ç®„Éç„É´„ÇÆ„ÉºÊ∂àË≤ª„ÇíÊúÄÂ∞èÂåñÔºà„É™„Éú„Ç§„É©„ÉºÁÜ±ÈáèÔºâ"""
    reflux_ratio, reboiler_duty = x
    return reboiler_duty  # ÊúÄÂ∞èÂåñ„Åó„Åü„ÅÑÁõÆÊ®ô

# Âà∂Á¥ÑÊù°‰ª∂: Á¥îÂ∫¶‚â•97%
def constraint_purity(x):
    """Á¥îÂ∫¶Âà∂Á¥ÑÔºà‚â•97%Ôºâ"""
    reflux_ratio, reboiler_duty = x

    # ÁâπÂæ¥ÈáèË®àÁÆó
    top_temp = 85 + 0.5 * (reflux_ratio - 2.5)
    mid_temp = 120
    bottom_temp = 155
    temp_gradient = top_temp - bottom_temp
    energy_efficiency = reboiler_duty / feed_rate_fixed

    features = np.array([[
        feed_temp_fixed, top_temp, mid_temp, bottom_temp,
        reflux_ratio, reboiler_duty, pressure_fixed, feed_rate_fixed,
        temp_gradient, energy_efficiency, 0, 1
    ]])

    features_df = pd.DataFrame(features, columns=feature_cols)
    features_scaled = scaler.transform(features_df)

    purity_pred = best_model.predict(features_scaled)[0]

    # Âà∂Á¥Ñ: purity >= 97 ‚Üí purity - 97 >= 0
    return purity_pred - 97.0

# Â§âÊï∞„ÅÆÁØÑÂõ≤
bounds = [
    (2.0, 3.5),      # ÈÇÑÊµÅÊØî
    (1300, 1700)     # „É™„Éú„Ç§„É©„ÉºÁÜ±Èáè (kW)
]

# Âà∂Á¥Ñ„ÅÆÂÆöÁæ©
constraints = [
    {'type': 'ineq', 'fun': constraint_purity}  # inequality: f(x) >= 0
]

# ÂàùÊúüÂÄ§
x0 = [2.5, 1500]

print("\nÊñπÊ≥ï1: SLSQPÔºàÂãæÈÖç„Éô„Éº„ÇπÔºâ")
result_slsqp = minimize(objective, x0, method='SLSQP',
                         bounds=bounds, constraints=constraints,
                         options={'disp': True})

if result_slsqp.success:
    print(f"\n„ÄêÊúÄÈÅ©Ëß£ÔºàSLSQPÔºâ„Äë")
    print(f"  ÈÇÑÊµÅÊØî: {result_slsqp.x[0]:.3f}")
    print(f"  „É™„Éú„Ç§„É©„ÉºÁÜ±Èáè: {result_slsqp.x[1]:.1f} kW")
    print(f"  ‰∫àÊ∏¨Á¥îÂ∫¶: {constraint_purity(result_slsqp.x) + 97:.2f}%")
else:
    print("\nÊúÄÈÅ©ÂåñÂ§±ÊïóÔºàSLSQPÔºâ")

# ÊñπÊ≥ï2: Differential EvolutionÔºàÈÄ≤ÂåñÁöÑ„Ç¢„É´„Ç¥„É™„Ç∫„É†Ôºâ
print("\n\nÊñπÊ≥ï2: Differential EvolutionÔºàÂ§ßÂüüÁöÑÊé¢Á¥¢Ôºâ")

def objective_with_penalty(x):
    """„Éö„Éä„É´„ÉÜ„Ç£Èñ¢Êï∞Ê≥ï„ÅßÂà∂Á¥Ñ„ÇíÁõÆÁöÑÈñ¢Êï∞„Å´ÁµÑ„ÅøËæº„ÇÄ"""
    energy = objective(x)
    purity_constraint = constraint_purity(x)

    # Âà∂Á¥ÑÈÅïÂèç„Å´„Éö„Éä„É´„ÉÜ„Ç£
    if purity_constraint < 0:
        penalty = 1000 * abs(purity_constraint)
        return energy + penalty
    else:
        return energy

result_de = differential_evolution(objective_with_penalty, bounds,
                                    seed=42, disp=True, maxiter=100)

print(f"\n„ÄêÊúÄÈÅ©Ëß£ÔºàDifferential EvolutionÔºâ„Äë")
print(f"  ÈÇÑÊµÅÊØî: {result_de.x[0]:.3f}")
print(f"  „É™„Éú„Ç§„É©„ÉºÁÜ±Èáè: {result_de.x[1]:.1f} kW")
print(f"  ‰∫àÊ∏¨Á¥îÂ∫¶: {constraint_purity(result_de.x) + 97:.2f}%")

# ÁµêÊûú„ÅÆÊØîËºÉ
print(f"\n„ÄêÊúÄÈÅ©ÂåñÊâãÊ≥ï„ÅÆÊØîËºÉ„Äë")
print(f"SLSQPÔºàÂ±ÄÊâÄÊúÄÈÅ©ÂåñÔºâ: „Ç®„Éç„É´„ÇÆ„Éº = {result_slsqp.fun:.1f} kW")
print(f"Differential EvolutionÔºàÂ§ßÂüüÊúÄÈÅ©ÂåñÔºâ: „Ç®„Éç„É´„ÇÆ„Éº = {result_de.fun:.1f} kW")

# ÂèØË¶ñÂåñ: ÊúÄÈÅ©Âåñ„ÅÆÁµåË∑Ø
fig, ax = plt.subplots(figsize=(10, 8))

# „Ç∞„É™„ÉÉ„Éâ„Åß„ÅÆÁ¥îÂ∫¶ÂàÜÂ∏É
reflux_grid = np.linspace(2.0, 3.5, 50)
duty_grid = np.linspace(1300, 1700, 50)
R, D = np.meshgrid(reflux_grid, duty_grid)

purity_grid = np.zeros_like(R)
for i in range(len(reflux_grid)):
    for j in range(len(duty_grid)):
        purity_grid[j, i] = constraint_purity([R[j, i], D[j, i]]) + 97

contour = ax.contourf(R, D, purity_grid, levels=20, cmap='RdYlGn', alpha=0.6)
ax.contour(R, D, purity_grid, levels=[97.0], colors='red', linewidths=3, linestyles='--')

# ÊúÄÈÅ©Ëß£„Çí„Éó„É≠„ÉÉ„Éà
if result_slsqp.success:
    ax.scatter(result_slsqp.x[0], result_slsqp.x[1], s=200, color='blue',
               marker='o', edgecolor='white', linewidth=2, label='SLSQP', zorder=5)

ax.scatter(result_de.x[0], result_de.x[1], s=200, color='orange',
           marker='*', edgecolor='white', linewidth=2, label='Differential Evolution', zorder=5)

# ÂàùÊúüÁÇπ
ax.scatter(x0[0], x0[1], s=100, color='black', marker='x', linewidth=2,
           label='Initial point', zorder=5)

ax.set_xlabel('Reflux Ratio', fontsize=12)
ax.set_ylabel('Reboiler Duty (kW)', fontsize=12)
ax.set_title('Optimization Results on Purity Contour', fontsize=13, fontweight='bold')
ax.legend(fontsize=10)
plt.colorbar(contour, ax=ax, label='Purity (%)')
plt.tight_layout()
plt.savefig('advanced_optimization.png', dpi=150, bbox_inches='tight')
plt.show()

print("\n„ÄêÊúÄÈÅ©ÂåñÊâãÊ≥ï„ÅÆÈÅ∏ÊäûÊåáÈáù„Äë")
print("‚úì SLSQP: È´òÈÄü„ÄÅÂãæÈÖçÊÉÖÂ†±„ÇíÂà©Áî®„ÄÅÂ±ÄÊâÄÊúÄÈÅ©Ëß£")
print("‚úì Differential Evolution: ÈÅÖ„ÅÑ„ÄÅÂ§ßÂüüÁöÑÊé¢Á¥¢„ÄÅË§áÈõë„Å™ÁõÆÁöÑÈñ¢Êï∞„Å´Âº∑„ÅÑ")
print("‚úì ÂÆüÂãô: „Åæ„ÅöSLSQP„ÅßÈ´òÈÄüÊé¢Á¥¢„ÄÅÂøÖË¶Å„Å´Âøú„Åò„Å¶DE„ÅßÁ¢∫Ë™ç")
</code></pre>

<p><strong>Âá∫Âäõ‰æã</strong>:</p>
<pre><code>„ÄêÈ´òÂ∫¶„Å™ÊúÄÈÅ©ÂåñÔºàScipy.optimizeÔºâ„Äë

ÊñπÊ≥ï1: SLSQPÔºàÂãæÈÖç„Éô„Éº„ÇπÔºâ
Optimization terminated successfully

„ÄêÊúÄÈÅ©Ëß£ÔºàSLSQPÔºâ„Äë
  ÈÇÑÊµÅÊØî: 2.784
  „É™„Éú„Ç§„É©„ÉºÁÜ±Èáè: 1365.2 kW
  ‰∫àÊ∏¨Á¥îÂ∫¶: 97.03%

ÊñπÊ≥ï2: Differential EvolutionÔºàÂ§ßÂüüÁöÑÊé¢Á¥¢Ôºâ

„ÄêÊúÄÈÅ©Ëß£ÔºàDifferential EvolutionÔºâ„Äë
  ÈÇÑÊµÅÊØî: 2.789
  „É™„Éú„Ç§„É©„ÉºÁÜ±Èáè: 1363.8 kW
  ‰∫àÊ∏¨Á¥îÂ∫¶: 97.05%

„ÄêÊúÄÈÅ©ÂåñÊâãÊ≥ï„ÅÆÊØîËºÉ„Äë
SLSQPÔºàÂ±ÄÊâÄÊúÄÈÅ©ÂåñÔºâ: „Ç®„Éç„É´„ÇÆ„Éº = 1365.2 kW
Differential EvolutionÔºàÂ§ßÂüüÊúÄÈÅ©ÂåñÔºâ: „Ç®„Éç„É´„ÇÆ„Éº = 1363.8 kW
</code></pre>

<p><strong>Ëß£Ë™¨</strong>: Scipy.optimize„Çí‰Ωø„ÅÜ„Åì„Å®„Åß„ÄÅ„Çà„ÇäÈ´òÂ∫¶„Å™ÊúÄÈÅ©Âåñ„ÅåÂèØËÉΩ„Åß„Åô„ÄÇSLSQP„ÅØÈ´òÈÄü„Åß„Åô„ÅåÂ±ÄÊâÄËß£„Å´Èô•„ÇãÂèØËÉΩÊÄß„Åå„ÅÇ„Çä„ÄÅDifferential Evolution„ÅØÈÅÖ„ÅÑ„Åß„Åô„ÅåÂ§ßÂüüÁöÑÊúÄÈÅ©Ëß£„ÇíË¶ã„Å§„Åë„ÇÑ„Åô„ÅÑÁâπÂæ¥„Åå„ÅÇ„Çä„Åæ„Åô„ÄÇ</p>

<hr />

<h2>4.4 ÂÆüË£Ö„Éó„É≠„Ç∏„Çß„ÇØ„ÉàÂÖ®‰Ωì„ÅÆ„ÉØ„Éº„ÇØ„Éï„É≠„Éº</h2>

<p>„Åì„Çå„Åæ„Åß„ÅÆÂÖ®„Çπ„ÉÜ„ÉÉ„Éó„ÇíÁµ±Âêà„Åó„ÄÅ„Ç®„É≥„Éâ„ÉÑ„Éº„Ç®„É≥„Éâ„ÅÆPI„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÉØ„Éº„ÇØ„Éï„É≠„Éº„ÇíÁ¢∫Á´ã„Åó„Åæ„Åô„ÄÇ</p>

<h4>„Ç≥„Éº„Éâ‰æã8: Áµ±Âêà„Éë„Ç§„Éó„É©„Ç§„É≥„Å®„Éá„Éó„É≠„Ç§„É°„É≥„ÉàÊ∫ñÂÇô</h4>

<pre><code class="language-python">import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import joblib
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import RobustScaler
from sklearn.ensemble import GradientBoostingRegressor
import json

print("=" * 80)
print("„ÄêPIÁµ±Âêà„Éó„É≠„Ç∏„Çß„ÇØ„Éà: „Ç®„É≥„Éâ„ÉÑ„Éº„Ç®„É≥„Éâ„ÉØ„Éº„ÇØ„Éï„É≠„Éº„Äë")
print("=" * 80)

# ============================================================================
# „Çπ„ÉÜ„ÉÉ„Éó1: „Éá„Éº„Çø„Éë„Ç§„Éó„É©„Ç§„É≥ÊßãÁØâ
# ============================================================================
print("\n„Äê„Çπ„ÉÜ„ÉÉ„Éó1: „Éá„Éº„Çø„Éë„Ç§„Éó„É©„Ç§„É≥ÊßãÁØâ„Äë")

class ProcessDataPipeline:
    """„Éó„É≠„Çª„Çπ„Éá„Éº„Çø„ÅÆÂâçÂá¶ÁêÜ„Éë„Ç§„Éó„É©„Ç§„É≥"""

    def __init__(self):
        self.scaler = RobustScaler()
        self.feature_cols = None

    def fit(self, df, feature_cols):
        """Ë®ìÁ∑¥„Éá„Éº„Çø„Åß„Éë„Ç§„Éó„É©„Ç§„É≥„Çífit"""
        self.feature_cols = feature_cols

        # Ê¨†ÊêçÂÄ§Ë£úÂÆå
        df_clean = df.copy()
        for col in feature_cols:
            df_clean[col] = df_clean[col].interpolate(method='linear')

        # „Çπ„Ç±„Éº„É™„É≥„Ç∞
        self.scaler.fit(df_clean[feature_cols])

        return self

    def transform(self, df):
        """„Éá„Éº„Çø„ÇíÂ§âÊèõ"""
        df_clean = df.copy()

        # Ê¨†ÊêçÂÄ§Ë£úÂÆå
        for col in self.feature_cols:
            df_clean[col] = df_clean[col].interpolate(method='linear')

        # „Çπ„Ç±„Éº„É™„É≥„Ç∞
        df_clean[self.feature_cols] = self.scaler.transform(df_clean[self.feature_cols])

        return df_clean

    def save(self, filepath):
        """„Éë„Ç§„Éó„É©„Ç§„É≥„Çí‰øùÂ≠ò"""
        joblib.dump(self, filepath)
        print(f"  „Éë„Ç§„Éó„É©„Ç§„É≥‰øùÂ≠ò: {filepath}")

    @staticmethod
    def load(filepath):
        """„Éë„Ç§„Éó„É©„Ç§„É≥„ÇíË™≠„ÅøËæº„Åø"""
        return joblib.load(filepath)

# „Éë„Ç§„Éó„É©„Ç§„É≥„ÅÆ„Ç§„É≥„Çπ„Çø„É≥„ÇπÂåñ
pipeline = ProcessDataPipeline()

# „Éá„Éº„ÇøË™≠„ÅøËæº„Åø
df = pd.read_csv('distillation_data_cleaned.csv', parse_dates=['timestamp'])
df = df.set_index('timestamp')

feature_cols = ['feed_temp', 'top_temp', 'mid_temp', 'bottom_temp',
                'reflux_ratio', 'reboiler_duty', 'pressure', 'feed_rate',
                'temp_gradient', 'energy_efficiency', 'hour_sin', 'hour_cos']

# „Ç™„Éï„É©„Ç§„É≥Ê∏¨ÂÆö„Éá„Éº„Çø„ÅÆ„Åø
train_data = df[df['purity_measured'].notna()].copy()
X_train = train_data[feature_cols]
y_train = train_data['purity_measured']

# „Éë„Ç§„Éó„É©„Ç§„É≥„Çífit
pipeline.fit(X_train, feature_cols)
X_train_processed = pipeline.transform(X_train)

print("  „Éá„Éº„ÇøÂâçÂá¶ÁêÜ„Éë„Ç§„Éó„É©„Ç§„É≥ÊßãÁØâÂÆå‰∫Ü")

# ============================================================================
# „Çπ„ÉÜ„ÉÉ„Éó2: „É¢„Éá„É´„Éà„É¨„Éº„Éã„É≥„Ç∞
# ============================================================================
print("\n„Äê„Çπ„ÉÜ„ÉÉ„Éó2: „É¢„Éá„É´„Éà„É¨„Éº„Éã„É≥„Ç∞„Äë")

model = GradientBoostingRegressor(n_estimators=100, max_depth=5,
                                   learning_rate=0.1, random_state=42)
model.fit(X_train_processed[feature_cols], y_train)

print(f"  „É¢„Éá„É´: Gradient Boosting Regressor")
print(f"  Ë®ìÁ∑¥„Éá„Éº„ÇøÊï∞: {len(X_train)}")
print(f"  ÁâπÂæ¥ÈáèÊï∞: {len(feature_cols)}")

# ============================================================================
# „Çπ„ÉÜ„ÉÉ„Éó3: „É¢„Éá„É´Ë©ï‰æ°
# ============================================================================
print("\n„Äê„Çπ„ÉÜ„ÉÉ„Éó3: „É¢„Éá„É´Ë©ï‰æ°„Äë")

from sklearn.model_selection import cross_val_score
from sklearn.metrics import r2_score, mean_squared_error

cv_scores = cross_val_score(model, X_train_processed[feature_cols], y_train, cv=5, scoring='r2')
print(f"  CV R¬≤ „Çπ„Ç≥„Ç¢: {cv_scores.mean():.4f} (¬±{cv_scores.std():.4f})")

y_train_pred = model.predict(X_train_processed[feature_cols])
train_r2 = r2_score(y_train, y_train_pred)
train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))
print(f"  Ë®ìÁ∑¥„Éá„Éº„Çø R¬≤: {train_r2:.4f}")
print(f"  Ë®ìÁ∑¥„Éá„Éº„Çø RMSE: {train_rmse:.4f}%")

# ============================================================================
# „Çπ„ÉÜ„ÉÉ„Éó4: „Éá„Éó„É≠„Ç§„É°„É≥„ÉàÊ∫ñÂÇô
# ============================================================================
print("\n„Äê„Çπ„ÉÜ„ÉÉ„Éó4: „Éá„Éó„É≠„Ç§„É°„É≥„ÉàÊ∫ñÂÇô„Äë")

# „É¢„Éá„É´„Å®„Éë„Ç§„Éó„É©„Ç§„É≥„Çí‰øùÂ≠ò
model_path = 'production_model.pkl'
pipeline_path = 'production_pipeline.pkl'

joblib.dump(model, model_path)
pipeline.save(pipeline_path)

print(f"  „É¢„Éá„É´‰øùÂ≠ò: {model_path}")
print(f"  „Éë„Ç§„Éó„É©„Ç§„É≥‰øùÂ≠ò: {pipeline_path}")

# „É°„Çø„Éá„Éº„Çø„ÅÆ‰øùÂ≠ò
metadata = {
    'model_type': 'Gradient Boosting Regressor',
    'training_date': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S'),
    'training_samples': len(X_train),
    'features': feature_cols,
    'cv_r2_mean': float(cv_scores.mean()),
    'cv_r2_std': float(cv_scores.std()),
    'train_r2': float(train_r2),
    'train_rmse': float(train_rmse),
    'target_variable': 'purity',
    'target_unit': '%',
    'quality_threshold': 97.0
}

with open('model_metadata.json', 'w') as f:
    json.dump(metadata, f, indent=2)

print("  „É°„Çø„Éá„Éº„Çø‰øùÂ≠ò: model_metadata.json")

# ============================================================================
# „Çπ„ÉÜ„ÉÉ„Éó5: Êé®Ë´ñÈñ¢Êï∞Ôºà„Éá„Éó„É≠„Ç§„É°„É≥„ÉàÁî®Ôºâ
# ============================================================================
print("\n„Äê„Çπ„ÉÜ„ÉÉ„Éó5: Êé®Ë´ñÈñ¢Êï∞„ÅÆÂÆüË£Ö„Äë")

def predict_purity(process_data):
    """
    „Éó„É≠„Çª„Çπ„Éá„Éº„Çø„Åã„ÇâÁ¥îÂ∫¶„Çí‰∫àÊ∏¨

    Parameters:
    -----------
    process_data : dict
        „Éó„É≠„Çª„ÇπÂ§âÊï∞„ÅÆËæûÊõ∏
        ‰æã: {'feed_temp': 60, 'top_temp': 85, ...}

    Returns:
    --------
    float
        ‰∫àÊ∏¨Á¥îÂ∫¶Ôºà%Ôºâ
    """
    # „É¢„Éá„É´„Å®„Éë„Ç§„Éó„É©„Ç§„É≥„ÅÆË™≠„ÅøËæº„Åø
    model = joblib.load('production_model.pkl')
    pipeline = ProcessDataPipeline.load('production_pipeline.pkl')

    # „Éá„Éº„Çø„Éï„É¨„Éº„É†„Å´Â§âÊèõ
    df = pd.DataFrame([process_data])

    # ÂâçÂá¶ÁêÜ
    df_processed = pipeline.transform(df)

    # ‰∫àÊ∏¨
    purity_pred = model.predict(df_processed[feature_cols])[0]

    return purity_pred

# „ÉÜ„Çπ„ÉàÂÆüË°å
test_data = {
    'feed_temp': 60.0,
    'top_temp': 85.5,
    'mid_temp': 120.0,
    'bottom_temp': 155.0,
    'reflux_ratio': 2.8,
    'reboiler_duty': 1400,
    'pressure': 1.2,
    'feed_rate': 100,
    'temp_gradient': -69.5,
    'energy_efficiency': 14.0,
    'hour_sin': 0,
    'hour_cos': 1
}

purity_prediction = predict_purity(test_data)
print(f"\n  Êé®Ë´ñ„ÉÜ„Çπ„Éà:")
print(f"    ÂÖ•Âäõ: {test_data}")
print(f"    ‰∫àÊ∏¨Á¥îÂ∫¶: {purity_prediction:.2f}%")

# ============================================================================
# „Çπ„ÉÜ„ÉÉ„Éó6: „É¢„Éã„Çø„É™„É≥„Ç∞„ÉÄ„ÉÉ„Ç∑„É•„Éú„Éº„ÉâÁî®„Éá„Éº„ÇøÂá∫Âäõ
# ============================================================================
print("\n„Äê„Çπ„ÉÜ„ÉÉ„Éó6: „É¢„Éã„Çø„É™„É≥„Ç∞„ÉÄ„ÉÉ„Ç∑„É•„Éú„Éº„ÉâÁî®„Éá„Éº„ÇøÁîüÊàê„Äë")

# ÂÖ®„Éá„Éº„Çø„Å´ÂØæ„Åó„Å¶„É™„Ç¢„É´„Çø„Ç§„É†‰∫àÊ∏¨
df_all = df.copy()
df_all_processed = pipeline.transform(df_all)
df_all['purity_predicted'] = model.predict(df_all_processed[feature_cols])

# ‰∫àÊ∏¨Ë™§Â∑Æ„ÅÆË®àÁÆóÔºà„Ç™„Éï„É©„Ç§„É≥Ê∏¨ÂÆö„Åå„ÅÇ„ÇãÊôÇ„ÅÆ„ÅøÔºâ
df_all['prediction_error'] = df_all['purity_measured'] - df_all['purity_predicted']

# „ÉÄ„ÉÉ„Ç∑„É•„Éú„Éº„ÉâÁî®„Éá„Éº„Çø„ÅÆ‰øùÂ≠òÔºàÊúÄÊñ∞1ÈÄ±ÈñìÔºâ
dashboard_data = df_all.tail(10080)[['purity', 'purity_predicted', 'purity_measured',
                                       'prediction_error', 'reflux_ratio', 'reboiler_duty']]
dashboard_data.to_csv('dashboard_data.csv')

print("  „ÉÄ„ÉÉ„Ç∑„É•„Éú„Éº„ÉâÁî®„Éá„Éº„Çø‰øùÂ≠ò: dashboard_data.csv")
print(f"  „Éá„Éº„ÇøÊúüÈñì: {dashboard_data.index.min()} „Äú {dashboard_data.index.max()}")

# ÊÄßËÉΩ„Çµ„Éû„É™„Éº
errors = df_all['prediction_error'].dropna()
print(f"\n  „É¢„Éá„É´ÊÄßËÉΩ„Çµ„Éû„É™„ÉºÔºà„Ç™„Éï„É©„Ç§„É≥Ê∏¨ÂÆö„Å®„ÅÆÊØîËºÉÔºâ:")
print(f"    Âπ≥ÂùáË™§Â∑Æ: {errors.mean():.4f}%")
print(f"    Ê®ôÊ∫ñÂÅèÂ∑Æ: {errors.std():.4f}%")
print(f"    ÊúÄÂ§ßË™§Â∑Æ: {errors.abs().max():.4f}%")

# ============================================================================
# „Åæ„Å®„ÇÅ
# ============================================================================
print("\n" + "=" * 80)
print("„Äê„Éó„É≠„Ç∏„Çß„ÇØ„ÉàÂÆå‰∫Ü„Äë")
print("=" * 80)
print("\nÊßãÁØâ„Åó„ÅüÊàêÊûúÁâ©:")
print("  1. production_model.pkl - Ë®ìÁ∑¥Ê∏à„Åø„É¢„Éá„É´")
print("  2. production_pipeline.pkl - „Éá„Éº„ÇøÂâçÂá¶ÁêÜ„Éë„Ç§„Éó„É©„Ç§„É≥")
print("  3. model_metadata.json - „É¢„Éá„É´„ÅÆ„É°„ÇøÊÉÖÂ†±")
print("  4. dashboard_data.csv - „É¢„Éã„Çø„É™„É≥„Ç∞„ÉÄ„ÉÉ„Ç∑„É•„Éú„Éº„ÉâÁî®„Éá„Éº„Çø")
print("  5. predict_purity() - Êé®Ë´ñÈñ¢Êï∞ÔºàÊú¨Áï™„Éá„Éó„É≠„Ç§Áî®Ôºâ")

print("\nÊ¨°„ÅÆ„Çπ„ÉÜ„ÉÉ„Éó:")
print("  ‚úì ÂÆü„Éó„É©„É≥„Éà„Åß„ÅÆ„Éë„Ç§„É≠„ÉÉ„ÉàÈÅãÁî®")
print("  ‚úì „É™„Ç¢„É´„Çø„Ç§„É†„Éá„Éº„Çø„Çπ„Éà„É™„Éº„É†„Å®„ÅÆÊé•Á∂ö")
print("  ‚úì ÂÆöÊúüÁöÑ„Å™„É¢„Éá„É´ÂÜçÂ≠¶Áøí„Çπ„Ç±„Ç∏„É•„Éº„É´„ÅÆÁ¢∫Á´ã")
print("  ‚úì „Ç¢„É©„Éº„ÉàÊ©üËÉΩ„ÅÆÂÆüË£ÖÔºà‰∫àÊ∏¨Á¥îÂ∫¶ < ÈñæÂÄ§Ôºâ")
print("  ‚úì A/B„ÉÜ„Çπ„Éà„Å´„Çà„ÇãÊúÄÈÅ©ÂåñÊù°‰ª∂„ÅÆÊ§úË®º")
</code></pre>

<p><strong>Âá∫Âäõ‰æã</strong>:</p>
<pre><code>================================================================================
„ÄêPIÁµ±Âêà„Éó„É≠„Ç∏„Çß„ÇØ„Éà: „Ç®„É≥„Éâ„ÉÑ„Éº„Ç®„É≥„Éâ„ÉØ„Éº„ÇØ„Éï„É≠„Éº„Äë
================================================================================

„Äê„Çπ„ÉÜ„ÉÉ„Éó1: „Éá„Éº„Çø„Éë„Ç§„Éó„É©„Ç§„É≥ÊßãÁØâ„Äë
  „Éá„Éº„ÇøÂâçÂá¶ÁêÜ„Éë„Ç§„Éó„É©„Ç§„É≥ÊßãÁØâÂÆå‰∫Ü

„Äê„Çπ„ÉÜ„ÉÉ„Éó2: „É¢„Éá„É´„Éà„É¨„Éº„Éã„É≥„Ç∞„Äë
  „É¢„Éá„É´: Gradient Boosting Regressor
  Ë®ìÁ∑¥„Éá„Éº„ÇøÊï∞: 25
  ÁâπÂæ¥ÈáèÊï∞: 12

„Äê„Çπ„ÉÜ„ÉÉ„Éó3: „É¢„Éá„É´Ë©ï‰æ°„Äë
  CV R¬≤ „Çπ„Ç≥„Ç¢: 0.8923 (¬±0.1056)
  Ë®ìÁ∑¥„Éá„Éº„Çø R¬≤: 0.9567
  Ë®ìÁ∑¥„Éá„Éº„Çø RMSE: 0.2456%

„Äê„Çπ„ÉÜ„ÉÉ„Éó4: „Éá„Éó„É≠„Ç§„É°„É≥„ÉàÊ∫ñÂÇô„Äë
  „É¢„Éá„É´‰øùÂ≠ò: production_model.pkl
  „Éë„Ç§„Éó„É©„Ç§„É≥‰øùÂ≠ò: production_pipeline.pkl
  „É°„Çø„Éá„Éº„Çø‰øùÂ≠ò: model_metadata.json

„Äê„Çπ„ÉÜ„ÉÉ„Éó5: Êé®Ë´ñÈñ¢Êï∞„ÅÆÂÆüË£Ö„Äë

  Êé®Ë´ñ„ÉÜ„Çπ„Éà:
    ÂÖ•Âäõ: {'feed_temp': 60.0, 'top_temp': 85.5, ...}
    ‰∫àÊ∏¨Á¥îÂ∫¶: 97.34%

„Äê„Çπ„ÉÜ„ÉÉ„Éó6: „É¢„Éã„Çø„É™„É≥„Ç∞„ÉÄ„ÉÉ„Ç∑„É•„Éú„Éº„ÉâÁî®„Éá„Éº„ÇøÁîüÊàê„Äë
  „ÉÄ„ÉÉ„Ç∑„É•„Éú„Éº„ÉâÁî®„Éá„Éº„Çø‰øùÂ≠ò: dashboard_data.csv
  „Éá„Éº„ÇøÊúüÈñì: 2025-01-24 00:00:00 „Äú 2025-01-30 23:59:00

  „É¢„Éá„É´ÊÄßËÉΩ„Çµ„Éû„É™„ÉºÔºà„Ç™„Éï„É©„Ç§„É≥Ê∏¨ÂÆö„Å®„ÅÆÊØîËºÉÔºâ:
    Âπ≥ÂùáË™§Â∑Æ: 0.0123%
    Ê®ôÊ∫ñÂÅèÂ∑Æ: 0.2567%
    ÊúÄÂ§ßË™§Â∑Æ: 0.5678%

================================================================================
„Äê„Éó„É≠„Ç∏„Çß„ÇØ„ÉàÂÆå‰∫Ü„Äë
================================================================================
</code></pre>

<p><strong>Ëß£Ë™¨</strong>: ÂÆüÂãô„Åß„ÅØ„ÄÅ„É¢„Éá„É´ÊßãÁØâ„Å†„Åë„Åß„Å™„Åè„ÄÅ„Éá„Éó„É≠„Ç§„É°„É≥„ÉàÊ∫ñÂÇô„ÄÅÊé®Ë´ñÈñ¢Êï∞„ÅÆÂÆüË£Ö„ÄÅ„É¢„Éã„Çø„É™„É≥„Ç∞Âü∫Áõ§„ÅÆÊï¥ÂÇô„Åæ„Åß„ÅåÈáçË¶Å„Åß„Åô„ÄÇ„Åì„ÅÆ„ÉØ„Éº„ÇØ„Éï„É≠„Éº„ÅØ„ÄÅÂÆü„Éó„É©„É≥„Éà„Å∏„ÅÆÈÅ©Áî®„ÅÆÂü∫Á§é„Å®„Å™„Çä„Åæ„Åô„ÄÇ</p>

<hr />

<h2>4.5 „Åæ„Å®„ÇÅ„Å®Ê¨°„ÅÆ„Çπ„ÉÜ„ÉÉ„Éó</h2>

<h3>Êú¨„Ç∑„É™„Éº„Ç∫„ÅßÂ≠¶„Çì„Å†„Åì„Å®</h3>

<details>
<summary><strong>Á¨¨1Á´†: PI„ÅÆÂü∫Á§éÊ¶ÇÂøµ</strong></summary>
<ul>
<li>„Éó„É≠„Çª„Çπ„Éª„Ç§„É≥„Éï„Ç©„Éû„ÉÜ„Ç£„ÇØ„Çπ„ÅÆÂÆöÁæ©„Å®ÁõÆÁöÑ</li>
<li>„Éó„É≠„Çª„ÇπÁî£Ê•≠„ÅÆÁâπÂæ¥„Å®„Éá„Éº„Çø„ÅÆÁ®ÆÈ°û</li>
<li>„Éá„Éº„ÇøÈßÜÂãïÂûã„Éó„É≠„Çª„ÇπÊîπÂñÑ„ÅÆÂÆü‰æã„Å®ROI</li>
<li>Python„Å´„Çà„ÇãÂü∫Êú¨ÁöÑ„Å™„Éá„Éº„ÇøÂèØË¶ñÂåñ</li>
</ul>
</details>

<details>
<summary><strong>Á¨¨2Á´†: „Éá„Éº„ÇøÂâçÂá¶ÁêÜ„Å®ÂèØË¶ñÂåñ</strong></summary>
<ul>
<li>ÊôÇÁ≥ªÂàó„Éá„Éº„Çø„ÅÆÊìç‰ΩúÔºà„É™„Çµ„É≥„Éó„É™„É≥„Ç∞„ÄÅ„É≠„Éº„É™„É≥„Ç∞Áµ±Ë®àÔºâ</li>
<li>Ê¨†ÊêçÂÄ§Âá¶ÁêÜ„Å®Â§ñ„ÇåÂÄ§Ê§úÂá∫„ÅÆÂÆüË∑µÊâãÊ≥ï</li>
<li>„Éá„Éº„Çø„Çπ„Ç±„Éº„É™„É≥„Ç∞„ÅÆÈÅ∏Êäû„Å®ÂÆüË£Ö</li>
<li>È´òÂ∫¶„Å™ÂèØË¶ñÂåñ„ÉÜ„ÇØ„Éã„ÉÉ„ÇØ</li>
</ul>
</details>

<details>
<summary><strong>Á¨¨3Á´†: „Éó„É≠„Çª„Çπ„É¢„Éá„É™„É≥„Ç∞„ÅÆÂü∫Á§é</strong></summary>
<ul>
<li>Á∑öÂΩ¢ÂõûÂ∏∞„Å´„Çà„ÇãÂìÅË≥™‰∫àÊ∏¨„É¢„Éá„É´ÊßãÁØâ</li>
<li>PLS„Å´„Çà„ÇãÂ§öÈáçÂÖ±Á∑öÊÄßÂØæÂá¶</li>
<li>„ÇΩ„Éï„Éà„Çª„É≥„Çµ„Éº„ÅÆË®≠Ë®à„Å®ÈÅãÁî®</li>
<li>„É¢„Éá„É´Ë©ï‰æ°ÊåáÊ®ô„Å®„ÇØ„É≠„Çπ„Éê„É™„Éá„Éº„Ç∑„Éß„É≥</li>
<li>ÈùûÁ∑öÂΩ¢„É¢„Éá„É´„Å∏„ÅÆÊã°Âºµ</li>
</ul>
</details>

<details>
<summary><strong>Á¨¨4Á´†: ÂÆüË∑µÊºîÁøí</strong></summary>
<ul>
<li>ÂÆü„Éó„É≠„Çª„Çπ„Éá„Éº„Çø„ÅÆEDA„Å®„ÇØ„É™„Éº„Éã„É≥„Ç∞</li>
<li>ÁâπÂæ¥Èáè„Ç®„É≥„Ç∏„Éã„Ç¢„É™„É≥„Ç∞</li>
<li>Ë§áÊï∞„É¢„Éá„É´„ÅÆÊØîËºÉ„Å®ÊúÄÈÅ©„É¢„Éá„É´ÈÅ∏Êäû</li>
<li>„Éó„É≠„Çª„ÇπÊù°‰ª∂ÊúÄÈÅ©Âåñ„ÅÆÂü∫Á§é</li>
<li>„Ç®„É≥„Éâ„ÉÑ„Éº„Ç®„É≥„Éâ„ÅÆ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÉØ„Éº„ÇØ„Éï„É≠„Éº</li>
</ul>
</details>

<h3>ÂÆüÂãôÈÅ©Áî®„ÅÆ„ÉÅ„Çß„ÉÉ„ÇØ„É™„Çπ„Éà</h3>

<ol>
<li><strong>„Éá„Éº„ÇøÂèéÈõÜ„ÉªÁÆ°ÁêÜ</strong>
<ul>
<li>‚ñ° „Éó„É≠„Çª„ÇπÂ§âÊï∞„Å®ÂìÅË≥™Â§âÊï∞„ÅÆÁâπÂÆö</li>
<li>‚ñ° „Éá„Éº„ÇøÂèéÈõÜÈ†ªÂ∫¶„ÅÆÊ±∫ÂÆö</li>
<li>‚ñ° „Éá„Éº„Çø„Éô„Éº„ÇπË®≠Ë®à„Å®„Éí„Çπ„Éà„É™„Ç¢„É≥Êé•Á∂ö</li>
</ul>
</li>
<li><strong>„Éá„Éº„ÇøÂàÜÊûê</strong>
<ul>
<li>‚ñ° EDA„Å´„Çà„Çã„Éá„Éº„ÇøÁêÜËß£</li>
<li>‚ñ° Ê¨†ÊêçÂÄ§„ÉªÂ§ñ„ÇåÂÄ§„ÅÆÂØæÂá¶ÊñπÈáùÊ±∫ÂÆö</li>
<li>‚ñ° Áõ∏Èñ¢ÂàÜÊûê„Å®ÁâπÂæ¥ÈáèÈÅ∏Êäû</li>
</ul>
</li>
<li><strong>„É¢„Éá„É´ÊßãÁØâ</strong>
<ul>
<li>‚ñ° „Éô„É≥„ÉÅ„Éû„Éº„ÇØ„É¢„Éá„É´„ÅÆÊßãÁØâÔºàÁ∑öÂΩ¢ÂõûÂ∏∞Ôºâ</li>
<li>‚ñ° Ë§áÊï∞ÊâãÊ≥ï„ÅÆÊØîËºÉÊ§úË®º</li>
<li>‚ñ° „ÇØ„É≠„Çπ„Éê„É™„Éá„Éº„Ç∑„Éß„É≥„Å´„Çà„ÇãÊÄßËÉΩË©ï‰æ°</li>
<li>‚ñ° „É¢„Éá„É´„ÅÆËß£ÈáàÊÄßÁ¢∫Ë™ç</li>
</ul>
</li>
<li><strong>ÂÆüË£Ö„ÉªÈÅãÁî®</strong>
<ul>
<li>‚ñ° „Éë„Ç§„É≠„ÉÉ„ÉàÈÅãÁî®Ë®àÁîª„ÅÆÁ≠ñÂÆö</li>
<li>‚ñ° „É™„Ç¢„É´„Çø„Ç§„É†Êé®Ë´ñÂü∫Áõ§„ÅÆÊßãÁØâ</li>
<li>‚ñ° „É¢„Éã„Çø„É™„É≥„Ç∞„ÉÄ„ÉÉ„Ç∑„É•„Éú„Éº„Éâ„ÅÆË®≠ÁΩÆ</li>
<li>‚ñ° ÂÆöÊúüÁöÑ„Å™ÂÜçÂ≠¶Áøí„Çπ„Ç±„Ç∏„É•„Éº„É´Á¢∫Á´ã</li>
</ul>
</li>
<li><strong>Á∂ôÁ∂öÊîπÂñÑ</strong>
<ul>
<li>‚ñ° ÊÄßËÉΩ„É¢„Éã„Çø„É™„É≥„Ç∞„Å®„Éâ„É™„Éï„ÉàÊ§úÂá∫</li>
<li>‚ñ° A/B„ÉÜ„Çπ„Éà„Å´„Çà„ÇãÂäπÊûúÊ§úË®º</li>
<li>‚ñ° „Éï„Ç£„Éº„Éâ„Éê„ÉÉ„ÇØ„É´„Éº„Éó„ÅÆÊßãÁØâ</li>
</ul>
</li>
</ol>

<h3>Ê¨°„ÅÆ„Çπ„ÉÜ„ÉÉ„ÉóÔºö‰∏äÁ¥ö„Éà„Éî„ÉÉ„ÇØ</h3>

<p>Êú¨„Ç∑„É™„Éº„Ç∫„ÅßÂü∫Á§é„ÇíÁøíÂæó„Åó„ÅüÊñπ„ÅØ„ÄÅ‰ª•‰∏ã„ÅÆ‰∏äÁ¥ö„Éà„Éî„ÉÉ„ÇØ„Å´ÈÄ≤„ÇÄ„Åì„Å®„Çí„ÅäÂãß„ÇÅ„Åó„Åæ„ÅôÔºö</p>

<h4>1. È´òÂ∫¶„Å™„É¢„Éá„É™„É≥„Ç∞ÊâãÊ≥ï</h4>
<ul>
<li><strong>„Éá„Ç£„Éº„Éó„É©„Éº„Éã„É≥„Ç∞</strong>: LSTM„ÄÅCNN„Çí‰Ωø„Å£„ÅüÊôÇÁ≥ªÂàó‰∫àÊ∏¨</li>
<li><strong>„Ç¢„É≥„Çµ„É≥„Éñ„É´Â≠¶Áøí</strong>: „Çπ„Çø„ÉÉ„Ç≠„É≥„Ç∞„ÄÅ„Éñ„É¨„É≥„Éá„Ç£„É≥„Ç∞</li>
<li><strong>„Éô„Ç§„Ç∫ÊúÄÈÅ©Âåñ</strong>: „Éè„Ç§„Éë„Éº„Éë„É©„É°„Éº„Çø„ÅÆÂäπÁéáÁöÑÊé¢Á¥¢</li>
<li><strong>Ëª¢ÁßªÂ≠¶Áøí</strong>: ‰ªñ„Éó„É©„É≥„Éà„ÅÆ„Éá„Éº„Çø„ÇíÊ¥ªÁî®</li>
</ul>

<h4>2. „É™„Ç¢„É´„Çø„Ç§„É†PI</h4>
<ul>
<li><strong>„Çπ„Éà„É™„Éº„É†Âá¶ÁêÜ</strong>: Apache Kafka„ÄÅSpark Streaming„Å®„ÅÆÈÄ£Êê∫</li>
<li><strong>„Ç™„É≥„É©„Ç§„É≥Â≠¶Áøí</strong>: „Ç§„É≥„ÇØ„É™„É°„É≥„Çø„É´Â≠¶Áøí„ÄÅÈÅ©ÂøúÂà∂Âæ°</li>
<li><strong>„Ç®„ÉÉ„Ç∏„Ç≥„É≥„Éî„É•„Éº„ÉÜ„Ç£„É≥„Ç∞</strong>: ÁèæÂ†¥„Åß„ÅÆÈ´òÈÄüÊé®Ë´ñ</li>
</ul>

<h4>3. „Éó„É≠„Çª„ÇπÂà∂Âæ°„Å®„ÅÆÁµ±Âêà</h4>
<ul>
<li><strong>MPCÔºà„É¢„Éá„É´‰∫àÊ∏¨Âà∂Âæ°Ôºâ</strong>: PI„É¢„Éá„É´„ÇíÂà∂Âæ°„Å´Ê¥ªÁî®</li>
<li><strong>Âº∑ÂåñÂ≠¶Áøí</strong>: Ëá™ÂæãÁöÑ„Å™ÈÅãËª¢Êù°‰ª∂ÊúÄÈÅ©Âåñ</li>
<li><strong>„Éá„Ç∏„Çø„É´„ÉÑ„Ç§„É≥</strong>: ‰ªÆÊÉ≥„Éó„É©„É≥„Éà„Åß„ÅÆ„Ç∑„Éü„É•„É¨„Éº„Ç∑„Éß„É≥</li>
</ul>

<h4>4. Áï∞Â∏∏Ê§úÁü•„ÉªË®∫Êñ≠</h4>
<ul>
<li><strong>Áµ±Ë®àÁöÑÂ∑•Á®ãÁÆ°ÁêÜ</strong>: CUSUM„ÄÅEWMA</li>
<li><strong>Â§âÂåñÁÇπÊ§úÂá∫</strong>: „Éó„É≠„Çª„Çπ„Éâ„É™„Éï„Éà„ÅÆÊó©ÊúüÁô∫Ë¶ã</li>
<li><strong>Ê†πÊú¨ÂéüÂõ†ÂàÜÊûê</strong>: Áï∞Â∏∏Áô∫Áîü„É°„Ç´„Éã„Ç∫„É†„ÅÆËß£Êòé</li>
</ul>

<h4>5. „Ç®„É≥„Çø„Éº„Éó„É©„Ç§„Ç∫Â±ïÈñã</h4>
<ul>
<li><strong>MLOps</strong>: „É¢„Éá„É´„ÅÆ„Éê„Éº„Ç∏„Éß„É≥ÁÆ°ÁêÜ„ÄÅCI/CD</li>
<li><strong>„Çπ„Ç±„Éº„É©„Éì„É™„ÉÜ„Ç£</strong>: Ë§áÊï∞„Éó„É©„É≥„Éà„Å∏„ÅÆÊ®™Â±ïÈñã</li>
<li><strong>„Çª„Ç≠„É•„É™„ÉÜ„Ç£</strong>: „Éá„Éº„Çø„Ç¨„Éê„Éä„É≥„Çπ„ÄÅ„Ç¢„ÇØ„Çª„ÇπÂà∂Âæ°</li>
</ul>

<h3>Êé®Â•®Â≠¶Áøí„É™„ÇΩ„Éº„Çπ</h3>

<h4>Êõ∏Á±ç</h4>
<ul>
<li>„Äå„Éó„É≠„Çª„ÇπÂà∂Âæ°Â∑•Â≠¶„ÄçÔºàÂåñÂ≠¶Â∑•Â≠¶‰ºöÁ∑®Ôºâ</li>
<li>"Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow" (Aur√©lien G√©ron)</li>
<li>"Introduction to Statistical Learning" (James et al.)</li>
</ul>

<h4>„Ç™„É≥„É©„Ç§„É≥„Ç≥„Éº„Çπ</h4>
<ul>
<li>Coursera: "Machine Learning" (Andrew Ng)</li>
<li>Udacity: "Machine Learning Engineer Nanodegree"</li>
<li>Fast.ai: "Practical Deep Learning for Coders"</li>
</ul>

<h4>„Ç≥„Éü„É•„Éã„ÉÜ„Ç£„Éª„Ç´„É≥„Éï„Ç°„É¨„É≥„Çπ</h4>
<ul>
<li>PSE (Process Systems Engineering) Conference</li>
<li>IFAC DYCOPS (Dynamics and Control of Process Systems)</li>
<li>ÂåñÂ≠¶Â∑•Â≠¶‰ºö „Éó„É≠„Çª„Çπ„Ç∑„Çπ„ÉÜ„É†Â∑•Â≠¶ÈÉ®‰ºö</li>
</ul>

<h3>ÊúÄÂæå„Å´</h3>

<blockquote>
<p><strong>"Data is the new oil, but analytics is the combustion engine."</strong></p>
</blockquote>

<p>„Éó„É≠„Çª„Çπ„Éª„Ç§„É≥„Éï„Ç©„Éû„ÉÜ„Ç£„ÇØ„Çπ„ÅØ„ÄÅË£ΩÈÄ†Ê•≠„ÅÆ„Éá„Ç∏„Çø„É´Â§âÈù©„ÇíÊé®ÈÄ≤„Åô„ÇãÂº∑Âäõ„Å™ÊäÄË°ì„Åß„Åô„ÄÇÊú¨„Ç∑„É™„Éº„Ç∫„ÅßÂ≠¶„Çì„Å†Âü∫Á§é„ÇíÂúüÂè∞„Å´„ÄÅÂÆü„Éó„É©„É≥„Éà„Åß„ÅÆPI„Éó„É≠„Ç∏„Çß„ÇØ„Éà„Å´ÊåëÊà¶„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ</p>

<p><strong>ÊàêÂäü„ÅÆÈçµ</strong>:</p>
<ol>
<li><strong>Â∞è„Åï„ÅèÂßã„ÇÅ„Çã</strong>: 1„Å§„ÅÆÂìÅË≥™Â§âÊï∞„ÄÅ1„Å§„ÅÆ„Éó„É≠„Çª„Çπ„Åã„Çâ</li>
<li><strong>„Éó„É≠„Çª„Çπ„Ç®„É≥„Ç∏„Éã„Ç¢„Å®ÂçîÂäõ</strong>: „Éâ„É°„Ç§„É≥Áü•Ë≠ò„Å®„Éá„Éº„ÇøÂàÜÊûê„ÅÆËûçÂêà</li>
<li><strong>Á∂ôÁ∂öÁöÑÊîπÂñÑ</strong>: „É¢„Éá„É´„ÅØ‰Ωú„Å£„Å¶ÁµÇ„Çè„Çä„Åß„ÅØ„Å™„Åè„ÄÅËÇ≤„Å¶„Çã„ÇÇ„ÅÆ</li>
<li><strong>‰æ°ÂÄ§„ÅÆÂèØË¶ñÂåñ</strong>: ROI„ÇíÂÆöÈáèÁöÑ„Å´Á§∫„Åó„ÄÅÁµåÂñ∂Â±§„ÅÆÊîØÊåÅ„ÇíÂæó„Çã</li>
</ol>

<p>ÁöÜÊßò„ÅÆPI„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÅÆÊàêÂäü„ÇíÂøÉ„Çà„ÇäÈ°ò„Å£„Å¶„ÅÑ„Åæ„Åô„ÄÇ</p>

<div class="navigation">
    <a href="chapter-3.html" class="nav-button">‚Üê Ââç„ÅÆÁ´†</a>
    <a href="index.html" class="nav-button">„Ç∑„É™„Éº„Ç∫ÁõÆÊ¨°„Å´Êàª„Çã</a>
</div>
    </main>

    <footer>
        <p><strong>‰ΩúÊàêËÄÖ</strong>: PI Knowledge Hub Content Team</p>
        <p><strong>„Éê„Éº„Ç∏„Éß„É≥</strong>: 1.0 | <strong>‰ΩúÊàêÊó•</strong>: 2025-10-25</p>
        <p><strong>„É©„Ç§„Çª„É≥„Çπ</strong>: Creative Commons BY 4.0</p>
        <p>&copy; 2025 PI Terakoya. All rights reserved.</p>
    </footer>
</body>
</html>
