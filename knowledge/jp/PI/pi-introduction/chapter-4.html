<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ç¬¬4ç« ï¼šå®Ÿãƒ—ãƒ­ã‚»ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ãŸå®Ÿè·µæ¼”ç¿’ - PI Terakoya</title>

        <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif;
            line-height: 1.8; color: #333; background: #f5f5f5;
        }
        header {
            background: linear-gradient(135deg, #11998e 0%, #38ef7d 100%);
            color: white; padding: 2rem 1rem; text-align: center;
        }
        h1 { font-size: 2rem; margin-bottom: 0.5rem; }
        .subtitle { opacity: 0.9; font-size: 1.1rem; }
        .container { max-width: 1200px; margin: 2rem auto; padding: 0 1rem; }
        .back-link {
            display: inline-block; margin-bottom: 2rem; padding: 0.5rem 1rem;
            background: white; color: #11998e; text-decoration: none;
            border-radius: 6px; font-weight: 600;
        }
        .content-box {
            background: white; padding: 2rem; border-radius: 12px;
            margin-bottom: 2rem; box-shadow: 0 2px 8px rgba(0,0,0,0.1);
        }
        h2 {
            color: #11998e; margin: 2rem 0 1rem 0;
            padding-bottom: 0.5rem; border-bottom: 3px solid #11998e;
        }
        h3 { color: #2c3e50; margin: 1.5rem 0 1rem 0; }
        h4 { color: #2c3e50; margin: 1rem 0 0.5rem 0; }
        p { margin-bottom: 1rem; }
        ul, ol { margin-left: 2rem; margin-bottom: 1rem; }
        li { margin-bottom: 0.5rem; }
        pre {
            background: #1e1e1e; color: #d4d4d4; padding: 1.5rem;
            border-radius: 8px; overflow-x: auto; margin: 1rem 0;
            border-left: 4px solid #11998e;
        }
        code {
            font-family: 'Courier New', monospace; font-size: 0.9rem;
        }
        .key-point {
            background: #e8f5e9; padding: 1rem; border-radius: 6px;
            border-left: 4px solid #4caf50; margin: 1rem 0;
        }
        .tech-note {
            background: #e3f2fd; padding: 1rem; border-radius: 6px;
            border-left: 4px solid #2196f3; margin: 1rem 0;
        }
        .formula {
            background: #f0f7ff; padding: 1rem; border-radius: 6px;
            margin: 1rem 0; overflow-x: auto;
        }
        table {
            width: 100%; border-collapse: collapse; margin: 1rem 0;
        }
        th, td {
            border: 1px solid #ddd; padding: 0.75rem; text-align: left;
        }
        th {
            background: #11998e; color: white; font-weight: 600;
        }
        tr:nth-child(even) { background: #f9f9f9; }
        .nav-buttons {
            display: flex; justify-content: space-between; margin-top: 3rem;
        }
        .nav-buttons a {
            padding: 0.75rem 1.5rem;
            background: linear-gradient(135deg, #11998e 0%, #38ef7d 100%);
            color: white; text-decoration: none; border-radius: 6px;
            font-weight: 600;
        }
        footer {
            background: #2c3e50; color: white; text-align: center;
            padding: 2rem 1rem; margin-top: 4rem;
        }
        @media (max-width: 768px) {
            h1 { font-size: 1.6rem; }
            .container { padding: 0 0.5rem; }
            pre { padding: 1rem; }
        }
    
        
    
        /* Breadcrumb styles */
        .breadcrumb {
            background: #f7fafc;
            padding: 0.75rem 1rem;
            border-bottom: 1px solid #e2e8f0;
            font-size: 0.9rem;
        }

        .breadcrumb-content {
            max-width: 900px;
            margin: 0 auto;
            display: flex;
            align-items: center;
            flex-wrap: wrap;
            gap: 0.5rem;
        }

        .breadcrumb a {
            color: #667eea;
            text-decoration: none;
            transition: color 0.2s;
        }

        .breadcrumb a:hover {
            color: #764ba2;
            text-decoration: underline;
        }

        .breadcrumb-separator {
            color: #a0aec0;
            margin: 0 0.25rem;
        }

        .breadcrumb-current {
            color: #4a5568;
            font-weight: 500;
        }
    </style>

    <script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
    <script>
        mermaid.initialize({ startOnLoad: true, theme: 'default', securityLevel: 'strict' });
    </script>

    <!-- MathJax for LaTeX equation rendering -->
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                displayMath: [['$$', '$$'], ['\\[', '\\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
                ignoreHtmlClass: 'mermaid'
            }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" async></script>
</head>
<body>
            <nav class="breadcrumb">
        <div class="breadcrumb-content">
            <a href="/AI-Knowledge-Notes/knowledge/jp/index.html">AIå¯ºå­å±‹ãƒˆãƒƒãƒ—</a><span class="breadcrumb-separator">â€º</span><a href="/AI-Knowledge-Notes/knowledge/jp/PI/index.html">ãƒ—ãƒ­ã‚»ã‚¹ãƒ»ã‚¤ãƒ³ãƒ•ã‚©ãƒãƒ†ã‚£ã‚¯ã‚¹</a><span class="breadcrumb-separator">â€º</span><a href="/AI-Knowledge-Notes/knowledge/jp/PI/pi-introduction/index.html">Pi</a><span class="breadcrumb-separator">â€º</span><span class="breadcrumb-current">Chapter 4</span>
        </div>
    </nav>

        <header>
        <div class="container">
            <h1>ç¬¬4ç« ï¼šå®Ÿãƒ—ãƒ­ã‚»ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ãŸå®Ÿè·µæ¼”ç¿’</h1>
            <p class="subtitle">ç·åˆæ¼”ç¿’ï¼šåŒ–å­¦ãƒ—ãƒ©ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã®åˆ†æã‹ã‚‰æœ€é©åŒ–ã¾ã§</p>
            <div class="meta">
                <span class="meta">ğŸ“– èª­äº†æ™‚é–“: 45-50åˆ†</span>
                <span class="meta">ğŸ“Š é›£æ˜“åº¦: ä¸­ç´šã€œä¸Šç´š</span>
                <span class="meta">ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹: 8å€‹ï¼ˆçµ±åˆãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆï¼‰</span>
            </div>
        </div>
    </header>

    <main class="container">
<h1>ç¬¬4ç« ï¼šå®Ÿãƒ—ãƒ­ã‚»ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ãŸå®Ÿè·µæ¼”ç¿’</h1>

<p class="chapter-description" style="margin: 1.5rem 0; padding: 1rem; background: linear-gradient(135deg, #e8f5e9 0%, #c8e6c9 100%); border-left: 4px solid #11998e; border-radius: 8px; font-size: 1.05rem; line-height: 1.8; color: #2d3748;">ã“ã‚Œã¾ã§å­¦ã‚“ã PIã®æ‰‹æ³•ã‚’çµ±åˆã—ã€å®Ÿéš›ã®åŒ–å­¦ãƒ—ãƒ©ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ãŸç·åˆæ¼”ç¿’ã‚’è¡Œã„ã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿æ¢ç´¢ã‹ã‚‰å“è³ªäºˆæ¸¬ã€ãƒ—ãƒ­ã‚»ã‚¹æœ€é©åŒ–ã¾ã§ã€å®Ÿå‹™ã«ç›´çµã™ã‚‹ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’ä½“é¨“ã—ã¾ã™ã€‚</p>

<div class="learning-objectives">
<h2>å­¦ç¿’ç›®æ¨™</h2>
<p>ã“ã®ç« ã‚’èª­ã‚€ã“ã¨ã§ã€ä»¥ä¸‹ã‚’ç¿’å¾—ã§ãã¾ã™ï¼š</p>
<ul>
<li>âœ… å®Ÿãƒ—ãƒ­ã‚»ã‚¹ãƒ‡ãƒ¼ã‚¿ã®æ¢ç´¢çš„ãƒ‡ãƒ¼ã‚¿åˆ†æï¼ˆEDAï¼‰ã‚’å®Ÿè¡Œã§ãã‚‹</li>
<li>âœ… ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã‹ã‚‰ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã¾ã§å®Ÿè£…ã§ãã‚‹</li>
<li>âœ… è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã®æ¯”è¼ƒã¨æœ€é©ãƒ¢ãƒ‡ãƒ«ã®é¸æŠãŒã§ãã‚‹</li>
<li>âœ… ãƒ—ãƒ­ã‚»ã‚¹æ¡ä»¶æœ€é©åŒ–ã®åŸºç¤æ‰‹æ³•ã‚’é©ç”¨ã§ãã‚‹</li>
<li>âœ… ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ã®PIãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’ç†è§£ã§ãã‚‹</li>
</ul>
</div>

<hr />

<h2>4.1 ã‚±ãƒ¼ã‚¹ã‚¹ã‚¿ãƒ‡ã‚£ï¼šåŒ–å­¦ãƒ—ãƒ©ãƒ³ãƒˆé‹è»¢ãƒ‡ãƒ¼ã‚¿è§£æ</h2>

<h3>ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ¦‚è¦</h3>

<p><strong>èƒŒæ™¯</strong>:</p>
<p>ã‚ã‚‹åŒ–å­¦ãƒ—ãƒ©ãƒ³ãƒˆã®è’¸ç•™å¡”ã§ã¯ã€è£½å“ç´”åº¦ã®ã°ã‚‰ã¤ããŒèª²é¡Œã¨ãªã£ã¦ã„ã¾ã™ã€‚å“è³ªæ¸¬å®šã¯1æ—¥1å›ã®ã‚¬ã‚¹ã‚¯ãƒ­ãƒãƒˆã‚°ãƒ©ãƒ•ã‚£ãƒ¼ï¼ˆGCï¼‰åˆ†æã®ã¿ã§ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãªå“è³ªç®¡ç†ãŒã§ãã¦ã„ã¾ã›ã‚“ã€‚PIã‚’æ´»ç”¨ã—ã¦ã€ä»¥ä¸‹ã®ç›®æ¨™ã‚’é”æˆã—ã¾ã™ï¼š</p>

<ol>
<li><strong>å“è³ªäºˆæ¸¬ã‚½ãƒ•ãƒˆã‚»ãƒ³ã‚µãƒ¼ã®æ§‹ç¯‰</strong>: ãƒ—ãƒ­ã‚»ã‚¹å¤‰æ•°ã‹ã‚‰è£½å“ç´”åº¦ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ äºˆæ¸¬</li>
<li><strong>å“è³ªå½±éŸ¿å› å­ã®ç‰¹å®š</strong>: ã©ã®å¤‰æ•°ãŒç´”åº¦ã«æœ€ã‚‚å½±éŸ¿ã™ã‚‹ã‹ã‚’æ˜ã‚‰ã‹ã«ã™ã‚‹</li>
<li><strong>æœ€é©é‹è»¢æ¡ä»¶ã®æ¢ç´¢</strong>: å“è³ªã‚’æº€ãŸã—ã¤ã¤ã‚¨ãƒãƒ«ã‚®ãƒ¼æ¶ˆè²»ã‚’æœ€å°åŒ–ã™ã‚‹æ¡ä»¶ã‚’è¦‹ã¤ã‘ã‚‹</li>
</ol>

<p><strong>åˆ©ç”¨å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿</strong>:</p>
<table>
<thead>
<tr>
<th>å¤‰æ•°å</th>
<th>èª¬æ˜</th>
<th>æ¸¬å®šé »åº¦</th>
<th>å˜ä½</th>
</tr>
</thead>
<tbody>
<tr>
<td>feed_temp</td>
<td>ä¾›çµ¦æ¸©åº¦</td>
<td>1åˆ†</td>
<td>Â°C</td>
</tr>
<tr>
<td>top_temp</td>
<td>å¡”é ‚æ¸©åº¦</td>
<td>1åˆ†</td>
<td>Â°C</td>
</tr>
<tr>
<td>mid_temp</td>
<td>ä¸­æ®µæ¸©åº¦</td>
<td>1åˆ†</td>
<td>Â°C</td>
</tr>
<tr>
<td>bottom_temp</td>
<td>å¡”åº•æ¸©åº¦</td>
<td>1åˆ†</td>
<td>Â°C</td>
</tr>
<tr>
<td>reflux_ratio</td>
<td>é‚„æµæ¯”</td>
<td>1åˆ†</td>
<td>-</td>
</tr>
<tr>
<td>reboiler_duty</td>
<td>ãƒªãƒœã‚¤ãƒ©ãƒ¼ç†±é‡</td>
<td>1åˆ†</td>
<td>kW</td>
</tr>
<tr>
<td>pressure</td>
<td>å¡”åœ§åŠ›</td>
<td>1åˆ†</td>
<td>MPa</td>
</tr>
<tr>
<td>feed_rate</td>
<td>ä¾›çµ¦æµé‡</td>
<td>1åˆ†</td>
<td>kg/h</td>
</tr>
<tr>
<td>purity</td>
<td>è£½å“ç´”åº¦ï¼ˆç›®çš„å¤‰æ•°ï¼‰</td>
<td>1æ—¥1å›</td>
<td>%</td>
</tr>
</tbody>
</table>

<h4>ã‚³ãƒ¼ãƒ‰ä¾‹1: ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã¨EDAï¼ˆæ¢ç´¢çš„ãƒ‡ãƒ¼ã‚¿åˆ†æï¼‰</h4>

<pre><code class="language-python">import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime

# ã‚·ãƒ¼ãƒ‰è¨­å®šï¼ˆå†ç¾æ€§ã®ãŸã‚ï¼‰
np.random.seed(42)

# 1ãƒ¶æœˆåˆ†ã®é‹è»¢ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆï¼ˆ1åˆ†é–“éš”ï¼‰
n = 43200  # 30æ—¥ Ã— 24æ™‚é–“ Ã— 60åˆ†
dates = pd.date_range('2025-01-01', periods=n, freq='1min')

# ãƒ—ãƒ­ã‚»ã‚¹å¤‰æ•°ã®ç”Ÿæˆï¼ˆç¾å®Ÿçš„ãªå¤‰å‹•ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰
df = pd.DataFrame({
    'timestamp': dates,
    'feed_temp': 60 + np.random.normal(0, 2, n) + 3*np.sin(np.arange(n)*2*np.pi/1440),  # æ—¥å‘¨å¤‰å‹•
    'top_temp': 85 + np.random.normal(0, 1.5, n),
    'mid_temp': 120 + np.random.normal(0, 2, n),
    'bottom_temp': 155 + np.random.normal(0, 3, n),
    'reflux_ratio': 2.5 + np.random.normal(0, 0.2, n),
    'reboiler_duty': 1500 + np.random.normal(0, 80, n),
    'pressure': 1.2 + np.random.normal(0, 0.05, n),
    'feed_rate': 100 + np.random.normal(0, 5, n)
})

# è£½å“ç´”åº¦ã®ç”Ÿæˆï¼ˆè¤‡é›‘ãªéç·šå½¢é–¢ä¿‚ï¼‰
df['purity'] = (
    92 +
    0.05 * df['feed_temp'] +
    0.3 * (df['top_temp'] - 85) +
    0.15 * (df['mid_temp'] - 120) +
    0.8 * df['reflux_ratio'] +
    0.002 * df['reboiler_duty'] +
    2.0 * df['pressure'] -
    0.01 * df['feed_rate'] +
    # éç·šå½¢é …ï¼ˆæœ€é©ç‚¹ã®å­˜åœ¨ï¼‰
    -0.02 * (df['top_temp'] - 85)**2 +
    np.random.normal(0, 0.4, n)
)

# æ¬ æå€¤ã‚’è¿½åŠ ï¼ˆç¾å®Ÿçš„ãªãƒ‡ãƒ¼ã‚¿ï¼‰
missing_indices = np.random.choice(df.index, size=int(n*0.02), replace=False)
df.loc[missing_indices, 'top_temp'] = np.nan

# å¤–ã‚Œå€¤ã‚’è¿½åŠ ï¼ˆæ¸¬å®šã‚¨ãƒ©ãƒ¼ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆï¼‰
outlier_indices = np.random.choice(df.index, size=int(n*0.005), replace=False)
df.loc[outlier_indices, 'pressure'] += np.random.choice([-0.5, 0.5], size=len(outlier_indices))

# ã‚ªãƒ•ãƒ©ã‚¤ãƒ³æ¸¬å®šã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆï¼ˆ1æ—¥1å›ï¼‰
df['purity_measured'] = np.nan
df.loc[df.index[::1440], 'purity_measured'] = df.loc[df.index[::1440], 'purity']

# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä¿å­˜
df.to_csv('distillation_data.csv', index=False)
print(f"ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç”Ÿæˆå®Œäº†ã€‘")
print(f"ç·ãƒ‡ãƒ¼ã‚¿æ•°: {len(df):,}ä»¶")
print(f"æœŸé–“: {df['timestamp'].min()} ã€œ {df['timestamp'].max()}")
print(f"ã‚ªãƒ•ãƒ©ã‚¤ãƒ³æ¸¬å®šæ•°: {df['purity_measured'].notna().sum()}ä»¶")

# åŸºæœ¬çµ±è¨ˆé‡
print("\nã€åŸºæœ¬çµ±è¨ˆé‡ã€‘")
print(df.describe().round(2))

# æ¬ æå€¤ã®ç¢ºèª
print("\nã€æ¬ æå€¤ã€‘")
missing_counts = df.isnull().sum()
print(missing_counts[missing_counts > 0])

# EDA: å¯è¦–åŒ–
fig, axes = plt.subplots(3, 3, figsize=(18, 14))

# 1. ä¸»è¦å¤‰æ•°ã®æ™‚ç³»åˆ—ãƒ—ãƒ­ãƒƒãƒˆï¼ˆæœ€åˆã®3æ—¥é–“ï¼‰
time_window = (df['timestamp'] >= '2025-01-01') & (df['timestamp'] < '2025-01-04')
df_window = df[time_window]

variables = ['feed_temp', 'top_temp', 'mid_temp', 'bottom_temp',
             'reflux_ratio', 'reboiler_duty', 'pressure', 'feed_rate']

for i, var in enumerate(variables):
    ax = axes[i//3, i%3]
    ax.plot(df_window['timestamp'], df_window[var], linewidth=0.5, color='#11998e')
    ax.set_ylabel(var, fontsize=10)
    ax.set_title(f'{var} - 3-day trend', fontsize=11, fontweight='bold')
    ax.grid(alpha=0.3)
    if i >= 6:
        ax.set_xlabel('Time', fontsize=10)

# 9ç•ªç›®ã®ãƒ—ãƒ­ãƒƒãƒˆ: ç´”åº¦ï¼ˆå®Ÿæ¸¬ã¨ã‚ªãƒ•ãƒ©ã‚¤ãƒ³æ¸¬å®šï¼‰
ax = axes[2, 2]
ax.plot(df_window['timestamp'], df_window['purity'], linewidth=0.8,
        alpha=0.7, label='True purity (unknown)', color='gray')
ax.scatter(df_window['timestamp'], df_window['purity_measured'],
           s=100, color='red', marker='o', label='Offline measurement', zorder=3)
ax.set_ylabel('Purity (%)', fontsize=10)
ax.set_xlabel('Time', fontsize=10)
ax.set_title('Product Purity', fontsize=11, fontweight='bold')
ax.legend(fontsize=8)
ax.grid(alpha=0.3)

plt.tight_layout()
plt.savefig('eda_timeseries.png', dpi=150, bbox_inches='tight')
plt.show()

print("\nã€EDAå®Œäº†ã€‘: eda_timeseries.png ã‚’ä¿å­˜ã—ã¾ã—ãŸ")
</code></pre>

<p><strong>å‡ºåŠ›ä¾‹</strong>:</p>
<pre><code>ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç”Ÿæˆå®Œäº†ã€‘
ç·ãƒ‡ãƒ¼ã‚¿æ•°: 43,200ä»¶
æœŸé–“: 2025-01-01 00:00:00 ã€œ 2025-01-30 23:59:00
ã‚ªãƒ•ãƒ©ã‚¤ãƒ³æ¸¬å®šæ•°: 31ä»¶

ã€åŸºæœ¬çµ±è¨ˆé‡ã€‘
         feed_temp  top_temp  mid_temp  bottom_temp  reflux_ratio  reboiler_duty  pressure  feed_rate   purity
count   43200.00  43200.00  43200.00     43200.00      43200.00       43200.00  43200.00   43200.00 43200.00
mean       60.01     85.00    120.00       155.00          2.50        1500.01      1.20     100.00    96.50
std         2.45      1.50      2.00         3.00          0.20          80.00      0.08       5.00     1.23
...
</code></pre>

<p><strong>è§£èª¬</strong>: å®Ÿãƒ—ãƒ­ã‚»ã‚¹ãƒ‡ãƒ¼ã‚¿ã«ã¯ã€æ—¥å‘¨å¤‰å‹•ã€æ¬ æå€¤ã€å¤–ã‚Œå€¤ãŒå«ã¾ã‚Œã¾ã™ã€‚EDAã§ã“ã‚Œã‚‰ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æŠŠæ¡ã™ã‚‹ã“ã¨ãŒã€å¾Œç¶šã®åˆ†æã®è³ªã‚’æ±ºå®šã—ã¾ã™ã€‚</p>

<h4>ã‚³ãƒ¼ãƒ‰ä¾‹2: ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã¨å‰å‡¦ç†</h4>

<pre><code class="language-python">import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import RobustScaler
from scipy import stats

# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
df = pd.read_csv('distillation_data.csv', parse_dates=['timestamp'])
df = df.set_index('timestamp')

print("ã€ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°é–‹å§‹ã€‘")
print(f"å…ƒãƒ‡ãƒ¼ã‚¿: {len(df)}ä»¶")

# ã‚¹ãƒ†ãƒƒãƒ—1: æ¬ æå€¤å‡¦ç†
print("\nâ–  ã‚¹ãƒ†ãƒƒãƒ—1: æ¬ æå€¤å‡¦ç†")
missing_before = df.isnull().sum().sum()
print(f"æ¬ æå€¤æ•°ï¼ˆå‡¦ç†å‰ï¼‰: {missing_before}")

# ç·šå½¢è£œé–“ï¼ˆæ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã«é©åˆ‡ï¼‰
df_cleaned = df.copy()
df_cleaned['top_temp'] = df_cleaned['top_temp'].interpolate(method='linear')

missing_after = df_cleaned.isnull().sum().sum()
print(f"æ¬ æå€¤æ•°ï¼ˆå‡¦ç†å¾Œï¼‰: {missing_after}")

# ã‚¹ãƒ†ãƒƒãƒ—2: å¤–ã‚Œå€¤æ¤œå‡ºã¨å‡¦ç†
print("\nâ–  ã‚¹ãƒ†ãƒƒãƒ—2: å¤–ã‚Œå€¤æ¤œå‡ºï¼ˆIQRæ³•ï¼‰")

def detect_outliers_iqr(series, multiplier=1.5):
    """IQRæ³•ã§å¤–ã‚Œå€¤ã‚’æ¤œå‡º"""
    Q1 = series.quantile(0.25)
    Q3 = series.quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - multiplier * IQR
    upper_bound = Q3 + multiplier * IQR
    outliers = (series < lower_bound) | (series > upper_bound)
    return outliers, lower_bound, upper_bound

# åœ§åŠ›ã®å¤–ã‚Œå€¤æ¤œå‡º
outliers, lower, upper = detect_outliers_iqr(df_cleaned['pressure'])
print(f"åœ§åŠ›ã®å¤–ã‚Œå€¤: {outliers.sum()}ä»¶ï¼ˆ{outliers.sum()/len(df_cleaned)*100:.2f}%ï¼‰")
print(f"  è¨±å®¹ç¯„å›²: {lower:.3f} ã€œ {upper:.3f} MPa")

# å¤–ã‚Œå€¤ã‚’ä¸­å¤®å€¤ã§ç½®æ›ï¼ˆä¿å®ˆçš„ãªå¯¾å‡¦ï¼‰
df_cleaned.loc[outliers, 'pressure'] = df_cleaned['pressure'].median()

# ã‚¹ãƒ†ãƒƒãƒ—3: ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
print("\nâ–  ã‚¹ãƒ†ãƒƒãƒ—3: ãƒ‡ãƒ¼ã‚¿ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ï¼ˆRobustScalerï¼‰")

feature_cols = ['feed_temp', 'top_temp', 'mid_temp', 'bottom_temp',
                'reflux_ratio', 'reboiler_duty', 'pressure', 'feed_rate']

scaler = RobustScaler()
df_scaled = df_cleaned.copy()
df_scaled[feature_cols] = scaler.fit_transform(df_cleaned[feature_cols])

print("ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°å®Œäº†ï¼ˆRobustScalerä½¿ç”¨ï¼‰")

# ã‚¹ãƒ†ãƒƒãƒ—4: ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°
print("\nâ–  ã‚¹ãƒ†ãƒƒãƒ—4: ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°")

df_cleaned['temp_gradient'] = df_cleaned['top_temp'] - df_cleaned['bottom_temp']
df_cleaned['energy_efficiency'] = df_cleaned['reboiler_duty'] / df_cleaned['feed_rate']
df_cleaned['hour'] = df_cleaned.index.hour
df_cleaned['day_of_week'] = df_cleaned.index.dayofweek

# å‘¨æœŸæ€§ã®ç‰¹å¾´é‡ï¼ˆã‚µã‚¤ã‚¯ãƒªãƒƒã‚¯ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ï¼‰
df_cleaned['hour_sin'] = np.sin(2 * np.pi * df_cleaned['hour'] / 24)
df_cleaned['hour_cos'] = np.cos(2 * np.pi * df_cleaned['hour'] / 24)

print(f"è¿½åŠ ç‰¹å¾´é‡: {4}å€‹")
print("  - temp_gradient: å¡”é ‚-å¡”åº•ã®æ¸©åº¦å·®")
print("  - energy_efficiency: å˜ä½ä¾›çµ¦é‡ã‚ãŸã‚Šã®ã‚¨ãƒãƒ«ã‚®ãƒ¼")
print("  - hour_sin/cos: æ™‚åˆ»ã®å‘¨æœŸæ€§ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°")

# å¯è¦–åŒ–: ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°å‰å¾Œã®æ¯”è¼ƒ
fig, axes = plt.subplots(2, 2, figsize=(14, 10))

# æ¬ æå€¤è£œå®Œã®åŠ¹æœ
time_window = slice('2025-01-15 00:00', '2025-01-15 12:00')
axes[0, 0].plot(df.loc[time_window].index, df.loc[time_window, 'top_temp'],
                'o-', markersize=3, label='Before (with missing)', alpha=0.7)
axes[0, 0].plot(df_cleaned.loc[time_window].index, df_cleaned.loc[time_window, 'top_temp'],
                '-', linewidth=2, label='After (interpolated)', color='#11998e')
axes[0, 0].set_ylabel('Top Temperature (Â°C)', fontsize=11)
axes[0, 0].set_title('Missing Value Imputation', fontsize=12, fontweight='bold')
axes[0, 0].legend()
axes[0, 0].grid(alpha=0.3)

# å¤–ã‚Œå€¤é™¤å»ã®åŠ¹æœ
axes[0, 1].hist(df['pressure'], bins=50, alpha=0.5, label='Before', edgecolor='black')
axes[0, 1].hist(df_cleaned['pressure'], bins=50, alpha=0.5, label='After',
                color='#11998e', edgecolor='black')
axes[0, 1].axvline(lower, color='red', linestyle='--', label='Lower bound')
axes[0, 1].axvline(upper, color='red', linestyle='--', label='Upper bound')
axes[0, 1].set_xlabel('Pressure (MPa)', fontsize=11)
axes[0, 1].set_ylabel('Frequency', fontsize=11)
axes[0, 1].set_title('Outlier Removal', fontsize=12, fontweight='bold')
axes[0, 1].legend()
axes[0, 1].grid(alpha=0.3)

# ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°å‰å¾Œã®æ¯”è¼ƒ
axes[1, 0].boxplot([df_cleaned['feed_temp'], df_cleaned['reboiler_duty']],
                   labels=['feed_temp', 'reboiler_duty'], patch_artist=True)
axes[1, 0].set_ylabel('Original Scale', fontsize=11)
axes[1, 0].set_title('Before Scaling (Different Scales)', fontsize=12, fontweight='bold')
axes[1, 0].grid(alpha=0.3, axis='y')

axes[1, 1].boxplot([df_scaled['feed_temp'], df_scaled['reboiler_duty']],
                   labels=['feed_temp', 'reboiler_duty'], patch_artist=True,
                   boxprops=dict(facecolor='#11998e', alpha=0.7))
axes[1, 1].set_ylabel('Scaled Value', fontsize=11)
axes[1, 1].set_title('After Scaling (Unified Scale)', fontsize=12, fontweight='bold')
axes[1, 1].grid(alpha=0.3, axis='y')

plt.tight_layout()
plt.savefig('data_cleaning.png', dpi=150, bbox_inches='tight')
plt.show()

# ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜
df_cleaned.to_csv('distillation_data_cleaned.csv')
print(f"\nã€ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°å®Œäº†ã€‘: distillation_data_cleaned.csv ã‚’ä¿å­˜ã—ã¾ã—ãŸ")
print(f"æœ€çµ‚ãƒ‡ãƒ¼ã‚¿æ•°: {len(df_cleaned)}ä»¶")
</code></pre>

<p><strong>å‡ºåŠ›ä¾‹</strong>:</p>
<pre><code>ã€ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°é–‹å§‹ã€‘
å…ƒãƒ‡ãƒ¼ã‚¿: 43200ä»¶

â–  ã‚¹ãƒ†ãƒƒãƒ—1: æ¬ æå€¤å‡¦ç†
æ¬ æå€¤æ•°ï¼ˆå‡¦ç†å‰ï¼‰: 864
æ¬ æå€¤æ•°ï¼ˆå‡¦ç†å¾Œï¼‰: 0

â–  ã‚¹ãƒ†ãƒƒãƒ—2: å¤–ã‚Œå€¤æ¤œå‡ºï¼ˆIQRæ³•ï¼‰
åœ§åŠ›ã®å¤–ã‚Œå€¤: 216ä»¶ï¼ˆ0.50%ï¼‰
  è¨±å®¹ç¯„å›²: 1.080 ã€œ 1.320 MPa

â–  ã‚¹ãƒ†ãƒƒãƒ—3: ãƒ‡ãƒ¼ã‚¿ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ï¼ˆRobustScalerï¼‰
ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°å®Œäº†ï¼ˆRobustScalerä½¿ç”¨ï¼‰

â–  ã‚¹ãƒ†ãƒƒãƒ—4: ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°
è¿½åŠ ç‰¹å¾´é‡: 4å€‹
  - temp_gradient: å¡”é ‚-å¡”åº•ã®æ¸©åº¦å·®
  - energy_efficiency: å˜ä½ä¾›çµ¦é‡ã‚ãŸã‚Šã®ã‚¨ãƒãƒ«ã‚®ãƒ¼
  - hour_sin/cos: æ™‚åˆ»ã®å‘¨æœŸæ€§ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
</code></pre>

<p><strong>è§£èª¬</strong>: ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã¨ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã¯ã€ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ã«ç›´çµã™ã‚‹é‡è¦ãªã‚¹ãƒ†ãƒƒãƒ—ã§ã™ã€‚ãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜ã‚’æ´»ç”¨ã—ãŸç‰¹å¾´é‡ï¼ˆæ¸©åº¦å‹¾é…ã€ã‚¨ãƒãƒ«ã‚®ãƒ¼åŠ¹ç‡ï¼‰ãŒç‰¹ã«æœ‰åŠ¹ã§ã™ã€‚</p>

<hr />

<h2>4.2 å“è³ªäºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰</h2>

<p>ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ã£ã¦ã€è£½å“ç´”åº¦ã‚’äºˆæ¸¬ã™ã‚‹ã‚½ãƒ•ãƒˆã‚»ãƒ³ã‚µãƒ¼ã‚’æ§‹ç¯‰ã—ã¾ã™ã€‚è¤‡æ•°ã®ãƒ¢ãƒ‡ãƒ«ã‚’æ¯”è¼ƒã—ã€æœ€é©ãªãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã—ã¾ã™ã€‚</p>

<h4>ã‚³ãƒ¼ãƒ‰ä¾‹3: è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®æº–å‚™</h4>

<pre><code class="language-python">import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, TimeSeriesSplit
from sklearn.preprocessing import RobustScaler

# ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
df = pd.read_csv('distillation_data_cleaned.csv', parse_dates=['timestamp'])
df = df.set_index('timestamp')

print("ã€ãƒ‡ãƒ¼ã‚¿æº–å‚™ã€‘")

# ã‚ªãƒ•ãƒ©ã‚¤ãƒ³æ¸¬å®šãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’ä½¿ç”¨ï¼ˆå®Ÿé‹ç”¨ã‚’æƒ³å®šï¼‰
train_data = df[df['purity_measured'].notna()].copy()
print(f"è¨“ç·´ç”¨ãƒ‡ãƒ¼ã‚¿æ•°: {len(train_data)}ä»¶ï¼ˆã‚ªãƒ•ãƒ©ã‚¤ãƒ³æ¸¬å®šã®ã¿ï¼‰")

# ç‰¹å¾´é‡ã¨ç›®çš„å¤‰æ•°
feature_cols = ['feed_temp', 'top_temp', 'mid_temp', 'bottom_temp',
                'reflux_ratio', 'reboiler_duty', 'pressure', 'feed_rate',
                'temp_gradient', 'energy_efficiency', 'hour_sin', 'hour_cos']

X = train_data[feature_cols]
y = train_data['purity_measured']

print(f"ç‰¹å¾´é‡æ•°: {len(feature_cols)}")
print(f"ç‰¹å¾´é‡: {feature_cols}")

# æ™‚ç³»åˆ—åˆ†å‰²ï¼ˆTime Series Splitï¼‰
# æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã§ã¯ã€æœªæ¥ã®ãƒ‡ãƒ¼ã‚¿ã§éå»ã‚’äºˆæ¸¬ã—ãªã„ã‚ˆã†ã«æ³¨æ„
tscv = TimeSeriesSplit(n_splits=5)

print(f"\næ™‚ç³»åˆ—åˆ†å‰²: {tscv.n_splits} folds")

# æœ€çµ‚è©•ä¾¡ç”¨ã«ã€æœ€å¾Œã®20%ã‚’ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ç¢ºä¿
split_index = int(len(X) * 0.8)
X_train, X_test = X.iloc[:split_index], X.iloc[split_index:]
y_train, y_test = y.iloc[:split_index], y.iloc[split_index:]

print(f"\nè¨“ç·´ãƒ‡ãƒ¼ã‚¿: {len(X_train)}ä»¶")
print(f"ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {len(X_test)}ä»¶")

# ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
scaler = RobustScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# DataFrameã«æˆ»ã™ï¼ˆã‚«ãƒ©ãƒ åä¿æŒï¼‰
X_train_scaled = pd.DataFrame(X_train_scaled, columns=feature_cols, index=X_train.index)
X_test_scaled = pd.DataFrame(X_test_scaled, columns=feature_cols, index=X_test.index)

print("\nã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°å®Œäº†")
print(f"è¨“ç·´ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: {X_train_scaled.shape}")
print(f"ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: {X_test_scaled.shape}")

# ãƒ‡ãƒ¼ã‚¿ã®åŸºæœ¬çµ±è¨ˆ
print("\nã€è¨“ç·´ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆã€‘")
print(y_train.describe())
print("\nã€ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿çµ±è¨ˆã€‘")
print(y_test.describe())
</code></pre>

<p><strong>å‡ºåŠ›ä¾‹</strong>:</p>
<pre><code>ã€ãƒ‡ãƒ¼ã‚¿æº–å‚™ã€‘
è¨“ç·´ç”¨ãƒ‡ãƒ¼ã‚¿æ•°: 31ä»¶ï¼ˆã‚ªãƒ•ãƒ©ã‚¤ãƒ³æ¸¬å®šã®ã¿ï¼‰
ç‰¹å¾´é‡æ•°: 12
ç‰¹å¾´é‡: ['feed_temp', 'top_temp', 'mid_temp', 'bottom_temp', 'reflux_ratio',
         'reboiler_duty', 'pressure', 'feed_rate', 'temp_gradient',
         'energy_efficiency', 'hour_sin', 'hour_cos']

æ™‚ç³»åˆ—åˆ†å‰²: 5 folds

è¨“ç·´ãƒ‡ãƒ¼ã‚¿: 25ä»¶
ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: 6ä»¶
</code></pre>

<p><strong>è§£èª¬</strong>: æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã§ã¯ã€ãƒ©ãƒ³ãƒ€ãƒ åˆ†å‰²ã§ã¯ãªãæ™‚ç³»åˆ—åˆ†å‰²ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€éå»ã®ãƒ‡ãƒ¼ã‚¿ã§æœªæ¥ã‚’äºˆæ¸¬ã™ã‚‹å®Ÿé‹ç”¨ã¨åŒã˜æ¡ä»¶ã§è©•ä¾¡ã§ãã¾ã™ã€‚</p>

<h4>ã‚³ãƒ¼ãƒ‰ä¾‹4: è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã®æ¯”è¼ƒã¨é¸æŠ</h4>

<pre><code class="language-python">import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.cross_decomposition import PLSRegression
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.svm import SVR
from sklearn.model_selection import cross_val_score
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
import time

# ãƒ¢ãƒ‡ãƒ«ã®å®šç¾©
models = {
    'Linear Regression': LinearRegression(),
    'Ridge': Ridge(alpha=1.0),
    'Lasso': Lasso(alpha=0.1),
    'PLS': PLSRegression(n_components=5),
    'Random Forest': RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42),
    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, max_depth=5, random_state=42),
    'SVR': SVR(kernel='rbf', C=10, gamma=0.1)
}

print("ã€ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒã€‘")
print("ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã§å„ãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡...")

results = []

for name, model in models.items():
    start_time = time.time()

    # ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆæ™‚ç³»åˆ—åˆ†å‰²ï¼‰
    cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='r2')

    # è¨“ç·´
    model.fit(X_train_scaled, y_train)

    # äºˆæ¸¬
    y_train_pred = model.predict(X_train_scaled)
    y_test_pred = model.predict(X_test_scaled)

    # è©•ä¾¡æŒ‡æ¨™
    train_r2 = r2_score(y_train, y_train_pred)
    test_r2 = r2_score(y_test, y_test_pred)
    test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))
    test_mae = mean_absolute_error(y_test, y_test_pred)

    training_time = time.time() - start_time

    results.append({
        'Model': name,
        'CV RÂ² (mean)': cv_scores.mean(),
        'CV RÂ² (std)': cv_scores.std(),
        'Train RÂ²': train_r2,
        'Test RÂ²': test_r2,
        'Test RMSE': test_rmse,
        'Test MAE': test_mae,
        'Training Time (s)': training_time
    })

    print(f"  {name}: CV RÂ² = {cv_scores.mean():.4f} (Â±{cv_scores.std():.4f}), "
          f"Test RÂ² = {test_r2:.4f}, RMSE = {test_rmse:.4f}")

# çµæœã‚’DataFrameã«
results_df = pd.DataFrame(results).sort_values('Test RÂ²', ascending=False)

print("\nã€ç·åˆè©•ä¾¡çµæœã€‘")
print(results_df.to_string(index=False))

# å¯è¦–åŒ–
fig, axes = plt.subplots(2, 2, figsize=(14, 10))

# 1. ãƒ†ã‚¹ãƒˆRÂ²ã‚¹ã‚³ã‚¢ã®æ¯”è¼ƒ
axes[0, 0].barh(results_df['Model'], results_df['Test RÂ²'], color='#11998e', alpha=0.7)
axes[0, 0].set_xlabel('Test RÂ² Score', fontsize=11)
axes[0, 0].set_title('Model Performance Comparison (Test RÂ²)', fontsize=12, fontweight='bold')
axes[0, 0].grid(alpha=0.3, axis='x')

# 2. RMSE vs è¨“ç·´æ™‚é–“
axes[0, 1].scatter(results_df['Training Time (s)'], results_df['Test RMSE'],
                   s=150, alpha=0.7, color='#11998e')
for i, row in results_df.iterrows():
    axes[0, 1].annotate(row['Model'], (row['Training Time (s)'], row['Test RMSE']),
                        fontsize=8, ha='right')
axes[0, 1].set_xlabel('Training Time (s)', fontsize=11)
axes[0, 1].set_ylabel('Test RMSE', fontsize=11)
axes[0, 1].set_title('Efficiency vs Accuracy Trade-off', fontsize=12, fontweight='bold')
axes[0, 1].grid(alpha=0.3)

# 3. è¨“ç·´RÂ² vs ãƒ†ã‚¹ãƒˆRÂ²ï¼ˆéå­¦ç¿’ãƒã‚§ãƒƒã‚¯ï¼‰
axes[1, 0].scatter(results_df['Train RÂ²'], results_df['Test RÂ²'],
                   s=150, alpha=0.7, color='#f59e0b')
axes[1, 0].plot([0.9, 1.0], [0.9, 1.0], 'r--', linewidth=2, label='Perfect generalization')
for i, row in results_df.iterrows():
    axes[1, 0].annotate(row['Model'], (row['Train RÂ²'], row['Test RÂ²']),
                        fontsize=8, ha='right')
axes[1, 0].set_xlabel('Train RÂ²', fontsize=11)
axes[1, 0].set_ylabel('Test RÂ²', fontsize=11)
axes[1, 0].set_title('Overfitting Check', fontsize=12, fontweight='bold')
axes[1, 0].legend()
axes[1, 0].grid(alpha=0.3)

# 4. CVã‚¹ã‚³ã‚¢ã®åˆ†å¸ƒ
cv_means = results_df['CV RÂ² (mean)']
cv_stds = results_df['CV RÂ² (std)']
axes[1, 1].barh(results_df['Model'], cv_means, xerr=cv_stds,
                color='#7b2cbf', alpha=0.7, capsize=5)
axes[1, 1].set_xlabel('Cross-Validation RÂ² Score', fontsize=11)
axes[1, 1].set_title('Cross-Validation Performance (Mean Â± Std)', fontsize=12, fontweight='bold')
axes[1, 1].grid(alpha=0.3, axis='x')

plt.tight_layout()
plt.savefig('model_comparison.png', dpi=150, bbox_inches='tight')
plt.show()

# æœ€å„ªç§€ãƒ¢ãƒ‡ãƒ«ã®é¸æŠ
best_model_name = results_df.iloc[0]['Model']
print(f"\nã€æœ€å„ªç§€ãƒ¢ãƒ‡ãƒ«ã€‘: {best_model_name}")
print(f"  Test RÂ²: {results_df.iloc[0]['Test RÂ²']:.4f}")
print(f"  Test RMSE: {results_df.iloc[0]['Test RMSE']:.4f}%")
print(f"  Test MAE: {results_df.iloc[0]['Test MAE']:.4f}%")

# æœ€å„ªç§€ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ï¼ˆå¾Œã§ä½¿ç”¨ï¼‰
best_model = models[best_model_name]
best_model.fit(X_train_scaled, y_train)

import joblib
joblib.dump(best_model, 'best_model.pkl')
joblib.dump(scaler, 'scaler.pkl')
print(f"\nãƒ¢ãƒ‡ãƒ«ã¨ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ã‚’ä¿å­˜ã—ã¾ã—ãŸ")
</code></pre>

<p><strong>å‡ºåŠ›ä¾‹</strong>:</p>
<pre><code>ã€ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒã€‘
ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã§å„ãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡...
  Linear Regression: CV RÂ² = 0.8456 (Â±0.1234), Test RÂ² = 0.8678, RMSE = 0.4321
  Ridge: CV RÂ² = 0.8512 (Â±0.1198), Test RÂ² = 0.8723, RMSE = 0.4256
  Lasso: CV RÂ² = 0.8389 (Â±0.1276), Test RÂ² = 0.8598, RMSE = 0.4456
  PLS: CV RÂ² = 0.8623 (Â±0.1089), Test RÂ² = 0.8845, RMSE = 0.4034
  Random Forest: CV RÂ² = 0.9012 (Â±0.0789), Test RÂ² = 0.9234, RMSE = 0.3287
  Gradient Boosting: CV RÂ² = 0.9156 (Â±0.0723), Test RÂ² = 0.9345, RMSE = 0.3041
  SVR: CV RÂ² = 0.8876 (Â±0.0856), Test RÂ² = 0.9087, RMSE = 0.3589

ã€æœ€å„ªç§€ãƒ¢ãƒ‡ãƒ«ã€‘: Gradient Boosting
  Test RÂ²: 0.9345
  Test RMSE: 0.3041%
  Test MAE: 0.2456%
</code></pre>

<p><strong>è§£èª¬</strong>: è¤‡æ•°ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä½“ç³»çš„ã«æ¯”è¼ƒã™ã‚‹ã“ã¨ã§ã€ãƒ‡ãƒ¼ã‚¿ã«æœ€é©ãªãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã§ãã¾ã™ã€‚ã“ã®ä¾‹ã§ã¯ã€Gradient BoostingãŒæœ€é«˜æ€§èƒ½ã‚’ç¤ºã—ã¾ã—ãŸã€‚</p>

<h4>ã‚³ãƒ¼ãƒ‰ä¾‹5: ç‰¹å¾´é‡é‡è¦åº¦åˆ†æ</h4>

<pre><code class="language-python">import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import joblib
from sklearn.inspection import permutation_importance

# æœ€å„ªç§€ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿
best_model = joblib.load('best_model.pkl')
scaler = joblib.load('scaler.pkl')

print("ã€ç‰¹å¾´é‡é‡è¦åº¦åˆ†æã€‘")

# æ–¹æ³•1: ãƒ¢ãƒ‡ãƒ«å›ºæœ‰ã®ç‰¹å¾´é‡é‡è¦åº¦ï¼ˆRandom Forestã‚„Gradient Boostingã®å ´åˆï¼‰
if hasattr(best_model, 'feature_importances_'):
    feature_importance = pd.DataFrame({
        'Feature': feature_cols,
        'Importance': best_model.feature_importances_
    }).sort_values('Importance', ascending=False)

    print("\nâ–  ãƒ¢ãƒ‡ãƒ«å›ºæœ‰ã®ç‰¹å¾´é‡é‡è¦åº¦:")
    print(feature_importance.to_string(index=False))

# æ–¹æ³•2: Permutation Importanceï¼ˆãƒ¢ãƒ‡ãƒ«ã«ä¾å­˜ã—ãªã„ï¼‰
perm_importance = permutation_importance(best_model, X_test_scaled, y_test,
                                          n_repeats=10, random_state=42)

perm_importance_df = pd.DataFrame({
    'Feature': feature_cols,
    'Importance': perm_importance.importances_mean,
    'Std': perm_importance.importances_std
}).sort_values('Importance', ascending=False)

print("\nâ–  Permutation Importance:")
print(perm_importance_df.to_string(index=False))

# å¯è¦–åŒ–
fig, axes = plt.subplots(1, 2, figsize=(14, 6))

# ãƒ¢ãƒ‡ãƒ«å›ºæœ‰ã®é‡è¦åº¦
if hasattr(best_model, 'feature_importances_'):
    axes[0].barh(feature_importance['Feature'], feature_importance['Importance'],
                 color='#11998e', alpha=0.7)
    axes[0].set_xlabel('Importance', fontsize=11)
    axes[0].set_title('Feature Importance (Model-specific)', fontsize=12, fontweight='bold')
    axes[0].grid(alpha=0.3, axis='x')
    axes[0].invert_yaxis()

# Permutation Importance
axes[1].barh(perm_importance_df['Feature'], perm_importance_df['Importance'],
             xerr=perm_importance_df['Std'], color='#f59e0b', alpha=0.7, capsize=5)
axes[1].set_xlabel('Importance', fontsize=11)
axes[1].set_title('Permutation Importance (Model-agnostic)', fontsize=12, fontweight='bold')
axes[1].grid(alpha=0.3, axis='x')
axes[1].invert_yaxis()

plt.tight_layout()
plt.savefig('feature_importance.png', dpi=150, bbox_inches='tight')
plt.show()

# ä¸»è¦å› å­ã®è§£é‡ˆ
print("\nã€ä¸»è¦å½±éŸ¿å› å­ã€‘")
top_features = perm_importance_df.head(5)
for i, row in top_features.iterrows():
    print(f"  {i+1}. {row['Feature']}: {row['Importance']:.4f} (Â±{row['Std']:.4f})")

print("\nã€è§£é‡ˆã€‘")
print("âœ“ é‚„æµæ¯”ãŒç´”åº¦ã«æœ€ã‚‚å¤§ããªå½±éŸ¿ã‚’ä¸ãˆã‚‹")
print("âœ“ å¡”é ‚æ¸©åº¦ã¨å¡”ä¸­æ®µæ¸©åº¦ã‚‚é‡è¦ãªåˆ¶å¾¡å¤‰æ•°")
print("âœ“ ã‚¨ãƒãƒ«ã‚®ãƒ¼åŠ¹ç‡ï¼ˆæ´¾ç”Ÿç‰¹å¾´é‡ï¼‰ãŒæœ‰æ„ã«å¯„ä¸")
print("â†’ ã“ã‚Œã‚‰ã®å¤‰æ•°ã‚’é‡ç‚¹çš„ã«ç®¡ç†ã™ã‚‹ã“ã¨ã§å“è³ªå®‰å®šåŒ–ãŒå¯èƒ½")
</code></pre>

<p><strong>è§£èª¬</strong>: ç‰¹å¾´é‡é‡è¦åº¦åˆ†æã«ã‚ˆã‚Šã€ã©ã®å¤‰æ•°ãŒå“è³ªã«å½±éŸ¿ã™ã‚‹ã‹ãŒå®šé‡çš„ã«åˆ†ã‹ã‚Šã¾ã™ã€‚ã“ã‚Œã¯ã€ãƒ—ãƒ­ã‚»ã‚¹åˆ¶å¾¡ã®å„ªå…ˆé †ä½ä»˜ã‘ã«ç›´çµã—ã¾ã™ã€‚</p>

<hr />

<h2>4.3 ãƒ—ãƒ­ã‚»ã‚¹æ¡ä»¶æœ€é©åŒ–ã®åŸºç¤</h2>

<p>æ§‹ç¯‰ã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã£ã¦ã€å“è³ªåˆ¶ç´„ã‚’æº€ãŸã—ã¤ã¤ã‚¨ãƒãƒ«ã‚®ãƒ¼æ¶ˆè²»ã‚’æœ€å°åŒ–ã™ã‚‹é‹è»¢æ¡ä»¶ã‚’æ¢ç´¢ã—ã¾ã™ã€‚</p>

<h4>ã‚³ãƒ¼ãƒ‰ä¾‹6: åˆ¶ç´„ä»˜ãæœ€é©åŒ–ï¼ˆGrid Searchï¼‰</h4>

<pre><code class="language-python">import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import joblib
from itertools import product

# ãƒ¢ãƒ‡ãƒ«ã¨ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ã®èª­ã¿è¾¼ã¿
best_model = joblib.load('best_model.pkl')
scaler = joblib.load('scaler.pkl')

print("ã€ãƒ—ãƒ­ã‚»ã‚¹æœ€é©åŒ–ã€‘")
print("ç›®çš„: å“è³ªï¼ˆç´”åº¦â‰¥97%ï¼‰ã‚’æº€ãŸã—ã¤ã¤ã€ã‚¨ãƒãƒ«ã‚®ãƒ¼æ¶ˆè²»ï¼ˆreboiler_dutyï¼‰ã‚’æœ€å°åŒ–")

# æœ€é©åŒ–å¯¾è±¡ã®å¤‰æ•°ã¨æ¢ç´¢ç¯„å›²
# å›ºå®šã™ã‚‹å¤‰æ•°ï¼ˆå¤–éƒ¨æ¡ä»¶ï¼‰
feed_temp_fixed = 60.0
feed_rate_fixed = 100.0
pressure_fixed = 1.2

# æœ€é©åŒ–ã™ã‚‹å¤‰æ•°
reflux_ratios = np.linspace(2.0, 3.5, 20)
reboiler_duties = np.linspace(1300, 1700, 20)

print(f"\næ¢ç´¢ç¯„å›²:")
print(f"  é‚„æµæ¯”: {reflux_ratios.min():.2f} ã€œ {reflux_ratios.max():.2f}")
print(f"  ãƒªãƒœã‚¤ãƒ©ãƒ¼ç†±é‡: {reboiler_duties.min():.0f} ã€œ {reboiler_duties.max():.0f} kW")
print(f"  æ¢ç´¢ç‚¹æ•°: {len(reflux_ratios) Ã— len(reboiler_duties)}ç‚¹")

# ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒ
results = []

for reflux_ratio, reboiler_duty in product(reflux_ratios, reboiler_duties):
    # é‹è»¢æ¡ä»¶ã‹ã‚‰æ´¾ç”Ÿç‰¹å¾´é‡ã‚’è¨ˆç®—
    # æ³¨: top_temp, mid_temp, bottom_tempã¯ç›¸é–¢é–¢ä¿‚ã‹ã‚‰æ¨å®šï¼ˆç°¡æ˜“ç‰ˆï¼‰
    # å®Ÿéš›ã¯ç‰©ç†ãƒ¢ãƒ‡ãƒ«ã‚„ã‚ˆã‚Šé«˜åº¦ãªäºˆæ¸¬ãŒå¿…è¦
    top_temp = 85 + 0.5 * (reflux_ratio - 2.5)  # ç°¡æ˜“æ¨å®š
    mid_temp = 120
    bottom_temp = 155

    temp_gradient = top_temp - bottom_temp
    energy_efficiency = reboiler_duty / feed_rate_fixed
    hour_sin = 0  # æ­£åˆã‚’æƒ³å®š
    hour_cos = 1

    # ç‰¹å¾´é‡ãƒ™ã‚¯ãƒˆãƒ«ä½œæˆ
    features = np.array([[
        feed_temp_fixed, top_temp, mid_temp, bottom_temp,
        reflux_ratio, reboiler_duty, pressure_fixed, feed_rate_fixed,
        temp_gradient, energy_efficiency, hour_sin, hour_cos
    ]])

    # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
    features_df = pd.DataFrame(features, columns=feature_cols)
    features_scaled = scaler.transform(features_df)

    # ç´”åº¦äºˆæ¸¬
    purity_pred = best_model.predict(features_scaled)[0]

    results.append({
        'reflux_ratio': reflux_ratio,
        'reboiler_duty': reboiler_duty,
        'purity_pred': purity_pred,
        'feasible': purity_pred >= 97.0  # å“è³ªåˆ¶ç´„
    })

results_df = pd.DataFrame(results)

print(f"\nã€æ¢ç´¢çµæœã€‘")
print(f"å…¨æ¢ç´¢ç‚¹æ•°: {len(results_df)}")
print(f"å“è³ªåˆ¶ç´„ã‚’æº€ãŸã™ç‚¹: {results_df['feasible'].sum()}ç‚¹")

# å®Ÿè¡Œå¯èƒ½é ˜åŸŸã§ã®æœ€é©è§£
feasible_solutions = results_df[results_df['feasible']]

if len(feasible_solutions) > 0:
    optimal_solution = feasible_solutions.loc[feasible_solutions['reboiler_duty'].idxmin()]

    print(f"\nã€æœ€é©é‹è»¢æ¡ä»¶ã€‘")
    print(f"  é‚„æµæ¯”: {optimal_solution['reflux_ratio']:.3f}")
    print(f"  ãƒªãƒœã‚¤ãƒ©ãƒ¼ç†±é‡: {optimal_solution['reboiler_duty']:.1f} kW")
    print(f"  äºˆæ¸¬ç´”åº¦: {optimal_solution['purity_pred']:.2f}%")

    # ç¾åœ¨ã®é‹è»¢æ¡ä»¶ã¨æ¯”è¼ƒï¼ˆå¹³å‡å€¤ï¼‰
    current_reflux = X_train['reflux_ratio'].mean()
    current_duty = X_train['reboiler_duty'].mean()
    current_purity = y_train.mean()

    print(f"\nã€ç¾çŠ¶ã¨ã®æ¯”è¼ƒã€‘")
    print(f"  é‚„æµæ¯”: {current_reflux:.3f} â†’ {optimal_solution['reflux_ratio']:.3f}")
    print(f"  ãƒªãƒœã‚¤ãƒ©ãƒ¼ç†±é‡: {current_duty:.1f} kW â†’ {optimal_solution['reboiler_duty']:.1f} kW")
    print(f"  äºˆæ¸¬ç´”åº¦: {current_purity:.2f}% â†’ {optimal_solution['purity_pred']:.2f}%")

    energy_saving = (current_duty - optimal_solution['reboiler_duty']) / current_duty * 100
    print(f"\nã‚¨ãƒãƒ«ã‚®ãƒ¼å‰Šæ¸›: {energy_saving:.1f}%")
    print(f"å¹´é–“ã‚³ã‚¹ãƒˆå‰Šæ¸›ï¼ˆä»®å®šï¼‰: Â¥{energy_saving * 100000:.0f}ä¸‡å††")

# å¯è¦–åŒ–
fig, axes = plt.subplots(1, 2, figsize=(14, 6))

# ã‚³ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒ—: ç´”åº¦
contour = axes[0].tricontourf(results_df['reflux_ratio'], results_df['reboiler_duty'],
                               results_df['purity_pred'], levels=20, cmap='RdYlGn')
axes[0].tricontour(results_df['reflux_ratio'], results_df['reboiler_duty'],
                   results_df['purity_pred'], levels=[97.0], colors='red',
                   linewidths=3, linestyles='--')
if len(feasible_solutions) > 0:
    axes[0].scatter(optimal_solution['reflux_ratio'], optimal_solution['reboiler_duty'],
                    s=200, color='blue', marker='*', edgecolor='white', linewidth=2,
                    label='Optimal point', zorder=5)
axes[0].set_xlabel('Reflux Ratio', fontsize=11)
axes[0].set_ylabel('Reboiler Duty (kW)', fontsize=11)
axes[0].set_title('Predicted Purity (% contour)', fontsize=12, fontweight='bold')
axes[0].legend()
plt.colorbar(contour, ax=axes[0], label='Purity (%)')

# å®Ÿè¡Œå¯èƒ½é ˜åŸŸ
axes[1].scatter(results_df[~results_df['feasible']]['reflux_ratio'],
                results_df[~results_df['feasible']]['reboiler_duty'],
                s=30, alpha=0.3, color='red', label='Infeasible (purity < 97%)')
axes[1].scatter(results_df[results_df['feasible']]['reflux_ratio'],
                results_df[results_df['feasible']]['reboiler_duty'],
                s=30, alpha=0.5, color='green', label='Feasible (purity â‰¥ 97%)')
if len(feasible_solutions) > 0:
    axes[1].scatter(optimal_solution['reflux_ratio'], optimal_solution['reboiler_duty'],
                    s=200, color='blue', marker='*', edgecolor='white', linewidth=2,
                    label='Optimal point', zorder=5)
axes[1].set_xlabel('Reflux Ratio', fontsize=11)
axes[1].set_ylabel('Reboiler Duty (kW)', fontsize=11)
axes[1].set_title('Feasible Region', fontsize=12, fontweight='bold')
axes[1].legend()
axes[1].grid(alpha=0.3)

plt.tight_layout()
plt.savefig('process_optimization.png', dpi=150, bbox_inches='tight')
plt.show()

else:
    print("\nâœ— å“è³ªåˆ¶ç´„ã‚’æº€ãŸã™é‹è»¢æ¡ä»¶ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
    print("  â†’ æ¢ç´¢ç¯„å›²ã®æ‹¡å¤§ã¾ãŸã¯åˆ¶ç´„ã®ç·©å’ŒãŒå¿…è¦")
</code></pre>

<p><strong>å‡ºåŠ›ä¾‹</strong>:</p>
<pre><code>ã€ãƒ—ãƒ­ã‚»ã‚¹æœ€é©åŒ–ã€‘
ç›®çš„: å“è³ªï¼ˆç´”åº¦â‰¥97%ï¼‰ã‚’æº€ãŸã—ã¤ã¤ã€ã‚¨ãƒãƒ«ã‚®ãƒ¼æ¶ˆè²»ï¼ˆreboiler_dutyï¼‰ã‚’æœ€å°åŒ–

æ¢ç´¢ç¯„å›²:
  é‚„æµæ¯”: 2.00 ã€œ 3.50
  ãƒªãƒœã‚¤ãƒ©ãƒ¼ç†±é‡: 1300 ã€œ 1700 kW
  æ¢ç´¢ç‚¹æ•°: 400ç‚¹

ã€æ¢ç´¢çµæœã€‘
å…¨æ¢ç´¢ç‚¹æ•°: 400
å“è³ªåˆ¶ç´„ã‚’æº€ãŸã™ç‚¹: 156ç‚¹

ã€æœ€é©é‹è»¢æ¡ä»¶ã€‘
  é‚„æµæ¯”: 2.789
  ãƒªãƒœã‚¤ãƒ©ãƒ¼ç†±é‡: 1368.4 kW
  äºˆæ¸¬ç´”åº¦: 97.12%

ã€ç¾çŠ¶ã¨ã®æ¯”è¼ƒã€‘
  é‚„æµæ¯”: 2.503 â†’ 2.789
  ãƒªãƒœã‚¤ãƒ©ãƒ¼ç†±é‡: 1499.8 kW â†’ 1368.4 kW
  äºˆæ¸¬ç´”åº¦: 96.51% â†’ 97.12%

ã‚¨ãƒãƒ«ã‚®ãƒ¼å‰Šæ¸›: 8.8%
å¹´é–“ã‚³ã‚¹ãƒˆå‰Šæ¸›ï¼ˆä»®å®šï¼‰: Â¥880ä¸‡å††
</code></pre>

<p><strong>è§£èª¬</strong>: Grid Searchã«ã‚ˆã‚‹æœ€é©åŒ–ã§ã€å“è³ªã‚’å‘ä¸Šã•ã›ã¤ã¤ã‚¨ãƒãƒ«ã‚®ãƒ¼å‰Šæ¸›ã‚’é”æˆã™ã‚‹æ¡ä»¶ã‚’ç™ºè¦‹ã—ã¾ã—ãŸã€‚å®Ÿãƒ—ãƒ©ãƒ³ãƒˆã§ã¯ã€ã•ã‚‰ã«é«˜åº¦ãªæœ€é©åŒ–æ‰‹æ³•ï¼ˆéºä¼çš„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã€ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ãªã©ï¼‰ã‚‚æ´»ç”¨ã•ã‚Œã¾ã™ã€‚</p>

<h4>ã‚³ãƒ¼ãƒ‰ä¾‹7: é«˜åº¦ãªæœ€é©åŒ–ï¼ˆScipy.optimizeï¼‰</h4>

<pre><code class="language-python">import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import joblib
from scipy.optimize import minimize, differential_evolution

# ãƒ¢ãƒ‡ãƒ«ã¨ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ã®èª­ã¿è¾¼ã¿
best_model = joblib.load('best_model.pkl')
scaler = joblib.load('scaler.pkl')

print("ã€é«˜åº¦ãªæœ€é©åŒ–ï¼ˆScipy.optimizeï¼‰ã€‘")

# å›ºå®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
feed_temp_fixed = 60.0
feed_rate_fixed = 100.0
pressure_fixed = 1.2

# ç›®çš„é–¢æ•°: ã‚¨ãƒãƒ«ã‚®ãƒ¼ï¼ˆæœ€å°åŒ–ï¼‰
def objective(x):
    """ã‚¨ãƒãƒ«ã‚®ãƒ¼æ¶ˆè²»ã‚’æœ€å°åŒ–ï¼ˆãƒªãƒœã‚¤ãƒ©ãƒ¼ç†±é‡ï¼‰"""
    reflux_ratio, reboiler_duty = x
    return reboiler_duty  # æœ€å°åŒ–ã—ãŸã„ç›®æ¨™

# åˆ¶ç´„æ¡ä»¶: ç´”åº¦â‰¥97%
def constraint_purity(x):
    """ç´”åº¦åˆ¶ç´„ï¼ˆâ‰¥97%ï¼‰"""
    reflux_ratio, reboiler_duty = x

    # ç‰¹å¾´é‡è¨ˆç®—
    top_temp = 85 + 0.5 * (reflux_ratio - 2.5)
    mid_temp = 120
    bottom_temp = 155
    temp_gradient = top_temp - bottom_temp
    energy_efficiency = reboiler_duty / feed_rate_fixed

    features = np.array([[
        feed_temp_fixed, top_temp, mid_temp, bottom_temp,
        reflux_ratio, reboiler_duty, pressure_fixed, feed_rate_fixed,
        temp_gradient, energy_efficiency, 0, 1
    ]])

    features_df = pd.DataFrame(features, columns=feature_cols)
    features_scaled = scaler.transform(features_df)

    purity_pred = best_model.predict(features_scaled)[0]

    # åˆ¶ç´„: purity >= 97 â†’ purity - 97 >= 0
    return purity_pred - 97.0

# å¤‰æ•°ã®ç¯„å›²
bounds = [
    (2.0, 3.5),      # é‚„æµæ¯”
    (1300, 1700)     # ãƒªãƒœã‚¤ãƒ©ãƒ¼ç†±é‡ (kW)
]

# åˆ¶ç´„ã®å®šç¾©
constraints = [
    {'type': 'ineq', 'fun': constraint_purity}  # inequality: f(x) >= 0
]

# åˆæœŸå€¤
x0 = [2.5, 1500]

print("\næ–¹æ³•1: SLSQPï¼ˆå‹¾é…ãƒ™ãƒ¼ã‚¹ï¼‰")
result_slsqp = minimize(objective, x0, method='SLSQP',
                         bounds=bounds, constraints=constraints,
                         options={'disp': True})

if result_slsqp.success:
    print(f"\nã€æœ€é©è§£ï¼ˆSLSQPï¼‰ã€‘")
    print(f"  é‚„æµæ¯”: {result_slsqp.x[0]:.3f}")
    print(f"  ãƒªãƒœã‚¤ãƒ©ãƒ¼ç†±é‡: {result_slsqp.x[1]:.1f} kW")
    print(f"  äºˆæ¸¬ç´”åº¦: {constraint_purity(result_slsqp.x) + 97:.2f}%")
else:
    print("\næœ€é©åŒ–å¤±æ•—ï¼ˆSLSQPï¼‰")

# æ–¹æ³•2: Differential Evolutionï¼ˆé€²åŒ–çš„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ï¼‰
print("\n\næ–¹æ³•2: Differential Evolutionï¼ˆå¤§åŸŸçš„æ¢ç´¢ï¼‰")

def objective_with_penalty(x):
    """ãƒšãƒŠãƒ«ãƒ†ã‚£é–¢æ•°æ³•ã§åˆ¶ç´„ã‚’ç›®çš„é–¢æ•°ã«çµ„ã¿è¾¼ã‚€"""
    energy = objective(x)
    purity_constraint = constraint_purity(x)

    # åˆ¶ç´„é•åã«ãƒšãƒŠãƒ«ãƒ†ã‚£
    if purity_constraint < 0:
        penalty = 1000 * abs(purity_constraint)
        return energy + penalty
    else:
        return energy

result_de = differential_evolution(objective_with_penalty, bounds,
                                    seed=42, disp=True, maxiter=100)

print(f"\nã€æœ€é©è§£ï¼ˆDifferential Evolutionï¼‰ã€‘")
print(f"  é‚„æµæ¯”: {result_de.x[0]:.3f}")
print(f"  ãƒªãƒœã‚¤ãƒ©ãƒ¼ç†±é‡: {result_de.x[1]:.1f} kW")
print(f"  äºˆæ¸¬ç´”åº¦: {constraint_purity(result_de.x) + 97:.2f}%")

# çµæœã®æ¯”è¼ƒ
print(f"\nã€æœ€é©åŒ–æ‰‹æ³•ã®æ¯”è¼ƒã€‘")
print(f"SLSQPï¼ˆå±€æ‰€æœ€é©åŒ–ï¼‰: ã‚¨ãƒãƒ«ã‚®ãƒ¼ = {result_slsqp.fun:.1f} kW")
print(f"Differential Evolutionï¼ˆå¤§åŸŸæœ€é©åŒ–ï¼‰: ã‚¨ãƒãƒ«ã‚®ãƒ¼ = {result_de.fun:.1f} kW")

# å¯è¦–åŒ–: æœ€é©åŒ–ã®çµŒè·¯
fig, ax = plt.subplots(figsize=(10, 8))

# ã‚°ãƒªãƒƒãƒ‰ã§ã®ç´”åº¦åˆ†å¸ƒ
reflux_grid = np.linspace(2.0, 3.5, 50)
duty_grid = np.linspace(1300, 1700, 50)
R, D = np.meshgrid(reflux_grid, duty_grid)

purity_grid = np.zeros_like(R)
for i in range(len(reflux_grid)):
    for j in range(len(duty_grid)):
        purity_grid[j, i] = constraint_purity([R[j, i], D[j, i]]) + 97

contour = ax.contourf(R, D, purity_grid, levels=20, cmap='RdYlGn', alpha=0.6)
ax.contour(R, D, purity_grid, levels=[97.0], colors='red', linewidths=3, linestyles='--')

# æœ€é©è§£ã‚’ãƒ—ãƒ­ãƒƒãƒˆ
if result_slsqp.success:
    ax.scatter(result_slsqp.x[0], result_slsqp.x[1], s=200, color='blue',
               marker='o', edgecolor='white', linewidth=2, label='SLSQP', zorder=5)

ax.scatter(result_de.x[0], result_de.x[1], s=200, color='orange',
           marker='*', edgecolor='white', linewidth=2, label='Differential Evolution', zorder=5)

# åˆæœŸç‚¹
ax.scatter(x0[0], x0[1], s=100, color='black', marker='x', linewidth=2,
           label='Initial point', zorder=5)

ax.set_xlabel('Reflux Ratio', fontsize=12)
ax.set_ylabel('Reboiler Duty (kW)', fontsize=12)
ax.set_title('Optimization Results on Purity Contour', fontsize=13, fontweight='bold')
ax.legend(fontsize=10)
plt.colorbar(contour, ax=ax, label='Purity (%)')
plt.tight_layout()
plt.savefig('advanced_optimization.png', dpi=150, bbox_inches='tight')
plt.show()

print("\nã€æœ€é©åŒ–æ‰‹æ³•ã®é¸æŠæŒ‡é‡ã€‘")
print("âœ“ SLSQP: é«˜é€Ÿã€å‹¾é…æƒ…å ±ã‚’åˆ©ç”¨ã€å±€æ‰€æœ€é©è§£")
print("âœ“ Differential Evolution: é…ã„ã€å¤§åŸŸçš„æ¢ç´¢ã€è¤‡é›‘ãªç›®çš„é–¢æ•°ã«å¼·ã„")
print("âœ“ å®Ÿå‹™: ã¾ãšSLSQPã§é«˜é€Ÿæ¢ç´¢ã€å¿…è¦ã«å¿œã˜ã¦DEã§ç¢ºèª")
</code></pre>

<p><strong>å‡ºåŠ›ä¾‹</strong>:</p>
<pre><code>ã€é«˜åº¦ãªæœ€é©åŒ–ï¼ˆScipy.optimizeï¼‰ã€‘

æ–¹æ³•1: SLSQPï¼ˆå‹¾é…ãƒ™ãƒ¼ã‚¹ï¼‰
Optimization terminated successfully

ã€æœ€é©è§£ï¼ˆSLSQPï¼‰ã€‘
  é‚„æµæ¯”: 2.784
  ãƒªãƒœã‚¤ãƒ©ãƒ¼ç†±é‡: 1365.2 kW
  äºˆæ¸¬ç´”åº¦: 97.03%

æ–¹æ³•2: Differential Evolutionï¼ˆå¤§åŸŸçš„æ¢ç´¢ï¼‰

ã€æœ€é©è§£ï¼ˆDifferential Evolutionï¼‰ã€‘
  é‚„æµæ¯”: 2.789
  ãƒªãƒœã‚¤ãƒ©ãƒ¼ç†±é‡: 1363.8 kW
  äºˆæ¸¬ç´”åº¦: 97.05%

ã€æœ€é©åŒ–æ‰‹æ³•ã®æ¯”è¼ƒã€‘
SLSQPï¼ˆå±€æ‰€æœ€é©åŒ–ï¼‰: ã‚¨ãƒãƒ«ã‚®ãƒ¼ = 1365.2 kW
Differential Evolutionï¼ˆå¤§åŸŸæœ€é©åŒ–ï¼‰: ã‚¨ãƒãƒ«ã‚®ãƒ¼ = 1363.8 kW
</code></pre>

<p><strong>è§£èª¬</strong>: Scipy.optimizeã‚’ä½¿ã†ã“ã¨ã§ã€ã‚ˆã‚Šé«˜åº¦ãªæœ€é©åŒ–ãŒå¯èƒ½ã§ã™ã€‚SLSQPã¯é«˜é€Ÿã§ã™ãŒå±€æ‰€è§£ã«é™¥ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã€Differential Evolutionã¯é…ã„ã§ã™ãŒå¤§åŸŸçš„æœ€é©è§£ã‚’è¦‹ã¤ã‘ã‚„ã™ã„ç‰¹å¾´ãŒã‚ã‚Šã¾ã™ã€‚</p>

<hr />

<h2>4.4 å®Ÿè£…ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå…¨ä½“ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼</h2>

<p>ã“ã‚Œã¾ã§ã®å…¨ã‚¹ãƒ†ãƒƒãƒ—ã‚’çµ±åˆã—ã€ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ã®PIãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’ç¢ºç«‹ã—ã¾ã™ã€‚</p>

<h4>ã‚³ãƒ¼ãƒ‰ä¾‹8: çµ±åˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã¨ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆæº–å‚™</h4>

<pre><code class="language-python">import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import joblib
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import RobustScaler
from sklearn.ensemble import GradientBoostingRegressor
import json

print("=" * 80)
print("ã€PIçµ±åˆãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã€‘")
print("=" * 80)

# ============================================================================
# ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ§‹ç¯‰
# ============================================================================
print("\nã€ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ§‹ç¯‰ã€‘")

class ProcessDataPipeline:
    """ãƒ—ãƒ­ã‚»ã‚¹ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³"""

    def __init__(self):
        self.scaler = RobustScaler()
        self.feature_cols = None

    def fit(self, df, feature_cols):
        """è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã§ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’fit"""
        self.feature_cols = feature_cols

        # æ¬ æå€¤è£œå®Œ
        df_clean = df.copy()
        for col in feature_cols:
            df_clean[col] = df_clean[col].interpolate(method='linear')

        # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
        self.scaler.fit(df_clean[feature_cols])

        return self

    def transform(self, df):
        """ãƒ‡ãƒ¼ã‚¿ã‚’å¤‰æ›"""
        df_clean = df.copy()

        # æ¬ æå€¤è£œå®Œ
        for col in self.feature_cols:
            df_clean[col] = df_clean[col].interpolate(method='linear')

        # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
        df_clean[self.feature_cols] = self.scaler.transform(df_clean[self.feature_cols])

        return df_clean

    def save(self, filepath):
        """ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ä¿å­˜"""
        joblib.dump(self, filepath)
        print(f"  ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ä¿å­˜: {filepath}")

    @staticmethod
    def load(filepath):
        """ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’èª­ã¿è¾¼ã¿"""
        return joblib.load(filepath)

# ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–
pipeline = ProcessDataPipeline()

# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
df = pd.read_csv('distillation_data_cleaned.csv', parse_dates=['timestamp'])
df = df.set_index('timestamp')

feature_cols = ['feed_temp', 'top_temp', 'mid_temp', 'bottom_temp',
                'reflux_ratio', 'reboiler_duty', 'pressure', 'feed_rate',
                'temp_gradient', 'energy_efficiency', 'hour_sin', 'hour_cos']

# ã‚ªãƒ•ãƒ©ã‚¤ãƒ³æ¸¬å®šãƒ‡ãƒ¼ã‚¿ã®ã¿
train_data = df[df['purity_measured'].notna()].copy()
X_train = train_data[feature_cols]
y_train = train_data['purity_measured']

# ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’fit
pipeline.fit(X_train, feature_cols)
X_train_processed = pipeline.transform(X_train)

print("  ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ§‹ç¯‰å®Œäº†")

# ============================================================================
# ã‚¹ãƒ†ãƒƒãƒ—2: ãƒ¢ãƒ‡ãƒ«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°
# ============================================================================
print("\nã€ã‚¹ãƒ†ãƒƒãƒ—2: ãƒ¢ãƒ‡ãƒ«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã€‘")

model = GradientBoostingRegressor(n_estimators=100, max_depth=5,
                                   learning_rate=0.1, random_state=42)
model.fit(X_train_processed[feature_cols], y_train)

print(f"  ãƒ¢ãƒ‡ãƒ«: Gradient Boosting Regressor")
print(f"  è¨“ç·´ãƒ‡ãƒ¼ã‚¿æ•°: {len(X_train)}")
print(f"  ç‰¹å¾´é‡æ•°: {len(feature_cols)}")

# ============================================================================
# ã‚¹ãƒ†ãƒƒãƒ—3: ãƒ¢ãƒ‡ãƒ«è©•ä¾¡
# ============================================================================
print("\nã€ã‚¹ãƒ†ãƒƒãƒ—3: ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ã€‘")

from sklearn.model_selection import cross_val_score
from sklearn.metrics import r2_score, mean_squared_error

cv_scores = cross_val_score(model, X_train_processed[feature_cols], y_train, cv=5, scoring='r2')
print(f"  CV RÂ² ã‚¹ã‚³ã‚¢: {cv_scores.mean():.4f} (Â±{cv_scores.std():.4f})")

y_train_pred = model.predict(X_train_processed[feature_cols])
train_r2 = r2_score(y_train, y_train_pred)
train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))
print(f"  è¨“ç·´ãƒ‡ãƒ¼ã‚¿ RÂ²: {train_r2:.4f}")
print(f"  è¨“ç·´ãƒ‡ãƒ¼ã‚¿ RMSE: {train_rmse:.4f}%")

# ============================================================================
# ã‚¹ãƒ†ãƒƒãƒ—4: ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆæº–å‚™
# ============================================================================
print("\nã€ã‚¹ãƒ†ãƒƒãƒ—4: ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆæº–å‚™ã€‘")

# ãƒ¢ãƒ‡ãƒ«ã¨ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ä¿å­˜
model_path = 'production_model.pkl'
pipeline_path = 'production_pipeline.pkl'

joblib.dump(model, model_path)
pipeline.save(pipeline_path)

print(f"  ãƒ¢ãƒ‡ãƒ«ä¿å­˜: {model_path}")
print(f"  ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ä¿å­˜: {pipeline_path}")

# ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜
metadata = {
    'model_type': 'Gradient Boosting Regressor',
    'training_date': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S'),
    'training_samples': len(X_train),
    'features': feature_cols,
    'cv_r2_mean': float(cv_scores.mean()),
    'cv_r2_std': float(cv_scores.std()),
    'train_r2': float(train_r2),
    'train_rmse': float(train_rmse),
    'target_variable': 'purity',
    'target_unit': '%',
    'quality_threshold': 97.0
}

with open('model_metadata.json', 'w') as f:
    json.dump(metadata, f, indent=2)

print("  ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä¿å­˜: model_metadata.json")

# ============================================================================
# ã‚¹ãƒ†ãƒƒãƒ—5: æ¨è«–é–¢æ•°ï¼ˆãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆç”¨ï¼‰
# ============================================================================
print("\nã€ã‚¹ãƒ†ãƒƒãƒ—5: æ¨è«–é–¢æ•°ã®å®Ÿè£…ã€‘")

def predict_purity(process_data):
    """
    ãƒ—ãƒ­ã‚»ã‚¹ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ç´”åº¦ã‚’äºˆæ¸¬

    Parameters:
    -----------
    process_data : dict
        ãƒ—ãƒ­ã‚»ã‚¹å¤‰æ•°ã®è¾æ›¸
        ä¾‹: {'feed_temp': 60, 'top_temp': 85, ...}

    Returns:
    --------
    float
        äºˆæ¸¬ç´”åº¦ï¼ˆ%ï¼‰
    """
    # ãƒ¢ãƒ‡ãƒ«ã¨ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®èª­ã¿è¾¼ã¿
    model = joblib.load('production_model.pkl')
    pipeline = ProcessDataPipeline.load('production_pipeline.pkl')

    # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«å¤‰æ›
    df = pd.DataFrame([process_data])

    # å‰å‡¦ç†
    df_processed = pipeline.transform(df)

    # äºˆæ¸¬
    purity_pred = model.predict(df_processed[feature_cols])[0]

    return purity_pred

# ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
test_data = {
    'feed_temp': 60.0,
    'top_temp': 85.5,
    'mid_temp': 120.0,
    'bottom_temp': 155.0,
    'reflux_ratio': 2.8,
    'reboiler_duty': 1400,
    'pressure': 1.2,
    'feed_rate': 100,
    'temp_gradient': -69.5,
    'energy_efficiency': 14.0,
    'hour_sin': 0,
    'hour_cos': 1
}

purity_prediction = predict_purity(test_data)
print(f"\n  æ¨è«–ãƒ†ã‚¹ãƒˆ:")
print(f"    å…¥åŠ›: {test_data}")
print(f"    äºˆæ¸¬ç´”åº¦: {purity_prediction:.2f}%")

# ============================================================================
# ã‚¹ãƒ†ãƒƒãƒ—6: ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ç”¨ãƒ‡ãƒ¼ã‚¿å‡ºåŠ›
# ============================================================================
print("\nã€ã‚¹ãƒ†ãƒƒãƒ—6: ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ç”¨ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã€‘")

# å…¨ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ äºˆæ¸¬
df_all = df.copy()
df_all_processed = pipeline.transform(df_all)
df_all['purity_predicted'] = model.predict(df_all_processed[feature_cols])

# äºˆæ¸¬èª¤å·®ã®è¨ˆç®—ï¼ˆã‚ªãƒ•ãƒ©ã‚¤ãƒ³æ¸¬å®šãŒã‚ã‚‹æ™‚ã®ã¿ï¼‰
df_all['prediction_error'] = df_all['purity_measured'] - df_all['purity_predicted']

# ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ç”¨ãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜ï¼ˆæœ€æ–°1é€±é–“ï¼‰
dashboard_data = df_all.tail(10080)[['purity', 'purity_predicted', 'purity_measured',
                                       'prediction_error', 'reflux_ratio', 'reboiler_duty']]
dashboard_data.to_csv('dashboard_data.csv')

print("  ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ç”¨ãƒ‡ãƒ¼ã‚¿ä¿å­˜: dashboard_data.csv")
print(f"  ãƒ‡ãƒ¼ã‚¿æœŸé–“: {dashboard_data.index.min()} ã€œ {dashboard_data.index.max()}")

# æ€§èƒ½ã‚µãƒãƒªãƒ¼
errors = df_all['prediction_error'].dropna()
print(f"\n  ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ã‚µãƒãƒªãƒ¼ï¼ˆã‚ªãƒ•ãƒ©ã‚¤ãƒ³æ¸¬å®šã¨ã®æ¯”è¼ƒï¼‰:")
print(f"    å¹³å‡èª¤å·®: {errors.mean():.4f}%")
print(f"    æ¨™æº–åå·®: {errors.std():.4f}%")
print(f"    æœ€å¤§èª¤å·®: {errors.abs().max():.4f}%")

# ============================================================================
# ã¾ã¨ã‚
# ============================================================================
print("\n" + "=" * 80)
print("ã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå®Œäº†ã€‘")
print("=" * 80)
print("\næ§‹ç¯‰ã—ãŸæˆæœç‰©:")
print("  1. production_model.pkl - è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«")
print("  2. production_pipeline.pkl - ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³")
print("  3. model_metadata.json - ãƒ¢ãƒ‡ãƒ«ã®ãƒ¡ã‚¿æƒ…å ±")
print("  4. dashboard_data.csv - ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ç”¨ãƒ‡ãƒ¼ã‚¿")
print("  5. predict_purity() - æ¨è«–é–¢æ•°ï¼ˆæœ¬ç•ªãƒ‡ãƒ—ãƒ­ã‚¤ç”¨ï¼‰")

print("\næ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
print("  âœ“ å®Ÿãƒ—ãƒ©ãƒ³ãƒˆã§ã®ãƒ‘ã‚¤ãƒ­ãƒƒãƒˆé‹ç”¨")
print("  âœ“ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆãƒªãƒ¼ãƒ ã¨ã®æ¥ç¶š")
print("  âœ“ å®šæœŸçš„ãªãƒ¢ãƒ‡ãƒ«å†å­¦ç¿’ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ç¢ºç«‹")
print("  âœ“ ã‚¢ãƒ©ãƒ¼ãƒˆæ©Ÿèƒ½ã®å®Ÿè£…ï¼ˆäºˆæ¸¬ç´”åº¦ < é–¾å€¤ï¼‰")
print("  âœ“ A/Bãƒ†ã‚¹ãƒˆã«ã‚ˆã‚‹æœ€é©åŒ–æ¡ä»¶ã®æ¤œè¨¼")
</code></pre>

<p><strong>å‡ºåŠ›ä¾‹</strong>:</p>
<pre><code>================================================================================
ã€PIçµ±åˆãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã€‘
================================================================================

ã€ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ§‹ç¯‰ã€‘
  ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ§‹ç¯‰å®Œäº†

ã€ã‚¹ãƒ†ãƒƒãƒ—2: ãƒ¢ãƒ‡ãƒ«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã€‘
  ãƒ¢ãƒ‡ãƒ«: Gradient Boosting Regressor
  è¨“ç·´ãƒ‡ãƒ¼ã‚¿æ•°: 25
  ç‰¹å¾´é‡æ•°: 12

ã€ã‚¹ãƒ†ãƒƒãƒ—3: ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ã€‘
  CV RÂ² ã‚¹ã‚³ã‚¢: 0.8923 (Â±0.1056)
  è¨“ç·´ãƒ‡ãƒ¼ã‚¿ RÂ²: 0.9567
  è¨“ç·´ãƒ‡ãƒ¼ã‚¿ RMSE: 0.2456%

ã€ã‚¹ãƒ†ãƒƒãƒ—4: ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆæº–å‚™ã€‘
  ãƒ¢ãƒ‡ãƒ«ä¿å­˜: production_model.pkl
  ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ä¿å­˜: production_pipeline.pkl
  ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä¿å­˜: model_metadata.json

ã€ã‚¹ãƒ†ãƒƒãƒ—5: æ¨è«–é–¢æ•°ã®å®Ÿè£…ã€‘

  æ¨è«–ãƒ†ã‚¹ãƒˆ:
    å…¥åŠ›: {'feed_temp': 60.0, 'top_temp': 85.5, ...}
    äºˆæ¸¬ç´”åº¦: 97.34%

ã€ã‚¹ãƒ†ãƒƒãƒ—6: ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ç”¨ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã€‘
  ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ç”¨ãƒ‡ãƒ¼ã‚¿ä¿å­˜: dashboard_data.csv
  ãƒ‡ãƒ¼ã‚¿æœŸé–“: 2025-01-24 00:00:00 ã€œ 2025-01-30 23:59:00

  ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ã‚µãƒãƒªãƒ¼ï¼ˆã‚ªãƒ•ãƒ©ã‚¤ãƒ³æ¸¬å®šã¨ã®æ¯”è¼ƒï¼‰:
    å¹³å‡èª¤å·®: 0.0123%
    æ¨™æº–åå·®: 0.2567%
    æœ€å¤§èª¤å·®: 0.5678%

================================================================================
ã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå®Œäº†ã€‘
================================================================================
</code></pre>

<p><strong>è§£èª¬</strong>: å®Ÿå‹™ã§ã¯ã€ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰ã ã‘ã§ãªãã€ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆæº–å‚™ã€æ¨è«–é–¢æ•°ã®å®Ÿè£…ã€ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°åŸºç›¤ã®æ•´å‚™ã¾ã§ãŒé‡è¦ã§ã™ã€‚ã“ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã¯ã€å®Ÿãƒ—ãƒ©ãƒ³ãƒˆã¸ã®é©ç”¨ã®åŸºç¤ã¨ãªã‚Šã¾ã™ã€‚</p>

<hr />

<h2>4.5 ã¾ã¨ã‚ã¨æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—</h2>

<h3>æœ¬ã‚·ãƒªãƒ¼ã‚ºã§å­¦ã‚“ã ã“ã¨</h3>

<details>
<summary><strong>ç¬¬1ç« : PIã®åŸºç¤æ¦‚å¿µ</strong></summary>
<ul>
<li>ãƒ—ãƒ­ã‚»ã‚¹ãƒ»ã‚¤ãƒ³ãƒ•ã‚©ãƒãƒ†ã‚£ã‚¯ã‚¹ã®å®šç¾©ã¨ç›®çš„</li>
<li>ãƒ—ãƒ­ã‚»ã‚¹ç”£æ¥­ã®ç‰¹å¾´ã¨ãƒ‡ãƒ¼ã‚¿ã®ç¨®é¡</li>
<li>ãƒ‡ãƒ¼ã‚¿é§†å‹•å‹ãƒ—ãƒ­ã‚»ã‚¹æ”¹å–„ã®å®Ÿä¾‹ã¨ROI</li>
<li>Pythonã«ã‚ˆã‚‹åŸºæœ¬çš„ãªãƒ‡ãƒ¼ã‚¿å¯è¦–åŒ–</li>
</ul>
</details>

<details>
<summary><strong>ç¬¬2ç« : ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ã¨å¯è¦–åŒ–</strong></summary>
<ul>
<li>æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã®æ“ä½œï¼ˆãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã€ãƒ­ãƒ¼ãƒªãƒ³ã‚°çµ±è¨ˆï¼‰</li>
<li>æ¬ æå€¤å‡¦ç†ã¨å¤–ã‚Œå€¤æ¤œå‡ºã®å®Ÿè·µæ‰‹æ³•</li>
<li>ãƒ‡ãƒ¼ã‚¿ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã®é¸æŠã¨å®Ÿè£…</li>
<li>é«˜åº¦ãªå¯è¦–åŒ–ãƒ†ã‚¯ãƒ‹ãƒƒã‚¯</li>
</ul>
</details>

<details>
<summary><strong>ç¬¬3ç« : ãƒ—ãƒ­ã‚»ã‚¹ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã®åŸºç¤</strong></summary>
<ul>
<li>ç·šå½¢å›å¸°ã«ã‚ˆã‚‹å“è³ªäºˆæ¸¬ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰</li>
<li>PLSã«ã‚ˆã‚‹å¤šé‡å…±ç·šæ€§å¯¾å‡¦</li>
<li>ã‚½ãƒ•ãƒˆã‚»ãƒ³ã‚µãƒ¼ã®è¨­è¨ˆã¨é‹ç”¨</li>
<li>ãƒ¢ãƒ‡ãƒ«è©•ä¾¡æŒ‡æ¨™ã¨ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³</li>
<li>éç·šå½¢ãƒ¢ãƒ‡ãƒ«ã¸ã®æ‹¡å¼µ</li>
</ul>
</details>

<details>
<summary><strong>ç¬¬4ç« : å®Ÿè·µæ¼”ç¿’</strong></summary>
<ul>
<li>å®Ÿãƒ—ãƒ­ã‚»ã‚¹ãƒ‡ãƒ¼ã‚¿ã®EDAã¨ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°</li>
<li>ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°</li>
<li>è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã®æ¯”è¼ƒã¨æœ€é©ãƒ¢ãƒ‡ãƒ«é¸æŠ</li>
<li>ãƒ—ãƒ­ã‚»ã‚¹æ¡ä»¶æœ€é©åŒ–ã®åŸºç¤</li>
<li>ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼</li>
</ul>
</details>

<h3>å®Ÿå‹™é©ç”¨ã®ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ</h3>

<ol>
<li><strong>ãƒ‡ãƒ¼ã‚¿åé›†ãƒ»ç®¡ç†</strong>
<ul>
<li>â–¡ ãƒ—ãƒ­ã‚»ã‚¹å¤‰æ•°ã¨å“è³ªå¤‰æ•°ã®ç‰¹å®š</li>
<li>â–¡ ãƒ‡ãƒ¼ã‚¿åé›†é »åº¦ã®æ±ºå®š</li>
<li>â–¡ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­è¨ˆã¨ãƒ’ã‚¹ãƒˆãƒªã‚¢ãƒ³æ¥ç¶š</li>
</ul>
</li>
<li><strong>ãƒ‡ãƒ¼ã‚¿åˆ†æ</strong>
<ul>
<li>â–¡ EDAã«ã‚ˆã‚‹ãƒ‡ãƒ¼ã‚¿ç†è§£</li>
<li>â–¡ æ¬ æå€¤ãƒ»å¤–ã‚Œå€¤ã®å¯¾å‡¦æ–¹é‡æ±ºå®š</li>
<li>â–¡ ç›¸é–¢åˆ†æã¨ç‰¹å¾´é‡é¸æŠ</li>
</ul>
</li>
<li><strong>ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰</strong>
<ul>
<li>â–¡ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰ï¼ˆç·šå½¢å›å¸°ï¼‰</li>
<li>â–¡ è¤‡æ•°æ‰‹æ³•ã®æ¯”è¼ƒæ¤œè¨¼</li>
<li>â–¡ ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã«ã‚ˆã‚‹æ€§èƒ½è©•ä¾¡</li>
<li>â–¡ ãƒ¢ãƒ‡ãƒ«ã®è§£é‡ˆæ€§ç¢ºèª</li>
</ul>
</li>
<li><strong>å®Ÿè£…ãƒ»é‹ç”¨</strong>
<ul>
<li>â–¡ ãƒ‘ã‚¤ãƒ­ãƒƒãƒˆé‹ç”¨è¨ˆç”»ã®ç­–å®š</li>
<li>â–¡ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¨è«–åŸºç›¤ã®æ§‹ç¯‰</li>
<li>â–¡ ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã®è¨­ç½®</li>
<li>â–¡ å®šæœŸçš„ãªå†å­¦ç¿’ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ç¢ºç«‹</li>
</ul>
</li>
<li><strong>ç¶™ç¶šæ”¹å–„</strong>
<ul>
<li>â–¡ æ€§èƒ½ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ã¨ãƒ‰ãƒªãƒ•ãƒˆæ¤œå‡º</li>
<li>â–¡ A/Bãƒ†ã‚¹ãƒˆã«ã‚ˆã‚‹åŠ¹æœæ¤œè¨¼</li>
<li>â–¡ ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ«ãƒ¼ãƒ—ã®æ§‹ç¯‰</li>
</ul>
</li>
</ol>

<h3>æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ï¼šä¸Šç´šãƒˆãƒ”ãƒƒã‚¯</h3>

<p>æœ¬ã‚·ãƒªãƒ¼ã‚ºã§åŸºç¤ã‚’ç¿’å¾—ã—ãŸæ–¹ã¯ã€ä»¥ä¸‹ã®ä¸Šç´šãƒˆãƒ”ãƒƒã‚¯ã«é€²ã‚€ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ï¼š</p>

<h4>1. é«˜åº¦ãªãƒ¢ãƒ‡ãƒªãƒ³ã‚°æ‰‹æ³•</h4>
<ul>
<li><strong>ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°</strong>: LSTMã€CNNã‚’ä½¿ã£ãŸæ™‚ç³»åˆ—äºˆæ¸¬</li>
<li><strong>ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å­¦ç¿’</strong>: ã‚¹ã‚¿ãƒƒã‚­ãƒ³ã‚°ã€ãƒ–ãƒ¬ãƒ³ãƒ‡ã‚£ãƒ³ã‚°</li>
<li><strong>ãƒ™ã‚¤ã‚ºæœ€é©åŒ–</strong>: ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®åŠ¹ç‡çš„æ¢ç´¢</li>
<li><strong>è»¢ç§»å­¦ç¿’</strong>: ä»–ãƒ—ãƒ©ãƒ³ãƒˆã®ãƒ‡ãƒ¼ã‚¿ã‚’æ´»ç”¨</li>
</ul>

<h4>2. ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ PI</h4>
<ul>
<li><strong>ã‚¹ãƒˆãƒªãƒ¼ãƒ å‡¦ç†</strong>: Apache Kafkaã€Spark Streamingã¨ã®é€£æº</li>
<li><strong>ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å­¦ç¿’</strong>: ã‚¤ãƒ³ã‚¯ãƒªãƒ¡ãƒ³ã‚¿ãƒ«å­¦ç¿’ã€é©å¿œåˆ¶å¾¡</li>
<li><strong>ã‚¨ãƒƒã‚¸ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°</strong>: ç¾å ´ã§ã®é«˜é€Ÿæ¨è«–</li>
</ul>

<h4>3. ãƒ—ãƒ­ã‚»ã‚¹åˆ¶å¾¡ã¨ã®çµ±åˆ</h4>
<ul>
<li><strong>MPCï¼ˆãƒ¢ãƒ‡ãƒ«äºˆæ¸¬åˆ¶å¾¡ï¼‰</strong>: PIãƒ¢ãƒ‡ãƒ«ã‚’åˆ¶å¾¡ã«æ´»ç”¨</li>
<li><strong>å¼·åŒ–å­¦ç¿’</strong>: è‡ªå¾‹çš„ãªé‹è»¢æ¡ä»¶æœ€é©åŒ–</li>
<li><strong>ãƒ‡ã‚¸ã‚¿ãƒ«ãƒ„ã‚¤ãƒ³</strong>: ä»®æƒ³ãƒ—ãƒ©ãƒ³ãƒˆã§ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³</li>
</ul>

<h4>4. ç•°å¸¸æ¤œçŸ¥ãƒ»è¨ºæ–­</h4>
<ul>
<li><strong>çµ±è¨ˆçš„å·¥ç¨‹ç®¡ç†</strong>: CUSUMã€EWMA</li>
<li><strong>å¤‰åŒ–ç‚¹æ¤œå‡º</strong>: ãƒ—ãƒ­ã‚»ã‚¹ãƒ‰ãƒªãƒ•ãƒˆã®æ—©æœŸç™ºè¦‹</li>
<li><strong>æ ¹æœ¬åŸå› åˆ†æ</strong>: ç•°å¸¸ç™ºç”Ÿãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã®è§£æ˜</li>
</ul>

<h4>5. ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚ºå±•é–‹</h4>
<ul>
<li><strong>MLOps</strong>: ãƒ¢ãƒ‡ãƒ«ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ã€CI/CD</li>
<li><strong>ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£</strong>: è¤‡æ•°ãƒ—ãƒ©ãƒ³ãƒˆã¸ã®æ¨ªå±•é–‹</li>
<li><strong>ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£</strong>: ãƒ‡ãƒ¼ã‚¿ã‚¬ãƒãƒŠãƒ³ã‚¹ã€ã‚¢ã‚¯ã‚»ã‚¹åˆ¶å¾¡</li>
</ul>

<h3>æ¨å¥¨å­¦ç¿’ãƒªã‚½ãƒ¼ã‚¹</h3>

<h4>æ›¸ç±</h4>
<ul>
<li>ã€Œãƒ—ãƒ­ã‚»ã‚¹åˆ¶å¾¡å·¥å­¦ã€ï¼ˆåŒ–å­¦å·¥å­¦ä¼šç·¨ï¼‰</li>
<li>"Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow" (AurÃ©lien GÃ©ron)</li>
<li>"Introduction to Statistical Learning" (James et al.)</li>
</ul>

<h4>ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã‚³ãƒ¼ã‚¹</h4>
<ul>
<li>Coursera: "Machine Learning" (Andrew Ng)</li>
<li>Udacity: "Machine Learning Engineer Nanodegree"</li>
<li>Fast.ai: "Practical Deep Learning for Coders"</li>
</ul>

<h4>ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ãƒ»ã‚«ãƒ³ãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹</h4>
<ul>
<li>PSE (Process Systems Engineering) Conference</li>
<li>IFAC DYCOPS (Dynamics and Control of Process Systems)</li>
<li>åŒ–å­¦å·¥å­¦ä¼š ãƒ—ãƒ­ã‚»ã‚¹ã‚·ã‚¹ãƒ†ãƒ å·¥å­¦éƒ¨ä¼š</li>
</ul>

<h3>æœ€å¾Œã«</h3>

<blockquote>
<p><strong>"Data is the new oil, but analytics is the combustion engine."</strong></p>
</blockquote>

<p>ãƒ—ãƒ­ã‚»ã‚¹ãƒ»ã‚¤ãƒ³ãƒ•ã‚©ãƒãƒ†ã‚£ã‚¯ã‚¹ã¯ã€è£½é€ æ¥­ã®ãƒ‡ã‚¸ã‚¿ãƒ«å¤‰é©ã‚’æ¨é€²ã™ã‚‹å¼·åŠ›ãªæŠ€è¡“ã§ã™ã€‚æœ¬ã‚·ãƒªãƒ¼ã‚ºã§å­¦ã‚“ã åŸºç¤ã‚’åœŸå°ã«ã€å®Ÿãƒ—ãƒ©ãƒ³ãƒˆã§ã®PIãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«æŒ‘æˆ¦ã—ã¦ãã ã•ã„ã€‚</p>

<p><strong>æˆåŠŸã®éµ</strong>:</p>
<ol>
<li><strong>å°ã•ãå§‹ã‚ã‚‹</strong>: 1ã¤ã®å“è³ªå¤‰æ•°ã€1ã¤ã®ãƒ—ãƒ­ã‚»ã‚¹ã‹ã‚‰</li>
<li><strong>ãƒ—ãƒ­ã‚»ã‚¹ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã¨å”åŠ›</strong>: ãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜ã¨ãƒ‡ãƒ¼ã‚¿åˆ†æã®èåˆ</li>
<li><strong>ç¶™ç¶šçš„æ”¹å–„</strong>: ãƒ¢ãƒ‡ãƒ«ã¯ä½œã£ã¦çµ‚ã‚ã‚Šã§ã¯ãªãã€è‚²ã¦ã‚‹ã‚‚ã®</li>
<li><strong>ä¾¡å€¤ã®å¯è¦–åŒ–</strong>: ROIã‚’å®šé‡çš„ã«ç¤ºã—ã€çµŒå–¶å±¤ã®æ”¯æŒã‚’å¾—ã‚‹</li>
</ol>

<p>çš†æ§˜ã®PIãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®æˆåŠŸã‚’å¿ƒã‚ˆã‚Šé¡˜ã£ã¦ã„ã¾ã™ã€‚</p>

<div class="navigation">
    <a href="chapter-3.html" class="nav-button">â† å‰ã®ç« </a>
    <a href="index.html" class="nav-button">ã‚·ãƒªãƒ¼ã‚ºç›®æ¬¡ã«æˆ»ã‚‹</a>
</div>
    </main>

    
    <section class="disclaimer">
        <h3>å…è²¬äº‹é …</h3>
        <ul>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯æ•™è‚²ãƒ»ç ”ç©¶ãƒ»æƒ…å ±æä¾›ã®ã¿ã‚’ç›®çš„ã¨ã—ã¦ãŠã‚Šã€å°‚é–€çš„ãªåŠ©è¨€(æ³•å¾‹ãƒ»ä¼šè¨ˆãƒ»æŠ€è¡“çš„ä¿è¨¼ãªã©)ã‚’æä¾›ã™ã‚‹ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŠã‚ˆã³ä»˜éšã™ã‚‹ã‚³ãƒ¼ãƒ‰ä¾‹ã¯ã€Œç¾çŠ¶æœ‰å§¿(AS IS)ã€ã§æä¾›ã•ã‚Œã€æ˜ç¤ºã¾ãŸã¯é»™ç¤ºã‚’å•ã‚ãšã€å•†å“æ€§ã€ç‰¹å®šç›®çš„é©åˆæ€§ã€æ¨©åˆ©éä¾µå®³ã€æ­£ç¢ºæ€§ãƒ»å®Œå…¨æ€§ã€å‹•ä½œãƒ»å®‰å…¨æ€§ç­‰ã„ã‹ãªã‚‹ä¿è¨¼ã‚‚ã—ã¾ã›ã‚“ã€‚</li>
            <li>å¤–éƒ¨ãƒªãƒ³ã‚¯ã€ç¬¬ä¸‰è€…ãŒæä¾›ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ»ãƒ„ãƒ¼ãƒ«ãƒ»ãƒ©ã‚¤ãƒ–ãƒ©ãƒªç­‰ã®å†…å®¹ãƒ»å¯ç”¨æ€§ãƒ»å®‰å…¨æ€§ã«ã¤ã„ã¦ã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯ä¸€åˆ‡ã®è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®åˆ©ç”¨ãƒ»å®Ÿè¡Œãƒ»è§£é‡ˆã«ã‚ˆã‚Šç›´æ¥çš„ãƒ»é–“æ¥çš„ãƒ»ä»˜éšçš„ãƒ»ç‰¹åˆ¥ãƒ»çµæœçš„ãƒ»æ‡²ç½°çš„æå®³ãŒç”Ÿã˜ãŸå ´åˆã§ã‚‚ã€é©ç”¨æ³•ã§è¨±å®¹ã•ã‚Œã‚‹æœ€å¤§é™ã®ç¯„å›²ã§ã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å†…å®¹ã¯ã€äºˆå‘Šãªãå¤‰æ›´ãƒ»æ›´æ–°ãƒ»æä¾›åœæ­¢ã•ã‚Œã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®è‘—ä½œæ¨©ãƒ»ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯æ˜è¨˜ã•ã‚ŒãŸæ¡ä»¶(ä¾‹: CC BY 4.0)ã«å¾“ã„ã¾ã™ã€‚å½“è©²ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯é€šå¸¸ã€ç„¡ä¿è¨¼æ¡é …ã‚’å«ã¿ã¾ã™ã€‚</li>
        </ul>
    </section>

<footer>
        <p><strong>ä½œæˆè€…</strong>: PI Knowledge Hub Content Team</p>
        <p><strong>ãƒãƒ¼ã‚¸ãƒ§ãƒ³</strong>: 1.0 | <strong>ä½œæˆæ—¥</strong>: 2025-10-25</p>
        <p><strong>ãƒ©ã‚¤ã‚»ãƒ³ã‚¹</strong>: Creative Commons BY 4.0</p>
        <p>&copy; 2025 PI Terakoya. All rights reserved.</p>
    </footer>
</body>
</html>
