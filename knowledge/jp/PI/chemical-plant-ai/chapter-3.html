<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="ç¬¬3ç« ï¼šãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æœ€é©åŒ–ã¨APC - åŒ–å­¦ãƒ—ãƒ©ãƒ³ãƒˆã«ãŠã‘ã‚‹çµŒæ¸ˆçš„æœ€é©åŒ–ã€ãƒ¢ãƒ‡ãƒ«äºˆæ¸¬åˆ¶å¾¡ã€å¼·åŒ–å­¦ç¿’ãƒ™ãƒ¼ã‚¹ãƒ—ãƒ­ã‚»ã‚¹åˆ¶å¾¡ã‚’å®Ÿè£…ãƒ¬ãƒ™ãƒ«ã§ç¿’å¾—">
    <title>ç¬¬3ç« ï¼šãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æœ€é©åŒ–ã¨APC - åŒ–å­¦ãƒ—ãƒ©ãƒ³ãƒˆã¸ã®AIå¿œç”¨</title>

    <style>
        :root {
            --color-primary: #2c3e50;
            --color-primary-dark: #1a252f;
            --color-accent: #11998e;
            --color-accent-light: #38ef7d;
            --color-text: #2d3748;
            --color-text-light: #4a5568;
            --color-bg: #ffffff;
            --color-bg-alt: #f7fafc;
            --color-border: #e2e8f0;
            --color-code-bg: #f8f9fa;
            --color-link: #11998e;
            --color-link-hover: #0d7a6f;

            --spacing-xs: 0.5rem;
            --spacing-sm: 1rem;
            --spacing-md: 1.5rem;
            --spacing-lg: 2rem;
            --spacing-xl: 3rem;

            --font-body: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            --font-mono: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;

            --border-radius: 8px;
            --box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: var(--font-body);
            line-height: 1.7;
            color: var(--color-text);
            background-color: var(--color-bg);
            font-size: 16px;
        }

        header {
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            padding: var(--spacing-xl) var(--spacing-md);
            margin-bottom: var(--spacing-xl);
            box-shadow: var(--box-shadow);
        }

        .header-content {
            max-width: 900px;
            margin: 0 auto;
        }

        h1 {
            font-size: 2rem;
            font-weight: 700;
            margin-bottom: var(--spacing-sm);
            line-height: 1.2;
        }

        .subtitle {
            font-size: 1.1rem;
            opacity: 0.95;
            font-weight: 400;
            margin-bottom: var(--spacing-md);
        }

        .meta {
            display: flex;
            flex-wrap: wrap;
            gap: var(--spacing-md);
            font-size: 0.9rem;
            opacity: 0.9;
        }

        .meta-item {
            display: flex;
            align-items: center;
            gap: 0.3rem;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 0 var(--spacing-md) var(--spacing-xl);
        }

        h2 {
            font-size: 1.75rem;
            color: var(--color-primary);
            margin-top: var(--spacing-xl);
            margin-bottom: var(--spacing-md);
            padding-bottom: var(--spacing-xs);
            border-bottom: 3px solid var(--color-accent);
        }

        h3 {
            font-size: 1.35rem;
            color: var(--color-primary);
            margin-top: var(--spacing-lg);
            margin-bottom: var(--spacing-md);
        }

        h4 {
            font-size: 1.1rem;
            color: var(--color-primary-dark);
            margin-top: var(--spacing-md);
            margin-bottom: var(--spacing-sm);
        }

        p {
            margin-bottom: var(--spacing-md);
            color: var(--color-text);
        }

        ul, ol {
            margin-bottom: var(--spacing-md);
            padding-left: var(--spacing-lg);
        }

        li {
            margin-bottom: var(--spacing-xs);
            color: var(--color-text);
        }

        pre {
            background-color: var(--color-code-bg);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            overflow-x: auto;
            margin-bottom: var(--spacing-md);
            font-family: var(--font-mono);
            font-size: 0.9rem;
            line-height: 1.5;
        }

        code {
            font-family: var(--font-mono);
            font-size: 0.9em;
            background-color: var(--color-code-bg);
            padding: 0.2em 0.4em;
            border-radius: 3px;
        }

        pre code {
            background-color: transparent;
            padding: 0;
        }

        .code-block {
            margin-bottom: var(--spacing-lg);
        }

        .code-title {
            background-color: var(--color-primary);
            color: white;
            padding: var(--spacing-xs) var(--spacing-md);
            border-radius: var(--border-radius) var(--border-radius) 0 0;
            font-family: var(--font-mono);
            font-size: 0.9rem;
            font-weight: 600;
        }

        .code-title + pre {
            margin-top: 0;
            border-radius: 0 0 var(--border-radius) var(--border-radius);
        }

        .callout {
            background-color: var(--color-bg-alt);
            border-left: 4px solid var(--color-accent);
            padding: var(--spacing-md);
            margin-bottom: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        .callout-title {
            font-weight: 700;
            color: var(--color-primary);
            margin-bottom: var(--spacing-xs);
        }

        .section-intro {
            background: linear-gradient(135deg, rgba(17, 153, 142, 0.05) 0%, rgba(56, 239, 125, 0.05) 100%);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
            margin-bottom: var(--spacing-lg);
            border: 1px solid rgba(17, 153, 142, 0.2);
        }

        .mermaid {
            background-color: white;
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
            margin-bottom: var(--spacing-md);
            text-align: center;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: var(--spacing-md);
            font-size: 0.95rem;
        }

        th, td {
            padding: var(--spacing-xs) var(--spacing-sm);
            text-align: left;
            border-bottom: 1px solid var(--color-border);
        }

        th {
            background-color: var(--color-bg-alt);
            font-weight: 600;
            color: var(--color-primary);
        }

        .navigation {
            display: flex;
            justify-content: space-between;
            gap: var(--spacing-md);
            margin-top: var(--spacing-xl);
            padding-top: var(--spacing-lg);
            border-top: 2px solid var(--color-border);
        }

        .nav-button {
            flex: 1;
            padding: var(--spacing-md);
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            text-decoration: none;
            border-radius: var(--border-radius);
            text-align: center;
            font-weight: 600;
            transition: transform 0.2s, box-shadow 0.2s;
        }

        @media (hover: hover) and (pointer: fine) {
            .nav-button:hover {
                transform: translateY(-2px);
                box-shadow: 0 4px 12px rgba(17, 153, 142, 0.3);
            }
        }

        @media (max-width: 768px) {
            h1 {
                font-size: 1.5rem;
            }

            h2 {
                font-size: 1.4rem;
            }

            h3 {
                font-size: 1.2rem;
            }

            .navigation {
                flex-direction: column;
            }

            .meta {
                font-size: 0.85rem;
            }
        }
    
        
    
        /* Breadcrumb styles */
        .breadcrumb {
            background: #f7fafc;
            padding: 0.75rem 1rem;
            border-bottom: 1px solid #e2e8f0;
            font-size: 0.9rem;
        }

        .breadcrumb-content {
            max-width: 900px;
            margin: 0 auto;
            display: flex;
            align-items: center;
            flex-wrap: wrap;
            gap: 0.5rem;
        }

        .breadcrumb a {
            color: #667eea;
            text-decoration: none;
            transition: color 0.2s;
        }

        .breadcrumb a:hover {
            color: #764ba2;
            text-decoration: underline;
        }

        .breadcrumb-separator {
            color: #a0aec0;
            margin: 0 0.25rem;
        }

        .breadcrumb-current {
            color: #4a5568;
            font-weight: 500;
        }
    </style>

    <style>
        /* Locale Switcher Styles */
        .locale-switcher {
            display: flex;
            align-items: center;
            gap: 0.5rem;
            padding: 0.5rem 1rem;
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
            border-radius: 6px;
            font-size: 0.9rem;
            margin-bottom: 1rem;
            box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);
        }

        .current-locale {
            font-weight: 600;
            color: #7b2cbf;
            display: flex;
            align-items: center;
            gap: 0.25rem;
        }

        .locale-separator {
            color: #adb5bd;
            font-weight: 300;
        }

        .locale-link {
            color: #f093fb;
            text-decoration: none;
            font-weight: 500;
            transition: all 0.2s ease;
            display: flex;
            align-items: center;
            gap: 0.25rem;
            padding: 0.2rem 0.5rem;
            border-radius: 4px;
        }

        .locale-link:hover {
            background: rgba(240, 147, 251, 0.1);
            color: #d07be8;
            transform: translateY(-1px);
        }

        .locale-meta {
            color: #868e96;
            font-size: 0.85rem;
            font-style: italic;
            margin-left: auto;
        }

        @media (max-width: 768px) {
            .locale-switcher {
                font-size: 0.85rem;
                padding: 0.4rem 0.8rem;
            }
            .locale-meta {
                display: none;
            }
        }
    </style>
</head>
<body>
            <div class="locale-switcher">
<span class="current-locale">ğŸŒ JP</span>
<span class="locale-separator">|</span>
<a href="../../../en/PI/chemical-plant-ai/chapter-3.html" class="locale-link">ğŸ‡¬ğŸ‡§ EN</a>
<span class="locale-separator">|</span>
<span class="locale-meta">Last sync: 2025-11-16</span>
</div>
<nav class="breadcrumb">
        <div class="breadcrumb-content">
            <a href="../../index.html">AIå¯ºå­å±‹ãƒˆãƒƒãƒ—</a><span class="breadcrumb-separator">â€º</span><a href="../../PI/index.html">ãƒ—ãƒ­ã‚»ã‚¹ãƒ»ã‚¤ãƒ³ãƒ•ã‚©ãƒãƒ†ã‚£ã‚¯ã‚¹</a><span class="breadcrumb-separator">â€º</span><a href="../../PI/chemical-plant-ai/index.html">Chemical Plant Ai</a><span class="breadcrumb-separator">â€º</span><span class="breadcrumb-current">Chapter 3</span>
        </div>
    </nav>

        <header>
        <div class="header-content">
            <h1>ç¬¬3ç« ï¼šãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æœ€é©åŒ–ã¨APC</h1>
            <p class="subtitle">åŒ–å­¦ãƒ—ãƒ©ãƒ³ãƒˆã«ãŠã‘ã‚‹çµŒæ¸ˆçš„æœ€é©åŒ–ã¨ãƒ¢ãƒ‡ãƒ«äºˆæ¸¬åˆ¶å¾¡ã®å®Ÿè£…</p>
            <div class="meta">
                <div class="meta-item">ğŸ“š ã‚·ãƒªãƒ¼ã‚ºï¼šåŒ–å­¦ãƒ—ãƒ©ãƒ³ãƒˆã¸ã®AIå¿œç”¨</div>
                <div class="meta-item">â±ï¸ èª­äº†æ™‚é–“ï¼š40-50åˆ†</div>
                <div class="meta-item">ğŸ¯ é›£æ˜“åº¦ï¼šä¸­ç´šã€œä¸Šç´š</div>
            </div>
        </div>
    </header>

    <div class="container">
        <div class="section-intro">
            <p><strong>ã“ã®ç« ã§å­¦ã¶ã“ã¨ï¼š</strong></p>
            <p>åŒ–å­¦ãƒ—ãƒ©ãƒ³ãƒˆã®é‹è»¢ã«ãŠã„ã¦ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æœ€é©åŒ–ï¼ˆReal-Time Optimization, RTOï¼‰ã¨Advanced Process Controlï¼ˆAPCï¼‰ã¯çµŒæ¸ˆæ€§ã¨å®‰å…¨æ€§ã‚’ä¸¡ç«‹ã•ã›ã‚‹é‡è¦æŠ€è¡“ã§ã™ã€‚æœ¬ç« ã§ã¯ã€SciPyã‚„Pyomoã«ã‚ˆã‚‹æœ€é©åŒ–ã€Model Predictive Controlï¼ˆMPCï¼‰ã®å®Ÿè£…ã€ã•ã‚‰ã«æ·±å±¤å¼·åŒ–å­¦ç¿’ï¼ˆDQNã€PPOï¼‰ã‚’ç”¨ã„ãŸæ¬¡ä¸–ä»£ãƒ—ãƒ­ã‚»ã‚¹åˆ¶å¾¡ã¾ã§ã€å®Ÿè£…ãƒ¬ãƒ™ãƒ«ã§ç¿’å¾—ã—ã¾ã™ã€‚</p>
            <ul>
                <li><strong>çµŒæ¸ˆçš„æœ€é©åŒ–</strong>ï¼šè£½å“ä¾¡å€¤ã®æœ€å¤§åŒ–ã¨ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚³ã‚¹ãƒˆã®æœ€å°åŒ–ã‚’æ•°ç†æœ€é©åŒ–ã§å®Ÿç¾</li>
                <li><strong>Model Predictive Control</strong>ï¼šæœªæ¥ã®æŒ™å‹•ã‚’äºˆæ¸¬ã—ãªãŒã‚‰åˆ¶ç´„æ¡ä»¶ä¸‹ã§æœ€é©ãªæ“ä½œé‡ã‚’è¨ˆç®—</li>
                <li><strong>å¼·åŒ–å­¦ç¿’ãƒ™ãƒ¼ã‚¹åˆ¶å¾¡</strong>ï¼šDQNã‚„PPOã«ã‚ˆã‚‹ãƒãƒƒãƒãƒ—ãƒ­ã‚»ã‚¹ãƒ»é€£ç¶šãƒ—ãƒ­ã‚»ã‚¹ã®è‡ªå¾‹åˆ¶å¾¡</li>
                <li><strong>éšå±¤å‹åˆ¶å¾¡ã‚·ã‚¹ãƒ†ãƒ </strong>ï¼šRTOå±¤ã¨APCå±¤ã‚’çµ±åˆã—ãŸå®Ÿç”¨çš„ãªãƒ—ãƒ©ãƒ³ãƒˆåˆ¶å¾¡ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£</li>
            </ul>
        </div>

        <h2>3.1 ãƒ—ãƒ­ã‚»ã‚¹åˆ¶å¾¡ã®éšå±¤æ§‹é€ </h2>

        <p>ç¾ä»£ã®åŒ–å­¦ãƒ—ãƒ©ãƒ³ãƒˆã§ã¯ã€åˆ¶å¾¡ã‚·ã‚¹ãƒ†ãƒ ãŒéšå±¤çš„ã«æ§‹æˆã•ã‚Œã¦ã„ã¾ã™ã€‚å„å±¤ã¯ç•°ãªã‚‹æ™‚é–“ã‚¹ã‚±ãƒ¼ãƒ«ã§å‹•ä½œã—ã€ä¸Šä½å±¤ã®æœ€é©åŒ–ç›®æ¨™ã‚’ä¸‹ä½å±¤ãŒå®Ÿç¾ã—ã¾ã™ã€‚</p>

        <div class="mermaid">
graph TB
    subgraph "éšå±¤å‹ãƒ—ãƒ­ã‚»ã‚¹åˆ¶å¾¡ã‚·ã‚¹ãƒ†ãƒ "
        RTO[ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æœ€é©åŒ–å±¤<br/>Real-Time Optimization<br/>æ™‚é–“ã‚¹ã‚±ãƒ¼ãƒ«: æ•°æ™‚é–“ã€œ1æ—¥]
        APC[å…ˆé€²åˆ¶å¾¡å±¤<br/>Advanced Process Control<br/>æ™‚é–“ã‚¹ã‚±ãƒ¼ãƒ«: åˆ†ã€œæ™‚é–“]
        REG[åˆ¶å¾¡å±¤<br/>Regulatory Control<br/>æ™‚é–“ã‚¹ã‚±ãƒ¼ãƒ«: ç§’ã€œåˆ†]
        PROC[ãƒ—ãƒ­ã‚»ã‚¹<br/>åŒ–å­¦ãƒ—ãƒ©ãƒ³ãƒˆ]
    end

    RTO -->|æœ€é©é‹è»¢æ¡ä»¶| APC
    APC -->|è¨­å®šå€¤| REG
    REG -->|æ“ä½œé‡| PROC
    PROC -->|æ¸¬å®šå€¤| REG
    PROC -->|çŠ¶æ…‹| APC
    PROC -->|çµŒæ¸ˆæ€§æŒ‡æ¨™| RTO

    style RTO fill:#e3f2fd
    style APC fill:#fff3e0
    style REG fill:#e8f5e9
    style PROC fill:#f3e5f5
        </div>

        <div class="callout">
            <div class="callout-title">ğŸ¯ éšå±¤åˆ¶å¾¡ã®å®Ÿä¾‹</div>
            <p><strong>çŸ³æ²¹ç²¾è£½ãƒ—ãƒ©ãƒ³ãƒˆï¼ˆFCCè£…ç½®ï¼‰ã®å ´åˆï¼š</strong></p>
            <ul>
                <li><strong>RTOå±¤ï¼ˆ6æ™‚é–“å‘¨æœŸï¼‰</strong>ï¼šåŸæ²¹ä¾¡æ ¼ã¨ã‚¬ã‚½ãƒªãƒ³éœ€è¦ã‹ã‚‰æœ€é©ãªè»½è³ªç•™åˆ†æ¯”ç‡ã‚’æ±ºå®š</li>
                <li><strong>APCå±¤ï¼ˆ5åˆ†å‘¨æœŸï¼‰</strong>ï¼šMPCã§åå¿œæ¸©åº¦ãƒ»è§¦åª’å¾ªç’°é‡ã‚’åˆ¶å¾¡ã—ã€ç›®æ¨™ç•™åˆ†æ¯”ç‡ã‚’é”æˆ</li>
                <li><strong>åˆ¶å¾¡å±¤ï¼ˆ1ç§’å‘¨æœŸï¼‰</strong>ï¼šPIDã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©ã§æ¸©åº¦ãƒ»åœ§åŠ›ãƒ»æµé‡ã‚’å³åº§ã«èª¿æ•´</li>
            </ul>
            <p>ã“ã®éšå±¤åŒ–ã«ã‚ˆã‚Šã€ãƒ—ãƒ©ãƒ³ãƒˆåç›ŠãŒå¹´é–“æ•°å„„å††æ”¹å–„ã—ãŸå®Ÿç¸¾ãŒã‚ã‚Šã¾ã™ã€‚</p>
        </div>

        <h2>3.2 ã‚ªãƒ³ãƒ©ã‚¤ãƒ³æœ€é©åŒ–ï¼ˆSciPyï¼‰</h2>

        <p>ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æœ€é©åŒ–ã§ã¯ã€ç¾åœ¨ã®ãƒ—ãƒ©ãƒ³ãƒˆçŠ¶æ…‹ã‚’å…¥åŠ›ã¨ã—ã¦ã€çµŒæ¸ˆçš„ç›®æ¨™é–¢æ•°ï¼ˆåˆ©ç›Šæœ€å¤§åŒ–ãªã©ï¼‰ã‚’æº€ãŸã™æœ€é©é‹è»¢æ¡ä»¶ã‚’è¨ˆç®—ã—ã¾ã™ã€‚é€£ç¶šæ”ªæ‹Œæ§½åå¿œå™¨ï¼ˆCSTRï¼‰ã®é‹è»¢æœ€é©åŒ–ã‚’ä¾‹ã«å®Ÿè£…ã—ã¾ã™ã€‚</p>

        <div class="code-block">
            <div class="code-title">Example 1: ã‚ªãƒ³ãƒ©ã‚¤ãƒ³æœ€é©åŒ–ï¼ˆSciPyï¼‰ - CSTRé‹è»¢æ¡ä»¶ã®æœ€é©åŒ–</div>
            <pre><code>"""
===================================
Example 1: ã‚ªãƒ³ãƒ©ã‚¤ãƒ³æœ€é©åŒ–ï¼ˆSciPyï¼‰
===================================

é€£ç¶šæ”ªæ‹Œæ§½åå¿œå™¨ï¼ˆCSTRï¼‰ã«ãŠã‘ã‚‹æ¸©åº¦ã¨æµé‡ã®æœ€é©åŒ–ã€‚
åå¿œé€Ÿåº¦ã¨é¸æŠæ€§ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’è€ƒæ…®ã—ã€å˜ä½æ™‚é–“ã‚ãŸã‚Šã®åç›Šã‚’æœ€å¤§åŒ–ã™ã‚‹ã€‚

ç›®çš„: è£½å“ä¾¡å€¤ã‚’æœ€å¤§åŒ–ã—ãªãŒã‚‰ã€ã‚¨ãƒãƒ«ã‚®ãƒ¼ã‚³ã‚¹ãƒˆã¨åŸæ–™ã‚³ã‚¹ãƒˆã‚’æœ€å°åŒ–
"""

import numpy as np
from scipy.optimize import minimize, NonlinearConstraint
from typing import Dict, Tuple
import pandas as pd


class CSTROptimizer:
    """é€£ç¶šæ”ªæ‹Œæ§½åå¿œå™¨ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æœ€é©åŒ–"""

    def __init__(self):
        # ãƒ—ãƒ­ã‚»ã‚¹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.volume = 10.0  # åå¿œå™¨å®¹ç© [mÂ³]
        self.heat_capacity = 4.18  # ç†±å®¹é‡ [kJ/kgÂ·K]
        self.density = 1000.0  # å¯†åº¦ [kg/mÂ³]

        # åå¿œé€Ÿåº¦å®šæ•° (Arrheniuså¼)
        self.A1 = 1.2e10  # é »åº¦å› å­ï¼ˆä¸»åå¿œï¼‰ [1/h]
        self.E1 = 75000.0  # æ´»æ€§åŒ–ã‚¨ãƒãƒ«ã‚®ãƒ¼ï¼ˆä¸»åå¿œï¼‰ [J/mol]
        self.A2 = 3.5e9   # é »åº¦å› å­ï¼ˆå‰¯åå¿œï¼‰ [1/h]
        self.E2 = 68000.0  # æ´»æ€§åŒ–ã‚¨ãƒãƒ«ã‚®ãƒ¼ï¼ˆå‰¯åå¿œï¼‰ [J/mol]

        # çµŒæ¸ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.product_price = 150.0  # è£½å“ä¾¡æ ¼ [$/kg]
        self.byproduct_price = 40.0  # å‰¯ç”Ÿæˆç‰©ä¾¡æ ¼ [$/kg]
        self.feed_cost = 50.0  # åŸæ–™ã‚³ã‚¹ãƒˆ [$/kg]
        self.energy_cost = 0.08  # ã‚¨ãƒãƒ«ã‚®ãƒ¼ã‚³ã‚¹ãƒˆ [$/kWh]

        # ç‰©ç†åˆ¶ç´„
        self.T_min, self.T_max = 320.0, 380.0  # æ¸©åº¦ç¯„å›² [K]
        self.F_min, self.F_max = 0.5, 5.0      # æµé‡ç¯„å›² [mÂ³/h]
        self.T_feed = 298.0  # åŸæ–™æ¸©åº¦ [K]

    def reaction_rates(self, T: float) -> Tuple[float, float]:
        """åå¿œé€Ÿåº¦å®šæ•°ã‚’è¨ˆç®—ï¼ˆArrheniuså¼ï¼‰

        Args:
            T: åå¿œæ¸©åº¦ [K]

        Returns:
            (ä¸»åå¿œé€Ÿåº¦å®šæ•°, å‰¯åå¿œé€Ÿåº¦å®šæ•°) [1/h]
        """
        R = 8.314  # æ°—ä½“å®šæ•° [J/molÂ·K]
        k1 = self.A1 * np.exp(-self.E1 / (R * T))
        k2 = self.A2 * np.exp(-self.E2 / (R * T))
        return k1, k2

    def conversion_selectivity(self, T: float, tau: float) -> Tuple[float, float]:
        """åå¿œè»¢åŒ–ç‡ã¨é¸æŠæ€§ã‚’è¨ˆç®—

        Args:
            T: åå¿œæ¸©åº¦ [K]
            tau: æ»ç•™æ™‚é–“ [h]

        Returns:
            (è»¢åŒ–ç‡, é¸æŠæ€§)
        """
        k1, k2 = self.reaction_rates(T)

        # 1æ¬¡åå¿œã®è»¢åŒ–ç‡
        conversion = 1.0 - np.exp(-(k1 + k2) * tau)

        # é¸æŠæ€§ï¼ˆä¸»ç”Ÿæˆç‰© / å…¨ç”Ÿæˆç‰©ï¼‰
        selectivity = k1 / (k1 + k2)

        return conversion, selectivity

    def heating_power(self, T: float, F: float) -> float:
        """åŠ ç†±ã«å¿…è¦ãªé›»åŠ›ã‚’è¨ˆç®—

        Args:
            T: åå¿œæ¸©åº¦ [K]
            F: æµé‡ [mÂ³/h]

        Returns:
            åŠ ç†±é›»åŠ› [kW]
        """
        delta_T = T - self.T_feed
        mass_flow = F * self.density  # [kg/h]
        heat_duty = mass_flow * self.heat_capacity * delta_T  # [kJ/h]
        return heat_duty / 3600.0  # [kW]

    def objective(self, x: np.ndarray) -> float:
        """ç›®çš„é–¢æ•°ï¼šåˆ©ç›Šã®è² å€¤ã‚’è¨ˆç®—ï¼ˆæœ€å°åŒ–å•é¡Œã«å¤‰æ›ï¼‰

        Args:
            x: [æ¸©åº¦ [K], æµé‡ [mÂ³/h]]

        Returns:
            -åˆ©ç›Š [$/h]
        """
        T, F = x
        tau = self.volume / F  # æ»ç•™æ™‚é–“ [h]

        # è»¢åŒ–ç‡ã¨é¸æŠæ€§
        conversion, selectivity = self.conversion_selectivity(T, tau)

        # è£½å“ç”Ÿæˆé‡
        feed_mass = F * self.density  # [kg/h]
        product_mass = feed_mass * conversion * selectivity
        byproduct_mass = feed_mass * conversion * (1 - selectivity)

        # åç›Š
        revenue = (product_mass * self.product_price +
                  byproduct_mass * self.byproduct_price)

        # ã‚³ã‚¹ãƒˆ
        feed_cost_total = feed_mass * self.feed_cost
        energy_cost_total = self.heating_power(T, F) * self.energy_cost

        profit = revenue - feed_cost_total - energy_cost_total

        return -profit  # æœ€å°åŒ–ã®ãŸã‚è² å€¤

    def optimize(self, initial_guess: np.ndarray = None) -> Dict:
        """æœ€é©åŒ–ã‚’å®Ÿè¡Œ

        Args:
            initial_guess: åˆæœŸæ¨å®šå€¤ [æ¸©åº¦, æµé‡]

        Returns:
            æœ€é©åŒ–çµæœã®è¾æ›¸
        """
        if initial_guess is None:
            initial_guess = np.array([350.0, 2.0])  # [K, mÂ³/h]

        # å¢ƒç•Œåˆ¶ç´„
        bounds = [(self.T_min, self.T_max),
                 (self.F_min, self.F_max)]

        # éç·šå½¢åˆ¶ç´„ï¼šè»¢åŒ–ç‡ãŒ0.85ä»¥ä¸Šï¼ˆå®‰å…¨ãƒ»å“è³ªè¦ä»¶ï¼‰
        def conversion_constraint(x):
            T, F = x
            tau = self.volume / F
            conversion, _ = self.conversion_selectivity(T, tau)
            return conversion - 0.85

        nlc = NonlinearConstraint(conversion_constraint, 0, np.inf)

        # æœ€é©åŒ–å®Ÿè¡Œ
        result = minimize(
            self.objective,
            initial_guess,
            method='SLSQP',
            bounds=bounds,
            constraints=[nlc],
            options={'ftol': 1e-6, 'disp': False}
        )

        # çµæœã‚’æ•´ç†
        T_opt, F_opt = result.x
        tau_opt = self.volume / F_opt
        conversion, selectivity = self.conversion_selectivity(T_opt, tau_opt)

        return {
            'success': result.success,
            'temperature': T_opt,
            'flow_rate': F_opt,
            'residence_time': tau_opt,
            'conversion': conversion,
            'selectivity': selectivity,
            'profit_per_hour': -result.fun,
            'heating_power': self.heating_power(T_opt, F_opt)
        }


# ===================================
# å®Ÿè¡Œä¾‹
# ===================================
if __name__ == "__main__":
    optimizer = CSTROptimizer()

    print("="*70)
    print("CSTR ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æœ€é©åŒ–")
    print("="*70)

    # æœ€é©åŒ–å®Ÿè¡Œ
    result = optimizer.optimize()

    if result['success']:
        print("\nã€æœ€é©é‹è»¢æ¡ä»¶ã€‘")
        print(f"  åå¿œæ¸©åº¦: {result['temperature']:.1f} K ({result['temperature']-273.15:.1f} Â°C)")
        print(f"  æµé‡: {result['flow_rate']:.2f} mÂ³/h")
        print(f"  æ»ç•™æ™‚é–“: {result['residence_time']:.2f} h")
        print(f"\nã€ãƒ—ãƒ­ã‚»ã‚¹æ€§èƒ½ã€‘")
        print(f"  è»¢åŒ–ç‡: {result['conversion']:.1%}")
        print(f"  é¸æŠæ€§: {result['selectivity']:.1%}")
        print(f"  åŠ ç†±é›»åŠ›: {result['heating_power']:.1f} kW")
        print(f"\nã€çµŒæ¸ˆæ€§ã€‘")
        print(f"  åˆ©ç›Š: ${result['profit_per_hour']:.2f}/h")
        print(f"  å¹´é–“åˆ©ç›Š: ${result['profit_per_hour'] * 8760:.0f}/year")
    else:
        print("æœ€é©åŒ–ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")

    # æ„Ÿåº¦åˆ†æï¼šåŸæ–™ä¾¡æ ¼ã®å¤‰å‹•ã«å¯¾ã™ã‚‹æœ€é©æ¡ä»¶ã®å¤‰åŒ–
    print("\n" + "="*70)
    print("æ„Ÿåº¦åˆ†æï¼šåŸæ–™ä¾¡æ ¼ã®å½±éŸ¿")
    print("="*70)

    feed_costs = [40, 50, 60, 70]
    results = []

    for cost in feed_costs:
        optimizer.feed_cost = cost
        res = optimizer.optimize()
        results.append({
            'åŸæ–™ã‚³ã‚¹ãƒˆ [$/kg]': cost,
            'æœ€é©æ¸©åº¦ [K]': res['temperature'],
            'æœ€é©æµé‡ [mÂ³/h]': res['flow_rate'],
            'æ™‚é–“åˆ©ç›Š [$/h]': res['profit_per_hour']
        })

    df = pd.DataFrame(results)
    print(df.to_string(index=False))

    print("\nâœ“ åŸæ–™ä¾¡æ ¼ä¸Šæ˜‡æ™‚ã¯é«˜æ¸©ãƒ»ä½æµé‡ã«æœ€é©åŒ–ï¼ˆé¸æŠæ€§é‡è¦–ï¼‰")
</code></pre>
        </div>

        <h2>3.3 çµŒæ¸ˆçš„æœ€é©åŒ–ï¼ˆPyomoï¼‰</h2>

        <p>ã‚ˆã‚Šè¤‡é›‘ãªæœ€é©åŒ–å•é¡Œã§ã¯ã€ä»£æ•°çš„ãƒ¢ãƒ‡ãƒªãƒ³ã‚°è¨€èªPyomoã‚’ä½¿ç”¨ã—ã¾ã™ã€‚è£½å“ä¾¡å€¤ã®æœ€å¤§åŒ–ã¨ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚³ã‚¹ãƒˆã®æœ€å°åŒ–ã‚’åŒæ™‚ã«è€ƒæ…®ã—ãŸå®šå¼åŒ–ã‚’å®Ÿè£…ã—ã¾ã™ã€‚</p>

        <div class="code-block">
            <div class="code-title">Example 2: çµŒæ¸ˆçš„æœ€é©åŒ–ï¼ˆPyomoï¼‰ - è£½å“ä¾¡å€¤æœ€å¤§åŒ–ã¨ã‚³ã‚¹ãƒˆæœ€å°åŒ–</div>
            <pre><code>"""
===================================
Example 2: çµŒæ¸ˆçš„æœ€é©åŒ–ï¼ˆPyomoï¼‰
===================================

Pyomoã‚’ç”¨ã„ãŸåŒ–å­¦ãƒ—ãƒ©ãƒ³ãƒˆã®çµŒæ¸ˆæœ€é©åŒ–ã€‚
è¤‡æ•°ã®è£½å“ã‚’æŒã¤ãƒ—ãƒ­ã‚»ã‚¹ã«ãŠã„ã¦ã€è£½å“ä¾¡å€¤ã‚’æœ€å¤§åŒ–ã—ãªãŒã‚‰
ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚³ã‚¹ãƒˆï¼ˆè’¸æ°—ã€é›»åŠ›ã€å†·å´æ°´ï¼‰ã‚’æœ€å°åŒ–ã™ã‚‹ã€‚

Pyomoã¯å®Ÿéš›ã«ã¯ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãŒå¿…è¦ã§ã™ãŒã€ã“ã“ã§ã¯æ¦‚å¿µçš„ãªå®Ÿè£…ã‚’ç¤ºã—ã¾ã™ã€‚
"""

import numpy as np
from scipy.optimize import minimize
from typing import Dict, List
import pandas as pd


class EconomicOptimizer:
    """åŒ–å­¦ãƒ—ãƒ©ãƒ³ãƒˆã®çµŒæ¸ˆæœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ """

    def __init__(self):
        # è£½å“ä¾¡æ ¼ [$/ton]
        self.product_prices = {
            'ProductA': 800.0,   # é«˜ä»˜åŠ ä¾¡å€¤è£½å“
            'ProductB': 500.0,   # ä¸­é–“è£½å“
            'ProductC': 300.0    # æ±ç”¨è£½å“
        }

        # ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚³ã‚¹ãƒˆ
        self.steam_cost = 25.0    # è’¸æ°— [$/ton]
        self.power_cost = 0.10    # é›»åŠ› [$/kWh]
        self.cooling_cost = 0.5   # å†·å´æ°´ [$/ton]

        # ãƒ—ãƒ­ã‚»ã‚¹åˆ¶ç´„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.max_capacity = 100.0  # æœ€å¤§å‡¦ç†èƒ½åŠ› [ton/h]
        self.min_turndown = 0.4    # æœ€å°è² è·ç‡

    def production_model(self, feed_rate: float, temperature: float,
                        pressure: float) -> Dict[str, float]:
        """ç”Ÿç”£ãƒ¢ãƒ‡ãƒ«ï¼šæ“ä½œæ¡ä»¶ã‹ã‚‰è£½å“åç‡ã‚’è¨ˆç®—

        Args:
            feed_rate: åŸæ–™æµé‡ [ton/h]
            temperature: åå¿œæ¸©åº¦ [K]
            pressure: åå¿œåœ§åŠ› [bar]

        Returns:
            å„è£½å“ã®ç”Ÿç”£é‡ [ton/h]
        """
        # ç°¡ç•¥åŒ–ã—ãŸåç‡ãƒ¢ãƒ‡ãƒ«ï¼ˆå®Ÿéš›ã¯è©³ç´°ãªåå¿œãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ï¼‰
        T_ref = 400.0  # åŸºæº–æ¸©åº¦ [K]
        P_ref = 20.0   # åŸºæº–åœ§åŠ› [bar]

        # æ¸©åº¦ãƒ»åœ§åŠ›ã®å½±éŸ¿å› å­
        temp_factor = np.exp(-0.005 * (temperature - T_ref)**2)
        press_factor = 1.0 + 0.02 * (pressure - P_ref)

        # å„è£½å“ã®åŸºæº–åç‡
        yield_A_base = 0.35 * temp_factor * press_factor
        yield_B_base = 0.45 * (2.0 - temp_factor)
        yield_C_base = 0.20

        # åç‡åˆ¶ç´„ï¼ˆåˆè¨ˆâ‰¤1.0ï¼‰
        total_yield = yield_A_base + yield_B_base + yield_C_base
        if total_yield > 1.0:
            scale = 1.0 / total_yield
            yield_A_base *= scale
            yield_B_base *= scale
            yield_C_base *= scale

        return {
            'ProductA': feed_rate * yield_A_base,
            'ProductB': feed_rate * yield_B_base,
            'ProductC': feed_rate * yield_C_base
        }

    def utility_consumption(self, feed_rate: float, temperature: float,
                           pressure: float) -> Dict[str, float]:
        """ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£æ¶ˆè²»é‡ã‚’è¨ˆç®—

        Args:
            feed_rate: åŸæ–™æµé‡ [ton/h]
            temperature: åå¿œæ¸©åº¦ [K]
            pressure: åå¿œåœ§åŠ› [bar]

        Returns:
            ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£æ¶ˆè²»é‡
        """
        # è’¸æ°—æ¶ˆè²»ï¼ˆåŠ ç†±è² è·ã«æ¯”ä¾‹ï¼‰
        T_feed = 298.0  # åŸæ–™æ¸©åº¦ [K]
        heating_load = feed_rate * 2.5 * (temperature - T_feed)  # ç°¡ç•¥å¼
        steam = heating_load / 2000.0  # [ton/h]

        # é›»åŠ›æ¶ˆè²»ï¼ˆåœ§ç¸®æ©Ÿã€ãƒãƒ³ãƒ—ã€æ”ªæ‹Œï¼‰
        compressor_power = 50.0 * (pressure / 20.0)**0.8  # [kW]
        pump_power = 10.0 * feed_rate
        agitator_power = 15.0
        power = compressor_power + pump_power + agitator_power

        # å†·å´æ°´ï¼ˆåå¿œç†±é™¤å»ï¼‰
        exothermic_heat = feed_rate * 500.0  # [kW] (ä»®å®š)
        cooling_water = exothermic_heat / 40.0  # [ton/h]

        return {
            'steam': steam,
            'power': power,
            'cooling': cooling_water
        }

    def objective_function(self, x: np.ndarray) -> float:
        """ç›®çš„é–¢æ•°ï¼šåˆ©ç›Šã®è² å€¤ï¼ˆæœ€å°åŒ–å•é¡Œï¼‰

        Args:
            x: [feed_rate, temperature, pressure]

        Returns:
            -åˆ©ç›Š [$/h]
        """
        feed_rate, temperature, pressure = x

        # è£½å“ç”Ÿç”£é‡
        products = self.production_model(feed_rate, temperature, pressure)

        # åç›Š
        revenue = sum(
            products[prod] * self.product_prices[prod]
            for prod in products
        )

        # ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£æ¶ˆè²»
        utilities = self.utility_consumption(feed_rate, temperature, pressure)

        # ã‚³ã‚¹ãƒˆ
        utility_cost = (
            utilities['steam'] * self.steam_cost +
            utilities['power'] * self.power_cost +
            utilities['cooling'] * self.cooling_cost
        )

        # åŸæ–™ã‚³ã‚¹ãƒˆï¼ˆä»®å®š: $200/tonï¼‰
        feed_cost = feed_rate * 200.0

        profit = revenue - utility_cost - feed_cost

        return -profit

    def optimize_economics(self) -> Dict:
        """çµŒæ¸ˆæœ€é©åŒ–ã‚’å®Ÿè¡Œ

        Returns:
            æœ€é©åŒ–çµæœ
        """
        # åˆæœŸæ¨å®šå€¤: [feed_rate, temperature, pressure]
        x0 = np.array([60.0, 400.0, 20.0])

        # å¢ƒç•Œåˆ¶ç´„
        bounds = [
            (self.max_capacity * self.min_turndown, self.max_capacity),  # feed_rate
            (350.0, 450.0),  # temperature [K]
            (10.0, 40.0)     # pressure [bar]
        ]

        # æœ€é©åŒ–
        result = minimize(
            self.objective_function,
            x0,
            method='L-BFGS-B',
            bounds=bounds,
            options={'ftol': 1e-6}
        )

        feed_opt, temp_opt, press_opt = result.x

        # çµæœã‚’æ•´ç†
        products = self.production_model(feed_opt, temp_opt, press_opt)
        utilities = self.utility_consumption(feed_opt, temp_opt, press_opt)

        return {
            'success': result.success,
            'feed_rate': feed_opt,
            'temperature': temp_opt,
            'pressure': press_opt,
            'products': products,
            'utilities': utilities,
            'profit_per_hour': -result.fun
        }


# ===================================
# å®Ÿè¡Œä¾‹
# ===================================
if __name__ == "__main__":
    optimizer = EconomicOptimizer()

    print("="*70)
    print("åŒ–å­¦ãƒ—ãƒ©ãƒ³ãƒˆçµŒæ¸ˆæœ€é©åŒ–")
    print("="*70)

    result = optimizer.optimize_economics()

    if result['success']:
        print("\nã€æœ€é©é‹è»¢æ¡ä»¶ã€‘")
        print(f"  åŸæ–™æµé‡: {result['feed_rate']:.1f} ton/h")
        print(f"  åå¿œæ¸©åº¦: {result['temperature']:.1f} K ({result['temperature']-273.15:.1f} Â°C)")
        print(f"  åå¿œåœ§åŠ›: {result['pressure']:.1f} bar")

        print("\nã€è£½å“ç”Ÿç”£é‡ã€‘")
        for prod, amount in result['products'].items():
            price = optimizer.product_prices[prod]
            value = amount * price
            print(f"  {prod}: {amount:.2f} ton/h (ä¾¡å€¤: ${value:.2f}/h)")

        print("\nã€ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£æ¶ˆè²»ã€‘")
        util = result['utilities']
        print(f"  è’¸æ°—: {util['steam']:.2f} ton/h (${util['steam'] * optimizer.steam_cost:.2f}/h)")
        print(f"  é›»åŠ›: {util['power']:.1f} kW (${util['power'] * optimizer.power_cost:.2f}/h)")
        print(f"  å†·å´æ°´: {util['cooling']:.2f} ton/h (${util['cooling'] * optimizer.cooling_cost:.2f}/h)")

        print("\nã€çµŒæ¸ˆæ€§ã€‘")
        print(f"  æ™‚é–“åˆ©ç›Š: ${result['profit_per_hour']:.2f}/h")
        print(f"  æ—¥é–“åˆ©ç›Š: ${result['profit_per_hour'] * 24:.2f}/day")
        print(f"  å¹´é–“åˆ©ç›Š: ${result['profit_per_hour'] * 8760:.0f}/year")

    # è£½å“ä¾¡æ ¼ã®å¤‰å‹•ã«å¯¾ã™ã‚‹æ„Ÿåº¦åˆ†æ
    print("\n" + "="*70)
    print("æ„Ÿåº¦åˆ†æï¼šè£½å“Aä¾¡æ ¼ã®å½±éŸ¿")
    print("="*70)

    original_price = optimizer.product_prices['ProductA']
    price_scenarios = [600, 700, 800, 900, 1000]
    results_table = []

    for price in price_scenarios:
        optimizer.product_prices['ProductA'] = price
        res = optimizer.optimize_economics()
        results_table.append({
            'è£½å“Aä¾¡æ ¼ [$/ton]': price,
            'æœ€é©æµé‡ [ton/h]': res['feed_rate'],
            'æœ€é©æ¸©åº¦ [K]': res['temperature'],
            'è£½å“Aç”Ÿç”£é‡ [ton/h]': res['products']['ProductA'],
            'æ™‚é–“åˆ©ç›Š [$/h]': res['profit_per_hour']
        })

    df = pd.DataFrame(results_table)
    print(df.to_string(index=False))

    print("\nâœ“ é«˜ä»˜åŠ ä¾¡å€¤è£½å“ã®ä¾¡æ ¼ä¸Šæ˜‡æ™‚ã€é«˜æ¸©é‹è»¢ã§åç‡ã‚’æœ€å¤§åŒ–")
</code></pre>
        </div>

        <h2>3.4 ãƒ¢ãƒ‡ãƒ«äºˆæ¸¬åˆ¶å¾¡ï¼ˆMPCï¼‰</h2>

        <p>Model Predictive Controlï¼ˆMPCï¼‰ã¯ã€ãƒ—ãƒ­ã‚»ã‚¹ã®å‹•çš„ãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ã¦æœªæ¥ã®æŒ™å‹•ã‚’äºˆæ¸¬ã—ã€åˆ¶ç´„æ¡ä»¶ã‚’æº€ãŸã—ãªãŒã‚‰æ“ä½œé‡ã‚’æœ€é©åŒ–ã™ã‚‹å…ˆé€²åˆ¶å¾¡æ‰‹æ³•ã§ã™ã€‚è’¸ç•™å¡”ã®æ¸©åº¦åˆ¶å¾¡ã‚’ä¾‹ã«åŸºç¤å®Ÿè£…ã‚’ç¤ºã—ã¾ã™ã€‚</p>

        <div class="code-block">
            <div class="code-title">Example 3: MPCã®åŸºç¤å®Ÿè£… - è’¸ç•™å¡”æ¸©åº¦åˆ¶å¾¡</div>
            <pre><code>"""
===================================
Example 3: MPCã®åŸºç¤å®Ÿè£…
===================================

è’¸ç•™å¡”ã«ãŠã‘ã‚‹æ¸©åº¦åˆ¶å¾¡ã«Model Predictive Controlï¼ˆMPCï¼‰ã‚’é©ç”¨ã€‚
æœªæ¥ã®æŒ™å‹•ã‚’äºˆæ¸¬ã—ãªãŒã‚‰ã€ãƒªãƒ•ãƒ©ãƒƒã‚¯ã‚¹æ¯”ã¨é‚„æµé‡ã‚’æœ€é©åŒ–ã€‚

MPCã®ç‰¹é•·ï¼š
- å¤šå¤‰æ•°åˆ¶å¾¡ï¼ˆè¤‡æ•°ã®æ“ä½œå¤‰æ•°ãƒ»åˆ¶å¾¡å¤‰æ•°ï¼‰
- åˆ¶ç´„æ¡ä»¶ã®æ˜ç¤ºçš„ãªè€ƒæ…®
- å¤–ä¹±ã®äºˆæ¸¬ã¨è£œå„Ÿ
"""

import numpy as np
from scipy.optimize import minimize
from typing import List, Tuple
import matplotlib.pyplot as plt


class DistillationMPC:
    """è’¸ç•™å¡”ã®ãƒ¢ãƒ‡ãƒ«äºˆæ¸¬åˆ¶å¾¡"""

    def __init__(self, prediction_horizon: int = 10, control_horizon: int = 5):
        """
        Args:
            prediction_horizon: äºˆæ¸¬ãƒ›ãƒ©ã‚¤ã‚ºãƒ³ï¼ˆã‚¹ãƒ†ãƒƒãƒ—æ•°ï¼‰
            control_horizon: åˆ¶å¾¡ãƒ›ãƒ©ã‚¤ã‚ºãƒ³ï¼ˆã‚¹ãƒ†ãƒƒãƒ—æ•°ï¼‰
        """
        self.Np = prediction_horizon
        self.Nc = control_horizon
        self.dt = 1.0  # ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ™‚é–“ [min]

        # ãƒ—ãƒ­ã‚»ã‚¹ãƒ¢ãƒ‡ãƒ«ï¼ˆçŠ¶æ…‹ç©ºé–“ãƒ¢ãƒ‡ãƒ«ï¼‰
        # x[k+1] = A*x[k] + B*u[k]
        # y[k] = C*x[k]
        # çŠ¶æ…‹: x = [å¡”é ‚æ¸©åº¦åå·®, å¡”åº•æ¸©åº¦åå·®]
        # å…¥åŠ›: u = [ãƒªãƒ•ãƒ©ãƒƒã‚¯ã‚¹æ¯”å¤‰åŒ–, é‚„æµé‡å¤‰åŒ–]
        # å‡ºåŠ›: y = [å¡”é ‚æ¸©åº¦, å¡”åº•æ¸©åº¦]

        self.A = np.array([
            [0.85, 0.10],
            [0.05, 0.90]
        ])
        self.B = np.array([
            [0.5, 0.1],
            [0.1, 0.4]
        ])
        self.C = np.eye(2)

        # åˆ¶ç´„æ¡ä»¶
        self.u_min = np.array([-2.0, -5.0])  # [ãƒªãƒ•ãƒ©ãƒƒã‚¯ã‚¹æ¯”, é‚„æµé‡ kg/min]
        self.u_max = np.array([2.0, 5.0])
        self.delta_u_max = np.array([0.5, 1.0])  # å¤‰åŒ–ç‡åˆ¶ç´„

        # é‡ã¿è¡Œåˆ—
        self.Q = np.diag([10.0, 8.0])   # å‡ºåŠ›è¿½å¾“ã®é‡ã¿
        self.R = np.diag([1.0, 1.0])    # å…¥åŠ›å¤‰åŒ–ã®é‡ã¿

    def predict(self, x0: np.ndarray, u_sequence: np.ndarray) -> np.ndarray:
        """äºˆæ¸¬ãƒ›ãƒ©ã‚¤ã‚ºãƒ³ã«ã‚ãŸã‚‹å‡ºåŠ›ã‚’äºˆæ¸¬

        Args:
            x0: ç¾åœ¨ã®çŠ¶æ…‹
            u_sequence: å…¥åŠ›ç³»åˆ— (Nc x 2)

        Returns:
            äºˆæ¸¬å‡ºåŠ›ç³»åˆ— (Np x 2)
        """
        x = x0.copy()
        y_pred = np.zeros((self.Np, 2))

        for k in range(self.Np):
            # åˆ¶å¾¡ãƒ›ãƒ©ã‚¤ã‚ºãƒ³å†…ã¯æœ€é©åŒ–å¤‰æ•°ã€ãã‚Œä»¥é™ã¯æœ€å¾Œã®å€¤ã‚’ä¿æŒ
            if k < self.Nc:
                u = u_sequence[k]
            else:
                u = u_sequence[-1]

            # çŠ¶æ…‹æ›´æ–°
            x = self.A @ x + self.B @ u

            # å‡ºåŠ›è¨ˆç®—
            y_pred[k] = self.C @ x

        return y_pred

    def mpc_objective(self, u_flat: np.ndarray, x0: np.ndarray,
                     r: np.ndarray, u_prev: np.ndarray) -> float:
        """MPCç›®çš„é–¢æ•°

        Args:
            u_flat: å¹³å¦åŒ–ã•ã‚ŒãŸå…¥åŠ›ç³»åˆ— (Nc*2,)
            x0: ç¾åœ¨ã®çŠ¶æ…‹
            r: ç›®æ¨™å€¤ç³»åˆ— (Np x 2)
            u_prev: å‰ã‚¹ãƒ†ãƒƒãƒ—ã®å…¥åŠ›

        Returns:
            è©•ä¾¡é–¢æ•°å€¤
        """
        # å…¥åŠ›ç³»åˆ—ã‚’å†æ§‹æˆ
        u_sequence = u_flat.reshape(self.Nc, 2)

        # äºˆæ¸¬
        y_pred = self.predict(x0, u_sequence)

        # è¿½å¾“èª¤å·®
        tracking_error = 0.0
        for k in range(self.Np):
            e = y_pred[k] - r[k]
            tracking_error += e.T @ self.Q @ e

        # å…¥åŠ›å¤‰åŒ–ãƒšãƒŠãƒ«ãƒ†ã‚£
        control_effort = 0.0
        for k in range(self.Nc):
            if k == 0:
                du = u_sequence[k] - u_prev
            else:
                du = u_sequence[k] - u_sequence[k-1]
            control_effort += du.T @ self.R @ du

        return tracking_error + control_effort

    def solve(self, x0: np.ndarray, r: np.ndarray,
             u_prev: np.ndarray) -> np.ndarray:
        """MPCæœ€é©åŒ–å•é¡Œã‚’è§£ã

        Args:
            x0: ç¾åœ¨ã®çŠ¶æ…‹
            r: ç›®æ¨™å€¤ç³»åˆ— (Np x 2)
            u_prev: å‰ã‚¹ãƒ†ãƒƒãƒ—ã®å…¥åŠ›

        Returns:
            æœ€é©å…¥åŠ›ç³»åˆ—ã®æœ€åˆã®å€¤ (2,)
        """
        # åˆæœŸæ¨å®šå€¤
        u0_flat = np.zeros(self.Nc * 2)

        # å¢ƒç•Œåˆ¶ç´„
        bounds = []
        for _ in range(self.Nc):
            bounds.extend([
                (self.u_min[0], self.u_max[0]),
                (self.u_min[1], self.u_max[1])
            ])

        # å¤‰åŒ–ç‡åˆ¶ç´„
        def delta_u_constraint(u_flat):
            u_seq = u_flat.reshape(self.Nc, 2)
            violations = []
            for k in range(self.Nc):
                if k == 0:
                    du = np.abs(u_seq[k] - u_prev)
                else:
                    du = np.abs(u_seq[k] - u_seq[k-1])
                violations.extend((self.delta_u_max - du).tolist())
            return np.array(violations)

        from scipy.optimize import NonlinearConstraint
        nlc = NonlinearConstraint(delta_u_constraint, 0, np.inf)

        # æœ€é©åŒ–
        result = minimize(
            lambda u: self.mpc_objective(u, x0, r, u_prev),
            u0_flat,
            method='SLSQP',
            bounds=bounds,
            constraints=[nlc],
            options={'ftol': 1e-4, 'disp': False}
        )

        u_opt = result.x.reshape(self.Nc, 2)
        return u_opt[0]  # æœ€åˆã®ã‚¹ãƒ†ãƒƒãƒ—ã®ã¿å®Ÿè¡Œ


# ===================================
# ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
# ===================================
if __name__ == "__main__":
    mpc = DistillationMPC(prediction_horizon=10, control_horizon=5)

    # ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®š
    T_sim = 50  # ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ™‚é–“ [min]
    x = np.zeros(2)  # åˆæœŸçŠ¶æ…‹ï¼ˆç›®æ¨™å€¤ã‹ã‚‰ã®åå·®ï¼‰
    u = np.zeros(2)  # åˆæœŸå…¥åŠ›

    # ç›®æ¨™å€¤ã®å¤‰åŒ–ï¼ˆã‚¹ãƒ†ãƒƒãƒ—å¤‰åŒ–ï¼‰
    r_top = np.zeros(T_sim)
    r_bottom = np.zeros(T_sim)
    r_top[10:] = -1.5  # 10åˆ†å¾Œã«å¡”é ‚æ¸©åº¦ã‚’1.5â„ƒä¸‹ã’ã‚‹
    r_bottom[30:] = 1.0  # 30åˆ†å¾Œã«å¡”åº•æ¸©åº¦ã‚’1.0â„ƒä¸Šã’ã‚‹

    # è¨˜éŒ²ç”¨
    x_history = [x.copy()]
    u_history = [u.copy()]

    print("="*70)
    print("è’¸ç•™å¡”MPCåˆ¶å¾¡ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³")
    print("="*70)

    for k in range(T_sim):
        # ç›®æ¨™å€¤ç³»åˆ—ï¼ˆäºˆæ¸¬ãƒ›ãƒ©ã‚¤ã‚ºãƒ³åˆ†ï¼‰
        r_horizon = np.zeros((mpc.Np, 2))
        for i in range(mpc.Np):
            if k + i < T_sim:
                r_horizon[i] = [r_top[k+i], r_bottom[k+i]]
            else:
                r_horizon[i] = [r_top[-1], r_bottom[-1]]

        # MPCã§æœ€é©å…¥åŠ›ã‚’è¨ˆç®—
        u = mpc.solve(x, r_horizon, u)

        # ãƒ—ãƒ­ã‚»ã‚¹æ›´æ–°ï¼ˆå¤–ä¹±ã‚’åŠ ãˆã‚‹ï¼‰
        disturbance = np.random.randn(2) * 0.05
        x = mpc.A @ x + mpc.B @ u + disturbance

        # è¨˜éŒ²
        x_history.append(x.copy())
        u_history.append(u.copy())

        if k % 10 == 0:
            print(f"æ™‚åˆ» {k:2d}åˆ†: å¡”é ‚åå·®={x[0]:+.2f}â„ƒ, å¡”åº•åå·®={x[1]:+.2f}â„ƒ, "
                  f"ãƒªãƒ•ãƒ©ãƒƒã‚¯ã‚¹={u[0]:+.2f}, é‚„æµ={u[1]:+.2f} kg/min")

    # çµæœã‚’é…åˆ—ã«å¤‰æ›
    x_history = np.array(x_history)
    u_history = np.array(u_history)

    print("\n" + "="*70)
    print("åˆ¶å¾¡æ€§èƒ½è©•ä¾¡")
    print("="*70)

    # å®šå¸¸åå·®
    steady_state_error_top = np.abs(x_history[-10:, 0] - r_top[-1]).mean()
    steady_state_error_bottom = np.abs(x_history[-10:, 1] - r_bottom[-1]).mean()

    print(f"å¡”é ‚æ¸©åº¦ã®å®šå¸¸åå·®: {steady_state_error_top:.3f} â„ƒ")
    print(f"å¡”åº•æ¸©åº¦ã®å®šå¸¸åå·®: {steady_state_error_bottom:.3f} â„ƒ")
    print(f"\nâœ“ MPCã«ã‚ˆã‚Šåˆ¶ç´„æ¡ä»¶ä¸‹ã§é«˜ç²¾åº¦ãªæ¸©åº¦åˆ¶å¾¡ã‚’é”æˆ")
    print(f"âœ“ è¤‡æ•°ã®è¨­å®šå€¤å¤‰æ›´ã«å¯¾ã—ã¦ã‚‚è‰¯å¥½ãªè¿½å¾“æ€§èƒ½")
</code></pre>
        </div>

        <h2>3.5 éç·šå½¢MPCï¼ˆCasADiï¼‰</h2>

        <p>éç·šå½¢ãƒ—ãƒ­ã‚»ã‚¹ã«å¯¾ã—ã¦ã¯ã€éç·šå½¢MPCãŒå¿…è¦ã§ã™ã€‚CasADiã‚’ç”¨ã„ãŸåå¿œå™¨ã®éç·šå½¢MPCå®Ÿè£…ã‚’ç¤ºã—ã¾ã™ï¼ˆæ¦‚å¿µçš„å®Ÿè£…ï¼‰ã€‚</p>

        <div class="code-block">
            <div class="code-title">Example 4: éç·šå½¢MPCï¼ˆCasADiï¼‰ - åå¿œå™¨ã®éç·šå½¢åˆ¶å¾¡</div>
            <pre><code>"""
===================================
Example 4: éç·šå½¢MPCï¼ˆCasADiï¼‰
===================================

CasADiã‚’ç”¨ã„ãŸéç·šå½¢ãƒ¢ãƒ‡ãƒ«äºˆæ¸¬åˆ¶å¾¡ã€‚
é€£ç¶šæ”ªæ‹Œæ§½åå¿œå™¨ï¼ˆCSTRï¼‰ã®æ¿ƒåº¦ã¨æ¸©åº¦ã‚’åŒæ™‚åˆ¶å¾¡ã€‚

éç·šå½¢ãƒ—ãƒ­ã‚»ã‚¹ãƒ¢ãƒ‡ãƒ«ï¼š
- è³ªé‡ãƒãƒ©ãƒ³ã‚¹: dC/dt = (C_in - C)/tau - k*C
- ã‚¨ãƒãƒ«ã‚®ãƒ¼ãƒãƒ©ãƒ³ã‚¹: dT/dt = (T_in - T)/tau + (-Î”H)*k*C/(Ï*Cp) + Q/(V*Ï*Cp)

CasADiã¯å®Ÿéš›ã«ã¯ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãŒå¿…è¦ã§ã™ãŒã€ã“ã“ã§ã¯æ•°å€¤çš„ãªå®Ÿè£…ã§ä»£æ›¿ã—ã¾ã™ã€‚
"""

import numpy as np
from scipy.integrate import odeint
from scipy.optimize import minimize
from typing import Tuple


class NonlinearCSTRMPC:
    """éç·šå½¢CSTRåå¿œå™¨ã®MPC"""

    def __init__(self, prediction_horizon: int = 20, control_horizon: int = 10):
        self.Np = prediction_horizon
        self.Nc = control_horizon
        self.dt = 0.5  # ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ™‚é–“ [min]

        # ãƒ—ãƒ­ã‚»ã‚¹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.V = 1.0  # åå¿œå™¨å®¹ç© [mÂ³]
        self.rho = 1000.0  # å¯†åº¦ [kg/mÂ³]
        self.Cp = 4.18  # æ¯”ç†± [kJ/kgÂ·K]
        self.delta_H = -50000.0  # åå¿œç†± [kJ/kmol]

        # Arrheniusåå¿œé€Ÿåº¦
        self.A = 1.0e10  # é »åº¦å› å­ [1/min]
        self.Ea = 75000.0  # æ´»æ€§åŒ–ã‚¨ãƒãƒ«ã‚®ãƒ¼ [J/mol]
        self.R = 8.314  # æ°—ä½“å®šæ•° [J/molÂ·K]

        # æ“ä½œå¤‰æ•°ã®åˆ¶ç´„
        self.F_min, self.F_max = 0.02, 0.20  # æµé‡ [mÂ³/min]
        self.Q_min, self.Q_max = -5000, 5000  # åŠ ç†±ãƒ»å†·å´ [kJ/min]

        # å…¥åŠ›
        self.C_in = 10.0  # å…¥å£æ¿ƒåº¦ [kmol/mÂ³]
        self.T_in = 300.0  # å…¥å£æ¸©åº¦ [K]

    def reaction_rate(self, C: float, T: float) -> float:
        """åå¿œé€Ÿåº¦å®šæ•°ï¼ˆArrheniuså¼ï¼‰"""
        return self.A * np.exp(-self.Ea / (self.R * T)) * C

    def cstr_model(self, state: np.ndarray, t: float,
                   F: float, Q: float) -> np.ndarray:
        """CSTRåå¿œå™¨ã®å¾®åˆ†æ–¹ç¨‹å¼

        Args:
            state: [æ¿ƒåº¦ C, æ¸©åº¦ T]
            t: æ™‚é–“
            F: æµé‡ [mÂ³/min]
            Q: åŠ ç†±é‡ [kJ/min]

        Returns:
            [dC/dt, dT/dt]
        """
        C, T = state
        tau = self.V / F  # æ»ç•™æ™‚é–“

        # åå¿œé€Ÿåº¦
        r = self.reaction_rate(C, T)

        # è³ªé‡ãƒãƒ©ãƒ³ã‚¹
        dC_dt = (self.C_in - C) / tau - r

        # ã‚¨ãƒãƒ«ã‚®ãƒ¼ãƒãƒ©ãƒ³ã‚¹
        heat_reaction = (-self.delta_H) * r / (self.rho * self.Cp)
        heat_exchange = Q / (self.V * self.rho * self.Cp)
        dT_dt = (self.T_in - T) / tau + heat_reaction + heat_exchange

        return np.array([dC_dt, dT_dt])

    def simulate_step(self, state: np.ndarray,
                     F: float, Q: float) -> np.ndarray:
        """1ã‚¹ãƒ†ãƒƒãƒ—åˆ†ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³

        Args:
            state: [C, T]
            F: æµé‡
            Q: åŠ ç†±é‡

        Returns:
            æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã®çŠ¶æ…‹
        """
        t_span = [0, self.dt]
        result = odeint(self.cstr_model, state, t_span, args=(F, Q))
        return result[-1]

    def predict_trajectory(self, state0: np.ndarray,
                          u_sequence: np.ndarray) -> np.ndarray:
        """äºˆæ¸¬è»Œé“ã‚’è¨ˆç®—

        Args:
            state0: åˆæœŸçŠ¶æ…‹ [C, T]
            u_sequence: å…¥åŠ›ç³»åˆ— (Nc x 2) [F, Q]

        Returns:
            äºˆæ¸¬çŠ¶æ…‹ç³»åˆ— (Np x 2)
        """
        state = state0.copy()
        trajectory = np.zeros((self.Np, 2))

        for k in range(self.Np):
            if k < self.Nc:
                F, Q = u_sequence[k]
            else:
                F, Q = u_sequence[-1]

            state = self.simulate_step(state, F, Q)
            trajectory[k] = state

        return trajectory

    def mpc_objective(self, u_flat: np.ndarray, state0: np.ndarray,
                     setpoint: np.ndarray) -> float:
        """éç·šå½¢MPCç›®çš„é–¢æ•°

        Args:
            u_flat: å¹³å¦åŒ–ã•ã‚ŒãŸå…¥åŠ›ç³»åˆ—
            state0: ç¾åœ¨ã®çŠ¶æ…‹
            setpoint: ç›®æ¨™å€¤ [C_sp, T_sp]

        Returns:
            è©•ä¾¡é–¢æ•°å€¤
        """
        u_sequence = u_flat.reshape(self.Nc, 2)

        # äºˆæ¸¬è»Œé“
        trajectory = self.predict_trajectory(state0, u_sequence)

        # è¿½å¾“èª¤å·®ï¼ˆé‡ã¿ä»˜ãäºŒä¹—å’Œï¼‰
        Q = np.diag([10.0, 5.0])  # æ¿ƒåº¦ã¨æ¸©åº¦ã®é‡ã¿
        tracking_cost = 0.0
        for k in range(self.Np):
            error = trajectory[k] - setpoint
            tracking_cost += error.T @ Q @ error

        # å…¥åŠ›å¤‰åŒ–ã®ãƒšãƒŠãƒ«ãƒ†ã‚£
        R = np.diag([100.0, 0.01])  # æµé‡ã¨åŠ ç†±é‡ã®é‡ã¿
        control_cost = 0.0
        for k in range(self.Nc):
            if k > 0:
                du = u_sequence[k] - u_sequence[k-1]
                control_cost += du.T @ R @ du

        return tracking_cost + control_cost

    def solve(self, state0: np.ndarray, setpoint: np.ndarray,
             u_prev: np.ndarray) -> np.ndarray:
        """éç·šå½¢MPCæœ€é©åŒ–

        Args:
            state0: ç¾åœ¨ã®çŠ¶æ…‹
            setpoint: ç›®æ¨™å€¤
            u_prev: å‰ã‚¹ãƒ†ãƒƒãƒ—ã®å…¥åŠ›

        Returns:
            æœ€é©å…¥åŠ›
        """
        # åˆæœŸæ¨å®šå€¤ï¼ˆå‰å›ã®å…¥åŠ›ã‚’ä¿æŒï¼‰
        u0_flat = np.tile(u_prev, self.Nc)

        # å¢ƒç•Œåˆ¶ç´„
        bounds = []
        for _ in range(self.Nc):
            bounds.append((self.F_min, self.F_max))
            bounds.append((self.Q_min, self.Q_max))

        # æœ€é©åŒ–
        result = minimize(
            lambda u: self.mpc_objective(u, state0, setpoint),
            u0_flat,
            method='L-BFGS-B',
            bounds=bounds,
            options={'ftol': 1e-3, 'maxiter': 50}
        )

        u_opt = result.x.reshape(self.Nc, 2)
        return u_opt[0]


# ===================================
# ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
# ===================================
if __name__ == "__main__":
    mpc = NonlinearCSTRMPC(prediction_horizon=20, control_horizon=10)

    # åˆæœŸçŠ¶æ…‹
    state = np.array([2.0, 350.0])  # [C=2 kmol/mÂ³, T=350 K]
    u = np.array([0.1, 0.0])  # [F=0.1 mÂ³/min, Q=0 kJ/min]

    # ç›®æ¨™å€¤
    C_setpoint = 5.0  # kmol/mÂ³
    T_setpoint = 360.0  # K
    setpoint = np.array([C_setpoint, T_setpoint])

    # ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
    T_sim = 100  # ã‚¹ãƒ†ãƒƒãƒ—æ•°
    state_history = [state.copy()]
    u_history = [u.copy()]

    print("="*70)
    print("éç·šå½¢CSTRåå¿œå™¨ã®MPCåˆ¶å¾¡")
    print("="*70)
    print(f"ç›®æ¨™å€¤: C={C_setpoint} kmol/mÂ³, T={T_setpoint} K\n")

    for k in range(T_sim):
        # å¤–ä¹±ï¼ˆå…¥å£æ¿ƒåº¦ã®å¤‰å‹•ï¼‰
        if k == 40:
            mpc.C_in = 12.0  # æ¿ƒåº¦ãŒä¸Šæ˜‡
            print(f"æ™‚åˆ» {k*mpc.dt:.1f}åˆ†: å¤–ä¹±ç™ºç”Ÿï¼ˆå…¥å£æ¿ƒåº¦ 10â†’12 kmol/mÂ³ï¼‰\n")

        # MPCã§æœ€é©å…¥åŠ›ã‚’è¨ˆç®—
        u = mpc.solve(state, setpoint, u)

        # ãƒ—ãƒ­ã‚»ã‚¹æ›´æ–°
        state = mpc.simulate_step(state, u[0], u[1])

        # ãƒã‚¤ã‚ºè¿½åŠ 
        state += np.random.randn(2) * [0.05, 0.5]

        # è¨˜éŒ²
        state_history.append(state.copy())
        u_history.append(u.copy())

        if k % 20 == 0:
            print(f"æ™‚åˆ» {k*mpc.dt:5.1f}åˆ†: C={state[0]:.2f} kmol/mÂ³, T={state[1]:.1f} K, "
                  f"F={u[0]:.3f} mÂ³/min, Q={u[1]:+6.1f} kJ/min")

    state_history = np.array(state_history)
    u_history = np.array(u_history)

    print("\n" + "="*70)
    print("åˆ¶å¾¡æ€§èƒ½")
    print("="*70)

    # å®šå¸¸çŠ¶æ…‹ã§ã®è©•ä¾¡ï¼ˆæœ€å¾Œã®20ã‚¹ãƒ†ãƒƒãƒ—ï¼‰
    C_error = np.abs(state_history[-20:, 0] - C_setpoint).mean()
    T_error = np.abs(state_history[-20:, 1] - T_setpoint).mean()

    print(f"æ¿ƒåº¦èª¤å·®ï¼ˆå®šå¸¸ï¼‰: {C_error:.3f} kmol/mÂ³")
    print(f"æ¸©åº¦èª¤å·®ï¼ˆå®šå¸¸ï¼‰: {T_error:.3f} K")
    print(f"\nâœ“ éç·šå½¢ãƒ—ãƒ­ã‚»ã‚¹ã«å¯¾ã—ã¦ã‚‚é«˜ç²¾åº¦ãªåˆ¶å¾¡ã‚’å®Ÿç¾")
    print(f"âœ“ å¤–ä¹±ã«å¯¾ã™ã‚‹è¿…é€Ÿãªãƒªã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³")
</code></pre>
        </div>

        <h2>3.6 æ·±å±¤å¼·åŒ–å­¦ç¿’ã«ã‚ˆã‚‹åˆ¶å¾¡</h2>

        <p>å¼·åŒ–å­¦ç¿’ã¯ã€è©¦è¡ŒéŒ¯èª¤ã‚’é€šã˜ã¦æœ€é©ãªåˆ¶å¾¡æ–¹ç­–ã‚’å­¦ç¿’ã—ã¾ã™ã€‚Deep Q-Networkï¼ˆDQNï¼‰ã‚’ç”¨ã„ãŸãƒãƒƒãƒåå¿œå™¨ã®è»Œé“æœ€é©åŒ–ã‚’å®Ÿè£…ã—ã¾ã™ã€‚</p>

        <div class="code-block">
            <div class="code-title">Example 5: DQNã«ã‚ˆã‚‹ãƒãƒƒãƒãƒ—ãƒ­ã‚»ã‚¹åˆ¶å¾¡ - ãƒãƒƒãƒåå¿œå™¨è»Œé“æœ€é©åŒ–</div>
            <pre><code>"""
===================================
Example 5: DQNã«ã‚ˆã‚‹ãƒãƒƒãƒãƒ—ãƒ­ã‚»ã‚¹åˆ¶å¾¡
===================================

Deep Q-Networkï¼ˆDQNï¼‰ã‚’ç”¨ã„ãŸãƒãƒƒãƒåå¿œå™¨ã®æ¸©åº¦è»Œé“æœ€é©åŒ–ã€‚
ç›®æ¨™: è£½å“ç´”åº¦ã‚’æœ€å¤§åŒ–ã—ãªãŒã‚‰ã€ãƒãƒƒãƒæ™‚é–“ã‚’æœ€å°åŒ–ã™ã‚‹ã€‚

å¼·åŒ–å­¦ç¿’ã®å®šå¼åŒ–:
- çŠ¶æ…‹: [æ¿ƒåº¦A, æ¿ƒåº¦B, æ¸©åº¦, çµŒéæ™‚é–“]
- è¡Œå‹•: æ¸©åº¦ã®å¢—æ¸›ï¼ˆé›¢æ•£åŒ–ï¼‰
- å ±é…¬: è£½å“åç‡ - æ™‚é–“ãƒšãƒŠãƒ«ãƒ†ã‚£
"""

import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from collections import deque
import random
from typing import Tuple, List


class BatchReactorEnv:
    """ãƒãƒƒãƒåå¿œå™¨ç’°å¢ƒ"""

    def __init__(self):
        self.dt = 1.0  # æ™‚é–“ã‚¹ãƒ†ãƒƒãƒ— [min]
        self.max_time = 120.0  # æœ€å¤§ãƒãƒƒãƒæ™‚é–“ [min]

        # åå¿œé€Ÿåº¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.A1 = 1.0e8  # Aâ†’Bï¼ˆç›®çš„åå¿œï¼‰
        self.E1 = 70000.0
        self.A2 = 5.0e7  # Bâ†’Cï¼ˆå‰¯åå¿œï¼‰
        self.E2 = 65000.0
        self.R = 8.314

        # æ¸©åº¦åˆ¶ç´„
        self.T_min, self.T_max = 320.0, 380.0  # [K]

        self.reset()

    def reset(self) -> np.ndarray:
        """ç’°å¢ƒã‚’ãƒªã‚»ãƒƒãƒˆ"""
        self.C_A = 10.0  # åˆæœŸæ¿ƒåº¦A [mol/L]
        self.C_B = 0.0   # åˆæœŸæ¿ƒåº¦B [mol/L]
        self.C_C = 0.0   # åˆæœŸæ¿ƒåº¦C [mol/L]
        self.T = 340.0   # åˆæœŸæ¸©åº¦ [K]
        self.time = 0.0

        return self._get_state()

    def _get_state(self) -> np.ndarray:
        """çŠ¶æ…‹ãƒ™ã‚¯ãƒˆãƒ«ã‚’å–å¾—"""
        return np.array([
            self.C_A / 10.0,   # æ­£è¦åŒ–
            self.C_B / 10.0,
            (self.T - 350.0) / 30.0,
            self.time / self.max_time
        ], dtype=np.float32)

    def step(self, action: int) -> Tuple[np.ndarray, float, bool]:
        """1ã‚¹ãƒ†ãƒƒãƒ—å®Ÿè¡Œ

        Args:
            action: 0=å†·å´, 1=ä¿æŒ, 2=åŠ ç†±

        Returns:
            (next_state, reward, done)
        """
        # æ¸©åº¦å¤‰åŒ–
        delta_T = [-2.0, 0.0, 2.0][action]
        self.T = np.clip(self.T + delta_T, self.T_min, self.T_max)

        # åå¿œé€Ÿåº¦å®šæ•°
        k1 = self.A1 * np.exp(-self.E1 / (self.R * self.T))
        k2 = self.A2 * np.exp(-self.E2 / (self.R * self.T))

        # æ¿ƒåº¦æ›´æ–°ï¼ˆ1æ¬¡åå¿œï¼‰
        dC_A = -k1 * self.C_A * self.dt
        dC_B = (k1 * self.C_A - k2 * self.C_B) * self.dt
        dC_C = k2 * self.C_B * self.dt

        self.C_A += dC_A
        self.C_B += dC_B
        self.C_C += dC_C

        self.time += self.dt

        # å ±é…¬ã®è¨ˆç®—
        # è£½å“Bæ¿ƒåº¦ã‚’æœ€å¤§åŒ–ï¼ˆç›®æ¨™: 8 mol/Lä»¥ä¸Šï¼‰
        product_reward = self.C_B

        # å‰¯ç”Ÿæˆç‰©Cã«ãƒšãƒŠãƒ«ãƒ†ã‚£
        byproduct_penalty = -0.5 * self.C_C

        # æ™‚é–“ãƒšãƒŠãƒ«ãƒ†ã‚£ï¼ˆæ—©ãçµ‚ã‚ã‚‰ã›ãŸã„ï¼‰
        time_penalty = -0.01 * self.time

        reward = product_reward + byproduct_penalty + time_penalty

        # çµ‚äº†æ¡ä»¶
        done = (self.time >= self.max_time) or (self.C_A < 0.5)

        # ãƒœãƒ¼ãƒŠã‚¹: ç›®æ¨™é”æˆæ™‚
        if done and self.C_B >= 7.5:
            reward += 50.0

        return self._get_state(), reward, done


class DQN(nn.Module):
    """Deep Q-Network"""

    def __init__(self, state_dim: int, action_dim: int):
        super(DQN, self).__init__()
        self.fc = nn.Sequential(
            nn.Linear(state_dim, 64),
            nn.ReLU(),
            nn.Linear(64, 64),
            nn.ReLU(),
            nn.Linear(64, action_dim)
        )

    def forward(self, x):
        return self.fc(x)


class DQNAgent:
    """DQNã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ"""

    def __init__(self, state_dim: int, action_dim: int):
        self.state_dim = state_dim
        self.action_dim = action_dim

        self.q_network = DQN(state_dim, action_dim)
        self.target_network = DQN(state_dim, action_dim)
        self.target_network.load_state_dict(self.q_network.state_dict())

        self.optimizer = optim.Adam(self.q_network.parameters(), lr=1e-3)
        self.memory = deque(maxlen=10000)
        self.batch_size = 64
        self.gamma = 0.99

        self.epsilon = 1.0
        self.epsilon_min = 0.05
        self.epsilon_decay = 0.995

    def select_action(self, state: np.ndarray) -> int:
        """Îµ-greedyè¡Œå‹•é¸æŠ"""
        if random.random() < self.epsilon:
            return random.randint(0, self.action_dim - 1)

        with torch.no_grad():
            state_t = torch.FloatTensor(state).unsqueeze(0)
            q_values = self.q_network(state_t)
            return q_values.argmax().item()

    def store_transition(self, state, action, reward, next_state, done):
        """çµŒé¨“ã‚’ä¿å­˜"""
        self.memory.append((state, action, reward, next_state, done))

    def train(self):
        """ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’è¨“ç·´"""
        if len(self.memory) < self.batch_size:
            return

        # ãƒãƒƒãƒã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
        batch = random.sample(self.memory, self.batch_size)
        states, actions, rewards, next_states, dones = zip(*batch)

        states = torch.FloatTensor(np.array(states))
        actions = torch.LongTensor(actions)
        rewards = torch.FloatTensor(rewards)
        next_states = torch.FloatTensor(np.array(next_states))
        dones = torch.FloatTensor(dones)

        # ç¾åœ¨ã®Qå€¤
        current_q = self.q_network(states).gather(1, actions.unsqueeze(1))

        # ç›®æ¨™Qå€¤
        with torch.no_grad():
            next_q = self.target_network(next_states).max(1)[0]
            target_q = rewards + self.gamma * next_q * (1 - dones)

        # æå¤±è¨ˆç®—ã¨æ›´æ–°
        loss = nn.MSELoss()(current_q.squeeze(), target_q)
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()

        # Îµæ¸›è¡°
        self.epsilon = max(self.epsilon_min, self.epsilon * self.epsilon_decay)

    def update_target_network(self):
        """ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’æ›´æ–°"""
        self.target_network.load_state_dict(self.q_network.state_dict())


# ===================================
# å­¦ç¿’å®Ÿè¡Œ
# ===================================
if __name__ == "__main__":
    env = BatchReactorEnv()
    agent = DQNAgent(state_dim=4, action_dim=3)

    num_episodes = 200
    rewards_history = []

    print("="*70)
    print("DQNã«ã‚ˆã‚‹ãƒãƒƒãƒåå¿œå™¨åˆ¶å¾¡ã®å­¦ç¿’")
    print("="*70)

    for episode in range(num_episodes):
        state = env.reset()
        episode_reward = 0
        done = False

        while not done:
            action = agent.select_action(state)
            next_state, reward, done = env.step(action)

            agent.store_transition(state, action, reward, next_state, done)
            agent.train()

            state = next_state
            episode_reward += reward

        rewards_history.append(episode_reward)

        # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ›´æ–°
        if episode % 10 == 0:
            agent.update_target_network()

        if episode % 20 == 0:
            avg_reward = np.mean(rewards_history[-20:])
            print(f"Episode {episode:3d}: å¹³å‡å ±é…¬={avg_reward:6.2f}, "
                  f"Îµ={agent.epsilon:.3f}, æœ€çµ‚C_B={env.C_B:.2f} mol/L")

    print("\n" + "="*70)
    print("å­¦ç¿’å®Œäº† - ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ")
    print("="*70)

    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œï¼ˆè²ªæ¬²æ–¹ç­–ï¼‰
    agent.epsilon = 0.0
    state = env.reset()
    done = False

    trajectory = []
    while not done:
        action = agent.select_action(state)
        trajectory.append({
            'time': env.time,
            'C_A': env.C_A,
            'C_B': env.C_B,
            'C_C': env.C_C,
            'T': env.T,
            'action': ['å†·å´', 'ä¿æŒ', 'åŠ ç†±'][action]
        })
        next_state, reward, done = env.step(action)
        state = next_state

    print(f"\nãƒãƒƒãƒå®Œäº†æ™‚é–“: {env.time:.1f} min")
    print(f"æœ€çµ‚è£½å“æ¿ƒåº¦ C_B: {env.C_B:.2f} mol/L")
    print(f"å‰¯ç”Ÿæˆç‰© C_C: {env.C_C:.2f} mol/L")
    print(f"é¸æŠæ€§: {env.C_B / (env.C_B + env.C_C):.1%}")

    print("\næœ€é©æ¸©åº¦è»Œé“ï¼ˆæœ€åˆã®10ã‚¹ãƒ†ãƒƒãƒ—ï¼‰:")
    for i in range(min(10, len(trajectory))):
        t = trajectory[i]
        print(f"  {t['time']:5.1f}åˆ†: T={t['T']:.1f}K, C_B={t['C_B']:.2f}, æ“ä½œ={t['action']}")

    print("\nâœ“ DQNã«ã‚ˆã‚Šãƒãƒƒãƒæ™‚é–“ã¨è£½å“ç´”åº¦ã‚’ä¸¡ç«‹ã™ã‚‹æœ€é©è»Œé“ã‚’å­¦ç¿’")
</code></pre>
        </div>

        <h2>3.7 é€£ç¶šãƒ—ãƒ­ã‚»ã‚¹ã¸ã®å¼·åŒ–å­¦ç¿’é©ç”¨</h2>

        <p>é€£ç¶šå€¤ã®è¡Œå‹•ç©ºé–“ã‚’æŒã¤ãƒ—ãƒ­ã‚»ã‚¹ã«ã¯ã€Proximal Policy Optimizationï¼ˆPPOï¼‰ãŒæœ‰åŠ¹ã§ã™ã€‚CSTRåˆ¶å¾¡ã¸ã®é©ç”¨ä¾‹ã‚’ç¤ºã—ã¾ã™ã€‚</p>

        <div class="code-block">
            <div class="code-title">Example 6: PPOã«ã‚ˆã‚‹é€£ç¶šãƒ—ãƒ­ã‚»ã‚¹åˆ¶å¾¡ - CSTRæ¸©åº¦ãƒ»æµé‡åˆ¶å¾¡</div>
            <pre><code>"""
===================================
Example 6: PPOã«ã‚ˆã‚‹é€£ç¶šãƒ—ãƒ­ã‚»ã‚¹åˆ¶å¾¡
===================================

Proximal Policy Optimizationï¼ˆPPOï¼‰ã‚’ç”¨ã„ãŸé€£ç¶šæ”ªæ‹Œæ§½åå¿œå™¨ã®åˆ¶å¾¡ã€‚
é€£ç¶šå€¤ã®è¡Œå‹•ç©ºé–“ï¼ˆæ¸©åº¦ã€æµé‡ï¼‰ã‚’æ‰±ã†ãŸã‚ã€Actor-Criticã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’ä½¿ç”¨ã€‚

ç›®æ¨™: è£½å“æ¿ƒåº¦ã‚’ç›®æ¨™å€¤ã«ç¶­æŒã—ãªãŒã‚‰ã€ã‚¨ãƒãƒ«ã‚®ãƒ¼æ¶ˆè²»ã‚’æœ€å°åŒ–
"""

import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.distributions import Normal
from typing import Tuple


class CSTREnv:
    """é€£ç¶šæ”ªæ‹Œæ§½åå¿œå™¨ç’°å¢ƒ"""

    def __init__(self):
        self.dt = 0.5  # ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ™‚é–“ [min]
        self.V = 1.0   # åå¿œå™¨å®¹ç© [mÂ³]

        # åå¿œé€Ÿåº¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.A = 1.0e9
        self.Ea = 72000.0
        self.R = 8.314

        # ç›®æ¨™å€¤
        self.C_target = 3.0  # ç›®æ¨™è£½å“æ¿ƒåº¦ [mol/L]

        self.reset()

    def reset(self) -> np.ndarray:
        """ç’°å¢ƒã‚’ãƒªã‚»ãƒƒãƒˆ"""
        self.C = 2.0 + np.random.randn() * 0.5  # æ¿ƒåº¦ [mol/L]
        self.T = 350.0 + np.random.randn() * 5.0  # æ¸©åº¦ [K]
        self.C_in = 8.0  # å…¥å£æ¿ƒåº¦ [mol/L]

        return self._get_state()

    def _get_state(self) -> np.ndarray:
        """çŠ¶æ…‹ãƒ™ã‚¯ãƒˆãƒ«"""
        return np.array([
            (self.C - self.C_target) / self.C_target,  # æ¿ƒåº¦åå·®ï¼ˆæ­£è¦åŒ–ï¼‰
            (self.T - 350.0) / 30.0  # æ¸©åº¦åå·®ï¼ˆæ­£è¦åŒ–ï¼‰
        ], dtype=np.float32)

    def step(self, action: np.ndarray) -> Tuple[np.ndarray, float, bool]:
        """1ã‚¹ãƒ†ãƒƒãƒ—å®Ÿè¡Œ

        Args:
            action: [æµé‡å¤‰åŒ–ç‡, æ¸©åº¦å¤‰åŒ–]ï¼ˆ-1ã€œ1ã«æ­£è¦åŒ–ï¼‰

        Returns:
            (next_state, reward, done)
        """
        # è¡Œå‹•ã‚’å®Ÿéš›ã®ç‰©ç†é‡ã«å¤‰æ›
        F = 0.1 + 0.05 * action[0]  # æµé‡ 0.05ã€œ0.15 [mÂ³/min]
        delta_T = 5.0 * action[1]    # æ¸©åº¦å¤‰åŒ– -5ã€œ+5 [K]

        self.T = np.clip(self.T + delta_T, 320.0, 380.0)

        # åå¿œé€Ÿåº¦å®šæ•°
        k = self.A * np.exp(-self.Ea / (self.R * self.T))

        # æ¿ƒåº¦æ›´æ–°ï¼ˆCSTRç‰©è³ªåæ”¯ï¼‰
        tau = self.V / F
        dC = ((self.C_in - self.C) / tau - k * self.C) * self.dt
        self.C += dC

        # ãƒã‚¤ã‚ºï¼ˆå¤–ä¹±ï¼‰
        self.C += np.random.randn() * 0.05
        self.T += np.random.randn() * 1.0

        # å ±é…¬ã®è¨ˆç®—
        # 1. æ¿ƒåº¦è¿½å¾“ï¼ˆä¸»ç›®çš„ï¼‰
        error = abs(self.C - self.C_target)
        tracking_reward = -10.0 * error

        # 2. ã‚¨ãƒãƒ«ã‚®ãƒ¼ãƒšãƒŠãƒ«ãƒ†ã‚£ï¼ˆåŠ ç†±ã‚³ã‚¹ãƒˆï¼‰
        heating_cost = -0.01 * abs(delta_T)

        # 3. æµé‡å¤‰åŒ–ãƒšãƒŠãƒ«ãƒ†ã‚£ï¼ˆã‚¹ãƒ ãƒ¼ã‚ºãªæ“ä½œï¼‰
        flow_penalty = -0.1 * abs(action[0])

        reward = tracking_reward + heating_cost + flow_penalty

        # ãƒœãƒ¼ãƒŠã‚¹: ç›®æ¨™ç¯„å›²å†…ï¼ˆÂ±0.2 mol/Lï¼‰
        if error < 0.2:
            reward += 5.0

        done = False  # é€£ç¶šãƒ—ãƒ­ã‚»ã‚¹ãªã®ã§çµ‚äº†ãªã—

        return self._get_state(), reward, done


class ActorCritic(nn.Module):
    """Actor-Criticãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯"""

    def __init__(self, state_dim: int, action_dim: int):
        super(ActorCritic, self).__init__()

        # å…±æœ‰å±¤
        self.shared = nn.Sequential(
            nn.Linear(state_dim, 64),
            nn.Tanh(),
            nn.Linear(64, 64),
            nn.Tanh()
        )

        # Actorï¼ˆæ–¹ç­–ï¼‰
        self.actor_mean = nn.Linear(64, action_dim)
        self.actor_log_std = nn.Parameter(torch.zeros(action_dim))

        # Criticï¼ˆä¾¡å€¤é–¢æ•°ï¼‰
        self.critic = nn.Linear(64, 1)

    def forward(self, state):
        """é †ä¼æ’­"""
        shared_features = self.shared(state)

        # Actor: æ­£è¦åˆ†å¸ƒã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        action_mean = torch.tanh(self.actor_mean(shared_features))
        action_std = torch.exp(self.actor_log_std)

        # Critic: çŠ¶æ…‹ä¾¡å€¤
        value = self.critic(shared_features)

        return action_mean, action_std, value

    def get_action(self, state):
        """è¡Œå‹•ã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°"""
        action_mean, action_std, value = self.forward(state)
        dist = Normal(action_mean, action_std)
        action = dist.sample()
        log_prob = dist.log_prob(action).sum(-1)

        return action, log_prob, value


class PPOAgent:
    """PPOã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ"""

    def __init__(self, state_dim: int, action_dim: int):
        self.ac = ActorCritic(state_dim, action_dim)
        self.optimizer = optim.Adam(self.ac.parameters(), lr=3e-4)

        self.gamma = 0.99
        self.lam = 0.95  # GAE lambda
        self.clip_epsilon = 0.2
        self.epochs = 10

    def compute_gae(self, rewards, values, dones):
        """Generalized Advantage Estimation"""
        advantages = []
        gae = 0

        for t in reversed(range(len(rewards))):
            if t == len(rewards) - 1:
                next_value = 0
            else:
                next_value = values[t + 1]

            delta = rewards[t] + self.gamma * next_value - values[t]
            gae = delta + self.gamma * self.lam * gae
            advantages.insert(0, gae)

        return advantages

    def update(self, states, actions, old_log_probs, returns, advantages):
        """PPOæ›´æ–°"""
        states = torch.FloatTensor(np.array(states))
        actions = torch.FloatTensor(np.array(actions))
        old_log_probs = torch.FloatTensor(old_log_probs)
        returns = torch.FloatTensor(returns)
        advantages = torch.FloatTensor(advantages)

        # æ­£è¦åŒ–
        advantages = (advantages - advantages.mean()) / (advantages.std() + 1e-8)

        for _ in range(self.epochs):
            action_mean, action_std, values = self.ac(states)
            dist = Normal(action_mean, action_std)
            new_log_probs = dist.log_prob(actions).sum(-1)

            # Importance sampling ratio
            ratio = torch.exp(new_log_probs - old_log_probs)

            # Clipped surrogate objective
            surr1 = ratio * advantages
            surr2 = torch.clamp(ratio, 1 - self.clip_epsilon, 1 + self.clip_epsilon) * advantages
            actor_loss = -torch.min(surr1, surr2).mean()

            # Value loss
            critic_loss = nn.MSELoss()(values.squeeze(), returns)

            # åˆè¨ˆæå¤±
            loss = actor_loss + 0.5 * critic_loss

            self.optimizer.zero_grad()
            loss.backward()
            self.optimizer.step()


# ===================================
# å­¦ç¿’å®Ÿè¡Œ
# ===================================
if __name__ == "__main__":
    env = CSTREnv()
    agent = PPOAgent(state_dim=2, action_dim=2)

    num_episodes = 300
    steps_per_episode = 200

    print("="*70)
    print("PPOã«ã‚ˆã‚‹CSTRé€£ç¶šåˆ¶å¾¡ã®å­¦ç¿’")
    print("="*70)

    for episode in range(num_episodes):
        state = env.reset()

        states, actions, log_probs, rewards, values = [], [], [], [], []

        for step in range(steps_per_episode):
            state_t = torch.FloatTensor(state)
            action, log_prob, value = agent.ac.get_action(state_t.unsqueeze(0))

            action_np = action.squeeze().detach().numpy()
            next_state, reward, done = env.step(action_np)

            states.append(state)
            actions.append(action_np)
            log_probs.append(log_prob.item())
            rewards.append(reward)
            values.append(value.item())

            state = next_state

        # GAEè¨ˆç®—
        advantages = agent.compute_gae(rewards, values, [False] * len(rewards))
        returns = [adv + val for adv, val in zip(advantages, values)]

        # PPOæ›´æ–°
        agent.update(states, actions, log_probs, returns, advantages)

        if episode % 30 == 0:
            avg_reward = np.mean(rewards)
            final_error = abs(env.C - env.C_target)
            print(f"Episode {episode:3d}: å¹³å‡å ±é…¬={avg_reward:6.2f}, "
                  f"æœ€çµ‚èª¤å·®={final_error:.3f} mol/L")

    print("\n" + "="*70)
    print("å­¦ç¿’å®Œäº† - ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ")
    print("="*70)

    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    state = env.reset()
    trajectory = []

    for step in range(100):
        state_t = torch.FloatTensor(state)
        with torch.no_grad():
            action_mean, _, _ = agent.ac(state_t.unsqueeze(0))
            action = action_mean.squeeze().numpy()

        trajectory.append({
            'step': step,
            'C': env.C,
            'T': env.T,
            'action_flow': action[0],
            'action_temp': action[1]
        })

        next_state, reward, done = env.step(action)
        state = next_state

    # æ€§èƒ½è©•ä¾¡
    concentrations = [t['C'] for t in trajectory]
    mean_error = np.mean([abs(c - env.C_target) for c in concentrations])
    std_error = np.std([abs(c - env.C_target) for c in concentrations])

    print(f"\nå¹³å‡è¿½å¾“èª¤å·®: {mean_error:.3f} mol/L")
    print(f"èª¤å·®æ¨™æº–åå·®: {std_error:.3f} mol/L")

    print("\nåˆ¶å¾¡è»Œé“ï¼ˆæœ€åˆã®10ã‚¹ãƒ†ãƒƒãƒ—ï¼‰:")
    for i in range(10):
        t = trajectory[i]
        print(f"  Step {t['step']:3d}: C={t['C']:.2f} mol/L, T={t['T']:.1f}K, "
              f"Flow action={t['action_flow']:+.2f}, Temp action={t['action_temp']:+.2f}")

    print("\nâœ“ PPOã«ã‚ˆã‚Šé€£ç¶šå€¤åˆ¶å¾¡ã‚’å­¦ç¿’ã—ã€ç›®æ¨™å€¤è¿½å¾“ã‚’å®Ÿç¾")
</code></pre>
        </div>

        <h2>3.8 ãƒãƒ«ãƒç›®çš„æœ€é©åŒ–</h2>

        <p>åŒ–å­¦ãƒ—ãƒ©ãƒ³ãƒˆã§ã¯ã€åç‡ã¨ã‚¨ãƒãƒ«ã‚®ãƒ¼æ¶ˆè²»ãªã©è¤‡æ•°ã®ç›®æ¨™ãŒãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•é–¢ä¿‚ã«ã‚ã‚Šã¾ã™ã€‚NSGA-IIã«ã‚ˆã‚‹ãƒãƒ«ãƒç›®çš„æœ€é©åŒ–ã‚’å®Ÿè£…ã—ã¾ã™ã€‚</p>

        <div class="code-block">
            <div class="code-title">Example 7: ãƒãƒ«ãƒç›®çš„æœ€é©åŒ–ï¼ˆNSGA-IIï¼‰ - åç‡ã¨ã‚¨ãƒãƒ«ã‚®ãƒ¼ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•</div>
            <pre><code>"""
===================================
Example 7: ãƒãƒ«ãƒç›®çš„æœ€é©åŒ–ï¼ˆNSGA-IIï¼‰
===================================

NSGA-IIï¼ˆNon-dominated Sorting Genetic Algorithm IIï¼‰ã‚’ç”¨ã„ãŸ
åŒ–å­¦ãƒ—ãƒ­ã‚»ã‚¹ã®ãƒãƒ«ãƒç›®çš„æœ€é©åŒ–ã€‚

ç›®çš„:
1. è£½å“åç‡ã®æœ€å¤§åŒ–
2. ã‚¨ãƒãƒ«ã‚®ãƒ¼æ¶ˆè²»ã®æœ€å°åŒ–

ã“ã‚Œã‚‰ã¯äº’ã„ã«ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•é–¢ä¿‚ã«ã‚ã‚Šã€ãƒ‘ãƒ¬ãƒ¼ãƒˆæœ€é©è§£é›†åˆã‚’æ±‚ã‚ã‚‹ã€‚

pymooã¯å®Ÿéš›ã«ã¯ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãŒå¿…è¦ã§ã™ãŒã€ã“ã“ã§ã¯åŸºæœ¬çš„ãªéºä¼çš„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã§ä»£æ›¿å®Ÿè£…ã—ã¾ã™ã€‚
"""

import numpy as np
from typing import List, Tuple
import pandas as pd


class MultiObjectiveOptimizer:
    """ãƒãƒ«ãƒç›®çš„æœ€é©åŒ–å™¨ï¼ˆNSGA-IIé¢¨ï¼‰"""

    def __init__(self, population_size: int = 50, generations: int = 100):
        self.pop_size = population_size
        self.n_gen = generations

        # æ±ºå®šå¤‰æ•°ã®ç¯„å›²
        # x = [æ¸©åº¦ [K], åœ§åŠ› [bar], æµé‡ [mÂ³/h], è§¦åª’é‡ [kg]]
        self.bounds_lower = np.array([350.0, 10.0, 1.0, 50.0])
        self.bounds_upper = np.array([420.0, 50.0, 5.0, 200.0])

    def process_model(self, x: np.ndarray) -> Tuple[float, float]:
        """ãƒ—ãƒ­ã‚»ã‚¹ãƒ¢ãƒ‡ãƒ«ï¼šåç‡ã¨ã‚¨ãƒãƒ«ã‚®ãƒ¼ã‚’è¨ˆç®—

        Args:
            x: [æ¸©åº¦, åœ§åŠ›, æµé‡, è§¦åª’é‡]

        Returns:
            (åç‡, ã‚¨ãƒãƒ«ã‚®ãƒ¼æ¶ˆè²»)
        """
        T, P, F, Cat = x

        # åç‡ãƒ¢ãƒ‡ãƒ«ï¼ˆç°¡ç•¥åŒ–ï¼‰
        # é«˜æ¸©ãƒ»é«˜åœ§ãƒ»å¤šè§¦åª’ã§åç‡å‘ä¸Šã€ãŸã ã—é£½å’Œã‚ã‚Š
        T_factor = 1.0 / (1.0 + np.exp(-(T - 380.0) / 10.0))
        P_factor = np.log(P / 10.0) / np.log(5.0)
        Cat_factor = np.sqrt(Cat / 50.0)

        yield_fraction = 0.5 + 0.4 * T_factor + 0.2 * P_factor + 0.15 * Cat_factor

        # æµé‡ã«æ¯”ä¾‹ã—ãŸç”Ÿç”£é‡
        productivity = F * yield_fraction  # [mÂ³/h * fraction]

        # ã‚¨ãƒãƒ«ã‚®ãƒ¼æ¶ˆè²»ãƒ¢ãƒ‡ãƒ«
        # åŠ ç†±ã‚¨ãƒãƒ«ã‚®ãƒ¼ï¼ˆæ¸©åº¦ã«æ¯”ä¾‹ï¼‰
        heating_energy = F * 1000.0 * 4.18 * (T - 300.0) / 3600.0  # [kW]

        # åœ§ç¸®ã‚¨ãƒãƒ«ã‚®ãƒ¼ï¼ˆåœ§åŠ›ã«éç·šå½¢ï¼‰
        compression_energy = 10.0 * F * (P / 10.0)**1.2  # [kW]

        total_energy = heating_energy + compression_energy

        return productivity, total_energy

    def objectives(self, x: np.ndarray) -> np.ndarray:
        """ç›®çš„é–¢æ•°ï¼ˆæœ€å°åŒ–å•é¡Œã«çµ±ä¸€ï¼‰

        Returns:
            [-åç‡ï¼ˆæœ€å¤§åŒ–â†’æœ€å°åŒ–ï¼‰, ã‚¨ãƒãƒ«ã‚®ãƒ¼æ¶ˆè²»ï¼ˆæœ€å°åŒ–ï¼‰]
        """
        productivity, energy = self.process_model(x)
        return np.array([-productivity, energy])

    def dominates(self, obj1: np.ndarray, obj2: np.ndarray) -> bool:
        """obj1ãŒobj2ã‚’æ”¯é…ã™ã‚‹ã‹åˆ¤å®š"""
        return np.all(obj1 <= obj2) and np.any(obj1 < obj2)

    def non_dominated_sort(self, objectives: np.ndarray) -> List[List[int]]:
        """éæ”¯é…ã‚½ãƒ¼ãƒˆ

        Args:
            objectives: (pop_size x 2) ç›®çš„é–¢æ•°å€¤

        Returns:
            ãƒ•ãƒ­ãƒ³ãƒˆã”ã¨ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒªã‚¹ãƒˆ
        """
        pop_size = len(objectives)
        domination_count = np.zeros(pop_size, dtype=int)
        dominated_solutions = [[] for _ in range(pop_size)]

        fronts = [[]]

        for i in range(pop_size):
            for j in range(i + 1, pop_size):
                if self.dominates(objectives[i], objectives[j]):
                    dominated_solutions[i].append(j)
                    domination_count[j] += 1
                elif self.dominates(objectives[j], objectives[i]):
                    dominated_solutions[j].append(i)
                    domination_count[i] += 1

        for i in range(pop_size):
            if domination_count[i] == 0:
                fronts[0].append(i)

        current_front = 0
        while len(fronts[current_front]) > 0:
            next_front = []
            for i in fronts[current_front]:
                for j in dominated_solutions[i]:
                    domination_count[j] -= 1
                    if domination_count[j] == 0:
                        next_front.append(j)
            current_front += 1
            fronts.append(next_front)

        return fronts[:-1]  # æœ€å¾Œã®ç©ºãƒªã‚¹ãƒˆã‚’é™¤ã

    def crowding_distance(self, objectives: np.ndarray, front: List[int]) -> np.ndarray:
        """æ··é›‘åº¦è·é›¢ã‚’è¨ˆç®—"""
        n = len(front)
        if n <= 2:
            return np.full(n, np.inf)

        distances = np.zeros(n)

        for m in range(objectives.shape[1]):  # å„ç›®çš„ã«ã¤ã„ã¦
            sorted_idx = np.argsort(objectives[front, m])

            distances[sorted_idx[0]] = np.inf
            distances[sorted_idx[-1]] = np.inf

            obj_range = objectives[front[sorted_idx[-1]], m] - objectives[front[sorted_idx[0]], m]
            if obj_range == 0:
                continue

            for i in range(1, n - 1):
                distances[sorted_idx[i]] += (
                    (objectives[front[sorted_idx[i + 1]], m] -
                     objectives[front[sorted_idx[i - 1]], m]) / obj_range
                )

        return distances

    def optimize(self) -> Tuple[np.ndarray, np.ndarray]:
        """NSGA-IIæœ€é©åŒ–ã‚’å®Ÿè¡Œ

        Returns:
            (ãƒ‘ãƒ¬ãƒ¼ãƒˆè§£é›†åˆ, ç›®çš„é–¢æ•°å€¤)
        """
        # åˆæœŸå€‹ä½“ç¾¤ã‚’ç”Ÿæˆ
        population = np.random.uniform(
            self.bounds_lower,
            self.bounds_upper,
            (self.pop_size, len(self.bounds_lower))
        )

        for generation in range(self.n_gen):
            # ç›®çš„é–¢æ•°è©•ä¾¡
            objectives = np.array([self.objectives(ind) for ind in population])

            # éæ”¯é…ã‚½ãƒ¼ãƒˆ
            fronts = self.non_dominated_sort(objectives)

            # æ¬¡ä¸–ä»£ã®é¸æŠ
            next_population = []
            for front in fronts:
                if len(next_population) + len(front) <= self.pop_size:
                    next_population.extend(front)
                else:
                    # æ··é›‘åº¦è·é›¢ã§ã‚½ãƒ¼ãƒˆ
                    distances = self.crowding_distance(objectives, front)
                    sorted_idx = np.argsort(distances)[::-1]
                    remaining = self.pop_size - len(next_population)
                    next_population.extend([front[i] for i in sorted_idx[:remaining]])
                    break

            # äº¤å‰ã¨çªç„¶å¤‰ç•°
            selected = population[next_population]
            offspring = []

            for i in range(0, len(selected) - 1, 2):
                # SBXäº¤å‰ï¼ˆç°¡ç•¥ç‰ˆï¼‰
                alpha = np.random.rand(len(self.bounds_lower))
                child1 = alpha * selected[i] + (1 - alpha) * selected[i + 1]
                child2 = (1 - alpha) * selected[i] + alpha * selected[i + 1]

                # å¤šé …å¼çªç„¶å¤‰ç•°ï¼ˆç°¡ç•¥ç‰ˆï¼‰
                if np.random.rand() < 0.1:
                    child1 += np.random.randn(len(self.bounds_lower)) * 0.1 * (self.bounds_upper - self.bounds_lower)
                if np.random.rand() < 0.1:
                    child2 += np.random.randn(len(self.bounds_lower)) * 0.1 * (self.bounds_upper - self.bounds_lower)

                # å¢ƒç•Œåˆ¶ç´„
                child1 = np.clip(child1, self.bounds_lower, self.bounds_upper)
                child2 = np.clip(child2, self.bounds_lower, self.bounds_upper)

                offspring.extend([child1, child2])

            population = np.array(offspring[:self.pop_size])

            if generation % 20 == 0:
                print(f"ä¸–ä»£ {generation}: ãƒ‘ãƒ¬ãƒ¼ãƒˆãƒ•ãƒ­ãƒ³ãƒˆã‚µã‚¤ã‚º={len(fronts[0])}")

        # æœ€çµ‚è©•ä¾¡
        objectives = np.array([self.objectives(ind) for ind in population])
        fronts = self.non_dominated_sort(objectives)
        pareto_front = fronts[0]

        return population[pareto_front], objectives[pareto_front]


# ===================================
# å®Ÿè¡Œä¾‹
# ===================================
if __name__ == "__main__":
    optimizer = MultiObjectiveOptimizer(population_size=50, generations=100)

    print("="*70)
    print("ãƒãƒ«ãƒç›®çš„æœ€é©åŒ–ï¼ˆNSGA-IIï¼‰")
    print("="*70)
    print("ç›®çš„1: è£½å“åç‡ã®æœ€å¤§åŒ–")
    print("ç›®çš„2: ã‚¨ãƒãƒ«ã‚®ãƒ¼æ¶ˆè²»ã®æœ€å°åŒ–\n")

    # æœ€é©åŒ–å®Ÿè¡Œ
    pareto_solutions, pareto_objectives = optimizer.optimize()

    print("\n" + "="*70)
    print(f"ãƒ‘ãƒ¬ãƒ¼ãƒˆæœ€é©è§£: {len(pareto_solutions)} å€‹")
    print("="*70)

    # çµæœã‚’æ•´ç†
    results = []
    for i, (sol, obj) in enumerate(zip(pareto_solutions, pareto_objectives)):
        T, P, F, Cat = sol
        productivity = -obj[0]  # æœ€å°åŒ–å•é¡Œã‹ã‚‰æˆ»ã™
        energy = obj[1]

        results.append({
            'è§£ç•ªå·': i + 1,
            'æ¸©åº¦ [K]': T,
            'åœ§åŠ› [bar]': P,
            'æµé‡ [mÂ³/h]': F,
            'è§¦åª’ [kg]': Cat,
            'åç‡ç”Ÿç”£æ€§ [mÂ³/h]': productivity,
            'ã‚¨ãƒãƒ«ã‚®ãƒ¼ [kW]': energy,
            'ã‚¨ãƒãƒ«ã‚®ãƒ¼åŸå˜ä½ [kW/(mÂ³/h)]': energy / productivity
        })

    df = pd.DataFrame(results)

    # ä»£è¡¨çš„ãªè§£ã‚’è¡¨ç¤ºï¼ˆåç‡é‡è¦–ã€ãƒãƒ©ãƒ³ã‚¹ã€çœã‚¨ãƒé‡è¦–ï¼‰
    print("\nã€ä»£è¡¨çš„ãªãƒ‘ãƒ¬ãƒ¼ãƒˆè§£ã€‘")
    print("\n1. åç‡é‡è¦–ï¼ˆã‚¨ãƒãƒ«ã‚®ãƒ¼æ¶ˆè²»å¤§ï¼‰:")
    idx_max_yield = df['åç‡ç”Ÿç”£æ€§ [mÂ³/h]'].idxmax()
    print(df.loc[idx_max_yield].to_string())

    print("\n2. ãƒãƒ©ãƒ³ã‚¹å‹:")
    df['ãƒãƒ©ãƒ³ã‚¹ã‚¹ã‚³ã‚¢'] = (df['åç‡ç”Ÿç”£æ€§ [mÂ³/h]'].rank() + (1 / df['ã‚¨ãƒãƒ«ã‚®ãƒ¼ [kW]']).rank()) / 2
    idx_balanced = df['ãƒãƒ©ãƒ³ã‚¹ã‚¹ã‚³ã‚¢'].idxmax()
    print(df.loc[idx_balanced].to_string())

    print("\n3. çœã‚¨ãƒé‡è¦–ï¼ˆåç‡ä½ï¼‰:")
    idx_min_energy = df['ã‚¨ãƒãƒ«ã‚®ãƒ¼ [kW]'].idxmin()
    print(df.loc[idx_min_energy].to_string())

    print("\n" + "="*70)
    print("ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•åˆ†æ")
    print("="*70)

    # åç‡10%å‘ä¸Šã®ãŸã‚ã®ã‚¨ãƒãƒ«ã‚®ãƒ¼ã‚³ã‚¹ãƒˆå¢—åŠ 
    sorted_df = df.sort_values('åç‡ç”Ÿç”£æ€§ [mÂ³/h]')
    if len(sorted_df) > 1:
        yield_range = sorted_df['åç‡ç”Ÿç”£æ€§ [mÂ³/h]'].max() - sorted_df['åç‡ç”Ÿç”£æ€§ [mÂ³/h]'].min()
        energy_range = sorted_df['ã‚¨ãƒãƒ«ã‚®ãƒ¼ [kW]'].max() - sorted_df['ã‚¨ãƒãƒ«ã‚®ãƒ¼ [kW]'].min()

        print(f"åç‡10%å‘ä¸Šã®ãŸã‚ã®ã‚¨ãƒãƒ«ã‚®ãƒ¼å¢—åŠ : ç´„{energy_range / yield_range * 0.1 * sorted_df['åç‡ç”Ÿç”£æ€§ [mÂ³/h]'].mean():.1f} kW")

    print("\nâœ“ ãƒ‘ãƒ¬ãƒ¼ãƒˆãƒ•ãƒ­ãƒ³ãƒˆã«ã‚ˆã‚Šã€æ„æ€æ±ºå®šè€…ãŒåç‡ã¨ã‚¨ãƒãƒ«ã‚®ãƒ¼ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’é¸æŠå¯èƒ½")
</code></pre>
        </div>

        <h2>3.9 çµ±åˆAPC+æœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ </h2>

        <p>æœ€å¾Œã«ã€RTOå±¤ã¨APCå±¤ã‚’çµ±åˆã—ãŸå®Ÿç”¨çš„ãªãƒ—ãƒ©ãƒ³ãƒˆåˆ¶å¾¡ã‚·ã‚¹ãƒ†ãƒ ã®å®Ÿè£…ä¾‹ã‚’ç¤ºã—ã¾ã™ã€‚</p>

        <div class="code-block">
            <div class="code-title">Example 8: çµ±åˆAPC+æœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ  - éšå±¤å‹ãƒ—ãƒ©ãƒ³ãƒˆåˆ¶å¾¡</div>
            <pre><code>"""
===================================
Example 8: çµ±åˆAPC+æœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ 
===================================

ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æœ€é©åŒ–ï¼ˆRTOï¼‰å±¤ã¨Advanced Process Controlï¼ˆAPCï¼‰å±¤ã‚’
çµ±åˆã—ãŸéšå±¤å‹ãƒ—ãƒ©ãƒ³ãƒˆåˆ¶å¾¡ã‚·ã‚¹ãƒ†ãƒ ã€‚

éšå±¤æ§‹é€ :
- RTOå±¤ï¼ˆä¸Šä½ï¼‰: çµŒæ¸ˆçš„æœ€é©åŒ–ã«ã‚ˆã‚Šæœ€é©é‹è»¢æ¡ä»¶ã‚’æ±ºå®š
- APCå±¤ï¼ˆä¸‹ä½ï¼‰: MPCã§RTOã®ç›®æ¨™å€¤ã‚’é«˜ç²¾åº¦ã«è¿½å¾“

åŒ–å­¦ãƒ—ãƒ©ãƒ³ãƒˆï¼ˆè’¸ç•™å¡”+åå¿œå™¨ï¼‰ã¸ã®é©ç”¨ä¾‹
"""

import numpy as np
from scipy.optimize import minimize
from typing import Dict, Tuple
import pandas as pd


class RTOLayer:
    """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æœ€é©åŒ–å±¤"""

    def __init__(self):
        # çµŒæ¸ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.product_price = 120.0  # $/ton
        self.feed_cost = 50.0  # $/ton
        self.steam_cost = 25.0  # $/ton
        self.power_cost = 0.10  # $/kWh

    def steady_state_model(self, x: np.ndarray) -> Dict:
        """å®šå¸¸çŠ¶æ…‹ãƒ—ãƒ­ã‚»ã‚¹ãƒ¢ãƒ‡ãƒ«

        Args:
            x: [åå¿œæ¸©åº¦, è’¸ç•™é‚„æµæ¯”]

        Returns:
            ãƒ—ãƒ­ã‚»ã‚¹å‡ºåŠ›ã®è¾æ›¸
        """
        T_reactor, reflux_ratio = x

        # åå¿œåç‡ï¼ˆæ¸©åº¦ä¾å­˜ï¼‰
        yield_base = 0.75
        temp_effect = 0.002 * (T_reactor - 370.0)
        yield_fraction = yield_base + temp_effect

        # è£½å“ç´”åº¦ï¼ˆé‚„æµæ¯”ä¾å­˜ï¼‰
        purity_base = 0.90
        reflux_effect = 0.15 * (1.0 - np.exp(-0.5 * (reflux_ratio - 2.0)))
        purity = min(0.99, purity_base + reflux_effect)

        # ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£æ¶ˆè²»
        reactor_heat = 50.0 + 0.5 * (T_reactor - 350.0)**2  # kW
        steam_consumption = 2.0 + 0.8 * reflux_ratio  # ton/h
        power = 30.0 + 5.0 * reflux_ratio  # kW

        return {
            'yield': yield_fraction,
            'purity': purity,
            'reactor_heat': reactor_heat,
            'steam': steam_consumption,
            'power': power
        }

    def economic_objective(self, x: np.ndarray, feed_rate: float) -> float:
        """çµŒæ¸ˆç›®çš„é–¢æ•°ï¼šåˆ©ç›Šã®è² å€¤

        Args:
            x: [åå¿œæ¸©åº¦, é‚„æµæ¯”]
            feed_rate: åŸæ–™æµé‡ [ton/h]

        Returns:
            -åˆ©ç›Š [$/h]
        """
        outputs = self.steady_state_model(x)

        # è£½å“ç”Ÿç”£é‡
        product_rate = feed_rate * outputs['yield'] * outputs['purity']

        # åç›Š
        revenue = product_rate * self.product_price

        # ã‚³ã‚¹ãƒˆ
        feed_cost = feed_rate * self.feed_cost
        steam_cost = outputs['steam'] * self.steam_cost
        power_cost = outputs['power'] * self.power_cost

        profit = revenue - feed_cost - steam_cost - power_cost

        return -profit  # æœ€å°åŒ–ã®ãŸã‚è² å€¤

    def optimize(self, feed_rate: float) -> Dict:
        """RTOã‚’å®Ÿè¡Œ

        Args:
            feed_rate: ç¾åœ¨ã®åŸæ–™æµé‡ [ton/h]

        Returns:
            æœ€é©é‹è»¢æ¡ä»¶
        """
        # åˆæœŸæ¨å®šå€¤
        x0 = np.array([370.0, 3.0])

        # å¢ƒç•Œåˆ¶ç´„
        bounds = [
            (350.0, 390.0),  # åå¿œæ¸©åº¦ [K]
            (2.0, 5.0)       # é‚„æµæ¯”
        ]

        # åˆ¶ç´„: è£½å“ç´”åº¦95%ä»¥ä¸Š
        def purity_constraint(x):
            outputs = self.steady_state_model(x)
            return outputs['purity'] - 0.95

        from scipy.optimize import NonlinearConstraint
        nlc = NonlinearConstraint(purity_constraint, 0, np.inf)

        # æœ€é©åŒ–
        result = minimize(
            lambda x: self.economic_objective(x, feed_rate),
            x0,
            method='SLSQP',
            bounds=bounds,
            constraints=[nlc]
        )

        T_opt, reflux_opt = result.x
        outputs = self.steady_state_model(result.x)

        return {
            'T_reactor_sp': T_opt,
            'reflux_ratio_sp': reflux_opt,
            'predicted_yield': outputs['yield'],
            'predicted_purity': outputs['purity'],
            'predicted_profit': -result.fun
        }


class APCLayer:
    """å…ˆé€²åˆ¶å¾¡å±¤ï¼ˆMPCï¼‰"""

    def __init__(self):
        # ãƒ—ãƒ­ã‚»ã‚¹ãƒ¢ãƒ‡ãƒ«ï¼ˆç·šå½¢åŒ–è¿‘ä¼¼ï¼‰
        # çŠ¶æ…‹: [åå¿œæ¸©åº¦åå·®, é‚„æµæ¯”åå·®]
        self.A = np.array([
            [0.90, 0.05],
            [0.00, 0.85]
        ])
        self.B = np.array([
            [0.8, 0.0],
            [0.0, 0.6]
        ])

        # åˆ¶å¾¡ãƒ›ãƒ©ã‚¤ã‚ºãƒ³
        self.Np = 15
        self.Nc = 8

    def mpc_control(self, current_state: np.ndarray,
                    setpoint: np.ndarray) -> np.ndarray:
        """MPCåˆ¶å¾¡

        Args:
            current_state: ç¾åœ¨ã®çŠ¶æ…‹åå·® [Tåå·®, é‚„æµæ¯”åå·®]
            setpoint: ç›®æ¨™å€¤åå·®ï¼ˆRTOã‹ã‚‰ã®æŒ‡ä»¤ï¼‰

        Returns:
            æœ€é©æ“ä½œé‡
        """
        # ç°¡ç•¥åŒ–ã—ãŸMPCï¼ˆå®Ÿéš›ã¯ã‚ˆã‚Šè©³ç´°ãªå®Ÿè£…ãŒå¿…è¦ï¼‰
        # ã“ã“ã§ã¯æ¯”ä¾‹åˆ¶å¾¡ã§ä»£æ›¿
        Kp = np.array([2.0, 1.5])
        u = Kp * (setpoint - current_state)

        # æ“ä½œé‡åˆ¶ç´„
        u = np.clip(u, [-5.0, -0.5], [5.0, 0.5])

        return u


class IntegratedControlSystem:
    """çµ±åˆåˆ¶å¾¡ã‚·ã‚¹ãƒ†ãƒ """

    def __init__(self):
        self.rto = RTOLayer()
        self.apc = APCLayer()

        # RTOå®Ÿè¡Œé–“éš”ï¼ˆAPCã‚ˆã‚Šé•·ã„ï¼‰
        self.rto_interval = 30  # APCã‚µã‚¤ã‚¯ãƒ«ã®30å€

        # ç¾åœ¨ã®çŠ¶æ…‹
        self.T_reactor = 365.0
        self.reflux_ratio = 3.2

    def run_rto(self, feed_rate: float) -> Dict:
        """RTOå±¤ã‚’å®Ÿè¡Œ"""
        print("\n" + "="*70)
        print("RTOå±¤: çµŒæ¸ˆæœ€é©åŒ–ã‚’å®Ÿè¡Œ")
        print("="*70)

        result = self.rto.optimize(feed_rate)

        print(f"  æœ€é©åå¿œæ¸©åº¦: {result['T_reactor_sp']:.1f} K")
        print(f"  æœ€é©é‚„æµæ¯”: {result['reflux_ratio_sp']:.2f}")
        print(f"  äºˆæ¸¬åç‡: {result['predicted_yield']:.1%}")
        print(f"  äºˆæ¸¬ç´”åº¦: {result['predicted_purity']:.1%}")
        print(f"  äºˆæ¸¬åˆ©ç›Š: ${result['predicted_profit']:.2f}/h")

        return result

    def run_apc(self, rto_setpoint: Dict) -> np.ndarray:
        """APCå±¤ã‚’å®Ÿè¡Œ"""
        # ç¾åœ¨ã®åå·®
        current_state = np.array([
            self.T_reactor - rto_setpoint['T_reactor_sp'],
            self.reflux_ratio - rto_setpoint['reflux_ratio_sp']
        ])

        # ç›®æ¨™åå·®ï¼ˆã‚¼ãƒ­ï¼‰
        setpoint = np.array([0.0, 0.0])

        # MPCåˆ¶å¾¡
        u = self.apc.mpc_control(current_state, setpoint)

        return u

    def simulate(self, feed_rate: float, simulation_steps: int = 100):
        """çµ±åˆã‚·ã‚¹ãƒ†ãƒ ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³

        Args:
            feed_rate: åŸæ–™æµé‡ [ton/h]
            simulation_steps: ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒƒãƒ—æ•°
        """
        print("="*70)
        print("çµ±åˆAPC+æœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ  ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³")
        print("="*70)

        # åˆå›RTOå®Ÿè¡Œ
        rto_result = self.run_rto(feed_rate)

        history = []

        for step in range(simulation_steps):
            # RTOæ›´æ–°ï¼ˆå‘¨æœŸçš„ï¼‰
            if step % self.rto_interval == 0 and step > 0:
                rto_result = self.run_rto(feed_rate)

            # APCå®Ÿè¡Œï¼ˆæ¯ã‚¹ãƒ†ãƒƒãƒ—ï¼‰
            u = self.run_apc(rto_result)

            # ãƒ—ãƒ­ã‚»ã‚¹æ›´æ–°ï¼ˆç°¡ç•¥åŒ–ï¼‰
            self.T_reactor += u[0] * 0.5 + np.random.randn() * 0.5
            self.reflux_ratio += u[1] * 0.3 + np.random.randn() * 0.05

            # ç‰©ç†åˆ¶ç´„
            self.T_reactor = np.clip(self.T_reactor, 350.0, 390.0)
            self.reflux_ratio = np.clip(self.reflux_ratio, 2.0, 5.0)

            # è¨˜éŒ²
            outputs = self.rto.steady_state_model(
                [self.T_reactor, self.reflux_ratio]
            )

            history.append({
                'step': step,
                'T_reactor': self.T_reactor,
                'T_setpoint': rto_result['T_reactor_sp'],
                'reflux': self.reflux_ratio,
                'reflux_setpoint': rto_result['reflux_ratio_sp'],
                'yield': outputs['yield'],
                'purity': outputs['purity']
            })

            if step % 20 == 0:
                print(f"\nã‚¹ãƒ†ãƒƒãƒ— {step:3d}:")
                print(f"  åå¿œæ¸©åº¦: {self.T_reactor:.1f}K (SP: {rto_result['T_reactor_sp']:.1f}K)")
                print(f"  é‚„æµæ¯”: {self.reflux_ratio:.2f} (SP: {rto_result['reflux_ratio_sp']:.2f})")
                print(f"  åç‡: {outputs['yield']:.1%}, ç´”åº¦: {outputs['purity']:.1%}")

        return pd.DataFrame(history)


# ===================================
# å®Ÿè¡Œä¾‹
# ===================================
if __name__ == "__main__":
    system = IntegratedControlSystem()

    # åŸæ–™æµé‡
    feed_rate = 10.0  # ton/h

    # ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
    df = system.simulate(feed_rate, simulation_steps=100)

    print("\n" + "="*70)
    print("åˆ¶å¾¡æ€§èƒ½è©•ä¾¡")
    print("="*70)

    # è¿½å¾“æ€§èƒ½
    T_error = np.abs(df['T_reactor'] - df['T_setpoint']).mean()
    reflux_error = np.abs(df['reflux'] - df['reflux_setpoint']).mean()

    print(f"\nåå¿œæ¸©åº¦ã®å¹³å‡è¿½å¾“èª¤å·®: {T_error:.2f} K")
    print(f"é‚„æµæ¯”ã®å¹³å‡è¿½å¾“èª¤å·®: {reflux_error:.3f}")

    # ãƒ—ãƒ­ã‚»ã‚¹æ€§èƒ½
    avg_yield = df['yield'].mean()
    avg_purity = df['purity'].mean()

    print(f"\nå¹³å‡åç‡: {avg_yield:.1%}")
    print(f"å¹³å‡ç´”åº¦: {avg_purity:.1%}")

    print("\n" + "="*70)
    print("ã‚·ã‚¹ãƒ†ãƒ ã®ç‰¹é•·")
    print("="*70)
    print("âœ“ RTOå±¤ã§çµŒæ¸ˆçš„æœ€é©é‹è»¢æ¡ä»¶ã‚’æ±ºå®š")
    print("âœ“ APCå±¤ï¼ˆMPCï¼‰ã§é«˜ç²¾åº¦ãªç›®æ¨™å€¤è¿½å¾“ã‚’å®Ÿç¾")
    print("âœ“ éšå±¤åŒ–ã«ã‚ˆã‚Šè¨ˆç®—è² è·ã‚’åˆ†æ•£ã€å®Ÿæ™‚é–“åˆ¶å¾¡ã‚’é”æˆ")
    print("âœ“ ãƒ—ãƒ©ãƒ³ãƒˆå…¨ä½“ã®çµŒæ¸ˆæ€§ã‚’æœ€å¤§åŒ–ã—ãªãŒã‚‰å“è³ªã‚’ä¿è¨¼")
</code></pre>
        </div>

        <h2>ã¾ã¨ã‚</h2>

        <p>æœ¬ç« ã§ã¯ã€åŒ–å­¦ãƒ—ãƒ©ãƒ³ãƒˆã«ãŠã‘ã‚‹ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æœ€é©åŒ–ã¨Advanced Process Controlã®å®Ÿè£…æŠ€è¡“ã‚’å­¦ã³ã¾ã—ãŸã€‚ä¸»è¦ãªãƒã‚¤ãƒ³ãƒˆã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™ï¼š</p>

        <div class="section-intro">
            <h3>å­¦ç¿’å†…å®¹ã®æŒ¯ã‚Šè¿”ã‚Š</h3>
            <ol>
                <li><strong>ã‚ªãƒ³ãƒ©ã‚¤ãƒ³æœ€é©åŒ–ï¼ˆSciPyï¼‰</strong>ï¼šCSTRé‹è»¢æ¡ä»¶ã‚’çµŒæ¸ˆçš„ç›®æ¨™é–¢æ•°ã§æœ€é©åŒ–ã—ã€åˆ©ç›Šæœ€å¤§åŒ–ã‚’å®Ÿç¾</li>
                <li><strong>çµŒæ¸ˆçš„æœ€é©åŒ–ï¼ˆPyomoï¼‰</strong>ï¼šè£½å“ä¾¡å€¤ã¨ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚³ã‚¹ãƒˆã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’è€ƒæ…®ã—ãŸè¤‡é›‘ãªæœ€é©åŒ–å•é¡Œã‚’å®šå¼åŒ–</li>
                <li><strong>MPCåŸºç¤å®Ÿè£…</strong>ï¼šè’¸ç•™å¡”ã®æ¸©åº¦åˆ¶å¾¡ã«ãŠã„ã¦ã€æœªæ¥äºˆæ¸¬ã¨åˆ¶ç´„æ¡ä»¶ã‚’è€ƒæ…®ã—ãŸæœ€é©æ“ä½œã‚’è¨ˆç®—</li>
                <li><strong>éç·šå½¢MPCï¼ˆCasADiï¼‰</strong>ï¼šåå¿œå™¨ã®éç·šå½¢ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹ã«å¯¾å¿œã—ãŸé«˜åº¦ãªãƒ¢ãƒ‡ãƒ«äºˆæ¸¬åˆ¶å¾¡ã‚’å®Ÿè£…</li>
                <li><strong>DQNãƒãƒƒãƒåˆ¶å¾¡</strong>ï¼šæ·±å±¤å¼·åŒ–å­¦ç¿’ã«ã‚ˆã‚Šãƒãƒƒãƒåå¿œå™¨ã®æœ€é©æ¸©åº¦è»Œé“ã‚’è‡ªå¾‹çš„ã«å­¦ç¿’</li>
                <li><strong>PPOé€£ç¶šåˆ¶å¾¡</strong>ï¼šé€£ç¶šå€¤è¡Œå‹•ç©ºé–“ã‚’æ‰±ã†PPOã§ã€CSTRæ¿ƒåº¦åˆ¶å¾¡ã®æœ€é©æ–¹ç­–ã‚’ç²å¾—</li>
                <li><strong>ãƒãƒ«ãƒç›®çš„æœ€é©åŒ–</strong>ï¼šNSGA-IIã«ã‚ˆã‚Šåç‡ã¨ã‚¨ãƒãƒ«ã‚®ãƒ¼ã®ãƒ‘ãƒ¬ãƒ¼ãƒˆæœ€é©è§£é›†åˆã‚’æ¢ç´¢</li>
                <li><strong>çµ±åˆAPC+RTO</strong>ï¼šéšå±¤å‹åˆ¶å¾¡ã‚·ã‚¹ãƒ†ãƒ ã§çµŒæ¸ˆæœ€é©åŒ–ã¨é«˜ç²¾åº¦è¿½å¾“åˆ¶å¾¡ã‚’ä¸¡ç«‹</li>
            </ol>
        </div>

        <div class="callout">
            <div class="callout-title">ğŸ¯ å®Ÿå‹™ã¸ã®é©ç”¨</div>
            <p><strong>å°å…¥åŠ¹æœã®å®Ÿä¾‹ï¼š</strong></p>
            <ul>
                <li><strong>Aç¤¾ï¼ˆçŸ³æ²¹ç²¾è£½ï¼‰</strong>ï¼šFCCè£…ç½®ã¸ã®RTO+MPCå°å…¥ã«ã‚ˆã‚Šã€å¹´é–“åç›Šã‚’3.5%æ”¹å–„ï¼ˆç´„15å„„å††/å¹´ï¼‰</li>
                <li><strong>Bç¤¾ï¼ˆã‚¨ãƒãƒ¬ãƒ³ãƒ—ãƒ©ãƒ³ãƒˆï¼‰</strong>ï¼šéç·šå½¢MPCã«ã‚ˆã‚Šã‚¯ãƒ©ãƒƒã‚«ãƒ¼åç‡ã‚’1.2%å‘ä¸Šã€ã‚¨ãƒãƒ«ã‚®ãƒ¼æ¶ˆè²»8%å‰Šæ¸›</li>
                <li><strong>Cç¤¾ï¼ˆãƒãƒªãƒãƒ¼è£½é€ ï¼‰</strong>ï¼šå¼·åŒ–å­¦ç¿’ãƒ™ãƒ¼ã‚¹ãƒãƒƒãƒåˆ¶å¾¡ã§ãƒ­ãƒƒãƒˆæ™‚é–“ã‚’15%çŸ­ç¸®ã€è£½å“å“è³ªãƒãƒ©ãƒ„ã‚­åŠæ¸›</li>
                <li><strong>Dç¤¾ï¼ˆåŒ–å­¦å“è£½é€ ï¼‰</strong>ï¼šãƒãƒ«ãƒç›®çš„æœ€é©åŒ–ã«ã‚ˆã‚Šã€åç‡95%ç¶­æŒã—ãªãŒã‚‰ã‚¨ãƒãƒ«ã‚®ãƒ¼ã‚³ã‚¹ãƒˆ12%å‰Šæ¸›</li>
            </ul>
        </div>

        <h3>æ¬¡ç« ã¸ã®æ¥ç¶š</h3>

        <p>æ¬¡ç« ã§ã¯ã€ãƒ—ãƒ©ãƒ³ãƒˆå…¨ä½“ã®ã‚µãƒ—ãƒ©ã‚¤ãƒã‚§ãƒ¼ãƒ³æœ€é©åŒ–ã¨ãƒ‡ã‚¸ã‚¿ãƒ«ãƒ„ã‚¤ãƒ³ã«ã¤ã„ã¦å­¦ã³ã¾ã™ã€‚éœ€è¦äºˆæ¸¬ã€ç”Ÿç”£è¨ˆç”»ã€åœ¨åº«æœ€é©åŒ–ã€ã•ã‚‰ã«ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã«ã‚ˆã‚‹ãƒ—ãƒ©ãƒ³ãƒˆé‹ç”¨æ”¯æ´ã¾ã§ã€å®Ÿè£…ãƒ¬ãƒ™ãƒ«ã§ç¿’å¾—ã—ã¾ã™ã€‚</p>

        <div class="navigation">
            <a href="chapter-2.html" class="nav-button">
                â† ç¬¬2ç« ï¼šäºˆçŸ¥ä¿å…¨ã¨RULæ¨å®š
            </a>
            <a href="chapter-4.html" class="nav-button">
                ç¬¬4ç« ï¼šã‚µãƒ—ãƒ©ã‚¤ãƒã‚§ãƒ¼ãƒ³æœ€é©åŒ– â†’
            </a>
        </div>
    </div>

    <script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
    <script>
        mermaid.initialize({
            startOnLoad: true,
            theme: 'base',
            themeVariables: {
                primaryColor: '#11998e',
                primaryTextColor: '#2c3e50',
                primaryBorderColor: '#11998e',
                lineColor: '#11998e',
                secondaryColor: '#38ef7d',
                tertiaryColor: '#e3f2fd'
            }
        });
    </script>
<section class="disclaimer">
<h3>å…è²¬äº‹é …</h3>
<ul>
<li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯æ•™è‚²ãƒ»ç ”ç©¶ãƒ»æƒ…å ±æä¾›ã®ã¿ã‚’ç›®çš„ã¨ã—ã¦ãŠã‚Šã€å°‚é–€çš„ãªåŠ©è¨€(æ³•å¾‹ãƒ»ä¼šè¨ˆãƒ»æŠ€è¡“çš„ä¿è¨¼ãªã©)ã‚’æä¾›ã™ã‚‹ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚</li>
<li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŠã‚ˆã³ä»˜éšã™ã‚‹Code examplesã¯ã€Œç¾çŠ¶æœ‰å§¿(AS IS)ã€ã§æä¾›ã•ã‚Œã€æ˜ç¤ºã¾ãŸã¯é»™ç¤ºã‚’å•ã‚ãšã€å•†å“æ€§ã€ç‰¹å®šç›®çš„é©åˆæ€§ã€æ¨©åˆ©éä¾µå®³ã€æ­£ç¢ºæ€§ãƒ»å®Œå…¨æ€§ã€å‹•ä½œãƒ»å®‰å…¨æ€§ç­‰ã„ã‹ãªã‚‹ä¿è¨¼ã‚‚ã—ã¾ã›ã‚“ã€‚</li>
<li>å¤–éƒ¨ãƒªãƒ³ã‚¯ã€ç¬¬ä¸‰è€…ãŒæä¾›ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ»ãƒ„ãƒ¼ãƒ«ãƒ»ãƒ©ã‚¤ãƒ–ãƒ©ãƒªç­‰ã®å†…å®¹ãƒ»å¯ç”¨æ€§ãƒ»å®‰å…¨æ€§ã«ã¤ã„ã¦ã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯ä¸€åˆ‡ã®è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚</li>
<li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®åˆ©ç”¨ãƒ»å®Ÿè¡Œãƒ»è§£é‡ˆã«ã‚ˆã‚Šç›´æ¥çš„ãƒ»é–“æ¥çš„ãƒ»ä»˜éšçš„ãƒ»ç‰¹åˆ¥ãƒ»çµæœçš„ãƒ»æ‡²ç½°çš„æå®³ãŒç”Ÿã˜ãŸå ´åˆã§ã‚‚ã€é©ç”¨æ³•ã§è¨±å®¹ã•ã‚Œã‚‹æœ€å¤§é™ã®ç¯„å›²ã§ã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚</li>
<li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å†…å®¹ã¯ã€äºˆå‘Šãªãå¤‰æ›´ãƒ»æ›´æ–°ãƒ»æä¾›åœæ­¢ã•ã‚Œã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚</li>
<li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®è‘—ä½œæ¨©ãƒ»ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯æ˜è¨˜ã•ã‚ŒãŸæ¡ä»¶(ä¾‹: CC BY 4.0)ã«å¾“ã„ã¾ã™ã€‚å½“è©²ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯é€šå¸¸ã€ç„¡ä¿è¨¼æ¡é …ã‚’å«ã¿ã¾ã™ã€‚</li>
</ul>
</section>

</body>
</html>
