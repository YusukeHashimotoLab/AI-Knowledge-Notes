---
title: ç¬¬3ç« ï¼šPythonã§ä½“é¨“ã™ã‚‹MLP - SchNetPackãƒãƒ³ã‚ºã‚ªãƒ³
chapter_title: ç¬¬3ç« ï¼šPythonã§ä½“é¨“ã™ã‚‹MLP - SchNetPackãƒãƒ³ã‚ºã‚ªãƒ³
---

# ç¬¬3ç« ï¼šPythonã§ä½“é¨“ã™ã‚‹MLP - SchNetPackãƒãƒ³ã‚ºã‚ªãƒ³

å°ã•ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã®è¨“ç·´ãƒ»è©•ä¾¡ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’ä¸€é€šã‚Šå›ã—ã¾ã™ã€‚å†ç¾æ€§ç¢ºä¿ã¨éå­¦ç¿’å¯¾ç­–ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚‚æ˜ç¢ºã«ã—ã¾ã™ã€‚

**ğŸ’¡ è£œè¶³:** ã‚·ãƒ¼ãƒ‰å›ºå®šã€ãƒ‡ãƒ¼ã‚¿åˆ†å‰²ã€å­¦ç¿’æ›²ç·šã®è¨˜éŒ²ãŒåŸºæœ¬ä¸‰ç‚¹ã‚»ãƒƒãƒˆã€‚æ—©æœŸçµ‚äº†ã¨é‡ã¿æ¸›è¡°ã§å®‰å®šåŒ–ã—ã¾ã™ã€‚

## å­¦ç¿’ç›®æ¨™

ã“ã®ç« ã‚’èª­ã‚€ã“ã¨ã§ã€ä»¥ä¸‹ã‚’ç¿’å¾—ã§ãã¾ã™ï¼š  
\- Pythonç’°å¢ƒã§SchNetPackã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã€ç’°å¢ƒã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã§ãã‚‹  
\- å°è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆMD17ã®ã‚¢ã‚¹ãƒ”ãƒªãƒ³åˆ†å­ï¼‰ã‚’ç”¨ã„ã¦MLPãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã§ãã‚‹  
\- è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®ç²¾åº¦ã‚’è©•ä¾¡ã—ã€ã‚¨ãƒãƒ«ã‚®ãƒ¼ãƒ»åŠ›ã®äºˆæ¸¬èª¤å·®ã‚’ç¢ºèªã§ãã‚‹  
\- MLP-MDã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œã—ã€ãƒˆãƒ©ã‚¸ã‚§ã‚¯ãƒˆãƒªã‚’è§£æã§ãã‚‹  
\- ã‚ˆãã‚ã‚‹ã‚¨ãƒ©ãƒ¼ã¨å¯¾å‡¦æ³•ã‚’ç†è§£ã™ã‚‹

* * *

## 3.1 ç’°å¢ƒæ§‹ç¯‰ï¼šå¿…è¦ãªãƒ„ãƒ¼ãƒ«ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

MLPã‚’å®Ÿè·µã™ã‚‹ã«ã¯ã€Pythonç’°å¢ƒã¨SchNetPackã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ãŒå¿…è¦ã§ã™ã€‚

### å¿…è¦ãªã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢

ãƒ„ãƒ¼ãƒ« | ãƒãƒ¼ã‚¸ãƒ§ãƒ³ | ç”¨é€”  
---|---|---  
**Python** | 3.9-3.11 | åŸºç›¤è¨€èª  
**PyTorch** | 2.0+ | ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯  
**SchNetPack** | 2.0+ | MLPè¨“ç·´ãƒ»æ¨è«–  
**ASE** | 3.22+ | åŸå­æ§‹é€ æ“ä½œã€MDå®Ÿè¡Œ  
**NumPy/Matplotlib** | æœ€æ–°ç‰ˆ | ãƒ‡ãƒ¼ã‚¿è§£æãƒ»å¯è¦–åŒ–  
  
### ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ‰‹é †

**ã‚¹ãƒ†ãƒƒãƒ—1: Condaç’°å¢ƒã®ä½œæˆ**
    
    
    # æ–°ã—ã„Condaç’°å¢ƒã‚’ä½œæˆï¼ˆPython 3.10ï¼‰
    conda create -n mlp-tutorial python=3.10 -y
    conda activate mlp-tutorial
    

**ã‚¹ãƒ†ãƒƒãƒ—2: PyTorchã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«**
    
    
    # CPUç‰ˆï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ãƒã‚·ãƒ³ã€è»½é‡ï¼‰
    conda install pytorch cpuonly -c pytorch
    
    # GPUç‰ˆï¼ˆCUDAãŒåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰
    conda install pytorch pytorch-cuda=11.8 -c pytorch -c nvidia
    

**ã‚¹ãƒ†ãƒƒãƒ—3: SchNetPackã¨ASEã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«**
    
    
    # SchNetPackï¼ˆpipæ¨å¥¨ï¼‰
    pip install schnetpack
    
    # ASEï¼ˆåŸå­ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç’°å¢ƒï¼‰
    pip install ase
    
    # å¯è¦–åŒ–ãƒ„ãƒ¼ãƒ«
    pip install matplotlib seaborn
    

**ã‚¹ãƒ†ãƒƒãƒ—4: å‹•ä½œç¢ºèª**
    
    
    # Example 1: ç’°å¢ƒç¢ºèªã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆ5è¡Œï¼‰
    import torch
    import schnetpack as spk
    print(f"PyTorch: {torch.__version__}")
    print(f"SchNetPack: {spk.__version__}")
    print(f"GPU available: {torch.cuda.is_available()}")
    

**æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›** :
    
    
    PyTorch: 2.1.0
    SchNetPack: 2.0.3
    GPU available: False  # CPUã®å ´åˆ
    

* * *

## 3.2 ãƒ‡ãƒ¼ã‚¿æº–å‚™ï¼šMD17ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®å–å¾—

SchNetPackã¯ã€å°è¦æ¨¡åˆ†å­ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ**MD17** ã‚’å†…è”µã—ã¦ã„ã¾ã™ã€‚

### MD17ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨ã¯

  * **å†…å®¹** : DFTè¨ˆç®—ã«ã‚ˆã‚‹åˆ†å­å‹•åŠ›å­¦ãƒˆãƒ©ã‚¸ã‚§ã‚¯ãƒˆãƒª
  * **å¯¾è±¡åˆ†å­** : ã‚¢ã‚¹ãƒ”ãƒªãƒ³ã€ãƒ™ãƒ³ã‚¼ãƒ³ã€ã‚¨ã‚¿ãƒãƒ¼ãƒ«ãªã©10ç¨®é¡
  * **ãƒ‡ãƒ¼ã‚¿æ•°** : å„åˆ†å­ç´„10ä¸‡é…ç½®
  * **ç²¾åº¦** : PBE/def2-SVP ãƒ¬ãƒ™ãƒ«ï¼ˆDFTï¼‰
  * **ç”¨é€”** : MLPæ‰‹æ³•ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯

### ãƒ‡ãƒ¼ã‚¿ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã¨èª­ã¿è¾¼ã¿

**Example 2: MD17ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ­ãƒ¼ãƒ‰ï¼ˆ10è¡Œï¼‰**
    
    
    from schnetpack.datasets import MD17
    from schnetpack.data import AtomsDataModule
    
    # ã‚¢ã‚¹ãƒ”ãƒªãƒ³åˆ†å­ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆç´„10ä¸‡é…ç½®ï¼‰ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    dataset = MD17(
        datapath='./data',
        molecule='aspirin',
        download=True
    )
    
    print(f"Total samples: {len(dataset)}")
    print(f"Properties: {dataset.available_properties}")
    print(f"First sample: {dataset[0]}")
    

**å‡ºåŠ›** :
    
    
    Total samples: 211762
    Properties: ['energy', 'forces']
    First sample: {'_atomic_numbers': tensor([...]), 'energy': tensor(-1234.5), 'forces': tensor([...])}
    

### ãƒ‡ãƒ¼ã‚¿ã®åˆ†å‰²

**Example 3: è¨“ç·´/æ¤œè¨¼/ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã®åˆ†å‰²ï¼ˆ10è¡Œï¼‰**
    
    
    # ãƒ‡ãƒ¼ã‚¿ã‚’è¨“ç·´:æ¤œè¨¼:ãƒ†ã‚¹ãƒˆ = 70%:15%:15%ã«åˆ†å‰²
    data_module = AtomsDataModule(
        datapath='./data',
        dataset=dataset,
        batch_size=32,
        num_train=100000,      # è¨“ç·´ãƒ‡ãƒ¼ã‚¿æ•°
        num_val=10000,          # æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿æ•°
        num_test=10000,         # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿æ•°
        split_file='split.npz', # åˆ†å‰²æƒ…å ±ã‚’ä¿å­˜
    )
    data_module.prepare_data()
    data_module.setup()
    

**èª¬æ˜** :  
\- `batch_size=32`: 32é…ç½®ãšã¤ã¾ã¨ã‚ã¦å‡¦ç†ï¼ˆãƒ¡ãƒ¢ãƒªåŠ¹ç‡ï¼‰  
\- `num_train=100000`: å¤§é‡ãƒ‡ãƒ¼ã‚¿ã§æ±åŒ–æ€§èƒ½å‘ä¸Š  
\- `split_file`: åˆ†å‰²ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ï¼ˆå†ç¾æ€§ç¢ºä¿ï¼‰

* * *

## 3.3 SchNetPackã§ã®ãƒ¢ãƒ‡ãƒ«è¨“ç·´

SchNetãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã—ã€ã‚¨ãƒãƒ«ã‚®ãƒ¼ã¨åŠ›ã‚’å­¦ç¿’ã—ã¾ã™ã€‚

### SchNetã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®è¨­å®š

**Example 4: SchNetãƒ¢ãƒ‡ãƒ«ã®å®šç¾©ï¼ˆ15è¡Œï¼‰**
    
    
    import schnetpack.transform as trn
    from schnetpack.representation import SchNet
    from schnetpack.model import AtomisticModel
    from schnetpack.task import ModelOutput
    
    # 1. SchNetè¡¨ç¾å±¤ï¼ˆåŸå­é…ç½®â†’ç‰¹å¾´ãƒ™ã‚¯ãƒˆãƒ«ï¼‰
    representation = SchNet(
        n_atom_basis=128,      # åŸå­ç‰¹å¾´ãƒ™ã‚¯ãƒˆãƒ«ã®æ¬¡å…ƒ
        n_interactions=6,      # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ‘ãƒƒã‚·ãƒ³ã‚°å±¤ã®æ•°
        cutoff=5.0,            # ã‚«ãƒƒãƒˆã‚ªãƒ•åŠå¾„ï¼ˆÃ…ï¼‰
        n_filters=128          # ãƒ•ã‚£ãƒ«ã‚¿æ•°
    )
    
    # 2. å‡ºåŠ›å±¤ï¼ˆã‚¨ãƒãƒ«ã‚®ãƒ¼äºˆæ¸¬ï¼‰
    output = ModelOutput(
        name='energy',
        loss_fn=torch.nn.MSELoss(),
        metrics={'MAE': spk.metrics.MeanAbsoluteError()}
    )
    

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è§£èª¬** :  
\- `n_atom_basis=128`: å„åŸå­ã®ç‰¹å¾´ãƒ™ã‚¯ãƒˆãƒ«ãŒ128æ¬¡å…ƒï¼ˆå…¸å‹çš„ãªå€¤ï¼‰  
\- `n_interactions=6`: 6å±¤ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ‘ãƒƒã‚·ãƒ³ã‚°ï¼ˆæ·±ã„ã»ã©é•·è·é›¢ç›¸äº’ä½œç”¨ã‚’æ‰ãˆã‚‹ï¼‰  
\- `cutoff=5.0Ã…`: ã“ã®è·é›¢ä»¥ä¸Šã®åŸå­é–“ç›¸äº’ä½œç”¨ã‚’ç„¡è¦–ï¼ˆè¨ˆç®—åŠ¹ç‡ï¼‰

### è¨“ç·´ã®å®Ÿè¡Œ

**Example 5: è¨“ç·´ãƒ«ãƒ¼ãƒ—ã®è¨­å®šï¼ˆ15è¡Œï¼‰**
    
    
    import pytorch_lightning as pl
    from schnetpack.task import AtomisticTask
    
    # è¨“ç·´ã‚¿ã‚¹ã‚¯ã®å®šç¾©
    task = AtomisticTask(
        model=AtomisticModel(representation, [output]),
        outputs=[output],
        optimizer_cls=torch.optim.AdamW,
        optimizer_args={'lr': 1e-4}  # å­¦ç¿’ç‡
    )
    
    # Trainerã®è¨­å®š
    trainer = pl.Trainer(
        max_epochs=50,               # æœ€å¤§50ã‚¨ãƒãƒƒã‚¯
        accelerator='cpu',           # CPUä½¿ç”¨ï¼ˆGPU: 'gpu'ï¼‰
        devices=1,
        default_root_dir='./training'
    )
    
    # è¨“ç·´é–‹å§‹
    trainer.fit(task, datamodule=data_module)
    

**è¨“ç·´æ™‚é–“ã®ç›®å®‰** :  
\- CPUï¼ˆ4ã‚³ã‚¢ï¼‰: ç´„2-3æ™‚é–“ï¼ˆ10ä¸‡é…ç½®ï¼‰  
\- GPUï¼ˆRTX 3090ï¼‰: ç´„15-20åˆ†

### è¨“ç·´ã®é€²æ—ç¢ºèª

**Example 6: TensorBoardã§ã®å¯è¦–åŒ–ï¼ˆ10è¡Œï¼‰**
    
    
    # TensorBoardã®èµ·å‹•ï¼ˆåˆ¥ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ï¼‰
    # tensorboard --logdir=./training/lightning_logs
    
    # Pythonã‹ã‚‰ã®ãƒ­ã‚°ç¢ºèª
    import pandas as pd
    
    metrics = pd.read_csv('./training/lightning_logs/version_0/metrics.csv')
    print(metrics[['epoch', 'train_loss', 'val_loss']].tail(10))
    

**æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›** :
    
    
       epoch  train_loss  val_loss
    40    40      0.0023    0.0031
    41    41      0.0022    0.0030
    42    42      0.0021    0.0029
    ...
    

**è¦³å¯Ÿãƒã‚¤ãƒ³ãƒˆ** :  
\- `train_loss`ã¨`val_loss`ãŒã¨ã‚‚ã«æ¸›å°‘ â†’ æ­£å¸¸ã«å­¦ç¿’ä¸­  
\- `val_loss`ãŒå¢—åŠ ã—å§‹ã‚ãŸã‚‰ **éå­¦ç¿’** ã®å…†å€™ â†’ Early Stoppingã‚’æ¤œè¨

* * *

## 3.4 ç²¾åº¦æ¤œè¨¼ï¼šã‚¨ãƒãƒ«ã‚®ãƒ¼ã¨åŠ›ã®äºˆæ¸¬ç²¾åº¦

è¨“ç·´ã—ãŸãƒ¢ãƒ‡ãƒ«ãŒDFTç²¾åº¦ã‚’é”æˆã—ã¦ã„ã‚‹ã‹è©•ä¾¡ã—ã¾ã™ã€‚

### ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã§ã®è©•ä¾¡

**Example 7: ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆè©•ä¾¡ï¼ˆ12è¡Œï¼‰**
    
    
    # ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã§è©•ä¾¡
    test_results = trainer.test(task, datamodule=data_module)
    
    # çµæœã®è¡¨ç¤º
    print(f"Energy MAE: {test_results[0]['test_energy_MAE']:.4f} eV")
    print(f"Energy RMSE: {test_results[0]['test_energy_RMSE']:.4f} eV")
    
    # åŠ›ã®è©•ä¾¡ï¼ˆåˆ¥é€”è¨ˆç®—ãŒå¿…è¦ï¼‰
    from schnetpack.metrics import MeanAbsoluteError
    force_mae = MeanAbsoluteError(target='forces')
    # ... åŠ›ã®è©•ä¾¡ã‚³ãƒ¼ãƒ‰
    

**è‰¯å¥½ãªç²¾åº¦ã®ç›®å®‰** ï¼ˆã‚¢ã‚¹ãƒ”ãƒªãƒ³åˆ†å­ã€21åŸå­ï¼‰:  
\- **ã‚¨ãƒãƒ«ã‚®ãƒ¼MAE** : < 1 kcal/molï¼ˆ< 0.043 eVï¼‰  
\- **åŠ›ã®MAE** : < 1 kcal/mol/Ã…ï¼ˆ< 0.043 eV/Ã…ï¼‰

### äºˆæ¸¬å€¤ã¨çœŸå€¤ã®ç›¸é–¢ãƒ—ãƒ­ãƒƒãƒˆ

**Example 8: äºˆæ¸¬ç²¾åº¦ã®å¯è¦–åŒ–ï¼ˆ15è¡Œï¼‰**
    
    
    import matplotlib.pyplot as plt
    import numpy as np
    
    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§äºˆæ¸¬
    model = task.model
    predictions, targets = [], []
    
    for batch in data_module.test_dataloader():
        pred = model(batch)['energy'].detach().numpy()
        true = batch['energy'].numpy()
        predictions.extend(pred)
        targets.extend(true)
    
    # æ•£å¸ƒå›³ãƒ—ãƒ­ãƒƒãƒˆ
    plt.scatter(targets, predictions, alpha=0.5, s=1)
    plt.plot([min(targets), max(targets)], [min(targets), max(targets)], 'r--')
    plt.xlabel('DFT Energy (eV)')
    plt.ylabel('MLP Predicted Energy (eV)')
    plt.title('Energy Prediction Accuracy')
    plt.show()
    

**ç†æƒ³çš„ãªçµæœ** :  
\- ç‚¹ãŒèµ¤ã„å¯¾è§’ç·šï¼ˆy=xï¼‰ä¸Šã«å¯†é›†  
\- RÂ² > 0.99ï¼ˆæ±ºå®šä¿‚æ•°ï¼‰

* * *

## 3.5 MLP-MDã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼šåˆ†å­å‹•åŠ›å­¦ã®å®Ÿè¡Œ

è¨“ç·´ã—ãŸMLPã‚’ä½¿ã£ã¦ã€DFTã‚ˆã‚Š10â´å€é«˜é€ŸãªMDã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚

### ASEã§ã®MLP-MDè¨­å®š

**Example 9: MLP-MDè¨ˆç®—ã®æº–å‚™ï¼ˆ10è¡Œï¼‰**
    
    
    from ase import units
    from ase.md.velocitydistribution import MaxwellBoltzmannDistribution
    from ase.md.verlet import VelocityVerlet
    import schnetpack.interfaces.ase_interface as spk_ase
    
    # MLPã‚’ASE Calculatorã¨ã—ã¦ãƒ©ãƒƒãƒ—
    calculator = spk_ase.SpkCalculator(
        model_file='./training/best_model.ckpt',
        device='cpu'
    )
    
    # åˆæœŸæ§‹é€ ã®æº–å‚™ï¼ˆMD17ã®æœ€åˆã®é…ç½®ï¼‰
    atoms = dataset.get_atoms(0)
    atoms.calc = calculator
    

### åˆæœŸé€Ÿåº¦ã®è¨­å®šã¨å¹³è¡¡åŒ–

**Example 10: æ¸©åº¦åˆæœŸåŒ–ï¼ˆ10è¡Œï¼‰**
    
    
    # 300Kã§ã®é€Ÿåº¦åˆ†å¸ƒã‚’è¨­å®š
    temperature = 300  # K
    MaxwellBoltzmannDistribution(atoms, temperature_K=temperature)
    
    # é‹å‹•é‡ã‚’ã‚¼ãƒ­ã«ï¼ˆç³»å…¨ä½“ã®ä¸¦é€²ã‚’é™¤å»ï¼‰
    from ase.md.velocitydistribution import Stationary
    Stationary(atoms)
    
    print(f"Initial kinetic energy: {atoms.get_kinetic_energy():.3f} eV")
    print(f"Initial potential energy: {atoms.get_potential_energy():.3f} eV")
    

### MDã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®å®Ÿè¡Œ

**Example 11: MDå®Ÿè¡Œã¨ãƒˆãƒ©ã‚¸ã‚§ã‚¯ãƒˆãƒªä¿å­˜ï¼ˆ12è¡Œï¼‰**
    
    
    from ase.io.trajectory import Trajectory
    
    # MDã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ã®è¨­å®š
    timestep = 0.5 * units.fs  # 0.5ãƒ•ã‚§ãƒ ãƒˆç§’
    dyn = VelocityVerlet(atoms, timestep=timestep)
    
    # ãƒˆãƒ©ã‚¸ã‚§ã‚¯ãƒˆãƒªãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›
    traj = Trajectory('aspirin_md.traj', 'w', atoms)
    dyn.attach(traj.write, interval=10)  # 10ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã«ä¿å­˜
    
    # 10,000ã‚¹ãƒ†ãƒƒãƒ—ï¼ˆ5ãƒ”ã‚³ç§’ï¼‰ã®MDå®Ÿè¡Œ
    dyn.run(10000)
    print("MD simulation completed!")
    

**è¨ˆç®—æ™‚é–“ã®ç›®å®‰** :  
\- CPUï¼ˆ4ã‚³ã‚¢ï¼‰: ç´„5åˆ†ï¼ˆ10,000ã‚¹ãƒ†ãƒƒãƒ—ï¼‰  
\- DFTãªã‚‰: ç´„1é€±é–“ï¼ˆ10,000ã‚¹ãƒ†ãƒƒãƒ—ï¼‰  
\- **10â´å€ã®é«˜é€ŸåŒ–é”æˆï¼**

### ãƒˆãƒ©ã‚¸ã‚§ã‚¯ãƒˆãƒªã®è§£æ

**Example 12: ã‚¨ãƒãƒ«ã‚®ãƒ¼ä¿å­˜ã¨RDFè¨ˆç®—ï¼ˆ15è¡Œï¼‰**
    
    
    from ase.io import read
    import numpy as np
    
    # ãƒˆãƒ©ã‚¸ã‚§ã‚¯ãƒˆãƒªã®èª­ã¿è¾¼ã¿
    traj_data = read('aspirin_md.traj', index=':')
    
    # ã‚¨ãƒãƒ«ã‚®ãƒ¼ä¿å­˜ã®ç¢ºèª
    energies = [a.get_total_energy() for a in traj_data]
    plt.plot(energies)
    plt.xlabel('Time step')
    plt.ylabel('Total Energy (eV)')
    plt.title('Energy Conservation Check')
    plt.show()
    
    # ã‚¨ãƒãƒ«ã‚®ãƒ¼ãƒ‰ãƒªãƒ•ãƒˆï¼ˆå˜èª¿å¢—åŠ /æ¸›å°‘ï¼‰ã®è¨ˆç®—
    drift = (energies[-1] - energies[0]) / len(energies)
    print(f"Energy drift: {drift:.6f} eV/step")
    

**è‰¯å¥½ãªã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®æŒ‡æ¨™** :  
\- ã‚¨ãƒãƒ«ã‚®ãƒ¼ãƒ‰ãƒªãƒ•ãƒˆ: < 0.001 eV/step  
\- å…¨ã‚¨ãƒãƒ«ã‚®ãƒ¼ãŒæ™‚é–“ã¨ã¨ã‚‚ã«æŒ¯å‹•ï¼ˆä¿å­˜å‰‡ï¼‰

* * *

## 3.6 ç‰©æ€§è¨ˆç®—ï¼šæŒ¯å‹•ã‚¹ãƒšã‚¯ãƒˆãƒ«ã¨æ‹¡æ•£ä¿‚æ•°

MLP-MDã‹ã‚‰ç‰©ç†çš„ãªç‰©æ€§å€¤ã‚’è¨ˆç®—ã—ã¾ã™ã€‚

### æŒ¯å‹•ã‚¹ãƒšã‚¯ãƒˆãƒ«ï¼ˆãƒ‘ãƒ¯ãƒ¼ã‚¹ãƒšã‚¯ãƒˆãƒ«ï¼‰

**Example 13: æŒ¯å‹•ã‚¹ãƒšã‚¯ãƒˆãƒ«è¨ˆç®—ï¼ˆ15è¡Œï¼‰**
    
    
    from scipy.fft import fft, fftfreq
    
    # 1ã¤ã®åŸå­ã®é€Ÿåº¦æ™‚ç³»åˆ—ã‚’æŠ½å‡º
    atom_idx = 0  # æœ€åˆã®åŸå­
    velocities = np.array([a.get_velocities()[atom_idx] for a in traj_data])
    
    # xæ–¹å‘é€Ÿåº¦ã®ãƒ•ãƒ¼ãƒªã‚¨å¤‰æ›
    vx = velocities[:, 0]
    freq = fftfreq(len(vx), d=timestep)
    spectrum = np.abs(fft(vx))**2
    
    # æ­£ã®å‘¨æ³¢æ•°ã®ã¿ãƒ—ãƒ­ãƒƒãƒˆ
    mask = freq > 0
    plt.plot(freq[mask] * 1e15 / (2 * np.pi), spectrum[mask])  # Hz â†’ THzå¤‰æ›
    plt.xlabel('Frequency (THz)')
    plt.ylabel('Power Spectrum')
    plt.title('Vibrational Spectrum')
    plt.xlim(0, 100)
    plt.show()
    

**è§£é‡ˆ** :  
\- ãƒ”ãƒ¼ã‚¯ãŒåˆ†å­ã®æŒ¯å‹•ãƒ¢ãƒ¼ãƒ‰ã«å¯¾å¿œ  
\- DFTã§è¨ˆç®—ã—ãŸæŒ¯å‹•ã‚¹ãƒšã‚¯ãƒˆãƒ«ã¨æ¯”è¼ƒã™ã‚‹ã“ã¨ã§ç²¾åº¦æ¤œè¨¼

### å¹³å‡äºŒä¹—å¤‰ä½ï¼ˆMSDï¼‰ã¨æ‹¡æ•£ä¿‚æ•°

**Example 14: MSDè¨ˆç®—ï¼ˆ15è¡Œï¼‰**
    
    
    def calculate_msd(traj, atom_idx=0):
        """å¹³å‡äºŒä¹—å¤‰ä½ã‚’è¨ˆç®—"""
        positions = np.array([a.positions[atom_idx] for a in traj])
        msd = np.zeros(len(positions))
    
        for t in range(len(positions)):
            displacement = positions[t:] - positions[:-t or None]
            msd[t] = np.mean(np.sum(displacement**2, axis=1))
    
        return msd
    
    # MSDè¨ˆç®—ã¨ãƒ—ãƒ­ãƒƒãƒˆ
    msd = calculate_msd(traj_data)
    time_ps = np.arange(len(msd)) * timestep / units.fs * 1e-3  # ãƒ”ã‚³ç§’
    
    plt.plot(time_ps, msd)
    plt.xlabel('Time (ps)')
    plt.ylabel('MSD (Å²)')
    plt.title('Mean Square Displacement')
    plt.show()
    

**æ‹¡æ•£ä¿‚æ•°ã®è¨ˆç®—** :
    
    
    # MSDã®ç·šå½¢é ˜åŸŸã‹ã‚‰æ‹¡æ•£ä¿‚æ•°ã‚’è¨ˆç®—ï¼ˆEinsteiné–¢ä¿‚å¼ï¼‰
    # D = lim_{tâ†’âˆ} MSD(t) / (6t)
    linear_region = slice(100, 500)
    fit = np.polyfit(time_ps[linear_region], msd[linear_region], deg=1)
    D = fit[0] / 6  # Å²/ps â†’ cmÂ²/så¤‰æ›ãŒå¿…è¦
    print(f"Diffusion coefficient: {D:.6f} Å²/ps")
    

* * *

## 3.7 Active Learningï¼šåŠ¹ç‡çš„ãªãƒ‡ãƒ¼ã‚¿è¿½åŠ 

ãƒ¢ãƒ‡ãƒ«ãŒä¸ç¢ºå®Ÿãªé…ç½®ã‚’è‡ªå‹•æ¤œå‡ºã—ã€DFTè¨ˆç®—ã‚’è¿½åŠ ã—ã¾ã™ã€‚

### ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ä¸ç¢ºå®Ÿæ€§ã®è©•ä¾¡

**Example 15: äºˆæ¸¬ã®ä¸ç¢ºå®Ÿæ€§ï¼ˆ15è¡Œï¼‰**
    
    
    # è¤‡æ•°ã®ç‹¬ç«‹ã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ï¼ˆçœç•¥ï¼šExample 5ã‚’3å›å®Ÿè¡Œï¼‰
    models = [model1, model2, model3]  # 3ã¤ã®ç‹¬ç«‹ãƒ¢ãƒ‡ãƒ«
    
    def predict_with_uncertainty(atoms, models):
        """ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬ã¨ä¸ç¢ºå®Ÿæ€§"""
        predictions = []
        for model in models:
            atoms.calc = spk_ase.SpkCalculator(model_file=model, device='cpu')
            predictions.append(atoms.get_potential_energy())
    
        mean = np.mean(predictions)
        std = np.std(predictions)
        return mean, std
    
    # MDãƒˆãƒ©ã‚¸ã‚§ã‚¯ãƒˆãƒªã®å„é…ç½®ã§ä¸ç¢ºå®Ÿæ€§è©•ä¾¡
    uncertainties = []
    for atoms in traj_data[::100]:  # 100ãƒ•ãƒ¬ãƒ¼ãƒ ã”ã¨
        _, std = predict_with_uncertainty(atoms, models)
        uncertainties.append(std)
    
    # ä¸ç¢ºå®Ÿæ€§ãŒé«˜ã„é…ç½®ã‚’ç‰¹å®š
    threshold = np.percentile(uncertainties, 95)
    high_uncertainty_frames = np.where(np.array(uncertainties) > threshold)[0]
    print(f"High uncertainty frames: {high_uncertainty_frames}")
    

**æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—** :  
\- ä¸ç¢ºå®Ÿæ€§ã®é«˜ã„é…ç½®ã‚’DFTè¨ˆç®—ã«è¿½åŠ   
\- ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ›´æ–°ã—ã¦ãƒ¢ãƒ‡ãƒ«å†è¨“ç·´  
\- ç²¾åº¦å‘ä¸Šã‚’ç¢ºèª

* * *

## 3.8 ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ï¼šã‚ˆãã‚ã‚‹ã‚¨ãƒ©ãƒ¼ã¨å¯¾å‡¦æ³•

å®Ÿè·µã§ã‚ˆãé­é‡ã™ã‚‹å•é¡Œã¨è§£æ±ºç­–ã‚’ç´¹ä»‹ã—ã¾ã™ã€‚

ã‚¨ãƒ©ãƒ¼ | åŸå›  | å¯¾å‡¦æ³•  
---|---|---  
**Out of Memory (OOM)** | ãƒãƒƒãƒã‚µã‚¤ã‚ºãŒå¤§ãã™ãã‚‹ | `batch_size`ã‚’32â†’16â†’8ã¨æ¸›ã‚‰ã™  
**Loss becomes NaN** | å­¦ç¿’ç‡ãŒé«˜ã™ãã‚‹ | `lr=1e-4`â†’`1e-5`ã«ä¸‹ã’ã‚‹  
**Energy drift in MD** | ã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ—ãŒå¤§ãã™ãã‚‹ | `timestep=0.5fs`â†’`0.25fs`ã«æ¸›ã‚‰ã™  
**Poor generalization** | è¨“ç·´ãƒ‡ãƒ¼ã‚¿ãŒåã£ã¦ã„ã‚‹ | Active Learningã§ãƒ‡ãƒ¼ã‚¿å¤šæ§˜åŒ–  
**CUDA error** | GPUäº’æ›æ€§ã®å•é¡Œ | PyTorchã¨CUDAãƒãƒ¼ã‚¸ãƒ§ãƒ³ç¢ºèª  
  
### ãƒ‡ãƒãƒƒã‚°ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹
    
    
    # 1. å°è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã§ãƒ†ã‚¹ãƒˆ
    data_module.num_train = 1000  # 1,000é…ç½®ã§ã‚¯ã‚¤ãƒƒã‚¯ãƒ†ã‚¹ãƒˆ
    
    # 2. 1ãƒãƒƒãƒã§ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°ç¢ºèª
    trainer = pl.Trainer(max_epochs=100, overfit_batches=1)
    # è¨“ç·´èª¤å·®ãŒ0ã«è¿‘ã¥ã‘ã°ã€ãƒ¢ãƒ‡ãƒ«ã«å­¦ç¿’èƒ½åŠ›ã‚ã‚Š
    
    # 3. ã‚°ãƒ©ãƒ‡ã‚£ã‚¨ãƒ³ãƒˆã®ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°
    task = AtomisticTask(..., gradient_clip_val=1.0)  # å‹¾é…çˆ†ç™ºé˜²æ­¢
    

* * *

## 3.9 æœ¬ç« ã®ã¾ã¨ã‚

### å­¦ã‚“ã ã“ã¨

  1. **ç’°å¢ƒæ§‹ç¯‰**  
\- Condaç’°å¢ƒã€PyTorchã€SchNetPackã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«  
\- GPU/CPUç’°å¢ƒã®é¸æŠ

  2. **ãƒ‡ãƒ¼ã‚¿æº–å‚™**  
\- MD17ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã¨èª­ã¿è¾¼ã¿  
\- è¨“ç·´/æ¤œè¨¼/ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã¸ã®åˆ†å‰²

  3. **ãƒ¢ãƒ‡ãƒ«è¨“ç·´**  
\- SchNetã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®è¨­å®šï¼ˆ6å±¤ã€128æ¬¡å…ƒï¼‰  
\- 50ã‚¨ãƒãƒƒã‚¯ã®è¨“ç·´ï¼ˆCPU: 2-3æ™‚é–“ï¼‰  
\- TensorBoardã§ã®é€²æ—ç¢ºèª

  4. **ç²¾åº¦æ¤œè¨¼**  
\- ã‚¨ãƒãƒ«ã‚®ãƒ¼MAE < 1 kcal/molé”æˆã‚’ç¢ºèª  
\- äºˆæ¸¬å€¤vsçœŸå€¤ã®ç›¸é–¢ãƒ—ãƒ­ãƒƒãƒˆ  
\- RÂ² > 0.99ã®é«˜ç²¾åº¦

  5. **MLP-MDå®Ÿè¡Œ**  
\- ASE Calculatorã¨ã—ã¦ã®çµ±åˆ  
\- 10,000ã‚¹ãƒ†ãƒƒãƒ—ï¼ˆ5ãƒ”ã‚³ç§’ï¼‰ã®MDå®Ÿè¡Œ  
\- DFTã‚ˆã‚Š10â´å€é«˜é€ŸåŒ–ã‚’ä½“é¨“

  6. **ç‰©æ€§è¨ˆç®—**  
\- æŒ¯å‹•ã‚¹ãƒšã‚¯ãƒˆãƒ«ï¼ˆãƒ•ãƒ¼ãƒªã‚¨å¤‰æ›ï¼‰  
\- æ‹¡æ•£ä¿‚æ•°ï¼ˆå¹³å‡äºŒä¹—å¤‰ä½ã‹ã‚‰è¨ˆç®—ï¼‰

  7. **Active Learning**  
\- ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ä¸ç¢ºå®Ÿæ€§ã«ã‚ˆã‚‹é…ç½®é¸æŠ  
\- ãƒ‡ãƒ¼ã‚¿è¿½åŠ ã®è‡ªå‹•åŒ–æˆ¦ç•¥

### é‡è¦ãªãƒã‚¤ãƒ³ãƒˆ

  * **SchNetPackã¯å®Ÿè£…ãŒå®¹æ˜“** : æ•°åè¡Œã®ã‚³ãƒ¼ãƒ‰ã§MLPè¨“ç·´ãŒå¯èƒ½
  * **å°è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ï¼ˆ10ä¸‡é…ç½®ï¼‰ã§å®Ÿç”¨ç²¾åº¦é”æˆ** : MD17ã¯å„ªã‚ŒãŸãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
  * **MLP-MDã¯å®Ÿç”¨çš„** : DFTã®10â´å€é«˜é€Ÿã€å€‹äººã®PCã§å®Ÿè¡Œå¯èƒ½
  * **Active Learningã§åŠ¹ç‡åŒ–** : é‡è¦ãªé…ç½®ã‚’è‡ªå‹•ç™ºè¦‹ã€ãƒ‡ãƒ¼ã‚¿åé›†ã‚³ã‚¹ãƒˆå‰Šæ¸›

### æ¬¡ã®ç« ã¸

ç¬¬4ç« ã§ã¯ã€æœ€æ–°ã®MLPæ‰‹æ³•ï¼ˆNequIPã€MACEï¼‰ã¨å®Ÿéš›ã®ç ”ç©¶å¿œç”¨ä¾‹ã‚’å­¦ã³ã¾ã™ï¼š  
\- E(3)ç­‰å¤‰ã‚°ãƒ©ãƒ•ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®ç†è«–  
\- ãƒ‡ãƒ¼ã‚¿åŠ¹ç‡ã®åŠ‡çš„å‘ä¸Šï¼ˆ10ä¸‡â†’3,000é…ç½®ï¼‰  
\- è§¦åª’åå¿œã€ãƒãƒƒãƒ†ãƒªãƒ¼ææ–™ã¸ã®å¿œç”¨äº‹ä¾‹  
\- å¤§è¦æ¨¡ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆ100ä¸‡åŸå­ï¼‰ã®å®Ÿç¾

* * *

## æ¼”ç¿’å•é¡Œ

### å•é¡Œ1ï¼ˆé›£æ˜“åº¦ï¼šeasyï¼‰

Example 4ã®SchNetè¨­å®šã§ã€`n_interactions`ï¼ˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ‘ãƒƒã‚·ãƒ³ã‚°å±¤ã®æ•°ï¼‰ã‚’3, 6, 9ã«å¤‰ãˆã¦è¨“ç·´ã—ã€ãƒ†ã‚¹ãƒˆMAEãŒã©ã®ã‚ˆã†ã«å¤‰åŒ–ã™ã‚‹ã‹äºˆæ¸¬ã—ã¦ãã ã•ã„ã€‚

ãƒ’ãƒ³ãƒˆ å±¤ãŒæ·±ã„ã»ã©ã€é•·è·é›¢ã®åŸå­é–“ç›¸äº’ä½œç”¨ã‚’æ‰ãˆã‚‰ã‚Œã¾ã™ã€‚ã—ã‹ã—ã€æ·±ã™ãã‚‹ã¨éå­¦ç¿’ã®ãƒªã‚¹ã‚¯ã‚‚ã€‚  è§£ç­”ä¾‹ **äºˆæ¸¬ã•ã‚Œã‚‹çµæœ**: | `n_interactions` | ãƒ†ã‚¹ãƒˆMAEäºˆæ¸¬ | è¨“ç·´æ™‚é–“ | ç‰¹å¾´ | |-----------------|-------------|---------|------| | **3** | 0.8-1.2 kcal/mol | 1æ™‚é–“ | æµ…ã„ãŸã‚é•·è·é›¢ç›¸äº’ä½œç”¨ã‚’æ‰ãˆãã‚Œãªã„ | | **6** | 0.5-0.8 kcal/mol | 2-3æ™‚é–“ | ãƒãƒ©ãƒ³ã‚¹ãŒè‰¯ã„ï¼ˆæ¨å¥¨ï¼‰ | | **9** | 0.6-1.0 kcal/mol | 4-5æ™‚é–“ | éå­¦ç¿’ãƒªã‚¹ã‚¯ã€è¨“ç·´ãƒ‡ãƒ¼ã‚¿ä¸è¶³ãªã‚‰ç²¾åº¦ä½ä¸‹ | **å®Ÿé¨“æ–¹æ³•**: 
    
    
    for n in [3, 6, 9]:
        representation = SchNet(n_interactions=n, ...)
        task = AtomisticTask(...)
        trainer.fit(task, datamodule=data_module)
        results = trainer.test(task, datamodule=data_module)
        print(f"n={n}: MAE={results[0]['test_energy_MAE']:.4f} eV")
    

**çµè«–**: å°åˆ†å­ï¼ˆã‚¢ã‚¹ãƒ”ãƒªãƒ³21åŸå­ï¼‰ã§ã¯`n_interactions=6`ãŒæœ€é©ã€‚å¤§è¦æ¨¡ç³»ï¼ˆ100åŸå­ä»¥ä¸Šï¼‰ã§ã¯9-12å±¤ãŒæœ‰åŠ¹ãªå ´åˆã‚‚ã‚ã‚‹ã€‚ 

### å•é¡Œ2ï¼ˆé›£æ˜“åº¦ï¼šmediumï¼‰

Example 11ã®MLP-MDã§ã€ã‚¨ãƒãƒ«ã‚®ãƒ¼ãƒ‰ãƒªãƒ•ãƒˆãŒè¨±å®¹ç¯„å›²ã‚’è¶…ãˆãŸå ´åˆï¼ˆä¾‹: 0.01 eV/stepï¼‰ã€ã©ã®ã‚ˆã†ãªå¯¾å‡¦æ³•ãŒè€ƒãˆã‚‰ã‚Œã¾ã™ã‹ï¼Ÿ3ã¤æŒ™ã’ã¦ãã ã•ã„ã€‚

ãƒ’ãƒ³ãƒˆ ã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ—ã€è¨“ç·´ç²¾åº¦ã€MDã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®3ã¤ã®è¦³ç‚¹ã‹ã‚‰è€ƒãˆã¾ã—ã‚‡ã†ã€‚  è§£ç­”ä¾‹ **å¯¾å‡¦æ³•1: ã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ—ã‚’å°ã•ãã™ã‚‹** 
    
    
    timestep = 0.25 * units.fs  # 0.5fs â†’ 0.25fsã«åŠæ¸›
    dyn = VelocityVerlet(atoms, timestep=timestep)
    

\- **ç†ç”±**: å°ã•ã„ã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ—ã¯æ•°å€¤ç©åˆ†ã®èª¤å·®ã‚’æ¸›ã‚‰ã™ \- **ãƒ‡ãƒ¡ãƒªãƒƒãƒˆ**: 2å€ã®è¨ˆç®—æ™‚é–“ **å¯¾å‡¦æ³•2: ãƒ¢ãƒ‡ãƒ«è¨“ç·´ç²¾åº¦ã‚’å‘ä¸Š** 
    
    
    # ã‚ˆã‚Šå¤šãã®ãƒ‡ãƒ¼ã‚¿ã§è¨“ç·´
    data_module.num_train = 200000  # 10ä¸‡â†’20ä¸‡é…ç½®ã«å¢—åŠ 
    
    # ã¾ãŸã¯åŠ›ã®æå¤±é–¢æ•°ã®é‡ã¿ã‚’å¢—ã‚„ã™
    task = AtomisticTask(..., loss_weights={'energy': 1.0, 'forces': 1000})
    

\- **ç†ç”±**: åŠ›ã®äºˆæ¸¬ç²¾åº¦ãŒä½ã„ã¨MDãŒä¸å®‰å®š \- **ç›®æ¨™**: åŠ›ã®MAE < 0.05 eV/Ã… **å¯¾å‡¦æ³•3: Langevinå‹•åŠ›å­¦ã«å¤‰æ›´ï¼ˆç†±æµ´çµåˆï¼‰** 
    
    
    from ase.md.langevin import Langevin
    dyn = Langevin(atoms, timestep=0.5*units.fs,
                   temperature_K=300, friction=0.01)
    

\- **ç†ç”±**: ç†±æµ´ãŒã‚¨ãƒãƒ«ã‚®ãƒ¼ãƒ‰ãƒªãƒ•ãƒˆã‚’å¸å \- **æ³¨æ„**: å³å¯†ãªå¾®å°æ­£æº–ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ï¼ˆNVEï¼‰ã§ã¯ãªããªã‚‹ **å„ªå…ˆé †ä½**: å¯¾å‡¦æ³•2ï¼ˆç²¾åº¦å‘ä¸Šï¼‰â†’ å¯¾å‡¦æ³•1ï¼ˆã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ—ï¼‰â†’ å¯¾å‡¦æ³•3ï¼ˆLangevinï¼‰ 

* * *

## 3.10 ãƒ‡ãƒ¼ã‚¿ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¨å†ç¾æ€§

æœ¬ç« ã®ãƒãƒ³ã‚ºã‚ªãƒ³ã‚³ãƒ¼ãƒ‰ã‚’å†ç¾ã™ã‚‹ãŸã‚ã«å¿…è¦ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨ãƒ„ãƒ¼ãƒ«ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³æƒ…å ±ã‚’è¨˜è¼‰ã—ã¾ã™ã€‚

### 3.10.1 ä½¿ç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ

ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ | èª¬æ˜ | ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ | ã‚¢ã‚¯ã‚»ã‚¹æ–¹æ³•  
---|---|---|---  
**MD17** | å°åˆ†å­MDè»Œé“ï¼ˆã‚¢ã‚¹ãƒ”ãƒªãƒ³ã€ãƒ™ãƒ³ã‚¼ãƒ³ãªã©10ç¨®é¡ï¼‰ | CC0 1.0 (Public Domain) | SchNetPackå†…è”µ (`MD17(molecule='aspirin')`)  
**ã‚¢ã‚¹ãƒ”ãƒªãƒ³åˆ†å­** | 211,762é…ç½®ã€DFTï¼ˆPBE/def2-SVPï¼‰ | CC0 1.0 | [sgdml.org](<http://sgdml.org/#datasets>)  
  
**æ³¨æ„äº‹é …** :  
\- **å•†ç”¨åˆ©ç”¨** : CC0ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã«ã‚ˆã‚Šã€å•†ç”¨åˆ©ç”¨ãƒ»æ”¹å¤‰ãƒ»å†é…å¸ƒã™ã¹ã¦è‡ªç”±  
\- **è«–æ–‡å¼•ç”¨** : MD17ä½¿ç”¨æ™‚ã¯ä»¥ä¸‹ã‚’å¼•ç”¨  
Chmiela, S., et al. (2017). "Machine learning of accurate energy-conserving molecular force fields." _Science Advances_ , 3(5), e1603015.  
\- **ãƒ‡ãƒ¼ã‚¿å®Œå…¨æ€§** : SchNetPackã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½ã¯SHA256ãƒã‚§ãƒƒã‚¯ã‚µãƒ ã§æ¤œè¨¼

### 3.10.2 ã‚³ãƒ¼ãƒ‰å†ç¾æ€§ã®ãŸã‚ã®ç’°å¢ƒæƒ…å ±

æœ¬ç« ã®ã‚³ãƒ¼ãƒ‰ä¾‹ã‚’æ­£ç¢ºã«å†ç¾ã™ã‚‹ãŸã‚ã«ã€ä»¥ä¸‹ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚

ãƒ„ãƒ¼ãƒ« | æ¨å¥¨ãƒãƒ¼ã‚¸ãƒ§ãƒ³ | ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã‚³ãƒãƒ³ãƒ‰ | äº’æ›æ€§  
---|---|---|---  
**Python** | 3.10.x | `conda create -n mlp python=3.10` | 3.9-3.11ã§å‹•ä½œç¢ºèªæ¸ˆã¿  
**PyTorch** | 2.1.0 | `conda install pytorch=2.1.0` | 2.0ä»¥ä¸Šå¿…é ˆ  
**SchNetPack** | 2.0.3 | `pip install schnetpack==2.0.3` | 2.0ç³»ã¨1.xç³»ã§APIãŒç•°ãªã‚‹  
**ASE** | 3.22.1 | `pip install ase==3.22.1` | 3.20ä»¥ä¸Šæ¨å¥¨  
**PyTorch Lightning** | 2.1.0 | `pip install pytorch-lightning==2.1.0` | SchNetPack 2.0.3ã¨äº’æ›  
**NumPy** | 1.24.3 | `pip install numpy==1.24.3` | 1.20ä»¥ä¸Š  
**Matplotlib** | 3.7.1 | `pip install matplotlib==3.7.1` | 3.5ä»¥ä¸Š  
  
**ç’°å¢ƒãƒ•ã‚¡ã‚¤ãƒ«ã®ä¿å­˜** :
    
    
    # ç¾åœ¨ã®ç’°å¢ƒã‚’å†ç¾å¯èƒ½ãªå½¢ã§ä¿å­˜
    conda env export > environment.yml
    
    # ä»–ã®ç’°å¢ƒã§å†ç¾
    conda env create -f environment.yml
    

**Dockerã«ã‚ˆã‚‹å†ç¾æ€§ç¢ºä¿** ï¼ˆæ¨å¥¨ï¼‰:
    
    
    # Dockerfileä¾‹
    FROM pytorch/pytorch:2.1.0-cuda11.8-cudnn8-runtime
    RUN pip install schnetpack==2.0.3 ase==3.22.1 pytorch-lightning==2.1.0
    

### 3.10.3 è¨“ç·´ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å®Œå…¨è¨˜éŒ²

Example 4, 5ã§ä½¿ç”¨ã—ãŸãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å…¨è¨˜éŒ²ï¼ˆè«–æ–‡å†ç¾ç”¨ï¼‰:

ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ | å€¤ | èª¬æ˜  
---|---|---  
`n_atom_basis` | 128 | åŸå­ç‰¹å¾´ãƒ™ã‚¯ãƒˆãƒ«ã®æ¬¡å…ƒ  
`n_interactions` | 6 | ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ‘ãƒƒã‚·ãƒ³ã‚°å±¤ã®æ•°  
`cutoff` | 5.0 Ã… | åŸå­é–“ç›¸äº’ä½œç”¨ã®ã‚«ãƒƒãƒˆã‚ªãƒ•åŠå¾„  
`n_filters` | 128 | ç•³ã¿è¾¼ã¿ãƒ•ã‚£ãƒ«ã‚¿ã®æ•°  
`batch_size` | 32 | ãƒŸãƒ‹ãƒãƒƒãƒã‚µã‚¤ã‚º  
`learning_rate` | 1e-4 | åˆæœŸå­¦ç¿’ç‡ï¼ˆAdamWï¼‰  
`max_epochs` | 50 | æœ€å¤§è¨“ç·´ã‚¨ãƒãƒƒã‚¯æ•°  
`num_train` | 100,000 | è¨“ç·´ãƒ‡ãƒ¼ã‚¿æ•°  
`num_val` | 10,000 | æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿æ•°  
`num_test` | 10,000 | ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿æ•°  
`random_seed` | 42 | ä¹±æ•°ã‚·ãƒ¼ãƒ‰ï¼ˆãƒ‡ãƒ¼ã‚¿åˆ†å‰²ã®å†ç¾æ€§ï¼‰  
  
**å®Œå…¨ãªå†ç¾ã‚³ãƒ¼ãƒ‰** :
    
    
    import torch
    torch.manual_seed(42)  # å†ç¾æ€§ç¢ºä¿
    
    representation = SchNet(
        n_atom_basis=128, n_interactions=6, cutoff=5.0, n_filters=128
    )
    task = AtomisticTask(
        model=AtomisticModel(representation, [output]),
        optimizer_cls=torch.optim.AdamW,
        optimizer_args={'lr': 1e-4, 'weight_decay': 0.01}
    )
    trainer = pl.Trainer(max_epochs=50, deterministic=True)
    

### 3.10.4 ã‚¨ãƒãƒ«ã‚®ãƒ¼ãƒ»åŠ›ã®å˜ä½æ›ç®—è¡¨

æœ¬ç« ã§ä½¿ç”¨ã™ã‚‹ç‰©ç†é‡ã®å˜ä½æ›ç®—ï¼ˆSchNetPackã¨ASEã®æ¨™æº–å˜ä½ï¼‰:

ç‰©ç†é‡ | SchNetPack/ASE | eV | kcal/mol | Hartree  
---|---|---|---|---  
**ã‚¨ãƒãƒ«ã‚®ãƒ¼** | eV | 1.0 | 23.06 | 0.03674  
**åŠ›** | eV/Ã… | 1.0 | 23.06 | 0.01945  
**è·é›¢** | Ã… | - | - | 1.889726 Bohr  
**æ™‚é–“** | fs (ãƒ•ã‚§ãƒ ãƒˆç§’) | - | - | 0.02419 a.u.  
  
**å˜ä½å¤‰æ›ä¾‹** :
    
    
    from ase import units
    
    # ã‚¨ãƒãƒ«ã‚®ãƒ¼æ›ç®—
    energy_ev = 1.0  # eV
    energy_kcal = energy_ev * 23.06052  # kcal/mol
    energy_hartree = energy_ev * 0.036749  # Hartree
    
    # ASEã®å˜ä½å®šæ•°ã‚’ä½¿ç”¨ï¼ˆæ¨å¥¨ï¼‰
    print(f"{energy_ev} eV = {energy_ev * units.eV / units.kcal * units.mol} kcal/mol")
    

* * *

## 3.11 å®Ÿè·µä¸Šã®æ³¨æ„ç‚¹ï¼šãƒãƒ³ã‚ºã‚ªãƒ³ã§ã®å¤±æ•—ãƒ‘ã‚¿ãƒ¼ãƒ³

### 3.11.1 ç’°å¢ƒæ§‹ç¯‰ã¨ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã®è½ã¨ã—ç©´

**å¤±æ•—1: PyTorchã¨CUDAãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®ä¸ä¸€è‡´**

**å•é¡Œ** :
    
    
    RuntimeError: CUDA error: no kernel image is available for execution on the device
    

**åŸå› ** :  
PyTorch 2.1.0ã¯CUDA 11.8ã¾ãŸã¯12.1ã§ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã•ã‚Œã¦ã„ã‚‹ãŒã€ã‚·ã‚¹ãƒ†ãƒ ã®CUDAãŒ10.2ãªã©å¤ã„ãƒãƒ¼ã‚¸ãƒ§ãƒ³

**è¨ºæ–­ã‚³ãƒ¼ãƒ‰** :
    
    
    import torch
    print(f"PyTorch version: {torch.__version__}")
    print(f"CUDA available: {torch.cuda.is_available()}")
    print(f"CUDA version (PyTorch): {torch.version.cuda}")
    
    # ã‚·ã‚¹ãƒ†ãƒ CUDAãƒãƒ¼ã‚¸ãƒ§ãƒ³ç¢ºèªï¼ˆã‚¿ãƒ¼ãƒŸãƒŠãƒ«ï¼‰
    # nvcc --version
    

**å¯¾å‡¦æ³•** :
    
    
    # ã‚·ã‚¹ãƒ†ãƒ CUDA 11.8ã®å ´åˆ
    conda install pytorch==2.1.0 pytorch-cuda=11.8 -c pytorch -c nvidia
    
    # CUDAåˆ©ç”¨ä¸å¯ã®å ´åˆã¯CPUç‰ˆã«åˆ‡ã‚Šæ›¿ãˆ
    conda install pytorch==2.1.0 cpuonly -c pytorch
    

**äºˆé˜²ç­–** :  
ç’°å¢ƒæ§‹ç¯‰å‰ã« `nvidia-smi` ã§GPUãƒ‰ãƒ©ã‚¤ãƒã¨CUDAãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ç¢ºèªã™ã‚‹

**å¤±æ•—2: SchNetPack 1.x ã¨ 2.x ã®APIæ··åŒ**

**å•é¡Œ** :
    
    
    AttributeError: module 'schnetpack' has no attribute 'AtomsData'
    

**åŸå› ** :  
SchNetPack 1.xç³»ã®å¤ã„ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã‚³ãƒ¼ãƒ‰ã‚’2.xç³»ã§å®Ÿè¡Œ

**ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç¢ºèª** :
    
    
    import schnetpack as spk
    print(spk.__version__)  # 2.0.3ãªã‚‰æœ¬ç« ã®ã‚³ãƒ¼ãƒ‰ãŒå‹•ä½œ
    

**ä¸»ãªAPIå¤‰æ›´** :

SchNetPack 1.x | SchNetPack 2.x  
---|---  
`spk.AtomsData` | `spk.data.AtomsDataModule`  
`spk.atomistic.Atomwise` | `spk.task.ModelOutput`  
`spk.train.Trainer` | `pytorch_lightning.Trainer`  
  
**å¯¾å‡¦æ³•** :  
æœ¬ç« ã®ã‚³ãƒ¼ãƒ‰ä¾‹ï¼ˆ2.xç³»ï¼‰ã‚’ä½¿ç”¨ã™ã‚‹ã‹ã€SchNetPackå…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆï¼ˆ[schnetpack.readthedocs.io](<https://schnetpack.readthedocs.io>)ï¼‰ã®2.xç³»ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã‚’å‚ç…§

**å¤±æ•—3: ãƒ¡ãƒ¢ãƒªä¸è¶³ï¼ˆOOMï¼‰ã®èª¤è¨ºæ–­**

**å•é¡Œ** :
    
    
    RuntimeError: CUDA out of memory. Tried to allocate 1.50 GiB
    

**ã‚ˆãã‚ã‚‹èª¤è§£** :  
ã€ŒGPUãƒ¡ãƒ¢ãƒªä¸è¶³ãªã®ã§GPUã‚’è²·ã„æ›¿ãˆã‚‹å¿…è¦ãŒã‚ã‚‹ã€â†’ **é–“é•ã„**

**è¨ºæ–­æ‰‹é †** :
    
    
    # 1. ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’ç¢ºèª
    print(f"Current batch size: {data_module.batch_size}")
    
    # 2. GPUãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’ç¢ºèª
    if torch.cuda.is_available():
        print(f"GPU memory allocated: {torch.cuda.memory_allocated() / 1e9:.2f} GB")
        print(f"GPU memory reserved: {torch.cuda.memory_reserved() / 1e9:.2f} GB")
    

**å¯¾å‡¦æ³•ï¼ˆå„ªå…ˆé †ï¼‰** :

  1. **ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’æ¸›ã‚‰ã™** : `batch_size=32` â†’ `16` â†’ `8` â†’ `4`
  2. **å‹¾é…ç´¯ç©** : å°ãƒãƒƒãƒã‚’è¤‡æ•°å›ç´¯ç©ã—ã¦ç–‘ä¼¼çš„ã«å¤§ãƒãƒƒãƒ

    
    
    trainer = pl.Trainer(accumulate_grad_batches=4)  # 4ãƒãƒƒãƒã”ã¨ã«æ›´æ–°
    

  3. **Mixed Precisionè¨“ç·´** : ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’åŠæ¸›

    
    
    trainer = pl.Trainer(precision=16)  # float16ä½¿ç”¨
    

**ç›®å®‰** :  
\- GPU 4GB: batch_size=4-8  
\- GPU 8GB: batch_size=16-32  
\- GPU 24GB: batch_size=64-128

### 3.11.2 è¨“ç·´ã¨ãƒ‡ãƒãƒƒã‚°ã®è½ã¨ã—ç©´

**å¤±æ•—4: è¨“ç·´èª¤å·®ãŒæ¸›å°‘ã—ãªã„ï¼ˆNaNæå¤±ï¼‰**

**å•é¡Œ** :
    
    
    Epoch 5: train_loss=nan, val_loss=nan
    

**åŸå› ãƒˆãƒƒãƒ—3** :

  1. **å­¦ç¿’ç‡ãŒé«˜ã™ãã‚‹** : å‹¾é…çˆ†ç™º â†’ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒNaNã«
  2. **ãƒ‡ãƒ¼ã‚¿æ­£è¦åŒ–ã®æ¬ å¦‚** : ã‚¨ãƒãƒ«ã‚®ãƒ¼ã®çµ¶å¯¾å€¤ãŒå¤§ãã™ãã‚‹ï¼ˆä¾‹: -1000 eVï¼‰
  3. **åŠ›ã®æå¤±ä¿‚æ•°ãŒä¸é©åˆ‡** : åŠ›ã®æå¤±ãŒæ”¯é…çš„ã™ãã‚‹

**è¨ºæ–­ã‚³ãƒ¼ãƒ‰** :
    
    
    # è¨“ç·´é–‹å§‹ç›´å¾Œã«ãƒ¢ãƒ‡ãƒ«ã®å‡ºåŠ›ã‚’ç¢ºèª
    for batch in data_module.train_dataloader():
        output = task.model(batch)
        print(f"Energy prediction: {output['energy'][:5]}")  # æœ€åˆã®5ã‚µãƒ³ãƒ—ãƒ«
        print(f"Energy target: {batch['energy'][:5]}")
        break
    
    # NaNãƒã‚§ãƒƒã‚¯
    print(f"Has NaN in prediction: {torch.isnan(output['energy']).any()}")
    

**å¯¾å‡¦æ³•** :

  1. **å­¦ç¿’ç‡ã‚’ä¸‹ã’ã‚‹** :

    
    
    optimizer_args={'lr': 1e-5}  # 1e-4 â†’ 1e-5ã«æ¸›å°‘
    

  2. **å‹¾é…ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°** :

    
    
    trainer = pl.Trainer(gradient_clip_val=1.0)  # å‹¾é…ãƒãƒ«ãƒ ã‚’1.0ä»¥ä¸‹ã«
    

  3. **ãƒ‡ãƒ¼ã‚¿æ­£è¦åŒ–** ï¼ˆSchNetPack 2.xã¯è‡ªå‹•ã ãŒã€æ‰‹å‹•ç¢ºèªï¼‰:

    
    
    import schnetpack.transform as trn
    data_module.train_transforms = [
        trn.SubtractCenterOfMass(),
        trn.RemoveOffsets('energy', remove_mean=True)  # ã‚¨ãƒãƒ«ã‚®ãƒ¼ã‚ªãƒ•ã‚»ãƒƒãƒˆé™¤å»
    ]
    

**å¤±æ•—5: éå­¦ç¿’ã®è¦‹é€ƒã—**

**å•é¡Œ** :  
è¨“ç·´èª¤å·®ã¯æ¸›å°‘ã™ã‚‹ãŒã€æ¤œè¨¼èª¤å·®ãŒåœæ»ã¾ãŸã¯å¢—åŠ 
    
    
    Epoch 30: train_loss=0.001, val_loss=0.050  # val_lossãŒæ‚ªåŒ–
    

**åŸå› ** :  
ãƒ¢ãƒ‡ãƒ«ãŒè¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚’è¨˜æ†¶ã—ã€æœªçŸ¥ãƒ‡ãƒ¼ã‚¿ã¸ã®æ±åŒ–æ€§èƒ½ãŒä½ä¸‹

**è¨ºæ–­ã‚°ãƒ©ãƒ•** :
    
    
    import matplotlib.pyplot as plt
    import pandas as pd
    
    metrics = pd.read_csv('./training/lightning_logs/version_0/metrics.csv')
    plt.plot(metrics['epoch'], metrics['train_loss'], label='Train')
    plt.plot(metrics['epoch'], metrics['val_loss'], label='Validation')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.show()
    

**å¯¾å‡¦æ³•** :

  1. **Early Stopping** ï¼ˆè‡ªå‹•åœæ­¢ï¼‰:

    
    
    from pytorch_lightning.callbacks import EarlyStopping
    
    early_stop = EarlyStopping(monitor='val_loss', patience=10, mode='min')
    trainer = pl.Trainer(callbacks=[early_stop])
    

  2. **ãƒ‡ãƒ¼ã‚¿å¢—å¼·** ï¼ˆè¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚’å¢—ã‚„ã™ï¼‰:

    
    
    data_module.num_train = 200000  # 10ä¸‡ â†’ 20ä¸‡ã«å¢—åŠ 
    

  3. **Dropoutï¼ˆéæ¨å¥¨ã€MLPã§ã¯åŠ¹æœè–„ã„ï¼‰** : ä»£ã‚ã‚Šã«ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã‚’æ¸›ã‚‰ã™

    
    
    representation = SchNet(n_atom_basis=64, n_interactions=4)  # 128â†’64ã«å‰Šæ¸›
    

### 3.11.3 MLP-MDã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®è½ã¨ã—ç©´

**å¤±æ•—6: ã‚¨ãƒãƒ«ã‚®ãƒ¼ãƒ‰ãƒªãƒ•ãƒˆã®éå°è©•ä¾¡**

**å•é¡Œ** :  
MDã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ä¸­ã«ã‚¨ãƒãƒ«ã‚®ãƒ¼ãŒå˜èª¿å¢—åŠ /æ¸›å°‘ï¼ˆä¿å­˜å‰‡ã®ç ´ã‚Œï¼‰

**è¨±å®¹ç¯„å›²ã®èª¤è§£** :

  * ã€Œå°‘ã—ãã‚‰ã„ã®ãƒ‰ãƒªãƒ•ãƒˆã¯ä»•æ–¹ãªã„ã€â†’ **å±é™º**
  * 0.01 eV/stepã®ãƒ‰ãƒªãƒ•ãƒˆã§ã‚‚ã€10,000ã‚¹ãƒ†ãƒƒãƒ—ã§100 eVã®ã‚¨ãƒãƒ«ã‚®ãƒ¼å¤‰åŒ–ï¼ˆéç¾å®Ÿçš„ï¼‰

**å®šé‡è¨ºæ–­** :
    
    
    from ase.io import read
    
    traj = read('aspirin_md.traj', index=':')
    energies = [a.get_total_energy() for a in traj]
    
    # ãƒ‰ãƒªãƒ•ãƒˆã®è¨ˆç®—ï¼ˆç·šå½¢ãƒ•ã‚£ãƒƒãƒˆï¼‰
    import numpy as np
    time_steps = np.arange(len(energies))
    drift_rate, offset = np.polyfit(time_steps, energies, deg=1)
    print(f"Energy drift: {drift_rate:.6f} eV/step")
    
    # è¨±å®¹ç¯„å›²ãƒã‚§ãƒƒã‚¯
    if abs(drift_rate) > 0.001:
        print("âš ï¸ WARNING: Excessive energy drift detected!")
    

**å¯¾å‡¦æ³•ï¼ˆå•é¡Œ2ã®è©³ç´°ç‰ˆï¼‰** :

  1. **åŠ›ã®è¨“ç·´ç²¾åº¦ã‚’å‘ä¸Š** ï¼ˆæœ€é‡è¦ï¼‰:

    
    
    # åŠ›ã®æå¤±é–¢æ•°ã®é‡ã¿ã‚’å¤§å¹…ã«å¢—åŠ 
    task = AtomisticTask(
        loss_weights={'energy': 0.01, 'forces': 0.99}  # åŠ›ã«99%ã®é‡ã¿
    )
    

  2. **ã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ—ã®æœ€é©åŒ–** :

    
    
    # å®‰å®šæ€§ãƒ†ã‚¹ãƒˆ
    for dt in [0.1, 0.25, 0.5, 1.0]:  # fs
        # dt=0.5ã§å®‰å®šã€dt=1.0ã§ç™ºæ•£ãªã‚‰ã€dt=0.5ã‚’æ¡ç”¨
    

  3. **MLPç²¾åº¦ã®é™ç•Œã‚’èªè­˜** :  
åŠ›ã®MAE > 0.1 eV/Ã…ã®å ´åˆã€é•·æ™‚é–“MDï¼ˆ>10 psï¼‰ã¯ä¿¡é ¼æ€§ä½ä¸‹  
â†’ Active Learningã§è¨“ç·´ãƒ‡ãƒ¼ã‚¿è¿½åŠ 

**å¤±æ•—7: MDçµæœã®ç‰©ç†çš„å¦¥å½“æ€§ã®æœªæ¤œè¨¼**

**å•é¡Œ** :  
ã€ŒMDãŒå®Œèµ°ã—ãŸã‹ã‚‰æˆåŠŸã€ã¨èª¤è§£ â†’ å®Ÿã¯éç‰©ç†çš„ãªæ§‹é€ å¤‰åŒ–

**æ¤œè¨¼ã™ã¹ãé …ç›®** :

**1\. æ¸©åº¦åˆ¶å¾¡ã®ç¢ºèª** :
    
    
    temperatures = [a.get_temperature() for a in traj]
    print(f"Average T: {np.mean(temperatures):.1f} K (target: 300 K)")
    print(f"Std T: {np.std(temperatures):.1f} K")
    # æ¨™æº–åå·®ãŒ30Kä»¥ä¸Šãªã‚‰ç•°å¸¸
    

**2\. æ§‹é€ ã®ç ´å£Šãƒã‚§ãƒƒã‚¯** :
    
    
    from ase.geometry.analysis import Analysis
    
    # åˆæœŸæ§‹é€ ã¨æœ€çµ‚æ§‹é€ ã®æ¯”è¼ƒ
    ana_init = Analysis(traj[0])
    ana_final = Analysis(traj[-1])
    
    # çµåˆãŒåˆ‡ã‚Œã¦ã„ãªã„ã‹ç¢ºèª
    bonds_init = ana_init.all_bonds[0]
    bonds_final = ana_final.all_bonds[0]
    print(f"Initial bonds: {len(bonds_init)}, Final bonds: {len(bonds_final)}")
    
    # çµåˆæ•°ãŒå¤‰åŒ– â†’ æ§‹é€ ç ´å£Šã®å¯èƒ½æ€§
    

**3\. å‹•å¾„åˆ†å¸ƒé–¢æ•°ï¼ˆRDFï¼‰ã®å¦¥å½“æ€§** :
    
    
    # ç¬¬ä¸€ãƒ”ãƒ¼ã‚¯ä½ç½®ãŒDFTè¨ˆç®—ã‚„Xç·šå›æŠ˜ãƒ‡ãƒ¼ã‚¿ã¨ä¸€è‡´ã™ã‚‹ã‹ç¢ºèª
    # ï¼ˆå®Ÿè£…ã¯é«˜åº¦ãªãŸã‚ã€çœç•¥ï¼‰
    

**å¯¾å‡¦æ³•** :  
ç‰©ç†çš„ã«å¦¥å½“ãªçµæœãŒå¾—ã‚‰ã‚Œãªã„å ´åˆã€è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®ç¯„å›²å¤–ï¼ˆå¤–æŒ¿ï¼‰ã®å¯èƒ½æ€§  
â†’ Active Learningã§è©²å½“ã™ã‚‹é…ç½®ã‚’è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã«è¿½åŠ 

* * *

## 3.12 ç« æœ«ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆï¼šãƒãƒ³ã‚ºã‚ªãƒ³ã®å“è³ªä¿è¨¼

ã“ã®ç« ã‚’å®Œäº†ã—ãŸã‚‰ã€ä»¥ä¸‹ã®é …ç›®ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚å…¨ã¦ãƒã‚§ãƒƒã‚¯ã§ãã‚Œã°ã€å®Ÿéš›ã®ç ”ç©¶ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§MLPã‚’æ´»ç”¨ã™ã‚‹æº–å‚™ãŒæ•´ã£ã¦ã„ã¾ã™ã€‚

### 3.12.1 æ¦‚å¿µç†è§£ï¼ˆUnderstandingï¼‰

**ç’°å¢ƒã¨ãƒ„ãƒ¼ãƒ«ã®ç†è§£** :

  * â–¡ SchNetPackã®å½¹å‰²ï¼ˆMLPè¨“ç·´ãƒ©ã‚¤ãƒ–ãƒ©ãƒªï¼‰ã‚’èª¬æ˜ã§ãã‚‹
  * â–¡ PyTorchã¨SchNetPackã®é–¢ä¿‚ï¼ˆPyTorchãƒ™ãƒ¼ã‚¹ã®MLPå®Ÿè£…ï¼‰ã‚’ç†è§£ã—ã¦ã„ã‚‹
  * â–¡ ASEã®å½¹å‰²ï¼ˆåŸå­æ§‹é€ æ“ä½œã€MDå®Ÿè¡Œï¼‰ã‚’èª¬æ˜ã§ãã‚‹
  * â–¡ MD17ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ç‰¹å¾´ï¼ˆ10ç¨®é¡ã®å°åˆ†å­ã€DFTç²¾åº¦ï¼‰ã‚’ç†è§£ã—ã¦ã„ã‚‹

**ãƒ¢ãƒ‡ãƒ«è¨“ç·´ã®ç†è§£** :

  * â–¡ SchNetã®ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆ`n_atom_basis`ã€`n_interactions`ã€`cutoff`ï¼‰ã®æ„å‘³ã‚’èª¬æ˜ã§ãã‚‹
  * â–¡ è¨“ç·´/æ¤œè¨¼/ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã®å½¹å‰²ã‚’ç†è§£ã—ã¦ã„ã‚‹
  * â–¡ éå­¦ç¿’ã®å…†å€™ï¼ˆæ¤œè¨¼èª¤å·®ã®å¢—åŠ ï¼‰ã‚’è­˜åˆ¥ã§ãã‚‹
  * â–¡ ã‚¨ãƒãƒ«ã‚®ãƒ¼MAE < 1 kcal/molãŒé«˜ç²¾åº¦ã®ç›®å®‰ã§ã‚ã‚‹ã“ã¨ã‚’ç†è§£ã—ã¦ã„ã‚‹

**MLP-MDã®ç†è§£** :

  * â–¡ MLPãŒASE Calculatorã¨ã—ã¦çµ±åˆã•ã‚Œã‚‹ä»•çµ„ã¿ã‚’ç†è§£ã—ã¦ã„ã‚‹
  * â–¡ ã‚¨ãƒãƒ«ã‚®ãƒ¼ä¿å­˜å‰‡ã¨ã‚¨ãƒãƒ«ã‚®ãƒ¼ãƒ‰ãƒªãƒ•ãƒˆã®é•ã„ã‚’èª¬æ˜ã§ãã‚‹
  * â–¡ ã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ—ï¼ˆ0.5 fsï¼‰ãŒå®‰å®šæ€§ã«å½±éŸ¿ã™ã‚‹ç†ç”±ã‚’ç†è§£ã—ã¦ã„ã‚‹
  * â–¡ MLP-MDãŒDFTã‚ˆã‚Š10â´å€é«˜é€Ÿãªç†ç”±ã‚’èª¬æ˜ã§ãã‚‹

### 3.12.2 å®Ÿè·µã‚¹ã‚­ãƒ«ï¼ˆDoingï¼‰

**ç’°å¢ƒæ§‹ç¯‰** :

  * â–¡ Condaç’°å¢ƒã‚’ä½œæˆã—ã€Python 3.10ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã§ãã‚‹
  * â–¡ PyTorchï¼ˆCPUç‰ˆ/GPUç‰ˆï¼‰ã‚’æ­£ã—ãã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã§ãã‚‹
  * â–¡ SchNetPack 2.0.3ã¨ASE 3.22.1ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã§ãã‚‹
  * â–¡ ç’°å¢ƒç¢ºèªã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å®Ÿè¡Œã—ã€ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ç¢ºèªã§ãã‚‹

**ãƒ‡ãƒ¼ã‚¿æº–å‚™ã¨è¨“ç·´** :

  * â–¡ MD17ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã€10ä¸‡é…ç½®ã«åˆ†å‰²ã§ãã‚‹
  * â–¡ SchNetãƒ¢ãƒ‡ãƒ«ã‚’å®šç¾©ã—ã€ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¨­å®šã§ãã‚‹
  * â–¡ 50ã‚¨ãƒãƒƒã‚¯ã®è¨“ç·´ã‚’å®Ÿè¡Œã—ã€TensorBoardã§é€²æ—ã‚’ç¢ºèªã§ãã‚‹
  * â–¡ ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã§MAEã‚’è©•ä¾¡ã—ã€ç›®æ¨™ç²¾åº¦ï¼ˆ< 1 kcal/molï¼‰ã‚’é”æˆã§ãã‚‹

**MLP-MDã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³** :

  * â–¡ è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ASE Calculatorã¨ã—ã¦ãƒ©ãƒƒãƒ—ã§ãã‚‹
  * â–¡ Maxwell-Boltzmannåˆ†å¸ƒã§åˆæœŸé€Ÿåº¦ã‚’è¨­å®šã§ãã‚‹
  * â–¡ 10,000ã‚¹ãƒ†ãƒƒãƒ—ï¼ˆ5ãƒ”ã‚³ç§’ï¼‰ã®MDã‚’å®Ÿè¡Œã§ãã‚‹
  * â–¡ ãƒˆãƒ©ã‚¸ã‚§ã‚¯ãƒˆãƒªã‚’ä¿å­˜ã—ã€ã‚¨ãƒãƒ«ã‚®ãƒ¼ä¿å­˜ã‚’ç¢ºèªã§ãã‚‹

**è§£æã¨ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°** :

  * â–¡ æŒ¯å‹•ã‚¹ãƒšã‚¯ãƒˆãƒ«ï¼ˆãƒ‘ãƒ¯ãƒ¼ã‚¹ãƒšã‚¯ãƒˆãƒ«ï¼‰ã‚’è¨ˆç®—ã§ãã‚‹
  * â–¡ å¹³å‡äºŒä¹—å¤‰ä½ï¼ˆMSDï¼‰ã‹ã‚‰æ‹¡æ•£ä¿‚æ•°ã‚’è¨ˆç®—ã§ãã‚‹
  * â–¡ Out of Memoryï¼ˆOOMï¼‰ã‚¨ãƒ©ãƒ¼ã«å¯¾å‡¦ã§ãã‚‹ï¼ˆãƒãƒƒãƒã‚µã‚¤ã‚ºå‰Šæ¸›ï¼‰
  * â–¡ NaNæå¤±ã®åŸå› ã‚’è¨ºæ–­ã—ã€å­¦ç¿’ç‡ã‚’èª¿æ•´ã§ãã‚‹

### 3.12.3 å¿œç”¨åŠ›ï¼ˆApplyingï¼‰

**è‡ªåˆ†ã®ç ”ç©¶ã¸ã®é©ç”¨è¨ˆç”»** :

  * â–¡ è‡ªåˆ†ã®ç ”ç©¶å¯¾è±¡ï¼ˆåˆ†å­ã€ææ–™ï¼‰ã§MD17ç›¸å½“ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’è¨­è¨ˆã§ãã‚‹
  * â–¡ å¿…è¦ãªDFTè¨ˆç®—æ•°ï¼ˆç›®æ¨™ç²¾åº¦ã¨ç³»ã®ã‚µã‚¤ã‚ºã‹ã‚‰ï¼‰ã‚’è¦‹ç©ã‚‚ã‚Œã‚‹
  * â–¡ SchNetã®ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è‡ªåˆ†ã®ç³»ã«æœ€é©åŒ–ã™ã‚‹æˆ¦ç•¥ã‚’ç«‹ã¦ã‚‰ã‚Œã‚‹
  * â–¡ MLP-MDã§å¾—ãŸã„ç‰©æ€§ï¼ˆæ‹¡æ•£ä¿‚æ•°ã€æŒ¯å‹•ã‚¹ãƒšã‚¯ãƒˆãƒ«ã€åå¿œçµŒè·¯ï¼‰ã‚’æ˜ç¢ºã«ã§ãã‚‹

**å•é¡Œè§£æ±ºã¨ãƒ‡ãƒãƒƒã‚°** :

  * â–¡ è¨“ç·´ãŒåæŸã—ãªã„å ´åˆã®è¨ºæ–­æ‰‹é †ï¼ˆå­¦ç¿’ç‡ã€ãƒ‡ãƒ¼ã‚¿æ­£è¦åŒ–ã€å‹¾é…ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°ï¼‰ã‚’å®Ÿè¡Œã§ãã‚‹
  * â–¡ ã‚¨ãƒãƒ«ã‚®ãƒ¼ãƒ‰ãƒªãƒ•ãƒˆã®åŸå› ã‚’ç‰¹å®šã—ã€å¯¾å‡¦æ³•ã‚’é¸æŠã§ãã‚‹
  * â–¡ éå­¦ç¿’ã‚’æ¤œå‡ºã—ã€Early Stoppingã‚„Data Augmentationã‚’é©ç”¨ã§ãã‚‹
  * â–¡ GPU/CPUãƒªã‚½ãƒ¼ã‚¹ã«å¿œã˜ã¦ãƒãƒƒãƒã‚µã‚¤ã‚ºã¨è¨“ç·´æ™‚é–“ã‚’æœ€é©åŒ–ã§ãã‚‹

**AdvancedæŠ€è¡“ã¸ã®æº–å‚™** :

  * â–¡ Active Learningï¼ˆExample 15ï¼‰ã®æ¦‚å¿µã‚’ç†è§£ã—ã€å®Ÿè£…ã®æµã‚Œã‚’èª¬æ˜ã§ãã‚‹
  * â–¡ ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ä¸ç¢ºå®Ÿæ€§ã«ã‚ˆã‚‹é…ç½®é¸æŠã®é‡è¦æ€§ã‚’ç†è§£ã—ã¦ã„ã‚‹
  * â–¡ æ¬¡ç« ï¼ˆNequIPã€MACEï¼‰ã§ãƒ‡ãƒ¼ã‚¿åŠ¹ç‡ãŒã©ã†æ”¹å–„ã•ã‚Œã‚‹ã‹æœŸå¾…ã‚’æŒã£ã¦ã„ã‚‹
  * â–¡ SchNetPackã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆï¼ˆ[schnetpack.readthedocs.io](<https://schnetpack.readthedocs.io>)ï¼‰ã‚’æ´»ç”¨ã—ã¦ã€ç‹¬å­¦ã§å­¦ç¿’ã‚’ç¶šã‘ã‚‰ã‚Œã‚‹

**æ¬¡ç« ã¸ã®ãƒ–ãƒªãƒƒã‚¸** :

  * â–¡ SchNetã®é™ç•Œï¼ˆãƒ‡ãƒ¼ã‚¿åŠ¹ç‡ã€å›è»¢ç­‰å¤‰æ€§ï¼‰ã‚’èªè­˜ã—ã¦ã„ã‚‹
  * â–¡ E(3)ç­‰å¤‰æ€§ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ï¼ˆNequIPã€MACEï¼‰ãŒã©ã†æ”¹å–„ã™ã‚‹ã‹èˆˆå‘³ã‚’æŒã£ã¦ã„ã‚‹
  * â–¡ å®Ÿéš›ã®ç ”ç©¶å¿œç”¨ä¾‹ï¼ˆè§¦åª’ã€ãƒãƒƒãƒ†ãƒªãƒ¼ã€å‰µè–¬ï¼‰ã‚’ç¬¬4ç« ã§å­¦ã¶æº–å‚™ãŒã§ãã¦ã„ã‚‹

* * *

## å‚è€ƒæ–‡çŒ®

  1. SchÃ¼tt, K. T., et al. (2019). "SchNetPack: A Deep Learning Toolbox For Atomistic Systems." _Journal of Chemical Theory and Computation_ , 15(1), 448-455.  
DOI: [10.1021/acs.jctc.8b00908](<https://doi.org/10.1021/acs.jctc.8b00908>)

  2. Chmiela, S., et al. (2017). "Machine learning of accurate energy-conserving molecular force fields." _Science Advances_ , 3(5), e1603015.  
DOI: [10.1126/sciadv.1603015](<https://doi.org/10.1126/sciadv.1603015>)

  3. Larsen, A. H., et al. (2017). "The atomic simulation environmentâ€”a Python library for working with atoms." _Journal of Physics: Condensed Matter_ , 29(27), 273002.  
DOI: [10.1088/1361-648X/aa680e](<https://doi.org/10.1088/1361-648X/aa680e>)

  4. Paszke, A., et al. (2019). "PyTorch: An imperative style, high-performance deep learning library." _Advances in Neural Information Processing Systems_ , 32.  
arXiv: [1912.01703](<https://arxiv.org/abs/1912.01703>)

  5. Zhang, L., et al. (2020). "Active learning of uniformly accurate interatomic potentials for materials simulation." _Physical Review Materials_ , 3(2), 023804.  
DOI: [10.1103/PhysRevMaterials.3.023804](<https://doi.org/10.1103/PhysRevMaterials.3.023804>)

  6. SchÃ¼tt, K. T., et al. (2017). "Quantum-chemical insights from deep tensor neural networks." _Nature Communications_ , 8(1), 13890.  
DOI: [10.1038/ncomms13890](<https://doi.org/10.1038/ncomms13890>)

* * *

## è‘—è€…æƒ…å ±

**ä½œæˆè€…** : MI Knowledge Hub Content Team  
**ä½œæˆæ—¥** : 2025-10-17  
**ãƒãƒ¼ã‚¸ãƒ§ãƒ³** : 1.1ï¼ˆChapter 3 quality improvementï¼‰  
**ã‚·ãƒªãƒ¼ã‚º** : MLPå…¥é–€ã‚·ãƒªãƒ¼ã‚º

**æ›´æ–°å±¥æ­´** :  
\- 2025-10-19: v1.1 å“è³ªå‘ä¸Šæ”¹è¨‚  
\- ãƒ‡ãƒ¼ã‚¿ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¨å†ç¾æ€§ã‚»ã‚¯ã‚·ãƒ§ãƒ³è¿½åŠ ï¼ˆMD17ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€ã‚¢ã‚¹ãƒ”ãƒªãƒ³åˆ†å­æƒ…å ±ï¼‰  
\- ã‚³ãƒ¼ãƒ‰å†ç¾æ€§æƒ…å ±ï¼ˆPython 3.10.x, PyTorch 2.1.0, SchNetPack 2.0.3, ASE 3.22.1ï¼‰  
\- è¨“ç·´ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å®Œå…¨è¨˜éŒ²ï¼ˆ11é …ç›®ã€è«–æ–‡å†ç¾ç”¨ï¼‰  
\- ã‚¨ãƒãƒ«ã‚®ãƒ¼ãƒ»åŠ›ã®å˜ä½æ›ç®—è¡¨ï¼ˆeV, kcal/mol, Hartreeç›¸äº’å¤‰æ›ï¼‰  
\- å®Ÿè·µä¸Šã®æ³¨æ„ç‚¹ã‚»ã‚¯ã‚·ãƒ§ãƒ³è¿½åŠ ï¼ˆ7ã¤ã®å¤±æ•—ãƒ‘ã‚¿ãƒ¼ãƒ³: CUDAä¸ä¸€è‡´ã€APIæ··åŒã€OOMã€NaNæå¤±ã€éå­¦ç¿’ã€ã‚¨ãƒãƒ«ã‚®ãƒ¼ãƒ‰ãƒªãƒ•ãƒˆã€ç‰©ç†å¦¥å½“æ€§ï¼‰  
\- ç« æœ«ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆè¿½åŠ ï¼ˆæ¦‚å¿µç†è§£12é …ç›®ã€å®Ÿè·µã‚¹ã‚­ãƒ«16é …ç›®ã€å¿œç”¨åŠ›16é …ç›®ï¼‰  
\- 2025-10-17: v1.0 ç¬¬3ç« åˆç‰ˆä½œæˆ  
\- Pythonç’°å¢ƒæ§‹ç¯‰ï¼ˆConda, PyTorch, SchNetPackï¼‰  
\- MD17ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæº–å‚™ã¨åˆ†å‰²  
\- SchNetãƒ¢ãƒ‡ãƒ«è¨“ç·´ï¼ˆ15ã‚³ãƒ¼ãƒ‰ä¾‹ï¼‰  
\- MLP-MDå®Ÿè¡Œã¨è§£æï¼ˆãƒˆãƒ©ã‚¸ã‚§ã‚¯ãƒˆãƒªã€æŒ¯å‹•ã‚¹ãƒšã‚¯ãƒˆãƒ«ã€MSDï¼‰  
\- Active Learningä¸ç¢ºå®Ÿæ€§è©•ä¾¡  
\- ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°è¡¨ï¼ˆ5é …ç›®ï¼‰  
\- æ¼”ç¿’å•é¡Œ2å•ï¼ˆeasy, mediumï¼‰  
\- å‚è€ƒæ–‡çŒ®6ä»¶

**ãƒ©ã‚¤ã‚»ãƒ³ã‚¹** : Creative Commons BY-NC-SA 4.0

[â† ã‚·ãƒªãƒ¼ã‚ºç›®æ¬¡ã«æˆ»ã‚‹](<index.html>)
