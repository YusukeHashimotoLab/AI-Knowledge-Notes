<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
<meta content="ç¬¬3ç« ï¼šç²å¾—é–¢æ•°è¨­è¨ˆ - AI Terakoya" name="description"/>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ç¬¬3ç« ï¼šç²å¾—é–¢æ•°è¨­è¨ˆ - AI Terakoya</title>

    <style>
        :root {
            --color-primary: #2c3e50;
            --color-primary-dark: #1a252f;
            --color-accent: #7b2cbf;
            --color-accent-light: #9d4edd;
            --color-text: #2d3748;
            --color-text-light: #4a5568;
            --color-bg: #ffffff;
            --color-bg-alt: #f7fafc;
            --color-border: #e2e8f0;
            --color-code-bg: #f8f9fa;
            --color-link: #3182ce;
            --color-link-hover: #2c5aa0;

            --spacing-xs: 0.5rem;
            --spacing-sm: 1rem;
            --spacing-md: 1.5rem;
            --spacing-lg: 2rem;
            --spacing-xl: 3rem;

            --font-body: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            --font-mono: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;

            --border-radius: 8px;
            --box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: var(--font-body);
            line-height: 1.7;
            color: var(--color-text);
            background-color: var(--color-bg);
            font-size: 16px;
        }

        header {
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            padding: var(--spacing-xl) var(--spacing-md);
            margin-bottom: var(--spacing-xl);
            box-shadow: var(--box-shadow);
        }

        .header-content {
            max-width: 900px;
            margin: 0 auto;
        }

        h1 {
            font-size: 2rem;
            font-weight: 700;
            margin-bottom: var(--spacing-sm);
            line-height: 1.2;
        }

        .subtitle {
            font-size: 1.1rem;
            opacity: 0.95;
            font-weight: 400;
            margin-bottom: var(--spacing-md);
        }

        .meta {
            display: flex;
            flex-wrap: wrap;
            gap: var(--spacing-md);
            font-size: 0.9rem;
            opacity: 0.9;
        }

        .meta-item {
            display: flex;
            align-items: center;
            gap: 0.3rem;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 0 var(--spacing-md) var(--spacing-xl);
        }

        h2 {
            font-size: 1.75rem;
            color: var(--color-primary);
            margin-top: var(--spacing-xl);
            margin-bottom: var(--spacing-md);
            padding-bottom: var(--spacing-xs);
            border-bottom: 3px solid var(--color-accent);
        }

        h3 {
            font-size: 1.4rem;
            color: var(--color-primary);
            margin-top: var(--spacing-lg);
            margin-bottom: var(--spacing-sm);
        }

        h4 {
            font-size: 1.1rem;
            color: var(--color-primary-dark);
            margin-top: var(--spacing-md);
            margin-bottom: var(--spacing-sm);
        }

        p {
            margin-bottom: var(--spacing-md);
            color: var(--color-text);
        }

        a {
            color: var(--color-link);
            text-decoration: none;
            transition: color 0.2s;
        }

        a:hover {
            color: var(--color-link-hover);
            text-decoration: underline;
        }

        ul, ol {
            margin-left: var(--spacing-lg);
            margin-bottom: var(--spacing-md);
        }

        li {
            margin-bottom: var(--spacing-xs);
            color: var(--color-text);
        }

        pre {
            background-color: var(--color-code-bg);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            overflow-x: auto;
            margin-bottom: var(--spacing-md);
            font-family: var(--font-mono);
            font-size: 0.9rem;
            line-height: 1.5;
        }

        code {
            font-family: var(--font-mono);
            font-size: 0.9em;
            background-color: var(--color-code-bg);
            padding: 0.2em 0.4em;
            border-radius: 3px;
        }

        pre code {
            background-color: transparent;
            padding: 0;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: var(--spacing-md);
            font-size: 0.95rem;
        }

        th, td {
            border: 1px solid var(--color-border);
            padding: var(--spacing-sm);
            text-align: left;
        }

        th {
            background-color: var(--color-bg-alt);
            font-weight: 600;
            color: var(--color-primary);
        }

        blockquote {
            border-left: 4px solid var(--color-accent);
            padding-left: var(--spacing-md);
            margin: var(--spacing-md) 0;
            color: var(--color-text-light);
            font-style: italic;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        .mermaid {
            text-align: center;
            margin: var(--spacing-lg) 0;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        details {
            background-color: var(--color-bg-alt);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            margin-bottom: var(--spacing-md);
        }

        summary {
            cursor: pointer;
            font-weight: 600;
            color: var(--color-primary);
            user-select: none;
            padding: var(--spacing-xs);
            margin: calc(-1 * var(--spacing-md));
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        summary:hover {
            background-color: rgba(123, 44, 191, 0.1);
        }

        details[open] summary {
            margin-bottom: var(--spacing-md);
            border-bottom: 1px solid var(--color-border);
        }

        .learning-objectives {
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
            padding: var(--spacing-lg);
            border-radius: var(--border-radius);
            border-left: 4px solid var(--color-accent);
            margin-bottom: var(--spacing-xl);
        }

        .learning-objectives h2 {
            margin-top: 0;
            border-bottom: none;
        }

        .navigation {
            display: flex;
            justify-content: space-between;
            gap: var(--spacing-md);
            margin: var(--spacing-xl) 0;
            padding-top: var(--spacing-lg);
            border-top: 2px solid var(--color-border);
        }

        .nav-button {
            flex: 1;
            padding: var(--spacing-md);
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            border-radius: var(--border-radius);
            text-align: center;
            font-weight: 600;
            transition: transform 0.2s, box-shadow 0.2s;
            box-shadow: var(--box-shadow);
        }

        .nav-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
            text-decoration: none;
        }

        footer {
            margin-top: var(--spacing-xl);
            padding: var(--spacing-lg) var(--spacing-md);
            background-color: var(--color-bg-alt);
            border-top: 1px solid var(--color-border);
            text-align: center;
            font-size: 0.9rem;
            color: var(--color-text-light);
        }
        .disclaimer {
            max-width: 900px;
            margin: 2rem auto;
            padding: 1.5rem;
            background: #f8f9fa;
            border-left: 4px solid #6c757d;
            border-radius: 4px;
        }

        .disclaimer h3 {
            color: #495057;
            margin-bottom: 1rem;
            font-size: 1.1rem;
        }

        .disclaimer ul {
            list-style: none;
            padding-left: 0;
        }

        .disclaimer li {
            padding: 0.5rem 0;
            padding-left: 1.5rem;
            position: relative;
            font-size: 0.9rem;
            color: #6c757d;
            line-height: 1.6;
        }

        .disclaimer li::before {
            content: "âš ï¸";
            position: absolute;
            left: 0;
        }


        @media (max-width: 768px) {
            h1 {
                font-size: 1.5rem;
            }

            h2 {
                font-size: 1.4rem;
            }

            h3 {
                font-size: 1.2rem;
            }

            .meta {
                font-size: 0.85rem;
            }

            .navigation {
                flex-direction: column;
            }

            table {
                font-size: 0.85rem;
            }

            th, td {
                padding: var(--spacing-xs);
            }
        }
    
        
    
        /* Breadcrumb styles */
        .breadcrumb {
            background: #f7fafc;
            padding: 0.75rem 1rem;
            border-bottom: 1px solid #e2e8f0;
            font-size: 0.9rem;
        }

        .breadcrumb-content {
            max-width: 900px;
            margin: 0 auto;
            display: flex;
            align-items: center;
            flex-wrap: wrap;
            gap: 0.5rem;
        }

        .breadcrumb a {
            color: #667eea;
            text-decoration: none;
            transition: color 0.2s;
        }

        .breadcrumb a:hover {
            color: #764ba2;
            text-decoration: underline;
        }

        .breadcrumb-separator {
            color: #a0aec0;
            margin: 0 0.25rem;
        }

        .breadcrumb-current {
            color: #4a5568;
            font-weight: 500;
        }
    </style>

    <script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
    <script>
        mermaid.initialize({ startOnLoad: true, theme: 'default', securityLevel: 'strict' });
    </script>

    <!-- MathJax for LaTeX equation rendering -->
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\(', '\)']],
                displayMath: [['$$', '$$'], ['\[', '\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
                ignoreHtmlClass: 'mermaid'
            }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" async></script>

    <style>
        /* Locale Switcher Styles */
        .locale-switcher {
            display: flex;
            align-items: center;
            gap: 0.5rem;
            padding: 0.5rem 1rem;
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
            border-radius: 6px;
            font-size: 0.9rem;
            margin-bottom: 1rem;
            box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);
        }

        .current-locale {
            font-weight: 600;
            color: #7b2cbf;
            display: flex;
            align-items: center;
            gap: 0.25rem;
        }

        .locale-separator {
            color: #adb5bd;
            font-weight: 300;
        }

        .locale-link {
            color: #f093fb;
            text-decoration: none;
            font-weight: 500;
            transition: all 0.2s ease;
            display: flex;
            align-items: center;
            gap: 0.25rem;
            padding: 0.2rem 0.5rem;
            border-radius: 4px;
        }

        .locale-link:hover {
            background: rgba(240, 147, 251, 0.1);
            color: #d07be8;
            transform: translateY(-1px);
        }

        .locale-meta {
            color: #868e96;
            font-size: 0.85rem;
            font-style: italic;
            margin-left: auto;
        }

        @media (max-width: 768px) {
            .locale-switcher {
                font-size: 0.85rem;
                padding: 0.4rem 0.8rem;
            }
            .locale-meta {
                display: none;
            }
        }
    </style>
</head>
<body>
            <div class="locale-switcher">
<span class="current-locale">ğŸŒ JP</span>
<span class="locale-separator">|</span>
<a href="../../../en/MI/active-learning-introduction/chapter-3.html" class="locale-link">ğŸ‡¬ğŸ‡§ EN</a>
<span class="locale-separator">|</span>
<span class="locale-meta">Last sync: 2025-11-16</span>
</div>
<nav class="breadcrumb">
        <div class="breadcrumb-content">
            <a href="../../index.html">AIå¯ºå­å±‹ãƒˆãƒƒãƒ—</a><span class="breadcrumb-separator">â€º</span><a href="../../MI/index.html">ãƒãƒ†ãƒªã‚¢ãƒ«ã‚ºãƒ»ã‚¤ãƒ³ãƒ•ã‚©ãƒãƒ†ã‚£ã‚¯ã‚¹</a><span class="breadcrumb-separator">â€º</span><a href="../../MI/active-learning-introduction/index.html">Active Learning</a><span class="breadcrumb-separator">â€º</span><span class="breadcrumb-current">Chapter 3</span>
        </div>
    </nav>

        <header>
        <div class="header-content">
            <h1>ç¬¬3ç« ï¼šç²å¾—é–¢æ•°è¨­è¨ˆ</h1>
            <p class="subtitle">Expected Improvementãƒ»UCBãƒ»å¤šç›®çš„æœ€é©åŒ–</p>
            <div class="meta">
                <span class="meta-item">ğŸ“– èª­äº†æ™‚é–“: 25-30åˆ†</span>
                <span class="meta-item">ğŸ“Š é›£æ˜“åº¦: ä¸­ç´šã€œä¸Šç´š</span>
                <span class="meta-item">ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹: 7å€‹</span>
                <span class="meta-item">ğŸ“ æ¼”ç¿’å•é¡Œ: 3å•</span>
            </div>
        </div>
    </header>

    <main class="container">
<h1>ç¬¬3ç« ï¼šç²å¾—é–¢æ•°è¨­è¨ˆ</h1>
<p><strong>Expected Improvementãƒ»UCBãƒ»å¤šç›®çš„æœ€é©åŒ–</strong></p>
<h2>å­¦ç¿’ç›®æ¨™</h2>
<p>ã“ã®ç« ã‚’èª­ã‚€ã“ã¨ã§ã€ä»¥ä¸‹ã‚’ç¿’å¾—ã§ãã¾ã™ï¼š</p>
<ul>
<li>âœ… 4ã¤ã®ä¸»è¦ç²å¾—é–¢æ•°ã®ç‰¹å¾´ã‚’ç†è§£ã—ã¦ã„ã‚‹</li>
<li>âœ… Expected Improvementã‚’å®Ÿè£…ã§ãã‚‹</li>
<li>âœ… å¤šç›®çš„æœ€é©åŒ–ã«Paretoæœ€é©æ€§ã‚’é©ç”¨ã§ãã‚‹"</li>
<li>âœ… åˆ¶ç´„æ¡ä»¶ã‚’ç²å¾—é–¢æ•°ã«çµ„ã¿è¾¼ã‚ã‚‹</li>
<li>âœ… ç²å¾—é–¢æ•°ã®é¸æŠåŸºæº–ã‚’èª¬æ˜ã§ãã‚‹</li>
</ul>
<p><strong>èª­äº†æ™‚é–“</strong>: 25-30åˆ†
<strong>ã‚³ãƒ¼ãƒ‰ä¾‹</strong>: 7å€‹
<strong>æ¼”ç¿’å•é¡Œ</strong>: 3å•</p>
<hr />
<h2>3.1 ç²å¾—é–¢æ•°ã®åŸºç¤</h2>
<h3>ç²å¾—é–¢æ•°ã¨ã¯</h3>
<p><strong>å®šç¾©</strong>: æ¬¡ã«ã©ã®ã‚µãƒ³ãƒ—ãƒ«ã‚’å–å¾—ã™ã¹ãã‹ã‚’æ±ºå®šã™ã‚‹ã‚¹ã‚³ã‚¢é–¢æ•°</p>
<p><strong>æ•°å¼</strong>:
$$
x^* = \arg\max_{x \in \mathcal{X}} \alpha(x | \mathcal{D})
$$</p>
<ul>
<li>$\alpha(x | \mathcal{D})$: ç²å¾—é–¢æ•°</li>
<li>$\mathcal{X}$: æ¢ç´¢ç©ºé–“</li>
<li>$\mathcal{D}$: ã“ã‚Œã¾ã§ã«å–å¾—ã—ãŸãƒ‡ãƒ¼ã‚¿</li>
</ul>
<h3>ä¸»è¦ãª4ã¤ã®ç²å¾—é–¢æ•°</h3>
<h4>1. Expected Improvement (EI)</h4>
<p><strong>åŸç†</strong>: ç¾åœ¨ã®æœ€è‰¯å€¤ã‹ã‚‰ã®æ”¹å–„æœŸå¾…å€¤</p>
<p><strong>æ•°å¼</strong>:
$$
\text{EI}(x) = \mathbb{E}[\max(f(x) - f^*, 0)]
$$</p>
<p>$$
= \begin{cases}
(\mu(x) - f^*)\Phi(Z) + \sigma(x)\phi(Z) &amp; \text{if } \sigma(x) &gt; 0 \
0 &amp; \text{if } \sigma(x) = 0
\end{cases}
$$</p>
<p>ã“ã“ã§ã€
$$
Z = \frac{\mu(x) - f^*}{\sigma(x)}
$$</p>
<ul>
<li>$f^*$: ç¾åœ¨ã®æœ€è‰¯å€¤</li>
<li>$\mu(x)$: äºˆæ¸¬å¹³å‡</li>
<li>$\sigma(x)$: äºˆæ¸¬æ¨™æº–åå·®</li>
<li>$\Phi(\cdot)$: æ¨™æº–æ­£è¦åˆ†å¸ƒã®ç´¯ç©åˆ†å¸ƒé–¢æ•°</li>
<li>$\phi(\cdot)$: æ¨™æº–æ­£è¦åˆ†å¸ƒã®ç¢ºç‡å¯†åº¦é–¢æ•°</li>
</ul>
<p><strong>ã‚³ãƒ¼ãƒ‰ä¾‹1: Expected Improvementã®å®Ÿè£…</strong></p>
<pre><code class="language-python">import numpy as np
from scipy.stats import norm

def expected_improvement(
    X,
    X_sample,
    Y_sample,
    gpr,
    xi=0.01
):
    &quot;&quot;&quot;
    Expected Improvementç²å¾—é–¢æ•°

    Parameters:
    -----------
    X : array
        å€™è£œç‚¹
    X_sample : array
        æ—¢å­˜ã‚µãƒ³ãƒ—ãƒ«ç‚¹
    Y_sample : array
        æ—¢å­˜ã‚µãƒ³ãƒ—ãƒ«ã®å€¤
    gpr : GaussianProcessRegressor
        å­¦ç¿’æ¸ˆã¿ã‚¬ã‚¦ã‚¹éç¨‹ãƒ¢ãƒ‡ãƒ«
    xi : float
        Exploitation-Exploration ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•

    Returns:
    --------
    ei : array
        Expected Improvementã‚¹ã‚³ã‚¢
    &quot;&quot;&quot;
    # äºˆæ¸¬å¹³å‡ã¨æ¨™æº–åå·®
    mu, sigma = gpr.predict(X, return_std=True)
    mu_sample = gpr.predict(X_sample)

    # ç¾åœ¨ã®æœ€è‰¯å€¤
    mu_sample_opt = np.max(mu_sample)

    # æ¨™æº–åå·®ãŒ0ã®å ´åˆã®å‡¦ç†
    with np.errstate(divide='warn'):
        imp = mu - mu_sample_opt - xi
        Z = imp / sigma
        ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)
        ei[sigma == 0.0] = 0.0

    return ei


# ä½¿ç”¨ä¾‹ï¼š1Dæœ€é©åŒ–å•é¡Œ
from sklearn.gaussian_process import GaussianProcessRegressor
from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C
import matplotlib.pyplot as plt

# ç›®çš„é–¢æ•°ï¼ˆæœªçŸ¥ã¨ã—ã¦æ‰±ã†ï¼‰
def objective_function(x):
    &quot;&quot;&quot;æœ€é©åŒ–å¯¾è±¡ã®1Dé–¢æ•°&quot;&quot;&quot;
    return -(x - 2) ** 2 + 5 + np.sin(5 * x)

# åˆæœŸã‚µãƒ³ãƒ—ãƒ«
X_sample = np.array([[0.5], [2.5], [4.0]])
Y_sample = objective_function(X_sample.ravel())

# ã‚¬ã‚¦ã‚¹éç¨‹ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’
kernel = C(1.0, (1e-3, 1e3)) * RBF(1.0, (1e-2, 1e2))
gpr = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10, alpha=1e-6)
gpr.fit(X_sample, Y_sample)

# å€™è£œç‚¹ã®ç”Ÿæˆ
X_candidates = np.linspace(0, 5, 1000).reshape(-1, 1)

# EIã®è¨ˆç®—
ei_values = expected_improvement(X_candidates, X_sample, Y_sample, gpr, xi=0.01)

# æ¬¡ã®ã‚µãƒ³ãƒ—ãƒ«ç‚¹ã‚’é¸æŠ
next_sample_idx = np.argmax(ei_values)
next_sample = X_candidates[next_sample_idx]

print(f&quot;æ¬¡ã®ã‚µãƒ³ãƒ—ãƒ«ç‚¹: x = {next_sample[0]:.3f}&quot;)
print(f&quot;EIå€¤: {ei_values[next_sample_idx]:.4f}&quot;)
print(f&quot;ç¾åœ¨ã®æœ€è‰¯å€¤: {np.max(Y_sample):.3f}&quot;)

# å¯è¦–åŒ–
fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 8))

# ä¸Šæ®µï¼šã‚¬ã‚¦ã‚¹éç¨‹ã«ã‚ˆã‚‹äºˆæ¸¬
mu, sigma = gpr.predict(X_candidates, return_std=True)
ax1.plot(X_candidates, objective_function(X_candidates.ravel()), 'r--', label='çœŸã®é–¢æ•°', alpha=0.5)
ax1.plot(X_candidates, mu, 'b-', label='äºˆæ¸¬å¹³å‡')
ax1.fill_between(X_candidates.ravel(), mu - 1.96 * sigma, mu + 1.96 * sigma, alpha=0.2, label='95%ä¿¡é ¼åŒºé–“')
ax1.scatter(X_sample, Y_sample, c='red', s=100, marker='o', label='æ—¢å­˜ã‚µãƒ³ãƒ—ãƒ«', zorder=5)
ax1.scatter(next_sample, gpr.predict(next_sample), c='green', s=150, marker='*', label='æ¬¡ã®ã‚µãƒ³ãƒ—ãƒ«', zorder=6)
ax1.set_xlabel('x')
ax1.set_ylabel('f(x)')
ax1.set_title('ã‚¬ã‚¦ã‚¹éç¨‹ã«ã‚ˆã‚‹äºˆæ¸¬')
ax1.legend()
ax1.grid(True, alpha=0.3)

# ä¸‹æ®µï¼šExpected Improvement
ax2.plot(X_candidates, ei_values, 'g-', linewidth=2)
ax2.scatter(next_sample, ei_values[next_sample_idx], c='green', s=150, marker='*', label='æœ€å¤§EIç‚¹', zorder=5)
ax2.axvline(next_sample[0], color='green', linestyle='--', alpha=0.5)
ax2.set_xlabel('x')
ax2.set_ylabel('EI(x)')
ax2.set_title('Expected Improvementç²å¾—é–¢æ•°')
ax2.legend()
ax2.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('ei_acquisition.png', dpi=150, bbox_inches='tight')
plt.show()

# å‡ºåŠ›ä¾‹:
# æ¬¡ã®ã‚µãƒ³ãƒ—ãƒ«ç‚¹: x = 3.742
# EIå€¤: 0.8523
# ç¾åœ¨ã®æœ€è‰¯å€¤: 5.891
</code></pre>
<h4>2. Probability of Improvement (PI)</h4>
<p><strong>åŸç†</strong>: ç¾åœ¨ã®æœ€è‰¯å€¤ã‚’æ”¹å–„ã™ã‚‹ç¢ºç‡</p>
<p><strong>æ•°å¼</strong>:
$$
\text{PI}(x) = P(f(x) \geq f^* + \xi)
$$</p>
<p>$$
= \Phi\left(\frac{\mu(x) - f^* - \xi}{\sigma(x)}\right)
$$</p>
<ul>
<li>$\xi$: æ”¹å–„ã®é–¾å€¤ï¼ˆé€šå¸¸0.01ï¼‰</li>
</ul>
<p><strong>ã‚³ãƒ¼ãƒ‰ä¾‹2: Probability of Improvementã®å®Ÿè£…</strong></p>
<pre><code class="language-python">def probability_of_improvement(
    X,
    X_sample,
    Y_sample,
    gpr,
    xi=0.01
):
    &quot;&quot;&quot;
    Probability of Improvementç²å¾—é–¢æ•°

    Parameters:
    -----------
    ï¼ˆExpected Improvementã¨åŒã˜ï¼‰

    Returns:
    --------
    pi : array
        Probability of Improvementã‚¹ã‚³ã‚¢
    &quot;&quot;&quot;
    mu, sigma = gpr.predict(X, return_std=True)
    mu_sample = gpr.predict(X_sample)
    mu_sample_opt = np.max(mu_sample)

    with np.errstate(divide='warn'):
        Z = (mu - mu_sample_opt - xi) / sigma
        pi = norm.cdf(Z)
        pi[sigma == 0.0] = 0.0

    return pi


# ä½¿ç”¨ä¾‹ï¼šPIã¨EIã®æ¯”è¼ƒ
# ï¼ˆå‰ã®ã‚³ãƒ¼ãƒ‰ä¾‹ã§å®šç¾©ã—ãŸGPRãƒ¢ãƒ‡ãƒ«ã¨å€™è£œç‚¹ã‚’ä½¿ç”¨ï¼‰

# PIã®è¨ˆç®—
pi_values = probability_of_improvement(X_candidates, X_sample, Y_sample, gpr, xi=0.01)

# æ¬¡ã®ã‚µãƒ³ãƒ—ãƒ«ç‚¹ã‚’é¸æŠ
next_sample_pi_idx = np.argmax(pi_values)
next_sample_pi = X_candidates[next_sample_pi_idx]

print(f&quot;PIé¸æŠç‚¹: x = {next_sample_pi[0]:.3f}, PIå€¤ = {pi_values[next_sample_pi_idx]:.4f}&quot;)
print(f&quot;EIé¸æŠç‚¹: x = {next_sample[0]:.3f}, EIå€¤ = {ei_values[next_sample_idx]:.4f}&quot;)

# EIã¨PIã®æ¯”è¼ƒå¯è¦–åŒ–
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))

# å·¦ï¼šExpected Improvement
ax1.plot(X_candidates, ei_values, 'g-', linewidth=2, label='EI')
ax1.scatter(next_sample, ei_values[next_sample_idx], c='green', s=150, marker='*', label=f'æœ€å¤§EI: x={next_sample[0]:.2f}', zorder=5)
ax1.axvline(next_sample[0], color='green', linestyle='--', alpha=0.5)
ax1.set_xlabel('x')
ax1.set_ylabel('EI(x)')
ax1.set_title('Expected Improvement')
ax1.legend()
ax1.grid(True, alpha=0.3)

# å³ï¼šProbability of Improvement
ax2.plot(X_candidates, pi_values, 'purple', linewidth=2, label='PI')
ax2.scatter(next_sample_pi, pi_values[next_sample_pi_idx], c='purple', s=150, marker='*', label=f'æœ€å¤§PI: x={next_sample_pi[0]:.2f}', zorder=5)
ax2.axvline(next_sample_pi[0], color='purple', linestyle='--', alpha=0.5)
ax2.set_xlabel('x')
ax2.set_ylabel('PI(x)')
ax2.set_title('Probability of Improvement')
ax2.legend()
ax2.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('pi_vs_ei.png', dpi=150, bbox_inches='tight')
plt.show()

# å‡ºåŠ›ä¾‹:
# PIé¸æŠç‚¹: x = 3.789, PIå€¤ = 0.8912
# EIé¸æŠç‚¹: x = 3.742, EIå€¤ = 0.8523
# ï¼ˆPIã¯æ”¹å–„ç¢ºç‡ã‚’æœ€å¤§åŒ–ã€EIã¯æ”¹å–„é‡ã®æœŸå¾…å€¤ã‚’æœ€å¤§åŒ–ï¼‰
</code></pre>
<h4>3. Upper Confidence Bound (UCB)</h4>
<p><strong>åŸç†</strong>: äºˆæ¸¬å¹³å‡ + ä¸ç¢ºå®Ÿæ€§ãƒœãƒ¼ãƒŠã‚¹</p>
<p><strong>æ•°å¼</strong>:
$$
\text{UCB}(x) = \mu(x) + \kappa \sigma(x)
$$</p>
<ul>
<li>$\kappa$: æ¢ç´¢ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆé€šå¸¸1.0ã€œ3.0ï¼‰</li>
</ul>
<p><strong>ã‚³ãƒ¼ãƒ‰ä¾‹3: UCBã®å®Ÿè£…</strong></p>
<pre><code class="language-python">def upper_confidence_bound(
    X,
    gpr,
    kappa=2.0
):
    &quot;&quot;&quot;
    Upper Confidence Boundç²å¾—é–¢æ•°

    Parameters:
    -----------
    X : array
        å€™è£œç‚¹
    gpr : GaussianProcessRegressor
        å­¦ç¿’æ¸ˆã¿ã‚¬ã‚¦ã‚¹éç¨‹ãƒ¢ãƒ‡ãƒ«
    kappa : float
        æ¢ç´¢ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿

    Returns:
    --------
    ucb : array
        UCBã‚¹ã‚³ã‚¢
    &quot;&quot;&quot;
    mu, sigma = gpr.predict(X, return_std=True)
    return mu + kappa * sigma


# ä½¿ç”¨ä¾‹ï¼škappaãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å½±éŸ¿
# ï¼ˆå‰ã®ã‚³ãƒ¼ãƒ‰ä¾‹ã§å®šç¾©ã—ãŸGPRãƒ¢ãƒ‡ãƒ«ã¨å€™è£œç‚¹ã‚’ä½¿ç”¨ï¼‰

# ç•°ãªã‚‹kappaã§UCBã‚’è¨ˆç®—
kappa_values = [0.5, 1.0, 2.0, 3.0]
ucb_results = {}

for kappa in kappa_values:
    ucb_vals = upper_confidence_bound(X_candidates, gpr, kappa=kappa)
    next_idx = np.argmax(ucb_vals)
    ucb_results[kappa] = {
        'values': ucb_vals,
        'next_x': X_candidates[next_idx][0],
        'ucb_score': ucb_vals[next_idx]
    }
    print(f&quot;kappa={kappa}: æ¬¡ã®ã‚µãƒ³ãƒ—ãƒ«ç‚¹ x={ucb_results[kappa]['next_x']:.3f}, UCB={ucb_results[kappa]['ucb_score']:.3f}&quot;)

# å¯è¦–åŒ–ï¼škappaã®å½±éŸ¿
fig, axes = plt.subplots(2, 2, figsize=(14, 10))
axes = axes.ravel()

for idx, kappa in enumerate(kappa_values):
    ax = axes[idx]
    ucb_vals = ucb_results[kappa]['values']
    next_x = ucb_results[kappa]['next_x']

    # ã‚¬ã‚¦ã‚¹éç¨‹ã®äºˆæ¸¬
    mu, sigma = gpr.predict(X_candidates, return_std=True)

    # UCBã®å¯è¦–åŒ–
    ax.plot(X_candidates, mu, 'b-', label='äºˆæ¸¬å¹³å‡ Î¼(x)', linewidth=2)
    ax.plot(X_candidates, ucb_vals, 'r-', label=f'UCB (Îº={kappa})', linewidth=2)
    ax.fill_between(X_candidates.ravel(), mu - 2*sigma, mu + 2*sigma, alpha=0.2, color='blue', label='Â±2Ïƒ')
    ax.scatter(X_sample, Y_sample, c='black', s=100, marker='o', label='æ—¢å­˜ã‚µãƒ³ãƒ—ãƒ«', zorder=5)
    ax.scatter(next_x, ucb_results[kappa]['ucb_score'], c='red', s=150, marker='*', label='æ¬¡ã®ã‚µãƒ³ãƒ—ãƒ«', zorder=6)
    ax.axvline(next_x, color='red', linestyle='--', alpha=0.5)
    ax.set_xlabel('x')
    ax.set_ylabel('f(x)')
    ax.set_title(f'UCB with Îº={kappa}')
    ax.legend(loc='best', fontsize=8)
    ax.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('ucb_kappa_comparison.png', dpi=150, bbox_inches='tight')
plt.show()

# å‡ºåŠ›ä¾‹:
# kappa=0.5: æ¬¡ã®ã‚µãƒ³ãƒ—ãƒ«ç‚¹ x=2.456, UCB=6.123
# kappa=1.0: æ¬¡ã®ã‚µãƒ³ãƒ—ãƒ«ç‚¹ x=3.215, UCB=6.789
# kappa=2.0: æ¬¡ã®ã‚µãƒ³ãƒ—ãƒ«ç‚¹ x=3.892, UCB=7.456
# kappa=3.0: æ¬¡ã®ã‚µãƒ³ãƒ—ãƒ«ç‚¹ x=4.123, UCB=8.234
# ï¼ˆkappaãŒå¤§ãã„ã»ã©æ¢ç´¢çš„ã€å°ã•ã„ã»ã©æ´»ç”¨çš„ï¼‰
</code></pre>
<h4>4. Thompson Sampling</h4>
<p><strong>åŸç†</strong>: ã‚¬ã‚¦ã‚¹éç¨‹ã‹ã‚‰ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ã¦æœ€å¤§å€¤ã‚’é¸æŠ</p>
<p><strong>æ•°å¼</strong>:
$$
f(x) \sim \mathcal{GP}(\mu(x), k(x, x'))
$$</p>
<p>$$
x^* = \arg\max_{x \in \mathcal{X}} f(x)
$$</p>
<p><strong>ã‚³ãƒ¼ãƒ‰ä¾‹4: Thompson Samplingã®å®Ÿè£…</strong></p>
<pre><code class="language-python">def thompson_sampling(
    X,
    gpr
):
    &quot;&quot;&quot;
    Thompson Sampling

    Parameters:
    -----------
    X : array
        å€™è£œç‚¹
    gpr : GaussianProcessRegressor
        å­¦ç¿’æ¸ˆã¿ã‚¬ã‚¦ã‚¹éç¨‹ãƒ¢ãƒ‡ãƒ«

    Returns:
    --------
    sample : array
        ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã•ã‚ŒãŸé–¢æ•°å€¤
    &quot;&quot;&quot;
    # ã‚¬ã‚¦ã‚¹éç¨‹ã‹ã‚‰ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
    mu, cov = gpr.predict(X, return_cov=True)

    # å…±åˆ†æ•£è¡Œåˆ—ã®æ•°å€¤å®‰å®šæ€§ã®ãŸã‚ã®å¯¾è§’æˆåˆ†è¿½åŠ 
    cov_stable = cov + 1e-6 * np.eye(cov.shape[0])
    sample = np.random.multivariate_normal(mu, cov_stable)

    return sample


# ä½¿ç”¨ä¾‹ï¼šThompson Samplingã«ã‚ˆã‚‹ç¢ºç‡çš„æ¢ç´¢
# ï¼ˆå‰ã®ã‚³ãƒ¼ãƒ‰ä¾‹ã§å®šç¾©ã—ãŸGPRãƒ¢ãƒ‡ãƒ«ã¨å€™è£œç‚¹ã‚’ä½¿ç”¨ï¼‰

# è¤‡æ•°å›ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ã¦æ¬¡ã®ç‚¹ã‚’æ±ºå®š
n_samples = 5
np.random.seed(42)

fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))

# ä¸Šæ®µï¼šè¤‡æ•°ã®Thompson Samplingã‚µãƒ³ãƒ—ãƒ«
mu, sigma = gpr.predict(X_candidates, return_std=True)
ax1.plot(X_candidates, objective_function(X_candidates.ravel()), 'r--', label='çœŸã®é–¢æ•°', alpha=0.5, linewidth=2)
ax1.plot(X_candidates, mu, 'b-', label='äºˆæ¸¬å¹³å‡', linewidth=2)
ax1.fill_between(X_candidates.ravel(), mu - 1.96 * sigma, mu + 1.96 * sigma, alpha=0.2, label='95%ä¿¡é ¼åŒºé–“')
ax1.scatter(X_sample, Y_sample, c='red', s=100, marker='o', label='æ—¢å­˜ã‚µãƒ³ãƒ—ãƒ«', zorder=5)

selected_points = []
for i in range(n_samples):
    # Thompson Samplingã§ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
    ts_sample = thompson_sampling(X_candidates, gpr)

    # ã‚µãƒ³ãƒ—ãƒ«ã®æœ€å¤§å€¤ã‚’é¸æŠ
    next_idx = np.argmax(ts_sample)
    next_x = X_candidates[next_idx][0]
    selected_points.append(next_x)

    # ã‚µãƒ³ãƒ—ãƒ«ã‚’ãƒ—ãƒ­ãƒƒãƒˆ
    ax1.plot(X_candidates, ts_sample, alpha=0.4, linewidth=1, label=f'Sample {i+1}')
    ax1.scatter(next_x, ts_sample[next_idx], s=80, marker='x', zorder=4)

ax1.set_xlabel('x')
ax1.set_ylabel('f(x)')
ax1.set_title('Thompson Sampling: ã‚¬ã‚¦ã‚¹éç¨‹ã‹ã‚‰ã®è¤‡æ•°ã‚µãƒ³ãƒ—ãƒ«')
ax1.legend(loc='upper left', fontsize=8, ncol=2)
ax1.grid(True, alpha=0.3)

# ä¸‹æ®µï¼šé¸æŠã•ã‚ŒãŸç‚¹ã®ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ 
ax2.hist(selected_points, bins=20, alpha=0.7, color='green', edgecolor='black')
ax2.axvline(np.mean(selected_points), color='red', linestyle='--', linewidth=2, label=f'å¹³å‡: {np.mean(selected_points):.2f}')
ax2.set_xlabel('x')
ax2.set_ylabel('é¸æŠé »åº¦')
ax2.set_title(f'Thompson Samplingã«ã‚ˆã‚‹é¸æŠç‚¹ã®åˆ†å¸ƒ (n={n_samples})')
ax2.legend()
ax2.grid(True, alpha=0.3, axis='y')

plt.tight_layout()
plt.savefig('thompson_sampling.png', dpi=150, bbox_inches='tight')
plt.show()

# æœ€ã‚‚é¸ã°ã‚ŒãŸç‚¹ã‚’æ¬¡ã®ã‚µãƒ³ãƒ—ãƒ«ã¨ã—ã¦é¸æŠ
from collections import Counter
most_common = Counter(np.round(selected_points, 2)).most_common(1)[0]
print(f&quot;Thompson Samplingçµæœ ({n_samples}å›è©¦è¡Œ):&quot;)
print(f&quot;  é¸æŠã•ã‚ŒãŸç‚¹: {selected_points}&quot;)
print(f&quot;  æœ€é »å‡ºç‚¹: x = {most_common[0]:.2f} (å‡ºç¾{most_common[1]}å›)&quot;)
print(f&quot;  å¹³å‡é¸æŠç‚¹: x = {np.mean(selected_points):.3f}&quot;)

# å‡ºåŠ›ä¾‹:
# Thompson Samplingçµæœ (5å›è©¦è¡Œ):
#   é¸æŠã•ã‚ŒãŸç‚¹: [3.89, 3.72, 4.01, 3.78, 3.95]
#   æœ€é »å‡ºç‚¹: x = 3.89 (å‡ºç¾2å›)
#   å¹³å‡é¸æŠç‚¹: x = 3.870
</code></pre>
<hr />
<h2>3.2 å¤šç›®çš„ç²å¾—é–¢æ•°</h2>
<h3>Paretoæœ€é©æ€§</h3>
<p><strong>å®šç¾©</strong>: 1ã¤ã®ç›®çš„ã‚’æ”¹å–„ã™ã‚‹ãŸã‚ã«ä»–ã®ç›®çš„ã‚’çŠ ç‰²ã«ã—ãªã„è§£</p>
<p><strong>æ•°å¼</strong>:
$$
x^* \text{ is Pareto optimal} \iff \nexists x : f_i(x) \geq f_i(x^*) \ \forall i \land f_j(x) &gt; f_j(x^*) \ \text{for some } j
$$</p>
<h3>Expected Hypervolume Improvement (EHVI)</h3>
<p><strong>åŸç†</strong>: ãƒã‚¤ãƒ‘ãƒ¼ãƒœãƒªãƒ¥ãƒ¼ãƒ ã®æœŸå¾…æ”¹å–„é‡ã‚’æœ€å¤§åŒ–</p>
<p><strong>æ•°å¼</strong>:
$$
\text{EHVI}(x) = \mathbb{E}[HV(\mathcal{P} \cup {f(x)}) - HV(\mathcal{P})]
$$</p>
<ul>
<li>$HV(\cdot)$: ãƒã‚¤ãƒ‘ãƒ¼ãƒœãƒªãƒ¥ãƒ¼ãƒ </li>
<li>$\mathcal{P}$: ç¾åœ¨ã®Paretoé›†åˆ</li>
</ul>
<p><strong>ã‚³ãƒ¼ãƒ‰ä¾‹5: å¤šç›®çš„æœ€é©åŒ–ã®å®Ÿè£…ï¼ˆBoTorchï¼‰</strong></p>
<pre><code class="language-python">import torch
from botorch.models import SingleTaskGP
from botorch.models.transforms.outcome import Standardize
from botorch.fit import fit_gpytorch_mll
from botorch.acquisition.multi_objective import qExpectedHypervolumeImprovement
from botorch.utils.multi_objective.box_decompositions.dominated import DominatedPartitioning
from botorch.optim import optimize_acqf
from botorch.utils.multi_objective.pareto import is_non_dominated
from gpytorch.mlls import ExactMarginalLogLikelihood
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D

# ãƒ‡ãƒã‚¤ã‚¹è¨­å®š
device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)
dtype = torch.double

# å¤šç›®çš„æœ€é©åŒ–å•é¡Œã®å®šç¾©ï¼ˆ2ç›®çš„ï¼‰
def multi_objective_function(x):
    &quot;&quot;&quot;
    2ç›®çš„æœ€é©åŒ–å•é¡Œ
    ç›®çš„1: f1(x) = x1^2 + x2^2 ã‚’æœ€å°åŒ–
    ç›®çš„2: f2(x) = (x1-1)^2 + (x2-1)^2 ã‚’æœ€å°åŒ–
    Paretoæœ€é©è§£ã¯ x1ã¨x2ã®ç·šå½¢çµåˆã§è¡¨ã•ã‚Œã‚‹

    Parameters:
    -----------
    x : torch.Tensor, shape (n, 2)
        å…¥åŠ›ç‚¹

    Returns:
    --------
    y : torch.Tensor, shape (n, 2)
        2ã¤ã®ç›®çš„é–¢æ•°å€¤ï¼ˆæœ€å¤§åŒ–ã®ãŸã‚è² ã®å€¤ã‚’è¿”ã™ï¼‰
    &quot;&quot;&quot;
    f1 = x[:, 0]**2 + x[:, 1]**2
    f2 = (x[:, 0] - 1)**2 + (x[:, 1] - 1)**2

    # BoTorchã¯æœ€å¤§åŒ–ã‚’å‰æã¨ã™ã‚‹ãŸã‚ã€æœ€å°åŒ–å•é¡Œã¯è² ã«ã™ã‚‹
    return torch.stack([-f1, -f2], dim=-1)


# åˆæœŸã‚µãƒ³ãƒ—ãƒ«ã®ç”Ÿæˆ
def generate_initial_data(n=6):
    &quot;&quot;&quot;åˆæœŸãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆ&quot;&quot;&quot;
    train_x = torch.rand(n, 2, device=device, dtype=dtype) * 2 - 1  # [-1, 1]ã®ç¯„å›²
    train_y = multi_objective_function(train_x)
    return train_x, train_y


# å¤šç›®çš„ã‚¬ã‚¦ã‚¹éç¨‹ãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰
def initialize_model(train_x, train_y):
    &quot;&quot;&quot;
    2ç›®çš„ã®ãŸã‚ã®ç‹¬ç«‹ãªGPãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰

    Parameters:
    -----------
    train_x : torch.Tensor
        å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ (n, 2)
    train_y : torch.Tensor
        ç›®çš„é–¢æ•°å€¤ (n, 2)

    Returns:
    --------
    model : SingleTaskGP
        å­¦ç¿’æ¸ˆã¿GPãƒ¢ãƒ‡ãƒ«
    &quot;&quot;&quot;
    model = SingleTaskGP(
        train_x,
        train_y,
        outcome_transform=Standardize(m=train_y.shape[-1])  # å„ç›®çš„ã‚’æ¨™æº–åŒ–
    )
    mll = ExactMarginalLogLikelihood(model.likelihood, model)
    fit_gpytorch_mll(mll)
    return model


# EHVIç²å¾—é–¢æ•°ã®æœ€é©åŒ–
def optimize_ehvi_and_get_observation(model, train_y, bounds):
    &quot;&quot;&quot;
    Expected Hypervolume Improvementç²å¾—é–¢æ•°ã‚’æœ€é©åŒ–

    Parameters:
    -----------
    model : SingleTaskGP
        å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«
    train_y : torch.Tensor
        æ—¢å­˜ã®ç›®çš„é–¢æ•°å€¤
    bounds : torch.Tensor
        æ¢ç´¢ç©ºé–“ã®å¢ƒç•Œ (2, 2)

    Returns:
    --------
    new_x : torch.Tensor
        æ¬¡ã®ã‚µãƒ³ãƒ—ãƒ«ç‚¹
    &quot;&quot;&quot;
    # å‚ç…§ç‚¹ã®è¨­å®šï¼ˆå…¨ã¦ã®ç›®çš„ã§æœ€æ‚ªã®å€¤ã‚ˆã‚Šå°‘ã—æ‚ªã„ç‚¹ï¼‰
    ref_point = train_y.min(dim=0).values - 0.1

    # Paretoå‰ç·šã®è¨ˆç®—
    pareto_mask = is_non_dominated(train_y)
    pareto_y = train_y[pareto_mask]

    # Box decompositionï¼ˆãƒã‚¤ãƒ‘ãƒ¼ãƒœãƒªãƒ¥ãƒ¼ãƒ è¨ˆç®—ç”¨ï¼‰
    partitioning = DominatedPartitioning(ref_point=ref_point, Y=pareto_y)

    # EHVIç²å¾—é–¢æ•°ã®å®šç¾©
    acq_func = qExpectedHypervolumeImprovement(
        model=model,
        ref_point=ref_point,
        partitioning=partitioning,
    )

    # ç²å¾—é–¢æ•°ã®æœ€å¤§åŒ–
    candidates, _ = optimize_acqf(
        acq_function=acq_func,
        bounds=bounds,
        q=1,  # 1ç‚¹ãšã¤é¸æŠ
        num_restarts=10,
        raw_samples=128,
    )

    return candidates.detach()


# Bayesian Optimization ãƒ«ãƒ¼ãƒ—
def run_bo_loop(n_iterations=10):
    &quot;&quot;&quot;
    å¤šç›®çš„ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã®å®Ÿè¡Œ

    Parameters:
    -----------
    n_iterations : int
        æœ€é©åŒ–ã®åå¾©å›æ•°

    Returns:
    --------
    train_x : torch.Tensor
        å…¨ã¦ã®ã‚µãƒ³ãƒ—ãƒ«ç‚¹
    train_y : torch.Tensor
        å…¨ã¦ã®ç›®çš„é–¢æ•°å€¤
    &quot;&quot;&quot;
    # æ¢ç´¢ç©ºé–“ã®å¢ƒç•Œ
    bounds = torch.tensor([[-1.0, -1.0], [1.0, 1.0]], device=device, dtype=dtype)

    # åˆæœŸãƒ‡ãƒ¼ã‚¿
    train_x, train_y = generate_initial_data(n=6)

    print(&quot;å¤šç›®çš„ãƒ™ã‚¤ã‚ºæœ€é©åŒ–é–‹å§‹&quot;)
    print(f&quot;åˆæœŸãƒ‡ãƒ¼ã‚¿: {train_x.shape[0]}ç‚¹&quot;)

    for iteration in range(n_iterations):
        # ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’
        model = initialize_model(train_x, train_y)

        # æ¬¡ã®ã‚µãƒ³ãƒ—ãƒ«ç‚¹ã‚’å–å¾—
        new_x = optimize_ehvi_and_get_observation(model, train_y, bounds)
        new_y = multi_objective_function(new_x)

        # ãƒ‡ãƒ¼ã‚¿ã«è¿½åŠ 
        train_x = torch.cat([train_x, new_x])
        train_y = torch.cat([train_y, new_y])

        # Paretoå‰ç·šã®æ›´æ–°
        pareto_mask = is_non_dominated(train_y)
        n_pareto = pareto_mask.sum().item()

        print(f&quot;Iteration {iteration + 1}: æ–°è¦ç‚¹ = {new_x.squeeze().cpu().numpy()}, Paretoè§£æ•° = {n_pareto}&quot;)

    return train_x, train_y


# å®Ÿè¡Œã¨å¯è¦–åŒ–
torch.manual_seed(42)
final_x, final_y = run_bo_loop(n_iterations=15)

# Paretoå‰ç·šã®æŠ½å‡º
pareto_mask = is_non_dominated(final_y)
pareto_x = final_x[pareto_mask].cpu().numpy()
pareto_y = final_y[pareto_mask].cpu().numpy()
non_pareto_y = final_y[~pareto_mask].cpu().numpy()

# å¯è¦–åŒ–
fig = plt.figure(figsize=(15, 5))

# å·¦ï¼šå…¥åŠ›ç©ºé–“
ax1 = fig.add_subplot(131)
ax1.scatter(final_x[:, 0].cpu(), final_x[:, 1].cpu(), c='blue', s=50, alpha=0.6, label='å…¨ã‚µãƒ³ãƒ—ãƒ«')
ax1.scatter(pareto_x[:, 0], pareto_x[:, 1], c='red', s=100, marker='*', label='Paretoè§£', zorder=5)
ax1.set_xlabel('x1')
ax1.set_ylabel('x2')
ax1.set_title('å…¥åŠ›ç©ºé–“ã®ã‚µãƒ³ãƒ—ãƒ«åˆ†å¸ƒ')
ax1.legend()
ax1.grid(True, alpha=0.3)

# ä¸­å¤®ï¼šç›®çš„ç©ºé–“ï¼ˆParetoå‰ç·šï¼‰
ax2 = fig.add_subplot(132)
ax2.scatter(non_pareto_y[:, 0], non_pareto_y[:, 1], c='blue', s=50, alpha=0.6, label='éParetoè§£')
ax2.scatter(pareto_y[:, 0], pareto_y[:, 1], c='red', s=100, marker='*', label='Paretoå‰ç·š', zorder=5)
# Paretoå‰ç·šã‚’ç·šã§çµã¶
sorted_idx = np.argsort(pareto_y[:, 0])
ax2.plot(pareto_y[sorted_idx, 0], pareto_y[sorted_idx, 1], 'r--', alpha=0.5, linewidth=2)
ax2.set_xlabel('ç›®çš„1: -f1(x)')
ax2.set_ylabel('ç›®çš„2: -f2(x)')
ax2.set_title('ç›®çš„ç©ºé–“ã®Paretoå‰ç·š')
ax2.legend()
ax2.grid(True, alpha=0.3)

# å³ï¼š3Då¯è¦–åŒ–ï¼ˆå…¥åŠ›ã¨ç›®çš„ã®é–¢ä¿‚ï¼‰
ax3 = fig.add_subplot(133, projection='3d')
ax3.scatter(final_x[:, 0].cpu(), final_x[:, 1].cpu(), final_y[:, 0].cpu(),
            c='blue', s=30, alpha=0.6, label='ç›®çš„1')
ax3.scatter(pareto_x[:, 0], pareto_x[:, 1], pareto_y[:, 0],
            c='red', s=80, marker='*', label='Paretoè§£ï¼ˆç›®çš„1ï¼‰', zorder=5)
ax3.set_xlabel('x1')
ax3.set_ylabel('x2')
ax3.set_zlabel('ç›®çš„1: -f1(x)')
ax3.set_title('å…¥åŠ›ç©ºé–“ã¨ç›®çš„1ã®é–¢ä¿‚')
ax3.legend()

plt.tight_layout()
plt.savefig('multi_objective_bo.png', dpi=150, bbox_inches='tight')
plt.show()

# çµæœã®å‡ºåŠ›
print(&quot;\næœ€é©åŒ–å®Œäº†&quot;)
print(f&quot;ç·ã‚µãƒ³ãƒ—ãƒ«æ•°: {final_x.shape[0]}&quot;)
print(f&quot;Paretoè§£æ•°: {pareto_mask.sum().item()}&quot;)
print(f&quot;\nParetoå‰ç·šã®ç›®çš„é–¢æ•°å€¤:&quot;)
for i, (y1, y2) in enumerate(pareto_y):
    print(f&quot;  è§£{i+1}: f1={-y1:.4f}, f2={-y2:.4f}&quot;)

# å‡ºåŠ›ä¾‹:
# å¤šç›®çš„ãƒ™ã‚¤ã‚ºæœ€é©åŒ–é–‹å§‹
# åˆæœŸãƒ‡ãƒ¼ã‚¿: 6ç‚¹
# Iteration 1: æ–°è¦ç‚¹ = [0.123 0.456], Paretoè§£æ•° = 4
# Iteration 2: æ–°è¦ç‚¹ = [-0.234 0.789], Paretoè§£æ•° = 5
# ...
# Iteration 15: æ–°è¦ç‚¹ = [0.512 0.487], Paretoè§£æ•° = 8
#
# æœ€é©åŒ–å®Œäº†
# ç·ã‚µãƒ³ãƒ—ãƒ«æ•°: 21
# Paretoè§£æ•°: 8
#
# Paretoå‰ç·šã®ç›®çš„é–¢æ•°å€¤:
#   è§£1: f1=0.0123, f2=1.2345
#   è§£2: f1=0.3456, f2=0.8901
#   è§£3: f1=0.6789, f2=0.4567
#   ...
</code></pre>
<hr />
<h2>3.3 åˆ¶ç´„ä»˜ãç²å¾—é–¢æ•°</h2>
<h3>åˆ¶ç´„æ¡ä»¶ã®æ‰±ã„</h3>
<p><strong>ä¾‹</strong>: åˆæˆå¯èƒ½æ€§åˆ¶ç´„ã€ã‚³ã‚¹ãƒˆåˆ¶ç´„</p>
<p><strong>æ•°å¼</strong>:
$$
x^* = \arg\max_{x \in \mathcal{X}} \alpha(x | \mathcal{D}) \cdot P_c(x)
$$</p>
<ul>
<li>$P_c(x)$: åˆ¶ç´„æ¡ä»¶ã‚’æº€ãŸã™ç¢ºç‡</li>
</ul>
<p><strong>Constrained Expected Improvement</strong>:
$$
\text{CEI}(x) = \text{EI}(x) \cdot P(c(x) \leq 0)
$$</p>
<hr />
<h2>3.4 ã‚±ãƒ¼ã‚¹ã‚¹ã‚¿ãƒ‡ã‚£ï¼šç†±é›»ææ–™æ¢ç´¢</h2>
<h3>å•é¡Œè¨­å®š</h3>
<p><strong>ç›®æ¨™</strong>: ç†±é›»æ€§èƒ½æŒ‡æ•°ZTå€¤ã®æœ€å¤§åŒ–</p>
<p><strong>ZTå€¤</strong>:
$$
ZT = \frac{S^2 \sigma T}{\kappa}
$$</p>
<ul>
<li>$S$: Seebeckä¿‚æ•°</li>
<li>$\sigma$: é›»æ°—ä¼å°åº¦</li>
<li>$T$: çµ¶å¯¾æ¸©åº¦</li>
<li>$\kappa$: ç†±ä¼å°åº¦</li>
</ul>
<p><strong>èª²é¡Œ</strong>: 3ã¤ã®ç‰©æ€§ã‚’åŒæ™‚ã«æœ€é©åŒ–ï¼ˆå¤šç›®çš„æœ€é©åŒ–ï¼‰</p>
<hr />
<h2>æœ¬ç« ã®ã¾ã¨ã‚</h2>
<h3>ç²å¾—é–¢æ•°ã®æ¯”è¼ƒè¡¨</h3>
<table>
<thead>
<tr>
<th>ç²å¾—é–¢æ•°</th>
<th>ç‰¹å¾´</th>
<th>æ¢ç´¢å‚¾å‘</th>
<th>è¨ˆç®—ã‚³ã‚¹ãƒˆ</th>
<th>æ¨å¥¨ç”¨é€”</th>
</tr>
</thead>
<tbody>
<tr>
<td>EI</td>
<td>æ”¹å–„æœŸå¾…å€¤</td>
<td>ãƒãƒ©ãƒ³ã‚¹</td>
<td>ä½</td>
<td>ä¸€èˆ¬çš„ãªæœ€é©åŒ–</td>
</tr>
<tr>
<td>PI</td>
<td>æ”¹å–„ç¢ºç‡</td>
<td>æ´»ç”¨é‡è¦–</td>
<td>ä½</td>
<td>é«˜é€Ÿæ¢ç´¢</td>
</tr>
<tr>
<td>UCB</td>
<td>ä¿¡é ¼ä¸Šé™</td>
<td>æ¢ç´¢é‡è¦–</td>
<td>ä½</td>
<td>åºƒç¯„å›²æ¢ç´¢</td>
</tr>
<tr>
<td>Thompson</td>
<td>ç¢ºç‡çš„</td>
<td>ãƒãƒ©ãƒ³ã‚¹</td>
<td>ä¸­</td>
<td>ä¸¦åˆ—å®Ÿé¨“</td>
</tr>
</tbody>
</table>
<h3>æ¬¡ã®ç« ã¸</h3>
<p>ç¬¬4ç« ã§ã¯ã€<strong>ææ–™æ¢ç´¢ã¸ã®å¿œç”¨ã¨å®Ÿè·µ</strong>ã‚’å­¦ã³ã¾ã™ï¼š
- Active Learning Ã— ãƒ™ã‚¤ã‚ºæœ€é©åŒ–
- Active Learning Ã— é«˜ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆè¨ˆç®—
- Active Learning Ã— å®Ÿé¨“ãƒ­ãƒœãƒƒãƒˆ
- å®Ÿä¸–ç•Œå¿œç”¨ã¨ã‚­ãƒ£ãƒªã‚¢ãƒ‘ã‚¹</p>
<p><strong><a href="./chapter-4.html">ç¬¬4ç« ï¼šææ–™æ¢ç´¢ã¸ã®å¿œç”¨ã¨å®Ÿè·µ â†’</a></strong></p>
<hr />
<h2>æ¼”ç¿’å•é¡Œ</h2>
<p>ï¼ˆçœç•¥ï¼šæ¼”ç¿’å•é¡Œã®è©³ç´°å®Ÿè£…ï¼‰</p>
<hr />
<h2>å‚è€ƒæ–‡çŒ®</h2>
<ol>
<li>
<p>Jones, D. R. et al. (1998). "Efficient Global Optimization of Expensive Black-Box Functions." <em>Journal of Global Optimization</em>, 13(4), 455-492.</p>
</li>
<li>
<p>Daulton, S. et al. (2020). "Differentiable Expected Hypervolume Improvement for Parallel Multi-Objective Bayesian Optimization." <em>NeurIPS</em>.</p>
</li>
</ol>
<hr />
<h2>ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³</h2>
<h3>å‰ã®ç« </h3>
<p><strong><a href="./chapter-2.html">â† ç¬¬2ç« ï¼šä¸ç¢ºå®Ÿæ€§æ¨å®šæ‰‹æ³•</a></strong></p>
<h3>æ¬¡ã®ç« </h3>
<p><strong><a href="./chapter-4.html">ç¬¬4ç« ï¼šææ–™æ¢ç´¢ã¸ã®å¿œç”¨ã¨å®Ÿè·µ â†’</a></strong></p>
<h3>ã‚·ãƒªãƒ¼ã‚ºç›®æ¬¡</h3>
<p><strong><a href="./index.html">â† ã‚·ãƒªãƒ¼ã‚ºç›®æ¬¡ã«æˆ»ã‚‹</a></strong></p>
<hr />
<p><strong>æ¬¡ã®ç« ã§å®Ÿè·µçš„ãªå¿œç”¨ã‚’å­¦ã³ã¾ã—ã‚‡ã†ï¼</strong></p><div class="navigation">
    <a href="chapter-2.html" class="nav-button">â† å‰ã®ç« </a>
    <a href="index.html" class="nav-button">ã‚·ãƒªãƒ¼ã‚ºç›®æ¬¡ã«æˆ»ã‚‹</a>
    <a href="chapter-4.html" class="nav-button">æ¬¡ã®ç«  â†’</a>
</div>
    </main>

    
    <section class="disclaimer">
        <h3>å…è²¬äº‹é …</h3>
        <ul>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯æ•™è‚²ãƒ»ç ”ç©¶ãƒ»æƒ…å ±æä¾›ã®ã¿ã‚’ç›®çš„ã¨ã—ã¦ãŠã‚Šã€å°‚é–€çš„ãªåŠ©è¨€(æ³•å¾‹ãƒ»ä¼šè¨ˆãƒ»æŠ€è¡“çš„ä¿è¨¼ãªã©)ã‚’æä¾›ã™ã‚‹ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŠã‚ˆã³ä»˜éšã™ã‚‹ã‚³ãƒ¼ãƒ‰ä¾‹ã¯ã€Œç¾çŠ¶æœ‰å§¿(AS IS)ã€ã§æä¾›ã•ã‚Œã€æ˜ç¤ºã¾ãŸã¯é»™ç¤ºã‚’å•ã‚ãšã€å•†å“æ€§ã€ç‰¹å®šç›®çš„é©åˆæ€§ã€æ¨©åˆ©éä¾µå®³ã€æ­£ç¢ºæ€§ãƒ»å®Œå…¨æ€§ã€å‹•ä½œãƒ»å®‰å…¨æ€§ç­‰ã„ã‹ãªã‚‹ä¿è¨¼ã‚‚ã—ã¾ã›ã‚“ã€‚</li>
            <li>å¤–éƒ¨ãƒªãƒ³ã‚¯ã€ç¬¬ä¸‰è€…ãŒæä¾›ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ»ãƒ„ãƒ¼ãƒ«ãƒ»ãƒ©ã‚¤ãƒ–ãƒ©ãƒªç­‰ã®å†…å®¹ãƒ»å¯ç”¨æ€§ãƒ»å®‰å…¨æ€§ã«ã¤ã„ã¦ã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯ä¸€åˆ‡ã®è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®åˆ©ç”¨ãƒ»å®Ÿè¡Œãƒ»è§£é‡ˆã«ã‚ˆã‚Šç›´æ¥çš„ãƒ»é–“æ¥çš„ãƒ»ä»˜éšçš„ãƒ»ç‰¹åˆ¥ãƒ»çµæœçš„ãƒ»æ‡²ç½°çš„æå®³ãŒç”Ÿã˜ãŸå ´åˆã§ã‚‚ã€é©ç”¨æ³•ã§è¨±å®¹ã•ã‚Œã‚‹æœ€å¤§é™ã®ç¯„å›²ã§ã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å†…å®¹ã¯ã€äºˆå‘Šãªãå¤‰æ›´ãƒ»æ›´æ–°ãƒ»æä¾›åœæ­¢ã•ã‚Œã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®è‘—ä½œæ¨©ãƒ»ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯æ˜è¨˜ã•ã‚ŒãŸæ¡ä»¶(ä¾‹: CC BY 4.0)ã«å¾“ã„ã¾ã™ã€‚å½“è©²ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯é€šå¸¸ã€ç„¡ä¿è¨¼æ¡é …ã‚’å«ã¿ã¾ã™ã€‚</li>
        </ul>
    </section>

<footer>
        <p><strong>ä½œæˆè€…</strong>: AI Terakoya Content Team</p>
        <p><strong>ãƒãƒ¼ã‚¸ãƒ§ãƒ³</strong>: 1.0 | <strong>ä½œæˆæ—¥</strong>: 2025-10-18</p>
        <p><strong>ãƒ©ã‚¤ã‚»ãƒ³ã‚¹</strong>: Creative Commons BY 4.0</p>
        <p>Â© 2025 AI Terakoya. All rights reserved.</p>
    </footer>
</body>
</html>
