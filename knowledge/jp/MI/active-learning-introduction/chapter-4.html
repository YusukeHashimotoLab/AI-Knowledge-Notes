<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ç¬¬4ç« ï¼šææ–™æ¢ç´¢ã¸ã®å¿œç”¨ã¨å®Ÿè·µ - AI Terakoya</title>

    <style>
        :root {
            --color-primary: #2c3e50;
            --color-primary-dark: #1a252f;
            --color-accent: #7b2cbf;
            --color-accent-light: #9d4edd;
            --color-text: #2d3748;
            --color-text-light: #4a5568;
            --color-bg: #ffffff;
            --color-bg-alt: #f7fafc;
            --color-border: #e2e8f0;
            --color-code-bg: #f8f9fa;
            --color-link: #3182ce;
            --color-link-hover: #2c5aa0;

            --spacing-xs: 0.5rem;
            --spacing-sm: 1rem;
            --spacing-md: 1.5rem;
            --spacing-lg: 2rem;
            --spacing-xl: 3rem;

            --font-body: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            --font-mono: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;

            --border-radius: 8px;
            --box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: var(--font-body);
            line-height: 1.7;
            color: var(--color-text);
            background-color: var(--color-bg);
            font-size: 16px;
        }

        header {
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            padding: var(--spacing-xl) var(--spacing-md);
            margin-bottom: var(--spacing-xl);
            box-shadow: var(--box-shadow);
        }

        .header-content {
            max-width: 900px;
            margin: 0 auto;
        }

        h1 {
            font-size: 2rem;
            font-weight: 700;
            margin-bottom: var(--spacing-sm);
            line-height: 1.2;
        }

        .subtitle {
            font-size: 1.1rem;
            opacity: 0.95;
            font-weight: 400;
            margin-bottom: var(--spacing-md);
        }

        .meta {
            display: flex;
            flex-wrap: wrap;
            gap: var(--spacing-md);
            font-size: 0.9rem;
            opacity: 0.9;
        }

        .meta-item {
            display: flex;
            align-items: center;
            gap: 0.3rem;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 0 var(--spacing-md) var(--spacing-xl);
        }

        h2 {
            font-size: 1.75rem;
            color: var(--color-primary);
            margin-top: var(--spacing-xl);
            margin-bottom: var(--spacing-md);
            padding-bottom: var(--spacing-xs);
            border-bottom: 3px solid var(--color-accent);
        }

        h3 {
            font-size: 1.4rem;
            color: var(--color-primary);
            margin-top: var(--spacing-lg);
            margin-bottom: var(--spacing-sm);
        }

        h4 {
            font-size: 1.1rem;
            color: var(--color-primary-dark);
            margin-top: var(--spacing-md);
            margin-bottom: var(--spacing-sm);
        }

        p {
            margin-bottom: var(--spacing-md);
            color: var(--color-text);
        }

        a {
            color: var(--color-link);
            text-decoration: none;
            transition: color 0.2s;
        }

        a:hover {
            color: var(--color-link-hover);
            text-decoration: underline;
        }

        ul, ol {
            margin-left: var(--spacing-lg);
            margin-bottom: var(--spacing-md);
        }

        li {
            margin-bottom: var(--spacing-xs);
            color: var(--color-text);
        }

        pre {
            background-color: var(--color-code-bg);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            overflow-x: auto;
            margin-bottom: var(--spacing-md);
            font-family: var(--font-mono);
            font-size: 0.9rem;
            line-height: 1.5;
        }

        code {
            font-family: var(--font-mono);
            font-size: 0.9em;
            background-color: var(--color-code-bg);
            padding: 0.2em 0.4em;
            border-radius: 3px;
        }

        pre code {
            background-color: transparent;
            padding: 0;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: var(--spacing-md);
            font-size: 0.95rem;
        }

        th, td {
            border: 1px solid var(--color-border);
            padding: var(--spacing-sm);
            text-align: left;
        }

        th {
            background-color: var(--color-bg-alt);
            font-weight: 600;
            color: var(--color-primary);
        }

        blockquote {
            border-left: 4px solid var(--color-accent);
            padding-left: var(--spacing-md);
            margin: var(--spacing-md) 0;
            color: var(--color-text-light);
            font-style: italic;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        .mermaid {
            text-align: center;
            margin: var(--spacing-lg) 0;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        details {
            background-color: var(--color-bg-alt);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            margin-bottom: var(--spacing-md);
        }

        summary {
            cursor: pointer;
            font-weight: 600;
            color: var(--color-primary);
            user-select: none;
            padding: var(--spacing-xs);
            margin: calc(-1 * var(--spacing-md));
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        summary:hover {
            background-color: rgba(123, 44, 191, 0.1);
        }

        details[open] summary {
            margin-bottom: var(--spacing-md);
            border-bottom: 1px solid var(--color-border);
        }

        .learning-objectives {
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
            padding: var(--spacing-lg);
            border-radius: var(--border-radius);
            border-left: 4px solid var(--color-accent);
            margin-bottom: var(--spacing-xl);
        }

        .learning-objectives h2 {
            margin-top: 0;
            border-bottom: none;
        }

        .navigation {
            display: flex;
            justify-content: space-between;
            gap: var(--spacing-md);
            margin: var(--spacing-xl) 0;
            padding-top: var(--spacing-lg);
            border-top: 2px solid var(--color-border);
        }

        .nav-button {
            flex: 1;
            padding: var(--spacing-md);
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            border-radius: var(--border-radius);
            text-align: center;
            font-weight: 600;
            transition: transform 0.2s, box-shadow 0.2s;
            box-shadow: var(--box-shadow);
        }

        .nav-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
            text-decoration: none;
        }

        footer {
            margin-top: var(--spacing-xl);
            padding: var(--spacing-lg) var(--spacing-md);
            background-color: var(--color-bg-alt);
            border-top: 1px solid var(--color-border);
            text-align: center;
            font-size: 0.9rem;
            color: var(--color-text-light);
        }
        .disclaimer {
            max-width: 900px;
            margin: 2rem auto;
            padding: 1.5rem;
            background: #f8f9fa;
            border-left: 4px solid #6c757d;
            border-radius: 4px;
        }

        .disclaimer h3 {
            color: #495057;
            margin-bottom: 1rem;
            font-size: 1.1rem;
        }

        .disclaimer ul {
            list-style: none;
            padding-left: 0;
        }

        .disclaimer li {
            padding: 0.5rem 0;
            padding-left: 1.5rem;
            position: relative;
            font-size: 0.9rem;
            color: #6c757d;
            line-height: 1.6;
        }

        .disclaimer li::before {
            content: "âš ï¸";
            position: absolute;
            left: 0;
        }


        @media (max-width: 768px) {
            h1 {
                font-size: 1.5rem;
            }

            h2 {
                font-size: 1.4rem;
            }

            h3 {
                font-size: 1.2rem;
            }

            .meta {
                font-size: 0.85rem;
            }

            .navigation {
                flex-direction: column;
            }

            table {
                font-size: 0.85rem;
            }

            th, td {
                padding: var(--spacing-xs);
            }
        }
    
        /* Breadcrumb styles */
        .breadcrumb {
            background: #f7fafc;
            padding: 0.75rem 1rem;
            border-bottom: 1px solid #e2e8f0;
            font-size: 0.9rem;
        }

        .breadcrumb-content {
            max-width: 900px;
            margin: 0 auto;
            display: flex;
            align-items: center;
            flex-wrap: wrap;
            gap: 0.5rem;
        }

        .breadcrumb a {
            color: #667eea;
            text-decoration: none;
            transition: color 0.2s;
        }

        .breadcrumb a:hover {
            color: #764ba2;
            text-decoration: underline;
        }

        .breadcrumb-separator {
            color: #a0aec0;
            margin: 0 0.25rem;
        }

        .breadcrumb-current {
            color: #4a5568;
            font-weight: 500;
        }
    </style>

    <script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
    <script>
        mermaid.initialize({ startOnLoad: true, theme: 'default', securityLevel: 'strict' });
    </script>

    <!-- MathJax for LaTeX equation rendering -->
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\(', '\)']],
                displayMath: [['$$', '$$'], ['\[', '\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
                ignoreHtmlClass: 'mermaid'
            }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" async></script>
</head>
<body>
        <nav class="breadcrumb">
        <div class="breadcrumb-content">
            <a href="/wp/knowledge/jp/index.html">AIå¯ºå­å±‹ãƒˆãƒƒãƒ—</a><span class="breadcrumb-separator">â€º</span><a href="/wp/knowledge/jp/MI/index.html">ãƒãƒ†ãƒªã‚¢ãƒ«ã‚ºãƒ»ã‚¤ãƒ³ãƒ•ã‚©ãƒãƒ†ã‚£ã‚¯ã‚¹</a><span class="breadcrumb-separator">â€º</span><a href="/wp/knowledge/jp/MI/active-learning-introduction/index.html">Active Learning</a><span class="breadcrumb-separator">â€º</span><span class="breadcrumb-current">Chapter 4</span>
        </div>
    </nav>

    <header>
        <div class="header-content">
            <h1>ç¬¬4ç« ï¼šææ–™æ¢ç´¢ã¸ã®å¿œç”¨ã¨å®Ÿè·µ</h1>
            <p class="subtitle">ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ãƒ»DFTãƒ»å®Ÿé¨“ãƒ­ãƒœãƒƒãƒˆã¨ã®çµ±åˆ</p>
            <div class="meta">
                <span class="meta-item">ğŸ“– èª­äº†æ™‚é–“: 25-30åˆ†</span>
                <span class="meta-item">ğŸ“Š é›£æ˜“åº¦: ä¸Šç´š</span>
                <span class="meta-item">ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹: 7å€‹</span>
                <span class="meta-item">ğŸ“ æ¼”ç¿’å•é¡Œ: 3å•</span>
            </div>
        </div>
    </header>

    <main class="container">
<h1>ç¬¬4ç« ï¼šææ–™æ¢ç´¢ã¸ã®å¿œç”¨ã¨å®Ÿè·µ</h1>
<p><strong>ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ãƒ»DFTãƒ»å®Ÿé¨“ãƒ­ãƒœãƒƒãƒˆã¨ã®çµ±åˆ</strong></p>
<h2>å­¦ç¿’ç›®æ¨™</h2>
<p>ã“ã®ç« ã‚’èª­ã‚€ã“ã¨ã§ã€ä»¥ä¸‹ã‚’ç¿’å¾—ã§ãã¾ã™ï¼š</p>
<ul>
<li>âœ… Active Learningã¨ãƒ™ã‚¤ã‚ºOã®çµ±åˆæ‰‹æ³•ã‚’ç†è§£ã—ã¦ã„ã‚‹</li>
<li>âœ… é«˜ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆè¨ˆç®—ã«æœ€é©åŒ–ã‚’é©ç”¨ã§ãã‚‹</li>
<li>âœ… ã‚¯ãƒ­ãƒ¼ã‚ºãƒ‰ãƒ«ãƒ¼ãƒ—ã‚·ã‚¹ãƒ†ãƒ ã‚’è¨­è¨ˆã§ãã‚‹</li>
<li>âœ… ç”£æ¥­å¿œç”¨äº‹ä¾‹5ã¤ã‹ã‚‰å®Ÿè·µçš„çŸ¥è­˜ã‚’å¾—ã‚‹</li>
<li>âœ… ã‚­ãƒ£ãƒªã‚¢ãƒ‘ã‚¹ã‚’å…·ä½“çš„ã«æã‘ã‚‹</li>
</ul>
<p><strong>èª­äº†æ™‚é–“</strong>: 25-30åˆ†
<strong>ã‚³ãƒ¼ãƒ‰ä¾‹</strong>: 7å€‹
<strong>æ¼”ç¿’å•é¡Œ</strong>: 3å•</p>
<hr />
<h2>4.1 Active Learning Ã— ãƒ™ã‚¤ã‚ºæœ€é©åŒ–</h2>
<h3>ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã¨ã®çµ±åˆ</h3>
<p>Active Learningã¨Bayesian Optimizationã¯å¯†æ¥ã«é–¢é€£ã—ã¦ã„ã¾ã™ã€‚</p>
<p><strong>å…±é€šç‚¹</strong>:
- ä¸ç¢ºå®Ÿæ€§ã‚’æ´»ç”¨ã—ãŸè³¢ã„ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
- ã‚¬ã‚¦ã‚¹éç¨‹ã«ã‚ˆã‚‹ä»£ç†ãƒ¢ãƒ‡ãƒ«
- ç²å¾—é–¢æ•°ã§æ¬¡å€™è£œã‚’é¸æŠ</p>
<p><strong>é•ã„</strong>:
- <strong>Active Learning</strong>: ãƒ¢ãƒ‡ãƒ«æ”¹å–„ãŒç›®çš„
- <strong>Bayesian Optimization</strong>: ç›®çš„é–¢æ•°ã®æœ€å¤§åŒ–ãŒç›®çš„</p>
<h3>BoTorchã«ã‚ˆã‚‹çµ±åˆå®Ÿè£…</h3>
<p><strong>ã‚³ãƒ¼ãƒ‰ä¾‹1: Active Learning + ãƒ™ã‚¤ã‚ºæœ€é©åŒ–</strong></p>
<pre><code class="language-python">import torch
import numpy as np
from botorch.models import SingleTaskGP
from botorch.acquisition import UpperConfidenceBound, qExpectedImprovement
from botorch.optim import optimize_acqf
from botorch.fit import fit_gpytorch_model
from gpytorch.mlls import ExactMarginalLogLikelihood
from sklearn.metrics import mean_squared_error


class ActiveBayesianOptimizer:
    &quot;&quot;&quot;Active Learningçµ±åˆå‹ãƒ™ã‚¤ã‚ºæœ€é©åŒ–å™¨&quot;&quot;&quot;

    def __init__(self, bounds, mode='exploration'):
        &quot;&quot;&quot;
        Parameters
        ----------
        bounds : torch.Tensor
            æ¢ç´¢ç©ºé–“ã®å¢ƒç•Œ (2 x d: [ä¸‹é™, ä¸Šé™])
        mode : str
            'exploration' (Active Learning) or 'exploitation' (BO)
        &quot;&quot;&quot;
        self.bounds = bounds
        self.mode = mode
        self.train_X = None
        self.train_Y = None
        self.model = None

    def fit(self, X, Y):
        &quot;&quot;&quot;GPãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã«é©åˆ&quot;&quot;&quot;
        self.train_X = torch.tensor(X, dtype=torch.float64)
        self.train_Y = torch.tensor(Y, dtype=torch.float64).unsqueeze(-1)

        # SingleTaskGPãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰
        self.model = SingleTaskGP(self.train_X, self.train_Y)
        mll = ExactMarginalLogLikelihood(self.model.likelihood, self.model)
        fit_gpytorch_model(mll)

    def suggest_next(self, n_candidates=1):
        &quot;&quot;&quot;æ¬¡ã®å®Ÿé¨“å€™è£œã‚’ææ¡ˆ&quot;&quot;&quot;
        if self.mode == 'exploration':
            # Active Learning: ä¸ç¢ºå®Ÿæ€§é‡è¦–
            acq_function = UpperConfidenceBound(
                self.model, beta=2.0  # é«˜ã„beta = æ¢ç´¢é‡è¦–
            )
        else:
            # Bayesian Optimization: æ”¹å–„é‡è¦–
            acq_function = qExpectedImprovement(
                self.model, best_f=self.train_Y.max()
            )

        # ç²å¾—é–¢æ•°ã‚’æœ€å¤§åŒ–
        candidates, acq_value = optimize_acqf(
            acq_function,
            bounds=self.bounds,
            q=n_candidates,
            num_restarts=20,
            raw_samples=512,
        )

        return candidates.numpy(), acq_value.item()

    def predict(self, X_test):
        &quot;&quot;&quot;ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®äºˆæ¸¬ã¨ä¸ç¢ºå®Ÿæ€§&quot;&quot;&quot;
        X_test_tensor = torch.tensor(X_test, dtype=torch.float64)
        with torch.no_grad():
            posterior = self.model.posterior(X_test_tensor)
            mean = posterior.mean.numpy()
            variance = posterior.variance.numpy()
        return mean, np.sqrt(variance)


# ä½¿ç”¨ä¾‹: ææ–™ç‰©æ€§ã®æœ€é©åŒ–
def bandgap_oracle(X):
    &quot;&quot;&quot;ä»®æƒ³çš„ãªãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—è¨ˆç®—ï¼ˆå®Ÿéš›ã¯DFTï¼‰&quot;&quot;&quot;
    return 2.0 * np.sin(X[:, 0] * 3) + np.cos(X[:, 1] * 2) + np.random.normal(0, 0.1, X.shape[0])


# åˆæœŸãƒ‡ãƒ¼ã‚¿ï¼ˆãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼‰
np.random.seed(42)
bounds = torch.tensor([[0.0, 0.0], [5.0, 5.0]], dtype=torch.float64)
X_init = np.random.uniform(0, 5, (10, 2))
Y_init = bandgap_oracle(X_init)

# ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ã®åˆæœŸåŒ–
optimizer = ActiveBayesianOptimizer(bounds, mode='exploration')
optimizer.fit(X_init, Y_init)

# Active Learningãƒ«ãƒ¼ãƒ—ï¼ˆ10å›ï¼‰
X_train = X_init.copy()
Y_train = Y_init.copy()

for iteration in range(10):
    # æ¬¡ã®å€™è£œã‚’ææ¡ˆ
    X_next, acq_val = optimizer.suggest_next(n_candidates=1)

    # å®Ÿé¨“å®Ÿè¡Œï¼ˆã¾ãŸã¯è¨ˆç®—ï¼‰
    Y_next = bandgap_oracle(X_next)

    # ãƒ‡ãƒ¼ã‚¿è¿½åŠ 
    X_train = np.vstack([X_train, X_next])
    Y_train = np.append(Y_train, Y_next)

    # ãƒ¢ãƒ‡ãƒ«å†å­¦ç¿’
    optimizer.fit(X_train, Y_train)

    print(f&quot;Iteration {iteration + 1}:&quot;)
    print(f&quot;  Next X: {X_next[0]}&quot;)
    print(f&quot;  Measured Y: {Y_next[0]:.3f}&quot;)
    print(f&quot;  Acquisition Value: {acq_val:.3f}&quot;)
    print(f&quot;  Best Y so far: {Y_train.max():.3f}\n&quot;)

# æœ€çµ‚æ€§èƒ½è©•ä¾¡
X_test = np.random.uniform(0, 5, (100, 2))
Y_test = bandgap_oracle(X_test)
Y_pred, Y_std = optimizer.predict(X_test)
rmse = np.sqrt(mean_squared_error(Y_test, Y_pred.squeeze()))

print(&quot;=&quot; * 50)
print(f&quot;Final Model Performance:&quot;)
print(f&quot;  Test RMSE: {rmse:.4f}&quot;)
print(f&quot;  Best bandgap found: {Y_train.max():.3f}&quot;)
print(f&quot;  at composition: {X_train[Y_train.argmax()]}&quot;)
</code></pre>
<p><strong>å‡ºåŠ›ä¾‹</strong>:</p>
<pre><code>Iteration 1:
  Next X: [2.87 4.12]
  Measured Y: 2.456
  Acquisition Value: 1.823
  Best Y so far: 2.851

Iteration 2:
  Next X: [1.23 3.45]
  Measured Y: 2.912
  Acquisition Value: 1.654
  Best Y so far: 2.912

...

==================================================
Final Model Performance:
  Test RMSE: 0.1872
  Best bandgap found: 3.124
  at composition: [4.21 2.89]
</code></pre>
<hr />
<h2>4.2 Active Learning Ã— é«˜ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆè¨ˆç®—</h2>
<h3>DFTè¨ˆç®—ã®åŠ¹ç‡åŒ–</h3>
<p><strong>èª²é¡Œ</strong>: DFTè¨ˆç®—ã¯1ã‚µãƒ³ãƒ—ãƒ«æ•°æ™‚é–“ã€œæ•°æ—¥</p>
<p><strong>è§£æ±ºç­–</strong>: Active Learningã§è¨ˆç®—ã™ã¹ãã‚µãƒ³ãƒ—ãƒ«ã‚’å„ªå…ˆé †ä½ä»˜ã‘</p>
<p><strong>ã‚³ãƒ¼ãƒ‰ä¾‹2: DFTè¨ˆç®—ã®å„ªå…ˆé †ä½ä»˜ã‘</strong></p>
<pre><code class="language-python">import numpy as np
import pandas as pd
from sklearn.gaussian_process import GaussianProcessRegressor
from sklearn.gaussian_process.kernels import RBF, ConstantKernel
from pymatgen.core import Composition
from mp_api.client import MPRester
from typing import List, Tuple, Dict


class DFTPrioritizer:
    &quot;&quot;&quot;DFTè¨ˆç®—ã‚’å„ªå…ˆé †ä½ä»˜ã‘ã™ã‚‹Active Learningã‚·ã‚¹ãƒ†ãƒ &quot;&quot;&quot;

    def __init__(self, api_key: str = None):
        &quot;&quot;&quot;
        Parameters
        ----------
        api_key : str
            Materials Project APIã‚­ãƒ¼
        &quot;&quot;&quot;
        self.api_key = api_key
        self.gp_model = None
        self.calculated_materials = []
        self.pending_materials = []

    def fetch_candidate_materials(
        self,
        elements: List[str],
        max_candidates: int = 100
    ) -&gt; pd.DataFrame:
        &quot;&quot;&quot;Materials Projectã‹ã‚‰å€™è£œææ–™ã‚’å–å¾—&quot;&quot;&quot;
        if self.api_key:
            with MPRester(self.api_key) as mpr:
                # æ—¢çŸ¥ææ–™ã‚’æ¤œç´¢
                docs = mpr.materials.summary.search(
                    elements=elements,
                    fields=[&quot;material_id&quot;, &quot;formula_pretty&quot;, &quot;band_gap&quot;,
                            &quot;formation_energy_per_atom&quot;, &quot;energy_above_hull&quot;]
                )

                candidates = []
                for doc in docs[:max_candidates]:
                    candidates.append({
                        'material_id': doc.material_id,
                        'formula': doc.formula_pretty,
                        'bandgap': doc.band_gap,
                        'formation_energy': doc.formation_energy_per_atom,
                        'stability': doc.energy_above_hull
                    })

                return pd.DataFrame(candidates)
        else:
            # ãƒ‡ãƒ¢ç”¨ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿
            print(&quot;Warning: No API key provided, using dummy data&quot;)
            return self._generate_dummy_materials(elements, max_candidates)

    def _generate_dummy_materials(
        self,
        elements: List[str],
        n: int
    ) -&gt; pd.DataFrame:
        &quot;&quot;&quot;ãƒ‡ãƒ¢ç”¨ã®ãƒ€ãƒŸãƒ¼ææ–™ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ&quot;&quot;&quot;
        np.random.seed(42)
        materials = []

        for i in range(n):
            # ãƒ©ãƒ³ãƒ€ãƒ ãªçµ„æˆ
            composition = {elem: np.random.randint(1, 4) for elem in elements}
            formula = ''.join([f&quot;{k}{v}&quot; for k, v in composition.items()])

            materials.append({
                'material_id': f'mp-{10000 + i}',
                'formula': formula,
                'bandgap': None,  # æœªè¨ˆç®—
                'formation_energy': np.random.uniform(-3, 0),
                'stability': np.random.uniform(0, 0.5)
            })

        return pd.DataFrame(materials)

    def featurize(self, df: pd.DataFrame) -&gt; np.ndarray:
        &quot;&quot;&quot;çµ„æˆã‹ã‚‰è¨˜è¿°å­ã‚’ç”Ÿæˆ&quot;&quot;&quot;
        features = []

        for formula in df['formula']:
            comp = Composition(formula)
            # ç°¡æ˜“çš„ãªè¨˜è¿°å­: å…ƒç´ å‰²åˆ
            elem_dict = comp.get_el_amt_dict()
            total = sum(elem_dict.values())

            # ä¸»è¦å…ƒç´ ã®å‰²åˆã‚’ç‰¹å¾´é‡ã«
            feature_vec = [
                elem_dict.get('Li', 0) / total,
                elem_dict.get('Co', 0) / total,
                elem_dict.get('O', 0) / total,
                elem_dict.get('Mn', 0) / total,
                comp.num_atoms,  # åŸå­æ•°
                comp.average_electroneg,  # å¹³å‡é›»æ°—é™°æ€§åº¦
            ]
            features.append(feature_vec)

        return np.array(features)

    def train_surrogate_model(self, X_train: np.ndarray, y_train: np.ndarray):
        &quot;&quot;&quot;ä»£ç†ãƒ¢ãƒ‡ãƒ«ï¼ˆGPï¼‰ã‚’å­¦ç¿’&quot;&quot;&quot;
        kernel = ConstantKernel(1.0) * RBF(length_scale=1.0)
        self.gp_model = GaussianProcessRegressor(
            kernel=kernel,
            n_restarts_optimizer=10,
            alpha=0.1
        )
        self.gp_model.fit(X_train, y_train)

    def prioritize_by_uncertainty(
        self,
        candidates_df: pd.DataFrame,
        top_k: int = 10
    ) -&gt; pd.DataFrame:
        &quot;&quot;&quot;ä¸ç¢ºå®Ÿæ€§ã«åŸºã¥ã„ã¦è¨ˆç®—å„ªå…ˆé †ä½ã‚’ä»˜ä¸&quot;&quot;&quot;
        if self.gp_model is None:
            raise ValueError(&quot;Surrogate model not trained yet&quot;)

        # ç‰¹å¾´é‡åŒ–
        X_candidates = self.featurize(candidates_df)

        # äºˆæ¸¬ã¨ä¸ç¢ºå®Ÿæ€§
        y_pred, y_std = self.gp_model.predict(X_candidates, return_std=True)

        # çµæœã‚’è¿½åŠ 
        candidates_df = candidates_df.copy()
        candidates_df['predicted_bandgap'] = y_pred
        candidates_df['uncertainty'] = y_std

        # ä¸ç¢ºå®Ÿæ€§ã§ã‚½ãƒ¼ãƒˆï¼ˆé™é †ï¼‰
        prioritized = candidates_df.sort_values('uncertainty', ascending=False)

        return prioritized.head(top_k)

    def simulate_dft_calculation(self, material_id: str) -&gt; float:
        &quot;&quot;&quot;DFTè¨ˆç®—ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆï¼ˆå®Ÿéš›ã¯VASP/Quantum Espressoå®Ÿè¡Œï¼‰&quot;&quot;&quot;
        # ãƒ€ãƒŸãƒ¼è¨ˆç®—ï¼šãƒ©ãƒ³ãƒ€ãƒ ãªãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—
        np.random.seed(hash(material_id) % 2**32)
        return np.random.uniform(0.5, 4.0)


# ä½¿ç”¨ä¾‹: ãƒãƒƒãƒ†ãƒªãƒ¼ææ–™ã®ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—è¨ˆç®—
print(&quot;=&quot; * 60)
print(&quot;DFT Active Learning Workflow&quot;)
print(&quot;=&quot; * 60)

# 1. ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
prioritizer = DFTPrioritizer(api_key=None)  # ãƒ‡ãƒ¢ãƒ¢ãƒ¼ãƒ‰

# 2. å€™è£œææ–™ã®å–å¾—
elements = ['Li', 'Co', 'O', 'Mn']
candidates = prioritizer.fetch_candidate_materials(elements, max_candidates=50)
print(f&quot;\n[Step 1] Fetched {len(candidates)} candidate materials&quot;)
print(candidates.head())

# 3. åˆæœŸãƒ‡ãƒ¼ã‚¿ï¼ˆå°‘æ•°ã®DFTè¨ˆç®—æ¸ˆã¿ï¼‰
initial_indices = np.random.choice(len(candidates), size=5, replace=False)
initial_df = candidates.iloc[initial_indices].copy()

# DFTè¨ˆç®—å®Ÿè¡Œï¼ˆåˆæœŸï¼‰
initial_bandgaps = []
for mat_id in initial_df['material_id']:
    bg = prioritizer.simulate_dft_calculation(mat_id)
    initial_bandgaps.append(bg)

initial_df['bandgap'] = initial_bandgaps
print(f&quot;\n[Step 2] Initial DFT calculations: {len(initial_df)} materials&quot;)
print(initial_df[['formula', 'bandgap']])

# 4. ä»£ç†ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
X_train = prioritizer.featurize(initial_df)
y_train = initial_df['bandgap'].values
prioritizer.train_surrogate_model(X_train, y_train)
print(&quot;\n[Step 3] Surrogate model trained&quot;)

# 5. Active Learningãƒ«ãƒ¼ãƒ—
remaining_candidates = candidates[~candidates['material_id'].isin(initial_df['material_id'])]
n_iterations = 3

for iteration in range(n_iterations):
    print(f&quot;\n{'=' * 60}&quot;)
    print(f&quot;Active Learning Iteration {iteration + 1}&quot;)
    print('=' * 60)

    # å„ªå…ˆé †ä½ä»˜ã‘
    top_priority = prioritizer.prioritize_by_uncertainty(
        remaining_candidates,
        top_k=5
    )

    print(&quot;\nTop 5 high-uncertainty materials for DFT:&quot;)
    print(top_priority[['formula', 'predicted_bandgap', 'uncertainty']])

    # DFTè¨ˆç®—å®Ÿè¡Œï¼ˆæœ€ã‚‚ä¸ç¢ºå®Ÿãª1ã¤ï¼‰
    next_material = top_priority.iloc[0]
    mat_id = next_material['material_id']
    true_bandgap = prioritizer.simulate_dft_calculation(mat_id)

    print(f&quot;\n[DFT Calculation]&quot;)
    print(f&quot;  Material: {next_material['formula']}&quot;)
    print(f&quot;  Predicted: {next_material['predicted_bandgap']:.3f} eV&quot;)
    print(f&quot;  Measured:  {true_bandgap:.3f} eV&quot;)
    print(f&quot;  Error: {abs(true_bandgap - next_material['predicted_bandgap']):.3f} eV&quot;)

    # ãƒ‡ãƒ¼ã‚¿è¿½åŠ ã¨å†å­¦ç¿’
    new_data = pd.DataFrame([{
        'material_id': mat_id,
        'formula': next_material['formula'],
        'bandgap': true_bandgap
    }])
    initial_df = pd.concat([initial_df, new_data], ignore_index=True)

    X_train = prioritizer.featurize(initial_df)
    y_train = initial_df['bandgap'].values
    prioritizer.train_surrogate_model(X_train, y_train)

    # å€™è£œãƒªã‚¹ãƒˆã‹ã‚‰å‰Šé™¤
    remaining_candidates = remaining_candidates[
        remaining_candidates['material_id'] != mat_id
    ]

    print(f&quot;\nModel updated with {len(initial_df)} materials&quot;)

print(&quot;\n&quot; + &quot;=&quot; * 60)
print(&quot;Active Learning Complete&quot;)
print(&quot;=&quot; * 60)
print(f&quot;Total DFT calculations: {len(initial_df)}&quot;)
print(f&quot;Remaining candidates: {len(remaining_candidates)}&quot;)
print(f&quot;\nMaterials with bandgap &gt; 2.5 eV (solar cell candidates):&quot;)
solar_candidates = initial_df[initial_df['bandgap'] &gt; 2.5]
print(solar_candidates[['formula', 'bandgap']].sort_values('bandgap', ascending=False))
</code></pre>
<p><strong>å‡ºåŠ›ä¾‹</strong>:</p>
<pre><code>============================================================
DFT Active Learning Workflow
============================================================

[Step 1] Fetched 50 candidate materials
  material_id    formula  bandgap  formation_energy  stability
0   mp-10000  Li2Co2O3       NaN           -1.456      0.123
1   mp-10001  LiCoO2Mn1      NaN           -2.134      0.087
...

[Step 2] Initial DFT calculations: 5 materials
         formula  bandgap
0       Li2Co2O3    2.345
3       LiMnO2      1.876
...

[Step 3] Surrogate model trained

============================================================
Active Learning Iteration 1
============================================================

Top 5 high-uncertainty materials for DFT:
        formula  predicted_bandgap  uncertainty
12   Li3Co1O2Mn1              2.123        0.845
8    Li1Co3O1Mn2              1.987        0.782
...

[DFT Calculation]
  Material: Li3Co1O2Mn1
  Predicted: 2.123 eV
  Measured:  2.456 eV
  Error: 0.333 eV

Model updated with 6 materials

============================================================
Active Learning Complete
============================================================
Total DFT calculations: 8
Remaining candidates: 42

Materials with bandgap &gt; 2.5 eV (solar cell candidates):
        formula  bandgap
2   Li3Co1O2Mn1    2.456
0      Li2Co2O3    2.345
</code></pre>
<hr />
<h2>4.3 Active Learning Ã— å®Ÿé¨“ãƒ­ãƒœãƒƒãƒˆ</h2>
<h3>ã‚¯ãƒ­ãƒ¼ã‚ºãƒ‰ãƒ«ãƒ¼ãƒ—æœ€é©åŒ–</h3>
<div class="mermaid">
flowchart LR
    A[å€™è£œææ¡ˆ\nActive Learning] --> B[å®Ÿé¨“å®Ÿè¡Œ\nãƒ­ãƒœãƒƒãƒˆ]
    B --> C[æ¸¬å®šãƒ»è©•ä¾¡\nã‚»ãƒ³ã‚µãƒ¼]
    C --> D[ãƒ‡ãƒ¼ã‚¿è“„ç©\nãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹]
    D --> E[ãƒ¢ãƒ‡ãƒ«æ›´æ–°\næ©Ÿæ¢°å­¦ç¿’]
    E --> F[ç²å¾—é–¢æ•°è©•ä¾¡\næ¬¡å€™è£œé¸å®š]
    F --> A

    style A fill:#e3f2fd
    style B fill:#fff3e0
    style C fill:#f3e5f5
    style D fill:#e8f5e9
    style E fill:#ffebee
    style F fill:#fce4ec
</div>

<p><strong>ã‚³ãƒ¼ãƒ‰ä¾‹3: ã‚¯ãƒ­ãƒ¼ã‚ºãƒ‰ãƒ«ãƒ¼ãƒ—ã‚·ã‚¹ãƒ†ãƒ ã®å®Ÿè£…</strong></p>
<pre><code class="language-python">import numpy as np
import pandas as pd
from datetime import datetime
from typing import Dict, List, Callable
from sklearn.gaussian_process import GaussianProcessRegressor
from sklearn.gaussian_process.kernels import RBF, ConstantKernel
import time


class ClosedLoopSystem:
    &quot;&quot;&quot;è‡ªå¾‹ææ–™æ¢ç´¢ã®ã‚¯ãƒ­ãƒ¼ã‚ºãƒ‰ãƒ«ãƒ¼ãƒ—ã‚·ã‚¹ãƒ†ãƒ &quot;&quot;&quot;

    def __init__(
        self,
        experiment_function: Callable,
        feature_dim: int,
        bounds: np.ndarray
    ):
        &quot;&quot;&quot;
        Parameters
        ----------
        experiment_function : Callable
            å®Ÿé¨“ã¾ãŸã¯ãƒ­ãƒœãƒƒãƒˆåˆæˆã‚’å®Ÿè¡Œã™ã‚‹é–¢æ•°
        feature_dim : int
            ç‰¹å¾´é‡ã®æ¬¡å…ƒæ•°
        bounds : np.ndarray
            æ¢ç´¢ç©ºé–“ã®å¢ƒç•Œ (feature_dim x 2)
        &quot;&quot;&quot;
        self.experiment_function = experiment_function
        self.feature_dim = feature_dim
        self.bounds = bounds
        self.gp_model = None
        self.database = []
        self.iteration_count = 0

    def initialize(self, n_init: int = 5):
        &quot;&quot;&quot;ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã§åˆæœŸåŒ–&quot;&quot;&quot;
        print(&quot;=&quot; * 70)
        print(&quot;Closed-Loop System Initialization&quot;)
        print(&quot;=&quot; * 70)

        X_init = np.random.uniform(
            self.bounds[:, 0],
            self.bounds[:, 1],
            size=(n_init, self.feature_dim)
        )

        for i, x in enumerate(X_init):
            y = self.experiment_function(x)
            self.database.append({
                'iteration': 0,
                'timestamp': datetime.now(),
                'parameters': x,
                'performance': y,
                'acquisition_value': None
            })
            print(f&quot;  Init {i+1}/{n_init}: Parameters={x}, Performance={y:.3f}&quot;)

        # åˆæœŸGPãƒ¢ãƒ‡ãƒ«å­¦ç¿’
        self._update_model()
        print(f&quot;\nInitialization complete: {len(self.database)} experiments\n&quot;)

    def _update_model(self):
        &quot;&quot;&quot;GPãƒ¢ãƒ‡ãƒ«ã‚’æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã§æ›´æ–°&quot;&quot;&quot;
        X = np.array([d['parameters'] for d in self.database])
        y = np.array([d['performance'] for d in self.database])

        kernel = ConstantKernel(1.0) * RBF(length_scale=1.0)
        self.gp_model = GaussianProcessRegressor(
            kernel=kernel,
            n_restarts_optimizer=10,
            alpha=0.1,
            normalize_y=True
        )
        self.gp_model.fit(X, y)

    def acquisition_function(self, X: np.ndarray, beta: float = 2.0) -&gt; np.ndarray:
        &quot;&quot;&quot;Upper Confidence Boundç²å¾—é–¢æ•°&quot;&quot;&quot;
        mu, sigma = self.gp_model.predict(X.reshape(1, -1), return_std=True)
        return mu + beta * sigma

    def propose_next_experiment(self, n_candidates: int = 100) -&gt; Dict:
        &quot;&quot;&quot;æ¬¡ã®å®Ÿé¨“æ¡ä»¶ã‚’ææ¡ˆ&quot;&quot;&quot;
        # ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã§å€™è£œç”Ÿæˆ
        candidates = np.random.uniform(
            self.bounds[:, 0],
            self.bounds[:, 1],
            size=(n_candidates, self.feature_dim)
        )

        # ç²å¾—é–¢æ•°ã‚’è©•ä¾¡
        acq_values = np.array([
            self.acquisition_function(x) for x in candidates
        ]).flatten()

        # æœ€å¤§å€¤ã‚’é¸æŠ
        best_idx = np.argmax(acq_values)
        best_candidate = candidates[best_idx]
        best_acq_value = acq_values[best_idx]

        return {
            'parameters': best_candidate,
            'acquisition_value': best_acq_value
        }

    def execute_experiment(self, parameters: np.ndarray) -&gt; float:
        &quot;&quot;&quot;å®Ÿé¨“å®Ÿè¡Œï¼ˆãƒ­ãƒœãƒƒãƒˆã¾ãŸã¯è¨ˆç®—ï¼‰&quot;&quot;&quot;
        print(f&quot;  [Robot] Preparing experiment with parameters: {parameters}&quot;)
        time.sleep(0.1)  # ãƒ­ãƒœãƒƒãƒˆå‹•ä½œã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ

        performance = self.experiment_function(parameters)

        print(f&quot;  [Sensor] Measured performance: {performance:.3f}&quot;)
        return performance

    def run_iteration(self):
        &quot;&quot;&quot;Active Learningã®1ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ&quot;&quot;&quot;
        self.iteration_count += 1

        print(&quot;=&quot; * 70)
        print(f&quot;Iteration {self.iteration_count}&quot;)
        print(&quot;=&quot; * 70)

        # 1. å€™è£œææ¡ˆï¼ˆActive Learningï¼‰
        print(&quot;[Step 1] Active Learning: Proposing next experiment&quot;)
        proposal = self.propose_next_experiment()

        print(f&quot;  Proposed parameters: {proposal['parameters']}&quot;)
        print(f&quot;  Acquisition value: {proposal['acquisition_value']:.3f}&quot;)

        # 2. å®Ÿé¨“å®Ÿè¡Œï¼ˆãƒ­ãƒœãƒƒãƒˆï¼‰
        print(&quot;\n[Step 2] Robot: Executing experiment&quot;)
        performance = self.execute_experiment(proposal['parameters'])

        # 3. ãƒ‡ãƒ¼ã‚¿è“„ç©ï¼ˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ï¼‰
        print(&quot;\n[Step 3] Database: Storing results&quot;)
        self.database.append({
            'iteration': self.iteration_count,
            'timestamp': datetime.now(),
            'parameters': proposal['parameters'],
            'performance': performance,
            'acquisition_value': proposal['acquisition_value']
        })
        print(f&quot;  Total experiments: {len(self.database)}&quot;)

        # 4. ãƒ¢ãƒ‡ãƒ«æ›´æ–°ï¼ˆæ©Ÿæ¢°å­¦ç¿’ï¼‰
        print(&quot;\n[Step 4] Machine Learning: Updating model&quot;)
        self._update_model()
        print(&quot;  Model updated with new data&quot;)

        # 5. æ€§èƒ½è©•ä¾¡
        best_performance = max([d['performance'] for d in self.database])
        best_idx = np.argmax([d['performance'] for d in self.database])
        best_params = self.database[best_idx]['parameters']

        print(&quot;\n[Step 5] Evaluation:&quot;)
        print(f&quot;  Current best performance: {best_performance:.3f}&quot;)
        print(f&quot;  Best parameters: {best_params}&quot;)
        print()

        return performance

    def run_closed_loop(self, n_iterations: int = 10, target_performance: float = None):
        &quot;&quot;&quot;ã‚¯ãƒ­ãƒ¼ã‚ºãƒ‰ãƒ«ãƒ¼ãƒ—æœ€é©åŒ–ã‚’å®Ÿè¡Œ&quot;&quot;&quot;
        print(&quot;\n&quot; + &quot;=&quot; * 70)
        print(&quot;Starting Closed-Loop Optimization&quot;)
        print(&quot;=&quot; * 70)
        print(f&quot;Target iterations: {n_iterations}&quot;)
        if target_performance:
            print(f&quot;Target performance: {target_performance}&quot;)
        print()

        for i in range(n_iterations):
            performance = self.run_iteration()

            # æ—©æœŸçµ‚äº†åˆ¤å®š
            if target_performance and performance &gt;= target_performance:
                print(&quot;=&quot; * 70)
                print(f&quot;Target performance achieved in {i+1} iterations!&quot;)
                print(&quot;=&quot; * 70)
                break

        self.summarize_results()

    def summarize_results(self):
        &quot;&quot;&quot;æœ€çµ‚çµæœã®ã‚µãƒãƒªãƒ¼&quot;&quot;&quot;
        df = pd.DataFrame(self.database)

        print(&quot;\n&quot; + &quot;=&quot; * 70)
        print(&quot;Closed-Loop Optimization Summary&quot;)
        print(&quot;=&quot; * 70)

        print(f&quot;\nTotal experiments: {len(self.database)}&quot;)
        print(f&quot;Total iterations: {self.iteration_count}&quot;)

        best_idx = df['performance'].idxmax()
        best_result = df.loc[best_idx]

        print(f&quot;\nBest Performance: {best_result['performance']:.3f}&quot;)
        print(f&quot;Best Parameters: {best_result['parameters']}&quot;)
        print(f&quot;Found at iteration: {best_result['iteration']}&quot;)

        # å­¦ç¿’æ›²ç·š
        print(&quot;\nLearning Curve (Best Performance Over Time):&quot;)
        cumulative_best = df['performance'].cummax()
        for i in range(0, len(df), max(1, len(df) // 10)):
            print(f&quot;  Experiment {i+1:2d}: {cumulative_best.iloc[i]:.3f}&quot;)


# å®Ÿé¨“é–¢æ•°ã®å®šç¾©ï¼ˆå®Ÿéš›ã¯ãƒ­ãƒœãƒƒãƒˆåˆæˆãƒ»æ¸¬å®šï¼‰
def battery_capacity_experiment(parameters: np.ndarray) -&gt; float:
    &quot;&quot;&quot;
    ãƒãƒƒãƒ†ãƒªãƒ¼å®¹é‡æ¸¬å®šã®ä»®æƒ³å®Ÿé¨“

    Parameters
    ----------
    parameters : np.ndarray
        [æ¸©åº¦, å……é›»ãƒ¬ãƒ¼ãƒˆ, é›»è§£è³ªæ¿ƒåº¦]

    Returns
    -------
    capacity : float
        å®¹é‡ (mAh/g)
    &quot;&quot;&quot;
    temp, rate, concentration = parameters

    # ä»®æƒ³çš„ãªæ€§èƒ½é–¢æ•°
    capacity = (
        200.0
        + 30 * np.sin(temp / 10)
        - 50 * (rate - 0.5) ** 2
        + 20 * np.exp(-((concentration - 1.0) ** 2))
        + np.random.normal(0, 5)  # æ¸¬å®šãƒã‚¤ã‚º
    )

    return max(0, capacity)


# ä½¿ç”¨ä¾‹: ãƒãƒƒãƒ†ãƒªãƒ¼ææ–™ã®è‡ªå¾‹æœ€é©åŒ–
if __name__ == &quot;__main__&quot;:
    # æ¢ç´¢ç©ºé–“ã®å®šç¾©
    # [æ¸©åº¦(â„ƒ), å……é›»ãƒ¬ãƒ¼ãƒˆ(C), é›»è§£è³ªæ¿ƒåº¦(M)]
    bounds = np.array([
        [20.0, 60.0],   # æ¸©åº¦: 20-60â„ƒ
        [0.1, 1.0],     # å……é›»ãƒ¬ãƒ¼ãƒˆ: 0.1-1.0C
        [0.5, 2.0]      # æ¿ƒåº¦: 0.5-2.0M
    ])

    # ã‚¯ãƒ­ãƒ¼ã‚ºãƒ‰ãƒ«ãƒ¼ãƒ—ã‚·ã‚¹ãƒ†ãƒ æ§‹ç¯‰
    system = ClosedLoopSystem(
        experiment_function=battery_capacity_experiment,
        feature_dim=3,
        bounds=bounds
    )

    # åˆæœŸåŒ–ï¼ˆãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼‰
    system.initialize(n_init=5)

    # ã‚¯ãƒ­ãƒ¼ã‚ºãƒ‰ãƒ«ãƒ¼ãƒ—æœ€é©åŒ–å®Ÿè¡Œ
    system.run_closed_loop(
        n_iterations=10,
        target_performance=240.0  # ç›®æ¨™å®¹é‡
    )
</code></pre>
<p><strong>å‡ºåŠ›ä¾‹</strong>:</p>
<pre><code>======================================================================
Closed-Loop System Initialization
======================================================================
  Init 1/5: Parameters=[45.2 0.62 1.34], Performance=218.456
  Init 2/5: Parameters=[28.7 0.41 0.89], Performance=195.234
  Init 3/5: Parameters=[52.1 0.73 1.67], Performance=207.891
  Init 4/5: Parameters=[35.6 0.28 1.12], Performance=212.678
  Init 5/5: Parameters=[41.3 0.55 1.45], Performance=221.345

Initialization complete: 5 experiments

======================================================================
Starting Closed-Loop Optimization
======================================================================
Target iterations: 10
Target performance: 240.0

======================================================================
Iteration 1
======================================================================
[Step 1] Active Learning: Proposing next experiment
  Proposed parameters: [38.4 0.49 1.02]
  Acquisition value: 1.823

[Step 2] Robot: Executing experiment
  [Robot] Preparing experiment with parameters: [38.4 0.49 1.02]
  [Sensor] Measured performance: 228.712

[Step 3] Database: Storing results
  Total experiments: 6

[Step 4] Machine Learning: Updating model
  Model updated with new data

[Step 5] Evaluation:
  Current best performance: 228.712
  Best parameters: [38.4 0.49 1.02]

======================================================================
Iteration 2
======================================================================
[Step 1] Active Learning: Proposing next experiment
  Proposed parameters: [36.2 0.51 0.98]
  Acquisition value: 2.145

[Step 2] Robot: Executing experiment
  [Robot] Preparing experiment with parameters: [36.2 0.51 0.98]
  [Sensor] Measured performance: 241.234

[Step 3] Database: Storing results
  Total experiments: 7

[Step 4] Machine Learning: Updating model
  Model updated with new data

[Step 5] Evaluation:
  Current best performance: 241.234
  Best parameters: [36.2 0.51 0.98]

======================================================================
Target performance achieved in 2 iterations!
======================================================================

======================================================================
Closed-Loop Optimization Summary
======================================================================

Total experiments: 7
Total iterations: 2

Best Performance: 241.234
Best Parameters: [36.2 0.51 0.98]
Found at iteration: 2

Learning Curve (Best Performance Over Time):
  Experiment  1: 218.456
  Experiment  7: 241.234
</code></pre>
<hr />
<h2>4.4 å®Ÿä¸–ç•Œå¿œç”¨ã¨ã‚­ãƒ£ãƒªã‚¢ãƒ‘ã‚¹</h2>
<h3>ç”£æ¥­å¿œç”¨äº‹ä¾‹</h3>
<h4>Case Study 1: ãƒˆãƒ¨ã‚¿ - è§¦åª’é–‹ç™º</h4>
<p><strong>èª²é¡Œ</strong>: æ’ã‚¬ã‚¹æµ„åŒ–è§¦åª’ã®æœ€é©åŒ–
<strong>æ‰‹æ³•</strong>: Active Learning + é«˜ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆå®Ÿé¨“
<strong>çµæœ</strong>:
- å®Ÿé¨“å›æ•°80%å‰Šæ¸›ï¼ˆ1,000å› â†’ 200å›ï¼‰
- é–‹ç™ºæœŸé–“2å¹´ â†’ 6ãƒ¶æœˆ
- è§¦åª’æ€§èƒ½20%å‘ä¸Š</p>
<h4>Case Study 2: MIT - ãƒãƒƒãƒ†ãƒªãƒ¼ææ–™</h4>
<p><strong>èª²é¡Œ</strong>: Li-ioné›»æ± é›»è§£è³ªã®æ¢ç´¢
<strong>æ‰‹æ³•</strong>: Active Learning + ãƒ­ãƒœãƒƒãƒˆåˆæˆ
<strong>çµæœ</strong>:
- é–‹ç™ºé€Ÿåº¦10å€å‘ä¸Š
- å€™è£œææ–™10,000ç¨® â†’ 50å®Ÿé¨“ã§æœ€é©è§£
- ã‚¤ã‚ªãƒ³ä¼å°åº¦30%å‘ä¸Š</p>
<h4>Case Study 3: BASF - ãƒ—ãƒ­ã‚»ã‚¹æœ€é©åŒ–</h4>
<p><strong>èª²é¡Œ</strong>: åŒ–å­¦ãƒ—ãƒ­ã‚»ã‚¹æ¡ä»¶ã®æœ€é©åŒ–
<strong>æ‰‹æ³•</strong>: Active Learning + ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
<strong>çµæœ</strong>:
- å¹´é–“3,000ä¸‡ãƒ¦ãƒ¼ãƒ­ã®ã‚³ã‚¹ãƒˆå‰Šæ¸›
- ãƒ—ãƒ­ã‚»ã‚¹åŠ¹ç‡15%å‘ä¸Š
- ç’°å¢ƒè² è·20%å‰Šæ¸›</p>
<h4>Case Study 4: Citrine Informatics</h4>
<p><strong>ä¼æ¥­æ¦‚è¦</strong>: Active Learningå°‚é–€ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—
<strong>é¡§å®¢</strong>: 50ç¤¾ä»¥ä¸Šï¼ˆåŒ–å­¦ã€ææ–™ã€è£½è–¬ï¼‰
<strong>ã‚µãƒ¼ãƒ“ã‚¹</strong>:
- Active Learningãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ 
- ãƒ‡ãƒ¼ã‚¿åˆ†æã‚³ãƒ³ã‚µãƒ«ãƒ†ã‚£ãƒ³ã‚°
- è‡ªå‹•å®Ÿé¨“ã‚·ã‚¹ãƒ†ãƒ çµ±åˆ</p>
<h4>Case Study 5: Berkeley Lab - A-Lab</h4>
<p><strong>ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ</strong>: ç„¡äººææ–™åˆæˆãƒ©ãƒœ
<strong>å®Ÿç¸¾</strong>:
- 17æ—¥é–“ã§41ç¨®é¡ã®æ–°ææ–™åˆæˆ
- 24æ™‚é–“365æ—¥ç¨¼åƒ
- Active Learningã§æ¬¡ã®åˆæˆå€™è£œã‚’è‡ªå‹•ææ¡ˆ</p>
<h3>ã‚­ãƒ£ãƒªã‚¢ãƒ‘ã‚¹</h3>
<p><strong>Active Learning Engineer</strong>
- å¹´å: 800ä¸‡ã€œ1,500ä¸‡å††
- å¿…è¦ã‚¹ã‚­ãƒ«: Pythonã€æ©Ÿæ¢°å­¦ç¿’ã€ææ–™ç§‘å­¦
- ä¸»ãªé›‡ç”¨ä¸»: ç´ æãƒ¡ãƒ¼ã‚«ãƒ¼ã€è£½è–¬ã€åŒ–å­¦</p>
<p><strong>Research Scientistï¼ˆALå°‚é–€ï¼‰</strong>
- å¹´å: 1,000ä¸‡ã€œ2,000ä¸‡å††
- å¿…è¦ã‚¹ã‚­ãƒ«: åšå£«å·ã€è«–æ–‡å®Ÿç¸¾ã€ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°
- ä¸»ãªé›‡ç”¨ä¸»: å¤§å­¦ã€ç ”ç©¶æ©Ÿé–¢ã€R&amp;Déƒ¨é–€</p>
<p><strong>Automation Engineer</strong>
- å¹´å: 900ä¸‡ã€œ1,800ä¸‡å††
- å¿…è¦ã‚¹ã‚­ãƒ«: ãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ã€ALã€ã‚·ã‚¹ãƒ†ãƒ çµ±åˆ
- ä¸»ãªé›‡ç”¨ä¸»: è‡ªå‹•åŒ–ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—ã€å¤§æ‰‹ãƒ¡ãƒ¼ã‚«ãƒ¼</p>
<hr />
<h2>æœ¬ç« ã®ã¾ã¨ã‚</h2>
<h3>å­¦ã‚“ã ã“ã¨</h3>
<ol>
<li>
<p><strong>ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã¨ã®çµ±åˆ</strong>
   - BoTorchã«ã‚ˆã‚‹å®Ÿè£…
   - é€£ç¶šç©ºé–“ vs é›¢æ•£ç©ºé–“</p>
</li>
<li>
<p><strong>é«˜ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆè¨ˆç®—</strong>
   - DFTè¨ˆç®—ã®åŠ¹ç‡åŒ–
   - Batch Active Learning</p>
</li>
<li>
<p><strong>å®Ÿé¨“ãƒ­ãƒœãƒƒãƒˆé€£æº</strong>
   - ã‚¯ãƒ­ãƒ¼ã‚ºãƒ‰ãƒ«ãƒ¼ãƒ—æœ€é©åŒ–
   - è‡ªå¾‹å®Ÿé¨“ã‚·ã‚¹ãƒ†ãƒ </p>
</li>
<li>
<p><strong>ç”£æ¥­å¿œç”¨</strong>
   - 5ã¤ã®æˆåŠŸäº‹ä¾‹
   - å®Ÿé¨“å›æ•°50-80%å‰Šæ¸›
   - é–‹ç™ºæœŸé–“å¤§å¹…çŸ­ç¸®</p>
</li>
<li>
<p><strong>ã‚­ãƒ£ãƒªã‚¢æ©Ÿä¼š</strong>
   - AL Engineerã€Research Scientist
   - å¹´å800ä¸‡ã€œ2,000ä¸‡å††
   - éœ€è¦æ€¥å¢—ä¸­</p>
</li>
</ol>
<h3>ã‚·ãƒªãƒ¼ã‚ºå®Œäº†</h3>
<p>ãŠã‚ã§ã¨ã†ã”ã–ã„ã¾ã™ï¼Active Learningå…¥é–€ã‚·ãƒªãƒ¼ã‚ºã‚’å®Œäº†ã—ã¾ã—ãŸã€‚</p>
<p><strong>æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—</strong>:
1. âœ… ç‹¬è‡ªãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«æŒ‘æˆ¦
2. âœ… GitHubã«ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªä½œæˆ
3. âœ… ãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹å®Ÿé¨“è‡ªå‹•åŒ–å…¥é–€ã¸
4. âœ… ç ”ç©¶ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã«å‚åŠ 
5. âœ… ç”£æ¥­ç•Œã§ã®ã‚­ãƒ£ãƒªã‚¢ã‚’æ¤œè¨</p>
<p><strong><a href="./index.html">ã‚·ãƒªãƒ¼ã‚ºç›®æ¬¡ã«æˆ»ã‚‹</a></strong></p>
<hr />
<h2>æ¼”ç¿’å•é¡Œ</h2>
<p>ï¼ˆçœç•¥ï¼šæ¼”ç¿’å•é¡Œã®è©³ç´°å®Ÿè£…ï¼‰</p>
<hr />
<h2>å‚è€ƒæ–‡çŒ®</h2>
<ol>
<li>
<p>Kusne, A. G. et al. (2020). "On-the-fly closed-loop materials discovery via Bayesian active learning." <em>Nature Communications</em>, 11(1), 5966.</p>
</li>
<li>
<p>MacLeod, B. P. et al. (2020). "Self-driving laboratory for accelerated discovery of thin-film materials." <em>Science Advances</em>, 6(20), eaaz8867.</p>
</li>
<li>
<p>Stein, H. S. et al. (2019). "Progress and prospects for accelerating materials science with automated and autonomous workflows." <em>Chemical Science</em>, 10(42), 9640-9649.</p>
</li>
</ol>
<hr />
<h2>ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³</h2>
<h3>å‰ã®ç« </h3>
<p><strong><a href="./chapter-3.html">â† ç¬¬3ç« ï¼šç²å¾—é–¢æ•°è¨­è¨ˆ</a></strong></p>
<h3>ã‚·ãƒªãƒ¼ã‚ºç›®æ¬¡</h3>
<p><strong><a href="./index.html">â† ã‚·ãƒªãƒ¼ã‚ºç›®æ¬¡ã«æˆ»ã‚‹</a></strong></p>
<hr />
<p><strong>ã‚·ãƒªãƒ¼ã‚ºå®Œäº†ï¼æ¬¡ã¯ãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹å®Ÿé¨“è‡ªå‹•åŒ–ã¸ï¼</strong></p><div class="navigation">
    <a href="chapter-3.html" class="nav-button">â† å‰ã®ç« </a>
    <a href="index.html" class="nav-button">ã‚·ãƒªãƒ¼ã‚ºç›®æ¬¡ã«æˆ»ã‚‹</a>
</div>
    </main>

    
    <section class="disclaimer">
        <h3>å…è²¬äº‹é …</h3>
        <ul>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯æ•™è‚²ãƒ»ç ”ç©¶ãƒ»æƒ…å ±æä¾›ã®ã¿ã‚’ç›®çš„ã¨ã—ã¦ãŠã‚Šã€å°‚é–€çš„ãªåŠ©è¨€(æ³•å¾‹ãƒ»ä¼šè¨ˆãƒ»æŠ€è¡“çš„ä¿è¨¼ãªã©)ã‚’æä¾›ã™ã‚‹ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŠã‚ˆã³ä»˜éšã™ã‚‹ã‚³ãƒ¼ãƒ‰ä¾‹ã¯ã€Œç¾çŠ¶æœ‰å§¿(AS IS)ã€ã§æä¾›ã•ã‚Œã€æ˜ç¤ºã¾ãŸã¯é»™ç¤ºã‚’å•ã‚ãšã€å•†å“æ€§ã€ç‰¹å®šç›®çš„é©åˆæ€§ã€æ¨©åˆ©éä¾µå®³ã€æ­£ç¢ºæ€§ãƒ»å®Œå…¨æ€§ã€å‹•ä½œãƒ»å®‰å…¨æ€§ç­‰ã„ã‹ãªã‚‹ä¿è¨¼ã‚‚ã—ã¾ã›ã‚“ã€‚</li>
            <li>å¤–éƒ¨ãƒªãƒ³ã‚¯ã€ç¬¬ä¸‰è€…ãŒæä¾›ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ»ãƒ„ãƒ¼ãƒ«ãƒ»ãƒ©ã‚¤ãƒ–ãƒ©ãƒªç­‰ã®å†…å®¹ãƒ»å¯ç”¨æ€§ãƒ»å®‰å…¨æ€§ã«ã¤ã„ã¦ã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯ä¸€åˆ‡ã®è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®åˆ©ç”¨ãƒ»å®Ÿè¡Œãƒ»è§£é‡ˆã«ã‚ˆã‚Šç›´æ¥çš„ãƒ»é–“æ¥çš„ãƒ»ä»˜éšçš„ãƒ»ç‰¹åˆ¥ãƒ»çµæœçš„ãƒ»æ‡²ç½°çš„æå®³ãŒç”Ÿã˜ãŸå ´åˆã§ã‚‚ã€é©ç”¨æ³•ã§è¨±å®¹ã•ã‚Œã‚‹æœ€å¤§é™ã®ç¯„å›²ã§ã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å†…å®¹ã¯ã€äºˆå‘Šãªãå¤‰æ›´ãƒ»æ›´æ–°ãƒ»æä¾›åœæ­¢ã•ã‚Œã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®è‘—ä½œæ¨©ãƒ»ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯æ˜è¨˜ã•ã‚ŒãŸæ¡ä»¶(ä¾‹: CC BY 4.0)ã«å¾“ã„ã¾ã™ã€‚å½“è©²ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯é€šå¸¸ã€ç„¡ä¿è¨¼æ¡é …ã‚’å«ã¿ã¾ã™ã€‚</li>
        </ul>
    </section>

<footer>
        <p><strong>ä½œæˆè€…</strong>: AI Terakoya Content Team</p>
        <p><strong>ãƒãƒ¼ã‚¸ãƒ§ãƒ³</strong>: 1.0 | <strong>ä½œæˆæ—¥</strong>: 2025-10-18</p>
        <p><strong>ãƒ©ã‚¤ã‚»ãƒ³ã‚¹</strong>: Creative Commons BY 4.0</p>
        <p>Â© 2025 AI Terakoya. All rights reserved.</p>
    </footer>
</body>
</html>
