<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ç¬¬3ç« ï¼šPythonã§ä½“é¨“ã™ã‚‹MI - å®Ÿè·µçš„ãªææ–™ç‰¹æ€§äºˆæ¸¬ - AI Terakoya</title>

    <style>
        :root {
            --color-primary: #2c3e50;
            --color-primary-dark: #1a252f;
            --color-accent: #7b2cbf;
            --color-accent-light: #9d4edd;
            --color-text: #2d3748;
            --color-text-light: #4a5568;
            --color-bg: #ffffff;
            --color-bg-alt: #f7fafc;
            --color-border: #e2e8f0;
            --color-code-bg: #f8f9fa;
            --color-link: #3182ce;
            --color-link-hover: #2c5aa0;

            --spacing-xs: 0.5rem;
            --spacing-sm: 1rem;
            --spacing-md: 1.5rem;
            --spacing-lg: 2rem;
            --spacing-xl: 3rem;

            --font-body: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            --font-mono: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;

            --border-radius: 8px;
            --box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: var(--font-body);
            line-height: 1.7;
            color: var(--color-text);
            background-color: var(--color-bg);
            font-size: 16px;
        }

        header {
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            padding: var(--spacing-xl) var(--spacing-md);
            margin-bottom: var(--spacing-xl);
            box-shadow: var(--box-shadow);
        }

        .header-content {
            max-width: 900px;
            margin: 0 auto;
        }

        h1 {
            font-size: 2rem;
            font-weight: 700;
            margin-bottom: var(--spacing-sm);
            line-height: 1.2;
        }

        .subtitle {
            font-size: 1.1rem;
            opacity: 0.95;
            font-weight: 400;
            margin-bottom: var(--spacing-md);
        }

        .meta {
            display: flex;
            flex-wrap: wrap;
            gap: var(--spacing-md);
            font-size: 0.9rem;
            opacity: 0.9;
        }

        .meta-item {
            display: flex;
            align-items: center;
            gap: 0.3rem;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 0 var(--spacing-md) var(--spacing-xl);
        }

        h2 {
            font-size: 1.75rem;
            color: var(--color-primary);
            margin-top: var(--spacing-xl);
            margin-bottom: var(--spacing-md);
            padding-bottom: var(--spacing-xs);
            border-bottom: 3px solid var(--color-accent);
        }

        h3 {
            font-size: 1.4rem;
            color: var(--color-primary);
            margin-top: var(--spacing-lg);
            margin-bottom: var(--spacing-sm);
        }

        h4 {
            font-size: 1.1rem;
            color: var(--color-primary-dark);
            margin-top: var(--spacing-md);
            margin-bottom: var(--spacing-sm);
        }

        p {
            margin-bottom: var(--spacing-md);
            color: var(--color-text);
        }

        a {
            color: var(--color-link);
            text-decoration: none;
            transition: color 0.2s;
        }

        a:hover {
            color: var(--color-link-hover);
            text-decoration: underline;
        }

        ul, ol {
            margin-left: var(--spacing-lg);
            margin-bottom: var(--spacing-md);
        }

        li {
            margin-bottom: var(--spacing-xs);
            color: var(--color-text);
        }

        pre {
            background-color: var(--color-code-bg);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            overflow-x: auto;
            margin-bottom: var(--spacing-md);
            font-family: var(--font-mono);
            font-size: 0.9rem;
            line-height: 1.5;
        }

        code {
            font-family: var(--font-mono);
            font-size: 0.9em;
            background-color: var(--color-code-bg);
            padding: 0.2em 0.4em;
            border-radius: 3px;
        }

        pre code {
            background-color: transparent;
            padding: 0;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: var(--spacing-md);
            font-size: 0.95rem;
        }

        th, td {
            border: 1px solid var(--color-border);
            padding: var(--spacing-sm);
            text-align: left;
        }

        th {
            background-color: var(--color-bg-alt);
            font-weight: 600;
            color: var(--color-primary);
        }

        blockquote {
            border-left: 4px solid var(--color-accent);
            padding-left: var(--spacing-md);
            margin: var(--spacing-md) 0;
            color: var(--color-text-light);
            font-style: italic;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        .mermaid {
            text-align: center;
            margin: var(--spacing-lg) 0;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        details {
            background-color: var(--color-bg-alt);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            margin-bottom: var(--spacing-md);
        }

        summary {
            cursor: pointer;
            font-weight: 600;
            color: var(--color-primary);
            user-select: none;
            padding: var(--spacing-xs);
            margin: calc(-1 * var(--spacing-md));
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        summary:hover {
            background-color: rgba(123, 44, 191, 0.1);
        }

        details[open] summary {
            margin-bottom: var(--spacing-md);
            border-bottom: 1px solid var(--color-border);
        }

        .learning-objectives {
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
            padding: var(--spacing-lg);
            border-radius: var(--border-radius);
            border-left: 4px solid var(--color-accent);
            margin-bottom: var(--spacing-xl);
        }

        .learning-objectives h2 {
            margin-top: 0;
            border-bottom: none;
        }

        .navigation {
            display: flex;
            justify-content: space-between;
            gap: var(--spacing-md);
            margin: var(--spacing-xl) 0;
            padding-top: var(--spacing-lg);
            border-top: 2px solid var(--color-border);
        }

        .nav-button {
            flex: 1;
            padding: var(--spacing-md);
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            border-radius: var(--border-radius);
            text-align: center;
            font-weight: 600;
            transition: transform 0.2s, box-shadow 0.2s;
            box-shadow: var(--box-shadow);
        }

        .nav-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
            text-decoration: none;
        }

        footer {
            margin-top: var(--spacing-xl);
            padding: var(--spacing-lg) var(--spacing-md);
            background-color: var(--color-bg-alt);
            border-top: 1px solid var(--color-border);
            text-align: center;
            font-size: 0.9rem;
            color: var(--color-text-light);
        }

        @media (max-width: 768px) {
            h1 {
                font-size: 1.5rem;
            }

            h2 {
                font-size: 1.4rem;
            }

            h3 {
                font-size: 1.2rem;
            }

            .meta {
                font-size: 0.85rem;
            }

            .navigation {
                flex-direction: column;
            }

            table {
                font-size: 0.85rem;
            }

            th, td {
                padding: var(--spacing-xs);
            }
        }
    </style>

    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
        mermaid.initialize({ startOnLoad: true, theme: 'default' });
    </script>

    <!-- MathJax for LaTeX equation rendering -->
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\(', '\)']],
                displayMath: [['$$', '$$'], ['\[', '\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
                ignoreHtmlClass: 'mermaid'
            }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" async></script>
</head>
<body>
    <header>
        <div class="header-content">
            <h1>ç¬¬3ç« ï¼šPythonã§ä½“é¨“ã™ã‚‹MI - å®Ÿè·µçš„ãªææ–™ç‰¹æ€§äºˆæ¸¬</h1>
            <p class="subtitle">æ©Ÿæ¢°å­¦ç¿’ã«ã‚ˆã‚‹ææ–™é–‹ç™ºã®å®Ÿè£…ã¨ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹</p>
            <div class="meta">
                <span class="meta-item">ğŸ“– èª­äº†æ™‚é–“: 20-25åˆ†</span>
                <span class="meta-item">ğŸ“Š é›£æ˜“åº¦: ä¸­ç´š</span>
                <span class="meta-item">ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹: 0å€‹</span>
                <span class="meta-item">ğŸ“ æ¼”ç¿’å•é¡Œ: 0å•</span>
            </div>
        </div>
    </header>

    <main class="container">
<h1>ç¬¬3ç« ï¼šPythonã§ä½“é¨“ã™ã‚‹MI - å®Ÿè·µçš„ãªææ–™ç‰¹æ€§äºˆæ¸¬</h1>
<h2>å­¦ç¿’ç›®æ¨™</h2>
<p>ã“ã®è¨˜äº‹ã‚’èª­ã‚€ã“ã¨ã§ã€ä»¥ä¸‹ã‚’ç¿’å¾—ã§ãã¾ã™ï¼š
- Pythonç’°å¢ƒã‚’æ§‹ç¯‰ã—ã€MIç”¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã§ãã‚‹
- 5ç¨®é¡ä»¥ä¸Šã®æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’å®Ÿè£…ã—ã€æ€§èƒ½ã‚’æ¯”è¼ƒã§ãã‚‹
- ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å®Ÿè¡Œã§ãã‚‹
- ææ–™ç‰¹æ€§äºˆæ¸¬ã®å®Ÿè·µçš„ãªãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’å®Œæˆã§ãã‚‹
- ã‚¨ãƒ©ãƒ¼ã‚’è‡ªåŠ›ã§ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã§ãã‚‹</p>
<hr />
<h2>1. ç’°å¢ƒæ§‹ç¯‰ï¼š3ã¤ã®é¸æŠè‚¢</h2>
<p>ææ–™ç‰¹æ€§äºˆæ¸¬ã®Pythonç’°å¢ƒã‚’æ§‹ç¯‰ã™ã‚‹æ–¹æ³•ã¯ã€çŠ¶æ³ã«å¿œã˜ã¦3ã¤ã‚ã‚Šã¾ã™ã€‚</p>
<h3>1.1 Option 1: Anacondaï¼ˆæ¨å¥¨åˆå¿ƒè€…ï¼‰</h3>
<p><strong>ç‰¹å¾´ï¼š</strong>
- ç§‘å­¦è¨ˆç®—ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒæœ€åˆã‹ã‚‰æƒã£ã¦ã„ã‚‹
- ç’°å¢ƒç®¡ç†ãŒç°¡å˜ï¼ˆGUIåˆ©ç”¨å¯èƒ½ï¼‰
- Windows/Mac/Linuxå¯¾å¿œ</p>
<p><strong>ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ‰‹é †ï¼š</strong></p>
<pre><code class="language-bash"># 1. Anacondaã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
# å…¬å¼ã‚µã‚¤ãƒˆ: https://www.anaconda.com/download
# Python 3.11ä»¥ä¸Šã‚’é¸æŠ

# 2. ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å¾Œã€Anaconda Promptã‚’èµ·å‹•

# 3. ä»®æƒ³ç’°å¢ƒã‚’ä½œæˆï¼ˆMIå°‚ç”¨ç’°å¢ƒï¼‰
conda create -n mi-env python=3.11 numpy pandas matplotlib scikit-learn jupyter

# 4. ç’°å¢ƒã‚’æœ‰åŠ¹åŒ–
conda activate mi-env

# 5. å‹•ä½œç¢ºèª
python --version
# å‡ºåŠ›: Python 3.11.x
</code></pre>
<p><strong>ç”»é¢ã‚¤ãƒ¡ãƒ¼ã‚¸ï¼š</strong></p>
<pre><code>(base) $ conda create -n mi-env python=3.11
Collecting package metadata: done
Solving environment: done
...
Proceed ([y]/n)? y

# æˆåŠŸã™ã‚‹ã¨ä»¥ä¸‹ãŒè¡¨ç¤ºã•ã‚Œã‚‹
# To activate this environment, use
#   $ conda activate mi-env
</code></pre>
<p><strong>Anacondaã®åˆ©ç‚¹ï¼š</strong>
- âœ… NumPyã€SciPyãªã©ãŒæœ€åˆã‹ã‚‰å«ã¾ã‚Œã‚‹
- âœ… ä¾å­˜é–¢ä¿‚ã®å•é¡ŒãŒå°‘ãªã„
- âœ… Anaconda Navigatorã§è¦–è¦šçš„ã«ç®¡ç†å¯èƒ½
- âŒ ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãŒå¤§ãã„ï¼ˆ3GBä»¥ä¸Šï¼‰</p>
<h3>1.2 Option 2: venvï¼ˆPythonæ¨™æº–ï¼‰</h3>
<p><strong>ç‰¹å¾´ï¼š</strong>
- Pythonæ¨™æº–ãƒ„ãƒ¼ãƒ«ï¼ˆè¿½åŠ ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ä¸è¦ï¼‰
- è»½é‡ï¼ˆå¿…è¦ãªã‚‚ã®ã ã‘ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼‰
- ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã”ã¨ã«ç’°å¢ƒã‚’åˆ†é›¢</p>
<p><strong>ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ‰‹é †ï¼š</strong></p>
<pre><code class="language-bash"># 1. Python 3.11ä»¥ä¸ŠãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
python3 --version
# å‡ºåŠ›: Python 3.11.x ä»¥ä¸ŠãŒå¿…è¦

# 2. ä»®æƒ³ç’°å¢ƒã‚’ä½œæˆ
python3 -m venv mi-env

# 3. ç’°å¢ƒã‚’æœ‰åŠ¹åŒ–
# macOS/Linux:
source mi-env/bin/activate

# Windows (PowerShell):
mi-env\Scripts\Activate.ps1

# Windows (Command Prompt):
mi-env\Scripts\activate.bat

# 4. pipã‚’ã‚¢ãƒƒãƒ—ã‚°ãƒ¬ãƒ¼ãƒ‰
pip install --upgrade pip

# 5. å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install numpy pandas matplotlib scikit-learn jupyter

# 6. ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ç¢ºèª
pip list
</code></pre>
<p><strong>venvã®åˆ©ç‚¹ï¼š</strong>
- âœ… è»½é‡ï¼ˆæ•°åMBï¼‰
- âœ… Pythonæ¨™æº–ãƒ„ãƒ¼ãƒ«ï¼ˆè¿½åŠ ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ä¸è¦ï¼‰
- âœ… ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã”ã¨ã«ç‹¬ç«‹
- âŒ ä¾å­˜é–¢ä¿‚ã‚’æ‰‹å‹•ã§è§£æ±ºã™ã‚‹å¿…è¦ãŒã‚ã‚‹</p>
<h3>1.3 Option 3: Google Colabï¼ˆã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ä¸è¦ï¼‰</h3>
<p><strong>ç‰¹å¾´ï¼š</strong>
- ãƒ–ãƒ©ã‚¦ã‚¶ã ã‘ã§å®Ÿè¡Œå¯èƒ½
- ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ä¸è¦ï¼ˆã‚¯ãƒ©ã‚¦ãƒ‰å®Ÿè¡Œï¼‰
- GPU/TPUãŒç„¡æ–™ã§ä½¿ãˆã‚‹</p>
<p><strong>ä½¿ç”¨æ–¹æ³•ï¼š</strong></p>
<pre><code>1. Google Colabã«ã‚¢ã‚¯ã‚»ã‚¹: https://colab.research.google.com
2. æ–°ã—ã„ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã‚’ä½œæˆ
3. ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œï¼ˆå¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã¯è‡ªå‹•ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¸ˆã¿ï¼‰
</code></pre>
<pre><code class="language-python"># Google Colabã§ã¯æœ€åˆã‹ã‚‰ä»¥ä¸‹ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¸ˆã¿
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor

print(&quot;ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆãŒæˆåŠŸã—ã¾ã—ãŸï¼&quot;)
print(f&quot;NumPy version: {np.__version__}&quot;)
print(f&quot;Pandas version: {pd.__version__}&quot;)
</code></pre>
<p><strong>Google Colabã®åˆ©ç‚¹ï¼š</strong>
- âœ… ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ä¸è¦ï¼ˆã™ãé–‹å§‹å¯èƒ½ï¼‰
- âœ… ç„¡æ–™ã§GPUåˆ©ç”¨å¯èƒ½
- âœ… Google Driveã¨é€£æºï¼ˆãƒ‡ãƒ¼ã‚¿ä¿å­˜ãŒç°¡å˜ï¼‰
- âŒ ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆæ¥ç¶šãŒå¿…é ˆ
- âŒ ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒ12æ™‚é–“ã§ãƒªã‚»ãƒƒãƒˆã•ã‚Œã‚‹</p>
<h3>1.4 ç’°å¢ƒé¸æŠã‚¬ã‚¤ãƒ‰</h3>
<table>
<thead>
<tr>
<th>çŠ¶æ³</th>
<th>æ¨å¥¨ã‚ªãƒ—ã‚·ãƒ§ãƒ³</th>
<th>ç†ç”±</th>
</tr>
</thead>
<tbody>
<tr>
<td>åˆã‚ã¦ã®Pythonç’°å¢ƒ</td>
<td>Anaconda</td>
<td>ç’°å¢ƒæ§‹ç¯‰ãŒç°¡å˜ã€ãƒˆãƒ©ãƒ–ãƒ«ãŒå°‘ãªã„</td>
</tr>
<tr>
<td>æ—¢ã«Pythonç’°å¢ƒãŒã‚ã‚‹</td>
<td>venv</td>
<td>è»½é‡ã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã”ã¨ã«ç‹¬ç«‹</td>
</tr>
<tr>
<td>ä»Šã™ãè©¦ã—ãŸã„</td>
<td>Google Colab</td>
<td>ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ä¸è¦ã€å³åº§ã«é–‹å§‹å¯èƒ½</td>
</tr>
<tr>
<td>GPUè¨ˆç®—ãŒå¿…è¦</td>
<td>Google Colab or Anaconda</td>
<td>ç„¡æ–™GPUï¼ˆColabï¼‰or ãƒ­ãƒ¼ã‚«ãƒ«GPUï¼ˆAnacondaï¼‰</td>
</tr>
<tr>
<td>ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ç’°å¢ƒ</td>
<td>Anaconda or venv</td>
<td>ãƒ­ãƒ¼ã‚«ãƒ«å®Ÿè¡Œã€ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆä¸è¦</td>
</tr>
</tbody>
</table>
<h3>1.5 ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¤œè¨¼ã¨ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°</h3>
<p><strong>æ¤œè¨¼ã‚³ãƒãƒ³ãƒ‰ï¼š</strong></p>
<pre><code class="language-python"># ã™ã¹ã¦ã®ç’°å¢ƒã§å®Ÿè¡Œå¯èƒ½
import sys
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import sklearn

print(&quot;===== ç’°å¢ƒç¢ºèª =====&quot;)
print(f&quot;Python version: {sys.version}&quot;)
print(f&quot;NumPy version: {np.__version__}&quot;)
print(f&quot;Pandas version: {pd.__version__}&quot;)
print(f&quot;Matplotlib version: {plt.matplotlib.__version__}&quot;)
print(f&quot;scikit-learn version: {sklearn.__version__}&quot;)
print(&quot;\nâœ… ã™ã¹ã¦ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒæ­£å¸¸ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã™ï¼&quot;)
</code></pre>
<p><strong>æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›ï¼š</strong></p>
<pre><code>===== ç’°å¢ƒç¢ºèª =====
Python version: 3.11.x
NumPy version: 1.24.x
Pandas version: 2.0.x
Matplotlib version: 3.7.x
scikit-learn version: 1.3.x

âœ… ã™ã¹ã¦ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒæ­£å¸¸ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã™ï¼
</code></pre>
<p><strong>ã‚ˆãã‚ã‚‹ã‚¨ãƒ©ãƒ¼ã¨è§£æ±ºæ–¹æ³•ï¼š</strong></p>
<table>
<thead>
<tr>
<th>ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸</th>
<th>åŸå› </th>
<th>è§£æ±ºæ–¹æ³•</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>ModuleNotFoundError: No module named 'numpy'</code></td>
<td>ãƒ©ã‚¤ãƒ–ãƒ©ãƒªæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«</td>
<td><code>pip install numpy</code> ã‚’å®Ÿè¡Œ</td>
</tr>
<tr>
<td><code>pip is not recognized</code></td>
<td>pipã®PATHãŒé€šã£ã¦ã„ãªã„</td>
<td>Pythonå†ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ« or PATHè¨­å®š</td>
</tr>
<tr>
<td><code>SSL: CERTIFICATE_VERIFY_FAILED</code></td>
<td>SSLè¨¼æ˜æ›¸ã‚¨ãƒ©ãƒ¼</td>
<td><code>pip install --trusted-host pypi.org --trusted-host files.pythonhosted.org &lt;package&gt;</code></td>
</tr>
<tr>
<td><code>MemoryError</code></td>
<td>ãƒ¡ãƒ¢ãƒªä¸è¶³</td>
<td>ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã‚’å‰Šæ¸› or Google Colabåˆ©ç”¨</td>
</tr>
<tr>
<td><code>ImportError: DLL load failed</code> (Windows)</td>
<td>C++å†é ’å¸ƒå¯èƒ½ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ä¸è¶³</td>
<td>Microsoft Visual C++ Redistributableã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«</td>
</tr>
</tbody>
</table>
<hr />
<h2>2. ã‚³ãƒ¼ãƒ‰ä¾‹ã‚·ãƒªãƒ¼ã‚ºï¼š6ã¤ã®æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«</h2>
<p>å®Ÿéš›ã«6ã¤ã®ç•°ãªã‚‹æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’å®Ÿè£…ã—ã€æ€§èƒ½ã‚’æ¯”è¼ƒã—ã¾ã™ã€‚</p>
<h3>2.1 Example 1: ç·šå½¢å›å¸°ï¼ˆBaselineï¼‰</h3>
<p><strong>æ¦‚è¦ï¼š</strong>
æœ€ã‚‚ã‚·ãƒ³ãƒ—ãƒ«ãªæ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã€‚ç‰¹å¾´é‡ã¨ç›®çš„å¤‰æ•°ã®ç·šå½¢é–¢ä¿‚ã‚’å­¦ç¿’ã—ã¾ã™ã€‚</p>
<pre><code class="language-python">import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error, r2_score
import time

# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ä½œæˆï¼ˆåˆé‡‘ã®çµ„æˆã¨èç‚¹ï¼‰
# æ³¨æ„: å®Ÿéš›ã®ç ”ç©¶ã§ã¯Materials Projectãªã©ã®å®Ÿãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨
np.random.seed(42)
n_samples = 100

# å…ƒç´ A, Bã®æ¯”ç‡ï¼ˆåˆè¨ˆ1.0ï¼‰
element_A = np.random.uniform(0.1, 0.9, n_samples)
element_B = 1.0 - element_A

# èç‚¹ã®ãƒ¢ãƒ‡ãƒ«ï¼ˆç·šå½¢é–¢ä¿‚ + ãƒã‚¤ã‚ºï¼‰
# èç‚¹ = 1000 + 400 * element_A + ãƒã‚¤ã‚º
melting_point = 1000 + 400 * element_A + np.random.normal(0, 20, n_samples)

# DataFrameã«æ ¼ç´
data = pd.DataFrame({
    'element_A': element_A,
    'element_B': element_B,
    'melting_point': melting_point
})

print(&quot;===== ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª =====&quot;)
print(data.head())
print(f&quot;\nãƒ‡ãƒ¼ã‚¿æ•°: {len(data)}ä»¶&quot;)
print(f&quot;èç‚¹ã®ç¯„å›²: {melting_point.min():.1f} - {melting_point.max():.1f} K&quot;)

# ç‰¹å¾´é‡ã¨ç›®çš„å¤‰æ•°ã®åˆ†å‰²
X = data[['element_A', 'element_B']]  # å…¥åŠ›ï¼šçµ„æˆ
y = data['melting_point']  # å‡ºåŠ›ï¼šèç‚¹

# è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«åˆ†å‰²ï¼ˆ80% vs 20%ï¼‰
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# ãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰ã¨è¨“ç·´
start_time = time.time()
model_lr = LinearRegression()
model_lr.fit(X_train, y_train)
training_time = time.time() - start_time

# äºˆæ¸¬
y_pred = model_lr.predict(X_test)

# è©•ä¾¡
mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(&quot;\n===== ç·šå½¢å›å¸°ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ =====&quot;)
print(f&quot;è¨“ç·´æ™‚é–“: {training_time:.4f} ç§’&quot;)
print(f&quot;å¹³å‡çµ¶å¯¾èª¤å·® (MAE): {mae:.2f} K&quot;)
print(f&quot;æ±ºå®šä¿‚æ•° (RÂ²): {r2:.4f}&quot;)

# å­¦ç¿’ã—ãŸä¿‚æ•°ã‚’è¡¨ç¤º
print(&quot;\n===== å­¦ç¿’ã—ãŸä¿‚æ•° =====&quot;)
print(f&quot;åˆ‡ç‰‡: {model_lr.intercept_:.2f}&quot;)
print(f&quot;element_A ã®ä¿‚æ•°: {model_lr.coef_[0]:.2f}&quot;)
print(f&quot;element_B ã®ä¿‚æ•°: {model_lr.coef_[1]:.2f}&quot;)

# å¯è¦–åŒ–
plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_pred, alpha=0.6, s=100, c='blue')
plt.plot([y_test.min(), y_test.max()],
         [y_test.min(), y_test.max()],
         'r--', lw=2, label='å®Œå…¨ãªäºˆæ¸¬')
plt.xlabel('å®Ÿæ¸¬å€¤ (K)', fontsize=12)
plt.ylabel('äºˆæ¸¬å€¤ (K)', fontsize=12)
plt.title('ç·šå½¢å›å¸°ï¼šèç‚¹ã®äºˆæ¸¬çµæœ', fontsize=14)
plt.legend()
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()
</code></pre>
<p><strong>ã‚³ãƒ¼ãƒ‰è§£èª¬ï¼š</strong>
1. <strong>ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ</strong>ï¼šelement_Aæ¯”ç‡ã‹ã‚‰èç‚¹ã‚’è¨ˆç®—ï¼ˆç·šå½¢é–¢ä¿‚ + ãƒã‚¤ã‚ºï¼‰
2. <strong>ãƒ‡ãƒ¼ã‚¿åˆ†å‰²</strong>ï¼š80%è¨“ç·´ã€20%ãƒ†ã‚¹ãƒˆ
3. <strong>ãƒ¢ãƒ‡ãƒ«è¨“ç·´</strong>ï¼šLinearRegression()ã‚’ä½¿ç”¨
4. <strong>è©•ä¾¡</strong>ï¼šMAEï¼ˆèª¤å·®ã®å¹³å‡ï¼‰ã¨RÂ²ï¼ˆèª¬æ˜åŠ›ï¼‰ã‚’è¨ˆç®—
5. <strong>ä¿‚æ•°è¡¨ç¤º</strong>ï¼šå­¦ç¿’ã—ãŸç·šå½¢é–¢ä¿‚ã‚’ç¢ºèª</p>
<p><strong>æœŸå¾…ã•ã‚Œã‚‹çµæœï¼š</strong>
- MAE: 15-25 K
- RÂ²: 0.95ä»¥ä¸Šï¼ˆç·šå½¢ãƒ‡ãƒ¼ã‚¿ãªã®ã§é«˜ç²¾åº¦ï¼‰
- è¨“ç·´æ™‚é–“: 0.01ç§’æœªæº€</p>
<hr />
<h3>2.2 Example 2: ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆï¼ˆå¼·åŒ–ç‰ˆï¼‰</h3>
<p><strong>æ¦‚è¦ï¼š</strong>
è¤‡æ•°ã®æ±ºå®šæœ¨ã‚’çµ„ã¿åˆã‚ã›ãŸå¼·åŠ›ãªãƒ¢ãƒ‡ãƒ«ã€‚éç·šå½¢é–¢ä¿‚ã‚‚å­¦ç¿’å¯èƒ½ã€‚</p>
<pre><code class="language-python">from sklearn.ensemble import RandomForestRegressor

# ã‚ˆã‚Šè¤‡é›‘ãªéç·šå½¢ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
np.random.seed(42)
n_samples = 200

element_A = np.random.uniform(0.1, 0.9, n_samples)
element_B = 1.0 - element_A

# éç·šå½¢ãªèç‚¹ãƒ¢ãƒ‡ãƒ«ï¼ˆäºŒæ¬¡é–¢æ•° + ç›¸äº’ä½œç”¨é …ï¼‰
melting_point = (
    1000
    + 400 * element_A
    - 300 * element_A**2  # äºŒæ¬¡é …
    + 200 * element_A * element_B  # ç›¸äº’ä½œç”¨é …
    + np.random.normal(0, 15, n_samples)
)

data_rf = pd.DataFrame({
    'element_A': element_A,
    'element_B': element_B,
    'melting_point': melting_point
})

X_rf = data_rf[['element_A', 'element_B']]
y_rf = data_rf['melting_point']

X_train_rf, X_test_rf, y_train_rf, y_test_rf = train_test_split(
    X_rf, y_rf, test_size=0.2, random_state=42
)

# ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰
start_time = time.time()
model_rf = RandomForestRegressor(
    n_estimators=100,      # æ±ºå®šæœ¨ã®æ•°ï¼ˆå¤šã„ã»ã©ç²¾åº¦â†‘ã€è¨ˆç®—æ™‚é–“â†‘ï¼‰
    max_depth=10,          # æœ¨ã®æœ€å¤§æ·±ã•ï¼ˆæ·±ã„ã»ã©è¤‡é›‘ãªé–¢ä¿‚ã‚’å­¦ç¿’ï¼‰
    min_samples_split=5,   # åˆ†å²ã«å¿…è¦ãªæœ€å°ã‚µãƒ³ãƒ—ãƒ«æ•°
    min_samples_leaf=2,    # è‘‰ãƒãƒ¼ãƒ‰ã®æœ€å°ã‚µãƒ³ãƒ—ãƒ«æ•°
    random_state=42,       # å†ç¾æ€§ã®ãŸã‚
    n_jobs=-1              # ã™ã¹ã¦ã®CPUã‚³ã‚¢ã‚’ä½¿ç”¨
)
model_rf.fit(X_train_rf, y_train_rf)
training_time_rf = time.time() - start_time

# äºˆæ¸¬ã¨è©•ä¾¡
y_pred_rf = model_rf.predict(X_test_rf)
mae_rf = mean_absolute_error(y_test_rf, y_pred_rf)
r2_rf = r2_score(y_test_rf, y_pred_rf)

print(&quot;\n===== ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ =====&quot;)
print(f&quot;è¨“ç·´æ™‚é–“: {training_time_rf:.4f} ç§’&quot;)
print(f&quot;å¹³å‡çµ¶å¯¾èª¤å·® (MAE): {mae_rf:.2f} K&quot;)
print(f&quot;æ±ºå®šä¿‚æ•° (RÂ²): {r2_rf:.4f}&quot;)

# ç‰¹å¾´é‡ã®é‡è¦åº¦
feature_importance = pd.DataFrame({
    'ç‰¹å¾´é‡': ['element_A', 'element_B'],
    'é‡è¦åº¦': model_rf.feature_importances_
}).sort_values('é‡è¦åº¦', ascending=False)

print(&quot;\n===== ç‰¹å¾´é‡ã®é‡è¦åº¦ =====&quot;)
print(feature_importance)

# Out-of-Bag (OOB) ã‚¹ã‚³ã‚¢ï¼ˆè¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®ä¸€éƒ¨ã‚’æ¤œè¨¼ã«ä½¿ç”¨ï¼‰
model_rf_oob = RandomForestRegressor(
    n_estimators=100,
    max_depth=10,
    random_state=42,
    oob_score=True  # OOBã‚¹ã‚³ã‚¢ã‚’æœ‰åŠ¹åŒ–
)
model_rf_oob.fit(X_train_rf, y_train_rf)
print(f&quot;\nOOBã‚¹ã‚³ã‚¢ (RÂ²): {model_rf_oob.oob_score_:.4f}&quot;)

# å¯è¦–åŒ–ï¼šäºˆæ¸¬çµæœ
fig, axes = plt.subplots(1, 2, figsize=(15, 6))

# å·¦ï¼šäºˆæ¸¬ vs å®Ÿæ¸¬
axes[0].scatter(y_test_rf, y_pred_rf, alpha=0.6, s=100, c='green')
axes[0].plot([y_test_rf.min(), y_test_rf.max()],
             [y_test_rf.min(), y_test_rf.max()],
             'r--', lw=2, label='å®Œå…¨ãªäºˆæ¸¬')
axes[0].set_xlabel('å®Ÿæ¸¬å€¤ (K)', fontsize=12)
axes[0].set_ylabel('äºˆæ¸¬å€¤ (K)', fontsize=12)
axes[0].set_title('ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆï¼šäºˆæ¸¬çµæœ', fontsize=14)
axes[0].legend()
axes[0].grid(True, alpha=0.3)

# å³ï¼šç‰¹å¾´é‡ã®é‡è¦åº¦
axes[1].barh(feature_importance['ç‰¹å¾´é‡'], feature_importance['é‡è¦åº¦'])
axes[1].set_xlabel('é‡è¦åº¦', fontsize=12)
axes[1].set_title('ç‰¹å¾´é‡ã®é‡è¦åº¦', fontsize=14)
axes[1].grid(True, alpha=0.3, axis='x')

plt.tight_layout()
plt.show()
</code></pre>
<p><strong>ã‚³ãƒ¼ãƒ‰è§£èª¬ï¼š</strong>
1. <strong>éç·šå½¢ãƒ‡ãƒ¼ã‚¿</strong>ï¼šäºŒæ¬¡é …ã¨ç›¸äº’ä½œç”¨é …ã‚’å«ã‚€è¤‡é›‘ãªé–¢ä¿‚
2. <strong>ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿</strong>ï¼š
   - <code>n_estimators</code>: æ±ºå®šæœ¨ã®æ•°ï¼ˆ100æœ¬ï¼‰
   - <code>max_depth</code>: æœ¨ã®æ·±ã•ï¼ˆ10å±¤ï¼‰
   - <code>min_samples_split</code>: åˆ†å²ã®æœ€å°ã‚µãƒ³ãƒ—ãƒ«æ•°ï¼ˆ5å€‹ï¼‰
3. <strong>ç‰¹å¾´é‡é‡è¦åº¦</strong>ï¼šã©ã®ç‰¹å¾´é‡ãŒäºˆæ¸¬ã«å¯„ä¸ã—ã¦ã„ã‚‹ã‹
4. <strong>OOBã‚¹ã‚³ã‚¢</strong>ï¼šè¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®ä¸€éƒ¨ã§æ¤œè¨¼ï¼ˆéå­¦ç¿’ãƒã‚§ãƒƒã‚¯ï¼‰</p>
<p><strong>æœŸå¾…ã•ã‚Œã‚‹çµæœï¼š</strong>
- MAE: 10-20 Kï¼ˆç·šå½¢å›å¸°ã‚ˆã‚Šæ”¹å–„ï¼‰
- RÂ²: 0.90-0.98ï¼ˆé«˜ç²¾åº¦ï¼‰
- è¨“ç·´æ™‚é–“: 0.1-0.5ç§’</p>
<hr />
<h3>2.3 Example 3: å‹¾é…ãƒ–ãƒ¼ã‚¹ãƒ†ã‚£ãƒ³ã‚°ï¼ˆXGBoost/LightGBMï¼‰</h3>
<p><strong>æ¦‚è¦ï¼š</strong>
æ±ºå®šæœ¨ã‚’é€æ¬¡çš„ã«å­¦ç¿’ã—ã€èª¤å·®ã‚’æ¸›ã‚‰ã—ã¦ã„ãæ‰‹æ³•ã€‚Kaggleã‚³ãƒ³ãƒšã§é »ç¹ã«å„ªå‹ã™ã‚‹å¼·åŠ›ãªãƒ¢ãƒ‡ãƒ«ã€‚</p>
<pre><code class="language-python"># LightGBMã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼ˆåˆå›ã®ã¿ï¼‰
# pip install lightgbm

import lightgbm as lgb

# LightGBMãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰
start_time = time.time()
model_lgb = lgb.LGBMRegressor(
    n_estimators=100,       # ãƒ–ãƒ¼ã‚¹ãƒ†ã‚£ãƒ³ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰æ•°
    learning_rate=0.1,      # å­¦ç¿’ç‡ï¼ˆå°ã•ã„ã»ã©æ…é‡ã€å¤§ãã„ã»ã©é€Ÿã„ï¼‰
    max_depth=5,            # æœ¨ã®æ·±ã•
    num_leaves=31,          # è‘‰ãƒãƒ¼ãƒ‰æ•°ï¼ˆLightGBMç‰¹æœ‰ï¼‰
    subsample=0.8,          # ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ¯”ç‡ï¼ˆéå­¦ç¿’é˜²æ­¢ï¼‰
    colsample_bytree=0.8,   # ç‰¹å¾´é‡ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ¯”ç‡
    random_state=42,
    verbose=-1              # è¨“ç·´ãƒ­ã‚°ã‚’éè¡¨ç¤º
)
model_lgb.fit(
    X_train_rf, y_train_rf,
    eval_set=[(X_test_rf, y_test_rf)],  # æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿
    eval_metric='mae',       # è©•ä¾¡æŒ‡æ¨™
    callbacks=[lgb.early_stopping(stopping_rounds=10, verbose=False)]  # æ—©æœŸçµ‚äº†
)
training_time_lgb = time.time() - start_time

# äºˆæ¸¬ã¨è©•ä¾¡
y_pred_lgb = model_lgb.predict(X_test_rf)
mae_lgb = mean_absolute_error(y_test_rf, y_pred_lgb)
r2_lgb = r2_score(y_test_rf, y_pred_lgb)

print(&quot;\n===== LightGBMãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ =====&quot;)
print(f&quot;è¨“ç·´æ™‚é–“: {training_time_lgb:.4f} ç§’&quot;)
print(f&quot;å¹³å‡çµ¶å¯¾èª¤å·® (MAE): {mae_lgb:.2f} K&quot;)
print(f&quot;æ±ºå®šä¿‚æ•° (RÂ²): {r2_lgb:.4f}&quot;)

# å­¦ç¿’æ›²ç·šã®è¡¨ç¤ºï¼ˆè¨“ç·´ã®é€²è¡ŒçŠ¶æ³ï¼‰
fig, ax = plt.subplots(figsize=(10, 6))
lgb.plot_metric(model_lgb, metric='mae', ax=ax)
ax.set_title('LightGBMå­¦ç¿’æ›²ç·šï¼ˆMAEã®å¤‰åŒ–ï¼‰', fontsize=14)
ax.set_xlabel('ãƒ–ãƒ¼ã‚¹ãƒ†ã‚£ãƒ³ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰', fontsize=12)
ax.set_ylabel('MAE (K)', fontsize=12)
ax.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()
</code></pre>
<p><strong>ã‚³ãƒ¼ãƒ‰è§£èª¬ï¼š</strong>
1. <strong>å‹¾é…ãƒ–ãƒ¼ã‚¹ãƒ†ã‚£ãƒ³ã‚°</strong>ï¼šå‰ã®æœ¨ã®èª¤å·®ã‚’æ¬¡ã®æœ¨ã§ä¿®æ­£
2. <strong>Early Stopping</strong>ï¼šæ¤œè¨¼èª¤å·®ãŒæ”¹å–„ã—ãªããªã£ãŸã‚‰è¨“ç·´ã‚’åœæ­¢ï¼ˆéå­¦ç¿’é˜²æ­¢ï¼‰
3. <strong>å­¦ç¿’ç‡</strong>ï¼š0.1ï¼ˆä¸€èˆ¬çš„ãªå€¤ã€0.01-0.3ã®ç¯„å›²ï¼‰
4. <strong>ã‚µãƒ–ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°</strong>ï¼šå„ãƒ©ã‚¦ãƒ³ãƒ‰ã§ãƒ‡ãƒ¼ã‚¿ã®80%ã‚’ãƒ©ãƒ³ãƒ€ãƒ é¸æŠ</p>
<p><strong>æœŸå¾…ã•ã‚Œã‚‹çµæœï¼š</strong>
- MAE: 8-15 Kï¼ˆãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆã¨åŒç­‰ä»¥ä¸Šï¼‰
- RÂ²: 0.92-0.99
- è¨“ç·´æ™‚é–“: 0.2-0.8ç§’</p>
<hr />
<h3>2.4 Example 4: ã‚µãƒãƒ¼ãƒˆãƒ™ã‚¯ã‚¿ãƒ¼å›å¸°ï¼ˆSVRï¼‰</h3>
<p><strong>æ¦‚è¦ï¼š</strong>
ã‚µãƒãƒ¼ãƒˆãƒ™ã‚¯ã‚¿ãƒ¼ãƒã‚·ãƒ³ã®å›å¸°ç‰ˆã€‚ã‚«ãƒ¼ãƒãƒ«ãƒˆãƒªãƒƒã‚¯ã«ã‚ˆã‚Šéç·šå½¢é–¢ä¿‚ã‚’å­¦ç¿’ã€‚</p>
<pre><code class="language-python">from sklearn.svm import SVR
from sklearn.preprocessing import StandardScaler

# SVRã¯ç‰¹å¾´é‡ã®ã‚¹ã‚±ãƒ¼ãƒ«ã«æ•æ„ŸãªãŸã‚ã€æ¨™æº–åŒ–ãŒå¿…é ˆ
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train_rf)
X_test_scaled = scaler.transform(X_test_rf)

# SVRãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰
start_time = time.time()
model_svr = SVR(
    kernel='rbf',      # ã‚¬ã‚¦ã‚·ã‚¢ãƒ³ã‚«ãƒ¼ãƒãƒ«ï¼ˆéç·šå½¢ã«å¯¾å¿œï¼‰
    C=100,             # æ­£å‰‡åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆå¤§ãã„ã»ã©è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã«é©åˆï¼‰
    gamma='scale',     # ã‚«ãƒ¼ãƒãƒ«ä¿‚æ•°ï¼ˆ'scale'ã¯è‡ªå‹•è¨­å®šï¼‰
    epsilon=0.1        # ã‚¤ãƒ—ã‚·ãƒ­ãƒ³ãƒãƒ¥ãƒ¼ãƒ–å¹…ï¼ˆã“ã®ç¯„å›²å†…ã®èª¤å·®ã¯ç„¡è¦–ï¼‰
)
model_svr.fit(X_train_scaled, y_train_rf)
training_time_svr = time.time() - start_time

# äºˆæ¸¬ã¨è©•ä¾¡
y_pred_svr = model_svr.predict(X_test_scaled)
mae_svr = mean_absolute_error(y_test_rf, y_pred_svr)
r2_svr = r2_score(y_test_rf, y_pred_svr)

print(&quot;\n===== SVRãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ =====&quot;)
print(f&quot;è¨“ç·´æ™‚é–“: {training_time_svr:.4f} ç§’&quot;)
print(f&quot;å¹³å‡çµ¶å¯¾èª¤å·® (MAE): {mae_svr:.2f} K&quot;)
print(f&quot;æ±ºå®šä¿‚æ•° (RÂ²): {r2_svr:.4f}&quot;)
print(f&quot;ã‚µãƒãƒ¼ãƒˆãƒ™ã‚¯ã‚¿ãƒ¼æ•°: {len(model_svr.support_)}/{len(X_train_rf)}&quot;)

# å¯è¦–åŒ–
plt.figure(figsize=(10, 6))
plt.scatter(y_test_rf, y_pred_svr, alpha=0.6, s=100, c='purple')
plt.plot([y_test_rf.min(), y_test_rf.max()],
         [y_test_rf.min(), y_test_rf.max()],
         'r--', lw=2, label='å®Œå…¨ãªäºˆæ¸¬')
plt.xlabel('å®Ÿæ¸¬å€¤ (K)', fontsize=12)
plt.ylabel('äºˆæ¸¬å€¤ (K)', fontsize=12)
plt.title('SVRï¼šèç‚¹ã®äºˆæ¸¬çµæœ', fontsize=14)
plt.legend()
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()
</code></pre>
<p><strong>ã‚³ãƒ¼ãƒ‰è§£èª¬ï¼š</strong>
1. <strong>æ¨™æº–åŒ–</strong>ï¼šå¹³å‡0ã€æ¨™æº–åå·®1ã«å¤‰æ›ï¼ˆSVRã«å¿…é ˆï¼‰
2. <strong>RBFã‚«ãƒ¼ãƒãƒ«</strong>ï¼šã‚¬ã‚¦ã‚·ã‚¢ãƒ³é–¢æ•°ã§éç·šå½¢å¤‰æ›
3. <strong>Cãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿</strong>ï¼šå¤§ãã„ã»ã©è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã«å³å¯†ã«é©åˆï¼ˆéå­¦ç¿’ãƒªã‚¹ã‚¯â†‘ï¼‰
4. <strong>ã‚µãƒãƒ¼ãƒˆãƒ™ã‚¯ã‚¿ãƒ¼</strong>ï¼šäºˆæ¸¬ã«ä½¿ç”¨ã™ã‚‹é‡è¦ãªãƒ‡ãƒ¼ã‚¿ç‚¹</p>
<p><strong>æœŸå¾…ã•ã‚Œã‚‹çµæœï¼š</strong>
- MAE: 12-25 K
- RÂ²: 0.85-0.95
- è¨“ç·´æ™‚é–“: 0.5-2ç§’ï¼ˆä»–ãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Šé…ã„ï¼‰</p>
<hr />
<h3>2.5 Example 5: ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼ˆMLPï¼‰</h3>
<p><strong>æ¦‚è¦ï¼š</strong>
å¤šå±¤ãƒ‘ãƒ¼ã‚»ãƒ—ãƒˆãƒ­ãƒ³ã€‚æ·±å±¤å­¦ç¿’ã®åŸºç¤ãƒ¢ãƒ‡ãƒ«ã€‚</p>
<pre><code class="language-python">from sklearn.neural_network import MLPRegressor

# MLPãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰
start_time = time.time()
model_mlp = MLPRegressor(
    hidden_layer_sizes=(64, 32, 16),  # 3å±¤ï¼š64â†’32â†’16ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³
    activation='relu',         # æ´»æ€§åŒ–é–¢æ•°ï¼ˆReLU: æœ€ã‚‚ä¸€èˆ¬çš„ï¼‰
    solver='adam',             # æœ€é©åŒ–ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ï¼ˆAdam: é©å¿œçš„å­¦ç¿’ç‡ï¼‰
    alpha=0.001,               # L2æ­£å‰‡åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆéå­¦ç¿’é˜²æ­¢ï¼‰
    learning_rate_init=0.01,   # åˆæœŸå­¦ç¿’ç‡
    max_iter=500,              # æœ€å¤§ã‚¨ãƒãƒƒã‚¯æ•°
    random_state=42,
    early_stopping=True,       # æ¤œè¨¼èª¤å·®ãŒæ”¹å–„ã—ãªã‘ã‚Œã°åœæ­¢
    validation_fraction=0.2,   # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®20%ã‚’æ¤œè¨¼ã«ä½¿ç”¨
    verbose=False
)
model_mlp.fit(X_train_scaled, y_train_rf)
training_time_mlp = time.time() - start_time

# äºˆæ¸¬ã¨è©•ä¾¡
y_pred_mlp = model_mlp.predict(X_test_scaled)
mae_mlp = mean_absolute_error(y_test_rf, y_pred_mlp)
r2_mlp = r2_score(y_test_rf, y_pred_mlp)

print(&quot;\n===== MLPãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ =====&quot;)
print(f&quot;è¨“ç·´æ™‚é–“: {training_time_mlp:.4f} ç§’&quot;)
print(f&quot;å¹³å‡çµ¶å¯¾èª¤å·® (MAE): {mae_mlp:.2f} K&quot;)
print(f&quot;æ±ºå®šä¿‚æ•° (RÂ²): {r2_mlp:.4f}&quot;)
print(f&quot;ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ•°: {model_mlp.n_iter_}&quot;)
print(f&quot;æå¤±: {model_mlp.loss_:.4f}&quot;)

# å­¦ç¿’æ›²ç·šã®å¯è¦–åŒ–
plt.figure(figsize=(10, 6))
plt.plot(model_mlp.loss_curve_, label='Training Loss', lw=2)
plt.xlabel('ã‚¨ãƒãƒƒã‚¯', fontsize=12)
plt.ylabel('æå¤±', fontsize=12)
plt.title('MLPã®å­¦ç¿’æ›²ç·š', fontsize=14)
plt.legend()
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()
</code></pre>
<p><strong>ã‚³ãƒ¼ãƒ‰è§£èª¬ï¼š</strong>
1. <strong>éš ã‚Œå±¤</strong>ï¼š(64, 32, 16) = 3å±¤ã®ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯
2. <strong>ReLUæ´»æ€§åŒ–é–¢æ•°</strong>ï¼šéç·šå½¢æ€§ã‚’å°å…¥
3. <strong>Adamæœ€é©åŒ–</strong>ï¼šé©å¿œçš„å­¦ç¿’ç‡ã§åŠ¹ç‡çš„ã«å­¦ç¿’
4. <strong>Early Stopping</strong>ï¼šéå­¦ç¿’ã‚’é˜²æ­¢</p>
<p><strong>æœŸå¾…ã•ã‚Œã‚‹çµæœï¼š</strong>
- MAE: 10-20 K
- RÂ²: 0.90-0.98
- è¨“ç·´æ™‚é–“: 1-3ç§’ï¼ˆä»–ãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Šé…ã„ï¼‰</p>
<hr />
<h3>2.6 Example 6: Materials Project APIå®Ÿãƒ‡ãƒ¼ã‚¿çµ±åˆ</h3>
<p><strong>æ¦‚è¦ï¼š</strong>
å®Ÿéš›ã®ææ–™ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã€æ©Ÿæ¢°å­¦ç¿’ã§äºˆæ¸¬ã€‚</p>
<pre><code class="language-python"># Materials Project APIã‚’ä½¿ç”¨ï¼ˆç„¡æ–™APIã‚­ãƒ¼ãŒå¿…è¦ï¼‰
# ç™»éŒ²: https://materialsproject.org

# æ³¨æ„: ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã¯APIã‚­ãƒ¼å–å¾—å¾Œã«å®Ÿè¡Œã—ã¦ãã ã•ã„
# ã“ã“ã§ã¯æ¨¡æ“¬ãƒ‡ãƒ¼ã‚¿ã§å‹•ä½œã‚’ç¤ºã—ã¾ã™

try:
    from pymatgen.ext.matproj import MPRester

    # APIã‚­ãƒ¼ã‚’è¨­å®šï¼ˆ'YOUR_API_KEY'ã‚’å®Ÿéš›ã®ã‚­ãƒ¼ã«ç½®ãæ›ãˆï¼‰
    API_KEY = &quot;YOUR_API_KEY&quot;

    with MPRester(API_KEY) as mpr:
        # ãƒªãƒã‚¦ãƒ åŒ–åˆç‰©ã®ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        entries = mpr.query(
            criteria={
                &quot;elements&quot;: {&quot;$all&quot;: [&quot;Li&quot;]},
                &quot;nelements&quot;: {&quot;$lte&quot;: 2}
            },
            properties=[
                &quot;material_id&quot;,
                &quot;pretty_formula&quot;,
                &quot;band_gap&quot;,
                &quot;formation_energy_per_atom&quot;
            ]
        )

        # DataFrameã«å¤‰æ›
        df_mp = pd.DataFrame(entries)
        print(f&quot;å–å¾—ãƒ‡ãƒ¼ã‚¿æ•°: {len(df_mp)}ä»¶&quot;)
        print(df_mp.head())

except ImportError:
    print(&quot;pymatgenãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚&quot;)
    print(&quot;pip install pymatgen ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„ã€‚&quot;)
except Exception as e:
    print(f&quot;APIæ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}&quot;)
    print(&quot;æ¨¡æ“¬ãƒ‡ãƒ¼ã‚¿ã§ç¶šè¡Œã—ã¾ã™ã€‚&quot;)

    # æ¨¡æ“¬ãƒ‡ãƒ¼ã‚¿ï¼ˆMaterials Projectã®å…¸å‹çš„ãªãƒ‡ãƒ¼ã‚¿å½¢å¼ï¼‰
    df_mp = pd.DataFrame({
        'material_id': ['mp-1', 'mp-2', 'mp-3', 'mp-4', 'mp-5'],
        'pretty_formula': ['Li', 'Li2O', 'LiH', 'Li3N', 'LiF'],
        'band_gap': [0.0, 7.5, 3.9, 1.2, 13.8],
        'formation_energy_per_atom': [0.0, -2.9, -0.5, -0.8, -3.5]
    })
    print(&quot;æ¨¡æ“¬ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¾ã™:&quot;)
    print(df_mp)

# æ©Ÿæ¢°å­¦ç¿’ã§å½¢æˆã‚¨ãƒãƒ«ã‚®ãƒ¼ã‹ã‚‰ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—ã‚’äºˆæ¸¬
if len(df_mp) &gt; 5:
    X_mp = df_mp[['formation_energy_per_atom']].values
    y_mp = df_mp['band_gap'].values

    X_train_mp, X_test_mp, y_train_mp, y_test_mp = train_test_split(
        X_mp, y_mp, test_size=0.2, random_state=42
    )

    # ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆã§äºˆæ¸¬
    model_mp = RandomForestRegressor(n_estimators=100, random_state=42)
    model_mp.fit(X_train_mp, y_train_mp)

    y_pred_mp = model_mp.predict(X_test_mp)
    mae_mp = mean_absolute_error(y_test_mp, y_pred_mp)
    r2_mp = r2_score(y_test_mp, y_pred_mp)

    print(f&quot;\n===== Materials Projectãƒ‡ãƒ¼ã‚¿ã§ã®äºˆæ¸¬æ€§èƒ½ =====&quot;)
    print(f&quot;MAE: {mae_mp:.2f} eV&quot;)
    print(f&quot;RÂ²: {r2_mp:.4f}&quot;)
else:
    print(&quot;ãƒ‡ãƒ¼ã‚¿æ•°ãŒå°‘ãªã„ãŸã‚ã€æ©Ÿæ¢°å­¦ç¿’ã¯ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚&quot;)
</code></pre>
<p><strong>ã‚³ãƒ¼ãƒ‰è§£èª¬ï¼š</strong>
1. <strong>MPRester</strong>ï¼šMaterials Project APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
2. <strong>query()</strong>: ææ–™ã‚’æ¤œç´¢ï¼ˆå…ƒç´ ã€ç‰¹æ€§ã§çµã‚Šè¾¼ã¿ï¼‰
3. <strong>å®Ÿãƒ‡ãƒ¼ã‚¿ã®åˆ©ç‚¹</strong>ï¼šDFTè¨ˆç®—ã«ã‚ˆã‚‹ä¿¡é ¼æ€§ã®é«˜ã„ãƒ‡ãƒ¼ã‚¿</p>
<p><strong>æœŸå¾…ã•ã‚Œã‚‹çµæœï¼š</strong>
- å®Ÿãƒ‡ãƒ¼ã‚¿å–å¾—æ•°ï¼š10-100ä»¶ï¼ˆæ¤œç´¢æ¡ä»¶ã«ã‚ˆã‚‹ï¼‰
- äºˆæ¸¬æ€§èƒ½ã¯ãƒ‡ãƒ¼ã‚¿æ•°ã«ä¾å­˜ï¼ˆRÂ²: 0.6-0.9ï¼‰</p>
<hr />
<h2>3. ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ã®æ¯”è¼ƒ</h2>
<p>ã™ã¹ã¦ã®ãƒ¢ãƒ‡ãƒ«ã‚’åŒã˜ãƒ‡ãƒ¼ã‚¿ã§è©•ä¾¡ã—ã€æ€§èƒ½ã‚’æ¯”è¼ƒã—ã¾ã™ã€‚</p>
<h3>3.1 ç·åˆæ¯”è¼ƒè¡¨</h3>
<table>
<thead>
<tr>
<th>ãƒ¢ãƒ‡ãƒ«</th>
<th>MAE (K)</th>
<th>RÂ²</th>
<th style="text-align: right;">è¨“ç·´æ™‚é–“ (ç§’)</th>
<th>ãƒ¡ãƒ¢ãƒª</th>
<th>è§£é‡ˆæ€§</th>
</tr>
</thead>
<tbody>
<tr>
<td>ç·šå½¢å›å¸°</td>
<td>18.5</td>
<td>0.952</td>
<td style="text-align: right;">0.005</td>
<td>å°</td>
<td>â­â­â­â­â­</td>
</tr>
<tr>
<td>ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆ</td>
<td>12.3</td>
<td>0.982</td>
<td style="text-align: right;">0.32</td>
<td>ä¸­</td>
<td>â­â­â­â­</td>
</tr>
<tr>
<td>LightGBM</td>
<td>10.8</td>
<td>0.987</td>
<td style="text-align: right;">0.45</td>
<td>ä¸­</td>
<td>â­â­â­</td>
</tr>
<tr>
<td>SVR</td>
<td>15.2</td>
<td>0.965</td>
<td style="text-align: right;">1.85</td>
<td>å¤§</td>
<td>â­â­</td>
</tr>
<tr>
<td>MLP</td>
<td>13.1</td>
<td>0.978</td>
<td style="text-align: right;">2.10</td>
<td>å¤§</td>
<td>â­</td>
</tr>
</tbody>
</table>
<p><strong>å‡¡ä¾‹ï¼š</strong>
- <strong>MAE</strong>: å°ã•ã„ã»ã©è‰¯ã„ï¼ˆå¹³å‡èª¤å·®ï¼‰
- <strong>RÂ²</strong>: 1ã«è¿‘ã„ã»ã©è‰¯ã„ï¼ˆèª¬æ˜åŠ›ï¼‰
- <strong>è¨“ç·´æ™‚é–“</strong>: çŸ­ã„ã»ã©è‰¯ã„
- <strong>ãƒ¡ãƒ¢ãƒª</strong>: å° &lt; ä¸­ &lt; å¤§
- <strong>è§£é‡ˆæ€§</strong>: â­å¤šã„ã»ã©è§£é‡ˆã—ã‚„ã™ã„</p>
<h3>3.2 å¯è¦–åŒ–ï¼šæ€§èƒ½æ¯”è¼ƒ</h3>
<pre><code class="language-python">import matplotlib.pyplot as plt

# ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ãƒ‡ãƒ¼ã‚¿
models = ['ç·šå½¢å›å¸°', 'ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆ', 'LightGBM', 'SVR', 'MLP']
mae_scores = [18.5, 12.3, 10.8, 15.2, 13.1]
r2_scores = [0.952, 0.982, 0.987, 0.965, 0.978]
training_times = [0.005, 0.32, 0.45, 1.85, 2.10]

fig, axes = plt.subplots(1, 3, figsize=(18, 5))

# MAEæ¯”è¼ƒ
axes[0].bar(models, mae_scores, color=['blue', 'green', 'orange', 'purple', 'red'])
axes[0].set_ylabel('MAE (K)', fontsize=12)
axes[0].set_title('å¹³å‡çµ¶å¯¾èª¤å·®ï¼ˆå°ã•ã„ã»ã©è‰¯ã„ï¼‰', fontsize=14)
axes[0].tick_params(axis='x', rotation=45)
axes[0].grid(True, alpha=0.3, axis='y')

# RÂ²æ¯”è¼ƒ
axes[1].bar(models, r2_scores, color=['blue', 'green', 'orange', 'purple', 'red'])
axes[1].set_ylabel('RÂ²', fontsize=12)
axes[1].set_title('æ±ºå®šä¿‚æ•°ï¼ˆ1ã«è¿‘ã„ã»ã©è‰¯ã„ï¼‰', fontsize=14)
axes[1].tick_params(axis='x', rotation=45)
axes[1].grid(True, alpha=0.3, axis='y')
axes[1].set_ylim(0.9, 1.0)

# è¨“ç·´æ™‚é–“æ¯”è¼ƒ
axes[2].bar(models, training_times, color=['blue', 'green', 'orange', 'purple', 'red'])
axes[2].set_ylabel('è¨“ç·´æ™‚é–“ (ç§’)', fontsize=12)
axes[2].set_title('è¨“ç·´æ™‚é–“ï¼ˆçŸ­ã„ã»ã©è‰¯ã„ï¼‰', fontsize=14)
axes[2].tick_params(axis='x', rotation=45)
axes[2].grid(True, alpha=0.3, axis='y')

plt.tight_layout()
plt.show()
</code></pre>
<h3>3.3 ãƒ¢ãƒ‡ãƒ«é¸æŠã®ãƒ•ãƒ­ãƒ¼ãƒãƒ£ãƒ¼ãƒˆ</h3>
<div class="mermaid">
graph TD
    A[ææ–™ç‰¹æ€§äºˆæ¸¬ã‚¿ã‚¹ã‚¯] --> B{ãƒ‡ãƒ¼ã‚¿æ•°ã¯ï¼Ÿ}
    B -->|< 100| C[ç·šå½¢å›å¸° or SVR]
    B -->|100-1000| D[ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆ]
    B -->|> 1000| E{è¨ˆç®—æ™‚é–“ã®åˆ¶ç´„ã¯ï¼Ÿ}

    E -->|å³ã—ã„| F[ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆ]
    E -->|ç·©ã„| G[LightGBM or MLP]

    C --> H{è§£é‡ˆæ€§ãŒé‡è¦ï¼Ÿ}
    H -->|ã¯ã„| I[ç·šå½¢å›å¸°]
    H -->|ã„ã„ãˆ| J[SVR]

    D --> K[ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆæ¨å¥¨]
    F --> K
    G --> L{éç·šå½¢æ€§ãŒå¼·ã„ï¼Ÿ}
    L -->|ã¯ã„| M[MLP]
    L -->|ã„ã„ãˆ| N[LightGBM]

    style A fill:#e3f2fd
    style K fill:#c8e6c9
    style M fill:#fff9c4
    style N fill:#fff9c4
    style I fill:#c8e6c9
    style J fill:#c8e6c9
</div>

<h3>3.4 ãƒ¢ãƒ‡ãƒ«é¸æŠã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³</h3>
<p><strong>çŠ¶æ³åˆ¥æ¨å¥¨ãƒ¢ãƒ‡ãƒ«ï¼š</strong></p>
<table>
<thead>
<tr>
<th>çŠ¶æ³</th>
<th>æ¨å¥¨ãƒ¢ãƒ‡ãƒ«</th>
<th>ç†ç”±</th>
</tr>
</thead>
<tbody>
<tr>
<td>ãƒ‡ãƒ¼ã‚¿æ•° &lt; 100</td>
<td>ç·šå½¢å›å¸° or SVR</td>
<td>éå­¦ç¿’ã‚’é˜²æ­¢ã€ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ¢ãƒ‡ãƒ«ãŒå®‰å…¨</td>
</tr>
<tr>
<td>ãƒ‡ãƒ¼ã‚¿æ•° 100-1000</td>
<td>ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆ</td>
<td>ãƒãƒ©ãƒ³ã‚¹ãŒè‰¯ã„ã€ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´ãŒå®¹æ˜“</td>
</tr>
<tr>
<td>ãƒ‡ãƒ¼ã‚¿æ•° &gt; 1000</td>
<td>LightGBM or MLP</td>
<td>å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã§é«˜ç²¾åº¦</td>
</tr>
<tr>
<td>è§£é‡ˆæ€§ãŒé‡è¦</td>
<td>ç·šå½¢å›å¸° or ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆ</td>
<td>ä¿‚æ•°ã‚„ç‰¹å¾´é‡é‡è¦åº¦ãŒåˆ†ã‹ã‚Šã‚„ã™ã„</td>
</tr>
<tr>
<td>è¨ˆç®—æ™‚é–“ãŒå³ã—ã„</td>
<td>ç·šå½¢å›å¸° or ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆ</td>
<td>è¨“ç·´ãŒé«˜é€Ÿ</td>
</tr>
<tr>
<td>æœ€é«˜ç²¾åº¦ãŒå¿…è¦</td>
<td>LightGBMï¼ˆã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ä½µç”¨ï¼‰</td>
<td>Kaggleã‚³ãƒ³ãƒšã§å®Ÿç¸¾å¤šæ•°</td>
</tr>
<tr>
<td>éç·šå½¢æ€§ãŒå¼·ã„</td>
<td>MLP or SVR</td>
<td>è¤‡é›‘ãªé–¢ä¿‚ã‚’å­¦ç¿’å¯èƒ½</td>
</tr>
</tbody>
</table>
<hr />
<h2>4. ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°</h2>
<p>ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’æœ€å¤§åŒ–ã™ã‚‹ãŸã‚ã€ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æœ€é©åŒ–ã—ã¾ã™ã€‚</p>
<h3>4.1 ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨ã¯</h3>
<p><strong>å®šç¾©ï¼š</strong>
æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®è¨­å®šå€¤ï¼ˆå­¦ç¿’å‰ã«æ±ºã‚ã‚‹å¿…è¦ãŒã‚ã‚‹ï¼‰ã€‚</p>
<p><strong>ä¾‹ï¼ˆãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆï¼‰ï¼š</strong>
- <code>n_estimators</code>: æ±ºå®šæœ¨ã®æ•°ï¼ˆ10, 50, 100, 200...ï¼‰
- <code>max_depth</code>: æœ¨ã®æ·±ã•ï¼ˆ3, 5, 10, 20...ï¼‰
- <code>min_samples_split</code>: åˆ†å²ã®æœ€å°ã‚µãƒ³ãƒ—ãƒ«æ•°ï¼ˆ2, 5, 10...ï¼‰</p>
<p><strong>é‡è¦æ€§ï¼š</strong>
é©åˆ‡ãªãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ã€æ€§èƒ½ãŒ10-30%å‘ä¸Šã™ã‚‹ã“ã¨ã‚‚ã€‚</p>
<h3>4.2 Grid Searchï¼ˆã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒï¼‰</h3>
<p><strong>æ¦‚è¦ï¼š</strong>
ã™ã¹ã¦ã®çµ„ã¿åˆã‚ã›ã‚’è©¦ã—ã€æœ€è‰¯ã®ã‚‚ã®ã‚’é¸æŠã€‚</p>
<pre><code class="language-python">from sklearn.model_selection import GridSearchCV

# ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆã®ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å€™è£œ
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [5, 10, 15, None],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}

# Grid Searchã®è¨­å®š
grid_search = GridSearchCV(
    estimator=RandomForestRegressor(random_state=42),
    param_grid=param_grid,
    cv=5,              # 5-foldäº¤å·®æ¤œè¨¼
    scoring='neg_mean_absolute_error',  # MAEã§è©•ä¾¡ï¼ˆå°ã•ã„ã»ã©è‰¯ã„ï¼‰
    n_jobs=-1,         # ä¸¦åˆ—å®Ÿè¡Œ
    verbose=1          # é€²æ—è¡¨ç¤º
)

# Grid Searchå®Ÿè¡Œ
print(&quot;===== Grid Searché–‹å§‹ =====&quot;)
print(f&quot;æ¢ç´¢ã™ã‚‹çµ„ã¿åˆã‚ã›æ•°: {len(param_grid['n_estimators']) * len(param_grid['max_depth']) * len(param_grid['min_samples_split']) * len(param_grid['min_samples_leaf'])}&quot;)
start_time = time.time()
grid_search.fit(X_train_rf, y_train_rf)
grid_search_time = time.time() - start_time

# æœ€è‰¯ã®ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
print(f&quot;\n===== Grid Searchå®Œäº†ï¼ˆ{grid_search_time:.2f}ç§’ï¼‰ =====&quot;)
print(&quot;æœ€è‰¯ã®ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:&quot;)
for param, value in grid_search.best_params_.items():
    print(f&quot;  {param}: {value}&quot;)

print(f&quot;\näº¤å·®æ¤œè¨¼MAE: {-grid_search.best_score_:.2f} K&quot;)

# æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ã§ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’è©•ä¾¡
best_model = grid_search.best_estimator_
y_pred_best = best_model.predict(X_test_rf)
mae_best = mean_absolute_error(y_test_rf, y_pred_best)
r2_best = r2_score(y_test_rf, y_pred_best)

print(f&quot;\nãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§ã®æ€§èƒ½:&quot;)
print(f&quot;  MAE: {mae_best:.2f} K&quot;)
print(f&quot;  RÂ²: {r2_best:.4f}&quot;)
</code></pre>
<p><strong>ã‚³ãƒ¼ãƒ‰è§£èª¬ï¼š</strong>
1. <strong>param_grid</strong>ï¼šæ¢ç´¢ã™ã‚‹ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ç¯„å›²
2. <strong>GridSearchCV</strong>ï¼šã™ã¹ã¦ã®çµ„ã¿åˆã‚ã›ï¼ˆ3Ã—4Ã—3Ã—3=108é€šã‚Šï¼‰ã‚’è©¦ã™
3. <strong>cv=5</strong>ï¼š5-foldäº¤å·®æ¤œè¨¼ã§è©•ä¾¡ï¼ˆãƒ‡ãƒ¼ã‚¿ã‚’5åˆ†å‰²ï¼‰
4. <strong>best_params_</strong>ï¼šæœ€è‰¯ã®çµ„ã¿åˆã‚ã›</p>
<p><strong>æœŸå¾…ã•ã‚Œã‚‹çµæœï¼š</strong>
- Grid Searchæ™‚é–“ï¼š10-60ç§’ï¼ˆãƒ‡ãƒ¼ã‚¿æ•°ã¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã«ã‚ˆã‚‹ï¼‰
- æœ€è‰¯MAEï¼š10-15 Kï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚ˆã‚Šæ”¹å–„ï¼‰</p>
<h3>4.3 Random Searchï¼ˆãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ¼ãƒï¼‰</h3>
<p><strong>æ¦‚è¦ï¼š</strong>
ãƒ©ãƒ³ãƒ€ãƒ ã«çµ„ã¿åˆã‚ã›ã‚’è©¦ã™ï¼ˆé«˜é€Ÿã€å¤§è¦æ¨¡æ¢ç´¢å‘ã‘ï¼‰ã€‚</p>
<pre><code class="language-python">from sklearn.model_selection import RandomizedSearchCV
from scipy.stats import randint, uniform

# ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®åˆ†å¸ƒã‚’æŒ‡å®š
param_distributions = {
    'n_estimators': randint(50, 300),        # 50-300ã®æ•´æ•°ã‚’ãƒ©ãƒ³ãƒ€ãƒ é¸æŠ
    'max_depth': randint(5, 30),             # 5-30ã®æ•´æ•°
    'min_samples_split': randint(2, 20),     # 2-20ã®æ•´æ•°
    'min_samples_leaf': randint(1, 10),      # 1-10ã®æ•´æ•°
    'max_features': uniform(0.5, 0.5)        # 0.5-1.0ã®å®Ÿæ•°
}

# Random Searchã®è¨­å®š
random_search = RandomizedSearchCV(
    estimator=RandomForestRegressor(random_state=42),
    param_distributions=param_distributions,
    n_iter=50,         # 50å›ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
    cv=5,
    scoring='neg_mean_absolute_error',
    n_jobs=-1,
    random_state=42,
    verbose=1
)

# Random Searchå®Ÿè¡Œ
print(&quot;===== Random Searché–‹å§‹ =====&quot;)
start_time = time.time()
random_search.fit(X_train_rf, y_train_rf)
random_search_time = time.time() - start_time

print(f&quot;\n===== Random Searchå®Œäº†ï¼ˆ{random_search_time:.2f}ç§’ï¼‰ =====&quot;)
print(&quot;æœ€è‰¯ã®ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:&quot;)
for param, value in random_search.best_params_.items():
    print(f&quot;  {param}: {value}&quot;)

print(f&quot;\näº¤å·®æ¤œè¨¼MAE: {-random_search.best_score_:.2f} K&quot;)
</code></pre>
<p><strong>Grid Search vs Random Search:</strong></p>
<table>
<thead>
<tr>
<th>é …ç›®</th>
<th>Grid Search</th>
<th>Random Search</th>
</tr>
</thead>
<tbody>
<tr>
<td>æ¢ç´¢æ–¹æ³•</td>
<td>ã™ã¹ã¦ã®çµ„ã¿åˆã‚ã›</td>
<td>ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°</td>
</tr>
<tr>
<td>å®Ÿè¡Œæ™‚é–“</td>
<td>é•·ã„ï¼ˆå…¨æ¢ç´¢ï¼‰</td>
<td>çŸ­ã„ï¼ˆæŒ‡å®šå›æ•°ã®ã¿ï¼‰</td>
</tr>
<tr>
<td>æœ€è‰¯è§£ã®ä¿è¨¼</td>
<td>ã‚ã‚Šï¼ˆå…¨æ¢ç´¢ï¼‰</td>
<td>ãªã—ï¼ˆç¢ºç‡çš„ï¼‰</td>
</tr>
<tr>
<td>é©ç”¨å ´é¢</td>
<td>å°è¦æ¨¡æ¢ç´¢</td>
<td>å¤§è¦æ¨¡æ¢ç´¢</td>
</tr>
</tbody>
</table>
<h3>4.4 ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®åŠ¹æœå¯è¦–åŒ–</h3>
<pre><code class="language-python"># Grid Searchã®å…¨çµæœã‚’å–å¾—
results = pd.DataFrame(grid_search.cv_results_)

# n_estimatorsã®å½±éŸ¿ã‚’å¯è¦–åŒ–
fig, axes = plt.subplots(1, 2, figsize=(15, 5))

# n_estimators vs MAE
for depth in [5, 10, 15, None]:
    mask = results['param_max_depth'] == depth
    axes[0].plot(
        results[mask]['param_n_estimators'],
        -results[mask]['mean_test_score'],
        marker='o',
        label=f'max_depth={depth}'
    )

axes[0].set_xlabel('n_estimators', fontsize=12)
axes[0].set_ylabel('äº¤å·®æ¤œè¨¼MAE (K)', fontsize=12)
axes[0].set_title('n_estimatorsã®å½±éŸ¿', fontsize=14)
axes[0].legend()
axes[0].grid(True, alpha=0.3)

# max_depth vs MAE
for n_est in [50, 100, 200]:
    mask = results['param_n_estimators'] == n_est
    axes[1].plot(
        results[mask]['param_max_depth'].apply(lambda x: 20 if x is None else x),
        -results[mask]['mean_test_score'],
        marker='o',
        label=f'n_estimators={n_est}'
    )

axes[1].set_xlabel('max_depth', fontsize=12)
axes[1].set_ylabel('äº¤å·®æ¤œè¨¼MAE (K)', fontsize=12)
axes[1].set_title('max_depthã®å½±éŸ¿', fontsize=14)
axes[1].legend()
axes[1].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
</code></pre>
<hr />
<h2>5. ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ï¼ˆææ–™å‘ã‘ï¼‰</h2>
<p>ææ–™ãƒ‡ãƒ¼ã‚¿ã«ç‰¹åŒ–ã—ãŸç‰¹å¾´é‡ã‚’ä½œæˆã—ã€äºˆæ¸¬æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã¾ã™ã€‚</p>
<h3>5.1 ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã¨ã¯</h3>
<p><strong>å®šç¾©ï¼š</strong>
ç”Ÿãƒ‡ãƒ¼ã‚¿ã‹ã‚‰äºˆæ¸¬ã«æœ‰åŠ¹ãªç‰¹å¾´é‡ã‚’ä½œæˆãƒ»é¸æŠã™ã‚‹ãƒ—ãƒ­ã‚»ã‚¹ã€‚</p>
<p><strong>é‡è¦æ€§ï¼š</strong>
ã€Œè‰¯ã„ç‰¹å¾´é‡ &gt; é«˜åº¦ãªãƒ¢ãƒ‡ãƒ«ã€
- é©åˆ‡ãªç‰¹å¾´é‡ã§ã€å˜ç´”ãªãƒ¢ãƒ‡ãƒ«ã§ã‚‚é«˜ç²¾åº¦ã‚’é”æˆã§ãã‚‹
- ä¸é©åˆ‡ãªç‰¹å¾´é‡ã§ã¯ã€ã©ã‚“ãªãƒ¢ãƒ‡ãƒ«ã§ã‚‚æ€§èƒ½ã¯ä¸ŠãŒã‚‰ãªã„</p>
<h3>5.2 Matminerã«ã‚ˆã‚‹è‡ªå‹•ç‰¹å¾´é‡æŠ½å‡º</h3>
<p><strong>Matminerï¼š</strong>
ææ–™ç§‘å­¦å‘ã‘ã®ç‰¹å¾´é‡æŠ½å‡ºãƒ©ã‚¤ãƒ–ãƒ©ãƒªã€‚</p>
<pre><code class="language-bash"># ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼ˆåˆå›ã®ã¿ï¼‰
pip install matminer
</code></pre>
<pre><code class="language-python">from matminer.featurizers.composition import ElementProperty
from pymatgen.core import Composition

# çµ„æˆãƒ‡ãƒ¼ã‚¿ï¼ˆä¾‹ï¼šLi2Oï¼‰
compositions = ['Li2O', 'LiCoO2', 'LiFePO4', 'Li4Ti5O12']

# Compositionã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«å¤‰æ›
comp_objects = [Composition(c) for c in compositions]

# ElementPropertyã§ç‰¹å¾´é‡æŠ½å‡º
featurizer = ElementProperty.from_preset('magpie')

# ç‰¹å¾´é‡ã‚’è¨ˆç®—
features = []
for comp in comp_objects:
    feat = featurizer.featurize(comp)
    features.append(feat)

# DataFrameã«å¤‰æ›
feature_names = featurizer.feature_labels()
df_features = pd.DataFrame(features, columns=feature_names)

print(&quot;===== Matminerã§æŠ½å‡ºã—ãŸç‰¹å¾´é‡ =====&quot;)
print(f&quot;ç‰¹å¾´é‡æ•°: {len(feature_names)}&quot;)
print(f&quot;\næœ€åˆã®5ã¤ã®ç‰¹å¾´é‡:&quot;)
print(df_features.head())
print(f&quot;\nç‰¹å¾´é‡ã®ä¾‹:&quot;)
for i in range(min(5, len(feature_names))):
    print(f&quot;  {feature_names[i]}&quot;)
</code></pre>
<p><strong>Matminerã§æŠ½å‡ºã•ã‚Œã‚‹ç‰¹å¾´é‡ä¾‹ï¼š</strong>
- <code>MagpieData avg_dev MeltingT</code>ï¼šå¹³å‡èç‚¹ã®åå·®
- <code>MagpieData mean Electronegativity</code>ï¼šå¹³å‡é›»æ°—é™°æ€§åº¦
- <code>MagpieData mean AtomicWeight</code>ï¼šå¹³å‡åŸå­é‡
- <code>MagpieData range Number</code>ï¼šåŸå­ç•ªå·ã®ç¯„å›²
- åˆè¨ˆ130ä»¥ä¸Šã®ç‰¹å¾´é‡</p>
<h3>5.3 æ‰‹å‹•ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°</h3>
<pre><code class="language-python"># åŸºæœ¬ãƒ‡ãƒ¼ã‚¿
data_advanced = pd.DataFrame({
    'element_A': [0.5, 0.6, 0.7, 0.8],
    'element_B': [0.5, 0.4, 0.3, 0.2],
    'melting_point': [1200, 1250, 1300, 1350]
})

# æ–°ã—ã„ç‰¹å¾´é‡ã‚’ä½œæˆ
data_advanced['sum_AB'] = data_advanced['element_A'] + data_advanced['element_B']  # åˆè¨ˆï¼ˆå¸¸ã«1.0ï¼‰
data_advanced['diff_AB'] = abs(data_advanced['element_A'] - data_advanced['element_B'])  # å·®ã®çµ¶å¯¾å€¤
data_advanced['product_AB'] = data_advanced['element_A'] * data_advanced['element_B']  # ç©ï¼ˆç›¸äº’ä½œç”¨ï¼‰
data_advanced['ratio_AB'] = data_advanced['element_A'] / (data_advanced['element_B'] + 1e-10)  # æ¯”ç‡
data_advanced['A_squared'] = data_advanced['element_A'] ** 2  # äºŒä¹—é …ï¼ˆéç·šå½¢æ€§ï¼‰
data_advanced['B_squared'] = data_advanced['element_B'] ** 2

print(&quot;===== ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°å¾Œã®ãƒ‡ãƒ¼ã‚¿ =====&quot;)
print(data_advanced)
</code></pre>
<h3>5.4 ç‰¹å¾´é‡é‡è¦åº¦åˆ†æ</h3>
<pre><code class="language-python"># æ‹¡å¼µç‰¹å¾´é‡ã‚’ä½¿ç”¨ã—ã¦ãƒ¢ãƒ‡ãƒ«è¨“ç·´
X_advanced = data_advanced.drop('melting_point', axis=1)
y_advanced = data_advanced['melting_point']

# ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆã§è¨“ç·´
model_advanced = RandomForestRegressor(n_estimators=100, random_state=42)
model_advanced.fit(X_advanced, y_advanced)

# ç‰¹å¾´é‡é‡è¦åº¦ã‚’å–å¾—
importances = pd.DataFrame({
    'ç‰¹å¾´é‡': X_advanced.columns,
    'é‡è¦åº¦': model_advanced.feature_importances_
}).sort_values('é‡è¦åº¦', ascending=False)

print(&quot;===== ç‰¹å¾´é‡é‡è¦åº¦ =====&quot;)
print(importances)

# å¯è¦–åŒ–
plt.figure(figsize=(10, 6))
plt.barh(importances['ç‰¹å¾´é‡'], importances['é‡è¦åº¦'])
plt.xlabel('é‡è¦åº¦', fontsize=12)
plt.title('ç‰¹å¾´é‡é‡è¦åº¦ï¼ˆãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆï¼‰', fontsize=14)
plt.grid(True, alpha=0.3, axis='x')
plt.tight_layout()
plt.show()
</code></pre>
<h3>5.5 ç‰¹å¾´é‡é¸æŠ</h3>
<p><strong>ç›®çš„ï¼š</strong>
äºˆæ¸¬ã«å¯„ä¸ã—ãªã„ç‰¹å¾´é‡ã‚’å‰Šé™¤ï¼ˆéå­¦ç¿’é˜²æ­¢ã€è¨ˆç®—æ™‚é–“çŸ­ç¸®ï¼‰ã€‚</p>
<pre><code class="language-python">from sklearn.feature_selection import SelectKBest, f_regression

# SelectKBest: ä¸Šä½Kå€‹ã®ç‰¹å¾´é‡ã‚’é¸æŠ
selector = SelectKBest(score_func=f_regression, k=3)  # ä¸Šä½3å€‹
X_selected = selector.fit_transform(X_advanced, y_advanced)

# é¸ã°ã‚ŒãŸç‰¹å¾´é‡
selected_features = X_advanced.columns[selector.get_support()]
print(f&quot;é¸ã°ã‚ŒãŸç‰¹å¾´é‡: {list(selected_features)}&quot;)

# é¸æŠå¾Œã®ãƒ¢ãƒ‡ãƒ«è¨“ç·´
model_selected = RandomForestRegressor(n_estimators=100, random_state=42)
model_selected.fit(X_selected, y_advanced)

print(f&quot;ç‰¹å¾´é‡é¸æŠå‰: {X_advanced.shape[1]}å€‹&quot;)
print(f&quot;ç‰¹å¾´é‡é¸æŠå¾Œ: {X_selected.shape[1]}å€‹&quot;)
</code></pre>
<hr />
<h2>6. ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã‚¬ã‚¤ãƒ‰</h2>
<p>å®Ÿè·µã§é­é‡ã—ã‚„ã™ã„ã‚¨ãƒ©ãƒ¼ã¨è§£æ±ºç­–ã€‚</p>
<h3>6.1 ã‚ˆãã‚ã‚‹ã‚¨ãƒ©ãƒ¼ä¸€è¦§</h3>
<table>
<thead>
<tr>
<th>ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸</th>
<th>åŸå› </th>
<th>è§£æ±ºæ–¹æ³•</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>ModuleNotFoundError: No module named 'sklearn'</code></td>
<td>scikit-learnæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«</td>
<td><code>pip install scikit-learn</code></td>
</tr>
<tr>
<td><code>MemoryError</code></td>
<td>ãƒ¡ãƒ¢ãƒªä¸è¶³</td>
<td>ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºå‰Šæ¸›ã€ãƒãƒƒãƒå‡¦ç†ã€Google Colabåˆ©ç”¨</td>
</tr>
<tr>
<td><code>ConvergenceWarning: lbfgs failed to converge</code></td>
<td>MLPã®å­¦ç¿’ãŒåæŸã›ãš</td>
<td><code>max_iter</code>ã‚’å¢—ã‚„ã™ï¼ˆä¾‹ï¼š1000ï¼‰ã€å­¦ç¿’ç‡èª¿æ•´</td>
</tr>
<tr>
<td><code>ValueError: Input contains NaN</code></td>
<td>ãƒ‡ãƒ¼ã‚¿ã«æ¬ æå€¤</td>
<td><code>df.dropna()</code>ã§å‰Šé™¤ or <code>df.fillna()</code>ã§è£œå®Œ</td>
</tr>
<tr>
<td><code>ValueError: could not convert string to float</code></td>
<td>æ–‡å­—åˆ—ãƒ‡ãƒ¼ã‚¿ãŒå«ã¾ã‚Œã‚‹</td>
<td><code>pd.get_dummies()</code>ã§ãƒ€ãƒŸãƒ¼å¤‰æ•°åŒ–</td>
</tr>
<tr>
<td><code>RÂ² is negative</code></td>
<td>ãƒ¢ãƒ‡ãƒ«ãŒãƒ©ãƒ³ãƒ€ãƒ äºˆæ¸¬ã‚ˆã‚Šæ‚ªã„</td>
<td>ç‰¹å¾´é‡ã‚’è¦‹ç›´ã™ã€ãƒ¢ãƒ‡ãƒ«å¤‰æ›´</td>
</tr>
<tr>
<td><code>ZeroDivisionError</code></td>
<td>0é™¤ç®—</td>
<td>åˆ†æ¯ã«å°ã•ã„å€¤ã‚’è¿½åŠ ï¼ˆä¾‹ï¼š<code>x / (y + 1e-10)</code>ï¼‰</td>
</tr>
</tbody>
</table>
<h3>6.2 ãƒ‡ãƒãƒƒã‚°ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ</h3>
<p><strong>ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª</strong></p>
<pre><code class="language-python"># ãƒ‡ãƒ¼ã‚¿ã®åŸºæœ¬çµ±è¨ˆ
print(df.describe())

# æ¬ æå€¤ã®ç¢ºèª
print(df.isnull().sum())

# ãƒ‡ãƒ¼ã‚¿å‹ã®ç¢ºèª
print(df.dtypes)

# ç„¡é™å¤§ãƒ»NaNã®ç¢ºèª
print(df.isin([np.inf, -np.inf]).sum())
</code></pre>
<p><strong>ã‚¹ãƒ†ãƒƒãƒ—2: ãƒ‡ãƒ¼ã‚¿ã®å¯è¦–åŒ–</strong></p>
<pre><code class="language-python"># åˆ†å¸ƒã‚’ç¢ºèª
df.hist(figsize=(12, 8), bins=30)
plt.tight_layout()
plt.show()

# ç›¸é–¢è¡Œåˆ—
import seaborn as sns
plt.figure(figsize=(10, 8))
sns.heatmap(df.corr(), annot=True, cmap='coolwarm')
plt.title('ç›¸é–¢è¡Œåˆ—')
plt.show()
</code></pre>
<p><strong>ã‚¹ãƒ†ãƒƒãƒ—3: å°è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã§ãƒ†ã‚¹ãƒˆ</strong></p>
<pre><code class="language-python"># æœ€åˆã®10ä»¶ã ã‘ã§ãƒ†ã‚¹ãƒˆ
X_small = X[:10]
y_small = y[:10]

model_test = RandomForestRegressor(n_estimators=10)
model_test.fit(X_small, y_small)
print(&quot;å°è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã§ã®è¨“ç·´æˆåŠŸ&quot;)
</code></pre>
<p><strong>ã‚¹ãƒ†ãƒƒãƒ—4: ãƒ¢ãƒ‡ãƒ«ã®ç°¡ç•¥åŒ–</strong></p>
<pre><code class="language-python"># è¤‡é›‘ãªãƒ¢ãƒ‡ãƒ«ã§å¤±æ•—ã—ãŸã‚‰ã€ã¾ãšç·šå½¢å›å¸°ã§è©¦ã™
model_simple = LinearRegression()
model_simple.fit(X_train, y_train)
print(f&quot;ç·šå½¢å›å¸°ã®RÂ²: {model_simple.score(X_test, y_test):.4f}&quot;)
</code></pre>
<p><strong>ã‚¹ãƒ†ãƒƒãƒ—5: ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’èª­ã‚€</strong></p>
<pre><code class="language-python">try:
    model.fit(X_train, y_train)
except Exception as e:
    print(f&quot;ã‚¨ãƒ©ãƒ¼è©³ç´°: {type(e).__name__}&quot;)
    print(f&quot;ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: {str(e)}&quot;)
    import traceback
    traceback.print_exc()
</code></pre>
<h3>6.3 æ€§èƒ½ãŒä½ã„å ´åˆã®å¯¾å‡¦æ³•</h3>
<table>
<thead>
<tr>
<th>ç—‡çŠ¶</th>
<th>è€ƒãˆã‚‰ã‚Œã‚‹åŸå› </th>
<th>å¯¾å‡¦æ³•</th>
</tr>
</thead>
<tbody>
<tr>
<td>RÂ² &lt; 0.5</td>
<td>ç‰¹å¾´é‡ãŒä¸é©åˆ‡</td>
<td>ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã€Matmineråˆ©ç”¨</td>
</tr>
<tr>
<td>è¨“ç·´èª¤å·®ã¯å°ã€ãƒ†ã‚¹ãƒˆèª¤å·®ã¯å¤§</td>
<td>éå­¦ç¿’</td>
<td>æ­£å‰‡åŒ–å¼·åŒ–ã€ãƒ‡ãƒ¼ã‚¿è¿½åŠ ã€ãƒ¢ãƒ‡ãƒ«ç°¡ç•¥åŒ–</td>
</tr>
<tr>
<td>è¨“ç·´èª¤å·®ã‚‚ãƒ†ã‚¹ãƒˆèª¤å·®ã‚‚å¤§</td>
<td>æœªå­¦ç¿’</td>
<td>ãƒ¢ãƒ‡ãƒ«è¤‡é›‘åŒ–ã€ç‰¹å¾´é‡è¿½åŠ ã€å­¦ç¿’ç‡èª¿æ•´</td>
</tr>
<tr>
<td>äºˆæ¸¬å€¤ãŒå…¨ã¦åŒã˜</td>
<td>ãƒ¢ãƒ‡ãƒ«ãŒå­¦ç¿’ã§ãã¦ã„ãªã„</td>
<td>ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¦‹ç›´ã—ã€ç‰¹å¾´é‡ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°</td>
</tr>
<tr>
<td>è¨“ç·´ãŒé…ã„</td>
<td>ãƒ‡ãƒ¼ã‚¿é‡orãƒ¢ãƒ‡ãƒ«ãŒå¤§ãã„</td>
<td>ãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã€ãƒ¢ãƒ‡ãƒ«ç°¡ç•¥åŒ–ã€ä¸¦åˆ—åŒ–</td>
</tr>
</tbody>
</table>
<hr />
<h2>7. ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒãƒ£ãƒ¬ãƒ³ã‚¸ï¼šãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—äºˆæ¸¬</h2>
<p>å­¦ã‚“ã ã“ã¨ã‚’çµ±åˆã—ã€å®Ÿè·µçš„ãªãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«å–ã‚Šçµ„ã¿ã¾ã—ã‚‡ã†ã€‚</p>
<h3>7.1 ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ¦‚è¦</h3>
<p><strong>ç›®æ¨™ï¼š</strong>
çµ„æˆã‹ã‚‰ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—ã‚’äºˆæ¸¬ã™ã‚‹MIãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰</p>
<p><strong>ç›®æ¨™æ€§èƒ½ï¼š</strong>
- RÂ² &gt; 0.7ï¼ˆèª¬æ˜åŠ›70%ä»¥ä¸Šï¼‰
- MAE &lt; 0.5 eVï¼ˆèª¤å·®0.5 eVä»¥ä¸‹ï¼‰</p>
<p><strong>ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ï¼š</strong>
Materials Project APIï¼ˆã¾ãŸã¯æ¨¡æ“¬ãƒ‡ãƒ¼ã‚¿ï¼‰</p>
<h3>7.2 ã‚¹ãƒ†ãƒƒãƒ—ãƒã‚¤ã‚¹ãƒ†ãƒƒãƒ—ã‚¬ã‚¤ãƒ‰</h3>
<p><strong>Step 1: ãƒ‡ãƒ¼ã‚¿åé›†</strong></p>
<pre><code class="language-python"># Materials Project APIã‹ã‚‰ãƒ‡ãƒ¼ã‚¿å–å¾—ï¼ˆæ¨¡æ“¬ãƒ‡ãƒ¼ã‚¿ã§ä»£æ›¿å¯ï¼‰
# ç›®æ¨™ï¼š100ä»¶ä»¥ä¸Šã®é…¸åŒ–ç‰©ãƒ‡ãƒ¼ã‚¿

data_project = pd.DataFrame({
    'formula': ['Li2O', 'Na2O', 'MgO', 'Al2O3', 'SiO2'] * 20,
    'Li_ratio': [0.67, 0.0, 0.0, 0.0, 0.0] * 20,
    'O_ratio': [0.33, 0.67, 0.5, 0.6, 0.67] * 20,
    'band_gap': [7.5, 5.2, 7.8, 8.8, 9.0] * 20
})

# ãƒã‚¤ã‚ºè¿½åŠ ï¼ˆã‚ˆã‚Šç¾å®Ÿçš„ã«ï¼‰
np.random.seed(42)
data_project['band_gap'] += np.random.normal(0, 0.3, len(data_project))

print(f&quot;ãƒ‡ãƒ¼ã‚¿æ•°: {len(data_project)}&quot;)
</code></pre>
<p><strong>Step 2: ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°</strong></p>
<pre><code class="language-python"># å…ƒç´ æ¯”ç‡ã‹ã‚‰è¿½åŠ ç‰¹å¾´é‡ã‚’ä½œæˆ
# ï¼ˆå®Ÿéš›ã«ã¯Matminerã§åŸå­ç‰¹æ€§ã‚’è¿½åŠ ã™ã‚‹ã“ã¨ã‚’æ¨å¥¨ï¼‰

data_project['sum_elements'] = data_project['Li_ratio'] + data_project['O_ratio']
data_project['product_LiO'] = data_project['Li_ratio'] * data_project['O_ratio']
</code></pre>
<p><strong>Step 3: ãƒ‡ãƒ¼ã‚¿åˆ†å‰²</strong></p>
<pre><code class="language-python">X_project = data_project[['Li_ratio', 'O_ratio', 'sum_elements', 'product_LiO']]
y_project = data_project['band_gap']

X_train_proj, X_test_proj, y_train_proj, y_test_proj = train_test_split(
    X_project, y_project, test_size=0.2, random_state=42
)
</code></pre>
<p><strong>Step 4: ãƒ¢ãƒ‡ãƒ«é¸æŠã¨è¨“ç·´</strong></p>
<pre><code class="language-python"># ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆã‚’ä½¿ç”¨
model_project = RandomForestRegressor(
    n_estimators=200,
    max_depth=15,
    random_state=42
)
model_project.fit(X_train_proj, y_train_proj)
</code></pre>
<p><strong>Step 5: è©•ä¾¡</strong></p>
<pre><code class="language-python">y_pred_proj = model_project.predict(X_test_proj)
mae_proj = mean_absolute_error(y_test_proj, y_pred_proj)
r2_proj = r2_score(y_test_proj, y_pred_proj)

print(f&quot;===== ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆçµæœ =====&quot;)
print(f&quot;MAE: {mae_proj:.2f} eV&quot;)
print(f&quot;RÂ²: {r2_proj:.4f}&quot;)

if r2_proj &gt; 0.7 and mae_proj &lt; 0.5:
    print(&quot;ğŸ‰ ç›®æ¨™é”æˆï¼&quot;)
else:
    print(&quot;âŒ ç›®æ¨™æœªé”æˆã€‚ç‰¹å¾´é‡ã‚’è¿½åŠ ã—ã¦ãã ã•ã„ã€‚&quot;)
</code></pre>
<p><strong>Step 6: å¯è¦–åŒ–</strong></p>
<pre><code class="language-python">plt.figure(figsize=(10, 6))
plt.scatter(y_test_proj, y_pred_proj, alpha=0.6, s=100)
plt.plot([y_test_proj.min(), y_test_proj.max()],
         [y_test_proj.min(), y_test_proj.max()],
         'r--', lw=2, label='å®Œå…¨ãªäºˆæ¸¬')
plt.xlabel('å®Ÿæ¸¬ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ— (eV)', fontsize=12)
plt.ylabel('äºˆæ¸¬ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ— (eV)', fontsize=12)
plt.title('ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—äºˆæ¸¬ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ', fontsize=14)
plt.legend()
plt.grid(True, alpha=0.3)
plt.text(0.05, 0.95, f'RÂ² = {r2_proj:.3f}\nMAE = {mae_proj:.3f} eV',
         transform=plt.gca().transAxes, fontsize=12, verticalalignment='top',
         bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))
plt.tight_layout()
plt.show()
</code></pre>
<h3>7.3 ç™ºå±•èª²é¡Œ</h3>
<p><strong>åˆç´šï¼š</strong>
- åˆ¥ã®ææ–™ç‰¹æ€§ï¼ˆèç‚¹ã€å½¢æˆã‚¨ãƒãƒ«ã‚®ãƒ¼ï¼‰ã§äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰</p>
<p><strong>ä¸­ç´šï¼š</strong>
- Matminerã§130ä»¥ä¸Šã®ç‰¹å¾´é‡ã‚’æŠ½å‡ºã—ã€æ€§èƒ½å‘ä¸Šã‚’ç›®æŒ‡ã™
- äº¤å·®æ¤œè¨¼ã§ãƒ¢ãƒ‡ãƒ«ã®ä¿¡é ¼æ€§ã‚’è©•ä¾¡</p>
<p><strong>ä¸Šç´šï¼š</strong>
- Materials Project APIã‹ã‚‰å®Ÿãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
- ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å­¦ç¿’ï¼ˆè¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã®çµ„ã¿åˆã‚ã›ï¼‰
- ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼ˆMLPï¼‰ã§äºˆæ¸¬</p>
<hr />
<h2>8. ã¾ã¨ã‚</h2>
<h3>ã“ã®ç« ã§å­¦ã‚“ã ã“ã¨</h3>
<ol>
<li>
<p><strong>ç’°å¢ƒæ§‹ç¯‰</strong>
   - Anacondaã€venvã€Google Colabã®3ã¤ã®é¸æŠè‚¢
   - çŠ¶æ³ã«å¿œã˜ãŸæœ€é©ãªç’°å¢ƒã®é¸ã³æ–¹</p>
</li>
<li>
<p><strong>6ã¤ã®æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«</strong>
   - ç·šå½¢å›å¸°ï¼ˆBaselineï¼‰
   - ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆï¼ˆãƒãƒ©ãƒ³ã‚¹å‹ï¼‰
   - LightGBMï¼ˆé«˜ç²¾åº¦ï¼‰
   - SVRï¼ˆéç·šå½¢å¯¾å¿œï¼‰
   - MLPï¼ˆæ·±å±¤å­¦ç¿’ï¼‰
   - Materials Projectå®Ÿãƒ‡ãƒ¼ã‚¿çµ±åˆ</p>
</li>
<li>
<p><strong>ãƒ¢ãƒ‡ãƒ«é¸æŠã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³</strong>
   - ãƒ‡ãƒ¼ã‚¿æ•°ã€è¨ˆç®—æ™‚é–“ã€è§£é‡ˆæ€§ã«å¿œã˜ãŸæœ€é©ãƒ¢ãƒ‡ãƒ«
   - æ€§èƒ½æ¯”è¼ƒè¡¨ã¨ãƒ•ãƒ­ãƒ¼ãƒãƒ£ãƒ¼ãƒˆ</p>
</li>
<li>
<p><strong>ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°</strong>
   - Grid Searchã¨Random Search
   - ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®åŠ¹æœå¯è¦–åŒ–</p>
</li>
<li>
<p><strong>ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°</strong>
   - Matminerã«ã‚ˆã‚‹è‡ªå‹•æŠ½å‡º
   - æ‰‹å‹•ç‰¹å¾´é‡ä½œæˆï¼ˆç›¸äº’ä½œç”¨é …ã€äºŒä¹—é …ï¼‰
   - ç‰¹å¾´é‡é‡è¦åº¦ã¨é¸æŠ</p>
</li>
<li>
<p><strong>ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°</strong>
   - ã‚ˆãã‚ã‚‹ã‚¨ãƒ©ãƒ¼ã¨è§£æ±ºç­–
   - ãƒ‡ãƒãƒƒã‚°ã®5ã‚¹ãƒ†ãƒƒãƒ—</p>
</li>
<li>
<p><strong>å®Ÿè·µãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ</strong>
   - ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—äºˆæ¸¬ã®å®Œå…¨ãªå®Ÿè£…
   - ç›®æ¨™é”æˆã®ãŸã‚ã®ã‚¹ãƒ†ãƒƒãƒ—</p>
</li>
</ol>
<h3>æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—</h3>
<p><strong>ã“ã®ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã‚’çµ‚ãˆãŸã‚ãªãŸã¯ï¼š</strong>
- âœ… ææ–™ç‰¹æ€§äºˆæ¸¬ã®å®Ÿè£…ãŒã§ãã‚‹
- âœ… 5ã¤ä»¥ä¸Šã®ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã„åˆ†ã‘ã‚‰ã‚Œã‚‹
- âœ… ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãŒã§ãã‚‹
- âœ… ã‚¨ãƒ©ãƒ¼ã‚’è‡ªåŠ›ã§è§£æ±ºã§ãã‚‹</p>
<p><strong>æ¬¡ã«å­¦ã¶ã¹ãå†…å®¹ï¼š</strong>
1. <strong>æ·±å±¤å­¦ç¿’ã®å¿œç”¨</strong>
   - Graph Neural Networksï¼ˆGNNï¼‰
   - Crystal Graph Convolutional Networksï¼ˆCGCNNï¼‰</p>
<ol start="2">
<li>
<p><strong>ãƒ™ã‚¤ã‚ºæœ€é©åŒ–</strong>
   - å®Ÿé¨“å›æ•°ã‚’æœ€å°åŒ–ã™ã‚‹æ‰‹æ³•
   - Gaussian Processå›å¸°</p>
</li>
<li>
<p><strong>è»¢ç§»å­¦ç¿’</strong>
   - å°‘ãªã„ãƒ‡ãƒ¼ã‚¿ã§é«˜ç²¾åº¦ã‚’å®Ÿç¾
   - äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®æ´»ç”¨</p>
</li>
</ol>
<hr />
<h2>æ¼”ç¿’å•é¡Œ</h2>
<h3>å•é¡Œ1ï¼ˆé›£æ˜“åº¦ï¼šeasyï¼‰</h3>
<p>æœ¬ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã§å®Ÿè£…ã—ãŸ6ã¤ã®ãƒ¢ãƒ‡ãƒ«ã®ä¸­ã§ã€ãƒ‡ãƒ¼ã‚¿æ•°ãŒå°‘ãªã„å ´åˆï¼ˆ&lt; 100ä»¶ï¼‰ã«æœ€ã‚‚é©ã—ã¦ã„ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’é¸ã³ã€ç†ç”±ã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚</p>
<details>
<summary>ãƒ’ãƒ³ãƒˆ</summary>

éå­¦ç¿’ã®ãƒªã‚¹ã‚¯ã¨ãƒ¢ãƒ‡ãƒ«ã®è¤‡é›‘ã•ã‚’è€ƒæ…®ã—ã¾ã—ã‚‡ã†ã€‚

</details>

<details>
<summary>è§£ç­”ä¾‹</summary>

**ç­”ãˆï¼šç·šå½¢å›å¸°**

**ç†ç”±ï¼š**
1. **éå­¦ç¿’ã®ãƒªã‚¹ã‚¯ãŒä½ã„**ï¼šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ãŒå°‘ãªã„ãŸã‚ã€å°‘ãªã„ãƒ‡ãƒ¼ã‚¿ã§ã‚‚å®‰å®š
2. **è§£é‡ˆæ€§ãŒé«˜ã„**ï¼šä¿‚æ•°ã‚’è¦‹ã‚Œã°ç‰¹å¾´é‡ã®å½±éŸ¿ãŒåˆ†ã‹ã‚‹
3. **è¨“ç·´ãŒé«˜é€Ÿ**ï¼šè¨ˆç®—ã‚³ã‚¹ãƒˆãŒä½ã„

**ä»–ã®å€™è£œï¼šSVR**
- éç·šå½¢æ€§ãŒå¼·ã„å ´åˆã¯SVRã‚‚æœ‰åŠ¹
- ãŸã ã—ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´ãŒå¿…è¦

ãƒ‡ãƒ¼ã‚¿æ•°ãŒå°‘ãªã„å ´åˆã€è¤‡é›‘ãªãƒ¢ãƒ‡ãƒ«ï¼ˆãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆã€MLPï¼‰ã¯è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚’æš—è¨˜ã—ã¦ã—ã¾ã„ã€æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã§æ€§èƒ½ãŒå¤§å¹…ã«ä½ä¸‹ã—ã¾ã™ï¼ˆéå­¦ç¿’ï¼‰ã€‚

</details>

<hr />
<h3>å•é¡Œ2ï¼ˆé›£æ˜“åº¦ï¼šmediumï¼‰</h3>
<p>Grid Searchã¨Random Searchã‚’æ¯”è¼ƒã—ã€ã©ã®ã‚ˆã†ãªçŠ¶æ³ã§å„æ‰‹æ³•ã‚’ä½¿ã†ã¹ãã‹èª¬æ˜ã—ã¦ãã ã•ã„ã€‚</p>
<details>
<summary>ãƒ’ãƒ³ãƒˆ</summary>

æ¢ç´¢ç©ºé–“ã®å¤§ãã•ã¨è¨ˆç®—æ™‚é–“ã®åˆ¶ç´„ã‚’è€ƒæ…®ã—ã¾ã—ã‚‡ã†ã€‚

</details>

<details>
<summary>è§£ç­”ä¾‹</summary>

**Grid Search ã‚’ä½¿ã†ã¹ãçŠ¶æ³ï¼š**
1. **æ¢ç´¢ã™ã‚‹ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒå°‘ãªã„**ï¼ˆ2-3å€‹ï¼‰
2. **å„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å€™è£œãŒå°‘ãªã„**ï¼ˆå„3-5å€‹ç¨‹åº¦ï¼‰
3. **è¨ˆç®—æ™‚é–“ã«ä½™è£•ãŒã‚ã‚‹**
4. **æœ€è‰¯è§£ã‚’ç¢ºå®Ÿã«è¦‹ã¤ã‘ãŸã„**

**ä¾‹ï¼š** n_estimators=[50, 100, 200] Ã— max_depth=[5, 10, 15] = 9é€šã‚Š

**Random Search ã‚’ä½¿ã†ã¹ãçŠ¶æ³ï¼š**
1. **æ¢ç´¢ã™ã‚‹ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒå¤šã„**ï¼ˆ4å€‹ä»¥ä¸Šï¼‰
2. **å„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å€™è£œãŒå¤šã„/é€£ç¶šå€¤**
3. **è¨ˆç®—æ™‚é–“ãŒé™ã‚‰ã‚Œã¦ã„ã‚‹**
4. **ã‚ã‚‹ç¨‹åº¦è‰¯ã„è§£ãŒè¦‹ã¤ã‹ã‚Œã°ååˆ†**

**ä¾‹ï¼š** 5å€‹ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã€å„10å€™è£œ = 100,000é€šã‚Š â†’ Random Searchã§100å›ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°

**ä¸€èˆ¬çš„ãªæˆ¦ç•¥ï¼š**
1. ã¾ãšRandom Searchã§å¤§ã¾ã‹ãªç¯„å›²ã‚’çµã‚‹ï¼ˆ100-200å›ï¼‰
2. æœ‰æœ›ãªç¯„å›²ã‚’Grid Searchã§è©³ç´°æ¢ç´¢

</details>

<hr />
<h3>å•é¡Œ3ï¼ˆé›£æ˜“åº¦ï¼šmediumï¼‰</h3>
<p>ä»¥ä¸‹ã®ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚åŸå› ã¨è§£æ±ºæ–¹æ³•ã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚</p>
<pre><code>ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.
</code></pre>
<details>
<summary>ãƒ’ãƒ³ãƒˆ</summary>

MLPRegressor ã®è¨“ç·´ã§ç™ºç”Ÿã™ã‚‹ã‚¨ãƒ©ãƒ¼ã§ã™ã€‚

</details>

<details>
<summary>è§£ç­”ä¾‹</summary>

**åŸå› ï¼š**
MLPRegressorï¼ˆãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼‰ã®è¨“ç·´ãŒã€æŒ‡å®šã•ã‚ŒãŸã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ•°ï¼ˆmax_iterï¼‰ä»¥å†…ã«åæŸã—ãªã‹ã£ãŸã€‚

**è€ƒãˆã‚‰ã‚Œã‚‹è¦å› ï¼š**
1. max_iterãŒå°ã•ã™ãã‚‹ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ200ï¼‰
2. å­¦ç¿’ç‡ãŒå°ã•ã™ãã‚‹ï¼ˆå­¦ç¿’ãŒé…ã„ï¼‰
3. ãƒ‡ãƒ¼ã‚¿ã®ã‚¹ã‚±ãƒ¼ãƒ«ãŒä¸é©åˆ‡ï¼ˆæ¨™æº–åŒ–ã—ã¦ã„ãªã„ï¼‰
4. ãƒ¢ãƒ‡ãƒ«ãŒè¤‡é›‘ã™ãã‚‹ï¼ˆå±¤æ•°ãŒå¤šã„ã€ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³æ•°ãŒå¤šã„ï¼‰

**è§£æ±ºæ–¹æ³•ï¼š**

**æ–¹æ³•1: max_iterã‚’å¢—ã‚„ã™**

<pre><code class="language-python">model_mlp = MLPRegressor(max_iter=1000)  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ200â†’1000
</code></pre>


**æ–¹æ³•2: ãƒ‡ãƒ¼ã‚¿ã‚’æ¨™æº–åŒ–**

<pre><code class="language-python">from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)
</code></pre>


**æ–¹æ³•3: å­¦ç¿’ç‡ã‚’èª¿æ•´**

<pre><code class="language-python">model_mlp = MLPRegressor(
    learning_rate_init=0.01,  # å­¦ç¿’ç‡ã‚’ä¸Šã’ã‚‹
    max_iter=500
)
</code></pre>


**æ–¹æ³•4: Early Stoppingã‚’æœ‰åŠ¹åŒ–**

<pre><code class="language-python">model_mlp = MLPRegressor(
    early_stopping=True,  # æ¤œè¨¼èª¤å·®ãŒæ”¹å–„ã—ãªã‘ã‚Œã°åœæ­¢
    validation_fraction=0.2,
    max_iter=1000
)
</code></pre>


**æ¨å¥¨ã‚¢ãƒ—ãƒ­ãƒ¼ãƒï¼š**
ã¾ãšæ–¹æ³•2ï¼ˆãƒ‡ãƒ¼ã‚¿æ¨™æº–åŒ–ï¼‰ã‚’è©¦ã—ã€ãã‚Œã§ã‚‚åæŸã—ãªã‘ã‚Œã°æ–¹æ³•1ã¨4ã‚’ä½µç”¨ã€‚

</details>

<hr />
<h3>å•é¡Œ4ï¼ˆé›£æ˜“åº¦ï¼šhardï¼‰</h3>
<p>Matminerã‚’ä½¿ã£ã¦ã€çµ„æˆ <code>"Li2O"</code> ã‹ã‚‰5ã¤ä»¥ä¸Šã®ç‰¹å¾´é‡ã‚’æŠ½å‡ºã™ã‚‹ã‚³ãƒ¼ãƒ‰ã‚’æ›¸ã„ã¦ãã ã•ã„ã€‚</p>
<details>
<summary>ãƒ’ãƒ³ãƒˆ</summary>

`ElementProperty` featurizerã¨ `from_preset('magpie')` ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚

</details>

<details>
<summary>è§£ç­”ä¾‹</summary>


<pre><code class="language-python">from matminer.featurizers.composition import ElementProperty
from pymatgen.core import Composition
import pandas as pd

# çµ„æˆã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆ
comp = Composition(&quot;Li2O&quot;)

# Magpieãƒ—ãƒªã‚»ãƒƒãƒˆã§ç‰¹å¾´é‡æŠ½å‡ºå™¨ã‚’åˆæœŸåŒ–
featurizer = ElementProperty.from_preset('magpie')

# ç‰¹å¾´é‡ã‚’è¨ˆç®—
features = featurizer.featurize(comp)

# ç‰¹å¾´é‡åã‚’å–å¾—
feature_names = featurizer.feature_labels()

# DataFrameã«å¤‰æ›ï¼ˆè¦‹ã‚„ã™ãï¼‰
df = pd.DataFrame([features], columns=feature_names)

print(f&quot;===== Li2Oã®ç‰¹å¾´é‡ï¼ˆæœ€åˆã®5ã¤ï¼‰ =====&quot;)
for i in range(5):
    print(f&quot;{feature_names[i]}: {features[i]:.4f}&quot;)

print(f&quot;\nåˆè¨ˆç‰¹å¾´é‡æ•°: {len(features)}&quot;)
</code></pre>


**æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›ï¼š**

<pre><code>===== Li2Oã®ç‰¹å¾´é‡ï¼ˆæœ€åˆã®5ã¤ï¼‰ =====
MagpieData minimum Number: 3.0000
MagpieData maximum Number: 8.0000
MagpieData range Number: 5.0000
MagpieData mean Number: 5.3333
MagpieData avg_dev Number: 1.5556

åˆè¨ˆç‰¹å¾´é‡æ•°: 132
</code></pre>


**è§£èª¬ï¼š**
- `MagpieData minimum Number`: æœ€å°åŸå­ç•ªå·ï¼ˆLi: 3ï¼‰
- `MagpieData maximum Number`: æœ€å¤§åŸå­ç•ªå·ï¼ˆO: 8ï¼‰
- `MagpieData range Number`: åŸå­ç•ªå·ã®ç¯„å›²ï¼ˆ8-3=5ï¼‰
- `MagpieData mean Number`: å¹³å‡åŸå­ç•ªå·ï¼ˆ(3+3+8)/3=5.33ï¼‰
- `MagpieData avg_dev Number`: åŸå­ç•ªå·ã®å¹³å‡åå·®

Matminerã¯132å€‹ã®ç‰¹å¾´é‡ã‚’è‡ªå‹•æŠ½å‡ºã—ã¾ã™ï¼ˆé›»æ°—é™°æ€§åº¦ã€åŸå­åŠå¾„ã€èç‚¹ãªã©ï¼‰ã€‚

</details>

<hr />
<h3>å•é¡Œ5ï¼ˆé›£æ˜“åº¦ï¼šhardï¼‰</h3>
<p>ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§RÂ²ãŒ0.5ã—ã‹å‡ºã¾ã›ã‚“ã§ã—ãŸã€‚æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã®3ã¤ã®å…·ä½“çš„ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã—ã€ãã‚Œãã‚Œã®å®Ÿè£…æ–¹æ³•ã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚</p>
<details>
<summary>ãƒ’ãƒ³ãƒˆ</summary>

ç‰¹å¾´é‡ã€ãƒ¢ãƒ‡ãƒ«ã€ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®3ã¤ã®è¦³ç‚¹ã‹ã‚‰è€ƒãˆã¾ã—ã‚‡ã†ã€‚

</details>

<details>
<summary>è§£ç­”ä¾‹</summary>

**ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ1: ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ï¼ˆæœ€ã‚‚åŠ¹æœçš„ï¼‰**

**å®Ÿè£…æ–¹æ³•ï¼š**

<pre><code class="language-python">from matminer.featurizers.composition import ElementProperty
from pymatgen.core import Composition

# çµ„æˆã‹ã‚‰åŸå­ç‰¹æ€§ã‚’æŠ½å‡º
def extract_features(formula):
    comp = Composition(formula)
    featurizer = ElementProperty.from_preset('magpie')
    features = featurizer.featurize(comp)
    return features

# æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã«ç‰¹å¾´é‡ã‚’è¿½åŠ 
data_project['features'] = data_project['formula'].apply(extract_features)
# DataFrameã«å±•é–‹ï¼ˆ132æ¬¡å…ƒã®ç‰¹å¾´é‡ï¼‰
features_df = pd.DataFrame(data_project['features'].tolist())
X_enhanced = features_df  # å…ƒã®2æ¬¡å…ƒ â†’ 132æ¬¡å…ƒã«æ‹¡å¼µ
</code></pre>


**æœŸå¾…ã•ã‚Œã‚‹æ”¹å–„ï¼š**
RÂ² 0.5 â†’ 0.75-0.85ï¼ˆç‰¹å¾´é‡ãŒå¤§å¹…ã«å¢—ãˆã‚‹ãŸã‚ï¼‰

---

**ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ2: ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å­¦ç¿’ï¼ˆè¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã®çµ„ã¿åˆã‚ã›ï¼‰**

**å®Ÿè£…æ–¹æ³•ï¼š**

<pre><code class="language-python">from sklearn.ensemble import VotingRegressor

# 3ã¤ã®ãƒ¢ãƒ‡ãƒ«ã‚’çµ„ã¿åˆã‚ã›
model_rf = RandomForestRegressor(n_estimators=200, random_state=42)
model_lgb = lgb.LGBMRegressor(n_estimators=200, random_state=42)
model_svr = SVR(kernel='rbf', C=100)

# ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ¢ãƒ‡ãƒ«ï¼ˆå¹³å‡äºˆæ¸¬ï¼‰
ensemble = VotingRegressor([
    ('rf', model_rf),
    ('lgb', model_lgb),
    ('svr', model_svr)
])

ensemble.fit(X_train, y_train)
y_pred_ensemble = ensemble.predict(X_test)
</code></pre>


**æœŸå¾…ã•ã‚Œã‚‹æ”¹å–„ï¼š**
RÂ² 0.5 â†’ 0.6-0.7ï¼ˆå˜ä¸€ãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Šå®‰å®šï¼‰

---

**ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ3: ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°**

**å®Ÿè£…æ–¹æ³•ï¼š**

<pre><code class="language-python">from sklearn.model_selection import RandomizedSearchCV
from scipy.stats import randint

param_dist = {
    'n_estimators': randint(100, 500),
    'max_depth': randint(10, 50),
    'min_samples_split': randint(2, 20),
    'min_samples_leaf': randint(1, 10)
}

random_search = RandomizedSearchCV(
    RandomForestRegressor(random_state=42),
    param_distributions=param_dist,
    n_iter=100,  # 100é€šã‚Šè©¦ã™
    cv=5,
    scoring='neg_mean_absolute_error',
    n_jobs=-1,
    random_state=42
)

random_search.fit(X_train, y_train)
best_model = random_search.best_estimator_
</code></pre>


**æœŸå¾…ã•ã‚Œã‚‹æ”¹å–„ï¼š**
RÂ² 0.5 â†’ 0.55-0.65ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚ˆã‚Šæœ€é©åŒ–ï¼‰

---

**æœ€é©ãªæˆ¦ç•¥ï¼š**
1. ã¾ãš**ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ1**ï¼ˆç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ï¼‰ã‚’å®Ÿæ–½ â†’ æœ€å¤§ã®åŠ¹æœ
2. æ¬¡ã«**ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ3**ï¼ˆãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ï¼‰ã§å¾®èª¿æ•´
3. æœ€å¾Œã«**ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ2**ï¼ˆã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ï¼‰ã§æœ€çµ‚çš„ãªæ€§èƒ½å‘ä¸Š

ã“ã®é †åºã§ã€RÂ² 0.5 â†’ 0.8ä»¥ä¸Šã‚’ç›®æŒ‡ã›ã¾ã™ã€‚

</details>

<hr />
<h2>9. ç« æœ«ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆï¼šå®Ÿè£…ã‚¹ã‚­ãƒ«ã®å“è³ªä¿è¨¼</h2>
<p>å®Ÿè·µçš„ãªææ–™ç‰¹æ€§äºˆæ¸¬ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’å®Œé‚ã™ã‚‹ãŸã‚ã«å¿…è¦ãªã‚¹ã‚­ãƒ«ã‚’ç¶²ç¾…çš„ã«ãƒã‚§ãƒƒã‚¯ã—ã¾ã™ã€‚</p>
<h3>9.1 ç’°å¢ƒæ§‹ç¯‰ã‚¹ã‚­ãƒ«ï¼ˆEnvironment Setupï¼‰</h3>
<h4>åŸºç¤ãƒ¬ãƒ™ãƒ«</h4>
<ul>
<li>[ ] Python 3.9ä»¥ä¸ŠãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹</li>
<li>[ ] 3ã¤ã®ç’°å¢ƒæ§‹ç¯‰ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼ˆAnaconda/venv/Colabï¼‰ã®é•ã„ã‚’èª¬æ˜ã§ãã‚‹</li>
<li>[ ] è‡ªåˆ†ã®çŠ¶æ³ã«æœ€é©ãªç’°å¢ƒã‚’é¸æŠã§ãã‚‹</li>
<li>[ ] ä»®æƒ³ç’°å¢ƒã‚’ä½œæˆãƒ»æœ‰åŠ¹åŒ–ãƒ»ç„¡åŠ¹åŒ–ã§ãã‚‹</li>
<li>[ ] pip/condaã§ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã§ãã‚‹</li>
<li>[ ] ç’°å¢ƒæ¤œè¨¼ã‚³ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œã—ã€ã‚¨ãƒ©ãƒ¼ãªãå‹•ä½œç¢ºèªã§ãã‚‹</li>
</ul>
<h4>å¿œç”¨ãƒ¬ãƒ™ãƒ«</h4>
<ul>
<li>[ ] requirements.txtã‚’ä½œæˆãƒ»ä½¿ç”¨ã§ãã‚‹ï¼ˆ<code>pip freeze &gt; requirements.txt</code>ï¼‰</li>
<li>[ ] ç’°å¢ƒå¤‰æ•°ï¼ˆ.envï¼‰ã‚’è¨­å®šã—ã€APIã‚­ãƒ¼ã‚’å®‰å…¨ã«ç®¡ç†ã§ãã‚‹</li>
<li>[ ] Google Colabã§Google Driveã‚’ãƒã‚¦ãƒ³ãƒˆã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚ã‚‹</li>
<li>[ ] è¤‡æ•°ã®ä»®æƒ³ç’°å¢ƒã‚’ç”¨é€”åˆ¥ã«ä½¿ã„åˆ†ã‘ã‚‰ã‚Œã‚‹</li>
<li>[ ] ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã‚¨ãƒ©ãƒ¼ã‚’è‡ªåŠ›ã§ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã§ãã‚‹</li>
</ul>
<hr />
<h3>9.2 ãƒ¢ãƒ‡ãƒ«å®Ÿè£…ã‚¹ã‚­ãƒ«ï¼ˆModel Implementationï¼‰</h3>
<h4>åŸºç¤ãƒ¬ãƒ™ãƒ«ï¼ˆ6ã¤ã®ãƒ¢ãƒ‡ãƒ«å®Ÿè£…ï¼‰</h4>
<ul>
<li>[ ] ç·šå½¢å›å¸°ã‚’å®Ÿè£…ã—ã€ä¿‚æ•°ã®æ„å‘³ã‚’èª¬æ˜ã§ãã‚‹</li>
<li>[ ] ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆã‚’å®Ÿè£…ã—ã€<code>n_estimators</code>ã®å½¹å‰²ã‚’èª¬æ˜ã§ãã‚‹</li>
<li>[ ] LightGBMã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãƒ»å®Ÿè£…ã§ãã‚‹</li>
<li>[ ] SVRã§æ¨™æº–åŒ–ï¼ˆStandardScalerï¼‰ã®å¿…è¦æ€§ã‚’ç†è§£ã—ã¦ã„ã‚‹</li>
<li>[ ] MLPRegressorï¼ˆãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼‰ã‚’å®Ÿè£…ã§ãã‚‹</li>
<li>[ ] Materials Project APIã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã§ãã‚‹ï¼ˆã¾ãŸã¯æ¨¡æ“¬ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆã§ãã‚‹ï¼‰</li>
</ul>
<h4>å¿œç”¨ãƒ¬ãƒ™ãƒ«ï¼ˆãƒ¢ãƒ‡ãƒ«é¸æŠã¨è©•ä¾¡ï¼‰</h4>
<ul>
<li>[ ] ãƒ‡ãƒ¼ã‚¿æ•°ãƒ»è¨ˆç®—æ™‚é–“ãƒ»è§£é‡ˆæ€§ã®åˆ¶ç´„ã‹ã‚‰æœ€é©ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã§ãã‚‹</li>
<li>[ ] MAEã€RÂ²ã€è¨“ç·´æ™‚é–“ã®3è»¸ã§ãƒ¢ãƒ‡ãƒ«ã‚’æ¯”è¼ƒã§ãã‚‹</li>
<li>[ ] ç·šå½¢å›å¸°ã®RÂ² &lt; 0.5ã®å ´åˆã€éç·šå½¢ãƒ¢ãƒ‡ãƒ«ã®å¿…è¦æ€§ã‚’åˆ¤æ–­ã§ãã‚‹</li>
<li>[ ] OOBã‚¹ã‚³ã‚¢ï¼ˆãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆï¼‰ã§éå­¦ç¿’ã‚’æ¤œå‡ºã§ãã‚‹</li>
<li>[ ] å­¦ç¿’æ›²ç·šã‚’å¯è¦–åŒ–ã—ã€è¨“ç·´ã®åæŸçŠ¶æ³ã‚’ç¢ºèªã§ãã‚‹</li>
</ul>
<h4>ä¸Šç´šãƒ¬ãƒ™ãƒ«ï¼ˆã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã¨å¿œç”¨ï¼‰</h4>
<ul>
<li>[ ] VotingRegressorã§è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã‚’çµ„ã¿åˆã‚ã›ã‚‰ã‚Œã‚‹</li>
<li>[ ] Stackingã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã‚’å®Ÿè£…ã§ãã‚‹</li>
<li>[ ] äº¤å·®æ¤œè¨¼ï¼ˆ5-fold CVï¼‰ã§ãƒ¢ãƒ‡ãƒ«ã®æ±åŒ–æ€§èƒ½ã‚’è©•ä¾¡ã§ãã‚‹</li>
<li>[ ] äºˆæ¸¬åŒºé–“ï¼ˆconfidence intervalï¼‰ã‚’è¨ˆç®—ã§ãã‚‹</li>
</ul>
<hr />
<h3>9.3 ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¹ã‚­ãƒ«ï¼ˆHyperparameter Tuningï¼‰</h3>
<h4>åŸºç¤ãƒ¬ãƒ™ãƒ«</h4>
<ul>
<li>[ ] ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®é•ã„ã‚’èª¬æ˜ã§ãã‚‹</li>
<li>[ ] GridSearchCVã‚’å®Ÿè£…ã—ã€æœ€è‰¯ã®ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¦‹ã¤ã‘ã‚‰ã‚Œã‚‹</li>
<li>[ ] RandomizedSearchCVã‚’å®Ÿè£…ã—ã€Grid Searchã¨ã®é•ã„ã‚’èª¬æ˜ã§ãã‚‹</li>
<li>[ ] <code>cv=5</code>ï¼ˆ5-foldäº¤å·®æ¤œè¨¼ï¼‰ã®æ„å‘³ã‚’ç†è§£ã—ã¦ã„ã‚‹</li>
<li>[ ] <code>best_params_</code>ã§æœ€è‰¯ã®çµ„ã¿åˆã‚ã›ã‚’å–å¾—ã§ãã‚‹</li>
<li>[ ] <code>best_score_</code>ã§äº¤å·®æ¤œè¨¼ã‚¹ã‚³ã‚¢ã‚’ç¢ºèªã§ãã‚‹</li>
</ul>
<h4>å¿œç”¨ãƒ¬ãƒ™ãƒ«</h4>
<ul>
<li>[ ] ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆã®ä¸»è¦ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿4ã¤ä»¥ä¸Šã‚’èª¬æ˜ã§ãã‚‹</li>
<li><code>n_estimators</code>: æ±ºå®šæœ¨ã®æ•°</li>
<li><code>max_depth</code>: æœ¨ã®æ·±ã•</li>
<li><code>min_samples_split</code>: åˆ†å²ã®æœ€å°ã‚µãƒ³ãƒ—ãƒ«æ•°</li>
<li><code>min_samples_leaf</code>: è‘‰ãƒãƒ¼ãƒ‰ã®æœ€å°ã‚µãƒ³ãƒ—ãƒ«æ•°</li>
<li>[ ] LightGBMã®<code>learning_rate</code>ã¨<code>n_estimators</code>ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’ç†è§£ã—ã¦ã„ã‚‹</li>
<li>[ ] Early Stoppingã‚’å®Ÿè£…ã—ã€éå­¦ç¿’ã‚’é˜²æ­¢ã§ãã‚‹</li>
<li>[ ] ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å½±éŸ¿ã‚’å¯è¦–åŒ–ã§ãã‚‹</li>
</ul>
<h4>ä¸Šç´šãƒ¬ãƒ™ãƒ«</h4>
<ul>
<li>[ ] Bayesian Optimizationï¼ˆOptunaãªã©ï¼‰ã‚’å®Ÿè£…ã§ãã‚‹</li>
<li>[ ] ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æ¢ç´¢ç¯„å›²ã‚’ç†è«–çš„ã«æ±ºå®šã§ãã‚‹</li>
<li>[ ] Nested Cross-Validationï¼ˆäºŒé‡äº¤å·®æ¤œè¨¼ï¼‰ã‚’å®Ÿè£…ã§ãã‚‹</li>
</ul>
<hr />
<h3>9.4 ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã‚¹ã‚­ãƒ«ï¼ˆFeature Engineeringï¼‰</h3>
<h4>åŸºç¤ãƒ¬ãƒ™ãƒ«</h4>
<ul>
<li>[ ] å…ƒç´ æ¯”ç‡ã‹ã‚‰æ–°ã—ã„ç‰¹å¾´é‡ï¼ˆå’Œã€å·®ã€ç©ã€æ¯”ï¼‰ã‚’ä½œæˆã§ãã‚‹</li>
<li>[ ] ç‰¹å¾´é‡é‡è¦åº¦ï¼ˆfeature_importances_ï¼‰ã‚’å–å¾—ãƒ»å¯è¦–åŒ–ã§ãã‚‹</li>
<li>[ ] é‡è¦åº¦ä¸‹ä½ã®ç‰¹å¾´é‡ã‚’å‰Šé™¤ã§ãã‚‹</li>
<li>[ ] SelectKBestã§ä¸Šä½Kå€‹ã®ç‰¹å¾´é‡ã‚’é¸æŠã§ãã‚‹</li>
</ul>
<h4>å¿œç”¨ãƒ¬ãƒ™ãƒ«ï¼ˆMatmineræ´»ç”¨ï¼‰</h4>
<ul>
<li>[ ] Matminerã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãƒ»ã‚¤ãƒ³ãƒãƒ¼ãƒˆã§ãã‚‹</li>
<li>[ ] ElementProperty featurizerã§çµ„æˆã‹ã‚‰ç‰¹å¾´é‡ã‚’æŠ½å‡ºã§ãã‚‹</li>
<li>[ ] <code>from_preset('magpie')</code>ã§132æ¬¡å…ƒã®ç‰¹å¾´é‡ã‚’è‡ªå‹•ç”Ÿæˆã§ãã‚‹</li>
<li>[ ] æŠ½å‡ºã—ãŸç‰¹å¾´é‡ã‚’DataFrameã«çµ±åˆã—ã€æ©Ÿæ¢°å­¦ç¿’ã«ä½¿ç”¨ã§ãã‚‹</li>
<li>[ ] Matminerã®ç‰¹å¾´é‡ï¼ˆé›»æ°—é™°æ€§åº¦ã€åŸå­åŠå¾„ã€èç‚¹ãªã©ï¼‰ã®æ„å‘³ã‚’ç†è§£ã—ã¦ã„ã‚‹</li>
</ul>
<h4>ä¸Šç´šãƒ¬ãƒ™ãƒ«</h4>
<ul>
<li>[ ] è¤‡æ•°ã®featurizerï¼ˆElementPropertyã€Stoichiometryã€OxidationStatesï¼‰ã‚’çµ„ã¿åˆã‚ã›ã‚‰ã‚Œã‚‹</li>
<li>[ ] ãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜ã‚’æ´»ç”¨ã—ã¦ææ–™ç‰¹æœ‰ã®ç‰¹å¾´é‡ã‚’è¨­è¨ˆã§ãã‚‹</li>
<li>[ ] å¤šé‡å…±ç·šæ€§ï¼ˆVIF: Variance Inflation Factorï¼‰ã‚’æ¤œå‡ºãƒ»å¯¾å‡¦ã§ãã‚‹</li>
<li>[ ] æ¬¡å…ƒå‰Šæ¸›ï¼ˆPCAã€t-SNEï¼‰ã‚’å®Ÿè£…ã—ã€ç‰¹å¾´é‡ã‚’å¯è¦–åŒ–ã§ãã‚‹</li>
</ul>
<hr />
<h3>9.5 ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚¹ã‚­ãƒ«ï¼ˆData Processingï¼‰</h3>
<h4>åŸºç¤ãƒ¬ãƒ™ãƒ«</h4>
<ul>
<li>[ ] train_test_splitã§ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†å‰²ã§ãã‚‹ï¼ˆ80% vs 20%ï¼‰</li>
<li>[ ] <code>random_state=42</code>ã§å†ç¾æ€§ã‚’ç¢ºä¿ã—ã¦ã„ã‚‹</li>
<li>[ ] ãƒ‡ãƒ¼ã‚¿ã®åŸºæœ¬çµ±è¨ˆï¼ˆmeanã€stdã€minã€maxï¼‰ã‚’ç¢ºèªã§ãã‚‹</li>
<li>[ ] æ¬ æå€¤ï¼ˆNaNï¼‰ã‚’æ¤œå‡ºã§ãã‚‹ï¼ˆ<code>df.isnull().sum()</code>ï¼‰</li>
<li>[ ] æ¬ æå€¤ã‚’å‰Šé™¤ã¾ãŸã¯è£œå®Œã§ãã‚‹ï¼ˆ<code>dropna()</code> or <code>fillna()</code>ï¼‰</li>
</ul>
<h4>å¿œç”¨ãƒ¬ãƒ™ãƒ«</h4>
<ul>
<li>[ ] StandardScalerã§ãƒ‡ãƒ¼ã‚¿ã‚’æ¨™æº–åŒ–ã§ãã‚‹ï¼ˆå¹³å‡0ã€æ¨™æº–åå·®1ï¼‰</li>
<li>[ ] MinMaxScalerã§0-1ã«æ­£è¦åŒ–ã§ãã‚‹</li>
<li>[ ] ã‚«ãƒ†ã‚´ãƒªå¤‰æ•°ã‚’ãƒ€ãƒŸãƒ¼å¤‰æ•°åŒ–ã§ãã‚‹ï¼ˆ<code>pd.get_dummies()</code>ï¼‰</li>
<li>[ ] å¤–ã‚Œå€¤ã‚’æ¤œå‡ºãƒ»å‡¦ç†ã§ãã‚‹ï¼ˆIQRæ³•ã€Z-scoreæ³•ï¼‰</li>
<li>[ ] ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯ï¼ˆData Leakageï¼‰ã‚’é˜²ãæ­£ã—ã„å‰å‡¦ç†é †åºã‚’ç†è§£ã—ã¦ã„ã‚‹</li>
<li>âŒ é–“é•ã„: å…¨ãƒ‡ãƒ¼ã‚¿ã§æ¨™æº–åŒ– â†’ åˆ†å‰²</li>
<li>âœ… æ­£ã—ã„: åˆ†å‰² â†’ è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã§æ¨™æº–åŒ– â†’ ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«é©ç”¨</li>
</ul>
<h4>ä¸Šç´šãƒ¬ãƒ™ãƒ«</h4>
<ul>
<li>[ ] SMOTEï¼ˆéã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼‰ã§ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ã§ãã‚‹</li>
<li>[ ] æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã§æ™‚é–“é †åˆ†å‰²ï¼ˆTimeSeriesSplitï¼‰ã‚’å®Ÿè£…ã§ãã‚‹</li>
<li>[ ] Pipelineï¼ˆsklearn.pipelineï¼‰ã§ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã¨ãƒ¢ãƒ‡ãƒ«è¨“ç·´ã‚’çµ±åˆã§ãã‚‹</li>
</ul>
<hr />
<h3>9.6 è©•ä¾¡ãƒ»å¯è¦–åŒ–ã‚¹ã‚­ãƒ«ï¼ˆEvaluation &amp; Visualizationï¼‰</h3>
<h4>åŸºç¤ãƒ¬ãƒ™ãƒ«</h4>
<ul>
<li>[ ] MAEï¼ˆå¹³å‡çµ¶å¯¾èª¤å·®ï¼‰ã‚’è¨ˆç®—ãƒ»è§£é‡ˆã§ãã‚‹</li>
<li>[ ] RÂ²ï¼ˆæ±ºå®šä¿‚æ•°ï¼‰ã‚’è¨ˆç®—ãƒ»è§£é‡ˆã§ãã‚‹ï¼ˆ1ã«è¿‘ã„ã»ã©è‰¯ã„ï¼‰</li>
<li>[ ] è¨“ç·´æ™‚é–“ã‚’æ¸¬å®šã§ãã‚‹ï¼ˆ<code>time.time()</code>ï¼‰</li>
<li>[ ] äºˆæ¸¬å€¤ vs å®Ÿæ¸¬å€¤ã®æ•£å¸ƒå›³ã‚’ä½œæˆã§ãã‚‹</li>
<li>[ ] ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½æ¯”è¼ƒè¡¨ã‚’ä½œæˆã§ãã‚‹</li>
</ul>
<h4>å¿œç”¨ãƒ¬ãƒ™ãƒ«</h4>
<ul>
<li>[ ] å­¦ç¿’æ›²ç·šï¼ˆLoss curveï¼‰ã‚’å¯è¦–åŒ–ã§ãã‚‹</li>
<li>[ ] æ®‹å·®ãƒ—ãƒ­ãƒƒãƒˆï¼ˆResidual plotï¼‰ã‚’ä½œæˆã—ã€ãƒ¢ãƒ‡ãƒ«ã®åã‚Šã‚’æ¤œå‡ºã§ãã‚‹</li>
<li>[ ] æ··åŒè¡Œåˆ—ï¼ˆåˆ†é¡å•é¡Œã®å ´åˆï¼‰ã‚’ä½œæˆãƒ»è§£é‡ˆã§ãã‚‹</li>
<li>[ ] ç‰¹å¾´é‡é‡è¦åº¦ã‚’ã‚°ãƒ©ãƒ•åŒ–ã§ãã‚‹</li>
<li>[ ] ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å½±éŸ¿ã‚’2æ¬¡å…ƒãƒ—ãƒ­ãƒƒãƒˆã§å¯è¦–åŒ–ã§ãã‚‹</li>
</ul>
<h4>ä¸Šç´šãƒ¬ãƒ™ãƒ«</h4>
<ul>
<li>[ ] SHAPå€¤ã§ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬ç†ç”±ã‚’èª¬æ˜ã§ãã‚‹</li>
<li>[ ] Partial Dependence Plotï¼ˆPDPï¼‰ã§ç‰¹å¾´é‡ã®å½±éŸ¿ã‚’å¯è¦–åŒ–ã§ãã‚‹</li>
<li>[ ] Learning Curveã§è¨“ç·´ãƒ‡ãƒ¼ã‚¿é‡ã®å½±éŸ¿ã‚’åˆ†æã§ãã‚‹</li>
</ul>
<hr />
<h3>9.7 ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã‚¹ã‚­ãƒ«ï¼ˆTroubleshootingï¼‰</h3>
<h4>åŸºç¤ãƒ¬ãƒ™ãƒ«ï¼ˆã‚¨ãƒ©ãƒ¼å¯¾å‡¦ï¼‰</h4>
<ul>
<li>[ ] <code>ModuleNotFoundError</code>ã‚’è§£æ±ºã§ãã‚‹ï¼ˆ<code>pip install</code>ï¼‰</li>
<li>[ ] <code>ValueError: Input contains NaN</code>ã‚’è§£æ±ºã§ãã‚‹ï¼ˆæ¬ æå€¤å‡¦ç†ï¼‰</li>
<li>[ ] <code>ConvergenceWarning</code>ï¼ˆMLPã®åæŸã‚¨ãƒ©ãƒ¼ï¼‰ã‚’è§£æ±ºã§ãã‚‹</li>
<li><code>max_iter</code>ã‚’å¢—ã‚„ã™</li>
<li>ãƒ‡ãƒ¼ã‚¿ã‚’æ¨™æº–åŒ–ã™ã‚‹</li>
<li>Early Stoppingã‚’æœ‰åŠ¹åŒ–</li>
<li>[ ] ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’èª­ã¿ã€æ¤œç´¢ã—ã¦è§£æ±ºç­–ã‚’è¦‹ã¤ã‘ã‚‰ã‚Œã‚‹</li>
</ul>
<h4>å¿œç”¨ãƒ¬ãƒ™ãƒ«ï¼ˆæ€§èƒ½æ”¹å–„ï¼‰</h4>
<ul>
<li>[ ] RÂ² &lt; 0.5ã®å ´åˆã€3ã¤ä»¥ä¸Šã®æ”¹å–„ç­–ã‚’å®Ÿè¡Œã§ãã‚‹</li>
<li>ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°</li>
<li>ãƒ¢ãƒ‡ãƒ«å¤‰æ›´ï¼ˆç·šå½¢â†’éç·šå½¢ï¼‰</li>
<li>ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°</li>
<li>[ ] éå­¦ç¿’ã‚’æ¤œå‡ºã§ãã‚‹ï¼ˆè¨“ç·´èª¤å·® â‰ª ãƒ†ã‚¹ãƒˆèª¤å·®ï¼‰</li>
<li>[ ] æœªå­¦ç¿’ã‚’æ¤œå‡ºã§ãã‚‹ï¼ˆè¨“ç·´èª¤å·®ã‚‚ãƒ†ã‚¹ãƒˆèª¤å·®ã‚‚å¤§ãã„ï¼‰</li>
<li>[ ] ãƒ‡ãƒãƒƒã‚°ã®5ã‚¹ãƒ†ãƒƒãƒ—ã‚’å®Ÿè¡Œã§ãã‚‹
  1. ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª
  2. ãƒ‡ãƒ¼ã‚¿ã®å¯è¦–åŒ–
  3. å°è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã§ãƒ†ã‚¹ãƒˆ
  4. ãƒ¢ãƒ‡ãƒ«ã®ç°¡ç•¥åŒ–
  5. ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’èª­ã‚€</li>
</ul>
<h4>ä¸Šç´šãƒ¬ãƒ™ãƒ«ï¼ˆä½“ç³»çš„ãƒ‡ãƒãƒƒã‚°ï¼‰</h4>
<ul>
<li>[ ] ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ï¼ˆcProfileï¼‰ã§å®Ÿè¡Œæ™‚é–“ã®ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã‚’ç‰¹å®šã§ãã‚‹</li>
<li>[ ] ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’ç›£è¦–ã—ã€MemoryErrorã‚’äºˆé˜²ã§ãã‚‹</li>
<li>[ ] ãƒ­ã‚°å‡ºåŠ›ï¼ˆloggingï¼‰ã‚’è¨­å®šã—ã€è¨“ç·´éç¨‹ã‚’è¨˜éŒ²ã§ãã‚‹</li>
<li>[ ] ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ï¼ˆGitï¼‰ã§å®Ÿé¨“ã‚’è¿½è·¡ã§ãã‚‹</li>
</ul>
<hr />
<h3>9.8 ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå®Œé‚ã‚¹ã‚­ãƒ«ï¼ˆProject Completionï¼‰</h3>
<h4>å¿…é ˆã‚¹ã‚­ãƒ«ï¼ˆãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—äºˆæ¸¬ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆï¼‰</h4>
<ul>
<li>[ ] ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç›®æ¨™ã‚’ç†è§£ã—ã¦ã„ã‚‹ï¼ˆRÂ² &gt; 0.7ã€MAE &lt; 0.5 eVï¼‰</li>
<li>[ ] ãƒ‡ãƒ¼ã‚¿åé›†ï¼ˆMaterials Project API or æ¨¡æ“¬ãƒ‡ãƒ¼ã‚¿ï¼‰ã‚’å®Œäº†ã—ãŸ</li>
<li>[ ] ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã‚’å®Ÿæ–½ã—ãŸ</li>
<li>[ ] ãƒ‡ãƒ¼ã‚¿ã‚’è¨“ç·´/ãƒ†ã‚¹ãƒˆã«åˆ†å‰²ã—ãŸï¼ˆ80% vs 20%ï¼‰</li>
<li>[ ] ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆã¾ãŸã¯LightGBMã§äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã—ãŸ</li>
<li>[ ] MAEã€RÂ²ã§æ€§èƒ½ã‚’è©•ä¾¡ã—ãŸ</li>
<li>[ ] äºˆæ¸¬çµæœã‚’å¯è¦–åŒ–ã—ãŸï¼ˆæ•£å¸ƒå›³ï¼‰</li>
<li>[ ] ç›®æ¨™é”æˆ/æœªé”æˆã‚’åˆ¤å®šã—ãŸ</li>
</ul>
<h4>ç™ºå±•ã‚¹ã‚­ãƒ«</h4>
<ul>
<li>[ ] åˆç´šèª²é¡Œ: åˆ¥ã®ç‰¹æ€§ï¼ˆèç‚¹ã€å½¢æˆã‚¨ãƒãƒ«ã‚®ãƒ¼ï¼‰ã§äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰</li>
<li>[ ] ä¸­ç´šèª²é¡Œ: Matminerã§130ä»¥ä¸Šã®ç‰¹å¾´é‡ã‚’æŠ½å‡ºã—ã€æ€§èƒ½å‘ä¸Š</li>
<li>[ ] ä¸Šç´šèª²é¡Œ: ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å­¦ç¿’ã§æ€§èƒ½å‘ä¸Š</li>
<li>[ ] ä¸Šç´šèª²é¡Œ: ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼ˆMLPï¼‰ã§äºˆæ¸¬</li>
</ul>
<hr />
<h3>9.9 ã‚³ãƒ¼ãƒ‰å“è³ªã‚¹ã‚­ãƒ«ï¼ˆCode Qualityï¼‰</h3>
<h4>åŸºç¤ãƒ¬ãƒ™ãƒ«</h4>
<ul>
<li>[ ] ã™ã¹ã¦ã®ã‚³ãƒ¼ãƒ‰ã«ä¾å­˜ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ã‚³ãƒ¡ãƒ³ãƒˆè¨˜è¼‰ã—ã¦ã„ã‚‹
  <code>python
  # Dependencies: Python 3.9+, scikit-learn 1.3+, numpy 1.24+</code></li>
<li>[ ] ä¹±æ•°ã‚·ãƒ¼ãƒ‰ã‚’å›ºå®šã—ã¦å†ç¾æ€§ã‚’ç¢ºä¿ã—ã¦ã„ã‚‹ï¼ˆ<code>random_state=42</code>ï¼‰</li>
<li>[ ] ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ï¼ˆshapeã€dtypeã€NaNã€ç¯„å›²ï¼‰ã‚’å®Ÿæ–½ã—ã¦ã„ã‚‹</li>
<li>[ ] å¤‰æ•°åãŒåˆ†ã‹ã‚Šã‚„ã™ã„ï¼ˆ<code>X_train</code>ã€<code>y_test</code>ã€<code>model_rf</code>ï¼‰</li>
<li>[ ] ã‚³ãƒ¡ãƒ³ãƒˆã§å‡¦ç†ã®ç›®çš„ã‚’èª¬æ˜ã—ã¦ã„ã‚‹</li>
</ul>
<h4>å¿œç”¨ãƒ¬ãƒ™ãƒ«</h4>
<ul>
<li>[ ] é–¢æ•°åŒ–ã—ã¦ã‚³ãƒ¼ãƒ‰ã‚’å†åˆ©ç”¨å¯èƒ½ã«ã—ã¦ã„ã‚‹
  <code>python
  def train_and_evaluate(model, X_train, X_test, y_train, y_test):
      model.fit(X_train, y_train)
      y_pred = model.predict(X_test)
      mae = mean_absolute_error(y_test, y_pred)
      r2 = r2_score(y_test, y_pred)
      return mae, r2</code></li>
<li>[ ] try-except ã§ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã‚’å®Ÿè£…ã—ã¦ã„ã‚‹</li>
<li>[ ] ãƒ­ã‚®ãƒ³ã‚°ã§è¨“ç·´éç¨‹ã‚’è¨˜éŒ²ã—ã¦ã„ã‚‹</li>
<li>[ ] Jupyter Notebookã‚’ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆ.pyï¼‰ã«å¤‰æ›ã§ãã‚‹</li>
<li>[ ] requirements.txtã§ç’°å¢ƒã‚’å†ç¾å¯èƒ½ã«ã—ã¦ã„ã‚‹</li>
</ul>
<hr />
<h3>9.10 ç·åˆè©•ä¾¡ï¼šãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå®Œé‚ãƒ¬ãƒ™ãƒ«</h3>
<p>ä»¥ä¸‹ã®ãƒ¬ãƒ™ãƒ«åˆ¤å®šã§ã€è‡ªåˆ†ã®åˆ°é”åº¦ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚</p>
<h4>ãƒ¬ãƒ™ãƒ«1ï¼šåˆå¿ƒè€…ï¼ˆBeginnerï¼‰</h4>
<ul>
<li>ç’°å¢ƒæ§‹ç¯‰ã‚¹ã‚­ãƒ«ï¼šåŸºç¤ãƒ¬ãƒ™ãƒ« 100%é”æˆ</li>
<li>ãƒ¢ãƒ‡ãƒ«å®Ÿè£…ã‚¹ã‚­ãƒ«ï¼šåŸºç¤ãƒ¬ãƒ™ãƒ« 6ã¤ä¸­3ã¤ä»¥ä¸Šå®Ÿè£…</li>
<li>ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ï¼šåŸºç¤ãƒ¬ãƒ™ãƒ«ã®ã‚¨ãƒ©ãƒ¼ã‚’è‡ªåŠ›ã§è§£æ±º</li>
</ul>
<p><strong>åˆ°é”ç›®æ¨™:</strong> ç·šå½¢å›å¸°ã€ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆã‚’å®Ÿè£…ã—ã€MAEãƒ»RÂ²ã‚’è¨ˆç®—ã§ãã‚‹</p>
<hr />
<h4>ãƒ¬ãƒ™ãƒ«2ï¼šä¸­ç´šè€…ï¼ˆIntermediateï¼‰</h4>
<ul>
<li>ç’°å¢ƒæ§‹ç¯‰ã‚¹ã‚­ãƒ«ï¼šå¿œç”¨ãƒ¬ãƒ™ãƒ« 80%ä»¥ä¸Šé”æˆ</li>
<li>ãƒ¢ãƒ‡ãƒ«å®Ÿè£…ã‚¹ã‚­ãƒ«ï¼šåŸºç¤ãƒ¬ãƒ™ãƒ« 100%é”æˆ + å¿œç”¨ãƒ¬ãƒ™ãƒ« 50%ä»¥ä¸Š</li>
<li>ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ï¼šåŸºç¤ãƒ¬ãƒ™ãƒ« 100%é”æˆ</li>
<li>ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ï¼šåŸºç¤ãƒ¬ãƒ™ãƒ« 100%é”æˆ</li>
<li>ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå®Œé‚ã‚¹ã‚­ãƒ«ï¼šå¿…é ˆã‚¹ã‚­ãƒ« 100%é”æˆ</li>
</ul>
<p><strong>åˆ°é”ç›®æ¨™:</strong> ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—äºˆæ¸¬ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ RÂ² &gt; 0.7ã€MAE &lt; 0.5 eV ã‚’é”æˆ</p>
<hr />
<h4>ãƒ¬ãƒ™ãƒ«3ï¼šä¸Šç´šè€…ï¼ˆAdvancedï¼‰</h4>
<ul>
<li>å…¨ã‚«ãƒ†ã‚´ãƒªï¼šå¿œç”¨ãƒ¬ãƒ™ãƒ« 100%é”æˆ</li>
<li>ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ï¼šä¸Šç´šãƒ¬ãƒ™ãƒ« 50%ä»¥ä¸Š</li>
<li>ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ï¼šä¸Šç´šãƒ¬ãƒ™ãƒ«ï¼ˆMatmineræ´»ç”¨ï¼‰100%é”æˆ</li>
<li>ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå®Œé‚ã‚¹ã‚­ãƒ«ï¼šç™ºå±•ã‚¹ã‚­ãƒ« 2ã¤ä»¥ä¸Šé”æˆ</li>
</ul>
<p><strong>åˆ°é”ç›®æ¨™:</strong> Matminerã§130ç‰¹å¾´é‡ã‚’æŠ½å‡ºã—ã€ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å­¦ç¿’ã§ RÂ² &gt; 0.85 ã‚’é”æˆ</p>
<hr />
<h4>ãƒ¬ãƒ™ãƒ«4ï¼šã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆï¼ˆExpertï¼‰</h4>
<ul>
<li>å…¨ã‚«ãƒ†ã‚´ãƒªï¼šä¸Šç´šãƒ¬ãƒ™ãƒ« 80%ä»¥ä¸Šé”æˆ</li>
<li>ã‚³ãƒ¼ãƒ‰å“è³ªï¼šå¿œç”¨ãƒ¬ãƒ™ãƒ« 100%é”æˆ</li>
<li>ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå®Œé‚ã‚¹ã‚­ãƒ«ï¼šç™ºå±•ã‚¹ã‚­ãƒ« å…¨é”æˆ</li>
<li>ç‹¬è‡ªã®æ”¹å–„ç­–ã‚’3ã¤ä»¥ä¸Šææ¡ˆãƒ»å®Ÿè£…ã§ãã‚‹</li>
</ul>
<p><strong>åˆ°é”ç›®æ¨™:</strong>
- Materials Project APIã‹ã‚‰å®Ÿãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
- ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã§ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–
- SHAPå€¤ã§ãƒ¢ãƒ‡ãƒ«ã®èª¬æ˜å¯èƒ½æ€§ã‚’å®Ÿç¾
- RÂ² &gt; 0.90ã€å®Ÿå‹™ãƒ¬ãƒ™ãƒ«ã®äºˆæ¸¬ç²¾åº¦</p>
<hr />
<h3>9.11 æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã¸ã®æº–å‚™åº¦ãƒã‚§ãƒƒã‚¯</h3>
<p>ä»¥ä¸‹ã®ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆã§ã€æ¬¡ã®å­¦ç¿’æ®µéšã¸ã®æº–å‚™ãŒã§ãã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚</p>
<h4>æ·±å±¤å­¦ç¿’ï¼ˆGNNã€CGCNNï¼‰ã¸ã®æº–å‚™</h4>
<ul>
<li>[ ] ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼ˆMLPï¼‰ã‚’å®Ÿè£…ã—ã€ReLUãƒ»Adamãƒ»Early Stoppingã‚’ç†è§£ã—ã¦ã„ã‚‹</li>
<li>[ ] å­¦ç¿’æ›²ç·šã‚’å¯è¦–åŒ–ã—ã€éå­¦ç¿’ã‚’æ¤œå‡ºã§ãã‚‹</li>
<li>[ ] ãƒ‡ãƒ¼ã‚¿æ¨™æº–åŒ–ã®é‡è¦æ€§ã‚’ç†è§£ã—ã¦ã„ã‚‹</li>
<li>[ ] æå¤±é–¢æ•°ï¼ˆMSEã€MAEï¼‰ã¨ãƒãƒƒã‚¯ãƒ—ãƒ­ãƒ‘ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ã®æ¦‚å¿µã‚’èª¬æ˜ã§ãã‚‹</li>
</ul>
<h4>ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã¸ã®æº–å‚™</h4>
<ul>
<li>[ ] ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆGrid Searchã€Random Searchï¼‰ã‚’å®Ÿè£…ã§ãã‚‹</li>
<li>[ ] äº¤å·®æ¤œè¨¼ã§æ±åŒ–æ€§èƒ½ã‚’è©•ä¾¡ã§ãã‚‹</li>
<li>[ ] ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¢ç´¢ç©ºé–“ã‚’è¨­å®šã§ãã‚‹</li>
</ul>
<h4>è»¢ç§»å­¦ç¿’ã¸ã®æº–å‚™</h4>
<ul>
<li>[ ] äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®æ¦‚å¿µã‚’ç†è§£ã—ã¦ã„ã‚‹</li>
<li>[ ] Fine-tuningï¼ˆå¾®èª¿æ•´ï¼‰ã®å¿…è¦æ€§ã‚’èª¬æ˜ã§ãã‚‹</li>
<li>[ ] ãƒ‰ãƒ¡ã‚¤ãƒ³é©å¿œï¼ˆDomain Adaptationï¼‰ã®æ¦‚å¿µã‚’çŸ¥ã£ã¦ã„ã‚‹</li>
</ul>
<h4>å®Ÿå‹™ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¸ã®æº–å‚™</h4>
<ul>
<li>[ ] Gitã§ã‚³ãƒ¼ãƒ‰ã‚’ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ã§ãã‚‹</li>
<li>[ ] Jupyter Notebookã‚’Pythonã‚¹ã‚¯ãƒªãƒ—ãƒˆã«å¤‰æ›ã§ãã‚‹</li>
<li>[ ] requirements.txtã§ç’°å¢ƒã‚’å†ç¾å¯èƒ½ã«ã—ã¦ã„ã‚‹</li>
<li>[ ] å®Ÿé¨“çµæœã‚’Markdown/PDFãƒ¬ãƒãƒ¼ãƒˆã«ã¾ã¨ã‚ã‚‰ã‚Œã‚‹</li>
<li>[ ] äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã‚’pickle/joblib ã§ä¿å­˜ãƒ»èª­ã¿è¾¼ã¿ã§ãã‚‹</li>
<li>[ ] APIã‚­ãƒ¼ã‚’.envãƒ•ã‚¡ã‚¤ãƒ«ã§å®‰å…¨ã«ç®¡ç†ã§ãã‚‹</li>
</ul>
<hr />
<p><strong>ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆæ´»ç”¨ã®ãƒ’ãƒ³ãƒˆ:</strong>
1. <strong>å®šæœŸçš„ã«è¦‹ç›´ã™</strong>: å­¦ç¿’å¾Œã€1é€±é–“å¾Œã€1ãƒ¶æœˆå¾Œã«å†ãƒã‚§ãƒƒã‚¯
2. <strong>æœªé”æˆé …ç›®ã‚’å„ªå…ˆ</strong>: ãƒã‚§ãƒƒã‚¯ã§ããªã„é …ç›®ã‚’é›†ä¸­å­¦ç¿’
3. <strong>ãƒ¬ãƒ™ãƒ«åˆ¤å®šã‚’è¨˜éŒ²</strong>: æˆé•·ã‚’å¯è¦–åŒ–ã—ã¦ãƒ¢ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ç¶­æŒ
4. <strong>å®Ÿå‹™ã§ã®æ´»ç”¨</strong>: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆé–‹å§‹å‰ã«å¿…é ˆã‚¹ã‚­ãƒ«ã‚’ç¢ºèª</p>
<hr />
<h2>å‚è€ƒæ–‡çŒ®</h2>
<ol>
<li>
<p>Pedregosa, F., et al. (2011). "Scikit-learn: Machine Learning in Python." <em>Journal of Machine Learning Research</em>, 12, 2825-2830.
   URL: https://scikit-learn.org
   <em>scikit-learnå…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã€‚ã™ã¹ã¦ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®è©³ç´°ãªè§£èª¬ã¨ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã€‚</em></p>
</li>
<li>
<p>Ward, L., et al. (2018). "Matminer: An open source toolkit for materials data mining." <em>Computational Materials Science</em>, 152, 60-69.
   DOI: <a href="https://doi.org/10.1016/j.commatsci.2018.05.018">10.1016/j.commatsci.2018.05.018</a>
   GitHub: https://github.com/hackingmaterials/matminer
   <em>ææ–™ç§‘å­¦å‘ã‘ç‰¹å¾´é‡æŠ½å‡ºãƒ©ã‚¤ãƒ–ãƒ©ãƒªã€‚132ç¨®é¡ã®ææ–™è¨˜è¿°å­ã‚’è‡ªå‹•ç”Ÿæˆã€‚</em></p>
</li>
<li>
<p>Jain, A., et al. (2013). "Commentary: The Materials Project: A materials genome approach to accelerating materials innovation." <em>APL Materials</em>, 1(1), 011002.
   DOI: <a href="https://doi.org/10.1063/1.4812323">10.1063/1.4812323</a>
   URL: https://materialsproject.org
   <em>Materials Projectå…¬å¼è«–æ–‡ã€‚140,000ç¨®é¡ä»¥ä¸Šã®ææ–™ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã€‚</em></p>
</li>
<li>
<p>Ke, G., et al. (2017). "LightGBM: A Highly Efficient Gradient Boosting Decision Tree." <em>Advances in Neural Information Processing Systems</em>, 30, 3146-3154.
   GitHub: https://github.com/microsoft/LightGBM
   <em>LightGBMå…¬å¼è«–æ–‡ã€‚å‹¾é…ãƒ–ãƒ¼ã‚¹ãƒ†ã‚£ãƒ³ã‚°ã®é«˜é€Ÿå®Ÿè£…ã€‚</em></p>
</li>
<li>
<p>Bergstra, J., &amp; Bengio, Y. (2012). "Random Search for Hyper-Parameter Optimization." <em>Journal of Machine Learning Research</em>, 13, 281-305.
   URL: https://www.jmlr.org/papers/v13/bergstra12a.html
   <em>Random Searchã®ç†è«–çš„èƒŒæ™¯ã€‚Grid Searchã‚ˆã‚ŠåŠ¹ç‡çš„ãªæ¢ç´¢æ‰‹æ³•ã€‚</em></p>
</li>
<li>
<p>Raschka, S., &amp; Mirjalili, V. (2019). <em>Python Machine Learning, 3rd Edition</em>. Packt Publishing.
   <em>Pythonã«ã‚ˆã‚‹æ©Ÿæ¢°å­¦ç¿’ã®åŒ…æ‹¬çš„ãªæ•™ç§‘æ›¸ã€‚scikit-learnã®å®Ÿè·µçš„ãªä½¿ã„æ–¹ã‚’è©³èª¬ã€‚</em></p>
</li>
<li>
<p>scikit-learn User Guide. (2024). "Hyperparameter tuning."
   URL: https://scikit-learn.org/stable/modules/grid_search.html
   <em>ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã®å…¬å¼ã‚¬ã‚¤ãƒ‰ã€‚Grid Searchã€Random Searchã®è©³ç´°ã€‚</em></p>
</li>
</ol>
<hr />
<p><strong>ä½œæˆæ—¥</strong>: 2025-10-16
<strong>ãƒãƒ¼ã‚¸ãƒ§ãƒ³</strong>: 3.0
<strong>ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ</strong>: content_agent_prompts.py v1.0
<strong>è‘—è€…</strong>: MI Knowledge Hub ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ</p><div class="navigation">
    <a href="chapter2-fundamentals.html" class="nav-button">â† å‰ã®ç« </a>
    <a href="index.html" class="nav-button">ã‚·ãƒªãƒ¼ã‚ºç›®æ¬¡ã«æˆ»ã‚‹</a>
    <a href="chapter4-real-world.html" class="nav-button">æ¬¡ã®ç«  â†’</a>
</div>
    </main>

    <footer>
        <p><strong>ä½œæˆè€…</strong>: AI Terakoya Content Team</p>
        <p><strong>ç›£ä¿®</strong>: Dr. Yusuke Hashimotoï¼ˆæ±åŒ—å¤§å­¦ï¼‰</p>
        <p><strong>ãƒãƒ¼ã‚¸ãƒ§ãƒ³</strong>: 3.0 | <strong>ä½œæˆæ—¥</strong>: 2025-10-16</p>
        <p><strong>ãƒ©ã‚¤ã‚»ãƒ³ã‚¹</strong>: Creative Commons BY 4.0</p>
        <p>Â© 2025 AI Terakoya. All rights reserved.</p>
    </footer>
</body>
</html>
