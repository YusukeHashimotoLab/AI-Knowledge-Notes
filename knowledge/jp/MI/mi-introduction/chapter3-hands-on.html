<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Á¨¨3Á´†ÔºöPython„Åß‰ΩìÈ®ì„Åô„ÇãMI - ÂÆüË∑µÁöÑ„Å™ÊùêÊñôÁâπÊÄß‰∫àÊ∏¨ - AI Terakoya</title>

    <style>
        :root {
            --color-primary: #2c3e50;
            --color-primary-dark: #1a252f;
            --color-accent: #7b2cbf;
            --color-accent-light: #9d4edd;
            --color-text: #2d3748;
            --color-text-light: #4a5568;
            --color-bg: #ffffff;
            --color-bg-alt: #f7fafc;
            --color-border: #e2e8f0;
            --color-code-bg: #f8f9fa;
            --color-link: #3182ce;
            --color-link-hover: #2c5aa0;

            --spacing-xs: 0.5rem;
            --spacing-sm: 1rem;
            --spacing-md: 1.5rem;
            --spacing-lg: 2rem;
            --spacing-xl: 3rem;

            --font-body: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            --font-mono: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;

            --border-radius: 8px;
            --box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: var(--font-body);
            line-height: 1.7;
            color: var(--color-text);
            background-color: var(--color-bg);
            font-size: 16px;
        }

        header {
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            padding: var(--spacing-xl) var(--spacing-md);
            margin-bottom: var(--spacing-xl);
            box-shadow: var(--box-shadow);
        }

        .header-content {
            max-width: 900px;
            margin: 0 auto;
        }

        h1 {
            font-size: 2rem;
            font-weight: 700;
            margin-bottom: var(--spacing-sm);
            line-height: 1.2;
        }

        .subtitle {
            font-size: 1.1rem;
            opacity: 0.95;
            font-weight: 400;
            margin-bottom: var(--spacing-md);
        }

        .meta {
            display: flex;
            flex-wrap: wrap;
            gap: var(--spacing-md);
            font-size: 0.9rem;
            opacity: 0.9;
        }

        .meta-item {
            display: flex;
            align-items: center;
            gap: 0.3rem;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 0 var(--spacing-md) var(--spacing-xl);
        }

        h2 {
            font-size: 1.75rem;
            color: var(--color-primary);
            margin-top: var(--spacing-xl);
            margin-bottom: var(--spacing-md);
            padding-bottom: var(--spacing-xs);
            border-bottom: 3px solid var(--color-accent);
        }

        h3 {
            font-size: 1.4rem;
            color: var(--color-primary);
            margin-top: var(--spacing-lg);
            margin-bottom: var(--spacing-sm);
        }

        h4 {
            font-size: 1.1rem;
            color: var(--color-primary-dark);
            margin-top: var(--spacing-md);
            margin-bottom: var(--spacing-sm);
        }

        p {
            margin-bottom: var(--spacing-md);
            color: var(--color-text);
        }

        a {
            color: var(--color-link);
            text-decoration: none;
            transition: color 0.2s;
        }

        a:hover {
            color: var(--color-link-hover);
            text-decoration: underline;
        }

        ul, ol {
            margin-left: var(--spacing-lg);
            margin-bottom: var(--spacing-md);
        }

        li {
            margin-bottom: var(--spacing-xs);
            color: var(--color-text);
        }

        pre {
            background-color: var(--color-code-bg);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            overflow-x: auto;
            margin-bottom: var(--spacing-md);
            font-family: var(--font-mono);
            font-size: 0.9rem;
            line-height: 1.5;
        }

        code {
            font-family: var(--font-mono);
            font-size: 0.9em;
            background-color: var(--color-code-bg);
            padding: 0.2em 0.4em;
            border-radius: 3px;
        }

        pre code {
            background-color: transparent;
            padding: 0;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: var(--spacing-md);
            font-size: 0.95rem;
        }

        th, td {
            border: 1px solid var(--color-border);
            padding: var(--spacing-sm);
            text-align: left;
        }

        th {
            background-color: var(--color-bg-alt);
            font-weight: 600;
            color: var(--color-primary);
        }

        blockquote {
            border-left: 4px solid var(--color-accent);
            padding-left: var(--spacing-md);
            margin: var(--spacing-md) 0;
            color: var(--color-text-light);
            font-style: italic;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        .mermaid {
            text-align: center;
            margin: var(--spacing-lg) 0;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        details {
            background-color: var(--color-bg-alt);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            margin-bottom: var(--spacing-md);
        }

        summary {
            cursor: pointer;
            font-weight: 600;
            color: var(--color-primary);
            user-select: none;
            padding: var(--spacing-xs);
            margin: calc(-1 * var(--spacing-md));
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        summary:hover {
            background-color: rgba(123, 44, 191, 0.1);
        }

        details[open] summary {
            margin-bottom: var(--spacing-md);
            border-bottom: 1px solid var(--color-border);
        }

        .learning-objectives {
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
            padding: var(--spacing-lg);
            border-radius: var(--border-radius);
            border-left: 4px solid var(--color-accent);
            margin-bottom: var(--spacing-xl);
        }

        .learning-objectives h2 {
            margin-top: 0;
            border-bottom: none;
        }

        .navigation {
            display: flex;
            justify-content: space-between;
            gap: var(--spacing-md);
            margin: var(--spacing-xl) 0;
            padding-top: var(--spacing-lg);
            border-top: 2px solid var(--color-border);
        }

        .nav-button {
            flex: 1;
            padding: var(--spacing-md);
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            border-radius: var(--border-radius);
            text-align: center;
            font-weight: 600;
            transition: transform 0.2s, box-shadow 0.2s;
            box-shadow: var(--box-shadow);
        }

        .nav-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
            text-decoration: none;
        }

        footer {
            margin-top: var(--spacing-xl);
            padding: var(--spacing-lg) var(--spacing-md);
            background-color: var(--color-bg-alt);
            border-top: 1px solid var(--color-border);
            text-align: center;
            font-size: 0.9rem;
            color: var(--color-text-light);
        }

        @media (max-width: 768px) {
            h1 {
                font-size: 1.5rem;
            }

            h2 {
                font-size: 1.4rem;
            }

            h3 {
                font-size: 1.2rem;
            }

            .meta {
                font-size: 0.85rem;
            }

            .navigation {
                flex-direction: column;
            }

            table {
                font-size: 0.85rem;
            }

            th, td {
                padding: var(--spacing-xs);
            }
        }
    </style>

    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
        mermaid.initialize({ startOnLoad: true, theme: 'default' });
    </script>

    <!-- MathJax for LaTeX equation rendering -->
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\(', '\)']],
                displayMath: [['$$', '$$'], ['\[', '\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
                ignoreHtmlClass: 'mermaid'
            }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" async></script>
</head>
<body>
    <header>
        <div class="header-content">
            <h1>Á¨¨3Á´†ÔºöPython„Åß‰ΩìÈ®ì„Åô„ÇãMI - ÂÆüË∑µÁöÑ„Å™ÊùêÊñôÁâπÊÄß‰∫àÊ∏¨</h1>
            <p class="subtitle">Ê©üÊ¢∞Â≠¶Áøí„Å´„Çà„ÇãÊùêÊñôÈñãÁô∫„ÅÆÂÆüË£Ö„Å®„Éô„Çπ„Éà„Éó„É©„ÇØ„ÉÜ„Ç£„Çπ</p>
            <div class="meta">
                <span class="meta-item">üìñ Ë™≠‰∫ÜÊôÇÈñì: 20-25ÂàÜ</span>
                <span class="meta-item">üìä Èõ£ÊòìÂ∫¶: ‰∏≠Á¥ö</span>
                <span class="meta-item">üíª „Ç≥„Éº„Éâ‰æã: 0ÂÄã</span>
                <span class="meta-item">üìù ÊºîÁøíÂïèÈ°å: 0Âïè</span>
            </div>
        </div>
    </header>

    <main class="container">
<h1>Á¨¨3Á´†ÔºöPython„Åß‰ΩìÈ®ì„Åô„ÇãMI - ÂÆüË∑µÁöÑ„Å™ÊùêÊñôÁâπÊÄß‰∫àÊ∏¨</h1>
<h2>Â≠¶ÁøíÁõÆÊ®ô</h2>
<p>„Åì„ÅÆË®ò‰∫ã„ÇíË™≠„ÇÄ„Åì„Å®„Åß„ÄÅ‰ª•‰∏ã„ÇíÁøíÂæó„Åß„Åç„Åæ„ÅôÔºö
- PythonÁí∞Â¢É„ÇíÊßãÁØâ„Åó„ÄÅMIÁî®„É©„Ç§„Éñ„É©„É™„Çí„Ç§„É≥„Çπ„Éà„Éº„É´„Åß„Åç„Çã
- 5Á®ÆÈ°û‰ª•‰∏ä„ÅÆÊ©üÊ¢∞Â≠¶Áøí„É¢„Éá„É´„ÇíÂÆüË£Ö„Åó„ÄÅÊÄßËÉΩ„ÇíÊØîËºÉ„Åß„Åç„Çã
- „Éè„Ç§„Éë„Éº„Éë„É©„É°„Éº„Çø„ÉÅ„É•„Éº„Éã„É≥„Ç∞„ÇíÂÆüË°å„Åß„Åç„Çã
- ÊùêÊñôÁâπÊÄß‰∫àÊ∏¨„ÅÆÂÆüË∑µÁöÑ„Å™„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÇíÂÆåÊàê„Åß„Åç„Çã
- „Ç®„É©„Éº„ÇíËá™Âäõ„Åß„Éà„É©„Éñ„É´„Ç∑„É•„Éº„ÉÜ„Ç£„É≥„Ç∞„Åß„Åç„Çã</p>
<hr />
<h2>1. Áí∞Â¢ÉÊßãÁØâÔºö3„Å§„ÅÆÈÅ∏ÊäûËÇ¢</h2>
<p>ÊùêÊñôÁâπÊÄß‰∫àÊ∏¨„ÅÆPythonÁí∞Â¢É„ÇíÊßãÁØâ„Åô„ÇãÊñπÊ≥ï„ÅØ„ÄÅÁä∂Ê≥Å„Å´Âøú„Åò„Å¶3„Å§„ÅÇ„Çä„Åæ„Åô„ÄÇ</p>
<h3>1.1 Option 1: AnacondaÔºàÊé®Â•®ÂàùÂøÉËÄÖÔºâ</h3>
<p><strong>ÁâπÂæ¥Ôºö</strong>
- ÁßëÂ≠¶Ë®àÁÆó„É©„Ç§„Éñ„É©„É™„ÅåÊúÄÂàù„Åã„ÇâÊèÉ„Å£„Å¶„ÅÑ„Çã
- Áí∞Â¢ÉÁÆ°ÁêÜ„ÅåÁ∞°ÂçòÔºàGUIÂà©Áî®ÂèØËÉΩÔºâ
- Windows/Mac/LinuxÂØæÂøú</p>
<p><strong>„Ç§„É≥„Çπ„Éà„Éº„É´ÊâãÈ†ÜÔºö</strong></p>
<pre><code class="language-bash"># 1. Anaconda„Çí„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ
# ÂÖ¨Âºè„Çµ„Ç§„Éà: https://www.anaconda.com/download
# Python 3.11‰ª•‰∏ä„ÇíÈÅ∏Êäû

# 2. „Ç§„É≥„Çπ„Éà„Éº„É´Âæå„ÄÅAnaconda Prompt„ÇíËµ∑Âãï

# 3. ‰ªÆÊÉ≥Áí∞Â¢É„Çí‰ΩúÊàêÔºàMIÂ∞ÇÁî®Áí∞Â¢ÉÔºâ
conda create -n mi-env python=3.11 numpy pandas matplotlib scikit-learn jupyter

# 4. Áí∞Â¢É„ÇíÊúâÂäπÂåñ
conda activate mi-env

# 5. Âãï‰ΩúÁ¢∫Ë™ç
python --version
# Âá∫Âäõ: Python 3.11.x
</code></pre>
<p><strong>ÁîªÈù¢„Ç§„É°„Éº„Ç∏Ôºö</strong></p>
<pre><code>(base) $ conda create -n mi-env python=3.11
Collecting package metadata: done
Solving environment: done
...
Proceed ([y]/n)? y

# ÊàêÂäü„Åô„Çã„Å®‰ª•‰∏ã„ÅåË°®Á§∫„Åï„Çå„Çã
# To activate this environment, use
#   $ conda activate mi-env
</code></pre>
<p><strong>Anaconda„ÅÆÂà©ÁÇπÔºö</strong>
- ‚úÖ NumPy„ÄÅSciPy„Å™„Å©„ÅåÊúÄÂàù„Åã„ÇâÂê´„Åæ„Çå„Çã
- ‚úÖ ‰æùÂ≠òÈñ¢‰øÇ„ÅÆÂïèÈ°å„ÅåÂ∞ë„Å™„ÅÑ
- ‚úÖ Anaconda Navigator„ÅßË¶ñË¶öÁöÑ„Å´ÁÆ°ÁêÜÂèØËÉΩ
- ‚ùå „Éï„Ç°„Ç§„É´„Çµ„Ç§„Ç∫„ÅåÂ§ß„Åç„ÅÑÔºà3GB‰ª•‰∏äÔºâ</p>
<h3>1.2 Option 2: venvÔºàPythonÊ®ôÊ∫ñÔºâ</h3>
<p><strong>ÁâπÂæ¥Ôºö</strong>
- PythonÊ®ôÊ∫ñ„ÉÑ„Éº„É´ÔºàËøΩÂä†„Ç§„É≥„Çπ„Éà„Éº„É´‰∏çË¶ÅÔºâ
- ËªΩÈáèÔºàÂøÖË¶Å„Å™„ÇÇ„ÅÆ„Å†„Åë„Ç§„É≥„Çπ„Éà„Éº„É´Ôºâ
- „Éó„É≠„Ç∏„Çß„ÇØ„Éà„Åî„Å®„Å´Áí∞Â¢É„ÇíÂàÜÈõ¢</p>
<p><strong>„Ç§„É≥„Çπ„Éà„Éº„É´ÊâãÈ†ÜÔºö</strong></p>
<pre><code class="language-bash"># 1. Python 3.11‰ª•‰∏ä„Åå„Ç§„É≥„Çπ„Éà„Éº„É´„Åï„Çå„Å¶„ÅÑ„Çã„ÅãÁ¢∫Ë™ç
python3 --version
# Âá∫Âäõ: Python 3.11.x ‰ª•‰∏ä„ÅåÂøÖË¶Å

# 2. ‰ªÆÊÉ≥Áí∞Â¢É„Çí‰ΩúÊàê
python3 -m venv mi-env

# 3. Áí∞Â¢É„ÇíÊúâÂäπÂåñ
# macOS/Linux:
source mi-env/bin/activate

# Windows (PowerShell):
mi-env\Scripts\Activate.ps1

# Windows (Command Prompt):
mi-env\Scripts\activate.bat

# 4. pip„Çí„Ç¢„ÉÉ„Éó„Ç∞„É¨„Éº„Éâ
pip install --upgrade pip

# 5. ÂøÖË¶Å„Å™„É©„Ç§„Éñ„É©„É™„Çí„Ç§„É≥„Çπ„Éà„Éº„É´
pip install numpy pandas matplotlib scikit-learn jupyter

# 6. „Ç§„É≥„Çπ„Éà„Éº„É´Á¢∫Ë™ç
pip list
</code></pre>
<p><strong>venv„ÅÆÂà©ÁÇπÔºö</strong>
- ‚úÖ ËªΩÈáèÔºàÊï∞ÂçÅMBÔºâ
- ‚úÖ PythonÊ®ôÊ∫ñ„ÉÑ„Éº„É´ÔºàËøΩÂä†„Ç§„É≥„Çπ„Éà„Éº„É´‰∏çË¶ÅÔºâ
- ‚úÖ „Éó„É≠„Ç∏„Çß„ÇØ„Éà„Åî„Å®„Å´Áã¨Á´ã
- ‚ùå ‰æùÂ≠òÈñ¢‰øÇ„ÇíÊâãÂãï„ÅßËß£Ê±∫„Åô„ÇãÂøÖË¶Å„Åå„ÅÇ„Çã</p>
<h3>1.3 Option 3: Google ColabÔºà„Ç§„É≥„Çπ„Éà„Éº„É´‰∏çË¶ÅÔºâ</h3>
<p><strong>ÁâπÂæ¥Ôºö</strong>
- „Éñ„É©„Ç¶„Ç∂„Å†„Åë„ÅßÂÆüË°åÂèØËÉΩ
- „Ç§„É≥„Çπ„Éà„Éº„É´‰∏çË¶ÅÔºà„ÇØ„É©„Ç¶„ÉâÂÆüË°åÔºâ
- GPU/TPU„ÅåÁÑ°Êñô„Åß‰Ωø„Åà„Çã</p>
<p><strong>‰ΩøÁî®ÊñπÊ≥ïÔºö</strong></p>
<pre><code>1. Google Colab„Å´„Ç¢„ÇØ„Çª„Çπ: https://colab.research.google.com
2. Êñ∞„Åó„ÅÑ„Éé„Éº„Éà„Éñ„ÉÉ„ÇØ„Çí‰ΩúÊàê
3. ‰ª•‰∏ã„ÅÆ„Ç≥„Éº„Éâ„ÇíÂÆüË°åÔºàÂøÖË¶Å„Å™„É©„Ç§„Éñ„É©„É™„ÅØËá™Âãï„Åß„Ç§„É≥„Çπ„Éà„Éº„É´Ê∏à„ÅøÔºâ
</code></pre>
<pre><code class="language-python"># Google Colab„Åß„ÅØÊúÄÂàù„Åã„Çâ‰ª•‰∏ã„Åå„Ç§„É≥„Çπ„Éà„Éº„É´Ê∏à„Åø
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor

print(&quot;„É©„Ç§„Éñ„É©„É™„ÅÆ„Ç§„É≥„Éù„Éº„Éà„ÅåÊàêÂäü„Åó„Åæ„Åó„ÅüÔºÅ&quot;)
print(f&quot;NumPy version: {np.__version__}&quot;)
print(f&quot;Pandas version: {pd.__version__}&quot;)
</code></pre>
<p><strong>Google Colab„ÅÆÂà©ÁÇπÔºö</strong>
- ‚úÖ „Ç§„É≥„Çπ„Éà„Éº„É´‰∏çË¶ÅÔºà„Åô„ÅêÈñãÂßãÂèØËÉΩÔºâ
- ‚úÖ ÁÑ°Êñô„ÅßGPUÂà©Áî®ÂèØËÉΩ
- ‚úÖ Google Drive„Å®ÈÄ£Êê∫Ôºà„Éá„Éº„Çø‰øùÂ≠ò„ÅåÁ∞°ÂçòÔºâ
- ‚ùå „Ç§„É≥„Çø„Éº„Éç„ÉÉ„ÉàÊé•Á∂ö„ÅåÂøÖÈ†à
- ‚ùå „Çª„ÉÉ„Ç∑„Éß„É≥„Åå12ÊôÇÈñì„Åß„É™„Çª„ÉÉ„Éà„Åï„Çå„Çã</p>
<h3>1.4 Áí∞Â¢ÉÈÅ∏Êäû„Ç¨„Ç§„Éâ</h3>
<table>
<thead>
<tr>
<th>Áä∂Ê≥Å</th>
<th>Êé®Â•®„Ç™„Éó„Ç∑„Éß„É≥</th>
<th>ÁêÜÁî±</th>
</tr>
</thead>
<tbody>
<tr>
<td>Âàù„ÇÅ„Å¶„ÅÆPythonÁí∞Â¢É</td>
<td>Anaconda</td>
<td>Áí∞Â¢ÉÊßãÁØâ„ÅåÁ∞°Âçò„ÄÅ„Éà„É©„Éñ„É´„ÅåÂ∞ë„Å™„ÅÑ</td>
</tr>
<tr>
<td>Êó¢„Å´PythonÁí∞Â¢É„Åå„ÅÇ„Çã</td>
<td>venv</td>
<td>ËªΩÈáè„ÄÅ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„Åî„Å®„Å´Áã¨Á´ã</td>
</tr>
<tr>
<td>‰ªä„Åô„ÅêË©¶„Åó„Åü„ÅÑ</td>
<td>Google Colab</td>
<td>„Ç§„É≥„Çπ„Éà„Éº„É´‰∏çË¶Å„ÄÅÂç≥Â∫ß„Å´ÈñãÂßãÂèØËÉΩ</td>
</tr>
<tr>
<td>GPUË®àÁÆó„ÅåÂøÖË¶Å</td>
<td>Google Colab or Anaconda</td>
<td>ÁÑ°ÊñôGPUÔºàColabÔºâor „É≠„Éº„Ç´„É´GPUÔºàAnacondaÔºâ</td>
</tr>
<tr>
<td>„Ç™„Éï„É©„Ç§„É≥Áí∞Â¢É</td>
<td>Anaconda or venv</td>
<td>„É≠„Éº„Ç´„É´ÂÆüË°å„ÄÅ„Ç§„É≥„Çø„Éº„Éç„ÉÉ„Éà‰∏çË¶Å</td>
</tr>
</tbody>
</table>
<h3>1.5 „Ç§„É≥„Çπ„Éà„Éº„É´Ê§úË®º„Å®„Éà„É©„Éñ„É´„Ç∑„É•„Éº„ÉÜ„Ç£„É≥„Ç∞</h3>
<p><strong>Ê§úË®º„Ç≥„Éû„É≥„ÉâÔºö</strong></p>
<pre><code class="language-python"># „Åô„Åπ„Å¶„ÅÆÁí∞Â¢É„ÅßÂÆüË°åÂèØËÉΩ
import sys
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import sklearn

print(&quot;===== Áí∞Â¢ÉÁ¢∫Ë™ç =====&quot;)
print(f&quot;Python version: {sys.version}&quot;)
print(f&quot;NumPy version: {np.__version__}&quot;)
print(f&quot;Pandas version: {pd.__version__}&quot;)
print(f&quot;Matplotlib version: {plt.matplotlib.__version__}&quot;)
print(f&quot;scikit-learn version: {sklearn.__version__}&quot;)
print(&quot;\n‚úÖ „Åô„Åπ„Å¶„ÅÆ„É©„Ç§„Éñ„É©„É™„ÅåÊ≠£Â∏∏„Å´„Ç§„É≥„Çπ„Éà„Éº„É´„Åï„Çå„Å¶„ÅÑ„Åæ„ÅôÔºÅ&quot;)
</code></pre>
<p><strong>ÊúüÂæÖ„Åï„Çå„ÇãÂá∫ÂäõÔºö</strong></p>
<pre><code>===== Áí∞Â¢ÉÁ¢∫Ë™ç =====
Python version: 3.11.x
NumPy version: 1.24.x
Pandas version: 2.0.x
Matplotlib version: 3.7.x
scikit-learn version: 1.3.x

‚úÖ „Åô„Åπ„Å¶„ÅÆ„É©„Ç§„Éñ„É©„É™„ÅåÊ≠£Â∏∏„Å´„Ç§„É≥„Çπ„Éà„Éº„É´„Åï„Çå„Å¶„ÅÑ„Åæ„ÅôÔºÅ
</code></pre>
<p><strong>„Çà„Åè„ÅÇ„Çã„Ç®„É©„Éº„Å®Ëß£Ê±∫ÊñπÊ≥ïÔºö</strong></p>
<table>
<thead>
<tr>
<th>„Ç®„É©„Éº„É°„ÉÉ„Çª„Éº„Ç∏</th>
<th>ÂéüÂõ†</th>
<th>Ëß£Ê±∫ÊñπÊ≥ï</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>ModuleNotFoundError: No module named 'numpy'</code></td>
<td>„É©„Ç§„Éñ„É©„É™Êú™„Ç§„É≥„Çπ„Éà„Éº„É´</td>
<td><code>pip install numpy</code> „ÇíÂÆüË°å</td>
</tr>
<tr>
<td><code>pip is not recognized</code></td>
<td>pip„ÅÆPATH„ÅåÈÄö„Å£„Å¶„ÅÑ„Å™„ÅÑ</td>
<td>PythonÂÜç„Ç§„É≥„Çπ„Éà„Éº„É´ or PATHË®≠ÂÆö</td>
</tr>
<tr>
<td><code>SSL: CERTIFICATE_VERIFY_FAILED</code></td>
<td>SSLË®ºÊòéÊõ∏„Ç®„É©„Éº</td>
<td><code>pip install --trusted-host pypi.org --trusted-host files.pythonhosted.org &lt;package&gt;</code></td>
</tr>
<tr>
<td><code>MemoryError</code></td>
<td>„É°„É¢„É™‰∏çË∂≥</td>
<td>„Éá„Éº„Çø„Çµ„Ç§„Ç∫„ÇíÂâäÊ∏õ or Google ColabÂà©Áî®</td>
</tr>
<tr>
<td><code>ImportError: DLL load failed</code> (Windows)</td>
<td>C++ÂÜçÈ†íÂ∏ÉÂèØËÉΩ„Éë„ÉÉ„Ç±„Éº„Ç∏‰∏çË∂≥</td>
<td>Microsoft Visual C++ Redistributable„Çí„Ç§„É≥„Çπ„Éà„Éº„É´</td>
</tr>
</tbody>
</table>
<hr />
<h2>2. „Ç≥„Éº„Éâ‰æã„Ç∑„É™„Éº„Ç∫Ôºö6„Å§„ÅÆÊ©üÊ¢∞Â≠¶Áøí„É¢„Éá„É´</h2>
<p>ÂÆüÈöõ„Å´6„Å§„ÅÆÁï∞„Å™„ÇãÊ©üÊ¢∞Â≠¶Áøí„É¢„Éá„É´„ÇíÂÆüË£Ö„Åó„ÄÅÊÄßËÉΩ„ÇíÊØîËºÉ„Åó„Åæ„Åô„ÄÇ</p>
<h3>2.1 Example 1: Á∑öÂΩ¢ÂõûÂ∏∞ÔºàBaselineÔºâ</h3>
<p><strong>Ê¶ÇË¶ÅÔºö</strong>
ÊúÄ„ÇÇ„Ç∑„É≥„Éó„É´„Å™Ê©üÊ¢∞Â≠¶Áøí„É¢„Éá„É´„ÄÇÁâπÂæ¥Èáè„Å®ÁõÆÁöÑÂ§âÊï∞„ÅÆÁ∑öÂΩ¢Èñ¢‰øÇ„ÇíÂ≠¶Áøí„Åó„Åæ„Åô„ÄÇ</p>
<pre><code class="language-python">import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error, r2_score
import time

# „Çµ„É≥„Éó„É´„Éá„Éº„Çø‰ΩúÊàêÔºàÂêàÈáë„ÅÆÁµÑÊàê„Å®ËûçÁÇπÔºâ
# Ê≥®ÊÑè: ÂÆüÈöõ„ÅÆÁ†îÁ©∂„Åß„ÅØMaterials Project„Å™„Å©„ÅÆÂÆü„Éá„Éº„Çø„Çí‰ΩøÁî®
np.random.seed(42)
n_samples = 100

# ÂÖÉÁ¥†A, B„ÅÆÊØîÁéáÔºàÂêàË®à1.0Ôºâ
element_A = np.random.uniform(0.1, 0.9, n_samples)
element_B = 1.0 - element_A

# ËûçÁÇπ„ÅÆ„É¢„Éá„É´ÔºàÁ∑öÂΩ¢Èñ¢‰øÇ + „Éé„Ç§„Ç∫Ôºâ
# ËûçÁÇπ = 1000 + 400 * element_A + „Éé„Ç§„Ç∫
melting_point = 1000 + 400 * element_A + np.random.normal(0, 20, n_samples)

# DataFrame„Å´Ê†ºÁ¥ç
data = pd.DataFrame({
    'element_A': element_A,
    'element_B': element_B,
    'melting_point': melting_point
})

print(&quot;===== „Éá„Éº„Çø„ÅÆÁ¢∫Ë™ç =====&quot;)
print(data.head())
print(f&quot;\n„Éá„Éº„ÇøÊï∞: {len(data)}‰ª∂&quot;)
print(f&quot;ËûçÁÇπ„ÅÆÁØÑÂõ≤: {melting_point.min():.1f} - {melting_point.max():.1f} K&quot;)

# ÁâπÂæ¥Èáè„Å®ÁõÆÁöÑÂ§âÊï∞„ÅÆÂàÜÂâ≤
X = data[['element_A', 'element_B']]  # ÂÖ•ÂäõÔºöÁµÑÊàê
y = data['melting_point']  # Âá∫ÂäõÔºöËûçÁÇπ

# Ë®ìÁ∑¥„Éá„Éº„Çø„Å®„ÉÜ„Çπ„Éà„Éá„Éº„Çø„Å´ÂàÜÂâ≤Ôºà80% vs 20%Ôºâ
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# „É¢„Éá„É´„ÅÆÊßãÁØâ„Å®Ë®ìÁ∑¥
start_time = time.time()
model_lr = LinearRegression()
model_lr.fit(X_train, y_train)
training_time = time.time() - start_time

# ‰∫àÊ∏¨
y_pred = model_lr.predict(X_test)

# Ë©ï‰æ°
mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(&quot;\n===== Á∑öÂΩ¢ÂõûÂ∏∞„É¢„Éá„É´„ÅÆÊÄßËÉΩ =====&quot;)
print(f&quot;Ë®ìÁ∑¥ÊôÇÈñì: {training_time:.4f} Áßí&quot;)
print(f&quot;Âπ≥ÂùáÁµ∂ÂØæË™§Â∑Æ (MAE): {mae:.2f} K&quot;)
print(f&quot;Ê±∫ÂÆö‰øÇÊï∞ (R¬≤): {r2:.4f}&quot;)

# Â≠¶Áøí„Åó„Åü‰øÇÊï∞„ÇíË°®Á§∫
print(&quot;\n===== Â≠¶Áøí„Åó„Åü‰øÇÊï∞ =====&quot;)
print(f&quot;ÂàáÁâá: {model_lr.intercept_:.2f}&quot;)
print(f&quot;element_A „ÅÆ‰øÇÊï∞: {model_lr.coef_[0]:.2f}&quot;)
print(f&quot;element_B „ÅÆ‰øÇÊï∞: {model_lr.coef_[1]:.2f}&quot;)

# ÂèØË¶ñÂåñ
plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_pred, alpha=0.6, s=100, c='blue')
plt.plot([y_test.min(), y_test.max()],
         [y_test.min(), y_test.max()],
         'r--', lw=2, label='ÂÆåÂÖ®„Å™‰∫àÊ∏¨')
plt.xlabel('ÂÆüÊ∏¨ÂÄ§ (K)', fontsize=12)
plt.ylabel('‰∫àÊ∏¨ÂÄ§ (K)', fontsize=12)
plt.title('Á∑öÂΩ¢ÂõûÂ∏∞ÔºöËûçÁÇπ„ÅÆ‰∫àÊ∏¨ÁµêÊûú', fontsize=14)
plt.legend()
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()
</code></pre>
<p><strong>„Ç≥„Éº„ÉâËß£Ë™¨Ôºö</strong>
1. <strong>„Éá„Éº„ÇøÁîüÊàê</strong>Ôºöelement_AÊØîÁéá„Åã„ÇâËûçÁÇπ„ÇíË®àÁÆóÔºàÁ∑öÂΩ¢Èñ¢‰øÇ + „Éé„Ç§„Ç∫Ôºâ
2. <strong>„Éá„Éº„ÇøÂàÜÂâ≤</strong>Ôºö80%Ë®ìÁ∑¥„ÄÅ20%„ÉÜ„Çπ„Éà
3. <strong>„É¢„Éá„É´Ë®ìÁ∑¥</strong>ÔºöLinearRegression()„Çí‰ΩøÁî®
4. <strong>Ë©ï‰æ°</strong>ÔºöMAEÔºàË™§Â∑Æ„ÅÆÂπ≥ÂùáÔºâ„Å®R¬≤ÔºàË™¨ÊòéÂäõÔºâ„ÇíË®àÁÆó
5. <strong>‰øÇÊï∞Ë°®Á§∫</strong>ÔºöÂ≠¶Áøí„Åó„ÅüÁ∑öÂΩ¢Èñ¢‰øÇ„ÇíÁ¢∫Ë™ç</p>
<p><strong>ÊúüÂæÖ„Åï„Çå„ÇãÁµêÊûúÔºö</strong>
- MAE: 15-25 K
- R¬≤: 0.95‰ª•‰∏äÔºàÁ∑öÂΩ¢„Éá„Éº„Çø„Å™„ÅÆ„ÅßÈ´òÁ≤æÂ∫¶Ôºâ
- Ë®ìÁ∑¥ÊôÇÈñì: 0.01ÁßíÊú™Ê∫Ä</p>
<hr />
<h3>2.2 Example 2: „É©„É≥„ÉÄ„É†„Éï„Ç©„É¨„Çπ„ÉàÔºàÂº∑ÂåñÁâàÔºâ</h3>
<p><strong>Ê¶ÇË¶ÅÔºö</strong>
Ë§áÊï∞„ÅÆÊ±∫ÂÆöÊú®„ÇíÁµÑ„ÅøÂêà„Çè„Åõ„ÅüÂº∑Âäõ„Å™„É¢„Éá„É´„ÄÇÈùûÁ∑öÂΩ¢Èñ¢‰øÇ„ÇÇÂ≠¶ÁøíÂèØËÉΩ„ÄÇ</p>
<pre><code class="language-python">from sklearn.ensemble import RandomForestRegressor

# „Çà„ÇäË§áÈõë„Å™ÈùûÁ∑öÂΩ¢„Éá„Éº„Çø„ÇíÁîüÊàê
np.random.seed(42)
n_samples = 200

element_A = np.random.uniform(0.1, 0.9, n_samples)
element_B = 1.0 - element_A

# ÈùûÁ∑öÂΩ¢„Å™ËûçÁÇπ„É¢„Éá„É´Ôºà‰∫åÊ¨°Èñ¢Êï∞ + Áõ∏‰∫í‰ΩúÁî®È†ÖÔºâ
melting_point = (
    1000
    + 400 * element_A
    - 300 * element_A**2  # ‰∫åÊ¨°È†Ö
    + 200 * element_A * element_B  # Áõ∏‰∫í‰ΩúÁî®È†Ö
    + np.random.normal(0, 15, n_samples)
)

data_rf = pd.DataFrame({
    'element_A': element_A,
    'element_B': element_B,
    'melting_point': melting_point
})

X_rf = data_rf[['element_A', 'element_B']]
y_rf = data_rf['melting_point']

X_train_rf, X_test_rf, y_train_rf, y_test_rf = train_test_split(
    X_rf, y_rf, test_size=0.2, random_state=42
)

# „É©„É≥„ÉÄ„É†„Éï„Ç©„É¨„Çπ„Éà„É¢„Éá„É´„ÅÆÊßãÁØâ
start_time = time.time()
model_rf = RandomForestRegressor(
    n_estimators=100,      # Ê±∫ÂÆöÊú®„ÅÆÊï∞ÔºàÂ§ö„ÅÑ„Åª„Å©Á≤æÂ∫¶‚Üë„ÄÅË®àÁÆóÊôÇÈñì‚ÜëÔºâ
    max_depth=10,          # Êú®„ÅÆÊúÄÂ§ßÊ∑±„ÅïÔºàÊ∑±„ÅÑ„Åª„Å©Ë§áÈõë„Å™Èñ¢‰øÇ„ÇíÂ≠¶ÁøíÔºâ
    min_samples_split=5,   # ÂàÜÂ≤ê„Å´ÂøÖË¶Å„Å™ÊúÄÂ∞è„Çµ„É≥„Éó„É´Êï∞
    min_samples_leaf=2,    # Ëëâ„Éé„Éº„Éâ„ÅÆÊúÄÂ∞è„Çµ„É≥„Éó„É´Êï∞
    random_state=42,       # ÂÜçÁèæÊÄß„ÅÆ„Åü„ÇÅ
    n_jobs=-1              # „Åô„Åπ„Å¶„ÅÆCPU„Ç≥„Ç¢„Çí‰ΩøÁî®
)
model_rf.fit(X_train_rf, y_train_rf)
training_time_rf = time.time() - start_time

# ‰∫àÊ∏¨„Å®Ë©ï‰æ°
y_pred_rf = model_rf.predict(X_test_rf)
mae_rf = mean_absolute_error(y_test_rf, y_pred_rf)
r2_rf = r2_score(y_test_rf, y_pred_rf)

print(&quot;\n===== „É©„É≥„ÉÄ„É†„Éï„Ç©„É¨„Çπ„Éà„É¢„Éá„É´„ÅÆÊÄßËÉΩ =====&quot;)
print(f&quot;Ë®ìÁ∑¥ÊôÇÈñì: {training_time_rf:.4f} Áßí&quot;)
print(f&quot;Âπ≥ÂùáÁµ∂ÂØæË™§Â∑Æ (MAE): {mae_rf:.2f} K&quot;)
print(f&quot;Ê±∫ÂÆö‰øÇÊï∞ (R¬≤): {r2_rf:.4f}&quot;)

# ÁâπÂæ¥Èáè„ÅÆÈáçË¶ÅÂ∫¶
feature_importance = pd.DataFrame({
    'ÁâπÂæ¥Èáè': ['element_A', 'element_B'],
    'ÈáçË¶ÅÂ∫¶': model_rf.feature_importances_
}).sort_values('ÈáçË¶ÅÂ∫¶', ascending=False)

print(&quot;\n===== ÁâπÂæ¥Èáè„ÅÆÈáçË¶ÅÂ∫¶ =====&quot;)
print(feature_importance)

# Out-of-Bag (OOB) „Çπ„Ç≥„Ç¢ÔºàË®ìÁ∑¥„Éá„Éº„Çø„ÅÆ‰∏ÄÈÉ®„ÇíÊ§úË®º„Å´‰ΩøÁî®Ôºâ
model_rf_oob = RandomForestRegressor(
    n_estimators=100,
    max_depth=10,
    random_state=42,
    oob_score=True  # OOB„Çπ„Ç≥„Ç¢„ÇíÊúâÂäπÂåñ
)
model_rf_oob.fit(X_train_rf, y_train_rf)
print(f&quot;\nOOB„Çπ„Ç≥„Ç¢ (R¬≤): {model_rf_oob.oob_score_:.4f}&quot;)

# ÂèØË¶ñÂåñÔºö‰∫àÊ∏¨ÁµêÊûú
fig, axes = plt.subplots(1, 2, figsize=(15, 6))

# Â∑¶Ôºö‰∫àÊ∏¨ vs ÂÆüÊ∏¨
axes[0].scatter(y_test_rf, y_pred_rf, alpha=0.6, s=100, c='green')
axes[0].plot([y_test_rf.min(), y_test_rf.max()],
             [y_test_rf.min(), y_test_rf.max()],
             'r--', lw=2, label='ÂÆåÂÖ®„Å™‰∫àÊ∏¨')
axes[0].set_xlabel('ÂÆüÊ∏¨ÂÄ§ (K)', fontsize=12)
axes[0].set_ylabel('‰∫àÊ∏¨ÂÄ§ (K)', fontsize=12)
axes[0].set_title('„É©„É≥„ÉÄ„É†„Éï„Ç©„É¨„Çπ„ÉàÔºö‰∫àÊ∏¨ÁµêÊûú', fontsize=14)
axes[0].legend()
axes[0].grid(True, alpha=0.3)

# Âè≥ÔºöÁâπÂæ¥Èáè„ÅÆÈáçË¶ÅÂ∫¶
axes[1].barh(feature_importance['ÁâπÂæ¥Èáè'], feature_importance['ÈáçË¶ÅÂ∫¶'])
axes[1].set_xlabel('ÈáçË¶ÅÂ∫¶', fontsize=12)
axes[1].set_title('ÁâπÂæ¥Èáè„ÅÆÈáçË¶ÅÂ∫¶', fontsize=14)
axes[1].grid(True, alpha=0.3, axis='x')

plt.tight_layout()
plt.show()
</code></pre>
<p><strong>„Ç≥„Éº„ÉâËß£Ë™¨Ôºö</strong>
1. <strong>ÈùûÁ∑öÂΩ¢„Éá„Éº„Çø</strong>Ôºö‰∫åÊ¨°È†Ö„Å®Áõ∏‰∫í‰ΩúÁî®È†Ö„ÇíÂê´„ÇÄË§áÈõë„Å™Èñ¢‰øÇ
2. <strong>„Éè„Ç§„Éë„Éº„Éë„É©„É°„Éº„Çø</strong>Ôºö
   - <code>n_estimators</code>: Ê±∫ÂÆöÊú®„ÅÆÊï∞Ôºà100Êú¨Ôºâ
   - <code>max_depth</code>: Êú®„ÅÆÊ∑±„ÅïÔºà10Â±§Ôºâ
   - <code>min_samples_split</code>: ÂàÜÂ≤ê„ÅÆÊúÄÂ∞è„Çµ„É≥„Éó„É´Êï∞Ôºà5ÂÄãÔºâ
3. <strong>ÁâπÂæ¥ÈáèÈáçË¶ÅÂ∫¶</strong>Ôºö„Å©„ÅÆÁâπÂæ¥Èáè„Åå‰∫àÊ∏¨„Å´ÂØÑ‰∏é„Åó„Å¶„ÅÑ„Çã„Åã
4. <strong>OOB„Çπ„Ç≥„Ç¢</strong>ÔºöË®ìÁ∑¥„Éá„Éº„Çø„ÅÆ‰∏ÄÈÉ®„ÅßÊ§úË®ºÔºàÈÅéÂ≠¶Áøí„ÉÅ„Çß„ÉÉ„ÇØÔºâ</p>
<p><strong>ÊúüÂæÖ„Åï„Çå„ÇãÁµêÊûúÔºö</strong>
- MAE: 10-20 KÔºàÁ∑öÂΩ¢ÂõûÂ∏∞„Çà„ÇäÊîπÂñÑÔºâ
- R¬≤: 0.90-0.98ÔºàÈ´òÁ≤æÂ∫¶Ôºâ
- Ë®ìÁ∑¥ÊôÇÈñì: 0.1-0.5Áßí</p>
<hr />
<h3>2.3 Example 3: ÂãæÈÖç„Éñ„Éº„Çπ„ÉÜ„Ç£„É≥„Ç∞ÔºàXGBoost/LightGBMÔºâ</h3>
<p><strong>Ê¶ÇË¶ÅÔºö</strong>
Ê±∫ÂÆöÊú®„ÇíÈÄêÊ¨°ÁöÑ„Å´Â≠¶Áøí„Åó„ÄÅË™§Â∑Æ„ÇíÊ∏õ„Çâ„Åó„Å¶„ÅÑ„ÅèÊâãÊ≥ï„ÄÇKaggle„Ç≥„É≥„Éö„ÅßÈ†ªÁπÅ„Å´ÂÑ™Âãù„Åô„ÇãÂº∑Âäõ„Å™„É¢„Éá„É´„ÄÇ</p>
<pre><code class="language-python"># LightGBM„Çí„Ç§„É≥„Çπ„Éà„Éº„É´ÔºàÂàùÂõû„ÅÆ„ÅøÔºâ
# pip install lightgbm

import lightgbm as lgb

# LightGBM„É¢„Éá„É´„ÅÆÊßãÁØâ
start_time = time.time()
model_lgb = lgb.LGBMRegressor(
    n_estimators=100,       # „Éñ„Éº„Çπ„ÉÜ„Ç£„É≥„Ç∞„É©„Ç¶„É≥„ÉâÊï∞
    learning_rate=0.1,      # Â≠¶ÁøíÁéáÔºàÂ∞è„Åï„ÅÑ„Åª„Å©ÊÖéÈáç„ÄÅÂ§ß„Åç„ÅÑ„Åª„Å©ÈÄü„ÅÑÔºâ
    max_depth=5,            # Êú®„ÅÆÊ∑±„Åï
    num_leaves=31,          # Ëëâ„Éé„Éº„ÉâÊï∞ÔºàLightGBMÁâπÊúâÔºâ
    subsample=0.8,          # „Çµ„É≥„Éó„É™„É≥„Ç∞ÊØîÁéáÔºàÈÅéÂ≠¶ÁøíÈò≤Ê≠¢Ôºâ
    colsample_bytree=0.8,   # ÁâπÂæ¥Èáè„Çµ„É≥„Éó„É™„É≥„Ç∞ÊØîÁéá
    random_state=42,
    verbose=-1              # Ë®ìÁ∑¥„É≠„Ç∞„ÇíÈùûË°®Á§∫
)
model_lgb.fit(
    X_train_rf, y_train_rf,
    eval_set=[(X_test_rf, y_test_rf)],  # Ê§úË®º„Éá„Éº„Çø
    eval_metric='mae',       # Ë©ï‰æ°ÊåáÊ®ô
    callbacks=[lgb.early_stopping(stopping_rounds=10, verbose=False)]  # Êó©ÊúüÁµÇ‰∫Ü
)
training_time_lgb = time.time() - start_time

# ‰∫àÊ∏¨„Å®Ë©ï‰æ°
y_pred_lgb = model_lgb.predict(X_test_rf)
mae_lgb = mean_absolute_error(y_test_rf, y_pred_lgb)
r2_lgb = r2_score(y_test_rf, y_pred_lgb)

print(&quot;\n===== LightGBM„É¢„Éá„É´„ÅÆÊÄßËÉΩ =====&quot;)
print(f&quot;Ë®ìÁ∑¥ÊôÇÈñì: {training_time_lgb:.4f} Áßí&quot;)
print(f&quot;Âπ≥ÂùáÁµ∂ÂØæË™§Â∑Æ (MAE): {mae_lgb:.2f} K&quot;)
print(f&quot;Ê±∫ÂÆö‰øÇÊï∞ (R¬≤): {r2_lgb:.4f}&quot;)

# Â≠¶ÁøíÊõ≤Á∑ö„ÅÆË°®Á§∫ÔºàË®ìÁ∑¥„ÅÆÈÄ≤Ë°åÁä∂Ê≥ÅÔºâ
fig, ax = plt.subplots(figsize=(10, 6))
lgb.plot_metric(model_lgb, metric='mae', ax=ax)
ax.set_title('LightGBMÂ≠¶ÁøíÊõ≤Á∑öÔºàMAE„ÅÆÂ§âÂåñÔºâ', fontsize=14)
ax.set_xlabel('„Éñ„Éº„Çπ„ÉÜ„Ç£„É≥„Ç∞„É©„Ç¶„É≥„Éâ', fontsize=12)
ax.set_ylabel('MAE (K)', fontsize=12)
ax.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()
</code></pre>
<p><strong>„Ç≥„Éº„ÉâËß£Ë™¨Ôºö</strong>
1. <strong>ÂãæÈÖç„Éñ„Éº„Çπ„ÉÜ„Ç£„É≥„Ç∞</strong>ÔºöÂâç„ÅÆÊú®„ÅÆË™§Â∑Æ„ÇíÊ¨°„ÅÆÊú®„Åß‰øÆÊ≠£
2. <strong>Early Stopping</strong>ÔºöÊ§úË®ºË™§Â∑Æ„ÅåÊîπÂñÑ„Åó„Å™„Åè„Å™„Å£„Åü„ÇâË®ìÁ∑¥„ÇíÂÅúÊ≠¢ÔºàÈÅéÂ≠¶ÁøíÈò≤Ê≠¢Ôºâ
3. <strong>Â≠¶ÁøíÁéá</strong>Ôºö0.1Ôºà‰∏ÄËà¨ÁöÑ„Å™ÂÄ§„ÄÅ0.01-0.3„ÅÆÁØÑÂõ≤Ôºâ
4. <strong>„Çµ„Éñ„Çµ„É≥„Éó„É™„É≥„Ç∞</strong>ÔºöÂêÑ„É©„Ç¶„É≥„Éâ„Åß„Éá„Éº„Çø„ÅÆ80%„Çí„É©„É≥„ÉÄ„É†ÈÅ∏Êäû</p>
<p><strong>ÊúüÂæÖ„Åï„Çå„ÇãÁµêÊûúÔºö</strong>
- MAE: 8-15 KÔºà„É©„É≥„ÉÄ„É†„Éï„Ç©„É¨„Çπ„Éà„Å®ÂêåÁ≠â‰ª•‰∏äÔºâ
- R¬≤: 0.92-0.99
- Ë®ìÁ∑¥ÊôÇÈñì: 0.2-0.8Áßí</p>
<hr />
<h3>2.4 Example 4: „Çµ„Éù„Éº„Éà„Éô„ÇØ„Çø„ÉºÂõûÂ∏∞ÔºàSVRÔºâ</h3>
<p><strong>Ê¶ÇË¶ÅÔºö</strong>
„Çµ„Éù„Éº„Éà„Éô„ÇØ„Çø„Éº„Éû„Ç∑„É≥„ÅÆÂõûÂ∏∞Áâà„ÄÇ„Ç´„Éº„Éç„É´„Éà„É™„ÉÉ„ÇØ„Å´„Çà„ÇäÈùûÁ∑öÂΩ¢Èñ¢‰øÇ„ÇíÂ≠¶Áøí„ÄÇ</p>
<pre><code class="language-python">from sklearn.svm import SVR
from sklearn.preprocessing import StandardScaler

# SVR„ÅØÁâπÂæ¥Èáè„ÅÆ„Çπ„Ç±„Éº„É´„Å´ÊïèÊÑü„Å™„Åü„ÇÅ„ÄÅÊ®ôÊ∫ñÂåñ„ÅåÂøÖÈ†à
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train_rf)
X_test_scaled = scaler.transform(X_test_rf)

# SVR„É¢„Éá„É´„ÅÆÊßãÁØâ
start_time = time.time()
model_svr = SVR(
    kernel='rbf',      # „Ç¨„Ç¶„Ç∑„Ç¢„É≥„Ç´„Éº„Éç„É´ÔºàÈùûÁ∑öÂΩ¢„Å´ÂØæÂøúÔºâ
    C=100,             # Ê≠£ÂâáÂåñ„Éë„É©„É°„Éº„ÇøÔºàÂ§ß„Åç„ÅÑ„Åª„Å©Ë®ìÁ∑¥„Éá„Éº„Çø„Å´ÈÅ©ÂêàÔºâ
    gamma='scale',     # „Ç´„Éº„Éç„É´‰øÇÊï∞Ôºà'scale'„ÅØËá™ÂãïË®≠ÂÆöÔºâ
    epsilon=0.1        # „Ç§„Éó„Ç∑„É≠„É≥„ÉÅ„É•„Éº„ÉñÂπÖÔºà„Åì„ÅÆÁØÑÂõ≤ÂÜÖ„ÅÆË™§Â∑Æ„ÅØÁÑ°Ë¶ñÔºâ
)
model_svr.fit(X_train_scaled, y_train_rf)
training_time_svr = time.time() - start_time

# ‰∫àÊ∏¨„Å®Ë©ï‰æ°
y_pred_svr = model_svr.predict(X_test_scaled)
mae_svr = mean_absolute_error(y_test_rf, y_pred_svr)
r2_svr = r2_score(y_test_rf, y_pred_svr)

print(&quot;\n===== SVR„É¢„Éá„É´„ÅÆÊÄßËÉΩ =====&quot;)
print(f&quot;Ë®ìÁ∑¥ÊôÇÈñì: {training_time_svr:.4f} Áßí&quot;)
print(f&quot;Âπ≥ÂùáÁµ∂ÂØæË™§Â∑Æ (MAE): {mae_svr:.2f} K&quot;)
print(f&quot;Ê±∫ÂÆö‰øÇÊï∞ (R¬≤): {r2_svr:.4f}&quot;)
print(f&quot;„Çµ„Éù„Éº„Éà„Éô„ÇØ„Çø„ÉºÊï∞: {len(model_svr.support_)}/{len(X_train_rf)}&quot;)

# ÂèØË¶ñÂåñ
plt.figure(figsize=(10, 6))
plt.scatter(y_test_rf, y_pred_svr, alpha=0.6, s=100, c='purple')
plt.plot([y_test_rf.min(), y_test_rf.max()],
         [y_test_rf.min(), y_test_rf.max()],
         'r--', lw=2, label='ÂÆåÂÖ®„Å™‰∫àÊ∏¨')
plt.xlabel('ÂÆüÊ∏¨ÂÄ§ (K)', fontsize=12)
plt.ylabel('‰∫àÊ∏¨ÂÄ§ (K)', fontsize=12)
plt.title('SVRÔºöËûçÁÇπ„ÅÆ‰∫àÊ∏¨ÁµêÊûú', fontsize=14)
plt.legend()
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()
</code></pre>
<p><strong>„Ç≥„Éº„ÉâËß£Ë™¨Ôºö</strong>
1. <strong>Ê®ôÊ∫ñÂåñ</strong>ÔºöÂπ≥Âùá0„ÄÅÊ®ôÊ∫ñÂÅèÂ∑Æ1„Å´Â§âÊèõÔºàSVR„Å´ÂøÖÈ†àÔºâ
2. <strong>RBF„Ç´„Éº„Éç„É´</strong>Ôºö„Ç¨„Ç¶„Ç∑„Ç¢„É≥Èñ¢Êï∞„ÅßÈùûÁ∑öÂΩ¢Â§âÊèõ
3. <strong>C„Éë„É©„É°„Éº„Çø</strong>ÔºöÂ§ß„Åç„ÅÑ„Åª„Å©Ë®ìÁ∑¥„Éá„Éº„Çø„Å´Âé≥ÂØÜ„Å´ÈÅ©ÂêàÔºàÈÅéÂ≠¶Áøí„É™„Çπ„ÇØ‚ÜëÔºâ
4. <strong>„Çµ„Éù„Éº„Éà„Éô„ÇØ„Çø„Éº</strong>Ôºö‰∫àÊ∏¨„Å´‰ΩøÁî®„Åô„ÇãÈáçË¶Å„Å™„Éá„Éº„ÇøÁÇπ</p>
<p><strong>ÊúüÂæÖ„Åï„Çå„ÇãÁµêÊûúÔºö</strong>
- MAE: 12-25 K
- R¬≤: 0.85-0.95
- Ë®ìÁ∑¥ÊôÇÈñì: 0.5-2ÁßíÔºà‰ªñ„É¢„Éá„É´„Çà„ÇäÈÅÖ„ÅÑÔºâ</p>
<hr />
<h3>2.5 Example 5: „Éã„É•„Éº„É©„É´„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØÔºàMLPÔºâ</h3>
<p><strong>Ê¶ÇË¶ÅÔºö</strong>
Â§öÂ±§„Éë„Éº„Çª„Éó„Éà„É≠„É≥„ÄÇÊ∑±Â±§Â≠¶Áøí„ÅÆÂü∫Á§é„É¢„Éá„É´„ÄÇ</p>
<pre><code class="language-python">from sklearn.neural_network import MLPRegressor

# MLP„É¢„Éá„É´„ÅÆÊßãÁØâ
start_time = time.time()
model_mlp = MLPRegressor(
    hidden_layer_sizes=(64, 32, 16),  # 3Â±§Ôºö64‚Üí32‚Üí16„Éã„É•„Éº„É≠„É≥
    activation='relu',         # Ê¥ªÊÄßÂåñÈñ¢Êï∞ÔºàReLU: ÊúÄ„ÇÇ‰∏ÄËà¨ÁöÑÔºâ
    solver='adam',             # ÊúÄÈÅ©Âåñ„Ç¢„É´„Ç¥„É™„Ç∫„É†ÔºàAdam: ÈÅ©ÂøúÁöÑÂ≠¶ÁøíÁéáÔºâ
    alpha=0.001,               # L2Ê≠£ÂâáÂåñ„Éë„É©„É°„Éº„ÇøÔºàÈÅéÂ≠¶ÁøíÈò≤Ê≠¢Ôºâ
    learning_rate_init=0.01,   # ÂàùÊúüÂ≠¶ÁøíÁéá
    max_iter=500,              # ÊúÄÂ§ß„Ç®„Éù„ÉÉ„ÇØÊï∞
    random_state=42,
    early_stopping=True,       # Ê§úË®ºË™§Â∑Æ„ÅåÊîπÂñÑ„Åó„Å™„Åë„Çå„Å∞ÂÅúÊ≠¢
    validation_fraction=0.2,   # Ë®ìÁ∑¥„Éá„Éº„Çø„ÅÆ20%„ÇíÊ§úË®º„Å´‰ΩøÁî®
    verbose=False
)
model_mlp.fit(X_train_scaled, y_train_rf)
training_time_mlp = time.time() - start_time

# ‰∫àÊ∏¨„Å®Ë©ï‰æ°
y_pred_mlp = model_mlp.predict(X_test_scaled)
mae_mlp = mean_absolute_error(y_test_rf, y_pred_mlp)
r2_mlp = r2_score(y_test_rf, y_pred_mlp)

print(&quot;\n===== MLP„É¢„Éá„É´„ÅÆÊÄßËÉΩ =====&quot;)
print(f&quot;Ë®ìÁ∑¥ÊôÇÈñì: {training_time_mlp:.4f} Áßí&quot;)
print(f&quot;Âπ≥ÂùáÁµ∂ÂØæË™§Â∑Æ (MAE): {mae_mlp:.2f} K&quot;)
print(f&quot;Ê±∫ÂÆö‰øÇÊï∞ (R¬≤): {r2_mlp:.4f}&quot;)
print(f&quot;„Ç§„ÉÜ„É¨„Éº„Ç∑„Éß„É≥Êï∞: {model_mlp.n_iter_}&quot;)
print(f&quot;ÊêçÂ§±: {model_mlp.loss_:.4f}&quot;)

# Â≠¶ÁøíÊõ≤Á∑ö„ÅÆÂèØË¶ñÂåñ
plt.figure(figsize=(10, 6))
plt.plot(model_mlp.loss_curve_, label='Training Loss', lw=2)
plt.xlabel('„Ç®„Éù„ÉÉ„ÇØ', fontsize=12)
plt.ylabel('ÊêçÂ§±', fontsize=12)
plt.title('MLP„ÅÆÂ≠¶ÁøíÊõ≤Á∑ö', fontsize=14)
plt.legend()
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()
</code></pre>
<p><strong>„Ç≥„Éº„ÉâËß£Ë™¨Ôºö</strong>
1. <strong>Èö†„ÇåÂ±§</strong>Ôºö(64, 32, 16) = 3Â±§„ÅÆ„Éã„É•„Éº„É©„É´„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ
2. <strong>ReLUÊ¥ªÊÄßÂåñÈñ¢Êï∞</strong>ÔºöÈùûÁ∑öÂΩ¢ÊÄß„ÇíÂ∞éÂÖ•
3. <strong>AdamÊúÄÈÅ©Âåñ</strong>ÔºöÈÅ©ÂøúÁöÑÂ≠¶ÁøíÁéá„ÅßÂäπÁéáÁöÑ„Å´Â≠¶Áøí
4. <strong>Early Stopping</strong>ÔºöÈÅéÂ≠¶Áøí„ÇíÈò≤Ê≠¢</p>
<p><strong>ÊúüÂæÖ„Åï„Çå„ÇãÁµêÊûúÔºö</strong>
- MAE: 10-20 K
- R¬≤: 0.90-0.98
- Ë®ìÁ∑¥ÊôÇÈñì: 1-3ÁßíÔºà‰ªñ„É¢„Éá„É´„Çà„ÇäÈÅÖ„ÅÑÔºâ</p>
<hr />
<h3>2.6 Example 6: Materials Project APIÂÆü„Éá„Éº„ÇøÁµ±Âêà</h3>
<p><strong>Ê¶ÇË¶ÅÔºö</strong>
ÂÆüÈöõ„ÅÆÊùêÊñô„Éá„Éº„Çø„Éô„Éº„Çπ„Åã„Çâ„Éá„Éº„Çø„ÇíÂèñÂæó„Åó„ÄÅÊ©üÊ¢∞Â≠¶Áøí„Åß‰∫àÊ∏¨„ÄÇ</p>
<pre><code class="language-python"># Materials Project API„Çí‰ΩøÁî®ÔºàÁÑ°ÊñôAPI„Ç≠„Éº„ÅåÂøÖË¶ÅÔºâ
# ÁôªÈå≤: https://materialsproject.org

# Ê≥®ÊÑè: ‰ª•‰∏ã„ÅÆ„Ç≥„Éº„Éâ„ÅØAPI„Ç≠„ÉºÂèñÂæóÂæå„Å´ÂÆüË°å„Åó„Å¶„Åè„Å†„Åï„ÅÑ
# „Åì„Åì„Åß„ÅØÊ®°Êì¨„Éá„Éº„Çø„ÅßÂãï‰Ωú„ÇíÁ§∫„Åó„Åæ„Åô

try:
    from pymatgen.ext.matproj import MPRester

    # API„Ç≠„Éº„ÇíË®≠ÂÆöÔºà'YOUR_API_KEY'„ÇíÂÆüÈöõ„ÅÆ„Ç≠„Éº„Å´ÁΩÆ„ÅçÊèõ„ÅàÔºâ
    API_KEY = &quot;YOUR_API_KEY&quot;

    with MPRester(API_KEY) as mpr:
        # „É™„ÉÅ„Ç¶„É†ÂåñÂêàÁâ©„ÅÆ„Éê„É≥„Éâ„ÇÆ„É£„ÉÉ„Éó„Éá„Éº„Çø„ÇíÂèñÂæó
        entries = mpr.query(
            criteria={
                &quot;elements&quot;: {&quot;$all&quot;: [&quot;Li&quot;]},
                &quot;nelements&quot;: {&quot;$lte&quot;: 2}
            },
            properties=[
                &quot;material_id&quot;,
                &quot;pretty_formula&quot;,
                &quot;band_gap&quot;,
                &quot;formation_energy_per_atom&quot;
            ]
        )

        # DataFrame„Å´Â§âÊèõ
        df_mp = pd.DataFrame(entries)
        print(f&quot;ÂèñÂæó„Éá„Éº„ÇøÊï∞: {len(df_mp)}‰ª∂&quot;)
        print(df_mp.head())

except ImportError:
    print(&quot;pymatgen„Åå„Ç§„É≥„Çπ„Éà„Éº„É´„Åï„Çå„Å¶„ÅÑ„Åæ„Åõ„Çì„ÄÇ&quot;)
    print(&quot;pip install pymatgen „Åß„Ç§„É≥„Çπ„Éà„Éº„É´„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ&quot;)
except Exception as e:
    print(f&quot;APIÊé•Á∂ö„Ç®„É©„Éº: {e}&quot;)
    print(&quot;Ê®°Êì¨„Éá„Éº„Çø„ÅßÁ∂öË°å„Åó„Åæ„Åô„ÄÇ&quot;)

    # Ê®°Êì¨„Éá„Éº„ÇøÔºàMaterials Project„ÅÆÂÖ∏ÂûãÁöÑ„Å™„Éá„Éº„ÇøÂΩ¢ÂºèÔºâ
    df_mp = pd.DataFrame({
        'material_id': ['mp-1', 'mp-2', 'mp-3', 'mp-4', 'mp-5'],
        'pretty_formula': ['Li', 'Li2O', 'LiH', 'Li3N', 'LiF'],
        'band_gap': [0.0, 7.5, 3.9, 1.2, 13.8],
        'formation_energy_per_atom': [0.0, -2.9, -0.5, -0.8, -3.5]
    })
    print(&quot;Ê®°Êì¨„Éá„Éº„Çø„Çí‰ΩøÁî®„Åó„Åæ„Åô:&quot;)
    print(df_mp)

# Ê©üÊ¢∞Â≠¶Áøí„ÅßÂΩ¢Êàê„Ç®„Éç„É´„ÇÆ„Éº„Åã„Çâ„Éê„É≥„Éâ„ÇÆ„É£„ÉÉ„Éó„Çí‰∫àÊ∏¨
if len(df_mp) &gt; 5:
    X_mp = df_mp[['formation_energy_per_atom']].values
    y_mp = df_mp['band_gap'].values

    X_train_mp, X_test_mp, y_train_mp, y_test_mp = train_test_split(
        X_mp, y_mp, test_size=0.2, random_state=42
    )

    # „É©„É≥„ÉÄ„É†„Éï„Ç©„É¨„Çπ„Éà„Åß‰∫àÊ∏¨
    model_mp = RandomForestRegressor(n_estimators=100, random_state=42)
    model_mp.fit(X_train_mp, y_train_mp)

    y_pred_mp = model_mp.predict(X_test_mp)
    mae_mp = mean_absolute_error(y_test_mp, y_pred_mp)
    r2_mp = r2_score(y_test_mp, y_pred_mp)

    print(f&quot;\n===== Materials Project„Éá„Éº„Çø„Åß„ÅÆ‰∫àÊ∏¨ÊÄßËÉΩ =====&quot;)
    print(f&quot;MAE: {mae_mp:.2f} eV&quot;)
    print(f&quot;R¬≤: {r2_mp:.4f}&quot;)
else:
    print(&quot;„Éá„Éº„ÇøÊï∞„ÅåÂ∞ë„Å™„ÅÑ„Åü„ÇÅ„ÄÅÊ©üÊ¢∞Â≠¶Áøí„ÅØ„Çπ„Ç≠„ÉÉ„Éó„Åó„Åæ„Åô„ÄÇ&quot;)
</code></pre>
<p><strong>„Ç≥„Éº„ÉâËß£Ë™¨Ôºö</strong>
1. <strong>MPRester</strong>ÔºöMaterials Project API„ÇØ„É©„Ç§„Ç¢„É≥„Éà
2. <strong>query()</strong>: ÊùêÊñô„ÇíÊ§úÁ¥¢ÔºàÂÖÉÁ¥†„ÄÅÁâπÊÄß„ÅßÁµû„ÇäËæº„ÅøÔºâ
3. <strong>ÂÆü„Éá„Éº„Çø„ÅÆÂà©ÁÇπ</strong>ÔºöDFTË®àÁÆó„Å´„Çà„Çã‰ø°È†ºÊÄß„ÅÆÈ´ò„ÅÑ„Éá„Éº„Çø</p>
<p><strong>ÊúüÂæÖ„Åï„Çå„ÇãÁµêÊûúÔºö</strong>
- ÂÆü„Éá„Éº„ÇøÂèñÂæóÊï∞Ôºö10-100‰ª∂ÔºàÊ§úÁ¥¢Êù°‰ª∂„Å´„Çà„ÇãÔºâ
- ‰∫àÊ∏¨ÊÄßËÉΩ„ÅØ„Éá„Éº„ÇøÊï∞„Å´‰æùÂ≠òÔºàR¬≤: 0.6-0.9Ôºâ</p>
<hr />
<h2>3. „É¢„Éá„É´ÊÄßËÉΩ„ÅÆÊØîËºÉ</h2>
<p>„Åô„Åπ„Å¶„ÅÆ„É¢„Éá„É´„ÇíÂêå„Åò„Éá„Éº„Çø„ÅßË©ï‰æ°„Åó„ÄÅÊÄßËÉΩ„ÇíÊØîËºÉ„Åó„Åæ„Åô„ÄÇ</p>
<h3>3.1 Á∑èÂêàÊØîËºÉË°®</h3>
<table>
<thead>
<tr>
<th>„É¢„Éá„É´</th>
<th>MAE (K)</th>
<th>R¬≤</th>
<th style="text-align: right;">Ë®ìÁ∑¥ÊôÇÈñì (Áßí)</th>
<th>„É°„É¢„É™</th>
<th>Ëß£ÈáàÊÄß</th>
</tr>
</thead>
<tbody>
<tr>
<td>Á∑öÂΩ¢ÂõûÂ∏∞</td>
<td>18.5</td>
<td>0.952</td>
<td style="text-align: right;">0.005</td>
<td>Â∞è</td>
<td>‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê</td>
</tr>
<tr>
<td>„É©„É≥„ÉÄ„É†„Éï„Ç©„É¨„Çπ„Éà</td>
<td>12.3</td>
<td>0.982</td>
<td style="text-align: right;">0.32</td>
<td>‰∏≠</td>
<td>‚≠ê‚≠ê‚≠ê‚≠ê</td>
</tr>
<tr>
<td>LightGBM</td>
<td>10.8</td>
<td>0.987</td>
<td style="text-align: right;">0.45</td>
<td>‰∏≠</td>
<td>‚≠ê‚≠ê‚≠ê</td>
</tr>
<tr>
<td>SVR</td>
<td>15.2</td>
<td>0.965</td>
<td style="text-align: right;">1.85</td>
<td>Â§ß</td>
<td>‚≠ê‚≠ê</td>
</tr>
<tr>
<td>MLP</td>
<td>13.1</td>
<td>0.978</td>
<td style="text-align: right;">2.10</td>
<td>Â§ß</td>
<td>‚≠ê</td>
</tr>
</tbody>
</table>
<p><strong>Âá°‰æãÔºö</strong>
- <strong>MAE</strong>: Â∞è„Åï„ÅÑ„Åª„Å©ËâØ„ÅÑÔºàÂπ≥ÂùáË™§Â∑ÆÔºâ
- <strong>R¬≤</strong>: 1„Å´Ëøë„ÅÑ„Åª„Å©ËâØ„ÅÑÔºàË™¨ÊòéÂäõÔºâ
- <strong>Ë®ìÁ∑¥ÊôÇÈñì</strong>: Áü≠„ÅÑ„Åª„Å©ËâØ„ÅÑ
- <strong>„É°„É¢„É™</strong>: Â∞è &lt; ‰∏≠ &lt; Â§ß
- <strong>Ëß£ÈáàÊÄß</strong>: ‚≠êÂ§ö„ÅÑ„Åª„Å©Ëß£Èáà„Åó„ÇÑ„Åô„ÅÑ</p>
<h3>3.2 ÂèØË¶ñÂåñÔºöÊÄßËÉΩÊØîËºÉ</h3>
<pre><code class="language-python">import matplotlib.pyplot as plt

# „É¢„Éá„É´ÊÄßËÉΩ„Éá„Éº„Çø
models = ['Á∑öÂΩ¢ÂõûÂ∏∞', '„É©„É≥„ÉÄ„É†„Éï„Ç©„É¨„Çπ„Éà', 'LightGBM', 'SVR', 'MLP']
mae_scores = [18.5, 12.3, 10.8, 15.2, 13.1]
r2_scores = [0.952, 0.982, 0.987, 0.965, 0.978]
training_times = [0.005, 0.32, 0.45, 1.85, 2.10]

fig, axes = plt.subplots(1, 3, figsize=(18, 5))

# MAEÊØîËºÉ
axes[0].bar(models, mae_scores, color=['blue', 'green', 'orange', 'purple', 'red'])
axes[0].set_ylabel('MAE (K)', fontsize=12)
axes[0].set_title('Âπ≥ÂùáÁµ∂ÂØæË™§Â∑ÆÔºàÂ∞è„Åï„ÅÑ„Åª„Å©ËâØ„ÅÑÔºâ', fontsize=14)
axes[0].tick_params(axis='x', rotation=45)
axes[0].grid(True, alpha=0.3, axis='y')

# R¬≤ÊØîËºÉ
axes[1].bar(models, r2_scores, color=['blue', 'green', 'orange', 'purple', 'red'])
axes[1].set_ylabel('R¬≤', fontsize=12)
axes[1].set_title('Ê±∫ÂÆö‰øÇÊï∞Ôºà1„Å´Ëøë„ÅÑ„Åª„Å©ËâØ„ÅÑÔºâ', fontsize=14)
axes[1].tick_params(axis='x', rotation=45)
axes[1].grid(True, alpha=0.3, axis='y')
axes[1].set_ylim(0.9, 1.0)

# Ë®ìÁ∑¥ÊôÇÈñìÊØîËºÉ
axes[2].bar(models, training_times, color=['blue', 'green', 'orange', 'purple', 'red'])
axes[2].set_ylabel('Ë®ìÁ∑¥ÊôÇÈñì (Áßí)', fontsize=12)
axes[2].set_title('Ë®ìÁ∑¥ÊôÇÈñìÔºàÁü≠„ÅÑ„Åª„Å©ËâØ„ÅÑÔºâ', fontsize=14)
axes[2].tick_params(axis='x', rotation=45)
axes[2].grid(True, alpha=0.3, axis='y')

plt.tight_layout()
plt.show()
</code></pre>
<h3>3.3 „É¢„Éá„É´ÈÅ∏Êäû„ÅÆ„Éï„É≠„Éº„ÉÅ„É£„Éº„Éà</h3>
<div class="mermaid">
graph TD
    A[ÊùêÊñôÁâπÊÄß‰∫àÊ∏¨„Çø„Çπ„ÇØ] --> B{„Éá„Éº„ÇøÊï∞„ÅØÔºü}
    B -->|< 100| C[Á∑öÂΩ¢ÂõûÂ∏∞ or SVR]
    B -->|100-1000| D[„É©„É≥„ÉÄ„É†„Éï„Ç©„É¨„Çπ„Éà]
    B -->|> 1000| E{Ë®àÁÆóÊôÇÈñì„ÅÆÂà∂Á¥Ñ„ÅØÔºü}

    E -->|Âé≥„Åó„ÅÑ| F[„É©„É≥„ÉÄ„É†„Éï„Ç©„É¨„Çπ„Éà]
    E -->|Á∑©„ÅÑ| G[LightGBM or MLP]

    C --> H{Ëß£ÈáàÊÄß„ÅåÈáçË¶ÅÔºü}
    H -->|„ÅØ„ÅÑ| I[Á∑öÂΩ¢ÂõûÂ∏∞]
    H -->|„ÅÑ„ÅÑ„Åà| J[SVR]

    D --> K[„É©„É≥„ÉÄ„É†„Éï„Ç©„É¨„Çπ„ÉàÊé®Â•®]
    F --> K
    G --> L{ÈùûÁ∑öÂΩ¢ÊÄß„ÅåÂº∑„ÅÑÔºü}
    L -->|„ÅØ„ÅÑ| M[MLP]
    L -->|„ÅÑ„ÅÑ„Åà| N[LightGBM]

    style A fill:#e3f2fd
    style K fill:#c8e6c9
    style M fill:#fff9c4
    style N fill:#fff9c4
    style I fill:#c8e6c9
    style J fill:#c8e6c9
</div>

<h3>3.4 „É¢„Éá„É´ÈÅ∏Êäû„Ç¨„Ç§„Éâ„É©„Ç§„É≥</h3>
<p><strong>Áä∂Ê≥ÅÂà•Êé®Â•®„É¢„Éá„É´Ôºö</strong></p>
<table>
<thead>
<tr>
<th>Áä∂Ê≥Å</th>
<th>Êé®Â•®„É¢„Éá„É´</th>
<th>ÁêÜÁî±</th>
</tr>
</thead>
<tbody>
<tr>
<td>„Éá„Éº„ÇøÊï∞ &lt; 100</td>
<td>Á∑öÂΩ¢ÂõûÂ∏∞ or SVR</td>
<td>ÈÅéÂ≠¶Áøí„ÇíÈò≤Ê≠¢„ÄÅ„Ç∑„É≥„Éó„É´„Å™„É¢„Éá„É´„ÅåÂÆâÂÖ®</td>
</tr>
<tr>
<td>„Éá„Éº„ÇøÊï∞ 100-1000</td>
<td>„É©„É≥„ÉÄ„É†„Éï„Ç©„É¨„Çπ„Éà</td>
<td>„Éê„É©„É≥„Çπ„ÅåËâØ„ÅÑ„ÄÅ„Éè„Ç§„Éë„Éº„Éë„É©„É°„Éº„ÇøË™øÊï¥„ÅåÂÆπÊòì</td>
</tr>
<tr>
<td>„Éá„Éº„ÇøÊï∞ &gt; 1000</td>
<td>LightGBM or MLP</td>
<td>Â§ßË¶èÊ®°„Éá„Éº„Çø„ÅßÈ´òÁ≤æÂ∫¶</td>
</tr>
<tr>
<td>Ëß£ÈáàÊÄß„ÅåÈáçË¶Å</td>
<td>Á∑öÂΩ¢ÂõûÂ∏∞ or „É©„É≥„ÉÄ„É†„Éï„Ç©„É¨„Çπ„Éà</td>
<td>‰øÇÊï∞„ÇÑÁâπÂæ¥ÈáèÈáçË¶ÅÂ∫¶„ÅåÂàÜ„Åã„Çä„ÇÑ„Åô„ÅÑ</td>
</tr>
<tr>
<td>Ë®àÁÆóÊôÇÈñì„ÅåÂé≥„Åó„ÅÑ</td>
<td>Á∑öÂΩ¢ÂõûÂ∏∞ or „É©„É≥„ÉÄ„É†„Éï„Ç©„É¨„Çπ„Éà</td>
<td>Ë®ìÁ∑¥„ÅåÈ´òÈÄü</td>
</tr>
<tr>
<td>ÊúÄÈ´òÁ≤æÂ∫¶„ÅåÂøÖË¶Å</td>
<td>LightGBMÔºà„Ç¢„É≥„Çµ„É≥„Éñ„É´‰ΩµÁî®Ôºâ</td>
<td>Kaggle„Ç≥„É≥„Éö„ÅßÂÆüÁ∏æÂ§öÊï∞</td>
</tr>
<tr>
<td>ÈùûÁ∑öÂΩ¢ÊÄß„ÅåÂº∑„ÅÑ</td>
<td>MLP or SVR</td>
<td>Ë§áÈõë„Å™Èñ¢‰øÇ„ÇíÂ≠¶ÁøíÂèØËÉΩ</td>
</tr>
</tbody>
</table>
<hr />
<h2>4. „Éè„Ç§„Éë„Éº„Éë„É©„É°„Éº„Çø„ÉÅ„É•„Éº„Éã„É≥„Ç∞</h2>
<p>„É¢„Éá„É´„ÅÆÊÄßËÉΩ„ÇíÊúÄÂ§ßÂåñ„Åô„Çã„Åü„ÇÅ„ÄÅ„Éè„Ç§„Éë„Éº„Éë„É©„É°„Éº„Çø„ÇíÊúÄÈÅ©Âåñ„Åó„Åæ„Åô„ÄÇ</p>
<h3>4.1 „Éè„Ç§„Éë„Éº„Éë„É©„É°„Éº„Çø„Å®„ÅØ</h3>
<p><strong>ÂÆöÁæ©Ôºö</strong>
Ê©üÊ¢∞Â≠¶Áøí„É¢„Éá„É´„ÅÆË®≠ÂÆöÂÄ§ÔºàÂ≠¶ÁøíÂâç„Å´Ê±∫„ÇÅ„ÇãÂøÖË¶Å„Åå„ÅÇ„ÇãÔºâ„ÄÇ</p>
<p><strong>‰æãÔºà„É©„É≥„ÉÄ„É†„Éï„Ç©„É¨„Çπ„ÉàÔºâÔºö</strong>
- <code>n_estimators</code>: Ê±∫ÂÆöÊú®„ÅÆÊï∞Ôºà10, 50, 100, 200...Ôºâ
- <code>max_depth</code>: Êú®„ÅÆÊ∑±„ÅïÔºà3, 5, 10, 20...Ôºâ
- <code>min_samples_split</code>: ÂàÜÂ≤ê„ÅÆÊúÄÂ∞è„Çµ„É≥„Éó„É´Êï∞Ôºà2, 5, 10...Ôºâ</p>
<p><strong>ÈáçË¶ÅÊÄßÔºö</strong>
ÈÅ©Âàá„Å™„Éè„Ç§„Éë„Éº„Éë„É©„É°„Éº„Çø„Åß„ÄÅÊÄßËÉΩ„Åå10-30%Âêë‰∏ä„Åô„Çã„Åì„Å®„ÇÇ„ÄÇ</p>
<h3>4.2 Grid SearchÔºà„Ç∞„É™„ÉÉ„Éâ„Çµ„Éº„ÉÅÔºâ</h3>
<p><strong>Ê¶ÇË¶ÅÔºö</strong>
„Åô„Åπ„Å¶„ÅÆÁµÑ„ÅøÂêà„Çè„Åõ„ÇíË©¶„Åó„ÄÅÊúÄËâØ„ÅÆ„ÇÇ„ÅÆ„ÇíÈÅ∏Êäû„ÄÇ</p>
<pre><code class="language-python">from sklearn.model_selection import GridSearchCV

# „É©„É≥„ÉÄ„É†„Éï„Ç©„É¨„Çπ„Éà„ÅÆ„Éè„Ç§„Éë„Éº„Éë„É©„É°„Éº„ÇøÂÄôË£ú
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [5, 10, 15, None],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}

# Grid Search„ÅÆË®≠ÂÆö
grid_search = GridSearchCV(
    estimator=RandomForestRegressor(random_state=42),
    param_grid=param_grid,
    cv=5,              # 5-fold‰∫§Â∑ÆÊ§úË®º
    scoring='neg_mean_absolute_error',  # MAE„ÅßË©ï‰æ°ÔºàÂ∞è„Åï„ÅÑ„Åª„Å©ËâØ„ÅÑÔºâ
    n_jobs=-1,         # ‰∏¶ÂàóÂÆüË°å
    verbose=1          # ÈÄ≤ÊçóË°®Á§∫
)

# Grid SearchÂÆüË°å
print(&quot;===== Grid SearchÈñãÂßã =====&quot;)
print(f&quot;Êé¢Á¥¢„Åô„ÇãÁµÑ„ÅøÂêà„Çè„ÅõÊï∞: {len(param_grid['n_estimators']) * len(param_grid['max_depth']) * len(param_grid['min_samples_split']) * len(param_grid['min_samples_leaf'])}&quot;)
start_time = time.time()
grid_search.fit(X_train_rf, y_train_rf)
grid_search_time = time.time() - start_time

# ÊúÄËâØ„ÅÆ„Éè„Ç§„Éë„Éº„Éë„É©„É°„Éº„Çø
print(f&quot;\n===== Grid SearchÂÆå‰∫ÜÔºà{grid_search_time:.2f}ÁßíÔºâ =====&quot;)
print(&quot;ÊúÄËâØ„ÅÆ„Éè„Ç§„Éë„Éº„Éë„É©„É°„Éº„Çø:&quot;)
for param, value in grid_search.best_params_.items():
    print(f&quot;  {param}: {value}&quot;)

print(f&quot;\n‰∫§Â∑ÆÊ§úË®ºMAE: {-grid_search.best_score_:.2f} K&quot;)

# ÊúÄËâØ„É¢„Éá„É´„Åß„ÉÜ„Çπ„Éà„Éá„Éº„Çø„ÇíË©ï‰æ°
best_model = grid_search.best_estimator_
y_pred_best = best_model.predict(X_test_rf)
mae_best = mean_absolute_error(y_test_rf, y_pred_best)
r2_best = r2_score(y_test_rf, y_pred_best)

print(f&quot;\n„ÉÜ„Çπ„Éà„Éá„Éº„Çø„Åß„ÅÆÊÄßËÉΩ:&quot;)
print(f&quot;  MAE: {mae_best:.2f} K&quot;)
print(f&quot;  R¬≤: {r2_best:.4f}&quot;)
</code></pre>
<p><strong>„Ç≥„Éº„ÉâËß£Ë™¨Ôºö</strong>
1. <strong>param_grid</strong>ÔºöÊé¢Á¥¢„Åô„Çã„Éè„Ç§„Éë„Éº„Éë„É©„É°„Éº„Çø„ÅÆÁØÑÂõ≤
2. <strong>GridSearchCV</strong>Ôºö„Åô„Åπ„Å¶„ÅÆÁµÑ„ÅøÂêà„Çè„ÅõÔºà3√ó4√ó3√ó3=108ÈÄö„ÇäÔºâ„ÇíË©¶„Åô
3. <strong>cv=5</strong>Ôºö5-fold‰∫§Â∑ÆÊ§úË®º„ÅßË©ï‰æ°Ôºà„Éá„Éº„Çø„Çí5ÂàÜÂâ≤Ôºâ
4. <strong>best_params_</strong>ÔºöÊúÄËâØ„ÅÆÁµÑ„ÅøÂêà„Çè„Åõ</p>
<p><strong>ÊúüÂæÖ„Åï„Çå„ÇãÁµêÊûúÔºö</strong>
- Grid SearchÊôÇÈñìÔºö10-60ÁßíÔºà„Éá„Éº„ÇøÊï∞„Å®„Éë„É©„É°„Éº„ÇøÊï∞„Å´„Çà„ÇãÔºâ
- ÊúÄËâØMAEÔºö10-15 KÔºà„Éá„Éï„Ç©„É´„Éà„Çà„ÇäÊîπÂñÑÔºâ</p>
<h3>4.3 Random SearchÔºà„É©„É≥„ÉÄ„É†„Çµ„Éº„ÉÅÔºâ</h3>
<p><strong>Ê¶ÇË¶ÅÔºö</strong>
„É©„É≥„ÉÄ„É†„Å´ÁµÑ„ÅøÂêà„Çè„Åõ„ÇíË©¶„ÅôÔºàÈ´òÈÄü„ÄÅÂ§ßË¶èÊ®°Êé¢Á¥¢Âêë„ÅëÔºâ„ÄÇ</p>
<pre><code class="language-python">from sklearn.model_selection import RandomizedSearchCV
from scipy.stats import randint, uniform

# „Éè„Ç§„Éë„Éº„Éë„É©„É°„Éº„Çø„ÅÆÂàÜÂ∏É„ÇíÊåáÂÆö
param_distributions = {
    'n_estimators': randint(50, 300),        # 50-300„ÅÆÊï¥Êï∞„Çí„É©„É≥„ÉÄ„É†ÈÅ∏Êäû
    'max_depth': randint(5, 30),             # 5-30„ÅÆÊï¥Êï∞
    'min_samples_split': randint(2, 20),     # 2-20„ÅÆÊï¥Êï∞
    'min_samples_leaf': randint(1, 10),      # 1-10„ÅÆÊï¥Êï∞
    'max_features': uniform(0.5, 0.5)        # 0.5-1.0„ÅÆÂÆüÊï∞
}

# Random Search„ÅÆË®≠ÂÆö
random_search = RandomizedSearchCV(
    estimator=RandomForestRegressor(random_state=42),
    param_distributions=param_distributions,
    n_iter=50,         # 50Âõû„É©„É≥„ÉÄ„É†„Çµ„É≥„Éó„É™„É≥„Ç∞
    cv=5,
    scoring='neg_mean_absolute_error',
    n_jobs=-1,
    random_state=42,
    verbose=1
)

# Random SearchÂÆüË°å
print(&quot;===== Random SearchÈñãÂßã =====&quot;)
start_time = time.time()
random_search.fit(X_train_rf, y_train_rf)
random_search_time = time.time() - start_time

print(f&quot;\n===== Random SearchÂÆå‰∫ÜÔºà{random_search_time:.2f}ÁßíÔºâ =====&quot;)
print(&quot;ÊúÄËâØ„ÅÆ„Éè„Ç§„Éë„Éº„Éë„É©„É°„Éº„Çø:&quot;)
for param, value in random_search.best_params_.items():
    print(f&quot;  {param}: {value}&quot;)

print(f&quot;\n‰∫§Â∑ÆÊ§úË®ºMAE: {-random_search.best_score_:.2f} K&quot;)
</code></pre>
<p><strong>Grid Search vs Random Search:</strong></p>
<table>
<thead>
<tr>
<th>È†ÖÁõÆ</th>
<th>Grid Search</th>
<th>Random Search</th>
</tr>
</thead>
<tbody>
<tr>
<td>Êé¢Á¥¢ÊñπÊ≥ï</td>
<td>„Åô„Åπ„Å¶„ÅÆÁµÑ„ÅøÂêà„Çè„Åõ</td>
<td>„É©„É≥„ÉÄ„É†„Çµ„É≥„Éó„É™„É≥„Ç∞</td>
</tr>
<tr>
<td>ÂÆüË°åÊôÇÈñì</td>
<td>Èï∑„ÅÑÔºàÂÖ®Êé¢Á¥¢Ôºâ</td>
<td>Áü≠„ÅÑÔºàÊåáÂÆöÂõûÊï∞„ÅÆ„ÅøÔºâ</td>
</tr>
<tr>
<td>ÊúÄËâØËß£„ÅÆ‰øùË®º</td>
<td>„ÅÇ„ÇäÔºàÂÖ®Êé¢Á¥¢Ôºâ</td>
<td>„Å™„ÅóÔºàÁ¢∫ÁéáÁöÑÔºâ</td>
</tr>
<tr>
<td>ÈÅ©Áî®Â†¥Èù¢</td>
<td>Â∞èË¶èÊ®°Êé¢Á¥¢</td>
<td>Â§ßË¶èÊ®°Êé¢Á¥¢</td>
</tr>
</tbody>
</table>
<h3>4.4 „Éè„Ç§„Éë„Éº„Éë„É©„É°„Éº„Çø„ÅÆÂäπÊûúÂèØË¶ñÂåñ</h3>
<pre><code class="language-python"># Grid Search„ÅÆÂÖ®ÁµêÊûú„ÇíÂèñÂæó
results = pd.DataFrame(grid_search.cv_results_)

# n_estimators„ÅÆÂΩ±Èüø„ÇíÂèØË¶ñÂåñ
fig, axes = plt.subplots(1, 2, figsize=(15, 5))

# n_estimators vs MAE
for depth in [5, 10, 15, None]:
    mask = results['param_max_depth'] == depth
    axes[0].plot(
        results[mask]['param_n_estimators'],
        -results[mask]['mean_test_score'],
        marker='o',
        label=f'max_depth={depth}'
    )

axes[0].set_xlabel('n_estimators', fontsize=12)
axes[0].set_ylabel('‰∫§Â∑ÆÊ§úË®ºMAE (K)', fontsize=12)
axes[0].set_title('n_estimators„ÅÆÂΩ±Èüø', fontsize=14)
axes[0].legend()
axes[0].grid(True, alpha=0.3)

# max_depth vs MAE
for n_est in [50, 100, 200]:
    mask = results['param_n_estimators'] == n_est
    axes[1].plot(
        results[mask]['param_max_depth'].apply(lambda x: 20 if x is None else x),
        -results[mask]['mean_test_score'],
        marker='o',
        label=f'n_estimators={n_est}'
    )

axes[1].set_xlabel('max_depth', fontsize=12)
axes[1].set_ylabel('‰∫§Â∑ÆÊ§úË®ºMAE (K)', fontsize=12)
axes[1].set_title('max_depth„ÅÆÂΩ±Èüø', fontsize=14)
axes[1].legend()
axes[1].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
</code></pre>
<hr />
<h2>5. ÁâπÂæ¥Èáè„Ç®„É≥„Ç∏„Éã„Ç¢„É™„É≥„Ç∞ÔºàÊùêÊñôÂêë„ÅëÔºâ</h2>
<p>ÊùêÊñô„Éá„Éº„Çø„Å´ÁâπÂåñ„Åó„ÅüÁâπÂæ¥Èáè„Çí‰ΩúÊàê„Åó„ÄÅ‰∫àÊ∏¨ÊÄßËÉΩ„ÇíÂêë‰∏ä„Åï„Åõ„Åæ„Åô„ÄÇ</p>
<h3>5.1 ÁâπÂæ¥Èáè„Ç®„É≥„Ç∏„Éã„Ç¢„É™„É≥„Ç∞„Å®„ÅØ</h3>
<p><strong>ÂÆöÁæ©Ôºö</strong>
Áîü„Éá„Éº„Çø„Åã„Çâ‰∫àÊ∏¨„Å´ÊúâÂäπ„Å™ÁâπÂæ¥Èáè„Çí‰ΩúÊàê„ÉªÈÅ∏Êäû„Åô„Çã„Éó„É≠„Çª„Çπ„ÄÇ</p>
<p><strong>ÈáçË¶ÅÊÄßÔºö</strong>
„ÄåËâØ„ÅÑÁâπÂæ¥Èáè &gt; È´òÂ∫¶„Å™„É¢„Éá„É´„Äç
- ÈÅ©Âàá„Å™ÁâπÂæ¥Èáè„Åß„ÄÅÂçòÁ¥î„Å™„É¢„Éá„É´„Åß„ÇÇÈ´òÁ≤æÂ∫¶„ÇíÈÅîÊàê„Åß„Åç„Çã
- ‰∏çÈÅ©Âàá„Å™ÁâπÂæ¥Èáè„Åß„ÅØ„ÄÅ„Å©„Çì„Å™„É¢„Éá„É´„Åß„ÇÇÊÄßËÉΩ„ÅØ‰∏ä„Åå„Çâ„Å™„ÅÑ</p>
<h3>5.2 Matminer„Å´„Çà„ÇãËá™ÂãïÁâπÂæ¥ÈáèÊäΩÂá∫</h3>
<p><strong>MatminerÔºö</strong>
ÊùêÊñôÁßëÂ≠¶Âêë„Åë„ÅÆÁâπÂæ¥ÈáèÊäΩÂá∫„É©„Ç§„Éñ„É©„É™„ÄÇ</p>
<pre><code class="language-bash"># „Ç§„É≥„Çπ„Éà„Éº„É´ÔºàÂàùÂõû„ÅÆ„ÅøÔºâ
pip install matminer
</code></pre>
<pre><code class="language-python">from matminer.featurizers.composition import ElementProperty
from pymatgen.core import Composition

# ÁµÑÊàê„Éá„Éº„ÇøÔºà‰æãÔºöLi2OÔºâ
compositions = ['Li2O', 'LiCoO2', 'LiFePO4', 'Li4Ti5O12']

# Composition„Ç™„Éñ„Ç∏„Çß„ÇØ„Éà„Å´Â§âÊèõ
comp_objects = [Composition(c) for c in compositions]

# ElementProperty„ÅßÁâπÂæ¥ÈáèÊäΩÂá∫
featurizer = ElementProperty.from_preset('magpie')

# ÁâπÂæ¥Èáè„ÇíË®àÁÆó
features = []
for comp in comp_objects:
    feat = featurizer.featurize(comp)
    features.append(feat)

# DataFrame„Å´Â§âÊèõ
feature_names = featurizer.feature_labels()
df_features = pd.DataFrame(features, columns=feature_names)

print(&quot;===== Matminer„ÅßÊäΩÂá∫„Åó„ÅüÁâπÂæ¥Èáè =====&quot;)
print(f&quot;ÁâπÂæ¥ÈáèÊï∞: {len(feature_names)}&quot;)
print(f&quot;\nÊúÄÂàù„ÅÆ5„Å§„ÅÆÁâπÂæ¥Èáè:&quot;)
print(df_features.head())
print(f&quot;\nÁâπÂæ¥Èáè„ÅÆ‰æã:&quot;)
for i in range(min(5, len(feature_names))):
    print(f&quot;  {feature_names[i]}&quot;)
</code></pre>
<p><strong>Matminer„ÅßÊäΩÂá∫„Åï„Çå„ÇãÁâπÂæ¥Èáè‰æãÔºö</strong>
- <code>MagpieData avg_dev MeltingT</code>ÔºöÂπ≥ÂùáËûçÁÇπ„ÅÆÂÅèÂ∑Æ
- <code>MagpieData mean Electronegativity</code>ÔºöÂπ≥ÂùáÈõªÊ∞óÈô∞ÊÄßÂ∫¶
- <code>MagpieData mean AtomicWeight</code>ÔºöÂπ≥ÂùáÂéüÂ≠êÈáè
- <code>MagpieData range Number</code>ÔºöÂéüÂ≠êÁï™Âè∑„ÅÆÁØÑÂõ≤
- ÂêàË®à130‰ª•‰∏ä„ÅÆÁâπÂæ¥Èáè</p>
<h3>5.3 ÊâãÂãïÁâπÂæ¥Èáè„Ç®„É≥„Ç∏„Éã„Ç¢„É™„É≥„Ç∞</h3>
<pre><code class="language-python"># Âü∫Êú¨„Éá„Éº„Çø
data_advanced = pd.DataFrame({
    'element_A': [0.5, 0.6, 0.7, 0.8],
    'element_B': [0.5, 0.4, 0.3, 0.2],
    'melting_point': [1200, 1250, 1300, 1350]
})

# Êñ∞„Åó„ÅÑÁâπÂæ¥Èáè„Çí‰ΩúÊàê
data_advanced['sum_AB'] = data_advanced['element_A'] + data_advanced['element_B']  # ÂêàË®àÔºàÂ∏∏„Å´1.0Ôºâ
data_advanced['diff_AB'] = abs(data_advanced['element_A'] - data_advanced['element_B'])  # Â∑Æ„ÅÆÁµ∂ÂØæÂÄ§
data_advanced['product_AB'] = data_advanced['element_A'] * data_advanced['element_B']  # Á©çÔºàÁõ∏‰∫í‰ΩúÁî®Ôºâ
data_advanced['ratio_AB'] = data_advanced['element_A'] / (data_advanced['element_B'] + 1e-10)  # ÊØîÁéá
data_advanced['A_squared'] = data_advanced['element_A'] ** 2  # ‰∫å‰πóÈ†ÖÔºàÈùûÁ∑öÂΩ¢ÊÄßÔºâ
data_advanced['B_squared'] = data_advanced['element_B'] ** 2

print(&quot;===== ÁâπÂæ¥Èáè„Ç®„É≥„Ç∏„Éã„Ç¢„É™„É≥„Ç∞Âæå„ÅÆ„Éá„Éº„Çø =====&quot;)
print(data_advanced)
</code></pre>
<h3>5.4 ÁâπÂæ¥ÈáèÈáçË¶ÅÂ∫¶ÂàÜÊûê</h3>
<pre><code class="language-python"># Êã°ÂºµÁâπÂæ¥Èáè„Çí‰ΩøÁî®„Åó„Å¶„É¢„Éá„É´Ë®ìÁ∑¥
X_advanced = data_advanced.drop('melting_point', axis=1)
y_advanced = data_advanced['melting_point']

# „É©„É≥„ÉÄ„É†„Éï„Ç©„É¨„Çπ„Éà„ÅßË®ìÁ∑¥
model_advanced = RandomForestRegressor(n_estimators=100, random_state=42)
model_advanced.fit(X_advanced, y_advanced)

# ÁâπÂæ¥ÈáèÈáçË¶ÅÂ∫¶„ÇíÂèñÂæó
importances = pd.DataFrame({
    'ÁâπÂæ¥Èáè': X_advanced.columns,
    'ÈáçË¶ÅÂ∫¶': model_advanced.feature_importances_
}).sort_values('ÈáçË¶ÅÂ∫¶', ascending=False)

print(&quot;===== ÁâπÂæ¥ÈáèÈáçË¶ÅÂ∫¶ =====&quot;)
print(importances)

# ÂèØË¶ñÂåñ
plt.figure(figsize=(10, 6))
plt.barh(importances['ÁâπÂæ¥Èáè'], importances['ÈáçË¶ÅÂ∫¶'])
plt.xlabel('ÈáçË¶ÅÂ∫¶', fontsize=12)
plt.title('ÁâπÂæ¥ÈáèÈáçË¶ÅÂ∫¶Ôºà„É©„É≥„ÉÄ„É†„Éï„Ç©„É¨„Çπ„ÉàÔºâ', fontsize=14)
plt.grid(True, alpha=0.3, axis='x')
plt.tight_layout()
plt.show()
</code></pre>
<h3>5.5 ÁâπÂæ¥ÈáèÈÅ∏Êäû</h3>
<p><strong>ÁõÆÁöÑÔºö</strong>
‰∫àÊ∏¨„Å´ÂØÑ‰∏é„Åó„Å™„ÅÑÁâπÂæ¥Èáè„ÇíÂâäÈô§ÔºàÈÅéÂ≠¶ÁøíÈò≤Ê≠¢„ÄÅË®àÁÆóÊôÇÈñìÁü≠Á∏ÆÔºâ„ÄÇ</p>
<pre><code class="language-python">from sklearn.feature_selection import SelectKBest, f_regression

# SelectKBest: ‰∏ä‰ΩçKÂÄã„ÅÆÁâπÂæ¥Èáè„ÇíÈÅ∏Êäû
selector = SelectKBest(score_func=f_regression, k=3)  # ‰∏ä‰Ωç3ÂÄã
X_selected = selector.fit_transform(X_advanced, y_advanced)

# ÈÅ∏„Å∞„Çå„ÅüÁâπÂæ¥Èáè
selected_features = X_advanced.columns[selector.get_support()]
print(f&quot;ÈÅ∏„Å∞„Çå„ÅüÁâπÂæ¥Èáè: {list(selected_features)}&quot;)

# ÈÅ∏ÊäûÂæå„ÅÆ„É¢„Éá„É´Ë®ìÁ∑¥
model_selected = RandomForestRegressor(n_estimators=100, random_state=42)
model_selected.fit(X_selected, y_advanced)

print(f&quot;ÁâπÂæ¥ÈáèÈÅ∏ÊäûÂâç: {X_advanced.shape[1]}ÂÄã&quot;)
print(f&quot;ÁâπÂæ¥ÈáèÈÅ∏ÊäûÂæå: {X_selected.shape[1]}ÂÄã&quot;)
</code></pre>
<hr />
<h2>6. „Éà„É©„Éñ„É´„Ç∑„É•„Éº„ÉÜ„Ç£„É≥„Ç∞„Ç¨„Ç§„Éâ</h2>
<p>ÂÆüË∑µ„ÅßÈÅ≠ÈÅá„Åó„ÇÑ„Åô„ÅÑ„Ç®„É©„Éº„Å®Ëß£Ê±∫Á≠ñ„ÄÇ</p>
<h3>6.1 „Çà„Åè„ÅÇ„Çã„Ç®„É©„Éº‰∏ÄË¶ß</h3>
<table>
<thead>
<tr>
<th>„Ç®„É©„Éº„É°„ÉÉ„Çª„Éº„Ç∏</th>
<th>ÂéüÂõ†</th>
<th>Ëß£Ê±∫ÊñπÊ≥ï</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>ModuleNotFoundError: No module named 'sklearn'</code></td>
<td>scikit-learnÊú™„Ç§„É≥„Çπ„Éà„Éº„É´</td>
<td><code>pip install scikit-learn</code></td>
</tr>
<tr>
<td><code>MemoryError</code></td>
<td>„É°„É¢„É™‰∏çË∂≥</td>
<td>„Éá„Éº„Çø„Çµ„Ç§„Ç∫ÂâäÊ∏õ„ÄÅ„Éê„ÉÉ„ÉÅÂá¶ÁêÜ„ÄÅGoogle ColabÂà©Áî®</td>
</tr>
<tr>
<td><code>ConvergenceWarning: lbfgs failed to converge</code></td>
<td>MLP„ÅÆÂ≠¶Áøí„ÅåÂèéÊùü„Åõ„Åö</td>
<td><code>max_iter</code>„ÇíÂ¢ó„ÇÑ„ÅôÔºà‰æãÔºö1000Ôºâ„ÄÅÂ≠¶ÁøíÁéáË™øÊï¥</td>
</tr>
<tr>
<td><code>ValueError: Input contains NaN</code></td>
<td>„Éá„Éº„Çø„Å´Ê¨†ÊêçÂÄ§</td>
<td><code>df.dropna()</code>„ÅßÂâäÈô§ or <code>df.fillna()</code>„ÅßË£úÂÆå</td>
</tr>
<tr>
<td><code>ValueError: could not convert string to float</code></td>
<td>ÊñáÂ≠óÂàó„Éá„Éº„Çø„ÅåÂê´„Åæ„Çå„Çã</td>
<td><code>pd.get_dummies()</code>„Åß„ÉÄ„Éü„ÉºÂ§âÊï∞Âåñ</td>
</tr>
<tr>
<td><code>R¬≤ is negative</code></td>
<td>„É¢„Éá„É´„Åå„É©„É≥„ÉÄ„É†‰∫àÊ∏¨„Çà„ÇäÊÇ™„ÅÑ</td>
<td>ÁâπÂæ¥Èáè„ÇíË¶ãÁõ¥„Åô„ÄÅ„É¢„Éá„É´Â§âÊõ¥</td>
</tr>
<tr>
<td><code>ZeroDivisionError</code></td>
<td>0Èô§ÁÆó</td>
<td>ÂàÜÊØç„Å´Â∞è„Åï„ÅÑÂÄ§„ÇíËøΩÂä†Ôºà‰æãÔºö<code>x / (y + 1e-10)</code>Ôºâ</td>
</tr>
</tbody>
</table>
<h3>6.2 „Éá„Éê„ÉÉ„Ç∞„ÉÅ„Çß„ÉÉ„ÇØ„É™„Çπ„Éà</h3>
<p><strong>„Çπ„ÉÜ„ÉÉ„Éó1: „Éá„Éº„Çø„ÅÆÁ¢∫Ë™ç</strong></p>
<pre><code class="language-python"># „Éá„Éº„Çø„ÅÆÂü∫Êú¨Áµ±Ë®à
print(df.describe())

# Ê¨†ÊêçÂÄ§„ÅÆÁ¢∫Ë™ç
print(df.isnull().sum())

# „Éá„Éº„ÇøÂûã„ÅÆÁ¢∫Ë™ç
print(df.dtypes)

# ÁÑ°ÈôêÂ§ß„ÉªNaN„ÅÆÁ¢∫Ë™ç
print(df.isin([np.inf, -np.inf]).sum())
</code></pre>
<p><strong>„Çπ„ÉÜ„ÉÉ„Éó2: „Éá„Éº„Çø„ÅÆÂèØË¶ñÂåñ</strong></p>
<pre><code class="language-python"># ÂàÜÂ∏É„ÇíÁ¢∫Ë™ç
df.hist(figsize=(12, 8), bins=30)
plt.tight_layout()
plt.show()

# Áõ∏Èñ¢Ë°åÂàó
import seaborn as sns
plt.figure(figsize=(10, 8))
sns.heatmap(df.corr(), annot=True, cmap='coolwarm')
plt.title('Áõ∏Èñ¢Ë°åÂàó')
plt.show()
</code></pre>
<p><strong>„Çπ„ÉÜ„ÉÉ„Éó3: Â∞èË¶èÊ®°„Éá„Éº„Çø„Åß„ÉÜ„Çπ„Éà</strong></p>
<pre><code class="language-python"># ÊúÄÂàù„ÅÆ10‰ª∂„Å†„Åë„Åß„ÉÜ„Çπ„Éà
X_small = X[:10]
y_small = y[:10]

model_test = RandomForestRegressor(n_estimators=10)
model_test.fit(X_small, y_small)
print(&quot;Â∞èË¶èÊ®°„Éá„Éº„Çø„Åß„ÅÆË®ìÁ∑¥ÊàêÂäü&quot;)
</code></pre>
<p><strong>„Çπ„ÉÜ„ÉÉ„Éó4: „É¢„Éá„É´„ÅÆÁ∞°Áï•Âåñ</strong></p>
<pre><code class="language-python"># Ë§áÈõë„Å™„É¢„Éá„É´„ÅßÂ§±Êïó„Åó„Åü„Çâ„ÄÅ„Åæ„ÅöÁ∑öÂΩ¢ÂõûÂ∏∞„ÅßË©¶„Åô
model_simple = LinearRegression()
model_simple.fit(X_train, y_train)
print(f&quot;Á∑öÂΩ¢ÂõûÂ∏∞„ÅÆR¬≤: {model_simple.score(X_test, y_test):.4f}&quot;)
</code></pre>
<p><strong>„Çπ„ÉÜ„ÉÉ„Éó5: „Ç®„É©„Éº„É°„ÉÉ„Çª„Éº„Ç∏„ÇíË™≠„ÇÄ</strong></p>
<pre><code class="language-python">try:
    model.fit(X_train, y_train)
except Exception as e:
    print(f&quot;„Ç®„É©„ÉºË©≥Á¥∞: {type(e).__name__}&quot;)
    print(f&quot;„É°„ÉÉ„Çª„Éº„Ç∏: {str(e)}&quot;)
    import traceback
    traceback.print_exc()
</code></pre>
<h3>6.3 ÊÄßËÉΩ„Åå‰Ωé„ÅÑÂ†¥Âêà„ÅÆÂØæÂá¶Ê≥ï</h3>
<table>
<thead>
<tr>
<th>ÁóáÁä∂</th>
<th>ËÄÉ„Åà„Çâ„Çå„ÇãÂéüÂõ†</th>
<th>ÂØæÂá¶Ê≥ï</th>
</tr>
</thead>
<tbody>
<tr>
<td>R¬≤ &lt; 0.5</td>
<td>ÁâπÂæ¥Èáè„Åå‰∏çÈÅ©Âàá</td>
<td>ÁâπÂæ¥Èáè„Ç®„É≥„Ç∏„Éã„Ç¢„É™„É≥„Ç∞„ÄÅMatminerÂà©Áî®</td>
</tr>
<tr>
<td>Ë®ìÁ∑¥Ë™§Â∑Æ„ÅØÂ∞è„ÄÅ„ÉÜ„Çπ„ÉàË™§Â∑Æ„ÅØÂ§ß</td>
<td>ÈÅéÂ≠¶Áøí</td>
<td>Ê≠£ÂâáÂåñÂº∑Âåñ„ÄÅ„Éá„Éº„ÇøËøΩÂä†„ÄÅ„É¢„Éá„É´Á∞°Áï•Âåñ</td>
</tr>
<tr>
<td>Ë®ìÁ∑¥Ë™§Â∑Æ„ÇÇ„ÉÜ„Çπ„ÉàË™§Â∑Æ„ÇÇÂ§ß</td>
<td>Êú™Â≠¶Áøí</td>
<td>„É¢„Éá„É´Ë§áÈõëÂåñ„ÄÅÁâπÂæ¥ÈáèËøΩÂä†„ÄÅÂ≠¶ÁøíÁéáË™øÊï¥</td>
</tr>
<tr>
<td>‰∫àÊ∏¨ÂÄ§„ÅåÂÖ®„Å¶Âêå„Åò</td>
<td>„É¢„Éá„É´„ÅåÂ≠¶Áøí„Åß„Åç„Å¶„ÅÑ„Å™„ÅÑ</td>
<td>„Éè„Ç§„Éë„Éº„Éë„É©„É°„Éº„ÇøË¶ãÁõ¥„Åó„ÄÅÁâπÂæ¥Èáè„Çπ„Ç±„Éº„É™„É≥„Ç∞</td>
</tr>
<tr>
<td>Ë®ìÁ∑¥„ÅåÈÅÖ„ÅÑ</td>
<td>„Éá„Éº„ÇøÈáèor„É¢„Éá„É´„ÅåÂ§ß„Åç„ÅÑ</td>
<td>„Éá„Éº„Çø„Çµ„É≥„Éó„É™„É≥„Ç∞„ÄÅ„É¢„Éá„É´Á∞°Áï•Âåñ„ÄÅ‰∏¶ÂàóÂåñ</td>
</tr>
</tbody>
</table>
<hr />
<h2>7. „Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÉÅ„É£„É¨„É≥„Ç∏Ôºö„Éê„É≥„Éâ„ÇÆ„É£„ÉÉ„Éó‰∫àÊ∏¨</h2>
<p>Â≠¶„Çì„Å†„Åì„Å®„ÇíÁµ±Âêà„Åó„ÄÅÂÆüË∑µÁöÑ„Å™„Éó„É≠„Ç∏„Çß„ÇØ„Éà„Å´Âèñ„ÇäÁµÑ„Åø„Åæ„Åó„Çá„ÅÜ„ÄÇ</p>
<h3>7.1 „Éó„É≠„Ç∏„Çß„ÇØ„ÉàÊ¶ÇË¶Å</h3>
<p><strong>ÁõÆÊ®ôÔºö</strong>
ÁµÑÊàê„Åã„Çâ„Éê„É≥„Éâ„ÇÆ„É£„ÉÉ„Éó„Çí‰∫àÊ∏¨„Åô„ÇãMI„É¢„Éá„É´„ÇíÊßãÁØâ</p>
<p><strong>ÁõÆÊ®ôÊÄßËÉΩÔºö</strong>
- R¬≤ &gt; 0.7ÔºàË™¨ÊòéÂäõ70%‰ª•‰∏äÔºâ
- MAE &lt; 0.5 eVÔºàË™§Â∑Æ0.5 eV‰ª•‰∏ãÔºâ</p>
<p><strong>„Éá„Éº„Çø„ÇΩ„Éº„ÇπÔºö</strong>
Materials Project APIÔºà„Åæ„Åü„ÅØÊ®°Êì¨„Éá„Éº„ÇøÔºâ</p>
<h3>7.2 „Çπ„ÉÜ„ÉÉ„Éó„Éê„Ç§„Çπ„ÉÜ„ÉÉ„Éó„Ç¨„Ç§„Éâ</h3>
<p><strong>Step 1: „Éá„Éº„ÇøÂèéÈõÜ</strong></p>
<pre><code class="language-python"># Materials Project API„Åã„Çâ„Éá„Éº„ÇøÂèñÂæóÔºàÊ®°Êì¨„Éá„Éº„Çø„Åß‰ª£ÊõøÂèØÔºâ
# ÁõÆÊ®ôÔºö100‰ª∂‰ª•‰∏ä„ÅÆÈÖ∏ÂåñÁâ©„Éá„Éº„Çø

data_project = pd.DataFrame({
    'formula': ['Li2O', 'Na2O', 'MgO', 'Al2O3', 'SiO2'] * 20,
    'Li_ratio': [0.67, 0.0, 0.0, 0.0, 0.0] * 20,
    'O_ratio': [0.33, 0.67, 0.5, 0.6, 0.67] * 20,
    'band_gap': [7.5, 5.2, 7.8, 8.8, 9.0] * 20
})

# „Éé„Ç§„Ç∫ËøΩÂä†Ôºà„Çà„ÇäÁèæÂÆüÁöÑ„Å´Ôºâ
np.random.seed(42)
data_project['band_gap'] += np.random.normal(0, 0.3, len(data_project))

print(f&quot;„Éá„Éº„ÇøÊï∞: {len(data_project)}&quot;)
</code></pre>
<p><strong>Step 2: ÁâπÂæ¥Èáè„Ç®„É≥„Ç∏„Éã„Ç¢„É™„É≥„Ç∞</strong></p>
<pre><code class="language-python"># ÂÖÉÁ¥†ÊØîÁéá„Åã„ÇâËøΩÂä†ÁâπÂæ¥Èáè„Çí‰ΩúÊàê
# ÔºàÂÆüÈöõ„Å´„ÅØMatminer„ÅßÂéüÂ≠êÁâπÊÄß„ÇíËøΩÂä†„Åô„Çã„Åì„Å®„ÇíÊé®Â•®Ôºâ

data_project['sum_elements'] = data_project['Li_ratio'] + data_project['O_ratio']
data_project['product_LiO'] = data_project['Li_ratio'] * data_project['O_ratio']
</code></pre>
<p><strong>Step 3: „Éá„Éº„ÇøÂàÜÂâ≤</strong></p>
<pre><code class="language-python">X_project = data_project[['Li_ratio', 'O_ratio', 'sum_elements', 'product_LiO']]
y_project = data_project['band_gap']

X_train_proj, X_test_proj, y_train_proj, y_test_proj = train_test_split(
    X_project, y_project, test_size=0.2, random_state=42
)
</code></pre>
<p><strong>Step 4: „É¢„Éá„É´ÈÅ∏Êäû„Å®Ë®ìÁ∑¥</strong></p>
<pre><code class="language-python"># „É©„É≥„ÉÄ„É†„Éï„Ç©„É¨„Çπ„Éà„Çí‰ΩøÁî®
model_project = RandomForestRegressor(
    n_estimators=200,
    max_depth=15,
    random_state=42
)
model_project.fit(X_train_proj, y_train_proj)
</code></pre>
<p><strong>Step 5: Ë©ï‰æ°</strong></p>
<pre><code class="language-python">y_pred_proj = model_project.predict(X_test_proj)
mae_proj = mean_absolute_error(y_test_proj, y_pred_proj)
r2_proj = r2_score(y_test_proj, y_pred_proj)

print(f&quot;===== „Éó„É≠„Ç∏„Çß„ÇØ„ÉàÁµêÊûú =====&quot;)
print(f&quot;MAE: {mae_proj:.2f} eV&quot;)
print(f&quot;R¬≤: {r2_proj:.4f}&quot;)

if r2_proj &gt; 0.7 and mae_proj &lt; 0.5:
    print(&quot;üéâ ÁõÆÊ®ôÈÅîÊàêÔºÅ&quot;)
else:
    print(&quot;‚ùå ÁõÆÊ®ôÊú™ÈÅîÊàê„ÄÇÁâπÂæ¥Èáè„ÇíËøΩÂä†„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ&quot;)
</code></pre>
<p><strong>Step 6: ÂèØË¶ñÂåñ</strong></p>
<pre><code class="language-python">plt.figure(figsize=(10, 6))
plt.scatter(y_test_proj, y_pred_proj, alpha=0.6, s=100)
plt.plot([y_test_proj.min(), y_test_proj.max()],
         [y_test_proj.min(), y_test_proj.max()],
         'r--', lw=2, label='ÂÆåÂÖ®„Å™‰∫àÊ∏¨')
plt.xlabel('ÂÆüÊ∏¨„Éê„É≥„Éâ„ÇÆ„É£„ÉÉ„Éó (eV)', fontsize=12)
plt.ylabel('‰∫àÊ∏¨„Éê„É≥„Éâ„ÇÆ„É£„ÉÉ„Éó (eV)', fontsize=12)
plt.title('„Éê„É≥„Éâ„ÇÆ„É£„ÉÉ„Éó‰∫àÊ∏¨„Éó„É≠„Ç∏„Çß„ÇØ„Éà', fontsize=14)
plt.legend()
plt.grid(True, alpha=0.3)
plt.text(0.05, 0.95, f'R¬≤ = {r2_proj:.3f}\nMAE = {mae_proj:.3f} eV',
         transform=plt.gca().transAxes, fontsize=12, verticalalignment='top',
         bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))
plt.tight_layout()
plt.show()
</code></pre>
<h3>7.3 Áô∫Â±ïË™≤È°å</h3>
<p><strong>ÂàùÁ¥öÔºö</strong>
- Âà•„ÅÆÊùêÊñôÁâπÊÄßÔºàËûçÁÇπ„ÄÅÂΩ¢Êàê„Ç®„Éç„É´„ÇÆ„ÉºÔºâ„Åß‰∫àÊ∏¨„É¢„Éá„É´„ÇíÊßãÁØâ</p>
<p><strong>‰∏≠Á¥öÔºö</strong>
- Matminer„Åß130‰ª•‰∏ä„ÅÆÁâπÂæ¥Èáè„ÇíÊäΩÂá∫„Åó„ÄÅÊÄßËÉΩÂêë‰∏ä„ÇíÁõÆÊåá„Åô
- ‰∫§Â∑ÆÊ§úË®º„Åß„É¢„Éá„É´„ÅÆ‰ø°È†ºÊÄß„ÇíË©ï‰æ°</p>
<p><strong>‰∏äÁ¥öÔºö</strong>
- Materials Project API„Åã„ÇâÂÆü„Éá„Éº„Çø„ÇíÂèñÂæó
- „Ç¢„É≥„Çµ„É≥„Éñ„É´Â≠¶ÁøíÔºàË§áÊï∞„É¢„Éá„É´„ÅÆÁµÑ„ÅøÂêà„Çè„ÅõÔºâ
- „Éã„É•„Éº„É©„É´„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØÔºàMLPÔºâ„Åß‰∫àÊ∏¨</p>
<hr />
<h2>8. „Åæ„Å®„ÇÅ</h2>
<h3>„Åì„ÅÆÁ´†„ÅßÂ≠¶„Çì„Å†„Åì„Å®</h3>
<ol>
<li>
<p><strong>Áí∞Â¢ÉÊßãÁØâ</strong>
   - Anaconda„ÄÅvenv„ÄÅGoogle Colab„ÅÆ3„Å§„ÅÆÈÅ∏ÊäûËÇ¢
   - Áä∂Ê≥Å„Å´Âøú„Åò„ÅüÊúÄÈÅ©„Å™Áí∞Â¢É„ÅÆÈÅ∏„Å≥Êñπ</p>
</li>
<li>
<p><strong>6„Å§„ÅÆÊ©üÊ¢∞Â≠¶Áøí„É¢„Éá„É´</strong>
   - Á∑öÂΩ¢ÂõûÂ∏∞ÔºàBaselineÔºâ
   - „É©„É≥„ÉÄ„É†„Éï„Ç©„É¨„Çπ„ÉàÔºà„Éê„É©„É≥„ÇπÂûãÔºâ
   - LightGBMÔºàÈ´òÁ≤æÂ∫¶Ôºâ
   - SVRÔºàÈùûÁ∑öÂΩ¢ÂØæÂøúÔºâ
   - MLPÔºàÊ∑±Â±§Â≠¶ÁøíÔºâ
   - Materials ProjectÂÆü„Éá„Éº„ÇøÁµ±Âêà</p>
</li>
<li>
<p><strong>„É¢„Éá„É´ÈÅ∏Êäû„Ç¨„Ç§„Éâ„É©„Ç§„É≥</strong>
   - „Éá„Éº„ÇøÊï∞„ÄÅË®àÁÆóÊôÇÈñì„ÄÅËß£ÈáàÊÄß„Å´Âøú„Åò„ÅüÊúÄÈÅ©„É¢„Éá„É´
   - ÊÄßËÉΩÊØîËºÉË°®„Å®„Éï„É≠„Éº„ÉÅ„É£„Éº„Éà</p>
</li>
<li>
<p><strong>„Éè„Ç§„Éë„Éº„Éë„É©„É°„Éº„Çø„ÉÅ„É•„Éº„Éã„É≥„Ç∞</strong>
   - Grid Search„Å®Random Search
   - „Éè„Ç§„Éë„Éº„Éë„É©„É°„Éº„Çø„ÅÆÂäπÊûúÂèØË¶ñÂåñ</p>
</li>
<li>
<p><strong>ÁâπÂæ¥Èáè„Ç®„É≥„Ç∏„Éã„Ç¢„É™„É≥„Ç∞</strong>
   - Matminer„Å´„Çà„ÇãËá™ÂãïÊäΩÂá∫
   - ÊâãÂãïÁâπÂæ¥Èáè‰ΩúÊàêÔºàÁõ∏‰∫í‰ΩúÁî®È†Ö„ÄÅ‰∫å‰πóÈ†ÖÔºâ
   - ÁâπÂæ¥ÈáèÈáçË¶ÅÂ∫¶„Å®ÈÅ∏Êäû</p>
</li>
<li>
<p><strong>„Éà„É©„Éñ„É´„Ç∑„É•„Éº„ÉÜ„Ç£„É≥„Ç∞</strong>
   - „Çà„Åè„ÅÇ„Çã„Ç®„É©„Éº„Å®Ëß£Ê±∫Á≠ñ
   - „Éá„Éê„ÉÉ„Ç∞„ÅÆ5„Çπ„ÉÜ„ÉÉ„Éó</p>
</li>
<li>
<p><strong>ÂÆüË∑µ„Éó„É≠„Ç∏„Çß„ÇØ„Éà</strong>
   - „Éê„É≥„Éâ„ÇÆ„É£„ÉÉ„Éó‰∫àÊ∏¨„ÅÆÂÆåÂÖ®„Å™ÂÆüË£Ö
   - ÁõÆÊ®ôÈÅîÊàê„ÅÆ„Åü„ÇÅ„ÅÆ„Çπ„ÉÜ„ÉÉ„Éó</p>
</li>
</ol>
<h3>Ê¨°„ÅÆ„Çπ„ÉÜ„ÉÉ„Éó</h3>
<p><strong>„Åì„ÅÆ„ÉÅ„É•„Éº„Éà„É™„Ç¢„É´„ÇíÁµÇ„Åà„Åü„ÅÇ„Å™„Åü„ÅØÔºö</strong>
- ‚úÖ ÊùêÊñôÁâπÊÄß‰∫àÊ∏¨„ÅÆÂÆüË£Ö„Åå„Åß„Åç„Çã
- ‚úÖ 5„Å§‰ª•‰∏ä„ÅÆ„É¢„Éá„É´„Çí‰Ωø„ÅÑÂàÜ„Åë„Çâ„Çå„Çã
- ‚úÖ „Éè„Ç§„Éë„Éº„Éë„É©„É°„Éº„Çø„ÉÅ„É•„Éº„Éã„É≥„Ç∞„Åå„Åß„Åç„Çã
- ‚úÖ „Ç®„É©„Éº„ÇíËá™Âäõ„ÅßËß£Ê±∫„Åß„Åç„Çã</p>
<p><strong>Ê¨°„Å´Â≠¶„Å∂„Åπ„ÅçÂÜÖÂÆπÔºö</strong>
1. <strong>Ê∑±Â±§Â≠¶Áøí„ÅÆÂøúÁî®</strong>
   - Graph Neural NetworksÔºàGNNÔºâ
   - Crystal Graph Convolutional NetworksÔºàCGCNNÔºâ</p>
<ol start="2">
<li>
<p><strong>„Éô„Ç§„Ç∫ÊúÄÈÅ©Âåñ</strong>
   - ÂÆüÈ®ìÂõûÊï∞„ÇíÊúÄÂ∞èÂåñ„Åô„ÇãÊâãÊ≥ï
   - Gaussian ProcessÂõûÂ∏∞</p>
</li>
<li>
<p><strong>Ëª¢ÁßªÂ≠¶Áøí</strong>
   - Â∞ë„Å™„ÅÑ„Éá„Éº„Çø„ÅßÈ´òÁ≤æÂ∫¶„ÇíÂÆüÁèæ
   - ‰∫ãÂâçÂ≠¶ÁøíÊ∏à„Åø„É¢„Éá„É´„ÅÆÊ¥ªÁî®</p>
</li>
</ol>
<hr />
<h2>ÊºîÁøíÂïèÈ°å</h2>
<h3>ÂïèÈ°å1ÔºàÈõ£ÊòìÂ∫¶ÔºöeasyÔºâ</h3>
<p>Êú¨„ÉÅ„É•„Éº„Éà„É™„Ç¢„É´„ÅßÂÆüË£Ö„Åó„Åü6„Å§„ÅÆ„É¢„Éá„É´„ÅÆ‰∏≠„Åß„ÄÅ„Éá„Éº„ÇøÊï∞„ÅåÂ∞ë„Å™„ÅÑÂ†¥ÂêàÔºà&lt; 100‰ª∂Ôºâ„Å´ÊúÄ„ÇÇÈÅ©„Åó„Å¶„ÅÑ„Çã„É¢„Éá„É´„ÇíÈÅ∏„Å≥„ÄÅÁêÜÁî±„ÇíË™¨Êòé„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ</p>
<details>
<summary>„Éí„É≥„Éà</summary>

ÈÅéÂ≠¶Áøí„ÅÆ„É™„Çπ„ÇØ„Å®„É¢„Éá„É´„ÅÆË§áÈõë„Åï„ÇíËÄÉÊÖÆ„Åó„Åæ„Åó„Çá„ÅÜ„ÄÇ

</details>

<details>
<summary>Ëß£Á≠î‰æã</summary>

**Á≠î„ÅàÔºöÁ∑öÂΩ¢ÂõûÂ∏∞**

**ÁêÜÁî±Ôºö**
1. **ÈÅéÂ≠¶Áøí„ÅÆ„É™„Çπ„ÇØ„Åå‰Ωé„ÅÑ**Ôºö„Éë„É©„É°„Éº„ÇøÊï∞„ÅåÂ∞ë„Å™„ÅÑ„Åü„ÇÅ„ÄÅÂ∞ë„Å™„ÅÑ„Éá„Éº„Çø„Åß„ÇÇÂÆâÂÆö
2. **Ëß£ÈáàÊÄß„ÅåÈ´ò„ÅÑ**Ôºö‰øÇÊï∞„ÇíË¶ã„Çå„Å∞ÁâπÂæ¥Èáè„ÅÆÂΩ±Èüø„ÅåÂàÜ„Åã„Çã
3. **Ë®ìÁ∑¥„ÅåÈ´òÈÄü**ÔºöË®àÁÆó„Ç≥„Çπ„Éà„Åå‰Ωé„ÅÑ

**‰ªñ„ÅÆÂÄôË£úÔºöSVR**
- ÈùûÁ∑öÂΩ¢ÊÄß„ÅåÂº∑„ÅÑÂ†¥Âêà„ÅØSVR„ÇÇÊúâÂäπ
- „Åü„Å†„Åó„Éè„Ç§„Éë„Éº„Éë„É©„É°„Éº„ÇøË™øÊï¥„ÅåÂøÖË¶Å

„Éá„Éº„ÇøÊï∞„ÅåÂ∞ë„Å™„ÅÑÂ†¥Âêà„ÄÅË§áÈõë„Å™„É¢„Éá„É´Ôºà„É©„É≥„ÉÄ„É†„Éï„Ç©„É¨„Çπ„Éà„ÄÅMLPÔºâ„ÅØË®ìÁ∑¥„Éá„Éº„Çø„ÇíÊöóË®ò„Åó„Å¶„Åó„Åæ„ÅÑ„ÄÅÊñ∞„Åó„ÅÑ„Éá„Éº„Çø„ÅßÊÄßËÉΩ„ÅåÂ§ßÂπÖ„Å´‰Ωé‰∏ã„Åó„Åæ„ÅôÔºàÈÅéÂ≠¶ÁøíÔºâ„ÄÇ

</details>

<hr />
<h3>ÂïèÈ°å2ÔºàÈõ£ÊòìÂ∫¶ÔºömediumÔºâ</h3>
<p>Grid Search„Å®Random Search„ÇíÊØîËºÉ„Åó„ÄÅ„Å©„ÅÆ„Çà„ÅÜ„Å™Áä∂Ê≥Å„ÅßÂêÑÊâãÊ≥ï„Çí‰Ωø„ÅÜ„Åπ„Åç„ÅãË™¨Êòé„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ</p>
<details>
<summary>„Éí„É≥„Éà</summary>

Êé¢Á¥¢Á©∫Èñì„ÅÆÂ§ß„Åç„Åï„Å®Ë®àÁÆóÊôÇÈñì„ÅÆÂà∂Á¥Ñ„ÇíËÄÉÊÖÆ„Åó„Åæ„Åó„Çá„ÅÜ„ÄÇ

</details>

<details>
<summary>Ëß£Á≠î‰æã</summary>

**Grid Search „Çí‰Ωø„ÅÜ„Åπ„ÅçÁä∂Ê≥ÅÔºö**
1. **Êé¢Á¥¢„Åô„Çã„Éè„Ç§„Éë„Éº„Éë„É©„É°„Éº„Çø„ÅåÂ∞ë„Å™„ÅÑ**Ôºà2-3ÂÄãÔºâ
2. **ÂêÑ„Éë„É©„É°„Éº„Çø„ÅÆÂÄôË£ú„ÅåÂ∞ë„Å™„ÅÑ**ÔºàÂêÑ3-5ÂÄãÁ®ãÂ∫¶Ôºâ
3. **Ë®àÁÆóÊôÇÈñì„Å´‰ΩôË£ï„Åå„ÅÇ„Çã**
4. **ÊúÄËâØËß£„ÇíÁ¢∫ÂÆü„Å´Ë¶ã„Å§„Åë„Åü„ÅÑ**

**‰æãÔºö** n_estimators=[50, 100, 200] √ó max_depth=[5, 10, 15] = 9ÈÄö„Çä

**Random Search „Çí‰Ωø„ÅÜ„Åπ„ÅçÁä∂Ê≥ÅÔºö**
1. **Êé¢Á¥¢„Åô„Çã„Éè„Ç§„Éë„Éº„Éë„É©„É°„Éº„Çø„ÅåÂ§ö„ÅÑ**Ôºà4ÂÄã‰ª•‰∏äÔºâ
2. **ÂêÑ„Éë„É©„É°„Éº„Çø„ÅÆÂÄôË£ú„ÅåÂ§ö„ÅÑ/ÈÄ£Á∂öÂÄ§**
3. **Ë®àÁÆóÊôÇÈñì„ÅåÈôê„Çâ„Çå„Å¶„ÅÑ„Çã**
4. **„ÅÇ„ÇãÁ®ãÂ∫¶ËâØ„ÅÑËß£„ÅåË¶ã„Å§„Åã„Çå„Å∞ÂçÅÂàÜ**

**‰æãÔºö** 5ÂÄã„ÅÆ„Éë„É©„É°„Éº„Çø„ÄÅÂêÑ10ÂÄôË£ú = 100,000ÈÄö„Çä ‚Üí Random Search„Åß100Âõû„Çµ„É≥„Éó„É™„É≥„Ç∞

**‰∏ÄËà¨ÁöÑ„Å™Êà¶Áï•Ôºö**
1. „Åæ„ÅöRandom Search„ÅßÂ§ß„Åæ„Åã„Å™ÁØÑÂõ≤„ÇíÁµû„ÇãÔºà100-200ÂõûÔºâ
2. ÊúâÊúõ„Å™ÁØÑÂõ≤„ÇíGrid Search„ÅßË©≥Á¥∞Êé¢Á¥¢

</details>

<hr />
<h3>ÂïèÈ°å3ÔºàÈõ£ÊòìÂ∫¶ÔºömediumÔºâ</h3>
<p>‰ª•‰∏ã„ÅÆ„Ç®„É©„Éº„ÅåÁô∫Áîü„Åó„Åæ„Åó„Åü„ÄÇÂéüÂõ†„Å®Ëß£Ê±∫ÊñπÊ≥ï„ÇíË™¨Êòé„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ</p>
<pre><code>ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.
</code></pre>
<details>
<summary>„Éí„É≥„Éà</summary>

MLPRegressor „ÅÆË®ìÁ∑¥„ÅßÁô∫Áîü„Åô„Çã„Ç®„É©„Éº„Åß„Åô„ÄÇ

</details>

<details>
<summary>Ëß£Á≠î‰æã</summary>

**ÂéüÂõ†Ôºö**
MLPRegressorÔºà„Éã„É•„Éº„É©„É´„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØÔºâ„ÅÆË®ìÁ∑¥„Åå„ÄÅÊåáÂÆö„Åï„Çå„Åü„Ç§„ÉÜ„É¨„Éº„Ç∑„Éß„É≥Êï∞Ôºàmax_iterÔºâ‰ª•ÂÜÖ„Å´ÂèéÊùü„Åó„Å™„Åã„Å£„Åü„ÄÇ

**ËÄÉ„Åà„Çâ„Çå„ÇãË¶ÅÂõ†Ôºö**
1. max_iter„ÅåÂ∞è„Åï„Åô„Åé„ÇãÔºà„Éá„Éï„Ç©„É´„Éà200Ôºâ
2. Â≠¶ÁøíÁéá„ÅåÂ∞è„Åï„Åô„Åé„ÇãÔºàÂ≠¶Áøí„ÅåÈÅÖ„ÅÑÔºâ
3. „Éá„Éº„Çø„ÅÆ„Çπ„Ç±„Éº„É´„Åå‰∏çÈÅ©ÂàáÔºàÊ®ôÊ∫ñÂåñ„Åó„Å¶„ÅÑ„Å™„ÅÑÔºâ
4. „É¢„Éá„É´„ÅåË§áÈõë„Åô„Åé„ÇãÔºàÂ±§Êï∞„ÅåÂ§ö„ÅÑ„ÄÅ„Éã„É•„Éº„É≠„É≥Êï∞„ÅåÂ§ö„ÅÑÔºâ

**Ëß£Ê±∫ÊñπÊ≥ïÔºö**

**ÊñπÊ≥ï1: max_iter„ÇíÂ¢ó„ÇÑ„Åô**

<pre><code class="language-python">model_mlp = MLPRegressor(max_iter=1000)  # „Éá„Éï„Ç©„É´„Éà200‚Üí1000
</code></pre>


**ÊñπÊ≥ï2: „Éá„Éº„Çø„ÇíÊ®ôÊ∫ñÂåñ**

<pre><code class="language-python">from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)
</code></pre>


**ÊñπÊ≥ï3: Â≠¶ÁøíÁéá„ÇíË™øÊï¥**

<pre><code class="language-python">model_mlp = MLPRegressor(
    learning_rate_init=0.01,  # Â≠¶ÁøíÁéá„Çí‰∏ä„Åí„Çã
    max_iter=500
)
</code></pre>


**ÊñπÊ≥ï4: Early Stopping„ÇíÊúâÂäπÂåñ**

<pre><code class="language-python">model_mlp = MLPRegressor(
    early_stopping=True,  # Ê§úË®ºË™§Â∑Æ„ÅåÊîπÂñÑ„Åó„Å™„Åë„Çå„Å∞ÂÅúÊ≠¢
    validation_fraction=0.2,
    max_iter=1000
)
</code></pre>


**Êé®Â•®„Ç¢„Éó„É≠„Éº„ÉÅÔºö**
„Åæ„ÅöÊñπÊ≥ï2Ôºà„Éá„Éº„ÇøÊ®ôÊ∫ñÂåñÔºâ„ÇíË©¶„Åó„ÄÅ„Åù„Çå„Åß„ÇÇÂèéÊùü„Åó„Å™„Åë„Çå„Å∞ÊñπÊ≥ï1„Å®4„Çí‰ΩµÁî®„ÄÇ

</details>

<hr />
<h3>ÂïèÈ°å4ÔºàÈõ£ÊòìÂ∫¶ÔºöhardÔºâ</h3>
<p>Matminer„Çí‰Ωø„Å£„Å¶„ÄÅÁµÑÊàê <code>"Li2O"</code> „Åã„Çâ5„Å§‰ª•‰∏ä„ÅÆÁâπÂæ¥Èáè„ÇíÊäΩÂá∫„Åô„Çã„Ç≥„Éº„Éâ„ÇíÊõ∏„ÅÑ„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ</p>
<details>
<summary>„Éí„É≥„Éà</summary>

`ElementProperty` featurizer„Å® `from_preset('magpie')` „Çí‰ΩøÁî®„Åó„Åæ„Åô„ÄÇ

</details>

<details>
<summary>Ëß£Á≠î‰æã</summary>


<pre><code class="language-python">from matminer.featurizers.composition import ElementProperty
from pymatgen.core import Composition
import pandas as pd

# ÁµÑÊàê„Ç™„Éñ„Ç∏„Çß„ÇØ„Éà„Çí‰ΩúÊàê
comp = Composition(&quot;Li2O&quot;)

# Magpie„Éó„É™„Çª„ÉÉ„Éà„ÅßÁâπÂæ¥ÈáèÊäΩÂá∫Âô®„ÇíÂàùÊúüÂåñ
featurizer = ElementProperty.from_preset('magpie')

# ÁâπÂæ¥Èáè„ÇíË®àÁÆó
features = featurizer.featurize(comp)

# ÁâπÂæ¥ÈáèÂêç„ÇíÂèñÂæó
feature_names = featurizer.feature_labels()

# DataFrame„Å´Â§âÊèõÔºàË¶ã„ÇÑ„Åô„ÅèÔºâ
df = pd.DataFrame([features], columns=feature_names)

print(f&quot;===== Li2O„ÅÆÁâπÂæ¥ÈáèÔºàÊúÄÂàù„ÅÆ5„Å§Ôºâ =====&quot;)
for i in range(5):
    print(f&quot;{feature_names[i]}: {features[i]:.4f}&quot;)

print(f&quot;\nÂêàË®àÁâπÂæ¥ÈáèÊï∞: {len(features)}&quot;)
</code></pre>


**ÊúüÂæÖ„Åï„Çå„ÇãÂá∫ÂäõÔºö**

<pre><code>===== Li2O„ÅÆÁâπÂæ¥ÈáèÔºàÊúÄÂàù„ÅÆ5„Å§Ôºâ =====
MagpieData minimum Number: 3.0000
MagpieData maximum Number: 8.0000
MagpieData range Number: 5.0000
MagpieData mean Number: 5.3333
MagpieData avg_dev Number: 1.5556

ÂêàË®àÁâπÂæ¥ÈáèÊï∞: 132
</code></pre>


**Ëß£Ë™¨Ôºö**
- `MagpieData minimum Number`: ÊúÄÂ∞èÂéüÂ≠êÁï™Âè∑ÔºàLi: 3Ôºâ
- `MagpieData maximum Number`: ÊúÄÂ§ßÂéüÂ≠êÁï™Âè∑ÔºàO: 8Ôºâ
- `MagpieData range Number`: ÂéüÂ≠êÁï™Âè∑„ÅÆÁØÑÂõ≤Ôºà8-3=5Ôºâ
- `MagpieData mean Number`: Âπ≥ÂùáÂéüÂ≠êÁï™Âè∑Ôºà(3+3+8)/3=5.33Ôºâ
- `MagpieData avg_dev Number`: ÂéüÂ≠êÁï™Âè∑„ÅÆÂπ≥ÂùáÂÅèÂ∑Æ

Matminer„ÅØ132ÂÄã„ÅÆÁâπÂæ¥Èáè„ÇíËá™ÂãïÊäΩÂá∫„Åó„Åæ„ÅôÔºàÈõªÊ∞óÈô∞ÊÄßÂ∫¶„ÄÅÂéüÂ≠êÂçäÂæÑ„ÄÅËûçÁÇπ„Å™„Å©Ôºâ„ÄÇ

</details>

<hr />
<h3>ÂïèÈ°å5ÔºàÈõ£ÊòìÂ∫¶ÔºöhardÔºâ</h3>
<p>„Éê„É≥„Éâ„ÇÆ„É£„ÉÉ„Éó„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÅßR¬≤„Åå0.5„Åó„ÅãÂá∫„Åæ„Åõ„Çì„Åß„Åó„Åü„ÄÇÊÄßËÉΩ„ÇíÂêë‰∏ä„Åï„Åõ„Çã„Åü„ÇÅ„ÅÆ3„Å§„ÅÆÂÖ∑‰ΩìÁöÑ„Å™„Ç¢„Éó„É≠„Éº„ÉÅ„ÇíÊèêÊ°à„Åó„ÄÅ„Åù„Çå„Åû„Çå„ÅÆÂÆüË£ÖÊñπÊ≥ï„ÇíË™¨Êòé„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ</p>
<details>
<summary>„Éí„É≥„Éà</summary>

ÁâπÂæ¥Èáè„ÄÅ„É¢„Éá„É´„ÄÅ„Éè„Ç§„Éë„Éº„Éë„É©„É°„Éº„Çø„ÅÆ3„Å§„ÅÆË¶≥ÁÇπ„Åã„ÇâËÄÉ„Åà„Åæ„Åó„Çá„ÅÜ„ÄÇ

</details>

<details>
<summary>Ëß£Á≠î‰æã</summary>

**„Ç¢„Éó„É≠„Éº„ÉÅ1: ÁâπÂæ¥Èáè„Ç®„É≥„Ç∏„Éã„Ç¢„É™„É≥„Ç∞ÔºàÊúÄ„ÇÇÂäπÊûúÁöÑÔºâ**

**ÂÆüË£ÖÊñπÊ≥ïÔºö**

<pre><code class="language-python">from matminer.featurizers.composition import ElementProperty
from pymatgen.core import Composition

# ÁµÑÊàê„Åã„ÇâÂéüÂ≠êÁâπÊÄß„ÇíÊäΩÂá∫
def extract_features(formula):
    comp = Composition(formula)
    featurizer = ElementProperty.from_preset('magpie')
    features = featurizer.featurize(comp)
    return features

# Êó¢Â≠ò„Éá„Éº„Çø„Å´ÁâπÂæ¥Èáè„ÇíËøΩÂä†
data_project['features'] = data_project['formula'].apply(extract_features)
# DataFrame„Å´Â±ïÈñãÔºà132Ê¨°ÂÖÉ„ÅÆÁâπÂæ¥ÈáèÔºâ
features_df = pd.DataFrame(data_project['features'].tolist())
X_enhanced = features_df  # ÂÖÉ„ÅÆ2Ê¨°ÂÖÉ ‚Üí 132Ê¨°ÂÖÉ„Å´Êã°Âºµ
</code></pre>


**ÊúüÂæÖ„Åï„Çå„ÇãÊîπÂñÑÔºö**
R¬≤ 0.5 ‚Üí 0.75-0.85ÔºàÁâπÂæ¥Èáè„ÅåÂ§ßÂπÖ„Å´Â¢ó„Åà„Çã„Åü„ÇÅÔºâ

---

**„Ç¢„Éó„É≠„Éº„ÉÅ2: „Ç¢„É≥„Çµ„É≥„Éñ„É´Â≠¶ÁøíÔºàË§áÊï∞„É¢„Éá„É´„ÅÆÁµÑ„ÅøÂêà„Çè„ÅõÔºâ**

**ÂÆüË£ÖÊñπÊ≥ïÔºö**

<pre><code class="language-python">from sklearn.ensemble import VotingRegressor

# 3„Å§„ÅÆ„É¢„Éá„É´„ÇíÁµÑ„ÅøÂêà„Çè„Åõ
model_rf = RandomForestRegressor(n_estimators=200, random_state=42)
model_lgb = lgb.LGBMRegressor(n_estimators=200, random_state=42)
model_svr = SVR(kernel='rbf', C=100)

# „Ç¢„É≥„Çµ„É≥„Éñ„É´„É¢„Éá„É´ÔºàÂπ≥Âùá‰∫àÊ∏¨Ôºâ
ensemble = VotingRegressor([
    ('rf', model_rf),
    ('lgb', model_lgb),
    ('svr', model_svr)
])

ensemble.fit(X_train, y_train)
y_pred_ensemble = ensemble.predict(X_test)
</code></pre>


**ÊúüÂæÖ„Åï„Çå„ÇãÊîπÂñÑÔºö**
R¬≤ 0.5 ‚Üí 0.6-0.7ÔºàÂçò‰∏Ä„É¢„Éá„É´„Çà„ÇäÂÆâÂÆöÔºâ

---

**„Ç¢„Éó„É≠„Éº„ÉÅ3: „Éè„Ç§„Éë„Éº„Éë„É©„É°„Éº„Çø„ÉÅ„É•„Éº„Éã„É≥„Ç∞**

**ÂÆüË£ÖÊñπÊ≥ïÔºö**

<pre><code class="language-python">from sklearn.model_selection import RandomizedSearchCV
from scipy.stats import randint

param_dist = {
    'n_estimators': randint(100, 500),
    'max_depth': randint(10, 50),
    'min_samples_split': randint(2, 20),
    'min_samples_leaf': randint(1, 10)
}

random_search = RandomizedSearchCV(
    RandomForestRegressor(random_state=42),
    param_distributions=param_dist,
    n_iter=100,  # 100ÈÄö„ÇäË©¶„Åô
    cv=5,
    scoring='neg_mean_absolute_error',
    n_jobs=-1,
    random_state=42
)

random_search.fit(X_train, y_train)
best_model = random_search.best_estimator_
</code></pre>


**ÊúüÂæÖ„Åï„Çå„ÇãÊîπÂñÑÔºö**
R¬≤ 0.5 ‚Üí 0.55-0.65Ôºà„Éá„Éï„Ç©„É´„Éà„Çà„ÇäÊúÄÈÅ©ÂåñÔºâ

---

**ÊúÄÈÅ©„Å™Êà¶Áï•Ôºö**
1. „Åæ„Åö**„Ç¢„Éó„É≠„Éº„ÉÅ1**ÔºàÁâπÂæ¥Èáè„Ç®„É≥„Ç∏„Éã„Ç¢„É™„É≥„Ç∞Ôºâ„ÇíÂÆüÊñΩ ‚Üí ÊúÄÂ§ß„ÅÆÂäπÊûú
2. Ê¨°„Å´**„Ç¢„Éó„É≠„Éº„ÉÅ3**Ôºà„Éè„Ç§„Éë„Éº„Éë„É©„É°„Éº„Çø„ÉÅ„É•„Éº„Éã„É≥„Ç∞Ôºâ„ÅßÂæÆË™øÊï¥
3. ÊúÄÂæå„Å´**„Ç¢„Éó„É≠„Éº„ÉÅ2**Ôºà„Ç¢„É≥„Çµ„É≥„Éñ„É´Ôºâ„ÅßÊúÄÁµÇÁöÑ„Å™ÊÄßËÉΩÂêë‰∏ä

„Åì„ÅÆÈ†ÜÂ∫è„Åß„ÄÅR¬≤ 0.5 ‚Üí 0.8‰ª•‰∏ä„ÇíÁõÆÊåá„Åõ„Åæ„Åô„ÄÇ

</details>

<hr />
<h2>9. Á´†Êú´„ÉÅ„Çß„ÉÉ„ÇØ„É™„Çπ„ÉàÔºöÂÆüË£Ö„Çπ„Ç≠„É´„ÅÆÂìÅË≥™‰øùË®º</h2>
<p>ÂÆüË∑µÁöÑ„Å™ÊùêÊñôÁâπÊÄß‰∫àÊ∏¨„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÇíÂÆåÈÅÇ„Åô„Çã„Åü„ÇÅ„Å´ÂøÖË¶Å„Å™„Çπ„Ç≠„É´„ÇíÁ∂≤ÁæÖÁöÑ„Å´„ÉÅ„Çß„ÉÉ„ÇØ„Åó„Åæ„Åô„ÄÇ</p>
<h3>9.1 Áí∞Â¢ÉÊßãÁØâ„Çπ„Ç≠„É´ÔºàEnvironment SetupÔºâ</h3>
<h4>Âü∫Á§é„É¨„Éô„É´</h4>
<ul>
<li>[ ] Python 3.9‰ª•‰∏ä„Åå„Ç§„É≥„Çπ„Éà„Éº„É´„Åï„Çå„Å¶„ÅÑ„Çã</li>
<li>[ ] 3„Å§„ÅÆÁí∞Â¢ÉÊßãÁØâ„Ç™„Éó„Ç∑„Éß„É≥ÔºàAnaconda/venv/ColabÔºâ„ÅÆÈÅï„ÅÑ„ÇíË™¨Êòé„Åß„Åç„Çã</li>
<li>[ ] Ëá™ÂàÜ„ÅÆÁä∂Ê≥Å„Å´ÊúÄÈÅ©„Å™Áí∞Â¢É„ÇíÈÅ∏Êäû„Åß„Åç„Çã</li>
<li>[ ] ‰ªÆÊÉ≥Áí∞Â¢É„Çí‰ΩúÊàê„ÉªÊúâÂäπÂåñ„ÉªÁÑ°ÂäπÂåñ„Åß„Åç„Çã</li>
<li>[ ] pip/conda„Åß„É©„Ç§„Éñ„É©„É™„Çí„Ç§„É≥„Çπ„Éà„Éº„É´„Åß„Åç„Çã</li>
<li>[ ] Áí∞Â¢ÉÊ§úË®º„Ç≥„Éº„Éâ„ÇíÂÆüË°å„Åó„ÄÅ„Ç®„É©„Éº„Å™„ÅèÂãï‰ΩúÁ¢∫Ë™ç„Åß„Åç„Çã</li>
</ul>
<h4>ÂøúÁî®„É¨„Éô„É´</h4>
<ul>
<li>[ ] requirements.txt„Çí‰ΩúÊàê„Éª‰ΩøÁî®„Åß„Åç„ÇãÔºà<code>pip freeze &gt; requirements.txt</code>Ôºâ</li>
<li>[ ] Áí∞Â¢ÉÂ§âÊï∞Ôºà.envÔºâ„ÇíË®≠ÂÆö„Åó„ÄÅAPI„Ç≠„Éº„ÇíÂÆâÂÖ®„Å´ÁÆ°ÁêÜ„Åß„Åç„Çã</li>
<li>[ ] Google Colab„ÅßGoogle Drive„Çí„Éû„Ç¶„É≥„Éà„Åó„Å¶„Éá„Éº„Çø„ÇíË™≠„ÅøËæº„ÇÅ„Çã</li>
<li>[ ] Ë§áÊï∞„ÅÆ‰ªÆÊÉ≥Áí∞Â¢É„ÇíÁî®ÈÄîÂà•„Å´‰Ωø„ÅÑÂàÜ„Åë„Çâ„Çå„Çã</li>
<li>[ ] „Ç§„É≥„Çπ„Éà„Éº„É´„Ç®„É©„Éº„ÇíËá™Âäõ„Åß„Éà„É©„Éñ„É´„Ç∑„É•„Éº„ÉÜ„Ç£„É≥„Ç∞„Åß„Åç„Çã</li>
</ul>
<hr />
<h3>9.2 „É¢„Éá„É´ÂÆüË£Ö„Çπ„Ç≠„É´ÔºàModel ImplementationÔºâ</h3>
<h4>Âü∫Á§é„É¨„Éô„É´Ôºà6„Å§„ÅÆ„É¢„Éá„É´ÂÆüË£ÖÔºâ</h4>
<ul>
<li>[ ] Á∑öÂΩ¢ÂõûÂ∏∞„ÇíÂÆüË£Ö„Åó„ÄÅ‰øÇÊï∞„ÅÆÊÑèÂë≥„ÇíË™¨Êòé„Åß„Åç„Çã</li>
<li>[ ] „É©„É≥„ÉÄ„É†„Éï„Ç©„É¨„Çπ„Éà„ÇíÂÆüË£Ö„Åó„ÄÅ<code>n_estimators</code>„ÅÆÂΩπÂâ≤„ÇíË™¨Êòé„Åß„Åç„Çã</li>
<li>[ ] LightGBM„Çí„Ç§„É≥„Çπ„Éà„Éº„É´„ÉªÂÆüË£Ö„Åß„Åç„Çã</li>
<li>[ ] SVR„ÅßÊ®ôÊ∫ñÂåñÔºàStandardScalerÔºâ„ÅÆÂøÖË¶ÅÊÄß„ÇíÁêÜËß£„Åó„Å¶„ÅÑ„Çã</li>
<li>[ ] MLPRegressorÔºà„Éã„É•„Éº„É©„É´„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØÔºâ„ÇíÂÆüË£Ö„Åß„Åç„Çã</li>
<li>[ ] Materials Project API„Åã„Çâ„Éá„Éº„Çø„ÇíÂèñÂæó„Åß„Åç„ÇãÔºà„Åæ„Åü„ÅØÊ®°Êì¨„Éá„Éº„Çø„Çí‰ΩúÊàê„Åß„Åç„ÇãÔºâ</li>
</ul>
<h4>ÂøúÁî®„É¨„Éô„É´Ôºà„É¢„Éá„É´ÈÅ∏Êäû„Å®Ë©ï‰æ°Ôºâ</h4>
<ul>
<li>[ ] „Éá„Éº„ÇøÊï∞„ÉªË®àÁÆóÊôÇÈñì„ÉªËß£ÈáàÊÄß„ÅÆÂà∂Á¥Ñ„Åã„ÇâÊúÄÈÅ©„É¢„Éá„É´„ÇíÈÅ∏Êäû„Åß„Åç„Çã</li>
<li>[ ] MAE„ÄÅR¬≤„ÄÅË®ìÁ∑¥ÊôÇÈñì„ÅÆ3Ëª∏„Åß„É¢„Éá„É´„ÇíÊØîËºÉ„Åß„Åç„Çã</li>
<li>[ ] Á∑öÂΩ¢ÂõûÂ∏∞„ÅÆR¬≤ &lt; 0.5„ÅÆÂ†¥Âêà„ÄÅÈùûÁ∑öÂΩ¢„É¢„Éá„É´„ÅÆÂøÖË¶ÅÊÄß„ÇíÂà§Êñ≠„Åß„Åç„Çã</li>
<li>[ ] OOB„Çπ„Ç≥„Ç¢Ôºà„É©„É≥„ÉÄ„É†„Éï„Ç©„É¨„Çπ„ÉàÔºâ„ÅßÈÅéÂ≠¶Áøí„ÇíÊ§úÂá∫„Åß„Åç„Çã</li>
<li>[ ] Â≠¶ÁøíÊõ≤Á∑ö„ÇíÂèØË¶ñÂåñ„Åó„ÄÅË®ìÁ∑¥„ÅÆÂèéÊùüÁä∂Ê≥Å„ÇíÁ¢∫Ë™ç„Åß„Åç„Çã</li>
</ul>
<h4>‰∏äÁ¥ö„É¨„Éô„É´Ôºà„Ç¢„É≥„Çµ„É≥„Éñ„É´„Å®ÂøúÁî®Ôºâ</h4>
<ul>
<li>[ ] VotingRegressor„ÅßË§áÊï∞„É¢„Éá„É´„ÇíÁµÑ„ÅøÂêà„Çè„Åõ„Çâ„Çå„Çã</li>
<li>[ ] Stacking„Ç¢„É≥„Çµ„É≥„Éñ„É´„ÇíÂÆüË£Ö„Åß„Åç„Çã</li>
<li>[ ] ‰∫§Â∑ÆÊ§úË®ºÔºà5-fold CVÔºâ„Åß„É¢„Éá„É´„ÅÆÊ±éÂåñÊÄßËÉΩ„ÇíË©ï‰æ°„Åß„Åç„Çã</li>
<li>[ ] ‰∫àÊ∏¨Âå∫ÈñìÔºàconfidence intervalÔºâ„ÇíË®àÁÆó„Åß„Åç„Çã</li>
</ul>
<hr />
<h3>9.3 „Éè„Ç§„Éë„Éº„Éë„É©„É°„Éº„Çø„ÉÅ„É•„Éº„Éã„É≥„Ç∞„Çπ„Ç≠„É´ÔºàHyperparameter TuningÔºâ</h3>
<h4>Âü∫Á§é„É¨„Éô„É´</h4>
<ul>
<li>[ ] „Éè„Ç§„Éë„Éº„Éë„É©„É°„Éº„Çø„Å®„Éë„É©„É°„Éº„Çø„ÅÆÈÅï„ÅÑ„ÇíË™¨Êòé„Åß„Åç„Çã</li>
<li>[ ] GridSearchCV„ÇíÂÆüË£Ö„Åó„ÄÅÊúÄËâØ„ÅÆ„Éè„Ç§„Éë„Éº„Éë„É©„É°„Éº„Çø„ÇíË¶ã„Å§„Åë„Çâ„Çå„Çã</li>
<li>[ ] RandomizedSearchCV„ÇíÂÆüË£Ö„Åó„ÄÅGrid Search„Å®„ÅÆÈÅï„ÅÑ„ÇíË™¨Êòé„Åß„Åç„Çã</li>
<li>[ ] <code>cv=5</code>Ôºà5-fold‰∫§Â∑ÆÊ§úË®ºÔºâ„ÅÆÊÑèÂë≥„ÇíÁêÜËß£„Åó„Å¶„ÅÑ„Çã</li>
<li>[ ] <code>best_params_</code>„ÅßÊúÄËâØ„ÅÆÁµÑ„ÅøÂêà„Çè„Åõ„ÇíÂèñÂæó„Åß„Åç„Çã</li>
<li>[ ] <code>best_score_</code>„Åß‰∫§Â∑ÆÊ§úË®º„Çπ„Ç≥„Ç¢„ÇíÁ¢∫Ë™ç„Åß„Åç„Çã</li>
</ul>
<h4>ÂøúÁî®„É¨„Éô„É´</h4>
<ul>
<li>[ ] „É©„É≥„ÉÄ„É†„Éï„Ç©„É¨„Çπ„Éà„ÅÆ‰∏ªË¶Å„Éè„Ç§„Éë„Éº„Éë„É©„É°„Éº„Çø4„Å§‰ª•‰∏ä„ÇíË™¨Êòé„Åß„Åç„Çã</li>
<li><code>n_estimators</code>: Ê±∫ÂÆöÊú®„ÅÆÊï∞</li>
<li><code>max_depth</code>: Êú®„ÅÆÊ∑±„Åï</li>
<li><code>min_samples_split</code>: ÂàÜÂ≤ê„ÅÆÊúÄÂ∞è„Çµ„É≥„Éó„É´Êï∞</li>
<li><code>min_samples_leaf</code>: Ëëâ„Éé„Éº„Éâ„ÅÆÊúÄÂ∞è„Çµ„É≥„Éó„É´Êï∞</li>
<li>[ ] LightGBM„ÅÆ<code>learning_rate</code>„Å®<code>n_estimators</code>„ÅÆ„Éà„É¨„Éº„Éâ„Ç™„Éï„ÇíÁêÜËß£„Åó„Å¶„ÅÑ„Çã</li>
<li>[ ] Early Stopping„ÇíÂÆüË£Ö„Åó„ÄÅÈÅéÂ≠¶Áøí„ÇíÈò≤Ê≠¢„Åß„Åç„Çã</li>
<li>[ ] „Éè„Ç§„Éë„Éº„Éë„É©„É°„Éº„Çø„ÅÆÂΩ±Èüø„ÇíÂèØË¶ñÂåñ„Åß„Åç„Çã</li>
</ul>
<h4>‰∏äÁ¥ö„É¨„Éô„É´</h4>
<ul>
<li>[ ] Bayesian OptimizationÔºàOptuna„Å™„Å©Ôºâ„ÇíÂÆüË£Ö„Åß„Åç„Çã</li>
<li>[ ] „Éè„Ç§„Éë„Éº„Éë„É©„É°„Éº„Çø„ÅÆÊé¢Á¥¢ÁØÑÂõ≤„ÇíÁêÜË´ñÁöÑ„Å´Ê±∫ÂÆö„Åß„Åç„Çã</li>
<li>[ ] Nested Cross-ValidationÔºà‰∫åÈáç‰∫§Â∑ÆÊ§úË®ºÔºâ„ÇíÂÆüË£Ö„Åß„Åç„Çã</li>
</ul>
<hr />
<h3>9.4 ÁâπÂæ¥Èáè„Ç®„É≥„Ç∏„Éã„Ç¢„É™„É≥„Ç∞„Çπ„Ç≠„É´ÔºàFeature EngineeringÔºâ</h3>
<h4>Âü∫Á§é„É¨„Éô„É´</h4>
<ul>
<li>[ ] ÂÖÉÁ¥†ÊØîÁéá„Åã„ÇâÊñ∞„Åó„ÅÑÁâπÂæ¥ÈáèÔºàÂíå„ÄÅÂ∑Æ„ÄÅÁ©ç„ÄÅÊØîÔºâ„Çí‰ΩúÊàê„Åß„Åç„Çã</li>
<li>[ ] ÁâπÂæ¥ÈáèÈáçË¶ÅÂ∫¶Ôºàfeature_importances_Ôºâ„ÇíÂèñÂæó„ÉªÂèØË¶ñÂåñ„Åß„Åç„Çã</li>
<li>[ ] ÈáçË¶ÅÂ∫¶‰∏ã‰Ωç„ÅÆÁâπÂæ¥Èáè„ÇíÂâäÈô§„Åß„Åç„Çã</li>
<li>[ ] SelectKBest„Åß‰∏ä‰ΩçKÂÄã„ÅÆÁâπÂæ¥Èáè„ÇíÈÅ∏Êäû„Åß„Åç„Çã</li>
</ul>
<h4>ÂøúÁî®„É¨„Éô„É´ÔºàMatminerÊ¥ªÁî®Ôºâ</h4>
<ul>
<li>[ ] Matminer„Çí„Ç§„É≥„Çπ„Éà„Éº„É´„Éª„Ç§„É≥„Éù„Éº„Éà„Åß„Åç„Çã</li>
<li>[ ] ElementProperty featurizer„ÅßÁµÑÊàê„Åã„ÇâÁâπÂæ¥Èáè„ÇíÊäΩÂá∫„Åß„Åç„Çã</li>
<li>[ ] <code>from_preset('magpie')</code>„Åß132Ê¨°ÂÖÉ„ÅÆÁâπÂæ¥Èáè„ÇíËá™ÂãïÁîüÊàê„Åß„Åç„Çã</li>
<li>[ ] ÊäΩÂá∫„Åó„ÅüÁâπÂæ¥Èáè„ÇíDataFrame„Å´Áµ±Âêà„Åó„ÄÅÊ©üÊ¢∞Â≠¶Áøí„Å´‰ΩøÁî®„Åß„Åç„Çã</li>
<li>[ ] Matminer„ÅÆÁâπÂæ¥ÈáèÔºàÈõªÊ∞óÈô∞ÊÄßÂ∫¶„ÄÅÂéüÂ≠êÂçäÂæÑ„ÄÅËûçÁÇπ„Å™„Å©Ôºâ„ÅÆÊÑèÂë≥„ÇíÁêÜËß£„Åó„Å¶„ÅÑ„Çã</li>
</ul>
<h4>‰∏äÁ¥ö„É¨„Éô„É´</h4>
<ul>
<li>[ ] Ë§áÊï∞„ÅÆfeaturizerÔºàElementProperty„ÄÅStoichiometry„ÄÅOxidationStatesÔºâ„ÇíÁµÑ„ÅøÂêà„Çè„Åõ„Çâ„Çå„Çã</li>
<li>[ ] „Éâ„É°„Ç§„É≥Áü•Ë≠ò„ÇíÊ¥ªÁî®„Åó„Å¶ÊùêÊñôÁâπÊúâ„ÅÆÁâπÂæ¥Èáè„ÇíË®≠Ë®à„Åß„Åç„Çã</li>
<li>[ ] Â§öÈáçÂÖ±Á∑öÊÄßÔºàVIF: Variance Inflation FactorÔºâ„ÇíÊ§úÂá∫„ÉªÂØæÂá¶„Åß„Åç„Çã</li>
<li>[ ] Ê¨°ÂÖÉÂâäÊ∏õÔºàPCA„ÄÅt-SNEÔºâ„ÇíÂÆüË£Ö„Åó„ÄÅÁâπÂæ¥Èáè„ÇíÂèØË¶ñÂåñ„Åß„Åç„Çã</li>
</ul>
<hr />
<h3>9.5 „Éá„Éº„ÇøÂá¶ÁêÜ„Çπ„Ç≠„É´ÔºàData ProcessingÔºâ</h3>
<h4>Âü∫Á§é„É¨„Éô„É´</h4>
<ul>
<li>[ ] train_test_split„Åß„Éá„Éº„Çø„ÇíÂàÜÂâ≤„Åß„Åç„ÇãÔºà80% vs 20%Ôºâ</li>
<li>[ ] <code>random_state=42</code>„ÅßÂÜçÁèæÊÄß„ÇíÁ¢∫‰øù„Åó„Å¶„ÅÑ„Çã</li>
<li>[ ] „Éá„Éº„Çø„ÅÆÂü∫Êú¨Áµ±Ë®àÔºàmean„ÄÅstd„ÄÅmin„ÄÅmaxÔºâ„ÇíÁ¢∫Ë™ç„Åß„Åç„Çã</li>
<li>[ ] Ê¨†ÊêçÂÄ§ÔºàNaNÔºâ„ÇíÊ§úÂá∫„Åß„Åç„ÇãÔºà<code>df.isnull().sum()</code>Ôºâ</li>
<li>[ ] Ê¨†ÊêçÂÄ§„ÇíÂâäÈô§„Åæ„Åü„ÅØË£úÂÆå„Åß„Åç„ÇãÔºà<code>dropna()</code> or <code>fillna()</code>Ôºâ</li>
</ul>
<h4>ÂøúÁî®„É¨„Éô„É´</h4>
<ul>
<li>[ ] StandardScaler„Åß„Éá„Éº„Çø„ÇíÊ®ôÊ∫ñÂåñ„Åß„Åç„ÇãÔºàÂπ≥Âùá0„ÄÅÊ®ôÊ∫ñÂÅèÂ∑Æ1Ôºâ</li>
<li>[ ] MinMaxScaler„Åß0-1„Å´Ê≠£Ë¶èÂåñ„Åß„Åç„Çã</li>
<li>[ ] „Ç´„ÉÜ„Ç¥„É™Â§âÊï∞„Çí„ÉÄ„Éü„ÉºÂ§âÊï∞Âåñ„Åß„Åç„ÇãÔºà<code>pd.get_dummies()</code>Ôºâ</li>
<li>[ ] Â§ñ„ÇåÂÄ§„ÇíÊ§úÂá∫„ÉªÂá¶ÁêÜ„Åß„Åç„ÇãÔºàIQRÊ≥ï„ÄÅZ-scoreÊ≥ïÔºâ</li>
<li>[ ] „Éá„Éº„Çø„É™„Éº„ÇØÔºàData LeakageÔºâ„ÇíÈò≤„ÅêÊ≠£„Åó„ÅÑÂâçÂá¶ÁêÜÈ†ÜÂ∫è„ÇíÁêÜËß£„Åó„Å¶„ÅÑ„Çã</li>
<li>‚ùå ÈñìÈÅï„ÅÑ: ÂÖ®„Éá„Éº„Çø„ÅßÊ®ôÊ∫ñÂåñ ‚Üí ÂàÜÂâ≤</li>
<li>‚úÖ Ê≠£„Åó„ÅÑ: ÂàÜÂâ≤ ‚Üí Ë®ìÁ∑¥„Éá„Éº„Çø„ÅßÊ®ôÊ∫ñÂåñ ‚Üí „ÉÜ„Çπ„Éà„Éá„Éº„Çø„Å´ÈÅ©Áî®</li>
</ul>
<h4>‰∏äÁ¥ö„É¨„Éô„É´</h4>
<ul>
<li>[ ] SMOTEÔºàÈÅé„Çµ„É≥„Éó„É™„É≥„Ç∞Ôºâ„Åß‰∏çÂùáË°°„Éá„Éº„Çø„ÇíÂá¶ÁêÜ„Åß„Åç„Çã</li>
<li>[ ] ÊôÇÁ≥ªÂàó„Éá„Éº„Çø„ÅßÊôÇÈñìÈ†ÜÂàÜÂâ≤ÔºàTimeSeriesSplitÔºâ„ÇíÂÆüË£Ö„Åß„Åç„Çã</li>
<li>[ ] PipelineÔºàsklearn.pipelineÔºâ„Åß„Éá„Éº„ÇøÂá¶ÁêÜ„Å®„É¢„Éá„É´Ë®ìÁ∑¥„ÇíÁµ±Âêà„Åß„Åç„Çã</li>
</ul>
<hr />
<h3>9.6 Ë©ï‰æ°„ÉªÂèØË¶ñÂåñ„Çπ„Ç≠„É´ÔºàEvaluation &amp; VisualizationÔºâ</h3>
<h4>Âü∫Á§é„É¨„Éô„É´</h4>
<ul>
<li>[ ] MAEÔºàÂπ≥ÂùáÁµ∂ÂØæË™§Â∑ÆÔºâ„ÇíË®àÁÆó„ÉªËß£Èáà„Åß„Åç„Çã</li>
<li>[ ] R¬≤ÔºàÊ±∫ÂÆö‰øÇÊï∞Ôºâ„ÇíË®àÁÆó„ÉªËß£Èáà„Åß„Åç„ÇãÔºà1„Å´Ëøë„ÅÑ„Åª„Å©ËâØ„ÅÑÔºâ</li>
<li>[ ] Ë®ìÁ∑¥ÊôÇÈñì„ÇíÊ∏¨ÂÆö„Åß„Åç„ÇãÔºà<code>time.time()</code>Ôºâ</li>
<li>[ ] ‰∫àÊ∏¨ÂÄ§ vs ÂÆüÊ∏¨ÂÄ§„ÅÆÊï£Â∏ÉÂõ≥„Çí‰ΩúÊàê„Åß„Åç„Çã</li>
<li>[ ] „É¢„Éá„É´„ÅÆÊÄßËÉΩÊØîËºÉË°®„Çí‰ΩúÊàê„Åß„Åç„Çã</li>
</ul>
<h4>ÂøúÁî®„É¨„Éô„É´</h4>
<ul>
<li>[ ] Â≠¶ÁøíÊõ≤Á∑öÔºàLoss curveÔºâ„ÇíÂèØË¶ñÂåñ„Åß„Åç„Çã</li>
<li>[ ] ÊÆãÂ∑Æ„Éó„É≠„ÉÉ„ÉàÔºàResidual plotÔºâ„Çí‰ΩúÊàê„Åó„ÄÅ„É¢„Éá„É´„ÅÆÂÅè„Çä„ÇíÊ§úÂá∫„Åß„Åç„Çã</li>
<li>[ ] Ê∑∑ÂêåË°åÂàóÔºàÂàÜÈ°ûÂïèÈ°å„ÅÆÂ†¥ÂêàÔºâ„Çí‰ΩúÊàê„ÉªËß£Èáà„Åß„Åç„Çã</li>
<li>[ ] ÁâπÂæ¥ÈáèÈáçË¶ÅÂ∫¶„Çí„Ç∞„É©„ÉïÂåñ„Åß„Åç„Çã</li>
<li>[ ] „Éè„Ç§„Éë„Éº„Éë„É©„É°„Éº„Çø„ÅÆÂΩ±Èüø„Çí2Ê¨°ÂÖÉ„Éó„É≠„ÉÉ„Éà„ÅßÂèØË¶ñÂåñ„Åß„Åç„Çã</li>
</ul>
<h4>‰∏äÁ¥ö„É¨„Éô„É´</h4>
<ul>
<li>[ ] SHAPÂÄ§„Åß„É¢„Éá„É´„ÅÆ‰∫àÊ∏¨ÁêÜÁî±„ÇíË™¨Êòé„Åß„Åç„Çã</li>
<li>[ ] Partial Dependence PlotÔºàPDPÔºâ„ÅßÁâπÂæ¥Èáè„ÅÆÂΩ±Èüø„ÇíÂèØË¶ñÂåñ„Åß„Åç„Çã</li>
<li>[ ] Learning Curve„ÅßË®ìÁ∑¥„Éá„Éº„ÇøÈáè„ÅÆÂΩ±Èüø„ÇíÂàÜÊûê„Åß„Åç„Çã</li>
</ul>
<hr />
<h3>9.7 „Éà„É©„Éñ„É´„Ç∑„É•„Éº„ÉÜ„Ç£„É≥„Ç∞„Çπ„Ç≠„É´ÔºàTroubleshootingÔºâ</h3>
<h4>Âü∫Á§é„É¨„Éô„É´Ôºà„Ç®„É©„ÉºÂØæÂá¶Ôºâ</h4>
<ul>
<li>[ ] <code>ModuleNotFoundError</code>„ÇíËß£Ê±∫„Åß„Åç„ÇãÔºà<code>pip install</code>Ôºâ</li>
<li>[ ] <code>ValueError: Input contains NaN</code>„ÇíËß£Ê±∫„Åß„Åç„ÇãÔºàÊ¨†ÊêçÂÄ§Âá¶ÁêÜÔºâ</li>
<li>[ ] <code>ConvergenceWarning</code>ÔºàMLP„ÅÆÂèéÊùü„Ç®„É©„ÉºÔºâ„ÇíËß£Ê±∫„Åß„Åç„Çã</li>
<li><code>max_iter</code>„ÇíÂ¢ó„ÇÑ„Åô</li>
<li>„Éá„Éº„Çø„ÇíÊ®ôÊ∫ñÂåñ„Åô„Çã</li>
<li>Early Stopping„ÇíÊúâÂäπÂåñ</li>
<li>[ ] „Ç®„É©„Éº„É°„ÉÉ„Çª„Éº„Ç∏„ÇíË™≠„Åø„ÄÅÊ§úÁ¥¢„Åó„Å¶Ëß£Ê±∫Á≠ñ„ÇíË¶ã„Å§„Åë„Çâ„Çå„Çã</li>
</ul>
<h4>ÂøúÁî®„É¨„Éô„É´ÔºàÊÄßËÉΩÊîπÂñÑÔºâ</h4>
<ul>
<li>[ ] R¬≤ &lt; 0.5„ÅÆÂ†¥Âêà„ÄÅ3„Å§‰ª•‰∏ä„ÅÆÊîπÂñÑÁ≠ñ„ÇíÂÆüË°å„Åß„Åç„Çã</li>
<li>ÁâπÂæ¥Èáè„Ç®„É≥„Ç∏„Éã„Ç¢„É™„É≥„Ç∞</li>
<li>„É¢„Éá„É´Â§âÊõ¥ÔºàÁ∑öÂΩ¢‚ÜíÈùûÁ∑öÂΩ¢Ôºâ</li>
<li>„Éè„Ç§„Éë„Éº„Éë„É©„É°„Éº„Çø„ÉÅ„É•„Éº„Éã„É≥„Ç∞</li>
<li>[ ] ÈÅéÂ≠¶Áøí„ÇíÊ§úÂá∫„Åß„Åç„ÇãÔºàË®ìÁ∑¥Ë™§Â∑Æ ‚â™ „ÉÜ„Çπ„ÉàË™§Â∑ÆÔºâ</li>
<li>[ ] Êú™Â≠¶Áøí„ÇíÊ§úÂá∫„Åß„Åç„ÇãÔºàË®ìÁ∑¥Ë™§Â∑Æ„ÇÇ„ÉÜ„Çπ„ÉàË™§Â∑Æ„ÇÇÂ§ß„Åç„ÅÑÔºâ</li>
<li>[ ] „Éá„Éê„ÉÉ„Ç∞„ÅÆ5„Çπ„ÉÜ„ÉÉ„Éó„ÇíÂÆüË°å„Åß„Åç„Çã
  1. „Éá„Éº„Çø„ÅÆÁ¢∫Ë™ç
  2. „Éá„Éº„Çø„ÅÆÂèØË¶ñÂåñ
  3. Â∞èË¶èÊ®°„Éá„Éº„Çø„Åß„ÉÜ„Çπ„Éà
  4. „É¢„Éá„É´„ÅÆÁ∞°Áï•Âåñ
  5. „Ç®„É©„Éº„É°„ÉÉ„Çª„Éº„Ç∏„ÇíË™≠„ÇÄ</li>
</ul>
<h4>‰∏äÁ¥ö„É¨„Éô„É´Ôºà‰ΩìÁ≥ªÁöÑ„Éá„Éê„ÉÉ„Ç∞Ôºâ</h4>
<ul>
<li>[ ] „Éó„É≠„Éï„Ç°„Ç§„É™„É≥„Ç∞ÔºàcProfileÔºâ„ÅßÂÆüË°åÊôÇÈñì„ÅÆ„Éú„Éà„É´„Éç„ÉÉ„ÇØ„ÇíÁâπÂÆö„Åß„Åç„Çã</li>
<li>[ ] „É°„É¢„É™‰ΩøÁî®Èáè„ÇíÁõ£Ë¶ñ„Åó„ÄÅMemoryError„Çí‰∫àÈò≤„Åß„Åç„Çã</li>
<li>[ ] „É≠„Ç∞Âá∫ÂäõÔºàloggingÔºâ„ÇíË®≠ÂÆö„Åó„ÄÅË®ìÁ∑¥ÈÅéÁ®ã„ÇíË®òÈå≤„Åß„Åç„Çã</li>
<li>[ ] „Éê„Éº„Ç∏„Éß„É≥ÁÆ°ÁêÜÔºàGitÔºâ„ÅßÂÆüÈ®ì„ÇíËøΩË∑°„Åß„Åç„Çã</li>
</ul>
<hr />
<h3>9.8 „Éó„É≠„Ç∏„Çß„ÇØ„ÉàÂÆåÈÅÇ„Çπ„Ç≠„É´ÔºàProject CompletionÔºâ</h3>
<h4>ÂøÖÈ†à„Çπ„Ç≠„É´Ôºà„Éê„É≥„Éâ„ÇÆ„É£„ÉÉ„Éó‰∫àÊ∏¨„Éó„É≠„Ç∏„Çß„ÇØ„ÉàÔºâ</h4>
<ul>
<li>[ ] „Éó„É≠„Ç∏„Çß„ÇØ„ÉàÁõÆÊ®ô„ÇíÁêÜËß£„Åó„Å¶„ÅÑ„ÇãÔºàR¬≤ &gt; 0.7„ÄÅMAE &lt; 0.5 eVÔºâ</li>
<li>[ ] „Éá„Éº„ÇøÂèéÈõÜÔºàMaterials Project API or Ê®°Êì¨„Éá„Éº„ÇøÔºâ„ÇíÂÆå‰∫Ü„Åó„Åü</li>
<li>[ ] ÁâπÂæ¥Èáè„Ç®„É≥„Ç∏„Éã„Ç¢„É™„É≥„Ç∞„ÇíÂÆüÊñΩ„Åó„Åü</li>
<li>[ ] „Éá„Éº„Çø„ÇíË®ìÁ∑¥/„ÉÜ„Çπ„Éà„Å´ÂàÜÂâ≤„Åó„ÅüÔºà80% vs 20%Ôºâ</li>
<li>[ ] „É©„É≥„ÉÄ„É†„Éï„Ç©„É¨„Çπ„Éà„Åæ„Åü„ÅØLightGBM„Åß‰∫àÊ∏¨„É¢„Éá„É´„ÇíÊßãÁØâ„Åó„Åü</li>
<li>[ ] MAE„ÄÅR¬≤„ÅßÊÄßËÉΩ„ÇíË©ï‰æ°„Åó„Åü</li>
<li>[ ] ‰∫àÊ∏¨ÁµêÊûú„ÇíÂèØË¶ñÂåñ„Åó„ÅüÔºàÊï£Â∏ÉÂõ≥Ôºâ</li>
<li>[ ] ÁõÆÊ®ôÈÅîÊàê/Êú™ÈÅîÊàê„ÇíÂà§ÂÆö„Åó„Åü</li>
</ul>
<h4>Áô∫Â±ï„Çπ„Ç≠„É´</h4>
<ul>
<li>[ ] ÂàùÁ¥öË™≤È°å: Âà•„ÅÆÁâπÊÄßÔºàËûçÁÇπ„ÄÅÂΩ¢Êàê„Ç®„Éç„É´„ÇÆ„ÉºÔºâ„Åß‰∫àÊ∏¨„É¢„Éá„É´„ÇíÊßãÁØâ</li>
<li>[ ] ‰∏≠Á¥öË™≤È°å: Matminer„Åß130‰ª•‰∏ä„ÅÆÁâπÂæ¥Èáè„ÇíÊäΩÂá∫„Åó„ÄÅÊÄßËÉΩÂêë‰∏ä</li>
<li>[ ] ‰∏äÁ¥öË™≤È°å: „Ç¢„É≥„Çµ„É≥„Éñ„É´Â≠¶Áøí„ÅßÊÄßËÉΩÂêë‰∏ä</li>
<li>[ ] ‰∏äÁ¥öË™≤È°å: „Éã„É•„Éº„É©„É´„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØÔºàMLPÔºâ„Åß‰∫àÊ∏¨</li>
</ul>
<hr />
<h3>9.9 „Ç≥„Éº„ÉâÂìÅË≥™„Çπ„Ç≠„É´ÔºàCode QualityÔºâ</h3>
<h4>Âü∫Á§é„É¨„Éô„É´</h4>
<ul>
<li>[ ] „Åô„Åπ„Å¶„ÅÆ„Ç≥„Éº„Éâ„Å´‰æùÂ≠ò„É©„Ç§„Éñ„É©„É™„Éê„Éº„Ç∏„Éß„É≥„Çí„Ç≥„É°„É≥„ÉàË®òËºâ„Åó„Å¶„ÅÑ„Çã
  <code>python
  # Dependencies: Python 3.9+, scikit-learn 1.3+, numpy 1.24+</code></li>
<li>[ ] ‰π±Êï∞„Ç∑„Éº„Éâ„ÇíÂõ∫ÂÆö„Åó„Å¶ÂÜçÁèæÊÄß„ÇíÁ¢∫‰øù„Åó„Å¶„ÅÑ„ÇãÔºà<code>random_state=42</code>Ôºâ</li>
<li>[ ] „Éá„Éº„ÇøÊ§úË®ºÔºàshape„ÄÅdtype„ÄÅNaN„ÄÅÁØÑÂõ≤Ôºâ„ÇíÂÆüÊñΩ„Åó„Å¶„ÅÑ„Çã</li>
<li>[ ] Â§âÊï∞Âêç„ÅåÂàÜ„Åã„Çä„ÇÑ„Åô„ÅÑÔºà<code>X_train</code>„ÄÅ<code>y_test</code>„ÄÅ<code>model_rf</code>Ôºâ</li>
<li>[ ] „Ç≥„É°„É≥„Éà„ÅßÂá¶ÁêÜ„ÅÆÁõÆÁöÑ„ÇíË™¨Êòé„Åó„Å¶„ÅÑ„Çã</li>
</ul>
<h4>ÂøúÁî®„É¨„Éô„É´</h4>
<ul>
<li>[ ] Èñ¢Êï∞Âåñ„Åó„Å¶„Ç≥„Éº„Éâ„ÇíÂÜçÂà©Áî®ÂèØËÉΩ„Å´„Åó„Å¶„ÅÑ„Çã
  <code>python
  def train_and_evaluate(model, X_train, X_test, y_train, y_test):
      model.fit(X_train, y_train)
      y_pred = model.predict(X_test)
      mae = mean_absolute_error(y_test, y_pred)
      r2 = r2_score(y_test, y_pred)
      return mae, r2</code></li>
<li>[ ] try-except „Åß„Ç®„É©„Éº„Éè„É≥„Éâ„É™„É≥„Ç∞„ÇíÂÆüË£Ö„Åó„Å¶„ÅÑ„Çã</li>
<li>[ ] „É≠„ÇÆ„É≥„Ç∞„ÅßË®ìÁ∑¥ÈÅéÁ®ã„ÇíË®òÈå≤„Åó„Å¶„ÅÑ„Çã</li>
<li>[ ] Jupyter Notebook„Çí„Çπ„ÇØ„É™„Éó„ÉàÔºà.pyÔºâ„Å´Â§âÊèõ„Åß„Åç„Çã</li>
<li>[ ] requirements.txt„ÅßÁí∞Â¢É„ÇíÂÜçÁèæÂèØËÉΩ„Å´„Åó„Å¶„ÅÑ„Çã</li>
</ul>
<hr />
<h3>9.10 Á∑èÂêàË©ï‰æ°Ôºö„Éó„É≠„Ç∏„Çß„ÇØ„ÉàÂÆåÈÅÇ„É¨„Éô„É´</h3>
<p>‰ª•‰∏ã„ÅÆ„É¨„Éô„É´Âà§ÂÆö„Åß„ÄÅËá™ÂàÜ„ÅÆÂà∞ÈÅîÂ∫¶„ÇíÁ¢∫Ë™ç„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ</p>
<h4>„É¨„Éô„É´1ÔºöÂàùÂøÉËÄÖÔºàBeginnerÔºâ</h4>
<ul>
<li>Áí∞Â¢ÉÊßãÁØâ„Çπ„Ç≠„É´ÔºöÂü∫Á§é„É¨„Éô„É´ 100%ÈÅîÊàê</li>
<li>„É¢„Éá„É´ÂÆüË£Ö„Çπ„Ç≠„É´ÔºöÂü∫Á§é„É¨„Éô„É´ 6„Å§‰∏≠3„Å§‰ª•‰∏äÂÆüË£Ö</li>
<li>„Éà„É©„Éñ„É´„Ç∑„É•„Éº„ÉÜ„Ç£„É≥„Ç∞ÔºöÂü∫Á§é„É¨„Éô„É´„ÅÆ„Ç®„É©„Éº„ÇíËá™Âäõ„ÅßËß£Ê±∫</li>
</ul>
<p><strong>Âà∞ÈÅîÁõÆÊ®ô:</strong> Á∑öÂΩ¢ÂõûÂ∏∞„ÄÅ„É©„É≥„ÉÄ„É†„Éï„Ç©„É¨„Çπ„Éà„ÇíÂÆüË£Ö„Åó„ÄÅMAE„ÉªR¬≤„ÇíË®àÁÆó„Åß„Åç„Çã</p>
<hr />
<h4>„É¨„Éô„É´2Ôºö‰∏≠Á¥öËÄÖÔºàIntermediateÔºâ</h4>
<ul>
<li>Áí∞Â¢ÉÊßãÁØâ„Çπ„Ç≠„É´ÔºöÂøúÁî®„É¨„Éô„É´ 80%‰ª•‰∏äÈÅîÊàê</li>
<li>„É¢„Éá„É´ÂÆüË£Ö„Çπ„Ç≠„É´ÔºöÂü∫Á§é„É¨„Éô„É´ 100%ÈÅîÊàê + ÂøúÁî®„É¨„Éô„É´ 50%‰ª•‰∏ä</li>
<li>„Éè„Ç§„Éë„Éº„Éë„É©„É°„Éº„Çø„ÉÅ„É•„Éº„Éã„É≥„Ç∞ÔºöÂü∫Á§é„É¨„Éô„É´ 100%ÈÅîÊàê</li>
<li>ÁâπÂæ¥Èáè„Ç®„É≥„Ç∏„Éã„Ç¢„É™„É≥„Ç∞ÔºöÂü∫Á§é„É¨„Éô„É´ 100%ÈÅîÊàê</li>
<li>„Éó„É≠„Ç∏„Çß„ÇØ„ÉàÂÆåÈÅÇ„Çπ„Ç≠„É´ÔºöÂøÖÈ†à„Çπ„Ç≠„É´ 100%ÈÅîÊàê</li>
</ul>
<p><strong>Âà∞ÈÅîÁõÆÊ®ô:</strong> „Éê„É≥„Éâ„ÇÆ„É£„ÉÉ„Éó‰∫àÊ∏¨„Éó„É≠„Ç∏„Çß„ÇØ„Éà„Åß R¬≤ &gt; 0.7„ÄÅMAE &lt; 0.5 eV „ÇíÈÅîÊàê</p>
<hr />
<h4>„É¨„Éô„É´3Ôºö‰∏äÁ¥öËÄÖÔºàAdvancedÔºâ</h4>
<ul>
<li>ÂÖ®„Ç´„ÉÜ„Ç¥„É™ÔºöÂøúÁî®„É¨„Éô„É´ 100%ÈÅîÊàê</li>
<li>„Éè„Ç§„Éë„Éº„Éë„É©„É°„Éº„Çø„ÉÅ„É•„Éº„Éã„É≥„Ç∞Ôºö‰∏äÁ¥ö„É¨„Éô„É´ 50%‰ª•‰∏ä</li>
<li>ÁâπÂæ¥Èáè„Ç®„É≥„Ç∏„Éã„Ç¢„É™„É≥„Ç∞Ôºö‰∏äÁ¥ö„É¨„Éô„É´ÔºàMatminerÊ¥ªÁî®Ôºâ100%ÈÅîÊàê</li>
<li>„Éó„É≠„Ç∏„Çß„ÇØ„ÉàÂÆåÈÅÇ„Çπ„Ç≠„É´ÔºöÁô∫Â±ï„Çπ„Ç≠„É´ 2„Å§‰ª•‰∏äÈÅîÊàê</li>
</ul>
<p><strong>Âà∞ÈÅîÁõÆÊ®ô:</strong> Matminer„Åß130ÁâπÂæ¥Èáè„ÇíÊäΩÂá∫„Åó„ÄÅ„Ç¢„É≥„Çµ„É≥„Éñ„É´Â≠¶Áøí„Åß R¬≤ &gt; 0.85 „ÇíÈÅîÊàê</p>
<hr />
<h4>„É¨„Éô„É´4Ôºö„Ç®„Ç≠„Çπ„Éë„Éº„ÉàÔºàExpertÔºâ</h4>
<ul>
<li>ÂÖ®„Ç´„ÉÜ„Ç¥„É™Ôºö‰∏äÁ¥ö„É¨„Éô„É´ 80%‰ª•‰∏äÈÅîÊàê</li>
<li>„Ç≥„Éº„ÉâÂìÅË≥™ÔºöÂøúÁî®„É¨„Éô„É´ 100%ÈÅîÊàê</li>
<li>„Éó„É≠„Ç∏„Çß„ÇØ„ÉàÂÆåÈÅÇ„Çπ„Ç≠„É´ÔºöÁô∫Â±ï„Çπ„Ç≠„É´ ÂÖ®ÈÅîÊàê</li>
<li>Áã¨Ëá™„ÅÆÊîπÂñÑÁ≠ñ„Çí3„Å§‰ª•‰∏äÊèêÊ°à„ÉªÂÆüË£Ö„Åß„Åç„Çã</li>
</ul>
<p><strong>Âà∞ÈÅîÁõÆÊ®ô:</strong>
- Materials Project API„Åã„ÇâÂÆü„Éá„Éº„Çø„ÇíÂèñÂæó
- „Éô„Ç§„Ç∫ÊúÄÈÅ©Âåñ„Åß„Éè„Ç§„Éë„Éº„Éë„É©„É°„Éº„ÇøÊúÄÈÅ©Âåñ
- SHAPÂÄ§„Åß„É¢„Éá„É´„ÅÆË™¨ÊòéÂèØËÉΩÊÄß„ÇíÂÆüÁèæ
- R¬≤ &gt; 0.90„ÄÅÂÆüÂãô„É¨„Éô„É´„ÅÆ‰∫àÊ∏¨Á≤æÂ∫¶</p>
<hr />
<h3>9.11 Ê¨°„ÅÆ„Çπ„ÉÜ„ÉÉ„Éó„Å∏„ÅÆÊ∫ñÂÇôÂ∫¶„ÉÅ„Çß„ÉÉ„ÇØ</h3>
<p>‰ª•‰∏ã„ÅÆ„ÉÅ„Çß„ÉÉ„ÇØ„É™„Çπ„Éà„Åß„ÄÅÊ¨°„ÅÆÂ≠¶ÁøíÊÆµÈöé„Å∏„ÅÆÊ∫ñÂÇô„Åå„Åß„Åç„Å¶„ÅÑ„Çã„ÅãÁ¢∫Ë™ç„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ</p>
<h4>Ê∑±Â±§Â≠¶ÁøíÔºàGNN„ÄÅCGCNNÔºâ„Å∏„ÅÆÊ∫ñÂÇô</h4>
<ul>
<li>[ ] „Éã„É•„Éº„É©„É´„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØÔºàMLPÔºâ„ÇíÂÆüË£Ö„Åó„ÄÅReLU„ÉªAdam„ÉªEarly Stopping„ÇíÁêÜËß£„Åó„Å¶„ÅÑ„Çã</li>
<li>[ ] Â≠¶ÁøíÊõ≤Á∑ö„ÇíÂèØË¶ñÂåñ„Åó„ÄÅÈÅéÂ≠¶Áøí„ÇíÊ§úÂá∫„Åß„Åç„Çã</li>
<li>[ ] „Éá„Éº„ÇøÊ®ôÊ∫ñÂåñ„ÅÆÈáçË¶ÅÊÄß„ÇíÁêÜËß£„Åó„Å¶„ÅÑ„Çã</li>
<li>[ ] ÊêçÂ§±Èñ¢Êï∞ÔºàMSE„ÄÅMAEÔºâ„Å®„Éê„ÉÉ„ÇØ„Éó„É≠„Éë„Ç≤„Éº„Ç∑„Éß„É≥„ÅÆÊ¶ÇÂøµ„ÇíË™¨Êòé„Åß„Åç„Çã</li>
</ul>
<h4>„Éô„Ç§„Ç∫ÊúÄÈÅ©Âåñ„Å∏„ÅÆÊ∫ñÂÇô</h4>
<ul>
<li>[ ] „Éè„Ç§„Éë„Éº„Éë„É©„É°„Éº„Çø„ÉÅ„É•„Éº„Éã„É≥„Ç∞ÔºàGrid Search„ÄÅRandom SearchÔºâ„ÇíÂÆüË£Ö„Åß„Åç„Çã</li>
<li>[ ] ‰∫§Â∑ÆÊ§úË®º„ÅßÊ±éÂåñÊÄßËÉΩ„ÇíË©ï‰æ°„Åß„Åç„Çã</li>
<li>[ ] „Éè„Ç§„Éë„Éº„Éë„É©„É°„Éº„ÇøÊé¢Á¥¢Á©∫Èñì„ÇíË®≠ÂÆö„Åß„Åç„Çã</li>
</ul>
<h4>Ëª¢ÁßªÂ≠¶Áøí„Å∏„ÅÆÊ∫ñÂÇô</h4>
<ul>
<li>[ ] ‰∫ãÂâçÂ≠¶ÁøíÊ∏à„Åø„É¢„Éá„É´„ÅÆÊ¶ÇÂøµ„ÇíÁêÜËß£„Åó„Å¶„ÅÑ„Çã</li>
<li>[ ] Fine-tuningÔºàÂæÆË™øÊï¥Ôºâ„ÅÆÂøÖË¶ÅÊÄß„ÇíË™¨Êòé„Åß„Åç„Çã</li>
<li>[ ] „Éâ„É°„Ç§„É≥ÈÅ©ÂøúÔºàDomain AdaptationÔºâ„ÅÆÊ¶ÇÂøµ„ÇíÁü•„Å£„Å¶„ÅÑ„Çã</li>
</ul>
<h4>ÂÆüÂãô„Éó„É≠„Ç∏„Çß„ÇØ„Éà„Å∏„ÅÆÊ∫ñÂÇô</h4>
<ul>
<li>[ ] Git„Åß„Ç≥„Éº„Éâ„Çí„Éê„Éº„Ç∏„Éß„É≥ÁÆ°ÁêÜ„Åß„Åç„Çã</li>
<li>[ ] Jupyter Notebook„ÇíPython„Çπ„ÇØ„É™„Éó„Éà„Å´Â§âÊèõ„Åß„Åç„Çã</li>
<li>[ ] requirements.txt„ÅßÁí∞Â¢É„ÇíÂÜçÁèæÂèØËÉΩ„Å´„Åó„Å¶„ÅÑ„Çã</li>
<li>[ ] ÂÆüÈ®ìÁµêÊûú„ÇíMarkdown/PDF„É¨„Éù„Éº„Éà„Å´„Åæ„Å®„ÇÅ„Çâ„Çå„Çã</li>
<li>[ ] ‰∫àÊ∏¨„É¢„Éá„É´„Çípickle/joblib „Åß‰øùÂ≠ò„ÉªË™≠„ÅøËæº„Åø„Åß„Åç„Çã</li>
<li>[ ] API„Ç≠„Éº„Çí.env„Éï„Ç°„Ç§„É´„ÅßÂÆâÂÖ®„Å´ÁÆ°ÁêÜ„Åß„Åç„Çã</li>
</ul>
<hr />
<p><strong>„ÉÅ„Çß„ÉÉ„ÇØ„É™„Çπ„ÉàÊ¥ªÁî®„ÅÆ„Éí„É≥„Éà:</strong>
1. <strong>ÂÆöÊúüÁöÑ„Å´Ë¶ãÁõ¥„Åô</strong>: Â≠¶ÁøíÂæå„ÄÅ1ÈÄ±ÈñìÂæå„ÄÅ1„É∂ÊúàÂæå„Å´ÂÜç„ÉÅ„Çß„ÉÉ„ÇØ
2. <strong>Êú™ÈÅîÊàêÈ†ÖÁõÆ„ÇíÂÑ™ÂÖà</strong>: „ÉÅ„Çß„ÉÉ„ÇØ„Åß„Åç„Å™„ÅÑÈ†ÖÁõÆ„ÇíÈõÜ‰∏≠Â≠¶Áøí
3. <strong>„É¨„Éô„É´Âà§ÂÆö„ÇíË®òÈå≤</strong>: ÊàêÈï∑„ÇíÂèØË¶ñÂåñ„Åó„Å¶„É¢„ÉÅ„Éô„Éº„Ç∑„Éß„É≥Á∂≠ÊåÅ
4. <strong>ÂÆüÂãô„Åß„ÅÆÊ¥ªÁî®</strong>: „Éó„É≠„Ç∏„Çß„ÇØ„ÉàÈñãÂßãÂâç„Å´ÂøÖÈ†à„Çπ„Ç≠„É´„ÇíÁ¢∫Ë™ç</p>
<hr />
<h2>ÂèÇËÄÉÊñáÁåÆ</h2>
<ol>
<li>
<p>Pedregosa, F., et al. (2011). "Scikit-learn: Machine Learning in Python." <em>Journal of Machine Learning Research</em>, 12, 2825-2830.
   URL: https://scikit-learn.org
   <em>scikit-learnÂÖ¨Âºè„Éâ„Ç≠„É•„É°„É≥„Éà„ÄÇ„Åô„Åπ„Å¶„ÅÆ„Ç¢„É´„Ç¥„É™„Ç∫„É†„ÅÆË©≥Á¥∞„Å™Ëß£Ë™¨„Å®„ÉÅ„É•„Éº„Éà„É™„Ç¢„É´„ÄÇ</em></p>
</li>
<li>
<p>Ward, L., et al. (2018). "Matminer: An open source toolkit for materials data mining." <em>Computational Materials Science</em>, 152, 60-69.
   DOI: <a href="https://doi.org/10.1016/j.commatsci.2018.05.018">10.1016/j.commatsci.2018.05.018</a>
   GitHub: https://github.com/hackingmaterials/matminer
   <em>ÊùêÊñôÁßëÂ≠¶Âêë„ÅëÁâπÂæ¥ÈáèÊäΩÂá∫„É©„Ç§„Éñ„É©„É™„ÄÇ132Á®ÆÈ°û„ÅÆÊùêÊñôË®òËø∞Â≠ê„ÇíËá™ÂãïÁîüÊàê„ÄÇ</em></p>
</li>
<li>
<p>Jain, A., et al. (2013). "Commentary: The Materials Project: A materials genome approach to accelerating materials innovation." <em>APL Materials</em>, 1(1), 011002.
   DOI: <a href="https://doi.org/10.1063/1.4812323">10.1063/1.4812323</a>
   URL: https://materialsproject.org
   <em>Materials ProjectÂÖ¨ÂºèË´ñÊñá„ÄÇ140,000Á®ÆÈ°û‰ª•‰∏ä„ÅÆÊùêÊñô„Éá„Éº„Çø„Éô„Éº„Çπ„ÄÇ</em></p>
</li>
<li>
<p>Ke, G., et al. (2017). "LightGBM: A Highly Efficient Gradient Boosting Decision Tree." <em>Advances in Neural Information Processing Systems</em>, 30, 3146-3154.
   GitHub: https://github.com/microsoft/LightGBM
   <em>LightGBMÂÖ¨ÂºèË´ñÊñá„ÄÇÂãæÈÖç„Éñ„Éº„Çπ„ÉÜ„Ç£„É≥„Ç∞„ÅÆÈ´òÈÄüÂÆüË£Ö„ÄÇ</em></p>
</li>
<li>
<p>Bergstra, J., &amp; Bengio, Y. (2012). "Random Search for Hyper-Parameter Optimization." <em>Journal of Machine Learning Research</em>, 13, 281-305.
   URL: https://www.jmlr.org/papers/v13/bergstra12a.html
   <em>Random Search„ÅÆÁêÜË´ñÁöÑËÉåÊôØ„ÄÇGrid Search„Çà„ÇäÂäπÁéáÁöÑ„Å™Êé¢Á¥¢ÊâãÊ≥ï„ÄÇ</em></p>
</li>
<li>
<p>Raschka, S., &amp; Mirjalili, V. (2019). <em>Python Machine Learning, 3rd Edition</em>. Packt Publishing.
   <em>Python„Å´„Çà„ÇãÊ©üÊ¢∞Â≠¶Áøí„ÅÆÂåÖÊã¨ÁöÑ„Å™ÊïôÁßëÊõ∏„ÄÇscikit-learn„ÅÆÂÆüË∑µÁöÑ„Å™‰Ωø„ÅÑÊñπ„ÇíË©≥Ë™¨„ÄÇ</em></p>
</li>
<li>
<p>scikit-learn User Guide. (2024). "Hyperparameter tuning."
   URL: https://scikit-learn.org/stable/modules/grid_search.html
   <em>„Éè„Ç§„Éë„Éº„Éë„É©„É°„Éº„Çø„ÉÅ„É•„Éº„Éã„É≥„Ç∞„ÅÆÂÖ¨Âºè„Ç¨„Ç§„Éâ„ÄÇGrid Search„ÄÅRandom Search„ÅÆË©≥Á¥∞„ÄÇ</em></p>
</li>
</ol>
<hr />
<p><strong>‰ΩúÊàêÊó•</strong>: 2025-10-16
<strong>„Éê„Éº„Ç∏„Éß„É≥</strong>: 3.0
<strong>„ÉÜ„É≥„Éó„É¨„Éº„Éà</strong>: content_agent_prompts.py v1.0
<strong>ËëóËÄÖ</strong>: MI Knowledge Hub „Éó„É≠„Ç∏„Çß„ÇØ„Éà</p><div class="navigation">
    <a href="chapter2-fundamentals.html" class="nav-button">‚Üê Ââç„ÅÆÁ´†</a>
    <a href="index.html" class="nav-button">„Ç∑„É™„Éº„Ç∫ÁõÆÊ¨°„Å´Êàª„Çã</a>
    <a href="chapter4-real-world.html" class="nav-button">Ê¨°„ÅÆÁ´† ‚Üí</a>
</div>
    </main>

    <footer>
        <p><strong>‰ΩúÊàêËÄÖ</strong>: AI Terakoya Content Team</p>
        <p><strong>Áõ£‰øÆ</strong>: Dr. Yusuke HashimotoÔºàÊù±ÂåóÂ§ßÂ≠¶Ôºâ</p>
        <p><strong>„Éê„Éº„Ç∏„Éß„É≥</strong>: 3.0 | <strong>‰ΩúÊàêÊó•</strong>: 2025-10-16</p>
        <p><strong>„É©„Ç§„Çª„É≥„Çπ</strong>: Creative Commons BY 4.0</p>
        <p>¬© 2025 AI Terakoya. All rights reserved.</p>
    </footer>
</body>
</html>
