<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ç¬¬2ç« ï¼šGNNã®åŸºç¤ç†è«– - AI Terakoya</title>

    <style>
        :root {
            --color-primary: #2c3e50;
            --color-primary-dark: #1a252f;
            --color-accent: #7b2cbf;
            --color-accent-light: #9d4edd;
            --color-text: #2d3748;
            --color-text-light: #4a5568;
            --color-bg: #ffffff;
            --color-bg-alt: #f7fafc;
            --color-border: #e2e8f0;
            --color-code-bg: #f8f9fa;
            --color-link: #3182ce;
            --color-link-hover: #2c5aa0;

            --spacing-xs: 0.5rem;
            --spacing-sm: 1rem;
            --spacing-md: 1.5rem;
            --spacing-lg: 2rem;
            --spacing-xl: 3rem;

            --font-body: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            --font-mono: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;

            --border-radius: 8px;
            --box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: var(--font-body);
            line-height: 1.7;
            color: var(--color-text);
            background-color: var(--color-bg);
            font-size: 16px;
        }

        header {
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            padding: var(--spacing-xl) var(--spacing-md);
            margin-bottom: var(--spacing-xl);
            box-shadow: var(--box-shadow);
        }

        .header-content {
            max-width: 900px;
            margin: 0 auto;
        }

        h1 {
            font-size: 2rem;
            font-weight: 700;
            margin-bottom: var(--spacing-sm);
            line-height: 1.2;
        }

        .subtitle {
            font-size: 1.1rem;
            opacity: 0.95;
            font-weight: 400;
            margin-bottom: var(--spacing-md);
        }

        .meta {
            display: flex;
            flex-wrap: wrap;
            gap: var(--spacing-md);
            font-size: 0.9rem;
            opacity: 0.9;
        }

        .meta-item {
            display: flex;
            align-items: center;
            gap: 0.3rem;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 0 var(--spacing-md) var(--spacing-xl);
        }

        h2 {
            font-size: 1.75rem;
            color: var(--color-primary);
            margin-top: var(--spacing-xl);
            margin-bottom: var(--spacing-md);
            padding-bottom: var(--spacing-xs);
            border-bottom: 3px solid var(--color-accent);
        }

        h3 {
            font-size: 1.4rem;
            color: var(--color-primary);
            margin-top: var(--spacing-lg);
            margin-bottom: var(--spacing-sm);
        }

        h4 {
            font-size: 1.1rem;
            color: var(--color-primary-dark);
            margin-top: var(--spacing-md);
            margin-bottom: var(--spacing-sm);
        }

        p {
            margin-bottom: var(--spacing-md);
            color: var(--color-text);
        }

        a {
            color: var(--color-link);
            text-decoration: none;
            transition: color 0.2s;
        }

        a:hover {
            color: var(--color-link-hover);
            text-decoration: underline;
        }

        ul, ol {
            margin-left: var(--spacing-lg);
            margin-bottom: var(--spacing-md);
        }

        li {
            margin-bottom: var(--spacing-xs);
            color: var(--color-text);
        }

        pre {
            background-color: var(--color-code-bg);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            overflow-x: auto;
            margin-bottom: var(--spacing-md);
            font-family: var(--font-mono);
            font-size: 0.9rem;
            line-height: 1.5;
        }

        code {
            font-family: var(--font-mono);
            font-size: 0.9em;
            background-color: var(--color-code-bg);
            padding: 0.2em 0.4em;
            border-radius: 3px;
        }

        pre code {
            background-color: transparent;
            padding: 0;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: var(--spacing-md);
            font-size: 0.95rem;
        }

        th, td {
            border: 1px solid var(--color-border);
            padding: var(--spacing-sm);
            text-align: left;
        }

        th {
            background-color: var(--color-bg-alt);
            font-weight: 600;
            color: var(--color-primary);
        }

        blockquote {
            border-left: 4px solid var(--color-accent);
            padding-left: var(--spacing-md);
            margin: var(--spacing-md) 0;
            color: var(--color-text-light);
            font-style: italic;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        .mermaid {
            text-align: center;
            margin: var(--spacing-lg) 0;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        details {
            background-color: var(--color-bg-alt);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            margin-bottom: var(--spacing-md);
        }

        summary {
            cursor: pointer;
            font-weight: 600;
            color: var(--color-primary);
            user-select: none;
            padding: var(--spacing-xs);
            margin: calc(-1 * var(--spacing-md));
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        summary:hover {
            background-color: rgba(123, 44, 191, 0.1);
        }

        details[open] summary {
            margin-bottom: var(--spacing-md);
            border-bottom: 1px solid var(--color-border);
        }

        .learning-objectives {
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
            padding: var(--spacing-lg);
            border-radius: var(--border-radius);
            border-left: 4px solid var(--color-accent);
            margin-bottom: var(--spacing-xl);
        }

        .learning-objectives h2 {
            margin-top: 0;
            border-bottom: none;
        }

        .navigation {
            display: flex;
            justify-content: space-between;
            gap: var(--spacing-md);
            margin: var(--spacing-xl) 0;
            padding-top: var(--spacing-lg);
            border-top: 2px solid var(--color-border);
        }

        .nav-button {
            flex: 1;
            padding: var(--spacing-md);
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            border-radius: var(--border-radius);
            text-align: center;
            font-weight: 600;
            transition: transform 0.2s, box-shadow 0.2s;
            box-shadow: var(--box-shadow);
        }

        .nav-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
            text-decoration: none;
        }

        footer {
            margin-top: var(--spacing-xl);
            padding: var(--spacing-lg) var(--spacing-md);
            background-color: var(--color-bg-alt);
            border-top: 1px solid var(--color-border);
            text-align: center;
            font-size: 0.9rem;
            color: var(--color-text-light);
        }
        .disclaimer {
            max-width: 900px;
            margin: 2rem auto;
            padding: 1.5rem;
            background: #f8f9fa;
            border-left: 4px solid #6c757d;
            border-radius: 4px;
        }

        .disclaimer h3 {
            color: #495057;
            margin-bottom: 1rem;
            font-size: 1.1rem;
        }

        .disclaimer ul {
            list-style: none;
            padding-left: 0;
        }

        .disclaimer li {
            padding: 0.5rem 0;
            padding-left: 1.5rem;
            position: relative;
            font-size: 0.9rem;
            color: #6c757d;
            line-height: 1.6;
        }

        .disclaimer li::before {
            content: "âš ï¸";
            position: absolute;
            left: 0;
        }


        @media (max-width: 768px) {
            h1 {
                font-size: 1.5rem;
            }

            h2 {
                font-size: 1.4rem;
            }

            h3 {
                font-size: 1.2rem;
            }

            .meta {
                font-size: 0.85rem;
            }

            .navigation {
                flex-direction: column;
            }

            table {
                font-size: 0.85rem;
            }

            th, td {
                padding: var(--spacing-xs);
            }
        }
    
        
    
        /* Breadcrumb styles */
        .breadcrumb {
            background: #f7fafc;
            padding: 0.75rem 1rem;
            border-bottom: 1px solid #e2e8f0;
            font-size: 0.9rem;
        }

        .breadcrumb-content {
            max-width: 900px;
            margin: 0 auto;
            display: flex;
            align-items: center;
            flex-wrap: wrap;
            gap: 0.5rem;
        }

        .breadcrumb a {
            color: #667eea;
            text-decoration: none;
            transition: color 0.2s;
        }

        .breadcrumb a:hover {
            color: #764ba2;
            text-decoration: underline;
        }

        .breadcrumb-separator {
            color: #a0aec0;
            margin: 0 0.25rem;
        }

        .breadcrumb-current {
            color: #4a5568;
            font-weight: 500;
        }
    </style>

    <script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
    <script>
        mermaid.initialize({ startOnLoad: true, theme: 'default', securityLevel: 'strict' });
    </script>

    <!-- MathJax for LaTeX equation rendering -->
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\(', '\)']],
                displayMath: [['$$', '$$'], ['\[', '\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
                ignoreHtmlClass: 'mermaid'
            }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" async></script>
</head>
<body>
            <nav class="breadcrumb">
        <div class="breadcrumb-content">
            <a href="../../index.html">AIå¯ºå­å±‹ãƒˆãƒƒãƒ—</a><span class="breadcrumb-separator">â€º</span><a href="../../MI/index.html">ãƒãƒ†ãƒªã‚¢ãƒ«ã‚ºãƒ»ã‚¤ãƒ³ãƒ•ã‚©ãƒãƒ†ã‚£ã‚¯ã‚¹</a><span class="breadcrumb-separator">â€º</span><a href="../../MI/gnn-introduction/index.html">Gnn</a><span class="breadcrumb-separator">â€º</span><span class="breadcrumb-current">Chapter 2</span>
        </div>
    </nav>

        <header>
        <div class="header-content">
            <h1>ç¬¬2ç« ï¼šGNNã®åŸºç¤ç†è«–</h1>
            <p class="subtitle">ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ‘ãƒƒã‚·ãƒ³ã‚°ã‹ã‚‰ææ–™ç§‘å­¦ç‰¹åŒ–GNNã¾ã§</p>
            <div class="meta">
                <span class="meta-item">ğŸ“– èª­äº†æ™‚é–“: 25-30åˆ†</span>
                <span class="meta-item">ğŸ“Š é›£æ˜“åº¦: ä¸­ç´š</span>
                <span class="meta-item">ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹: 10å€‹</span>
                <span class="meta-item">ğŸ“ æ¼”ç¿’å•é¡Œ: 3å•</span>
            </div>
        </div>
    </header>

    <main class="container">
<h1>ç¬¬2ç« ï¼šGNNã®åŸºç¤ç†è«–</h1>
<p class="chapter-description" style="margin: 1.5rem 0; padding: 1rem; background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%); border-left: 4px solid #7b2cbf; border-radius: 8px; font-size: 1.05rem; line-height: 1.8; color: #2d3748;">ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ‘ãƒƒã‚·ãƒ³ã‚°ã®åŸºæœ¬æ©Ÿæ§‹ã‚’æ•°å¼æŠœãã§ã‚‚ã‚¤ãƒ¡ãƒ¼ã‚¸ã§ãã‚‹ã‚ˆã†ã«æ•´ç†ã—ã¾ã™ã€‚ä»£è¡¨ãƒ¢ãƒ‡ãƒ«ã®é•ã„ã¨ä½¿ã„åˆ†ã‘ã‚’æŠ¼ã•ãˆã¾ã™ã€‚</p>
<p class="chapter-supplement" style="margin: 0.75rem 0 1.5rem 0; padding: 0.75rem 1rem; background: linear-gradient(135deg, #fff8e1 0%, #fff3cd 100%); border-left: 3px solid #f59e0b; border-radius: 6px; font-size: 0.95rem; line-height: 1.7; color: #4a5568;"><strong>ğŸ’¡ è£œè¶³:</strong> ä¼ãˆã‚‹é‡ï¼ˆé‡ã¿ï¼‰ã¨å›æ•°ï¼ˆå±¤æ•°ï¼‰ã€å—ã‘å–ã‚Šæ–¹ï¼ˆé›†ç´„ï¼‰ã®ä¸‰ç‚¹ã‚’åˆ†ã‘ã¦è€ƒãˆã‚‹ã¨ç†è§£ãŒæ—©ã„ã§ã™ã€‚</p>





<p><strong>ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ‘ãƒƒã‚·ãƒ³ã‚°ã‹ã‚‰ææ–™ç§‘å­¦ç‰¹åŒ–GNNã¾ã§</strong></p>
<h2>å­¦ç¿’ç›®æ¨™</h2>
<p>ã“ã®ç« ã‚’èª­ã‚€ã“ã¨ã§ã€ä»¥ä¸‹ã‚’ç¿’å¾—ã§ãã¾ã™ï¼š</p>
<ul>
<li>âœ… ã‚°ãƒ©ãƒ•ã®æ•°å­¦çš„å®šç¾©ã¨è¡¨ç¾æ–¹æ³•ã‚’ç†è§£ã™ã‚‹</li>
<li>âœ… ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ‘ãƒƒã‚·ãƒ³ã‚°ã®3ã‚¹ãƒ†ãƒƒãƒ—ï¼ˆé›†ç´„â†’æ›´æ–°â†’å‡ºåŠ›ï¼‰ã‚’èª¬æ˜ã§ãã‚‹</li>
<li>âœ… GCNã€GATã€GraphSAGEã®åŸç†ã¨é•ã„ã‚’ç†è§£ã™ã‚‹</li>
<li>âœ… ææ–™ç§‘å­¦ç‰¹åŒ–GNNï¼ˆSchNetã€DimeNetï¼‰ã®ç‰¹å¾´ã‚’çŸ¥ã‚‹</li>
<li>âœ… ã‚·ãƒ³ãƒ—ãƒ«ãªGNNã‚’PyTorchã§å®Ÿè£…ã§ãã‚‹</li>
<li>âœ… ç­‰å¤‰GNNã®é‡è¦æ€§ã‚’ç†è§£ã™ã‚‹</li>
</ul>
<p><strong>èª­äº†æ™‚é–“</strong>: 25-30åˆ†
<strong>ã‚³ãƒ¼ãƒ‰ä¾‹</strong>: 10å€‹
<strong>æ¼”ç¿’å•é¡Œ</strong>: 3å•</p>
<hr />
<h2>2.1 ã‚°ãƒ©ãƒ•ã®æ•°å­¦çš„å®šç¾©</h2>
<h3>ã‚°ãƒ©ãƒ•ã®åŸºæœ¬è¦ç´ </h3>
<p><strong>å®šç¾©</strong>:</p>
<blockquote>
<p>ã‚°ãƒ©ãƒ• $G = (V, E)$ ã¯ã€é ‚ç‚¹é›†åˆ $V$ ã¨è¾ºé›†åˆ $E \subseteq V \times V$ ã‹ã‚‰ãªã‚‹ã€‚</p>
</blockquote>
<p><strong>è¨˜æ³•</strong>:
- $n = |V|$: é ‚ç‚¹æ•°
- $m = |E|$: è¾ºæ•°
- $\mathcal{N}(v)$: é ‚ç‚¹ $v$ ã®éš£æ¥é ‚ç‚¹é›†åˆ</p>
<hr />
<h3>éš£æ¥è¡Œåˆ—ï¼ˆAdjacency Matrixï¼‰</h3>
<p><strong>å®šç¾©</strong>:
$$
A \in {0, 1}^{n \times n}, \quad A_{ij} = \begin{cases}
1 &amp; \text{if } (v_i, v_j) \in E \
0 &amp; \text{otherwise}
\end{cases}
$$</p>
<p><strong>Pythonã§ã®å®Ÿè£…</strong>:</p>
<pre><code class="language-python">import numpy as np

# ä¾‹ï¼šä¸‰è§’å½¢ã‚°ãƒ©ãƒ•ï¼ˆ3é ‚ç‚¹ã€3è¾ºï¼‰
n = 3
A = np.array([
    [0, 1, 1],  # é ‚ç‚¹0: 1, 2ã«æ¥ç¶š
    [1, 0, 1],  # é ‚ç‚¹1: 0, 2ã«æ¥ç¶š
    [1, 1, 0]   # é ‚ç‚¹2: 0, 1ã«æ¥ç¶š
])

print(&quot;éš£æ¥è¡Œåˆ—:&quot;)
print(A)
print(f&quot;\né ‚ç‚¹æ•°: {n}&quot;)
print(f&quot;è¾ºæ•°: {A.sum() // 2}&quot;)  # ç„¡å‘ã‚°ãƒ©ãƒ•ã¯2ã§å‰²ã‚‹
</code></pre>
<p><strong>å‡ºåŠ›</strong>:</p>
<pre><code>éš£æ¥è¡Œåˆ—:
[[0 1 1]
 [1 0 1]
 [1 1 0]]

é ‚ç‚¹æ•°: 3
è¾ºæ•°: 3
</code></pre>
<hr />
<h3>æ¬¡æ•°è¡Œåˆ—ï¼ˆDegree Matrixï¼‰</h3>
<p><strong>å®šç¾©</strong>:
$$
D \in \mathbb{R}^{n \times n}, \quad D_{ii} = \sum_{j=1}^{n} A_{ij}
$$</p>
<p><strong>ç‰©ç†çš„æ„å‘³</strong>: å„é ‚ç‚¹ã®æ¥ç¶šæ•°ï¼ˆåŒ–å­¦ã§ã¯çµåˆæ•°ï¼‰</p>
<pre><code class="language-python"># æ¬¡æ•°è¡Œåˆ—
D = np.diag(A.sum(axis=1))
print(&quot;æ¬¡æ•°è¡Œåˆ—:&quot;)
print(D)
print(f&quot;\nå„é ‚ç‚¹ã®æ¬¡æ•°: {np.diag(D)}&quot;)
</code></pre>
<p><strong>å‡ºåŠ›</strong>:</p>
<pre><code>æ¬¡æ•°è¡Œåˆ—:
[[2 0 0]
 [0 2 0]
 [0 0 2]]

å„é ‚ç‚¹ã®æ¬¡æ•°: [2 2 2]
</code></pre>
<hr />
<h3>ãƒ©ãƒ—ãƒ©ã‚·ã‚¢ãƒ³è¡Œåˆ—ï¼ˆLaplacian Matrixï¼‰</h3>
<p><strong>å®šç¾©</strong>:
$$
L = D - A
$$</p>
<p><strong>æ­£è¦åŒ–ãƒ©ãƒ—ãƒ©ã‚·ã‚¢ãƒ³</strong>ï¼ˆGNNã§ã‚ˆãä½¿ç”¨ï¼‰:
$$
\tilde{L} = D^{-1/2} L D^{-1/2} = I - D^{-1/2} A D^{-1/2}
$$</p>
<pre><code class="language-python"># ãƒ©ãƒ—ãƒ©ã‚·ã‚¢ãƒ³è¡Œåˆ—
L = D - A
print(&quot;ãƒ©ãƒ—ãƒ©ã‚·ã‚¢ãƒ³è¡Œåˆ—:&quot;)
print(L)

# æ­£è¦åŒ–ãƒ©ãƒ—ãƒ©ã‚·ã‚¢ãƒ³
D_inv_sqrt = np.diag(1 / np.sqrt(np.diag(D)))
L_norm = np.eye(n) - D_inv_sqrt @ A @ D_inv_sqrt
print(&quot;\næ­£è¦åŒ–ãƒ©ãƒ—ãƒ©ã‚·ã‚¢ãƒ³:&quot;)
print(L_norm)
</code></pre>
<p><strong>å‡ºåŠ›</strong>:</p>
<pre><code>ãƒ©ãƒ—ãƒ©ã‚·ã‚¢ãƒ³è¡Œåˆ—:
[[ 2 -1 -1]
 [-1  2 -1]
 [-1 -1  2]]

æ­£è¦åŒ–ãƒ©ãƒ—ãƒ©ã‚·ã‚¢ãƒ³:
[[ 1.  -0.5 -0.5]
 [-0.5  1.  -0.5]
 [-0.5 -0.5  1. ]]
</code></pre>
<p><strong>ç”¨é€”</strong>:
- ã‚¹ãƒšã‚¯ãƒˆãƒ«ã‚°ãƒ©ãƒ•ç†è«–
- ã‚°ãƒ©ãƒ•ãƒ•ãƒ¼ãƒªã‚¨å¤‰æ›
- ã‚°ãƒ©ãƒ•ä¿¡å·å‡¦ç†</p>
<hr />
<h3>é ‚ç‚¹ç‰¹å¾´é‡ã¨è¾ºç‰¹å¾´é‡</h3>
<p><strong>é ‚ç‚¹ç‰¹å¾´è¡Œåˆ—</strong> $X \in \mathbb{R}^{n \times d}$:
- å„è¡Œ $x_i \in \mathbb{R}^d$: é ‚ç‚¹ $i$ ã®ç‰¹å¾´ãƒ™ã‚¯ãƒˆãƒ«
- ææ–™ç§‘å­¦: åŸå­ç•ªå·ã€é›»æ°—é™°æ€§åº¦ã€ä¾¡é›»å­æ•°ãªã©</p>
<p><strong>è¾ºç‰¹å¾´è¡Œåˆ—</strong> $E \in \mathbb{R}^{m \times d_e}$:
- å„è¡Œ $e_{ij} \in \mathbb{R}^{d_e}$: è¾º $(i, j)$ ã®ç‰¹å¾´
- ææ–™ç§‘å­¦: çµåˆé•·ã€çµåˆæ¬¡æ•°ã€çµåˆè§’ãªã©</p>
<pre><code class="language-python"># ä¾‹ï¼šæ°´åˆ†å­ï¼ˆHâ‚‚Oï¼‰ã®ç‰¹å¾´é‡
X = np.array([
    [8, 2.55, 6],   # O: åŸå­ç•ªå·8, é›»æ°—é™°æ€§åº¦2.55, ä¾¡é›»å­6
    [1, 2.20, 1],   # H1
    [1, 2.20, 1]    # H2
])

print(&quot;é ‚ç‚¹ç‰¹å¾´è¡Œåˆ— (3Ã—3):&quot;)
print(X)
print(f&quot;å½¢çŠ¶: {X.shape}&quot;)
</code></pre>
<hr />
<h2>2.2 ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ‘ãƒƒã‚·ãƒ³ã‚°ã®ä»•çµ„ã¿</h2>
<h3>Message Passing Neural Network (MPNN)</h3>
<p>GNNã®<strong>çµ±ä¸€ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯</strong>ã§ã™ï¼ˆGilmer et al., 2017ï¼‰ã€‚</p>
<p><strong>ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ </strong>:</p>
<div class="mermaid">
flowchart LR
    A[å…¥åŠ›: é ‚ç‚¹ç‰¹å¾´ X] --> B[ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç”Ÿæˆ]
    B --> C[ã‚¹ãƒ†ãƒƒãƒ—2: é›†ç´„ Aggregation]
    C --> D[ã‚¹ãƒ†ãƒƒãƒ—3: æ›´æ–° Update]
    D --> E{ç¹°ã‚Šè¿”ã—?}
    E -->|Yes| B
    E -->|No| F[å‡ºåŠ›: æ–°ã—ã„ç‰¹å¾´]

    style A fill:#e3f2fd
    style B fill:#fff3e0
    style C fill:#f3e5f5
    style D fill:#e8f5e9
    style F fill:#ffebee
</div>

<hr />
<h3>ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç”Ÿæˆï¼ˆMessageï¼‰</h3>
<p><strong>å®šç¾©</strong>:
$$
m_{ij}^{(t)} = \text{Message}(h_i^{(t)}, h_j^{(t)}, e_{ij})
$$</p>
<ul>
<li>$h_i^{(t)}$: ãƒ¬ã‚¤ãƒ¤ãƒ¼ $t$ ã§ã®é ‚ç‚¹ $i$ ã®éš ã‚ŒçŠ¶æ…‹</li>
<li>$h_j^{(t)}$: éš£æ¥é ‚ç‚¹ $j$ ã®éš ã‚ŒçŠ¶æ…‹</li>
<li>$e_{ij}$: è¾º $(i, j)$ ã®ç‰¹å¾´é‡</li>
</ul>
<p><strong>æœ€ã‚‚ã‚·ãƒ³ãƒ—ãƒ«ãªå½¢</strong>:
$$
m_{ij}^{(t)} = W \cdot h_j^{(t)}
$$</p>
<pre><code class="language-python">import torch
import torch.nn as nn

class MessageFunction(nn.Module):
    def __init__(self, in_dim, out_dim):
        super().__init__()
        self.W = nn.Linear(in_dim, out_dim)

    def forward(self, h_j):
        &quot;&quot;&quot;
        éš£æ¥é ‚ç‚¹ã‹ã‚‰ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç”Ÿæˆ

        Parameters:
        -----------
        h_j : Tensor (num_neighbors, in_dim)
            éš£æ¥é ‚ç‚¹ã®ç‰¹å¾´é‡

        Returns:
        --------
        messages : Tensor (num_neighbors, out_dim)
            ç”Ÿæˆã•ã‚ŒãŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        &quot;&quot;&quot;
        return self.W(h_j)

# ä¾‹
in_dim, out_dim = 16, 32
msg_fn = MessageFunction(in_dim, out_dim)

# éš£æ¥é ‚ç‚¹ã®ç‰¹å¾´ï¼ˆ3å€‹ã®éš£æ¥é ‚ç‚¹ï¼‰
h_neighbors = torch.randn(3, in_dim)
messages = msg_fn(h_neighbors)
print(f&quot;ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å½¢çŠ¶: {messages.shape}&quot;)
# å‡ºåŠ›: torch.Size([3, 32])
</code></pre>
<hr />
<h3>ã‚¹ãƒ†ãƒƒãƒ—2: é›†ç´„ï¼ˆAggregationï¼‰</h3>
<p><strong>å®šç¾©</strong>:
$$
m_i^{(t)} = \text{Aggregate}\left( {m_{ij}^{(t)} : j \in \mathcal{N}(i)} \right)
$$</p>
<p><strong>ä»£è¡¨çš„ãªé›†ç´„é–¢æ•°</strong>:</p>
<table>
<thead>
<tr>
<th>é›†ç´„æ–¹æ³•</th>
<th>æ•°å¼</th>
<th>ç‰¹å¾´</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Sum</strong></td>
<td>$\sum_{j \in \mathcal{N}(i)} m_{ij}^{(t)}$</td>
<td>é †åºä¸å¤‰ã€æ¬¡æ•°ã«æ•æ„Ÿ</td>
</tr>
<tr>
<td><strong>Mean</strong></td>
<td>$\frac{1}{</td>
<td>\mathcal{N}(i)</td>
</tr>
<tr>
<td><strong>Max</strong></td>
<td>$\max_{j \in \mathcal{N}(i)} m_{ij}^{(t)}$</td>
<td>æœ€ã‚‚å¼·ã„ç‰¹å¾´ã‚’ä¿æŒ</td>
</tr>
<tr>
<td><strong>Attention</strong></td>
<td>$\sum_{j \in \mathcal{N}(i)} \alpha_{ij} m_{ij}^{(t)}$</td>
<td>é‡è¦åº¦ã§é‡ã¿ä»˜ã‘</td>
</tr>
</tbody>
</table>
<pre><code class="language-python">class AggregationFunction:
    @staticmethod
    def sum_agg(messages):
        &quot;&quot;&quot;Sum aggregation&quot;&quot;&quot;
        return torch.sum(messages, dim=0)

    @staticmethod
    def mean_agg(messages):
        &quot;&quot;&quot;Mean aggregation&quot;&quot;&quot;
        return torch.mean(messages, dim=0)

    @staticmethod
    def max_agg(messages):
        &quot;&quot;&quot;Max aggregation&quot;&quot;&quot;
        return torch.max(messages, dim=0)[0]

# ä¾‹
messages = torch.tensor([
    [1.0, 2.0, 3.0],
    [4.0, 5.0, 6.0],
    [7.0, 8.0, 9.0]
])

print(&quot;Sum:&quot;, AggregationFunction.sum_agg(messages))
# å‡ºåŠ›: tensor([12., 15., 18.])

print(&quot;Mean:&quot;, AggregationFunction.mean_agg(messages))
# å‡ºåŠ›: tensor([4., 5., 6.])

print(&quot;Max:&quot;, AggregationFunction.max_agg(messages))
# å‡ºåŠ›: tensor([7., 8., 9.])
</code></pre>
<hr />
<h3>ã‚¹ãƒ†ãƒƒãƒ—3: æ›´æ–°ï¼ˆUpdateï¼‰</h3>
<p><strong>å®šç¾©</strong>:
$$
h_i^{(t+1)} = \text{Update}\left( h_i^{(t)}, m_i^{(t)} \right)
$$</p>
<p><strong>å…¸å‹çš„ãªæ›´æ–°å¼</strong>:
$$
h_i^{(t+1)} = \sigma\left( W_1 h_i^{(t)} + W_2 m_i^{(t)} \right)
$$</p>
<pre><code class="language-python">class UpdateFunction(nn.Module):
    def __init__(self, hidden_dim):
        super().__init__()
        self.W1 = nn.Linear(hidden_dim, hidden_dim)
        self.W2 = nn.Linear(hidden_dim, hidden_dim)
        self.activation = nn.ReLU()

    def forward(self, h_i, m_i):
        &quot;&quot;&quot;
        é ‚ç‚¹ç‰¹å¾´ã‚’æ›´æ–°

        Parameters:
        -----------
        h_i : Tensor (hidden_dim,)
            ç¾åœ¨ã®é ‚ç‚¹ç‰¹å¾´
        m_i : Tensor (hidden_dim,)
            é›†ç´„ã•ã‚ŒãŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸

        Returns:
        --------
        h_new : Tensor (hidden_dim,)
            æ›´æ–°ã•ã‚ŒãŸé ‚ç‚¹ç‰¹å¾´
        &quot;&quot;&quot;
        return self.activation(self.W1(h_i) + self.W2(m_i))

# ä¾‹
hidden_dim = 32
update_fn = UpdateFunction(hidden_dim)

h_current = torch.randn(hidden_dim)
m_aggregated = torch.randn(hidden_dim)
h_new = update_fn(h_current, m_aggregated)

print(f&quot;æ›´æ–°å‰: {h_current[:5]}&quot;)
print(f&quot;æ›´æ–°å¾Œ: {h_new[:5]}&quot;)
</code></pre>
<hr />
<h3>ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ‘ãƒƒã‚·ãƒ³ã‚°ã®å…¨ä½“åƒ</h3>
<pre><code class="language-python">class SimpleGNN(nn.Module):
    def __init__(self, in_dim, hidden_dim, num_layers):
        super().__init__()
        self.num_layers = num_layers

        # å„ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.message_fns = nn.ModuleList([
            MessageFunction(hidden_dim, hidden_dim)
            for _ in range(num_layers)
        ])
        self.update_fns = nn.ModuleList([
            UpdateFunction(hidden_dim)
            for _ in range(num_layers)
        ])

        # å…¥åŠ›å¤‰æ›
        self.input_proj = nn.Linear(in_dim, hidden_dim)

    def forward(self, x, edge_index):
        &quot;&quot;&quot;
        Parameters:
        -----------
        x : Tensor (num_nodes, in_dim)
            é ‚ç‚¹ç‰¹å¾´è¡Œåˆ—
        edge_index : Tensor (2, num_edges)
            è¾ºã®ãƒªã‚¹ãƒˆ [[src], [dst]]

        Returns:
        --------
        h : Tensor (num_nodes, hidden_dim)
            æ›´æ–°ã•ã‚ŒãŸé ‚ç‚¹ç‰¹å¾´
        &quot;&quot;&quot;
        # å…¥åŠ›å¤‰æ›
        h = self.input_proj(x)

        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ‘ãƒƒã‚·ãƒ³ã‚°ã®ãƒ¬ã‚¤ãƒ¤ãƒ¼
        for layer in range(self.num_layers):
            h_new = []

            # å„é ‚ç‚¹ã‚’æ›´æ–°
            for i in range(x.size(0)):
                # éš£æ¥é ‚ç‚¹ã‚’å–å¾—
                neighbors = edge_index[1][edge_index[0] == i]

                if len(neighbors) &gt; 0:
                    # ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç”Ÿæˆ
                    messages = self.message_fns[layer](h[neighbors])

                    # ã‚¹ãƒ†ãƒƒãƒ—2: é›†ç´„
                    m_i = torch.mean(messages, dim=0)

                    # ã‚¹ãƒ†ãƒƒãƒ—3: æ›´æ–°
                    h_i_new = self.update_fns[layer](h[i], m_i)
                else:
                    # éš£æ¥é ‚ç‚¹ãŒãªã„å ´åˆ
                    h_i_new = h[i]

                h_new.append(h_i_new)

            h = torch.stack(h_new)

        return h

# ä½¿ç”¨ä¾‹
model = SimpleGNN(in_dim=16, hidden_dim=32, num_layers=3)

# ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ï¼ˆä¸‰è§’å½¢ï¼‰
x = torch.randn(3, 16)  # 3é ‚ç‚¹ã€16æ¬¡å…ƒç‰¹å¾´
edge_index = torch.tensor([
    [0, 0, 1, 1, 2, 2],  # å§‹ç‚¹
    [1, 2, 0, 2, 0, 1]   # çµ‚ç‚¹
])

# é †ä¼æ’­
h_out = model(x, edge_index)
print(f&quot;å‡ºåŠ›å½¢çŠ¶: {h_out.shape}&quot;)
# å‡ºåŠ›: torch.Size([3, 32])
</code></pre>
<hr />
<h2>2.3 ä»£è¡¨çš„ãªGNNã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£</h2>
<h3>Graph Convolutional Network (GCN)</h3>
<p><strong>è«–æ–‡</strong>: Kipf &amp; Welling (2017), <em>ICLR</em></p>
<p><strong>æ ¸å¿ƒã‚¢ã‚¤ãƒ‡ã‚¢</strong>: ã‚°ãƒ©ãƒ•ã®ã‚¹ãƒšã‚¯ãƒˆãƒ«ç•³ã¿è¾¼ã¿</p>
<p><strong>æ›´æ–°å¼</strong>:
$$
H^{(l+1)} = \sigma\left( \tilde{D}^{-1/2} \tilde{A} \tilde{D}^{-1/2} H^{(l)} W^{(l)} \right)
$$</p>
<ul>
<li>$\tilde{A} = A + I$: è‡ªå·±ãƒ«ãƒ¼ãƒ—ä»˜ãéš£æ¥è¡Œåˆ—</li>
<li>$\tilde{D}_{ii} = \sum_j \tilde{A}_{ij}$: æ¬¡æ•°è¡Œåˆ—</li>
<li>$H^{(l)} \in \mathbb{R}^{n \times d}$: ãƒ¬ã‚¤ãƒ¤ãƒ¼ $l$ ã®ç‰¹å¾´é‡</li>
<li>$W^{(l)} \in \mathbb{R}^{d \times d'}$: å­¦ç¿’å¯èƒ½ãªé‡ã¿</li>
</ul>
<p><strong>Pythonã§ã®å®Ÿè£…</strong>:</p>
<pre><code class="language-python">import torch
import torch.nn as nn
import torch.nn.functional as F

class GCNLayer(nn.Module):
    def __init__(self, in_features, out_features):
        super().__init__()
        self.linear = nn.Linear(in_features, out_features)

    def forward(self, X, A):
        &quot;&quot;&quot;
        Parameters:
        -----------
        X : Tensor (num_nodes, in_features)
            é ‚ç‚¹ç‰¹å¾´è¡Œåˆ—
        A : Tensor (num_nodes, num_nodes)
            éš£æ¥è¡Œåˆ—

        Returns:
        --------
        H : Tensor (num_nodes, out_features)
            æ›´æ–°ã•ã‚ŒãŸç‰¹å¾´é‡
        &quot;&quot;&quot;
        # è‡ªå·±ãƒ«ãƒ¼ãƒ—ã®è¿½åŠ 
        A_tilde = A + torch.eye(A.size(0), device=A.device)

        # æ¬¡æ•°è¡Œåˆ—
        D_tilde = torch.diag(A_tilde.sum(dim=1))

        # æ­£è¦åŒ–: D^(-1/2) * A * D^(-1/2)
        D_inv_sqrt = torch.diag(1.0 / torch.sqrt(D_tilde.diagonal()))
        A_norm = D_inv_sqrt @ A_tilde @ D_inv_sqrt

        # ã‚°ãƒ©ãƒ•ç•³ã¿è¾¼ã¿
        H = A_norm @ X
        H = self.linear(H)
        return F.relu(H)

# ä½¿ç”¨ä¾‹
gcn = GCNLayer(in_features=16, out_features=32)

# ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿
X = torch.randn(5, 16)  # 5é ‚ç‚¹ã€16æ¬¡å…ƒ
A = torch.tensor([
    [0, 1, 1, 0, 0],
    [1, 0, 1, 1, 0],
    [1, 1, 0, 1, 1],
    [0, 1, 1, 0, 1],
    [0, 0, 1, 1, 0]
], dtype=torch.float32)

H = gcn(X, A)
print(f&quot;GCNå‡ºåŠ›å½¢çŠ¶: {H.shape}&quot;)
# å‡ºåŠ›: torch.Size([5, 32])
</code></pre>
<p><strong>ç‰¹å¾´</strong>:
- âœ… ã‚·ãƒ³ãƒ—ãƒ«ã§é«˜é€Ÿ
- âœ… éå‰°å¹³æ»‘åŒ–ï¼ˆover-smoothingï¼‰ã«æ³¨æ„
- âœ… å›ºå®šçš„ãªé‡ã¿ï¼ˆå…¨éš£æ¥é ‚ç‚¹ãŒåŒã˜æ‰±ã„ï¼‰</p>
<hr />
<h3>Graph Attention Network (GAT)</h3>
<p><strong>è«–æ–‡</strong>: VeliÄkoviÄ‡ et al. (2018), <em>ICLR</em></p>
<p><strong>æ ¸å¿ƒã‚¢ã‚¤ãƒ‡ã‚¢</strong>: Attentionã§é‡è¦ãªéš£æ¥é ‚ç‚¹ã‚’é‡è¦–</p>
<p><strong>Attentionä¿‚æ•°</strong>:
$$
\alpha_{ij} = \frac{\exp\left( \text{LeakyReLU}(a^T [W h_i | W h_j]) \right)}
{\sum_{k \in \mathcal{N}(i)} \exp\left( \text{LeakyReLU}(a^T [W h_i | W h_k]) \right)}
$$</p>
<p><strong>æ›´æ–°å¼</strong>:
$$
h_i^{(l+1)} = \sigma\left( \sum_{j \in \mathcal{N}(i)} \alpha_{ij} W^{(l)} h_j^{(l)} \right)
$$</p>
<pre><code class="language-python">class GATLayer(nn.Module):
    def __init__(self, in_features, out_features, dropout=0.6,
                 alpha=0.2):
        super().__init__()
        self.W = nn.Linear(in_features, out_features, bias=False)
        self.a = nn.Parameter(torch.zeros(2 * out_features, 1))
        self.leakyrelu = nn.LeakyReLU(alpha)
        self.dropout = nn.Dropout(dropout)

        nn.init.xavier_uniform_(self.a.data, gain=1.414)

    def forward(self, X, A):
        &quot;&quot;&quot;
        Parameters:
        -----------
        X : Tensor (num_nodes, in_features)
        A : Tensor (num_nodes, num_nodes)

        Returns:
        --------
        H : Tensor (num_nodes, out_features)
        &quot;&quot;&quot;
        # ç·šå½¢å¤‰æ›
        Wh = self.W(X)  # (N, out_features)
        N = Wh.size(0)

        # Attentionè¨ˆç®—
        # [Wh_i || Wh_j] for all edges
        Wh_repeat_interleave = Wh.repeat_interleave(N, dim=0)
        Wh_repeat = Wh.repeat(N, 1)
        concat = torch.cat([Wh_repeat_interleave, Wh_repeat], dim=1)
        concat = concat.view(N, N, -1)

        # Attention score
        e = self.leakyrelu(concat @ self.a).squeeze(2)

        # ãƒã‚¹ã‚¯ï¼ˆè¾ºãŒãªã„å ´åˆã¯-infï¼‰
        zero_vec = -9e15 * torch.ones_like(e)
        attention = torch.where(A &gt; 0, e, zero_vec)

        # Softmax
        attention = F.softmax(attention, dim=1)
        attention = self.dropout(attention)

        # Weighted sum
        H = torch.matmul(attention, Wh)
        return F.elu(H)

# ä½¿ç”¨ä¾‹
gat = GATLayer(in_features=16, out_features=32)
H_gat = gat(X, A)
print(f&quot;GATå‡ºåŠ›å½¢çŠ¶: {H_gat.shape}&quot;)
# å‡ºåŠ›: torch.Size([5, 32])
</code></pre>
<p><strong>ç‰¹å¾´</strong>:
- âœ… å‹•çš„ãªé‡ã¿ï¼ˆé‡è¦ãªéš£æ¥é ‚ç‚¹ã‚’è‡ªå‹•å­¦ç¿’ï¼‰
- âœ… è§£é‡ˆå¯èƒ½æ€§ï¼ˆAttentionä¿‚æ•°ã®å¯è¦–åŒ–ï¼‰
- âŒ è¨ˆç®—ã‚³ã‚¹ãƒˆãŒé«˜ã„ï¼ˆGCNã®ç´„2å€ï¼‰</p>
<hr />
<h3>GraphSAGEï¼ˆSAmple and aggreGatEï¼‰</h3>
<p><strong>è«–æ–‡</strong>: Hamilton et al. (2017), <em>NeurIPS</em></p>
<p><strong>æ ¸å¿ƒã‚¢ã‚¤ãƒ‡ã‚¢</strong>: ãƒŸãƒ‹ãƒãƒƒãƒå­¦ç¿’ã®ãŸã‚ã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°</p>
<p><strong>æ›´æ–°å¼</strong>:
$$
h_i^{(l+1)} = \sigma\left( W \cdot \text{Concat}\left( h_i^{(l)}, \text{Aggregate}({h_j^{(l)} : j \in \mathcal{S}(i)}) \right) \right)
$$</p>
<ul>
<li>$\mathcal{S}(i)$: ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã•ã‚ŒãŸéš£æ¥é ‚ç‚¹ï¼ˆå…¨ã¦ã§ã¯ãªã„ï¼‰</li>
</ul>
<pre><code class="language-python">class GraphSAGELayer(nn.Module):
    def __init__(self, in_features, out_features, num_samples=10):
        super().__init__()
        self.num_samples = num_samples
        # Concatç‰ˆ: å…¥åŠ›ã¯ in_features * 2
        self.linear = nn.Linear(in_features * 2, out_features)

    def forward(self, X, A):
        &quot;&quot;&quot;
        Parameters:
        -----------
        X : Tensor (num_nodes, in_features)
        A : Tensor (num_nodes, num_nodes)

        Returns:
        --------
        H : Tensor (num_nodes, out_features)
        &quot;&quot;&quot;
        N = X.size(0)
        H_new = []

        for i in range(N):
            # éš£æ¥é ‚ç‚¹ã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
            neighbors = torch.nonzero(A[i]).squeeze()
            if neighbors.numel() &gt; self.num_samples:
                # ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
                perm = torch.randperm(neighbors.numel())
                sampled = neighbors[perm[:self.num_samples]]
            else:
                sampled = neighbors

            # é›†ç´„ï¼ˆMeanï¼‰
            if sampled.numel() &gt; 0:
                h_neighbors = X[sampled]
                h_agg = torch.mean(h_neighbors, dim=0)
            else:
                h_agg = torch.zeros_like(X[i])

            # Concat
            h_concat = torch.cat([X[i], h_agg], dim=0)

            # ç·šå½¢å¤‰æ›
            h_new = self.linear(h_concat)
            H_new.append(h_new)

        H = torch.stack(H_new)
        return F.relu(H)

# ä½¿ç”¨ä¾‹
sage = GraphSAGELayer(in_features=16, out_features=32,
                      num_samples=3)
H_sage = sage(X, A)
print(f&quot;GraphSAGEå‡ºåŠ›å½¢çŠ¶: {H_sage.shape}&quot;)
# å‡ºåŠ›: torch.Size([5, 32])
</code></pre>
<p><strong>ç‰¹å¾´</strong>:
- âœ… ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ï¼ˆå¤§è¦æ¨¡ã‚°ãƒ©ãƒ•ã«å¯¾å¿œï¼‰
- âœ… ãƒŸãƒ‹ãƒãƒƒãƒè¨“ç·´ãŒå¯èƒ½
- âœ… å¸°ç´çš„å­¦ç¿’ï¼ˆæ–°ã—ã„é ‚ç‚¹ã¸ã®æ±åŒ–ï¼‰</p>
<hr />
<h3>3ã¤ã®GNNã®æ¯”è¼ƒ</h3>
<div class="mermaid">
flowchart TD
    A[GNNé¸æŠ] --> B{ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º}
    B -->|å°è¦æ¨¡\n10ké ‚ç‚¹| C[GCN]
    B -->|ä¸­è¦æ¨¡\n10k-100k| D[GAT]
    B -->|å¤§è¦æ¨¡\n100k+| E[GraphSAGE]

    C --> F[ã‚·ãƒ³ãƒ—ãƒ«ã€é«˜é€Ÿ]
    D --> G[é«˜ç²¾åº¦ã€è§£é‡ˆæ€§]
    E --> H[ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«]

    style A fill:#e3f2fd
    style C fill:#fff3e0
    style D fill:#f3e5f5
    style E fill:#e8f5e9
</div>

<table>
<thead>
<tr>
<th>æ‰‹æ³•</th>
<th>è¨ˆç®—é‡</th>
<th>ç²¾åº¦</th>
<th>ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£</th>
<th>è§£é‡ˆæ€§</th>
<th>æ¨å¥¨ç”¨é€”</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>GCN</strong></td>
<td>$O(m \cdot d^2)$</td>
<td>ä¸­</td>
<td>ä½</td>
<td>ä¸­</td>
<td>å°è¦æ¨¡ã€ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ”ãƒ³ã‚°</td>
</tr>
<tr>
<td><strong>GAT</strong></td>
<td>$O(m \cdot d^2 + n \cdot d)$</td>
<td>é«˜</td>
<td>ä¸­</td>
<td>é«˜</td>
<td>ä¸­è¦æ¨¡ã€é«˜ç²¾åº¦è¦æ±‚</td>
</tr>
<tr>
<td><strong>GraphSAGE</strong></td>
<td>$O(k \cdot s \cdot d^2)$</td>
<td>ä¸­ã€œé«˜</td>
<td>é«˜</td>
<td>ä¸­</td>
<td>å¤§è¦æ¨¡ã€å®Ÿæ™‚é–“äºˆæ¸¬</td>
</tr>
</tbody>
</table>
<ul>
<li>$m$: è¾ºæ•°</li>
<li>$n$: é ‚ç‚¹æ•°</li>
<li>$d$: ç‰¹å¾´æ¬¡å…ƒ</li>
<li>$k$: ãƒ¬ã‚¤ãƒ¤ãƒ¼æ•°</li>
<li>$s$: ã‚µãƒ³ãƒ—ãƒ«æ•°</li>
</ul>
<hr />
<h2>2.4 ææ–™ç§‘å­¦ç‰¹åŒ–GNN</h2>
<h3>SchNetï¼ˆContinuous-filter Convolutional NNï¼‰</h3>
<p><strong>è«–æ–‡</strong>: SchÃ¼tt et al. (2017), <em>NeurIPS</em></p>
<p><strong>å¯¾è±¡</strong>: åˆ†å­ãƒ»ææ–™ã®<strong>é‡å­åŒ–å­¦ç‰¹æ€§</strong>äºˆæ¸¬</p>
<p><strong>æ ¸å¿ƒã‚¢ã‚¤ãƒ‡ã‚¢</strong>:
1. <strong>é€£ç¶šãƒ•ã‚£ãƒ«ã‚¿</strong>: é›¢æ•£ã‚°ãƒ©ãƒ•ã§ã¯ãªã3Dç©ºé–“ã§ã®ç•³ã¿è¾¼ã¿
2. <strong>è·é›¢ä¾å­˜</strong>: åŸå­é–“è·é›¢ã‚’æ˜ç¤ºçš„ã«ãƒ¢ãƒ‡ãƒ«åŒ–</p>
<p><strong>ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£</strong>:</p>
<div class="mermaid">
flowchart LR
    A[åŸå­ç‰¹å¾´] --> B[åŸ‹ã‚è¾¼ã¿å±¤]
    B --> C[ç›¸äº’ä½œç”¨ãƒ–ãƒ­ãƒƒã‚¯ 1]
    C --> D[ç›¸äº’ä½œç”¨ãƒ–ãƒ­ãƒƒã‚¯ 2]
    D --> E[ç›¸äº’ä½œç”¨ãƒ–ãƒ­ãƒƒã‚¯ 3]
    E --> F[å‡ºåŠ›å±¤]

    G[åŸå­é–“è·é›¢] --> C
    G --> D
    G --> E

    style A fill:#e3f2fd
    style B fill:#fff3e0
    style C fill:#f3e5f5
    style D fill:#e8f5e9
    style E fill:#ffebee
    style F fill:#fff9c4
    style G fill:#e1bee7
</div>

<p><strong>æ•°å¼</strong>:
$$
h_i^{(l+1)} = h_i^{(l)} + \sum_{j \in \mathcal{N}(i)} h_j^{(l)} \odot \phi\left( |r_i - r_j| \right)
$$</p>
<ul>
<li>$\phi(d)$: <strong>é€£ç¶šãƒ•ã‚£ãƒ«ã‚¿é–¢æ•°</strong>ï¼ˆè·é›¢ $d$ ã«ä¾å­˜ï¼‰</li>
<li>$r_i, r_j$: åŸå­ã®3Dåº§æ¨™</li>
</ul>
<p><strong>ãƒ•ã‚£ãƒ«ã‚¿é–¢æ•°</strong>:
$$
\phi(d) = \sum_{k=1}^{K} w_k \exp\left( -\gamma (d - \mu_k)^2 \right)
$$</p>
<ul>
<li>ã‚¬ã‚¦ã‚¹åŸºåº•å±•é–‹ï¼ˆRBF: Radial Basis Functionï¼‰</li>
</ul>
<pre><code class="language-python">import torch
import torch.nn as nn

class GaussianBasis(nn.Module):
    def __init__(self, start=0.0, stop=5.0, num_gaussians=50):
        super().__init__()
        self.mu = nn.Parameter(
            torch.linspace(start, stop, num_gaussians),
            requires_grad=False
        )
        self.gamma = nn.Parameter(
            torch.tensor(10.0),
            requires_grad=True
        )

    def forward(self, distances):
        &quot;&quot;&quot;
        Parameters:
        -----------
        distances : Tensor (num_edges,)
            åŸå­é–“è·é›¢

        Returns:
        --------
        rbf : Tensor (num_edges, num_gaussians)
            ã‚¬ã‚¦ã‚¹åŸºåº•å±•é–‹
        &quot;&quot;&quot;
        # (num_edges, 1) - (1, num_gaussians)
        diff = distances.unsqueeze(-1) - self.mu.unsqueeze(0)
        rbf = torch.exp(-self.gamma * diff ** 2)
        return rbf

class SchNetInteraction(nn.Module):
    def __init__(self, hidden_dim, num_gaussians):
        super().__init__()
        self.rbf_layer = GaussianBasis(num_gaussians=num_gaussians)
        self.filter_net = nn.Sequential(
            nn.Linear(num_gaussians, hidden_dim),
            nn.Softplus(),
            nn.Linear(hidden_dim, hidden_dim)
        )
        self.linear = nn.Linear(hidden_dim, hidden_dim)

    def forward(self, h, edge_index, distances):
        &quot;&quot;&quot;
        Parameters:
        -----------
        h : Tensor (num_atoms, hidden_dim)
            åŸå­ç‰¹å¾´
        edge_index : Tensor (2, num_edges)
            è¾ºã®ãƒªã‚¹ãƒˆ
        distances : Tensor (num_edges,)
            åŸå­é–“è·é›¢

        Returns:
        --------
        h_new : Tensor (num_atoms, hidden_dim)
            æ›´æ–°ã•ã‚ŒãŸç‰¹å¾´
        &quot;&quot;&quot;
        # RBFå±•é–‹
        rbf = self.rbf_layer(distances)

        # ãƒ•ã‚£ãƒ«ã‚¿ç”Ÿæˆ
        W = self.filter_net(rbf)

        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ‘ãƒƒã‚·ãƒ³ã‚°
        src, dst = edge_index
        messages = h[dst] * W  # è¦ç´ ç©

        # é›†ç´„
        h_agg = torch.zeros_like(h)
        h_agg.index_add_(0, src, messages)

        # æ›´æ–°
        h_new = h + self.linear(h_agg)
        return h_new

# ä½¿ç”¨ä¾‹
schnet_layer = SchNetInteraction(hidden_dim=128,
                                 num_gaussians=50)

# ãƒ‡ãƒ¼ã‚¿
num_atoms = 5
h = torch.randn(num_atoms, 128)
edge_index = torch.tensor([[0, 1, 2, 3], [1, 2, 3, 4]])
distances = torch.tensor([1.5, 1.8, 2.0, 1.6])

h_new = schnet_layer(h, edge_index, distances)
print(f&quot;SchNetå‡ºåŠ›å½¢çŠ¶: {h_new.shape}&quot;)
# å‡ºåŠ›: torch.Size([5, 128])
</code></pre>
<p><strong>é©ç”¨ä¾‹</strong>:
- QM9ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆåˆ†å­ç‰¹æ€§äºˆæ¸¬ï¼‰
- MD17ï¼ˆåˆ†å­å‹•åŠ›å­¦ï¼‰
- OC20ï¼ˆè§¦åª’å¸ç€ã‚¨ãƒãƒ«ã‚®ãƒ¼ï¼‰</p>
<p><strong>æ€§èƒ½</strong>:</p>
<pre><code>QM9 HOMO-LUMO gap:
- DFTè¨ˆç®—: 24æ™‚é–“/åˆ†å­
- SchNet: 0.01ç§’/åˆ†å­ï¼ˆMAE=0.04 eVï¼‰
</code></pre>
<hr />
<h3>DimeNetï¼ˆDirectional Message Passing NNï¼‰</h3>
<p><strong>è«–æ–‡</strong>: Klicpera et al. (2020), <em>ICLR</em></p>
<p><strong>æ‹¡å¼µ</strong>: <strong>çµåˆè§’</strong>ã‚‚è€ƒæ…®</p>
<p><strong>æ ¸å¿ƒã‚¢ã‚¤ãƒ‡ã‚¢</strong>:
- è·é›¢ã ã‘ã§ãªã<strong>è§’åº¦æƒ…å ±</strong>ã‚‚åˆ©ç”¨
- 3ä½“ç›¸äº’ä½œç”¨ï¼ˆtriplet interactionï¼‰</p>
<p><strong>æ›´æ–°å¼</strong>:
$$
m_{ij} = \sum_{k \in \mathcal{N}(j) \setminus {i}} W\left( d_{ij}, d_{jk}, \theta_{ijk} \right) h_k
$$</p>
<ul>
<li>$\theta_{ijk}$: è§’åº¦ $\angle i-j-k$</li>
</ul>
<div class="mermaid">
flowchart TD
    A[åŸå­ i] --|d_ij| B[åŸå­ j]
    B --|d_jk| C[åŸå­ k]
    A - è§’åº¦Î¸_ijk .-> C

    style A fill:#e3f2fd
    style B fill:#fff3e0
    style C fill:#f3e5f5
</div>

<p><strong>è§’åº¦ã®è¨ˆç®—</strong>:</p>
<pre><code class="language-python">import torch

def compute_angle(pos_i, pos_j, pos_k):
    &quot;&quot;&quot;
    3åŸå­é–“ã®è§’åº¦ã‚’è¨ˆç®—

    Parameters:
    -----------
    pos_i, pos_j, pos_k : Tensor (3,)
        åŸå­ã®3Dåº§æ¨™

    Returns:
    --------
    angle : Tensor (1,)
        è§’åº¦ï¼ˆãƒ©ã‚¸ã‚¢ãƒ³ï¼‰
    &quot;&quot;&quot;
    # ãƒ™ã‚¯ãƒˆãƒ«
    v_ij = pos_j - pos_i
    v_jk = pos_k - pos_j

    # å†…ç©
    cos_angle = torch.dot(v_ij, v_jk) / (
        torch.norm(v_ij) * torch.norm(v_jk) + 1e-8
    )

    # è§’åº¦
    angle = torch.acos(torch.clamp(cos_angle, -1.0, 1.0))
    return angle

# ä¾‹ï¼šæ°´åˆ†å­ã®çµåˆè§’ï¼ˆH-O-Hï¼‰
pos_O = torch.tensor([0.0, 0.0, 0.0])
pos_H1 = torch.tensor([0.96, 0.0, 0.0])
pos_H2 = torch.tensor([0.24, 0.93, 0.0])

angle = compute_angle(pos_H1, pos_O, pos_H2)
print(f&quot;H-O-Hè§’åº¦: {torch.rad2deg(angle):.1f}Â°&quot;)
# å‡ºåŠ›: 104.5Â°ï¼ˆå®Ÿæ¸¬å€¤ã¨ã»ã¼ä¸€è‡´ï¼‰
</code></pre>
<p><strong>æ€§èƒ½</strong>:</p>
<pre><code>QM9ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ:
- SchNet: MAE=0.041 eV
- DimeNet: MAE=0.033 eVï¼ˆ20%æ”¹å–„ï¼‰

è¨ˆç®—æ™‚é–“:
- SchNet: 0.01ç§’/åˆ†å­
- DimeNet: 0.05ç§’/åˆ†å­ï¼ˆ5å€é…ã„ï¼‰
</code></pre>
<hr />
<h3>GemNetï¼ˆGeometric Message Passing NNï¼‰</h3>
<p><strong>è«–æ–‡</strong>: Gasteiger et al. (2021), <em>NeurIPS</em></p>
<p><strong>ã•ã‚‰ãªã‚‹æ‹¡å¼µ</strong>: <strong>4ä½“ç›¸äº’ä½œç”¨</strong>ï¼ˆäºŒé¢è§’ï¼‰</p>
<p><strong>å¯¾è±¡</strong>: çµæ™¶æ§‹é€ ã€è¤‡é›‘ãªåˆ†å­</p>
<p><strong>æ ¸å¿ƒã‚¢ã‚¤ãƒ‡ã‚¢</strong>:
- äºŒé¢è§’ï¼ˆtorsion angleï¼‰ã®è€ƒæ…®
- ã‚ˆã‚Šé«˜æ¬¡ã®å¹¾ä½•å­¦çš„æƒ…å ±</p>
<div class="mermaid">
flowchart LR
    A[åŸå­ i] --- B[åŸå­ j]
    B --- C[åŸå­ k]
    C --- D[åŸå­ l]

    A - äºŒé¢è§’Ï† .-> D

    style A fill:#e3f2fd
    style B fill:#fff3e0
    style C fill:#f3e5f5
    style D fill:#e8f5e9
</div>

<p><strong>æ€§èƒ½</strong>:</p>
<pre><code>OC20ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆè§¦åª’ï¼‰:
- SchNet: MAE=0.61 eV
- DimeNet++: MAE=0.49 eV
- GemNet: MAE=0.43 eVï¼ˆæœ€é«˜ç²¾åº¦ï¼‰
</code></pre>
<hr />
<h3>ææ–™ç§‘å­¦GNNã®æ¯”è¼ƒ</h3>
<table>
<thead>
<tr>
<th>æ‰‹æ³•</th>
<th>è€ƒæ…®ã™ã‚‹æƒ…å ±</th>
<th>ç²¾åº¦</th>
<th>é€Ÿåº¦</th>
<th>æ¨å¥¨ç”¨é€”</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>SchNet</strong></td>
<td>è·é›¢</td>
<td>ä¸­</td>
<td>é€Ÿã„</td>
<td>åˆ†å­ç‰¹æ€§äºˆæ¸¬</td>
</tr>
<tr>
<td><strong>DimeNet</strong></td>
<td>è·é›¢ + è§’åº¦</td>
<td>é«˜</td>
<td>ä¸­</td>
<td>è§¦åª’ã€è¤‡é›‘ãªåˆ†å­</td>
</tr>
<tr>
<td><strong>GemNet</strong></td>
<td>è·é›¢ + è§’åº¦ + äºŒé¢è§’</td>
<td>æœ€é«˜</td>
<td>é…ã„</td>
<td>çµæ™¶ã€é«˜ç²¾åº¦è¦æ±‚</td>
</tr>
</tbody>
</table>
<hr />
<h2>2.5 ç­‰å¤‰æ€§ï¼ˆEquivarianceï¼‰ã®é‡è¦æ€§</h2>
<h3>ç­‰å¤‰æ€§ã¨ã¯</h3>
<p><strong>å®šç¾©</strong>:</p>
<blockquote>
<p>é–¢æ•° $f$ ãŒå¤‰æ› $T$ ã«å¯¾ã—ã¦<strong>ç­‰å¤‰</strong>ï¼ˆequivariantï¼‰ã§ã‚ã‚‹ã¨ã¯ã€
$$f(T(x)) = T(f(x))$$
ãŒæˆã‚Šç«‹ã¤ã“ã¨ã€‚</p>
</blockquote>
<p><strong>ææ–™ç§‘å­¦ã§ã®æ„å‘³</strong>:
- åˆ†å­ã‚’å›è»¢ãƒ»ä¸¦é€²ã—ã¦ã‚‚ã€äºˆæ¸¬ã¯åŒã˜ï¼ˆã¾ãŸã¯å¯¾å¿œã™ã‚‹å¤‰æ›ï¼‰</p>
<hr />
<h3>E(3)ç­‰å¤‰æ€§</h3>
<p><strong>E(3)ç¾¤</strong>: 3æ¬¡å…ƒãƒ¦ãƒ¼ã‚¯ãƒªãƒƒãƒ‰ç©ºé–“ã®ç­‰é•·å¤‰æ›
- å›è»¢ï¼ˆRotationï¼‰
- ä¸¦é€²ï¼ˆTranslationï¼‰
- åè»¢ï¼ˆInversionï¼‰</p>
<p><strong>é‡è¦æ€§</strong>:
- ç‰©ç†æ³•å‰‡ã¯åº§æ¨™ç³»ã«ä¾å­˜ã—ãªã„
- GNNã‚‚åŒæ§˜ã§ã‚ã‚‹ã¹ã</p>
<hr />
<h3>ç­‰å¤‰GNNã®ä¾‹ï¼šNequIPã€MACE</h3>
<p><strong>NequIP</strong> (Batzner et al., 2022):
- <strong>E(3)ç­‰å¤‰ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ‘ãƒƒã‚·ãƒ³ã‚°</strong>
- çƒé¢èª¿å’Œé–¢æ•°ï¼ˆSpherical Harmonicsï¼‰ã®åˆ©ç”¨</p>
<p><strong>æ›´æ–°å¼</strong>:
$$
m_{ij} = \phi\left( |r_i - r_j| \right) \otimes Y_l(r_{ij})
$$</p>
<ul>
<li>$Y_l$: çƒé¢èª¿å’Œé–¢æ•°ï¼ˆè§’åº¦æƒ…å ±ã‚’ä¿æŒï¼‰</li>
<li>$\otimes$: ãƒ†ãƒ³ã‚½ãƒ«ç©</li>
</ul>
<p><strong>MACE</strong> (Batatia et al., 2022):
- <strong>é«˜æ¬¡ã®ç­‰å¤‰æ€§</strong>
- ã‚ˆã‚Šæ­£ç¢ºãªåŠ›å ´ï¼ˆforce fieldï¼‰äºˆæ¸¬</p>
<p><strong>æ€§èƒ½</strong>:</p>
<pre><code>MD17ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆåˆ†å­å‹•åŠ›å­¦ï¼‰:
- SchNet: MAE(åŠ›) = 0.21 kcal/mol/Ã…
- NequIP: MAE(åŠ›) = 0.05 kcal/mol/Ã…ï¼ˆ76%æ”¹å–„ï¼‰
</code></pre>
<hr />
<h3>ç­‰å¤‰æ€§ã®ãƒ†ã‚¹ãƒˆ</h3>
<pre><code class="language-python">import torch
import torch.nn as nn

def test_equivariance(model, pos, edge_index):
    &quot;&quot;&quot;
    ãƒ¢ãƒ‡ãƒ«ã®ç­‰å¤‰æ€§ã‚’ãƒ†ã‚¹ãƒˆ
    &quot;&quot;&quot;
    # ã‚ªãƒªã‚¸ãƒŠãƒ«ã®äºˆæ¸¬
    pred_original = model(pos, edge_index)

    # å›è»¢è¡Œåˆ—ï¼ˆ90åº¦å›è»¢ï¼‰
    angle = torch.tensor(torch.pi / 2)
    rotation = torch.tensor([
        [torch.cos(angle), -torch.sin(angle), 0],
        [torch.sin(angle), torch.cos(angle), 0],
        [0, 0, 1]
    ])

    # åº§æ¨™ã‚’å›è»¢
    pos_rotated = pos @ rotation.T

    # å›è»¢å¾Œã®äºˆæ¸¬
    pred_rotated = model(pos_rotated, edge_index)

    # äºˆæ¸¬ã‚’å›è»¢
    pred_original_rotated = pred_original @ rotation.T

    # èª¤å·®ã‚’è¨ˆç®—
    error = torch.abs(pred_rotated - pred_original_rotated).mean()
    print(f&quot;ç­‰å¤‰æ€§èª¤å·®: {error.item():.6f}&quot;)

    if error &lt; 1e-5:
        print(&quot;âœ… ãƒ¢ãƒ‡ãƒ«ã¯ç­‰å¤‰ã§ã™&quot;)
    else:
        print(&quot;âŒ ãƒ¢ãƒ‡ãƒ«ã¯ç­‰å¤‰ã§ã¯ã‚ã‚Šã¾ã›ã‚“&quot;)

# ä½¿ç”¨ä¾‹ï¼ˆç°¡ç•¥ç‰ˆï¼‰
class SimpleEquivariantModel(nn.Module):
    def forward(self, pos, edge_index):
        # ç°¡ç•¥åŒ–: åº§æ¨™ã®å·®åˆ†ã‚’è¨ˆç®—ï¼ˆç­‰å¤‰ï¼‰
        src, dst = edge_index
        diff = pos[dst] - pos[src]
        return diff

model = SimpleEquivariantModel()
pos = torch.randn(5, 3)
edge_index = torch.tensor([[0, 1, 2], [1, 2, 3]])

test_equivariance(model, pos, edge_index)
</code></pre>
<hr />
<h2>2.6 ã‚³ãƒ©ãƒ ï¼šãªãœæ·±ã„GNNã¯é›£ã—ã„ã‹</h2>
<h3>éå‰°å¹³æ»‘åŒ–ï¼ˆOver-smoothingï¼‰</h3>
<p><strong>å•é¡Œ</strong>: ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚’æ·±ãã™ã‚‹ã¨ã€<strong>å…¨ã¦ã®é ‚ç‚¹ãŒåŒã˜ç‰¹å¾´</strong>ã«ãªã‚‹</p>
<p><strong>åŸå› </strong>: ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ‘ãƒƒã‚·ãƒ³ã‚°ã®ç¹°ã‚Šè¿”ã—ã§æƒ…å ±ãŒæ‹¡æ•£</p>
<pre><code class="language-python"># éå‰°å¹³æ»‘åŒ–ã®ãƒ‡ãƒ¢
import torch
import torch.nn.functional as F

def demonstrate_oversmoothing(X, A, num_layers=10):
    &quot;&quot;&quot;
    éå‰°å¹³æ»‘åŒ–ã®å¯è¦–åŒ–
    &quot;&quot;&quot;
    H = X
    smoothness = []

    for layer in range(num_layers):
        # ç°¡å˜ãªGCNå±¤
        D = torch.diag(A.sum(dim=1))
        D_inv_sqrt = torch.diag(1.0 / torch.sqrt(D.diagonal()))
        A_norm = D_inv_sqrt @ A @ D_inv_sqrt

        H = A_norm @ H
        H = F.relu(H)

        # å¹³æ»‘åº¦ï¼ˆé ‚ç‚¹é–“ã®é¡ä¼¼åº¦ï¼‰
        similarity = F.cosine_similarity(
            H.unsqueeze(1), H.unsqueeze(0), dim=2
        )
        avg_similarity = similarity[torch.triu_indices(
            H.size(0), H.size(0), offset=1
        )[0], torch.triu_indices(
            H.size(0), H.size(0), offset=1
        )[1]].mean()

        smoothness.append(avg_similarity.item())
        print(f&quot;Layer {layer+1}: å¹³å‡é¡ä¼¼åº¦ = {avg_similarity:.4f}&quot;)

    return smoothness

# å®Ÿè¡Œ
X = torch.randn(5, 16)
A = torch.eye(5) + torch.rand(5, 5) &gt; 0.7
smoothness = demonstrate_oversmoothing(X, A.float(), num_layers=10)
</code></pre>
<p><strong>å‡ºåŠ›ä¾‹</strong>:</p>
<pre><code>Layer 1: å¹³å‡é¡ä¼¼åº¦ = 0.2341
Layer 2: å¹³å‡é¡ä¼¼åº¦ = 0.4523
Layer 3: å¹³å‡é¡ä¼¼åº¦ = 0.6789
...
Layer 10: å¹³å‡é¡ä¼¼åº¦ = 0.9876
</code></pre>
<p>â†’ ãƒ¬ã‚¤ãƒ¤ãƒ¼ãŒæ·±ããªã‚‹ã«ã¤ã‚Œã€å…¨é ‚ç‚¹ãŒä¼¼ã¦ãã‚‹</p>
<hr />
<h3>å¯¾ç­–</h3>
<ol>
<li>
<p><strong>Residual Connectionï¼ˆæ®‹å·®æ¥ç¶šï¼‰</strong>:
   $$h_i^{(l+1)} = h_i^{(l)} + \text{GNN}(h_i^{(l)})$$</p>
</li>
<li>
<p><strong>Jumping Knowledge Network</strong>:
   - å…¨ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®å‡ºåŠ›ã‚’çµåˆ</p>
</li>
<li>
<p><strong>PairNorm</strong>:
   - ç‰¹å¾´é‡ã®æ­£è¦åŒ–</p>
</li>
</ol>
<pre><code class="language-python">class GNNWithResidual(nn.Module):
    def \_\_init\_\_(self, hidden\_dim):
        super().\_\_init\_\_()
        self.conv = GCNLayer(hidden\_dim, hidden\_dim)

    def forward(self, X, A):
        # Residual connection
        H = self.conv(X, A)
        return X + H  # ã‚·ãƒ§ãƒ¼ãƒˆã‚«ãƒƒãƒˆ
</code></pre>
<hr />
<h2>2.7 æœ¬ç« ã®ã¾ã¨ã‚</h2>
<h3>å­¦ã‚“ã ã“ã¨</h3>
<ol>
<li>
<p><strong>ã‚°ãƒ©ãƒ•ã®æ•°å­¦çš„å®šç¾©</strong>
   - éš£æ¥è¡Œåˆ—ã€æ¬¡æ•°è¡Œåˆ—ã€ãƒ©ãƒ—ãƒ©ã‚·ã‚¢ãƒ³è¡Œåˆ—
   - é ‚ç‚¹ç‰¹å¾´é‡ã¨è¾ºç‰¹å¾´é‡</p>
</li>
<li>
<p><strong>ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ‘ãƒƒã‚·ãƒ³ã‚°</strong>
   - 3ã‚¹ãƒ†ãƒƒãƒ—: ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç”Ÿæˆ â†’ é›†ç´„ â†’ æ›´æ–°
   - é›†ç´„é–¢æ•°: Sumã€Meanã€Maxã€Attention</p>
</li>
<li>
<p><strong>ä»£è¡¨çš„GNNã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£</strong>
   - GCN: ã‚·ãƒ³ãƒ—ãƒ«ã€é«˜é€Ÿ
   - GAT: Attentionã€é«˜ç²¾åº¦
   - GraphSAGE: ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ã€ãƒŸãƒ‹ãƒãƒƒãƒ</p>
</li>
<li>
<p><strong>ææ–™ç§‘å­¦ç‰¹åŒ–GNN</strong>
   - SchNet: è·é›¢ä¾å­˜ã€é€£ç¶šãƒ•ã‚£ãƒ«ã‚¿
   - DimeNet: è§’åº¦æƒ…å ±ã‚‚è€ƒæ…®
   - GemNet: äºŒé¢è§’ã¾ã§è€ƒæ…®</p>
</li>
<li>
<p><strong>ç­‰å¤‰æ€§</strong>
   - E(3)ç­‰å¤‰æ€§ã®é‡è¦æ€§
   - NequIPã€MACEãªã©æœ€æ–°æ‰‹æ³•</p>
</li>
</ol>
<h3>é‡è¦ãªãƒã‚¤ãƒ³ãƒˆ</h3>
<ul>
<li>âœ… ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ‘ãƒƒã‚·ãƒ³ã‚°ã¯GNNã®<strong>çµ±ä¸€ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯</strong></li>
<li>âœ… é›†ç´„é–¢æ•°ã®é¸æŠãŒæ€§èƒ½ã«å¤§ããå½±éŸ¿</li>
<li>âœ… ææ–™ç§‘å­¦ã§ã¯<strong>å¹¾ä½•å­¦çš„æƒ…å ±</strong>ï¼ˆè·é›¢ã€è§’åº¦ï¼‰ãŒé‡è¦</li>
<li>âœ… ç­‰å¤‰æ€§ã«ã‚ˆã‚Š<strong>ç‰©ç†æ³•å‰‡ã‚’ä¿è¨¼</strong></li>
<li>âœ… éå‰°å¹³æ»‘åŒ–ã«æ³¨æ„ï¼ˆResidual Connectionã§å¯¾ç­–ï¼‰</li>
</ul>
<h3>æ¬¡ã®ç« ã¸</h3>
<p>ç¬¬3ç« ã§ã¯ã€<strong>PyTorch Geometricå®Ÿè·µ</strong>ã‚’å­¦ã³ã¾ã™ï¼š
- ç’°å¢ƒæ§‹ç¯‰ï¼ˆPyGã€RDKitã€ASEï¼‰
- QM9ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§åˆ†å­ç‰¹æ€§äºˆæ¸¬
- Materials Projectãƒ‡ãƒ¼ã‚¿ã§çµæ™¶ç‰¹æ€§äºˆæ¸¬
- ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ã¨ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°
- å®Ÿè·µãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ</p>
<p><strong><a href="./chapter-3.html">ç¬¬3ç« ï¼šPyTorch Geometricå®Ÿè·µ â†’</a></strong></p>
<hr />
<h2>æ¼”ç¿’å•é¡Œ</h2>
<h3>å•é¡Œ1ï¼ˆé›£æ˜“åº¦ï¼šeasyï¼‰</h3>
<p>æ¬¡ã®æ–‡ç« ã®æ­£èª¤ã‚’åˆ¤å®šã—ã¦ãã ã•ã„ã€‚</p>
<ol>
<li>ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ‘ãƒƒã‚·ãƒ³ã‚°ã¯ã€é›†ç´„ï¼ˆAggregationï¼‰â†’ æ›´æ–°ï¼ˆUpdateï¼‰â†’ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç”Ÿæˆã®é †ã§è¡Œã‚ã‚Œã‚‹</li>
<li>GATã¯Attentionã‚’ä½¿ã†ãŸã‚ã€å…¨ã¦ã®éš£æ¥é ‚ç‚¹ã‚’åŒã˜é‡ã¿ã§æ‰±ã†</li>
<li>SchNetã¯åŸå­é–“è·é›¢ã‚’æ˜ç¤ºçš„ã«è€ƒæ…®ã™ã‚‹</li>
</ol>
<details>
<summary>ãƒ’ãƒ³ãƒˆ</summary>

- ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ‘ãƒƒã‚·ãƒ³ã‚°ã®3ã‚¹ãƒ†ãƒƒãƒ—ã‚’æ€ã„å‡ºã—ã¾ã—ã‚‡ã†
- GATã®æ ¸å¿ƒã‚¢ã‚¤ãƒ‡ã‚¢ã¯ã€Œé‡è¦ãªéš£æ¥é ‚ç‚¹ã‚’é‡è¦–ã€ã§ã™
- SchNetã®ç‰¹å¾´ã¯ã€Œé€£ç¶šãƒ•ã‚£ãƒ«ã‚¿ã€ã§ã™

</details>

<details>
<summary>è§£ç­”ä¾‹</summary>

**è§£ç­”**:
1. **èª¤** - æ­£ã—ã„é †ç•ªã¯ï¼šãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç”Ÿæˆ â†’ é›†ç´„ â†’ æ›´æ–°
2. **èª¤** - GATã¯ Attentionã§**ç•°ãªã‚‹é‡ã¿**ã‚’å‰²ã‚Šå½“ã¦ã‚‹
3. **æ­£** - SchNetã¯RBFï¼ˆã‚¬ã‚¦ã‚¹åŸºåº•ï¼‰ã§è·é›¢ã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰

**è§£èª¬**:

1ã«ã¤ã„ã¦ï¼š

<pre><code class="language-python"># æ­£ã—ã„é †åº
for layer in range(num\_layers):
    # Step 1: ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç”Ÿæˆ
    messages = message\_function(h\_neighbors)

    # Step 2: é›†ç´„
    m\_i = aggregate(messages)

    # Step 3: æ›´æ–°
    h\_i = update\_function(h\_i, m\_i)
</code></pre>


2ã«ã¤ã„ã¦ï¼š
- GAT ã® Attention ä¿‚æ•° $\alpha\_{ij}$ ã¯éš£æ¥é ‚ç‚¹ã”ã¨ã«ç•°ãªã‚‹
- é‡è¦ãªéš£æ¥é ‚ç‚¹ã«ã¯å¤§ããªé‡ã¿ã€ãã†ã§ãªã„ã‚‚ã®ã«ã¯å°ã•ãªé‡ã¿

3ã«ã¤ã„ã¦ï¼š
- SchNet ã® ãƒ•ã‚£ãƒ«ã‚¿é–¢æ•°: $\phi(d) = \sum\_k w\_k \exp(-\gamma (d - \mu\_k)^2)$
- è·é›¢ $d$ ãŒç•°ãªã‚Œã°ã€ãƒ•ã‚£ãƒ«ã‚¿ã®å€¤ã‚‚ç•°ãªã‚‹

</details>

<hr />
<h3>å•é¡Œ2ï¼ˆé›£æ˜“åº¦ï¼šmediumï¼‰</h3>
<p>ä»¥ä¸‹ã®ã‚°ãƒ©ãƒ•ã«å¯¾ã—ã¦ã€GCNã®1å±¤ã®é †ä¼æ’­ã‚’æ‰‹è¨ˆç®—ã§æ±‚ã‚ã¦ãã ã•ã„ã€‚</p>
<p><strong>ã‚°ãƒ©ãƒ•</strong>:</p>
<pre><code>é ‚ç‚¹: 3å€‹ï¼ˆv0, v1, v2ï¼‰
è¾º: v0-v1, v1-v2ï¼ˆç·šå½¢ã‚°ãƒ©ãƒ•ï¼‰

é ‚ç‚¹ç‰¹å¾´:
X = [[1, 0],
     [0, 1],
     [1, 1]]

éš£æ¥è¡Œåˆ—:
A = [[0, 1, 0],
     [1, 0, 1],
     [0, 1, 0]]

é‡ã¿è¡Œåˆ—ï¼ˆç°¡ç•¥åŒ–ï¼‰:
W = [[1, 0],
     [0, 1]]  ï¼ˆæ’ç­‰è¡Œåˆ—ï¼‰
</code></pre>
<p><strong>è¦æ±‚äº‹é …</strong>:
1. $\tilde{A} = A + I$ ã‚’è¨ˆç®—
2. æ­£è¦åŒ–éš£æ¥è¡Œåˆ— $\hat{A} = \tilde{D}^{-1/2} \tilde{A} \tilde{D}^{-1/2}$ ã‚’è¨ˆç®—
3. GCNå‡ºåŠ› $H = \hat{A} X W$ ã‚’è¨ˆç®—ï¼ˆæ´»æ€§åŒ–é–¢æ•°ãªã—ï¼‰</p>
<details>
<summary>ãƒ’ãƒ³ãƒˆ</summary>

**æ‰‹é †**:
1. è‡ªå·±ãƒ«ãƒ¼ãƒ—ã‚’è¿½åŠ : $\tilde{A}\_{ii} = 1$
2. æ¬¡æ•°è¡Œåˆ—: $\tilde{D}\_{ii} = \sum\_j \tilde{A}\_{ij}$
3. $\tilde{D}^{-1/2}$ ã‚’è¨ˆç®—ï¼ˆå¯¾è§’è¦ç´ ã®é€†æ•°ã®å¹³æ–¹æ ¹ï¼‰
4. è¡Œåˆ—ç©ã‚’è¨ˆç®—

</details>

<details>
<summary>è§£ç­”ä¾‹</summary>

**Step 1: è‡ªå·±ãƒ«ãƒ¼ãƒ—ä»˜ãéš£æ¥è¡Œåˆ—**
$$
\tilde{A} = A + I = \begin{bmatrix}
0 & 1 & 0 \\
1 & 0 & 1 \\
0 & 1 & 0
\end{bmatrix} + \begin{bmatrix}
1 & 0 & 0 \\
0 & 1 & 0 \\
0 & 0 & 1
\end{bmatrix} = \begin{bmatrix}
1 & 1 & 0 \\
1 & 1 & 1 \\
0 & 1 & 1
\end{bmatrix}
$$

**Step 2: æ¬¡æ•°è¡Œåˆ—**
$$
\tilde{D} = \begin{bmatrix}
2 & 0 & 0 \\
0 & 3 & 0 \\
0 & 0 & 2
\end{bmatrix}
$$

ï¼ˆå„è¡Œã®å’Œï¼‰

**Step 3: $\tilde{D}^{-1/2}$**
$$
\tilde{D}^{-1/2} = \begin{bmatrix}
1/\sqrt{2} & 0 & 0 \\
0 & 1/\sqrt{3} & 0 \\
0 & 0 & 1/\sqrt{2}
\end{bmatrix} \approx \begin{bmatrix}
0.707 & 0 & 0 \\
0 & 0.577 & 0 \\
0 & 0 & 0.707
\end{bmatrix}
$$

**Step 4: æ­£è¦åŒ–éš£æ¥è¡Œåˆ—**
$$
\hat{A} = \tilde{D}^{-1/2} \tilde{A} \tilde{D}^{-1/2}
$$

è¨ˆç®—éç¨‹:

<pre><code class="language-python">import numpy as np

A\_tilde = np.array([
    [1, 1, 0],
    [1, 1, 1],
    [0, 1, 1]
], dtype=float)

D\_tilde = np.diag([2, 3, 2])
D\_inv\_sqrt = np.diag([1/np.sqrt(2), 1/np.sqrt(3), 1/np.sqrt(2)])

A\_hat = D\_inv\_sqrt @ A\_tilde @ D\_inv\_sqrt
print(&quot;æ­£è¦åŒ–éš£æ¥è¡Œåˆ—:&quot;)
print(A\_hat)
</code></pre>


$$
\hat{A} \approx \begin{bmatrix}
0.500 & 0.408 & 0 \\
0.408 & 0.333 & 0.408 \\
0 & 0.408 & 0.500
\end{bmatrix}
$$

**Step 5: GCNå‡ºåŠ›**
$$
H = \hat{A} X W
$$

ï¼ˆ$W = I$ ãªã®ã§ $H = \hat{A} X$ï¼‰


<pre><code class="language-python">X = np.array([
    [1, 0],
    [0, 1],
    [1, 1]
], dtype=float)

H = A\_hat @ X
print(&quot;GCNå‡ºåŠ›:&quot;)
print(H)
</code></pre>


$$
H \approx \begin{bmatrix}
0.500 & 0.408 \\
0.816 & 0.741 \\
0.408 & 0.908
\end{bmatrix}
$$

**è§£é‡ˆ**:
- é ‚ç‚¹1ï¼ˆä¸­å¿ƒï¼‰: ä¸¡å´ã®éš£æ¥é ‚ç‚¹ã®æƒ…å ±ã‚’é›†ç´„
- é ‚ç‚¹0,2ï¼ˆç«¯ç‚¹ï¼‰: éš£æ¥é ‚ç‚¹1ã®æƒ…å ±ã‚’ä¸»ã«å–ã‚Šè¾¼ã‚€

**Pythonã§ã®æ¤œè¨¼**:

<pre><code class="language-python"># å®Œå…¨ãªã‚³ãƒ¼ãƒ‰
A = np.array([[0, 1, 0], [1, 0, 1], [0, 1, 0]], dtype=float)
X = np.array([[1, 0], [0, 1], [1, 1]], dtype=float)

# GCN
A\_tilde = A + np.eye(3)
D\_tilde = np.diag(A\_tilde.sum(axis=1))
D\_inv\_sqrt = np.diag(1.0 / np.sqrt(D\_tilde.diagonal()))
A\_hat = D\_inv\_sqrt @ A\_tilde @ D\_inv\_sqrt

H = A\_hat @ X
print(&quot;æœ€çµ‚å‡ºåŠ›:&quot;)
print(H)
</code></pre>


</details>

<hr />
<h3>å•é¡Œ3ï¼ˆé›£æ˜“åº¦ï¼šhardï¼‰</h3>
<p>SchNetã®é€£ç¶šãƒ•ã‚£ãƒ«ã‚¿é–¢æ•°ã‚’å®Ÿè£…ã—ã€ç•°ãªã‚‹åŸå­é–“è·é›¢ã«å¯¾ã™ã‚‹ãƒ•ã‚£ãƒ«ã‚¿ã®å¿œç­”ã‚’å¯è¦–åŒ–ã—ã¦ãã ã•ã„ã€‚</p>
<p><strong>è¦æ±‚äº‹é …</strong>:
1. ã‚¬ã‚¦ã‚¹åŸºåº•ï¼ˆRBFï¼‰é–¢æ•°ã‚’å®Ÿè£…
2. è·é›¢0.5Ã…ã€œ5.0Ã…ã«å¯¾ã™ã‚‹RBFå¿œç­”ã‚’è¨ˆç®—
3. ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã§å¯è¦–åŒ–
4. ãƒ•ã‚£ãƒ«ã‚¿ã®ç‰©ç†çš„æ„å‘³ã‚’è€ƒå¯Ÿ</p>
<details>
<summary>ãƒ’ãƒ³ãƒˆ</summary>

**RBF ã®å¼**:
$$\phi_k(d) = \exp\left( -\gamma (d - \mu_k)^2 \right)$$

- $\mu\_k$: ã‚¬ã‚¦ã‚¹é–¢æ•°ã®ä¸­å¿ƒï¼ˆ0ã€œ5Ã…ã«å‡ç­‰é…ç½®ï¼‰
- $\gamma$: åºƒãŒã‚Šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆ10ç¨‹åº¦ï¼‰

**å¯è¦–åŒ–ã®ãƒã‚¤ãƒ³ãƒˆ**:
- Xè»¸: è·é›¢ (0.5ã€œ5.0Ã…)
- Yè»¸: RBF ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ (0ã€œ49)
- è‰²: RBF å¿œç­”å€¤ (0ã€œ1)

</details>

<details>
<summary>è§£ç­”ä¾‹</summary>


<pre><code class="language-python">import torch
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# ===== å®Ÿè£… =====
class GaussianBasisFunction:
    def __init__(self, start=0.0, stop=5.0, num_gaussians=50,
                 gamma=10.0):
        &quot;&quot;&quot;
        ã‚¬ã‚¦ã‚¹åŸºåº•é–¢æ•°ï¼ˆRBFï¼‰

        Parameters:
        -----------
        start, stop : float
            è·é›¢ã®ç¯„å›²
        num_gaussians : int
            ã‚¬ã‚¦ã‚¹é–¢æ•°ã®æ•°
        gamma : float
            åºƒãŒã‚Šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        &quot;&quot;&quot;
        self.mu = torch.linspace(start, stop, num_gaussians)
        self.gamma = gamma

    def __call__(self, distances):
        &quot;&quot;&quot;
        RBF å¿œç­”ã‚’è¨ˆç®—

        Parameters:
        -----------
        distances : Tensor (num_distances,)

        Returns:
        --------
        rbf : Tensor (num_distances, num_gaussians)
        &quot;&quot;&quot;
        # (num_distances, 1) - (1, num_gaussians)
        diff = distances.unsqueeze(-1) - self.mu.unsqueeze(0)
        rbf = torch.exp(-self.gamma * diff ** 2)
        return rbf

# ===== å¯è¦–åŒ– =====
# RBFç”Ÿæˆ
rbf_layer = GaussianBasisFunction(
    start=0.0, stop=5.0,
    num_gaussians=50, gamma=10.0
)

# è·é›¢ã‚µãƒ³ãƒ—ãƒ«ï¼ˆ0.5ã€œ5.0Ã…ï¼‰
distances = torch.linspace(0.5, 5.0, 100)

# RBF å¿œç­”
rbf_response = rbf_layer(distances)  # (100, 50)

# ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—
plt.figure(figsize=(12, 6))
sns.heatmap(
    rbf_response.T.numpy(),  # è»¢ç½®ï¼ˆRBF x è·é›¢ï¼‰
    cmap='viridis',
    xticklabels=10,
    yticklabels=10,
    cbar_kws={'label': 'RBF Response'}
)
plt.xlabel('Distance (Ã…)')
plt.ylabel('RBF Index')
plt.title('SchNet Continuous Filter: RBF Response')

# Xè»¸ãƒ©ãƒ™ãƒ«ã‚’å®Ÿéš›ã®è·é›¢ã«
xticks = np.linspace(0, len(distances)-1, 10).astype(int)
xticklabels = [f'{distances[i]:.1f}' for i in xticks]
plt.xticks(xticks, xticklabels)

plt.tight_layout()
plt.savefig('schnet_rbf_heatmap.png', dpi=150)
plt.show()

# ===== ç‰¹å®šè·é›¢ã®RBFå¿œç­” =====
fig, axes = plt.subplots(2, 2, figsize=(12, 10))
example_distances = [1.0, 1.5, 2.0, 3.0]  # Ã…

for ax, d in zip(axes.flatten(), example_distances):
    d_tensor = torch.tensor([d])
    rbf = rbf_layer(d_tensor).squeeze()

    ax.plot(rbf_layer.mu.numpy(), rbf.numpy(),
            marker='o', linewidth=2)
    ax.axvline(d, color='red', linestyle='--',
               label=f'Distance = {d}Ã…')
    ax.set_xlabel('RBF Center Î¼ (Ã…)')
    ax.set_ylabel('RBF Response')
    ax.set_title(f'RBF Response at d = {d}Ã…')
    ax.legend()
    ax.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('schnet_rbf_profiles.png', dpi=150)
plt.show()

# ===== ç‰©ç†çš„æ„å‘³ã®è€ƒå¯Ÿ =====
print(&quot;\n===== ç‰©ç†çš„æ„å‘³ =====&quot;)
print(&quot;1. çŸ­è·é›¢ï¼ˆ0.5-2.0Ã…ï¼‰: å…±æœ‰çµåˆé ˜åŸŸ&quot;)
print(&quot;   - C-C: 1.54Ã…, C=C: 1.34Ã…, C-H: 1.09Ã…&quot;)
print(&quot;   - RBFã¯æ€¥å³»ã«åå¿œï¼ˆçµåˆã®æœ‰ç„¡ã‚’è­˜åˆ¥ï¼‰&quot;)

print(&quot;\n2. ä¸­è·é›¢ï¼ˆ2.0-3.5Ã…ï¼‰: éå…±æœ‰çµåˆç›¸äº’ä½œç”¨&quot;)
print(&quot;   - æ°´ç´ çµåˆ: 2.8Ã…, ãƒ•ã‚¡ãƒ³ãƒ‡ãƒ«ãƒ¯ãƒ¼ãƒ«ã‚¹åŠ›&quot;)
print(&quot;   - RBFã¯ãªã ã‚‰ã‹ã«åå¿œ&quot;)

print(&quot;\n3. é•·è·é›¢ï¼ˆ3.5-5.0Ã…ï¼‰: å¼±ã„ç›¸äº’ä½œç”¨&quot;)
print(&quot;   - é™é›»ç›¸äº’ä½œç”¨ã€åˆ†æ•£åŠ›&quot;)
print(&quot;   - RBFã®å¿œç­”ã¯å°ã•ã„&quot;)

print(&quot;\n4. ã‚¬ã‚¦ã‚¹åŸºåº•ã®å½¹å‰²:&quot;)
print(&quot;   - é€£ç¶šçš„ãªè·é›¢è¡¨ç¾ï¼ˆé›¢æ•£åŒ–ãªã—ï¼‰&quot;)
print(&quot;   - ä»»æ„ã®è·é›¢ã«å¯¾ã—ã¦å¾®åˆ†å¯èƒ½&quot;)
print(&quot;   - æ©Ÿæ¢°å­¦ç¿’ã§æœ€é©åŒ–å¯èƒ½ï¼ˆÎ³ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼‰&quot;)
</code></pre>


**å‡ºåŠ›ã®è§£é‡ˆ**:

1. **ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—**:
   - å¯¾è§’ç·šçŠ¶ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆå„RBFãŒç‰¹å®šè·é›¢ã§æœ€å¤§å¿œç­”ï¼‰
   - æ»‘ã‚‰ã‹ãªé·ç§»ï¼ˆã‚¬ã‚¦ã‚¹é–¢æ•°ã®é‡ãªã‚Šï¼‰

2. **RBFãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«**:
   - è·é›¢1.0Ã…: RBF #10ä»˜è¿‘ãŒå¼·ãåå¿œ
   - è·é›¢2.0Ã…: RBF #20ä»˜è¿‘ãŒå¼·ãåå¿œ
   - ã‚¬ã‚¦ã‚¹å½¢çŠ¶ã«ã‚ˆã‚Šã€éš£æ¥RBFã‚‚å¼±ãåå¿œ

3. **ç‰©ç†çš„æ„å‘³**:
   - **SchNetã¯è·é›¢ã‚’ã€Œåˆ†å¸ƒã€ã¨ã—ã¦è¡¨ç¾**
   - é›¢æ•£çš„ãªãƒ“ãƒ³åˆ†ã‘ã§ã¯ãªãã€é€£ç¶šçš„ãªé‡ãªã‚Š
   - ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãŒè·é›¢ä¾å­˜æ€§ã‚’å­¦ç¿’

**æ‹¡å¼µèª²é¡Œ**:
1. $\gamma$ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å¤‰ãˆã¦ã€RBFã®åºƒãŒã‚Šã‚’èª¿æ•´
2. éå¯¾ç§°ãªã‚¬ã‚¦ã‚¹åŸºåº•ï¼ˆçŸ­è·é›¢ã‚’å¯†ã«ã€é•·è·é›¢ã‚’ç–ã«ï¼‰
3. å®Ÿéš›ã®åˆ†å­ã§RBFãƒ•ã‚£ãƒ«ã‚¿ã‚’å¯è¦–åŒ–

</details>

<hr />
<h2>å‚è€ƒæ–‡çŒ®</h2>
<ol>
<li>
<p>Kipf, T. N. &amp; Welling, M. (2017). "Semi-Supervised Classification with Graph Convolutional Networks." <em>ICLR</em>.
   DOI: <a href="https://arxiv.org/abs/1609.02907">https://arxiv.org/abs/1609.02907</a></p>
</li>
<li>
<p>VeliÄkoviÄ‡, P. et al. (2018). "Graph Attention Networks." <em>ICLR</em>.
   DOI: <a href="https://arxiv.org/abs/1710.10903">https://arxiv.org/abs/1710.10903</a></p>
</li>
<li>
<p>Hamilton, W. L. et al. (2017). "Inductive Representation Learning on Large Graphs." <em>NeurIPS</em>.
   DOI: <a href="https://arxiv.org/abs/1706.02216">https://arxiv.org/abs/1706.02216</a></p>
</li>
<li>
<p>SchÃ¼tt, K. T. et al. (2017). "SchNet: A continuous-filter convolutional neural network for modeling quantum interactions." <em>NeurIPS</em>.
   DOI: <a href="https://arxiv.org/abs/1706.08566">https://arxiv.org/abs/1706.08566</a></p>
</li>
<li>
<p>Klicpera, J. et al. (2020). "Directional Message Passing for Molecular Graphs." <em>ICLR</em>.
   DOI: <a href="https://arxiv.org/abs/2003.03123">https://arxiv.org/abs/2003.03123</a></p>
</li>
<li>
<p>Gasteiger, J. et al. (2021). "GemNet: Universal Directional Graph Neural Networks for Molecules." <em>NeurIPS</em>.
   DOI: <a href="https://arxiv.org/abs/2106.08903">https://arxiv.org/abs/2106.08903</a></p>
</li>
<li>
<p>Batzner, S. et al. (2022). "E(3)-equivariant graph neural networks for data-efficient and accurate interatomic potentials." <em>Nature Communications</em>, 13, 2453.
   DOI: <a href="https://doi.org/10.1038/s41467-022-29939-5">https://doi.org/10.1038/s41467-022-29939-5</a></p>
</li>
</ol>
<hr />
<h2>ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³</h2>
<h3>å‰ã®ç« </h3>
<p><strong><a href="./chapter-1.html">ç¬¬1ç« ï¼šãªãœææ–™ç§‘å­¦ã«GNNãŒå¿…è¦ã‹ â†</a></strong></p>
<h3>æ¬¡ã®ç« </h3>
<p><strong><a href="./chapter-3.html">ç¬¬3ç« ï¼šPyTorch Geometricå®Ÿè·µ â†’</a></strong></p>
<h3>ã‚·ãƒªãƒ¼ã‚ºç›®æ¬¡</h3>
<p><strong><a href="./index.html">â† ã‚·ãƒªãƒ¼ã‚ºç›®æ¬¡ã«æˆ»ã‚‹</a></strong></p>
<hr />
<h2>è‘—è€…æƒ…å ±</h2>
<p><strong>ä½œæˆè€…</strong>: AI Terakoya Content Team
<strong>ä½œæˆæ—¥</strong>: 2025-10-17
<strong>ãƒãƒ¼ã‚¸ãƒ§ãƒ³</strong>: 1.0</p>
<p><strong>æ›´æ–°å±¥æ­´</strong>:
- 2025-10-17: v1.0 åˆç‰ˆå…¬é–‹</p>
<p><strong>ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯</strong>:
- GitHub Issues: [ãƒªãƒã‚¸ãƒˆãƒªURL]/issues
- Email: yusuke.hashimoto.b8@tohoku.ac.jp</p>
<p><strong>ãƒ©ã‚¤ã‚»ãƒ³ã‚¹</strong>: Creative Commons BY 4.0</p>
<hr />
<p><strong>ç¬¬3ç« ã§ã€å®Ÿéš›ã«GNNã‚’å‹•ã‹ã—ã¦ã¿ã¾ã—ã‚‡ã†ï¼</strong></p><div class="navigation">
    <a href="chapter-1.html" class="nav-button">â† å‰ã®ç« </a>
    <a href="index.html" class="nav-button">ã‚·ãƒªãƒ¼ã‚ºç›®æ¬¡ã«æˆ»ã‚‹</a>
    <a href="chapter-3.html" class="nav-button">æ¬¡ã®ç«  â†’</a>
</div>
    </main>

    
    <section class="disclaimer">
        <h3>å…è²¬äº‹é …</h3>
        <ul>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯æ•™è‚²ãƒ»ç ”ç©¶ãƒ»æƒ…å ±æä¾›ã®ã¿ã‚’ç›®çš„ã¨ã—ã¦ãŠã‚Šã€å°‚é–€çš„ãªåŠ©è¨€(æ³•å¾‹ãƒ»ä¼šè¨ˆãƒ»æŠ€è¡“çš„ä¿è¨¼ãªã©)ã‚’æä¾›ã™ã‚‹ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŠã‚ˆã³ä»˜éšã™ã‚‹ã‚³ãƒ¼ãƒ‰ä¾‹ã¯ã€Œç¾çŠ¶æœ‰å§¿(AS IS)ã€ã§æä¾›ã•ã‚Œã€æ˜ç¤ºã¾ãŸã¯é»™ç¤ºã‚’å•ã‚ãšã€å•†å“æ€§ã€ç‰¹å®šç›®çš„é©åˆæ€§ã€æ¨©åˆ©éä¾µå®³ã€æ­£ç¢ºæ€§ãƒ»å®Œå…¨æ€§ã€å‹•ä½œãƒ»å®‰å…¨æ€§ç­‰ã„ã‹ãªã‚‹ä¿è¨¼ã‚‚ã—ã¾ã›ã‚“ã€‚</li>
            <li>å¤–éƒ¨ãƒªãƒ³ã‚¯ã€ç¬¬ä¸‰è€…ãŒæä¾›ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ»ãƒ„ãƒ¼ãƒ«ãƒ»ãƒ©ã‚¤ãƒ–ãƒ©ãƒªç­‰ã®å†…å®¹ãƒ»å¯ç”¨æ€§ãƒ»å®‰å…¨æ€§ã«ã¤ã„ã¦ã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯ä¸€åˆ‡ã®è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®åˆ©ç”¨ãƒ»å®Ÿè¡Œãƒ»è§£é‡ˆã«ã‚ˆã‚Šç›´æ¥çš„ãƒ»é–“æ¥çš„ãƒ»ä»˜éšçš„ãƒ»ç‰¹åˆ¥ãƒ»çµæœçš„ãƒ»æ‡²ç½°çš„æå®³ãŒç”Ÿã˜ãŸå ´åˆã§ã‚‚ã€é©ç”¨æ³•ã§è¨±å®¹ã•ã‚Œã‚‹æœ€å¤§é™ã®ç¯„å›²ã§ã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å†…å®¹ã¯ã€äºˆå‘Šãªãå¤‰æ›´ãƒ»æ›´æ–°ãƒ»æä¾›åœæ­¢ã•ã‚Œã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®è‘—ä½œæ¨©ãƒ»ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯æ˜è¨˜ã•ã‚ŒãŸæ¡ä»¶(ä¾‹: CC BY 4.0)ã«å¾“ã„ã¾ã™ã€‚å½“è©²ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯é€šå¸¸ã€ç„¡ä¿è¨¼æ¡é …ã‚’å«ã¿ã¾ã™ã€‚</li>
        </ul>
    </section>

<footer>
        <p><strong>ä½œæˆè€…</strong>: AI Terakoya Content Team</p>
        <p><strong>ãƒãƒ¼ã‚¸ãƒ§ãƒ³</strong>: 1.0 | <strong>ä½œæˆæ—¥</strong>: 2025-10-17</p>
        <p><strong>ãƒ©ã‚¤ã‚»ãƒ³ã‚¹</strong>: Creative Commons BY 4.0</p>
        <p>Â© 2025 AI Terakoya. All rights reserved.</p>
    </footer>
</body>
</html>
