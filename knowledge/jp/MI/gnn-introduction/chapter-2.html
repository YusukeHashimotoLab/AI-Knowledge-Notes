<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Á¨¨2Á´†ÔºöGNN„ÅÆÂü∫Á§éÁêÜË´ñ - AI Terakoya</title>

    <style>
        :root {
            --color-primary: #2c3e50;
            --color-primary-dark: #1a252f;
            --color-accent: #7b2cbf;
            --color-accent-light: #9d4edd;
            --color-text: #2d3748;
            --color-text-light: #4a5568;
            --color-bg: #ffffff;
            --color-bg-alt: #f7fafc;
            --color-border: #e2e8f0;
            --color-code-bg: #f8f9fa;
            --color-link: #3182ce;
            --color-link-hover: #2c5aa0;

            --spacing-xs: 0.5rem;
            --spacing-sm: 1rem;
            --spacing-md: 1.5rem;
            --spacing-lg: 2rem;
            --spacing-xl: 3rem;

            --font-body: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            --font-mono: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;

            --border-radius: 8px;
            --box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: var(--font-body);
            line-height: 1.7;
            color: var(--color-text);
            background-color: var(--color-bg);
            font-size: 16px;
        }

        header {
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            padding: var(--spacing-xl) var(--spacing-md);
            margin-bottom: var(--spacing-xl);
            box-shadow: var(--box-shadow);
        }

        .header-content {
            max-width: 900px;
            margin: 0 auto;
        }

        h1 {
            font-size: 2rem;
            font-weight: 700;
            margin-bottom: var(--spacing-sm);
            line-height: 1.2;
        }

        .subtitle {
            font-size: 1.1rem;
            opacity: 0.95;
            font-weight: 400;
            margin-bottom: var(--spacing-md);
        }

        .meta {
            display: flex;
            flex-wrap: wrap;
            gap: var(--spacing-md);
            font-size: 0.9rem;
            opacity: 0.9;
        }

        .meta-item {
            display: flex;
            align-items: center;
            gap: 0.3rem;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 0 var(--spacing-md) var(--spacing-xl);
        }

        h2 {
            font-size: 1.75rem;
            color: var(--color-primary);
            margin-top: var(--spacing-xl);
            margin-bottom: var(--spacing-md);
            padding-bottom: var(--spacing-xs);
            border-bottom: 3px solid var(--color-accent);
        }

        h3 {
            font-size: 1.4rem;
            color: var(--color-primary);
            margin-top: var(--spacing-lg);
            margin-bottom: var(--spacing-sm);
        }

        h4 {
            font-size: 1.1rem;
            color: var(--color-primary-dark);
            margin-top: var(--spacing-md);
            margin-bottom: var(--spacing-sm);
        }

        p {
            margin-bottom: var(--spacing-md);
            color: var(--color-text);
        }

        a {
            color: var(--color-link);
            text-decoration: none;
            transition: color 0.2s;
        }

        a:hover {
            color: var(--color-link-hover);
            text-decoration: underline;
        }

        ul, ol {
            margin-left: var(--spacing-lg);
            margin-bottom: var(--spacing-md);
        }

        li {
            margin-bottom: var(--spacing-xs);
            color: var(--color-text);
        }

        pre {
            background-color: var(--color-code-bg);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            overflow-x: auto;
            margin-bottom: var(--spacing-md);
            font-family: var(--font-mono);
            font-size: 0.9rem;
            line-height: 1.5;
        }

        code {
            font-family: var(--font-mono);
            font-size: 0.9em;
            background-color: var(--color-code-bg);
            padding: 0.2em 0.4em;
            border-radius: 3px;
        }

        pre code {
            background-color: transparent;
            padding: 0;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: var(--spacing-md);
            font-size: 0.95rem;
        }

        th, td {
            border: 1px solid var(--color-border);
            padding: var(--spacing-sm);
            text-align: left;
        }

        th {
            background-color: var(--color-bg-alt);
            font-weight: 600;
            color: var(--color-primary);
        }

        blockquote {
            border-left: 4px solid var(--color-accent);
            padding-left: var(--spacing-md);
            margin: var(--spacing-md) 0;
            color: var(--color-text-light);
            font-style: italic;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        .mermaid {
            text-align: center;
            margin: var(--spacing-lg) 0;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        details {
            background-color: var(--color-bg-alt);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            margin-bottom: var(--spacing-md);
        }

        summary {
            cursor: pointer;
            font-weight: 600;
            color: var(--color-primary);
            user-select: none;
            padding: var(--spacing-xs);
            margin: calc(-1 * var(--spacing-md));
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        summary:hover {
            background-color: rgba(123, 44, 191, 0.1);
        }

        details[open] summary {
            margin-bottom: var(--spacing-md);
            border-bottom: 1px solid var(--color-border);
        }

        .learning-objectives {
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
            padding: var(--spacing-lg);
            border-radius: var(--border-radius);
            border-left: 4px solid var(--color-accent);
            margin-bottom: var(--spacing-xl);
        }

        .learning-objectives h2 {
            margin-top: 0;
            border-bottom: none;
        }

        .navigation {
            display: flex;
            justify-content: space-between;
            gap: var(--spacing-md);
            margin: var(--spacing-xl) 0;
            padding-top: var(--spacing-lg);
            border-top: 2px solid var(--color-border);
        }

        .nav-button {
            flex: 1;
            padding: var(--spacing-md);
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            border-radius: var(--border-radius);
            text-align: center;
            font-weight: 600;
            transition: transform 0.2s, box-shadow 0.2s;
            box-shadow: var(--box-shadow);
        }

        .nav-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
            text-decoration: none;
        }

        footer {
            margin-top: var(--spacing-xl);
            padding: var(--spacing-lg) var(--spacing-md);
            background-color: var(--color-bg-alt);
            border-top: 1px solid var(--color-border);
            text-align: center;
            font-size: 0.9rem;
            color: var(--color-text-light);
        }

        @media (max-width: 768px) {
            h1 {
                font-size: 1.5rem;
            }

            h2 {
                font-size: 1.4rem;
            }

            h3 {
                font-size: 1.2rem;
            }

            .meta {
                font-size: 0.85rem;
            }

            .navigation {
                flex-direction: column;
            }

            table {
                font-size: 0.85rem;
            }

            th, td {
                padding: var(--spacing-xs);
            }
        }
    </style>

    <script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
    <script>
        mermaid.initialize({ startOnLoad: true, theme: 'default', securityLevel: 'strict' });
    </script>

    <!-- MathJax for LaTeX equation rendering -->
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\(', '\)']],
                displayMath: [['$$', '$$'], ['\[', '\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
                ignoreHtmlClass: 'mermaid'
            }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" async></script>
</head>
<body>
    <header>
        <div class="header-content">
            <h1>Á¨¨2Á´†ÔºöGNN„ÅÆÂü∫Á§éÁêÜË´ñ</h1>
            <p class="subtitle">„É°„ÉÉ„Çª„Éº„Ç∏„Éë„ÉÉ„Ç∑„É≥„Ç∞„Åã„ÇâÊùêÊñôÁßëÂ≠¶ÁâπÂåñGNN„Åæ„Åß</p>
            <div class="meta">
                <span class="meta-item">üìñ Ë™≠‰∫ÜÊôÇÈñì: 25-30ÂàÜ</span>
                <span class="meta-item">üìä Èõ£ÊòìÂ∫¶: ‰∏≠Á¥ö</span>
                <span class="meta-item">üíª „Ç≥„Éº„Éâ‰æã: 10ÂÄã</span>
                <span class="meta-item">üìù ÊºîÁøíÂïèÈ°å: 3Âïè</span>
            </div>
        </div>
    </header>

    <main class="container">
<h1>Á¨¨2Á´†ÔºöGNN„ÅÆÂü∫Á§éÁêÜË´ñ</h1>
<p class="chapter-description" style="margin: 1.5rem 0; padding: 1rem; background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%); border-left: 4px solid #7b2cbf; border-radius: 8px; font-size: 1.05rem; line-height: 1.8; color: #2d3748;">„É°„ÉÉ„Çª„Éº„Ç∏„Éë„ÉÉ„Ç∑„É≥„Ç∞„ÅÆÂü∫Êú¨Ê©üÊßã„ÇíÊï∞ÂºèÊäú„Åç„Åß„ÇÇ„Ç§„É°„Éº„Ç∏„Åß„Åç„Çã„Çà„ÅÜ„Å´Êï¥ÁêÜ„Åó„Åæ„Åô„ÄÇ‰ª£Ë°®„É¢„Éá„É´„ÅÆÈÅï„ÅÑ„Å®‰Ωø„ÅÑÂàÜ„Åë„ÇíÊäº„Åï„Åà„Åæ„Åô„ÄÇ</p>
<p class="chapter-supplement" style="margin: 0.75rem 0 1.5rem 0; padding: 0.75rem 1rem; background: linear-gradient(135deg, #fff8e1 0%, #fff3cd 100%); border-left: 3px solid #f59e0b; border-radius: 6px; font-size: 0.95rem; line-height: 1.7; color: #4a5568;"><strong>üí° Ë£úË∂≥:</strong> ‰ºù„Åà„ÇãÈáèÔºàÈáç„ÅøÔºâ„Å®ÂõûÊï∞ÔºàÂ±§Êï∞Ôºâ„ÄÅÂèó„ÅëÂèñ„ÇäÊñπÔºàÈõÜÁ¥ÑÔºâ„ÅÆ‰∏âÁÇπ„ÇíÂàÜ„Åë„Å¶ËÄÉ„Åà„Çã„Å®ÁêÜËß£„ÅåÊó©„ÅÑ„Åß„Åô„ÄÇ</p>





<p><strong>„É°„ÉÉ„Çª„Éº„Ç∏„Éë„ÉÉ„Ç∑„É≥„Ç∞„Åã„ÇâÊùêÊñôÁßëÂ≠¶ÁâπÂåñGNN„Åæ„Åß</strong></p>
<h2>Â≠¶ÁøíÁõÆÊ®ô</h2>
<p>„Åì„ÅÆÁ´†„ÇíË™≠„ÇÄ„Åì„Å®„Åß„ÄÅ‰ª•‰∏ã„ÇíÁøíÂæó„Åß„Åç„Åæ„ÅôÔºö</p>
<ul>
<li>‚úÖ „Ç∞„É©„Éï„ÅÆÊï∞Â≠¶ÁöÑÂÆöÁæ©„Å®Ë°®ÁèæÊñπÊ≥ï„ÇíÁêÜËß£„Åô„Çã</li>
<li>‚úÖ „É°„ÉÉ„Çª„Éº„Ç∏„Éë„ÉÉ„Ç∑„É≥„Ç∞„ÅÆ3„Çπ„ÉÜ„ÉÉ„ÉóÔºàÈõÜÁ¥Ñ‚ÜíÊõ¥Êñ∞‚ÜíÂá∫ÂäõÔºâ„ÇíË™¨Êòé„Åß„Åç„Çã</li>
<li>‚úÖ GCN„ÄÅGAT„ÄÅGraphSAGE„ÅÆÂéüÁêÜ„Å®ÈÅï„ÅÑ„ÇíÁêÜËß£„Åô„Çã</li>
<li>‚úÖ ÊùêÊñôÁßëÂ≠¶ÁâπÂåñGNNÔºàSchNet„ÄÅDimeNetÔºâ„ÅÆÁâπÂæ¥„ÇíÁü•„Çã</li>
<li>‚úÖ „Ç∑„É≥„Éó„É´„Å™GNN„ÇíPyTorch„ÅßÂÆüË£Ö„Åß„Åç„Çã</li>
<li>‚úÖ Á≠âÂ§âGNN„ÅÆÈáçË¶ÅÊÄß„ÇíÁêÜËß£„Åô„Çã</li>
</ul>
<p><strong>Ë™≠‰∫ÜÊôÇÈñì</strong>: 25-30ÂàÜ
<strong>„Ç≥„Éº„Éâ‰æã</strong>: 10ÂÄã
<strong>ÊºîÁøíÂïèÈ°å</strong>: 3Âïè</p>
<hr />
<h2>2.1 „Ç∞„É©„Éï„ÅÆÊï∞Â≠¶ÁöÑÂÆöÁæ©</h2>
<h3>„Ç∞„É©„Éï„ÅÆÂü∫Êú¨Ë¶ÅÁ¥†</h3>
<p><strong>ÂÆöÁæ©</strong>:</p>
<blockquote>
<p>„Ç∞„É©„Éï $G = (V, E)$ „ÅØ„ÄÅÈ†ÇÁÇπÈõÜÂêà $V$ „Å®Ëæ∫ÈõÜÂêà $E \subseteq V \times V$ „Åã„Çâ„Å™„Çã„ÄÇ</p>
</blockquote>
<p><strong>Ë®òÊ≥ï</strong>:
- $n = |V|$: È†ÇÁÇπÊï∞
- $m = |E|$: Ëæ∫Êï∞
- $\mathcal{N}(v)$: È†ÇÁÇπ $v$ „ÅÆÈö£Êé•È†ÇÁÇπÈõÜÂêà</p>
<hr />
<h3>Èö£Êé•Ë°åÂàóÔºàAdjacency MatrixÔºâ</h3>
<p><strong>ÂÆöÁæ©</strong>:
$$
A \in {0, 1}^{n \times n}, \quad A_{ij} = \begin{cases}
1 &amp; \text{if } (v_i, v_j) \in E \
0 &amp; \text{otherwise}
\end{cases}
$$</p>
<p><strong>Python„Åß„ÅÆÂÆüË£Ö</strong>:</p>
<pre><code class="language-python">import numpy as np

# ‰æãÔºö‰∏âËßíÂΩ¢„Ç∞„É©„ÉïÔºà3È†ÇÁÇπ„ÄÅ3Ëæ∫Ôºâ
n = 3
A = np.array([
    [0, 1, 1],  # È†ÇÁÇπ0: 1, 2„Å´Êé•Á∂ö
    [1, 0, 1],  # È†ÇÁÇπ1: 0, 2„Å´Êé•Á∂ö
    [1, 1, 0]   # È†ÇÁÇπ2: 0, 1„Å´Êé•Á∂ö
])

print(&quot;Èö£Êé•Ë°åÂàó:&quot;)
print(A)
print(f&quot;\nÈ†ÇÁÇπÊï∞: {n}&quot;)
print(f&quot;Ëæ∫Êï∞: {A.sum() // 2}&quot;)  # ÁÑ°Âêë„Ç∞„É©„Éï„ÅØ2„ÅßÂâ≤„Çã
</code></pre>
<p><strong>Âá∫Âäõ</strong>:</p>
<pre><code>Èö£Êé•Ë°åÂàó:
[[0 1 1]
 [1 0 1]
 [1 1 0]]

È†ÇÁÇπÊï∞: 3
Ëæ∫Êï∞: 3
</code></pre>
<hr />
<h3>Ê¨°Êï∞Ë°åÂàóÔºàDegree MatrixÔºâ</h3>
<p><strong>ÂÆöÁæ©</strong>:
$$
D \in \mathbb{R}^{n \times n}, \quad D_{ii} = \sum_{j=1}^{n} A_{ij}
$$</p>
<p><strong>Áâ©ÁêÜÁöÑÊÑèÂë≥</strong>: ÂêÑÈ†ÇÁÇπ„ÅÆÊé•Á∂öÊï∞ÔºàÂåñÂ≠¶„Åß„ÅØÁµêÂêàÊï∞Ôºâ</p>
<pre><code class="language-python"># Ê¨°Êï∞Ë°åÂàó
D = np.diag(A.sum(axis=1))
print(&quot;Ê¨°Êï∞Ë°åÂàó:&quot;)
print(D)
print(f&quot;\nÂêÑÈ†ÇÁÇπ„ÅÆÊ¨°Êï∞: {np.diag(D)}&quot;)
</code></pre>
<p><strong>Âá∫Âäõ</strong>:</p>
<pre><code>Ê¨°Êï∞Ë°åÂàó:
[[2 0 0]
 [0 2 0]
 [0 0 2]]

ÂêÑÈ†ÇÁÇπ„ÅÆÊ¨°Êï∞: [2 2 2]
</code></pre>
<hr />
<h3>„É©„Éó„É©„Ç∑„Ç¢„É≥Ë°åÂàóÔºàLaplacian MatrixÔºâ</h3>
<p><strong>ÂÆöÁæ©</strong>:
$$
L = D - A
$$</p>
<p><strong>Ê≠£Ë¶èÂåñ„É©„Éó„É©„Ç∑„Ç¢„É≥</strong>ÔºàGNN„Åß„Çà„Åè‰ΩøÁî®Ôºâ:
$$
\tilde{L} = D^{-1/2} L D^{-1/2} = I - D^{-1/2} A D^{-1/2}
$$</p>
<pre><code class="language-python"># „É©„Éó„É©„Ç∑„Ç¢„É≥Ë°åÂàó
L = D - A
print(&quot;„É©„Éó„É©„Ç∑„Ç¢„É≥Ë°åÂàó:&quot;)
print(L)

# Ê≠£Ë¶èÂåñ„É©„Éó„É©„Ç∑„Ç¢„É≥
D_inv_sqrt = np.diag(1 / np.sqrt(np.diag(D)))
L_norm = np.eye(n) - D_inv_sqrt @ A @ D_inv_sqrt
print(&quot;\nÊ≠£Ë¶èÂåñ„É©„Éó„É©„Ç∑„Ç¢„É≥:&quot;)
print(L_norm)
</code></pre>
<p><strong>Âá∫Âäõ</strong>:</p>
<pre><code>„É©„Éó„É©„Ç∑„Ç¢„É≥Ë°åÂàó:
[[ 2 -1 -1]
 [-1  2 -1]
 [-1 -1  2]]

Ê≠£Ë¶èÂåñ„É©„Éó„É©„Ç∑„Ç¢„É≥:
[[ 1.  -0.5 -0.5]
 [-0.5  1.  -0.5]
 [-0.5 -0.5  1. ]]
</code></pre>
<p><strong>Áî®ÈÄî</strong>:
- „Çπ„Éö„ÇØ„Éà„É´„Ç∞„É©„ÉïÁêÜË´ñ
- „Ç∞„É©„Éï„Éï„Éº„É™„Ç®Â§âÊèõ
- „Ç∞„É©„Éï‰ø°Âè∑Âá¶ÁêÜ</p>
<hr />
<h3>È†ÇÁÇπÁâπÂæ¥Èáè„Å®Ëæ∫ÁâπÂæ¥Èáè</h3>
<p><strong>È†ÇÁÇπÁâπÂæ¥Ë°åÂàó</strong> $X \in \mathbb{R}^{n \times d}$:
- ÂêÑË°å $x_i \in \mathbb{R}^d$: È†ÇÁÇπ $i$ „ÅÆÁâπÂæ¥„Éô„ÇØ„Éà„É´
- ÊùêÊñôÁßëÂ≠¶: ÂéüÂ≠êÁï™Âè∑„ÄÅÈõªÊ∞óÈô∞ÊÄßÂ∫¶„ÄÅ‰æ°ÈõªÂ≠êÊï∞„Å™„Å©</p>
<p><strong>Ëæ∫ÁâπÂæ¥Ë°åÂàó</strong> $E \in \mathbb{R}^{m \times d_e}$:
- ÂêÑË°å $e_{ij} \in \mathbb{R}^{d_e}$: Ëæ∫ $(i, j)$ „ÅÆÁâπÂæ¥
- ÊùêÊñôÁßëÂ≠¶: ÁµêÂêàÈï∑„ÄÅÁµêÂêàÊ¨°Êï∞„ÄÅÁµêÂêàËßí„Å™„Å©</p>
<pre><code class="language-python"># ‰æãÔºöÊ∞¥ÂàÜÂ≠êÔºàH‚ÇÇOÔºâ„ÅÆÁâπÂæ¥Èáè
X = np.array([
    [8, 2.55, 6],   # O: ÂéüÂ≠êÁï™Âè∑8, ÈõªÊ∞óÈô∞ÊÄßÂ∫¶2.55, ‰æ°ÈõªÂ≠ê6
    [1, 2.20, 1],   # H1
    [1, 2.20, 1]    # H2
])

print(&quot;È†ÇÁÇπÁâπÂæ¥Ë°åÂàó (3√ó3):&quot;)
print(X)
print(f&quot;ÂΩ¢Áä∂: {X.shape}&quot;)
</code></pre>
<hr />
<h2>2.2 „É°„ÉÉ„Çª„Éº„Ç∏„Éë„ÉÉ„Ç∑„É≥„Ç∞„ÅÆ‰ªïÁµÑ„Åø</h2>
<h3>Message Passing Neural Network (MPNN)</h3>
<p>GNN„ÅÆ<strong>Áµ±‰∏Ä„Éï„É¨„Éº„É†„ÉØ„Éº„ÇØ</strong>„Åß„ÅôÔºàGilmer et al., 2017Ôºâ„ÄÇ</p>
<p><strong>„Ç¢„É´„Ç¥„É™„Ç∫„É†</strong>:</p>
<div class="mermaid">
flowchart LR
    A[ÂÖ•Âäõ: È†ÇÁÇπÁâπÂæ¥ X] --> B[„Çπ„ÉÜ„ÉÉ„Éó1: „É°„ÉÉ„Çª„Éº„Ç∏ÁîüÊàê]
    B --> C[„Çπ„ÉÜ„ÉÉ„Éó2: ÈõÜÁ¥Ñ Aggregation]
    C --> D[„Çπ„ÉÜ„ÉÉ„Éó3: Êõ¥Êñ∞ Update]
    D --> E{Áπ∞„ÇäËøî„Åó?}
    E -->|Yes| B
    E -->|No| F[Âá∫Âäõ: Êñ∞„Åó„ÅÑÁâπÂæ¥]

    style A fill:#e3f2fd
    style B fill:#fff3e0
    style C fill:#f3e5f5
    style D fill:#e8f5e9
    style F fill:#ffebee
</div>

<hr />
<h3>„Çπ„ÉÜ„ÉÉ„Éó1: „É°„ÉÉ„Çª„Éº„Ç∏ÁîüÊàêÔºàMessageÔºâ</h3>
<p><strong>ÂÆöÁæ©</strong>:
$$
m_{ij}^{(t)} = \text{Message}(h_i^{(t)}, h_j^{(t)}, e_{ij})
$$</p>
<ul>
<li>$h_i^{(t)}$: „É¨„Ç§„É§„Éº $t$ „Åß„ÅÆÈ†ÇÁÇπ $i$ „ÅÆÈö†„ÇåÁä∂ÊÖã</li>
<li>$h_j^{(t)}$: Èö£Êé•È†ÇÁÇπ $j$ „ÅÆÈö†„ÇåÁä∂ÊÖã</li>
<li>$e_{ij}$: Ëæ∫ $(i, j)$ „ÅÆÁâπÂæ¥Èáè</li>
</ul>
<p><strong>ÊúÄ„ÇÇ„Ç∑„É≥„Éó„É´„Å™ÂΩ¢</strong>:
$$
m_{ij}^{(t)} = W \cdot h_j^{(t)}
$$</p>
<pre><code class="language-python">import torch
import torch.nn as nn

class MessageFunction(nn.Module):
    def __init__(self, in_dim, out_dim):
        super().__init__()
        self.W = nn.Linear(in_dim, out_dim)

    def forward(self, h_j):
        &quot;&quot;&quot;
        Èö£Êé•È†ÇÁÇπ„Åã„Çâ„É°„ÉÉ„Çª„Éº„Ç∏„ÇíÁîüÊàê

        Parameters:
        -----------
        h_j : Tensor (num_neighbors, in_dim)
            Èö£Êé•È†ÇÁÇπ„ÅÆÁâπÂæ¥Èáè

        Returns:
        --------
        messages : Tensor (num_neighbors, out_dim)
            ÁîüÊàê„Åï„Çå„Åü„É°„ÉÉ„Çª„Éº„Ç∏
        &quot;&quot;&quot;
        return self.W(h_j)

# ‰æã
in_dim, out_dim = 16, 32
msg_fn = MessageFunction(in_dim, out_dim)

# Èö£Êé•È†ÇÁÇπ„ÅÆÁâπÂæ¥Ôºà3ÂÄã„ÅÆÈö£Êé•È†ÇÁÇπÔºâ
h_neighbors = torch.randn(3, in_dim)
messages = msg_fn(h_neighbors)
print(f&quot;„É°„ÉÉ„Çª„Éº„Ç∏ÂΩ¢Áä∂: {messages.shape}&quot;)
# Âá∫Âäõ: torch.Size([3, 32])
</code></pre>
<hr />
<h3>„Çπ„ÉÜ„ÉÉ„Éó2: ÈõÜÁ¥ÑÔºàAggregationÔºâ</h3>
<p><strong>ÂÆöÁæ©</strong>:
$$
m_i^{(t)} = \text{Aggregate}\left( {m_{ij}^{(t)} : j \in \mathcal{N}(i)} \right)
$$</p>
<p><strong>‰ª£Ë°®ÁöÑ„Å™ÈõÜÁ¥ÑÈñ¢Êï∞</strong>:</p>
<table>
<thead>
<tr>
<th>ÈõÜÁ¥ÑÊñπÊ≥ï</th>
<th>Êï∞Âºè</th>
<th>ÁâπÂæ¥</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Sum</strong></td>
<td>$\sum_{j \in \mathcal{N}(i)} m_{ij}^{(t)}$</td>
<td>È†ÜÂ∫è‰∏çÂ§â„ÄÅÊ¨°Êï∞„Å´ÊïèÊÑü</td>
</tr>
<tr>
<td><strong>Mean</strong></td>
<td>$\frac{1}{</td>
<td>\mathcal{N}(i)</td>
</tr>
<tr>
<td><strong>Max</strong></td>
<td>$\max_{j \in \mathcal{N}(i)} m_{ij}^{(t)}$</td>
<td>ÊúÄ„ÇÇÂº∑„ÅÑÁâπÂæ¥„Çí‰øùÊåÅ</td>
</tr>
<tr>
<td><strong>Attention</strong></td>
<td>$\sum_{j \in \mathcal{N}(i)} \alpha_{ij} m_{ij}^{(t)}$</td>
<td>ÈáçË¶ÅÂ∫¶„ÅßÈáç„Åø‰ªò„Åë</td>
</tr>
</tbody>
</table>
<pre><code class="language-python">class AggregationFunction:
    @staticmethod
    def sum_agg(messages):
        &quot;&quot;&quot;Sum aggregation&quot;&quot;&quot;
        return torch.sum(messages, dim=0)

    @staticmethod
    def mean_agg(messages):
        &quot;&quot;&quot;Mean aggregation&quot;&quot;&quot;
        return torch.mean(messages, dim=0)

    @staticmethod
    def max_agg(messages):
        &quot;&quot;&quot;Max aggregation&quot;&quot;&quot;
        return torch.max(messages, dim=0)[0]

# ‰æã
messages = torch.tensor([
    [1.0, 2.0, 3.0],
    [4.0, 5.0, 6.0],
    [7.0, 8.0, 9.0]
])

print(&quot;Sum:&quot;, AggregationFunction.sum_agg(messages))
# Âá∫Âäõ: tensor([12., 15., 18.])

print(&quot;Mean:&quot;, AggregationFunction.mean_agg(messages))
# Âá∫Âäõ: tensor([4., 5., 6.])

print(&quot;Max:&quot;, AggregationFunction.max_agg(messages))
# Âá∫Âäõ: tensor([7., 8., 9.])
</code></pre>
<hr />
<h3>„Çπ„ÉÜ„ÉÉ„Éó3: Êõ¥Êñ∞ÔºàUpdateÔºâ</h3>
<p><strong>ÂÆöÁæ©</strong>:
$$
h_i^{(t+1)} = \text{Update}\left( h_i^{(t)}, m_i^{(t)} \right)
$$</p>
<p><strong>ÂÖ∏ÂûãÁöÑ„Å™Êõ¥Êñ∞Âºè</strong>:
$$
h_i^{(t+1)} = \sigma\left( W_1 h_i^{(t)} + W_2 m_i^{(t)} \right)
$$</p>
<pre><code class="language-python">class UpdateFunction(nn.Module):
    def __init__(self, hidden_dim):
        super().__init__()
        self.W1 = nn.Linear(hidden_dim, hidden_dim)
        self.W2 = nn.Linear(hidden_dim, hidden_dim)
        self.activation = nn.ReLU()

    def forward(self, h_i, m_i):
        &quot;&quot;&quot;
        È†ÇÁÇπÁâπÂæ¥„ÇíÊõ¥Êñ∞

        Parameters:
        -----------
        h_i : Tensor (hidden_dim,)
            ÁèæÂú®„ÅÆÈ†ÇÁÇπÁâπÂæ¥
        m_i : Tensor (hidden_dim,)
            ÈõÜÁ¥Ñ„Åï„Çå„Åü„É°„ÉÉ„Çª„Éº„Ç∏

        Returns:
        --------
        h_new : Tensor (hidden_dim,)
            Êõ¥Êñ∞„Åï„Çå„ÅüÈ†ÇÁÇπÁâπÂæ¥
        &quot;&quot;&quot;
        return self.activation(self.W1(h_i) + self.W2(m_i))

# ‰æã
hidden_dim = 32
update_fn = UpdateFunction(hidden_dim)

h_current = torch.randn(hidden_dim)
m_aggregated = torch.randn(hidden_dim)
h_new = update_fn(h_current, m_aggregated)

print(f&quot;Êõ¥Êñ∞Ââç: {h_current[:5]}&quot;)
print(f&quot;Êõ¥Êñ∞Âæå: {h_new[:5]}&quot;)
</code></pre>
<hr />
<h3>„É°„ÉÉ„Çª„Éº„Ç∏„Éë„ÉÉ„Ç∑„É≥„Ç∞„ÅÆÂÖ®‰ΩìÂÉè</h3>
<pre><code class="language-python">class SimpleGNN(nn.Module):
    def __init__(self, in_dim, hidden_dim, num_layers):
        super().__init__()
        self.num_layers = num_layers

        # ÂêÑ„É¨„Ç§„É§„Éº„ÅÆ„Éë„É©„É°„Éº„Çø
        self.message_fns = nn.ModuleList([
            MessageFunction(hidden_dim, hidden_dim)
            for _ in range(num_layers)
        ])
        self.update_fns = nn.ModuleList([
            UpdateFunction(hidden_dim)
            for _ in range(num_layers)
        ])

        # ÂÖ•ÂäõÂ§âÊèõ
        self.input_proj = nn.Linear(in_dim, hidden_dim)

    def forward(self, x, edge_index):
        &quot;&quot;&quot;
        Parameters:
        -----------
        x : Tensor (num_nodes, in_dim)
            È†ÇÁÇπÁâπÂæ¥Ë°åÂàó
        edge_index : Tensor (2, num_edges)
            Ëæ∫„ÅÆ„É™„Çπ„Éà [[src], [dst]]

        Returns:
        --------
        h : Tensor (num_nodes, hidden_dim)
            Êõ¥Êñ∞„Åï„Çå„ÅüÈ†ÇÁÇπÁâπÂæ¥
        &quot;&quot;&quot;
        # ÂÖ•ÂäõÂ§âÊèõ
        h = self.input_proj(x)

        # „É°„ÉÉ„Çª„Éº„Ç∏„Éë„ÉÉ„Ç∑„É≥„Ç∞„ÅÆ„É¨„Ç§„É§„Éº
        for layer in range(self.num_layers):
            h_new = []

            # ÂêÑÈ†ÇÁÇπ„ÇíÊõ¥Êñ∞
            for i in range(x.size(0)):
                # Èö£Êé•È†ÇÁÇπ„ÇíÂèñÂæó
                neighbors = edge_index[1][edge_index[0] == i]

                if len(neighbors) &gt; 0:
                    # „Çπ„ÉÜ„ÉÉ„Éó1: „É°„ÉÉ„Çª„Éº„Ç∏ÁîüÊàê
                    messages = self.message_fns[layer](h[neighbors])

                    # „Çπ„ÉÜ„ÉÉ„Éó2: ÈõÜÁ¥Ñ
                    m_i = torch.mean(messages, dim=0)

                    # „Çπ„ÉÜ„ÉÉ„Éó3: Êõ¥Êñ∞
                    h_i_new = self.update_fns[layer](h[i], m_i)
                else:
                    # Èö£Êé•È†ÇÁÇπ„Åå„Å™„ÅÑÂ†¥Âêà
                    h_i_new = h[i]

                h_new.append(h_i_new)

            h = torch.stack(h_new)

        return h

# ‰ΩøÁî®‰æã
model = SimpleGNN(in_dim=16, hidden_dim=32, num_layers=3)

# „Ç∞„É©„Éï„Éá„Éº„ÇøÔºà‰∏âËßíÂΩ¢Ôºâ
x = torch.randn(3, 16)  # 3È†ÇÁÇπ„ÄÅ16Ê¨°ÂÖÉÁâπÂæ¥
edge_index = torch.tensor([
    [0, 0, 1, 1, 2, 2],  # ÂßãÁÇπ
    [1, 2, 0, 2, 0, 1]   # ÁµÇÁÇπ
])

# È†Ü‰ºùÊí≠
h_out = model(x, edge_index)
print(f&quot;Âá∫ÂäõÂΩ¢Áä∂: {h_out.shape}&quot;)
# Âá∫Âäõ: torch.Size([3, 32])
</code></pre>
<hr />
<h2>2.3 ‰ª£Ë°®ÁöÑ„Å™GNN„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£</h2>
<h3>Graph Convolutional Network (GCN)</h3>
<p><strong>Ë´ñÊñá</strong>: Kipf &amp; Welling (2017), <em>ICLR</em></p>
<p><strong>Ê†∏ÂøÉ„Ç¢„Ç§„Éá„Ç¢</strong>: „Ç∞„É©„Éï„ÅÆ„Çπ„Éö„ÇØ„Éà„É´Áï≥„ÅøËæº„Åø</p>
<p><strong>Êõ¥Êñ∞Âºè</strong>:
$$
H^{(l+1)} = \sigma\left( \tilde{D}^{-1/2} \tilde{A} \tilde{D}^{-1/2} H^{(l)} W^{(l)} \right)
$$</p>
<ul>
<li>$\tilde{A} = A + I$: Ëá™Â∑±„É´„Éº„Éó‰ªò„ÅçÈö£Êé•Ë°åÂàó</li>
<li>$\tilde{D}_{ii} = \sum_j \tilde{A}_{ij}$: Ê¨°Êï∞Ë°åÂàó</li>
<li>$H^{(l)} \in \mathbb{R}^{n \times d}$: „É¨„Ç§„É§„Éº $l$ „ÅÆÁâπÂæ¥Èáè</li>
<li>$W^{(l)} \in \mathbb{R}^{d \times d'}$: Â≠¶ÁøíÂèØËÉΩ„Å™Èáç„Åø</li>
</ul>
<p><strong>Python„Åß„ÅÆÂÆüË£Ö</strong>:</p>
<pre><code class="language-python">import torch
import torch.nn as nn
import torch.nn.functional as F

class GCNLayer(nn.Module):
    def __init__(self, in_features, out_features):
        super().__init__()
        self.linear = nn.Linear(in_features, out_features)

    def forward(self, X, A):
        &quot;&quot;&quot;
        Parameters:
        -----------
        X : Tensor (num_nodes, in_features)
            È†ÇÁÇπÁâπÂæ¥Ë°åÂàó
        A : Tensor (num_nodes, num_nodes)
            Èö£Êé•Ë°åÂàó

        Returns:
        --------
        H : Tensor (num_nodes, out_features)
            Êõ¥Êñ∞„Åï„Çå„ÅüÁâπÂæ¥Èáè
        &quot;&quot;&quot;
        # Ëá™Â∑±„É´„Éº„Éó„ÅÆËøΩÂä†
        A_tilde = A + torch.eye(A.size(0), device=A.device)

        # Ê¨°Êï∞Ë°åÂàó
        D_tilde = torch.diag(A_tilde.sum(dim=1))

        # Ê≠£Ë¶èÂåñ: D^(-1/2) * A * D^(-1/2)
        D_inv_sqrt = torch.diag(1.0 / torch.sqrt(D_tilde.diagonal()))
        A_norm = D_inv_sqrt @ A_tilde @ D_inv_sqrt

        # „Ç∞„É©„ÉïÁï≥„ÅøËæº„Åø
        H = A_norm @ X
        H = self.linear(H)
        return F.relu(H)

# ‰ΩøÁî®‰æã
gcn = GCNLayer(in_features=16, out_features=32)

# „Ç∞„É©„Éï„Éá„Éº„Çø
X = torch.randn(5, 16)  # 5È†ÇÁÇπ„ÄÅ16Ê¨°ÂÖÉ
A = torch.tensor([
    [0, 1, 1, 0, 0],
    [1, 0, 1, 1, 0],
    [1, 1, 0, 1, 1],
    [0, 1, 1, 0, 1],
    [0, 0, 1, 1, 0]
], dtype=torch.float32)

H = gcn(X, A)
print(f&quot;GCNÂá∫ÂäõÂΩ¢Áä∂: {H.shape}&quot;)
# Âá∫Âäõ: torch.Size([5, 32])
</code></pre>
<p><strong>ÁâπÂæ¥</strong>:
- ‚úÖ „Ç∑„É≥„Éó„É´„ÅßÈ´òÈÄü
- ‚úÖ ÈÅéÂâ∞Âπ≥ÊªëÂåñÔºàover-smoothingÔºâ„Å´Ê≥®ÊÑè
- ‚úÖ Âõ∫ÂÆöÁöÑ„Å™Èáç„ÅøÔºàÂÖ®Èö£Êé•È†ÇÁÇπ„ÅåÂêå„ÅòÊâ±„ÅÑÔºâ</p>
<hr />
<h3>Graph Attention Network (GAT)</h3>
<p><strong>Ë´ñÊñá</strong>: Veliƒçkoviƒá et al. (2018), <em>ICLR</em></p>
<p><strong>Ê†∏ÂøÉ„Ç¢„Ç§„Éá„Ç¢</strong>: Attention„ÅßÈáçË¶Å„Å™Èö£Êé•È†ÇÁÇπ„ÇíÈáçË¶ñ</p>
<p><strong>Attention‰øÇÊï∞</strong>:
$$
\alpha_{ij} = \frac{\exp\left( \text{LeakyReLU}(a^T [W h_i | W h_j]) \right)}
{\sum_{k \in \mathcal{N}(i)} \exp\left( \text{LeakyReLU}(a^T [W h_i | W h_k]) \right)}
$$</p>
<p><strong>Êõ¥Êñ∞Âºè</strong>:
$$
h_i^{(l+1)} = \sigma\left( \sum_{j \in \mathcal{N}(i)} \alpha_{ij} W^{(l)} h_j^{(l)} \right)
$$</p>
<pre><code class="language-python">class GATLayer(nn.Module):
    def __init__(self, in_features, out_features, dropout=0.6,
                 alpha=0.2):
        super().__init__()
        self.W = nn.Linear(in_features, out_features, bias=False)
        self.a = nn.Parameter(torch.zeros(2 * out_features, 1))
        self.leakyrelu = nn.LeakyReLU(alpha)
        self.dropout = nn.Dropout(dropout)

        nn.init.xavier_uniform_(self.a.data, gain=1.414)

    def forward(self, X, A):
        &quot;&quot;&quot;
        Parameters:
        -----------
        X : Tensor (num_nodes, in_features)
        A : Tensor (num_nodes, num_nodes)

        Returns:
        --------
        H : Tensor (num_nodes, out_features)
        &quot;&quot;&quot;
        # Á∑öÂΩ¢Â§âÊèõ
        Wh = self.W(X)  # (N, out_features)
        N = Wh.size(0)

        # AttentionË®àÁÆó
        # [Wh_i || Wh_j] for all edges
        Wh_repeat_interleave = Wh.repeat_interleave(N, dim=0)
        Wh_repeat = Wh.repeat(N, 1)
        concat = torch.cat([Wh_repeat_interleave, Wh_repeat], dim=1)
        concat = concat.view(N, N, -1)

        # Attention score
        e = self.leakyrelu(concat @ self.a).squeeze(2)

        # „Éû„Çπ„ÇØÔºàËæ∫„Åå„Å™„ÅÑÂ†¥Âêà„ÅØ-infÔºâ
        zero_vec = -9e15 * torch.ones_like(e)
        attention = torch.where(A &gt; 0, e, zero_vec)

        # Softmax
        attention = F.softmax(attention, dim=1)
        attention = self.dropout(attention)

        # Weighted sum
        H = torch.matmul(attention, Wh)
        return F.elu(H)

# ‰ΩøÁî®‰æã
gat = GATLayer(in_features=16, out_features=32)
H_gat = gat(X, A)
print(f&quot;GATÂá∫ÂäõÂΩ¢Áä∂: {H_gat.shape}&quot;)
# Âá∫Âäõ: torch.Size([5, 32])
</code></pre>
<p><strong>ÁâπÂæ¥</strong>:
- ‚úÖ ÂãïÁöÑ„Å™Èáç„ÅøÔºàÈáçË¶Å„Å™Èö£Êé•È†ÇÁÇπ„ÇíËá™ÂãïÂ≠¶ÁøíÔºâ
- ‚úÖ Ëß£ÈáàÂèØËÉΩÊÄßÔºàAttention‰øÇÊï∞„ÅÆÂèØË¶ñÂåñÔºâ
- ‚ùå Ë®àÁÆó„Ç≥„Çπ„Éà„ÅåÈ´ò„ÅÑÔºàGCN„ÅÆÁ¥Ñ2ÂÄçÔºâ</p>
<hr />
<h3>GraphSAGEÔºàSAmple and aggreGatEÔºâ</h3>
<p><strong>Ë´ñÊñá</strong>: Hamilton et al. (2017), <em>NeurIPS</em></p>
<p><strong>Ê†∏ÂøÉ„Ç¢„Ç§„Éá„Ç¢</strong>: „Éü„Éã„Éê„ÉÉ„ÉÅÂ≠¶Áøí„ÅÆ„Åü„ÇÅ„ÅÆ„Çµ„É≥„Éó„É™„É≥„Ç∞</p>
<p><strong>Êõ¥Êñ∞Âºè</strong>:
$$
h_i^{(l+1)} = \sigma\left( W \cdot \text{Concat}\left( h_i^{(l)}, \text{Aggregate}({h_j^{(l)} : j \in \mathcal{S}(i)}) \right) \right)
$$</p>
<ul>
<li>$\mathcal{S}(i)$: „Çµ„É≥„Éó„É™„É≥„Ç∞„Åï„Çå„ÅüÈö£Êé•È†ÇÁÇπÔºàÂÖ®„Å¶„Åß„ÅØ„Å™„ÅÑÔºâ</li>
</ul>
<pre><code class="language-python">class GraphSAGELayer(nn.Module):
    def __init__(self, in_features, out_features, num_samples=10):
        super().__init__()
        self.num_samples = num_samples
        # ConcatÁâà: ÂÖ•Âäõ„ÅØ in_features * 2
        self.linear = nn.Linear(in_features * 2, out_features)

    def forward(self, X, A):
        &quot;&quot;&quot;
        Parameters:
        -----------
        X : Tensor (num_nodes, in_features)
        A : Tensor (num_nodes, num_nodes)

        Returns:
        --------
        H : Tensor (num_nodes, out_features)
        &quot;&quot;&quot;
        N = X.size(0)
        H_new = []

        for i in range(N):
            # Èö£Êé•È†ÇÁÇπ„ÅÆ„Çµ„É≥„Éó„É™„É≥„Ç∞
            neighbors = torch.nonzero(A[i]).squeeze()
            if neighbors.numel() &gt; self.num_samples:
                # „É©„É≥„ÉÄ„É†„Çµ„É≥„Éó„É™„É≥„Ç∞
                perm = torch.randperm(neighbors.numel())
                sampled = neighbors[perm[:self.num_samples]]
            else:
                sampled = neighbors

            # ÈõÜÁ¥ÑÔºàMeanÔºâ
            if sampled.numel() &gt; 0:
                h_neighbors = X[sampled]
                h_agg = torch.mean(h_neighbors, dim=0)
            else:
                h_agg = torch.zeros_like(X[i])

            # Concat
            h_concat = torch.cat([X[i], h_agg], dim=0)

            # Á∑öÂΩ¢Â§âÊèõ
            h_new = self.linear(h_concat)
            H_new.append(h_new)

        H = torch.stack(H_new)
        return F.relu(H)

# ‰ΩøÁî®‰æã
sage = GraphSAGELayer(in_features=16, out_features=32,
                      num_samples=3)
H_sage = sage(X, A)
print(f&quot;GraphSAGEÂá∫ÂäõÂΩ¢Áä∂: {H_sage.shape}&quot;)
# Âá∫Âäõ: torch.Size([5, 32])
</code></pre>
<p><strong>ÁâπÂæ¥</strong>:
- ‚úÖ „Çπ„Ç±„Éº„É©„Éñ„É´ÔºàÂ§ßË¶èÊ®°„Ç∞„É©„Éï„Å´ÂØæÂøúÔºâ
- ‚úÖ „Éü„Éã„Éê„ÉÉ„ÉÅË®ìÁ∑¥„ÅåÂèØËÉΩ
- ‚úÖ Â∏∞Á¥çÁöÑÂ≠¶ÁøíÔºàÊñ∞„Åó„ÅÑÈ†ÇÁÇπ„Å∏„ÅÆÊ±éÂåñÔºâ</p>
<hr />
<h3>3„Å§„ÅÆGNN„ÅÆÊØîËºÉ</h3>
<div class="mermaid">
flowchart TD
    A[GNNÈÅ∏Êäû] --> B{„Éá„Éº„Çø„Çµ„Ç§„Ç∫}
    B -->|Â∞èË¶èÊ®°\n10kÈ†ÇÁÇπ| C[GCN]
    B -->|‰∏≠Ë¶èÊ®°\n10k-100k| D[GAT]
    B -->|Â§ßË¶èÊ®°\n100k+| E[GraphSAGE]

    C --> F[„Ç∑„É≥„Éó„É´„ÄÅÈ´òÈÄü]
    D --> G[È´òÁ≤æÂ∫¶„ÄÅËß£ÈáàÊÄß]
    E --> H[„Çπ„Ç±„Éº„É©„Éñ„É´]

    style A fill:#e3f2fd
    style C fill:#fff3e0
    style D fill:#f3e5f5
    style E fill:#e8f5e9
</div>

<table>
<thead>
<tr>
<th>ÊâãÊ≥ï</th>
<th>Ë®àÁÆóÈáè</th>
<th>Á≤æÂ∫¶</th>
<th>„Çπ„Ç±„Éº„É©„Éì„É™„ÉÜ„Ç£</th>
<th>Ëß£ÈáàÊÄß</th>
<th>Êé®Â•®Áî®ÈÄî</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>GCN</strong></td>
<td>$O(m \cdot d^2)$</td>
<td>‰∏≠</td>
<td>‰Ωé</td>
<td>‰∏≠</td>
<td>Â∞èË¶èÊ®°„ÄÅ„Éó„É≠„Éà„Çø„Ç§„Éî„É≥„Ç∞</td>
</tr>
<tr>
<td><strong>GAT</strong></td>
<td>$O(m \cdot d^2 + n \cdot d)$</td>
<td>È´ò</td>
<td>‰∏≠</td>
<td>È´ò</td>
<td>‰∏≠Ë¶èÊ®°„ÄÅÈ´òÁ≤æÂ∫¶Ë¶ÅÊ±Ç</td>
</tr>
<tr>
<td><strong>GraphSAGE</strong></td>
<td>$O(k \cdot s \cdot d^2)$</td>
<td>‰∏≠„ÄúÈ´ò</td>
<td>È´ò</td>
<td>‰∏≠</td>
<td>Â§ßË¶èÊ®°„ÄÅÂÆüÊôÇÈñì‰∫àÊ∏¨</td>
</tr>
</tbody>
</table>
<ul>
<li>$m$: Ëæ∫Êï∞</li>
<li>$n$: È†ÇÁÇπÊï∞</li>
<li>$d$: ÁâπÂæ¥Ê¨°ÂÖÉ</li>
<li>$k$: „É¨„Ç§„É§„ÉºÊï∞</li>
<li>$s$: „Çµ„É≥„Éó„É´Êï∞</li>
</ul>
<hr />
<h2>2.4 ÊùêÊñôÁßëÂ≠¶ÁâπÂåñGNN</h2>
<h3>SchNetÔºàContinuous-filter Convolutional NNÔºâ</h3>
<p><strong>Ë´ñÊñá</strong>: Sch√ºtt et al. (2017), <em>NeurIPS</em></p>
<p><strong>ÂØæË±°</strong>: ÂàÜÂ≠ê„ÉªÊùêÊñô„ÅÆ<strong>ÈáèÂ≠êÂåñÂ≠¶ÁâπÊÄß</strong>‰∫àÊ∏¨</p>
<p><strong>Ê†∏ÂøÉ„Ç¢„Ç§„Éá„Ç¢</strong>:
1. <strong>ÈÄ£Á∂ö„Éï„Ç£„É´„Çø</strong>: Èõ¢Êï£„Ç∞„É©„Éï„Åß„ÅØ„Å™„Åè3DÁ©∫Èñì„Åß„ÅÆÁï≥„ÅøËæº„Åø
2. <strong>Ë∑ùÈõ¢‰æùÂ≠ò</strong>: ÂéüÂ≠êÈñìË∑ùÈõ¢„ÇíÊòéÁ§∫ÁöÑ„Å´„É¢„Éá„É´Âåñ</p>
<p><strong>„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£</strong>:</p>
<div class="mermaid">
flowchart LR
    A[ÂéüÂ≠êÁâπÂæ¥] --> B[Âüã„ÇÅËæº„ÅøÂ±§]
    B --> C[Áõ∏‰∫í‰ΩúÁî®„Éñ„É≠„ÉÉ„ÇØ 1]
    C --> D[Áõ∏‰∫í‰ΩúÁî®„Éñ„É≠„ÉÉ„ÇØ 2]
    D --> E[Áõ∏‰∫í‰ΩúÁî®„Éñ„É≠„ÉÉ„ÇØ 3]
    E --> F[Âá∫ÂäõÂ±§]

    G[ÂéüÂ≠êÈñìË∑ùÈõ¢] --> C
    G --> D
    G --> E

    style A fill:#e3f2fd
    style B fill:#fff3e0
    style C fill:#f3e5f5
    style D fill:#e8f5e9
    style E fill:#ffebee
    style F fill:#fff9c4
    style G fill:#e1bee7
</div>

<p><strong>Êï∞Âºè</strong>:
$$
h_i^{(l+1)} = h_i^{(l)} + \sum_{j \in \mathcal{N}(i)} h_j^{(l)} \odot \phi\left( |r_i - r_j| \right)
$$</p>
<ul>
<li>$\phi(d)$: <strong>ÈÄ£Á∂ö„Éï„Ç£„É´„ÇøÈñ¢Êï∞</strong>ÔºàË∑ùÈõ¢ $d$ „Å´‰æùÂ≠òÔºâ</li>
<li>$r_i, r_j$: ÂéüÂ≠ê„ÅÆ3DÂ∫ßÊ®ô</li>
</ul>
<p><strong>„Éï„Ç£„É´„ÇøÈñ¢Êï∞</strong>:
$$
\phi(d) = \sum_{k=1}^{K} w_k \exp\left( -\gamma (d - \mu_k)^2 \right)
$$</p>
<ul>
<li>„Ç¨„Ç¶„ÇπÂü∫Â∫ïÂ±ïÈñãÔºàRBF: Radial Basis FunctionÔºâ</li>
</ul>
<pre><code class="language-python">import torch
import torch.nn as nn

class GaussianBasis(nn.Module):
    def __init__(self, start=0.0, stop=5.0, num_gaussians=50):
        super().__init__()
        self.mu = nn.Parameter(
            torch.linspace(start, stop, num_gaussians),
            requires_grad=False
        )
        self.gamma = nn.Parameter(
            torch.tensor(10.0),
            requires_grad=True
        )

    def forward(self, distances):
        &quot;&quot;&quot;
        Parameters:
        -----------
        distances : Tensor (num_edges,)
            ÂéüÂ≠êÈñìË∑ùÈõ¢

        Returns:
        --------
        rbf : Tensor (num_edges, num_gaussians)
            „Ç¨„Ç¶„ÇπÂü∫Â∫ïÂ±ïÈñã
        &quot;&quot;&quot;
        # (num_edges, 1) - (1, num_gaussians)
        diff = distances.unsqueeze(-1) - self.mu.unsqueeze(0)
        rbf = torch.exp(-self.gamma * diff ** 2)
        return rbf

class SchNetInteraction(nn.Module):
    def __init__(self, hidden_dim, num_gaussians):
        super().__init__()
        self.rbf_layer = GaussianBasis(num_gaussians=num_gaussians)
        self.filter_net = nn.Sequential(
            nn.Linear(num_gaussians, hidden_dim),
            nn.Softplus(),
            nn.Linear(hidden_dim, hidden_dim)
        )
        self.linear = nn.Linear(hidden_dim, hidden_dim)

    def forward(self, h, edge_index, distances):
        &quot;&quot;&quot;
        Parameters:
        -----------
        h : Tensor (num_atoms, hidden_dim)
            ÂéüÂ≠êÁâπÂæ¥
        edge_index : Tensor (2, num_edges)
            Ëæ∫„ÅÆ„É™„Çπ„Éà
        distances : Tensor (num_edges,)
            ÂéüÂ≠êÈñìË∑ùÈõ¢

        Returns:
        --------
        h_new : Tensor (num_atoms, hidden_dim)
            Êõ¥Êñ∞„Åï„Çå„ÅüÁâπÂæ¥
        &quot;&quot;&quot;
        # RBFÂ±ïÈñã
        rbf = self.rbf_layer(distances)

        # „Éï„Ç£„É´„ÇøÁîüÊàê
        W = self.filter_net(rbf)

        # „É°„ÉÉ„Çª„Éº„Ç∏„Éë„ÉÉ„Ç∑„É≥„Ç∞
        src, dst = edge_index
        messages = h[dst] * W  # Ë¶ÅÁ¥†Á©ç

        # ÈõÜÁ¥Ñ
        h_agg = torch.zeros_like(h)
        h_agg.index_add_(0, src, messages)

        # Êõ¥Êñ∞
        h_new = h + self.linear(h_agg)
        return h_new

# ‰ΩøÁî®‰æã
schnet_layer = SchNetInteraction(hidden_dim=128,
                                 num_gaussians=50)

# „Éá„Éº„Çø
num_atoms = 5
h = torch.randn(num_atoms, 128)
edge_index = torch.tensor([[0, 1, 2, 3], [1, 2, 3, 4]])
distances = torch.tensor([1.5, 1.8, 2.0, 1.6])

h_new = schnet_layer(h, edge_index, distances)
print(f&quot;SchNetÂá∫ÂäõÂΩ¢Áä∂: {h_new.shape}&quot;)
# Âá∫Âäõ: torch.Size([5, 128])
</code></pre>
<p><strong>ÈÅ©Áî®‰æã</strong>:
- QM9„Éá„Éº„Çø„Çª„ÉÉ„ÉàÔºàÂàÜÂ≠êÁâπÊÄß‰∫àÊ∏¨Ôºâ
- MD17ÔºàÂàÜÂ≠êÂãïÂäõÂ≠¶Ôºâ
- OC20ÔºàËß¶Â™íÂê∏ÁùÄ„Ç®„Éç„É´„ÇÆ„ÉºÔºâ</p>
<p><strong>ÊÄßËÉΩ</strong>:</p>
<pre><code>QM9 HOMO-LUMO gap:
- DFTË®àÁÆó: 24ÊôÇÈñì/ÂàÜÂ≠ê
- SchNet: 0.01Áßí/ÂàÜÂ≠êÔºàMAE=0.04 eVÔºâ
</code></pre>
<hr />
<h3>DimeNetÔºàDirectional Message Passing NNÔºâ</h3>
<p><strong>Ë´ñÊñá</strong>: Klicpera et al. (2020), <em>ICLR</em></p>
<p><strong>Êã°Âºµ</strong>: <strong>ÁµêÂêàËßí</strong>„ÇÇËÄÉÊÖÆ</p>
<p><strong>Ê†∏ÂøÉ„Ç¢„Ç§„Éá„Ç¢</strong>:
- Ë∑ùÈõ¢„Å†„Åë„Åß„Å™„Åè<strong>ËßíÂ∫¶ÊÉÖÂ†±</strong>„ÇÇÂà©Áî®
- 3‰ΩìÁõ∏‰∫í‰ΩúÁî®Ôºàtriplet interactionÔºâ</p>
<p><strong>Êõ¥Êñ∞Âºè</strong>:
$$
m_{ij} = \sum_{k \in \mathcal{N}(j) \setminus {i}} W\left( d_{ij}, d_{jk}, \theta_{ijk} \right) h_k
$$</p>
<ul>
<li>$\theta_{ijk}$: ËßíÂ∫¶ $\angle i-j-k$</li>
</ul>
<div class="mermaid">
flowchart TD
    A[ÂéüÂ≠ê i] --|d_ij| B[ÂéüÂ≠ê j]
    B --|d_jk| C[ÂéüÂ≠ê k]
    A - ËßíÂ∫¶Œ∏_ijk .-> C

    style A fill:#e3f2fd
    style B fill:#fff3e0
    style C fill:#f3e5f5
</div>

<p><strong>ËßíÂ∫¶„ÅÆË®àÁÆó</strong>:</p>
<pre><code class="language-python">import torch

def compute_angle(pos_i, pos_j, pos_k):
    &quot;&quot;&quot;
    3ÂéüÂ≠êÈñì„ÅÆËßíÂ∫¶„ÇíË®àÁÆó

    Parameters:
    -----------
    pos_i, pos_j, pos_k : Tensor (3,)
        ÂéüÂ≠ê„ÅÆ3DÂ∫ßÊ®ô

    Returns:
    --------
    angle : Tensor (1,)
        ËßíÂ∫¶Ôºà„É©„Ç∏„Ç¢„É≥Ôºâ
    &quot;&quot;&quot;
    # „Éô„ÇØ„Éà„É´
    v_ij = pos_j - pos_i
    v_jk = pos_k - pos_j

    # ÂÜÖÁ©ç
    cos_angle = torch.dot(v_ij, v_jk) / (
        torch.norm(v_ij) * torch.norm(v_jk) + 1e-8
    )

    # ËßíÂ∫¶
    angle = torch.acos(torch.clamp(cos_angle, -1.0, 1.0))
    return angle

# ‰æãÔºöÊ∞¥ÂàÜÂ≠ê„ÅÆÁµêÂêàËßíÔºàH-O-HÔºâ
pos_O = torch.tensor([0.0, 0.0, 0.0])
pos_H1 = torch.tensor([0.96, 0.0, 0.0])
pos_H2 = torch.tensor([0.24, 0.93, 0.0])

angle = compute_angle(pos_H1, pos_O, pos_H2)
print(f&quot;H-O-HËßíÂ∫¶: {torch.rad2deg(angle):.1f}¬∞&quot;)
# Âá∫Âäõ: 104.5¬∞ÔºàÂÆüÊ∏¨ÂÄ§„Å®„Åª„Åº‰∏ÄËá¥Ôºâ
</code></pre>
<p><strong>ÊÄßËÉΩ</strong>:</p>
<pre><code>QM9„Éá„Éº„Çø„Çª„ÉÉ„Éà:
- SchNet: MAE=0.041 eV
- DimeNet: MAE=0.033 eVÔºà20%ÊîπÂñÑÔºâ

Ë®àÁÆóÊôÇÈñì:
- SchNet: 0.01Áßí/ÂàÜÂ≠ê
- DimeNet: 0.05Áßí/ÂàÜÂ≠êÔºà5ÂÄçÈÅÖ„ÅÑÔºâ
</code></pre>
<hr />
<h3>GemNetÔºàGeometric Message Passing NNÔºâ</h3>
<p><strong>Ë´ñÊñá</strong>: Gasteiger et al. (2021), <em>NeurIPS</em></p>
<p><strong>„Åï„Çâ„Å™„ÇãÊã°Âºµ</strong>: <strong>4‰ΩìÁõ∏‰∫í‰ΩúÁî®</strong>Ôºà‰∫åÈù¢ËßíÔºâ</p>
<p><strong>ÂØæË±°</strong>: ÁµêÊô∂ÊßãÈÄ†„ÄÅË§áÈõë„Å™ÂàÜÂ≠ê</p>
<p><strong>Ê†∏ÂøÉ„Ç¢„Ç§„Éá„Ç¢</strong>:
- ‰∫åÈù¢ËßíÔºàtorsion angleÔºâ„ÅÆËÄÉÊÖÆ
- „Çà„ÇäÈ´òÊ¨°„ÅÆÂπæ‰ΩïÂ≠¶ÁöÑÊÉÖÂ†±</p>
<div class="mermaid">
flowchart LR
    A[ÂéüÂ≠ê i] --- B[ÂéüÂ≠ê j]
    B --- C[ÂéüÂ≠ê k]
    C --- D[ÂéüÂ≠ê l]

    A - ‰∫åÈù¢ËßíœÜ .-> D

    style A fill:#e3f2fd
    style B fill:#fff3e0
    style C fill:#f3e5f5
    style D fill:#e8f5e9
</div>

<p><strong>ÊÄßËÉΩ</strong>:</p>
<pre><code>OC20„Éá„Éº„Çø„Çª„ÉÉ„ÉàÔºàËß¶Â™íÔºâ:
- SchNet: MAE=0.61 eV
- DimeNet++: MAE=0.49 eV
- GemNet: MAE=0.43 eVÔºàÊúÄÈ´òÁ≤æÂ∫¶Ôºâ
</code></pre>
<hr />
<h3>ÊùêÊñôÁßëÂ≠¶GNN„ÅÆÊØîËºÉ</h3>
<table>
<thead>
<tr>
<th>ÊâãÊ≥ï</th>
<th>ËÄÉÊÖÆ„Åô„ÇãÊÉÖÂ†±</th>
<th>Á≤æÂ∫¶</th>
<th>ÈÄüÂ∫¶</th>
<th>Êé®Â•®Áî®ÈÄî</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>SchNet</strong></td>
<td>Ë∑ùÈõ¢</td>
<td>‰∏≠</td>
<td>ÈÄü„ÅÑ</td>
<td>ÂàÜÂ≠êÁâπÊÄß‰∫àÊ∏¨</td>
</tr>
<tr>
<td><strong>DimeNet</strong></td>
<td>Ë∑ùÈõ¢ + ËßíÂ∫¶</td>
<td>È´ò</td>
<td>‰∏≠</td>
<td>Ëß¶Â™í„ÄÅË§áÈõë„Å™ÂàÜÂ≠ê</td>
</tr>
<tr>
<td><strong>GemNet</strong></td>
<td>Ë∑ùÈõ¢ + ËßíÂ∫¶ + ‰∫åÈù¢Ëßí</td>
<td>ÊúÄÈ´ò</td>
<td>ÈÅÖ„ÅÑ</td>
<td>ÁµêÊô∂„ÄÅÈ´òÁ≤æÂ∫¶Ë¶ÅÊ±Ç</td>
</tr>
</tbody>
</table>
<hr />
<h2>2.5 Á≠âÂ§âÊÄßÔºàEquivarianceÔºâ„ÅÆÈáçË¶ÅÊÄß</h2>
<h3>Á≠âÂ§âÊÄß„Å®„ÅØ</h3>
<p><strong>ÂÆöÁæ©</strong>:</p>
<blockquote>
<p>Èñ¢Êï∞ $f$ „ÅåÂ§âÊèõ $T$ „Å´ÂØæ„Åó„Å¶<strong>Á≠âÂ§â</strong>ÔºàequivariantÔºâ„Åß„ÅÇ„Çã„Å®„ÅØ„ÄÅ
$$f(T(x)) = T(f(x))$$
„ÅåÊàê„ÇäÁ´ã„Å§„Åì„Å®„ÄÇ</p>
</blockquote>
<p><strong>ÊùêÊñôÁßëÂ≠¶„Åß„ÅÆÊÑèÂë≥</strong>:
- ÂàÜÂ≠ê„ÇíÂõûËª¢„Éª‰∏¶ÈÄ≤„Åó„Å¶„ÇÇ„ÄÅ‰∫àÊ∏¨„ÅØÂêå„ÅòÔºà„Åæ„Åü„ÅØÂØæÂøú„Åô„ÇãÂ§âÊèõÔºâ</p>
<hr />
<h3>E(3)Á≠âÂ§âÊÄß</h3>
<p><strong>E(3)Áæ§</strong>: 3Ê¨°ÂÖÉ„É¶„Éº„ÇØ„É™„ÉÉ„ÉâÁ©∫Èñì„ÅÆÁ≠âÈï∑Â§âÊèõ
- ÂõûËª¢ÔºàRotationÔºâ
- ‰∏¶ÈÄ≤ÔºàTranslationÔºâ
- ÂèçËª¢ÔºàInversionÔºâ</p>
<p><strong>ÈáçË¶ÅÊÄß</strong>:
- Áâ©ÁêÜÊ≥ïÂâá„ÅØÂ∫ßÊ®ôÁ≥ª„Å´‰æùÂ≠ò„Åó„Å™„ÅÑ
- GNN„ÇÇÂêåÊßò„Åß„ÅÇ„Çã„Åπ„Åç</p>
<hr />
<h3>Á≠âÂ§âGNN„ÅÆ‰æãÔºöNequIP„ÄÅMACE</h3>
<p><strong>NequIP</strong> (Batzner et al., 2022):
- <strong>E(3)Á≠âÂ§â„É°„ÉÉ„Çª„Éº„Ç∏„Éë„ÉÉ„Ç∑„É≥„Ç∞</strong>
- ÁêÉÈù¢Ë™øÂíåÈñ¢Êï∞ÔºàSpherical HarmonicsÔºâ„ÅÆÂà©Áî®</p>
<p><strong>Êõ¥Êñ∞Âºè</strong>:
$$
m_{ij} = \phi\left( |r_i - r_j| \right) \otimes Y_l(r_{ij})
$$</p>
<ul>
<li>$Y_l$: ÁêÉÈù¢Ë™øÂíåÈñ¢Êï∞ÔºàËßíÂ∫¶ÊÉÖÂ†±„Çí‰øùÊåÅÔºâ</li>
<li>$\otimes$: „ÉÜ„É≥„ÇΩ„É´Á©ç</li>
</ul>
<p><strong>MACE</strong> (Batatia et al., 2022):
- <strong>È´òÊ¨°„ÅÆÁ≠âÂ§âÊÄß</strong>
- „Çà„ÇäÊ≠£Á¢∫„Å™ÂäõÂ†¥Ôºàforce fieldÔºâ‰∫àÊ∏¨</p>
<p><strong>ÊÄßËÉΩ</strong>:</p>
<pre><code>MD17„Éá„Éº„Çø„Çª„ÉÉ„ÉàÔºàÂàÜÂ≠êÂãïÂäõÂ≠¶Ôºâ:
- SchNet: MAE(Âäõ) = 0.21 kcal/mol/√Ö
- NequIP: MAE(Âäõ) = 0.05 kcal/mol/√ÖÔºà76%ÊîπÂñÑÔºâ
</code></pre>
<hr />
<h3>Á≠âÂ§âÊÄß„ÅÆ„ÉÜ„Çπ„Éà</h3>
<pre><code class="language-python">import torch
import torch.nn as nn

def test_equivariance(model, pos, edge_index):
    &quot;&quot;&quot;
    „É¢„Éá„É´„ÅÆÁ≠âÂ§âÊÄß„Çí„ÉÜ„Çπ„Éà
    &quot;&quot;&quot;
    # „Ç™„É™„Ç∏„Éä„É´„ÅÆ‰∫àÊ∏¨
    pred_original = model(pos, edge_index)

    # ÂõûËª¢Ë°åÂàóÔºà90Â∫¶ÂõûËª¢Ôºâ
    angle = torch.tensor(torch.pi / 2)
    rotation = torch.tensor([
        [torch.cos(angle), -torch.sin(angle), 0],
        [torch.sin(angle), torch.cos(angle), 0],
        [0, 0, 1]
    ])

    # Â∫ßÊ®ô„ÇíÂõûËª¢
    pos_rotated = pos @ rotation.T

    # ÂõûËª¢Âæå„ÅÆ‰∫àÊ∏¨
    pred_rotated = model(pos_rotated, edge_index)

    # ‰∫àÊ∏¨„ÇíÂõûËª¢
    pred_original_rotated = pred_original @ rotation.T

    # Ë™§Â∑Æ„ÇíË®àÁÆó
    error = torch.abs(pred_rotated - pred_original_rotated).mean()
    print(f&quot;Á≠âÂ§âÊÄßË™§Â∑Æ: {error.item():.6f}&quot;)

    if error &lt; 1e-5:
        print(&quot;‚úÖ „É¢„Éá„É´„ÅØÁ≠âÂ§â„Åß„Åô&quot;)
    else:
        print(&quot;‚ùå „É¢„Éá„É´„ÅØÁ≠âÂ§â„Åß„ÅØ„ÅÇ„Çä„Åæ„Åõ„Çì&quot;)

# ‰ΩøÁî®‰æãÔºàÁ∞°Áï•ÁâàÔºâ
class SimpleEquivariantModel(nn.Module):
    def forward(self, pos, edge_index):
        # Á∞°Áï•Âåñ: Â∫ßÊ®ô„ÅÆÂ∑ÆÂàÜ„ÇíË®àÁÆóÔºàÁ≠âÂ§âÔºâ
        src, dst = edge_index
        diff = pos[dst] - pos[src]
        return diff

model = SimpleEquivariantModel()
pos = torch.randn(5, 3)
edge_index = torch.tensor([[0, 1, 2], [1, 2, 3]])

test_equivariance(model, pos, edge_index)
</code></pre>
<hr />
<h2>2.6 „Ç≥„É©„É†Ôºö„Å™„ÅúÊ∑±„ÅÑGNN„ÅØÈõ£„Åó„ÅÑ„Åã</h2>
<h3>ÈÅéÂâ∞Âπ≥ÊªëÂåñÔºàOver-smoothingÔºâ</h3>
<p><strong>ÂïèÈ°å</strong>: „É¨„Ç§„É§„Éº„ÇíÊ∑±„Åè„Åô„Çã„Å®„ÄÅ<strong>ÂÖ®„Å¶„ÅÆÈ†ÇÁÇπ„ÅåÂêå„ÅòÁâπÂæ¥</strong>„Å´„Å™„Çã</p>
<p><strong>ÂéüÂõ†</strong>: „É°„ÉÉ„Çª„Éº„Ç∏„Éë„ÉÉ„Ç∑„É≥„Ç∞„ÅÆÁπ∞„ÇäËøî„Åó„ÅßÊÉÖÂ†±„ÅåÊã°Êï£</p>
<pre><code class="language-python"># ÈÅéÂâ∞Âπ≥ÊªëÂåñ„ÅÆ„Éá„É¢
import torch
import torch.nn.functional as F

def demonstrate_oversmoothing(X, A, num_layers=10):
    &quot;&quot;&quot;
    ÈÅéÂâ∞Âπ≥ÊªëÂåñ„ÅÆÂèØË¶ñÂåñ
    &quot;&quot;&quot;
    H = X
    smoothness = []

    for layer in range(num_layers):
        # Á∞°Âçò„Å™GCNÂ±§
        D = torch.diag(A.sum(dim=1))
        D_inv_sqrt = torch.diag(1.0 / torch.sqrt(D.diagonal()))
        A_norm = D_inv_sqrt @ A @ D_inv_sqrt

        H = A_norm @ H
        H = F.relu(H)

        # Âπ≥ÊªëÂ∫¶ÔºàÈ†ÇÁÇπÈñì„ÅÆÈ°û‰ººÂ∫¶Ôºâ
        similarity = F.cosine_similarity(
            H.unsqueeze(1), H.unsqueeze(0), dim=2
        )
        avg_similarity = similarity[torch.triu_indices(
            H.size(0), H.size(0), offset=1
        )[0], torch.triu_indices(
            H.size(0), H.size(0), offset=1
        )[1]].mean()

        smoothness.append(avg_similarity.item())
        print(f&quot;Layer {layer+1}: Âπ≥ÂùáÈ°û‰ººÂ∫¶ = {avg_similarity:.4f}&quot;)

    return smoothness

# ÂÆüË°å
X = torch.randn(5, 16)
A = torch.eye(5) + torch.rand(5, 5) &gt; 0.7
smoothness = demonstrate_oversmoothing(X, A.float(), num_layers=10)
</code></pre>
<p><strong>Âá∫Âäõ‰æã</strong>:</p>
<pre><code>Layer 1: Âπ≥ÂùáÈ°û‰ººÂ∫¶ = 0.2341
Layer 2: Âπ≥ÂùáÈ°û‰ººÂ∫¶ = 0.4523
Layer 3: Âπ≥ÂùáÈ°û‰ººÂ∫¶ = 0.6789
...
Layer 10: Âπ≥ÂùáÈ°û‰ººÂ∫¶ = 0.9876
</code></pre>
<p>‚Üí „É¨„Ç§„É§„Éº„ÅåÊ∑±„Åè„Å™„Çã„Å´„Å§„Çå„ÄÅÂÖ®È†ÇÁÇπ„Åå‰ºº„Å¶„Åè„Çã</p>
<hr />
<h3>ÂØæÁ≠ñ</h3>
<ol>
<li>
<p><strong>Residual ConnectionÔºàÊÆãÂ∑ÆÊé•Á∂öÔºâ</strong>:
   $$h_i^{(l+1)} = h_i^{(l)} + \text{GNN}(h_i^{(l)})$$</p>
</li>
<li>
<p><strong>Jumping Knowledge Network</strong>:
   - ÂÖ®„É¨„Ç§„É§„Éº„ÅÆÂá∫Âäõ„ÇíÁµêÂêà</p>
</li>
<li>
<p><strong>PairNorm</strong>:
   - ÁâπÂæ¥Èáè„ÅÆÊ≠£Ë¶èÂåñ</p>
</li>
</ol>
<pre><code class="language-python">class GNNWithResidual(nn.Module):
    def \_\_init\_\_(self, hidden\_dim):
        super().\_\_init\_\_()
        self.conv = GCNLayer(hidden\_dim, hidden\_dim)

    def forward(self, X, A):
        # Residual connection
        H = self.conv(X, A)
        return X + H  # „Ç∑„Éß„Éº„Éà„Ç´„ÉÉ„Éà
</code></pre>
<hr />
<h2>2.7 Êú¨Á´†„ÅÆ„Åæ„Å®„ÇÅ</h2>
<h3>Â≠¶„Çì„Å†„Åì„Å®</h3>
<ol>
<li>
<p><strong>„Ç∞„É©„Éï„ÅÆÊï∞Â≠¶ÁöÑÂÆöÁæ©</strong>
   - Èö£Êé•Ë°åÂàó„ÄÅÊ¨°Êï∞Ë°åÂàó„ÄÅ„É©„Éó„É©„Ç∑„Ç¢„É≥Ë°åÂàó
   - È†ÇÁÇπÁâπÂæ¥Èáè„Å®Ëæ∫ÁâπÂæ¥Èáè</p>
</li>
<li>
<p><strong>„É°„ÉÉ„Çª„Éº„Ç∏„Éë„ÉÉ„Ç∑„É≥„Ç∞</strong>
   - 3„Çπ„ÉÜ„ÉÉ„Éó: „É°„ÉÉ„Çª„Éº„Ç∏ÁîüÊàê ‚Üí ÈõÜÁ¥Ñ ‚Üí Êõ¥Êñ∞
   - ÈõÜÁ¥ÑÈñ¢Êï∞: Sum„ÄÅMean„ÄÅMax„ÄÅAttention</p>
</li>
<li>
<p><strong>‰ª£Ë°®ÁöÑGNN„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£</strong>
   - GCN: „Ç∑„É≥„Éó„É´„ÄÅÈ´òÈÄü
   - GAT: Attention„ÄÅÈ´òÁ≤æÂ∫¶
   - GraphSAGE: „Çπ„Ç±„Éº„É©„Éñ„É´„ÄÅ„Éü„Éã„Éê„ÉÉ„ÉÅ</p>
</li>
<li>
<p><strong>ÊùêÊñôÁßëÂ≠¶ÁâπÂåñGNN</strong>
   - SchNet: Ë∑ùÈõ¢‰æùÂ≠ò„ÄÅÈÄ£Á∂ö„Éï„Ç£„É´„Çø
   - DimeNet: ËßíÂ∫¶ÊÉÖÂ†±„ÇÇËÄÉÊÖÆ
   - GemNet: ‰∫åÈù¢Ëßí„Åæ„ÅßËÄÉÊÖÆ</p>
</li>
<li>
<p><strong>Á≠âÂ§âÊÄß</strong>
   - E(3)Á≠âÂ§âÊÄß„ÅÆÈáçË¶ÅÊÄß
   - NequIP„ÄÅMACE„Å™„Å©ÊúÄÊñ∞ÊâãÊ≥ï</p>
</li>
</ol>
<h3>ÈáçË¶Å„Å™„Éù„Ç§„É≥„Éà</h3>
<ul>
<li>‚úÖ „É°„ÉÉ„Çª„Éº„Ç∏„Éë„ÉÉ„Ç∑„É≥„Ç∞„ÅØGNN„ÅÆ<strong>Áµ±‰∏Ä„Éï„É¨„Éº„É†„ÉØ„Éº„ÇØ</strong></li>
<li>‚úÖ ÈõÜÁ¥ÑÈñ¢Êï∞„ÅÆÈÅ∏Êäû„ÅåÊÄßËÉΩ„Å´Â§ß„Åç„ÅèÂΩ±Èüø</li>
<li>‚úÖ ÊùêÊñôÁßëÂ≠¶„Åß„ÅØ<strong>Âπæ‰ΩïÂ≠¶ÁöÑÊÉÖÂ†±</strong>ÔºàË∑ùÈõ¢„ÄÅËßíÂ∫¶Ôºâ„ÅåÈáçË¶Å</li>
<li>‚úÖ Á≠âÂ§âÊÄß„Å´„Çà„Çä<strong>Áâ©ÁêÜÊ≥ïÂâá„Çí‰øùË®º</strong></li>
<li>‚úÖ ÈÅéÂâ∞Âπ≥ÊªëÂåñ„Å´Ê≥®ÊÑèÔºàResidual Connection„ÅßÂØæÁ≠ñÔºâ</li>
</ul>
<h3>Ê¨°„ÅÆÁ´†„Å∏</h3>
<p>Á¨¨3Á´†„Åß„ÅØ„ÄÅ<strong>PyTorch GeometricÂÆüË∑µ</strong>„ÇíÂ≠¶„Å≥„Åæ„ÅôÔºö
- Áí∞Â¢ÉÊßãÁØâÔºàPyG„ÄÅRDKit„ÄÅASEÔºâ
- QM9„Éá„Éº„Çø„Çª„ÉÉ„Éà„ÅßÂàÜÂ≠êÁâπÊÄß‰∫àÊ∏¨
- Materials Project„Éá„Éº„Çø„ÅßÁµêÊô∂ÁâπÊÄß‰∫àÊ∏¨
- „É¢„Éá„É´Ë©ï‰æ°„Å®„Éè„Ç§„Éë„Éº„Éë„É©„É°„Éº„Çø„ÉÅ„É•„Éº„Éã„É≥„Ç∞
- ÂÆüË∑µ„Éó„É≠„Ç∏„Çß„ÇØ„Éà</p>
<p><strong><a href="./chapter-3.html">Á¨¨3Á´†ÔºöPyTorch GeometricÂÆüË∑µ ‚Üí</a></strong></p>
<hr />
<h2>ÊºîÁøíÂïèÈ°å</h2>
<h3>ÂïèÈ°å1ÔºàÈõ£ÊòìÂ∫¶ÔºöeasyÔºâ</h3>
<p>Ê¨°„ÅÆÊñáÁ´†„ÅÆÊ≠£Ë™§„ÇíÂà§ÂÆö„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ</p>
<ol>
<li>„É°„ÉÉ„Çª„Éº„Ç∏„Éë„ÉÉ„Ç∑„É≥„Ç∞„ÅØ„ÄÅÈõÜÁ¥ÑÔºàAggregationÔºâ‚Üí Êõ¥Êñ∞ÔºàUpdateÔºâ‚Üí „É°„ÉÉ„Çª„Éº„Ç∏ÁîüÊàê„ÅÆÈ†Ü„ÅßË°å„Çè„Çå„Çã</li>
<li>GAT„ÅØAttention„Çí‰Ωø„ÅÜ„Åü„ÇÅ„ÄÅÂÖ®„Å¶„ÅÆÈö£Êé•È†ÇÁÇπ„ÇíÂêå„ÅòÈáç„Åø„ÅßÊâ±„ÅÜ</li>
<li>SchNet„ÅØÂéüÂ≠êÈñìË∑ùÈõ¢„ÇíÊòéÁ§∫ÁöÑ„Å´ËÄÉÊÖÆ„Åô„Çã</li>
</ol>
<details>
<summary>„Éí„É≥„Éà</summary>

- „É°„ÉÉ„Çª„Éº„Ç∏„Éë„ÉÉ„Ç∑„É≥„Ç∞„ÅÆ3„Çπ„ÉÜ„ÉÉ„Éó„ÇíÊÄù„ÅÑÂá∫„Åó„Åæ„Åó„Çá„ÅÜ
- GAT„ÅÆÊ†∏ÂøÉ„Ç¢„Ç§„Éá„Ç¢„ÅØ„ÄåÈáçË¶Å„Å™Èö£Êé•È†ÇÁÇπ„ÇíÈáçË¶ñ„Äç„Åß„Åô
- SchNet„ÅÆÁâπÂæ¥„ÅØ„ÄåÈÄ£Á∂ö„Éï„Ç£„É´„Çø„Äç„Åß„Åô

</details>

<details>
<summary>Ëß£Á≠î‰æã</summary>

**Ëß£Á≠î**:
1. **Ë™§** - Ê≠£„Åó„ÅÑÈ†ÜÁï™„ÅØÔºö„É°„ÉÉ„Çª„Éº„Ç∏ÁîüÊàê ‚Üí ÈõÜÁ¥Ñ ‚Üí Êõ¥Êñ∞
2. **Ë™§** - GAT„ÅØ Attention„Åß**Áï∞„Å™„ÇãÈáç„Åø**„ÇíÂâ≤„ÇäÂΩì„Å¶„Çã
3. **Ê≠£** - SchNet„ÅØRBFÔºà„Ç¨„Ç¶„ÇπÂü∫Â∫ïÔºâ„ÅßË∑ùÈõ¢„Çí„Ç®„É≥„Ç≥„Éº„Éâ

**Ëß£Ë™¨**:

1„Å´„Å§„ÅÑ„Å¶Ôºö

<pre><code class="language-python"># Ê≠£„Åó„ÅÑÈ†ÜÂ∫è
for layer in range(num\_layers):
    # Step 1: „É°„ÉÉ„Çª„Éº„Ç∏ÁîüÊàê
    messages = message\_function(h\_neighbors)

    # Step 2: ÈõÜÁ¥Ñ
    m\_i = aggregate(messages)

    # Step 3: Êõ¥Êñ∞
    h\_i = update\_function(h\_i, m\_i)
</code></pre>


2„Å´„Å§„ÅÑ„Å¶Ôºö
- GAT „ÅÆ Attention ‰øÇÊï∞ $\alpha\_{ij}$ „ÅØÈö£Êé•È†ÇÁÇπ„Åî„Å®„Å´Áï∞„Å™„Çã
- ÈáçË¶Å„Å™Èö£Êé•È†ÇÁÇπ„Å´„ÅØÂ§ß„Åç„Å™Èáç„Åø„ÄÅ„Åù„ÅÜ„Åß„Å™„ÅÑ„ÇÇ„ÅÆ„Å´„ÅØÂ∞è„Åï„Å™Èáç„Åø

3„Å´„Å§„ÅÑ„Å¶Ôºö
- SchNet „ÅÆ „Éï„Ç£„É´„ÇøÈñ¢Êï∞: $\phi(d) = \sum\_k w\_k \exp(-\gamma (d - \mu\_k)^2)$
- Ë∑ùÈõ¢ $d$ „ÅåÁï∞„Å™„Çå„Å∞„ÄÅ„Éï„Ç£„É´„Çø„ÅÆÂÄ§„ÇÇÁï∞„Å™„Çã

</details>

<hr />
<h3>ÂïèÈ°å2ÔºàÈõ£ÊòìÂ∫¶ÔºömediumÔºâ</h3>
<p>‰ª•‰∏ã„ÅÆ„Ç∞„É©„Éï„Å´ÂØæ„Åó„Å¶„ÄÅGCN„ÅÆ1Â±§„ÅÆÈ†Ü‰ºùÊí≠„ÇíÊâãË®àÁÆó„ÅßÊ±Ç„ÇÅ„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ</p>
<p><strong>„Ç∞„É©„Éï</strong>:</p>
<pre><code>È†ÇÁÇπ: 3ÂÄãÔºàv0, v1, v2Ôºâ
Ëæ∫: v0-v1, v1-v2ÔºàÁ∑öÂΩ¢„Ç∞„É©„ÉïÔºâ

È†ÇÁÇπÁâπÂæ¥:
X = [[1, 0],
     [0, 1],
     [1, 1]]

Èö£Êé•Ë°åÂàó:
A = [[0, 1, 0],
     [1, 0, 1],
     [0, 1, 0]]

Èáç„ÅøË°åÂàóÔºàÁ∞°Áï•ÂåñÔºâ:
W = [[1, 0],
     [0, 1]]  ÔºàÊÅíÁ≠âË°åÂàóÔºâ
</code></pre>
<p><strong>Ë¶ÅÊ±Ç‰∫ãÈ†Ö</strong>:
1. $\tilde{A} = A + I$ „ÇíË®àÁÆó
2. Ê≠£Ë¶èÂåñÈö£Êé•Ë°åÂàó $\hat{A} = \tilde{D}^{-1/2} \tilde{A} \tilde{D}^{-1/2}$ „ÇíË®àÁÆó
3. GCNÂá∫Âäõ $H = \hat{A} X W$ „ÇíË®àÁÆóÔºàÊ¥ªÊÄßÂåñÈñ¢Êï∞„Å™„ÅóÔºâ</p>
<details>
<summary>„Éí„É≥„Éà</summary>

**ÊâãÈ†Ü**:
1. Ëá™Â∑±„É´„Éº„Éó„ÇíËøΩÂä†: $\tilde{A}\_{ii} = 1$
2. Ê¨°Êï∞Ë°åÂàó: $\tilde{D}\_{ii} = \sum\_j \tilde{A}\_{ij}$
3. $\tilde{D}^{-1/2}$ „ÇíË®àÁÆóÔºàÂØæËßíË¶ÅÁ¥†„ÅÆÈÄÜÊï∞„ÅÆÂπ≥ÊñπÊ†πÔºâ
4. Ë°åÂàóÁ©ç„ÇíË®àÁÆó

</details>

<details>
<summary>Ëß£Á≠î‰æã</summary>

**Step 1: Ëá™Â∑±„É´„Éº„Éó‰ªò„ÅçÈö£Êé•Ë°åÂàó**
$$
\tilde{A} = A + I = \begin{bmatrix}
0 & 1 & 0 \\
1 & 0 & 1 \\
0 & 1 & 0
\end{bmatrix} + \begin{bmatrix}
1 & 0 & 0 \\
0 & 1 & 0 \\
0 & 0 & 1
\end{bmatrix} = \begin{bmatrix}
1 & 1 & 0 \\
1 & 1 & 1 \\
0 & 1 & 1
\end{bmatrix}
$$

**Step 2: Ê¨°Êï∞Ë°åÂàó**
$$
\tilde{D} = \begin{bmatrix}
2 & 0 & 0 \\
0 & 3 & 0 \\
0 & 0 & 2
\end{bmatrix}
$$

ÔºàÂêÑË°å„ÅÆÂíåÔºâ

**Step 3: $\tilde{D}^{-1/2}$**
$$
\tilde{D}^{-1/2} = \begin{bmatrix}
1/\sqrt{2} & 0 & 0 \\
0 & 1/\sqrt{3} & 0 \\
0 & 0 & 1/\sqrt{2}
\end{bmatrix} \approx \begin{bmatrix}
0.707 & 0 & 0 \\
0 & 0.577 & 0 \\
0 & 0 & 0.707
\end{bmatrix}
$$

**Step 4: Ê≠£Ë¶èÂåñÈö£Êé•Ë°åÂàó**
$$
\hat{A} = \tilde{D}^{-1/2} \tilde{A} \tilde{D}^{-1/2}
$$

Ë®àÁÆóÈÅéÁ®ã:

<pre><code class="language-python">import numpy as np

A\_tilde = np.array([
    [1, 1, 0],
    [1, 1, 1],
    [0, 1, 1]
], dtype=float)

D\_tilde = np.diag([2, 3, 2])
D\_inv\_sqrt = np.diag([1/np.sqrt(2), 1/np.sqrt(3), 1/np.sqrt(2)])

A\_hat = D\_inv\_sqrt @ A\_tilde @ D\_inv\_sqrt
print(&quot;Ê≠£Ë¶èÂåñÈö£Êé•Ë°åÂàó:&quot;)
print(A\_hat)
</code></pre>


$$
\hat{A} \approx \begin{bmatrix}
0.500 & 0.408 & 0 \\
0.408 & 0.333 & 0.408 \\
0 & 0.408 & 0.500
\end{bmatrix}
$$

**Step 5: GCNÂá∫Âäõ**
$$
H = \hat{A} X W
$$

Ôºà$W = I$ „Å™„ÅÆ„Åß $H = \hat{A} X$Ôºâ


<pre><code class="language-python">X = np.array([
    [1, 0],
    [0, 1],
    [1, 1]
], dtype=float)

H = A\_hat @ X
print(&quot;GCNÂá∫Âäõ:&quot;)
print(H)
</code></pre>


$$
H \approx \begin{bmatrix}
0.500 & 0.408 \\
0.816 & 0.741 \\
0.408 & 0.908
\end{bmatrix}
$$

**Ëß£Èáà**:
- È†ÇÁÇπ1Ôºà‰∏≠ÂøÉÔºâ: ‰∏°ÂÅ¥„ÅÆÈö£Êé•È†ÇÁÇπ„ÅÆÊÉÖÂ†±„ÇíÈõÜÁ¥Ñ
- È†ÇÁÇπ0,2ÔºàÁ´ØÁÇπÔºâ: Èö£Êé•È†ÇÁÇπ1„ÅÆÊÉÖÂ†±„Çí‰∏ª„Å´Âèñ„ÇäËæº„ÇÄ

**Python„Åß„ÅÆÊ§úË®º**:

<pre><code class="language-python"># ÂÆåÂÖ®„Å™„Ç≥„Éº„Éâ
A = np.array([[0, 1, 0], [1, 0, 1], [0, 1, 0]], dtype=float)
X = np.array([[1, 0], [0, 1], [1, 1]], dtype=float)

# GCN
A\_tilde = A + np.eye(3)
D\_tilde = np.diag(A\_tilde.sum(axis=1))
D\_inv\_sqrt = np.diag(1.0 / np.sqrt(D\_tilde.diagonal()))
A\_hat = D\_inv\_sqrt @ A\_tilde @ D\_inv\_sqrt

H = A\_hat @ X
print(&quot;ÊúÄÁµÇÂá∫Âäõ:&quot;)
print(H)
</code></pre>


</details>

<hr />
<h3>ÂïèÈ°å3ÔºàÈõ£ÊòìÂ∫¶ÔºöhardÔºâ</h3>
<p>SchNet„ÅÆÈÄ£Á∂ö„Éï„Ç£„É´„ÇøÈñ¢Êï∞„ÇíÂÆüË£Ö„Åó„ÄÅÁï∞„Å™„ÇãÂéüÂ≠êÈñìË∑ùÈõ¢„Å´ÂØæ„Åô„Çã„Éï„Ç£„É´„Çø„ÅÆÂøúÁ≠î„ÇíÂèØË¶ñÂåñ„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ</p>
<p><strong>Ë¶ÅÊ±Ç‰∫ãÈ†Ö</strong>:
1. „Ç¨„Ç¶„ÇπÂü∫Â∫ïÔºàRBFÔºâÈñ¢Êï∞„ÇíÂÆüË£Ö
2. Ë∑ùÈõ¢0.5√Ö„Äú5.0√Ö„Å´ÂØæ„Åô„ÇãRBFÂøúÁ≠î„ÇíË®àÁÆó
3. „Éí„Éº„Éà„Éû„ÉÉ„Éó„ÅßÂèØË¶ñÂåñ
4. „Éï„Ç£„É´„Çø„ÅÆÁâ©ÁêÜÁöÑÊÑèÂë≥„ÇíËÄÉÂØü</p>
<details>
<summary>„Éí„É≥„Éà</summary>

**RBF „ÅÆÂºè**:
$$\phi_k(d) = \exp\left( -\gamma (d - \mu_k)^2 \right)$$

- $\mu\_k$: „Ç¨„Ç¶„ÇπÈñ¢Êï∞„ÅÆ‰∏≠ÂøÉÔºà0„Äú5√Ö„Å´ÂùáÁ≠âÈÖçÁΩÆÔºâ
- $\gamma$: Â∫É„Åå„Çä„Éë„É©„É°„Éº„ÇøÔºà10Á®ãÂ∫¶Ôºâ

**ÂèØË¶ñÂåñ„ÅÆ„Éù„Ç§„É≥„Éà**:
- XËª∏: Ë∑ùÈõ¢ (0.5„Äú5.0√Ö)
- YËª∏: RBF „Ç§„É≥„Éá„ÉÉ„ÇØ„Çπ (0„Äú49)
- Ëâ≤: RBF ÂøúÁ≠îÂÄ§ (0„Äú1)

</details>

<details>
<summary>Ëß£Á≠î‰æã</summary>


<pre><code class="language-python">import torch
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# ===== ÂÆüË£Ö =====
class GaussianBasisFunction:
    def __init__(self, start=0.0, stop=5.0, num_gaussians=50,
                 gamma=10.0):
        &quot;&quot;&quot;
        „Ç¨„Ç¶„ÇπÂü∫Â∫ïÈñ¢Êï∞ÔºàRBFÔºâ

        Parameters:
        -----------
        start, stop : float
            Ë∑ùÈõ¢„ÅÆÁØÑÂõ≤
        num_gaussians : int
            „Ç¨„Ç¶„ÇπÈñ¢Êï∞„ÅÆÊï∞
        gamma : float
            Â∫É„Åå„Çä„Éë„É©„É°„Éº„Çø
        &quot;&quot;&quot;
        self.mu = torch.linspace(start, stop, num_gaussians)
        self.gamma = gamma

    def __call__(self, distances):
        &quot;&quot;&quot;
        RBF ÂøúÁ≠î„ÇíË®àÁÆó

        Parameters:
        -----------
        distances : Tensor (num_distances,)

        Returns:
        --------
        rbf : Tensor (num_distances, num_gaussians)
        &quot;&quot;&quot;
        # (num_distances, 1) - (1, num_gaussians)
        diff = distances.unsqueeze(-1) - self.mu.unsqueeze(0)
        rbf = torch.exp(-self.gamma * diff ** 2)
        return rbf

# ===== ÂèØË¶ñÂåñ =====
# RBFÁîüÊàê
rbf_layer = GaussianBasisFunction(
    start=0.0, stop=5.0,
    num_gaussians=50, gamma=10.0
)

# Ë∑ùÈõ¢„Çµ„É≥„Éó„É´Ôºà0.5„Äú5.0√ÖÔºâ
distances = torch.linspace(0.5, 5.0, 100)

# RBF ÂøúÁ≠î
rbf_response = rbf_layer(distances)  # (100, 50)

# „Éí„Éº„Éà„Éû„ÉÉ„Éó
plt.figure(figsize=(12, 6))
sns.heatmap(
    rbf_response.T.numpy(),  # Ëª¢ÁΩÆÔºàRBF x Ë∑ùÈõ¢Ôºâ
    cmap='viridis',
    xticklabels=10,
    yticklabels=10,
    cbar_kws={'label': 'RBF Response'}
)
plt.xlabel('Distance (√Ö)')
plt.ylabel('RBF Index')
plt.title('SchNet Continuous Filter: RBF Response')

# XËª∏„É©„Éô„É´„ÇíÂÆüÈöõ„ÅÆË∑ùÈõ¢„Å´
xticks = np.linspace(0, len(distances)-1, 10).astype(int)
xticklabels = [f'{distances[i]:.1f}' for i in xticks]
plt.xticks(xticks, xticklabels)

plt.tight_layout()
plt.savefig('schnet_rbf_heatmap.png', dpi=150)
plt.show()

# ===== ÁâπÂÆöË∑ùÈõ¢„ÅÆRBFÂøúÁ≠î =====
fig, axes = plt.subplots(2, 2, figsize=(12, 10))
example_distances = [1.0, 1.5, 2.0, 3.0]  # √Ö

for ax, d in zip(axes.flatten(), example_distances):
    d_tensor = torch.tensor([d])
    rbf = rbf_layer(d_tensor).squeeze()

    ax.plot(rbf_layer.mu.numpy(), rbf.numpy(),
            marker='o', linewidth=2)
    ax.axvline(d, color='red', linestyle='--',
               label=f'Distance = {d}√Ö')
    ax.set_xlabel('RBF Center Œº (√Ö)')
    ax.set_ylabel('RBF Response')
    ax.set_title(f'RBF Response at d = {d}√Ö')
    ax.legend()
    ax.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('schnet_rbf_profiles.png', dpi=150)
plt.show()

# ===== Áâ©ÁêÜÁöÑÊÑèÂë≥„ÅÆËÄÉÂØü =====
print(&quot;\n===== Áâ©ÁêÜÁöÑÊÑèÂë≥ =====&quot;)
print(&quot;1. Áü≠Ë∑ùÈõ¢Ôºà0.5-2.0√ÖÔºâ: ÂÖ±ÊúâÁµêÂêàÈ†òÂüü&quot;)
print(&quot;   - C-C: 1.54√Ö, C=C: 1.34√Ö, C-H: 1.09√Ö&quot;)
print(&quot;   - RBF„ÅØÊÄ•Â≥ª„Å´ÂèçÂøúÔºàÁµêÂêà„ÅÆÊúâÁÑ°„ÇíË≠òÂà•Ôºâ&quot;)

print(&quot;\n2. ‰∏≠Ë∑ùÈõ¢Ôºà2.0-3.5√ÖÔºâ: ÈùûÂÖ±ÊúâÁµêÂêàÁõ∏‰∫í‰ΩúÁî®&quot;)
print(&quot;   - Ê∞¥Á¥†ÁµêÂêà: 2.8√Ö, „Éï„Ç°„É≥„Éá„É´„ÉØ„Éº„É´„ÇπÂäõ&quot;)
print(&quot;   - RBF„ÅØ„Å™„Å†„Çâ„Åã„Å´ÂèçÂøú&quot;)

print(&quot;\n3. Èï∑Ë∑ùÈõ¢Ôºà3.5-5.0√ÖÔºâ: Âº±„ÅÑÁõ∏‰∫í‰ΩúÁî®&quot;)
print(&quot;   - ÈùôÈõªÁõ∏‰∫í‰ΩúÁî®„ÄÅÂàÜÊï£Âäõ&quot;)
print(&quot;   - RBF„ÅÆÂøúÁ≠î„ÅØÂ∞è„Åï„ÅÑ&quot;)

print(&quot;\n4. „Ç¨„Ç¶„ÇπÂü∫Â∫ï„ÅÆÂΩπÂâ≤:&quot;)
print(&quot;   - ÈÄ£Á∂öÁöÑ„Å™Ë∑ùÈõ¢Ë°®ÁèæÔºàÈõ¢Êï£Âåñ„Å™„ÅóÔºâ&quot;)
print(&quot;   - ‰ªªÊÑè„ÅÆË∑ùÈõ¢„Å´ÂØæ„Åó„Å¶ÂæÆÂàÜÂèØËÉΩ&quot;)
print(&quot;   - Ê©üÊ¢∞Â≠¶Áøí„ÅßÊúÄÈÅ©ÂåñÂèØËÉΩÔºàŒ≥„Éë„É©„É°„Éº„ÇøÔºâ&quot;)
</code></pre>


**Âá∫Âäõ„ÅÆËß£Èáà**:

1. **„Éí„Éº„Éà„Éû„ÉÉ„Éó**:
   - ÂØæËßíÁ∑öÁä∂„ÅÆ„Éë„Çø„Éº„É≥ÔºàÂêÑRBF„ÅåÁâπÂÆöË∑ùÈõ¢„ÅßÊúÄÂ§ßÂøúÁ≠îÔºâ
   - Êªë„Çâ„Åã„Å™ÈÅ∑ÁßªÔºà„Ç¨„Ç¶„ÇπÈñ¢Êï∞„ÅÆÈáç„Å™„ÇäÔºâ

2. **RBF„Éó„É≠„Éï„Ç°„Ç§„É´**:
   - Ë∑ùÈõ¢1.0√Ö: RBF #10‰ªòËøë„ÅåÂº∑„ÅèÂèçÂøú
   - Ë∑ùÈõ¢2.0√Ö: RBF #20‰ªòËøë„ÅåÂº∑„ÅèÂèçÂøú
   - „Ç¨„Ç¶„ÇπÂΩ¢Áä∂„Å´„Çà„Çä„ÄÅÈö£Êé•RBF„ÇÇÂº±„ÅèÂèçÂøú

3. **Áâ©ÁêÜÁöÑÊÑèÂë≥**:
   - **SchNet„ÅØË∑ùÈõ¢„Çí„ÄåÂàÜÂ∏É„Äç„Å®„Åó„Å¶Ë°®Áèæ**
   - Èõ¢Êï£ÁöÑ„Å™„Éì„É≥ÂàÜ„Åë„Åß„ÅØ„Å™„Åè„ÄÅÈÄ£Á∂öÁöÑ„Å™Èáç„Å™„Çä
   - „Éã„É•„Éº„É©„É´„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ„ÅåË∑ùÈõ¢‰æùÂ≠òÊÄß„ÇíÂ≠¶Áøí

**Êã°ÂºµË™≤È°å**:
1. $\gamma$ „Éë„É©„É°„Éº„Çø„ÇíÂ§â„Åà„Å¶„ÄÅRBF„ÅÆÂ∫É„Åå„Çä„ÇíË™øÊï¥
2. ÈùûÂØæÁß∞„Å™„Ç¨„Ç¶„ÇπÂü∫Â∫ïÔºàÁü≠Ë∑ùÈõ¢„ÇíÂØÜ„Å´„ÄÅÈï∑Ë∑ùÈõ¢„ÇíÁñé„Å´Ôºâ
3. ÂÆüÈöõ„ÅÆÂàÜÂ≠ê„ÅßRBF„Éï„Ç£„É´„Çø„ÇíÂèØË¶ñÂåñ

</details>

<hr />
<h2>ÂèÇËÄÉÊñáÁåÆ</h2>
<ol>
<li>
<p>Kipf, T. N. &amp; Welling, M. (2017). "Semi-Supervised Classification with Graph Convolutional Networks." <em>ICLR</em>.
   DOI: <a href="https://arxiv.org/abs/1609.02907">https://arxiv.org/abs/1609.02907</a></p>
</li>
<li>
<p>Veliƒçkoviƒá, P. et al. (2018). "Graph Attention Networks." <em>ICLR</em>.
   DOI: <a href="https://arxiv.org/abs/1710.10903">https://arxiv.org/abs/1710.10903</a></p>
</li>
<li>
<p>Hamilton, W. L. et al. (2017). "Inductive Representation Learning on Large Graphs." <em>NeurIPS</em>.
   DOI: <a href="https://arxiv.org/abs/1706.02216">https://arxiv.org/abs/1706.02216</a></p>
</li>
<li>
<p>Sch√ºtt, K. T. et al. (2017). "SchNet: A continuous-filter convolutional neural network for modeling quantum interactions." <em>NeurIPS</em>.
   DOI: <a href="https://arxiv.org/abs/1706.08566">https://arxiv.org/abs/1706.08566</a></p>
</li>
<li>
<p>Klicpera, J. et al. (2020). "Directional Message Passing for Molecular Graphs." <em>ICLR</em>.
   DOI: <a href="https://arxiv.org/abs/2003.03123">https://arxiv.org/abs/2003.03123</a></p>
</li>
<li>
<p>Gasteiger, J. et al. (2021). "GemNet: Universal Directional Graph Neural Networks for Molecules." <em>NeurIPS</em>.
   DOI: <a href="https://arxiv.org/abs/2106.08903">https://arxiv.org/abs/2106.08903</a></p>
</li>
<li>
<p>Batzner, S. et al. (2022). "E(3)-equivariant graph neural networks for data-efficient and accurate interatomic potentials." <em>Nature Communications</em>, 13, 2453.
   DOI: <a href="https://doi.org/10.1038/s41467-022-29939-5">https://doi.org/10.1038/s41467-022-29939-5</a></p>
</li>
</ol>
<hr />
<h2>„Éä„Éì„Ç≤„Éº„Ç∑„Éß„É≥</h2>
<h3>Ââç„ÅÆÁ´†</h3>
<p><strong><a href="./chapter-1.html">Á¨¨1Á´†Ôºö„Å™„ÅúÊùêÊñôÁßëÂ≠¶„Å´GNN„ÅåÂøÖË¶Å„Åã ‚Üê</a></strong></p>
<h3>Ê¨°„ÅÆÁ´†</h3>
<p><strong><a href="./chapter-3.html">Á¨¨3Á´†ÔºöPyTorch GeometricÂÆüË∑µ ‚Üí</a></strong></p>
<h3>„Ç∑„É™„Éº„Ç∫ÁõÆÊ¨°</h3>
<p><strong><a href="./index.html">‚Üê „Ç∑„É™„Éº„Ç∫ÁõÆÊ¨°„Å´Êàª„Çã</a></strong></p>
<hr />
<h2>ËëóËÄÖÊÉÖÂ†±</h2>
<p><strong>‰ΩúÊàêËÄÖ</strong>: AI Terakoya Content Team
<strong>‰ΩúÊàêÊó•</strong>: 2025-10-17
<strong>„Éê„Éº„Ç∏„Éß„É≥</strong>: 1.0</p>
<p><strong>Êõ¥Êñ∞Â±•Ê≠¥</strong>:
- 2025-10-17: v1.0 ÂàùÁâàÂÖ¨Èñã</p>
<p><strong>„Éï„Ç£„Éº„Éâ„Éê„ÉÉ„ÇØ</strong>:
- GitHub Issues: [„É™„Éù„Ç∏„Éà„É™URL]/issues
- Email: yusuke.hashimoto.b8@tohoku.ac.jp</p>
<p><strong>„É©„Ç§„Çª„É≥„Çπ</strong>: Creative Commons BY 4.0</p>
<hr />
<p><strong>Á¨¨3Á´†„Åß„ÄÅÂÆüÈöõ„Å´GNN„ÇíÂãï„Åã„Åó„Å¶„Åø„Åæ„Åó„Çá„ÅÜÔºÅ</strong></p><div class="navigation">
    <a href="chapter-1.html" class="nav-button">‚Üê Ââç„ÅÆÁ´†</a>
    <a href="index.html" class="nav-button">„Ç∑„É™„Éº„Ç∫ÁõÆÊ¨°„Å´Êàª„Çã</a>
    <a href="chapter-3.html" class="nav-button">Ê¨°„ÅÆÁ´† ‚Üí</a>
</div>
    </main>

    <footer>
        <p><strong>‰ΩúÊàêËÄÖ</strong>: AI Terakoya Content Team</p>
        <p><strong>„Éê„Éº„Ç∏„Éß„É≥</strong>: 1.0 | <strong>‰ΩúÊàêÊó•</strong>: 2025-10-17</p>
        <p><strong>„É©„Ç§„Çª„É≥„Çπ</strong>: Creative Commons BY 4.0</p>
        <p>¬© 2025 AI Terakoya. All rights reserved.</p>
    </footer>
</body>
</html>
