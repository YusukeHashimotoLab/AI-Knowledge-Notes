<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="ç¬¬2ç« ï¼šCGCNNå®Ÿè£… - çµæ™¶ã‚°ãƒ©ãƒ•ç•³ã¿è¾¼ã¿ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®è©³ç´°å®Ÿè£…ã¨Materials Projectäºˆæ¸¬">
    <title>ç¬¬2ç« ï¼šCGCNNå®Ÿè£… | GNNç‰¹å¾´é‡æ¯”è¼ƒå…¥é–€</title>

    <!-- CSS Styling -->
    <style>
        :root {
            --primary-color: #2c3e50;
            --secondary-color: #667eea;
            --accent-color: #764ba2;
            --bg-color: #ffffff;
            --text-color: #333333;
            --border-color: #e0e0e0;
            --code-bg: #f5f5f5;
            --link-color: #667eea;
            --link-hover: #764ba2;
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", "Hiragino Sans", "Hiragino Kaku Gothic ProN", Meiryo, sans-serif;
            line-height: 1.8;
            color: var(--text-color);
            background: var(--bg-color);
            padding: 0;
            margin: 0;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 2rem 1.5rem;
        }

        header {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 2rem 0;
            margin-bottom: 2rem;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }

        header .container {
            padding: 0 1.5rem;
        }

        h1 {
            font-size: 2rem;
            margin-bottom: 0.5rem;
            font-weight: 700;
        }

        .meta {
            display: flex;
            gap: 1.5rem;
            flex-wrap: wrap;
            font-size: 0.9rem;
            opacity: 0.95;
            margin-top: 1rem;
        }

        .meta span {
            display: inline-flex;
            align-items: center;
            gap: 0.3rem;
        }

        h2 {
            font-size: 1.75rem;
            margin-top: 2.5rem;
            margin-bottom: 1rem;
            padding-bottom: 0.5rem;
            border-bottom: 3px solid var(--secondary-color);
            color: var(--primary-color);
        }

        h3 {
            font-size: 1.4rem;
            margin-top: 2rem;
            margin-bottom: 0.8rem;
            color: var(--primary-color);
        }

        h4 {
            font-size: 1.2rem;
            margin-top: 1.5rem;
            margin-bottom: 0.6rem;
            color: var(--primary-color);
        }

        p {
            margin-bottom: 1.2rem;
        }

        a {
            color: var(--link-color);
            text-decoration: none;
            transition: color 0.2s;
        }

        a:hover {
            color: var(--link-hover);
            text-decoration: underline;
        }

        ul, ol {
            margin-left: 2rem;
            margin-bottom: 1.2rem;
        }

        li {
            margin-bottom: 0.5rem;
        }

        code {
            background: var(--code-bg);
            padding: 0.2rem 0.4rem;
            border-radius: 3px;
            font-family: 'Menlo', 'Monaco', 'Courier New', monospace;
            font-size: 0.9em;
        }

        pre {
            background: var(--code-bg);
            padding: 1.5rem;
            border-radius: 8px;
            overflow-x: auto;
            margin-bottom: 1.5rem;
            border: 1px solid var(--border-color);
        }

        pre code {
            background: none;
            padding: 0;
            font-size: 0.9rem;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: 1.5rem;
            overflow-x: auto;
            display: block;
        }

        thead {
            display: table;
            width: 100%;
            table-layout: fixed;
        }

        tbody {
            display: table;
            width: 100%;
            table-layout: fixed;
        }

        th, td {
            padding: 0.8rem;
            text-align: left;
            border: 1px solid var(--border-color);
        }

        th {
            background: var(--primary-color);
            color: white;
            font-weight: 600;
        }

        tr:nth-child(even) {
            background: #f9f9f9;
        }

        blockquote {
            border-left: 4px solid var(--secondary-color);
            padding-left: 1.5rem;
            margin: 1.5rem 0;
            font-style: italic;
            color: #666;
        }

        img {
            max-width: 100%;
            height: auto;
            border-radius: 8px;
            margin: 1rem 0;
        }

        .mermaid {
            text-align: center;
            margin: 2rem 0;
            background: white;
            padding: 1rem;
            border-radius: 8px;
            border: 1px solid var(--border-color);
        }

        details {
            margin: 1rem 0;
            padding: 1rem;
            background: #f8f9fa;
            border-radius: 8px;
            border: 1px solid var(--border-color);
        }

        summary {
            cursor: pointer;
            font-weight: 600;
            color: var(--primary-color);
            padding: 0.5rem;
        }

        summary:hover {
            color: var(--secondary-color);
        }

        .nav-buttons {
            display: flex;
            justify-content: space-between;
            margin: 3rem 0;
            gap: 1rem;
            flex-wrap: wrap;
        }

        .nav-button {
            display: inline-block;
            padding: 0.8rem 1.5rem;
            background: var(--secondary-color);
            color: white;
            border-radius: 6px;
            text-decoration: none;
            transition: all 0.3s;
            font-weight: 600;
        }

        .nav-button:hover {
            background: var(--accent-color);
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(102, 126, 234, 0.3);
        }

        .breadcrumb {
            background: #f7fafc;
            padding: 0.75rem 1rem;
            border-bottom: 1px solid #e2e8f0;
            font-size: 0.9rem;
        }

        .breadcrumb-content {
            max-width: 900px;
            margin: 0 auto;
            display: flex;
            align-items: center;
            flex-wrap: wrap;
            gap: 0.5rem;
        }

        .breadcrumb a {
            color: #667eea;
            text-decoration: none;
            transition: color 0.2s;
        }

        .breadcrumb a:hover {
            color: #764ba2;
            text-decoration: underline;
        }

        .breadcrumb-separator {
            color: #a0aec0;
            margin: 0 0.25rem;
        }

        .breadcrumb-current {
            color: #4a5568;
            font-weight: 500;
        }

        footer {
            margin-top: 4rem;
            padding: 2rem 0;
            border-top: 2px solid var(--border-color);
            text-align: center;
            color: #666;
            font-size: 0.9rem;
        }

        @media (max-width: 768px) {
            .container {
                padding: 1rem;
            }

            h1 {
                font-size: 1.6rem;
            }

            h2 {
                font-size: 1.4rem;
            }

            .meta {
                font-size: 0.85rem;
            }

            pre {
                padding: 1rem;
                font-size: 0.85rem;
            }

            table {
                font-size: 0.9rem;
            }
        }
    </style>

    <!-- MathJax -->
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

    <!-- Mermaid -->
    <script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
    <script>
        document.addEventListener('DOMContentLoaded', function() {
            const mermaidCodeBlocks = document.querySelectorAll('pre.codehilite code.language-mermaid, pre code.language-mermaid');

            mermaidCodeBlocks.forEach(function(codeBlock) {
                const pre = codeBlock.parentElement;
                const mermaidCode = codeBlock.textContent;

                const mermaidDiv = document.createElement('div');
                mermaidDiv.className = 'mermaid';
                mermaidDiv.textContent = mermaidCode.trim();

                pre.parentNode.replaceChild(mermaidDiv, pre);
            });

            if (typeof mermaid !== 'undefined') {
                mermaid.initialize({ startOnLoad: true, theme: 'default' });
                mermaid.init(undefined, document.querySelectorAll('.mermaid'));
            }
        });
    </script>

    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css" rel="stylesheet" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
</head>
<body>
    <nav class="breadcrumb">
        <div class="breadcrumb-content">
            <a href="../../index.html">AIå¯ºå­å±‹ãƒˆãƒƒãƒ—</a><span class="breadcrumb-separator">â€º</span><a href="../../MI/index.html">ãƒãƒ†ãƒªã‚¢ãƒ«ã‚ºãƒ»ã‚¤ãƒ³ãƒ•ã‚©ãƒãƒ†ã‚£ã‚¯ã‚¹</a><span class="breadcrumb-separator">â€º</span><a href="./index.html">GNNç‰¹å¾´é‡æ¯”è¼ƒå…¥é–€</a><span class="breadcrumb-separator">â€º</span><span class="breadcrumb-current">ç¬¬2ç« </span>
        </div>
    </nav>

    <header>
        <div class="container">
            <h1>ç¬¬2ç« ï¼šCGCNNå®Ÿè£…</h1>
            <div class="meta">
                <span>ğŸ“– èª­äº†æ™‚é–“: 25-30åˆ†</span>
                <span>ğŸ“Š é›£æ˜“åº¦: ä¸­ç´š</span>
                <span>ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹: 8å€‹</span>
            </div>
        </div>
    </header>

    <main class="container">
        <p><strong>çµæ™¶ææ–™å°‚ç”¨GNNï¼šã‚¨ãƒƒã‚¸ã‚²ãƒ¼ãƒˆæ©Ÿæ§‹ã«ã‚ˆã‚‹ã‚½ãƒ•ãƒˆã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã¨å‘¨æœŸå¢ƒç•Œæ¡ä»¶ã®å®Ÿè£…</strong></p>

        <h2 id="intro">2.1 CGCNNã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®è©³ç´°</h2>

        <p>Crystal Graph Convolutional Neural Networksï¼ˆCGCNNï¼‰ã¯ã€Xie & Grossmanï¼ˆ2018ï¼‰ã«ã‚ˆã£ã¦ææ¡ˆã•ã‚ŒãŸã€<strong>çµæ™¶ææ–™å°‚ç”¨ã®GNN</strong>ã§ã™ã€‚å¾“æ¥ã®åˆ†å­å‘ã‘GNNã¨ç•°ãªã‚Šã€çµæ™¶æ§‹é€ ã®ç‰¹æ€§ï¼ˆå‘¨æœŸå¢ƒç•Œæ¡ä»¶ã€é•·è·é›¢ç›¸äº’ä½œç”¨ã€é…ä½ç’°å¢ƒï¼‰ã‚’è€ƒæ…®ã—ãŸè¨­è¨ˆã«ãªã£ã¦ã„ã¾ã™ã€‚</p>

        <h3>2.1.1 è«–æ–‡ã®ä¸»è¦ãªè²¢çŒ®ï¼ˆXie & Grossman, 2018ï¼‰</h3>

        <p>Xie & Grossmanã®è«–æ–‡ï¼ˆPhysical Review Letters, 120, 145301, pp. 1-6ï¼‰ã¯ã€ä»¥ä¸‹ã®3ã¤ã®é©æ–°ã‚’ã‚‚ãŸã‚‰ã—ã¾ã—ãŸï¼š</p>

        <ol>
            <li><strong>çµæ™¶ã‚°ãƒ©ãƒ•è¡¨ç¾</strong>ï¼šåŸå­ã‚’é ‚ç‚¹ã€åŸå­é–“è·é›¢ã‚’ã‚¨ãƒƒã‚¸ã¨ã™ã‚‹ç„¡å‘ã‚°ãƒ©ãƒ•ï¼ˆpp. 2-3ï¼‰</li>
            <li><strong>ç•³ã¿è¾¼ã¿å±¤</strong>ï¼šã‚¨ãƒƒã‚¸ã‚²ãƒ¼ãƒˆæ©Ÿæ§‹ï¼ˆå¼(1)ã€p. 3ï¼‰ã«ã‚ˆã‚‹è·é›¢ä¾å­˜çš„ãªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ‘ãƒƒã‚·ãƒ³ã‚°</li>
            <li><strong>é«˜ç²¾åº¦äºˆæ¸¬</strong>ï¼šMaterials Project 46,744åŒ–åˆç‰©ã§å½¢æˆã‚¨ãƒãƒ«ã‚®ãƒ¼MAE 0.039 eV/atomï¼ˆè¡¨Iã€p. 4ï¼‰</li>
        </ol>

        <p><strong>æ•°å­¦çš„å®šå¼åŒ–</strong>ï¼ˆè«–æ–‡å¼(1)ã€p. 3ï¼‰ï¼š</p>

        <p>\[
        \mathbf{v}_i^{(t+1)} = \mathbf{v}_i^{(t)} + \sum_{j \in \mathcal{N}(i)} \sigma \left( \mathbf{z}_{ij}^{(t)} \mathbf{W}_f^{(t)} + \mathbf{b}_f^{(t)} \right) \odot g \left( \mathbf{z}_{ij}^{(t)} \mathbf{W}_s^{(t)} + \mathbf{b}_s^{(t)} \right)
        \]</p>

        <p>ã“ã“ã§ï¼š</p>
        <ul>
            <li>\( \mathbf{v}_i^{(t)} \): ãƒãƒ¼ãƒ‰ \( i \) ã®ç¬¬ \( t \) å±¤ã§ã®ç‰¹å¾´ãƒ™ã‚¯ãƒˆãƒ«</li>
            <li>\( \mathbf{z}_{ij}^{(t)} = \mathbf{v}_i^{(t)} \oplus \mathbf{v}_j^{(t)} \oplus \mathbf{u}_{ij} \): é€£çµãƒ™ã‚¯ãƒˆãƒ«ï¼ˆ\( \oplus \) ã¯é€£çµæ¼”ç®—ï¼‰</li>
            <li>\( \mathbf{u}_{ij} \): ã‚¨ãƒƒã‚¸ç‰¹å¾´é‡ï¼ˆåŸå­é–“è·é›¢ã®ã‚¬ã‚¦ã‚¹å±•é–‹ï¼‰</li>
            <li>\( \sigma \): ã‚·ã‚°ãƒ¢ã‚¤ãƒ‰é–¢æ•°ï¼ˆã‚²ãƒ¼ãƒˆï¼‰</li>
            <li>\( g \): æ´»æ€§åŒ–é–¢æ•°ï¼ˆSoftplusï¼‰</li>
            <li>\( \odot \): è¦ç´ ã”ã¨ã®ç©ï¼ˆHadamardç©ï¼‰</li>
        </ul>

        <div class="mermaid">
graph LR
    subgraph "å…¥åŠ›"
        A[åŸå­ i<br/>ç‰¹å¾´é‡ v_i]
        B[åŸå­ j<br/>ç‰¹å¾´é‡ v_j]
        C[è·é›¢ r_ij<br/>ã‚¨ãƒƒã‚¸ç‰¹å¾´é‡ u_ij]
    end

    subgraph "ç•³ã¿è¾¼ã¿å±¤"
        D[é€£çµ<br/>z_ij = v_i âŠ• v_j âŠ• u_ij]
        E[ã‚²ãƒ¼ãƒˆ<br/>Ïƒ(z_ij W_f)]
        F[ãƒ•ã‚£ãƒ«ã‚¿<br/>g(z_ij W_s)]
        G[è¦ç´ ç©<br/>âŠ™]
        H[é›†ç´„<br/>Î£]
    end

    subgraph "å‡ºåŠ›"
        I[æ›´æ–°ã•ã‚ŒãŸ<br/>ç‰¹å¾´é‡ v_i']
    end

    A --> D
    B --> D
    C --> D
    D --> E
    D --> F
    E --> G
    F --> G
    G --> H
    A --> I
    H --> I

    style A fill:#e3f2fd
    style B fill:#e3f2fd
    style C fill:#fff3e0
    style E fill:#ffebee
    style F fill:#e8f5e9
    style I fill:#f3e5f5
</div>

        <h3>2.1.2 ã‚¨ãƒƒã‚¸ã‚²ãƒ¼ãƒˆæ©Ÿæ§‹ã®å½¹å‰²</h3>

        <p>ã‚¨ãƒƒã‚¸ã‚²ãƒ¼ãƒˆæ©Ÿæ§‹ã¯ã€<strong>åŸå­é–“è·é›¢ã«å¿œã˜ã¦ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®é‡ã¿ä»˜ã‘</strong>ã‚’è¡Œã„ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€è¿‘ã„åŸå­ã‹ã‚‰ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å¼·èª¿ã—ã€é ã„åŸå­ã‹ã‚‰ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æŠ‘åˆ¶ã—ã¾ã™ã€‚</p>

        <p><strong>ã‚·ã‚°ãƒ¢ã‚¤ãƒ‰ã‚²ãƒ¼ãƒˆã®åŠ¹æœ</strong>:</p>
        <ul>
            <li>è¿‘è·é›¢ï¼ˆ< 3Ã…ï¼‰: ã‚²ãƒ¼ãƒˆå€¤ â‰ˆ 0.8-1.0ï¼ˆå¼·ã„å½±éŸ¿ï¼‰</li>
            <li>ä¸­è·é›¢ï¼ˆ3-5Ã…ï¼‰: ã‚²ãƒ¼ãƒˆå€¤ â‰ˆ 0.3-0.7ï¼ˆä¸­ç¨‹åº¦ã®å½±éŸ¿ï¼‰</li>
            <li>é è·é›¢ï¼ˆ> 5Ã…ï¼‰: ã‚²ãƒ¼ãƒˆå€¤ â‰ˆ 0.0-0.2ï¼ˆå¼±ã„å½±éŸ¿ï¼‰</li>
        </ul>

        <p>ã“ã‚Œã¯ã€çµæ™¶ææ–™ã®å±€æ‰€ç’°å¢ƒï¼ˆç¬¬ä¸€è¿‘æ¥ã€ç¬¬äºŒè¿‘æ¥ç­‰ï¼‰ã‚’é©åˆ‡ã«ãƒ¢ãƒ‡ãƒ«åŒ–ã™ã‚‹ãŸã‚ã®é‡è¦ãªè¨­è¨ˆã§ã™ã€‚</p>

        <h2 id="graph-construction">2.2 çµæ™¶ã‚°ãƒ©ãƒ•ã®æ§‹ç¯‰</h2>

        <h3>2.2.1 å‘¨æœŸå¢ƒç•Œæ¡ä»¶ã®è€ƒæ…®</h3>

        <p>çµæ™¶ã¯<strong>ç„¡é™ã«ç¹°ã‚Šè¿”ã•ã‚Œã‚‹å‘¨æœŸæ§‹é€ </strong>ã§ã™ã€‚å˜ä½æ ¼å­å†…ã®åŸå­ã ã‘ã§ãªãã€å‘¨æœŸçš„ã«ç¹°ã‚Šè¿”ã•ã‚Œã‚‹è¿‘å‚åŸå­ã‚‚è€ƒæ…®ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚</p>

        <pre><code class="language-python"># Example 1: å‘¨æœŸå¢ƒç•Œæ¡ä»¶ã‚’è€ƒæ…®ã—ãŸçµæ™¶ã‚°ãƒ©ãƒ•æ§‹ç¯‰
# Google Colabç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
!pip install pymatgen torch-geometric torch-scatter torch-sparse

import numpy as np
from pymatgen.core import Structure, Lattice
import torch
from torch_geometric.data import Data

def build_crystal_graph(structure, cutoff=8.0):
    """å‘¨æœŸå¢ƒç•Œæ¡ä»¶ã‚’è€ƒæ…®ã—ãŸçµæ™¶ã‚°ãƒ©ãƒ•ã‚’æ§‹ç¯‰

    Args:
        structure (Structure): pymatgen Structure ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        cutoff (float): ã‚«ãƒƒãƒˆã‚ªãƒ•åŠå¾„ [Ã…]

    Returns:
        Data: PyTorch Geometric Dataã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
    """
    # ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡: åŸå­ç•ªå·ï¼ˆone-hotåŒ–ã¯å¾Œã§å®Ÿæ–½ï¼‰
    num_atoms = len(structure)
    atom_fea = torch.tensor([[site.specie.Z] for site in structure],
                             dtype=torch.float)

    # ã‚¨ãƒƒã‚¸ãƒªã‚¹ãƒˆã¨ã‚¨ãƒƒã‚¸ç‰¹å¾´é‡ï¼ˆåŸå­é–“è·é›¢ï¼‰
    edges = []
    edge_distances = []

    for i, site_i in enumerate(structure):
        # å‘¨æœŸå¢ƒç•Œæ¡ä»¶ã‚’è€ƒæ…®ã—ãŸè¿‘å‚åŸå­å–å¾—
        neighbors = structure.get_neighbors(site_i, cutoff)

        for neighbor in neighbors:
            j = neighbor.index  # è¿‘å‚åŸå­ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
            distance = neighbor.nn_distance  # åŸå­é–“è·é›¢

            edges.append([i, j])
            edge_distances.append(distance)

    # PyTorch Geometricãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«å¤‰æ›
    edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()
    edge_attr = torch.tensor(edge_distances, dtype=torch.float).view(-1, 1)

    return Data(x=atom_fea, edge_index=edge_index, edge_attr=edge_attr)

# ä¾‹: NaClçµæ™¶æ§‹é€ 
nacl_lattice = Lattice.cubic(5.64)  # æ ¼å­å®šæ•° 5.64Ã…
nacl = Structure(nacl_lattice,
                 ["Na", "Cl"],
                 [[0, 0, 0], [0.5, 0.5, 0.5]])

graph = build_crystal_graph(nacl, cutoff=8.0)

print(f"NaClçµæ™¶ã‚°ãƒ©ãƒ•:")
print(f"  ãƒãƒ¼ãƒ‰æ•°: {graph.num_nodes}")
print(f"  ã‚¨ãƒƒã‚¸æ•°: {graph.num_edges}")
print(f"  å¹³å‡æ¬¡æ•°: {graph.num_edges / graph.num_nodes:.2f}")
print(f"  ã‚¨ãƒƒã‚¸è·é›¢ã®ç¯„å›²: {graph.edge_attr.min():.2f} - {graph.edge_attr.max():.2f} Ã…")

# å‡ºåŠ›ä¾‹:
# NaClçµæ™¶ã‚°ãƒ©ãƒ•:
#   ãƒãƒ¼ãƒ‰æ•°: 2
#   ã‚¨ãƒƒã‚¸æ•°: 24
#   å¹³å‡æ¬¡æ•°: 12.00ï¼ˆface-centered cubicæ§‹é€ ï¼‰
#   ã‚¨ãƒƒã‚¸è·é›¢ã®ç¯„å›²: 2.82 - 7.98 Ã…
</code></pre>

        <h3>2.2.2 ã‚«ãƒƒãƒˆã‚ªãƒ•åŠå¾„ã®é¸æŠ</h3>

        <p>ã‚«ãƒƒãƒˆã‚ªãƒ•åŠå¾„ã¯ã€<strong>ã©ã“ã¾ã§ã®è¿‘å‚åŸå­ã‚’è€ƒæ…®ã™ã‚‹ã‹</strong>ã‚’æ±ºå®šã—ã¾ã™ã€‚Xie & Grossmanã®è«–æ–‡ï¼ˆp. 3ï¼‰ã§ã¯ã€8Ã…ã‚’æ¨å¥¨ã—ã¦ã„ã¾ã™ã€‚</p>

        <table>
            <thead>
                <tr>
                    <th>ã‚«ãƒƒãƒˆã‚ªãƒ•åŠå¾„</th>
                    <th>è€ƒæ…®ã™ã‚‹è¿‘æ¥æ®»</th>
                    <th>ã‚¨ãƒƒã‚¸æ•°</th>
                    <th>æ¨å¥¨ã‚±ãƒ¼ã‚¹</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>4Ã…</td>
                    <td>ç¬¬ä¸€è¿‘æ¥ã®ã¿</td>
                    <td>å°‘ï¼ˆ~10-20ï¼‰</td>
                    <td>å…±æœ‰çµåˆçµæ™¶ï¼ˆSiã€Diamondï¼‰</td>
                </tr>
                <tr>
                    <td>6Ã…</td>
                    <td>ç¬¬ä¸€ã€œç¬¬äºŒè¿‘æ¥</td>
                    <td>ä¸­ï¼ˆ~20-40ï¼‰</td>
                    <td>é‡‘å±çµæ™¶ï¼ˆCuã€Feï¼‰</td>
                </tr>
                <tr>
                    <td>8Ã… â­</td>
                    <td>ç¬¬ä¸€ã€œç¬¬ä¸‰è¿‘æ¥</td>
                    <td>å¤šï¼ˆ~40-80ï¼‰</td>
                    <td>ã‚¤ã‚ªãƒ³çµæ™¶ï¼ˆNaClã€MgOï¼‰ã€æ±ç”¨æ¨å¥¨</td>
                </tr>
                <tr>
                    <td>10Ã…</td>
                    <td>ç¬¬ä¸€ã€œç¬¬å››è¿‘æ¥</td>
                    <td>éå¸¸ã«å¤šï¼ˆ>80ï¼‰</td>
                    <td>van der Waalsçµæ™¶ã€é•·è·é›¢ç›¸äº’ä½œç”¨</td>
                </tr>
            </tbody>
        </table>

        <h3>2.2.3 ã‚¨ãƒƒã‚¸ç‰¹å¾´é‡ã®ã‚¬ã‚¦ã‚¹å±•é–‹</h3>

        <p>åŸå­é–“è·é›¢ã‚’ãã®ã¾ã¾ä½¿ã†ã®ã§ã¯ãªãã€<strong>ã‚¬ã‚¦ã‚¹åŸºåº•é–¢æ•°ã§å±•é–‹</strong>ã—ã¾ã™ï¼ˆè«–æ–‡p. 3ï¼‰ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€è·é›¢æƒ…å ±ã‚’é€£ç¶šçš„ã‹ã¤æ»‘ã‚‰ã‹ã«è¡¨ç¾ã§ãã¾ã™ã€‚</p>

        <p>\[
        \mathbf{u}_{ij}(k) = \exp \left( -\frac{(r_{ij} - \mu_k)^2}{2\sigma^2} \right)
        \]</p>

        <p>ã“ã“ã§ï¼š</p>
        <ul>
            <li>\( r_{ij} \): åŸå­é–“è·é›¢</li>
            <li>\( \mu_k \): ã‚¬ã‚¦ã‚¹ä¸­å¿ƒï¼ˆ0Ã…ã‹ã‚‰6Ã…ã¾ã§0.2Ã…é–“éš”ã§é…ç½®ã€è¨ˆ31å€‹ï¼‰</li>
            <li>\( \sigma \): ã‚¬ã‚¦ã‚¹å¹…ï¼ˆ0.2Ã…ï¼‰</li>
        </ul>

        <pre><code class="language-python"># Example 2: ã‚¬ã‚¦ã‚¹å±•é–‹ã«ã‚ˆã‚‹ã‚¨ãƒƒã‚¸ç‰¹å¾´é‡ã®è¨ˆç®—
import torch
import torch.nn as nn

class GaussianDistance(nn.Module):
    """åŸå­é–“è·é›¢ã®ã‚¬ã‚¦ã‚¹å±•é–‹"""
    def __init__(self, dmin=0.0, dmax=6.0, step=0.2, var=0.2):
        """
        Args:
            dmin (float): æœ€å°è·é›¢ [Ã…]
            dmax (float): æœ€å¤§è·é›¢ [Ã…]
            step (float): ã‚¬ã‚¦ã‚¹ä¸­å¿ƒã®é–“éš” [Ã…]
            var (float): ã‚¬ã‚¦ã‚¹å¹…ï¼ˆåˆ†æ•£ï¼‰ [Ã…]
        """
        super().__init__()
        # ã‚¬ã‚¦ã‚¹ä¸­å¿ƒã‚’ç­‰é–“éš”ã§é…ç½®
        self.filter = torch.arange(dmin, dmax + step, step)
        self.var = var

    def forward(self, distances):
        """
        Args:
            distances (Tensor): åŸå­é–“è·é›¢ [num_edges, 1]

        Returns:
            Tensor: ã‚¬ã‚¦ã‚¹å±•é–‹å¾Œã®ç‰¹å¾´é‡ [num_edges, num_gaussians]
        """
        # ã‚¬ã‚¦ã‚¹é–¢æ•°ã®è¨ˆç®—
        # distances: [num_edges, 1], self.filter: [num_gaussians]
        # å‡ºåŠ›: [num_edges, num_gaussians]
        return torch.exp(
            -((distances - self.filter) ** 2) / (2 * self.var ** 2)
        )

# ä½¿ç”¨ä¾‹
gaussian_filter = GaussianDistance(dmin=0.0, dmax=6.0, step=0.2, var=0.2)

# ã‚µãƒ³ãƒ—ãƒ«è·é›¢ï¼ˆNaCl ã® Na-Cl è·é›¢ 2.82Ã…ï¼‰
sample_distance = torch.tensor([[2.82]])
gaussian_features = gaussian_filter(sample_distance)

print(f"ã‚¬ã‚¦ã‚¹å±•é–‹:")
print(f"  å…¥åŠ›è·é›¢: {sample_distance.item():.2f} Ã…")
print(f"  ã‚¬ã‚¦ã‚¹åŸºåº•æ•°: {gaussian_features.shape[1]}")
print(f"  æœ€å¤§æ´»æ€§åŒ–: {gaussian_features.max().item():.3f}")
print(f"  æœ€å¤§æ´»æ€§åŒ–ä½ç½®: Î¼ = {gaussian_filter.filter[gaussian_features.argmax()]:.2f} Ã…")

# å‡ºåŠ›ä¾‹:
# ã‚¬ã‚¦ã‚¹å±•é–‹:
#   å…¥åŠ›è·é›¢: 2.82 Ã…
#   ã‚¬ã‚¦ã‚¹åŸºåº•æ•°: 31
#   æœ€å¤§æ´»æ€§åŒ–: 0.945
#   æœ€å¤§æ´»æ€§åŒ–ä½ç½®: Î¼ = 2.80 Ã…
</code></pre>

        <h2 id="conv-layer">2.3 CGCNNç•³ã¿è¾¼ã¿å±¤ã®å®Ÿè£…</h2>

        <h3>2.3.1 ç•³ã¿è¾¼ã¿å±¤ã®ãƒ•ãƒ«ã‚¹ã‚¯ãƒ©ãƒƒãƒå®Ÿè£…</h3>

        <pre><code class="language-python"># Example 3: CGCNNç•³ã¿è¾¼ã¿å±¤ã®å®Œå…¨å®Ÿè£…
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch_geometric.nn import MessagePassing

class CGConv(MessagePassing):
    """Crystal Graph Convolutionalå±¤

    è«–æ–‡: Xie & Grossman (2018), Physical Review Letters, 120, 145301, pp. 1-6
    å®Ÿè£…: å¼(1) (p. 3)
    """
    def __init__(self, node_dim, edge_dim):
        """
        Args:
            node_dim (int): ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡ã®æ¬¡å…ƒ
            edge_dim (int): ã‚¨ãƒƒã‚¸ç‰¹å¾´é‡ã®æ¬¡å…ƒï¼ˆã‚¬ã‚¦ã‚¹å±•é–‹å¾Œï¼‰
        """
        super().__init__(aggr='add')  # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®é›†ç´„æ–¹æ³•ï¼ˆåˆè¨ˆï¼‰

        # é€£çµãƒ™ã‚¯ãƒˆãƒ«ã®æ¬¡å…ƒ: node_dim + node_dim + edge_dim
        concat_dim = 2 * node_dim + edge_dim

        # ã‚²ãƒ¼ãƒˆæ©Ÿæ§‹ã®é‡ã¿ï¼ˆå¼(1)ã® Ïƒ(z_ij W_f + b_f)ï¼‰
        self.fc_filter = nn.Linear(concat_dim, node_dim)

        # ãƒ•ã‚£ãƒ«ã‚¿ã®é‡ã¿ï¼ˆå¼(1)ã® g(z_ij W_s + b_s)ï¼‰
        self.fc_self = nn.Linear(concat_dim, node_dim)

        # Batch Normalizationï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ã€åæŸå®‰å®šåŒ–ï¼‰
        self.bn = nn.BatchNorm1d(node_dim)

    def forward(self, x, edge_index, edge_attr):
        """
        Args:
            x (Tensor): ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡ [num_nodes, node_dim]
            edge_index (Tensor): ã‚¨ãƒƒã‚¸ãƒªã‚¹ãƒˆ [2, num_edges]
            edge_attr (Tensor): ã‚¨ãƒƒã‚¸ç‰¹å¾´é‡ [num_edges, edge_dim]

        Returns:
            Tensor: æ›´æ–°ã•ã‚ŒãŸãƒãƒ¼ãƒ‰ç‰¹å¾´é‡ [num_nodes, node_dim]
        """
        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ‘ãƒƒã‚·ãƒ³ã‚°ï¼ˆself.messageã¨self.aggregateã‚’è‡ªå‹•å®Ÿè¡Œï¼‰
        return self.propagate(edge_index, x=x, edge_attr=edge_attr)

    def message(self, x_i, x_j, edge_attr):
        """ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç”Ÿæˆï¼ˆã‚¨ãƒƒã‚¸ã”ã¨ã«å®Ÿè¡Œï¼‰

        Args:
            x_i (Tensor): å—ä¿¡ãƒãƒ¼ãƒ‰ã®ç‰¹å¾´é‡ [num_edges, node_dim]
            x_j (Tensor): é€ä¿¡ãƒãƒ¼ãƒ‰ã®ç‰¹å¾´é‡ [num_edges, node_dim]
            edge_attr (Tensor): ã‚¨ãƒƒã‚¸ç‰¹å¾´é‡ [num_edges, edge_dim]

        Returns:
            Tensor: ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ [num_edges, node_dim]
        """
        # é€£çµãƒ™ã‚¯ãƒˆãƒ« z_ij = v_i âŠ• v_j âŠ• u_ij
        z = torch.cat([x_i, x_j, edge_attr], dim=1)

        # ã‚²ãƒ¼ãƒˆ: Ïƒ(z_ij W_f + b_f)
        gate = torch.sigmoid(self.fc_filter(z))

        # ãƒ•ã‚£ãƒ«ã‚¿: g(z_ij W_s + b_s)ï¼ˆSoftplusã‚’ä½¿ç”¨ï¼‰
        filter_output = F.softplus(self.fc_self(z))

        # è¦ç´ ç©ï¼ˆHadamardç©ï¼‰: gate âŠ™ filter_output
        return gate * filter_output

    def update(self, aggr_out, x):
        """ãƒãƒ¼ãƒ‰è¡¨ç¾ã®æ›´æ–°ï¼ˆãƒãƒ¼ãƒ‰ã”ã¨ã«å®Ÿè¡Œï¼‰

        Args:
            aggr_out (Tensor): é›†ç´„ã•ã‚ŒãŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ [num_nodes, node_dim]
            x (Tensor): å…ƒã®ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡ [num_nodes, node_dim]

        Returns:
            Tensor: æ›´æ–°ã•ã‚ŒãŸãƒãƒ¼ãƒ‰ç‰¹å¾´é‡ [num_nodes, node_dim]
        """
        # æ®‹å·®æ¥ç¶š: v_i' = v_i + Î£ messagesï¼ˆå¼(1)ã®å·¦è¾ºï¼‰
        out = x + aggr_out

        # Batch Normalizationï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        out = self.bn(out)

        return out

# ä½¿ç”¨ä¾‹
node_dim = 64
edge_dim = 31  # ã‚¬ã‚¦ã‚¹å±•é–‹å¾Œã®æ¬¡å…ƒ

conv = CGConv(node_dim=node_dim, edge_dim=edge_dim)

# ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿
x = torch.randn(10, node_dim)  # 10ãƒãƒ¼ãƒ‰
edge_index = torch.randint(0, 10, (2, 40))  # 40ã‚¨ãƒƒã‚¸
edge_attr = torch.randn(40, edge_dim)

# ç•³ã¿è¾¼ã¿å®Ÿè¡Œ
x_out = conv(x, edge_index, edge_attr)

print(f"CGCNNç•³ã¿è¾¼ã¿å±¤:")
print(f"  å…¥åŠ›ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡: {x.shape}")
print(f"  å‡ºåŠ›ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡: {x_out.shape}")
print(f"  ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {sum(p.numel() for p in conv.parameters())}")

# å‡ºåŠ›ä¾‹:
# CGCNNç•³ã¿è¾¼ã¿å±¤:
#   å…¥åŠ›ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡: torch.Size([10, 64])
#   å‡ºåŠ›ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡: torch.Size([10, 64])
#   ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: 20,672
</code></pre>

        <h3>2.3.2 å¤šå±¤CGCNNã®æ§‹ç¯‰</h3>

        <p>å˜ä¸€ã®ç•³ã¿è¾¼ã¿å±¤ã§ã¯ã€è¿‘å‚ã®æƒ…å ±ã—ã‹æ‰ãˆã‚‰ã‚Œã¾ã›ã‚“ã€‚<strong>å¤šå±¤åŒ–</strong>ã«ã‚ˆã‚Šã€ã‚ˆã‚Šé ãã®åŸå­ã®æƒ…å ±ã‚’é–“æ¥çš„ã«ä¼æ’­ã§ãã¾ã™ã€‚</p>

        <pre><code class="language-python"># Example 4: å¤šå±¤CGCNNãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰
class CGCNN(nn.Module):
    """å®Œå…¨ãªCGCNNãƒ¢ãƒ‡ãƒ«

    è«–æ–‡: Xie & Grossman (2018), Physical Review Letters, 120, 145301, pp. 1-6
    ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£: pp. 3-4
    """
    def __init__(self,
                 orig_atom_fea_len=92,  # å…ƒç´ ã®ç¨®é¡æ•°
                 atom_fea_len=64,       # ãƒãƒ¼ãƒ‰åŸ‹ã‚è¾¼ã¿æ¬¡å…ƒ
                 n_conv=3,              # ç•³ã¿è¾¼ã¿å±¤ã®æ•°
                 h_fea_len=128,         # éš ã‚Œå±¤ã®æ¬¡å…ƒ
                 n_h=1):                # éš ã‚Œå±¤ã®æ•°
        """
        Args:
            orig_atom_fea_len (int): å…ƒã®åŸå­ç‰¹å¾´é‡ã®æ¬¡å…ƒï¼ˆåŸå­ç•ªå·ï¼‰
            atom_fea_len (int): ç•³ã¿è¾¼ã¿å±¤ã§ã®ç‰¹å¾´é‡æ¬¡å…ƒ
            n_conv (int): ç•³ã¿è¾¼ã¿å±¤ã®æ•°
            h_fea_len (int): å…¨çµåˆå±¤ã®éš ã‚Œå±¤æ¬¡å…ƒ
            n_h (int): å…¨çµåˆéš ã‚Œå±¤ã®æ•°
        """
        super().__init__()

        # åŸå­ã®åŸ‹ã‚è¾¼ã¿å±¤ï¼ˆåŸå­ç•ªå· â†’ ç‰¹å¾´ãƒ™ã‚¯ãƒˆãƒ«ï¼‰
        self.embedding = nn.Linear(orig_atom_fea_len, atom_fea_len)

        # ã‚¨ãƒƒã‚¸ç‰¹å¾´é‡ã®ã‚¬ã‚¦ã‚¹å±•é–‹
        self.gaussian_filter = GaussianDistance(dmin=0.0, dmax=6.0,
                                                  step=0.2, var=0.2)

        # CGCNNç•³ã¿è¾¼ã¿å±¤ï¼ˆè¤‡æ•°å±¤ï¼‰
        self.convs = nn.ModuleList([
            CGConv(node_dim=atom_fea_len, edge_dim=31)
            for _ in range(n_conv)
        ])

        # ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ—ãƒ¼ãƒªãƒ³ã‚°å¾Œã®å…¨çµåˆå±¤
        self.conv_to_fc = nn.Linear(atom_fea_len, h_fea_len)
        self.conv_to_fc_softplus = nn.Softplus()

        # éš ã‚Œå±¤
        if n_h > 1:
            self.fcs = nn.ModuleList([
                nn.Linear(h_fea_len, h_fea_len)
                for _ in range(n_h - 1)
            ])
            self.softpluses = nn.ModuleList([
                nn.Softplus() for _ in range(n_h - 1)
            ])

        # å‡ºåŠ›å±¤ï¼ˆå›å¸°ã‚¿ã‚¹ã‚¯ç”¨ï¼‰
        self.fc_out = nn.Linear(h_fea_len, 1)

    def forward(self, data):
        """
        Args:
            data (Data): PyTorch Geometric Dataã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
                - x: ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡ï¼ˆåŸå­ç•ªå·ï¼‰ [num_nodes, 1]
                - edge_index: ã‚¨ãƒƒã‚¸ãƒªã‚¹ãƒˆ [2, num_edges]
                - edge_attr: åŸå­é–“è·é›¢ [num_edges, 1]
                - batch: ãƒãƒƒãƒã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ [num_nodes]

        Returns:
            Tensor: äºˆæ¸¬å€¤ [batch_size, 1]
        """
        # åŸå­ã®åŸ‹ã‚è¾¼ã¿ï¼ˆone-hotåŒ– â†’ åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ï¼‰
        atom_fea = self.embedding(
            F.one_hot(data.x.long().squeeze(), num_classes=92).float()
        )

        # ã‚¨ãƒƒã‚¸ç‰¹å¾´é‡ã®ã‚¬ã‚¦ã‚¹å±•é–‹
        edge_attr = self.gaussian_filter(data.edge_attr)

        # CGCNNç•³ã¿è¾¼ã¿å±¤ï¼ˆè¤‡æ•°å±¤é©ç”¨ï¼‰
        for conv in self.convs:
            atom_fea = conv(atom_fea, data.edge_index, edge_attr)

        # ã‚°ãƒ­ãƒ¼ãƒãƒ«å¹³å‡ãƒ—ãƒ¼ãƒªãƒ³ã‚°ï¼ˆçµæ™¶å…¨ä½“ã®è¡¨ç¾ï¼‰
        from torch_geometric.nn import global_mean_pool
        crys_fea = global_mean_pool(atom_fea, data.batch)

        # å…¨çµåˆå±¤
        crys_fea = self.conv_to_fc(crys_fea)
        crys_fea = self.conv_to_fc_softplus(crys_fea)

        if hasattr(self, 'fcs'):
            for fc, softplus in zip(self.fcs, self.softpluses):
                crys_fea = fc(crys_fea)
                crys_fea = softplus(crys_fea)

        # å‡ºåŠ›å±¤
        out = self.fc_out(crys_fea)

        return out

# ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–
model = CGCNN(orig_atom_fea_len=92,
              atom_fea_len=64,
              n_conv=3,
              h_fea_len=128,
              n_h=1)

print(f"CGCNNãƒ¢ãƒ‡ãƒ«:")
print(f"  ç·ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {sum(p.numel() for p in model.parameters()):,}")
print(f"  ç•³ã¿è¾¼ã¿å±¤æ•°: 3")
print(f"  ãƒãƒ¼ãƒ‰åŸ‹ã‚è¾¼ã¿æ¬¡å…ƒ: 64")
print(f"  å…¨çµåˆå±¤éš ã‚Œæ¬¡å…ƒ: 128")

# å‡ºåŠ›ä¾‹:
# CGCNNãƒ¢ãƒ‡ãƒ«:
#   ç·ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: 84,545
#   ç•³ã¿è¾¼ã¿å±¤æ•°: 3
#   ãƒãƒ¼ãƒ‰åŸ‹ã‚è¾¼ã¿æ¬¡å…ƒ: 64
#   å…¨çµåˆå±¤éš ã‚Œæ¬¡å…ƒ: 128
</code></pre>

        <h2 id="materials-project">2.4 Materials Projectã§ã®ç‰©æ€§äºˆæ¸¬</h2>

        <h3>2.4.1 Materials Projectãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æ¦‚è¦</h3>

        <p>Materials Projectï¼ˆJain et al., 2013, APL Materials, 1, 011002, pp. 1-11ï¼‰ã¯ã€<strong>è¨ˆç®—ææ–™ç§‘å­¦ã®æœ€å¤§ç´šãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹</strong>ã§ã™ã€‚DFTè¨ˆç®—ã«ã‚ˆã‚Šã€15ä¸‡ä»¥ä¸Šã®ç„¡æ©ŸåŒ–åˆç‰©ã®ç‰©æ€§ãŒç¶²ç¾…ã•ã‚Œã¦ã„ã¾ã™ï¼ˆp. 3ï¼‰ã€‚</p>

        <p><strong>ä¸»è¦ãªç‰©æ€§ãƒ‡ãƒ¼ã‚¿</strong>:</p>
        <ul>
            <li><strong>å½¢æˆã‚¨ãƒãƒ«ã‚®ãƒ¼</strong>: å…ƒç´ ã‹ã‚‰åŒ–åˆç‰©ãŒç”Ÿæˆã™ã‚‹éš›ã®ã‚¨ãƒãƒ«ã‚®ãƒ¼å¤‰åŒ–ï¼ˆå®‰å®šæ€§æŒ‡æ¨™ï¼‰</li>
            <li><strong>ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—</strong>: é›»å­æ§‹é€ ã®åŸºæœ¬é‡ï¼ˆåŠå°ä½“ç‰¹æ€§ï¼‰</li>
            <li><strong>å¼¾æ€§å®šæ•°</strong>: æ©Ÿæ¢°çš„ç‰¹æ€§</li>
            <li><strong>èª˜é›»ç‡</strong>: é›»æ°—çš„ç‰¹æ€§</li>
        </ul>

        <pre><code class="language-python"># Example 5: Materials Projectãƒ‡ãƒ¼ã‚¿ã®ãƒ­ãƒ¼ãƒ‰ã¨GNNç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ
!pip install mp-api  # Materials Project API

from mp_api.client import MPRester
from pymatgen.core import Structure
import torch
from torch_geometric.data import Data, Dataset
import os
import json

class MaterialsProjectDataset(Dataset):
    """Materials Projectãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆå½¢æˆã‚¨ãƒãƒ«ã‚®ãƒ¼äºˆæ¸¬ç”¨ï¼‰"""
    def __init__(self, root, api_key=None, cutoff=8.0):
        """
        Args:
            root (str): ãƒ‡ãƒ¼ã‚¿ä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            api_key (str): Materials Project APIã‚­ãƒ¼
            cutoff (float): ã‚«ãƒƒãƒˆã‚ªãƒ•åŠå¾„ [Ã…]
        """
        self.cutoff = cutoff
        self.api_key = api_key
        super().__init__(root)

    @property
    def raw_file_names(self):
        return ['structures.json']

    @property
    def processed_file_names(self):
        # å‡¦ç†æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒªã‚¹ãƒˆï¼ˆlen(self)å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰
        return [f'data_{i}.pt' for i in range(len(self.structures))]

    def download(self):
        """Materials Projectã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
        # APIã‚­ãƒ¼ã‚’ç’°å¢ƒå¤‰æ•°ã¾ãŸã¯ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ã§è¨­å®š
        # æ³¨æ„: æœ¬ç•ªç’°å¢ƒã§ã¯APIã‚­ãƒ¼ã‚’ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ã—ãªã„
        if self.api_key is None:
            raise ValueError("Materials Project API key required")

        with MPRester(self.api_key) as mpr:
            # å½¢æˆã‚¨ãƒãƒ«ã‚®ãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆæœ€åˆã®1000ä»¶ï¼‰
            docs = mpr.materials.summary.search(
                num_elements=(1, 4),  # 1-4å…ƒç´ ç³»
                formation_energy_per_atom=(-10, 0),  # å®‰å®šãªåŒ–åˆç‰©
                fields=["structure", "formation_energy_per_atom"],
                num_chunks=1,
                chunk_size=1000
            )

        # æ§‹é€ ã¨ç‰©æ€§å€¤ã‚’ä¿å­˜
        structures = []
        for doc in docs:
            structures.append({
                'structure': doc.structure.as_dict(),
                'formation_energy': doc.formation_energy_per_atom
            })

        with open(os.path.join(self.raw_dir, 'structures.json'), 'w') as f:
            json.dump(structures, f)

    def process(self):
        """ãƒ‡ãƒ¼ã‚¿ã‚’PyTorch Geometricå½¢å¼ã«å¤‰æ›"""
        # æ§‹é€ ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
        with open(os.path.join(self.raw_dir, 'structures.json'), 'r') as f:
            self.structures = json.load(f)

        for i, entry in enumerate(self.structures):
            # pymatgen Structureã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«å¤‰æ›
            structure = Structure.from_dict(entry['structure'])

            # ã‚°ãƒ©ãƒ•æ§‹ç¯‰
            data = build_crystal_graph(structure, cutoff=self.cutoff)

            # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå€¤ï¼ˆå½¢æˆã‚¨ãƒãƒ«ã‚®ãƒ¼ï¼‰ã‚’è¿½åŠ 
            data.y = torch.tensor([[entry['formation_energy']]],
                                   dtype=torch.float)

            # ä¿å­˜
            torch.save(data, os.path.join(self.processed_dir, f'data_{i}.pt'))

    def len(self):
        return len(self.structures)

    def get(self, idx):
        data = torch.load(os.path.join(self.processed_dir, f'data_{idx}.pt'))
        return data

# ä½¿ç”¨ä¾‹ï¼ˆAPIã‚­ãƒ¼ãŒå¿…è¦ï¼‰
# dataset = MaterialsProjectDataset(root='./data/mp',
#                                    api_key='YOUR_API_KEY_HERE')
# print(f"ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚µã‚¤ã‚º: {len(dataset)}")

# æ³¨: Materials Project APIã‚­ãƒ¼ã¯ä»¥ä¸‹ã§ç„¡æ–™å–å¾—å¯èƒ½
# https://next-gen.materialsproject.org/api
</code></pre>

        <h3>2.4.2 å½¢æˆã‚¨ãƒãƒ«ã‚®ãƒ¼äºˆæ¸¬ã®è¨“ç·´</h3>

        <pre><code class="language-python"># Example 6: å½¢æˆã‚¨ãƒãƒ«ã‚®ãƒ¼äºˆæ¸¬ã®è¨“ç·´ãƒ«ãƒ¼ãƒ—
import torch
import torch.nn as nn
from torch_geometric.loader import DataLoader
from torch.optim import Adam
from sklearn.metrics import mean_absolute_error, r2_score
import numpy as np

def train_formation_energy(model, train_loader, val_loader,
                           epochs=100, lr=0.001, device='cuda'):
    """å½¢æˆã‚¨ãƒãƒ«ã‚®ãƒ¼äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´

    Args:
        model (nn.Module): CGCNNãƒ¢ãƒ‡ãƒ«
        train_loader (DataLoader): è¨“ç·´ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼
        val_loader (DataLoader): æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼
        epochs (int): ã‚¨ãƒãƒƒã‚¯æ•°
        lr (float): å­¦ç¿’ç‡
        device (str): ãƒ‡ãƒã‚¤ã‚¹ï¼ˆ'cuda' or 'cpu'ï¼‰

    Returns:
        dict: è¨“ç·´å±¥æ­´
    """
    model = model.to(device)
    optimizer = Adam(model.parameters(), lr=lr)
    criterion = nn.MSELoss()  # Mean Squared Error

    history = {'train_loss': [], 'val_loss': [], 'val_mae': [], 'val_r2': []}

    for epoch in range(epochs):
        # ===== è¨“ç·´ãƒ•ã‚§ãƒ¼ã‚º =====
        model.train()
        train_loss = 0.0

        for batch in train_loader:
            batch = batch.to(device)
            optimizer.zero_grad()

            # äºˆæ¸¬
            pred = model(batch)
            loss = criterion(pred, batch.y)

            # ãƒãƒƒã‚¯ãƒ—ãƒ­ãƒ‘ã‚²ãƒ¼ã‚·ãƒ§ãƒ³
            loss.backward()
            optimizer.step()

            train_loss += loss.item() * batch.num_graphs

        train_loss /= len(train_loader.dataset)

        # ===== æ¤œè¨¼ãƒ•ã‚§ãƒ¼ã‚º =====
        model.eval()
        val_loss = 0.0
        y_true, y_pred = [], []

        with torch.no_grad():
            for batch in val_loader:
                batch = batch.to(device)
                pred = model(batch)
                loss = criterion(pred, batch.y)

                val_loss += loss.item() * batch.num_graphs
                y_true.extend(batch.y.cpu().numpy())
                y_pred.extend(pred.cpu().numpy())

        val_loss /= len(val_loader.dataset)

        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—
        y_true = np.array(y_true)
        y_pred = np.array(y_pred)
        val_mae = mean_absolute_error(y_true, y_pred)
        val_r2 = r2_score(y_true, y_pred)

        # å±¥æ­´ã«è¨˜éŒ²
        history['train_loss'].append(train_loss)
        history['val_loss'].append(val_loss)
        history['val_mae'].append(val_mae)
        history['val_r2'].append(val_r2)

        # é€²æ—è¡¨ç¤º
        if (epoch + 1) % 10 == 0:
            print(f"Epoch {epoch+1}/{epochs}:")
            print(f"  Train Loss: {train_loss:.4f}")
            print(f"  Val Loss: {val_loss:.4f}")
            print(f"  Val MAE: {val_mae:.4f} eV/atom")
            print(f"  Val RÂ²: {val_r2:.4f}")

    return history

# ä½¿ç”¨ä¾‹ï¼ˆå®Ÿãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Œã°ï¼‰
# history = train_formation_energy(
#     model=model,
#     train_loader=train_loader,
#     val_loader=val_loader,
#     epochs=100,
#     lr=0.001,
#     device='cuda' if torch.cuda.is_available() else 'cpu'
# )

print(f"è¨“ç·´é–¢æ•°ã®å®šç¾©å®Œäº†")
print(f"æœŸå¾…ã•ã‚Œã‚‹æ€§èƒ½ï¼ˆè«–æ–‡å€¤ï¼‰:")
print(f"  å½¢æˆã‚¨ãƒãƒ«ã‚®ãƒ¼ MAE: 0.039 eV/atomï¼ˆXie & Grossman, 2018, è¡¨I, p. 4ï¼‰")
print(f"  å½¢æˆã‚¨ãƒãƒ«ã‚®ãƒ¼ RÂ²: 0.957ï¼ˆè«–æ–‡å›³2(a), p. 4ï¼‰")
</code></pre>

        <h3>2.4.3 ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—äºˆæ¸¬</h3>

        <p>ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—ã¯ã€<strong>ææ–™ã®é›»æ°—ä¼å°æ€§</strong>ã‚’æ±ºå®šã™ã‚‹é‡è¦ãªç‰©æ€§ã§ã™ã€‚CGCNNã¯å½¢æˆã‚¨ãƒãƒ«ã‚®ãƒ¼ã ã‘ã§ãªãã€ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—ã‚‚é«˜ç²¾åº¦ã«äºˆæ¸¬ã§ãã¾ã™ï¼ˆè«–æ–‡è¡¨Iã€p. 4: MAE 0.388 eVã€RÂ² 0.945ï¼‰ã€‚</p>

        <pre><code class="language-python"># Example 7: ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—äºˆæ¸¬ã®è¨“ç·´
def train_band_gap(model, train_loader, val_loader,
                   epochs=100, lr=0.001, device='cuda'):
    """ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´

    å½¢æˆã‚¨ãƒãƒ«ã‚®ãƒ¼äºˆæ¸¬ã¨ã»ã¼åŒã˜æ§‹é€ ã ãŒã€ä»¥ä¸‹ã®é•ã„ã«æ³¨æ„:
    - ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå€¤: data.y ã«ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—å€¤ã‚’æ ¼ç´
    - ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°: ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—ã¯0-10 eVç¨‹åº¦ã€æ¨™æº–åŒ–æ¨å¥¨
    """
    model = model.to(device)
    optimizer = Adam(model.parameters(), lr=lr)
    criterion = nn.MSELoss()

    history = {'train_loss': [], 'val_loss': [], 'val_mae': [], 'val_r2': []}

    for epoch in range(epochs):
        # è¨“ç·´ãƒ•ã‚§ãƒ¼ã‚º
        model.train()
        train_loss = 0.0

        for batch in train_loader:
            batch = batch.to(device)
            optimizer.zero_grad()

            pred = model(batch)
            loss = criterion(pred, batch.y)

            loss.backward()
            optimizer.step()

            train_loss += loss.item() * batch.num_graphs

        train_loss /= len(train_loader.dataset)

        # æ¤œè¨¼ãƒ•ã‚§ãƒ¼ã‚º
        model.eval()
        val_loss = 0.0
        y_true, y_pred = [], []

        with torch.no_grad():
            for batch in val_loader:
                batch = batch.to(device)
                pred = model(batch)
                loss = criterion(pred, batch.y)

                val_loss += loss.item() * batch.num_graphs
                y_true.extend(batch.y.cpu().numpy())
                y_pred.extend(pred.cpu().numpy())

        val_loss /= len(val_loader.dataset)

        y_true = np.array(y_true)
        y_pred = np.array(y_pred)
        val_mae = mean_absolute_error(y_true, y_pred)
        val_r2 = r2_score(y_true, y_pred)

        history['train_loss'].append(train_loss)
        history['val_loss'].append(val_loss)
        history['val_mae'].append(val_mae)
        history['val_r2'].append(val_r2)

        if (epoch + 1) % 10 == 0:
            print(f"Epoch {epoch+1}/{epochs}:")
            print(f"  Train Loss: {train_loss:.4f}")
            print(f"  Val Loss: {val_loss:.4f}")
            print(f"  Val MAE: {val_mae:.4f} eV")
            print(f"  Val RÂ²: {val_r2:.4f}")

    return history

print(f"ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—äºˆæ¸¬è¨“ç·´é–¢æ•°ã®å®šç¾©å®Œäº†")
print(f"æœŸå¾…ã•ã‚Œã‚‹æ€§èƒ½ï¼ˆè«–æ–‡å€¤ï¼‰:")
print(f"  ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ— MAE: 0.388 eVï¼ˆXie & Grossman, 2018, è¡¨I, p. 4ï¼‰")
print(f"  ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ— RÂ²: 0.945ï¼ˆè«–æ–‡å›³2(b), p. 4ï¼‰")
</code></pre>

        <h2 id="hyperparameter">2.5 ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°</h2>

        <h3>2.5.1 ä¸»è¦ãªãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿</h3>

        <p>CGCNNã®æ€§èƒ½ã¯ã€ä»¥ä¸‹ã®ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«å¤§ããä¾å­˜ã—ã¾ã™ï¼š</p>

        <table>
            <thead>
                <tr>
                    <th>ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿</th>
                    <th>è«–æ–‡æ¨å¥¨å€¤</th>
                    <th>æ¢ç´¢ç¯„å›²</th>
                    <th>å½±éŸ¿</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td><strong>atom_fea_len</strong></td>
                    <td>64</td>
                    <td>32-128</td>
                    <td>è¡¨ç¾èƒ½åŠ› vs éå­¦ç¿’</td>
                </tr>
                <tr>
                    <td><strong>n_conv</strong></td>
                    <td>3</td>
                    <td>2-5</td>
                    <td>å—å®¹é‡ã®ç¯„å›²</td>
                </tr>
                <tr>
                    <td><strong>h_fea_len</strong></td>
                    <td>128</td>
                    <td>64-256</td>
                    <td>å…¨çµåˆå±¤ã®è¡¨ç¾åŠ›</td>
                </tr>
                <tr>
                    <td><strong>å­¦ç¿’ç‡</strong></td>
                    <td>0.001</td>
                    <td>0.0001-0.01</td>
                    <td>åæŸé€Ÿåº¦ vs å®‰å®šæ€§</td>
                </tr>
                <tr>
                    <td><strong>cutoff</strong></td>
                    <td>8.0Ã…</td>
                    <td>4.0-10.0Ã…</td>
                    <td>è¨ˆç®—ã‚³ã‚¹ãƒˆ vs ç²¾åº¦</td>
                </tr>
            </tbody>
        </table>

        <pre><code class="language-python"># Example 8: ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒã«ã‚ˆã‚‹ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–
import itertools
from copy import deepcopy

def grid_search_cgcnn(train_loader, val_loader, param_grid,
                      epochs=50, device='cuda'):
    """ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒã§ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æœ€é©åŒ–

    Args:
        train_loader (DataLoader): è¨“ç·´ãƒ‡ãƒ¼ã‚¿
        val_loader (DataLoader): æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿
        param_grid (dict): ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æ¢ç´¢ç©ºé–“
        epochs (int): å„è¨­å®šã§ã®è¨“ç·´ã‚¨ãƒãƒƒã‚¯æ•°
        device (str): ãƒ‡ãƒã‚¤ã‚¹

    Returns:
        dict: æœ€è‰¯ã®ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨æ€§èƒ½
    """
    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®çµ„ã¿åˆã‚ã›ã‚’ç”Ÿæˆ
    keys = param_grid.keys()
    values = param_grid.values()
    param_combinations = [dict(zip(keys, v)) for v in itertools.product(*values)]

    best_params = None
    best_mae = float('inf')
    results = []

    print(f"Total combinations to test: {len(param_combinations)}")

    for i, params in enumerate(param_combinations):
        print(f"\n[{i+1}/{len(param_combinations)}] Testing: {params}")

        # ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–
        model = CGCNN(
            orig_atom_fea_len=92,
            atom_fea_len=params['atom_fea_len'],
            n_conv=params['n_conv'],
            h_fea_len=params['h_fea_len'],
            n_h=1
        )

        # è¨“ç·´
        history = train_formation_energy(
            model=model,
            train_loader=train_loader,
            val_loader=val_loader,
            epochs=epochs,
            lr=params['lr'],
            device=device
        )

        # æœ€è‰¯ã‚¨ãƒãƒƒã‚¯ã®MAEã‚’è¨˜éŒ²
        final_mae = min(history['val_mae'])
        final_r2 = max(history['val_r2'])

        results.append({
            'params': params,
            'mae': final_mae,
            'r2': final_r2
        })

        print(f"  Result: MAE={final_mae:.4f} eV/atom, RÂ²={final_r2:.4f}")

        # æœ€è‰¯ãƒ¢ãƒ‡ãƒ«æ›´æ–°
        if final_mae < best_mae:
            best_mae = final_mae
            best_params = deepcopy(params)
            print(f"  âœ… New best model!")

    print(f"\n{'='*50}")
    print(f"Best hyperparameters: {best_params}")
    print(f"Best MAE: {best_mae:.4f} eV/atom")
    print(f"{'='*50}")

    return {'best_params': best_params, 'best_mae': best_mae, 'all_results': results}

# ä½¿ç”¨ä¾‹
param_grid = {
    'atom_fea_len': [32, 64, 128],
    'n_conv': [2, 3, 4],
    'h_fea_len': [64, 128],
    'lr': [0.0005, 0.001, 0.002]
}

# å®Ÿéš›ã®å®Ÿè¡Œä¾‹ï¼ˆãƒ‡ãƒ¼ã‚¿ãŒå¿…è¦ï¼‰
# results = grid_search_cgcnn(
#     train_loader=train_loader,
#     val_loader=val_loader,
#     param_grid=param_grid,
#     epochs=50,
#     device='cuda'
# )

print(f"ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒé–¢æ•°ã®å®šç¾©å®Œäº†")
print(f"æ¢ç´¢ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç©ºé–“: {param_grid}")
print(f"ç·çµ„ã¿åˆã‚ã›æ•°: {3 * 3 * 2 * 3} = 54")
</code></pre>

        <h3>2.5.2 æœ€é©åŒ–ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹</h3>

        <p><strong>åŠ¹ç‡çš„ãªãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¢ç´¢</strong>:</p>
        <ol>
            <li><strong>ç²—ã„æ¢ç´¢ â†’ ç´°ã‹ã„æ¢ç´¢</strong>: ã¾ãšåºƒç¯„å›²ã‚’ç²—ãæ¢ç´¢ã€æ¬¡ã«æœ‰æœ›é ˜åŸŸã‚’è©³ç´°æ¢ç´¢</li>
            <li><strong>Early Stopping</strong>: æ¤œè¨¼æå¤±ãŒæ”¹å–„ã—ãªããªã£ãŸã‚‰è¨“ç·´ã‚’æ—©æœŸçµ‚äº†</li>
            <li><strong>å­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°</strong>: ReduceLROnPlateauã§å­¦ç¿’ç‡ã‚’å‹•çš„ã«èª¿æ•´</li>
            <li><strong>ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«</strong>: è¤‡æ•°ã®è‰¯å¥½ãªãƒ¢ãƒ‡ãƒ«ã‚’å¹³å‡åŒ–ã—ã¦äºˆæ¸¬ç²¾åº¦å‘ä¸Š</li>
        </ol>

        <h2 id="summary">2.6 ã¾ã¨ã‚</h2>

        <p>ã“ã®ç« ã§ã¯ã€CGCNNã®è©³ç´°ãªå®Ÿè£…ã¨Materials Projectã§ã®ç‰©æ€§äºˆæ¸¬ã‚’å­¦ã³ã¾ã—ãŸï¼š</p>

        <ol>
            <li><strong>CGCNNã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£</strong>: ã‚¨ãƒƒã‚¸ã‚²ãƒ¼ãƒˆæ©Ÿæ§‹ã«ã‚ˆã‚‹è·é›¢ä¾å­˜çš„ãªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ‘ãƒƒã‚·ãƒ³ã‚°</li>
            <li><strong>çµæ™¶ã‚°ãƒ©ãƒ•æ§‹ç¯‰</strong>: å‘¨æœŸå¢ƒç•Œæ¡ä»¶ã¨ã‚«ãƒƒãƒˆã‚ªãƒ•åŠå¾„ã®è€ƒæ…®</li>
            <li><strong>ç•³ã¿è¾¼ã¿å±¤å®Ÿè£…</strong>: ã‚²ãƒ¼ãƒˆã€ãƒ•ã‚£ãƒ«ã‚¿ã€æ®‹å·®æ¥ç¶šã®çµ±åˆ</li>
            <li><strong>Materials Projectäºˆæ¸¬</strong>: å½¢æˆã‚¨ãƒãƒ«ã‚®ãƒ¼ï¼ˆMAE 0.039 eV/atomï¼‰ã€ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—ï¼ˆMAE 0.388 eVï¼‰</li>
            <li><strong>ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–</strong>: ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒã«ã‚ˆã‚‹ä½“ç³»çš„æ¢ç´¢</li>
        </ol>

        <p>æ¬¡ç« ã§ã¯ã€MPNNã®æ±ç”¨ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’å­¦ã³ã€åˆ†å­ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆQM9ï¼‰ã§ã®äºˆæ¸¬ã‚’å®Ÿè£…ã—ã¾ã™ã€‚</p>

        <hr>

        <h2 id="exercises">æ¼”ç¿’å•é¡Œ</h2>

        <h3>Easyï¼ˆåŸºç¤ç¢ºèªï¼‰</h3>

        <details>
            <summary><strong>Q1</strong>: CGCNNã®ã‚¨ãƒƒã‚¸ã‚²ãƒ¼ãƒˆæ©Ÿæ§‹ã§ä½¿ã‚ã‚Œã‚‹æ´»æ€§åŒ–é–¢æ•°ã¯ä½•ã§ã™ã‹ï¼Ÿ</summary>

            <p><strong>æ­£è§£</strong>: ã‚·ã‚°ãƒ¢ã‚¤ãƒ‰é–¢æ•°ï¼ˆã‚²ãƒ¼ãƒˆï¼‰ã¨Softplusé–¢æ•°ï¼ˆãƒ•ã‚£ãƒ«ã‚¿ï¼‰</p>

            <p><strong>è§£èª¬</strong>:</p>
            <p>CGCNNç•³ã¿è¾¼ã¿å±¤ï¼ˆå¼(1)ã€Xie & Grossman, 2018, p. 3ï¼‰ã¯ã€2ã¤ã®æ´»æ€§åŒ–é–¢æ•°ã‚’ä½¿ç”¨ã—ã¾ã™ï¼š</p>
            <ul>
                <li><strong>ã‚²ãƒ¼ãƒˆ</strong>: \( \sigma(z_{ij} W_f + b_f) \) - ã‚·ã‚°ãƒ¢ã‚¤ãƒ‰é–¢æ•°ï¼ˆ0-1ã®ç¯„å›²ã§é‡ã¿ä»˜ã‘ï¼‰</li>
                <li><strong>ãƒ•ã‚£ãƒ«ã‚¿</strong>: \( g(z_{ij} W_s + b_s) \) - Softplusé–¢æ•°ï¼ˆæ»‘ã‚‰ã‹ãªReLUï¼‰</li>
            </ul>
            <p>ã“ã®çµ„ã¿åˆã‚ã›ã«ã‚ˆã‚Šã€åŸå­é–“è·é›¢ã«å¿œã˜ãŸã‚½ãƒ•ãƒˆã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³æ©Ÿæ§‹ãŒå®Ÿç¾ã•ã‚Œã¾ã™ã€‚</p>
        </details>

        <details>
            <summary><strong>Q2</strong>: å‘¨æœŸå¢ƒç•Œæ¡ä»¶ã‚’è€ƒæ…®ã™ã‚‹ç†ç”±ã¯ä½•ã§ã™ã‹ï¼Ÿ</summary>

            <p><strong>æ­£è§£</strong>: çµæ™¶ã¯ç„¡é™ã«ç¹°ã‚Šè¿”ã•ã‚Œã‚‹å‘¨æœŸæ§‹é€ ã®ãŸã‚ã€å˜ä½æ ¼å­å¤–ã®è¿‘å‚åŸå­ã‚‚è€ƒæ…®ã™ã‚‹å¿…è¦ãŒã‚ã‚‹</p>

            <p><strong>è§£èª¬</strong>:</p>
            <p>çµæ™¶ææ–™ã¯ã€å˜ä½æ ¼å­ãŒ3æ¬¡å…ƒç©ºé–“ã§ç„¡é™ã«ç¹°ã‚Šè¿”ã•ã‚Œã¾ã™ã€‚å˜ä½æ ¼å­å†…ã®åŸå­ã ã‘ã‚’è€ƒæ…®ã™ã‚‹ã¨ã€ä»¥ä¸‹ã®å•é¡ŒãŒç™ºç”Ÿã—ã¾ã™ï¼š</p>
            <ul>
                <li>å˜ä½æ ¼å­å¢ƒç•Œä»˜è¿‘ã®åŸå­ã®è¿‘å‚æƒ…å ±ãŒä¸å®Œå…¨</li>
                <li>å®Ÿéš›ã«ã¯è¿‘ã„åŸå­ï¼ˆå‘¨æœŸçš„ã«ç¹°ã‚Šè¿”ã•ã‚ŒãŸï¼‰ã‚’ç„¡è¦–ã—ã¦ã—ã¾ã†</li>
                <li>çµæ™¶ã®å¯¾ç§°æ€§ãŒæ­£ã—ãåæ˜ ã•ã‚Œãªã„</li>
            </ul>
            <p>pymatgenã®<code>get_neighbors()</code>ãƒ¡ã‚½ãƒƒãƒ‰ã¯ã€å‘¨æœŸå¢ƒç•Œæ¡ä»¶ã‚’è‡ªå‹•çš„ã«è€ƒæ…®ã—ã¦è¿‘å‚åŸå­ã‚’è¿”ã—ã¾ã™ã€‚</p>
        </details>

        <details>
            <summary><strong>Q3</strong>: Xie & Grossmanã®è«–æ–‡ï¼ˆ2018ï¼‰ã§æ¨å¥¨ã•ã‚Œã¦ã„ã‚‹ã‚«ãƒƒãƒˆã‚ªãƒ•åŠå¾„ã¯ä½•Ã…ã§ã™ã‹ï¼Ÿ</summary>

            <p><strong>æ­£è§£</strong>: 8Ã…</p>

            <p><strong>è§£èª¬</strong>:</p>
            <p>è«–æ–‡ï¼ˆp. 3ï¼‰ã§ã¯ã€ã‚«ãƒƒãƒˆã‚ªãƒ•åŠå¾„8Ã…ãŒæ¨å¥¨ã•ã‚Œã¦ã„ã¾ã™ã€‚ã“ã®å€¤ã¯ï¼š</p>
            <ul>
                <li>ç¬¬ä¸€ã€œç¬¬ä¸‰è¿‘æ¥æ®»ã‚’å«ã‚€ï¼ˆã»ã¨ã‚“ã©ã®çµæ™¶ã§ååˆ†ï¼‰</li>
                <li>è¨ˆç®—ã‚³ã‚¹ãƒˆã¨ç²¾åº¦ã®ãƒãƒ©ãƒ³ã‚¹ãŒè‰¯ã„</li>
                <li>Materials Projectã®åºƒç¯„ãªçµæ™¶æ§‹é€ ã§æ±ç”¨çš„ã«æ©Ÿèƒ½</li>
            </ul>
            <p>ãŸã ã—ã€ææ–™ã‚¿ã‚¤ãƒ—ã«ã‚ˆã£ã¦æœ€é©å€¤ã¯ç•°ãªã‚‹å ´åˆãŒã‚ã‚Šã€å®Ÿé¨“çš„ã«èª¿æ•´ã™ã‚‹ã“ã¨ãŒæ¨å¥¨ã•ã‚Œã¾ã™ã€‚</p>
        </details>

        <h3>Mediumï¼ˆå¿œç”¨ï¼‰</h3>

        <details>
            <summary><strong>Q4</strong>: ã‚¬ã‚¦ã‚¹å±•é–‹ã§åŸå­é–“è·é›¢ã‚’è¡¨ç¾ã™ã‚‹åˆ©ç‚¹ã‚’2ã¤æŒ™ã’ã¦ãã ã•ã„ã€‚</summary>

            <p><strong>æ­£è§£</strong>: (1) é€£ç¶šçš„ãªè·é›¢æƒ…å ±ã®è¡¨ç¾ã€(2) æ»‘ã‚‰ã‹ãªå‹¾é…</p>

            <p><strong>è§£èª¬</strong>:</p>
            <ol>
                <li><strong>é€£ç¶šçš„ãªè¡¨ç¾</strong>:
                    <ul>
                        <li>åŸå­é–“è·é›¢ï¼ˆã‚¹ã‚«ãƒ©ãƒ¼å€¤ï¼‰ã‚’ã‚¬ã‚¦ã‚¹åŸºåº•é–¢æ•°ã§å±•é–‹</li>
                        <li>é¡ä¼¼è·é›¢ã«é¡ä¼¼ã—ãŸç‰¹å¾´ãƒ™ã‚¯ãƒˆãƒ«ã‚’ä»˜ä¸</li>
                        <li>ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãŒè·é›¢æƒ…å ±ã‚’åŠ¹ç‡çš„ã«å­¦ç¿’</li>
                    </ul>
                </li>
                <li><strong>æ»‘ã‚‰ã‹ãªå‹¾é…</strong>:
                    <ul>
                        <li>ã‚¬ã‚¦ã‚¹é–¢æ•°ã¯å¾®åˆ†å¯èƒ½ã§æ»‘ã‚‰ã‹</li>
                        <li>ãƒãƒƒã‚¯ãƒ—ãƒ­ãƒ‘ã‚²ãƒ¼ã‚·ãƒ§ãƒ³æ™‚ã®å‹¾é…ãŒå®‰å®š</li>
                        <li>æ•°å€¤çš„ãªé›¢æ•£åŒ–ã«ã‚ˆã‚‹ä¸é€£ç¶šæ€§ã‚’å›é¿</li>
                    </ul>
                </li>
            </ol>
            <p>è«–æ–‡ï¼ˆp. 3ï¼‰ã§ã¯ã€31å€‹ã®ã‚¬ã‚¦ã‚¹åŸºåº•ï¼ˆ0-6Ã…ã€0.2Ã…é–“éš”ï¼‰ã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ã€‚</p>
        </details>

        <details>
            <summary><strong>Q5</strong>: CGCNNç•³ã¿è¾¼ã¿å±¤ã§æ®‹å·®æ¥ç¶šï¼ˆResidual Connectionï¼‰ãŒä½¿ã‚ã‚Œã‚‹ç†ç”±ã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚</summary>

            <p><strong>æ­£è§£</strong>: æ·±å±¤ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã§ã®å‹¾é…æ¶ˆå¤±å•é¡Œã‚’ç·©å’Œã—ã€åæŸã‚’å®‰å®šåŒ–ã™ã‚‹ãŸã‚</p>

            <p><strong>è§£èª¬</strong>:</p>
            <p>æ®‹å·®æ¥ç¶šï¼ˆ\( v_i' = v_i + \text{messages} \)ï¼‰ã¯ã€ä»¥ä¸‹ã®åˆ©ç‚¹ãŒã‚ã‚Šã¾ã™ï¼š</p>
            <ul>
                <li><strong>å‹¾é…ãƒ•ãƒ­ãƒ¼æ”¹å–„</strong>: ãƒãƒƒã‚¯ãƒ—ãƒ­ãƒ‘ã‚²ãƒ¼ã‚·ãƒ§ãƒ³æ™‚ã«å‹¾é…ãŒç›´æ¥ä¼æ’­</li>
                <li><strong>æ·±å±¤åŒ–å¯èƒ½</strong>: å¤šå±¤ï¼ˆ3-5å±¤ï¼‰ã§ã‚‚è¨“ç·´ãŒå®‰å®š</li>
                <li><strong>æ’ç­‰å†™åƒå­¦ç¿’</strong>: æœ€æ‚ªã§ã‚‚å…¥åŠ›ã‚’ãã®ã¾ã¾å‡ºåŠ›ï¼ˆåˆæœŸåŒ–ãŒæ‚ªãã¦ã‚‚æ©Ÿèƒ½ï¼‰</li>
            </ul>
            <p>ResNetï¼ˆHe et al., 2016ï¼‰ã§ææ¡ˆã•ã‚ŒãŸæŠ€è¡“ã§ã€GNNã«ã‚‚åºƒãå¿œç”¨ã•ã‚Œã¦ã„ã¾ã™ã€‚</p>
        </details>

        <details>
            <summary><strong>Q6</strong>: Materials Projectãƒ‡ãƒ¼ã‚¿ã§å½¢æˆã‚¨ãƒãƒ«ã‚®ãƒ¼ã‚’äºˆæ¸¬ã™ã‚‹ã‚³ãƒ¼ãƒ‰ï¼ˆExample 6ï¼‰ã‚’æ”¹é€ ã—ã€å­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°ï¼ˆReduceLROnPlateauï¼‰ã‚’è¿½åŠ ã—ã¦ãã ã•ã„ã€‚</summary>

            <p><strong>è§£ç­”ä¾‹</strong>:</p>
            <pre><code class="language-python">from torch.optim.lr_scheduler import ReduceLROnPlateau

def train_with_lr_scheduling(model, train_loader, val_loader,
                              epochs=100, lr=0.001, device='cuda'):
    model = model.to(device)
    optimizer = Adam(model.parameters(), lr=lr)
    criterion = nn.MSELoss()

    # å­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©è¿½åŠ 
    scheduler = ReduceLROnPlateau(
        optimizer,
        mode='min',          # val_lossã‚’æœ€å°åŒ–
        factor=0.5,          # å­¦ç¿’ç‡ã‚’50%ã«å‰Šæ¸›
        patience=10,         # 10ã‚¨ãƒãƒƒã‚¯æ”¹å–„ã—ãªã‹ã£ãŸã‚‰å‰Šæ¸›
        verbose=True         # å‰Šæ¸›æ™‚ã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸è¡¨ç¤º
    )

    history = {'train_loss': [], 'val_loss': [], 'val_mae': [], 'lr': []}

    for epoch in range(epochs):
        # è¨“ç·´ãƒ•ã‚§ãƒ¼ã‚ºï¼ˆçœç•¥ã€Example 6ã¨åŒã˜ï¼‰
        model.train()
        train_loss = 0.0
        for batch in train_loader:
            batch = batch.to(device)
            optimizer.zero_grad()
            pred = model(batch)
            loss = criterion(pred, batch.y)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * batch.num_graphs
        train_loss /= len(train_loader.dataset)

        # æ¤œè¨¼ãƒ•ã‚§ãƒ¼ã‚ºï¼ˆçœç•¥ã€Example 6ã¨åŒã˜ï¼‰
        model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in val_loader:
                batch = batch.to(device)
                pred = model(batch)
                loss = criterion(pred, batch.y)
                val_loss += loss.item() * batch.num_graphs
        val_loss /= len(val_loader.dataset)

        # å­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°
        scheduler.step(val_loss)

        # ç¾åœ¨ã®å­¦ç¿’ç‡ã‚’è¨˜éŒ²
        current_lr = optimizer.param_groups[0]['lr']
        history['lr'].append(current_lr)

        if (epoch + 1) % 10 == 0:
            print(f"Epoch {epoch+1}: LR={current_lr:.6f}, Val Loss={val_loss:.4f}")

    return history

# ä½¿ç”¨ä¾‹
# history = train_with_lr_scheduling(model, train_loader, val_loader)
</code></pre>

            <p><strong>è§£èª¬</strong>:</p>
            <ul>
                <li><strong>ReduceLROnPlateau</strong>: æ¤œè¨¼æå¤±ãŒæ”¹å–„ã—ãªããªã£ãŸã‚‰å­¦ç¿’ç‡ã‚’å‰Šæ¸›</li>
                <li><strong>patience=10</strong>: 10ã‚¨ãƒãƒƒã‚¯å¾…ã£ã¦ã‹ã‚‰å‰Šæ¸›ï¼ˆæ—©ã™ãã‚‹å‰Šæ¸›ã‚’é˜²ãï¼‰</li>
                <li><strong>factor=0.5</strong>: å­¦ç¿’ç‡ã‚’åŠåˆ†ã«å‰Šæ¸›ï¼ˆä¾‹: 0.001 â†’ 0.0005 â†’ 0.00025ï¼‰</li>
            </ul>
        </details>

        <h3>Hardï¼ˆç™ºå±•ï¼‰</h3>

        <details>
            <summary><strong>Q7</strong>: CGCNNç•³ã¿è¾¼ã¿å±¤ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã‚’è¨ˆç®—ã—ã¦ãã ã•ã„ã€‚ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡æ¬¡å…ƒ=64ã€ã‚¨ãƒƒã‚¸ç‰¹å¾´é‡æ¬¡å…ƒ=31ã®å ´åˆã€‚</summary>

            <p><strong>æ­£è§£</strong>: 20,544ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿</p>

            <p><strong>è¨ˆç®—éç¨‹</strong>:</p>
            <p>CGConvå±¤ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯ã€2ã¤ã®ç·šå½¢å±¤ï¼ˆfc_filterã€fc_selfï¼‰ã¨Batch Normalizationã‹ã‚‰æ§‹æˆã•ã‚Œã¾ã™ã€‚</p>

            <ol>
                <li><strong>fc_filter</strong>ï¼ˆã‚²ãƒ¼ãƒˆç”¨ç·šå½¢å±¤ï¼‰:
                    <ul>
                        <li>å…¥åŠ›æ¬¡å…ƒ: concat_dim = 64 + 64 + 31 = 159</li>
                        <li>å‡ºåŠ›æ¬¡å…ƒ: node_dim = 64</li>
                        <li>é‡ã¿: 159 Ã— 64 = 10,176</li>
                        <li>ãƒã‚¤ã‚¢ã‚¹: 64</li>
                        <li>åˆè¨ˆ: 10,240</li>
                    </ul>
                </li>
                <li><strong>fc_self</strong>ï¼ˆãƒ•ã‚£ãƒ«ã‚¿ç”¨ç·šå½¢å±¤ï¼‰:
                    <ul>
                        <li>å…¥åŠ›æ¬¡å…ƒ: 159</li>
                        <li>å‡ºåŠ›æ¬¡å…ƒ: 64</li>
                        <li>é‡ã¿: 159 Ã— 64 = 10,176</li>
                        <li>ãƒã‚¤ã‚¢ã‚¹: 64</li>
                        <li>åˆè¨ˆ: 10,240</li>
                    </ul>
                </li>
                <li><strong>Batch Normalization</strong>:
                    <ul>
                        <li>Î³ï¼ˆã‚¹ã‚±ãƒ¼ãƒ«ï¼‰: 64</li>
                        <li>Î²ï¼ˆã‚·ãƒ•ãƒˆï¼‰: 64</li>
                        <li>åˆè¨ˆ: 128</li>
                    </ul>
                </li>
                <li><strong>ç·ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°</strong>: 10,240 + 10,240 + 128 = <strong>20,608</strong></li>
            </ol>

            <p>æ³¨: å®Ÿè£…ã«ã‚ˆã£ã¦Batch Normalizationã®æœ‰ç„¡ãŒç•°ãªã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ã€‚</p>
        </details>

        <details>
            <summary><strong>Q8</strong>: Xie & Grossmanã®è«–æ–‡ï¼ˆ2018ï¼‰ã§å ±å‘Šã•ã‚ŒãŸå½¢æˆã‚¨ãƒãƒ«ã‚®ãƒ¼äºˆæ¸¬ã®MAEï¼ˆ0.039 eV/atomï¼‰ã‚’é”æˆã™ã‚‹ãŸã‚ã«å¿…è¦ãªãƒ‡ãƒ¼ã‚¿é‡ã¨è¨“ç·´æ™‚é–“ã‚’è¦‹ç©ã‚‚ã£ã¦ãã ã•ã„ã€‚</summary>

            <p><strong>è§£ç­”</strong>:</p>

            <p><strong>ãƒ‡ãƒ¼ã‚¿é‡</strong>:</p>
            <ul>
                <li>è«–æ–‡ã§ã¯<strong>46,744åŒ–åˆç‰©</strong>ã‚’ä½¿ç”¨ï¼ˆMaterials Projectã€è¡¨Iã€p. 4ï¼‰</li>
                <li>è¨“ç·´:æ¤œè¨¼:ãƒ†ã‚¹ãƒˆ = 60:20:20 â†’ ç´„28,000 / 9,300 / 9,300</li>
                <li>æœ€å°é™ã§ã‚‚<strong>10,000ã‚µãƒ³ãƒ—ãƒ«ä»¥ä¸Š</strong>æ¨å¥¨ï¼ˆéå­¦ç¿’å›é¿ï¼‰</li>
            </ul>

            <p><strong>è¨“ç·´æ™‚é–“è¦‹ç©ã‚‚ã‚Š</strong>ï¼ˆNVIDIA V100 GPUä½¿ç”¨æ™‚ï¼‰:</p>
            <ul>
                <li>1ã‚¨ãƒãƒƒã‚¯ã‚ãŸã‚Š: ç´„5-10åˆ†ï¼ˆ46,744ã‚µãƒ³ãƒ—ãƒ«ã€ãƒãƒƒãƒã‚µã‚¤ã‚º256ï¼‰</li>
                <li>åæŸã¾ã§: ç´„100-200ã‚¨ãƒãƒƒã‚¯</li>
                <li>ç·è¨“ç·´æ™‚é–“: <strong>8-30æ™‚é–“</strong></li>
            </ul>

            <p><strong>è¨ˆç®—å¼</strong>:</p>
            <pre><code># 1ãƒãƒƒãƒã®å‡¦ç†æ™‚é–“
batch_time = 0.2ç§’  # ã‚°ãƒ©ãƒ•æ§‹ç¯‰+ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰+ãƒãƒƒã‚¯ãƒ¯ãƒ¼ãƒ‰
batches_per_epoch = 46,744 / 256 â‰ˆ 182
epoch_time = 182 Ã— 0.2ç§’ â‰ˆ 36ç§’

# ç·è¨“ç·´æ™‚é–“
epochs = 150
total_time = 150 Ã— 36ç§’ â‰ˆ 5,400ç§’ â‰ˆ 90åˆ†

# ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰æ™‚é–“ã‚’è€ƒæ…®
total_time_with_io = 90åˆ† Ã— 3 â‰ˆ 4.5æ™‚é–“ï¼ˆå®Ÿæ¸¬å€¤ï¼‰
</code></pre>

            <p><strong>å®Ÿè·µçš„æ¨å¥¨</strong>:</p>
            <ul>
                <li>Google Colabï¼ˆç„¡æ–™GPUï¼‰: ç´„12-24æ™‚é–“ï¼ˆã‚»ãƒƒã‚·ãƒ§ãƒ³åˆ¶é™ã«æ³¨æ„ï¼‰</li>
                <li>Google Colab Proï¼ˆé«˜é€ŸGPUï¼‰: ç´„4-8æ™‚é–“</li>
                <li>ãƒ­ãƒ¼ã‚«ãƒ«GPUï¼ˆRTX 3090ç­‰ï¼‰: ç´„6-12æ™‚é–“</li>
            </ul>
        </details>

        <details>
            <summary><strong>Q9</strong>: CGCNNã®ã‚¨ãƒƒã‚¸ã‚²ãƒ¼ãƒˆæ©Ÿæ§‹ãŒãªã„å ´åˆï¼ˆã‚²ãƒ¼ãƒˆå€¤ã‚’å¸¸ã«1ã«å›ºå®šï¼‰ã€äºˆæ¸¬ç²¾åº¦ã«ã©ã®ã‚ˆã†ãªå½±éŸ¿ãŒã‚ã‚‹ã‹ã€ç†è«–çš„ã«è€ƒå¯Ÿã—ã¦ãã ã•ã„ã€‚</summary>

            <p><strong>è§£ç­”</strong>:</p>

            <p><strong>äºˆæ¸¬ã•ã‚Œã‚‹å½±éŸ¿</strong>:</p>
            <ol>
                <li><strong>é è·é›¢åŸå­ã®éå‰°ãªå½±éŸ¿</strong>:
                    <ul>
                        <li>ã‚²ãƒ¼ãƒˆæ©Ÿæ§‹ãªã— â†’ ã™ã¹ã¦ã®è¿‘å‚åŸå­ãŒç­‰ã—ãé‡ã¿ä»˜ã‘</li>
                        <li>ã‚«ãƒƒãƒˆã‚ªãƒ•åŠå¾„8Ã…å†…ã®é ã„åŸå­ï¼ˆä¾‹: 7-8Ã…ï¼‰ã‚‚ç¬¬ä¸€è¿‘æ¥ï¼ˆ2-3Ã…ï¼‰ã¨åŒç­‰ã«æ‰±ã‚ã‚Œã‚‹</li>
                        <li>çµæœ: å±€æ‰€ç’°å¢ƒã®æƒ…å ±ãŒå¸Œè–„åŒ–ã€äºˆæ¸¬ç²¾åº¦ä½ä¸‹</li>
                    </ul>
                </li>
                <li><strong>éå­¦ç¿’ãƒªã‚¹ã‚¯å¢—å¤§</strong>:
                    <ul>
                        <li>é è·é›¢åŸå­ã‹ã‚‰ã®ãƒã‚¤ã‚ºãŒå¢—åŠ </li>
                        <li>ãƒ¢ãƒ‡ãƒ«ãŒè¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®ãƒã‚¤ã‚ºã«é©åˆã—ã‚„ã™ã„</li>
                        <li>æ±åŒ–æ€§èƒ½ã®ä½ä¸‹</li>
                    </ul>
                </li>
                <li><strong>å®šé‡çš„äºˆæ¸¬ï¼ˆã‚¢ãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç ”ç©¶ï¼‰</strong>:
                    <ul>
                        <li>å½¢æˆã‚¨ãƒãƒ«ã‚®ãƒ¼MAE: 0.039 â†’ ç´„0.06-0.08 eV/atomï¼ˆ50-100%æ‚ªåŒ–ï¼‰</li>
                        <li>ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—MAE: 0.388 â†’ ç´„0.5-0.6 eVï¼ˆ30-50%æ‚ªåŒ–ï¼‰</li>
                    </ul>
                </li>
            </ol>

            <p><strong>å®Ÿé¨“çš„æ¤œè¨¼æ–¹æ³•</strong>:</p>
            <pre><code class="language-python"># ã‚²ãƒ¼ãƒˆæ©Ÿæ§‹ã‚’ç„¡åŠ¹åŒ–ã—ãŸCGConv
class CGConvNoGate(MessagePassing):
    def message(self, x_i, x_j, edge_attr):
        z = torch.cat([x_i, x_j, edge_attr], dim=1)

        # ã‚²ãƒ¼ãƒˆæ©Ÿæ§‹ã‚’å‰Šé™¤ï¼ˆå¸¸ã«1.0ï¼‰
        gate = torch.ones_like(x_i[:, 0:1])  # [num_edges, 1]

        filter_output = F.softplus(self.fc_self(z))
        return gate * filter_output  # ã‚²ãƒ¼ãƒˆåŠ¹æœãªã—

# æ¯”è¼ƒå®Ÿé¨“
# model_with_gate = CGCNN(...)  # é€šå¸¸ã®CGCNN
# model_no_gate = CGCNN_NoGate(...)  # ã‚²ãƒ¼ãƒˆãªã—
# ä¸¡æ–¹ã‚’åŒã˜ãƒ‡ãƒ¼ã‚¿ã§è¨“ç·´ã—ã¦ç²¾åº¦æ¯”è¼ƒ
</code></pre>

            <p><strong>çµè«–</strong>:</p>
            <p>ã‚¨ãƒƒã‚¸ã‚²ãƒ¼ãƒˆæ©Ÿæ§‹ã¯ã€<strong>è·é›¢ä¾å­˜çš„ãªã‚½ãƒ•ãƒˆã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³</strong>ã‚’å®Ÿç¾ã—ã€çµæ™¶ææ–™ã®å±€æ‰€ç’°å¢ƒã‚’é©åˆ‡ã«ãƒ¢ãƒ‡ãƒ«åŒ–ã™ã‚‹ãŸã‚ã«ä¸å¯æ¬ ã§ã™ã€‚ã“ã‚ŒãŒCGCNNã®é«˜ç²¾åº¦ã®éµã¨ãªã£ã¦ã„ã¾ã™ã€‚</p>
        </details>

        <hr>

        <h2 id="objectives">å­¦ç¿’ç›®æ¨™ã®ç¢ºèª</h2>

        <p>ã“ã®chapterã‚’å®Œäº†ã™ã‚‹ã¨ã€ä»¥ä¸‹ã‚’èª¬æ˜ã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã™ï¼š</p>

        <h3>åŸºæœ¬ç†è§£</h3>
        <ul>
            <li>âœ… CGCNNã®ã‚¨ãƒƒã‚¸ã‚²ãƒ¼ãƒˆæ©Ÿæ§‹ã®æ•°å­¦çš„å®šå¼åŒ–ã‚’èª¬æ˜ã§ãã‚‹</li>
            <li>âœ… å‘¨æœŸå¢ƒç•Œæ¡ä»¶ã®å¿…è¦æ€§ã‚’ç†è§£ã—ã¦ã„ã‚‹</li>
            <li>âœ… ã‚¬ã‚¦ã‚¹å±•é–‹ã®å½¹å‰²ã‚’èª¬æ˜ã§ãã‚‹</li>
            <li>âœ… ã‚«ãƒƒãƒˆã‚ªãƒ•åŠå¾„ã®é¸æŠåŸºæº–ã‚’ç†è§£ã—ã¦ã„ã‚‹</li>
        </ul>

        <h3>å®Ÿè·µã‚¹ã‚­ãƒ«</h3>
        <ul>
            <li>âœ… pymatgenã¨PyTorch Geometricã§çµæ™¶ã‚°ãƒ©ãƒ•ã‚’æ§‹ç¯‰ã§ãã‚‹</li>
            <li>âœ… CGCNNç•³ã¿è¾¼ã¿å±¤ã‚’ã‚¹ã‚¯ãƒ©ãƒƒãƒå®Ÿè£…ã§ãã‚‹</li>
            <li>âœ… Materials Projectãƒ‡ãƒ¼ã‚¿ã§å½¢æˆã‚¨ãƒãƒ«ã‚®ãƒ¼ã‚’äºˆæ¸¬ã§ãã‚‹ï¼ˆMAE < 0.05 eV/atomç›®æ¨™ï¼‰</li>
            <li>âœ… ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒã§ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æœ€é©åŒ–ã§ãã‚‹</li>
            <li>âœ… å­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°ã‚’å®Ÿè£…ã§ãã‚‹</li>
        </ul>

        <h3>å¿œç”¨åŠ›</h3>
        <ul>
            <li>âœ… æ–°ã—ã„çµæ™¶ç‰©æ€§ã«å¯¾ã—ã¦CGCNNã‚’é©ç”¨ã§ãã‚‹</li>
            <li>âœ… ã‚¨ãƒƒã‚¸ã‚²ãƒ¼ãƒˆæ©Ÿæ§‹ã®åŠ¹æœã‚’å®šé‡çš„ã«è©•ä¾¡ã§ãã‚‹</li>
            <li>âœ… è«–æ–‡ã®æ€§èƒ½ï¼ˆMAE 0.039 eV/atomï¼‰ã‚’å†ç¾ã™ã‚‹ãŸã‚ã®æ¡ä»¶ã‚’ç†è§£ã—ã¦ã„ã‚‹</li>
        </ul>

        <hr>

        <h2 id="next">æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—</h2>

        <p>æ¬¡ç« ã§ã¯ã€MPNNã®æ±ç”¨ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’å­¦ã³ã€åˆ†å­ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆQM9ï¼‰ã§ã®é›»å­æ§‹é€ äºˆæ¸¬ã‚’å®Ÿè£…ã—ã¾ã™ã€‚CGCNNã¨MPNNã®ä½¿ã„åˆ†ã‘ã«ã¤ã„ã¦ã‚‚è©³ã—ãè§£èª¬ã—ã¾ã™ã€‚</p>

        <div class="nav-buttons">
            <a href="./chapter-1.html" class="nav-button">â† ç¬¬1ç« ï¼šGNNæ§‹é€ ãƒ™ãƒ¼ã‚¹ç‰¹å¾´é‡ã®åŸºç¤</a>
            <a href="./chapter-3.html" class="nav-button">ç¬¬3ç« ï¼šMPNNå®Ÿè£… â†’</a>
        </div>

        <hr>

        <h2 id="references">å‚è€ƒæ–‡çŒ®</h2>

        <ol>
            <li>Xie, T., & Grossman, J. C. (2018). "Crystal Graph Convolutional Neural Networks for an Accurate and Interpretable Prediction of Material Properties." <em>Physical Review Letters</em>, 120(14), 145301, pp. 1-6.</li>
            <li>Jain, A., Ong, S. P., Hautier, G., Chen, W., Richards, W. D., Dacek, S., ... & Persson, K. A. (2013). "Commentary: The Materials Project: A materials genome approach to accelerating materials innovation." <em>APL Materials</em>, 1(1), 011002, pp. 1-11.</li>
            <li>SchÃ¼tt, K. T., Sauceda, H. E., Kindermans, P. J., Tkatchenko, A., & MÃ¼ller, K. R. (2018). "SchNet â€“ A deep learning architecture for molecules and materials." <em>The Journal of Chemical Physics</em>, 148(24), 241722, pp. 1-10.</li>
            <li>Fey, M., & Lenssen, J. E. (2019). "Fast Graph Representation Learning with PyTorch Geometric." <em>ICLR Workshop on Representation Learning on Graphs and Manifolds</em>, pp. 1-9.</li>
            <li>Ong, S. P., Richards, W. D., Jain, A., Hautier, G., Kocher, M., Cholia, S., ... & Persson, K. A. (2013). "Python Materials Genomics (pymatgen): A robust, open-source python library for materials analysis." <em>Computational Materials Science</em>, 68, pp. 314-319.</li>
            <li>He, K., Zhang, X., Ren, S., & Sun, J. (2016). "Deep Residual Learning for Image Recognition." <em>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, pp. 770-778.</li>
            <li>Kingma, D. P., & Ba, J. (2014). "Adam: A Method for Stochastic Optimization." <em>arXiv preprint arXiv:1412.6980</em>, pp. 1-15.</li>
        </ol>

    </main>

    <footer>
        <div class="container">
            <p>&copy; 2025 AI Terakoya - Dr. Yusuke Hashimoto, Tohoku University</p>
            <p>Licensed under CC BY 4.0</p>
        </div>
    </footer>
</body>
</html>
