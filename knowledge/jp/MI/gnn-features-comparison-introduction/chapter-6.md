---
title: "Chapter 6: PyTorch Geometricãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼"
chapter_title: "Chapter 6: PyTorch Geometricãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼"
---

ğŸŒ JP | [ğŸ‡¬ğŸ‡§ EN](<../../../en/MI/gnn-features-comparison-introduction/chapter-6.html>) | Last sync: 2025-11-16

# Chapter 6: PyTorch Geometricãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼

æœ¬ç« ã§ã¯ã€PyTorch Geometricã¨Materials Project APIã‚’ç”¨ã„ãŸå®Ÿè·µçš„ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’å­¦ã³ã¾ã™ã€‚ã‚«ã‚¹ã‚¿ãƒ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ä½œæˆã€åˆ†æ•£å­¦ç¿’ã€GPUæœ€é©åŒ–ã€ãã—ã¦æœ¬ç•ªç’°å¢ƒã¸ã®ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆã¾ã§ã€å®Ÿéš›ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§å¿…è¦ã¨ãªã‚‹æŠ€è¡“ã‚’åŒ…æ‹¬çš„ã«ç¿’å¾—ã—ã¾ã™ã€‚

## 6.1 Materials Project APIã«ã‚ˆã‚‹ãƒ‡ãƒ¼ã‚¿å–å¾—

Materials Projectã¯ææ–™ç§‘å­¦ã«ãŠã‘ã‚‹æœ€å¤§ç´šã®ã‚ªãƒ¼ãƒ—ãƒ³ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã§ã‚ã‚Šã€148,000ä»¥ä¸Šã®çµæ™¶æ§‹é€ ã¨ç‰©æ€§ãƒ‡ãƒ¼ã‚¿ã‚’æä¾›ã—ã¦ã„ã¾ã™ã€‚`pymatgen`ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã¨`mp-api`ã‚’ç”¨ã„ã¦ã€ã“ã‚Œã‚‰ã®ãƒ‡ãƒ¼ã‚¿ã‚’åŠ¹ç‡çš„ã«å–å¾—ãƒ»å‡¦ç†ã™ã‚‹æ–¹æ³•ã‚’å­¦ã³ã¾ã™ã€‚

### 6.1.1 Materials Project APIèªè¨¼

Materials Project APIã‚’ä½¿ç”¨ã™ã‚‹ã«ã¯ã€ç„¡æ–™ã®APIã‚­ãƒ¼ãŒå¿…è¦ã§ã™ã€‚[Materials Projectã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆ](<https://materialsproject.org/>)ã§ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚’ä½œæˆã—ã€APIã‚­ãƒ¼ã‚’å–å¾—ã—ã¦ãã ã•ã„ã€‚
    
    
    # ã‚³ãƒ¼ãƒ‰ä¾‹1: Materials Project APIèªè¨¼ã¨åŸºæœ¬çš„ãªãƒ‡ãƒ¼ã‚¿å–å¾—
    # Google Colabã§å®Ÿè¡Œå¯èƒ½
    
    # å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
    !pip install mp-api pymatgen -q
    
    from mp_api.client import MPRester
    from pymatgen.core import Structure
    import pandas as pd
    
    # APIã‚­ãƒ¼ã‚’è¨­å®šï¼ˆã”è‡ªèº«ã®APIã‚­ãƒ¼ã«ç½®ãæ›ãˆã¦ãã ã•ã„ï¼‰
    API_KEY = "your_api_key_here"
    
    # MPResterã‚’åˆæœŸåŒ–
    with MPRester(API_KEY) as mpr:
        # ãƒšãƒ­ãƒ–ã‚¹ã‚«ã‚¤ãƒˆæ§‹é€ ï¼ˆABX3ï¼‰ã®ææ–™ã‚’æ¤œç´¢
        # å½¢æˆã‚¨ãƒãƒ«ã‚®ãƒ¼ãŒè² ï¼ˆå®‰å®šï¼‰ã§ã€ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—ãŒ1-3 eVã®ææ–™
        docs = mpr.materials.summary.search(
            formula="*3",  # ABX3å½¢å¼
            num_elements=(3, 3),  # 3å…ƒç´ ç³»
            energy_above_hull=(0, 0.01),  # ã»ã¼å®‰å®šç›¸
            band_gap=(1.0, 3.0),  # åŠå°ä½“é ˜åŸŸ
            fields=["material_id", "formula_pretty", "band_gap",
                    "energy_above_hull", "formation_energy_per_atom"]
        )
    
    # çµæœã‚’DataFrameã«å¤‰æ›
    data = []
    for doc in docs:
        data.append({
            "material_id": doc.material_id,
            "formula": doc.formula_pretty,
            "band_gap": doc.band_gap,
            "e_hull": doc.energy_above_hull,
            "formation_energy": doc.formation_energy_per_atom
        })
    
    df = pd.DataFrame(data)
    print(f"æ¤œç´¢çµæœ: {len(df)}ä»¶ã®ææ–™")
    print(df.head())
    
    # çµ±è¨ˆæƒ…å ±
    print("\n=== çµ±è¨ˆæƒ…å ± ===")
    print(f"ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—ç¯„å›²: {df['band_gap'].min():.3f} - {df['band_gap'].max():.3f} eV")
    print(f"å½¢æˆã‚¨ãƒãƒ«ã‚®ãƒ¼ç¯„å›²: {df['formation_energy'].min():.3f} - {df['formation_energy'].max():.3f} eV/atom")
    

**å®Ÿè¡Œçµæœã®ä¾‹:**  
æ¤œç´¢çµæœ: 247ä»¶ã®ææ–™  
ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—ç¯„å›²: 1.012 - 2.987 eV  
å½¢æˆã‚¨ãƒãƒ«ã‚®ãƒ¼ç¯„å›²: -2.345 - -0.128 eV/atom 

### 6.1.2 çµæ™¶æ§‹é€ ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ã¨CIFå½¢å¼ä¿å­˜

Materials Projectã‹ã‚‰å–å¾—ã—ãŸçµæ™¶æ§‹é€ ã¯ã€pymatgenã®`Structure`ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¨ã—ã¦æ‰±ã‚ã‚Œã¾ã™ã€‚ã“ã‚Œã‚’CIFï¼ˆCrystallographic Information Fileï¼‰å½¢å¼ã§ä¿å­˜ã—ã€å¯è¦–åŒ–ã‚„æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã¸ã®å…¥åŠ›ã¨ã—ã¦æ´»ç”¨ã§ãã¾ã™ã€‚
    
    
    # ã‚³ãƒ¼ãƒ‰ä¾‹2: çµæ™¶æ§‹é€ ã®å–å¾—ã¨CIFå½¢å¼ã§ã®ä¿å­˜
    # Google Colabã§å®Ÿè¡Œå¯èƒ½
    
    from mp_api.client import MPRester
    from pymatgen.io.cif import CifWriter
    import os
    
    API_KEY = "your_api_key_here"
    
    # ä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
    os.makedirs("structures", exist_ok=True)
    
    with MPRester(API_KEY) as mpr:
        # ä¾‹: mp-1234ï¼ˆä»®ã®Material IDï¼‰ã®çµæ™¶æ§‹é€ ã‚’å–å¾—
        # å®Ÿéš›ã®Material IDã«ç½®ãæ›ãˆã¦ãã ã•ã„
        structure = mpr.get_structure_by_material_id("mp-1234")
    
        # æ§‹é€ æƒ…å ±ã®è¡¨ç¤º
        print("=== çµæ™¶æ§‹é€ æƒ…å ± ===")
        print(f"åŒ–å­¦å¼: {structure.composition.reduced_formula}")
        print(f"ç©ºé–“ç¾¤: {structure.get_space_group_info()}")
        print(f"æ ¼å­å®šæ•°: {structure.lattice.abc}")
        print(f"æ ¼å­è§’åº¦: {structure.lattice.angles}")
        print(f"åŸå­æ•°: {len(structure)}")
        print(f"ä½“ç©: {structure.volume:.3f} Ã…Â³")
    
        # åŸå­ã‚µã‚¤ãƒˆæƒ…å ±
        print("\n=== åŸå­ã‚µã‚¤ãƒˆ ===")
        for i, site in enumerate(structure):
            print(f"Site {i+1}: {site.species_string} at {site.frac_coords}")
    
        # CIFå½¢å¼ã§ä¿å­˜
        cif_writer = CifWriter(structure)
        cif_writer.write_file(f"structures/mp-1234.cif")
        print("\nCIFãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸ: structures/mp-1234.cif")
    
    # è¤‡æ•°ã®ææ–™ã‚’ãƒãƒƒãƒå–å¾—
    material_ids = ["mp-1234", "mp-5678", "mp-9012"]  # å®Ÿéš›ã®IDã«ç½®ãæ›ãˆ
    
    with MPRester(API_KEY) as mpr:
        for mat_id in material_ids:
            try:
                structure = mpr.get_structure_by_material_id(mat_id)
                cif_writer = CifWriter(structure)
                cif_writer.write_file(f"structures/{mat_id}.cif")
                print(f"âœ“ {mat_id}: {structure.composition.reduced_formula}")
            except Exception as e:
                print(f"âœ— {mat_id}: ã‚¨ãƒ©ãƒ¼ - {e}")
    

**APIåˆ¶é™ã«ã¤ã„ã¦:** Materials Project APIã«ã¯1æ—¥ã‚ãŸã‚Šã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°åˆ¶é™ãŒã‚ã‚Šã¾ã™ã€‚å¤§è¦æ¨¡ãªãƒ‡ãƒ¼ã‚¿å–å¾—ã‚’è¡Œã†å ´åˆã¯ã€`time.sleep()`ã§ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚’éµå®ˆã—ã€ãƒãƒƒãƒå‡¦ç†ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚ 

## 6.2 PyTorch Geometricã‚«ã‚¹ã‚¿ãƒ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ

Materials Projectã‹ã‚‰å–å¾—ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚’PyTorch Geometricã®`Data`ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«å¤‰æ›ã—ã€è¨“ç·´ç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆã—ã¾ã™ã€‚`InMemoryDataset`ã‚¯ãƒ©ã‚¹ã‚’ç¶™æ‰¿ã—ã¦ã€åŠ¹ç‡çš„ãªãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’å®Ÿç¾ã—ã¾ã™ã€‚

### 6.2.1 Materials Projectã‹ã‚‰PyG Dataã¸ã®å¤‰æ›
    
    
    # ã‚³ãƒ¼ãƒ‰ä¾‹3: Materials Projectæ§‹é€ ã‚’PyTorch Geometric Dataã«å¤‰æ›
    # Google Colabã§å®Ÿè¡Œå¯èƒ½ï¼ˆGPUæ¨å¥¨ï¼‰
    
    import torch
    from torch_geometric.data import Data, InMemoryDataset
    from pymatgen.core import Structure
    from mp_api.client import MPRester
    import numpy as np
    from typing import List, Tuple
    
    class StructureToGraph:
        """
        pymatgen Structureã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ã‚°ãƒ©ãƒ•è¡¨ç¾ã«å¤‰æ›
        """
        def __init__(self, cutoff: float = 5.0):
            """
            Args:
                cutoff: åŸå­é–“è·é›¢ã®ã‚«ãƒƒãƒˆã‚ªãƒ•åŠå¾„ï¼ˆÃ…ï¼‰
            """
            self.cutoff = cutoff
    
        def convert(self, structure: Structure) -> Data:
            """
            Structure â†’ PyG Dataå¤‰æ›
    
            Args:
                structure: pymatgen Structureã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
    
            Returns:
                PyG Dataã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
            """
            # ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡: åŸå­ç•ªå·ã®ãƒ¯ãƒ³ãƒ›ãƒƒãƒˆè¡¨ç¾ï¼ˆæœ€å¤§åŸå­ç•ªå·92: Uï¼‰
            atom_numbers = [site.specie.Z for site in structure]
            x = torch.zeros((len(atom_numbers), 92))
            for i, z in enumerate(atom_numbers):
                x[i, z-1] = 1.0  # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¯0å§‹ã¾ã‚Š
    
            # ã‚¨ãƒƒã‚¸æ§‹ç¯‰: ã‚«ãƒƒãƒˆã‚ªãƒ•åŠå¾„å†…ã®åŸå­ãƒšã‚¢
            edge_index = []
            edge_attr = []
    
            for i, site_i in enumerate(structure):
                # å‘¨æœŸå¢ƒç•Œæ¡ä»¶ã‚’è€ƒæ…®ã—ãŸè¿‘å‚æ¢ç´¢
                neighbors = structure.get_neighbors(site_i, self.cutoff)
    
                for neighbor in neighbors:
                    j = neighbor.index
                    distance = neighbor.nn_distance
    
                    # ã‚¨ãƒƒã‚¸è¿½åŠ ï¼ˆç„¡å‘ã‚°ãƒ©ãƒ•ãªã®ã§åŒæ–¹å‘ï¼‰
                    edge_index.append([i, j])
    
                    # ã‚¨ãƒƒã‚¸ç‰¹å¾´é‡: è·é›¢ã®ã‚¬ã‚¦ã‚¹å±•é–‹
                    edge_feature = self._gaussian_expansion(distance)
                    edge_attr.append(edge_feature)
    
            edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()
            edge_attr = torch.tensor(edge_attr, dtype=torch.float)
    
            # ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ä½œæˆ
            data = Data(
                x=x,
                edge_index=edge_index,
                edge_attr=edge_attr
            )
    
            return data
    
        def _gaussian_expansion(self, distance: float, num_centers: int = 41) -> np.ndarray:
            """
            è·é›¢ã‚’ã‚¬ã‚¦ã‚¹åŸºåº•é–¢æ•°ã§å±•é–‹
    
            Args:
                distance: åŸå­é–“è·é›¢ï¼ˆÃ…ï¼‰
                num_centers: ã‚¬ã‚¦ã‚¹åŸºåº•ã®æ•°
    
            Returns:
                å±•é–‹ä¿‚æ•°ãƒ™ã‚¯ãƒˆãƒ«
            """
            centers = np.linspace(0, self.cutoff, num_centers)
            width = 0.5  # ã‚¬ã‚¦ã‚¹å¹…
    
            gamma = -0.5 / (width ** 2)
            return np.exp(gamma * (distance - centers) ** 2)
    
    # ä½¿ç”¨ä¾‹
    API_KEY = "your_api_key_here"
    converter = StructureToGraph(cutoff=5.0)
    
    with MPRester(API_KEY) as mpr:
        structure = mpr.get_structure_by_material_id("mp-1234")
        data = converter.convert(structure)
    
        print("=== ã‚°ãƒ©ãƒ•è¡¨ç¾ ===")
        print(f"ãƒãƒ¼ãƒ‰æ•°: {data.x.size(0)}")
        print(f"ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡æ¬¡å…ƒ: {data.x.size(1)}")
        print(f"ã‚¨ãƒƒã‚¸æ•°: {data.edge_index.size(1)}")
        print(f"ã‚¨ãƒƒã‚¸ç‰¹å¾´é‡æ¬¡å…ƒ: {data.edge_attr.size(1)}")
    

### 6.2.2 ã‚«ã‚¹ã‚¿ãƒ InMemoryDatasetå®Ÿè£…

`InMemoryDataset`ã‚’ç¶™æ‰¿ã—ã¦ã€Materials Projectãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†ã¨ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ã‚’è‡ªå‹•åŒ–ã—ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€å†å®Ÿè¡Œæ™‚ã®ãƒ‡ãƒ¼ã‚¿å–å¾—æ™‚é–“ã‚’å¤§å¹…ã«å‰Šæ¸›ã§ãã¾ã™ã€‚
    
    
    # ã‚³ãƒ¼ãƒ‰ä¾‹4: Materials Projectç”¨ã‚«ã‚¹ã‚¿ãƒ InMemoryDataset
    # Google Colabã§å®Ÿè¡Œå¯èƒ½ï¼ˆGPUæ¨å¥¨ï¼‰
    
    import os
    import torch
    from torch_geometric.data import InMemoryDataset, Data
    from mp_api.client import MPRester
    import pickle
    
    class MaterialsProjectDataset(InMemoryDataset):
        """
        Materials Projectã‹ã‚‰ææ–™ç‰©æ€§äºˆæ¸¬ç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆ
        """
        def __init__(self, root, api_key, material_ids=None,
                     property_name="band_gap", cutoff=5.0,
                     transform=None, pre_transform=None, pre_filter=None):
            """
            Args:
                root: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
                api_key: Materials Project APIã‚­ãƒ¼
                material_ids: å–å¾—ã™ã‚‹Material IDã®ãƒªã‚¹ãƒˆï¼ˆNoneã®å ´åˆã¯æ¤œç´¢ï¼‰
                property_name: äºˆæ¸¬å¯¾è±¡ç‰©æ€§ï¼ˆ'band_gap', 'formation_energy_per_atom'ç­‰ï¼‰
                cutoff: ã‚°ãƒ©ãƒ•æ§‹ç¯‰ã‚«ãƒƒãƒˆã‚ªãƒ•åŠå¾„ï¼ˆÃ…ï¼‰
            """
            self.api_key = api_key
            self.material_ids = material_ids
            self.property_name = property_name
            self.converter = StructureToGraph(cutoff=cutoff)
    
            super().__init__(root, transform, pre_transform, pre_filter)
            self.data, self.slices = torch.load(self.processed_paths[0])
    
        @property
        def raw_file_names(self):
            return ['materials.pkl']
    
        @property
        def processed_file_names(self):
            return ['data.pt']
    
        def download(self):
            """
            Materials Project APIã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            """
            with MPRester(self.api_key) as mpr:
                if self.material_ids is None:
                    # Material IDãŒæŒ‡å®šã•ã‚Œã¦ã„ãªã„å ´åˆã¯æ¤œç´¢
                    docs = mpr.materials.summary.search(
                        energy_above_hull=(0, 0.05),  # æº–å®‰å®šç›¸ã¾ã§å«ã‚€
                        num_elements=(1, 5),  # 1-5å…ƒç´ ç³»
                        fields=["material_id", self.property_name]
                    )
                    self.material_ids = [doc.material_id for doc in docs
                                         if getattr(doc, self.property_name) is not None]
                    print(f"æ¤œç´¢çµæœ: {len(self.material_ids)}ä»¶ã®ææ–™")
    
                # æ§‹é€ ã¨ç‰©æ€§ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
                materials_data = []
                for i, mat_id in enumerate(self.material_ids):
                    try:
                        structure = mpr.get_structure_by_material_id(mat_id)
                        doc = mpr.materials.summary.search(
                            material_ids=[mat_id],
                            fields=[self.property_name]
                        )[0]
    
                        property_value = getattr(doc, self.property_name)
    
                        materials_data.append({
                            'material_id': mat_id,
                            'structure': structure,
                            'property': property_value
                        })
    
                        if (i + 1) % 100 == 0:
                            print(f"ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰é€²æ—: {i+1}/{len(self.material_ids)}")
    
                    except Exception as e:
                        print(f"ã‚¨ãƒ©ãƒ¼ ({mat_id}): {e}")
    
                # ä¿å­˜
                os.makedirs(self.raw_dir, exist_ok=True)
                with open(self.raw_paths[0], 'wb') as f:
                    pickle.dump(materials_data, f)
    
                print(f"âœ“ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†: {len(materials_data)}ä»¶")
    
        def process(self):
            """
            Raw dataã‚’PyG Dataå½¢å¼ã«å¤‰æ›
            """
            # Raw dataã®èª­ã¿è¾¼ã¿
            with open(self.raw_paths[0], 'rb') as f:
                materials_data = pickle.load(f)
    
            # PyG Dataå½¢å¼ã«å¤‰æ›
            data_list = []
            for item in materials_data:
                # ã‚°ãƒ©ãƒ•å¤‰æ›
                data = self.converter.convert(item['structure'])
    
                # ãƒ©ãƒ™ãƒ«ï¼ˆç‰©æ€§å€¤ï¼‰ã‚’è¿½åŠ 
                data.y = torch.tensor([item['property']], dtype=torch.float)
                data.material_id = item['material_id']
    
                data_list.append(data)
    
            # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            if self.pre_filter is not None:
                data_list = [d for d in data_list if self.pre_filter(d)]
    
            # å‰å‡¦ç†ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            if self.pre_transform is not None:
                data_list = [self.pre_transform(d) for d in data_list]
    
            # ä¿å­˜
            data, slices = self.collate(data_list)
            torch.save((data, slices), self.processed_paths[0])
            print(f"âœ“ å‡¦ç†å®Œäº†: {len(data_list)}ä»¶")
    
    # ä½¿ç”¨ä¾‹
    API_KEY = "your_api_key_here"
    
    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆï¼ˆåˆå›ã¯è‡ªå‹•ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ & å‡¦ç†ï¼‰
    dataset = MaterialsProjectDataset(
        root='./data/mp_band_gap',
        api_key=API_KEY,
        property_name='band_gap',
        cutoff=5.0
    )
    
    print(f"ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚µã‚¤ã‚º: {len(dataset)}")
    print(f"ã‚µãƒ³ãƒ—ãƒ«: {dataset[0]}")
    

**ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°æ©Ÿèƒ½:** `InMemoryDataset`ã¯å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’è‡ªå‹•ä¿å­˜ã—ã¾ã™ã€‚2å›ç›®ä»¥é™ã®å®Ÿè¡Œã§ã¯ã€ä¿å­˜ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€ã ã‘ã§é«˜é€Ÿã«èµ·å‹•ã—ã¾ã™ã€‚ 

## 6.3 åˆ†æ•£å­¦ç¿’ã¨GPUæœ€é©åŒ–

å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚„è¤‡é›‘ãªGNNãƒ¢ãƒ‡ãƒ«ã‚’åŠ¹ç‡çš„ã«è¨“ç·´ã™ã‚‹ãŸã‚ã€PyTorchã®åˆ†æ•£å­¦ç¿’æ©Ÿèƒ½ã¨GPUæœ€é©åŒ–ãƒ†ã‚¯ãƒ‹ãƒƒã‚¯ã‚’æ´»ç”¨ã—ã¾ã™ã€‚

### 6.3.1 DataParallelã«ã‚ˆã‚‹ãƒãƒ«ãƒGPUå­¦ç¿’
    
    
    # ã‚³ãƒ¼ãƒ‰ä¾‹5: DataParallelã«ã‚ˆã‚‹ãƒãƒ«ãƒGPUä¸¦åˆ—å­¦ç¿’
    # Google Colab Pro/Pro+ï¼ˆè¤‡æ•°GPUç’°å¢ƒï¼‰ã§å®Ÿè¡Œå¯èƒ½
    
    import torch
    import torch.nn as nn
    from torch_geometric.nn import CGConv, global_mean_pool
    from torch_geometric.loader import DataLoader
    import time
    
    class CGCNNModel(nn.Module):
        """
        CGCNNï¼ˆCrystal Graph Convolutional Neural Networkï¼‰
        """
        def __init__(self, atom_fea_len=92, nbr_fea_len=41,
                     hidden_dim=128, n_conv=3):
            super(CGCNNModel, self).__init__()
    
            # åŸå­åŸ‹ã‚è¾¼ã¿
            self.atom_embedding = nn.Linear(atom_fea_len, hidden_dim)
    
            # CGConvå±¤
            self.conv_layers = nn.ModuleList([
                CGConv(hidden_dim, nbr_fea_len) for _ in range(n_conv)
            ])
    
            self.bn_layers = nn.ModuleList([
                nn.BatchNorm1d(hidden_dim) for _ in range(n_conv)
            ])
    
            # äºˆæ¸¬ãƒ˜ãƒƒãƒ‰
            self.fc1 = nn.Linear(hidden_dim, 64)
            self.fc2 = nn.Linear(64, 1)
    
            self.activation = nn.Softplus()
    
        def forward(self, data):
            x, edge_index, edge_attr, batch = data.x, data.edge_index, data.edge_attr, data.batch
    
            # åŸå­åŸ‹ã‚è¾¼ã¿
            x = self.atom_embedding(x)
    
            # CGConvå±¤ï¼ˆæ®‹å·®æ¥ç¶šä»˜ãï¼‰
            for conv, bn in zip(self.conv_layers, self.bn_layers):
                x_new = conv(x, edge_index, edge_attr)
                x_new = bn(x_new)
                x_new = self.activation(x_new)
                x = x + x_new  # æ®‹å·®æ¥ç¶š
    
            # ã‚°ãƒ©ãƒ•ãƒ¬ãƒ™ãƒ«ãƒ—ãƒ¼ãƒªãƒ³ã‚°
            x = global_mean_pool(x, batch)
    
            # äºˆæ¸¬
            x = self.activation(self.fc1(x))
            x = self.fc2(x)
    
            return x.squeeze()
    
    # ãƒãƒ«ãƒGPUå­¦ç¿’
    def train_multigpu(dataset, epochs=100, batch_size=64, lr=0.001):
        """
        DataParallelã«ã‚ˆã‚‹ãƒãƒ«ãƒGPUä¸¦åˆ—å­¦ç¿’
        """
        # ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼
        train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4)
    
        # ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰
        model = CGCNNModel()
    
        # GPUãƒ‡ãƒã‚¤ã‚¹ç¢ºèª
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        gpu_count = torch.cuda.device_count()
        print(f"ä½¿ç”¨å¯èƒ½GPUæ•°: {gpu_count}")
    
        if gpu_count > 1:
            # ãƒãƒ«ãƒGPUä¸¦åˆ—åŒ–
            model = nn.DataParallel(model)
            print(f"DataParallelãƒ¢ãƒ¼ãƒ‰: {gpu_count}å€‹ã®GPUã‚’ä½¿ç”¨")
    
        model = model.to(device)
    
        # æœ€é©åŒ–è¨­å®š
        criterion = nn.MSELoss()
        optimizer = torch.optim.Adam(model.parameters(), lr=lr)
        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
            optimizer, mode='min', factor=0.5, patience=10, verbose=True
        )
    
        # å­¦ç¿’ãƒ«ãƒ¼ãƒ—
        for epoch in range(epochs):
            model.train()
            total_loss = 0
            start_time = time.time()
    
            for batch in train_loader:
                batch = batch.to(device)
    
                optimizer.zero_grad()
                output = model(batch)
                loss = criterion(output, batch.y)
                loss.backward()
                optimizer.step()
    
                total_loss += loss.item() * batch.num_graphs
    
            avg_loss = total_loss / len(dataset)
            epoch_time = time.time() - start_time
    
            # å­¦ç¿’ç‡èª¿æ•´
            scheduler.step(avg_loss)
    
            if (epoch + 1) % 10 == 0:
                print(f"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}, Time: {epoch_time:.2f}s")
    
        return model
    
    # å®Ÿè¡Œä¾‹
    # dataset = MaterialsProjectDataset(...) ã§ä½œæˆã—ãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
    # model = train_multigpu(dataset, epochs=200, batch_size=64)
    

**DataParallelã®å‹•ä½œ:** ãƒãƒƒãƒã‚’GPUé–“ã§åˆ†å‰²ã—ã€å„GPUã§ä¸¦åˆ—ã«é †ä¼æ’­ãƒ»é€†ä¼æ’­ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚å‹¾é…ã¯GPU 0ã«é›†ç´„ã•ã‚Œã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ›´æ–°ãŒè¡Œã‚ã‚Œã¾ã™ã€‚ 

### 6.3.2 Mixed Precision Trainingï¼ˆæ··åˆç²¾åº¦å­¦ç¿’ï¼‰

PyTorchã®`torch.cuda.amp`ã‚’ç”¨ã„ã¦ã€FP16ï¼ˆåŠç²¾åº¦æµ®å‹•å°æ•°ç‚¹ï¼‰ã¨FP32ï¼ˆå˜ç²¾åº¦ï¼‰ã‚’æ··åˆã—ã¦å­¦ç¿’ã—ã¾ã™ã€‚ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’å‰Šæ¸›ã—ã€å­¦ç¿’é€Ÿåº¦ã‚’æœ€å¤§2å€é«˜é€ŸåŒ–ã§ãã¾ã™ã€‚
    
    
    # ã‚³ãƒ¼ãƒ‰ä¾‹6: Mixed Precision Trainingï¼ˆæ··åˆç²¾åº¦å­¦ç¿’ï¼‰
    # Google Colabï¼ˆGPUç’°å¢ƒï¼‰ã§å®Ÿè¡Œå¯èƒ½
    
    import torch
    from torch.cuda.amp import autocast, GradScaler
    from torch_geometric.loader import DataLoader
    import time
    
    def train_mixed_precision(model, dataset, epochs=100, batch_size=64, lr=0.001):
        """
        Mixed Precision Trainingã«ã‚ˆã‚‹é«˜é€Ÿå­¦ç¿’
        """
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        model = model.to(device)
    
        # ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼
        train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4)
    
        # æœ€é©åŒ–è¨­å®š
        criterion = torch.nn.MSELoss()
        optimizer = torch.optim.Adam(model.parameters(), lr=lr)
    
        # Gradient Scalerï¼ˆå‹¾é…ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ï¼‰
        scaler = GradScaler()
    
        print("=== Mixed Precision Trainingé–‹å§‹ ===")
    
        for epoch in range(epochs):
            model.train()
            total_loss = 0
            start_time = time.time()
    
            for batch in train_loader:
                batch = batch.to(device)
    
                optimizer.zero_grad()
    
                # Mixed Precision: FP16ã§é †ä¼æ’­
                with autocast():
                    output = model(batch)
                    loss = criterion(output, batch.y)
    
                # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ä»˜ãé€†ä¼æ’­
                scaler.scale(loss).backward()
    
                # å‹¾é…ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
                scaler.unscale_(optimizer)
                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
    
                # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ›´æ–°
                scaler.step(optimizer)
                scaler.update()
    
                total_loss += loss.item() * batch.num_graphs
    
            avg_loss = total_loss / len(dataset)
            epoch_time = time.time() - start_time
    
            if (epoch + 1) % 10 == 0:
                # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡è¡¨ç¤º
                if torch.cuda.is_available():
                    memory_allocated = torch.cuda.memory_allocated() / 1024**3  # GB
                    memory_reserved = torch.cuda.memory_reserved() / 1024**3
                    print(f"Epoch {epoch+1}: Loss={avg_loss:.4f}, Time={epoch_time:.2f}s, "
                          f"Memory={memory_allocated:.2f}GB/{memory_reserved:.2f}GB")
                else:
                    print(f"Epoch {epoch+1}: Loss={avg_loss:.4f}, Time={epoch_time:.2f}s")
    
        return model
    
    # ä½¿ç”¨ä¾‹
    model = CGCNNModel()
    # model = train_mixed_precision(model, dataset, epochs=200)
    

**Mixed Precisionã®åŠ¹æœ:** V100 GPUã§ç´„1.5-2å€ã®å­¦ç¿’é€Ÿåº¦å‘ä¸Šã€ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’ç´„40%å‰Šæ¸›å¯èƒ½ã§ã™ã€‚ç²¾åº¦ã¸ã®å½±éŸ¿ã¯ã»ã¨ã‚“ã©ã‚ã‚Šã¾ã›ã‚“ï¼ˆMAEå·®0.001ä»¥ä¸‹ï¼‰ã€‚ 

## 6.4 ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜ã¨ãƒ­ãƒ¼ãƒ‰

è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã—ã€å¾Œã§æ¨è«–ã«ä½¿ç”¨ã™ã‚‹ãŸã‚ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã‚’å­¦ã³ã¾ã™ã€‚

### 6.4.1 ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜
    
    
    # ã‚³ãƒ¼ãƒ‰ä¾‹7: ãƒ¢ãƒ‡ãƒ«ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã®ä¿å­˜ã¨ãƒ­ãƒ¼ãƒ‰
    # Google Colabã§å®Ÿè¡Œå¯èƒ½
    
    import torch
    import os
    from datetime import datetime
    
    class ModelCheckpoint:
        """
        ãƒ¢ãƒ‡ãƒ«ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆç®¡ç†
        """
        def __init__(self, save_dir='checkpoints', monitor='val_loss', mode='min'):
            """
            Args:
                save_dir: ä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
                monitor: ç›£è¦–ã™ã‚‹æŒ‡æ¨™ï¼ˆ'val_loss', 'val_mae'ç­‰ï¼‰
                mode: 'min'ï¼ˆæœ€å°åŒ–ï¼‰ã¾ãŸã¯'max'ï¼ˆæœ€å¤§åŒ–ï¼‰
            """
            self.save_dir = save_dir
            self.monitor = monitor
            self.mode = mode
            self.best_score = float('inf') if mode == 'min' else float('-inf')
    
            os.makedirs(save_dir, exist_ok=True)
    
        def save(self, model, optimizer, epoch, metrics, filename=None):
            """
            ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’ä¿å­˜
    
            Args:
                model: PyTorchãƒ¢ãƒ‡ãƒ«
                optimizer: ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãƒ¼
                epoch: ç¾åœ¨ã®ã‚¨ãƒãƒƒã‚¯
                metrics: ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¾æ›¸ï¼ˆä¾‹: {'val_loss': 0.025, 'val_mae': 0.18}ï¼‰
                filename: ä¿å­˜ãƒ•ã‚¡ã‚¤ãƒ«åï¼ˆNoneã®å ´åˆã¯è‡ªå‹•ç”Ÿæˆï¼‰
            """
            if filename is None:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = f"checkpoint_epoch{epoch}_{timestamp}.pt"
    
            filepath = os.path.join(self.save_dir, filename)
    
            # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿
            checkpoint = {
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'metrics': metrics
            }
    
            torch.save(checkpoint, filepath)
            print(f"âœ“ Checkpoint saved: {filepath}")
    
            # ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã®å ´åˆã¯åˆ¥åã§ã‚‚ä¿å­˜
            current_score = metrics.get(self.monitor)
            if current_score is not None:
                is_best = (self.mode == 'min' and current_score < self.best_score) or \
                          (self.mode == 'max' and current_score > self.best_score)
    
                if is_best:
                    self.best_score = current_score
                    best_path = os.path.join(self.save_dir, 'best_model.pt')
                    torch.save(checkpoint, best_path)
                    print(f"âœ“ Best model updated: {self.monitor}={current_score:.4f}")
    
        @staticmethod
        def load(filepath, model, optimizer=None):
            """
            ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’ãƒ­ãƒ¼ãƒ‰
    
            Args:
                filepath: ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
                model: ãƒ­ãƒ¼ãƒ‰å…ˆãƒ¢ãƒ‡ãƒ«
                optimizer: ãƒ­ãƒ¼ãƒ‰å…ˆã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãƒ¼ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    
            Returns:
                epoch, metrics
            """
            checkpoint = torch.load(filepath)
    
            model.load_state_dict(checkpoint['model_state_dict'])
    
            if optimizer is not None and 'optimizer_state_dict' in checkpoint:
                optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
    
            epoch = checkpoint.get('epoch', 0)
            metrics = checkpoint.get('metrics', {})
    
            print(f"âœ“ Checkpoint loaded: {filepath}")
            print(f"  Epoch: {epoch}, Metrics: {metrics}")
    
            return epoch, metrics
    
    # ä½¿ç”¨ä¾‹: å­¦ç¿’ãƒ«ãƒ¼ãƒ—å†…ã§ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜
    checkpoint_manager = ModelCheckpoint(save_dir='./checkpoints', monitor='val_mae', mode='min')
    
    for epoch in range(100):
        # å­¦ç¿’å‡¦ç†
        train_loss = 0.0  # å®Ÿéš›ã®å­¦ç¿’ã§è¨ˆç®—
    
        # æ¤œè¨¼å‡¦ç†
        val_loss = 0.0  # å®Ÿéš›ã®æ¤œè¨¼ã§è¨ˆç®—
        val_mae = 0.0
    
        # 10ã‚¨ãƒãƒƒã‚¯ã”ã¨ã«ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜
        if (epoch + 1) % 10 == 0:
            metrics = {
                'train_loss': train_loss,
                'val_loss': val_loss,
                'val_mae': val_mae
            }
            checkpoint_manager.save(model, optimizer, epoch + 1, metrics)
    
    # ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰
    model_new = CGCNNModel()
    checkpoint_manager.load('./checkpoints/best_model.pt', model_new)
    

### 6.4.2 ONNXå½¢å¼ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆï¼ˆæ¨è«–æœ€é©åŒ–ï¼‰

ONNXï¼ˆOpen Neural Network Exchangeï¼‰å½¢å¼ã«ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã™ã‚‹ã“ã¨ã§ã€æ¨è«–é€Ÿåº¦ã‚’æœ€å¤§åŒ–ã—ã€ç•°ãªã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ï¼ˆTensorFlowã€C++ç­‰ï¼‰ã§ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã§ãã¾ã™ã€‚
    
    
    # ã‚³ãƒ¼ãƒ‰ä¾‹8: ONNXã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã¨æ¨è«–
    # Google Colabã§å®Ÿè¡Œå¯èƒ½
    
    import torch
    import torch.onnx
    from torch_geometric.data import Batch
    
    def export_to_onnx(model, sample_data, onnx_path='model.onnx'):
        """
        PyTorch Geometricãƒ¢ãƒ‡ãƒ«ã‚’ONNXå½¢å¼ã«ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
    
        Args:
            model: PyTorchãƒ¢ãƒ‡ãƒ«
            sample_data: ã‚µãƒ³ãƒ—ãƒ«å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ï¼ˆDataå‹ï¼‰
            onnx_path: ä¿å­˜ãƒ‘ã‚¹
        """
        model.eval()
    
        # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ãƒãƒƒãƒå½¢å¼ã«å¤‰æ›
        batch = Batch.from_data_list([sample_data])
    
        # ãƒ€ãƒŸãƒ¼å…¥åŠ›ä½œæˆï¼ˆONNXã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã«å¿…è¦ï¼‰
        dummy_input = (
            batch.x,
            batch.edge_index,
            batch.edge_attr,
            batch.batch
        )
    
        # ONNXã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
        torch.onnx.export(
            model,
            dummy_input,
            onnx_path,
            export_params=True,
            opset_version=14,
            do_constant_folding=True,
            input_names=['x', 'edge_index', 'edge_attr', 'batch'],
            output_names=['output'],
            dynamic_axes={
                'x': {0: 'num_nodes'},
                'edge_index': {1: 'num_edges'},
                'edge_attr': {0: 'num_edges'},
                'batch': {0: 'num_nodes'}
            }
        )
    
        print(f"âœ“ ONNX export completed: {onnx_path}")
    
        # ONNXãƒ¢ãƒ‡ãƒ«ã®æ¤œè¨¼
        import onnx
        onnx_model = onnx.load(onnx_path)
        onnx.checker.check_model(onnx_model)
        print("âœ“ ONNX model validation passed")
    
    # ONNX Runtimeæ¨è«–ï¼ˆé«˜é€Ÿæ¨è«–ï¼‰
    def inference_onnx(onnx_path, data):
        """
        ONNX Runtimeã‚’ç”¨ã„ãŸé«˜é€Ÿæ¨è«–
    
        Args:
            onnx_path: ONNXãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹
            data: å…¥åŠ›Data
    
        Returns:
            äºˆæ¸¬å€¤
        """
        import onnxruntime as ort
        import numpy as np
    
        # ONNX Runtimeã‚»ãƒƒã‚·ãƒ§ãƒ³ä½œæˆ
        ort_session = ort.InferenceSession(onnx_path)
    
        # ãƒãƒƒãƒåŒ–
        batch = Batch.from_data_list([data])
    
        # NumPyé…åˆ—ã«å¤‰æ›
        ort_inputs = {
            'x': batch.x.numpy(),
            'edge_index': batch.edge_index.numpy(),
            'edge_attr': batch.edge_attr.numpy(),
            'batch': batch.batch.numpy()
        }
    
        # æ¨è«–
        ort_outputs = ort_session.run(None, ort_inputs)
        prediction = ort_outputs[0]
    
        return prediction[0]
    
    # ä½¿ç”¨ä¾‹
    # model = CGCNNModel()  # è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«
    # sample_data = dataset[0]  # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿
    
    # export_to_onnx(model, sample_data, 'cgcnn_model.onnx')
    # prediction = inference_onnx('cgcnn_model.onnx', sample_data)
    # print(f"ONNXäºˆæ¸¬: {prediction:.4f}")
    

**ONNX Runtimeã®åˆ©ç‚¹:** PyTorchãƒã‚¤ãƒ†ã‚£ãƒ–æ¨è«–ã¨æ¯”è¼ƒã—ã¦ã€1.5-3å€ã®æ¨è«–é€Ÿåº¦å‘ä¸ŠãŒæœŸå¾…ã§ãã¾ã™ã€‚ç‰¹ã«CPUç’°å¢ƒã§ã®åŠ¹æœãŒé¡•è‘—ã§ã™ã€‚ 

## 6.5 æœ¬ç•ªç’°å¢ƒãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆ

è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’REST APIã¨ã—ã¦å…¬é–‹ã—ã€Webã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚„ä»–ã®ã‚·ã‚¹ãƒ†ãƒ ã‹ã‚‰åˆ©ç”¨å¯èƒ½ã«ã—ã¾ã™ã€‚FastAPIã‚’ç”¨ã„ãŸå®Ÿè£…ä¾‹ã‚’ç¤ºã—ã¾ã™ã€‚
    
    
    ```mermaid
    graph LR
        A[Webã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ] -->|POST /predict| B[FastAPI Server]
        B --> C[ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰]
        C --> D[PyG Dataå¤‰æ›]
        D --> E[æ¨è«–å®Ÿè¡Œ]
        E --> F[çµæœJSON]
        F -->|Response| A
    
        style B fill:#667eea,color:#fff
        style E fill:#764ba2,color:#fff
    ```
    
    
    # ã‚³ãƒ¼ãƒ‰ä¾‹9: FastAPI REST APIãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆ
    # ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã¾ãŸã¯ã‚µãƒ¼ãƒãƒ¼ã§å®Ÿè¡Œ
    
    # requirements.txt:
    # fastapi
    # uvicorn
    # torch
    # torch-geometric
    # pymatgen
    
    from fastapi import FastAPI, HTTPException
    from pydantic import BaseModel
    import torch
    from pymatgen.core import Structure
    import json
    
    app = FastAPI(title="Materials Property Prediction API")
    
    # ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã¨ã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰
    MODEL = None
    DEVICE = None
    
    class CrystalInput(BaseModel):
        """
        å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã‚¹ã‚­ãƒ¼ãƒ
        """
        structure: dict  # pymatgen Structureè¾æ›¸è¡¨ç¾
        # ã¾ãŸã¯
        cif_string: str = None  # CIFæ–‡å­—åˆ—
    
    class PredictionResponse(BaseModel):
        """
        äºˆæ¸¬çµæœã‚¹ã‚­ãƒ¼ãƒ
        """
        prediction: float
        uncertainty: float = None
        material_id: str = None
    
    @app.on_event("startup")
    async def load_model():
        """
        ã‚µãƒ¼ãƒãƒ¼èµ·å‹•æ™‚ã«ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰
        """
        global MODEL, DEVICE
    
        DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
        # ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰
        MODEL = CGCNNModel()
        checkpoint = torch.load('checkpoints/best_model.pt', map_location=DEVICE)
        MODEL.load_state_dict(checkpoint['model_state_dict'])
        MODEL.to(DEVICE)
        MODEL.eval()
    
        print(f"âœ“ Model loaded on {DEVICE}")
    
    @app.post("/predict", response_model=PredictionResponse)
    async def predict_property(input_data: CrystalInput):
        """
        ææ–™ç‰©æ€§äºˆæ¸¬ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
    
        Args:
            input_data: çµæ™¶æ§‹é€ ãƒ‡ãƒ¼ã‚¿
    
        Returns:
            äºˆæ¸¬çµæœ
        """
        try:
            # æ§‹é€ ãƒ‡ãƒ¼ã‚¿ã®ãƒ‘ãƒ¼ã‚¹
            if input_data.cif_string:
                structure = Structure.from_str(input_data.cif_string, fmt='cif')
            else:
                structure = Structure.from_dict(input_data.structure)
    
            # ã‚°ãƒ©ãƒ•å¤‰æ›
            converter = StructureToGraph(cutoff=5.0)
            data = converter.convert(structure)
            data = data.to(DEVICE)
    
            # æ¨è«–
            with torch.no_grad():
                prediction = MODEL(data).item()
    
            return PredictionResponse(
                prediction=prediction,
                material_id=input_data.structure.get('material_id', 'unknown')
            )
    
        except Exception as e:
            raise HTTPException(status_code=400, detail=str(e))
    
    @app.get("/health")
    async def health_check():
        """
        ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
        """
        return {
            "status": "healthy",
            "model_loaded": MODEL is not None,
            "device": str(DEVICE)
        }
    
    @app.get("/")
    async def root():
        """
        APIãƒ«ãƒ¼ãƒˆ
        """
        return {
            "message": "Materials Property Prediction API",
            "endpoints": {
                "POST /predict": "Predict material property from structure",
                "GET /health": "Health check",
                "GET /docs": "API documentation (Swagger UI)"
            }
        }
    
    # ã‚µãƒ¼ãƒãƒ¼èµ·å‹•ã‚³ãƒãƒ³ãƒ‰:
    # uvicorn api:app --host 0.0.0.0 --port 8000 --reload
    
    # ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆä½¿ç”¨ä¾‹ï¼ˆPythonï¼‰:
    """
    import requests
    import json
    
    # CIFæ–‡å­—åˆ—ï¼ˆä¾‹ï¼‰
    cif_string = '''
    data_mp-1234
    _cell_length_a    3.905
    _cell_length_b    3.905
    _cell_length_c    3.905
    _cell_angle_alpha 90.0
    _cell_angle_beta  90.0
    _cell_angle_gamma 90.0
    _symmetry_space_group_name_H-M 'P 1'
    loop_
    _atom_site_label
    _atom_site_type_symbol
    _atom_site_fract_x
    _atom_site_fract_y
    _atom_site_fract_z
    Ti1 Ti 0.0 0.0 0.0
    O1  O  0.5 0.5 0.0
    O2  O  0.5 0.0 0.5
    O3  O  0.0 0.5 0.5
    '''
    
    # APIå‘¼ã³å‡ºã—
    response = requests.post(
        'http://localhost:8000/predict',
        json={'cif_string': cif_string}
    )
    
    result = response.json()
    print(f"äºˆæ¸¬ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—: {result['prediction']:.3f} eV")
    """
    

**FastAPIã®åˆ©ç‚¹:** è‡ªå‹•APIæ–‡æ›¸ç”Ÿæˆï¼ˆSwagger UIï¼‰ã€é«˜é€ŸãªéåŒæœŸå‡¦ç†ã€å‹ãƒã‚§ãƒƒã‚¯ã€ç°¡æ½”ãªã‚³ãƒ¼ãƒ‰è¨˜è¿°ãŒå¯èƒ½ã§ã™ã€‚`http://localhost:8000/docs`ã§ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªAPIæ–‡æ›¸ã‚’ç¢ºèªã§ãã¾ã™ã€‚ 

## 6.6 æœ¬ç« ã®ã¾ã¨ã‚

æœ¬ç« ã§ã¯ã€PyTorch Geometricã¨Materials Project APIã‚’ç”¨ã„ãŸå®Ÿè·µçš„ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’å­¦ã³ã¾ã—ãŸã€‚ã‚«ã‚¹ã‚¿ãƒ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ä½œæˆã‹ã‚‰æœ¬ç•ªãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆã¾ã§ã€å®Ÿéš›ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§å¿…è¦ã¨ãªã‚‹æŠ€è¡“ã‚’åŒ…æ‹¬çš„ã«ç¿’å¾—ã—ã¾ã—ãŸã€‚

### é‡è¦ãªãƒã‚¤ãƒ³ãƒˆ

  * **Materials Project API** : 148,000ä»¥ä¸Šã®çµæ™¶æ§‹é€ ã¨ç‰©æ€§ãƒ‡ãƒ¼ã‚¿ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ã€pymatgenã«ã‚ˆã‚‹æ§‹é€ è§£æ
  * **ã‚«ã‚¹ã‚¿ãƒ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ** : `InMemoryDataset`ç¶™æ‰¿ã«ã‚ˆã‚‹åŠ¹ç‡çš„ãªãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã€ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°æ©Ÿèƒ½
  * **åˆ†æ•£å­¦ç¿’** : `DataParallel`ã«ã‚ˆã‚‹ãƒãƒ«ãƒGPUå­¦ç¿’ã€Mixed Precision Trainingï¼ˆ1.5-2å€é«˜é€ŸåŒ–ã€40%ãƒ¡ãƒ¢ãƒªå‰Šæ¸›ï¼‰
  * **ãƒ¢ãƒ‡ãƒ«ä¿å­˜** : ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆç®¡ç†ã€ONNXå½¢å¼ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆï¼ˆ1.5-3å€æ¨è«–é«˜é€ŸåŒ–ï¼‰
  * **æœ¬ç•ªãƒ‡ãƒ—ãƒ­ã‚¤** : FastAPIã«ã‚ˆã‚‹REST APIã‚µãƒ¼ãƒãƒ¼ã€Swagger UIè‡ªå‹•ç”Ÿæˆ

### å®Ÿè·µçš„ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼
    
    
    ```mermaid
    graph TD
        A[Materials Project API] --> B[ãƒ‡ãƒ¼ã‚¿å–å¾— & CIFä¿å­˜]
        B --> C[PyG Datasetä½œæˆ]
        C --> D[åˆ†æ•£å­¦ç¿’ / GPUæœ€é©åŒ–]
        D --> E[ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜]
        E --> F[ONNXå¤‰æ›]
        F --> G[FastAPI ãƒ‡ãƒ—ãƒ­ã‚¤]
        G --> H[REST APIå…¬é–‹]
    
        style A fill:#667eea,color:#fff
        style D fill:#764ba2,color:#fff
        style H fill:#28a745,color:#fff
    ```

### æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

æœ¬ã‚·ãƒªãƒ¼ã‚ºã§å­¦ã‚“ã çŸ¥è­˜ã‚’æ´»ç”¨ã—ã¦ã€ä»¥ä¸‹ã®ã‚ˆã†ãªå®Ÿè·µãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«æŒ‘æˆ¦ã—ã¦ã¿ã¾ã—ã‚‡ã†ï¼š

  1. **ã‚«ã‚¹ã‚¿ãƒ ç‰©æ€§äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«** : Materials Projectã®åˆ¥ã®ç‰©æ€§ï¼ˆå½¢æˆã‚¨ãƒãƒ«ã‚®ãƒ¼ã€å¼¾æ€§ç‡ç­‰ï¼‰ã‚’äºˆæ¸¬ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰
  2. **ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ¢ãƒ‡ãƒ«** : çµ„æˆãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã¨GNNãƒ¢ãƒ‡ãƒ«ã®ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã«ã‚ˆã‚‹é«˜ç²¾åº¦äºˆæ¸¬
  3. **èƒ½å‹•å­¦ç¿’ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³** : ä¸ç¢ºå®Ÿæ€§æ¨å®šã‚’ç”¨ã„ãŸåŠ¹ç‡çš„ãªãƒ‡ãƒ¼ã‚¿åé›†æˆ¦ç•¥
  4. **Webã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³** : Streamlitç­‰ã‚’ç”¨ã„ãŸã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªææ–™æ¢ç´¢ãƒ„ãƒ¼ãƒ«

## æ¼”ç¿’å•é¡Œ

#### æ¼”ç¿’ 6.1ï¼ˆEasyï¼‰: Materials Project APIã«ã‚ˆã‚‹åŸºæœ¬çš„ãªãƒ‡ãƒ¼ã‚¿å–å¾—

Materials Project APIã‚’ç”¨ã„ã¦ã€å½¢æˆã‚¨ãƒãƒ«ã‚®ãƒ¼ãŒ-2.0 eV/atomä»¥ä¸‹ã®å®‰å®šãªé…¸åŒ–ç‰©ææ–™ï¼ˆOå«æœ‰ï¼‰ã‚’100ä»¶å–å¾—ã—ã€ä»¥ä¸‹ã®çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤ºã™ã‚‹ã‚³ãƒ¼ãƒ‰ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

  * å¹³å‡å½¢æˆã‚¨ãƒãƒ«ã‚®ãƒ¼
  * å«ã¾ã‚Œã‚‹å…ƒç´ ã®ç¨®é¡ã¨é »åº¦
  * ç©ºé–“ç¾¤ã®åˆ†å¸ƒ

**è§£ç­”ä¾‹:**
    
    
    from mp_api.client import MPRester
    import pandas as pd
    from collections import Counter
    
    API_KEY = "your_api_key_here"
    
    with MPRester(API_KEY) as mpr:
        docs = mpr.materials.summary.search(
            elements=["O"],  # é…¸ç´ å«æœ‰
            formation_energy_per_atom=(None, -2.0),  # -2.0 eV/atomä»¥ä¸‹
            num_elements=(2, 5),  # 2-5å…ƒç´ ç³»
            fields=["material_id", "formula_pretty", "formation_energy_per_atom",
                    "elements", "symmetry"]
        )
    
    # çµ±è¨ˆæƒ…å ±è¨ˆç®—
    formation_energies = [doc.formation_energy_per_atom for doc in docs]
    all_elements = []
    space_groups = []
    
    for doc in docs:
        all_elements.extend([str(el) for el in doc.elements])
        space_groups.append(doc.symmetry.symbol)
    
    print(f"=== çµ±è¨ˆæƒ…å ±ï¼ˆ{len(docs)}ä»¶ï¼‰ ===")
    print(f"å¹³å‡å½¢æˆã‚¨ãƒãƒ«ã‚®ãƒ¼: {sum(formation_energies)/len(formation_energies):.3f} eV/atom")
    print(f"\nå…ƒç´ é »åº¦ï¼ˆä¸Šä½10ï¼‰:")
    for elem, count in Counter(all_elements).most_common(10):
        print(f"  {elem}: {count}å›")
    print(f"\nç©ºé–“ç¾¤åˆ†å¸ƒï¼ˆä¸Šä½5ï¼‰:")
    for sg, count in Counter(space_groups).most_common(5):
        print(f"  {sg}: {count}ä»¶")

#### æ¼”ç¿’ 6.2ï¼ˆEasyï¼‰: CIFå½¢å¼ã§ã®ãƒ‡ãƒ¼ã‚¿ä¿å­˜ã¨ãƒ­ãƒ¼ãƒ‰

Materials Projectã‹ã‚‰ä»»æ„ã®ææ–™ï¼ˆmaterial_idæŒ‡å®šï¼‰ã®çµæ™¶æ§‹é€ ã‚’å–å¾—ã—ã€CIFå½¢å¼ã§ä¿å­˜å¾Œã€å†åº¦ãƒ­ãƒ¼ãƒ‰ã—ã¦åŸå­ã‚µã‚¤ãƒˆæƒ…å ±ã‚’è¡¨ç¤ºã™ã‚‹ã‚³ãƒ¼ãƒ‰ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
    
    
    from mp_api.client import MPRester
    from pymatgen.io.cif import CifWriter, CifParser
    
    API_KEY = "your_api_key_here"
    material_id = "mp-1234"  # å®Ÿéš›ã®IDã«ç½®ãæ›ãˆ
    
    # 1. ãƒ‡ãƒ¼ã‚¿å–å¾—ã¨CIFä¿å­˜
    with MPRester(API_KEY) as mpr:
        structure = mpr.get_structure_by_material_id(material_id)
    
        cif_writer = CifWriter(structure)
        cif_writer.write_file(f"{material_id}.cif")
        print(f"âœ“ CIFä¿å­˜: {material_id}.cif")
    
    # 2. CIFãƒ­ãƒ¼ãƒ‰
    parser = CifParser(f"{material_id}.cif")
    structure_loaded = parser.get_structures()[0]
    
    # 3. åŸå­ã‚µã‚¤ãƒˆæƒ…å ±è¡¨ç¤º
    print(f"\n=== åŸå­ã‚µã‚¤ãƒˆæƒ…å ± ===")
    print(f"åŒ–å­¦å¼: {structure_loaded.composition.reduced_formula}")
    for i, site in enumerate(structure_loaded):
        print(f"Site {i+1}: {site.species_string} at fractional coords {site.frac_coords}")

#### æ¼”ç¿’ 6.3ï¼ˆMediumï¼‰: ã‚«ã‚¹ã‚¿ãƒ InMemoryDatasetã®æ‹¡å¼µ

ã‚³ãƒ¼ãƒ‰ä¾‹4ã®`MaterialsProjectDataset`ã‚’æ‹¡å¼µã—ã€ä»¥ä¸‹ã®æ©Ÿèƒ½ã‚’è¿½åŠ ã—ã¦ãã ã•ã„ï¼š

  1. è¤‡æ•°ã®ç‰©æ€§ï¼ˆband_gap, formation_energy_per_atomï¼‰ã‚’åŒæ™‚ã«å–å¾—
  2. `__len__()`ã¨`__getitem__()`ãƒ¡ã‚½ãƒƒãƒ‰ã®æ˜ç¤ºçš„å®Ÿè£…
  3. ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®çµ±è¨ˆæƒ…å ±ã‚’è¿”ã™`statistics()`ãƒ¡ã‚½ãƒƒãƒ‰ã®è¿½åŠ 

**è§£ç­”ä¾‹:**
    
    
    class MultiPropertyDataset(InMemoryDataset):
        def __init__(self, root, api_key, property_names=['band_gap', 'formation_energy_per_atom'],
                     cutoff=5.0, transform=None, pre_transform=None, pre_filter=None):
            self.api_key = api_key
            self.property_names = property_names
            self.converter = StructureToGraph(cutoff=cutoff)
    
            super().__init__(root, transform, pre_transform, pre_filter)
            self.data, self.slices = torch.load(self.processed_paths[0])
    
        @property
        def raw_file_names(self):
            return ['materials.pkl']
    
        @property
        def processed_file_names(self):
            return ['data.pt']
    
        def download(self):
            with MPRester(self.api_key) as mpr:
                docs = mpr.materials.summary.search(
                    energy_above_hull=(0, 0.05),
                    fields=["material_id"] + self.property_names
                )
    
                materials_data = []
                for doc in docs:
                    try:
                        structure = mpr.get_structure_by_material_id(doc.material_id)
                        properties = {prop: getattr(doc, prop) for prop in self.property_names}
    
                        materials_data.append({
                            'material_id': doc.material_id,
                            'structure': structure,
                            'properties': properties
                        })
                    except:
                        pass
    
                with open(self.raw_paths[0], 'wb') as f:
                    pickle.dump(materials_data, f)
    
        def process(self):
            with open(self.raw_paths[0], 'rb') as f:
                materials_data = pickle.load(f)
    
            data_list = []
            for item in materials_data:
                data = self.converter.convert(item['structure'])
    
                # è¤‡æ•°ç‰©æ€§ã‚’ãƒ†ãƒ³ã‚½ãƒ«åŒ–
                y = torch.tensor([item['properties'][prop] for prop in self.property_names],
                                 dtype=torch.float)
                data.y = y
                data.material_id = item['material_id']
    
                data_list.append(data)
    
            data, slices = self.collate(data_list)
            torch.save((data, slices), self.processed_paths[0])
    
        def __len__(self):
            return len(self.slices['x']) - 1
    
        def __getitem__(self, idx):
            data = self.get(idx)
            return data
    
        def statistics(self):
            """ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®çµ±è¨ˆæƒ…å ±ã‚’è¿”ã™"""
            stats = {
                'num_samples': len(self),
                'properties': {}
            }
    
            for i, prop in enumerate(self.property_names):
                values = [self[j].y[i].item() for j in range(len(self))]
                stats['properties'][prop] = {
                    'mean': np.mean(values),
                    'std': np.std(values),
                    'min': np.min(values),
                    'max': np.max(values)
                }
    
            return stats

#### æ¼”ç¿’ 6.4ï¼ˆMediumï¼‰: Mixed Precision Trainingã®åŠ¹æœæ¤œè¨¼

é€šå¸¸ã®FP32å­¦ç¿’ã¨Mixed Precision Trainingï¼ˆFP16ï¼‰ã‚’æ¯”è¼ƒã—ã€ä»¥ä¸‹ã‚’æ¤œè¨¼ã™ã‚‹ã‚³ãƒ¼ãƒ‰ã‚’ä½œæˆã—ã¦ãã ã•ã„ï¼š

  * å­¦ç¿’æ™‚é–“ã®å·®
  * GPU ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®å·®
  * æœ€çµ‚çš„ãªMAEã®å·®ï¼ˆç²¾åº¦ã¸ã®å½±éŸ¿ï¼‰

**è§£ç­”ä¾‹:**
    
    
    import torch
    from torch.cuda.amp import autocast, GradScaler
    import time
    
    def compare_training_precision(model, dataset, epochs=50):
        device = torch.device('cuda')
        train_loader = DataLoader(dataset, batch_size=64, shuffle=True)
    
        results = {}
    
        # 1. FP32å­¦ç¿’
        print("=== FP32å­¦ç¿’ ===")
        model_fp32 = model.to(device)
        optimizer = torch.optim.Adam(model_fp32.parameters(), lr=0.001)
        criterion = torch.nn.MSELoss()
    
        torch.cuda.reset_peak_memory_stats()
        start_time = time.time()
    
        for epoch in range(epochs):
            for batch in train_loader:
                batch = batch.to(device)
                optimizer.zero_grad()
                output = model_fp32(batch)
                loss = criterion(output, batch.y)
                loss.backward()
                optimizer.step()
    
        fp32_time = time.time() - start_time
        fp32_memory = torch.cuda.max_memory_allocated() / 1024**3  # GB
    
        results['fp32'] = {'time': fp32_time, 'memory': fp32_memory}
    
        # 2. Mixed Precisionå­¦ç¿’
        print("\n=== Mixed Precisionå­¦ç¿’ ===")
        model_fp16 = model.to(device)
        optimizer = torch.optim.Adam(model_fp16.parameters(), lr=0.001)
        scaler = GradScaler()
    
        torch.cuda.reset_peak_memory_stats()
        start_time = time.time()
    
        for epoch in range(epochs):
            for batch in train_loader:
                batch = batch.to(device)
                optimizer.zero_grad()
    
                with autocast():
                    output = model_fp16(batch)
                    loss = criterion(output, batch.y)
    
                scaler.scale(loss).backward()
                scaler.step(optimizer)
                scaler.update()
    
        fp16_time = time.time() - start_time
        fp16_memory = torch.cuda.max_memory_allocated() / 1024**3
    
        results['fp16'] = {'time': fp16_time, 'memory': fp16_memory}
    
        # çµæœè¡¨ç¤º
        print("\n=== æ¯”è¼ƒçµæœ ===")
        print(f"å­¦ç¿’æ™‚é–“: FP32={fp32_time:.2f}s, FP16={fp16_time:.2f}s (é«˜é€ŸåŒ–ç‡: {fp32_time/fp16_time:.2f}x)")
        print(f"GPU ãƒ¡ãƒ¢ãƒª: FP32={fp32_memory:.2f}GB, FP16={fp16_memory:.2f}GB (å‰Šæ¸›ç‡: {(1-fp16_memory/fp32_memory)*100:.1f}%)")
    
        return results

#### æ¼”ç¿’ 6.5ï¼ˆMediumï¼‰: ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰ã®å­¦ç¿’å†é–‹

å­¦ç¿’ã‚’é€”ä¸­ã§ä¸­æ–­ã—ã€ä¿å­˜ã•ã‚ŒãŸãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰å­¦ç¿’ã‚’å†é–‹ã™ã‚‹ã‚³ãƒ¼ãƒ‰ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚ã‚¨ãƒãƒƒã‚¯ç•ªå·ã€lossã€optimizerçŠ¶æ…‹ã‚’æ­£ã—ãå¾©å…ƒã—ã¦ãã ã•ã„ã€‚

**è§£ç­”ä¾‹:**
    
    
    import torch
    
    def train_with_resume(model, dataset, total_epochs=100, checkpoint_path=None):
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        model = model.to(device)
    
        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
        criterion = torch.nn.MSELoss()
        train_loader = DataLoader(dataset, batch_size=64, shuffle=True)
    
        start_epoch = 0
    
        # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰å†é–‹
        if checkpoint_path and os.path.exists(checkpoint_path):
            checkpoint = torch.load(checkpoint_path)
            model.load_state_dict(checkpoint['model_state_dict'])
            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
            start_epoch = checkpoint['epoch']
            print(f"âœ“ ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰å†é–‹: Epoch {start_epoch}")
    
        # å­¦ç¿’ãƒ«ãƒ¼ãƒ—
        for epoch in range(start_epoch, total_epochs):
            model.train()
            total_loss = 0
    
            for batch in train_loader:
                batch = batch.to(device)
                optimizer.zero_grad()
                output = model(batch)
                loss = criterion(output, batch.y)
                loss.backward()
                optimizer.step()
    
                total_loss += loss.item()
    
            avg_loss = total_loss / len(train_loader)
            print(f"Epoch {epoch+1}/{total_epochs}, Loss: {avg_loss:.4f}")
    
            # 10ã‚¨ãƒãƒƒã‚¯ã”ã¨ã«ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜
            if (epoch + 1) % 10 == 0:
                checkpoint = {
                    'epoch': epoch + 1,
                    'model_state_dict': model.state_dict(),
                    'optimizer_state_dict': optimizer.state_dict(),
                    'loss': avg_loss
                }
                torch.save(checkpoint, f'checkpoint_epoch{epoch+1}.pt')
                print(f"âœ“ Checkpoint saved")
    
        return model
    
    # ä½¿ç”¨ä¾‹
    # model = train_with_resume(CGCNNModel(), dataset, total_epochs=100, checkpoint_path='checkpoint_epoch50.pt')

#### æ¼”ç¿’ 6.6ï¼ˆHardï¼‰: ãƒãƒƒãƒäºˆæ¸¬ã¨ONNXæ¨è«–é€Ÿåº¦ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯

PyTorchãƒã‚¤ãƒ†ã‚£ãƒ–æ¨è«–ã¨ONNX Runtimeæ¨è«–ã®é€Ÿåº¦ã‚’æ¯”è¼ƒã™ã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚³ãƒ¼ãƒ‰ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚ä»¥ä¸‹ã®æ¡ä»¶ã§æ¸¬å®šã—ã¦ãã ã•ã„ï¼š

  * ãƒãƒƒãƒã‚µã‚¤ã‚º: 1, 32, 64, 128
  * å„ãƒãƒƒãƒã‚µã‚¤ã‚ºã§100å›æ¨è«–ã‚’å®Ÿè¡Œ
  * å¹³å‡æ¨è«–æ™‚é–“ï¼ˆmsï¼‰ã¨ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆï¼ˆsamples/secï¼‰ã‚’è¨ˆç®—

**è§£ç­”ä¾‹:**
    
    
    import torch
    import onnxruntime as ort
    import time
    import numpy as np
    from torch_geometric.data import DataLoader, Batch
    
    def benchmark_inference(model, dataset, onnx_path, batch_sizes=[1, 32, 64, 128], n_iterations=100):
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        model = model.to(device)
        model.eval()
    
        # ONNX Runtime ã‚»ãƒƒã‚·ãƒ§ãƒ³
        ort_session = ort.InferenceSession(onnx_path)
    
        results = []
    
        for batch_size in batch_sizes:
            print(f"\n=== Batch Size: {batch_size} ===")
    
            loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)
    
            # PyTorchæ¨è«–
            torch_times = []
            for _ in range(n_iterations):
                batch = next(iter(loader))
                batch = batch.to(device)
    
                start = time.time()
                with torch.no_grad():
                    _ = model(batch)
                torch.cuda.synchronize() if torch.cuda.is_available() else None
                torch_times.append((time.time() - start) * 1000)  # ms
    
            torch_avg = np.mean(torch_times)
            torch_throughput = batch_size * 1000 / torch_avg
    
            # ONNX Runtimeæ¨è«–
            onnx_times = []
            for _ in range(n_iterations):
                batch = next(iter(loader))
    
                ort_inputs = {
                    'x': batch.x.numpy(),
                    'edge_index': batch.edge_index.numpy(),
                    'edge_attr': batch.edge_attr.numpy(),
                    'batch': batch.batch.numpy()
                }
    
                start = time.time()
                _ = ort_session.run(None, ort_inputs)
                onnx_times.append((time.time() - start) * 1000)
    
            onnx_avg = np.mean(onnx_times)
            onnx_throughput = batch_size * 1000 / onnx_avg
    
            # çµæœä¿å­˜
            results.append({
                'batch_size': batch_size,
                'pytorch_ms': torch_avg,
                'onnx_ms': onnx_avg,
                'speedup': torch_avg / onnx_avg,
                'pytorch_throughput': torch_throughput,
                'onnx_throughput': onnx_throughput
            })
    
            print(f"PyTorch: {torch_avg:.2f} ms/batch ({torch_throughput:.1f} samples/sec)")
            print(f"ONNX: {onnx_avg:.2f} ms/batch ({onnx_throughput:.1f} samples/sec)")
            print(f"é«˜é€ŸåŒ–ç‡: {torch_avg/onnx_avg:.2f}x")
    
        return results
    
    # ä½¿ç”¨ä¾‹
    # results = benchmark_inference(model, dataset, 'cgcnn_model.onnx')

#### æ¼”ç¿’ 6.7ï¼ˆHardï¼‰: FastAPIéåŒæœŸãƒãƒƒãƒæ¨è«–

FastAPIã®ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚¿ã‚¹ã‚¯æ©Ÿèƒ½ã‚’ç”¨ã„ã¦ã€è¤‡æ•°ã®äºˆæ¸¬ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ãƒãƒƒãƒå‡¦ç†ã™ã‚‹éåŒæœŸAPIã‚’å®Ÿè£…ã—ã¦ãã ã•ã„ã€‚ä»¥ä¸‹ã®è¦ä»¶ã‚’æº€ãŸã—ã¦ãã ã•ã„ï¼š

  * ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ä¸€å®šæ™‚é–“ï¼ˆä¾‹: 1ç§’ï¼‰ãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°
  * ãƒãƒƒãƒ•ã‚¡ã•ã‚ŒãŸãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ãƒãƒƒãƒã¨ã—ã¦ä¸€æ‹¬æ¨è«–
  * å„ãƒªã‚¯ã‚¨ã‚¹ãƒˆã«å¯¾ã—ã¦ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªã‚¸ãƒ§ãƒ–IDã‚’ç™ºè¡Œ
  * `/result/{job_id}`ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã§çµæœã‚’å–å¾—

**è§£ç­”ä¾‹:**
    
    
    from fastapi import FastAPI, BackgroundTasks
    from pydantic import BaseModel
    import asyncio
    import uuid
    from collections import defaultdict
    import torch
    
    app = FastAPI()
    
    # ã‚°ãƒ­ãƒ¼ãƒãƒ«çŠ¶æ…‹
    pending_requests = []
    results_store = {}
    MODEL = None
    
    class PredictionRequest(BaseModel):
        structure: dict
    
    class JobResponse(BaseModel):
        job_id: str
        status: str
    
    class ResultResponse(BaseModel):
        job_id: str
        prediction: float = None
        status: str
    
    async def batch_processor():
        """ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§ãƒãƒƒãƒå‡¦ç†ã‚’å®Ÿè¡Œ"""
        while True:
            await asyncio.sleep(1.0)  # 1ç§’ã”ã¨ã«ãƒãƒƒãƒå‡¦ç†
    
            if len(pending_requests) == 0:
                continue
    
            # ãƒãƒƒãƒ•ã‚¡ã•ã‚ŒãŸãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å–å¾—
            batch_requests = pending_requests.copy()
            pending_requests.clear()
    
            # ãƒãƒƒãƒæ¨è«–
            job_ids = [req['job_id'] for req in batch_requests]
            structures = [req['structure'] for req in batch_requests]
    
            # ã‚°ãƒ©ãƒ•å¤‰æ›ï¼ˆä¸¦åˆ—å‡¦ç†ï¼‰
            data_list = []
            for structure in structures:
                converter = StructureToGraph(cutoff=5.0)
                data = converter.convert(Structure.from_dict(structure))
                data_list.append(data)
    
            # ãƒãƒƒãƒåŒ–
            from torch_geometric.data import Batch
            batch = Batch.from_data_list(data_list)
            batch = batch.to('cuda' if torch.cuda.is_available() else 'cpu')
    
            # æ¨è«–
            with torch.no_grad():
                predictions = MODEL(batch).cpu().numpy()
    
            # çµæœä¿å­˜
            for job_id, pred in zip(job_ids, predictions):
                results_store[job_id] = {
                    'status': 'completed',
                    'prediction': float(pred)
                }
    
    @app.on_event("startup")
    async def startup_event():
        global MODEL
        MODEL = CGCNNModel()
        checkpoint = torch.load('checkpoints/best_model.pt')
        MODEL.load_state_dict(checkpoint['model_state_dict'])
        MODEL.eval()
    
        # ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚¿ã‚¹ã‚¯é–‹å§‹
        asyncio.create_task(batch_processor())
    
    @app.post("/predict/async", response_model=JobResponse)
    async def predict_async(request: PredictionRequest):
        """éåŒæœŸäºˆæ¸¬ãƒªã‚¯ã‚¨ã‚¹ãƒˆ"""
        job_id = str(uuid.uuid4())
    
        # ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ãƒãƒƒãƒ•ã‚¡ã«è¿½åŠ 
        pending_requests.append({
            'job_id': job_id,
            'structure': request.structure
        })
    
        # çµæœã‚¹ãƒˆã‚¢ã«åˆæœŸçŠ¶æ…‹ã‚’ä¿å­˜
        results_store[job_id] = {'status': 'pending'}
    
        return JobResponse(job_id=job_id, status='pending')
    
    @app.get("/result/{job_id}", response_model=ResultResponse)
    async def get_result(job_id: str):
        """çµæœå–å¾—"""
        if job_id not in results_store:
            return ResultResponse(job_id=job_id, status='not_found')
    
        result = results_store[job_id]
    
        return ResultResponse(
            job_id=job_id,
            prediction=result.get('prediction'),
            status=result['status']
        )

#### æ¼”ç¿’ 6.8ï¼ˆHardï¼‰: ä¸ç¢ºå®Ÿæ€§æ¨å®šä»˜ãäºˆæ¸¬API

Monte Carlo Dropoutï¼ˆMCãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆï¼‰ã‚’ç”¨ã„ã¦ã€äºˆæ¸¬å€¤ã®ä¸ç¢ºå®Ÿæ€§ã‚’æ¨å®šã™ã‚‹APIã‚’å®Ÿè£…ã—ã¦ãã ã•ã„ã€‚ä»¥ä¸‹ã‚’å«ã‚ã¦ãã ã•ã„ï¼š

  * ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆå±¤ã‚’æŒã¤ãƒ¢ãƒ‡ãƒ«å®šç¾©
  * æ¨è«–æ™‚ã«ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆã‚’æœ‰åŠ¹åŒ–ã—ã€è¤‡æ•°å›ï¼ˆä¾‹: 30å›ï¼‰æ¨è«–
  * äºˆæ¸¬å€¤ã®å¹³å‡ã¨æ¨™æº–åå·®ã‚’è¿”ã™

**è§£ç­”ä¾‹:**
    
    
    import torch
    import torch.nn as nn
    from torch_geometric.nn import CGConv, global_mean_pool
    import numpy as np
    
    class CGCNNWithDropout(nn.Module):
        """ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆå±¤ã‚’æŒã¤CGCNN"""
        def __init__(self, atom_fea_len=92, nbr_fea_len=41,
                     hidden_dim=128, n_conv=3, dropout=0.1):
            super().__init__()
    
            self.atom_embedding = nn.Linear(atom_fea_len, hidden_dim)
    
            self.conv_layers = nn.ModuleList([
                CGConv(hidden_dim, nbr_fea_len) for _ in range(n_conv)
            ])
    
            self.bn_layers = nn.ModuleList([
                nn.BatchNorm1d(hidden_dim) for _ in range(n_conv)
            ])
    
            self.dropout = nn.Dropout(p=dropout)
    
            self.fc1 = nn.Linear(hidden_dim, 64)
            self.fc2 = nn.Linear(64, 1)
            self.activation = nn.Softplus()
    
        def forward(self, data):
            x, edge_index, edge_attr, batch = data.x, data.edge_index, data.edge_attr, data.batch
    
            x = self.atom_embedding(x)
    
            for conv, bn in zip(self.conv_layers, self.bn_layers):
                x_new = conv(x, edge_index, edge_attr)
                x_new = bn(x_new)
                x_new = self.activation(x_new)
                x_new = self.dropout(x_new)  # ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆ
                x = x + x_new
    
            x = global_mean_pool(x, batch)
    
            x = self.dropout(self.activation(self.fc1(x)))  # ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆ
            x = self.fc2(x)
    
            return x.squeeze()
    
        def predict_with_uncertainty(self, data, n_samples=30):
            """
            MC Dropoutã«ã‚ˆã‚‹ä¸ç¢ºå®Ÿæ€§æ¨å®š
    
            Returns:
                mean, std (äºˆæ¸¬å€¤ã®å¹³å‡ã¨æ¨™æº–åå·®)
            """
            self.train()  # ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆã‚’æœ‰åŠ¹åŒ–
    
            predictions = []
            with torch.no_grad():
                for _ in range(n_samples):
                    pred = self.forward(data).item()
                    predictions.append(pred)
    
            mean = np.mean(predictions)
            std = np.std(predictions)
    
            return mean, std
    
    # FastAPIçµ±åˆ
    from fastapi import FastAPI
    from pydantic import BaseModel
    
    app = FastAPI()
    MODEL = None
    
    class UncertaintyResponse(BaseModel):
        prediction: float
        uncertainty: float
        confidence_interval_95: tuple
    
    @app.post("/predict/uncertainty", response_model=UncertaintyResponse)
    async def predict_with_uncertainty(request: CrystalInput):
        """ä¸ç¢ºå®Ÿæ€§æ¨å®šä»˜ãäºˆæ¸¬"""
        # æ§‹é€ ãƒ‡ãƒ¼ã‚¿ã®ãƒ‘ãƒ¼ã‚¹
        structure = Structure.from_dict(request.structure)
    
        # ã‚°ãƒ©ãƒ•å¤‰æ›
        converter = StructureToGraph(cutoff=5.0)
        data = converter.convert(structure)
        data = data.to('cuda' if torch.cuda.is_available() else 'cpu')
    
        # MC Dropoutæ¨è«–
        mean, std = MODEL.predict_with_uncertainty(data, n_samples=30)
    
        # 95%ä¿¡é ¼åŒºé–“
        ci_lower = mean - 1.96 * std
        ci_upper = mean + 1.96 * std
    
        return UncertaintyResponse(
            prediction=mean,
            uncertainty=std,
            confidence_interval_95=(ci_lower, ci_upper)
        )

## å‚è€ƒæ–‡çŒ®

  1. Jain, A., Ong, S. P., Hautier, G., et al. (2013). Commentary: The Materials Project: A materials genome approach to accelerating materials innovation. _APL Materials_ , 1(1), 011002. DOI: 10.1063/1.4812323, pp. 1-11. (Materials Project APIã®åŸºç¤æ–‡çŒ®)
  2. Ong, S. P., Richards, W. D., Jain, A., et al. (2013). Python Materials Genomics (pymatgen): A robust, open-source python library for materials analysis. _Computational Materials Science_ , 68, 314-319. DOI: 10.1016/j.commatsci.2012.10.028, pp. 314-319. (pymatgenãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®å…¬å¼è«–æ–‡)
  3. Fey, M., & Lenssen, J. E. (2019). Fast Graph Representation Learning with PyTorch Geometric. In _ICLR Workshop on Representation Learning on Graphs and Manifolds_. arXiv:1903.02428, pp. 1-5. (PyTorch Geometricã®å…¬å¼è«–æ–‡)
  4. Micikevicius, P., Narang, S., Alben, J., et al. (2018). Mixed Precision Training. In _International Conference on Learning Representations (ICLR)_. arXiv:1710.03740, pp. 1-12. (Mixed Precision Trainingã®ææ¡ˆè«–æ–‡)
  5. Bingham, E., Chen, J. P., Jankowiak, M., et al. (2019). Pyro: Deep Universal Probabilistic Programming. _Journal of Machine Learning Research_ , 20(28), 1-6. (ä¸ç¢ºå®Ÿæ€§æ¨å®šã®ç†è«–çš„èƒŒæ™¯)
  6. RamÃ­rez, S. (2021). _FastAPI: Modern Python Web Development_. O'Reilly Media, pp. 1-350. (FastAPIã®åŒ…æ‹¬çš„ãªã‚¬ã‚¤ãƒ‰ã€ç‰¹ã«Chapter 5-7ãŒæœ¬ç•ªãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆã«æœ‰ç”¨)
  7. ONNX Runtime Development Team. (2020). ONNX Runtime Performance Tuning. Microsoft Technical Report. https://onnxruntime.ai/docs/performance/ (ONNX Runtimeæœ€é©åŒ–ã®å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ)

[â† ã‚·ãƒªãƒ¼ã‚ºãƒˆãƒƒãƒ—ã«æˆ»ã‚‹](<index.html>)

### å…è²¬äº‹é …

  * æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯æ•™è‚²ãƒ»ç ”ç©¶ãƒ»æƒ…å ±æä¾›ã®ã¿ã‚’ç›®çš„ã¨ã—ã¦ãŠã‚Šã€å°‚é–€çš„ãªåŠ©è¨€(æ³•å¾‹ãƒ»ä¼šè¨ˆãƒ»æŠ€è¡“çš„ä¿è¨¼ãªã©)ã‚’æä¾›ã™ã‚‹ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚
  * æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŠã‚ˆã³ä»˜éšã™ã‚‹Code examplesã¯ã€Œç¾çŠ¶æœ‰å§¿(AS IS)ã€ã§æä¾›ã•ã‚Œã€æ˜ç¤ºã¾ãŸã¯é»™ç¤ºã‚’å•ã‚ãšã€å•†å“æ€§ã€ç‰¹å®šç›®çš„é©åˆæ€§ã€æ¨©åˆ©éä¾µå®³ã€æ­£ç¢ºæ€§ãƒ»å®Œå…¨æ€§ã€å‹•ä½œãƒ»å®‰å…¨æ€§ç­‰ã„ã‹ãªã‚‹ä¿è¨¼ã‚‚ã—ã¾ã›ã‚“ã€‚
  * å¤–éƒ¨ãƒªãƒ³ã‚¯ã€ç¬¬ä¸‰è€…ãŒæä¾›ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ»ãƒ„ãƒ¼ãƒ«ãƒ»ãƒ©ã‚¤ãƒ–ãƒ©ãƒªç­‰ã®å†…å®¹ãƒ»å¯ç”¨æ€§ãƒ»å®‰å…¨æ€§ã«ã¤ã„ã¦ã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯ä¸€åˆ‡ã®è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚
  * æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®åˆ©ç”¨ãƒ»å®Ÿè¡Œãƒ»è§£é‡ˆã«ã‚ˆã‚Šç›´æ¥çš„ãƒ»é–“æ¥çš„ãƒ»ä»˜éšçš„ãƒ»ç‰¹åˆ¥ãƒ»çµæœçš„ãƒ»æ‡²ç½°çš„æå®³ãŒç”Ÿã˜ãŸå ´åˆã§ã‚‚ã€é©ç”¨æ³•ã§è¨±å®¹ã•ã‚Œã‚‹æœ€å¤§é™ã®ç¯„å›²ã§ã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚
  * æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å†…å®¹ã¯ã€äºˆå‘Šãªãå¤‰æ›´ãƒ»æ›´æ–°ãƒ»æä¾›åœæ­¢ã•ã‚Œã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚
  * æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®è‘—ä½œæ¨©ãƒ»ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯æ˜è¨˜ã•ã‚ŒãŸæ¡ä»¶(ä¾‹: CC BY 4.0)ã«å¾“ã„ã¾ã™ã€‚å½“è©²ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯é€šå¸¸ã€ç„¡ä¿è¨¼æ¡é …ã‚’å«ã¿ã¾ã™ã€‚
