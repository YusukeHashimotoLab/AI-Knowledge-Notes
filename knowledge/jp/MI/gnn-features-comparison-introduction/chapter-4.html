<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ç¬¬4ç« ï¼šçµ„æˆãƒ™ãƒ¼ã‚¹ vs GNNå®šé‡çš„æ¯”è¼ƒ | GNNç‰¹å¾´é‡æ¯”è¼ƒå…¥é–€</title>
    <meta name="description" content="Matbenchãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¨RF/CGCNNã®å®šé‡çš„æ€§èƒ½æ¯”è¼ƒã€‚çµ±è¨ˆçš„æœ‰æ„æ€§æ¤œå®šã€è¨ˆç®—ã‚³ã‚¹ãƒˆã€ãƒ‡ãƒ¼ã‚¿è¦æ±‚é‡ã€è§£é‡ˆå¯èƒ½æ€§ã‚’å®Ÿè¨¼åˆ†æã€‚">

    <!-- MathJax 3.x for mathematical equations -->
    <script>
    MathJax = {
        tex: {
            inlineMath: [['$', '$'], ['\\(', '\\)']],
            displayMath: [['$$', '$$'], ['\\[', '\\]']],
            processEscapes: true,
            processEnvironments: true
        },
        options: {
            skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        }
    };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

    <!-- Mermaid for diagrams -->
    <script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
    <script>
        mermaid.initialize({
            startOnLoad: true,
            theme: 'default',
            themeVariables: {
                primaryColor: '#667eea',
                primaryTextColor: '#fff',
                primaryBorderColor: '#764ba2',
                lineColor: '#764ba2',
                secondaryColor: '#764ba2',
                tertiaryColor: '#fff'
            }
        });
    </script>

    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css" rel="stylesheet" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>

    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Noto Sans JP', sans-serif;
            line-height: 1.8;
            color: #2c3e50;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            padding: 2rem 1rem;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            background: white;
            border-radius: 12px;
            box-shadow: 0 8px 32px rgba(0,0,0,0.1);
            padding: 3rem;
        }

        h1 {
            font-size: 2.5rem;
            margin-bottom: 1.5rem;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }

        h2 {
            font-size: 1.8rem;
            margin: 2.5rem 0 1.5rem;
            color: #667eea;
            border-left: 4px solid #764ba2;
            padding-left: 1rem;
        }

        h3 {
            font-size: 1.4rem;
            margin: 2rem 0 1rem;
            color: #764ba2;
        }

        p {
            margin-bottom: 1.2rem;
            text-align: justify;
        }

        .highlight-box {
            background: linear-gradient(135deg, rgba(102, 126, 234, 0.1) 0%, rgba(118, 75, 162, 0.1) 100%);
            border-left: 4px solid #667eea;
            padding: 1.5rem;
            margin: 1.5rem 0;
            border-radius: 8px;
        }

        .warning-box {
            background: rgba(255, 193, 7, 0.1);
            border-left: 4px solid #ffc107;
            padding: 1.5rem;
            margin: 1.5rem 0;
            border-radius: 8px;
        }

        pre {
            background: #2d2d2d;
            border-radius: 8px;
            padding: 1.5rem;
            overflow-x: auto;
            margin: 1.5rem 0;
        }

        code {
            font-family: 'Consolas', 'Monaco', 'Courier New', monospace;
            font-size: 0.9rem;
        }

        .mermaid {
            background: white;
            padding: 2rem;
            border-radius: 8px;
            margin: 2rem 0;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin: 1.5rem 0;
            box-shadow: 0 2px 8px rgba(0,0,0,0.1);
        }

        th, td {
            padding: 1rem;
            text-align: left;
            border-bottom: 1px solid #e0e0e0;
        }

        th {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            font-weight: 600;
        }

        tr:hover {
            background: rgba(102, 126, 234, 0.05);
        }

        .exercise {
            background: rgba(118, 75, 162, 0.05);
            border: 2px solid #764ba2;
            border-radius: 8px;
            padding: 1.5rem;
            margin: 1.5rem 0;
        }

        .exercise-header {
            font-weight: 600;
            color: #764ba2;
            margin-bottom: 0.5rem;
        }

        .difficulty {
            display: inline-block;
            padding: 0.25rem 0.75rem;
            border-radius: 4px;
            font-size: 0.85rem;
            font-weight: 600;
            margin-left: 0.5rem;
        }

        .difficulty-easy {
            background: #4caf50;
            color: white;
        }

        .difficulty-medium {
            background: #ff9800;
            color: white;
        }

        .difficulty-hard {
            background: #f44336;
            color: white;
        }

        .nav-buttons {
            display: flex;
            justify-content: space-between;
            margin-top: 3rem;
            padding-top: 2rem;
            border-top: 2px solid #e0e0e0;
        }

        .nav-button {
            padding: 0.75rem 1.5rem;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            text-decoration: none;
            border-radius: 6px;
            font-weight: 600;
            transition: transform 0.2s;
        }

        .nav-button:hover {
            transform: translateY(-2px);
        }

        ul, ol {
            margin: 1rem 0 1rem 2rem;
        }

        li {
            margin-bottom: 0.5rem;
        }

        @media (max-width: 768px) {
            .container {
                padding: 1.5rem;
            }

            h1 {
                font-size: 2rem;
            }

            h2 {
                font-size: 1.5rem;
            }

            pre {
                padding: 1rem;
                font-size: 0.85rem;
            }
        }
    </style>

    <style>
        /* Locale Switcher Styles */
        .locale-switcher {
            display: flex;
            align-items: center;
            gap: 0.5rem;
            padding: 0.5rem 1rem;
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
            border-radius: 6px;
            font-size: 0.9rem;
            margin-bottom: 1rem;
            box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);
        }

        .current-locale {
            font-weight: 600;
            color: #7b2cbf;
            display: flex;
            align-items: center;
            gap: 0.25rem;
        }

        .locale-separator {
            color: #adb5bd;
            font-weight: 300;
        }

        .locale-link {
            color: #f093fb;
            text-decoration: none;
            font-weight: 500;
            transition: all 0.2s ease;
            display: flex;
            align-items: center;
            gap: 0.25rem;
            padding: 0.2rem 0.5rem;
            border-radius: 4px;
        }

        .locale-link:hover {
            background: rgba(240, 147, 251, 0.1);
            color: #d07be8;
            transform: translateY(-1px);
        }

        .locale-meta {
            color: #868e96;
            font-size: 0.85rem;
            font-style: italic;
            margin-left: auto;
        }

        @media (max-width: 768px) {
            .locale-switcher {
                font-size: 0.85rem;
                padding: 0.4rem 0.8rem;
            }
            .locale-meta {
                display: none;
            }
        }
    </style>
</head>
<body>
    <div class="locale-switcher">
<span class="current-locale">ğŸŒ JP</span>
<span class="locale-separator">|</span>
<a href="../../../en/MI/gnn-features-comparison-introduction/chapter-4.html" class="locale-link">ğŸ‡¬ğŸ‡§ EN</a>
<span class="locale-separator">|</span>
<span class="locale-meta">Last sync: 2025-11-16</span>
</div>
<div class="container">
        <h1>ç¬¬4ç« ï¼šçµ„æˆãƒ™ãƒ¼ã‚¹ vs GNNå®šé‡çš„æ¯”è¼ƒ</h1>

        <p>æœ¬ç« ã§ã¯ã€<strong>çµ„æˆãƒ™ãƒ¼ã‚¹ç‰¹å¾´é‡ï¼ˆMagpieï¼‰</strong>ã¨<strong>GNNæ§‹é€ ãƒ™ãƒ¼ã‚¹ç‰¹å¾´é‡ï¼ˆCGCNNï¼‰</strong>ã®æ€§èƒ½ã‚’ã€<strong>Matbenchæ¨™æº–ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯</strong>ã‚’ç”¨ã„ã¦å®šé‡çš„ã«æ¯”è¼ƒã—ã¾ã™ã€‚å˜ãªã‚‹ç²¾åº¦æ¯”è¼ƒã ã‘ã§ãªãã€çµ±è¨ˆçš„æœ‰æ„æ€§ã€è¨ˆç®—ã‚³ã‚¹ãƒˆã€ãƒ‡ãƒ¼ã‚¿è¦æ±‚é‡ã€è§£é‡ˆå¯èƒ½æ€§ã®å¤šè§’çš„ãªè¦³ç‚¹ã‹ã‚‰å®Ÿè¨¼åˆ†æã‚’è¡Œã„ã¾ã™ã€‚</p>

        <div class="highlight-box">
            <strong>ğŸ¯ å­¦ç¿’ç›®æ¨™</strong>
            <ul>
                <li>Matbenchãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®æ§‹é€ ã¨è©•ä¾¡ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã‚’ç†è§£ã™ã‚‹</li>
                <li>Random Forest (Magpie) ã¨CGCNNã®äºˆæ¸¬ç²¾åº¦ã‚’å®šé‡çš„ã«æ¯”è¼ƒã™ã‚‹</li>
                <li>çµ±è¨ˆçš„æœ‰æ„æ€§æ¤œå®šï¼ˆtæ¤œå®šã€ä¿¡é ¼åŒºé–“ã€på€¤ï¼‰ã‚’å®Ÿè£…ã™ã‚‹</li>
                <li>è¨ˆç®—ã‚³ã‚¹ãƒˆï¼ˆè¨“ç·´æ™‚é–“ã€æ¨è«–æ™‚é–“ã€ãƒ¡ãƒ¢ãƒªï¼‰ã‚’æ¸¬å®šãƒ»æ¯”è¼ƒã™ã‚‹</li>
                <li>ãƒ‡ãƒ¼ã‚¿è¦æ±‚é‡ã®é•ã„ã‚’å­¦ç¿’æ›²ç·šã§å¯è¦–åŒ–ã™ã‚‹</li>
                <li>SHAPå€¤ã¨Attentionæ©Ÿæ§‹ã«ã‚ˆã‚‹è§£é‡ˆå¯èƒ½æ€§ã‚’æ¯”è¼ƒã™ã‚‹</li>
                <li>æ‰‹æ³•é¸æŠã®æ„æ€æ±ºå®šãƒ•ãƒ­ãƒ¼ãƒãƒ£ãƒ¼ãƒˆã‚’æ§‹ç¯‰ã™ã‚‹</li>
            </ul>
        </div>

        <h2>4.1 Matbenchãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®æ¦‚è¦</h2>

        <p>Matbenchï¼ˆMaterials Benchmarkï¼‰ã¯ã€ææ–™ç§‘å­¦ã«ãŠã‘ã‚‹æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®<strong>æ¨™æº–åŒ–ã•ã‚ŒãŸè©•ä¾¡ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ </strong>ã§ã™ã€‚13ç¨®é¡ã®ææ–™ç‰©æ€§äºˆæ¸¬ã‚¿ã‚¹ã‚¯ãŒå®šç¾©ã•ã‚Œã¦ãŠã‚Šã€å„ã‚¿ã‚¹ã‚¯ã«ã¯è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã€æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã€ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãŒäº‹å‰ã«åˆ†å‰²ã•ã‚Œã¦ã„ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ç•°ãªã‚‹ç ”ç©¶é–“ã§ã®å…¬å¹³ãªæ€§èƒ½æ¯”è¼ƒãŒå¯èƒ½ã«ãªã‚Šã¾ã™ã€‚</p>

        <h3>4.1.1 Matbenchã®ä¸»è¦ã‚¿ã‚¹ã‚¯</h3>

        <table>
            <thead>
                <tr>
                    <th>ã‚¿ã‚¹ã‚¯å</th>
                    <th>ç‰©æ€§</th>
                    <th>ãƒ‡ãƒ¼ã‚¿æ•°</th>
                    <th>è©•ä¾¡æŒ‡æ¨™</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>matbench_mp_e_form</td>
                    <td>ç”Ÿæˆã‚¨ãƒãƒ«ã‚®ãƒ¼ (eV/atom)</td>
                    <td>132,752</td>
                    <td>MAE</td>
                </tr>
                <tr>
                    <td>matbench_mp_gap</td>
                    <td>ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ— (eV)</td>
                    <td>106,113</td>
                    <td>MAE</td>
                </tr>
                <tr>
                    <td>matbench_perovskites</td>
                    <td>ç”Ÿæˆã‚¨ãƒãƒ«ã‚®ãƒ¼ (eV/atom)</td>
                    <td>18,928</td>
                    <td>MAE</td>
                </tr>
                <tr>
                    <td>matbench_phonons</td>
                    <td>æœ€å¤§ãƒ•ã‚©ãƒãƒ³å‘¨æ³¢æ•° (cmâ»Â¹)</td>
                    <td>1,265</td>
                    <td>MAE</td>
                </tr>
                <tr>
                    <td>matbench_jdft2d</td>
                    <td>å‰¥é›¢ã‚¨ãƒãƒ«ã‚®ãƒ¼ (meV/atom)</td>
                    <td>636</td>
                    <td>MAE</td>
                </tr>
            </tbody>
        </table>

        <p>æœ¬ç« ã§ã¯ã€<strong>matbench_mp_e_formï¼ˆç”Ÿæˆã‚¨ãƒãƒ«ã‚®ãƒ¼äºˆæ¸¬ï¼‰</strong>ã¨<strong>matbench_mp_gapï¼ˆãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—äºˆæ¸¬ï¼‰</strong>ã®2ã¤ã®ã‚¿ã‚¹ã‚¯ã‚’å¯¾è±¡ã«ã€Random Forestï¼ˆMagpieç‰¹å¾´é‡ï¼‰ã¨CGCNNã®æ€§èƒ½ã‚’æ¯”è¼ƒã—ã¾ã™ã€‚</p>

        <h3>4.1.2 è©•ä¾¡ãƒ—ãƒ­ãƒˆã‚³ãƒ«</h3>

        <p>Matbenchã§ã¯ã€<strong>5-foldäº¤å·®æ¤œè¨¼</strong>ã«ã‚ˆã‚‹è©•ä¾¡ãŒæ¨™æº–ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã§ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå…¨ä½“ãŒ5ã¤ã®foldã«åˆ†å‰²ã•ã‚Œã¦ãŠã‚Šã€å„foldã«ã¤ã„ã¦ä»¥ä¸‹ã®è©•ä¾¡ã‚’å®Ÿæ–½ã—ã¾ã™ï¼š</p>

        <ol>
            <li><strong>è¨“ç·´ï¼ˆTrainingï¼‰</strong>ï¼šæ®‹ã‚Šã®4 foldã§ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´</li>
            <li><strong>æ¤œè¨¼ï¼ˆValidationï¼‰</strong>ï¼šãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«ä½¿ç”¨ï¼ˆä»»æ„ï¼‰</li>
            <li><strong>ãƒ†ã‚¹ãƒˆï¼ˆTestingï¼‰</strong>ï¼šè©²å½“foldã§æ€§èƒ½è©•ä¾¡ï¼ˆMAEã€RMSEã€RÂ²ã‚’è¨ˆç®—ï¼‰</li>
        </ol>

        <p>5ã¤ã®foldã®è©•ä¾¡æŒ‡æ¨™ã‚’å¹³å‡ã™ã‚‹ã“ã¨ã§ã€<strong>æ±åŒ–æ€§èƒ½ã®ä¿¡é ¼æ€§ã®é«˜ã„æ¨å®š</strong>ãŒå¾—ã‚‰ã‚Œã¾ã™ã€‚</p>

        <h2>4.2 Matbenchãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè£…</h2>

        <p>æœ¬ç¯€ã§ã¯ã€Random Forestï¼ˆMagpieï¼‰ã¨CGCNN on Matbench mp_e_formã‚¿ã‚¹ã‚¯ã‚’å®Ÿè£…ã—ã€äºˆæ¸¬ç²¾åº¦ã‚’å®šé‡çš„ã«æ¯”è¼ƒã—ã¾ã™ã€‚</p>

        <h3>4.2.1 ç’°å¢ƒæ§‹ç¯‰ã¨ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰</h3>

        <div class="highlight-box">
            <strong>ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹1ï¼šMatbenchãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ­ãƒ¼ãƒ‰</strong>
        </div>

        <pre><code class="language-python"># Matbenchãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ­ãƒ¼ãƒ‰ã¨å‰å‡¦ç†
import numpy as np
import pandas as pd
from matbench.bench import MatbenchBenchmark
from pymatgen.core import Structure
from matminer.featurizers.composition import ElementProperty
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import warnings
warnings.filterwarnings('ignore')

# Matbenchãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®åˆæœŸåŒ–
mb = MatbenchBenchmark(autoload=False)

# mp_e_formã‚¿ã‚¹ã‚¯ã‚’ãƒ­ãƒ¼ãƒ‰ï¼ˆç”Ÿæˆã‚¨ãƒãƒ«ã‚®ãƒ¼äºˆæ¸¬ï¼‰
task = mb.matbench_mp_e_form
task.load()

print(f"ã‚¿ã‚¹ã‚¯å: {task.metadata['task_type']}")
print(f"ãƒ‡ãƒ¼ã‚¿æ•°: {len(task.df)}")
print(f"å…¥åŠ›: {task.metadata['input_type']}")
print(f"å‡ºåŠ›: {task.metadata['target']}")

# ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®ç¢ºèª
print("\nãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒ«:")
print(task.df.head(3))

# å‡ºåŠ›ä¾‹ï¼š
# ã‚¿ã‚¹ã‚¯å: regression
# ãƒ‡ãƒ¼ã‚¿æ•°: 132752
# å…¥åŠ›: structure
# å‡ºåŠ›: e_form (eV/atom)
#
# ãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒ«:
#                                           structure  e_form
# 0  Structure: Fe2 O3 ...                    -2.54
# 1  Structure: Mn2 O3 ...                    -2.89
# 2  Structure: Co2 O3 ...                    -2.31
</code></pre>

        <h3>4.2.2 Random Forestï¼ˆMagpieç‰¹å¾´é‡ï¼‰ã®å®Ÿè£…</h3>

        <div class="highlight-box">
            <strong>ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹2ï¼šMagpieç‰¹å¾´é‡æŠ½å‡ºã¨Random Forestè¨“ç·´</strong>
        </div>

        <pre><code class="language-python"># Random Forest + Magpieç‰¹å¾´é‡ã®å®Ÿè£…
from matminer.featurizers.composition import ElementProperty

def extract_magpie_features(structures):
    """
    Pymatgenã®Structureã‹ã‚‰Magpieç‰¹å¾´é‡ã‚’æŠ½å‡º

    Parameters:
    -----------
    structures : list of Structure
        çµæ™¶æ§‹é€ ã®ãƒªã‚¹ãƒˆ

    Returns:
    --------
    features : np.ndarray, shape (n_samples, 145)
        Magpieç‰¹å¾´é‡ï¼ˆ145æ¬¡å…ƒï¼‰
    """
    # Magpieç‰¹å¾´é‡æŠ½å‡ºå™¨ã®åˆæœŸåŒ–
    featurizer = ElementProperty.from_preset("magpie")

    features = []
    for struct in structures:
        # Structureã‹ã‚‰Compositionã‚’å–å¾—
        comp = struct.composition
        # Magpieç‰¹å¾´é‡ã‚’è¨ˆç®—ï¼ˆ145æ¬¡å…ƒï¼‰
        feat = featurizer.featurize(comp)
        features.append(feat)

    return np.array(features)

# 5-foldäº¤å·®æ¤œè¨¼ã®è©•ä¾¡
rf_results = []

for fold_idx, fold in enumerate(task.folds):
    print(f"\n=== Fold {fold_idx + 1}/5 ===")

    # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    train_inputs, train_outputs = task.get_train_and_val_data(fold)
    test_inputs, test_outputs = task.get_test_data(fold, include_target=True)

    # Magpieç‰¹å¾´é‡æŠ½å‡º
    print("Magpieç‰¹å¾´é‡ã‚’æŠ½å‡ºä¸­...")
    X_train = extract_magpie_features(train_inputs)
    X_test = extract_magpie_features(test_inputs)
    y_train = train_outputs.values
    y_test = test_outputs.values

    print(f"è¨“ç·´ãƒ‡ãƒ¼ã‚¿: {X_train.shape}, ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {X_test.shape}")

    # Random Forestãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´
    print("Random Forestã‚’è¨“ç·´ä¸­...")
    rf_model = RandomForestRegressor(
        n_estimators=100,
        max_depth=30,
        min_samples_split=5,
        random_state=42,
        n_jobs=-1
    )
    rf_model.fit(X_train, y_train)

    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§äºˆæ¸¬
    y_pred = rf_model.predict(X_test)

    # è©•ä¾¡æŒ‡æ¨™ã‚’è¨ˆç®—
    mae = mean_absolute_error(y_test, y_pred)
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    r2 = r2_score(y_test, y_pred)

    print(f"MAE:  {mae:.4f} eV/atom")
    print(f"RMSE: {rmse:.4f} eV/atom")
    print(f"RÂ²:   {r2:.4f}")

    rf_results.append({
        'fold': fold_idx + 1,
        'mae': mae,
        'rmse': rmse,
        'r2': r2
    })

# 5-foldå¹³å‡ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—
rf_df = pd.DataFrame(rf_results)
print("\n=== Random Forest (Magpie) ç·åˆçµæœ ===")
print(f"MAE:  {rf_df['mae'].mean():.4f} Â± {rf_df['mae'].std():.4f} eV/atom")
print(f"RMSE: {rf_df['rmse'].mean():.4f} Â± {rf_df['rmse'].std():.4f} eV/atom")
print(f"RÂ²:   {rf_df['r2'].mean():.4f} Â± {rf_df['r2'].std():.4f}")

# å‡ºåŠ›ä¾‹ï¼š
# === Random Forest (Magpie) ç·åˆçµæœ ===
# MAE:  0.0325 Â± 0.0012 eV/atom
# RMSE: 0.0678 Â± 0.0019 eV/atom
# RÂ²:   0.9321 Â± 0.0045
</code></pre>

        <h3>4.2.3 CGCNNã®å®Ÿè£…</h3>

        <div class="highlight-box">
            <strong>ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹3ï¼šCGCNN on Matbenchè¨“ç·´</strong>
        </div>

        <pre><code class="language-python"># CGCNN on Matbenchã®å®Ÿè£…
import torch
import torch.nn as nn
from torch_geometric.data import Data, DataLoader
from torch_geometric.nn import CGConv, global_mean_pool
import time

# CGCNN for Matbenchã®å®šç¾©ï¼ˆChapter 2ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ï¼‰
class CGCNNMatbench(nn.Module):
    def __init__(self, atom_fea_len=92, nbr_fea_len=41, hidden_dim=128, n_conv=3):
        super(CGCNNMatbench, self).__init__()

        # Atom embedding
        self.atom_embedding = nn.Linear(atom_fea_len, hidden_dim)

        # Convolution layers
        self.conv_layers = nn.ModuleList([
            CGConv(hidden_dim, nbr_fea_len) for _ in range(n_conv)
        ])
        self.bn_layers = nn.ModuleList([
            nn.BatchNorm1d(hidden_dim) for _ in range(n_conv)
        ])

        # Readout
        self.fc1 = nn.Linear(hidden_dim, 64)
        self.fc2 = nn.Linear(64, 1)
        self.activation = nn.Softplus()

    def forward(self, data):
        x, edge_index, edge_attr, batch = data.x, data.edge_index, data.edge_attr, data.batch

        # Atom embedding
        x = self.atom_embedding(x)

        # Graph convolutions
        for conv, bn in zip(self.conv_layers, self.bn_layers):
            x = conv(x, edge_index, edge_attr)
            x = bn(x)
            x = self.activation(x)

        # Global pooling
        x = global_mean_pool(x, batch)

        # Fully connected layers
        x = self.fc1(x)
        x = self.activation(x)
        x = self.fc2(x)

        return x.squeeze()

def structure_to_pyg_data(structure, target, cutoff=8.0):
    """
    Pymatgenã®Structureã‚’PyTorch Geometricã®ãƒ‡ãƒ¼ã‚¿ã«å¤‰æ›

    Parameters:
    -----------
    structure : Structure
        çµæ™¶æ§‹é€ 
    target : float
        ç›®æ¨™å€¤ï¼ˆç”Ÿæˆã‚¨ãƒãƒ«ã‚®ãƒ¼ï¼‰
    cutoff : float
        ã‚«ãƒƒãƒˆã‚ªãƒ•åŠå¾„ (Ã…)

    Returns:
    --------
    data : Data
        PyTorch Geometricã®ãƒ‡ãƒ¼ã‚¿ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
    """
    # ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡ï¼ˆå…ƒç´ ã®one-hot encodingã€92æ¬¡å…ƒï¼‰
    atom_types = [site.specie.Z for site in structure]
    x = torch.zeros(len(atom_types), 92)
    for i, z in enumerate(atom_types):
        x[i, z - 1] = 1.0

    # ã‚¨ãƒƒã‚¸æ§‹ç¯‰ï¼ˆcutoffåŠå¾„ä»¥å†…ã®åŸå­ãƒšã‚¢ï¼‰
    neighbors = structure.get_all_neighbors(cutoff)
    edge_index = []
    edge_attr = []

    for i, neighbors_i in enumerate(neighbors):
        for neighbor in neighbors_i:
            j = neighbor.index
            distance = neighbor.nn_distance

            # Gaussian distance expansion (41æ¬¡å…ƒ)
            distances = torch.linspace(0, cutoff, 41)
            sigma = 0.5
            edge_feature = torch.exp(-((distance - distances) ** 2) / (2 * sigma ** 2))

            edge_index.append([i, j])
            edge_attr.append(edge_feature)

    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()
    edge_attr = torch.stack(edge_attr)
    y = torch.tensor([target], dtype=torch.float)

    return Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)

# 5-foldäº¤å·®æ¤œè¨¼ã®è©•ä¾¡
cgcnn_results = []

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹: {device}")

for fold_idx, fold in enumerate(task.folds):
    print(f"\n=== Fold {fold_idx + 1}/5 ===")

    # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    train_inputs, train_outputs = task.get_train_and_val_data(fold)
    test_inputs, test_outputs = task.get_test_data(fold, include_target=True)

    # PyTorch Geometricãƒ‡ãƒ¼ã‚¿ã«å¤‰æ›
    print("ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ã‚’æ§‹ç¯‰ä¸­...")
    train_data = [structure_to_pyg_data(s, t) for s, t in zip(train_inputs, train_outputs.values)]
    test_data = [structure_to_pyg_data(s, t) for s, t in zip(test_inputs, test_outputs.values)]

    train_loader = DataLoader(train_data, batch_size=32, shuffle=True)
    test_loader = DataLoader(test_data, batch_size=32, shuffle=False)

    # CGCNNãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–
    model = CGCNNMatbench().to(device)
    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
    criterion = nn.L1Loss()  # MAEæå¤±

    # è¨“ç·´
    print("CGCNNã‚’è¨“ç·´ä¸­...")
    model.train()
    for epoch in range(50):  # å®Ÿéš›ã«ã¯early stoppingã‚’ä½¿ç”¨ã™ã¹ã
        total_loss = 0
        for batch in train_loader:
            batch = batch.to(device)
            optimizer.zero_grad()
            out = model(batch)
            loss = criterion(out, batch.y)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()

        if (epoch + 1) % 10 == 0:
            print(f"Epoch {epoch+1}/50, Loss: {total_loss/len(train_loader):.4f}")

    # ãƒ†ã‚¹ãƒˆ
    model.eval()
    y_true = []
    y_pred = []

    with torch.no_grad():
        for batch in test_loader:
            batch = batch.to(device)
            out = model(batch)
            y_true.extend(batch.y.cpu().numpy())
            y_pred.extend(out.cpu().numpy())

    y_true = np.array(y_true)
    y_pred = np.array(y_pred)

    # è©•ä¾¡æŒ‡æ¨™ã‚’è¨ˆç®—
    mae = mean_absolute_error(y_true, y_pred)
    rmse = np.sqrt(mean_squared_error(y_true, y_pred))
    r2 = r2_score(y_true, y_pred)

    print(f"MAE:  {mae:.4f} eV/atom")
    print(f"RMSE: {rmse:.4f} eV/atom")
    print(f"RÂ²:   {r2:.4f}")

    cgcnn_results.append({
        'fold': fold_idx + 1,
        'mae': mae,
        'rmse': rmse,
        'r2': r2
    })

# 5-foldå¹³å‡ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—
cgcnn_df = pd.DataFrame(cgcnn_results)
print("\n=== CGCNN ç·åˆçµæœ ===")
print(f"MAE:  {cgcnn_df['mae'].mean():.4f} Â± {cgcnn_df['mae'].std():.4f} eV/atom")
print(f"RMSE: {cgcnn_df['rmse'].mean():.4f} Â± {cgcnn_df['rmse'].std():.4f} eV/atom")
print(f"RÂ²:   {cgcnn_df['r2'].mean():.4f} Â± {cgcnn_df['r2'].std():.4f}")

# å‡ºåŠ›ä¾‹ï¼š
# === CGCNN ç·åˆçµæœ ===
# MAE:  0.0286 Â± 0.0009 eV/atom
# RMSE: 0.0592 Â± 0.0014 eV/atom
# RÂ²:   0.9524 Â± 0.0032
</code></pre>

        <h3>4.2.4 äºˆæ¸¬ç²¾åº¦ã®å®šé‡çš„æ¯”è¼ƒ</h3>

        <p>5-foldäº¤å·®æ¤œè¨¼ã®çµæœã‚’çµ±åˆã—ã€Random Forestï¼ˆMagpieï¼‰ã¨CGCNNã®äºˆæ¸¬ç²¾åº¦ã‚’æ¯”è¼ƒã—ã¾ã™ã€‚</p>

        <div class="highlight-box">
            <strong>ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹4ï¼šäºˆæ¸¬ç²¾åº¦æ¯”è¼ƒã®å¯è¦–åŒ–</strong>
        </div>

        <pre><code class="language-python"># äºˆæ¸¬ç²¾åº¦æ¯”è¼ƒã®å¯è¦–åŒ–
import matplotlib.pyplot as plt
import seaborn as sns

# çµæœã‚’çµ±åˆ
comparison_df = pd.DataFrame({
    'Model': ['RF (Magpie)'] * 5 + ['CGCNN'] * 5,
    'Fold': list(range(1, 6)) * 2,
    'MAE': list(rf_df['mae']) + list(cgcnn_df['mae']),
    'RMSE': list(rf_df['rmse']) + list(cgcnn_df['rmse']),
    'RÂ²': list(rf_df['r2']) + list(cgcnn_df['r2'])
})

# å¯è¦–åŒ–
fig, axes = plt.subplots(1, 3, figsize=(15, 5))

# MAEæ¯”è¼ƒ
sns.barplot(data=comparison_df, x='Model', y='MAE', ax=axes[0], palette=['#667eea', '#764ba2'])
axes[0].set_title('MAE Comparison (Lower is Better)', fontsize=14, fontweight='bold')
axes[0].set_ylabel('MAE (eV/atom)', fontsize=12)
axes[0].axhline(0.03, color='red', linestyle='--', linewidth=1, label='Target: 0.03')
axes[0].legend()

# RMSEæ¯”è¼ƒ
sns.barplot(data=comparison_df, x='Model', y='RMSE', ax=axes[1], palette=['#667eea', '#764ba2'])
axes[1].set_title('RMSE Comparison (Lower is Better)', fontsize=14, fontweight='bold')
axes[1].set_ylabel('RMSE (eV/atom)', fontsize=12)

# RÂ²æ¯”è¼ƒ
sns.barplot(data=comparison_df, x='Model', y='RÂ²', ax=axes[2], palette=['#667eea', '#764ba2'])
axes[2].set_title('RÂ² Comparison (Higher is Better)', fontsize=14, fontweight='bold')
axes[2].set_ylabel('RÂ²', fontsize=12)
axes[2].axhline(0.95, color='red', linestyle='--', linewidth=1, label='Target: 0.95')
axes[2].legend()

plt.tight_layout()
plt.savefig('accuracy_comparison.png', dpi=300, bbox_inches='tight')
plt.show()

# çµ±è¨ˆã‚µãƒãƒªãƒ¼
print("=== äºˆæ¸¬ç²¾åº¦ã®çµ±è¨ˆã‚µãƒãƒªãƒ¼ ===")
print(comparison_df.groupby('Model').agg({
    'MAE': ['mean', 'std'],
    'RMSE': ['mean', 'std'],
    'RÂ²': ['mean', 'std']
}).round(4))

# ç›¸å¯¾çš„ãªæ”¹å–„ç‡ã‚’è¨ˆç®—
mae_improvement = (rf_df['mae'].mean() - cgcnn_df['mae'].mean()) / rf_df['mae'].mean() * 100
rmse_improvement = (rf_df['rmse'].mean() - cgcnn_df['rmse'].mean()) / rf_df['rmse'].mean() * 100
r2_improvement = (cgcnn_df['r2'].mean() - rf_df['r2'].mean()) / rf_df['r2'].mean() * 100

print(f"\n=== CGCNNã®ç›¸å¯¾çš„æ”¹å–„ç‡ ===")
print(f"MAEæ”¹å–„:  {mae_improvement:.2f}%")
print(f"RMSEæ”¹å–„: {rmse_improvement:.2f}%")
print(f"RÂ²æ”¹å–„:   {r2_improvement:.2f}%")

# å‡ºåŠ›ä¾‹ï¼š
# === CGCNNã®ç›¸å¯¾çš„æ”¹å–„ç‡ ===
# MAEæ”¹å–„:  12.00%
# RMSEæ”¹å–„: 12.68%
# RÂ²æ”¹å–„:   2.18%
</code></pre>

        <p><strong>çµæœã®è§£é‡ˆï¼š</strong></p>
        <ul>
            <li><strong>MAEæ”¹å–„ï¼š12.00%</strong> - CGCNNã¯ç”Ÿæˆã‚¨ãƒãƒ«ã‚®ãƒ¼äºˆæ¸¬ã«ãŠã„ã¦ã€Magpie+RFã‚ˆã‚Šã‚‚ç´„12%ä½ã„èª¤å·®ã‚’é”æˆ</li>
            <li><strong>RÂ²æ”¹å–„ï¼š2.18%</strong> - æ—¢ã«RFãŒé«˜ã„RÂ²ï¼ˆ0.932ï¼‰ã‚’é”æˆã—ã¦ã„ã‚‹ãŸã‚ã€ç›¸å¯¾çš„æ”¹å–„ç‡ã¯å°ã•ã„ãŒã€CGCNNã¯0.952ã¨ã„ã†æ¥µã‚ã¦é«˜ã„æ±ºå®šä¿‚æ•°ã‚’å®Ÿç¾</li>
            <li><strong>çµ±è¨ˆçš„æœ‰æ„æ€§ã®æ¤œè¨¼ãŒå¿…è¦</strong> - æ¬¡ç¯€ã§ã€ã“ã®ç²¾åº¦å·®ãŒçµ±è¨ˆçš„ã«æœ‰æ„ã‹ã‚’æ¤œå®šã—ã¾ã™</li>
        </ul>

        <div class="warning-box">
            <strong>âš ï¸ é‡è¦ãªæ³¨æ„ç‚¹</strong>
            <p>æœ¬ã‚³ãƒ¼ãƒ‰ä¾‹ã§ã¯è¨ˆç®—æ™‚é–“ã®éƒ½åˆä¸Šã€CGCNNã®ã‚¨ãƒãƒƒã‚¯æ•°ã‚’50ã«åˆ¶é™ã—ã¦ã„ã¾ã™ãŒã€å®Ÿéš›ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã¯<strong>early stoppingã¨ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–</strong>ã‚’å®Ÿæ–½ã™ã¹ãã§ã™ã€‚ã¾ãŸã€GPUç’°å¢ƒã§ã®å®Ÿè¡Œã‚’å¼·ãæ¨å¥¨ã—ã¾ã™ï¼ˆè¨“ç·´æ™‚é–“ãŒ10-20å€é«˜é€ŸåŒ–ï¼‰ã€‚</p>
        </div>

        <h2>4.3 çµ±è¨ˆçš„æœ‰æ„æ€§æ¤œå®š</h2>

        <p>å‰ç¯€ã§ã¯ã€CGCNNãŒRandom Forestï¼ˆMagpieï¼‰ã‚ˆã‚Šã‚‚ç´„12%ä½ã„MAEã‚’é”æˆã™ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¾ã—ãŸã€‚ã—ã‹ã—ã€ã“ã®ç²¾åº¦å·®ãŒ<strong>çµ±è¨ˆçš„ã«æœ‰æ„</strong>ã‹ã©ã†ã‹ã‚’æ¤œè¨¼ã—ãªã‘ã‚Œã°ã€å˜ãªã‚‹å¶ç„¶ã®å¯èƒ½æ€§ã‚’æ’é™¤ã§ãã¾ã›ã‚“ã€‚æœ¬ç¯€ã§ã¯ã€<strong>å¯¾å¿œã®ã‚ã‚‹tæ¤œå®šï¼ˆpaired t-testï¼‰</strong>ã¨<strong>95%ä¿¡é ¼åŒºé–“</strong>ã‚’ç”¨ã„ã¦çµ±è¨ˆçš„æœ‰æ„æ€§ã‚’è©•ä¾¡ã—ã¾ã™ã€‚</p>

        <h3>4.3.1 å¯¾å¿œã®ã‚ã‚‹tæ¤œå®šã®åŸç†</h3>

        <p>5-foldäº¤å·®æ¤œè¨¼ã§ã¯ã€åŒã˜ãƒ‡ãƒ¼ã‚¿åˆ†å‰²ã«å¯¾ã—ã¦RFã¨CGCNNã®ä¸¡æ–¹ã‚’è©•ä¾¡ã—ã¦ã„ã¾ã™ã€‚ã—ãŸãŒã£ã¦ã€å„foldã®MAEå·®ã¯<strong>å¯¾å¿œã®ã‚ã‚‹ãƒ‡ãƒ¼ã‚¿ï¼ˆpaired dataï¼‰</strong>ã¨ã—ã¦æ‰±ã†ã“ã¨ãŒã§ãã¾ã™ã€‚å¯¾å¿œã®ã‚ã‚‹tæ¤œå®šã¯ã€ä»¥ä¸‹ã®å¸°ç„¡ä»®èª¬ã‚’æ¤œå®šã—ã¾ã™ï¼š</p>

        <p>$$H_0: \mu_{\text{diff}} = 0 \quad \text{ï¼ˆRFã¨CGCNNã®å¹³å‡MAEå·®ã¯ã‚¼ãƒ­ï¼‰}$$</p>

        <p>$$H_1: \mu_{\text{diff}} \neq 0 \quad \text{ï¼ˆå¹³å‡MAEå·®ã¯ã‚¼ãƒ­ã§ã¯ãªã„ï¼‰}$$</p>

        <p>æ¤œå®šçµ±è¨ˆé‡tã¯ä»¥ä¸‹ã®ã‚ˆã†ã«è¨ˆç®—ã•ã‚Œã¾ã™ï¼š</p>

        <p>$$t = \frac{\bar{d}}{s_d / \sqrt{n}}$$</p>

        <p>ã“ã“ã§ã€$\bar{d}$ã¯å·®ã®å¹³å‡ã€$s_d$ã¯å·®ã®æ¨™æº–åå·®ã€$n$ã¯ã‚µãƒ³ãƒ—ãƒ«æ•°ï¼ˆfoldæ•°=5ï¼‰ã§ã™ã€‚</p>

        <h3>4.3.2 tæ¤œå®šã®å®Ÿè£…</h3>

        <div class="highlight-box">
            <strong>ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹5ï¼šå¯¾å¿œã®ã‚ã‚‹tæ¤œå®šã®å®Ÿè£…</strong>
        </div>

        <pre><code class="language-python"># å¯¾å¿œã®ã‚ã‚‹tæ¤œå®šã®å®Ÿè£…
from scipy import stats
import numpy as np

# Random Forestã¨CGCNNã®MAEï¼ˆ5 foldã®çµæœï¼‰
rf_mae = np.array([0.0325, 0.0338, 0.0312, 0.0329, 0.0321])  # ä¾‹ç¤ºãƒ‡ãƒ¼ã‚¿
cgcnn_mae = np.array([0.0286, 0.0293, 0.0279, 0.0288, 0.0284])  # ä¾‹ç¤ºãƒ‡ãƒ¼ã‚¿

# MAEã®å·®ã‚’è¨ˆç®—
mae_diff = rf_mae - cgcnn_mae

print("=== å¯¾å¿œã®ã‚ã‚‹tæ¤œå®š ===")
print(f"RF MAE:     {rf_mae}")
print(f"CGCNN MAE:  {cgcnn_mae}")
print(f"MAEå·®:      {mae_diff}")
print(f"å¹³å‡å·®:     {mae_diff.mean():.4f} eV/atom")
print(f"æ¨™æº–åå·®:   {mae_diff.std(ddof=1):.4f} eV/atom")

# å¯¾å¿œã®ã‚ã‚‹tæ¤œå®šã‚’å®Ÿæ–½
t_statistic, p_value = stats.ttest_rel(rf_mae, cgcnn_mae)

print(f"\ntçµ±è¨ˆé‡:    {t_statistic:.4f}")
print(f"på€¤:        {p_value:.4f}")

# æœ‰æ„æ°´æº–Î±=0.05ã§åˆ¤å®š
alpha = 0.05
if p_value < alpha:
    print(f"\nåˆ¤å®š: på€¤ ({p_value:.4f}) < Î± ({alpha}) â†’ å¸°ç„¡ä»®èª¬ã‚’æ£„å´")
    print("çµè«–: CGCNNã¨RFã®ç²¾åº¦å·®ã¯çµ±è¨ˆçš„ã«æœ‰æ„ã§ã™ã€‚")
else:
    print(f"\nåˆ¤å®š: på€¤ ({p_value:.4f}) â‰¥ Î± ({alpha}) â†’ å¸°ç„¡ä»®èª¬ã‚’æ£„å´ã§ãã¾ã›ã‚“")
    print("çµè«–: CGCNNã¨RFã®ç²¾åº¦å·®ã¯çµ±è¨ˆçš„ã«æœ‰æ„ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")

# åŠ¹æœé‡ï¼ˆCohen's dï¼‰ã‚’è¨ˆç®—
cohens_d = mae_diff.mean() / mae_diff.std(ddof=1)
print(f"\nåŠ¹æœé‡ï¼ˆCohen's dï¼‰: {cohens_d:.4f}")
if abs(cohens_d) < 0.2:
    print("åŠ¹æœé‡ã®å¤§ãã•: å°ã•ã„")
elif abs(cohens_d) < 0.5:
    print("åŠ¹æœé‡ã®å¤§ãã•: ä¸­ç¨‹åº¦")
elif abs(cohens_d) < 0.8:
    print("åŠ¹æœé‡ã®å¤§ãã•: å¤§ãã„")
else:
    print("åŠ¹æœé‡ã®å¤§ãã•: éå¸¸ã«å¤§ãã„")

# å‡ºåŠ›ä¾‹ï¼š
# === å¯¾å¿œã®ã‚ã‚‹tæ¤œå®š ===
# RF MAE:     [0.0325 0.0338 0.0312 0.0329 0.0321]
# CGCNN MAE:  [0.0286 0.0293 0.0279 0.0288 0.0284]
# MAEå·®:      [0.0039 0.0045 0.0033 0.0041 0.0037]
# å¹³å‡å·®:     0.0039 eV/atom
# æ¨™æº–åå·®:   0.0004 eV/atom
#
# tçµ±è¨ˆé‡:    20.5891
# på€¤:        0.0001
#
# åˆ¤å®š: på€¤ (0.0001) < Î± (0.05) â†’ å¸°ç„¡ä»®èª¬ã‚’æ£„å´
# çµè«–: CGCNNã¨RFã®ç²¾åº¦å·®ã¯çµ±è¨ˆçš„ã«æœ‰æ„ã§ã™ã€‚
#
# åŠ¹æœé‡ï¼ˆCohen's dï¼‰: 9.1894
# åŠ¹æœé‡ã®å¤§ãã•: éå¸¸ã«å¤§ãã„
</code></pre>

        <h3>4.3.3 95%ä¿¡é ¼åŒºé–“ã®è¨ˆç®—</h3>

        <p>95%ä¿¡é ¼åŒºé–“ã¯ã€<strong>çœŸã®å¹³å‡å·®ãŒ95%ã®ç¢ºç‡ã§å«ã¾ã‚Œã‚‹ç¯„å›²</strong>ã‚’ç¤ºã—ã¾ã™ã€‚ä¿¡é ¼åŒºé–“ãŒ0ã‚’å«ã¾ãªã„å ´åˆã€çµ±è¨ˆçš„ã«æœ‰æ„ãªå·®ãŒã‚ã‚‹ã¨çµè«–ã§ãã¾ã™ã€‚</p>

        <div class="highlight-box">
            <strong>ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹6ï¼š95%ä¿¡é ¼åŒºé–“ã®è¨ˆç®—ã¨å¯è¦–åŒ–</strong>
        </div>

        <pre><code class="language-python"># 95%ä¿¡é ¼åŒºé–“ã®è¨ˆç®—ã¨å¯è¦–åŒ–
from scipy import stats
import matplotlib.pyplot as plt

# 95%ä¿¡é ¼åŒºé–“ã‚’è¨ˆç®—
confidence_level = 0.95
degrees_freedom = len(mae_diff) - 1
t_critical = stats.t.ppf((1 + confidence_level) / 2, degrees_freedom)

mean_diff = mae_diff.mean()
se_diff = mae_diff.std(ddof=1) / np.sqrt(len(mae_diff))
margin_error = t_critical * se_diff

ci_lower = mean_diff - margin_error
ci_upper = mean_diff + margin_error

print("=== 95%ä¿¡é ¼åŒºé–“ ===")
print(f"å¹³å‡å·®:          {mean_diff:.4f} eV/atom")
print(f"æ¨™æº–èª¤å·®:        {se_diff:.4f} eV/atom")
print(f"tè‡¨ç•Œå€¤ (df={degrees_freedom}): {t_critical:.4f}")
print(f"èª¤å·®ç¯„å›²:        Â±{margin_error:.4f} eV/atom")
print(f"95%ä¿¡é ¼åŒºé–“:     [{ci_lower:.4f}, {ci_upper:.4f}] eV/atom")

if ci_lower > 0:
    print("\nåˆ¤å®š: ä¿¡é ¼åŒºé–“ãŒ0ã‚’å«ã¾ãªã„ â†’ çµ±è¨ˆçš„ã«æœ‰æ„ãªå·®ã‚ã‚Š")
else:
    print("\nåˆ¤å®š: ä¿¡é ¼åŒºé–“ãŒ0ã‚’å«ã‚€ â†’ çµ±è¨ˆçš„ã«æœ‰æ„ãªå·®ãªã—")

# å¯è¦–åŒ–
fig, ax = plt.subplots(figsize=(10, 6))

# å„foldã®MAEå·®ã‚’ãƒ—ãƒ­ãƒƒãƒˆ
ax.scatter(range(1, 6), mae_diff, s=100, color='#764ba2', zorder=3, label='å„foldã®MAEå·®')

# å¹³å‡ç·š
ax.axhline(mean_diff, color='#667eea', linestyle='--', linewidth=2, label=f'å¹³å‡å·®: {mean_diff:.4f}')

# 95%ä¿¡é ¼åŒºé–“
ax.axhspan(ci_lower, ci_upper, alpha=0.2, color='#667eea', label=f'95%ä¿¡é ¼åŒºé–“: [{ci_lower:.4f}, {ci_upper:.4f}]')

# ã‚¼ãƒ­ãƒ©ã‚¤ãƒ³
ax.axhline(0, color='red', linestyle='-', linewidth=1, label='å·®ãªã—ï¼ˆHâ‚€ï¼‰')

ax.set_xlabel('Foldç•ªå·', fontsize=12)
ax.set_ylabel('MAEå·® (RF - CGCNN) [eV/atom]', fontsize=12)
ax.set_title('5-foldäº¤å·®æ¤œè¨¼ã«ãŠã‘ã‚‹MAEå·®ã¨95%ä¿¡é ¼åŒºé–“', fontsize=14, fontweight='bold')
ax.set_xticks(range(1, 6))
ax.legend(fontsize=10)
ax.grid(alpha=0.3)

plt.tight_layout()
plt.savefig('statistical_significance.png', dpi=300, bbox_inches='tight')
plt.show()

# å‡ºåŠ›ä¾‹ï¼š
# === 95%ä¿¡é ¼åŒºé–“ ===
# å¹³å‡å·®:          0.0039 eV/atom
# æ¨™æº–èª¤å·®:        0.0002 eV/atom
# tè‡¨ç•Œå€¤ (df=4): 2.7764
# èª¤å·®ç¯„å›²:        Â±0.0005 eV/atom
# 95%ä¿¡é ¼åŒºé–“:     [0.0034, 0.0044] eV/atom
#
# åˆ¤å®š: ä¿¡é ¼åŒºé–“ãŒ0ã‚’å«ã¾ãªã„ â†’ çµ±è¨ˆçš„ã«æœ‰æ„ãªå·®ã‚ã‚Š
</code></pre>

        <h3>4.3.4 çµ±è¨ˆçš„æ¤œå®šçµæœã®ã¾ã¨ã‚</h3>

        <table>
            <thead>
                <tr>
                    <th>æ¤œå®šæ‰‹æ³•</th>
                    <th>çµæœ</th>
                    <th>è§£é‡ˆ</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>å¯¾å¿œã®ã‚ã‚‹tæ¤œå®š</td>
                    <td>t=20.59, p=0.0001</td>
                    <td>p < 0.05 â†’ çµ±è¨ˆçš„ã«æœ‰æ„</td>
                </tr>
                <tr>
                    <td>95%ä¿¡é ¼åŒºé–“</td>
                    <td>[0.0034, 0.0044] eV/atom</td>
                    <td>0ã‚’å«ã¾ãªã„ â†’ çµ±è¨ˆçš„ã«æœ‰æ„</td>
                </tr>
                <tr>
                    <td>åŠ¹æœé‡ï¼ˆCohen's dï¼‰</td>
                    <td>9.19</td>
                    <td>éå¸¸ã«å¤§ãã„åŠ¹æœé‡</td>
                </tr>
                <tr>
                    <td>ç›¸å¯¾çš„æ”¹å–„ç‡</td>
                    <td>12.00%</td>
                    <td>å®Ÿç”¨ä¸Šã®æ„ç¾©ã‚ã‚Š</td>
                </tr>
            </tbody>
        </table>

        <p><strong>çµè«–ï¼š</strong></p>
        <ul>
            <li>CGCNNã¯Random Forestï¼ˆMagpieï¼‰ã«å¯¾ã—ã¦<strong>çµ±è¨ˆçš„ã«æœ‰æ„ãªç²¾åº¦å‘ä¸Š</strong>ã‚’ç¤ºã—ã¾ã—ãŸï¼ˆp=0.0001 << 0.05ï¼‰</li>
            <li>95%ä¿¡é ¼åŒºé–“ [0.0034, 0.0044] eV/atomã¯0ã‚’å«ã¾ãªã„ãŸã‚ã€ç²¾åº¦å·®ã®å­˜åœ¨ã¯çµ±è¨ˆçš„ã«æ”¯æŒã•ã‚Œã¾ã™</li>
            <li>Cohen's d = 9.19ã¨ã„ã†æ¥µã‚ã¦å¤§ãã„åŠ¹æœé‡ã¯ã€CGCNNã®å®Ÿç”¨ä¸Šã®å„ªä½æ€§ã‚’ç¤ºã—ã¦ã„ã¾ã™</li>
            <li>12%ã®ç›¸å¯¾çš„æ”¹å–„ç‡ã¯ã€ææ–™æ¢ç´¢ã®åŠ¹ç‡åŒ–ã«ç›´çµã™ã‚‹å®Ÿå‹™çš„ãªãƒ¡ãƒªãƒƒãƒˆãŒã‚ã‚Šã¾ã™</li>
        </ul>

        <div class="warning-box">
            <strong>âš ï¸ çµ±è¨ˆçš„æœ‰æ„æ€§ vs å®Ÿç”¨çš„æœ‰æ„æ€§</strong>
            <p>çµ±è¨ˆçš„ã«æœ‰æ„ãªå·®ãŒèªã‚ã‚‰ã‚Œã¦ã‚‚ã€ãã®å·®ãŒ<strong>å®Ÿç”¨ä¸Šæ„å‘³ãŒã‚ã‚‹ã‹</strong>ã¯åˆ¥é€”æ¤œè¨ãŒå¿…è¦ã§ã™ã€‚æœ¬ã‚±ãƒ¼ã‚¹ã§ã¯ã€MAEå·®0.0039 eV/atomã¯ææ–™æ¢ç´¢ã«ãŠã„ã¦ååˆ†å®Ÿç”¨çš„ãªæ”¹å–„ã¨åˆ¤æ–­ã§ãã¾ã™ï¼ˆç”Ÿæˆã‚¨ãƒãƒ«ã‚®ãƒ¼äºˆæ¸¬ç²¾åº¦ãŒç´„1 meV/atomå‘ä¸Šï¼‰ã€‚</p>
        </div>

        <h2>4.4 è¨ˆç®—ã‚³ã‚¹ãƒˆã®å®šé‡çš„æ¯”è¼ƒ</h2>

        <p>ç²¾åº¦ã ã‘ã§ãªãã€<strong>è¨ˆç®—ã‚³ã‚¹ãƒˆï¼ˆè¨“ç·´æ™‚é–“ã€æ¨è«–æ™‚é–“ã€ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ï¼‰</strong>ã‚‚ãƒ¢ãƒ‡ãƒ«é¸æŠã®é‡è¦ãªè¦ç´ ã§ã™ã€‚æœ¬ç¯€ã§ã¯ã€Random Forestã¨CGCNNã®è¨ˆç®—ã‚³ã‚¹ãƒˆã‚’å®Ÿæ¸¬ã—ã€å®šé‡çš„ã«æ¯”è¼ƒã—ã¾ã™ã€‚</p>

        <h3>4.4.1 è¨“ç·´æ™‚é–“ã®æ¸¬å®š</h3>

        <div class="highlight-box">
            <strong>ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹7ï¼šè¨“ç·´æ™‚é–“ã¨æ¨è«–æ™‚é–“ã®æ¸¬å®š</strong>
        </div>

        <pre><code class="language-python"># è¨“ç·´æ™‚é–“ã¨æ¨è«–æ™‚é–“ã®æ¸¬å®š
import time
import psutil
import os

def measure_training_time_and_memory(model_type='rf'):
    """
    ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´æ™‚é–“ã¨ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’æ¸¬å®š

    Parameters:
    -----------
    model_type : str
        'rf' (Random Forest) or 'cgcnn'

    Returns:
    --------
    results : dict
        è¨“ç·´æ™‚é–“ã€æ¨è«–æ™‚é–“ã€ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡
    """
    # ãƒ—ãƒ­ã‚»ã‚¹ã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’å–å¾—
    process = psutil.Process(os.getpid())
    mem_before = process.memory_info().rss / (1024 ** 2)  # MB

    # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ï¼ˆFold 1ã®ã¿ä½¿ç”¨ï¼‰
    train_inputs, train_outputs = task.get_train_and_val_data(task.folds[0])
    test_inputs, test_outputs = task.get_test_data(task.folds[0], include_target=True)

    if model_type == 'rf':
        # Random Forestã®è¨“ç·´æ™‚é–“æ¸¬å®š
        X_train = extract_magpie_features(train_inputs)
        X_test = extract_magpie_features(test_inputs)
        y_train = train_outputs.values

        # è¨“ç·´é–‹å§‹
        start_train = time.time()
        rf_model = RandomForestRegressor(
            n_estimators=100,
            max_depth=30,
            random_state=42,
            n_jobs=-1
        )
        rf_model.fit(X_train, y_train)
        train_time = time.time() - start_train

        # æ¨è«–æ™‚é–“æ¸¬å®š
        start_infer = time.time()
        _ = rf_model.predict(X_test)
        infer_time = time.time() - start_infer

        mem_after = process.memory_info().rss / (1024 ** 2)
        memory_usage = mem_after - mem_before

    elif model_type == 'cgcnn':
        # CGCNNã®è¨“ç·´æ™‚é–“æ¸¬å®š
        train_data = [structure_to_pyg_data(s, t) for s, t in zip(train_inputs, train_outputs.values)]
        test_data = [structure_to_pyg_data(s, t) for s, t in zip(test_inputs, test_outputs.values)]

        train_loader = DataLoader(train_data, batch_size=32, shuffle=True)
        test_loader = DataLoader(test_data, batch_size=32, shuffle=False)

        model = CGCNNMatbench().to(device)
        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
        criterion = nn.L1Loss()

        # è¨“ç·´é–‹å§‹
        start_train = time.time()
        model.train()
        for epoch in range(50):
            for batch in train_loader:
                batch = batch.to(device)
                optimizer.zero_grad()
                out = model(batch)
                loss = criterion(out, batch.y)
                loss.backward()
                optimizer.step()
        train_time = time.time() - start_train

        # æ¨è«–æ™‚é–“æ¸¬å®š
        model.eval()
        start_infer = time.time()
        with torch.no_grad():
            for batch in test_loader:
                batch = batch.to(device)
                _ = model(batch)
        infer_time = time.time() - start_infer

        mem_after = process.memory_info().rss / (1024 ** 2)
        memory_usage = mem_after - mem_before

    return {
        'train_time': train_time,
        'infer_time': infer_time,
        'memory_usage': memory_usage
    }

# Random Forestã®è¨ˆç®—ã‚³ã‚¹ãƒˆæ¸¬å®š
print("=== Random Forestè¨ˆç®—ã‚³ã‚¹ãƒˆæ¸¬å®šä¸­... ===")
rf_cost = measure_training_time_and_memory('rf')

print(f"è¨“ç·´æ™‚é–“:   {rf_cost['train_time']:.2f} ç§’")
print(f"æ¨è«–æ™‚é–“:   {rf_cost['infer_time']:.2f} ç§’")
print(f"ãƒ¡ãƒ¢ãƒªä½¿ç”¨: {rf_cost['memory_usage']:.2f} MB")

# CGCNNã®è¨ˆç®—ã‚³ã‚¹ãƒˆæ¸¬å®šï¼ˆGPUä½¿ç”¨æ™‚ï¼‰
print("\n=== CGCNNè¨ˆç®—ã‚³ã‚¹ãƒˆæ¸¬å®šä¸­... ===")
cgcnn_cost = measure_training_time_and_memory('cgcnn')

print(f"è¨“ç·´æ™‚é–“:   {cgcnn_cost['train_time']:.2f} ç§’")
print(f"æ¨è«–æ™‚é–“:   {cgcnn_cost['infer_time']:.2f} ç§’")
print(f"ãƒ¡ãƒ¢ãƒªä½¿ç”¨: {cgcnn_cost['memory_usage']:.2f} MB")

# æ¯”è¼ƒ
print("\n=== è¨ˆç®—ã‚³ã‚¹ãƒˆæ¯”è¼ƒ ===")
print(f"è¨“ç·´æ™‚é–“æ¯” (CGCNN/RF): {cgcnn_cost['train_time'] / rf_cost['train_time']:.2f}x")
print(f"æ¨è«–æ™‚é–“æ¯” (CGCNN/RF): {cgcnn_cost['infer_time'] / rf_cost['infer_time']:.2f}x")
print(f"ãƒ¡ãƒ¢ãƒªæ¯” (CGCNN/RF):   {cgcnn_cost['memory_usage'] / rf_cost['memory_usage']:.2f}x")

# å‡ºåŠ›ä¾‹ï¼š
# === Random Forestè¨ˆç®—ã‚³ã‚¹ãƒˆæ¸¬å®šä¸­... ===
# è¨“ç·´æ™‚é–“:   45.32 ç§’
# æ¨è«–æ™‚é–“:   0.18 ç§’
# ãƒ¡ãƒ¢ãƒªä½¿ç”¨: 1250.45 MB
#
# === CGCNNè¨ˆç®—ã‚³ã‚¹ãƒˆæ¸¬å®šä¸­... ===
# è¨“ç·´æ™‚é–“:   1832.56 ç§’
# æ¨è«–æ™‚é–“:   2.34 ç§’
# ãƒ¡ãƒ¢ãƒªä½¿ç”¨: 3450.23 MB
#
# === è¨ˆç®—ã‚³ã‚¹ãƒˆæ¯”è¼ƒ ===
# è¨“ç·´æ™‚é–“æ¯” (CGCNN/RF): 40.45x
# æ¨è«–æ™‚é–“æ¯” (CGCNN/RF): 13.00x
# ãƒ¡ãƒ¢ãƒªæ¯” (CGCNN/RF):   2.76x
</code></pre>

        <h3>4.4.2 è¨ˆç®—ã‚³ã‚¹ãƒˆã®å¯è¦–åŒ–</h3>

        <div class="highlight-box">
            <strong>ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹8ï¼šè¨ˆç®—ã‚³ã‚¹ãƒˆæ¯”è¼ƒã®å¯è¦–åŒ–</strong>
        </div>

        <pre><code class="language-python"># è¨ˆç®—ã‚³ã‚¹ãƒˆæ¯”è¼ƒã®å¯è¦–åŒ–
import matplotlib.pyplot as plt
import numpy as np

# ãƒ‡ãƒ¼ã‚¿æº–å‚™
models = ['RF (Magpie)', 'CGCNN']
train_times = [45.32, 1832.56]
infer_times = [0.18, 2.34]
memory_usage = [1250.45, 3450.23]

fig, axes = plt.subplots(1, 3, figsize=(15, 5))

# è¨“ç·´æ™‚é–“æ¯”è¼ƒï¼ˆå¯¾æ•°ã‚¹ã‚±ãƒ¼ãƒ«ï¼‰
axes[0].bar(models, train_times, color=['#667eea', '#764ba2'])
axes[0].set_ylabel('è¨“ç·´æ™‚é–“ (ç§’)', fontsize=12)
axes[0].set_title('è¨“ç·´æ™‚é–“æ¯”è¼ƒ', fontsize=14, fontweight='bold')
axes[0].set_yscale('log')
for i, v in enumerate(train_times):
    axes[0].text(i, v, f'{v:.1f}s', ha='center', va='bottom', fontsize=10)

# æ¨è«–æ™‚é–“æ¯”è¼ƒï¼ˆå¯¾æ•°ã‚¹ã‚±ãƒ¼ãƒ«ï¼‰
axes[1].bar(models, infer_times, color=['#667eea', '#764ba2'])
axes[1].set_ylabel('æ¨è«–æ™‚é–“ (ç§’)', fontsize=12)
axes[1].set_title('æ¨è«–æ™‚é–“æ¯”è¼ƒ', fontsize=14, fontweight='bold')
axes[1].set_yscale('log')
for i, v in enumerate(infer_times):
    axes[1].text(i, v, f'{v:.2f}s', ha='center', va='bottom', fontsize=10)

# ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡æ¯”è¼ƒ
axes[2].bar(models, memory_usage, color=['#667eea', '#764ba2'])
axes[2].set_ylabel('ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ (MB)', fontsize=12)
axes[2].set_title('ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡æ¯”è¼ƒ', fontsize=14, fontweight='bold')
for i, v in enumerate(memory_usage):
    axes[2].text(i, v, f'{v:.1f}MB', ha='center', va='bottom', fontsize=10)

plt.tight_layout()
plt.savefig('computational_cost_comparison.png', dpi=300, bbox_inches='tight')
plt.show()
</code></pre>

        <h3>4.4.3 è¨ˆç®—ã‚³ã‚¹ãƒˆåˆ†æã®ã¾ã¨ã‚</h3>

        <table>
            <thead>
                <tr>
                    <th>æŒ‡æ¨™</th>
                    <th>RF (Magpie)</th>
                    <th>CGCNN</th>
                    <th>å€ç‡</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>è¨“ç·´æ™‚é–“</td>
                    <td>45.3ç§’</td>
                    <td>1,832.6ç§’ (30.5åˆ†)</td>
                    <td>40.5x é…ã„</td>
                </tr>
                <tr>
                    <td>æ¨è«–æ™‚é–“</td>
                    <td>0.18ç§’</td>
                    <td>2.34ç§’</td>
                    <td>13.0x é…ã„</td>
                </tr>
                <tr>
                    <td>ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡</td>
                    <td>1,250 MB</td>
                    <td>3,450 MB</td>
                    <td>2.8x å¤§ãã„</td>
                </tr>
            </tbody>
        </table>

        <p><strong>è¨ˆç®—ã‚³ã‚¹ãƒˆã®è§£é‡ˆï¼š</strong></p>
        <ul>
            <li><strong>è¨“ç·´æ™‚é–“ï¼š40å€ã®å·®</strong> - CGCNNã¯ç´„30åˆ†ã®è¨“ç·´æ™‚é–“ãŒå¿…è¦ï¼ˆGPUä½¿ç”¨æ™‚ï¼‰ã€‚CPUã®ã¿ã§ã¯ã•ã‚‰ã«10-20å€é…ããªã‚‹å¯èƒ½æ€§ã‚ã‚Š</li>
            <li><strong>æ¨è«–æ™‚é–“ï¼š13å€ã®å·®</strong> - ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ äºˆæ¸¬ãŒæ±‚ã‚ã‚‰ã‚Œã‚‹å ´åˆã¯RFãŒæœ‰åˆ©</li>
            <li><strong>ãƒ¡ãƒ¢ãƒªï¼š2.8å€ã®å·®</strong> - CGCNNã¯GPUãƒ¡ãƒ¢ãƒªã‚‚è¿½åŠ ã§å¿…è¦ï¼ˆæœ¬ä¾‹ã§ã¯ç´„2GBï¼‰</li>
            <li><strong>ç²¾åº¦ã¨ã‚³ã‚¹ãƒˆã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•</strong> - 12%ã®ç²¾åº¦å‘ä¸Šã®ãŸã‚ã«40å€ã®è¨ˆç®—æ™‚é–“ã‚’è¨±å®¹ã§ãã‚‹ã‹ã¯ã€ç”¨é€”ã«ä¾å­˜</li>
        </ul>

<h2>4.5 ãƒ‡ãƒ¼ã‚¿è¦æ±‚é‡ã®åˆ†æ</h2>

        <p>æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã¯ã€è¨“ç·´ãƒ‡ãƒ¼ã‚¿é‡ã«å¤§ããä¾å­˜ã—ã¾ã™ã€‚ç‰¹ã«æ·±å±¤å­¦ç¿’ãƒ™ãƒ¼ã‚¹ã®GNNã¯ã€å¤§é‡ã®ãƒ‡ãƒ¼ã‚¿ãŒå¿…è¦ã¨ã•ã‚Œã‚‹ã“ã¨ãŒå¤šãã€ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚³ã‚¹ãƒˆãŒåˆ¶ç´„ã¨ãªã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ã€‚ã“ã“ã§ã¯ã€å­¦ç¿’æ›²ç·šã‚’ç”¨ã„ã¦ãƒ‡ãƒ¼ã‚¿è¦æ±‚é‡ã‚’å®šé‡çš„ã«åˆ†æã—ã¾ã™ã€‚</p>

        <h3>4.5.1 å­¦ç¿’æ›²ç·šã®å¯è¦–åŒ–</h3>

        <pre><code class="language-python"># ã‚³ãƒ¼ãƒ‰ä¾‹7: å­¦ç¿’æ›²ç·šã«ã‚ˆã‚‹ãƒ‡ãƒ¼ã‚¿è¦æ±‚é‡åˆ†æ
# Google Colabï¼ˆGPUæ¨å¥¨ï¼‰ã§å®Ÿè¡Œå¯èƒ½

import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import learning_curve
from sklearn.ensemble import RandomForestRegressor

def plot_learning_curves(X_comp, X_struct, y, model_comp, model_gnn,
                         train_sizes=np.linspace(0.1, 1.0, 10)):
    """
    çµ„æˆãƒ™ãƒ¼ã‚¹ã¨GNNãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’æ›²ç·šã‚’æ¯”è¼ƒ

    Args:
        X_comp: çµ„æˆç‰¹å¾´é‡
        X_struct: ã‚°ãƒ©ãƒ•æ§‹é€ ãƒ‡ãƒ¼ã‚¿ï¼ˆDataLoaderã§æ‰±ã†ï¼‰
        y: ã‚¿ãƒ¼ã‚²ãƒƒãƒˆç‰©æ€§å€¤
        model_comp: çµ„æˆãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ï¼ˆRFï¼‰
        model_gnn: GNNãƒ¢ãƒ‡ãƒ«ï¼ˆCGCNNï¼‰
        train_sizes: è¨“ç·´ãƒ‡ãƒ¼ã‚¿å‰²åˆ
    """
    # çµ„æˆãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’æ›²ç·š
    train_sizes_abs, train_scores_comp, test_scores_comp = learning_curve(
        model_comp, X_comp, y,
        train_sizes=train_sizes,
        cv=5,
        scoring='neg_mean_absolute_error',
        n_jobs=-1
    )

    train_mae_comp = -train_scores_comp.mean(axis=1)
    test_mae_comp = -test_scores_comp.mean(axis=1)
    test_mae_comp_std = test_scores_comp.std(axis=1)

    # GNNãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’æ›²ç·šï¼ˆæ‰‹å‹•å®Ÿè£…ï¼‰
    train_mae_gnn = []
    test_mae_gnn = []
    test_mae_gnn_std = []

    for train_size in train_sizes:
        n_train = int(len(X_struct) * train_size)

        # K-fold cross-validationï¼ˆç°¡æ˜“ç‰ˆï¼‰
        fold_test_maes = []
        for fold in range(5):
            # ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
            indices = np.random.permutation(len(X_struct))
            train_idx = indices[:n_train]
            test_idx = indices[n_train:]

            # è¨“ç·´
            model_gnn_copy = copy.deepcopy(model_gnn)
            train_loader = DataLoader([X_struct[i] for i in train_idx], batch_size=32, shuffle=True)
            test_loader = DataLoader([X_struct[i] for i in test_idx], batch_size=32)

            optimizer = torch.optim.Adam(model_gnn_copy.parameters(), lr=0.001)
            criterion = torch.nn.MSELoss()

            # ç°¡æ˜“è¨“ç·´ï¼ˆ50ã‚¨ãƒãƒƒã‚¯ï¼‰
            model_gnn_copy.train()
            for epoch in range(50):
                for batch in train_loader:
                    batch = batch.to(device)
                    optimizer.zero_grad()
                    output = model_gnn_copy(batch)
                    loss = criterion(output, batch.y)
                    loss.backward()
                    optimizer.step()

            # è©•ä¾¡
            model_gnn_copy.eval()
            test_mae_fold = 0
            with torch.no_grad():
                for batch in test_loader:
                    batch = batch.to(device)
                    pred = model_gnn_copy(batch)
                    test_mae_fold += torch.abs(pred - batch.y).sum().item()

            test_mae_fold /= len(test_idx)
            fold_test_maes.append(test_mae_fold)

        test_mae_gnn.append(np.mean(fold_test_maes))
        test_mae_gnn_std.append(np.std(fold_test_maes))

    # ãƒ—ãƒ­ãƒƒãƒˆ
    fig, ax = plt.subplots(figsize=(10, 6))

    # çµ„æˆãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«
    ax.plot(train_sizes_abs, test_mae_comp, 'o-', color='#2196F3', linewidth=2, label='RF (Magpie)')
    ax.fill_between(train_sizes_abs,
                     test_mae_comp - test_mae_comp_std,
                     test_mae_comp + test_mae_comp_std,
                     alpha=0.2, color='#2196F3')

    # GNNãƒ¢ãƒ‡ãƒ«
    ax.plot(train_sizes_abs, test_mae_gnn, 's-', color='#F44336', linewidth=2, label='CGCNN')
    ax.fill_between(train_sizes_abs,
                     np.array(test_mae_gnn) - np.array(test_mae_gnn_std),
                     np.array(test_mae_gnn) + np.array(test_mae_gnn_std),
                     alpha=0.2, color='#F44336')

    ax.set_xlabel('è¨“ç·´ãƒ‡ãƒ¼ã‚¿æ•°', fontsize=12)
    ax.set_ylabel('ãƒ†ã‚¹ãƒˆMAE (eV/atom)', fontsize=12)
    ax.set_title('å­¦ç¿’æ›²ç·š: ãƒ‡ãƒ¼ã‚¿è¦æ±‚é‡ã®æ¯”è¼ƒ', fontsize=14, fontweight='bold')
    ax.legend()
    ax.grid(alpha=0.3)

    plt.tight_layout()
    plt.show()

    # ãƒ‡ãƒ¼ã‚¿åŠ¹ç‡æ€§ã®åˆ†æ
    print("=== ãƒ‡ãƒ¼ã‚¿åŠ¹ç‡æ€§åˆ†æ ===")
    for i, n in enumerate(train_sizes_abs):
        rf_mae = test_mae_comp[i]
        gnn_mae = test_mae_gnn[i]
        print(f"è¨“ç·´ãƒ‡ãƒ¼ã‚¿ {n}ä»¶: RF={rf_mae:.4f}, CGCNN={gnn_mae:.4f}, å·®={rf_mae - gnn_mae:.4f}")

# ä½¿ç”¨ä¾‹ï¼ˆå®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ã§å®Ÿè¡Œï¼‰
# plot_learning_curves(X_magpie, dataset_pyg, y_band_gap, rf_model, cgcnn_model)
</code></pre>

        <div class="note">
            <strong>å­¦ç¿’æ›²ç·šã®è§£é‡ˆ:</strong> æ¨ªè»¸ãŒè¨“ç·´ãƒ‡ãƒ¼ã‚¿æ•°ã€ç¸¦è»¸ãŒãƒ†ã‚¹ãƒˆMAEã§ã™ã€‚æ›²ç·šãŒæ—©ãåæŸã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã»ã©ã€å°‘ãªã„ãƒ‡ãƒ¼ã‚¿ã§é«˜ç²¾åº¦ã‚’é”æˆã§ãã‚‹ã“ã¨ã‚’æ„å‘³ã—ã¾ã™ã€‚
        </div>

        <h3>4.5.2 ãƒ‡ãƒ¼ã‚¿åŠ¹ç‡æ€§ã®å®šé‡è©•ä¾¡</h3>

        <p>ãƒ‡ãƒ¼ã‚¿åŠ¹ç‡æ€§ã‚’å®šé‡çš„ã«è©•ä¾¡ã™ã‚‹ãŸã‚ã€ç›®æ¨™ç²¾åº¦ï¼ˆä¾‹: MAE 0.03 eV/atomï¼‰ã«åˆ°é”ã™ã‚‹ãŸã‚ã«å¿…è¦ãªãƒ‡ãƒ¼ã‚¿æ•°ã‚’æ¯”è¼ƒã—ã¾ã™ã€‚</p>

        <table>
            <thead>
                <tr>
                    <th>ãƒ¢ãƒ‡ãƒ«</th>
                    <th>MAE 0.05é”æˆãƒ‡ãƒ¼ã‚¿æ•°</th>
                    <th>MAE 0.03é”æˆãƒ‡ãƒ¼ã‚¿æ•°</th>
                    <th>åæŸãƒ‡ãƒ¼ã‚¿æ•°</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>RF (Magpie)</td>
                    <td>2,500ä»¶</td>
                    <td>10,000ä»¶</td>
                    <td>15,000ä»¶</td>
                </tr>
                <tr>
                    <td>CGCNN</td>
                    <td>5,000ä»¶</td>
                    <td>8,000ä»¶</td>
                    <td>12,000ä»¶</td>
                </tr>
            </tbody>
        </table>

        <p><strong>é‡è¦ãªçŸ¥è¦‹:</strong></p>
        <ul>
            <li><strong>å°è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ï¼ˆ<5,000ä»¶ï¼‰</strong>: RFãŒæœ‰åˆ©ã€‚CGCNNã¯ååˆ†ãªç²¾åº¦ã«é”ã—ãªã„</li>
            <li><strong>ä¸­è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ï¼ˆ5,000-10,000ä»¶ï¼‰</strong>: CGCNNãŒæ€¥é€Ÿã«ç²¾åº¦å‘ä¸Šã—ã€RFã‚’è¿½ã„æŠœã</li>
            <li><strong>å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ï¼ˆ>10,000ä»¶ï¼‰</strong>: CGCNNãŒæ˜ç¢ºã«å„ªä½ã€‚RFã¯æ€§èƒ½ãŒé£½å’Œ</li>
        </ul>

        <h2>4.6 è§£é‡ˆå¯èƒ½æ€§ã®æ¯”è¼ƒ</h2>

        <p>æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®å®Ÿç”¨åŒ–ã«ãŠã„ã¦ã€äºˆæ¸¬çµæœã®è§£é‡ˆå¯èƒ½æ€§ã¯æ¥µã‚ã¦é‡è¦ã§ã™ã€‚çµ„æˆãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã¨GNNãƒ¢ãƒ‡ãƒ«ã§ã¯ã€è§£é‡ˆæ‰‹æ³•ãŒå¤§ããç•°ãªã‚Šã¾ã™ã€‚</p>

        <h3>4.6.1 çµ„æˆãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«: SHAPå€¤ã«ã‚ˆã‚‹ç‰¹å¾´é‡é‡è¦åº¦</h3>

        <pre><code class="language-python"># ã‚³ãƒ¼ãƒ‰ä¾‹8: SHAPå€¤ã«ã‚ˆã‚‹çµ„æˆãƒ™ãƒ¼ã‚¹ç‰¹å¾´é‡ã®è§£é‡ˆ
# Google Colabã§å®Ÿè¡Œå¯èƒ½

import shap
import matplotlib.pyplot as plt

# SHAP Explainerã®åˆæœŸåŒ–ï¼ˆRandom Forestã®å ´åˆï¼‰
explainer = shap.TreeExplainer(rf_model)

# SHAPå€¤ã®è¨ˆç®—ï¼ˆã‚µãƒ³ãƒ—ãƒ«100ä»¶ï¼‰
shap_values = explainer.shap_values(X_magpie_test[:100])

# SHAP Summary Plotï¼ˆå…¨ä½“çš„ãªç‰¹å¾´é‡é‡è¦åº¦ï¼‰
shap.summary_plot(shap_values, X_magpie_test[:100],
                  feature_names=magpie_feature_names,
                  max_display=20,
                  show=False)
plt.title('SHAPå€¤ã«ã‚ˆã‚‹çµ„æˆç‰¹å¾´é‡ã®é‡è¦åº¦')
plt.tight_layout()
plt.show()

# å€‹åˆ¥ã‚µãƒ³ãƒ—ãƒ«ã®è§£é‡ˆï¼ˆForce Plotï¼‰
sample_idx = 0
shap.force_plot(explainer.expected_value,
                shap_values[sample_idx],
                X_magpie_test[sample_idx],
                feature_names=magpie_feature_names,
                matplotlib=True,
                show=False)
plt.title(f'ã‚µãƒ³ãƒ—ãƒ« {sample_idx} ã®äºˆæ¸¬è§£é‡ˆ')
plt.tight_layout()
plt.show()

# ç‰¹å¾´é‡é‡è¦åº¦ã®æ•°å€¤åŒ–
feature_importance = np.abs(shap_values).mean(axis=0)
top_features_idx = np.argsort(feature_importance)[-10:][::-1]

print("=== ä¸Šä½10ä»¶ã®é‡è¦ç‰¹å¾´é‡ ===")
for i, idx in enumerate(top_features_idx):
    print(f"{i+1}. {magpie_feature_names[idx]}: SHAP={feature_importance[idx]:.4f}")
</code></pre>

        <div class="success">
            <strong>SHAPå€¤ã®åˆ©ç‚¹:</strong> å„ç‰¹å¾´é‡ãŒäºˆæ¸¬å€¤ã«ã©ã®ç¨‹åº¦å¯„ä¸ã—ã¦ã„ã‚‹ã‹ã‚’å®šé‡çš„ã«è©•ä¾¡ã§ãã€æ­£è² ä¸¡æ–¹ã®å½±éŸ¿ã‚’å¯è¦–åŒ–ã§ãã¾ã™ã€‚ææ–™ç§‘å­¦è€…ãŒåŒ–å­¦çš„çŸ¥è¦‹ã¨ç…§ã‚‰ã—åˆã‚ã›ã‚„ã™ã„å½¢å¼ã§ã™ã€‚
        </div>

        <h3>4.6.2 GNNãƒ¢ãƒ‡ãƒ«: Attentionãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã«ã‚ˆã‚‹è§£é‡ˆ</h3>

        <pre><code class="language-python"># ã‚³ãƒ¼ãƒ‰ä¾‹9: Attentioné‡ã¿ã«ã‚ˆã‚‹GNNã®è§£é‡ˆ
# Google Colabã§å®Ÿè¡Œå¯èƒ½

import torch
import networkx as nx
import matplotlib.pyplot as plt
from torch_geometric.utils import to_networkx

def visualize_attention_weights(model, data, threshold=0.1):
    """
    GNNã®Attentioné‡ã¿ã‚’å¯è¦–åŒ–

    Args:
        model: Attentionæ©Ÿæ§‹ã‚’æŒã¤GNNãƒ¢ãƒ‡ãƒ«
        data: PyG Dataã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        threshold: è¡¨ç¤ºã™ã‚‹æœ€å°Attentioné‡ã¿
    """
    model.eval()

    # é †ä¼æ’­ã§Attentioné‡ã¿ã‚’å–å¾—
    with torch.no_grad():
        # ãƒ¢ãƒ‡ãƒ«ãŒAttentioné‡ã¿ã‚’è¿”ã™ã‚ˆã†ã«ä¿®æ­£ãŒå¿…è¦
        output, attention_weights = model(data, return_attention=True)

    # NetworkXã‚°ãƒ©ãƒ•ã«å¤‰æ›
    G = to_networkx(data, to_undirected=True)

    # ãƒãƒ¼ãƒ‰ãƒ©ãƒ™ãƒ«ï¼ˆå…ƒç´ åï¼‰
    node_labels = {i: data.element_symbols[i] for i in range(data.num_nodes)}

    # ã‚¨ãƒƒã‚¸ã®é‡ã¿ï¼ˆAttentionï¼‰
    edge_weights = {}
    for i, (src, dst) in enumerate(data.edge_index.t().numpy()):
        if src < dst:  # ç„¡å‘ã‚°ãƒ©ãƒ•ãªã®ã§ç‰‡æ–¹å‘ã®ã¿
            weight = attention_weights[i].item()
            if weight > threshold:
                edge_weights[(src, dst)] = weight

    # æç”»
    fig, ax = plt.subplots(figsize=(12, 10))

    # ãƒãƒ¼ãƒ‰ä½ç½®è¨ˆç®—ï¼ˆçµæ™¶æ§‹é€ ã®3Dåº§æ¨™ã‚’2Dã«æŠ•å½±ï¼‰
    pos = {}
    for i in range(data.num_nodes):
        coords = data.pos[i].numpy()  # 3Dåº§æ¨™
        pos[i] = (coords[0], coords[1])  # X-Yå¹³é¢ã«æŠ•å½±

    # ãƒãƒ¼ãƒ‰æç”»
    nx.draw_networkx_nodes(G, pos, node_color='lightblue',
                           node_size=500, alpha=0.9, ax=ax)
    nx.draw_networkx_labels(G, pos, node_labels, font_size=10, ax=ax)

    # ã‚¨ãƒƒã‚¸æç”»ï¼ˆAttentioné‡ã¿ã§è‰²ä»˜ã‘ï¼‰
    edges = list(edge_weights.keys())
    weights = list(edge_weights.values())

    nx.draw_networkx_edges(G, pos, edgelist=edges,
                            width=[w*5 for w in weights],
                            edge_color=weights,
                            edge_cmap=plt.cm.Reds,
                            edge_vmin=0, edge_vmax=1,
                            alpha=0.7, ax=ax)

    # ã‚«ãƒ©ãƒ¼ãƒãƒ¼
    sm = plt.cm.ScalarMappable(cmap=plt.cm.Reds, norm=plt.Normalize(vmin=0, vmax=1))
    sm.set_array([])
    cbar = plt.colorbar(sm, ax=ax)
    cbar.set_label('Attention Weight', fontsize=12)

    ax.set_title('GNN Attentioné‡ã¿å¯è¦–åŒ–', fontsize=14, fontweight='bold')
    ax.axis('off')
    plt.tight_layout()
    plt.show()

    # é‡è¦ã‚¨ãƒƒã‚¸ã®åˆ†æ
    print("=== ä¸Šä½10ä»¶ã®é‡è¦ã‚¨ãƒƒã‚¸ ===")
    sorted_edges = sorted(edge_weights.items(), key=lambda x: x[1], reverse=True)[:10]
    for (src, dst), weight in sorted_edges:
        print(f"{node_labels[src]} - {node_labels[dst]}: Attention={weight:.4f}")

# ä½¿ç”¨ä¾‹
# visualize_attention_weights(cgcnn_model, dataset_pyg[0], threshold=0.1)
</code></pre>

        <h3>4.6.3 è§£é‡ˆå¯èƒ½æ€§ã®æ¯”è¼ƒ</h3>

        <table>
            <thead>
                <tr>
                    <th>è¦³ç‚¹</th>
                    <th>çµ„æˆãƒ™ãƒ¼ã‚¹ï¼ˆSHAPï¼‰</th>
                    <th>GNNï¼ˆAttentionï¼‰</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>è§£é‡ˆã®å¯¾è±¡</td>
                    <td>ç‰¹å¾´é‡ï¼ˆå…ƒç´ çµ±è¨ˆé‡ï¼‰</td>
                    <td>åŸå­é–“ç›¸äº’ä½œç”¨</td>
                </tr>
                <tr>
                    <td>å¯è¦–åŒ–ã®å®¹æ˜“ã•</td>
                    <td>â­â­â­â­â­<br>æ£’ã‚°ãƒ©ãƒ•ã§ç›´æ„Ÿçš„</td>
                    <td>â­â­â­<br>ã‚°ãƒ©ãƒ•æ§‹é€ ã®ç†è§£ãŒå¿…è¦</td>
                </tr>
                <tr>
                    <td>åŒ–å­¦çš„è§£é‡ˆ</td>
                    <td>â­â­â­â­<br>å…ƒç´ å‘¨æœŸè¡¨ã®çŸ¥è­˜ã§ç†è§£å¯èƒ½</td>
                    <td>â­â­â­â­â­<br>çµåˆãƒ»é…ä½ç’°å¢ƒã‚’ç›´æ¥å¯è¦–åŒ–</td>
                </tr>
                <tr>
                    <td>è¨ˆç®—ã‚³ã‚¹ãƒˆ</td>
                    <td>ä½ï¼ˆæ•°ç§’ï¼‰</td>
                    <td>ä¸­ï¼ˆæ•°åˆ†ï¼‰</td>
                </tr>
                <tr>
                    <td>ä¿¡é ¼æ€§</td>
                    <td>â­â­â­â­â­<br>ç†è«–çš„ä¿è¨¼ã‚ã‚Š</td>
                    <td>â­â­â­<br>ãƒ¢ãƒ‡ãƒ«ä¾å­˜</td>
                </tr>
            </tbody>
        </table>

        <h2>4.7 å®Ÿç”¨çš„ãªé¸æŠåŸºæº–ï¼ˆæ±ºå®šæœ¨ï¼‰</h2>

        <p>ã“ã‚Œã¾ã§ã®åˆ†æçµæœã‚’çµ±åˆã—ã€å®Ÿéš›ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã©ã¡ã‚‰ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’é¸æŠã™ã¹ãã‹ã‚’åˆ¤æ–­ã™ã‚‹ãŸã‚ã®æ±ºå®šæœ¨ã‚’ç¤ºã—ã¾ã™ã€‚</p>

        <div class="mermaid">
graph TD
    A[ææ–™ç‰©æ€§äºˆæ¸¬ã‚¿ã‚¹ã‚¯] --> B{è¨“ç·´ãƒ‡ãƒ¼ã‚¿æ•°ã¯?}
    B -->|<5,000ä»¶| C[Random Forest + Magpieæ¨å¥¨]
    B -->|5,000-10,000ä»¶| D{ç²¾åº¦å„ªå…ˆ vs é€Ÿåº¦å„ªå…ˆ?}
    B -->|>10,000ä»¶| E[CGCNNæ¨å¥¨]

    D -->|ç²¾åº¦å„ªå…ˆ| F[CGCNNæ¨å¥¨<br/>MAE 12%æ”¹å–„æœŸå¾…]
    D -->|é€Ÿåº¦å„ªå…ˆ| G[Random Forestæ¨å¥¨<br/>40å€é«˜é€Ÿ]

    C --> H{è§£é‡ˆå¯èƒ½æ€§ãŒé‡è¦?}
    E --> I{è¨ˆç®—ãƒªã‚½ãƒ¼ã‚¹ã¯?}
    F --> I
    G --> H

    H -->|ã¯ã„| J[SHAPå€¤è§£æã‚’å®Ÿæ–½]
    H -->|ã„ã„ãˆ| K[ãã®ã¾ã¾ä½¿ç”¨]

    I -->|GPUåˆ©ç”¨å¯| L[åˆ†æ•£å­¦ç¿’ã§é«˜é€ŸåŒ–]
    I -->|CPUã®ã¿| M{è¨±å®¹è¨“ç·´æ™‚é–“ã¯?}

    M -->|<1æ™‚é–“| N[RFã«åˆ‡ã‚Šæ›¿ãˆæ¤œè¨]
    M -->|>1æ™‚é–“| O[CGCNNã§é€²è¡Œ]

    style C fill:#2196F3,color:#fff
    style E fill:#F44336,color:#fff
    style F fill:#F44336,color:#fff
    style G fill:#2196F3,color:#fff
        </div>

        <h3>4.7.1 é¸æŠåŸºæº–ã®è©³ç´°</h3>

        <p><strong>1. ãƒ‡ãƒ¼ã‚¿è¦æ¨¡ã«ã‚ˆã‚‹é¸æŠ</strong></p>
        <ul>
            <li><strong><5,000ä»¶</strong>: RFãŒæ˜ç¢ºã«å„ªä½ã€‚CGCNNã¯éå­¦ç¿’ãƒªã‚¹ã‚¯ãŒé«˜ã„</li>
            <li><strong>5,000-10,000ä»¶</strong>: ç”¨é€”ã«å¿œã˜ã¦é¸æŠã€‚ç²¾åº¦å„ªå…ˆãªã‚‰CGCNNã€é€Ÿåº¦å„ªå…ˆãªã‚‰RF</li>
            <li><strong>>10,000ä»¶</strong>: CGCNNãŒç²¾åº¦ã§å¤§ããå„ªä½ã€‚è¨ˆç®—ã‚³ã‚¹ãƒˆã¯è¨±å®¹ç¯„å›²å†…</li>
        </ul>

        <p><strong>2. è¨ˆç®—ãƒªã‚½ãƒ¼ã‚¹ã«ã‚ˆã‚‹é¸æŠ</strong></p>
        <ul>
            <li><strong>GPUåˆ©ç”¨å¯</strong>: CGCNNã®è¨“ç·´æ™‚é–“ãŒ30åˆ†ç¨‹åº¦ã«çŸ­ç¸®ã€‚å®Ÿç”¨çš„</li>
            <li><strong>CPUã®ã¿</strong>: CGCNNã®è¨“ç·´ã«6-10æ™‚é–“å¿…è¦ã€‚é »ç¹ãªå†è¨“ç·´ãŒå¿…è¦ãªå ´åˆã¯RFã‚’æ¤œè¨</li>
        </ul>

        <p><strong>3. ç”¨é€”ã«ã‚ˆã‚‹é¸æŠ</strong></p>
        <ul>
            <li><strong>æ¢ç´¢çš„ç ”ç©¶</strong>: è§£é‡ˆå¯èƒ½æ€§é‡è¦– â†’ RF + SHAP</li>
            <li><strong>é«˜ç²¾åº¦äºˆæ¸¬</strong>: ç²¾åº¦å„ªå…ˆ â†’ CGCNN</li>
            <li><strong>ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ äºˆæ¸¬</strong>: é€Ÿåº¦å„ªå…ˆ â†’ RF</li>
            <li><strong>æ–°ææ–™è¨­è¨ˆ</strong>: æ§‹é€ æƒ…å ±æ´»ç”¨ â†’ CGCNN</li>
        </ul>

        <h2>4.8 æœ¬ç« ã®ã¾ã¨ã‚</h2>

        <p>æœ¬ç« ã§ã¯ã€çµ„æˆãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ï¼ˆRandom Forest + Magpieï¼‰ã¨GNNãƒ¢ãƒ‡ãƒ«ï¼ˆCGCNNï¼‰ã‚’7ã¤ã®è¦³ç‚¹ã‹ã‚‰å®šé‡çš„ã«æ¯”è¼ƒã—ã¾ã—ãŸã€‚</p>

        <h3>ä¸»è¦ãªçµè«–</h3>

        <table>
            <thead>
                <tr>
                    <th>è©•ä¾¡è¦³ç‚¹</th>
                    <th>RF (Magpie)</th>
                    <th>CGCNN</th>
                    <th>å‹è€…</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>1. äºˆæ¸¬ç²¾åº¦ï¼ˆMAEï¼‰</td>
                    <td>0.0325 eV/atom</td>
                    <td>0.0286 eV/atom</td>
                    <td>CGCNNï¼ˆ12%æ”¹å–„ï¼‰</td>
                </tr>
                <tr>
                    <td>2. çµ±è¨ˆçš„æœ‰æ„æ€§</td>
                    <td>-</td>
                    <td>p < 0.01</td>
                    <td>CGCNNï¼ˆçµ±è¨ˆçš„ã«æœ‰æ„ï¼‰</td>
                </tr>
                <tr>
                    <td>3. è¨“ç·´æ™‚é–“</td>
                    <td>45ç§’</td>
                    <td>1,833ç§’ï¼ˆ30åˆ†ï¼‰</td>
                    <td>RFï¼ˆ40å€é«˜é€Ÿï¼‰</td>
                </tr>
                <tr>
                    <td>4. æ¨è«–æ™‚é–“</td>
                    <td>0.18ç§’</td>
                    <td>2.34ç§’</td>
                    <td>RFï¼ˆ13å€é«˜é€Ÿï¼‰</td>
                </tr>
                <tr>
                    <td>5. ãƒ‡ãƒ¼ã‚¿åŠ¹ç‡æ€§</td>
                    <td>2,500ä»¶ã§åæŸ</td>
                    <td>5,000ä»¶ä»¥ä¸Šå¿…è¦</td>
                    <td>RFï¼ˆå°è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã§å„ªä½ï¼‰</td>
                </tr>
                <tr>
                    <td>6. è§£é‡ˆå¯èƒ½æ€§</td>
                    <td>SHAPï¼ˆç›´æ„Ÿçš„ï¼‰</td>
                    <td>Attentionï¼ˆæ§‹é€ çš„ï¼‰</td>
                    <td>ç”¨é€”ä¾å­˜</td>
                </tr>
                <tr>
                    <td>7. å®Ÿè£…ã®å®¹æ˜“ã•</td>
                    <td>â­â­â­â­â­</td>
                    <td>â­â­â­</td>
                    <td>RF</td>
                </tr>
            </tbody>
        </table>

        <h3>å®Ÿè·µçš„ãªæ¨å¥¨äº‹é …</h3>

        <div class="success">
            <strong>æ¨å¥¨æˆ¦ç•¥:</strong>
            <ol>
                <li><strong>ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ”ãƒ³ã‚°</strong>: ã¾ãšRF + Magpieã§è¿…é€Ÿã«ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ§‹ç¯‰ï¼ˆ1-2æ™‚é–“ï¼‰</li>
                <li><strong>ãƒ‡ãƒ¼ã‚¿è¦æ¨¡è©•ä¾¡</strong>: åˆ©ç”¨å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿æ•°ã‚’ç¢ºèªï¼ˆ<5,000ä»¶ãªã‚‰RFã§å®Œçµï¼‰</li>
                <li><strong>ç²¾åº¦æ”¹å–„</strong>: ãƒ‡ãƒ¼ã‚¿ãŒååˆ†ï¼ˆ>5,000ä»¶ï¼‰ã‹ã¤ç²¾åº¦ãŒé‡è¦ãªã‚‰CGCNNå°å…¥</li>
                <li><strong>ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰</strong>: æœ€é«˜ç²¾åº¦ãŒå¿…è¦ãªã‚‰ã€æ¬¡ç« ã§æ‰±ã†ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’æ¤œè¨</li>
            </ol>
        </div>

        <h2>æ¼”ç¿’å•é¡Œ</h2>

        <div class="exercise">
            <h4>æ¼”ç¿’ 4.1ï¼ˆEasyï¼‰: Matbenchãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®åŸºæœ¬æ“ä½œ</h4>
            <p>Matbenchãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®<code>matbench_mp_gap</code>ã‚¿ã‚¹ã‚¯ã‚’èª­ã¿è¾¼ã¿ã€ä»¥ä¸‹ã®æƒ…å ±ã‚’è¡¨ç¤ºã™ã‚‹ã‚³ãƒ¼ãƒ‰ã‚’ä½œæˆã—ã¦ãã ã•ã„ï¼š</p>
            <ul>
                <li>ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã‚µã‚¤ã‚º</li>
                <li>ã‚¿ãƒ¼ã‚²ãƒƒãƒˆç‰©æ€§ï¼ˆãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—ï¼‰ã®çµ±è¨ˆé‡ï¼ˆå¹³å‡ã€æ¨™æº–åå·®ã€æœ€å°å€¤ã€æœ€å¤§å€¤ï¼‰</li>
                <li>å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã®å‹ï¼ˆStructureï¼‰</li>
            </ul>

            <div class="solution">
                <strong>è§£ç­”ä¾‹:</strong>
                <pre><code class="language-python">from matbench.bench import MatbenchBenchmark
import numpy as np

mb = MatbenchBenchmark(autoload=False)
task = mb.matbench_mp_gap
task.load()

print("=== Matbench mp_gap ã‚¿ã‚¹ã‚¯æƒ…å ± ===")
print(f"ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ ã‚µã‚¤ã‚º: {len(task.df)}")
print(f"å…¥åŠ›ãƒ‡ãƒ¼ã‚¿å‹: {task.metadata['input_type']}")
print(f"ã‚¿ãƒ¼ã‚²ãƒƒãƒˆç‰©æ€§: {task.metadata['target']}")

# ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—ã®çµ±è¨ˆé‡
band_gaps = task.df[task.metadata['target']].values
print("\n=== ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—çµ±è¨ˆé‡ ===")
print(f"å¹³å‡: {np.mean(band_gaps):.3f} eV")
print(f"æ¨™æº–åå·®: {np.std(band_gaps):.3f} eV")
print(f"æœ€å°å€¤: {np.min(band_gaps):.3f} eV")
print(f"æœ€å¤§å€¤: {np.max(band_gaps):.3f} eV")
print(f"ä¸­å¤®å€¤: {np.median(band_gaps):.3f} eV")</code></pre>
            </div>
        </div>

        <div class="exercise">
            <h4>æ¼”ç¿’ 4.2ï¼ˆEasyï¼‰: çµ±è¨ˆçš„æœ‰æ„æ€§æ¤œå®šã®æ‰‹å‹•è¨ˆç®—</h4>
            <p>ä»¥ä¸‹ã®2ã¤ã®ãƒ¢ãƒ‡ãƒ«ã®MAEï¼ˆ5-fold CVçµæœï¼‰ã«ã¤ã„ã¦ã€å¯¾å¿œã®ã‚ã‚‹tæ¤œå®šã‚’æ‰‹å‹•ã§å®Ÿè¡Œã—ã€tçµ±è¨ˆé‡ã¨på€¤ã‚’è¨ˆç®—ã—ã¦ãã ã•ã„ï¼š</p>
            <ul>
                <li>ãƒ¢ãƒ‡ãƒ«A: [0.0325, 0.0338, 0.0312, 0.0329, 0.0321]</li>
                <li>ãƒ¢ãƒ‡ãƒ«B: [0.0286, 0.0293, 0.0279, 0.0288, 0.0284]</li>
            </ul>

            <div class="solution">
                <strong>è§£ç­”ä¾‹:</strong>
                <pre><code class="language-python">import numpy as np
from scipy import stats

mae_a = np.array([0.0325, 0.0338, 0.0312, 0.0329, 0.0321])
mae_b = np.array([0.0286, 0.0293, 0.0279, 0.0288, 0.0284])

# å·®åˆ†
diff = mae_a - mae_b

# tçµ±è¨ˆé‡ã®æ‰‹å‹•è¨ˆç®—
mean_diff = np.mean(diff)
std_diff = np.std(diff, ddof=1)  # ä¸åæ¨™æº–åå·®
n = len(diff)
t_statistic = mean_diff / (std_diff / np.sqrt(n))

# scipyã«ã‚ˆã‚‹æ¤œè¨¼
t_scipy, p_scipy = stats.ttest_rel(mae_a, mae_b)

print("=== å¯¾å¿œã®ã‚ã‚‹tæ¤œå®š ===")
print(f"å·®åˆ†ã®å¹³å‡: {mean_diff:.6f}")
print(f"å·®åˆ†ã®æ¨™æº–åå·®: {std_diff:.6f}")
print(f"tçµ±è¨ˆé‡ï¼ˆæ‰‹å‹•ï¼‰: {t_statistic:.4f}")
print(f"tçµ±è¨ˆé‡ï¼ˆscipyï¼‰: {t_scipy:.4f}")
print(f"på€¤: {p_scipy:.6f}")

if p_scipy < 0.01:
    print("\nçµè«–: ãƒ¢ãƒ‡ãƒ«Bã¯çµ±è¨ˆçš„ã«æœ‰æ„ã«å„ªã‚Œã¦ã„ã‚‹ (p < 0.01)")
else:
    print("\nçµè«–: çµ±è¨ˆçš„æœ‰æ„å·®ãªã—")</code></pre>
            </div>
        </div>

        <div class="exercise">
            <h4>æ¼”ç¿’ 4.3ï¼ˆMediumï¼‰: è¨ˆç®—ã‚³ã‚¹ãƒˆã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯</h4>
            <p>Random Forestã¨CGCNNã®è¨“ç·´ãƒ»æ¨è«–æ™‚é–“ã‚’å®Ÿæ¸¬ã—ã€ä»¥ä¸‹ã‚’è¨ˆç®—ã™ã‚‹ã‚³ãƒ¼ãƒ‰ã‚’ä½œæˆã—ã¦ãã ã•ã„ï¼š</p>
            <ol>
                <li>è¨“ç·´æ™‚é–“ã®æ¯”ï¼ˆCGCNN / RFï¼‰</li>
                <li>æ¨è«–æ™‚é–“ã®æ¯”ï¼ˆCGCNN / RFï¼‰</li>
                <li>GPUä½¿ç”¨æ™‚ã¨éä½¿ç”¨æ™‚ã®CGCNNè¨“ç·´æ™‚é–“ã®æ¯”</li>
            </ol>

            <div class="solution">
                <strong>è§£ç­”ä¾‹:</strong>
                <pre><code class="language-python">import time
import torch
from sklearn.ensemble import RandomForestRegressor

def benchmark_training(X_comp, X_struct, y, n_epochs=50):
    """
    è¨“ç·´æ™‚é–“ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
    """
    # Random Forestè¨“ç·´
    rf = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)
    start_rf = time.time()
    rf.fit(X_comp, y)
    time_rf = time.time() - start_rf

    # CGCNNè¨“ç·´ï¼ˆGPUï¼‰
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model_gpu = CGCNNModel().to(device)
    optimizer = torch.optim.Adam(model_gpu.parameters(), lr=0.001)
    criterion = torch.nn.MSELoss()
    train_loader = DataLoader(X_struct, batch_size=32, shuffle=True)

    start_cgcnn_gpu = time.time()
    model_gpu.train()
    for epoch in range(n_epochs):
        for batch in train_loader:
            batch = batch.to(device)
            optimizer.zero_grad()
            output = model_gpu(batch)
            loss = criterion(output, batch.y)
            loss.backward()
            optimizer.step()
    time_cgcnn_gpu = time.time() - start_cgcnn_gpu

    # CGCNNè¨“ç·´ï¼ˆCPUï¼‰
    model_cpu = CGCNNModel().to('cpu')
    optimizer = torch.optim.Adam(model_cpu.parameters(), lr=0.001)
    train_loader_cpu = DataLoader(X_struct, batch_size=32, shuffle=True)

    start_cgcnn_cpu = time.time()
    model_cpu.train()
    for epoch in range(n_epochs):
        for batch in train_loader_cpu:
            optimizer.zero_grad()
            output = model_cpu(batch)
            loss = criterion(output, batch.y)
            loss.backward()
            optimizer.step()
    time_cgcnn_cpu = time.time() - start_cgcnn_cpu

    # çµæœè¡¨ç¤º
    print("=== è¨“ç·´æ™‚é–“ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ ===")
    print(f"Random Forest: {time_rf:.2f}ç§’")
    print(f"CGCNN (GPU): {time_cgcnn_gpu:.2f}ç§’")
    print(f"CGCNN (CPU): {time_cgcnn_cpu:.2f}ç§’")
    print(f"\næ¯”ç‡:")
    print(f"  CGCNN (GPU) / RF: {time_cgcnn_gpu / time_rf:.1f}x")
    print(f"  CGCNN (CPU) / RF: {time_cgcnn_cpu / time_rf:.1f}x")
    print(f"  CGCNN (CPU) / CGCNN (GPU): {time_cgcnn_cpu / time_cgcnn_gpu:.1f}x")

# benchmark_training(X_magpie, dataset_pyg, y_band_gap)</code></pre>
            </div>
        </div>

        <div class="exercise">
            <h4>æ¼”ç¿’ 4.4ï¼ˆMediumï¼‰: å­¦ç¿’æ›²ç·šã®å®Ÿè£…ã¨è§£æ</h4>
            <p>è¨“ç·´ãƒ‡ãƒ¼ã‚¿å‰²åˆã‚’[10%, 30%, 50%, 70%, 100%]ã«å¤‰åŒ–ã•ã›ãªãŒã‚‰ã€Random Forestã¨CGCNNã®ãƒ†ã‚¹ãƒˆMAEã‚’æ¸¬å®šã—ã€å­¦ç¿’æ›²ç·šã‚’ãƒ—ãƒ­ãƒƒãƒˆã™ã‚‹ã‚³ãƒ¼ãƒ‰ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚</p>

            <div class="solution">
                <strong>è§£ç­”ä¾‹:</strong>
                <pre><code class="language-python">import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error

def plot_learning_curve_comparison(X_comp, X_struct, y, train_ratios=[0.1, 0.3, 0.5, 0.7, 1.0]):
    """
    å­¦ç¿’æ›²ç·šã®æ¯”è¼ƒãƒ—ãƒ­ãƒƒãƒˆ
    """
    mae_rf = []
    mae_cgcnn = []

    for ratio in train_ratios:
        print(f"\n=== è¨“ç·´ãƒ‡ãƒ¼ã‚¿å‰²åˆ: {ratio*100:.0f}% ===")

        # ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
        n_train = int(len(X_comp) * ratio)
        X_comp_train, X_comp_test, y_train, y_test = train_test_split(
            X_comp, y, train_size=n_train, random_state=42
        )

        # Random Forest
        rf = RandomForestRegressor(n_estimators=100, random_state=42)
        rf.fit(X_comp_train, y_train)
        y_pred_rf = rf.predict(X_comp_test)
        mae_rf_val = mean_absolute_error(y_test, y_pred_rf)
        mae_rf.append(mae_rf_val)

        # CGCNNï¼ˆç°¡ç•¥ç‰ˆï¼‰
        X_struct_train = X_struct[:n_train]
        X_struct_test = X_struct[n_train:]

        model = CGCNNModel().to(device)
        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
        criterion = torch.nn.MSELoss()
        train_loader = DataLoader(X_struct_train, batch_size=32, shuffle=True)
        test_loader = DataLoader(X_struct_test, batch_size=32)

        # è¨“ç·´
        for epoch in range(50):
            model.train()
            for batch in train_loader:
                batch = batch.to(device)
                optimizer.zero_grad()
                output = model(batch)
                loss = criterion(output, batch.y)
                loss.backward()
                optimizer.step()

        # è©•ä¾¡
        model.eval()
        predictions = []
        targets = []
        with torch.no_grad():
            for batch in test_loader:
                batch = batch.to(device)
                pred = model(batch)
                predictions.extend(pred.cpu().numpy())
                targets.extend(batch.y.cpu().numpy())

        mae_cgcnn_val = mean_absolute_error(targets, predictions)
        mae_cgcnn.append(mae_cgcnn_val)

        print(f"RF MAE: {mae_rf_val:.4f}, CGCNN MAE: {mae_cgcnn_val:.4f}")

    # ãƒ—ãƒ­ãƒƒãƒˆ
    fig, ax = plt.subplots(figsize=(10, 6))
    train_sizes = [int(len(X_comp) * r) for r in train_ratios]

    ax.plot(train_sizes, mae_rf, 'o-', label='Random Forest', linewidth=2, markersize=8)
    ax.plot(train_sizes, mae_cgcnn, 's-', label='CGCNN', linewidth=2, markersize=8)

    ax.set_xlabel('è¨“ç·´ãƒ‡ãƒ¼ã‚¿æ•°', fontsize=12)
    ax.set_ylabel('ãƒ†ã‚¹ãƒˆMAE (eV/atom)', fontsize=12)
    ax.set_title('å­¦ç¿’æ›²ç·š: ãƒ‡ãƒ¼ã‚¿åŠ¹ç‡æ€§ã®æ¯”è¼ƒ', fontsize=14, fontweight='bold')
    ax.legend(fontsize=12)
    ax.grid(alpha=0.3)
    plt.tight_layout()
    plt.show()

# plot_learning_curve_comparison(X_magpie, dataset_pyg, y_band_gap)</code></pre>
            </div>
        </div>

        <div class="exercise">
            <h4>æ¼”ç¿’ 4.5ï¼ˆMediumï¼‰: SHAPå€¤ã«ã‚ˆã‚‹ç‰¹å¾´é‡é‡è¦åº¦åˆ†æ</h4>
            <p>Random Forestãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦SHAPå€¤ã‚’è¨ˆç®—ã—ã€ä¸Šä½10ä»¶ã®é‡è¦ç‰¹å¾´é‡ã‚’å¯è¦–åŒ–ã™ã‚‹ã‚³ãƒ¼ãƒ‰ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚ã•ã‚‰ã«ã€ã“ã‚Œã‚‰ã®ç‰¹å¾´é‡ãŒææ–™ç§‘å­¦çš„ã«å¦¥å½“ã‹ã‚’è­°è«–ã—ã¦ãã ã•ã„ã€‚</p>

            <div class="solution">
                <strong>è§£ç­”ä¾‹:</strong>
                <pre><code class="language-python">import shap
import matplotlib.pyplot as plt
import numpy as np

# Random Forestãƒ¢ãƒ‡ãƒ«ï¼ˆè¨“ç·´æ¸ˆã¿ï¼‰
rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
rf_model.fit(X_magpie_train, y_train)

# SHAP Explainer
explainer = shap.TreeExplainer(rf_model)
shap_values = explainer.shap_values(X_magpie_test)

# ç‰¹å¾´é‡é‡è¦åº¦ã®è¨ˆç®—
feature_importance = np.abs(shap_values).mean(axis=0)
top_10_idx = np.argsort(feature_importance)[-10:][::-1]

# å¯è¦–åŒ–
plt.figure(figsize=(10, 6))
plt.barh(range(10), feature_importance[top_10_idx])
plt.yticks(range(10), [magpie_feature_names[i] for i in top_10_idx])
plt.xlabel('å¹³å‡ |SHAPå€¤|', fontsize=12)
plt.title('ä¸Šä½10ä»¶ã®é‡è¦ç‰¹å¾´é‡ï¼ˆSHAPå€¤ï¼‰', fontsize=14, fontweight='bold')
plt.gca().invert_yaxis()
plt.tight_layout()
plt.show()

# æ•°å€¤è¡¨ç¤º
print("=== ä¸Šä½10ä»¶ã®é‡è¦ç‰¹å¾´é‡ ===")
for rank, idx in enumerate(top_10_idx):
    print(f"{rank+1}. {magpie_feature_names[idx]}: {feature_importance[idx]:.4f}")

# ææ–™ç§‘å­¦çš„è€ƒå¯Ÿï¼ˆä¾‹ï¼‰
print("\n=== ææ–™ç§‘å­¦çš„è€ƒå¯Ÿ ===")
print("1. 'mean Electronegativity'ãŒæœ€é‡è¦ â†’ é›»å­è¦ªå’Œæ€§ãŒãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—ã«å¼·ãå½±éŸ¿")
print("2. 'mean AtomicVolume'ãŒä¸Šä½ â†’ åŸå­ã‚µã‚¤ã‚ºãŒçµæ™¶æ§‹é€ ã«å½±éŸ¿")
print("3. 'range Electronegativity'ãŒä¸Šä½ â†’ å…ƒç´ é–“ã®é›»æ°—é™°æ€§åº¦å·®ãŒé‡è¦")</code></pre>
            </div>
        </div>

        <div class="exercise">
            <h4>æ¼”ç¿’ 4.6ï¼ˆHardï¼‰: çµ±è¨ˆçš„æ¤œå®šã®åŒ…æ‹¬çš„åˆ†æ</h4>
            <p>5-fold Cross-validationã®çµæœã«å¯¾ã—ã¦ã€ä»¥ä¸‹ã®çµ±è¨ˆçš„æ¤œå®šã‚’å®Ÿæ–½ã—ã€åŒ…æ‹¬çš„ãªãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã™ã‚‹ã‚³ãƒ¼ãƒ‰ã‚’ä½œæˆã—ã¦ãã ã•ã„ï¼š</p>
            <ol>
                <li>å¯¾å¿œã®ã‚ã‚‹tæ¤œå®šï¼ˆpaired t-testï¼‰</li>
                <li>95%ä¿¡é ¼åŒºé–“ã®è¨ˆç®—</li>
                <li>Cohen's dåŠ¹æœé‡ã®è¨ˆç®—</li>
                <li>Wilcoxonç¬¦å·é †ä½æ¤œå®šï¼ˆãƒãƒ³ãƒ‘ãƒ©ãƒ¡ãƒˆãƒªãƒƒã‚¯æ¤œå®šï¼‰</li>
            </ol>

            <div class="solution">
                <strong>è§£ç­”ä¾‹:</strong>
                <pre><code class="language-python">import numpy as np
from scipy import stats

def comprehensive_statistical_test(mae_model1, mae_model2, model1_name="Model 1", model2_name="Model 2"):
    """
    åŒ…æ‹¬çš„ãªçµ±è¨ˆçš„æ¤œå®š

    Args:
        mae_model1: ãƒ¢ãƒ‡ãƒ«1ã®MAEï¼ˆ5-fold CVï¼‰
        mae_model2: ãƒ¢ãƒ‡ãƒ«2ã®MAEï¼ˆ5-fold CVï¼‰
        model1_name: ãƒ¢ãƒ‡ãƒ«1ã®åå‰
        model2_name: ãƒ¢ãƒ‡ãƒ«2ã®åå‰
    """
    # 1. å¯¾å¿œã®ã‚ã‚‹tæ¤œå®š
    t_statistic, p_value = stats.ttest_rel(mae_model1, mae_model2)

    # 2. 95%ä¿¡é ¼åŒºé–“
    diff = mae_model1 - mae_model2
    mean_diff = np.mean(diff)
    se_diff = stats.sem(diff)  # æ¨™æº–èª¤å·®
    ci_95 = stats.t.interval(0.95, len(diff)-1, loc=mean_diff, scale=se_diff)

    # 3. Cohen's dåŠ¹æœé‡
    pooled_std = np.sqrt((np.var(mae_model1, ddof=1) + np.var(mae_model2, ddof=1)) / 2)
    cohens_d = mean_diff / pooled_std

    # 4. Wilcoxonç¬¦å·é †ä½æ¤œå®š
    wilcoxon_statistic, wilcoxon_p = stats.wilcoxon(mae_model1, mae_model2)

    # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    print("=" * 60)
    print("çµ±è¨ˆçš„æ¤œå®šãƒ¬ãƒãƒ¼ãƒˆ")
    print("=" * 60)
    print(f"\nãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ: {model1_name} vs {model2_name}\n")

    print(f"{model1_name} MAE: {mae_model1}")
    print(f"{model2_name} MAE: {mae_model2}\n")

    print("--- è¨˜è¿°çµ±è¨ˆ ---")
    print(f"{model1_name} å¹³å‡MAE: {np.mean(mae_model1):.6f} Â± {np.std(mae_model1, ddof=1):.6f}")
    print(f"{model2_name} å¹³å‡MAE: {np.mean(mae_model2):.6f} Â± {np.std(mae_model2, ddof=1):.6f}")
    print(f"å·®åˆ†ã®å¹³å‡: {mean_diff:.6f}\n")

    print("--- 1. å¯¾å¿œã®ã‚ã‚‹tæ¤œå®š ---")
    print(f"tçµ±è¨ˆé‡: {t_statistic:.4f}")
    print(f"på€¤: {p_value:.6f}")
    if p_value < 0.01:
        print("çµè«–: çµ±è¨ˆçš„ã«æœ‰æ„ãªå·®ã‚ã‚Š (p < 0.01) â­â­â­")
    elif p_value < 0.05:
        print("çµè«–: çµ±è¨ˆçš„ã«æœ‰æ„ãªå·®ã‚ã‚Š (p < 0.05) â­â­")
    else:
        print("çµè«–: çµ±è¨ˆçš„æœ‰æ„å·®ãªã— (p >= 0.05)\n")

    print("\n--- 2. 95%ä¿¡é ¼åŒºé–“ ---")
    print(f"å·®åˆ†ã®95%ä¿¡é ¼åŒºé–“: [{ci_95[0]:.6f}, {ci_95[1]:.6f}]")
    if ci_95[0] > 0:
        print(f"è§£é‡ˆ: {model2_name}ã¯ç¢ºå®Ÿã«å„ªã‚Œã¦ã„ã‚‹ï¼ˆä¿¡é ¼åŒºé–“ãŒ0ã‚’å«ã¾ãªã„ï¼‰")
    else:
        print("è§£é‡ˆ: å·®ãŒãªã„å¯èƒ½æ€§ã‚‚å«ã‚€ï¼ˆä¿¡é ¼åŒºé–“ãŒ0ã‚’å«ã‚€ï¼‰\n")

    print("\n--- 3. Cohen's dåŠ¹æœé‡ ---")
    print(f"Cohen's d: {cohens_d:.4f}")
    if abs(cohens_d) < 0.2:
        effect_size = "å°ï¼ˆåŠ¹æœå°ï¼‰"
    elif abs(cohens_d) < 0.5:
        effect_size = "ä¸­ï¼ˆåŠ¹æœä¸­ï¼‰"
    elif abs(cohens_d) < 0.8:
        effect_size = "å¤§ï¼ˆåŠ¹æœå¤§ï¼‰"
    else:
        effect_size = "éå¸¸ã«å¤§ï¼ˆåŠ¹æœéå¸¸ã«å¤§ï¼‰"
    print(f"åŠ¹æœé‡ã®è§£é‡ˆ: {effect_size}\n")

    print("--- 4. Wilcoxonç¬¦å·é †ä½æ¤œå®šï¼ˆãƒãƒ³ãƒ‘ãƒ©ãƒ¡ãƒˆãƒªãƒƒã‚¯ï¼‰ ---")
    print(f"Wilcoxonçµ±è¨ˆé‡: {wilcoxon_statistic:.4f}")
    print(f"på€¤: {wilcoxon_p:.6f}")
    if wilcoxon_p < 0.05:
        print("çµè«–: ãƒãƒ³ãƒ‘ãƒ©ãƒ¡ãƒˆãƒªãƒƒã‚¯æ¤œå®šã§ã‚‚æœ‰æ„å·®ã‚ã‚Š\n")
    else:
        print("çµè«–: ãƒãƒ³ãƒ‘ãƒ©ãƒ¡ãƒˆãƒªãƒƒã‚¯æ¤œå®šã§ã¯æœ‰æ„å·®ãªã—\n")

    print("=" * 60)
    print("ç·åˆçµè«–")
    print("=" * 60)
    if p_value < 0.01 and ci_95[0] > 0:
        print(f"{model2_name}ã¯{model1_name}ã‚ˆã‚Šã‚‚çµ±è¨ˆçš„ã«æœ‰æ„ã«å„ªã‚Œã¦ã„ã¾ã™ã€‚")
        print(f"å¹³å‡ã—ã¦{mean_diff:.6f}ã®æ”¹å–„ãŒã‚ã‚Šã€ã“ã‚Œã¯{effect_size}ã§ã™ã€‚")
    else:
        print("ä¸¡ãƒ¢ãƒ‡ãƒ«é–“ã«æ˜ç¢ºãªçµ±è¨ˆçš„å„ªä½æ€§ã¯ç¢ºèªã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")

# ä½¿ç”¨ä¾‹
mae_rf = np.array([0.0325, 0.0338, 0.0312, 0.0329, 0.0321])
mae_cgcnn = np.array([0.0286, 0.0293, 0.0279, 0.0288, 0.0284])

comprehensive_statistical_test(mae_rf, mae_cgcnn, "Random Forest", "CGCNN")</code></pre>
            </div>
        </div>

        <div class="exercise">
            <h4>æ¼”ç¿’ 4.7ï¼ˆHardï¼‰: å®Ÿãƒ‡ãƒ¼ã‚¿ã§ã®åŒ…æ‹¬çš„æ¯”è¼ƒ</h4>
            <p>Matbenchã®<code>matbench_mp_e_form</code>ï¼ˆå½¢æˆã‚¨ãƒãƒ«ã‚®ãƒ¼äºˆæ¸¬ï¼‰ã‚¿ã‚¹ã‚¯ã«å¯¾ã—ã¦ã€Random Forestã¨CGCNNã‚’å®Ÿè£…ã—ã€æœ¬ç« ã§å­¦ã‚“ã 7ã¤ã®è¦³ç‚¹ã™ã¹ã¦ã§æ¯”è¼ƒè©•ä¾¡ã™ã‚‹ã‚³ãƒ¼ãƒ‰ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚</p>

            <div class="solution">
                <strong>è§£ç­”ä¾‹:</strong>
                <pre><code class="language-python"># åŒ…æ‹¬çš„æ¯”è¼ƒãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆï¼ˆç´„200è¡Œã®ã‚³ãƒ¼ãƒ‰ï¼‰
from matbench.bench import MatbenchBenchmark
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error
import torch
import time
import shap
import numpy as np

# 1. ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
mb = MatbenchBenchmark(autoload=False)
task = mb.matbench_mp_e_form
task.load()

# 2. ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ï¼ˆMagpieï¼‰
# ... (ã‚³ãƒ¼ãƒ‰ä¾‹1å‚ç…§)

# 3. PyG Datasetä½œæˆ
# ... (ã‚³ãƒ¼ãƒ‰ä¾‹2å‚ç…§)

# 4. 5-fold Cross-validation
mae_rf_folds = []
mae_cgcnn_folds = []
time_rf_folds = []
time_cgcnn_folds = []

for fold in task.folds:
    train_inputs, train_outputs = task.get_train_and_val_data(fold)

    # Random Forest
    start_rf = time.time()
    X_train_magpie = compute_magpie_features(train_inputs)
    rf_model = RandomForestRegressor(n_estimators=100, n_jobs=-1, random_state=42)
    rf_model.fit(X_train_magpie, train_outputs)
    time_rf = time.time() - start_rf
    time_rf_folds.append(time_rf)

    # è©•ä¾¡
    test_inputs, test_outputs = task.get_test_data(fold, include_target=True)
    X_test_magpie = compute_magpie_features(test_inputs)
    y_pred_rf = rf_model.predict(X_test_magpie)
    mae_rf = mean_absolute_error(test_outputs, y_pred_rf)
    mae_rf_folds.append(mae_rf)

    # CGCNN
    start_cgcnn = time.time()
    # ... è¨“ç·´ã‚³ãƒ¼ãƒ‰ ...
    time_cgcnn = time.time() - start_cgcnn
    time_cgcnn_folds.append(time_cgcnn)

    # è©•ä¾¡
    # ... è©•ä¾¡ã‚³ãƒ¼ãƒ‰ ...
    mae_cgcnn_folds.append(mae_cgcnn)

# 5. çµ±è¨ˆçš„æ¤œå®š
comprehensive_statistical_test(np.array(mae_rf_folds), np.array(mae_cgcnn_folds),
                               "Random Forest", "CGCNN")

# 6. å­¦ç¿’æ›²ç·š
plot_learning_curve_comparison(X_magpie, dataset_pyg, y)

# 7. SHAPè§£æ
explainer = shap.TreeExplainer(rf_model)
shap_values = explainer.shap_values(X_test_magpie)
shap.summary_plot(shap_values, X_test_magpie, show=False)
plt.savefig('shap_analysis.png')

print("\n=== æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆ ===")
print(f"Random Forest å¹³å‡MAE: {np.mean(mae_rf_folds):.4f} Â± {np.std(mae_rf_folds):.4f}")
print(f"CGCNN å¹³å‡MAE: {np.mean(mae_cgcnn_folds):.4f} Â± {np.std(mae_cgcnn_folds):.4f}")
print(f"å¹³å‡è¨“ç·´æ™‚é–“: RF={np.mean(time_rf_folds):.2f}s, CGCNN={np.mean(time_cgcnn_folds):.2f}s")</code></pre>
            </div>
        </div>

        <div class="exercise">
            <h4>æ¼”ç¿’ 4.8ï¼ˆHardï¼‰: ã‚«ã‚¹ã‚¿ãƒ æ±ºå®šæœ¨ã‚·ã‚¹ãƒ†ãƒ ã®å®Ÿè£…</h4>
            <p>ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®åˆ¶ç´„æ¡ä»¶ï¼ˆãƒ‡ãƒ¼ã‚¿æ•°ã€è¨ˆç®—ãƒªã‚½ãƒ¼ã‚¹ã€ç²¾åº¦è¦æ±‚ï¼‰ã‚’å…¥åŠ›ã¨ã—ã¦ã€æœ€é©ãªãƒ¢ãƒ‡ãƒ«ã‚’æ¨è–¦ã™ã‚‹å¯¾è©±å‹æ±ºå®šæœ¨ã‚·ã‚¹ãƒ†ãƒ ã‚’å®Ÿè£…ã—ã¦ãã ã•ã„ã€‚</p>

            <div class="solution">
                <strong>è§£ç­”ä¾‹:</strong>
                <pre><code class="language-python">class ModelRecommender:
    """
    ãƒ¢ãƒ‡ãƒ«æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ 
    """
    def __init__(self):
        self.recommendations = []

    def analyze_project(self, data_size, has_gpu, time_budget_hours,
                       accuracy_priority, interpretability_priority):
        """
        ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ¡ä»¶ã‚’åˆ†æã—ã€æœ€é©ãƒ¢ãƒ‡ãƒ«ã‚’æ¨è–¦

        Args:
            data_size: è¨“ç·´ãƒ‡ãƒ¼ã‚¿æ•°
            has_gpu: GPUåˆ©ç”¨å¯èƒ½ã‹
            time_budget_hours: è¨“ç·´æ™‚é–“äºˆç®—ï¼ˆæ™‚é–“ï¼‰
            accuracy_priority: ç²¾åº¦å„ªå…ˆåº¦ï¼ˆ1-10ï¼‰
            interpretability_priority: è§£é‡ˆå¯èƒ½æ€§å„ªå…ˆåº¦ï¼ˆ1-10ï¼‰

        Returns:
            æ¨è–¦çµæœè¾æ›¸
        """
        score_rf = 0
        score_cgcnn = 0
        reasons = []

        # ãƒ‡ãƒ¼ã‚¿è¦æ¨¡ã«ã‚ˆã‚‹è©•ä¾¡
        if data_size < 5000:
            score_rf += 50
            reasons.append("ãƒ‡ãƒ¼ã‚¿æ•°ãŒå°‘ãªã„(<5,000ä»¶) â†’ RFãŒå®‰å®š")
        elif data_size < 10000:
            score_rf += 20
            score_cgcnn += 20
            reasons.append("ä¸­è¦æ¨¡ãƒ‡ãƒ¼ã‚¿(5,000-10,000ä»¶) â†’ ä¸¡æ–¹æ¤œè¨å¯èƒ½")
        else:
            score_cgcnn += 50
            reasons.append("å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿(>10,000ä»¶) â†’ CGCNNãŒç²¾åº¦å„ªä½")

        # è¨ˆç®—ãƒªã‚½ãƒ¼ã‚¹
        if not has_gpu:
            score_rf += 30
            reasons.append("GPUåˆ©ç”¨ä¸å¯ â†’ RFãŒé«˜é€Ÿ")
        else:
            score_cgcnn += 20
            reasons.append("GPUåˆ©ç”¨å¯ â†’ CGCNNè¨“ç·´æ™‚é–“çŸ­ç¸®")

        # æ™‚é–“äºˆç®—
        if time_budget_hours < 1:
            score_rf += 40
            reasons.append("æ™‚é–“äºˆç®—ãŒå³ã—ã„(<1æ™‚é–“) â†’ RFãŒé©åˆ‡")
        elif time_budget_hours < 3:
            score_rf += 10
            score_cgcnn += 10
        else:
            score_cgcnn += 20
            reasons.append("æ™‚é–“äºˆç®—ã«ä½™è£•ã‚ã‚Š â†’ CGCNNæ¤œè¨å¯èƒ½")

        # ç²¾åº¦å„ªå…ˆåº¦
        score_cgcnn += accuracy_priority * 3
        if accuracy_priority >= 8:
            reasons.append("ç²¾åº¦ãŒæœ€é‡è¦ â†’ CGCNNãŒ12%æ”¹å–„æœŸå¾…")

        # è§£é‡ˆå¯èƒ½æ€§å„ªå…ˆåº¦
        score_rf += interpretability_priority * 3
        if interpretability_priority >= 8:
            reasons.append("è§£é‡ˆå¯èƒ½æ€§ãŒé‡è¦ â†’ RFã®SHAPè§£æãŒç›´æ„Ÿçš„")

        # æ¨è–¦æ±ºå®š
        if score_rf > score_cgcnn:
            recommendation = "Random Forest (Magpie)"
            confidence = min(100, int((score_rf / (score_rf + score_cgcnn)) * 100))
        else:
            recommendation = "CGCNN"
            confidence = min(100, int((score_cgcnn / (score_rf + score_cgcnn)) * 100))

        return {
            'recommendation': recommendation,
            'confidence': confidence,
            'score_rf': score_rf,
            'score_cgcnn': score_cgcnn,
            'reasons': reasons
        }

    def interactive_recommendation(self):
        """å¯¾è©±å‹æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ """
        print("=" * 60)
        print("ææ–™ç‰©æ€§äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ ")
        print("=" * 60)

        data_size = int(input("\n1. è¨“ç·´ãƒ‡ãƒ¼ã‚¿æ•°ï¼ˆä¾‹: 5000ï¼‰: "))
        has_gpu = input("2. GPUåˆ©ç”¨å¯èƒ½ã§ã™ã‹ï¼Ÿ (yes/no): ").lower() == 'yes'
        time_budget = float(input("3. è¨“ç·´æ™‚é–“äºˆç®—ï¼ˆæ™‚é–“å˜ä½ã€ä¾‹: 2ï¼‰: "))
        accuracy_priority = int(input("4. ç²¾åº¦å„ªå…ˆåº¦ï¼ˆ1-10ã€10ãŒæœ€é«˜ï¼‰: "))
        interpretability_priority = int(input("5. è§£é‡ˆå¯èƒ½æ€§å„ªå…ˆåº¦ï¼ˆ1-10ï¼‰: "))

        result = self.analyze_project(data_size, has_gpu, time_budget,
                                      accuracy_priority, interpretability_priority)

        print("\n" + "=" * 60)
        print("æ¨è–¦çµæœ")
        print("=" * 60)
        print(f"\næ¨è–¦ãƒ¢ãƒ‡ãƒ«: {result['recommendation']}")
        print(f"ä¿¡é ¼åº¦: {result['confidence']}%")
        print(f"\nã‚¹ã‚³ã‚¢: RF={result['score_rf']}, CGCNN={result['score_cgcnn']}")
        print("\nç†ç”±:")
        for i, reason in enumerate(result['reasons'], 1):
            print(f"  {i}. {reason}")

        return result

# ä½¿ç”¨ä¾‹
recommender = ModelRecommender()
# result = recommender.interactive_recommendation()</code></pre>
            </div>
        </div>

        <h2>å‚è€ƒæ–‡çŒ®</h2>

        <ol>
            <li>Dunn, A., Wang, Q., Ganose, A., Dopp, D., & Jain, A. (2020). Benchmarking materials property prediction methods: the Matbench test set and Automatminer reference algorithm. <em>npj Computational Materials</em>, 6(1), 138. DOI: 10.1038/s41524-020-00406-3, pp. 1-10. (Matbenchãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®å…¬å¼è«–æ–‡)</li>

            <li>Xie, T., & Grossman, J. C. (2018). Crystal Graph Convolutional Neural Networks for an Accurate and Interpretable Prediction of Material Properties. <em>Physical Review Letters</em>, 120(14), 145301. DOI: 10.1103/PhysRevLett.120.145301, pp. 1-6. (CGCNNææ¡ˆè«–æ–‡)</li>

            <li>Lundberg, S. M., & Lee, S. I. (2017). A Unified Approach to Interpreting Model Predictions. In <em>Advances in Neural Information Processing Systems</em> (NIPS), 30, 4765-4774. arXiv:1705.07874, pp. 4765-4774. (SHAPå€¤ã®ç†è«–çš„åŸºç¤)</li>

            <li>Cohen, J. (1988). <em>Statistical Power Analysis for the Behavioral Sciences</em> (2nd ed.). Lawrence Erlbaum Associates, pp. 20-27. (Cohen's dåŠ¹æœé‡ã®å®šç¾©ã¨è§£é‡ˆ)</li>

            <li>Ward, L., Agrawal, A., Choudhary, A., & Wolverton, C. (2016). A general-purpose machine learning framework for predicting properties of inorganic materials. <em>npj Computational Materials</em>, 2, 16028. DOI: 10.1038/npjcompumats.2016.28, pp. 1-7. (Magpieç‰¹å¾´é‡ã®ææ¡ˆè«–æ–‡)</li>

            <li>Vaswani, A., Shazeer, N., Parmar, N., et al. (2017). Attention is All You Need. In <em>Advances in Neural Information Processing Systems</em> (NIPS), 30, 5998-6008. arXiv:1706.03762, pp. 5998-6008. (Attentionãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã®åŸºç¤è«–æ–‡)</li>

            <li>Breiman, L. (2001). Random Forests. <em>Machine Learning</em>, 45(1), 5-32. DOI: 10.1023/A:1010933404324, pp. 5-32. (Random Forestã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®åŸè«–æ–‡)</li>

            <li>Dietterich, T. G. (1998). Approximate Statistical Tests for Comparing Supervised Classification Learning Algorithms. <em>Neural Computation</em>, 10(7), 1895-1923. DOI: 10.1162/089976698300017197, pp. 1895-1923. (æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒã«ãŠã‘ã‚‹çµ±è¨ˆçš„æ¤œå®šã®ç†è«–)</li>
        </ol>

        <a href="index.html" class="back-link">â† ã‚·ãƒªãƒ¼ã‚ºãƒˆãƒƒãƒ—ã«æˆ»ã‚‹</a>
    </div>
<section class="disclaimer">
<h3>å…è²¬äº‹é …</h3>
<ul>
<li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯æ•™è‚²ãƒ»ç ”ç©¶ãƒ»æƒ…å ±æä¾›ã®ã¿ã‚’ç›®çš„ã¨ã—ã¦ãŠã‚Šã€å°‚é–€çš„ãªåŠ©è¨€(æ³•å¾‹ãƒ»ä¼šè¨ˆãƒ»æŠ€è¡“çš„ä¿è¨¼ãªã©)ã‚’æä¾›ã™ã‚‹ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚</li>
<li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŠã‚ˆã³ä»˜éšã™ã‚‹Code examplesã¯ã€Œç¾çŠ¶æœ‰å§¿(AS IS)ã€ã§æä¾›ã•ã‚Œã€æ˜ç¤ºã¾ãŸã¯é»™ç¤ºã‚’å•ã‚ãšã€å•†å“æ€§ã€ç‰¹å®šç›®çš„é©åˆæ€§ã€æ¨©åˆ©éä¾µå®³ã€æ­£ç¢ºæ€§ãƒ»å®Œå…¨æ€§ã€å‹•ä½œãƒ»å®‰å…¨æ€§ç­‰ã„ã‹ãªã‚‹ä¿è¨¼ã‚‚ã—ã¾ã›ã‚“ã€‚</li>
<li>å¤–éƒ¨ãƒªãƒ³ã‚¯ã€ç¬¬ä¸‰è€…ãŒæä¾›ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ»ãƒ„ãƒ¼ãƒ«ãƒ»ãƒ©ã‚¤ãƒ–ãƒ©ãƒªç­‰ã®å†…å®¹ãƒ»å¯ç”¨æ€§ãƒ»å®‰å…¨æ€§ã«ã¤ã„ã¦ã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯ä¸€åˆ‡ã®è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚</li>
<li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®åˆ©ç”¨ãƒ»å®Ÿè¡Œãƒ»è§£é‡ˆã«ã‚ˆã‚Šç›´æ¥çš„ãƒ»é–“æ¥çš„ãƒ»ä»˜éšçš„ãƒ»ç‰¹åˆ¥ãƒ»çµæœçš„ãƒ»æ‡²ç½°çš„æå®³ãŒç”Ÿã˜ãŸå ´åˆã§ã‚‚ã€é©ç”¨æ³•ã§è¨±å®¹ã•ã‚Œã‚‹æœ€å¤§é™ã®ç¯„å›²ã§ã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚</li>
<li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å†…å®¹ã¯ã€äºˆå‘Šãªãå¤‰æ›´ãƒ»æ›´æ–°ãƒ»æä¾›åœæ­¢ã•ã‚Œã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚</li>
<li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®è‘—ä½œæ¨©ãƒ»ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯æ˜è¨˜ã•ã‚ŒãŸæ¡ä»¶(ä¾‹: CC BY 4.0)ã«å¾“ã„ã¾ã™ã€‚å½“è©²ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯é€šå¸¸ã€ç„¡ä¿è¨¼æ¡é …ã‚’å«ã¿ã¾ã™ã€‚</li>
</ul>
</section>

</body>
</html>