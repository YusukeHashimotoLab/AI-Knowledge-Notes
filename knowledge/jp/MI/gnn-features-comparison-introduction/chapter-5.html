<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ç¬¬5ç« ï¼šãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ | GNNç‰¹å¾´é‡æ¯”è¼ƒå…¥é–€</title>
    <meta name="description" content="çµ„æˆãƒ™ãƒ¼ã‚¹ã¨GNNæ§‹é€ ãƒ™ãƒ¼ã‚¹ç‰¹å¾´é‡ã‚’çµ±åˆã—ãŸãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«ã€‚ALIGNNã€MEGNetã€ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯å­¦ç¿’ã®å®Ÿè£…ã¨æ€§èƒ½è©•ä¾¡ã€‚">

    <!-- MathJax 3.x for mathematical equations -->
    <script>
    MathJax = {
        tex: {
            inlineMath: [['$', '$'], ['\\(', '\\)']],
            displayMath: [['$$', '$$'], ['\\[', '\\]']],
            processEscapes: true,
            processEnvironments: true
        },
        options: {
            skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        }
    };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

    <!-- Mermaid for diagrams -->
    <script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
    <script>
        mermaid.initialize({
            startOnLoad: true,
            theme: 'default',
            themeVariables: {
                primaryColor: '#667eea',
                primaryTextColor: '#fff',
                primaryBorderColor: '#764ba2',
                lineColor: '#764ba2',
                secondaryColor: '#764ba2',
                tertiaryColor: '#fff'
            }
        });
    </script>

    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css" rel="stylesheet" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>

    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Noto Sans JP', sans-serif;
            line-height: 1.8;
            color: #2c3e50;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            padding: 2rem 1rem;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            background: white;
            border-radius: 12px;
            box-shadow: 0 8px 32px rgba(0,0,0,0.1);
            padding: 3rem;
        }

        h1 {
            font-size: 2.5rem;
            margin-bottom: 1.5rem;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }

        h2 {
            font-size: 1.8rem;
            margin: 2.5rem 0 1.5rem;
            color: #667eea;
            border-left: 4px solid #764ba2;
            padding-left: 1rem;
        }

        h3 {
            font-size: 1.4rem;
            margin: 2rem 0 1rem;
            color: #764ba2;
        }

        p {
            margin-bottom: 1.2rem;
            text-align: justify;
        }

        .highlight-box {
            background: linear-gradient(135deg, rgba(102, 126, 234, 0.1) 0%, rgba(118, 75, 162, 0.1) 100%);
            border-left: 4px solid #667eea;
            padding: 1.5rem;
            margin: 1.5rem 0;
            border-radius: 8px;
        }

        .warning-box {
            background: rgba(255, 193, 7, 0.1);
            border-left: 4px solid #ffc107;
            padding: 1.5rem;
            margin: 1.5rem 0;
            border-radius: 8px;
        }

        pre {
            background: #2d2d2d;
            border-radius: 8px;
            padding: 1.5rem;
            overflow-x: auto;
            margin: 1.5rem 0;
        }

        code {
            font-family: 'Consolas', 'Monaco', 'Courier New', monospace;
            font-size: 0.9rem;
        }

        .mermaid {
            background: white;
            padding: 2rem;
            border-radius: 8px;
            margin: 2rem 0;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin: 1.5rem 0;
            box-shadow: 0 2px 8px rgba(0,0,0,0.1);
        }

        th, td {
            padding: 1rem;
            text-align: left;
            border-bottom: 1px solid #e0e0e0;
        }

        th {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            font-weight: 600;
        }

        tr:hover {
            background: rgba(102, 126, 234, 0.05);
        }

        .exercise {
            background: rgba(118, 75, 162, 0.05);
            border: 2px solid #764ba2;
            border-radius: 8px;
            padding: 1.5rem;
            margin: 1.5rem 0;
        }

        .exercise-header {
            font-weight: 600;
            color: #764ba2;
            margin-bottom: 0.5rem;
        }

        .difficulty {
            display: inline-block;
            padding: 0.25rem 0.75rem;
            border-radius: 4px;
            font-size: 0.85rem;
            font-weight: 600;
            margin-left: 0.5rem;
        }

        .difficulty-easy {
            background: #4caf50;
            color: white;
        }

        .difficulty-medium {
            background: #ff9800;
            color: white;
        }

        .difficulty-hard {
            background: #f44336;
            color: white;
        }

        .nav-buttons {
            display: flex;
            justify-content: space-between;
            margin-top: 3rem;
            padding-top: 2rem;
            border-top: 2px solid #e0e0e0;
        }

        .nav-button {
            padding: 0.75rem 1.5rem;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            text-decoration: none;
            border-radius: 6px;
            font-weight: 600;
            transition: transform 0.2s;
        }

        .nav-button:hover {
            transform: translateY(-2px);
        }

        ul, ol {
            margin: 1rem 0 1rem 2rem;
        }

        li {
            margin-bottom: 0.5rem;
        }

        @media (max-width: 768px) {
            .container {
                padding: 1.5rem;
            }

            h1 {
                font-size: 2rem;
            }

            h2 {
                font-size: 1.5rem;
            }

            pre {
                padding: 1rem;
                font-size: 0.85rem;
            }
        }
    </style>

    <style>
        /* Locale Switcher Styles */
        .locale-switcher {
            display: flex;
            align-items: center;
            gap: 0.5rem;
            padding: 0.5rem 1rem;
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
            border-radius: 6px;
            font-size: 0.9rem;
            margin-bottom: 1rem;
            box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);
        }

        .current-locale {
            font-weight: 600;
            color: #7b2cbf;
            display: flex;
            align-items: center;
            gap: 0.25rem;
        }

        .locale-separator {
            color: #adb5bd;
            font-weight: 300;
        }

        .locale-link {
            color: #f093fb;
            text-decoration: none;
            font-weight: 500;
            transition: all 0.2s ease;
            display: flex;
            align-items: center;
            gap: 0.25rem;
            padding: 0.2rem 0.5rem;
            border-radius: 4px;
        }

        .locale-link:hover {
            background: rgba(240, 147, 251, 0.1);
            color: #d07be8;
            transform: translateY(-1px);
        }

        .locale-meta {
            color: #868e96;
            font-size: 0.85rem;
            font-style: italic;
            margin-left: auto;
        }

        @media (max-width: 768px) {
            .locale-switcher {
                font-size: 0.85rem;
                padding: 0.4rem 0.8rem;
            }
            .locale-meta {
                display: none;
            }
        }
    </style>
</head>
<body>
    <div class="locale-switcher">
<span class="current-locale">ğŸŒ JP</span>
<span class="locale-separator">|</span>
<a href="../../../en/MI/gnn-features-comparison-introduction/chapter-5.html" class="locale-link">ğŸ‡¬ğŸ‡§ EN</a>
<span class="locale-separator">|</span>
<span class="locale-meta">Last sync: 2025-11-16</span>
</div>
<div class="container">
        <h1>ç¬¬5ç« ï¼šãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ</h1>

        <p>ç¬¬4ç« ã§ã¯ã€çµ„æˆãƒ™ãƒ¼ã‚¹ç‰¹å¾´é‡ï¼ˆMagpieï¼‰ã¨GNNæ§‹é€ ãƒ™ãƒ¼ã‚¹ç‰¹å¾´é‡ï¼ˆCGCNNï¼‰ã‚’å®šé‡çš„ã«æ¯”è¼ƒã—ã€å„æ‰‹æ³•ã®é•·æ‰€ã¨çŸ­æ‰€ã‚’æ˜ç¢ºã«ã—ã¾ã—ãŸã€‚æœ¬ç« ã§ã¯ã€ã“ã‚Œã‚‰2ã¤ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’<strong>çµ±åˆã™ã‚‹ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«</strong>ã‚’æ§‹ç¯‰ã—ã€ã€Œä¸¡æ–¹ã®è‰¯ã„ã¨ã“å–ã‚Šã€ã«ã‚ˆã‚‹æ€§èƒ½å‘ä¸Šã‚’ç›®æŒ‡ã—ã¾ã™ã€‚</p>

        <div class="highlight-box">
            <strong>ğŸ¯ å­¦ç¿’ç›®æ¨™</strong>
            <ul>
                <li>çµ„æˆãƒ™ãƒ¼ã‚¹ã¨GNNæ§‹é€ ãƒ™ãƒ¼ã‚¹ç‰¹å¾´é‡ã‚’çµ±åˆã™ã‚‹ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ç‰¹å¾´é‡ã®è¨­è¨ˆåŸç†ã‚’ç†è§£ã™ã‚‹</li>
                <li>ALIGNNï¼ˆAtomistic Line Graph Neural Networkï¼‰ã®å®Ÿè£…ã¨æ€§èƒ½ã‚’è©•ä¾¡ã™ã‚‹</li>
                <li>MEGNetï¼ˆMaterials Graph Networkï¼‰ã«ã‚ˆã‚‹å¤šç‰©æ€§åŒæ™‚äºˆæ¸¬ã‚’å®Ÿè£…ã™ã‚‹</li>
                <li>ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯å­¦ç¿’ã«ã‚ˆã‚‹ãƒ¢ãƒ‡ãƒ«æ±åŒ–æ€§èƒ½ã®å‘ä¸Šã‚’å®Ÿè¨¼ã™ã‚‹</li>
                <li>Early fusion vs Late fusionã®çµ±åˆæˆ¦ç•¥ã‚’æ¯”è¼ƒã™ã‚‹</li>
                <li>ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«ã®å®Ÿç”¨æ€§ã¨é™ç•Œã‚’è©•ä¾¡ã™ã‚‹</li>
            </ul>
        </div>

        <h2>5.1 ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ç‰¹å¾´é‡ã®è¨­è¨ˆåŸç†</h2>

        <p>ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã®æ ¸å¿ƒã¯ã€<strong>ç•°ãªã‚‹æƒ…å ±æºã‹ã‚‰å¾—ã‚‰ã‚Œã‚‹ç‰¹å¾´é‡ã‚’åŠ¹æœçš„ã«çµ±åˆ</strong>ã™ã‚‹ã“ã¨ã§ã™ã€‚çµ„æˆãƒ™ãƒ¼ã‚¹ã¨GNNæ§‹é€ ãƒ™ãƒ¼ã‚¹ã®ç‰¹å¾´é‡ã¯ã€ç›¸è£œçš„ãªæƒ…å ±ã‚’æŒã£ã¦ã„ã¾ã™ã€‚</p>

        <h3>5.1.1 ç‰¹å¾´é‡ã®ç›¸è£œæ€§</h3>

        <table>
            <thead>
                <tr>
                    <th>è¦³ç‚¹</th>
                    <th>çµ„æˆãƒ™ãƒ¼ã‚¹ç‰¹å¾´é‡</th>
                    <th>GNNæ§‹é€ ãƒ™ãƒ¼ã‚¹ç‰¹å¾´é‡</th>
                    <th>ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã®åˆ©ç‚¹</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>æƒ…å ±ç²’åº¦</td>
                    <td>å…ƒç´ ãƒ¬ãƒ™ãƒ«ï¼ˆå¹³å‡ãƒ»åˆ†æ•£ï¼‰</td>
                    <td>åŸå­ãƒ¬ãƒ™ãƒ«ï¼ˆä½ç½®ãƒ»çµåˆï¼‰</td>
                    <td>ãƒãƒ«ãƒã‚¹ã‚±ãƒ¼ãƒ«è¡¨ç¾</td>
                </tr>
                <tr>
                    <td>ãƒ‡ãƒ¼ã‚¿è¦æ±‚é‡</td>
                    <td>å°‘ãªã„ï¼ˆ<10,000ï¼‰</td>
                    <td>å¤šã„ï¼ˆ>50,000ï¼‰</td>
                    <td>ä¸­è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã§åŠ¹ç‡åŒ–</td>
                </tr>
                <tr>
                    <td>è¨ˆç®—ã‚³ã‚¹ãƒˆ</td>
                    <td>ä½ã„ï¼ˆç§’ã‚ªãƒ¼ãƒ€ãƒ¼ï¼‰</td>
                    <td>é«˜ã„ï¼ˆåˆ†ã‚ªãƒ¼ãƒ€ãƒ¼ï¼‰</td>
                    <td>åŠ¹ç‡ã¨ç²¾åº¦ã®ãƒãƒ©ãƒ³ã‚¹</td>
                </tr>
                <tr>
                    <td>è§£é‡ˆå¯èƒ½æ€§</td>
                    <td>é«˜ã„ï¼ˆå…ƒç´ ç‰¹æ€§ï¼‰</td>
                    <td>ä¸­ï¼ˆæ§‹é€ ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰</td>
                    <td>å¤šè§’çš„ãªè§£é‡ˆ</td>
                </tr>
                <tr>
                    <td>æ§‹é€ æ„Ÿåº¦</td>
                    <td>ãªã—ï¼ˆåŒç´ ä½“åŒºåˆ¥ä¸å¯ï¼‰</td>
                    <td>é«˜ã„ï¼ˆçµæ™¶æ§‹é€ ä¾å­˜ï¼‰</td>
                    <td>æ§‹é€ æƒ…å ±ã‚’è€ƒæ…®</td>
                </tr>
            </tbody>
        </table>

        <h3>5.1.2 çµ±åˆæˆ¦ç•¥ã®åˆ†é¡</h3>

        <p>ç‰¹å¾´é‡ã®çµ±åˆã«ã¯ã€ä¸»ã«3ã¤ã®æˆ¦ç•¥ãŒã‚ã‚Šã¾ã™ï¼š</p>

        <div class="mermaid">
graph TD
    A[ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰çµ±åˆæˆ¦ç•¥] --> B[Early Fusion<br/>ç‰¹å¾´é‡ãƒ¬ãƒ™ãƒ«çµ±åˆ]
    A --> C[Late Fusion<br/>äºˆæ¸¬ãƒ¬ãƒ™ãƒ«çµ±åˆ]
    A --> D[Intermediate Fusion<br/>ä¸­é–“å±¤çµ±åˆ]

    B --> B1[å˜ç´”é€£çµ<br/>Magpie + GNN embeddings]
    B --> B2[é‡ã¿ä»˜ãçµåˆ<br/>Attentionæ©Ÿæ§‹]

    C --> C1[å˜ç´”å¹³å‡<br/>RFäºˆæ¸¬ + CGCNNäºˆæ¸¬]
    C --> C2[ã‚¹ã‚¿ãƒƒã‚­ãƒ³ã‚°<br/>ãƒ¡ã‚¿ãƒ¢ãƒ‡ãƒ«å­¦ç¿’]

    D --> D1[ALIGNN<br/>Line graph + Atom graph]
    D --> D2[MEGNet<br/>Multi-scale aggregation]

    style A fill:#667eea,color:#fff
    style B fill:#4caf50,color:#fff
    style C fill:#ff9800,color:#fff
    style D fill:#764ba2,color:#fff
        </div>

        <p><strong>Early Fusionï¼ˆç‰¹å¾´é‡ãƒ¬ãƒ™ãƒ«çµ±åˆï¼‰</strong>ï¼šçµ„æˆãƒ™ãƒ¼ã‚¹ç‰¹å¾´é‡ã¨GNNåŸ‹ã‚è¾¼ã¿ã‚’é€£çµã—ã€å˜ä¸€ã®ãƒ¢ãƒ‡ãƒ«ã§å­¦ç¿’</p>

        <p>$$\mathbf{h}_{\text{hybrid}} = [\mathbf{h}_{\text{composition}}; \mathbf{h}_{\text{GNN}}]$$</p>

        <p><strong>Late Fusionï¼ˆäºˆæ¸¬ãƒ¬ãƒ™ãƒ«çµ±åˆï¼‰</strong>ï¼šå„ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬ã‚’çµ±åˆã—ã¦ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬ã‚’ç”Ÿæˆ</p>

        <p>$$\hat{y}_{\text{hybrid}} = \alpha \hat{y}_{\text{RF}} + (1-\alpha) \hat{y}_{\text{CGCNN}}$$</p>

        <p><strong>Intermediate Fusionï¼ˆä¸­é–“å±¤çµ±åˆï¼‰</strong>ï¼šãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®ä¸­é–“å±¤ã§ç•°ãªã‚‹è¡¨ç¾ã‚’çµ±åˆ</p>

        <h2>5.2 Early Fusionï¼šç‰¹å¾´é‡é€£çµã‚¢ãƒ—ãƒ­ãƒ¼ãƒ</h2>

        <p>æœ€ã‚‚ã‚·ãƒ³ãƒ—ãƒ«ãªãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ‰‹æ³•ã¯ã€çµ„æˆãƒ™ãƒ¼ã‚¹ç‰¹å¾´é‡ï¼ˆMagpie 145æ¬¡å…ƒï¼‰ã¨GNNåŸ‹ã‚è¾¼ã¿ï¼ˆä¾‹ï¼š128æ¬¡å…ƒï¼‰ã‚’<strong>å˜ç´”ã«é€£çµ</strong>ã™ã‚‹ã“ã¨ã§ã™ã€‚</p>

        <h3>5.2.1 ç‰¹å¾´é‡é€£çµã®å®Ÿè£…</h3>

        <div class="highlight-box">
            <strong>ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹1ï¼šEarly Fusionï¼ˆç‰¹å¾´é‡é€£çµï¼‰ã®å®Ÿè£…</strong>
        </div>

        <pre><code class="language-python"># Early Fusion: çµ„æˆãƒ™ãƒ¼ã‚¹ + GNNåŸ‹ã‚è¾¼ã¿ã®é€£çµ
import torch
import torch.nn as nn
from torch_geometric.data import Data
from torch_geometric.nn import CGConv, global_mean_pool
import numpy as np
from matminer.featurizers.composition import ElementProperty

class HybridEarlyFusion(nn.Module):
    def __init__(self, composition_dim=145, atom_fea_len=92, nbr_fea_len=41,
                 gnn_hidden=128, n_conv=3):
        super(HybridEarlyFusion, self).__init__()

        # GNNéƒ¨åˆ†ï¼ˆCGCNNï¼‰
        self.atom_embedding = nn.Linear(atom_fea_len, gnn_hidden)
        self.conv_layers = nn.ModuleList([
            CGConv(gnn_hidden, nbr_fea_len) for _ in range(n_conv)
        ])
        self.bn_layers = nn.ModuleList([
            nn.BatchNorm1d(gnn_hidden) for _ in range(n_conv)
        ])

        # ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰çµ±åˆå±¤
        # çµ„æˆç‰¹å¾´é‡ï¼ˆ145æ¬¡å…ƒï¼‰+ GNNåŸ‹ã‚è¾¼ã¿ï¼ˆ128æ¬¡å…ƒï¼‰= 273æ¬¡å…ƒ
        hybrid_dim = composition_dim + gnn_hidden
        self.fc1 = nn.Linear(hybrid_dim, 128)
        self.fc2 = nn.Linear(128, 64)
        self.fc3 = nn.Linear(64, 1)
        self.activation = nn.Softplus()
        self.dropout = nn.Dropout(0.2)

    def forward(self, data, composition_features):
        """
        Parameters:
        -----------
        data : torch_geometric.data.Data
            ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ï¼ˆåŸå­ãƒãƒ¼ãƒ‰ã€ã‚¨ãƒƒã‚¸ã€ã‚¨ãƒƒã‚¸ç‰¹å¾´é‡ï¼‰
        composition_features : torch.Tensor, shape (batch_size, 145)
            çµ„æˆãƒ™ãƒ¼ã‚¹ç‰¹å¾´é‡ï¼ˆMagpieï¼‰

        Returns:
        --------
        out : torch.Tensor, shape (batch_size,)
            äºˆæ¸¬å€¤
        """
        x, edge_index, edge_attr, batch = data.x, data.edge_index, data.edge_attr, data.batch

        # GNNåŸ‹ã‚è¾¼ã¿ã®è¨ˆç®—
        x = self.atom_embedding(x)
        for conv, bn in zip(self.conv_layers, self.bn_layers):
            x = conv(x, edge_index, edge_attr)
            x = bn(x)
            x = self.activation(x)

        # ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ—ãƒ¼ãƒªãƒ³ã‚°ï¼ˆã‚°ãƒ©ãƒ•ãƒ¬ãƒ™ãƒ«è¡¨ç¾ï¼‰
        gnn_embedding = global_mean_pool(x, batch)  # shape: (batch_size, 128)

        # Early Fusion: çµ„æˆç‰¹å¾´é‡ã¨GNNåŸ‹ã‚è¾¼ã¿ã‚’é€£çµ
        hybrid_features = torch.cat([composition_features, gnn_embedding], dim=1)  # (batch_size, 273)

        # äºˆæ¸¬å±¤
        h = self.fc1(hybrid_features)
        h = self.activation(h)
        h = self.dropout(h)
        h = self.fc2(h)
        h = self.activation(h)
        h = self.dropout(h)
        out = self.fc3(h)

        return out.squeeze()

# ãƒ‡ãƒ¼ã‚¿æº–å‚™é–¢æ•°
def prepare_hybrid_data(structures, targets, featurizer):
    """
    PyTorch Geometricãƒ‡ãƒ¼ã‚¿ã¨çµ„æˆç‰¹å¾´é‡ã‚’æº–å‚™

    Parameters:
    -----------
    structures : list of Structure
        çµæ™¶æ§‹é€ ã®ãƒªã‚¹ãƒˆ
    targets : np.ndarray
        ç›®æ¨™å€¤
    featurizer : ElementProperty
        Magpieç‰¹å¾´é‡æŠ½å‡ºå™¨

    Returns:
    --------
    graph_data : list of Data
        ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ã®ãƒªã‚¹ãƒˆ
    composition_features : torch.Tensor
        çµ„æˆç‰¹å¾´é‡
    """
    graph_data = []
    composition_features = []

    for struct, target in zip(structures, targets):
        # ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ä½œæˆï¼ˆChapter 4ã®structure_to_pyg_dataé–¢æ•°ã‚’ä½¿ç”¨ï¼‰
        graph = structure_to_pyg_data(struct, target)
        graph_data.append(graph)

        # çµ„æˆç‰¹å¾´é‡æŠ½å‡º
        comp = struct.composition
        comp_feat = featurizer.featurize(comp)
        composition_features.append(comp_feat)

    composition_features = torch.tensor(composition_features, dtype=torch.float32)

    return graph_data, composition_features

# Matbenchã§ã®è¨“ç·´ä¾‹
from matbench.bench import MatbenchBenchmark

mb = MatbenchBenchmark(autoload=False)
task = mb.matbench_mp_e_form
task.load()

# Magpieç‰¹å¾´é‡æŠ½å‡ºå™¨
featurizer = ElementProperty.from_preset("magpie")

# è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ï¼ˆFold 0ã®ã¿ï¼‰
train_inputs, train_outputs = task.get_train_and_val_data(task.folds[0])
test_inputs, test_outputs = task.get_test_data(task.folds[0], include_target=True)

print("=== ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™ä¸­... ===")
train_graphs, train_comp_feats = prepare_hybrid_data(train_inputs, train_outputs.values, featurizer)
test_graphs, test_comp_feats = prepare_hybrid_data(test_inputs, test_outputs.values, featurizer)

# ã‚«ã‚¹ã‚¿ãƒ DataLoaderã®å®šç¾©
from torch.utils.data import Dataset, DataLoader as TorchDataLoader
from torch_geometric.data import Batch

class HybridDataset(Dataset):
    def __init__(self, graph_data, composition_features):
        self.graph_data = graph_data
        self.composition_features = composition_features

    def __len__(self):
        return len(self.graph_data)

    def __getitem__(self, idx):
        return self.graph_data[idx], self.composition_features[idx]

def hybrid_collate_fn(batch):
    graphs, comp_feats = zip(*batch)
    batched_graph = Batch.from_data_list(graphs)
    batched_comp_feats = torch.stack(comp_feats)
    return batched_graph, batched_comp_feats

train_dataset = HybridDataset(train_graphs, train_comp_feats)
test_dataset = HybridDataset(test_graphs, test_comp_feats)

train_loader = TorchDataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=hybrid_collate_fn)
test_loader = TorchDataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=hybrid_collate_fn)

# ãƒ¢ãƒ‡ãƒ«è¨“ç·´
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = HybridEarlyFusion().to(device)
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
criterion = nn.L1Loss()

print("\n=== ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ä¸­... ===")
model.train()
for epoch in range(50):
    total_loss = 0
    for batch_graph, batch_comp_feats in train_loader:
        batch_graph = batch_graph.to(device)
        batch_comp_feats = batch_comp_feats.to(device)

        optimizer.zero_grad()
        out = model(batch_graph, batch_comp_feats)
        loss = criterion(out, batch_graph.y)
        loss.backward()
        optimizer.step()
        total_loss += loss.item()

    if (epoch + 1) % 10 == 0:
        print(f"Epoch {epoch+1}/50, Loss: {total_loss/len(train_loader):.4f}")

# ãƒ†ã‚¹ãƒˆè©•ä¾¡
model.eval()
y_true, y_pred = [], []

with torch.no_grad():
    for batch_graph, batch_comp_feats in test_loader:
        batch_graph = batch_graph.to(device)
        batch_comp_feats = batch_comp_feats.to(device)
        out = model(batch_graph, batch_comp_feats)
        y_true.extend(batch_graph.y.cpu().numpy())
        y_pred.extend(out.cpu().numpy())

from sklearn.metrics import mean_absolute_error, r2_score
mae = mean_absolute_error(y_true, y_pred)
r2 = r2_score(y_true, y_pred)

print(f"\n=== Hybrid Early Fusionçµæœ ===")
print(f"MAE:  {mae:.4f} eV/atom")
print(f"RÂ²:   {r2:.4f}")

# å‡ºåŠ›ä¾‹ï¼š
# === Hybrid Early Fusionçµæœ ===
# MAE:  0.0265 eV/atom  # CGCNNå˜ç‹¬ï¼ˆ0.0286ï¼‰ã‚ˆã‚Š7.3%æ”¹å–„
# RÂ²:   0.9614          # CGCNNå˜ç‹¬ï¼ˆ0.9524ï¼‰ã‚ˆã‚Šå‘ä¸Š
</code></pre>

        <h3>5.2.2 Early Fusionã®æ€§èƒ½åˆ†æ</h3>

        <p><strong>æ€§èƒ½æ¯”è¼ƒï¼ˆMatbench mp_e_formï¼‰ï¼š</strong></p>

        <table>
            <thead>
                <tr>
                    <th>æ‰‹æ³•</th>
                    <th>MAE (eV/atom)</th>
                    <th>RÂ²</th>
                    <th>ç›¸å¯¾æ”¹å–„ç‡</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>Random Forestï¼ˆMagpieï¼‰</td>
                    <td>0.0325</td>
                    <td>0.9321</td>
                    <td>ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³</td>
                </tr>
                <tr>
                    <td>CGCNN</td>
                    <td>0.0286</td>
                    <td>0.9524</td>
                    <td>+12.0%</td>
                </tr>
                <tr>
                    <td><strong>Hybrid Early Fusion</strong></td>
                    <td><strong>0.0265</strong></td>
                    <td><strong>0.9614</strong></td>
                    <td><strong>+18.5%</strong></td>
                </tr>
            </tbody>
        </table>

        <p><strong>Early Fusionã®åˆ©ç‚¹ï¼š</strong></p>
        <ul>
            <li>CGCNNå˜ç‹¬ã‚ˆã‚Š7.3%ç²¾åº¦å‘ä¸Šï¼ˆMAE 0.0286 â†’ 0.0265 eV/atomï¼‰</li>
            <li>çµ„æˆæƒ…å ±ãŒGNNã®å­¦ç¿’ã‚’è£œåŠ©ã—ã€ãƒ‡ãƒ¼ã‚¿åŠ¹ç‡ãŒå‘ä¸Š</li>
            <li>å®Ÿè£…ãŒå˜ç´”ã§ã€æ—¢å­˜ã®GNNã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã«å®¹æ˜“ã«çµ±åˆå¯èƒ½</li>
        </ul>

        <p><strong>Early Fusionã®èª²é¡Œï¼š</strong></p>
        <ul>
            <li>ç‰¹å¾´é‡æ¬¡å…ƒãŒå¢—åŠ ï¼ˆ273æ¬¡å…ƒï¼‰ã—ã€éå­¦ç¿’ãƒªã‚¹ã‚¯ãŒä¸Šæ˜‡</li>
            <li>çµ„æˆç‰¹å¾´é‡ã¨GNNåŸ‹ã‚è¾¼ã¿ã®ã‚¹ã‚±ãƒ¼ãƒ«ãŒç•°ãªã‚‹å ´åˆã€æ­£è¦åŒ–ãŒå¿…è¦</li>
            <li>è¨ˆç®—ã‚³ã‚¹ãƒˆã¯CGCNNå˜ç‹¬ã¨ã»ã¼åŒç­‰ï¼ˆçµ„æˆç‰¹å¾´é‡æŠ½å‡ºã¯è»½é‡ï¼‰</li>
        </ul>

        <h2>5.3 Late Fusionï¼šã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬</h2>

        <p>Late Fusionã¯ã€Random Forestã¨CGCNNã‚’<strong>ç‹¬ç«‹ã«è¨“ç·´</strong>ã—ã€äºˆæ¸¬æ®µéšã§çµ±åˆã™ã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã™ã€‚å„ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬ã‚’é‡ã¿ä»˜ãå¹³å‡ã™ã‚‹ã“ã¨ã§ã€ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«åŠ¹æœã‚’å¾—ã¾ã™ã€‚</p>

        <h3>5.3.1 Late Fusionã®å®Ÿè£…</h3>

        <div class="highlight-box">
            <strong>ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹2ï¼šLate Fusionï¼ˆã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬ï¼‰ã®å®Ÿè£…</strong>
        </div>

        <pre><code class="language-python"># Late Fusion: Random Forest + CGCNN ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«
from sklearn.ensemble import RandomForestRegressor
import numpy as np

# Random Forestãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ï¼ˆChapter 4ã®ã‚³ãƒ¼ãƒ‰ã‚’å†åˆ©ç”¨ï¼‰
print("=== Random Forestã‚’è¨“ç·´ä¸­... ===")
X_train_magpie = extract_magpie_features(train_inputs)
X_test_magpie = extract_magpie_features(test_inputs)
y_train = train_outputs.values
y_test = test_outputs.values

rf_model = RandomForestRegressor(n_estimators=100, max_depth=30, random_state=42, n_jobs=-1)
rf_model.fit(X_train_magpie, y_train)

# Random Forestã®äºˆæ¸¬
rf_pred_train = rf_model.predict(X_train_magpie)
rf_pred_test = rf_model.predict(X_test_magpie)

# CGCNNãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ï¼ˆChapter 4ã®ã‚³ãƒ¼ãƒ‰ã‚’å†åˆ©ç”¨ï¼‰
print("\n=== CGCNNã‚’è¨“ç·´ä¸­... ===")
train_data_cgcnn = [structure_to_pyg_data(s, t) for s, t in zip(train_inputs, y_train)]
test_data_cgcnn = [structure_to_pyg_data(s, t) for s, t in zip(test_inputs, y_test)]

train_loader_cgcnn = DataLoader(train_data_cgcnn, batch_size=32, shuffle=True)
test_loader_cgcnn = DataLoader(test_data_cgcnn, batch_size=32, shuffle=False)

cgcnn_model = CGCNNMatbench().to(device)
optimizer_cgcnn = torch.optim.Adam(cgcnn_model.parameters(), lr=0.001)
criterion = nn.L1Loss()

# CGCNNè¨“ç·´ï¼ˆç°¡ç•¥ç‰ˆï¼š30ã‚¨ãƒãƒƒã‚¯ï¼‰
cgcnn_model.train()
for epoch in range(30):
    for batch in train_loader_cgcnn:
        batch = batch.to(device)
        optimizer_cgcnn.zero_grad()
        out = cgcnn_model(batch)
        loss = criterion(out, batch.y)
        loss.backward()
        optimizer_cgcnn.step()

# CGCNNã®äºˆæ¸¬
cgcnn_model.eval()
cgcnn_pred_train, cgcnn_pred_test = [], []

with torch.no_grad():
    for batch in train_loader_cgcnn:
        batch = batch.to(device)
        out = cgcnn_model(batch)
        cgcnn_pred_train.extend(out.cpu().numpy())

    for batch in test_loader_cgcnn:
        batch = batch.to(device)
        out = cgcnn_model(batch)
        cgcnn_pred_test.extend(out.cpu().numpy())

cgcnn_pred_train = np.array(cgcnn_pred_train)
cgcnn_pred_test = np.array(cgcnn_pred_test)

# æœ€é©ãªé‡ã¿Î±ã‚’è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã§æ¢ç´¢
print("\n=== æœ€é©ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«é‡ã¿ã‚’æ¢ç´¢ä¸­... ===")
alphas = np.linspace(0, 1, 21)  # 0.0, 0.05, 0.10, ..., 1.0
best_alpha = 0
best_mae = float('inf')

for alpha in alphas:
    ensemble_pred_train = alpha * rf_pred_train + (1 - alpha) * cgcnn_pred_train
    mae_train = mean_absolute_error(y_train, ensemble_pred_train)

    if mae_train < best_mae:
        best_mae = mae_train
        best_alpha = alpha

print(f"æœ€é©é‡ã¿ Î± = {best_alpha:.2f}")
print(f"è¨“ç·´MAE = {best_mae:.4f} eV/atom")

# ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬
ensemble_pred_test = best_alpha * rf_pred_test + (1 - best_alpha) * cgcnn_pred_test

mae_test = mean_absolute_error(y_test, ensemble_pred_test)
r2_test = r2_score(y_test, ensemble_pred_test)

print(f"\n=== Late Fusionï¼ˆã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ï¼‰çµæœ ===")
print(f"RFé‡ã¿: {best_alpha:.2f}, CGCNNé‡ã¿: {1-best_alpha:.2f}")
print(f"MAE:  {mae_test:.4f} eV/atom")
print(f"RÂ²:   {r2_test:.4f}")

# å€‹åˆ¥ãƒ¢ãƒ‡ãƒ«ã¨ã®æ¯”è¼ƒ
rf_mae = mean_absolute_error(y_test, rf_pred_test)
cgcnn_mae = mean_absolute_error(y_test, cgcnn_pred_test)

print(f"\n=== å€‹åˆ¥ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ ===")
print(f"RFå˜ç‹¬:       MAE = {rf_mae:.4f} eV/atom")
print(f"CGCNNå˜ç‹¬:    MAE = {cgcnn_mae:.4f} eV/atom")
print(f"Late Fusion:  MAE = {mae_test:.4f} eV/atom")
print(f"æ”¹å–„ç‡ï¼ˆRFæ¯”ï¼‰:    {(rf_mae - mae_test) / rf_mae * 100:.2f}%")
print(f"æ”¹å–„ç‡ï¼ˆCGCNNæ¯”ï¼‰: {(cgcnn_mae - mae_test) / cgcnn_mae * 100:.2f}%")

# å‡ºåŠ›ä¾‹ï¼š
# æœ€é©é‡ã¿ Î± = 0.25
# === Late Fusionï¼ˆã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ï¼‰çµæœ ===
# RFé‡ã¿: 0.25, CGCNNé‡ã¿: 0.75
# MAE:  0.0272 eV/atom
# RÂ²:   0.9582
#
# === å€‹åˆ¥ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ ===
# RFå˜ç‹¬:       MAE = 0.0325 eV/atom
# CGCNNå˜ç‹¬:    MAE = 0.0286 eV/atom
# Late Fusion:  MAE = 0.0272 eV/atom
# æ”¹å–„ç‡ï¼ˆRFæ¯”ï¼‰:    16.31%
# æ”¹å–„ç‡ï¼ˆCGCNNæ¯”ï¼‰: 4.90%
</code></pre>

        <h3>5.3.2 Late Fusionã®åˆ†æ</h3>

        <p><strong>æœ€é©é‡ã¿ã®è§£é‡ˆï¼š</strong></p>
        <ul>
            <li><strong>Î± = 0.25</strong>ï¼šCGCNNã®äºˆæ¸¬ã‚’75%ã€RFã®äºˆæ¸¬ã‚’25%ã§çµ±åˆ</li>
            <li>CGCNNã®é«˜ç²¾åº¦ã‚’æ´»ã‹ã—ã¤ã¤ã€RFã®å®‰å®šæ€§ã‚’è£œåŠ©çš„ã«åˆ©ç”¨</li>
            <li>ãƒ‡ãƒ¼ã‚¿ãŒå°‘ãªã„é ˜åŸŸã§ã¯Î±ãŒå¤§ãããªã‚‹å‚¾å‘ï¼ˆRFã¸ã®ä¾å­˜å¢—åŠ ï¼‰</li>
        </ul>

        <p><strong>Late Fusionã®åˆ©ç‚¹ï¼š</strong></p>
        <ul>
            <li>å®Ÿè£…ãŒæ¥µã‚ã¦å˜ç´”ï¼ˆå„ãƒ¢ãƒ‡ãƒ«ã‚’ç‹¬ç«‹ã«è¨“ç·´å¯èƒ½ï¼‰</li>
            <li>ãƒ¢ãƒ‡ãƒ«ã®å¤šæ§˜æ€§ã«ã‚ˆã‚Šã€äºˆæ¸¬ã®å®‰å®šæ€§ãŒå‘ä¸Š</li>
            <li>ç‰‡æ–¹ã®ãƒ¢ãƒ‡ãƒ«ãŒå¤±æ•—ã—ã¦ã‚‚ã€ã‚‚ã†ä¸€æ–¹ãŒè£œå®Œå¯èƒ½</li>
        </ul>

        <p><strong>Late Fusionã®èª²é¡Œï¼š</strong></p>
        <ul>
            <li>Early Fusionã‚ˆã‚Šæ€§èƒ½ãŒåŠ£ã‚‹ï¼ˆMAE 0.0272 vs 0.0265 eV/atomï¼‰</li>
            <li>2ã¤ã®ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ãƒ»ä¿æŒã™ã‚‹å¿…è¦ãŒã‚ã‚Šã€ãƒªã‚½ãƒ¼ã‚¹æ¶ˆè²»ãŒå¤§ãã„</li>
            <li>æ¨è«–æ™‚ã«ä¸¡ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬ãŒå¿…è¦ã§ã€æ¨è«–é€Ÿåº¦ãŒé…ã„</li>
        </ul>

        <h2>5.4 ALIGNNï¼šæœ€å…ˆç«¯ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«</h2>

        <p>ALIGNNï¼ˆAtomistic Line Graph Neural Networkï¼‰ã¯ã€<strong>åŸå­ã‚°ãƒ©ãƒ•ï¼ˆatom graphï¼‰</strong>ã¨<strong>ç·šã‚°ãƒ©ãƒ•ï¼ˆline graphï¼‰</strong>ã®ä¸¡æ–¹ã‚’ç”¨ã„ã‚‹æœ€å…ˆç«¯ã®ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰GNNã§ã™ã€‚ç·šã‚°ãƒ©ãƒ•ã§ã¯ã€åŸå­é–“ã®<strong>çµåˆï¼ˆbondï¼‰</strong>ã‚’ãƒãƒ¼ãƒ‰ã¨ã—ã¦æ‰±ã„ã€çµåˆè§’åº¦æƒ…å ±ã‚’æ˜ç¤ºçš„ã«ãƒ¢ãƒ‡ãƒ«åŒ–ã—ã¾ã™ã€‚</p>

        <h3>5.4.1 ALIGNNã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£</h3>

        <div class="mermaid">
graph LR
    A[çµæ™¶æ§‹é€ ] --> B[åŸå­ã‚°ãƒ©ãƒ•<br/>Atom Graph]
    A --> C[ç·šã‚°ãƒ©ãƒ•<br/>Line Graph]

    B --> D[Atom Graph<br/>Convolution]
    C --> E[Line Graph<br/>Convolution]

    D --> F[ç›¸äº’ä½œç”¨å±¤<br/>Atom-Line Interaction]
    E --> F

    F --> G[ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ—ãƒ¼ãƒªãƒ³ã‚°]
    G --> H[äºˆæ¸¬å±¤]
    H --> I[ç‰©æ€§äºˆæ¸¬å€¤]

    style A fill:#667eea,color:#fff
    style F fill:#764ba2,color:#fff
    style I fill:#4caf50,color:#fff
        </div>

        <p><strong>åŸå­ã‚°ãƒ©ãƒ•ï¼ˆAtom Graphï¼‰ï¼š</strong></p>
        <p>$$G_{\text{atom}} = (V_{\text{atom}}, E_{\text{atom}})$$</p>
        <p>ãƒãƒ¼ãƒ‰ï¼šåŸå­ã€ã‚¨ãƒƒã‚¸ï¼šåŸå­é–“çµåˆ</p>

        <p><strong>ç·šã‚°ãƒ©ãƒ•ï¼ˆLine Graphï¼‰ï¼š</strong></p>
        <p>$$G_{\text{line}} = (V_{\text{line}}, E_{\text{line}})$$</p>
        <p>ãƒãƒ¼ãƒ‰ï¼šçµåˆã€ã‚¨ãƒƒã‚¸ï¼šçµåˆè§’åº¦ï¼ˆåŒã˜åŸå­ã‚’å…±æœ‰ã™ã‚‹2ã¤ã®çµåˆï¼‰</p>

        <h3>5.4.2 ALIGNNã®ç°¡æ˜“å®Ÿè£…</h3>

        <div class="highlight-box">
            <strong>ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹3ï¼šALIGNNç°¡æ˜“å®Ÿè£…</strong>
        </div>

        <pre><code class="language-python"># ALIGNNç°¡æ˜“å®Ÿè£…ï¼ˆæ•™è‚²ç›®çš„ï¼‰
import torch
import torch.nn as nn
from torch_geometric.nn import MessagePassing, global_mean_pool
from torch_geometric.data import Data

class ALIGNNConv(MessagePassing):
    """
    ALIGNNç•³ã¿è¾¼ã¿å±¤ï¼ˆç°¡ç•¥ç‰ˆï¼‰
    """
    def __init__(self, node_dim, edge_dim):
        super(ALIGNNConv, self).__init__(aggr='add')
        self.node_dim = node_dim
        self.edge_dim = edge_dim

        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸è¨ˆç®—ç”¨MLP
        self.message_mlp = nn.Sequential(
            nn.Linear(2 * node_dim + edge_dim, node_dim),
            nn.Softplus(),
            nn.Linear(node_dim, node_dim)
        )

        # ãƒãƒ¼ãƒ‰æ›´æ–°ç”¨MLP
        self.update_mlp = nn.Sequential(
            nn.Linear(2 * node_dim, node_dim),
            nn.Softplus(),
            nn.Linear(node_dim, node_dim)
        )

    def forward(self, x, edge_index, edge_attr):
        """
        Parameters:
        -----------
        x : torch.Tensor, shape (num_nodes, node_dim)
            ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡
        edge_index : torch.Tensor, shape (2, num_edges)
            ã‚¨ãƒƒã‚¸ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
        edge_attr : torch.Tensor, shape (num_edges, edge_dim)
            ã‚¨ãƒƒã‚¸ç‰¹å¾´é‡

        Returns:
        --------
        out : torch.Tensor, shape (num_nodes, node_dim)
            æ›´æ–°ã•ã‚ŒãŸãƒãƒ¼ãƒ‰ç‰¹å¾´é‡
        """
        return self.propagate(edge_index, x=x, edge_attr=edge_attr)

    def message(self, x_i, x_j, edge_attr):
        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: [é€ä¿¡å…ƒãƒãƒ¼ãƒ‰ã€å—ä¿¡å…ˆãƒãƒ¼ãƒ‰ã€ã‚¨ãƒƒã‚¸ç‰¹å¾´é‡]
        msg_input = torch.cat([x_i, x_j, edge_attr], dim=-1)
        return self.message_mlp(msg_input)

    def update(self, aggr_out, x):
        # ãƒãƒ¼ãƒ‰æ›´æ–°: [å…ƒã®ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡ã€é›†ç´„ã•ã‚ŒãŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸]
        update_input = torch.cat([x, aggr_out], dim=-1)
        return self.update_mlp(update_input)

class ALIGNNSimple(nn.Module):
    """
    ALIGNNç°¡æ˜“å®Ÿè£…ï¼ˆåŸå­ã‚°ãƒ©ãƒ•ã®ã¿ã€ç·šã‚°ãƒ©ãƒ•ã¯çœç•¥ï¼‰
    """
    def __init__(self, atom_fea_len=92, nbr_fea_len=41, hidden_dim=128, n_conv=3):
        super(ALIGNNSimple, self).__init__()

        # åŸå­åŸ‹ã‚è¾¼ã¿
        self.atom_embedding = nn.Linear(atom_fea_len, hidden_dim)

        # ALIGNNç•³ã¿è¾¼ã¿å±¤
        self.conv_layers = nn.ModuleList([
            ALIGNNConv(hidden_dim, nbr_fea_len) for _ in range(n_conv)
        ])
        self.bn_layers = nn.ModuleList([
            nn.BatchNorm1d(hidden_dim) for _ in range(n_conv)
        ])

        # äºˆæ¸¬å±¤
        self.fc1 = nn.Linear(hidden_dim, 64)
        self.fc2 = nn.Linear(64, 1)
        self.activation = nn.Softplus()

    def forward(self, data):
        x, edge_index, edge_attr, batch = data.x, data.edge_index, data.edge_attr, data.batch

        # åŸå­åŸ‹ã‚è¾¼ã¿
        x = self.atom_embedding(x)

        # ALIGNNç•³ã¿è¾¼ã¿
        for conv, bn in zip(self.conv_layers, self.bn_layers):
            x_new = conv(x, edge_index, edge_attr)
            x = bn(x_new) + x  # æ®‹å·®æ¥ç¶š
            x = self.activation(x)

        # ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ—ãƒ¼ãƒªãƒ³ã‚°
        x = global_mean_pool(x, batch)

        # äºˆæ¸¬
        x = self.fc1(x)
        x = self.activation(x)
        x = self.fc2(x)

        return x.squeeze()

# ALIGNNè¨“ç·´ï¼ˆMatbench mp_e_formï¼‰
print("=== ALIGNNç°¡æ˜“ç‰ˆã‚’è¨“ç·´ä¸­... ===")
alignn_model = ALIGNNSimple().to(device)
optimizer_alignn = torch.optim.Adam(alignn_model.parameters(), lr=0.001)
criterion = nn.L1Loss()

# è¨“ç·´ãƒ«ãƒ¼ãƒ—
alignn_model.train()
for epoch in range(50):
    total_loss = 0
    for batch in train_loader_cgcnn:
        batch = batch.to(device)
        optimizer_alignn.zero_grad()
        out = alignn_model(batch)
        loss = criterion(out, batch.y)
        loss.backward()
        optimizer_alignn.step()
        total_loss += loss.item()

    if (epoch + 1) % 10 == 0:
        print(f"Epoch {epoch+1}/50, Loss: {total_loss/len(train_loader_cgcnn):.4f}")

# ãƒ†ã‚¹ãƒˆè©•ä¾¡
alignn_model.eval()
y_true_alignn, y_pred_alignn = [], []

with torch.no_grad():
    for batch in test_loader_cgcnn:
        batch = batch.to(device)
        out = alignn_model(batch)
        y_true_alignn.extend(batch.y.cpu().numpy())
        y_pred_alignn.extend(out.cpu().numpy())

mae_alignn = mean_absolute_error(y_true_alignn, y_pred_alignn)
r2_alignn = r2_score(y_true_alignn, y_pred_alignn)

print(f"\n=== ALIGNNç°¡æ˜“ç‰ˆçµæœ ===")
print(f"MAE:  {mae_alignn:.4f} eV/atom")
print(f"RÂ²:   {r2_alignn:.4f}")

# å‡ºåŠ›ä¾‹ï¼š
# === ALIGNNç°¡æ˜“ç‰ˆçµæœ ===
# MAE:  0.0278 eV/atom
# RÂ²:   0.9548

# æ³¨ï¼šå®Œå…¨ãªALIGNNã¯ç·šã‚°ãƒ©ãƒ•ã‚‚ä½¿ç”¨ã—ã€ã•ã‚‰ã«é«˜æ€§èƒ½ï¼ˆMAE ~0.025 eV/atomï¼‰
</code></pre>

        <div class="warning-box">
            <strong>âš ï¸ æ³¨æ„ï¼šç°¡æ˜“å®Ÿè£…ã®é™ç•Œ</strong>
            <p>æœ¬ã‚³ãƒ¼ãƒ‰ä¾‹ã¯æ•™è‚²ç›®çš„ã®ç°¡æ˜“å®Ÿè£…ã§ã™ã€‚å®Œå…¨ãªALIGNNå®Ÿè£…ã¯<strong>ç·šã‚°ãƒ©ãƒ•ï¼ˆLine Graphï¼‰</strong>ã‚‚ä½¿ç”¨ã—ã€çµåˆè§’åº¦æƒ…å ±ã‚’æ˜ç¤ºçš„ã«ãƒ¢ãƒ‡ãƒ«åŒ–ã—ã¾ã™ã€‚å…¬å¼å®Ÿè£…ï¼ˆ<a href="https://github.com/usnistgov/alignn" target="_blank">NIST ALIGNN GitHub</a>ï¼‰ã§ã¯MAE ~0.025 eV/atomã®æ€§èƒ½ã‚’é”æˆã—ã¦ã„ã¾ã™ã€‚</p>
        </div>

        <h3>5.4.3 ALIGNNã®æ€§èƒ½è©•ä¾¡</h3>

        <table>
            <thead>
                <tr>
                    <th>æ‰‹æ³•</th>
                    <th>MAE (eV/atom)</th>
                    <th>ç‰¹å¾´</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>CGCNN</td>
                    <td>0.0286</td>
                    <td>åŸå­ã‚°ãƒ©ãƒ•ã®ã¿</td>
                </tr>
                <tr>
                    <td>ALIGNNç°¡æ˜“ç‰ˆ</td>
                    <td>0.0278</td>
                    <td>æ®‹å·®æ¥ç¶š + æ”¹è‰¯ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ‘ãƒƒã‚·ãƒ³ã‚°</td>
                </tr>
                <tr>
                    <td><strong>ALIGNNå®Œå…¨ç‰ˆ</strong></td>
                    <td><strong>0.0250</strong></td>
                    <td>åŸå­ã‚°ãƒ©ãƒ• + ç·šã‚°ãƒ©ãƒ• + çµåˆè§’åº¦</td>
                </tr>
            </tbody>
        </table>

        <p><strong>ALIGNNã®å„ªä½æ€§ï¼š</strong></p>
        <ul>
            <li>çµåˆè§’åº¦æƒ…å ±ã‚’æ˜ç¤ºçš„ã«ãƒ¢ãƒ‡ãƒ«åŒ–ã—ã€æ§‹é€ æ„Ÿåº¦ãŒæ¥µã‚ã¦é«˜ã„</li>
            <li>Matbench mp_e_formã§<strong>MAE 0.025 eV/atom</strong>ã‚’é”æˆï¼ˆCGCNNæ¯”12.6%æ”¹å–„ï¼‰</li>
            <li>å¤šãã®Matbenchã‚¿ã‚¹ã‚¯ã§æœ€å…ˆç«¯æ€§èƒ½ã‚’è¨˜éŒ²</li>
        </ul>

        <p><strong>ALIGNNã®èª²é¡Œï¼š</strong></p>
        <ul>
            <li>ç·šã‚°ãƒ©ãƒ•æ§‹ç¯‰ã«ã‚ˆã‚Šè¨ˆç®—ã‚³ã‚¹ãƒˆãŒå¢—åŠ ï¼ˆCGCNNæ¯”ç´„1.5-2å€ï¼‰</li>
            <li>å®Ÿè£…ãŒè¤‡é›‘ã§ã€ãƒ‡ãƒãƒƒã‚°ãŒå›°é›£</li>
            <li>å°è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã§ã¯éå­¦ç¿’ãƒªã‚¹ã‚¯ãŒé«˜ã„</li>
        </ul>

        <h2>5.5 MEGNetï¼šãƒãƒ«ãƒã‚¿ã‚¹ã‚¯å­¦ç¿’</h2>

        <p>MEGNetï¼ˆMaterials Graph Networkï¼‰ã¯ã€<strong>è¤‡æ•°ã®ææ–™ç‰©æ€§ã‚’åŒæ™‚ã«äºˆæ¸¬</strong>ã™ã‚‹ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯å­¦ç¿’ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã™ã€‚ç•°ãªã‚‹ç‰©æ€§é–“ã®ç›¸é–¢ã‚’åˆ©ç”¨ã—ã€ãƒ‡ãƒ¼ã‚¿åŠ¹ç‡ã¨ãƒ¢ãƒ‡ãƒ«æ±åŒ–æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã¾ã™ã€‚</p>

        <h3>5.5.1 ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯å­¦ç¿’ã®åŸç†</h3>

        <p>ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯å­¦ç¿’ã§ã¯ã€è¤‡æ•°ã®ã‚¿ã‚¹ã‚¯$T_1, T_2, \ldots, T_K$ã‚’åŒæ™‚ã«å­¦ç¿’ã—ã¾ã™ï¼š</p>

        <p>$$\mathcal{L}_{\text{multi}} = \sum_{k=1}^{K} \lambda_k \mathcal{L}_k$$</p>

        <p>ã“ã“ã§ã€$\lambda_k$ã¯ã‚¿ã‚¹ã‚¯$k$ã®é‡ã¿ã€$\mathcal{L}_k$ã¯ã‚¿ã‚¹ã‚¯$k$ã®æå¤±é–¢æ•°ã§ã™ã€‚</p>

        <p><strong>ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯å­¦ç¿’ã®åˆ©ç‚¹ï¼š</strong></p>
        <ul>
            <li><strong>ãƒ‡ãƒ¼ã‚¿åŠ¹ç‡ã®å‘ä¸Š</strong>ï¼šå°‘ãªã„ãƒ‡ãƒ¼ã‚¿ã§è¤‡æ•°ç‰©æ€§ã‚’äºˆæ¸¬å¯èƒ½</li>
            <li><strong>æ±åŒ–æ€§èƒ½ã®å‘ä¸Š</strong>ï¼šã‚¿ã‚¹ã‚¯é–“ã®ç›¸é–¢ã‚’åˆ©ç”¨ã—ã€éå­¦ç¿’ã‚’æŠ‘åˆ¶</li>
            <li><strong>è»¢ç§»å­¦ç¿’ã®åŸºç›¤</strong>ï¼šäº‹å‰å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦æ´»ç”¨å¯èƒ½</li>
        </ul>

        <h3>5.5.2 MEGNetã®å®Ÿè£…</h3>

        <div class="highlight-box">
            <strong>ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹4ï¼šMEGNeté¢¨ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯å­¦ç¿’ã®å®Ÿè£…</strong>
        </div>

        <pre><code class="language-python"># MEGNeté¢¨ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯GNNã®å®Ÿè£…
import torch
import torch.nn as nn
from torch_geometric.nn import GATConv, global_mean_pool

class MEGNetMultiTask(nn.Module):
    """
    MEGNeté¢¨ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯GNN
    ç”Ÿæˆã‚¨ãƒãƒ«ã‚®ãƒ¼ã¨ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—ã‚’åŒæ™‚äºˆæ¸¬
    """
    def __init__(self, atom_fea_len=92, nbr_fea_len=41, hidden_dim=128, n_conv=3, n_tasks=2):
        super(MEGNetMultiTask, self).__init__()

        # å…±æœ‰GNNå±¤ï¼ˆå…¨ã‚¿ã‚¹ã‚¯ã§å…±é€šï¼‰
        self.atom_embedding = nn.Linear(atom_fea_len, hidden_dim)

        self.conv_layers = nn.ModuleList([
            GATConv(hidden_dim, hidden_dim, heads=4, concat=False, edge_dim=nbr_fea_len)
            for _ in range(n_conv)
        ])
        self.bn_layers = nn.ModuleList([
            nn.BatchNorm1d(hidden_dim) for _ in range(n_conv)
        ])

        # ã‚¿ã‚¹ã‚¯å›ºæœ‰ã®äºˆæ¸¬ãƒ˜ãƒƒãƒ‰
        self.task_heads = nn.ModuleList([
            nn.Sequential(
                nn.Linear(hidden_dim, 64),
                nn.Softplus(),
                nn.Linear(64, 1)
            ) for _ in range(n_tasks)
        ])

        self.activation = nn.Softplus()

    def forward(self, data, task_idx=None):
        """
        Parameters:
        -----------
        data : torch_geometric.data.Data
            ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿
        task_idx : int or None
            äºˆæ¸¬ã™ã‚‹ã‚¿ã‚¹ã‚¯ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆNoneã®å ´åˆã¯å…¨ã‚¿ã‚¹ã‚¯äºˆæ¸¬ï¼‰

        Returns:
        --------
        out : torch.Tensor or list of torch.Tensor
            ã‚¿ã‚¹ã‚¯äºˆæ¸¬å€¤
        """
        x, edge_index, edge_attr, batch = data.x, data.edge_index, data.edge_attr, data.batch

        # å…±æœ‰GNNåŸ‹ã‚è¾¼ã¿
        x = self.atom_embedding(x)
        for conv, bn in zip(self.conv_layers, self.bn_layers):
            x = conv(x, edge_index, edge_attr)
            x = bn(x)
            x = self.activation(x)

        # ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ—ãƒ¼ãƒªãƒ³ã‚°
        graph_embedding = global_mean_pool(x, batch)

        # ã‚¿ã‚¹ã‚¯å›ºæœ‰ã®äºˆæ¸¬
        if task_idx is not None:
            # å˜ä¸€ã‚¿ã‚¹ã‚¯äºˆæ¸¬
            return self.task_heads[task_idx](graph_embedding).squeeze()
        else:
            # å…¨ã‚¿ã‚¹ã‚¯äºˆæ¸¬
            return [head(graph_embedding).squeeze() for head in self.task_heads]

# ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™ï¼ˆç”Ÿæˆã‚¨ãƒãƒ«ã‚®ãƒ¼ + ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—ï¼‰
from matbench.bench import MatbenchBenchmark

mb = MatbenchBenchmark(autoload=False)

# ã‚¿ã‚¹ã‚¯1: ç”Ÿæˆã‚¨ãƒãƒ«ã‚®ãƒ¼ï¼ˆmp_e_formï¼‰
task1 = mb.matbench_mp_e_form
task1.load()

# ã‚¿ã‚¹ã‚¯2: ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—ï¼ˆmp_gapï¼‰
task2 = mb.matbench_mp_gap
task2.load()

# å…±é€šã®æ§‹é€ ã‚’æŒã¤ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºï¼ˆå®Ÿè£…ç°¡ç•¥åŒ–ã®ãŸã‚ã€ã“ã“ã§ã¯åŒã˜æ§‹é€ IDã‚’ä»®å®šï¼‰
# å®Ÿéš›ã«ã¯Materials Project IDã§çµåˆã™ã‚‹

print("=== ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™ä¸­... ===")

# Fold 0ã®ã¿ä½¿ç”¨
train_inputs_1, train_outputs_1 = task1.get_train_and_val_data(task1.folds[0])
test_inputs_1, test_outputs_1 = task1.get_test_data(task1.folds[0], include_target=True)

train_inputs_2, train_outputs_2 = task2.get_train_and_val_data(task2.folds[0])
test_inputs_2, test_outputs_2 = task2.get_test_data(task2.folds[0], include_target=True)

# ç°¡ç•¥åŒ–ã®ãŸã‚ã€æœ€åˆã®10,000ã‚µãƒ³ãƒ—ãƒ«ã®ã¿ä½¿ç”¨
n_samples = 10000
train_inputs_1 = train_inputs_1[:n_samples]
train_outputs_1 = train_outputs_1.values[:n_samples]
train_inputs_2 = train_inputs_2[:n_samples]
train_outputs_2 = train_outputs_2.values[:n_samples]

# ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿æ§‹ç¯‰
def create_multitask_data(structures, targets_task1, targets_task2):
    """
    ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
    """
    data_list = []
    for struct, t1, t2 in zip(structures, targets_task1, targets_task2):
        graph = structure_to_pyg_data(struct, t1)
        graph.y_task1 = torch.tensor([t1], dtype=torch.float)
        graph.y_task2 = torch.tensor([t2], dtype=torch.float)
        data_list.append(graph)
    return data_list

train_data_multi = create_multitask_data(train_inputs_1, train_outputs_1, train_outputs_2)
test_data_multi = create_multitask_data(test_inputs_1[:1000],
                                         test_outputs_1.values[:1000],
                                         test_outputs_2.values[:1000])

train_loader_multi = DataLoader(train_data_multi, batch_size=32, shuffle=True)
test_loader_multi = DataLoader(test_data_multi, batch_size=32, shuffle=False)

# MEGNetãƒãƒ«ãƒã‚¿ã‚¹ã‚¯ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´
print("\n=== MEGNetãƒãƒ«ãƒã‚¿ã‚¹ã‚¯ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ä¸­... ===")
megnet_model = MEGNetMultiTask(n_tasks=2).to(device)
optimizer_megnet = torch.optim.Adam(megnet_model.parameters(), lr=0.001)

# ã‚¿ã‚¹ã‚¯é‡ã¿ï¼ˆæå¤±ã®ãƒãƒ©ãƒ³ã‚¹èª¿æ•´ï¼‰
lambda_task1 = 1.0  # ç”Ÿæˆã‚¨ãƒãƒ«ã‚®ãƒ¼
lambda_task2 = 0.5  # ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—ï¼ˆã‚¹ã‚±ãƒ¼ãƒ«èª¿æ•´ï¼‰

megnet_model.train()
for epoch in range(30):
    total_loss = 0
    for batch in train_loader_multi:
        batch = batch.to(device)
        optimizer_megnet.zero_grad()

        # 2ã‚¿ã‚¹ã‚¯ã®äºˆæ¸¬
        pred_task1, pred_task2 = megnet_model(batch)

        # ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯æå¤±
        loss_task1 = nn.L1Loss()(pred_task1, batch.y_task1.squeeze())
        loss_task2 = nn.L1Loss()(pred_task2, batch.y_task2.squeeze())

        loss = lambda_task1 * loss_task1 + lambda_task2 * loss_task2
        loss.backward()
        optimizer_megnet.step()
        total_loss += loss.item()

    if (epoch + 1) % 10 == 0:
        print(f"Epoch {epoch+1}/30, Total Loss: {total_loss/len(train_loader_multi):.4f}")

# ãƒ†ã‚¹ãƒˆè©•ä¾¡ï¼ˆå„ã‚¿ã‚¹ã‚¯ï¼‰
megnet_model.eval()
y_true_task1, y_pred_task1 = [], []
y_true_task2, y_pred_task2 = [], []

with torch.no_grad():
    for batch in test_loader_multi:
        batch = batch.to(device)
        pred_task1, pred_task2 = megnet_model(batch)

        y_true_task1.extend(batch.y_task1.squeeze().cpu().numpy())
        y_pred_task1.extend(pred_task1.cpu().numpy())

        y_true_task2.extend(batch.y_task2.squeeze().cpu().numpy())
        y_pred_task2.extend(pred_task2.cpu().numpy())

mae_task1 = mean_absolute_error(y_true_task1, y_pred_task1)
mae_task2 = mean_absolute_error(y_true_task2, y_pred_task2)

print(f"\n=== MEGNetãƒãƒ«ãƒã‚¿ã‚¹ã‚¯çµæœ ===")
print(f"Task 1ï¼ˆç”Ÿæˆã‚¨ãƒãƒ«ã‚®ãƒ¼ï¼‰: MAE = {mae_task1:.4f} eV/atom")
print(f"Task 2ï¼ˆãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—ï¼‰:  MAE = {mae_task2:.4f} eV")

# å˜ä¸€ã‚¿ã‚¹ã‚¯ãƒ¢ãƒ‡ãƒ«ã¨ã®æ¯”è¼ƒï¼ˆå‚è€ƒï¼‰
print(f"\nå˜ä¸€ã‚¿ã‚¹ã‚¯CGCNNæ¯”è¼ƒ:")
print(f"Task 1: ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯ {mae_task1:.4f} vs å˜ä¸€ã‚¿ã‚¹ã‚¯ ~0.0286 eV/atom")
print(f"Task 2: ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯ {mae_task2:.4f} vs å˜ä¸€ã‚¿ã‚¹ã‚¯ ~0.180 eV")

# å‡ºåŠ›ä¾‹ï¼š
# === MEGNetãƒãƒ«ãƒã‚¿ã‚¹ã‚¯çµæœ ===
# Task 1ï¼ˆç”Ÿæˆã‚¨ãƒãƒ«ã‚®ãƒ¼ï¼‰: MAE = 0.0292 eV/atom
# Task 2ï¼ˆãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—ï¼‰:  MAE = 0.185 eV
#
# å˜ä¸€ã‚¿ã‚¹ã‚¯CGCNNæ¯”è¼ƒ:
# Task 1: ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯ 0.0292 vs å˜ä¸€ã‚¿ã‚¹ã‚¯ ~0.0286 eV/atomï¼ˆã‚ãšã‹ã«åŠ£åŒ–ï¼‰
# Task 2: ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯ 0.185 vs å˜ä¸€ã‚¿ã‚¹ã‚¯ ~0.180 eVï¼ˆåŒç¨‹åº¦ï¼‰
</code></pre>

        <h3>5.5.3 ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯å­¦ç¿’ã®åŠ¹æœ</h3>

        <p><strong>ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯å­¦ç¿’ã®ãƒ¡ãƒªãƒƒãƒˆï¼š</strong></p>
        <ul>
            <li><strong>ãƒ‡ãƒ¼ã‚¿åŠ¹ç‡ã®å‘ä¸Š</strong>ï¼šå˜ä¸€ã‚¿ã‚¹ã‚¯ã§10,000ã‚µãƒ³ãƒ—ãƒ«å¿…è¦ãªã¨ã“ã‚ã€5,000ã‚µãƒ³ãƒ—ãƒ«Ã—2ã‚¿ã‚¹ã‚¯ã§åŒç­‰æ€§èƒ½</li>
            <li><strong>æ±åŒ–æ€§èƒ½ã®å‘ä¸Š</strong>ï¼šã‚¿ã‚¹ã‚¯é–“ã®ç›¸é–¢ã‚’åˆ©ç”¨ã—ã€éå­¦ç¿’ã‚’æŠ‘åˆ¶</li>
            <li><strong>ãƒ¢ãƒ‡ãƒ«å…±æœ‰</strong>ï¼š1ã¤ã®ãƒ¢ãƒ‡ãƒ«ã§è¤‡æ•°ç‰©æ€§ã‚’äºˆæ¸¬å¯èƒ½</li>
        </ul>

        <p><strong>ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯å­¦ç¿’ã®èª²é¡Œï¼š</strong></p>
        <ul>
            <li><strong>è² ã®è»¢ç§»ï¼ˆNegative Transferï¼‰</strong>ï¼šã‚¿ã‚¹ã‚¯é–“ã®ç›¸é–¢ãŒä½ã„å ´åˆã€æ€§èƒ½ãŒåŠ£åŒ–</li>
            <li><strong>ã‚¿ã‚¹ã‚¯é‡ã¿ã®èª¿æ•´</strong>ï¼šé©åˆ‡ãª$\lambda_k$ã®è¨­å®šãŒå›°é›£</li>
            <li><strong>ã‚¹ã‚±ãƒ¼ãƒ«ã®é•ã„</strong>ï¼šç”Ÿæˆã‚¨ãƒãƒ«ã‚®ãƒ¼ï¼ˆeV/atomï¼‰ã¨ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—ï¼ˆeVï¼‰ã®ã‚¹ã‚±ãƒ¼ãƒ«å·®ã«å¯¾å‡¦ãŒå¿…è¦</li>
        </ul>

        <h2>5.6 ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½æ¯”è¼ƒ</h2>

        <p>æœ¬ç« ã§å®Ÿè£…ã—ãŸå…¨ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ‰‹æ³•ã®æ€§èƒ½ã‚’çµ±åˆæ¯”è¼ƒã—ã¾ã™ã€‚</p>

        <div class="highlight-box">
            <strong>ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹5ï¼šãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ‰‹æ³•ã®çµ±åˆæ¯”è¼ƒ</strong>
        </div>

        <pre><code class="language-python"># ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ‰‹æ³•ã®çµ±åˆæ¯”è¼ƒ
import matplotlib.pyplot as plt
import pandas as pd

# æ€§èƒ½ãƒ‡ãƒ¼ã‚¿ï¼ˆMatbench mp_e_formï¼‰
results = {
    'Model': [
        'Random Forest (Magpie)',
        'CGCNN',
        'Hybrid Early Fusion',
        'Hybrid Late Fusion',
        'ALIGNN (Simple)',
        'ALIGNN (Full)',
        'MEGNet Multi-Task'
    ],
    'MAE (eV/atom)': [0.0325, 0.0286, 0.0265, 0.0272, 0.0278, 0.0250, 0.0292],
    'RÂ²': [0.9321, 0.9524, 0.9614, 0.9582, 0.9548, 0.9680, 0.9510],
    'Training Time (min)': [0.75, 30.5, 32.0, 31.25, 35.0, 45.0, 50.0],
    'Category': ['Composition', 'GNN', 'Hybrid', 'Hybrid', 'Hybrid', 'Hybrid', 'Multi-Task']
}

df = pd.DataFrame(results)

# å¯è¦–åŒ–
fig, axes = plt.subplots(1, 2, figsize=(14, 6))

# MAEæ¯”è¼ƒ
colors = {'Composition': '#4caf50', 'GNN': '#667eea', 'Hybrid': '#764ba2', 'Multi-Task': '#ff9800'}
ax1 = axes[0]
bars = ax1.barh(df['Model'], df['MAE (eV/atom)'],
                color=[colors[cat] for cat in df['Category']])
ax1.set_xlabel('MAE (eV/atom)', fontsize=12)
ax1.set_title('äºˆæ¸¬ç²¾åº¦æ¯”è¼ƒï¼ˆLower is Betterï¼‰', fontsize=14, fontweight='bold')
ax1.invert_yaxis()

# ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã¨ã®æ¯”è¼ƒç·š
ax1.axvline(0.0325, color='red', linestyle='--', linewidth=1, alpha=0.7, label='RF Baseline')
ax1.legend()

# è¨“ç·´æ™‚é–“ vs MAE
ax2 = axes[1]
for idx, row in df.iterrows():
    ax2.scatter(row['Training Time (min)'], row['MAE (eV/atom)'],
                s=200, color=colors[row['Category']], alpha=0.7, edgecolors='black', linewidth=1.5)
    ax2.text(row['Training Time (min)'], row['MAE (eV/atom)'],
             row['Model'], fontsize=8, ha='right', va='bottom')

ax2.set_xlabel('è¨“ç·´æ™‚é–“ (åˆ†)', fontsize=12)
ax2.set_ylabel('MAE (eV/atom)', fontsize=12)
ax2.set_title('è¨“ç·´æ™‚é–“ vs ç²¾åº¦ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•', fontsize=14, fontweight='bold')
ax2.invert_yaxis()
ax2.grid(alpha=0.3)

plt.tight_layout()
plt.savefig('hybrid_comparison.png', dpi=300, bbox_inches='tight')
plt.show()

# çµ±è¨ˆã‚µãƒãƒªãƒ¼
print("=== ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ‰‹æ³•çµ±åˆæ¯”è¼ƒ ===")
print(df.to_string(index=False))

# æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ã®è­˜åˆ¥
best_mae_idx = df['MAE (eV/atom)'].idxmin()
best_efficiency_idx = (df['MAE (eV/atom)'] / df['Training Time (min)']).idxmin()

print(f"\næœ€é«˜ç²¾åº¦ãƒ¢ãƒ‡ãƒ«: {df.loc[best_mae_idx, 'Model']} (MAE = {df.loc[best_mae_idx, 'MAE (eV/atom)']:.4f})")
print(f"æœ€é«˜åŠ¹ç‡ãƒ¢ãƒ‡ãƒ«: {df.loc[best_efficiency_idx, 'Model']} (MAE/Time = {df.loc[best_efficiency_idx, 'MAE (eV/atom)'] / df.loc[best_efficiency_idx, 'Training Time (min)']:.6f})")

# å‡ºåŠ›ä¾‹ï¼š
# === ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ‰‹æ³•çµ±åˆæ¯”è¼ƒ ===
#                       Model  MAE (eV/atom)     RÂ²  Training Time (min)    Category
#   Random Forest (Magpie)         0.0325  0.9321                 0.75 Composition
#                    CGCNN         0.0286  0.9524                30.50         GNN
#      Hybrid Early Fusion         0.0265  0.9614                32.00      Hybrid
#       Hybrid Late Fusion         0.0272  0.9582                31.25      Hybrid
#           ALIGNN (Simple)         0.0278  0.9548                35.00      Hybrid
#             ALIGNN (Full)         0.0250  0.9680                45.00      Hybrid
#        MEGNet Multi-Task         0.0292  0.9510                50.00  Multi-Task
#
# æœ€é«˜ç²¾åº¦ãƒ¢ãƒ‡ãƒ«: ALIGNN (Full) (MAE = 0.0250)
# æœ€é«˜åŠ¹ç‡ãƒ¢ãƒ‡ãƒ«: Random Forest (Magpie) (MAE/Time = 0.043333)
</code></pre>

        <h3>5.6.1 æ€§èƒ½åˆ†æã®ã¾ã¨ã‚</h3>

        <table>
            <thead>
                <tr>
                    <th>æ‰‹æ³•</th>
                    <th>ç²¾åº¦</th>
                    <th>åŠ¹ç‡</th>
                    <th>å®Ÿè£…é›£æ˜“åº¦</th>
                    <th>æ¨å¥¨ã‚·ãƒŠãƒªã‚ª</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>Hybrid Early Fusion</td>
                    <td>â­â­â­â­</td>
                    <td>â­â­â­</td>
                    <td>ä½</td>
                    <td>ä¸­è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã€å®Ÿè£…å®¹æ˜“æ€§é‡è¦–</td>
                </tr>
                <tr>
                    <td>Hybrid Late Fusion</td>
                    <td>â­â­â­</td>
                    <td>â­â­</td>
                    <td>ä½</td>
                    <td>æ—¢å­˜ãƒ¢ãƒ‡ãƒ«ã®çµ±åˆã€å®‰å®šæ€§é‡è¦–</td>
                </tr>
                <tr>
                    <td>ALIGNN (Full)</td>
                    <td>â­â­â­â­â­</td>
                    <td>â­â­</td>
                    <td>é«˜</td>
                    <td>æœ€é«˜ç²¾åº¦ãŒå¿…é ˆã€è¨ˆç®—ãƒªã‚½ãƒ¼ã‚¹ååˆ†</td>
                </tr>
                <tr>
                    <td>MEGNet Multi-Task</td>
                    <td>â­â­â­</td>
                    <td>â­â­â­</td>
                    <td>ä¸­</td>
                    <td>è¤‡æ•°ç‰©æ€§äºˆæ¸¬ã€ãƒ‡ãƒ¼ã‚¿åŠ¹ç‡é‡è¦–</td>
                </tr>
            </tbody>
        </table>

        <h2>5.7 æœ¬ç« ã®ã¾ã¨ã‚</h2>

        <p>æœ¬ç« ã§ã¯ã€çµ„æˆãƒ™ãƒ¼ã‚¹ã¨GNNæ§‹é€ ãƒ™ãƒ¼ã‚¹ç‰¹å¾´é‡ã‚’çµ±åˆã™ã‚‹<strong>ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ</strong>ã‚’ä½“ç³»çš„ã«å­¦ã³ã¾ã—ãŸã€‚</p>

        <h3>ä¸»è¦ãªçŸ¥è¦‹</h3>

        <ul>
            <li><strong>Early Fusion</strong>ï¼šç‰¹å¾´é‡é€£çµã«ã‚ˆã‚Šã€CGCNNå˜ç‹¬æ¯”7.3%ç²¾åº¦å‘ä¸Šï¼ˆMAE 0.0265 eV/atomï¼‰</li>
            <li><strong>Late Fusion</strong>ï¼šã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬ã«ã‚ˆã‚Šã€å®‰å®šæ€§å‘ä¸Šã¨ãƒªã‚¹ã‚¯åˆ†æ•£ã‚’å®Ÿç¾</li>
            <li><strong>ALIGNN</strong>ï¼šç·šã‚°ãƒ©ãƒ•ã«ã‚ˆã‚‹çµåˆè§’åº¦æƒ…å ±ã®çµ±åˆã§ã€æœ€å…ˆç«¯ç²¾åº¦ï¼ˆMAE 0.0250 eV/atomï¼‰</li>
            <li><strong>MEGNet</strong>ï¼šãƒãƒ«ãƒã‚¿ã‚¹ã‚¯å­¦ç¿’ã«ã‚ˆã‚‹ãƒ‡ãƒ¼ã‚¿åŠ¹ç‡ã¨æ±åŒ–æ€§èƒ½ã®å‘ä¸Š</li>
        </ul>

        <div class="highlight-box">
            <strong>ğŸ¯ å®Ÿå‹™ä¸Šã®æ¨å¥¨</strong>
            <ul>
                <li><strong>ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ”ãƒ³ã‚°</strong>ï¼šHybrid Early Fusionï¼ˆå®Ÿè£…å®¹æ˜“ã€ååˆ†ãªç²¾åº¦ï¼‰</li>
                <li><strong>æœ€é«˜ç²¾åº¦è¿½æ±‚</strong>ï¼šALIGNNå®Œå…¨ç‰ˆï¼ˆè¨ˆç®—ã‚³ã‚¹ãƒˆè¨±å®¹ã§ãã‚‹å ´åˆï¼‰</li>
                <li><strong>è¤‡æ•°ç‰©æ€§äºˆæ¸¬</strong>ï¼šMEGNetãƒãƒ«ãƒã‚¿ã‚¹ã‚¯ï¼ˆãƒ‡ãƒ¼ã‚¿åŠ¹ç‡é‡è¦–ï¼‰</li>
                <li><strong>å®‰å®šæ€§é‡è¦–</strong>ï¼šLate Fusionï¼ˆæ—¢å­˜ãƒ¢ãƒ‡ãƒ«ã®çµ±åˆãŒå®¹æ˜“ï¼‰</li>
            </ul>
        </div>

        <h2>æ¼”ç¿’å•é¡Œ</h2>

        <div class="exercise">
            <div class="exercise-header">æ¼”ç¿’1ï¼šEarly Fusionã®ç‰¹å¾´é‡æ¬¡å…ƒ <span class="difficulty difficulty-easy">Easy</span></div>
            <p><strong>å•é¡Œï¼š</strong>Magpieç‰¹å¾´é‡ï¼ˆ145æ¬¡å…ƒï¼‰ã¨GNNåŸ‹ã‚è¾¼ã¿ï¼ˆ256æ¬¡å…ƒï¼‰ã‚’Early Fusionã§çµ±åˆã™ã‚‹å ´åˆã€çµ±åˆå¾Œã®ç‰¹å¾´é‡æ¬¡å…ƒã¯ã„ãã¤ã«ãªã‚‹ã‹ï¼Ÿã¾ãŸã€éå­¦ç¿’ãƒªã‚¹ã‚¯ã‚’ä½æ¸›ã™ã‚‹ãŸã‚ã®æ‰‹æ³•ã‚’2ã¤æŒ™ã’ã‚ˆã€‚</p>
            <p><strong>è§£ç­”ï¼š</strong></p>
            <p>çµ±åˆå¾Œã®ç‰¹å¾´é‡æ¬¡å…ƒ: 145 + 256 = <strong>401æ¬¡å…ƒ</strong></p>
            <p>éå­¦ç¿’ãƒªã‚¹ã‚¯ä½æ¸›æ‰‹æ³•:</p>
            <ol>
                <li><strong>Dropout</strong>: çµ±åˆå±¤ã¨äºˆæ¸¬å±¤ã®é–“ã«Dropoutï¼ˆä¾‹ï¼šp=0.3ï¼‰ã‚’æŒ¿å…¥ã—ã€ãƒ©ãƒ³ãƒ€ãƒ ã«ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã‚’ç„¡åŠ¹åŒ–</li>
                <li><strong>L2æ­£å‰‡åŒ–</strong>: æå¤±é–¢æ•°ã«é‡ã¿æ¸›è¡°é …ã‚’è¿½åŠ ï¼ˆä¾‹ï¼šweight_decay=1e-4ï¼‰</li>
            </ol>
        </div>

        <div class="exercise">
            <div class="exercise-header">æ¼”ç¿’2ï¼šLate Fusionã®æœ€é©é‡ã¿ <span class="difficulty difficulty-easy">Easy</span></div>
            <p><strong>å•é¡Œï¼š</strong>Random Forestï¼ˆMAE 0.035 eV/atomï¼‰ã¨CGCNNï¼ˆMAE 0.028 eV/atomï¼‰ã®Late Fusionã§ã€æœ€é©é‡ã¿Î±=0.20ãŒå¾—ã‚‰ã‚ŒãŸã€‚ã“ã®é‡ã¿ã®æ„å‘³ã‚’è§£é‡ˆã—ã€ãªãœCGCNNã®é‡ã¿ãŒé«˜ã„ã®ã‹èª¬æ˜ã›ã‚ˆã€‚</p>
            <p><strong>è§£ç­”ï¼š</strong></p>
            <p><strong>é‡ã¿ã®æ„å‘³ï¼š</strong></p>
            <p>$$\hat{y}_{\text{ensemble}} = 0.20 \times \hat{y}_{\text{RF}} + 0.80 \times \hat{y}_{\text{CGCNN}}$$</p>
            <p>CGCNNã®äºˆæ¸¬ã‚’80%ã€RFã®äºˆæ¸¬ã‚’20%ã§çµ±åˆã€‚</p>
            <p><strong>CGCNNé‡ã¿ãŒé«˜ã„ç†ç”±ï¼š</strong></p>
            <ul>
                <li>CGCNNã®å€‹åˆ¥æ€§èƒ½ï¼ˆMAE 0.028ï¼‰ãŒRFï¼ˆMAE 0.035ï¼‰ã‚ˆã‚Š20%å„ªã‚Œã¦ã„ã‚‹</li>
                <li>ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã§ã¯é«˜æ€§èƒ½ãƒ¢ãƒ‡ãƒ«ã«å¤§ããªé‡ã¿ã‚’å‰²ã‚Šå½“ã¦ã‚‹ã“ã¨ãŒæœ€é©</li>
                <li>RFã®äºˆæ¸¬ã¯è£œåŠ©çš„ãªå½¹å‰²ï¼ˆå¤–ã‚Œå€¤è£œæ­£ã€å®‰å®šæ€§å‘ä¸Šï¼‰ã¨ã—ã¦æ´»ç”¨</li>
            </ul>
        </div>

        <div class="exercise">
            <div class="exercise-header">æ¼”ç¿’3ï¼šALIGNNã®ç·šã‚°ãƒ©ãƒ• <span class="difficulty difficulty-medium">Medium</span></div>
            <p><strong>å•é¡Œï¼š</strong>åŸå­ã‚°ãƒ©ãƒ•ã¨ç·šã‚°ãƒ©ãƒ•ã®é•ã„ã‚’èª¬æ˜ã—ã€ç·šã‚°ãƒ©ãƒ•ãŒçµåˆè§’åº¦æƒ…å ±ã‚’ã©ã®ã‚ˆã†ã«è¡¨ç¾ã™ã‚‹ã‹å…·ä½“ä¾‹ã‚’ç¤ºã›ã€‚</p>
            <p><strong>è§£ç­”ï¼š</strong></p>
            <p><strong>åŸå­ã‚°ãƒ©ãƒ•ï¼ˆAtom Graphï¼‰ï¼š</strong></p>
            <ul>
                <li>ãƒãƒ¼ãƒ‰: åŸå­</li>
                <li>ã‚¨ãƒƒã‚¸: åŸå­é–“ã®çµåˆï¼ˆè·é›¢ãƒ™ãƒ¼ã‚¹ï¼‰</li>
                <li>ä¾‹: æ°´åˆ†å­Hâ‚‚O â†’ ãƒãƒ¼ãƒ‰3å€‹ï¼ˆO, H, Hï¼‰ã€ã‚¨ãƒƒã‚¸2æœ¬ï¼ˆO-H, O-Hï¼‰</li>
            </ul>
            <p><strong>ç·šã‚°ãƒ©ãƒ•ï¼ˆLine Graphï¼‰ï¼š</strong></p>
            <ul>
                <li>ãƒãƒ¼ãƒ‰: åŸå­é–“ã®çµåˆ</li>
                <li>ã‚¨ãƒƒã‚¸: çµåˆè§’åº¦ï¼ˆåŒã˜åŸå­ã‚’å…±æœ‰ã™ã‚‹2ã¤ã®çµåˆï¼‰</li>
                <li>ä¾‹: æ°´åˆ†å­Hâ‚‚O â†’ ãƒãƒ¼ãƒ‰2å€‹ï¼ˆO-Hçµåˆ1, O-Hçµåˆ2ï¼‰ã€ã‚¨ãƒƒã‚¸1æœ¬ï¼ˆçµåˆ1ã¨çµåˆ2ã®è§’åº¦ â‰ˆ 104.5Â°ï¼‰</li>
            </ul>
            <p><strong>çµåˆè§’åº¦æƒ…å ±ã®è¡¨ç¾ï¼š</strong></p>
            <p>ç·šã‚°ãƒ©ãƒ•ã®ã‚¨ãƒƒã‚¸ç‰¹å¾´é‡ã¨ã—ã¦ã€2ã¤ã®çµåˆãŒä½œã‚‹è§’åº¦Î¸ã‚’ä»¥ä¸‹ã®ã‚ˆã†ã«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ï¼š</p>
            <pre><code class="language-python">angle_feature = torch.cos(theta)  # cosÎ¸ã‚’ç‰¹å¾´é‡ã«ä½¿ç”¨
# ä¾‹: H-O-Hè§’åº¦104.5Â° â†’ cos(104.5Â°) â‰ˆ -0.25
</code></pre>
            <p>ã“ã‚Œã«ã‚ˆã‚Šã€ALIGNNã¯ã€Œç›´ç·šçš„ãªçµåˆï¼ˆÎ¸=180Â°ï¼‰ã€ã¨ã€Œå±ˆæ›²ã—ãŸçµåˆï¼ˆÎ¸<120Â°ï¼‰ã€ã‚’æ˜ç¤ºçš„ã«åŒºåˆ¥ã§ãã¾ã™ã€‚</p>
        </div>

        <div class="exercise">
            <div class="exercise-header">æ¼”ç¿’4ï¼šãƒãƒ«ãƒã‚¿ã‚¹ã‚¯å­¦ç¿’ã®æå¤±é‡ã¿ <span class="difficulty difficulty-medium">Medium</span></div>
            <p><strong>å•é¡Œï¼š</strong>ç”Ÿæˆã‚¨ãƒãƒ«ã‚®ãƒ¼ï¼ˆã‚¹ã‚±ãƒ¼ãƒ«ï¼š-5ï½5 eV/atomï¼‰ã¨ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—ï¼ˆã‚¹ã‚±ãƒ¼ãƒ«ï¼š0ï½10 eVï¼‰ã‚’åŒæ™‚äºˆæ¸¬ã™ã‚‹ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯GNNã«ãŠã„ã¦ã€é©åˆ‡ãªã‚¿ã‚¹ã‚¯é‡ã¿Î»â‚ã€Î»â‚‚ã‚’è¨­è¨ˆã›ã‚ˆã€‚å˜ç´”ã«$\lambda_1 = \lambda_2 = 1.0$ã¨ã—ãŸå ´åˆã®å•é¡Œç‚¹ã‚‚èª¬æ˜ã™ã‚‹ã“ã¨ã€‚</p>
            <p><strong>è§£ç­”ï¼š</strong></p>
            <p><strong>å•é¡Œç‚¹ï¼ˆ$\lambda_1 = \lambda_2 = 1.0$ï¼‰ï¼š</strong></p>
            <p>ç”Ÿæˆã‚¨ãƒãƒ«ã‚®ãƒ¼ã¨ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—ã®ã‚¹ã‚±ãƒ¼ãƒ«ãŒç•°ãªã‚‹ãŸã‚ã€æå¤±ã®å¤§ãã•ãŒä¸å‡è¡¡ã«ãªã‚Šã¾ã™ï¼š</p>
            <pre><code class="language-python"># ç”Ÿæˆã‚¨ãƒãƒ«ã‚®ãƒ¼ã®å…¸å‹çš„ãªMAE: 0.03 eV/atom
loss_task1 = 0.03

# ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—ã®å…¸å‹çš„ãªMAE: 0.18 eV
loss_task2 = 0.18

# ç·æå¤±ï¼ˆÎ»â‚ = Î»â‚‚ = 1.0ï¼‰
total_loss = 1.0 * 0.03 + 1.0 * 0.18 = 0.21
# â†’ ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—ã®æå¤±ãŒ6å€å¤§ãã„ â†’ ç”Ÿæˆã‚¨ãƒãƒ«ã‚®ãƒ¼ã®å­¦ç¿’ãŒä¸ååˆ†
</code></pre>
            <p><strong>é©åˆ‡ãªã‚¿ã‚¹ã‚¯é‡ã¿ã®è¨­è¨ˆï¼š</strong></p>
            <p>å„ã‚¿ã‚¹ã‚¯ã®æå¤±ã‚’åŒç¨‹åº¦ã«ã™ã‚‹ãŸã‚ã€ã‚¹ã‚±ãƒ¼ãƒ«ã®é€†æ•°ã§é‡ã¿ä»˜ã‘ï¼š</p>
            <pre><code class="language-python"># ã‚¿ã‚¹ã‚¯é‡ã¿ã®è¨­å®š
lambda_1 = 1.0  # ç”Ÿæˆã‚¨ãƒãƒ«ã‚®ãƒ¼ï¼ˆåŸºæº–ï¼‰
lambda_2 = 0.03 / 0.18 â‰ˆ 0.17  # ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—ï¼ˆã‚¹ã‚±ãƒ¼ãƒ«èª¿æ•´ï¼‰

# ã¾ãŸã¯ã€æ¨™æº–åå·®ã®é€†æ•°ã‚’ä½¿ç”¨
std_task1 = 1.5  # ç”Ÿæˆã‚¨ãƒãƒ«ã‚®ãƒ¼ã®æ¨™æº–åå·®
std_task2 = 2.0  # ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—ã®æ¨™æº–åå·®

lambda_1 = 1 / std_task1 â‰ˆ 0.67
lambda_2 = 1 / std_task2 = 0.50

# æ­£è¦åŒ–ã—ã¦åˆè¨ˆã‚’1ã«ã™ã‚‹
lambda_1 = 0.67 / (0.67 + 0.50) â‰ˆ 0.57
lambda_2 = 0.50 / (0.67 + 0.50) â‰ˆ 0.43
</code></pre>
        </div>

        <div class="exercise">
            <div class="exercise-header">æ¼”ç¿’5ï¼šãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ‰‹æ³•ã®é¸æŠ <span class="difficulty difficulty-medium">Medium</span></div>
            <p><strong>å•é¡Œï¼š</strong>ä»¥ä¸‹ã®3ã¤ã®ã‚·ãƒŠãƒªã‚ªã«å¯¾ã—ã¦ã€æœ€é©ãªãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ‰‹æ³•ã‚’é¸æŠã—ã€ãã®ç†ç”±ã‚’è¿°ã¹ã‚ˆã€‚</p>
            <p><strong>ã‚·ãƒŠãƒªã‚ªA</strong>: ãƒ‡ãƒ¼ã‚¿30,000ã‚µãƒ³ãƒ—ãƒ«ã€GPUåˆ©ç”¨å¯èƒ½ã€ç²¾åº¦å„ªå…ˆã€å®Ÿè£…æœŸé™2é€±é–“</p>
            <p><strong>ã‚·ãƒŠãƒªã‚ªB</strong>: ãƒ‡ãƒ¼ã‚¿100,000ã‚µãƒ³ãƒ—ãƒ«ã€GPUè¤‡æ•°å°ã€æœ€é«˜ç²¾åº¦ãŒå¿…é ˆã€è¨ˆç®—æ™‚é–“åˆ¶ç´„ãªã—</p>
            <p><strong>ã‚·ãƒŠãƒªã‚ªC</strong>: æ—¢å­˜ã®RFãƒ¢ãƒ‡ãƒ«ã¨CGCNNãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚Šã€çµ±åˆã—ãŸã„ã€ãƒªã‚¹ã‚¯å›é¿é‡è¦–</p>
            <p><strong>è§£ç­”ï¼š</strong></p>
            <p><strong>ã‚·ãƒŠãƒªã‚ªA â†’ Hybrid Early Fusion</strong></p>
            <ul>
                <li>30,000ã‚µãƒ³ãƒ—ãƒ«ã¯ä¸­è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã§ã€Early Fusionã®ãƒ‡ãƒ¼ã‚¿åŠ¹ç‡ãŒæ´»ãã‚‹</li>
                <li>å®Ÿè£…ãŒå˜ç´”ï¼ˆ2é€±é–“ã§ååˆ†å®Ÿè£…å¯èƒ½ï¼‰</li>
                <li>CGCNNæ¯”7.3%ç²¾åº¦å‘ä¸ŠãŒæœŸå¾…ã§ãã‚‹</li>
            </ul>
            <p><strong>ã‚·ãƒŠãƒªã‚ªB â†’ ALIGNN (Full)</strong></p>
            <ul>
                <li>100,000ã‚µãƒ³ãƒ—ãƒ«ã¯å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã§ã€ALIGNNã®æ€§èƒ½ãŒæœ€å¤§åŒ–</li>
                <li>GPUè¤‡æ•°å°ã§ä¸¦åˆ—è¨“ç·´å¯èƒ½</li>
                <li>æœ€é«˜ç²¾åº¦ï¼ˆMAE 0.025 eV/atomï¼‰ãŒé”æˆå¯èƒ½</li>
            </ul>
            <p><strong>ã‚·ãƒŠãƒªã‚ªC â†’ Hybrid Late Fusion</strong></p>
            <ul>
                <li>æ—¢å­˜ãƒ¢ãƒ‡ãƒ«ã‚’ãã®ã¾ã¾æ´»ç”¨å¯èƒ½ï¼ˆå†è¨“ç·´ä¸è¦ï¼‰</li>
                <li>ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã«ã‚ˆã‚Šã€ç‰‡æ–¹ã®ãƒ¢ãƒ‡ãƒ«å¤±æ•—æ™‚ã‚‚å®‰å®šå‹•ä½œ</li>
                <li>ãƒªã‚¹ã‚¯åˆ†æ•£ãŒæœ€ã‚‚åŠ¹æœçš„</li>
            </ul>
        </div>

        <div class="exercise">
            <div class="exercise-header">æ¼”ç¿’6ï¼šEarly Fusionã®å®Ÿè£… <span class="difficulty difficulty-hard">Hard</span></div>
            <p><strong>å•é¡Œï¼š</strong>Hybrid Early Fusionãƒ¢ãƒ‡ãƒ«ã«<strong>Attentionæ©Ÿæ§‹</strong>ã‚’å°å…¥ã—ã€çµ„æˆç‰¹å¾´é‡ã¨GNNåŸ‹ã‚è¾¼ã¿ã®é‡è¦åº¦ã‚’å‹•çš„ã«èª¿æ•´ã™ã‚‹ã‚³ãƒ¼ãƒ‰ã‚’è¨˜è¿°ã›ã‚ˆã€‚</p>
            <p><strong>è§£ç­”ï¼š</strong></p>
            <pre><code class="language-python"># Attentionæ©Ÿæ§‹ä»˜ãEarly Fusion
import torch
import torch.nn as nn
import torch.nn.functional as F

class AttentionEarlyFusion(nn.Module):
    def __init__(self, composition_dim=145, gnn_dim=128):
        super(AttentionEarlyFusion, self).__init__()

        # ç‰¹å¾´é‡å¤‰æ›å±¤ï¼ˆåŒã˜æ¬¡å…ƒã«çµ±ä¸€ï¼‰
        self.comp_transform = nn.Linear(composition_dim, gnn_dim)
        # GNNéƒ¨åˆ†ï¼ˆçœç•¥ã€CGCNNã¨åŒã˜ï¼‰

        # Attentionæ©Ÿæ§‹
        self.attention_comp = nn.Linear(gnn_dim, 1)
        self.attention_gnn = nn.Linear(gnn_dim, 1)

        # äºˆæ¸¬å±¤
        self.fc = nn.Sequential(
            nn.Linear(gnn_dim, 64),
            nn.Softplus(),
            nn.Linear(64, 1)
        )

    def forward(self, data, composition_features):
        # çµ„æˆç‰¹å¾´é‡ã‚’å¤‰æ›ï¼ˆ145 â†’ 128æ¬¡å…ƒï¼‰
        comp_transformed = self.comp_transform(composition_features)

        # GNNåŸ‹ã‚è¾¼ã¿è¨ˆç®—ï¼ˆçœç•¥ã€CGCNNã¨åŒã˜å‡¦ç†ï¼‰
        # gnn_embedding = ... (shape: batch_size, 128)

        # Attentioné‡ã¿ã®è¨ˆç®—
        alpha_comp = self.attention_comp(comp_transformed)  # (batch_size, 1)
        alpha_gnn = self.attention_gnn(gnn_embedding)       # (batch_size, 1)

        # Softmaxæ­£è¦åŒ–
        attention_weights = F.softmax(torch.cat([alpha_comp, alpha_gnn], dim=1), dim=1)
        w_comp = attention_weights[:, 0:1]  # çµ„æˆç‰¹å¾´é‡ã®é‡ã¿
        w_gnn = attention_weights[:, 1:2]   # GNNåŸ‹ã‚è¾¼ã¿ã®é‡ã¿

        # é‡ã¿ä»˜ãçµ±åˆ
        hybrid_features = w_comp * comp_transformed + w_gnn * gnn_embedding

        # äºˆæ¸¬
        out = self.fc(hybrid_features)
        return out.squeeze(), w_comp.squeeze(), w_gnn.squeeze()

# ä½¿ç”¨ä¾‹
model = AttentionEarlyFusion().to(device)
# ... è¨“ç·´ ...

# æ¨è«–æ™‚ã«Attentioné‡ã¿ã‚’ç¢ºèª
model.eval()
with torch.no_grad():
    pred, w_comp, w_gnn = model(test_data, test_comp_feats)
    print(f"çµ„æˆç‰¹å¾´é‡é‡ã¿: {w_comp.mean():.3f}")
    print(f"GNNåŸ‹ã‚è¾¼ã¿é‡ã¿: {w_gnn.mean():.3f}")

# å‡ºåŠ›ä¾‹ï¼š
# çµ„æˆç‰¹å¾´é‡é‡ã¿: 0.285
# GNNåŸ‹ã‚è¾¼ã¿é‡ã¿: 0.715
# â†’ ãƒ‡ãƒ¼ã‚¿ã«å¿œã˜ã¦å‹•çš„ã«é‡ã¿èª¿æ•´
</code></pre>
        </div>

        <div class="exercise">
            <div class="exercise-header">æ¼”ç¿’7ï¼šè² ã®è»¢ç§»ã®æ¤œå‡º <span class="difficulty difficulty-hard">Hard</span></div>
            <p><strong>å•é¡Œï¼š</strong>ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯å­¦ç¿’ã«ãŠã„ã¦ã€ã€Œè² ã®è»¢ç§»ï¼ˆNegative Transferï¼‰ã€ãŒç™ºç”Ÿã—ã¦ã„ã‚‹ã‹ã‚’æ¤œå‡ºã™ã‚‹æ‰‹æ³•ã‚’ææ¡ˆã—ã€ãã®å¯¾ç­–ã‚’3ã¤æŒ™ã’ã‚ˆã€‚</p>
            <p><strong>è§£ç­”ï¼š</strong></p>
            <p><strong>è² ã®è»¢ç§»ã®æ¤œå‡ºæ‰‹æ³•ï¼š</strong></p>
            <pre><code class="language-python"># è² ã®è»¢ç§»ã®æ¤œå‡º
# å˜ä¸€ã‚¿ã‚¹ã‚¯ãƒ¢ãƒ‡ãƒ«ã¨ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’æ¯”è¼ƒ

# å˜ä¸€ã‚¿ã‚¹ã‚¯ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´
single_task1_model = train_single_task(task1_data)
single_task2_model = train_single_task(task2_data)

# ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´
multi_task_model = train_multi_task(task1_data, task2_data)

# æ€§èƒ½è©•ä¾¡
mae_single_task1 = evaluate(single_task1_model, task1_test_data)
mae_single_task2 = evaluate(single_task2_model, task2_test_data)

mae_multi_task1 = evaluate_multitask(multi_task_model, task1_test_data, task_idx=0)
mae_multi_task2 = evaluate_multitask(multi_task_model, task2_test_data, task_idx=1)

# è² ã®è»¢ç§»ã®åˆ¤å®š
if mae_multi_task1 > mae_single_task1:
    print("Task 1ã§è² ã®è»¢ç§»ç™ºç”Ÿ")
if mae_multi_task2 > mae_single_task2:
    print("Task 2ã§è² ã®è»¢ç§»ç™ºç”Ÿ")

# å‡ºåŠ›ä¾‹ï¼š
# Task 1ã§è² ã®è»¢ç§»ç™ºç”Ÿï¼ˆãƒãƒ«ãƒ 0.0295 > å˜ä¸€ 0.0286ï¼‰
# â†’ ã‚¿ã‚¹ã‚¯é–“ã®ç›¸é–¢ãŒä½ã„ã€ã¾ãŸã¯ã‚¿ã‚¹ã‚¯é‡ã¿ãŒä¸é©åˆ‡
</code></pre>
            <p><strong>è² ã®è»¢ç§»ã®å¯¾ç­–ï¼š</strong></p>
            <ol>
                <li><strong>ã‚¿ã‚¹ã‚¯ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°</strong>ï¼šç›¸é–¢ã®é«˜ã„ã‚¿ã‚¹ã‚¯ã®ã¿ã‚’ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã—ã¦ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯å­¦ç¿’
                    <pre><code class="language-python"># ã‚¿ã‚¹ã‚¯é–“ã®ç›¸é–¢ã‚’è¨ˆç®—
from scipy.stats import pearsonr

# Task 1ã¨Task 2ã®äºˆæ¸¬å€¤ã®ç›¸é–¢
corr, _ = pearsonr(y_pred_task1, y_pred_task2)

if corr > 0.5:
    print("é«˜ç›¸é–¢ â†’ ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯å­¦ç¿’æ¨å¥¨")
else:
    print("ä½ç›¸é–¢ â†’ å˜ä¸€ã‚¿ã‚¹ã‚¯å­¦ç¿’æ¨å¥¨")
</code></pre>
                </li>
                <li><strong>ã‚¿ã‚¹ã‚¯å›ºæœ‰ã®å±¤ã‚’å¢—ã‚„ã™</strong>ï¼šå…±æœ‰å±¤ã‚’æµ…ãã—ã€ã‚¿ã‚¹ã‚¯å›ºæœ‰å±¤ã‚’æ·±ãã™ã‚‹ã“ã¨ã§è² ã®è»¢ç§»ã‚’æŠ‘åˆ¶
                    <pre><code class="language-python">self.shared_layers = nn.Sequential(  # å…±æœ‰: 2å±¤ã®ã¿
    nn.Linear(input_dim, 128),
    nn.Softplus()
)

self.task1_layers = nn.Sequential(  # ã‚¿ã‚¹ã‚¯å›ºæœ‰: 3å±¤
    nn.Linear(128, 128),
    nn.Softplus(),
    nn.Linear(128, 64),
    nn.Softplus(),
    nn.Linear(64, 1)
)
</code></pre>
                </li>
                <li><strong>å‹•çš„ã‚¿ã‚¹ã‚¯é‡ã¿èª¿æ•´</strong>ï¼šè¨“ç·´ä¸­ã«ã‚¿ã‚¹ã‚¯é‡ã¿ã‚’é©å¿œçš„ã«å¤‰æ›´
                    <pre><code class="language-python"># Uncertainty Weightingï¼ˆä¸ç¢ºå®Ÿæ€§ã«åŸºã¥ãé‡ã¿èª¿æ•´ï¼‰
class MultiTaskUncertaintyWeighting(nn.Module):
    def __init__(self, n_tasks=2):
        super().__init__()
        self.log_vars = nn.Parameter(torch.zeros(n_tasks))

    def forward(self, losses):
        # ã‚¿ã‚¹ã‚¯kã®é‡ã¿: 1 / (2 * Ïƒ_kÂ²)
        weighted_losses = []
        for i, loss in enumerate(losses):
            precision = torch.exp(-self.log_vars[i])
            weighted_loss = precision * loss + self.log_vars[i]
            weighted_losses.append(weighted_loss)
        return sum(weighted_losses)

# ä½¿ç”¨ä¾‹
uncertainty_weighting = MultiTaskUncertaintyWeighting(n_tasks=2)
total_loss = uncertainty_weighting([loss_task1, loss_task2])
</code></pre>
                </li>
            </ol>
        </div>

        <div class="exercise">
            <div class="exercise-header">æ¼”ç¿’8ï¼šãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«ã®è§£é‡ˆå¯èƒ½æ€§ <span class="difficulty difficulty-hard">Hard</span></div>
            <p><strong>å•é¡Œï¼š</strong>Hybrid Early Fusionãƒ¢ãƒ‡ãƒ«ã«ãŠã„ã¦ã€ã€Œçµ„æˆç‰¹å¾´é‡ã¨GNNåŸ‹ã‚è¾¼ã¿ã®ã©ã¡ã‚‰ãŒäºˆæ¸¬ã«å¯„ä¸ã—ã¦ã„ã‚‹ã‹ã€ã‚’å®šé‡çš„ã«åˆ†æã™ã‚‹æ‰‹æ³•ã‚’ææ¡ˆã—ã€å®Ÿè£…ã›ã‚ˆã€‚</p>
            <p><strong>è§£ç­”ï¼š</strong></p>
            <pre><code class="language-python"># ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«ã®è§£é‡ˆå¯èƒ½æ€§åˆ†æ
import numpy as np
from sklearn.inspection import permutation_importance

def hybrid_feature_importance_analysis(model, test_data, test_comp_feats, test_targets):
    """
    çµ„æˆç‰¹å¾´é‡ã¨GNNåŸ‹ã‚è¾¼ã¿ã®å¯„ä¸åº¦ã‚’åˆ†æ

    Returns:
    --------
    comp_importance : float
        çµ„æˆç‰¹å¾´é‡ã®é‡è¦åº¦
    gnn_importance : float
        GNNåŸ‹ã‚è¾¼ã¿ã®é‡è¦åº¦
    """
    model.eval()

    # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³äºˆæ¸¬ï¼ˆé€šå¸¸ã®äºˆæ¸¬ï¼‰
    with torch.no_grad():
        baseline_pred = model(test_data, test_comp_feats).cpu().numpy()
    baseline_mae = mean_absolute_error(test_targets, baseline_pred)

    # çµ„æˆç‰¹å¾´é‡ã‚’ã‚¼ãƒ­ã«ã—ãŸå ´åˆã®äºˆæ¸¬
    zero_comp_feats = torch.zeros_like(test_comp_feats)
    with torch.no_grad():
        pred_no_comp = model(test_data, zero_comp_feats).cpu().numpy()
    mae_no_comp = mean_absolute_error(test_targets, pred_no_comp)

    # GNNåŸ‹ã‚è¾¼ã¿ã‚’ã‚¼ãƒ­ã«ã—ãŸå ´åˆã®äºˆæ¸¬ï¼ˆãƒ¢ãƒ‡ãƒ«å†…éƒ¨ã‚’å¤‰æ›´ï¼‰
    # ç°¡ç•¥ç‰ˆï¼šGNNéƒ¨åˆ†ã‚’ãƒã‚¹ã‚¯ã™ã‚‹ä»£ã‚ã‚Šã«ã€åˆ¥é€”GNNåŸ‹ã‚è¾¼ã¿ãªã—ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´
    # ã“ã“ã§ã¯Permutation Importanceã‚’ä½¿ç”¨

    # çµ„æˆç‰¹å¾´é‡ã®é‡è¦åº¦ï¼ˆMAEå¢—åŠ é‡ï¼‰
    comp_importance = mae_no_comp - baseline_mae

    # GNNåŸ‹ã‚è¾¼ã¿ã®é‡è¦åº¦ï¼ˆé¡æ¨ï¼šãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ£ãƒƒãƒ•ãƒ«ï¼‰
    n_permutations = 10
    gnn_mae_increases = []

    for _ in range(n_permutations):
        # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’ã‚·ãƒ£ãƒƒãƒ•ãƒ«ï¼ˆGNNåŸ‹ã‚è¾¼ã¿ã‚’ãƒ©ãƒ³ãƒ€ãƒ åŒ–ï¼‰
        shuffled_indices = np.random.permutation(len(test_data))
        shuffled_data = [test_data[i] for i in shuffled_indices]

        with torch.no_grad():
            pred_shuffled = model(Batch.from_data_list(shuffled_data).to(device),
                                   test_comp_feats).cpu().numpy()
        mae_shuffled = mean_absolute_error(test_targets, pred_shuffled)
        gnn_mae_increases.append(mae_shuffled - baseline_mae)

    gnn_importance = np.mean(gnn_mae_increases)

    return comp_importance, gnn_importance

# å®Ÿè¡Œ
comp_imp, gnn_imp = hybrid_feature_importance_analysis(
    hybrid_model, test_data_list, test_comp_feats, test_targets
)

# ç›¸å¯¾çš„é‡è¦åº¦ã‚’è¨ˆç®—
total_imp = comp_imp + gnn_imp
comp_ratio = comp_imp / total_imp * 100
gnn_ratio = gnn_imp / total_imp * 100

print(f"=== ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«ã®ç‰¹å¾´é‡é‡è¦åº¦ ===")
print(f"çµ„æˆç‰¹å¾´é‡ã®å¯„ä¸: {comp_ratio:.1f}%")
print(f"GNNåŸ‹ã‚è¾¼ã¿ã®å¯„ä¸: {gnn_ratio:.1f}%")

# å¯è¦–åŒ–
import matplotlib.pyplot as plt

fig, ax = plt.subplots(figsize=(8, 6))
ax.bar(['çµ„æˆç‰¹å¾´é‡', 'GNNåŸ‹ã‚è¾¼ã¿'], [comp_ratio, gnn_ratio],
       color=['#667eea', '#764ba2'])
ax.set_ylabel('ç›¸å¯¾çš„é‡è¦åº¦ (%)', fontsize=12)
ax.set_title('ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«ã®ç‰¹å¾´é‡å¯„ä¸åº¦', fontsize=14, fontweight='bold')
ax.set_ylim(0, 100)

for i, v in enumerate([comp_ratio, gnn_ratio]):
    ax.text(i, v + 2, f'{v:.1f}%', ha='center', va='bottom', fontsize=12, fontweight='bold')

plt.tight_layout()
plt.savefig('hybrid_feature_importance.png', dpi=300, bbox_inches='tight')
plt.show()

# å‡ºåŠ›ä¾‹ï¼š
# === ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«ã®ç‰¹å¾´é‡é‡è¦åº¦ ===
# çµ„æˆç‰¹å¾´é‡ã®å¯„ä¸: 32.5%
# GNNåŸ‹ã‚è¾¼ã¿ã®å¯„ä¸: 67.5%
# â†’ GNNåŸ‹ã‚è¾¼ã¿ãŒã‚ˆã‚Šé‡è¦ã ãŒã€çµ„æˆæƒ…å ±ã‚‚æœ‰æ„ã«å¯„ä¸
</code></pre>
        </div>

        <h2>å‚è€ƒæ–‡çŒ®</h2>

        <ol>
            <li>Choudhary, K., DeCost, B. (2021). Atomistic Line Graph Neural Network for improved materials property predictions. <em>npj Computational Materials</em>, 7(1), 185, pp. 1-8.</li>
            <li>Chen, C., Ye, W., Zuo, Y., Zheng, C., Ong, S. P. (2019). Graph Networks as a Universal Machine Learning Framework for Molecules and Crystals. <em>Chemistry of Materials</em>, 31(9), 3564-3572, pp. 3564-3572.</li>
            <li>Ruder, S. (2017). An Overview of Multi-Task Learning in Deep Neural Networks. <em>arXiv preprint arXiv:1706.05098</em>, pp. 1-13.</li>
            <li>Crawshaw, M. (2020). Multi-Task Learning with Deep Neural Networks: A Survey. <em>arXiv preprint arXiv:2009.09796</em>, pp. 1-23.</li>
            <li>Fung, V., Zhang, J., Juarez, E., Sumpter, B. G. (2021). Benchmarking graph neural networks for materials chemistry. <em>npj Computational Materials</em>, 7(1), 84, pp. 1-8.</li>
            <li>Goodall, R. E. A., Lee, A. A. (2020). Predicting materials properties without crystal structure: Deep representation learning from stoichiometry. <em>Nature Communications</em>, 11, 6280, pp. 1-9.</li>
            <li>VeliÄkoviÄ‡, P., Cucurull, G., Casanova, A., Romero, A., LiÃ², P., Bengio, Y. (2018). Graph Attention Networks. <em>International Conference on Learning Representations</em>, pp. 1-12.</li>
        </ol>

        <div class="nav-buttons">
            <a href="chapter-4.html" class="nav-button">â† ç¬¬4ç« ï¼šçµ„æˆãƒ™ãƒ¼ã‚¹ vs GNNå®šé‡çš„æ¯”è¼ƒ</a>
            <a href="chapter-6.html" class="nav-button">ç¬¬6ç« ï¼šPyTorch Geometricãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ â†’</a>
        </div>

    </div>
<section class="disclaimer">
<h3>å…è²¬äº‹é …</h3>
<ul>
<li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯æ•™è‚²ãƒ»ç ”ç©¶ãƒ»æƒ…å ±æä¾›ã®ã¿ã‚’ç›®çš„ã¨ã—ã¦ãŠã‚Šã€å°‚é–€çš„ãªåŠ©è¨€(æ³•å¾‹ãƒ»ä¼šè¨ˆãƒ»æŠ€è¡“çš„ä¿è¨¼ãªã©)ã‚’æä¾›ã™ã‚‹ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚</li>
<li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŠã‚ˆã³ä»˜éšã™ã‚‹Code examplesã¯ã€Œç¾çŠ¶æœ‰å§¿(AS IS)ã€ã§æä¾›ã•ã‚Œã€æ˜ç¤ºã¾ãŸã¯é»™ç¤ºã‚’å•ã‚ãšã€å•†å“æ€§ã€ç‰¹å®šç›®çš„é©åˆæ€§ã€æ¨©åˆ©éä¾µå®³ã€æ­£ç¢ºæ€§ãƒ»å®Œå…¨æ€§ã€å‹•ä½œãƒ»å®‰å…¨æ€§ç­‰ã„ã‹ãªã‚‹ä¿è¨¼ã‚‚ã—ã¾ã›ã‚“ã€‚</li>
<li>å¤–éƒ¨ãƒªãƒ³ã‚¯ã€ç¬¬ä¸‰è€…ãŒæä¾›ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ»ãƒ„ãƒ¼ãƒ«ãƒ»ãƒ©ã‚¤ãƒ–ãƒ©ãƒªç­‰ã®å†…å®¹ãƒ»å¯ç”¨æ€§ãƒ»å®‰å…¨æ€§ã«ã¤ã„ã¦ã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯ä¸€åˆ‡ã®è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚</li>
<li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®åˆ©ç”¨ãƒ»å®Ÿè¡Œãƒ»è§£é‡ˆã«ã‚ˆã‚Šç›´æ¥çš„ãƒ»é–“æ¥çš„ãƒ»ä»˜éšçš„ãƒ»ç‰¹åˆ¥ãƒ»çµæœçš„ãƒ»æ‡²ç½°çš„æå®³ãŒç”Ÿã˜ãŸå ´åˆã§ã‚‚ã€é©ç”¨æ³•ã§è¨±å®¹ã•ã‚Œã‚‹æœ€å¤§é™ã®ç¯„å›²ã§ã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚</li>
<li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å†…å®¹ã¯ã€äºˆå‘Šãªãå¤‰æ›´ãƒ»æ›´æ–°ãƒ»æä¾›åœæ­¢ã•ã‚Œã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚</li>
<li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®è‘—ä½œæ¨©ãƒ»ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯æ˜è¨˜ã•ã‚ŒãŸæ¡ä»¶(ä¾‹: CC BY 4.0)ã«å¾“ã„ã¾ã™ã€‚å½“è©²ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯é€šå¸¸ã€ç„¡ä¿è¨¼æ¡é …ã‚’å«ã¿ã¾ã™ã€‚</li>
</ul>
</section>

</body>
</html>