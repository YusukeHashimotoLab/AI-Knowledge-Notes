<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Chapter - AI Terakoya</title>

    <style>
        :root {
            --color-primary: #2c3e50;
            --color-primary-dark: #1a252f;
            --color-accent: #7b2cbf;
            --color-accent-light: #9d4edd;
            --color-text: #2d3748;
            --color-text-light: #4a5568;
            --color-bg: #ffffff;
            --color-bg-alt: #f7fafc;
            --color-border: #e2e8f0;
            --color-code-bg: #f8f9fa;
            --color-link: #3182ce;
            --color-link-hover: #2c5aa0;

            --spacing-xs: 0.5rem;
            --spacing-sm: 1rem;
            --spacing-md: 1.5rem;
            --spacing-lg: 2rem;
            --spacing-xl: 3rem;

            --font-body: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            --font-mono: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;

            --border-radius: 8px;
            --box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: var(--font-body);
            line-height: 1.7;
            color: var(--color-text);
            background-color: var(--color-bg);
            font-size: 16px;
        }

        header {
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            padding: var(--spacing-xl) var(--spacing-md);
            margin-bottom: var(--spacing-xl);
            box-shadow: var(--box-shadow);
        }

        .header-content {
            max-width: 900px;
            margin: 0 auto;
        }

        h1 {
            font-size: 2rem;
            font-weight: 700;
            margin-bottom: var(--spacing-sm);
            line-height: 1.2;
        }

        .subtitle {
            font-size: 1.1rem;
            opacity: 0.95;
            font-weight: 400;
            margin-bottom: var(--spacing-md);
        }

        .meta {
            display: flex;
            flex-wrap: wrap;
            gap: var(--spacing-md);
            font-size: 0.9rem;
            opacity: 0.9;
        }

        .meta-item {
            display: flex;
            align-items: center;
            gap: 0.3rem;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 0 var(--spacing-md) var(--spacing-xl);
        }

        h2 {
            font-size: 1.75rem;
            color: var(--color-primary);
            margin-top: var(--spacing-xl);
            margin-bottom: var(--spacing-md);
            padding-bottom: var(--spacing-xs);
            border-bottom: 3px solid var(--color-accent);
        }

        h3 {
            font-size: 1.4rem;
            color: var(--color-primary);
            margin-top: var(--spacing-lg);
            margin-bottom: var(--spacing-sm);
        }

        h4 {
            font-size: 1.1rem;
            color: var(--color-primary-dark);
            margin-top: var(--spacing-md);
            margin-bottom: var(--spacing-sm);
        }

        p {
            margin-bottom: var(--spacing-md);
            color: var(--color-text);
        }

        a {
            color: var(--color-link);
            text-decoration: none;
            transition: color 0.2s;
        }

        a:hover {
            color: var(--color-link-hover);
            text-decoration: underline;
        }

        ul, ol {
            margin-left: var(--spacing-lg);
            margin-bottom: var(--spacing-md);
        }

        li {
            margin-bottom: var(--spacing-xs);
            color: var(--color-text);
        }

        pre {
            background-color: var(--color-code-bg);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            overflow-x: auto;
            margin-bottom: var(--spacing-md);
            font-family: var(--font-mono);
            font-size: 0.9rem;
            line-height: 1.5;
        }

        code {
            font-family: var(--font-mono);
            font-size: 0.9em;
            background-color: var(--color-code-bg);
            padding: 0.2em 0.4em;
            border-radius: 3px;
        }

        pre code {
            background-color: transparent;
            padding: 0;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: var(--spacing-md);
            font-size: 0.95rem;
        }

        th, td {
            border: 1px solid var(--color-border);
            padding: var(--spacing-sm);
            text-align: left;
        }

        th {
            background-color: var(--color-bg-alt);
            font-weight: 600;
            color: var(--color-primary);
        }

        blockquote {
            border-left: 4px solid var(--color-accent);
            padding-left: var(--spacing-md);
            margin: var(--spacing-md) 0;
            color: var(--color-text-light);
            font-style: italic;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        .mermaid {
            text-align: center;
            margin: var(--spacing-lg) 0;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        details {
            background-color: var(--color-bg-alt);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            margin-bottom: var(--spacing-md);
        }

        summary {
            cursor: pointer;
            font-weight: 600;
            color: var(--color-primary);
            user-select: none;
            padding: var(--spacing-xs);
            margin: calc(-1 * var(--spacing-md));
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        summary:hover {
            background-color: rgba(123, 44, 191, 0.1);
        }

        details[open] summary {
            margin-bottom: var(--spacing-md);
            border-bottom: 1px solid var(--color-border);
        }

        .learning-objectives {
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
            padding: var(--spacing-lg);
            border-radius: var(--border-radius);
            border-left: 4px solid var(--color-accent);
            margin-bottom: var(--spacing-xl);
        }

        .learning-objectives h2 {
            margin-top: 0;
            border-bottom: none;
        }

        .navigation {
            display: flex;
            justify-content: space-between;
            gap: var(--spacing-md);
            margin: var(--spacing-xl) 0;
            padding-top: var(--spacing-lg);
            border-top: 2px solid var(--color-border);
        }

        .nav-button {
            flex: 1;
            padding: var(--spacing-md);
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            border-radius: var(--border-radius);
            text-align: center;
            font-weight: 600;
            transition: transform 0.2s, box-shadow 0.2s;
            box-shadow: var(--box-shadow);
        }

        .nav-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
            text-decoration: none;
        }

        footer {
            margin-top: var(--spacing-xl);
            padding: var(--spacing-lg) var(--spacing-md);
            background-color: var(--color-bg-alt);
            border-top: 1px solid var(--color-border);
            text-align: center;
            font-size: 0.9rem;
            color: var(--color-text-light);
        }

        @media (max-width: 768px) {
            h1 {
                font-size: 1.5rem;
            }

            h2 {
                font-size: 1.4rem;
            }

            h3 {
                font-size: 1.2rem;
            }

            .meta {
                font-size: 0.85rem;
            }

            .navigation {
                flex-direction: column;
            }

            table {
                font-size: 0.85rem;
            }

            th, td {
                padding: var(--spacing-xs);
            }
        }
    </style>

    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
        mermaid.initialize({ startOnLoad: true, theme: 'default' });
    </script>

    <!-- MathJax for LaTeX equation rendering -->
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\(', '\)']],
                displayMath: [['$$', '$$'], ['\[', '\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
                ignoreHtmlClass: 'mermaid'
            }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" async></script>
</head>
<body>
    <header>
        <div class="header-content">
            <h1>Chapter</h1>
            <p class="subtitle"></p>
            <div class="meta">
                <span class="meta-item">üìñ Ë™≠‰∫ÜÊôÇÈñì: 20-25ÂàÜ</span>
                <span class="meta-item">üìä Èõ£ÊòìÂ∫¶: ÂàùÁ¥ö</span>
                <span class="meta-item">üíª „Ç≥„Éº„Éâ‰æã: 0ÂÄã</span>
                <span class="meta-item">üìù ÊºîÁøíÂïèÈ°å: 0Âïè</span>
            </div>
        </div>
    </header>

    <main class="container">
<h1>Á¨¨3Á´†ÔºöGNN„Å´„Çà„ÇãÊùêÊñôË°®ÁèæÂ≠¶Áøí</h1>
<h2>Ê¶ÇË¶Å</h2>
<p>Graph Neural NetworksÔºàGNNÔºâ„ÅØ„ÄÅÁµêÊô∂ÊßãÈÄ†„ÅÆ„Çà„ÅÜ„Å™ÂéüÂ≠êÈñì„ÅÆ„Å§„Å™„Åå„Çä„ÇíÊåÅ„Å§„Éá„Éº„Çø„ÇíËá™ÁÑ∂„Å´Êâ±„Åà„ÇãÂº∑Âäõ„Å™Ê©üÊ¢∞Â≠¶Áøí„É¢„Éá„É´„Åß„Åô„ÄÇÊú¨Á´†„Åß„ÅØ„ÄÅÊùêÊñô„ÅÆÁµêÊô∂ÊßãÈÄ†„Åã„ÇâÈ´òÊ¨°ÂÖÉ„ÅÆÁâπÂæ¥Ë°®ÁèæÔºàembeddingÔºâ„ÇíÂ≠¶Áøí„Åó„ÄÅ„Åù„Çå„ÇíÊ¨°ÂÖÉÂâäÊ∏õ„Å®ÁµÑ„ÅøÂêà„Çè„Åõ„Å¶ÊùêÊñôÁ©∫Èñì„Çí„Éû„ÉÉ„Éî„É≥„Ç∞„Åô„ÇãÊñπÊ≥ï„ÇíÂ≠¶„Å≥„Åæ„Åô„ÄÇ</p>
<h3>Â≠¶ÁøíÁõÆÊ®ô</h3>
<ul>
<li>ÊùêÊñô„Çí„Ç∞„É©„Éï„Å®„Åó„Å¶Ë°®Áèæ„Åô„ÇãÊñπÊ≥ï„ÇíÁêÜËß£„Åô„Çã</li>
<li>PyTorch Geometric„ÇíÁî®„ÅÑ„ÅüGNN„É¢„Éá„É´„ÅÆÂÆüË£Ö„Åå„Åß„Åç„Çã</li>
<li>CGCNN„ÄÅMEGNet„ÄÅSchNet„ÅÆÁâπÂæ¥„Å®ÂÆüË£Ö„ÇíÁêÜËß£„Åô„Çã</li>
<li>GNN„Åã„ÇâÂæó„Çâ„Çå„Åüembedding„ÇíÂèØË¶ñÂåñ„Åß„Åç„Çã</li>
</ul>
<h2>3.1 ÊùêÊñô„ÅÆ„Ç∞„É©„ÉïË°®Áèæ</h2>
<h3>3.1.1 ÁµêÊô∂ÊßãÈÄ†„Å®„Ç∞„É©„Éï„ÅÆÂØæÂøú</h3>
<p>ÁµêÊô∂ÊßãÈÄ†„ÅØËá™ÁÑ∂„Å´„Ç∞„É©„Éï„Å®„Åó„Å¶Ë°®Áèæ„Åß„Åç„Åæ„ÅôÔºö</p>
<ul>
<li><strong>„Éé„Éº„ÉâÔºàÈ†ÇÁÇπÔºâ</strong>: ÂéüÂ≠ê</li>
<li><strong>„Éé„Éº„ÉâÁâπÂæ¥</strong>: ÂéüÂ≠êÁï™Âè∑„ÄÅÈõªÊ∞óÈô∞ÊÄßÂ∫¶„ÄÅ„Ç§„Ç™„É≥ÂçäÂæÑ„Å™„Å©</li>
<li><strong>„Ç®„ÉÉ„Ç∏ÔºàËæ∫Ôºâ</strong>: ÂéüÂ≠êÈñì„ÅÆÁµêÂêàÔºà‰∏ÄÂÆöË∑ùÈõ¢ÂÜÖ„ÅÆÈö£Êé•Èñ¢‰øÇÔºâ</li>
<li><strong>„Ç®„ÉÉ„Ç∏ÁâπÂæ¥</strong>: ÂéüÂ≠êÈñìË∑ùÈõ¢„ÄÅÁµêÂêàËßíÂ∫¶„Å™„Å©</li>
<li><strong>„Ç∞„É≠„Éº„Éê„É´ÁâπÂæ¥</strong>: „Çª„É´‰ΩìÁ©ç„ÄÅÂØÜÂ∫¶„Å™„Å©</li>
</ul>
<h3>„Ç≥„Éº„Éâ‰æã1: PyTorch Geometric„ÅÆ„Ç§„É≥„Çπ„Éà„Éº„É´„Å®Âü∫Êú¨Ë®≠ÂÆö</h3>
<pre><code class="language-python"># PyTorch Geometric„ÅÆ„Ç§„É≥„Çπ„Éà„Éº„É´ÔºàÂàùÂõû„ÅÆ„ÅøÔºâ
# !pip install torch torchvision torchaudio
# !pip install torch-geometric
# !pip install torch-scatter torch-sparse torch-cluster torch-spline-conv -f https://data.pyg.org/whl/torch-2.0.0+cpu.html

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch_geometric.data import Data, DataLoader
from torch_geometric.nn import MessagePassing, global_mean_pool, global_add_pool
import numpy as np
import matplotlib.pyplot as plt

# „Éá„Éê„Ç§„ÇπË®≠ÂÆö
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f&quot;Using device: {device}&quot;)

# PyTorch Geometric„Éê„Éº„Ç∏„Éß„É≥Á¢∫Ë™ç
import torch_geometric
print(f&quot;PyTorch Geometric version: {torch_geometric.__version__}&quot;)
print(f&quot;PyTorch version: {torch.__version__}&quot;)
</code></pre>
<p><strong>Âá∫Âäõ‰æã</strong>:</p>
<pre><code>Using device: cpu
PyTorch Geometric version: 2.3.1
PyTorch version: 2.0.1
</code></pre>
<h3>„Ç≥„Éº„Éâ‰æã2: ÁµêÊô∂ÊßãÈÄ†„Åã„Çâ„Ç∞„É©„Éï„Éá„Éº„Çø„Å∏„ÅÆÂ§âÊèõ</h3>
<pre><code class="language-python">from pymatgen.core import Structure, Lattice
import numpy as np
import torch
from torch_geometric.data import Data

def structure_to_graph(structure, cutoff=5.0):
    &quot;&quot;&quot;
    pymatgen Structure„ÇíPyTorch Geometric Data„Ç™„Éñ„Ç∏„Çß„ÇØ„Éà„Å´Â§âÊèõ

    Parameters:
    -----------
    structure : pymatgen.Structure
        ÁµêÊô∂ÊßãÈÄ†
    cutoff : float
        „Ç®„ÉÉ„Ç∏„ÇíÁîüÊàê„Åô„ÇãÂéüÂ≠êÈñìË∑ùÈõ¢„ÅÆÈñæÂÄ§ÔºàAngstromÔºâ

    Returns:
    --------
    data : torch_geometric.data.Data
        „Ç∞„É©„Éï„Éá„Éº„Çø
    &quot;&quot;&quot;
    # „Éé„Éº„ÉâÁâπÂæ¥: ÂéüÂ≠êÁï™Âè∑Ôºà„ÉØ„É≥„Éõ„ÉÉ„Éà„Ç®„É≥„Ç≥„Éº„Éá„Ç£„É≥„Ç∞„ÅØÂæå„ÅßÂÆüË£ÖÔºâ
    atomic_numbers = torch.tensor([site.specie.Z for site in structure],
                                  dtype=torch.float).view(-1, 1)

    # „Ç®„ÉÉ„Ç∏„ÅÆÊßãÁØâ
    all_neighbors = structure.get_all_neighbors(cutoff)
    edge_index = []
    edge_attr = []

    for i, neighbors in enumerate(all_neighbors):
        for neighbor in neighbors:
            j = neighbor.index
            distance = neighbor.nn_distance

            edge_index.append([i, j])
            edge_attr.append(distance)

    # „Ç®„ÉÉ„Ç∏„Åå„Å™„ÅÑÂ†¥Âêà„ÅÆÂá¶ÁêÜ
    if len(edge_index) == 0:
        edge_index = torch.zeros((2, 0), dtype=torch.long)
        edge_attr = torch.zeros((0, 1), dtype=torch.float)
    else:
        edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()
        edge_attr = torch.tensor(edge_attr, dtype=torch.float).view(-1, 1)

    # Data„Ç™„Éñ„Ç∏„Çß„ÇØ„Éà„ÅÆ‰ΩúÊàê
    data = Data(x=atomic_numbers,
                edge_index=edge_index,
                edge_attr=edge_attr)

    return data


# „Çµ„É≥„Éó„É´ÁµêÊô∂ÊßãÈÄ†„ÅÆ‰ΩúÊàêÔºà„Ç∑„É≥„Éó„É´„Å™CsClÊßãÈÄ†Ôºâ
lattice = Lattice.cubic(4.0)
structure = Structure(lattice, [&quot;Cs&quot;, &quot;Cl&quot;], [[0, 0, 0], [0.5, 0.5, 0.5]])

# „Ç∞„É©„Éï„Å∏„ÅÆÂ§âÊèõ
graph_data = structure_to_graph(structure, cutoff=5.0)

print(&quot;„Ç∞„É©„Éï„Éá„Éº„Çø„ÅÆÊÉÖÂ†±:&quot;)
print(f&quot;„Éé„Éº„ÉâÊï∞: {graph_data.num_nodes}&quot;)
print(f&quot;„Ç®„ÉÉ„Ç∏Êï∞: {graph_data.num_edges}&quot;)
print(f&quot;„Éé„Éº„ÉâÁâπÂæ¥„ÅÆÂΩ¢Áä∂: {graph_data.x.shape}&quot;)
print(f&quot;„Ç®„ÉÉ„Ç∏„Ç§„É≥„Éá„ÉÉ„ÇØ„Çπ„ÅÆÂΩ¢Áä∂: {graph_data.edge_index.shape}&quot;)
print(f&quot;„Ç®„ÉÉ„Ç∏ÁâπÂæ¥„ÅÆÂΩ¢Áä∂: {graph_data.edge_attr.shape}&quot;)
</code></pre>
<p><strong>Âá∫Âäõ‰æã</strong>:</p>
<pre><code>„Ç∞„É©„Éï„Éá„Éº„Çø„ÅÆÊÉÖÂ†±:
„Éé„Éº„ÉâÊï∞: 2
„Ç®„ÉÉ„Ç∏Êï∞: 16
„Éé„Éº„ÉâÁâπÂæ¥„ÅÆÂΩ¢Áä∂: torch.Size([2, 1])
„Ç®„ÉÉ„Ç∏„Ç§„É≥„Éá„ÉÉ„ÇØ„Çπ„ÅÆÂΩ¢Áä∂: torch.Size([2, 16])
„Ç®„ÉÉ„Ç∏ÁâπÂæ¥„ÅÆÂΩ¢Áä∂: torch.Size([16, 1])
</code></pre>
<h3>„Ç≥„Éº„Éâ‰æã3: ÂéüÂ≠êÁâπÂæ¥„ÅÆ„Ç®„É≥„Ç≥„Éº„Éá„Ç£„É≥„Ç∞</h3>
<pre><code class="language-python">import torch
import torch.nn as nn

class AtomFeaturizer:
    &quot;&quot;&quot;ÂéüÂ≠ê„ÅÆÁâπÂæ¥„Çí„Éô„ÇØ„Éà„É´Âåñ„Åô„Çã„ÇØ„É©„Çπ&quot;&quot;&quot;

    def __init__(self, max_z=100):
        &quot;&quot;&quot;
        Parameters:
        -----------
        max_z : int
            Êâ±„ÅÜÊúÄÂ§ß„ÅÆÂéüÂ≠êÁï™Âè∑
        &quot;&quot;&quot;
        self.max_z = max_z

        # ÂéüÂ≠êÁâπÊÄß„ÅÆ„É™„Çπ„ÉàÔºàÁ∞°ÊòìÁâàÔºâ
        # ÂÆüÈöõ„Å´„ÅØ mendeleev „Å™„Å©„ÅÆ„É©„Ç§„Éñ„É©„É™„Çí‰ΩøÁî®„Åô„Çã„Å®ËâØ„ÅÑ
        self.electronegativity = self._load_property('electronegativity')
        self.covalent_radius = self._load_property('covalent_radius')
        self.valence_electrons = self._load_property('valence_electrons')

    def _load_property(self, property_name):
        &quot;&quot;&quot;
        ÂéüÂ≠êÁâπÊÄß„ÅÆ„ÉÄ„Éü„Éº„Éá„Éº„ÇøÁîüÊàê
        ÂÆüÈöõ„ÅÆ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„Åß„ÅØmendeleev„É©„Ç§„Éñ„É©„É™„Å™„Å©„Åã„ÇâÂèñÂæó
        &quot;&quot;&quot;
        # „ÉÄ„Éü„Éº„Éá„Éº„ÇøÔºàÂÆüÈöõ„Å´„ÅØÊ≠£Á¢∫„Å™ÂÄ§„Çí‰ΩøÁî®Ôºâ
        np.random.seed(42)
        if property_name == 'electronegativity':
            return np.random.uniform(0.7, 4.0, self.max_z)
        elif property_name == 'covalent_radius':
            return np.random.uniform(0.3, 2.5, self.max_z)
        elif property_name == 'valence_electrons':
            return np.random.randint(1, 8, self.max_z).astype(float)

    def featurize(self, atomic_number):
        &quot;&quot;&quot;
        ÂéüÂ≠êÁï™Âè∑„Åã„ÇâÁâπÂæ¥„Éô„ÇØ„Éà„É´„ÇíÁîüÊàê

        Parameters:
        -----------
        atomic_number : int or array-like
            ÂéüÂ≠êÁï™Âè∑

        Returns:
        --------
        features : torch.Tensor
            ÁâπÂæ¥„Éô„ÇØ„Éà„É´
        &quot;&quot;&quot;
        if isinstance(atomic_number, (int, np.integer)):
            atomic_number = [atomic_number]

        features = []
        for z in atomic_number:
            z_idx = int(z) - 1  # 0-indexed

            feat = [
                z / self.max_z,  # Ê≠£Ë¶èÂåñ„Åï„Çå„ÅüÂéüÂ≠êÁï™Âè∑
                self.electronegativity[z_idx],
                self.covalent_radius[z_idx],
                self.valence_electrons[z_idx]
            ]
            features.append(feat)

        return torch.tensor(features, dtype=torch.float)


# ‰ΩøÁî®‰æã
featurizer = AtomFeaturizer(max_z=100)

# Cs (Z=55) „Å® Cl (Z=17) „ÅÆÁâπÂæ¥Âåñ
cs_features = featurizer.featurize(55)
cl_features = featurizer.featurize(17)

print(&quot;Cs „ÅÆÁâπÂæ¥„Éô„ÇØ„Éà„É´:&quot;)
print(cs_features)
print(&quot;\nCl „ÅÆÁâπÂæ¥„Éô„ÇØ„Éà„É´:&quot;)
print(cl_features)

# ÊßãÈÄ†ÂÖ®‰Ωì„ÅÆÁâπÂæ¥Âåñ
atomic_numbers = [site.specie.Z for site in structure]
all_features = featurizer.featurize(atomic_numbers)
print(f&quot;\nÊßãÈÄ†ÂÖ®‰Ωì„ÅÆÁâπÂæ¥Ë°åÂàó„ÅÆÂΩ¢Áä∂: {all_features.shape}&quot;)
</code></pre>
<h3>„Ç≥„Éº„Éâ‰æã4: „ÉÄ„Éü„ÉºÊùêÊñô„Éá„Éº„Çø„Çª„ÉÉ„Éà„ÅÆÁîüÊàê</h3>
<pre><code class="language-python">import torch
from torch_geometric.data import Data, InMemoryDataset
import numpy as np

class DummyMaterialsDataset(InMemoryDataset):
    &quot;&quot;&quot;
    Â≠¶ÁøíÁî®„ÅÆ„ÉÄ„Éü„ÉºÊùêÊñô„Éá„Éº„Çø„Çª„ÉÉ„Éà
    ÂÆüÈöõ„ÅÆ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„Åß„ÅØMaterials Project API„Å™„Å©„Åã„ÇâÂèñÂæó
    &quot;&quot;&quot;

    def __init__(self, num_materials=1000, num_atom_types=20):
        self.num_materials = num_materials
        self.num_atom_types = num_atom_types
        super().__init__(root=None)
        self.data, self.slices = self._generate_data()

    def _generate_data(self):
        &quot;&quot;&quot;„ÉÄ„Éü„Éº„ÅÆ„Ç∞„É©„Éï„Éá„Éº„Çø„ÇíÁîüÊàê&quot;&quot;&quot;
        data_list = []

        np.random.seed(42)
        torch.manual_seed(42)

        for i in range(self.num_materials):
            # „Éé„Éº„ÉâÊï∞„Çí„É©„É≥„ÉÄ„É†„Å´Ë®≠ÂÆöÔºà5-30ÂéüÂ≠êÔºâ
            num_nodes = np.random.randint(5, 30)

            # „Éé„Éº„ÉâÁâπÂæ¥ÔºàÂéüÂ≠ê„Çø„Ç§„Éó„ÅÆ„ÉØ„É≥„Éõ„ÉÉ„Éà + ÈÄ£Á∂öÂÄ§ÁâπÂæ¥Ôºâ
            atom_types = torch.randint(0, self.num_atom_types, (num_nodes,))
            atom_features = torch.randn(num_nodes, 4)  # 4Ê¨°ÂÖÉ„ÅÆÁâπÂæ¥

            # ÂÆåÂÖ®„Å™„Éé„Éº„ÉâÁâπÂæ¥
            x = torch.cat([
                F.one_hot(atom_types, num_classes=self.num_atom_types).float(),
                atom_features
            ], dim=1)

            # „Ç®„ÉÉ„Ç∏„ÅÆÁîüÊàêÔºàÂêÑ„Éé„Éº„Éâ„Åã„ÇâÂπ≥Âùá5„Å§„ÅÆ„Ç®„ÉÉ„Ç∏Ôºâ
            num_edges = num_nodes * 5
            edge_index = torch.randint(0, num_nodes, (2, num_edges))

            # „Ç®„ÉÉ„Ç∏ÁâπÂæ¥ÔºàË∑ùÈõ¢„Å™„Å©Ôºâ
            edge_attr = torch.rand(num_edges, 1) * 5.0  # 0-5 Angstrom

            # „Çø„Éº„Ç≤„ÉÉ„ÉàÁâπÊÄßÔºà„Éê„É≥„Éâ„ÇÆ„É£„ÉÉ„Éó„ÇíÊÉ≥ÂÆöÔºâ
            y = torch.tensor([np.random.exponential(2.0)], dtype=torch.float)

            data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)
            data_list.append(data)

        return self.collate(data_list)

# „Éá„Éº„Çø„Çª„ÉÉ„Éà„ÅÆ‰ΩúÊàê
dataset = DummyMaterialsDataset(num_materials=1000, num_atom_types=20)

print(f&quot;„Éá„Éº„Çø„Çª„ÉÉ„Éà„Çµ„Ç§„Ç∫: {len(dataset)}&quot;)
print(f&quot;„Çµ„É≥„Éó„É´„Éá„Éº„Çø:&quot;)
print(dataset[0])
print(f&quot;\n„Éé„Éº„ÉâÁâπÂæ¥Ê¨°ÂÖÉ: {dataset[0].x.shape[1]}&quot;)
print(f&quot;„Çø„Éº„Ç≤„ÉÉ„Éà: {dataset[0].y.item():.3f}&quot;)
</code></pre>
<p><strong>Âá∫Âäõ‰æã</strong>:</p>
<pre><code>„Éá„Éº„Çø„Çª„ÉÉ„Éà„Çµ„Ç§„Ç∫: 1000
„Çµ„É≥„Éó„É´„Éá„Éº„Çø:
Data(x=[18, 24], edge_index=[2, 90], edge_attr=[90, 1], y=[1])

„Éé„Éº„ÉâÁâπÂæ¥Ê¨°ÂÖÉ: 24
„Çø„Éº„Ç≤„ÉÉ„Éà: 2.134
</code></pre>
<h2>3.2 Crystal Graph Convolutional Neural Network (CGCNN)</h2>
<p>CGCNN„ÅØ„ÄÅÁµêÊô∂ÊßãÈÄ†„ÅÆÁâπÊÄß‰∫àÊ∏¨„Å´ÁâπÂåñ„Åó„ÅüGNN„É¢„Éá„É´„Åß„Åô„ÄÇ</p>
<h3>„Ç≥„Éº„Éâ‰æã5: CGCNN„ÅÆÁï≥„ÅøËæº„ÅøÂ±§</h3>
<pre><code class="language-python">import torch
import torch.nn as nn
from torch_geometric.nn import MessagePassing

class CGConv(MessagePassing):
    &quot;&quot;&quot;
    CGCNNÁï≥„ÅøËæº„ÅøÂ±§
    &quot;&quot;&quot;

    def __init__(self, node_dim, edge_dim, hidden_dim=128):
        super().__init__(aggr='add')  # aggregation: sum

        self.node_dim = node_dim
        self.edge_dim = edge_dim
        self.hidden_dim = hidden_dim

        # „Éé„Éº„ÉâÊõ¥Êñ∞Áî®„ÅÆ„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ
        self.node_fc = nn.Sequential(
            nn.Linear(node_dim, hidden_dim),
            nn.Softplus(),
            nn.Linear(hidden_dim, hidden_dim)
        )

        # „Ç®„ÉÉ„Ç∏ÁâπÂæ¥„Å®„Éé„Éº„ÉâÁâπÂæ¥„ÇíÁµÑ„ÅøÂêà„Çè„Åõ„Çã„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ
        self.edge_fc = nn.Sequential(
            nn.Linear(node_dim + edge_dim, hidden_dim),
            nn.Softplus(),
            nn.Linear(hidden_dim, hidden_dim)
        )

        # „Ç≤„Éº„ÉàÊ©üÊßã
        self.gate = nn.Sequential(
            nn.Linear(node_dim + edge_dim, hidden_dim),
            nn.Sigmoid()
        )

    def forward(self, x, edge_index, edge_attr):
        &quot;&quot;&quot;
        È†Ü‰ºùÊí≠

        Parameters:
        -----------
        x : Tensor [num_nodes, node_dim]
            „Éé„Éº„ÉâÁâπÂæ¥
        edge_index : Tensor [2, num_edges]
            „Ç®„ÉÉ„Ç∏„Ç§„É≥„Éá„ÉÉ„ÇØ„Çπ
        edge_attr : Tensor [num_edges, edge_dim]
            „Ç®„ÉÉ„Ç∏ÁâπÂæ¥

        Returns:
        --------
        out : Tensor [num_nodes, hidden_dim]
            Êõ¥Êñ∞„Åï„Çå„Åü„Éé„Éº„ÉâÁâπÂæ¥
        &quot;&quot;&quot;
        # „É°„ÉÉ„Çª„Éº„Ç∏„Éë„ÉÉ„Ç∑„É≥„Ç∞
        out = self.propagate(edge_index, x=x, edge_attr=edge_attr)

        # Ëá™Â∑±„É´„Éº„ÉóÔºàÊÆãÂ∑ÆÊé•Á∂öÁöÑ„Å™Âá¶ÁêÜÔºâ
        out = out + self.node_fc(x)

        return out

    def message(self, x_j, edge_attr):
        &quot;&quot;&quot;
        „É°„ÉÉ„Çª„Éº„Ç∏Èñ¢Êï∞
        „Ç®„ÉÉ„Ç∏„ÇíÈÄö„Åò„Å¶Èö£Êé•„Éé„Éº„Éâ„Åã„ÇâÈÄÅ„Çâ„Çå„ÇãÊÉÖÂ†±„ÇíË®àÁÆó

        Parameters:
        -----------
        x_j : Tensor [num_edges, node_dim]
            ÈÄÅ‰ø°ÂÖÉ„Éé„Éº„Éâ„ÅÆÁâπÂæ¥
        edge_attr : Tensor [num_edges, edge_dim]
            „Ç®„ÉÉ„Ç∏ÁâπÂæ¥

        Returns:
        --------
        message : Tensor [num_edges, hidden_dim]
            „É°„ÉÉ„Çª„Éº„Ç∏
        &quot;&quot;&quot;
        # „Ç®„ÉÉ„Ç∏„Å®„Éé„Éº„ÉâÁâπÂæ¥„ÇíÈÄ£Áµê
        z = torch.cat([x_j, edge_attr], dim=1)

        # „Ç≤„Éº„ÉÜ„Ç£„É≥„Ç∞
        gate_values = self.gate(z)
        message_values = self.edge_fc(z)

        return gate_values * message_values


# „ÉÜ„Çπ„Éà
node_dim = 24
edge_dim = 1
hidden_dim = 64

conv_layer = CGConv(node_dim, edge_dim, hidden_dim)

# „ÉÄ„Éü„Éº„Éá„Éº„Çø
x = torch.randn(10, node_dim)
edge_index = torch.randint(0, 10, (2, 30))
edge_attr = torch.randn(30, edge_dim)

# È†Ü‰ºùÊí≠
out = conv_layer(x, edge_index, edge_attr)

print(f&quot;ÂÖ•Âäõ„Éé„Éº„ÉâÁâπÂæ¥„ÅÆÂΩ¢Áä∂: {x.shape}&quot;)
print(f&quot;Âá∫Âäõ„Éé„Éº„ÉâÁâπÂæ¥„ÅÆÂΩ¢Áä∂: {out.shape}&quot;)
</code></pre>
<p><strong>Âá∫Âäõ‰æã</strong>:</p>
<pre><code>ÂÖ•Âäõ„Éé„Éº„ÉâÁâπÂæ¥„ÅÆÂΩ¢Áä∂: torch.Size([10, 24])
Âá∫Âäõ„Éé„Éº„ÉâÁâπÂæ¥„ÅÆÂΩ¢Áä∂: torch.Size([10, 64])
</code></pre>
<h3>„Ç≥„Éº„Éâ‰æã6: ÂÆåÂÖ®„Å™CGCNN„É¢„Éá„É´</h3>
<pre><code class="language-python">import torch
import torch.nn as nn
import torch.nn.functional as F
from torch_geometric.nn import global_mean_pool

class CGCNN(nn.Module):
    &quot;&quot;&quot;
    Crystal Graph Convolutional Neural Network
    &quot;&quot;&quot;

    def __init__(self, node_dim, edge_dim, hidden_dim=64, num_conv=3, num_fc=2):
        super().__init__()

        self.node_dim = node_dim
        self.edge_dim = edge_dim
        self.hidden_dim = hidden_dim
        self.num_conv = num_conv

        # ÂÖ•ÂäõÂüã„ÇÅËæº„ÅøÂ±§
        self.embedding = nn.Linear(node_dim, hidden_dim)

        # CGConvÂ±§„ÅÆ„É™„Çπ„Éà
        self.conv_layers = nn.ModuleList([
            CGConv(hidden_dim, edge_dim, hidden_dim)
            for _ in range(num_conv)
        ])

        # Batch Normalization
        self.bn_layers = nn.ModuleList([
            nn.BatchNorm1d(hidden_dim)
            for _ in range(num_conv)
        ])

        # ÂÖ®ÁµêÂêàÂ±§ÔºàÁâπÊÄß‰∫àÊ∏¨Áî®Ôºâ
        fc_layers = []
        for i in range(num_fc):
            if i == 0:
                fc_layers.append(nn.Linear(hidden_dim, hidden_dim // 2))
            else:
                fc_layers.append(nn.Linear(hidden_dim // 2, hidden_dim // 2))
            fc_layers.append(nn.ReLU())
            fc_layers.append(nn.Dropout(0.2))

        fc_layers.append(nn.Linear(hidden_dim // 2, 1))  # Âá∫ÂäõÊ¨°ÂÖÉ=1ÔºàÂõûÂ∏∞„Çø„Çπ„ÇØÔºâ

        self.fc = nn.Sequential(*fc_layers)

    def forward(self, data):
        &quot;&quot;&quot;
        È†Ü‰ºùÊí≠

        Parameters:
        -----------
        data : torch_geometric.data.Data or Batch
            „Ç∞„É©„Éï„Éá„Éº„Çø

        Returns:
        --------
        out : Tensor [batch_size, 1]
            ‰∫àÊ∏¨ÂÄ§
        embedding : Tensor [batch_size, hidden_dim]
            „Ç∞„É©„ÉïÂüã„ÇÅËæº„ÅøÔºàÂèØË¶ñÂåñÁî®Ôºâ
        &quot;&quot;&quot;
        x, edge_index, edge_attr, batch = data.x, data.edge_index, data.edge_attr, data.batch

        # ÂÖ•ÂäõÂüã„ÇÅËæº„Åø
        x = self.embedding(x)

        # CGConvÂ±§„ÅÆÈÅ©Áî®
        for i, (conv, bn) in enumerate(zip(self.conv_layers, self.bn_layers)):
            x = conv(x, edge_index, edge_attr)
            x = bn(x)
            x = F.softplus(x)

        # „Ç∞„É©„Éï„É¨„Éô„É´„ÅÆÂüã„ÇÅËæº„ÅøÔºàÂπ≥Âùá„Éó„Éº„É™„É≥„Ç∞Ôºâ
        graph_embedding = global_mean_pool(x, batch)

        # ÁâπÊÄß‰∫àÊ∏¨
        out = self.fc(graph_embedding)

        return out, graph_embedding


# „É¢„Éá„É´„ÅÆ„Ç§„É≥„Çπ„Çø„É≥„ÇπÂåñ
model = CGCNN(node_dim=24, edge_dim=1, hidden_dim=64, num_conv=3, num_fc=2)

print(f&quot;„É¢„Éá„É´„ÅÆÁ∑è„Éë„É©„É°„Éº„ÇøÊï∞: {sum(p.numel() for p in model.parameters()):,}&quot;)

# „ÉÜ„Çπ„Éà
from torch_geometric.loader import DataLoader

dataloader = DataLoader(dataset, batch_size=32, shuffle=False)
batch = next(iter(dataloader))

predictions, embeddings = model(batch)

print(f&quot;\n‰∫àÊ∏¨ÂÄ§„ÅÆÂΩ¢Áä∂: {predictions.shape}&quot;)
print(f&quot;Âüã„ÇÅËæº„Åø„ÅÆÂΩ¢Áä∂: {embeddings.shape}&quot;)
</code></pre>
<p><strong>Âá∫Âäõ‰æã</strong>:</p>
<pre><code>„É¢„Éá„É´„ÅÆÁ∑è„Éë„É©„É°„Éº„ÇøÊï∞: 23,713

‰∫àÊ∏¨ÂÄ§„ÅÆÂΩ¢Áä∂: torch.Size([32, 1])
Âüã„ÇÅËæº„Åø„ÅÆÂΩ¢Áä∂: torch.Size([32, 64])
</code></pre>
<h3>„Ç≥„Éº„Éâ‰æã7: CGCNN„ÅÆÂ≠¶Áøí„É´„Éº„Éó</h3>
<pre><code class="language-python">import torch
import torch.optim as optim
from torch_geometric.loader import DataLoader
from sklearn.model_selection import train_test_split
import numpy as np

# „Éá„Éº„Çø„Çª„ÉÉ„Éà„ÅÆÂàÜÂâ≤
train_idx, test_idx = train_test_split(
    range(len(dataset)), test_size=0.2, random_state=42
)

train_dataset = dataset[train_idx]
test_dataset = dataset[test_idx]

# DataLoader„ÅÆ‰ΩúÊàê
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

# „É¢„Éá„É´„ÄÅÊêçÂ§±Èñ¢Êï∞„ÄÅ„Ç™„Éó„ÉÜ„Ç£„Éû„Ç§„Ç∂
model = CGCNN(node_dim=24, edge_dim=1, hidden_dim=64, num_conv=3)
model = model.to(device)

criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# Â≠¶Áøí„É´„Éº„Éó
num_epochs = 50
train_losses = []
test_losses = []

print(&quot;Â≠¶ÁøíÈñãÂßã...&quot;)
for epoch in range(num_epochs):
    # Training
    model.train()
    train_loss = 0.0

    for batch in train_loader:
        batch = batch.to(device)

        optimizer.zero_grad()
        predictions, _ = model(batch)
        loss = criterion(predictions, batch.y)

        loss.backward()
        optimizer.step()

        train_loss += loss.item() * batch.num_graphs

    train_loss /= len(train_dataset)
    train_losses.append(train_loss)

    # Validation
    model.eval()
    test_loss = 0.0

    with torch.no_grad():
        for batch in test_loader:
            batch = batch.to(device)

            predictions, _ = model(batch)
            loss = criterion(predictions, batch.y)

            test_loss += loss.item() * batch.num_graphs

    test_loss /= len(test_dataset)
    test_losses.append(test_loss)

    if (epoch + 1) % 10 == 0:
        print(f&quot;Epoch [{epoch+1}/{num_epochs}] - &quot;
              f&quot;Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}&quot;)

print(&quot;Â≠¶ÁøíÂÆå‰∫ÜÔºÅ&quot;)

# Â≠¶ÁøíÊõ≤Á∑ö„ÅÆ„Éó„É≠„ÉÉ„Éà
import matplotlib.pyplot as plt

plt.figure(figsize=(10, 6))
plt.plot(train_losses, label='Train Loss', linewidth=2)
plt.plot(test_losses, label='Test Loss', linewidth=2)
plt.xlabel('Epoch', fontsize=14, fontweight='bold')
plt.ylabel('MSE Loss', fontsize=14, fontweight='bold')
plt.title('CGCNN Training Curve', fontsize=16, fontweight='bold')
plt.legend(fontsize=12)
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.savefig('cgcnn_training_curve.png', dpi=300)
print(&quot;Â≠¶ÁøíÊõ≤Á∑ö„Çí cgcnn_training_curve.png „Å´‰øùÂ≠ò„Åó„Åæ„Åó„Åü&quot;)
plt.show()
</code></pre>
<p><strong>Âá∫Âäõ‰æã</strong>:</p>
<pre><code>Â≠¶ÁøíÈñãÂßã...
Epoch [10/50] - Train Loss: 2.1234, Test Loss: 2.3456
Epoch [20/50] - Train Loss: 1.5678, Test Loss: 1.7890
Epoch [30/50] - Train Loss: 1.2345, Test Loss: 1.4567
Epoch [40/50] - Train Loss: 1.0123, Test Loss: 1.2345
Epoch [50/50] - Train Loss: 0.8901, Test Loss: 1.1234
Â≠¶ÁøíÂÆå‰∫ÜÔºÅ
Â≠¶ÁøíÊõ≤Á∑ö„Çí cgcnn_training_curve.png „Å´‰øùÂ≠ò„Åó„Åæ„Åó„Åü
</code></pre>
<h3>„Ç≥„Éº„Éâ‰æã8: CGCNN„Åã„Çâ„ÅÆÂüã„ÇÅËæº„ÅøÊäΩÂá∫</h3>
<pre><code class="language-python">import torch
import numpy as np
from torch_geometric.loader import DataLoader

def extract_embeddings(model, dataset, device='cpu'):
    &quot;&quot;&quot;
    Â≠¶ÁøíÊ∏à„Åø„É¢„Éá„É´„Åã„ÇâÂÖ®„Éá„Éº„Çø„ÅÆÂüã„ÇÅËæº„Åø„ÇíÊäΩÂá∫

    Parameters:
    -----------
    model : nn.Module
        Â≠¶ÁøíÊ∏à„Åø„É¢„Éá„É´
    dataset : Dataset
        „Éá„Éº„Çø„Çª„ÉÉ„Éà
    device : str
        „Éá„Éê„Ç§„Çπ

    Returns:
    --------
    embeddings : np.ndarray
        Âüã„ÇÅËæº„Åø„Éô„ÇØ„Éà„É´
    targets : np.ndarray
        „Çø„Éº„Ç≤„ÉÉ„ÉàÂÄ§
    &quot;&quot;&quot;
    model.eval()
    loader = DataLoader(dataset, batch_size=64, shuffle=False)

    all_embeddings = []
    all_targets = []

    with torch.no_grad():
        for batch in loader:
            batch = batch.to(device)
            _, embeddings = model(batch)

            all_embeddings.append(embeddings.cpu().numpy())
            all_targets.append(batch.y.cpu().numpy())

    embeddings = np.concatenate(all_embeddings, axis=0)
    targets = np.concatenate(all_targets, axis=0).flatten()

    return embeddings, targets


# ÂÖ®„Éá„Éº„Çø„Çª„ÉÉ„Éà„Åã„ÇâÂüã„ÇÅËæº„Åø„ÇíÊäΩÂá∫
embeddings, targets = extract_embeddings(model, dataset, device=device)

print(f&quot;Âüã„ÇÅËæº„Åø„ÅÆÂΩ¢Áä∂: {embeddings.shape}&quot;)
print(f&quot;„Çø„Éº„Ç≤„ÉÉ„Éà„ÅÆÂΩ¢Áä∂: {targets.shape}&quot;)
print(f&quot;\n„Çø„Éº„Ç≤„ÉÉ„ÉàÁµ±Ë®à:&quot;)
print(f&quot;  Âπ≥Âùá: {targets.mean():.3f}&quot;)
print(f&quot;  Ê®ôÊ∫ñÂÅèÂ∑Æ: {targets.std():.3f}&quot;)
print(f&quot;  ÊúÄÂ∞èÂÄ§: {targets.min():.3f}&quot;)
print(f&quot;  ÊúÄÂ§ßÂÄ§: {targets.max():.3f}&quot;)
</code></pre>
<p><strong>Âá∫Âäõ‰æã</strong>:</p>
<pre><code>Âüã„ÇÅËæº„Åø„ÅÆÂΩ¢Áä∂: (1000, 64)
„Çø„Éº„Ç≤„ÉÉ„Éà„ÅÆÂΩ¢Áä∂: (1000,)

„Çø„Éº„Ç≤„ÉÉ„ÉàÁµ±Ë®à:
  Âπ≥Âùá: 2.015
  Ê®ôÊ∫ñÂÅèÂ∑Æ: 2.034
  ÊúÄÂ∞èÂÄ§: 0.012
  ÊúÄÂ§ßÂÄ§: 12.456
</code></pre>
<h2>3.3 MEGNetÔºàMatErials Graph NetworkÔºâ</h2>
<p>MEGNet„ÅØ„ÄÅ„Ç∞„É≠„Éº„Éê„É´Áä∂ÊÖã„ÇíËÄÉÊÖÆ„Åó„Åü„Çà„ÇäÊüîËªü„Å™GNN„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£„Åß„Åô„ÄÇ</p>
<h3>„Ç≥„Éº„Éâ‰æã9: MEGNet„Éñ„É≠„ÉÉ„ÇØ</h3>
<pre><code class="language-python">import torch
import torch.nn as nn
from torch_geometric.nn import MessagePassing, global_mean_pool

class MEGNetBlock(MessagePassing):
    &quot;&quot;&quot;
    MEGNet„ÅÆÂü∫Êú¨„Éñ„É≠„ÉÉ„ÇØ
    „Éé„Éº„Éâ„ÄÅ„Ç®„ÉÉ„Ç∏„ÄÅ„Ç∞„É≠„Éº„Éê„É´Áä∂ÊÖã„ÇíÂêåÊôÇ„Å´Êõ¥Êñ∞
    &quot;&quot;&quot;

    def __init__(self, node_dim, edge_dim, global_dim, hidden_dim=64):
        super().__init__(aggr='mean')

        self.node_dim = node_dim
        self.edge_dim = edge_dim
        self.global_dim = global_dim
        self.hidden_dim = hidden_dim

        # „Ç®„ÉÉ„Ç∏Êõ¥Êñ∞„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ
        self.edge_model = nn.Sequential(
            nn.Linear(node_dim * 2 + edge_dim + global_dim, hidden_dim),
            nn.Softplus(),
            nn.Linear(hidden_dim, edge_dim)
        )

        # „Éé„Éº„ÉâÊõ¥Êñ∞„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ
        self.node_model = nn.Sequential(
            nn.Linear(node_dim + edge_dim + global_dim, hidden_dim),
            nn.Softplus(),
            nn.Linear(hidden_dim, node_dim)
        )

        # „Ç∞„É≠„Éº„Éê„É´Áä∂ÊÖãÊõ¥Êñ∞„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ
        self.global_model = nn.Sequential(
            nn.Linear(node_dim + edge_dim + global_dim, hidden_dim),
            nn.Softplus(),
            nn.Linear(hidden_dim, global_dim)
        )

    def forward(self, x, edge_index, edge_attr, u, batch):
        &quot;&quot;&quot;
        È†Ü‰ºùÊí≠

        Parameters:
        -----------
        x : Tensor [num_nodes, node_dim]
            „Éé„Éº„ÉâÁâπÂæ¥
        edge_index : Tensor [2, num_edges]
            „Ç®„ÉÉ„Ç∏„Ç§„É≥„Éá„ÉÉ„ÇØ„Çπ
        edge_attr : Tensor [num_edges, edge_dim]
            „Ç®„ÉÉ„Ç∏ÁâπÂæ¥
        u : Tensor [batch_size, global_dim]
            „Ç∞„É≠„Éº„Éê„É´Áä∂ÊÖã
        batch : Tensor [num_nodes]
            „Éê„ÉÉ„ÉÅ„Ç§„É≥„Éá„ÉÉ„ÇØ„Çπ

        Returns:
        --------
        x_new : Tensor [num_nodes, node_dim]
            Êõ¥Êñ∞„Åï„Çå„Åü„Éé„Éº„ÉâÁâπÂæ¥
        edge_attr_new : Tensor [num_edges, edge_dim]
            Êõ¥Êñ∞„Åï„Çå„Åü„Ç®„ÉÉ„Ç∏ÁâπÂæ¥
        u_new : Tensor [batch_size, global_dim]
            Êõ¥Êñ∞„Åï„Çå„Åü„Ç∞„É≠„Éº„Éê„É´Áä∂ÊÖã
        &quot;&quot;&quot;
        row, col = edge_index

        # 1. „Ç®„ÉÉ„Ç∏Êõ¥Êñ∞
        edge_input = torch.cat([
            x[row], x[col], edge_attr, u[batch[row]]
        ], dim=1)
        edge_attr_new = edge_attr + self.edge_model(edge_input)

        # 2. „Éé„Éº„ÉâÊõ¥Êñ∞Ôºà„É°„ÉÉ„Çª„Éº„Ç∏„Éë„ÉÉ„Ç∑„É≥„Ç∞Ôºâ
        x_new = x + self.propagate(edge_index, x=x, edge_attr=edge_attr_new,
                                    u=u, batch=batch)

        # 3. „Ç∞„É≠„Éº„Éê„É´Áä∂ÊÖãÊõ¥Êñ∞
        # „Ç∞„É©„Éï„Åî„Å®„ÅÆ„Éé„Éº„Éâ„Éª„Ç®„ÉÉ„Ç∏ÁâπÂæ¥„ÅÆÂπ≥Âùá
        node_global = global_mean_pool(x_new, batch)
        edge_global = global_mean_pool(edge_attr_new, batch[row])

        global_input = torch.cat([node_global, edge_global, u], dim=1)
        u_new = u + self.global_model(global_input)

        return x_new, edge_attr_new, u_new

    def message(self, x_j, edge_attr, u, batch):
        &quot;&quot;&quot;
        „É°„ÉÉ„Çª„Éº„Ç∏Èñ¢Êï∞

        Parameters:
        -----------
        x_j : Tensor [num_edges, node_dim]
            ÈÄÅ‰ø°ÂÖÉ„Éé„Éº„ÉâÁâπÂæ¥
        edge_attr : Tensor [num_edges, edge_dim]
            „Ç®„ÉÉ„Ç∏ÁâπÂæ¥
        u : Tensor [batch_size, global_dim]
            „Ç∞„É≠„Éº„Éê„É´Áä∂ÊÖã
        batch : Tensor [num_edges]
            „Éê„ÉÉ„ÉÅ„Ç§„É≥„Éá„ÉÉ„ÇØ„Çπ

        Returns:
        --------
        message : Tensor [num_edges, node_dim]
            „É°„ÉÉ„Çª„Éº„Ç∏
        &quot;&quot;&quot;
        # „Éé„Éº„ÉâËá™Ë∫´„ÅÆÁâπÂæ¥„ÇÇ‰Ωø„ÅÜÂ†¥Âêà„ÅØpropagate„ÅÆÂºïÊï∞„Åã„ÇâÂèñÂæó
        # „Åì„Åì„Åß„ÅØÁ∞°Áï•Âåñ„ÅÆ„Åü„ÇÅÁúÅÁï•
        message_input = torch.cat([x_j, edge_attr, u[batch]], dim=1)
        return self.node_model(message_input) - x_j  # ÊÆãÂ∑Æ


# „ÉÜ„Çπ„Éà
node_dim = 32
edge_dim = 16
global_dim = 8
hidden_dim = 64

megnet_block = MEGNetBlock(node_dim, edge_dim, global_dim, hidden_dim)

# „ÉÄ„Éü„Éº„Éá„Éº„Çø
x = torch.randn(10, node_dim)
edge_index = torch.randint(0, 10, (2, 30))
edge_attr = torch.randn(30, edge_dim)
u = torch.randn(1, global_dim)  # 1„Å§„ÅÆ„Ç∞„É©„Éï
batch = torch.zeros(10, dtype=torch.long)  # ÂÖ®„Éé„Éº„Éâ„ÅåÂêå„Åò„Ç∞„É©„Éï„Å´Â±û„Åô„Çã

# È†Ü‰ºùÊí≠
x_new, edge_attr_new, u_new = megnet_block(x, edge_index, edge_attr, u, batch)

print(f&quot;„Éé„Éº„ÉâÁâπÂæ¥: {x.shape} -&gt; {x_new.shape}&quot;)
print(f&quot;„Ç®„ÉÉ„Ç∏ÁâπÂæ¥: {edge_attr.shape} -&gt; {edge_attr_new.shape}&quot;)
print(f&quot;„Ç∞„É≠„Éº„Éê„É´Áä∂ÊÖã: {u.shape} -&gt; {u_new.shape}&quot;)
</code></pre>
<p><strong>Âá∫Âäõ‰æã</strong>:</p>
<pre><code>„Éé„Éº„ÉâÁâπÂæ¥: torch.Size([10, 32]) -&gt; torch.Size([10, 32])
„Ç®„ÉÉ„Ç∏ÁâπÂæ¥: torch.Size([30, 16]) -&gt; torch.Size([30, 16])
„Ç∞„É≠„Éº„Éê„É´Áä∂ÊÖã: torch.Size([1, 8]) -&gt; torch.Size([1, 8])
</code></pre>
<h3>„Ç≥„Éº„Éâ‰æã10: ÂÆåÂÖ®„Å™MEGNet„É¢„Éá„É´</h3>
<pre><code class="language-python">import torch
import torch.nn as nn
import torch.nn.functional as F
from torch_geometric.nn import global_mean_pool

class MEGNet(nn.Module):
    &quot;&quot;&quot;
    MatErials Graph Network (MEGNet)
    &quot;&quot;&quot;

    def __init__(self, node_dim, edge_dim, hidden_dim=64, num_blocks=3):
        super().__init__()

        self.node_dim = node_dim
        self.edge_dim_orig = edge_dim
        self.hidden_dim = hidden_dim
        self.num_blocks = num_blocks

        # ÁâπÂæ¥„ÅÆÊ¨°ÂÖÉ„ÇíÁµ±‰∏Ä
        self.node_embedding = nn.Linear(node_dim, hidden_dim)
        self.edge_embedding = nn.Linear(edge_dim, hidden_dim)

        # „Ç∞„É≠„Éº„Éê„É´Áä∂ÊÖã„ÅÆÂàùÊúüÂåñ
        self.global_init = nn.Parameter(torch.randn(1, hidden_dim))

        # MEGNet„Éñ„É≠„ÉÉ„ÇØ
        self.blocks = nn.ModuleList([
            MEGNetBlock(hidden_dim, hidden_dim, hidden_dim, hidden_dim)
            for _ in range(num_blocks)
        ])

        # Âá∫ÂäõÂ±§
        self.fc = nn.Sequential(
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.Softplus(),
            nn.Dropout(0.2),
            nn.Linear(hidden_dim // 2, 1)
        )

    def forward(self, data):
        &quot;&quot;&quot;
        È†Ü‰ºùÊí≠

        Parameters:
        -----------
        data : torch_geometric.data.Data or Batch
            „Ç∞„É©„Éï„Éá„Éº„Çø

        Returns:
        --------
        out : Tensor [batch_size, 1]
            ‰∫àÊ∏¨ÂÄ§
        embedding : Tensor [batch_size, hidden_dim]
            „Ç∞„É©„ÉïÂüã„ÇÅËæº„Åø
        &quot;&quot;&quot;
        x, edge_index, edge_attr, batch = data.x, data.edge_index, data.edge_attr, data.batch

        # Âüã„ÇÅËæº„Åø
        x = self.node_embedding(x)
        edge_attr = self.edge_embedding(edge_attr)

        # „Éê„ÉÉ„ÉÅ„Çµ„Ç§„Ç∫„ÅÆÂèñÂæó
        batch_size = batch.max().item() + 1

        # „Ç∞„É≠„Éº„Éê„É´Áä∂ÊÖã„ÅÆÂàùÊúüÂåñ
        u = self.global_init.expand(batch_size, -1)

        # MEGNet„Éñ„É≠„ÉÉ„ÇØ„ÅÆÈÅ©Áî®
        for block in self.blocks:
            x, edge_attr, u = block(x, edge_index, edge_attr, u, batch)

        # „Ç∞„É≠„Éº„Éê„É´Áä∂ÊÖã„ÅåÊúÄÁµÇÁöÑ„Å™Âüã„ÇÅËæº„Åø
        graph_embedding = u

        # Âá∫Âäõ
        out = self.fc(graph_embedding)

        return out, graph_embedding


# „É¢„Éá„É´„ÅÆ„Ç§„É≥„Çπ„Çø„É≥„ÇπÂåñ„Å®„ÉÜ„Çπ„Éà
megnet_model = MEGNet(node_dim=24, edge_dim=1, hidden_dim=64, num_blocks=3)

print(f&quot;MEGNet„É¢„Éá„É´„ÅÆÁ∑è„Éë„É©„É°„Éº„ÇøÊï∞: {sum(p.numel() for p in megnet_model.parameters()):,}&quot;)

# „ÉÜ„Çπ„Éà
batch = next(iter(DataLoader(dataset, batch_size=32, shuffle=False)))
predictions, embeddings = megnet_model(batch)

print(f&quot;\n‰∫àÊ∏¨ÂÄ§„ÅÆÂΩ¢Áä∂: {predictions.shape}&quot;)
print(f&quot;Âüã„ÇÅËæº„Åø„ÅÆÂΩ¢Áä∂: {embeddings.shape}&quot;)
</code></pre>
<h2>3.4 SchNet</h2>
<p>SchNet„ÅØ„ÄÅÈÄ£Á∂ö„Éï„Ç£„É´„Çø„ÇíÁî®„ÅÑ„ÅüÁâ©ÁêÜÁöÑ„Å´Â¶•ÂΩì„Å™GNN„É¢„Éá„É´„Åß„Åô„ÄÇ</p>
<h3>„Ç≥„Éº„Éâ‰æã11: SchNet„ÅÆÈÄ£Á∂ö„Éï„Ç£„É´„ÇøÁï≥„ÅøËæº„ÅøÂ±§</h3>
<pre><code class="language-python">import torch
import torch.nn as nn
import numpy as np
from torch_geometric.nn import MessagePassing

class GaussianSmearing(nn.Module):
    &quot;&quot;&quot;
    „Ç¨„Ç¶„ÇπÂü∫Â∫ïÈñ¢Êï∞„Å´„Çà„ÇãË∑ùÈõ¢„ÅÆÂüã„ÇÅËæº„Åø
    &quot;&quot;&quot;

    def __init__(self, start=0.0, stop=5.0, num_gaussians=50):
        super().__init__()

        offset = torch.linspace(start, stop, num_gaussians)
        self.coeff = -0.5 / (offset[1] - offset[0]).item() ** 2
        self.register_buffer('offset', offset)

    def forward(self, dist):
        &quot;&quot;&quot;
        Parameters:
        -----------
        dist : Tensor [num_edges, 1]
            ÂéüÂ≠êÈñìË∑ùÈõ¢

        Returns:
        --------
        rbf : Tensor [num_edges, num_gaussians]
            „Ç¨„Ç¶„ÇπÂü∫Â∫ïÈñ¢Êï∞„Å´„Çà„ÇãË°®Áèæ
        &quot;&quot;&quot;
        dist = dist.view(-1, 1) - self.offset.view(1, -1)
        return torch.exp(self.coeff * torch.pow(dist, 2))


class CFConv(MessagePassing):
    &quot;&quot;&quot;
    Continuous-Filter Convolution (SchNet„ÅÆÂü∫Êú¨Â±§)
    &quot;&quot;&quot;

    def __init__(self, node_dim, edge_dim, hidden_dim=64, num_gaussians=50):
        super().__init__(aggr='add')

        self.node_dim = node_dim
        self.edge_dim = edge_dim
        self.hidden_dim = hidden_dim

        # „Ç¨„Ç¶„ÇπÂü∫Â∫ïÈñ¢Êï∞
        self.distance_expansion = GaussianSmearing(0.0, 5.0, num_gaussians)

        # „Éï„Ç£„É´„Çø„ÉºÁîüÊàê„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ
        self.filter_network = nn.Sequential(
            nn.Linear(num_gaussians, hidden_dim),
            nn.Softplus(),
            nn.Linear(hidden_dim, node_dim * hidden_dim)
        )

        # „Éé„Éº„ÉâÊõ¥Êñ∞„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ
        self.node_network = nn.Sequential(
            nn.Linear(node_dim, hidden_dim),
            nn.Softplus(),
            nn.Linear(hidden_dim, hidden_dim)
        )

    def forward(self, x, edge_index, edge_attr):
        &quot;&quot;&quot;
        È†Ü‰ºùÊí≠

        Parameters:
        -----------
        x : Tensor [num_nodes, node_dim]
            „Éé„Éº„ÉâÁâπÂæ¥
        edge_index : Tensor [2, num_edges]
            „Ç®„ÉÉ„Ç∏„Ç§„É≥„Éá„ÉÉ„ÇØ„Çπ
        edge_attr : Tensor [num_edges, 1]
            „Ç®„ÉÉ„Ç∏ÁâπÂæ¥ÔºàË∑ùÈõ¢Ôºâ

        Returns:
        --------
        out : Tensor [num_nodes, hidden_dim]
            Êõ¥Êñ∞„Åï„Çå„Åü„Éé„Éº„ÉâÁâπÂæ¥
        &quot;&quot;&quot;
        # „Éé„Éº„ÉâÁâπÂæ¥„ÅÆÂâçÂá¶ÁêÜ
        x = self.node_network(x)

        # „É°„ÉÉ„Çª„Éº„Ç∏„Éë„ÉÉ„Ç∑„É≥„Ç∞
        out = self.propagate(edge_index, x=x, edge_attr=edge_attr)

        return out

    def message(self, x_j, edge_attr):
        &quot;&quot;&quot;
        „É°„ÉÉ„Çª„Éº„Ç∏Èñ¢Êï∞

        Parameters:
        -----------
        x_j : Tensor [num_edges, node_dim]
            ÈÄÅ‰ø°ÂÖÉ„Éé„Éº„ÉâÁâπÂæ¥
        edge_attr : Tensor [num_edges, 1]
            „Ç®„ÉÉ„Ç∏ÁâπÂæ¥ÔºàË∑ùÈõ¢Ôºâ

        Returns:
        --------
        message : Tensor [num_edges, hidden_dim]
            „É°„ÉÉ„Çª„Éº„Ç∏
        &quot;&quot;&quot;
        # Ë∑ùÈõ¢„ÇíÂü∫Â∫ïÈñ¢Êï∞„ÅßÂ±ïÈñã
        edge_features = self.distance_expansion(edge_attr)

        # „Éï„Ç£„É´„Çø„Éº„ÅÆÁîüÊàê
        W = self.filter_network(edge_features)
        W = W.view(-1, self.node_dim, self.hidden_dim)

        # „Éï„Ç£„É´„Çø„Éº„ÅÆÈÅ©Áî®
        x_j = x_j.unsqueeze(1)  # [num_edges, 1, node_dim]
        message = torch.bmm(x_j, W).squeeze(1)  # [num_edges, hidden_dim]

        return message


# „ÉÜ„Çπ„Éà
node_dim = 64
edge_dim = 1
hidden_dim = 64

cfconv = CFConv(node_dim, edge_dim, hidden_dim, num_gaussians=50)

# „ÉÄ„Éü„Éº„Éá„Éº„Çø
x = torch.randn(10, node_dim)
edge_index = torch.randint(0, 10, (2, 30))
edge_attr = torch.rand(30, 1) * 5.0  # Ë∑ùÈõ¢

# È†Ü‰ºùÊí≠
out = cfconv(x, edge_index, edge_attr)

print(f&quot;ÂÖ•Âäõ„Éé„Éº„ÉâÁâπÂæ¥„ÅÆÂΩ¢Áä∂: {x.shape}&quot;)
print(f&quot;Âá∫Âäõ„Éé„Éº„ÉâÁâπÂæ¥„ÅÆÂΩ¢Áä∂: {out.shape}&quot;)
</code></pre>
<p><strong>Âá∫Âäõ‰æã</strong>:</p>
<pre><code>ÂÖ•Âäõ„Éé„Éº„ÉâÁâπÂæ¥„ÅÆÂΩ¢Áä∂: torch.Size([10, 64])
Âá∫Âäõ„Éé„Éº„ÉâÁâπÂæ¥„ÅÆÂΩ¢Áä∂: torch.Size([10, 64])
</code></pre>
<h3>„Ç≥„Éº„Éâ‰æã12: ÂÆåÂÖ®„Å™SchNet„É¢„Éá„É´</h3>
<pre><code class="language-python">import torch
import torch.nn as nn
import torch.nn.functional as F
from torch_geometric.nn import global_add_pool

class SchNet(nn.Module):
    &quot;&quot;&quot;
    SchNet: continuous-filter convolutional neural network
    &quot;&quot;&quot;

    def __init__(self, node_dim, hidden_dim=64, num_filters=64,
                 num_interactions=3, num_gaussians=50):
        super().__init__()

        self.node_dim = node_dim
        self.hidden_dim = hidden_dim
        self.num_filters = num_filters
        self.num_interactions = num_interactions

        # Âüã„ÇÅËæº„ÅøÂ±§
        self.embedding = nn.Linear(node_dim, hidden_dim)

        # Interaction blocks
        self.interactions = nn.ModuleList([
            CFConv(hidden_dim, 1, num_filters, num_gaussians)
            for _ in range(num_interactions)
        ])

        # Update networks
        self.updates = nn.ModuleList([
            nn.Sequential(
                nn.Linear(num_filters, hidden_dim),
                nn.Softplus(),
                nn.Linear(hidden_dim, hidden_dim)
            )
            for _ in range(num_interactions)
        ])

        # Âá∫Âäõ„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ
        self.fc = nn.Sequential(
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.Softplus(),
            nn.Dropout(0.2),
            nn.Linear(hidden_dim // 2, 1)
        )

    def forward(self, data):
        &quot;&quot;&quot;
        È†Ü‰ºùÊí≠

        Parameters:
        -----------
        data : torch_geometric.data.Data or Batch
            „Ç∞„É©„Éï„Éá„Éº„Çø

        Returns:
        --------
        out : Tensor [batch_size, 1]
            ‰∫àÊ∏¨ÂÄ§
        embedding : Tensor [batch_size, hidden_dim]
            „Ç∞„É©„ÉïÂüã„ÇÅËæº„Åø
        &quot;&quot;&quot;
        x, edge_index, edge_attr, batch = data.x, data.edge_index, data.edge_attr, data.batch

        # Âüã„ÇÅËæº„Åø
        x = self.embedding(x)

        # Interaction blocks
        for interaction, update in zip(self.interactions, self.updates):
            # CFConv
            v = interaction(x, edge_index, edge_attr)

            # Update
            x = x + update(v)

        # „Ç∞„É©„Éï„É¨„Éô„É´„ÅÆÂüã„ÇÅËæº„Åø
        graph_embedding = global_add_pool(x, batch)

        # Âá∫Âäõ
        out = self.fc(graph_embedding)

        return out, graph_embedding


# „É¢„Éá„É´„ÅÆ„Ç§„É≥„Çπ„Çø„É≥„ÇπÂåñ„Å®„ÉÜ„Çπ„Éà
schnet_model = SchNet(node_dim=24, hidden_dim=64, num_filters=64,
                      num_interactions=3, num_gaussians=50)

print(f&quot;SchNet„É¢„Éá„É´„ÅÆÁ∑è„Éë„É©„É°„Éº„ÇøÊï∞: {sum(p.numel() for p in schnet_model.parameters()):,}&quot;)

# „ÉÜ„Çπ„Éà
batch = next(iter(DataLoader(dataset, batch_size=32, shuffle=False)))
predictions, embeddings = schnet_model(batch)

print(f&quot;\n‰∫àÊ∏¨ÂÄ§„ÅÆÂΩ¢Áä∂: {predictions.shape}&quot;)
print(f&quot;Âüã„ÇÅËæº„Åø„ÅÆÂΩ¢Áä∂: {embeddings.shape}&quot;)
</code></pre>
<h2>3.5 Âüã„ÇÅËæº„Åø„ÅÆÂèØË¶ñÂåñ„Å®ÂàÜÊûê</h2>
<h3>„Ç≥„Éº„Éâ‰æã13: UMAP„Å´„Çà„ÇãGNNÂüã„ÇÅËæº„Åø„ÅÆÂèØË¶ñÂåñ</h3>
<pre><code class="language-python">import umap
import matplotlib.pyplot as plt
import numpy as np

# CGCNN„Åã„Çâ„ÅÆÂüã„ÇÅËæº„ÅøÊäΩÂá∫
cgcnn_embeddings, cgcnn_targets = extract_embeddings(model, dataset, device=device)

# UMAP„Å´„Çà„ÇãÊ¨°ÂÖÉÂâäÊ∏õ
reducer = umap.UMAP(n_components=2, n_neighbors=15, min_dist=0.1, random_state=42)
cgcnn_umap = reducer.fit_transform(cgcnn_embeddings)

# ÂèØË¶ñÂåñ
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 7))

# „Çø„Éº„Ç≤„ÉÉ„ÉàÂÄ§„ÅßËâ≤‰ªò„Åë
scatter1 = ax1.scatter(cgcnn_umap[:, 0], cgcnn_umap[:, 1],
                       c=cgcnn_targets, cmap='viridis',
                       s=50, alpha=0.6, edgecolors='black', linewidth=0.5)
ax1.set_xlabel('UMAP 1', fontsize=14, fontweight='bold')
ax1.set_ylabel('UMAP 2', fontsize=14, fontweight='bold')
ax1.set_title('CGCNN Embeddings: colored by Band Gap',
              fontsize=16, fontweight='bold')
ax1.grid(True, alpha=0.3)
cbar1 = plt.colorbar(scatter1, ax=ax1)
cbar1.set_label('Band Gap (eV)', fontsize=12, fontweight='bold')

# ÂÆâÂÆöÊÄß„Åß„Ç´„ÉÜ„Ç¥„É™ÂàÜ„ÅëÔºà„ÉÄ„Éü„Éº„Éá„Éº„Çø„Å™„ÅÆ„Åß‰ªÆ„ÅÆÂàÜÈ°ûÔºâ
stability_categories = np.digitize(cgcnn_targets, bins=[0, 1, 2, 4])
colors_cat = ['red', 'orange', 'yellow', 'green']

for i, label in enumerate(['Very Low', 'Low', 'Medium', 'High']):
    mask = stability_categories == i
    ax2.scatter(cgcnn_umap[mask, 0], cgcnn_umap[mask, 1],
                c=colors_cat[i], label=label, s=50, alpha=0.7,
                edgecolors='black', linewidth=0.5)

ax2.set_xlabel('UMAP 1', fontsize=14, fontweight='bold')
ax2.set_ylabel('UMAP 2', fontsize=14, fontweight='bold')
ax2.set_title('CGCNN Embeddings: colored by Category',
              fontsize=16, fontweight='bold')
ax2.legend(title='Band Gap Category', fontsize=11)
ax2.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('cgcnn_embeddings_umap.png', dpi=300, bbox_inches='tight')
print(&quot;CGCNNÂüã„ÇÅËæº„Åø„ÅÆUMAP„Çí cgcnn_embeddings_umap.png „Å´‰øùÂ≠ò„Åó„Åæ„Åó„Åü&quot;)
plt.show()
</code></pre>
<h3>„Ç≥„Éº„Éâ‰æã14: t-SNE„Å´„Çà„ÇãË§áÊï∞„É¢„Éá„É´„ÅÆÊØîËºÉ</h3>
<pre><code class="language-python">from sklearn.manifold import TSNE
import matplotlib.pyplot as plt

# Ë§áÊï∞„É¢„Éá„É´„ÅÆÂüã„ÇÅËæº„ÅøÔºà„Åì„Åì„Åß„ÅØCGCNN„ÅÆ„Åø„Å†„ÅåMEGNet„ÄÅSchNet„ÇÇÂêåÊßò„Å´ÊäΩÂá∫ÂèØËÉΩÔºâ
models_dict = {
    'CGCNN': (model, cgcnn_embeddings)
}

# t-SNE„Å´„Çà„ÇãÊ¨°ÂÖÉÂâäÊ∏õ
tsne_results = {}
for model_name, (_, embeddings) in models_dict.items():
    tsne = TSNE(n_components=2, perplexity=30, n_iter=1000, random_state=42)
    tsne_embedding = tsne.fit_transform(embeddings)
    tsne_results[model_name] = tsne_embedding

# ÂèØË¶ñÂåñ
fig, axes = plt.subplots(1, len(models_dict), figsize=(8 * len(models_dict), 7))

if len(models_dict) == 1:
    axes = [axes]

for idx, (model_name, tsne_emb) in enumerate(tsne_results.items()):
    ax = axes[idx]

    scatter = ax.scatter(tsne_emb[:, 0], tsne_emb[:, 1],
                         c=cgcnn_targets, cmap='plasma',
                         s=50, alpha=0.6, edgecolors='black', linewidth=0.5)

    ax.set_xlabel('t-SNE 1', fontsize=14, fontweight='bold')
    ax.set_ylabel('t-SNE 2', fontsize=14, fontweight='bold')
    ax.set_title(f'{model_name} Embeddings (t-SNE)',
                 fontsize=16, fontweight='bold')
    ax.grid(True, alpha=0.3)

    cbar = plt.colorbar(scatter, ax=ax)
    cbar.set_label('Band Gap (eV)', fontsize=12, fontweight='bold')

plt.tight_layout()
plt.savefig('gnn_embeddings_tsne_comparison.png', dpi=300, bbox_inches='tight')
print(&quot;GNNÂüã„ÇÅËæº„Åø„ÅÆt-SNEÊØîËºÉ„Çí gnn_embeddings_tsne_comparison.png „Å´‰øùÂ≠ò„Åó„Åæ„Åó„Åü&quot;)
plt.show()
</code></pre>
<h3>„Ç≥„Éº„Éâ‰æã15: „ÇØ„É©„Çπ„Çø„É™„É≥„Ç∞„Å®ÁâπÊÄßÂàÜÊûê</h3>
<pre><code class="language-python">from sklearn.cluster import KMeans
import pandas as pd
import seaborn as sns

# K-Means„ÇØ„É©„Çπ„Çø„É™„É≥„Ç∞
n_clusters = 5
kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
cluster_labels = kmeans.fit_predict(cgcnn_embeddings)

# UMAP‰∏ä„Å´„ÇØ„É©„Çπ„Çø„ÇíË°®Á§∫
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 7))

# „ÇØ„É©„Çπ„Çø„É©„Éô„É´„ÅßËâ≤‰ªò„Åë
colors = plt.cm.Set3(np.linspace(0, 1, n_clusters))
for cluster_id in range(n_clusters):
    mask = cluster_labels == cluster_id
    ax1.scatter(cgcnn_umap[mask, 0], cgcnn_umap[mask, 1],
                c=[colors[cluster_id]], label=f'Cluster {cluster_id}',
                s=60, alpha=0.7, edgecolors='black', linewidth=0.5)

# „ÇØ„É©„Çπ„Çø‰∏≠ÂøÉ
kmeans_umap = reducer.transform(kmeans.cluster_centers_)
ax1.scatter(kmeans_umap[:, 0], kmeans_umap[:, 1],
            c='red', marker='X', s=300, edgecolors='black',
            linewidth=2, label='Centroids', zorder=10)

ax1.set_xlabel('UMAP 1', fontsize=14, fontweight='bold')
ax1.set_ylabel('UMAP 2', fontsize=14, fontweight='bold')
ax1.set_title('Clustering on CGCNN Embeddings',
              fontsize=16, fontweight='bold')
ax1.legend(fontsize=11, loc='best')
ax1.grid(True, alpha=0.3)

# „ÇØ„É©„Çπ„Çø„Åî„Å®„ÅÆ„Çø„Éº„Ç≤„ÉÉ„ÉàÂàÜÂ∏É
cluster_df = pd.DataFrame({
    'cluster': cluster_labels,
    'band_gap': cgcnn_targets
})

sns.boxplot(data=cluster_df, x='cluster', y='band_gap', ax=ax2, palette='Set3')
ax2.set_xlabel('Cluster ID', fontsize=14, fontweight='bold')
ax2.set_ylabel('Band Gap (eV)', fontsize=14, fontweight='bold')
ax2.set_title('Band Gap Distribution by Cluster',
              fontsize=16, fontweight='bold')
ax2.grid(True, alpha=0.3, axis='y')

plt.tight_layout()
plt.savefig('cgcnn_clustering_analysis.png', dpi=300, bbox_inches='tight')
print(&quot;„ÇØ„É©„Çπ„Çø„É™„É≥„Ç∞ÂàÜÊûê„Çí cgcnn_clustering_analysis.png „Å´‰øùÂ≠ò„Åó„Åæ„Åó„Åü&quot;)
plt.show()

# „ÇØ„É©„Çπ„ÇøÁµ±Ë®à
print(&quot;\n„ÇØ„É©„Çπ„Çø„Åî„Å®„ÅÆ„Éê„É≥„Éâ„ÇÆ„É£„ÉÉ„ÉóÁµ±Ë®à:&quot;)
cluster_stats = cluster_df.groupby('cluster')['band_gap'].agg(['mean', 'std', 'min', 'max', 'count'])
print(cluster_stats.round(3))
</code></pre>
<h2>3.6 Âüã„ÇÅËæº„ÅøÁ©∫Èñì„ÅÆËß£Èáà</h2>
<h3>„Ç≥„Éº„Éâ‰æã16: Âüã„ÇÅËæº„Åø„Éô„ÇØ„Éà„É´„ÅÆ‰∏ªÊàêÂàÜÂàÜÊûê</h3>
<pre><code class="language-python">from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
import numpy as np

# PCA„Å´„Çà„ÇãÂüã„ÇÅËæº„ÅøÁ©∫Èñì„ÅÆÂàÜÊûê
pca_embedding = PCA(n_components=10)
cgcnn_pca = pca_embedding.fit_transform(cgcnn_embeddings)

# ÂØÑ‰∏éÁéá„ÅÆ„Éó„É≠„ÉÉ„Éà
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))

# ÂÄãÂà•ÂØÑ‰∏éÁéá
ax1.bar(range(1, 11), pca_embedding.explained_variance_ratio_,
        alpha=0.7, edgecolor='black', color='steelblue')
ax1.set_xlabel('Principal Component', fontsize=14, fontweight='bold')
ax1.set_ylabel('Explained Variance Ratio', fontsize=14, fontweight='bold')
ax1.set_title('PCA on CGCNN Embeddings: Variance Explained',
              fontsize=16, fontweight='bold')
ax1.grid(True, alpha=0.3, axis='y')

# Á¥ØÁ©çÂØÑ‰∏éÁéá
cumsum_var = np.cumsum(pca_embedding.explained_variance_ratio_)
ax2.plot(range(1, 11), cumsum_var, marker='o', linewidth=2,
         markersize=8, color='darkred')
ax2.axhline(y=0.95, color='green', linestyle='--', linewidth=2,
            label='95% threshold', alpha=0.7)
ax2.set_xlabel('Number of Components', fontsize=14, fontweight='bold')
ax2.set_ylabel('Cumulative Variance Explained', fontsize=14, fontweight='bold')
ax2.set_title('Cumulative Variance Explained',
              fontsize=16, fontweight='bold')
ax2.legend(fontsize=12)
ax2.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('cgcnn_embedding_pca.png', dpi=300, bbox_inches='tight')
print(&quot;Âüã„ÇÅËæº„ÅøPCAÂàÜÊûê„Çí cgcnn_embedding_pca.png „Å´‰øùÂ≠ò„Åó„Åæ„Åó„Åü&quot;)
print(f&quot;\n95%„ÅÆÂàÜÊï£„ÇíË™¨Êòé„Åô„Çã„Åü„ÇÅ„Å´ÂøÖË¶Å„Å™‰∏ªÊàêÂàÜÊï∞: {np.argmax(cumsum_var &gt;= 0.95) + 1}&quot;)
plt.show()
</code></pre>
<h3>„Ç≥„Éº„Éâ‰æã17: Âüã„ÇÅËæº„ÅøÁ©∫Èñì„Åß„ÅÆËøëÂÇçÊé¢Á¥¢</h3>
<pre><code class="language-python">from sklearn.neighbors import NearestNeighbors
import numpy as np

def find_similar_materials(query_idx, embeddings, targets, k=5):
    &quot;&quot;&quot;
    Âüã„ÇÅËæº„ÅøÁ©∫Èñì„ÅßÈ°û‰ººÊùêÊñô„ÇíÊ§úÁ¥¢

    Parameters:
    -----------
    query_idx : int
        „ÇØ„Ç®„É™ÊùêÊñô„ÅÆ„Ç§„É≥„Éá„ÉÉ„ÇØ„Çπ
    embeddings : np.ndarray
        Âüã„ÇÅËæº„Åø„Éô„ÇØ„Éà„É´
    targets : np.ndarray
        „Çø„Éº„Ç≤„ÉÉ„ÉàÂÄ§
    k : int
        Ê§úÁ¥¢„Åô„ÇãËøëÂÇçÊï∞

    Returns:
    --------
    neighbors : dict
        ËøëÂÇçÊùêÊñô„ÅÆÊÉÖÂ†±
    &quot;&quot;&quot;
    nbrs = NearestNeighbors(n_neighbors=k+1, metric='cosine').fit(embeddings)
    distances, indices = nbrs.kneighbors(embeddings[query_idx:query_idx+1])

    neighbors = {
        'query_idx': query_idx,
        'query_target': targets[query_idx],
        'neighbor_indices': indices[0, 1:],  # Ëá™ÂàÜËá™Ë∫´„ÇíÈô§„Åè
        'neighbor_targets': targets[indices[0, 1:]],
        'distances': distances[0, 1:]
    }

    return neighbors


# „É©„É≥„ÉÄ„É†„Å´5„Å§„ÅÆÊùêÊñô„ÇíÈÅ∏„Çì„ÅßËøëÂÇçÊé¢Á¥¢
np.random.seed(42)
query_indices = np.random.choice(len(dataset), 5, replace=False)

print(&quot;ËøëÂÇçÊé¢Á¥¢ÁµêÊûú:\n&quot;)
for query_idx in query_indices:
    neighbors = find_similar_materials(query_idx, cgcnn_embeddings,
                                       cgcnn_targets, k=5)

    print(f&quot;„ÇØ„Ç®„É™ÊùêÊñô #{neighbors['query_idx']}:&quot;)
    print(f&quot;  „Çø„Éº„Ç≤„ÉÉ„ÉàÂÄ§: {neighbors['query_target']:.3f}&quot;)
    print(f&quot;  È°û‰ººÊùêÊñô:&quot;)

    for i, (neighbor_idx, target, dist) in enumerate(zip(
        neighbors['neighbor_indices'],
        neighbors['neighbor_targets'],
        neighbors['distances']
    )):
        print(f&quot;    {i+1}. Material #{neighbor_idx}: &quot;
              f&quot;Target={target:.3f}, Distance={dist:.3f}&quot;)
    print()
</code></pre>
<p><strong>Âá∫Âäõ‰æã</strong>:</p>
<pre><code>ËøëÂÇçÊé¢Á¥¢ÁµêÊûú:

„ÇØ„Ç®„É™ÊùêÊñô #123:
  „Çø„Éº„Ç≤„ÉÉ„ÉàÂÄ§: 2.456
  È°û‰ººÊùêÊñô:
    1. Material #456: Target=2.389, Distance=0.145
    2. Material #789: Target=2.567, Distance=0.189
    3. Material #234: Target=2.123, Distance=0.234
    4. Material #567: Target=2.678, Distance=0.267
    5. Material #890: Target=2.345, Distance=0.289
...
</code></pre>
<h3>„Ç≥„Éº„Éâ‰æã18: Âüã„ÇÅËæº„ÅøÁ©∫Èñì„ÅÆË∑ùÈõ¢ÂàÜÂ∏ÉÂàÜÊûê</h3>
<pre><code class="language-python">from scipy.spatial.distance import pdist, squareform
import matplotlib.pyplot as plt
import seaborn as sns

# ÂÖ®„Éö„Ç¢Èñì„ÅÆË∑ùÈõ¢„ÇíË®àÁÆóÔºà„Çµ„Éñ„Çª„ÉÉ„Éà„ÅßË®àÁÆóÔºâ
subset_size = 200
subset_indices = np.random.choice(len(cgcnn_embeddings), subset_size, replace=False)
subset_embeddings = cgcnn_embeddings[subset_indices]
subset_targets = cgcnn_targets[subset_indices]

# „É¶„Éº„ÇØ„É™„ÉÉ„ÉâË∑ùÈõ¢„Å®„Ç≥„Çµ„Ç§„É≥Ë∑ùÈõ¢
euclidean_distances = pdist(subset_embeddings, metric='euclidean')
cosine_distances = pdist(subset_embeddings, metric='cosine')

# „Çø„Éº„Ç≤„ÉÉ„ÉàÂÄ§„ÅÆÂ∑Æ
target_diff = pdist(subset_targets.reshape(-1, 1), metric='euclidean')

# ÂèØË¶ñÂåñ
fig, axes = plt.subplots(2, 2, figsize=(15, 12))

# 1. „É¶„Éº„ÇØ„É™„ÉÉ„ÉâË∑ùÈõ¢„ÅÆÂàÜÂ∏É
axes[0, 0].hist(euclidean_distances, bins=50, alpha=0.7,
                edgecolor='black', color='steelblue')
axes[0, 0].set_xlabel('Euclidean Distance', fontsize=12, fontweight='bold')
axes[0, 0].set_ylabel('Frequency', fontsize=12, fontweight='bold')
axes[0, 0].set_title('Distribution of Euclidean Distances',
                      fontsize=14, fontweight='bold')
axes[0, 0].grid(True, alpha=0.3)

# 2. „Ç≥„Çµ„Ç§„É≥Ë∑ùÈõ¢„ÅÆÂàÜÂ∏É
axes[0, 1].hist(cosine_distances, bins=50, alpha=0.7,
                edgecolor='black', color='coral')
axes[0, 1].set_xlabel('Cosine Distance', fontsize=12, fontweight='bold')
axes[0, 1].set_ylabel('Frequency', fontsize=12, fontweight='bold')
axes[0, 1].set_title('Distribution of Cosine Distances',
                      fontsize=14, fontweight='bold')
axes[0, 1].grid(True, alpha=0.3)

# 3. Âüã„ÇÅËæº„ÅøË∑ùÈõ¢ vs „Çø„Éº„Ç≤„ÉÉ„ÉàÂ∑Æ
axes[1, 0].scatter(euclidean_distances, target_diff,
                   alpha=0.3, s=10, color='purple')
axes[1, 0].set_xlabel('Embedding Distance (Euclidean)', fontsize=12, fontweight='bold')
axes[1, 0].set_ylabel('Band Gap Difference', fontsize=12, fontweight='bold')
axes[1, 0].set_title('Embedding Distance vs Property Difference',
                      fontsize=14, fontweight='bold')
axes[1, 0].grid(True, alpha=0.3)

# Áõ∏Èñ¢‰øÇÊï∞
correlation = np.corrcoef(euclidean_distances, target_diff)[0, 1]
axes[1, 0].text(0.05, 0.95, f'Correlation: {correlation:.3f}',
                transform=axes[1, 0].transAxes, fontsize=12,
                verticalalignment='top',
                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))

# 4. 2DÂØÜÂ∫¶„Éó„É≠„ÉÉ„Éà
from scipy.stats import gaussian_kde

# „Éá„Éº„Çø„ÅÆÊ∫ñÂÇô
x = euclidean_distances
y = target_diff

# KDE
xy = np.vstack([x, y])
z = gaussian_kde(xy)(xy)

# „ÇΩ„Éº„ÉàÔºàÂØÜÂ∫¶„ÅÆÈ´ò„ÅÑÁÇπ„Çí‰∏ä„Å´ÊèèÁîªÔºâ
idx = z.argsort()
x, y, z = x[idx], y[idx], z[idx]

scatter = axes[1, 1].scatter(x, y, c=z, cmap='hot', s=15, alpha=0.6)
axes[1, 1].set_xlabel('Embedding Distance (Euclidean)', fontsize=12, fontweight='bold')
axes[1, 1].set_ylabel('Band Gap Difference', fontsize=12, fontweight='bold')
axes[1, 1].set_title('Density Plot: Distance vs Difference',
                      fontsize=14, fontweight='bold')
axes[1, 1].grid(True, alpha=0.3)

cbar = plt.colorbar(scatter, ax=axes[1, 1])
cbar.set_label('Density', fontsize=10, fontweight='bold')

plt.tight_layout()
plt.savefig('cgcnn_embedding_distance_analysis.png', dpi=300, bbox_inches='tight')
print(&quot;Âüã„ÇÅËæº„ÅøË∑ùÈõ¢ÂàÜÊûê„Çí cgcnn_embedding_distance_analysis.png „Å´‰øùÂ≠ò„Åó„Åæ„Åó„Åü&quot;)
plt.show()
</code></pre>
<h3>„Ç≥„Éº„Éâ‰æã19: „Ç§„É≥„Çø„É©„ÇØ„ÉÜ„Ç£„Éñ3DÂèØË¶ñÂåñÔºàPlotlyÔºâ</h3>
<pre><code class="language-python">import plotly.express as px
import plotly.graph_objects as go
import umap

# 3Ê¨°ÂÖÉUMAP
reducer_3d = umap.UMAP(n_components=3, n_neighbors=15, min_dist=0.1, random_state=42)
cgcnn_umap_3d = reducer_3d.fit_transform(cgcnn_embeddings)

# „Éá„Éº„Çø„Éï„É¨„Éº„É†„ÅÆ‰ΩúÊàê
import pandas as pd

df_3d = pd.DataFrame({
    'UMAP1': cgcnn_umap_3d[:, 0],
    'UMAP2': cgcnn_umap_3d[:, 1],
    'UMAP3': cgcnn_umap_3d[:, 2],
    'Band_Gap': cgcnn_targets,
    'Material_ID': [f'Material_{i}' for i in range(len(cgcnn_targets))],
    'Cluster': cluster_labels
})

# „Ç§„É≥„Çø„É©„ÇØ„ÉÜ„Ç£„Éñ3D„Éó„É≠„ÉÉ„Éà
fig = px.scatter_3d(df_3d,
                    x='UMAP1', y='UMAP2', z='UMAP3',
                    color='Band_Gap',
                    size='Band_Gap',
                    hover_data=['Material_ID', 'Cluster'],
                    color_continuous_scale='Viridis',
                    title='Interactive 3D Visualization of CGCNN Embeddings')

fig.update_traces(marker=dict(line=dict(width=0.5, color='DarkSlateGrey')))

fig.update_layout(
    scene=dict(
        xaxis_title='UMAP 1',
        yaxis_title='UMAP 2',
        zaxis_title='UMAP 3',
        xaxis=dict(backgroundcolor=&quot;rgb(230, 230, 230)&quot;, gridcolor=&quot;white&quot;),
        yaxis=dict(backgroundcolor=&quot;rgb(230, 230, 230)&quot;, gridcolor=&quot;white&quot;),
        zaxis=dict(backgroundcolor=&quot;rgb(230, 230, 230)&quot;, gridcolor=&quot;white&quot;),
    ),
    width=1000,
    height=800,
    font=dict(size=12)
)

fig.write_html('cgcnn_embeddings_3d_interactive.html')
print(&quot;„Ç§„É≥„Çø„É©„ÇØ„ÉÜ„Ç£„Éñ3DÂèØË¶ñÂåñ„Çí cgcnn_embeddings_3d_interactive.html „Å´‰øùÂ≠ò„Åó„Åæ„Åó„Åü&quot;)
fig.show()
</code></pre>
<h3>„Ç≥„Éº„Éâ‰æã20: Âüã„ÇÅËæº„ÅøÂìÅË≥™„ÅÆÂÆöÈáèË©ï‰æ°</h3>
<pre><code class="language-python">from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score
import numpy as np

def evaluate_embedding_quality(embeddings, labels, targets):
    &quot;&quot;&quot;
    Âüã„ÇÅËæº„Åø„ÅÆÂìÅË≥™„ÇíË§áÊï∞„ÅÆÊåáÊ®ô„ÅßË©ï‰æ°

    Parameters:
    -----------
    embeddings : np.ndarray
        Âüã„ÇÅËæº„Åø„Éô„ÇØ„Éà„É´
    labels : np.ndarray
        „ÇØ„É©„Çπ„Çø„É©„Éô„É´
    targets : np.ndarray
        „Çø„Éº„Ç≤„ÉÉ„ÉàÂÄ§ÔºàÈÄ£Á∂öÂÄ§Ôºâ

    Returns:
    --------
    metrics : dict
        Ë©ï‰æ°ÊåáÊ®ô
    &quot;&quot;&quot;
    # „ÇØ„É©„Çπ„Çø„É™„É≥„Ç∞ÂìÅË≥™ÊåáÊ®ô
    silhouette = silhouette_score(embeddings, labels)
    davies_bouldin = davies_bouldin_score(embeddings, labels)
    calinski_harabasz = calinski_harabasz_score(embeddings, labels)

    # „Çø„Éº„Ç≤„ÉÉ„ÉàÂÄ§„Å®„ÅÆÁõ∏Èñ¢ÔºàËøëÂÇç‰øùÂ≠òÔºâ
    from sklearn.neighbors import NearestNeighbors

    k = 10
    nbrs_embedding = NearestNeighbors(n_neighbors=k+1).fit(embeddings)
    _, indices_emb = nbrs_embedding.kneighbors(embeddings)

    nbrs_target = NearestNeighbors(n_neighbors=k+1).fit(targets.reshape(-1, 1))
    _, indices_tgt = nbrs_target.kneighbors(targets.reshape(-1, 1))

    # ËøëÂÇç„ÅÆ‰∏ÄËá¥Áéá
    neighborhood_match = []
    for i in range(len(embeddings)):
        neighbors_emb = set(indices_emb[i, 1:])
        neighbors_tgt = set(indices_tgt[i, 1:])
        intersection = len(neighbors_emb &amp; neighbors_tgt)
        neighborhood_match.append(intersection / k)

    neighborhood_preservation = np.mean(neighborhood_match)

    metrics = {
        'silhouette_score': silhouette,
        'davies_bouldin_score': davies_bouldin,
        'calinski_harabasz_score': calinski_harabasz,
        'neighborhood_preservation': neighborhood_preservation
    }

    return metrics


# Ë©ï‰æ°ÂÆüË°å
metrics = evaluate_embedding_quality(cgcnn_embeddings, cluster_labels, cgcnn_targets)

print(&quot;CGCNNÂüã„ÇÅËæº„Åø„ÅÆÂìÅË≥™Ë©ï‰æ°:&quot;)
print(f&quot;  Silhouette Score: {metrics['silhouette_score']:.3f} (È´ò„ÅÑ„Åª„Å©ËâØ„ÅÑ)&quot;)
print(f&quot;  Davies-Bouldin Score: {metrics['davies_bouldin_score']:.3f} (‰Ωé„ÅÑ„Åª„Å©ËâØ„ÅÑ)&quot;)
print(f&quot;  Calinski-Harabasz Score: {metrics['calinski_harabasz_score']:.3f} (È´ò„ÅÑ„Åª„Å©ËâØ„ÅÑ)&quot;)
print(f&quot;  Neighborhood Preservation: {metrics['neighborhood_preservation']:.3f} (È´ò„ÅÑ„Åª„Å©ËâØ„ÅÑ)&quot;)

# Ë§áÊï∞„ÅÆ„ÇØ„É©„Çπ„ÇøÊï∞„ÅßË©ï‰æ°
k_range = range(2, 11)
silhouette_scores = []

for k in k_range:
    kmeans_k = KMeans(n_clusters=k, random_state=42, n_init=10)
    labels_k = kmeans_k.fit_predict(cgcnn_embeddings)
    silhouette_scores.append(silhouette_score(cgcnn_embeddings, labels_k))

# „Éó„É≠„ÉÉ„Éà
plt.figure(figsize=(10, 6))
plt.plot(list(k_range), silhouette_scores, marker='o', linewidth=2,
         markersize=8, color='darkblue')
plt.xlabel('Number of Clusters', fontsize=14, fontweight='bold')
plt.ylabel('Silhouette Score', fontsize=14, fontweight='bold')
plt.title('Silhouette Score vs Number of Clusters',
          fontsize=16, fontweight='bold')
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.savefig('cgcnn_silhouette_analysis.png', dpi=300, bbox_inches='tight')
print(&quot;\n„Ç∑„É´„Ç®„ÉÉ„Éà„Çπ„Ç≥„Ç¢ÂàÜÊûê„Çí cgcnn_silhouette_analysis.png „Å´‰øùÂ≠ò„Åó„Åæ„Åó„Åü&quot;)
plt.show()
</code></pre>
<p><strong>Âá∫Âäõ‰æã</strong>:</p>
<pre><code>CGCNNÂüã„ÇÅËæº„Åø„ÅÆÂìÅË≥™Ë©ï‰æ°:
  Silhouette Score: 0.342 (È´ò„ÅÑ„Åª„Å©ËâØ„ÅÑ)
  Davies-Bouldin Score: 1.234 (‰Ωé„ÅÑ„Åª„Å©ËâØ„ÅÑ)
  Calinski-Harabasz Score: 456.789 (È´ò„ÅÑ„Åª„Å©ËâØ„ÅÑ)
  Neighborhood Preservation: 0.675 (È´ò„ÅÑ„Åª„Å©ËâØ„ÅÑ)

„Ç∑„É´„Ç®„ÉÉ„Éà„Çπ„Ç≥„Ç¢ÂàÜÊûê„Çí cgcnn_silhouette_analysis.png „Å´‰øùÂ≠ò„Åó„Åæ„Åó„Åü
</code></pre>
<h2>3.7 „Åæ„Å®„ÇÅ</h2>
<p>Êú¨Á´†„Åß„ÅØ„ÄÅGNN„Å´„Çà„ÇãÊùêÊñôË°®ÁèæÂ≠¶Áøí„Å´„Å§„ÅÑ„Å¶Â≠¶„Å≥„Åæ„Åó„ÅüÔºö</p>
<h3>‰∏ªË¶Å„Å™GNN„É¢„Éá„É´</h3>
<table>
<thead>
<tr>
<th>„É¢„Éá„É´</th>
<th>ÁâπÂæ¥</th>
<th>Âà©ÁÇπ</th>
<th>ÈÅ©Áî®Â†¥Èù¢</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>CGCNN</strong></td>
<td>ÁµêÊô∂ÊßãÈÄ†ÁâπÂåñ</td>
<td>Áâ©ÁêÜÁöÑËß£ÈáàÊÄß</td>
<td>ÁµêÊô∂ÊùêÊñôÁâπÊÄß‰∫àÊ∏¨</td>
</tr>
<tr>
<td><strong>MEGNet</strong></td>
<td>„Ç∞„É≠„Éº„Éê„É´Áä∂ÊÖã</td>
<td>ÊüîËªüÊÄß„ÄÅË°®ÁèæÂäõ</td>
<td>Â§öÊßò„Å™ÊùêÊñô„Ç∑„Çπ„ÉÜ„É†</td>
</tr>
<tr>
<td><strong>SchNet</strong></td>
<td>ÈÄ£Á∂ö„Éï„Ç£„É´„Çø</td>
<td>Áâ©ÁêÜÁöÑÂ¶•ÂΩìÊÄß</td>
<td>ÂàÜÂ≠ê„ÉªÂéüÂ≠êÁ≥ª</td>
</tr>
</tbody>
</table>
<h3>ÂÆüË£Ö„Åó„Åü„Ç≥„Éº„Éâ</h3>
<table>
<thead>
<tr>
<th>„Ç≥„Éº„Éâ‰æã</th>
<th>ÂÜÖÂÆπ</th>
<th>‰∏ª„Å™Ê©üËÉΩ</th>
</tr>
</thead>
<tbody>
<tr>
<td>‰æã1-4</td>
<td>„Ç∞„É©„Éï„Éá„Éº„ÇøÊ∫ñÂÇô</td>
<td>ÊßãÈÄ†‚Üí„Ç∞„É©„ÉïÂ§âÊèõ</td>
</tr>
<tr>
<td>‰æã5-8</td>
<td>CGCNNÂÆüË£Ö</td>
<td>„É¢„Éá„É´ÊßãÁØâ„ÄÅÂ≠¶Áøí„ÄÅÂüã„ÇÅËæº„ÅøÊäΩÂá∫</td>
</tr>
<tr>
<td>‰æã9-10</td>
<td>MEGNetÂÆüË£Ö</td>
<td>„Ç∞„É≠„Éº„Éê„É´Áä∂ÊÖã„ÇíÂê´„ÇÄGNN</td>
</tr>
<tr>
<td>‰æã11-12</td>
<td>SchNetÂÆüË£Ö</td>
<td>ÈÄ£Á∂ö„Éï„Ç£„É´„ÇøÁï≥„ÅøËæº„Åø</td>
</tr>
<tr>
<td>‰æã13-20</td>
<td>Âüã„ÇÅËæº„ÅøÂèØË¶ñÂåñ„ÉªÂàÜÊûê</td>
<td>UMAP„ÄÅt-SNE„ÄÅ„ÇØ„É©„Çπ„Çø„É™„É≥„Ç∞„ÄÅË©ï‰æ°</td>
</tr>
</tbody>
</table>
<h3>„Éô„Çπ„Éà„Éó„É©„ÇØ„ÉÜ„Ç£„Çπ</h3>
<ol>
<li><strong>„Éá„Éº„ÇøÊ∫ñÂÇô</strong>: ÈÅ©Âàá„Å™„Ç´„ÉÉ„Éà„Ç™„ÉïË∑ùÈõ¢„ÄÅÁâπÂæ¥„Ç®„É≥„Ç≥„Éº„Éá„Ç£„É≥„Ç∞</li>
<li><strong>„É¢„Éá„É´ÈÅ∏Êäû</strong>: „Çø„Çπ„ÇØ„Å´Âøú„Åò„Åü„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£</li>
<li><strong>„Éè„Ç§„Éë„Éº„Éë„É©„É°„Éº„Çø</strong>: hidden_dim„ÄÅnum_layers„ÄÅlearning_rate„ÅÆË™øÊï¥</li>
<li><strong>Ë©ï‰æ°</strong>: ‰∫àÊ∏¨ÊÄßËÉΩ„Å†„Åë„Åß„Å™„ÅèÂüã„ÇÅËæº„ÅøÂìÅË≥™„ÇÇË©ï‰æ°</li>
</ol>
<h3>Ê¨°Á´†„Å∏„ÅÆÂ±ïÊúõ</h3>
<p>Á¨¨4Á´†„Åß„ÅØ„ÄÅ„Åì„Çå„Åæ„ÅßÂ≠¶„Çì„Å†Ê¨°ÂÖÉÂâäÊ∏õÊâãÊ≥ïÔºàÁ¨¨2Á´†Ôºâ„Å®GNNË°®ÁèæÂ≠¶ÁøíÔºàÁ¨¨3Á´†Ôºâ„ÇíÁµÑ„ÅøÂêà„Çè„Åõ„ÅüÂÆüË∑µÁöÑ„Å™ÊùêÊñô„Éû„ÉÉ„Éî„É≥„Ç∞„Ç∑„Çπ„ÉÜ„É†„ÇíÊßãÁØâ„Åó„Åæ„Åô„ÄÇMaterials Project API„Åã„ÇâÂÆü„Éá„Éº„Çø„ÇíÂèñÂæó„Åó„ÄÅ„Ç®„É≥„Éâ„ÉÑ„Éº„Ç®„É≥„Éâ„ÅÆ„Éë„Ç§„Éó„É©„Ç§„É≥„ÇíÂÆüË£Ö„Åó„Åæ„Åô„ÄÇ</p>
<hr />
<p><strong>ÂâçÁ´†</strong>: <a href="chapter-2.html">Á¨¨2Á´†ÔºöÊ¨°ÂÖÉÂâäÊ∏õÊâãÊ≥ï„Å´„Çà„ÇãÊùêÊñôÁ©∫Èñì„ÅÆ„Éû„ÉÉ„Éî„É≥„Ç∞</a></p>
<p><strong>Ê¨°Á´†</strong>: <a href="chapter-4.html">Á¨¨4Á´†ÔºöÂÆüË∑µÁ∑® - GNN + Ê¨°ÂÖÉÂâäÊ∏õ„Å´„Çà„ÇãÊùêÊñô„Éû„ÉÉ„Éî„É≥„Ç∞</a></p>
<p><strong>„Ç∑„É™„Éº„Ç∫„Éà„ÉÉ„Éó</strong>: <a href="index.html">ÊùêÊñôÁâπÊÄß„Éû„ÉÉ„Éî„É≥„Ç∞ÂÖ•ÈñÄ</a></p><div class="navigation">
    <a href="index.html" class="nav-button">„Ç∑„É™„Éº„Ç∫ÁõÆÊ¨°„Å´Êàª„Çã</a>
    <a href="chapter-4.html" class="nav-button">Ê¨°„ÅÆÁ´† ‚Üí</a>
</div>
    </main>

    <footer>
        <p><strong>‰ΩúÊàêËÄÖ</strong>: AI Terakoya Content Team</p>
        <p><strong>Áõ£‰øÆ</strong>: Dr. Yusuke HashimotoÔºàÊù±ÂåóÂ§ßÂ≠¶Ôºâ</p>
        <p><strong>„Éê„Éº„Ç∏„Éß„É≥</strong>: 1.0 | <strong>‰ΩúÊàêÊó•</strong>: 2025-10-17</p>
        <p><strong>„É©„Ç§„Çª„É≥„Çπ</strong>: Creative Commons BY 4.0</p>
        <p>¬© 2025 AI Terakoya. All rights reserved.</p>
    </footer>
</body>
</html>
