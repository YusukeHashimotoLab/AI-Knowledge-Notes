<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
<meta content="Chapter - AI Terakoya" name="description"/>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Chapter - AI Terakoya</title>

    <style>
        :root {
            --color-primary: #2c3e50;
            --color-primary-dark: #1a252f;
            --color-accent: #7b2cbf;
            --color-accent-light: #9d4edd;
            --color-text: #2d3748;
            --color-text-light: #4a5568;
            --color-bg: #ffffff;
            --color-bg-alt: #f7fafc;
            --color-border: #e2e8f0;
            --color-code-bg: #f8f9fa;
            --color-link: #3182ce;
            --color-link-hover: #2c5aa0;

            --spacing-xs: 0.5rem;
            --spacing-sm: 1rem;
            --spacing-md: 1.5rem;
            --spacing-lg: 2rem;
            --spacing-xl: 3rem;

            --font-body: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            --font-mono: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;

            --border-radius: 8px;
            --box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: var(--font-body);
            line-height: 1.7;
            color: var(--color-text);
            background-color: var(--color-bg);
            font-size: 16px;
        }

        header {
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            padding: var(--spacing-xl) var(--spacing-md);
            margin-bottom: var(--spacing-xl);
            box-shadow: var(--box-shadow);
        }

        .header-content {
            max-width: 900px;
            margin: 0 auto;
        }

        h1 {
            font-size: 2rem;
            font-weight: 700;
            margin-bottom: var(--spacing-sm);
            line-height: 1.2;
        }

        .subtitle {
            font-size: 1.1rem;
            opacity: 0.95;
            font-weight: 400;
            margin-bottom: var(--spacing-md);
        }

        .meta {
            display: flex;
            flex-wrap: wrap;
            gap: var(--spacing-md);
            font-size: 0.9rem;
            opacity: 0.9;
        }

        .meta-item {
            display: flex;
            align-items: center;
            gap: 0.3rem;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 0 var(--spacing-md) var(--spacing-xl);
        }

        h2 {
            font-size: 1.75rem;
            color: var(--color-primary);
            margin-top: var(--spacing-xl);
            margin-bottom: var(--spacing-md);
            padding-bottom: var(--spacing-xs);
            border-bottom: 3px solid var(--color-accent);
        }

        h3 {
            font-size: 1.4rem;
            color: var(--color-primary);
            margin-top: var(--spacing-lg);
            margin-bottom: var(--spacing-sm);
        }

        h4 {
            font-size: 1.1rem;
            color: var(--color-primary-dark);
            margin-top: var(--spacing-md);
            margin-bottom: var(--spacing-sm);
        }

        p {
            margin-bottom: var(--spacing-md);
            color: var(--color-text);
        }

        a {
            color: var(--color-link);
            text-decoration: none;
            transition: color 0.2s;
        }

        a:hover {
            color: var(--color-link-hover);
            text-decoration: underline;
        }

        ul, ol {
            margin-left: var(--spacing-lg);
            margin-bottom: var(--spacing-md);
        }

        li {
            margin-bottom: var(--spacing-xs);
            color: var(--color-text);
        }

        pre {
            background-color: var(--color-code-bg);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            overflow-x: auto;
            margin-bottom: var(--spacing-md);
            font-family: var(--font-mono);
            font-size: 0.9rem;
            line-height: 1.5;
        }

        code {
            font-family: var(--font-mono);
            font-size: 0.9em;
            background-color: var(--color-code-bg);
            padding: 0.2em 0.4em;
            border-radius: 3px;
        }

        pre code {
            background-color: transparent;
            padding: 0;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: var(--spacing-md);
            font-size: 0.95rem;
        }

        th, td {
            border: 1px solid var(--color-border);
            padding: var(--spacing-sm);
            text-align: left;
        }

        th {
            background-color: var(--color-bg-alt);
            font-weight: 600;
            color: var(--color-primary);
        }

        blockquote {
            border-left: 4px solid var(--color-accent);
            padding-left: var(--spacing-md);
            margin: var(--spacing-md) 0;
            color: var(--color-text-light);
            font-style: italic;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        .mermaid {
            text-align: center;
            margin: var(--spacing-lg) 0;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        details {
            background-color: var(--color-bg-alt);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            margin-bottom: var(--spacing-md);
        }

        summary {
            cursor: pointer;
            font-weight: 600;
            color: var(--color-primary);
            user-select: none;
            padding: var(--spacing-xs);
            margin: calc(-1 * var(--spacing-md));
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        summary:hover {
            background-color: rgba(123, 44, 191, 0.1);
        }

        details[open] summary {
            margin-bottom: var(--spacing-md);
            border-bottom: 1px solid var(--color-border);
        }

        .learning-objectives {
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
            padding: var(--spacing-lg);
            border-radius: var(--border-radius);
            border-left: 4px solid var(--color-accent);
            margin-bottom: var(--spacing-xl);
        }

        .learning-objectives h2 {
            margin-top: 0;
            border-bottom: none;
        }

        .navigation {
            display: flex;
            justify-content: space-between;
            gap: var(--spacing-md);
            margin: var(--spacing-xl) 0;
            padding-top: var(--spacing-lg);
            border-top: 2px solid var(--color-border);
        }

        .nav-button {
            flex: 1;
            padding: var(--spacing-md);
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            border-radius: var(--border-radius);
            text-align: center;
            font-weight: 600;
            transition: transform 0.2s, box-shadow 0.2s;
            box-shadow: var(--box-shadow);
        }

        .nav-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
            text-decoration: none;
        }

        footer {
            margin-top: var(--spacing-xl);
            padding: var(--spacing-lg) var(--spacing-md);
            background-color: var(--color-bg-alt);
            border-top: 1px solid var(--color-border);
            text-align: center;
            font-size: 0.9rem;
            color: var(--color-text-light);
        }
        .disclaimer {
            max-width: 900px;
            margin: 2rem auto;
            padding: 1.5rem;
            background: #f8f9fa;
            border-left: 4px solid #6c757d;
            border-radius: 4px;
        }

        .disclaimer h3 {
            color: #495057;
            margin-bottom: 1rem;
            font-size: 1.1rem;
        }

        .disclaimer ul {
            list-style: none;
            padding-left: 0;
        }

        .disclaimer li {
            padding: 0.5rem 0;
            padding-left: 1.5rem;
            position: relative;
            font-size: 0.9rem;
            color: #6c757d;
            line-height: 1.6;
        }

        .disclaimer li::before {
            content: "âš ï¸";
            position: absolute;
            left: 0;
        }


        @media (max-width: 768px) {
            h1 {
                font-size: 1.5rem;
            }

            h2 {
                font-size: 1.4rem;
            }

            h3 {
                font-size: 1.2rem;
            }

            .meta {
                font-size: 0.85rem;
            }

            .navigation {
                flex-direction: column;
            }

            table {
                font-size: 0.85rem;
            }

            th, td {
                padding: var(--spacing-xs);
            }
        }
    
        
    
        /* Breadcrumb styles */
        .breadcrumb {
            background: #f7fafc;
            padding: 0.75rem 1rem;
            border-bottom: 1px solid #e2e8f0;
            font-size: 0.9rem;
        }

        .breadcrumb-content {
            max-width: 900px;
            margin: 0 auto;
            display: flex;
            align-items: center;
            flex-wrap: wrap;
            gap: 0.5rem;
        }

        .breadcrumb a {
            color: #667eea;
            text-decoration: none;
            transition: color 0.2s;
        }

        .breadcrumb a:hover {
            color: #764ba2;
            text-decoration: underline;
        }

        .breadcrumb-separator {
            color: #a0aec0;
            margin: 0 0.25rem;
        }

        .breadcrumb-current {
            color: #4a5568;
            font-weight: 500;
        }
    </style>

    <script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
    <script>
        mermaid.initialize({ startOnLoad: true, theme: 'default', securityLevel: 'strict' });
    </script>

    <!-- MathJax for LaTeX equation rendering -->
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\(', '\)']],
                displayMath: [['$$', '$$'], ['\[', '\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
                ignoreHtmlClass: 'mermaid'
            }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" async></script>

    <style>
        /* Locale Switcher Styles */
        .locale-switcher {
            display: flex;
            align-items: center;
            gap: 0.5rem;
            padding: 0.5rem 1rem;
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
            border-radius: 6px;
            font-size: 0.9rem;
            margin-bottom: 1rem;
            box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);
        }

        .current-locale {
            font-weight: 600;
            color: #7b2cbf;
            display: flex;
            align-items: center;
            gap: 0.25rem;
        }

        .locale-separator {
            color: #adb5bd;
            font-weight: 300;
        }

        .locale-link {
            color: #f093fb;
            text-decoration: none;
            font-weight: 500;
            transition: all 0.2s ease;
            display: flex;
            align-items: center;
            gap: 0.25rem;
            padding: 0.2rem 0.5rem;
            border-radius: 4px;
        }

        .locale-link:hover {
            background: rgba(240, 147, 251, 0.1);
            color: #d07be8;
            transform: translateY(-1px);
        }

        .locale-meta {
            color: #868e96;
            font-size: 0.85rem;
            font-style: italic;
            margin-left: auto;
        }

        @media (max-width: 768px) {
            .locale-switcher {
                font-size: 0.85rem;
                padding: 0.4rem 0.8rem;
            }
            .locale-meta {
                display: none;
            }
        }
    </style>
</head>
<body>
            <div class="locale-switcher">
<span class="current-locale">ğŸŒ JP</span>
<span class="locale-separator">|</span>
<a href="../../../en/MI/materials-property-mapping-introduction/chapter-4.html" class="locale-link">ğŸ‡¬ğŸ‡§ EN</a>
<span class="locale-separator">|</span>
<span class="locale-meta">Last sync: 2025-11-16</span>
</div>
<nav class="breadcrumb">
        <div class="breadcrumb-content">
            <a href="../../index.html">AIå¯ºå­å±‹ãƒˆãƒƒãƒ—</a><span class="breadcrumb-separator">â€º</span><a href="../../MI/index.html">ãƒãƒ†ãƒªã‚¢ãƒ«ã‚ºãƒ»ã‚¤ãƒ³ãƒ•ã‚©ãƒãƒ†ã‚£ã‚¯ã‚¹</a><span class="breadcrumb-separator">â€º</span><a href="../../MI/materials-property-mapping-introduction/index.html">Materials Property Mapping</a><span class="breadcrumb-separator">â€º</span><span class="breadcrumb-current">Chapter 4</span>
        </div>
    </nav>

        <header>
        <div class="header-content">
            <h1>Chapter</h1>
            <p class="subtitle"></p>
            <div class="meta">
                <span class="meta-item">ğŸ“– èª­äº†æ™‚é–“: 20-25åˆ†</span>
                <span class="meta-item">ğŸ“Š é›£æ˜“åº¦: åˆç´š</span>
                <span class="meta-item">ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹: 0å€‹</span>
                <span class="meta-item">ğŸ“ æ¼”ç¿’å•é¡Œ: 0å•</span>
            </div>
        </div>
    </header>

    <main class="container">
<h1>ç¬¬4ç« ï¼šå®Ÿè·µç·¨ - GNN + æ¬¡å…ƒå‰Šæ¸›ã«ã‚ˆã‚‹ææ–™ãƒãƒƒãƒ”ãƒ³ã‚°</h1>
<h2>æ¦‚è¦</h2>
<p>æœ¬ç« ã§ã¯ã€ã“ã‚Œã¾ã§å­¦ã‚“ã GNNã«ã‚ˆã‚‹è¡¨ç¾å­¦ç¿’ï¼ˆç¬¬3ç« ï¼‰ã¨æ¬¡å…ƒå‰Šæ¸›æ‰‹æ³•ï¼ˆç¬¬2ç« ï¼‰ã‚’çµ„ã¿åˆã‚ã›ãŸã€å®Ÿè·µçš„ãªææ–™ç©ºé–“ãƒãƒƒãƒ”ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ã—ã¾ã™ã€‚Materials Project APIã‹ã‚‰å®Ÿãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã€ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å®Ÿè£…ã—ã¾ã™ã€‚</p>
<h3>å­¦ç¿’ç›®æ¨™</h3>
<ul>
<li>Materials Project APIã‚’ç”¨ã„ãŸå®Ÿãƒ‡ãƒ¼ã‚¿åé›†ãŒã§ãã‚‹</li>
<li>GNNå­¦ç¿’ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’æ§‹ç¯‰ã§ãã‚‹</li>
<li>å­¦ç¿’æ¸ˆã¿GNNåŸ‹ã‚è¾¼ã¿ã‚’æ¬¡å…ƒå‰Šæ¸›ã§å¯è¦–åŒ–ã§ãã‚‹</li>
<li>ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªææ–™æ¢ç´¢ã‚·ã‚¹ãƒ†ãƒ ã‚’å®Ÿè£…ã§ãã‚‹</li>
<li>å®Ÿéš›ã®ææ–™è¨­è¨ˆã‚¿ã‚¹ã‚¯ã«å¿œç”¨ã§ãã‚‹</li>
</ul>
<h2>4.1 ç’°å¢ƒæ§‹ç¯‰ã¨ãƒ‡ãƒ¼ã‚¿åé›†</h2>
<h3>ã‚³ãƒ¼ãƒ‰ä¾‹1: å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«</h3>
<pre><code class="language-python"># å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼ˆåˆå›ã®ã¿å®Ÿè¡Œï¼‰
&quot;&quot;&quot;
!pip install pymatgen
!pip install mp-api
!pip install torch torchvision torchaudio
!pip install torch-geometric
!pip install torch-scatter torch-sparse torch-cluster torch-spline-conv -f https://data.pyg.org/whl/torch-2.0.0+cpu.html
!pip install umap-learn
!pip install plotly
!pip install bokeh
!pip install scikit-learn
!pip install pandas matplotlib seaborn
!pip install tqdm
&quot;&quot;&quot;

# ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
import warnings
warnings.filterwarnings('ignore')

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch_geometric.data import Data, Dataset, DataLoader

import umap
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.cluster import KMeans

from tqdm import tqdm
import json
import pickle
from pathlib import Path

print(&quot;All libraries imported successfully!&quot;)
print(f&quot;PyTorch version: {torch.__version__}&quot;)
print(f&quot;CUDA available: {torch.cuda.is_available()}&quot;)
</code></pre>
<h3>ã‚³ãƒ¼ãƒ‰ä¾‹2: Materials Project APIã®è¨­å®šã¨ãƒ‡ãƒ¼ã‚¿å–å¾—</h3>
<pre><code class="language-python">from mp_api.client import MPRester
from pymatgen.core import Structure
import warnings
warnings.filterwarnings('ignore')

# APIã‚­ãƒ¼ã®è¨­å®šï¼ˆç’°å¢ƒå¤‰æ•°ã¾ãŸã¯ç›´æ¥æŒ‡å®šï¼‰
# MP_API_KEY = &quot;your_api_key_here&quot;  # https://next-gen.materialsproject.org/api ã§å–å¾—
# æ³¨: å®Ÿéš›ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã¯ç’°å¢ƒå¤‰æ•°ã‹ã‚‰èª­ã¿è¾¼ã‚€ã“ã¨ã‚’æ¨å¥¨

def fetch_materials_data(api_key, criteria, properties, max_materials=1000):
    &quot;&quot;&quot;
    Materials Project APIã‹ã‚‰ææ–™ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—

    Parameters:
    -----------
    api_key : str
        Materials Project APIã‚­ãƒ¼
    criteria : dict
        æ¤œç´¢æ¡ä»¶
    properties : list
        å–å¾—ã™ã‚‹ç‰¹æ€§ã®ãƒªã‚¹ãƒˆ
    max_materials : int
        å–å¾—ã™ã‚‹æœ€å¤§ææ–™æ•°

    Returns:
    --------
    materials_df : pd.DataFrame
        ææ–™ãƒ‡ãƒ¼ã‚¿
    structures : list
        çµæ™¶æ§‹é€ ã®ãƒªã‚¹ãƒˆ
    &quot;&quot;&quot;
    with MPRester(api_key) as mpr:
        # ãƒ‡ãƒ¼ã‚¿ã®å–å¾—
        docs = mpr.materials.summary.search(
            **criteria,
            fields=properties,
            num_chunks=10,
            chunk_size=100
        )

        # æœ€å¤§æ•°ã«åˆ¶é™
        docs = docs[:max_materials]

        print(f&quot;å–å¾—ã—ãŸææ–™æ•°: {len(docs)}&quot;)

        # DataFrameã«å¤‰æ›
        data_dict = {prop: [] for prop in properties}
        data_dict['material_id'] = []
        data_dict['formula'] = []
        structures = []

        for doc in tqdm(docs, desc=&quot;ãƒ‡ãƒ¼ã‚¿å‡¦ç†ä¸­&quot;):
            try:
                data_dict['material_id'].append(doc.material_id)
                data_dict['formula'].append(str(doc.formula_pretty))

                for prop in properties:
                    if prop == 'structure':
                        structures.append(doc.structure)
                    else:
                        value = getattr(doc, prop, None)
                        data_dict[prop].append(value)

            except Exception as e:
                print(f&quot;Error processing {doc.material_id}: {e}&quot;)
                continue

        materials_df = pd.DataFrame(data_dict)
        materials_df = materials_df.dropna()  # æ¬ æå€¤ã‚’å«ã‚€è¡Œã‚’å‰Šé™¤

        print(f&quot;æœ‰åŠ¹ãªææ–™æ•°: {len(materials_df)}&quot;)

        return materials_df, structures


# ä½¿ç”¨ä¾‹ï¼ˆãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã§ä»£æ›¿ - å®Ÿéš›ã®APIã‚­ãƒ¼ãŒã‚ã‚‹å ´åˆã¯ã‚³ãƒ¡ãƒ³ãƒˆè§£é™¤ï¼‰
# criteria = {
#     &quot;band_gap&quot;: (0.5, 5.0),  # ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ— 0.5-5.0 eV
#     &quot;is_stable&quot;: True,       # å®‰å®šãªææ–™ã®ã¿
#     &quot;nelements&quot;: (2, 3)      # 2-3å…ƒç´ ç³»
# }
#
# properties = [
#     &quot;material_id&quot;, &quot;formula_pretty&quot;, &quot;structure&quot;,
#     &quot;band_gap&quot;, &quot;formation_energy_per_atom&quot;, &quot;density&quot;,
#     &quot;energy_above_hull&quot;, &quot;volume&quot;
# ]
#
# materials_df, structures = fetch_materials_data(
#     api_key=MP_API_KEY,
#     criteria=criteria,
#     properties=properties,
#     max_materials=1000
# )

# ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆï¼ˆAPIã‚­ãƒ¼ãŒãªã„å ´åˆï¼‰
print(&quot;\nãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã¾ã™...&quot;)
from pymatgen.core import Lattice, Structure

np.random.seed(42)
n_materials = 1000

materials_df = pd.DataFrame({
    'material_id': [f'mp-{1000+i}' for i in range(n_materials)],
    'formula': [f'Material_{i}' for i in range(n_materials)],
    'band_gap': np.random.exponential(2.0, n_materials),
    'formation_energy_per_atom': np.random.normal(-1.5, 0.8, n_materials),
    'density': np.random.normal(5.0, 1.5, n_materials).clip(0.1),
    'energy_above_hull': np.random.exponential(0.05, n_materials),
    'volume': np.random.normal(50, 15, n_materials).clip(10)
})

# ãƒ€ãƒŸãƒ¼çµæ™¶æ§‹é€ ã®ç”Ÿæˆ
structures = []
for i in range(n_materials):
    lattice = Lattice.cubic(4.0 + np.random.rand())
    n_atoms = np.random.randint(2, 8)
    species = np.random.choice(['Li', 'Na', 'K', 'O', 'S', 'Cl', 'F'], n_atoms)
    coords = np.random.rand(n_atoms, 3)
    structure = Structure(lattice, species, coords)
    structures.append(structure)

print(f&quot;ãƒ€ãƒŸãƒ¼ææ–™ãƒ‡ãƒ¼ã‚¿ã‚’ {n_materials}å€‹ ç”Ÿæˆã—ã¾ã—ãŸ&quot;)
print(&quot;\nææ–™ãƒ‡ãƒ¼ã‚¿ã®æœ€åˆã®5è¡Œ:&quot;)
print(materials_df.head())
</code></pre>
<p><strong>å‡ºåŠ›ä¾‹</strong>:</p>
<pre><code>ãƒ€ãƒŸãƒ¼ææ–™ãƒ‡ãƒ¼ã‚¿ã‚’ 1000å€‹ ç”Ÿæˆã—ã¾ã—ãŸ

ææ–™ãƒ‡ãƒ¼ã‚¿ã®æœ€åˆã®5è¡Œ:
  material_id      formula  band_gap  formation_energy_per_atom  density  energy_above_hull  volume
0     mp-1000  Material_0  1.234567                  -1.678901    4.567             0.012345  45.678
1     mp-1001  Material_1  2.345678                  -1.234567    5.678             0.023456  50.789
2     mp-1002  Material_2  0.987654                  -2.012345    3.456             0.001234  48.901
3     mp-1003  Material_3  3.456789                  -0.987654    6.789             0.034567  52.345
4     mp-1004  Material_4  1.876543                  -1.456789    4.890             0.009876  47.234
</code></pre>
<h3>ã‚³ãƒ¼ãƒ‰ä¾‹3: ãƒ‡ãƒ¼ã‚¿ã®æ¢ç´¢çš„åˆ†æ</h3>
<pre><code class="language-python">import matplotlib.pyplot as plt
import seaborn as sns

# åŸºæœ¬çµ±è¨ˆé‡
print(&quot;ææ–™ãƒ‡ãƒ¼ã‚¿ã®åŸºæœ¬çµ±è¨ˆé‡:&quot;)
print(materials_df.describe())

# ç‰¹æ€§ã®åˆ†å¸ƒ
fig, axes = plt.subplots(2, 3, figsize=(18, 12))
axes = axes.ravel()

properties_to_plot = [
    'band_gap', 'formation_energy_per_atom', 'density',
    'energy_above_hull', 'volume'
]

for idx, prop in enumerate(properties_to_plot):
    axes[idx].hist(materials_df[prop], bins=50, alpha=0.7,
                   edgecolor='black', color='steelblue')
    axes[idx].set_xlabel(prop.replace('_', ' ').title(), fontsize=12, fontweight='bold')
    axes[idx].set_ylabel('Frequency', fontsize=12, fontweight='bold')
    axes[idx].set_title(f'Distribution of {prop.replace(&quot;_&quot;, &quot; &quot;).title()}',
                        fontsize=14, fontweight='bold')
    axes[idx].grid(True, alpha=0.3)

# æœ€å¾Œã®ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆã‚’éè¡¨ç¤º
axes[-1].axis('off')

plt.tight_layout()
plt.savefig('materials_data_distributions.png', dpi=300, bbox_inches='tight')
print(&quot;\nç‰¹æ€§åˆ†å¸ƒã‚’ materials_data_distributions.png ã«ä¿å­˜ã—ã¾ã—ãŸ&quot;)
plt.show()

# ç›¸é–¢è¡Œåˆ—
correlation_matrix = materials_df[properties_to_plot].corr()

plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, fmt='.3f', cmap='RdBu_r',
            center=0, square=True, linewidths=1, cbar_kws={&quot;shrink&quot;: 0.8})
plt.title('Correlation Matrix of Material Properties',
          fontsize=16, fontweight='bold', pad=20)
plt.tight_layout()
plt.savefig('materials_correlation_matrix.png', dpi=300, bbox_inches='tight')
print(&quot;ç›¸é–¢è¡Œåˆ—ã‚’ materials_correlation_matrix.png ã«ä¿å­˜ã—ã¾ã—ãŸ&quot;)
plt.show()
</code></pre>
<h2>4.2 ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æ§‹ç¯‰</h2>
<h3>ã‚³ãƒ¼ãƒ‰ä¾‹4: çµæ™¶æ§‹é€ ã‹ã‚‰ã‚°ãƒ©ãƒ•ã¸ã®å¤‰æ›ï¼ˆæœ€é©åŒ–ç‰ˆï¼‰</h3>
<pre><code class="language-python">import torch
from torch_geometric.data import Data
from pymatgen.core import Structure
from pymatgen.core.periodic_table import Element
import numpy as np

class MaterialGraphConverter:
    &quot;&quot;&quot;çµæ™¶æ§‹é€ ã‚’ã‚°ãƒ©ãƒ•ã«å¤‰æ›ã™ã‚‹ã‚¯ãƒ©ã‚¹&quot;&quot;&quot;

    def __init__(self, cutoff=5.0, max_neighbors=12):
        self.cutoff = cutoff
        self.max_neighbors = max_neighbors

        # åŸå­ç‰¹æ€§ã®å®šç¾©ï¼ˆå…ƒç´ è¨˜å· â†’ ç‰¹å¾´ãƒ™ã‚¯ãƒˆãƒ«ï¼‰
        self._build_atom_features()

    def _build_atom_features(self):
        &quot;&quot;&quot;åŸå­ç‰¹æ€§è¾æ›¸ã‚’æ§‹ç¯‰&quot;&quot;&quot;
        # ä¸»è¦ãªå…ƒç´ ã®ç‰¹æ€§ã‚’äº‹å‰è¨ˆç®—
        common_elements = [
            'H', 'He', 'Li', 'Be', 'B', 'C', 'N', 'O', 'F', 'Ne',
            'Na', 'Mg', 'Al', 'Si', 'P', 'S', 'Cl', 'Ar', 'K', 'Ca',
            'Sc', 'Ti', 'V', 'Cr', 'Mn', 'Fe', 'Co', 'Ni', 'Cu', 'Zn',
            'Ga', 'Ge', 'As', 'Se', 'Br', 'Kr', 'Rb', 'Sr', 'Y', 'Zr'
        ]

        self.atom_features = {}

        for symbol in common_elements:
            try:
                element = Element(symbol)

                features = [
                    element.Z / 100.0,  # æ­£è¦åŒ–ã•ã‚ŒãŸåŸå­ç•ªå·
                    element.atomic_mass / 200.0,  # æ­£è¦åŒ–ã•ã‚ŒãŸåŸå­é‡
                    element.X if element.X is not None else 0.0,  # é›»æ°—é™°æ€§åº¦
                    element.atomic_radius if element.atomic_radius is not None else 0.0,  # åŸå­åŠå¾„
                    element.group if element.group is not None else 0.0,  # æ—
                    element.row if element.row is not None else 0.0,  # å‘¨æœŸ
                ]

                self.atom_features[symbol] = features

            except Exception as e:
                print(f&quot;Warning: Could not process element {symbol}: {e}&quot;)
                self.atom_features[symbol] = [0.0] * 6

    def get_atom_features(self, species):
        &quot;&quot;&quot;å…ƒç´ è¨˜å·ã‹ã‚‰ç‰¹å¾´ãƒ™ã‚¯ãƒˆãƒ«ã‚’å–å¾—&quot;&quot;&quot;
        symbol = str(species)
        if symbol in self.atom_features:
            return self.atom_features[symbol]
        else:
            # æœªçŸ¥ã®å…ƒç´ ã¯ã‚¼ãƒ­ãƒ™ã‚¯ãƒˆãƒ«
            return [0.0] * 6

    def structure_to_graph(self, structure, target=None):
        &quot;&quot;&quot;
        pymatgen Structureã‚’PyTorch Geometric Dataã«å¤‰æ›

        Parameters:
        -----------
        structure : pymatgen.Structure
            çµæ™¶æ§‹é€ 
        target : float, optional
            ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå€¤ï¼ˆç‰¹æ€§äºˆæ¸¬ç”¨ï¼‰

        Returns:
        --------
        data : torch_geometric.data.Data
            ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿
        &quot;&quot;&quot;
        # ãƒãƒ¼ãƒ‰ç‰¹å¾´
        node_features = []
        for site in structure:
            features = self.get_atom_features(site.specie)
            node_features.append(features)

        node_features = torch.tensor(node_features, dtype=torch.float)

        # ã‚¨ãƒƒã‚¸ã®æ§‹ç¯‰
        all_neighbors = structure.get_all_neighbors(self.cutoff)
        edge_index = []
        edge_attr = []

        for i, neighbors in enumerate(all_neighbors):
            # è·é›¢ã§ã‚½ãƒ¼ãƒˆã—ã¦è¿‘ã„é †ã«max_neighborså€‹ã¾ã§
            neighbors = sorted(neighbors, key=lambda x: x.nn_distance)[:self.max_neighbors]

            for neighbor in neighbors:
                j = neighbor.index
                distance = neighbor.nn_distance

                edge_index.append([i, j])
                edge_attr.append([distance])

        # ã‚¨ãƒƒã‚¸ãŒãªã„å ´åˆã®å‡¦ç†
        if len(edge_index) == 0:
            edge_index = torch.zeros((2, 0), dtype=torch.long)
            edge_attr = torch.zeros((0, 1), dtype=torch.float)
        else:
            edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()
            edge_attr = torch.tensor(edge_attr, dtype=torch.float)

        # Dataã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ä½œæˆ
        data = Data(x=node_features, edge_index=edge_index, edge_attr=edge_attr)

        if target is not None:
            data.y = torch.tensor([target], dtype=torch.float)

        return data


# ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–ã¨ãƒ†ã‚¹ãƒˆ
converter = MaterialGraphConverter(cutoff=5.0, max_neighbors=12)

# æœ€åˆã®ææ–™ã§ãƒ†ã‚¹ãƒˆ
test_structure = structures[0]
test_target = materials_df.iloc[0]['band_gap']
test_graph = converter.structure_to_graph(test_structure, test_target)

print(&quot;ã‚°ãƒ©ãƒ•å¤‰æ›ã®ãƒ†ã‚¹ãƒˆ:&quot;)
print(f&quot;ãƒãƒ¼ãƒ‰æ•°: {test_graph.num_nodes}&quot;)
print(f&quot;ã‚¨ãƒƒã‚¸æ•°: {test_graph.num_edges}&quot;)
print(f&quot;ãƒãƒ¼ãƒ‰ç‰¹å¾´æ¬¡å…ƒ: {test_graph.x.shape[1]}&quot;)
print(f&quot;ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå€¤: {test_graph.y.item():.3f}&quot;)
</code></pre>
<h3>ã‚³ãƒ¼ãƒ‰ä¾‹5: ã‚«ã‚¹ã‚¿ãƒ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚¯ãƒ©ã‚¹</h3>
<pre><code class="language-python">from torch_geometric.data import Dataset, Data
import torch
from tqdm import tqdm
import pickle

class MaterialsDataset(Dataset):
    &quot;&quot;&quot;
    ææ–™ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ

    Parameters:
    -----------
    structures : list
        pymatgen.Structure ã®ãƒªã‚¹ãƒˆ
    targets : array-like
        ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå€¤
    converter : MaterialGraphConverter
        ã‚°ãƒ©ãƒ•å¤‰æ›å™¨
    root : str
        ãƒ‡ãƒ¼ã‚¿ä¿å­˜å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    transform : callable, optional
        ãƒ‡ãƒ¼ã‚¿å¤‰æ›é–¢æ•°
    pre_transform : callable, optional
        å‰å‡¦ç†é–¢æ•°
    &quot;&quot;&quot;

    def __init__(self, structures, targets, converter,
                 root='data/materials', transform=None, pre_transform=None):
        self.structures = structures
        self.targets = targets
        self.converter = converter

        super().__init__(root, transform, pre_transform)

    @property
    def raw_file_names(self):
        return []

    @property
    def processed_file_names(self):
        return [f'data_{i}.pt' for i in range(len(self.structures))]

    def download(self):
        pass

    def process(self):
        &quot;&quot;&quot;æ§‹é€ ã‚’ã‚°ãƒ©ãƒ•ã«å¤‰æ›ã—ã¦ä¿å­˜&quot;&quot;&quot;
        for idx in tqdm(range(len(self.structures)), desc=&quot;ã‚°ãƒ©ãƒ•å¤‰æ›ä¸­&quot;):
            structure = self.structures[idx]
            target = self.targets[idx]

            # ã‚°ãƒ©ãƒ•ã¸ã®å¤‰æ›
            data = self.converter.structure_to_graph(structure, target)

            if self.pre_transform is not None:
                data = self.pre_transform(data)

            # ä¿å­˜
            torch.save(data, self.processed_paths[idx])

    def len(self):
        return len(self.structures)

    def get(self, idx):
        data = torch.load(self.processed_paths[idx])
        return data


# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ä½œæˆ
print(&quot;ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆä¸­...&quot;)

# ã‚¿ãƒ¼ã‚²ãƒƒãƒˆç‰¹æ€§ï¼ˆãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—ï¼‰
targets = materials_df['band_gap'].values

# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–
dataset = MaterialsDataset(
    structures=structures,
    targets=targets,
    converter=converter,
    root='data/materials_dataset'
)

print(f&quot;\nãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆå®Œäº†ï¼&quot;)
print(f&quot;ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚µã‚¤ã‚º: {len(dataset)}&quot;)
print(f&quot;ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿:&quot;)
print(dataset[0])
</code></pre>
<p><strong>å‡ºåŠ›ä¾‹</strong>:</p>
<pre><code>ã‚°ãƒ©ãƒ•å¤‰æ›ä¸­: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:15&lt;00:00, 63.42it/s]

ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆå®Œäº†ï¼
ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚µã‚¤ã‚º: 1000
ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿:
Data(x=[5, 6], edge_index=[2, 48], edge_attr=[48, 1], y=[1])
</code></pre>
<h3>ã‚³ãƒ¼ãƒ‰ä¾‹6: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®åˆ†å‰²ã¨DataLoader</h3>
<pre><code class="language-python">from torch_geometric.loader import DataLoader
from sklearn.model_selection import train_test_split
import torch

# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åˆ†å‰²
train_idx, temp_idx = train_test_split(
    range(len(dataset)), test_size=0.3, random_state=42
)
val_idx, test_idx = train_test_split(
    temp_idx, test_size=0.5, random_state=42
)

# ã‚µãƒ–ã‚»ãƒƒãƒˆã®ä½œæˆ
train_dataset = dataset[train_idx]
val_dataset = dataset[val_idx]
test_dataset = dataset[test_idx]

print(f&quot;ãƒ‡ãƒ¼ã‚¿åˆ†å‰²:&quot;)
print(f&quot;  å­¦ç¿’ãƒ‡ãƒ¼ã‚¿: {len(train_dataset)}&quot;)
print(f&quot;  æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿: {len(val_dataset)}&quot;)
print(f&quot;  ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {len(test_dataset)}&quot;)

# DataLoaderã®ä½œæˆ
batch_size = 32

train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)
test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

# DataLoaderã®ãƒ†ã‚¹ãƒˆ
batch = next(iter(train_loader))
print(f&quot;\nãƒãƒƒãƒãƒ‡ãƒ¼ã‚¿:&quot;)
print(f&quot;  ãƒãƒƒãƒã‚µã‚¤ã‚º: {batch.num_graphs}&quot;)
print(f&quot;  ç·ãƒãƒ¼ãƒ‰æ•°: {batch.num_nodes}&quot;)
print(f&quot;  ç·ã‚¨ãƒƒã‚¸æ•°: {batch.num_edges}&quot;)
print(f&quot;  ãƒãƒ¼ãƒ‰ç‰¹å¾´å½¢çŠ¶: {batch.x.shape}&quot;)
print(f&quot;  ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå½¢çŠ¶: {batch.y.shape}&quot;)
</code></pre>
<p><strong>å‡ºåŠ›ä¾‹</strong>:</p>
<pre><code>ãƒ‡ãƒ¼ã‚¿åˆ†å‰²:
  å­¦ç¿’ãƒ‡ãƒ¼ã‚¿: 700
  æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿: 150
  ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: 150

ãƒãƒƒãƒãƒ‡ãƒ¼ã‚¿:
  ãƒãƒƒãƒã‚µã‚¤ã‚º: 32
  ç·ãƒãƒ¼ãƒ‰æ•°: 168
  ç·ã‚¨ãƒƒã‚¸æ•°: 1568
  ãƒãƒ¼ãƒ‰ç‰¹å¾´å½¢çŠ¶: torch.Size([168, 6])
  ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå½¢çŠ¶: torch.Size([32, 1])
</code></pre>
<h2>4.3 GNNãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’</h2>
<h3>ã‚³ãƒ¼ãƒ‰ä¾‹7: æ”¹è‰¯ç‰ˆCGCNNãƒ¢ãƒ‡ãƒ«</h3>
<pre><code class="language-python">import torch
import torch.nn as nn
import torch.nn.functional as F
from torch_geometric.nn import MessagePassing, global_mean_pool, global_add_pool, global_max_pool

class ImprovedCGConv(MessagePassing):
    &quot;&quot;&quot;æ”¹è‰¯ç‰ˆCGCNNç•³ã¿è¾¼ã¿å±¤&quot;&quot;&quot;

    def __init__(self, node_dim, edge_dim, hidden_dim=128):
        super().__init__(aggr='add')

        self.node_dim = node_dim
        self.edge_dim = edge_dim
        self.hidden_dim = hidden_dim

        # ã‚¨ãƒƒã‚¸ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯
        self.edge_network = nn.Sequential(
            nn.Linear(2 * node_dim + edge_dim, hidden_dim),
            nn.BatchNorm1d(hidden_dim),
            nn.Softplus(),
            nn.Linear(hidden_dim, hidden_dim),
            nn.BatchNorm1d(hidden_dim),
            nn.Softplus()
        )

        # ã‚²ãƒ¼ãƒˆãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯
        self.gate_network = nn.Sequential(
            nn.Linear(2 * node_dim + edge_dim, hidden_dim),
            nn.Sigmoid()
        )

        # ãƒãƒ¼ãƒ‰æ›´æ–°ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯
        self.node_update = nn.Sequential(
            nn.Linear(node_dim + hidden_dim, hidden_dim),
            nn.BatchNorm1d(hidden_dim),
            nn.Softplus(),
            nn.Linear(hidden_dim, hidden_dim)
        )

    def forward(self, x, edge_index, edge_attr):
        return self.propagate(edge_index, x=x, edge_attr=edge_attr)

    def message(self, x_i, x_j, edge_attr):
        &quot;&quot;&quot;ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é–¢æ•°&quot;&quot;&quot;
        # é€ä¿¡å…ƒã€å—ä¿¡å…ˆã€ã‚¨ãƒƒã‚¸ç‰¹å¾´ã‚’çµåˆ
        z = torch.cat([x_i, x_j, edge_attr], dim=1)

        # ã‚²ãƒ¼ãƒ†ã‚£ãƒ³ã‚°æ©Ÿæ§‹
        gate = self.gate_network(z)
        message = self.edge_network(z)

        return gate * message

    def update(self, aggr_out, x):
        &quot;&quot;&quot;ãƒãƒ¼ãƒ‰æ›´æ–°&quot;&quot;&quot;
        combined = torch.cat([x, aggr_out], dim=1)
        return self.node_update(combined)


class ImprovedCGCNN(nn.Module):
    &quot;&quot;&quot;æ”¹è‰¯ç‰ˆCGCNNãƒ¢ãƒ‡ãƒ«&quot;&quot;&quot;

    def __init__(self, node_dim, edge_dim, hidden_dim=128,
                 num_conv=4, dropout=0.2, pooling='mean'):
        super().__init__()

        self.node_dim = node_dim
        self.edge_dim = edge_dim
        self.hidden_dim = hidden_dim
        self.num_conv = num_conv
        self.pooling = pooling

        # å…¥åŠ›åŸ‹ã‚è¾¼ã¿
        self.node_embedding = nn.Sequential(
            nn.Linear(node_dim, hidden_dim),
            nn.BatchNorm1d(hidden_dim),
            nn.Softplus()
        )

        # CGConvå±¤
        self.conv_layers = nn.ModuleList([
            ImprovedCGConv(hidden_dim, edge_dim, hidden_dim)
            for _ in range(num_conv)
        ])

        # Batch Normalization
        self.bn_layers = nn.ModuleList([
            nn.BatchNorm1d(hidden_dim)
            for _ in range(num_conv)
        ])

        # Dropout
        self.dropout = nn.Dropout(dropout)

        # ãƒ—ãƒ¼ãƒªãƒ³ã‚°
        if pooling == 'mean':
            self.pool = global_mean_pool
        elif pooling == 'add':
            self.pool = global_add_pool
        elif pooling == 'max':
            self.pool = global_max_pool
        else:
            raise ValueError(f&quot;Unknown pooling: {pooling}&quot;)

        # å‡ºåŠ›ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯
        self.fc = nn.Sequential(
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.BatchNorm1d(hidden_dim // 2),
            nn.Softplus(),
            nn.Dropout(dropout),
            nn.Linear(hidden_dim // 2, hidden_dim // 4),
            nn.BatchNorm1d(hidden_dim // 4),
            nn.Softplus(),
            nn.Dropout(dropout),
            nn.Linear(hidden_dim // 4, 1)
        )

    def forward(self, data, return_embedding=False):
        &quot;&quot;&quot;
        é †ä¼æ’­

        Parameters:
        -----------
        data : torch_geometric.data.Batch
            ãƒãƒƒãƒãƒ‡ãƒ¼ã‚¿
        return_embedding : bool
            åŸ‹ã‚è¾¼ã¿ã‚’è¿”ã™ã‹

        Returns:
        --------
        out : Tensor
            äºˆæ¸¬å€¤
        embedding : Tensor (optional)
            ã‚°ãƒ©ãƒ•åŸ‹ã‚è¾¼ã¿
        &quot;&quot;&quot;
        x, edge_index, edge_attr, batch = data.x, data.edge_index, data.edge_attr, data.batch

        # å…¥åŠ›åŸ‹ã‚è¾¼ã¿
        x = self.node_embedding(x)

        # CGConvå±¤ã®é©ç”¨
        for conv, bn in zip(self.conv_layers, self.bn_layers):
            x_new = conv(x, edge_index, edge_attr)
            x_new = bn(x_new)
            x_new = F.softplus(x_new)
            x_new = self.dropout(x_new)

            # æ®‹å·®æ¥ç¶š
            x = x + x_new

        # ã‚°ãƒ©ãƒ•ãƒ¬ãƒ™ãƒ«ã®ãƒ—ãƒ¼ãƒªãƒ³ã‚°
        graph_embedding = self.pool(x, batch)

        # å‡ºåŠ›
        out = self.fc(graph_embedding)

        if return_embedding:
            return out, graph_embedding
        else:
            return out


# ãƒ¢ãƒ‡ãƒ«ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

model = ImprovedCGCNN(
    node_dim=6,
    edge_dim=1,
    hidden_dim=128,
    num_conv=4,
    dropout=0.2,
    pooling='mean'
).to(device)

print(f&quot;ãƒ¢ãƒ‡ãƒ«ã®ç·ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {sum(p.numel() for p in model.parameters()):,}&quot;)

# ãƒ†ã‚¹ãƒˆ
batch = next(iter(train_loader)).to(device)
predictions, embeddings = model(batch, return_embedding=True)

print(f&quot;\näºˆæ¸¬å€¤ã®å½¢çŠ¶: {predictions.shape}&quot;)
print(f&quot;åŸ‹ã‚è¾¼ã¿ã®å½¢çŠ¶: {embeddings.shape}&quot;)
</code></pre>
<h3>ã‚³ãƒ¼ãƒ‰ä¾‹8: å­¦ç¿’ãƒ«ãƒ¼ãƒ—ï¼ˆEarly Stoppingä»˜ãï¼‰</h3>
<pre><code class="language-python">import torch
import torch.optim as optim
from torch.optim.lr_scheduler import ReduceLROnPlateau
import numpy as np
from tqdm import tqdm
import time

class EarlyStopping:
    &quot;&quot;&quot;Early Stoppingã‚¯ãƒ©ã‚¹&quot;&quot;&quot;

    def __init__(self, patience=20, delta=0.001, path='best_model.pt'):
        self.patience = patience
        self.delta = delta
        self.path = path
        self.counter = 0
        self.best_score = None
        self.early_stop = False
        self.val_loss_min = np.Inf

    def __call__(self, val_loss, model):
        score = -val_loss

        if self.best_score is None:
            self.best_score = score
            self.save_checkpoint(val_loss, model)
        elif score &lt; self.best_score + self.delta:
            self.counter += 1
            if self.counter &gt;= self.patience:
                self.early_stop = True
        else:
            self.best_score = score
            self.save_checkpoint(val_loss, model)
            self.counter = 0

    def save_checkpoint(self, val_loss, model):
        torch.save(model.state_dict(), self.path)
        self.val_loss_min = val_loss


def train_epoch(model, loader, criterion, optimizer, device):
    &quot;&quot;&quot;1ã‚¨ãƒãƒƒã‚¯ã®å­¦ç¿’&quot;&quot;&quot;
    model.train()
    total_loss = 0
    total_samples = 0

    for batch in loader:
        batch = batch.to(device)

        optimizer.zero_grad()
        predictions = model(batch)
        loss = criterion(predictions, batch.y)

        loss.backward()
        optimizer.step()

        total_loss += loss.item() * batch.num_graphs
        total_samples += batch.num_graphs

    return total_loss / total_samples


def validate_epoch(model, loader, criterion, device):
    &quot;&quot;&quot;1ã‚¨ãƒãƒƒã‚¯ã®æ¤œè¨¼&quot;&quot;&quot;
    model.eval()
    total_loss = 0
    total_samples = 0

    with torch.no_grad():
        for batch in loader:
            batch = batch.to(device)

            predictions = model(batch)
            loss = criterion(predictions, batch.y)

            total_loss += loss.item() * batch.num_graphs
            total_samples += batch.num_graphs

    return total_loss / total_samples


# å­¦ç¿’è¨­å®š
criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)
scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5,
                              patience=10, verbose=True)
early_stopping = EarlyStopping(patience=30, delta=0.001,
                               path='best_cgcnn_model.pt')

# å­¦ç¿’ãƒ«ãƒ¼ãƒ—
num_epochs = 200
train_losses = []
val_losses = []

print(&quot;å­¦ç¿’é–‹å§‹...&quot;)
start_time = time.time()

for epoch in range(num_epochs):
    # å­¦ç¿’
    train_loss = train_epoch(model, train_loader, criterion, optimizer, device)
    train_losses.append(train_loss)

    # æ¤œè¨¼
    val_loss = validate_epoch(model, val_loader, criterion, device)
    val_losses.append(val_loss)

    # å­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©
    scheduler.step(val_loss)

    # Early Stopping
    early_stopping(val_loss, model)

    if (epoch + 1) % 10 == 0:
        elapsed_time = time.time() - start_time
        print(f&quot;Epoch [{epoch+1}/{num_epochs}] - &quot;
              f&quot;Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f} - &quot;
              f&quot;Time: {elapsed_time:.1f}s&quot;)

    if early_stopping.early_stop:
        print(f&quot;Early stopping at epoch {epoch+1}&quot;)
        break

total_time = time.time() - start_time
print(f&quot;\nå­¦ç¿’å®Œäº†ï¼ ç·æ™‚é–“: {total_time/60:.1f}åˆ†&quot;)

# ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰
model.load_state_dict(torch.load('best_cgcnn_model.pt'))
print(f&quot;ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸ (Val Loss: {early_stopping.val_loss_min:.4f})&quot;)
</code></pre>
<p><strong>å‡ºåŠ›ä¾‹</strong>:</p>
<pre><code>å­¦ç¿’é–‹å§‹...
Epoch [10/200] - Train Loss: 1.2345, Val Loss: 1.3456 - Time: 15.3s
Epoch [20/200] - Train Loss: 0.9876, Val Loss: 1.1234 - Time: 30.7s
Epoch [30/200] - Train Loss: 0.7654, Val Loss: 1.0123 - Time: 46.1s
Epoch [40/200] - Train Loss: 0.6543, Val Loss: 0.9876 - Time: 61.5s
Epoch [50/200] - Train Loss: 0.5678, Val Loss: 0.9654 - Time: 76.9s
Early stopping at epoch 85

å­¦ç¿’å®Œäº†ï¼ ç·æ™‚é–“: 2.3åˆ†
ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸ (Val Loss: 0.9234)
</code></pre>
<h3>ã‚³ãƒ¼ãƒ‰ä¾‹9: å­¦ç¿’æ›²ç·šã®å¯è¦–åŒ–</h3>
<pre><code class="language-python">import matplotlib.pyplot as plt
import numpy as np

# å­¦ç¿’æ›²ç·š
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))

# Lossæ›²ç·š
epochs = range(1, len(train_losses) + 1)
ax1.plot(epochs, train_losses, label='Train Loss', linewidth=2, color='blue')
ax1.plot(epochs, val_losses, label='Validation Loss', linewidth=2, color='red')
ax1.set_xlabel('Epoch', fontsize=14, fontweight='bold')
ax1.set_ylabel('MSE Loss', fontsize=14, fontweight='bold')
ax1.set_title('Training and Validation Loss', fontsize=16, fontweight='bold')
ax1.legend(fontsize=12)
ax1.grid(True, alpha=0.3)

# å¯¾æ•°ã‚¹ã‚±ãƒ¼ãƒ«
ax2.semilogy(epochs, train_losses, label='Train Loss', linewidth=2, color='blue')
ax2.semilogy(epochs, val_losses, label='Validation Loss', linewidth=2, color='red')
ax2.set_xlabel('Epoch', fontsize=14, fontweight='bold')
ax2.set_ylabel('MSE Loss (log scale)', fontsize=14, fontweight='bold')
ax2.set_title('Training Curve (Log Scale)', fontsize=16, fontweight='bold')
ax2.legend(fontsize=12)
ax2.grid(True, alpha=0.3, which='both')

plt.tight_layout()
plt.savefig('training_curve.png', dpi=300, bbox_inches='tight')
print(&quot;å­¦ç¿’æ›²ç·šã‚’ training_curve.png ã«ä¿å­˜ã—ã¾ã—ãŸ&quot;)
plt.show()
</code></pre>
<h3>ã‚³ãƒ¼ãƒ‰ä¾‹10: ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§ã®è©•ä¾¡</h3>
<pre><code class="language-python">from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import matplotlib.pyplot as plt
import numpy as np

def evaluate_model(model, loader, device):
    &quot;&quot;&quot;ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡&quot;&quot;&quot;
    model.eval()

    all_predictions = []
    all_targets = []

    with torch.no_grad():
        for batch in loader:
            batch = batch.to(device)

            predictions = model(batch)

            all_predictions.append(predictions.cpu().numpy())
            all_targets.append(batch.y.cpu().numpy())

    predictions = np.concatenate(all_predictions, axis=0).flatten()
    targets = np.concatenate(all_targets, axis=0).flatten()

    return predictions, targets


# ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§ã®è©•ä¾¡
test_predictions, test_targets = evaluate_model(model, test_loader, device)

# è©•ä¾¡æŒ‡æ¨™ã®è¨ˆç®—
mae = mean_absolute_error(test_targets, test_predictions)
rmse = np.sqrt(mean_squared_error(test_targets, test_predictions))
r2 = r2_score(test_targets, test_predictions)

print(&quot;ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§ã®è©•ä¾¡:&quot;)
print(f&quot;  MAE:  {mae:.4f}&quot;)
print(f&quot;  RMSE: {rmse:.4f}&quot;)
print(f&quot;  RÂ²:   {r2:.4f}&quot;)

# äºˆæ¸¬å€¤ vs å®Ÿæ¸¬å€¤ã®ãƒ—ãƒ­ãƒƒãƒˆ
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))

# æ•£å¸ƒå›³
ax1.scatter(test_targets, test_predictions, alpha=0.6, s=50,
            edgecolors='black', linewidth=0.5, color='steelblue')

# ç†æƒ³ç·š
min_val = min(test_targets.min(), test_predictions.min())
max_val = max(test_targets.max(), test_predictions.max())
ax1.plot([min_val, max_val], [min_val, max_val],
         'r--', linewidth=2, label='Ideal')

ax1.set_xlabel('True Band Gap (eV)', fontsize=14, fontweight='bold')
ax1.set_ylabel('Predicted Band Gap (eV)', fontsize=14, fontweight='bold')
ax1.set_title(f'Predictions vs True Values\nRÂ²={r2:.3f}, MAE={mae:.3f}',
              fontsize=16, fontweight='bold')
ax1.legend(fontsize=12)
ax1.grid(True, alpha=0.3)

# æ®‹å·®ãƒ—ãƒ­ãƒƒãƒˆ
residuals = test_predictions - test_targets
ax2.scatter(test_targets, residuals, alpha=0.6, s=50,
            edgecolors='black', linewidth=0.5, color='coral')
ax2.axhline(y=0, color='r', linestyle='--', linewidth=2)

ax2.set_xlabel('True Band Gap (eV)', fontsize=14, fontweight='bold')
ax2.set_ylabel('Residuals (eV)', fontsize=14, fontweight='bold')
ax2.set_title('Residual Plot', fontsize=16, fontweight='bold')
ax2.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('test_evaluation.png', dpi=300, bbox_inches='tight')
print(&quot;\nè©•ä¾¡çµæœã‚’ test_evaluation.png ã«ä¿å­˜ã—ã¾ã—ãŸ&quot;)
plt.show()
</code></pre>
<h2>4.4 åŸ‹ã‚è¾¼ã¿æŠ½å‡ºã¨æ¬¡å…ƒå‰Šæ¸›</h2>
<h3>ã‚³ãƒ¼ãƒ‰ä¾‹11: å…¨ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã®åŸ‹ã‚è¾¼ã¿æŠ½å‡º</h3>
<pre><code class="language-python">def extract_all_embeddings(model, dataset, device, batch_size=64):
    &quot;&quot;&quot;
    å…¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‹ã‚‰åŸ‹ã‚è¾¼ã¿ã‚’æŠ½å‡º

    Parameters:
    -----------
    model : nn.Module
        å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«
    dataset : Dataset
        ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
    device : torch.device
        ãƒ‡ãƒã‚¤ã‚¹
    batch_size : int
        ãƒãƒƒãƒã‚µã‚¤ã‚º

    Returns:
    --------
    embeddings : np.ndarray
        åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«
    targets : np.ndarray
        ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå€¤
    &quot;&quot;&quot;
    model.eval()
    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)

    all_embeddings = []
    all_targets = []

    with torch.no_grad():
        for batch in tqdm(loader, desc=&quot;åŸ‹ã‚è¾¼ã¿æŠ½å‡ºä¸­&quot;):
            batch = batch.to(device)

            _, embeddings = model(batch, return_embedding=True)

            all_embeddings.append(embeddings.cpu().numpy())
            all_targets.append(batch.y.cpu().numpy())

    embeddings = np.concatenate(all_embeddings, axis=0)
    targets = np.concatenate(all_targets, axis=0).flatten()

    return embeddings, targets


# å…¨ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰åŸ‹ã‚è¾¼ã¿ã‚’æŠ½å‡º
embeddings, targets = extract_all_embeddings(model, dataset, device)

print(f&quot;åŸ‹ã‚è¾¼ã¿ã®å½¢çŠ¶: {embeddings.shape}&quot;)
print(f&quot;ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®å½¢çŠ¶: {targets.shape}&quot;)

# ä¿å­˜
np.save('cgcnn_embeddings.npy', embeddings)
np.save('cgcnn_targets.npy', targets)
print(&quot;\nåŸ‹ã‚è¾¼ã¿ã‚’ä¿å­˜ã—ã¾ã—ãŸ&quot;)
</code></pre>
<h3>ã‚³ãƒ¼ãƒ‰ä¾‹12: PCAã«ã‚ˆã‚‹æ¬¡å…ƒå‰Šæ¸›</h3>
<pre><code class="language-python">from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
import numpy as np

# PCAã®å®Ÿè¡Œ
pca = PCA(n_components=min(50, embeddings.shape[1]))
embeddings_pca = pca.fit_transform(embeddings)

# å¯„ä¸ç‡ã®åˆ†æ
explained_variance_ratio = pca.explained_variance_ratio_
cumsum_variance = np.cumsum(explained_variance_ratio)

# ã‚¹ã‚¯ãƒªãƒ¼ãƒ—ãƒ­ãƒƒãƒˆ
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))

# å€‹åˆ¥å¯„ä¸ç‡
ax1.bar(range(1, 21), explained_variance_ratio[:20],
        alpha=0.7, edgecolor='black', color='steelblue')
ax1.set_xlabel('Principal Component', fontsize=14, fontweight='bold')
ax1.set_ylabel('Explained Variance Ratio', fontsize=14, fontweight='bold')
ax1.set_title('PCA Scree Plot (Top 20 Components)',
              fontsize=16, fontweight='bold')
ax1.grid(True, alpha=0.3, axis='y')

# ç´¯ç©å¯„ä¸ç‡
ax2.plot(range(1, len(cumsum_variance) + 1), cumsum_variance,
         marker='o', linewidth=2, markersize=4, color='darkred')
ax2.axhline(y=0.95, color='green', linestyle='--', linewidth=2,
            label='95% threshold', alpha=0.7)
ax2.set_xlabel('Number of Components', fontsize=14, fontweight='bold')
ax2.set_ylabel('Cumulative Explained Variance', fontsize=14, fontweight='bold')
ax2.set_title('Cumulative Variance Explained',
              fontsize=16, fontweight='bold')
ax2.legend(fontsize=12)
ax2.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('pca_analysis.png', dpi=300, bbox_inches='tight')
print(f&quot;PCAåˆ†æã‚’ pca_analysis.png ã«ä¿å­˜ã—ã¾ã—ãŸ&quot;)
print(f&quot;\n95%ã®åˆ†æ•£ã‚’èª¬æ˜ã™ã‚‹ä¸»æˆåˆ†æ•°: {np.argmax(cumsum_variance &gt;= 0.95) + 1}&quot;)
plt.show()

# 2æ¬¡å…ƒPCAå¯è¦–åŒ–
pca_2d = PCA(n_components=2)
embeddings_pca_2d = pca_2d.fit_transform(embeddings)

plt.figure(figsize=(12, 9))
scatter = plt.scatter(embeddings_pca_2d[:, 0], embeddings_pca_2d[:, 1],
                      c=targets, cmap='viridis', s=50, alpha=0.6,
                      edgecolors='black', linewidth=0.5)
plt.xlabel(f'PC1 ({pca_2d.explained_variance_ratio_[0]*100:.1f}% variance)',
           fontsize=14, fontweight='bold')
plt.ylabel(f'PC2 ({pca_2d.explained_variance_ratio_[1]*100:.1f}% variance)',
           fontsize=14, fontweight='bold')
plt.title('PCA: 2D Projection of CGCNN Embeddings',
          fontsize=16, fontweight='bold')
plt.colorbar(scatter, label='Band Gap (eV)')
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.savefig('pca_2d_projection.png', dpi=300, bbox_inches='tight')
print(&quot;PCA 2Då°„å½±ã‚’ pca_2d_projection.png ã«ä¿å­˜ã—ã¾ã—ãŸ&quot;)
plt.show()
</code></pre>
<h3>ã‚³ãƒ¼ãƒ‰ä¾‹13: UMAPã«ã‚ˆã‚‹æ¬¡å…ƒå‰Šæ¸›</h3>
<pre><code class="language-python">import umap
import matplotlib.pyplot as plt
import numpy as np

# UMAPå®Ÿè¡Œï¼ˆè¤‡æ•°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§å®Ÿé¨“ï¼‰
n_neighbors_list = [5, 15, 30, 50]
min_dist_list = [0.0, 0.1, 0.3]

# æœ€é©ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ã®å®Ÿè¡Œ
print(&quot;UMAPã‚’å®Ÿè¡Œä¸­...&quot;)
reducer = umap.UMAP(
    n_components=2,
    n_neighbors=15,
    min_dist=0.1,
    metric='euclidean',
    random_state=42,
    verbose=True
)

embeddings_umap = reducer.fit_transform(embeddings)

# å¯è¦–åŒ–
fig, axes = plt.subplots(1, 2, figsize=(18, 7))

# ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå€¤ã§è‰²ä»˜ã‘
scatter1 = axes[0].scatter(embeddings_umap[:, 0], embeddings_umap[:, 1],
                           c=targets, cmap='viridis', s=50, alpha=0.6,
                           edgecolors='black', linewidth=0.5)
axes[0].set_xlabel('UMAP 1', fontsize=14, fontweight='bold')
axes[0].set_ylabel('UMAP 2', fontsize=14, fontweight='bold')
axes[0].set_title('UMAP: Colored by Band Gap',
                  fontsize=16, fontweight='bold')
axes[0].grid(True, alpha=0.3)
cbar1 = plt.colorbar(scatter1, ax=axes[0])
cbar1.set_label('Band Gap (eV)', fontsize=12, fontweight='bold')

# ã‚«ãƒ†ã‚´ãƒªã§è‰²ä»˜ã‘
band_gap_categories = pd.cut(targets, bins=[0, 1, 2, 3, 10],
                              labels=['Small', 'Medium', 'Large', 'Very Large'])

colors_map = {'Small': 'red', 'Medium': 'orange', 'Large': 'yellow', 'Very Large': 'green'}
colors = [colors_map[cat] for cat in band_gap_categories]

for category in ['Small', 'Medium', 'Large', 'Very Large']:
    mask = band_gap_categories == category
    axes[1].scatter(embeddings_umap[mask, 0], embeddings_umap[mask, 1],
                    c=colors_map[category], label=category, s=50, alpha=0.7,
                    edgecolors='black', linewidth=0.5)

axes[1].set_xlabel('UMAP 1', fontsize=14, fontweight='bold')
axes[1].set_ylabel('UMAP 2', fontsize=14, fontweight='bold')
axes[1].set_title('UMAP: Colored by Band Gap Category',
                  fontsize=16, fontweight='bold')
axes[1].legend(title='Band Gap', fontsize=11)
axes[1].grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('umap_2d_projection.png', dpi=300, bbox_inches='tight')
print(&quot;\nUMAP 2Då°„å½±ã‚’ umap_2d_projection.png ã«ä¿å­˜ã—ã¾ã—ãŸ&quot;)
plt.show()

# UMAPçµæœã®ä¿å­˜
np.save('umap_embeddings_2d.npy', embeddings_umap)
</code></pre>
<h3>ã‚³ãƒ¼ãƒ‰ä¾‹14: t-SNEã«ã‚ˆã‚‹æ¬¡å…ƒå‰Šæ¸›</h3>
<pre><code class="language-python">from sklearn.manifold import TSNE
import matplotlib.pyplot as plt
import time

# t-SNEå®Ÿè¡Œï¼ˆã‚µãƒ–ã‚»ãƒƒãƒˆã§é«˜é€ŸåŒ–ï¼‰
subset_size = min(1000, len(embeddings))
subset_indices = np.random.choice(len(embeddings), subset_size, replace=False)

embeddings_subset = embeddings[subset_indices]
targets_subset = targets[subset_indices]

print(f&quot;t-SNEã‚’å®Ÿè¡Œä¸­ (ã‚µãƒ–ã‚»ãƒƒãƒˆã‚µã‚¤ã‚º: {subset_size})...&quot;)
start_time = time.time()

tsne = TSNE(
    n_components=2,
    perplexity=30,
    n_iter=1000,
    random_state=42,
    verbose=1
)

embeddings_tsne = tsne.fit_transform(embeddings_subset)

elapsed_time = time.time() - start_time
print(f&quot;t-SNEå®Œäº† (æ‰€è¦æ™‚é–“: {elapsed_time:.1f}ç§’)&quot;)

# å¯è¦–åŒ–
plt.figure(figsize=(12, 9))
scatter = plt.scatter(embeddings_tsne[:, 0], embeddings_tsne[:, 1],
                      c=targets_subset, cmap='plasma', s=50, alpha=0.6,
                      edgecolors='black', linewidth=0.5)
plt.xlabel('t-SNE 1', fontsize=14, fontweight='bold')
plt.ylabel('t-SNE 2', fontsize=14, fontweight='bold')
plt.title('t-SNE: 2D Projection of CGCNN Embeddings',
          fontsize=16, fontweight='bold')
plt.colorbar(scatter, label='Band Gap (eV)')
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.savefig('tsne_2d_projection.png', dpi=300, bbox_inches='tight')
print(&quot;t-SNE 2Då°„å½±ã‚’ tsne_2d_projection.png ã«ä¿å­˜ã—ã¾ã—ãŸ&quot;)
plt.show()
</code></pre>
<h3>ã‚³ãƒ¼ãƒ‰ä¾‹15: æ¬¡å…ƒå‰Šæ¸›æ‰‹æ³•ã®æ¯”è¼ƒ</h3>
<pre><code class="language-python">import matplotlib.pyplot as plt
import numpy as np

# 3ã¤ã®æ‰‹æ³•ã®çµæœã‚’ä¸¦ã¹ã¦è¡¨ç¤º
fig, axes = plt.subplots(1, 3, figsize=(21, 6))

# PCA
scatter = axes[0].scatter(embeddings_pca_2d[:, 0], embeddings_pca_2d[:, 1],
                          c=targets, cmap='viridis', s=30, alpha=0.6,
                          edgecolors='none')
axes[0].set_xlabel('PC1', fontsize=12, fontweight='bold')
axes[0].set_ylabel('PC2', fontsize=12, fontweight='bold')
axes[0].set_title('PCA', fontsize=14, fontweight='bold')
axes[0].grid(True, alpha=0.3)

# UMAP
scatter = axes[1].scatter(embeddings_umap[:, 0], embeddings_umap[:, 1],
                          c=targets, cmap='viridis', s=30, alpha=0.6,
                          edgecolors='none')
axes[1].set_xlabel('UMAP 1', fontsize=12, fontweight='bold')
axes[1].set_ylabel('UMAP 2', fontsize=12, fontweight='bold')
axes[1].set_title('UMAP', fontsize=14, fontweight='bold')
axes[1].grid(True, alpha=0.3)

# t-SNE
scatter = axes[2].scatter(embeddings_tsne[:, 0], embeddings_tsne[:, 1],
                          c=targets_subset, cmap='viridis', s=30, alpha=0.6,
                          edgecolors='none')
axes[2].set_xlabel('t-SNE 1', fontsize=12, fontweight='bold')
axes[2].set_ylabel('t-SNE 2', fontsize=12, fontweight='bold')
axes[2].set_title('t-SNE', fontsize=14, fontweight='bold')
axes[2].grid(True, alpha=0.3)

# å…±é€šã‚«ãƒ©ãƒ¼ãƒãƒ¼
fig.subplots_adjust(right=0.9)
cbar_ax = fig.add_axes([0.92, 0.15, 0.02, 0.7])
cbar = fig.colorbar(scatter, cax=cbar_ax)
cbar.set_label('Band Gap (eV)', fontsize=12, fontweight='bold')

plt.savefig('dimensionality_reduction_comparison.png', dpi=300, bbox_inches='tight')
print(&quot;æ¬¡å…ƒå‰Šæ¸›æ‰‹æ³•æ¯”è¼ƒã‚’ dimensionality_reduction_comparison.png ã«ä¿å­˜ã—ã¾ã—ãŸ&quot;)
plt.show()
</code></pre>
<h2>4.5 ææ–™ç©ºé–“ã®åˆ†æ</h2>
<h3>ã‚³ãƒ¼ãƒ‰ä¾‹16: ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã¨ç‰¹æ€§åˆ†æ</h3>
<pre><code class="language-python">from sklearn.cluster import KMeans
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# K-Meansã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ï¼ˆUMAPç©ºé–“ä¸Šï¼‰
n_clusters = 6
kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=20)
cluster_labels = kmeans.fit_predict(embeddings_umap)

# ã‚¯ãƒ©ã‚¹ã‚¿ã”ã¨ã®å¯è¦–åŒ–
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 7))

# ã‚¯ãƒ©ã‚¹ã‚¿ãƒ©ãƒ™ãƒ«ã§è‰²ä»˜ã‘
colors = plt.cm.Set3(np.linspace(0, 1, n_clusters))
for cluster_id in range(n_clusters):
    mask = cluster_labels == cluster_id
    ax1.scatter(embeddings_umap[mask, 0], embeddings_umap[mask, 1],
                c=[colors[cluster_id]], label=f'Cluster {cluster_id}',
                s=60, alpha=0.7, edgecolors='black', linewidth=0.5)

# ã‚¯ãƒ©ã‚¹ã‚¿ä¸­å¿ƒ
umap_reducer_for_centers = umap.UMAP(n_components=2, n_neighbors=15,
                                     min_dist=0.1, random_state=42)
umap_reducer_for_centers.fit(embeddings)
centers_umap = umap_reducer_for_centers.transform(kmeans.cluster_centers_)

ax1.scatter(centers_umap[:, 0], centers_umap[:, 1],
            c='red', marker='X', s=300, edgecolors='black',
            linewidth=2, label='Centroids', zorder=10)

ax1.set_xlabel('UMAP 1', fontsize=14, fontweight='bold')
ax1.set_ylabel('UMAP 2', fontsize=14, fontweight='bold')
ax1.set_title(f'K-Means Clustering (k={n_clusters})',
              fontsize=16, fontweight='bold')
ax1.legend(fontsize=10, loc='best', ncol=2)
ax1.grid(True, alpha=0.3)

# ã‚¯ãƒ©ã‚¹ã‚¿ã”ã¨ã®ç‰¹æ€§åˆ†å¸ƒ
cluster_df = pd.DataFrame({
    'cluster': cluster_labels,
    'band_gap': targets
})

sns.boxplot(data=cluster_df, x='cluster', y='band_gap',
            ax=ax2, palette='Set3')
sns.swarmplot(data=cluster_df, x='cluster', y='band_gap',
              ax=ax2, color='black', alpha=0.3, size=2)

ax2.set_xlabel('Cluster ID', fontsize=14, fontweight='bold')
ax2.set_ylabel('Band Gap (eV)', fontsize=14, fontweight='bold')
ax2.set_title('Band Gap Distribution by Cluster',
              fontsize=16, fontweight='bold')
ax2.grid(True, alpha=0.3, axis='y')

plt.tight_layout()
plt.savefig('clustering_analysis.png', dpi=300, bbox_inches='tight')
print(&quot;ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°åˆ†æã‚’ clustering_analysis.png ã«ä¿å­˜ã—ã¾ã—ãŸ&quot;)
plt.show()

# ã‚¯ãƒ©ã‚¹ã‚¿çµ±è¨ˆ
print(&quot;\nã‚¯ãƒ©ã‚¹ã‚¿ã”ã¨ã®ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—çµ±è¨ˆ:&quot;)
cluster_stats = cluster_df.groupby('cluster')['band_gap'].agg([
    'count', 'mean', 'std', 'min', 'max'
])
print(cluster_stats.round(3))
</code></pre>
<h3>ã‚³ãƒ¼ãƒ‰ä¾‹17: ææ–™ç‰¹æ€§ã¨ã‚¯ãƒ©ã‚¹ã‚¿ã®é–¢ä¿‚åˆ†æ</h3>
<pre><code class="language-python">import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# è¿½åŠ ã®ææ–™ç‰¹æ€§ã‚’DataFrameã«çµ±åˆ
materials_analysis_df = materials_df.copy()
materials_analysis_df['cluster'] = cluster_labels
materials_analysis_df['umap1'] = embeddings_umap[:, 0]
materials_analysis_df['umap2'] = embeddings_umap[:, 1]

# ã‚¯ãƒ©ã‚¹ã‚¿ã”ã¨ã®è¤‡æ•°ç‰¹æ€§ã®çµ±è¨ˆ
properties_to_analyze = [
    'band_gap', 'formation_energy_per_atom',
    'density', 'energy_above_hull', 'volume'
]

cluster_property_stats = materials_analysis_df.groupby('cluster')[
    properties_to_analyze
].mean()

# ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã§å¯è¦–åŒ–
plt.figure(figsize=(12, 8))
sns.heatmap(cluster_property_stats.T, annot=True, fmt='.2f',
            cmap='RdYlGn_r', center=0, linewidths=1,
            cbar_kws={&quot;label&quot;: &quot;Normalized Value&quot;})
plt.title('Average Material Properties by Cluster',
          fontsize=16, fontweight='bold', pad=20)
plt.xlabel('Cluster ID', fontsize=14, fontweight='bold')
plt.ylabel('Property', fontsize=14, fontweight='bold')
plt.tight_layout()
plt.savefig('cluster_properties_heatmap.png', dpi=300, bbox_inches='tight')
print(&quot;ã‚¯ãƒ©ã‚¹ã‚¿ç‰¹æ€§ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã‚’ cluster_properties_heatmap.png ã«ä¿å­˜ã—ã¾ã—ãŸ&quot;)
plt.show()
</code></pre>
<h3>ã‚³ãƒ¼ãƒ‰ä¾‹18: å¯†åº¦ãƒãƒƒãƒ—ã®ä½œæˆ</h3>
<pre><code class="language-python">from scipy.stats import gaussian_kde
import matplotlib.pyplot as plt
import numpy as np

# UMAPç©ºé–“ã§ã®å¯†åº¦æ¨å®š
xy = np.vstack([embeddings_umap[:, 0], embeddings_umap[:, 1]])
density = gaussian_kde(xy)(xy)

# å¯†åº¦ã§ã‚½ãƒ¼ãƒˆï¼ˆé«˜å¯†åº¦ç‚¹ã‚’ä¸Šã«æç”»ï¼‰
idx = density.argsort()
x, y, z = embeddings_umap[idx, 0], embeddings_umap[idx, 1], density[idx]

# ãƒ—ãƒ­ãƒƒãƒˆ
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 7))

# å¯†åº¦ãƒãƒƒãƒ—
scatter1 = ax1.scatter(x, y, c=z, cmap='hot', s=50, alpha=0.7,
                       edgecolors='black', linewidth=0.3)
ax1.set_xlabel('UMAP 1', fontsize=14, fontweight='bold')
ax1.set_ylabel('UMAP 2', fontsize=14, fontweight='bold')
ax1.set_title('Materials Space Density Map',
              fontsize=16, fontweight='bold')
ax1.grid(True, alpha=0.3)
cbar1 = plt.colorbar(scatter1, ax=ax1)
cbar1.set_label('Point Density', fontsize=12, fontweight='bold')

# å¯†åº¦ãƒãƒƒãƒ— + ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—
scatter2 = ax2.scatter(embeddings_umap[:, 0], embeddings_umap[:, 1],
                       c=targets, s=50 + density*1000, alpha=0.6,
                       cmap='viridis', edgecolors='black', linewidth=0.5)
ax2.set_xlabel('UMAP 1', fontsize=14, fontweight='bold')
ax2.set_ylabel('UMAP 2', fontsize=14, fontweight='bold')
ax2.set_title('Band Gap with Density (size = density)',
              fontsize=16, fontweight='bold')
ax2.grid(True, alpha=0.3)
cbar2 = plt.colorbar(scatter2, ax=ax2)
cbar2.set_label('Band Gap (eV)', fontsize=12, fontweight='bold')

plt.tight_layout()
plt.savefig('density_map.png', dpi=300, bbox_inches='tight')
print(&quot;å¯†åº¦ãƒãƒƒãƒ—ã‚’ density_map.png ã«ä¿å­˜ã—ã¾ã—ãŸ&quot;)
plt.show()
</code></pre>
<h3>ã‚³ãƒ¼ãƒ‰ä¾‹19: è¿‘å‚ææ–™ã®æ¢ç´¢</h3>
<pre><code class="language-python">from sklearn.neighbors import NearestNeighbors
import pandas as pd

def find_similar_materials_in_embedding_space(
    query_idx, embeddings, materials_df, k=10
):
    &quot;&quot;&quot;
    åŸ‹ã‚è¾¼ã¿ç©ºé–“ã§é¡ä¼¼ææ–™ã‚’æ¤œç´¢

    Parameters:
    -----------
    query_idx : int
        ã‚¯ã‚¨ãƒªææ–™ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
    embeddings : np.ndarray
        åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«
    materials_df : pd.DataFrame
        ææ–™ãƒ‡ãƒ¼ã‚¿
    k : int
        æ¤œç´¢ã™ã‚‹è¿‘å‚æ•°

    Returns:
    --------
    results_df : pd.DataFrame
        è¿‘å‚ææ–™ã®æƒ…å ±
    &quot;&quot;&quot;
    nbrs = NearestNeighbors(n_neighbors=k+1, metric='cosine').fit(embeddings)
    distances, indices = nbrs.kneighbors(embeddings[query_idx:query_idx+1])

    # çµæœã®DataFrameä½œæˆ
    results = []
    for i, (idx, dist) in enumerate(zip(indices[0], distances[0])):
        if i == 0:  # ã‚¯ã‚¨ãƒªè‡ªèº«ã‚’ã‚¹ã‚­ãƒƒãƒ—
            continue

        result = {
            'rank': i,
            'material_id': materials_df.iloc[idx]['material_id'],
            'formula': materials_df.iloc[idx]['formula'],
            'band_gap': materials_df.iloc[idx]['band_gap'],
            'formation_energy': materials_df.iloc[idx]['formation_energy_per_atom'],
            'density': materials_df.iloc[idx]['density'],
            'distance': dist
        }
        results.append(result)

    results_df = pd.DataFrame(results)
    return results_df


# ä½¿ç”¨ä¾‹: ãƒ©ãƒ³ãƒ€ãƒ ã«ææ–™ã‚’é¸ã‚“ã§é¡ä¼¼ææ–™ã‚’æ¤œç´¢
np.random.seed(42)
query_indices = np.random.choice(len(materials_df), 3, replace=False)

print(&quot;é¡ä¼¼ææ–™æ¤œç´¢ã®ä¾‹:\n&quot;)
for query_idx in query_indices:
    query_material = materials_df.iloc[query_idx]

    print(f&quot;ã‚¯ã‚¨ãƒªææ–™:&quot;)
    print(f&quot;  Material ID: {query_material['material_id']}&quot;)
    print(f&quot;  Formula: {query_material['formula']}&quot;)
    print(f&quot;  Band Gap: {query_material['band_gap']:.3f} eV&quot;)
    print(f&quot;\né¡ä¼¼ææ–™ (Top 5):&quot;)

    similar_materials = find_similar_materials_in_embedding_space(
        query_idx, embeddings, materials_df, k=5
    )

    print(similar_materials[['rank', 'material_id', 'formula', 'band_gap', 'distance']].to_string(index=False))
    print(&quot;\n&quot; + &quot;=&quot;*80 + &quot;\n&quot;)
</code></pre>
<h3>ã‚³ãƒ¼ãƒ‰ä¾‹20: ææ–™æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ </h3>
<pre><code class="language-python">def recommend_materials_by_property(
    target_property_value,
    property_name,
    embeddings,
    materials_df,
    n_recommendations=10,
    property_weight=0.7,
    embedding_weight=0.3
):
    &quot;&quot;&quot;
    ç›®æ¨™ç‰¹æ€§å€¤ã«åŸºã¥ã„ã¦ææ–™ã‚’æ¨è–¦

    Parameters:
    -----------
    target_property_value : float
        ç›®æ¨™ç‰¹æ€§å€¤
    property_name : str
        ç‰¹æ€§å
    embeddings : np.ndarray
        åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«
    materials_df : pd.DataFrame
        ææ–™ãƒ‡ãƒ¼ã‚¿
    n_recommendations : int
        æ¨è–¦æ•°
    property_weight : float
        ç‰¹æ€§å€¤ã®é‡ã¿
    embedding_weight : float
        åŸ‹ã‚è¾¼ã¿è·é›¢ã®é‡ã¿

    Returns:
    --------
    recommendations_df : pd.DataFrame
        æ¨è–¦ææ–™ã®ãƒªã‚¹ãƒˆ
    &quot;&quot;&quot;
    # ç‰¹æ€§å€¤ã®å·®
    property_diff = np.abs(materials_df[property_name].values - target_property_value)
    property_diff_normalized = property_diff / property_diff.max()

    # ç›®æ¨™ç‰¹æ€§å€¤ã«æœ€ã‚‚è¿‘ã„ææ–™ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
    closest_idx = property_diff.argmin()

    # åŸ‹ã‚è¾¼ã¿ç©ºé–“ã§ã®è·é›¢
    from sklearn.metrics.pairwise import cosine_distances
    embedding_distances = cosine_distances(
        embeddings[closest_idx:closest_idx+1],
        embeddings
    ).flatten()
    embedding_distances_normalized = embedding_distances / embedding_distances.max()

    # çµ±åˆã‚¹ã‚³ã‚¢ï¼ˆå°ã•ã„ã»ã©è‰¯ã„ï¼‰
    combined_score = (
        property_weight * property_diff_normalized +
        embedding_weight * embedding_distances_normalized
    )

    # ä¸Šä½n_recommendationså€‹ã‚’é¸æŠ
    top_indices = combined_score.argsort()[:n_recommendations]

    # çµæœã®DataFrameä½œæˆ
    recommendations = []
    for rank, idx in enumerate(top_indices, 1):
        rec = {
            'rank': rank,
            'material_id': materials_df.iloc[idx]['material_id'],
            'formula': materials_df.iloc[idx]['formula'],
            property_name: materials_df.iloc[idx][property_name],
            'property_diff': property_diff[idx],
            'embedding_distance': embedding_distances[idx],
            'combined_score': combined_score[idx]
        }
        recommendations.append(rec)

    recommendations_df = pd.DataFrame(recommendations)
    return recommendations_df


# ä½¿ç”¨ä¾‹: ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—2.0 eVã«è¿‘ã„ææ–™ã‚’æ¨è–¦
target_bandgap = 2.0

print(f&quot;ç›®æ¨™ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—: {target_bandgap} eV&quot;)
print(&quot;\næ¨è–¦ææ–™ï¼ˆTop 10ï¼‰:\n&quot;)

recommendations = recommend_materials_by_property(
    target_property_value=target_bandgap,
    property_name='band_gap',
    embeddings=embeddings,
    materials_df=materials_df,
    n_recommendations=10,
    property_weight=0.7,
    embedding_weight=0.3
)

print(recommendations[['rank', 'material_id', 'formula', 'band_gap',
                       'property_diff', 'combined_score']].to_string(index=False))
</code></pre>
<h2>4.6 ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–å¯è¦–åŒ–</h2>
<h3>ã‚³ãƒ¼ãƒ‰ä¾‹21: Plotlyã«ã‚ˆã‚‹3D UMAP</h3>
<pre><code class="language-python">import plotly.express as px
import plotly.graph_objects as go
import umap
import pandas as pd

# 3æ¬¡å…ƒUMAP
print(&quot;3æ¬¡å…ƒUMAPã‚’å®Ÿè¡Œä¸­...&quot;)
reducer_3d = umap.UMAP(
    n_components=3,
    n_neighbors=15,
    min_dist=0.1,
    random_state=42,
    verbose=False
)

embeddings_umap_3d = reducer_3d.fit_transform(embeddings)

# DataFrameã®ä½œæˆ
df_3d = pd.DataFrame({
    'UMAP1': embeddings_umap_3d[:, 0],
    'UMAP2': embeddings_umap_3d[:, 1],
    'UMAP3': embeddings_umap_3d[:, 2],
    'Band_Gap': targets,
    'Material_ID': materials_df['material_id'].values,
    'Formula': materials_df['formula'].values,
    'Formation_Energy': materials_df['formation_energy_per_atom'].values,
    'Density': materials_df['density'].values,
    'Cluster': cluster_labels
})

# ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–3Dãƒ—ãƒ­ãƒƒãƒˆ
fig = px.scatter_3d(
    df_3d,
    x='UMAP1', y='UMAP2', z='UMAP3',
    color='Band_Gap',
    size='Density',
    hover_data=['Material_ID', 'Formula', 'Formation_Energy', 'Cluster'],
    color_continuous_scale='Viridis',
    title='Interactive 3D UMAP: Materials Space Explorer'
)

fig.update_traces(marker=dict(line=dict(width=0.5, color='DarkSlateGrey')))

fig.update_layout(
    scene=dict(
        xaxis_title='UMAP 1',
        yaxis_title='UMAP 2',
        zaxis_title='UMAP 3',
        xaxis=dict(backgroundcolor=&quot;rgb(230, 230, 230)&quot;, gridcolor=&quot;white&quot;),
        yaxis=dict(backgroundcolor=&quot;rgb(230, 230, 230)&quot;, gridcolor=&quot;white&quot;),
        zaxis=dict(backgroundcolor=&quot;rgb(230, 230, 230)&quot;, gridcolor=&quot;white&quot;),
    ),
    width=1000,
    height=800,
    font=dict(size=12)
)

fig.write_html('materials_3d_interactive.html')
print(&quot;ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–3Då¯è¦–åŒ–ã‚’ materials_3d_interactive.html ã«ä¿å­˜ã—ã¾ã—ãŸ&quot;)
fig.show()
</code></pre>
<h3>ã‚³ãƒ¼ãƒ‰ä¾‹22: Bokehã«ã‚ˆã‚‹ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–æ•£å¸ƒå›³</h3>
<pre><code class="language-python">from bokeh.plotting import figure, output_file, save
from bokeh.models import HoverTool, ColorBar, LinearColorMapper, ColumnDataSource
from bokeh.palettes import Viridis256
from bokeh.io import show
from bokeh.layouts import column, row
from bokeh.models.widgets import Select

# ã‚«ãƒ©ãƒ¼ãƒãƒƒãƒ‘ãƒ¼
color_mapper = LinearColorMapper(
    palette=Viridis256,
    low=targets.min(),
    high=targets.max()
)

# ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹
source = ColumnDataSource(data=dict(
    x=embeddings_umap[:, 0],
    y=embeddings_umap[:, 1],
    material_id=materials_df['material_id'].values,
    formula=materials_df['formula'].values,
    band_gap=targets,
    formation_energy=materials_df['formation_energy_per_atom'].values,
    density=materials_df['density'].values,
    volume=materials_df['volume'].values,
    cluster=cluster_labels
))

# ãƒ—ãƒ­ãƒƒãƒˆã®ä½œæˆ
output_file('materials_interactive.html')

p = figure(
    width=1000,
    height=800,
    title='Interactive Materials Space Explorer (UMAP)',
    tools='pan,wheel_zoom,box_zoom,box_select,lasso_select,reset,save'
)

# æ•£å¸ƒå›³
circles = p.circle(
    'x', 'y',
    size=8,
    source=source,
    fill_color={'field': 'band_gap', 'transform': color_mapper},
    fill_alpha=0.7,
    line_color='black',
    line_width=0.5
)

# ãƒ›ãƒãƒ¼ãƒ„ãƒ¼ãƒ«
hover = HoverTool(tooltips=[
    ('Material ID', '@material_id'),
    ('Formula', '@formula'),
    ('Band Gap', '@band_gap{0.00} eV'),
    ('Formation E', '@formation_energy{0.00} eV/atom'),
    ('Density', '@density{0.00} g/cmÂ³'),
    ('Volume', '@volume{0.0} Å²'),
    ('Cluster', '@cluster')
])
p.add_tools(hover)

# ã‚«ãƒ©ãƒ¼ãƒãƒ¼
color_bar = ColorBar(
    color_mapper=color_mapper,
    label_standoff=12,
    title='Band Gap (eV)',
    location=(0, 0)
)
p.add_layout(color_bar, 'right')

# è»¸ãƒ©ãƒ™ãƒ«
p.xaxis.axis_label = 'UMAP 1'
p.yaxis.axis_label = 'UMAP 2'
p.title.text_font_size = '16pt'
p.xaxis.axis_label_text_font_size = '14pt'
p.yaxis.axis_label_text_font_size = '14pt'

save(p)
print(&quot;ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–UMAPã‚’ materials_interactive.html ã«ä¿å­˜ã—ã¾ã—ãŸ&quot;)
show(p)
</code></pre>
<h3>ã‚³ãƒ¼ãƒ‰ä¾‹23: Dashã«ã‚ˆã‚‹ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰</h3>
<pre><code class="language-python"># Dashã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼ˆåˆå›ã®ã¿ï¼‰
# !pip install dash

&quot;&quot;&quot;
import dash
from dash import dcc, html
from dash.dependencies import Input, Output
import plotly.express as px
import plotly.graph_objects as go
import pandas as pd

# Dashã‚¢ãƒ—ãƒªã®ä½œæˆ
app = dash.Dash(__name__)

# ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®æº–å‚™
df_dash = pd.DataFrame({
    'umap1': embeddings_umap[:, 0],
    'umap2': embeddings_umap[:, 1],
    'material_id': materials_df['material_id'].values,
    'formula': materials_df['formula'].values,
    'band_gap': targets,
    'formation_energy': materials_df['formation_energy_per_atom'].values,
    'density': materials_df['density'].values,
    'cluster': cluster_labels
})

# ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ
app.layout = html.Div([
    html.H1('Materials Space Explorer Dashboard'),

    html.Div([
        html.Label('Color by:'),
        dcc.Dropdown(
            id='color-dropdown',
            options=[
                {'label': 'Band Gap', 'value': 'band_gap'},
                {'label': 'Formation Energy', 'value': 'formation_energy'},
                {'label': 'Density', 'value': 'density'},
                {'label': 'Cluster', 'value': 'cluster'}
            ],
            value='band_gap'
        ),
    ], style={'width': '30%', 'display': 'inline-block'}),

    dcc.Graph(id='umap-scatter'),

    html.Div(id='material-info')
])

# ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯
@app.callback(
    Output('umap-scatter', 'figure'),
    Input('color-dropdown', 'value')
)
def update_scatter(color_by):
    fig = px.scatter(
        df_dash,
        x='umap1',
        y='umap2',
        color=color_by,
        hover_data=['material_id', 'formula', 'band_gap', 'formation_energy'],
        color_continuous_scale='Viridis',
        title=f'UMAP colored by {color_by}'
    )

    fig.update_traces(marker=dict(size=8, line=dict(width=0.5, color='black')))

    return fig

# ã‚¢ãƒ—ãƒªã®å®Ÿè¡Œ
if __name__ == '__main__':
    app.run_server(debug=True)
&quot;&quot;&quot;

print(&quot;Dashãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã®ã‚³ãƒ¼ãƒ‰ä¾‹ã‚’è¡¨ç¤ºã—ã¾ã—ãŸ&quot;)
print(&quot;ã‚³ãƒ¡ãƒ³ãƒˆã‚’å¤–ã—ã¦å®Ÿè¡Œã—ã¦ãã ã•ã„&quot;)
</code></pre>
<h2>4.7 é«˜åº¦ãªåˆ†æã¨å¿œç”¨</h2>
<h3>ã‚³ãƒ¼ãƒ‰ä¾‹24: ææ–™ç©ºé–“ã®ãƒœãƒ­ãƒã‚¤åˆ†å‰²</h3>
<pre><code class="language-python">from scipy.spatial import Voronoi, voronoi_plot_2d
import matplotlib.pyplot as plt
import numpy as np

# ã‚µãƒ–ã‚»ãƒƒãƒˆã§ãƒœãƒ­ãƒã‚¤å›³ã‚’ä½œæˆï¼ˆè¨ˆç®—é‡å‰Šæ¸›ï¼‰
subset_size = 100
subset_indices = np.random.choice(len(embeddings_umap), subset_size, replace=False)

points = embeddings_umap[subset_indices]
targets_subset = targets[subset_indices]

# ãƒœãƒ­ãƒã‚¤å›³ã®è¨ˆç®—
vor = Voronoi(points)

# ãƒ—ãƒ­ãƒƒãƒˆ
fig, ax = plt.subplots(figsize=(14, 12))

# ãƒœãƒ­ãƒã‚¤ã‚»ãƒ«
voronoi_plot_2d(vor, ax=ax, show_vertices=False, line_colors='gray',
                line_width=1, line_alpha=0.6, point_size=0)

# ææ–™ç‚¹
scatter = ax.scatter(points[:, 0], points[:, 1],
                     c=targets_subset, cmap='viridis',
                     s=100, alpha=0.8, edgecolors='black', linewidth=1.5,
                     zorder=5)

ax.set_xlabel('UMAP 1', fontsize=14, fontweight='bold')
ax.set_ylabel('UMAP 2', fontsize=14, fontweight='bold')
ax.set_title('Voronoi Tessellation of Materials Space',
             fontsize=16, fontweight='bold')

cbar = plt.colorbar(scatter, ax=ax)
cbar.set_label('Band Gap (eV)', fontsize=12, fontweight='bold')

# è»¸ã®ç¯„å›²ã‚’åˆ¶é™ï¼ˆç„¡é™é ç‚¹ã®é™¤å¤–ï¼‰
ax.set_xlim([points[:, 0].min() - 1, points[:, 0].max() + 1])
ax.set_ylim([points[:, 1].min() - 1, points[:, 1].max() + 1])

plt.tight_layout()
plt.savefig('voronoi_tessellation.png', dpi=300, bbox_inches='tight')
print(&quot;ãƒœãƒ­ãƒã‚¤åˆ†å‰²ã‚’ voronoi_tessellation.png ã«ä¿å­˜ã—ã¾ã—ãŸ&quot;)
plt.show()
</code></pre>
<h3>ã‚³ãƒ¼ãƒ‰ä¾‹25: ç‰¹æ€§å‹¾é…ã®å¯è¦–åŒ–</h3>
<pre><code class="language-python">import matplotlib.pyplot as plt
import numpy as np
from scipy.interpolate import griddata

# ã‚°ãƒªãƒƒãƒ‰ã®ä½œæˆ
grid_x, grid_y = np.mgrid[
    embeddings_umap[:, 0].min():embeddings_umap[:, 0].max():100j,
    embeddings_umap[:, 1].min():embeddings_umap[:, 1].max():100j
]

# è£œé–“
grid_z = griddata(
    embeddings_umap,
    targets,
    (grid_x, grid_y),
    method='cubic'
)

# ãƒ—ãƒ­ãƒƒãƒˆ
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 7))

# ç­‰é«˜ç·šå›³
contour = ax1.contourf(grid_x, grid_y, grid_z, levels=20, cmap='viridis', alpha=0.8)
ax1.scatter(embeddings_umap[:, 0], embeddings_umap[:, 1],
            c='white', s=5, alpha=0.5, edgecolors='none')
ax1.set_xlabel('UMAP 1', fontsize=14, fontweight='bold')
ax1.set_ylabel('UMAP 2', fontsize=14, fontweight='bold')
ax1.set_title('Band Gap Contour Map', fontsize=16, fontweight='bold')
cbar1 = plt.colorbar(contour, ax=ax1)
cbar1.set_label('Band Gap (eV)', fontsize=12, fontweight='bold')

# å‹¾é…ãƒ™ã‚¯ãƒˆãƒ«
gradient_y, gradient_x = np.gradient(grid_z)

# ã‚µãƒ–ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆçŸ¢å°ã®å¯†åº¦èª¿æ•´ï¼‰
skip = 5
ax2.contourf(grid_x, grid_y, grid_z, levels=20, cmap='viridis', alpha=0.6)
ax2.quiver(grid_x[::skip, ::skip], grid_y[::skip, ::skip],
           gradient_x[::skip, ::skip], gradient_y[::skip, ::skip],
           color='white', alpha=0.8, scale=50)
ax2.scatter(embeddings_umap[:, 0], embeddings_umap[:, 1],
            c='black', s=5, alpha=0.3, edgecolors='none')
ax2.set_xlabel('UMAP 1', fontsize=14, fontweight='bold')
ax2.set_ylabel('UMAP 2', fontsize=14, fontweight='bold')
ax2.set_title('Band Gap Gradient Field', fontsize=16, fontweight='bold')
cbar2 = plt.colorbar(contour, ax=ax2)
cbar2.set_label('Band Gap (eV)', fontsize=12, fontweight='bold')

plt.tight_layout()
plt.savefig('property_gradient.png', dpi=300, bbox_inches='tight')
print(&quot;ç‰¹æ€§å‹¾é…ã‚’ property_gradient.png ã«ä¿å­˜ã—ã¾ã—ãŸ&quot;)
plt.show()
</code></pre>
<h3>ã‚³ãƒ¼ãƒ‰ä¾‹26: åŸ‹ã‚è¾¼ã¿ã®å®‰å®šæ€§è©•ä¾¡</h3>
<pre><code class="language-python">import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import KFold

def evaluate_embedding_stability(model, dataset, device, n_splits=5):
    &quot;&quot;&quot;
    ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã§åŸ‹ã‚è¾¼ã¿ã®å®‰å®šæ€§ã‚’è©•ä¾¡

    Parameters:
    -----------
    model : nn.Module
        ãƒ¢ãƒ‡ãƒ«ï¼ˆå†å­¦ç¿’ç”¨ï¼‰
    dataset : Dataset
        ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
    device : torch.device
        ãƒ‡ãƒã‚¤ã‚¹
    n_splits : int
        åˆ†å‰²æ•°

    Returns:
    --------
    stability_scores : list
        å®‰å®šæ€§ã‚¹ã‚³ã‚¢
    &quot;&quot;&quot;
    kfold = KFold(n_splits=n_splits, shuffle=True, random_state=42)

    embeddings_list = []

    for fold, (train_idx, val_idx) in enumerate(kfold.split(range(len(dataset)))):
        print(f&quot;Fold {fold+1}/{n_splits}&quot;)

        # çœç•¥: ã“ã“ã§å„foldã§ãƒ¢ãƒ‡ãƒ«ã‚’å†å­¦ç¿’
        # å®Ÿéš›ã«ã¯æ–°ã—ã„ãƒ¢ãƒ‡ãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆã—ã€train_idx ã§å­¦ç¿’

        # ãƒ‡ãƒ¢ç”¨: æ—¢å­˜ã®åŸ‹ã‚è¾¼ã¿ã‚’ä½¿ç”¨
        embeddings_list.append(embeddings)

    # åŸ‹ã‚è¾¼ã¿é–“ã®é¡ä¼¼åº¦ã‚’è¨ˆç®—
    from sklearn.metrics.pairwise import cosine_similarity

    similarities = []
    for i in range(len(embeddings_list)):
        for j in range(i+1, len(embeddings_list)):
            sim_matrix = cosine_similarity(embeddings_list[i], embeddings_list[j])
            # å¯¾è§’æˆåˆ†ã®å¹³å‡ï¼ˆå„ç‚¹ã®å¯¾å¿œã™ã‚‹åŸ‹ã‚è¾¼ã¿é–“ã®é¡ä¼¼åº¦ï¼‰
            sim_score = np.mean(np.diag(sim_matrix))
            similarities.append(sim_score)

    return similarities


# å®Ÿè¡Œï¼ˆãƒ‡ãƒ¢ï¼‰
print(&quot;åŸ‹ã‚è¾¼ã¿å®‰å®šæ€§è©•ä¾¡ï¼ˆãƒ‡ãƒ¢ï¼‰:&quot;)
stability_scores = evaluate_embedding_stability(model, dataset, device, n_splits=3)
print(f&quot;å¹³å‡é¡ä¼¼åº¦: {np.mean(stability_scores):.3f}&quot;)
print(f&quot;æ¨™æº–åå·®: {np.std(stability_scores):.3f}&quot;)
</code></pre>
<h3>ã‚³ãƒ¼ãƒ‰ä¾‹27: ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ¢ãƒ‡ãƒ«ã®åŸ‹ã‚è¾¼ã¿çµ±åˆ</h3>
<pre><code class="language-python">def create_ensemble_embeddings(models_list, dataset, device):
    &quot;&quot;&quot;
    è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã®åŸ‹ã‚è¾¼ã¿ã‚’çµ±åˆ

    Parameters:
    -----------
    models_list : list
        å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®ãƒªã‚¹ãƒˆ
    dataset : Dataset
        ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
    device : torch.device
        ãƒ‡ãƒã‚¤ã‚¹

    Returns:
    --------
    ensemble_embeddings : np.ndarray
        çµ±åˆã•ã‚ŒãŸåŸ‹ã‚è¾¼ã¿
    &quot;&quot;&quot;
    all_embeddings = []

    for model in models_list:
        emb, _ = extract_all_embeddings(model, dataset, device)
        all_embeddings.append(emb)

    # å¹³å‡ã‚’å–ã‚‹
    ensemble_embeddings = np.mean(all_embeddings, axis=0)

    return ensemble_embeddings


# ãƒ‡ãƒ¢: å˜ä¸€ãƒ¢ãƒ‡ãƒ«ã‚’3å›ä½¿ç”¨ï¼ˆå®Ÿéš›ã«ã¯ç•°ãªã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ï¼‰
print(&quot;ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«åŸ‹ã‚è¾¼ã¿ã®ãƒ‡ãƒ¢:&quot;)
models_list = [model, model, model]  # å®Ÿéš›ã«ã¯ç•°ãªã‚‹ãƒ¢ãƒ‡ãƒ«

ensemble_emb = create_ensemble_embeddings(models_list, dataset, device)
print(f&quot;ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«åŸ‹ã‚è¾¼ã¿ã®å½¢çŠ¶: {ensemble_emb.shape}&quot;)
</code></pre>
<h3>ã‚³ãƒ¼ãƒ‰ä¾‹28: æ™‚ç³»åˆ—çš„ãªææ–™ç©ºé–“ã®å¤‰åŒ–ï¼ˆæ‹¡å¼µæ€§ï¼‰</h3>
<pre><code class="language-python">&quot;&quot;&quot;
æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã‚„è¤‡æ•°ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®ãƒ¢ãƒ‡ãƒ«ã§ææ–™ç©ºé–“ã®å¤‰åŒ–ã‚’è¿½è·¡

def visualize_materials_space_evolution(
    embeddings_timeline,
    targets_timeline,
    timestamps
):
    '''
    æ™‚ç³»åˆ—çš„ãªææ–™ç©ºé–“ã®å¤‰åŒ–ã‚’å¯è¦–åŒ–

    Parameters:
    -----------
    embeddings_timeline : list of np.ndarray
        å„æ™‚ç‚¹ã§ã®åŸ‹ã‚è¾¼ã¿
    targets_timeline : list of np.ndarray
        å„æ™‚ç‚¹ã§ã®ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ
    timestamps : list
        ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—

    Returns:
    --------
    animation or multiple plots
    '''
    import matplotlib.animation as animation

    fig, ax = plt.subplots(figsize=(10, 8))

    def update(frame):
        ax.clear()
        embeddings = embeddings_timeline[frame]
        targets = targets_timeline[frame]

        scatter = ax.scatter(embeddings[:, 0], embeddings[:, 1],
                            c=targets, cmap='viridis', s=50, alpha=0.6)
        ax.set_title(f'Materials Space at {timestamps[frame]}')
        ax.set_xlabel('Component 1')
        ax.set_ylabel('Component 2')

        return scatter,

    anim = animation.FuncAnimation(fig, update, frames=len(timestamps),
                                  interval=500, blit=False)

    return anim
'''

print(&quot;æ™‚ç³»åˆ—å¯è¦–åŒ–ã®æ‹¡å¼µæ€§ã‚³ãƒ¼ãƒ‰ä¾‹ã‚’è¡¨ç¤ºã—ã¾ã—ãŸ&quot;)
&quot;&quot;&quot;
</code></pre>
<h3>ã‚³ãƒ¼ãƒ‰ä¾‹29: å¤–æŒ¿é ˜åŸŸã®æ¤œå‡º</h3>
<pre><code class="language-python">from sklearn.ensemble import IsolationForest
import matplotlib.pyplot as plt
import numpy as np

# å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®åŸ‹ã‚è¾¼ã¿ç¯„å›²ã‚’å­¦ç¿’
train_embeddings = embeddings[train_idx]

# Isolation Forestã§å¤–ã‚Œå€¤ï¼ˆå¤–æŒ¿é ˜åŸŸï¼‰ã‚’æ¤œå‡º
iso_forest = IsolationForest(contamination=0.1, random_state=42)
iso_forest.fit(train_embeddings)

# å…¨ãƒ‡ãƒ¼ã‚¿ã§äºˆæ¸¬
outlier_labels = iso_forest.predict(embeddings)
outlier_scores = iso_forest.score_samples(embeddings)

# ãƒ—ãƒ­ãƒƒãƒˆ
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 7))

# å¤–ã‚Œå€¤ãƒ©ãƒ™ãƒ«
colors_outlier = ['red' if label == -1 else 'blue' for label in outlier_labels]
ax1.scatter(embeddings_umap[:, 0], embeddings_umap[:, 1],
            c=colors_outlier, s=50, alpha=0.6, edgecolors='black', linewidth=0.5)
ax1.set_xlabel('UMAP 1', fontsize=14, fontweight='bold')
ax1.set_ylabel('UMAP 2', fontsize=14, fontweight='bold')
ax1.set_title('Extrapolation Region Detection (Red = Outlier)',
              fontsize=16, fontweight='bold')
ax1.grid(True, alpha=0.3)

# å¤–ã‚Œå€¤ã‚¹ã‚³ã‚¢
scatter = ax2.scatter(embeddings_umap[:, 0], embeddings_umap[:, 1],
                      c=outlier_scores, cmap='RdYlGn', s=50, alpha=0.6,
                      edgecolors='black', linewidth=0.5)
ax2.set_xlabel('UMAP 1', fontsize=14, fontweight='bold')
ax2.set_ylabel('UMAP 2', fontsize=14, fontweight='bold')
ax2.set_title('Anomaly Score (Green = Normal, Red = Outlier)',
              fontsize=16, fontweight='bold')
ax2.grid(True, alpha=0.3)
cbar = plt.colorbar(scatter, ax=ax2)
cbar.set_label('Anomaly Score', fontsize=12, fontweight='bold')

plt.tight_layout()
plt.savefig('extrapolation_detection.png', dpi=300, bbox_inches='tight')
print(&quot;å¤–æŒ¿é ˜åŸŸæ¤œå‡ºã‚’ extrapolation_detection.png ã«ä¿å­˜ã—ã¾ã—ãŸ&quot;)
plt.show()

print(f&quot;\nå¤–ã‚Œå€¤æ•°: {np.sum(outlier_labels == -1)} / {len(outlier_labels)}&quot;)
</code></pre>
<h3>ã‚³ãƒ¼ãƒ‰ä¾‹30: ç·åˆãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ</h3>
<pre><code class="language-python">import json
from datetime import datetime

def generate_comprehensive_report(
    model, dataset, embeddings, targets,
    materials_df, cluster_labels, test_predictions, test_targets
):
    &quot;&quot;&quot;
    ç·åˆçš„ãªåˆ†æãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ

    Parameters:
    -----------
    model : nn.Module
        å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«
    dataset : Dataset
        ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
    embeddings : np.ndarray
        åŸ‹ã‚è¾¼ã¿
    targets : np.ndarray
        ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ
    materials_df : pd.DataFrame
        ææ–™ãƒ‡ãƒ¼ã‚¿
    cluster_labels : np.ndarray
        ã‚¯ãƒ©ã‚¹ã‚¿ãƒ©ãƒ™ãƒ«
    test_predictions : np.ndarray
        ãƒ†ã‚¹ãƒˆäºˆæ¸¬å€¤
    test_targets : np.ndarray
        ãƒ†ã‚¹ãƒˆçœŸå€¤

    Returns:
    --------
    report : dict
        ãƒ¬ãƒãƒ¼ãƒˆè¾æ›¸
    &quot;&quot;&quot;
    from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

    # ãƒ¢ãƒ‡ãƒ«æ€§èƒ½
    mae = mean_absolute_error(test_targets, test_predictions)
    rmse = np.sqrt(mean_squared_error(test_targets, test_predictions))
    r2 = r2_score(test_targets, test_predictions)

    # åŸ‹ã‚è¾¼ã¿çµ±è¨ˆ
    embedding_stats = {
        'dimension': embeddings.shape[1],
        'mean_norm': float(np.mean(np.linalg.norm(embeddings, axis=1))),
        'std_norm': float(np.std(np.linalg.norm(embeddings, axis=1))),
    }

    # ã‚¯ãƒ©ã‚¹ã‚¿çµ±è¨ˆ
    cluster_stats = {}
    for cluster_id in np.unique(cluster_labels):
        mask = cluster_labels == cluster_id
        cluster_stats[f'cluster_{cluster_id}'] = {
            'size': int(np.sum(mask)),
            'mean_band_gap': float(np.mean(targets[mask])),
            'std_band_gap': float(np.std(targets[mask]))
        }

    # ãƒ¬ãƒãƒ¼ãƒˆ
    report = {
        'metadata': {
            'timestamp': datetime.now().isoformat(),
            'dataset_size': len(dataset),
            'model_parameters': sum(p.numel() for p in model.parameters())
        },
        'model_performance': {
            'MAE': float(mae),
            'RMSE': float(rmse),
            'R2': float(r2)
        },
        'embedding_statistics': embedding_stats,
        'cluster_statistics': cluster_stats,
        'target_statistics': {
            'mean': float(np.mean(targets)),
            'std': float(np.std(targets)),
            'min': float(np.min(targets)),
            'max': float(np.max(targets))
        }
    }

    return report


# ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
report = generate_comprehensive_report(
    model, dataset, embeddings, targets,
    materials_df, cluster_labels,
    test_predictions, test_targets
)

# JSONå½¢å¼ã§ä¿å­˜
with open('comprehensive_report.json', 'w') as f:
    json.dump(report, f, indent=2)

print(&quot;ç·åˆãƒ¬ãƒãƒ¼ãƒˆã‚’ comprehensive_report.json ã«ä¿å­˜ã—ã¾ã—ãŸ\n&quot;)
print(&quot;ãƒ¬ãƒãƒ¼ãƒˆã‚µãƒãƒªãƒ¼:&quot;)
print(json.dumps(report, indent=2)[:1000] + &quot;...&quot;)

# Markdownãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
markdown_report = f&quot;&quot;&quot;
# ææ–™ç©ºé–“ãƒãƒƒãƒ”ãƒ³ã‚° - ç·åˆãƒ¬ãƒãƒ¼ãƒˆ

ç”Ÿæˆæ—¥æ™‚: {report['metadata']['timestamp']}

## 1. ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæƒ…å ±

- ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚µã‚¤ã‚º: {report['metadata']['dataset_size']}
- ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {report['metadata']['model_parameters']:,}

## 2. ãƒ¢ãƒ‡ãƒ«æ€§èƒ½

| æŒ‡æ¨™ | å€¤ |
|------|-----|
| MAE  | {report['model_performance']['MAE']:.4f} |
| RMSE | {report['model_performance']['RMSE']:.4f} |
| RÂ²   | {report['model_performance']['R2']:.4f} |

## 3. åŸ‹ã‚è¾¼ã¿çµ±è¨ˆ

- æ¬¡å…ƒæ•°: {report['embedding_statistics']['dimension']}
- å¹³å‡ãƒãƒ«ãƒ : {report['embedding_statistics']['mean_norm']:.3f}
- ãƒãƒ«ãƒ æ¨™æº–åå·®: {report['embedding_statistics']['std_norm']:.3f}

## 4. ã‚¿ãƒ¼ã‚²ãƒƒãƒˆç‰¹æ€§çµ±è¨ˆ

| çµ±è¨ˆé‡ | å€¤ (eV) |
|--------|---------|
| å¹³å‡   | {report['target_statistics']['mean']:.3f} |
| æ¨™æº–åå·® | {report['target_statistics']['std']:.3f} |
| æœ€å°å€¤ | {report['target_statistics']['min']:.3f} |
| æœ€å¤§å€¤ | {report['target_statistics']['max']:.3f} |

## 5. ã‚¯ãƒ©ã‚¹ã‚¿åˆ†æ

&quot;&quot;&quot;

for cluster_id, stats in report['cluster_statistics'].items():
    markdown_report += f&quot;- **{cluster_id}**: ã‚µã‚¤ã‚º={stats['size']}, å¹³å‡ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—={stats['mean_band_gap']:.3f} eV\n&quot;

markdown_report += &quot;&quot;&quot;

## 6. ç”Ÿæˆã•ã‚ŒãŸå¯è¦–åŒ–

- `training_curve.png`: å­¦ç¿’æ›²ç·š
- `test_evaluation.png`: ãƒ†ã‚¹ãƒˆè©•ä¾¡
- `pca_2d_projection.png`: PCA 2Då°„å½±
- `umap_2d_projection.png`: UMAP 2Då°„å½±
- `tsne_2d_projection.png`: t-SNE 2Då°„å½±
- `clustering_analysis.png`: ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°åˆ†æ
- `materials_3d_interactive.html`: ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–3Då¯è¦–åŒ–
- `materials_interactive.html`: ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–2Då¯è¦–åŒ–

## 7. ã¾ã¨ã‚

æœ¬åˆ†æã§ã¯ã€GNNã«ã‚ˆã‚‹ææ–™è¡¨ç¾å­¦ç¿’ã¨æ¬¡å…ƒå‰Šæ¸›ã‚’çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã§ã€
é«˜æ¬¡å…ƒã®ææ–™ç©ºé–“ã‚’åŠ¹æœçš„ã«å¯è¦–åŒ–ã—ã€ææ–™é–“ã®é¡ä¼¼æ€§ã‚„ç‰¹æ€§ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’
æ˜ã‚‰ã‹ã«ã™ã‚‹ã“ã¨ãŒã§ãã¾ã—ãŸã€‚

&quot;&quot;&quot;

# Markdownãƒ¬ãƒãƒ¼ãƒˆã®ä¿å­˜
with open('comprehensive_report.md', 'w') as f:
    f.write(markdown_report)

print(&quot;\nMarkdownãƒ¬ãƒãƒ¼ãƒˆã‚’ comprehensive_report.md ã«ä¿å­˜ã—ã¾ã—ãŸ&quot;)
</code></pre>
<h2>4.8 ã¾ã¨ã‚</h2>
<p>æœ¬ç« ã§ã¯ã€GNNã¨æ¬¡å…ƒå‰Šæ¸›ã‚’çµ„ã¿åˆã‚ã›ãŸå®Ÿè·µçš„ãªææ–™ãƒãƒƒãƒ”ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ã—ã¾ã—ãŸã€‚</p>
<h3>å®Ÿè£…ã—ãŸæ©Ÿèƒ½</h3>
<table>
<thead>
<tr>
<th>æ©Ÿèƒ½</th>
<th>ã‚³ãƒ¼ãƒ‰ä¾‹æ•°</th>
<th>ä¸»ãªå†…å®¹</th>
</tr>
</thead>
<tbody>
<tr>
<td>ãƒ‡ãƒ¼ã‚¿åé›†ãƒ»æº–å‚™</td>
<td>ä¾‹1-6</td>
<td>MP APIã€ã‚°ãƒ©ãƒ•å¤‰æ›ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ</td>
</tr>
<tr>
<td>ãƒ¢ãƒ‡ãƒ«å­¦ç¿’</td>
<td>ä¾‹7-10</td>
<td>CGCNNã€å­¦ç¿’ãƒ«ãƒ¼ãƒ—ã€è©•ä¾¡</td>
</tr>
<tr>
<td>åŸ‹ã‚è¾¼ã¿æŠ½å‡ºãƒ»æ¬¡å…ƒå‰Šæ¸›</td>
<td>ä¾‹11-15</td>
<td>PCAã€UMAPã€t-SNEã€æ¯”è¼ƒ</td>
</tr>
<tr>
<td>ææ–™ç©ºé–“åˆ†æ</td>
<td>ä¾‹16-20</td>
<td>ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã€è¿‘å‚æ¢ç´¢ã€æ¨è–¦</td>
</tr>
<tr>
<td>ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–å¯è¦–åŒ–</td>
<td>ä¾‹21-23</td>
<td>Plotly 3Dã€Bokehã€Dash</td>
</tr>
<tr>
<td>é«˜åº¦ãªåˆ†æ</td>
<td>ä¾‹24-30</td>
<td>ãƒœãƒ­ãƒã‚¤ã€å‹¾é…ã€å¤–æŒ¿ã€ãƒ¬ãƒãƒ¼ãƒˆ</td>
</tr>
</tbody>
</table>
<h3>ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹</h3>
<ol>
<li><strong>ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†</strong>: æ¨™æº–åŒ–ã€æ¬ æå€¤å‡¦ç†ã€å¤–ã‚Œå€¤é™¤å»</li>
<li><strong>ãƒ¢ãƒ‡ãƒ«å­¦ç¿’</strong>: Early Stoppingã€å­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°ã€æ­£å‰‡åŒ–</li>
<li><strong>æ¬¡å…ƒå‰Šæ¸›</strong>: è¤‡æ•°æ‰‹æ³•ã®æ¯”è¼ƒã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°</li>
<li><strong>å¯è¦–åŒ–</strong>: ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–æ€§ã€è¤‡æ•°è¦–ç‚¹ã€èª¬æ˜æ€§</li>
<li><strong>å†ç¾æ€§</strong>: ä¹±æ•°ã‚·ãƒ¼ãƒ‰å›ºå®šã€è¨­å®šä¿å­˜ã€ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†</li>
</ol>
<h3>å¿œç”¨å¯èƒ½æ€§</h3>
<ul>
<li><strong>ææ–™æ¢ç´¢</strong>: ç›®æ¨™ç‰¹æ€§ã‚’æŒã¤ææ–™ã®æ¨è–¦</li>
<li><strong>ç‰¹æ€§äºˆæ¸¬</strong>: æ–°è¦ææ–™ã®ç‰¹æ€§äºˆæ¸¬</li>
<li><strong>æ§‹é€ -ç‰¹æ€§é–¢ä¿‚</strong>: ææ–™ç©ºé–“ã§ã®æ§‹é€ ã¨ç‰¹æ€§ã®é–¢ä¿‚è§£æ˜</li>
<li><strong>å®Ÿé¨“è¨ˆç”»</strong>: æ¬¡ã«åˆæˆã™ã¹ãææ–™ã®ææ¡ˆ</li>
</ul>
<h3>ä»Šå¾Œã®ç™ºå±•</h3>
<ul>
<li><strong>ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯å­¦ç¿’</strong>: è¤‡æ•°ç‰¹æ€§ã®åŒæ™‚äºˆæ¸¬</li>
<li><strong>è»¢ç§»å­¦ç¿’</strong>: å°è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¸ã®é©ç”¨</li>
<li><strong>èƒ½å‹•å­¦ç¿’</strong>: åŠ¹ç‡çš„ãªãƒ‡ãƒ¼ã‚¿åé›†æˆ¦ç•¥</li>
<li><strong>èª¬æ˜å¯èƒ½AI</strong>: GNNäºˆæ¸¬ã®è§£é‡ˆæ€§å‘ä¸Š</li>
</ul>
<hr />
<p><strong>å‰ç« </strong>: <a href="chapter-3.html">ç¬¬3ç« ï¼šGNNã«ã‚ˆã‚‹ææ–™è¡¨ç¾å­¦ç¿’</a></p>
<p><strong>ã‚·ãƒªãƒ¼ã‚ºãƒˆãƒƒãƒ—</strong>: <a href="index.html">ææ–™ç‰¹æ€§ãƒãƒƒãƒ”ãƒ³ã‚°å…¥é–€</a></p>
<h2>ã•ã‚‰ã«å­¦ã¶ãŸã‚ã«</h2>
<h3>æ¨è–¦æ–‡çŒ®</h3>
<ol>
<li><strong>GNN for Materials</strong>: "Graph Networks as a Universal Machine Learning Framework for Molecules and Crystals" (Xie &amp; Grossman, 2018)</li>
<li><strong>UMAP</strong>: "UMAP: Uniform Manifold Approximation and Projection" (McInnes et al., 2018)</li>
<li><strong>Materials Informatics</strong>: "Materials Informatics" (Ramprasad et al., 2017)</li>
</ol>
<h3>é–¢é€£ãƒªã‚½ãƒ¼ã‚¹</h3>
<ul>
<li><a href="https://materialsproject.org/">Materials Project</a></li>
<li><a href="https://pytorch-geometric.readthedocs.io/">PyTorch Geometric</a></li>
<li><a href="https://umap-learn.readthedocs.io/">UMAP Documentation</a></li>
</ul>
<p>ãŠç–²ã‚Œæ§˜ã§ã—ãŸï¼æœ¬ã‚·ãƒªãƒ¼ã‚ºã‚’é€šã˜ã¦ã€ææ–™ç‰¹æ€§ãƒãƒƒãƒ”ãƒ³ã‚°ã®åŸºç¤ã‹ã‚‰å®Ÿè·µã¾ã§ã‚’å­¦ã³ã¾ã—ãŸã€‚</p><div class="navigation">
    <a href="index.html" class="nav-button">ã‚·ãƒªãƒ¼ã‚ºç›®æ¬¡ã«æˆ»ã‚‹</a>
</div>
    </main>

    
    <section class="disclaimer">
        <h3>å…è²¬äº‹é …</h3>
        <ul>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯æ•™è‚²ãƒ»ç ”ç©¶ãƒ»æƒ…å ±æä¾›ã®ã¿ã‚’ç›®çš„ã¨ã—ã¦ãŠã‚Šã€å°‚é–€çš„ãªåŠ©è¨€(æ³•å¾‹ãƒ»ä¼šè¨ˆãƒ»æŠ€è¡“çš„ä¿è¨¼ãªã©)ã‚’æä¾›ã™ã‚‹ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŠã‚ˆã³ä»˜éšã™ã‚‹ã‚³ãƒ¼ãƒ‰ä¾‹ã¯ã€Œç¾çŠ¶æœ‰å§¿(AS IS)ã€ã§æä¾›ã•ã‚Œã€æ˜ç¤ºã¾ãŸã¯é»™ç¤ºã‚’å•ã‚ãšã€å•†å“æ€§ã€ç‰¹å®šç›®çš„é©åˆæ€§ã€æ¨©åˆ©éä¾µå®³ã€æ­£ç¢ºæ€§ãƒ»å®Œå…¨æ€§ã€å‹•ä½œãƒ»å®‰å…¨æ€§ç­‰ã„ã‹ãªã‚‹ä¿è¨¼ã‚‚ã—ã¾ã›ã‚“ã€‚</li>
            <li>å¤–éƒ¨ãƒªãƒ³ã‚¯ã€ç¬¬ä¸‰è€…ãŒæä¾›ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ»ãƒ„ãƒ¼ãƒ«ãƒ»ãƒ©ã‚¤ãƒ–ãƒ©ãƒªç­‰ã®å†…å®¹ãƒ»å¯ç”¨æ€§ãƒ»å®‰å…¨æ€§ã«ã¤ã„ã¦ã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯ä¸€åˆ‡ã®è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®åˆ©ç”¨ãƒ»å®Ÿè¡Œãƒ»è§£é‡ˆã«ã‚ˆã‚Šç›´æ¥çš„ãƒ»é–“æ¥çš„ãƒ»ä»˜éšçš„ãƒ»ç‰¹åˆ¥ãƒ»çµæœçš„ãƒ»æ‡²ç½°çš„æå®³ãŒç”Ÿã˜ãŸå ´åˆã§ã‚‚ã€é©ç”¨æ³•ã§è¨±å®¹ã•ã‚Œã‚‹æœ€å¤§é™ã®ç¯„å›²ã§ã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å†…å®¹ã¯ã€äºˆå‘Šãªãå¤‰æ›´ãƒ»æ›´æ–°ãƒ»æä¾›åœæ­¢ã•ã‚Œã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®è‘—ä½œæ¨©ãƒ»ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯æ˜è¨˜ã•ã‚ŒãŸæ¡ä»¶(ä¾‹: CC BY 4.0)ã«å¾“ã„ã¾ã™ã€‚å½“è©²ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯é€šå¸¸ã€ç„¡ä¿è¨¼æ¡é …ã‚’å«ã¿ã¾ã™ã€‚</li>
        </ul>
    </section>

<footer>
        <p><strong>ä½œæˆè€…</strong>: AI Terakoya Content Team</p>
        <p><strong>ãƒãƒ¼ã‚¸ãƒ§ãƒ³</strong>: 1.0 | <strong>ä½œæˆæ—¥</strong>: 2025-10-17</p>
        <p><strong>ãƒ©ã‚¤ã‚»ãƒ³ã‚¹</strong>: Creative Commons BY 4.0</p>
        <p>Â© 2025 AI Terakoya. All rights reserved.</p>
    </footer>
</body>
</html>
