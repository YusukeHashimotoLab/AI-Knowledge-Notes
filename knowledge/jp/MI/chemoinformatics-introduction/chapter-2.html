<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Á¨¨2Á´†ÔºöQSAR/QSPRÂÖ•ÈñÄ - Áâ©ÊÄß‰∫àÊ∏¨„ÅÆÂü∫Á§é - AI Terakoya</title>

    <style>
        :root {
            --color-primary: #2c3e50;
            --color-primary-dark: #1a252f;
            --color-accent: #7b2cbf;
            --color-accent-light: #9d4edd;
            --color-text: #2d3748;
            --color-text-light: #4a5568;
            --color-bg: #ffffff;
            --color-bg-alt: #f7fafc;
            --color-border: #e2e8f0;
            --color-code-bg: #f8f9fa;
            --color-link: #3182ce;
            --color-link-hover: #2c5aa0;

            --spacing-xs: 0.5rem;
            --spacing-sm: 1rem;
            --spacing-md: 1.5rem;
            --spacing-lg: 2rem;
            --spacing-xl: 3rem;

            --font-body: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            --font-mono: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;

            --border-radius: 8px;
            --box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: var(--font-body);
            line-height: 1.7;
            color: var(--color-text);
            background-color: var(--color-bg);
            font-size: 16px;
        }

        header {
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            padding: var(--spacing-xl) var(--spacing-md);
            margin-bottom: var(--spacing-xl);
            box-shadow: var(--box-shadow);
        }

        .header-content {
            max-width: 900px;
            margin: 0 auto;
        }

        h1 {
            font-size: 2rem;
            font-weight: 700;
            margin-bottom: var(--spacing-sm);
            line-height: 1.2;
        }

        .subtitle {
            font-size: 1.1rem;
            opacity: 0.95;
            font-weight: 400;
            margin-bottom: var(--spacing-md);
        }

        .meta {
            display: flex;
            flex-wrap: wrap;
            gap: var(--spacing-md);
            font-size: 0.9rem;
            opacity: 0.9;
        }

        .meta-item {
            display: flex;
            align-items: center;
            gap: 0.3rem;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 0 var(--spacing-md) var(--spacing-xl);
        }

        h2 {
            font-size: 1.75rem;
            color: var(--color-primary);
            margin-top: var(--spacing-xl);
            margin-bottom: var(--spacing-md);
            padding-bottom: var(--spacing-xs);
            border-bottom: 3px solid var(--color-accent);
        }

        h3 {
            font-size: 1.4rem;
            color: var(--color-primary);
            margin-top: var(--spacing-lg);
            margin-bottom: var(--spacing-sm);
        }

        h4 {
            font-size: 1.1rem;
            color: var(--color-primary-dark);
            margin-top: var(--spacing-md);
            margin-bottom: var(--spacing-sm);
        }

        p {
            margin-bottom: var(--spacing-md);
            color: var(--color-text);
        }

        a {
            color: var(--color-link);
            text-decoration: none;
            transition: color 0.2s;
        }

        a:hover {
            color: var(--color-link-hover);
            text-decoration: underline;
        }

        ul, ol {
            margin-left: var(--spacing-lg);
            margin-bottom: var(--spacing-md);
        }

        li {
            margin-bottom: var(--spacing-xs);
            color: var(--color-text);
        }

        pre {
            background-color: var(--color-code-bg);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            overflow-x: auto;
            margin-bottom: var(--spacing-md);
            font-family: var(--font-mono);
            font-size: 0.9rem;
            line-height: 1.5;
        }

        code {
            font-family: var(--font-mono);
            font-size: 0.9em;
            background-color: var(--color-code-bg);
            padding: 0.2em 0.4em;
            border-radius: 3px;
        }

        pre code {
            background-color: transparent;
            padding: 0;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: var(--spacing-md);
            font-size: 0.95rem;
        }

        th, td {
            border: 1px solid var(--color-border);
            padding: var(--spacing-sm);
            text-align: left;
        }

        th {
            background-color: var(--color-bg-alt);
            font-weight: 600;
            color: var(--color-primary);
        }

        blockquote {
            border-left: 4px solid var(--color-accent);
            padding-left: var(--spacing-md);
            margin: var(--spacing-md) 0;
            color: var(--color-text-light);
            font-style: italic;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        .mermaid {
            text-align: center;
            margin: var(--spacing-lg) 0;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        details {
            background-color: var(--color-bg-alt);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            margin-bottom: var(--spacing-md);
        }

        summary {
            cursor: pointer;
            font-weight: 600;
            color: var(--color-primary);
            user-select: none;
            padding: var(--spacing-xs);
            margin: calc(-1 * var(--spacing-md));
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        summary:hover {
            background-color: rgba(123, 44, 191, 0.1);
        }

        details[open] summary {
            margin-bottom: var(--spacing-md);
            border-bottom: 1px solid var(--color-border);
        }

        .learning-objectives {
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
            padding: var(--spacing-lg);
            border-radius: var(--border-radius);
            border-left: 4px solid var(--color-accent);
            margin-bottom: var(--spacing-xl);
        }

        .learning-objectives h2 {
            margin-top: 0;
            border-bottom: none;
        }

        .navigation {
            display: flex;
            justify-content: space-between;
            gap: var(--spacing-md);
            margin: var(--spacing-xl) 0;
            padding-top: var(--spacing-lg);
            border-top: 2px solid var(--color-border);
        }

        .nav-button {
            flex: 1;
            padding: var(--spacing-md);
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            border-radius: var(--border-radius);
            text-align: center;
            font-weight: 600;
            transition: transform 0.2s, box-shadow 0.2s;
            box-shadow: var(--box-shadow);
        }

        .nav-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
            text-decoration: none;
        }

        footer {
            margin-top: var(--spacing-xl);
            padding: var(--spacing-lg) var(--spacing-md);
            background-color: var(--color-bg-alt);
            border-top: 1px solid var(--color-border);
            text-align: center;
            font-size: 0.9rem;
            color: var(--color-text-light);
        }

        @media (max-width: 768px) {
            h1 {
                font-size: 1.5rem;
            }

            h2 {
                font-size: 1.4rem;
            }

            h3 {
                font-size: 1.2rem;
            }

            .meta {
                font-size: 0.85rem;
            }

            .navigation {
                flex-direction: column;
            }

            table {
                font-size: 0.85rem;
            }

            th, td {
                padding: var(--spacing-xs);
            }
        }
    </style>

    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
        mermaid.initialize({ startOnLoad: true, theme: 'default' });
    </script>

    <!-- MathJax for LaTeX equation rendering -->
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\(', '\)']],
                displayMath: [['$$', '$$'], ['\[', '\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
                ignoreHtmlClass: 'mermaid'
            }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" async></script>
</head>
<body>
    <header>
        <div class="header-content">
            <h1>QSAR/QSPRÂÖ•ÈñÄ - Áâ©ÊÄß‰∫àÊ∏¨„ÅÆÂü∫Á§é</h1>
            <p class="subtitle"></p>
            <div class="meta">
                <span class="meta-item">üìñ Ë™≠‰∫ÜÊôÇÈñì: 25-30ÂàÜ</span>
                <span class="meta-item">üìä Èõ£ÊòìÂ∫¶: ÂàùÁ¥ö„Äú‰∏≠Á¥ö</span>
                <span class="meta-item">üíª „Ç≥„Éº„Éâ‰æã: 12ÂÄã</span>
                <span class="meta-item">üìù ÊºîÁøíÂïèÈ°å: 4Âïè</span>
            </div>
        </div>
    </header>

    <main class="container">
<h1>Á¨¨2Á´†ÔºöQSAR/QSPRÂÖ•ÈñÄ - Áâ©ÊÄß‰∫àÊ∏¨„ÅÆÂü∫Á§é</h1>
<h2>„Åì„ÅÆÁ´†„ÅßÂ≠¶„Å∂„Åì„Å®</h2>
<p>„Åì„ÅÆÁ´†„Åß„ÅØ„ÄÅÂàÜÂ≠êË®òËø∞Â≠ê„ÅÆË®àÁÆó„Å®QSAR/QSPR„É¢„Éá„É™„É≥„Ç∞„ÅÆÂü∫Á§é„ÇíÂ≠¶„Å≥„Åæ„Åô„ÄÇÂàÜÂ≠êÊßãÈÄ†„Åã„ÇâÁâ©ÊÄß„Çí‰∫àÊ∏¨„Åô„ÇãÊäÄË°ì„ÅØ„ÄÅÂâµËñ¨„ÇÑÊùêÊñôÈñãÁô∫„ÅÆÂäπÁéáÂåñ„Å´‰∏çÂèØÊ¨†„Åß„Åô„ÄÇ</p>
<h3>Â≠¶ÁøíÁõÆÊ®ô</h3>
<ul>
<li>‚úÖ 1D/2D/3DÂàÜÂ≠êË®òËø∞Â≠ê„ÅÆÁ®ÆÈ°û„Å®‰Ωø„ÅÑÂàÜ„Åë„ÇíÁêÜËß£„Åó„Å¶„ÅÑ„Çã</li>
<li>‚úÖ mordred„ÅßÂåÖÊã¨ÁöÑ„Å™Ë®òËø∞Â≠ê„ÇíË®àÁÆó„Åß„Åç„Çã</li>
<li>‚úÖ QSAR/QSPR„É¢„Éá„É´„ÇíÊßãÁØâ„Åó„ÄÅË©ï‰æ°„Åß„Åç„Çã</li>
<li>‚úÖ ÁâπÂæ¥ÈáèÈÅ∏Êäû„Å®Ëß£Èáà„Å´„Çà„Çä„ÄÅÊßãÈÄ†-Áâ©ÊÄßÁõ∏Èñ¢„ÇíÁêÜËß£„Åß„Åç„Çã</li>
<li>‚úÖ Ê∫∂Ëß£Â∫¶‰∫àÊ∏¨„Å™„Å©ÂÆü„Éá„Éº„Çø„Å´Ê©üÊ¢∞Â≠¶Áøí„ÇíÈÅ©Áî®„Åß„Åç„Çã</li>
</ul>
<hr />
<h2>2.1 ÂàÜÂ≠êË®òËø∞Â≠ê„ÅÆÂü∫Á§é</h2>
<p><strong>ÂàÜÂ≠êË®òËø∞Â≠êÔºàMolecular DescriptorÔºâ</strong>„ÅØ„ÄÅÂàÜÂ≠êÊßãÈÄ†„ÇíÊï∞ÂÄ§Âåñ„Åó„Åü„ÇÇ„ÅÆ„Åß„ÄÅÊ©üÊ¢∞Â≠¶Áøí„É¢„Éá„É´„ÅÆÂÖ•Âäõ„Å®„Åó„Å¶‰ΩøÁî®„Åï„Çå„Åæ„Åô„ÄÇ</p>
<div class="mermaid">
graph TD
    A[ÂàÜÂ≠êÊßãÈÄ†] --> B[ÂàÜÂ≠êË®òËø∞Â≠êË®àÁÆó]
    B --> C[1DË®òËø∞Â≠ê]
    B --> D[2DË®òËø∞Â≠ê]
    B --> E[3DË®òËø∞Â≠ê]

    C --> F[ÂàÜÂ≠êÈáè„ÄÅlogP„ÄÅTPSA]
    D --> G[ÊåáÁ¥ã„ÄÅ„Ç∞„É©„ÉïË®òËø∞Â≠ê]
    E --> H[Á´ã‰ΩìÈÖçÂ∫ß‰æùÂ≠òË®òËø∞Â≠ê]

    F --> I[Ê©üÊ¢∞Â≠¶Áøí„É¢„Éá„É´]
    G --> I
    H --> I
    I --> J[Áâ©ÊÄß‰∫àÊ∏¨]

    style A fill:#e3f2fd
    style I fill:#4CAF50,color:#fff
    style J fill:#FF9800,color:#fff
</div>

<h3>2.1.1 1DË®òËø∞Â≠êÔºöÂàÜÂ≠êÂÖ®‰Ωì„ÅÆÊÄßË≥™</h3>
<p>1DË®òËø∞Â≠ê„ÅØ„ÄÅÂàÜÂ≠êÊßãÈÄ†„Å´‰æùÂ≠ò„Åó„Å™„ÅÑÂü∫Êú¨ÁöÑ„Å™ÊÄßË≥™„ÇíË°®„Åó„Åæ„Åô„ÄÇ</p>
<p><strong>‰∏ªË¶Å„Å™1DË®òËø∞Â≠ê</strong>Ôºö</p>
<table>
<thead>
<tr>
<th>Ë®òËø∞Â≠ê</th>
<th>Ë™¨Êòé</th>
<th>Áî®ÈÄî</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>ÂàÜÂ≠êÈáèÔºàMWÔºâ</strong></td>
<td>ÂàÜÂ≠ê„ÅÆË≥™Èáè</td>
<td>ËÜúÈÄèÈÅéÊÄß‰∫àÊ∏¨</td>
</tr>
<tr>
<td><strong>logP</strong></td>
<td>ËÑÇÊ∫∂ÊÄßÔºàÊ∞¥-„Ç™„ÇØ„Çø„Éé„Éº„É´ÂàÜÈÖç‰øÇÊï∞Ôºâ</td>
<td>Âê∏ÂèéÊÄß‰∫àÊ∏¨</td>
</tr>
<tr>
<td><strong>TPSA</strong></td>
<td>Ê•µÊÄßË°®Èù¢Á©ç</td>
<td>Ë°ÄÊ∂≤ËÑ≥Èñ¢ÈñÄÈÄèÈÅéÊÄß</td>
</tr>
<tr>
<td><strong>HBA/HBD</strong></td>
<td>Ê∞¥Á¥†ÁµêÂêàÂèóÂÆπ‰Ωì/‰æõ‰∏é‰ΩìÊï∞</td>
<td>Lipinski„É´„Éº„É´</td>
</tr>
<tr>
<td><strong>ÂõûËª¢ÂèØËÉΩÁµêÂêàÊï∞</strong></td>
<td>ÂàÜÂ≠ê„ÅÆÊüîËªüÊÄß</td>
<td>ÁµêÂêàË¶™ÂíåÊÄß</td>
</tr>
</tbody>
</table>
<h4>„Ç≥„Éº„Éâ‰æã1: Âü∫Êú¨ÁöÑ„Å™1DË®òËø∞Â≠ê„ÅÆË®àÁÆó</h4>
<pre><code class="language-python">from rdkit import Chem
from rdkit.Chem import Descriptors
import pandas as pd

# „Çµ„É≥„Éó„É´ÂåªËñ¨ÂìÅ
drugs = {
    &quot;Aspirin&quot;: &quot;CC(=O)Oc1ccccc1C(=O)O&quot;,
    &quot;Ibuprofen&quot;: &quot;CC(C)Cc1ccc(cc1)C(C)C(=O)O&quot;,
    &quot;Paracetamol&quot;: &quot;CC(=O)Nc1ccc(O)cc1&quot;,
    &quot;Caffeine&quot;: &quot;CN1C=NC2=C1C(=O)N(C(=O)N2C)C&quot;
}

# Ë®òËø∞Â≠êË®àÁÆó
data = []
for name, smiles in drugs.items():
    mol = Chem.MolFromSmiles(smiles)
    data.append({
        'Name': name,
        'MW': Descriptors.MolWt(mol),
        'LogP': Descriptors.MolLogP(mol),
        'TPSA': Descriptors.TPSA(mol),
        'HBA': Descriptors.NumHAcceptors(mol),
        'HBD': Descriptors.NumHDonors(mol),
        'RotBonds': Descriptors.NumRotatableBonds(mol)
    })

df = pd.DataFrame(data)
print(df.to_string(index=False))
</code></pre>
<p><strong>Âá∫Âäõ‰æã:</strong></p>
<pre><code>        Name      MW  LogP  TPSA  HBA  HBD  RotBonds
     Aspirin  180.16  1.19 63.60    4    1         3
   Ibuprofen  206.28  3.50 37.30    2    1         4
 Paracetamol  151.16  0.46 49.33    2    2         1
    Caffeine  194.19 -0.07 58.44    6    0         0
</code></pre>
<h3>2.1.2 2DË®òËø∞Â≠êÔºöÂàÜÂ≠êÊåáÁ¥ã„Å®„Ç∞„É©„ÉïË®òËø∞Â≠ê</h3>
<p>2DË®òËø∞Â≠ê„ÅØ„ÄÅÂàÜÂ≠ê„ÅÆ„Éà„Éù„É≠„Ç∏„ÉºÔºàÁµêÂêàÈñ¢‰øÇÔºâ„ÇíÂèçÊò†„Åó„Åæ„Åô„ÄÇ</p>
<h4>MorganÊåáÁ¥ãÔºàECFPÔºâ</h4>
<p>MorganÊåáÁ¥ã„ÅØ„ÄÅÂêÑÂéüÂ≠ê„ÅÆÂë®Ëæ∫Áí∞Â¢É„Çí„Éè„ÉÉ„Ç∑„É•Âåñ„Åó„Åü„Éì„ÉÉ„Éà„Éô„ÇØ„Éà„É´„Åß„Åô„ÄÇ</p>
<div class="mermaid">
graph LR
    A[‰∏≠ÂøÉÂéüÂ≠ê] --> B[ÂçäÂæÑ1„ÅÆÁí∞Â¢É]
    B --> C[ÂçäÂæÑ2„ÅÆÁí∞Â¢É]
    C --> D[„Éè„ÉÉ„Ç∑„É•Âåñ]
    D --> E[„Éì„ÉÉ„Éà„Éô„ÇØ„Éà„É´]

    style A fill:#e3f2fd
    style E fill:#4CAF50,color:#fff
</div>

<h4>„Ç≥„Éº„Éâ‰æã2: MorganÊåáÁ¥ã„ÅÆË®àÁÆó</h4>
<pre><code class="language-python">from rdkit import Chem
from rdkit.Chem import AllChem
import numpy as np

# ÂàÜÂ≠ê„ÅÆÊ∫ñÂÇô
smiles_list = [
    &quot;CCO&quot;,  # „Ç®„Çø„Éé„Éº„É´
    &quot;CCCO&quot;,  # „Éó„É≠„Éë„Éé„Éº„É´ÔºàÈ°û‰ººÔºâ
    &quot;c1ccccc1&quot;  # „Éô„É≥„Çº„É≥ÔºàÁï∞„Å™„ÇãÔºâ
]

# MorganÊåáÁ¥ã„ÅÆË®àÁÆóÔºàÂçäÂæÑ2„ÄÅ„Éì„ÉÉ„ÉàÈï∑2048Ôºâ
fps = []
for smiles in smiles_list:
    mol = Chem.MolFromSmiles(smiles)
    fp = AllChem.GetMorganFingerprintAsBitVect(
        mol,
        radius=2,
        nBits=2048
    )
    fps.append(fp)

# TanimotoÈ°û‰ººÂ∫¶„ÅÆË®àÁÆó
from rdkit import DataStructs

print(&quot;TanimotoÈ°û‰ººÂ∫¶Ë°åÂàó:&quot;)
for i, fp1 in enumerate(fps):
    similarities = []
    for j, fp2 in enumerate(fps):
        sim = DataStructs.TanimotoSimilarity(fp1, fp2)
        similarities.append(f&quot;{sim:.3f}&quot;)
    print(f&quot;{smiles_list[i]:15s} {' '.join(similarities)}&quot;)
</code></pre>
<p><strong>Âá∫Âäõ‰æã:</strong></p>
<pre><code>TanimotoÈ°û‰ººÂ∫¶Ë°åÂàó:
CCO             1.000 0.571 0.111
CCCO            0.571 1.000 0.103
c1ccccc1        0.111 0.103 1.000
</code></pre>
<p><strong>Ëß£Èáà</strong>: „Ç®„Çø„Éé„Éº„É´„Å®„Éó„É≠„Éë„Éé„Éº„É´„ÅØÈ°û‰ººÂ∫¶0.571„Å®È´ò„Åè„ÄÅ„Éô„É≥„Çº„É≥„Å®„ÅØ‰Ωé„ÅÑÈ°û‰ººÂ∫¶„ÇíÁ§∫„Åó„Åæ„Åô„ÄÇ</p>
<h4>„Ç≥„Éº„Éâ‰æã3: MACCSÈçµÔºàÊßãÈÄ†ÁöÑÁâπÂæ¥Ôºâ</h4>
<pre><code class="language-python">from rdkit import Chem
from rdkit.Chem import MACCSkeys
import numpy as np

# MACCSÈçµ„ÅØ166„Éì„ÉÉ„Éà„ÅÆÊßãÈÄ†ÁöÑÁâπÂæ¥
smiles = &quot;CC(=O)Oc1ccccc1C(=O)O&quot;  # „Ç¢„Çπ„Éî„É™„É≥
mol = Chem.MolFromSmiles(smiles)

# MACCSÈçµ„ÅÆË®àÁÆó
maccs = MACCSkeys.GenMACCSKeys(mol)

# „Éì„ÉÉ„Éà„ÅåÁ´ã„Å£„Å¶„ÅÑ„ÇãÁâπÂæ¥„ÇíË°®Á§∫
on_bits = [i for i in range(len(maccs)) if maccs[i]]
print(f&quot;„Ç¢„Çπ„Éî„É™„É≥„ÅÆÊßãÈÄ†ÁöÑÁâπÂæ¥ÔºàON bitsÔºâ: {len(on_bits)} / 166&quot;)
print(f&quot;ÁâπÂæ¥„Ç§„É≥„Éá„ÉÉ„ÇØ„Çπ: {on_bits[:20]}...&quot;)  # ÊúÄÂàù„ÅÆ20ÂÄã
</code></pre>
<p><strong>Âá∫Âäõ‰æã:</strong></p>
<pre><code>„Ç¢„Çπ„Éî„É™„É≥„ÅÆÊßãÈÄ†ÁöÑÁâπÂæ¥ÔºàON bitsÔºâ: 38 / 166
ÁâπÂæ¥„Ç§„É≥„Éá„ÉÉ„ÇØ„Çπ: [1, 7, 10, 21, 32, 35, 47, 48, 56, 60, ...]
</code></pre>
<h3>2.1.3 3DË®òËø∞Â≠êÔºöÁ´ã‰ΩìÈÖçÂ∫ß‰æùÂ≠òË®òËø∞Â≠ê</h3>
<p>3DË®òËø∞Â≠ê„ÅØ„ÄÅÂàÜÂ≠ê„ÅÆÁ´ã‰ΩìÊßãÈÄ†„ÇíËÄÉÊÖÆ„Åó„ÅüË®òËø∞Â≠ê„Åß„Åô„ÄÇ</p>
<h4>„Ç≥„Éº„Éâ‰æã4: 3DË®òËø∞Â≠ê„ÅÆË®àÁÆó</h4>
<pre><code class="language-python">from rdkit import Chem
from rdkit.Chem import AllChem, Descriptors3D
import pandas as pd

# ÂàÜÂ≠ê„ÅÆÊ∫ñÂÇô
smiles = &quot;CC(C)Cc1ccc(cc1)C(C)C(=O)O&quot;  # „Ç§„Éñ„Éó„É≠„Éï„Çß„É≥
mol = Chem.MolFromSmiles(smiles)

# 3DÂ∫ßÊ®ô„ÇíÁîüÊàê
AllChem.EmbedMolecule(mol, randomSeed=42)
AllChem.MMFFOptimizeMolecule(mol)

# 3DË®òËø∞Â≠ê„ÅÆË®àÁÆó
descriptors_3d = {
    'PMI1': Descriptors3D.PMI1(mol),  # ‰∏ªÊÖ£ÊÄß„É¢„Éº„É°„É≥„Éà1
    'PMI2': Descriptors3D.PMI2(mol),  # ‰∏ªÊÖ£ÊÄß„É¢„Éº„É°„É≥„Éà2
    'PMI3': Descriptors3D.PMI3(mol),  # ‰∏ªÊÖ£ÊÄß„É¢„Éº„É°„É≥„Éà3
    'NPR1': Descriptors3D.NPR1(mol),  # Ê≠£Ë¶èÂåñ‰∏ªÊÖ£ÊÄßÊØî1
    'NPR2': Descriptors3D.NPR2(mol),  # Ê≠£Ë¶èÂåñ‰∏ªÊÖ£ÊÄßÊØî2
    'RadiusOfGyration': Descriptors3D.RadiusOfGyration(mol),
    'InertialShapeFactor': Descriptors3D.InertialShapeFactor(mol),
    'Asphericity': Descriptors3D.Asphericity(mol),
    'Eccentricity': Descriptors3D.Eccentricity(mol)
}

df = pd.DataFrame([descriptors_3d])
print(df.T)
</code></pre>
<p><strong>Âá∫Âäõ‰æã:</strong></p>
<pre><code>                              0
PMI1                    197.45
PMI2                    598.32
PMI3                    712.18
NPR1                      0.28
NPR2                      0.84
RadiusOfGyration          3.42
InertialShapeFactor       0.18
Asphericity               0.23
Eccentricity              0.89
</code></pre>
<h3>2.1.4 mordred„Å´„Çà„ÇãÂåÖÊã¨ÁöÑË®òËø∞Â≠êË®àÁÆó</h3>
<p>mordred„ÅØ1,800Á®ÆÈ°û‰ª•‰∏ä„ÅÆË®òËø∞Â≠ê„Çí‰∏ÄÊã¨Ë®àÁÆó„Åß„Åç„Çã„É©„Ç§„Éñ„É©„É™„Åß„Åô„ÄÇ</p>
<h4>„Ç≥„Éº„Éâ‰æã5: mordred„ÅßÂÖ®Ë®òËø∞Â≠ê„ÇíË®àÁÆó</h4>
<pre><code class="language-python"># mordred„ÅÆ„Ç§„É≥„Çπ„Éà„Éº„É´
# pip install mordred

from mordred import Calculator, descriptors
from rdkit import Chem
import pandas as pd

# Calculator„ÅÆÂàùÊúüÂåñÔºàÂÖ®Ë®òËø∞Â≠êÔºâ
calc = Calculator(descriptors, ignore_3D=True)

# ÂàÜÂ≠ê„É™„Çπ„Éà
smiles_list = [
    &quot;CCO&quot;,
    &quot;CC(=O)Oc1ccccc1C(=O)O&quot;,
    &quot;CN1C=NC2=C1C(=O)N(C(=O)N2C)C&quot;
]

mols = [Chem.MolFromSmiles(smi) for smi in smiles_list]

# Ë®òËø∞Â≠êË®àÁÆóÔºàÊôÇÈñì„Åå„Åã„Åã„ÇãÂ†¥Âêà„ÅÇ„ÇäÔºâ
df = calc.pandas(mols)

print(f&quot;Ë®àÁÆó„Åï„Çå„ÅüË®òËø∞Â≠êÊï∞: {len(df.columns)}&quot;)
print(f&quot;ÂàÜÂ≠êÊï∞: {len(df)}&quot;)
print(&quot;\nÊúÄÂàù„ÅÆ10ÂÄã„ÅÆË®òËø∞Â≠ê:&quot;)
print(df.iloc[:, :10])

# NaN„ÇÑÁÑ°ÈôêÂ§ß„ÇíÈô§Âéª
df_clean = df.select_dtypes(include=[np.number])
df_clean = df_clean.replace([np.inf, -np.inf], np.nan)
df_clean = df_clean.dropna(axis=1, how='any')

print(f&quot;\n„ÇØ„É™„Éº„Éã„É≥„Ç∞Âæå„ÅÆË®òËø∞Â≠êÊï∞: {len(df_clean.columns)}&quot;)
</code></pre>
<p><strong>Âá∫Âäõ‰æã:</strong></p>
<pre><code>Ë®àÁÆó„Åï„Çå„ÅüË®òËø∞Â≠êÊï∞: 1826
ÂàÜÂ≠êÊï∞: 3

ÊúÄÂàù„ÅÆ10ÂÄã„ÅÆË®òËø∞Â≠ê:
   ABC    ABCGG  nAcid  nBase  SpAbs_A  SpMax_A  SpDiam_A  ...
0  3.46    3.82      0      0     2.57     1.29      2.31  ...
1  16.52  17.88      1      0    13.45     2.34      5.67  ...
2  15.78  16.45      0      6    12.87     2.12      5.34  ...

„ÇØ„É™„Éº„Éã„É≥„Ç∞Âæå„ÅÆË®òËø∞Â≠êÊï∞: 1654
</code></pre>
<hr />
<h2>2.2 QSAR/QSPR„É¢„Éá„É™„É≥„Ç∞</h2>
<h3>ÂÆöÁæ©</h3>
<ul>
<li><strong>QSARÔºàQuantitative Structure-Activity RelationshipÔºâ</strong>: ÊßãÈÄ†-Ê¥ªÊÄßÁõ∏Èñ¢</li>
<li>ÁîüÁâ©Ê¥ªÊÄßÔºàIC50„ÄÅEC50„Å™„Å©Ôºâ„ÅÆ‰∫àÊ∏¨</li>
<li>
<p>ÂâµËñ¨„Å´„Åä„Åë„ÇãÂÄôË£úÂåñÂêàÁâ©„ÅÆÈÅ∏ÂÆö</p>
</li>
<li>
<p><strong>QSPRÔºàQuantitative Structure-Property RelationshipÔºâ</strong>: ÊßãÈÄ†-Áâ©ÊÄßÁõ∏Èñ¢</p>
</li>
<li>Áâ©ÁêÜÂåñÂ≠¶ÁöÑÊÄßË≥™ÔºàÊ∫∂Ëß£Â∫¶„ÄÅËûçÁÇπ„Å™„Å©Ôºâ„ÅÆ‰∫àÊ∏¨</li>
<li>ÊùêÊñôË®≠Ë®à„Å´„Åä„Åë„ÇãÁâ©ÊÄßÊúÄÈÅ©Âåñ</li>
</ul>
<div class="mermaid">
graph TD
    A[ÂàÜÂ≠êÊßãÈÄ†<br>SMILES] --> B[Ë®òËø∞Â≠êË®àÁÆó]
    B --> C[ÁâπÂæ¥ÈáèË°åÂàó<br>X]

    D[ÂÆüÊ∏¨ÂÄ§<br>Ê¥ªÊÄß„ÉªÁâ©ÊÄß] --> E[ÁõÆÁöÑÂ§âÊï∞<br>y]

    C --> F[Ê©üÊ¢∞Â≠¶Áøí„É¢„Éá„É´]
    E --> F

    F --> G[Ë®ìÁ∑¥]
    G --> H[Ë©ï‰æ°]
    H --> I{ÊÄßËÉΩOK?}
    I -->|No| J[ÁâπÂæ¥ÈáèÈÅ∏Êäû/<br>„É¢„Éá„É´Â§âÊõ¥]
    J --> F
    I -->|Yes| K[Êñ∞Ë¶èÂàÜÂ≠ê„ÅÆ‰∫àÊ∏¨]

    style A fill:#e3f2fd
    style K fill:#4CAF50,color:#fff
</div>

<h3>2.2.1 Á∑öÂΩ¢„É¢„Éá„É´</h3>
<h4>„Ç≥„Éº„Éâ‰æã6: Ridge„É¢„Éá„É´„Å´„Çà„ÇãÁâ©ÊÄß‰∫àÊ∏¨</h4>
<pre><code class="language-python">from sklearn.linear_model import Ridge, Lasso
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score, mean_squared_error
from sklearn.preprocessing import StandardScaler
import numpy as np

# „Çµ„É≥„Éó„É´„Éá„Éº„ÇøÔºàÂÆüÈöõ„ÅØmordred„Å™„Å©„ÅßË®àÁÆóÔºâ
# X: Ë®òËø∞Â≠êË°åÂàó„ÄÅy: Ê∫∂Ëß£Â∫¶
np.random.seed(42)
n_samples = 100
n_features = 50

X = np.random.randn(n_samples, n_features)
y = X[:, 0] * 2 + X[:, 1] * (-1.5) + np.random.randn(n_samples) * 0.5

# „Éá„Éº„ÇøÂàÜÂâ≤
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# Ê®ôÊ∫ñÂåñ
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Ridge„É¢„Éá„É´
ridge = Ridge(alpha=1.0)
ridge.fit(X_train_scaled, y_train)

# ‰∫àÊ∏¨
y_pred_train = ridge.predict(X_train_scaled)
y_pred_test = ridge.predict(X_test_scaled)

# Ë©ï‰æ°
print(&quot;RidgeÂõûÂ∏∞„ÅÆÊÄßËÉΩ:&quot;)
print(f&quot;Ë®ìÁ∑¥ R¬≤: {r2_score(y_train, y_pred_train):.3f}&quot;)
print(f&quot;„ÉÜ„Çπ„Éà R¬≤: {r2_score(y_test, y_pred_test):.3f}&quot;)
print(f&quot;„ÉÜ„Çπ„Éà RMSE: {np.sqrt(mean_squared_error(y_test, y_pred_test)):.3f}&quot;)

# Lasso„É¢„Éá„É´Ôºà„Çπ„Éë„Éº„ÇπÊÄß„ÅÆÂ∞éÂÖ•Ôºâ
lasso = Lasso(alpha=0.1)
lasso.fit(X_train_scaled, y_train)

# Èùû„Çº„É≠‰øÇÊï∞„ÅÆÊï∞ÔºàÈÅ∏Êäû„Åï„Çå„ÅüÁâπÂæ¥ÈáèÔºâ
non_zero = np.sum(lasso.coef_ != 0)
print(f&quot;\nLasso„ÅåÈÅ∏Êäû„Åó„ÅüÁâπÂæ¥Èáè: {non_zero} / {n_features}&quot;)
</code></pre>
<p><strong>Âá∫Âäõ‰æã:</strong></p>
<pre><code>RidgeÂõûÂ∏∞„ÅÆÊÄßËÉΩ:
Ë®ìÁ∑¥ R¬≤: 0.923
„ÉÜ„Çπ„Éà R¬≤: 0.891
„ÉÜ„Çπ„Éà RMSE: 0.542

Lasso„ÅåÈÅ∏Êäû„Åó„ÅüÁâπÂæ¥Èáè: 18 / 50
</code></pre>
<h3>2.2.2 ÈùûÁ∑öÂΩ¢„É¢„Éá„É´</h3>
<h4>„Ç≥„Éº„Éâ‰æã7: Random Forest„Å´„Çà„Çã‰∫àÊ∏¨</h4>
<pre><code class="language-python">from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import cross_val_score
import matplotlib.pyplot as plt

# Random Forest„É¢„Éá„É´
rf = RandomForestRegressor(
    n_estimators=100,
    max_depth=10,
    min_samples_split=5,
    random_state=42
)

# ‰∫§Â∑ÆÊ§úË®º
cv_scores = cross_val_score(
    rf, X_train_scaled, y_train,
    cv=5,
    scoring='r2'
)

print(f&quot;Random Forest‰∫§Â∑ÆÊ§úË®º R¬≤: {cv_scores.mean():.3f} ¬± {cv_scores.std():.3f}&quot;)

# Ë®ìÁ∑¥
rf.fit(X_train_scaled, y_train)
y_pred_rf = rf.predict(X_test_scaled)

print(f&quot;„ÉÜ„Çπ„Éà R¬≤: {r2_score(y_test, y_pred_rf):.3f}&quot;)
print(f&quot;„ÉÜ„Çπ„Éà RMSE: {np.sqrt(mean_squared_error(y_test, y_pred_rf)):.3f}&quot;)

# ‰∫àÊ∏¨vsÂÆüÊ∏¨„Éó„É≠„ÉÉ„Éà
plt.figure(figsize=(8, 6))
plt.scatter(y_test, y_pred_rf, alpha=0.6, edgecolors='k')
plt.plot([y_test.min(), y_test.max()],
         [y_test.min(), y_test.max()],
         'r--', lw=2, label='Perfect prediction')
plt.xlabel('Actual', fontsize=12)
plt.ylabel('Predicted', fontsize=12)
plt.title('Random Forest: Predicted vs Actual', fontsize=14)
plt.legend()
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.savefig('rf_prediction.png', dpi=300)
plt.close()
</code></pre>
<h4>„Ç≥„Éº„Éâ‰æã8: LightGBM„Å´„Çà„ÇãÈ´òÈÄü‰∫àÊ∏¨</h4>
<pre><code class="language-python"># LightGBM„ÅÆ„Ç§„É≥„Çπ„Éà„Éº„É´
# pip install lightgbm

import lightgbm as lgb

# LightGBM„Éá„Éº„Çø„Çª„ÉÉ„Éà
train_data = lgb.Dataset(X_train_scaled, label=y_train)
test_data = lgb.Dataset(X_test_scaled, label=y_test, reference=train_data)

# „Éë„É©„É°„Éº„Çø
params = {
    'objective': 'regression',
    'metric': 'rmse',
    'boosting_type': 'gbdt',
    'num_leaves': 31,
    'learning_rate': 0.05,
    'feature_fraction': 0.9,
    'bagging_fraction': 0.8,
    'bagging_freq': 5,
    'verbose': -1
}

# Ë®ìÁ∑¥
gbm = lgb.train(
    params,
    train_data,
    num_boost_round=100,
    valid_sets=[test_data],
    callbacks=[lgb.early_stopping(stopping_rounds=10)]
)

# ‰∫àÊ∏¨
y_pred_lgb = gbm.predict(X_test_scaled, num_iteration=gbm.best_iteration)

print(f&quot;LightGBM „ÉÜ„Çπ„Éà R¬≤: {r2_score(y_test, y_pred_lgb):.3f}&quot;)
print(f&quot;LightGBM „ÉÜ„Çπ„Éà RMSE: {np.sqrt(mean_squared_error(y_test, y_pred_lgb)):.3f}&quot;)
</code></pre>
<p><strong>Âá∫Âäõ‰æã:</strong></p>
<pre><code>Random Forest‰∫§Â∑ÆÊ§úË®º R¬≤: 0.912 ¬± 0.034
„ÉÜ„Çπ„Éà R¬≤: 0.924
„ÉÜ„Çπ„Éà RMSE: 0.451

LightGBM „ÉÜ„Çπ„Éà R¬≤: 0.931
LightGBM „ÉÜ„Çπ„Éà RMSE: 0.429
</code></pre>
<hr />
<h2>2.3 ÁâπÂæ¥ÈáèÈÅ∏Êäû„Å®Ëß£Èáà</h2>
<h3>2.3.1 Áõ∏Èñ¢ÂàÜÊûê„Å´„Çà„ÇãÂÜóÈï∑ÊÄßÈô§Âéª</h3>
<h4>„Ç≥„Éº„Éâ‰æã9: Áõ∏Èñ¢Ë°åÂàó„Å®ÂÜóÈï∑ÁâπÂæ¥Èáè„ÅÆÂâäÈô§</h4>
<pre><code class="language-python">import seaborn as sns
import matplotlib.pyplot as plt

# Áõ∏Èñ¢Ë°åÂàó„ÅÆË®àÁÆó
corr_matrix = pd.DataFrame(X_train_scaled).corr()

# È´òÁõ∏Èñ¢„Éö„Ç¢„ÅÆÊ§úÂá∫ÔºàÈñæÂÄ§0.95Ôºâ
threshold = 0.95
high_corr_pairs = []

for i in range(len(corr_matrix.columns)):
    for j in range(i+1, len(corr_matrix.columns)):
        if abs(corr_matrix.iloc[i, j]) &gt; threshold:
            high_corr_pairs.append((i, j, corr_matrix.iloc[i, j]))

print(f&quot;È´òÁõ∏Èñ¢„Éö„Ç¢Ôºà|r| &gt; {threshold}Ôºâ: {len(high_corr_pairs)}ÁµÑ&quot;)

# ÂÜóÈï∑ÁâπÂæ¥Èáè„ÅÆÂâäÈô§
columns_to_drop = set()
for i, j, corr in high_corr_pairs:
    columns_to_drop.add(j)  # jÁï™ÁõÆ„ÇíÂâäÈô§Ôºà‰ªªÊÑè„ÅÆÈÅ∏ÊäûÔºâ

X_train_reduced = np.delete(X_train_scaled, list(columns_to_drop), axis=1)
X_test_reduced = np.delete(X_test_scaled, list(columns_to_drop), axis=1)

print(f&quot;ÂâäÊ∏õÂâç„ÅÆÁâπÂæ¥ÈáèÊï∞: {X_train_scaled.shape[1]}&quot;)
print(f&quot;ÂâäÊ∏õÂæå„ÅÆÁâπÂæ¥ÈáèÊï∞: {X_train_reduced.shape[1]}&quot;)

# „Éí„Éº„Éà„Éû„ÉÉ„Éó„ÅÆÊèèÁîªÔºàÊúÄÂàù„ÅÆ20ÁâπÂæ¥Èáè„ÅÆ„ÅøÔºâ
plt.figure(figsize=(12, 10))
sns.heatmap(
    corr_matrix.iloc[:20, :20],
    annot=True,
    fmt='.2f',
    cmap='coolwarm',
    center=0,
    square=True,
    linewidths=0.5
)
plt.title('Áõ∏Èñ¢Ë°åÂàó„Éí„Éº„Éà„Éû„ÉÉ„ÉóÔºàÊúÄÂàù„ÅÆ20ÁâπÂæ¥ÈáèÔºâ', fontsize=14)
plt.tight_layout()
plt.savefig('correlation_heatmap.png', dpi=300)
plt.close()
</code></pre>
<h3>2.3.2 ÁâπÂæ¥ÈáèÈáçË¶ÅÂ∫¶„ÅÆÂàÜÊûê</h3>
<h4>„Ç≥„Éº„Éâ‰æã10: SHAP„Å´„Çà„ÇãÁâπÂæ¥ÈáèËß£Èáà</h4>
<pre><code class="language-python"># SHAP„ÅÆ„Ç§„É≥„Çπ„Éà„Éº„É´
# pip install shap

import shap

# Random Forest„É¢„Éá„É´„ÅßÂÜçË®ìÁ∑¥
rf_model = RandomForestRegressor(
    n_estimators=100,
    max_depth=10,
    random_state=42
)
rf_model.fit(X_train_scaled, y_train)

# SHAPÂÄ§„ÅÆË®àÁÆó
explainer = shap.TreeExplainer(rf_model)
shap_values = explainer.shap_values(X_test_scaled)

# ÁâπÂæ¥ÈáèÈáçË¶ÅÂ∫¶„ÅÆÂèØË¶ñÂåñ
plt.figure(figsize=(10, 6))
shap.summary_plot(
    shap_values,
    X_test_scaled,
    feature_names=[f'F{i}' for i in range(X_test_scaled.shape[1])],
    show=False,
    max_display=20
)
plt.title('SHAPÁâπÂæ¥ÈáèÈáçË¶ÅÂ∫¶', fontsize=14)
plt.tight_layout()
plt.savefig('shap_summary.png', dpi=300)
plt.close()

# ÂÄãÂà•„Çµ„É≥„Éó„É´„ÅÆË™¨Êòé
plt.figure(figsize=(10, 6))
shap.waterfall_plot(
    shap.Explanation(
        values=shap_values[0],
        base_values=explainer.expected_value,
        data=X_test_scaled[0],
        feature_names=[f'F{i}' for i in range(X_test_scaled.shape[1])]
    ),
    max_display=15,
    show=False
)
plt.title('„Çµ„É≥„Éó„É´1„ÅÆ‰∫àÊ∏¨Ë™¨Êòé', fontsize=14)
plt.tight_layout()
plt.savefig('shap_waterfall.png', dpi=300)
plt.close()

print(&quot;SHAPËß£Èáà„ÅÆÂèØË¶ñÂåñ„Çí‰øùÂ≠ò„Åó„Åæ„Åó„Åü&quot;)
</code></pre>
<hr />
<h2>2.4 „Ç±„Éº„Çπ„Çπ„Çø„Éá„Ç£ÔºöÊ∫∂Ëß£Â∫¶‰∫àÊ∏¨</h2>
<h3>„Éá„Éº„Çø„Çª„ÉÉ„Éà: ESOLÔºàEstimated SolubilityÔºâ</h3>
<p>ESOL„Éá„Éº„Çø„Çª„ÉÉ„Éà„ÅØ„ÄÅ1,128Á®ÆÈ°û„ÅÆÂåñÂêàÁâ©„ÅÆÊ∞¥Ê∫∂Ëß£Â∫¶„Éá„Éº„Çø„Åß„Åô„ÄÇ</p>
<h4>„Ç≥„Éº„Éâ‰æã11: ESOL„Éá„Éº„Çø„Çª„ÉÉ„Éà„ÅÆÂèñÂæó„Å®ÂâçÂá¶ÁêÜ</h4>
<pre><code class="language-python">from rdkit import Chem
from rdkit.Chem import Descriptors
import pandas as pd
import numpy as np

# ESOL„Éá„Éº„Çø„Çª„ÉÉ„Éà„ÅÆË™≠„ÅøËæº„Åø
# „Éá„Éº„Çø„ÅØ https://raw.githubusercontent.com/deepchem/deepchem/master/datasets/delaney-processed.csv „Åã„ÇâÂèñÂæó
url = &quot;https://raw.githubusercontent.com/deepchem/deepchem/master/datasets/delaney-processed.csv&quot;
df_esol = pd.read_csv(url)

print(f&quot;„Éá„Éº„ÇøÊï∞: {len(df_esol)}&quot;)
print(f&quot;\n„Ç´„É©„É†: {df_esol.columns.tolist()}&quot;)
print(f&quot;\n„Éá„Éº„Çø„ÅÆÂÖàÈ†≠:&quot;)
print(df_esol.head())

# SMILES„Åã„ÇâÂàÜÂ≠ê„Ç™„Éñ„Ç∏„Çß„ÇØ„Éà„Çí‰ΩúÊàê
df_esol['mol'] = df_esol['smiles'].apply(Chem.MolFromSmiles)

# ÁÑ°Âäπ„Å™SMILES„ÇíÈô§Âéª
df_esol = df_esol[df_esol['mol'].notna()]
print(f&quot;\nÊúâÂäπ„Å™ÂàÜÂ≠êÊï∞: {len(df_esol)}&quot;)

# RDKitË®òËø∞Â≠ê„ÅÆË®àÁÆó
descriptors_list = [
    'MolWt', 'MolLogP', 'NumHAcceptors', 'NumHDonors',
    'TPSA', 'NumRotatableBonds', 'NumAromaticRings',
    'NumHeteroatoms', 'RingCount', 'FractionCsp3'
]

for desc_name in descriptors_list:
    desc_func = getattr(Descriptors, desc_name)
    df_esol[desc_name] = df_esol['mol'].apply(desc_func)

# MorganÊåáÁ¥ã„ÅÆËøΩÂä†
from rdkit.Chem import AllChem

def get_morgan_fp(mol):
    fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2, nBits=1024)
    return np.array(fp)

fp_array = np.array([get_morgan_fp(mol) for mol in df_esol['mol']])

# ÁâπÂæ¥ÈáèË°åÂàó„ÅÆ‰ΩúÊàê
X_descriptors = df_esol[descriptors_list].values
X_fingerprints = fp_array
X_combined = np.hstack([X_descriptors, X_fingerprints])

# ÁõÆÁöÑÂ§âÊï∞ÔºàÊ∫∂Ëß£Â∫¶ logSÔºâ
y = df_esol['measured log solubility in mols per litre'].values

print(f&quot;\nÁâπÂæ¥ÈáèË°åÂàó„ÅÆÂΩ¢Áä∂:&quot;)
print(f&quot;Ë®òËø∞Â≠ê„ÅÆ„Åø: {X_descriptors.shape}&quot;)
print(f&quot;ÊåáÁ¥ã„ÅÆ„Åø: {X_fingerprints.shape}&quot;)
print(f&quot;ÁµêÂêàÂæå: {X_combined.shape}&quot;)
</code></pre>
<p><strong>Âá∫Âäõ‰æã:</strong></p>
<pre><code>„Éá„Éº„ÇøÊï∞: 1128

„Ç´„É©„É†: ['Compound ID', 'smiles', 'measured log solubility in mols per litre', ...]

ÊúâÂäπ„Å™ÂàÜÂ≠êÊï∞: 1128

ÁâπÂæ¥ÈáèË°åÂàó„ÅÆÂΩ¢Áä∂:
Ë®òËø∞Â≠ê„ÅÆ„Åø: (1128, 10)
ÊåáÁ¥ã„ÅÆ„Åø: (1128, 1024)
ÁµêÂêàÂæå: (1128, 1034)
</code></pre>
<h4>„Ç≥„Éº„Éâ‰æã12: Ë§áÊï∞„É¢„Éá„É´„ÅÆÊØîËºÉ„Å®ÊúÄÈÅ©Âåñ</h4>
<pre><code class="language-python">from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import Ridge
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
import matplotlib.pyplot as plt

# „Éá„Éº„ÇøÂàÜÂâ≤
X_train, X_test, y_train, y_test = train_test_split(
    X_combined, y, test_size=0.2, random_state=42
)

# Ê®ôÊ∫ñÂåñ
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# „É¢„Éá„É´1: RidgeÂõûÂ∏∞
ridge = Ridge(alpha=1.0)
ridge.fit(X_train_scaled, y_train)
y_pred_ridge = ridge.predict(X_test_scaled)

# „É¢„Éá„É´2: Random ForestÔºà„Éè„Ç§„Éë„Éº„Éë„É©„É°„Éº„ÇøÊé¢Á¥¢Ôºâ
param_grid_rf = {
    'n_estimators': [50, 100, 200],
    'max_depth': [5, 10, 15],
    'min_samples_split': [2, 5, 10]
}

rf_grid = GridSearchCV(
    RandomForestRegressor(random_state=42),
    param_grid_rf,
    cv=5,
    scoring='r2',
    n_jobs=-1
)
rf_grid.fit(X_train_scaled, y_train)
y_pred_rf = rf_grid.predict(X_test_scaled)

print(f&quot;Random Forest„Éô„Çπ„Éà„Éë„É©„É°„Éº„Çø: {rf_grid.best_params_}&quot;)

# „É¢„Éá„É´3: LightGBM
import lightgbm as lgb

lgb_train = lgb.Dataset(X_train_scaled, y_train)
lgb_test = lgb.Dataset(X_test_scaled, y_test, reference=lgb_train)

params_lgb = {
    'objective': 'regression',
    'metric': 'rmse',
    'num_leaves': 31,
    'learning_rate': 0.05,
    'feature_fraction': 0.9,
    'verbose': -1
}

gbm = lgb.train(
    params_lgb,
    lgb_train,
    num_boost_round=200,
    valid_sets=[lgb_test],
    callbacks=[lgb.early_stopping(stopping_rounds=20, verbose=False)]
)
y_pred_lgb = gbm.predict(X_test_scaled, num_iteration=gbm.best_iteration)

# ÊÄßËÉΩÊØîËºÉ
models = {
    'Ridge': y_pred_ridge,
    'Random Forest': y_pred_rf,
    'LightGBM': y_pred_lgb
}

print(&quot;\n=== „É¢„Éá„É´ÊÄßËÉΩÊØîËºÉ ===&quot;)
for name, y_pred in models.items():
    r2 = r2_score(y_test, y_pred)
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    mae = mean_absolute_error(y_test, y_pred)
    print(f&quot;\n{name}:&quot;)
    print(f&quot;  R¬≤: {r2:.3f}&quot;)
    print(f&quot;  RMSE: {rmse:.3f}&quot;)
    print(f&quot;  MAE: {mae:.3f}&quot;)

# ‰∫àÊ∏¨vsÂÆüÊ∏¨„Éó„É≠„ÉÉ„ÉàÔºà3„É¢„Éá„É´ÊØîËºÉÔºâ
fig, axes = plt.subplots(1, 3, figsize=(18, 5))

for ax, (name, y_pred) in zip(axes, models.items()):
    ax.scatter(y_test, y_pred, alpha=0.6, edgecolors='k')
    ax.plot([y_test.min(), y_test.max()],
            [y_test.min(), y_test.max()],
            'r--', lw=2)
    ax.set_xlabel('Actual log(S)', fontsize=12)
    ax.set_ylabel('Predicted log(S)', fontsize=12)
    ax.set_title(f'{name} (R¬≤ = {r2_score(y_test, y_pred):.3f})',
                 fontsize=14)
    ax.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('esol_model_comparison.png', dpi=300)
plt.close()

print(&quot;\n„É¢„Éá„É´ÊØîËºÉ„Éó„É≠„ÉÉ„Éà„Çí‰øùÂ≠ò„Åó„Åæ„Åó„Åü&quot;)
</code></pre>
<p><strong>Âá∫Âäõ‰æã:</strong></p>
<pre><code>Random Forest„Éô„Çπ„Éà„Éë„É©„É°„Éº„Çø: {'max_depth': 15, 'min_samples_split': 2, 'n_estimators': 200}

=== „É¢„Éá„É´ÊÄßËÉΩÊØîËºÉ ===

Ridge:
  R¬≤: 0.789
  RMSE: 0.712
  MAE: 0.543

Random Forest:
  R¬≤: 0.891
  RMSE: 0.511
  MAE: 0.382

LightGBM:
  R¬≤: 0.912
  RMSE: 0.459
  MAE: 0.341

„É¢„Éá„É´ÊØîËºÉ„Éó„É≠„ÉÉ„Éà„Çí‰øùÂ≠ò„Åó„Åæ„Åó„Åü
</code></pre>
<p><strong>Ëß£Èáà</strong>:
- <strong>LightGBM</strong>„ÅåÊúÄÈ´òÊÄßËÉΩÔºàR¬≤ = 0.912Ôºâ
- <strong>Random Forest</strong>„ÇÇÂÑ™ÁßÄÔºàR¬≤ = 0.891Ôºâ
- <strong>Ridge</strong>„ÅØÁ∑öÂΩ¢„É¢„Éá„É´„ÅÆ„Åü„ÇÅÊÄßËÉΩ„Åå„ÇÑ„ÇÑ‰Ωé„ÅÑ</p>
<hr />
<h2>ÊºîÁøíÂïèÈ°å</h2>
<h3>ÊºîÁøí1: ÂàÜÂ≠êË®òËø∞Â≠ê„ÅÆÁêÜËß£</h3>
<p>‰ª•‰∏ã„ÅÆË®òËø∞Â≠ê„Å´„Å§„ÅÑ„Å¶„ÄÅ„Åù„Çå„Åû„Çå„ÅÆÊÑèÂë≥„Å®ÂâµËñ¨„Å´„Åä„Åë„ÇãÈáçË¶ÅÊÄß„ÇíË™¨Êòé„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ</p>
<ol>
<li><strong>logPÔºàËÑÇÊ∫∂ÊÄßÔºâ</strong>: È´ò„ÅÑÂÄ§„ÅØ„Å©„ÅÆ„Çà„ÅÜ„Å™ÊÄßË≥™„ÇíÁ§∫„Åô„ÅãÔºü</li>
<li><strong>TPSAÔºàÊ•µÊÄßË°®Èù¢Á©çÔºâ</strong>: Ë°ÄÊ∂≤ËÑ≥Èñ¢ÈñÄÈÄèÈÅéÊÄß„Å®„ÅÆÈñ¢‰øÇ„ÅØÔºü</li>
<li><strong>ÂàÜÂ≠êÈáè</strong>: Lipinski„ÅÆ„É´„Éº„É´„Ç™„Éñ„Éï„Ç°„Ç§„Éñ„Å´„Åä„Åë„ÇãÈñæÂÄ§„ÅØÔºü</li>
</ol>
<details>
<summary>Ëß£Á≠î‰æã</summary>

1. **logPÔºàËÑÇÊ∫∂ÊÄßÔºâ**
   - Ê∞¥-„Ç™„ÇØ„Çø„Éé„Éº„É´ÂàÜÈÖç‰øÇÊï∞„ÅÆÂØæÊï∞ÂÄ§
   - È´ò„ÅÑÂÄ§Ôºà‰æã: logP > 5Ôºâ: ËÑÇÊ∫∂ÊÄß„ÅåÈ´ò„Åè„ÄÅËÜúÈÄèÈÅéÊÄß„ÅØËâØ„ÅÑ„ÅåÊ∞¥Ê∫∂ÊÄß„Åå‰Ωé„ÅÑ
   - ‰Ωé„ÅÑÂÄ§Ôºà‰æã: logP < 0Ôºâ: Ê∞¥Ê∫∂ÊÄß„ÅåÈ´ò„ÅÑ„Åå„ÄÅËÜúÈÄèÈÅéÊÄß„Åå‰Ωé„ÅÑ
   - **ÂâµËñ¨„Åß„ÅÆÈáçË¶ÅÊÄß**: ÁµåÂè£Âê∏ÂèéÊÄß„ÇÑË°ÄÊ∂≤ËÑ≥Èñ¢ÈñÄÈÄèÈÅéÊÄß„Å´ÂΩ±Èüø

2. **TPSAÔºàÊ•µÊÄßË°®Èù¢Á©çÔºâ**
   - ÂàÜÂ≠ê‰∏≠„ÅÆÊ•µÊÄßÂéüÂ≠êÔºàN, O„Å™„Å©Ôºâ„ÅÆË°®Èù¢Á©ç„ÅÆÂêàË®à
   - TPSA < 140 √Ö¬≤: ÁµåÂè£Âê∏ÂèéÊÄß„ÅåËâØÂ•Ω
   - TPSA < 60 √Ö¬≤: Ë°ÄÊ∂≤ËÑ≥Èñ¢ÈñÄ„ÇíÈÄèÈÅé„Åó„ÇÑ„Åô„ÅÑ
   - **ÂâµËñ¨„Åß„ÅÆÈáçË¶ÅÊÄß**: CNSËñ¨„ÅÆË®≠Ë®à„Å´ÂøÖÈ†à

3. **ÂàÜÂ≠êÈáè**
   - Lipinski„ÅÆ„É´„Éº„É´„Ç™„Éñ„Éï„Ç°„Ç§„Éñ: MW < 500 Da
   - È´òÂàÜÂ≠êÈáèÔºà> 500 DaÔºâ: ËÜúÈÄèÈÅéÊÄß„Åå‰Ωé‰∏ã
   - **ÂâµËñ¨„Åß„ÅÆÈáçË¶ÅÊÄß**: ÁµåÂè£Âê∏ÂèéÊÄß„ÅÆ‰∫àÊ∏¨

</details>

<hr />
<h3>ÊºîÁøí2: ÁâπÂæ¥ÈáèÈÅ∏Êäû„ÅÆÂÆüË£Ö</h3>
<p>‰ª•‰∏ã„ÅÆ„Çø„Çπ„ÇØ„ÇíÂÆüË°å„Åó„Å¶„Åè„Å†„Åï„ÅÑÔºö</p>
<ol>
<li>ESOL„Éá„Éº„Çø„Çª„ÉÉ„Éà„ÅÆË®òËø∞Â≠ê„ÇíË®àÁÆó</li>
<li>Áõ∏Èñ¢‰øÇÊï∞ &gt; 0.9 „ÅÆÁâπÂæ¥Èáè„Éö„Ç¢„ÇíÊ§úÂá∫</li>
<li>ÂÜóÈï∑„Å™ÁâπÂæ¥Èáè„ÇíÂâäÈô§„Åó„Å¶„É¢„Éá„É´„ÇíÂÜçË®ìÁ∑¥</li>
<li>ÊÄßËÉΩÂ§âÂåñ„ÇíË©ï‰æ°</li>
</ol>
<details>
<summary>Ëß£Á≠î‰æã</summary>


<pre><code class="language-python">from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score
import numpy as np
import pandas as pd

# Áõ∏Èñ¢Ë°åÂàó„ÅÆË®àÁÆó
X_df = pd.DataFrame(X_train_scaled)
corr_matrix = X_df.corr()

# È´òÁõ∏Èñ¢„Éö„Ç¢„ÅÆÊ§úÂá∫
threshold = 0.9
high_corr_pairs = []
for i in range(len(corr_matrix.columns)):
    for j in range(i+1, len(corr_matrix.columns)):
        if abs(corr_matrix.iloc[i, j]) &gt; threshold:
            high_corr_pairs.append((i, j, corr_matrix.iloc[i, j]))

print(f&quot;È´òÁõ∏Èñ¢„Éö„Ç¢Êï∞: {len(high_corr_pairs)}&quot;)

# ÂÜóÈï∑ÁâπÂæ¥Èáè„ÅÆÂâäÈô§
columns_to_drop = set([j for i, j, _ in high_corr_pairs])
X_train_reduced = np.delete(X_train_scaled, list(columns_to_drop), axis=1)
X_test_reduced = np.delete(X_test_scaled, list(columns_to_drop), axis=1)

print(f&quot;ÂâäÊ∏õÂâç: {X_train_scaled.shape[1]} ÁâπÂæ¥Èáè&quot;)
print(f&quot;ÂâäÊ∏õÂæå: {X_train_reduced.shape[1]} ÁâπÂæ¥Èáè&quot;)

# „É¢„Éá„É´Ë®ìÁ∑¥ÔºàÂâäÊ∏õÂâçÔºâ
rf_original = RandomForestRegressor(n_estimators=100, random_state=42)
rf_original.fit(X_train_scaled, y_train)
y_pred_orig = rf_original.predict(X_test_scaled)
r2_orig = r2_score(y_test, y_pred_orig)

# „É¢„Éá„É´Ë®ìÁ∑¥ÔºàÂâäÊ∏õÂæåÔºâ
rf_reduced = RandomForestRegressor(n_estimators=100, random_state=42)
rf_reduced.fit(X_train_reduced, y_train)
y_pred_red = rf_reduced.predict(X_test_reduced)
r2_red = r2_score(y_test, y_pred_red)

print(f&quot;\nR¬≤ (ÂâäÊ∏õÂâç): {r2_orig:.3f}&quot;)
print(f&quot;R¬≤ (ÂâäÊ∏õÂæå): {r2_red:.3f}&quot;)
print(f&quot;ÊÄßËÉΩÂ§âÂåñ: {r2_red - r2_orig:+.3f}&quot;)
</code></pre>


**ÊúüÂæÖ„Åï„Çå„ÇãÂá∫Âäõ:**

<pre><code>È´òÁõ∏Èñ¢„Éö„Ç¢Êï∞: 145
ÂâäÊ∏õÂâç: 1034 ÁâπÂæ¥Èáè
ÂâäÊ∏õÂæå: 889 ÁâπÂæ¥Èáè

R¬≤ (ÂâäÊ∏õÂâç): 0.891
R¬≤ (ÂâäÊ∏õÂæå): 0.887
ÊÄßËÉΩÂ§âÂåñ: -0.004
</code></pre>


**Ëß£Èáà**: „Çè„Åö„Åã„Å™ÊÄßËÉΩ‰Ωé‰∏ãÔºà0.004Ôºâ„Åß145ÂÄã„ÅÆÂÜóÈï∑ÁâπÂæ¥Èáè„ÇíÂâäÈô§„Åß„Åç„ÄÅ„É¢„Éá„É´„ÅåÁ∞°ÊΩî„Å´„Å™„Çä„Åæ„Åó„Åü„ÄÇ

</details>

<hr />
<h3>ÊºîÁøí3: „Éè„Ç§„Éë„Éº„Éë„É©„É°„Éº„Çø„ÉÅ„É•„Éº„Éã„É≥„Ç∞</h3>
<p>LightGBM„ÅÆ„Éè„Ç§„Éë„Éº„Éë„É©„É°„Éº„Çø„ÇíÊúÄÈÅ©Âåñ„Åó„ÄÅ„ÉÜ„Çπ„Éà„Çª„ÉÉ„Éà„Åß„ÅÆR¬≤„Çí0.92‰ª•‰∏ä„Å´„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ</p>
<p><strong>„Éí„É≥„Éà</strong>:
- <code>num_leaves</code>ÔºàËëâ„ÅÆÊï∞Ôºâ
- <code>learning_rate</code>ÔºàÂ≠¶ÁøíÁéáÔºâ
- <code>feature_fraction</code>ÔºàÁâπÂæ¥Èáè„ÅÆ„Çµ„É≥„Éó„É™„É≥„Ç∞ÊØîÁéáÔºâ</p>
<details>
<summary>Ëß£Á≠î‰æã</summary>


<pre><code class="language-python">import lightgbm as lgb
from sklearn.model_selection import RandomizedSearchCV
import numpy as np

# „Éë„É©„É°„Éº„ÇøÁ©∫Èñì„ÅÆÂÆöÁæ©
param_dist = {
    'num_leaves': [15, 31, 63, 127],
    'learning_rate': [0.01, 0.05, 0.1],
    'n_estimators': [100, 200, 300],
    'feature_fraction': [0.7, 0.8, 0.9, 1.0],
    'bagging_fraction': [0.7, 0.8, 0.9, 1.0],
    'bagging_freq': [0, 5, 10],
    'min_child_samples': [10, 20, 30]
}

# LightGBM„É¢„Éá„É´
lgbm = lgb.LGBMRegressor(random_state=42, verbose=-1)

# „É©„É≥„ÉÄ„É†„Çµ„Éº„ÉÅ
random_search = RandomizedSearchCV(
    lgbm,
    param_distributions=param_dist,
    n_iter=50,
    cv=5,
    scoring='r2',
    random_state=42,
    n_jobs=-1
)

random_search.fit(X_train_scaled, y_train)

print(f&quot;„Éô„Çπ„Éà„Éë„É©„É°„Éº„Çø: {random_search.best_params_}&quot;)
print(f&quot;„Éô„Çπ„ÉàCV R¬≤: {random_search.best_score_:.3f}&quot;)

# „ÉÜ„Çπ„Éà„Çª„ÉÉ„Éà„Åß„ÅÆË©ï‰æ°
y_pred_optimized = random_search.predict(X_test_scaled)
r2_optimized = r2_score(y_test, y_pred_optimized)
rmse_optimized = np.sqrt(mean_squared_error(y_test, y_pred_optimized))

print(f&quot;\n„ÉÜ„Çπ„Éà R¬≤: {r2_optimized:.3f}&quot;)
print(f&quot;„ÉÜ„Çπ„Éà RMSE: {rmse_optimized:.3f}&quot;)

if r2_optimized &gt;= 0.92:
    print(&quot;‚úÖ ÁõÆÊ®ôÈÅîÊàêÔºÅ R¬≤ ‚â• 0.92&quot;)
else:
    print(f&quot;‚ùå ÁõÆÊ®ôÊú™ÈÅîÊàê„ÄÇ„ÅÇ„Å® {0.92 - r2_optimized:.3f} ÂøÖË¶Å&quot;)
</code></pre>


**ÊúüÂæÖ„Åï„Çå„ÇãÂá∫Âäõ:**

<pre><code>„Éô„Çπ„Éà„Éë„É©„É°„Éº„Çø: {'num_leaves': 63, 'n_estimators': 300, 'min_child_samples': 10,
                  'learning_rate': 0.05, 'feature_fraction': 0.9,
                  'bagging_freq': 5, 'bagging_fraction': 0.9}
„Éô„Çπ„ÉàCV R¬≤: 0.908

„ÉÜ„Çπ„Éà R¬≤: 0.923
„ÉÜ„Çπ„Éà RMSE: 0.429

‚úÖ ÁõÆÊ®ôÈÅîÊàêÔºÅ R¬≤ ‚â• 0.92
</code></pre>


</details>

<hr />
<h3>ÊºîÁøí4: „Ç¢„É≥„Çµ„É≥„Éñ„É´„É¢„Éá„É´„ÅÆÊßãÁØâ</h3>
<p>Ridge„ÄÅRandom Forest„ÄÅLightGBM„ÅÆ3„É¢„Éá„É´„ÅÆ‰∫àÊ∏¨„ÇíÂπ≥ÂùáÂåñÔºà„Ç¢„É≥„Çµ„É≥„Éñ„É´Ôºâ„Åó„ÄÅÊÄßËÉΩ„ÇíÂêë‰∏ä„Åï„Åõ„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ</p>
<details>
<summary>Ëß£Á≠î‰æã</summary>


<pre><code class="language-python"># ÂÄãÂà•„É¢„Éá„É´„ÅÆË®ìÁ∑¥
from sklearn.linear_model import Ridge
from sklearn.ensemble import RandomForestRegressor
import lightgbm as lgb

# Ridge
ridge = Ridge(alpha=1.0)
ridge.fit(X_train_scaled, y_train)
y_pred_ridge = ridge.predict(X_test_scaled)

# Random Forest
rf = RandomForestRegressor(n_estimators=200, max_depth=15, random_state=42)
rf.fit(X_train_scaled, y_train)
y_pred_rf = rf.predict(X_test_scaled)

# LightGBM
lgb_train = lgb.Dataset(X_train_scaled, y_train)
params = {
    'objective': 'regression',
    'metric': 'rmse',
    'num_leaves': 63,
    'learning_rate': 0.05,
    'verbose': -1
}
gbm = lgb.train(params, lgb_train, num_boost_round=200)
y_pred_lgb = gbm.predict(X_test_scaled)

# „Ç¢„É≥„Çµ„É≥„Éñ„É´ÔºàÂçòÁ¥îÂπ≥ÂùáÔºâ
y_pred_ensemble = (y_pred_ridge + y_pred_rf + y_pred_lgb) / 3

# ÊÄßËÉΩÊØîËºÉ
print(&quot;=== ÂÄãÂà•„É¢„Éá„É´„Å®„Ç¢„É≥„Çµ„É≥„Éñ„É´„ÅÆÊÄßËÉΩ ===\n&quot;)
models = {
    'Ridge': y_pred_ridge,
    'Random Forest': y_pred_rf,
    'LightGBM': y_pred_lgb,
    'Ensemble (Âπ≥Âùá)': y_pred_ensemble
}

for name, y_pred in models.items():
    r2 = r2_score(y_test, y_pred)
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    print(f&quot;{name:20s} R¬≤: {r2:.3f}  RMSE: {rmse:.3f}&quot;)

# Èáç„Åø‰ªò„Åç„Ç¢„É≥„Çµ„É≥„Éñ„É´ÔºàÊÄßËÉΩ„Å´Âøú„Åò„ÅüÈáç„ÅøÔºâ
weights = [0.1, 0.4, 0.5]  # Ridge, RF, LightGBM
y_pred_weighted = (
    weights[0] * y_pred_ridge +
    weights[1] * y_pred_rf +
    weights[2] * y_pred_lgb
)

r2_weighted = r2_score(y_test, y_pred_weighted)
rmse_weighted = np.sqrt(mean_squared_error(y_test, y_pred_weighted))

print(f&quot;\nÈáç„Åø‰ªò„Åç„Ç¢„É≥„Çµ„É≥„Éñ„É´  R¬≤: {r2_weighted:.3f}  RMSE: {rmse_weighted:.3f}&quot;)
</code></pre>


**ÊúüÂæÖ„Åï„Çå„ÇãÂá∫Âäõ:**

<pre><code>=== ÂÄãÂà•„É¢„Éá„É´„Å®„Ç¢„É≥„Çµ„É≥„Éñ„É´„ÅÆÊÄßËÉΩ ===

Ridge                R¬≤: 0.789  RMSE: 0.712
Random Forest        R¬≤: 0.891  RMSE: 0.511
LightGBM             R¬≤: 0.912  RMSE: 0.459
Ensemble (Âπ≥Âùá)       R¬≤: 0.918  RMSE: 0.443

Èáç„Åø‰ªò„Åç„Ç¢„É≥„Çµ„É≥„Éñ„É´  R¬≤: 0.920  RMSE: 0.437
</code></pre>


**Ëß£Èáà**: „Ç¢„É≥„Çµ„É≥„Éñ„É´„Å´„Çà„Çä„ÄÅÊúÄËâØ„ÅÆÂçò‰∏Ä„É¢„Éá„É´ÔºàLightGBMÔºâ„Çà„Çä„ÇÇ„Åï„Çâ„Å´ÊÄßËÉΩ„ÅåÂêë‰∏ä„Åó„Åæ„Åó„Åü„ÄÇ

</details>

<hr />
<h2>„Åæ„Å®„ÇÅ</h2>
<p>„Åì„ÅÆÁ´†„Åß„ÅØ„ÄÅ‰ª•‰∏ã„ÇíÂ≠¶„Å≥„Åæ„Åó„ÅüÔºö</p>
<h3>Â≠¶Áøí„Åó„ÅüÂÜÖÂÆπ</h3>
<ol>
<li>
<p><strong>ÂàÜÂ≠êË®òËø∞Â≠ê</strong>
   - 1DË®òËø∞Â≠êÔºöÂàÜÂ≠êÈáè„ÄÅlogP„ÄÅTPSA
   - 2DË®òËø∞Â≠êÔºöMorganÊåáÁ¥ã„ÄÅMACCSÈçµ
   - 3DË®òËø∞Â≠êÔºöÁ´ã‰ΩìÈÖçÂ∫ß‰æùÂ≠òË®òËø∞Â≠ê
   - mordred„Å´„Çà„ÇãÂåÖÊã¨ÁöÑË®àÁÆóÔºà1,800Á®ÆÈ°û‰ª•‰∏äÔºâ</p>
</li>
<li>
<p><strong>QSAR/QSPR„É¢„Éá„É™„É≥„Ç∞</strong>
   - Á∑öÂΩ¢„É¢„Éá„É´ÔºàRidge„ÄÅLassoÔºâ
   - ÈùûÁ∑öÂΩ¢„É¢„Éá„É´ÔºàRandom Forest„ÄÅLightGBMÔºâ
   - „É¢„Éá„É´Ë©ï‰æ°ÔºàR¬≤„ÄÅRMSE„ÄÅMAEÔºâ</p>
</li>
<li>
<p><strong>ÁâπÂæ¥ÈáèÈÅ∏Êäû„Å®Ëß£Èáà</strong>
   - Áõ∏Èñ¢ÂàÜÊûê„Å´„Çà„ÇãÂÜóÈï∑ÊÄßÈô§Âéª
   - SHAP/LIME„Å´„Çà„ÇãÁâπÂæ¥ÈáèÈáçË¶ÅÂ∫¶
   - „Å©„ÅÆÈÉ®ÂàÜÊßãÈÄ†„ÅåÁâ©ÊÄß„Å´ÂØÑ‰∏é„Åô„Çã„Åã</p>
</li>
<li>
<p><strong>ÂÆüË∑µÔºöESOLÊ∫∂Ëß£Â∫¶‰∫àÊ∏¨</strong>
   - „Éá„Éº„ÇøÂèñÂæó„Å®ÂâçÂá¶ÁêÜ
   - Ë§áÊï∞„É¢„Éá„É´„ÅÆÊØîËºÉ
   - „Éè„Ç§„Éë„Éº„Éë„É©„É°„Éº„ÇøÊúÄÈÅ©Âåñ
   - „Ç¢„É≥„Çµ„É≥„Éñ„É´Â≠¶Áøí</p>
</li>
</ol>
<h3>Ê¨°„ÅÆ„Çπ„ÉÜ„ÉÉ„Éó</h3>
<p>Á¨¨3Á´†„Åß„ÅØ„ÄÅÂåñÂ≠¶Á©∫ÈñìÊé¢Á¥¢„Å®È°û‰ººÊÄßÊ§úÁ¥¢„ÇíÂ≠¶„Å≥„Åæ„Åô„ÄÇ</p>
<p><strong><a href="./chapter-3.html">Á¨¨3Á´†ÔºöÂåñÂ≠¶Á©∫ÈñìÊé¢Á¥¢„Å®È°û‰ººÊÄßÊ§úÁ¥¢ ‚Üí</a></strong></p>
<hr />
<h2>ÂèÇËÄÉÊñáÁåÆ</h2>
<ol>
<li>Todeschini, R., &amp; Consonni, V. (2009). <em>Molecular Descriptors for Chemoinformatics</em>. Wiley-VCH. ISBN: 978-3527318520</li>
<li>Delaney, J. S. (2004). "ESOL: Estimating aqueous solubility directly from molecular structure." <em>Journal of Chemical Information and Computer Sciences</em>, 44(3), 1000-1005. DOI: 10.1021/ci034243x</li>
<li>Moriwaki, H. et al. (2018). "Mordred: a molecular descriptor calculator." <em>Journal of Cheminformatics</em>, 10, 4. DOI: 10.1186/s13321-018-0258-y</li>
<li>Lundberg, S. M., &amp; Lee, S. I. (2017). "A unified approach to interpreting model predictions." <em>Advances in Neural Information Processing Systems</em>, 30.</li>
</ol>
<hr />
<p><strong><a href="./chapter-1.html">‚Üê Á¨¨1Á´†</a></strong> | <strong><a href="./index.html">„Ç∑„É™„Éº„Ç∫„Éà„ÉÉ„Éó„Å∏</a></strong> | <strong><a href="./chapter-3.html">Á¨¨3Á´†„Å∏ ‚Üí</a></strong></p><div class="navigation">
    <a href="chapter-1.html" class="nav-button">‚Üê Á¨¨1Á´†</a>
    <a href="index.html" class="nav-button">„Ç∑„É™„Éº„Ç∫ÁõÆÊ¨°„Å´Êàª„Çã</a>
    <a href="chapter-3.html" class="nav-button">Á¨¨3Á´† ‚Üí</a>
</div>
    </main>

    <footer>
        <p><strong>‰ΩúÊàêËÄÖ</strong>: AI Terakoya Content Team</p>
        <p><strong>Áõ£‰øÆ</strong>: Dr. Yusuke HashimotoÔºàÊù±ÂåóÂ§ßÂ≠¶Ôºâ</p>
        <p><strong>„Éê„Éº„Ç∏„Éß„É≥</strong>: 1.0 | <strong>‰ΩúÊàêÊó•</strong>: 2025-10-18</p>
        <p><strong>„É©„Ç§„Çª„É≥„Çπ</strong>: Creative Commons BY 4.0</p>
        <p>¬© 2025 AI Terakoya. All rights reserved.</p>
    </footer>
</body>
</html>
