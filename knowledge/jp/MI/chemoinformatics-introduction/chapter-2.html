<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ç¬¬2ç« ï¼šQSAR/QSPRå…¥é–€ - ç‰©æ€§äºˆæ¸¬ã®åŸºç¤ - AI Terakoya</title>

    <style>
        :root {
            --color-primary: #2c3e50;
            --color-primary-dark: #1a252f;
            --color-accent: #7b2cbf;
            --color-accent-light: #9d4edd;
            --color-text: #2d3748;
            --color-text-light: #4a5568;
            --color-bg: #ffffff;
            --color-bg-alt: #f7fafc;
            --color-border: #e2e8f0;
            --color-code-bg: #f8f9fa;
            --color-link: #3182ce;
            --color-link-hover: #2c5aa0;

            --spacing-xs: 0.5rem;
            --spacing-sm: 1rem;
            --spacing-md: 1.5rem;
            --spacing-lg: 2rem;
            --spacing-xl: 3rem;

            --font-body: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            --font-mono: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;

            --border-radius: 8px;
            --box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: var(--font-body);
            line-height: 1.7;
            color: var(--color-text);
            background-color: var(--color-bg);
            font-size: 16px;
        }

        header {
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            padding: var(--spacing-xl) var(--spacing-md);
            margin-bottom: var(--spacing-xl);
            box-shadow: var(--box-shadow);
        }

        .header-content {
            max-width: 900px;
            margin: 0 auto;
        }

        h1 {
            font-size: 2rem;
            font-weight: 700;
            margin-bottom: var(--spacing-sm);
            line-height: 1.2;
        }

        .subtitle {
            font-size: 1.1rem;
            opacity: 0.95;
            font-weight: 400;
            margin-bottom: var(--spacing-md);
        }

        .meta {
            display: flex;
            flex-wrap: wrap;
            gap: var(--spacing-md);
            font-size: 0.9rem;
            opacity: 0.9;
        }

        .meta-item {
            display: flex;
            align-items: center;
            gap: 0.3rem;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 0 var(--spacing-md) var(--spacing-xl);
        }

        h2 {
            font-size: 1.75rem;
            color: var(--color-primary);
            margin-top: var(--spacing-xl);
            margin-bottom: var(--spacing-md);
            padding-bottom: var(--spacing-xs);
            border-bottom: 3px solid var(--color-accent);
        }

        h3 {
            font-size: 1.4rem;
            color: var(--color-primary);
            margin-top: var(--spacing-lg);
            margin-bottom: var(--spacing-sm);
        }

        h4 {
            font-size: 1.1rem;
            color: var(--color-primary-dark);
            margin-top: var(--spacing-md);
            margin-bottom: var(--spacing-sm);
        }

        p {
            margin-bottom: var(--spacing-md);
            color: var(--color-text);
        }

        a {
            color: var(--color-link);
            text-decoration: none;
            transition: color 0.2s;
        }

        a:hover {
            color: var(--color-link-hover);
            text-decoration: underline;
        }

        ul, ol {
            margin-left: var(--spacing-lg);
            margin-bottom: var(--spacing-md);
        }

        li {
            margin-bottom: var(--spacing-xs);
            color: var(--color-text);
        }

        pre {
            background-color: var(--color-code-bg);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            overflow-x: auto;
            margin-bottom: var(--spacing-md);
            font-family: var(--font-mono);
            font-size: 0.9rem;
            line-height: 1.5;
        }

        code {
            font-family: var(--font-mono);
            font-size: 0.9em;
            background-color: var(--color-code-bg);
            padding: 0.2em 0.4em;
            border-radius: 3px;
        }

        pre code {
            background-color: transparent;
            padding: 0;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: var(--spacing-md);
            font-size: 0.95rem;
        }

        th, td {
            border: 1px solid var(--color-border);
            padding: var(--spacing-sm);
            text-align: left;
        }

        th {
            background-color: var(--color-bg-alt);
            font-weight: 600;
            color: var(--color-primary);
        }

        blockquote {
            border-left: 4px solid var(--color-accent);
            padding-left: var(--spacing-md);
            margin: var(--spacing-md) 0;
            color: var(--color-text-light);
            font-style: italic;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        .mermaid {
            text-align: center;
            margin: var(--spacing-lg) 0;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        details {
            background-color: var(--color-bg-alt);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            margin-bottom: var(--spacing-md);
        }

        summary {
            cursor: pointer;
            font-weight: 600;
            color: var(--color-primary);
            user-select: none;
            padding: var(--spacing-xs);
            margin: calc(-1 * var(--spacing-md));
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        summary:hover {
            background-color: rgba(123, 44, 191, 0.1);
        }

        details[open] summary {
            margin-bottom: var(--spacing-md);
            border-bottom: 1px solid var(--color-border);
        }

        .learning-objectives {
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
            padding: var(--spacing-lg);
            border-radius: var(--border-radius);
            border-left: 4px solid var(--color-accent);
            margin-bottom: var(--spacing-xl);
        }

        .learning-objectives h2 {
            margin-top: 0;
            border-bottom: none;
        }

        .navigation {
            display: flex;
            justify-content: space-between;
            gap: var(--spacing-md);
            margin: var(--spacing-xl) 0;
            padding-top: var(--spacing-lg);
            border-top: 2px solid var(--color-border);
        }

        .nav-button {
            flex: 1;
            padding: var(--spacing-md);
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            border-radius: var(--border-radius);
            text-align: center;
            font-weight: 600;
            transition: transform 0.2s, box-shadow 0.2s;
            box-shadow: var(--box-shadow);
        }

        .nav-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
            text-decoration: none;
        }

        footer {
            margin-top: var(--spacing-xl);
            padding: var(--spacing-lg) var(--spacing-md);
            background-color: var(--color-bg-alt);
            border-top: 1px solid var(--color-border);
            text-align: center;
            font-size: 0.9rem;
            color: var(--color-text-light);
        }
        .disclaimer {
            max-width: 900px;
            margin: 2rem auto;
            padding: 1.5rem;
            background: #f8f9fa;
            border-left: 4px solid #6c757d;
            border-radius: 4px;
        }

        .disclaimer h3 {
            color: #495057;
            margin-bottom: 1rem;
            font-size: 1.1rem;
        }

        .disclaimer ul {
            list-style: none;
            padding-left: 0;
        }

        .disclaimer li {
            padding: 0.5rem 0;
            padding-left: 1.5rem;
            position: relative;
            font-size: 0.9rem;
            color: #6c757d;
            line-height: 1.6;
        }

        .disclaimer li::before {
            content: "âš ï¸";
            position: absolute;
            left: 0;
        }


        @media (max-width: 768px) {
            h1 {
                font-size: 1.5rem;
            }

            h2 {
                font-size: 1.4rem;
            }

            h3 {
                font-size: 1.2rem;
            }

            .meta {
                font-size: 0.85rem;
            }

            .navigation {
                flex-direction: column;
            }

            table {
                font-size: 0.85rem;
            }

            th, td {
                padding: var(--spacing-xs);
            }
        }
    
        /* Breadcrumb styles */
        .breadcrumb {
            background: #f7fafc;
            padding: 0.75rem 1rem;
            border-bottom: 1px solid #e2e8f0;
            font-size: 0.9rem;
        }

        .breadcrumb-content {
            max-width: 900px;
            margin: 0 auto;
            display: flex;
            align-items: center;
            flex-wrap: wrap;
            gap: 0.5rem;
        }

        .breadcrumb a {
            color: #667eea;
            text-decoration: none;
            transition: color 0.2s;
        }

        .breadcrumb a:hover {
            color: #764ba2;
            text-decoration: underline;
        }

        .breadcrumb-separator {
            color: #a0aec0;
            margin: 0 0.25rem;
        }

        .breadcrumb-current {
            color: #4a5568;
            font-weight: 500;
        }
    </style>

    <script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
    <script>
        mermaid.initialize({ startOnLoad: true, theme: 'default', securityLevel: 'strict' });
    </script>

    <!-- MathJax for LaTeX equation rendering -->
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\(', '\)']],
                displayMath: [['$$', '$$'], ['\[', '\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
                ignoreHtmlClass: 'mermaid'
            }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" async></script>
</head>
<body>
        <nav class="breadcrumb">
        <div class="breadcrumb-content">
            <a href="/wp/knowledge/jp/index.html">AIå¯ºå­å±‹ãƒˆãƒƒãƒ—</a><span class="breadcrumb-separator">â€º</span><a href="/wp/knowledge/jp/MI/index.html">ãƒãƒ†ãƒªã‚¢ãƒ«ã‚ºãƒ»ã‚¤ãƒ³ãƒ•ã‚©ãƒãƒ†ã‚£ã‚¯ã‚¹</a><span class="breadcrumb-separator">â€º</span><a href="/wp/knowledge/jp/MI/chemoinformatics-introduction/index.html">Chemoinformatics</a><span class="breadcrumb-separator">â€º</span><span class="breadcrumb-current">Chapter 2</span>
        </div>
    </nav>

    <header>
        <div class="header-content">
            <h1>QSAR/QSPRå…¥é–€ - ç‰©æ€§äºˆæ¸¬ã®åŸºç¤</h1>
            <p class="subtitle"></p>
            <div class="meta">
                <span class="meta-item">ğŸ“– èª­äº†æ™‚é–“: 25-30åˆ†</span>
                <span class="meta-item">ğŸ“Š é›£æ˜“åº¦: åˆç´šã€œä¸­ç´š</span>
                <span class="meta-item">ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹: 12å€‹</span>
                <span class="meta-item">ğŸ“ æ¼”ç¿’å•é¡Œ: 4å•</span>
            </div>
        </div>
    </header>

    <main class="container">
<h1>ç¬¬2ç« ï¼šQSAR/QSPRå…¥é–€ - ç‰©æ€§äºˆæ¸¬ã®åŸºç¤</h1>
<h2>ã“ã®ç« ã§å­¦ã¶ã“ã¨</h2>
<p>ã“ã®ç« ã§ã¯ã€åˆ†å­è¨˜è¿°å­ã®è¨ˆç®—ã¨QSAR/QSPRãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã®åŸºç¤ã‚’å­¦ã³ã¾ã™ã€‚åˆ†å­æ§‹é€ ã‹ã‚‰ç‰©æ€§ã‚’äºˆæ¸¬ã™ã‚‹æŠ€è¡“ã¯ã€å‰µè–¬ã‚„ææ–™é–‹ç™ºã®åŠ¹ç‡åŒ–ã«ä¸å¯æ¬ ã§ã™ã€‚</p>
<h3>å­¦ç¿’ç›®æ¨™</h3>
<ul>
<li>âœ… 1D/2D/3Dåˆ†å­è¨˜è¿°å­ã®ç¨®é¡ã¨ä½¿ã„åˆ†ã‘ã‚’ç†è§£ã—ã¦ã„ã‚‹</li>
<li>âœ… mordredã§åŒ…æ‹¬çš„ãªè¨˜è¿°å­ã‚’è¨ˆç®—ã§ãã‚‹</li>
<li>âœ… QSAR/QSPRãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã—ã€è©•ä¾¡ã§ãã‚‹</li>
<li>âœ… ç‰¹å¾´é‡é¸æŠã¨è§£é‡ˆã«ã‚ˆã‚Šã€æ§‹é€ -ç‰©æ€§ç›¸é–¢ã‚’ç†è§£ã§ãã‚‹</li>
<li>âœ… æº¶è§£åº¦äºˆæ¸¬ãªã©å®Ÿãƒ‡ãƒ¼ã‚¿ã«æ©Ÿæ¢°å­¦ç¿’ã‚’é©ç”¨ã§ãã‚‹</li>
</ul>
<hr />
<h2>2.1 åˆ†å­è¨˜è¿°å­ã®åŸºç¤</h2>
<p><strong>åˆ†å­è¨˜è¿°å­ï¼ˆMolecular Descriptorï¼‰</strong>ã¯ã€åˆ†å­æ§‹é€ ã‚’æ•°å€¤åŒ–ã—ãŸã‚‚ã®ã§ã€æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®å…¥åŠ›ã¨ã—ã¦ä½¿ç”¨ã•ã‚Œã¾ã™ã€‚</p>
<div class="mermaid">
flowchart TD
    A[åˆ†å­æ§‹é€ ] --> B[åˆ†å­è¨˜è¿°å­è¨ˆç®—]
    B --> C[1Dè¨˜è¿°å­]
    B --> D[2Dè¨˜è¿°å­]
    B --> E[3Dè¨˜è¿°å­]

    C --> F[åˆ†å­é‡ã€logPã€TPSA]
    D --> G[æŒ‡ç´‹ã€ã‚°ãƒ©ãƒ•è¨˜è¿°å­]
    E --> H[ç«‹ä½“é…åº§ä¾å­˜è¨˜è¿°å­]

    F --> I[æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«]
    G --> I
    H --> I
    I --> J[ç‰©æ€§äºˆæ¸¬]

    style A fill:#e3f2fd
    style I fill:#4CAF50,color:#fff
    style J fill:#FF9800,color:#fff
</div>

<h3>2.1.1 1Dè¨˜è¿°å­ï¼šåˆ†å­å…¨ä½“ã®æ€§è³ª</h3>
<p>1Dè¨˜è¿°å­ã¯ã€åˆ†å­æ§‹é€ ã«ä¾å­˜ã—ãªã„åŸºæœ¬çš„ãªæ€§è³ªã‚’è¡¨ã—ã¾ã™ã€‚</p>
<p><strong>ä¸»è¦ãª1Dè¨˜è¿°å­</strong>ï¼š</p>
<table>
<thead>
<tr>
<th>è¨˜è¿°å­</th>
<th>èª¬æ˜</th>
<th>ç”¨é€”</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>åˆ†å­é‡ï¼ˆMWï¼‰</strong></td>
<td>åˆ†å­ã®è³ªé‡</td>
<td>è†œé€éæ€§äºˆæ¸¬</td>
</tr>
<tr>
<td><strong>logP</strong></td>
<td>è„‚æº¶æ€§ï¼ˆæ°´-ã‚ªã‚¯ã‚¿ãƒãƒ¼ãƒ«åˆ†é…ä¿‚æ•°ï¼‰</td>
<td>å¸åæ€§äºˆæ¸¬</td>
</tr>
<tr>
<td><strong>TPSA</strong></td>
<td>æ¥µæ€§è¡¨é¢ç©</td>
<td>è¡€æ¶²è„³é–¢é–€é€éæ€§</td>
</tr>
<tr>
<td><strong>HBA/HBD</strong></td>
<td>æ°´ç´ çµåˆå—å®¹ä½“/ä¾›ä¸ä½“æ•°</td>
<td>Lipinskiãƒ«ãƒ¼ãƒ«</td>
</tr>
<tr>
<td><strong>å›è»¢å¯èƒ½çµåˆæ•°</strong></td>
<td>åˆ†å­ã®æŸ”è»Ÿæ€§</td>
<td>çµåˆè¦ªå’Œæ€§</td>
</tr>
</tbody>
</table>
<h4>ã‚³ãƒ¼ãƒ‰ä¾‹1: åŸºæœ¬çš„ãª1Dè¨˜è¿°å­ã®è¨ˆç®—</h4>
<pre><code class="language-python">from rdkit import Chem
from rdkit.Chem import Descriptors
import pandas as pd

# ã‚µãƒ³ãƒ—ãƒ«åŒ»è–¬å“
drugs = {
    &quot;Aspirin&quot;: &quot;CC(=O)Oc1ccccc1C(=O)O&quot;,
    &quot;Ibuprofen&quot;: &quot;CC(C)Cc1ccc(cc1)C(C)C(=O)O&quot;,
    &quot;Paracetamol&quot;: &quot;CC(=O)Nc1ccc(O)cc1&quot;,
    &quot;Caffeine&quot;: &quot;CN1C=NC2=C1C(=O)N(C(=O)N2C)C&quot;
}

# è¨˜è¿°å­è¨ˆç®—
data = []
for name, smiles in drugs.items():
    mol = Chem.MolFromSmiles(smiles)
    data.append({
        'Name': name,
        'MW': Descriptors.MolWt(mol),
        'LogP': Descriptors.MolLogP(mol),
        'TPSA': Descriptors.TPSA(mol),
        'HBA': Descriptors.NumHAcceptors(mol),
        'HBD': Descriptors.NumHDonors(mol),
        'RotBonds': Descriptors.NumRotatableBonds(mol)
    })

df = pd.DataFrame(data)
print(df.to_string(index=False))
</code></pre>
<p><strong>å‡ºåŠ›ä¾‹:</strong></p>
<pre><code>        Name      MW  LogP  TPSA  HBA  HBD  RotBonds
     Aspirin  180.16  1.19 63.60    4    1         3
   Ibuprofen  206.28  3.50 37.30    2    1         4
 Paracetamol  151.16  0.46 49.33    2    2         1
    Caffeine  194.19 -0.07 58.44    6    0         0
</code></pre>
<h3>2.1.2 2Dè¨˜è¿°å­ï¼šåˆ†å­æŒ‡ç´‹ã¨ã‚°ãƒ©ãƒ•è¨˜è¿°å­</h3>
<p>2Dè¨˜è¿°å­ã¯ã€åˆ†å­ã®ãƒˆãƒãƒ­ã‚¸ãƒ¼ï¼ˆçµåˆé–¢ä¿‚ï¼‰ã‚’åæ˜ ã—ã¾ã™ã€‚</p>
<h4>MorganæŒ‡ç´‹ï¼ˆECFPï¼‰</h4>
<p>MorganæŒ‡ç´‹ã¯ã€å„åŸå­ã®å‘¨è¾ºç’°å¢ƒã‚’ãƒãƒƒã‚·ãƒ¥åŒ–ã—ãŸãƒ“ãƒƒãƒˆãƒ™ã‚¯ãƒˆãƒ«ã§ã™ã€‚</p>
<div class="mermaid">
flowchart LR
    A[ä¸­å¿ƒåŸå­] --> B[åŠå¾„1ã®ç’°å¢ƒ]
    B --> C[åŠå¾„2ã®ç’°å¢ƒ]
    C --> D[ãƒãƒƒã‚·ãƒ¥åŒ–]
    D --> E[ãƒ“ãƒƒãƒˆãƒ™ã‚¯ãƒˆãƒ«]

    style A fill:#e3f2fd
    style E fill:#4CAF50,color:#fff
</div>

<h4>ã‚³ãƒ¼ãƒ‰ä¾‹2: MorganæŒ‡ç´‹ã®è¨ˆç®—</h4>
<pre><code class="language-python">from rdkit import Chem
from rdkit.Chem import AllChem
import numpy as np

# åˆ†å­ã®æº–å‚™
smiles_list = [
    &quot;CCO&quot;,  # ã‚¨ã‚¿ãƒãƒ¼ãƒ«
    &quot;CCCO&quot;,  # ãƒ—ãƒ­ãƒ‘ãƒãƒ¼ãƒ«ï¼ˆé¡ä¼¼ï¼‰
    &quot;c1ccccc1&quot;  # ãƒ™ãƒ³ã‚¼ãƒ³ï¼ˆç•°ãªã‚‹ï¼‰
]

# MorganæŒ‡ç´‹ã®è¨ˆç®—ï¼ˆåŠå¾„2ã€ãƒ“ãƒƒãƒˆé•·2048ï¼‰
fps = []
for smiles in smiles_list:
    mol = Chem.MolFromSmiles(smiles)
    fp = AllChem.GetMorganFingerprintAsBitVect(
        mol,
        radius=2,
        nBits=2048
    )
    fps.append(fp)

# Tanimotoé¡ä¼¼åº¦ã®è¨ˆç®—
from rdkit import DataStructs

print(&quot;Tanimotoé¡ä¼¼åº¦è¡Œåˆ—:&quot;)
for i, fp1 in enumerate(fps):
    similarities = []
    for j, fp2 in enumerate(fps):
        sim = DataStructs.TanimotoSimilarity(fp1, fp2)
        similarities.append(f&quot;{sim:.3f}&quot;)
    print(f&quot;{smiles_list[i]:15s} {' '.join(similarities)}&quot;)
</code></pre>
<p><strong>å‡ºåŠ›ä¾‹:</strong></p>
<pre><code>Tanimotoé¡ä¼¼åº¦è¡Œåˆ—:
CCO             1.000 0.571 0.111
CCCO            0.571 1.000 0.103
c1ccccc1        0.111 0.103 1.000
</code></pre>
<p><strong>è§£é‡ˆ</strong>: ã‚¨ã‚¿ãƒãƒ¼ãƒ«ã¨ãƒ—ãƒ­ãƒ‘ãƒãƒ¼ãƒ«ã¯é¡ä¼¼åº¦0.571ã¨é«˜ãã€ãƒ™ãƒ³ã‚¼ãƒ³ã¨ã¯ä½ã„é¡ä¼¼åº¦ã‚’ç¤ºã—ã¾ã™ã€‚</p>
<h4>ã‚³ãƒ¼ãƒ‰ä¾‹3: MACCSéµï¼ˆæ§‹é€ çš„ç‰¹å¾´ï¼‰</h4>
<pre><code class="language-python">from rdkit import Chem
from rdkit.Chem import MACCSkeys
import numpy as np

# MACCSéµã¯166ãƒ“ãƒƒãƒˆã®æ§‹é€ çš„ç‰¹å¾´
smiles = &quot;CC(=O)Oc1ccccc1C(=O)O&quot;  # ã‚¢ã‚¹ãƒ”ãƒªãƒ³
mol = Chem.MolFromSmiles(smiles)

# MACCSéµã®è¨ˆç®—
maccs = MACCSkeys.GenMACCSKeys(mol)

# ãƒ“ãƒƒãƒˆãŒç«‹ã£ã¦ã„ã‚‹ç‰¹å¾´ã‚’è¡¨ç¤º
on_bits = [i for i in range(len(maccs)) if maccs[i]]
print(f&quot;ã‚¢ã‚¹ãƒ”ãƒªãƒ³ã®æ§‹é€ çš„ç‰¹å¾´ï¼ˆON bitsï¼‰: {len(on_bits)} / 166&quot;)
print(f&quot;ç‰¹å¾´ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹: {on_bits[:20]}...&quot;)  # æœ€åˆã®20å€‹
</code></pre>
<p><strong>å‡ºåŠ›ä¾‹:</strong></p>
<pre><code>ã‚¢ã‚¹ãƒ”ãƒªãƒ³ã®æ§‹é€ çš„ç‰¹å¾´ï¼ˆON bitsï¼‰: 38 / 166
ç‰¹å¾´ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹: [1, 7, 10, 21, 32, 35, 47, 48, 56, 60, ...]
</code></pre>
<h3>2.1.3 3Dè¨˜è¿°å­ï¼šç«‹ä½“é…åº§ä¾å­˜è¨˜è¿°å­</h3>
<p>3Dè¨˜è¿°å­ã¯ã€åˆ†å­ã®ç«‹ä½“æ§‹é€ ã‚’è€ƒæ…®ã—ãŸè¨˜è¿°å­ã§ã™ã€‚</p>
<h4>ã‚³ãƒ¼ãƒ‰ä¾‹4: 3Dè¨˜è¿°å­ã®è¨ˆç®—</h4>
<pre><code class="language-python">from rdkit import Chem
from rdkit.Chem import AllChem, Descriptors3D
import pandas as pd

# åˆ†å­ã®æº–å‚™
smiles = &quot;CC(C)Cc1ccc(cc1)C(C)C(=O)O&quot;  # ã‚¤ãƒ–ãƒ—ãƒ­ãƒ•ã‚§ãƒ³
mol = Chem.MolFromSmiles(smiles)

# 3Dåº§æ¨™ã‚’ç”Ÿæˆ
AllChem.EmbedMolecule(mol, randomSeed=42)
AllChem.MMFFOptimizeMolecule(mol)

# 3Dè¨˜è¿°å­ã®è¨ˆç®—
descriptors_3d = {
    'PMI1': Descriptors3D.PMI1(mol),  # ä¸»æ…£æ€§ãƒ¢ãƒ¼ãƒ¡ãƒ³ãƒˆ1
    'PMI2': Descriptors3D.PMI2(mol),  # ä¸»æ…£æ€§ãƒ¢ãƒ¼ãƒ¡ãƒ³ãƒˆ2
    'PMI3': Descriptors3D.PMI3(mol),  # ä¸»æ…£æ€§ãƒ¢ãƒ¼ãƒ¡ãƒ³ãƒˆ3
    'NPR1': Descriptors3D.NPR1(mol),  # æ­£è¦åŒ–ä¸»æ…£æ€§æ¯”1
    'NPR2': Descriptors3D.NPR2(mol),  # æ­£è¦åŒ–ä¸»æ…£æ€§æ¯”2
    'RadiusOfGyration': Descriptors3D.RadiusOfGyration(mol),
    'InertialShapeFactor': Descriptors3D.InertialShapeFactor(mol),
    'Asphericity': Descriptors3D.Asphericity(mol),
    'Eccentricity': Descriptors3D.Eccentricity(mol)
}

df = pd.DataFrame([descriptors_3d])
print(df.T)
</code></pre>
<p><strong>å‡ºåŠ›ä¾‹:</strong></p>
<pre><code>                              0
PMI1                    197.45
PMI2                    598.32
PMI3                    712.18
NPR1                      0.28
NPR2                      0.84
RadiusOfGyration          3.42
InertialShapeFactor       0.18
Asphericity               0.23
Eccentricity              0.89
</code></pre>
<h3>2.1.4 mordredã«ã‚ˆã‚‹åŒ…æ‹¬çš„è¨˜è¿°å­è¨ˆç®—</h3>
<p>mordredã¯1,800ç¨®é¡ä»¥ä¸Šã®è¨˜è¿°å­ã‚’ä¸€æ‹¬è¨ˆç®—ã§ãã‚‹ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§ã™ã€‚</p>
<h4>ã‚³ãƒ¼ãƒ‰ä¾‹5: mordredã§å…¨è¨˜è¿°å­ã‚’è¨ˆç®—</h4>
<pre><code class="language-python"># mordredã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
# pip install mordred

from mordred import Calculator, descriptors
from rdkit import Chem
import pandas as pd

# Calculatorã®åˆæœŸåŒ–ï¼ˆå…¨è¨˜è¿°å­ï¼‰
calc = Calculator(descriptors, ignore_3D=True)

# åˆ†å­ãƒªã‚¹ãƒˆ
smiles_list = [
    &quot;CCO&quot;,
    &quot;CC(=O)Oc1ccccc1C(=O)O&quot;,
    &quot;CN1C=NC2=C1C(=O)N(C(=O)N2C)C&quot;
]

mols = [Chem.MolFromSmiles(smi) for smi in smiles_list]

# è¨˜è¿°å­è¨ˆç®—ï¼ˆæ™‚é–“ãŒã‹ã‹ã‚‹å ´åˆã‚ã‚Šï¼‰
df = calc.pandas(mols)

print(f&quot;è¨ˆç®—ã•ã‚ŒãŸè¨˜è¿°å­æ•°: {len(df.columns)}&quot;)
print(f&quot;åˆ†å­æ•°: {len(df)}&quot;)
print(&quot;\næœ€åˆã®10å€‹ã®è¨˜è¿°å­:&quot;)
print(df.iloc[:, :10])

# NaNã‚„ç„¡é™å¤§ã‚’é™¤å»
df_clean = df.select_dtypes(include=[np.number])
df_clean = df_clean.replace([np.inf, -np.inf], np.nan)
df_clean = df_clean.dropna(axis=1, how='any')

print(f&quot;\nã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°å¾Œã®è¨˜è¿°å­æ•°: {len(df_clean.columns)}&quot;)
</code></pre>
<p><strong>å‡ºåŠ›ä¾‹:</strong></p>
<pre><code>è¨ˆç®—ã•ã‚ŒãŸè¨˜è¿°å­æ•°: 1826
åˆ†å­æ•°: 3

æœ€åˆã®10å€‹ã®è¨˜è¿°å­:
   ABC    ABCGG  nAcid  nBase  SpAbs_A  SpMax_A  SpDiam_A  ...
0  3.46    3.82      0      0     2.57     1.29      2.31  ...
1  16.52  17.88      1      0    13.45     2.34      5.67  ...
2  15.78  16.45      0      6    12.87     2.12      5.34  ...

ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°å¾Œã®è¨˜è¿°å­æ•°: 1654
</code></pre>
<hr />
<h2>2.2 QSAR/QSPRãƒ¢ãƒ‡ãƒªãƒ³ã‚°</h2>
<h3>å®šç¾©</h3>
<ul>
<li><strong>QSARï¼ˆQuantitative Structure-Activity Relationshipï¼‰</strong>: æ§‹é€ -æ´»æ€§ç›¸é–¢</li>
<li>ç”Ÿç‰©æ´»æ€§ï¼ˆIC50ã€EC50ãªã©ï¼‰ã®äºˆæ¸¬</li>
<li>
<p>å‰µè–¬ã«ãŠã‘ã‚‹å€™è£œåŒ–åˆç‰©ã®é¸å®š</p>
</li>
<li>
<p><strong>QSPRï¼ˆQuantitative Structure-Property Relationshipï¼‰</strong>: æ§‹é€ -ç‰©æ€§ç›¸é–¢</p>
</li>
<li>ç‰©ç†åŒ–å­¦çš„æ€§è³ªï¼ˆæº¶è§£åº¦ã€èç‚¹ãªã©ï¼‰ã®äºˆæ¸¬</li>
<li>ææ–™è¨­è¨ˆã«ãŠã‘ã‚‹ç‰©æ€§æœ€é©åŒ–</li>
</ul>
<div class="mermaid">
flowchart TD
    A[åˆ†å­æ§‹é€ \nSMILES] --> B[è¨˜è¿°å­è¨ˆç®—]
    B --> C[ç‰¹å¾´é‡è¡Œåˆ—\nX]

    D[å®Ÿæ¸¬å€¤\næ´»æ€§ãƒ»ç‰©æ€§] --> E[ç›®çš„å¤‰æ•°\ny]

    C --> F[æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«]
    E --> F

    F --> G[è¨“ç·´]
    G --> H[è©•ä¾¡]
    H --> I{æ€§èƒ½OK?}
    I -->|No| J[ç‰¹å¾´é‡é¸æŠ/\nãƒ¢ãƒ‡ãƒ«å¤‰æ›´]
    J --> F
    I -->|Yes| K[æ–°è¦åˆ†å­ã®äºˆæ¸¬]

    style A fill:#e3f2fd
    style K fill:#4CAF50,color:#fff
</div>

<h3>2.2.1 ç·šå½¢ãƒ¢ãƒ‡ãƒ«</h3>
<h4>ã‚³ãƒ¼ãƒ‰ä¾‹6: Ridgeãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹ç‰©æ€§äºˆæ¸¬</h4>
<pre><code class="language-python">from sklearn.linear_model import Ridge, Lasso
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score, mean_squared_error
from sklearn.preprocessing import StandardScaler
import numpy as np

# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ï¼ˆå®Ÿéš›ã¯mordredãªã©ã§è¨ˆç®—ï¼‰
# X: è¨˜è¿°å­è¡Œåˆ—ã€y: æº¶è§£åº¦
np.random.seed(42)
n_samples = 100
n_features = 50

X = np.random.randn(n_samples, n_features)
y = X[:, 0] * 2 + X[:, 1] * (-1.5) + np.random.randn(n_samples) * 0.5

# ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# æ¨™æº–åŒ–
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Ridgeãƒ¢ãƒ‡ãƒ«
ridge = Ridge(alpha=1.0)
ridge.fit(X_train_scaled, y_train)

# äºˆæ¸¬
y_pred_train = ridge.predict(X_train_scaled)
y_pred_test = ridge.predict(X_test_scaled)

# è©•ä¾¡
print(&quot;Ridgeå›å¸°ã®æ€§èƒ½:&quot;)
print(f&quot;è¨“ç·´ RÂ²: {r2_score(y_train, y_pred_train):.3f}&quot;)
print(f&quot;ãƒ†ã‚¹ãƒˆ RÂ²: {r2_score(y_test, y_pred_test):.3f}&quot;)
print(f&quot;ãƒ†ã‚¹ãƒˆ RMSE: {np.sqrt(mean_squared_error(y_test, y_pred_test)):.3f}&quot;)

# Lassoãƒ¢ãƒ‡ãƒ«ï¼ˆã‚¹ãƒ‘ãƒ¼ã‚¹æ€§ã®å°å…¥ï¼‰
lasso = Lasso(alpha=0.1)
lasso.fit(X_train_scaled, y_train)

# éã‚¼ãƒ­ä¿‚æ•°ã®æ•°ï¼ˆé¸æŠã•ã‚ŒãŸç‰¹å¾´é‡ï¼‰
non_zero = np.sum(lasso.coef_ != 0)
print(f&quot;\nLassoãŒé¸æŠã—ãŸç‰¹å¾´é‡: {non_zero} / {n_features}&quot;)
</code></pre>
<p><strong>å‡ºåŠ›ä¾‹:</strong></p>
<pre><code>Ridgeå›å¸°ã®æ€§èƒ½:
è¨“ç·´ RÂ²: 0.923
ãƒ†ã‚¹ãƒˆ RÂ²: 0.891
ãƒ†ã‚¹ãƒˆ RMSE: 0.542

LassoãŒé¸æŠã—ãŸç‰¹å¾´é‡: 18 / 50
</code></pre>
<h3>2.2.2 éç·šå½¢ãƒ¢ãƒ‡ãƒ«</h3>
<h4>ã‚³ãƒ¼ãƒ‰ä¾‹7: Random Forestã«ã‚ˆã‚‹äºˆæ¸¬</h4>
<pre><code class="language-python">from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import cross_val_score
import matplotlib.pyplot as plt

# Random Forestãƒ¢ãƒ‡ãƒ«
rf = RandomForestRegressor(
    n_estimators=100,
    max_depth=10,
    min_samples_split=5,
    random_state=42
)

# äº¤å·®æ¤œè¨¼
cv_scores = cross_val_score(
    rf, X_train_scaled, y_train,
    cv=5,
    scoring='r2'
)

print(f&quot;Random Forestäº¤å·®æ¤œè¨¼ RÂ²: {cv_scores.mean():.3f} Â± {cv_scores.std():.3f}&quot;)

# è¨“ç·´
rf.fit(X_train_scaled, y_train)
y_pred_rf = rf.predict(X_test_scaled)

print(f&quot;ãƒ†ã‚¹ãƒˆ RÂ²: {r2_score(y_test, y_pred_rf):.3f}&quot;)
print(f&quot;ãƒ†ã‚¹ãƒˆ RMSE: {np.sqrt(mean_squared_error(y_test, y_pred_rf)):.3f}&quot;)

# äºˆæ¸¬vså®Ÿæ¸¬ãƒ—ãƒ­ãƒƒãƒˆ
plt.figure(figsize=(8, 6))
plt.scatter(y_test, y_pred_rf, alpha=0.6, edgecolors='k')
plt.plot([y_test.min(), y_test.max()],
         [y_test.min(), y_test.max()],
         'r--', lw=2, label='Perfect prediction')
plt.xlabel('Actual', fontsize=12)
plt.ylabel('Predicted', fontsize=12)
plt.title('Random Forest: Predicted vs Actual', fontsize=14)
plt.legend()
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.savefig('rf_prediction.png', dpi=300)
plt.close()
</code></pre>
<h4>ã‚³ãƒ¼ãƒ‰ä¾‹8: LightGBMã«ã‚ˆã‚‹é«˜é€Ÿäºˆæ¸¬</h4>
<pre><code class="language-python"># LightGBMã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
# pip install lightgbm

import lightgbm as lgb

# LightGBMãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
train_data = lgb.Dataset(X_train_scaled, label=y_train)
test_data = lgb.Dataset(X_test_scaled, label=y_test, reference=train_data)

# ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
params = {
    'objective': 'regression',
    'metric': 'rmse',
    'boosting_type': 'gbdt',
    'num_leaves': 31,
    'learning_rate': 0.05,
    'feature_fraction': 0.9,
    'bagging_fraction': 0.8,
    'bagging_freq': 5,
    'verbose': -1
}

# è¨“ç·´
gbm = lgb.train(
    params,
    train_data,
    num_boost_round=100,
    valid_sets=[test_data],
    callbacks=[lgb.early_stopping(stopping_rounds=10)]
)

# äºˆæ¸¬
y_pred_lgb = gbm.predict(X_test_scaled, num_iteration=gbm.best_iteration)

print(f&quot;LightGBM ãƒ†ã‚¹ãƒˆ RÂ²: {r2_score(y_test, y_pred_lgb):.3f}&quot;)
print(f&quot;LightGBM ãƒ†ã‚¹ãƒˆ RMSE: {np.sqrt(mean_squared_error(y_test, y_pred_lgb)):.3f}&quot;)
</code></pre>
<p><strong>å‡ºåŠ›ä¾‹:</strong></p>
<pre><code>Random Forestäº¤å·®æ¤œè¨¼ RÂ²: 0.912 Â± 0.034
ãƒ†ã‚¹ãƒˆ RÂ²: 0.924
ãƒ†ã‚¹ãƒˆ RMSE: 0.451

LightGBM ãƒ†ã‚¹ãƒˆ RÂ²: 0.931
LightGBM ãƒ†ã‚¹ãƒˆ RMSE: 0.429
</code></pre>
<hr />
<h2>2.3 ç‰¹å¾´é‡é¸æŠã¨è§£é‡ˆ</h2>
<h3>2.3.1 ç›¸é–¢åˆ†æã«ã‚ˆã‚‹å†—é•·æ€§é™¤å»</h3>
<h4>ã‚³ãƒ¼ãƒ‰ä¾‹9: ç›¸é–¢è¡Œåˆ—ã¨å†—é•·ç‰¹å¾´é‡ã®å‰Šé™¤</h4>
<pre><code class="language-python">import seaborn as sns
import matplotlib.pyplot as plt

# ç›¸é–¢è¡Œåˆ—ã®è¨ˆç®—
corr_matrix = pd.DataFrame(X_train_scaled).corr()

# é«˜ç›¸é–¢ãƒšã‚¢ã®æ¤œå‡ºï¼ˆé–¾å€¤0.95ï¼‰
threshold = 0.95
high_corr_pairs = []

for i in range(len(corr_matrix.columns)):
    for j in range(i+1, len(corr_matrix.columns)):
        if abs(corr_matrix.iloc[i, j]) &gt; threshold:
            high_corr_pairs.append((i, j, corr_matrix.iloc[i, j]))

print(f&quot;é«˜ç›¸é–¢ãƒšã‚¢ï¼ˆ|r| &gt; {threshold}ï¼‰: {len(high_corr_pairs)}çµ„&quot;)

# å†—é•·ç‰¹å¾´é‡ã®å‰Šé™¤
columns_to_drop = set()
for i, j, corr in high_corr_pairs:
    columns_to_drop.add(j)  # jç•ªç›®ã‚’å‰Šé™¤ï¼ˆä»»æ„ã®é¸æŠï¼‰

X_train_reduced = np.delete(X_train_scaled, list(columns_to_drop), axis=1)
X_test_reduced = np.delete(X_test_scaled, list(columns_to_drop), axis=1)

print(f&quot;å‰Šæ¸›å‰ã®ç‰¹å¾´é‡æ•°: {X_train_scaled.shape[1]}&quot;)
print(f&quot;å‰Šæ¸›å¾Œã®ç‰¹å¾´é‡æ•°: {X_train_reduced.shape[1]}&quot;)

# ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã®æç”»ï¼ˆæœ€åˆã®20ç‰¹å¾´é‡ã®ã¿ï¼‰
plt.figure(figsize=(12, 10))
sns.heatmap(
    corr_matrix.iloc[:20, :20],
    annot=True,
    fmt='.2f',
    cmap='coolwarm',
    center=0,
    square=True,
    linewidths=0.5
)
plt.title('ç›¸é–¢è¡Œåˆ—ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ï¼ˆæœ€åˆã®20ç‰¹å¾´é‡ï¼‰', fontsize=14)
plt.tight_layout()
plt.savefig('correlation_heatmap.png', dpi=300)
plt.close()
</code></pre>
<h3>2.3.2 ç‰¹å¾´é‡é‡è¦åº¦ã®åˆ†æ</h3>
<h4>ã‚³ãƒ¼ãƒ‰ä¾‹10: SHAPã«ã‚ˆã‚‹ç‰¹å¾´é‡è§£é‡ˆ</h4>
<pre><code class="language-python"># SHAPã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
# pip install shap

import shap

# Random Forestãƒ¢ãƒ‡ãƒ«ã§å†è¨“ç·´
rf_model = RandomForestRegressor(
    n_estimators=100,
    max_depth=10,
    random_state=42
)
rf_model.fit(X_train_scaled, y_train)

# SHAPå€¤ã®è¨ˆç®—
explainer = shap.TreeExplainer(rf_model)
shap_values = explainer.shap_values(X_test_scaled)

# ç‰¹å¾´é‡é‡è¦åº¦ã®å¯è¦–åŒ–
plt.figure(figsize=(10, 6))
shap.summary_plot(
    shap_values,
    X_test_scaled,
    feature_names=[f'F{i}' for i in range(X_test_scaled.shape[1])],
    show=False,
    max_display=20
)
plt.title('SHAPç‰¹å¾´é‡é‡è¦åº¦', fontsize=14)
plt.tight_layout()
plt.savefig('shap_summary.png', dpi=300)
plt.close()

# å€‹åˆ¥ã‚µãƒ³ãƒ—ãƒ«ã®èª¬æ˜
plt.figure(figsize=(10, 6))
shap.waterfall_plot(
    shap.Explanation(
        values=shap_values[0],
        base_values=explainer.expected_value,
        data=X_test_scaled[0],
        feature_names=[f'F{i}' for i in range(X_test_scaled.shape[1])]
    ),
    max_display=15,
    show=False
)
plt.title('ã‚µãƒ³ãƒ—ãƒ«1ã®äºˆæ¸¬èª¬æ˜', fontsize=14)
plt.tight_layout()
plt.savefig('shap_waterfall.png', dpi=300)
plt.close()

print(&quot;SHAPè§£é‡ˆã®å¯è¦–åŒ–ã‚’ä¿å­˜ã—ã¾ã—ãŸ&quot;)
</code></pre>
<hr />
<h2>2.4 ã‚±ãƒ¼ã‚¹ã‚¹ã‚¿ãƒ‡ã‚£ï¼šæº¶è§£åº¦äºˆæ¸¬</h2>
<h3>ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ: ESOLï¼ˆEstimated Solubilityï¼‰</h3>
<p>ESOLãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯ã€1,128ç¨®é¡ã®åŒ–åˆç‰©ã®æ°´æº¶è§£åº¦ãƒ‡ãƒ¼ã‚¿ã§ã™ã€‚</p>
<h4>ã‚³ãƒ¼ãƒ‰ä¾‹11: ESOLãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®å–å¾—ã¨å‰å‡¦ç†</h4>
<pre><code class="language-python">from rdkit import Chem
from rdkit.Chem import Descriptors
import pandas as pd
import numpy as np

# ESOLãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®èª­ã¿è¾¼ã¿
# ãƒ‡ãƒ¼ã‚¿ã¯ https://raw.githubusercontent.com/deepchem/deepchem/master/datasets/delaney-processed.csv ã‹ã‚‰å–å¾—
url = &quot;https://raw.githubusercontent.com/deepchem/deepchem/master/datasets/delaney-processed.csv&quot;
df_esol = pd.read_csv(url)

print(f&quot;ãƒ‡ãƒ¼ã‚¿æ•°: {len(df_esol)}&quot;)
print(f&quot;\nã‚«ãƒ©ãƒ : {df_esol.columns.tolist()}&quot;)
print(f&quot;\nãƒ‡ãƒ¼ã‚¿ã®å…ˆé ­:&quot;)
print(df_esol.head())

# SMILESã‹ã‚‰åˆ†å­ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆ
df_esol['mol'] = df_esol['smiles'].apply(Chem.MolFromSmiles)

# ç„¡åŠ¹ãªSMILESã‚’é™¤å»
df_esol = df_esol[df_esol['mol'].notna()]
print(f&quot;\næœ‰åŠ¹ãªåˆ†å­æ•°: {len(df_esol)}&quot;)

# RDKitè¨˜è¿°å­ã®è¨ˆç®—
descriptors_list = [
    'MolWt', 'MolLogP', 'NumHAcceptors', 'NumHDonors',
    'TPSA', 'NumRotatableBonds', 'NumAromaticRings',
    'NumHeteroatoms', 'RingCount', 'FractionCsp3'
]

for desc_name in descriptors_list:
    desc_func = getattr(Descriptors, desc_name)
    df_esol[desc_name] = df_esol['mol'].apply(desc_func)

# MorganæŒ‡ç´‹ã®è¿½åŠ 
from rdkit.Chem import AllChem

def get_morgan_fp(mol):
    fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2, nBits=1024)
    return np.array(fp)

fp_array = np.array([get_morgan_fp(mol) for mol in df_esol['mol']])

# ç‰¹å¾´é‡è¡Œåˆ—ã®ä½œæˆ
X_descriptors = df_esol[descriptors_list].values
X_fingerprints = fp_array
X_combined = np.hstack([X_descriptors, X_fingerprints])

# ç›®çš„å¤‰æ•°ï¼ˆæº¶è§£åº¦ logSï¼‰
y = df_esol['measured log solubility in mols per litre'].values

print(f&quot;\nç‰¹å¾´é‡è¡Œåˆ—ã®å½¢çŠ¶:&quot;)
print(f&quot;è¨˜è¿°å­ã®ã¿: {X_descriptors.shape}&quot;)
print(f&quot;æŒ‡ç´‹ã®ã¿: {X_fingerprints.shape}&quot;)
print(f&quot;çµåˆå¾Œ: {X_combined.shape}&quot;)
</code></pre>
<p><strong>å‡ºåŠ›ä¾‹:</strong></p>
<pre><code>ãƒ‡ãƒ¼ã‚¿æ•°: 1128

ã‚«ãƒ©ãƒ : ['Compound ID', 'smiles', 'measured log solubility in mols per litre', ...]

æœ‰åŠ¹ãªåˆ†å­æ•°: 1128

ç‰¹å¾´é‡è¡Œåˆ—ã®å½¢çŠ¶:
è¨˜è¿°å­ã®ã¿: (1128, 10)
æŒ‡ç´‹ã®ã¿: (1128, 1024)
çµåˆå¾Œ: (1128, 1034)
</code></pre>
<h4>ã‚³ãƒ¼ãƒ‰ä¾‹12: è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã®æ¯”è¼ƒã¨æœ€é©åŒ–</h4>
<pre><code class="language-python">from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import Ridge
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
import matplotlib.pyplot as plt

# ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
X_train, X_test, y_train, y_test = train_test_split(
    X_combined, y, test_size=0.2, random_state=42
)

# æ¨™æº–åŒ–
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# ãƒ¢ãƒ‡ãƒ«1: Ridgeå›å¸°
ridge = Ridge(alpha=1.0)
ridge.fit(X_train_scaled, y_train)
y_pred_ridge = ridge.predict(X_test_scaled)

# ãƒ¢ãƒ‡ãƒ«2: Random Forestï¼ˆãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¢ç´¢ï¼‰
param_grid_rf = {
    'n_estimators': [50, 100, 200],
    'max_depth': [5, 10, 15],
    'min_samples_split': [2, 5, 10]
}

rf_grid = GridSearchCV(
    RandomForestRegressor(random_state=42),
    param_grid_rf,
    cv=5,
    scoring='r2',
    n_jobs=-1
)
rf_grid.fit(X_train_scaled, y_train)
y_pred_rf = rf_grid.predict(X_test_scaled)

print(f&quot;Random Forestãƒ™ã‚¹ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: {rf_grid.best_params_}&quot;)

# ãƒ¢ãƒ‡ãƒ«3: LightGBM
import lightgbm as lgb

lgb_train = lgb.Dataset(X_train_scaled, y_train)
lgb_test = lgb.Dataset(X_test_scaled, y_test, reference=lgb_train)

params_lgb = {
    'objective': 'regression',
    'metric': 'rmse',
    'num_leaves': 31,
    'learning_rate': 0.05,
    'feature_fraction': 0.9,
    'verbose': -1
}

gbm = lgb.train(
    params_lgb,
    lgb_train,
    num_boost_round=200,
    valid_sets=[lgb_test],
    callbacks=[lgb.early_stopping(stopping_rounds=20, verbose=False)]
)
y_pred_lgb = gbm.predict(X_test_scaled, num_iteration=gbm.best_iteration)

# æ€§èƒ½æ¯”è¼ƒ
models = {
    'Ridge': y_pred_ridge,
    'Random Forest': y_pred_rf,
    'LightGBM': y_pred_lgb
}

print(&quot;\n=== ãƒ¢ãƒ‡ãƒ«æ€§èƒ½æ¯”è¼ƒ ===&quot;)
for name, y_pred in models.items():
    r2 = r2_score(y_test, y_pred)
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    mae = mean_absolute_error(y_test, y_pred)
    print(f&quot;\n{name}:&quot;)
    print(f&quot;  RÂ²: {r2:.3f}&quot;)
    print(f&quot;  RMSE: {rmse:.3f}&quot;)
    print(f&quot;  MAE: {mae:.3f}&quot;)

# äºˆæ¸¬vså®Ÿæ¸¬ãƒ—ãƒ­ãƒƒãƒˆï¼ˆ3ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒï¼‰
fig, axes = plt.subplots(1, 3, figsize=(18, 5))

for ax, (name, y_pred) in zip(axes, models.items()):
    ax.scatter(y_test, y_pred, alpha=0.6, edgecolors='k')
    ax.plot([y_test.min(), y_test.max()],
            [y_test.min(), y_test.max()],
            'r--', lw=2)
    ax.set_xlabel('Actual log(S)', fontsize=12)
    ax.set_ylabel('Predicted log(S)', fontsize=12)
    ax.set_title(f'{name} (RÂ² = {r2_score(y_test, y_pred):.3f})',
                 fontsize=14)
    ax.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('esol_model_comparison.png', dpi=300)
plt.close()

print(&quot;\nãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒãƒ—ãƒ­ãƒƒãƒˆã‚’ä¿å­˜ã—ã¾ã—ãŸ&quot;)
</code></pre>
<p><strong>å‡ºåŠ›ä¾‹:</strong></p>
<pre><code>Random Forestãƒ™ã‚¹ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: {'max_depth': 15, 'min_samples_split': 2, 'n_estimators': 200}

=== ãƒ¢ãƒ‡ãƒ«æ€§èƒ½æ¯”è¼ƒ ===

Ridge:
  RÂ²: 0.789
  RMSE: 0.712
  MAE: 0.543

Random Forest:
  RÂ²: 0.891
  RMSE: 0.511
  MAE: 0.382

LightGBM:
  RÂ²: 0.912
  RMSE: 0.459
  MAE: 0.341

ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒãƒ—ãƒ­ãƒƒãƒˆã‚’ä¿å­˜ã—ã¾ã—ãŸ
</code></pre>
<p><strong>è§£é‡ˆ</strong>:
- <strong>LightGBM</strong>ãŒæœ€é«˜æ€§èƒ½ï¼ˆRÂ² = 0.912ï¼‰
- <strong>Random Forest</strong>ã‚‚å„ªç§€ï¼ˆRÂ² = 0.891ï¼‰
- <strong>Ridge</strong>ã¯ç·šå½¢ãƒ¢ãƒ‡ãƒ«ã®ãŸã‚æ€§èƒ½ãŒã‚„ã‚„ä½ã„</p>
<hr />
<h2>æ¼”ç¿’å•é¡Œ</h2>
<h3>æ¼”ç¿’1: åˆ†å­è¨˜è¿°å­ã®ç†è§£</h3>
<p>ä»¥ä¸‹ã®è¨˜è¿°å­ã«ã¤ã„ã¦ã€ãã‚Œãã‚Œã®æ„å‘³ã¨å‰µè–¬ã«ãŠã‘ã‚‹é‡è¦æ€§ã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚</p>
<ol>
<li><strong>logPï¼ˆè„‚æº¶æ€§ï¼‰</strong>: é«˜ã„å€¤ã¯ã©ã®ã‚ˆã†ãªæ€§è³ªã‚’ç¤ºã™ã‹ï¼Ÿ</li>
<li><strong>TPSAï¼ˆæ¥µæ€§è¡¨é¢ç©ï¼‰</strong>: è¡€æ¶²è„³é–¢é–€é€éæ€§ã¨ã®é–¢ä¿‚ã¯ï¼Ÿ</li>
<li><strong>åˆ†å­é‡</strong>: Lipinskiã®ãƒ«ãƒ¼ãƒ«ã‚ªãƒ–ãƒ•ã‚¡ã‚¤ãƒ–ã«ãŠã‘ã‚‹é–¾å€¤ã¯ï¼Ÿ</li>
</ol>
<details>
<summary>è§£ç­”ä¾‹</summary>

1. **logPï¼ˆè„‚æº¶æ€§ï¼‰**
   - æ°´-ã‚ªã‚¯ã‚¿ãƒãƒ¼ãƒ«åˆ†é…ä¿‚æ•°ã®å¯¾æ•°å€¤
   - é«˜ã„å€¤ï¼ˆä¾‹: logP > 5ï¼‰: è„‚æº¶æ€§ãŒé«˜ãã€è†œé€éæ€§ã¯è‰¯ã„ãŒæ°´æº¶æ€§ãŒä½ã„
   - ä½ã„å€¤ï¼ˆä¾‹: logP < 0ï¼‰: æ°´æº¶æ€§ãŒé«˜ã„ãŒã€è†œé€éæ€§ãŒä½ã„
   - **å‰µè–¬ã§ã®é‡è¦æ€§**: çµŒå£å¸åæ€§ã‚„è¡€æ¶²è„³é–¢é–€é€éæ€§ã«å½±éŸ¿

2. **TPSAï¼ˆæ¥µæ€§è¡¨é¢ç©ï¼‰**
   - åˆ†å­ä¸­ã®æ¥µæ€§åŸå­ï¼ˆN, Oãªã©ï¼‰ã®è¡¨é¢ç©ã®åˆè¨ˆ
   - TPSA < 140 Ã…Â²: çµŒå£å¸åæ€§ãŒè‰¯å¥½
   - TPSA < 60 Ã…Â²: è¡€æ¶²è„³é–¢é–€ã‚’é€éã—ã‚„ã™ã„
   - **å‰µè–¬ã§ã®é‡è¦æ€§**: CNSè–¬ã®è¨­è¨ˆã«å¿…é ˆ

3. **åˆ†å­é‡**
   - Lipinskiã®ãƒ«ãƒ¼ãƒ«ã‚ªãƒ–ãƒ•ã‚¡ã‚¤ãƒ–: MW < 500 Da
   - é«˜åˆ†å­é‡ï¼ˆ> 500 Daï¼‰: è†œé€éæ€§ãŒä½ä¸‹
   - **å‰µè–¬ã§ã®é‡è¦æ€§**: çµŒå£å¸åæ€§ã®äºˆæ¸¬

</details>

<hr />
<h3>æ¼”ç¿’2: ç‰¹å¾´é‡é¸æŠã®å®Ÿè£…</h3>
<p>ä»¥ä¸‹ã®ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ï¼š</p>
<ol>
<li>ESOLãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®è¨˜è¿°å­ã‚’è¨ˆç®—</li>
<li>ç›¸é–¢ä¿‚æ•° &gt; 0.9 ã®ç‰¹å¾´é‡ãƒšã‚¢ã‚’æ¤œå‡º</li>
<li>å†—é•·ãªç‰¹å¾´é‡ã‚’å‰Šé™¤ã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’å†è¨“ç·´</li>
<li>æ€§èƒ½å¤‰åŒ–ã‚’è©•ä¾¡</li>
</ol>
<details>
<summary>è§£ç­”ä¾‹</summary>


<pre><code class="language-python">from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score
import numpy as np
import pandas as pd

# ç›¸é–¢è¡Œåˆ—ã®è¨ˆç®—
X_df = pd.DataFrame(X_train_scaled)
corr_matrix = X_df.corr()

# é«˜ç›¸é–¢ãƒšã‚¢ã®æ¤œå‡º
threshold = 0.9
high_corr_pairs = []
for i in range(len(corr_matrix.columns)):
    for j in range(i+1, len(corr_matrix.columns)):
        if abs(corr_matrix.iloc[i, j]) &gt; threshold:
            high_corr_pairs.append((i, j, corr_matrix.iloc[i, j]))

print(f&quot;é«˜ç›¸é–¢ãƒšã‚¢æ•°: {len(high_corr_pairs)}&quot;)

# å†—é•·ç‰¹å¾´é‡ã®å‰Šé™¤
columns_to_drop = set([j for i, j, _ in high_corr_pairs])
X_train_reduced = np.delete(X_train_scaled, list(columns_to_drop), axis=1)
X_test_reduced = np.delete(X_test_scaled, list(columns_to_drop), axis=1)

print(f&quot;å‰Šæ¸›å‰: {X_train_scaled.shape[1]} ç‰¹å¾´é‡&quot;)
print(f&quot;å‰Šæ¸›å¾Œ: {X_train_reduced.shape[1]} ç‰¹å¾´é‡&quot;)

# ãƒ¢ãƒ‡ãƒ«è¨“ç·´ï¼ˆå‰Šæ¸›å‰ï¼‰
rf_original = RandomForestRegressor(n_estimators=100, random_state=42)
rf_original.fit(X_train_scaled, y_train)
y_pred_orig = rf_original.predict(X_test_scaled)
r2_orig = r2_score(y_test, y_pred_orig)

# ãƒ¢ãƒ‡ãƒ«è¨“ç·´ï¼ˆå‰Šæ¸›å¾Œï¼‰
rf_reduced = RandomForestRegressor(n_estimators=100, random_state=42)
rf_reduced.fit(X_train_reduced, y_train)
y_pred_red = rf_reduced.predict(X_test_reduced)
r2_red = r2_score(y_test, y_pred_red)

print(f&quot;\nRÂ² (å‰Šæ¸›å‰): {r2_orig:.3f}&quot;)
print(f&quot;RÂ² (å‰Šæ¸›å¾Œ): {r2_red:.3f}&quot;)
print(f&quot;æ€§èƒ½å¤‰åŒ–: {r2_red - r2_orig:+.3f}&quot;)
</code></pre>


**æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›:**

<pre><code>é«˜ç›¸é–¢ãƒšã‚¢æ•°: 145
å‰Šæ¸›å‰: 1034 ç‰¹å¾´é‡
å‰Šæ¸›å¾Œ: 889 ç‰¹å¾´é‡

RÂ² (å‰Šæ¸›å‰): 0.891
RÂ² (å‰Šæ¸›å¾Œ): 0.887
æ€§èƒ½å¤‰åŒ–: -0.004
</code></pre>


**è§£é‡ˆ**: ã‚ãšã‹ãªæ€§èƒ½ä½ä¸‹ï¼ˆ0.004ï¼‰ã§145å€‹ã®å†—é•·ç‰¹å¾´é‡ã‚’å‰Šé™¤ã§ãã€ãƒ¢ãƒ‡ãƒ«ãŒç°¡æ½”ã«ãªã‚Šã¾ã—ãŸã€‚

</details>

<hr />
<h3>æ¼”ç¿’3: ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°</h3>
<p>LightGBMã®ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æœ€é©åŒ–ã—ã€ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã§ã®RÂ²ã‚’0.92ä»¥ä¸Šã«ã—ã¦ãã ã•ã„ã€‚</p>
<p><strong>ãƒ’ãƒ³ãƒˆ</strong>:
- <code>num_leaves</code>ï¼ˆè‘‰ã®æ•°ï¼‰
- <code>learning_rate</code>ï¼ˆå­¦ç¿’ç‡ï¼‰
- <code>feature_fraction</code>ï¼ˆç‰¹å¾´é‡ã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ¯”ç‡ï¼‰</p>
<details>
<summary>è§£ç­”ä¾‹</summary>


<pre><code class="language-python">import lightgbm as lgb
from sklearn.model_selection import RandomizedSearchCV
import numpy as np

# ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç©ºé–“ã®å®šç¾©
param_dist = {
    'num_leaves': [15, 31, 63, 127],
    'learning_rate': [0.01, 0.05, 0.1],
    'n_estimators': [100, 200, 300],
    'feature_fraction': [0.7, 0.8, 0.9, 1.0],
    'bagging_fraction': [0.7, 0.8, 0.9, 1.0],
    'bagging_freq': [0, 5, 10],
    'min_child_samples': [10, 20, 30]
}

# LightGBMãƒ¢ãƒ‡ãƒ«
lgbm = lgb.LGBMRegressor(random_state=42, verbose=-1)

# ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ¼ãƒ
random_search = RandomizedSearchCV(
    lgbm,
    param_distributions=param_dist,
    n_iter=50,
    cv=5,
    scoring='r2',
    random_state=42,
    n_jobs=-1
)

random_search.fit(X_train_scaled, y_train)

print(f&quot;ãƒ™ã‚¹ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: {random_search.best_params_}&quot;)
print(f&quot;ãƒ™ã‚¹ãƒˆCV RÂ²: {random_search.best_score_:.3f}&quot;)

# ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã§ã®è©•ä¾¡
y_pred_optimized = random_search.predict(X_test_scaled)
r2_optimized = r2_score(y_test, y_pred_optimized)
rmse_optimized = np.sqrt(mean_squared_error(y_test, y_pred_optimized))

print(f&quot;\nãƒ†ã‚¹ãƒˆ RÂ²: {r2_optimized:.3f}&quot;)
print(f&quot;ãƒ†ã‚¹ãƒˆ RMSE: {rmse_optimized:.3f}&quot;)

if r2_optimized &gt;= 0.92:
    print(&quot;âœ… ç›®æ¨™é”æˆï¼ RÂ² â‰¥ 0.92&quot;)
else:
    print(f&quot;âŒ ç›®æ¨™æœªé”æˆã€‚ã‚ã¨ {0.92 - r2_optimized:.3f} å¿…è¦&quot;)
</code></pre>


**æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›:**

<pre><code>ãƒ™ã‚¹ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: {'num_leaves': 63, 'n_estimators': 300, 'min_child_samples': 10,
                  'learning_rate': 0.05, 'feature_fraction': 0.9,
                  'bagging_freq': 5, 'bagging_fraction': 0.9}
ãƒ™ã‚¹ãƒˆCV RÂ²: 0.908

ãƒ†ã‚¹ãƒˆ RÂ²: 0.923
ãƒ†ã‚¹ãƒˆ RMSE: 0.429

âœ… ç›®æ¨™é”æˆï¼ RÂ² â‰¥ 0.92
</code></pre>


</details>

<hr />
<h3>æ¼”ç¿’4: ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰</h3>
<p>Ridgeã€Random Forestã€LightGBMã®3ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬ã‚’å¹³å‡åŒ–ï¼ˆã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ï¼‰ã—ã€æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã¦ãã ã•ã„ã€‚</p>
<details>
<summary>è§£ç­”ä¾‹</summary>


<pre><code class="language-python"># å€‹åˆ¥ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´
from sklearn.linear_model import Ridge
from sklearn.ensemble import RandomForestRegressor
import lightgbm as lgb

# Ridge
ridge = Ridge(alpha=1.0)
ridge.fit(X_train_scaled, y_train)
y_pred_ridge = ridge.predict(X_test_scaled)

# Random Forest
rf = RandomForestRegressor(n_estimators=200, max_depth=15, random_state=42)
rf.fit(X_train_scaled, y_train)
y_pred_rf = rf.predict(X_test_scaled)

# LightGBM
lgb_train = lgb.Dataset(X_train_scaled, y_train)
params = {
    'objective': 'regression',
    'metric': 'rmse',
    'num_leaves': 63,
    'learning_rate': 0.05,
    'verbose': -1
}
gbm = lgb.train(params, lgb_train, num_boost_round=200)
y_pred_lgb = gbm.predict(X_test_scaled)

# ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ï¼ˆå˜ç´”å¹³å‡ï¼‰
y_pred_ensemble = (y_pred_ridge + y_pred_rf + y_pred_lgb) / 3

# æ€§èƒ½æ¯”è¼ƒ
print(&quot;=== å€‹åˆ¥ãƒ¢ãƒ‡ãƒ«ã¨ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã®æ€§èƒ½ ===\n&quot;)
models = {
    'Ridge': y_pred_ridge,
    'Random Forest': y_pred_rf,
    'LightGBM': y_pred_lgb,
    'Ensemble (å¹³å‡)': y_pred_ensemble
}

for name, y_pred in models.items():
    r2 = r2_score(y_test, y_pred)
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    print(f&quot;{name:20s} RÂ²: {r2:.3f}  RMSE: {rmse:.3f}&quot;)

# é‡ã¿ä»˜ãã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ï¼ˆæ€§èƒ½ã«å¿œã˜ãŸé‡ã¿ï¼‰
weights = [0.1, 0.4, 0.5]  # Ridge, RF, LightGBM
y_pred_weighted = (
    weights[0] * y_pred_ridge +
    weights[1] * y_pred_rf +
    weights[2] * y_pred_lgb
)

r2_weighted = r2_score(y_test, y_pred_weighted)
rmse_weighted = np.sqrt(mean_squared_error(y_test, y_pred_weighted))

print(f&quot;\né‡ã¿ä»˜ãã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«  RÂ²: {r2_weighted:.3f}  RMSE: {rmse_weighted:.3f}&quot;)
</code></pre>


**æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›:**

<pre><code>=== å€‹åˆ¥ãƒ¢ãƒ‡ãƒ«ã¨ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã®æ€§èƒ½ ===

Ridge                RÂ²: 0.789  RMSE: 0.712
Random Forest        RÂ²: 0.891  RMSE: 0.511
LightGBM             RÂ²: 0.912  RMSE: 0.459
Ensemble (å¹³å‡)       RÂ²: 0.918  RMSE: 0.443

é‡ã¿ä»˜ãã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«  RÂ²: 0.920  RMSE: 0.437
</code></pre>


**è§£é‡ˆ**: ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã«ã‚ˆã‚Šã€æœ€è‰¯ã®å˜ä¸€ãƒ¢ãƒ‡ãƒ«ï¼ˆLightGBMï¼‰ã‚ˆã‚Šã‚‚ã•ã‚‰ã«æ€§èƒ½ãŒå‘ä¸Šã—ã¾ã—ãŸã€‚

</details>

<hr />
<h2>ã¾ã¨ã‚</h2>
<p>ã“ã®ç« ã§ã¯ã€ä»¥ä¸‹ã‚’å­¦ã³ã¾ã—ãŸï¼š</p>
<h3>å­¦ç¿’ã—ãŸå†…å®¹</h3>
<ol>
<li>
<p><strong>åˆ†å­è¨˜è¿°å­</strong>
   - 1Dè¨˜è¿°å­ï¼šåˆ†å­é‡ã€logPã€TPSA
   - 2Dè¨˜è¿°å­ï¼šMorganæŒ‡ç´‹ã€MACCSéµ
   - 3Dè¨˜è¿°å­ï¼šç«‹ä½“é…åº§ä¾å­˜è¨˜è¿°å­
   - mordredã«ã‚ˆã‚‹åŒ…æ‹¬çš„è¨ˆç®—ï¼ˆ1,800ç¨®é¡ä»¥ä¸Šï¼‰</p>
</li>
<li>
<p><strong>QSAR/QSPRãƒ¢ãƒ‡ãƒªãƒ³ã‚°</strong>
   - ç·šå½¢ãƒ¢ãƒ‡ãƒ«ï¼ˆRidgeã€Lassoï¼‰
   - éç·šå½¢ãƒ¢ãƒ‡ãƒ«ï¼ˆRandom Forestã€LightGBMï¼‰
   - ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ï¼ˆRÂ²ã€RMSEã€MAEï¼‰</p>
</li>
<li>
<p><strong>ç‰¹å¾´é‡é¸æŠã¨è§£é‡ˆ</strong>
   - ç›¸é–¢åˆ†æã«ã‚ˆã‚‹å†—é•·æ€§é™¤å»
   - SHAP/LIMEã«ã‚ˆã‚‹ç‰¹å¾´é‡é‡è¦åº¦
   - ã©ã®éƒ¨åˆ†æ§‹é€ ãŒç‰©æ€§ã«å¯„ä¸ã™ã‚‹ã‹</p>
</li>
<li>
<p><strong>å®Ÿè·µï¼šESOLæº¶è§£åº¦äºˆæ¸¬</strong>
   - ãƒ‡ãƒ¼ã‚¿å–å¾—ã¨å‰å‡¦ç†
   - è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã®æ¯”è¼ƒ
   - ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–
   - ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å­¦ç¿’</p>
</li>
</ol>
<h3>æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—</h3>
<p>ç¬¬3ç« ã§ã¯ã€åŒ–å­¦ç©ºé–“æ¢ç´¢ã¨é¡ä¼¼æ€§æ¤œç´¢ã‚’å­¦ã³ã¾ã™ã€‚</p>
<p><strong><a href="./chapter-3.html">ç¬¬3ç« ï¼šåŒ–å­¦ç©ºé–“æ¢ç´¢ã¨é¡ä¼¼æ€§æ¤œç´¢ â†’</a></strong></p>
<hr />
<h2>å‚è€ƒæ–‡çŒ®</h2>
<ol>
<li>Todeschini, R., &amp; Consonni, V. (2009). <em>Molecular Descriptors for Chemoinformatics</em>. Wiley-VCH. ISBN: 978-3527318520</li>
<li>Delaney, J. S. (2004). "ESOL: Estimating aqueous solubility directly from molecular structure." <em>Journal of Chemical Information and Computer Sciences</em>, 44(3), 1000-1005. DOI: 10.1021/ci034243x</li>
<li>Moriwaki, H. et al. (2018). "Mordred: a molecular descriptor calculator." <em>Journal of Cheminformatics</em>, 10, 4. DOI: 10.1186/s13321-018-0258-y</li>
<li>Lundberg, S. M., &amp; Lee, S. I. (2017). "A unified approach to interpreting model predictions." <em>Advances in Neural Information Processing Systems</em>, 30.</li>
</ol>
<hr />
<p><strong><a href="./chapter-1.html">â† ç¬¬1ç« </a></strong> | <strong><a href="./index.html">ã‚·ãƒªãƒ¼ã‚ºãƒˆãƒƒãƒ—ã¸</a></strong> | <strong><a href="./chapter-3.html">ç¬¬3ç« ã¸ â†’</a></strong></p><div class="navigation">
    <a href="chapter-1.html" class="nav-button">â† å‰ã®ç« </a>
    <a href="index.html" class="nav-button">ã‚·ãƒªãƒ¼ã‚ºç›®æ¬¡ã«æˆ»ã‚‹</a>
    <a href="chapter-3.html" class="nav-button">æ¬¡ã®ç«  â†’</a>
</div>
    </main>

    
    <section class="disclaimer">
        <h3>å…è²¬äº‹é …</h3>
        <ul>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯æ•™è‚²ãƒ»ç ”ç©¶ãƒ»æƒ…å ±æä¾›ã®ã¿ã‚’ç›®çš„ã¨ã—ã¦ãŠã‚Šã€å°‚é–€çš„ãªåŠ©è¨€(æ³•å¾‹ãƒ»ä¼šè¨ˆãƒ»æŠ€è¡“çš„ä¿è¨¼ãªã©)ã‚’æä¾›ã™ã‚‹ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŠã‚ˆã³ä»˜éšã™ã‚‹ã‚³ãƒ¼ãƒ‰ä¾‹ã¯ã€Œç¾çŠ¶æœ‰å§¿(AS IS)ã€ã§æä¾›ã•ã‚Œã€æ˜ç¤ºã¾ãŸã¯é»™ç¤ºã‚’å•ã‚ãšã€å•†å“æ€§ã€ç‰¹å®šç›®çš„é©åˆæ€§ã€æ¨©åˆ©éä¾µå®³ã€æ­£ç¢ºæ€§ãƒ»å®Œå…¨æ€§ã€å‹•ä½œãƒ»å®‰å…¨æ€§ç­‰ã„ã‹ãªã‚‹ä¿è¨¼ã‚‚ã—ã¾ã›ã‚“ã€‚</li>
            <li>å¤–éƒ¨ãƒªãƒ³ã‚¯ã€ç¬¬ä¸‰è€…ãŒæä¾›ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ»ãƒ„ãƒ¼ãƒ«ãƒ»ãƒ©ã‚¤ãƒ–ãƒ©ãƒªç­‰ã®å†…å®¹ãƒ»å¯ç”¨æ€§ãƒ»å®‰å…¨æ€§ã«ã¤ã„ã¦ã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯ä¸€åˆ‡ã®è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®åˆ©ç”¨ãƒ»å®Ÿè¡Œãƒ»è§£é‡ˆã«ã‚ˆã‚Šç›´æ¥çš„ãƒ»é–“æ¥çš„ãƒ»ä»˜éšçš„ãƒ»ç‰¹åˆ¥ãƒ»çµæœçš„ãƒ»æ‡²ç½°çš„æå®³ãŒç”Ÿã˜ãŸå ´åˆã§ã‚‚ã€é©ç”¨æ³•ã§è¨±å®¹ã•ã‚Œã‚‹æœ€å¤§é™ã®ç¯„å›²ã§ã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å†…å®¹ã¯ã€äºˆå‘Šãªãå¤‰æ›´ãƒ»æ›´æ–°ãƒ»æä¾›åœæ­¢ã•ã‚Œã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®è‘—ä½œæ¨©ãƒ»ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯æ˜è¨˜ã•ã‚ŒãŸæ¡ä»¶(ä¾‹: CC BY 4.0)ã«å¾“ã„ã¾ã™ã€‚å½“è©²ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯é€šå¸¸ã€ç„¡ä¿è¨¼æ¡é …ã‚’å«ã¿ã¾ã™ã€‚</li>
        </ul>
    </section>

<footer>
        <p><strong>ä½œæˆè€…</strong>: AI Terakoya Content Team</p>
        <p><strong>ãƒãƒ¼ã‚¸ãƒ§ãƒ³</strong>: 1.0 | <strong>ä½œæˆæ—¥</strong>: 2025-10-18</p>
        <p><strong>ãƒ©ã‚¤ã‚»ãƒ³ã‚¹</strong>: Creative Commons BY 4.0</p>
        <p>Â© 2025 AI Terakoya. All rights reserved.</p>
    </footer>
</body>
</html>
