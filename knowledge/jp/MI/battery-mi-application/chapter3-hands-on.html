<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Pythonã§å®Ÿè£…ã™ã‚‹é›»æ± MIå®Ÿè·µãƒãƒ³ã‚ºã‚ªãƒ³ - AI Terakoya</title>

    <style>
        :root {
            --color-primary: #2c3e50;
            --color-primary-dark: #1a252f;
            --color-accent: #7b2cbf;
            --color-accent-light: #9d4edd;
            --color-text: #2d3748;
            --color-text-light: #4a5568;
            --color-bg: #ffffff;
            --color-bg-alt: #f7fafc;
            --color-border: #e2e8f0;
            --color-code-bg: #f8f9fa;
            --color-link: #3182ce;
            --color-link-hover: #2c5aa0;

            --spacing-xs: 0.5rem;
            --spacing-sm: 1rem;
            --spacing-md: 1.5rem;
            --spacing-lg: 2rem;
            --spacing-xl: 3rem;

            --font-body: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            --font-mono: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;

            --border-radius: 8px;
            --box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: var(--font-body);
            line-height: 1.7;
            color: var(--color-text);
            background-color: var(--color-bg);
            font-size: 16px;
        }

        header {
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            padding: var(--spacing-xl) var(--spacing-md);
            margin-bottom: var(--spacing-xl);
            box-shadow: var(--box-shadow);
        }

        .header-content {
            max-width: 900px;
            margin: 0 auto;
        }

        h1 {
            font-size: 2rem;
            font-weight: 700;
            margin-bottom: var(--spacing-sm);
            line-height: 1.2;
        }

        .subtitle {
            font-size: 1.1rem;
            opacity: 0.95;
            font-weight: 400;
            margin-bottom: var(--spacing-md);
        }

        .meta {
            display: flex;
            flex-wrap: wrap;
            gap: var(--spacing-md);
            font-size: 0.9rem;
            opacity: 0.9;
        }

        .meta-item {
            display: flex;
            align-items: center;
            gap: 0.3rem;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 0 var(--spacing-md) var(--spacing-xl);
        }

        h2 {
            font-size: 1.75rem;
            color: var(--color-primary);
            margin-top: var(--spacing-xl);
            margin-bottom: var(--spacing-md);
            padding-bottom: var(--spacing-xs);
            border-bottom: 3px solid var(--color-accent);
        }

        h3 {
            font-size: 1.4rem;
            color: var(--color-primary);
            margin-top: var(--spacing-lg);
            margin-bottom: var(--spacing-sm);
        }

        h4 {
            font-size: 1.1rem;
            color: var(--color-primary-dark);
            margin-top: var(--spacing-md);
            margin-bottom: var(--spacing-sm);
        }

        p {
            margin-bottom: var(--spacing-md);
            color: var(--color-text);
        }

        a {
            color: var(--color-link);
            text-decoration: none;
            transition: color 0.2s;
        }

        a:hover {
            color: var(--color-link-hover);
            text-decoration: underline;
        }

        ul, ol {
            margin-left: var(--spacing-lg);
            margin-bottom: var(--spacing-md);
        }

        li {
            margin-bottom: var(--spacing-xs);
            color: var(--color-text);
        }

        pre {
            background-color: var(--color-code-bg);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            overflow-x: auto;
            margin-bottom: var(--spacing-md);
            font-family: var(--font-mono);
            font-size: 0.9rem;
            line-height: 1.5;
        }

        code {
            font-family: var(--font-mono);
            font-size: 0.9em;
            background-color: var(--color-code-bg);
            padding: 0.2em 0.4em;
            border-radius: 3px;
        }

        pre code {
            background-color: transparent;
            padding: 0;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: var(--spacing-md);
            font-size: 0.95rem;
        }

        th, td {
            border: 1px solid var(--color-border);
            padding: var(--spacing-sm);
            text-align: left;
        }

        th {
            background-color: var(--color-bg-alt);
            font-weight: 600;
            color: var(--color-primary);
        }

        blockquote {
            border-left: 4px solid var(--color-accent);
            padding-left: var(--spacing-md);
            margin: var(--spacing-md) 0;
            color: var(--color-text-light);
            font-style: italic;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        .mermaid {
            text-align: center;
            margin: var(--spacing-lg) 0;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        details {
            background-color: var(--color-bg-alt);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            margin-bottom: var(--spacing-md);
        }

        summary {
            cursor: pointer;
            font-weight: 600;
            color: var(--color-primary);
            user-select: none;
            padding: var(--spacing-xs);
            margin: calc(-1 * var(--spacing-md));
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        summary:hover {
            background-color: rgba(123, 44, 191, 0.1);
        }

        details[open] summary {
            margin-bottom: var(--spacing-md);
            border-bottom: 1px solid var(--color-border);
        }

        .navigation {
            display: flex;
            justify-content: space-between;
            gap: var(--spacing-md);
            margin: var(--spacing-xl) 0;
            padding-top: var(--spacing-lg);
            border-top: 2px solid var(--color-border);
        }

        .nav-button {
            flex: 1;
            padding: var(--spacing-md);
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            border-radius: var(--border-radius);
            text-align: center;
            font-weight: 600;
            transition: transform 0.2s, box-shadow 0.2s;
            box-shadow: var(--box-shadow);
        }

        .nav-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
            text-decoration: none;
        }

        footer {
            margin-top: var(--spacing-xl);
            padding: var(--spacing-lg) var(--spacing-md);
            background-color: var(--color-bg-alt);
            border-top: 1px solid var(--color-border);
            text-align: center;
            font-size: 0.9rem;
            color: var(--color-text-light);
        }

        @media (max-width: 768px) {
            h1 { font-size: 1.5rem; }
            h2 { font-size: 1.4rem; }
            h3 { font-size: 1.2rem; }
            .meta { font-size: 0.85rem; }
            .navigation { flex-direction: column; }
            table { font-size: 0.85rem; }
            th, td { padding: var(--spacing-xs); }
        }
    </style>

    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
        mermaid.initialize({ startOnLoad: true, theme: 'default' });
    </script>

    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\(', '\)']],
                displayMath: [['$$', '$$'], ['\[', '\]']],
                processEscapes: true
            }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" async></script>
</head>
<body>
    <header>
        <div class="header-content">
            <h1>Pythonã§å®Ÿè£…ã™ã‚‹é›»æ± MIå®Ÿè·µãƒãƒ³ã‚ºã‚ªãƒ³</h1>
            <p class="subtitle">å®Ÿè£…ã‚³ãƒ¼ãƒ‰ã§å­¦ã¶é›»æ± ææ–™è¨­è¨ˆ</p>
            <div class="meta">
                <span class="meta-item">ğŸ“– 60-70åˆ†</span>
                <span class="meta-item">ğŸ“Š ä¸­ç´š</span>
                <span class="meta-item">ğŸ’» 30å€‹</span>
                <span class="meta-item">ğŸ“ 5å•</span>
            </div>
        </div>
    </header>

    <main class="container">
<h1>ç¬¬3ç« ï¼šPythonã§å®Ÿè£…ã™ã‚‹é›»æ± MIå®Ÿè·µãƒãƒ³ã‚ºã‚ªãƒ³</h1>
<p><strong>å­¦ç¿’ç›®æ¨™:</strong>
- PyBaMMã§é›»æ± ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ãƒ»ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§ãã‚‹
- å®¹é‡ãƒ»é›»åœ§äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã‚’å®Ÿè£…ã—è©•ä¾¡ã§ãã‚‹
- LSTMã§ã‚µã‚¤ã‚¯ãƒ«åŠ£åŒ–ã‚’äºˆæ¸¬ã§ãã‚‹
- ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã§æœ€é©ææ–™ã‚’æ¢ç´¢ã§ãã‚‹</p>
<p><strong>å‰æçŸ¥è­˜:</strong>
- PythonåŸºç¤ï¼ˆNumPy, Pandas, Matplotlibï¼‰
- æ©Ÿæ¢°å­¦ç¿’åŸºç¤ï¼ˆscikit-learnï¼‰
- ç¬¬1ç« ãƒ»ç¬¬2ç« ã®å†…å®¹ç†è§£</p>
<p><strong>å®Ÿè¡Œç’°å¢ƒ:</strong></p>
<pre><code class="language-bash">pip install pybamm numpy pandas scikit-learn tensorflow scikit-optimize matplotlib seaborn
</code></pre>
<hr />
<h2>3.1 é›»æ± ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ã¨å‰å‡¦ç†</h2>
<h3>ä¾‹1: Materials Projectã‹ã‚‰æ­£æ¥µææ–™ãƒ‡ãƒ¼ã‚¿å–å¾—</h3>
<pre><code class="language-python">from pymatgen.ext.matproj import MPRester
import pandas as pd

# Materials Project API
API_KEY = &quot;YOUR_API_KEY&quot;  # https://materialsproject.org/open ã‹ã‚‰å–å¾—

with MPRester(API_KEY) as mpr:
    # Liå«æœ‰é…¸åŒ–ç‰©ã®æ¤œç´¢
    data = mpr.query(
        criteria={
            &quot;elements&quot;: {&quot;$all&quot;: [&quot;Li&quot;], &quot;$in&quot;: [&quot;Co&quot;, &quot;Ni&quot;, &quot;Mn&quot;]},
            &quot;nelements&quot;: {&quot;$lte&quot;: 4}
        },
        properties=[&quot;material_id&quot;, &quot;pretty_formula&quot;, &quot;energy_per_atom&quot;,
                   &quot;band_gap&quot;, &quot;formation_energy_per_atom&quot;]
    )

df = pd.DataFrame(data)
print(f&quot;å–å¾—ææ–™æ•°: {len(df)}&quot;)
print(df.head())
</code></pre>
<h3>ä¾‹2: å……æ”¾é›»æ›²ç·šã®èª­ã¿è¾¼ã¿ã¨å¯è¦–åŒ–</h3>
<pre><code class="language-python">import numpy as np
import matplotlib.pyplot as plt

# ã‚µãƒ³ãƒ—ãƒ«å……æ”¾é›»ãƒ‡ãƒ¼ã‚¿
def load_charge_discharge_data():
    &quot;&quot;&quot;å……æ”¾é›»æ›²ç·šãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆï¼ˆå®Ÿéš›ã¯ãƒ•ã‚¡ã‚¤ãƒ«èª­è¾¼ï¼‰&quot;&quot;&quot;
    capacity = np.linspace(0, 200, 100)  # mAh/g
    voltage_charge = 3.0 + 0.7 * (capacity / 200) + 0.3 * np.sin(capacity / 20)
    voltage_discharge = 3.0 + 0.6 * (capacity / 200) + 0.2 * np.sin(capacity / 20)
    return capacity, voltage_charge, voltage_discharge

cap, V_ch, V_dch = load_charge_discharge_data()

fig, ax = plt.subplots(figsize=(10, 6))
ax.plot(cap, V_ch, 'r-', label='Charge', linewidth=2)
ax.plot(cap, V_dch, 'b-', label='Discharge', linewidth=2)
ax.set_xlabel('Capacity (mAh/g)', fontsize=12)
ax.set_ylabel('Voltage (V)', fontsize=12)
ax.set_title('Charge-Discharge Curve', fontsize=14)
ax.legend()
ax.grid(alpha=0.3)

print(f&quot;å¹³å‡å……é›»é›»åœ§: {V_ch.mean():.2f} V&quot;)
print(f&quot;å¹³å‡æ”¾é›»é›»åœ§: {V_dch.mean():.2f} V&quot;)
</code></pre>
<h3>ä¾‹3: é›»ä½ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«è¨ˆç®—</h3>
<pre><code class="language-python">from scipy.integrate import cumtrapz

def calculate_average_voltage(capacity, voltage):
    &quot;&quot;&quot;å¹³å‡é›»åœ§ã®è¨ˆç®—&quot;&quot;&quot;
    energy = cumtrapz(voltage, capacity, initial=0)
    avg_voltage = energy[-1] / capacity[-1] if capacity[-1] &gt; 0 else 0
    return avg_voltage

# å……æ”¾é›»ã®å¹³å‡é›»åœ§
V_avg_ch = calculate_average_voltage(cap, V_ch)
V_avg_dch = calculate_average_voltage(cap, V_dch)

# ã‚¨ãƒãƒ«ã‚®ãƒ¼å¯†åº¦
capacity_max = cap[-1]  # mAh/g
energy_density = capacity_max * V_avg_dch * 0.001  # Wh/g

print(f&quot;å¹³å‡å……é›»é›»åœ§: {V_avg_ch:.3f} V&quot;)
print(f&quot;å¹³å‡æ”¾é›»é›»åœ§: {V_avg_dch:.3f} V&quot;)
print(f&quot;ã‚¨ãƒãƒ«ã‚®ãƒ¼å¯†åº¦: {energy_density:.1f} Wh/g&quot;)
</code></pre>
<h3>ä¾‹4: å®¹é‡è¨ˆç®—ã¨ã‚¯ãƒ¼ãƒ­ãƒ³åŠ¹ç‡</h3>
<pre><code class="language-python">def calculate_coulombic_efficiency(Q_charge, Q_discharge):
    &quot;&quot;&quot;ã‚¯ãƒ¼ãƒ­ãƒ³åŠ¹ç‡ã®è¨ˆç®—&quot;&quot;&quot;
    CE = (Q_discharge / Q_charge) * 100
    return CE

# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿
Q_charge = 195.0  # mAh/g
Q_discharge = 190.0  # mAh/g

CE = calculate_coulombic_efficiency(Q_charge, Q_discharge)
print(f&quot;å……é›»å®¹é‡: {Q_charge:.1f} mAh/g&quot;)
print(f&quot;æ”¾é›»å®¹é‡: {Q_discharge:.1f} mAh/g&quot;)
print(f&quot;ã‚¯ãƒ¼ãƒ­ãƒ³åŠ¹ç‡: {CE:.2f}%&quot;)

if CE &lt; 98:
    print(&quot;âš ï¸ è­¦å‘Š: ã‚¯ãƒ¼ãƒ­ãƒ³åŠ¹ç‡ãŒä½ã„ï¼ˆå‰¯åå¿œã®å¯èƒ½æ€§ï¼‰&quot;)
elif CE &gt; 99.5:
    print(&quot;âœ… å„ªç§€: é«˜ã„ã‚¯ãƒ¼ãƒ­ãƒ³åŠ¹ç‡&quot;)
</code></pre>
<h3>ä¾‹5: è¨˜è¿°å­ã®è‡ªå‹•è¨ˆç®—ï¼ˆmatminerï¼‰</h3>
<pre><code class="language-python">from matminer.featurizers.composition import ElementProperty
from pymatgen.core import Composition

# æ­£æ¥µææ–™ã®çµ„æˆ
compositions = [&quot;LiCoO2&quot;, &quot;LiNi0.8Co0.15Al0.05O2&quot;, &quot;LiFePO4&quot;]

# è¨˜è¿°å­è¨ˆç®—
ep_feat = ElementProperty.from_preset(&quot;magpie&quot;)
descriptors = []

for comp_str in compositions:
    comp = Composition(comp_str)
    desc = ep_feat.featurize(comp)
    descriptors.append(desc)

# DataFrameåŒ–
feature_labels = ep_feat.feature_labels()
df_desc = pd.DataFrame(descriptors, columns=feature_labels, index=compositions)

print(&quot;è¨˜è¿°å­ã®ä¾‹ï¼ˆæœ€åˆã®5åˆ—ï¼‰:&quot;)
print(df_desc.iloc[:, :5])
print(f&quot;\nç·è¨˜è¿°å­æ•°: {len(feature_labels)}&quot;)
</code></pre>
<h3>ä¾‹6: ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã¨å¤–ã‚Œå€¤é™¤å»</h3>
<pre><code class="language-python">from sklearn.preprocessing import StandardScaler
from scipy import stats

# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿
np.random.seed(42)
capacity_data = np.concatenate([
    np.random.normal(180, 10, 95),  # æ­£å¸¸ãƒ‡ãƒ¼ã‚¿
    np.array([250, 280, 300, 310, 50])  # å¤–ã‚Œå€¤
])

# Z-scoreã«ã‚ˆã‚‹å¤–ã‚Œå€¤æ¤œå‡º
z_scores = np.abs(stats.zscore(capacity_data))
threshold = 3
outliers = z_scores &gt; threshold

print(f&quot;ãƒ‡ãƒ¼ã‚¿æ•°: {len(capacity_data)}&quot;)
print(f&quot;å¤–ã‚Œå€¤æ•°: {outliers.sum()} ({outliers.sum()/len(capacity_data)*100:.1f}%)&quot;)
print(f&quot;å¤–ã‚Œå€¤: {capacity_data[outliers]}&quot;)

# ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°å¾Œ
capacity_clean = capacity_data[~outliers]
print(f&quot;ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°å¾Œãƒ‡ãƒ¼ã‚¿æ•°: {len(capacity_clean)}&quot;)
print(f&quot;å¹³å‡å®¹é‡: {capacity_clean.mean():.1f} Â± {capacity_clean.std():.1f} mAh/g&quot;)
</code></pre>
<h3>ä¾‹7: Train/Testãƒ‡ãƒ¼ã‚¿åˆ†å‰²</h3>
<pre><code class="language-python">from sklearn.model_selection import train_test_split

# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
np.random.seed(42)
n_samples = 200
X = np.random.randn(n_samples, 10)  # 10å€‹ã®è¨˜è¿°å­
y = 150 + 30 * X[:, 0] - 20 * X[:, 1] + np.random.randn(n_samples) * 5  # å®¹é‡

# Train/Teståˆ†å‰²
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

print(f&quot;è¨“ç·´ãƒ‡ãƒ¼ã‚¿: {X_train.shape}&quot;)
print(f&quot;ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {X_test.shape}&quot;)
print(f&quot;å®¹é‡ç¯„å›²: {y.min():.1f} - {y.max():.1f} mAh/g&quot;)

# æ¨™æº–åŒ–
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)
print(&quot;\næ¨™æº–åŒ–å®Œäº†&quot;)
</code></pre>
<hr />
<h2>3.2 å®¹é‡ãƒ»é›»åœ§äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«</h2>
<h3>ä¾‹8: Random Forestå›å¸°ï¼ˆå®¹é‡äºˆæ¸¬ï¼‰</h3>
<pre><code class="language-python">from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, r2_score

# ãƒ¢ãƒ‡ãƒ«è¨“ç·´
model_rf = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42)
model_rf.fit(X_train_scaled, y_train)

# äºˆæ¸¬
y_pred_train = model_rf.predict(X_train_scaled)
y_pred_test = model_rf.predict(X_test_scaled)

# è©•ä¾¡
mae_train = mean_absolute_error(y_train, y_pred_train)
mae_test = mean_absolute_error(y_test, y_pred_test)
r2_train = r2_score(y_train, y_pred_train)
r2_test = r2_score(y_test, y_pred_test)

print(f&quot;Random Forest å®¹é‡äºˆæ¸¬:&quot;)
print(f&quot;  è¨“ç·´: MAE={mae_train:.2f} mAh/g, RÂ²={r2_train:.3f}&quot;)
print(f&quot;  ãƒ†ã‚¹ãƒˆ: MAE={mae_test:.2f} mAh/g, RÂ²={r2_test:.3f}&quot;)
</code></pre>
<h3>ä¾‹9: XGBoostï¼ˆé›»åœ§äºˆæ¸¬ï¼‰</h3>
<pre><code class="language-python">from xgboost import XGBRegressor

# é›»åœ§ãƒ‡ãƒ¼ã‚¿ï¼ˆã‚µãƒ³ãƒ—ãƒ«ï¼‰
y_voltage = 3.7 + 0.3 * X[:, 0] - 0.2 * X[:, 2] + np.random.randn(n_samples) * 0.1

y_v_train, y_v_test = y_voltage[:len(X_train)], y_voltage[len(X_train):]

# XGBoostãƒ¢ãƒ‡ãƒ«
model_xgb = XGBRegressor(n_estimators=200, learning_rate=0.05, max_depth=6, random_state=42)
model_xgb.fit(X_train_scaled, y_v_train)

# äºˆæ¸¬ã¨è©•ä¾¡
y_v_pred = model_xgb.predict(X_test_scaled)
mae_voltage = mean_absolute_error(y_v_test, y_v_pred)
r2_voltage = r2_score(y_v_test, y_v_pred)

print(f&quot;XGBoost é›»åœ§äºˆæ¸¬:&quot;)
print(f&quot;  MAE: {mae_voltage:.3f} V&quot;)
print(f&quot;  RÂ²: {r2_voltage:.3f}&quot;)
</code></pre>
<h3>ä¾‹10: Neural Networkï¼ˆKerasï¼‰</h3>
<pre><code class="language-python">from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.optimizers import Adam

# ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰
model_nn = Sequential([
    Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),
    Dropout(0.2),
    Dense(32, activation='relu'),
    Dropout(0.2),
    Dense(16, activation='relu'),
    Dense(1)
])

model_nn.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])

# è¨“ç·´
history = model_nn.fit(
    X_train_scaled, y_train,
    validation_split=0.2,
    epochs=100,
    batch_size=32,
    verbose=0
)

# è©•ä¾¡
y_nn_pred = model_nn.predict(X_test_scaled).flatten()
mae_nn = mean_absolute_error(y_test, y_nn_pred)
r2_nn = r2_score(y_test, y_nn_pred)

print(f&quot;Neural Network å®¹é‡äºˆæ¸¬:&quot;)
print(f&quot;  MAE: {mae_nn:.2f} mAh/g&quot;)
print(f&quot;  RÂ²: {r2_nn:.3f}&quot;)
</code></pre>
<h3>ä¾‹11: Graph Neural Networkï¼ˆæ¦‚å¿µå®Ÿè£…ï¼‰</h3>
<pre><code class="language-python"># PyTorch Geometricã‚’ä½¿ç”¨ï¼ˆå®Ÿè£…ã®æ¦‚è¦ï¼‰
&quot;&quot;&quot;
from torch_geometric.nn import CGConv, global_mean_pool

class CrystalGNN(torch.nn.Module):
    def __init__(self, node_features, edge_features, hidden_dim):
        super().__init__()
        self.conv1 = CGConv(node_features, edge_features, hidden_dim)
        self.conv2 = CGConv(hidden_dim, edge_features, hidden_dim)
        self.fc = torch.nn.Linear(hidden_dim, 1)

    def forward(self, data):
        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr
        x = F.relu(self.conv1(x, edge_index, edge_attr))
        x = F.relu(self.conv2(x, edge_index, edge_attr))
        x = global_mean_pool(x, data.batch)
        return self.fc(x)

# è¨“ç·´ãƒ»äºˆæ¸¬ï¼ˆè©³ç´°ã¯ç¬¬4ç« ï¼‰
&quot;&quot;&quot;

print(&quot;Graph Neural Networkã®æ¦‚å¿µ:&quot;)
print(&quot;  å…¥åŠ›: çµæ™¶æ§‹é€ ï¼ˆåŸå­åº§æ¨™ã€çµåˆæƒ…å ±ï¼‰&quot;)
print(&quot;  å‡¦ç†: Graph Convolution Layers&quot;)
print(&quot;  å‡ºåŠ›: å®¹é‡ã€é›»åœ§äºˆæ¸¬&quot;)
print(&quot;  åˆ©ç‚¹: è¨˜è¿°å­è¨­è¨ˆä¸è¦ã€é«˜ç²¾åº¦&quot;)
</code></pre>
<h3>ä¾‹12: Transfer Learning</h3>
<pre><code class="language-python">from tensorflow.keras.models import load_model

# äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ï¼ˆä»®æƒ³ï¼‰
def create_pretrained_model():
    &quot;&quot;&quot;LIBæ­£æ¥µææ–™ã§è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«&quot;&quot;&quot;
    model = Sequential([
        Dense(64, activation='relu', input_shape=(10,)),
        Dense(32, activation='relu'),
        Dense(1)
    ])
    return model

pretrained = create_pretrained_model()
pretrained.compile(optimizer=Adam(lr=0.001), loss='mse')
# ä»®æƒ³è¨“ç·´
pretrained.fit(X_train_scaled[:100], y_train[:100], epochs=50, verbose=0)

# ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆå…¨å›ºä½“é›»æ± ãƒ‡ãƒ¼ã‚¿ï¼‰
X_target = X_train_scaled[100:120]
y_target = y_train[100:120]

# æœ€çµ‚å±¤ã‚’å†è¨“ç·´
for layer in pretrained.layers[:-1]:
    layer.trainable = False

pretrained.compile(optimizer=Adam(lr=1e-4), loss='mse')
pretrained.fit(X_target, y_target, epochs=30, verbose=0)

# è©•ä¾¡
y_tl_pred = pretrained.predict(X_test_scaled).flatten()
mae_tl = mean_absolute_error(y_test, y_tl_pred)

print(f&quot;Transfer Learning:&quot;)
print(f&quot;  ã‚½ãƒ¼ã‚¹: LIBæ­£æ¥µï¼ˆ100ã‚µãƒ³ãƒ—ãƒ«ï¼‰&quot;)
print(f&quot;  ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ: å…¨å›ºä½“é›»æ± ï¼ˆ20ã‚µãƒ³ãƒ—ãƒ«ï¼‰&quot;)
print(f&quot;  MAE: {mae_tl:.2f} mAh/g&quot;)
</code></pre>
<h3>ä¾‹13: ç‰¹å¾´é‡é‡è¦åº¦åˆ†æï¼ˆSHAPï¼‰</h3>
<pre><code class="language-python">import shap

# SHAP Explainer
explainer = shap.TreeExplainer(model_rf)
shap_values = explainer.shap_values(X_test_scaled[:100])

# ç‰¹å¾´é‡é‡è¦åº¦
feature_names = [f&quot;Feature_{i}&quot; for i in range(X.shape[1])]
shap.summary_plot(shap_values, X_test_scaled[:100], feature_names=feature_names, show=False)

print(&quot;SHAPåˆ†æ:&quot;)
print(&quot;  å„ç‰¹å¾´é‡ã®å®¹é‡ã¸ã®å¯„ä¸ã‚’å®šé‡åŒ–&quot;)
print(&quot;  æ­£ã®å¯„ä¸: å®¹é‡å¢—åŠ &quot;)
print(&quot;  è² ã®å¯„ä¸: å®¹é‡æ¸›å°‘&quot;)
</code></pre>
<h3>ä¾‹14: äº¤å·®æ¤œè¨¼</h3>
<pre><code class="language-python">from sklearn.model_selection import cross_val_score

# 5-foldäº¤å·®æ¤œè¨¼
cv_scores = cross_val_score(
    model_rf, X_train_scaled, y_train,
    cv=5, scoring='neg_mean_absolute_error'
)

print(f&quot;5-foldäº¤å·®æ¤œè¨¼:&quot;)
print(f&quot;  MAE: {-cv_scores.mean():.2f} Â± {cv_scores.std():.2f} mAh/g&quot;)
print(f&quot;  å„fold: {-cv_scores}&quot;)
</code></pre>
<h3>ä¾‹15: Parity Plot</h3>
<pre><code class="language-python">fig, ax = plt.subplots(figsize=(8, 8))

ax.scatter(y_test, y_pred_test, alpha=0.6, s=50)
ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()],
       'r--', linewidth=2, label='Ideal')

ax.set_xlabel('Actual Capacity (mAh/g)', fontsize=12)
ax.set_ylabel('Predicted Capacity (mAh/g)', fontsize=12)
ax.set_title(f'Parity Plot (MAE={mae_test:.2f} mAh/g)', fontsize=14)
ax.legend()
ax.grid(alpha=0.3)

print(&quot;Parity Plot: äºˆæ¸¬å€¤ vs å®Ÿæ¸¬å€¤ã®æ¯”è¼ƒ&quot;)
</code></pre>
<hr />
<h2>3.3 ã‚µã‚¤ã‚¯ãƒ«åŠ£åŒ–äºˆæ¸¬</h2>
<h3>ä¾‹16: å……æ”¾é›»æ›²ç·šã®æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿æº–å‚™</h3>
<pre><code class="language-python">def generate_cycle_data(n_cycles=500):
    &quot;&quot;&quot;ã‚µã‚¤ã‚¯ãƒ«ãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆ&quot;&quot;&quot;
    cycles = np.arange(1, n_cycles + 1)

    # å®¹é‡æ¸›è¡°ï¼ˆæŒ‡æ•°é–¢æ•°çš„ï¼‰
    Q_initial = 200  # mAh/g
    decay_rate = 0.0005
    capacity = Q_initial * np.exp(-decay_rate * cycles) + np.random.randn(n_cycles) * 2

    # SOH (State of Health)
    SOH = (capacity / Q_initial) * 100

    return cycles, capacity, SOH

cycles, capacity, SOH = generate_cycle_data()

plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
plt.plot(cycles, capacity)
plt.xlabel('Cycle Number')
plt.ylabel('Capacity (mAh/g)')
plt.title('Capacity Fade')
plt.grid(alpha=0.3)

plt.subplot(1, 2, 2)
plt.plot(cycles, SOH)
plt.xlabel('Cycle Number')
plt.ylabel('SOH (%)')
plt.axhline(80, color='r', linestyle='--', label='80% threshold')
plt.title('State of Health')
plt.legend()
plt.grid(alpha=0.3)
plt.tight_layout()

print(f&quot;åˆæœŸå®¹é‡: {capacity[0]:.1f} mAh/g&quot;)
print(f&quot;æœ€çµ‚å®¹é‡: {capacity[-1]:.1f} mAh/g&quot;)
print(f&quot;å®¹é‡ä¿æŒç‡: {SOH[-1]:.1f}%&quot;)
</code></pre>
<h3>ä¾‹17: LSTMï¼ˆLong Short-Term Memoryï¼‰ãƒ¢ãƒ‡ãƒ«</h3>
<pre><code class="language-python">from tensorflow.keras.layers import LSTM

# ãƒ‡ãƒ¼ã‚¿æº–å‚™ï¼ˆæ™‚ç³»åˆ—ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ï¼‰
def create_sequences(data, seq_length=50):
    X, y = [], []
    for i in range(len(data) - seq_length):
        X.append(data[i:i+seq_length])
        y.append(data[i+seq_length])
    return np.array(X), np.array(y)

seq_length = 50
X_lstm, y_lstm = create_sequences(capacity, seq_length)
X_lstm = X_lstm.reshape(-1, seq_length, 1)

# Train/Teståˆ†å‰²
split = int(0.8 * len(X_lstm))
X_train_lstm, X_test_lstm = X_lstm[:split], X_lstm[split:]
y_train_lstm, y_test_lstm = y_lstm[:split], y_lstm[split:]

# LSTMãƒ¢ãƒ‡ãƒ«
model_lstm = Sequential([
    LSTM(64, return_sequences=True, input_shape=(seq_length, 1)),
    LSTM(32),
    Dense(16, activation='relu'),
    Dense(1)
])

model_lstm.compile(optimizer=Adam(lr=0.001), loss='mse')
model_lstm.fit(X_train_lstm, y_train_lstm, epochs=50, batch_size=32, verbose=0)

# äºˆæ¸¬
y_lstm_pred = model_lstm.predict(X_test_lstm).flatten()
mae_lstm = mean_absolute_error(y_test_lstm, y_lstm_pred)

print(f&quot;LSTM åŠ£åŒ–äºˆæ¸¬:&quot;)
print(f&quot;  MAE: {mae_lstm:.2f} mAh/g&quot;)
print(f&quot;  ã‚·ãƒ¼ã‚±ãƒ³ã‚¹é•·: {seq_length}ã‚µã‚¤ã‚¯ãƒ«&quot;)
</code></pre>
<h3>ä¾‹18: GRUï¼ˆGated Recurrent Unitï¼‰ãƒ¢ãƒ‡ãƒ«</h3>
<pre><code class="language-python">from tensorflow.keras.layers import GRU

# GRUãƒ¢ãƒ‡ãƒ«ï¼ˆLSTMã‚ˆã‚Šè»½é‡ï¼‰
model_gru = Sequential([
    GRU(64, return_sequences=True, input_shape=(seq_length, 1)),
    GRU(32),
    Dense(16, activation='relu'),
    Dense(1)
])

model_gru.compile(optimizer=Adam(lr=0.001), loss='mse')
model_gru.fit(X_train_lstm, y_train_lstm, epochs=50, batch_size=32, verbose=0)

# äºˆæ¸¬
y_gru_pred = model_gru.predict(X_test_lstm).flatten()
mae_gru = mean_absolute_error(y_test_lstm, y_gru_pred)

print(f&quot;GRU åŠ£åŒ–äºˆæ¸¬:&quot;)
print(f&quot;  MAE: {mae_gru:.2f} mAh/g&quot;)
print(f&quot;  LSTMæ¯”è¼ƒ: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•° {model_gru.count_params()} vs {model_lstm.count_params()}&quot;)
</code></pre>
<h3>ä¾‹19: å¯¿å‘½äºˆæ¸¬ï¼ˆRUL: Remaining Useful Lifeï¼‰</h3>
<pre><code class="language-python">def predict_RUL(capacity_history, threshold=160):
    &quot;&quot;&quot;80%å®¹é‡ï¼ˆ160 mAh/gï¼‰åˆ°é”ã¾ã§ã®ã‚µã‚¤ã‚¯ãƒ«æ•°äºˆæ¸¬&quot;&quot;&quot;
    # åˆæœŸ100ã‚µã‚¤ã‚¯ãƒ«ã‹ã‚‰äºˆæ¸¬
    early_cycles = capacity_history[:100]

    # ç·šå½¢ãƒ•ã‚£ãƒƒãƒˆ
    x = np.arange(len(early_cycles))
    coeffs = np.polyfit(x, early_cycles, 1)
    decay_rate = -coeffs[0]

    # RULè¨ˆç®—
    current_capacity = early_cycles[-1]
    remaining = current_capacity - threshold
    RUL = int(remaining / decay_rate) if decay_rate &gt; 0 else np.inf

    return RUL, decay_rate

RUL, decay = predict_RUL(capacity)
actual_life = np.where(capacity &lt; 160)[0][0] if np.any(capacity &lt; 160) else len(capacity)

print(f&quot;å¯¿å‘½äºˆæ¸¬ï¼ˆåˆæœŸ100ã‚µã‚¤ã‚¯ãƒ«ã‹ã‚‰ï¼‰:&quot;)
print(f&quot;  äºˆæ¸¬RUL: {RUL}ã‚µã‚¤ã‚¯ãƒ«&quot;)
print(f&quot;  å®Ÿéš›ã®å¯¿å‘½: {actual_life}ã‚µã‚¤ã‚¯ãƒ«&quot;)
print(f&quot;  äºˆæ¸¬èª¤å·®: {abs(RUL - actual_life)}ã‚µã‚¤ã‚¯ãƒ« ({abs(RUL - actual_life)/actual_life*100:.1f}%)&quot;)
print(f&quot;  åŠ£åŒ–é€Ÿåº¦: {decay:.3f} mAh/g/cycle&quot;)
</code></pre>
<h3>ä¾‹20: åŠ£åŒ–é€Ÿåº¦ã®äºˆæ¸¬</h3>
<pre><code class="language-python">def analyze_degradation_rate(capacity, window=50):
    &quot;&quot;&quot;ç§»å‹•ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã§ã®åŠ£åŒ–é€Ÿåº¦è§£æ&quot;&quot;&quot;
    rates = []
    cycles = []

    for i in range(window, len(capacity)):
        window_data = capacity[i-window:i]
        x = np.arange(window)
        rate = -np.polyfit(x, window_data, 1)[0]
        rates.append(rate)
        cycles.append(i)

    return np.array(cycles), np.array(rates)

cycles_rate, degradation_rates = analyze_degradation_rate(capacity)

plt.figure(figsize=(10, 6))
plt.plot(cycles_rate, degradation_rates * 1000, linewidth=2)
plt.xlabel('Cycle Number')
plt.ylabel('Degradation Rate (mAh/g per 1000 cycles)')
plt.title('Degradation Rate Evolution')
plt.grid(alpha=0.3)

print(f&quot;å¹³å‡åŠ£åŒ–é€Ÿåº¦: {degradation_rates.mean():.4f} mAh/g/cycle&quot;)
print(f&quot;æœ€å¤§åŠ£åŒ–é€Ÿåº¦: {degradation_rates.max():.4f} mAh/g/cycle (cycle {cycles_rate[degradation_rates.argmax()]})&quot;)
</code></pre>
<h3>ä¾‹21: ç•°å¸¸æ¤œçŸ¥ï¼ˆIsolation Forestï¼‰</h3>
<pre><code class="language-python">from sklearn.ensemble import IsolationForest

# ç‰¹å¾´é‡: å®¹é‡ã€åŠ£åŒ–é€Ÿåº¦
features = np.column_stack([capacity[50:], degradation_rates])

# Isolation Forest
clf = IsolationForest(contamination=0.05, random_state=42)
anomalies = clf.fit_predict(features)

n_anomalies = (anomalies == -1).sum()
print(f&quot;ç•°å¸¸æ¤œçŸ¥:&quot;)
print(f&quot;  ç•°å¸¸ã‚µã‚¤ã‚¯ãƒ«æ•°: {n_anomalies}&quot;)
print(f&quot;  ç•°å¸¸ç‡: {n_anomalies/len(anomalies)*100:.1f}%&quot;)
print(f&quot;  ç•°å¸¸ã‚µã‚¤ã‚¯ãƒ«: {cycles_rate[anomalies == -1]}&quot;)

# å¯è¦–åŒ–
plt.figure(figsize=(10, 6))
plt.scatter(cycles_rate[anomalies == 1], capacity[50:][anomalies == 1],
           c='blue', label='Normal', alpha=0.6)
plt.scatter(cycles_rate[anomalies == -1], capacity[50:][anomalies == -1],
           c='red', label='Anomaly', s=100, marker='x')
plt.xlabel('Cycle Number')
plt.ylabel('Capacity (mAh/g)')
plt.title('Anomaly Detection in Cycle Data')
plt.legend()
plt.grid(alpha=0.3)
</code></pre>
<h3>ä¾‹22: SOHï¼ˆState of Healthï¼‰æ¨å®š</h3>
<pre><code class="language-python">def estimate_SOH(current_capacity, initial_capacity=200):
    &quot;&quot;&quot;SOHæ¨å®š&quot;&quot;&quot;
    SOH = (current_capacity / initial_capacity) * 100

    if SOH &gt; 95:
        status = &quot;å„ªç§€&quot;
    elif SOH &gt; 80:
        status = &quot;è‰¯å¥½&quot;
    elif SOH &gt; 70:
        status = &quot;åŠ£åŒ–é€²è¡Œä¸­&quot;
    else:
        status = &quot;è¦äº¤æ›&quot;

    return SOH, status

# å„ã‚µã‚¤ã‚¯ãƒ«ã§ã®SOHæ¨å®š
for cycle in [100, 200, 300, 400, 500]:
    if cycle &lt;= len(capacity):
        soh, status = estimate_SOH(capacity[cycle-1])
        print(f&quot;Cycle {cycle:3d}: SOH={soh:5.1f}%, å®¹é‡={capacity[cycle-1]:5.1f} mAh/g, çŠ¶æ…‹={status}&quot;)
</code></pre>
<hr />
<h2>3.4 ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã«ã‚ˆã‚‹ææ–™æ¢ç´¢</h2>
<h3>ä¾‹23: Gaussian Processå›å¸°</h3>
<pre><code class="language-python">from sklearn.gaussian_process import GaussianProcessRegressor
from sklearn.gaussian_process.kernels import RBF, ConstantKernel

# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ï¼ˆNiæ¯”ç‡ vs å®¹é‡ï¼‰
X_gp = np.array([[0.3], [0.5], [0.6], [0.7], [0.9]])
y_gp = np.array([160, 180, 195, 190, 170])

# GPRãƒ¢ãƒ‡ãƒ«
kernel = ConstantKernel(1.0) * RBF(length_scale=0.1)
gpr = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10)
gpr.fit(X_gp, y_gp)

# äºˆæ¸¬
X_pred = np.linspace(0.2, 1.0, 100).reshape(-1, 1)
y_pred, y_std = gpr.predict(X_pred, return_std=True)

# å¯è¦–åŒ–
plt.figure(figsize=(10, 6))
plt.plot(X_pred, y_pred, 'b-', label='Mean prediction')
plt.fill_between(X_pred.ravel(), y_pred - 2*y_std, y_pred + 2*y_std,
                alpha=0.3, label='Â±2Ïƒ')
plt.scatter(X_gp, y_gp, c='red', s=100, label='Observations', zorder=10)
plt.xlabel('Ni Ratio')
plt.ylabel('Capacity (mAh/g)')
plt.title('Gaussian Process Regression')
plt.legend()
plt.grid(alpha=0.3)

print(f&quot;æœ€é©Niæ¯”ç‡ï¼ˆäºˆæ¸¬ï¼‰: {X_pred[np.argmax(y_pred)][0]:.2f}&quot;)
print(f&quot;æœ€å¤§äºˆæ¸¬å®¹é‡: {y_pred.max():.1f} mAh/g&quot;)
</code></pre>
<h3>ä¾‹24: ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ãƒ«ãƒ¼ãƒ—</h3>
<pre><code class="language-python">from skopt import gp_minimize
from skopt.space import Real

# ç›®çš„é–¢æ•°ï¼ˆå®¹é‡ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
def battery_capacity(x):
    &quot;&quot;&quot;Niæ¯”ç‡ã‹ã‚‰å®¹é‡ã‚’äºˆæ¸¬ï¼ˆå®Ÿéš›ã¯å®Ÿé¨“ or DFTè¨ˆç®—ï¼‰&quot;&quot;&quot;
    ni_ratio = x[0]
    # ä»®æƒ³çš„ãªå®¹é‡é–¢æ•°
    capacity = 200 * ni_ratio - 150 * (ni_ratio - 0.65)**2 + np.random.randn() * 3
    return -capacity  # æœ€å°åŒ–å•é¡Œã«å¤‰æ›

# æ¢ç´¢ç©ºé–“
space = [Real(0.3, 1.0, name='Ni_ratio')]

# ãƒ™ã‚¤ã‚ºæœ€é©åŒ–
result = gp_minimize(
    battery_capacity,
    space,
    n_calls=20,
    random_state=42,
    verbose=False
)

print(f&quot;ãƒ™ã‚¤ã‚ºæœ€é©åŒ–çµæœ:&quot;)
print(f&quot;  æœ€é©Niæ¯”ç‡: {result.x[0]:.3f}&quot;)
print(f&quot;  æœ€å¤§å®¹é‡: {-result.fun:.1f} mAh/g&quot;)
print(f&quot;  å®Ÿé¨“å›æ•°: {len(result.x_iters)}&quot;)
</code></pre>
<h3>ä¾‹25: å¤šç›®çš„æœ€é©åŒ–ï¼ˆå®¹é‡ &amp; ã‚µã‚¤ã‚¯ãƒ«å¯¿å‘½ï¼‰</h3>
<pre><code class="language-python">def multi_objective(x):
    &quot;&quot;&quot;å®¹é‡ã¨ã‚µã‚¤ã‚¯ãƒ«å¯¿å‘½ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•&quot;&quot;&quot;
    ni_ratio = x[0]

    # å®¹é‡ï¼ˆé«˜Niæ¯”ç‡ã§å¢—åŠ ï¼‰
    capacity = 200 * ni_ratio - 100 * (ni_ratio - 0.7)**2

    # ã‚µã‚¤ã‚¯ãƒ«å¯¿å‘½ï¼ˆä½Niæ¯”ç‡ã§å‘ä¸Šï¼‰
    cycle_life = 2000 - 1000 * ni_ratio + 500 * (ni_ratio - 0.5)**2

    # é‡ã¿ä»˜ãå’Œï¼ˆã‚¹ã‚«ãƒ©ãƒ¼åŒ–ï¼‰
    weight_cap = 0.6
    weight_life = 0.4

    score = weight_cap * capacity + weight_life * (cycle_life / 10)
    return -score

result_mo = gp_minimize(multi_objective, space, n_calls=25, random_state=42)

print(f&quot;å¤šç›®çš„æœ€é©åŒ–çµæœ:&quot;)
print(f&quot;  æœ€é©Niæ¯”ç‡: {result_mo.x[0]:.3f}&quot;)
print(f&quot;  äºˆæ¸¬å®¹é‡: {(200 * result_mo.x[0] - 100 * (result_mo.x[0] - 0.7)**2):.1f} mAh/g&quot;)
print(f&quot;  äºˆæ¸¬å¯¿å‘½: {(2000 - 1000 * result_mo.x[0] + 500 * (result_mo.x[0] - 0.5)**2):.0f} cycles&quot;)
</code></pre>
<h3>ä¾‹26: åˆ¶ç´„ä»˜ãæœ€é©åŒ–</h3>
<pre><code class="language-python">def constrained_optimization(x):
    &quot;&quot;&quot;å®‰å…¨æ€§åˆ¶ç´„ä»˜ãå®¹é‡æœ€é©åŒ–&quot;&quot;&quot;
    ni_ratio = x[0]

    # åˆ¶ç´„: Niæ¯”ç‡ &lt; 0.85ï¼ˆå®‰å…¨æ€§è€ƒæ…®ï¼‰
    if ni_ratio &gt; 0.85:
        return 1e6  # ãƒšãƒŠãƒ«ãƒ†ã‚£

    # å®¹é‡äºˆæ¸¬
    capacity = 200 * ni_ratio - 120 * (ni_ratio - 0.7)**2
    return -capacity

result_const = gp_minimize(constrained_optimization, space, n_calls=20, random_state=42)

print(f&quot;åˆ¶ç´„ä»˜ãæœ€é©åŒ–çµæœ:&quot;)
print(f&quot;  æœ€é©Niæ¯”ç‡: {result_const.x[0]:.3f} (&lt; 0.85)&quot;)
print(f&quot;  æœ€å¤§å®¹é‡: {-result_const.fun:.1f} mAh/g&quot;)
</code></pre>
<h3>ä¾‹27: ãƒ‘ãƒ¬ãƒ¼ãƒˆãƒ•ãƒ­ãƒ³ãƒˆå¯è¦–åŒ–</h3>
<pre><code class="language-python"># å¤šç›®çš„æœ€é©åŒ–ã®çµæœï¼ˆå®¹é‡ vs ã‚µã‚¤ã‚¯ãƒ«å¯¿å‘½ï¼‰
ni_ratios = np.linspace(0.3, 1.0, 50)
capacities = [200 * ni - 100 * (ni - 0.7)**2 for ni in ni_ratios]
cycle_lives = [2000 - 1000 * ni + 500 * (ni - 0.5)**2 for ni in ni_ratios]

plt.figure(figsize=(10, 6))
plt.scatter(capacities, cycle_lives, c=ni_ratios, cmap='viridis', s=50)
plt.colorbar(label='Ni Ratio')
plt.xlabel('Capacity (mAh/g)')
plt.ylabel('Cycle Life')
plt.title('Pareto Front: Capacity vs Cycle Life')
plt.grid(alpha=0.3)

# ãƒ‘ãƒ¬ãƒ¼ãƒˆæœ€é©ç‚¹ã®æ¤œå‡º
pareto_indices = []
for i in range(len(capacities)):
    dominated = False
    for j in range(len(capacities)):
        if capacities[j] &gt; capacities[i] and cycle_lives[j] &gt; cycle_lives[i]:
            dominated = True
            break
    if not dominated:
        pareto_indices.append(i)

plt.scatter([capacities[i] for i in pareto_indices],
           [cycle_lives[i] for i in pareto_indices],
           c='red', s=100, marker='*', label='Pareto Optimal', zorder=10)
plt.legend()

print(f&quot;ãƒ‘ãƒ¬ãƒ¼ãƒˆæœ€é©è§£ã®æ•°: {len(pareto_indices)}&quot;)
</code></pre>
<hr />
<h2>3.5 PyBaMMã«ã‚ˆã‚‹é›»æ± ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³</h2>
<h3>ä¾‹28: DFNãƒ¢ãƒ‡ãƒ«ï¼ˆDoyle-Fuller-Newmanï¼‰</h3>
<pre><code class="language-python">import pybamm

# DFNãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰
model = pybamm.lithium_ion.DFN()

# ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®šï¼ˆGraphite || LCOï¼‰
parameter_values = pybamm.ParameterValues(&quot;Chen2020&quot;)

# ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®š
sim = pybamm.Simulation(model, parameter_values=parameter_values)

# 1Cæ”¾é›»
sim.solve([0, 3600])  # 0-3600ç§’ï¼ˆ1æ™‚é–“ï¼‰

# çµæœå–å¾—
time = sim.solution[&quot;Time [h]&quot;].entries
voltage = sim.solution[&quot;Terminal voltage [V]&quot;].entries
current = sim.solution[&quot;Current [A]&quot;].entries

print(&quot;DFNãƒ¢ãƒ‡ãƒ«ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³:&quot;)
print(f&quot;  åˆæœŸé›»åœ§: {voltage[0]:.3f} V&quot;)
print(f&quot;  æœ€çµ‚é›»åœ§: {voltage[-1]:.3f} V&quot;)
print(f&quot;  æ”¾é›»æ™‚é–“: {time[-1]:.2f} h&quot;)
</code></pre>
<h3>ä¾‹29: å……æ”¾é›»æ›²ç·šã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³</h3>
<pre><code class="language-python"># è¤‡æ•°ã®C-rateã§ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
c_rates = [0.5, 1, 2, 5]
experiments = []

for c_rate in c_rates:
    experiment = pybamm.Experiment([
        f&quot;Discharge at {c_rate}C until 2.5 V&quot;,
        &quot;Rest for 10 minutes&quot;,
        &quot;Charge at 1C until 4.2 V&quot;,
        &quot;Hold at 4.2 V until C/50&quot;
    ])
    experiments.append(experiment)

# å¯è¦–åŒ–
fig, ax = plt.subplots(figsize=(10, 6))

for i, c_rate in enumerate(c_rates):
    sim = pybamm.Simulation(model, parameter_values=parameter_values,
                            experiment=experiments[i])
    sim.solve()

    time = sim.solution[&quot;Time [h]&quot;].entries
    voltage = sim.solution[&quot;Terminal voltage [V]&quot;].entries

    ax.plot(time, voltage, label=f'{c_rate}C', linewidth=2)

ax.set_xlabel('Time (h)')
ax.set_ylabel('Voltage (V)')
ax.set_title('Discharge Curves at Different C-rates')
ax.legend()
ax.grid(alpha=0.3)

print(&quot;è¤‡æ•°C-rateã§ã®æ”¾é›»ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Œäº†&quot;)
</code></pre>
<h3>ä¾‹30: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–ã¨ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°</h3>
<pre><code class="language-python"># å®Ÿé¨“ãƒ‡ãƒ¼ã‚¿ï¼ˆã‚µãƒ³ãƒ—ãƒ«ï¼‰
experimental_voltage = voltage + np.random.randn(len(voltage)) * 0.05

# ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–ï¼ˆç°¡æ˜“ç‰ˆï¼‰
def fit_resistance(R_value):
    &quot;&quot;&quot;å†…éƒ¨æŠµæŠ—ã®ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°&quot;&quot;&quot;
    params = parameter_values.copy()
    params[&quot;Electrolyte conductivity [S.m-1]&quot;] = R_value

    sim_fit = pybamm.Simulation(model, parameter_values=params)
    sim_fit.solve([0, 3600])

    sim_voltage = sim_fit.solution[&quot;Terminal voltage [V]&quot;].entries

    # èª¤å·®è¨ˆç®—
    mse = np.mean((sim_voltage - experimental_voltage)**2)
    return mse

# æœ€é©åŒ–
from scipy.optimize import minimize_scalar

result_fit = minimize_scalar(fit_resistance, bounds=(0.5, 2.0), method='bounded')

print(f&quot;ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°:&quot;)
print(f&quot;  æœ€é©é›»è§£è³ªä¼å°åº¦: {result_fit.x:.3f} S/m&quot;)
print(f&quot;  MSE: {result_fit.fun:.6f}&quot;)

# æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
params_opt = parameter_values.copy()
params_opt[&quot;Electrolyte conductivity [S.m-1]&quot;] = result_fit.x
sim_opt = pybamm.Simulation(model, parameter_values=params_opt)
sim_opt.solve([0, 3600])

print(&quot;æœ€é©åŒ–å®Œäº†: å®Ÿé¨“ãƒ‡ãƒ¼ã‚¿ã«ãƒ•ã‚£ãƒƒãƒˆ&quot;)
</code></pre>
<hr />
<h2>3.6 ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒãƒ£ãƒ¬ãƒ³ã‚¸</h2>
<p><strong>èª²é¡Œ: é«˜å®¹é‡ãƒ»é•·å¯¿å‘½æ­£æ¥µææ–™ã®ç™ºè¦‹</strong></p>
<p>ä»¥ä¸‹ã®æ‰‹é †ã§ã€æœ€é©ãªNCMæ­£æ¥µææ–™ã‚’è¨­è¨ˆã—ã¦ãã ã•ã„ï¼š</p>
<ol>
<li><strong>ãƒ‡ãƒ¼ã‚¿åé›†</strong>: Materials Projectã‹ã‚‰Ni-Co-Mné…¸åŒ–ç‰©ãƒ‡ãƒ¼ã‚¿å–å¾—</li>
<li><strong>è¨˜è¿°å­è¨ˆç®—</strong>: çµ„æˆæ¯”ã€æ ¼å­å®šæ•°ã€ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—ãªã©</li>
<li><strong>äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰</strong>: XGBoostã§å®¹é‡äºˆæ¸¬ï¼ˆç›®æ¨™ &gt; 200 mAh/gï¼‰</li>
<li><strong>ãƒ™ã‚¤ã‚ºæœ€é©åŒ–</strong>: Ni:Co:Mnæ¯”ã®æœ€é©åŒ–ï¼ˆåˆ¶ç´„: å®‰å…¨æ€§ï¼‰</li>
<li><strong>ã‚µã‚¤ã‚¯ãƒ«æ€§èƒ½è©•ä¾¡</strong>: PyBaMMã§ã‚µã‚¤ã‚¯ãƒ«å¯¿å‘½ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆç›®æ¨™ &gt; 2,000ã‚µã‚¤ã‚¯ãƒ«ï¼‰</li>
</ol>
<p><strong>è©•ä¾¡åŸºæº–:</strong>
- å®¹é‡ &gt; 200 mAh/g
- ã‚µã‚¤ã‚¯ãƒ«å¯¿å‘½ &gt; 2,000ã‚µã‚¤ã‚¯ãƒ«ï¼ˆ80%å®¹é‡ç¶­æŒï¼‰
- å®‰å…¨æ€§: Niæ¯”ç‡ &lt; 0.85
- ã‚³ã‚¹ãƒˆ: Coä½¿ç”¨é‡æœ€å°åŒ–</p>
<p><strong>æå‡ºç‰©:</strong>
- æœ€é©çµ„æˆï¼ˆNi:Co:Mnæ¯”ç‡ï¼‰
- äºˆæ¸¬æ€§èƒ½ï¼ˆå®¹é‡ã€å¯¿å‘½ï¼‰
- Pythonã‚³ãƒ¼ãƒ‰å…¨ä½“</p>
<hr />
<h2>æ¼”ç¿’å•é¡Œ</h2>
<p><strong>å•1:</strong> LiNiâ‚€.â‚ˆCoâ‚€.â‚Mnâ‚€.â‚Oâ‚‚ã®ç†è«–å®¹é‡ã‚’è¨ˆç®—ã—ã€å®Ÿæ¸¬å®¹é‡ãŒ180 mAh/gã®å ´åˆã®ã‚¯ãƒ¼ãƒ­ãƒ³åŠ¹ç‡ã‚’æ±‚ã‚ã‚ˆã€‚</p>
<p><strong>å•2:</strong> LSTM RNNæ§‹é€ ã¯ã€Feed-forward Neural Networkã¨æ¯”è¼ƒã—ã¦ã‚µã‚¤ã‚¯ãƒ«åŠ£åŒ–äºˆæ¸¬ã«ãŠã„ã¦ãªãœå„ªã‚Œã¦ã„ã‚‹ã‹èª¬æ˜ã›ã‚ˆã€‚</p>
<p><strong>å•3:</strong> ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã§ã€ç²å¾—é–¢æ•°ã¨ã—ã¦EIï¼ˆExpected Improvementï¼‰ã‚’ç”¨ã„ã‚‹åˆ©ç‚¹ã‚’2ã¤æŒ™ã’ã‚ˆã€‚</p>
<p><strong>å•4:</strong> PyBaMMã®DFNãƒ¢ãƒ‡ãƒ«ã§ã€è² æ¥µææ–™ã‚’ã‚°ãƒ©ãƒ•ã‚¡ã‚¤ãƒˆã‹ã‚‰ã‚·ãƒªã‚³ãƒ³ã«å¤‰æ›´ã—ãŸå ´åˆã®å½±éŸ¿ã‚’äºˆæ¸¬ã›ã‚ˆã€‚</p>
<p><strong>å•5:</strong> Transfer Learningã‚’ç”¨ã„ã¦ã€LIBæ­£æ¥µææ–™ã®çŸ¥è­˜ã‚’Na-ioné›»æ± æ­£æ¥µææ–™ã«é©ç”¨ã™ã‚‹éš›ã®èª²é¡Œã‚’è«–ã˜ã‚ˆï¼ˆ400å­—ä»¥å†…ï¼‰ã€‚</p>
<hr />
<h2>å‚è€ƒæ–‡çŒ®</h2>
<ol>
<li>Sulzer, V. et al. "Python Battery Mathematical Modelling (PyBaMM)." <em>JOSS</em> (2021).</li>
<li>Severson, K. A. et al. "Data-driven prediction of battery cycle life." <em>Nat. Energy</em> (2019).</li>
<li>Chen, C. et al. "A Critical Review of Machine Learning of Energy Materials." <em>Adv. Energy Mater.</em> (2020).</li>
<li>Attia, P. M. et al. "Closed-loop optimization of fast-charging protocols." <em>Nature</em> (2020).</li>
</ol>
<hr />
<p><strong>æ¬¡ç« </strong>: <a href="chapter4-case-studies.md">ç¬¬4ç« ï¼šé›»æ± é–‹ç™ºã®æœ€æ–°äº‹ä¾‹ã¨ç”£æ¥­å¿œç”¨</a></p>
<p><strong>ãƒ©ã‚¤ã‚»ãƒ³ã‚¹</strong>: ã“ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯CC BY 4.0ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã®ä¸‹ã§æä¾›ã•ã‚Œã¦ã„ã¾ã™ã€‚</p><div class="navigation">
    <a href="chapter2-methods.html" class="nav-button">â† ç¬¬2ç« </a>
    <a href="index.html" class="nav-button">ã‚·ãƒªãƒ¼ã‚ºç›®æ¬¡</a>
    <a href="chapter4-case-studies.html" class="nav-button">ç¬¬4ç«  â†’</a>
</div>
    </main>

    <footer>
        <p><strong>AI Terakoya ãƒãƒ†ãƒªã‚¢ãƒ«ã‚ºãƒ»ã‚¤ãƒ³ãƒ•ã‚©ãƒãƒ†ã‚£ã‚¯ã‚¹æ•™è‚²ã‚³ãƒ³ãƒ†ãƒ³ãƒ„</strong></p>
        <p>ç›£ä¿®: Dr. Yusuke Hashimotoï¼ˆæ±åŒ—å¤§å­¦ï¼‰</p>
        <p>Â© 2025 AI Terakoya. Licensed under CC BY 4.0</p>
    </footer>
</body>
</html>
