<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Chapter - AI Terakoya</title>

    <style>
        :root {
            --color-primary: #2c3e50;
            --color-primary-dark: #1a252f;
            --color-accent: #7b2cbf;
            --color-accent-light: #9d4edd;
            --color-text: #2d3748;
            --color-text-light: #4a5568;
            --color-bg: #ffffff;
            --color-bg-alt: #f7fafc;
            --color-border: #e2e8f0;
            --color-code-bg: #f8f9fa;
            --color-link: #3182ce;
            --color-link-hover: #2c5aa0;

            --spacing-xs: 0.5rem;
            --spacing-sm: 1rem;
            --spacing-md: 1.5rem;
            --spacing-lg: 2rem;
            --spacing-xl: 3rem;

            --font-body: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            --font-mono: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;

            --border-radius: 8px;
            --box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: var(--font-body);
            line-height: 1.7;
            color: var(--color-text);
            background-color: var(--color-bg);
            font-size: 16px;
        }

        header {
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            padding: var(--spacing-xl) var(--spacing-md);
            margin-bottom: var(--spacing-xl);
            box-shadow: var(--box-shadow);
        }

        .header-content {
            max-width: 900px;
            margin: 0 auto;
        }

        h1 {
            font-size: 2rem;
            font-weight: 700;
            margin-bottom: var(--spacing-sm);
            line-height: 1.2;
        }

        .subtitle {
            font-size: 1.1rem;
            opacity: 0.95;
            font-weight: 400;
            margin-bottom: var(--spacing-md);
        }

        .meta {
            display: flex;
            flex-wrap: wrap;
            gap: var(--spacing-md);
            font-size: 0.9rem;
            opacity: 0.9;
        }

        .meta-item {
            display: flex;
            align-items: center;
            gap: 0.3rem;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 0 var(--spacing-md) var(--spacing-xl);
        }

        h2 {
            font-size: 1.75rem;
            color: var(--color-primary);
            margin-top: var(--spacing-xl);
            margin-bottom: var(--spacing-md);
            padding-bottom: var(--spacing-xs);
            border-bottom: 3px solid var(--color-accent);
        }

        h3 {
            font-size: 1.4rem;
            color: var(--color-primary);
            margin-top: var(--spacing-lg);
            margin-bottom: var(--spacing-sm);
        }

        h4 {
            font-size: 1.1rem;
            color: var(--color-primary-dark);
            margin-top: var(--spacing-md);
            margin-bottom: var(--spacing-sm);
        }

        p {
            margin-bottom: var(--spacing-md);
            color: var(--color-text);
        }

        a {
            color: var(--color-link);
            text-decoration: none;
            transition: color 0.2s;
        }

        a:hover {
            color: var(--color-link-hover);
            text-decoration: underline;
        }

        ul, ol {
            margin-left: var(--spacing-lg);
            margin-bottom: var(--spacing-md);
        }

        li {
            margin-bottom: var(--spacing-xs);
            color: var(--color-text);
        }

        pre {
            background-color: var(--color-code-bg);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            overflow-x: auto;
            margin-bottom: var(--spacing-md);
            font-family: var(--font-mono);
            font-size: 0.9rem;
            line-height: 1.5;
        }

        code {
            font-family: var(--font-mono);
            font-size: 0.9em;
            background-color: var(--color-code-bg);
            padding: 0.2em 0.4em;
            border-radius: 3px;
        }

        pre code {
            background-color: transparent;
            padding: 0;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: var(--spacing-md);
            font-size: 0.95rem;
        }

        th, td {
            border: 1px solid var(--color-border);
            padding: var(--spacing-sm);
            text-align: left;
        }

        th {
            background-color: var(--color-bg-alt);
            font-weight: 600;
            color: var(--color-primary);
        }

        blockquote {
            border-left: 4px solid var(--color-accent);
            padding-left: var(--spacing-md);
            margin: var(--spacing-md) 0;
            color: var(--color-text-light);
            font-style: italic;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        .mermaid {
            text-align: center;
            margin: var(--spacing-lg) 0;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        details {
            background-color: var(--color-bg-alt);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            margin-bottom: var(--spacing-md);
        }

        summary {
            cursor: pointer;
            font-weight: 600;
            color: var(--color-primary);
            user-select: none;
            padding: var(--spacing-xs);
            margin: calc(-1 * var(--spacing-md));
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        summary:hover {
            background-color: rgba(123, 44, 191, 0.1);
        }

        details[open] summary {
            margin-bottom: var(--spacing-md);
            border-bottom: 1px solid var(--color-border);
        }

        .learning-objectives {
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
            padding: var(--spacing-lg);
            border-radius: var(--border-radius);
            border-left: 4px solid var(--color-accent);
            margin-bottom: var(--spacing-xl);
        }

        .learning-objectives h2 {
            margin-top: 0;
            border-bottom: none;
        }

        .navigation {
            display: flex;
            justify-content: space-between;
            gap: var(--spacing-md);
            margin: var(--spacing-xl) 0;
            padding-top: var(--spacing-lg);
            border-top: 2px solid var(--color-border);
        }

        .nav-button {
            flex: 1;
            padding: var(--spacing-md);
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            border-radius: var(--border-radius);
            text-align: center;
            font-weight: 600;
            transition: transform 0.2s, box-shadow 0.2s;
            box-shadow: var(--box-shadow);
        }

        .nav-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
            text-decoration: none;
        }

        footer {
            margin-top: var(--spacing-xl);
            padding: var(--spacing-lg) var(--spacing-md);
            background-color: var(--color-bg-alt);
            border-top: 1px solid var(--color-border);
            text-align: center;
            font-size: 0.9rem;
            color: var(--color-text-light);
        }

        @media (max-width: 768px) {
            h1 {
                font-size: 1.5rem;
            }

            h2 {
                font-size: 1.4rem;
            }

            h3 {
                font-size: 1.2rem;
            }

            .meta {
                font-size: 0.85rem;
            }

            .navigation {
                flex-direction: column;
            }

            table {
                font-size: 0.85rem;
            }

            th, td {
                padding: var(--spacing-xs);
            }
        }
    </style>

    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
        mermaid.initialize({ startOnLoad: true, theme: 'default' });
    </script>

    <!-- MathJax for LaTeX equation rendering -->
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\(', '\)']],
                displayMath: [['$$', '$$'], ['\[', '\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
                ignoreHtmlClass: 'mermaid'
            }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" async></script>
</head>
<body>
    <header>
        <div class="header-content">
            <h1>Chapter</h1>
            <p class="subtitle"></p>
            <div class="meta">
                <span class="meta-item">üìñ Ë™≠‰∫ÜÊôÇÈñì: 20-25ÂàÜ</span>
                <span class="meta-item">üìä Èõ£ÊòìÂ∫¶: ÂàùÁ¥ö</span>
                <span class="meta-item">üíª „Ç≥„Éº„Éâ‰æã: 0ÂÄã</span>
                <span class="meta-item">üìù ÊºîÁøíÂïèÈ°å: 0Âïè</span>
            </div>
        </div>
    </header>

    <main class="container">
<h1>Á¨¨4Á´†: ÁîüÊàê„É¢„Éá„É´„Å®ÈÄÜË®≠Ë®à</h1>
<p><strong>Â≠¶ÁøíÊôÇÈñì</strong>: 20-25ÂàÜ | <strong>Èõ£ÊòìÂ∫¶</strong>: ‰∏äÁ¥ö</p>
<h2>üìã „Åì„ÅÆÁ´†„ÅßÂ≠¶„Å∂„Åì„Å®</h2>
<ul>
<li>Êã°Êï£„É¢„Éá„É´ÔºàDiffusion ModelsÔºâ„ÅÆÂéüÁêÜ</li>
<li>Êù°‰ª∂‰ªò„ÅçÁîüÊàêÔºàConditional GenerationÔºâ</li>
<li>ÂàÜÂ≠êÁîüÊàê„Å®SMILESÁîüÊàê</li>
<li>ÊùêÊñôÈÄÜË®≠Ë®àÔºàInverse DesignÔºâ</li>
<li>Áî£Ê•≠ÂøúÁî®„Å®„Ç≠„É£„É™„Ç¢„Éë„Çπ</li>
</ul>
<hr />
<h2>4.1 ÁîüÊàê„É¢„Éá„É´„Å®„ÅØ</h2>
<h3>ÊùêÊñôÁßëÂ≠¶„Å´„Åä„Åë„ÇãÁîüÊàê„É¢„Éá„É´„ÅÆÈáçË¶ÅÊÄß</h3>
<p><strong>ÂæìÊù•„ÅÆ„Ç¢„Éó„É≠„Éº„ÉÅÔºàÈ†ÜÂïèÈ°åÔºâ</strong>:</p>
<pre><code>ÊùêÊñôÊßãÈÄ† ‚Üí ÁâπÊÄß‰∫àÊ∏¨
</code></pre>
<p><strong>ÈÄÜË®≠Ë®àÔºàÈÄÜÂïèÈ°åÔºâ</strong>:</p>
<pre><code>Êúõ„Åæ„Åó„ÅÑÁâπÊÄß ‚Üí ÊùêÊñôÊßãÈÄ†ÁîüÊàê
</code></pre>
<p><strong>ÁîüÊàê„É¢„Éá„É´„ÅÆÂà©ÁÇπ</strong>:
- ‚úÖ Â∫ÉÂ§ß„Å™Êé¢Á¥¢Á©∫Èñì„Åã„ÇâÂÄôË£ú„ÇíËá™ÂãïÁîüÊàê
- ‚úÖ Â§öÁõÆÁöÑÊúÄÈÅ©ÂåñÔºàË§áÊï∞„ÅÆÁâπÊÄß„ÇíÂêåÊôÇ„Å´Ê∫ÄË∂≥Ôºâ
- ‚úÖ ÂêàÊàêÂèØËÉΩÊÄß„ÇíËÄÉÊÖÆ„Åó„ÅüÁîüÊàê
- ‚úÖ ‰∫∫Èñì„ÅÆÁõ¥ÊÑü„ÇíË∂Ö„Åà„ÅüÊñ∞Ë¶èÊßãÈÄ†„ÅÆÁô∫Ë¶ã</p>
<div class="mermaid">
graph LR
    A[ÁõÆÊ®ôÁâπÊÄß] --> B[ÁîüÊàê„É¢„Éá„É´]
    C[Âà∂Á¥ÑÊù°‰ª∂] --> B
    B --> D[ÂÄôË£úÊùêÊñô]
    D --> E[ÁâπÊÄß‰∫àÊ∏¨]
    E --> F{ÁõÆÊ®ôÈÅîÊàê?}
    F -->|No| B
    F -->|Yes| G[ÂÆüÈ®ìÊ§úË®º]

    style B fill:#e1f5ff
    style G fill:#ffe1e1
</div>

<hr />
<h2>4.2 Êã°Êï£„É¢„Éá„É´„ÅÆÂéüÁêÜ</h2>
<h3>Êã°Êï£„É¢„Éá„É´„Å®„ÅØ</h3>
<p><strong>Âü∫Êú¨„Ç¢„Ç§„Éá„Ç¢</strong>: „Éé„Ç§„Ç∫ËøΩÂä†„Éó„É≠„Çª„Çπ„ÇíÈÄÜËª¢„Åó„Å¶„ÄÅ„Éé„Ç§„Ç∫„Åã„Çâ„Éá„Éº„Çø„ÇíÁîüÊàê</p>
<p><strong>Forward ProcessÔºà„Éé„Ç§„Ç∫ËøΩÂä†Ôºâ</strong>:
$$
q(x_t | x_{t-1}) = \mathcal{N}(x_t; \sqrt{1-\beta_t} x_{t-1}, \beta_t I)
$$</p>
<p><strong>Reverse ProcessÔºà„Éé„Ç§„Ç∫Èô§ÂéªÔºâ</strong>:
$$
p_\theta(x_{t-1} | x_t) = \mathcal{N}(x_{t-1}; \mu_\theta(x_t, t), \Sigma_\theta(x_t, t))
$$</p>
<h3>Ë¶ñË¶öÁöÑÁêÜËß£</h3>
<div class="mermaid">
graph LR
    X0[ÂÖÉ„Éá„Éº„Çø x‚ÇÄ] -->|„Éé„Ç§„Ç∫ËøΩÂä†| X1[x‚ÇÅ]
    X1 -->|„Éé„Ç§„Ç∫ËøΩÂä†| X2[x‚ÇÇ]
    X2 -->|...| XT[Á¥îÁ≤ã„Éé„Ç§„Ç∫ x‚Çú]

    XT -->|„Éé„Ç§„Ç∫Èô§Âéª| X2R[x‚ÇÇ]
    X2R -->|„Éé„Ç§„Ç∫Èô§Âéª| X1R[x‚ÇÅ]
    X1R -->|„Éé„Ç§„Ç∫Èô§Âéª| X0R[ÁîüÊàê„Éá„Éº„Çø x‚ÇÄ]

    style X0 fill:#e1f5ff
    style XT fill:#ffe1e1
    style X0R fill:#e1ffe1
</div>

<h3>Á∞°ÊòìÂÆüË£Ö</h3>
<pre><code class="language-python">import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np

class SimpleDiffusionModel(nn.Module):
    def __init__(self, input_dim, hidden_dim=256, num_timesteps=1000):
        super(SimpleDiffusionModel, self).__init__()
        self.num_timesteps = num_timesteps

        # „Éé„Ç§„Ç∫„Çπ„Ç±„Ç∏„É•„Éº„É´
        self.betas = torch.linspace(1e-4, 0.02, num_timesteps)
        self.alphas = 1.0 - self.betas
        self.alphas_cumprod = torch.cumprod(self.alphas, dim=0)

        # „Éé„Ç§„Ç∫‰∫àÊ∏¨„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ
        self.noise_predictor = nn.Sequential(
            nn.Linear(input_dim + 1, hidden_dim),  # +1„ÅØ„Çø„Ç§„É†„Çπ„ÉÜ„ÉÉ„Éó
            nn.ReLU(),
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, input_dim)
        )

    def forward_process(self, x0, t):
        &quot;&quot;&quot;
        Forward process: „Éé„Ç§„Ç∫ËøΩÂä†

        Args:
            x0: ÂÖÉ„Éá„Éº„Çø (batch_size, input_dim)
            t: „Çø„Ç§„É†„Çπ„ÉÜ„ÉÉ„Éó (batch_size,)
        Returns:
            xt: „Éé„Ç§„Ç∫„ÅåËøΩÂä†„Åï„Çå„Åü„Éá„Éº„Çø
            noise: ËøΩÂä†„Åï„Çå„Åü„Éé„Ç§„Ç∫
        &quot;&quot;&quot;
        batch_size = x0.size(0)

        # „Çø„Ç§„É†„Çπ„ÉÜ„ÉÉ„Éó„Åî„Å®„ÅÆ„Éé„Ç§„Ç∫„É¨„Éô„É´
        alpha_t = self.alphas_cumprod[t].view(-1, 1)
        sqrt_alpha_t = torch.sqrt(alpha_t)
        sqrt_one_minus_alpha_t = torch.sqrt(1 - alpha_t)

        # „Éé„Ç§„Ç∫„Çí„Çµ„É≥„Éó„É™„É≥„Ç∞
        noise = torch.randn_like(x0)

        # „Éé„Ç§„Ç∫„ÇíËøΩÂä†
        xt = sqrt_alpha_t * x0 + sqrt_one_minus_alpha_t * noise

        return xt, noise

    def predict_noise(self, xt, t):
        &quot;&quot;&quot;
        „Éé„Ç§„Ç∫„Çí‰∫àÊ∏¨

        Args:
            xt: „Éé„Ç§„Ç∫„ÅåËøΩÂä†„Åï„Çå„Åü„Éá„Éº„Çø
            t: „Çø„Ç§„É†„Çπ„ÉÜ„ÉÉ„Éó
        Returns:
            predicted_noise: ‰∫àÊ∏¨„Åï„Çå„Åü„Éé„Ç§„Ç∫
        &quot;&quot;&quot;
        # „Çø„Ç§„É†„Çπ„ÉÜ„ÉÉ„Éó„ÇíÂüã„ÇÅËæº„Åø
        t_embed = t.float().unsqueeze(1) / self.num_timesteps

        # „Éé„Ç§„Ç∫‰∫àÊ∏¨
        x_with_t = torch.cat([xt, t_embed], dim=1)
        predicted_noise = self.noise_predictor(x_with_t)

        return predicted_noise

    def reverse_process(self, xt, t):
        &quot;&quot;&quot;
        Reverse process: „Éé„Ç§„Ç∫Èô§ÂéªÔºà1„Çπ„ÉÜ„ÉÉ„ÉóÔºâ

        Args:
            xt: ÁèæÂú®„ÅÆ„Éá„Éº„Çø
            t: „Çø„Ç§„É†„Çπ„ÉÜ„ÉÉ„Éó
        Returns:
            x_prev: 1„Çπ„ÉÜ„ÉÉ„ÉóÂâç„ÅÆ„Éá„Éº„Çø
        &quot;&quot;&quot;
        # „Éé„Ç§„Ç∫„Çí‰∫àÊ∏¨
        predicted_noise = self.predict_noise(xt, t)

        # „Éë„É©„É°„Éº„Çø
        alpha_t = self.alphas[t].view(-1, 1)
        alpha_t_cumprod = self.alphas_cumprod[t].view(-1, 1)
        beta_t = self.betas[t].view(-1, 1)

        # Ââç„ÅÆ„Çπ„ÉÜ„ÉÉ„Éó„ÇíË®àÁÆó
        x_prev = (1 / torch.sqrt(alpha_t)) * (
            xt - (beta_t / torch.sqrt(1 - alpha_t_cumprod)) * predicted_noise
        )

        # „Éé„Ç§„Ç∫„ÇíËøΩÂä†Ôºàt &gt; 0„ÅÆÂ†¥ÂêàÔºâ
        if t[0] &gt; 0:
            noise = torch.randn_like(xt)
            x_prev = x_prev + torch.sqrt(beta_t) * noise

        return x_prev

    def generate(self, batch_size, input_dim):
        &quot;&quot;&quot;
        „Éá„Éº„Çø„ÇíÁîüÊàê

        Args:
            batch_size: „Éê„ÉÉ„ÉÅ„Çµ„Ç§„Ç∫
            input_dim: „Éá„Éº„ÇøÊ¨°ÂÖÉ
        Returns:
            x0: ÁîüÊàê„Åï„Çå„Åü„Éá„Éº„Çø
        &quot;&quot;&quot;
        # Á¥îÁ≤ã„Éé„Ç§„Ç∫„Åã„ÇâÈñãÂßã
        xt = torch.randn(batch_size, input_dim)

        # ÈÄÜ„Éó„É≠„Çª„Çπ„ÇíÂÆüË°å
        for t in reversed(range(self.num_timesteps)):
            t_batch = torch.full((batch_size,), t, dtype=torch.long)
            xt = self.reverse_process(xt, t_batch)

        return xt

# ‰ΩøÁî®‰æã: ÂàÜÂ≠êË®òËø∞Â≠ê„ÅÆÁîüÊàê
input_dim = 128  # Ë®òËø∞Â≠ê„ÅÆÊ¨°ÂÖÉ
diffusion_model = SimpleDiffusionModel(input_dim, hidden_dim=256, num_timesteps=100)

# Ë®ìÁ∑¥„Éá„Éº„ÇøÔºà„ÉÄ„Éü„ÉºÔºâ
x0 = torch.randn(64, input_dim)  # 64ÂàÜÂ≠ê„ÅÆË®òËø∞Â≠ê

# Forward processÔºà„Éé„Ç§„Ç∫ËøΩÂä†Ôºâ
t = torch.randint(0, 100, (64,))
xt, noise = diffusion_model.forward_process(x0, t)

# „Éé„Ç§„Ç∫‰∫àÊ∏¨
predicted_noise = diffusion_model.predict_noise(xt, t)

# ÊêçÂ§±
loss = F.mse_loss(predicted_noise, noise)
print(f&quot;Training loss: {loss.item():.4f}&quot;)

# ÁîüÊàê
generated_data = diffusion_model.generate(batch_size=10, input_dim=input_dim)
print(f&quot;Generated data shape: {generated_data.shape}&quot;)
</code></pre>
<hr />
<h2>4.3 Êù°‰ª∂‰ªò„ÅçÁîüÊàê</h2>
<h3>Ê¶ÇË¶Å</h3>
<p><strong>Êù°‰ª∂‰ªò„ÅçÁîüÊàê</strong>: ÁõÆÊ®ôÁâπÊÄß„ÇíÊù°‰ª∂„Å®„Åó„Å¶‰∏é„Åà„Å¶ÁîüÊàê</p>
<p><strong>‰æã</strong>:</p>
<pre><code class="language-python"># Êù°‰ª∂: „Éê„É≥„Éâ„ÇÆ„É£„ÉÉ„Éó = 2.0 eV„ÄÅÂΩ¢Êàê„Ç®„Éç„É´„ÇÆ„Éº &lt; 0
# ÁîüÊàê: Êù°‰ª∂„ÇíÊ∫Ä„Åü„ÅôÊùêÊñôÊßãÈÄ†
</code></pre>
<h3>ÂÆüË£Ö: Conditional Diffusion</h3>
<pre><code class="language-python">class ConditionalDiffusionModel(nn.Module):
    def __init__(self, input_dim, condition_dim, hidden_dim=256, num_timesteps=1000):
        super(ConditionalDiffusionModel, self).__init__()
        self.num_timesteps = num_timesteps

        # „Éé„Ç§„Ç∫„Çπ„Ç±„Ç∏„É•„Éº„É´
        self.betas = torch.linspace(1e-4, 0.02, num_timesteps)
        self.alphas = 1.0 - self.betas
        self.alphas_cumprod = torch.cumprod(self.alphas, dim=0)

        # Êù°‰ª∂„Ç®„É≥„Ç≥„Éº„ÉÄ
        self.condition_encoder = nn.Sequential(
            nn.Linear(condition_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, hidden_dim)
        )

        # „Éé„Ç§„Ç∫‰∫àÊ∏¨„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØÔºàÊù°‰ª∂‰ªò„ÅçÔºâ
        self.noise_predictor = nn.Sequential(
            nn.Linear(input_dim + hidden_dim + 1, hidden_dim),  # +1„ÅØ„Çø„Ç§„É†„Çπ„ÉÜ„ÉÉ„Éó
            nn.ReLU(),
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, input_dim)
        )

    def predict_noise(self, xt, t, condition):
        &quot;&quot;&quot;
        Êù°‰ª∂‰ªò„Åç„Éé„Ç§„Ç∫‰∫àÊ∏¨

        Args:
            xt: „Éé„Ç§„Ç∫„ÅåËøΩÂä†„Åï„Çå„Åü„Éá„Éº„Çø (batch_size, input_dim)
            t: „Çø„Ç§„É†„Çπ„ÉÜ„ÉÉ„Éó (batch_size,)
            condition: Êù°‰ª∂ÔºàÁõÆÊ®ôÁâπÊÄßÔºâ (batch_size, condition_dim)
        Returns:
            predicted_noise: ‰∫àÊ∏¨„Åï„Çå„Åü„Éé„Ç§„Ç∫
        &quot;&quot;&quot;
        # Êù°‰ª∂„ÇíÂüã„ÇÅËæº„Åø
        condition_embed = self.condition_encoder(condition)

        # „Çø„Ç§„É†„Çπ„ÉÜ„ÉÉ„Éó„ÇíÂüã„ÇÅËæº„Åø
        t_embed = t.float().unsqueeze(1) / self.num_timesteps

        # ÁµêÂêà
        x_with_condition = torch.cat([xt, condition_embed, t_embed], dim=1)

        # „Éé„Ç§„Ç∫‰∫àÊ∏¨
        predicted_noise = self.noise_predictor(x_with_condition)

        return predicted_noise

    def generate_conditional(self, condition, input_dim):
        &quot;&quot;&quot;
        Êù°‰ª∂‰ªò„Åç„Éá„Éº„ÇøÁîüÊàê

        Args:
            condition: Êù°‰ª∂ (batch_size, condition_dim)
            input_dim: „Éá„Éº„ÇøÊ¨°ÂÖÉ
        Returns:
            x0: ÁîüÊàê„Åï„Çå„Åü„Éá„Éº„Çø
        &quot;&quot;&quot;
        batch_size = condition.size(0)

        # Á¥îÁ≤ã„Éé„Ç§„Ç∫„Åã„ÇâÈñãÂßã
        xt = torch.randn(batch_size, input_dim)

        # ÈÄÜ„Éó„É≠„Çª„Çπ
        for t in reversed(range(self.num_timesteps)):
            t_batch = torch.full((batch_size,), t, dtype=torch.long)

            # „Éé„Ç§„Ç∫‰∫àÊ∏¨
            predicted_noise = self.predict_noise(xt, t_batch, condition)

            # „Éë„É©„É°„Éº„Çø
            alpha_t = self.alphas[t]
            alpha_t_cumprod = self.alphas_cumprod[t]
            beta_t = self.betas[t]

            # Ââç„ÅÆ„Çπ„ÉÜ„ÉÉ„Éó„ÇíË®àÁÆó
            xt = (1 / torch.sqrt(alpha_t)) * (
                xt - (beta_t / torch.sqrt(1 - alpha_t_cumprod)) * predicted_noise
            )

            # „Éé„Ç§„Ç∫„ÇíËøΩÂä†Ôºàt &gt; 0„ÅÆÂ†¥ÂêàÔºâ
            if t &gt; 0:
                noise = torch.randn_like(xt)
                xt = xt + torch.sqrt(beta_t) * noise

        return xt

# ‰ΩøÁî®‰æã
input_dim = 128
condition_dim = 3  # „Éê„É≥„Éâ„ÇÆ„É£„ÉÉ„Éó„ÄÅÂΩ¢Êàê„Ç®„Éç„É´„ÇÆ„Éº„ÄÅÁ£ÅÊ∞ó„É¢„Éº„É°„É≥„Éà

conditional_model = ConditionalDiffusionModel(input_dim, condition_dim, hidden_dim=256, num_timesteps=100)

# ÁõÆÊ®ôÁâπÊÄß
target_properties = torch.tensor([
    [2.0, -0.5, 0.0],  # „Éê„É≥„Éâ„ÇÆ„É£„ÉÉ„Éó2.0eV„ÄÅÂΩ¢Êàê„Ç®„Éç„É´„ÇÆ„Éº-0.5eV„ÄÅÈùûÁ£ÅÊÄß
    [3.5, -1.0, 2.0],  # „Éê„É≥„Éâ„ÇÆ„É£„ÉÉ„Éó3.5eV„ÄÅÂΩ¢Êàê„Ç®„Éç„É´„ÇÆ„Éº-1.0eV„ÄÅÁ£ÅÊÄß
])

# Êù°‰ª∂‰ªò„ÅçÁîüÊàê
generated_materials = conditional_model.generate_conditional(target_properties, input_dim)
print(f&quot;Generated materials shape: {generated_materials.shape}&quot;)  # (2, 128)
</code></pre>
<hr />
<h2>4.4 ÂàÜÂ≠êÁîüÊàê: SMILESÁîüÊàê</h2>
<h3>Ê¶ÇË¶Å</h3>
<p><strong>SMILESÔºàSimplified Molecular Input Line Entry SystemÔºâ</strong>: ÂàÜÂ≠ê„ÇíÊñáÂ≠óÂàó„ÅßË°®Áèæ</p>
<p><strong>‰æã</strong>:
- „Ç®„Çø„Éé„Éº„É´: <code>CCO</code>
- „Éô„É≥„Çº„É≥: <code>c1ccccc1</code>
- „Ç¢„Çπ„Éî„É™„É≥: <code>CC(=O)Oc1ccccc1C(=O)O</code></p>
<h3>Transformer-based SMILESÁîüÊàê</h3>
<pre><code class="language-python">from transformers import GPT2Config, GPT2LMHeadModel, GPT2Tokenizer

class SMILESGenerator(nn.Module):
    def __init__(self, vocab_size=1000, d_model=512, num_layers=6):
        super(SMILESGenerator, self).__init__()

        # GPT-2 config
        config = GPT2Config(
            vocab_size=vocab_size,
            n_positions=512,
            n_embd=d_model,
            n_layer=num_layers,
            n_head=8
        )

        self.gpt = GPT2LMHeadModel(config)

    def forward(self, input_ids, labels=None):
        &quot;&quot;&quot;
        Args:
            input_ids: (batch_size, seq_len)
            labels: (batch_size, seq_len) Ê¨°„Éà„Éº„ÇØ„É≥‰∫àÊ∏¨„ÅÆ„Çø„Éº„Ç≤„ÉÉ„Éà
        &quot;&quot;&quot;
        outputs = self.gpt(input_ids, labels=labels)
        return outputs

    def generate_smiles(self, start_token_id, max_length=100, temperature=1.0):
        &quot;&quot;&quot;
        SMILESÊñáÂ≠óÂàó„ÇíÁîüÊàê

        Args:
            start_token_id: ÈñãÂßã„Éà„Éº„ÇØ„É≥ID
            max_length: ÊúÄÂ§ßÈï∑
            temperature: „Çµ„É≥„Éó„É™„É≥„Ç∞Ê∏©Â∫¶ÔºàÈ´ò„ÅÑ„Åª„Å©„É©„É≥„ÉÄ„É†Ôºâ
        Returns:
            generated_ids: ÁîüÊàê„Åï„Çå„Åü„Éà„Éº„ÇØ„É≥ID
        &quot;&quot;&quot;
        generated = [start_token_id]

        for _ in range(max_length):
            input_ids = torch.tensor([generated])
            outputs = self.gpt(input_ids)
            logits = outputs.logits[:, -1, :] / temperature

            # „Çµ„É≥„Éó„É™„É≥„Ç∞
            probs = F.softmax(logits, dim=-1)
            next_token = torch.multinomial(probs, num_samples=1).item()

            generated.append(next_token)

            # ÁµÇ‰∫Ü„Éà„Éº„ÇØ„É≥„Å™„ÇâÂÅúÊ≠¢
            if next_token == 2:  # [EOS]
                break

        return generated

# Êù°‰ª∂‰ªò„ÅçSMILESÁîüÊàê
class ConditionalSMILESGenerator(nn.Module):
    def __init__(self, vocab_size=1000, condition_dim=10, d_model=512):
        super(ConditionalSMILESGenerator, self).__init__()

        # Êù°‰ª∂„Ç®„É≥„Ç≥„Éº„ÉÄ
        self.condition_encoder = nn.Linear(condition_dim, d_model)

        # GPT-2 config
        config = GPT2Config(
            vocab_size=vocab_size,
            n_positions=512,
            n_embd=d_model,
            n_layer=6,
            n_head=8
        )
        self.gpt = GPT2LMHeadModel(config)

    def forward(self, input_ids, condition):
        &quot;&quot;&quot;
        Args:
            input_ids: (batch_size, seq_len)
            condition: (batch_size, condition_dim) ÁõÆÊ®ôÁâπÊÄß
        &quot;&quot;&quot;
        batch_size, seq_len = input_ids.shape

        # Êù°‰ª∂„ÇíÂüã„ÇÅËæº„Åø
        condition_embed = self.condition_encoder(condition).unsqueeze(1)  # (batch, 1, d_model)

        # „Éà„Éº„ÇØ„É≥Âüã„ÇÅËæº„Åø
        token_embeddings = self.gpt.transformer.wte(input_ids)

        # Êù°‰ª∂„ÇíÂÖàÈ†≠„Å´ËøΩÂä†
        embeddings = torch.cat([condition_embed, token_embeddings], dim=1)

        # GPT-2 forwardÔºàÂüã„ÇÅËæº„Åø„Åã„ÇâÁõ¥Êé•Ôºâ
        outputs = self.gpt(inputs_embeds=embeddings)

        return outputs

# ‰ΩøÁî®‰æã: Ê∫∂Ëß£Â∫¶„ÅåÈ´ò„ÅÑÂàÜÂ≠ê„ÇíÁîüÊàê
condition_dim = 5  # logP, Ê∫∂Ëß£Â∫¶, ÂàÜÂ≠êÈáè, HB„Éâ„Éä„ÉºÊï∞, HB„Ç¢„ÇØ„Çª„Éó„Çø„ÉºÊï∞
target_properties = torch.tensor([[1.5, 10.0, 250.0, 2.0, 3.0]])  # È´òÊ∫∂Ëß£Â∫¶

conditional_smiles_gen = ConditionalSMILESGenerator(vocab_size=1000, condition_dim=condition_dim)
</code></pre>
<hr />
<h2>4.5 ÊùêÊñôÈÄÜË®≠Ë®à„ÅÆ„ÉØ„Éº„ÇØ„Éï„É≠„Éº</h2>
<h3>ÂÆåÂÖ®„Å™„ÉØ„Éº„ÇØ„Éï„É≠„Éº</h3>
<div class="mermaid">
graph TB
    A[ÁõÆÊ®ôÁâπÊÄßÂÆöÁæ©] --> B[Êù°‰ª∂‰ªò„ÅçÁîüÊàê„É¢„Éá„É´]
    B --> C[ÂÄôË£úÊùêÊñôÁîüÊàê]
    C --> D[ÁâπÊÄß‰∫àÊ∏¨„É¢„Éá„É´]
    D --> E{ÁõÆÊ®ôÈÅîÊàê?}
    E -->|No| F[ÂÄôË£úÈô§Â§ñ]
    F --> B
    E -->|Yes| G[ÂêàÊàêÂèØËÉΩÊÄß„ÉÅ„Çß„ÉÉ„ÇØ]
    G --> H{ÂêàÊàêÂèØËÉΩ?}
    H -->|No| F
    H -->|Yes| I[ÂÆâÂÆöÊÄßË®àÁÆó]
    I --> J{ÂÆâÂÆö?}
    J -->|No| F
    J -->|Yes| K[ÂÆüÈ®ìÂÄôË£ú„É™„Çπ„Éà]

    style A fill:#e1f5ff
    style K fill:#e1ffe1
</div>

<h3>ÂÆüË£Ö‰æã</h3>
<pre><code class="language-python">class MaterialsInverseDesign:
    def __init__(self, generator, predictor, synthesizability_checker):
        &quot;&quot;&quot;
        ÊùêÊñôÈÄÜË®≠Ë®à„Ç∑„Çπ„ÉÜ„É†

        Args:
            generator: Êù°‰ª∂‰ªò„ÅçÁîüÊàê„É¢„Éá„É´
            predictor: ÁâπÊÄß‰∫àÊ∏¨„É¢„Éá„É´
            synthesizability_checker: ÂêàÊàêÂèØËÉΩÊÄß„ÉÅ„Çß„ÉÉ„Ç´„Éº
        &quot;&quot;&quot;
        self.generator = generator
        self.predictor = predictor
        self.synthesizability_checker = synthesizability_checker

    def design_materials(self, target_properties, num_candidates=100, threshold=0.1):
        &quot;&quot;&quot;
        ÊùêÊñô„ÇíÈÄÜË®≠Ë®à

        Args:
            target_properties: ÁõÆÊ®ôÁâπÊÄß (condition_dim,)
            num_candidates: ÁîüÊàê„Åô„ÇãÂÄôË£úÊï∞
            threshold: Ë®±ÂÆπË™§Â∑Æ
        Returns:
            valid_materials: Ê§úË®º„ÇíÈÄöÈÅé„Åó„ÅüÊùêÊñô„É™„Çπ„Éà
        &quot;&quot;&quot;
        valid_materials = []

        for i in range(num_candidates):
            # 1. ÂÄôË£úÁîüÊàê
            candidate = self.generator.generate_conditional(
                target_properties.unsqueeze(0),
                input_dim=128
            )

            # 2. ÁâπÊÄß‰∫àÊ∏¨
            predicted_properties = self.predictor(candidate)

            # 3. ÁõÆÊ®ô„Å®„ÅÆÊØîËºÉ
            error = torch.abs(predicted_properties - target_properties).mean()
            if error &gt; threshold:
                continue

            # 4. ÂêàÊàêÂèØËÉΩÊÄß„ÉÅ„Çß„ÉÉ„ÇØ
            if not self.synthesizability_checker(candidate):
                continue

            # 5. ÂÆâÂÆöÊÄß„ÉÅ„Çß„ÉÉ„ÇØÔºàÁúÅÁï•Ôºâ

            # ÂêàÊ†º
            valid_materials.append({
                'structure': candidate,
                'predicted_properties': predicted_properties,
                'error': error.item()
            })

        # Ë™§Â∑Æ„Åß„ÇΩ„Éº„Éà
        valid_materials.sort(key=lambda x: x['error'])

        return valid_materials

# ‰ΩøÁî®‰æã
def simple_synthesizability_checker(structure):
    &quot;&quot;&quot;
    Á∞°ÊòìÂêàÊàêÂèØËÉΩÊÄß„ÉÅ„Çß„ÉÉ„ÇØÔºàÂÆüÈöõ„ÅØ„Çà„ÇäË§áÈõëÔºâ
    &quot;&quot;&quot;
    # „Åì„Åì„Åß„ÅØÂ∏∏„Å´True„ÇíËøî„ÅôÔºàÂÆüÈöõ„ÅØRetrosyn„Å™„Å©„Çí‰ΩøÁî®Ôºâ
    return True

# „Ç∑„Çπ„ÉÜ„É†ÊßãÁØâ
inverse_design_system = MaterialsInverseDesign(
    generator=conditional_model,
    predictor=lambda x: torch.randn(x.size(0), 3),  # „ÉÄ„Éü„Éº‰∫àÊ∏¨Âô®
    synthesizability_checker=simple_synthesizability_checker
)

# ÁõÆÊ®ôÁâπÊÄß
target = torch.tensor([2.5, -0.8, 0.0])  # „Éê„É≥„Éâ„ÇÆ„É£„ÉÉ„Éó„ÄÅÂΩ¢Êàê„Ç®„Éç„É´„ÇÆ„Éº„ÄÅÁ£ÅÊ∞ó„É¢„Éº„É°„É≥„Éà

# ÈÄÜË®≠Ë®àÂÆüË°å
designed_materials = inverse_design_system.design_materials(target, num_candidates=50)
print(f&quot;Found {len(designed_materials)} valid materials&quot;)

# ‰∏ä‰Ωç3„Å§„ÇíË°®Á§∫
for i, material in enumerate(designed_materials[:3]):
    print(f&quot;\nMaterial {i+1}:&quot;)
    print(f&quot;  Predicted properties: {material['predicted_properties']}&quot;)
    print(f&quot;  Error: {material['error']:.4f}&quot;)
</code></pre>
<hr />
<h2>4.6 Áî£Ê•≠ÂøúÁî®„Å®„Ç≠„É£„É™„Ç¢</h2>
<h3>ÂÆü‰∏ñÁïå„ÅÆÊàêÂäü‰∫ã‰æã</h3>
<h4>1. ÂâµËñ¨: Êñ∞Ë¶èÊäóÁîüÁâ©Ë≥™„ÅÆÁô∫Ë¶ã</h4>
<p><strong>MIT (2020)</strong>:
- <strong>ÊâãÊ≥ï</strong>: Êã°Êï£„É¢„Éá„É´„ÅßÂàÜÂ≠êÁîüÊàê
- <strong>ÊàêÊûú</strong>: halicinÔºàÊñ∞Ë¶èÊäóÁîüÁâ©Ë≥™ÔºâÁô∫Ë¶ã
- <strong>„Ç§„É≥„Éë„ÇØ„Éà</strong>: ÂæìÊù•ÊâãÊ≥ï„Çà„Çä100ÂÄçÈ´òÈÄü</p>
<h4>2. ÈõªÊ±†ÊùêÊñô: È´ò„Ç®„Éç„É´„ÇÆ„ÉºÂØÜÂ∫¶ÈõªËß£Ë≥™</h4>
<p><strong>Stanford/Toyota (2022)</strong>:
- <strong>ÊâãÊ≥ï</strong>: Transformer + Âº∑ÂåñÂ≠¶Áøí
- <strong>ÊàêÊûú</strong>: „É™„ÉÅ„Ç¶„É†‰ºùÂ∞éÂ∫¶1.5ÂÄç„ÅÆÂõ∫‰ΩìÈõªËß£Ë≥™
- <strong>„Ç§„É≥„Éë„ÇØ„Éà</strong>: ÂÖ®Âõ∫‰ΩìÈõªÊ±†„ÅÆÂÆüÁî®ÂåñÂä†ÈÄü</p>
<h4>3. Ëß¶Â™í: CO‚ÇÇÈÇÑÂÖÉËß¶Â™í</h4>
<p><strong>CMU (2023)</strong>:
- <strong>ÊâãÊ≥ï</strong>: Êù°‰ª∂‰ªò„ÅçÁîüÊàê + DFTË®àÁÆó
- <strong>ÊàêÊûú</strong>: ÂäπÁéá10ÂÄç„ÅÆËß¶Â™íÁô∫Ë¶ã
- <strong>„Ç§„É≥„Éë„ÇØ„Éà</strong>: „Ç´„Éº„Éú„É≥„Éã„É•„Éº„Éà„É©„É´ÂÆüÁèæ„Å∏„ÅÆË≤¢ÁåÆ</p>
<h3>„Ç≠„É£„É™„Ç¢„Éë„Çπ</h3>
<p><strong>AIÊùêÊñôË®≠Ë®à„Ç®„É≥„Ç∏„Éã„Ç¢</strong>:
- <strong>ËÅ∑Á®Æ</strong>: Ë£ΩËñ¨„ÄÅÂåñÂ≠¶„ÄÅÊùêÊñô„É°„Éº„Ç´„Éº„ÅÆR&amp;D
- <strong>Âπ¥Âèé</strong>: 800-1500‰∏áÂÜÜÔºàÊó•Êú¨Ôºâ„ÄÅ$120k-$250kÔºàÁ±≥ÂõΩÔºâ
- <strong>ÂøÖË¶Å„Çπ„Ç≠„É´</strong>: Transformer„ÄÅÁîüÊàê„É¢„Éá„É´„ÄÅÊùêÊñôÁßëÂ≠¶</p>
<p><strong>Á†îÁ©∂ËÄÖÔºà„Ç¢„Ç´„Éá„Éü„Ç¢Ôºâ</strong>:
- <strong>ËÅ∑Á®Æ</strong>: Â§ßÂ≠¶„ÉªÁ†îÁ©∂Ê©üÈñ¢„ÅÆPI
- <strong>Á†îÁ©∂ÂàÜÈáé</strong>: AIÊùêÊñôÁßëÂ≠¶„ÄÅË®àÁÆóÊùêÊñôÁßëÂ≠¶
- <strong>Á´∂‰∫âÂäõ</strong>: Nature/ScienceÁ¥ö„ÅÆË´ñÊñá„ÅåÊ±Ç„ÇÅ„Çâ„Çå„Çã</p>
<p><strong>„Çπ„Çø„Éº„Éà„Ç¢„ÉÉ„ÉóÂâµÊ•≠</strong>:
- <strong>‰æã</strong>: Insilico MedicineÔºàÂâµËñ¨AIÔºâ„ÄÅCitrine InformaticsÔºàÊùêÊñôAIÔºâ
- <strong>Ë≥áÈáëË™øÈÅî</strong>: „Ç∑„É™„Éº„Ç∫A„ÄúC„ÄÅÊï∞ÂÑÑ„ÄúÊï∞ÂçÅÂÑÑÂÜÜ
- <strong>ÊàêÂäü‰æã</strong>: IPO„ÄÅÂ§ßÊâã‰ºÅÊ•≠„Å∏„ÅÆË≤∑Âèé</p>
<hr />
<h2>4.7 „Åæ„Å®„ÇÅ</h2>
<h3>ÈáçË¶Å„Éù„Ç§„É≥„Éà</h3>
<ol>
<li><strong>Êã°Êï£„É¢„Éá„É´</strong>: „Éé„Ç§„Ç∫„Åã„ÇâÈ´òÂìÅË≥™„Éá„Éº„Çø„ÇíÁîüÊàê</li>
<li><strong>Êù°‰ª∂‰ªò„ÅçÁîüÊàê</strong>: ÁõÆÊ®ôÁâπÊÄß„ÇíÊåáÂÆö„Åó„Å¶ÊùêÊñôË®≠Ë®à</li>
<li><strong>SMILESÁîüÊàê</strong>: Transformer„ÅßÂàÜÂ≠êÊßãÈÄ†„ÇíÁîüÊàê</li>
<li><strong>ÈÄÜË®≠Ë®à</strong>: ÁâπÊÄß„Åã„ÇâÊßãÈÄ†„Å∏„ÅÆÈÄÜÂêë„ÅçÊé¢Á¥¢</li>
<li><strong>Áî£Ê•≠ÂøúÁî®</strong>: ÂâµËñ¨„ÄÅÈõªÊ±†„ÄÅËß¶Â™í„ÅßÂÆüÁî®ÂåñÈÄ≤„ÇÄ</li>
</ol>
<h3>„Ç∑„É™„Éº„Ç∫„ÅÆ„Åæ„Å®„ÇÅ</h3>
<p><strong>Á¨¨1Á´†</strong>: TransformerÂü∫Á§é„ÄÅAttentionÊ©üÊßã
<strong>Á¨¨2Á´†</strong>: ÊùêÊñôÁâπÂåñ„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£ÔºàMatformer„ÄÅChemBERTaÔºâ
<strong>Á¨¨3Á´†</strong>: ‰∫ãÂâçÂ≠¶Áøí„É¢„Éá„É´„ÄÅËª¢ÁßªÂ≠¶Áøí
<strong>Á¨¨4Á´†</strong>: ÁîüÊàê„É¢„Éá„É´„ÄÅÈÄÜË®≠Ë®à</p>
<p><strong>Ê¨°„ÅÆ„Çπ„ÉÜ„ÉÉ„Éó</strong>:
1. ÂÆüË∑µ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÅßÁµåÈ®ì„ÇíÁ©ç„ÇÄ
2. ÊúÄÊñ∞Ë´ñÊñá„ÇíË™≠„Çì„ÅßÁü•Ë≠ò„ÇíÊõ¥Êñ∞
3. Kaggle„Ç≥„É≥„Éö„Å´ÂèÇÂä†„Åó„Å¶ÂÆüÂäõ„ÇíË©¶„Åô
4. „Ç≥„Éü„É•„Éã„ÉÜ„Ç£„Å´ÂèÇÂä†„Åó„Å¶ÊÉÖÂ†±‰∫§Êèõ</p>
<hr />
<h2>üìù ÊºîÁøíÂïèÈ°å</h2>
<h3>ÂïèÈ°å1: Ê¶ÇÂøµÁêÜËß£</h3>
<p>Êã°Êï£„É¢„Éá„É´„ÅåÂæìÊù•„ÅÆÁîüÊàê„É¢„Éá„É´ÔºàVAE„ÄÅGANÔºâ„Å®ÊØî„Åπ„Å¶ÂÑ™„Çå„Å¶„ÅÑ„ÇãÁÇπ„Çí3„Å§Êåô„Åí„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ</p>
<details>
<summary>Ëß£Á≠î‰æã</summary>

1. **Â≠¶Áøí„ÅÆÂÆâÂÆöÊÄß**: GAN„ÅÆ„Çà„ÅÜ„Å™mode collapse„ÅåËµ∑„Åì„Çä„Å´„Åè„ÅÑ
2. **„Çµ„É≥„Éó„É´ÂìÅË≥™**: È´òÂìÅË≥™„ÅßÂ§öÊßò„Å™„Çµ„É≥„Éó„É´„ÇíÁîüÊàêÂèØËÉΩ
3. **ÊüîËªü„Å™Êù°‰ª∂‰ªò„Åë**: Êßò„ÄÖ„Å™Êù°‰ª∂ÔºàÁâπÊÄß„ÄÅÂà∂Á¥ÑÔºâ„ÇíÂÆπÊòì„Å´ÁµÑ„ÅøËæº„ÇÅ„Çã

ËøΩÂä†:
- **Ëß£ÈáàÊÄß**: ÁîüÊàê„Éó„É≠„Çª„Çπ„ÅåÊÆµÈöéÁöÑ„ÅßÁêÜËß£„Åó„ÇÑ„Åô„ÅÑ
- **„Çπ„Ç±„Éº„É©„Éì„É™„ÉÜ„Ç£**: Â§ßË¶èÊ®°„Éá„Éº„Çø„Åß„ÇÇÂäπÁéáÁöÑ„Å´Â≠¶Áøí
</details>

<h3>ÂïèÈ°å2: ÂÆüË£Ö</h3>
<p>Êù°‰ª∂‰ªò„ÅçÁîüÊàê„Åß„ÄÅË§áÊï∞„ÅÆÁõÆÊ®ôÁâπÊÄßÔºà„Éê„É≥„Éâ„ÇÆ„É£„ÉÉ„Éó„ÄÅÂΩ¢Êàê„Ç®„Éç„É´„ÇÆ„ÉºÔºâ„ÇíÂêåÊôÇ„Å´Ê∫Ä„Åü„ÅôÊùêÊñô„ÇíÁîüÊàê„Åô„Çã„Ç≥„Éº„Éâ„ÇíÊõ∏„ÅÑ„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ</p>
<pre><code class="language-python">def multi_objective_generation(generator, target_bandgap, target_formation_energy, num_samples=10):
    &quot;&quot;&quot;
    Â§öÁõÆÁöÑÊúÄÈÅ©Âåñ„ÅßÊùêÊñô„ÇíÁîüÊàê

    Args:
        generator: Êù°‰ª∂‰ªò„ÅçÁîüÊàê„É¢„Éá„É´
        target_bandgap: ÁõÆÊ®ô„Éê„É≥„Éâ„ÇÆ„É£„ÉÉ„ÉóÔºàeVÔºâ
        target_formation_energy: ÁõÆÊ®ôÂΩ¢Êàê„Ç®„Éç„É´„ÇÆ„ÉºÔºàeV/atomÔºâ
        num_samples: ÁîüÊàêÊï∞
    Returns:
        generated_materials: ÁîüÊàê„Åï„Çå„ÅüÊùêÊñô„ÅÆ„É™„Çπ„Éà
    &quot;&quot;&quot;
    # „Åì„Åì„Å´ÂÆüË£Ö
    pass
</code></pre>
<details>
<summary>Ëß£Á≠î‰æã</summary>


<pre><code class="language-python">def multi_objective_generation(generator, target_bandgap, target_formation_energy, num_samples=10):
    # Êù°‰ª∂„Çí‰ΩúÊàê
    condition = torch.tensor([[target_bandgap, target_formation_energy]])
    condition = condition.repeat(num_samples, 1)

    # ÁîüÊàê
    generated_materials = generator.generate_conditional(condition, input_dim=128)

    return generated_materials

# ‰ΩøÁî®‰æã
target_bg = 2.0  # 2.0 eV
target_fe = -0.5  # -0.5 eV/atom

materials = multi_objective_generation(conditional_model, target_bg, target_fe, num_samples=20)
print(f&quot;Generated {materials.shape[0]} materials&quot;)
</code></pre>

</details>

<h3>ÂïèÈ°å3: ÂøúÁî®</h3>
<p>ÊùêÊñôÈÄÜË®≠Ë®à„Å´„Åä„ÅÑ„Å¶„ÄÅÁîüÊàê„Åï„Çå„ÅüÂÄôË£úÊùêÊñô„ÇíË©ï‰æ°„Åô„ÇãÈöõ„ÅÆÈáçË¶Å„Å™Âü∫Ê∫ñ„Çí5„Å§Êåô„Åí„ÄÅ„Åù„Çå„Åû„Çå„ÇíË™¨Êòé„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ</p>
<details>
<summary>Ëß£Á≠î‰æã</summary>

1. **ÁõÆÊ®ôÁâπÊÄß„ÅÆÈÅîÊàêÂ∫¶**:
   - ‰∫àÊ∏¨ÁâπÊÄß„ÅåÁõÆÊ®ôÂÄ§„Å´„Å©„Çå„Å†„ÅëËøë„ÅÑ„Åã
   - Ë§áÊï∞ÁâπÊÄß„ÅÆÂ†¥Âêà„ÄÅ„Éë„É¨„Éº„ÉàÊúÄÈÅ©ÊÄß

2. **ÂêàÊàêÂèØËÉΩÊÄß**:
   - Êó¢Áü•„ÅÆÂêàÊàêÊâãÊ≥ï„Åß‰ΩúË£ΩÂèØËÉΩ„Åã
   - ÂâçÈßÜ‰Ωì„ÅÆÂÖ•ÊâãÂèØËÉΩÊÄß
   - ÂêàÊàêÊù°‰ª∂ÔºàÊ∏©Â∫¶„ÄÅÂúßÂäõÔºâ„ÅÆÂÆüÁèæÂèØËÉΩÊÄß

3. **ÁÜ±ÂäõÂ≠¶ÁöÑÂÆâÂÆöÊÄß**:
   - ÂΩ¢Êàê„Ç®„Éç„É´„ÇÆ„Éº„ÅåË≤†ÔºàÂÆâÂÆöÁõ∏Ôºâ
   - ‰ªñ„ÅÆÁµêÊô∂ÊßãÈÄ†„Å®ÊØîËºÉ„Åó„Å¶ÊúÄÂÆâÂÆö
   - ÂàÜËß£ÂèçÂøú„Å´ÂØæ„Åô„ÇãÂÆâÂÆöÊÄß

4. **ÂåñÂ≠¶ÁöÑÂ¶•ÂΩìÊÄß**:
   - ÂéüÂ≠ê‰æ°Ââá„ÇíÊ∫Ä„Åü„Åô
   - ÁµêÂêàË∑ùÈõ¢„ÉªËßíÂ∫¶„ÅåÂ¶•ÂΩì
   - Êó¢Áü•„ÅÆÂåñÂ≠¶Á≥ª„Å®Êï¥Âêà

5. **„Ç≥„Çπ„Éà„Å®Áí∞Â¢ÉË≤†Ëç∑**:
   - ÊßãÊàêÂÖÉÁ¥†„ÅÆ‰æ°Ê†º„Å®ÂüãËîµÈáè
   - ÊúâÂÆ≥ÂÖÉÁ¥†ÔºàCd„ÄÅPbÁ≠âÔºâ„ÅÆ‰ΩøÁî®
   - „É™„Çµ„Ç§„ÇØ„É´ÂèØËÉΩÊÄß
</details>

<hr />
<h2>üéì „Ç∑„É™„Éº„Ç∫ÂÆå‰∫Ü„Åä„ÇÅ„Åß„Å®„ÅÜ„Åî„Åñ„ÅÑ„Åæ„ÅôÔºÅ</h2>
<p>„Åì„ÅÆ„Ç∑„É™„Éº„Ç∫„ÇíÂÆå‰∫Ü„Åó„Åü„ÅÇ„Å™„Åü„ÅØ„ÄÅTransformer„Å®ÁîüÊàê„É¢„Éá„É´„ÅÆÂü∫Á§é„Åã„ÇâÂøúÁî®„Åæ„Åß„ÄÅÊùêÊñôÁßëÂ≠¶„Åß„ÅÆÊ¥ªÁî®ÊñπÊ≥ï„ÇíÁøíÂæó„Åó„Åæ„Åó„Åü„ÄÇ</p>
<h3>Ê¨°„ÅÆ„Çπ„ÉÜ„ÉÉ„Éó</h3>
<ol>
<li>
<p><strong>ÂÆüË∑µ„Éó„É≠„Ç∏„Çß„ÇØ„Éà</strong>:
   - Materials Project„Éá„Éº„Çø„ÅßÊùêÊñôÁâπÊÄß‰∫àÊ∏¨
   - QM9„Éá„Éº„Çø„Çª„ÉÉ„Éà„ÅßÂàÜÂ≠êÁîüÊàê
   - Áã¨Ëá™„Éá„Éº„Çø„Åß„Éï„Ç°„Ç§„É≥„ÉÅ„É•„Éº„Éã„É≥„Ç∞</p>
</li>
<li>
<p><strong>Ë´ñÊñáÂÆüË£Ö</strong>:
   - MatformerË´ñÊñá„ÇíË™≠„Çì„ÅßÂÆüË£Ö
   - ÊúÄÊñ∞„ÅÆÁîüÊàê„É¢„Éá„É´Ë´ñÊñá„Å´ÊåëÊà¶</p>
</li>
<li>
<p><strong>„Ç≥„É≥„Éö„ÉÜ„Ç£„Éº„Ç∑„Éß„É≥</strong>:
   - Open Catalyst Challenge
   - Kaggle„ÅÆÂàÜÂ≠ê‰∫àÊ∏¨„Ç≥„É≥„Éö</p>
</li>
<li>
<p><strong>„Ç≥„Éü„É•„Éã„ÉÜ„Ç£ÂèÇÂä†</strong>:
   - Hugging Face Forum
   - Materials Project Community
   - ÊùêÊñôÁßëÂ≠¶„ÅÆ„Ç´„É≥„Éï„Ç°„É¨„É≥„ÇπÔºàMRS„ÄÅAPSÔºâ</p>
</li>
</ol>
<hr />
<h2>üéØ ÊùêÊñôÁâπÂåñTransformer„ÅÆË©≥Á¥∞</h2>
<h3>ChemBERTa: ÂåñÂ≠¶BERT</h3>
<pre><code class="language-python">from transformers import RobertaTokenizer, RobertaModel, RobertaConfig

class ChemBERTa(nn.Module):
    &quot;&quot;&quot;
    ChemBERTa: RoBERTa trained on 10M SMILES strings

    ÁâπÂæ¥:
    - PubChem, ZINC, ChEMBL„Åß‰∫ãÂâçÂ≠¶Áøí
    - SMILESÂ∞ÇÁî®„Éà„Éº„ÇØ„Éä„Ç§„Ç∂„Éº
    - ÂàÜÂ≠êÁâπÊÄß‰∫àÊ∏¨„Å´ÊúÄÈÅ©Âåñ
    &quot;&quot;&quot;

    def __init__(self, pretrained_model=&quot;seyonec/ChemBERTa-zinc-base-v1&quot;):
        super().__init__()
        self.tokenizer = RobertaTokenizer.from_pretrained(pretrained_model)
        self.model = RobertaModel.from_pretrained(pretrained_model)

    def forward(self, smiles_list):
        &quot;&quot;&quot;
        Args:
            smiles_list: List of SMILES strings

        Returns:
            embeddings: (batch_size, 768) molecular embeddings
        &quot;&quot;&quot;
        # Tokenize
        encoded = self.tokenizer(
            smiles_list,
            padding=True,
            truncation=True,
            max_length=512,
            return_tensors='pt'
        )

        # Forward
        outputs = self.model(**encoded)

        # [CLS] token embedding
        embeddings = outputs.last_hidden_state[:, 0, :]

        return embeddings

# ‰ΩøÁî®‰æã
chemberta = ChemBERTa()

smiles_list = [
    &quot;CC(C)Cc1ccc(cc1)C(C)C(=O)O&quot;,  # „Ç§„Éñ„Éó„É≠„Éï„Çß„É≥
    &quot;CN1C=NC2=C1C(=O)N(C(=O)N2C)C&quot;  # „Ç´„Éï„Çß„Ç§„É≥
]

embeddings = chemberta(smiles_list)
print(f&quot;Molecular embeddings: {embeddings.shape}&quot;)  # (2, 768)
</code></pre>
<h3>MatBERT: ÊùêÊñôÁµÑÊàêBERT</h3>
<pre><code class="language-python">class MatBERT(nn.Module):
    &quot;&quot;&quot;
    MatBERT: BERT for materials composition

    ‰∫ãÂâçÂ≠¶Áøí:
    - Materials Project (500k+ compositions)
    - OQMD, AFLOW datasets
    - Masked composition prediction
    &quot;&quot;&quot;

    def __init__(self, vocab_size=120, d_model=768, num_layers=12):
        super().__init__()

        config = BertConfig(
            vocab_size=vocab_size,
            hidden_size=d_model,
            num_hidden_layers=num_layers,
            num_attention_heads=12,
            intermediate_size=3072,
            max_position_embeddings=50  # ÊùêÊñô„ÅÆÊúÄÂ§ßÂéüÂ≠êÊï∞
        )

        self.bert = BertModel(config)

    def forward(self, composition_ids, attention_mask=None):
        &quot;&quot;&quot;
        Args:
            composition_ids: (batch, seq_len) ÂéüÂ≠êÁï™Âè∑„Ç∑„Éº„Ç±„É≥„Çπ
                             ‰æã: [CLS] Fe Fe O O O [SEP]

        Returns:
            outputs: BERT outputs
        &quot;&quot;&quot;
        outputs = self.bert(
            input_ids=composition_ids,
            attention_mask=attention_mask
        )

        return outputs

# „Éï„Ç°„Ç§„É≥„ÉÅ„É•„Éº„Éã„É≥„Ç∞‰æã: „Éê„É≥„Éâ„ÇÆ„É£„ÉÉ„Éó‰∫àÊ∏¨
class MatBERTForBandgap(nn.Module):
    def __init__(self, matbert):
        super().__init__()
        self.matbert = matbert

        # Prediction head
        self.regressor = nn.Sequential(
            nn.Linear(768, 256),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(256, 1)
        )

    def forward(self, composition_ids, attention_mask=None):
        outputs = self.matbert(composition_ids, attention_mask)
        cls_embedding = outputs.pooler_output

        bandgap = self.regressor(cls_embedding)
        return bandgap
</code></pre>
<h3>MatGPT: ÊùêÊñôÁîüÊàêGPT</h3>
<pre><code class="language-python">from transformers import GPT2LMHeadModel, GPT2Config

class MatGPT(nn.Module):
    &quot;&quot;&quot;
    MatGPT: GPT for materials composition generation

    ÂøúÁî®:
    - Êñ∞Ë¶èÊùêÊñôÁµÑÊàê„ÅÆÁîüÊàê
    - Êù°‰ª∂‰ªò„ÅçÁîüÊàêÔºàÁõÆÊ®ôÁâπÊÄß ‚Üí ÁµÑÊàêÔºâ
    - ÊùêÊñôË®≠Ë®à„ÅÆËá™ÂãïÂåñ
    &quot;&quot;&quot;

    def __init__(self, vocab_size=120, d_model=768, num_layers=12):
        super().__init__()

        config = GPT2Config(
            vocab_size=vocab_size,
            n_positions=50,
            n_embd=d_model,
            n_layer=num_layers,
            n_head=12
        )

        self.gpt = GPT2LMHeadModel(config)

    def generate_composition(self, start_tokens, max_length=30, temperature=1.0, top_k=50):
        &quot;&quot;&quot;
        ÁµÑÊàêÂºèÁîüÊàê

        Args:
            start_tokens: (1, start_len) ÈñãÂßã„Éà„Éº„ÇØ„É≥
                         ‰æã: [CLS] Li
            max_length: ÊúÄÂ§ßÁîüÊàêÈï∑
            temperature: „Çµ„É≥„Éó„É™„É≥„Ç∞Ê∏©Â∫¶ (‰Ωé„ÅÑ‚ÜíÁ¢∫ÂÆöÁöÑ„ÄÅÈ´ò„ÅÑ‚Üí„É©„É≥„ÉÄ„É†)
            top_k: Top-k sampling

        Returns:
            generated: (1, gen_len) ÁîüÊàê„Åï„Çå„ÅüÁµÑÊàêÂºè
        &quot;&quot;&quot;
        self.eval()

        with torch.no_grad():
            generated = self.gpt.generate(
                start_tokens,
                max_length=max_length,
                temperature=temperature,
                top_k=top_k,
                do_sample=True,
                pad_token_id=0
            )

        return generated

# Êù°‰ª∂‰ªò„ÅçÁîüÊàê
class ConditionalMatGPT(nn.Module):
    &quot;&quot;&quot;
    Êù°‰ª∂‰ªò„ÅçÊùêÊñôÁîüÊàê

    Êù°‰ª∂: „Éê„É≥„Éâ„ÇÆ„É£„ÉÉ„Éó„ÄÅÂΩ¢Êàê„Ç®„Éç„É´„ÇÆ„Éº„ÄÅÁ£ÅÊ∞ó„É¢„Éº„É°„É≥„Éà
    &quot;&quot;&quot;

    def __init__(self, matgpt, condition_dim=3):
        super().__init__()
        self.matgpt = matgpt

        # Êù°‰ª∂„Ç®„É≥„Ç≥„Éº„ÉÄ
        self.condition_encoder = nn.Sequential(
            nn.Linear(condition_dim, 768),
            nn.ReLU(),
            nn.Linear(768, 768)
        )

    def forward(self, input_ids, conditions):
        &quot;&quot;&quot;
        Args:
            input_ids: (batch, seq_len)
            conditions: (batch, condition_dim) ÁõÆÊ®ôÁâπÊÄß

        Returns:
            logits: (batch, seq_len, vocab_size)
        &quot;&quot;&quot;
        # Êù°‰ª∂„ÇíÂüã„ÇÅËæº„Åø
        condition_embed = self.condition_encoder(conditions)
        condition_embed = condition_embed.unsqueeze(1)  # (batch, 1, 768)

        # ÂÖ•ÂäõÂüã„ÇÅËæº„Åø
        input_embeddings = self.matgpt.gpt.transformer.wte(input_ids)

        # Êù°‰ª∂„ÇíÂÖàÈ†≠„Å´ËøΩÂä†
        embeddings = torch.cat([condition_embed, input_embeddings], dim=1)

        # GPT forward
        outputs = self.matgpt.gpt(inputs_embeds=embeddings)

        return outputs.logits

# ‰ΩøÁî®‰æã
matgpt = MatGPT(vocab_size=120)
cond_matgpt = ConditionalMatGPT(matgpt, condition_dim=3)

# ÁõÆÊ®ô: „Éê„É≥„Éâ„ÇÆ„É£„ÉÉ„Éó 2.5 eV„ÄÅÂΩ¢Êàê„Ç®„Éç„É´„ÇÆ„Éº -1.0 eV„ÄÅÈùûÁ£ÅÊÄß
target_conditions = torch.tensor([[2.5, -1.0, 0.0]])

# ÁîüÊàêÈñãÂßã„Éà„Éº„ÇØ„É≥
start = torch.tensor([[101]])  # [CLS]

# ÁîüÊàê
with torch.no_grad():
    logits = cond_matgpt(start, target_conditions)
    # „Çµ„É≥„Éó„É™„É≥„Ç∞„ÅßÊ¨°„Éà„Éº„ÇØ„É≥„ÇíÁîüÊàê
    probs = torch.softmax(logits[:, -1, :], dim=-1)
    next_token = torch.multinomial(probs, num_samples=1)

print(f&quot;Next token: {next_token}&quot;)
</code></pre>
<hr />
<h2>üî¨ Ëª¢ÁßªÂ≠¶ÁøíÊà¶Áï•„ÅÆË©≥Á¥∞</h2>
<h3>Êà¶Áï•1: Full Fine-tuning</h3>
<pre><code class="language-python">def full_finetuning(pretrained_model, train_loader, val_loader):
    &quot;&quot;&quot;
    ÂÖ®„Éë„É©„É°„Éº„Çø„ÇíÊõ¥Êñ∞

    ÈÅ©Áî®Â†¥Èù¢:
    - „Çø„Éº„Ç≤„ÉÉ„Éà„Éá„Éº„Çø„ÅåÂçÅÂàÜÔºàÊï∞ÂçÉ„Çµ„É≥„Éó„É´‰ª•‰∏äÔºâ
    - „Éâ„É°„Ç§„É≥„ÅåÈ°û‰ºº
    - ÊúÄÈ´òÁ≤æÂ∫¶„ÇíÁõÆÊåá„ÅôÂ†¥Âêà
    &quot;&quot;&quot;
    model = pretrained_model

    # ÂÖ®„Éë„É©„É°„Éº„Çø„ÇíÊõ¥Êñ∞
    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)

    # Learning rate scheduler
    num_training_steps = len(train_loader) * epochs
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_training_steps)

    best_val_loss = float('inf')

    for epoch in range(epochs):
        model.train()
        for batch in train_loader:
            optimizer.zero_grad()

            outputs = model(**batch)
            loss = outputs.loss

            loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            optimizer.step()
            scheduler.step()

        # Validation
        model.eval()
        val_loss = evaluate(model, val_loader)

        if val_loss &lt; best_val_loss:
            best_val_loss = val_loss
            torch.save(model.state_dict(), 'best_full_finetuned.pt')

    return model
</code></pre>
<h3>Êà¶Áï•2: Adapter Tuning</h3>
<pre><code class="language-python">class AdapterLayer(nn.Module):
    &quot;&quot;&quot;
    Adapter: Â∞ë„Éë„É©„É°„Éº„Çø„ÅßÈ´òÊÄßËÉΩ

    „Ç¢„Ç§„Éá„Ç¢: Transformer„ÅÆÂêÑÂ±§„Å´AdapterÔºàÂ∞è„Åï„Å™„Éú„Éà„É´„Éç„ÉÉ„ÇØNNÔºâ„ÇíÊåøÂÖ•
    &quot;&quot;&quot;

    def __init__(self, d_model, adapter_size=64):
        super().__init__()

        self.adapter = nn.Sequential(
            nn.Linear(d_model, adapter_size),  # Down-project
            nn.ReLU(),
            nn.Linear(adapter_size, d_model)   # Up-project
        )

        # Residual connection
        self.layer_norm = nn.LayerNorm(d_model)

    def forward(self, x):
        &quot;&quot;&quot;
        Args:
            x: (batch, seq_len, d_model)

        Returns:
            x + adapter(x): Residual connection
        &quot;&quot;&quot;
        residual = x
        x = self.layer_norm(x)
        x = self.adapter(x)
        return residual + x

class MatBERTWithAdapters(nn.Module):
    &quot;&quot;&quot;
    MatBERT + Adapters

    Âà©ÁÇπ:
    - Êõ¥Êñ∞„Éë„É©„É°„Éº„ÇøÊï∞: 1-2% of full model
    - ÊÄßËÉΩ: Full fine-tuning „ÅÆ 95-98%
    - Ë§áÊï∞„Çø„Çπ„ÇØ„ÅßAdapterÂàá„ÇäÊõø„ÅàÂèØËÉΩ
    &quot;&quot;&quot;

    def __init__(self, pretrained_matbert, adapter_size=64):
        super().__init__()
        self.matbert = pretrained_matbert

        # MatBERT„ÅÆ„Éë„É©„É°„Éº„Çø„ÇíÂõ∫ÂÆö
        for param in self.matbert.parameters():
            param.requires_grad = False

        # ÂêÑTransformer„É¨„Ç§„É§„Éº„Å´adapter„ÇíËøΩÂä†
        self.adapters = nn.ModuleList([
            AdapterLayer(768, adapter_size)
            for _ in range(12)  # 12 layers
        ])

    def forward(self, input_ids, attention_mask=None):
        # MatBERT forward (frozen)
        outputs = self.matbert(input_ids, attention_mask, output_hidden_states=True)

        hidden_states = outputs.hidden_states

        # ÂêÑÂ±§„Å´Adapter„ÇíÈÅ©Áî®
        for i, adapter in enumerate(self.adapters):
            hidden_states[i+1] = adapter(hidden_states[i+1])

        # ÊúÄÁµÇÂ±§„ÅÆÂá∫Âäõ
        final_hidden = hidden_states[-1]

        return final_hidden

# ‰ΩøÁî®‰æã
pretrained = MatBERT(vocab_size=120)
model_with_adapters = MatBERTWithAdapters(pretrained, adapter_size=64)

# Adapter„ÅÆ„ÅøË®ìÁ∑¥
trainable_params = sum(p.numel() for p in model_with_adapters.adapters.parameters())
total_params = sum(p.numel() for p in model_with_adapters.parameters())

print(f&quot;Trainable params: {trainable_params} ({trainable_params/total_params*100:.2f}%)&quot;)
</code></pre>
<h3>Êà¶Áï•3: LoRA (Low-Rank Adaptation)</h3>
<pre><code class="language-python">class LoRALayer(nn.Module):
    &quot;&quot;&quot;
    LoRA: Low-Rank Adaptation of Large Language Models

    „Ç¢„Ç§„Éá„Ç¢: Èáç„ÅøË°åÂàó„ÅÆÊõ¥Êñ∞„Çí‰Ωé„É©„É≥„ÇØÂàÜËß£
    W_new = W_frozen + BA (B: m√ór, A: r√ón, r &lt;&lt; m,n)
    &quot;&quot;&quot;

    def __init__(self, in_features, out_features, rank=8):
        super().__init__()

        self.rank = rank

        # Low-rank matrices (trainable)
        self.lora_A = nn.Parameter(torch.randn(rank, in_features) / rank)
        self.lora_B = nn.Parameter(torch.zeros(out_features, rank))

    def forward(self, x, frozen_weight):
        &quot;&quot;&quot;
        Args:
            x: (batch, seq_len, in_features)
            frozen_weight: (out_features, in_features) Âõ∫ÂÆö„Åï„Çå„ÅüÈáç„Åø

        Returns:
            output: (batch, seq_len, out_features)
        &quot;&quot;&quot;
        # Frozen part
        output = torch.matmul(x, frozen_weight.T)

        # LoRA part
        lora_output = torch.matmul(x, self.lora_A.T)
        lora_output = torch.matmul(lora_output, self.lora_B.T)

        return output + lora_output

class MatBERTWithLoRA(nn.Module):
    &quot;&quot;&quot;
    MatBERT + LoRA

    Âà©ÁÇπ:
    - Êõ¥Êñ∞„Éë„É©„É°„Éº„ÇøÊï∞: 0.1-1% of full model
    - ÊÄßËÉΩ: Full fine-tuning „Å®ÂêåÁ≠â
    - Êé®Ë´ñÊôÇ„Å´LoRA„Çí„Éû„Éº„Ç∏ÂèØËÉΩÔºàÈÄüÂ∫¶‰Ωé‰∏ã„Å™„ÅóÔºâ
    &quot;&quot;&quot;

    def __init__(self, pretrained_matbert, rank=8):
        super().__init__()
        self.matbert = pretrained_matbert

        # MatBERT„ÅÆ„Éë„É©„É°„Éº„Çø„ÇíÂõ∫ÂÆö
        for param in self.matbert.parameters():
            param.requires_grad = False

        # Attention QKV„Å´LoRA„ÇíËøΩÂä†
        self.lora_layers = nn.ModuleDict()
        for layer_idx in range(12):
            self.lora_layers[f'layer_{layer_idx}_q'] = LoRALayer(768, 768, rank)
            self.lora_layers[f'layer_{layer_idx}_v'] = LoRALayer(768, 768, rank)

    def forward(self, input_ids, attention_mask=None):
        # ÁúÅÁï•: LoRA„ÇíAttentionË®àÁÆó„Å´Áµ±Âêà
        pass

# ‰ΩøÁî®‰æã
model_with_lora = MatBERTWithLoRA(pretrained, rank=8)

trainable_params = sum(p.numel() for p in model_with_lora.lora_layers.parameters())
total_params = sum(p.numel() for p in model_with_lora.parameters())

print(f&quot;Trainable params: {trainable_params} ({trainable_params/total_params*100:.3f}%)&quot;)
</code></pre>
<hr />
<h2>üéì ÊùêÊñôÂêë„Åë‰∫ãÂâçÂ≠¶Áøí„ÅÆÂÆüË£Ö</h2>
<h3>‰∫ãÂâçÂ≠¶Áøí„Çø„Çπ„ÇØ1: Masked Atom Prediction</h3>
<pre><code class="language-python">def pretrain_masked_atom_prediction(model, dataloader, epochs=100):
    &quot;&quot;&quot;
    Masked Atom Prediction (MAP)

    „Çø„Çπ„ÇØ: „Éû„Çπ„ÇØ„Åï„Çå„ÅüÂéüÂ≠ê„Çí‰∫àÊ∏¨
    ‰æã: Fe [MASK] O ‚Üí Fe Fe O (Fe2O3)
    &quot;&quot;&quot;
    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)
    criterion = nn.CrossEntropyLoss(ignore_index=0)  # Pad token

    model.train()

    for epoch in range(epochs):
        total_loss = 0

        for batch in dataloader:
            composition_ids = batch['composition_ids']  # (batch, seq_len)

            # 15%„ÅÆÂéüÂ≠ê„Çí„Éû„Çπ„ÇØ
            mask_prob = 0.15
            masked_composition, labels = mask_atoms(composition_ids, mask_prob)

            # Forward
            outputs = model(masked_composition)
            logits = outputs.logits  # (batch, seq_len, vocab_size)

            # Loss
            loss = criterion(logits.view(-1, vocab_size), labels.view(-1))

            # Backward
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            total_loss += loss.item()

        avg_loss = total_loss / len(dataloader)
        print(f&quot;Epoch {epoch+1}, MAP Loss: {avg_loss:.4f}&quot;)

    return model

def mask_atoms(composition_ids, mask_prob=0.15):
    &quot;&quot;&quot;
    ÂéüÂ≠ê„Çí„Éû„Çπ„ÇØ

    Êà¶Áï•:
    - 80%: [MASK]„Å´ÁΩÆ„ÅçÊèõ„Åà
    - 10%: „É©„É≥„ÉÄ„É†„Å™ÂéüÂ≠ê„Å´ÁΩÆ„ÅçÊèõ„Åà
    - 10%: Â§âÊõ¥„Å™„Åó
    &quot;&quot;&quot;
    labels = composition_ids.clone()
    masked_composition = composition_ids.clone()

    # „Éû„Çπ„ÇØÂØæË±°„ÇíÈÅ∏Êäû
    mask = torch.rand(composition_ids.shape) &lt; mask_prob
    mask[:, 0] = False  # [CLS]„ÅØÈô§Â§ñ
    mask[:, -1] = False  # [SEP]„ÅØÈô§Â§ñ

    # 80%„Çí[MASK]„Å´
    mask_token_mask = torch.rand(composition_ids.shape) &lt; 0.8
    masked_composition[mask &amp; mask_token_mask] = MASK_TOKEN_ID

    # 10%„Çí„É©„É≥„ÉÄ„É†ÂéüÂ≠ê„Å´
    random_mask = torch.rand(composition_ids.shape) &lt; 0.1
    random_atoms = torch.randint(1, 119, composition_ids.shape)
    masked_composition[mask &amp; random_mask] = random_atoms[mask &amp; random_mask]

    # 10%„ÅØ„Åù„ÅÆ„Åæ„Åæ

    # „Éû„Çπ„ÇØ„Åï„Çå„Å¶„ÅÑ„Å™„ÅÑ‰ΩçÁΩÆ„ÅÆ„É©„Éô„É´„ÅØÁÑ°Ë¶ñ
    labels[~mask] = -100

    return masked_composition, labels
</code></pre>
<h3>‰∫ãÂâçÂ≠¶Áøí„Çø„Çπ„ÇØ2: Contrastive Learning</h3>
<pre><code class="language-python">class ContrastiveLearning(nn.Module):
    &quot;&quot;&quot;
    Contrastive Learning for Materials

    „Ç¢„Ç§„Éá„Ç¢: È°û‰ººÊùêÊñô„ÇíËøë„Åè„ÄÅÁï∞„Å™„ÇãÊùêÊñô„ÇíÈÅ†„Åè„Å´ÈÖçÁΩÆ
    &quot;&quot;&quot;

    def __init__(self, matbert, temperature=0.07):
        super().__init__()
        self.matbert = matbert
        self.temperature = temperature

    def forward(self, compositions1, compositions2, labels):
        &quot;&quot;&quot;
        Args:
            compositions1: (batch, seq_len) Augmented sample 1
            compositions2: (batch, seq_len) Augmented sample 2
            labels: (batch,) 1 if similar, 0 if dissimilar

        Returns:
            loss: Contrastive loss
        &quot;&quot;&quot;
        # Embeddings
        emb1 = self.matbert(compositions1).pooler_output  # (batch, 768)
        emb2 = self.matbert(compositions2).pooler_output

        # Normalize
        emb1 = F.normalize(emb1, dim=-1)
        emb2 = F.normalize(emb2, dim=-1)

        # Cosine similarity
        similarity = torch.matmul(emb1, emb2.T) / self.temperature  # (batch, batch)

        # Loss: InfoNCE
        loss = F.cross_entropy(similarity, torch.arange(emb1.size(0), device=emb1.device))

        return loss

# „Éá„Éº„ÇøÊã°Âºµ
def augment_composition(composition_ids):
    &quot;&quot;&quot;
    ÁµÑÊàêÂºè„ÅÆ„Éá„Éº„ÇøÊã°Âºµ

    ÊâãÊ≥ï:
    - ÂéüÂ≠êÈ†ÜÂ∫è„ÅÆ„Ç∑„É£„ÉÉ„Éï„É´ (Fe2O3 ‚Üí O3Fe2)
    - ÂêåÊóèÂÖÉÁ¥†„ÅÆÁΩÆÊèõ (LiCoO2 ‚Üí NaCoO2)
    &quot;&quot;&quot;
    # ÂÆüË£ÖÁúÅÁï•
    pass
</code></pre>
<hr />
<h2>‚úÖ Á¨¨4Á´†ÂÆå‰∫Ü„ÉÅ„Çß„ÉÉ„ÇØ„É™„Çπ„Éà</h2>
<h3>Ê¶ÇÂøµÁêÜËß£Ôºà10È†ÖÁõÆÔºâ</h3>
<ul>
<li>[ ] Êã°Êï£„É¢„Éá„É´„ÅÆÂéüÁêÜÔºàforward/reverse processÔºâ„ÇíÁêÜËß£„Åó„Å¶„ÅÑ„Çã</li>
<li>[ ] Êù°‰ª∂‰ªò„ÅçÁîüÊàê„ÅÆ‰ªïÁµÑ„Åø„ÇíÁêÜËß£„Åó„Å¶„ÅÑ„Çã</li>
<li>[ ] SMILES„Å®SELFIES„ÅÆÈÅï„ÅÑ„Å®Âà©ÁÇπ„ÇíË™¨Êòé„Åß„Åç„Çã</li>
<li>[ ] ÊùêÊñôÈÄÜË®≠Ë®à„ÅÆ„ÉØ„Éº„ÇØ„Éï„É≠„Éº„ÇíÁêÜËß£„Åó„Å¶„ÅÑ„Çã</li>
<li>[ ] ChemBERTa„Å®MatBERT„ÅÆÈÅï„ÅÑ„ÇíË™¨Êòé„Åß„Åç„Çã</li>
<li>[ ] Full fine-tuning/Adapter/LoRA„ÅÆÈÅï„ÅÑ„Å®ÈÅ©Áî®Â†¥Èù¢„ÇíÁêÜËß£„Åó„Å¶„ÅÑ„Çã</li>
<li>[ ] Masked Atom Prediction„ÅÆÂéüÁêÜ„ÇíÁêÜËß£„Åó„Å¶„ÅÑ„Çã</li>
<li>[ ] Contrastive Learning„ÅÆÊùêÊñôÁßëÂ≠¶„Å∏„ÅÆÂøúÁî®„ÇíÁêÜËß£„Åó„Å¶„ÅÑ„Çã</li>
<li>[ ] ÁîüÊàê„É¢„Éá„É´„ÅÆË©ï‰æ°ÊåáÊ®ôÔºàÂ¶•ÂΩìÊÄß„ÄÅÂ§öÊßòÊÄß„ÄÅÊñ∞Ë¶èÊÄßÔºâ„ÇíË™¨Êòé„Åß„Åç„Çã</li>
<li>[ ] ÊùêÊñôÈÄÜË®≠Ë®à„Å´„Åä„Åë„ÇãÂà∂Á¥ÑÔºàÂêàÊàêÂèØËÉΩÊÄß„ÄÅÂÆâÂÆöÊÄßÔºâ„ÇíÁêÜËß£„Åó„Å¶„ÅÑ„Çã</li>
</ul>
<h3>ÂÆüË£Ö„Çπ„Ç≠„É´Ôºà15È†ÖÁõÆÔºâ</h3>
<ul>
<li>[ ] SimpleDiffusionModel„ÇíÂÆüË£Ö„Åß„Åç„Çã</li>
<li>[ ] ConditionalDiffusionModel„ÇíÂÆüË£Ö„Åß„Åç„Çã</li>
<li>[ ] SMILESGenerator„ÇíÂÆüË£Ö„Åß„Åç„Çã</li>
<li>[ ] ConditionalSMILESGenerator„ÇíÂÆüË£Ö„Åß„Åç„Çã</li>
<li>[ ] ChemBERTa„Çí‰ΩøÁî®„Åß„Åç„Çã</li>
<li>[ ] MatBERT„ÇíÂÆüË£Ö„Åß„Åç„Çã</li>
<li>[ ] MatGPTÔºàÊù°‰ª∂‰ªò„ÅçÁîüÊàêÂê´„ÇÄÔºâ„ÇíÂÆüË£Ö„Åß„Åç„Çã</li>
<li>[ ] AdapterLayer„ÇíÂÆüË£Ö„Åß„Åç„Çã</li>
<li>[ ] LoRALayer„ÇíÂÆüË£Ö„Åß„Åç„Çã</li>
<li>[ ] Masked Atom Prediction„ÇíÂÆüË£Ö„Åß„Åç„Çã</li>
<li>[ ] Contrastive Learning„ÇíÂÆüË£Ö„Åß„Åç„Çã</li>
<li>[ ] ÊùêÊñôÈÄÜË®≠Ë®à„Ç∑„Çπ„ÉÜ„É†„ÇíÊßãÁØâ„Åß„Åç„Çã</li>
<li>[ ] ÂêàÊàêÂèØËÉΩÊÄß„ÉÅ„Çß„ÉÉ„ÇØ„ÇíÂÆüË£Ö„Åß„Åç„Çã</li>
<li>[ ] ÁîüÊàê„Åï„Çå„ÅüÊùêÊñô„ÅÆÊ§úË®º„Éë„Ç§„Éó„É©„Ç§„É≥„ÇíÊßãÁØâ„Åß„Åç„Çã</li>
<li>[ ] „Éì„Éº„É†Êé¢Á¥¢Ôºàbeam searchÔºâ„ÇíÂÆüË£Ö„Åß„Åç„Çã</li>
</ul>
<h3>„Éá„Éê„ÉÉ„Ç∞„Çπ„Ç≠„É´Ôºà5È†ÖÁõÆÔºâ</h3>
<ul>
<li>[ ] Êã°Êï£„É¢„Éá„É´„ÅÆ„Çµ„É≥„Éó„É´ÂìÅË≥™„ÇíË©ï‰æ°„Åß„Åç„Çã</li>
<li>[ ] ÁîüÊàê„Åï„Çå„ÅüSMILES„ÅÆÂ¶•ÂΩìÊÄß„ÇíÊ§úË®º„Åß„Åç„Çã</li>
<li>[ ] Êù°‰ª∂‰ªò„ÅçÁîüÊàê„ÅÆÊù°‰ª∂ÈÅîÊàêÂ∫¶„ÇíË©ï‰æ°„Åß„Åç„Çã</li>
<li>[ ] LoRA/Adapter„ÅÆÊÄßËÉΩ„Çífull fine-tuning„Å®ÊØîËºÉ„Åß„Åç„Çã</li>
<li>[ ] ‰∫ãÂâçÂ≠¶Áøí„ÅÆÂäπÊûú„ÇíÂèØË¶ñÂåñ„ÉªÂàÜÊûê„Åß„Åç„Çã</li>
</ul>
<h3>ÂøúÁî®ÂäõÔºà5È†ÖÁõÆÔºâ</h3>
<ul>
<li>[ ] Êñ∞Ë¶èÊùêÊñôÊé¢Á¥¢„Å´ÁîüÊàê„É¢„Éá„É´„ÇíÈÅ©Áî®„Åß„Åç„Çã</li>
<li>[ ] Â§öÁõÆÁöÑÊúÄÈÅ©ÂåñÔºàË§áÊï∞ÁâπÊÄßÔºâ„ÇíÂÆüË£Ö„Åß„Åç„Çã</li>
<li>[ ] ÁîüÊàê„É¢„Éá„É´„Å®‰∫àÊ∏¨„É¢„Éá„É´„ÇíÁµÑ„ÅøÂêà„Çè„Åõ„Åü„É´„Éº„Éó„ÇíÊßãÁØâ„Åß„Åç„Çã</li>
<li>[ ] „Éâ„É°„Ç§„É≥Áü•Ë≠òÔºàÂåñÂ≠¶Ââá„ÄÅÁµêÊô∂Â≠¶Ôºâ„ÇíÁîüÊàê„Å´ÁµÑ„ÅøËæº„ÇÅ„Çã</li>
<li>[ ] ÂÆüÈ®ìÂÄôË£ú„ÅÆÂÑ™ÂÖàÈ†Ü‰Ωç‰ªò„Åë„Åå„Åß„Åç„Çã</li>
</ul>
<h3>„Éá„Éº„ÇøÂá¶ÁêÜÔºà5È†ÖÁõÆÔºâ</h3>
<ul>
<li>[ ] SMILES/SELFIES„ÅÆÁõ∏‰∫íÂ§âÊèõ„Åå„Åß„Åç„Çã</li>
<li>[ ] ÂàÜÂ≠ê„ÅÆÂ¶•ÂΩìÊÄß„ÉÅ„Çß„ÉÉ„ÇØÔºàRDKitÔºâ„Åå„Åß„Åç„Çã</li>
<li>[ ] ÁµÑÊàêÂºè„ÅÆÊ≠£Ë¶èÂåñ„Åå„Åß„Åç„Çã</li>
<li>[ ] „Éá„Éº„ÇøÊã°ÂºµÔºàaugmentationÔºâ„ÇíÂÆüË£Ö„Åß„Åç„Çã</li>
<li>[ ] ÁîüÊàê„Éá„Éº„Çø„ÅÆÂæåÂá¶ÁêÜÔºà„Éï„Ç£„É´„Çø„É™„É≥„Ç∞Ôºâ„Åå„Åß„Åç„Çã</li>
</ul>
<h3>Ë©ï‰æ°„Çπ„Ç≠„É´Ôºà5È†ÖÁõÆÔºâ</h3>
<ul>
<li>[ ] ÁîüÊàê„É¢„Éá„É´„ÅÆÂ¶•ÂΩìÊÄßÔºàvalidityÔºâ„ÇíÊ∏¨ÂÆö„Åß„Åç„Çã</li>
<li>[ ] Â§öÊßòÊÄßÔºàdiversityÔºâ„ÇíÂÆöÈáèË©ï‰æ°„Åß„Åç„Çã</li>
<li>[ ] Êñ∞Ë¶èÊÄßÔºànoveltyÔºâ„ÇíË©ï‰æ°„Åß„Åç„Çã</li>
<li>[ ] Êù°‰ª∂ÈÅîÊàêÂ∫¶Ôºàcondition satisfactionÔºâ„ÇíÊ∏¨ÂÆö„Åß„Åç„Çã</li>
<li>[ ] ÂêàÊàêÂèØËÉΩÊÄß„Çπ„Ç≥„Ç¢„ÇíË®àÁÆó„Åß„Åç„Çã</li>
</ul>
<h3>ÁêÜË´ñÁöÑËÉåÊôØÔºà5È†ÖÁõÆÔºâ</h3>
<ul>
<li>[ ] Êã°Êï£„É¢„Éá„É´Ë´ñÊñáÔºàHo et al., 2020Ôºâ„ÇíË™≠„Çì„Å†</li>
<li>[ ] ChemBERTa/MatBERTË´ñÊñá„ÇíË™≠„Çì„Å†</li>
<li>[ ] LoRAË´ñÊñáÔºàHu et al., 2021Ôºâ„ÇíË™≠„Çì„Å†</li>
<li>[ ] ÊùêÊñôÈÄÜË®≠Ë®à„ÅÆË´ñÊñá„Çí1Êú¨‰ª•‰∏äË™≠„Çì„Å†</li>
<li>[ ] ÁîüÊàê„É¢„Éá„É´„ÅÆÁêÜË´ñÔºàVAE, GAN, DiffusionÔºâ„ÇíÁêÜËß£„Åó„Å¶„ÅÑ„Çã</li>
</ul>
<h3>ÂÆå‰∫ÜÂü∫Ê∫ñ</h3>
<ul>
<li><strong>ÊúÄ‰ΩéÂü∫Ê∫ñ</strong>: 40È†ÖÁõÆ‰ª•‰∏äÈÅîÊàêÔºà80%Ôºâ</li>
<li><strong>Êé®Â•®Âü∫Ê∫ñ</strong>: 45È†ÖÁõÆ‰ª•‰∏äÈÅîÊàêÔºà90%Ôºâ</li>
<li><strong>ÂÑ™ÁßÄÂü∫Ê∫ñ</strong>: 50È†ÖÁõÆÂÖ®„Å¶ÈÅîÊàêÔºà100%Ôºâ</li>
</ul>
<hr />
<h2>üîó ÂèÇËÄÉË≥áÊñô</h2>
<h3>Ë´ñÊñá</h3>
<ul>
<li>Ho et al. (2020) "Denoising Diffusion Probabilistic Models" <a href="https://arxiv.org/abs/2006.11239">arXiv:2006.11239</a></li>
<li>Chen et al. (2022) "Matformer: Nested Transformer for Elastic Inference"</li>
<li>Xie et al. (2021) "Crystal Diffusion Variational Autoencoder" <a href="https://arxiv.org/abs/2110.06197">arXiv:2110.06197</a></li>
<li>Stokes et al. (2020) "A Deep Learning Approach to Antibiotic Discovery" Nature</li>
<li>Hu et al. (2021) "LoRA: Low-Rank Adaptation of Large Language Models" <a href="https://arxiv.org/abs/2106.09685">arXiv:2106.09685</a></li>
<li>Chithrananda et al. (2020) "ChemBERTa: Large-Scale Self-Supervised Pretraining for Molecular Property Prediction" <a href="https://arxiv.org/abs/2010.09885">arXiv:2010.09885</a></li>
</ul>
<h3>„ÉÑ„Éº„É´</h3>
<ul>
<li><a href="https://github.com/huggingface/diffusers">Hugging Face Diffusers</a></li>
<li><a href="https://www.rdkit.org/">RDKit</a> - ÂàÜÂ≠êÂá¶ÁêÜ</li>
<li><a href="https://materialsproject.org/">Materials Project API</a></li>
<li><a href="https://github.com/aspuru-guzik-group/selfies">SELFIES</a> - ÂàÜÂ≠êË°®Áèæ</li>
<li><a href="https://pymatgen.org/">PyMatGen</a> - ÊùêÊñôÁßëÂ≠¶</li>
</ul>
<h3>Ê¨°„ÅÆ„Ç∑„É™„Éº„Ç∫</h3>
<ul>
<li><strong>Âº∑ÂåñÂ≠¶ÁøíÂÖ•ÈñÄ</strong>: ÊùêÊñôÊé¢Á¥¢„Å∏„ÅÆÂº∑ÂåñÂ≠¶ÁøíÈÅ©Áî®</li>
<li><strong>GNNÂÖ•ÈñÄ</strong>: „Ç∞„É©„Éï„Éã„É•„Éº„É©„É´„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ„ÅßÂàÜÂ≠ê„ÉªÊùêÊñôË°®Áèæ</li>
<li><strong>Foundation ModelsÂÖ•ÈñÄ</strong>: LLaMA, GPT-4, Claude for Materials</li>
</ul>
<hr />
<p><strong>‰ΩúÊàêËÄÖ</strong>: Ê©ãÊú¨‰Ωë‰ªãÔºàÊù±ÂåóÂ§ßÂ≠¶Ôºâ
<strong>ÊúÄÁµÇÊõ¥Êñ∞</strong>: 2025Âπ¥10Êúà19Êó•
<strong>„Ç∑„É™„Éº„Ç∫</strong>: Transformer„ÉªFoundation ModelsÂÖ•ÈñÄÔºàÂÖ®4Á´†ÂÆåÔºâ</p>
<p><strong>„É©„Ç§„Çª„É≥„Çπ</strong>: CC BY 4.0</p><div class="navigation">
    <a href="chapter-3.html" class="nav-button">‚Üê Ââç„ÅÆÁ´†</a>
    <a href="index.html" class="nav-button">„Ç∑„É™„Éº„Ç∫ÁõÆÊ¨°„Å´Êàª„Çã</a>
</div>
    </main>

    <footer>
        <p><strong>‰ΩúÊàêËÄÖ</strong>: AI Terakoya Content Team</p>
        <p><strong>Áõ£‰øÆ</strong>: Dr. Yusuke HashimotoÔºàÊù±ÂåóÂ§ßÂ≠¶Ôºâ</p>
        <p><strong>„Éê„Éº„Ç∏„Éß„É≥</strong>: 1.0 | <strong>‰ΩúÊàêÊó•</strong>: 2025-10-17</p>
        <p><strong>„É©„Ç§„Çª„É≥„Çπ</strong>: Creative Commons BY 4.0</p>
        <p>¬© 2025 AI Terakoya. All rights reserved.</p>
    </footer>
</body>
</html>
