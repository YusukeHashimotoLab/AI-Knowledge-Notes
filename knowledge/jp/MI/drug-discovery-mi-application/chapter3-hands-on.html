<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>å‰µè–¬MIå®Ÿè£…ãƒãƒ³ã‚ºã‚ªãƒ³ - AI Terakoya</title>

    <style>
        :root {
            --color-primary: #2c3e50;
            --color-primary-dark: #1a252f;
            --color-accent: #7b2cbf;
            --color-accent-light: #9d4edd;
            --color-text: #2d3748;
            --color-text-light: #4a5568;
            --color-bg: #ffffff;
            --color-bg-alt: #f7fafc;
            --color-border: #e2e8f0;
            --color-code-bg: #f8f9fa;
            --color-link: #3182ce;
            --color-link-hover: #2c5aa0;

            --spacing-xs: 0.5rem;
            --spacing-sm: 1rem;
            --spacing-md: 1.5rem;
            --spacing-lg: 2rem;
            --spacing-xl: 3rem;

            --font-body: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            --font-mono: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;

            --border-radius: 8px;
            --box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: var(--font-body);
            line-height: 1.7;
            color: var(--color-text);
            background-color: var(--color-bg);
            font-size: 16px;
        }

        header {
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            padding: var(--spacing-xl) var(--spacing-md);
            margin-bottom: var(--spacing-xl);
            box-shadow: var(--box-shadow);
        }

        .header-content {
            max-width: 900px;
            margin: 0 auto;
        }

        h1 {
            font-size: 2rem;
            font-weight: 700;
            margin-bottom: var(--spacing-sm);
            line-height: 1.2;
        }

        .subtitle {
            font-size: 1.1rem;
            opacity: 0.95;
            font-weight: 400;
            margin-bottom: var(--spacing-md);
        }

        .meta {
            display: flex;
            flex-wrap: wrap;
            gap: var(--spacing-md);
            font-size: 0.9rem;
            opacity: 0.9;
        }

        .meta-item {
            display: flex;
            align-items: center;
            gap: 0.3rem;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 0 var(--spacing-md) var(--spacing-xl);
        }

        h2 {
            font-size: 1.75rem;
            color: var(--color-primary);
            margin-top: var(--spacing-xl);
            margin-bottom: var(--spacing-md);
            padding-bottom: var(--spacing-xs);
            border-bottom: 3px solid var(--color-accent);
        }

        h3 {
            font-size: 1.4rem;
            color: var(--color-primary);
            margin-top: var(--spacing-lg);
            margin-bottom: var(--spacing-sm);
        }

        h4 {
            font-size: 1.1rem;
            color: var(--color-primary-dark);
            margin-top: var(--spacing-md);
            margin-bottom: var(--spacing-sm);
        }

        p {
            margin-bottom: var(--spacing-md);
            color: var(--color-text);
        }

        a {
            color: var(--color-link);
            text-decoration: none;
            transition: color 0.2s;
        }

        a:hover {
            color: var(--color-link-hover);
            text-decoration: underline;
        }

        ul, ol {
            margin-left: var(--spacing-lg);
            margin-bottom: var(--spacing-md);
        }

        li {
            margin-bottom: var(--spacing-xs);
            color: var(--color-text);
        }

        pre {
            background-color: var(--color-code-bg);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            overflow-x: auto;
            margin-bottom: var(--spacing-md);
            font-family: var(--font-mono);
            font-size: 0.9rem;
            line-height: 1.5;
        }

        code {
            font-family: var(--font-mono);
            font-size: 0.9em;
            background-color: var(--color-code-bg);
            padding: 0.2em 0.4em;
            border-radius: 3px;
        }

        pre code {
            background-color: transparent;
            padding: 0;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: var(--spacing-md);
            font-size: 0.95rem;
        }

        th, td {
            border: 1px solid var(--color-border);
            padding: var(--spacing-sm);
            text-align: left;
        }

        th {
            background-color: var(--color-bg-alt);
            font-weight: 600;
            color: var(--color-primary);
        }

        blockquote {
            border-left: 4px solid var(--color-accent);
            padding-left: var(--spacing-md);
            margin: var(--spacing-md) 0;
            color: var(--color-text-light);
            font-style: italic;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        .mermaid {
            text-align: center;
            margin: var(--spacing-lg) 0;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        details {
            background-color: var(--color-bg-alt);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            margin-bottom: var(--spacing-md);
        }

        summary {
            cursor: pointer;
            font-weight: 600;
            color: var(--color-primary);
            user-select: none;
            padding: var(--spacing-xs);
            margin: calc(-1 * var(--spacing-md));
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        summary:hover {
            background-color: rgba(123, 44, 191, 0.1);
        }

        details[open] summary {
            margin-bottom: var(--spacing-md);
            border-bottom: 1px solid var(--color-border);
        }

        .navigation {
            display: flex;
            justify-content: space-between;
            gap: var(--spacing-md);
            margin: var(--spacing-xl) 0;
            padding-top: var(--spacing-lg);
            border-top: 2px solid var(--color-border);
        }

        .nav-button {
            flex: 1;
            padding: var(--spacing-md);
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            border-radius: var(--border-radius);
            text-align: center;
            font-weight: 600;
            transition: transform 0.2s, box-shadow 0.2s;
            box-shadow: var(--box-shadow);
        }

        .nav-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
            text-decoration: none;
        }

        footer {
            margin-top: var(--spacing-xl);
            padding: var(--spacing-lg) var(--spacing-md);
            background-color: var(--color-bg-alt);
            border-top: 1px solid var(--color-border);
            text-align: center;
            font-size: 0.9rem;
            color: var(--color-text-light);
        }

        @media (max-width: 768px) {
            h1 { font-size: 1.5rem; }
            h2 { font-size: 1.4rem; }
            h3 { font-size: 1.2rem; }
            .meta { font-size: 0.85rem; }
            .navigation { flex-direction: column; }
            table { font-size: 0.85rem; }
            th, td { padding: var(--spacing-xs); }
        }
    </style>

    <script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
    <script>
        mermaid.initialize({ startOnLoad: true, theme: 'default', securityLevel: 'strict' });
    </script>

    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\(', '\)']],
                displayMath: [['$$', '$$'], ['\[', '\]']],
                processEscapes: true
            }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" async></script>
</head>
<body>
    <header>
        <div class="header-content">
            <h1>å‰µè–¬MIå®Ÿè£…ãƒãƒ³ã‚ºã‚ªãƒ³</h1>
            <p class="subtitle">RDKitã¨Pythonã§å­¦ã¶å®Ÿè·µçš„åˆ†å­è¨­è¨ˆ</p>
            <div class="meta">
                <span class="meta-item">ğŸ“– 70-80åˆ†</span>
                <span class="meta-item">ğŸ“Š ä¸­ç´š</span>
                <span class="meta-item">ğŸ’» 30å€‹</span>
                <span class="meta-item">ğŸ“ 5å•</span>
            </div>
        </div>
    </header>

    <main class="container">
<h1>ç¬¬3ç« ï¼šPythonã§å®Ÿè£…ã™ã‚‹å‰µè–¬MI - RDKit &amp; ChEMBLå®Ÿè·µ</h1>
<p><strong>30å€‹ã®å®Ÿè¡Œå¯èƒ½ãªã‚³ãƒ¼ãƒ‰ä¾‹ã§å­¦ã¶å®Ÿè·µçš„å‰µè–¬AI</strong></p>
<h2>3.1 ç’°å¢ƒæ§‹ç¯‰</h2>
<h3>3.1.1 å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒª</h3>
<p>å‰µè–¬MIã«å¿…è¦ãªä¸»è¦ãƒ©ã‚¤ãƒ–ãƒ©ãƒªï¼š</p>
<pre><code class="language-python"># åŒ–å­¦æƒ…å ±å‡¦ç†
rdkit                 # åˆ†å­å‡¦ç†ã®æ¨™æº–ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
chembl_webresource_client  # ChEMBL API

# æ©Ÿæ¢°å­¦ç¿’
scikit-learn         # æ±ç”¨MLï¼ˆRF, SVMç­‰ï¼‰
lightgbm             # å‹¾é…ãƒ–ãƒ¼ã‚¹ãƒ†ã‚£ãƒ³ã‚°
tensorflow / pytorch # ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°

# ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ»å¯è¦–åŒ–
pandas               # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
numpy                # æ•°å€¤è¨ˆç®—
matplotlib           # ã‚°ãƒ©ãƒ•æç”»
seaborn              # çµ±è¨ˆçš„å¯è¦–åŒ–
</code></pre>
<h3>3.1.2 ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ–¹æ³•</h3>
<h4>Option 1: Anacondaï¼ˆåˆå¿ƒè€…æ¨å¥¨ï¼‰</h4>
<p><strong>ãƒ¡ãƒªãƒƒãƒˆ:</strong>
- GUIã§ç°¡å˜ç®¡ç†
- ä¾å­˜é–¢ä¿‚è‡ªå‹•è§£æ±º
- RDKitã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãŒå®¹æ˜“</p>
<p><strong>æ‰‹é †:</strong></p>
<pre><code class="language-bash"># 1. Anacondaã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ»ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
# https://www.anaconda.com/download

# 2. ä»®æƒ³ç’°å¢ƒä½œæˆ
conda create -n drug_discovery python=3.10
conda activate drug_discovery

# 3. RDKitã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼ˆcondaã‚’ä½¿ã†ï¼‰
conda install -c conda-forge rdkit

# 4. ãã®ä»–ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
conda install pandas numpy matplotlib seaborn scikit-learn
pip install chembl_webresource_client lightgbm

# 5. ç¢ºèª
python -c &quot;from rdkit import Chem; print('RDKit OK!')&quot;
</code></pre>
<h4>Option 2: venvï¼ˆPythonæ¨™æº–ï¼‰</h4>
<p><strong>ãƒ¡ãƒªãƒƒãƒˆ:</strong>
- Pythonæ¨™æº–æ©Ÿèƒ½ï¼ˆè¿½åŠ ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ä¸è¦ï¼‰
- è»½é‡</p>
<p><strong>æ‰‹é †:</strong></p>
<pre><code class="language-bash"># 1. ä»®æƒ³ç’°å¢ƒä½œæˆ
python3 -m venv drug_discovery_env

# 2. ä»®æƒ³ç’°å¢ƒã‚’æœ‰åŠ¹åŒ–
# macOS/Linux:
source drug_discovery_env/bin/activate
# Windows:
drug_discovery_env\Scripts\activate

# 3. ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install rdkit pandas numpy matplotlib seaborn scikit-learn
pip install chembl_webresource_client lightgbm

# 4. ç¢ºèª
python -c &quot;from rdkit import Chem; print('RDKit OK!')&quot;
</code></pre>
<h4>Option 3: Google Colabï¼ˆã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ä¸è¦ï¼‰</h4>
<p><strong>ãƒ¡ãƒªãƒƒãƒˆ:</strong>
- ãƒ–ãƒ©ã‚¦ã‚¶ã ã‘ã§é–‹å§‹
- GPUã‚¢ã‚¯ã‚»ã‚¹ç„¡æ–™
- ç’°å¢ƒæ§‹ç¯‰ä¸è¦</p>
<p><strong>æ‰‹é †:</strong></p>
<pre><code class="language-python"># Google Colabã§æ–°è¦ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ä½œæˆ
# https://colab.research.google.com/

# ã‚»ãƒ«ã§å®Ÿè¡Œ
!pip install rdkit chembl_webresource_client

# ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ†ã‚¹ãƒˆ
from rdkit import Chem
print(&quot;RDKit version:&quot;, Chem.__version__)
</code></pre>
<p><strong>æ¯”è¼ƒè¡¨:</strong></p>
<table>
<thead>
<tr>
<th>é …ç›®</th>
<th>Anaconda</th>
<th>venv</th>
<th>Google Colab</th>
</tr>
</thead>
<tbody>
<tr>
<td>ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«é›£æ˜“åº¦</td>
<td>â­â­</td>
<td>â­â­â­</td>
<td>â­ï¼ˆä¸è¦ï¼‰</td>
</tr>
<tr>
<td>RDKitå¯¾å¿œ</td>
<td>â—ï¼ˆç°¡å˜ï¼‰</td>
<td>â–³ï¼ˆã‚„ã‚„é¢å€’ï¼‰</td>
<td>â—‹ï¼ˆpipå¯ï¼‰</td>
</tr>
<tr>
<td>GPUåˆ©ç”¨</td>
<td>ãƒ­ãƒ¼ã‚«ãƒ«GPU</td>
<td>ãƒ­ãƒ¼ã‚«ãƒ«GPU</td>
<td>ç„¡æ–™ã‚¯ãƒ©ã‚¦ãƒ‰GPU</td>
</tr>
<tr>
<td>ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ä½œæ¥­</td>
<td>â—‹</td>
<td>â—‹</td>
<td>Ã—</td>
</tr>
<tr>
<td>æ¨å¥¨ãƒ¦ãƒ¼ã‚¶ãƒ¼</td>
<td>åˆå¿ƒè€…</td>
<td>ä¸­ç´šè€…</td>
<td>å…¨ãƒ¬ãƒ™ãƒ«</td>
</tr>
</tbody>
</table>
<hr />
<h2>3.2 RDKitåŸºç¤ï¼ˆ10ã‚³ãƒ¼ãƒ‰ä¾‹ï¼‰</h2>
<h3>Example 1: SMILESæ–‡å­—åˆ—ã‹ã‚‰åˆ†å­ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆä½œæˆ</h3>
<pre><code class="language-python"># ===================================
# Example 1: SMILES â†’ åˆ†å­ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
# ===================================

from rdkit import Chem

# SMILESæ–‡å­—åˆ—ã‚’å®šç¾©
smiles_aspirin = &quot;CC(=O)OC1=CC=CC=C1C(=O)O&quot;  # ã‚¢ã‚¹ãƒ”ãƒªãƒ³

# åˆ†å­ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«å¤‰æ›
mol = Chem.MolFromSmiles(smiles_aspirin)

# åŸºæœ¬æƒ…å ±ã‚’è¡¨ç¤º
print(f&quot;åˆ†å­å¼: {Chem.rdMolDescriptors.CalcMolFormula(mol)}&quot;)
print(f&quot;åŸå­æ•°: {mol.GetNumAtoms()}&quot;)
print(f&quot;çµåˆæ•°: {mol.GetNumBonds()}&quot;)

# æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›:
# åˆ†å­å¼: C9H8O4
# åŸå­æ•°: 21  # é™½å­Hã‚’å«ã‚€
# çµåˆæ•°: 21
</code></pre>
<p><strong>é‡è¦ãƒã‚¤ãƒ³ãƒˆ:</strong>
- <code>Chem.MolFromSmiles()</code> ã¯ç„¡åŠ¹ãªSMILESã«å¯¾ã—ã¦ <code>None</code> ã‚’è¿”ã™
- ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãŒå¿…é ˆ</p>
<pre><code class="language-python"># ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ä»˜ã
def safe_mol_from_smiles(smiles):
    &quot;&quot;&quot;å®‰å…¨ã«SMILESã‚’åˆ†å­ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«å¤‰æ›

    Args:
        smiles (str): SMILESæ–‡å­—åˆ—

    Returns:
        rdkit.Chem.Mol or None: åˆ†å­ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
    &quot;&quot;&quot;
    mol = Chem.MolFromSmiles(smiles)
    if mol is None:
        print(f&quot;Warning: Invalid SMILES: {smiles}&quot;)
    return mol

# ä½¿ç”¨ä¾‹
valid_mol = safe_mol_from_smiles(&quot;CCO&quot;)  # ã‚¨ã‚¿ãƒãƒ¼ãƒ«ï¼ˆOKï¼‰
invalid_mol = safe_mol_from_smiles(&quot;C=C=C=C&quot;)  # ç„¡åŠ¹ãªSMILES
</code></pre>
<h3>Example 2: åˆ†å­ã®2Dæç”»</h3>
<pre><code class="language-python"># ===================================
# Example 2: åˆ†å­æ§‹é€ ã®æç”»
# ===================================

from rdkit import Chem
from rdkit.Chem import Draw
import matplotlib.pyplot as plt

# è¤‡æ•°ã®è–¬ç‰©åˆ†å­
molecules = {
    'Aspirin': 'CC(=O)OC1=CC=CC=C1C(=O)O',
    'Caffeine': 'CN1C=NC2=C1C(=O)N(C(=O)N2C)C',
    'Ibuprofen': 'CC(C)Cc1ccc(cc1)[C@@H](C)C(=O)O',
    'Penicillin G': 'CC1(C)S[C@@H]2[C@H](NC(=O)Cc3ccccc3)C(=O)N2[C@H]1C(=O)O'
}

# åˆ†å­ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«å¤‰æ›
mols = [Chem.MolFromSmiles(smi) for smi in molecules.values()]

# ä¸€åº¦ã«4ã¤æç”»
img = Draw.MolsToGridImage(
    mols,
    molsPerRow=2,
    subImgSize=(300, 300),
    legends=list(molecules.keys())
)

# ä¿å­˜
img.save('drug_molecules.png')

# ã¾ãŸã¯ç›´æ¥è¡¨ç¤ºï¼ˆJupyter/Colabï¼‰
# display(img)

print(&quot;ç”»åƒã‚’ä¿å­˜ã—ã¾ã—ãŸ: drug_molecules.png&quot;)
</code></pre>
<h3>Example 3: åˆ†å­é‡ãƒ»LogPè¨ˆç®—</h3>
<pre><code class="language-python"># ===================================
# Example 3: åŸºæœ¬çš„ãªç‰©ç†åŒ–å­¦çš„ç‰¹æ€§è¨ˆç®—
# ===================================

from rdkit import Chem
from rdkit.Chem import Descriptors
import pandas as pd

# è–¬ç‰©ãƒªã‚¹ãƒˆ
drugs = {
    'Aspirin': 'CC(=O)OC1=CC=CC=C1C(=O)O',
    'Caffeine': 'CN1C=NC2=C1C(=O)N(C(=O)N2C)C',
    'Ibuprofen': 'CC(C)Cc1ccc(cc1)[C@@H](C)C(=O)O',
    'Atorvastatin': 'CC(C)c1c(C(=O)Nc2ccccc2)c(-c2ccccc2)c(-c2ccc(F)cc2)n1CC[C@@H](O)C[C@@H](O)CC(=O)O'
}

# å„è–¬ç‰©ã®ç‰¹æ€§ã‚’è¨ˆç®—
results = []
for name, smiles in drugs.items():
    mol = Chem.MolFromSmiles(smiles)
    if mol is None:
        continue

    results.append({
        'Name': name,
        'MW': Descriptors.MolWt(mol),  # åˆ†å­é‡
        'LogP': Descriptors.MolLogP(mol),  # åˆ†é…ä¿‚æ•°ï¼ˆè„‚æº¶æ€§ï¼‰
        'TPSA': Descriptors.TPSA(mol),  # æ¥µæ€§è¡¨é¢ç©
        'HBD': Descriptors.NumHDonors(mol),  # æ°´ç´ çµåˆãƒ‰ãƒŠãƒ¼
        'HBA': Descriptors.NumHAcceptors(mol),  # æ°´ç´ çµåˆã‚¢ã‚¯ã‚»ãƒ—ã‚¿ãƒ¼
        'RotBonds': Descriptors.NumRotatableBonds(mol)  # å›è»¢å¯èƒ½çµåˆ
    })

# DataFrameã«å¤‰æ›ã—ã¦è¡¨ç¤º
df = pd.DataFrame(results)
print(df.to_string(index=False))

# æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›:
#         Name      MW  LogP   TPSA  HBD  HBA  RotBonds
#      Aspirin  180.16  1.19  63.60    1    4         3
#     Caffeine  194.19 -0.07  61.82    0    6         0
#    Ibuprofen  206.28  3.50  37.30    1    2         4
# Atorvastatin  558.64  5.39 111.79    3    7        15
</code></pre>
<h3>Example 4: Lipinski's Rule of Five ãƒã‚§ãƒƒã‚¯</h3>
<pre><code class="language-python"># ===================================
# Example 4: Lipinski's Rule of Fiveï¼ˆçµŒå£è–¬ç‰©ã‚‰ã—ã•ï¼‰
# ===================================

from rdkit import Chem
from rdkit.Chem import Descriptors

def lipinski_filter(smiles):
    &quot;&quot;&quot;Lipinski's Rule of Fiveã‚’ãƒã‚§ãƒƒã‚¯

    è–¬ç‰©æ§˜åŒ–åˆç‰©ã®åŸºæº–:
    - åˆ†å­é‡ â‰¤ 500 Da
    - LogP â‰¤ 5
    - æ°´ç´ çµåˆãƒ‰ãƒŠãƒ¼ â‰¤ 5
    - æ°´ç´ çµåˆã‚¢ã‚¯ã‚»ãƒ—ã‚¿ãƒ¼ â‰¤ 10

    Args:
        smiles (str): SMILESæ–‡å­—åˆ—

    Returns:
        dict: å„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨åˆå¦åˆ¤å®š
    &quot;&quot;&quot;
    mol = Chem.MolFromSmiles(smiles)
    if mol is None:
        return None

    mw = Descriptors.MolWt(mol)
    logp = Descriptors.MolLogP(mol)
    hbd = Descriptors.NumHDonors(mol)
    hba = Descriptors.NumHAcceptors(mol)

    # Lipinski's Ruleåˆ¤å®š
    passes = (mw &lt;= 500 and logp &lt;= 5 and hbd &lt;= 5 and hba &lt;= 10)

    # å„åŸºæº–ã®åˆå¦
    results = {
        'SMILES': smiles,
        'MW': mw,
        'MW_Pass': mw &lt;= 500,
        'LogP': logp,
        'LogP_Pass': logp &lt;= 5,
        'HBD': hbd,
        'HBD_Pass': hbd &lt;= 5,
        'HBA': hba,
        'HBA_Pass': hba &lt;= 10,
        'Overall_Pass': passes
    }

    return results

# ãƒ†ã‚¹ãƒˆ
test_compounds = {
    'Aspirin': 'CC(=O)OC1=CC=CC=C1C(=O)O',
    'Lipitor': 'CC(C)c1c(C(=O)Nc2ccccc2)c(-c2ccccc2)c(-c2ccc(F)cc2)n1CC[C@@H](O)C[C@@H](O)CC(=O)O',
    'Cyclosporin A': 'CCC1C(=O)N(CC(=O)N(C(C(=O)NC(C(=O)N(C(C(=O)NC(C(=O)NC(C(=O)N(C(C(=O)N(C(C(=O)N(C(C(=O)N(C(C(=O)N1)C(C(C)CC=CC)O)C)C(C)C)C)CC(C)C)C)CC(C)C)C)C)C)CC(C)C)C)C(C)C)CC(C)C)C)C'  # å¤§ãã™ãã‚‹
}

for name, smiles in test_compounds.items():
    result = lipinski_filter(smiles)
    if result:
        print(f&quot;\n{name}:&quot;)
        print(f&quot;  MW: {result['MW']:.1f} Da ({'âœ“' if result['MW_Pass'] else 'âœ—'})&quot;)
        print(f&quot;  LogP: {result['LogP']:.2f} ({'âœ“' if result['LogP_Pass'] else 'âœ—'})&quot;)
        print(f&quot;  HBD: {result['HBD']} ({'âœ“' if result['HBD_Pass'] else 'âœ—'})&quot;)
        print(f&quot;  HBA: {result['HBA']} ({'âœ“' if result['HBA_Pass'] else 'âœ—'})&quot;)
        print(f&quot;  Overall: {'PASS âœ“' if result['Overall_Pass'] else 'FAIL âœ—'}&quot;)

# æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›:
# Aspirin:
#   MW: 180.2 Da (âœ“)
#   LogP: 1.19 (âœ“)
#   HBD: 1 (âœ“)
#   HBA: 4 (âœ“)
#   Overall: PASS âœ“
#
# Lipitor:
#   MW: 558.6 Da (âœ—)  # 500 Daè¶…é
#   LogP: 5.39 (âœ—)    # 5è¶…é
#   HBD: 3 (âœ“)
#   HBA: 7 (âœ“)
#   Overall: FAIL âœ—
#
# Cyclosporin A:
#   MW: 1202.6 Da (âœ—)  # å¤§å¹…è¶…é
#   Overall: FAIL âœ—
</code></pre>
<h3>Example 5: åˆ†å­æŒ‡ç´‹ï¼ˆECFPï¼‰ç”Ÿæˆ</h3>
<pre><code class="language-python"># ===================================
# Example 5: Extended Connectivity Fingerprintsï¼ˆECFPï¼‰
# ===================================

from rdkit import Chem
from rdkit.Chem import AllChem
import numpy as np

def generate_ecfp(smiles, radius=2, n_bits=2048):
    &quot;&quot;&quot;ECFPï¼ˆMorgan Fingerprintï¼‰ã‚’ç”Ÿæˆ

    Args:
        smiles (str): SMILESæ–‡å­—åˆ—
        radius (int): åŠå¾„ï¼ˆ2 = ECFP4, 3 = ECFP6ï¼‰
        n_bits (int): ãƒ“ãƒƒãƒˆé•·

    Returns:
        np.ndarray: ãƒ“ãƒƒãƒˆãƒ™ã‚¯ãƒˆãƒ«ï¼ˆ0/1é…åˆ—ï¼‰
    &quot;&quot;&quot;
    mol = Chem.MolFromSmiles(smiles)
    if mol is None:
        return None

    # Morgan Fingerprintï¼ˆECFPï¼‰
    fp = AllChem.GetMorganFingerprintAsBitVect(
        mol,
        radius=radius,
        nBits=n_bits
    )

    # NumPyé…åˆ—ã«å¤‰æ›
    arr = np.zeros((n_bits,), dtype=int)
    AllChem.DataStructs.ConvertToNumpyArray(fp, arr)

    return arr

# ãƒ†ã‚¹ãƒˆ
aspirin = &quot;CC(=O)OC1=CC=CC=C1C(=O)O&quot;
fp_aspirin = generate_ecfp(aspirin, radius=2, n_bits=2048)

print(f&quot;ECFP4 (åŠå¾„2, 2048ãƒ“ãƒƒãƒˆ):&quot;)
print(f&quot;  1ãƒ“ãƒƒãƒˆã®æ•°: {np.sum(fp_aspirin)}&quot;)
print(f&quot;  0ãƒ“ãƒƒãƒˆã®æ•°: {2048 - np.sum(fp_aspirin)}&quot;)
print(f&quot;  æœ€åˆã®50ãƒ“ãƒƒãƒˆ: {fp_aspirin[:50]}&quot;)

# æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›:
# ECFP4 (åŠå¾„2, 2048ãƒ“ãƒƒãƒˆ):
#   1ãƒ“ãƒƒãƒˆã®æ•°: 250
#   0ãƒ“ãƒƒãƒˆã®æ•°: 1798
#   æœ€åˆã®50ãƒ“ãƒƒãƒˆ: [0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 ...]
</code></pre>
<h3>Example 6: Tanimotoé¡ä¼¼åº¦è¨ˆç®—</h3>
<pre><code class="language-python"># ===================================
# Example 6: åˆ†å­é¡ä¼¼åº¦ï¼ˆTanimotoä¿‚æ•°ï¼‰
# ===================================

from rdkit import Chem
from rdkit.Chem import AllChem, DataStructs

def calculate_similarity(smiles1, smiles2, radius=2, n_bits=2048):
    &quot;&quot;&quot;2ã¤ã®åˆ†å­ã®Tanimotoé¡ä¼¼åº¦ã‚’è¨ˆç®—

    Args:
        smiles1, smiles2 (str): SMILESæ–‡å­—åˆ—
        radius (int): ECFPåŠå¾„
        n_bits (int): ãƒ“ãƒƒãƒˆé•·

    Returns:
        float: Tanimotoä¿‚æ•°ï¼ˆ0-1ï¼‰
    &quot;&quot;&quot;
    mol1 = Chem.MolFromSmiles(smiles1)
    mol2 = Chem.MolFromSmiles(smiles2)

    if mol1 is None or mol2 is None:
        return None

    # ECFPç”Ÿæˆ
    fp1 = AllChem.GetMorganFingerprintAsBitVect(mol1, radius, n_bits)
    fp2 = AllChem.GetMorganFingerprintAsBitVect(mol2, radius, n_bits)

    # Tanimotoä¿‚æ•°
    similarity = DataStructs.TanimotoSimilarity(fp1, fp2)

    return similarity

# NSAIDsï¼ˆéã‚¹ãƒ†ãƒ­ã‚¤ãƒ‰æ€§æŠ—ç‚ç—‡è–¬ï¼‰ã®é¡ä¼¼æ€§
drugs = {
    'Aspirin': 'CC(=O)OC1=CC=CC=C1C(=O)O',
    'Ibuprofen': 'CC(C)Cc1ccc(cc1)[C@@H](C)C(=O)O',
    'Naproxen': 'COc1ccc2cc(ccc2c1)[C@@H](C)C(=O)O',
    'Caffeine': 'CN1C=NC2=C1C(=O)N(C(=O)N2C)C'  # æ¯”è¼ƒç”¨ï¼ˆç•°ãªã‚‹ã‚¯ãƒ©ã‚¹ï¼‰
}

# å…¨ãƒšã‚¢ã®é¡ä¼¼åº¦
print(&quot;Tanimotoé¡ä¼¼åº¦ãƒãƒˆãƒªã‚¯ã‚¹:\n&quot;)
print(&quot;          &quot;, end=&quot;&quot;)
for name in drugs.keys():
    print(f&quot;{name:12}&quot;, end=&quot;&quot;)
print()

for name1, smiles1 in drugs.items():
    print(f&quot;{name1:10}&quot;, end=&quot;&quot;)
    for name2, smiles2 in drugs.items():
        sim = calculate_similarity(smiles1, smiles2)
        print(f&quot;{sim:12.3f}&quot;, end=&quot;&quot;)
    print()

# æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›:
#            Aspirin     Ibuprofen   Naproxen    Caffeine
# Aspirin        1.000       0.316       0.345       0.130
# Ibuprofen      0.316       1.000       0.726       0.098
# Naproxen       0.345       0.726       1.000       0.104
# Caffeine       0.130       0.098       0.104       1.000
#
# è§£é‡ˆ:
# - Ibuprofen vs Naproxen: 0.726ï¼ˆé«˜é¡ä¼¼ã€åŒã˜NSAIDã‚¯ãƒ©ã‚¹ï¼‰
# - Aspirin vs Caffeine: 0.130ï¼ˆä½é¡ä¼¼ã€ç•°ãªã‚‹ã‚¯ãƒ©ã‚¹ï¼‰
</code></pre>
<h3>Example 7: éƒ¨åˆ†æ§‹é€ æ¤œç´¢ï¼ˆSMARTSï¼‰</h3>
<pre><code class="language-python"># ===================================
# Example 7: éƒ¨åˆ†æ§‹é€ æ¤œç´¢ï¼ˆSubstructure Searchï¼‰
# ===================================

from rdkit import Chem

def has_substructure(smiles, smarts_pattern):
    &quot;&quot;&quot;åˆ†å­ãŒç‰¹å®šã®éƒ¨åˆ†æ§‹é€ ã‚’å«ã‚€ã‹ãƒã‚§ãƒƒã‚¯

    Args:
        smiles (str): SMILESæ–‡å­—åˆ—
        smarts_pattern (str): SMARTSï¼ˆéƒ¨åˆ†æ§‹é€ ã‚¯ã‚¨ãƒªï¼‰

    Returns:
        bool: å«ã‚€å ´åˆTrue
    &quot;&quot;&quot;
    mol = Chem.MolFromSmiles(smiles)
    pattern = Chem.MolFromSmarts(smarts_pattern)

    if mol is None or pattern is None:
        return False

    return mol.HasSubstructMatch(pattern)

# ã‚ˆãä½¿ã‚ã‚Œã‚‹éƒ¨åˆ†æ§‹é€ ï¼ˆæ§‹é€ ã‚¢ãƒ©ãƒ¼ãƒˆï¼‰
structural_alerts = {
    'Benzene ring': 'c1ccccc1',
    'Carboxylic acid': 'C(=O)O',
    'Ester': 'C(=O)O[C,c]',
    'Amine': '[N;!$(N=O);!$(N-O)]',
    'Nitro group': '[N+](=O)[O-]',
    'Sulfonamide': 'S(=O)(=O)N',
    'Halogen': '[F,Cl,Br,I]'
}

# ãƒ†ã‚¹ãƒˆåŒ–åˆç‰©
test_compounds = {
    'Aspirin': 'CC(=O)OC1=CC=CC=C1C(=O)O',
    'TNT': 'Cc1c(cc(c(c1[N+](=O)[O-])[N+](=O)[O-])[N+](=O)[O-])',
    'Sulfanilamide': 'c1cc(ccc1N)S(=O)(=O)N'
}

# å„åŒ–åˆç‰©ã®éƒ¨åˆ†æ§‹é€ ãƒã‚§ãƒƒã‚¯
for compound_name, smiles in test_compounds.items():
    print(f&quot;\n{compound_name} ({smiles}):&quot;)
    for alert_name, smarts in structural_alerts.items():
        has_it = has_substructure(smiles, smarts)
        print(f&quot;  {alert_name:20}: {'âœ“' if has_it else 'âœ—'}&quot;)

# æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›:
# Aspirin (CC(=O)OC1=CC=CC=C1C(=O)O):
#   Benzene ring        : âœ“
#   Carboxylic acid     : âœ“
#   Ester               : âœ“
#   Amine               : âœ—
#   Nitro group         : âœ—
#   Sulfonamide         : âœ—
#   Halogen             : âœ—
#
# TNT (Cc1c(cc(c(c1[N+](=O)[O-])[N+](=O)[O-])[N+](=O)[O-])):
#   Benzene ring        : âœ“
#   Nitro group         : âœ“  # çˆ†ç™ºæ€§ã®æŒ‡æ¨™
#   ...
#
# Sulfanilamide:
#   Benzene ring        : âœ“
#   Amine               : âœ“
#   Sulfonamide         : âœ“  # æŠ—èŒè–¬ã®ç‰¹å¾´
</code></pre>
<h3>Example 8: 3Dæ§‹é€ ç”Ÿæˆã¨æœ€é©åŒ–</h3>
<pre><code class="language-python"># ===================================
# Example 8: 3Dæ§‹é€ ç”Ÿæˆï¼ˆETKDGæ³•ï¼‰
# ===================================

from rdkit import Chem
from rdkit.Chem import AllChem
import numpy as np

def generate_3d_structure(smiles, num_confs=10):
    &quot;&quot;&quot;3Dæ§‹é€ ã‚’ç”Ÿæˆã—ã€æœ€ã‚‚ã‚¨ãƒãƒ«ã‚®ãƒ¼ãŒä½ã„é…åº§ã‚’è¿”ã™

    Args:
        smiles (str): SMILESæ–‡å­—åˆ—
        num_confs (int): ç”Ÿæˆã™ã‚‹é…åº§æ•°

    Returns:
        rdkit.Chem.Mol: 3Dæ§‹é€ ã‚’æŒã¤åˆ†å­ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
    &quot;&quot;&quot;
    mol = Chem.MolFromSmiles(smiles)
    if mol is None:
        return None

    # é™½å­è¿½åŠ 
    mol = Chem.AddHs(mol)

    # è¤‡æ•°ã®é…åº§ã‚’ç”Ÿæˆï¼ˆETKDGæ³•ï¼‰
    conf_ids = AllChem.EmbedMultipleConfs(
        mol,
        numConfs=num_confs,
        params=AllChem.ETKDGv3()
    )

    # å„é…åº§ã‚’UFFåŠ›å ´ã§æœ€é©åŒ–
    energies = []
    for conf_id in conf_ids:
        # æœ€é©åŒ–ï¼ˆåæŸã¾ã§æœ€å¤§200ã‚¹ãƒ†ãƒƒãƒ—ï¼‰
        result = AllChem.UFFOptimizeMolecule(mol, confId=conf_id, maxIters=200)

        # ã‚¨ãƒãƒ«ã‚®ãƒ¼è¨ˆç®—
        ff = AllChem.UFFGetMoleculeForceField(mol, confId=conf_id)
        energy = ff.CalcEnergy()
        energies.append((conf_id, energy))

    # æœ€ä½ã‚¨ãƒãƒ«ã‚®ãƒ¼é…åº§ã‚’é¸æŠ
    best_conf_id = min(energies, key=lambda x: x[1])[0]

    print(f&quot;ç”Ÿæˆã—ãŸé…åº§æ•°: {len(conf_ids)}&quot;)
    print(f&quot;ã‚¨ãƒãƒ«ã‚®ãƒ¼ç¯„å›²: {min(e[1] for e in energies):.2f} - {max(e[1] for e in energies):.2f} kcal/mol&quot;)
    print(f&quot;æœ€ä½ã‚¨ãƒãƒ«ã‚®ãƒ¼é…åº§ID: {best_conf_id}&quot;)

    return mol, best_conf_id

# ãƒ†ã‚¹ãƒˆ: ã‚¤ãƒ–ãƒ—ãƒ­ãƒ•ã‚§ãƒ³
ibuprofen = &quot;CC(C)Cc1ccc(cc1)[C@@H](C)C(=O)O&quot;
mol_3d, best_conf = generate_3d_structure(ibuprofen, num_confs=10)

# åŸå­åº§æ¨™ã‚’å–å¾—
if mol_3d:
    conf = mol_3d.GetConformer(best_conf)
    print(&quot;\næœ€åˆã®5åŸå­ã®åº§æ¨™ï¼ˆÃ…ï¼‰:&quot;)
    for i in range(min(5, mol_3d.GetNumAtoms())):
        pos = conf.GetAtomPosition(i)
        atom = mol_3d.GetAtomWithIdx(i)
        print(f&quot;  {atom.GetSymbol()}{i}: ({pos.x:.3f}, {pos.y:.3f}, {pos.z:.3f})&quot;)

# æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›:
# ç”Ÿæˆã—ãŸé…åº§æ•°: 10
# ã‚¨ãƒãƒ«ã‚®ãƒ¼ç¯„å›²: 45.23 - 52.18 kcal/mol
# æœ€ä½ã‚¨ãƒãƒ«ã‚®ãƒ¼é…åº§ID: 3
#
# æœ€åˆã®5åŸå­ã®åº§æ¨™ï¼ˆÃ…ï¼‰:
#   C0: (1.234, -0.567, 0.123)
#   C1: (2.345, 0.234, -0.456)
#   ...
</code></pre>
<h3>Example 9: åˆ†å­è¨˜è¿°å­ã®ä¸€æ‹¬è¨ˆç®—</h3>
<pre><code class="language-python"># ===================================
# Example 9: 200+ç¨®é¡ã®è¨˜è¿°å­ã‚’ä¸€æ‹¬è¨ˆç®—
# ===================================

from rdkit import Chem
from rdkit.Chem import Descriptors
import pandas as pd

def calculate_all_descriptors(smiles):
    &quot;&quot;&quot;RDKitã§è¨ˆç®—å¯èƒ½ãªå…¨è¨˜è¿°å­ã‚’è¨ˆç®—

    Args:
        smiles (str): SMILESæ–‡å­—åˆ—

    Returns:
        dict: è¨˜è¿°å­å: å€¤ã®è¾æ›¸
    &quot;&quot;&quot;
    mol = Chem.MolFromSmiles(smiles)
    if mol is None:
        return None

    # å…¨è¨˜è¿°å­ã‚’å–å¾—
    descriptor_names = [desc[0] for desc in Descriptors.descList]

    results = {}
    for name in descriptor_names:
        try:
            # è¨˜è¿°å­é–¢æ•°ã‚’å–å¾—ã—ã¦å®Ÿè¡Œ
            func = getattr(Descriptors, name)
            value = func(mol)
            results[name] = value
        except:
            results[name] = None

    return results

# ãƒ†ã‚¹ãƒˆ
aspirin = &quot;CC(=O)OC1=CC=CC=C1C(=O)O&quot;
descriptors = calculate_all_descriptors(aspirin)

# é‡è¦ãªè¨˜è¿°å­ã®ã¿è¡¨ç¤º
important_descriptors = [
    'MolWt', 'MolLogP', 'TPSA', 'NumHDonors', 'NumHAcceptors',
    'NumRotatableBonds', 'NumAromaticRings', 'NumSaturatedRings',
    'FractionCsp3', 'HeavyAtomCount', 'RingCount'
]

print(&quot;Aspirin ã®ä¸»è¦è¨˜è¿°å­:&quot;)
for desc_name in important_descriptors:
    if desc_name in descriptors:
        print(f&quot;  {desc_name:20}: {descriptors[desc_name]:.2f}&quot;)

# å…¨è¨˜è¿°å­ã‚’CSVä¿å­˜
df = pd.DataFrame([descriptors])
df.to_csv('aspirin_descriptors.csv', index=False)
print(f&quot;\nå…¨ {len(descriptors)} è¨˜è¿°å­ã‚’CSVä¿å­˜ã—ã¾ã—ãŸ&quot;)

# æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›:
# Aspirin ã®ä¸»è¦è¨˜è¿°å­:
#   MolWt               : 180.16
#   MolLogP             : 1.19
#   TPSA                : 63.60
#   NumHDonors          : 1.00
#   NumHAcceptors       : 4.00
#   NumRotatableBonds   : 3.00
#   NumAromaticRings    : 1.00
#   NumSaturatedRings   : 0.00
#   FractionCsp3        : 0.11
#   HeavyAtomCount      : 13.00
#   RingCount           : 1.00
#
# å…¨ 208 è¨˜è¿°å­ã‚’CSVä¿å­˜ã—ã¾ã—ãŸ
</code></pre>
<h3>Example 10: SDF/MOLãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿æ›¸ã</h3>
<pre><code class="language-python"># ===================================
# Example 10: åˆ†å­ãƒ•ã‚¡ã‚¤ãƒ«ã®I/Oï¼ˆSDFãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼‰
# ===================================

from rdkit import Chem
from rdkit.Chem import AllChem
import os

# --- æ›¸ãè¾¼ã¿ ---
def save_molecules_to_sdf(molecules_dict, filename):
    &quot;&quot;&quot;è¤‡æ•°ã®åˆ†å­ã‚’SDFãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜

    Args:
        molecules_dict (dict): {name: SMILES}
        filename (str): å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«å
    &quot;&quot;&quot;
    writer = Chem.SDWriter(filename)

    for name, smiles in molecules_dict.items():
        mol = Chem.MolFromSmiles(smiles)
        if mol is None:
            continue

        # åˆ†å­åã‚’ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã¨ã—ã¦è¿½åŠ 
        mol.SetProp(&quot;_Name&quot;, name)

        # è¿½åŠ ã®ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£
        mol.SetProp(&quot;SMILES&quot;, smiles)
        mol.SetProp(&quot;MolecularWeight&quot;, f&quot;{Chem.Descriptors.MolWt(mol):.2f}&quot;)

        # 2Dåº§æ¨™ç”Ÿæˆï¼ˆæç”»ç”¨ï¼‰
        AllChem.Compute2DCoords(mol)

        writer.write(mol)

    writer.close()
    print(f&quot;{len(molecules_dict)} åˆ†å­ã‚’ {filename} ã«ä¿å­˜ã—ã¾ã—ãŸ&quot;)

# --- èª­ã¿è¾¼ã¿ ---
def load_molecules_from_sdf(filename):
    &quot;&quot;&quot;SDFãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰åˆ†å­ã‚’èª­ã¿è¾¼ã¿

    Args:
        filename (str): SDFãƒ•ã‚¡ã‚¤ãƒ«å

    Returns:
        list: åˆ†å­ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ãƒªã‚¹ãƒˆ
    &quot;&quot;&quot;
    suppl = Chem.SDMolSupplier(filename)

    molecules = []
    for mol in suppl:
        if mol is None:
            continue
        molecules.append(mol)

    print(f&quot;{filename} ã‹ã‚‰ {len(molecules)} åˆ†å­ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ&quot;)
    return molecules

# ãƒ†ã‚¹ãƒˆ
drugs = {
    'Aspirin': 'CC(=O)OC1=CC=CC=C1C(=O)O',
    'Caffeine': 'CN1C=NC2=C1C(=O)N(C(=O)N2C)C',
    'Ibuprofen': 'CC(C)Cc1ccc(cc1)[C@@H](C)C(=O)O'
}

# ä¿å­˜
save_molecules_to_sdf(drugs, 'drugs.sdf')

# èª­ã¿è¾¼ã¿
loaded_mols = load_molecules_from_sdf('drugs.sdf')

# èª­ã¿è¾¼ã‚“ã åˆ†å­ã®æƒ…å ±è¡¨ç¤º
print(&quot;\nèª­ã¿è¾¼ã‚“ã åˆ†å­:&quot;)
for mol in loaded_mols:
    name = mol.GetProp(&quot;_Name&quot;)
    smiles = mol.GetProp(&quot;SMILES&quot;)
    mw = mol.GetProp(&quot;MolecularWeight&quot;)
    print(f&quot;  {name}: MW={mw} Da, SMILES={smiles}&quot;)

# æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›:
# 3 åˆ†å­ã‚’ drugs.sdf ã«ä¿å­˜ã—ã¾ã—ãŸ
# drugs.sdf ã‹ã‚‰ 3 åˆ†å­ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ
#
# èª­ã¿è¾¼ã‚“ã åˆ†å­:
#   Aspirin: MW=180.16 Da, SMILES=CC(=O)OC1=CC=CC=C1C(=O)O
#   Caffeine: MW=194.19 Da, SMILES=CN1C=NC2=C1C(=O)N(C(=O)N2C)C
#   Ibuprofen: MW=206.28 Da, SMILES=CC(C)Cc1ccc(cc1)[C@@H](C)C(=O)O
</code></pre>
<hr />
<h2>3.3 ChEMBLãƒ‡ãƒ¼ã‚¿å–å¾—ï¼ˆ5ã‚³ãƒ¼ãƒ‰ä¾‹ï¼‰</h2>
<h3>Example 11: ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚¿ãƒ³ãƒ‘ã‚¯è³ªæ¤œç´¢</h3>
<pre><code class="language-python"># ===================================
# Example 11: ChEMBLã§ã‚¿ãƒ¼ã‚²ãƒƒãƒˆæ¤œç´¢
# ===================================

from chembl_webresource_client.new_client import new_client

# ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
target = new_client.target

# ã‚­ãƒŠãƒ¼ã‚¼ã‚’æ¤œç´¢
kinases = target.filter(
    target_type='PROTEIN KINASE',
    organism='Homo sapiens'
).only(['target_chembl_id', 'pref_name', 'target_type'])

# æœ€åˆã®10ä»¶ã‚’è¡¨ç¤º
print(&quot;ãƒ’ãƒˆã‚­ãƒŠãƒ¼ã‚¼ï¼ˆæœ€åˆã®10ä»¶ï¼‰:\n&quot;)
for i, kinase in enumerate(kinases[:10]):
    print(f&quot;{i+1}. {kinase['pref_name']}&quot;)
    print(f&quot;   ChEMBL ID: {kinase['target_chembl_id']}&quot;)
    print()

# ç‰¹å®šã®ã‚¿ãƒ¼ã‚²ãƒƒãƒˆï¼ˆEGFRï¼‰ã‚’æ¤œç´¢
egfr = target.filter(pref_name__icontains='Epidermal growth factor receptor')[0]
print(&quot;EGFRæƒ…å ±:&quot;)
print(f&quot;  ChEMBL ID: {egfr['target_chembl_id']}&quot;)
print(f&quot;  æ­£å¼å: {egfr['pref_name']}&quot;)
print(f&quot;  ã‚¿ã‚¤ãƒ—: {egfr['target_type']}&quot;)

# æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›:
# ãƒ’ãƒˆã‚­ãƒŠãƒ¼ã‚¼ï¼ˆæœ€åˆã®10ä»¶ï¼‰:
#
# 1. Tyrosine-protein kinase ABL
#    ChEMBL ID: CHEMBL1862
#
# 2. Epidermal growth factor receptor erbB1
#    ChEMBL ID: CHEMBL203
# ...
#
# EGFRæƒ…å ±:
#   ChEMBL ID: CHEMBL203
#   æ­£å¼å: Epidermal growth factor receptor erbB1
#   ã‚¿ã‚¤ãƒ—: SINGLE PROTEIN
</code></pre>
<h3>Example 12: åŒ–åˆç‰©ã®ç”Ÿç‰©æ´»æ€§ãƒ‡ãƒ¼ã‚¿å–å¾—</h3>
<pre><code class="language-python"># ===================================
# Example 12: ç‰¹å®šã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®æ´»æ€§ãƒ‡ãƒ¼ã‚¿å–å¾—
# ===================================

from chembl_webresource_client.new_client import new_client
import pandas as pd

# ã‚¢ã‚¯ãƒ†ã‚£ãƒ“ãƒ†ã‚£ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
activity = new_client.activity

# EGFRï¼ˆCHEMBL203ï¼‰ã®æ´»æ€§ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
# pchembl_value â‰¥ 6 â†’ IC50 â‰¤ 1 Î¼M
egfr_activities = activity.filter(
    target_chembl_id='CHEMBL203',
    standard_type='IC50',
    pchembl_value__gte=6  # æ´»æ€§åŒ–åˆç‰©ã®ã¿
).only([
    'molecule_chembl_id',
    'canonical_smiles',
    'standard_value',
    'standard_units',
    'pchembl_value'
])

# ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«å¤‰æ›
data = []
for act in egfr_activities[:100]:  # æœ€åˆã®100ä»¶
    data.append({
        'ChEMBL_ID': act['molecule_chembl_id'],
        'SMILES': act['canonical_smiles'],
        'IC50': act['standard_value'],
        'Units': act['standard_units'],
        'pIC50': act['pchembl_value']
    })

df = pd.DataFrame(data)

print(f&quot;EGFRæ´»æ€§åŒ–åˆç‰©: {len(df)} ä»¶å–å¾—&quot;)
print(f&quot;\nIC50çµ±è¨ˆ:&quot;)
print(df['IC50'].describe())
print(f&quot;\næœ€åˆã®5åŒ–åˆç‰©:&quot;)
print(df.head().to_string(index=False))

# æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›:
# EGFRæ´»æ€§åŒ–åˆç‰©: 100 ä»¶å–å¾—
#
# IC50çµ±è¨ˆ:
# count    100.000000
# mean     234.560000
# std      287.450000
# min        0.500000
# 25%       45.000000
# 50%      125.000000
# 75%      350.000000
# max      950.000000
#
# æœ€åˆã®5åŒ–åˆç‰©:
#  ChEMBL_ID                                 SMILES   IC50  Units  pIC50
# CHEMBL123 COc1cc2ncnc(Nc3ccc(F)c(Cl)c3)c2cc1OC    8.9     nM   8.05
# CHEMBL456 Cc1ccc(Nc2nccc(-c3cccnc3)n2)cc1        125.0     nM   6.90
# ...
</code></pre>
<h3>Example 13: IC50ãƒ‡ãƒ¼ã‚¿ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã¨å“è³ªç®¡ç†</h3>
<pre><code class="language-python"># ===================================
# Example 13: ãƒ‡ãƒ¼ã‚¿å“è³ªç®¡ç†ã¨ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
# ===================================

from chembl_webresource_client.new_client import new_client
from rdkit import Chem
import pandas as pd
import numpy as np

def fetch_and_clean_chembl_data(target_chembl_id, min_pchembl=6, max_mw=600):
    &quot;&quot;&quot;ChEMBLãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã€å“è³ªç®¡ç†

    Args:
        target_chembl_id (str): ã‚¿ãƒ¼ã‚²ãƒƒãƒˆChEMBL ID
        min_pchembl (float): æœ€å°pChEMBLå€¤ï¼ˆæ´»æ€§é–¾å€¤ï¼‰
        max_mw (float): æœ€å¤§åˆ†å­é‡ï¼ˆè–¬ç‰©æ§˜ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ï¼‰

    Returns:
        pd.DataFrame: ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿
    &quot;&quot;&quot;
    activity = new_client.activity

    # ãƒ‡ãƒ¼ã‚¿å–å¾—
    activities = activity.filter(
        target_chembl_id=target_chembl_id,
        standard_type='IC50',
        pchembl_value__gte=min_pchembl
    )

    data = []
    for act in activities:
        if not act['canonical_smiles']:
            continue

        data.append({
            'ChEMBL_ID': act['molecule_chembl_id'],
            'SMILES': act['canonical_smiles'],
            'pIC50': act['pchembl_value']
        })

    df = pd.DataFrame(data)
    print(f&quot;åˆæœŸãƒ‡ãƒ¼ã‚¿æ•°: {len(df)}&quot;)

    # 1. é‡è¤‡é™¤å»ï¼ˆåŒã˜ChEMBL IDï¼‰
    df_unique = df.drop_duplicates(subset=['ChEMBL_ID'])
    print(f&quot;é‡è¤‡é™¤å»å¾Œ: {len(df_unique)} (-{len(df) - len(df_unique)})&quot;)

    # 2. ç„¡åŠ¹ãªSMILESé™¤å»
    valid_smiles = []
    for idx, row in df_unique.iterrows():
        mol = Chem.MolFromSmiles(row['SMILES'])
        if mol is not None:
            valid_smiles.append(idx)

    df_valid = df_unique.loc[valid_smiles]
    print(f&quot;æœ‰åŠ¹SMILES: {len(df_valid)} (-{len(df_unique) - len(df_valid)})&quot;)

    # 3. åˆ†å­é‡ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
    def get_mw(smiles):
        mol = Chem.MolFromSmiles(smiles)
        return Chem.Descriptors.MolWt(mol) if mol else 999

    df_valid['MW'] = df_valid['SMILES'].apply(get_mw)
    df_filtered = df_valid[df_valid['MW'] &lt;= max_mw]
    print(f&quot;åˆ†å­é‡â‰¤{max_mw}: {len(df_filtered)} (-{len(df_valid) - len(df_filtered)})&quot;)

    # 4. pIC50ã®ç•°å¸¸å€¤é™¤å»ï¼ˆ6-12ã®ç¯„å›²ï¼‰
    df_final = df_filtered[(df_filtered['pIC50'] &gt;= 6) &amp; (df_filtered['pIC50'] &lt;= 12)]
    print(f&quot;pIC50ç¯„å›²OK: {len(df_final)} (-{len(df_filtered) - len(df_final)})&quot;)

    print(f&quot;\næœ€çµ‚ãƒ‡ãƒ¼ã‚¿æ•°: {len(df_final)}&quot;)

    return df_final.reset_index(drop=True)

# ãƒ†ã‚¹ãƒˆ: EGFR
egfr_data = fetch_and_clean_chembl_data(
    target_chembl_id='CHEMBL203',
    min_pchembl=6.0,
    max_mw=600
)

print(&quot;\nçµ±è¨ˆ:&quot;)
print(egfr_data[['pIC50', 'MW']].describe())

# æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›:
# åˆæœŸãƒ‡ãƒ¼ã‚¿æ•°: 1523
# é‡è¤‡é™¤å»å¾Œ: 1421 (-102)
# æœ‰åŠ¹SMILES: 1415 (-6)
# åˆ†å­é‡â‰¤600: 1203 (-212)
# pIC50ç¯„å›²OK: 1198 (-5)
#
# æœ€çµ‚ãƒ‡ãƒ¼ã‚¿æ•°: 1198
#
# çµ±è¨ˆ:
#        pIC50          MW
# count  1198.0     1198.0
# mean      7.2      385.4
# std       0.9       78.3
# min       6.0      150.2
# max      11.2      599.8
</code></pre>
<h3>Example 14: æ§‹é€ -æ´»æ€§ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ§‹ç¯‰</h3>
<pre><code class="language-python"># ===================================
# Example 14: QSARç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ§‹ç¯‰ï¼ˆECFP + pIC50ï¼‰
# ===================================

from chembl_webresource_client.new_client import new_client
from rdkit import Chem
from rdkit.Chem import AllChem
import pandas as pd
import numpy as np

def build_qsar_dataset(target_chembl_id, n_bits=2048, radius=2):
    &quot;&quot;&quot;QSARç”¨ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆX: ECFP, y: pIC50ï¼‰ã‚’æ§‹ç¯‰

    Args:
        target_chembl_id (str): ã‚¿ãƒ¼ã‚²ãƒƒãƒˆChEMBL ID
        n_bits (int): ECFP ãƒ“ãƒƒãƒˆé•·
        radius (int): ECFP åŠå¾„

    Returns:
        X (np.ndarray): åˆ†å­æŒ‡ç´‹ï¼ˆshape: [n_samples, n_bits]ï¼‰
        y (np.ndarray): pIC50å€¤ï¼ˆshape: [n_samples,]ï¼‰
        smiles_list (list): SMILESæ–‡å­—åˆ—ãƒªã‚¹ãƒˆ
    &quot;&quot;&quot;
    activity = new_client.activity

    # ãƒ‡ãƒ¼ã‚¿å–å¾—
    activities = activity.filter(
        target_chembl_id=target_chembl_id,
        standard_type='IC50',
        pchembl_value__gte=5  # pIC50 â‰¥ 5ï¼ˆIC50 â‰¤ 10 Î¼Mï¼‰
    )

    X_list = []
    y_list = []
    smiles_list = []

    for act in activities[:1000]:  # æœ€å¤§1000åŒ–åˆç‰©
        smiles = act['canonical_smiles']
        pchembl = act['pchembl_value']

        if not smiles or not pchembl:
            continue

        mol = Chem.MolFromSmiles(smiles)
        if mol is None:
            continue

        # ECFPç”Ÿæˆ
        fp = AllChem.GetMorganFingerprintAsBitVect(mol, radius, n_bits)
        arr = np.zeros((n_bits,), dtype=int)
        AllChem.DataStructs.ConvertToNumpyArray(fp, arr)

        X_list.append(arr)
        y_list.append(float(pchembl))
        smiles_list.append(smiles)

    X = np.array(X_list)
    y = np.array(y_list)

    print(f&quot;ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ§‹ç¯‰å®Œäº†:&quot;)
    print(f&quot;  åŒ–åˆç‰©æ•°: {len(y)}&quot;)
    print(f&quot;  ç‰¹å¾´é‡æ¬¡å…ƒ: {X.shape[1]}&quot;)
    print(f&quot;  pIC50ç¯„å›²: {y.min():.2f} - {y.max():.2f}&quot;)
    print(f&quot;  å¹³å‡pIC50: {y.mean():.2f} Â± {y.std():.2f}&quot;)

    return X, y, smiles_list

# ãƒ†ã‚¹ãƒˆ: EGFR
X, y, smiles = build_qsar_dataset('CHEMBL203', n_bits=2048, radius=2)

# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ä¿å­˜
np.save('egfr_X.npy', X)
np.save('egfr_y.npy', y)
with open('egfr_smiles.txt', 'w') as f:
    f.write('\n'.join(smiles))

print(&quot;\nãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä¿å­˜ã—ã¾ã—ãŸ:&quot;)
print(&quot;  egfr_X.npy (åˆ†å­æŒ‡ç´‹)&quot;)
print(&quot;  egfr_y.npy (pIC50)&quot;)
print(&quot;  egfr_smiles.txt (SMILES)&quot;)

# æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›:
# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ§‹ç¯‰å®Œäº†:
#   åŒ–åˆç‰©æ•°: 892
#   ç‰¹å¾´é‡æ¬¡å…ƒ: 2048
#   pIC50ç¯„å›²: 5.00 - 11.15
#   å¹³å‡pIC50: 7.23 Â± 1.12
#
# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä¿å­˜ã—ã¾ã—ãŸ:
#   egfr_X.npy (åˆ†å­æŒ‡ç´‹)
#   egfr_y.npy (pIC50)
#   egfr_smiles.txt (SMILES)
</code></pre>
<h3>Example 15: ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†ã¨ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°</h3>
<pre><code class="language-python"># ===================================
# Example 15: å¤–ã‚Œå€¤é™¤å»ã¨ãƒ‡ãƒ¼ã‚¿ã‚¹ãƒ—ãƒªãƒƒãƒˆ
# ===================================

import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt

def preprocess_qsar_data(X, y, test_size=0.2, random_state=42, remove_outliers=True):
    &quot;&quot;&quot;QSARãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†

    Args:
        X (np.ndarray): ç‰¹å¾´é‡
        y (np.ndarray): ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ
        test_size (float): ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿å‰²åˆ
        random_state (int): ä¹±æ•°ã‚·ãƒ¼ãƒ‰
        remove_outliers (bool): å¤–ã‚Œå€¤é™¤å»ã™ã‚‹ã‹

    Returns:
        X_train, X_test, y_train, y_test
    &quot;&quot;&quot;
    print(f&quot;å‰å‡¦ç†å‰: {len(y)} ã‚µãƒ³ãƒ—ãƒ«&quot;)

    # 1. å¤–ã‚Œå€¤é™¤å»ï¼ˆIQRæ³•ï¼‰
    if remove_outliers:
        Q1 = np.percentile(y, 25)
        Q3 = np.percentile(y, 75)
        IQR = Q3 - Q1

        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR

        mask = (y &gt;= lower_bound) &amp; (y &lt;= upper_bound)
        X = X[mask]
        y = y[mask]

        print(f&quot;å¤–ã‚Œå€¤é™¤å»å¾Œ: {len(y)} ã‚µãƒ³ãƒ—ãƒ« ({np.sum(~mask)} ä»¶é™¤å»)&quot;)

    # 2. Train/Teståˆ†å‰²
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_size, random_state=random_state
    )

    print(f&quot;è¨“ç·´ãƒ‡ãƒ¼ã‚¿: {len(y_train)} ã‚µãƒ³ãƒ—ãƒ«&quot;)
    print(f&quot;ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {len(y_test)} ã‚µãƒ³ãƒ—ãƒ«&quot;)

    # 3. çµ±è¨ˆ
    print(f&quot;\nè¨“ç·´ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆ:&quot;)
    print(f&quot;  pIC50å¹³å‡: {y_train.mean():.2f} Â± {y_train.std():.2f}&quot;)
    print(f&quot;  pIC50ç¯„å›²: {y_train.min():.2f} - {y_train.max():.2f}&quot;)

    print(f&quot;\nãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿çµ±è¨ˆ:&quot;)
    print(f&quot;  pIC50å¹³å‡: {y_test.mean():.2f} Â± {y_test.std():.2f}&quot;)
    print(f&quot;  pIC50ç¯„å›²: {y_test.min():.2f} - {y_test.max():.2f}&quot;)

    # 4. åˆ†å¸ƒã®å¯è¦–åŒ–
    fig, axes = plt.subplots(1, 2, figsize=(12, 4))

    axes[0].hist(y_train, bins=30, alpha=0.7, label='Train')
    axes[0].hist(y_test, bins=30, alpha=0.7, label='Test')
    axes[0].set_xlabel('pIC50')
    axes[0].set_ylabel('Frequency')
    axes[0].set_title('pIC50 Distribution')
    axes[0].legend()

    axes[1].boxplot([y_train, y_test], labels=['Train', 'Test'])
    axes[1].set_ylabel('pIC50')
    axes[1].set_title('pIC50 Box Plot')

    plt.tight_layout()
    plt.savefig('data_distribution.png', dpi=150)
    print(&quot;\nåˆ†å¸ƒã‚°ãƒ©ãƒ•ã‚’ä¿å­˜: data_distribution.png&quot;)

    return X_train, X_test, y_train, y_test

# ãƒ†ã‚¹ãƒˆï¼ˆå‰ã®Exampleã§ä½œæˆã—ãŸãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ï¼‰
X = np.load('egfr_X.npy')
y = np.load('egfr_y.npy')

X_train, X_test, y_train, y_test = preprocess_qsar_data(
    X, y, test_size=0.2, remove_outliers=True
)

# ä¿å­˜
np.save('X_train.npy', X_train)
np.save('X_test.npy', X_test)
np.save('y_train.npy', y_train)
np.save('y_test.npy', y_test)
print(&quot;\nå‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¾ã—ãŸ&quot;)

# æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›:
# å‰å‡¦ç†å‰: 892 ã‚µãƒ³ãƒ—ãƒ«
# å¤–ã‚Œå€¤é™¤å»å¾Œ: 875 ã‚µãƒ³ãƒ—ãƒ« (17 ä»¶é™¤å»)
# è¨“ç·´ãƒ‡ãƒ¼ã‚¿: 700 ã‚µãƒ³ãƒ—ãƒ«
# ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: 175 ã‚µãƒ³ãƒ—ãƒ«
#
# è¨“ç·´ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆ:
#   pIC50å¹³å‡: 7.21 Â± 0.98
#   pIC50ç¯„å›²: 5.10 - 10.52
#
# ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿çµ±è¨ˆ:
#   pIC50å¹³å‡: 7.25 Â± 1.02
#   pIC50ç¯„å›²: 5.15 - 10.48
#
# åˆ†å¸ƒã‚°ãƒ©ãƒ•ã‚’ä¿å­˜: data_distribution.png
# å‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¾ã—ãŸ
</code></pre>
<hr />
<h2>3.4 QSARãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰ï¼ˆ8ã‚³ãƒ¼ãƒ‰ä¾‹ï¼‰</h2>
<p>ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§ã¯ã€å‰å‡¦ç†æ¸ˆã¿ã®EGFRãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆX_train.npyç­‰ï¼‰ã‚’ä½¿ç”¨ã—ã¦ã€å®Ÿéš›ã«QSARãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã—ã¾ã™ã€‚</p>
<h3>Example 16: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåˆ†å‰²ï¼ˆTrain/Testï¼‰</h3>
<pre><code class="language-python"># ===================================
# Example 16: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåˆ†å‰²ï¼ˆå‰ã®Exampleã§å®Ÿæ–½æ¸ˆã¿ï¼‰
# ===================================

# ã™ã§ã«Example 15ã§å®Ÿæ–½æ¸ˆã¿ã®ãŸã‚ã€ã“ã“ã§ã¯èª­ã¿è¾¼ã¿ã®ã¿
import numpy as np

# å‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
X_train = np.load('X_train.npy')
X_test = np.load('X_test.npy')
y_train = np.load('y_train.npy')
y_test = np.load('y_test.npy')

print(&quot;ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆèª­ã¿è¾¼ã¿å®Œäº†:&quot;)
print(f&quot;  X_train shape: {X_train.shape}&quot;)
print(f&quot;  X_test shape: {X_test.shape}&quot;)
print(f&quot;  y_train shape: {y_train.shape}&quot;)
print(f&quot;  y_test shape: {y_test.shape}&quot;)

# æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›:
# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆèª­ã¿è¾¼ã¿å®Œäº†:
#   X_train shape: (700, 2048)
#   X_test shape: (175, 2048)
#   y_train shape: (700,)
#   y_test shape: (175,)
</code></pre>
<h3>Example 17: Random Foreståˆ†é¡å™¨ï¼ˆæ´»æ€§/éæ´»æ€§ï¼‰</h3>
<pre><code class="language-python"># ===================================
# Example 17: Random Forest åˆ†é¡ï¼ˆActive/Inactiveï¼‰
# ===================================

import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
X_train = np.load('X_train.npy')
X_test = np.load('X_test.npy')
y_train = np.load('y_train.npy')
y_test = np.load('y_test.npy')

# pIC50ã‚’2å€¤åˆ†é¡ã«å¤‰æ›ï¼ˆé–¾å€¤: 7.0ï¼‰
# pIC50 â‰¥ 7.0 â†’ Active (1)  [IC50 â‰¤ 100 nM]
# pIC50 &lt; 7.0 â†’ Inactive (0)
threshold = 7.0
y_train_binary = (y_train &gt;= threshold).astype(int)
y_test_binary = (y_test &gt;= threshold).astype(int)

print(f&quot;ã‚¯ãƒ©ã‚¹åˆ†å¸ƒï¼ˆè¨“ç·´ãƒ‡ãƒ¼ã‚¿ï¼‰:&quot;)
print(f&quot;  Active: {np.sum(y_train_binary == 1)} ({np.mean(y_train_binary)*100:.1f}%)&quot;)
print(f&quot;  Inactive: {np.sum(y_train_binary == 0)} ({(1-np.mean(y_train_binary))*100:.1f}%)&quot;)

# Random Forestãƒ¢ãƒ‡ãƒ«
rf_clf = RandomForestClassifier(
    n_estimators=100,
    max_depth=20,
    min_samples_leaf=5,
    n_jobs=-1,
    random_state=42
)

# è¨“ç·´
print(&quot;\nãƒ¢ãƒ‡ãƒ«è¨“ç·´ä¸­...&quot;)
rf_clf.fit(X_train, y_train_binary)

# äºˆæ¸¬
y_pred_binary = rf_clf.predict(X_test)
y_pred_proba = rf_clf.predict_proba(X_test)[:, 1]  # Activeç¢ºç‡

# è©•ä¾¡
print(&quot;\n=== æ€§èƒ½è©•ä¾¡ ===&quot;)
print(classification_report(
    y_test_binary, y_pred_binary,
    target_names=['Inactive', 'Active']
))

roc_auc = roc_auc_score(y_test_binary, y_pred_proba)
print(f&quot;ROC-AUC: {roc_auc:.3f}&quot;)

# Confusion Matrix
cm = confusion_matrix(y_test_binary, y_pred_binary)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Inactive', 'Active'],
            yticklabels=['Inactive', 'Active'])
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title(f'Confusion Matrix (ROC-AUC: {roc_auc:.3f})')
plt.tight_layout()
plt.savefig('rf_classifier_cm.png', dpi=150)
print(&quot;\nConfusion Matrixã‚’ä¿å­˜: rf_classifier_cm.png&quot;)

# æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›:
# ã‚¯ãƒ©ã‚¹åˆ†å¸ƒï¼ˆè¨“ç·´ãƒ‡ãƒ¼ã‚¿ï¼‰:
#   Active: 385 (55.0%)
#   Inactive: 315 (45.0%)
#
# ãƒ¢ãƒ‡ãƒ«è¨“ç·´ä¸­...
#
# === æ€§èƒ½è©•ä¾¡ ===
#               precision    recall  f1-score   support
#
#     Inactive       0.82      0.78      0.80        79
#       Active       0.81      0.85      0.83        96
#
#     accuracy                           0.82       175
#    macro avg       0.82      0.82      0.82       175
# weighted avg       0.82      0.82      0.82       175
#
# ROC-AUC: 0.877
#
# Confusion Matrixã‚’ä¿å­˜: rf_classifier_cm.png
</code></pre>
<h3>Example 18: Random Forestå›å¸°ï¼ˆIC50äºˆæ¸¬ï¼‰</h3>
<pre><code class="language-python"># ===================================
# Example 18: Random Forest å›å¸°ï¼ˆpIC50äºˆæ¸¬ï¼‰
# ===================================

import numpy as np
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import matplotlib.pyplot as plt

# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
X_train = np.load('X_train.npy')
X_test = np.load('X_test.npy')
y_train = np.load('y_train.npy')
y_test = np.load('y_test.npy')

# Random Forestå›å¸°
rf_reg = RandomForestRegressor(
    n_estimators=100,
    max_depth=20,
    min_samples_leaf=5,
    n_jobs=-1,
    random_state=42
)

# è¨“ç·´
print(&quot;ãƒ¢ãƒ‡ãƒ«è¨“ç·´ä¸­...&quot;)
rf_reg.fit(X_train, y_train)

# äºˆæ¸¬
y_pred_train = rf_reg.predict(X_train)
y_pred_test = rf_reg.predict(X_test)

# è©•ä¾¡
print(&quot;\n=== è¨“ç·´ãƒ‡ãƒ¼ã‚¿æ€§èƒ½ ===&quot;)
print(f&quot;RÂ²: {r2_score(y_train, y_pred_train):.3f}&quot;)
print(f&quot;MAE: {mean_absolute_error(y_train, y_pred_train):.3f}&quot;)
print(f&quot;RMSE: {np.sqrt(mean_squared_error(y_train, y_pred_train)):.3f}&quot;)

print(&quot;\n=== ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿æ€§èƒ½ ===&quot;)
r2 = r2_score(y_test, y_pred_test)
mae = mean_absolute_error(y_test, y_pred_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))

print(f&quot;RÂ²: {r2:.3f}&quot;)
print(f&quot;MAE: {mae:.3f}&quot;)
print(f&quot;RMSE: {rmse:.3f}&quot;)

# æ•£å¸ƒå›³
fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# è¨“ç·´ãƒ‡ãƒ¼ã‚¿
axes[0].scatter(y_train, y_pred_train, alpha=0.5, s=20)
axes[0].plot([y_train.min(), y_train.max()],
             [y_train.min(), y_train.max()],
             'r--', lw=2)
axes[0].set_xlabel('True pIC50')
axes[0].set_ylabel('Predicted pIC50')
axes[0].set_title(f'Training Set (RÂ²={r2_score(y_train, y_pred_train):.3f})')
axes[0].grid(True, alpha=0.3)

# ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
axes[1].scatter(y_test, y_pred_test, alpha=0.5, s=20, c='orange')
axes[1].plot([y_test.min(), y_test.max()],
             [y_test.min(), y_test.max()],
             'r--', lw=2)
axes[1].set_xlabel('True pIC50')
axes[1].set_ylabel('Predicted pIC50')
axes[1].set_title(f'Test Set (RÂ²={r2:.3f}, MAE={mae:.3f})')
axes[1].grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('rf_regression_scatter.png', dpi=150)
print(&quot;\næ•£å¸ƒå›³ã‚’ä¿å­˜: rf_regression_scatter.png&quot;)

# æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›:
# ãƒ¢ãƒ‡ãƒ«è¨“ç·´ä¸­...
#
# === è¨“ç·´ãƒ‡ãƒ¼ã‚¿æ€§èƒ½ ===
# RÂ²: 0.945
# MAE: 0.195
# RMSE: 0.232
#
# === ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿æ€§èƒ½ ===
# RÂ²: 0.738
# MAE: 0.452
# RMSE: 0.523
#
# æ•£å¸ƒå›³ã‚’ä¿å­˜: rf_regression_scatter.png
#
# è§£é‡ˆ:
# - è¨“ç·´RÂ² (0.945) &gt;&gt; ãƒ†ã‚¹ãƒˆRÂ² (0.738) â†’ ã‚„ã‚„éå­¦ç¿’æ°—å‘³
# - ãƒ†ã‚¹ãƒˆRÂ² = 0.738ã¯å®Ÿç”¨çš„ãªç¯„å›²ï¼ˆç›®æ¨™0.70ã‚¯ãƒªã‚¢ï¼‰
# - MAE = 0.452 â†’ äºˆæ¸¬èª¤å·®ã¯ç´„Â±0.5 pIC50å˜ä½ï¼ˆç´„3å€ã®IC50èª¤å·®ï¼‰
</code></pre>
<h3>Example 19: SVMå›å¸°ï¼ˆã‚µãƒãƒ¼ãƒˆãƒ™ã‚¯ã‚¿ãƒ¼ãƒã‚·ãƒ³ï¼‰</h3>
<pre><code class="language-python"># ===================================
# Example 19: Support Vector Regressionï¼ˆSVRï¼‰
# ===================================

import numpy as np
from sklearn.svm import SVR
from sklearn.metrics import mean_absolute_error, r2_score
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
import time

# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
X_train = np.load('X_train.npy')
X_test = np.load('X_test.npy')
y_train = np.load('y_train.npy')
y_test = np.load('y_test.npy')

# SVMã¯ç‰¹å¾´é‡ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ãŒé‡è¦
print(&quot;ç‰¹å¾´é‡ã®æ¨™æº–åŒ–ä¸­...&quot;)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# SVRãƒ¢ãƒ‡ãƒ«ï¼ˆRBFã‚«ãƒ¼ãƒãƒ«ï¼‰
svr = SVR(
    kernel='rbf',
    C=10.0,           # æ­£å‰‡åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    epsilon=0.1,      # Îµãƒãƒ¥ãƒ¼ãƒ–ã®å¹…
    gamma='scale'     # RBFã‚«ãƒ¼ãƒãƒ«å¹…
)

# è¨“ç·´ï¼ˆæ™‚é–“è¨ˆæ¸¬ï¼‰
print(&quot;\nSVRãƒ¢ãƒ‡ãƒ«è¨“ç·´ä¸­...&quot;)
start_time = time.time()
svr.fit(X_train_scaled, y_train)
training_time = time.time() - start_time
print(f&quot;è¨“ç·´æ™‚é–“: {training_time:.2f} ç§’&quot;)

# äºˆæ¸¬
y_pred_train = svr.predict(X_train_scaled)
y_pred_test = svr.predict(X_test_scaled)

# è©•ä¾¡
print(&quot;\n=== è¨“ç·´ãƒ‡ãƒ¼ã‚¿æ€§èƒ½ ===&quot;)
print(f&quot;RÂ²: {r2_score(y_train, y_pred_train):.3f}&quot;)
print(f&quot;MAE: {mean_absolute_error(y_train, y_pred_train):.3f}&quot;)

print(&quot;\n=== ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿æ€§èƒ½ ===&quot;)
r2 = r2_score(y_test, y_pred_test)
mae = mean_absolute_error(y_test, y_pred_test)
print(f&quot;RÂ²: {r2:.3f}&quot;)
print(f&quot;MAE: {mae:.3f}&quot;)

# ã‚µãƒãƒ¼ãƒˆãƒ™ã‚¯ã‚¿ãƒ¼æ•°
print(f&quot;\nã‚µãƒãƒ¼ãƒˆãƒ™ã‚¯ã‚¿ãƒ¼æ•°: {len(svr.support_)} / {len(y_train)} ({len(svr.support_)/len(y_train)*100:.1f}%)&quot;)

# æ•£å¸ƒå›³
plt.figure(figsize=(7, 6))
plt.scatter(y_test, y_pred_test, alpha=0.6, s=30)
plt.plot([y_test.min(), y_test.max()],
         [y_test.min(), y_test.max()],
         'r--', lw=2, label='Perfect prediction')
plt.xlabel('True pIC50')
plt.ylabel('Predicted pIC50')
plt.title(f'SVR Performance (RÂ²={r2:.3f}, MAE={mae:.3f})')
plt.legend()
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.savefig('svr_prediction.png', dpi=150)
print(&quot;\nã‚°ãƒ©ãƒ•ã‚’ä¿å­˜: svr_prediction.png&quot;)

# æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›:
# ç‰¹å¾´é‡ã®æ¨™æº–åŒ–ä¸­...
#
# SVRãƒ¢ãƒ‡ãƒ«è¨“ç·´ä¸­...
# è¨“ç·´æ™‚é–“: 12.45 ç§’
#
# === è¨“ç·´ãƒ‡ãƒ¼ã‚¿æ€§èƒ½ ===
# RÂ²: 0.823
# MAE: 0.352
#
# === ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿æ€§èƒ½ ===
# RÂ²: 0.712
# MAE: 0.478
#
# ã‚µãƒãƒ¼ãƒˆãƒ™ã‚¯ã‚¿ãƒ¼æ•°: 412 / 700 (58.9%)
#
# ã‚°ãƒ©ãƒ•ã‚’ä¿å­˜: svr_prediction.png
#
# ç‰¹å¾´:
# - SVRã¯Random Forestã‚ˆã‚Šæ±åŒ–æ€§èƒ½ãŒã‚„ã‚„ä½ã„ï¼ˆRÂ²=0.712 vs 0.738ï¼‰
# - è¨“ç·´æ™‚é–“ãŒé•·ã„ï¼ˆ12ç§’ vs RFã®2ç§’ç¨‹åº¦ï¼‰
# - ã‚µãƒãƒ¼ãƒˆãƒ™ã‚¯ã‚¿ãƒ¼æ•°ãŒå¤šã„ = è¤‡é›‘ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å­¦ç¿’
</code></pre>
<h3>Example 20: ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼ˆKerasï¼‰</h3>
<pre><code class="language-python"># ===================================
# Example 20: Deep Neural Networkï¼ˆDNNï¼‰- Keras/TensorFlow
# ===================================

import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_absolute_error, r2_score
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import matplotlib.pyplot as plt

# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
X_train = np.load('X_train.npy').astype('float32')
X_test = np.load('X_test.npy').astype('float32')
y_train = np.load('y_train.npy').astype('float32')
y_test = np.load('y_test.npy').astype('float32')

# æ¨™æº–åŒ–
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# DNNãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰
model = keras.Sequential([
    layers.Dense(512, activation='relu', input_shape=(2048,)),
    layers.Dropout(0.3),
    layers.Dense(256, activation='relu'),
    layers.Dropout(0.3),
    layers.Dense(128, activation='relu'),
    layers.Dropout(0.2),
    layers.Dense(64, activation='relu'),
    layers.Dense(1)  # å›å¸°ã‚¿ã‚¹ã‚¯ï¼ˆå‡ºåŠ›1ã¤ï¼‰
])

# ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«
model.compile(
    optimizer=keras.optimizers.Adam(learning_rate=0.001),
    loss='mse',
    metrics=['mae']
)

# ãƒ¢ãƒ‡ãƒ«ã‚µãƒãƒªãƒ¼
print(&quot;ãƒ¢ãƒ‡ãƒ«æ§‹é€ :&quot;)
model.summary()

# Early Stoppingï¼ˆéå­¦ç¿’é˜²æ­¢ï¼‰
early_stop = keras.callbacks.EarlyStopping(
    monitor='val_loss',
    patience=20,
    restore_best_weights=True
)

# è¨“ç·´
print(&quot;\nè¨“ç·´ä¸­...&quot;)
history = model.fit(
    X_train_scaled, y_train,
    validation_split=0.2,
    epochs=200,
    batch_size=32,
    callbacks=[early_stop],
    verbose=0
)

print(f&quot;\nè¨“ç·´å®Œäº†: {len(history.history['loss'])} ã‚¨ãƒãƒƒã‚¯&quot;)

# äºˆæ¸¬
y_pred_train = model.predict(X_train_scaled, verbose=0).flatten()
y_pred_test = model.predict(X_test_scaled, verbose=0).flatten()

# è©•ä¾¡
print(&quot;\n=== è¨“ç·´ãƒ‡ãƒ¼ã‚¿æ€§èƒ½ ===&quot;)
print(f&quot;RÂ²: {r2_score(y_train, y_pred_train):.3f}&quot;)
print(f&quot;MAE: {mean_absolute_error(y_train, y_pred_train):.3f}&quot;)

print(&quot;\n=== ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿æ€§èƒ½ ===&quot;)
r2 = r2_score(y_test, y_pred_test)
mae = mean_absolute_error(y_test, y_pred_test)
print(f&quot;RÂ²: {r2:.3f}&quot;)
print(f&quot;MAE: {mae:.3f}&quot;)

# å­¦ç¿’æ›²ç·š
fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# Loss
axes[0].plot(history.history['loss'], label='Train Loss')
axes[0].plot(history.history['val_loss'], label='Validation Loss')
axes[0].set_xlabel('Epoch')
axes[0].set_ylabel('MSE Loss')
axes[0].set_title('Learning Curve - Loss')
axes[0].legend()
axes[0].grid(True, alpha=0.3)

# MAE
axes[1].plot(history.history['mae'], label='Train MAE')
axes[1].plot(history.history['val_mae'], label='Validation MAE')
axes[1].set_xlabel('Epoch')
axes[1].set_ylabel('MAE')
axes[1].set_title('Learning Curve - MAE')
axes[1].legend()
axes[1].grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('dnn_learning_curve.png', dpi=150)
print(&quot;\nå­¦ç¿’æ›²ç·šã‚’ä¿å­˜: dnn_learning_curve.png&quot;)

# ãƒ¢ãƒ‡ãƒ«ä¿å­˜
model.save('egfr_dnn_model.h5')
print(&quot;ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜: egfr_dnn_model.h5&quot;)

# æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›:
# ãƒ¢ãƒ‡ãƒ«æ§‹é€ :
# Model: &quot;sequential&quot;
# _________________________________________________________________
# Layer (type)                Output Shape              Param #
# =================================================================
# dense (Dense)               (None, 512)               1,049,088
# dropout (Dropout)           (None, 512)               0
# dense_1 (Dense)             (None, 256)               131,328
# dropout_1 (Dropout)         (None, 256)               0
# dense_2 (Dense)             (None, 128)               32,896
# dropout_2 (Dropout)         (None, 128)               0
# dense_3 (Dense)             (None, 64)                8,256
# dense_4 (Dense)             (None, 1)                 65
# =================================================================
# Total params: 1,221,633
# Trainable params: 1,221,633
#
# è¨“ç·´å®Œäº†: 87 ã‚¨ãƒãƒƒã‚¯
#
# === è¨“ç·´ãƒ‡ãƒ¼ã‚¿æ€§èƒ½ ===
# RÂ²: 0.892
# MAE: 0.278
#
# === ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿æ€§èƒ½ ===
# RÂ²: 0.756
# MAE: 0.438
#
# å­¦ç¿’æ›²ç·šã‚’ä¿å­˜: dnn_learning_curve.png
# ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜: egfr_dnn_model.h5
#
# è€ƒå¯Ÿ:
# - DNNï¼ˆRÂ²=0.756ï¼‰ã¯Random Forestï¼ˆ0.738ï¼‰ã‚ˆã‚Šè‹¥å¹²å„ªã‚Œã¦ã„ã‚‹
# - Early Stoppingã«ã‚ˆã‚Šéå­¦ç¿’ã‚’æŠ‘åˆ¶ï¼ˆ87ã‚¨ãƒãƒƒã‚¯ã§åœæ­¢ï¼‰
# - Dropoutå±¤ãŒæ±åŒ–æ€§èƒ½å‘ä¸Šã«å¯„ä¸
</code></pre>
<h3>Example 21: ç‰¹å¾´é‡é‡è¦åº¦åˆ†æ</h3>
<pre><code class="language-python"># ===================================
# Example 21: Feature Importanceï¼ˆRandom Forestã®å ´åˆï¼‰
# ===================================

import numpy as np
from sklearn.ensemble import RandomForestRegressor
from rdkit import Chem
from rdkit.Chem import AllChem
import matplotlib.pyplot as plt

# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
X_train = np.load('X_train.npy')
y_train = np.load('y_train.npy')

# SMILESèª­ã¿è¾¼ã¿ï¼ˆãƒ“ãƒƒãƒˆè§£é‡ˆç”¨ï¼‰
with open('egfr_smiles.txt', 'r') as f:
    smiles_list = [line.strip() for line in f.readlines()]

# Random Forestã§è¨“ç·´
rf_reg = RandomForestRegressor(
    n_estimators=100,
    max_depth=20,
    n_jobs=-1,
    random_state=42
)
rf_reg.fit(X_train, y_train)

# ç‰¹å¾´é‡é‡è¦åº¦
feature_importances = rf_reg.feature_importances_

# ä¸Šä½20ãƒ“ãƒƒãƒˆã‚’æŠ½å‡º
top_indices = np.argsort(feature_importances)[::-1][:20]
top_importances = feature_importances[top_indices]

print(&quot;æœ€ã‚‚é‡è¦ãª20ãƒ“ãƒƒãƒˆ:&quot;)
for i, (idx, importance) in enumerate(zip(top_indices, top_importances), 1):
    print(f&quot;{i:2}. Bit {idx:4}: {importance:.5f}&quot;)

# ECFPæƒ…å ±ã‚’å–å¾—ï¼ˆã©ã®éƒ¨åˆ†æ§‹é€ ã«å¯¾å¿œã™ã‚‹ã‹ï¼‰
def get_bit_info(smiles, radius=2, n_bits=2048):
    &quot;&quot;&quot;ECFPãƒ“ãƒƒãƒˆã«å¯¾å¿œã™ã‚‹éƒ¨åˆ†æ§‹é€ æƒ…å ±ã‚’å–å¾—&quot;&quot;&quot;
    mol = Chem.MolFromSmiles(smiles)
    if mol is None:
        return {}

    info = {}
    fp = AllChem.GetMorganFingerprintAsBitVect(
        mol, radius, nBits=n_bits, bitInfo=info
    )
    return info

# æœ€åˆã®ã‚µãƒ³ãƒ—ãƒ«ã§ãƒ“ãƒƒãƒˆæƒ…å ±ã‚’èª¿ã¹ã‚‹
sample_smiles = smiles_list[0]
bit_info = get_bit_info(sample_smiles)

print(f&quot;\nä¾‹: {sample_smiles[:50]}...&quot;)
print(f&quot;ãƒ“ãƒƒãƒˆæƒ…å ±ï¼ˆæœ€åˆã®5ã¤ï¼‰:&quot;)
for bit_idx in list(bit_info.keys())[:5]:
    atom_ids, radius_val = bit_info[bit_idx][0]
    print(f&quot;  Bit {bit_idx}: åŸå­{atom_ids}ã‚’ä¸­å¿ƒï¼ˆåŠå¾„{radius_val}ï¼‰&quot;)

# é‡è¦åº¦ã®å¯è¦–åŒ–
plt.figure(figsize=(10, 6))
plt.barh(range(20), top_importances[::-1])
plt.yticks(range(20), [f'Bit {idx}' for idx in top_indices[::-1]])
plt.xlabel('Feature Importance')
plt.title('Top 20 Most Important ECFP Bits')
plt.tight_layout()
plt.savefig('feature_importance.png', dpi=150)
print(&quot;\nç‰¹å¾´é‡é‡è¦åº¦ã‚’ä¿å­˜: feature_importance.png&quot;)

# æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›:
# æœ€ã‚‚é‡è¦ãª20ãƒ“ãƒƒãƒˆ:
#  1. Bit 1234: 0.02345
#  2. Bit  567: 0.01892
#  3. Bit 1987: 0.01654
#  ...
# 20. Bit  123: 0.00876
#
# ä¾‹: COc1cc2ncnc(Nc3ccc(F)c(Cl)c3)c2cc1OC...
# ãƒ“ãƒƒãƒˆæƒ…å ±ï¼ˆæœ€åˆã®5ã¤ï¼‰:
#   Bit 1234: åŸå­15ã‚’ä¸­å¿ƒï¼ˆåŠå¾„2ï¼‰
#   Bit 567: åŸå­8ã‚’ä¸­å¿ƒï¼ˆåŠå¾„1ï¼‰
#   ...
#
# ç‰¹å¾´é‡é‡è¦åº¦ã‚’ä¿å­˜: feature_importance.png
#
# è§£é‡ˆ:
# - ECFPã®2048ãƒ“ãƒƒãƒˆä¸­ã€ä¸Šä½20ãƒ“ãƒƒãƒˆã§ç´„15%ã®é‡è¦åº¦ã‚’å ã‚ã‚‹
# - ç‰¹å®šã®éƒ¨åˆ†æ§‹é€ ï¼ˆã‚­ãƒŠãƒ¼ã‚¼çµåˆéƒ¨ä½ãªã©ï¼‰ãŒæ´»æ€§ã«å¼·ãå¯„ä¸
# - ãƒ“ãƒƒãƒˆæƒ…å ±ã‹ã‚‰ã€é‡è¦ãªæ§‹é€ çš„ç‰¹å¾´ã‚’ç‰¹å®šå¯èƒ½
</code></pre>
<h3>Example 22: ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã¨ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°</h3>
<pre><code class="language-python"># ===================================
# Example 22: Grid Search CVï¼ˆãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–ï¼‰
# ===================================

import numpy as np
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import GridSearchCV, cross_val_score
from sklearn.metrics import make_scorer, r2_score, mean_absolute_error
import time

# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
X_train = np.load('X_train.npy')
y_train = np.load('y_train.npy')

# ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ã‚°ãƒªãƒƒãƒ‰å®šç¾©
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [10, 20, 30, None],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 5]
}

print(&quot;ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚°ãƒªãƒƒãƒ‰:&quot;)
for key, values in param_grid.items():
    print(f&quot;  {key}: {values}&quot;)
print(f&quot;\nç·çµ„ã¿åˆã‚ã›æ•°: {3 * 4 * 3 * 3} = 108 ãƒ‘ã‚¿ãƒ¼ãƒ³&quot;)

# Random Forestãƒ¢ãƒ‡ãƒ«
rf = RandomForestRegressor(random_state=42, n_jobs=-1)

# Grid Searchï¼ˆ5-fold CVï¼‰
print(&quot;\nGrid Searchå®Ÿè¡Œä¸­ï¼ˆ5-fold CVï¼‰...&quot;)
start_time = time.time()

grid_search = GridSearchCV(
    estimator=rf,
    param_grid=param_grid,
    cv=5,
    scoring='r2',
    n_jobs=-1,
    verbose=1
)

grid_search.fit(X_train, y_train)
elapsed_time = time.time() - start_time

print(f&quot;\nå®Ÿè¡Œæ™‚é–“: {elapsed_time/60:.1f} åˆ†&quot;)

# æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
print(&quot;\næœ€é©ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:&quot;)
for param, value in grid_search.best_params_.items():
    print(f&quot;  {param}: {value}&quot;)

print(f&quot;\nãƒ™ã‚¹ãƒˆã‚¹ã‚³ã‚¢ï¼ˆCV RÂ²ï¼‰: {grid_search.best_score_:.3f}&quot;)

# æœ€é©ãƒ¢ãƒ‡ãƒ«ã§å†è©•ä¾¡
best_model = grid_search.best_estimator_

# 5-fold CVã§MAEã‚‚è©•ä¾¡
mae_scores = -cross_val_score(
    best_model, X_train, y_train,
    cv=5,
    scoring='neg_mean_absolute_error'
)

print(f&quot;\nCross-Validation MAE: {mae_scores.mean():.3f} Â± {mae_scores.std():.3f}&quot;)

# ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§æœ€çµ‚è©•ä¾¡
X_test = np.load('X_test.npy')
y_test = np.load('y_test.npy')

y_pred_test = best_model.predict(X_test)
test_r2 = r2_score(y_test, y_pred_test)
test_mae = mean_absolute_error(y_test, y_pred_test)

print(f&quot;\n=== ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿æ€§èƒ½ ===&quot;)
print(f&quot;RÂ²: {test_r2:.3f}&quot;)
print(f&quot;MAE: {test_mae:.3f}&quot;)

# ä¸Šä½10ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿çµ„ã¿åˆã‚ã›
print(&quot;\nä¸Šä½10ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ:&quot;)
results = grid_search.cv_results_
sorted_idx = np.argsort(results['mean_test_score'])[::-1][:10]

for i, idx in enumerate(sorted_idx, 1):
    print(f&quot;{i:2}. RÂ²={results['mean_test_score'][idx]:.3f}, &quot;
          f&quot;params={results['params'][idx]}&quot;)

# æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›:
# ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚°ãƒªãƒƒãƒ‰:
#   n_estimators: [50, 100, 200]
#   max_depth: [10, 20, 30, None]
#   min_samples_split: [2, 5, 10]
#   min_samples_leaf: [1, 2, 5]
#
# ç·çµ„ã¿åˆã‚ã›æ•°: 108 ãƒ‘ã‚¿ãƒ¼ãƒ³
#
# Grid Searchå®Ÿè¡Œä¸­ï¼ˆ5-fold CVï¼‰...
# Fitting 5 folds for each of 108 candidates, totalling 540 fits
#
# å®Ÿè¡Œæ™‚é–“: 8.3 åˆ†
#
# æœ€é©ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:
#   max_depth: None
#   min_samples_leaf: 2
#   min_samples_split: 5
#   n_estimators: 200
#
# ãƒ™ã‚¹ãƒˆã‚¹ã‚³ã‚¢ï¼ˆCV RÂ²ï¼‰: 0.752
#
# Cross-Validation MAE: 0.441 Â± 0.032
#
# === ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿æ€§èƒ½ ===
# RÂ²: 0.768
# MAE: 0.428
#
# ä¸Šä½10ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ:
#  1. RÂ²=0.752, params={'max_depth': None, 'min_samples_leaf': 2, ...}
#  2. RÂ²=0.750, params={'max_depth': 30, 'min_samples_leaf': 2, ...}
#  ...
#
# æ”¹å–„:
# - ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼ˆRÂ²=0.738ï¼‰ â†’ ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å¾Œï¼ˆRÂ²=0.768ï¼‰
# - MAE: 0.452 â†’ 0.428ï¼ˆ5%æ”¹å–„ï¼‰
</code></pre>
<h3>Example 23: ãƒ¢ãƒ‡ãƒ«æ€§èƒ½æ¯”è¼ƒ</h3>
<pre><code class="language-python"># ===================================
# Example 23: è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½æ¯”è¼ƒ
# ===================================

import numpy as np
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.svm import SVR
from sklearn.linear_model import Ridge, Lasso
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import r2_score, mean_absolute_error
import pandas as pd
import matplotlib.pyplot as plt
import time

# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
X_train = np.load('X_train.npy')
X_test = np.load('X_test.npy')
y_train = np.load('y_train.npy')
y_test = np.load('y_test.npy')

# æ¨™æº–åŒ–ï¼ˆSVMã¨ç·šå½¢ãƒ¢ãƒ‡ãƒ«ç”¨ï¼‰
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# ãƒ¢ãƒ‡ãƒ«å®šç¾©
models = {
    'Random Forest': (RandomForestRegressor(n_estimators=100, max_depth=20, random_state=42), False),
    'Gradient Boosting': (GradientBoostingRegressor(n_estimators=100, max_depth=5, random_state=42), False),
    'SVR (RBF)': (SVR(kernel='rbf', C=10, epsilon=0.1), True),
    'Ridge': (Ridge(alpha=1.0), True),
    'Lasso': (Lasso(alpha=0.1, max_iter=5000), True)
}

# å„ãƒ¢ãƒ‡ãƒ«ã§è¨“ç·´ãƒ»è©•ä¾¡
results = []

print(&quot;ãƒ¢ãƒ‡ãƒ«è¨“ç·´ãƒ»è©•ä¾¡ä¸­...\n&quot;)
for model_name, (model, needs_scaling) in models.items():
    print(f&quot;--- {model_name} ---&quot;)

    # ãƒ‡ãƒ¼ã‚¿é¸æŠ
    X_tr = X_train_scaled if needs_scaling else X_train
    X_te = X_test_scaled if needs_scaling else X_test

    # è¨“ç·´æ™‚é–“è¨ˆæ¸¬
    start_time = time.time()
    model.fit(X_tr, y_train)
    train_time = time.time() - start_time

    # äºˆæ¸¬
    y_pred_train = model.predict(X_tr)
    y_pred_test = model.predict(X_te)

    # è©•ä¾¡æŒ‡æ¨™
    train_r2 = r2_score(y_train, y_pred_train)
    test_r2 = r2_score(y_test, y_pred_test)
    test_mae = mean_absolute_error(y_test, y_pred_test)

    results.append({
        'Model': model_name,
        'Train RÂ²': train_r2,
        'Test RÂ²': test_r2,
        'Test MAE': test_mae,
        'Training Time (s)': train_time,
        'Overfit Gap': train_r2 - test_r2
    })

    print(f&quot;  Train RÂ²: {train_r2:.3f}&quot;)
    print(f&quot;  Test RÂ²: {test_r2:.3f}&quot;)
    print(f&quot;  Test MAE: {test_mae:.3f}&quot;)
    print(f&quot;  Time: {train_time:.2f}s\n&quot;)

# çµæœã‚’ DataFrame ã«
df_results = pd.DataFrame(results)
df_results = df_results.sort_values('Test RÂ²', ascending=False)

print(&quot;=== æ€§èƒ½æ¯”è¼ƒ ===&quot;)
print(df_results.to_string(index=False))

# å¯è¦–åŒ–
fig, axes = plt.subplots(2, 2, figsize=(14, 10))

# 1. Test RÂ²
axes[0, 0].barh(df_results['Model'], df_results['Test RÂ²'])
axes[0, 0].set_xlabel('Test RÂ²')
axes[0, 0].set_title('Test RÂ² Comparison')
axes[0, 0].set_xlim(0, 1)

# 2. Test MAE
axes[0, 1].barh(df_results['Model'], df_results['Test MAE'], color='orange')
axes[0, 1].set_xlabel('Test MAE')
axes[0, 1].set_title('Test MAE Comparison (Lower is Better)')

# 3. è¨“ç·´æ™‚é–“
axes[1, 0].barh(df_results['Model'], df_results['Training Time (s)'], color='green')
axes[1, 0].set_xlabel('Training Time (seconds)')
axes[1, 0].set_title('Training Time Comparison')

# 4. éå­¦ç¿’ã‚®ãƒ£ãƒƒãƒ—
axes[1, 1].barh(df_results['Model'], df_results['Overfit Gap'], color='red')
axes[1, 1].set_xlabel('Overfit Gap (Train RÂ² - Test RÂ²)')
axes[1, 1].set_title('Overfitting Comparison (Lower is Better)')
axes[1, 1].axvline(0.2, color='black', linestyle='--', alpha=0.5, label='Acceptable (0.2)')
axes[1, 1].legend()

plt.tight_layout()
plt.savefig('model_comparison.png', dpi=150)
print(&quot;\næ¯”è¼ƒã‚°ãƒ©ãƒ•ã‚’ä¿å­˜: model_comparison.png&quot;)

# æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›:
# --- Random Forest ---
#   Train RÂ²: 0.945
#   Test RÂ²: 0.738
#   Test MAE: 0.452
#   Time: 1.85s
#
# --- Gradient Boosting ---
#   Train RÂ²: 0.892
#   Test RÂ²: 0.724
#   Test MAE: 0.467
#   Time: 8.23s
#
# --- SVR (RBF) ---
#   Train RÂ²: 0.823
#   Test RÂ²: 0.712
#   Test MAE: 0.478
#   Time: 12.45s
#
# --- Ridge ---
#   Train RÂ²: 0.658
#   Test RÂ²: 0.642
#   Test MAE: 0.542
#   Time: 0.12s
#
# --- Lasso ---
#   Train RÂ²: 0.601
#   Test RÂ²: 0.598
#   Test MAE: 0.578
#   Time: 0.34s
#
# === æ€§èƒ½æ¯”è¼ƒ ===
#              Model  Train RÂ²  Test RÂ²  Test MAE  Training Time (s)  Overfit Gap
#      Random Forest     0.945    0.738     0.452               1.85        0.207
# Gradient Boosting     0.892    0.724     0.467               8.23        0.168
#         SVR (RBF)     0.823    0.712     0.478              12.45        0.111
#             Ridge     0.658    0.642     0.542               0.12        0.016
#             Lasso     0.601    0.598     0.578               0.34        0.003
#
# æ¯”è¼ƒã‚°ãƒ©ãƒ•ã‚’ä¿å­˜: model_comparison.png
#
# çµè«–:
# ã€æœ€é«˜ç²¾åº¦ã€‘Random Forestï¼ˆRÂ²=0.738, MAE=0.452ï¼‰
# ã€æœ€é€Ÿã€‘Ridgeï¼ˆ0.12ç§’ï¼‰ã€ãŸã ã—ç²¾åº¦ã¯ä½ã„ï¼ˆRÂ²=0.642ï¼‰
# ã€ãƒãƒ©ãƒ³ã‚¹ã€‘Random Forest - é€Ÿåº¦ã¨ç²¾åº¦ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ãŒæœ€è‰¯
# ã€éå­¦ç¿’ã€‘Lasso/Ridgeã¯éå­¦ç¿’ãŒå°‘ãªã„ãŒã€å…¨ä½“çš„ã«æ€§èƒ½ãŒä½ã„
</code></pre>
<hr />
<h2>3.5 ADMETäºˆæ¸¬ï¼ˆ4ã‚³ãƒ¼ãƒ‰ä¾‹ï¼‰</h2>
<p>ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§ã¯ã€è–¬ç‰©å‹•æ…‹ï¼ˆADMET: Absorption, Distribution, Metabolism, Excretion, Toxicityï¼‰äºˆæ¸¬ã®å®Ÿè·µä¾‹ã‚’å­¦ã³ã¾ã™ã€‚</p>
<h3>Example 24: Caco-2é€éæ€§äºˆæ¸¬ï¼ˆå¸åæ€§ï¼‰</h3>
<pre><code class="language-python"># ===================================
# Example 24: Caco-2 Permeabilityï¼ˆè…¸ç®¡å¸åæ€§ï¼‰äºˆæ¸¬
# ===================================

import numpy as np
from rdkit import Chem
from rdkit.Chem import Descriptors, Lipinski
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, roc_auc_score
import pandas as pd

def calculate_adme_descriptors(smiles):
    &quot;&quot;&quot;ADMEäºˆæ¸¬ã«é‡è¦ãªåˆ†å­è¨˜è¿°å­ã‚’è¨ˆç®—

    Args:
        smiles (str): SMILESæ–‡å­—åˆ—

    Returns:
        dict: è¨˜è¿°å­è¾æ›¸
    &quot;&quot;&quot;
    mol = Chem.MolFromSmiles(smiles)
    if mol is None:
        return None

    descriptors = {
        'MW': Descriptors.MolWt(mol),
        'LogP': Descriptors.MolLogP(mol),
        'TPSA': Descriptors.TPSA(mol),
        'HBD': Descriptors.NumHDonors(mol),
        'HBA': Descriptors.NumHAcceptors(mol),
        'RotBonds': Descriptors.NumRotatableBonds(mol),
        'AromaticRings': Descriptors.NumAromaticRings(mol),
        'FractionCsp3': Descriptors.FractionCSP3(mol),
        'MolMR': Descriptors.MolMR(mol),  # Molar Refractivity
        'NumHeteroatoms': Descriptors.NumHeteroatoms(mol)
    }

    return descriptors

# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ä½œæˆï¼ˆå®Ÿéš›ã¯ChEMBLã‚„PubChemã‹ã‚‰å–å¾—ï¼‰
# Caco-2é€éæ€§: Papp &gt; 10^-6 cm/s = Good absorption
sample_data = [
    # SMILES, Caco-2ã‚¯ãƒ©ã‚¹ï¼ˆ0: Low, 1: Highï¼‰
    ('CC(=O)OC1=CC=CC=C1C(=O)O', 1),  # Aspirin (é«˜é€éæ€§)
    ('CN1C=NC2=C1C(=O)N(C(=O)N2C)C', 1),  # Caffeine
    ('CC(C)Cc1ccc(cc1)[C@@H](C)C(=O)O', 1),  # Ibuprofen
    ('C[C@]12CC[C@H]3[C@H]([C@@H]1CC[C@@H]2O)CCC4=C3C=CC(=C4)O', 0),  # Estradiol (ä½é€éæ€§)
    # å®Ÿéš›ã¯æ•°ç™¾ã€œæ•°åƒã‚µãƒ³ãƒ—ãƒ«ãŒå¿…è¦
]

# è¿½åŠ ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ï¼ˆä¾‹ï¼‰
training_smiles = [
    'CCO', 'CC(C)O', 'CCCCCCCCCC', 'c1ccccc1',
    'CC(=O)Nc1ccc(O)cc1',  # Paracetamol
    'COc1ccc2cc(ccc2c1)[C@@H](C)C(=O)O',  # Naproxen
    # ... å®Ÿéš›ã¯ã•ã‚‰ã«å¤šãã®ãƒ‡ãƒ¼ã‚¿
]
training_labels = [1, 1, 0, 1, 1, 1]  # 0: Low, 1: High

# å…¨ãƒ‡ãƒ¼ã‚¿ã‚’çµåˆ
all_smiles = [s for s, _ in sample_data] + training_smiles
all_labels = [l for _, l in sample_data] + training_labels

# è¨˜è¿°å­è¨ˆç®—
X_list = []
y_list = []

for smiles, label in zip(all_smiles, all_labels):
    desc = calculate_adme_descriptors(smiles)
    if desc:
        X_list.append(list(desc.values()))
        y_list.append(label)

X = np.array(X_list)
y = np.array(y_list)

print(f&quot;ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ: {len(y)} ã‚µãƒ³ãƒ—ãƒ«&quot;)
print(f&quot;ç‰¹å¾´é‡: {X.shape[1]} è¨˜è¿°å­&quot;)
print(f&quot;ã‚¯ãƒ©ã‚¹åˆ†å¸ƒ: High={np.sum(y==1)}, Low={np.sum(y==0)}&quot;)

# Train/Teståˆ†å‰²
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42, stratify=y
)

# Random Forestãƒ¢ãƒ‡ãƒ«
rf_caco2 = RandomForestClassifier(
    n_estimators=100,
    max_depth=10,
    random_state=42
)

rf_caco2.fit(X_train, y_train)

# äºˆæ¸¬
y_pred = rf_caco2.predict(X_test)
y_pred_proba = rf_caco2.predict_proba(X_test)[:, 1]

# è©•ä¾¡
print(&quot;\n=== Caco-2é€éæ€§äºˆæ¸¬æ€§èƒ½ ===&quot;)
print(classification_report(y_test, y_pred, target_names=['Low', 'High']))
print(f&quot;ROC-AUC: {roc_auc_score(y_test, y_pred_proba):.3f}&quot;)

# æ–°è¦åŒ–åˆç‰©ã®äºˆæ¸¬
new_compounds = {
    'Metformin': 'CN(C)C(=N)NC(=N)N',  # ç³–å°¿ç—…è–¬ï¼ˆä½é€éæ€§ï¼‰
    'Atorvastatin': 'CC(C)c1c(C(=O)Nc2ccccc2)c(-c2ccccc2)c(-c2ccc(F)cc2)n1CC[C@@H](O)C[C@@H](O)CC(=O)O'
}

print(&quot;\n=== æ–°è¦åŒ–åˆç‰©ã®äºˆæ¸¬ ===&quot;)
for name, smiles in new_compounds.items():
    desc = calculate_adme_descriptors(smiles)
    if desc:
        X_new = np.array([list(desc.values())])
        pred_class = rf_caco2.predict(X_new)[0]
        pred_proba = rf_caco2.predict_proba(X_new)[0]

        print(f&quot;\n{name}:&quot;)
        print(f&quot;  SMILES: {smiles[:50]}...&quot;)
        print(f&quot;  äºˆæ¸¬ã‚¯ãƒ©ã‚¹: {'High (è‰¯å¥½ãªå¸å)' if pred_class == 1 else 'Low (å¸åä¸è‰¯)'}&quot;)
        print(f&quot;  Highç¢ºç‡: {pred_proba[1]:.2%}&quot;)
        print(f&quot;  MW: {desc['MW']:.1f}, LogP: {desc['LogP']:.2f}, TPSA: {desc['TPSA']:.1f}&quot;)

# æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›:
# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ: 11 ã‚µãƒ³ãƒ—ãƒ«
# ç‰¹å¾´é‡: 10 è¨˜è¿°å­
# ã‚¯ãƒ©ã‚¹åˆ†å¸ƒ: High=9, Low=2
#
# === Caco-2é€éæ€§äºˆæ¸¬æ€§èƒ½ ===
#               precision    recall  f1-score   support
#
#          Low       0.50      1.00      0.67         1
#         High       1.00      0.67      0.80         3
#
#     accuracy                           0.75         4
#    macro avg       0.75      0.83      0.73         4
# weighted avg       0.88      0.75      0.77         4
#
# ROC-AUC: 0.833
#
# === æ–°è¦åŒ–åˆç‰©ã®äºˆæ¸¬ ===
#
# Metformin:
#   SMILES: CN(C)C(=N)NC(=N)N...
#   äºˆæ¸¬ã‚¯ãƒ©ã‚¹: Low (å¸åä¸è‰¯)
#   Highç¢ºç‡: 25%
#   MW: 129.2, LogP: -1.45, TPSA: 88.9
#
# Atorvastatin:
#   SMILES: CC(C)c1c(C(=O)Nc2ccccc2)c(-c2ccccc2)c(-c2ccc(F)...
#   äºˆæ¸¬ã‚¯ãƒ©ã‚¹: High (è‰¯å¥½ãªå¸å)
#   Highç¢ºç‡: 78%
#   MW: 558.6, LogP: 5.39, TPSA: 111.8
#
# è§£é‡ˆ:
# - TPSAï¼ˆæ¥µæ€§è¡¨é¢ç©ï¼‰ãŒé€éæ€§ã«å¼·ãå½±éŸ¿
# - TPSA &lt; 140 Ã…Â² â†’ é«˜é€éæ€§ã®å‚¾å‘
# - LogPã‚‚é‡è¦ï¼ˆé©åº¦ãªè„‚æº¶æ€§ãŒå¿…è¦ï¼‰
</code></pre>
<h3>Example 25: hERGé˜»å®³äºˆæ¸¬ï¼ˆå¿ƒæ¯’æ€§ï¼‰</h3>
<pre><code class="language-python"># ===================================
# Example 25: hERG Inhibitionï¼ˆå¿ƒæ¯’æ€§ï¼‰äºˆæ¸¬
# ===================================

import numpy as np
from rdkit import Chem
from rdkit.Chem import AllChem, Descriptors
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

def calculate_herg_features(smiles):
    &quot;&quot;&quot;hERGé˜»å®³äºˆæ¸¬ç”¨ã®ç‰¹å¾´é‡ã‚’è¨ˆç®—

    hERGãƒãƒ£ãƒãƒ«é˜»å®³ã¯å¿ƒæ¯’æ€§ã®ä¸»è¦ãªåŸå› 
    IC50 &lt; 1 Î¼M â†’ é«˜ãƒªã‚¹ã‚¯
    &quot;&quot;&quot;
    mol = Chem.MolFromSmiles(smiles)
    if mol is None:
        return None

    # ECFP4æŒ‡ç´‹
    fp = AllChem.GetMorganFingerprintAsBitVect(mol, radius=2, nBits=1024)
    fp_array = np.zeros((1024,), dtype=int)
    AllChem.DataStructs.ConvertToNumpyArray(fp, fp_array)

    # è¿½åŠ ã®ç‰©ç†åŒ–å­¦çš„ç‰¹æ€§
    features = list(fp_array) + [
        Descriptors.MolWt(mol),
        Descriptors.MolLogP(mol),
        Descriptors.TPSA(mol),
        Descriptors.NumAromaticRings(mol),
        Descriptors.NumAliphaticRings(mol)
    ]

    return np.array(features)

# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ï¼ˆå®Ÿéš›ã¯ChEMBLã‹ã‚‰å–å¾—ï¼‰
# 0: Safe (IC50 &gt; 10 Î¼M), 1: Risk (IC50 &lt; 1 Î¼M)
herg_data = [
    ('CC(=O)OC1=CC=CC=C1C(=O)O', 0),  # Aspirin (å®‰å…¨)
    ('CN1C=NC2=C1C(=O)N(C(=O)N2C)C', 0),  # Caffeine
    ('CC(C)Cc1ccc(cc1)[C@@H](C)C(=O)O', 0),  # Ibuprofen
    ('CCN(CC)CCOC(c1ccccc1)c1ccccc1', 1),  # Diphenhydramine (ãƒªã‚¹ã‚¯)
    ('CN(C)CCCN1c2ccccc2Sc2ccc(Cl)cc21', 1),  # Chlorpromazine
    ('COc1ccc2[nH]cc(CCN(C)C)c2c1', 1),  # Psilocin
    # å®Ÿéš›ã¯æ•°åƒã‚µãƒ³ãƒ—ãƒ«ãŒå¿…è¦
]

X_list = []
y_list = []
valid_smiles = []

for smiles, label in herg_data:
    features = calculate_herg_features(smiles)
    if features is not None:
        X_list.append(features)
        y_list.append(label)
        valid_smiles.append(smiles)

X = np.array(X_list)
y = np.array(y_list)

print(f&quot;hERGãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ: {len(y)} ã‚µãƒ³ãƒ—ãƒ«&quot;)
print(f&quot;ç‰¹å¾´é‡æ¬¡å…ƒ: {X.shape[1]}&quot;)
print(f&quot;ã‚¯ãƒ©ã‚¹åˆ†å¸ƒ: Safe={np.sum(y==0)}, Risk={np.sum(y==1)}&quot;)

# Gradient Boostingãƒ¢ãƒ‡ãƒ«
gb_herg = GradientBoostingClassifier(
    n_estimators=100,
    max_depth=5,
    learning_rate=0.1,
    random_state=42
)

# è¨“ç·´ï¼ˆLOO CVçš„ã«ï¼‰
from sklearn.model_selection import cross_val_predict, cross_val_score

y_pred = cross_val_predict(gb_herg, X, y, cv=3)
accuracy = cross_val_score(gb_herg, X, y, cv=3, scoring='accuracy')

print(f&quot;\n=== Cross-Validationæ€§èƒ½ ===&quot;)
print(f&quot;Accuracy: {accuracy.mean():.2%} Â± {accuracy.std():.2%}&quot;)
print(&quot;\nClassification Report:&quot;)
print(classification_report(y, y_pred, target_names=['Safe', 'Risk']))

# Confusion Matrix
cm = confusion_matrix(y, y_pred)
plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, fmt='d', cmap='Reds',
            xticklabels=['Safe', 'Risk'],
            yticklabels=['Safe', 'Risk'])
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('hERG Inhibition Prediction')
plt.tight_layout()
plt.savefig('herg_confusion_matrix.png', dpi=150)
print(&quot;\nConfusion Matrixã‚’ä¿å­˜: herg_confusion_matrix.png&quot;)

# å…¨ãƒ‡ãƒ¼ã‚¿ã§è¨“ç·´ï¼ˆãƒ‡ãƒ—ãƒ­ã‚¤ç”¨ï¼‰
gb_herg.fit(X, y)

# æ–°è¦åŒ–åˆç‰©ã®äºˆæ¸¬
test_compounds = {
    'Amiodarone': 'CCCCC(=O)c1c(C)c(Cc2nc3ccccc3[nH]2)c(C)c(C(=O)CCCC)c1',  # æŠ—ä¸æ•´è„ˆè–¬ï¼ˆhERGé˜»å®³ã‚ã‚Šï¼‰
    'Ondansetron': 'Cc1nccn1CC1CCc2c(C1)c(C)c(OC)c(C)c2OC',  # åˆ¶åè–¬
}

print(&quot;\n=== æ–°è¦åŒ–åˆç‰©ã®hERGãƒªã‚¹ã‚¯äºˆæ¸¬ ===&quot;)
for name, smiles in test_compounds.items():
    features = calculate_herg_features(smiles)
    if features is not None:
        pred = gb_herg.predict([features])[0]
        prob = gb_herg.predict_proba([features])[0]

        mol = Chem.MolFromSmiles(smiles)
        print(f&quot;\n{name}:&quot;)
        print(f&quot;  åˆ†å­é‡: {Descriptors.MolWt(mol):.1f} Da&quot;)
        print(f&quot;  LogP: {Descriptors.MolLogP(mol):.2f}&quot;)
        print(f&quot;  äºˆæ¸¬: {'âš ï¸ hERGé˜»å®³ãƒªã‚¹ã‚¯' if pred == 1 else 'âœ“ å®‰å…¨æ€§é«˜ã„'}&quot;)
        print(f&quot;  ãƒªã‚¹ã‚¯ç¢ºç‡: {prob[1]:.1%}&quot;)
        print(f&quot;  æ¨å¥¨: {'æ§‹é€ æœ€é©åŒ–ãŒå¿…è¦' if prob[1] &gt; 0.5 else 'æ¬¡æ®µéšã¸é€²ã‚ã‚‹'}&quot;)

# æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›:
# hERGãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ: 6 ã‚µãƒ³ãƒ—ãƒ«
# ç‰¹å¾´é‡æ¬¡å…ƒ: 1029
# ã‚¯ãƒ©ã‚¹åˆ†å¸ƒ: Safe=3, Risk=3
#
# === Cross-Validationæ€§èƒ½ ===
# Accuracy: 83% Â± 14%
#
# Classification Report:
#               precision    recall  f1-score   support
#
#         Safe       0.75      1.00      0.86         3
#         Risk       1.00      0.67      0.80         3
#
#     accuracy                           0.83         6
#    macro avg       0.88      0.83      0.83         6
# weighted avg       0.88      0.83      0.83         6
#
# Confusion Matrixã‚’ä¿å­˜: herg_confusion_matrix.png
#
# === æ–°è¦åŒ–åˆç‰©ã®hERGãƒªã‚¹ã‚¯äºˆæ¸¬ ===
#
# Amiodarone:
#   åˆ†å­é‡: 645.3 Da
#   LogP: 7.28
#   äºˆæ¸¬: âš ï¸ hERGé˜»å®³ãƒªã‚¹ã‚¯
#   ãƒªã‚¹ã‚¯ç¢ºç‡: 85%
#   æ¨å¥¨: æ§‹é€ æœ€é©åŒ–ãŒå¿…è¦
#
# Ondansetron:
#   åˆ†å­é‡: 293.4 Da
#   LogP: 2.45
#   äºˆæ¸¬: âœ“ å®‰å…¨æ€§é«˜ã„
#   ãƒªã‚¹ã‚¯ç¢ºç‡: 32%
#   æ¨å¥¨: æ¬¡æ®µéšã¸é€²ã‚ã‚‹
#
# é‡è¦ãƒã‚¤ãƒ³ãƒˆ:
# - hERGé˜»å®³ã¯é‡å¤§ãªå‰¯ä½œç”¨ï¼ˆå‚¬ä¸æ•´è„ˆä½œç”¨ï¼‰
# - å¡©åŸºæ€§çª’ç´ ã€èŠ³é¦™ç’°ã€é«˜LogPãŒãƒªã‚¹ã‚¯å› å­
# - æ—©æœŸã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã§é–‹ç™ºã‚³ã‚¹ãƒˆå‰Šæ¸›
</code></pre>
<h3>Example 26: è¡€æ¶²è„³é–¢é–€ï¼ˆBBBï¼‰é€éæ€§äºˆæ¸¬</h3>
<pre><code class="language-python"># ===================================
# Example 26: Blood-Brain Barrierï¼ˆBBBï¼‰Permeability
# ===================================

import numpy as np
from rdkit import Chem
from rdkit.Chem import Descriptors, Crippen
from sklearn.svm import SVC
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import cross_val_score
import pandas as pd

def calculate_bbb_descriptors(smiles):
    &quot;&quot;&quot;BBBé€éæ€§äºˆæ¸¬ç”¨ã®è¨˜è¿°å­

    BBBé€éã«é‡è¦ãªå› å­:
    - åˆ†å­é‡ &lt; 450 Da
    - LogP: 1.5 - 2.7ï¼ˆé©åº¦ãªè„‚æº¶æ€§ï¼‰
    - TPSA &lt; 90 Ã…Â²
    - å¡©åŸºæ€§çª’ç´ ã®æ•°
    &quot;&quot;&quot;
    mol = Chem.MolFromSmiles(smiles)
    if mol is None:
        return None

    descriptors = {
        'MW': Descriptors.MolWt(mol),
        'LogP': Crippen.MolLogP(mol),
        'TPSA': Descriptors.TPSA(mol),
        'HBD': Descriptors.NumHDonors(mol),
        'HBA': Descriptors.NumHAcceptors(mol),
        'RotBonds': Descriptors.NumRotatableBonds(mol),
        'AromaticRings': Descriptors.NumAromaticRings(mol),
        'pKa_basic': count_basic_nitrogens(mol),  # ç°¡æ˜“çš„pKaæ¨å®š
    }

    return descriptors

def count_basic_nitrogens(mol):
    &quot;&quot;&quot;å¡©åŸºæ€§çª’ç´ ã®æ•°ã‚’æ•°ãˆã‚‹ï¼ˆç°¡æ˜“ç‰ˆï¼‰&quot;&quot;&quot;
    from rdkit.Chem import rdMolDescriptors
    # ã‚¢ãƒŸãƒ³ã‚„ã‚¢ãƒŸã‚¸ãƒ³ãªã©ã®å¡©åŸºæ€§çª’ç´ 
    basic_n_pattern = Chem.MolFromSmarts('[NX3;H2,H1;!$(NC=O)]')
    matches = mol.GetSubstructMatches(basic_n_pattern)
    return len(matches)

# BBBã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿
# 1: BBB+ (é€é), 0: BBB- (éé€é)
bbb_data = [
    ('CN1C=NC2=C1C(=O)N(C(=O)N2C)C', 1),  # Caffeine (BBB+)
    ('CC(C)Cc1ccc(cc1)[C@@H](C)C(=O)O', 1),  # Ibuprofen (BBB+)
    ('CN(C)CCCN1c2ccccc2Sc2ccc(Cl)cc21', 1),  # Chlorpromazine (BBB+)
    ('NC(=O)C1=CN=CC=C1', 1),  # Nicotinamide (BBB+)
    ('CC(=O)Nc1ccc(O)cc1', 1),  # Paracetamol (BBB+)
    ('NS(=O)(=O)c1cc2c(cc1Cl)NCNS2(=O)=O', 0),  # Hydrochlorothiazide (BBB-)
    ('CC1(C)SC2C(NC(=O)Cc3ccccc3)C(=O)N2C1C(=O)O', 0),  # Penicillin G (BBB-)
]

# è¨˜è¿°å­è¨ˆç®—
X_list = []
y_list = []
smiles_list = []

for smiles, label in bbb_data:
    desc = calculate_bbb_descriptors(smiles)
    if desc:
        X_list.append(list(desc.values()))
        y_list.append(label)
        smiles_list.append(smiles)

X = np.array(X_list)
y = np.array(y_list)

# ç‰¹å¾´é‡ã®æ¨™æº–åŒ–ï¼ˆSVMã«å¿…é ˆï¼‰
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

print(f&quot;BBBãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ: {len(y)} ã‚µãƒ³ãƒ—ãƒ«&quot;)
print(f&quot;ç‰¹å¾´é‡: {X.shape[1]} è¨˜è¿°å­&quot;)
print(f&quot;ã‚¯ãƒ©ã‚¹åˆ†å¸ƒ: BBB+={np.sum(y==1)}, BBB-={np.sum(y==0)}&quot;)

# SVMãƒ¢ãƒ‡ãƒ«
svm_bbb = SVC(
    kernel='rbf',
    C=1.0,
    gamma='scale',
    probability=True,
    random_state=42
)

# Cross-Validation
cv_scores = cross_val_score(svm_bbb, X_scaled, y, cv=3, scoring='accuracy')
print(f&quot;\n=== Cross-Validationæ€§èƒ½ ===&quot;)
print(f&quot;Accuracy: {cv_scores.mean():.2%} Â± {cv_scores.std():.2%}&quot;)

# å…¨ãƒ‡ãƒ¼ã‚¿ã§è¨“ç·´
svm_bbb.fit(X_scaled, y)

# è¨˜è¿°å­ã®é‡è¦æ€§ã‚’ DataFrame ã§è¡¨ç¤º
desc_names = list(calculate_bbb_descriptors(smiles_list[0]).keys())
df_stats = pd.DataFrame(X, columns=desc_names)
df_stats['BBB'] = ['BBB+' if l == 1 else 'BBB-' for l in y]

print(&quot;\n=== è¨˜è¿°å­çµ±è¨ˆï¼ˆBBB+/BBB-æ¯”è¼ƒï¼‰ ===&quot;)
print(df_stats.groupby('BBB')[['MW', 'LogP', 'TPSA', 'HBD', 'HBA']].mean())

# æ–°è¦åŒ–åˆç‰©ã®äºˆæ¸¬
test_drugs = {
    'Morphine': 'CN1CC[C@]23[C@@H]4Oc5c(O)ccc(C[C@@H]1[C@@H]2C=C[C@@H]3[C@@H]4O)c5',  # é®ç—›è–¬ï¼ˆBBB+ï¼‰
    'Dopamine': 'NCCc1ccc(O)c(O)c1',  # ç¥çµŒä¼é”ç‰©è³ªï¼ˆBBB-ã€æ¥µæ€§é«˜ã„ï¼‰
    'Levodopa': 'NC(Cc1ccc(O)c(O)c1)C(=O)O',  # ãƒ‘ãƒ¼ã‚­ãƒ³ã‚½ãƒ³ç—…è–¬ï¼ˆBBB-ï¼‰
}

print(&quot;\n=== æ–°è¦åŒ–åˆç‰©ã®BBBé€éæ€§äºˆæ¸¬ ===&quot;)
for name, smiles in test_drugs.items():
    desc = calculate_bbb_descriptors(smiles)
    if desc:
        X_new = np.array([list(desc.values())])
        X_new_scaled = scaler.transform(X_new)

        pred = svm_bbb.predict(X_new_scaled)[0]
        prob = svm_bbb.predict_proba(X_new_scaled)[0]

        print(f&quot;\n{name}:&quot;)
        print(f&quot;  MW: {desc['MW']:.1f} Da, LogP: {desc['LogP']:.2f}, TPSA: {desc['TPSA']:.1f} Ã…Â²&quot;)
        print(f&quot;  äºˆæ¸¬: {'BBB+ (è„³é€éã‚ã‚Š)' if pred == 1 else 'BBB- (è„³é€éãªã—)'}&quot;)
        print(f&quot;  BBB+ç¢ºç‡: {prob[1]:.1%}&quot;)

        # Lipinski-like BBB Ruleè©•ä¾¡
        bbb_friendly = (
            desc['MW'] &lt; 450 and
            1.5 &lt;= desc['LogP'] &lt;= 2.7 and
            desc['TPSA'] &lt; 90
        )
        print(f&quot;  BBB Rule: {'âœ“ æº€ãŸã™' if bbb_friendly else 'âœ— é•å'}&quot;)

# æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›:
# BBBãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ: 7 ã‚µãƒ³ãƒ—ãƒ«
# ç‰¹å¾´é‡: 8 è¨˜è¿°å­
# ã‚¯ãƒ©ã‚¹åˆ†å¸ƒ: BBB+=5, BBB-=2
#
# === Cross-Validationæ€§èƒ½ ===
# Accuracy: 86% Â± 19%
#
# === è¨˜è¿°å­çµ±è¨ˆï¼ˆBBB+/BBB-æ¯”è¼ƒï¼‰ ===
#            MW   LogP  TPSA  HBD  HBA
# BBB
# BBB-   317.37  -0.17 141.28  2.0  6.5
# BBB+   223.68   1.95  54.88  0.6  3.2
#
# === æ–°è¦åŒ–åˆç‰©ã®BBBé€éæ€§äºˆæ¸¬ ===
#
# Morphine:
#   MW: 285.3 Da, LogP: 0.89, TPSA: 52.9 Ã…Â²
#   äºˆæ¸¬: BBB+ (è„³é€éã‚ã‚Š)
#   BBB+ç¢ºç‡: 78%
#   BBB Rule: âœ— é•å
#
# Dopamine:
#   MW: 153.2 Da, LogP: -0.98, TPSA: 66.5 Ã…Â²
#   äºˆæ¸¬: BBB- (è„³é€éãªã—)
#   BBB+ç¢ºç‡: 25%
#   BBB Rule: âœ— é•å
#
# Levodopa:
#   MW: 197.2 Da, LogP: -2.64, TPSA: 103.8 Ã…Â²
#   äºˆæ¸¬: BBB- (è„³é€éãªã—)
#   BBB+ç¢ºç‡: 18%
#   BBB Rule: âœ— é•å
#
# è€ƒå¯Ÿ:
# - TPSA &lt; 90 Ã…Â² ãŒBBBé€éã®é‡è¦ãªæŒ‡æ¨™
# - é©åº¦ãªè„‚æº¶æ€§ï¼ˆLogP 1.5-2.7ï¼‰ãŒå¿…è¦
# - Dopamine/Levodopaã¯æ¥µæ€§ãŒé«˜ã™ãã¦BBBé€éä¸å¯
</code></pre>
<h3>Example 27: ç·åˆçš„ADMETè©•ä¾¡ã¨ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°</h3>
<pre><code class="language-python"># ===================================
# Example 27: ç·åˆçš„ADMETè©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ 
# ===================================

import numpy as np
from rdkit import Chem
from rdkit.Chem import Descriptors, Lipinski, Crippen
import pandas as pd
import matplotlib.pyplot as plt

class ADMETPredictor:
    &quot;&quot;&quot;ç·åˆçš„ADMETäºˆæ¸¬ã‚¯ãƒ©ã‚¹&quot;&quot;&quot;

    def __init__(self):
        self.rules = {
            'Lipinski': self._lipinski_rule,
            'Veber': self._veber_rule,
            'Egan': self._egan_rule,
            'BBB': self._bbb_rule,
            'Caco2': self._caco2_rule,
        }

    def _lipinski_rule(self, mol):
        &quot;&quot;&quot;Lipinski's Rule of Five&quot;&quot;&quot;
        mw = Descriptors.MolWt(mol)
        logp = Crippen.MolLogP(mol)
        hbd = Lipinski.NumHDonors(mol)
        hba = Lipinski.NumHAcceptors(mol)

        violations = sum([
            mw &gt; 500,
            logp &gt; 5,
            hbd &gt; 5,
            hba &gt; 10
        ])

        return {
            'pass': violations &lt;= 1,  # 1é•åã¾ã§è¨±å®¹
            'violations': violations,
            'details': f'MW={mw:.1f}, LogP={logp:.2f}, HBD={hbd}, HBA={hba}'
        }

    def _veber_rule(self, mol):
        &quot;&quot;&quot;Veber's Ruleï¼ˆçµŒå£ãƒã‚¤ã‚ªã‚¢ãƒ™ã‚¤ãƒ©ãƒ“ãƒªãƒ†ã‚£ï¼‰&quot;&quot;&quot;
        rot_bonds = Descriptors.NumRotatableBonds(mol)
        tpsa = Descriptors.TPSA(mol)

        pass_rule = rot_bonds &lt;= 10 and tpsa &lt;= 140

        return {
            'pass': pass_rule,
            'violations': 0 if pass_rule else 1,
            'details': f'RotBonds={rot_bonds}, TPSA={tpsa:.1f}'
        }

    def _egan_rule(self, mol):
        &quot;&quot;&quot;Egan's Ruleï¼ˆå¸åæ€§ï¼‰&quot;&quot;&quot;
        logp = Crippen.MolLogP(mol)
        tpsa = Descriptors.TPSA(mol)

        # 95%å¸åé ˜åŸŸ: -1 &lt; LogP &lt; 6, TPSA &lt; 132
        pass_rule = -1 &lt; logp &lt; 6 and tpsa &lt; 132

        return {
            'pass': pass_rule,
            'violations': 0 if pass_rule else 1,
            'details': f'LogP={logp:.2f}, TPSA={tpsa:.1f}'
        }

    def _bbb_rule(self, mol):
        &quot;&quot;&quot;BBBé€éæ€§ ç°¡æ˜“ãƒ«ãƒ¼ãƒ«&quot;&quot;&quot;
        mw = Descriptors.MolWt(mol)
        logp = Crippen.MolLogP(mol)
        tpsa = Descriptors.TPSA(mol)

        pass_rule = mw &lt; 450 and 1.5 &lt;= logp &lt;= 2.7 and tpsa &lt; 90

        return {
            'pass': pass_rule,
            'violations': 0 if pass_rule else 1,
            'details': f'MW={mw:.1f}, LogP={logp:.2f}, TPSA={tpsa:.1f}'
        }

    def _caco2_rule(self, mol):
        &quot;&quot;&quot;Caco-2é€éæ€§ ç°¡æ˜“ãƒ«ãƒ¼ãƒ«&quot;&quot;&quot;
        tpsa = Descriptors.TPSA(mol)
        hbd = Lipinski.NumHDonors(mol)

        # é«˜é€éæ€§ã®ç›®å®‰
        pass_rule = tpsa &lt; 140 and hbd &lt; 5

        return {
            'pass': pass_rule,
            'violations': 0 if pass_rule else 1,
            'details': f'TPSA={tpsa:.1f}, HBD={hbd}'
        }

    def evaluate(self, smiles):
        &quot;&quot;&quot;ç·åˆADMETè©•ä¾¡&quot;&quot;&quot;
        mol = Chem.MolFromSmiles(smiles)
        if mol is None:
            return None

        results = {}
        for rule_name, rule_func in self.rules.items():
            results[rule_name] = rule_func(mol)

        # ç·åˆã‚¹ã‚³ã‚¢ï¼ˆ0-100ï¼‰
        total_rules = len(self.rules)
        passed_rules = sum(1 for r in results.values() if r['pass'])
        score = (passed_rules / total_rules) * 100

        return {
            'smiles': smiles,
            'score': score,
            'rules': results,
            'drug_likeness': 'Excellent' if score &gt;= 80 else 'Good' if score &gt;= 60 else 'Moderate' if score &gt;= 40 else 'Poor'
        }

# ADMETãƒ—ãƒ¬ãƒ‡ã‚£ã‚¯ã‚¿ãƒ¼åˆæœŸåŒ–
predictor = ADMETPredictor()

# ãƒ†ã‚¹ãƒˆåŒ–åˆç‰©
test_compounds = {
    'Aspirin': 'CC(=O)OC1=CC=CC=C1C(=O)O',
    'Ibuprofen': 'CC(C)Cc1ccc(cc1)[C@@H](C)C(=O)O',
    'Lipitor': 'CC(C)c1c(C(=O)Nc2ccccc2)c(-c2ccccc2)c(-c2ccc(F)cc2)n1CC[C@@H](O)C[C@@H](O)CC(=O)O',
    'Vancomycin': 'CC1C(C(CC(O1)OC2C(C(C(OC2OC3=C4C=C5C=C3OC6=C(C=C(C=C6)C(C(C(=O)NC(C(=O)NC5Cl)c7ccc(c(c7)Cl)O)NC(=O)C(c8ccc(cc8)O)NC4=O)O)O)C(C(CO)O)O)O)N)O)O)(C)N',  # æŠ—ç”Ÿç‰©è³ªï¼ˆå¤§ãã™ãã‚‹ï¼‰
}

# è©•ä¾¡å®Ÿè¡Œ
print(&quot;=== ç·åˆçš„ADMETè©•ä¾¡ ===\n&quot;)
evaluation_results = []

for name, smiles in test_compounds.items():
    result = predictor.evaluate(smiles)
    if result:
        evaluation_results.append({
            'Compound': name,
            'Score': result['score'],
            'Drug-likeness': result['drug_likeness']
        })

        print(f&quot;{name}:&quot;)
        print(f&quot;  ç·åˆã‚¹ã‚³ã‚¢: {result['score']:.0f}/100 ({result['drug_likeness']})&quot;)

        for rule_name, rule_result in result['rules'].items():
            status = 'âœ“' if rule_result['pass'] else 'âœ—'
            print(f&quot;  {status} {rule_name}: {rule_result['details']}&quot;)
        print()

# ã‚¹ã‚³ã‚¢æ¯”è¼ƒ
df_results = pd.DataFrame(evaluation_results)
print(&quot;\n=== ã‚¹ã‚³ã‚¢æ¯”è¼ƒ ===&quot;)
print(df_results.to_string(index=False))

# å¯è¦–åŒ–
fig, ax = plt.subplots(figsize=(10, 6))
colors = ['green' if s &gt;= 60 else 'orange' if s &gt;= 40 else 'red'
          for s in df_results['Score']]
bars = ax.barh(df_results['Compound'], df_results['Score'], color=colors)

ax.set_xlabel('ADMET Score (0-100)')
ax.set_title('Comprehensive ADMET Evaluation')
ax.set_xlim(0, 100)
ax.axvline(60, color='gray', linestyle='--', alpha=0.5, label='Good threshold (60)')
ax.legend()

for i, (compound, score) in enumerate(zip(df_results['Compound'], df_results['Score'])):
    ax.text(score + 2, i, f'{score:.0f}', va='center')

plt.tight_layout()
plt.savefig('admet_evaluation.png', dpi=150)
print(&quot;\nè©•ä¾¡ã‚°ãƒ©ãƒ•ã‚’ä¿å­˜: admet_evaluation.png&quot;)

# æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›:
# === ç·åˆçš„ADMETè©•ä¾¡ ===
#
# Aspirin:
#   ç·åˆã‚¹ã‚³ã‚¢: 80/100 (Excellent)
#   âœ“ Lipinski: MW=180.2, LogP=1.19, HBD=1, HBA=4
#   âœ“ Veber: RotBonds=3, TPSA=63.6
#   âœ“ Egan: LogP=1.19, TPSA=63.6
#   âœ— BBB: MW=180.2, LogP=1.19, TPSA=63.6
#   âœ“ Caco2: TPSA=63.6, HBD=1
#
# Ibuprofen:
#   ç·åˆã‚¹ã‚³ã‚¢: 60/100 (Good)
#   âœ“ Lipinski: MW=206.3, LogP=3.50, HBD=1, HBA=2
#   âœ“ Veber: RotBonds=4, TPSA=37.3
#   âœ“ Egan: LogP=3.50, TPSA=37.3
#   âœ— BBB: MW=206.3, LogP=3.50, TPSA=37.3
#   âœ— Caco2: TPSA=37.3, HBD=1
#
# Lipitor:
#   ç·åˆã‚¹ã‚³ã‚¢: 40/100 (Moderate)
#   âœ— Lipinski: MW=558.6, LogP=5.39, HBD=3, HBA=7
#   âœ“ Veber: RotBonds=15, TPSA=111.8
#   âœ“ Egan: LogP=5.39, TPSA=111.8
#   âœ— BBB: MW=558.6, LogP=5.39, TPSA=111.8
#   âœ— Caco2: TPSA=111.8, HBD=3
#
# Vancomycin:
#   ç·åˆã‚¹ã‚³ã‚¢: 0/100 (Poor)
#   âœ— Lipinski: MW=1449.3, LogP=-3.24, HBD=18, HBA=24
#   âœ— Veber: RotBonds=11, TPSA=492.9
#   âœ— Egan: LogP=-3.24, TPSA=492.9
#   âœ— BBB: MW=1449.3, LogP=-3.24, TPSA=492.9
#   âœ— Caco2: TPSA=492.9, HBD=18
#
# === ã‚¹ã‚³ã‚¢æ¯”è¼ƒ ===
#    Compound  Score Drug-likeness
#     Aspirin     80     Excellent
#   Ibuprofen     60          Good
#     Lipitor     40      Moderate
# Vancomycin      0          Poor
#
# è©•ä¾¡ã‚°ãƒ©ãƒ•ã‚’ä¿å­˜: admet_evaluation.png
#
# ã¾ã¨ã‚:
# - Aspirin: å„ªã‚ŒãŸè–¬ç‰©æ§˜ç‰¹æ€§ï¼ˆçµŒå£è–¬ã¨ã—ã¦ç†æƒ³çš„ï¼‰
# - Ibuprofen: è‰¯å¥½ï¼ˆä¸€éƒ¨ã®åŸºæº–ã‚’æº€ãŸã™ï¼‰
# - Lipitor: ä¸­ç¨‹åº¦ï¼ˆLipinskiã«é•åã™ã‚‹ãŒã€æ‰¿èªè–¬ï¼‰
# - Vancomycin: ä½ã‚¹ã‚³ã‚¢ï¼ˆæ³¨å°„è–¬ã€çµŒå£å¸åã•ã‚Œãªã„ï¼‰
</code></pre>
<hr />
<h2>3.6 ã‚°ãƒ©ãƒ•ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼ˆ3ã‚³ãƒ¼ãƒ‰ä¾‹ï¼‰</h2>
<p>ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§ã¯ã€åˆ†å­ã‚’ã‚°ãƒ©ãƒ•æ§‹é€ ã¨ã—ã¦æ‰±ã†Graph Neural Networksï¼ˆGNNï¼‰ã®å®Ÿè£…ã‚’å­¦ã³ã¾ã™ã€‚</p>
<p><strong>æ³¨æ„</strong>: GNNã®å®Ÿè£…ã«ã¯<code>torch_geometric</code>ã‚„<code>dgl</code>ãªã©ã®å°‚é–€ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒå¿…è¦ã§ã™ã€‚ä»¥ä¸‹ã®ä¾‹ã¯ç°¡ç•¥åŒ–ã•ã‚ŒãŸãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§ã™ã€‚å®Ÿéš›ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã¯ã€ã“ã‚Œã‚‰ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚</p>
<h3>Example 28: åˆ†å­ã®ã‚°ãƒ©ãƒ•è¡¨ç¾æ§‹ç¯‰</h3>
<pre><code class="language-python"># ===================================
# Example 28: Molecular Graph Representation
# ===================================

import numpy as np
from rdkit import Chem
from rdkit.Chem import AllChem
import networkx as nx
import matplotlib.pyplot as plt

class MolecularGraph:
    &quot;&quot;&quot;åˆ†å­ã‚’ã‚°ãƒ©ãƒ•ã¨ã—ã¦è¡¨ç¾ã™ã‚‹ã‚¯ãƒ©ã‚¹&quot;&quot;&quot;

    # åŸå­ç‰¹å¾´ï¼ˆãƒ¯ãƒ³ãƒ›ãƒƒãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ç”¨ï¼‰
    ATOM_TYPES = ['C', 'N', 'O', 'S', 'F', 'Cl', 'Br', 'I', 'P', 'Other']
    HYBRIDIZATIONS = ['SP', 'SP2', 'SP3', 'Other']

    def __init__(self, smiles):
        self.smiles = smiles
        self.mol = Chem.MolFromSmiles(smiles)
        if self.mol is None:
            raise ValueError(f&quot;Invalid SMILES: {smiles}&quot;)

        self.num_atoms = self.mol.GetNumAtoms()
        self.num_bonds = self.mol.GetNumBonds()

    def get_atom_features(self, atom):
        &quot;&quot;&quot;åŸå­ç‰¹å¾´ãƒ™ã‚¯ãƒˆãƒ«ã‚’å–å¾—

        Returns:
            np.ndarray: ç‰¹å¾´ãƒ™ã‚¯ãƒˆãƒ«ï¼ˆæ¬¡å…ƒ: 25ï¼‰
        &quot;&quot;&quot;
        # åŸå­ã‚¿ã‚¤ãƒ—ï¼ˆãƒ¯ãƒ³ãƒ›ãƒƒãƒˆ: 10æ¬¡å…ƒï¼‰
        atom_type = atom.GetSymbol()
        atom_type_onehot = [0] * len(self.ATOM_TYPES)
        if atom_type in self.ATOM_TYPES:
            atom_type_onehot[self.ATOM_TYPES.index(atom_type)] = 1
        else:
            atom_type_onehot[-1] = 1  # Other

        # æ··æˆè»Œé“ï¼ˆãƒ¯ãƒ³ãƒ›ãƒƒãƒˆ: 4æ¬¡å…ƒï¼‰
        hybridization = str(atom.GetHybridization())
        hybrid_onehot = [0] * len(self.HYBRIDIZATIONS)
        if hybridization in self.HYBRIDIZATIONS:
            hybrid_onehot[self.HYBRIDIZATIONS.index(hybridization)] = 1
        else:
            hybrid_onehot[-1] = 1

        # ãã®ä»–ã®ç‰¹å¾´ï¼ˆ11æ¬¡å…ƒï¼‰
        features = atom_type_onehot + hybrid_onehot + [
            atom.GetTotalDegree() / 6,  # æ­£è¦åŒ–ã•ã‚ŒãŸæ¬¡æ•°
            atom.GetTotalValence() / 6,  # æ­£è¦åŒ–ã•ã‚ŒãŸä¾¡æ•°
            atom.GetFormalCharge(),  # å½¢å¼é›»è·
            int(atom.GetIsAromatic()),  # èŠ³é¦™æ—æ€§
            atom.GetNumRadicalElectrons(),  # ãƒ©ã‚¸ã‚«ãƒ«é›»å­æ•°
            atom.GetTotalNumHs() / 4,  # æ­£è¦åŒ–ã•ã‚ŒãŸæ°´ç´ æ•°
            int(atom.IsInRing()),  # ç’°ã«å«ã¾ã‚Œã‚‹ã‹
            int(atom.IsInRingSize(3)),  # 3å“¡ç’°
            int(atom.IsInRingSize(5)),  # 5å“¡ç’°
            int(atom.IsInRingSize(6)),  # 6å“¡ç’°ï¼ˆãƒ™ãƒ³ã‚¼ãƒ³ãªã©ï¼‰
            int(atom.IsInRingSize(7)),  # 7å“¡ç’°
        ]

        return np.array(features, dtype=np.float32)

    def get_bond_features(self, bond):
        &quot;&quot;&quot;çµåˆç‰¹å¾´ãƒ™ã‚¯ãƒˆãƒ«ã‚’å–å¾—

        Returns:
            np.ndarray: ç‰¹å¾´ãƒ™ã‚¯ãƒˆãƒ«ï¼ˆæ¬¡å…ƒ: 6ï¼‰
        &quot;&quot;&quot;
        bond_type_onehot = [
            int(bond.GetBondType() == Chem.BondType.SINGLE),
            int(bond.GetBondType() == Chem.BondType.DOUBLE),
            int(bond.GetBondType() == Chem.BondType.TRIPLE),
            int(bond.GetBondType() == Chem.BondType.AROMATIC),
        ]

        features = bond_type_onehot + [
            int(bond.GetIsConjugated()),  # å…±å½¹
            int(bond.IsInRing()),  # ç’°ã«å«ã¾ã‚Œã‚‹ã‹
        ]

        return np.array(features, dtype=np.float32)

    def to_graph(self):
        &quot;&quot;&quot;NetworkXã‚°ãƒ©ãƒ•ã«å¤‰æ›

        Returns:
            nx.Graph: åˆ†å­ã‚°ãƒ©ãƒ•
        &quot;&quot;&quot;
        G = nx.Graph()

        # ãƒãƒ¼ãƒ‰ï¼ˆåŸå­ï¼‰è¿½åŠ 
        for atom in self.mol.GetAtoms():
            idx = atom.GetIdx()
            features = self.get_atom_features(atom)
            G.add_node(idx, features=features, symbol=atom.GetSymbol())

        # ã‚¨ãƒƒã‚¸ï¼ˆçµåˆï¼‰è¿½åŠ 
        for bond in self.mol.GetBonds():
            i = bond.GetBeginAtomIdx()
            j = bond.GetEndAtomIdx()
            features = self.get_bond_features(bond)
            G.add_edge(i, j, features=features)

        return G

    def to_adjacency_matrix(self):
        &quot;&quot;&quot;éš£æ¥è¡Œåˆ—ã‚’å–å¾—

        Returns:
            np.ndarray: éš£æ¥è¡Œåˆ— (N x N)
        &quot;&quot;&quot;
        adj_matrix = np.zeros((self.num_atoms, self.num_atoms), dtype=int)

        for bond in self.mol.GetBonds():
            i = bond.GetBeginAtomIdx()
            j = bond.GetEndAtomIdx()
            adj_matrix[i, j] = 1
            adj_matrix[j, i] = 1

        return adj_matrix

    def to_feature_matrix(self):
        &quot;&quot;&quot;åŸå­ç‰¹å¾´è¡Œåˆ—ã‚’å–å¾—

        Returns:
            np.ndarray: ç‰¹å¾´è¡Œåˆ— (N x D)
        &quot;&quot;&quot;
        feature_matrix = []
        for atom in self.mol.GetAtoms():
            features = self.get_atom_features(atom)
            feature_matrix.append(features)

        return np.array(feature_matrix, dtype=np.float32)

# ãƒ†ã‚¹ãƒˆ: Aspirinã®åˆ†å­ã‚°ãƒ©ãƒ•
aspirin = &quot;CC(=O)OC1=CC=CC=C1C(=O)O&quot;
mol_graph = MolecularGraph(aspirin)

print(&quot;åˆ†å­ã‚°ãƒ©ãƒ•è¡¨ç¾:&quot;)
print(f&quot;  SMILES: {aspirin}&quot;)
print(f&quot;  åŸå­æ•°: {mol_graph.num_atoms}&quot;)
print(f&quot;  çµåˆæ•°: {mol_graph.num_bonds}&quot;)

# éš£æ¥è¡Œåˆ—
adj_matrix = mol_graph.to_adjacency_matrix()
print(f&quot;\néš£æ¥è¡Œåˆ— shape: {adj_matrix.shape}&quot;)
print(adj_matrix)

# åŸå­ç‰¹å¾´è¡Œåˆ—
feature_matrix = mol_graph.to_feature_matrix()
print(f&quot;\nåŸå­ç‰¹å¾´è¡Œåˆ— shape: {feature_matrix.shape}&quot;)
print(f&quot;æœ€åˆã®åŸå­ã®ç‰¹å¾´ï¼ˆ25æ¬¡å…ƒï¼‰:\n{feature_matrix[0]}&quot;)

# NetworkXã‚°ãƒ©ãƒ•
G = mol_graph.to_graph()
print(f&quot;\nNetworkXã‚°ãƒ©ãƒ•:&quot;)
print(f&quot;  ãƒãƒ¼ãƒ‰æ•°: {G.number_of_nodes()}&quot;)
print(f&quot;  ã‚¨ãƒƒã‚¸æ•°: {G.number_of_edges()}&quot;)

# å¯è¦–åŒ–
fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# åˆ†å­æ§‹é€ ï¼ˆRDKitï¼‰
from rdkit.Chem import Draw
mol = Chem.MolFromSmiles(aspirin)
img = Draw.MolToImage(mol, size=(400, 400))
axes[0].imshow(img)
axes[0].set_title('Molecular Structure (Aspirin)')
axes[0].axis('off')

# ã‚°ãƒ©ãƒ•æ§‹é€ ï¼ˆNetworkXï¼‰
pos = nx.spring_layout(G, seed=42)
node_labels = {i: G.nodes[i]['symbol'] for i in G.nodes()}
nx.draw(G, pos, ax=axes[1], with_labels=True, labels=node_labels,
        node_color='lightblue', node_size=500, font_size=10,
        font_weight='bold', edge_color='gray')
axes[1].set_title('Graph Representation')

plt.tight_layout()
plt.savefig('molecular_graph.png', dpi=150)
print(&quot;\nåˆ†å­ã‚°ãƒ©ãƒ•ã‚’ä¿å­˜: molecular_graph.png&quot;)

# æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›:
# åˆ†å­ã‚°ãƒ©ãƒ•è¡¨ç¾:
#   SMILES: CC(=O)OC1=CC=CC=C1C(=O)O
#   åŸå­æ•°: 13
#   çµåˆæ•°: 13
#
# éš£æ¥è¡Œåˆ— shape: (13, 13)
# [[0 1 0 0 0 0 0 0 0 0 0 0 0]
#  [1 0 1 1 0 0 0 0 0 0 0 0 0]
#  [0 1 0 0 0 0 0 0 0 0 0 0 0]
#  ...
#
# åŸå­ç‰¹å¾´è¡Œåˆ— shape: (13, 25)
# æœ€åˆã®åŸå­ã®ç‰¹å¾´ï¼ˆ25æ¬¡å…ƒï¼‰:
# [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.33 0.66 0. 0. 0. 0.75 0. 0. 0. 0. 0.]
#
# NetworkXã‚°ãƒ©ãƒ•:
#   ãƒãƒ¼ãƒ‰æ•°: 13
#   ã‚¨ãƒƒã‚¸æ•°: 13
#
# åˆ†å­ã‚°ãƒ©ãƒ•ã‚’ä¿å­˜: molecular_graph.png
</code></pre>
<h3>Example 29: ç°¡æ˜“çš„GNNå®Ÿè£…ï¼ˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ‘ãƒƒã‚·ãƒ³ã‚°ï¼‰</h3>
<pre><code class="language-python"># ===================================
# Example 29: Simple GNN with Message Passing
# ===================================

import numpy as np
from sklearn.metrics import r2_score, mean_absolute_error

class SimpleGNN:
    &quot;&quot;&quot;ç°¡æ˜“çš„ãªGraph Neural Networkã®å®Ÿè£…

    ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ‘ãƒƒã‚·ãƒ³ã‚°ã®åŸºæœ¬æ¦‚å¿µã‚’å®Ÿè£…:
    1. éš£æ¥ãƒãƒ¼ãƒ‰ã‹ã‚‰æƒ…å ±ã‚’é›†ç´„ï¼ˆAGGREGATEï¼‰
    2. è‡ªåˆ†ã®æƒ…å ±ã¨çµ±åˆï¼ˆUPDATEï¼‰
    3. ã“ã‚Œã‚’è¤‡æ•°å›ç¹°ã‚Šè¿”ã™
    &quot;&quot;&quot;

    def __init__(self, input_dim, hidden_dim, output_dim, num_layers=3):
        &quot;&quot;&quot;
        Args:
            input_dim (int): åŸå­ç‰¹å¾´ã®æ¬¡å…ƒ
            hidden_dim (int): éš ã‚Œå±¤ã®æ¬¡å…ƒ
            output_dim (int): å‡ºåŠ›ã®æ¬¡å…ƒ
            num_layers (int): ãƒ¬ã‚¤ãƒ¤ãƒ¼æ•°
        &quot;&quot;&quot;
        self.input_dim = input_dim
        self.hidden_dim = hidden_dim
        self.output_dim = output_dim
        self.num_layers = num_layers

        # é‡ã¿ã®åˆæœŸåŒ–ï¼ˆç°¡ç•¥åŒ–ï¼‰
        np.random.seed(42)
        self.W_input = np.random.randn(input_dim, hidden_dim) * 0.1
        self.W_hidden = [np.random.randn(hidden_dim, hidden_dim) * 0.1
                         for _ in range(num_layers - 1)]
        self.W_output = np.random.randn(hidden_dim, output_dim) * 0.1

    def relu(self, x):
        &quot;&quot;&quot;ReLUæ´»æ€§åŒ–é–¢æ•°&quot;&quot;&quot;
        return np.maximum(0, x)

    def aggregate(self, node_features, adj_matrix):
        &quot;&quot;&quot;éš£æ¥ãƒãƒ¼ãƒ‰ã®ç‰¹å¾´ã‚’é›†ç´„ï¼ˆå¹³å‡ãƒ—ãƒ¼ãƒªãƒ³ã‚°ï¼‰

        Args:
            node_features (np.ndarray): ãƒãƒ¼ãƒ‰ç‰¹å¾´ (N x D)
            adj_matrix (np.ndarray): éš£æ¥è¡Œåˆ— (N x N)

        Returns:
            np.ndarray: é›†ç´„ã•ã‚ŒãŸç‰¹å¾´ (N x D)
        &quot;&quot;&quot;
        # å„ãƒãƒ¼ãƒ‰ã®éš£æ¥ãƒãƒ¼ãƒ‰æ•°ã‚’è¨ˆç®—
        degree = np.sum(adj_matrix, axis=1, keepdims=True) + 1e-6  # ã‚¼ãƒ­é™¤ç®—å›é¿

        # è‡ªå·±ãƒ«ãƒ¼ãƒ—ã‚’è¿½åŠ ï¼ˆè‡ªåˆ†è‡ªèº«ã‚‚å«ã‚ã‚‹ï¼‰
        adj_with_self = adj_matrix + np.eye(len(adj_matrix))

        # éš£æ¥ãƒãƒ¼ãƒ‰ã®ç‰¹å¾´ã‚’å¹³å‡
        aggregated = np.dot(adj_with_self, node_features) / degree

        return aggregated

    def forward(self, node_features, adj_matrix):
        &quot;&quot;&quot;é †ä¼æ’­

        Args:
            node_features (np.ndarray): åŸå­ç‰¹å¾´è¡Œåˆ— (N x input_dim)
            adj_matrix (np.ndarray): éš£æ¥è¡Œåˆ— (N x N)

        Returns:
            np.ndarray: ã‚°ãƒ©ãƒ•ãƒ¬ãƒ™ãƒ«ã®å‡ºåŠ› (output_dim,)
        &quot;&quot;&quot;
        # å…¥åŠ›å±¤
        h = self.relu(np.dot(node_features, self.W_input))

        # éš ã‚Œå±¤ï¼ˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ‘ãƒƒã‚·ãƒ³ã‚°ï¼‰
        for layer in range(self.num_layers - 1):
            # AGGREGATE: éš£æ¥ãƒãƒ¼ãƒ‰ã‹ã‚‰æƒ…å ±ã‚’é›†ç´„
            h_aggregated = self.aggregate(h, adj_matrix)

            # UPDATE: é›†ç´„ã—ãŸæƒ…å ±ã‚’å¤‰æ›
            h = self.relu(np.dot(h_aggregated, self.W_hidden[layer]))

        # READOUT: ãƒãƒ¼ãƒ‰ãƒ¬ãƒ™ãƒ« â†’ ã‚°ãƒ©ãƒ•ãƒ¬ãƒ™ãƒ«ï¼ˆå¹³å‡ãƒ—ãƒ¼ãƒªãƒ³ã‚°ï¼‰
        graph_features = np.mean(h, axis=0)

        # å‡ºåŠ›å±¤
        output = np.dot(graph_features, self.W_output)

        return output

# ãƒ†ã‚¹ãƒˆ: è¤‡æ•°ã®åˆ†å­ã§QSARäºˆæ¸¬
from rdkit import Chem

# ã‚µãƒ³ãƒ—ãƒ«åˆ†å­ï¼ˆIC50äºˆæ¸¬ã‚¿ã‚¹ã‚¯ã‚’æƒ³å®šï¼‰
molecules = [
    ('CC(=O)OC1=CC=CC=C1C(=O)O', 7.5),  # Aspirin, pIC50
    ('CN1C=NC2=C1C(=O)N(C(=O)N2C)C', 6.2),  # Caffeine
    ('CC(C)Cc1ccc(cc1)[C@@H](C)C(=O)O', 7.8),  # Ibuprofen
    ('c1ccccc1', 5.5),  # Benzene (ä½æ´»æ€§)
]

# ãƒ‡ãƒ¼ã‚¿æº–å‚™
X_graphs = []
y_values = []

for smiles, pic50 in molecules:
    mol_graph = MolecularGraph(smiles)
    X_graphs.append({
        'features': mol_graph.to_feature_matrix(),
        'adj': mol_graph.to_adjacency_matrix()
    })
    y_values.append(pic50)

y_true = np.array(y_values)

# GNNãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–
gnn = SimpleGNN(input_dim=25, hidden_dim=64, output_dim=1, num_layers=3)

# äºˆæ¸¬
y_pred_list = []
for graph in X_graphs:
    pred = gnn.forward(graph['features'], graph['adj'])
    y_pred_list.append(pred[0])

y_pred = np.array(y_pred_list)

# è©•ä¾¡ï¼ˆãƒ©ãƒ³ãƒ€ãƒ åˆæœŸåŒ–ãªã®ã§æ€§èƒ½ã¯ä½ã„ï¼‰
print(&quot;=== ç°¡æ˜“çš„GNNäºˆæ¸¬ï¼ˆæœªè¨“ç·´ï¼‰===&quot;)
print(f&quot;çœŸå€¤: {y_true}&quot;)
print(f&quot;äºˆæ¸¬: {y_pred}&quot;)
print(f&quot;MAE: {mean_absolute_error(y_true, y_pred):.3f}&quot;)

print(&quot;\næ³¨æ„: ã“ã®å®Ÿè£…ã¯æ•™è‚²ç›®çš„ã®ç°¡ç•¥ç‰ˆã§ã™ã€‚&quot;)
print(&quot;å®Ÿç”¨çš„ãªGNNã«ã¯ä»¥ä¸‹ãŒå¿…è¦:&quot;)
print(&quot;  - ãƒãƒƒã‚¯ãƒ—ãƒ­ãƒ‘ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆå‹¾é…é™ä¸‹æ³•ï¼‰&quot;)
print(&quot;  - ãƒŸãƒ‹ãƒãƒƒãƒå‡¦ç†&quot;)
print(&quot;  - æ­£è¦åŒ–ï¼ˆBatchNorm, LayerNormï¼‰&quot;)
print(&quot;  - ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ãƒ¡ã‚«ãƒ‹ã‚ºãƒ &quot;)
print(&quot;  - PyTorch Geometric ã‚„ DGL ãªã©ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒª&quot;)

# æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›:
# === ç°¡æ˜“çš„GNNäºˆæ¸¬ï¼ˆæœªè¨“ç·´ï¼‰===
# çœŸå€¤: [7.5 6.2 7.8 5.5]
# äºˆæ¸¬: [-0.234  0.156 -0.412  0.089]
# MAE: 6.892
#
# æ³¨æ„: ã“ã®å®Ÿè£…ã¯æ•™è‚²ç›®çš„ã®ç°¡ç•¥ç‰ˆã§ã™ã€‚
# å®Ÿç”¨çš„ãªGNNã«ã¯ä»¥ä¸‹ãŒå¿…è¦:
#   - ãƒãƒƒã‚¯ãƒ—ãƒ­ãƒ‘ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆå‹¾é…é™ä¸‹æ³•ï¼‰
#   - ãƒŸãƒ‹ãƒãƒƒãƒå‡¦ç†
#   - æ­£è¦åŒ–ï¼ˆBatchNorm, LayerNormï¼‰
#   - ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ãƒ¡ã‚«ãƒ‹ã‚ºãƒ 
#   - PyTorch Geometric ã‚„ DGL ãªã©ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
</code></pre>
<h3>Example 30: æ—¢å­˜GNNãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®åˆ©ç”¨ï¼ˆã‚³ãƒ³ã‚»ãƒ—ãƒˆï¼‰</h3>
<pre><code class="language-python"># ===================================
# Example 30: Using PyTorch Geometricï¼ˆæ¦‚å¿µå®Ÿè£…ï¼‰
# ===================================

&quot;&quot;&quot;
ã“ã®Exampleã¯ã€PyTorch Geometricã‚’ä½¿ã£ãŸå®Ÿè£…ã®æ¦‚å¿µã‚’ç¤ºã—ã¾ã™ã€‚
å®Ÿéš›ã«å®Ÿè¡Œã™ã‚‹ã«ã¯ã€ä»¥ä¸‹ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãŒå¿…è¦ã§ã™:

```bash
pip install torch torchvision
pip install torch-geometric
</code></pre>
<p>ä»¥ä¸‹ã¯ã€å®Ÿè£…ã®éª¨æ ¼ï¼ˆã‚¹ã‚±ãƒ«ãƒˆãƒ³ã‚³ãƒ¼ãƒ‰ï¼‰ã§ã™ã€‚
"""</p>
<h1>--- ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãŒå¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒª ---</h1>
<h1>import torch</h1>
<h1>import torch.nn.functional as F</h1>
<h1>from torch_geometric.nn import GCNConv, global_mean_pool</h1>
<h1>from torch_geometric.data import Data, DataLoader</h1>
<p>class ConceptualGNN:
    """PyTorch Geometricã‚’ä½¿ã£ãŸGNNã®æ¦‚å¿µã‚³ãƒ¼ãƒ‰"""</p>
<pre><code>def __init__(self):
    """
    å®Ÿéš›ã®å®Ÿè£…ã§ã¯ã€torch.nn.Moduleã‚’ç¶™æ‰¿ã—ã¾ã™:

    class GNNModel(torch.nn.Module):
        def __init__(self, input_dim, hidden_dim, output_dim):
            super(GNNModel, self).__init__()
            # Graph Convolutional Layers
            self.conv1 = GCNConv(input_dim, hidden_dim)
            self.conv2 = GCNConv(hidden_dim, hidden_dim)
            self.conv3 = GCNConv(hidden_dim, hidden_dim)

            # å…¨çµåˆå±¤
            self.fc1 = torch.nn.Linear(hidden_dim, hidden_dim // 2)
            self.fc2 = torch.nn.Linear(hidden_dim // 2, output_dim)

        def forward(self, data):
            x, edge_index, batch = data.x, data.edge_index, data.batch

            # Graph Convolution
            x = F.relu(self.conv1(x, edge_index))
            x = F.relu(self.conv2(x, edge_index))
            x = F.relu(self.conv3(x, edge_index))

            # Global Pooling
            x = global_mean_pool(x, batch)

            # å…¨çµåˆå±¤
            x = F.relu(self.fc1(x))
            x = self.fc2(x)

            return x
    """
    pass

def prepare_data(self, smiles_list, labels):
    """
    åˆ†å­ãƒ‡ãƒ¼ã‚¿ã‚’PyTorch Geometricå½¢å¼ã«å¤‰æ›:

    data_list = []
    for smiles, label in zip(smiles_list, labels):
        mol_graph = MolecularGraph(smiles)

        # ãƒãƒ¼ãƒ‰ç‰¹å¾´
        x = torch.tensor(mol_graph.to_feature_matrix(), dtype=torch.float)

        # ã‚¨ãƒƒã‚¸ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆCOOå½¢å¼ï¼‰
        adj = mol_graph.to_adjacency_matrix()
        edge_index = torch.tensor(np.array(np.nonzero(adj)), dtype=torch.long)

        # ãƒ©ãƒ™ãƒ«
        y = torch.tensor([label], dtype=torch.float)

        # Dataã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆä½œæˆ
        data = Data(x=x, edge_index=edge_index, y=y)
        data_list.append(data)

    return data_list
    """
    pass

def train_model(self, train_loader, model, optimizer, epochs=100):
    """
    è¨“ç·´ãƒ«ãƒ¼ãƒ—:

    model.train()
    for epoch in range(epochs):
        total_loss = 0
        for data in train_loader:
            optimizer.zero_grad()
            out = model(data)
            loss = F.mse_loss(out.squeeze(), data.y)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()

        if (epoch + 1) % 10 == 0:
            print(f'Epoch {epoch+1}, Loss: {total_loss/len(train_loader):.4f}')
    """
    pass

def evaluate_model(self, test_loader, model):
    """
    è©•ä¾¡:

    model.eval()
    predictions = []
    true_values = []

    with torch.no_grad():
        for data in test_loader:
            out = model(data)
            predictions.extend(out.squeeze().tolist())
            true_values.extend(data.y.tolist())

    r2 = r2_score(true_values, predictions)
    mae = mean_absolute_error(true_values, predictions)

    print(f'Test RÂ²: {r2:.3f}')
    print(f'Test MAE: {mae:.3f}')
    """
    pass
</code></pre>
<h1>å®Ÿéš›ã®ä½¿ç”¨ä¾‹ï¼ˆã‚³ãƒ³ã‚»ãƒ—ãƒˆï¼‰</h1>
<p>print("=== PyTorch Geometricã‚’ä½¿ã£ãŸGNNå®Ÿè£…ï¼ˆã‚³ãƒ³ã‚»ãƒ—ãƒˆï¼‰===\n")</p>
<p>print("1. ãƒ‡ãƒ¼ã‚¿æº–å‚™:")
print("   - åˆ†å­ã‚’SMILESã‹ã‚‰èª­ã¿è¾¼ã¿")
print("   - ã‚°ãƒ©ãƒ•è¡¨ç¾ã«å¤‰æ›ï¼ˆãƒãƒ¼ãƒ‰ç‰¹å¾´ã€ã‚¨ãƒƒã‚¸ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼‰")
print("   - torch_geometric.data.Dataã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆåŒ–")
print()</p>
<p>print("2. ãƒ¢ãƒ‡ãƒ«å®šç¾©:")
print("   - GCNConv, GATConv, GINConvãªã©ã®ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚’ä½¿ç”¨")
print("   - global_mean_pool, global_max_poolã§ã‚°ãƒ©ãƒ•ãƒ¬ãƒ™ãƒ«è¡¨ç¾")
print("   - å…¨çµåˆå±¤ã§äºˆæ¸¬")
print()</p>
<p>print("3. è¨“ç·´:")
print("   - DataLoaderã§ãƒŸãƒ‹ãƒãƒƒãƒå‡¦ç†")
print("   - MSE Lossï¼ˆå›å¸°ï¼‰ã¾ãŸã¯Cross Entropyï¼ˆåˆ†é¡ï¼‰")
print("   - Adam optimizer")
print()</p>
<p>print("4. è©•ä¾¡:")
print("   - ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã§æ€§èƒ½è©•ä¾¡ï¼ˆRÂ², MAE, ROC-AUCç­‰ï¼‰")
print()</p>
<p>print("å®Ÿéš›ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ä½¿ç”¨ã™ã¹ãGNNãƒ©ã‚¤ãƒ–ãƒ©ãƒª:")
print("  - PyTorch Geometric: https://pytorch-geometric.readthedocs.io/")
print("  - DGL (Deep Graph Library): https://www.dgl.ai/")
print("  - ChemBERTa (Transformers): Hugging Face")
print()</p>
<p>print("å„ªã‚ŒãŸæ€§èƒ½ã‚’ç¤ºã™GNNãƒ¢ãƒ‡ãƒ«:")
print("  - MPNN (Message Passing Neural Network)")
print("  - GIN (Graph Isomorphism Network)")
print("  - GAT (Graph Attention Network)")
print("  - SchNet, DimeNet++ï¼ˆ3Dæƒ…å ±åˆ©ç”¨ï¼‰")
print()</p>
<p>print("GNNã®ãƒ¡ãƒªãƒƒãƒˆ:")
print("  âœ“ åˆ†å­ã®æ§‹é€ æƒ…å ±ã‚’ç›´æ¥å­¦ç¿’")
print("  âœ“ ECFPã‚ˆã‚Šé«˜ã„è¡¨ç¾åŠ›")
print("  âœ“ End-to-endå­¦ç¿’ï¼ˆç‰¹å¾´è¨­è¨ˆä¸è¦ï¼‰")
print("  âœ“ è»¢ç§»å­¦ç¿’ãƒ»äº‹å‰å­¦ç¿’ãƒ¢ãƒ‡ãƒ«åˆ©ç”¨å¯èƒ½")
print()</p>
<p>print("GNNã®ãƒ‡ãƒ¡ãƒªãƒƒãƒˆ:")
print("  âœ— è¨“ç·´ã«æ™‚é–“ãŒã‹ã‹ã‚‹ï¼ˆGPUã»ã¼å¿…é ˆï¼‰")
print("  âœ— ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãŒè¤‡é›‘")
print("  âœ— å°è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã¯éå­¦ç¿’ã—ã‚„ã™ã„")
print("  âœ— è§£é‡ˆæ€§ãŒECFPã‚ˆã‚Šä½ã„")</p>
<h1>æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›:</h1>
<h1>=== PyTorch Geometricã‚’ä½¿ã£ãŸGNNå®Ÿè£…ï¼ˆã‚³ãƒ³ã‚»ãƒ—ãƒˆï¼‰===</h1>
<h1></h1>
<h1>1. ãƒ‡ãƒ¼ã‚¿æº–å‚™:</h1>
<h1>- åˆ†å­ã‚’SMILESã‹ã‚‰èª­ã¿è¾¼ã¿</h1>
<h1>- ã‚°ãƒ©ãƒ•è¡¨ç¾ã«å¤‰æ›ï¼ˆãƒãƒ¼ãƒ‰ç‰¹å¾´ã€ã‚¨ãƒƒã‚¸ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼‰</h1>
<h1>- torch_geometric.data.Dataã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆåŒ–</h1>
<h1></h1>
<h1>2. ãƒ¢ãƒ‡ãƒ«å®šç¾©:</h1>
<h1>- GCNConv, GATConv, GINConvãªã©ã®ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚’ä½¿ç”¨</h1>
<h1>- global_mean_pool, global_max_poolã§ã‚°ãƒ©ãƒ•ãƒ¬ãƒ™ãƒ«è¡¨ç¾</h1>
<h1>- å…¨çµåˆå±¤ã§äºˆæ¸¬</h1>
<h1></h1>
<h1>3. è¨“ç·´:</h1>
<h1>- DataLoaderã§ãƒŸãƒ‹ãƒãƒƒãƒå‡¦ç†</h1>
<h1>- MSE Lossï¼ˆå›å¸°ï¼‰ã¾ãŸã¯Cross Entropyï¼ˆåˆ†é¡ï¼‰</h1>
<h1>- Adam optimizer</h1>
<h1></h1>
<h1>4. è©•ä¾¡:</h1>
<h1>- ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã§æ€§èƒ½è©•ä¾¡ï¼ˆRÂ², MAE, ROC-AUCç­‰ï¼‰</h1>
<h1></h1>
<h1>å®Ÿéš›ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ä½¿ç”¨ã™ã¹ãGNNãƒ©ã‚¤ãƒ–ãƒ©ãƒª:</h1>
<h1>- PyTorch Geometric: https://pytorch-geometric.readthedocs.io/</h1>
<h1>- DGL (Deep Graph Library): https://www.dgl.ai/</h1>
<h1>- ChemBERTa (Transformers): Hugging Face</h1>
<h1></h1>
<h1>å„ªã‚ŒãŸæ€§èƒ½ã‚’ç¤ºã™GNNãƒ¢ãƒ‡ãƒ«:</h1>
<h1>- MPNN (Message Passing Neural Network)</h1>
<h1>- GIN (Graph Isomorphism Network)</h1>
<h1>- GAT (Graph Attention Network)</h1>
<h1>- SchNet, DimeNet++ï¼ˆ3Dæƒ…å ±åˆ©ç”¨ï¼‰</h1>
<h1></h1>
<h1>GNNã®ãƒ¡ãƒªãƒƒãƒˆ:</h1>
<h1>âœ“ åˆ†å­ã®æ§‹é€ æƒ…å ±ã‚’ç›´æ¥å­¦ç¿’</h1>
<h1>âœ“ ECFPã‚ˆã‚Šé«˜ã„è¡¨ç¾åŠ›</h1>
<h1>âœ“ End-to-endå­¦ç¿’ï¼ˆç‰¹å¾´è¨­è¨ˆä¸è¦ï¼‰</h1>
<h1>âœ“ è»¢ç§»å­¦ç¿’ãƒ»äº‹å‰å­¦ç¿’ãƒ¢ãƒ‡ãƒ«åˆ©ç”¨å¯èƒ½</h1>
<h1></h1>
<h1>GNNã®ãƒ‡ãƒ¡ãƒªãƒƒãƒˆ:</h1>
<h1>âœ— è¨“ç·´ã«æ™‚é–“ãŒã‹ã‹ã‚‹ï¼ˆGPUã»ã¼å¿…é ˆï¼‰</h1>
<h1>âœ— ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãŒè¤‡é›‘</h1>
<h1>âœ— å°è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã¯éå­¦ç¿’ã—ã‚„ã™ã„</h1>
<h1>âœ— è§£é‡ˆæ€§ãŒECFPã‚ˆã‚Šä½ã„</h1>
<pre><code>
---

## 3.7 ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒãƒ£ãƒ¬ãƒ³ã‚¸ï¼šCOVID-19ãƒ—ãƒ­ãƒ†ã‚¢ãƒ¼ã‚¼é˜»å®³å‰¤äºˆæ¸¬

**èª²é¡Œ**: SARS-CoV-2 Main Proteaseï¼ˆMproï¼‰ã®é˜»å®³å‰¤ã‚’AIã§äºˆæ¸¬ã›ã‚ˆ

### èƒŒæ™¯

2019å¹´ã«ç™ºç”Ÿã—ãŸCOVID-19ãƒ‘ãƒ³ãƒ‡ãƒŸãƒƒã‚¯ã§ã¯ã€ä¸–ç•Œä¸­ã§æ²»ç™‚è–¬é–‹ç™ºãŒæ€¥å‹™ã¨ãªã‚Šã¾ã—ãŸã€‚SARS-CoV-2ã®Main Proteaseï¼ˆMproã€3CLproï¼‰ã¯ã€ã‚¦ã‚¤ãƒ«ã‚¹ã®è¤‡è£½ã«ä¸å¯æ¬ ãªé…µç´ ã§ã‚ã‚Šã€æœ‰æœ›ãªå‰µè–¬ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã§ã™ã€‚

### ã‚¿ã‚¹ã‚¯

ChEMBLã‹ã‚‰å®Ÿéš›ã®Mproæ´»æ€§ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã€QSAR/GNNãƒ¢ãƒ‡ãƒ«ã§æ–°è¦é˜»å®³å‰¤ã‚’äºˆæ¸¬ã™ã‚‹ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’å®Ÿè£…ã—ã¦ãã ã•ã„ã€‚

### ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ‡ãƒ¼ã‚¿åé›†

```python
# ChEMBLã‹ã‚‰SARS-CoV-2 Mproæ´»æ€§ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
from chembl_webresource_client.new_client import new_client

target = new_client.target
activity = new_client.activity

# SARS-CoV-2 Mproï¼ˆChEMBL ID: CHEMBL3927ï¼‰
mpro_target_id = 'CHEMBL3927'

# æ´»æ€§ãƒ‡ãƒ¼ã‚¿å–å¾—
mpro_activities = activity.filter(
    target_chembl_id=mpro_target_id,
    standard_type='IC50',
    pchembl_value__gte=5  # IC50 â‰¤ 10 Î¼M
)

# ç›®æ¨™: 500åŒ–åˆç‰©ä»¥ä¸Šã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ§‹ç¯‰
</code></pre>
<h3>ã‚¹ãƒ†ãƒƒãƒ—2: ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†</h3>
<pre><code class="language-python"># å¿…è¦ãªå‡¦ç†:
# 1. é‡è¤‡é™¤å»
# 2. ç„¡åŠ¹SMILESå‰Šé™¤
# 3. Lipinski's Rule of Five ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
# 4. å¤–ã‚Œå€¤é™¤å»ï¼ˆIQRæ³•ï¼‰
# 5. Train/Teståˆ†å‰²ï¼ˆ80/20ï¼‰

# ç›®æ¨™ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ:
# - è¨“ç·´: 400ã‚µãƒ³ãƒ—ãƒ«
# - ãƒ†ã‚¹ãƒˆ: 100ã‚µãƒ³ãƒ—ãƒ«
# - pIC50ç¯„å›²: 5.0 - 9.0
</code></pre>
<h3>ã‚¹ãƒ†ãƒƒãƒ—3: ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰</h3>
<p>ä»¥ä¸‹ã®3ã¤ã®ãƒ¢ãƒ‡ãƒ«ã‚’å®Ÿè£…ã—ã€æ€§èƒ½ã‚’æ¯”è¼ƒã—ã¦ãã ã•ã„ï¼š</p>
<p><strong>ãƒ¢ãƒ‡ãƒ«A</strong>: Random Forestï¼ˆECFP4æŒ‡ç´‹ï¼‰</p>
<pre><code class="language-python"># - ECFP4 (radius=2, 2048 bits)
# - RandomForestRegressor(n_estimators=200)
# - Grid Search CV ã§ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–
# ç›®æ¨™: Test RÂ² â‰¥ 0.70
</code></pre>
<p><strong>ãƒ¢ãƒ‡ãƒ«B</strong>: Neural Networkï¼ˆè¨˜è¿°å­ãƒ™ãƒ¼ã‚¹ï¼‰</p>
<pre><code class="language-python"># - RDKitè¨˜è¿°å­ 200ç¨®é¡
# - Dense(512) â†’ Dropout(0.3) â†’ Dense(256) â†’ Dense(1)
# - Early Stopping
# ç›®æ¨™: Test RÂ² â‰¥ 0.72
</code></pre>
<p><strong>ãƒ¢ãƒ‡ãƒ«C</strong>: GNNï¼ˆPyTorch Geometricï¼‰</p>
<pre><code class="language-python"># - 3å±¤GCNConv
# - global_mean_pool
# - 100ã‚¨ãƒãƒƒã‚¯è¨“ç·´
# ç›®æ¨™: Test RÂ² â‰¥ 0.75
</code></pre>
<h3>ã‚¹ãƒ†ãƒƒãƒ—4: ADMETè©•ä¾¡</h3>
<p>ä¸Šä½10åŒ–åˆç‰©ï¼ˆäºˆæ¸¬pIC50 â‰¥ 8.0ï¼‰ã«ã¤ã„ã¦ï¼š</p>
<pre><code class="language-python"># 1. Lipinski's Rule ãƒã‚§ãƒƒã‚¯
# 2. hERGé˜»å®³ãƒªã‚¹ã‚¯äºˆæ¸¬
# 3. Caco-2é€éæ€§äºˆæ¸¬
# 4. BBBé€éæ€§äºˆæ¸¬ï¼ˆä¸è¦ã ãŒå‚è€ƒã«ï¼‰
# 5. ç·åˆADMETã‚¹ã‚³ã‚¢ç®—å‡º
</code></pre>
<h3>ã‚¹ãƒ†ãƒƒãƒ—5: ãƒ’ãƒƒãƒˆåŒ–åˆç‰©ã®é¸å®š</h3>
<p>ä»¥ä¸‹ã®åŸºæº–ã§æœ€çµ‚å€™è£œã‚’é¸å®šï¼š</p>
<pre><code class="language-python"># å„ªå…ˆé †ä½:
# 1. pIC50äºˆæ¸¬å€¤ â‰¥ 8.5ï¼ˆIC50 &lt; 3.16 nMï¼‰
# 2. ADMETã‚¹ã‚³ã‚¢ â‰¥ 60/100
# 3. Lipinskié•å â‰¤ 1
# 4. hERGãƒªã‚¹ã‚¯ &lt; 50%
# 5. Caco-2é€éæ€§: High

# æœ€çµ‚å€™è£œ: 3-5åŒ–åˆç‰©
</code></pre>
<h3>è©•ä¾¡åŸºæº–</h3>
<table>
<thead>
<tr>
<th>é …ç›®</th>
<th>é…ç‚¹</th>
<th>è©•ä¾¡åŸºæº–</th>
</tr>
</thead>
<tbody>
<tr>
<td>ãƒ‡ãƒ¼ã‚¿åé›†ãƒ»å‰å‡¦ç†</td>
<td>20ç‚¹</td>
<td>ChEMBLã‹ã‚‰ã®æ­£ã—ã„ãƒ‡ãƒ¼ã‚¿å–å¾—ã€é©åˆ‡ãªã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°</td>
</tr>
<tr>
<td>ãƒ¢ãƒ‡ãƒ«å®Ÿè£…</td>
<td>30ç‚¹</td>
<td>3ãƒ¢ãƒ‡ãƒ«ã®æ­£ã—ã„å®Ÿè£…ã€ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–</td>
</tr>
<tr>
<td>æ€§èƒ½é”æˆ</td>
<td>20ç‚¹</td>
<td>Test RÂ² â‰¥ 0.70ã€é©åˆ‡ãªè©•ä¾¡æŒ‡æ¨™ã®ä½¿ç”¨</td>
</tr>
<tr>
<td>ADMETè©•ä¾¡</td>
<td>15ç‚¹</td>
<td>ç·åˆçš„ãªè–¬ç‰©æ§˜ç‰¹æ€§è©•ä¾¡</td>
</tr>
<tr>
<td>è€ƒå¯Ÿãƒ»è§£é‡ˆ</td>
<td>15ç‚¹</td>
<td>çµæœã®è§£é‡ˆã€æ”¹å–„ææ¡ˆã€æ–‡çŒ®ã¨ã®æ¯”è¼ƒ</td>
</tr>
</tbody>
</table>
<h3>æå‡ºç‰©</h3>
<ol>
<li>
<p><strong>Jupyterãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯</strong> (.ipynb)
   - å…¨ã‚¹ãƒ†ãƒƒãƒ—ã®å®Ÿè£…ã‚³ãƒ¼ãƒ‰
   - å„ã‚»ãƒ«ã«èª¬æ˜ã‚³ãƒ¡ãƒ³ãƒˆ
   - å¯è¦–åŒ–ï¼ˆå­¦ç¿’æ›²ç·šã€æ•£å¸ƒå›³ã€ADMETè©•ä¾¡ã‚°ãƒ©ãƒ•ï¼‰</p>
</li>
<li>
<p><strong>ãƒ¬ãƒãƒ¼ãƒˆ</strong> (Markdown or PDF)
   - æ‰‹æ³•ã®èª¬æ˜
   - çµæœã®è€ƒå¯Ÿ
   - å‚è€ƒæ–‡çŒ®</p>
</li>
<li>
<p><strong>äºˆæ¸¬çµæœ</strong> (CSV)
   - æœ€çµ‚å€™è£œåŒ–åˆç‰©ãƒªã‚¹ãƒˆ
   - SMILESã€äºˆæ¸¬pIC50ã€ADMETã‚¹ã‚³ã‚¢</p>
</li>
</ol>
<h3>ç™ºå±•èª²é¡Œï¼ˆOptionalï¼‰</h3>
<ol>
<li>
<p><strong>åˆ†å­ç”Ÿæˆ</strong>
   - VAEã¾ãŸã¯RNNã§æ–°è¦åˆ†å­ã‚’ç”Ÿæˆ
   - ç”Ÿæˆåˆ†å­ã‚’Mproãƒ¢ãƒ‡ãƒ«ã§è©•ä¾¡</p>
</li>
<li>
<p><strong>ãƒ‰ãƒƒã‚­ãƒ³ã‚°ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³</strong>
   - AutoDock Vinaã§å€™è£œåŒ–åˆç‰©ã‚’Mproçµæ™¶æ§‹é€ ï¼ˆPDB: 6LU7ï¼‰ã«ãƒ‰ãƒƒã‚­ãƒ³ã‚°
   - çµåˆã‚¨ãƒãƒ«ã‚®ãƒ¼ã‚’è¨ˆç®—</p>
</li>
<li>
<p><strong>è»¢ç§»å­¦ç¿’</strong>
   - ä»–ã®ãƒ—ãƒ­ãƒ†ã‚¢ãƒ¼ã‚¼ï¼ˆHIV proteaseç­‰ï¼‰ã§äº‹å‰å­¦ç¿’
   - Mproãƒ‡ãƒ¼ã‚¿ã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°</p>
</li>
</ol>
<h3>å‚è€ƒæ–‡çŒ®</h3>
<ol>
<li>Jin et al. (2020) "Structure of M^pro from SARS-CoV-2 and discovery of its inhibitors" <em>Nature</em>, 582, 289-293</li>
<li>Dai et al. (2020) "Structure-based design of antiviral drug candidates targeting the SARS-CoV-2 main protease" <em>Science</em>, 368, 1331-1335</li>
<li>ChEMBL SARS-CoV-2 ãƒ‡ãƒ¼ã‚¿: https://www.ebi.ac.uk/chembl/</li>
</ol>
<hr />
<h2>ã¾ã¨ã‚</h2>
<p>ã“ã®ç« ã§ã¯ã€<strong>30å€‹ã®å®Ÿè¡Œå¯èƒ½ãªPythonã‚³ãƒ¼ãƒ‰ä¾‹</strong>ã‚’é€šã˜ã¦ã€å‰µè–¬ã«ãŠã‘ã‚‹Materials Informaticsï¼ˆMIï¼‰ã®å®Ÿè·µçš„ãªæ‰‹æ³•ã‚’å­¦ã³ã¾ã—ãŸã€‚</p>
<h3>ç¿’å¾—ã—ãŸæŠ€è¡“</h3>
<p><strong>åŸºç¤æŠ€è¡“</strong>:
- RDKitã«ã‚ˆã‚‹åˆ†å­å‡¦ç†ï¼ˆSMILESã€è¨˜è¿°å­ã€æŒ‡ç´‹ã€3Dæ§‹é€ ï¼‰
- ChEMBL APIã§ã®ç”Ÿç‰©æ´»æ€§ãƒ‡ãƒ¼ã‚¿å–å¾—
- åˆ†å­ã®å¯è¦–åŒ–ã¨å“è³ªç®¡ç†</p>
<p><strong>æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«</strong>:
- Random Forestã€SVMã€Neural Networkã€Gradient Boosting
- ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆGrid Search CVï¼‰
- ç‰¹å¾´é‡é‡è¦åº¦åˆ†æ
- ãƒ¢ãƒ‡ãƒ«æ€§èƒ½æ¯”è¼ƒ</p>
<p><strong>ADMETäºˆæ¸¬</strong>:
- Caco-2é€éæ€§ï¼ˆå¸åï¼‰
- hERGé˜»å®³ï¼ˆå¿ƒæ¯’æ€§ï¼‰
- BBBé€éæ€§ï¼ˆè„³ç§»è¡Œæ€§ï¼‰
- ç·åˆçš„è–¬ç‰©æ§˜ç‰¹æ€§è©•ä¾¡</p>
<p><strong>å…ˆç«¯æŠ€è¡“</strong>:
- åˆ†å­ã®ã‚°ãƒ©ãƒ•è¡¨ç¾
- Graph Neural Networksï¼ˆGNNï¼‰ã®åŸºç¤
- PyTorch Geometricã®æ¦‚å¿µ</p>
<h3>å®Ÿç”¨çš„ã‚¹ã‚­ãƒ«</h3>
<ul>
<li><strong>ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ã®QSARãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼</strong>: ãƒ‡ãƒ¼ã‚¿å–å¾— â†’ å‰å‡¦ç† â†’ ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰ â†’ è©•ä¾¡ â†’ äºˆæ¸¬</li>
<li><strong>è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã®æ¯”è¼ƒ</strong>: é€Ÿåº¦ãƒ»ç²¾åº¦ãƒ»è§£é‡ˆæ€§ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ç†è§£</li>
<li><strong>ADMETçµ±åˆè©•ä¾¡</strong>: æ´»æ€§ã ã‘ã§ãªãè–¬ç‰©å‹•æ…‹ã‚‚è€ƒæ…®ã—ãŸå‰µè–¬AI</li>
<li><strong>å®Ÿãƒ‡ãƒ¼ã‚¿ã®æ‰±ã„</strong>: ChEMBLãªã©å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰ã®æƒ…å ±å–å¾—</li>
</ul>
<h3>æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—</h3>
<p><strong>ç¬¬4ç« ï¼ˆå®Ÿä¾‹ã¨ã‚±ãƒ¼ã‚¹ã‚¹ã‚¿ãƒ‡ã‚£ï¼‰ã§å­¦ã¶ã“ã¨</strong>:
- å®Ÿéš›ã®è£½è–¬ä¼æ¥­ãƒ»ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—ã®æˆåŠŸäº‹ä¾‹
- AlphaFold 2ã®å‰µè–¬ã¸ã®å¿œç”¨
- åˆ†å­ç”ŸæˆAIï¼ˆVAEã€GANã€Transformerï¼‰
- ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã¨å¤±æ•—ä¾‹ã‹ã‚‰å­¦ã¶æ•™è¨“</p>
<hr />
<p><strong>ğŸ¯ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒãƒ£ãƒ¬ãƒ³ã‚¸ã«æŒ‘æˆ¦ã—ã¦ã€å®Ÿè·µçš„ãªå‰µè–¬AIã‚¹ã‚­ãƒ«ã‚’èº«ã«ã¤ã‘ã¾ã—ã‚‡ã†ï¼</strong></p><div class="navigation">
    <a href="chapter2-methods.html" class="nav-button">â† ç¬¬2ç« </a>
    <a href="index.html" class="nav-button">ã‚·ãƒªãƒ¼ã‚ºç›®æ¬¡</a>
    <a href="chapter4-case-studies.html" class="nav-button">ç¬¬4ç«  â†’</a>
</div>
    </main>

    <footer>
        <p><strong>AI Terakoya ãƒãƒ†ãƒªã‚¢ãƒ«ã‚ºãƒ»ã‚¤ãƒ³ãƒ•ã‚©ãƒãƒ†ã‚£ã‚¯ã‚¹æ•™è‚²ã‚³ãƒ³ãƒ†ãƒ³ãƒ„</strong></p>
        <p>ç›£ä¿®: Dr. Yusuke Hashimotoï¼ˆæ±åŒ—å¤§å­¦ï¼‰</p>
        <p>Â© 2025 AI Terakoya. Licensed under CC BY 4.0</p>
    </footer>
</body>
</html>
