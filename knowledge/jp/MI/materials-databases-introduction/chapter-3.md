---
title: ç¬¬3ç« ï¼šãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çµ±åˆã¨ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼
chapter_title: ç¬¬3ç« ï¼šãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çµ±åˆã¨ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼
subtitle: è¤‡æ•°DBã®çµ±åˆã¨ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°å®Ÿè·µ
reading_time: 20-25åˆ†
difficulty: åˆç´šã€œä¸­ç´š
code_examples: 12
exercises: 3
---

# ç¬¬3ç« ï¼šãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çµ±åˆã¨ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼

ã‚¹ã‚­ãƒ¼ãƒã®é•ã„ã‚’ä¹—ã‚Šè¶Šãˆã¦ãƒ‡ãƒ¼ã‚¿ã‚’çµ±åˆã™ã‚‹æµã‚Œã‚’å­¦ã³ã¾ã™ã€‚å“è³ªç®¡ç†ã¨è¿½è·¡å¯èƒ½æ€§ã®å‹˜æ‰€ã‚‚ç¢ºèªã—ã¾ã™ã€‚

**ğŸ’¡ è£œè¶³:** ã‚­ãƒ¼æ•´åˆã¨å˜ä½çµ±ä¸€ãŒæœ€é‡è¦ã€‚ç”±æ¥ï¼ˆprovenanceï¼‰ã‚’æ®‹ã™ã¨å¾Œã‹ã‚‰æ¤œè¨¼ã§ãã¾ã™ã€‚

**è¤‡æ•°DBã®çµ±åˆã¨ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°å®Ÿè·µ**

## å­¦ç¿’ç›®æ¨™

ã“ã®ç« ã‚’èª­ã‚€ã“ã¨ã§ã€ä»¥ä¸‹ã‚’ç¿’å¾—ã§ãã¾ã™ï¼š

  * âœ… Materials Projectã¨AFLOWãƒ‡ãƒ¼ã‚¿ã‚’çµ±åˆã§ãã‚‹
  * âœ… ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã®æ¨™æº–æ‰‹æ³•ã‚’é©ç”¨ã§ãã‚‹
  * âœ… æ¬ æå€¤ã‚’é©åˆ‡ã«å‡¦ç†ã§ãã‚‹
  * âœ… è‡ªå‹•æ›´æ–°ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’æ§‹ç¯‰ã§ãã‚‹
  * âœ… ãƒ‡ãƒ¼ã‚¿å“è³ªã‚’å®šé‡çš„ã«è©•ä¾¡ã§ãã‚‹

**èª­äº†æ™‚é–“** : 20-25åˆ† **ã‚³ãƒ¼ãƒ‰ä¾‹** : 12å€‹ **æ¼”ç¿’å•é¡Œ** : 3å•

* * *

## 3.1 è¤‡æ•°ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®çµ±åˆ

ææ–™ç ”ç©¶ã§ã¯ã€å˜ä¸€ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã ã‘ã§ãªãã€è¤‡æ•°ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã§ã€ã‚ˆã‚Šä¿¡é ¼æ€§ã®é«˜ã„çµæœãŒå¾—ã‚‰ã‚Œã¾ã™ã€‚ã“ã“ã§ã¯ã€Materials Projectã¨AFLOWãƒ‡ãƒ¼ã‚¿ã‚’çµ±åˆã™ã‚‹æ–¹æ³•ã‚’å­¦ã³ã¾ã™ã€‚

### 3.1.1 ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çµ±åˆã®åŸºæœ¬æˆ¦ç•¥
    
    
    ```mermaid
    flowchart TD
        A[Materials Project] --> C[å…±é€šè­˜åˆ¥å­ã§ç…§åˆ]
        B[AFLOW] --> C
        C --> D[ãƒ‡ãƒ¼ã‚¿çµåˆ]
        D --> E[é‡è¤‡å‰Šé™¤]
        E --> F[æ¬ æå€¤å‡¦ç†]
        F --> G[çµ±åˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ]
    
        style A fill:#e3f2fd
        style B fill:#fff3e0
        style G fill:#e8f5e9
    ```

**ã‚³ãƒ¼ãƒ‰ä¾‹1: Materials Projectã¨AFLOWãƒ‡ãƒ¼ã‚¿ã®å–å¾—**
    
    
    from mp_api.client import MPRester
    import requests
    import pandas as pd
    
    MP_API_KEY = "your_mp_key"
    
    def get_mp_data(formula):
        """Materials Projectã‹ã‚‰ãƒ‡ãƒ¼ã‚¿å–å¾—"""
        with MPRester(MP_API_KEY) as mpr:
            docs = mpr.materials.summary.search(
                formula=formula,
                fields=[
                    "material_id",
                    "formula_pretty",
                    "band_gap",
                    "formation_energy_per_atom",
                    "energy_above_hull"
                ]
            )
    
            if docs:
                doc = docs[0]
                return {
                    "source": "Materials Project",
                    "id": doc.material_id,
                    "formula": doc.formula_pretty,
                    "band_gap": doc.band_gap,
                    "formation_energy":
                        doc.formation_energy_per_atom,
                    "stability": doc.energy_above_hull
                }
        return None
    
    def get_aflow_data(formula):
        """AFLOWã‹ã‚‰ãƒ‡ãƒ¼ã‚¿å–å¾—"""
        url = "http://aflowlib.org/API/aflux"
        params = {
            "species": formula,
            "$": "formula,Egap,enthalpy_formation_atom"
        }
    
        try:
            response = requests.get(url, params=params, timeout=10)
            data = response.json()
    
            if data:
                item = data[0]
                return {
                    "source": "AFLOW",
                    "id": item.get("auid", "N/A"),
                    "formula": item.get("formula", formula),
                    "band_gap": item.get("Egap", None),
                    "formation_energy":
                        item.get("enthalpy_formation_atom", None),
                    "stability": None  # AFLOWã«ã¯ç›´æ¥çš„ãªå€¤ãªã—
                }
        except Exception as e:
            print(f"AFLOWå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
    
        return None
    
    # TiO2ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä¸¡æ–¹ã‹ã‚‰å–å¾—
    formula = "TiO2"
    mp_data = get_mp_data(formula)
    aflow_data = get_aflow_data(formula)
    
    print(f"=== {formula}ã®ãƒ‡ãƒ¼ã‚¿æ¯”è¼ƒ ===")
    print(f"\nMaterials Project:")
    print(mp_data)
    print(f"\nAFLOW:")
    print(aflow_data)
    

**å‡ºåŠ›ä¾‹** :
    
    
    === TiO2ã®ãƒ‡ãƒ¼ã‚¿æ¯”è¼ƒ ===
    
    Materials Project:
    {'source': 'Materials Project', 'id': 'mp-2657', 'formula': 'TiO2',
     'band_gap': 3.44, 'formation_energy': -4.872, 'stability': 0.0}
    
    AFLOW:
    {'source': 'AFLOW', 'id': 'aflow:123456', 'formula': 'TiO2',
     'band_gap': 3.38, 'formation_energy': -4.915, 'stability': None}
    

### 3.1.2 ãƒ‡ãƒ¼ã‚¿çµåˆï¼ˆJoinï¼‰

**ã‚³ãƒ¼ãƒ‰ä¾‹2: åŒ–å­¦å¼ã‚’ã‚­ãƒ¼ã¨ã—ãŸçµåˆ**
    
    
    import pandas as pd
    
    def merge_databases(formulas):
        """è¤‡æ•°ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ãƒ‡ãƒ¼ã‚¿ã‚’çµåˆ"""
        mp_data_list = []
        aflow_data_list = []
    
        for formula in formulas:
            mp_data = get_mp_data(formula)
            if mp_data:
                mp_data_list.append(mp_data)
    
            aflow_data = get_aflow_data(formula)
            if aflow_data:
                aflow_data_list.append(aflow_data)
    
        # DataFrameã«å¤‰æ›
        df_mp = pd.DataFrame(mp_data_list)
        df_aflow = pd.DataFrame(aflow_data_list)
    
        # åŒ–å­¦å¼ã§ãƒãƒ¼ã‚¸
        df_merged = pd.merge(
            df_mp,
            df_aflow,
            on="formula",
            how="outer",
            suffixes=("_mp", "_aflow")
        )
    
        return df_merged
    
    # è¤‡æ•°ææ–™ã§çµ±åˆ
    formulas = ["TiO2", "ZnO", "GaN", "SiC"]
    df = merge_databases(formulas)
    
    print("çµ±åˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ:")
    print(df)
    print(f"\nç·ä»¶æ•°: {len(df)}")
    

**å‡ºåŠ›ä¾‹** :
    
    
    çµ±åˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ:
      formula    id_mp  band_gap_mp  formation_energy_mp    id_aflow  band_gap_aflow  ...
    0    TiO2  mp-2657         3.44                -4.872  aflow:123              3.38  ...
    1     ZnO  mp-2133         3.44                -1.950  aflow:456              3.41  ...
    ...
    
    ç·ä»¶æ•°: 4
    

* * *

## 3.2 ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°

### 3.2.1 é‡è¤‡ãƒ‡ãƒ¼ã‚¿ã®æ¤œå‡ºã¨å‰Šé™¤

**ã‚³ãƒ¼ãƒ‰ä¾‹3: é‡è¤‡æ¤œå‡º**
    
    
    import pandas as pd
    
    def detect_duplicates(df):
        """é‡è¤‡ãƒ‡ãƒ¼ã‚¿ã®æ¤œå‡º"""
        # åŒ–å­¦å¼ã«ã‚ˆã‚‹é‡è¤‡
        duplicates = df[df.duplicated(subset=['formula'],
                                       keep=False)]
    
        print("=== é‡è¤‡ãƒ‡ãƒ¼ã‚¿æ¤œå‡º ===")
        print(f"ç·ãƒ‡ãƒ¼ã‚¿æ•°: {len(df)}")
        print(f"é‡è¤‡ã‚ã‚Š: {len(duplicates)}")
    
        if len(duplicates) > 0:
            print("\né‡è¤‡ãƒ‡ãƒ¼ã‚¿:")
            print(duplicates[['formula', 'source', 'id']])
    
        # é‡è¤‡å‰Šé™¤ï¼ˆæœ€åˆã®ã‚¨ãƒ³ãƒˆãƒªã‚’ä¿æŒï¼‰
        df_clean = df.drop_duplicates(subset=['formula'],
                                       keep='first')
    
        print(f"\né‡è¤‡å‰Šé™¤å¾Œ: {len(df_clean)}ä»¶")
        return df_clean
    
    # ä½¿ç”¨ä¾‹
    df_clean = detect_duplicates(df)
    

### 3.2.2 ç•°å¸¸å€¤ã®æ¤œå‡º

**ã‚³ãƒ¼ãƒ‰ä¾‹4: å¤–ã‚Œå€¤æ¤œå‡ºï¼ˆIQRæ³•ï¼‰**
    
    
    import numpy as np
    
    def detect_outliers(df, column):
        """IQRæ³•ã«ã‚ˆã‚‹å¤–ã‚Œå€¤æ¤œå‡º"""
        Q1 = df[column].quantile(0.25)
        Q3 = df[column].quantile(0.75)
        IQR = Q3 - Q1
    
        # å¤–ã‚Œå€¤ã®ç¯„å›²
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
    
        # å¤–ã‚Œå€¤æ¤œå‡º
        outliers = df[
            (df[column] < lower_bound) |
            (df[column] > upper_bound)
        ]
    
        print(f"=== {column}ã®å¤–ã‚Œå€¤æ¤œå‡º ===")
        print(f"Q1: {Q1:.3f}, Q3: {Q3:.3f}, IQR: {IQR:.3f}")
        print(f"ç¯„å›²: [{lower_bound:.3f}, {upper_bound:.3f}]")
        print(f"å¤–ã‚Œå€¤: {len(outliers)}ä»¶")
    
        if len(outliers) > 0:
            print("\nå¤–ã‚Œå€¤ãƒ‡ãƒ¼ã‚¿:")
            print(outliers[['formula', column]])
    
        return outliers
    
    # ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—ã®å¤–ã‚Œå€¤æ¤œå‡º
    outliers_bg = detect_outliers(df_clean, 'band_gap_mp')
    

* * *

## 3.3 æ¬ æå€¤å‡¦ç†

### 3.3.1 æ¬ æãƒ‘ã‚¿ãƒ¼ãƒ³ã®å¯è¦–åŒ–

**ã‚³ãƒ¼ãƒ‰ä¾‹5: æ¬ æå€¤ã®åˆ†æ**
    
    
    import matplotlib.pyplot as plt
    import seaborn as sns
    
    def analyze_missing_values(df):
        """æ¬ æå€¤ã®è©³ç´°åˆ†æ"""
        # æ¬ æå€¤ã‚«ã‚¦ãƒ³ãƒˆ
        missing_count = df.isnull().sum()
        missing_percent = (missing_count / len(df)) * 100
    
        # ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ
        missing_df = pd.DataFrame({
            "Column": missing_count.index,
            "Missing Count": missing_count.values,
            "Missing %": missing_percent.values
        })
        missing_df = missing_df[missing_df["Missing Count"] > 0]
        missing_df = missing_df.sort_values("Missing %",
                                            ascending=False)
    
        print("=== æ¬ æå€¤ãƒ¬ãƒãƒ¼ãƒˆ ===")
        print(missing_df)
    
        # ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—
        plt.figure(figsize=(10, 6))
        sns.heatmap(
            df.isnull(),
            cbar=True,
            cmap='viridis',
            yticklabels=False
        )
        plt.title("Missing Values Heatmap")
        plt.xlabel("Columns")
        plt.tight_layout()
        plt.savefig("missing_values_heatmap.png", dpi=150)
        plt.show()
    
        return missing_df
    
    # æ¬ æå€¤åˆ†æ
    missing_report = analyze_missing_values(df_clean)
    

### 3.3.2 æ¬ æå€¤ã®è£œå®Œ

**ã‚³ãƒ¼ãƒ‰ä¾‹6: è£œå®Œæˆ¦ç•¥**
    
    
    from sklearn.impute import SimpleImputer, KNNImputer
    
    def impute_missing_values(df, method='mean'):
        """
        æ¬ æå€¤è£œå®Œ
    
        Parameters:
        -----------
        method : str
            'mean', 'median', 'knn'ã®ã„ãšã‚Œã‹
        """
        numeric_cols = df.select_dtypes(
            include=[np.number]
        ).columns
    
        df_imputed = df.copy()
    
        if method == 'mean':
            imputer = SimpleImputer(strategy='mean')
        elif method == 'median':
            imputer = SimpleImputer(strategy='median')
        elif method == 'knn':
            imputer = KNNImputer(n_neighbors=5)
        else:
            raise ValueError(f"Unknown method: {method}")
    
        # æ•°å€¤åˆ—ã®ã¿è£œå®Œ
        df_imputed[numeric_cols] = imputer.fit_transform(
            df[numeric_cols]
        )
    
        print(f"=== æ¬ æå€¤è£œå®Œï¼ˆ{method}æ³•ï¼‰ ===")
        print(f"è£œå®Œå‰: {df.isnull().sum().sum()}ä»¶")
        print(f"è£œå®Œå¾Œ: {df_imputed.isnull().sum().sum()}ä»¶")
    
        return df_imputed
    
    # å¹³å‡å€¤è£œå®Œ
    df_imputed = impute_missing_values(df_clean, method='mean')
    
    # KNNè£œå®Œï¼ˆã‚ˆã‚Šé«˜åº¦ï¼‰
    df_knn = impute_missing_values(df_clean, method='knn')
    

* * *

## 3.4 è‡ªå‹•æ›´æ–°ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

### 3.4.1 ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

**ã‚³ãƒ¼ãƒ‰ä¾‹7: è‡ªå‹•æ›´æ–°ã‚¹ã‚¯ãƒªãƒ—ãƒˆ**
    
    
    from datetime import datetime
    import json
    import os
    
    class DataUpdatePipeline:
        """è‡ªå‹•ãƒ‡ãƒ¼ã‚¿æ›´æ–°ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³"""
    
        def __init__(self, output_dir="data"):
            self.output_dir = output_dir
            os.makedirs(output_dir, exist_ok=True)
    
        def fetch_data(self, formulas):
            """ãƒ‡ãƒ¼ã‚¿å–å¾—"""
            print(f"ãƒ‡ãƒ¼ã‚¿å–å¾—é–‹å§‹: {datetime.now()}")
            df = merge_databases(formulas)
            return df
    
        def clean_data(self, df):
            """ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°"""
            print("ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ä¸­...")
            df = detect_duplicates(df)
            df = impute_missing_values(df, method='mean')
            return df
    
        def save_data(self, df, filename=None):
            """ãƒ‡ãƒ¼ã‚¿ä¿å­˜"""
            if filename is None:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = f"materials_data_{timestamp}.csv"
    
            filepath = os.path.join(self.output_dir, filename)
            df.to_csv(filepath, index=False)
            print(f"ãƒ‡ãƒ¼ã‚¿ä¿å­˜å®Œäº†: {filepath}")
    
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä¿å­˜
            metadata = {
                "timestamp": datetime.now().isoformat(),
                "num_records": len(df),
                "columns": list(df.columns),
                "file": filename
            }
    
            meta_file = filepath.replace(".csv", "_meta.json")
            with open(meta_file, 'w') as f:
                json.dump(metadata, f, indent=2)
    
            return filepath
    
        def run(self, formulas):
            """ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ"""
            # ãƒ‡ãƒ¼ã‚¿å–å¾—
            df = self.fetch_data(formulas)
    
            # ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
            df_clean = self.clean_data(df)
    
            # ä¿å­˜
            filepath = self.save_data(df_clean)
    
            print(f"\n=== ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Œäº† ===")
            print(f"å–å¾—ä»¶æ•°: {len(df_clean)}")
            print(f"ãƒ•ã‚¡ã‚¤ãƒ«: {filepath}")
    
            return df_clean
    
    # ä½¿ç”¨ä¾‹
    pipeline = DataUpdatePipeline()
    formulas = ["TiO2", "ZnO", "GaN", "SiC", "Al2O3"]
    df_result = pipeline.run(formulas)
    

### 3.4.2 ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«å®Ÿè¡Œ

**ã‚³ãƒ¼ãƒ‰ä¾‹8: croné¢¨ã®å®šæœŸå®Ÿè¡Œ**
    
    
    import schedule
    import time
    
    def scheduled_update():
        """å®šæœŸæ›´æ–°ã‚¸ãƒ§ãƒ–"""
        print(f"\n{'='*50}")
        print(f"å®šæœŸæ›´æ–°é–‹å§‹: {datetime.now()}")
        print(f"{'='*50}")
    
        # ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ
        pipeline = DataUpdatePipeline()
        formulas = ["TiO2", "ZnO", "GaN", "SiC"]
        pipeline.run(formulas)
    
    # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«è¨­å®š
    schedule.every().day.at("09:00").do(scheduled_update)
    schedule.every().week.do(scheduled_update)
    
    # å®Ÿè¡Œï¼ˆãƒ‡ãƒ¢ç”¨: 10ç§’ã”ã¨ï¼‰
    schedule.every(10).seconds.do(scheduled_update)
    
    print("ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼é–‹å§‹...")
    print("Ctrl+Cã§çµ‚äº†")
    
    # ç„¡é™ãƒ«ãƒ¼ãƒ—
    while True:
        schedule.run_pending()
        time.sleep(1)
    

* * *

## 3.5 ãƒ‡ãƒ¼ã‚¿å“è³ªç®¡ç†

### 3.5.1 å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹

**ã‚³ãƒ¼ãƒ‰ä¾‹9: ãƒ‡ãƒ¼ã‚¿å“è³ªè©•ä¾¡**
    
    
    def calculate_quality_metrics(df):
        """ãƒ‡ãƒ¼ã‚¿å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—"""
    
        metrics = {}
    
        # å®Œå…¨æ€§ï¼ˆCompletenessï¼‰
        total_cells = df.size
        missing_cells = df.isnull().sum().sum()
        completeness = (
            (total_cells - missing_cells) / total_cells
        ) * 100
    
        # ä¸€è²«æ€§ï¼ˆConsistencyï¼‰
        # ä¾‹: ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—ãŒè² ã®å€¤ã§ãªã„ã‹
        if 'band_gap_mp' in df.columns:
            invalid_bg = (df['band_gap_mp'] < 0).sum()
            consistency = (
                (len(df) - invalid_bg) / len(df)
            ) * 100
        else:
            consistency = 100.0
    
        # ç²¾åº¦ï¼ˆAccuracyï¼‰
        # ä¾‹: MPã¨AFLOWã®å·®ç•°
        if 'band_gap_mp' in df.columns and \
           'band_gap_aflow' in df.columns:
            diff = (
                df['band_gap_mp'] - df['band_gap_aflow']
            ).abs()
            avg_diff = diff.mean()
            accuracy = max(
                0, 100 - (avg_diff / df['band_gap_mp'].mean()) * 100
            )
        else:
            accuracy = None
    
        metrics = {
            "Completeness (%)": round(completeness, 2),
            "Consistency (%)": round(consistency, 2),
            "Accuracy (%)": round(accuracy, 2) if accuracy else "N/A",
            "Total Records": len(df),
            "Total Cells": total_cells,
            "Missing Cells": missing_cells
        }
    
        print("=== ãƒ‡ãƒ¼ã‚¿å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹ ===")
        for key, value in metrics.items():
            print(f"{key}: {value}")
    
        return metrics
    
    # å“è³ªè©•ä¾¡
    quality = calculate_quality_metrics(df_clean)
    

### 3.5.2 ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ãƒ«ãƒ¼ãƒ«

**ã‚³ãƒ¼ãƒ‰ä¾‹10: ãƒ‡ãƒ¼ã‚¿ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³**
    
    
    def validate_materials_data(df):
        """ææ–™ãƒ‡ãƒ¼ã‚¿ã®ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³"""
    
        validation_report = []
    
        # ãƒ«ãƒ¼ãƒ«1: ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—ã¯0ä»¥ä¸Š
        if 'band_gap_mp' in df.columns:
            invalid_bg = df[df['band_gap_mp'] < 0]
            if len(invalid_bg) > 0:
                validation_report.append({
                    "Rule": "Band Gap >= 0",
                    "Status": "FAIL",
                    "Failed Records": len(invalid_bg)
                })
            else:
                validation_report.append({
                    "Rule": "Band Gap >= 0",
                    "Status": "PASS",
                    "Failed Records": 0
                })
    
        # ãƒ«ãƒ¼ãƒ«2: å½¢æˆã‚¨ãƒãƒ«ã‚®ãƒ¼ã¯è² 
        if 'formation_energy_mp' in df.columns:
            invalid_fe = df[df['formation_energy_mp'] > 0]
            if len(invalid_fe) > 0:
                validation_report.append({
                    "Rule": "Formation Energy <= 0",
                    "Status": "WARNING",
                    "Failed Records": len(invalid_fe)
                })
            else:
                validation_report.append({
                    "Rule": "Formation Energy <= 0",
                    "Status": "PASS",
                    "Failed Records": 0
                })
    
        # ãƒ«ãƒ¼ãƒ«3: å®‰å®šæ€§ <= 0.1 eV/atom
        if 'stability_mp' in df.columns:
            unstable = df[df['stability_mp'] > 0.1]
            validation_report.append({
                "Rule": "Stability <= 0.1 eV/atom",
                "Status": "INFO",
                "Failed Records": len(unstable)
            })
    
        # ãƒ¬ãƒãƒ¼ãƒˆè¡¨ç¤º
        print("=== ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¬ãƒãƒ¼ãƒˆ ===")
        report_df = pd.DataFrame(validation_report)
        print(report_df)
    
        return report_df
    
    # ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
    validation = validate_materials_data(df_clean)
    

* * *

## 3.6 å®Ÿè·µã‚±ãƒ¼ã‚¹ã‚¹ã‚¿ãƒ‡ã‚£

### 3.6.1 é›»æ± ææ–™æ¢ç´¢

**ã‚³ãƒ¼ãƒ‰ä¾‹11: Li-ioné›»æ± æ­£æ¥µææ–™ã®çµ±åˆæ¢ç´¢**
    
    
    def find_battery_materials():
        """è¤‡æ•°DBã‹ã‚‰é›»æ± ææ–™ã‚’æ¢ç´¢"""
    
        # Materials Projectã‹ã‚‰æ¢ç´¢
        with MPRester(MP_API_KEY) as mpr:
            mp_docs = mpr.materials.summary.search(
                elements=["Li", "Co", "O"],
                energy_above_hull=(0, 0.05),
                fields=[
                    "material_id",
                    "formula_pretty",
                    "energy_above_hull",
                    "formation_energy_per_atom"
                ]
            )
    
        mp_data = [{
            "source": "MP",
            "formula": doc.formula_pretty,
            "stability": doc.energy_above_hull,
            "formation_energy": doc.formation_energy_per_atom
        } for doc in mp_docs]
    
        # AFLOWï¼ˆç°¡ç•¥ç‰ˆï¼‰
        # å®Ÿéš›ã®AFLOW APIã‚³ãƒ¼ãƒ«ã¯çœç•¥
    
        # çµ±åˆ
        df_battery = pd.DataFrame(mp_data)
    
        # å®‰å®šæ€§ã§ã‚½ãƒ¼ãƒˆ
        df_battery = df_battery.sort_values('stability')
    
        print("=== Li-Co-Oç³»é›»æ± ææ–™å€™è£œ ===")
        print(df_battery.head(10))
    
        return df_battery
    
    # å®Ÿè¡Œ
    df_battery = find_battery_materials()
    

### 3.6.2 è§¦åª’ææ–™ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°

**ã‚³ãƒ¼ãƒ‰ä¾‹12: é·ç§»é‡‘å±é…¸åŒ–ç‰©è§¦åª’ã®çµ±åˆã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°**
    
    
    def screen_catalysts(
        transition_metals=["Ti", "V", "Cr", "Mn", "Fe"]
    ):
        """è§¦åª’ææ–™ã®çµ±åˆã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°"""
    
        all_results = []
    
        for tm in transition_metals:
            # Materials Projectã‹ã‚‰å–å¾—
            with MPRester(MP_API_KEY) as mpr:
                docs = mpr.materials.summary.search(
                    elements=[tm, "O"],
                    band_gap=(0.1, 3.0),
                    energy_above_hull=(0, 0.1),
                    fields=[
                        "material_id",
                        "formula_pretty",
                        "band_gap",
                        "energy_above_hull"
                    ]
                )
    
                for doc in docs:
                    all_results.append({
                        "transition_metal": tm,
                        "formula": doc.formula_pretty,
                        "band_gap": doc.band_gap,
                        "stability": doc.energy_above_hull,
                        "source": "MP"
                    })
    
        df_catalysts = pd.DataFrame(all_results)
    
        # ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
        df_catalysts = df_catalysts.drop_duplicates(
            subset=['formula']
        )
    
        # ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—ç¯„å›²ã§ãƒ•ã‚£ãƒ«ã‚¿
        df_ideal = df_catalysts[
            (df_catalysts['band_gap'] >= 1.5) &
            (df_catalysts['band_gap'] <= 2.5)
        ]
    
        print(f"=== è§¦åª’å€™è£œææ–™ ===")
        print(f"ç·å€™è£œ: {len(df_catalysts)}ä»¶")
        print(f"ç†æƒ³çš„ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—: {len(df_ideal)}ä»¶")
        print("\nä¸Šä½10ä»¶:")
        print(df_ideal.head(10))
    
        return df_ideal
    
    # å®Ÿè¡Œ
    df_catalysts = screen_catalysts()
    

* * *

## 3.7 ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å¯è¦–åŒ–
    
    
    ```mermaid
    flowchart TD
        A[ãƒ‡ãƒ¼ã‚¿å–å¾—] --> B[Materials Project]
        A --> C[AFLOW]
        A --> D[OQMD]
    
        B --> E[ãƒ‡ãƒ¼ã‚¿çµåˆ]
        C --> E
        D --> E
    
        E --> F[é‡è¤‡å‰Šé™¤]
        F --> G[å¤–ã‚Œå€¤æ¤œå‡º]
        G --> H[æ¬ æå€¤å‡¦ç†]
    
        H --> I[å“è³ªè©•ä¾¡]
        I --> J{å“è³ªOK?}
    
        J -->|Yes| K[ãƒ‡ãƒ¼ã‚¿ä¿å­˜]
        J -->|No| L[å†å‡¦ç†]
        L --> E
    
        K --> M[å®šæœŸæ›´æ–°]
        M --> A
    
        style A fill:#e3f2fd
        style K fill:#e8f5e9
        style J fill:#fff3e0
    ```

* * *

## 3.8 æœ¬ç« ã®ã¾ã¨ã‚

### å­¦ã‚“ã ã“ã¨

  1. **ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çµ±åˆ** \- Materials Projectã¨AFLOWã®çµ±åˆ \- åŒ–å­¦å¼ã‚’ã‚­ãƒ¼ã¨ã—ãŸçµåˆ \- outer joinã«ã‚ˆã‚‹ãƒ‡ãƒ¼ã‚¿çµ±åˆ

  2. **ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°** \- é‡è¤‡ãƒ‡ãƒ¼ã‚¿ã®æ¤œå‡ºã¨å‰Šé™¤ \- IQRæ³•ã«ã‚ˆã‚‹å¤–ã‚Œå€¤æ¤œå‡º \- ãƒ‡ãƒ¼ã‚¿å‹ã®çµ±ä¸€

  3. **æ¬ æå€¤å‡¦ç†** \- æ¬ æãƒ‘ã‚¿ãƒ¼ãƒ³ã®å¯è¦–åŒ– \- å¹³å‡å€¤ãƒ»ä¸­å¤®å€¤è£œå®Œ \- KNNè£œå®Œ

  4. **è‡ªå‹•åŒ–ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³** \- ãƒ‡ãƒ¼ã‚¿å–å¾—â†’ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°â†’ä¿å­˜ \- ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«å®Ÿè¡Œ \- ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç®¡ç†

  5. **å“è³ªç®¡ç†** \- å®Œå…¨æ€§ãƒ»ä¸€è²«æ€§ãƒ»ç²¾åº¦ã®è©•ä¾¡ \- ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ãƒ«ãƒ¼ãƒ« \- å“è³ªãƒ¬ãƒãƒ¼ãƒˆè‡ªå‹•ç”Ÿæˆ

### é‡è¦ãªãƒã‚¤ãƒ³ãƒˆ

  * âœ… è¤‡æ•°DBã®çµ±åˆã§ä¿¡é ¼æ€§å‘ä¸Š
  * âœ… ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã¯å¿…é ˆãƒ—ãƒ­ã‚»ã‚¹
  * âœ… æ¬ æå€¤å‡¦ç†ã¯ç”¨é€”ã«å¿œã˜ã¦é¸æŠ
  * âœ… è‡ªå‹•åŒ–ã§ç¶™ç¶šçš„ãªãƒ‡ãƒ¼ã‚¿æ›´æ–°
  * âœ… å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹ã§å®¢è¦³çš„è©•ä¾¡

### æ¬¡ã®ç« ã¸

ç¬¬4ç« ã§ã¯ã€ç‹¬è‡ªãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®æ§‹ç¯‰ã‚’å­¦ã³ã¾ã™ï¼š \- SQLite/PostgreSQLè¨­è¨ˆ \- ã‚¹ã‚­ãƒ¼ãƒè¨­è¨ˆ \- CRUDæ“ä½œ \- ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æˆ¦ç•¥

**[ç¬¬4ç« ï¼šç‹¬è‡ªãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ§‹ç¯‰ â†’](<./chapter-4.html>)**

* * *

## æ¼”ç¿’å•é¡Œ

### å•é¡Œ1ï¼ˆé›£æ˜“åº¦ï¼šeasyï¼‰

Materials Projectã¨AFLOWã‹ã‚‰åŒä¸€ææ–™ï¼ˆSiCï¼‰ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã€ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—ã¨å½¢æˆã‚¨ãƒãƒ«ã‚®ãƒ¼ã‚’æ¯”è¼ƒã—ã¦ãã ã•ã„ã€‚

**è¦æ±‚äº‹é …** : 1\. ä¸¡æ–¹ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰SiCã®ãƒ‡ãƒ¼ã‚¿å–å¾— 2\. ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—ã®å·®ç•°ã‚’%ã§è¡¨ç¤º 3\. å½¢æˆã‚¨ãƒãƒ«ã‚®ãƒ¼ã®å·®ç•°ã‚’%ã§è¡¨ç¤º

è§£ç­”ä¾‹
    
    
    from mp_api.client import MPRester
    import requests
    
    MP_API_KEY = "your_api_key"
    
    # Materials Projectã‹ã‚‰å–å¾—
    with MPRester(MP_API_KEY) as mpr:
        mp_docs = mpr.materials.summary.search(
            formula="SiC",
            fields=["band_gap", "formation_energy_per_atom"]
        )
        mp_bg = mp_docs[0].band_gap
        mp_fe = mp_docs[0].formation_energy_per_atom
    
    # AFLOWã‹ã‚‰å–å¾—ï¼ˆç°¡ç•¥ç‰ˆï¼‰
    aflow_url = "http://aflowlib.org/API/aflux"
    params = {
        "species": "Si,C",
        "$": "Egap,enthalpy_formation_atom"
    }
    response = requests.get(aflow_url, params=params)
    aflow_data = response.json()[0]
    aflow_bg = aflow_data.get("Egap")
    aflow_fe = aflow_data.get("enthalpy_formation_atom")
    
    # æ¯”è¼ƒ
    bg_diff = abs(mp_bg - aflow_bg) / mp_bg * 100
    fe_diff = abs(mp_fe - aflow_fe) / abs(mp_fe) * 100
    
    print(f"SiCãƒ‡ãƒ¼ã‚¿æ¯”è¼ƒ:")
    print(f"ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—: MP={mp_bg} eV, AFLOW={aflow_bg} eV")
    print(f"å·®ç•°: {bg_diff:.1f}%")
    print(f"\nå½¢æˆã‚¨ãƒãƒ«ã‚®ãƒ¼: MP={mp_fe} eV/atom, "
          f"AFLOW={aflow_fe} eV/atom")
    print(f"å·®ç•°: {fe_diff:.1f}%")
    

* * *

### å•é¡Œ2ï¼ˆé›£æ˜“åº¦ï¼šmediumï¼‰

ä»¥ä¸‹ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«å¯¾ã—ã¦ã€æ¬ æå€¤å‡¦ç†ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚
    
    
    import pandas as pd
    import numpy as np
    
    # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿
    data = {
        'material_id': ['mp-1', 'mp-2', 'mp-3', 'mp-4', 'mp-5'],
        'formula': ['TiO2', 'ZnO', 'GaN', 'SiC', 'Al2O3'],
        'band_gap': [3.44, np.nan, 3.20, 2.36, np.nan],
        'formation_energy': [-4.87, -1.95, np.nan, -0.67, -3.45]
    }
    df = pd.DataFrame(data)
    

**è¦æ±‚äº‹é …** : 1\. æ¬ æå€¤ã‚’å¹³å‡å€¤ã§è£œå®Œ 2\. æ¬ æå€¤ã‚’KNNæ³•ã§è£œå®Œ 3\. 2ã¤ã®æ–¹æ³•ã®çµæœã‚’æ¯”è¼ƒ

è§£ç­”ä¾‹
    
    
    from sklearn.impute import SimpleImputer, KNNImputer
    
    # å¹³å‡å€¤è£œå®Œ
    imputer_mean = SimpleImputer(strategy='mean')
    df_mean = df.copy()
    df_mean[['band_gap', 'formation_energy']] = \
        imputer_mean.fit_transform(
            df[['band_gap', 'formation_energy']]
        )
    
    # KNNè£œå®Œ
    imputer_knn = KNNImputer(n_neighbors=2)
    df_knn = df.copy()
    df_knn[['band_gap', 'formation_energy']] = \
        imputer_knn.fit_transform(
            df[['band_gap', 'formation_energy']]
        )
    
    # æ¯”è¼ƒ
    print("å…ƒãƒ‡ãƒ¼ã‚¿:")
    print(df)
    print("\nå¹³å‡å€¤è£œå®Œ:")
    print(df_mean)
    print("\nKNNè£œå®Œ:")
    print(df_knn)
    
    # å·®ç•°åˆ†æ
    diff_bg = (
        df_mean['band_gap'] - df_knn['band_gap']
    ).abs().mean()
    diff_fe = (
        df_mean['formation_energy'] -
        df_knn['formation_energy']
    ).abs().mean()
    
    print(f"\nå¹³å‡å·®ç•°:")
    print(f"ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—: {diff_bg:.3f} eV")
    print(f"å½¢æˆã‚¨ãƒãƒ«ã‚®ãƒ¼: {diff_fe:.3f} eV/atom")
    

* * *

### å•é¡Œ3ï¼ˆé›£æ˜“åº¦ï¼šhardï¼‰

Materials Projectã¨AFLOWã‹ã‚‰100ä»¶ä»¥ä¸Šã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã€çµ±åˆãƒ»ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ãƒ»å“è³ªè©•ä¾¡ã‚’è¡Œã†å®Œå…¨ãªãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’æ§‹ç¯‰ã—ã¦ãã ã•ã„ã€‚

**è¦æ±‚äº‹é …** : 1\. é…¸åŒ–ç‰©ï¼ˆOå«æœ‰ï¼‰ææ–™ã‚’100ä»¶ä»¥ä¸Šå–å¾— 2\. ãƒ‡ãƒ¼ã‚¿çµ±åˆï¼ˆouter joinï¼‰ 3\. é‡è¤‡å‰Šé™¤ã€å¤–ã‚Œå€¤æ¤œå‡º 4\. æ¬ æå€¤è£œå®Œ 5\. å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹ç®—å‡º 6\. çµæœã‚’CSVã¨JSONã§ä¿å­˜

è§£ç­”ä¾‹
    
    
    from mp_api.client import MPRester
    import requests
    import pandas as pd
    import numpy as np
    from sklearn.impute import KNNImputer
    import json
    from datetime import datetime
    
    MP_API_KEY = "your_api_key"
    
    class IntegratedDataPipeline:
        """çµ±åˆãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³"""
    
        def __init__(self):
            self.df = None
    
        def fetch_mp_data(self, num_materials=100):
            """Materials Projectã‹ã‚‰ãƒ‡ãƒ¼ã‚¿å–å¾—"""
            with MPRester(MP_API_KEY) as mpr:
                docs = mpr.materials.summary.search(
                    elements=["O"],
                    fields=[
                        "material_id",
                        "formula_pretty",
                        "band_gap",
                        "formation_energy_per_atom"
                    ]
                )[:num_materials]
    
                return pd.DataFrame([{
                    "material_id": doc.material_id,
                    "formula": doc.formula_pretty,
                    "band_gap_mp": doc.band_gap,
                    "formation_energy_mp":
                        doc.formation_energy_per_atom,
                    "source": "MP"
                } for doc in docs])
    
        def merge_data(self, df_mp, df_aflow=None):
            """ãƒ‡ãƒ¼ã‚¿çµ±åˆ"""
            # ç°¡ç•¥ç‰ˆ: AFLOWãƒ‡ãƒ¼ã‚¿ã¯çœç•¥
            return df_mp
    
        def clean_data(self, df):
            """ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°"""
            # é‡è¤‡å‰Šé™¤
            df = df.drop_duplicates(subset=['formula'])
    
            # å¤–ã‚Œå€¤æ¤œå‡ºï¼ˆIQRæ³•ï¼‰
            Q1 = df['band_gap_mp'].quantile(0.25)
            Q3 = df['band_gap_mp'].quantile(0.75)
            IQR = Q3 - Q1
            df = df[
                (df['band_gap_mp'] >= Q1 - 1.5 * IQR) &
                (df['band_gap_mp'] <= Q3 + 1.5 * IQR)
            ]
    
            return df
    
        def impute_missing(self, df):
            """æ¬ æå€¤è£œå®Œ"""
            numeric_cols = [
                'band_gap_mp', 'formation_energy_mp'
            ]
            imputer = KNNImputer(n_neighbors=5)
            df[numeric_cols] = imputer.fit_transform(
                df[numeric_cols]
            )
            return df
    
        def calculate_quality(self, df):
            """å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹"""
            total_cells = df.size
            missing_cells = df.isnull().sum().sum()
            completeness = (
                (total_cells - missing_cells) / total_cells
            ) * 100
    
            return {
                "completeness": completeness,
                "num_records": len(df),
                "timestamp": datetime.now().isoformat()
            }
    
        def save_results(self, df, quality):
            """çµæœä¿å­˜"""
            # CSVä¿å­˜
            df.to_csv("integrated_data.csv", index=False)
    
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä¿å­˜
            with open("quality_report.json", 'w') as f:
                json.dump(quality, f, indent=2)
    
            print("ãƒ‡ãƒ¼ã‚¿ä¿å­˜å®Œäº†:")
            print("- integrated_data.csv")
            print("- quality_report.json")
    
        def run(self):
            """ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ"""
            print("=== çµ±åˆãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ ===")
    
            # ãƒ‡ãƒ¼ã‚¿å–å¾—
            print("1. ãƒ‡ãƒ¼ã‚¿å–å¾—ä¸­...")
            df_mp = self.fetch_mp_data(100)
    
            # çµ±åˆ
            print("2. ãƒ‡ãƒ¼ã‚¿çµ±åˆä¸­...")
            df = self.merge_data(df_mp)
    
            # ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
            print("3. ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ä¸­...")
            df = self.clean_data(df)
    
            # æ¬ æå€¤è£œå®Œ
            print("4. æ¬ æå€¤è£œå®Œä¸­...")
            df = self.impute_missing(df)
    
            # å“è³ªè©•ä¾¡
            print("5. å“è³ªè©•ä¾¡ä¸­...")
            quality = self.calculate_quality(df)
    
            # ä¿å­˜
            print("6. çµæœä¿å­˜ä¸­...")
            self.save_results(df, quality)
    
            print("\n=== å®Œäº† ===")
            print(f"ç·ãƒ‡ãƒ¼ã‚¿æ•°: {len(df)}")
            print(f"å“è³ªã‚¹ã‚³ã‚¢: {quality['completeness']:.2f}%")
    
            self.df = df
            return df, quality
    
    # å®Ÿè¡Œ
    pipeline = IntegratedDataPipeline()
    df_result, quality_metrics = pipeline.run()
    

* * *

## å‚è€ƒæ–‡çŒ®

  1. Wilkinson, M. D. et al. (2016). "The FAIR Guiding Principles for scientific data management and stewardship." _Scientific Data_ , 3, 160018. DOI: [10.1038/sdata.2016.18](<https://doi.org/10.1038/sdata.2016.18>)

  2. pandas Documentation. "Merge, join, concatenate and compare." URL: [pandas.pydata.org/docs](<https://pandas.pydata.org/docs>)

* * *

## ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³

### å‰ã®ç« 

**[ç¬¬2ç« ï¼šMaterials Projectå®Œå…¨ã‚¬ã‚¤ãƒ‰ â†](<./chapter-2.html>)**

### æ¬¡ã®ç« 

**[ç¬¬4ç« ï¼šç‹¬è‡ªãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ§‹ç¯‰ â†’](<./chapter-4.html>)**

### ã‚·ãƒªãƒ¼ã‚ºç›®æ¬¡

**[â† ã‚·ãƒªãƒ¼ã‚ºç›®æ¬¡ã«æˆ»ã‚‹](<./index.html>)**

* * *

## è‘—è€…æƒ…å ±

**ä½œæˆè€…** : AI Terakoya Content Team **ä½œæˆæ—¥** : 2025-10-17 **ãƒãƒ¼ã‚¸ãƒ§ãƒ³** : 1.0

**ãƒ©ã‚¤ã‚»ãƒ³ã‚¹** : Creative Commons BY 4.0

* * *

**æ¬¡ã®ç« ã§å­¦ç¿’ã‚’ç¶šã‘ã¾ã—ã‚‡ã†ï¼**
