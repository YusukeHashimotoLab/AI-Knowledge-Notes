<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Chapter - AI Terakoya</title>

    <style>
        :root {
            --color-primary: #2c3e50;
            --color-primary-dark: #1a252f;
            --color-accent: #7b2cbf;
            --color-accent-light: #9d4edd;
            --color-text: #2d3748;
            --color-text-light: #4a5568;
            --color-bg: #ffffff;
            --color-bg-alt: #f7fafc;
            --color-border: #e2e8f0;
            --color-code-bg: #f8f9fa;
            --color-link: #3182ce;
            --color-link-hover: #2c5aa0;

            --spacing-xs: 0.5rem;
            --spacing-sm: 1rem;
            --spacing-md: 1.5rem;
            --spacing-lg: 2rem;
            --spacing-xl: 3rem;

            --font-body: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            --font-mono: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;

            --border-radius: 8px;
            --box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: var(--font-body);
            line-height: 1.7;
            color: var(--color-text);
            background-color: var(--color-bg);
            font-size: 16px;
        }

        header {
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            padding: var(--spacing-xl) var(--spacing-md);
            margin-bottom: var(--spacing-xl);
            box-shadow: var(--box-shadow);
        }

        .header-content {
            max-width: 900px;
            margin: 0 auto;
        }

        h1 {
            font-size: 2rem;
            font-weight: 700;
            margin-bottom: var(--spacing-sm);
            line-height: 1.2;
        }

        .subtitle {
            font-size: 1.1rem;
            opacity: 0.95;
            font-weight: 400;
            margin-bottom: var(--spacing-md);
        }

        .meta {
            display: flex;
            flex-wrap: wrap;
            gap: var(--spacing-md);
            font-size: 0.9rem;
            opacity: 0.9;
        }

        .meta-item {
            display: flex;
            align-items: center;
            gap: 0.3rem;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 0 var(--spacing-md) var(--spacing-xl);
        }

        h2 {
            font-size: 1.75rem;
            color: var(--color-primary);
            margin-top: var(--spacing-xl);
            margin-bottom: var(--spacing-md);
            padding-bottom: var(--spacing-xs);
            border-bottom: 3px solid var(--color-accent);
        }

        h3 {
            font-size: 1.4rem;
            color: var(--color-primary);
            margin-top: var(--spacing-lg);
            margin-bottom: var(--spacing-sm);
        }

        h4 {
            font-size: 1.1rem;
            color: var(--color-primary-dark);
            margin-top: var(--spacing-md);
            margin-bottom: var(--spacing-sm);
        }

        p {
            margin-bottom: var(--spacing-md);
            color: var(--color-text);
        }

        a {
            color: var(--color-link);
            text-decoration: none;
            transition: color 0.2s;
        }

        a:hover {
            color: var(--color-link-hover);
            text-decoration: underline;
        }

        ul, ol {
            margin-left: var(--spacing-lg);
            margin-bottom: var(--spacing-md);
        }

        li {
            margin-bottom: var(--spacing-xs);
            color: var(--color-text);
        }

        pre {
            background-color: var(--color-code-bg);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            overflow-x: auto;
            margin-bottom: var(--spacing-md);
            font-family: var(--font-mono);
            font-size: 0.9rem;
            line-height: 1.5;
        }

        code {
            font-family: var(--font-mono);
            font-size: 0.9em;
            background-color: var(--color-code-bg);
            padding: 0.2em 0.4em;
            border-radius: 3px;
        }

        pre code {
            background-color: transparent;
            padding: 0;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: var(--spacing-md);
            font-size: 0.95rem;
        }

        th, td {
            border: 1px solid var(--color-border);
            padding: var(--spacing-sm);
            text-align: left;
        }

        th {
            background-color: var(--color-bg-alt);
            font-weight: 600;
            color: var(--color-primary);
        }

        blockquote {
            border-left: 4px solid var(--color-accent);
            padding-left: var(--spacing-md);
            margin: var(--spacing-md) 0;
            color: var(--color-text-light);
            font-style: italic;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        .mermaid {
            text-align: center;
            margin: var(--spacing-lg) 0;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        details {
            background-color: var(--color-bg-alt);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            margin-bottom: var(--spacing-md);
        }

        summary {
            cursor: pointer;
            font-weight: 600;
            color: var(--color-primary);
            user-select: none;
            padding: var(--spacing-xs);
            margin: calc(-1 * var(--spacing-md));
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        summary:hover {
            background-color: rgba(123, 44, 191, 0.1);
        }

        details[open] summary {
            margin-bottom: var(--spacing-md);
            border-bottom: 1px solid var(--color-border);
        }

        .learning-objectives {
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
            padding: var(--spacing-lg);
            border-radius: var(--border-radius);
            border-left: 4px solid var(--color-accent);
            margin-bottom: var(--spacing-xl);
        }

        .learning-objectives h2 {
            margin-top: 0;
            border-bottom: none;
        }

        .navigation {
            display: flex;
            justify-content: space-between;
            gap: var(--spacing-md);
            margin: var(--spacing-xl) 0;
            padding-top: var(--spacing-lg);
            border-top: 2px solid var(--color-border);
        }

        .nav-button {
            flex: 1;
            padding: var(--spacing-md);
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            border-radius: var(--border-radius);
            text-align: center;
            font-weight: 600;
            transition: transform 0.2s, box-shadow 0.2s;
            box-shadow: var(--box-shadow);
        }

        .nav-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
            text-decoration: none;
        }

        footer {
            margin-top: var(--spacing-xl);
            padding: var(--spacing-lg) var(--spacing-md);
            background-color: var(--color-bg-alt);
            border-top: 1px solid var(--color-border);
            text-align: center;
            font-size: 0.9rem;
            color: var(--color-text-light);
        }

        @media (max-width: 768px) {
            h1 {
                font-size: 1.5rem;
            }

            h2 {
                font-size: 1.4rem;
            }

            h3 {
                font-size: 1.2rem;
            }

            .meta {
                font-size: 0.85rem;
            }

            .navigation {
                flex-direction: column;
            }

            table {
                font-size: 0.85rem;
            }

            th, td {
                padding: var(--spacing-xs);
            }
        }
    </style>

    <script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
    <script>
        mermaid.initialize({ startOnLoad: true, theme: 'default', securityLevel: 'strict' });
    </script>

    <!-- MathJax for LaTeX equation rendering -->
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\(', '\)']],
                displayMath: [['$$', '$$'], ['\[', '\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
                ignoreHtmlClass: 'mermaid'
            }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" async></script>
</head>
<body>
    <header>
        <div class="header-content">
            <h1>Chapter</h1>
            <p class="subtitle"></p>
            <div class="meta">
                <span class="meta-item">ğŸ“– èª­äº†æ™‚é–“: 20-25åˆ†</span>
                <span class="meta-item">ğŸ“Š é›£æ˜“åº¦: åˆç´š</span>
                <span class="meta-item">ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹: 0å€‹</span>
                <span class="meta-item">ğŸ“ æ¼”ç¿’å•é¡Œ: 0å•</span>
            </div>
        </div>
    </header>

    <main class="container">
<h1>Chapter 3 Quality Enhancements</h1>
<p class="chapter-description" style="margin: 1.5rem 0; padding: 1rem; background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%); border-left: 4px solid #7b2cbf; border-radius: 8px; font-size: 1.05rem; line-height: 1.8; color: #2d3748;">scikit-optimizeã‚„BoTorchã§ã®æœ€å°å®Ÿè£…ã‹ã‚‰å§‹ã‚ã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®šã®å‹˜æ‰€ã‚’æŠ¼ã•ãˆã¾ã™ã€‚åˆ¶ç´„ã‚„å¤šç›®çš„ã¸ã®æ‹¡å¼µã®å…¥å£ã‚‚ç¤ºã—ã¾ã™ã€‚</p>
<p class="chapter-supplement" style="margin: 0.75rem 0 1.5rem 0; padding: 0.75rem 1rem; background: linear-gradient(135deg, #fff8e1 0%, #fff3cd 100%); border-left: 3px solid #f59e0b; border-radius: 6px; font-size: 0.95rem; line-height: 1.7; color: #4a5568;"><strong>ğŸ’¡ è£œè¶³:</strong> ãƒã‚¤ã‚ºã®è¦‹ç©ã‚‚ã‚Šã¨ã‚¹ã‚±ãƒ¼ãƒ«èª¿æ•´ã§å®‰å®šåŒ–ã€‚åå¾©å›æ•°ã¯â€œå°‘æ•°ç²¾é‹­â€ã§è¨­è¨ˆã—ã¾ã™ã€‚</p>





<p>This file contains enhancements to be integrated into chapter-3.md</p>
<h2>Code Reproducibility Section (add after section 3.1)</h2>
<h3>ã‚³ãƒ¼ãƒ‰å†ç¾æ€§ã®ç¢ºä¿</h3>
<p><strong>ç’°å¢ƒè¨­å®šã®é‡è¦æ€§</strong>:</p>
<p>ã™ã¹ã¦ã®ã‚³ãƒ¼ãƒ‰ä¾‹ã¯ä»¥ä¸‹ã®ç’°å¢ƒã§å‹•ä½œç¢ºèªã•ã‚Œã¦ã„ã¾ã™ï¼š</p>
<pre><code class="language-python"># å¿…é ˆãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³
&quot;&quot;&quot;
Python: 3.8+
numpy: 1.21.0
scikit-learn: 1.0.0
scikit-optimize: 0.9.0
torch: 1.12.0
gpytorch: 1.8.0
botorch: 0.7.0
matplotlib: 3.5.0
pandas: 1.3.0
scipy: 1.7.0
&quot;&quot;&quot;

# å†ç¾æ€§ç¢ºä¿ã®ãŸã‚ã®è¨­å®š
import numpy as np
import torch
import random

# ä¹±æ•°ã‚·ãƒ¼ãƒ‰ã®å›ºå®š
RANDOM_SEED = 42
np.random.seed(RANDOM_SEED)
torch.manual_seed(RANDOM_SEED)
random.seed(RANDOM_SEED)

# GPyTorchã‚«ãƒ¼ãƒãƒ«è¨­å®šï¼ˆæ¨å¥¨ï¼‰
from gpytorch.kernels import RBF, MaternKernel, ScaleKernel

# RBFã‚«ãƒ¼ãƒãƒ«ï¼ˆæœ€ã‚‚ä¸€èˆ¬çš„ï¼‰
kernel_rbf = ScaleKernel(RBF(
    lengthscale_prior=None,  # ãƒ‡ãƒ¼ã‚¿é§†å‹•ã§æœ€é©åŒ–
    ard_num_dims=None  # Automatic Relevance Determination
))

# Maternã‚«ãƒ¼ãƒãƒ«ï¼ˆæ»‘ã‚‰ã‹ã•èª¿æ•´å¯èƒ½ï¼‰
kernel_matern = ScaleKernel(MaternKernel(
    nu=2.5,  # æ»‘ã‚‰ã‹ã•ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆ1.5, 2.5, ã¾ãŸã¯ infï¼ˆRBFã¨åŒç­‰ï¼‰ï¼‰
    ard_num_dims=None
))

print(&quot;ç’°å¢ƒè¨­å®šå®Œäº†&quot;)
print(f&quot;NumPy version: {np.__version__}&quot;)
print(f&quot;PyTorch version: {torch.__version__}&quot;)
</code></pre>
<p><strong>ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ‰‹é †</strong>:</p>
<pre><code class="language-bash"># ä»®æƒ³ç’°å¢ƒã®ä½œæˆï¼ˆæ¨å¥¨ï¼‰
python -m venv bo_env
source bo_env/bin/activate  # Linuxmac
# bo_env\Scripts\activate  # Windows

# å¿…é ˆãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install numpy==1.21.0 scikit-learn==1.0.0 scikit-optimize==0.9.0
pip install torch==1.12.0 gpytorch==1.8.0 botorch==0.7.0
pip install matplotlib==3.5.0 pandas==1.3.0 scipy==1.7.0

# ã‚ªãƒ—ã‚·ãƒ§ãƒ³: Materials Project API
pip install mp-api==0.30.0

# ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ç¢ºèª
python -c &quot;import botorch; print(f'BoTorch {botorch.__version__} installed')&quot;
</code></pre>
<hr />
<h2>Practical Pitfalls Section (add after section 3.7)</h2>
<h3>3.8 å®Ÿè·µçš„ãªè½ã¨ã—ç©´ã¨å¯¾å‡¦æ³•</h3>
<h4>è½ã¨ã—ç©´1: ä¸é©åˆ‡ãªã‚«ãƒ¼ãƒãƒ«é¸æŠ</h4>
<p><strong>å•é¡Œ</strong>: ã‚«ãƒ¼ãƒãƒ«é¸æŠãŒç›®çš„é–¢æ•°ã®æ€§è³ªã¨åˆã£ã¦ã„ãªã„</p>
<p><strong>ç—‡çŠ¶</strong>:
- äºˆæ¸¬ç²¾åº¦ãŒä½ã„
- æ¢ç´¢åŠ¹ç‡ãŒæ‚ªã„
- å±€æ‰€æœ€é©ã«é™¥ã‚Šã‚„ã™ã„</p>
<p><strong>è§£æ±ºç­–</strong>:</p>
<pre><code class="language-python"># ã‚«ãƒ¼ãƒãƒ«é¸æŠã‚¬ã‚¤ãƒ‰
from gpytorch.kernels import RBF, MaternKernel, PeriodicKernel

def select_kernel(problem_characteristics):
    &quot;&quot;&quot;
    å•é¡Œã®ç‰¹æ€§ã«å¿œã˜ãŸã‚«ãƒ¼ãƒãƒ«é¸æŠ

    Parameters:
    -----------
    problem_characteristics : dict
        å•é¡Œã®ç‰¹æ€§ã‚’è¨˜è¿°ã™ã‚‹è¾æ›¸
        - 'smoothness': 'smooth' | 'rough'
        - 'periodicity': True | False
        - 'dimensionality': int

    Returns:
    --------
    kernel : gpytorch.kernels.Kernel
        æ¨å¥¨ã‚«ãƒ¼ãƒãƒ«
    &quot;&quot;&quot;
    if problem_characteristics.get('periodicity'):
        # å‘¨æœŸæ€§ãŒã‚ã‚‹å ´åˆ
        return PeriodicKernel()

    elif problem_characteristics.get('smoothness') == 'smooth':
        # æ»‘ã‚‰ã‹ãªé–¢æ•°ï¼ˆææ–™ç‰©æ€§ãªã©ï¼‰
        return RBF()

    elif problem_characteristics.get('smoothness') == 'rough':
        # ãƒã‚¤ã‚ºã‚„ä¸é€£ç¶šæ€§ãŒã‚ã‚‹
        return MaternKernel(nu=1.5)

    else:
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: Matern 5/2ï¼ˆæ±ç”¨æ€§é«˜ã„ï¼‰
        return MaternKernel(nu=2.5)

# ä½¿ç”¨ä¾‹
problem_specs = {
    'smoothness': 'smooth',
    'periodicity': False,
    'dimensionality': 4
}

recommended_kernel = select_kernel(problem_specs)
print(f&quot;æ¨å¥¨ã‚«ãƒ¼ãƒãƒ«: {recommended_kernel}&quot;)
</code></pre>
<p><strong>ã‚«ãƒ¼ãƒãƒ«æ¯”è¼ƒå®Ÿé¨“</strong>:</p>
<pre><code class="language-python">import numpy as np
import matplotlib.pyplot as plt
from sklearn.gaussian_process import GaussianProcessRegressor
from sklearn.gaussian_process.kernels import RBF, Matern

# ãƒ†ã‚¹ãƒˆé–¢æ•°
def test_function(x):
    &quot;&quot;&quot;ãƒã‚¤ã‚ºã®ã‚ã‚‹è¤‡é›‘ãªé–¢æ•°&quot;&quot;&quot;
    return np.sin(5*x) + 0.5*np.cos(15*x) + 0.1*np.random.randn(len(x))

# ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
np.random.seed(42)
X_train = np.random.uniform(0, 1, 20).reshape(-1, 1)
y_train = test_function(X_train.ravel())

X_test = np.linspace(0, 1, 200).reshape(-1, 1)
y_true = test_function(X_test.ravel())

# ç•°ãªã‚‹ã‚«ãƒ¼ãƒãƒ«ã§æ¯”è¼ƒ
kernels = {
    'RBF': RBF(length_scale=0.1),
    'Matern 1.5': Matern(length_scale=0.1, nu=1.5),
    'Matern 2.5': Matern(length_scale=0.1, nu=2.5)
}

fig, axes = plt.subplots(1, 3, figsize=(15, 4))

for ax, (name, kernel) in zip(axes, kernels.items()):
    gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10)
    gp.fit(X_train, y_train)
    y_pred, y_std = gp.predict(X_test, return_std=True)

    ax.scatter(X_train, y_train, c='red', label='è¨“ç·´ãƒ‡ãƒ¼ã‚¿')
    ax.plot(X_test, y_pred, 'b-', label='äºˆæ¸¬')
    ax.fill_between(X_test.ravel(), y_pred - 2*y_std, y_pred + 2*y_std,
                     alpha=0.3, color='blue')
    ax.set_title(f'ã‚«ãƒ¼ãƒãƒ«: {name}')
    ax.legend()
    ax.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('kernel_comparison.png', dpi=150)
plt.show()

print(&quot;çµè«–:&quot;)
print(&quot;  RBF: æ»‘ã‚‰ã‹ãªé–¢æ•°ã«æœ€é©&quot;)
print(&quot;  Matern 1.5: ãƒã‚¤ã‚ºè€æ€§ãŒé«˜ã„&quot;)
print(&quot;  Matern 2.5: ãƒãƒ©ãƒ³ã‚¹ãŒè‰¯ã„ï¼ˆæ¨å¥¨ï¼‰&quot;)
</code></pre>
<hr />
<h4>è½ã¨ã—ç©´2: åˆæœŸåŒ–æˆ¦ç•¥ã®å¤±æ•—</h4>
<p><strong>å•é¡Œ</strong>: åˆæœŸã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãŒæ¢ç´¢ç©ºé–“ã‚’ååˆ†ã‚«ãƒãƒ¼ã—ã¦ã„ãªã„</p>
<p><strong>ç—‡çŠ¶</strong>:
- æ¢ç´¢ãŒåã‚‹
- é‡è¦ãªé ˜åŸŸã‚’è¦‹é€ƒã™
- åæŸãŒé…ã„</p>
<p><strong>è§£æ±ºç­–</strong>: ãƒ©ãƒ†ãƒ³è¶…æ–¹æ ¼ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆLHSï¼‰</p>
<pre><code class="language-python">from scipy.stats.qmc import LatinHypercube

def initialize_with_lhs(n_samples, bounds, seed=42):
    &quot;&quot;&quot;
    ãƒ©ãƒ†ãƒ³è¶…æ–¹æ ¼ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã§åˆæœŸç‚¹ã‚’ç”Ÿæˆ

    Parameters:
    -----------
    n_samples : int
        ã‚µãƒ³ãƒ—ãƒ«æ•°
    bounds : array (n_dims, 2)
        å„æ¬¡å…ƒã® [lower, upper] å¢ƒç•Œ
    seed : int
        ä¹±æ•°ã‚·ãƒ¼ãƒ‰

    Returns:
    --------
    X_init : array (n_samples, n_dims)
        åˆæœŸã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ç‚¹
    &quot;&quot;&quot;
    bounds = np.array(bounds)
    n_dims = len(bounds)

    # LHSã‚µãƒ³ãƒ—ãƒ©ãƒ¼
    sampler = LatinHypercube(d=n_dims, seed=seed)
    X_unit = sampler.random(n=n_samples)

    # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
    X_init = bounds[:, 0] + (bounds[:, 1] - bounds[:, 0]) * X_unit

    return X_init

# ä½¿ç”¨ä¾‹: Li-ioné›»æ± çµ„æˆã®åˆæœŸåŒ–
bounds_composition = [
    [0.1, 0.5],  # Li
    [0.1, 0.4],  # Ni
    [0.1, 0.3],  # Co
    [0.0, 0.5]   # Mn
]

X_init_lhs = initialize_with_lhs(
    n_samples=20,
    bounds=bounds_composition,
    seed=42
)

# çµ„æˆæ­£è¦åŒ–
X_init_lhs = X_init_lhs / X_init_lhs.sum(axis=1, keepdims=True)

print(&quot;LHSåˆæœŸåŒ–å®Œäº†&quot;)
print(f&quot;åˆæœŸã‚µãƒ³ãƒ—ãƒ«æ•°: {len(X_init_lhs)}&quot;)
print(f&quot;å„æ¬¡å…ƒã®ã‚«ãƒãƒ¼ç¯„å›²:&quot;)
for i, dim_name in enumerate(['Li', 'Ni', 'Co', 'Mn']):
    print(f&quot;  {dim_name}: [{X_init_lhs[:, i].min():.3f}, &quot;
          f&quot;{X_init_lhs[:, i].max():.3f}]&quot;)

# ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã¨ã®æ¯”è¼ƒå¯è¦–åŒ–
fig, axes = plt.subplots(1, 2, figsize=(12, 5))

# ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
np.random.seed(42)
X_random = np.random.uniform(0, 1, (20, 2))

axes[0].scatter(X_random[:, 0], X_random[:, 1], s=100)
axes[0].set_title('ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°')
axes[0].set_xlabel('æ¬¡å…ƒ1')
axes[0].set_ylabel('æ¬¡å…ƒ2')
axes[0].grid(True, alpha=0.3)

# LHS
axes[1].scatter(X_init_lhs[:, 0], X_init_lhs[:, 1], s=100, c='red')
axes[1].set_title('ãƒ©ãƒ†ãƒ³è¶…æ–¹æ ¼ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆLHSï¼‰')
axes[1].set_xlabel('æ¬¡å…ƒ1 (Li)')
axes[1].set_ylabel('æ¬¡å…ƒ2 (Ni)')
axes[1].grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('lhs_vs_random.png', dpi=150)
plt.show()
</code></pre>
<hr />
<h4>è½ã¨ã—ç©´3: ãƒã‚¤ã‚ºã®ã‚ã‚‹è¦³æ¸¬ã¸ã®å¯¾å¿œä¸è¶³</h4>
<p><strong>å•é¡Œ</strong>: å®Ÿé¨“ãƒã‚¤ã‚ºã‚’è€ƒæ…®ã—ã¦ã„ãªã„</p>
<p><strong>ç—‡çŠ¶</strong>:
- åŒã˜æ¡ä»¶ã§çµæœãŒå†ç¾ã—ãªã„
- ãƒ¢ãƒ‡ãƒ«ãŒéå­¦ç¿’ã™ã‚‹
- æœ€é©ç‚¹ãŒä¸å®‰å®š</p>
<p><strong>è§£æ±ºç­–</strong>: ãƒã‚¤ã‚ºã‚’æ˜ç¤ºçš„ã«ãƒ¢ãƒ‡ãƒ«åŒ–</p>
<pre><code class="language-python">import torch
from botorch.models import SingleTaskGP
from gpytorch.mlls import ExactMarginalLogLikelihood

def fit_gp_with_noise(X, y, noise_variance=0.01):
    &quot;&quot;&quot;
    ãƒã‚¤ã‚ºã‚’è€ƒæ…®ã—ãŸã‚¬ã‚¦ã‚¹éç¨‹ã®å­¦ç¿’

    Parameters:
    -----------
    X : Tensor (n, d)
        å…¥åŠ›ãƒ‡ãƒ¼ã‚¿
    y : Tensor (n, 1)
        è¦³æ¸¬å€¤ï¼ˆãƒã‚¤ã‚ºå«ã‚€ï¼‰
    noise_variance : float
        è¦³æ¸¬ãƒã‚¤ã‚ºã®åˆ†æ•£ï¼ˆäº‹å‰çŸ¥è­˜ã‹ã‚‰è¨­å®šï¼‰

    Returns:
    --------
    gp_model : SingleTaskGP
        å­¦ç¿’æ¸ˆã¿GPãƒ¢ãƒ‡ãƒ«
    &quot;&quot;&quot;
    # ãƒã‚¤ã‚ºåˆ†æ•£ã‚’è¨­å®šã—ã¦GPæ§‹ç¯‰
    gp_model = SingleTaskGP(X, y, train_Yvar=torch.full_like(y, noise_variance))

    # å°¤åº¦æœ€å¤§åŒ–
    mll = ExactMarginalLogLikelihood(gp_model.likelihood, gp_model)
    from botorch.fit import fit_gpytorch_model
    fit_gpytorch_model(mll)

    return gp_model

# ä½¿ç”¨ä¾‹: ãƒã‚¤ã‚ºã®ã‚ã‚‹å®Ÿé¨“ãƒ‡ãƒ¼ã‚¿
np.random.seed(42)
X_obs = np.random.rand(15, 4)
X_obs = X_obs / X_obs.sum(axis=1, keepdims=True)

# çœŸã®å®¹é‡ + å®Ÿé¨“ãƒã‚¤ã‚º
y_true = 200 + 150 * X_obs[:, 0] + 50 * X_obs[:, 1]
noise = np.random.randn(15) * 10  # å®Ÿé¨“ãƒã‚¤ã‚º Ïƒ=10 mAh/g
y_obs = y_true + noise

# PyTorchãƒ†ãƒ³ã‚½ãƒ«ã«å¤‰æ›
X_tensor = torch.tensor(X_obs, dtype=torch.float64)
y_tensor = torch.tensor(y_obs, dtype=torch.float64).unsqueeze(-1)

# ãƒã‚¤ã‚ºã‚’è€ƒæ…®ã—ã¦GPå­¦ç¿’
gp_noisy = fit_gp_with_noise(X_tensor, y_tensor, noise_variance=100.0)

print(&quot;ãƒã‚¤ã‚ºã‚’è€ƒæ…®ã—ãŸGPå­¦ç¿’å®Œäº†&quot;)
print(f&quot;è¦³æ¸¬ãƒã‚¤ã‚ºæ¨™æº–åå·®: 10 mAh/g&quot;)
print(f&quot;ãƒ¢ãƒ‡ãƒ«åŒ–ãƒã‚¤ã‚ºåˆ†æ•£: 100.0 (mAh/g)Â²&quot;)
</code></pre>
<p><strong>ãƒã‚¤ã‚ºãƒ¬ãƒ™ãƒ«ã®æ¨å®š</strong>:</p>
<pre><code class="language-python">def estimate_noise_level(X, y, n_replicates=3):
    &quot;&quot;&quot;
    è¤‡è£½å®Ÿé¨“ã‹ã‚‰ãƒã‚¤ã‚ºãƒ¬ãƒ™ãƒ«ã‚’æ¨å®š

    Parameters:
    -----------
    X : array (n, d)
        å®Ÿé¨“æ¡ä»¶
    y : array (n,)
        è¦³æ¸¬å€¤
    n_replicates : int
        å„æ¡ä»¶ã§ã®è¤‡è£½å®Ÿé¨“æ•°

    Returns:
    --------
    noise_std : float
        æ¨å®šãƒã‚¤ã‚ºæ¨™æº–åå·®
    &quot;&quot;&quot;
    # åŒä¸€æ¡ä»¶ã®è¤‡è£½å®Ÿé¨“ã‚’æŠ½å‡º
    unique_X, indices = np.unique(X, axis=0, return_inverse=True)

    variances = []
    for i in range(len(unique_X)):
        replicates = y[indices == i]
        if len(replicates) &gt;= 2:
            variances.append(np.var(replicates, ddof=1))

    if len(variances) == 0:
        print(&quot;è­¦å‘Š: è¤‡è£½å®Ÿé¨“ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ä½¿ç”¨&quot;)
        return 1.0

    noise_std = np.sqrt(np.mean(variances))
    return noise_std

# ä½¿ç”¨ä¾‹
noise_std_estimated = estimate_noise_level(X_obs, y_obs)
print(f&quot;æ¨å®šãƒã‚¤ã‚ºæ¨™æº–åå·®: {noise_std_estimated:.2f} mAh/g&quot;)
</code></pre>
<hr />
<h4>è½ã¨ã—ç©´4: åˆ¶ç´„å‡¦ç†ã®ä¸å‚™</h4>
<p><strong>å•é¡Œ</strong>: åˆ¶ç´„é•åã‚’é©åˆ‡ã«æ‰±ã£ã¦ã„ãªã„</p>
<p><strong>ç—‡çŠ¶</strong>:
- å®Ÿè¡Œä¸å¯èƒ½ãªææ–™ã‚’ææ¡ˆ
- æœ€é©åŒ–ãŒåæŸã—ãªã„
- ç„¡é§„ãªå®Ÿé¨“ãŒå¤šã„</p>
<p><strong>è§£æ±ºç­–</strong>: åˆ¶ç´„ä»˜ãç²å¾—é–¢æ•°</p>
<pre><code class="language-python">from botorch.acquisition import ConstrainedExpectedImprovement

def constrained_bayesian_optimization_example():
    &quot;&quot;&quot;
    åˆ¶ç´„ä»˜ããƒ™ã‚¤ã‚ºæœ€é©åŒ–ã®å®Ÿè£…ä¾‹

    åˆ¶ç´„:
    1. çµ„æˆã®åˆè¨ˆ = 1.0 (Â±2%)
    2. Coå«é‡ &lt; 0.3 (ã‚³ã‚¹ãƒˆåˆ¶ç´„)
    3. å®‰å®šæ€§: formation energy &lt; -1.5 eV/atom
    &quot;&quot;&quot;
    # åˆæœŸãƒ‡ãƒ¼ã‚¿
    n_initial = 10
    X_init = initialize_with_lhs(n_initial, bounds_composition, seed=42)
    X_init = X_init / X_init.sum(axis=1, keepdims=True)  # æ­£è¦åŒ–

    # ç›®çš„é–¢æ•°ã¨åˆ¶ç´„ã®è©•ä¾¡
    y_capacity = []
    constraints_satisfied = []

    for x in X_init:
        # å®¹é‡äºˆæ¸¬ï¼ˆç›®çš„é–¢æ•°ï¼‰
        capacity = 200 + 150*x[0] + 50*x[1]
        y_capacity.append(capacity)

        # åˆ¶ç´„ãƒã‚§ãƒƒã‚¯
        co_constraint = x[2] &lt; 0.3  # Co &lt; 0.3
        stability = -2.0 - 0.5*x[0] - 0.3*x[1]
        stability_constraint = stability &lt; -1.5  # å®‰å®š

        all_satisfied = co_constraint and stability_constraint
        constraints_satisfied.append(1.0 if all_satisfied else 0.0)

    X_tensor = torch.tensor(X_init, dtype=torch.float64)
    y_tensor = torch.tensor(y_capacity, dtype=torch.float64).unsqueeze(-1)
    c_tensor = torch.tensor(constraints_satisfied, dtype=torch.float64).unsqueeze(-1)

    # ã‚¬ã‚¦ã‚¹éç¨‹ãƒ¢ãƒ‡ãƒ«ï¼ˆç›®çš„é–¢æ•°ï¼‰
    gp_objective = SingleTaskGP(X_tensor, y_tensor)
    mll_obj = ExactMarginalLogLikelihood(gp_objective.likelihood, gp_objective)
    from botorch.fit import fit_gpytorch_model
    fit_gpytorch_model(mll_obj)

    # ã‚¬ã‚¦ã‚¹éç¨‹ãƒ¢ãƒ‡ãƒ«ï¼ˆåˆ¶ç´„ï¼‰
    gp_constraint = SingleTaskGP(X_tensor, c_tensor)
    mll_con = ExactMarginalLogLikelihood(gp_constraint.likelihood, gp_constraint)
    fit_gpytorch_model(mll_con)

    # åˆ¶ç´„ä»˜ãEIç²å¾—é–¢æ•°
    best_f = y_tensor.max()
    acq_func = ConstrainedExpectedImprovement(
        model=gp_objective,
        best_f=best_f,
        objective_index=0,
        constraints={0: [None, 0.5]}  # åˆ¶ç´„æº€è¶³ç¢ºç‡ &gt; 0.5
    )

    print(&quot;åˆ¶ç´„ä»˜ããƒ™ã‚¤ã‚ºæœ€é©åŒ–ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å®Œäº†&quot;)
    print(f&quot;åˆæœŸå®Ÿè¡Œå¯èƒ½è§£: {sum(constraints_satisfied)}/{n_initial}&quot;)

    return gp_objective, gp_constraint, acq_func

# å®Ÿè¡Œ
gp_obj, gp_con, acq = constrained_bayesian_optimization_example()
</code></pre>
<hr />
<h2>End-of-Chapter Checklist (add before "æ¼”ç¿’å•é¡Œ")</h2>
<h3>3.9 ç« æœ«ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ</h3>
<h4>âœ… ã‚¬ã‚¦ã‚¹éç¨‹ã®ç†è§£</h4>
<ul>
<li>[ ] ã‚¬ã‚¦ã‚¹éç¨‹ã®åŸºæœ¬æ¦‚å¿µã‚’èª¬æ˜ã§ãã‚‹</li>
<li>[ ] ã‚«ãƒ¼ãƒãƒ«é–¢æ•°ã®å½¹å‰²ã‚’ç†è§£ã—ã¦ã„ã‚‹</li>
<li>[ ] äºˆæ¸¬å¹³å‡ã¨ä¸ç¢ºå®Ÿæ€§ã®æ„å‘³ã‚’çŸ¥ã£ã¦ã„ã‚‹</li>
<li>[ ] é©åˆ‡ãªã‚«ãƒ¼ãƒãƒ«ã‚’é¸æŠã§ãã‚‹</li>
<li>[ ] ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å½±éŸ¿ã‚’èª¬æ˜ã§ãã‚‹</li>
</ul>
<p><strong>ç¢ºèªå•é¡Œ</strong>:</p>
<pre><code>Q: RBFã‚«ãƒ¼ãƒãƒ«ã¨Maternã‚«ãƒ¼ãƒãƒ«ã®é•ã„ã¯ä½•ã§ã™ã‹ï¼Ÿ
A: RBFã¯ç„¡é™å›å¾®åˆ†å¯èƒ½ï¼ˆéå¸¸ã«æ»‘ã‚‰ã‹ï¼‰ã€Maternã¯ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿Î½ã§
   æ»‘ã‚‰ã‹ã•ã‚’èª¿æ•´å¯èƒ½ã€‚ãƒã‚¤ã‚ºãŒã‚ã‚‹å ´åˆã¯Matern (Î½=2.5) ãŒæ¨å¥¨ã€‚
</code></pre>
<hr />
<h4>âœ… ç²å¾—é–¢æ•°ã®é¸æŠ</h4>
<ul>
<li>[ ] Expected Improvement (EI) ã®ä»•çµ„ã¿ã‚’ç†è§£ã—ã¦ã„ã‚‹</li>
<li>[ ] Upper Confidence Bound (UCB) ã®æ¢ç´¢ãƒ»æ´»ç”¨ãƒãƒ©ãƒ³ã‚¹ã‚’èª¬æ˜ã§ãã‚‹</li>
<li>[ ] Probability of Improvement (PI) ã®ç‰¹æ€§ã‚’çŸ¥ã£ã¦ã„ã‚‹</li>
<li>[ ] Knowledge Gradient (KG) ã®é©ç”¨å ´é¢ã‚’ç†è§£ã—ã¦ã„ã‚‹</li>
<li>[ ] å•é¡Œã«å¿œã˜ã¦ç²å¾—é–¢æ•°ã‚’é¸æŠã§ãã‚‹</li>
</ul>
<p><strong>é¸æŠã‚¬ã‚¤ãƒ‰</strong>:</p>
<pre><code>ä¸€èˆ¬çš„ãªæœ€é©åŒ–     â†’ EI (ãƒãƒ©ãƒ³ã‚¹è‰¯ã„)
æ¢ç´¢é‡è¦–ã®åˆæœŸ     â†’ UCB (Îº=2~3)
å®‰å…¨é‡è¦–          â†’ PI (ä¿å®ˆçš„)
ãƒãƒƒãƒæœ€é©åŒ–      â†’ q-EI, q-KG
å¤šç›®çš„æœ€é©åŒ–      â†’ EHVI (Hypervolume)
</code></pre>
<hr />
<h4>âœ… å¤šç›®çš„æœ€é©åŒ–</h4>
<ul>
<li>[ ] Paretoæœ€é©ã®å®šç¾©ã‚’èª¬æ˜ã§ãã‚‹</li>
<li>[ ] Paretoãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢ã®æ„å‘³ã‚’ç†è§£ã—ã¦ã„ã‚‹</li>
<li>[ ] Expected Hypervolume Improvement (EHVI) ã®ä»•çµ„ã¿ã‚’çŸ¥ã£ã¦ã„ã‚‹</li>
<li>[ ] ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’å®šé‡çš„ã«è©•ä¾¡ã§ãã‚‹</li>
<li>[ ] å¤šç›®çš„æœ€é©åŒ–ã‚’å®Ÿè£…ã§ãã‚‹</li>
</ul>
<p><strong>å®Ÿè£…ãƒã‚§ãƒƒã‚¯</strong>:</p>
<pre><code class="language-python"># ä»¥ä¸‹ã‚’å®Ÿè£…ã§ãã¾ã™ã‹ï¼Ÿ
def is_pareto_optimal(objectives):
    &quot;&quot;&quot;
    Paretoæœ€é©è§£ã‚’åˆ¤å®šã™ã‚‹é–¢æ•°
    objectives: (n_points, n_objectives)
    &quot;&quot;&quot;
    # ã‚ãªãŸã®å®Ÿè£…
    pass

# æ­£è§£ã¯æ¼”ç¿’å•é¡Œ3ã‚’å‚ç…§
</code></pre>
<hr />
<h4>âœ… ãƒãƒƒãƒãƒ™ã‚¤ã‚ºæœ€é©åŒ–</h4>
<ul>
<li>[ ] ãƒãƒƒãƒæœ€é©åŒ–ã®åˆ©ç‚¹ã‚’èª¬æ˜ã§ãã‚‹</li>
<li>[ ] q-EIç²å¾—é–¢æ•°ã®ä»•çµ„ã¿ã‚’ç†è§£ã—ã¦ã„ã‚‹</li>
<li>[ ] Kriging Believeræ³•ã‚’çŸ¥ã£ã¦ã„ã‚‹</li>
<li>[ ] ä¸¦åˆ—å®Ÿé¨“ã®åŠ¹ç‡åŒ–æˆ¦ç•¥ã‚’ç«‹ã¦ã‚‰ã‚Œã‚‹</li>
<li>[ ] ãƒãƒƒãƒã‚µã‚¤ã‚ºã®é¸æŠåŸºæº–ã‚’ç†è§£ã—ã¦ã„ã‚‹</li>
</ul>
<p><strong>ãƒãƒƒãƒã‚µã‚¤ã‚ºé¸æŠ</strong>:</p>
<pre><code>å®Ÿé¨“è£…ç½®æ•°: nå°
â†’ ãƒãƒƒãƒã‚µã‚¤ã‚º: nï¼ˆæœ€å¤§æ´»ç”¨ï¼‰

è¨ˆç®—ã‚³ã‚¹ãƒˆåˆ¶ç´„ã‚ã‚Š
â†’ ãƒãƒƒãƒã‚µã‚¤ã‚º: 3~5ï¼ˆå®Ÿç”¨çš„ï¼‰

æ¢ç´¢åˆæœŸ
â†’ ãƒãƒƒãƒã‚µã‚¤ã‚º: å¤§ãã‚ï¼ˆå¤šæ§˜æ€§é‡è¦–ï¼‰

åæŸæœŸ
â†’ ãƒãƒƒãƒã‚µã‚¤ã‚º: å°ã•ã‚ï¼ˆç²¾å¯†åŒ–ï¼‰
</code></pre>
<hr />
<h4>âœ… åˆ¶ç´„å‡¦ç†</h4>
<ul>
<li>[ ] åˆ¶ç´„ã®ç¨®é¡ï¼ˆç­‰å¼ã€ä¸ç­‰å¼ï¼‰ã‚’åŒºåˆ¥ã§ãã‚‹</li>
<li>[ ] å®Ÿè¡Œå¯èƒ½é ˜åŸŸã®æ¦‚å¿µã‚’ç†è§£ã—ã¦ã„ã‚‹</li>
<li>[ ] åˆ¶ç´„ä»˜ãç²å¾—é–¢æ•°ã‚’å®Ÿè£…ã§ãã‚‹</li>
<li>[ ] å®Ÿè¡Œå¯èƒ½ç¢ºç‡ã‚’è¨ˆç®—ã§ãã‚‹</li>
<li>[ ] æ®µéšçš„åˆ¶ç´„ç·©å’Œã®æˆ¦ç•¥ã‚’çŸ¥ã£ã¦ã„ã‚‹</li>
</ul>
<p><strong>åˆ¶ç´„å‡¦ç†ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ</strong>:</p>
<pre><code>â–¡ çµ„æˆåˆ¶ç´„ï¼ˆåˆè¨ˆ=1.0ï¼‰ã‚’æ­£è¦åŒ–ã§å‡¦ç†
â–¡ å¢ƒç•Œåˆ¶ç´„ã‚’boundsãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§è¨­å®š
â–¡ éç·šå½¢åˆ¶ç´„ã‚’ãƒšãƒŠãƒ«ãƒ†ã‚£é–¢æ•°ã§è¡¨ç¾
â–¡ å®Ÿè¡Œå¯èƒ½è§£ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã®å¯¾å‡¦æ³•ã‚’æº–å‚™
â–¡ åˆ¶ç´„æº€è¶³ç¢ºç‡ã‚’å¯è¦–åŒ–
</code></pre>
<hr />
<h4>âœ… å®Ÿè£…ã‚¹ã‚­ãƒ«ï¼ˆGPyTorch/BoTorchï¼‰</h4>
<ul>
<li>[ ] SingleTaskGPãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã§ãã‚‹</li>
<li>[ ] ã‚«ãƒ¼ãƒãƒ«ã‚’é©åˆ‡ã«é¸æŠãƒ»è¨­å®šã§ãã‚‹</li>
<li>[ ] ç²å¾—é–¢æ•°ã‚’æœ€é©åŒ–ã§ãã‚‹</li>
<li>[ ] ãƒãƒƒãƒæœ€é©åŒ–ã‚’å®Ÿè£…ã§ãã‚‹</li>
<li>[ ] ãƒã‚¤ã‚ºã‚’è€ƒæ…®ã—ãŸãƒ¢ãƒ‡ãƒªãƒ³ã‚°ãŒã§ãã‚‹</li>
</ul>
<p><strong>ã‚³ãƒ¼ãƒ‰å®Ÿè£…ç¢ºèª</strong>:</p>
<pre><code class="language-python"># ã“ã®ã‚³ãƒ¼ãƒ‰ãŒç†è§£ã§ãã¾ã™ã‹ï¼Ÿ
from botorch.models import SingleTaskGP
from botorch.fit import fit_gpytorch_model
from gpytorch.mlls import ExactMarginalLogLikelihood
from botorch.acquisition import ExpectedImprovement
from botorch.optim import optimize_acqf

# GPãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰
gp = SingleTaskGP(X_train, y_train)
mll = ExactMarginalLogLikelihood(gp.likelihood, gp)
fit_gpytorch_model(mll)

# EIæœ€å¤§åŒ–
EI = ExpectedImprovement(gp, best_f=y_train.max())
candidate, acq_value = optimize_acqf(
    EI, bounds=bounds, q=1, num_restarts=10
)

# å„è¡Œã®æ„å‘³ã‚’èª¬æ˜ã§ãã¾ã™ã‹ï¼Ÿ
</code></pre>
<hr />
<h4>âœ… å®Ÿé¨“è¨­è¨ˆã¨ã®çµ±åˆ</h4>
<ul>
<li>[ ] Materials Projectãªã©å®Ÿãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚’æ´»ç”¨ã§ãã‚‹</li>
<li>[ ] MLãƒ¢ãƒ‡ãƒ«ã¨ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã‚’çµ±åˆã§ãã‚‹</li>
<li>[ ] å®Ÿé¨“è¨ˆç”»ã‚’ç«‹ã¦ã‚‰ã‚Œã‚‹</li>
<li>[ ] çµæœã‚’å¯è¦–åŒ–ãƒ»è§£é‡ˆã§ãã‚‹</li>
<li>[ ] ROIã‚’è©•ä¾¡ã§ãã‚‹</li>
</ul>
<p><strong>å®Ÿé¨“è¨ˆç”»ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ</strong>:</p>
<pre><code>1. ç›®çš„è¨­å®š
   - æœ€é©åŒ–ã™ã‚‹ç‰¹æ€§: ________
   - åˆ¶ç´„æ¡ä»¶: ________
   - å®Ÿé¨“äºˆç®—: ________ å›

2. åˆæœŸåŒ–
   - åˆæœŸã‚µãƒ³ãƒ—ãƒ«æ•°: ________
   - ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ³•: LHS / Random
   - äºˆæƒ³å®Ÿé¨“æœŸé–“: ________

3. æœ€é©åŒ–æˆ¦ç•¥
   - ç²å¾—é–¢æ•°: ________
   - ã‚«ãƒ¼ãƒãƒ«: ________
   - ãƒãƒƒãƒã‚µã‚¤ã‚º: ________

4. çµ‚äº†æ¡ä»¶
   - æœ€å¤§å®Ÿé¨“å›æ•°: ________
   - ç›®æ¨™æ€§èƒ½: ________
   - æ”¹å–„ç‡é–¾å€¤: ________
</code></pre>
<hr />
<h4>âœ… ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°</h4>
<ul>
<li>[ ] å±€æ‰€æœ€é©ã‹ã‚‰ã®è„±å‡ºæ–¹æ³•ã‚’çŸ¥ã£ã¦ã„ã‚‹</li>
<li>[ ] åˆ¶ç´„é•åã¸ã®å¯¾å‡¦æ³•ã‚’ç†è§£ã—ã¦ã„ã‚‹</li>
<li>[ ] è¨ˆç®—æ™‚é–“å‰Šæ¸›ã®æ‰‹æ³•ã‚’çŸ¥ã£ã¦ã„ã‚‹</li>
<li>[ ] ãƒã‚¤ã‚ºã¸ã®å¯¾å‡¦æ³•ã‚’å®Ÿè£…ã§ãã‚‹</li>
<li>[ ] ãƒ‡ãƒãƒƒã‚°æ–¹æ³•ã‚’çŸ¥ã£ã¦ã„ã‚‹</li>
</ul>
<p><strong>ã‚ˆãã‚ã‚‹ã‚¨ãƒ©ãƒ¼ã¨å¯¾å‡¦æ³•</strong>:</p>
<pre><code>ã‚¨ãƒ©ãƒ¼: &quot;RuntimeError: cholesky_cpu: U(i,i) is zero&quot;
â†’ åŸå› : æ•°å€¤ä¸å®‰å®šæ€§
â†’ å¯¾å‡¦: GPãƒ¢ãƒ‡ãƒ«ã«jitterè¿½åŠ 
   gp = SingleTaskGP(X, y, covar_module=...).double()
   gp.likelihood.noise = 1e-4

ã‚¨ãƒ©ãƒ¼: &quot;All points violate constraints&quot;
â†’ åŸå› : åˆ¶ç´„ãŒå³ã—ã™ãã‚‹
â†’ å¯¾å‡¦: æ®µéšçš„åˆ¶ç´„ç·©å’Œã€åˆæœŸLHSã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°

è­¦å‘Š: &quot;Optimization failed to converge&quot;
â†’ åŸå› : ç²å¾—é–¢æ•°æœ€é©åŒ–ã®å¤±æ•—
â†’ å¯¾å‡¦: num_restartså¢—åŠ ã€raw_sampleså¢—åŠ 
</code></pre>
<hr />
<h3>åˆæ ¼åŸºæº–</h3>
<p>å„ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§80%ä»¥ä¸Šã®ãƒã‚§ãƒƒã‚¯é …ç›®ã‚’ã‚¯ãƒªã‚¢ã—ã€
å®Ÿè£…ç¢ºèªã‚³ãƒ¼ãƒ‰ãŒç†è§£ã§ãã‚Œã°ã€æ¬¡ç« ã¸é€²ã‚€æº–å‚™å®Œäº†ã§ã™ã€‚</p>
<p><strong>æœ€çµ‚ç¢ºèªå•é¡Œ</strong>:
1. Li-ioné›»æ± æ­£æ¥µææ–™ã®æœ€é©åŒ–å•é¡Œã‚’å®šå¼åŒ–ã§ãã¾ã™ã‹ï¼Ÿ
2. 3ç›®çš„ï¼ˆå®¹é‡ã€é›»åœ§ã€å®‰å®šæ€§ï¼‰ã®æœ€é©åŒ–ã‚’å®Ÿè£…ã§ãã¾ã™ã‹ï¼Ÿ
3. å®Ÿé¨“å›æ•°50å›ã§Paretoæœ€é©è§£10å€‹ã‚’è¦‹ã¤ã‘ã‚‰ã‚Œã¾ã™ã‹ï¼Ÿ</p>
<p>å…¨ã¦YESãªã‚‰ã€ç¬¬4ç« ã€Œã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ã¨å®Ÿé¨“é€£æºã€ã¸é€²ã¿ã¾ã—ã‚‡ã†ï¼</p><div class="navigation">
    <a href="chapter-2.html" class="nav-button">â† å‰ã®ç« </a>
    <a href="index.html" class="nav-button">ã‚·ãƒªãƒ¼ã‚ºç›®æ¬¡ã«æˆ»ã‚‹</a>
    <a href="chapter-4-enhancements.html" class="nav-button">æ¬¡ã®ç«  â†’</a>
</div>
    </main>

    <footer>
        <p><strong>ä½œæˆè€…</strong>: AI Terakoya Content Team</p>
        <p><strong>ãƒãƒ¼ã‚¸ãƒ§ãƒ³</strong>: 1.0 | <strong>ä½œæˆæ—¥</strong>: 2025-10-17</p>
        <p><strong>ãƒ©ã‚¤ã‚»ãƒ³ã‚¹</strong>: Creative Commons BY 4.0</p>
        <p>Â© 2025 AI Terakoya. All rights reserved.</p>
    </footer>
</body>
</html>
