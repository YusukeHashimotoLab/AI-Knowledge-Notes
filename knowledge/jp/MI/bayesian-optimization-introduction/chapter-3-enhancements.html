<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Chapter - AI Terakoya</title>

    <style>
        :root {
            --color-primary: #2c3e50;
            --color-primary-dark: #1a252f;
            --color-accent: #7b2cbf;
            --color-accent-light: #9d4edd;
            --color-text: #2d3748;
            --color-text-light: #4a5568;
            --color-bg: #ffffff;
            --color-bg-alt: #f7fafc;
            --color-border: #e2e8f0;
            --color-code-bg: #f8f9fa;
            --color-link: #3182ce;
            --color-link-hover: #2c5aa0;

            --spacing-xs: 0.5rem;
            --spacing-sm: 1rem;
            --spacing-md: 1.5rem;
            --spacing-lg: 2rem;
            --spacing-xl: 3rem;

            --font-body: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            --font-mono: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;

            --border-radius: 8px;
            --box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: var(--font-body);
            line-height: 1.7;
            color: var(--color-text);
            background-color: var(--color-bg);
            font-size: 16px;
        }

        header {
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            padding: var(--spacing-xl) var(--spacing-md);
            margin-bottom: var(--spacing-xl);
            box-shadow: var(--box-shadow);
        }

        .header-content {
            max-width: 900px;
            margin: 0 auto;
        }

        h1 {
            font-size: 2rem;
            font-weight: 700;
            margin-bottom: var(--spacing-sm);
            line-height: 1.2;
        }

        .subtitle {
            font-size: 1.1rem;
            opacity: 0.95;
            font-weight: 400;
            margin-bottom: var(--spacing-md);
        }

        .meta {
            display: flex;
            flex-wrap: wrap;
            gap: var(--spacing-md);
            font-size: 0.9rem;
            opacity: 0.9;
        }

        .meta-item {
            display: flex;
            align-items: center;
            gap: 0.3rem;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 0 var(--spacing-md) var(--spacing-xl);
        }

        h2 {
            font-size: 1.75rem;
            color: var(--color-primary);
            margin-top: var(--spacing-xl);
            margin-bottom: var(--spacing-md);
            padding-bottom: var(--spacing-xs);
            border-bottom: 3px solid var(--color-accent);
        }

        h3 {
            font-size: 1.4rem;
            color: var(--color-primary);
            margin-top: var(--spacing-lg);
            margin-bottom: var(--spacing-sm);
        }

        h4 {
            font-size: 1.1rem;
            color: var(--color-primary-dark);
            margin-top: var(--spacing-md);
            margin-bottom: var(--spacing-sm);
        }

        p {
            margin-bottom: var(--spacing-md);
            color: var(--color-text);
        }

        a {
            color: var(--color-link);
            text-decoration: none;
            transition: color 0.2s;
        }

        a:hover {
            color: var(--color-link-hover);
            text-decoration: underline;
        }

        ul, ol {
            margin-left: var(--spacing-lg);
            margin-bottom: var(--spacing-md);
        }

        li {
            margin-bottom: var(--spacing-xs);
            color: var(--color-text);
        }

        pre {
            background-color: var(--color-code-bg);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            overflow-x: auto;
            margin-bottom: var(--spacing-md);
            font-family: var(--font-mono);
            font-size: 0.9rem;
            line-height: 1.5;
        }

        code {
            font-family: var(--font-mono);
            font-size: 0.9em;
            background-color: var(--color-code-bg);
            padding: 0.2em 0.4em;
            border-radius: 3px;
        }

        pre code {
            background-color: transparent;
            padding: 0;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: var(--spacing-md);
            font-size: 0.95rem;
        }

        th, td {
            border: 1px solid var(--color-border);
            padding: var(--spacing-sm);
            text-align: left;
        }

        th {
            background-color: var(--color-bg-alt);
            font-weight: 600;
            color: var(--color-primary);
        }

        blockquote {
            border-left: 4px solid var(--color-accent);
            padding-left: var(--spacing-md);
            margin: var(--spacing-md) 0;
            color: var(--color-text-light);
            font-style: italic;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        .mermaid {
            text-align: center;
            margin: var(--spacing-lg) 0;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        details {
            background-color: var(--color-bg-alt);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            margin-bottom: var(--spacing-md);
        }

        summary {
            cursor: pointer;
            font-weight: 600;
            color: var(--color-primary);
            user-select: none;
            padding: var(--spacing-xs);
            margin: calc(-1 * var(--spacing-md));
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        summary:hover {
            background-color: rgba(123, 44, 191, 0.1);
        }

        details[open] summary {
            margin-bottom: var(--spacing-md);
            border-bottom: 1px solid var(--color-border);
        }

        .learning-objectives {
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
            padding: var(--spacing-lg);
            border-radius: var(--border-radius);
            border-left: 4px solid var(--color-accent);
            margin-bottom: var(--spacing-xl);
        }

        .learning-objectives h2 {
            margin-top: 0;
            border-bottom: none;
        }

        .navigation {
            display: flex;
            justify-content: space-between;
            gap: var(--spacing-md);
            margin: var(--spacing-xl) 0;
            padding-top: var(--spacing-lg);
            border-top: 2px solid var(--color-border);
        }

        .nav-button {
            flex: 1;
            padding: var(--spacing-md);
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            border-radius: var(--border-radius);
            text-align: center;
            font-weight: 600;
            transition: transform 0.2s, box-shadow 0.2s;
            box-shadow: var(--box-shadow);
        }

        .nav-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
            text-decoration: none;
        }

        footer {
            margin-top: var(--spacing-xl);
            padding: var(--spacing-lg) var(--spacing-md);
            background-color: var(--color-bg-alt);
            border-top: 1px solid var(--color-border);
            text-align: center;
            font-size: 0.9rem;
            color: var(--color-text-light);
        }

        @media (max-width: 768px) {
            h1 {
                font-size: 1.5rem;
            }

            h2 {
                font-size: 1.4rem;
            }

            h3 {
                font-size: 1.2rem;
            }

            .meta {
                font-size: 0.85rem;
            }

            .navigation {
                flex-direction: column;
            }

            table {
                font-size: 0.85rem;
            }

            th, td {
                padding: var(--spacing-xs);
            }
        }
    </style>

    <script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
    <script>
        mermaid.initialize({ startOnLoad: true, theme: 'default', securityLevel: 'strict' });
    </script>

    <!-- MathJax for LaTeX equation rendering -->
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\(', '\)']],
                displayMath: [['$$', '$$'], ['\[', '\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
                ignoreHtmlClass: 'mermaid'
            }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" async></script>
</head>
<body>
    <header>
        <div class="header-content">
            <h1>Chapter</h1>
            <p class="subtitle"></p>
            <div class="meta">
                <span class="meta-item">üìñ Ë™≠‰∫ÜÊôÇÈñì: 20-25ÂàÜ</span>
                <span class="meta-item">üìä Èõ£ÊòìÂ∫¶: ÂàùÁ¥ö</span>
                <span class="meta-item">üíª „Ç≥„Éº„Éâ‰æã: 0ÂÄã</span>
                <span class="meta-item">üìù ÊºîÁøíÂïèÈ°å: 0Âïè</span>
            </div>
        </div>
    </header>

    <main class="container">
<h1>Chapter 3 Quality Enhancements</h1>
<p class="chapter-description" style="margin: 1.5rem 0; padding: 1rem; background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%); border-left: 4px solid #7b2cbf; border-radius: 8px; font-size: 1.05rem; line-height: 1.8; color: #2d3748;">scikit-optimize„ÇÑBoTorch„Åß„ÅÆÊúÄÂ∞èÂÆüË£Ö„Åã„ÇâÂßã„ÇÅ„ÄÅ„Éë„É©„É°„Éº„ÇøË®≠ÂÆö„ÅÆÂãòÊâÄ„ÇíÊäº„Åï„Åà„Åæ„Åô„ÄÇÂà∂Á¥Ñ„ÇÑÂ§öÁõÆÁöÑ„Å∏„ÅÆÊã°Âºµ„ÅÆÂÖ•Âè£„ÇÇÁ§∫„Åó„Åæ„Åô„ÄÇ</p>
<p class="chapter-supplement" style="margin: 0.75rem 0 1.5rem 0; padding: 0.75rem 1rem; background: linear-gradient(135deg, #fff8e1 0%, #fff3cd 100%); border-left: 3px solid #f59e0b; border-radius: 6px; font-size: 0.95rem; line-height: 1.7; color: #4a5568;"><strong>üí° Ë£úË∂≥:</strong> „Éé„Ç§„Ç∫„ÅÆË¶ãÁ©ç„ÇÇ„Çä„Å®„Çπ„Ç±„Éº„É´Ë™øÊï¥„ÅßÂÆâÂÆöÂåñ„ÄÇÂèçÂæ©ÂõûÊï∞„ÅØ‚ÄúÂ∞ëÊï∞Á≤æÈã≠‚Äù„ÅßË®≠Ë®à„Åó„Åæ„Åô„ÄÇ</p>





<p>This file contains enhancements to be integrated into chapter-3.md</p>
<h2>Code Reproducibility Section (add after section 3.1)</h2>
<h3>„Ç≥„Éº„ÉâÂÜçÁèæÊÄß„ÅÆÁ¢∫‰øù</h3>
<p><strong>Áí∞Â¢ÉË®≠ÂÆö„ÅÆÈáçË¶ÅÊÄß</strong>:</p>
<p>„Åô„Åπ„Å¶„ÅÆ„Ç≥„Éº„Éâ‰æã„ÅØ‰ª•‰∏ã„ÅÆÁí∞Â¢É„ÅßÂãï‰ΩúÁ¢∫Ë™ç„Åï„Çå„Å¶„ÅÑ„Åæ„ÅôÔºö</p>
<pre><code class="language-python"># ÂøÖÈ†à„É©„Ç§„Éñ„É©„É™„ÅÆ„Éê„Éº„Ç∏„Éß„É≥
&quot;&quot;&quot;
Python: 3.8+
numpy: 1.21.0
scikit-learn: 1.0.0
scikit-optimize: 0.9.0
torch: 1.12.0
gpytorch: 1.8.0
botorch: 0.7.0
matplotlib: 3.5.0
pandas: 1.3.0
scipy: 1.7.0
&quot;&quot;&quot;

# ÂÜçÁèæÊÄßÁ¢∫‰øù„ÅÆ„Åü„ÇÅ„ÅÆË®≠ÂÆö
import numpy as np
import torch
import random

# ‰π±Êï∞„Ç∑„Éº„Éâ„ÅÆÂõ∫ÂÆö
RANDOM_SEED = 42
np.random.seed(RANDOM_SEED)
torch.manual_seed(RANDOM_SEED)
random.seed(RANDOM_SEED)

# GPyTorch„Ç´„Éº„Éç„É´Ë®≠ÂÆöÔºàÊé®Â•®Ôºâ
from gpytorch.kernels import RBF, MaternKernel, ScaleKernel

# RBF„Ç´„Éº„Éç„É´ÔºàÊúÄ„ÇÇ‰∏ÄËà¨ÁöÑÔºâ
kernel_rbf = ScaleKernel(RBF(
    lengthscale_prior=None,  # „Éá„Éº„ÇøÈßÜÂãï„ÅßÊúÄÈÅ©Âåñ
    ard_num_dims=None  # Automatic Relevance Determination
))

# Matern„Ç´„Éº„Éç„É´ÔºàÊªë„Çâ„Åã„ÅïË™øÊï¥ÂèØËÉΩÔºâ
kernel_matern = ScaleKernel(MaternKernel(
    nu=2.5,  # Êªë„Çâ„Åã„Åï„Éë„É©„É°„Éº„ÇøÔºà1.5, 2.5, „Åæ„Åü„ÅØ infÔºàRBF„Å®ÂêåÁ≠âÔºâÔºâ
    ard_num_dims=None
))

print(&quot;Áí∞Â¢ÉË®≠ÂÆöÂÆå‰∫Ü&quot;)
print(f&quot;NumPy version: {np.__version__}&quot;)
print(f&quot;PyTorch version: {torch.__version__}&quot;)
</code></pre>
<p><strong>„Ç§„É≥„Çπ„Éà„Éº„É´ÊâãÈ†Ü</strong>:</p>
<pre><code class="language-bash"># ‰ªÆÊÉ≥Áí∞Â¢É„ÅÆ‰ΩúÊàêÔºàÊé®Â•®Ôºâ
python -m venv bo_env
source bo_env/bin/activate  # Linuxmac
# bo_env\Scripts\activate  # Windows

# ÂøÖÈ†à„Éë„ÉÉ„Ç±„Éº„Ç∏„ÅÆ„Ç§„É≥„Çπ„Éà„Éº„É´
pip install numpy==1.21.0 scikit-learn==1.0.0 scikit-optimize==0.9.0
pip install torch==1.12.0 gpytorch==1.8.0 botorch==0.7.0
pip install matplotlib==3.5.0 pandas==1.3.0 scipy==1.7.0

# „Ç™„Éó„Ç∑„Éß„É≥: Materials Project API
pip install mp-api==0.30.0

# „Ç§„É≥„Çπ„Éà„Éº„É´Á¢∫Ë™ç
python -c &quot;import botorch; print(f'BoTorch {botorch.__version__} installed')&quot;
</code></pre>
<hr />
<h2>Practical Pitfalls Section (add after section 3.7)</h2>
<h3>3.8 ÂÆüË∑µÁöÑ„Å™ËêΩ„Å®„ÅóÁ©¥„Å®ÂØæÂá¶Ê≥ï</h3>
<h4>ËêΩ„Å®„ÅóÁ©¥1: ‰∏çÈÅ©Âàá„Å™„Ç´„Éº„Éç„É´ÈÅ∏Êäû</h4>
<p><strong>ÂïèÈ°å</strong>: „Ç´„Éº„Éç„É´ÈÅ∏Êäû„ÅåÁõÆÁöÑÈñ¢Êï∞„ÅÆÊÄßË≥™„Å®Âêà„Å£„Å¶„ÅÑ„Å™„ÅÑ</p>
<p><strong>ÁóáÁä∂</strong>:
- ‰∫àÊ∏¨Á≤æÂ∫¶„Åå‰Ωé„ÅÑ
- Êé¢Á¥¢ÂäπÁéá„ÅåÊÇ™„ÅÑ
- Â±ÄÊâÄÊúÄÈÅ©„Å´Èô•„Çä„ÇÑ„Åô„ÅÑ</p>
<p><strong>Ëß£Ê±∫Á≠ñ</strong>:</p>
<pre><code class="language-python"># „Ç´„Éº„Éç„É´ÈÅ∏Êäû„Ç¨„Ç§„Éâ
from gpytorch.kernels import RBF, MaternKernel, PeriodicKernel

def select_kernel(problem_characteristics):
    &quot;&quot;&quot;
    ÂïèÈ°å„ÅÆÁâπÊÄß„Å´Âøú„Åò„Åü„Ç´„Éº„Éç„É´ÈÅ∏Êäû

    Parameters:
    -----------
    problem_characteristics : dict
        ÂïèÈ°å„ÅÆÁâπÊÄß„ÇíË®òËø∞„Åô„ÇãËæûÊõ∏
        - 'smoothness': 'smooth' | 'rough'
        - 'periodicity': True | False
        - 'dimensionality': int

    Returns:
    --------
    kernel : gpytorch.kernels.Kernel
        Êé®Â•®„Ç´„Éº„Éç„É´
    &quot;&quot;&quot;
    if problem_characteristics.get('periodicity'):
        # Âë®ÊúüÊÄß„Åå„ÅÇ„ÇãÂ†¥Âêà
        return PeriodicKernel()

    elif problem_characteristics.get('smoothness') == 'smooth':
        # Êªë„Çâ„Åã„Å™Èñ¢Êï∞ÔºàÊùêÊñôÁâ©ÊÄß„Å™„Å©Ôºâ
        return RBF()

    elif problem_characteristics.get('smoothness') == 'rough':
        # „Éé„Ç§„Ç∫„ÇÑ‰∏çÈÄ£Á∂öÊÄß„Åå„ÅÇ„Çã
        return MaternKernel(nu=1.5)

    else:
        # „Éá„Éï„Ç©„É´„Éà: Matern 5/2ÔºàÊ±éÁî®ÊÄßÈ´ò„ÅÑÔºâ
        return MaternKernel(nu=2.5)

# ‰ΩøÁî®‰æã
problem_specs = {
    'smoothness': 'smooth',
    'periodicity': False,
    'dimensionality': 4
}

recommended_kernel = select_kernel(problem_specs)
print(f&quot;Êé®Â•®„Ç´„Éº„Éç„É´: {recommended_kernel}&quot;)
</code></pre>
<p><strong>„Ç´„Éº„Éç„É´ÊØîËºÉÂÆüÈ®ì</strong>:</p>
<pre><code class="language-python">import numpy as np
import matplotlib.pyplot as plt
from sklearn.gaussian_process import GaussianProcessRegressor
from sklearn.gaussian_process.kernels import RBF, Matern

# „ÉÜ„Çπ„ÉàÈñ¢Êï∞
def test_function(x):
    &quot;&quot;&quot;„Éé„Ç§„Ç∫„ÅÆ„ÅÇ„ÇãË§áÈõë„Å™Èñ¢Êï∞&quot;&quot;&quot;
    return np.sin(5*x) + 0.5*np.cos(15*x) + 0.1*np.random.randn(len(x))

# „Éá„Éº„ÇøÁîüÊàê
np.random.seed(42)
X_train = np.random.uniform(0, 1, 20).reshape(-1, 1)
y_train = test_function(X_train.ravel())

X_test = np.linspace(0, 1, 200).reshape(-1, 1)
y_true = test_function(X_test.ravel())

# Áï∞„Å™„Çã„Ç´„Éº„Éç„É´„ÅßÊØîËºÉ
kernels = {
    'RBF': RBF(length_scale=0.1),
    'Matern 1.5': Matern(length_scale=0.1, nu=1.5),
    'Matern 2.5': Matern(length_scale=0.1, nu=2.5)
}

fig, axes = plt.subplots(1, 3, figsize=(15, 4))

for ax, (name, kernel) in zip(axes, kernels.items()):
    gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10)
    gp.fit(X_train, y_train)
    y_pred, y_std = gp.predict(X_test, return_std=True)

    ax.scatter(X_train, y_train, c='red', label='Ë®ìÁ∑¥„Éá„Éº„Çø')
    ax.plot(X_test, y_pred, 'b-', label='‰∫àÊ∏¨')
    ax.fill_between(X_test.ravel(), y_pred - 2*y_std, y_pred + 2*y_std,
                     alpha=0.3, color='blue')
    ax.set_title(f'„Ç´„Éº„Éç„É´: {name}')
    ax.legend()
    ax.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('kernel_comparison.png', dpi=150)
plt.show()

print(&quot;ÁµêË´ñ:&quot;)
print(&quot;  RBF: Êªë„Çâ„Åã„Å™Èñ¢Êï∞„Å´ÊúÄÈÅ©&quot;)
print(&quot;  Matern 1.5: „Éé„Ç§„Ç∫ËÄêÊÄß„ÅåÈ´ò„ÅÑ&quot;)
print(&quot;  Matern 2.5: „Éê„É©„É≥„Çπ„ÅåËâØ„ÅÑÔºàÊé®Â•®Ôºâ&quot;)
</code></pre>
<hr />
<h4>ËêΩ„Å®„ÅóÁ©¥2: ÂàùÊúüÂåñÊà¶Áï•„ÅÆÂ§±Êïó</h4>
<p><strong>ÂïèÈ°å</strong>: ÂàùÊúü„Çµ„É≥„Éó„É™„É≥„Ç∞„ÅåÊé¢Á¥¢Á©∫Èñì„ÇíÂçÅÂàÜ„Ç´„Éê„Éº„Åó„Å¶„ÅÑ„Å™„ÅÑ</p>
<p><strong>ÁóáÁä∂</strong>:
- Êé¢Á¥¢„ÅåÂÅè„Çã
- ÈáçË¶Å„Å™È†òÂüü„ÇíË¶ãÈÄÉ„Åô
- ÂèéÊùü„ÅåÈÅÖ„ÅÑ</p>
<p><strong>Ëß£Ê±∫Á≠ñ</strong>: „É©„ÉÜ„É≥Ë∂ÖÊñπÊ†º„Çµ„É≥„Éó„É™„É≥„Ç∞ÔºàLHSÔºâ</p>
<pre><code class="language-python">from scipy.stats.qmc import LatinHypercube

def initialize_with_lhs(n_samples, bounds, seed=42):
    &quot;&quot;&quot;
    „É©„ÉÜ„É≥Ë∂ÖÊñπÊ†º„Çµ„É≥„Éó„É™„É≥„Ç∞„ÅßÂàùÊúüÁÇπ„ÇíÁîüÊàê

    Parameters:
    -----------
    n_samples : int
        „Çµ„É≥„Éó„É´Êï∞
    bounds : array (n_dims, 2)
        ÂêÑÊ¨°ÂÖÉ„ÅÆ [lower, upper] Â¢ÉÁïå
    seed : int
        ‰π±Êï∞„Ç∑„Éº„Éâ

    Returns:
    --------
    X_init : array (n_samples, n_dims)
        ÂàùÊúü„Çµ„É≥„Éó„É™„É≥„Ç∞ÁÇπ
    &quot;&quot;&quot;
    bounds = np.array(bounds)
    n_dims = len(bounds)

    # LHS„Çµ„É≥„Éó„É©„Éº
    sampler = LatinHypercube(d=n_dims, seed=seed)
    X_unit = sampler.random(n=n_samples)

    # „Çπ„Ç±„Éº„É™„É≥„Ç∞
    X_init = bounds[:, 0] + (bounds[:, 1] - bounds[:, 0]) * X_unit

    return X_init

# ‰ΩøÁî®‰æã: Li-ionÈõªÊ±†ÁµÑÊàê„ÅÆÂàùÊúüÂåñ
bounds_composition = [
    [0.1, 0.5],  # Li
    [0.1, 0.4],  # Ni
    [0.1, 0.3],  # Co
    [0.0, 0.5]   # Mn
]

X_init_lhs = initialize_with_lhs(
    n_samples=20,
    bounds=bounds_composition,
    seed=42
)

# ÁµÑÊàêÊ≠£Ë¶èÂåñ
X_init_lhs = X_init_lhs / X_init_lhs.sum(axis=1, keepdims=True)

print(&quot;LHSÂàùÊúüÂåñÂÆå‰∫Ü&quot;)
print(f&quot;ÂàùÊúü„Çµ„É≥„Éó„É´Êï∞: {len(X_init_lhs)}&quot;)
print(f&quot;ÂêÑÊ¨°ÂÖÉ„ÅÆ„Ç´„Éê„ÉºÁØÑÂõ≤:&quot;)
for i, dim_name in enumerate(['Li', 'Ni', 'Co', 'Mn']):
    print(f&quot;  {dim_name}: [{X_init_lhs[:, i].min():.3f}, &quot;
          f&quot;{X_init_lhs[:, i].max():.3f}]&quot;)

# „É©„É≥„ÉÄ„É†„Çµ„É≥„Éó„É™„É≥„Ç∞„Å®„ÅÆÊØîËºÉÂèØË¶ñÂåñ
fig, axes = plt.subplots(1, 2, figsize=(12, 5))

# „É©„É≥„ÉÄ„É†„Çµ„É≥„Éó„É™„É≥„Ç∞
np.random.seed(42)
X_random = np.random.uniform(0, 1, (20, 2))

axes[0].scatter(X_random[:, 0], X_random[:, 1], s=100)
axes[0].set_title('„É©„É≥„ÉÄ„É†„Çµ„É≥„Éó„É™„É≥„Ç∞')
axes[0].set_xlabel('Ê¨°ÂÖÉ1')
axes[0].set_ylabel('Ê¨°ÂÖÉ2')
axes[0].grid(True, alpha=0.3)

# LHS
axes[1].scatter(X_init_lhs[:, 0], X_init_lhs[:, 1], s=100, c='red')
axes[1].set_title('„É©„ÉÜ„É≥Ë∂ÖÊñπÊ†º„Çµ„É≥„Éó„É™„É≥„Ç∞ÔºàLHSÔºâ')
axes[1].set_xlabel('Ê¨°ÂÖÉ1 (Li)')
axes[1].set_ylabel('Ê¨°ÂÖÉ2 (Ni)')
axes[1].grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('lhs_vs_random.png', dpi=150)
plt.show()
</code></pre>
<hr />
<h4>ËêΩ„Å®„ÅóÁ©¥3: „Éé„Ç§„Ç∫„ÅÆ„ÅÇ„ÇãË¶≥Ê∏¨„Å∏„ÅÆÂØæÂøú‰∏çË∂≥</h4>
<p><strong>ÂïèÈ°å</strong>: ÂÆüÈ®ì„Éé„Ç§„Ç∫„ÇíËÄÉÊÖÆ„Åó„Å¶„ÅÑ„Å™„ÅÑ</p>
<p><strong>ÁóáÁä∂</strong>:
- Âêå„ÅòÊù°‰ª∂„ÅßÁµêÊûú„ÅåÂÜçÁèæ„Åó„Å™„ÅÑ
- „É¢„Éá„É´„ÅåÈÅéÂ≠¶Áøí„Åô„Çã
- ÊúÄÈÅ©ÁÇπ„Åå‰∏çÂÆâÂÆö</p>
<p><strong>Ëß£Ê±∫Á≠ñ</strong>: „Éé„Ç§„Ç∫„ÇíÊòéÁ§∫ÁöÑ„Å´„É¢„Éá„É´Âåñ</p>
<pre><code class="language-python">import torch
from botorch.models import SingleTaskGP
from gpytorch.mlls import ExactMarginalLogLikelihood

def fit_gp_with_noise(X, y, noise_variance=0.01):
    &quot;&quot;&quot;
    „Éé„Ç§„Ç∫„ÇíËÄÉÊÖÆ„Åó„Åü„Ç¨„Ç¶„ÇπÈÅéÁ®ã„ÅÆÂ≠¶Áøí

    Parameters:
    -----------
    X : Tensor (n, d)
        ÂÖ•Âäõ„Éá„Éº„Çø
    y : Tensor (n, 1)
        Ë¶≥Ê∏¨ÂÄ§Ôºà„Éé„Ç§„Ç∫Âê´„ÇÄÔºâ
    noise_variance : float
        Ë¶≥Ê∏¨„Éé„Ç§„Ç∫„ÅÆÂàÜÊï£Ôºà‰∫ãÂâçÁü•Ë≠ò„Åã„ÇâË®≠ÂÆöÔºâ

    Returns:
    --------
    gp_model : SingleTaskGP
        Â≠¶ÁøíÊ∏à„ÅøGP„É¢„Éá„É´
    &quot;&quot;&quot;
    # „Éé„Ç§„Ç∫ÂàÜÊï£„ÇíË®≠ÂÆö„Åó„Å¶GPÊßãÁØâ
    gp_model = SingleTaskGP(X, y, train_Yvar=torch.full_like(y, noise_variance))

    # Â∞§Â∫¶ÊúÄÂ§ßÂåñ
    mll = ExactMarginalLogLikelihood(gp_model.likelihood, gp_model)
    from botorch.fit import fit_gpytorch_model
    fit_gpytorch_model(mll)

    return gp_model

# ‰ΩøÁî®‰æã: „Éé„Ç§„Ç∫„ÅÆ„ÅÇ„ÇãÂÆüÈ®ì„Éá„Éº„Çø
np.random.seed(42)
X_obs = np.random.rand(15, 4)
X_obs = X_obs / X_obs.sum(axis=1, keepdims=True)

# Áúü„ÅÆÂÆπÈáè + ÂÆüÈ®ì„Éé„Ç§„Ç∫
y_true = 200 + 150 * X_obs[:, 0] + 50 * X_obs[:, 1]
noise = np.random.randn(15) * 10  # ÂÆüÈ®ì„Éé„Ç§„Ç∫ œÉ=10 mAh/g
y_obs = y_true + noise

# PyTorch„ÉÜ„É≥„ÇΩ„É´„Å´Â§âÊèõ
X_tensor = torch.tensor(X_obs, dtype=torch.float64)
y_tensor = torch.tensor(y_obs, dtype=torch.float64).unsqueeze(-1)

# „Éé„Ç§„Ç∫„ÇíËÄÉÊÖÆ„Åó„Å¶GPÂ≠¶Áøí
gp_noisy = fit_gp_with_noise(X_tensor, y_tensor, noise_variance=100.0)

print(&quot;„Éé„Ç§„Ç∫„ÇíËÄÉÊÖÆ„Åó„ÅüGPÂ≠¶ÁøíÂÆå‰∫Ü&quot;)
print(f&quot;Ë¶≥Ê∏¨„Éé„Ç§„Ç∫Ê®ôÊ∫ñÂÅèÂ∑Æ: 10 mAh/g&quot;)
print(f&quot;„É¢„Éá„É´Âåñ„Éé„Ç§„Ç∫ÂàÜÊï£: 100.0 (mAh/g)¬≤&quot;)
</code></pre>
<p><strong>„Éé„Ç§„Ç∫„É¨„Éô„É´„ÅÆÊé®ÂÆö</strong>:</p>
<pre><code class="language-python">def estimate_noise_level(X, y, n_replicates=3):
    &quot;&quot;&quot;
    Ë§áË£ΩÂÆüÈ®ì„Åã„Çâ„Éé„Ç§„Ç∫„É¨„Éô„É´„ÇíÊé®ÂÆö

    Parameters:
    -----------
    X : array (n, d)
        ÂÆüÈ®ìÊù°‰ª∂
    y : array (n,)
        Ë¶≥Ê∏¨ÂÄ§
    n_replicates : int
        ÂêÑÊù°‰ª∂„Åß„ÅÆË§áË£ΩÂÆüÈ®ìÊï∞

    Returns:
    --------
    noise_std : float
        Êé®ÂÆö„Éé„Ç§„Ç∫Ê®ôÊ∫ñÂÅèÂ∑Æ
    &quot;&quot;&quot;
    # Âêå‰∏ÄÊù°‰ª∂„ÅÆË§áË£ΩÂÆüÈ®ì„ÇíÊäΩÂá∫
    unique_X, indices = np.unique(X, axis=0, return_inverse=True)

    variances = []
    for i in range(len(unique_X)):
        replicates = y[indices == i]
        if len(replicates) &gt;= 2:
            variances.append(np.var(replicates, ddof=1))

    if len(variances) == 0:
        print(&quot;Ë≠¶Âëä: Ë§áË£ΩÂÆüÈ®ì„Åå„ÅÇ„Çä„Åæ„Åõ„Çì„ÄÇ„Éá„Éï„Ç©„É´„ÉàÂÄ§„Çí‰ΩøÁî®&quot;)
        return 1.0

    noise_std = np.sqrt(np.mean(variances))
    return noise_std

# ‰ΩøÁî®‰æã
noise_std_estimated = estimate_noise_level(X_obs, y_obs)
print(f&quot;Êé®ÂÆö„Éé„Ç§„Ç∫Ê®ôÊ∫ñÂÅèÂ∑Æ: {noise_std_estimated:.2f} mAh/g&quot;)
</code></pre>
<hr />
<h4>ËêΩ„Å®„ÅóÁ©¥4: Âà∂Á¥ÑÂá¶ÁêÜ„ÅÆ‰∏çÂÇô</h4>
<p><strong>ÂïèÈ°å</strong>: Âà∂Á¥ÑÈÅïÂèç„ÇíÈÅ©Âàá„Å´Êâ±„Å£„Å¶„ÅÑ„Å™„ÅÑ</p>
<p><strong>ÁóáÁä∂</strong>:
- ÂÆüË°å‰∏çÂèØËÉΩ„Å™ÊùêÊñô„ÇíÊèêÊ°à
- ÊúÄÈÅ©Âåñ„ÅåÂèéÊùü„Åó„Å™„ÅÑ
- ÁÑ°ÈßÑ„Å™ÂÆüÈ®ì„ÅåÂ§ö„ÅÑ</p>
<p><strong>Ëß£Ê±∫Á≠ñ</strong>: Âà∂Á¥Ñ‰ªò„ÅçÁç≤ÂæóÈñ¢Êï∞</p>
<pre><code class="language-python">from botorch.acquisition import ConstrainedExpectedImprovement

def constrained_bayesian_optimization_example():
    &quot;&quot;&quot;
    Âà∂Á¥Ñ‰ªò„Åç„Éô„Ç§„Ç∫ÊúÄÈÅ©Âåñ„ÅÆÂÆüË£Ö‰æã

    Âà∂Á¥Ñ:
    1. ÁµÑÊàê„ÅÆÂêàË®à = 1.0 (¬±2%)
    2. CoÂê´Èáè &lt; 0.3 („Ç≥„Çπ„ÉàÂà∂Á¥Ñ)
    3. ÂÆâÂÆöÊÄß: formation energy &lt; -1.5 eV/atom
    &quot;&quot;&quot;
    # ÂàùÊúü„Éá„Éº„Çø
    n_initial = 10
    X_init = initialize_with_lhs(n_initial, bounds_composition, seed=42)
    X_init = X_init / X_init.sum(axis=1, keepdims=True)  # Ê≠£Ë¶èÂåñ

    # ÁõÆÁöÑÈñ¢Êï∞„Å®Âà∂Á¥Ñ„ÅÆË©ï‰æ°
    y_capacity = []
    constraints_satisfied = []

    for x in X_init:
        # ÂÆπÈáè‰∫àÊ∏¨ÔºàÁõÆÁöÑÈñ¢Êï∞Ôºâ
        capacity = 200 + 150*x[0] + 50*x[1]
        y_capacity.append(capacity)

        # Âà∂Á¥Ñ„ÉÅ„Çß„ÉÉ„ÇØ
        co_constraint = x[2] &lt; 0.3  # Co &lt; 0.3
        stability = -2.0 - 0.5*x[0] - 0.3*x[1]
        stability_constraint = stability &lt; -1.5  # ÂÆâÂÆö

        all_satisfied = co_constraint and stability_constraint
        constraints_satisfied.append(1.0 if all_satisfied else 0.0)

    X_tensor = torch.tensor(X_init, dtype=torch.float64)
    y_tensor = torch.tensor(y_capacity, dtype=torch.float64).unsqueeze(-1)
    c_tensor = torch.tensor(constraints_satisfied, dtype=torch.float64).unsqueeze(-1)

    # „Ç¨„Ç¶„ÇπÈÅéÁ®ã„É¢„Éá„É´ÔºàÁõÆÁöÑÈñ¢Êï∞Ôºâ
    gp_objective = SingleTaskGP(X_tensor, y_tensor)
    mll_obj = ExactMarginalLogLikelihood(gp_objective.likelihood, gp_objective)
    from botorch.fit import fit_gpytorch_model
    fit_gpytorch_model(mll_obj)

    # „Ç¨„Ç¶„ÇπÈÅéÁ®ã„É¢„Éá„É´ÔºàÂà∂Á¥ÑÔºâ
    gp_constraint = SingleTaskGP(X_tensor, c_tensor)
    mll_con = ExactMarginalLogLikelihood(gp_constraint.likelihood, gp_constraint)
    fit_gpytorch_model(mll_con)

    # Âà∂Á¥Ñ‰ªò„ÅçEIÁç≤ÂæóÈñ¢Êï∞
    best_f = y_tensor.max()
    acq_func = ConstrainedExpectedImprovement(
        model=gp_objective,
        best_f=best_f,
        objective_index=0,
        constraints={0: [None, 0.5]}  # Âà∂Á¥ÑÊ∫ÄË∂≥Á¢∫Áéá &gt; 0.5
    )

    print(&quot;Âà∂Á¥Ñ‰ªò„Åç„Éô„Ç§„Ç∫ÊúÄÈÅ©Âåñ„Çª„ÉÉ„Éà„Ç¢„ÉÉ„ÉóÂÆå‰∫Ü&quot;)
    print(f&quot;ÂàùÊúüÂÆüË°åÂèØËÉΩËß£: {sum(constraints_satisfied)}/{n_initial}&quot;)

    return gp_objective, gp_constraint, acq_func

# ÂÆüË°å
gp_obj, gp_con, acq = constrained_bayesian_optimization_example()
</code></pre>
<hr />
<h2>End-of-Chapter Checklist (add before "ÊºîÁøíÂïèÈ°å")</h2>
<h3>3.9 Á´†Êú´„ÉÅ„Çß„ÉÉ„ÇØ„É™„Çπ„Éà</h3>
<h4>‚úÖ „Ç¨„Ç¶„ÇπÈÅéÁ®ã„ÅÆÁêÜËß£</h4>
<ul>
<li>[ ] „Ç¨„Ç¶„ÇπÈÅéÁ®ã„ÅÆÂü∫Êú¨Ê¶ÇÂøµ„ÇíË™¨Êòé„Åß„Åç„Çã</li>
<li>[ ] „Ç´„Éº„Éç„É´Èñ¢Êï∞„ÅÆÂΩπÂâ≤„ÇíÁêÜËß£„Åó„Å¶„ÅÑ„Çã</li>
<li>[ ] ‰∫àÊ∏¨Âπ≥Âùá„Å®‰∏çÁ¢∫ÂÆüÊÄß„ÅÆÊÑèÂë≥„ÇíÁü•„Å£„Å¶„ÅÑ„Çã</li>
<li>[ ] ÈÅ©Âàá„Å™„Ç´„Éº„Éç„É´„ÇíÈÅ∏Êäû„Åß„Åç„Çã</li>
<li>[ ] „Éè„Ç§„Éë„Éº„Éë„É©„É°„Éº„Çø„ÅÆÂΩ±Èüø„ÇíË™¨Êòé„Åß„Åç„Çã</li>
</ul>
<p><strong>Á¢∫Ë™çÂïèÈ°å</strong>:</p>
<pre><code>Q: RBF„Ç´„Éº„Éç„É´„Å®Matern„Ç´„Éº„Éç„É´„ÅÆÈÅï„ÅÑ„ÅØ‰Ωï„Åß„Åô„ÅãÔºü
A: RBF„ÅØÁÑ°ÈôêÂõûÂæÆÂàÜÂèØËÉΩÔºàÈùûÂ∏∏„Å´Êªë„Çâ„ÅãÔºâ„ÄÅMatern„ÅØ„Éë„É©„É°„Éº„ÇøŒΩ„Åß
   Êªë„Çâ„Åã„Åï„ÇíË™øÊï¥ÂèØËÉΩ„ÄÇ„Éé„Ç§„Ç∫„Åå„ÅÇ„ÇãÂ†¥Âêà„ÅØMatern (ŒΩ=2.5) „ÅåÊé®Â•®„ÄÇ
</code></pre>
<hr />
<h4>‚úÖ Áç≤ÂæóÈñ¢Êï∞„ÅÆÈÅ∏Êäû</h4>
<ul>
<li>[ ] Expected Improvement (EI) „ÅÆ‰ªïÁµÑ„Åø„ÇíÁêÜËß£„Åó„Å¶„ÅÑ„Çã</li>
<li>[ ] Upper Confidence Bound (UCB) „ÅÆÊé¢Á¥¢„ÉªÊ¥ªÁî®„Éê„É©„É≥„Çπ„ÇíË™¨Êòé„Åß„Åç„Çã</li>
<li>[ ] Probability of Improvement (PI) „ÅÆÁâπÊÄß„ÇíÁü•„Å£„Å¶„ÅÑ„Çã</li>
<li>[ ] Knowledge Gradient (KG) „ÅÆÈÅ©Áî®Â†¥Èù¢„ÇíÁêÜËß£„Åó„Å¶„ÅÑ„Çã</li>
<li>[ ] ÂïèÈ°å„Å´Âøú„Åò„Å¶Áç≤ÂæóÈñ¢Êï∞„ÇíÈÅ∏Êäû„Åß„Åç„Çã</li>
</ul>
<p><strong>ÈÅ∏Êäû„Ç¨„Ç§„Éâ</strong>:</p>
<pre><code>‰∏ÄËà¨ÁöÑ„Å™ÊúÄÈÅ©Âåñ     ‚Üí EI („Éê„É©„É≥„ÇπËâØ„ÅÑ)
Êé¢Á¥¢ÈáçË¶ñ„ÅÆÂàùÊúü     ‚Üí UCB (Œ∫=2~3)
ÂÆâÂÖ®ÈáçË¶ñ          ‚Üí PI (‰øùÂÆàÁöÑ)
„Éê„ÉÉ„ÉÅÊúÄÈÅ©Âåñ      ‚Üí q-EI, q-KG
Â§öÁõÆÁöÑÊúÄÈÅ©Âåñ      ‚Üí EHVI (Hypervolume)
</code></pre>
<hr />
<h4>‚úÖ Â§öÁõÆÁöÑÊúÄÈÅ©Âåñ</h4>
<ul>
<li>[ ] ParetoÊúÄÈÅ©„ÅÆÂÆöÁæ©„ÇíË™¨Êòé„Åß„Åç„Çã</li>
<li>[ ] Pareto„Éï„É≠„É≥„ÉÜ„Ç£„Ç¢„ÅÆÊÑèÂë≥„ÇíÁêÜËß£„Åó„Å¶„ÅÑ„Çã</li>
<li>[ ] Expected Hypervolume Improvement (EHVI) „ÅÆ‰ªïÁµÑ„Åø„ÇíÁü•„Å£„Å¶„ÅÑ„Çã</li>
<li>[ ] „Éà„É¨„Éº„Éâ„Ç™„Éï„ÇíÂÆöÈáèÁöÑ„Å´Ë©ï‰æ°„Åß„Åç„Çã</li>
<li>[ ] Â§öÁõÆÁöÑÊúÄÈÅ©Âåñ„ÇíÂÆüË£Ö„Åß„Åç„Çã</li>
</ul>
<p><strong>ÂÆüË£Ö„ÉÅ„Çß„ÉÉ„ÇØ</strong>:</p>
<pre><code class="language-python"># ‰ª•‰∏ã„ÇíÂÆüË£Ö„Åß„Åç„Åæ„Åô„ÅãÔºü
def is_pareto_optimal(objectives):
    &quot;&quot;&quot;
    ParetoÊúÄÈÅ©Ëß£„ÇíÂà§ÂÆö„Åô„ÇãÈñ¢Êï∞
    objectives: (n_points, n_objectives)
    &quot;&quot;&quot;
    # „ÅÇ„Å™„Åü„ÅÆÂÆüË£Ö
    pass

# Ê≠£Ëß£„ÅØÊºîÁøíÂïèÈ°å3„ÇíÂèÇÁÖß
</code></pre>
<hr />
<h4>‚úÖ „Éê„ÉÉ„ÉÅ„Éô„Ç§„Ç∫ÊúÄÈÅ©Âåñ</h4>
<ul>
<li>[ ] „Éê„ÉÉ„ÉÅÊúÄÈÅ©Âåñ„ÅÆÂà©ÁÇπ„ÇíË™¨Êòé„Åß„Åç„Çã</li>
<li>[ ] q-EIÁç≤ÂæóÈñ¢Êï∞„ÅÆ‰ªïÁµÑ„Åø„ÇíÁêÜËß£„Åó„Å¶„ÅÑ„Çã</li>
<li>[ ] Kriging BelieverÊ≥ï„ÇíÁü•„Å£„Å¶„ÅÑ„Çã</li>
<li>[ ] ‰∏¶ÂàóÂÆüÈ®ì„ÅÆÂäπÁéáÂåñÊà¶Áï•„ÇíÁ´ã„Å¶„Çâ„Çå„Çã</li>
<li>[ ] „Éê„ÉÉ„ÉÅ„Çµ„Ç§„Ç∫„ÅÆÈÅ∏ÊäûÂü∫Ê∫ñ„ÇíÁêÜËß£„Åó„Å¶„ÅÑ„Çã</li>
</ul>
<p><strong>„Éê„ÉÉ„ÉÅ„Çµ„Ç§„Ç∫ÈÅ∏Êäû</strong>:</p>
<pre><code>ÂÆüÈ®ìË£ÖÁΩÆÊï∞: nÂè∞
‚Üí „Éê„ÉÉ„ÉÅ„Çµ„Ç§„Ç∫: nÔºàÊúÄÂ§ßÊ¥ªÁî®Ôºâ

Ë®àÁÆó„Ç≥„Çπ„ÉàÂà∂Á¥Ñ„ÅÇ„Çä
‚Üí „Éê„ÉÉ„ÉÅ„Çµ„Ç§„Ç∫: 3~5ÔºàÂÆüÁî®ÁöÑÔºâ

Êé¢Á¥¢ÂàùÊúü
‚Üí „Éê„ÉÉ„ÉÅ„Çµ„Ç§„Ç∫: Â§ß„Åç„ÇÅÔºàÂ§öÊßòÊÄßÈáçË¶ñÔºâ

ÂèéÊùüÊúü
‚Üí „Éê„ÉÉ„ÉÅ„Çµ„Ç§„Ç∫: Â∞è„Åï„ÇÅÔºàÁ≤æÂØÜÂåñÔºâ
</code></pre>
<hr />
<h4>‚úÖ Âà∂Á¥ÑÂá¶ÁêÜ</h4>
<ul>
<li>[ ] Âà∂Á¥Ñ„ÅÆÁ®ÆÈ°ûÔºàÁ≠âÂºè„ÄÅ‰∏çÁ≠âÂºèÔºâ„ÇíÂå∫Âà•„Åß„Åç„Çã</li>
<li>[ ] ÂÆüË°åÂèØËÉΩÈ†òÂüü„ÅÆÊ¶ÇÂøµ„ÇíÁêÜËß£„Åó„Å¶„ÅÑ„Çã</li>
<li>[ ] Âà∂Á¥Ñ‰ªò„ÅçÁç≤ÂæóÈñ¢Êï∞„ÇíÂÆüË£Ö„Åß„Åç„Çã</li>
<li>[ ] ÂÆüË°åÂèØËÉΩÁ¢∫Áéá„ÇíË®àÁÆó„Åß„Åç„Çã</li>
<li>[ ] ÊÆµÈöéÁöÑÂà∂Á¥ÑÁ∑©Âíå„ÅÆÊà¶Áï•„ÇíÁü•„Å£„Å¶„ÅÑ„Çã</li>
</ul>
<p><strong>Âà∂Á¥ÑÂá¶ÁêÜ„ÉÅ„Çß„ÉÉ„ÇØ„É™„Çπ„Éà</strong>:</p>
<pre><code>‚ñ° ÁµÑÊàêÂà∂Á¥ÑÔºàÂêàË®à=1.0Ôºâ„ÇíÊ≠£Ë¶èÂåñ„ÅßÂá¶ÁêÜ
‚ñ° Â¢ÉÁïåÂà∂Á¥Ñ„Çíbounds„Éë„É©„É°„Éº„Çø„ÅßË®≠ÂÆö
‚ñ° ÈùûÁ∑öÂΩ¢Âà∂Á¥Ñ„Çí„Éö„Éä„É´„ÉÜ„Ç£Èñ¢Êï∞„ÅßË°®Áèæ
‚ñ° ÂÆüË°åÂèØËÉΩËß£„ÅåË¶ã„Å§„Åã„Çâ„Å™„ÅÑÂ†¥Âêà„ÅÆÂØæÂá¶Ê≥ï„ÇíÊ∫ñÂÇô
‚ñ° Âà∂Á¥ÑÊ∫ÄË∂≥Á¢∫Áéá„ÇíÂèØË¶ñÂåñ
</code></pre>
<hr />
<h4>‚úÖ ÂÆüË£Ö„Çπ„Ç≠„É´ÔºàGPyTorch/BoTorchÔºâ</h4>
<ul>
<li>[ ] SingleTaskGP„É¢„Éá„É´„ÇíÊßãÁØâ„Åß„Åç„Çã</li>
<li>[ ] „Ç´„Éº„Éç„É´„ÇíÈÅ©Âàá„Å´ÈÅ∏Êäû„ÉªË®≠ÂÆö„Åß„Åç„Çã</li>
<li>[ ] Áç≤ÂæóÈñ¢Êï∞„ÇíÊúÄÈÅ©Âåñ„Åß„Åç„Çã</li>
<li>[ ] „Éê„ÉÉ„ÉÅÊúÄÈÅ©Âåñ„ÇíÂÆüË£Ö„Åß„Åç„Çã</li>
<li>[ ] „Éé„Ç§„Ç∫„ÇíËÄÉÊÖÆ„Åó„Åü„É¢„Éá„É™„É≥„Ç∞„Åå„Åß„Åç„Çã</li>
</ul>
<p><strong>„Ç≥„Éº„ÉâÂÆüË£ÖÁ¢∫Ë™ç</strong>:</p>
<pre><code class="language-python"># „Åì„ÅÆ„Ç≥„Éº„Éâ„ÅåÁêÜËß£„Åß„Åç„Åæ„Åô„ÅãÔºü
from botorch.models import SingleTaskGP
from botorch.fit import fit_gpytorch_model
from gpytorch.mlls import ExactMarginalLogLikelihood
from botorch.acquisition import ExpectedImprovement
from botorch.optim import optimize_acqf

# GP„É¢„Éá„É´ÊßãÁØâ
gp = SingleTaskGP(X_train, y_train)
mll = ExactMarginalLogLikelihood(gp.likelihood, gp)
fit_gpytorch_model(mll)

# EIÊúÄÂ§ßÂåñ
EI = ExpectedImprovement(gp, best_f=y_train.max())
candidate, acq_value = optimize_acqf(
    EI, bounds=bounds, q=1, num_restarts=10
)

# ÂêÑË°å„ÅÆÊÑèÂë≥„ÇíË™¨Êòé„Åß„Åç„Åæ„Åô„ÅãÔºü
</code></pre>
<hr />
<h4>‚úÖ ÂÆüÈ®ìË®≠Ë®à„Å®„ÅÆÁµ±Âêà</h4>
<ul>
<li>[ ] Materials Project„Å™„Å©ÂÆü„Éá„Éº„Çø„ÇΩ„Éº„Çπ„ÇíÊ¥ªÁî®„Åß„Åç„Çã</li>
<li>[ ] ML„É¢„Éá„É´„Å®„Éô„Ç§„Ç∫ÊúÄÈÅ©Âåñ„ÇíÁµ±Âêà„Åß„Åç„Çã</li>
<li>[ ] ÂÆüÈ®ìË®àÁîª„ÇíÁ´ã„Å¶„Çâ„Çå„Çã</li>
<li>[ ] ÁµêÊûú„ÇíÂèØË¶ñÂåñ„ÉªËß£Èáà„Åß„Åç„Çã</li>
<li>[ ] ROI„ÇíË©ï‰æ°„Åß„Åç„Çã</li>
</ul>
<p><strong>ÂÆüÈ®ìË®àÁîª„ÉÜ„É≥„Éó„É¨„Éº„Éà</strong>:</p>
<pre><code>1. ÁõÆÁöÑË®≠ÂÆö
   - ÊúÄÈÅ©Âåñ„Åô„ÇãÁâπÊÄß: ________
   - Âà∂Á¥ÑÊù°‰ª∂: ________
   - ÂÆüÈ®ì‰∫àÁÆó: ________ Âõû

2. ÂàùÊúüÂåñ
   - ÂàùÊúü„Çµ„É≥„Éó„É´Êï∞: ________
   - „Çµ„É≥„Éó„É™„É≥„Ç∞Ê≥ï: LHS / Random
   - ‰∫àÊÉ≥ÂÆüÈ®ìÊúüÈñì: ________

3. ÊúÄÈÅ©ÂåñÊà¶Áï•
   - Áç≤ÂæóÈñ¢Êï∞: ________
   - „Ç´„Éº„Éç„É´: ________
   - „Éê„ÉÉ„ÉÅ„Çµ„Ç§„Ç∫: ________

4. ÁµÇ‰∫ÜÊù°‰ª∂
   - ÊúÄÂ§ßÂÆüÈ®ìÂõûÊï∞: ________
   - ÁõÆÊ®ôÊÄßËÉΩ: ________
   - ÊîπÂñÑÁéáÈñæÂÄ§: ________
</code></pre>
<hr />
<h4>‚úÖ „Éà„É©„Éñ„É´„Ç∑„É•„Éº„ÉÜ„Ç£„É≥„Ç∞</h4>
<ul>
<li>[ ] Â±ÄÊâÄÊúÄÈÅ©„Åã„Çâ„ÅÆËÑ±Âá∫ÊñπÊ≥ï„ÇíÁü•„Å£„Å¶„ÅÑ„Çã</li>
<li>[ ] Âà∂Á¥ÑÈÅïÂèç„Å∏„ÅÆÂØæÂá¶Ê≥ï„ÇíÁêÜËß£„Åó„Å¶„ÅÑ„Çã</li>
<li>[ ] Ë®àÁÆóÊôÇÈñìÂâäÊ∏õ„ÅÆÊâãÊ≥ï„ÇíÁü•„Å£„Å¶„ÅÑ„Çã</li>
<li>[ ] „Éé„Ç§„Ç∫„Å∏„ÅÆÂØæÂá¶Ê≥ï„ÇíÂÆüË£Ö„Åß„Åç„Çã</li>
<li>[ ] „Éá„Éê„ÉÉ„Ç∞ÊñπÊ≥ï„ÇíÁü•„Å£„Å¶„ÅÑ„Çã</li>
</ul>
<p><strong>„Çà„Åè„ÅÇ„Çã„Ç®„É©„Éº„Å®ÂØæÂá¶Ê≥ï</strong>:</p>
<pre><code>„Ç®„É©„Éº: &quot;RuntimeError: cholesky_cpu: U(i,i) is zero&quot;
‚Üí ÂéüÂõ†: Êï∞ÂÄ§‰∏çÂÆâÂÆöÊÄß
‚Üí ÂØæÂá¶: GP„É¢„Éá„É´„Å´jitterËøΩÂä†
   gp = SingleTaskGP(X, y, covar_module=...).double()
   gp.likelihood.noise = 1e-4

„Ç®„É©„Éº: &quot;All points violate constraints&quot;
‚Üí ÂéüÂõ†: Âà∂Á¥Ñ„ÅåÂé≥„Åó„Åô„Åé„Çã
‚Üí ÂØæÂá¶: ÊÆµÈöéÁöÑÂà∂Á¥ÑÁ∑©Âíå„ÄÅÂàùÊúüLHS„Çµ„É≥„Éó„É™„É≥„Ç∞

Ë≠¶Âëä: &quot;Optimization failed to converge&quot;
‚Üí ÂéüÂõ†: Áç≤ÂæóÈñ¢Êï∞ÊúÄÈÅ©Âåñ„ÅÆÂ§±Êïó
‚Üí ÂØæÂá¶: num_restartsÂ¢óÂä†„ÄÅraw_samplesÂ¢óÂä†
</code></pre>
<hr />
<h3>ÂêàÊ†ºÂü∫Ê∫ñ</h3>
<p>ÂêÑ„Çª„ÇØ„Ç∑„Éß„É≥„Åß80%‰ª•‰∏ä„ÅÆ„ÉÅ„Çß„ÉÉ„ÇØÈ†ÖÁõÆ„Çí„ÇØ„É™„Ç¢„Åó„ÄÅ
ÂÆüË£ÖÁ¢∫Ë™ç„Ç≥„Éº„Éâ„ÅåÁêÜËß£„Åß„Åç„Çå„Å∞„ÄÅÊ¨°Á´†„Å∏ÈÄ≤„ÇÄÊ∫ñÂÇôÂÆå‰∫Ü„Åß„Åô„ÄÇ</p>
<p><strong>ÊúÄÁµÇÁ¢∫Ë™çÂïèÈ°å</strong>:
1. Li-ionÈõªÊ±†Ê≠£Ê•µÊùêÊñô„ÅÆÊúÄÈÅ©ÂåñÂïèÈ°å„ÇíÂÆöÂºèÂåñ„Åß„Åç„Åæ„Åô„ÅãÔºü
2. 3ÁõÆÁöÑÔºàÂÆπÈáè„ÄÅÈõªÂúß„ÄÅÂÆâÂÆöÊÄßÔºâ„ÅÆÊúÄÈÅ©Âåñ„ÇíÂÆüË£Ö„Åß„Åç„Åæ„Åô„ÅãÔºü
3. ÂÆüÈ®ìÂõûÊï∞50Âõû„ÅßParetoÊúÄÈÅ©Ëß£10ÂÄã„ÇíË¶ã„Å§„Åë„Çâ„Çå„Åæ„Åô„ÅãÔºü</p>
<p>ÂÖ®„Å¶YES„Å™„Çâ„ÄÅÁ¨¨4Á´†„Äå„Ç¢„ÇØ„ÉÜ„Ç£„Éñ„É©„Éº„Éã„É≥„Ç∞„Å®ÂÆüÈ®ìÈÄ£Êê∫„Äç„Å∏ÈÄ≤„Åø„Åæ„Åó„Çá„ÅÜÔºÅ</p><div class="navigation">
    <a href="chapter-2.html" class="nav-button">‚Üê Ââç„ÅÆÁ´†</a>
    <a href="index.html" class="nav-button">„Ç∑„É™„Éº„Ç∫ÁõÆÊ¨°„Å´Êàª„Çã</a>
    <a href="chapter-4-enhancements.html" class="nav-button">Ê¨°„ÅÆÁ´† ‚Üí</a>
</div>
    </main>

    <footer>
        <p><strong>‰ΩúÊàêËÄÖ</strong>: AI Terakoya Content Team</p>
        <p><strong>„Éê„Éº„Ç∏„Éß„É≥</strong>: 1.0 | <strong>‰ΩúÊàêÊó•</strong>: 2025-10-17</p>
        <p><strong>„É©„Ç§„Çª„É≥„Çπ</strong>: Creative Commons BY 4.0</p>
        <p>¬© 2025 AI Terakoya. All rights reserved.</p>
    </footer>
</body>
</html>
