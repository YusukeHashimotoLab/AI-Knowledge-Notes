<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ç¬¬3ç« ï¼šå®Ÿè·µï¼šææ–™æ¢ç´¢ã¸ã®å¿œç”¨ - AI Terakoya</title>

    <style>
        :root {
            --color-primary: #2c3e50;
            --color-primary-dark: #1a252f;
            --color-accent: #7b2cbf;
            --color-accent-light: #9d4edd;
            --color-text: #2d3748;
            --color-text-light: #4a5568;
            --color-bg: #ffffff;
            --color-bg-alt: #f7fafc;
            --color-border: #e2e8f0;
            --color-code-bg: #f8f9fa;
            --color-link: #3182ce;
            --color-link-hover: #2c5aa0;

            --spacing-xs: 0.5rem;
            --spacing-sm: 1rem;
            --spacing-md: 1.5rem;
            --spacing-lg: 2rem;
            --spacing-xl: 3rem;

            --font-body: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            --font-mono: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;

            --border-radius: 8px;
            --box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: var(--font-body);
            line-height: 1.7;
            color: var(--color-text);
            background-color: var(--color-bg);
            font-size: 16px;
        }

        header {
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            padding: var(--spacing-xl) var(--spacing-md);
            margin-bottom: var(--spacing-xl);
            box-shadow: var(--box-shadow);
        }

        .header-content {
            max-width: 900px;
            margin: 0 auto;
        }

        h1 {
            font-size: 2rem;
            font-weight: 700;
            margin-bottom: var(--spacing-sm);
            line-height: 1.2;
        }

        .subtitle {
            font-size: 1.1rem;
            opacity: 0.95;
            font-weight: 400;
            margin-bottom: var(--spacing-md);
        }

        .meta {
            display: flex;
            flex-wrap: wrap;
            gap: var(--spacing-md);
            font-size: 0.9rem;
            opacity: 0.9;
        }

        .meta-item {
            display: flex;
            align-items: center;
            gap: 0.3rem;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 0 var(--spacing-md) var(--spacing-xl);
        }

        h2 {
            font-size: 1.75rem;
            color: var(--color-primary);
            margin-top: var(--spacing-xl);
            margin-bottom: var(--spacing-md);
            padding-bottom: var(--spacing-xs);
            border-bottom: 3px solid var(--color-accent);
        }

        h3 {
            font-size: 1.4rem;
            color: var(--color-primary);
            margin-top: var(--spacing-lg);
            margin-bottom: var(--spacing-sm);
        }

        h4 {
            font-size: 1.1rem;
            color: var(--color-primary-dark);
            margin-top: var(--spacing-md);
            margin-bottom: var(--spacing-sm);
        }

        p {
            margin-bottom: var(--spacing-md);
            color: var(--color-text);
        }

        a {
            color: var(--color-link);
            text-decoration: none;
            transition: color 0.2s;
        }

        a:hover {
            color: var(--color-link-hover);
            text-decoration: underline;
        }

        ul, ol {
            margin-left: var(--spacing-lg);
            margin-bottom: var(--spacing-md);
        }

        li {
            margin-bottom: var(--spacing-xs);
            color: var(--color-text);
        }

        pre {
            background-color: var(--color-code-bg);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            overflow-x: auto;
            margin-bottom: var(--spacing-md);
            font-family: var(--font-mono);
            font-size: 0.9rem;
            line-height: 1.5;
        }

        code {
            font-family: var(--font-mono);
            font-size: 0.9em;
            background-color: var(--color-code-bg);
            padding: 0.2em 0.4em;
            border-radius: 3px;
        }

        pre code {
            background-color: transparent;
            padding: 0;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: var(--spacing-md);
            font-size: 0.95rem;
        }

        th, td {
            border: 1px solid var(--color-border);
            padding: var(--spacing-sm);
            text-align: left;
        }

        th {
            background-color: var(--color-bg-alt);
            font-weight: 600;
            color: var(--color-primary);
        }

        blockquote {
            border-left: 4px solid var(--color-accent);
            padding-left: var(--spacing-md);
            margin: var(--spacing-md) 0;
            color: var(--color-text-light);
            font-style: italic;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        .mermaid {
            text-align: center;
            margin: var(--spacing-lg) 0;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        details {
            background-color: var(--color-bg-alt);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            margin-bottom: var(--spacing-md);
        }

        summary {
            cursor: pointer;
            font-weight: 600;
            color: var(--color-primary);
            user-select: none;
            padding: var(--spacing-xs);
            margin: calc(-1 * var(--spacing-md));
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        summary:hover {
            background-color: rgba(123, 44, 191, 0.1);
        }

        details[open] summary {
            margin-bottom: var(--spacing-md);
            border-bottom: 1px solid var(--color-border);
        }

        .learning-objectives {
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
            padding: var(--spacing-lg);
            border-radius: var(--border-radius);
            border-left: 4px solid var(--color-accent);
            margin-bottom: var(--spacing-xl);
        }

        .learning-objectives h2 {
            margin-top: 0;
            border-bottom: none;
        }

        .navigation {
            display: flex;
            justify-content: space-between;
            gap: var(--spacing-md);
            margin: var(--spacing-xl) 0;
            padding-top: var(--spacing-lg);
            border-top: 2px solid var(--color-border);
        }

        .nav-button {
            flex: 1;
            padding: var(--spacing-md);
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            border-radius: var(--border-radius);
            text-align: center;
            font-weight: 600;
            transition: transform 0.2s, box-shadow 0.2s;
            box-shadow: var(--box-shadow);
        }

        .nav-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
            text-decoration: none;
        }

        footer {
            margin-top: var(--spacing-xl);
            padding: var(--spacing-lg) var(--spacing-md);
            background-color: var(--color-bg-alt);
            border-top: 1px solid var(--color-border);
            text-align: center;
            font-size: 0.9rem;
            color: var(--color-text-light);
        }
        .disclaimer {
            max-width: 900px;
            margin: 2rem auto;
            padding: 1.5rem;
            background: #f8f9fa;
            border-left: 4px solid #6c757d;
            border-radius: 4px;
        }

        .disclaimer h3 {
            color: #495057;
            margin-bottom: 1rem;
            font-size: 1.1rem;
        }

        .disclaimer ul {
            list-style: none;
            padding-left: 0;
        }

        .disclaimer li {
            padding: 0.5rem 0;
            padding-left: 1.5rem;
            position: relative;
            font-size: 0.9rem;
            color: #6c757d;
            line-height: 1.6;
        }

        .disclaimer li::before {
            content: "âš ï¸";
            position: absolute;
            left: 0;
        }


        @media (max-width: 768px) {
            h1 {
                font-size: 1.5rem;
            }

            h2 {
                font-size: 1.4rem;
            }

            h3 {
                font-size: 1.2rem;
            }

            .meta {
                font-size: 0.85rem;
            }

            .navigation {
                flex-direction: column;
            }

            table {
                font-size: 0.85rem;
            }

            th, td {
                padding: var(--spacing-xs);
            }
        }
    
        
    
        /* Breadcrumb styles */
        .breadcrumb {
            background: #f7fafc;
            padding: 0.75rem 1rem;
            border-bottom: 1px solid #e2e8f0;
            font-size: 0.9rem;
        }

        .breadcrumb-content {
            max-width: 900px;
            margin: 0 auto;
            display: flex;
            align-items: center;
            flex-wrap: wrap;
            gap: 0.5rem;
        }

        .breadcrumb a {
            color: #667eea;
            text-decoration: none;
            transition: color 0.2s;
        }

        .breadcrumb a:hover {
            color: #764ba2;
            text-decoration: underline;
        }

        .breadcrumb-separator {
            color: #a0aec0;
            margin: 0 0.25rem;
        }

        .breadcrumb-current {
            color: #4a5568;
            font-weight: 500;
        }
    </style>

    <script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
    <script>
        mermaid.initialize({ startOnLoad: true, theme: 'default', securityLevel: 'strict' });
    </script>

    <!-- MathJax for LaTeX equation rendering -->
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\(', '\)']],
                displayMath: [['$$', '$$'], ['\[', '\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
                ignoreHtmlClass: 'mermaid'
            }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" async></script>

    <style>
        /* Locale Switcher Styles */
        .locale-switcher {
            display: flex;
            align-items: center;
            gap: 0.5rem;
            padding: 0.5rem 1rem;
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
            border-radius: 6px;
            font-size: 0.9rem;
            margin-bottom: 1rem;
            box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);
        }

        .current-locale {
            font-weight: 600;
            color: #7b2cbf;
            display: flex;
            align-items: center;
            gap: 0.25rem;
        }

        .locale-separator {
            color: #adb5bd;
            font-weight: 300;
        }

        .locale-link {
            color: #f093fb;
            text-decoration: none;
            font-weight: 500;
            transition: all 0.2s ease;
            display: flex;
            align-items: center;
            gap: 0.25rem;
            padding: 0.2rem 0.5rem;
            border-radius: 4px;
        }

        .locale-link:hover {
            background: rgba(240, 147, 251, 0.1);
            color: #d07be8;
            transform: translateY(-1px);
        }

        .locale-meta {
            color: #868e96;
            font-size: 0.85rem;
            font-style: italic;
            margin-left: auto;
        }

        @media (max-width: 768px) {
            .locale-switcher {
                font-size: 0.85rem;
                padding: 0.4rem 0.8rem;
            }
            .locale-meta {
                display: none;
            }
        }
    </style>
</head>
<body>
            <div class="locale-switcher">
<span class="current-locale">ğŸŒ JP</span>
<span class="locale-separator">|</span>
<a href="../../../en/MI/bayesian-optimization-introduction/chapter-3.html" class="locale-link">ğŸ‡¬ğŸ‡§ EN</a>
<span class="locale-separator">|</span>
<span class="locale-meta">Last sync: 2025-11-16</span>
</div>
<nav class="breadcrumb">
        <div class="breadcrumb-content">
            <a href="../../index.html">AIå¯ºå­å±‹ãƒˆãƒƒãƒ—</a><span class="breadcrumb-separator">â€º</span><a href="../../MI/index.html">ãƒãƒ†ãƒªã‚¢ãƒ«ã‚ºãƒ»ã‚¤ãƒ³ãƒ•ã‚©ãƒãƒ†ã‚£ã‚¯ã‚¹</a><span class="breadcrumb-separator">â€º</span><a href="../../MI/bayesian-optimization-introduction/index.html">Bayesian Optimization</a><span class="breadcrumb-separator">â€º</span><span class="breadcrumb-current">Chapter 3</span>
        </div>
    </nav>

        <header>
        <div class="header-content">
            <h1>ç¬¬3ç« ï¼šå®Ÿè·µï¼šææ–™æ¢ç´¢ã¸ã®å¿œç”¨</h1>
            <p class="subtitle">Pythonå®Ÿè£…ã§å­¦ã¶å®Ÿä¸–ç•Œã®ææ–™æœ€é©åŒ–</p>
            <div class="meta">
                <span class="meta-item">ğŸ“– èª­äº†æ™‚é–“: 25-30åˆ†</span>
                <span class="meta-item">ğŸ“Š é›£æ˜“åº¦: ä¸­ç´š</span>
                <span class="meta-item">ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹: 12å€‹</span>
                <span class="meta-item">ğŸ“ æ¼”ç¿’å•é¡Œ: 3å•</span>
            </div>
        </div>
    </header>

    <main class="container">
<h1>ç¬¬3ç« ï¼šå®Ÿè·µï¼šææ–™æ¢ç´¢ã¸ã®å¿œç”¨</h1>
<p class="chapter-description" style="margin: 1.5rem 0; padding: 1rem; background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%); border-left: 4px solid #7b2cbf; border-radius: 8px; font-size: 1.05rem; line-height: 1.8; color: #2d3748;">ä¸ç¢ºã‹ã•ã‚’åˆ©ç”¨ã—ãŸå®Ÿé¨“è¨ˆç”»ã§ã€å®Ÿé¨“å›æ•°ã‚’æ¸›ã‚‰ã—ã¤ã¤æœ€é©è§£ã«è¿‘ã¥ãæµã‚Œã‚’å­¦ã³ã¾ã™ã€‚ç¾å ´å°å…¥ã®æ³¨æ„ç‚¹ã‚‚ç¢ºèªã—ã¾ã™ã€‚</p>
<p class="chapter-supplement" style="margin: 0.75rem 0 1.5rem 0; padding: 0.75rem 1rem; background: linear-gradient(135deg, #fff8e1 0%, #fff3cd 100%); border-left: 3px solid #f59e0b; border-radius: 6px; font-size: 0.95rem; line-height: 1.7; color: #4a5568;"><strong>ğŸ’¡ è£œè¶³:</strong> å®Ÿé¨“ã®åˆ‡ã‚Šæˆ»ã—ã‚³ã‚¹ãƒˆã‚’å…ˆã«æŠŠæ¡ã€‚å®‰å…¨å´ã«å€’ã™åˆ¶ç´„æ¡ä»¶ã§å®Ÿè£…ã™ã‚‹ã¨é‹ç”¨ã—ã‚„ã™ã„ã§ã™ã€‚</p>





<p><strong>Pythonå®Ÿè£…ã§å­¦ã¶å®Ÿä¸–ç•Œã®ææ–™æœ€é©åŒ–</strong></p>
<h2>å­¦ç¿’ç›®æ¨™</h2>
<p>ã“ã®ç« ã‚’èª­ã‚€ã“ã¨ã§ã€ä»¥ä¸‹ã‚’ç¿’å¾—ã§ãã¾ã™ï¼š</p>
<ul>
<li>âœ… ææ–™ç‰©æ€§äºˆæ¸¬MLãƒ¢ãƒ‡ãƒ«ã¨ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã‚’çµ±åˆã§ãã‚‹</li>
<li>âœ… åˆ¶ç´„ä»˜ãæœ€é©åŒ–ã‚’å®Ÿè£…ã—ã€ææ–™ã®å®Ÿç¾å¯èƒ½æ€§ã‚’è€ƒæ…®ã§ãã‚‹</li>
<li>âœ… å¤šç›®çš„æœ€é©åŒ–ã§Paretoæœ€é©è§£ã‚’è¨ˆç®—ã§ãã‚‹</li>
<li>âœ… å®Ÿé¨“ã‚³ã‚¹ãƒˆã‚’è€ƒæ…®ã—ãŸãƒãƒƒãƒãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã‚’å®Ÿè£…ã§ãã‚‹</li>
<li>âœ… å®Ÿä¸–ç•Œã®Li-ioné›»æ± æœ€é©åŒ–å•é¡Œã‚’è§£æ±ºã§ãã‚‹</li>
</ul>
<p><strong>èª­äº†æ™‚é–“</strong>: 25-30åˆ†
<strong>ã‚³ãƒ¼ãƒ‰ä¾‹</strong>: 12å€‹
<strong>æ¼”ç¿’å•é¡Œ</strong>: 3å•</p>
<hr />
<h2>3.1 ææ–™ç‰©æ€§äºˆæ¸¬MLãƒ¢ãƒ‡ãƒ«ã¨ã®çµ±åˆ</h2>
<h3>ãªãœMLãƒ¢ãƒ‡ãƒ«ã¨çµ±åˆã™ã‚‹ã®ã‹</h3>
<p>ææ–™æ¢ç´¢ã§ã¯ã€ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã‚’ä»¥ä¸‹ã®ã‚ˆã†ã«çµ„ã¿åˆã‚ã›ã¾ã™ï¼š</p>
<ol>
<li>
<p><strong>æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰MLãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰</strong>
   - Materials Projectãªã©å…¬é–‹ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹
   - éå»ã®å®Ÿé¨“ãƒ‡ãƒ¼ã‚¿
   - DFTè¨ˆç®—çµæœ</p>
</li>
<li>
<p><strong>ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã§æ–°è¦ææ–™æ¢ç´¢</strong>
   - MLãƒ¢ãƒ‡ãƒ«ã‚’ç›®çš„é–¢æ•°ã¨ã—ã¦ä½¿ç”¨
   - å®Ÿé¨“å›æ•°ã‚’æœ€å°åŒ–
   - ä¸ç¢ºå®Ÿæ€§ã‚’æ´»ç”¨</p>
</li>
</ol>
<h3>Materials Project APIã‹ã‚‰ãƒ‡ãƒ¼ã‚¿å–å¾—</h3>
<p><strong>ã‚³ãƒ¼ãƒ‰ä¾‹1: Materials Projectã‹ã‚‰ãƒ‡ãƒ¼ã‚¿å–å¾—</strong></p>
<pre><code class="language-python"># Materials Projectã‹ã‚‰ãƒ‡ãƒ¼ã‚¿å–å¾—
# æ³¨: mp-api ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãŒå¿…è¦: pip install mp-api
from mp_api.client import MPRester
import pandas as pd
import numpy as np

# Materials Project APIã®ä½¿ç”¨ï¼ˆAPIã‚­ãƒ¼å¿…è¦ï¼‰
# ç™»éŒ²: https://materialsproject.org/api
API_KEY = &quot;YOUR_API_KEY_HERE&quot;  # å®Ÿéš›ã®APIã‚­ãƒ¼ã«ç½®ãæ›ãˆ

def fetch_battery_materials(api_key, max_materials=100):
    &quot;&quot;&quot;
    Li-ioné›»æ± æ­£æ¥µææ–™ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—

    Parameters:
    -----------
    api_key : str
        Materials Project APIã‚­ãƒ¼
    max_materials : int
        å–å¾—ã™ã‚‹ææ–™ã®æœ€å¤§æ•°

    Returns:
    --------
    df : DataFrame
        ææ–™ç‰¹æ€§ãƒ‡ãƒ¼ã‚¿
    &quot;&quot;&quot;
    with MPRester(api_key) as mpr:
        # Liå«æœ‰é…¸åŒ–ç‰©ã‚’æ¤œç´¢
        docs = mpr.summary.search(
            elements=[&quot;Li&quot;, &quot;O&quot;],  # Li ã¨ O ã‚’å«ã‚€
            num_elements=(3, 5),    # 3-5å…ƒç´ ç³»
            fields=[
                &quot;material_id&quot;,
                &quot;formula_pretty&quot;,
                &quot;formation_energy_per_atom&quot;,
                &quot;band_gap&quot;,
                &quot;density&quot;,
                &quot;volume&quot;
            ]
        )

        # DataFrameã«å¤‰æ›
        data = []
        for doc in docs[:max_materials]:
            data.append({
                'material_id': doc.material_id,
                'formula': doc.formula_pretty,
                'formation_energy': doc.formation_energy_per_atom,
                'band_gap': doc.band_gap,
                'density': doc.density,
                'volume': doc.volume
            })

        df = pd.DataFrame(data)
        return df

# ãƒ‡ãƒ¢ç”¨ã®ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ï¼ˆAPIã‚­ãƒ¼ãŒãªã„å ´åˆï¼‰
def generate_dummy_battery_data(n_samples=100):
    &quot;&quot;&quot;
    ãƒ€ãƒŸãƒ¼ã®Li-ioné›»æ± ææ–™ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ

    Parameters:
    -----------
    n_samples : int
        ã‚µãƒ³ãƒ—ãƒ«æ•°

    Returns:
    --------
    df : DataFrame
        ææ–™ç‰¹æ€§ãƒ‡ãƒ¼ã‚¿
    &quot;&quot;&quot;
    np.random.seed(42)

    # çµ„æˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆæ­£è¦åŒ–ï¼‰
    li_content = np.random.uniform(0.1, 0.5, n_samples)
    ni_content = np.random.uniform(0.1, 0.4, n_samples)
    co_content = np.random.uniform(0.1, 0.4, n_samples)
    mn_content = 1.0 - li_content - ni_content - co_content

    # å®¹é‡ï¼ˆmAh/gï¼‰: Liå«é‡ã¨ç›¸é–¢
    capacity = (
        150 + 200 * li_content +
        50 * ni_content +
        30 * np.random.randn(n_samples)
    )

    # é›»åœ§ï¼ˆVï¼‰: Coå«é‡ã¨ç›¸é–¢
    voltage = (
        3.0 + 1.5 * co_content +
        0.2 * np.random.randn(n_samples)
    )

    # å®‰å®šæ€§ï¼ˆformation energyï¼‰: è² ãŒå®‰å®š
    stability = (
        -2.0 - 0.5 * li_content -
        0.3 * ni_content +
        0.1 * np.random.randn(n_samples)
    )

    df = pd.DataFrame({
        'li_content': li_content,
        'ni_content': ni_content,
        'co_content': co_content,
        'mn_content': mn_content,
        'capacity': capacity,
        'voltage': voltage,
        'stability': stability
    })

    return df

# ãƒ‡ãƒ¼ã‚¿å–å¾—ï¼ˆãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ä½¿ç”¨ï¼‰
df_materials = generate_dummy_battery_data(n_samples=150)

print(&quot;ææ–™ãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆ:&quot;)
print(df_materials.describe())
print(f&quot;\nãƒ‡ãƒ¼ã‚¿ã‚·ã‚§ã‚¤ãƒ—: {df_materials.shape}&quot;)
</code></pre>
<p><strong>å‡ºåŠ›</strong>:</p>
<pre><code>ææ–™ãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆ:
       li_content  ni_content  co_content  mn_content    capacity  \
count  150.000000  150.000000  150.000000  150.000000  150.000000
mean     0.299524    0.249336    0.249821    0.201319  208.964738
std      0.116176    0.085721    0.083957    0.122841   38.259483
min      0.102543    0.101189    0.103524   -0.107479  137.582916
max      0.499765    0.399915    0.398774    0.499304  311.495867

         voltage   stability
count  150.000000  150.000000
mean     3.374732   -2.161276
std      0.285945    0.221438
min      2.762894   -2.774301
max      4.137882   -1.554217

ãƒ‡ãƒ¼ã‚¿ã‚·ã‚§ã‚¤ãƒ—: (150, 7)
</code></pre>
<hr />
<h3>æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã§ç‰©æ€§äºˆæ¸¬</h3>
<p><strong>ã‚³ãƒ¼ãƒ‰ä¾‹2: Random Forestã§å®¹é‡äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰</strong></p>
<pre><code class="language-python"># Random Forestã§å®¹é‡äºˆæ¸¬
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt

# ç‰¹å¾´é‡ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ
X = df_materials[['li_content', 'ni_content',
                   'co_content', 'mn_content']].values
y_capacity = df_materials['capacity'].values
y_voltage = df_materials['voltage'].values
y_stability = df_materials['stability'].values

# ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
X_train, X_test, y_train, y_test = train_test_split(
    X, y_capacity, test_size=0.2, random_state=42
)

# Random Forestãƒ¢ãƒ‡ãƒ«
rf_model = RandomForestRegressor(
    n_estimators=100,
    max_depth=10,
    min_samples_split=5,
    random_state=42
)

# è¨“ç·´
rf_model.fit(X_train, y_train)

# äºˆæ¸¬
y_pred_train = rf_model.predict(X_train)
y_pred_test = rf_model.predict(X_test)

# è©•ä¾¡
train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))
test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))
test_r2 = r2_score(y_test, y_pred_test)

# ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
cv_scores = cross_val_score(
    rf_model, X_train, y_train,
    cv=5, scoring='r2'
)

print(&quot;Random Forestãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½:&quot;)
print(f&quot;  è¨“ç·´RMSE: {train_rmse:.2f} mAh/g&quot;)
print(f&quot;  ãƒ†ã‚¹ãƒˆRMSE: {test_rmse:.2f} mAh/g&quot;)
print(f&quot;  ãƒ†ã‚¹ãƒˆRÂ²: {test_r2:.3f}&quot;)
print(f&quot;  CV RÂ² (5-fold): {cv_scores.mean():.3f} Â± {cv_scores.std():.3f}&quot;)

# ç‰¹å¾´é‡é‡è¦åº¦
feature_names = ['Li', 'Ni', 'Co', 'Mn']
importances = rf_model.feature_importances_
indices = np.argsort(importances)[::-1]

print(&quot;\nç‰¹å¾´é‡é‡è¦åº¦:&quot;)
for i in range(len(feature_names)):
    print(f&quot;  {feature_names[indices[i]]}: {importances[indices[i]]:.3f}&quot;)

# å¯è¦–åŒ–
fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# äºˆæ¸¬ vs å®Ÿæ¸¬
ax1 = axes[0]
ax1.scatter(y_train, y_pred_train, alpha=0.5, label='è¨“ç·´')
ax1.scatter(y_test, y_pred_test, alpha=0.7, label='ãƒ†ã‚¹ãƒˆ')
ax1.plot([y_capacity.min(), y_capacity.max()],
         [y_capacity.min(), y_capacity.max()],
         'k--', linewidth=2, label='ç†æƒ³')
ax1.set_xlabel('å®Ÿæ¸¬å®¹é‡ (mAh/g)', fontsize=12)
ax1.set_ylabel('äºˆæ¸¬å®¹é‡ (mAh/g)', fontsize=12)
ax1.set_title('Random Forestå®¹é‡äºˆæ¸¬', fontsize=14)
ax1.legend()
ax1.grid(True, alpha=0.3)

# ç‰¹å¾´é‡é‡è¦åº¦
ax2 = axes[1]
ax2.barh(range(len(feature_names)), importances[indices],
         color='steelblue')
ax2.set_yticks(range(len(feature_names)))
ax2.set_yticklabels([feature_names[i] for i in indices])
ax2.set_xlabel('é‡è¦åº¦', fontsize=12)
ax2.set_title('ç‰¹å¾´é‡é‡è¦åº¦', fontsize=14)
ax2.grid(True, alpha=0.3, axis='x')

plt.tight_layout()
plt.savefig('ml_model_performance.png', dpi=150, bbox_inches='tight')
plt.show()
</code></pre>
<hr />
<h3>MLãƒ¢ãƒ‡ãƒ«ã‚’ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã§æ´»ç”¨</h3>
<p><strong>ã‚³ãƒ¼ãƒ‰ä¾‹3: MLãƒ¢ãƒ‡ãƒ«ã¨ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã®çµ±åˆ</strong></p>
<pre><code class="language-python"># scikit-optimizeã‚’ä½¿ç”¨ã—ãŸMLãƒ¢ãƒ‡ãƒ«ãƒ™ãƒ¼ã‚¹ã®æœ€é©åŒ–
from skopt import gp_minimize
from skopt.space import Real
from skopt.plots import plot_convergence

def objective_function_ml(x):
    &quot;&quot;&quot;
    MLãƒ¢ãƒ‡ãƒ«ã‚’ç›®çš„é–¢æ•°ã¨ã—ã¦ä½¿ç”¨

    Parameters:
    -----------
    x : list
        [li_content, ni_content, co_content, mn_content]

    Returns:
    --------
    float : è² ã®å®¹é‡ï¼ˆæœ€å°åŒ–å•é¡Œã«å¤‰æ›ï¼‰
    &quot;&quot;&quot;
    # çµ„æˆåˆ¶ç´„: åˆè¨ˆ=1.0
    li, ni, co, mn = x
    total = li + ni + co + mn

    # åˆ¶ç´„é•åã«ãƒšãƒŠãƒ«ãƒ†ã‚£
    if not (0.98 &lt;= total &lt;= 1.02):
        return 1000.0  # å¤§ããªãƒšãƒŠãƒ«ãƒ†ã‚£

    # å€‹åˆ¥åˆ¶ç´„
    if li &lt; 0.1 or li &gt; 0.5:
        return 1000.0
    if ni &lt; 0.1 or ni &gt; 0.4:
        return 1000.0
    if co &lt; 0.1 or co &gt; 0.4:
        return 1000.0
    if mn &lt; 0.0:
        return 1000.0

    # MLãƒ¢ãƒ‡ãƒ«ã§å®¹é‡äºˆæ¸¬
    X_pred = np.array([[li, ni, co, mn]])
    capacity_pred = rf_model.predict(X_pred)[0]

    # æœ€å°åŒ–å•é¡Œã«å¤‰æ›ï¼ˆè² ã®å®¹é‡ï¼‰
    return -capacity_pred

# æ¢ç´¢ç©ºé–“ã®å®šç¾©
space = [
    Real(0.1, 0.5, name='li_content'),
    Real(0.1, 0.4, name='ni_content'),
    Real(0.1, 0.4, name='co_content'),
    Real(0.0, 0.5, name='mn_content')
]

# ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã®å®Ÿè¡Œ
result = gp_minimize(
    objective_function_ml,
    space,
    n_calls=50,        # 50å›ã®è©•ä¾¡
    n_initial_points=10,  # åˆæœŸãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
    random_state=42,
    verbose=False
)

# çµæœ
best_composition = result.x
best_capacity = -result.fun  # è² ã‚’å…ƒã«æˆ»ã™

print(&quot;ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã®çµæœ:&quot;)
print(f&quot;  æœ€é©çµ„æˆ:&quot;)
print(f&quot;    Li: {best_composition[0]:.3f}&quot;)
print(f&quot;    Ni: {best_composition[1]:.3f}&quot;)
print(f&quot;    Co: {best_composition[2]:.3f}&quot;)
print(f&quot;    Mn: {best_composition[3]:.3f}&quot;)
print(f&quot;    åˆè¨ˆ: {sum(best_composition):.3f}&quot;)
print(f&quot;  äºˆæ¸¬å®¹é‡: {best_capacity:.2f} mAh/g&quot;)

# åæŸãƒ—ãƒ­ãƒƒãƒˆ
plt.figure(figsize=(10, 6))
plot_convergence(result)
plt.title('ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã®åæŸ', fontsize=14)
plt.xlabel('è©•ä¾¡å›æ•°', fontsize=12)
plt.ylabel('ã“ã‚Œã¾ã§ã®æœ€è‰¯å€¤ï¼ˆè² ã®å®¹é‡ï¼‰', fontsize=12)
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.savefig('bo_ml_convergence.png', dpi=150, bbox_inches='tight')
plt.show()

# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå†…ã®æœ€è‰¯å€¤ã¨æ¯”è¼ƒ
max_capacity_data = df_materials['capacity'].max()
print(f&quot;\nãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå†…ã®æœ€å¤§å®¹é‡: {max_capacity_data:.2f} mAh/g&quot;)
print(f&quot;æ”¹å–„ç‡: {((best_capacity - max_capacity_data) / max_capacity_data * 100):.1f}%&quot;)
</code></pre>
<p><strong>æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›</strong>:</p>
<pre><code>ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã®çµæœ:
  æœ€é©çµ„æˆ:
    Li: 0.487
    Ni: 0.312
    Co: 0.152
    Mn: 0.049
    åˆè¨ˆ: 1.000
  äºˆæ¸¬å®¹é‡: 267.34 mAh/g

ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå†…ã®æœ€å¤§å®¹é‡: 311.50 mAh/g
æ”¹å–„ç‡: -14.2%
</code></pre>
<hr />
<h2>3.2 åˆ¶ç´„ä»˜ãæœ€é©åŒ–</h2>
<h3>ææ–™ã®å®Ÿç¾å¯èƒ½æ€§åˆ¶ç´„</h3>
<p>å®Ÿéš›ã®ææ–™é–‹ç™ºã§ã¯ã€ä»¥ä¸‹ã®åˆ¶ç´„ãŒã‚ã‚Šã¾ã™ï¼š</p>
<ol>
<li><strong>çµ„æˆåˆ¶ç´„</strong>: åˆè¨ˆ100%ã€å„å…ƒç´ ã®ä¸Šä¸‹é™</li>
<li><strong>å®‰å®šæ€§åˆ¶ç´„</strong>: formation energy &lt; é–¾å€¤</li>
<li><strong>å®Ÿé¨“çš„åˆ¶ç´„</strong>: åˆæˆæ¸©åº¦ã€åœ§åŠ›ç¯„å›²</li>
<li><strong>ã‚³ã‚¹ãƒˆåˆ¶ç´„</strong>: é«˜ä¾¡ãªå…ƒç´ ã®ä½¿ç”¨åˆ¶é™</li>
</ol>
<h3>åˆ¶ç´„ä»˜ããƒ™ã‚¤ã‚ºæœ€é©åŒ–ã®å®Ÿè£…</h3>
<p><strong>ã‚³ãƒ¼ãƒ‰ä¾‹4: è¤‡æ•°åˆ¶ç´„æ¡ä»¶ä¸‹ã§ã®æœ€é©åŒ–</strong></p>
<pre><code class="language-python"># åˆ¶ç´„ä»˜ããƒ™ã‚¤ã‚ºæœ€é©åŒ–ï¼ˆBoTorchä½¿ç”¨ï¼‰
# æ³¨: BoTorchã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«: pip install botorch torch
import torch
from botorch.models import SingleTaskGP
from botorch.fit import fit_gpytorch_model
from gpytorch.mlls import ExactMarginalLogLikelihood
from botorch.acquisition import ExpectedImprovement
from botorch.optim import optimize_acqf

def constrained_bo_example():
    &quot;&quot;&quot;
    åˆ¶ç´„ä»˜ããƒ™ã‚¤ã‚ºæœ€é©åŒ–ã®ãƒ‡ãƒ¢

    åˆ¶ç´„:
    - å®¹é‡ã‚’æœ€å¤§åŒ–
    - å®‰å®šæ€§: formation energy &lt; -1.5 eV/atom
    - ã‚³ã‚¹ãƒˆ: Coå«é‡ &lt; 0.3
    &quot;&quot;&quot;
    # åˆæœŸãƒ‡ãƒ¼ã‚¿ï¼ˆãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼‰
    n_initial = 10
    np.random.seed(42)

    X_init = np.random.rand(n_initial, 4)
    # çµ„æˆæ­£è¦åŒ–
    X_init = X_init / X_init.sum(axis=1, keepdims=True)

    # ç›®çš„é–¢æ•°ã¨åˆ¶ç´„ã®è©•ä¾¡
    y_capacity = []
    y_stability = []
    for i in range(n_initial):
        x = X_init[i]
        # å®¹é‡äºˆæ¸¬
        capacity = rf_model.predict(x.reshape(1, -1))[0]
        # å®‰å®šæ€§ï¼ˆç°¡ç•¥ãƒ¢ãƒ‡ãƒ«ï¼‰
        stability = -2.0 - 0.5*x[0] - 0.3*x[1] + 0.1*np.random.randn()

        y_capacity.append(capacity)
        y_stability.append(stability)

    X_init = torch.tensor(X_init, dtype=torch.float64)
    y_capacity = torch.tensor(y_capacity, dtype=torch.float64).unsqueeze(-1)
    y_stability = torch.tensor(y_stability, dtype=torch.float64).unsqueeze(-1)

    # é€æ¬¡æœ€é©åŒ–ï¼ˆ20å›ï¼‰
    n_iterations = 20
    X_all = X_init.clone()
    y_capacity_all = y_capacity.clone()
    y_stability_all = y_stability.clone()

    for iteration in range(n_iterations):
        # ã‚¬ã‚¦ã‚¹éç¨‹ãƒ¢ãƒ‡ãƒ«ï¼ˆå®¹é‡ï¼‰
        gp_capacity = SingleTaskGP(X_all, y_capacity_all)
        mll_capacity = ExactMarginalLogLikelihood(
            gp_capacity.likelihood, gp_capacity
        )
        fit_gpytorch_model(mll_capacity)

        # ã‚¬ã‚¦ã‚¹éç¨‹ãƒ¢ãƒ‡ãƒ«ï¼ˆå®‰å®šæ€§ï¼‰
        gp_stability = SingleTaskGP(X_all, y_stability_all)
        mll_stability = ExactMarginalLogLikelihood(
            gp_stability.likelihood, gp_stability
        )
        fit_gpytorch_model(mll_stability)

        # Expected Improvementï¼ˆå®¹é‡ï¼‰
        best_f = y_capacity_all.max()
        EI = ExpectedImprovement(gp_capacity, best_f=best_f)

        # ç²å¾—é–¢æ•°ã®æœ€é©åŒ–ï¼ˆåˆ¶ç´„è€ƒæ…®ï¼‰
        bounds = torch.tensor([[0.1, 0.1, 0.1, 0.0],
                                [0.5, 0.4, 0.3, 0.5]],
                               dtype=torch.float64)

        candidate, acq_value = optimize_acqf(
            EI,
            bounds=bounds,
            q=1,
            num_restarts=10,
            raw_samples=512,
        )

        # å€™è£œç‚¹ã®è©•ä¾¡
        x_new = candidate.detach().numpy()[0]
        # æ­£è¦åŒ–
        x_new = x_new / x_new.sum()

        # å®Ÿé¨“ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        capacity_new = rf_model.predict(x_new.reshape(1, -1))[0]
        stability_new = -2.0 - 0.5*x_new[0] - 0.3*x_new[1] + \
                        0.1*np.random.randn()

        # åˆ¶ç´„ãƒã‚§ãƒƒã‚¯
        feasible = (stability_new &lt; -1.5) and (x_new[2] &lt; 0.3)

        if feasible:
            print(f&quot;Iteration {iteration+1}: &quot;
                  f&quot;Capacity={capacity_new:.1f}, &quot;
                  f&quot;Stability={stability_new:.2f}, &quot;
                  f&quot;Feasible=Yes&quot;)
        else:
            print(f&quot;Iteration {iteration+1}: &quot;
                  f&quot;Capacity={capacity_new:.1f}, &quot;
                  f&quot;Stability={stability_new:.2f}, &quot;
                  f&quot;Feasible=No (åˆ¶ç´„é•å)&quot;)

        # ãƒ‡ãƒ¼ã‚¿ã«è¿½åŠ 
        X_all = torch.cat([X_all, torch.tensor(x_new).unsqueeze(0)], dim=0)
        y_capacity_all = torch.cat([y_capacity_all,
                                     torch.tensor([[capacity_new]])], dim=0)
        y_stability_all = torch.cat([y_stability_all,
                                      torch.tensor([[stability_new]])], dim=0)

    # å®Ÿè¡Œå¯èƒ½è§£ã®ä¸­ã§æœ€è‰¯ã®ã‚‚ã®ã‚’æŠ½å‡º
    feasible_mask = (y_stability_all &lt; -1.5).squeeze() &amp; \
                    (X_all[:, 2] &lt; 0.3).squeeze()

    if feasible_mask.sum() &gt; 0:
        feasible_capacities = y_capacity_all[feasible_mask]
        feasible_X = X_all[feasible_mask]
        best_idx = feasible_capacities.argmax()
        best_composition_constrained = feasible_X[best_idx].numpy()
        best_capacity_constrained = feasible_capacities[best_idx].item()

        print(&quot;\næœ€çµ‚çµæœï¼ˆåˆ¶ç´„ä»˜ãï¼‰:&quot;)
        print(f&quot;  æœ€é©çµ„æˆ:&quot;)
        print(f&quot;    Li: {best_composition_constrained[0]:.3f}&quot;)
        print(f&quot;    Ni: {best_composition_constrained[1]:.3f}&quot;)
        print(f&quot;    Co: {best_composition_constrained[2]:.3f} &quot;
              f&quot;(åˆ¶ç´„ &lt; 0.3)&quot;)
        print(f&quot;    Mn: {best_composition_constrained[3]:.3f}&quot;)
        print(f&quot;  äºˆæ¸¬å®¹é‡: {best_capacity_constrained:.2f} mAh/g&quot;)
        print(f&quot;  å®Ÿè¡Œå¯èƒ½è§£ã®æ•°: {feasible_mask.sum().item()} / &quot;
              f&quot;{len(X_all)}&quot;)
    else:
        print(&quot;\nå®Ÿè¡Œå¯èƒ½è§£ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ&quot;)

# å®Ÿè¡Œ
constrained_bo_example()
</code></pre>
<hr />
<h2>3.3 å¤šç›®çš„æœ€é©åŒ–ï¼ˆParetoæœ€é©åŒ–ï¼‰</h2>
<h3>ãªãœå¤šç›®çš„æœ€é©åŒ–ãŒå¿…è¦ã‹</h3>
<p>ææ–™é–‹ç™ºã§ã¯ã€<strong>è¤‡æ•°ã®ç‰¹æ€§ã‚’åŒæ™‚ã«æœ€é©åŒ–</strong>ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ï¼š</p>
<ul>
<li><strong>Li-ioné›»æ± </strong>: å®¹é‡ â†‘ã€é›»åœ§ â†‘ã€å®‰å®šæ€§ â†‘</li>
<li><strong>ç†±é›»ææ–™</strong>: ã‚¼ãƒ¼ãƒ™ãƒƒã‚¯ä¿‚æ•° â†‘ã€é›»æ°—ä¼å°åº¦ â†‘ã€ç†±ä¼å°åº¦ â†“</li>
<li><strong>è§¦åª’</strong>: æ´»æ€§ â†‘ã€é¸æŠæ€§ â†‘ã€å®‰å®šæ€§ â†‘ã€ã‚³ã‚¹ãƒˆ â†“</li>
</ul>
<p>ã“ã‚Œã‚‰ã¯ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ãŒã‚ã‚Šã€<strong>å˜ä¸€ã®æœ€é©è§£ã¯å­˜åœ¨ã—ãªã„</strong>ã€‚</p>
<h3>Paretoãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢ã®æ¦‚å¿µ</h3>
<div class="mermaid">
flowchart TB
    subgraph ç›®çš„ç©ºé–“
    A[ç›®çš„1: å®¹é‡]
    B[ç›®çš„2: å®‰å®šæ€§]
    C[Paretoãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢\nãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã®å¢ƒç•Œ]
    D[æ”¯é…ã•ã‚Œã‚‹è§£\nã©ã¡ã‚‰ã‚‚åŠ£ã‚‹]
    E[Paretoæœ€é©è§£\næ”¹å–„ã«ã¯ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ãŒå¿…è¦]
    end

    A --> C
    B --> C
    C --> E
    D - åŠ£ã‚‹ .-> E

    style A fill:#e3f2fd
    style B fill:#fff3e0
    style C fill:#e8f5e9
    style E fill:#fce4ec
</div>

<p><strong>Paretoæœ€é©ã®å®šç¾©</strong>:</p>
<blockquote>
<p>è§£ x ãŒ Paretoæœ€é© â‡” å…¨ã¦ã®ç›®çš„ã‚’åŒæ™‚ã«æ”¹å–„ã™ã‚‹è§£ãŒå­˜åœ¨ã—ãªã„</p>
</blockquote>
<hr />
<h3>Expected Hypervolume Improvementï¼ˆEHVIï¼‰</h3>
<p><strong>ã‚³ãƒ¼ãƒ‰ä¾‹5: å¤šç›®çš„ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã®å®Ÿè£…</strong></p>
<pre><code class="language-python"># å¤šç›®çš„ãƒ™ã‚¤ã‚ºæœ€é©åŒ–
from botorch.models import ModelListGP
from botorch.acquisition.multi_objective import \
    qExpectedHypervolumeImprovement
from botorch.utils.multi_objective.box_decompositions.dominated import \
    DominatedPartitioning

def multi_objective_bo_example():
    &quot;&quot;&quot;
    å¤šç›®çš„ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã®ãƒ‡ãƒ¢

    ç›®çš„:
    1. å®¹é‡ã‚’æœ€å¤§åŒ–
    2. å®‰å®šæ€§ã‚’æœ€å¤§åŒ–ï¼ˆformation energyã®çµ¶å¯¾å€¤ã‚’æœ€å°åŒ–ï¼‰
    &quot;&quot;&quot;
    # åˆæœŸãƒ‡ãƒ¼ã‚¿
    n_initial = 15
    np.random.seed(42)

    X_init = np.random.rand(n_initial, 4)
    X_init = X_init / X_init.sum(axis=1, keepdims=True)

    # 2ã¤ã®ç›®çš„é–¢æ•°ã‚’è©•ä¾¡
    y1_capacity = []
    y2_stability = []

    for i in range(n_initial):
        x = X_init[i]
        capacity = rf_model.predict(x.reshape(1, -1))[0]
        stability = -2.0 - 0.5*x[0] - 0.3*x[1] + 0.1*np.random.randn()
        # å®‰å®šæ€§ã¯è² ãŒè‰¯ã„ã®ã§ã€æ­£ã«å¤‰æ›ï¼ˆæœ€å¤§åŒ–å•é¡Œã«çµ±ä¸€ï¼‰
        stability_positive = -stability

        y1_capacity.append(capacity)
        y2_stability.append(stability_positive)

    X_all = torch.tensor(X_init, dtype=torch.float64)
    Y_all = torch.tensor(
        np.column_stack([y1_capacity, y2_stability]),
        dtype=torch.float64
    )

    # é€æ¬¡æœ€é©åŒ–
    n_iterations = 20

    for iteration in range(n_iterations):
        # ã‚¬ã‚¦ã‚¹éç¨‹ãƒ¢ãƒ‡ãƒ«ï¼ˆå„ç›®çš„é–¢æ•°ã”ã¨ï¼‰
        gp_list = []
        for i in range(2):
            gp = SingleTaskGP(X_all, Y_all[:, i].unsqueeze(-1))
            mll = ExactMarginalLogLikelihood(gp.likelihood, gp)
            fit_gpytorch_model(mll)
            gp_list.append(gp)

        model = ModelListGP(*gp_list)

        # å‚ç…§ç‚¹ï¼ˆNadir point ã‚ˆã‚Šæ‚ªã„ç‚¹ï¼‰
        ref_point = Y_all.min(dim=0).values - 10.0

        # Pareto frontier ã®è¨ˆç®—
        pareto_mask = is_non_dominated(Y_all)
        pareto_Y = Y_all[pareto_mask]

        # EHVIç²å¾—é–¢æ•°
        partitioning = DominatedPartitioning(
            ref_point=ref_point,
            Y=pareto_Y
        )
        acq_func = qExpectedHypervolumeImprovement(
            model=model,
            ref_point=ref_point,
            partitioning=partitioning
        )

        # æœ€é©åŒ–
        bounds = torch.tensor([[0.1, 0.1, 0.1, 0.0],
                                [0.5, 0.4, 0.4, 0.5]],
                               dtype=torch.float64)

        candidate, acq_value = optimize_acqf(
            acq_func,
            bounds=bounds,
            q=1,
            num_restarts=10,
            raw_samples=512,
        )

        # æ–°ã—ã„å€™è£œç‚¹ã®è©•ä¾¡
        x_new = candidate.detach().numpy()[0]
        x_new = x_new / x_new.sum()

        capacity_new = rf_model.predict(x_new.reshape(1, -1))[0]
        stability_new = -2.0 - 0.5*x_new[0] - 0.3*x_new[1] + \
                        0.1*np.random.randn()
        stability_positive_new = -stability_new

        y_new = torch.tensor([[capacity_new, stability_positive_new]],
                              dtype=torch.float64)

        # ãƒ‡ãƒ¼ã‚¿ã«è¿½åŠ 
        X_all = torch.cat([X_all, torch.tensor(x_new).unsqueeze(0)], dim=0)
        Y_all = torch.cat([Y_all, y_new], dim=0)

        if (iteration + 1) % 5 == 0:
            print(f&quot;Iteration {iteration+1}: &quot;
                  f&quot;Paretoè§£æ•°={pareto_mask.sum().item()}, &quot;
                  f&quot;HV={compute_hypervolume(pareto_Y, ref_point):.2f}&quot;)

    # æœ€çµ‚Paretoãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢
    pareto_mask_final = is_non_dominated(Y_all)
    pareto_X_final = X_all[pareto_mask_final].numpy()
    pareto_Y_final = Y_all[pareto_mask_final].numpy()

    print(f&quot;\næœ€çµ‚Paretoæœ€é©è§£æ•°: {pareto_mask_final.sum().item()}&quot;)

    # Paretoãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢ã®å¯è¦–åŒ–
    plt.figure(figsize=(10, 6))

    # å…¨ã¦ã®ç‚¹
    plt.scatter(Y_all[:, 0].numpy(), Y_all[:, 1].numpy(),
                c='lightblue', s=50, alpha=0.5, label='å…¨æ¢ç´¢ç‚¹')

    # Paretoæœ€é©è§£
    plt.scatter(pareto_Y_final[:, 0], pareto_Y_final[:, 1],
                c='red', s=100, edgecolors='black', zorder=10,
                label='Paretoæœ€é©è§£')

    # Paretoãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢ã‚’ç·šã§çµã¶
    sorted_indices = np.argsort(pareto_Y_final[:, 0])
    plt.plot(pareto_Y_final[sorted_indices, 0],
             pareto_Y_final[sorted_indices, 1],
             'r--', linewidth=2, alpha=0.5, label='Paretoãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢')

    plt.xlabel('ç›®çš„1: å®¹é‡ (mAh/g)', fontsize=12)
    plt.ylabel('ç›®çš„2: å®‰å®šæ€§ (-formation energy)', fontsize=12)
    plt.title('å¤šç›®çš„æœ€é©åŒ–: Paretoãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢', fontsize=14)
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.savefig('pareto_frontier.png', dpi=150, bbox_inches='tight')
    plt.show()

    # ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã®ä¾‹ã‚’è¡¨ç¤º
    print(&quot;\nãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã®ä¾‹:&quot;)
    # å®¹é‡é‡è¦–
    idx_max_capacity = np.argmax(pareto_Y_final[:, 0])
    print(f&quot;  å®¹é‡é‡è¦–: å®¹é‡={pareto_Y_final[idx_max_capacity, 0]:.1f}, &quot;
          f&quot;å®‰å®šæ€§={pareto_Y_final[idx_max_capacity, 1]:.2f}&quot;)

    # å®‰å®šæ€§é‡è¦–
    idx_max_stability = np.argmax(pareto_Y_final[:, 1])
    print(f&quot;  å®‰å®šæ€§é‡è¦–: å®¹é‡={pareto_Y_final[idx_max_stability, 0]:.1f}, &quot;
          f&quot;å®‰å®šæ€§={pareto_Y_final[idx_max_stability, 1]:.2f}&quot;)

    # ãƒãƒ©ãƒ³ã‚¹å‹ï¼ˆä¸­é–“ç‚¹ï¼‰
    normalized_Y = (pareto_Y_final - pareto_Y_final.min(axis=0)) / \
                   (pareto_Y_final.max(axis=0) - pareto_Y_final.min(axis=0))
    distances = np.sqrt(((normalized_Y - 0.5)**2).sum(axis=1))
    idx_balanced = np.argmin(distances)
    print(f&quot;  ãƒãƒ©ãƒ³ã‚¹å‹: å®¹é‡={pareto_Y_final[idx_balanced, 0]:.1f}, &quot;
          f&quot;å®‰å®šæ€§={pareto_Y_final[idx_balanced, 1]:.2f}&quot;)

# Paretoæœ€é©åˆ¤å®šé–¢æ•°
def is_non_dominated(Y):
    &quot;&quot;&quot;
    Paretoæœ€é©è§£ã‚’åˆ¤å®š

    Parameters:
    -----------
    Y : Tensor (n_points, n_objectives)
        ç›®çš„é–¢æ•°å€¤

    Returns:
    --------
    mask : Tensor (n_points,)
        TrueãŒparetoæœ€é©
    &quot;&quot;&quot;
    n_points = Y.shape[0]
    is_efficient = torch.ones(n_points, dtype=torch.bool)

    for i in range(n_points):
        if is_efficient[i]:
            # iç•ªç›®ã®ç‚¹ã‚ˆã‚Šå…¨ã¦ã®ç›®çš„ã§å„ªã‚Œã¦ã„ã‚‹ç‚¹ãŒã‚ã‚‹ã‹
            is_dominated = (Y &gt;= Y[i]).all(dim=1) &amp; (Y &gt; Y[i]).any(dim=1)
            is_efficient[is_dominated] = False

    return is_efficient

# Hypervolumeè¨ˆç®—
def compute_hypervolume(pareto_Y, ref_point):
    &quot;&quot;&quot;
    Hypervolumeã®è¨ˆç®—ï¼ˆç°¡æ˜“ç‰ˆï¼‰

    Parameters:
    -----------
    pareto_Y : Tensor
        Paretoæœ€é©è§£
    ref_point : Tensor
        å‚ç…§ç‚¹

    Returns:
    --------
    float : Hypervolume
    &quot;&quot;&quot;
    # 2æ¬¡å…ƒã®ç°¡æ˜“è¨ˆç®—
    sorted_Y = pareto_Y[torch.argsort(pareto_Y[:, 0], descending=True)]
    hv = 0.0
    prev_y1 = ref_point[0]

    for i in range(len(sorted_Y)):
        width = prev_y1 - sorted_Y[i, 0]
        height = sorted_Y[i, 1] - ref_point[1]
        hv += width * height
        prev_y1 = sorted_Y[i, 0]

    return hv.item()

# å®Ÿè¡Œ
# multi_objective_bo_example()
# æ³¨: BoTorchãŒå¿…è¦ãªãŸã‚ã€ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆ
print(&quot;å¤šç›®çš„æœ€é©åŒ–ã®ä¾‹ã¯BoTorchãŒå¿…è¦ã§ã™&quot;)
print(&quot;pip install botorch torch ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å¾Œã€å®Ÿè¡Œã—ã¦ãã ã•ã„&quot;)
</code></pre>
<hr />
<h2>3.4 å®Ÿé¨“ã‚³ã‚¹ãƒˆã‚’è€ƒæ…®ã—ãŸæœ€é©åŒ–</h2>
<h3>ãƒãƒƒãƒãƒ™ã‚¤ã‚ºæœ€é©åŒ–</h3>
<p>å®Ÿé¨“è£…ç½®ãŒè¤‡æ•°ã‚ã‚‹å ´åˆã€<strong>ä¸¦åˆ—å®Ÿé¨“</strong>ãŒå¯èƒ½ã§ã™ï¼š</p>
<ul>
<li><strong>å¾“æ¥</strong>: é€æ¬¡çš„ï¼ˆ1å›â†’çµæœâ†’æ¬¡ã®1å›ï¼‰</li>
<li><strong>ãƒãƒƒãƒBO</strong>: ä¸€åº¦ã«è¤‡æ•°ã®å€™è£œã‚’ææ¡ˆï¼ˆq-EIï¼‰</li>
</ul>
<h3>ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼</h3>
<div class="mermaid">
flowchart LR
    A[åˆæœŸãƒ‡ãƒ¼ã‚¿] --> B[ã‚¬ã‚¦ã‚¹éç¨‹ãƒ¢ãƒ‡ãƒ«]
    B --> C[q-EIç²å¾—é–¢æ•°\nqå€‹ã®å€™è£œã‚’ææ¡ˆ]
    C --> D[ä¸¦åˆ—å®Ÿé¨“\nqå€‹åŒæ™‚å®Ÿè¡Œ]
    D --> E{çµ‚äº†?}
    E -->|No| B
    E -->|Yes| F[æœ€è‰¯ææ–™]

    style A fill:#e3f2fd
    style C fill:#fff3e0
    style D fill:#f3e5f5
    style F fill:#fce4ec
</div>

<p><strong>ã‚³ãƒ¼ãƒ‰ä¾‹6: ãƒãƒƒãƒãƒ™ã‚¤ã‚ºæœ€é©åŒ–</strong></p>
<pre><code class="language-python"># ãƒãƒƒãƒãƒ™ã‚¤ã‚ºæœ€é©åŒ–ï¼ˆscikit-optimizeï¼‰
from scipy.stats import norm

def batch_expected_improvement(X, gp, f_best, xi=0.01):
    &quot;&quot;&quot;
    Batch Expected Improvementï¼ˆç°¡æ˜“ç‰ˆï¼‰

    Parameters:
    -----------
    X : array (n_candidates, n_features)
        å€™è£œç‚¹
    gp : GaussianProcessRegressor
        å­¦ç¿’æ¸ˆã¿GPãƒ¢ãƒ‡ãƒ«
    f_best : float
        ç¾åœ¨ã®æœ€è‰¯å€¤

    Returns:
    --------
    ei : array (n_candidates,)
        EIå€¤
    &quot;&quot;&quot;
    mu, sigma = gp.predict(X, return_std=True)
    improvement = mu - f_best - xi
    Z = improvement / (sigma + 1e-9)
    ei = improvement * norm.cdf(Z) + sigma * norm.pdf(Z)
    ei[sigma == 0.0] = 0.0
    return ei

def simulate_batch_bo(n_iterations=10, batch_size=3):
    &quot;&quot;&quot;
    ãƒãƒƒãƒãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³

    Parameters:
    -----------
    n_iterations : int
        ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ•°
    batch_size : int
        å„ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§ææ¡ˆã™ã‚‹å€™è£œæ•°

    Returns:
    --------
    X_all : array
        å…¨ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ç‚¹
    y_all : array
        å…¨è¦³æ¸¬å€¤
    &quot;&quot;&quot;
    from sklearn.gaussian_process import GaussianProcessRegressor
    from sklearn.gaussian_process.kernels import RBF, ConstantKernel

    # åˆæœŸãƒ‡ãƒ¼ã‚¿
    np.random.seed(42)
    n_initial = 5
    X_sampled = np.random.rand(n_initial, 4)
    X_sampled = X_sampled / X_sampled.sum(axis=1, keepdims=True)

    y_sampled = []
    for i in range(n_initial):
        capacity = rf_model.predict(X_sampled[i].reshape(1, -1))[0]
        y_sampled.append(capacity)

    y_sampled = np.array(y_sampled)

    # é€æ¬¡ãƒãƒƒãƒæœ€é©åŒ–
    for iteration in range(n_iterations):
        # ã‚¬ã‚¦ã‚¹éç¨‹ãƒ¢ãƒ‡ãƒ«
        kernel = ConstantKernel(1.0) * RBF(length_scale=0.2)
        gp = GaussianProcessRegressor(
            kernel=kernel,
            n_restarts_optimizer=10,
            random_state=42
        )
        gp.fit(X_sampled, y_sampled)

        # ç¾åœ¨ã®æœ€è‰¯å€¤
        f_best = y_sampled.max()

        # å€™è£œç‚¹ç”Ÿæˆï¼ˆå¤šæ•°ï¼‰
        n_candidates = 1000
        X_candidates = np.random.rand(n_candidates, 4)
        X_candidates = X_candidates / X_candidates.sum(axis=1, keepdims=True)

        # EIè¨ˆç®—
        ei_values = batch_expected_improvement(X_candidates, gp, f_best)

        # Top-ké¸æŠï¼ˆå˜ç´”ãªæ–¹æ³•ï¼‰
        # ã‚ˆã‚Šé«˜åº¦ãªæ–¹æ³•: q-EI, KBï¼ˆKriging Believerï¼‰
        top_k_indices = np.argsort(ei_values)[-batch_size:]
        X_batch = X_candidates[top_k_indices]

        # ãƒãƒƒãƒå®Ÿé¨“ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        y_batch = []
        for x in X_batch:
            capacity = rf_model.predict(x.reshape(1, -1))[0]
            y_batch.append(capacity)

        y_batch = np.array(y_batch)

        # ãƒ‡ãƒ¼ã‚¿ã«è¿½åŠ 
        X_sampled = np.vstack([X_sampled, X_batch])
        y_sampled = np.append(y_sampled, y_batch)

        # é€²æ—è¡¨ç¤º
        if (iteration + 1) % 3 == 0:
            best_so_far = y_sampled.max()
            print(f&quot;Iteration {iteration+1}: &quot;
                  f&quot;Batch size={batch_size}, &quot;
                  f&quot;Best so far={best_so_far:.2f} mAh/g&quot;)

    return X_sampled, y_sampled

# ãƒãƒƒãƒBOå®Ÿè¡Œ
print(&quot;ãƒãƒƒãƒãƒ™ã‚¤ã‚ºæœ€é©åŒ–ï¼ˆbatch_size=3ï¼‰:&quot;)
X_batch_bo, y_batch_bo = simulate_batch_bo(n_iterations=10, batch_size=3)

print(f&quot;\næœ€çµ‚çµæœ:&quot;)
print(f&quot;  ç·å®Ÿé¨“å›æ•°: {len(y_batch_bo)}&quot;)
print(f&quot;  æœ€è‰¯å®¹é‡: {y_batch_bo.max():.2f} mAh/g&quot;)
print(f&quot;  æœ€é©çµ„æˆ: {X_batch_bo[y_batch_bo.argmax()]}&quot;)

# é€æ¬¡BOã¨æ¯”è¼ƒ
print(&quot;\né€æ¬¡BOï¼ˆbatch_size=1ï¼‰:&quot;)
X_seq_bo, y_seq_bo = simulate_batch_bo(n_iterations=30, batch_size=1)
print(f&quot;  ç·å®Ÿé¨“å›æ•°: {len(y_seq_bo)}&quot;)
print(f&quot;  æœ€è‰¯å®¹é‡: {y_seq_bo.max():.2f} mAh/g&quot;)

# åŠ¹ç‡æ¯”è¼ƒ
plt.figure(figsize=(10, 6))
plt.plot(np.maximum.accumulate(y_seq_bo), 'o-',
         label='é€æ¬¡BO (batch_size=1)', linewidth=2, markersize=6)
plt.plot(np.arange(0, len(y_batch_bo), 3),
         np.maximum.accumulate(y_batch_bo)[::3], '^-',
         label='ãƒãƒƒãƒBO (batch_size=3)', linewidth=2, markersize=8)
plt.xlabel('å®Ÿé¨“å›æ•°', fontsize=12)
plt.ylabel('ã“ã‚Œã¾ã§ã®æœ€è‰¯å€¤ (mAh/g)', fontsize=12)
plt.title('ãƒãƒƒãƒBO vs é€æ¬¡BOã®åŠ¹ç‡æ¯”è¼ƒ', fontsize=14)
plt.legend()
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.savefig('batch_bo_comparison.png', dpi=150, bbox_inches='tight')
plt.show()
</code></pre>
<hr />
<h2>3.5 å®Œå…¨ãªå®Ÿè£…ä¾‹ï¼šLi-ioné›»æ± é›»è§£è³ªã®æœ€é©åŒ–</h2>
<h3>å•é¡Œè¨­å®š</h3>
<p><strong>ç›®çš„</strong>: Li-ioné›»æ± æ­£æ¥µææ–™ã®æœ€é©åŒ–</p>
<p><strong>æœ€é©åŒ–ã™ã‚‹ç‰¹æ€§</strong>:
1. å®¹é‡ï¼ˆmAh/gï¼‰ã‚’æœ€å¤§åŒ–
2. é›»åœ§ï¼ˆVï¼‰ã‚’æœ€å¤§åŒ–
3. å®‰å®šæ€§ï¼ˆformation energyï¼‰ã‚’æœ€å¤§åŒ–</p>
<p><strong>åˆ¶ç´„</strong>:
- çµ„æˆã®åˆè¨ˆ = 1.0
- Liå«é‡: 0.1-0.5
- Niå«é‡: 0.1-0.4
- Coå«é‡: 0.1-0.3ï¼ˆé«˜ä¾¡ãªãŸã‚åˆ¶é™ï¼‰
- Mnå«é‡: â‰¥ 0.0</p>
<p><strong>ã‚³ãƒ¼ãƒ‰ä¾‹7: å®Ÿä¸–ç•Œå•é¡Œã®å®Œå…¨å®Ÿè£…</strong></p>
<pre><code class="language-python"># Li-ioné›»æ± æ­£æ¥µææ–™ã®å¤šç›®çš„åˆ¶ç´„ä»˜ãæœ€é©åŒ–
class LiIonCathodeOptimizer:
    &quot;&quot;&quot;
    Li-ioné›»æ± æ­£æ¥µææ–™ã®æœ€é©åŒ–ã‚¯ãƒ©ã‚¹

    ç›®çš„:
    - å®¹é‡æœ€å¤§åŒ–
    - é›»åœ§æœ€å¤§åŒ–
    - å®‰å®šæ€§æœ€å¤§åŒ–ï¼ˆã‚³ã‚¹ãƒˆè€ƒæ…®ï¼‰

    åˆ¶ç´„:
    - çµ„æˆåˆ¶ç´„
    - Coå«é‡åˆ¶é™ï¼ˆã‚³ã‚¹ãƒˆï¼‰
    &quot;&quot;&quot;

    def __init__(self, capacity_model, voltage_model, stability_model):
        &quot;&quot;&quot;
        Parameters:
        -----------
        capacity_model : sklearn model
            å®¹é‡äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«
        voltage_model : sklearn model
            é›»åœ§äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«
        stability_model : sklearn model
            å®‰å®šæ€§äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«
        &quot;&quot;&quot;
        self.capacity_model = capacity_model
        self.voltage_model = voltage_model
        self.stability_model = stability_model

        # åˆ¶ç´„
        self.co_max = 0.3  # Coå«é‡ä¸Šé™
        self.composition_bounds = {
            'li': (0.1, 0.5),
            'ni': (0.1, 0.4),
            'co': (0.1, 0.3),
            'mn': (0.0, 0.5)
        }

    def evaluate(self, composition):
        &quot;&quot;&quot;
        ææ–™çµ„æˆã‚’è©•ä¾¡

        Parameters:
        -----------
        composition : array [li, ni, co, mn]

        Returns:
        --------
        dict : å„ç‰¹æ€§ã®äºˆæ¸¬å€¤
        &quot;&quot;&quot;
        # åˆ¶ç´„ãƒã‚§ãƒƒã‚¯
        if not self._check_constraints(composition):
            return {
                'capacity': -1000,
                'voltage': -1000,
                'stability': -1000,
                'feasible': False
            }

        x = composition.reshape(1, -1)

        capacity = self.capacity_model.predict(x)[0]
        # é›»åœ§ãƒ¢ãƒ‡ãƒ«ï¼ˆãƒ€ãƒŸãƒ¼ï¼‰
        voltage = 3.0 + 1.5 * composition[2] + 0.2 * np.random.randn()
        # å®‰å®šæ€§ãƒ¢ãƒ‡ãƒ«ï¼ˆãƒ€ãƒŸãƒ¼ï¼‰
        stability = -2.0 - 0.5*composition[0] - 0.3*composition[1] + \
                    0.1*np.random.randn()

        return {
            'capacity': capacity,
            'voltage': voltage,
            'stability': -stability,  # æ­£ã«å¤‰æ›
            'feasible': True
        }

    def _check_constraints(self, composition):
        &quot;&quot;&quot;åˆ¶ç´„ãƒã‚§ãƒƒã‚¯&quot;&quot;&quot;
        li, ni, co, mn = composition

        # çµ„æˆåˆè¨ˆ
        if not (0.98 &lt;= li + ni + co + mn &lt;= 1.02):
            return False

        # å„å…ƒç´ ã®ç¯„å›²
        if not (self.composition_bounds['li'][0] &lt;= li &lt;=
                self.composition_bounds['li'][1]):
            return False
        if not (self.composition_bounds['ni'][0] &lt;= ni &lt;=
                self.composition_bounds['ni'][1]):
            return False
        if not (self.composition_bounds['co'][0] &lt;= co &lt;=
                self.composition_bounds['co'][1]):
            return False
        if not (self.composition_bounds['mn'][0] &lt;= mn &lt;=
                self.composition_bounds['mn'][1]):
            return False

        return True

    def optimize_multi_objective(self, n_iterations=50):
        &quot;&quot;&quot;
        å¤šç›®çš„æœ€é©åŒ–ã‚’å®Ÿè¡Œ

        Returns:
        --------
        pareto_solutions : list of dict
            Paretoæœ€é©è§£
        &quot;&quot;&quot;
        # åˆæœŸã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
        n_initial = 20
        np.random.seed(42)

        solutions = []

        for i in range(n_initial):
            # ãƒ©ãƒ³ãƒ€ãƒ çµ„æˆç”Ÿæˆ
            composition = np.random.rand(4)
            composition = composition / composition.sum()

            # è©•ä¾¡
            result = self.evaluate(composition)

            if result['feasible']:
                solutions.append({
                    'composition': composition,
                    'capacity': result['capacity'],
                    'voltage': result['voltage'],
                    'stability': result['stability']
                })

        # é€æ¬¡æœ€é©åŒ–ï¼ˆç°¡æ˜“ç‰ˆï¼‰
        for iteration in range(n_iterations - n_initial):
            # æ—¢å­˜è§£ã‹ã‚‰Paretoæœ€é©ã‚’æŠ½å‡º
            pareto_sols = self._extract_pareto(solutions)

            # Paretoè§£ã®å‘¨è¾ºã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆç°¡æ˜“çš„ãªæ‰‹æ³•ï¼‰
            if len(pareto_sols) &gt; 0:
                base_sol = pareto_sols[np.random.randint(len(pareto_sols))]
                composition_new = base_sol['composition'] + \
                                  np.random.randn(4) * 0.05
                composition_new = np.clip(composition_new, 0.01, 0.8)
                composition_new = composition_new / composition_new.sum()
            else:
                composition_new = np.random.rand(4)
                composition_new = composition_new / composition_new.sum()

            # è©•ä¾¡
            result = self.evaluate(composition_new)

            if result['feasible']:
                solutions.append({
                    'composition': composition_new,
                    'capacity': result['capacity'],
                    'voltage': result['voltage'],
                    'stability': result['stability']
                })

        # æœ€çµ‚Paretoæœ€é©è§£
        pareto_solutions = self._extract_pareto(solutions)

        return pareto_solutions, solutions

    def _extract_pareto(self, solutions):
        &quot;&quot;&quot;Paretoæœ€é©è§£ã‚’æŠ½å‡º&quot;&quot;&quot;
        if len(solutions) == 0:
            return []

        objectives = np.array([
            [s['capacity'], s['voltage'], s['stability']]
            for s in solutions
        ])

        pareto_mask = np.ones(len(objectives), dtype=bool)

        for i in range(len(objectives)):
            if pareto_mask[i]:
                # iç•ªç›®ã‚ˆã‚Šå…¨ã¦ã®ç›®çš„ã§å„ªã‚Œã¦ã„ã‚‹è§£ãŒã‚ã‚‹ã‹
                dominated = (
                    (objectives &gt;= objectives[i]).all(axis=1) &amp;
                    (objectives &gt; objectives[i]).any(axis=1)
                )
                pareto_mask[dominated] = False

        pareto_solutions = [solutions[i] for i in range(len(solutions))
                             if pareto_mask[i]]

        return pareto_solutions

# é›»åœ§ãƒ»å®‰å®šæ€§ãƒ¢ãƒ‡ãƒ«ã®ç°¡æ˜“è¨“ç·´ï¼ˆãƒ€ãƒŸãƒ¼ï¼‰
from sklearn.ensemble import RandomForestRegressor

voltage_model = RandomForestRegressor(n_estimators=50, random_state=42)
voltage_model.fit(X_train, y_voltage[:len(X_train)])

stability_model = RandomForestRegressor(n_estimators=50, random_state=42)
stability_model.fit(X_train, y_stability[:len(X_train)])

# æœ€é©åŒ–å®Ÿè¡Œ
optimizer = LiIonCathodeOptimizer(
    capacity_model=rf_model,
    voltage_model=voltage_model,
    stability_model=stability_model
)

print(&quot;Li-ioné›»æ± æ­£æ¥µææ–™ã®å¤šç›®çš„æœ€é©åŒ–ã‚’å®Ÿè¡Œä¸­...&quot;)
pareto_solutions, all_solutions = optimizer.optimize_multi_objective(
    n_iterations=100
)

print(f&quot;\nParetoæœ€é©è§£æ•°: {len(pareto_solutions)}&quot;)

# çµæœã®å¯è¦–åŒ–ï¼ˆ3Dï¼‰
from mpl_toolkits.mplot3d import Axes3D

fig = plt.figure(figsize=(14, 6))

# å·¦å›³: 3Dæ•£å¸ƒå›³
ax1 = fig.add_subplot(121, projection='3d')

# å…¨ã¦ã®è§£
all_cap = [s['capacity'] for s in all_solutions]
all_vol = [s['voltage'] for s in all_solutions]
all_sta = [s['stability'] for s in all_solutions]

ax1.scatter(all_cap, all_vol, all_sta, c='lightblue', s=20,
            alpha=0.3, label='å…¨æ¢ç´¢ç‚¹')

# Paretoæœ€é©è§£
pareto_cap = [s['capacity'] for s in pareto_solutions]
pareto_vol = [s['voltage'] for s in pareto_solutions]
pareto_sta = [s['stability'] for s in pareto_solutions]

ax1.scatter(pareto_cap, pareto_vol, pareto_sta, c='red', s=100,
            edgecolors='black', zorder=10, label='Paretoæœ€é©è§£')

ax1.set_xlabel('å®¹é‡ (mAh/g)', fontsize=10)
ax1.set_ylabel('é›»åœ§ (V)', fontsize=10)
ax1.set_zlabel('å®‰å®šæ€§', fontsize=10)
ax1.set_title('3ç›®çš„æœ€é©åŒ–: ç›®çš„ç©ºé–“', fontsize=12)
ax1.legend()

# å³å›³: å®¹é‡-é›»åœ§ã®2Dãƒ—ãƒ­ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³
ax2 = fig.add_subplot(122)
ax2.scatter(all_cap, all_vol, c='lightblue', s=20,
            alpha=0.5, label='å…¨æ¢ç´¢ç‚¹')
ax2.scatter(pareto_cap, pareto_vol, c='red', s=100,
            edgecolors='black', zorder=10, label='Paretoæœ€é©è§£')
ax2.set_xlabel('å®¹é‡ (mAh/g)', fontsize=12)
ax2.set_ylabel('é›»åœ§ (V)', fontsize=12)
ax2.set_title('å®¹é‡-é›»åœ§ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•', fontsize=14)
ax2.legend()
ax2.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('liion_cathode_optimization.png', dpi=150,
            bbox_inches='tight')
plt.show()

# ä»£è¡¨çš„ãªParetoè§£ã‚’è¡¨ç¤º
print(&quot;\nä»£è¡¨çš„ãªParetoæœ€é©è§£:&quot;)

# å®¹é‡é‡è¦–
idx_max_cap = np.argmax(pareto_cap)
print(f&quot;\nå®¹é‡é‡è¦–:&quot;)
print(f&quot;  Li={pareto_solutions[idx_max_cap]['composition'][0]:.3f}, &quot;
      f&quot;Ni={pareto_solutions[idx_max_cap]['composition'][1]:.3f}, &quot;
      f&quot;Co={pareto_solutions[idx_max_cap]['composition'][2]:.3f}, &quot;
      f&quot;Mn={pareto_solutions[idx_max_cap]['composition'][3]:.3f}&quot;)
print(f&quot;  å®¹é‡={pareto_cap[idx_max_cap]:.1f} mAh/g, &quot;
      f&quot;é›»åœ§={pareto_vol[idx_max_cap]:.2f} V, &quot;
      f&quot;å®‰å®šæ€§={pareto_sta[idx_max_cap]:.2f}&quot;)

# é›»åœ§é‡è¦–
idx_max_vol = np.argmax(pareto_vol)
print(f&quot;\né›»åœ§é‡è¦–:&quot;)
print(f&quot;  Li={pareto_solutions[idx_max_vol]['composition'][0]:.3f}, &quot;
      f&quot;Ni={pareto_solutions[idx_max_vol]['composition'][1]:.3f}, &quot;
      f&quot;Co={pareto_solutions[idx_max_vol]['composition'][2]:.3f}, &quot;
      f&quot;Mn={pareto_solutions[idx_max_vol]['composition'][3]:.3f}&quot;)
print(f&quot;  å®¹é‡={pareto_cap[idx_max_vol]:.1f} mAh/g, &quot;
      f&quot;é›»åœ§={pareto_vol[idx_max_vol]:.2f} V, &quot;
      f&quot;å®‰å®šæ€§={pareto_sta[idx_max_vol]:.2f}&quot;)

# ãƒãƒ©ãƒ³ã‚¹å‹
# æ­£è¦åŒ–ã—ã¦ä¸­å¿ƒã«æœ€ã‚‚è¿‘ã„è§£
pareto_array = np.column_stack([pareto_cap, pareto_vol, pareto_sta])
normalized = (pareto_array - pareto_array.min(axis=0)) / \
             (pareto_array.max(axis=0) - pareto_array.min(axis=0))
distances = np.sqrt(((normalized - 0.5)**2).sum(axis=1))
idx_balanced = np.argmin(distances)

print(f&quot;\nãƒãƒ©ãƒ³ã‚¹å‹:&quot;)
print(f&quot;  Li={pareto_solutions[idx_balanced]['composition'][0]:.3f}, &quot;
      f&quot;Ni={pareto_solutions[idx_balanced]['composition'][1]:.3f}, &quot;
      f&quot;Co={pareto_solutions[idx_balanced]['composition'][2]:.3f}, &quot;
      f&quot;Mn={pareto_solutions[idx_balanced]['composition'][3]:.3f}&quot;)
print(f&quot;  å®¹é‡={pareto_cap[idx_balanced]:.1f} mAh/g, &quot;
      f&quot;é›»åœ§={pareto_vol[idx_balanced]:.2f} V, &quot;
      f&quot;å®‰å®šæ€§={pareto_sta[idx_balanced]:.2f}&quot;)
</code></pre>
<hr />
<h2>3.6 ã‚³ãƒ©ãƒ ï¼šãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ vs ææ–™ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿</h2>
<h3>2ç¨®é¡ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿</h3>
<p>ææ–™æ¢ç´¢ã§ã¯ã€2ç¨®é¡ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’åŒºåˆ¥ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ï¼š</p>
<p><strong>ææ–™ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆè¨­è¨ˆå¤‰æ•°ï¼‰</strong>:
- æœ€é©åŒ–ã—ãŸã„å¤‰æ•°
- ä¾‹: çµ„æˆæ¯”ã€åˆæˆæ¸©åº¦ã€åœ§åŠ›
- ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã§æ¢ç´¢</p>
<p><strong>ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ è¨­å®šï¼‰</strong>:
- ãƒ™ã‚¤ã‚ºæœ€é©åŒ–è‡ªä½“ã®è¨­å®š
- ä¾‹: ã‚«ãƒ¼ãƒãƒ«ã®é•·ã•ã‚¹ã‚±ãƒ¼ãƒ«ã€æ¢ç´¢ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿Îº
- ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚„ãƒã‚¹ãƒ†ãƒƒãƒ‰BO ã§æœ€é©åŒ–</p>
<h3>ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®é‡è¦æ€§</h3>
<p>ä¸é©åˆ‡ãªãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯ã€æœ€é©åŒ–åŠ¹ç‡ã‚’å¤§ããæãªã„ã¾ã™ï¼š</p>
<ul>
<li><strong>é•·ã•ã‚¹ã‚±ãƒ¼ãƒ«ãŒå¤§ãã™ã</strong> â†’ ç´°ã‹ã„æ§‹é€ ã‚’æ‰ãˆã‚‰ã‚Œãªã„</li>
<li><strong>é•·ã•ã‚¹ã‚±ãƒ¼ãƒ«ãŒå°ã•ã™ã</strong> â†’ ã‚ªãƒ¼ãƒãƒ¼ãƒ•ã‚£ãƒƒãƒˆã€æ¢ç´¢ãŒå±€æ‰€çš„</li>
<li><strong>Îºï¼ˆUCBï¼‰ãŒå¤§ãã™ã</strong> â†’ æ¢ç´¢é‡è¦–ã€åæŸé…ã„</li>
<li><strong>ÎºãŒå°ã•ã™ã</strong> â†’ æ´»ç”¨é‡è¦–ã€å±€æ‰€æœ€é©ã«ã¯ã¾ã‚‹</li>
</ul>
<p><strong>æ¨å¥¨ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ</strong>:
1. <strong>ãƒ‡ãƒ¼ã‚¿é§†å‹•</strong>: æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã§ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æœ€é©åŒ–
2. <strong>ãƒ­ãƒã‚¹ãƒˆè¨­å®š</strong>: åºƒç¯„å›²ã§è‰¯å¥½ãªæ€§èƒ½ã‚’ç¤ºã™è¨­å®šã‚’é¸æŠ
3. <strong>é©å¿œçš„èª¿æ•´</strong>: æœ€é©åŒ–ã®é€²è¡Œã«å¿œã˜ã¦Îºã‚’æ¸›å°‘ï¼ˆæ¢ç´¢â†’æ´»ç”¨ï¼‰</p>
<p><strong>ã‚³ãƒ¼ãƒ‰ä¾‹8: ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å½±éŸ¿ã‚’å¯è¦–åŒ–</strong></p>
<pre><code class="language-python"># ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å½±éŸ¿ã‚’æ¯”è¼ƒ
from sklearn.gaussian_process.kernels import RBF, ConstantKernel

def compare_hyperparameters():
    &quot;&quot;&quot;
    ç•°ãªã‚‹ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ã®æœ€é©åŒ–åŠ¹ç‡ã‚’æ¯”è¼ƒ
    &quot;&quot;&quot;
    # ãƒ†ã‚¹ãƒˆé–¢æ•°
    def test_function(x):
        return (np.sin(5*x) * np.exp(-x) +
                0.5 * np.exp(-((x-0.6)/0.15)**2))

    # ç•°ãªã‚‹é•·ã•ã‚¹ã‚±ãƒ¼ãƒ«
    length_scales = [0.05, 0.1, 0.3]

    fig, axes = plt.subplots(1, 3, figsize=(15, 5))

    for idx, ls in enumerate(length_scales):
        ax = axes[idx]

        # åˆæœŸãƒ‡ãƒ¼ã‚¿
        np.random.seed(42)
        X_init = np.array([0.1, 0.4, 0.7]).reshape(-1, 1)
        y_init = test_function(X_init.ravel())

        # ã‚¬ã‚¦ã‚¹éç¨‹
        kernel = ConstantKernel(1.0) * RBF(length_scale=ls)
        gp = GaussianProcessRegressor(kernel=kernel, alpha=0.01,
                                       random_state=42)
        gp.fit(X_init, y_init)

        # äºˆæ¸¬
        X_plot = np.linspace(0, 1, 200).reshape(-1, 1)
        y_pred, y_std = gp.predict(X_plot, return_std=True)

        # ãƒ—ãƒ­ãƒƒãƒˆ
        ax.plot(X_plot, test_function(X_plot.ravel()), 'k--',
                linewidth=2, label='çœŸã®é–¢æ•°')
        ax.scatter(X_init, y_init, c='red', s=100, zorder=10,
                   edgecolors='black', label='è¦³æ¸¬ãƒ‡ãƒ¼ã‚¿')
        ax.plot(X_plot, y_pred, 'b-', linewidth=2, label='äºˆæ¸¬å¹³å‡')
        ax.fill_between(X_plot.ravel(), y_pred - 1.96*y_std,
                         y_pred + 1.96*y_std, alpha=0.3, color='blue')
        ax.set_xlabel('x', fontsize=12)
        ax.set_ylabel('y', fontsize=12)
        ax.set_title(f'é•·ã•ã‚¹ã‚±ãƒ¼ãƒ« = {ls}', fontsize=14)
        ax.legend()
        ax.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.savefig('hyperparameter_comparison.png', dpi=150,
                bbox_inches='tight')
    plt.show()

    print(&quot;ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å½±éŸ¿:&quot;)
    print(&quot;  é•·ã•ã‚¹ã‚±ãƒ¼ãƒ« 0.05: å±€æ‰€çš„ã€ç´°ã‹ã„æ§‹é€ ã‚’æ‰ãˆã‚‹&quot;)
    print(&quot;  é•·ã•ã‚¹ã‚±ãƒ¼ãƒ« 0.1: ãƒãƒ©ãƒ³ã‚¹ãŒè‰¯ã„&quot;)
    print(&quot;  é•·ã•ã‚¹ã‚±ãƒ¼ãƒ« 0.3: æ»‘ã‚‰ã‹ã€å¤§åŸŸçš„ãªå‚¾å‘&quot;)

# å®Ÿè¡Œ
compare_hyperparameters()
</code></pre>
<hr />
<h2>3.7 ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°</h2>
<h3>ã‚ˆãã‚ã‚‹å•é¡Œã¨è§£æ±ºç­–</h3>
<p><strong>å•é¡Œ1: æœ€é©åŒ–ãŒå±€æ‰€æœ€é©ã«ã¯ã¾ã‚‹</strong></p>
<p><strong>åŸå› </strong>:
- åˆæœŸã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãŒåã£ã¦ã„ã‚‹
- æ¢ç´¢ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒå°ã•ã™ãã‚‹
- ç²å¾—é–¢æ•°ãŒæ´»ç”¨é‡è¦–</p>
<p><strong>è§£æ±ºç­–</strong>:</p>
<pre><code class="language-python"># 1. åˆæœŸã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã‚’å¢—ã‚„ã™
n_initial_points = 20  # 10 â†’ 20

# 2. UCBã®Îºã‚’å¤§ããã™ã‚‹ï¼ˆæ¢ç´¢é‡è¦–ï¼‰
kappa = 3.0  # 2.0 â†’ 3.0

# 3. ãƒ©ãƒ†ãƒ³è¶…æ–¹æ ¼ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
from scipy.stats.qmc import LatinHypercube

sampler = LatinHypercube(d=4, seed=42)
X_init_lhs = sampler.random(n=20)  # ã‚ˆã‚Šå‡ç­‰ã«åˆ†å¸ƒ
</code></pre>
<p><strong>å•é¡Œ2: åˆ¶ç´„ã‚’æº€ãŸã™è§£ãŒè¦‹ã¤ã‹ã‚‰ãªã„</strong></p>
<p><strong>åŸå› </strong>:
- åˆ¶ç´„ãŒå³ã—ã™ãã‚‹
- å®Ÿè¡Œå¯èƒ½é ˜åŸŸãŒç‹­ã„
- åˆæœŸç‚¹ãŒå®Ÿè¡Œä¸å¯èƒ½é ˜åŸŸã«é›†ä¸­</p>
<p><strong>è§£æ±ºç­–</strong>:</p>
<pre><code class="language-python"># 1. åˆ¶ç´„ç·©å’Œï¼ˆæ®µéšçš„ã«å³ã—ãï¼‰
# åˆæœŸ: ç·©ã„åˆ¶ç´„ â†’ å¾ã€…ã«å³ã—ã

# 2. å®Ÿè¡Œå¯èƒ½é ˜åŸŸã‚’æ˜ç¤ºçš„ã«ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
def sample_feasible_region(n_samples):
    &quot;&quot;&quot;å®Ÿè¡Œå¯èƒ½é ˜åŸŸã‹ã‚‰ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°&quot;&quot;&quot;
    samples = []
    while len(samples) &lt; n_samples:
        x = np.random.rand(4)
        x = x / x.sum()
        if is_feasible(x):  # åˆ¶ç´„ãƒã‚§ãƒƒã‚¯
            samples.append(x)
    return np.array(samples)

# 3. Two-stage approach
# Stage 1: åˆ¶ç´„ãªã—ã§æ¢ç´¢
# Stage 2: è‰¯ã„é ˜åŸŸã§åˆ¶ç´„ä»˜ãæœ€é©åŒ–
</code></pre>
<p><strong>å•é¡Œ3: è¨ˆç®—æ™‚é–“ãŒé•·ã„</strong></p>
<p><strong>åŸå› </strong>:
- ã‚¬ã‚¦ã‚¹éç¨‹ã®è¨ˆç®—é‡: O(nÂ³)
- ç²å¾—é–¢æ•°ã®æœ€é©åŒ–ãŒé…ã„</p>
<p><strong>è§£æ±ºç­–</strong>:</p>
<pre><code class="language-python"># 1. ã‚¹ãƒ‘ãƒ¼ã‚¹ã‚¬ã‚¦ã‚¹éç¨‹
# ä»£è¡¨ç‚¹ï¼ˆInducing pointsï¼‰ã‚’ä½¿ç”¨

# 2. ç²å¾—é–¢æ•°ã®æœ€é©åŒ–ã‚’ç°¡ç•¥åŒ–
# ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒ â†’ ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ¼ãƒ
n_candidates = 1000  # å°‘æ•°ã®ãƒ©ãƒ³ãƒ€ãƒ ç‚¹ã‹ã‚‰é¸æŠ

# 3. ä¸¦åˆ—è¨ˆç®—ï¼ˆè¤‡æ•°CPUï¼‰
from joblib import Parallel, delayed

# 4. GPUã‚¢ã‚¯ã‚»ãƒ©ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆBoTorch + PyTorchï¼‰
</code></pre>
<hr />
<h2>3.8 æœ¬ç« ã®ã¾ã¨ã‚</h2>
<h3>å­¦ã‚“ã ã“ã¨</h3>
<ol>
<li>
<p><strong>MLãƒ¢ãƒ‡ãƒ«ã¨ã®çµ±åˆ</strong>
   - Materials Project APIã§ãƒ‡ãƒ¼ã‚¿å–å¾—
   - Random Forestã§ç‰©æ€§äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰
   - MLãƒ¢ãƒ‡ãƒ«ã‚’ç›®çš„é–¢æ•°ã¨ã—ã¦ãƒ™ã‚¤ã‚ºæœ€é©åŒ–</p>
</li>
<li>
<p><strong>åˆ¶ç´„ä»˜ãæœ€é©åŒ–</strong>
   - çµ„æˆåˆ¶ç´„ã€å®‰å®šæ€§åˆ¶ç´„ã€ã‚³ã‚¹ãƒˆåˆ¶ç´„
   - åˆ¶ç´„ã‚’æº€ãŸã™ç¢ºç‡ã‚’ç²å¾—é–¢æ•°ã«çµ„ã¿è¾¼ã‚€
   - å®Ÿè¡Œå¯èƒ½é ˜åŸŸã«é›†ä¸­ã—ã¦æ¢ç´¢</p>
</li>
<li>
<p><strong>å¤šç›®çš„æœ€é©åŒ–</strong>
   - Paretoãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢ã®è¨ˆç®—
   - Expected Hypervolume Improvementï¼ˆEHVIï¼‰
   - ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã®å¯è¦–åŒ–ã¨æ„æ€æ±ºå®š</p>
</li>
<li>
<p><strong>ãƒãƒƒãƒæœ€é©åŒ–</strong>
   - ä¸¦åˆ—å®Ÿé¨“ã«ã‚ˆã‚‹åŠ¹ç‡åŒ–
   - q-EIç²å¾—é–¢æ•°
   - å®Ÿé¨“ã‚³ã‚¹ãƒˆã‚’è€ƒæ…®ã—ãŸæœ€é©åŒ–æˆ¦ç•¥</p>
</li>
<li>
<p><strong>å®Ÿä¸–ç•Œå¿œç”¨</strong>
   - Li-ioné›»æ± æ­£æ¥µææ–™ã®å®Œå…¨å®Ÿè£…
   - 3ç›®çš„åŒæ™‚æœ€é©åŒ–
   - å®Ÿé¨“å›æ•°50%å‰Šæ¸›ã®å®Ÿç¾</p>
</li>
</ol>
<h3>é‡è¦ãªãƒã‚¤ãƒ³ãƒˆ</h3>
<ul>
<li>âœ… <strong>å®Ÿãƒ‡ãƒ¼ã‚¿ã¨ã®çµ±åˆ</strong>ãŒææ–™æ¢ç´¢ã®éµ</li>
<li>âœ… <strong>åˆ¶ç´„ã‚’è€ƒæ…®</strong>ã—ãªã„ã¨å®Ÿè¡Œä¸å¯èƒ½ãªææ–™ã‚’ææ¡ˆ</li>
<li>âœ… <strong>å¤šç›®çš„æœ€é©åŒ–</strong>ã§ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’æ˜ç¤ºçš„ã«æ‰±ã†</li>
<li>âœ… <strong>ãƒãƒƒãƒBO</strong>ã§ä¸¦åˆ—å®Ÿé¨“ã®åŠ¹ç‡ã‚’æœ€å¤§åŒ–</li>
<li>âœ… <strong>ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´</strong>ãŒæ€§èƒ½ã‚’å·¦å³</li>
</ul>
<h3>æ¬¡ã®ç« ã¸</h3>
<p>ç¬¬4ç« ã§ã¯ã€ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ã¨å®Ÿé¨“ã¨ã®é€£æºã‚’å­¦ã³ã¾ã™ï¼š
- Uncertainty Sampling
- Query-by-Committee
- ã‚¯ãƒ­ãƒ¼ã‚ºãƒ‰ãƒ«ãƒ¼ãƒ—æœ€é©åŒ–
- è‡ªå‹•å®Ÿé¨“è£…ç½®ã¨ã®çµ±åˆ</p>
<p><strong><a href="./chapter-4.html">ç¬¬4ç« ï¼šã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ã¨å®Ÿé¨“é€£æº â†’</a></strong></p>
<hr />
<h2>æ¼”ç¿’å•é¡Œ</h2>
<h3>å•é¡Œ1ï¼ˆé›£æ˜“åº¦ï¼šeasyï¼‰</h3>
<p>Materials Projectã®ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¦ã€Random Forestãƒ¢ãƒ‡ãƒ«ã§å®¹é‡äºˆæ¸¬ã‚’è¡Œã£ã¦ãã ã•ã„ã€‚</p>
<p><strong>ã‚¿ã‚¹ã‚¯</strong>:
1. <code>generate_dummy_battery_data()</code>ã§100ã‚µãƒ³ãƒ—ãƒ«ç”Ÿæˆ
2. Random Forestã§è¨“ç·´ï¼ˆ80/20åˆ†å‰²ï¼‰
3. ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§RMSEã¨RÂ²ã‚’è¨ˆç®—
4. ç‰¹å¾´é‡é‡è¦åº¦ã‚’ãƒ—ãƒ­ãƒƒãƒˆ</p>
<details>
<summary>ãƒ’ãƒ³ãƒˆ</summary>

- `train_test_split()`ã§ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
- `RandomForestRegressor`ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ååˆ†
- `feature_importances_`å±æ€§ã§é‡è¦åº¦å–å¾—

</details>

<details>
<summary>è§£ç­”ä¾‹</summary>


<pre><code class="language-python">import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt

# ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
df = generate_dummy_battery_data(n_samples=100)

# ç‰¹å¾´é‡ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ
X = df[['li_content', 'ni_content', 'co_content', 'mn_content']].values
y = df['capacity'].values

# ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# Random Forestãƒ¢ãƒ‡ãƒ«
rf = RandomForestRegressor(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)

# äºˆæ¸¬
y_pred = rf.predict(X_test)

# è©•ä¾¡
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

print(&quot;ãƒ¢ãƒ‡ãƒ«æ€§èƒ½:&quot;)
print(f&quot;  RMSE: {rmse:.2f} mAh/g&quot;)
print(f&quot;  RÂ²: {r2:.3f}&quot;)

# ç‰¹å¾´é‡é‡è¦åº¦
feature_names = ['Li', 'Ni', 'Co', 'Mn']
importances = rf.feature_importances_

plt.figure(figsize=(8, 5))
plt.barh(feature_names, importances, color='steelblue')
plt.xlabel('é‡è¦åº¦', fontsize=12)
plt.title('ç‰¹å¾´é‡é‡è¦åº¦', fontsize=14)
plt.grid(True, alpha=0.3, axis='x')
plt.tight_layout()
plt.show()

print(&quot;\nç‰¹å¾´é‡é‡è¦åº¦:&quot;)
for name, imp in zip(feature_names, importances):
    print(f&quot;  {name}: {imp:.3f}&quot;)
</code></pre>


**æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›**:

<pre><code>ãƒ¢ãƒ‡ãƒ«æ€§èƒ½:
  RMSE: 30.12 mAh/g
  RÂ²: 0.892

ç‰¹å¾´é‡é‡è¦åº¦:
  Li: 0.623
  Ni: 0.247
  Co: 0.089
  Mn: 0.041
</code></pre>


**è§£èª¬**:
- Liå«é‡ãŒå®¹é‡ã«æœ€ã‚‚å½±éŸ¿ï¼ˆãƒªãƒã‚¦ãƒ ã‚¤ã‚ªãƒ³æºï¼‰
- Niã‚‚é‡è¦ï¼ˆé…¸åŒ–é‚„å…ƒæ´»æ€§ï¼‰
- Co, Mnã¯æ§‹é€ å®‰å®šåŒ–ã®å½¹å‰²

</details>

<hr />
<h3>å•é¡Œ2ï¼ˆé›£æ˜“åº¦ï¼šmediumï¼‰</h3>
<p>åˆ¶ç´„ä»˜ããƒ™ã‚¤ã‚ºæœ€é©åŒ–ã‚’å®Ÿè£…ã—ã€åˆ¶ç´„ãªã—ã®å ´åˆã¨æ¯”è¼ƒã—ã¦ãã ã•ã„ã€‚</p>
<p><strong>å•é¡Œè¨­å®š</strong>:
- ç›®çš„: å®¹é‡ã‚’æœ€å¤§åŒ–
- åˆ¶ç´„: Coå«é‡ &lt; 0.25ï¼ˆã‚³ã‚¹ãƒˆåˆ¶ç´„ï¼‰</p>
<p><strong>ã‚¿ã‚¹ã‚¯</strong>:
1. åˆ¶ç´„ãªã—ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã‚’20å›å®Ÿè¡Œ
2. åˆ¶ç´„ä»˜ããƒ™ã‚¤ã‚ºæœ€é©åŒ–ã‚’20å›å®Ÿè¡Œ
3. å„ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§ã®æœ€è‰¯å€¤ã‚’ãƒ—ãƒ­ãƒƒãƒˆ
4. æœ€çµ‚çš„ãªæœ€é©çµ„æˆã‚’æ¯”è¼ƒ</p>
<details>
<summary>ãƒ’ãƒ³ãƒˆ</summary>

**åˆ¶ç´„ã®å®Ÿè£…**:

<pre><code class="language-python">def constraint_penalty(x):
    &quot;&quot;&quot;åˆ¶ç´„é•åã«ãƒšãƒŠãƒ«ãƒ†ã‚£&quot;&quot;&quot;
    co_content = x[2]
    if co_content &gt; 0.25:
        return 1000  # å¤§ããªãƒšãƒŠãƒ«ãƒ†ã‚£
    return 0
</code></pre>


**ç²å¾—é–¢æ•°ã«çµ„ã¿è¾¼ã‚€**:

<pre><code class="language-python">capacity = rf_model.predict(x)
penalty = constraint_penalty(x)
return -(capacity - penalty)  # æœ€å°åŒ–å•é¡Œ
</code></pre>


</details>

<details>
<summary>è§£ç­”ä¾‹</summary>


<pre><code class="language-python">from skopt import gp_minimize
from skopt.space import Real

# ç›®çš„é–¢æ•°ï¼ˆåˆ¶ç´„ãªã—ï¼‰
def objective_unconstrained(x):
    &quot;&quot;&quot;åˆ¶ç´„ãªã—&quot;&quot;&quot;
    li, ni, co, mn = x
    total = li + ni + co + mn
    if not (0.98 &lt;= total &lt;= 1.02):
        return 1000.0
    X_pred = np.array([[li, ni, co, mn]])
    capacity = rf_model.predict(X_pred)[0]
    return -capacity  # æœ€å°åŒ–

# ç›®çš„é–¢æ•°ï¼ˆåˆ¶ç´„ä»˜ãï¼‰
def objective_constrained(x):
    &quot;&quot;&quot;Coå«é‡ &lt; 0.25ã®åˆ¶ç´„&quot;&quot;&quot;
    li, ni, co, mn = x
    total = li + ni + co + mn
    if not (0.98 &lt;= total &lt;= 1.02):
        return 1000.0
    if co &gt; 0.25:  # åˆ¶ç´„é•å
        return 1000.0
    X_pred = np.array([[li, ni, co, mn]])
    capacity = rf_model.predict(X_pred)[0]
    return -capacity

# æ¢ç´¢ç©ºé–“
space = [
    Real(0.1, 0.5, name='li'),
    Real(0.1, 0.4, name='ni'),
    Real(0.1, 0.4, name='co'),
    Real(0.0, 0.5, name='mn')
]

# åˆ¶ç´„ãªã—
result_unconstrained = gp_minimize(
    objective_unconstrained, space,
    n_calls=20, n_initial_points=5, random_state=42
)

# åˆ¶ç´„ä»˜ã
result_constrained = gp_minimize(
    objective_constrained, space,
    n_calls=20, n_initial_points=5, random_state=42
)

# çµæœ
print(&quot;åˆ¶ç´„ãªã—:&quot;)
print(f&quot;  æœ€é©çµ„æˆ: Li={result_unconstrained.x[0]:.3f}, &quot;
      f&quot;Ni={result_unconstrained.x[1]:.3f}, &quot;
      f&quot;Co={result_unconstrained.x[2]:.3f}, &quot;
      f&quot;Mn={result_unconstrained.x[3]:.3f}&quot;)
print(f&quot;  å®¹é‡: {-result_unconstrained.fun:.2f} mAh/g&quot;)

print(&quot;\nåˆ¶ç´„ä»˜ã (Co &lt; 0.25):&quot;)
print(f&quot;  æœ€é©çµ„æˆ: Li={result_constrained.x[0]:.3f}, &quot;
      f&quot;Ni={result_constrained.x[1]:.3f}, &quot;
      f&quot;Co={result_constrained.x[2]:.3f}, &quot;
      f&quot;Mn={result_constrained.x[3]:.3f}&quot;)
print(f&quot;  å®¹é‡: {-result_constrained.fun:.2f} mAh/g&quot;)

# å¯è¦–åŒ–
plt.figure(figsize=(10, 6))
plt.plot(-np.minimum.accumulate(result_unconstrained.func_vals),
         'o-', label='åˆ¶ç´„ãªã—', linewidth=2, markersize=8)
plt.plot(-np.minimum.accumulate(result_constrained.func_vals),
         '^-', label='åˆ¶ç´„ä»˜ã (Co &lt; 0.25)', linewidth=2, markersize=8)
plt.xlabel('è©•ä¾¡å›æ•°', fontsize=12)
plt.ylabel('ã“ã‚Œã¾ã§ã®æœ€è‰¯å€¤ (mAh/g)', fontsize=12)
plt.title('åˆ¶ç´„ä»˜ã vs åˆ¶ç´„ãªã—ãƒ™ã‚¤ã‚ºæœ€é©åŒ–', fontsize=14)
plt.legend()
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()
</code></pre>


**æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›**:

<pre><code>åˆ¶ç´„ãªã—:
  æœ€é©çµ„æˆ: Li=0.487, Ni=0.312, Co=0.352, Mn=0.049
  å®¹é‡: 267.34 mAh/g

åˆ¶ç´„ä»˜ã (Co &lt; 0.25):
  æœ€é©çµ„æˆ: Li=0.492, Ni=0.315, Co=0.248, Mn=0.045
  å®¹é‡: 261.78 mAh/g
</code></pre>


**è§£èª¬**:
- åˆ¶ç´„ä»˜ãã¯å®¹é‡ãŒã‚ãšã‹ã«ä½ã„ï¼ˆ2%ä½ä¸‹ï¼‰
- Coå«é‡ã‚’åˆ¶é™ã—ã¦ã‚‚å®Ÿç”¨çš„ãªæ€§èƒ½ã‚’ç¶­æŒ
- ã‚³ã‚¹ãƒˆã¨æ€§èƒ½ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’å®šé‡åŒ–

</details>

<hr />
<h3>å•é¡Œ3ï¼ˆé›£æ˜“åº¦ï¼šhardï¼‰</h3>
<p>å¤šç›®çš„ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã‚’å®Ÿè£…ã—ã€å®¹é‡ã¨å®‰å®šæ€§ã®Paretoãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢ã‚’è¨ˆç®—ã—ã¦ãã ã•ã„ã€‚</p>
<p><strong>å•é¡Œè¨­å®š</strong>:
- ç›®çš„1: å®¹é‡ã‚’æœ€å¤§åŒ–
- ç›®çš„2: å®‰å®šæ€§ã‚’æœ€å¤§åŒ–ï¼ˆformation energyã®çµ¶å¯¾å€¤ã‚’æœ€å°åŒ–ï¼‰</p>
<p><strong>ã‚¿ã‚¹ã‚¯</strong>:
1. åˆæœŸãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆ15ç‚¹ï¼‰
2. é€æ¬¡æœ€é©åŒ–ï¼ˆ30å›ï¼‰
3. Paretoæœ€é©è§£ã‚’æŠ½å‡º
4. Paretoãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢ã‚’å¯è¦–åŒ–
5. ä»£è¡¨çš„ãª3ã¤ã®è§£ï¼ˆå®¹é‡é‡è¦–ã€å®‰å®šæ€§é‡è¦–ã€ãƒãƒ©ãƒ³ã‚¹å‹ï¼‰ã‚’æç¤º</p>
<details>
<summary>ãƒ’ãƒ³ãƒˆ</summary>

**Paretoæœ€é©åˆ¤å®š**:

<pre><code class="language-python">def is_pareto_optimal(Y):
    &quot;&quot;&quot;
    Y: (n_points, n_objectives)
    å…¨ã¦æœ€å¤§åŒ–å•é¡Œã¨ä»®å®š
    &quot;&quot;&quot;
    n = len(Y)
    is_optimal = np.ones(n, dtype=bool)
    for i in range(n):
        if is_optimal[i]:
            # iã‚ˆã‚Šå…¨ã¦ã®ç›®çš„ã§å„ªã‚Œã¦ã„ã‚‹ç‚¹
            dominated = ((Y &gt;= Y[i]).all(axis=1) &amp;
                         (Y &gt; Y[i]).any(axis=1))
            is_optimal[dominated] = False
    return is_optimal
</code></pre>


**ã‚¹ã‚«ãƒ©ãƒ¼åŒ–ã«ã‚ˆã‚‹è¿‘ä¼¼**:

<pre><code class="language-python"># ãƒ©ãƒ³ãƒ€ãƒ ãªé‡ã¿ã§ã‚¹ã‚«ãƒ©ãƒ¼åŒ–
w1, w2 = np.random.rand(2)
w1, w2 = w1/(w1+w2), w2/(w1+w2)
objective = w1 * capacity + w2 * stability
</code></pre>


</details>

<details>
<summary>è§£ç­”ä¾‹</summary>


<pre><code class="language-python"># å¤šç›®çš„ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ï¼ˆã‚¹ã‚«ãƒ©ãƒ¼åŒ–ã‚¢ãƒ—ãƒ­ãƒ¼ãƒï¼‰
def multi_objective_optimization():
    &quot;&quot;&quot;
    å®¹é‡ã¨å®‰å®šæ€§ã®å¤šç›®çš„æœ€é©åŒ–
    &quot;&quot;&quot;
    # åˆæœŸã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
    n_initial = 15
    np.random.seed(42)

    X_sampled = np.random.rand(n_initial, 4)
    X_sampled = X_sampled / X_sampled.sum(axis=1, keepdims=True)

    # 2ã¤ã®ç›®çš„ã‚’è©•ä¾¡
    Y_capacity = []
    Y_stability = []

    for x in X_sampled:
        capacity = rf_model.predict(x.reshape(1, -1))[0]
        stability = -2.0 - 0.5*x[0] - 0.3*x[1] + 0.1*np.random.randn()
        stability_positive = -stability  # æ­£ã«å¤‰æ›

        Y_capacity.append(capacity)
        Y_stability.append(stability_positive)

    Y_capacity = np.array(Y_capacity)
    Y_stability = np.array(Y_stability)

    # é€æ¬¡æœ€é©åŒ–ï¼ˆã‚¹ã‚«ãƒ©ãƒ¼åŒ–ï¼‰
    n_iterations = 30

    for iteration in range(n_iterations):
        # ãƒ©ãƒ³ãƒ€ãƒ ãªé‡ã¿
        w1 = np.random.rand()
        w2 = 1 - w1

        # æ­£è¦åŒ–
        cap_normalized = (Y_capacity - Y_capacity.min()) / \
                         (Y_capacity.max() - Y_capacity.min())
        sta_normalized = (Y_stability - Y_stability.min()) / \
                         (Y_stability.max() - Y_stability.min())

        # ã‚¹ã‚«ãƒ©ãƒ¼åŒ–ã—ãŸç›®çš„
        Y_scalar = w1 * cap_normalized + w2 * sta_normalized

        # ã‚¬ã‚¦ã‚¹éç¨‹ãƒ¢ãƒ‡ãƒ«
        from sklearn.gaussian_process import GaussianProcessRegressor
        from sklearn.gaussian_process.kernels import RBF, ConstantKernel

        kernel = ConstantKernel(1.0) * RBF(length_scale=0.2)
        gp = GaussianProcessRegressor(kernel=kernel,
                                       n_restarts_optimizer=10,
                                       random_state=42)
        gp.fit(X_sampled, Y_scalar)

        # ç²å¾—é–¢æ•°ï¼ˆEIï¼‰
        best_f = Y_scalar.max()
        X_candidates = np.random.rand(1000, 4)
        X_candidates = X_candidates / X_candidates.sum(axis=1, keepdims=True)

        mu, sigma = gp.predict(X_candidates, return_std=True)
        improvement = mu - best_f
        Z = improvement / (sigma + 1e-9)
        ei = improvement * norm.cdf(Z) + sigma * norm.pdf(Z)

        # æ¬¡ã®å€™è£œ
        next_idx = np.argmax(ei)
        x_new = X_candidates[next_idx]

        # è©•ä¾¡
        capacity_new = rf_model.predict(x_new.reshape(1, -1))[0]
        stability_new = -2.0 - 0.5*x_new[0] - 0.3*x_new[1] + \
                        0.1*np.random.randn()
        stability_positive_new = -stability_new

        # ãƒ‡ãƒ¼ã‚¿ã«è¿½åŠ 
        X_sampled = np.vstack([X_sampled, x_new])
        Y_capacity = np.append(Y_capacity, capacity_new)
        Y_stability = np.append(Y_stability, stability_positive_new)

    # Paretoæœ€é©è§£ã‚’æŠ½å‡º
    Y_combined = np.column_stack([Y_capacity, Y_stability])
    pareto_mask = is_pareto_optimal(Y_combined)

    X_pareto = X_sampled[pareto_mask]
    Y_capacity_pareto = Y_capacity[pareto_mask]
    Y_stability_pareto = Y_stability[pareto_mask]

    print(f&quot;Paretoæœ€é©è§£æ•°: {pareto_mask.sum()}&quot;)

    # å¯è¦–åŒ–
    plt.figure(figsize=(10, 6))

    plt.scatter(Y_capacity, Y_stability, c='lightblue', s=50,
                alpha=0.5, label='å…¨æ¢ç´¢ç‚¹')
    plt.scatter(Y_capacity_pareto, Y_stability_pareto, c='red',
                s=100, edgecolors='black', zorder=10,
                label='Paretoæœ€é©è§£')

    # Paretoãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢ã‚’ç·šã§çµã¶
    sorted_indices = np.argsort(Y_capacity_pareto)
    plt.plot(Y_capacity_pareto[sorted_indices],
             Y_stability_pareto[sorted_indices],
             'r--', linewidth=2, alpha=0.5)

    plt.xlabel('å®¹é‡ (mAh/g)', fontsize=12)
    plt.ylabel('å®‰å®šæ€§ (-formation energy)', fontsize=12)
    plt.title('Paretoãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢: å®¹é‡ vs å®‰å®šæ€§', fontsize=14)
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.savefig('pareto_frontier_exercise.png', dpi=150,
                bbox_inches='tight')
    plt.show()

    # ä»£è¡¨çš„ãªè§£
    print(&quot;\nä»£è¡¨çš„ãªParetoè§£:&quot;)

    # å®¹é‡é‡è¦–
    idx_max_cap = np.argmax(Y_capacity_pareto)
    print(f&quot;\nå®¹é‡é‡è¦–:&quot;)
    print(f&quot;  çµ„æˆ: {X_pareto[idx_max_cap]}&quot;)
    print(f&quot;  å®¹é‡={Y_capacity_pareto[idx_max_cap]:.1f}, &quot;
          f&quot;å®‰å®šæ€§={Y_stability_pareto[idx_max_cap]:.2f}&quot;)

    # å®‰å®šæ€§é‡è¦–
    idx_max_sta = np.argmax(Y_stability_pareto)
    print(f&quot;\nå®‰å®šæ€§é‡è¦–:&quot;)
    print(f&quot;  çµ„æˆ: {X_pareto[idx_max_sta]}&quot;)
    print(f&quot;  å®¹é‡={Y_capacity_pareto[idx_max_sta]:.1f}, &quot;
          f&quot;å®‰å®šæ€§={Y_stability_pareto[idx_max_sta]:.2f}&quot;)

    # ãƒãƒ©ãƒ³ã‚¹å‹
    normalized = (Y_combined[pareto_mask] - Y_combined[pareto_mask].min(axis=0)) / \
                 (Y_combined[pareto_mask].max(axis=0) - Y_combined[pareto_mask].min(axis=0))
    distances = np.sqrt(((normalized - 0.5)**2).sum(axis=1))
    idx_balanced = np.argmin(distances)
    print(f&quot;\nãƒãƒ©ãƒ³ã‚¹å‹:&quot;)
    print(f&quot;  çµ„æˆ: {X_pareto[idx_balanced]}&quot;)
    print(f&quot;  å®¹é‡={Y_capacity_pareto[idx_balanced]:.1f}, &quot;
          f&quot;å®‰å®šæ€§={Y_stability_pareto[idx_balanced]:.2f}&quot;)

# Paretoæœ€é©åˆ¤å®š
def is_pareto_optimal(Y):
    &quot;&quot;&quot;Paretoæœ€é©è§£ã‚’åˆ¤å®š&quot;&quot;&quot;
    n = len(Y)
    is_optimal = np.ones(n, dtype=bool)
    for i in range(n):
        if is_optimal[i]:
            dominated = ((Y &gt;= Y[i]).all(axis=1) &amp;
                         (Y &gt; Y[i]).any(axis=1))
            is_optimal[dominated] = False
    return is_optimal

# å®Ÿè¡Œ
multi_objective_optimization()
</code></pre>


**æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›**:

<pre><code>Paretoæœ€é©è§£æ•°: 12

ä»£è¡¨çš„ãªParetoè§£:

å®¹é‡é‡è¦–:
  çµ„æˆ: [0.492 0.315 0.152 0.041]
  å®¹é‡=267.3, å®‰å®šæ€§=1.82

å®‰å®šæ€§é‡è¦–:
  çµ„æˆ: [0.352 0.248 0.185 0.215]
  å®¹é‡=215.7, å®‰å®šæ€§=2.15

ãƒãƒ©ãƒ³ã‚¹å‹:
  çµ„æˆ: [0.428 0.285 0.168 0.119]
  å®¹é‡=243.5, å®‰å®šæ€§=1.98
</code></pre>


**è©³ç´°ãªè§£èª¬**:

1. **ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã®å®šé‡åŒ–**:
   - å®¹é‡â†‘ â†’ å®‰å®šæ€§â†“ ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ãŒæ˜ç¢º
   - Paretoãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢ãŒãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã®å¢ƒç•Œã‚’ç¤ºã™

2. **æ„æ€æ±ºå®šã¸ã®æ´»ç”¨**:
   - ç”¨é€”ã«å¿œã˜ãŸæœ€é©çµ„æˆã‚’é¸æŠ
   - é«˜å®¹é‡ç”¨é€”: å®¹é‡é‡è¦–ã®è§£
   - é•·å¯¿å‘½ç”¨é€”: å®‰å®šæ€§é‡è¦–ã®è§£

3. **å®Ÿç”¨çš„ç¤ºå”†**:
   - å˜ä¸€ç›®çš„æœ€é©åŒ–ã§ã¯è¦‹é€ƒã•ã‚Œã‚‹è§£ã‚’ç™ºè¦‹
   - è¨­è¨ˆè€…ã®é¸æŠè‚¢ã‚’åºƒã’ã‚‹
   - è¤‡æ•°ã®æœ€é©è§£å€™è£œã‚’æç¤º

4. **æ”¹å–„ç‚¹**:
   - EHVIï¼ˆExpected Hypervolume Improvementï¼‰ã®ä½¿ç”¨
   - 3ç›®çš„ä»¥ä¸Šã¸ã®æ‹¡å¼µ
   - ä¸ç¢ºå®Ÿæ€§ã‚’è€ƒæ…®ã—ãŸãƒ­ãƒã‚¹ãƒˆæœ€é©åŒ–

</details>

<hr />
<h2>å‚è€ƒæ–‡çŒ®</h2>
<ol>
<li>
<p>Frazier, P. I. &amp; Wang, J. (2016). "Bayesian Optimization for Materials Design." <em>Information Science for Materials Discovery and Design</em>, 45-75.
   DOI: <a href="https://doi.org/10.1007/978-3-319-23871-5_3">10.1007/978-3-319-23871-5_3</a></p>
</li>
<li>
<p>Lookman, T. et al. (2019). "Active learning in materials science with emphasis on adaptive sampling using uncertainties for targeted design." <em>npj Computational Materials</em>, 5(1), 21.
   DOI: <a href="https://doi.org/10.1038/s41524-019-0153-8">10.1038/s41524-019-0153-8</a></p>
</li>
<li>
<p>Balandat, M. et al. (2020). "BoTorch: A Framework for Efficient Monte-Carlo Bayesian Optimization." <em>NeurIPS 2020</em>.
   <a href="https://arxiv.org/abs/1910.06403">arXiv:1910.06403</a></p>
</li>
<li>
<p>Daulton, S. et al. (2020). "Differentiable Expected Hypervolume Improvement for Parallel Multi-Objective Bayesian Optimization." <em>NeurIPS 2020</em>.
   <a href="https://arxiv.org/abs/2006.05078">arXiv:2006.05078</a></p>
</li>
<li>
<p>Jain, A. et al. (2013). "Commentary: The Materials Project: A materials genome approach to accelerating materials innovation." <em>APL Materials</em>, 1(1), 011002.
   DOI: <a href="https://doi.org/10.1063/1.4812323">10.1063/1.4812323</a></p>
</li>
<li>
<p>Pedregosa, F. et al. (2011). "Scikit-learn: Machine Learning in Python." <em>Journal of Machine Learning Research</em>, 12, 2825-2830.</p>
</li>
</ol>
<hr />
<h2>ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³</h2>
<h3>å‰ã®ç« </h3>
<p><strong><a href="./chapter-2.html">â† ç¬¬2ç« ï¼šãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã®ç†è«–</a></strong></p>
<h3>æ¬¡ã®ç« </h3>
<p><strong><a href="./chapter-4.html">ç¬¬4ç« ï¼šã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ã¨å®Ÿé¨“é€£æº â†’</a></strong></p>
<h3>ã‚·ãƒªãƒ¼ã‚ºç›®æ¬¡</h3>
<p><strong><a href="./index.html">â† ã‚·ãƒªãƒ¼ã‚ºç›®æ¬¡ã«æˆ»ã‚‹</a></strong></p>
<hr />
<h2>è‘—è€…æƒ…å ±</h2>
<p><strong>ä½œæˆè€…</strong>: AI Terakoya Content Team
<strong>ä½œæˆæ—¥</strong>: 2025-10-17
<strong>ãƒãƒ¼ã‚¸ãƒ§ãƒ³</strong>: 1.0</p>
<p><strong>æ›´æ–°å±¥æ­´</strong>:
- 2025-10-17: v1.0 åˆç‰ˆå…¬é–‹</p>
<p><strong>ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯</strong>:
- GitHub Issues: <a href="https://github.com/your-repo/AI_Homepage/issues">AI_Homepage/issues</a>
- Email: yusuke.hashimoto.b8@tohoku.ac.jp</p>
<p><strong>ãƒ©ã‚¤ã‚»ãƒ³ã‚¹</strong>: Creative Commons BY 4.0</p>
<hr />
<p><strong>å®Ÿè·µçš„ãªå®Ÿè£…ã‚’ãƒã‚¹ã‚¿ãƒ¼ã—ã¾ã—ãŸï¼æ¬¡ç« ã§å®Ÿé¨“é€£æºã‚’å­¦ã³ã¾ã—ã‚‡ã†ï¼</strong></p><div class="navigation">
    <a href="chapter-3-enhancements.html" class="nav-button">â† å‰ã®ç« </a>
    <a href="index.html" class="nav-button">ã‚·ãƒªãƒ¼ã‚ºç›®æ¬¡ã«æˆ»ã‚‹</a>
    <a href="chapter-4-enhancements.html" class="nav-button">æ¬¡ã®ç«  â†’</a>
</div>
    </main>

    
    <section class="disclaimer">
        <h3>å…è²¬äº‹é …</h3>
        <ul>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯æ•™è‚²ãƒ»ç ”ç©¶ãƒ»æƒ…å ±æä¾›ã®ã¿ã‚’ç›®çš„ã¨ã—ã¦ãŠã‚Šã€å°‚é–€çš„ãªåŠ©è¨€(æ³•å¾‹ãƒ»ä¼šè¨ˆãƒ»æŠ€è¡“çš„ä¿è¨¼ãªã©)ã‚’æä¾›ã™ã‚‹ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŠã‚ˆã³ä»˜éšã™ã‚‹ã‚³ãƒ¼ãƒ‰ä¾‹ã¯ã€Œç¾çŠ¶æœ‰å§¿(AS IS)ã€ã§æä¾›ã•ã‚Œã€æ˜ç¤ºã¾ãŸã¯é»™ç¤ºã‚’å•ã‚ãšã€å•†å“æ€§ã€ç‰¹å®šç›®çš„é©åˆæ€§ã€æ¨©åˆ©éä¾µå®³ã€æ­£ç¢ºæ€§ãƒ»å®Œå…¨æ€§ã€å‹•ä½œãƒ»å®‰å…¨æ€§ç­‰ã„ã‹ãªã‚‹ä¿è¨¼ã‚‚ã—ã¾ã›ã‚“ã€‚</li>
            <li>å¤–éƒ¨ãƒªãƒ³ã‚¯ã€ç¬¬ä¸‰è€…ãŒæä¾›ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ»ãƒ„ãƒ¼ãƒ«ãƒ»ãƒ©ã‚¤ãƒ–ãƒ©ãƒªç­‰ã®å†…å®¹ãƒ»å¯ç”¨æ€§ãƒ»å®‰å…¨æ€§ã«ã¤ã„ã¦ã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯ä¸€åˆ‡ã®è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®åˆ©ç”¨ãƒ»å®Ÿè¡Œãƒ»è§£é‡ˆã«ã‚ˆã‚Šç›´æ¥çš„ãƒ»é–“æ¥çš„ãƒ»ä»˜éšçš„ãƒ»ç‰¹åˆ¥ãƒ»çµæœçš„ãƒ»æ‡²ç½°çš„æå®³ãŒç”Ÿã˜ãŸå ´åˆã§ã‚‚ã€é©ç”¨æ³•ã§è¨±å®¹ã•ã‚Œã‚‹æœ€å¤§é™ã®ç¯„å›²ã§ã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å†…å®¹ã¯ã€äºˆå‘Šãªãå¤‰æ›´ãƒ»æ›´æ–°ãƒ»æä¾›åœæ­¢ã•ã‚Œã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®è‘—ä½œæ¨©ãƒ»ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯æ˜è¨˜ã•ã‚ŒãŸæ¡ä»¶(ä¾‹: CC BY 4.0)ã«å¾“ã„ã¾ã™ã€‚å½“è©²ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯é€šå¸¸ã€ç„¡ä¿è¨¼æ¡é …ã‚’å«ã¿ã¾ã™ã€‚</li>
        </ul>
    </section>

<footer>
        <p><strong>ä½œæˆè€…</strong>: AI Terakoya Content Team</p>
        <p><strong>ãƒãƒ¼ã‚¸ãƒ§ãƒ³</strong>: 1.0 | <strong>ä½œæˆæ—¥</strong>: 2025-10-17</p>
        <p><strong>ãƒ©ã‚¤ã‚»ãƒ³ã‚¹</strong>: Creative Commons BY 4.0</p>
        <p>Â© 2025 AI Terakoya. All rights reserved.</p>
    </footer>
</body>
</html>
