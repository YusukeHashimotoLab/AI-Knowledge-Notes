<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ç¬¬5ç« ï¼šç¬¬ä¸€åŸç†è¨ˆç®—ã¨æ©Ÿæ¢°å­¦ç¿’ã®çµ±åˆ - AI Terakoya</title>

    <style>
        :root {
            --color-primary: #2c3e50;
            --color-primary-dark: #1a252f;
            --color-accent: #7b2cbf;
            --color-accent-light: #9d4edd;
            --color-text: #2d3748;
            --color-text-light: #4a5568;
            --color-bg: #ffffff;
            --color-bg-alt: #f7fafc;
            --color-border: #e2e8f0;
            --color-code-bg: #f8f9fa;
            --color-link: #3182ce;
            --color-link-hover: #2c5aa0;

            --spacing-xs: 0.5rem;
            --spacing-sm: 1rem;
            --spacing-md: 1.5rem;
            --spacing-lg: 2rem;
            --spacing-xl: 3rem;

            --font-body: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            --font-mono: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;

            --border-radius: 8px;
            --box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: var(--font-body);
            line-height: 1.7;
            color: var(--color-text);
            background-color: var(--color-bg);
            font-size: 16px;
        }

        header {
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            padding: var(--spacing-xl) var(--spacing-md);
            margin-bottom: var(--spacing-xl);
            box-shadow: var(--box-shadow);
        }

        .header-content {
            max-width: 900px;
            margin: 0 auto;
        }

        h1 {
            font-size: 2rem;
            font-weight: 700;
            margin-bottom: var(--spacing-sm);
            line-height: 1.2;
        }

        .subtitle {
            font-size: 1.1rem;
            opacity: 0.95;
            font-weight: 400;
            margin-bottom: var(--spacing-md);
        }

        .meta {
            display: flex;
            flex-wrap: wrap;
            gap: var(--spacing-md);
            font-size: 0.9rem;
            opacity: 0.9;
        }

        .meta-item {
            display: flex;
            align-items: center;
            gap: 0.3rem;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 0 var(--spacing-md) var(--spacing-xl);
        }

        h2 {
            font-size: 1.75rem;
            color: var(--color-primary);
            margin-top: var(--spacing-xl);
            margin-bottom: var(--spacing-md);
            padding-bottom: var(--spacing-xs);
            border-bottom: 3px solid var(--color-accent);
        }

        h3 {
            font-size: 1.4rem;
            color: var(--color-primary);
            margin-top: var(--spacing-lg);
            margin-bottom: var(--spacing-sm);
        }

        h4 {
            font-size: 1.1rem;
            color: var(--color-primary-dark);
            margin-top: var(--spacing-md);
            margin-bottom: var(--spacing-sm);
        }

        p {
            margin-bottom: var(--spacing-md);
            color: var(--color-text);
        }

        a {
            color: var(--color-link);
            text-decoration: none;
            transition: color 0.2s;
        }

        a:hover {
            color: var(--color-link-hover);
            text-decoration: underline;
        }

        ul, ol {
            margin-left: var(--spacing-lg);
            margin-bottom: var(--spacing-md);
        }

        li {
            margin-bottom: var(--spacing-xs);
            color: var(--color-text);
        }

        pre {
            background-color: var(--color-code-bg);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            overflow-x: auto;
            margin-bottom: var(--spacing-md);
            font-family: var(--font-mono);
            font-size: 0.9rem;
            line-height: 1.5;
        }

        code {
            font-family: var(--font-mono);
            font-size: 0.9em;
            background-color: var(--color-code-bg);
            padding: 0.2em 0.4em;
            border-radius: 3px;
        }

        pre code {
            background-color: transparent;
            padding: 0;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: var(--spacing-md);
            font-size: 0.95rem;
        }

        th, td {
            border: 1px solid var(--color-border);
            padding: var(--spacing-sm);
            text-align: left;
        }

        th {
            background-color: var(--color-bg-alt);
            font-weight: 600;
            color: var(--color-primary);
        }

        blockquote {
            border-left: 4px solid var(--color-accent);
            padding-left: var(--spacing-md);
            margin: var(--spacing-md) 0;
            color: var(--color-text-light);
            font-style: italic;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        .mermaid {
            text-align: center;
            margin: var(--spacing-lg) 0;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        details {
            background-color: var(--color-bg-alt);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            margin-bottom: var(--spacing-md);
        }

        summary {
            cursor: pointer;
            font-weight: 600;
            color: var(--color-primary);
            user-select: none;
            padding: var(--spacing-xs);
            margin: calc(-1 * var(--spacing-md));
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        summary:hover {
            background-color: rgba(123, 44, 191, 0.1);
        }

        details[open] summary {
            margin-bottom: var(--spacing-md);
            border-bottom: 1px solid var(--color-border);
        }

        .learning-objectives {
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
            padding: var(--spacing-lg);
            border-radius: var(--border-radius);
            border-left: 4px solid var(--color-accent);
            margin-bottom: var(--spacing-xl);
        }

        .learning-objectives h2 {
            margin-top: 0;
            border-bottom: none;
        }

        .navigation {
            display: flex;
            justify-content: space-between;
            gap: var(--spacing-md);
            margin: var(--spacing-xl) 0;
            padding-top: var(--spacing-lg);
            border-top: 2px solid var(--color-border);
        }

        .nav-button {
            flex: 1;
            padding: var(--spacing-md);
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            border-radius: var(--border-radius);
            text-align: center;
            font-weight: 600;
            transition: transform 0.2s, box-shadow 0.2s;
            box-shadow: var(--box-shadow);
        }

        .nav-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
            text-decoration: none;
        }

        footer {
            margin-top: var(--spacing-xl);
            padding: var(--spacing-lg) var(--spacing-md);
            background-color: var(--color-bg-alt);
            border-top: 1px solid var(--color-border);
            text-align: center;
            font-size: 0.9rem;
            color: var(--color-text-light);
        }

        @media (max-width: 768px) {
            h1 {
                font-size: 1.5rem;
            }

            h2 {
                font-size: 1.4rem;
            }

            h3 {
                font-size: 1.2rem;
            }

            .meta {
                font-size: 0.85rem;
            }

            .navigation {
                flex-direction: column;
            }

            table {
                font-size: 0.85rem;
            }

            th, td {
                padding: var(--spacing-xs);
            }
        }
    </style>

    <script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
    <script>
        mermaid.initialize({ startOnLoad: true, theme: 'default', securityLevel: 'strict' });
    </script>

    <!-- MathJax for LaTeX equation rendering -->
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\(', '\)']],
                displayMath: [['$$', '$$'], ['\[', '\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
                ignoreHtmlClass: 'mermaid'
            }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" async></script>
</head>
<body>
    <header>
        <div class="header-content">
            <h1>ç¬¬5ç« ï¼šç¬¬ä¸€åŸç†è¨ˆç®—ã¨æ©Ÿæ¢°å­¦ç¿’ã®çµ±åˆ</h1>
            <p class="subtitle">Machine Learning Potential ã¨ Active Learning</p>
            <div class="meta">
                <span class="meta-item">ğŸ“– èª­äº†æ™‚é–“: 20-25åˆ†</span>
                <span class="meta-item">ğŸ“Š é›£æ˜“åº¦: ä¸Šç´š</span>
                <span class="meta-item">ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹: 6å€‹</span>
                <span class="meta-item">ğŸ“ æ¼”ç¿’å•é¡Œ: 0å•</span>
            </div>
        </div>
    </header>

    <main class="container">
<h1>ç¬¬5ç« ï¼šç¬¬ä¸€åŸç†è¨ˆç®—ã¨æ©Ÿæ¢°å­¦ç¿’ã®çµ±åˆ</h1>
<p class="chapter-description" style="margin: 1.5rem 0; padding: 1rem; background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%); border-left: 4px solid #7b2cbf; border-radius: 8px; font-size: 1.05rem; line-height: 1.8; color: #2d3748;">VASP/Quantum ESPRESSO/LAMMPSã‚’ä½¿ã£ãŸæœ€å°å®Ÿè¡Œã®é“ç­‹ã‚’ç¤ºã—ã¾ã™ã€‚å‰å¾Œå‡¦ç†ã®æ¨™æº–ãƒ„ãƒ¼ãƒ«ã‚‚ä¸€è¦§ã§æŠ¼ã•ãˆã¾ã™ã€‚</p>
<p class="chapter-supplement" style="margin: 0.75rem 0 1.5rem 0; padding: 0.75rem 1rem; background: linear-gradient(135deg, #fff8e1 0%, #fff3cd 100%); border-left: 3px solid #f59e0b; border-radius: 6px; font-size: 0.95rem; line-height: 1.7; color: #4a5568;"><strong>ğŸ’¡ è£œè¶³:</strong> ã¾ãšã¯å°ç³»ã§ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’é€šã—ã€å…¥å‡ºåŠ›ã¨å˜ä½ç³»ã«æ…£ã‚Œã‚‹ã®ãŒè¿‘é“ã§ã™ã€‚</p>





<h2>å­¦ç¿’ç›®æ¨™</h2>
<p>ã“ã®ç« ã‚’èª­ã‚€ã“ã¨ã§ã€ä»¥ä¸‹ã‚’ç¿’å¾—ã§ãã¾ã™ï¼š
- æ©Ÿæ¢°å­¦ç¿’ãƒãƒ†ãƒ³ã‚·ãƒ£ãƒ«ï¼ˆMLPï¼‰ã®åŸºæœ¬æ¦‚å¿µã‚’ç†è§£ã™ã‚‹
- Classical MDã€AIMDã€MLPã®é•ã„ã¨ä½¿ã„åˆ†ã‘ã‚’èª¬æ˜ã§ãã‚‹
- DFTè¨ˆç®—ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒãƒ†ãƒ³ã‚·ãƒ£ãƒ«ã‚’è¨“ç·´ã§ãã‚‹
- Active Learningã«ã‚ˆã‚‹åŠ¹ç‡çš„ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆæˆ¦ç•¥ã‚’ç†è§£ã™ã‚‹
- æœ€æ–°ã®Universal MLPã‚„Foundation Modelsã®ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’æŠŠæ¡ã™ã‚‹</p>
<hr />
<h2>5.1 ãªãœMachine Learning PotentialãŒå¿…è¦ã‹</h2>
<h3>3ã¤ã®è¨ˆç®—æ‰‹æ³•ã®æ¯”è¼ƒ</h3>
<div class="mermaid">
flowchart LR
    A[Classical MD] -->|ç²¾åº¦ vs é€Ÿåº¦| B[AIMD]
    B -->|ç²¾åº¦ vs é€Ÿåº¦| C[Machine Learning Potential]
    C - ãƒ‡ãƒ¼ã‚¿é§†å‹• .-> B

    style A fill:#ffcccc
    style B fill:#ccffcc
    style C fill:#ccccff
</div>

<table>
<thead>
<tr>
<th>é …ç›®</th>
<th>Classical MD</th>
<th>AIMDï¼ˆDFT-MDï¼‰</th>
<th>MLP-MD</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>åŠ›ã®è¨ˆç®—</strong></td>
<td>çµŒé¨“çš„åŠ›å ´</td>
<td>DFTï¼ˆç¬¬ä¸€åŸç†ï¼‰</td>
<td>æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«</td>
</tr>
<tr>
<td><strong>ç²¾åº¦</strong></td>
<td>ä¸­ï¼ˆåŠ›å ´ã«ä¾å­˜ï¼‰</td>
<td>é«˜ï¼ˆé‡å­åŠ›å­¦çš„ï¼‰</td>
<td>é«˜ï¼ˆDFTåŒç­‰ï¼‰</td>
</tr>
<tr>
<td><strong>è¨ˆç®—é€Ÿåº¦</strong></td>
<td>è¶…é«˜é€Ÿï¼ˆns/æ—¥ï¼‰</td>
<td>æ¥µã‚ã¦é…ã„ï¼ˆps/æ—¥ï¼‰</td>
<td>é«˜é€Ÿï¼ˆns/æ—¥ï¼‰</td>
</tr>
<tr>
<td><strong>ç³»ã®ã‚µã‚¤ã‚º</strong></td>
<td>æ•°ç™¾ä¸‡åŸå­</td>
<td>æ•°ç™¾åŸå­</td>
<td>æ•°åƒã€œæ•°ä¸‡åŸå­</td>
</tr>
<tr>
<td><strong>é©ç”¨ç¯„å›²</strong></td>
<td>è¨“ç·´æ¸ˆã¿ç³»ã®ã¿</td>
<td>æ±ç”¨çš„</td>
<td>è¨“ç·´ãƒ‡ãƒ¼ã‚¿ç¯„å›²å†…</td>
</tr>
<tr>
<td><strong>é–‹ç™ºã‚³ã‚¹ãƒˆ</strong></td>
<td>ä½ï¼ˆæ—¢å­˜åŠ›å ´ä½¿ç”¨ï¼‰</td>
<td>ãªã—</td>
<td>é«˜ï¼ˆè¨“ç·´ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆï¼‰</td>
</tr>
</tbody>
</table>
<h3>MLPã®åˆ©ç‚¹</h3>
<p><strong>ã€ŒDFTç´šã®ç²¾åº¦ã§Classical MDç´šã®é€Ÿåº¦ã€</strong></p>
<ul>
<li>âœ… åŒ–å­¦åå¿œã‚’æ­£ç¢ºã«è¨˜è¿°ï¼ˆçµåˆã®åˆ‡æ–­ãƒ»ç”Ÿæˆï¼‰</li>
<li>âœ… é•·æ™‚é–“ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆnsã€œÎ¼sã‚¹ã‚±ãƒ¼ãƒ«ï¼‰</li>
<li>âœ… å¤§è¦æ¨¡ç³»ï¼ˆæ•°åƒã€œæ•°ä¸‡åŸå­ï¼‰</li>
<li>âœ… åŠ›å ´ãŒå­˜åœ¨ã—ãªã„æ–°è¦ææ–™ã«ã‚‚é©ç”¨å¯èƒ½</li>
</ul>
<p><strong>èª²é¡Œ</strong>:
- âŒ è¨“ç·´ãƒ‡ãƒ¼ã‚¿ï¼ˆDFTè¨ˆç®—ï¼‰ã®ç”Ÿæˆã‚³ã‚¹ãƒˆ
- âŒ è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®ç¯„å›²å¤–ã§ã¯ç²¾åº¦ä½ä¸‹
- âŒ ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ã«è¨ˆç®—è³‡æºã¨ãƒã‚¦ãƒã‚¦ãŒå¿…è¦</p>
<hr />
<h2>5.2 æ©Ÿæ¢°å­¦ç¿’ãƒãƒ†ãƒ³ã‚·ãƒ£ãƒ«ã®ç¨®é¡</h2>
<h3>1. Gaussian Approximation Potential (GAP)</h3>
<p><strong>åŸç†</strong>: ã‚«ãƒ¼ãƒãƒ«æ³•ï¼ˆGaussian Processï¼‰</p>
<p>$$
E_{\text{GAP}}(\mathbf{R}) = \sum_{i=1}^N \alpha_i K(\mathbf{R}, \mathbf{R}_i)
$$</p>
<ul>
<li>$K$: ã‚«ãƒ¼ãƒãƒ«é–¢æ•°ï¼ˆé¡ä¼¼åº¦ã‚’æ¸¬ã‚‹ï¼‰</li>
<li>$\mathbf{R}_i$: è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®åŸå­é…ç½®</li>
<li>$\alpha_i$: è¨“ç·´ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿</li>
</ul>
<p><strong>ç‰¹å¾´</strong>:
- âœ… ä¸ç¢ºå®Ÿæ€§æ¨å®šãŒå¯èƒ½ï¼ˆActive Learningã«æœ‰åˆ©ï¼‰
- âœ… å°‘ãªã„ãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’å¯èƒ½
- âŒ è¨“ç·´ãƒ‡ãƒ¼ã‚¿æ•°ã«æ¯”ä¾‹ã—ã¦è¨ˆç®—ã‚³ã‚¹ãƒˆå¢—åŠ </p>
<h3>2. Neural Network Potential (NNP)</h3>
<p><strong>Behler-Parrinelloå‹</strong>: å„åŸå­ã®ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã‚’è¨˜è¿°å­åŒ–</p>
<p>$$
E_{\text{NNP}} = \sum_{i=1}^{N_{\text{atoms}}} E_i^{\text{NN}}({\mathbf{G}_i})
$$</p>
<ul>
<li>$E_i^{\text{NN}}$: åŸå­$i$ã®ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒãƒ«ã‚®ãƒ¼</li>
<li>$\mathbf{G}_i$: å¯¾ç§°é–¢æ•°ï¼ˆSymmetry Functionsï¼‰ã€åŸå­$i$ã®å‘¨å›²ç’°å¢ƒã‚’è¨˜è¿°</li>
</ul>
<p><strong>å¯¾ç§°é–¢æ•°ã®ä¾‹</strong>ï¼ˆå‹•å¾„æˆåˆ†ï¼‰:</p>
<p>$$
G_i^{\text{rad}} = \sum_{j \neq i} e^{-\eta(r_{ij} - R_s)^2} f_c(r_{ij})
$$</p>
<ul>
<li>$r_{ij}$: åŸå­é–“è·é›¢</li>
<li>$f_c(r)$: ã‚«ãƒƒãƒˆã‚ªãƒ•é–¢æ•°ï¼ˆä¸€å®šè·é›¢ä»¥é ã‚’ç„¡è¦–ï¼‰</li>
</ul>
<p><strong>ç‰¹å¾´</strong>:
- âœ… å¤§è¦æ¨¡ç³»ã§ã‚‚é«˜é€Ÿ
- âœ… è¨“ç·´ãƒ‡ãƒ¼ã‚¿æ•°ãŒå¢—ãˆã¦ã‚‚è¨ˆç®—ã‚³ã‚¹ãƒˆä¸€å®š
- âŒ ä¸ç¢ºå®Ÿæ€§æ¨å®šãŒå›°é›£</p>
<h3>3. Message Passing Neural Network (MPNN)</h3>
<p>ã‚°ãƒ©ãƒ•ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼ˆGNNï¼‰ã®ä¸€ç¨®ï¼š</p>
<p>$$
\mathbf{h}_i^{(k+1)} = \text{Update}\left(\mathbf{h}_i^{(k)}, \sum_{j \in \mathcal{N}(i)} \text{Message}(\mathbf{h}_i^{(k)}, \mathbf{h}_j^{(k)}, \mathbf{e}_{ij})\right)
$$</p>
<ul>
<li>$\mathbf{h}_i^{(k)}$: åŸå­$i$ã®$k$å±¤ç›®ã®éš ã‚ŒçŠ¶æ…‹</li>
<li>$\mathcal{N}(i)$: åŸå­$i$ã®è¿‘å‚åŸå­</li>
<li>$\mathbf{e}_{ij}$: çµåˆæƒ…å ±ï¼ˆè·é›¢ã€è§’åº¦ï¼‰</li>
</ul>
<p><strong>ä»£è¡¨çš„ãƒ¢ãƒ‡ãƒ«</strong>: SchNetã€DimeNetã€GemNetã€MACE</p>
<p><strong>ç‰¹å¾´</strong>:
- âœ… å›è»¢ãƒ»ä¸¦é€²ä¸å¤‰æ€§ã‚’è‡ªç„¶ã«å®Ÿç¾
- âœ… é•·è·é›¢ç›¸äº’ä½œç”¨ã‚’åŠ¹ç‡çš„ã«å­¦ç¿’
- âœ… æœ€æ–°ã®é«˜ç²¾åº¦ãƒ¢ãƒ‡ãƒ«</p>
<h3>4. Moment Tensor Potential (MTP)</h3>
<p><strong>åŸç†</strong>: åŸå­ç’°å¢ƒã‚’å¤šä½“å±•é–‹ã§è¨˜è¿°</p>
<p>$$
E_{\text{MTP}} = \sum_i \sum_{\alpha} c_{\alpha} B_{\alpha}(\mathbf{R}_i)
$$</p>
<p>$B_{\alpha}$ã¯ãƒ¢ãƒ¼ãƒ¡ãƒ³ãƒˆãƒ†ãƒ³ã‚½ãƒ«åŸºåº•é–¢æ•°ã€‚</p>
<p><strong>ç‰¹å¾´</strong>:
- âœ… é«˜é€Ÿï¼ˆç·šå½¢ãƒ¢ãƒ‡ãƒ«ï¼‰
- âœ… è¨“ç·´ãŒå®¹æ˜“
- âŒ è¡¨ç¾åŠ›ãŒNNPã‚ˆã‚Šä½ã„</p>
<hr />
<h2>5.3 Neural Network Potentialã®è¨“ç·´ï¼ˆå®Ÿè·µï¼‰</h2>
<h3>Example 1: AMPã‚’ä½¿ã£ãŸNNPè¨“ç·´ï¼ˆæ°´åˆ†å­ï¼‰</h3>
<pre><code class="language-python">import numpy as np
from ase.build import molecule
from ase.calculators.emt import EMT
from gpaw import GPAW, PW
from amp import Amp
from amp.descriptor.gaussian import Gaussian
from amp.model.neuralnetwork import NeuralNetwork
import matplotlib.pyplot as plt

# Step 1: è¨“ç·´ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆï¼ˆMDã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ + DFTï¼‰
def generate_training_data(n_samples=50):
    &quot;&quot;&quot;
    æ°´åˆ†å­ã®æ§˜ã€…ãªé…ç½®ã§DFTè¨ˆç®—
    &quot;&quot;&quot;
    from ase.md.velocitydistribution import MaxwellBoltzmannDistribution
    from ase.md.verlet import VelocityVerlet
    from ase import units

    h2o = molecule('H2O')
    h2o.center(vacuum=5.0)

    # DFTè¨ˆç®—æ©Ÿ
    calc = GPAW(mode=PW(300), xc='PBE', txt=None)
    h2o.calc = calc

    # åˆæœŸé€Ÿåº¦
    MaxwellBoltzmannDistribution(h2o, temperature_K=500)

    # MDã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
    dyn = VelocityVerlet(h2o, timestep=1.0*units.fs)

    images = []
    for i in range(n_samples):
        dyn.run(10)  # 10ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã«ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
        atoms_copy = h2o.copy()
        atoms_copy.calc = calc
        atoms_copy.get_potential_energy()  # DFTè¨ˆç®—å®Ÿè¡Œ
        atoms_copy.get_forces()
        images.append(atoms_copy)
        print(f&quot;Sample {i+1}/{n_samples} collected&quot;)

    return images

print(&quot;Generating training data...&quot;)
train_images = generate_training_data(n_samples=50)

# Step 2: NNPã®è¨“ç·´
print(&quot;Training Neural Network Potential...&quot;)

# è¨˜è¿°å­: Gaussianå¯¾ç§°é–¢æ•°
descriptor = Gaussian()

# ãƒ¢ãƒ‡ãƒ«: ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯
model = NeuralNetwork(hiddenlayers=(10, 10, 10))  # 3å±¤ã€å„10ãƒãƒ¼ãƒ‰

# AMPãƒãƒ†ãƒ³ã‚·ãƒ£ãƒ«
calc_nnp = Amp(descriptor=descriptor,
               model=model,
               label='h2o_nnp',
               dblabel='h2o_nnp')

# è¨“ç·´
calc_nnp.train(images=train_images,
               energy_coefficient=1.0,
               force_coefficient=0.04)

print(&quot;Training complete!&quot;)

# Step 3: ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§ç²¾åº¦è©•ä¾¡
print(&quot;\nGenerating test data...&quot;)
test_images = generate_training_data(n_samples=10)

E_dft = []
E_nnp = []
F_dft = []
F_nnp = []

for atoms in test_images:
    # DFT
    atoms.calc = GPAW(mode=PW(300), xc='PBE', txt=None)
    e_dft = atoms.get_potential_energy()
    f_dft = atoms.get_forces().flatten()

    # NNP
    atoms.calc = calc_nnp
    e_nnp = atoms.get_potential_energy()
    f_nnp = atoms.get_forces().flatten()

    E_dft.append(e_dft)
    E_nnp.append(e_nnp)
    F_dft.extend(f_dft)
    F_nnp.extend(f_nnp)

E_dft = np.array(E_dft)
E_nnp = np.array(E_nnp)
F_dft = np.array(F_dft)
F_nnp = np.array(F_nnp)

# ãƒ—ãƒ­ãƒƒãƒˆ
fig, axes = plt.subplots(1, 2, figsize=(12, 5))

# ã‚¨ãƒãƒ«ã‚®ãƒ¼
axes[0].scatter(E_dft, E_nnp, alpha=0.6)
axes[0].plot([E_dft.min(), E_dft.max()],
             [E_dft.min(), E_dft.max()], 'r--', label='Perfect')
axes[0].set_xlabel('DFT Energy (eV)', fontsize=12)
axes[0].set_ylabel('NNP Energy (eV)', fontsize=12)
axes[0].set_title('Energy Prediction', fontsize=14)
mae_e = np.mean(np.abs(E_dft - E_nnp))
axes[0].text(0.05, 0.95, f'MAE = {mae_e:.3f} eV',
            transform=axes[0].transAxes, va='top')
axes[0].legend()
axes[0].grid(alpha=0.3)

# åŠ›
axes[1].scatter(F_dft, F_nnp, alpha=0.3, s=10)
axes[1].plot([F_dft.min(), F_dft.max()],
             [F_dft.min(), F_dft.max()], 'r--', label='Perfect')
axes[1].set_xlabel('DFT Force (eV/Ã…)', fontsize=12)
axes[1].set_ylabel('NNP Force (eV/Ã…)', fontsize=12)
axes[1].set_title('Force Prediction', fontsize=14)
mae_f = np.mean(np.abs(F_dft - F_nnp))
axes[1].text(0.05, 0.95, f'MAE = {mae_f:.3f} eV/Ã…',
            transform=axes[1].transAxes, va='top')
axes[1].legend()
axes[1].grid(alpha=0.3)

plt.tight_layout()
plt.savefig('nnp_accuracy.png', dpi=150)
plt.show()

print(f&quot;\nNNP Accuracy:&quot;)
print(f&quot;Energy MAE: {mae_e:.4f} eV&quot;)
print(f&quot;Force MAE: {mae_f:.4f} eV/Ã…&quot;)
</code></pre>
<p><strong>ç›®æ¨™ç²¾åº¦</strong>:
- ã‚¨ãƒãƒ«ã‚®ãƒ¼: MAE &lt; 1 meV/atom
- åŠ›: MAE &lt; 0.1 eV/Ã…</p>
<hr />
<h2>5.4 Active Learning</h2>
<h3>åŸºæœ¬çš„ãªè€ƒãˆæ–¹</h3>
<p><strong>å•é¡Œ</strong>: ã™ã¹ã¦ã®é…ç½®ã§DFTè¨ˆç®—ã‚’è¡Œã†ã®ã¯éç¾å®Ÿçš„ï¼ˆè¨ˆç®—ã‚³ã‚¹ãƒˆå¤§ï¼‰</p>
<p><strong>è§£æ±ºç­–</strong>: <strong>æœ€ã‚‚æƒ…å ±é‡ã®å¤šã„é…ç½®ã‚’å„ªå…ˆçš„ã«ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°</strong></p>
<div class="mermaid">
flowchart TD
    A[åˆæœŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå°‘æ•°] --> B[NNPè¨“ç·´]
    B --> C[MDã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ with NNP]
    C --> D[ä¸ç¢ºå®Ÿæ€§ã®é«˜ã„é…ç½®ã‚’æ¤œå‡º]
    D --> E{è¿½åŠ ãƒ‡ãƒ¼ã‚¿å¿…è¦?}
    E -->|Yes| F[DFTè¨ˆç®—è¿½åŠ ãƒ‡ãƒ¼ã‚¿]
    F --> G[ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«è¿½åŠ ]
    G --> B
    E -->|No| H[è¨“ç·´å®Œäº†]

    style A fill:#e3f2fd
    style H fill:#c8e6c9
</div>

<h3>ä¸ç¢ºå®Ÿæ€§æ¨å®šã®æ–¹æ³•</h3>
<p><strong>1. Ensembleæ³•</strong>:
- è¤‡æ•°ã®NNPã‚’è¨“ç·´ï¼ˆç•°ãªã‚‹åˆæœŸå€¤ã€ãƒ‡ãƒ¼ã‚¿åˆ†å‰²ï¼‰
- äºˆæ¸¬ã®ã°ã‚‰ã¤ãï¼ˆåˆ†æ•£ï¼‰ã‚’ä¸ç¢ºå®Ÿæ€§ã¨ã™ã‚‹</p>
<p>$$
\sigma_E^2 = \frac{1}{M}\sum_{m=1}^M (E_m - \bar{E})^2
$$</p>
<p><strong>2. Dropoutæ³•</strong>:
- è¨“ç·´æ™‚ã«ãƒ©ãƒ³ãƒ€ãƒ ã«ãƒãƒ¼ãƒ‰ã‚’ç„¡åŠ¹åŒ–
- æ¨è«–æ™‚ã«ã‚‚Dropoutã‚’é©ç”¨ã—ã€è¤‡æ•°å›äºˆæ¸¬
- äºˆæ¸¬ã®ã°ã‚‰ã¤ãã‚’ä¸ç¢ºå®Ÿæ€§ã¨ã™ã‚‹</p>
<p><strong>3. Query-by-Committee</strong>:
- ç•°ãªã‚‹ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®ãƒ¢ãƒ‡ãƒ«ã‚’è¤‡æ•°ä½¿ç”¨
- äºˆæ¸¬ã®ä¸€è‡´åº¦ãŒä½ã„é…ç½®ã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°</p>
<h3>Active Learningå®Ÿè£…ä¾‹</h3>
<pre><code class="language-python">import numpy as np
from ase.md.langevin import Langevin
from ase import units

def active_learning_loop(initial_images, n_iterations=5, n_md_steps=1000):
    &quot;&quot;&quot;
    Active Learningã«ã‚ˆã‚‹åŠ¹ç‡çš„è¨“ç·´ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    &quot;&quot;&quot;
    dataset = initial_images.copy()

    for iteration in range(n_iterations):
        print(f&quot;\n--- Iteration {iteration+1}/{n_iterations} ---&quot;)

        # Step 1: NNPã‚’è¨“ç·´
        print(&quot;Training NNP...&quot;)
        nnp = train_nnp(dataset)  # å‰è¿°ã®Ampè¨“ç·´

        # Step 2: NNPã§MDã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        print(&quot;Running MD with NNP...&quot;)
        h2o = dataset[0].copy()
        h2o.calc = nnp

        # Langevin MDï¼ˆç†±æµ´ä»˜ãï¼‰
        dyn = Langevin(h2o, timestep=1.0*units.fs,
                       temperature_K=500, friction=0.01)

        # ä¸ç¢ºå®Ÿæ€§ã®é«˜ã„é…ç½®ã‚’åé›†
        uncertain_images = []
        uncertainties = []

        for step in range(n_md_steps):
            dyn.run(1)

            # Ensembleã§ä¸ç¢ºå®Ÿæ€§æ¨å®šï¼ˆç°¡ç•¥åŒ–ï¼‰
            # å®Ÿéš›ã«ã¯è¤‡æ•°ã®NNPã§äºˆæ¸¬ã—ã¦ã°ã‚‰ã¤ãã‚’è¨ˆç®—
            uncertainty = estimate_uncertainty(h2o, nnp)  # ä»®æƒ³é–¢æ•°

            if uncertainty &gt; threshold:  # é–¾å€¤ä»¥ä¸Šãªã‚‰è¿½åŠ 
                atoms_copy = h2o.copy()
                uncertain_images.append(atoms_copy)
                uncertainties.append(uncertainty)

        print(f&quot;Found {len(uncertain_images)} uncertain configurations&quot;)

        # Step 3: ä¸ç¢ºå®Ÿæ€§ã®é«˜ã„é…ç½®ã§DFTè¨ˆç®—
        print(&quot;Running DFT for uncertain configurations...&quot;)
        for atoms in uncertain_images[:10]:  # ä¸Šä½10å€‹
            atoms.calc = GPAW(mode=PW(300), xc='PBE', txt=None)
            atoms.get_potential_energy()
            atoms.get_forces()
            dataset.append(atoms)

        print(f&quot;Dataset size: {len(dataset)}&quot;)

    return dataset, nnp

# å®Ÿè¡Œ
initial_data = generate_training_data(n_samples=20)
final_dataset, final_nnp = active_learning_loop(initial_data, n_iterations=5)

print(f&quot;\nFinal dataset size: {len(final_dataset)}&quot;)
print(f&quot;vs. random sampling: 50-100 samples would be needed&quot;)
print(f&quot;Efficiency gain: {100/len(final_dataset):.1f}x&quot;)
</code></pre>
<p><strong>Active Learningã®åˆ©ç‚¹</strong>:
- è¨“ç·´ãƒ‡ãƒ¼ã‚¿æ•°ã‚’50-90%å‰Šæ¸›å¯èƒ½
- é‡è¦ãªé…ç½®ï¼ˆç›¸è»¢ç§»ã€åå¿œçµŒè·¯ï¼‰ã‚’å„ªå…ˆçš„ã«ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
- è¨ˆç®—è³‡æºã®åŠ¹ç‡çš„åˆ©ç”¨</p>
<hr />
<h2>5.5 æœ€æ–°ãƒˆãƒ¬ãƒ³ãƒ‰</h2>
<h3>1. Universal Machine Learning Potential</h3>
<p><strong>ç›®æ¨™</strong>: 1ã¤ã®ãƒ¢ãƒ‡ãƒ«ã§å¤šæ§˜ãªææ–™ç³»ã‚’ã‚«ãƒãƒ¼</p>
<p><strong>ä»£è¡¨ä¾‹</strong>:
- <strong>CHGNet</strong>ï¼ˆ2023å¹´ï¼‰: 140ä¸‡ææ–™ã®Materials Projectãƒ‡ãƒ¼ã‚¿ã§è¨“ç·´
  - 89å…ƒç´ ã‚’ã‚«ãƒãƒ¼
  - ç£æ€§ã‚‚è€ƒæ…®
  - ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹</p>
<ul>
<li><strong>M3GNet</strong>ï¼ˆ2022å¹´ï¼‰: å¤šä½“ã‚°ãƒ©ãƒ•ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯</li>
<li>çµæ™¶ã€è¡¨é¢ã€åˆ†å­ã«é©ç”¨å¯èƒ½</li>
<li>
<p>åŠ›ã€å¿œåŠ›ã€ç£æ°—ãƒ¢ãƒ¼ãƒ¡ãƒ³ãƒˆã‚’äºˆæ¸¬</p>
</li>
<li>
<p><strong>MACE</strong>ï¼ˆ2023å¹´ï¼‰: ç­‰å¤‰ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ‘ãƒƒã‚·ãƒ³ã‚°</p>
</li>
<li>é«˜ç²¾åº¦ï¼ˆDFTèª¤å·®ã®ç´„2å€ç¨‹åº¦ã®èª¤å·®ï¼‰</li>
<li>å°è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã§è¨“ç·´å¯èƒ½</li>
</ul>
<p><strong>ä½¿ã„æ–¹</strong>:</p>
<pre><code class="language-python">from chgnet.model import CHGNet
from pymatgen.core import Structure

# äº‹å‰è¨“ç·´ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰
model = CHGNet.load()

# ä»»æ„ã®çµæ™¶æ§‹é€ ã§äºˆæ¸¬
structure = Structure.from_file('POSCAR')
energy = model.predict_structure(structure)

print(f&quot;Predicted energy: {energy} eV&quot;)
</code></pre>
<h3>2. Foundation Models for Materials</h3>
<p><strong>å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMï¼‰ã®ææ–™ç§‘å­¦ç‰ˆ</strong>:</p>
<ul>
<li><strong>MatGPT</strong>: ææ–™ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã§äº‹å‰å­¦ç¿’</li>
<li><strong>LLaMat</strong>: çµæ™¶æ§‹é€ â†’ç‰¹æ€§äºˆæ¸¬</li>
</ul>
<p><strong>è»¢ç§»å­¦ç¿’</strong>:
- å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã§äº‹å‰å­¦ç¿’
- å°‘æ•°ãƒ‡ãƒ¼ã‚¿ã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°
- 10-100ã‚µãƒ³ãƒ—ãƒ«ã§å®Ÿç”¨ç²¾åº¦</p>
<h3>3. è‡ªå¾‹å®Ÿé¨“ã¸ã®å¿œç”¨</h3>
<p><strong>ã‚¯ãƒ­ãƒ¼ã‚ºãƒ‰ãƒ«ãƒ¼ãƒ—æœ€é©åŒ–</strong>:</p>
<pre><code>MLäºˆæ¸¬ â†’ æœ€é©å€™è£œææ¡ˆ â†’ ãƒ­ãƒœãƒƒãƒˆå®Ÿé¨“ â†’ æ¸¬å®š â†’ ãƒ‡ãƒ¼ã‚¿è“„ç© â†’ MLå†è¨“ç·´
</code></pre>
<p><strong>å®Ÿä¾‹</strong>:
- <strong>A-Lab</strong>ï¼ˆBerkeley, 2023å¹´ï¼‰: 41ææ–™ã‚’17æ—¥ã§åˆæˆãƒ»è©•ä¾¡
- <strong>è‡ªå¾‹ææ–™æ¢ç´¢</strong>: è§¦åª’ã€é›»æ± ææ–™ã€é‡å­ãƒ‰ãƒƒãƒˆ</p>
<hr />
<h2>5.6 MLPã®å®Ÿç”¨ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³</h2>
<h3>ã„ã¤MLPã‚’ä½¿ã†ã¹ãã‹</h3>
<p><strong>é©ã—ã¦ã„ã‚‹å ´åˆ</strong>:
- âœ… é•·æ™‚é–“MDï¼ˆns-Î¼sï¼‰ãŒå¿…è¦
- âœ… å¤§è¦æ¨¡ç³»ï¼ˆæ•°åƒåŸå­ä»¥ä¸Šï¼‰
- âœ… åŒ–å­¦åå¿œã‚’å«ã‚€
- âœ… åŠ›å ´ãŒå­˜åœ¨ã—ãªã„æ–°è¦ææ–™
- âœ… è¨“ç·´ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã®è¨ˆç®—è³‡æºãŒã‚ã‚‹</p>
<p><strong>é©ã•ãªã„å ´åˆ</strong>:
- âŒ 1å›é™ã‚Šã®çŸ­æ™‚é–“MDï¼ˆç›´æ¥AIMDãŒç°¡å˜ï¼‰
- âŒ è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®ä»£è¡¨æ€§ã‚’ç¢ºä¿ã§ããªã„
- âŒ è¨“ç·´ãƒ‡ãƒ¼ã‚¿ç¯„å›²å¤–ã®å¤–æŒ¿ãŒå¿…è¦
- âŒ æ—¢å­˜ã®é«˜ç²¾åº¦åŠ›å ´ãŒã‚ã‚‹ï¼ˆReaxFFã€COMBç­‰ï¼‰</p>
<h3>å®Ÿè£…ã®æµã‚Œ</h3>
<div class="mermaid">
flowchart TD
    A[å•é¡Œè¨­å®š] --> B[åˆæœŸãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ 20-100ã‚µãƒ³ãƒ—ãƒ«]
    B --> C[NNPè¨“ç·´]
    C --> D[æ¤œè¨¼ã‚»ãƒƒãƒˆã§ç²¾åº¦è©•ä¾¡]
    D --> E{ç²¾åº¦OK?}
    E -->|No| F[Active Learning]
    F --> G[è¿½åŠ DFTè¨ˆç®—]
    G --> C
    E -->|Yes| H[æœ¬ç•ªMDã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³]
    H --> I[ç‰©æ€§è¨ˆç®—]

    style A fill:#e3f2fd
    style I fill:#c8e6c9
</div>

<h3>æ¨å¥¨ãƒ„ãƒ¼ãƒ«</h3>
<table>
<thead>
<tr>
<th>ãƒ„ãƒ¼ãƒ«</th>
<th>æ‰‹æ³•</th>
<th>ç‰¹å¾´</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>AMP</strong></td>
<td>NNP</td>
<td>Pythonãƒã‚¤ãƒ†ã‚£ãƒ–ã€ASEçµ±åˆ</td>
</tr>
<tr>
<td><strong>DeePMD</strong></td>
<td>NNP</td>
<td>é«˜é€Ÿã€ä¸¦åˆ—åŒ–ã€TensorFlow</td>
</tr>
<tr>
<td><strong>SchNetPack</strong></td>
<td>GNN</td>
<td>SchNetã€ç ”ç©¶å‘ã‘</td>
</tr>
<tr>
<td><strong>MACE</strong></td>
<td>Equivariant GNN</td>
<td>æœ€æ–°ã€é«˜ç²¾åº¦</td>
</tr>
<tr>
<td><strong>GAP</strong></td>
<td>Gaussian Process</td>
<td>ä¸ç¢ºå®Ÿæ€§æ¨å®š</td>
</tr>
<tr>
<td><strong>MTP</strong></td>
<td>Moment Tensor</td>
<td>é«˜é€Ÿè¨“ç·´</td>
</tr>
<tr>
<td><strong>CHGNet</strong></td>
<td>Universal</td>
<td>äº‹å‰è¨“ç·´æ¸ˆã¿</td>
</tr>
</tbody>
</table>
<hr />
<h2>5.7 æœ¬ç« ã®ã¾ã¨ã‚</h2>
<h3>å­¦ã‚“ã ã“ã¨</h3>
<ol>
<li>
<p><strong>MLPã®å¿…è¦æ€§</strong>
   - DFTç´šç²¾åº¦ + Classical MDç´šé€Ÿåº¦
   - é•·æ™‚é–“ãƒ»å¤§è¦æ¨¡ç³»ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³</p>
</li>
<li>
<p><strong>MLPã®ç¨®é¡</strong>
   - GAPï¼ˆGaussian Processï¼‰
   - NNPï¼ˆNeural Networkï¼‰
   - MPNNï¼ˆGraph Neural Networkï¼‰
   - MTPï¼ˆMoment Tensorï¼‰</p>
</li>
<li>
<p><strong>NNPã®è¨“ç·´</strong>
   - DFTãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
   - AMPã§ã®å®Ÿè£…
   - ç²¾åº¦è©•ä¾¡</p>
</li>
<li>
<p><strong>Active Learning</strong>
   - ä¸ç¢ºå®Ÿæ€§æ¨å®š
   - åŠ¹ç‡çš„ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
   - 50-90%ã®è¨ˆç®—é‡å‰Šæ¸›</p>
</li>
<li>
<p><strong>æœ€æ–°ãƒˆãƒ¬ãƒ³ãƒ‰</strong>
   - Universal MLPï¼ˆCHGNetã€M3GNetï¼‰
   - Foundation Models
   - è‡ªå¾‹å®Ÿé¨“</p>
</li>
</ol>
<h3>é‡è¦ãªãƒã‚¤ãƒ³ãƒˆ</h3>
<ul>
<li>MLPã¯è¨ˆç®—ææ–™ç§‘å­¦ã®æ–°ã—ã„ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ </li>
<li>Active LearningãŒè¨“ç·´åŠ¹ç‡ã®éµ</li>
<li>Universal MLPã§äº‹å‰è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãŒåˆ©ç”¨å¯èƒ½</li>
<li>å®Ÿç”¨åŒ–ãŒé€²ã‚“ã§ã„ã‚‹ï¼ˆè‡ªå¾‹å®Ÿé¨“ã€ææ–™æ¢ç´¢ï¼‰</li>
</ul>
<h3>æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—</h3>
<ul>
<li>è‡ªåˆ†ã®ç ”ç©¶ãƒ†ãƒ¼ãƒã§MLPã‚’è©¦ã™</li>
<li>æœ€æ–°è«–æ–‡ã‚’è¿½ã†ï¼ˆ<em>npj Computational Materials</em>, <em>Nature Materials</em>ï¼‰</li>
<li>ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ„ãƒ¼ãƒ«ã«è²¢çŒ®</li>
<li>å®Ÿé¨“ç ”ç©¶è€…ã¨ã®å…±åŒç ”ç©¶</li>
</ul>
<hr />
<h2>æ¼”ç¿’å•é¡Œ</h2>
<h3>å•é¡Œ1ï¼ˆé›£æ˜“åº¦ï¼šeasyï¼‰</h3>
<p>Classical MDã€AIMDã€MLP-MDã®é•ã„ã‚’è¡¨ã«ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚</p>
<details>
<summary>è§£ç­”ä¾‹</summary>

| é …ç›® | Classical MD | AIMDï¼ˆDFT-MDï¼‰ | MLP-MD |
|-----|-------------|-------------|--------|
| **åŠ›ã®è¨ˆç®—æ³•** | çµŒé¨“çš„åŠ›å ´ï¼ˆè§£æå¼ï¼‰ | DFTï¼ˆç¬¬ä¸€åŸç†ï¼‰ | æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ« |
| **ç²¾åº¦** | ä¸­ï¼ˆåŠ›å ´ã®è³ªã«ä¾å­˜ï¼‰ | é«˜ï¼ˆé‡å­åŠ›å­¦çš„ã«æ­£ç¢ºï¼‰ | é«˜ï¼ˆDFTã¨åŒç­‰ï¼‰ |
| **è¨ˆç®—é€Ÿåº¦** | è¶…é«˜é€Ÿï¼ˆ1 ns/æ—¥ï¼‰ | æ¥µã‚ã¦é…ã„ï¼ˆ10 ps/æ—¥ï¼‰ | é«˜é€Ÿï¼ˆ1 ns/æ—¥ï¼‰ |
| **ç³»ã®ã‚µã‚¤ã‚º** | æ•°ç™¾ä¸‡åŸå­ | æ•°ç™¾åŸå­ | æ•°åƒã€œæ•°ä¸‡åŸå­ |
| **åŒ–å­¦åå¿œ** | è¨˜è¿°ä¸å¯ï¼ˆReaxFFã¯å¯ï¼‰ | æ­£ç¢ºã«è¨˜è¿° | æ­£ç¢ºã«è¨˜è¿° |
| **é©ç”¨ç¯„å›²** | åŠ›å ´ãŒè¨“ç·´ã•ã‚ŒãŸç³»ã®ã¿ | æ±ç”¨çš„ | è¨“ç·´ãƒ‡ãƒ¼ã‚¿ç¯„å›²å†… |
| **é–‹ç™ºã‚³ã‚¹ãƒˆ** | ä½ï¼ˆæ—¢å­˜åŠ›å ´ï¼‰ | ãªã— | é«˜ï¼ˆè¨“ç·´ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆï¼‰ |
| **ç”¨é€”** | æ‹¡æ•£ã€ç›¸è»¢ç§»ã€å¤§è¦æ¨¡ | åŒ–å­¦åå¿œã€é›»å­çŠ¶æ…‹ | åå¿œ+é•·æ™‚é–“MD |

**ä½¿ã„åˆ†ã‘ã®ç›®å®‰**:
- æ—¢çŸ¥ã®åŠ›å ´ãŒã‚ã‚‹ â†’ Classical MD
- åŒ–å­¦åå¿œã‚’å«ã‚€çŸ­æ™‚é–“ â†’ AIMD
- åŒ–å­¦åå¿œ+é•·æ™‚é–“ â†’ MLP-MD
- æ–°è¦ææ–™ã®æ¢ç´¢ â†’ AIMD â†’ MLP â†’ å¤§è¦æ¨¡MD

</details>

<h3>å•é¡Œ2ï¼ˆé›£æ˜“åº¦ï¼šmediumï¼‰</h3>
<p>Active LearningãŒãªãœåŠ¹ç‡çš„ãªã®ã‹ã€å…·ä½“ä¾‹ã¨ã¨ã‚‚ã«èª¬æ˜ã—ã¦ãã ã•ã„ã€‚</p>
<details>
<summary>è§£ç­”ä¾‹</summary>

**Active Learningã®åŸºæœ¬åŸç†**:

å¾“æ¥ã®æ©Ÿæ¢°å­¦ç¿’ï¼ˆRandom Samplingï¼‰:
- ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
- å¤šãã®ãƒ‡ãƒ¼ã‚¿ãŒã€Œæ—¢çŸ¥ã®é ˜åŸŸã€ã®é‡è¤‡
- éåŠ¹ç‡

Active Learningï¼ˆUncertainty Samplingï¼‰:
- ãƒ¢ãƒ‡ãƒ«ãŒã€Œä¸ç¢ºå®Ÿã€ãªé…ç½®ã‚’å„ªå…ˆçš„ã«ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
- æ–°ã—ã„æƒ…å ±ã‚’åŠ¹ç‡çš„ã«ç²å¾—
- å°‘ãªã„ãƒ‡ãƒ¼ã‚¿ã§é«˜ç²¾åº¦

**å…·ä½“ä¾‹: æ°´åˆ†å­ã®NNPè¨“ç·´**

**Random Samplingï¼ˆå¾“æ¥æ³•ï¼‰**:
- 300Kå¹³è¡¡çŠ¶æ…‹ã‹ã‚‰100é…ç½®ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
- ãã®ã†ã¡80%ã¯å¹³è¡¡æ§‹é€ ã®è¿‘å‚ï¼ˆé¡ä¼¼é…ç½®ï¼‰
- æ®‹ã‚Š20%ãŒåå¿œçµŒè·¯ã‚„é«˜ã‚¨ãƒãƒ«ã‚®ãƒ¼é…ç½®
- çµæœ: 100 DFTè¨ˆç®—ã€ç²¾åº¦ MAE = 5 meV/atom

**Active Learning**:
- åˆæœŸ20é…ç½®ã‹ã‚‰è¨“ç·´
- MDã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ä¸­ã«ä¸ç¢ºå®Ÿæ€§ã®é«˜ã„é…ç½®ã‚’æ¤œå‡º
  - O-HçµåˆãŒä¼¸ã³ãŸé…ç½®ï¼ˆè§£é›¢éç¨‹ï¼‰
  - H-O-Hè§’åº¦ãŒå¤§ããæ­ªã‚“ã é…ç½®
  - é«˜ã‚¨ãƒãƒ«ã‚®ãƒ¼åŠ±èµ·çŠ¶æ…‹
- ã“ã‚Œã‚‰ã®é…ç½®ã§DFTè¨ˆç®—ï¼ˆ20é…ç½®è¿½åŠ ï¼‰
- åˆè¨ˆ40 DFTè¨ˆç®—ã€ç²¾åº¦ MAE = 3 meV/atom

**åŠ¹ç‡åŒ–ã®ç†ç”±**:

1. **æƒ…å ±é‡ã®æœ€å¤§åŒ–**:
   - é¡ä¼¼é…ç½®ã®é‡è¤‡ã‚’é¿ã‘ã‚‹
   - ãƒ¢ãƒ‡ãƒ«ãŒã€ŒçŸ¥ã‚‰ãªã„ã€é ˜åŸŸã‚’å„ªå…ˆ

2. **æ¢ç´¢ã¨æ´»ç”¨ã®ãƒãƒ©ãƒ³ã‚¹**:
   - æ—¢çŸ¥ã®é…ç½®ã§ã®å®‰å®šäºˆæ¸¬ï¼ˆæ´»ç”¨ï¼‰
   - æœªçŸ¥ã®é…ç½®ã§ã®æ–°æƒ…å ±ç²å¾—ï¼ˆæ¢ç´¢ï¼‰

3. **é©å¿œçš„ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°**:
   - ç³»ã®é‡è¦é ˜åŸŸï¼ˆåå¿œçµŒè·¯ã€ç›¸è»¢ç§»ï¼‰ã‚’è‡ªå‹•æ¤œå‡º
   - äººé–“ã®ç›´æ„Ÿã«é ¼ã‚‰ãªã„

**å®Ÿéš›ã®åŠ¹ç‡åŒ–**:
- 50-90%ã®DFTè¨ˆç®—å‰Šæ¸›ï¼ˆæ–‡çŒ®å€¤ï¼‰
- ç‰¹ã«è¤‡é›‘ãªç³»ï¼ˆå¤šæˆåˆ†ã€åå¿œç³»ï¼‰ã§åŠ¹æœå¤§
- è¨“ç·´æ™‚é–“å…¨ä½“ã§ã¯10-50å€ã®åŠ¹ç‡åŒ–

**ä¾‹: Li-ioné›»æ± é›»è§£æ¶²**:
- Random: 10,000 DFTè¨ˆç®—ã€2ãƒ¶æœˆ
- Active Learning: 2,000 DFTè¨ˆç®—ã€2é€±é–“
- åŠ¹ç‡åŒ–: 5å€ã€åŒç­‰ç²¾åº¦

</details>

<h3>å•é¡Œ3ï¼ˆé›£æ˜“åº¦ï¼šhardï¼‰</h3>
<p>Universal Machine Learning Potentialï¼ˆCHGNetã€M3GNetç­‰ï¼‰ã®åˆ©ç‚¹ã¨é™ç•Œã‚’è­°è«–ã—ã¦ãã ã•ã„ã€‚</p>
<details>
<summary>è§£ç­”ä¾‹</summary>

**Universal MLPï¼ˆä¾‹: CHGNetï¼‰ã®æ¦‚è¦**:

- **è¨“ç·´ãƒ‡ãƒ¼ã‚¿**: Materials Projectï¼ˆ140ä¸‡ææ–™ã€89å…ƒç´ ï¼‰
- **ãƒ¢ãƒ‡ãƒ«**: Graph Neural Network
- **äºˆæ¸¬**: ã‚¨ãƒãƒ«ã‚®ãƒ¼ã€åŠ›ã€å¿œåŠ›ã€ç£æ°—ãƒ¢ãƒ¼ãƒ¡ãƒ³ãƒˆ

**åˆ©ç‚¹**:

1. **å³åº§ã«ä½¿ãˆã‚‹**:
   - äº‹å‰è¨“ç·´æ¸ˆã¿ â†’ è¿½åŠ è¨“ç·´ä¸è¦
   - ä»»æ„ã®çµæ™¶æ§‹é€ ã§äºˆæ¸¬å¯èƒ½
   - æ•°ç§’ã§æ•°åƒææ–™ã‚’ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°

2. **åºƒã„é©ç”¨ç¯„å›²**:
   - 89å…ƒç´ ï¼ˆH-Amã¾ã§ï¼‰
   - é…¸åŒ–ç‰©ã€åˆé‡‘ã€åŠå°ä½“ã€çµ¶ç¸ä½“
   - ç£æ€§ææ–™ã‚‚å¯¾å¿œ

3. **è»¢ç§»å­¦ç¿’ã®åŸºç›¤**:
   - å°‘æ•°ãƒ‡ãƒ¼ã‚¿ï¼ˆ10-100ã‚µãƒ³ãƒ—ãƒ«ï¼‰ã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°
   - ç³»ç‰¹åŒ–ã®é«˜ç²¾åº¦ãƒ¢ãƒ‡ãƒ«ã‚’åŠ¹ç‡çš„ã«ä½œæˆ

4. **ææ–™æ¢ç´¢ã®åŠ é€Ÿ**:
   - å¤§è¦æ¨¡å€™è£œã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆ100ä¸‡ææ–™/æ—¥ï¼‰
   - å®Ÿé¨“å€™è£œã®çµã‚Šè¾¼ã¿
   - ãƒã‚¤ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆè¨ˆç®—ã¨ã®çµ„ã¿åˆã‚ã›

**é™ç•Œ**:

1. **ç²¾åº¦ã®é™ç•Œ**:
   - DFTèª¤å·®ã®ç´„2-5å€ç¨‹åº¦ï¼ˆCHGNet: MAE ~30 meV/atomï¼‰
   - ç²¾å¯†è¨ˆç®—ã«ã¯ä¸ååˆ†
   - ç‰¹å®šç³»ã§ã¯å°‚ç”¨MLPã«åŠ£ã‚‹

2. **å¤–æŒ¿ã®å•é¡Œ**:
   - è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã«ãªã„é…ç½®ï¼ˆæ¥µç«¯ãªæ¸©åº¦ãƒ»åœ§åŠ›ï¼‰ã§ç²¾åº¦ä½ä¸‹
   - æ–°è¦ææ–™ç³»ï¼ˆè¶…é«˜åœ§ã€æ–°å…ƒç´ çµ„ã¿åˆã‚ã›ï¼‰ã¯ä¸ç¢ºå®Ÿ

3. **ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ã‚¢ã‚¹**:
   - Materials Projectã®è¨ˆç®—æ¡ä»¶ï¼ˆPBEæ±é–¢æ•°ï¼‰ã«ä¾å­˜
   - å®Ÿé¨“ã¨ã®ç³»çµ±çš„ãªãšã‚Œï¼ˆãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—éå°è©•ä¾¡ç­‰ï¼‰
   - ç‰¹å®šææ–™ã‚¯ãƒ©ã‚¹ã®éå‰°/éå°‘è¡¨ç¾

4. **ç‰©ç†çš„åˆ¶ç´„ã®æ¬ å¦‚**:
   - ã‚¨ãƒãƒ«ã‚®ãƒ¼ä¿å­˜å‰‡ã®å³å¯†ãªä¿è¨¼ãªã—
   - é•·æ™‚é–“MDã§ã®ãƒ‰ãƒªãƒ•ãƒˆ
   - å¯¾ç§°æ€§ã®ç ´ã‚Œï¼ˆç¨€ï¼‰

**å®Ÿç”¨çš„æˆ¦ç•¥**:

**Scenario 1: ææ–™ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°**
- Universal MLPã§100ä¸‡å€™è£œã‹ã‚‰ä¸Šä½1000ã«çµã‚Šè¾¼ã¿
- DFTã§ç²¾å¯†è¨ˆç®—
- åŠ¹ç‡åŒ–: 1000å€

**Scenario 2: ç‰¹å®šç³»ã®ç²¾å¯†MD**
- Universal MLPã‹ã‚‰è»¢ç§»å­¦ç¿’
- ç³»ç‰¹åŒ–ãƒ‡ãƒ¼ã‚¿ï¼ˆ100ã‚µãƒ³ãƒ—ãƒ«ï¼‰ã§è¿½åŠ è¨“ç·´
- ç²¾åº¦å‘ä¸Š: MAE 5 meV/atomï¼ˆå®Ÿç”¨ãƒ¬ãƒ™ãƒ«ï¼‰

**Scenario 3: æ–°è¦ææ–™ã‚¯ãƒ©ã‚¹**
- Universal MLPã¯å‚è€ƒç¨‹åº¦
- ã‚¼ãƒ­ã‹ã‚‰å°‚ç”¨MLPæ§‹ç¯‰ï¼ˆActive Learningï¼‰
- è¨“ç·´ãƒ‡ãƒ¼ã‚¿: 500-1000ã‚µãƒ³ãƒ—ãƒ«

**å°†æ¥å±•æœ›**:

1. **ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æ‹¡å……**:
   - å®Ÿé¨“ãƒ‡ãƒ¼ã‚¿ã®çµ±åˆ
   - å¤šæ§˜ãªè¨ˆç®—æ‰‹æ³•ï¼ˆGWã€DMFTï¼‰ã®ãƒ‡ãƒ¼ã‚¿

2. **Foundation Modelsã¸ã®é€²åŒ–**:
   - è‡ªç„¶è¨€èªå‡¦ç†ã®GPTã«ç›¸å½“
   - Few-shot learningï¼ˆæ•°ã‚µãƒ³ãƒ—ãƒ«ã§é©å¿œï¼‰
   - Zero-shot transferï¼ˆè¨“ç·´ãªã—ã§æ–°è¦ç³»ï¼‰

3. **å®Ÿé¨“ã¨ã®é€£æº**:
   - è‡ªå¾‹å®Ÿé¨“ãƒ«ãƒ¼ãƒ—
   - ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯

**çµè«–**:
Universal MLPã¯ææ–™ç§‘å­¦ã®ã€ŒåŸºç›¤ã‚¤ãƒ³ãƒ•ãƒ©ã€ã¨ãªã‚Šã¤ã¤ã‚ã‚‹ãŒã€ä¸‡èƒ½ã§ã¯ãªã„ã€‚ç”¨é€”ã«å¿œã˜ã¦å°‚ç”¨MLPã¨ä½¿ã„åˆ†ã‘ãŒé‡è¦ã€‚

</details>

<hr />
<h2>ãƒ‡ãƒ¼ã‚¿ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¨å¼•ç”¨</h2>
<h3>ä½¿ç”¨ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ</h3>
<ol>
<li>
<p><strong>Materials Project Database</strong> (CC BY 4.0)
   - 140ä¸‡ææ–™ã®DFTãƒ‡ãƒ¼ã‚¿ï¼ˆCHGNetè¨“ç·´ï¼‰
   - URL: https://materialsproject.org
   - å¼•ç”¨: Jain, A., et al. (2013). <em>APL Materials</em>, 1, 011002.</p>
</li>
<li>
<p><strong>Open Catalyst Project</strong> (CC BY 4.0)
   - è§¦åª’è¡¨é¢ã®DFTãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
   - URL: https://opencatalystproject.org/</p>
</li>
<li>
<p><strong>QM9 Dataset</strong> (CC0)
   - å°åˆ†å­134,000å€‹ã®DFTãƒ‡ãƒ¼ã‚¿
   - URL: http://quantum-machine.org/datasets/</p>
</li>
</ol>
<h3>ä½¿ç”¨ã—ãŸã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢</h3>
<ol>
<li>
<p><strong>AMP - Atomistic Machine-learning Package</strong> (GPL v3)
   - URL: https://amp.readthedocs.io/</p>
</li>
<li>
<p><strong>CHGNet</strong> (MIT License)
   - Universal ML Potential
   - URL: https://github.com/CederGroupHub/chgnet</p>
</li>
<li>
<p><strong>M3GNet</strong> (BSD 3-Clause)
   - Graph Neural Network Potential
   - URL: https://github.com/materialsvirtuallab/m3gnet</p>
</li>
<li>
<p><strong>MACE</strong> (MIT License)
   - Equivariant Message Passing
   - URL: https://github.com/ACEsuit/mace</p>
</li>
</ol>
<hr />
<h2>ã‚³ãƒ¼ãƒ‰å†ç¾æ€§ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ</h2>
<h3>ç’°å¢ƒæ§‹ç¯‰</h3>
<pre><code class="language-bash"># MLPåŸºæœ¬ç’°å¢ƒ
conda create -n mlp python=3.11
conda activate mlp
conda install pytorch torchvision -c pytorch
conda install -c conda-forge ase gpaw

# å€‹åˆ¥MLPãƒ„ãƒ¼ãƒ«
pip install amp-atomistics  # AMP
pip install chgnet  # CHGNet
pip install m3gnet  # M3GNet
pip install mace-torch  # MACE
</code></pre>
<h3>GPUè¦ä»¶ï¼ˆæ¨å¥¨ï¼‰</h3>
<table>
<thead>
<tr>
<th>è¨“ç·´ãƒ‡ãƒ¼ã‚¿æ•°</th>
<th>GPU ãƒ¡ãƒ¢ãƒª</th>
<th>è¨“ç·´æ™‚é–“</th>
<th>æ¨å¥¨GPU</th>
</tr>
</thead>
<tbody>
<tr>
<td>100ã‚µãƒ³ãƒ—ãƒ«</td>
<td>~2 GB</td>
<td>~30åˆ†</td>
<td>GTX 1060</td>
</tr>
<tr>
<td>1,000ã‚µãƒ³ãƒ—ãƒ«</td>
<td>~8 GB</td>
<td>~3æ™‚é–“</td>
<td>RTX 3070</td>
</tr>
<tr>
<td>10,000ã‚µãƒ³ãƒ—ãƒ«</td>
<td>~16 GB</td>
<td>~1æ—¥</td>
<td>RTX 3090/A100</td>
</tr>
</tbody>
</table>
<h3>ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°</h3>
<p><strong>å•é¡Œ</strong>: CUDA out of memory
<strong>è§£æ±º</strong>:</p>
<pre><code class="language-python"># ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’å‰Šæ¸›
model.train(batch_size=8)  # 32 â†’ 8
</code></pre>
<p><strong>å•é¡Œ</strong>: è¨“ç·´ãŒåæŸã—ãªã„
<strong>è§£æ±º</strong>:</p>
<pre><code class="language-python"># å­¦ç¿’ç‡ã‚’èª¿æ•´
optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)  # 1e-3 â†’ 1e-4
</code></pre>
<hr />
<h2>å®Ÿè·µçš„ãªè½ã¨ã—ç©´ã¨å¯¾ç­–</h2>
<h3>1. è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®åã‚Š</h3>
<pre><code class="language-python"># âŒ é–“é•ã„: å¹³è¡¡æ§‹é€ ã®ã¿
train_data = [equilibrium_structures]  # ç¯„å›²ãŒç‹­ã™ã

# âœ… æ­£è§£: å¤šæ§˜ãªé…ç½®ã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
# - å¹³è¡¡æ§‹é€ 
# - MDè»Œé“ï¼ˆé«˜æ¸©ï¼‰
# - æ§‹é€ æœ€é©åŒ–é€”ä¸­
# - é«˜ã‚¨ãƒãƒ«ã‚®ãƒ¼é…ç½®
</code></pre>
<h3>2. åŠ›ã®é‡ã¿ãŒä¸é©åˆ‡</h3>
<pre><code class="language-python"># âŒ ä¸å‡è¡¡: ã‚¨ãƒãƒ«ã‚®ãƒ¼ã®ã¿é‡è¦–
loss = energy_loss  # åŠ›ã‚’ç„¡è¦–

# âœ… ãƒãƒ©ãƒ³ã‚¹: åŠ›ã‚‚é‡è¦–
loss = energy_loss + 0.1 * force_loss  # åŠ›ã®é‡ã¿0.1
</code></pre>
<h3>3. å¤–æŒ¿é ˜åŸŸã§ã®ä½¿ç”¨</h3>
<pre><code class="language-python"># âŒ å±é™º: è¨“ç·´ç¯„å›²å¤–ã§äºˆæ¸¬
# è¨“ç·´: 0-1000 K
# ä½¿ç”¨: 2000 K â†’ ä¸æ­£ç¢º

# âœ… å®‰å…¨: è¨“ç·´ç¯„å›²å†…ã§ä½¿ç”¨
# ã¾ãŸã¯ä¸ç¢ºå®Ÿæ€§æ¨å®šã§è­¦å‘Š
</code></pre>
<h3>4. Active Learningã®é–¾å€¤è¨­å®š</h3>
<pre><code class="language-python"># âŒ é–¾å€¤ãŒé«˜ã™ã â†’ ãƒ‡ãƒ¼ã‚¿ä¸è¶³
uncertainty_threshold = 10.0  # ç·©ã™ã

# âœ… é©åˆ‡ãªé–¾å€¤
uncertainty_threshold = 0.1  # ã‚¨ãƒãƒ«ã‚®ãƒ¼[eV/atom]
</code></pre>
<hr />
<h2>å“è³ªä¿è¨¼ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ</h2>
<h3>MLPè¨“ç·´ã®å¦¥å½“æ€§</h3>
<ul>
<li>[ ] è¨“ç·´èª¤å·®: Energy MAE &lt; 10 meV/atom</li>
<li>[ ] è¨“ç·´èª¤å·®: Force MAE &lt; 0.1 eV/Ã…</li>
<li>[ ] ãƒ†ã‚¹ãƒˆèª¤å·®ãŒè¨“ç·´èª¤å·®ã®2å€ä»¥å†…ï¼ˆéå­¦ç¿’ãªã—ï¼‰</li>
<li>[ ] æ¤œè¨¼ã‚»ãƒƒãƒˆã§ã®æ€§èƒ½ãŒå®‰å®š</li>
</ul>
<h3>ç‰©ç†çš„å¦¥å½“æ€§</h3>
<ul>
<li>[ ] ã‚¨ãƒãƒ«ã‚®ãƒ¼ä¿å­˜ï¼ˆNVE MDã§æ¤œè¨¼ï¼‰</li>
<li>[ ] ä¸¦é€²ãƒ»å›è»¢ä¸å¤‰æ€§</li>
<li>[ ] å¯¾ç§°æ€§ã®ä¿å­˜</li>
<li>[ ] ç•°å¸¸ãªåŠ›ï¼ˆ&gt; 10 eV/Ã…ï¼‰ãªã—</li>
</ul>
<h3>Active Learningã®åŠ¹ç‡</h3>
<ul>
<li>[ ] è¨“ç·´ãƒ‡ãƒ¼ã‚¿å‰Šæ¸›ç‡ &gt; 50%</li>
<li>[ ] åæŸã¾ã§ã®ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ &lt; 10å›</li>
<li>[ ] æœ€çµ‚ç²¾åº¦ãŒãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã¨åŒç­‰ä»¥ä¸Š</li>
</ul>
<hr />
<h2>å‚è€ƒæ–‡çŒ®</h2>
<ol>
<li>
<p>Behler, J., &amp; Parrinello, M. (2007). "Generalized Neural-Network Representation of High-Dimensional Potential-Energy Surfaces." <em>Physical Review Letters</em>, 98, 146401.
   DOI: <a href="https://doi.org/10.1103/PhysRevLett.98.146401">10.1103/PhysRevLett.98.146401</a></p>
</li>
<li>
<p>BartÃ³k, A. P., et al. (2010). "Gaussian Approximation Potentials: The Accuracy of Quantum Mechanics, without the Electrons." <em>Physical Review Letters</em>, 104, 136403.
   DOI: <a href="https://doi.org/10.1103/PhysRevLett.104.136403">10.1103/PhysRevLett.104.136403</a></p>
</li>
<li>
<p>SchÃ¼tt, K. T., et al. (2017). "SchNet: A continuous-filter convolutional neural network for modeling quantum interactions." <em>NeurIPS</em>.</p>
</li>
<li>
<p>Chen, C., &amp; Ong, S. P. (2022). "A universal graph deep learning interatomic potential for the periodic table." <em>Nature Computational Science</em>, 2, 718-728.
   DOI: <a href="https://doi.org/10.1038/s43588-022-00349-3">10.1038/s43588-022-00349-3</a></p>
</li>
<li>
<p>Batatia, I., et al. (2022). "MACE: Higher Order Equivariant Message Passing Neural Networks for Fast and Accurate Force Fields." <em>NeurIPS</em>.</p>
</li>
<li>
<p>CHGNet: https://github.com/CederGroupHub/chgnet</p>
</li>
<li>M3GNet: https://github.com/materialsvirtuallab/m3gnet</li>
<li>MACE: https://github.com/ACEsuit/mace</li>
</ol>
<hr />
<h2>è‘—è€…æƒ…å ±</h2>
<p><strong>ä½œæˆè€…</strong>: MI Knowledge Hub Content Team
<strong>ç›£ä¿®</strong>: Dr. Yusuke Hashimotoï¼ˆæ±åŒ—å¤§å­¦ï¼‰
<strong>ä½œæˆæ—¥</strong>: 2025-10-17
<strong>ãƒãƒ¼ã‚¸ãƒ§ãƒ³</strong>: 1.0
<strong>ã‚·ãƒªãƒ¼ã‚º</strong>: è¨ˆç®—ææ–™ç§‘å­¦åŸºç¤å…¥é–€ v1.0</p>
<p><strong>ãƒ©ã‚¤ã‚»ãƒ³ã‚¹</strong>: Creative Commons BY-NC-SA 4.0</p>
<hr />
<p><strong>ãŠã‚ã§ã¨ã†ã”ã–ã„ã¾ã™ï¼è¨ˆç®—ææ–™ç§‘å­¦åŸºç¤å…¥é–€ã‚·ãƒªãƒ¼ã‚ºã‚’å®Œäº†ã—ã¾ã—ãŸï¼</strong></p>
<p>æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ï¼š
- è‡ªåˆ†ã®ç ”ç©¶ãƒ†ãƒ¼ãƒã§å®Ÿéš›ã«è¨ˆç®—ã‚’å®Ÿè¡Œ
- ãƒã‚¤ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆè¨ˆç®—å…¥é–€ã‚·ãƒªãƒ¼ã‚ºã¸é€²ã‚€
- æœ€æ–°è«–æ–‡ã‚’èª­ã‚“ã§çŸ¥è­˜ã‚’æ·±ã‚ã‚‹
- ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã«å‚åŠ ï¼ˆGitHubã€å­¦ä¼šï¼‰</p>
<p><strong>ç¶™ç¶šçš„ãªå­¦ç¿’ãŒææ–™ç§‘å­¦ã®æœªæ¥ã‚’æ‹“ãã¾ã™ï¼</strong></p><div class="navigation">
    <a href="chapter-4.html" class="nav-button">â† å‰ã®ç« </a>
    <a href="index.html" class="nav-button">ã‚·ãƒªãƒ¼ã‚ºç›®æ¬¡ã«æˆ»ã‚‹</a>
</div>
    </main>

    <footer>
        <p><strong>ä½œæˆè€…</strong>: AI Terakoya Content Team</p>
        <p><strong>ç›£ä¿®</strong>: Dr. Yusuke Hashimotoï¼ˆæ±åŒ—å¤§å­¦ï¼‰</p>
        <p><strong>ãƒãƒ¼ã‚¸ãƒ§ãƒ³</strong>: 1.0 | <strong>ä½œæˆæ—¥</strong>: 2025-10-17</p>
        <p><strong>ãƒ©ã‚¤ã‚»ãƒ³ã‚¹</strong>: Creative Commons BY 4.0</p>
        <p>Â© 2025 AI Terakoya. All rights reserved.</p>
    </footer>
</body>
</html>
