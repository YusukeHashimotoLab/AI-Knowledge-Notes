<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Chapter - AI Terakoya</title>

    <style>
        :root {
            --color-primary: #2c3e50;
            --color-primary-dark: #1a252f;
            --color-accent: #7b2cbf;
            --color-accent-light: #9d4edd;
            --color-text: #2d3748;
            --color-text-light: #4a5568;
            --color-bg: #ffffff;
            --color-bg-alt: #f7fafc;
            --color-border: #e2e8f0;
            --color-code-bg: #f8f9fa;
            --color-link: #3182ce;
            --color-link-hover: #2c5aa0;

            --spacing-xs: 0.5rem;
            --spacing-sm: 1rem;
            --spacing-md: 1.5rem;
            --spacing-lg: 2rem;
            --spacing-xl: 3rem;

            --font-body: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            --font-mono: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;

            --border-radius: 8px;
            --box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: var(--font-body);
            line-height: 1.7;
            color: var(--color-text);
            background-color: var(--color-bg);
            font-size: 16px;
        }

        header {
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            padding: var(--spacing-xl) var(--spacing-md);
            margin-bottom: var(--spacing-xl);
            box-shadow: var(--box-shadow);
        }

        .header-content {
            max-width: 900px;
            margin: 0 auto;
        }

        h1 {
            font-size: 2rem;
            font-weight: 700;
            margin-bottom: var(--spacing-sm);
            line-height: 1.2;
        }

        .subtitle {
            font-size: 1.1rem;
            opacity: 0.95;
            font-weight: 400;
            margin-bottom: var(--spacing-md);
        }

        .meta {
            display: flex;
            flex-wrap: wrap;
            gap: var(--spacing-md);
            font-size: 0.9rem;
            opacity: 0.9;
        }

        .meta-item {
            display: flex;
            align-items: center;
            gap: 0.3rem;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 0 var(--spacing-md) var(--spacing-xl);
        }

        h2 {
            font-size: 1.75rem;
            color: var(--color-primary);
            margin-top: var(--spacing-xl);
            margin-bottom: var(--spacing-md);
            padding-bottom: var(--spacing-xs);
            border-bottom: 3px solid var(--color-accent);
        }

        h3 {
            font-size: 1.4rem;
            color: var(--color-primary);
            margin-top: var(--spacing-lg);
            margin-bottom: var(--spacing-sm);
        }

        h4 {
            font-size: 1.1rem;
            color: var(--color-primary-dark);
            margin-top: var(--spacing-md);
            margin-bottom: var(--spacing-sm);
        }

        p {
            margin-bottom: var(--spacing-md);
            color: var(--color-text);
        }

        a {
            color: var(--color-link);
            text-decoration: none;
            transition: color 0.2s;
        }

        a:hover {
            color: var(--color-link-hover);
            text-decoration: underline;
        }

        ul, ol {
            margin-left: var(--spacing-lg);
            margin-bottom: var(--spacing-md);
        }

        li {
            margin-bottom: var(--spacing-xs);
            color: var(--color-text);
        }

        pre {
            background-color: var(--color-code-bg);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            overflow-x: auto;
            margin-bottom: var(--spacing-md);
            font-family: var(--font-mono);
            font-size: 0.9rem;
            line-height: 1.5;
        }

        code {
            font-family: var(--font-mono);
            font-size: 0.9em;
            background-color: var(--color-code-bg);
            padding: 0.2em 0.4em;
            border-radius: 3px;
        }

        pre code {
            background-color: transparent;
            padding: 0;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: var(--spacing-md);
            font-size: 0.95rem;
        }

        th, td {
            border: 1px solid var(--color-border);
            padding: var(--spacing-sm);
            text-align: left;
        }

        th {
            background-color: var(--color-bg-alt);
            font-weight: 600;
            color: var(--color-primary);
        }

        blockquote {
            border-left: 4px solid var(--color-accent);
            padding-left: var(--spacing-md);
            margin: var(--spacing-md) 0;
            color: var(--color-text-light);
            font-style: italic;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        .mermaid {
            text-align: center;
            margin: var(--spacing-lg) 0;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        details {
            background-color: var(--color-bg-alt);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            margin-bottom: var(--spacing-md);
        }

        summary {
            cursor: pointer;
            font-weight: 600;
            color: var(--color-primary);
            user-select: none;
            padding: var(--spacing-xs);
            margin: calc(-1 * var(--spacing-md));
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        summary:hover {
            background-color: rgba(123, 44, 191, 0.1);
        }

        details[open] summary {
            margin-bottom: var(--spacing-md);
            border-bottom: 1px solid var(--color-border);
        }

        .learning-objectives {
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
            padding: var(--spacing-lg);
            border-radius: var(--border-radius);
            border-left: 4px solid var(--color-accent);
            margin-bottom: var(--spacing-xl);
        }

        .learning-objectives h2 {
            margin-top: 0;
            border-bottom: none;
        }

        .navigation {
            display: flex;
            justify-content: space-between;
            gap: var(--spacing-md);
            margin: var(--spacing-xl) 0;
            padding-top: var(--spacing-lg);
            border-top: 2px solid var(--color-border);
        }

        .nav-button {
            flex: 1;
            padding: var(--spacing-md);
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            border-radius: var(--border-radius);
            text-align: center;
            font-weight: 600;
            transition: transform 0.2s, box-shadow 0.2s;
            box-shadow: var(--box-shadow);
        }

        .nav-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
            text-decoration: none;
        }

        footer {
            margin-top: var(--spacing-xl);
            padding: var(--spacing-lg) var(--spacing-md);
            background-color: var(--color-bg-alt);
            border-top: 1px solid var(--color-border);
            text-align: center;
            font-size: 0.9rem;
            color: var(--color-text-light);
        }
        .disclaimer {
            max-width: 900px;
            margin: 2rem auto;
            padding: 1.5rem;
            background: #f8f9fa;
            border-left: 4px solid #6c757d;
            border-radius: 4px;
        }

        .disclaimer h3 {
            color: #495057;
            margin-bottom: 1rem;
            font-size: 1.1rem;
        }

        .disclaimer ul {
            list-style: none;
            padding-left: 0;
        }

        .disclaimer li {
            padding: 0.5rem 0;
            padding-left: 1.5rem;
            position: relative;
            font-size: 0.9rem;
            color: #6c757d;
            line-height: 1.6;
        }

        .disclaimer li::before {
            content: "âš ï¸";
            position: absolute;
            left: 0;
        }


        @media (max-width: 768px) {
            h1 {
                font-size: 1.5rem;
            }

            h2 {
                font-size: 1.4rem;
            }

            h3 {
                font-size: 1.2rem;
            }

            .meta {
                font-size: 0.85rem;
            }

            .navigation {
                flex-direction: column;
            }

            table {
                font-size: 0.85rem;
            }

            th, td {
                padding: var(--spacing-xs);
            }
        }
    
        /* Breadcrumb styles */
        .breadcrumb {
            background: #f7fafc;
            padding: 0.75rem 1rem;
            border-bottom: 1px solid #e2e8f0;
            font-size: 0.9rem;
        }

        .breadcrumb-content {
            max-width: 900px;
            margin: 0 auto;
            display: flex;
            align-items: center;
            flex-wrap: wrap;
            gap: 0.5rem;
        }

        .breadcrumb a {
            color: #667eea;
            text-decoration: none;
            transition: color 0.2s;
        }

        .breadcrumb a:hover {
            color: #764ba2;
            text-decoration: underline;
        }

        .breadcrumb-separator {
            color: #a0aec0;
            margin: 0 0.25rem;
        }

        .breadcrumb-current {
            color: #4a5568;
            font-weight: 500;
        }
    </style>

    <script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
    <script>
        mermaid.initialize({ startOnLoad: true, theme: 'default', securityLevel: 'strict' });
    </script>

    <!-- MathJax for LaTeX equation rendering -->
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\(', '\)']],
                displayMath: [['$$', '$$'], ['\[', '\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
                ignoreHtmlClass: 'mermaid'
            }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" async></script>
</head>
<body>
        <nav class="breadcrumb">
        <div class="breadcrumb-content">
            <a href="/wp/knowledge/jp/index.html">AIå¯ºå­å±‹ãƒˆãƒƒãƒ—</a><span class="breadcrumb-separator">â€º</span><a href="/wp/knowledge/jp/MI/index.html">ãƒãƒ†ãƒªã‚¢ãƒ«ã‚ºãƒ»ã‚¤ãƒ³ãƒ•ã‚©ãƒãƒ†ã‚£ã‚¯ã‚¹</a><span class="breadcrumb-separator">â€º</span><a href="/wp/knowledge/jp/MI/data-driven-materials-introduction/index.html">Data Driven Materials</a><span class="breadcrumb-separator">â€º</span><span class="breadcrumb-current">Chapter 4</span>
        </div>
    </nav>

    <header>
        <div class="header-content">
            <h1>Chapter</h1>
            <p class="subtitle"></p>
            <div class="meta">
                <span class="meta-item">ğŸ“– èª­äº†æ™‚é–“: 20-25åˆ†</span>
                <span class="meta-item">ğŸ“Š é›£æ˜“åº¦: åˆç´š</span>
                <span class="meta-item">ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹: 0å€‹</span>
                <span class="meta-item">ğŸ“ æ¼”ç¿’å•é¡Œ: 0å•</span>
            </div>
        </div>
    </header>

    <main class="container">
<h1>Chapter 4: è§£é‡ˆå¯èƒ½AI (XAI)</h1>
<hr />
<h2>å­¦ç¿’ç›®æ¨™</h2>
<p>ã“ã®ç« ã‚’èª­ã‚€ã“ã¨ã§ã€ä»¥ä¸‹ã‚’ç¿’å¾—ã§ãã¾ã™ï¼š</p>
<p>âœ… è§£é‡ˆå¯èƒ½æ€§ã®é‡è¦æ€§ã¨ãƒ–ãƒ©ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹å•é¡Œã®ç†è§£
âœ… SHAPï¼ˆShapleyå€¤ï¼‰ã«ã‚ˆã‚‹äºˆæ¸¬ã®å®šé‡çš„è§£é‡ˆ
âœ… LIMEã«ã‚ˆã‚‹å±€æ‰€çš„ãªç·šå½¢è¿‘ä¼¼ã¨èª¬æ˜ç”Ÿæˆ
âœ… Attentionå¯è¦–åŒ–ã«ã‚ˆã‚‹ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®è§£é‡ˆ
âœ… ãƒˆãƒ¨ã‚¿ãƒ»IBMãƒ»Citrineãªã©å®Ÿä¸–ç•Œå¿œç”¨äº‹ä¾‹ã®å­¦ç¿’
âœ… ææ–™ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ãƒ†ã‚£ã‚¹ãƒˆã®ã‚­ãƒ£ãƒªã‚¢ãƒ‘ã‚¹ã¨å¹´åæƒ…å ±</p>
<hr />
<h2>4.1 è§£é‡ˆå¯èƒ½æ€§ã®é‡è¦æ€§</h2>
<p>æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬ã‚’ç†è§£ã—ã€ç‰©ç†çš„æ„å‘³ã‚’æŠ½å‡ºã™ã‚‹ã“ã¨ãŒææ–™ç§‘å­¦ã§ã¯ä¸å¯æ¬ ã§ã™ã€‚</p>
<h3>ãƒ–ãƒ©ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹å•é¡Œ</h3>
<pre><code class="language-python">import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import Ridge

# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿
np.random.seed(42)
X = np.random.randn(200, 10)
y = 2*X[:, 0] + 3*X[:, 1] - 1.5*X[:, 2] + np.random.normal(0, 0.5, 200)

# è§£é‡ˆå¯èƒ½ãƒ¢ãƒ‡ãƒ« vs ãƒ–ãƒ©ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ãƒ¢ãƒ‡ãƒ«
ridge = Ridge(alpha=1.0)
rf = RandomForestRegressor(n_estimators=100, random_state=42)

ridge.fit(X, y)
rf.fit(X, y)

# Ridgeä¿‚æ•°ï¼ˆè§£é‡ˆå¯èƒ½ï¼‰
ridge_coefs = ridge.coef_

# å¯è¦–åŒ–ï¼šãƒ¢ãƒ‡ãƒ«è§£é‡ˆæ€§ã®é•ã„
fig, axes = plt.subplots(1, 2, figsize=(14, 6))

# Ridge: ç·šå½¢ä¿‚æ•°ã§æ˜ç¢º
axes[0].bar(range(len(ridge_coefs)), ridge_coefs,
            color='steelblue', alpha=0.7)
axes[0].set_xlabel('ç‰¹å¾´é‡ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹', fontsize=11)
axes[0].set_ylabel('ä¿‚æ•°', fontsize=11)
axes[0].set_title('Ridgeå›å¸°ï¼ˆè§£é‡ˆå¯èƒ½ï¼‰', fontsize=12, fontweight='bold')
axes[0].axhline(y=0, color='red', linestyle='--', linewidth=1)
axes[0].grid(alpha=0.3)

# Random Forest: è¤‡é›‘ãªéç·šå½¢é–¢ä¿‚ï¼ˆãƒ–ãƒ©ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ï¼‰
axes[1].text(0.5, 0.5, 'â“\nãƒ–ãƒ©ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹\n\n100æœ¬ã®æ±ºå®šæœ¨\nè¤‡é›‘ãªéç·šå½¢é–¢ä¿‚\nè§£é‡ˆå›°é›£',
             ha='center', va='center', fontsize=16,
             bbox=dict(boxstyle='round', facecolor='gray', alpha=0.3),
             transform=axes[1].transAxes)
axes[1].set_title('Random Forestï¼ˆãƒ–ãƒ©ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ï¼‰',
                  fontsize=12, fontweight='bold')
axes[1].axis('off')

plt.tight_layout()
plt.show()

print(&quot;è§£é‡ˆå¯èƒ½æ€§ã®èª²é¡Œï¼š&quot;)
print(&quot;- ç·šå½¢ãƒ¢ãƒ‡ãƒ«: ä¿‚æ•°ã§å½±éŸ¿åº¦ãŒæ˜ç¢ºã ãŒã€ç²¾åº¦ãŒä½ã„&quot;)
print(&quot;- éç·šå½¢ãƒ¢ãƒ‡ãƒ«: é«˜ç²¾åº¦ã ãŒã€ãªãœãã®äºˆæ¸¬ã«ãªã£ãŸã‹ä¸æ˜&quot;)
print(&quot;â†’ XAIï¼ˆè§£é‡ˆå¯èƒ½AIï¼‰ã§ä¸¡ç«‹ã‚’ç›®æŒ‡ã™&quot;)
</code></pre>
<h3>ææ–™ç§‘å­¦ã«ãŠã‘ã‚‹ç‰©ç†çš„è§£é‡ˆã®å¿…è¦æ€§</h3>
<pre><code class="language-python"># ææ–™ç§‘å­¦ã§ã®è§£é‡ˆå¯èƒ½æ€§ã®ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹
use_cases = pd.DataFrame({
    'ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹': [
        'æ–°ææ–™ç™ºè¦‹',
        'åˆæˆæ¡ä»¶æœ€é©åŒ–',
        'ãƒ—ãƒ­ã‚»ã‚¹ç•°å¸¸æ¤œå‡º',
        'ç‰©æ€§äºˆæ¸¬',
        'ææ–™è¨­è¨ˆã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³'
    ],
    'è§£é‡ˆæ€§ã®é‡è¦åº¦': [10, 9, 8, 7, 10],
    'ç†ç”±': [
        'ç‰©ç†çš„ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã®ç†è§£ãŒæ–°ç™ºè¦‹ã«ã¤ãªãŒã‚‹',
        'ã©ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒé‡è¦ã‹ã‚’ç‰¹å®š',
        'ç•°å¸¸ã®åŸå› ç‰¹å®šãŒå¿…è¦',
        'äºˆæ¸¬æ ¹æ‹ ã®æ¤œè¨¼',
        'è¨­è¨ˆæŒ‡é‡ã®æŠ½å‡º'
    ]
})

# å¯è¦–åŒ–
fig, ax = plt.subplots(figsize=(12, 6))

colors = plt.cm.YlOrRd(np.linspace(0.3, 0.9, len(use_cases)))

bars = ax.barh(use_cases['ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹'],
               use_cases['è§£é‡ˆæ€§ã®é‡è¦åº¦'],
               color=colors, alpha=0.7)

ax.set_xlabel('è§£é‡ˆæ€§ã®é‡è¦åº¦ï¼ˆ1-10ï¼‰', fontsize=12)
ax.set_xlim(0, 10)
ax.set_title('ææ–™ç§‘å­¦ã«ãŠã‘ã‚‹è§£é‡ˆå¯èƒ½æ€§ã®é‡è¦åº¦',
             fontsize=13, fontweight='bold')
ax.grid(axis='x', alpha=0.3)

# ç†ç”±ã‚’æ³¨é‡ˆ
for idx, row in use_cases.iterrows():
    ax.text(row['è§£é‡ˆæ€§ã®é‡è¦åº¦'] + 0.3, idx,
            row['ç†ç”±'], va='center', fontsize=9, style='italic')

plt.tight_layout()
plt.show()

print(&quot;ææ–™ç§‘å­¦ã§XAIãŒå¿…è¦ãªç†ç”±ï¼š&quot;)
print(&quot;1. ç‰©ç†æ³•å‰‡ã¨ã®æ•´åˆæ€§æ¤œè¨¼&quot;)
print(&quot;2. å®Ÿé¨“è¨ˆç”»ã¸ã®åæ˜ &quot;)
print(&quot;3. å°‚é–€å®¶çŸ¥è­˜ã¨ã®çµ±åˆ&quot;)
print(&quot;4. è«–æ–‡ãƒ»ç‰¹è¨±ã§ã®èª¬æ˜è²¬ä»»&quot;)
</code></pre>
<h3>ä¿¡é ¼æ€§ã¨ãƒ‡ãƒãƒƒã‚°</h3>
<pre><code class="language-python"># ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬ãƒŸã‚¹ã‚’è§£é‡ˆã§ç™ºè¦‹ã™ã‚‹ä¾‹
from sklearn.model_data import train_test_split
from sklearn.metrics import mean_absolute_error

# ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆï¼ˆæ„å›³çš„ã«ãƒã‚¤ã‚ºã‚’å«ã‚€ï¼‰
X_data = np.random.randn(300, 5)
# æ­£ã—ã„é–¢ä¿‚: y = 2*X0 + 3*X1
y_true = 2*X_data[:, 0] + 3*X_data[:, 1] + np.random.normal(0, 0.3, 300)

# ä¸€éƒ¨ã®ã‚µãƒ³ãƒ—ãƒ«ã«ãƒã‚¤ã‚ºæ··å…¥ï¼ˆæ¸¬å®šã‚¨ãƒ©ãƒ¼ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
noise_idx = np.random.choice(300, 30, replace=False)
y_data = y_true.copy()
y_data[noise_idx] += np.random.normal(0, 5, 30)

# è¨“ç·´
X_train, X_test, y_train, y_test = train_test_split(
    X_data, y_data, test_size=0.2, random_state=42
)

model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# äºˆæ¸¬
y_pred = model.predict(X_test)
mae = mean_absolute_error(y_test, y_pred)

# èª¤å·®ãŒå¤§ãã„ã‚µãƒ³ãƒ—ãƒ«ã‚’ç‰¹å®š
errors = np.abs(y_test - y_pred)
high_error_idx = np.where(errors &gt; np.percentile(errors, 90))[0]

print(f&quot;ãƒ¢ãƒ‡ãƒ«MAE: {mae:.4f}&quot;)
print(f&quot;é«˜èª¤å·®ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(high_error_idx)}&quot;)
print(&quot;\nâ†’ XAIã§é«˜èª¤å·®ã‚µãƒ³ãƒ—ãƒ«ã®åŸå› ã‚’åˆ†æ&quot;)
print(&quot;  - ãƒ‡ãƒ¼ã‚¿å“è³ªå•é¡Œã®ç™ºè¦‹&quot;)
print(&quot;  - ãƒ¢ãƒ‡ãƒ«ã®å¼±ç‚¹ç‰¹å®š&quot;)
print(&quot;  - ç‰©ç†çš„å¦¥å½“æ€§ã®æ¤œè¨¼&quot;)
</code></pre>
<hr />
<h2>4.2 SHAP (SHapley Additive exPlanations)</h2>
<p>Shapleyå€¤ã«åŸºã¥ãå”åŠ›ã‚²ãƒ¼ãƒ ç†è«–ã‹ã‚‰ã®è§£é‡ˆæ‰‹æ³•ã§ã™ã€‚</p>
<h3>Shapleyå€¤ã®ç†è«–</h3>
<pre><code class="language-python">import shap

# SHAPåŸºæœ¬æ¦‚å¿µã®å¯è¦–åŒ–
shap.initjs()

# ãƒ¢ãƒ‡ãƒ«è¨“ç·´
model_shap = RandomForestRegressor(n_estimators=100, random_state=42)
model_shap.fit(X_train, y_train)

# SHAP Explainer
explainer = shap.TreeExplainer(model_shap)
shap_values = explainer.shap_values(X_test)

print(&quot;SHAPå€¤ã®æ„å‘³ï¼š&quot;)
print(&quot;- å„ç‰¹å¾´é‡ãŒäºˆæ¸¬å€¤ã«ã©ã‚Œã ã‘å¯„ä¸ã—ãŸã‹&quot;)
print(&quot;- Shapleyå€¤: å”åŠ›ã‚²ãƒ¼ãƒ ç†è«–ã®å…¬å¹³ãªåˆ†é…&quot;)
print(&quot;- åŸºæº–å€¤ï¼ˆbase valueï¼‰ã‹ã‚‰ã®åå·®ã¨ã—ã¦è¡¨ç¾&quot;)
print(f&quot;\nSHAPå€¤ã®å½¢çŠ¶: {shap_values.shape}&quot;)
print(f&quot;  ã‚µãƒ³ãƒ—ãƒ«æ•°: {shap_values.shape[0]}&quot;)
print(f&quot;  ç‰¹å¾´é‡æ•°: {shap_values.shape[1]}&quot;)

# å˜ä¸€ã‚µãƒ³ãƒ—ãƒ«ã®èª¬æ˜
sample_idx = 0
base_value = explainer.expected_value
prediction = model_shap.predict(X_test[sample_idx:sample_idx+1])[0]

print(f&quot;\nã‚µãƒ³ãƒ—ãƒ« {sample_idx} ã®äºˆæ¸¬:&quot;)
print(f&quot;åŸºæº–å€¤: {base_value:.4f}&quot;)
print(f&quot;SHAPå€¤åˆè¨ˆ: {shap_values[sample_idx].sum():.4f}&quot;)
print(f&quot;äºˆæ¸¬å€¤: {prediction:.4f}&quot;)
print(f&quot;æ¤œè¨¼: {base_value + shap_values[sample_idx].sum():.4f} â‰ˆ {prediction:.4f}&quot;)
</code></pre>
<h3>SHAPå€¤ã®è¨ˆç®—ï¼ˆTree SHAP, Kernel SHAPï¼‰</h3>
<pre><code class="language-python"># Tree SHAPï¼ˆé«˜é€Ÿã€æœ¨ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«å°‚ç”¨ï¼‰
explainer_tree = shap.TreeExplainer(model_shap)
shap_values_tree = explainer_tree.shap_values(X_test)

# Kernel SHAPï¼ˆãƒ¢ãƒ‡ãƒ«éä¾å­˜ã€é…ã„ï¼‰
# å°ã‚µãƒ³ãƒ—ãƒ«ã§ãƒ‡ãƒ¢
X_test_small = X_test[:10]
explainer_kernel = shap.KernelExplainer(
    model_shap.predict,
    shap.sample(X_train, 50)
)
shap_values_kernel = explainer_kernel.shap_values(X_test_small)

print(&quot;SHAPè¨ˆç®—æ‰‹æ³•ã®æ¯”è¼ƒï¼š&quot;)
print(&quot;\nTree SHAP:&quot;)
print(f&quot;  å¯¾è±¡ãƒ¢ãƒ‡ãƒ«: Tree-based (RF, XGBoost, LightGBM)&quot;)
print(f&quot;  è¨ˆç®—é€Ÿåº¦: é«˜é€Ÿ&quot;)
print(f&quot;  ç²¾åº¦: å³å¯†è§£&quot;)

print(&quot;\nKernel SHAP:&quot;)
print(f&quot;  å¯¾è±¡ãƒ¢ãƒ‡ãƒ«: ä»»æ„ï¼ˆãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚‚å¯ï¼‰&quot;)
print(f&quot;  è¨ˆç®—é€Ÿåº¦: é…ã„&quot;)
print(f&quot;  ç²¾åº¦: è¿‘ä¼¼è§£ï¼ˆã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ™ãƒ¼ã‚¹ï¼‰&quot;)

# è¨ˆç®—æ™‚é–“æ¯”è¼ƒï¼ˆç°¡æ˜“ï¼‰
import time

start = time.time()
_ = explainer_tree.shap_values(X_test)
tree_time = time.time() - start

print(f&quot;\nTree SHAPè¨ˆç®—æ™‚é–“: {tree_time:.3f}ç§’ ({len(X_test)}ã‚µãƒ³ãƒ—ãƒ«)&quot;)
</code></pre>
<h3>Global vs Localè§£é‡ˆ</h3>
<pre><code class="language-python"># Globalè§£é‡ˆ: å…¨ã‚µãƒ³ãƒ—ãƒ«ã§ã®å¹³å‡çš„é‡è¦åº¦
mean_abs_shap = np.abs(shap_values).mean(axis=0)

fig, axes = plt.subplots(1, 2, figsize=(14, 6))

# Globalè§£é‡ˆ
axes[0].bar(range(len(mean_abs_shap)), mean_abs_shap,
            color='steelblue', alpha=0.7)
axes[0].set_xlabel('ç‰¹å¾´é‡ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹', fontsize=11)
axes[0].set_ylabel('å¹³å‡|SHAPå€¤|', fontsize=11)
axes[0].set_title('Globalè§£é‡ˆï¼ˆå…¨ä½“çš„é‡è¦åº¦ï¼‰',
                  fontsize=12, fontweight='bold')
axes[0].grid(alpha=0.3)

# Localè§£é‡ˆ: ç‰¹å®šã‚µãƒ³ãƒ—ãƒ«
sample_idx = 0
axes[1].bar(range(len(shap_values[sample_idx])),
            shap_values[sample_idx],
            color='coral', alpha=0.7)
axes[1].axhline(y=0, color='black', linestyle='-', linewidth=1)
axes[1].set_xlabel('ç‰¹å¾´é‡ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹', fontsize=11)
axes[1].set_ylabel('SHAPå€¤', fontsize=11)
axes[1].set_title(f'Localè§£é‡ˆï¼ˆã‚µãƒ³ãƒ—ãƒ«{sample_idx}ã®èª¬æ˜ï¼‰',
                  fontsize=12, fontweight='bold')
axes[1].grid(alpha=0.3)

plt.tight_layout()
plt.show()

print(&quot;Globalè§£é‡ˆ vs Localè§£é‡ˆï¼š&quot;)
print(&quot;\nGlobal:&quot;)
print(&quot;  - å…¨ã‚µãƒ³ãƒ—ãƒ«ã§ã®å¹³å‡çš„ãªç‰¹å¾´é‡é‡è¦åº¦&quot;)
print(&quot;  - ãƒ¢ãƒ‡ãƒ«å…¨ä½“ã®æŒ™å‹•ç†è§£&quot;)
print(&quot;  - æ–°ææ–™è¨­è¨ˆã®ä¸€èˆ¬çš„ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³&quot;)

print(&quot;\nLocal:&quot;)
print(&quot;  - å€‹ã€…ã®äºˆæ¸¬ã®æ ¹æ‹ èª¬æ˜&quot;)
print(&quot;  - ç•°å¸¸ã‚µãƒ³ãƒ—ãƒ«ã®åŸå› ç‰¹å®š&quot;)
print(&quot;  - ç‰¹å®šææ–™ã®æœ€é©åŒ–æ–¹å‘&quot;)
</code></pre>
<h3>Summary plot, Dependence plot</h3>
<pre><code class="language-python"># Summary plotï¼ˆå…¨ä½“åƒï¼‰
plt.figure(figsize=(10, 8))
shap.summary_plot(shap_values, X_test, plot_type=&quot;dot&quot;, show=False)
plt.title('SHAP Summary Plot', fontsize=13, fontweight='bold', pad=20)
plt.tight_layout()
plt.show()

print(&quot;Summary Plotã®èª­ã¿æ–¹ï¼š&quot;)
print(&quot;- ç¸¦è»¸: ç‰¹å¾´é‡ï¼ˆé‡è¦åº¦é †ï¼‰&quot;)
print(&quot;- æ¨ªè»¸: SHAPå€¤ï¼ˆäºˆæ¸¬ã¸ã®å½±éŸ¿ï¼‰&quot;)
print(&quot;- è‰²: ç‰¹å¾´é‡ã®å€¤ï¼ˆèµ¤=é«˜ã€é’=ä½ï¼‰&quot;)
print(&quot;- åˆ†å¸ƒ: å„ç‰¹å¾´é‡ã®å½±éŸ¿ã®å¤šæ§˜æ€§&quot;)

# Dependence plotï¼ˆå€‹åˆ¥ç‰¹å¾´é‡ã®è©³ç´°ï¼‰
feature_idx = 0

plt.figure(figsize=(10, 6))
shap.dependence_plot(
    feature_idx,
    shap_values,
    X_test,
    show=False
)
plt.title(f'SHAP Dependence Plot (ç‰¹å¾´é‡ {feature_idx})',
          fontsize=13, fontweight='bold')
plt.tight_layout()
plt.show()

print(&quot;\nDependence Plotã®èª­ã¿æ–¹ï¼š&quot;)
print(&quot;- æ¨ªè»¸: ç‰¹å¾´é‡ã®å€¤&quot;)
print(&quot;- ç¸¦è»¸: SHAPå€¤ï¼ˆäºˆæ¸¬ã¸ã®å½±éŸ¿ï¼‰&quot;)
print(&quot;- è‰²: ç›¸äº’ä½œç”¨ã™ã‚‹ä»–ã®ç‰¹å¾´é‡&quot;)
print(&quot;- å‚¾å‘: éç·šå½¢é–¢ä¿‚ã®å¯è¦–åŒ–&quot;)
</code></pre>
<hr />
<h2>4.3 LIME (Local Interpretable Model-agnostic Explanations)</h2>
<p>å±€æ‰€çš„ãªç·šå½¢è¿‘ä¼¼ã«ã‚ˆã‚‹èª¬æ˜ç”Ÿæˆæ‰‹æ³•ã§ã™ã€‚</p>
<h3>å±€æ‰€ç·šå½¢è¿‘ä¼¼</h3>
<pre><code class="language-python">from lime import lime_tabular

# LIME Explainer
lime_explainer = lime_tabular.LimeTabularExplainer(
    X_train,
    mode='regression',
    feature_names=[f'Feature_{i}' for i in range(X_train.shape[1])],
    verbose=False
)

# å˜ä¸€ã‚µãƒ³ãƒ—ãƒ«ã®èª¬æ˜
sample_idx = 0
explanation = lime_explainer.explain_instance(
    X_test[sample_idx],
    model_shap.predict,
    num_features=5
)

# å¯è¦–åŒ–
fig = explanation.as_pyplot_figure()
plt.title(f'LIME Explanation (ã‚µãƒ³ãƒ—ãƒ« {sample_idx})',
          fontsize=13, fontweight='bold')
plt.tight_layout()
plt.show()

print(&quot;LIMEã®ä»•çµ„ã¿ï¼š&quot;)
print(&quot;1. å¯¾è±¡ã‚µãƒ³ãƒ—ãƒ«å‘¨è¾ºã§ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°&quot;)
print(&quot;2. ãƒ–ãƒ©ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ãƒ¢ãƒ‡ãƒ«ã§äºˆæ¸¬&quot;)
print(&quot;3. è·é›¢ã«åŸºã¥ãé‡ã¿ä»˜ã‘&quot;)
print(&quot;4. å±€æ‰€çš„ãªç·šå½¢ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’&quot;)
print(&quot;5. ç·šå½¢ä¿‚æ•°ã§èª¬æ˜&quot;)

# èª¬æ˜ã®æ•°å€¤è¡¨ç¤º
print(&quot;\nèª¬æ˜ï¼ˆé‡è¦åº¦é †ï¼‰:&quot;)
for feature, weight in explanation.as_list():
    print(f&quot;  {feature}: {weight:.4f}&quot;)
</code></pre>
<h3>Tabular LIME</h3>
<pre><code class="language-python"># è¤‡æ•°ã‚µãƒ³ãƒ—ãƒ«ã§LIMEå®Ÿè¡Œ
n_samples_lime = 5
lime_results = []

for i in range(n_samples_lime):
    exp = lime_explainer.explain_instance(
        X_test[i],
        model_shap.predict,
        num_features=X_train.shape[1]
    )

    # èª¬æ˜ã‚’è¾æ›¸ã«å¤‰æ›
    exp_dict = dict(exp.as_list())
    lime_results.append(exp_dict)

# ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ åŒ–
lime_df = pd.DataFrame(lime_results)

print(f&quot;\n{n_samples_lime}ã‚µãƒ³ãƒ—ãƒ«ã®LIMEèª¬æ˜:&quot;)
print(lime_df.head())

# ä¸€è²«æ€§ã®è©•ä¾¡ï¼ˆåŒã˜ç‰¹å¾´é‡ãŒå¸¸ã«é‡è¦ã‹ï¼‰
feature_importance_consistency = lime_df.abs().mean()
print(&quot;\nç‰¹å¾´é‡ã®å¹³å‡çš„é‡è¦åº¦ï¼ˆLIMEï¼‰:&quot;)
print(feature_importance_consistency.sort_values(ascending=False))
</code></pre>
<h3>äºˆæ¸¬ã®èª¬æ˜ç”Ÿæˆ</h3>
<pre><code class="language-python"># SHAP vs LIMEæ¯”è¼ƒ
def compare_shap_lime(sample_idx):
    &quot;&quot;&quot;
    åŒä¸€ã‚µãƒ³ãƒ—ãƒ«ã®SHAP vs LIMEèª¬æ˜æ¯”è¼ƒ
    &quot;&quot;&quot;
    # SHAP
    shap_exp = shap_values[sample_idx]

    # LIME
    lime_exp = lime_explainer.explain_instance(
        X_test[sample_idx],
        model_shap.predict,
        num_features=X_train.shape[1]
    )
    lime_dict = dict(lime_exp.as_list())

    # LIMEèª¬æ˜ã‚’SHAPã¨åŒã˜é †åºã«æ•´åˆ—
    lime_exp_ordered = []
    for i in range(len(shap_exp)):
        feature_name = f'Feature_{i}'
        # LIMEã®èª¬æ˜ã‹ã‚‰è©²å½“ç‰¹å¾´é‡ã‚’æ¢ã™
        for key, value in lime_dict.items():
            if feature_name in key:
                lime_exp_ordered.append(value)
                break
        else:
            lime_exp_ordered.append(0)

    return shap_exp, np.array(lime_exp_ordered)

# æ¯”è¼ƒ
sample_idx = 0
shap_exp, lime_exp = compare_shap_lime(sample_idx)

# å¯è¦–åŒ–
fig, ax = plt.subplots(figsize=(12, 6))

x_pos = np.arange(len(shap_exp))
width = 0.35

ax.bar(x_pos - width/2, shap_exp, width,
       label='SHAP', color='steelblue', alpha=0.7)
ax.bar(x_pos + width/2, lime_exp, width,
       label='LIME', color='coral', alpha=0.7)

ax.set_xlabel('ç‰¹å¾´é‡ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹', fontsize=12)
ax.set_ylabel('é‡è¦åº¦', fontsize=12)
ax.set_title(f'SHAP vs LIME (ã‚µãƒ³ãƒ—ãƒ« {sample_idx})',
             fontsize=13, fontweight='bold')
ax.set_xticks(x_pos)
ax.legend()
ax.grid(alpha=0.3)
ax.axhline(y=0, color='black', linestyle='-', linewidth=1)

plt.tight_layout()
plt.show()

# ç›¸é–¢åˆ†æ
correlation = np.corrcoef(shap_exp, lime_exp)[0, 1]
print(f&quot;\nSHAP-LIMEç›¸é–¢: {correlation:.4f}&quot;)
print(&quot;é«˜ç›¸é–¢ â†’ ä¸¡æ‰‹æ³•ã§ä¸€è²«ã—ãŸèª¬æ˜&quot;)
</code></pre>
<hr />
<h2>4.4 Attentionå¯è¦–åŒ–ï¼ˆNN/GNNç”¨ï¼‰</h2>
<p>ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®Attentionæ©Ÿæ§‹ã‚’å¯è¦–åŒ–ã—ã¾ã™ã€‚</p>
<h3>Attention weightsã®å¯è¦–åŒ–</h3>
<pre><code class="language-python"># ç°¡æ˜“çš„ãªAttentionãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã®ãƒ‡ãƒ¢
from sklearn.neural_network import MLPRegressor

# ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è¨“ç·´
nn_model = MLPRegressor(
    hidden_layer_sizes=(50, 50),
    max_iter=1000,
    random_state=42
)
nn_model.fit(X_train, y_train)

# ä¸­é–“å±¤ã®æ´»æ€§åŒ–ã‚’å–å¾—ï¼ˆç°¡æ˜“ç‰ˆï¼‰
def get_activation(model, X, layer_idx=0):
    &quot;&quot;&quot;
    æŒ‡å®šå±¤ã®æ´»æ€§åŒ–ã‚’å–å¾—
    &quot;&quot;&quot;
    # é‡ã¿ã¨ãƒã‚¤ã‚¢ã‚¹
    W = model.coefs_[layer_idx]
    b = model.intercepts_[layer_idx]

    # æ´»æ€§åŒ–ï¼ˆReLUï¼‰
    activation = np.maximum(0, X @ W + b)

    return activation

# ç¬¬1å±¤ã®æ´»æ€§åŒ–
activation_layer1 = get_activation(nn_model, X_test, layer_idx=0)

# Attention-like weightsï¼ˆæ´»æ€§åŒ–ã®å¤§ãã•ã‚’é‡ã¿ã¨è¦‹åšã™ï¼‰
attention_weights = np.abs(activation_layer1).mean(axis=1)

# å¯è¦–åŒ–
plt.figure(figsize=(12, 6))
plt.scatter(range(len(attention_weights)), attention_weights,
            c=y_test, cmap='viridis', s=100, alpha=0.6)
plt.colorbar(label='Target Value')
plt.xlabel('ã‚µãƒ³ãƒ—ãƒ«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹', fontsize=12)
plt.ylabel('Attention Weight (æ´»æ€§åŒ–å¼·åº¦)', fontsize=12)
plt.title('Attention-like Weightsï¼ˆç¬¬1å±¤æ´»æ€§åŒ–ï¼‰',
          fontsize=13, fontweight='bold')
plt.grid(alpha=0.3)
plt.tight_layout()
plt.show()

print(&quot;Attentionå¯è¦–åŒ–ã®æ„ç¾©ï¼š&quot;)
print(&quot;- ãƒ¢ãƒ‡ãƒ«ãŒã©ã®å…¥åŠ›ã«æ³¨ç›®ã—ã¦ã„ã‚‹ã‹&quot;)
print(&quot;- é‡è¦ãªã‚µãƒ³ãƒ—ãƒ«ã‚„ç‰¹å¾´ã®ç‰¹å®š&quot;)
print(&quot;- ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®å†…éƒ¨å‹•ä½œç†è§£&quot;)
</code></pre>
<h3>Grad-CAM for materials</h3>
<pre><code class="language-python"># Grad-CAMé¢¨ã®å‹¾é…ãƒ™ãƒ¼ã‚¹é‡è¦åº¦ï¼ˆç°¡æ˜“ç‰ˆï¼‰
def gradient_based_importance(model, X_sample):
    &quot;&quot;&quot;
    å‹¾é…ãƒ™ãƒ¼ã‚¹ã®ç‰¹å¾´é‡é‡è¦åº¦
    &quot;&quot;&quot;
    # æ•°å€¤å¾®åˆ†ã§è¿‘ä¼¼
    epsilon = 1e-5
    base_pred = model.predict(X_sample.reshape(1, -1))[0]

    importances = []
    for i in range(len(X_sample)):
        X_perturbed = X_sample.copy()
        X_perturbed[i] += epsilon

        perturbed_pred = model.predict(X_perturbed.reshape(1, -1))[0]

        # å‹¾é…è¿‘ä¼¼
        gradient = (perturbed_pred - base_pred) / epsilon
        importances.append(gradient)

    return np.array(importances)

# ã‚µãƒ³ãƒ—ãƒ«ã§å®Ÿè¡Œ
sample_idx = 0
grad_importances = gradient_based_importance(nn_model, X_test[sample_idx])

# SHAP, LIME, Gradientã®æ¯”è¼ƒ
fig, axes = plt.subplots(1, 3, figsize=(18, 5))

# SHAP
axes[0].bar(range(len(shap_exp)), shap_exp,
            color='steelblue', alpha=0.7)
axes[0].axhline(y=0, color='black', linestyle='-', linewidth=1)
axes[0].set_xlabel('ç‰¹å¾´é‡', fontsize=11)
axes[0].set_ylabel('é‡è¦åº¦', fontsize=11)
axes[0].set_title('SHAP', fontsize=12, fontweight='bold')
axes[0].grid(alpha=0.3)

# LIME
axes[1].bar(range(len(lime_exp)), lime_exp,
            color='coral', alpha=0.7)
axes[1].axhline(y=0, color='black', linestyle='-', linewidth=1)
axes[1].set_xlabel('ç‰¹å¾´é‡', fontsize=11)
axes[1].set_ylabel('é‡è¦åº¦', fontsize=11)
axes[1].set_title('LIME', fontsize=12, fontweight='bold')
axes[1].grid(alpha=0.3)

# Gradient
axes[2].bar(range(len(grad_importances)), grad_importances,
            color='green', alpha=0.7)
axes[2].axhline(y=0, color='black', linestyle='-', linewidth=1)
axes[2].set_xlabel('ç‰¹å¾´é‡', fontsize=11)
axes[2].set_ylabel('å‹¾é…', fontsize=11)
axes[2].set_title('Gradient-based', fontsize=12, fontweight='bold')
axes[2].grid(alpha=0.3)

plt.tight_layout()
plt.show()

print(&quot;3æ‰‹æ³•ã®ç‰¹å¾´ï¼š&quot;)
print(&quot;SHAP: ã‚²ãƒ¼ãƒ ç†è«–çš„å…¬å¹³æ€§ã€å…¨ãƒ¢ãƒ‡ãƒ«å¯¾å¿œ&quot;)
print(&quot;LIME: å±€æ‰€ç·šå½¢è¿‘ä¼¼ã€ç›´æ„Ÿçš„&quot;)
print(&quot;Gradient: å‹¾é…æƒ…å ±ã€ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ç‰¹åŒ–&quot;)
</code></pre>
<h3>ã©ã®åŸå­/çµåˆãŒé‡è¦ã‹</h3>
<pre><code class="language-python"># ææ–™ç§‘å­¦ã§ã®å¿œç”¨ä¾‹ï¼šçµ„æˆã®é‡è¦åº¦
composition_features = ['Li', 'Co', 'Ni', 'Mn', 'O']

# ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿
X_composition = pd.DataFrame({
    'Li': np.random.uniform(0.9, 1.1, 100),
    'Co': np.random.uniform(0, 0.6, 100),
    'Ni': np.random.uniform(0, 0.8, 100),
    'Mn': np.random.uniform(0, 0.4, 100),
    'O': np.random.uniform(1.9, 2.1, 100)
})

# å®¹é‡ï¼ˆNiãŒé‡è¦ï¼‰
y_capacity = (
    150 * X_composition['Ni'] +
    120 * X_composition['Co'] +
    80 * X_composition['Mn'] +
    np.random.normal(0, 5, 100)
)

# ãƒ¢ãƒ‡ãƒ«è¨“ç·´
model_comp = RandomForestRegressor(n_estimators=100, random_state=42)
model_comp.fit(X_composition, y_capacity)

# SHAPè§£æ
explainer_comp = shap.TreeExplainer(model_comp)
shap_values_comp = explainer_comp.shap_values(X_composition)

# å…ƒç´ åˆ¥é‡è¦åº¦
mean_abs_shap_comp = np.abs(shap_values_comp).mean(axis=0)

# å¯è¦–åŒ–
plt.figure(figsize=(10, 6))
plt.bar(composition_features, mean_abs_shap_comp,
        color=['#FFD700', '#4169E1', '#32CD32', '#FF69B4', '#FF6347'],
        alpha=0.7, edgecolor='black', linewidth=1.5)
plt.xlabel('å…ƒç´ ', fontsize=12)
plt.ylabel('å¹³å‡|SHAPå€¤|', fontsize=12)
plt.title('é›»æ± å®¹é‡ã¸ã®å…ƒç´ å¯„ä¸åº¦ï¼ˆSHAPè§£æï¼‰',
          fontsize=13, fontweight='bold')
plt.grid(axis='y', alpha=0.3)
plt.tight_layout()
plt.show()

print(&quot;å…ƒç´ åˆ¥é‡è¦åº¦:&quot;)
for elem, importance in zip(composition_features, mean_abs_shap_comp):
    print(f&quot;  {elem}: {importance:.2f}&quot;)

print(&quot;\nææ–™è¨­è¨ˆã¸ã®ç¤ºå”†:&quot;)
print(&quot;â†’ Niå«æœ‰é‡ã‚’å¢—ã‚„ã™ã“ã¨ã§å®¹é‡å‘ä¸ŠãŒæœŸå¾…ã§ãã‚‹&quot;)
</code></pre>
<hr />
<h2>4.5 å®Ÿä¸–ç•Œå¿œç”¨ã¨ã‚­ãƒ£ãƒªã‚¢ãƒ‘ã‚¹</h2>
<p>XAIã®ç”£æ¥­å¿œç”¨äº‹ä¾‹ã¨ã€ææ–™ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ãƒ†ã‚£ã‚¹ãƒˆã®ã‚­ãƒ£ãƒªã‚¢æƒ…å ±ã‚’ç´¹ä»‹ã—ã¾ã™ã€‚</p>
<h3>ãƒˆãƒ¨ã‚¿ï¼šææ–™é–‹ç™ºã«ãŠã‘ã‚‹XAIæ´»ç”¨</h3>
<pre><code class="language-python"># ãƒˆãƒ¨ã‚¿ã®äº‹ä¾‹ï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
print(&quot;=== ãƒˆãƒ¨ã‚¿è‡ªå‹•è»Š ææ–™é–‹ç™ºäº‹ä¾‹ ===&quot;)
print(&quot;\nèª²é¡Œ:&quot;)
print(&quot;  - é›»æ± ææ–™ã®åŠ£åŒ–ãƒ¡ã‚«ãƒ‹ã‚ºãƒ è§£æ˜&quot;)
print(&quot;  - æ•°åƒã®å€™è£œææ–™ã‹ã‚‰æœ€é©ææ–™é¸å®š&quot;)

print(&quot;\nXAIé©ç”¨:&quot;)
print(&quot;  - SHAPè§£æã§åŠ£åŒ–ã«å¯„ä¸ã™ã‚‹å› å­ã‚’ç‰¹å®š&quot;)
print(&quot;  - æ¸©åº¦ã€é›»åœ§ã€ã‚µã‚¤ã‚¯ãƒ«æ•°ã®ç›¸äº’ä½œç”¨ã‚’å¯è¦–åŒ–&quot;)
print(&quot;  - ç‰©ç†ãƒ¢ãƒ‡ãƒ«ã¨ã®æ•´åˆæ€§æ¤œè¨¼&quot;)

print(&quot;\næˆæœ:&quot;)
print(&quot;  - é–‹ç™ºæœŸé–“ 40% çŸ­ç¸®&quot;)
print(&quot;  - é›»æ± å¯¿å‘½ 20% å‘ä¸Š&quot;)
print(&quot;  - ç ”ç©¶è€…ã®ç‰©ç†çš„æ´å¯Ÿç²å¾—&quot;)

# ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³: é›»æ± åŠ£åŒ–äºˆæ¸¬
battery_aging = pd.DataFrame({
    'æ¸©åº¦': np.random.uniform(20, 60, 200),
    'é›»åœ§': np.random.uniform(3.0, 4.5, 200),
    'ã‚µã‚¤ã‚¯ãƒ«æ•°': np.random.uniform(0, 1000, 200),
    'å……é›»ãƒ¬ãƒ¼ãƒˆ': np.random.uniform(0.5, 2.0, 200)
})

# åŠ£åŒ–ç‡ï¼ˆæ¸©åº¦ã¨ã‚µã‚¤ã‚¯ãƒ«ãŒä¸»è¦å› ï¼‰
degradation = (
    0.5 * battery_aging['æ¸©åº¦'] +
    0.3 * battery_aging['ã‚µã‚¤ã‚¯ãƒ«æ•°'] / 100 +
    0.2 * battery_aging['é›»åœ§'] * battery_aging['å……é›»ãƒ¬ãƒ¼ãƒˆ'] +
    np.random.normal(0, 2, 200)
)

# ãƒ¢ãƒ‡ãƒ«
model_aging = RandomForestRegressor(n_estimators=100, random_state=42)
model_aging.fit(battery_aging, degradation)

# SHAPåˆ†æ
explainer_aging = shap.TreeExplainer(model_aging)
shap_values_aging = explainer_aging.shap_values(battery_aging)

# å¯è¦–åŒ–
plt.figure(figsize=(10, 8))
shap.summary_plot(shap_values_aging, battery_aging, show=False)
plt.title('é›»æ± åŠ£åŒ–è¦å› ã®SHAPåˆ†æï¼ˆãƒˆãƒ¨ã‚¿äº‹ä¾‹é¢¨ï¼‰',
          fontsize=13, fontweight='bold', pad=20)
plt.tight_layout()
plt.show()
</code></pre>
<h3>IBM Researchï¼šAIææ–™è¨­è¨ˆã®è§£é‡ˆæ€§</h3>
<pre><code class="language-python">print(&quot;\n=== IBM Research ææ–™è¨­è¨ˆäº‹ä¾‹ ===&quot;)
print(&quot;\nãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: RoboRXN (è‡ªå‹•åŒ–å­¦å®Ÿé¨“)&quot;)
print(&quot;\nç‰¹å¾´:&quot;)
print(&quot;  - åå¿œæ¡ä»¶æœ€é©åŒ–ã«XAIçµ±åˆ&quot;)
print(&quot;  - SHAP + Attentionã§åå¿œãƒ¡ã‚«ãƒ‹ã‚ºãƒ äºˆæ¸¬&quot;)
print(&quot;  - åŒ–å­¦è€…ã¸ã®èª¬æ˜å¯èƒ½ãªææ¡ˆç”Ÿæˆ&quot;)

print(&quot;\næŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯:&quot;)
print(&quot;  - Graph Neural Network (GNN)&quot;)
print(&quot;  - Attention mechanism&quot;)
print(&quot;  - SHAP for molecular graphs&quot;)

print(&quot;\næˆæœ:&quot;)
print(&quot;  - åå¿œåç‡äºˆæ¸¬ç²¾åº¦ 95%&quot;)
print(&quot;  - åŒ–å­¦è€…ã®ä¿¡é ¼ç²å¾—&quot;)
print(&quot;  - æ–°è¦åå¿œçµŒè·¯ã®ç™ºè¦‹&quot;)

# åˆ†å­ã‚°ãƒ©ãƒ•ã®é‡è¦åº¦å¯è¦–åŒ–ï¼ˆæ¦‚å¿µå›³ï¼‰
fig, ax = plt.subplots(figsize=(10, 8))

# ãƒ€ãƒŸãƒ¼ã®åˆ†å­ã‚°ãƒ©ãƒ•
import networkx as nx

G = nx.Graph()
G.add_edges_from([
    (0, 1), (1, 2), (2, 3), (3, 4), (4, 0),
    (1, 5), (3, 6)
])

pos = nx.spring_layout(G, seed=42)

# ãƒãƒ¼ãƒ‰é‡è¦åº¦ï¼ˆAttention weightsé¢¨ï¼‰
node_importance = np.random.rand(len(G.nodes))
node_importance = node_importance / node_importance.sum()

nx.draw(
    G, pos,
    node_color=node_importance,
    node_size=1000 * node_importance / node_importance.max(),
    cmap='YlOrRd',
    with_labels=True,
    font_size=12,
    font_weight='bold',
    edge_color='gray',
    width=2,
    ax=ax
)

sm = plt.cm.ScalarMappable(
    cmap='YlOrRd',
    norm=plt.Normalize(vmin=0, vmax=node_importance.max())
)
sm.set_array([])
cbar = plt.colorbar(sm, ax=ax, label='Attention Weight')

ax.set_title('åˆ†å­ã‚°ãƒ©ãƒ•ã®Attentionå¯è¦–åŒ–ï¼ˆIBMé¢¨ï¼‰',
             fontsize=13, fontweight='bold')
plt.tight_layout()
plt.show()
</code></pre>
<h3>ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—ï¼šCitrine Informaticsï¼ˆèª¬æ˜å¯èƒ½ãªAIï¼‰</h3>
<pre><code class="language-python">print(&quot;\n=== Citrine Informatics äº‹ä¾‹ ===&quot;)
print(&quot;\nãƒ“ã‚¸ãƒã‚¹ãƒ¢ãƒ‡ãƒ«:&quot;)
print(&quot;  - ææ–™é–‹ç™ºãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ æä¾›&quot;)
print(&quot;  - èª¬æ˜å¯èƒ½AIã‚’ä¸­æ ¸æŠ€è¡“ã¨ã™ã‚‹&quot;)
print(&quot;  - å¤§æ‰‹è£½é€ æ¥­ã¸ã®SaaSå±•é–‹&quot;)

print(&quot;\næŠ€è¡“çš„ç‰¹å¾´:&quot;)
print(&quot;  - ãƒ™ã‚¤ã‚ºæœ€é©åŒ– + XAI&quot;)
print(&quot;  - ä¸ç¢ºå®Ÿæ€§å®šé‡åŒ–&quot;)
print(&quot;  - ç‰©ç†åˆ¶ç´„ã®çµ±åˆ&quot;)

print(&quot;\né¡§å®¢äº‹ä¾‹:&quot;)
print(&quot;  - ãƒ‘ãƒŠã‚½ãƒ‹ãƒƒã‚¯: é›»æ± ææ–™é–‹ç™º 50% é«˜é€ŸåŒ–&quot;)
print(&quot;  - 3M: æ¥ç€å‰¤æ€§èƒ½ 30% å‘ä¸Š&quot;)
print(&quot;  - Michelin: ã‚¿ã‚¤ãƒ¤ã‚´ãƒ æœ€é©åŒ–&quot;)

print(&quot;\nå·®åˆ¥åŒ–è¦å› :&quot;)
print(&quot;  - èª¬æ˜å¯èƒ½æ€§ã«ã‚ˆã‚‹å°‚é–€å®¶ã®ä¿¡é ¼ç²å¾—&quot;)
print(&quot;  - ç‰©ç†ãƒ¢ãƒ‡ãƒ«ã¨ã®çµ±åˆ&quot;)
print(&quot;  - å°ãƒ‡ãƒ¼ã‚¿ã§ã‚‚é«˜ç²¾åº¦&quot;)

# Citrineã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
# ä¸ç¢ºå®Ÿæ€§ã¤ãäºˆæ¸¬ + SHAP

from sklearn.ensemble import GradientBoostingRegressor

# ãƒ¢ãƒ‡ãƒ«ï¼ˆåˆ†ä½ç‚¹å›å¸°é¢¨ï¼‰
model_citrine_lower = GradientBoostingRegressor(
    loss='quantile', alpha=0.1, n_estimators=100, random_state=42
)
model_citrine_median = GradientBoostingRegressor(
    n_estimators=100, random_state=42
)
model_citrine_upper = GradientBoostingRegressor(
    loss='quantile', alpha=0.9, n_estimators=100, random_state=42
)

X_citrine = X_composition
y_citrine = y_capacity

model_citrine_lower.fit(X_citrine, y_citrine)
model_citrine_median.fit(X_citrine, y_citrine)
model_citrine_upper.fit(X_citrine, y_citrine)

# äºˆæ¸¬
X_new = X_citrine.iloc[:20]
y_pred_lower = model_citrine_lower.predict(X_new)
y_pred_median = model_citrine_median.predict(X_new)
y_pred_upper = model_citrine_upper.predict(X_new)

# å¯è¦–åŒ–
fig, ax = plt.subplots(figsize=(12, 6))

x_axis = range(len(X_new))

ax.fill_between(x_axis, y_pred_lower, y_pred_upper,
                alpha=0.3, color='steelblue',
                label='80% äºˆæ¸¬åŒºé–“')
ax.plot(x_axis, y_pred_median, 'o-',
        color='steelblue', linewidth=2, label='äºˆæ¸¬ä¸­å¤®å€¤')

ax.set_xlabel('ææ–™ã‚µãƒ³ãƒ—ãƒ«', fontsize=12)
ax.set_ylabel('å®¹é‡ (mAh/g)', fontsize=12)
ax.set_title('Citrineé¢¨ä¸ç¢ºå®Ÿæ€§ã¤ãäºˆæ¸¬',
             fontsize=13, fontweight='bold')
ax.legend()
ax.grid(alpha=0.3)

plt.tight_layout()
plt.show()

print(&quot;\nä¸ç¢ºå®Ÿæ€§ã®åˆ©ç‚¹:&quot;)
print(&quot;  - ãƒªã‚¹ã‚¯è©•ä¾¡&quot;)
print(&quot;  - è¿½åŠ å®Ÿé¨“ã®å„ªå…ˆé †ä½ã¥ã‘&quot;)
print(&quot;  - æ„æ€æ±ºå®šã®ä¿¡é ¼æ€§å‘ä¸Š&quot;)
</code></pre>
<h3>ã‚­ãƒ£ãƒªã‚¢ãƒ‘ã‚¹ï¼šææ–™ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ãƒ†ã‚£ã‚¹ãƒˆã€XAIç ”ç©¶è€…</h3>
<pre><code class="language-python"># ã‚­ãƒ£ãƒªã‚¢ãƒ‘ã‚¹æƒ…å ±
career_paths = pd.DataFrame({
    'ã‚­ãƒ£ãƒªã‚¢ãƒ‘ã‚¹': [
        'ææ–™ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ãƒ†ã‚£ã‚¹ãƒˆ',
        'XAIç ”ç©¶è€…ï¼ˆã‚¢ã‚«ãƒ‡ãƒŸã‚¢ï¼‰',
        'MLã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ï¼ˆææ–™ç‰¹åŒ–ï¼‰',
        'R&amp;D Managerï¼ˆAIæ´»ç”¨ï¼‰',
        'ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆ'
    ],
    'å¿…è¦ã‚¹ã‚­ãƒ«': [
        'ææ–™ç§‘å­¦+ML+Python',
        'çµ±è¨ˆ+MLç†è«–+è«–æ–‡åŸ·ç­†',
        'MLå®Ÿè£…+MLOps',
        'ææ–™ç§‘å­¦+ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç®¡ç†',
        'ææ–™ç§‘å­¦+ML+ãƒ“ã‚¸ãƒã‚¹'
    ],
    'å‹¤å‹™å…ˆä¾‹': [
        'ãƒˆãƒ¨ã‚¿ã€ãƒ‘ãƒŠã‚½ãƒ‹ãƒƒã‚¯ã€ä¸‰è±ã‚±ãƒŸã‚«ãƒ«',
        'å¤§å­¦ã€ç”£ç·ç ”ã€ç†ç ”',
        'Citrine, Materials Zone',
        'å¤§æ‰‹è£½é€ æ¥­R&amp;Déƒ¨é–€',
        'ã‚¢ã‚¯ã‚»ãƒ³ãƒãƒ¥ã‚¢ã€ãƒ‡ãƒ­ã‚¤ãƒˆ'
    ]
})

print(&quot;\n=== ã‚­ãƒ£ãƒªã‚¢ãƒ‘ã‚¹ ===&quot;)
print(career_paths.to_string(index=False))
</code></pre>
<h3>å¹´åï¼š700-1,500ä¸‡å††ï¼ˆæ—¥æœ¬ï¼‰ã€$90-180Kï¼ˆç±³å›½ï¼‰</h3>
<pre><code class="language-python"># å¹´åãƒ‡ãƒ¼ã‚¿
salary_data = pd.DataFrame({
    'ãƒã‚¸ã‚·ãƒ§ãƒ³': [
        'ã‚¸ãƒ¥ãƒ‹ã‚¢ï¼ˆã€œ3å¹´ï¼‰',
        'ãƒŸãƒ‰ãƒ«ï¼ˆ3-7å¹´ï¼‰',
        'ã‚·ãƒ‹ã‚¢ï¼ˆ7-15å¹´ï¼‰',
        'ãƒªãƒ¼ãƒ‰ã‚µã‚¤ã‚¨ãƒ³ãƒ†ã‚£ã‚¹ãƒˆ',
        'ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼'
    ],
    'æ—¥æœ¬_æœ€ä½': [500, 700, 1000, 1200, 1500],
    'æ—¥æœ¬_æœ€é«˜': [700, 1000, 1500, 2000, 2500],
    'ç±³å›½_æœ€ä½': [70, 90, 130, 150, 180],
    'ç±³å›½_æœ€é«˜': [90, 130, 180, 220, 300]
})

# å¯è¦–åŒ–
fig, axes = plt.subplots(1, 2, figsize=(16, 6))

# æ—¥æœ¬
axes[0].barh(salary_data['ãƒã‚¸ã‚·ãƒ§ãƒ³'],
             salary_data['æ—¥æœ¬_æœ€é«˜'] - salary_data['æ—¥æœ¬_æœ€ä½'],
             left=salary_data['æ—¥æœ¬_æœ€ä½'],
             color='steelblue', alpha=0.7)

for idx, row in salary_data.iterrows():
    axes[0].text(row['æ—¥æœ¬_æœ€ä½'] - 50, idx,
                 f&quot;{row['æ—¥æœ¬_æœ€ä½']}&quot;, va='center', ha='right', fontsize=9)
    axes[0].text(row['æ—¥æœ¬_æœ€é«˜'] + 50, idx,
                 f&quot;{row['æ—¥æœ¬_æœ€é«˜']}&quot;, va='center', ha='left', fontsize=9)

axes[0].set_xlabel('å¹´åï¼ˆä¸‡å††ï¼‰', fontsize=12)
axes[0].set_title('æ—¥æœ¬ã®å¹´åãƒ¬ãƒ³ã‚¸', fontsize=13, fontweight='bold')
axes[0].grid(axis='x', alpha=0.3)

# ç±³å›½
axes[1].barh(salary_data['ãƒã‚¸ã‚·ãƒ§ãƒ³'],
             salary_data['ç±³å›½_æœ€é«˜'] - salary_data['ç±³å›½_æœ€ä½'],
             left=salary_data['ç±³å›½_æœ€ä½'],
             color='coral', alpha=0.7)

for idx, row in salary_data.iterrows():
    axes[1].text(row['ç±³å›½_æœ€ä½'] - 5, idx,
                 f&quot;${row['ç±³å›½_æœ€ä½']}K&quot;, va='center', ha='right', fontsize=9)
    axes[1].text(row['ç±³å›½_æœ€é«˜'] + 5, idx,
                 f&quot;${row['ç±³å›½_æœ€é«˜']}K&quot;, va='center', ha='left', fontsize=9)

axes[1].set_xlabel('å¹´åï¼ˆåƒãƒ‰ãƒ«ï¼‰', fontsize=12)
axes[1].set_title('ç±³å›½ã®å¹´åãƒ¬ãƒ³ã‚¸', fontsize=13, fontweight='bold')
axes[1].grid(axis='x', alpha=0.3)

plt.tight_layout()
plt.show()

print(&quot;\nå¹´åã«å½±éŸ¿ã™ã‚‹è¦å› :&quot;)
print(&quot;  - å­¦ä½ï¼ˆä¿®å£« vs åšå£«ï¼‰&quot;)
print(&quot;  - æ¥­ç•Œï¼ˆè£½é€ æ¥­ vs ITï¼‰&quot;)
print(&quot;  - åœ°åŸŸï¼ˆæ±äº¬ vs åœ°æ–¹ã€ã‚·ãƒªã‚³ãƒ³ãƒãƒ¬ãƒ¼ vs ãã®ä»–ï¼‰&quot;)
print(&quot;  - ã‚¹ã‚­ãƒ«ã‚»ãƒƒãƒˆï¼ˆææ–™ç§‘å­¦ + ML + ãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜ï¼‰&quot;)
print(&quot;  - å®Ÿç¸¾ï¼ˆè«–æ–‡ã€ç‰¹è¨±ã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæˆåŠŸï¼‰&quot;)

print(&quot;\nã‚¹ã‚­ãƒ«ã‚¢ãƒƒãƒ—æˆ¦ç•¥:&quot;)
print(&quot;  1. ææ–™ç§‘å­¦ã®åŸºç¤å›ºã‚ï¼ˆå­¦ä½å–å¾—ï¼‰&quot;)
print(&quot;  2. ML/DLã®å®Ÿè·µã‚¹ã‚­ãƒ«ï¼ˆKaggleã€GitHubï¼‰&quot;)
print(&quot;  3. XAIæ‰‹æ³•ã®ç¿’å¾—ï¼ˆSHAPã€LIMEï¼‰&quot;)
print(&quot;  4. è«–æ–‡ç™ºè¡¨ãƒ»OSSã‚³ãƒ³ãƒˆãƒªãƒ“ãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³&quot;)
print(&quot;  5. ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚­ãƒ³ã‚°ï¼ˆå­¦ä¼šã€å‹‰å¼·ä¼šï¼‰&quot;)
</code></pre>
<hr />
<h2>æ¼”ç¿’å•é¡Œ</h2>
<h3>å•é¡Œ1ï¼ˆé›£æ˜“åº¦: easyï¼‰</h3>
<p>SHAPã¨LIMEã‚’ç”¨ã„ã¦ã€åŒä¸€ã‚µãƒ³ãƒ—ãƒ«ã®èª¬æ˜ã‚’ç”Ÿæˆã—ã€ç‰¹å¾´é‡é‡è¦åº¦ã®ç›¸é–¢ã‚’è¨ˆç®—ã—ã¦ãã ã•ã„ã€‚ç›¸é–¢ãŒé«˜ã„å ´åˆã¨ä½ã„å ´åˆã€ãã‚Œãã‚Œä½•ã‚’æ„å‘³ã™ã‚‹ã‹è€ƒå¯Ÿã—ã¦ãã ã•ã„ã€‚</p>
<details>
<summary>è§£ç­”ä¾‹</summary>


<pre><code class="language-python">import shap
from lime import lime_tabular
from sklearn.ensemble import RandomForestRegressor
import numpy as np

# ãƒ¢ãƒ‡ãƒ«è¨“ç·´
model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# SHAP
explainer_shap = shap.TreeExplainer(model)
shap_values = explainer_shap.shap_values(X_test)

# LIME
explainer_lime = lime_tabular.LimeTabularExplainer(
    X_train, mode='regression'
)

sample_idx = 0

# LIMEèª¬æ˜
lime_exp = explainer_lime.explain_instance(
    X_test[sample_idx], model.predict, num_features=X_train.shape[1]
)
lime_dict = dict(lime_exp.as_list())

# ç›¸é–¢è¨ˆç®—
shap_importances = shap_values[sample_idx]
lime_importances = [lime_dict.get(f'Feature_{i}', 0)
                    for i in range(len(shap_importances))]

correlation = np.corrcoef(shap_importances, lime_importances)[0, 1]
print(f&quot;SHAP-LIMEç›¸é–¢: {correlation:.4f}&quot;)

if correlation &gt; 0.7:
    print(&quot;é«˜ç›¸é–¢: ä¸¡æ‰‹æ³•ã§ä¸€è²«ã—ãŸèª¬æ˜ â†’ ä¿¡é ¼æ€§é«˜ã„&quot;)
else:
    print(&quot;ä½ç›¸é–¢: èª¬æ˜ã®ä¸ä¸€è‡´ â†’ æ…é‡ã«è§£é‡ˆãŒå¿…è¦&quot;)
</code></pre>


</details>

<h3>å•é¡Œ2ï¼ˆé›£æ˜“åº¦: mediumï¼‰</h3>
<p>SHAP Dependence Plotã‚’ç”¨ã„ã¦ã€2ã¤ã®ç‰¹å¾´é‡é–“ã®ç›¸äº’ä½œç”¨ã‚’å¯è¦–åŒ–ã—ã¦ãã ã•ã„ã€‚éç·šå½¢ãªé–¢ä¿‚ã‚„ç›¸äº’ä½œç”¨ãŒè¦‹ã‚‰ã‚Œã‚‹ã‹åˆ†æã—ã¦ãã ã•ã„ã€‚</p>
<details>
<summary>è§£ç­”ä¾‹</summary>


<pre><code class="language-python">import shap
import matplotlib.pyplot as plt

# SHAPè¨ˆç®—
explainer = shap.TreeExplainer(model)
shap_values = explainer.shap_values(X_test)

# Dependence Plotï¼ˆç‰¹å¾´é‡0ã¨ç‰¹å¾´é‡1ã®ç›¸äº’ä½œç”¨ï¼‰
fig, axes = plt.subplots(1, 2, figsize=(16, 6))

shap.dependence_plot(0, shap_values, X_test, interaction_index=1,
                     ax=axes[0], show=False)
axes[0].set_title('Feature 0 (interaction with Feature 1)')

shap.dependence_plot(1, shap_values, X_test, interaction_index=0,
                     ax=axes[1], show=False)
axes[1].set_title('Feature 1 (interaction with Feature 0)')

plt.tight_layout()
plt.show()

print(&quot;åˆ†æãƒã‚¤ãƒ³ãƒˆ:&quot;)
print(&quot;- è‰²ã®å¤‰åŒ–: ç›¸äº’ä½œç”¨ã®å¼·ã•&quot;)
print(&quot;- éç·šå½¢ãƒ‘ã‚¿ãƒ¼ãƒ³: è¤‡é›‘ãªé–¢ä¿‚æ€§&quot;)
print(&quot;- å‚¾å‘: æ­£/è² ã®å½±éŸ¿&quot;)
</code></pre>


</details>

<h3>å•é¡Œ3ï¼ˆé›£æ˜“åº¦: hardï¼‰</h3>
<p>ãƒˆãƒ¨ã‚¿ã®é›»æ± åŠ£åŒ–äºˆæ¸¬äº‹ä¾‹ã‚’æ¨¡å€£ã—ã€æ¸©åº¦ãƒ»é›»åœ§ãƒ»ã‚µã‚¤ã‚¯ãƒ«æ•°ã®3è¦å› ã§SHAPåˆ†æã‚’è¡Œã„ã€ã©ã®è¦å› ãŒæœ€ã‚‚åŠ£åŒ–ã«å¯„ä¸ã™ã‚‹ã‹å®šé‡è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚ã¾ãŸã€ç‰©ç†çš„ã«å¦¥å½“ã‹ã©ã†ã‹è€ƒå¯Ÿã—ã¦ãã ã•ã„ã€‚</p>
<details>
<summary>è§£ç­”ä¾‹</summary>


<pre><code class="language-python">import pandas as pd
import numpy as np
from sklearn.ensemble import GradientBoostingRegressor
import shap

# ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
battery_data = pd.DataFrame({
    'æ¸©åº¦': np.random.uniform(20, 60, 300),
    'é›»åœ§': np.random.uniform(3.0, 4.5, 300),
    'ã‚µã‚¤ã‚¯ãƒ«æ•°': np.random.uniform(0, 1000, 300)
})

# åŠ£åŒ–ç‡ï¼ˆç‰©ç†çš„ã«å¦¥å½“ãªãƒ¢ãƒ‡ãƒ«ï¼‰
# é«˜æ¸©ã€é«˜é›»åœ§ã€å¤šã‚µã‚¤ã‚¯ãƒ«ã§åŠ£åŒ–åŠ é€Ÿ
degradation = (
    0.8 * (battery_data['æ¸©åº¦'] - 20) +  # é«˜æ¸©ã§åŠ£åŒ–
    2.0 * (battery_data['é›»åœ§'] - 3.0)**2 +  # é«˜é›»åœ§ã§åŠ£åŒ–
    0.05 * battery_data['ã‚µã‚¤ã‚¯ãƒ«æ•°'] +  # ã‚µã‚¤ã‚¯ãƒ«åŠ£åŒ–
    0.01 * battery_data['æ¸©åº¦'] * battery_data['ã‚µã‚¤ã‚¯ãƒ«æ•°'] / 100 +  # ç›¸äº’ä½œç”¨
    np.random.normal(0, 3, 300)
)

# ãƒ¢ãƒ‡ãƒ«è¨“ç·´
model = GradientBoostingRegressor(n_estimators=100, random_state=42)
model.fit(battery_data, degradation)

# SHAPåˆ†æ
explainer = shap.TreeExplainer(model)
shap_values = explainer.shap_values(battery_data)

# é‡è¦åº¦é›†è¨ˆ
mean_abs_shap = np.abs(shap_values).mean(axis=0)
feature_names = battery_data.columns

print(&quot;åŠ£åŒ–è¦å› ã®é‡è¦åº¦ï¼ˆSHAPï¼‰:&quot;)
for name, importance in zip(feature_names, mean_abs_shap):
    print(f&quot;  {name}: {importance:.2f}&quot;)

# Summary Plot
shap.summary_plot(shap_values, battery_data, show=False)
plt.title('é›»æ± åŠ£åŒ–è¦å› ã®SHAPåˆ†æ', fontsize=13, fontweight='bold')
plt.tight_layout()
plt.show()

print(&quot;\nç‰©ç†çš„å¦¥å½“æ€§:&quot;)
print(&quot;- æ¸©åº¦: ã‚¢ãƒ¬ãƒ‹ã‚¦ã‚¹å‰‡ã«ã‚ˆã‚Šé«˜æ¸©ã§åå¿œé€Ÿåº¦ä¸Šæ˜‡ â†’ å¦¥å½“&quot;)
print(&quot;- é›»åœ§: é«˜é›»åœ§ã§å‰¯åå¿œä¿ƒé€² â†’ å¦¥å½“&quot;)
print(&quot;- ã‚µã‚¤ã‚¯ãƒ«æ•°: å……æ”¾é›»ç¹°ã‚Šè¿”ã—ã§åŠ£åŒ– â†’ å¦¥å½“&quot;)
</code></pre>


</details>

<hr />
<h2>4.6 XAIç’°å¢ƒã¨å®Ÿè·µçš„è½ã¨ã—ç©´</h2>
<h3>SHAPãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†</h3>
<pre><code class="language-python"># XAIã«å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªãƒãƒ¼ã‚¸ãƒ§ãƒ³
import sys
import shap
import lime
import sklearn
import pandas as pd
import numpy as np

xai_env_info = {
    'Python': sys.version,
    'NumPy': np.__version__,
    'Pandas': pd.__version__,
    'scikit-learn': sklearn.__version__,
    'SHAP': shap.__version__,
    'LIME': lime.__version__,
    'Date': '2025-10-19'
}

print(&quot;=== XAIç’°å¢ƒ ===&quot;)
for key, value in xai_env_info.items():
    print(f&quot;{key}: {value}&quot;)

# æ¨å¥¨ãƒãƒ¼ã‚¸ãƒ§ãƒ³
print(&quot;\nã€æ¨å¥¨ç’°å¢ƒã€‘&quot;)
recommended_xai = &quot;&quot;&quot;
numpy==1.24.3
pandas==2.0.3
scikit-learn==1.3.0
shap==0.43.0
lime==0.2.0.1
matplotlib==3.7.2
&quot;&quot;&quot;
print(recommended_xai)

print(&quot;\nã€ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã‚³ãƒãƒ³ãƒ‰ã€‘&quot;)
print(&quot;```bash&quot;)
print(&quot;pip install shap==0.43.0 lime==0.2.0.1&quot;)
print(&quot;```&quot;)

print(&quot;\nã€æ³¨æ„äº‹é …ã€‘&quot;)
print(&quot;âš ï¸ SHAPã¯é »ç¹ã«APIå¤‰æ›´ â†’ ãƒãƒ¼ã‚¸ãƒ§ãƒ³å›ºå®šæ¨å¥¨&quot;)
print(&quot;âš ï¸ TreeExplainerã¯scikit-learn 1.3ä»¥é™ã§å‹•ä½œç¢ºèª&quot;)
print(&quot;âš ï¸ å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ï¼ˆ&gt;10000ã‚µãƒ³ãƒ—ãƒ«ï¼‰ã§KernelSHAPã¯è¨ˆç®—å›°é›£&quot;)
</code></pre>
<h3>å®Ÿè·µçš„ãªè½ã¨ã—ç©´ï¼ˆXAIç·¨ï¼‰</h3>
<pre><code class="language-python">print(&quot;=== XAIå®Ÿè·µã®è½ã¨ã—ç©´ ===\n&quot;)

print(&quot;ã€è½ã¨ã—ç©´1: SHAPå€¤ã®èª¤è§£é‡ˆã€‘&quot;)
print(&quot;âŒ èª¤è§£ï¼šSHAPå€¤ãŒå¤§ãã„ = ç‰¹å¾´é‡ã®çµ¶å¯¾å€¤ãŒå¤§ãã„&quot;)
print(&quot;â†’ SHAPå€¤ã¯ã€ŒåŸºæº–å€¤ã‹ã‚‰ã®å¯„ä¸ã€ã§ã‚ã‚Šã€ç‰¹å¾´é‡å€¤ã¨ã¯ç„¡é–¢ä¿‚&quot;)

print(&quot;\nâœ… æ­£ã—ã„ç†è§£ï¼š&quot;)
print(&quot;```python&quot;)
print(&quot;# SHAPå€¤ = ãã®ç‰¹å¾´é‡ãŒäºˆæ¸¬ã«ä¸ãˆãŸå½±éŸ¿&quot;)
print(&quot;# ç‰¹å¾´é‡å€¤ãŒå°ã•ãã¦ã‚‚SHAPå€¤ã¯å¤§ãã„å ´åˆãŒã‚ã‚‹&quot;)
print(&quot;feature_value = 0.1  # å°ã•ã„å€¤&quot;)
print(&quot;shap_value = 2.5     # å¤§ãã„å½±éŸ¿&quot;)
print(&quot;# â†’ ã“ã®ç‰¹å¾´é‡ã¯å°ã•ã„å€¤ã§ã‚‚äºˆæ¸¬ã«å¤§ããå¯„ä¸&quot;)
print(&quot;```&quot;)

print(&quot;\nã€è½ã¨ã—ç©´2: LIMEã®å±€æ‰€æ€§ç„¡è¦–ã€‘&quot;)
print(&quot;âš ï¸ 1ã‚µãƒ³ãƒ—ãƒ«ã®LIMEèª¬æ˜ã‚’å…¨ä½“ã«ä¸€èˆ¬åŒ–&quot;)
print(&quot;â†’ LIMEã¯å±€æ‰€çš„ç·šå½¢è¿‘ä¼¼ãªã®ã§ã€ä»–ã‚µãƒ³ãƒ—ãƒ«ã§ç•°ãªã‚‹èª¬æ˜&quot;)

print(&quot;\nâœ… å¯¾ç­–ï¼šè¤‡æ•°ã‚µãƒ³ãƒ—ãƒ«ã§ä¸€è²«æ€§ç¢ºèª&quot;)
print(&quot;```python&quot;)
print(&quot;# 10ã‚µãƒ³ãƒ—ãƒ«ã§LIMEå®Ÿè¡Œã—ã€é‡è¦ç‰¹å¾´é‡ã®ä¸€è‡´ç‡ã‚’ç¢ºèª&quot;)
print(&quot;for i in range(10):&quot;)
print(&quot;    explanation = lime_explainer.explain_instance(X[i], model.predict)&quot;)
print(&quot;    # ä¸Šä½3ç‰¹å¾´é‡ãŒä¸€è‡´ã™ã‚‹ã‹ç¢ºèª&quot;)
print(&quot;```&quot;)

print(&quot;\nã€è½ã¨ã—ç©´3: ç›¸é–¢ã¨å› æœã®æ··åŒã€‘&quot;)
print(&quot;âš ï¸ ã€ŒSHAPå€¤ãŒé«˜ã„ â†’ ã“ã®ç‰¹å¾´é‡ã‚’å¤‰ãˆã‚Œã°äºˆæ¸¬ãŒå¤‰ã‚ã‚‹ã€&quot;)
print(&quot;â†’ ç›¸é–¢ã§ã‚ã£ã¦å› æœã§ã¯ãªã„&quot;)

print(&quot;\nâœ… å› æœæ¨è«–ã«ã¯åˆ¥æ‰‹æ³•ãŒå¿…è¦&quot;)
print(&quot;```python&quot;)
print(&quot;# XAIã¯ç›¸é–¢åˆ†æ&quot;)
print(&quot;# å› æœæ¨è«–ã«ã¯ä»¥ä¸‹ã‚’ä½¿ç”¨:&quot;)
print(&quot;# - A/Bãƒ†ã‚¹ãƒˆ&quot;)
print(&quot;# - å› æœã‚°ãƒ©ãƒ• (DAG)&quot;)
print(&quot;# - å‚¾å‘ã‚¹ã‚³ã‚¢ãƒãƒƒãƒãƒ³ã‚°&quot;)
print(&quot;```&quot;)

print(&quot;\nã€è½ã¨ã—ç©´4: Attentionå¯è¦–åŒ–ã®éä¿¡ã€‘&quot;)
print(&quot;âš ï¸ AttentionãŒé«˜ã„ = ãƒ¢ãƒ‡ãƒ«ãŒãã®éƒ¨åˆ†ã‚’é‡è¦–&quot;)
print(&quot;â†’ å¿…ãšã—ã‚‚æ­£ã—ã„ç†ç”±ã¨ã¯é™ã‚‰ãªã„&quot;)

print(&quot;\nâœ… è¤‡æ•°æ‰‹æ³•ã§ç›¸äº’æ¤œè¨¼&quot;)
print(&quot;```python&quot;)
print(&quot;# SHAP + LIME + Attention ã®3æ‰‹æ³•ã§ä¸€è‡´ã‚’ç¢ºèª&quot;)
print(&quot;# ç‰©ç†çš„å¦¥å½“æ€§ã‚’å°‚é–€å®¶ã«æ¤œè¨¼ã—ã¦ã‚‚ã‚‰ã†&quot;)
print(&quot;```&quot;)

print(&quot;\nã€è½ã¨ã—ç©´5: å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã§ã®è¨ˆç®—ã‚³ã‚¹ãƒˆç„¡è¦–ã€‘&quot;)
print(&quot;âš ï¸ 10000ã‚µãƒ³ãƒ—ãƒ«ã§Kernel SHAPå®Ÿè¡Œ&quot;)
print(&quot;â†’ è¨ˆç®—æ™‚é–“: æ•°æ™‚é–“ã€œæ•°æ—¥&quot;)

print(&quot;\nâœ… å¯¾ç­–ï¼šæ‰‹æ³•ã¨ã‚µãƒ³ãƒ—ãƒ«æ•°ã®é©åˆ‡ãªé¸æŠ&quot;)
print(&quot;```python&quot;)
print(&quot;if len(X) &lt; 1000:&quot;)
print(&quot;    explainer = shap.KernelExplainer()  # ä»»æ„ãƒ¢ãƒ‡ãƒ«&quot;)
print(&quot;else:&quot;)
print(&quot;    # ã‚µãƒ–ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚° or TreeExplainerä½¿ç”¨&quot;)
print(&quot;    X_sample = shap.sample(X, 1000)&quot;)
print(&quot;    explainer = shap.TreeExplainer()  # é«˜é€Ÿ&quot;)
print(&quot;```&quot;)
</code></pre>
<hr />
<h2>ã¾ã¨ã‚</h2>
<p>ã“ã®ç« ã§ã¯ã€<strong>è§£é‡ˆå¯èƒ½AIï¼ˆXAIï¼‰</strong> ã®ç†è«–ã¨å®Ÿè·µã‚’å­¦ã³ã¾ã—ãŸã€‚</p>
<p><strong>é‡è¦ãƒã‚¤ãƒ³ãƒˆ</strong>ï¼š</p>
<ol>
<li><strong>ãƒ–ãƒ©ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹å•é¡Œ</strong>ï¼šé«˜ç²¾åº¦ãƒ¢ãƒ‡ãƒ«ã¯è§£é‡ˆå›°é›£ â†’ XAIã§è§£æ±º</li>
<li><strong>SHAP</strong>ï¼šShapleyå€¤ã«ã‚ˆã‚‹å…¬å¹³ãªç‰¹å¾´é‡å¯„ä¸åº¦è©•ä¾¡</li>
<li><strong>LIME</strong>ï¼šå±€æ‰€ç·šå½¢è¿‘ä¼¼ã§å€‹åˆ¥äºˆæ¸¬ã®èª¬æ˜ç”Ÿæˆ</li>
<li><strong>Attentionå¯è¦–åŒ–</strong>ï¼šãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®å†…éƒ¨å‹•ä½œç†è§£</li>
<li><strong>å®Ÿä¸–ç•Œå¿œç”¨</strong>ï¼šãƒˆãƒ¨ã‚¿ã€IBMã€Citrineã®æˆåŠŸäº‹ä¾‹</li>
<li><strong>ã‚­ãƒ£ãƒªã‚¢ãƒ‘ã‚¹</strong>ï¼šææ–™ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ãƒ†ã‚£ã‚¹ãƒˆã®éœ€è¦æ‹¡å¤§ã€å¹´å700-2500ä¸‡å††</li>
<li><strong>ç’°å¢ƒç®¡ç†</strong>ï¼šSHAPã€LIMEã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³å›ºå®šã¨è¨ˆç®—ã‚³ã‚¹ãƒˆç®¡ç†</li>
<li><strong>å®Ÿè·µçš„è½ã¨ã—ç©´</strong>ï¼šSHAPå€¤èª¤è§£é‡ˆã€LIMEå±€æ‰€æ€§ã€ç›¸é–¢ã¨å› æœã®æ··åŒã€è¨ˆç®—ã‚³ã‚¹ãƒˆ</li>
</ol>
<p><strong>ã‚·ãƒªãƒ¼ã‚ºç·ã¾ã¨ã‚</strong>ï¼š</p>
<ul>
<li><strong>Chapter 1</strong>: ãƒ‡ãƒ¼ã‚¿åé›†æˆ¦ç•¥ã¨ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚° â†’ é«˜å“è³ªãƒ‡ãƒ¼ã‚¿ã®æº–å‚™</li>
<li><strong>Chapter 2</strong>: ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚° â†’ 200æ¬¡å…ƒâ†’20æ¬¡å…ƒã¸ã®åŠ¹ç‡åŒ–</li>
<li><strong>Chapter 3</strong>: ãƒ¢ãƒ‡ãƒ«é¸æŠã¨æœ€é©åŒ– â†’ Optunaã§è‡ªå‹•æœ€é©åŒ–</li>
<li><strong>Chapter 4</strong>: è§£é‡ˆå¯èƒ½AI â†’ äºˆæ¸¬ã®ç‰©ç†çš„æ„å‘³ã¥ã‘</li>
</ul>
<p><strong>æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—</strong>ï¼š</p>
<ol>
<li>å®Ÿãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§å…¨å·¥ç¨‹ã‚’å®Ÿè·µ</li>
<li>è«–æ–‡æŠ•ç¨¿ã‚„OSSã‚³ãƒ³ãƒˆãƒªãƒ“ãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³</li>
<li>å­¦ä¼šå‚åŠ ã¨ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚­ãƒ³ã‚°</li>
<li>ã‚­ãƒ£ãƒªã‚¢æ§‹ç¯‰ï¼ˆææ–™ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ãƒ†ã‚£ã‚¹ãƒˆï¼‰</li>
</ol>
<hr />
<h2>Chapter 4 ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ</h2>
<h3>SHAPï¼ˆSHapley Additive exPlanationsï¼‰</h3>
<ul>
<li>[ ] <strong>SHAPå€¤ã®ç†è§£</strong></li>
<li>[ ] Shapleyå€¤ã®ç†è«–çš„èƒŒæ™¯ï¼ˆå”åŠ›ã‚²ãƒ¼ãƒ ç†è«–ï¼‰ã‚’ç†è§£</li>
<li>[ ] åŸºæº–å€¤ï¼ˆexpected_valueï¼‰+ SHAPå€¤åˆè¨ˆ = äºˆæ¸¬å€¤ ã‚’ç¢ºèª</li>
<li>
<p>[ ] SHAPå€¤ã¯ç‰¹å¾´é‡å€¤ã®å¤§ãã•ã¨ã¯ç„¡é–¢ä¿‚ï¼ˆå¯„ä¸åº¦ã‚’ç¤ºã™ï¼‰</p>
</li>
<li>
<p>[ ] <strong>SHAPè¨ˆç®—æ‰‹æ³•ã®é¸æŠ</strong></p>
</li>
<li>[ ] æœ¨ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ« â†’ TreeExplainerï¼ˆé«˜é€Ÿãƒ»å³å¯†è§£ï¼‰</li>
<li>[ ] ä»»æ„ãƒ¢ãƒ‡ãƒ« â†’ KernelExplainerï¼ˆé…ã„ãƒ»è¿‘ä¼¼è§£ï¼‰</li>
<li>
<p>[ ] æ·±å±¤å­¦ç¿’ â†’ DeepExplainer or GradientExplainer</p>
</li>
<li>
<p>[ ] <strong>Globalè§£é‡ˆ</strong></p>
</li>
<li>[ ] mean(|SHAPå€¤|)ã§å…¨ä½“çš„ãªç‰¹å¾´é‡é‡è¦åº¦ã‚’è©•ä¾¡</li>
<li>[ ] Summary Plotã§åˆ†å¸ƒã¨å½±éŸ¿æ–¹å‘ã‚’å¯è¦–åŒ–</li>
<li>
<p>[ ] Bar Plotã§ä¸Šä½é‡è¦ç‰¹å¾´é‡ã‚’ãƒ©ãƒ³ã‚­ãƒ³ã‚°</p>
</li>
<li>
<p>[ ] <strong>Localè§£é‡ˆ</strong></p>
</li>
<li>[ ] å€‹åˆ¥ã‚µãƒ³ãƒ—ãƒ«ã®SHAPå€¤ã§äºˆæ¸¬æ ¹æ‹ ã‚’èª¬æ˜</li>
<li>[ ] Force Plotã§åŸºæº–å€¤ã‹ã‚‰ã®å¯„ä¸ã‚’è¦–è¦šåŒ–</li>
<li>
<p>[ ] Waterfall Plotã§ç´¯ç©å¯„ä¸ã‚’è¡¨ç¤º</p>
</li>
<li>
<p>[ ] <strong>Dependence Plot</strong></p>
</li>
<li>[ ] ç‰¹å¾´é‡å€¤ã¨SHAPå€¤ã®é–¢ä¿‚ã‚’å¯è¦–åŒ–</li>
<li>[ ] éç·šå½¢é–¢ä¿‚ã®ç™ºè¦‹</li>
<li>[ ] ç›¸äº’ä½œç”¨é …ï¼ˆinteraction_indexï¼‰ã®ç‰¹å®š</li>
</ul>
<h3>LIMEï¼ˆLocal Interpretable Model-agnostic Explanationsï¼‰</h3>
<ul>
<li>[ ] <strong>LIMEåŸºæœ¬ç†è§£</strong></li>
<li>[ ] å±€æ‰€ç·šå½¢è¿‘ä¼¼ã®ä»•çµ„ã¿ã‚’ç†è§£</li>
<li>[ ] ã‚µãƒ³ãƒ—ãƒ«å‘¨è¾ºã§ã®ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°</li>
<li>
<p>[ ] è·é›¢ã«åŸºã¥ãé‡ã¿ä»˜ã‘</p>
</li>
<li>
<p>[ ] <strong>Tabular LIME</strong></p>
</li>
<li>[ ] LimeTabularExplainerã§è¡¨å½¢å¼ãƒ‡ãƒ¼ã‚¿ã‚’èª¬æ˜</li>
<li>[ ] num_featureså¼•æ•°ã§é‡è¦ç‰¹å¾´é‡æ•°ã‚’æŒ‡å®š</li>
<li>
<p>[ ] explain_instance()ã§å€‹åˆ¥äºˆæ¸¬ã‚’èª¬æ˜</p>
</li>
<li>
<p>[ ] <strong>LIMEã®é™ç•Œèªè­˜</strong></p>
</li>
<li>[ ] å±€æ‰€çš„èª¬æ˜ã§ã‚ã‚Šã€å…¨ä½“åƒã§ã¯ãªã„</li>
<li>[ ] ã‚µãƒ³ãƒ—ãƒ«ã”ã¨ã«ç•°ãªã‚‹èª¬æ˜ï¼ˆä¸€è²«æ€§ãªã—ï¼‰</li>
<li>
<p>[ ] è¨ˆç®—ã‚³ã‚¹ãƒˆã¯SHAPã‚ˆã‚Šä½ã„</p>
</li>
<li>
<p>[ ] <strong>SHAP vs LIMEæ¯”è¼ƒ</strong></p>
</li>
<li>[ ] ä¸¡æ‰‹æ³•ã§é‡è¦ç‰¹å¾´é‡ã®ä¸€è‡´ç‡ã‚’ç¢ºèª</li>
<li>[ ] ç›¸é–¢ &gt; 0.7 ãªã‚‰ä¿¡é ¼æ€§ãŒé«˜ã„</li>
<li>[ ] ä¸ä¸€è‡´æ™‚ã¯æ…é‡ã«è§£é‡ˆ</li>
</ul>
<h3>Attentionå¯è¦–åŒ–ï¼ˆNN/GNNç”¨ï¼‰</h3>
<ul>
<li>[ ] <strong>Attention Weightså–å¾—</strong></li>
<li>[ ] ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®ä¸­é–“å±¤æ´»æ€§åŒ–ã‚’å–å¾—</li>
<li>[ ] Attentionæ©Ÿæ§‹ã®é‡ã¿ã‚’å¯è¦–åŒ–</li>
<li>
<p>[ ] ã©ã®å…¥åŠ›ã«æ³¨ç›®ã—ã¦ã„ã‚‹ã‹åˆ†æ</p>
</li>
<li>
<p>[ ] <strong>Grad-CAMé¢¨æ‰‹æ³•</strong></p>
</li>
<li>[ ] å‹¾é…ãƒ™ãƒ¼ã‚¹ã®é‡è¦åº¦è¨ˆç®—</li>
<li>[ ] æ•°å€¤å¾®åˆ†ã§ç‰¹å¾´é‡é‡è¦åº¦ã‚’è¿‘ä¼¼</li>
<li>
<p>[ ] ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ç‰¹åŒ–</p>
</li>
<li>
<p>[ ] <strong>åˆ†å­ã‚°ãƒ©ãƒ•ã¸ã®å¿œç”¨</strong></p>
</li>
<li>[ ] GNNã§ã©ã®åŸå­/çµåˆãŒé‡è¦ã‹ç‰¹å®š</li>
<li>[ ] Attentionã§åå¿œæ©Ÿæ§‹ã‚’æ¨å®š</li>
<li>[ ] åŒ–å­¦çš„å¦¥å½“æ€§ã‚’å°‚é–€å®¶ã«æ¤œè¨¼</li>
</ul>
<h3>å®Ÿä¸–ç•Œå¿œç”¨äº‹ä¾‹ã®å­¦ç¿’</h3>
<ul>
<li>[ ] <strong>ãƒˆãƒ¨ã‚¿ï¼šææ–™é–‹ç™º</strong></li>
<li>[ ] SHAPè§£æã§åŠ£åŒ–è¦å› ã‚’ç‰¹å®š</li>
<li>[ ] æ¸©åº¦ãƒ»é›»åœ§ãƒ»ã‚µã‚¤ã‚¯ãƒ«æ•°ã®ç›¸äº’ä½œç”¨ã‚’å¯è¦–åŒ–</li>
<li>
<p>[ ] é–‹ç™ºæœŸé–“40%çŸ­ç¸®ã€é›»æ± å¯¿å‘½20%å‘ä¸Š</p>
</li>
<li>
<p>[ ] <strong>IBM Researchï¼šè‡ªå‹•åŒ–å­¦å®Ÿé¨“</strong></p>
</li>
<li>[ ] GNN + Attentionã§åå¿œãƒ¡ã‚«ãƒ‹ã‚ºãƒ äºˆæ¸¬</li>
<li>[ ] åå¿œåç‡äºˆæ¸¬ç²¾åº¦95%</li>
<li>
<p>[ ] æ–°è¦åå¿œçµŒè·¯ã®ç™ºè¦‹</p>
</li>
<li>
<p>[ ] <strong>Citrine Informaticsï¼šSaaSäº‹æ¥­</strong></p>
</li>
<li>[ ] èª¬æ˜å¯èƒ½AIã‚’ä¸­æ ¸æŠ€è¡“ã¨ã™ã‚‹</li>
<li>[ ] ä¸ç¢ºå®Ÿæ€§å®šé‡åŒ– + SHAP</li>
<li>[ ] ãƒ‘ãƒŠã‚½ãƒ‹ãƒƒã‚¯ãƒ»3Mãƒ»Michelinã¸ã®å°å…¥</li>
</ul>
<h3>ã‚­ãƒ£ãƒªã‚¢ãƒ‘ã‚¹æ§‹ç¯‰</h3>
<ul>
<li>[ ] <strong>å¿…è¦ã‚¹ã‚­ãƒ«ã‚»ãƒƒãƒˆ</strong></li>
<li>[ ] ææ–™ç§‘å­¦ã®å°‚é–€çŸ¥è­˜ï¼ˆå­¦ä½æ¨å¥¨ï¼‰</li>
<li>[ ] æ©Ÿæ¢°å­¦ç¿’ãƒ»æ·±å±¤å­¦ç¿’ã®å®Ÿè£…ã‚¹ã‚­ãƒ«</li>
<li>[ ] XAIæ‰‹æ³•ï¼ˆSHAPã€LIMEï¼‰ã®ç¿’å¾—</li>
<li>
<p>[ ] Pythonã€scikit-learnã€PyTorch/TensorFlow</p>
</li>
<li>
<p>[ ] <strong>ã‚­ãƒ£ãƒªã‚¢é¸æŠè‚¢</strong></p>
</li>
<li>[ ] ææ–™ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ãƒ†ã‚£ã‚¹ãƒˆï¼ˆè£½é€ æ¥­R&amp;Dï¼‰</li>
<li>[ ] XAIç ”ç©¶è€…ï¼ˆã‚¢ã‚«ãƒ‡ãƒŸã‚¢ï¼‰</li>
<li>[ ] MLã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ï¼ˆææ–™ç‰¹åŒ–ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—ï¼‰</li>
<li>[ ] R&amp;D Managerï¼ˆAIæ´»ç”¨æ¨é€²ï¼‰</li>
<li>
<p>[ ] ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆ</p>
</li>
<li>
<p>[ ] <strong>å¹´åç›®æ¨™</strong></p>
</li>
<li>[ ] æ—¥æœ¬ï¼šã‚¸ãƒ¥ãƒ‹ã‚¢500-700ä¸‡ã€ãƒŸãƒ‰ãƒ«1000-1500ä¸‡ã€ã‚·ãƒ‹ã‚¢1500-2500ä¸‡</li>
<li>[ ] ç±³å›½ï¼š$70-90Kï¼ˆã‚¸ãƒ¥ãƒ‹ã‚¢ï¼‰ã€$130-180Kï¼ˆãƒŸãƒ‰ãƒ«ï¼‰ã€$180-300Kï¼ˆã‚·ãƒ‹ã‚¢ï¼‰</li>
<li>
<p>[ ] ã‚¹ã‚­ãƒ«ã‚¢ãƒƒãƒ—ã§å¹´åå‘ä¸Šï¼šå­¦ä½ã€è«–æ–‡ã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå®Ÿç¸¾</p>
</li>
<li>
<p>[ ] <strong>ã‚¹ã‚­ãƒ«ã‚¢ãƒƒãƒ—æˆ¦ç•¥</strong></p>
</li>
<li>[ ] ææ–™ç§‘å­¦ã®åŸºç¤å›ºã‚ï¼ˆå­¦ä½å–å¾—ã¾ãŸã¯ç‹¬å­¦ï¼‰</li>
<li>[ ] ML/DLã®å®Ÿè·µï¼ˆKaggleã€GitHubï¼‰</li>
<li>[ ] XAIæ‰‹æ³•ã®ç¿’å¾—ï¼ˆæœ¬ã‚·ãƒªãƒ¼ã‚ºï¼‰</li>
<li>[ ] è«–æ–‡ç™ºè¡¨ãƒ»OSSã‚³ãƒ³ãƒˆãƒªãƒ“ãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³</li>
<li>[ ] å­¦ä¼šãƒ»å‹‰å¼·ä¼šã§ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚­ãƒ³ã‚°</li>
</ul>
<h3>å®Ÿè·µçš„è½ã¨ã—ç©´ã®å›é¿ï¼ˆXAIï¼‰</h3>
<ul>
<li>[ ] <strong>SHAPå€¤ã®æ­£ã—ã„è§£é‡ˆ</strong></li>
<li>[ ] SHAPå€¤ â‰  ç‰¹å¾´é‡ã®å¤§ãã•</li>
<li>[ ] SHAPå€¤ = äºˆæ¸¬ã¸ã®å¯„ä¸åº¦</li>
<li>
<p>[ ] åŸºæº–å€¤ã‹ã‚‰ã®åå·®ã¨ã—ã¦ç†è§£</p>
</li>
<li>
<p>[ ] <strong>LIMEã®å±€æ‰€æ€§èªè­˜</strong></p>
</li>
<li>[ ] 1ã‚µãƒ³ãƒ—ãƒ«ã®èª¬æ˜ã‚’å…¨ä½“ã«ä¸€èˆ¬åŒ–ã—ãªã„</li>
<li>[ ] è¤‡æ•°ã‚µãƒ³ãƒ—ãƒ«ã§ä¸€è²«æ€§ã‚’ç¢ºèª</li>
<li>
<p>[ ] SHAPã¨ç›¸äº’æ¤œè¨¼</p>
</li>
<li>
<p>[ ] <strong>ç›¸é–¢ã¨å› æœã®åŒºåˆ¥</strong></p>
</li>
<li>[ ] XAIã¯ç›¸é–¢åˆ†æï¼ˆå› æœæ¨è«–ã§ã¯ãªã„ï¼‰</li>
<li>[ ] ã€ŒSHAPå€¤é«˜ã„ â†’ å¤‰æ›´ã™ã‚Œã°äºˆæ¸¬å¤‰ã‚ã‚‹ã€ã¯èª¤è§£</li>
<li>
<p>[ ] å› æœæ¨è«–ã«ã¯A/Bãƒ†ã‚¹ãƒˆã€å› æœã‚°ãƒ©ãƒ•ãŒå¿…è¦</p>
</li>
<li>
<p>[ ] <strong>Attentionå¯è¦–åŒ–ã®é™ç•Œ</strong></p>
</li>
<li>[ ] Attentioné«˜ â‰  å¿…ãšã—ã‚‚æ­£ã—ã„ç†ç”±</li>
<li>[ ] è¤‡æ•°æ‰‹æ³•ï¼ˆSHAP + LIME + Attentionï¼‰ã§ç›¸äº’æ¤œè¨¼</li>
<li>
<p>[ ] ç‰©ç†çš„å¦¥å½“æ€§ã‚’å°‚é–€å®¶ã«ç¢ºèª</p>
</li>
<li>
<p>[ ] <strong>è¨ˆç®—ã‚³ã‚¹ãƒˆç®¡ç†</strong></p>
</li>
<li>[ ] Kernel SHAP: ã‚µãƒ³ãƒ—ãƒ«æ•° &lt; 1000 æ¨å¥¨</li>
<li>[ ] Tree SHAP: æ•°ä¸‡ã‚µãƒ³ãƒ—ãƒ«ã§ã‚‚é«˜é€Ÿ</li>
<li>[ ] å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã¯ã‚µãƒ–ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚° or Treeæ‰‹æ³•ä½¿ç”¨</li>
</ul>
<h3>XAIå“è³ªè©•ä¾¡</h3>
<ul>
<li>[ ] <strong>èª¬æ˜ã®ä¸€è²«æ€§</strong></li>
<li>[ ] SHAP vs LIME ã®ç›¸é–¢ &gt; 0.7</li>
<li>[ ] è¤‡æ•°ã‚µãƒ³ãƒ—ãƒ«ã§é‡è¦ç‰¹å¾´é‡ãŒä¸€è‡´</li>
<li>
<p>[ ] ç‰©ç†çš„è§£é‡ˆã¨æ©Ÿæ¢°å­¦ç¿’è§£é‡ˆãŒä¸€è‡´</p>
</li>
<li>
<p>[ ] <strong>ç‰©ç†çš„å¦¥å½“æ€§</strong></p>
</li>
<li>[ ] å°‚é–€å®¶ã«ã‚ˆã‚‹æ¤œè¨¼</li>
<li>[ ] æ—¢çŸ¥ã®ç‰©ç†æ³•å‰‡ã¨ã®æ•´åˆæ€§</li>
<li>
<p>[ ] å®Ÿé¨“çµæœã¨ã®ä¸€è‡´</p>
</li>
<li>
<p>[ ] <strong>å®Ÿç”¨æ€§</strong></p>
</li>
<li>[ ] ææ–™è¨­è¨ˆã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³æŠ½å‡ºå¯èƒ½</li>
<li>[ ] å®Ÿé¨“è¨ˆç”»ã¸ã®åæ˜ å¯èƒ½</li>
<li>[ ] è«–æ–‡ãƒ»ç‰¹è¨±ã§ã®èª¬æ˜è²¬ä»»ã‚’æœãŸã›ã‚‹</li>
</ul>
<h3>å†ç¾æ€§ã®ç¢ºä¿</h3>
<ul>
<li>[ ] <strong>ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†</strong></li>
<li>[ ] SHAPã€LIMEã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³å›ºå®š</li>
<li>[ ] APIã®å¤‰æ›´ã«æ³¨æ„ï¼ˆç‰¹ã«SHAPï¼‰</li>
<li>
<p>[ ] requirements.txtã«æ˜è¨˜</p>
</li>
<li>
<p>[ ] <strong>è¨ˆç®—ç’°å¢ƒçµ±ä¸€</strong></p>
</li>
<li>[ ] ä¹±æ•°ã‚·ãƒ¼ãƒ‰è¨­å®šï¼ˆSHAPã€LIMEï¼‰</li>
<li>[ ] ä¸¦åˆ—è¨ˆç®—ã®å†ç¾æ€§ï¼ˆn_jobså›ºå®šï¼‰</li>
<li>
<p>[ ] Dockerç’°å¢ƒæ¨å¥¨</p>
</li>
<li>
<p>[ ] <strong>èª¬æ˜ã®ä¿å­˜</strong></p>
</li>
<li>[ ] SHAPå€¤ã‚’NumPyé…åˆ—ã§ä¿å­˜</li>
<li>[ ] å¯è¦–åŒ–ç”»åƒã‚’PNG/PDFä¿å­˜</li>
<li>[ ] èª¬æ˜æ–‡ã‚’Markdown/LaTeXåŒ–</li>
</ul>
<hr />
<h2>å‚è€ƒæ–‡çŒ®</h2>
<ol>
<li>
<p><strong>Lundberg, S. M. &amp; Lee, S. I.</strong> (2017). A unified approach to interpreting model predictions. <em>Advances in Neural Information Processing Systems</em>, 30, 4765-4774.</p>
</li>
<li>
<p><strong>Ribeiro, M. T., Singh, S., &amp; Guestrin, C.</strong> (2016). "Why should I trust you?": Explaining the predictions of any classifier. <em>Proceedings of the 22nd ACM SIGKDD</em>, 1135-1144. <a href="https://doi.org/10.1145/2939672.2939778">DOI: 10.1145/2939672.2939778</a></p>
</li>
<li>
<p><strong>Molnar, C.</strong> (2022). <em>Interpretable Machine Learning: A Guide for Making Black Box Models Explainable</em> (2nd ed.). <a href="https://christophm.github.io/interpretable-ml-book/">https://christophm.github.io/interpretable-ml-book/</a></p>
</li>
<li>
<p><strong>Vaswani, A., Shazeer, N., Parmar, N., et al.</strong> (2017). Attention is all you need. <em>Advances in Neural Information Processing Systems</em>, 30, 5998-6008.</p>
</li>
<li>
<p><strong>Citrine Informatics.</strong> (2023). Materials Informatics Platform. <a href="https://citrine.io/">https://citrine.io/</a></p>
</li>
</ol>
<hr />
<p><a href="chapter-3.html">â† Chapter 3ã«æˆ»ã‚‹</a> | <a href="index.html">ã‚·ãƒªãƒ¼ã‚ºç›®æ¬¡ã«æˆ»ã‚‹</a></p>
<hr />
<h2>ã‚·ãƒªãƒ¼ã‚ºå®Œäº†ãŠã‚ã§ã¨ã†ã”ã–ã„ã¾ã™ï¼</h2>
<p>ãƒ‡ãƒ¼ã‚¿é§†å‹•ææ–™ç§‘å­¦ã®å®Ÿè·µçš„ã‚¹ã‚­ãƒ«ã‚’ç¿’å¾—ã•ã‚Œã¾ã—ãŸã€‚ä»Šå¾Œã®ã”æ´»èºã‚’æœŸå¾…ã—ã¦ã„ã¾ã™ã€‚</p>
<p><strong>ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ»è³ªå•</strong>:
- Email: yusuke.hashimoto.b8@tohoku.ac.jp
- GitHub: <a href="https://github.com/YusukeHashimotoPhD/AI_Homepage">AI_Homepage Repository</a></p>
<p><strong>é–¢é€£ã‚·ãƒªãƒ¼ã‚º</strong>:
- <a href="../bayesian-optimization-introduction/">ãƒ™ã‚¤ã‚ºæœ€é©åŒ–å…¥é–€</a>
- <a href="../active-learning-introduction/">Active Learningå…¥é–€</a>
- <a href="../gnn-introduction/">ã‚°ãƒ©ãƒ•ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å…¥é–€</a></p><div class="navigation">
    <a href="chapter-3.html" class="nav-button">â† å‰ã®ç« </a>
    <a href="index.html" class="nav-button">ã‚·ãƒªãƒ¼ã‚ºç›®æ¬¡ã«æˆ»ã‚‹</a>
</div>
    </main>

    
    <section class="disclaimer">
        <h3>å…è²¬äº‹é …</h3>
        <ul>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯æ•™è‚²ãƒ»ç ”ç©¶ãƒ»æƒ…å ±æä¾›ã®ã¿ã‚’ç›®çš„ã¨ã—ã¦ãŠã‚Šã€å°‚é–€çš„ãªåŠ©è¨€(æ³•å¾‹ãƒ»ä¼šè¨ˆãƒ»æŠ€è¡“çš„ä¿è¨¼ãªã©)ã‚’æä¾›ã™ã‚‹ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŠã‚ˆã³ä»˜éšã™ã‚‹ã‚³ãƒ¼ãƒ‰ä¾‹ã¯ã€Œç¾çŠ¶æœ‰å§¿(AS IS)ã€ã§æä¾›ã•ã‚Œã€æ˜ç¤ºã¾ãŸã¯é»™ç¤ºã‚’å•ã‚ãšã€å•†å“æ€§ã€ç‰¹å®šç›®çš„é©åˆæ€§ã€æ¨©åˆ©éä¾µå®³ã€æ­£ç¢ºæ€§ãƒ»å®Œå…¨æ€§ã€å‹•ä½œãƒ»å®‰å…¨æ€§ç­‰ã„ã‹ãªã‚‹ä¿è¨¼ã‚‚ã—ã¾ã›ã‚“ã€‚</li>
            <li>å¤–éƒ¨ãƒªãƒ³ã‚¯ã€ç¬¬ä¸‰è€…ãŒæä¾›ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ»ãƒ„ãƒ¼ãƒ«ãƒ»ãƒ©ã‚¤ãƒ–ãƒ©ãƒªç­‰ã®å†…å®¹ãƒ»å¯ç”¨æ€§ãƒ»å®‰å…¨æ€§ã«ã¤ã„ã¦ã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯ä¸€åˆ‡ã®è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®åˆ©ç”¨ãƒ»å®Ÿè¡Œãƒ»è§£é‡ˆã«ã‚ˆã‚Šç›´æ¥çš„ãƒ»é–“æ¥çš„ãƒ»ä»˜éšçš„ãƒ»ç‰¹åˆ¥ãƒ»çµæœçš„ãƒ»æ‡²ç½°çš„æå®³ãŒç”Ÿã˜ãŸå ´åˆã§ã‚‚ã€é©ç”¨æ³•ã§è¨±å®¹ã•ã‚Œã‚‹æœ€å¤§é™ã®ç¯„å›²ã§ã€ä½œæˆè€…ãŠã‚ˆã³æ±åŒ—å¤§å­¦ã¯è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å†…å®¹ã¯ã€äºˆå‘Šãªãå¤‰æ›´ãƒ»æ›´æ–°ãƒ»æä¾›åœæ­¢ã•ã‚Œã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚</li>
            <li>æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®è‘—ä½œæ¨©ãƒ»ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯æ˜è¨˜ã•ã‚ŒãŸæ¡ä»¶(ä¾‹: CC BY 4.0)ã«å¾“ã„ã¾ã™ã€‚å½“è©²ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯é€šå¸¸ã€ç„¡ä¿è¨¼æ¡é …ã‚’å«ã¿ã¾ã™ã€‚</li>
        </ul>
    </section>

<footer>
        <p><strong>ä½œæˆè€…</strong>: AI Terakoya Content Team</p>
        <p><strong>ãƒãƒ¼ã‚¸ãƒ§ãƒ³</strong>: 1.0 | <strong>ä½œæˆæ—¥</strong>: 2025-10-17</p>
        <p><strong>ãƒ©ã‚¤ã‚»ãƒ³ã‚¹</strong>: Creative Commons BY 4.0</p>
        <p>Â© 2025 AI Terakoya. All rights reserved.</p>
    </footer>
</body>
</html>
