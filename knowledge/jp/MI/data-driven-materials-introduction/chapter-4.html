<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Chapter - AI Terakoya</title>

    <style>
        :root {
            --color-primary: #2c3e50;
            --color-primary-dark: #1a252f;
            --color-accent: #7b2cbf;
            --color-accent-light: #9d4edd;
            --color-text: #2d3748;
            --color-text-light: #4a5568;
            --color-bg: #ffffff;
            --color-bg-alt: #f7fafc;
            --color-border: #e2e8f0;
            --color-code-bg: #f8f9fa;
            --color-link: #3182ce;
            --color-link-hover: #2c5aa0;

            --spacing-xs: 0.5rem;
            --spacing-sm: 1rem;
            --spacing-md: 1.5rem;
            --spacing-lg: 2rem;
            --spacing-xl: 3rem;

            --font-body: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            --font-mono: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;

            --border-radius: 8px;
            --box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: var(--font-body);
            line-height: 1.7;
            color: var(--color-text);
            background-color: var(--color-bg);
            font-size: 16px;
        }

        header {
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            padding: var(--spacing-xl) var(--spacing-md);
            margin-bottom: var(--spacing-xl);
            box-shadow: var(--box-shadow);
        }

        .header-content {
            max-width: 900px;
            margin: 0 auto;
        }

        h1 {
            font-size: 2rem;
            font-weight: 700;
            margin-bottom: var(--spacing-sm);
            line-height: 1.2;
        }

        .subtitle {
            font-size: 1.1rem;
            opacity: 0.95;
            font-weight: 400;
            margin-bottom: var(--spacing-md);
        }

        .meta {
            display: flex;
            flex-wrap: wrap;
            gap: var(--spacing-md);
            font-size: 0.9rem;
            opacity: 0.9;
        }

        .meta-item {
            display: flex;
            align-items: center;
            gap: 0.3rem;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 0 var(--spacing-md) var(--spacing-xl);
        }

        h2 {
            font-size: 1.75rem;
            color: var(--color-primary);
            margin-top: var(--spacing-xl);
            margin-bottom: var(--spacing-md);
            padding-bottom: var(--spacing-xs);
            border-bottom: 3px solid var(--color-accent);
        }

        h3 {
            font-size: 1.4rem;
            color: var(--color-primary);
            margin-top: var(--spacing-lg);
            margin-bottom: var(--spacing-sm);
        }

        h4 {
            font-size: 1.1rem;
            color: var(--color-primary-dark);
            margin-top: var(--spacing-md);
            margin-bottom: var(--spacing-sm);
        }

        p {
            margin-bottom: var(--spacing-md);
            color: var(--color-text);
        }

        a {
            color: var(--color-link);
            text-decoration: none;
            transition: color 0.2s;
        }

        a:hover {
            color: var(--color-link-hover);
            text-decoration: underline;
        }

        ul, ol {
            margin-left: var(--spacing-lg);
            margin-bottom: var(--spacing-md);
        }

        li {
            margin-bottom: var(--spacing-xs);
            color: var(--color-text);
        }

        pre {
            background-color: var(--color-code-bg);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            overflow-x: auto;
            margin-bottom: var(--spacing-md);
            font-family: var(--font-mono);
            font-size: 0.9rem;
            line-height: 1.5;
        }

        code {
            font-family: var(--font-mono);
            font-size: 0.9em;
            background-color: var(--color-code-bg);
            padding: 0.2em 0.4em;
            border-radius: 3px;
        }

        pre code {
            background-color: transparent;
            padding: 0;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: var(--spacing-md);
            font-size: 0.95rem;
        }

        th, td {
            border: 1px solid var(--color-border);
            padding: var(--spacing-sm);
            text-align: left;
        }

        th {
            background-color: var(--color-bg-alt);
            font-weight: 600;
            color: var(--color-primary);
        }

        blockquote {
            border-left: 4px solid var(--color-accent);
            padding-left: var(--spacing-md);
            margin: var(--spacing-md) 0;
            color: var(--color-text-light);
            font-style: italic;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        .mermaid {
            text-align: center;
            margin: var(--spacing-lg) 0;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        details {
            background-color: var(--color-bg-alt);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            margin-bottom: var(--spacing-md);
        }

        summary {
            cursor: pointer;
            font-weight: 600;
            color: var(--color-primary);
            user-select: none;
            padding: var(--spacing-xs);
            margin: calc(-1 * var(--spacing-md));
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        summary:hover {
            background-color: rgba(123, 44, 191, 0.1);
        }

        details[open] summary {
            margin-bottom: var(--spacing-md);
            border-bottom: 1px solid var(--color-border);
        }

        .learning-objectives {
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
            padding: var(--spacing-lg);
            border-radius: var(--border-radius);
            border-left: 4px solid var(--color-accent);
            margin-bottom: var(--spacing-xl);
        }

        .learning-objectives h2 {
            margin-top: 0;
            border-bottom: none;
        }

        .navigation {
            display: flex;
            justify-content: space-between;
            gap: var(--spacing-md);
            margin: var(--spacing-xl) 0;
            padding-top: var(--spacing-lg);
            border-top: 2px solid var(--color-border);
        }

        .nav-button {
            flex: 1;
            padding: var(--spacing-md);
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            border-radius: var(--border-radius);
            text-align: center;
            font-weight: 600;
            transition: transform 0.2s, box-shadow 0.2s;
            box-shadow: var(--box-shadow);
        }

        .nav-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
            text-decoration: none;
        }

        footer {
            margin-top: var(--spacing-xl);
            padding: var(--spacing-lg) var(--spacing-md);
            background-color: var(--color-bg-alt);
            border-top: 1px solid var(--color-border);
            text-align: center;
            font-size: 0.9rem;
            color: var(--color-text-light);
        }

        @media (max-width: 768px) {
            h1 {
                font-size: 1.5rem;
            }

            h2 {
                font-size: 1.4rem;
            }

            h3 {
                font-size: 1.2rem;
            }

            .meta {
                font-size: 0.85rem;
            }

            .navigation {
                flex-direction: column;
            }

            table {
                font-size: 0.85rem;
            }

            th, td {
                padding: var(--spacing-xs);
            }
        }
    </style>

    <script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
    <script>
        mermaid.initialize({ startOnLoad: true, theme: 'default', securityLevel: 'strict' });
    </script>

    <!-- MathJax for LaTeX equation rendering -->
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\(', '\)']],
                displayMath: [['$$', '$$'], ['\[', '\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
                ignoreHtmlClass: 'mermaid'
            }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" async></script>
</head>
<body>
    <header>
        <div class="header-content">
            <h1>Chapter</h1>
            <p class="subtitle"></p>
            <div class="meta">
                <span class="meta-item">üìñ Ë™≠‰∫ÜÊôÇÈñì: 20-25ÂàÜ</span>
                <span class="meta-item">üìä Èõ£ÊòìÂ∫¶: ÂàùÁ¥ö</span>
                <span class="meta-item">üíª „Ç≥„Éº„Éâ‰æã: 0ÂÄã</span>
                <span class="meta-item">üìù ÊºîÁøíÂïèÈ°å: 0Âïè</span>
            </div>
        </div>
    </header>

    <main class="container">
<h1>Chapter 4: Ëß£ÈáàÂèØËÉΩAI (XAI)</h1>
<hr />
<h2>Â≠¶ÁøíÁõÆÊ®ô</h2>
<p>„Åì„ÅÆÁ´†„ÇíË™≠„ÇÄ„Åì„Å®„Åß„ÄÅ‰ª•‰∏ã„ÇíÁøíÂæó„Åß„Åç„Åæ„ÅôÔºö</p>
<p>‚úÖ Ëß£ÈáàÂèØËÉΩÊÄß„ÅÆÈáçË¶ÅÊÄß„Å®„Éñ„É©„ÉÉ„ÇØ„Éú„ÉÉ„ÇØ„ÇπÂïèÈ°å„ÅÆÁêÜËß£
‚úÖ SHAPÔºàShapleyÂÄ§Ôºâ„Å´„Çà„Çã‰∫àÊ∏¨„ÅÆÂÆöÈáèÁöÑËß£Èáà
‚úÖ LIME„Å´„Çà„ÇãÂ±ÄÊâÄÁöÑ„Å™Á∑öÂΩ¢Ëøë‰ºº„Å®Ë™¨ÊòéÁîüÊàê
‚úÖ AttentionÂèØË¶ñÂåñ„Å´„Çà„Çã„Éã„É•„Éº„É©„É´„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ„ÅÆËß£Èáà
‚úÖ „Éà„É®„Çø„ÉªIBM„ÉªCitrine„Å™„Å©ÂÆü‰∏ñÁïåÂøúÁî®‰∫ã‰æã„ÅÆÂ≠¶Áøí
‚úÖ ÊùêÊñô„Éá„Éº„Çø„Çµ„Ç§„Ç®„É≥„ÉÜ„Ç£„Çπ„Éà„ÅÆ„Ç≠„É£„É™„Ç¢„Éë„Çπ„Å®Âπ¥ÂèéÊÉÖÂ†±</p>
<hr />
<h2>4.1 Ëß£ÈáàÂèØËÉΩÊÄß„ÅÆÈáçË¶ÅÊÄß</h2>
<p>Ê©üÊ¢∞Â≠¶Áøí„É¢„Éá„É´„ÅÆ‰∫àÊ∏¨„ÇíÁêÜËß£„Åó„ÄÅÁâ©ÁêÜÁöÑÊÑèÂë≥„ÇíÊäΩÂá∫„Åô„Çã„Åì„Å®„ÅåÊùêÊñôÁßëÂ≠¶„Åß„ÅØ‰∏çÂèØÊ¨†„Åß„Åô„ÄÇ</p>
<h3>„Éñ„É©„ÉÉ„ÇØ„Éú„ÉÉ„ÇØ„ÇπÂïèÈ°å</h3>
<pre><code class="language-python">import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import Ridge

# „Çµ„É≥„Éó„É´„Éá„Éº„Çø
np.random.seed(42)
X = np.random.randn(200, 10)
y = 2*X[:, 0] + 3*X[:, 1] - 1.5*X[:, 2] + np.random.normal(0, 0.5, 200)

# Ëß£ÈáàÂèØËÉΩ„É¢„Éá„É´ vs „Éñ„É©„ÉÉ„ÇØ„Éú„ÉÉ„ÇØ„Çπ„É¢„Éá„É´
ridge = Ridge(alpha=1.0)
rf = RandomForestRegressor(n_estimators=100, random_state=42)

ridge.fit(X, y)
rf.fit(X, y)

# Ridge‰øÇÊï∞ÔºàËß£ÈáàÂèØËÉΩÔºâ
ridge_coefs = ridge.coef_

# ÂèØË¶ñÂåñÔºö„É¢„Éá„É´Ëß£ÈáàÊÄß„ÅÆÈÅï„ÅÑ
fig, axes = plt.subplots(1, 2, figsize=(14, 6))

# Ridge: Á∑öÂΩ¢‰øÇÊï∞„ÅßÊòéÁ¢∫
axes[0].bar(range(len(ridge_coefs)), ridge_coefs,
            color='steelblue', alpha=0.7)
axes[0].set_xlabel('ÁâπÂæ¥Èáè„Ç§„É≥„Éá„ÉÉ„ÇØ„Çπ', fontsize=11)
axes[0].set_ylabel('‰øÇÊï∞', fontsize=11)
axes[0].set_title('RidgeÂõûÂ∏∞ÔºàËß£ÈáàÂèØËÉΩÔºâ', fontsize=12, fontweight='bold')
axes[0].axhline(y=0, color='red', linestyle='--', linewidth=1)
axes[0].grid(alpha=0.3)

# Random Forest: Ë§áÈõë„Å™ÈùûÁ∑öÂΩ¢Èñ¢‰øÇÔºà„Éñ„É©„ÉÉ„ÇØ„Éú„ÉÉ„ÇØ„ÇπÔºâ
axes[1].text(0.5, 0.5, '‚ùì\n„Éñ„É©„ÉÉ„ÇØ„Éú„ÉÉ„ÇØ„Çπ\n\n100Êú¨„ÅÆÊ±∫ÂÆöÊú®\nË§áÈõë„Å™ÈùûÁ∑öÂΩ¢Èñ¢‰øÇ\nËß£ÈáàÂõ∞Èõ£',
             ha='center', va='center', fontsize=16,
             bbox=dict(boxstyle='round', facecolor='gray', alpha=0.3),
             transform=axes[1].transAxes)
axes[1].set_title('Random ForestÔºà„Éñ„É©„ÉÉ„ÇØ„Éú„ÉÉ„ÇØ„ÇπÔºâ',
                  fontsize=12, fontweight='bold')
axes[1].axis('off')

plt.tight_layout()
plt.show()

print(&quot;Ëß£ÈáàÂèØËÉΩÊÄß„ÅÆË™≤È°åÔºö&quot;)
print(&quot;- Á∑öÂΩ¢„É¢„Éá„É´: ‰øÇÊï∞„ÅßÂΩ±ÈüøÂ∫¶„ÅåÊòéÁ¢∫„Å†„Åå„ÄÅÁ≤æÂ∫¶„Åå‰Ωé„ÅÑ&quot;)
print(&quot;- ÈùûÁ∑öÂΩ¢„É¢„Éá„É´: È´òÁ≤æÂ∫¶„Å†„Åå„ÄÅ„Å™„Åú„Åù„ÅÆ‰∫àÊ∏¨„Å´„Å™„Å£„Åü„Åã‰∏çÊòé&quot;)
print(&quot;‚Üí XAIÔºàËß£ÈáàÂèØËÉΩAIÔºâ„Åß‰∏°Á´ã„ÇíÁõÆÊåá„Åô&quot;)
</code></pre>
<h3>ÊùêÊñôÁßëÂ≠¶„Å´„Åä„Åë„ÇãÁâ©ÁêÜÁöÑËß£Èáà„ÅÆÂøÖË¶ÅÊÄß</h3>
<pre><code class="language-python"># ÊùêÊñôÁßëÂ≠¶„Åß„ÅÆËß£ÈáàÂèØËÉΩÊÄß„ÅÆ„É¶„Éº„Çπ„Ç±„Éº„Çπ
use_cases = pd.DataFrame({
    '„É¶„Éº„Çπ„Ç±„Éº„Çπ': [
        'Êñ∞ÊùêÊñôÁô∫Ë¶ã',
        'ÂêàÊàêÊù°‰ª∂ÊúÄÈÅ©Âåñ',
        '„Éó„É≠„Çª„ÇπÁï∞Â∏∏Ê§úÂá∫',
        'Áâ©ÊÄß‰∫àÊ∏¨',
        'ÊùêÊñôË®≠Ë®à„Ç¨„Ç§„Éâ„É©„Ç§„É≥'
    ],
    'Ëß£ÈáàÊÄß„ÅÆÈáçË¶ÅÂ∫¶': [10, 9, 8, 7, 10],
    'ÁêÜÁî±': [
        'Áâ©ÁêÜÁöÑ„É°„Ç´„Éã„Ç∫„É†„ÅÆÁêÜËß£„ÅåÊñ∞Áô∫Ë¶ã„Å´„Å§„Å™„Åå„Çã',
        '„Å©„ÅÆ„Éë„É©„É°„Éº„Çø„ÅåÈáçË¶Å„Åã„ÇíÁâπÂÆö',
        'Áï∞Â∏∏„ÅÆÂéüÂõ†ÁâπÂÆö„ÅåÂøÖË¶Å',
        '‰∫àÊ∏¨Ê†πÊã†„ÅÆÊ§úË®º',
        'Ë®≠Ë®àÊåáÈáù„ÅÆÊäΩÂá∫'
    ]
})

# ÂèØË¶ñÂåñ
fig, ax = plt.subplots(figsize=(12, 6))

colors = plt.cm.YlOrRd(np.linspace(0.3, 0.9, len(use_cases)))

bars = ax.barh(use_cases['„É¶„Éº„Çπ„Ç±„Éº„Çπ'],
               use_cases['Ëß£ÈáàÊÄß„ÅÆÈáçË¶ÅÂ∫¶'],
               color=colors, alpha=0.7)

ax.set_xlabel('Ëß£ÈáàÊÄß„ÅÆÈáçË¶ÅÂ∫¶Ôºà1-10Ôºâ', fontsize=12)
ax.set_xlim(0, 10)
ax.set_title('ÊùêÊñôÁßëÂ≠¶„Å´„Åä„Åë„ÇãËß£ÈáàÂèØËÉΩÊÄß„ÅÆÈáçË¶ÅÂ∫¶',
             fontsize=13, fontweight='bold')
ax.grid(axis='x', alpha=0.3)

# ÁêÜÁî±„ÇíÊ≥®Èáà
for idx, row in use_cases.iterrows():
    ax.text(row['Ëß£ÈáàÊÄß„ÅÆÈáçË¶ÅÂ∫¶'] + 0.3, idx,
            row['ÁêÜÁî±'], va='center', fontsize=9, style='italic')

plt.tight_layout()
plt.show()

print(&quot;ÊùêÊñôÁßëÂ≠¶„ÅßXAI„ÅåÂøÖË¶Å„Å™ÁêÜÁî±Ôºö&quot;)
print(&quot;1. Áâ©ÁêÜÊ≥ïÂâá„Å®„ÅÆÊï¥ÂêàÊÄßÊ§úË®º&quot;)
print(&quot;2. ÂÆüÈ®ìË®àÁîª„Å∏„ÅÆÂèçÊò†&quot;)
print(&quot;3. Â∞ÇÈñÄÂÆ∂Áü•Ë≠ò„Å®„ÅÆÁµ±Âêà&quot;)
print(&quot;4. Ë´ñÊñá„ÉªÁâπË®±„Åß„ÅÆË™¨ÊòéË≤¨‰ªª&quot;)
</code></pre>
<h3>‰ø°È†ºÊÄß„Å®„Éá„Éê„ÉÉ„Ç∞</h3>
<pre><code class="language-python"># „É¢„Éá„É´„ÅÆ‰∫àÊ∏¨„Éü„Çπ„ÇíËß£Èáà„ÅßÁô∫Ë¶ã„Åô„Çã‰æã
from sklearn.model_data import train_test_split
from sklearn.metrics import mean_absolute_error

# „Éá„Éº„ÇøÁîüÊàêÔºàÊÑèÂõ≥ÁöÑ„Å´„Éé„Ç§„Ç∫„ÇíÂê´„ÇÄÔºâ
X_data = np.random.randn(300, 5)
# Ê≠£„Åó„ÅÑÈñ¢‰øÇ: y = 2*X0 + 3*X1
y_true = 2*X_data[:, 0] + 3*X_data[:, 1] + np.random.normal(0, 0.3, 300)

# ‰∏ÄÈÉ®„ÅÆ„Çµ„É≥„Éó„É´„Å´„Éé„Ç§„Ç∫Ê∑∑ÂÖ•ÔºàÊ∏¨ÂÆö„Ç®„É©„Éº„Ç∑„Éü„É•„É¨„Éº„Ç∑„Éß„É≥Ôºâ
noise_idx = np.random.choice(300, 30, replace=False)
y_data = y_true.copy()
y_data[noise_idx] += np.random.normal(0, 5, 30)

# Ë®ìÁ∑¥
X_train, X_test, y_train, y_test = train_test_split(
    X_data, y_data, test_size=0.2, random_state=42
)

model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# ‰∫àÊ∏¨
y_pred = model.predict(X_test)
mae = mean_absolute_error(y_test, y_pred)

# Ë™§Â∑Æ„ÅåÂ§ß„Åç„ÅÑ„Çµ„É≥„Éó„É´„ÇíÁâπÂÆö
errors = np.abs(y_test - y_pred)
high_error_idx = np.where(errors &gt; np.percentile(errors, 90))[0]

print(f&quot;„É¢„Éá„É´MAE: {mae:.4f}&quot;)
print(f&quot;È´òË™§Â∑Æ„Çµ„É≥„Éó„É´Êï∞: {len(high_error_idx)}&quot;)
print(&quot;\n‚Üí XAI„ÅßÈ´òË™§Â∑Æ„Çµ„É≥„Éó„É´„ÅÆÂéüÂõ†„ÇíÂàÜÊûê&quot;)
print(&quot;  - „Éá„Éº„ÇøÂìÅË≥™ÂïèÈ°å„ÅÆÁô∫Ë¶ã&quot;)
print(&quot;  - „É¢„Éá„É´„ÅÆÂº±ÁÇπÁâπÂÆö&quot;)
print(&quot;  - Áâ©ÁêÜÁöÑÂ¶•ÂΩìÊÄß„ÅÆÊ§úË®º&quot;)
</code></pre>
<hr />
<h2>4.2 SHAP (SHapley Additive exPlanations)</h2>
<p>ShapleyÂÄ§„Å´Âü∫„Å•„ÅèÂçîÂäõ„Ç≤„Éº„É†ÁêÜË´ñ„Åã„Çâ„ÅÆËß£ÈáàÊâãÊ≥ï„Åß„Åô„ÄÇ</p>
<h3>ShapleyÂÄ§„ÅÆÁêÜË´ñ</h3>
<pre><code class="language-python">import shap

# SHAPÂü∫Êú¨Ê¶ÇÂøµ„ÅÆÂèØË¶ñÂåñ
shap.initjs()

# „É¢„Éá„É´Ë®ìÁ∑¥
model_shap = RandomForestRegressor(n_estimators=100, random_state=42)
model_shap.fit(X_train, y_train)

# SHAP Explainer
explainer = shap.TreeExplainer(model_shap)
shap_values = explainer.shap_values(X_test)

print(&quot;SHAPÂÄ§„ÅÆÊÑèÂë≥Ôºö&quot;)
print(&quot;- ÂêÑÁâπÂæ¥Èáè„Åå‰∫àÊ∏¨ÂÄ§„Å´„Å©„Çå„Å†„ÅëÂØÑ‰∏é„Åó„Åü„Åã&quot;)
print(&quot;- ShapleyÂÄ§: ÂçîÂäõ„Ç≤„Éº„É†ÁêÜË´ñ„ÅÆÂÖ¨Âπ≥„Å™ÂàÜÈÖç&quot;)
print(&quot;- Âü∫Ê∫ñÂÄ§Ôºàbase valueÔºâ„Åã„Çâ„ÅÆÂÅèÂ∑Æ„Å®„Åó„Å¶Ë°®Áèæ&quot;)
print(f&quot;\nSHAPÂÄ§„ÅÆÂΩ¢Áä∂: {shap_values.shape}&quot;)
print(f&quot;  „Çµ„É≥„Éó„É´Êï∞: {shap_values.shape[0]}&quot;)
print(f&quot;  ÁâπÂæ¥ÈáèÊï∞: {shap_values.shape[1]}&quot;)

# Âçò‰∏Ä„Çµ„É≥„Éó„É´„ÅÆË™¨Êòé
sample_idx = 0
base_value = explainer.expected_value
prediction = model_shap.predict(X_test[sample_idx:sample_idx+1])[0]

print(f&quot;\n„Çµ„É≥„Éó„É´ {sample_idx} „ÅÆ‰∫àÊ∏¨:&quot;)
print(f&quot;Âü∫Ê∫ñÂÄ§: {base_value:.4f}&quot;)
print(f&quot;SHAPÂÄ§ÂêàË®à: {shap_values[sample_idx].sum():.4f}&quot;)
print(f&quot;‰∫àÊ∏¨ÂÄ§: {prediction:.4f}&quot;)
print(f&quot;Ê§úË®º: {base_value + shap_values[sample_idx].sum():.4f} ‚âà {prediction:.4f}&quot;)
</code></pre>
<h3>SHAPÂÄ§„ÅÆË®àÁÆóÔºàTree SHAP, Kernel SHAPÔºâ</h3>
<pre><code class="language-python"># Tree SHAPÔºàÈ´òÈÄü„ÄÅÊú®„Éô„Éº„Çπ„É¢„Éá„É´Â∞ÇÁî®Ôºâ
explainer_tree = shap.TreeExplainer(model_shap)
shap_values_tree = explainer_tree.shap_values(X_test)

# Kernel SHAPÔºà„É¢„Éá„É´Èùû‰æùÂ≠ò„ÄÅÈÅÖ„ÅÑÔºâ
# Â∞è„Çµ„É≥„Éó„É´„Åß„Éá„É¢
X_test_small = X_test[:10]
explainer_kernel = shap.KernelExplainer(
    model_shap.predict,
    shap.sample(X_train, 50)
)
shap_values_kernel = explainer_kernel.shap_values(X_test_small)

print(&quot;SHAPË®àÁÆóÊâãÊ≥ï„ÅÆÊØîËºÉÔºö&quot;)
print(&quot;\nTree SHAP:&quot;)
print(f&quot;  ÂØæË±°„É¢„Éá„É´: Tree-based (RF, XGBoost, LightGBM)&quot;)
print(f&quot;  Ë®àÁÆóÈÄüÂ∫¶: È´òÈÄü&quot;)
print(f&quot;  Á≤æÂ∫¶: Âé≥ÂØÜËß£&quot;)

print(&quot;\nKernel SHAP:&quot;)
print(f&quot;  ÂØæË±°„É¢„Éá„É´: ‰ªªÊÑèÔºà„Éã„É•„Éº„É©„É´„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ„ÇÇÂèØÔºâ&quot;)
print(f&quot;  Ë®àÁÆóÈÄüÂ∫¶: ÈÅÖ„ÅÑ&quot;)
print(f&quot;  Á≤æÂ∫¶: Ëøë‰ººËß£Ôºà„Çµ„É≥„Éó„É™„É≥„Ç∞„Éô„Éº„ÇπÔºâ&quot;)

# Ë®àÁÆóÊôÇÈñìÊØîËºÉÔºàÁ∞°ÊòìÔºâ
import time

start = time.time()
_ = explainer_tree.shap_values(X_test)
tree_time = time.time() - start

print(f&quot;\nTree SHAPË®àÁÆóÊôÇÈñì: {tree_time:.3f}Áßí ({len(X_test)}„Çµ„É≥„Éó„É´)&quot;)
</code></pre>
<h3>Global vs LocalËß£Èáà</h3>
<pre><code class="language-python"># GlobalËß£Èáà: ÂÖ®„Çµ„É≥„Éó„É´„Åß„ÅÆÂπ≥ÂùáÁöÑÈáçË¶ÅÂ∫¶
mean_abs_shap = np.abs(shap_values).mean(axis=0)

fig, axes = plt.subplots(1, 2, figsize=(14, 6))

# GlobalËß£Èáà
axes[0].bar(range(len(mean_abs_shap)), mean_abs_shap,
            color='steelblue', alpha=0.7)
axes[0].set_xlabel('ÁâπÂæ¥Èáè„Ç§„É≥„Éá„ÉÉ„ÇØ„Çπ', fontsize=11)
axes[0].set_ylabel('Âπ≥Âùá|SHAPÂÄ§|', fontsize=11)
axes[0].set_title('GlobalËß£ÈáàÔºàÂÖ®‰ΩìÁöÑÈáçË¶ÅÂ∫¶Ôºâ',
                  fontsize=12, fontweight='bold')
axes[0].grid(alpha=0.3)

# LocalËß£Èáà: ÁâπÂÆö„Çµ„É≥„Éó„É´
sample_idx = 0
axes[1].bar(range(len(shap_values[sample_idx])),
            shap_values[sample_idx],
            color='coral', alpha=0.7)
axes[1].axhline(y=0, color='black', linestyle='-', linewidth=1)
axes[1].set_xlabel('ÁâπÂæ¥Èáè„Ç§„É≥„Éá„ÉÉ„ÇØ„Çπ', fontsize=11)
axes[1].set_ylabel('SHAPÂÄ§', fontsize=11)
axes[1].set_title(f'LocalËß£ÈáàÔºà„Çµ„É≥„Éó„É´{sample_idx}„ÅÆË™¨ÊòéÔºâ',
                  fontsize=12, fontweight='bold')
axes[1].grid(alpha=0.3)

plt.tight_layout()
plt.show()

print(&quot;GlobalËß£Èáà vs LocalËß£ÈáàÔºö&quot;)
print(&quot;\nGlobal:&quot;)
print(&quot;  - ÂÖ®„Çµ„É≥„Éó„É´„Åß„ÅÆÂπ≥ÂùáÁöÑ„Å™ÁâπÂæ¥ÈáèÈáçË¶ÅÂ∫¶&quot;)
print(&quot;  - „É¢„Éá„É´ÂÖ®‰Ωì„ÅÆÊåôÂãïÁêÜËß£&quot;)
print(&quot;  - Êñ∞ÊùêÊñôË®≠Ë®à„ÅÆ‰∏ÄËà¨ÁöÑ„Ç¨„Ç§„Éâ„É©„Ç§„É≥&quot;)

print(&quot;\nLocal:&quot;)
print(&quot;  - ÂÄã„ÄÖ„ÅÆ‰∫àÊ∏¨„ÅÆÊ†πÊã†Ë™¨Êòé&quot;)
print(&quot;  - Áï∞Â∏∏„Çµ„É≥„Éó„É´„ÅÆÂéüÂõ†ÁâπÂÆö&quot;)
print(&quot;  - ÁâπÂÆöÊùêÊñô„ÅÆÊúÄÈÅ©ÂåñÊñπÂêë&quot;)
</code></pre>
<h3>Summary plot, Dependence plot</h3>
<pre><code class="language-python"># Summary plotÔºàÂÖ®‰ΩìÂÉèÔºâ
plt.figure(figsize=(10, 8))
shap.summary_plot(shap_values, X_test, plot_type=&quot;dot&quot;, show=False)
plt.title('SHAP Summary Plot', fontsize=13, fontweight='bold', pad=20)
plt.tight_layout()
plt.show()

print(&quot;Summary Plot„ÅÆË™≠„ÅøÊñπÔºö&quot;)
print(&quot;- Á∏¶Ëª∏: ÁâπÂæ¥ÈáèÔºàÈáçË¶ÅÂ∫¶È†ÜÔºâ&quot;)
print(&quot;- Ê®™Ëª∏: SHAPÂÄ§Ôºà‰∫àÊ∏¨„Å∏„ÅÆÂΩ±ÈüøÔºâ&quot;)
print(&quot;- Ëâ≤: ÁâπÂæ¥Èáè„ÅÆÂÄ§ÔºàËµ§=È´ò„ÄÅÈùí=‰ΩéÔºâ&quot;)
print(&quot;- ÂàÜÂ∏É: ÂêÑÁâπÂæ¥Èáè„ÅÆÂΩ±Èüø„ÅÆÂ§öÊßòÊÄß&quot;)

# Dependence plotÔºàÂÄãÂà•ÁâπÂæ¥Èáè„ÅÆË©≥Á¥∞Ôºâ
feature_idx = 0

plt.figure(figsize=(10, 6))
shap.dependence_plot(
    feature_idx,
    shap_values,
    X_test,
    show=False
)
plt.title(f'SHAP Dependence Plot (ÁâπÂæ¥Èáè {feature_idx})',
          fontsize=13, fontweight='bold')
plt.tight_layout()
plt.show()

print(&quot;\nDependence Plot„ÅÆË™≠„ÅøÊñπÔºö&quot;)
print(&quot;- Ê®™Ëª∏: ÁâπÂæ¥Èáè„ÅÆÂÄ§&quot;)
print(&quot;- Á∏¶Ëª∏: SHAPÂÄ§Ôºà‰∫àÊ∏¨„Å∏„ÅÆÂΩ±ÈüøÔºâ&quot;)
print(&quot;- Ëâ≤: Áõ∏‰∫í‰ΩúÁî®„Åô„Çã‰ªñ„ÅÆÁâπÂæ¥Èáè&quot;)
print(&quot;- ÂÇæÂêë: ÈùûÁ∑öÂΩ¢Èñ¢‰øÇ„ÅÆÂèØË¶ñÂåñ&quot;)
</code></pre>
<hr />
<h2>4.3 LIME (Local Interpretable Model-agnostic Explanations)</h2>
<p>Â±ÄÊâÄÁöÑ„Å™Á∑öÂΩ¢Ëøë‰ºº„Å´„Çà„ÇãË™¨ÊòéÁîüÊàêÊâãÊ≥ï„Åß„Åô„ÄÇ</p>
<h3>Â±ÄÊâÄÁ∑öÂΩ¢Ëøë‰ºº</h3>
<pre><code class="language-python">from lime import lime_tabular

# LIME Explainer
lime_explainer = lime_tabular.LimeTabularExplainer(
    X_train,
    mode='regression',
    feature_names=[f'Feature_{i}' for i in range(X_train.shape[1])],
    verbose=False
)

# Âçò‰∏Ä„Çµ„É≥„Éó„É´„ÅÆË™¨Êòé
sample_idx = 0
explanation = lime_explainer.explain_instance(
    X_test[sample_idx],
    model_shap.predict,
    num_features=5
)

# ÂèØË¶ñÂåñ
fig = explanation.as_pyplot_figure()
plt.title(f'LIME Explanation („Çµ„É≥„Éó„É´ {sample_idx})',
          fontsize=13, fontweight='bold')
plt.tight_layout()
plt.show()

print(&quot;LIME„ÅÆ‰ªïÁµÑ„ÅøÔºö&quot;)
print(&quot;1. ÂØæË±°„Çµ„É≥„Éó„É´Âë®Ëæ∫„Åß„É©„É≥„ÉÄ„É†„Çµ„É≥„Éó„É™„É≥„Ç∞&quot;)
print(&quot;2. „Éñ„É©„ÉÉ„ÇØ„Éú„ÉÉ„ÇØ„Çπ„É¢„Éá„É´„Åß‰∫àÊ∏¨&quot;)
print(&quot;3. Ë∑ùÈõ¢„Å´Âü∫„Å•„ÅèÈáç„Åø‰ªò„Åë&quot;)
print(&quot;4. Â±ÄÊâÄÁöÑ„Å™Á∑öÂΩ¢„É¢„Éá„É´„ÇíÂ≠¶Áøí&quot;)
print(&quot;5. Á∑öÂΩ¢‰øÇÊï∞„ÅßË™¨Êòé&quot;)

# Ë™¨Êòé„ÅÆÊï∞ÂÄ§Ë°®Á§∫
print(&quot;\nË™¨ÊòéÔºàÈáçË¶ÅÂ∫¶È†ÜÔºâ:&quot;)
for feature, weight in explanation.as_list():
    print(f&quot;  {feature}: {weight:.4f}&quot;)
</code></pre>
<h3>Tabular LIME</h3>
<pre><code class="language-python"># Ë§áÊï∞„Çµ„É≥„Éó„É´„ÅßLIMEÂÆüË°å
n_samples_lime = 5
lime_results = []

for i in range(n_samples_lime):
    exp = lime_explainer.explain_instance(
        X_test[i],
        model_shap.predict,
        num_features=X_train.shape[1]
    )

    # Ë™¨Êòé„ÇíËæûÊõ∏„Å´Â§âÊèõ
    exp_dict = dict(exp.as_list())
    lime_results.append(exp_dict)

# „Éá„Éº„Çø„Éï„É¨„Éº„É†Âåñ
lime_df = pd.DataFrame(lime_results)

print(f&quot;\n{n_samples_lime}„Çµ„É≥„Éó„É´„ÅÆLIMEË™¨Êòé:&quot;)
print(lime_df.head())

# ‰∏ÄË≤´ÊÄß„ÅÆË©ï‰æ°ÔºàÂêå„ÅòÁâπÂæ¥Èáè„ÅåÂ∏∏„Å´ÈáçË¶Å„ÅãÔºâ
feature_importance_consistency = lime_df.abs().mean()
print(&quot;\nÁâπÂæ¥Èáè„ÅÆÂπ≥ÂùáÁöÑÈáçË¶ÅÂ∫¶ÔºàLIMEÔºâ:&quot;)
print(feature_importance_consistency.sort_values(ascending=False))
</code></pre>
<h3>‰∫àÊ∏¨„ÅÆË™¨ÊòéÁîüÊàê</h3>
<pre><code class="language-python"># SHAP vs LIMEÊØîËºÉ
def compare_shap_lime(sample_idx):
    &quot;&quot;&quot;
    Âêå‰∏Ä„Çµ„É≥„Éó„É´„ÅÆSHAP vs LIMEË™¨ÊòéÊØîËºÉ
    &quot;&quot;&quot;
    # SHAP
    shap_exp = shap_values[sample_idx]

    # LIME
    lime_exp = lime_explainer.explain_instance(
        X_test[sample_idx],
        model_shap.predict,
        num_features=X_train.shape[1]
    )
    lime_dict = dict(lime_exp.as_list())

    # LIMEË™¨Êòé„ÇíSHAP„Å®Âêå„ÅòÈ†ÜÂ∫è„Å´Êï¥Âàó
    lime_exp_ordered = []
    for i in range(len(shap_exp)):
        feature_name = f'Feature_{i}'
        # LIME„ÅÆË™¨Êòé„Åã„ÇâË©≤ÂΩìÁâπÂæ¥Èáè„ÇíÊé¢„Åô
        for key, value in lime_dict.items():
            if feature_name in key:
                lime_exp_ordered.append(value)
                break
        else:
            lime_exp_ordered.append(0)

    return shap_exp, np.array(lime_exp_ordered)

# ÊØîËºÉ
sample_idx = 0
shap_exp, lime_exp = compare_shap_lime(sample_idx)

# ÂèØË¶ñÂåñ
fig, ax = plt.subplots(figsize=(12, 6))

x_pos = np.arange(len(shap_exp))
width = 0.35

ax.bar(x_pos - width/2, shap_exp, width,
       label='SHAP', color='steelblue', alpha=0.7)
ax.bar(x_pos + width/2, lime_exp, width,
       label='LIME', color='coral', alpha=0.7)

ax.set_xlabel('ÁâπÂæ¥Èáè„Ç§„É≥„Éá„ÉÉ„ÇØ„Çπ', fontsize=12)
ax.set_ylabel('ÈáçË¶ÅÂ∫¶', fontsize=12)
ax.set_title(f'SHAP vs LIME („Çµ„É≥„Éó„É´ {sample_idx})',
             fontsize=13, fontweight='bold')
ax.set_xticks(x_pos)
ax.legend()
ax.grid(alpha=0.3)
ax.axhline(y=0, color='black', linestyle='-', linewidth=1)

plt.tight_layout()
plt.show()

# Áõ∏Èñ¢ÂàÜÊûê
correlation = np.corrcoef(shap_exp, lime_exp)[0, 1]
print(f&quot;\nSHAP-LIMEÁõ∏Èñ¢: {correlation:.4f}&quot;)
print(&quot;È´òÁõ∏Èñ¢ ‚Üí ‰∏°ÊâãÊ≥ï„Åß‰∏ÄË≤´„Åó„ÅüË™¨Êòé&quot;)
</code></pre>
<hr />
<h2>4.4 AttentionÂèØË¶ñÂåñÔºàNN/GNNÁî®Ôºâ</h2>
<p>„Éã„É•„Éº„É©„É´„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ„ÅÆAttentionÊ©üÊßã„ÇíÂèØË¶ñÂåñ„Åó„Åæ„Åô„ÄÇ</p>
<h3>Attention weights„ÅÆÂèØË¶ñÂåñ</h3>
<pre><code class="language-python"># Á∞°ÊòìÁöÑ„Å™Attention„É°„Ç´„Éã„Ç∫„É†„ÅÆ„Éá„É¢
from sklearn.neural_network import MLPRegressor

# „Éã„É•„Éº„É©„É´„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØË®ìÁ∑¥
nn_model = MLPRegressor(
    hidden_layer_sizes=(50, 50),
    max_iter=1000,
    random_state=42
)
nn_model.fit(X_train, y_train)

# ‰∏≠ÈñìÂ±§„ÅÆÊ¥ªÊÄßÂåñ„ÇíÂèñÂæóÔºàÁ∞°ÊòìÁâàÔºâ
def get_activation(model, X, layer_idx=0):
    &quot;&quot;&quot;
    ÊåáÂÆöÂ±§„ÅÆÊ¥ªÊÄßÂåñ„ÇíÂèñÂæó
    &quot;&quot;&quot;
    # Èáç„Åø„Å®„Éê„Ç§„Ç¢„Çπ
    W = model.coefs_[layer_idx]
    b = model.intercepts_[layer_idx]

    # Ê¥ªÊÄßÂåñÔºàReLUÔºâ
    activation = np.maximum(0, X @ W + b)

    return activation

# Á¨¨1Â±§„ÅÆÊ¥ªÊÄßÂåñ
activation_layer1 = get_activation(nn_model, X_test, layer_idx=0)

# Attention-like weightsÔºàÊ¥ªÊÄßÂåñ„ÅÆÂ§ß„Åç„Åï„ÇíÈáç„Åø„Å®Ë¶ãÂÅö„ÅôÔºâ
attention_weights = np.abs(activation_layer1).mean(axis=1)

# ÂèØË¶ñÂåñ
plt.figure(figsize=(12, 6))
plt.scatter(range(len(attention_weights)), attention_weights,
            c=y_test, cmap='viridis', s=100, alpha=0.6)
plt.colorbar(label='Target Value')
plt.xlabel('„Çµ„É≥„Éó„É´„Ç§„É≥„Éá„ÉÉ„ÇØ„Çπ', fontsize=12)
plt.ylabel('Attention Weight (Ê¥ªÊÄßÂåñÂº∑Â∫¶)', fontsize=12)
plt.title('Attention-like WeightsÔºàÁ¨¨1Â±§Ê¥ªÊÄßÂåñÔºâ',
          fontsize=13, fontweight='bold')
plt.grid(alpha=0.3)
plt.tight_layout()
plt.show()

print(&quot;AttentionÂèØË¶ñÂåñ„ÅÆÊÑèÁæ©Ôºö&quot;)
print(&quot;- „É¢„Éá„É´„Åå„Å©„ÅÆÂÖ•Âäõ„Å´Ê≥®ÁõÆ„Åó„Å¶„ÅÑ„Çã„Åã&quot;)
print(&quot;- ÈáçË¶Å„Å™„Çµ„É≥„Éó„É´„ÇÑÁâπÂæ¥„ÅÆÁâπÂÆö&quot;)
print(&quot;- „Éã„É•„Éº„É©„É´„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ„ÅÆÂÜÖÈÉ®Âãï‰ΩúÁêÜËß£&quot;)
</code></pre>
<h3>Grad-CAM for materials</h3>
<pre><code class="language-python"># Grad-CAMÈ¢®„ÅÆÂãæÈÖç„Éô„Éº„ÇπÈáçË¶ÅÂ∫¶ÔºàÁ∞°ÊòìÁâàÔºâ
def gradient_based_importance(model, X_sample):
    &quot;&quot;&quot;
    ÂãæÈÖç„Éô„Éº„Çπ„ÅÆÁâπÂæ¥ÈáèÈáçË¶ÅÂ∫¶
    &quot;&quot;&quot;
    # Êï∞ÂÄ§ÂæÆÂàÜ„ÅßËøë‰ºº
    epsilon = 1e-5
    base_pred = model.predict(X_sample.reshape(1, -1))[0]

    importances = []
    for i in range(len(X_sample)):
        X_perturbed = X_sample.copy()
        X_perturbed[i] += epsilon

        perturbed_pred = model.predict(X_perturbed.reshape(1, -1))[0]

        # ÂãæÈÖçËøë‰ºº
        gradient = (perturbed_pred - base_pred) / epsilon
        importances.append(gradient)

    return np.array(importances)

# „Çµ„É≥„Éó„É´„ÅßÂÆüË°å
sample_idx = 0
grad_importances = gradient_based_importance(nn_model, X_test[sample_idx])

# SHAP, LIME, Gradient„ÅÆÊØîËºÉ
fig, axes = plt.subplots(1, 3, figsize=(18, 5))

# SHAP
axes[0].bar(range(len(shap_exp)), shap_exp,
            color='steelblue', alpha=0.7)
axes[0].axhline(y=0, color='black', linestyle='-', linewidth=1)
axes[0].set_xlabel('ÁâπÂæ¥Èáè', fontsize=11)
axes[0].set_ylabel('ÈáçË¶ÅÂ∫¶', fontsize=11)
axes[0].set_title('SHAP', fontsize=12, fontweight='bold')
axes[0].grid(alpha=0.3)

# LIME
axes[1].bar(range(len(lime_exp)), lime_exp,
            color='coral', alpha=0.7)
axes[1].axhline(y=0, color='black', linestyle='-', linewidth=1)
axes[1].set_xlabel('ÁâπÂæ¥Èáè', fontsize=11)
axes[1].set_ylabel('ÈáçË¶ÅÂ∫¶', fontsize=11)
axes[1].set_title('LIME', fontsize=12, fontweight='bold')
axes[1].grid(alpha=0.3)

# Gradient
axes[2].bar(range(len(grad_importances)), grad_importances,
            color='green', alpha=0.7)
axes[2].axhline(y=0, color='black', linestyle='-', linewidth=1)
axes[2].set_xlabel('ÁâπÂæ¥Èáè', fontsize=11)
axes[2].set_ylabel('ÂãæÈÖç', fontsize=11)
axes[2].set_title('Gradient-based', fontsize=12, fontweight='bold')
axes[2].grid(alpha=0.3)

plt.tight_layout()
plt.show()

print(&quot;3ÊâãÊ≥ï„ÅÆÁâπÂæ¥Ôºö&quot;)
print(&quot;SHAP: „Ç≤„Éº„É†ÁêÜË´ñÁöÑÂÖ¨Âπ≥ÊÄß„ÄÅÂÖ®„É¢„Éá„É´ÂØæÂøú&quot;)
print(&quot;LIME: Â±ÄÊâÄÁ∑öÂΩ¢Ëøë‰ºº„ÄÅÁõ¥ÊÑüÁöÑ&quot;)
print(&quot;Gradient: ÂãæÈÖçÊÉÖÂ†±„ÄÅ„Éã„É•„Éº„É©„É´„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØÁâπÂåñ&quot;)
</code></pre>
<h3>„Å©„ÅÆÂéüÂ≠ê/ÁµêÂêà„ÅåÈáçË¶Å„Åã</h3>
<pre><code class="language-python"># ÊùêÊñôÁßëÂ≠¶„Åß„ÅÆÂøúÁî®‰æãÔºöÁµÑÊàê„ÅÆÈáçË¶ÅÂ∫¶
composition_features = ['Li', 'Co', 'Ni', 'Mn', 'O']

# „Ç∑„Éü„É•„É¨„Éº„Ç∑„Éß„É≥„Éá„Éº„Çø
X_composition = pd.DataFrame({
    'Li': np.random.uniform(0.9, 1.1, 100),
    'Co': np.random.uniform(0, 0.6, 100),
    'Ni': np.random.uniform(0, 0.8, 100),
    'Mn': np.random.uniform(0, 0.4, 100),
    'O': np.random.uniform(1.9, 2.1, 100)
})

# ÂÆπÈáèÔºàNi„ÅåÈáçË¶ÅÔºâ
y_capacity = (
    150 * X_composition['Ni'] +
    120 * X_composition['Co'] +
    80 * X_composition['Mn'] +
    np.random.normal(0, 5, 100)
)

# „É¢„Éá„É´Ë®ìÁ∑¥
model_comp = RandomForestRegressor(n_estimators=100, random_state=42)
model_comp.fit(X_composition, y_capacity)

# SHAPËß£Êûê
explainer_comp = shap.TreeExplainer(model_comp)
shap_values_comp = explainer_comp.shap_values(X_composition)

# ÂÖÉÁ¥†Âà•ÈáçË¶ÅÂ∫¶
mean_abs_shap_comp = np.abs(shap_values_comp).mean(axis=0)

# ÂèØË¶ñÂåñ
plt.figure(figsize=(10, 6))
plt.bar(composition_features, mean_abs_shap_comp,
        color=['#FFD700', '#4169E1', '#32CD32', '#FF69B4', '#FF6347'],
        alpha=0.7, edgecolor='black', linewidth=1.5)
plt.xlabel('ÂÖÉÁ¥†', fontsize=12)
plt.ylabel('Âπ≥Âùá|SHAPÂÄ§|', fontsize=12)
plt.title('ÈõªÊ±†ÂÆπÈáè„Å∏„ÅÆÂÖÉÁ¥†ÂØÑ‰∏éÂ∫¶ÔºàSHAPËß£ÊûêÔºâ',
          fontsize=13, fontweight='bold')
plt.grid(axis='y', alpha=0.3)
plt.tight_layout()
plt.show()

print(&quot;ÂÖÉÁ¥†Âà•ÈáçË¶ÅÂ∫¶:&quot;)
for elem, importance in zip(composition_features, mean_abs_shap_comp):
    print(f&quot;  {elem}: {importance:.2f}&quot;)

print(&quot;\nÊùêÊñôË®≠Ë®à„Å∏„ÅÆÁ§∫ÂîÜ:&quot;)
print(&quot;‚Üí NiÂê´ÊúâÈáè„ÇíÂ¢ó„ÇÑ„Åô„Åì„Å®„ÅßÂÆπÈáèÂêë‰∏ä„ÅåÊúüÂæÖ„Åß„Åç„Çã&quot;)
</code></pre>
<hr />
<h2>4.5 ÂÆü‰∏ñÁïåÂøúÁî®„Å®„Ç≠„É£„É™„Ç¢„Éë„Çπ</h2>
<p>XAI„ÅÆÁî£Ê•≠ÂøúÁî®‰∫ã‰æã„Å®„ÄÅÊùêÊñô„Éá„Éº„Çø„Çµ„Ç§„Ç®„É≥„ÉÜ„Ç£„Çπ„Éà„ÅÆ„Ç≠„É£„É™„Ç¢ÊÉÖÂ†±„ÇíÁ¥π‰ªã„Åó„Åæ„Åô„ÄÇ</p>
<h3>„Éà„É®„ÇøÔºöÊùêÊñôÈñãÁô∫„Å´„Åä„Åë„ÇãXAIÊ¥ªÁî®</h3>
<pre><code class="language-python"># „Éà„É®„Çø„ÅÆ‰∫ã‰æãÔºà„Ç∑„Éü„É•„É¨„Éº„Ç∑„Éß„É≥Ôºâ
print(&quot;=== „Éà„É®„ÇøËá™ÂãïËªä ÊùêÊñôÈñãÁô∫‰∫ã‰æã ===&quot;)
print(&quot;\nË™≤È°å:&quot;)
print(&quot;  - ÈõªÊ±†ÊùêÊñô„ÅÆÂä£Âåñ„É°„Ç´„Éã„Ç∫„É†Ëß£Êòé&quot;)
print(&quot;  - Êï∞ÂçÉ„ÅÆÂÄôË£úÊùêÊñô„Åã„ÇâÊúÄÈÅ©ÊùêÊñôÈÅ∏ÂÆö&quot;)

print(&quot;\nXAIÈÅ©Áî®:&quot;)
print(&quot;  - SHAPËß£Êûê„ÅßÂä£Âåñ„Å´ÂØÑ‰∏é„Åô„ÇãÂõ†Â≠ê„ÇíÁâπÂÆö&quot;)
print(&quot;  - Ê∏©Â∫¶„ÄÅÈõªÂúß„ÄÅ„Çµ„Ç§„ÇØ„É´Êï∞„ÅÆÁõ∏‰∫í‰ΩúÁî®„ÇíÂèØË¶ñÂåñ&quot;)
print(&quot;  - Áâ©ÁêÜ„É¢„Éá„É´„Å®„ÅÆÊï¥ÂêàÊÄßÊ§úË®º&quot;)

print(&quot;\nÊàêÊûú:&quot;)
print(&quot;  - ÈñãÁô∫ÊúüÈñì 40% Áü≠Á∏Æ&quot;)
print(&quot;  - ÈõªÊ±†ÂØøÂëΩ 20% Âêë‰∏ä&quot;)
print(&quot;  - Á†îÁ©∂ËÄÖ„ÅÆÁâ©ÁêÜÁöÑÊ¥ûÂØüÁç≤Âæó&quot;)

# „Ç∑„Éü„É•„É¨„Éº„Ç∑„Éß„É≥: ÈõªÊ±†Âä£Âåñ‰∫àÊ∏¨
battery_aging = pd.DataFrame({
    'Ê∏©Â∫¶': np.random.uniform(20, 60, 200),
    'ÈõªÂúß': np.random.uniform(3.0, 4.5, 200),
    '„Çµ„Ç§„ÇØ„É´Êï∞': np.random.uniform(0, 1000, 200),
    'ÂÖÖÈõª„É¨„Éº„Éà': np.random.uniform(0.5, 2.0, 200)
})

# Âä£ÂåñÁéáÔºàÊ∏©Â∫¶„Å®„Çµ„Ç§„ÇØ„É´„Åå‰∏ªË¶ÅÂõ†Ôºâ
degradation = (
    0.5 * battery_aging['Ê∏©Â∫¶'] +
    0.3 * battery_aging['„Çµ„Ç§„ÇØ„É´Êï∞'] / 100 +
    0.2 * battery_aging['ÈõªÂúß'] * battery_aging['ÂÖÖÈõª„É¨„Éº„Éà'] +
    np.random.normal(0, 2, 200)
)

# „É¢„Éá„É´
model_aging = RandomForestRegressor(n_estimators=100, random_state=42)
model_aging.fit(battery_aging, degradation)

# SHAPÂàÜÊûê
explainer_aging = shap.TreeExplainer(model_aging)
shap_values_aging = explainer_aging.shap_values(battery_aging)

# ÂèØË¶ñÂåñ
plt.figure(figsize=(10, 8))
shap.summary_plot(shap_values_aging, battery_aging, show=False)
plt.title('ÈõªÊ±†Âä£ÂåñË¶ÅÂõ†„ÅÆSHAPÂàÜÊûêÔºà„Éà„É®„Çø‰∫ã‰æãÈ¢®Ôºâ',
          fontsize=13, fontweight='bold', pad=20)
plt.tight_layout()
plt.show()
</code></pre>
<h3>IBM ResearchÔºöAIÊùêÊñôË®≠Ë®à„ÅÆËß£ÈáàÊÄß</h3>
<pre><code class="language-python">print(&quot;\n=== IBM Research ÊùêÊñôË®≠Ë®à‰∫ã‰æã ===&quot;)
print(&quot;\n„Éó„É≠„Ç∏„Çß„ÇØ„Éà: RoboRXN (Ëá™ÂãïÂåñÂ≠¶ÂÆüÈ®ì)&quot;)
print(&quot;\nÁâπÂæ¥:&quot;)
print(&quot;  - ÂèçÂøúÊù°‰ª∂ÊúÄÈÅ©Âåñ„Å´XAIÁµ±Âêà&quot;)
print(&quot;  - SHAP + Attention„ÅßÂèçÂøú„É°„Ç´„Éã„Ç∫„É†‰∫àÊ∏¨&quot;)
print(&quot;  - ÂåñÂ≠¶ËÄÖ„Å∏„ÅÆË™¨ÊòéÂèØËÉΩ„Å™ÊèêÊ°àÁîüÊàê&quot;)

print(&quot;\nÊäÄË°ì„Çπ„Çø„ÉÉ„ÇØ:&quot;)
print(&quot;  - Graph Neural Network (GNN)&quot;)
print(&quot;  - Attention mechanism&quot;)
print(&quot;  - SHAP for molecular graphs&quot;)

print(&quot;\nÊàêÊûú:&quot;)
print(&quot;  - ÂèçÂøúÂèéÁéá‰∫àÊ∏¨Á≤æÂ∫¶ 95%&quot;)
print(&quot;  - ÂåñÂ≠¶ËÄÖ„ÅÆ‰ø°È†ºÁç≤Âæó&quot;)
print(&quot;  - Êñ∞Ë¶èÂèçÂøúÁµåË∑Ø„ÅÆÁô∫Ë¶ã&quot;)

# ÂàÜÂ≠ê„Ç∞„É©„Éï„ÅÆÈáçË¶ÅÂ∫¶ÂèØË¶ñÂåñÔºàÊ¶ÇÂøµÂõ≥Ôºâ
fig, ax = plt.subplots(figsize=(10, 8))

# „ÉÄ„Éü„Éº„ÅÆÂàÜÂ≠ê„Ç∞„É©„Éï
import networkx as nx

G = nx.Graph()
G.add_edges_from([
    (0, 1), (1, 2), (2, 3), (3, 4), (4, 0),
    (1, 5), (3, 6)
])

pos = nx.spring_layout(G, seed=42)

# „Éé„Éº„ÉâÈáçË¶ÅÂ∫¶ÔºàAttention weightsÈ¢®Ôºâ
node_importance = np.random.rand(len(G.nodes))
node_importance = node_importance / node_importance.sum()

nx.draw(
    G, pos,
    node_color=node_importance,
    node_size=1000 * node_importance / node_importance.max(),
    cmap='YlOrRd',
    with_labels=True,
    font_size=12,
    font_weight='bold',
    edge_color='gray',
    width=2,
    ax=ax
)

sm = plt.cm.ScalarMappable(
    cmap='YlOrRd',
    norm=plt.Normalize(vmin=0, vmax=node_importance.max())
)
sm.set_array([])
cbar = plt.colorbar(sm, ax=ax, label='Attention Weight')

ax.set_title('ÂàÜÂ≠ê„Ç∞„É©„Éï„ÅÆAttentionÂèØË¶ñÂåñÔºàIBMÈ¢®Ôºâ',
             fontsize=13, fontweight='bold')
plt.tight_layout()
plt.show()
</code></pre>
<h3>„Çπ„Çø„Éº„Éà„Ç¢„ÉÉ„ÉóÔºöCitrine InformaticsÔºàË™¨ÊòéÂèØËÉΩ„Å™AIÔºâ</h3>
<pre><code class="language-python">print(&quot;\n=== Citrine Informatics ‰∫ã‰æã ===&quot;)
print(&quot;\n„Éì„Ç∏„Éç„Çπ„É¢„Éá„É´:&quot;)
print(&quot;  - ÊùêÊñôÈñãÁô∫„Éó„É©„ÉÉ„Éà„Éï„Ç©„Éº„É†Êèê‰æõ&quot;)
print(&quot;  - Ë™¨ÊòéÂèØËÉΩAI„Çí‰∏≠Ê†∏ÊäÄË°ì„Å®„Åô„Çã&quot;)
print(&quot;  - Â§ßÊâãË£ΩÈÄ†Ê•≠„Å∏„ÅÆSaaSÂ±ïÈñã&quot;)

print(&quot;\nÊäÄË°ìÁöÑÁâπÂæ¥:&quot;)
print(&quot;  - „Éô„Ç§„Ç∫ÊúÄÈÅ©Âåñ + XAI&quot;)
print(&quot;  - ‰∏çÁ¢∫ÂÆüÊÄßÂÆöÈáèÂåñ&quot;)
print(&quot;  - Áâ©ÁêÜÂà∂Á¥Ñ„ÅÆÁµ±Âêà&quot;)

print(&quot;\nÈ°ßÂÆ¢‰∫ã‰æã:&quot;)
print(&quot;  - „Éë„Éä„ÇΩ„Éã„ÉÉ„ÇØ: ÈõªÊ±†ÊùêÊñôÈñãÁô∫ 50% È´òÈÄüÂåñ&quot;)
print(&quot;  - 3M: Êé•ÁùÄÂâ§ÊÄßËÉΩ 30% Âêë‰∏ä&quot;)
print(&quot;  - Michelin: „Çø„Ç§„É§„Ç¥„É†ÊúÄÈÅ©Âåñ&quot;)

print(&quot;\nÂ∑ÆÂà•ÂåñË¶ÅÂõ†:&quot;)
print(&quot;  - Ë™¨ÊòéÂèØËÉΩÊÄß„Å´„Çà„ÇãÂ∞ÇÈñÄÂÆ∂„ÅÆ‰ø°È†ºÁç≤Âæó&quot;)
print(&quot;  - Áâ©ÁêÜ„É¢„Éá„É´„Å®„ÅÆÁµ±Âêà&quot;)
print(&quot;  - Â∞è„Éá„Éº„Çø„Åß„ÇÇÈ´òÁ≤æÂ∫¶&quot;)

# Citrine„ÅÆ„Ç¢„Éó„É≠„Éº„ÉÅÔºà„Ç∑„Éü„É•„É¨„Éº„Ç∑„Éß„É≥Ôºâ
# ‰∏çÁ¢∫ÂÆüÊÄß„Å§„Åç‰∫àÊ∏¨ + SHAP

from sklearn.ensemble import GradientBoostingRegressor

# „É¢„Éá„É´ÔºàÂàÜ‰ΩçÁÇπÂõûÂ∏∞È¢®Ôºâ
model_citrine_lower = GradientBoostingRegressor(
    loss='quantile', alpha=0.1, n_estimators=100, random_state=42
)
model_citrine_median = GradientBoostingRegressor(
    n_estimators=100, random_state=42
)
model_citrine_upper = GradientBoostingRegressor(
    loss='quantile', alpha=0.9, n_estimators=100, random_state=42
)

X_citrine = X_composition
y_citrine = y_capacity

model_citrine_lower.fit(X_citrine, y_citrine)
model_citrine_median.fit(X_citrine, y_citrine)
model_citrine_upper.fit(X_citrine, y_citrine)

# ‰∫àÊ∏¨
X_new = X_citrine.iloc[:20]
y_pred_lower = model_citrine_lower.predict(X_new)
y_pred_median = model_citrine_median.predict(X_new)
y_pred_upper = model_citrine_upper.predict(X_new)

# ÂèØË¶ñÂåñ
fig, ax = plt.subplots(figsize=(12, 6))

x_axis = range(len(X_new))

ax.fill_between(x_axis, y_pred_lower, y_pred_upper,
                alpha=0.3, color='steelblue',
                label='80% ‰∫àÊ∏¨Âå∫Èñì')
ax.plot(x_axis, y_pred_median, 'o-',
        color='steelblue', linewidth=2, label='‰∫àÊ∏¨‰∏≠Â§ÆÂÄ§')

ax.set_xlabel('ÊùêÊñô„Çµ„É≥„Éó„É´', fontsize=12)
ax.set_ylabel('ÂÆπÈáè (mAh/g)', fontsize=12)
ax.set_title('CitrineÈ¢®‰∏çÁ¢∫ÂÆüÊÄß„Å§„Åç‰∫àÊ∏¨',
             fontsize=13, fontweight='bold')
ax.legend()
ax.grid(alpha=0.3)

plt.tight_layout()
plt.show()

print(&quot;\n‰∏çÁ¢∫ÂÆüÊÄß„ÅÆÂà©ÁÇπ:&quot;)
print(&quot;  - „É™„Çπ„ÇØË©ï‰æ°&quot;)
print(&quot;  - ËøΩÂä†ÂÆüÈ®ì„ÅÆÂÑ™ÂÖàÈ†Ü‰Ωç„Å•„Åë&quot;)
print(&quot;  - ÊÑèÊÄùÊ±∫ÂÆö„ÅÆ‰ø°È†ºÊÄßÂêë‰∏ä&quot;)
</code></pre>
<h3>„Ç≠„É£„É™„Ç¢„Éë„ÇπÔºöÊùêÊñô„Éá„Éº„Çø„Çµ„Ç§„Ç®„É≥„ÉÜ„Ç£„Çπ„Éà„ÄÅXAIÁ†îÁ©∂ËÄÖ</h3>
<pre><code class="language-python"># „Ç≠„É£„É™„Ç¢„Éë„ÇπÊÉÖÂ†±
career_paths = pd.DataFrame({
    '„Ç≠„É£„É™„Ç¢„Éë„Çπ': [
        'ÊùêÊñô„Éá„Éº„Çø„Çµ„Ç§„Ç®„É≥„ÉÜ„Ç£„Çπ„Éà',
        'XAIÁ†îÁ©∂ËÄÖÔºà„Ç¢„Ç´„Éá„Éü„Ç¢Ôºâ',
        'ML„Ç®„É≥„Ç∏„Éã„Ç¢ÔºàÊùêÊñôÁâπÂåñÔºâ',
        'R&amp;D ManagerÔºàAIÊ¥ªÁî®Ôºâ',
        '„ÉÜ„ÇØ„Éã„Ç´„É´„Ç≥„É≥„Çµ„É´„Çø„É≥„Éà'
    ],
    'ÂøÖË¶Å„Çπ„Ç≠„É´': [
        'ÊùêÊñôÁßëÂ≠¶+ML+Python',
        'Áµ±Ë®à+MLÁêÜË´ñ+Ë´ñÊñáÂü∑Á≠Ü',
        'MLÂÆüË£Ö+MLOps',
        'ÊùêÊñôÁßëÂ≠¶+„Éó„É≠„Ç∏„Çß„ÇØ„ÉàÁÆ°ÁêÜ',
        'ÊùêÊñôÁßëÂ≠¶+ML+„Éì„Ç∏„Éç„Çπ'
    ],
    'Âã§ÂãôÂÖà‰æã': [
        '„Éà„É®„Çø„ÄÅ„Éë„Éä„ÇΩ„Éã„ÉÉ„ÇØ„ÄÅ‰∏âËè±„Ç±„Éü„Ç´„É´',
        'Â§ßÂ≠¶„ÄÅÁî£Á∑èÁ†î„ÄÅÁêÜÁ†î',
        'Citrine, Materials Zone',
        'Â§ßÊâãË£ΩÈÄ†Ê•≠R&amp;DÈÉ®ÈñÄ',
        '„Ç¢„ÇØ„Çª„É≥„ÉÅ„É•„Ç¢„ÄÅ„Éá„É≠„Ç§„Éà'
    ]
})

print(&quot;\n=== „Ç≠„É£„É™„Ç¢„Éë„Çπ ===&quot;)
print(career_paths.to_string(index=False))
</code></pre>
<h3>Âπ¥ÂèéÔºö700-1,500‰∏áÂÜÜÔºàÊó•Êú¨Ôºâ„ÄÅ$90-180KÔºàÁ±≥ÂõΩÔºâ</h3>
<pre><code class="language-python"># Âπ¥Âèé„Éá„Éº„Çø
salary_data = pd.DataFrame({
    '„Éù„Ç∏„Ç∑„Éß„É≥': [
        '„Ç∏„É•„Éã„Ç¢Ôºà„Äú3Âπ¥Ôºâ',
        '„Éü„Éâ„É´Ôºà3-7Âπ¥Ôºâ',
        '„Ç∑„Éã„Ç¢Ôºà7-15Âπ¥Ôºâ',
        '„É™„Éº„Éâ„Çµ„Ç§„Ç®„É≥„ÉÜ„Ç£„Çπ„Éà',
        '„Éû„Éç„Éº„Ç∏„É£„Éº'
    ],
    'Êó•Êú¨_ÊúÄ‰Ωé': [500, 700, 1000, 1200, 1500],
    'Êó•Êú¨_ÊúÄÈ´ò': [700, 1000, 1500, 2000, 2500],
    'Á±≥ÂõΩ_ÊúÄ‰Ωé': [70, 90, 130, 150, 180],
    'Á±≥ÂõΩ_ÊúÄÈ´ò': [90, 130, 180, 220, 300]
})

# ÂèØË¶ñÂåñ
fig, axes = plt.subplots(1, 2, figsize=(16, 6))

# Êó•Êú¨
axes[0].barh(salary_data['„Éù„Ç∏„Ç∑„Éß„É≥'],
             salary_data['Êó•Êú¨_ÊúÄÈ´ò'] - salary_data['Êó•Êú¨_ÊúÄ‰Ωé'],
             left=salary_data['Êó•Êú¨_ÊúÄ‰Ωé'],
             color='steelblue', alpha=0.7)

for idx, row in salary_data.iterrows():
    axes[0].text(row['Êó•Êú¨_ÊúÄ‰Ωé'] - 50, idx,
                 f&quot;{row['Êó•Êú¨_ÊúÄ‰Ωé']}&quot;, va='center', ha='right', fontsize=9)
    axes[0].text(row['Êó•Êú¨_ÊúÄÈ´ò'] + 50, idx,
                 f&quot;{row['Êó•Êú¨_ÊúÄÈ´ò']}&quot;, va='center', ha='left', fontsize=9)

axes[0].set_xlabel('Âπ¥ÂèéÔºà‰∏áÂÜÜÔºâ', fontsize=12)
axes[0].set_title('Êó•Êú¨„ÅÆÂπ¥Âèé„É¨„É≥„Ç∏', fontsize=13, fontweight='bold')
axes[0].grid(axis='x', alpha=0.3)

# Á±≥ÂõΩ
axes[1].barh(salary_data['„Éù„Ç∏„Ç∑„Éß„É≥'],
             salary_data['Á±≥ÂõΩ_ÊúÄÈ´ò'] - salary_data['Á±≥ÂõΩ_ÊúÄ‰Ωé'],
             left=salary_data['Á±≥ÂõΩ_ÊúÄ‰Ωé'],
             color='coral', alpha=0.7)

for idx, row in salary_data.iterrows():
    axes[1].text(row['Á±≥ÂõΩ_ÊúÄ‰Ωé'] - 5, idx,
                 f&quot;${row['Á±≥ÂõΩ_ÊúÄ‰Ωé']}K&quot;, va='center', ha='right', fontsize=9)
    axes[1].text(row['Á±≥ÂõΩ_ÊúÄÈ´ò'] + 5, idx,
                 f&quot;${row['Á±≥ÂõΩ_ÊúÄÈ´ò']}K&quot;, va='center', ha='left', fontsize=9)

axes[1].set_xlabel('Âπ¥ÂèéÔºàÂçÉ„Éâ„É´Ôºâ', fontsize=12)
axes[1].set_title('Á±≥ÂõΩ„ÅÆÂπ¥Âèé„É¨„É≥„Ç∏', fontsize=13, fontweight='bold')
axes[1].grid(axis='x', alpha=0.3)

plt.tight_layout()
plt.show()

print(&quot;\nÂπ¥Âèé„Å´ÂΩ±Èüø„Åô„ÇãË¶ÅÂõ†:&quot;)
print(&quot;  - Â≠¶‰ΩçÔºà‰øÆÂ£´ vs ÂçöÂ£´Ôºâ&quot;)
print(&quot;  - Ê•≠ÁïåÔºàË£ΩÈÄ†Ê•≠ vs ITÔºâ&quot;)
print(&quot;  - Âú∞ÂüüÔºàÊù±‰∫¨ vs Âú∞Êñπ„ÄÅ„Ç∑„É™„Ç≥„É≥„Éê„É¨„Éº vs „Åù„ÅÆ‰ªñÔºâ&quot;)
print(&quot;  - „Çπ„Ç≠„É´„Çª„ÉÉ„ÉàÔºàÊùêÊñôÁßëÂ≠¶ + ML + „Éâ„É°„Ç§„É≥Áü•Ë≠òÔºâ&quot;)
print(&quot;  - ÂÆüÁ∏æÔºàË´ñÊñá„ÄÅÁâπË®±„ÄÅ„Éó„É≠„Ç∏„Çß„ÇØ„ÉàÊàêÂäüÔºâ&quot;)

print(&quot;\n„Çπ„Ç≠„É´„Ç¢„ÉÉ„ÉóÊà¶Áï•:&quot;)
print(&quot;  1. ÊùêÊñôÁßëÂ≠¶„ÅÆÂü∫Á§éÂõ∫„ÇÅÔºàÂ≠¶‰ΩçÂèñÂæóÔºâ&quot;)
print(&quot;  2. ML/DL„ÅÆÂÆüË∑µ„Çπ„Ç≠„É´ÔºàKaggle„ÄÅGitHubÔºâ&quot;)
print(&quot;  3. XAIÊâãÊ≥ï„ÅÆÁøíÂæóÔºàSHAP„ÄÅLIMEÔºâ&quot;)
print(&quot;  4. Ë´ñÊñáÁô∫Ë°®„ÉªOSS„Ç≥„É≥„Éà„É™„Éì„É•„Éº„Ç∑„Éß„É≥&quot;)
print(&quot;  5. „Éç„ÉÉ„Éà„ÉØ„Éº„Ç≠„É≥„Ç∞ÔºàÂ≠¶‰ºö„ÄÅÂãâÂº∑‰ºöÔºâ&quot;)
</code></pre>
<hr />
<h2>ÊºîÁøíÂïèÈ°å</h2>
<h3>ÂïèÈ°å1ÔºàÈõ£ÊòìÂ∫¶: easyÔºâ</h3>
<p>SHAP„Å®LIME„ÇíÁî®„ÅÑ„Å¶„ÄÅÂêå‰∏Ä„Çµ„É≥„Éó„É´„ÅÆË™¨Êòé„ÇíÁîüÊàê„Åó„ÄÅÁâπÂæ¥ÈáèÈáçË¶ÅÂ∫¶„ÅÆÁõ∏Èñ¢„ÇíË®àÁÆó„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇÁõ∏Èñ¢„ÅåÈ´ò„ÅÑÂ†¥Âêà„Å®‰Ωé„ÅÑÂ†¥Âêà„ÄÅ„Åù„Çå„Åû„Çå‰Ωï„ÇíÊÑèÂë≥„Åô„Çã„ÅãËÄÉÂØü„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ</p>
<details>
<summary>Ëß£Á≠î‰æã</summary>


<pre><code class="language-python">import shap
from lime import lime_tabular
from sklearn.ensemble import RandomForestRegressor
import numpy as np

# „É¢„Éá„É´Ë®ìÁ∑¥
model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# SHAP
explainer_shap = shap.TreeExplainer(model)
shap_values = explainer_shap.shap_values(X_test)

# LIME
explainer_lime = lime_tabular.LimeTabularExplainer(
    X_train, mode='regression'
)

sample_idx = 0

# LIMEË™¨Êòé
lime_exp = explainer_lime.explain_instance(
    X_test[sample_idx], model.predict, num_features=X_train.shape[1]
)
lime_dict = dict(lime_exp.as_list())

# Áõ∏Èñ¢Ë®àÁÆó
shap_importances = shap_values[sample_idx]
lime_importances = [lime_dict.get(f'Feature_{i}', 0)
                    for i in range(len(shap_importances))]

correlation = np.corrcoef(shap_importances, lime_importances)[0, 1]
print(f&quot;SHAP-LIMEÁõ∏Èñ¢: {correlation:.4f}&quot;)

if correlation &gt; 0.7:
    print(&quot;È´òÁõ∏Èñ¢: ‰∏°ÊâãÊ≥ï„Åß‰∏ÄË≤´„Åó„ÅüË™¨Êòé ‚Üí ‰ø°È†ºÊÄßÈ´ò„ÅÑ&quot;)
else:
    print(&quot;‰ΩéÁõ∏Èñ¢: Ë™¨Êòé„ÅÆ‰∏ç‰∏ÄËá¥ ‚Üí ÊÖéÈáç„Å´Ëß£Èáà„ÅåÂøÖË¶Å&quot;)
</code></pre>


</details>

<h3>ÂïèÈ°å2ÔºàÈõ£ÊòìÂ∫¶: mediumÔºâ</h3>
<p>SHAP Dependence Plot„ÇíÁî®„ÅÑ„Å¶„ÄÅ2„Å§„ÅÆÁâπÂæ¥ÈáèÈñì„ÅÆÁõ∏‰∫í‰ΩúÁî®„ÇíÂèØË¶ñÂåñ„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇÈùûÁ∑öÂΩ¢„Å™Èñ¢‰øÇ„ÇÑÁõ∏‰∫í‰ΩúÁî®„ÅåË¶ã„Çâ„Çå„Çã„ÅãÂàÜÊûê„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ</p>
<details>
<summary>Ëß£Á≠î‰æã</summary>


<pre><code class="language-python">import shap
import matplotlib.pyplot as plt

# SHAPË®àÁÆó
explainer = shap.TreeExplainer(model)
shap_values = explainer.shap_values(X_test)

# Dependence PlotÔºàÁâπÂæ¥Èáè0„Å®ÁâπÂæ¥Èáè1„ÅÆÁõ∏‰∫í‰ΩúÁî®Ôºâ
fig, axes = plt.subplots(1, 2, figsize=(16, 6))

shap.dependence_plot(0, shap_values, X_test, interaction_index=1,
                     ax=axes[0], show=False)
axes[0].set_title('Feature 0 (interaction with Feature 1)')

shap.dependence_plot(1, shap_values, X_test, interaction_index=0,
                     ax=axes[1], show=False)
axes[1].set_title('Feature 1 (interaction with Feature 0)')

plt.tight_layout()
plt.show()

print(&quot;ÂàÜÊûê„Éù„Ç§„É≥„Éà:&quot;)
print(&quot;- Ëâ≤„ÅÆÂ§âÂåñ: Áõ∏‰∫í‰ΩúÁî®„ÅÆÂº∑„Åï&quot;)
print(&quot;- ÈùûÁ∑öÂΩ¢„Éë„Çø„Éº„É≥: Ë§áÈõë„Å™Èñ¢‰øÇÊÄß&quot;)
print(&quot;- ÂÇæÂêë: Ê≠£/Ë≤†„ÅÆÂΩ±Èüø&quot;)
</code></pre>


</details>

<h3>ÂïèÈ°å3ÔºàÈõ£ÊòìÂ∫¶: hardÔºâ</h3>
<p>„Éà„É®„Çø„ÅÆÈõªÊ±†Âä£Âåñ‰∫àÊ∏¨‰∫ã‰æã„ÇíÊ®°ÂÄ£„Åó„ÄÅÊ∏©Â∫¶„ÉªÈõªÂúß„Éª„Çµ„Ç§„ÇØ„É´Êï∞„ÅÆ3Ë¶ÅÂõ†„ÅßSHAPÂàÜÊûê„ÇíË°å„ÅÑ„ÄÅ„Å©„ÅÆË¶ÅÂõ†„ÅåÊúÄ„ÇÇÂä£Âåñ„Å´ÂØÑ‰∏é„Åô„Çã„ÅãÂÆöÈáèË©ï‰æ°„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ„Åæ„Åü„ÄÅÁâ©ÁêÜÁöÑ„Å´Â¶•ÂΩì„Åã„Å©„ÅÜ„ÅãËÄÉÂØü„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ</p>
<details>
<summary>Ëß£Á≠î‰æã</summary>


<pre><code class="language-python">import pandas as pd
import numpy as np
from sklearn.ensemble import GradientBoostingRegressor
import shap

# „Éá„Éº„ÇøÁîüÊàê
battery_data = pd.DataFrame({
    'Ê∏©Â∫¶': np.random.uniform(20, 60, 300),
    'ÈõªÂúß': np.random.uniform(3.0, 4.5, 300),
    '„Çµ„Ç§„ÇØ„É´Êï∞': np.random.uniform(0, 1000, 300)
})

# Âä£ÂåñÁéáÔºàÁâ©ÁêÜÁöÑ„Å´Â¶•ÂΩì„Å™„É¢„Éá„É´Ôºâ
# È´òÊ∏©„ÄÅÈ´òÈõªÂúß„ÄÅÂ§ö„Çµ„Ç§„ÇØ„É´„ÅßÂä£ÂåñÂä†ÈÄü
degradation = (
    0.8 * (battery_data['Ê∏©Â∫¶'] - 20) +  # È´òÊ∏©„ÅßÂä£Âåñ
    2.0 * (battery_data['ÈõªÂúß'] - 3.0)**2 +  # È´òÈõªÂúß„ÅßÂä£Âåñ
    0.05 * battery_data['„Çµ„Ç§„ÇØ„É´Êï∞'] +  # „Çµ„Ç§„ÇØ„É´Âä£Âåñ
    0.01 * battery_data['Ê∏©Â∫¶'] * battery_data['„Çµ„Ç§„ÇØ„É´Êï∞'] / 100 +  # Áõ∏‰∫í‰ΩúÁî®
    np.random.normal(0, 3, 300)
)

# „É¢„Éá„É´Ë®ìÁ∑¥
model = GradientBoostingRegressor(n_estimators=100, random_state=42)
model.fit(battery_data, degradation)

# SHAPÂàÜÊûê
explainer = shap.TreeExplainer(model)
shap_values = explainer.shap_values(battery_data)

# ÈáçË¶ÅÂ∫¶ÈõÜË®à
mean_abs_shap = np.abs(shap_values).mean(axis=0)
feature_names = battery_data.columns

print(&quot;Âä£ÂåñË¶ÅÂõ†„ÅÆÈáçË¶ÅÂ∫¶ÔºàSHAPÔºâ:&quot;)
for name, importance in zip(feature_names, mean_abs_shap):
    print(f&quot;  {name}: {importance:.2f}&quot;)

# Summary Plot
shap.summary_plot(shap_values, battery_data, show=False)
plt.title('ÈõªÊ±†Âä£ÂåñË¶ÅÂõ†„ÅÆSHAPÂàÜÊûê', fontsize=13, fontweight='bold')
plt.tight_layout()
plt.show()

print(&quot;\nÁâ©ÁêÜÁöÑÂ¶•ÂΩìÊÄß:&quot;)
print(&quot;- Ê∏©Â∫¶: „Ç¢„É¨„Éã„Ç¶„ÇπÂâá„Å´„Çà„ÇäÈ´òÊ∏©„ÅßÂèçÂøúÈÄüÂ∫¶‰∏äÊòá ‚Üí Â¶•ÂΩì&quot;)
print(&quot;- ÈõªÂúß: È´òÈõªÂúß„ÅßÂâØÂèçÂøú‰øÉÈÄ≤ ‚Üí Â¶•ÂΩì&quot;)
print(&quot;- „Çµ„Ç§„ÇØ„É´Êï∞: ÂÖÖÊîæÈõªÁπ∞„ÇäËøî„Åó„ÅßÂä£Âåñ ‚Üí Â¶•ÂΩì&quot;)
</code></pre>


</details>

<hr />
<h2>4.6 XAIÁí∞Â¢É„Å®ÂÆüË∑µÁöÑËêΩ„Å®„ÅóÁ©¥</h2>
<h3>SHAP„É©„Ç§„Éñ„É©„É™„ÅÆ„Éê„Éº„Ç∏„Éß„É≥ÁÆ°ÁêÜ</h3>
<pre><code class="language-python"># XAI„Å´ÂøÖË¶Å„Å™„É©„Ç§„Éñ„É©„É™„Éê„Éº„Ç∏„Éß„É≥
import sys
import shap
import lime
import sklearn
import pandas as pd
import numpy as np

xai_env_info = {
    'Python': sys.version,
    'NumPy': np.__version__,
    'Pandas': pd.__version__,
    'scikit-learn': sklearn.__version__,
    'SHAP': shap.__version__,
    'LIME': lime.__version__,
    'Date': '2025-10-19'
}

print(&quot;=== XAIÁí∞Â¢É ===&quot;)
for key, value in xai_env_info.items():
    print(f&quot;{key}: {value}&quot;)

# Êé®Â•®„Éê„Éº„Ç∏„Éß„É≥
print(&quot;\n„ÄêÊé®Â•®Áí∞Â¢É„Äë&quot;)
recommended_xai = &quot;&quot;&quot;
numpy==1.24.3
pandas==2.0.3
scikit-learn==1.3.0
shap==0.43.0
lime==0.2.0.1
matplotlib==3.7.2
&quot;&quot;&quot;
print(recommended_xai)

print(&quot;\n„Äê„Ç§„É≥„Çπ„Éà„Éº„É´„Ç≥„Éû„É≥„Éâ„Äë&quot;)
print(&quot;```bash&quot;)
print(&quot;pip install shap==0.43.0 lime==0.2.0.1&quot;)
print(&quot;```&quot;)

print(&quot;\n„ÄêÊ≥®ÊÑè‰∫ãÈ†Ö„Äë&quot;)
print(&quot;‚ö†Ô∏è SHAP„ÅØÈ†ªÁπÅ„Å´APIÂ§âÊõ¥ ‚Üí „Éê„Éº„Ç∏„Éß„É≥Âõ∫ÂÆöÊé®Â•®&quot;)
print(&quot;‚ö†Ô∏è TreeExplainer„ÅØscikit-learn 1.3‰ª•Èôç„ÅßÂãï‰ΩúÁ¢∫Ë™ç&quot;)
print(&quot;‚ö†Ô∏è Â§ßË¶èÊ®°„Éá„Éº„ÇøÔºà&gt;10000„Çµ„É≥„Éó„É´Ôºâ„ÅßKernelSHAP„ÅØË®àÁÆóÂõ∞Èõ£&quot;)
</code></pre>
<h3>ÂÆüË∑µÁöÑ„Å™ËêΩ„Å®„ÅóÁ©¥ÔºàXAIÁ∑®Ôºâ</h3>
<pre><code class="language-python">print(&quot;=== XAIÂÆüË∑µ„ÅÆËêΩ„Å®„ÅóÁ©¥ ===\n&quot;)

print(&quot;„ÄêËêΩ„Å®„ÅóÁ©¥1: SHAPÂÄ§„ÅÆË™§Ëß£Èáà„Äë&quot;)
print(&quot;‚ùå Ë™§Ëß£ÔºöSHAPÂÄ§„ÅåÂ§ß„Åç„ÅÑ = ÁâπÂæ¥Èáè„ÅÆÁµ∂ÂØæÂÄ§„ÅåÂ§ß„Åç„ÅÑ&quot;)
print(&quot;‚Üí SHAPÂÄ§„ÅØ„ÄåÂü∫Ê∫ñÂÄ§„Åã„Çâ„ÅÆÂØÑ‰∏é„Äç„Åß„ÅÇ„Çä„ÄÅÁâπÂæ¥ÈáèÂÄ§„Å®„ÅØÁÑ°Èñ¢‰øÇ&quot;)

print(&quot;\n‚úÖ Ê≠£„Åó„ÅÑÁêÜËß£Ôºö&quot;)
print(&quot;```python&quot;)
print(&quot;# SHAPÂÄ§ = „Åù„ÅÆÁâπÂæ¥Èáè„Åå‰∫àÊ∏¨„Å´‰∏é„Åà„ÅüÂΩ±Èüø&quot;)
print(&quot;# ÁâπÂæ¥ÈáèÂÄ§„ÅåÂ∞è„Åï„Åè„Å¶„ÇÇSHAPÂÄ§„ÅØÂ§ß„Åç„ÅÑÂ†¥Âêà„Åå„ÅÇ„Çã&quot;)
print(&quot;feature_value = 0.1  # Â∞è„Åï„ÅÑÂÄ§&quot;)
print(&quot;shap_value = 2.5     # Â§ß„Åç„ÅÑÂΩ±Èüø&quot;)
print(&quot;# ‚Üí „Åì„ÅÆÁâπÂæ¥Èáè„ÅØÂ∞è„Åï„ÅÑÂÄ§„Åß„ÇÇ‰∫àÊ∏¨„Å´Â§ß„Åç„ÅèÂØÑ‰∏é&quot;)
print(&quot;```&quot;)

print(&quot;\n„ÄêËêΩ„Å®„ÅóÁ©¥2: LIME„ÅÆÂ±ÄÊâÄÊÄßÁÑ°Ë¶ñ„Äë&quot;)
print(&quot;‚ö†Ô∏è 1„Çµ„É≥„Éó„É´„ÅÆLIMEË™¨Êòé„ÇíÂÖ®‰Ωì„Å´‰∏ÄËà¨Âåñ&quot;)
print(&quot;‚Üí LIME„ÅØÂ±ÄÊâÄÁöÑÁ∑öÂΩ¢Ëøë‰ºº„Å™„ÅÆ„Åß„ÄÅ‰ªñ„Çµ„É≥„Éó„É´„ÅßÁï∞„Å™„ÇãË™¨Êòé&quot;)

print(&quot;\n‚úÖ ÂØæÁ≠ñÔºöË§áÊï∞„Çµ„É≥„Éó„É´„Åß‰∏ÄË≤´ÊÄßÁ¢∫Ë™ç&quot;)
print(&quot;```python&quot;)
print(&quot;# 10„Çµ„É≥„Éó„É´„ÅßLIMEÂÆüË°å„Åó„ÄÅÈáçË¶ÅÁâπÂæ¥Èáè„ÅÆ‰∏ÄËá¥Áéá„ÇíÁ¢∫Ë™ç&quot;)
print(&quot;for i in range(10):&quot;)
print(&quot;    explanation = lime_explainer.explain_instance(X[i], model.predict)&quot;)
print(&quot;    # ‰∏ä‰Ωç3ÁâπÂæ¥Èáè„Åå‰∏ÄËá¥„Åô„Çã„ÅãÁ¢∫Ë™ç&quot;)
print(&quot;```&quot;)

print(&quot;\n„ÄêËêΩ„Å®„ÅóÁ©¥3: Áõ∏Èñ¢„Å®Âõ†Êûú„ÅÆÊ∑∑Âêå„Äë&quot;)
print(&quot;‚ö†Ô∏è „ÄåSHAPÂÄ§„ÅåÈ´ò„ÅÑ ‚Üí „Åì„ÅÆÁâπÂæ¥Èáè„ÇíÂ§â„Åà„Çå„Å∞‰∫àÊ∏¨„ÅåÂ§â„Çè„Çã„Äç&quot;)
print(&quot;‚Üí Áõ∏Èñ¢„Åß„ÅÇ„Å£„Å¶Âõ†Êûú„Åß„ÅØ„Å™„ÅÑ&quot;)

print(&quot;\n‚úÖ Âõ†ÊûúÊé®Ë´ñ„Å´„ÅØÂà•ÊâãÊ≥ï„ÅåÂøÖË¶Å&quot;)
print(&quot;```python&quot;)
print(&quot;# XAI„ÅØÁõ∏Èñ¢ÂàÜÊûê&quot;)
print(&quot;# Âõ†ÊûúÊé®Ë´ñ„Å´„ÅØ‰ª•‰∏ã„Çí‰ΩøÁî®:&quot;)
print(&quot;# - A/B„ÉÜ„Çπ„Éà&quot;)
print(&quot;# - Âõ†Êûú„Ç∞„É©„Éï (DAG)&quot;)
print(&quot;# - ÂÇæÂêë„Çπ„Ç≥„Ç¢„Éû„ÉÉ„ÉÅ„É≥„Ç∞&quot;)
print(&quot;```&quot;)

print(&quot;\n„ÄêËêΩ„Å®„ÅóÁ©¥4: AttentionÂèØË¶ñÂåñ„ÅÆÈÅé‰ø°„Äë&quot;)
print(&quot;‚ö†Ô∏è Attention„ÅåÈ´ò„ÅÑ = „É¢„Éá„É´„Åå„Åù„ÅÆÈÉ®ÂàÜ„ÇíÈáçË¶ñ&quot;)
print(&quot;‚Üí ÂøÖ„Åö„Åó„ÇÇÊ≠£„Åó„ÅÑÁêÜÁî±„Å®„ÅØÈôê„Çâ„Å™„ÅÑ&quot;)

print(&quot;\n‚úÖ Ë§áÊï∞ÊâãÊ≥ï„ÅßÁõ∏‰∫íÊ§úË®º&quot;)
print(&quot;```python&quot;)
print(&quot;# SHAP + LIME + Attention „ÅÆ3ÊâãÊ≥ï„Åß‰∏ÄËá¥„ÇíÁ¢∫Ë™ç&quot;)
print(&quot;# Áâ©ÁêÜÁöÑÂ¶•ÂΩìÊÄß„ÇíÂ∞ÇÈñÄÂÆ∂„Å´Ê§úË®º„Åó„Å¶„ÇÇ„Çâ„ÅÜ&quot;)
print(&quot;```&quot;)

print(&quot;\n„ÄêËêΩ„Å®„ÅóÁ©¥5: Â§ßË¶èÊ®°„Éá„Éº„Çø„Åß„ÅÆË®àÁÆó„Ç≥„Çπ„ÉàÁÑ°Ë¶ñ„Äë&quot;)
print(&quot;‚ö†Ô∏è 10000„Çµ„É≥„Éó„É´„ÅßKernel SHAPÂÆüË°å&quot;)
print(&quot;‚Üí Ë®àÁÆóÊôÇÈñì: Êï∞ÊôÇÈñì„ÄúÊï∞Êó•&quot;)

print(&quot;\n‚úÖ ÂØæÁ≠ñÔºöÊâãÊ≥ï„Å®„Çµ„É≥„Éó„É´Êï∞„ÅÆÈÅ©Âàá„Å™ÈÅ∏Êäû&quot;)
print(&quot;```python&quot;)
print(&quot;if len(X) &lt; 1000:&quot;)
print(&quot;    explainer = shap.KernelExplainer()  # ‰ªªÊÑè„É¢„Éá„É´&quot;)
print(&quot;else:&quot;)
print(&quot;    # „Çµ„Éñ„Çµ„É≥„Éó„É™„É≥„Ç∞ or TreeExplainer‰ΩøÁî®&quot;)
print(&quot;    X_sample = shap.sample(X, 1000)&quot;)
print(&quot;    explainer = shap.TreeExplainer()  # È´òÈÄü&quot;)
print(&quot;```&quot;)
</code></pre>
<hr />
<h2>„Åæ„Å®„ÇÅ</h2>
<p>„Åì„ÅÆÁ´†„Åß„ÅØ„ÄÅ<strong>Ëß£ÈáàÂèØËÉΩAIÔºàXAIÔºâ</strong> „ÅÆÁêÜË´ñ„Å®ÂÆüË∑µ„ÇíÂ≠¶„Å≥„Åæ„Åó„Åü„ÄÇ</p>
<p><strong>ÈáçË¶Å„Éù„Ç§„É≥„Éà</strong>Ôºö</p>
<ol>
<li><strong>„Éñ„É©„ÉÉ„ÇØ„Éú„ÉÉ„ÇØ„ÇπÂïèÈ°å</strong>ÔºöÈ´òÁ≤æÂ∫¶„É¢„Éá„É´„ÅØËß£ÈáàÂõ∞Èõ£ ‚Üí XAI„ÅßËß£Ê±∫</li>
<li><strong>SHAP</strong>ÔºöShapleyÂÄ§„Å´„Çà„ÇãÂÖ¨Âπ≥„Å™ÁâπÂæ¥ÈáèÂØÑ‰∏éÂ∫¶Ë©ï‰æ°</li>
<li><strong>LIME</strong>ÔºöÂ±ÄÊâÄÁ∑öÂΩ¢Ëøë‰ºº„ÅßÂÄãÂà•‰∫àÊ∏¨„ÅÆË™¨ÊòéÁîüÊàê</li>
<li><strong>AttentionÂèØË¶ñÂåñ</strong>Ôºö„Éã„É•„Éº„É©„É´„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ„ÅÆÂÜÖÈÉ®Âãï‰ΩúÁêÜËß£</li>
<li><strong>ÂÆü‰∏ñÁïåÂøúÁî®</strong>Ôºö„Éà„É®„Çø„ÄÅIBM„ÄÅCitrine„ÅÆÊàêÂäü‰∫ã‰æã</li>
<li><strong>„Ç≠„É£„É™„Ç¢„Éë„Çπ</strong>ÔºöÊùêÊñô„Éá„Éº„Çø„Çµ„Ç§„Ç®„É≥„ÉÜ„Ç£„Çπ„Éà„ÅÆÈúÄË¶ÅÊã°Â§ß„ÄÅÂπ¥Âèé700-2500‰∏áÂÜÜ</li>
<li><strong>Áí∞Â¢ÉÁÆ°ÁêÜ</strong>ÔºöSHAP„ÄÅLIME„ÅÆ„Éê„Éº„Ç∏„Éß„É≥Âõ∫ÂÆö„Å®Ë®àÁÆó„Ç≥„Çπ„ÉàÁÆ°ÁêÜ</li>
<li><strong>ÂÆüË∑µÁöÑËêΩ„Å®„ÅóÁ©¥</strong>ÔºöSHAPÂÄ§Ë™§Ëß£Èáà„ÄÅLIMEÂ±ÄÊâÄÊÄß„ÄÅÁõ∏Èñ¢„Å®Âõ†Êûú„ÅÆÊ∑∑Âêå„ÄÅË®àÁÆó„Ç≥„Çπ„Éà</li>
</ol>
<p><strong>„Ç∑„É™„Éº„Ç∫Á∑è„Åæ„Å®„ÇÅ</strong>Ôºö</p>
<ul>
<li><strong>Chapter 1</strong>: „Éá„Éº„ÇøÂèéÈõÜÊà¶Áï•„Å®„ÇØ„É™„Éº„Éã„É≥„Ç∞ ‚Üí È´òÂìÅË≥™„Éá„Éº„Çø„ÅÆÊ∫ñÂÇô</li>
<li><strong>Chapter 2</strong>: ÁâπÂæ¥Èáè„Ç®„É≥„Ç∏„Éã„Ç¢„É™„É≥„Ç∞ ‚Üí 200Ê¨°ÂÖÉ‚Üí20Ê¨°ÂÖÉ„Å∏„ÅÆÂäπÁéáÂåñ</li>
<li><strong>Chapter 3</strong>: „É¢„Éá„É´ÈÅ∏Êäû„Å®ÊúÄÈÅ©Âåñ ‚Üí Optuna„ÅßËá™ÂãïÊúÄÈÅ©Âåñ</li>
<li><strong>Chapter 4</strong>: Ëß£ÈáàÂèØËÉΩAI ‚Üí ‰∫àÊ∏¨„ÅÆÁâ©ÁêÜÁöÑÊÑèÂë≥„Å•„Åë</li>
</ul>
<p><strong>Ê¨°„ÅÆ„Çπ„ÉÜ„ÉÉ„Éó</strong>Ôºö</p>
<ol>
<li>ÂÆü„Éá„Éº„Çø„Çª„ÉÉ„Éà„ÅßÂÖ®Â∑•Á®ã„ÇíÂÆüË∑µ</li>
<li>Ë´ñÊñáÊäïÁ®ø„ÇÑOSS„Ç≥„É≥„Éà„É™„Éì„É•„Éº„Ç∑„Éß„É≥</li>
<li>Â≠¶‰ºöÂèÇÂä†„Å®„Éç„ÉÉ„Éà„ÉØ„Éº„Ç≠„É≥„Ç∞</li>
<li>„Ç≠„É£„É™„Ç¢ÊßãÁØâÔºàÊùêÊñô„Éá„Éº„Çø„Çµ„Ç§„Ç®„É≥„ÉÜ„Ç£„Çπ„ÉàÔºâ</li>
</ol>
<hr />
<h2>Chapter 4 „ÉÅ„Çß„ÉÉ„ÇØ„É™„Çπ„Éà</h2>
<h3>SHAPÔºàSHapley Additive exPlanationsÔºâ</h3>
<ul>
<li>[ ] <strong>SHAPÂÄ§„ÅÆÁêÜËß£</strong></li>
<li>[ ] ShapleyÂÄ§„ÅÆÁêÜË´ñÁöÑËÉåÊôØÔºàÂçîÂäõ„Ç≤„Éº„É†ÁêÜË´ñÔºâ„ÇíÁêÜËß£</li>
<li>[ ] Âü∫Ê∫ñÂÄ§Ôºàexpected_valueÔºâ+ SHAPÂÄ§ÂêàË®à = ‰∫àÊ∏¨ÂÄ§ „ÇíÁ¢∫Ë™ç</li>
<li>
<p>[ ] SHAPÂÄ§„ÅØÁâπÂæ¥ÈáèÂÄ§„ÅÆÂ§ß„Åç„Åï„Å®„ÅØÁÑ°Èñ¢‰øÇÔºàÂØÑ‰∏éÂ∫¶„ÇíÁ§∫„ÅôÔºâ</p>
</li>
<li>
<p>[ ] <strong>SHAPË®àÁÆóÊâãÊ≥ï„ÅÆÈÅ∏Êäû</strong></p>
</li>
<li>[ ] Êú®„Éô„Éº„Çπ„É¢„Éá„É´ ‚Üí TreeExplainerÔºàÈ´òÈÄü„ÉªÂé≥ÂØÜËß£Ôºâ</li>
<li>[ ] ‰ªªÊÑè„É¢„Éá„É´ ‚Üí KernelExplainerÔºàÈÅÖ„ÅÑ„ÉªËøë‰ººËß£Ôºâ</li>
<li>
<p>[ ] Ê∑±Â±§Â≠¶Áøí ‚Üí DeepExplainer or GradientExplainer</p>
</li>
<li>
<p>[ ] <strong>GlobalËß£Èáà</strong></p>
</li>
<li>[ ] mean(|SHAPÂÄ§|)„ÅßÂÖ®‰ΩìÁöÑ„Å™ÁâπÂæ¥ÈáèÈáçË¶ÅÂ∫¶„ÇíË©ï‰æ°</li>
<li>[ ] Summary Plot„ÅßÂàÜÂ∏É„Å®ÂΩ±ÈüøÊñπÂêë„ÇíÂèØË¶ñÂåñ</li>
<li>
<p>[ ] Bar Plot„Åß‰∏ä‰ΩçÈáçË¶ÅÁâπÂæ¥Èáè„Çí„É©„É≥„Ç≠„É≥„Ç∞</p>
</li>
<li>
<p>[ ] <strong>LocalËß£Èáà</strong></p>
</li>
<li>[ ] ÂÄãÂà•„Çµ„É≥„Éó„É´„ÅÆSHAPÂÄ§„Åß‰∫àÊ∏¨Ê†πÊã†„ÇíË™¨Êòé</li>
<li>[ ] Force Plot„ÅßÂü∫Ê∫ñÂÄ§„Åã„Çâ„ÅÆÂØÑ‰∏é„ÇíË¶ñË¶öÂåñ</li>
<li>
<p>[ ] Waterfall Plot„ÅßÁ¥ØÁ©çÂØÑ‰∏é„ÇíË°®Á§∫</p>
</li>
<li>
<p>[ ] <strong>Dependence Plot</strong></p>
</li>
<li>[ ] ÁâπÂæ¥ÈáèÂÄ§„Å®SHAPÂÄ§„ÅÆÈñ¢‰øÇ„ÇíÂèØË¶ñÂåñ</li>
<li>[ ] ÈùûÁ∑öÂΩ¢Èñ¢‰øÇ„ÅÆÁô∫Ë¶ã</li>
<li>[ ] Áõ∏‰∫í‰ΩúÁî®È†ÖÔºàinteraction_indexÔºâ„ÅÆÁâπÂÆö</li>
</ul>
<h3>LIMEÔºàLocal Interpretable Model-agnostic ExplanationsÔºâ</h3>
<ul>
<li>[ ] <strong>LIMEÂü∫Êú¨ÁêÜËß£</strong></li>
<li>[ ] Â±ÄÊâÄÁ∑öÂΩ¢Ëøë‰ºº„ÅÆ‰ªïÁµÑ„Åø„ÇíÁêÜËß£</li>
<li>[ ] „Çµ„É≥„Éó„É´Âë®Ëæ∫„Åß„ÅÆ„É©„É≥„ÉÄ„É†„Çµ„É≥„Éó„É™„É≥„Ç∞</li>
<li>
<p>[ ] Ë∑ùÈõ¢„Å´Âü∫„Å•„ÅèÈáç„Åø‰ªò„Åë</p>
</li>
<li>
<p>[ ] <strong>Tabular LIME</strong></p>
</li>
<li>[ ] LimeTabularExplainer„ÅßË°®ÂΩ¢Âºè„Éá„Éº„Çø„ÇíË™¨Êòé</li>
<li>[ ] num_featuresÂºïÊï∞„ÅßÈáçË¶ÅÁâπÂæ¥ÈáèÊï∞„ÇíÊåáÂÆö</li>
<li>
<p>[ ] explain_instance()„ÅßÂÄãÂà•‰∫àÊ∏¨„ÇíË™¨Êòé</p>
</li>
<li>
<p>[ ] <strong>LIME„ÅÆÈôêÁïåË™çË≠ò</strong></p>
</li>
<li>[ ] Â±ÄÊâÄÁöÑË™¨Êòé„Åß„ÅÇ„Çä„ÄÅÂÖ®‰ΩìÂÉè„Åß„ÅØ„Å™„ÅÑ</li>
<li>[ ] „Çµ„É≥„Éó„É´„Åî„Å®„Å´Áï∞„Å™„ÇãË™¨ÊòéÔºà‰∏ÄË≤´ÊÄß„Å™„ÅóÔºâ</li>
<li>
<p>[ ] Ë®àÁÆó„Ç≥„Çπ„Éà„ÅØSHAP„Çà„Çä‰Ωé„ÅÑ</p>
</li>
<li>
<p>[ ] <strong>SHAP vs LIMEÊØîËºÉ</strong></p>
</li>
<li>[ ] ‰∏°ÊâãÊ≥ï„ÅßÈáçË¶ÅÁâπÂæ¥Èáè„ÅÆ‰∏ÄËá¥Áéá„ÇíÁ¢∫Ë™ç</li>
<li>[ ] Áõ∏Èñ¢ &gt; 0.7 „Å™„Çâ‰ø°È†ºÊÄß„ÅåÈ´ò„ÅÑ</li>
<li>[ ] ‰∏ç‰∏ÄËá¥ÊôÇ„ÅØÊÖéÈáç„Å´Ëß£Èáà</li>
</ul>
<h3>AttentionÂèØË¶ñÂåñÔºàNN/GNNÁî®Ôºâ</h3>
<ul>
<li>[ ] <strong>Attention WeightsÂèñÂæó</strong></li>
<li>[ ] „Éã„É•„Éº„É©„É´„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ„ÅÆ‰∏≠ÈñìÂ±§Ê¥ªÊÄßÂåñ„ÇíÂèñÂæó</li>
<li>[ ] AttentionÊ©üÊßã„ÅÆÈáç„Åø„ÇíÂèØË¶ñÂåñ</li>
<li>
<p>[ ] „Å©„ÅÆÂÖ•Âäõ„Å´Ê≥®ÁõÆ„Åó„Å¶„ÅÑ„Çã„ÅãÂàÜÊûê</p>
</li>
<li>
<p>[ ] <strong>Grad-CAMÈ¢®ÊâãÊ≥ï</strong></p>
</li>
<li>[ ] ÂãæÈÖç„Éô„Éº„Çπ„ÅÆÈáçË¶ÅÂ∫¶Ë®àÁÆó</li>
<li>[ ] Êï∞ÂÄ§ÂæÆÂàÜ„ÅßÁâπÂæ¥ÈáèÈáçË¶ÅÂ∫¶„ÇíËøë‰ºº</li>
<li>
<p>[ ] „Éã„É•„Éº„É©„É´„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØÁâπÂåñ</p>
</li>
<li>
<p>[ ] <strong>ÂàÜÂ≠ê„Ç∞„É©„Éï„Å∏„ÅÆÂøúÁî®</strong></p>
</li>
<li>[ ] GNN„Åß„Å©„ÅÆÂéüÂ≠ê/ÁµêÂêà„ÅåÈáçË¶Å„ÅãÁâπÂÆö</li>
<li>[ ] Attention„ÅßÂèçÂøúÊ©üÊßã„ÇíÊé®ÂÆö</li>
<li>[ ] ÂåñÂ≠¶ÁöÑÂ¶•ÂΩìÊÄß„ÇíÂ∞ÇÈñÄÂÆ∂„Å´Ê§úË®º</li>
</ul>
<h3>ÂÆü‰∏ñÁïåÂøúÁî®‰∫ã‰æã„ÅÆÂ≠¶Áøí</h3>
<ul>
<li>[ ] <strong>„Éà„É®„ÇøÔºöÊùêÊñôÈñãÁô∫</strong></li>
<li>[ ] SHAPËß£Êûê„ÅßÂä£ÂåñË¶ÅÂõ†„ÇíÁâπÂÆö</li>
<li>[ ] Ê∏©Â∫¶„ÉªÈõªÂúß„Éª„Çµ„Ç§„ÇØ„É´Êï∞„ÅÆÁõ∏‰∫í‰ΩúÁî®„ÇíÂèØË¶ñÂåñ</li>
<li>
<p>[ ] ÈñãÁô∫ÊúüÈñì40%Áü≠Á∏Æ„ÄÅÈõªÊ±†ÂØøÂëΩ20%Âêë‰∏ä</p>
</li>
<li>
<p>[ ] <strong>IBM ResearchÔºöËá™ÂãïÂåñÂ≠¶ÂÆüÈ®ì</strong></p>
</li>
<li>[ ] GNN + Attention„ÅßÂèçÂøú„É°„Ç´„Éã„Ç∫„É†‰∫àÊ∏¨</li>
<li>[ ] ÂèçÂøúÂèéÁéá‰∫àÊ∏¨Á≤æÂ∫¶95%</li>
<li>
<p>[ ] Êñ∞Ë¶èÂèçÂøúÁµåË∑Ø„ÅÆÁô∫Ë¶ã</p>
</li>
<li>
<p>[ ] <strong>Citrine InformaticsÔºöSaaS‰∫ãÊ•≠</strong></p>
</li>
<li>[ ] Ë™¨ÊòéÂèØËÉΩAI„Çí‰∏≠Ê†∏ÊäÄË°ì„Å®„Åô„Çã</li>
<li>[ ] ‰∏çÁ¢∫ÂÆüÊÄßÂÆöÈáèÂåñ + SHAP</li>
<li>[ ] „Éë„Éä„ÇΩ„Éã„ÉÉ„ÇØ„Éª3M„ÉªMichelin„Å∏„ÅÆÂ∞éÂÖ•</li>
</ul>
<h3>„Ç≠„É£„É™„Ç¢„Éë„ÇπÊßãÁØâ</h3>
<ul>
<li>[ ] <strong>ÂøÖË¶Å„Çπ„Ç≠„É´„Çª„ÉÉ„Éà</strong></li>
<li>[ ] ÊùêÊñôÁßëÂ≠¶„ÅÆÂ∞ÇÈñÄÁü•Ë≠òÔºàÂ≠¶‰ΩçÊé®Â•®Ôºâ</li>
<li>[ ] Ê©üÊ¢∞Â≠¶Áøí„ÉªÊ∑±Â±§Â≠¶Áøí„ÅÆÂÆüË£Ö„Çπ„Ç≠„É´</li>
<li>[ ] XAIÊâãÊ≥ïÔºàSHAP„ÄÅLIMEÔºâ„ÅÆÁøíÂæó</li>
<li>
<p>[ ] Python„ÄÅscikit-learn„ÄÅPyTorch/TensorFlow</p>
</li>
<li>
<p>[ ] <strong>„Ç≠„É£„É™„Ç¢ÈÅ∏ÊäûËÇ¢</strong></p>
</li>
<li>[ ] ÊùêÊñô„Éá„Éº„Çø„Çµ„Ç§„Ç®„É≥„ÉÜ„Ç£„Çπ„ÉàÔºàË£ΩÈÄ†Ê•≠R&amp;DÔºâ</li>
<li>[ ] XAIÁ†îÁ©∂ËÄÖÔºà„Ç¢„Ç´„Éá„Éü„Ç¢Ôºâ</li>
<li>[ ] ML„Ç®„É≥„Ç∏„Éã„Ç¢ÔºàÊùêÊñôÁâπÂåñ„Çπ„Çø„Éº„Éà„Ç¢„ÉÉ„ÉóÔºâ</li>
<li>[ ] R&amp;D ManagerÔºàAIÊ¥ªÁî®Êé®ÈÄ≤Ôºâ</li>
<li>
<p>[ ] „ÉÜ„ÇØ„Éã„Ç´„É´„Ç≥„É≥„Çµ„É´„Çø„É≥„Éà</p>
</li>
<li>
<p>[ ] <strong>Âπ¥ÂèéÁõÆÊ®ô</strong></p>
</li>
<li>[ ] Êó•Êú¨Ôºö„Ç∏„É•„Éã„Ç¢500-700‰∏á„ÄÅ„Éü„Éâ„É´1000-1500‰∏á„ÄÅ„Ç∑„Éã„Ç¢1500-2500‰∏á</li>
<li>[ ] Á±≥ÂõΩÔºö$70-90KÔºà„Ç∏„É•„Éã„Ç¢Ôºâ„ÄÅ$130-180KÔºà„Éü„Éâ„É´Ôºâ„ÄÅ$180-300KÔºà„Ç∑„Éã„Ç¢Ôºâ</li>
<li>
<p>[ ] „Çπ„Ç≠„É´„Ç¢„ÉÉ„Éó„ÅßÂπ¥ÂèéÂêë‰∏äÔºöÂ≠¶‰Ωç„ÄÅË´ñÊñá„ÄÅ„Éó„É≠„Ç∏„Çß„ÇØ„ÉàÂÆüÁ∏æ</p>
</li>
<li>
<p>[ ] <strong>„Çπ„Ç≠„É´„Ç¢„ÉÉ„ÉóÊà¶Áï•</strong></p>
</li>
<li>[ ] ÊùêÊñôÁßëÂ≠¶„ÅÆÂü∫Á§éÂõ∫„ÇÅÔºàÂ≠¶‰ΩçÂèñÂæó„Åæ„Åü„ÅØÁã¨Â≠¶Ôºâ</li>
<li>[ ] ML/DL„ÅÆÂÆüË∑µÔºàKaggle„ÄÅGitHubÔºâ</li>
<li>[ ] XAIÊâãÊ≥ï„ÅÆÁøíÂæóÔºàÊú¨„Ç∑„É™„Éº„Ç∫Ôºâ</li>
<li>[ ] Ë´ñÊñáÁô∫Ë°®„ÉªOSS„Ç≥„É≥„Éà„É™„Éì„É•„Éº„Ç∑„Éß„É≥</li>
<li>[ ] Â≠¶‰ºö„ÉªÂãâÂº∑‰ºö„Åß„Éç„ÉÉ„Éà„ÉØ„Éº„Ç≠„É≥„Ç∞</li>
</ul>
<h3>ÂÆüË∑µÁöÑËêΩ„Å®„ÅóÁ©¥„ÅÆÂõûÈÅøÔºàXAIÔºâ</h3>
<ul>
<li>[ ] <strong>SHAPÂÄ§„ÅÆÊ≠£„Åó„ÅÑËß£Èáà</strong></li>
<li>[ ] SHAPÂÄ§ ‚â† ÁâπÂæ¥Èáè„ÅÆÂ§ß„Åç„Åï</li>
<li>[ ] SHAPÂÄ§ = ‰∫àÊ∏¨„Å∏„ÅÆÂØÑ‰∏éÂ∫¶</li>
<li>
<p>[ ] Âü∫Ê∫ñÂÄ§„Åã„Çâ„ÅÆÂÅèÂ∑Æ„Å®„Åó„Å¶ÁêÜËß£</p>
</li>
<li>
<p>[ ] <strong>LIME„ÅÆÂ±ÄÊâÄÊÄßË™çË≠ò</strong></p>
</li>
<li>[ ] 1„Çµ„É≥„Éó„É´„ÅÆË™¨Êòé„ÇíÂÖ®‰Ωì„Å´‰∏ÄËà¨Âåñ„Åó„Å™„ÅÑ</li>
<li>[ ] Ë§áÊï∞„Çµ„É≥„Éó„É´„Åß‰∏ÄË≤´ÊÄß„ÇíÁ¢∫Ë™ç</li>
<li>
<p>[ ] SHAP„Å®Áõ∏‰∫íÊ§úË®º</p>
</li>
<li>
<p>[ ] <strong>Áõ∏Èñ¢„Å®Âõ†Êûú„ÅÆÂå∫Âà•</strong></p>
</li>
<li>[ ] XAI„ÅØÁõ∏Èñ¢ÂàÜÊûêÔºàÂõ†ÊûúÊé®Ë´ñ„Åß„ÅØ„Å™„ÅÑÔºâ</li>
<li>[ ] „ÄåSHAPÂÄ§È´ò„ÅÑ ‚Üí Â§âÊõ¥„Åô„Çå„Å∞‰∫àÊ∏¨Â§â„Çè„Çã„Äç„ÅØË™§Ëß£</li>
<li>
<p>[ ] Âõ†ÊûúÊé®Ë´ñ„Å´„ÅØA/B„ÉÜ„Çπ„Éà„ÄÅÂõ†Êûú„Ç∞„É©„Éï„ÅåÂøÖË¶Å</p>
</li>
<li>
<p>[ ] <strong>AttentionÂèØË¶ñÂåñ„ÅÆÈôêÁïå</strong></p>
</li>
<li>[ ] AttentionÈ´ò ‚â† ÂøÖ„Åö„Åó„ÇÇÊ≠£„Åó„ÅÑÁêÜÁî±</li>
<li>[ ] Ë§áÊï∞ÊâãÊ≥ïÔºàSHAP + LIME + AttentionÔºâ„ÅßÁõ∏‰∫íÊ§úË®º</li>
<li>
<p>[ ] Áâ©ÁêÜÁöÑÂ¶•ÂΩìÊÄß„ÇíÂ∞ÇÈñÄÂÆ∂„Å´Á¢∫Ë™ç</p>
</li>
<li>
<p>[ ] <strong>Ë®àÁÆó„Ç≥„Çπ„ÉàÁÆ°ÁêÜ</strong></p>
</li>
<li>[ ] Kernel SHAP: „Çµ„É≥„Éó„É´Êï∞ &lt; 1000 Êé®Â•®</li>
<li>[ ] Tree SHAP: Êï∞‰∏á„Çµ„É≥„Éó„É´„Åß„ÇÇÈ´òÈÄü</li>
<li>[ ] Â§ßË¶èÊ®°„Éá„Éº„Çø„ÅØ„Çµ„Éñ„Çµ„É≥„Éó„É™„É≥„Ç∞ or TreeÊâãÊ≥ï‰ΩøÁî®</li>
</ul>
<h3>XAIÂìÅË≥™Ë©ï‰æ°</h3>
<ul>
<li>[ ] <strong>Ë™¨Êòé„ÅÆ‰∏ÄË≤´ÊÄß</strong></li>
<li>[ ] SHAP vs LIME „ÅÆÁõ∏Èñ¢ &gt; 0.7</li>
<li>[ ] Ë§áÊï∞„Çµ„É≥„Éó„É´„ÅßÈáçË¶ÅÁâπÂæ¥Èáè„Åå‰∏ÄËá¥</li>
<li>
<p>[ ] Áâ©ÁêÜÁöÑËß£Èáà„Å®Ê©üÊ¢∞Â≠¶ÁøíËß£Èáà„Åå‰∏ÄËá¥</p>
</li>
<li>
<p>[ ] <strong>Áâ©ÁêÜÁöÑÂ¶•ÂΩìÊÄß</strong></p>
</li>
<li>[ ] Â∞ÇÈñÄÂÆ∂„Å´„Çà„ÇãÊ§úË®º</li>
<li>[ ] Êó¢Áü•„ÅÆÁâ©ÁêÜÊ≥ïÂâá„Å®„ÅÆÊï¥ÂêàÊÄß</li>
<li>
<p>[ ] ÂÆüÈ®ìÁµêÊûú„Å®„ÅÆ‰∏ÄËá¥</p>
</li>
<li>
<p>[ ] <strong>ÂÆüÁî®ÊÄß</strong></p>
</li>
<li>[ ] ÊùêÊñôË®≠Ë®à„Ç¨„Ç§„Éâ„É©„Ç§„É≥ÊäΩÂá∫ÂèØËÉΩ</li>
<li>[ ] ÂÆüÈ®ìË®àÁîª„Å∏„ÅÆÂèçÊò†ÂèØËÉΩ</li>
<li>[ ] Ë´ñÊñá„ÉªÁâπË®±„Åß„ÅÆË™¨ÊòéË≤¨‰ªª„ÇíÊûú„Åü„Åõ„Çã</li>
</ul>
<h3>ÂÜçÁèæÊÄß„ÅÆÁ¢∫‰øù</h3>
<ul>
<li>[ ] <strong>„Éê„Éº„Ç∏„Éß„É≥ÁÆ°ÁêÜ</strong></li>
<li>[ ] SHAP„ÄÅLIME„ÅÆ„Éê„Éº„Ç∏„Éß„É≥Âõ∫ÂÆö</li>
<li>[ ] API„ÅÆÂ§âÊõ¥„Å´Ê≥®ÊÑèÔºàÁâπ„Å´SHAPÔºâ</li>
<li>
<p>[ ] requirements.txt„Å´ÊòéË®ò</p>
</li>
<li>
<p>[ ] <strong>Ë®àÁÆóÁí∞Â¢ÉÁµ±‰∏Ä</strong></p>
</li>
<li>[ ] ‰π±Êï∞„Ç∑„Éº„ÉâË®≠ÂÆöÔºàSHAP„ÄÅLIMEÔºâ</li>
<li>[ ] ‰∏¶ÂàóË®àÁÆó„ÅÆÂÜçÁèæÊÄßÔºàn_jobsÂõ∫ÂÆöÔºâ</li>
<li>
<p>[ ] DockerÁí∞Â¢ÉÊé®Â•®</p>
</li>
<li>
<p>[ ] <strong>Ë™¨Êòé„ÅÆ‰øùÂ≠ò</strong></p>
</li>
<li>[ ] SHAPÂÄ§„ÇíNumPyÈÖçÂàó„Åß‰øùÂ≠ò</li>
<li>[ ] ÂèØË¶ñÂåñÁîªÂÉè„ÇíPNG/PDF‰øùÂ≠ò</li>
<li>[ ] Ë™¨ÊòéÊñá„ÇíMarkdown/LaTeXÂåñ</li>
</ul>
<hr />
<h2>ÂèÇËÄÉÊñáÁåÆ</h2>
<ol>
<li>
<p><strong>Lundberg, S. M. &amp; Lee, S. I.</strong> (2017). A unified approach to interpreting model predictions. <em>Advances in Neural Information Processing Systems</em>, 30, 4765-4774.</p>
</li>
<li>
<p><strong>Ribeiro, M. T., Singh, S., &amp; Guestrin, C.</strong> (2016). "Why should I trust you?": Explaining the predictions of any classifier. <em>Proceedings of the 22nd ACM SIGKDD</em>, 1135-1144. <a href="https://doi.org/10.1145/2939672.2939778">DOI: 10.1145/2939672.2939778</a></p>
</li>
<li>
<p><strong>Molnar, C.</strong> (2022). <em>Interpretable Machine Learning: A Guide for Making Black Box Models Explainable</em> (2nd ed.). <a href="https://christophm.github.io/interpretable-ml-book/">https://christophm.github.io/interpretable-ml-book/</a></p>
</li>
<li>
<p><strong>Vaswani, A., Shazeer, N., Parmar, N., et al.</strong> (2017). Attention is all you need. <em>Advances in Neural Information Processing Systems</em>, 30, 5998-6008.</p>
</li>
<li>
<p><strong>Citrine Informatics.</strong> (2023). Materials Informatics Platform. <a href="https://citrine.io/">https://citrine.io/</a></p>
</li>
</ol>
<hr />
<p><a href="chapter-3.html">‚Üê Chapter 3„Å´Êàª„Çã</a> | <a href="index.html">„Ç∑„É™„Éº„Ç∫ÁõÆÊ¨°„Å´Êàª„Çã</a></p>
<hr />
<h2>„Ç∑„É™„Éº„Ç∫ÂÆå‰∫Ü„Åä„ÇÅ„Åß„Å®„ÅÜ„Åî„Åñ„ÅÑ„Åæ„ÅôÔºÅ</h2>
<p>„Éá„Éº„ÇøÈßÜÂãïÊùêÊñôÁßëÂ≠¶„ÅÆÂÆüË∑µÁöÑ„Çπ„Ç≠„É´„ÇíÁøíÂæó„Åï„Çå„Åæ„Åó„Åü„ÄÇ‰ªäÂæå„ÅÆ„ÅîÊ¥ªË∫ç„ÇíÊúüÂæÖ„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ</p>
<p><strong>„Éï„Ç£„Éº„Éâ„Éê„ÉÉ„ÇØ„ÉªË≥™Âïè</strong>:
- Email: yusuke.hashimoto.b8@tohoku.ac.jp
- GitHub: <a href="https://github.com/YusukeHashimotoPhD/AI_Homepage">AI_Homepage Repository</a></p>
<p><strong>Èñ¢ÈÄ£„Ç∑„É™„Éº„Ç∫</strong>:
- <a href="../bayesian-optimization-introduction/">„Éô„Ç§„Ç∫ÊúÄÈÅ©ÂåñÂÖ•ÈñÄ</a>
- <a href="../active-learning-introduction/">Active LearningÂÖ•ÈñÄ</a>
- <a href="../gnn-introduction/">„Ç∞„É©„Éï„Éã„É•„Éº„É©„É´„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØÂÖ•ÈñÄ</a></p><div class="navigation">
    <a href="chapter-3.html" class="nav-button">‚Üê Ââç„ÅÆÁ´†</a>
    <a href="index.html" class="nav-button">„Ç∑„É™„Éº„Ç∫ÁõÆÊ¨°„Å´Êàª„Çã</a>
</div>
    </main>

    <footer>
        <p><strong>‰ΩúÊàêËÄÖ</strong>: AI Terakoya Content Team</p>
        <p><strong>„Éê„Éº„Ç∏„Éß„É≥</strong>: 1.0 | <strong>‰ΩúÊàêÊó•</strong>: 2025-10-17</p>
        <p><strong>„É©„Ç§„Çª„É≥„Çπ</strong>: Creative Commons BY 4.0</p>
        <p>¬© 2025 AI Terakoya. All rights reserved.</p>
    </footer>
</body>
</html>
