---
title: "ç¬¬3ç« : ææ–™æ¢ç´¢ç’°å¢ƒã®æ§‹ç¯‰"
chapter_title: "ç¬¬3ç« : ææ–™æ¢ç´¢ç’°å¢ƒã®æ§‹ç¯‰"
subtitle: 
reading_time: 20-25åˆ†
difficulty: åˆç´š
code_examples: 7
exercises: 3
---

# ç¬¬3ç« : ææ–™æ¢ç´¢ç’°å¢ƒã®æ§‹ç¯‰

çŠ¶æ…‹ãƒ»è¡Œå‹•ãƒ»å ±é…¬ã®å®šç¾©ã‚’ä¾‹ã§ç¤ºã—ã€æ¢ç´¢æˆ¦ç•¥ã®çµ„ã¿ç«‹ã¦æ–¹ã‚’å…·ä½“åŒ–ã—ã¾ã™ã€‚ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿æ´»ç”¨ã®ãƒã‚¤ãƒ³ãƒˆã‚‚ç¢ºèªã—ã¾ã™ã€‚

**ğŸ’¡ è£œè¶³:** ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ã®â€œç¾å®Ÿã¨ã®ã‚ºãƒ¬â€ã‚’è¦‹ç©ã‚‚ã‚Šã€é ˜åŸŸç„¡é–¢ä¿‚å­¦ç¿’ï¼ˆDomain Randomizationï¼‰ã§é ‘å¥åŒ–ã—ã¾ã™ã€‚

## å­¦ç¿’ç›®æ¨™

ã“ã®ç« ã§ã¯ã€ä»¥ä¸‹ã‚’ç¿’å¾—ã—ã¾ã™ï¼š

  * OpenAI Gymã‚«ã‚¹ã‚¿ãƒ ç’°å¢ƒã®å®Ÿè£…æ–¹æ³•
  * ææ–™è¨˜è¿°å­ã¨çŠ¶æ…‹ç©ºé–“ã®è¨­è¨ˆ
  * åŠ¹æœçš„ãªå ±é…¬é–¢æ•°ã®è¨­è¨ˆåŸå‰‡
  * DFTè¨ˆç®—ãƒ»å®Ÿé¨“è£…ç½®ã¨ã®çµ±åˆæ–¹æ³•

* * *

## 3.1 OpenAI Gymç’°å¢ƒã®åŸºç¤

### Gymç’°å¢ƒã®æ§‹æˆè¦ç´ 

OpenAI Gymã¯ã€å¼·åŒ–å­¦ç¿’ç’°å¢ƒã®æ¨™æº–ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã§ã™ã€‚ã™ã¹ã¦ã®Gymç’°å¢ƒã¯ä»¥ä¸‹ã®ãƒ¡ã‚½ãƒƒãƒ‰ã‚’å®Ÿè£…ã—ã¾ã™ï¼š
    
    
    import gym
    import numpy as np
    
    class CustomEnv(gym.Env):
        """ã‚«ã‚¹ã‚¿ãƒ Gymç’°å¢ƒã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ"""
    
        def __init__(self):
            super(CustomEnv, self).__init__()
    
            # è¡Œå‹•ç©ºé–“ã¨è¦³æ¸¬ç©ºé–“ã®å®šç¾©ï¼ˆå¿…é ˆï¼‰
            self.action_space = gym.spaces.Discrete(4)  # é›¢æ•£è¡Œå‹•ï¼ˆ4ç¨®é¡ï¼‰
            self.observation_space = gym.spaces.Box(
                low=0, high=10, shape=(4,), dtype=np.float32
            )  # é€£ç¶šçŠ¶æ…‹ï¼ˆ4æ¬¡å…ƒã€ç¯„å›² [0, 10]ï¼‰
    
        def reset(self):
            """ç’°å¢ƒã‚’åˆæœŸçŠ¶æ…‹ã«ãƒªã‚»ãƒƒãƒˆ
    
            Returns:
                observation: åˆæœŸçŠ¶æ…‹
            """
            self.state = np.random.uniform(0, 10, 4).astype(np.float32)
            return self.state
    
        def step(self, action):
            """è¡Œå‹•ã‚’å®Ÿè¡Œã—ã€ç’°å¢ƒã‚’1ã‚¹ãƒ†ãƒƒãƒ—é€²ã‚ã‚‹
    
            Args:
                action: å®Ÿè¡Œã™ã‚‹è¡Œå‹•
    
            Returns:
                observation: æ¬¡ã®çŠ¶æ…‹
                reward: å ±é…¬
                done: ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰çµ‚äº†ãƒ•ãƒ©ã‚°
                info: è¿½åŠ æƒ…å ±ï¼ˆè¾æ›¸ï¼‰
            """
            # è¡Œå‹•ã«å¿œã˜ã¦çŠ¶æ…‹ã‚’æ›´æ–°
            self.state = self._update_state(action)
    
            # å ±é…¬ã‚’è¨ˆç®—
            reward = self._compute_reward()
    
            # çµ‚äº†æ¡ä»¶ã‚’ãƒã‚§ãƒƒã‚¯
            done = self._is_done()
    
            # è¿½åŠ æƒ…å ±
            info = {'distance': self._compute_distance()}
    
            return self.state, reward, done, info
    
        def render(self, mode='human'):
            """ç’°å¢ƒã‚’å¯è¦–åŒ–ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰"""
            print(f"Current state: {self.state}")
    
        def _update_state(self, action):
            """çŠ¶æ…‹æ›´æ–°ãƒ­ã‚¸ãƒƒã‚¯"""
            # å®Ÿè£…ã¯ç’°å¢ƒã«ã‚ˆã‚‹
            pass
    
        def _compute_reward(self):
            """å ±é…¬è¨ˆç®—ãƒ­ã‚¸ãƒƒã‚¯"""
            pass
    
        def _is_done(self):
            """çµ‚äº†æ¡ä»¶ãƒã‚§ãƒƒã‚¯"""
            pass
    
        def _compute_distance(self):
            """è¿½åŠ æƒ…å ±ã®è¨ˆç®—"""
            pass
    

### è¡Œå‹•ç©ºé–“ã¨è¦³æ¸¬ç©ºé–“ã®å®šç¾©

Gymã¯å¤šæ§˜ãªç©ºé–“ã‚¿ã‚¤ãƒ—ã‚’ã‚µãƒãƒ¼ãƒˆï¼š
    
    
    from gym import spaces
    
    # é›¢æ•£è¡Œå‹•ï¼ˆæ•´æ•° 0, 1, 2, 3ï¼‰
    action_space = spaces.Discrete(4)
    
    # é€£ç¶šè¡Œå‹•ï¼ˆå®Ÿæ•°ãƒ™ã‚¯ãƒˆãƒ« [-1, 1]^3ï¼‰
    action_space = spaces.Box(low=-1, high=1, shape=(3,), dtype=np.float32)
    
    # è¾æ›¸å½¢å¼ï¼ˆè¤‡æ•°ã®å…¥åŠ›ï¼‰
    observation_space = spaces.Dict({
        'composition': spaces.Box(low=0, high=1, shape=(10,), dtype=np.float32),
        'temperature': spaces.Box(low=0, high=1000, shape=(1,), dtype=np.float32),
        'pressure': spaces.Box(low=0, high=10, shape=(1,), dtype=np.float32)
    })
    
    # ã‚¿ãƒ—ãƒ«å½¢å¼
    action_space = spaces.Tuple((
        spaces.Discrete(5),      # å…ƒç´ é¸æŠ
        spaces.Box(low=0, high=1, shape=(1,))  # çµ„æˆæ¯”ç‡
    ))
    
    # ãƒãƒ«ãƒãƒã‚¤ãƒŠãƒªï¼ˆè¤‡æ•°ã®ãƒã‚¤ãƒŠãƒªé¸æŠï¼‰
    action_space = spaces.MultiBinary(10)  # 10å€‹ã®å…ƒç´ ã‚’ON/OFF
    

* * *

## 3.2 ææ–™è¨˜è¿°å­ã¨çŠ¶æ…‹ç©ºé–“ã®è¨­è¨ˆ

### ææ–™è¨˜è¿°å­ã®é¸æŠ

çŠ¶æ…‹ç©ºé–“ã¯ã€**ææ–™ã®ç‰¹æ€§ã‚’æ•°å€¤ãƒ™ã‚¯ãƒˆãƒ«ã§è¡¨ç¾** ã—ãŸã‚‚ã®ã§ã™ã€‚åŠ¹æœçš„ãªè¨˜è¿°å­ã®é¸æŠãŒé‡è¦ã§ã™ã€‚

#### 1\. çµ„æˆãƒ™ãƒ¼ã‚¹è¨˜è¿°å­

**å…ƒç´ å‰²åˆ** :
    
    
    # ä¾‹: Li2MnO3ã®çµ„æˆãƒ™ã‚¯ãƒˆãƒ«
    composition = {
        'Li': 2/6,   # 33.3%
        'Mn': 1/6,   # 16.7%
        'O': 3/6     # 50.0%
    }
    
    # å‘¨æœŸè¡¨å…¨ä½“ã®ãƒ™ã‚¯ãƒˆãƒ«ï¼ˆ118æ¬¡å…ƒï¼‰
    state = np.zeros(118)
    state[2] = 0.333   # Li (åŸå­ç•ªå·3)
    state[24] = 0.167  # Mn (åŸå­ç•ªå·25)
    state[7] = 0.500   # O (åŸå­ç•ªå·8)
    

**Magpieè¨˜è¿°å­** ï¼ˆWard et al., 2016ï¼‰:
    
    
    from matminer.featurizers.composition import ElementProperty
    
    featurizer = ElementProperty.from_preset("magpie")
    # çµ„æˆã‹ã‚‰132æ¬¡å…ƒã®è¨˜è¿°å­ã‚’ç”Ÿæˆ
    # - å¹³å‡åŸå­ç•ªå·ã€å¹³å‡é›»æ°—é™°æ€§åº¦ã€å¹³å‡ã‚¤ã‚ªãƒ³åŠå¾„ãªã©
    composition = "Li2MnO3"
    features = featurizer.featurize(Composition(composition))
    

#### 2\. æ§‹é€ ãƒ™ãƒ¼ã‚¹è¨˜è¿°å­

**æ ¼å­å®šæ•°** :
    
    
    # çµæ™¶æ ¼å­
    state = np.array([
        a, b, c,           # æ ¼å­å®šæ•°
        alpha, beta, gamma # è§’åº¦
    ])
    

**Smooth Overlap of Atomic Positions (SOAP)** :
    
    
    from dscribe.descriptors import SOAP
    from ase import Atoms
    
    # åŸå­æ§‹é€ ã‹ã‚‰è¨˜è¿°å­ç”Ÿæˆ
    atoms = Atoms('H2O', positions=[[0, 0, 0], [0, 0, 1], [0, 1, 0]])
    soap = SOAP(species=['H', 'O'], rcut=5.0, nmax=8, lmax=6)
    state = soap.create(atoms)  # é«˜æ¬¡å…ƒãƒ™ã‚¯ãƒˆãƒ«
    

#### 3\. ãƒ—ãƒ­ã‚»ã‚¹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿

**åˆæˆæ¡ä»¶** :
    
    
    # åˆæˆãƒ—ãƒ­ã‚»ã‚¹ã®çŠ¶æ…‹
    state = np.array([
        temperature,      # æ¸©åº¦ [K]
        pressure,         # åœ§åŠ› [Pa]
        time,             # æ™‚é–“ [s]
        heating_rate,     # æ˜‡æ¸©é€Ÿåº¦ [K/min]
        atmosphere_O2     # é…¸ç´ åˆ†åœ§ [Pa]
    ])
    

### å®Ÿä¾‹: ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—æ¢ç´¢ç’°å¢ƒ
    
    
    from pymatgen.core import Composition
    from matminer.featurizers.composition import ElementProperty
    
    class BandgapDiscoveryEnv(gym.Env):
        """ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—æœ€é©åŒ–ç’°å¢ƒ
    
        ç›®æ¨™: ç‰¹å®šã®ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—ï¼ˆä¾‹: 3.0 eVï¼‰ã‚’æŒã¤ææ–™ã‚’ç™ºè¦‹
        """
    
        def __init__(self, target_bandgap=3.0, element_pool=None):
            super(BandgapDiscoveryEnv, self).__init__()
    
            self.target_bandgap = target_bandgap
    
            # ä½¿ç”¨å¯èƒ½ãªå…ƒç´ ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: å…¸å‹çš„ãªåŠå°ä½“å…ƒç´ ï¼‰
            if element_pool is None:
                self.element_pool = ['Ti', 'Zr', 'Hf', 'V', 'Nb', 'Ta', 'Cr', 'Mo', 'W',
                                      'Mn', 'Fe', 'Co', 'Ni', 'Cu', 'Zn', 'Ga', 'Ge',
                                      'As', 'Se', 'Sr', 'Y', 'In', 'Sn', 'Sb', 'Te', 'O', 'S', 'N']
            else:
                self.element_pool = element_pool
    
            self.n_elements = len(self.element_pool)
    
            # è¡Œå‹•ç©ºé–“: 3å…ƒç´ ã‚’é¸æŠ + å„å…ƒç´ ã®æ¯”ç‡
            # ç°¡ç•¥åŒ–: 3å…ƒç´ ã®é›¢æ•£é¸æŠï¼ˆçµ„ã¿åˆã‚ã›ï¼‰
            self.action_space = gym.spaces.MultiDiscrete([self.n_elements] * 3)
    
            # çŠ¶æ…‹ç©ºé–“: Magpieè¨˜è¿°å­ï¼ˆ132æ¬¡å…ƒï¼‰
            self.featurizer = ElementProperty.from_preset("magpie")
            self.observation_space = gym.spaces.Box(
                low=-10, high=10, shape=(132,), dtype=np.float32
            )
    
            # å±¥æ­´ï¼ˆè©¦ã—ãŸçµ„æˆï¼‰
            self.history = []
            self.current_composition = None
    
        def reset(self):
            """ãƒ©ãƒ³ãƒ€ãƒ ãªåˆæœŸçµ„æˆ"""
            self.history = []
            action = self.action_space.sample()
            self.current_composition = self._action_to_composition(action)
            return self._get_state()
    
        def step(self, action):
            """æ–°ã—ã„ææ–™çµ„æˆã‚’è©¦ã™"""
            self.current_composition = self._action_to_composition(action)
    
            # çŠ¶æ…‹ï¼ˆè¨˜è¿°å­ï¼‰
            state = self._get_state()
    
            # ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—ã‚’äºˆæ¸¬ï¼ˆã‚µãƒ­ã‚²ãƒ¼ãƒˆãƒ¢ãƒ‡ãƒ« or DFTï¼‰
            predicted_bandgap = self._predict_bandgap(self.current_composition)
    
            # å ±é…¬: ç›®æ¨™ã¨ã®å·®ã®è² ã®å€¤
            error = abs(predicted_bandgap - self.target_bandgap)
            reward = -error
    
            # ãƒœãƒ¼ãƒŠã‚¹å ±é…¬ï¼ˆç›®æ¨™ã«è¿‘ã„å ´åˆï¼‰
            if error < 0.1:
                reward += 10.0  # éå¸¸ã«è¿‘ã„
    
            # å±¥æ­´ã«è¿½åŠ 
            self.history.append({
                'composition': self.current_composition,
                'bandgap': predicted_bandgap,
                'reward': reward
            })
    
            # çµ‚äº†æ¡ä»¶: ç›®æ¨™ã«åˆ°é” or æœ€å¤§ã‚¹ãƒ†ãƒƒãƒ—æ•°
            done = error < 0.05 or len(self.history) >= 100
    
            info = {
                'composition': self.current_composition,
                'predicted_bandgap': predicted_bandgap,
                'error': error
            }
    
            return state, reward, done, info
    
        def _action_to_composition(self, action):
            """è¡Œå‹•ã‚’çµ„æˆæ–‡å­—åˆ—ã«å¤‰æ›
    
            Args:
                action: [elem1_idx, elem2_idx, elem3_idx]
    
            Returns:
                çµ„æˆæ–‡å­—åˆ—ï¼ˆä¾‹: "TiO2"ï¼‰
            """
            elements = [self.element_pool[idx] for idx in action]
    
            # é‡è¤‡é™¤å»
            unique_elements = list(set(elements))
    
            # ç°¡ç•¥åŒ–: ç­‰é‡æ··åˆ
            if len(unique_elements) == 1:
                comp_str = unique_elements[0]
            elif len(unique_elements) == 2:
                comp_str = f"{unique_elements[0]}{unique_elements[1]}"
            else:
                comp_str = f"{unique_elements[0]}{unique_elements[1]}{unique_elements[2]}"
    
            return comp_str
    
        def _get_state(self):
            """ç¾åœ¨ã®çµ„æˆã‹ã‚‰è¨˜è¿°å­ã‚’ç”Ÿæˆ"""
            try:
                comp = Composition(self.current_composition)
                features = self.featurizer.featurize(comp)
                return np.array(features, dtype=np.float32)
            except:
                # ç„¡åŠ¹ãªçµ„æˆã®å ´åˆã€ã‚¼ãƒ­ãƒ™ã‚¯ãƒˆãƒ«
                return np.zeros(132, dtype=np.float32)
    
        def _predict_bandgap(self, composition):
            """ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—ã‚’äºˆæ¸¬
    
            å®Ÿéš›ã«ã¯:
            - æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ï¼ˆäº‹å‰å­¦ç¿’æ¸ˆã¿ï¼‰
            - DFTè¨ˆç®—ï¼ˆpymatgen + VASPï¼‰
            - ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¤œç´¢ï¼ˆMaterials Projectï¼‰
    
            ã“ã“ã§ã¯ç°¡æ˜“çš„ãªãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹
            """
            try:
                comp = Composition(composition)
    
                # ç°¡æ˜“ãƒ«ãƒ¼ãƒ«: é…¸ç´ ã‚’å«ã‚€åŒ–åˆç‰©ã¯ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—ãŒå¤§ãã„å‚¾å‘
                if 'O' in comp:
                    base_gap = 2.5
                elif 'S' in comp:
                    base_gap = 1.8
                elif 'N' in comp:
                    base_gap = 2.0
                else:
                    base_gap = 1.0
    
                # é‡‘å±å…ƒç´ ã®å½±éŸ¿
                metals = ['Ti', 'Zr', 'Hf', 'V', 'Nb', 'Ta']
                for metal in metals:
                    if metal in comp:
                        base_gap += 0.5
    
                # ãƒ©ãƒ³ãƒ€ãƒ ãƒã‚¤ã‚ºï¼ˆå®Ÿé¨“èª¤å·®ï¼‰
                noise = np.random.normal(0, 0.2)
                return max(0, base_gap + noise)
    
            except:
                return 0.0
    
        def render(self, mode='human'):
            print(f"Current composition: {self.current_composition}")
            if self.history:
                last = self.history[-1]
                print(f"Predicted bandgap: {last['bandgap']:.2f} eV")
                print(f"Target: {self.target_bandgap:.2f} eV")
                print(f"Reward: {last['reward']:.2f}")
    
    
    # ç’°å¢ƒã®ãƒ†ã‚¹ãƒˆ
    env = BandgapDiscoveryEnv(target_bandgap=3.0)
    
    state = env.reset()
    print(f"åˆæœŸçŠ¶æ…‹: {state.shape}")
    
    for step in range(10):
        action = env.action_space.sample()
        state, reward, done, info = env.step(action)
    
        print(f"\nStep {step+1}:")
        print(f"  çµ„æˆ: {info['composition']}")
        print(f"  äºˆæ¸¬ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—: {info['predicted_bandgap']:.2f} eV")
        print(f"  å ±é…¬: {reward:.2f}")
    
        if done:
            print("ç›®æ¨™åˆ°é”ï¼")
            break
    

**å‡ºåŠ›ä¾‹** :
    
    
    åˆæœŸçŠ¶æ…‹: (132,)
    
    Step 1:
      çµ„æˆ: TiO
      äºˆæ¸¬ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—: 3.12 eV
      å ±é…¬: -0.12
    
    Step 2:
      çµ„æˆ: ZrO
      äºˆæ¸¬ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—: 2.95 eV
      å ±é…¬: -0.05
    ç›®æ¨™åˆ°é”ï¼
    

* * *

## 3.3 åŠ¹æœçš„ãªå ±é…¬é–¢æ•°ã®è¨­è¨ˆ

### å ±é…¬è¨­è¨ˆã®åŸå‰‡

å ±é…¬é–¢æ•°ã¯ã€**ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒä½•ã‚’æœ€é©åŒ–ã™ã¹ãã‹ã‚’å®šç¾©** ã—ã¾ã™ã€‚ä¸é©åˆ‡ãªå ±é…¬ã¯ã€æœ›ã¾ãªã„è¡Œå‹•ã‚„å­¦ç¿’å¤±æ•—ã‚’å¼•ãèµ·ã“ã—ã¾ã™ã€‚

#### åŸå‰‡1: æ˜ç¢ºãªç›®æ¨™

**æ‚ªã„ä¾‹** :
    
    
    # æ›–æ˜§ãªå ±é…¬
    reward = 1 if 'good_material' else 0  # "good"ã®å®šç¾©ãŒä¸æ˜ç¢º
    

**è‰¯ã„ä¾‹** :
    
    
    # æ˜ç¢ºãªç›®æ¨™ï¼ˆãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—ï¼‰
    target = 3.0
    predicted = 2.8
    reward = -abs(predicted - target)  # ç›®æ¨™ã¨ã®è·é›¢
    

#### åŸå‰‡2: ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°

å ±é…¬ã®ç¯„å›²ã‚’é©åˆ‡ã«è¨­å®šï¼š

**æ‚ªã„ä¾‹** :
    
    
    # å ±é…¬ãŒæ¥µç«¯ã«å¤§ãã„
    reward = 1e10 if success else -1e10  # å­¦ç¿’ãŒä¸å®‰å®š
    

**è‰¯ã„ä¾‹** :
    
    
    # [-1, 1]ç¨‹åº¦ã«æ­£è¦åŒ–
    reward = -error / max_error  # error âˆˆ [0, max_error]
    

#### åŸå‰‡3: ã‚·ã‚§ã‚¤ãƒ”ãƒ³ã‚°ï¼ˆä¸­é–“å ±é…¬ï¼‰

ç–å ±é…¬ã‚’å¯†å ±é…¬ã«å¤‰æ›ï¼š

**ç–å ±é…¬ï¼ˆå­¦ç¿’ãŒå›°é›£ï¼‰** :
    
    
    reward = 1.0 if distance < 0.1 else 0.0
    

**å¯†å ±é…¬ï¼ˆå­¦ç¿’ãŒå®¹æ˜“ï¼‰** :
    
    
    # è·é›¢ã«å¿œã˜ãŸé€£ç¶šçš„ãªå ±é…¬
    reward = -distance
    
    # ã•ã‚‰ã«éšå±¤çš„ãªå ±é…¬
    if distance < 0.5:
        reward += 5.0  # è¿‘ã„
    if distance < 0.1:
        reward += 10.0  # éå¸¸ã«è¿‘ã„
    

#### åŸå‰‡4: å¤šç›®çš„æœ€é©åŒ–

è¤‡æ•°ã®ç›®æ¨™ã‚’é‡ã¿ä»˜ã‘ï¼š
    
    
    # ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—ã¨å®‰å®šæ€§ã®ä¸¡æ–¹ã‚’æœ€é©åŒ–
    bandgap_error = abs(predicted_bandgap - target_bandgap)
    stability = formation_energy  # è² ã®å€¤ãŒå®‰å®š
    
    # é‡ã¿ä»˜ãå ±é…¬
    w1, w2 = 0.7, 0.3
    reward = -w1 * bandgap_error - w2 * max(0, stability)
    

### å ±é…¬è¨­è¨ˆã®å®Ÿä¾‹

#### ä¾‹1: è§¦åª’æ´»æ€§æœ€å¤§åŒ–
    
    
    class CatalystOptimizationEnv(gym.Env):
        """è§¦åª’æ´»æ€§ã‚’æœ€å¤§åŒ–ã™ã‚‹ç’°å¢ƒ"""
    
        def _compute_reward(self, activity, selectivity, stability):
            """å¤šç›®çš„å ±é…¬
    
            Args:
                activity: è§¦åª’æ´»æ€§ï¼ˆé«˜ã„ã»ã©è‰¯ã„ï¼‰
                selectivity: é¸æŠæ€§ï¼ˆç›®çš„ç”Ÿæˆç‰©ã¸ã®é¸æŠæ€§ã€é«˜ã„ã»ã©è‰¯ã„ï¼‰
                stability: å®‰å®šæ€§ï¼ˆè² ã®å½¢æˆã‚¨ãƒãƒ«ã‚®ãƒ¼ã€ä½ã„ã»ã©å®‰å®šï¼‰
    
            Returns:
                ç·åˆå ±é…¬
            """
            # å„æŒ‡æ¨™ã‚’æ­£è¦åŒ– [0, 1]
            activity_norm = activity / 100.0  # ä»®ã«æœ€å¤§100
            selectivity_norm = selectivity  # æ—¢ã« [0, 1]
            stability_norm = -stability / 5.0  # ä»®ã«æœ€å¤§-5 eV
    
            # é‡ã¿ä»˜ãå’Œï¼ˆæ´»æ€§ã‚’é‡è¦–ï¼‰
            weights = {'activity': 0.5, 'selectivity': 0.3, 'stability': 0.2}
            reward = (weights['activity'] * activity_norm +
                      weights['selectivity'] * selectivity_norm +
                      weights['stability'] * stability_norm)
    
            # ãƒšãƒŠãƒ«ãƒ†ã‚£: ä¸å®‰å®šãªææ–™
            if stability > 0:  # æ­£ã®å½¢æˆã‚¨ãƒãƒ«ã‚®ãƒ¼ï¼ˆä¸å®‰å®šï¼‰
                reward -= 1.0
    
            return reward
    

#### ä¾‹2: åˆæˆã‚³ã‚¹ãƒˆåˆ¶ç´„
    
    
    def reward_with_cost_constraint(self, performance, synthesis_cost, max_cost=1000):
        """ã‚³ã‚¹ãƒˆåˆ¶ç´„ä»˜ãå ±é…¬
    
        Args:
            performance: ææ–™æ€§èƒ½
            synthesis_cost: åˆæˆã‚³ã‚¹ãƒˆ [USD/kg]
            max_cost: ã‚³ã‚¹ãƒˆä¸Šé™
    
        Returns:
            å ±é…¬
        """
        # æ€§èƒ½ã«åŸºã¥ãåŸºæœ¬å ±é…¬
        base_reward = performance
    
        # ã‚³ã‚¹ãƒˆåˆ¶ç´„é•åã®ãƒšãƒŠãƒ«ãƒ†ã‚£
        if synthesis_cost > max_cost:
            penalty = (synthesis_cost - max_cost) / max_cost
            base_reward -= 10.0 * penalty
    
        # ã‚³ã‚¹ãƒˆãŒä½ã„ã»ã©ãƒœãƒ¼ãƒŠã‚¹
        cost_bonus = max(0, (max_cost - synthesis_cost) / max_cost)
        base_reward += 2.0 * cost_bonus
    
        return base_reward
    

* * *

## 3.4 DFTè¨ˆç®—ã¨ã®çµ±åˆ

### Materials Projectã‹ã‚‰ã®ãƒ‡ãƒ¼ã‚¿å–å¾—

å®Ÿéš›ã®ææ–™ç‰¹æ€§ã‚’å–å¾—ã—ã€å ±é…¬ã«ä½¿ç”¨ï¼š
    
    
    from mp_api.client import MPRester
    import os
    
    class MPIntegratedEnv(gym.Env):
        """Materials Projectçµ±åˆç’°å¢ƒ"""
    
        def __init__(self, mp_api_key=None):
            super(MPIntegratedEnv, self).__init__()
    
            # Materials Project APIã‚­ãƒ¼
            if mp_api_key is None:
                mp_api_key = os.getenv("MP_API_KEY")
    
            self.mpr = MPRester(mp_api_key)
    
            # ... (ç’°å¢ƒè¨­å®š) ...
    
        def _get_bandgap_from_mp(self, composition):
            """Materials Projectã‹ã‚‰ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—ã‚’å–å¾—
    
            Args:
                composition: çµ„æˆï¼ˆä¾‹: "TiO2"ï¼‰
    
            Returns:
                ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ— [eV]ï¼ˆãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã¯Noneï¼‰
            """
            try:
                # çµ„æˆã§æ¤œç´¢
                docs = self.mpr.materials.summary.search(
                    formula=composition,
                    fields=["material_id", "band_gap", "formation_energy_per_atom"]
                )
    
                if docs:
                    # æœ€ã‚‚å®‰å®šãªæ§‹é€ ï¼ˆå½¢æˆã‚¨ãƒãƒ«ã‚®ãƒ¼ãŒæœ€å°ï¼‰ã‚’é¸æŠ
                    stable_doc = min(docs, key=lambda x: x.formation_energy_per_atom)
                    return stable_doc.band_gap
                else:
                    return None
    
            except Exception as e:
                print(f"Materials Projectæ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
                return None
    
        def step(self, action):
            composition = self._action_to_composition(action)
    
            # Materials Projectã‹ã‚‰ãƒ‡ãƒ¼ã‚¿å–å¾—
            bandgap = self._get_bandgap_from_mp(composition)
    
            if bandgap is not None:
                # å®Ÿãƒ‡ãƒ¼ã‚¿ã§å ±é…¬è¨ˆç®—
                error = abs(bandgap - self.target_bandgap)
                reward = -error
            else:
                # ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã€äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ or ãƒšãƒŠãƒ«ãƒ†ã‚£
                reward = -10.0  # æœªçŸ¥ã®ææ–™ã¸ã®ãƒšãƒŠãƒ«ãƒ†ã‚£
    
            # ... (çŠ¶æ…‹ã€çµ‚äº†æ¡ä»¶ãªã©) ...
    
            return state, reward, done, info
    

**æ³¨æ„** : Materials Projectã¸ã®å¤§é‡ãƒªã‚¯ã‚¨ã‚¹ãƒˆã¯é¿ã‘ã€ãƒ­ãƒ¼ã‚«ãƒ«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’æ´»ç”¨ã—ã¦ãã ã•ã„ã€‚

### ASEã«ã‚ˆã‚‹DFTè¨ˆç®—çµ±åˆï¼ˆé«˜åº¦ï¼‰
    
    
    from ase import Atoms
    from ase.calculators.vasp import Vasp
    from ase.optimize import BFGS
    
    class DFTIntegratedEnv(gym.Env):
        """DFTè¨ˆç®—çµ±åˆç’°å¢ƒï¼ˆè¨ˆç®—ã‚³ã‚¹ãƒˆå¤§ï¼‰"""
    
        def _calculate_bandgap_dft(self, composition):
            """DFTè¨ˆç®—ã§ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—ã‚’å–å¾—
    
            è­¦å‘Š: éå¸¸ã«æ™‚é–“ãŒã‹ã‹ã‚‹ï¼ˆ1ææ–™ã‚ãŸã‚Šæ•°æ™‚é–“ã€œæ•°æ—¥ï¼‰
            å®Ÿç”¨çš„ã«ã¯äº‹å‰è¨ˆç®—ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ä½¿ç”¨
    
            Args:
                composition: çµ„æˆ
    
            Returns:
                ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ— [eV]
            """
            # çµæ™¶æ§‹é€ ã‚’ç”Ÿæˆï¼ˆpymatgenãªã©ã§ï¼‰
            structure = self._generate_structure(composition)
    
            # ASE Atomsã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«å¤‰æ›
            atoms = Atoms(
                symbols=structure.species,
                positions=structure.cart_coords,
                cell=structure.lattice.matrix,
                pbc=True
            )
    
            # VASPè¨ˆç®—è¨­å®š
            calc = Vasp(
                xc='PBE',
                encut=520,
                kpts=(4, 4, 4),
                ismear=0,
                sigma=0.05,
                directory='vasp_calc'
            )
            atoms.calc = calc
    
            # æ§‹é€ æœ€é©åŒ–
            opt = BFGS(atoms)
            opt.run(fmax=0.05)
    
            # ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—è¨ˆç®—
            # ... (VASPã®OUTCARè§£æ) ...
    
            return bandgap
    
        def step(self, action):
            # DFTè¨ˆç®—ã¯æ™‚é–“ãŒã‹ã‹ã‚‹ãŸã‚ã€
            # å®Ÿéš›ã«ã¯ä»¥ä¸‹ã®ã‚ˆã†ãªå·¥å¤«ãŒå¿…è¦:
            # 1. äº‹å‰è¨ˆç®—ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’æ§‹ç¯‰
            # 2. ã‚µãƒ­ã‚²ãƒ¼ãƒˆãƒ¢ãƒ‡ãƒ«ã§é«˜é€Ÿäºˆæ¸¬
            # 3. ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ã§é‡è¦ãªææ–™ã®ã¿DFTè¨ˆç®—
            pass
    

**å®Ÿç”¨çš„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ** : 1\. **äº‹å‰å­¦ç¿’** : Materials Projectãªã©ã®ãƒ‡ãƒ¼ã‚¿ã§ã‚µãƒ­ã‚²ãƒ¼ãƒˆãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ 2\. **å¼·åŒ–å­¦ç¿’** : ã‚µãƒ­ã‚²ãƒ¼ãƒˆãƒ¢ãƒ‡ãƒ«ã§é«˜é€Ÿæ¢ç´¢ 3\. **æ¤œè¨¼** : æœ‰æœ›ãªææ–™ã®ã¿DFTè¨ˆç®—ã§ç²¾å¯†è©•ä¾¡

* * *

## 3.5 å®Ÿé¨“è£…ç½®ã¨ã®çµ±åˆï¼ˆã‚¯ãƒ­ãƒ¼ã‚ºãƒ‰ãƒ«ãƒ¼ãƒ—ï¼‰

### REST APIã«ã‚ˆã‚‹è‡ªå‹•å®Ÿé¨“è£…ç½®åˆ¶å¾¡
    
    
    import requests
    
    class RoboticLabEnv(gym.Env):
        """ãƒ­ãƒœãƒƒãƒˆå®Ÿé¨“è£…ç½®çµ±åˆç’°å¢ƒ"""
    
        def __init__(self, api_endpoint="http://lab-robot.example.com/api"):
            super(RoboticLabEnv, self).__init__()
            self.api_endpoint = api_endpoint
    
            # ... (ç’°å¢ƒè¨­å®š) ...
    
        def _synthesize_and_measure(self, composition, temperature, time):
            """ææ–™ã‚’åˆæˆã—ã€ç‰¹æ€§ã‚’æ¸¬å®š
    
            Args:
                composition: çµ„æˆ
                temperature: åˆæˆæ¸©åº¦ [K]
                time: åˆæˆæ™‚é–“ [min]
    
            Returns:
                æ¸¬å®šçµæœï¼ˆãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—ã€XRDãƒ‘ã‚¿ãƒ¼ãƒ³ãªã©ï¼‰
            """
            # ãƒ­ãƒœãƒƒãƒˆã«åˆæˆãƒªã‚¯ã‚¨ã‚¹ãƒˆ
            payload = {
                'composition': composition,
                'temperature': temperature,
                'time': time,
                'measurement': ['bandgap', 'xrd']
            }
    
            response = requests.post(
                f"{self.api_endpoint}/synthesize",
                json=payload,
                headers={'Authorization': 'Bearer YOUR_API_KEY'}
            )
    
            if response.status_code == 200:
                result = response.json()
                return result['bandgap'], result['xrd_pattern']
            else:
                raise Exception(f"å®Ÿé¨“å¤±æ•—: {response.text}")
    
        def step(self, action):
            """è¡Œå‹• = åˆæˆæ¡ä»¶"""
            composition, temperature, time = self._decode_action(action)
    
            # å®Ÿé¨“å®Ÿè¡Œï¼ˆæ•°åˆ†ã€œæ•°æ™‚é–“ï¼‰
            bandgap, xrd = self._synthesize_and_measure(composition, temperature, time)
    
            # å ±é…¬è¨ˆç®—
            reward = -abs(bandgap - self.target_bandgap)
    
            # çŠ¶æ…‹æ›´æ–°ï¼ˆå®Ÿé¨“å±¥æ­´ã‚’å«ã‚€ï¼‰
            state = self._update_state(composition, temperature, time, bandgap, xrd)
    
            done = len(self.history) >= self.max_experiments
    
            return state, reward, done, {'bandgap': bandgap}
    

**èª²é¡Œ** : \- **å®Ÿé¨“ã‚³ã‚¹ãƒˆ** : 1å›ã‚ãŸã‚Šæ•°åƒå††ã€œæ•°ä¸‡å†† \- **æ™‚é–“** : åˆæˆãƒ»æ¸¬å®šã«æ•°æ™‚é–“ã€œæ•°æ—¥ \- **å®‰å…¨æ€§** : ãƒ­ãƒœãƒƒãƒˆã®èª¤ä½œå‹•ã€å±é™ºç‰©è³ªã®æ‰±ã„

**è§£æ±ºç­–** : \- **ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å…ˆè¡Œ** : ã‚µãƒ­ã‚²ãƒ¼ãƒˆãƒ¢ãƒ‡ãƒ«ã§äº‹å‰æ¢ç´¢ \- **ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ä½µç”¨** : åŠ¹ç‡çš„ãªå®Ÿé¨“ç‚¹é¸æŠ \- **ãƒãƒƒãƒå®Ÿé¨“** : ä¸¦åˆ—ã§è¤‡æ•°ææ–™ã‚’åˆæˆ

* * *

## æ¼”ç¿’å•é¡Œ

### å•é¡Œ1 (é›£æ˜“åº¦: easy)

ä»¥ä¸‹ã®2ã¤ã®å ±é…¬é–¢æ•°ã®é•ã„ã‚’èª¬æ˜ã—ã€ã©ã¡ã‚‰ãŒå­¦ç¿’ã—ã‚„ã™ã„ã‹ç†ç”±ã¨ã¨ã‚‚ã«ç­”ãˆã¦ãã ã•ã„ã€‚

**å ±é…¬A** :
    
    
    reward = 10.0 if abs(bandgap - 3.0) < 0.1 else 0.0
    

**å ±é…¬B** :
    
    
    reward = -abs(bandgap - 3.0)
    

ãƒ’ãƒ³ãƒˆ å ±é…¬Aã¯ç–å ±é…¬ã€å ±é…¬Bã¯å¯†å ±é…¬ã§ã™ã€‚å­¦ç¿’ã‚·ã‚°ãƒŠãƒ«ã®é »åº¦ã‚’è€ƒãˆã¦ã¿ã¾ã—ã‚‡ã†ã€‚  è§£ç­”ä¾‹ **å ±é…¬Aã®ç‰¹å¾´**: \- **ç–å ±é…¬**: ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—ãŒ2.9ã€œ3.1 eVã®ç¯„å›²ã«å…¥ã£ãŸã¨ãã®ã¿å ±é…¬10.0ã€ãã‚Œä»¥å¤–ã¯0.0 \- **å­¦ç¿’ãŒå›°é›£**: ã»ã¨ã‚“ã©ã®æ¢ç´¢ã§å ±é…¬0ã€ã©ã®æ–¹å‘ã«é€²ã‚ã°è‰¯ã„ã‹ã‚ã‹ã‚‰ãªã„ \- **æ¢ç´¢ãŒéåŠ¹ç‡**: ãƒ©ãƒ³ãƒ€ãƒ æ¢ç´¢ã«è¿‘ããªã‚‹ **å ±é…¬Bã®ç‰¹å¾´**: \- **å¯†å ±é…¬**: ã™ã¹ã¦ã®è¡Œå‹•ã§å ±é…¬ãŒå¾—ã‚‰ã‚Œã‚‹ï¼ˆç›®æ¨™ã¨ã®è·é›¢ï¼‰ \- **å­¦ç¿’ãŒå®¹æ˜“**: ç›®æ¨™ã«è¿‘ã¥ãã¨å ±é…¬ãŒæ”¹å–„ã™ã‚‹ãŸã‚ã€å‹¾é…ãŒæ˜ç¢º \- **æ¢ç´¢ãŒåŠ¹ç‡çš„**: å ±é…¬ã®å¤‰åŒ–ã‹ã‚‰å­¦ç¿’ã§ãã‚‹ **çµè«–**: **å ±é…¬Bã®æ–¹ãŒå­¦ç¿’ã—ã‚„ã™ã„** ãŸã ã—ã€å ±é…¬Bã«ã¯å±€æ‰€æœ€é©è§£ã«é™¥ã‚Šã‚„ã™ã„ã¨ã„ã†æ¬ ç‚¹ã‚‚ã‚ã‚Šã¾ã™ã€‚å®Ÿç”¨çš„ã«ã¯ã€å ±é…¬Bã‚’ãƒ™ãƒ¼ã‚¹ã«ã€å ±é…¬Aã®ã‚ˆã†ãªãƒœãƒ¼ãƒŠã‚¹ã‚’è¿½åŠ ã™ã‚‹ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰è¨­è¨ˆãŒæœ‰åŠ¹ã§ã™ã€‚ 
    
    
    # ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰å ±é…¬
    reward = -abs(bandgap - 3.0)  # å¯†å ±é…¬
    if abs(bandgap - 3.0) < 0.1:
        reward += 10.0  # ãƒœãƒ¼ãƒŠã‚¹ï¼ˆç–å ±é…¬ã®è¦ç´ ï¼‰
    

* * *

### å•é¡Œ2 (é›£æ˜“åº¦: medium)

ææ–™æ¢ç´¢ã«ãŠã„ã¦ã€ä»¥ä¸‹ã®3ã¤ã®çŠ¶æ…‹è¡¨ç¾ã‚’æ¯”è¼ƒã—ã€ãã‚Œãã‚Œã®é•·æ‰€ãƒ»çŸ­æ‰€ã‚’è¿°ã¹ã¦ãã ã•ã„ã€‚

  1. **çµ„æˆã®ã¿** : `["Li2MnO3"]`ï¼ˆæ–‡å­—åˆ—ï¼‰
  2. **å…ƒç´ å‰²åˆ** : `[0.33, 0.17, 0.50]`ï¼ˆLi, Mn, Oã®å‰²åˆï¼‰
  3. **Magpieè¨˜è¿°å­** : 132æ¬¡å…ƒãƒ™ã‚¯ãƒˆãƒ«ï¼ˆå¹³å‡åŸå­ç•ªå·ã€é›»æ°—é™°æ€§åº¦ãªã©ï¼‰

ãƒ’ãƒ³ãƒˆ ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã¯æ•°å€¤å…¥åŠ›ã‚’å¿…è¦ã¨ã—ã¾ã™ã€‚ã¾ãŸã€è¨˜è¿°å­ã®æ¬¡å…ƒæ•°ã¨å­¦ç¿’ã®è¤‡é›‘ã•ã®é–¢ä¿‚ã‚’è€ƒãˆã¦ã¿ã¾ã—ã‚‡ã†ã€‚  è§£ç­”ä¾‹ **1. çµ„æˆæ–‡å­—åˆ—ã®é•·æ‰€ãƒ»çŸ­æ‰€**: **é•·æ‰€**: \- äººé–“ãŒç†è§£ã—ã‚„ã™ã„ \- ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¤œç´¢ã«ç›´æ¥ä½¿ç”¨å¯èƒ½ **çŸ­æ‰€**: \- ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã«ç›´æ¥å…¥åŠ›ã§ããªã„ï¼ˆæ•°å€¤å¤‰æ›ãŒå¿…è¦ï¼‰ \- é¡ä¼¼çµ„æˆã®é–¢ä¿‚æ€§ã‚’æ‰ãˆã«ãã„ï¼ˆ"TiO2"ã¨"ZrO2"ãŒä¼¼ã¦ã„ã‚‹ã“ã¨ã‚’å­¦ç¿’ã—ã«ãã„ï¼‰ **2. å…ƒç´ å‰²åˆã®é•·æ‰€ãƒ»çŸ­æ‰€**: **é•·æ‰€**: \- æ•°å€¤ãƒ™ã‚¯ãƒˆãƒ«ãªã®ã§NNã«å…¥åŠ›å¯èƒ½ \- ä½æ¬¡å…ƒï¼ˆ3æ¬¡å…ƒãªã©ï¼‰ã§æ‰±ã„ã‚„ã™ã„ **çŸ­æ‰€**: \- å…ƒç´ ã®åŒ–å­¦çš„æ€§è³ªã‚’åæ˜ ã—ãªã„ï¼ˆTiã¨ZrãŒä¼¼ã¦ã„ã‚‹ã“ã¨ã‚’è¡¨ç¾ã§ããªã„ï¼‰ \- å…ƒç´ ã®é †åºãŒä»»æ„ï¼ˆ[Li, Mn, O]ã¨[O, Mn, Li]ãŒç•°ãªã‚‹ãƒ™ã‚¯ãƒˆãƒ«ã«ãªã‚‹ï¼‰ **3. Magpieè¨˜è¿°å­ã®é•·æ‰€ãƒ»çŸ­æ‰€**: **é•·æ‰€**: \- å…ƒç´ ã®åŒ–å­¦çš„æ€§è³ªã‚’åæ˜ ï¼ˆé›»æ°—é™°æ€§åº¦ã€ã‚¤ã‚ªãƒ³åŠå¾„ãªã©ï¼‰ \- é¡ä¼¼çµ„æˆãŒä¼¼ãŸãƒ™ã‚¯ãƒˆãƒ«ã«ãªã‚‹ \- æ©Ÿæ¢°å­¦ç¿’ã§é«˜ã„äºˆæ¸¬æ€§èƒ½ **çŸ­æ‰€**: \- é«˜æ¬¡å…ƒï¼ˆ132æ¬¡å…ƒï¼‰ã§å­¦ç¿’ãŒè¤‡é›‘ \- è§£é‡ˆæ€§ãŒä½ã„ï¼ˆã©ã®æ¬¡å…ƒãŒä½•ã‚’è¡¨ã™ã‹ç›´æ„Ÿçš„ã§ãªã„ï¼‰ **æ¨å¥¨**: \- **åˆæœŸæ¢ç´¢**: Magpieè¨˜è¿°å­ï¼ˆæ±ç”¨æ€§ãŒé«˜ã„ï¼‰ \- **ç‰¹å®šã‚¿ã‚¹ã‚¯**: ã‚¿ã‚¹ã‚¯å°‚ç”¨ã®è¨˜è¿°å­ï¼ˆä¾‹: è§¦åª’ãªã‚‰dè»Œé“å æœ‰æ•°ï¼‰ \- **ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰**: çµ„æˆ + ãƒ—ãƒ­ã‚»ã‚¹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ 

* * *

### å•é¡Œ3 (é›£æ˜“åº¦: hard)

ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—æ¢ç´¢ç’°å¢ƒã«ãŠã„ã¦ã€ä»¥ä¸‹ã®æ”¹å–„ã‚’å®Ÿè£…ã—ã¦ãã ã•ã„ï¼š

  1. **å±¥æ­´ã‚’è€ƒæ…®ã—ãŸçŠ¶æ…‹** : ã“ã‚Œã¾ã§è©¦ã—ãŸææ–™ã®æƒ…å ±ã‚’çŠ¶æ…‹ã«å«ã‚ã‚‹
  2. **æ¢ç´¢ãƒœãƒ¼ãƒŠã‚¹** : æœªçŸ¥ã®é ˜åŸŸã‚’æ¢ç´¢ã—ãŸå ´åˆã«è¿½åŠ å ±é…¬
  3. **æ—©æœŸçµ‚äº†** : 10ã‚¹ãƒ†ãƒƒãƒ—é€£ç¶šã§æ”¹å–„ãŒãªã„å ´åˆã€ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰çµ‚äº†

ãƒ’ãƒ³ãƒˆ å±¥æ­´ã¯è¾æ›¸å½¢å¼ã§ä¿å­˜ã—ã€çŠ¶æ…‹ã«ã¯ã€Œæœ€è‰¯ææ–™ã¨ã®è·é›¢ã€ãªã©ã‚’è¿½åŠ ã—ã¾ã™ã€‚æ¢ç´¢ãƒœãƒ¼ãƒŠã‚¹ã¯ã€éå»ã®ææ–™ã¨ã®é¡ä¼¼åº¦ã§è¨ˆç®—ã§ãã¾ã™ã€‚  è§£ç­”ä¾‹
    
    
    import numpy as np
    from scipy.spatial.distance import euclidean
    
    class ImprovedBandgapEnv(gym.Env):
        """æ”¹å–„ç‰ˆãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—æ¢ç´¢ç’°å¢ƒ"""
    
        def __init__(self, target_bandgap=3.0):
            super(ImprovedBandgapEnv, self).__init__()
    
            self.target_bandgap = target_bandgap
    
            # è¡Œå‹•ãƒ»çŠ¶æ…‹ç©ºé–“ï¼ˆç°¡ç•¥åŒ–ï¼‰
            self.action_space = gym.spaces.Box(low=0, high=1, shape=(10,), dtype=np.float32)
            self.observation_space = gym.spaces.Box(low=-10, high=10, shape=(15,), dtype=np.float32)
    
            # å±¥æ­´
            self.history = []
            self.best_error = float('inf')
            self.no_improvement_count = 0
    
        def reset(self):
            self.history = []
            self.best_error = float('inf')
            self.no_improvement_count = 0
    
            initial_state = self._get_state(np.random.uniform(0, 1, 10))
            return initial_state
    
        def step(self, action):
            # ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—äºˆæ¸¬ï¼ˆç°¡æ˜“ãƒ¢ãƒ‡ãƒ«ï¼‰
            predicted_bandgap = np.sum(action) * 3.0  # ä»®ã®äºˆæ¸¬
    
            # èª¤å·®
            error = abs(predicted_bandgap - self.target_bandgap)
    
            # åŸºæœ¬å ±é…¬
            reward = -error
    
            # æ”¹å–„1: å±¥æ­´ã‚’è€ƒæ…®ã—ãŸçŠ¶æ…‹
            state = self._get_state(action)
    
            # æ”¹å–„2: æ¢ç´¢ãƒœãƒ¼ãƒŠã‚¹
            exploration_bonus = self._compute_exploration_bonus(action)
            reward += 0.1 * exploration_bonus
    
            # æ”¹å–„3: æ—©æœŸçµ‚äº†
            if error < self.best_error:
                self.best_error = error
                self.no_improvement_count = 0
            else:
                self.no_improvement_count += 1
    
            done = error < 0.05 or self.no_improvement_count >= 10 or len(self.history) >= 100
    
            # å±¥æ­´ã«è¿½åŠ 
            self.history.append({
                'action': action,
                'bandgap': predicted_bandgap,
                'error': error
            })
    
            info = {'bandgap': predicted_bandgap, 'exploration_bonus': exploration_bonus}
    
            return state, reward, done, info
    
        def _get_state(self, action):
            """å±¥æ­´ã‚’è€ƒæ…®ã—ãŸçŠ¶æ…‹
    
            çŠ¶æ…‹æ§‹æˆ:
            - ç¾åœ¨ã®è¡Œå‹•ï¼ˆ10æ¬¡å…ƒï¼‰
            - æœ€è‰¯ææ–™ã¨ã®è·é›¢ï¼ˆ1æ¬¡å…ƒï¼‰
            - å±¥æ­´ã‚µã‚¤ã‚ºï¼ˆ1æ¬¡å…ƒï¼‰
            - æ”¹å–„ãªã—é€£ç¶šå›æ•°ï¼ˆ1æ¬¡å…ƒï¼‰
            - å¹³å‡èª¤å·®ï¼ˆ1æ¬¡å…ƒï¼‰
            - æœ€è‰¯èª¤å·®ï¼ˆ1æ¬¡å…ƒï¼‰
            """
            state = np.zeros(15, dtype=np.float32)
    
            # ç¾åœ¨ã®è¡Œå‹•
            state[:10] = action
    
            # æœ€è‰¯ææ–™ã¨ã®è·é›¢
            if self.history:
                best_action = min(self.history, key=lambda x: x['error'])['action']
                state[10] = euclidean(action, best_action) / 10.0  # æ­£è¦åŒ–
            else:
                state[10] = 1.0
    
            # å±¥æ­´ã‚µã‚¤ã‚º
            state[11] = len(self.history) / 100.0  # æ­£è¦åŒ–
    
            # æ”¹å–„ãªã—é€£ç¶šå›æ•°
            state[12] = self.no_improvement_count / 10.0
    
            # å¹³å‡èª¤å·®
            if self.history:
                state[13] = np.mean([h['error'] for h in self.history])
            else:
                state[13] = 10.0
    
            # æœ€è‰¯èª¤å·®
            state[14] = self.best_error
    
            return state
    
        def _compute_exploration_bonus(self, action):
            """æ¢ç´¢ãƒœãƒ¼ãƒŠã‚¹
    
            éå»ã®è¡Œå‹•ã¨é›¢ã‚Œã¦ã„ã‚‹ã»ã©é«˜ã„ãƒœãƒ¼ãƒŠã‚¹
            """
            if not self.history:
                return 1.0  # æœ€åˆã¯å¸¸ã«æ¢ç´¢
    
            # éå»ã®è¡Œå‹•ã¨ã®æœ€å°è·é›¢
            min_distance = min(
                euclidean(action, h['action'])
                for h in self.history
            )
    
            # è·é›¢ãŒå¤§ãã„ã»ã©ãƒœãƒ¼ãƒŠã‚¹ï¼ˆæœ€å¤§1.0ï¼‰
            bonus = min(1.0, min_distance / 5.0)
    
            return bonus
    
    
    # ãƒ†ã‚¹ãƒˆ
    env = ImprovedBandgapEnv()
    state = env.reset()
    
    for step in range(50):
        action = env.action_space.sample()
        state, reward, done, info = env.step(action)
    
        print(f"Step {step+1}: Bandgap={info['bandgap']:.2f}, "
              f"Reward={reward:.2f}, Exploration={info['exploration_bonus']:.2f}")
    
        if done:
            print(f"çµ‚äº†: æœ€è‰¯èª¤å·®={env.best_error:.4f}, "
                  f"æ”¹å–„ãªã—é€£ç¶š={env.no_improvement_count}å›")
            break
    

**ãƒã‚¤ãƒ³ãƒˆ**: \- å±¥æ­´æƒ…å ±ã‚’çŠ¶æ…‹ã«å«ã‚ã‚‹ã“ã¨ã§ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒéå»ã®çµŒé¨“ã‚’æ´»ç”¨ \- æ¢ç´¢ãƒœãƒ¼ãƒŠã‚¹ã«ã‚ˆã‚Šã€æœªçŸ¥é ˜åŸŸã®æ¢ç´¢ã‚’ä¿ƒé€² \- æ—©æœŸçµ‚äº†ã«ã‚ˆã‚Šã€ç„¡é§„ãªæ¢ç´¢ã‚’å‰Šæ¸› 

* * *

## ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®ã¾ã¨ã‚

  * **OpenAI Gym** ã¯å¼·åŒ–å­¦ç¿’ç’°å¢ƒã®æ¨™æº–ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
  * **çŠ¶æ…‹ç©ºé–“** ã¯ææ–™è¨˜è¿°å­ã§è¨­è¨ˆï¼ˆçµ„æˆã€æ§‹é€ ã€ãƒ—ãƒ­ã‚»ã‚¹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼‰
  * **å ±é…¬é–¢æ•°** ã¯æ˜ç¢ºãªç›®æ¨™ã€é©åˆ‡ãªã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã€ä¸­é–“å ±é…¬ãŒé‡è¦
  * **DFTçµ±åˆ** ã¯ã‚µãƒ­ã‚²ãƒ¼ãƒˆãƒ¢ãƒ‡ãƒ«ã§é«˜é€ŸåŒ–ã—ã€é‡è¦ãªææ–™ã®ã¿ç²¾å¯†è¨ˆç®—
  * **å®Ÿé¨“è£…ç½®çµ±åˆ** ã¯REST APIã§ã‚¯ãƒ­ãƒ¼ã‚ºãƒ‰ãƒ«ãƒ¼ãƒ—æœ€é©åŒ–ã‚’å®Ÿç¾

æ¬¡ç« ã§ã¯ã€åŒ–å­¦ãƒ—ãƒ­ã‚»ã‚¹åˆ¶å¾¡ã‚„åˆæˆçµŒè·¯è¨­è¨ˆãªã©ã€å®Ÿä¸–ç•Œã§ã®å¿œç”¨äº‹ä¾‹ã‚’å­¦ã³ã¾ã™ã€‚

* * *

## å‚è€ƒæ–‡çŒ®

  1. Brockman et al. "OpenAI Gym" _arXiv_ (2016) - Gymç’°å¢ƒã®æ¨™æº–
  2. Ward et al. "A general-purpose machine learning framework for predicting properties of inorganic materials" _npj Computational Materials_ (2016) - Magpieè¨˜è¿°å­
  3. Brockherde et al. "Bypassing the Kohn-Sham equations with machine learning" _Nature Communications_ (2017) - DFTåŠ é€Ÿ
  4. Ng et al. "Policy invariance under reward transformations" _ICML_ (1999) - å ±é…¬ã‚·ã‚§ã‚¤ãƒ”ãƒ³ã‚°ç†è«–

* * *

**æ¬¡ç« ** : ç¬¬4ç« : å®Ÿä¸–ç•Œå¿œç”¨ã¨ã‚¯ãƒ­ãƒ¼ã‚ºãƒ‰ãƒ«ãƒ¼ãƒ—ï¼ˆæº–å‚™ä¸­ï¼‰
