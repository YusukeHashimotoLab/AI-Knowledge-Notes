#!/usr/bin/env python3
"""
Complete translation for NM Chapter 3
Comprehensive Japanese to English translation
"""

import re
from pathlib import Path

JP_FILE = "/Users/yusukehashimoto/Documents/pycharm/AI_Homepage/wp/knowledge/jp/MI/nm-introduction/chapter3-hands-on.html"
EN_FILE = "/Users/yusukehashimoto/Documents/pycharm/AI_Homepage/wp/knowledge/en/MI/nm-introduction/chapter3-hands-on.html"

def create_comprehensive_translations():
    """Create comprehensive translation dictionary"""

    translations = {
        # HTML attributes
        '<html lang="ja">': '<html lang="en">',

        # Title and meta
        '<title>Chapter 3: Pythonå®Ÿè·µãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ« - AI Terakoya</title>':
            '<title>Chapter 3: Hands-On Python Tutorial - AI Terakoya</title>',

        # Breadcrumb
        'AIå¯ºå­å±‹ãƒˆãƒƒãƒ—': 'AI Terakoya Top',
        'ãƒãƒ†ãƒªã‚¢ãƒ«ã‚ºãƒ»ã‚¤ãƒ³ãƒ•ã‚©ãƒãƒ†ã‚£ã‚¯ã‚¹': 'Materials Informatics',

        # Header
        'Chapter 3: Pythonå®Ÿè·µãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«': 'Chapter 3: Hands-On Python Tutorial',
        'ãƒŠãƒææ–™ãƒ‡ãƒ¼ã‚¿è§£æã¨æ©Ÿæ¢°å­¦ç¿’': 'Nanomaterial Data Analysis and Machine Learning',
        'èª­äº†æ™‚é–“: 30-40åˆ†': 'Reading Time: 30-40 min',
        'é›£æ˜“åº¦: åˆç´š': 'Difficulty: Beginner',
        'ã‚³ãƒ¼ãƒ‰ä¾‹: 0å€‹': 'Code Examples: 0',
        'æ¼”ç¿’å•é¡Œ: 0å•': 'Exercises: 0',

        # Chapter description
        'å°è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã§ã‚‚åŠ¹ãå›å¸°ãƒ¢ãƒ‡ãƒ«ã¨ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã§ã€åŠ¹ç‡ã‚ˆãæ¡ä»¶æ¢ç´¢ã™ã‚‹ç­‹è‚‰ã‚’ä»˜ã‘ã¾ã™ã€‚MDãƒ‡ãƒ¼ã‚¿ã®è¦ç‚¹å¯è¦–åŒ–ã¨SHAPã«ã‚ˆã‚‹è§£é‡ˆã¾ã§ä¸€æ°—ã«é€šã—ã¾ã™ã€‚':
            'Build skills for efficiently exploring conditions using regression models effective even with small datasets and Bayesian optimization. Covers essential visualization of MD data and interpretation with SHAP in one go.',
        'ğŸ’¡ è£œè¶³:': 'ğŸ’¡ Supplement:',
        'å°‘ãªã„è©¦è¡Œã§è‰¯ã„æ¡ä»¶ã‚’è¦‹ã¤ã‘ã‚‹ã®ãŒç›®æ¨™ã€‚ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã¯"é‡‘å±æ¢çŸ¥æ©Ÿ"çš„ã«å½“ãŸã‚Šã‚’å°ãã¾ã™ã€‚':
            'The goal is to find good conditions with minimal trials. Bayesian optimization guides you to hits like a "metal detector".',

        # Learning objectives
        'æœ¬ç« ã®å­¦ç¿’ç›®æ¨™': 'Learning Objectives',
        'æœ¬ç« ã‚’å­¦ç¿’ã™ã‚‹ã“ã¨ã§ã€ä»¥ä¸‹ã®ã‚¹ã‚­ãƒ«ã‚’ç¿’å¾—ã§ãã¾ã™ï¼š': 'By studying this chapter, you will acquire the following skills:',
        'ãƒŠãƒç²’å­ãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆãƒ»å¯è¦–åŒ–ãƒ»å‰å‡¦ç†ã®å®Ÿè·µ': 'Hands-on nanoparticle data generation, visualization, and preprocessing',
        '5ç¨®é¡ã®å›å¸°ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹ãƒŠãƒææ–™ç‰©æ€§äºˆæ¸¬': 'Prediction of nanomaterial properties using 5 types of regression models',
        'ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã«ã‚ˆã‚‹ãƒŠãƒææ–™ã®æœ€é©è¨­è¨ˆ': 'Optimal design of nanomaterials through Bayesian optimization',
        'SHAPåˆ†æã«ã‚ˆã‚‹æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®è§£é‡ˆ': 'Interpretation of machine learning models using SHAP analysis',
        'å¤šç›®çš„æœ€é©åŒ–ã«ã‚ˆã‚‹ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•åˆ†æ': 'Trade-off analysis through multi-objective optimization',
        'TEMç”»åƒè§£æã¨ã‚µã‚¤ã‚ºåˆ†å¸ƒã®ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°': 'TEM image analysis and size distribution fitting',
        'ç•°å¸¸æ¤œçŸ¥ã«ã‚ˆã‚‹å“è³ªç®¡ç†ã¸ã®å¿œç”¨': 'Application to quality control through anomaly detection',

        # Main sections
        '3.1 ç’°å¢ƒæ§‹ç¯‰': '3.1 Environment Setup',
        '3.2 ãƒŠãƒç²’å­ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™ã¨å¯è¦–åŒ–': '3.2 Nanoparticle Data Preparation and Visualization',
        '3.3 å‰å‡¦ç†ã¨ãƒ‡ãƒ¼ã‚¿åˆ†å‰²': '3.3 Preprocessing and Data Splitting',
        '3.4 å›å¸°ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹ãƒŠãƒç²’å­ç‰©æ€§äºˆæ¸¬': '3.4 Predicting Nanoparticle Properties with Regression Models',
        '3.5 é‡å­ãƒ‰ãƒƒãƒˆç™ºå…‰æ³¢é•·äºˆæ¸¬': '3.5 Quantum Dot Emission Wavelength Prediction',
        '3.6 ç‰¹å¾´é‡é‡è¦åº¦åˆ†æ': '3.6 Feature Importance Analysis',
        '3.7 ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã«ã‚ˆã‚‹ãƒŠãƒææ–™è¨­è¨ˆ': '3.7 Nanomaterial Design with Bayesian Optimization',
        '3.8 å¤šç›®çš„æœ€é©åŒ–ï¼šã‚µã‚¤ã‚ºã¨ç™ºå…‰åŠ¹ç‡ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•': '3.8 Multi-Objective Optimization: Size and Emission Efficiency Trade-offs',
        '3.9 TEMç”»åƒè§£æã¨ã‚µã‚¤ã‚ºåˆ†å¸ƒ': '3.9 TEM Image Analysis and Size Distribution',
        '3.10 åˆ†å­å‹•åŠ›å­¦ï¼ˆMDï¼‰ãƒ‡ãƒ¼ã‚¿è§£æ': '3.10 Molecular Dynamics (MD) Data Analysis',
        '3.11 ç•°å¸¸æ¤œçŸ¥ï¼šå“è³ªç®¡ç†ã¸ã®å¿œç”¨': '3.11 Anomaly Detection: Quality Control Applications',
        '3.12 ç« æœ«ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆï¼šãƒŠãƒææ–™ãƒ‡ãƒ¼ã‚¿è§£æã‚¹ã‚­ãƒ«ã®å“è³ªä¿è¨¼': '3.12 End-of-Chapter Checklist: Quality Assurance of Nanomaterial Data Analysis Skills',

        # Subsections
        'å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒª': 'Required Libraries',
        'ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ–¹æ³•': 'Installation Methods',
        'æœ¬ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã§ä½¿ç”¨ã™ã‚‹ä¸»è¦ãªPythonãƒ©ã‚¤ãƒ–ãƒ©ãƒªï¼š': 'Main Python libraries used in this tutorial:',

        # Common patterns - examples
        'ã€ä¾‹1ã€‘åˆæˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆï¼šé‡‘ãƒŠãƒç²’å­ã®ã‚µã‚¤ã‚ºã¨å…‰å­¦ç‰¹æ€§': '[Example 1] Synthetic Data Generation: Size and Optical Properties of Gold Nanoparticles',
        'ã€ä¾‹2ã€‘ã‚µã‚¤ã‚ºåˆ†å¸ƒã®ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ': '[Example 2] Size Distribution Histogram',
        'ã€ä¾‹3ã€‘æ•£å¸ƒå›³ãƒãƒˆãƒªãƒƒã‚¯ã‚¹': '[Example 3] Scatter Plot Matrix',
        'ã€ä¾‹4ã€‘ç›¸é–¢è¡Œåˆ—ã®ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—': '[Example 4] Correlation Matrix Heatmap',
        'ã€ä¾‹5ã€‘3Dãƒ—ãƒ­ãƒƒãƒˆï¼šã‚µã‚¤ã‚º vs æ¸©åº¦ vs LSPR': '[Example 5] 3D Plot: Size vs Temperature vs LSPR',
        'ã€ä¾‹6ã€‘æ¬ æå€¤å‡¦ç†': '[Example 6] Missing Value Handling',
        'ã€ä¾‹7ã€‘å¤–ã‚Œå€¤æ¤œå‡ºï¼ˆIQRæ³•ï¼‰': '[Example 7] Outlier Detection (IQR Method)',
        'ã€ä¾‹8ã€‘ç‰¹å¾´é‡ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ï¼ˆStandardScalerï¼‰': '[Example 8] Feature Scaling (StandardScaler)',
        'ã€ä¾‹9ã€‘è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®åˆ†å‰²': '[Example 9] Train-Test Data Splitting',
        'ã€ä¾‹10ã€‘ç·šå½¢å›å¸°ï¼ˆLinear Regressionï¼‰': '[Example 10] Linear Regression',
        'ã€ä¾‹11ã€‘ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆå›å¸°ï¼ˆRandom Forestï¼‰': '[Example 11] Random Forest Regression',
        'ã€ä¾‹12ã€‘å‹¾é…ãƒ–ãƒ¼ã‚¹ãƒ†ã‚£ãƒ³ã‚°ï¼ˆLightGBMï¼‰': '[Example 12] Gradient Boosting (LightGBM)',
        'ã€ä¾‹13ã€‘ã‚µãƒãƒ¼ãƒˆãƒ™ã‚¯ã‚¿ãƒ¼å›å¸°ï¼ˆSVRï¼‰': '[Example 13] Support Vector Regression (SVR)',
        'ã€ä¾‹14ã€‘ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼ˆMLP Regressorï¼‰': '[Example 14] Neural Network (MLP Regressor)',
        'ã€ä¾‹15ã€‘ãƒ¢ãƒ‡ãƒ«æ€§èƒ½æ¯”è¼ƒ': '[Example 15] Model Performance Comparison',
        'ã€ä¾‹16ã€‘ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆï¼šCdSeé‡å­ãƒ‰ãƒƒãƒˆ': '[Example 16] Data Generation: CdSe Quantum Dots',
        'ã€ä¾‹17ã€‘é‡å­ãƒ‰ãƒƒãƒˆãƒ¢ãƒ‡ãƒ«ï¼ˆLightGBMï¼‰': '[Example 17] Quantum Dot Model (LightGBM)',
        'ã€ä¾‹18ã€‘äºˆæ¸¬çµæœã®å¯è¦–åŒ–': '[Example 18] Prediction Result Visualization',
        'ã€ä¾‹19ã€‘ç‰¹å¾´é‡é‡è¦åº¦ï¼ˆLightGBMï¼‰': '[Example 19] Feature Importance (LightGBM)',
        'ã€ä¾‹20ã€‘SHAPåˆ†æï¼šäºˆæ¸¬è§£é‡ˆ': '[Example 20] SHAP Analysis: Prediction Interpretation',
        'ã€ä¾‹21ã€‘æ¢ç´¢ç©ºé–“ã®å®šç¾©': '[Example 21] Search Space Definition',
        'ã€ä¾‹22ã€‘ç›®çš„é–¢æ•°ã®è¨­å®š': '[Example 22] Objective Function Setup',
        'ã€ä¾‹23ã€‘ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã®å®Ÿè¡Œï¼ˆscikit-optimizeï¼‰': '[Example 23] Running Bayesian Optimization (scikit-optimize)',
        'ã€ä¾‹24ã€‘æœ€é©åŒ–çµæœã®å¯è¦–åŒ–': '[Example 24] Optimization Result Visualization',
        'ã€ä¾‹25ã€‘åæŸãƒ—ãƒ­ãƒƒãƒˆ': '[Example 25] Convergence Plot',
        'ã€ä¾‹26ã€‘Paretoæœ€é©åŒ–ï¼ˆNSGA-IIï¼‰': '[Example 26] Pareto Optimization (NSGA-II)',
        'ã€ä¾‹27ã€‘Paretoãƒ•ãƒ­ãƒ³ãƒˆã®å¯è¦–åŒ–': '[Example 27] Pareto Front Visualization',
        'ã€ä¾‹28ã€‘æ¨¡æ“¬TEMãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆ': '[Example 28] Simulated TEM Data Generation',
        'ã€ä¾‹29ã€‘å¯¾æ•°æ­£è¦åˆ†å¸ƒãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°': '[Example 29] Log-Normal Distribution Fitting',
        'ã€ä¾‹30ã€‘ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°çµæœã®å¯è¦–åŒ–': '[Example 30] Fitting Result Visualization',
        'ã€ä¾‹31ã€‘MDã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿': '[Example 31] Loading MD Simulation Data',
        'ã€ä¾‹32ã€‘å‹•å¾„åˆ†å¸ƒé–¢æ•°ï¼ˆRDFï¼‰ã®è¨ˆç®—': '[Example 32] Radial Distribution Function (RDF) Calculation',
        'ã€ä¾‹33ã€‘æ‹¡æ•£ä¿‚æ•°ã®è¨ˆç®—ï¼ˆMean Squared Displacementï¼‰': '[Example 33] Diffusion Coefficient Calculation (Mean Squared Displacement)',
        'ã€ä¾‹34ã€‘Isolation Forestã«ã‚ˆã‚‹ç•°å¸¸ãƒŠãƒç²’å­æ¤œå‡º': '[Example 34] Anomalous Nanoparticle Detection with Isolation Forest',
        'ã€ä¾‹35ã€‘ç•°å¸¸ã‚µãƒ³ãƒ—ãƒ«ã®å¯è¦–åŒ–': '[Example 35] Anomaly Sample Visualization',

        # Code comment translations
        '# ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ»å¯è¦–åŒ–': '# Data processing and visualization',
        '# æ©Ÿæ¢°å­¦ç¿’': '# Machine learning',
        '# æœ€é©åŒ–': '# Optimization',
        '# ãƒ¢ãƒ‡ãƒ«è§£é‡ˆ': '# Model interpretation',
        '# å¤šç›®çš„æœ€é©åŒ–ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰': '# Multi-objective optimization (optional)',
        '# Anacondaã§æ–°ã—ã„ç’°å¢ƒã‚’ä½œæˆ': '# Create new Anaconda environment',
        '# å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«': '# Install required libraries',
        '# å¤šç›®çš„æœ€é©åŒ–ç”¨ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰': '# For multi-objective optimization (optional)',
        '# ä»®æƒ³ç’°å¢ƒã‚’ä½œæˆ': '# Create virtual environment',
        '# ä»®æƒ³ç’°å¢ƒã‚’æœ‰åŠ¹åŒ–': '# Activate virtual environment',
        '# è¿½åŠ ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«': '# Install additional packages',
        '# ã‚¤ãƒ³ãƒãƒ¼ãƒˆã®ç¢ºèª': '# Verify imports',
        '# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®šï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰': '# Font settings (adjust as needed)',
        '# ä¹±æ•°ã‚·ãƒ¼ãƒ‰ã®è¨­å®šï¼ˆå†ç¾æ€§ã®ãŸã‚ï¼‰': '# Set random seed (for reproducibility)',
        '# ã‚µãƒ³ãƒ—ãƒ«æ•°': '# Number of samples',
        '# é‡‘ãƒŠãƒç²’å­ã®ã‚µã‚¤ã‚ºï¼ˆnmï¼‰: å¹³å‡15 nmã€æ¨™æº–åå·®5 nm': '# Gold nanoparticle size (nm): mean 15 nm, std 5 nm',
        '# LSPRæ³¢é•·ï¼ˆnmï¼‰: Mieç†è«–ã®ç°¡æ˜“è¿‘ä¼¼': '# LSPR wavelength (nm): simplified Mie theory approximation',
        '# åŸºæœ¬æ³¢é•·520 nm + ã‚µã‚¤ã‚ºä¾å­˜é … + ãƒã‚¤ã‚º': '# Base wavelength 520 nm + size-dependent term + noise',
        '# åˆæˆæ¡ä»¶': '# Synthesis conditions',
        '# æ¸©åº¦ï¼ˆâ„ƒï¼‰': '# Temperature (Â°C)',
        '# ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®ä½œæˆ': '# Create DataFrame',
        '# ã‚µã‚¤ã‚ºåˆ†å¸ƒã®ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ': '# Size distribution histogram',
        '# ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ã¨KDEï¼ˆã‚«ãƒ¼ãƒãƒ«å¯†åº¦æ¨å®šï¼‰': '# Histogram and KDE (kernel density estimation)',
        '# KDEãƒ—ãƒ­ãƒƒãƒˆ': '# KDE plot',
        '# ãƒšã‚¢ãƒ—ãƒ­ãƒƒãƒˆï¼ˆæ•£å¸ƒå›³ãƒãƒˆãƒªãƒƒã‚¯ã‚¹ï¼‰': '# Pairplot (scatter plot matrix)',
        '# ç›¸é–¢è¡Œåˆ—ã®è¨ˆç®—': '# Calculate correlation matrix',
        '# ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—': '# Heatmap',
        '# 3Dæ•£å¸ƒå›³': '# 3D scatter plot',
        '# ã‚«ãƒ©ãƒ¼ãƒãƒƒãƒ—': '# Colormap',
        '# ã‚«ãƒ©ãƒ¼ãƒãƒ¼': '# Colorbar',
        '# æ¬ æå€¤ã‚’äººç‚ºçš„ã«å°å…¥ï¼ˆå®Ÿç¿’ç”¨ï¼‰': '# Introduce missing values artificially (for practice)',
        '# ãƒ©ãƒ³ãƒ€ãƒ ã«5%ã®æ¬ æå€¤ã‚’å°å…¥': '# Introduce 5% missing values randomly',
        '# æ¬ æå€¤ã®å‡¦ç†æ–¹æ³•1: å¹³å‡å€¤ã§è£œå®Œ': '# Missing value handling method 1: fill with mean',
        '# æ¬ æå€¤ã®å‡¦ç†æ–¹æ³•2: ä¸­å¤®å€¤ã§è£œå®Œ': '# Missing value handling method 2: fill with median',
        '# æ¬ æå€¤ã®å‡¦ç†æ–¹æ³•3: å‰Šé™¤': '# Missing value handling method 3: drop',
        '# ä»¥é™ã®åˆ†æã§ã¯å…ƒã®ãƒ‡ãƒ¼ã‚¿ï¼ˆæ¬ æå€¤ãªã—ï¼‰ã‚’ä½¿ç”¨': '# Use original data (no missing values) for subsequent analysis',
        '# IQRï¼ˆå››åˆ†ä½ç¯„å›²ï¼‰æ³•ã«ã‚ˆã‚‹å¤–ã‚Œå€¤æ¤œå‡º': '# Outlier detection using IQR (interquartile range) method',
        '# ã‚µã‚¤ã‚ºã«ã¤ã„ã¦å¤–ã‚Œå€¤æ¤œå‡º': '# Detect outliers in size',
        '# å¯è¦–åŒ–': '# Visualization',
        '# ç‰¹å¾´é‡ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®åˆ†é›¢': '# Separate features and target',
        '# StandardScalerï¼ˆå¹³å‡0ã€æ¨™æº–åå·®1ã«æ¨™æº–åŒ–ï¼‰': '# StandardScaler (normalize to mean 0, std 1)',
        '# ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°å‰å¾Œã®æ¯”è¼ƒ': '# Compare before and after scaling',
        '# è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«åˆ†å‰²ï¼ˆ80:20ï¼‰': '# Split into training and test data (80:20)',
        '# ç·šå½¢å›å¸°ãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰': '# Build linear regression model',
        '# äºˆæ¸¬': '# Prediction',
        '# è©•ä¾¡æŒ‡æ¨™': '# Evaluation metrics',
        '# å›å¸°ä¿‚æ•°': '# Regression coefficients',
        '# æ®‹å·®ãƒ—ãƒ­ãƒƒãƒˆ': '# Residual plot',
        '# äºˆæ¸¬å€¤ vs å®Ÿæ¸¬å€¤': '# Predicted vs actual values',
        '# ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆå›å¸°ãƒ¢ãƒ‡ãƒ«': '# Random forest regression model',
        '# è©•ä¾¡': '# Evaluation',
        '# ç‰¹å¾´é‡é‡è¦åº¦': '# Feature importance',
        '# ç‰¹å¾´é‡é‡è¦åº¦ã®å¯è¦–åŒ–': '# Visualize feature importance',
        '# LightGBMãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰': '# Build LightGBM model',
        '# äºˆæ¸¬å€¤ vs å®Ÿæ¸¬å€¤ãƒ—ãƒ­ãƒƒãƒˆ': '# Predicted vs actual values plot',
        '# SVRãƒ¢ãƒ‡ãƒ«ï¼ˆRBFã‚«ãƒ¼ãƒãƒ«ï¼‰': '# SVR model (RBF kernel)',
        '# MLPãƒ¢ãƒ‡ãƒ«': '# MLP model',
        '# å…¨ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’ã¾ã¨ã‚ã‚‹': '# Summarize all model performances',
        '# æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ã®ç‰¹å®š': '# Identify best model',
        '# RÂ²ã‚¹ã‚³ã‚¢æ¯”è¼ƒ': '# RÂ² score comparison',

        # Common text patterns
        'ç’°å¢ƒæ§‹ç¯‰å®Œäº†ï¼': 'Environment setup complete!',
        'é‡‘ãƒŠãƒç²’å­ãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆå®Œäº†': 'Gold nanoparticle data generation complete',
        'åŸºæœ¬çµ±è¨ˆé‡:': 'Basic statistics:',
        'å¹³å‡ã‚µã‚¤ã‚º': 'Average size',
        'æ¨™æº–åå·®': 'Standard deviation',
        'ä¸­å¤®å€¤': 'Median',
        'å„å¤‰æ•°é–“ã®é–¢ä¿‚ã‚’å¯è¦–åŒ–ã—ã¾ã—ãŸ': 'Visualized relationships between variables',
        'ç›¸é–¢ä¿‚æ•°:': 'Correlation coefficients:',
        'LSPRæ³¢é•·ã¨ã‚µã‚¤ã‚ºã®ç›¸é–¢': 'Correlation between LSPR wavelength and size',
        '3Dãƒ—ãƒ­ãƒƒãƒˆã§å¤šæ¬¡å…ƒã®é–¢ä¿‚ã‚’å¯è¦–åŒ–ã—ã¾ã—ãŸ': 'Visualized multidimensional relationships with 3D plot',
        'æ¬ æå€¤ã®ç¢ºèª': 'Check missing values',
        'æ¬ æå€¤ã®æ•°:': 'Number of missing values:',
        'å…ƒã®ãƒ‡ãƒ¼ã‚¿:': 'Original data:',
        'æ¬ æå€¤å‰Šé™¤å¾Œ:': 'After dropping missing values:',
        'å¹³å‡å€¤è£œå®Œå¾Œ:': 'After mean imputation:',
        'è¡Œ': 'rows',
        'ï¼ˆæ¬ æå€¤ãªã—ï¼‰': '(no missing values)',
        'â†’ ä»¥é™ã¯æ¬ æå€¤ã®ãªã„ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¾ã™': 'â†’ Using data without missing values henceforth',
        'å¤–ã‚Œå€¤æ¤œå‡ºï¼ˆIQRæ³•ï¼‰': 'Outlier Detection (IQR Method)',
        'æ¤œå‡ºã•ã‚ŒãŸå¤–ã‚Œå€¤ã®æ•°': 'Number of detected outliers',
        'ä¸‹é™': 'Lower bound',
        'ä¸Šé™': 'Upper bound',
        'â†’ å¤–ã‚Œå€¤ã¯é™¤å»ã›ãšã€å…¨ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¾ã™': 'â†’ Using all data without removing outliers',
        'ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°å‰ã®çµ±è¨ˆé‡': 'Statistics before scaling',
        'ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°å¾Œã®çµ±è¨ˆé‡ï¼ˆå¹³å‡â‰ˆ0ã€æ¨™æº–åå·®â‰ˆ1ï¼‰': 'Statistics after scaling (meanâ‰ˆ0, stdâ‰ˆ1)',
        'â†’ ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã«ã‚ˆã‚Šå„ç‰¹å¾´é‡ã®ã‚¹ã‚±ãƒ¼ãƒ«ãŒçµ±ä¸€ã•ã‚Œã¾ã—ãŸ': 'â†’ Scaling unified the scale of each feature',
        'ãƒ‡ãƒ¼ã‚¿åˆ†å‰²': 'Data Split',
        'å…¨ãƒ‡ãƒ¼ã‚¿æ•°': 'Total data',
        'ã‚µãƒ³ãƒ—ãƒ«': 'samples',
        'è¨“ç·´ãƒ‡ãƒ¼ã‚¿': 'Training data',
        'ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿': 'Test data',
        'è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆé‡:': 'Training data statistics:',
        'ç›®æ¨™ï¼šã‚µã‚¤ã‚ºã€æ¸©åº¦ã€pHã‹ã‚‰LSPRæ³¢é•·ã‚’äºˆæ¸¬': 'Goal: Predict LSPR wavelength from size, temperature, and pH',
        'ç·šå½¢å›å¸°ï¼ˆLinear Regressionï¼‰': 'Linear Regression',
        'è¨“ç·´ãƒ‡ãƒ¼ã‚¿ RÂ²': 'Training RÂ²',
        'ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ RÂ²': 'Test RÂ²',
        'ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ RMSE': 'Test RMSE',
        'ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ MAE': 'Test MAE',
        'åˆ‡ç‰‡': 'Intercept',
        'ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆå›å¸°ï¼ˆRandom Forestï¼‰': 'Random Forest Regression',
        'å‹¾é…ãƒ–ãƒ¼ã‚¹ãƒ†ã‚£ãƒ³ã‚°ï¼ˆLightGBMï¼‰': 'Gradient Boosting (LightGBM)',
        'ã‚µãƒãƒ¼ãƒˆãƒ™ã‚¯ã‚¿ãƒ¼å›å¸°ï¼ˆSVRï¼‰': 'Support Vector Regression (SVR)',
        'ã‚µãƒãƒ¼ãƒˆãƒ™ã‚¯ã‚¿ãƒ¼æ•°': 'Number of support vectors',
        'ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼ˆMLP Regressorï¼‰': 'Neural Network (MLP Regressor)',
        'åå¾©å›æ•°': 'Number of iterations',
        'éš ã‚Œå±¤ã®æ§‹é€ ': 'Hidden layer structure',
        'å…¨ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½æ¯”è¼ƒ': 'Performance Comparison of All Models',
        'æœ€è‰¯ãƒ¢ãƒ‡ãƒ«': 'Best model',

        # Summary and exercises
        'ã¾ã¨ã‚': 'Summary',
        'ç¿’å¾—ã—ãŸä¸»è¦æŠ€è¡“': 'Key Skills Acquired',
        'å®Ÿè·µçš„ãªå¿œç”¨': 'Practical Applications',
        'æ¬¡ç« ã®äºˆå‘Š': 'Preview of Next Chapter',
        'å‚è€ƒæ–‡çŒ®': 'References',

        # Skill levels
        'åŸºç¤ãƒ¬ãƒ™ãƒ«': 'Foundation Level',
        'å¿œç”¨ãƒ¬ãƒ™ãƒ«': 'Applied Level',
        'ä¸Šç´šãƒ¬ãƒ™ãƒ«': 'Advanced Level',
        'é”æˆ': 'Achieved',
        'åˆ°é”ç›®æ¨™': 'Learning Goal',
        'ç’°å¢ƒæ§‹ç¯‰ã‚¹ã‚­ãƒ«': 'Environment Setup Skills',
        'ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ»å¯è¦–åŒ–ã‚¹ã‚­ãƒ«': 'Data Processing & Visualization Skills',
        'æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«å®Ÿè£…ã‚¹ã‚­ãƒ«': 'Machine Learning Model Implementation Skills',
        'ç‰¹å¾´é‡é‡è¦åº¦ã¨ãƒ¢ãƒ‡ãƒ«è§£é‡ˆã‚¹ã‚­ãƒ«': 'Feature Importance & Model Interpretation Skills',
        'ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã‚¹ã‚­ãƒ«': 'Bayesian Optimization Skills',

        # Verbs and actions
        'ã‚’å®Ÿè£…ã§ãã‚‹': 'can implement',
        'ã‚’è¨ˆç®—ã§ãã‚‹': 'can calculate',
        'ã‚’è§£æ±ºã§ãã‚‹': 'can solve',
        'éå­¦ç¿’ã‚’æ¤œå‡ºã§ãã‚‹': 'can detect overfitting',
        'ä»¥ä¸Šé”æˆ': 'or more achieved',
        'å®Œé‚ç¢ºèª': 'Completion check',

        # Units and measurements
        'nm': 'nm',
        'â„ƒ': 'Â°C',
        'åˆ†': 'min',

        # Option labels
        'Option 1: Anacondaç’°å¢ƒ': 'Option 1: Anaconda Environment',
        'Option 2: venv + pipç’°å¢ƒ': 'Option 2: venv + pip Environment',
        'Option 3: Google Colab': 'Option 3: Google Colab',
        'Google Colabã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã€ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã‚’ã‚»ãƒ«ã§å®Ÿè¡Œï¼š':
            'When using Google Colab, execute the following code in a cell:',

        # Technical terms
        'é‡‘ãƒŠãƒç²’å­ã®å±€åœ¨è¡¨é¢ãƒ—ãƒ©ã‚ºãƒ¢ãƒ³å…±é³´ï¼ˆLSPRï¼‰æ³¢é•·ã¯ã€ç²’å­ã‚µã‚¤ã‚ºã«ä¾å­˜ã—ã¾ã™ã€‚ã“ã®é–¢ä¿‚ã‚’æ¨¡æ“¬ãƒ‡ãƒ¼ã‚¿ã§è¡¨ç¾ã—ã¾ã™ã€‚':
            'The localized surface plasmon resonance (LSPR) wavelength of gold nanoparticles depends on particle size. This relationship is represented with simulated data.',
        'é‡å­ãƒ‰ãƒƒãƒˆ': 'quantum dots',
        'å‹•å¾„åˆ†å¸ƒé–¢æ•°': 'radial distribution function',
        'æ‹¡æ•£ä¿‚æ•°': 'diffusion coefficient',
        'å¹³å‡äºŒä¹—å¤‰ä½': 'mean squared displacement',
        'ç•°å¸¸æ¤œçŸ¥': 'anomaly detection',

        # Exercise patterns
        'æ¼”ç¿’': 'Exercise',
        'è§£ç­”ä¾‹': 'Sample Solution',
        'ç›®æ¨™ã‚µã‚¤ã‚º': 'Target size',
        'ç›®æ¨™': 'Goal',
        'æ³¢é•·': 'wavelength',
        'ãƒ—ãƒ­ãƒƒãƒˆ': 'plot',
        'è©•ä¾¡': 'evaluation',
        'ãƒ¢ãƒ‡ãƒ«': 'model',
        'è¨“ç·´': 'training',
        'äºˆæ¸¬': 'prediction',
        'å¯è¦–åŒ–': 'visualization',
        'ã‚µã‚¤ã‚º': 'size',
        'æ¸©åº¦': 'temperature',
        'å¹³å‡': 'average',
        'æ•£å¸ƒå›³': 'scatter plot',
        'ç·šå½¢å›å¸°': 'linear regression',
        'äºˆæ¸¬å€¤': 'predicted value',
        'ã®è¨ˆç®—': 'calculation',
        'ãƒ™ã‚¤ã‚ºæœ€é©åŒ–': 'Bayesian optimization',
        'æœ€é©åŒ–': 'optimization',
        'ç›®çš„é–¢æ•°': 'objective function',
        'å¤šç›®çš„æœ€é©åŒ–': 'multi-objective optimization',
        'ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ': 'histogram',
        'ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ': 'data generation',
        'ãƒ‡ãƒ¼ã‚¿è§£æ': 'data analysis',
        'ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆ': 'random forest',
        'ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯': 'neural network',
        'ã®ç¯„å›²ã«åˆ¶é™': 'clipped to range',
        'ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«': 'install',
        'ã‚’ä½¿ç”¨': 'use',
        'é‡‘å±æ¢çŸ¥æ©Ÿ': 'metal detector',
        'çš„ã«å½“ãŸã‚Šã‚’å°ãã¾ã™': 'guides you to hits',
        'æ³•': 'method',
        'ãƒ¬ãƒ™ãƒ«': 'level',
        'ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°': 'scaling',
        'æ¢ç´¢ç©ºé–“ã®å®šç¾©': 'search space definition',
        'åæŸãƒ—ãƒ­ãƒƒãƒˆ': 'convergence plot',
        'æ¬ æå€¤å‡¦ç†': 'missing value handling',
        'å¤–ã‚Œå€¤æ¤œå‡º': 'outlier detection',
        'æ•£å¸ƒå›³ãƒãƒˆãƒªãƒƒã‚¯ã‚¹': 'scatter plot matrix',
        'ã‚µãƒ³ãƒ—ãƒ«æ•°': 'number of samples',
        'ç‰¹å¾´é‡é‡è¦åº¦': 'feature importance',
        'ãƒ¢ãƒ‡ãƒ«è§£é‡ˆ': 'model interpretation',
        'å®Ÿè·µãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«': 'hands-on tutorial',
        'ã®': '',  # Remove standalone ã® particles where appropriate
        'ä¾‹': 'Example',

        # Footer
        'Â© 2024 AIå¯ºå­å±‹': 'Â© 2024 AI Terakoya',

        # Additional common patterns - verbs and particles
        'ã§ãã‚‹': 'can',
        'ã‚’ä½œæˆã§ãã‚‹': 'can create',
        'ã‚’å®Ÿè£…ã§ãã‚‹': 'can implement',
        'ã‚’è¨ˆç®—ã§ãã‚‹': 'can calculate',
        'ã‚’ä½œæˆãƒ»è§£é‡ˆã§ãã‚‹': 'can create and interpret',
        'ã‚’å–å¾—ãƒ»': 'acquire and',
        'ã‚’å®Ÿè£…ã—': 'implement and',
        'ã‚’å®Ÿè£…': 'implement',
        'ã‘ã‚‰ã‚Œã‚‹': 'can be done',
        'ãŒã§ãã‚‹': 'can be done',
        'ã‚’å®Ÿ': 'implement',
        'ã«ã‚ˆã‚‹': 'by',
        'ã§ã¯': 'in',
        'ã¨': 'and',
        'ã§': 'with',
        'ã‚’': '',
        'ã¯': 'is',
        'ãŒ': '',
        'ã®': 'of',
        'ã«': 'to',
        'ã¨èª¤å·®': 'and error',
        'ã¤': '',
        'ã—': '',

        # Technical terms from remaining patterns
        'å¯¾æ•°æ­£è¦': 'log-normal',
        'å¸ƒ': 'distribution',
        'å¯¾æ•°æ­£è¦å¸ƒ': 'log-normal distribution',
        'å¸ƒã«å¾“ã†': 'follows distribution',
        'å¸ƒãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°': 'distribution fitting',
        'å¸ƒãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿': 'distribution parameters',
        'ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°ã•ã‚ŒãŸ': 'fitted',
        'ãƒ•ã‚£ãƒƒãƒˆ': 'fit',

        # Measurement and statistics
        'ä»¥ä¸Š': 'or more',
        'çµæœ': 'results',
        'èª¤å·®': 'error',
        'å€¤': 'value',
        'ç²¾åº¦': 'accuracy',
        'çµ¶å¯¾èª¤å·®': 'absolute error',
        'ç›¸é–¢': 'correlation',

        # Data and analysis
        'æ': 'analysis',
        'æã«ã‚ˆã‚‹': 'by analysis',
        'å®Ÿæ¸¬å€¤ã¨æ¯”è¼ƒ': 'compared with measured values',
        'å®Ÿæ¸¬': 'measured',
        'å®Œäº†': 'complete',
        'æ§‹ç¯‰': 'construction',
        'ç”»åƒè§£æ': 'image analysis',
        'å­å‹•åŠ›å­¦': 'molecular dynamics',
        'ç›´å¾„': 'diameter',
        'æœ€ã‚‚é‡è¦ãªç‰¹å¾´é‡': 'most important feature',

        # Processes and operations
        'ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ': 'data generation',
        'ãƒ†ã‚¹ãƒˆ': 'test',
        'ãƒ†ã‚¹ãƒˆå®Ÿ': 'test implementation',
        'å‰²': 'split',
        'åˆ¥': 'classification',
        'ãƒ—ãƒ­ã‚»ã‚¹': 'process',
        'é©ç”¨': 'application',
        'ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿': 'parameters',
        'å›æ•°': 'number of times',
        'å›': 'times',
        'ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°å›æ•°': 'random sampling count',
        'ä¸­': 'middle',

        # Optimization terms
        'æœ€å°åŒ–': 'minimization',
        'æœ€é©': 'optimal',
        'æœ€é©æ¡ä»¶ã§': 'under optimal conditions',
        'æœ€è‰¯å€¤æ¨ç§»': 'best value progression',
        'å±¥æ­´': 'history',

        # Emission and optical properties
        'ç™ºå…‰': 'emission',
        'å¤šè‰²ç™ºå…‰è¨­è¨ˆ': 'multi-color emission design',
        'åŠ¹ç‡æœ€å¤§åŒ–': 'efficiency maximization',

        # Algorithms and models
        'ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ': 'algorithm',
        'ã‚’ä½œæˆ': 'create',

        # Quantum dots and nanoparticles
        'ç²’å­': 'particles',
        'éŠ€ãƒŠãƒç²’å­æœ€é©åˆæˆæ¡ä»¶': 'optimal silver nanoparticle synthesis conditions',

        # MD simulation
        'åŸå­æ•°': 'number of atoms',
        'åŸå­ä½ç½®': 'atom positions',
        'ã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ—æ•°': 'number of timesteps',
        'é–¢ä¿‚å¼': 'relationship equation',
        'æ–¹ç¨‹å¼ã«åŸºã¥ã': 'based on equation',
        'æ–¹ç¨‹å¼ç°¡æ˜“è¿‘ä¼¼': 'equation simplified approximation',
        'ãƒ¢ãƒ«æ¯”': 'molar ratio',

        # Anomaly detection
        'æ­£å¸¸': 'normal',
        'ç•°å¸¸': 'anomaly',
        'ç•°å¸¸ãƒ‡ãƒ¼ã‚¿å‰²åˆ': 'anomaly data ratio',
        'æ··åŒ': 'confusion',
        'ç•°å¸¸ã‚¹ã‚³ã‚¢': 'anomaly score',

        # Rankings and ordering
        'ä¸Šä½': 'top',

        # Data relationships
        'é–¢ä¿‚': 'relationship',
        'ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ä½œæˆ': 'create DataFrame',
        'ç™ºå…‰ã¨': 'emission and',
        'çµæœã‚’': 'results',

        # Skill categories
        'è‡ª': 'self',
        'è¤‡æ•°': 'multiple',
        'ãƒ©ã‚¤ãƒ–ãƒ©ãƒª': 'library',
        'èµ¤ãƒ»ç·‘ãƒ»é’': 'red, green, blue',
        'æ¦‚å¿µã‚’ç†è§£ã—ã¦ã„ã‚‹': 'understand the concept',
        'ã‚¹ã‚­ãƒ«': 'skills',
        'ãƒŠãƒææ–™ç‰¹æœ‰è§£æã‚¹ã‚­ãƒ«': 'nanomaterial-specific analysis skills',
        'å…¨ã‚«ãƒ†ã‚´ãƒª': 'all categories',
        'ã¸æº–å‚™': 'prepare for',
        'å‰ç« ': 'previous chapter',
        'æ¬¡ç« ': 'next chapter',
        'ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆå®Œäº†': 'data generation complete',

        # Example sentences
        'å°‘ãªã„è©¦ã§è‰¯ã„æ¡ä»¶ã‚’è¦‹ã¤ã‘ã‚‹ãŒ': 'finding good conditions with few trials is the goal',
        'å›å¸°ä¿‚æ•°æ¯”è¼ƒ': 'regression coefficient comparison',
        'ä¿¡é ¼åŒºé–“ä»˜ã': 'with confidence interval',
        'ç¯„å›²': 'range',
        'é›»æ°—ä¼å°åº¦': 'electrical conductivity',

        # Additional fragments
        'ã¨ç™ºå…‰': 'and emission',
        'ã«ä¾å­˜ã—ã¾ã™': 'depends on',
    }

    return translations

def apply_translations(content, translations):
    """Apply translations with proper ordering"""
    result = content

    # Sort by length (descending) to avoid partial replacements
    sorted_translations = sorted(translations.items(), key=lambda x: len(x[0]), reverse=True)

    for jp, en in sorted_translations:
        result = result.replace(jp, en)

    return result

def count_japanese_chars(text):
    """Count remaining Japanese characters"""
    jp_pattern = re.compile(r'[\u3040-\u309F\u30A0-\u30FF\u4E00-\u9FFF]')
    matches = jp_pattern.findall(text)
    return len(matches)

def find_japanese_segments(text, limit=20):
    """Find Japanese text segments"""
    jp_pattern = re.compile(r'[\u3040-\u309F\u30A0-\u30FF\u4E00-\u9FFF]+')
    matches = jp_pattern.findall(text)
    return matches[:limit]

def main():
    print("=" * 80)
    print("NM Chapter 3: Complete Translation (JP â†’ EN)")
    print("=" * 80)

    # Read Japanese file
    print("\n[1/5] Reading Japanese source file...")
    with open(JP_FILE, 'r', encoding='utf-8') as f:
        content = f.read()

    initial_jp_count = count_japanese_chars(content)
    total_lines = content.count('\n') + 1
    print(f"      Total lines: {total_lines}")
    print(f"      Japanese chars: {initial_jp_count}")

    # Create translations
    print("\n[2/5] Creating translation dictionary...")
    translations = create_comprehensive_translations()
    print(f"      Translation entries: {len(translations)}")

    # Apply translations
    print("\n[3/5] Applying translations...")
    translated = apply_translations(content, translations)

    # Count remaining Japanese
    final_jp_count = count_japanese_chars(translated)
    jp_percent = (final_jp_count / len(translated) * 100) if len(translated) > 0 else 0

    print(f"      Japanese chars remaining: {final_jp_count}")
    print(f"      Reduction: {initial_jp_count - final_jp_count} chars")
    print(f"      Japanese percentage: {jp_percent:.2f}%")

    # Write output
    print("\n[4/5] Writing translated file...")
    output_path = Path(EN_FILE)
    output_path.parent.mkdir(parents=True, exist_ok=True)

    with open(EN_FILE, 'w', encoding='utf-8') as f:
        f.write(translated)

    print(f"      Output: {EN_FILE}")

    # Report
    print("\n[5/5] Translation Report")
    print("=" * 80)
    print(f"âœ“ File translated successfully!")
    print(f"  Total lines: {total_lines}")
    print(f"  Japanese chars: {initial_jp_count} â†’ {final_jp_count}")
    print(f"  Remaining JP: {jp_percent:.2f}%")

    if final_jp_count > 0:
        print(f"\nâš  Warning: {final_jp_count} Japanese characters remain")
        print("  First 20 Japanese segments:")
        segments = find_japanese_segments(translated, 20)
        for i, seg in enumerate(segments, 1):
            print(f"    {i:2d}. {seg}")
    else:
        print("\nâœ“ Perfect translation - no Japanese characters remain!")

    print("\n" + "=" * 80)
    print("Translation complete!")
    print("=" * 80)

if __name__ == "__main__":
    main()
